From drj|m|emon @end|ng |rom gm@||@com  Thu Nov  1 00:25:27 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 1 Nov 2018 10:25:27 +1100
Subject: [R] Different stack barplots - same color legends
In-Reply-To: <CAKDq9_OU8bNq4p8zLr45JADz=SWvGAhG+-ACqdu+qC4a+D8FUw@mail.gmail.com>
References: <CAKDq9_N16xaeL4O2j=v2bVuMb=tuHfu0Ao+yuLQcEq6B-ngq1A@mail.gmail.com>
 <af9001d319ac4992b0bfc5526150f03b@tamu.edu>
 <CAKDq9_P8hQEHWFH=c_86bG81fU0GS+EUCOmtZ9gJa_7kY-2uhA@mail.gmail.com>
 <CAGx1TMAYybconxY7ZVVJcdiYW6+WOjr_D+=GHOA=Xxv2AWRCqQ@mail.gmail.com>
 <CAKDq9_Oi0HGNV7qLnmi4HgVr7orF_gpC7Sys8mLKAxMfjHVtvQ@mail.gmail.com>
 <CAGx1TMB+=RnNeoBmzF=_-gxZ2bzaabExs2Gf-8dKE2vAcpiHpA@mail.gmail.com>
 <CAKDq9_P3GfHXbFbChQwrDUm=E+RuuWGP89tf_KPFXRjYAsrA+A@mail.gmail.com>
 <CAGx1TMByCiZvwOPm06qo4bssWjh=UP9ZPvkX5zi+6dNE=wggaA@mail.gmail.com>
 <CAKDq9_OkLfiP98cuYUg0BU_+cCXmKi9gKHqxSm+Eu16eC3WWyg@mail.gmail.com>
 <CAGx1TMCF8bg64+UOP9ULygHcRnna505RO+1WCWxWJuuFaNp4fQ@mail.gmail.com>
 <CAKDq9_OU8bNq4p8zLr45JADz=SWvGAhG+-ACqdu+qC4a+D8FUw@mail.gmail.com>
Message-ID: <CA+8X3fXCOPecub-SzuXcp2r4sxQz9TVp2Tr6V_RM2FaX3=5BmA@mail.gmail.com>

Hi Roberto,
Here is a snippet of code that translates the text responses of the
BIS-11 into numeric values. Note the reversal of the order in the
second item:

BIS$Q1<-as.numeric(factor(BIS$Q1,
 levels=c("Almost","Often","Occasionally","Rarely/Never")))
BIS$Q2<-as.numeric(factor(BIS$Q2,
 levels=c("Rarely/Never","Occasionally","Often","Almost")))
...

Jim
On Thu, Nov 1, 2018 at 8:57 AM P. Roberto Bakker
<robertobakker at gmail.com> wrote:
>
> Hi Rich,
>
> Thank you for your answer.
> The sentences are strings (likert scale: 'the situation is highly
> applicable to me' etc - in Dutch), or column labels; it may be confusing as
> it is in Dutch. Below I show you part of the dataframe with my annotation
> added (string/column lable) to give you an idea.
> I need to change the likert strings into numeric (1:5). And this is a
> challenge somehow.
> With dplyr, plyr it did not work.
> After I have the numeric version then I can stack them as suggested by
> David.
>



From myr|@m@croze07 @end|ng |rom gm@||@com  Thu Nov  1 03:20:54 2018
From: myr|@m@croze07 @end|ng |rom gm@||@com (Myriam Croze)
Date: Thu, 1 Nov 2018 11:20:54 +0900
Subject: [R] Plot a matrix
Message-ID: <CAMKaf34G0TBbGMDbp8Wzm=jAen_FXQw3NAKOWRDaG-pt_qjaQw@mail.gmail.com>

Hello!

I need your help to plot my data. I have a file .csv which looks like that:

41540 41540 41442 41599 41709 41823 41806 41837 41898 41848
41442 0.001
41599 0.002 0.001
41709 0.004 0.003 0.003
41823 0.002 0.001 0.002 0.001
41806 0.004 0.004 0.005 0.006 0.005
41837 0.004 0.004 0.005 0.006 0.005 0.001
41898 0.004 0.004 0.005 0.006 0.005 0.001 0.001
41848 0.005 0.004 0.005 0.007 0.005 0.001 0.001 0.001

It is a matrix of distance with in the 1st column and row the days of
sampling and then the distance values.
I would like to do a scatterplot of the data with for the y axis the
distance values and for the x axis the difference between the days of
sampling (e.g. x = |41442-41540| and y = 0.001).
Do you know how I could do that with r?
Thanks in advance for your help.

Best regards,
Myriam

-- 
Myriam Croze
Post-doctorante
Division of EcoScience,
Ewha Womans University
Seoul, South Korea

Email: myriam.croze07 at gmail.com

	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Thu Nov  1 07:55:44 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 1 Nov 2018 17:55:44 +1100
Subject: [R] Plot a matrix
In-Reply-To: <CAMKaf34G0TBbGMDbp8Wzm=jAen_FXQw3NAKOWRDaG-pt_qjaQw@mail.gmail.com>
References: <CAMKaf34G0TBbGMDbp8Wzm=jAen_FXQw3NAKOWRDaG-pt_qjaQw@mail.gmail.com>
Message-ID: <CA+8X3fV3w-R4GWTvZ+gqd_sx1aGwHXFy5S4TWaPeRmnoE5suaw@mail.gmail.com>

Hi Myriam,
This may not be the ideal way to do this, but I think it works:

mcdf<-read.table(text="41540 41540 41442 41599 41709 41823 41806 41837
41898 41848
41442 0.001
41599 0.002 0.001
41709 0.004 0.003 0.003
41823 0.002 0.001 0.002 0.001
41806 0.004 0.004 0.005 0.006 0.005
41837 0.004 0.004 0.005 0.006 0.005 0.001
41898 0.004 0.004 0.005 0.006 0.005 0.001 0.001
41848 0.005 0.004 0.005 0.007 0.005 0.001 0.001 0.001",
fill=TRUE)
nrows<-nrow(mcdf)
ncols<-ncol(mcdf)
mcdf2<-mcdf
for(row in 2:nrows) {
 for(col in 2:ncols) {
  if(!is.na(mcdf2[row,col])) mcdf2[row,col]<-mcdf[row,1]-mcdf[1,col]
 }
}
plot(0,xlim=range(as.numeric(unlist(mcdf2[2:nrows,2:ncols])),na.rm=TRUE),
 ylim=range(as.numeric(unlist(mcdf[2:nrows,2:ncols])),na.rm=TRUE),
 xlab="Difference in days",ylab="Distance",type="n")
for(row in 2:nrows) {
 for(col in 2:ncols) {
  if(!is.na(mcdf2[row,col])) points(mcdf2[row,col],mcdf[row,col])
 }
}

Jim
On Thu, Nov 1, 2018 at 5:21 PM Myriam Croze <myriam.croze07 at gmail.com> wrote:
>
> Hello!
>
> I need your help to plot my data. I have a file .csv which looks like that:
>
> 41540 41540 41442 41599 41709 41823 41806 41837 41898 41848
> 41442 0.001
> 41599 0.002 0.001
> 41709 0.004 0.003 0.003
> 41823 0.002 0.001 0.002 0.001
> 41806 0.004 0.004 0.005 0.006 0.005
> 41837 0.004 0.004 0.005 0.006 0.005 0.001
> 41898 0.004 0.004 0.005 0.006 0.005 0.001 0.001
> 41848 0.005 0.004 0.005 0.007 0.005 0.001 0.001 0.001
>
> It is a matrix of distance with in the 1st column and row the days of
> sampling and then the distance values.
> I would like to do a scatterplot of the data with for the y axis the
> distance values and for the x axis the difference between the days of
> sampling (e.g. x = |41442-41540| and y = 0.001).
> Do you know how I could do that with r?
> Thanks in advance for your help.
>
> Best regards,
> Myriam
>
> --
> Myriam Croze
> Post-doctorante
> Division of EcoScience,
> Ewha Womans University
> Seoul, South Korea
>
> Email: myriam.croze07 at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Nov  1 08:05:54 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 1 Nov 2018 07:05:54 +0000
Subject: [R] OT: R version 1.0.1 is still a success.
Message-ID: <188bfabe-6c72-ff35-ceca-b82a621315f7@sapo.pt>

Hello,

This has nothing to do with R-help and I apologize in advance but this 
is really, really strange.

A SO user is still using R 1.0.1:

https://stackoverflow.com/questions/53096176/how-do-i-change-the-str-of-my-diff-time-from-atomic-to-num#comment93089103_53096176

Imagine if R wasn't for free...

Rui Barradas



From er|cjberger @end|ng |rom gm@||@com  Thu Nov  1 08:27:04 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 1 Nov 2018 09:27:04 +0200
Subject: [R] OT: R version 1.0.1 is still a success.
In-Reply-To: <188bfabe-6c72-ff35-ceca-b82a621315f7@sapo.pt>
References: <188bfabe-6c72-ff35-ceca-b82a621315f7@sapo.pt>
Message-ID: <CAGgJW74tSmcq55gx4B7sTgMvOHf-72idk1=tRXmxqkPC6H7ovA@mail.gmail.com>

:-)

On Thu, Nov 1, 2018 at 9:06 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> This has nothing to do with R-help and I apologize in advance but this
> is really, really strange.
>
> A SO user is still using R 1.0.1:
>
>
> https://stackoverflow.com/questions/53096176/how-do-i-change-the-str-of-my-diff-time-from-atomic-to-num#comment93089103_53096176
>
> Imagine if R wasn't for free...
>
> Rui Barradas
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From p_conno||y @end|ng |rom @||ng@hot@co@nz  Thu Nov  1 08:51:05 2018
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Thu, 1 Nov 2018 20:51:05 +1300
Subject: [R] Corrupted package?
In-Reply-To: <41FEDABD-D3DF-4BEF-8BB1-152F6342617A@gmail.com>
References: <20181031072248.GA8540@slingshot.co.nz>
 <41FEDABD-D3DF-4BEF-8BB1-152F6342617A@gmail.com>
Message-ID: <20181101075105.GB8540@slingshot.co.nz>

On Wed, 31-Oct-2018 at 07:30PM +0100, peter dalgaard wrote:

|> Hm, a source install to r-devel gave me 
|> 
|> Peter-Dalgaards-MacBook-Air:BUILD pd$ ls -l library/pkgconfig/R/pkgconfig.rdb
|> -rw-r--r--  1 pd  staff  4515 Oct 31 19:15 library/pkgconfig/R/pkgconfig.rdb
|> Peter-Dalgaards-MacBook-Air:BUILD pd$ ls -l library/pkgconfig/help/pkgconfig.rdb
|> -rw-r--r--  1 pd  staff  5748 Oct 31 19:15 library/pkgconfig/help/pkgconfig.rdb
|> 
|> and an install to R_3.4.1 (yes, 4...) said
|> 
|> $ ls -l /Library/Frameworks/R.framework/Versions/3.4/Resources/library/pkgconfig/*/pkgconfig.rdb
|> -rw-r--r--  1 pd  admin  2432 Aug 17 11:36 /Library/Frameworks/R.framework/Versions/3.4/Resources/library/pkgconfig/R/pkgconfig.rdb
|> -rw-r--r--  1 pd  admin  5412 Aug 17 11:36 /Library/Frameworks/R.framework/Versions/3.4/Resources/library/pkgconfig/help/pkgconfig.rdb
|> 
|> I.e., it looks like it is the larger of your file sizes that is anomalous(?).
|> 

That's very strange.  If I look further back, the large size is
historical in my experience.

ll `locate pkgconfig.rdb`

-rw-r--r-- 1 hrapgc hrapgc  5356 Aug  8  2017 /home/hrapgc/local/R-3.4.4/library/pkgconfig/help/pkgconfig.rdb
-rw-r--r-- 1 hrapgc hrapgc 13377 Aug  8  2017 /home/hrapgc/local/R-3.4.4/library/pkgconfig/R/pkgconfig.rdb
-rw-r--r-- 1 hrapgc hrapgc  5335 May  8 14:06 /home/hrapgc/local/R-3.5.0/library/pkgconfig/help/pkgconfig.rdb
-rw-r--r-- 1 hrapgc hrapgc 15669 May  8 14:06 /home/hrapgc/local/R-3.5.0/library/pkgconfig/R/pkgconfig.rdb
-rw-r--r-- 1 hrapgc hrapgc  5359 Oct 31 16:12 /home/hrapgc/local/R-3.5.1/library/pkgconfig/help/pkgconfig.rdb
-rw-r--r-- 1 hrapgc hrapgc  4367 Oct 31 16:12 /home/hrapgc/local/R-3.5.1/library/pkgconfig/R/pkgconfig.rdb

Yet when I look at my home machine that I use sometimes:

> ll `locate pkgconfig.rdb`
-rw-r--r-- 1 pat pat  5349 Sep 13  2017 /home/pat/local/R-3.2.3/library/pkgconfig/help/pkgconfig.rdb
-rw-r--r-- 1 pat pat 13374 Sep 13  2017 /home/pat/local/R-3.2.3/library/pkgconfig/R/pkgconfig.rdb
-rw-r--r-- 1 pat pat  5355 Feb  2  2018 /home/pat/local/R-3.4.3/library/pkgconfig/help/pkgconfig.rdb
-rw-r--r-- 1 pat pat 13392 Feb  2  2018 /home/pat/local/R-3.4.3/library/pkgconfig/R/pkgconfig.rdb
-rw-r--r-- 1 pat pat  5356 Apr 13  2018 /home/pat/local/R-3.4.4/library/pkgconfig/help/pkgconfig.rdb
-rw-r--r-- 1 pat pat 13392 Apr 13  2018 /home/pat/local/R-3.4.4/library/pkgconfig/R/pkgconfig.rdb
-rw-r--r-- 1 pat pat  5351 Jul  3 20:38 /home/pat/local/R-3.5.0/library/pkgconfig/help/pkgconfig.rdb
-rw-r--r-- 1 pat pat  4349 Jul  3 20:38 /home/pat/local/R-3.5.0/library/pkgconfig/R/pkgconfig.rdb

Similar sizes, but not corresponding to the same R versions!!

|> Did you try a straight install with install.packages("pkgconfig")? 

Another interesting story:

> install.packages("pkgconfig")
trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/pkgconfig_2.0.2.tar.gz'
Content type 'application/x-gzip' length 6024 bytes
==================================================
downloaded 6024 bytes

This session PID is 24632:
begun at 2018-11-01 11:11:41:
* installing *source* package ?pkgconfig? ...
** package ?pkgconfig? successfully unpacked and MD5 sums checked
** R
** inst
** byte-compile and prepare package for lazy loading
Error in unloadNamespace(pkg_name) : 
  namespace ?pkgconfig? is imported by ?dplyr? so cannot be unloaded
* removing ?/home/hrapgc/local/R-3.5.1/library/pkgconfig?
* restoring previous ?/home/hrapgc/local/R-3.5.1/library/pkgconfig?

The downloaded source packages are in
	?/tmp/RtmpQ3KfLM/downloaded_packages?
Updating HTML index of packages in '.Library'
Making 'packages.html' ... done
Warning message:
In install.packages("pkgconfig") :
  installation of package ?pkgconfig? had non-zero exit status

----

 So I used this approach:

echo 'options(repos=list(CRAN="https://cloud.r-project.org"));install.packages("pkgconfig", depend = TRUE)' | R --vanilla

That was "successful", even if corrupted.

|> 
|> And, BTW, which system are you using?
|> 

> sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

Matrix products: default
BLAS: /home/hrapgc/local/R-3.5.1/lib/libRblas.so
LAPACK: /home/hrapgc/local/R-3.5.1/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
 [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
 [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] grDevices utils     stats     graphics  methods   base     

other attached packages: ## <probably unnecessary detail>
 [1] bindrcpp_0.2.2     ggthemes_4.0.1     cowplot_0.9.3      ggrepel_0.8.0     
 [5] quanteda_1.3.4     topicmodels_0.2-7  rvest_0.3.2        xml2_1.2.0        
 [9] wordcloud_2.6      RColorBrewer_1.1-2 wordcloud2_0.2.1   tm_0.7-5          
[13] NLP_0.2-0          tidytext_0.2.0     forcats_0.3.0      stringr_1.3.1     
[17] purrr_0.2.5        readr_1.1.1        tidyr_0.8.2        tibble_1.4.2      
[21] ggplot2_3.1.0      tidyverse_1.2.1    knitr_1.20         slam_0.1-43       
[25] RcppParallel_4.4.1 tokenizers_0.2.1   dplyr_0.7.7        lattice_0.20-35   

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.19      here_0.1          lubridate_1.7.4   rprojroot_1.3-2  
 [5] assertthat_0.2.0  digest_0.6.18     R6_2.3.0          cellranger_1.1.0 
 [9] plyr_1.8.4        backports_1.1.2   stats4_3.5.1      httr_1.3.1       
[13] pillar_1.3.0      rlang_0.3.0.1     curl_3.2          lazyeval_0.2.1   
[17] readxl_1.1.0      rstudioapi_0.8    data.table_1.11.8 Matrix_1.2-14    
[21] selectr_0.4-1     htmlwidgets_1.3   munsell_0.5.0     broom_0.5.0      
[25] compiler_3.5.1    janeaustenr_0.1.5 spacyr_0.9.91     modelr_0.1.2     
[29] pkgconfig_2.0.2   htmltools_0.3.6   tidyselect_0.2.5  crayon_1.3.4     
[33] withr_2.1.2       SnowballC_0.5.1   grid_3.5.1        nlme_3.1-137     
[37] jsonlite_1.5      gtable_0.2.0      magrittr_1.5      scales_1.0.0     
[41] cli_1.0.1         stringi_1.2.4     stopwords_0.9.0   fastmatch_1.1-0  
[45] tools_3.5.1       glue_1.3.0        hms_0.4.2         parallel_3.5.1   
[49] colorspace_1.3-2  bindr_0.1.1       haven_1.1.2       modeltools_0.2-22
> 
 </probably unnecessary detail>

|> -pd
|> 
[..]

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.



From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Nov  1 09:05:06 2018
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 1 Nov 2018 09:05:06 +0100
Subject: [R] OT: R version 1.0.1 is still a success.
In-Reply-To: <188bfabe-6c72-ff35-ceca-b82a621315f7@sapo.pt>
References: <188bfabe-6c72-ff35-ceca-b82a621315f7@sapo.pt>
Message-ID: <23514.46002.872670.865724@stat.math.ethz.ch>

>>>>> Rui Barradas 
>>>>>     on Thu, 1 Nov 2018 07:05:54 +0000 writes:

    > Hello, This has nothing to do with R-help and I apologize
    > in advance but this is really, really strange.

    > A SO user is still using R 1.0.1:

    > https://stackoverflow.com/questions/53096176/how-do-i-change-the-str-of-my-diff-time-from-atomic-to-num#comment93089103_53096176

    > Imagine if R wasn't for free...

I actually do still have a running version of R 1.0.1 on my
computers,
but Rui you are almost surely wrong the OP said  1.0.153  and
hence falls in the ever increasing group of people who believe
that Rstudio owns and produces R ...

I'm happy about the existence of Rstudio and all the good it
brought to the R community -- notably Rmarkdown and tons of
related tools.
But as one of the "parents" of R, I'm really really saddened to
notice that even relatively smart people (such as our students)
think and talk about using Rstudio when they use R via
Rstudio...

Martin



From robertob@kker @end|ng |rom gm@||@com  Thu Nov  1 10:38:06 2018
From: robertob@kker @end|ng |rom gm@||@com (P. Roberto Bakker)
Date: Thu, 1 Nov 2018 10:38:06 +0100
Subject: [R] Different stack barplots - same color legends
In-Reply-To: <CA+8X3fXCOPecub-SzuXcp2r4sxQz9TVp2Tr6V_RM2FaX3=5BmA@mail.gmail.com>
References: <CAKDq9_N16xaeL4O2j=v2bVuMb=tuHfu0Ao+yuLQcEq6B-ngq1A@mail.gmail.com>
 <af9001d319ac4992b0bfc5526150f03b@tamu.edu>
 <CAKDq9_P8hQEHWFH=c_86bG81fU0GS+EUCOmtZ9gJa_7kY-2uhA@mail.gmail.com>
 <CAGx1TMAYybconxY7ZVVJcdiYW6+WOjr_D+=GHOA=Xxv2AWRCqQ@mail.gmail.com>
 <CAKDq9_Oi0HGNV7qLnmi4HgVr7orF_gpC7Sys8mLKAxMfjHVtvQ@mail.gmail.com>
 <CAGx1TMB+=RnNeoBmzF=_-gxZ2bzaabExs2Gf-8dKE2vAcpiHpA@mail.gmail.com>
 <CAKDq9_P3GfHXbFbChQwrDUm=E+RuuWGP89tf_KPFXRjYAsrA+A@mail.gmail.com>
 <CAGx1TMByCiZvwOPm06qo4bssWjh=UP9ZPvkX5zi+6dNE=wggaA@mail.gmail.com>
 <CAKDq9_OkLfiP98cuYUg0BU_+cCXmKi9gKHqxSm+Eu16eC3WWyg@mail.gmail.com>
 <CAGx1TMCF8bg64+UOP9ULygHcRnna505RO+1WCWxWJuuFaNp4fQ@mail.gmail.com>
 <CAKDq9_OU8bNq4p8zLr45JADz=SWvGAhG+-ACqdu+qC4a+D8FUw@mail.gmail.com>
 <CA+8X3fXCOPecub-SzuXcp2r4sxQz9TVp2Tr6V_RM2FaX3=5BmA@mail.gmail.com>
Message-ID: <CAKDq9_O2nRxSW6+dHyhk5P_qpEzkDJafQZZU2aLQF=eAuKRmYg@mail.gmail.com>

Hi Jim,

Thank you.
An additional question: as I have many columns to change in numeric, and
the columns are long sentences, what is an efficient way to do this?
I checked in StackOverflow but could not find the right answer
Best Roberto


Op do 1 nov. 2018 om 00:25 schreef Jim Lemon <drjimlemon at gmail.com>:

> Hi Roberto,
> Here is a snippet of code that translates the text responses of the
> BIS-11 into numeric values. Note the reversal of the order in the
> second item:
>
> BIS$Q1<-as.numeric(factor(BIS$Q1,
>  levels=c("Almost","Often","Occasionally","Rarely/Never")))
> BIS$Q2<-as.numeric(factor(BIS$Q2,
>  levels=c("Rarely/Never","Occasionally","Often","Almost")))
> ...
>
> Jim
> On Thu, Nov 1, 2018 at 8:57 AM P. Roberto Bakker
> <robertobakker at gmail.com> wrote:
> >
> > Hi Rich,
> >
> > Thank you for your answer.
> > The sentences are strings (likert scale: 'the situation is highly
> > applicable to me' etc - in Dutch), or column labels; it may be confusing
> as
> > it is in Dutch. Below I show you part of the dataframe with my annotation
> > added (string/column lable) to give you an idea.
> > I need to change the likert strings into numeric (1:5). And this is a
> > challenge somehow.
> > With dplyr, plyr it did not work.
> > After I have the numeric version then I can stack them as suggested by
> > David.
> >
>

	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Thu Nov  1 10:50:40 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 1 Nov 2018 20:50:40 +1100
Subject: [R] Different stack barplots - same color legends
In-Reply-To: <CAKDq9_O2nRxSW6+dHyhk5P_qpEzkDJafQZZU2aLQF=eAuKRmYg@mail.gmail.com>
References: <CAKDq9_N16xaeL4O2j=v2bVuMb=tuHfu0Ao+yuLQcEq6B-ngq1A@mail.gmail.com>
 <af9001d319ac4992b0bfc5526150f03b@tamu.edu>
 <CAKDq9_P8hQEHWFH=c_86bG81fU0GS+EUCOmtZ9gJa_7kY-2uhA@mail.gmail.com>
 <CAGx1TMAYybconxY7ZVVJcdiYW6+WOjr_D+=GHOA=Xxv2AWRCqQ@mail.gmail.com>
 <CAKDq9_Oi0HGNV7qLnmi4HgVr7orF_gpC7Sys8mLKAxMfjHVtvQ@mail.gmail.com>
 <CAGx1TMB+=RnNeoBmzF=_-gxZ2bzaabExs2Gf-8dKE2vAcpiHpA@mail.gmail.com>
 <CAKDq9_P3GfHXbFbChQwrDUm=E+RuuWGP89tf_KPFXRjYAsrA+A@mail.gmail.com>
 <CAGx1TMByCiZvwOPm06qo4bssWjh=UP9ZPvkX5zi+6dNE=wggaA@mail.gmail.com>
 <CAKDq9_OkLfiP98cuYUg0BU_+cCXmKi9gKHqxSm+Eu16eC3WWyg@mail.gmail.com>
 <CAGx1TMCF8bg64+UOP9ULygHcRnna505RO+1WCWxWJuuFaNp4fQ@mail.gmail.com>
 <CAKDq9_OU8bNq4p8zLr45JADz=SWvGAhG+-ACqdu+qC4a+D8FUw@mail.gmail.com>
 <CA+8X3fXCOPecub-SzuXcp2r4sxQz9TVp2Tr6V_RM2FaX3=5BmA@mail.gmail.com>
 <CAKDq9_O2nRxSW6+dHyhk5P_qpEzkDJafQZZU2aLQF=eAuKRmYg@mail.gmail.com>
Message-ID: <CA+8X3fUUFwx2YDUMxLvpOCpmS6wnWtUg+W=eo+EYt74u1cx8+Q@mail.gmail.com>

Hi Roberto,
What I suggested is a brute force method of translating response
options into ordinal numbers. Fortunately for me, the Barratt
Impulsivity Scale has relatively short and constant response options.
As I programmed the test myself, I already had the questions in plain
text, so I simply added the "as.numeric(factor(" and "levels=..."
commands to the forward and reversed response options to create the
whole transformation code. With a bit of cut-and-paste work, it didn't
take that long. Because the BIS-11 is used quite a bit where I am
working. it was worth the trouble.

Jim

On Thu, Nov 1, 2018 at 8:38 PM P. Roberto Bakker
<robertobakker at gmail.com> wrote:
>
> Hi Jim,
>
> Thank you.
> An additional question: as I have many columns to change in numeric, and the columns are long sentences, what is an efficient way to do this?
> I checked in StackOverflow but could not find the right answer
> Best Roberto
>
>
> Op do 1 nov. 2018 om 00:25 schreef Jim Lemon <drjimlemon at gmail.com>:
>>
>> Hi Roberto,
>> Here is a snippet of code that translates the text responses of the
>> BIS-11 into numeric values. Note the reversal of the order in the
>> second item:
>>
>> BIS$Q1<-as.numeric(factor(BIS$Q1,
>>  levels=c("Almost","Often","Occasionally","Rarely/Never")))
>> BIS$Q2<-as.numeric(factor(BIS$Q2,
>>  levels=c("Rarely/Never","Occasionally","Often","Almost")))
>> ...
>>
>> Jim
>> On Thu, Nov 1, 2018 at 8:57 AM P. Roberto Bakker
>> <robertobakker at gmail.com> wrote:
>> >
>> > Hi Rich,
>> >
>> > Thank you for your answer.
>> > The sentences are strings (likert scale: 'the situation is highly
>> > applicable to me' etc - in Dutch), or column labels; it may be confusing as
>> > it is in Dutch. Below I show you part of the dataframe with my annotation
>> > added (string/column lable) to give you an idea.
>> > I need to change the likert strings into numeric (1:5). And this is a
>> > challenge somehow.
>> > With dplyr, plyr it did not work.
>> > After I have the numeric version then I can stack them as suggested by
>> > David.
>> >



From robertob@kker @end|ng |rom gm@||@com  Thu Nov  1 11:00:51 2018
From: robertob@kker @end|ng |rom gm@||@com (P. Roberto Bakker)
Date: Thu, 1 Nov 2018 11:00:51 +0100
Subject: [R] Different stack barplots - same color legends
In-Reply-To: <CA+8X3fUUFwx2YDUMxLvpOCpmS6wnWtUg+W=eo+EYt74u1cx8+Q@mail.gmail.com>
References: <CAKDq9_N16xaeL4O2j=v2bVuMb=tuHfu0Ao+yuLQcEq6B-ngq1A@mail.gmail.com>
 <af9001d319ac4992b0bfc5526150f03b@tamu.edu>
 <CAKDq9_P8hQEHWFH=c_86bG81fU0GS+EUCOmtZ9gJa_7kY-2uhA@mail.gmail.com>
 <CAGx1TMAYybconxY7ZVVJcdiYW6+WOjr_D+=GHOA=Xxv2AWRCqQ@mail.gmail.com>
 <CAKDq9_Oi0HGNV7qLnmi4HgVr7orF_gpC7Sys8mLKAxMfjHVtvQ@mail.gmail.com>
 <CAGx1TMB+=RnNeoBmzF=_-gxZ2bzaabExs2Gf-8dKE2vAcpiHpA@mail.gmail.com>
 <CAKDq9_P3GfHXbFbChQwrDUm=E+RuuWGP89tf_KPFXRjYAsrA+A@mail.gmail.com>
 <CAGx1TMByCiZvwOPm06qo4bssWjh=UP9ZPvkX5zi+6dNE=wggaA@mail.gmail.com>
 <CAKDq9_OkLfiP98cuYUg0BU_+cCXmKi9gKHqxSm+Eu16eC3WWyg@mail.gmail.com>
 <CAGx1TMCF8bg64+UOP9ULygHcRnna505RO+1WCWxWJuuFaNp4fQ@mail.gmail.com>
 <CAKDq9_OU8bNq4p8zLr45JADz=SWvGAhG+-ACqdu+qC4a+D8FUw@mail.gmail.com>
 <CA+8X3fXCOPecub-SzuXcp2r4sxQz9TVp2Tr6V_RM2FaX3=5BmA@mail.gmail.com>
 <CAKDq9_O2nRxSW6+dHyhk5P_qpEzkDJafQZZU2aLQF=eAuKRmYg@mail.gmail.com>
 <CA+8X3fUUFwx2YDUMxLvpOCpmS6wnWtUg+W=eo+EYt74u1cx8+Q@mail.gmail.com>
Message-ID: <CAKDq9_MEoEguz-k78bPhT+dKTP5GzPDWprTQ22B3Fe58Q8Dekw@mail.gmail.com>

Hi Jim,

Thank you for your quick reply. It is a great procedure.
The response options in my data.frame are (fortunately) similar in all
columns.
It would be nice if I could use your procedure in all columns at once
instead of each column.
My data.frame contains 48 columns, each with long column names.
This means that I need to put each (long) column name after "$:
dataname$"very long name".
So, is ther a way to do this procedure for all columns?

Roberto


Op do 1 nov. 2018 om 10:50 schreef Jim Lemon <drjimlemon at gmail.com>:

> Hi Roberto,
> What I suggested is a brute force method of translating response
> options into ordinal numbers. Fortunately for me, the Barratt
> Impulsivity Scale has relatively short and constant response options.
> As I programmed the test myself, I already had the questions in plain
> text, so I simply added the "as.numeric(factor(" and "levels=..."
> commands to the forward and reversed response options to create the
> whole transformation code. With a bit of cut-and-paste work, it didn't
> take that long. Because the BIS-11 is used quite a bit where I am
> working. it was worth the trouble.
>
> Jim
>
> On Thu, Nov 1, 2018 at 8:38 PM P. Roberto Bakker
> <robertobakker at gmail.com> wrote:
> >
> > Hi Jim,
> >
> > Thank you.
> > An additional question: as I have many columns to change in numeric, and
> the columns are long sentences, what is an efficient way to do this?
> > I checked in StackOverflow but could not find the right answer
> > Best Roberto
> >
> >
> > Op do 1 nov. 2018 om 00:25 schreef Jim Lemon <drjimlemon at gmail.com>:
> >>
> >> Hi Roberto,
> >> Here is a snippet of code that translates the text responses of the
> >> BIS-11 into numeric values. Note the reversal of the order in the
> >> second item:
> >>
> >> BIS$Q1<-as.numeric(factor(BIS$Q1,
> >>  levels=c("Almost","Often","Occasionally","Rarely/Never")))
> >> BIS$Q2<-as.numeric(factor(BIS$Q2,
> >>  levels=c("Rarely/Never","Occasionally","Often","Almost")))
> >> ...
> >>
> >> Jim
> >> On Thu, Nov 1, 2018 at 8:57 AM P. Roberto Bakker
> >> <robertobakker at gmail.com> wrote:
> >> >
> >> > Hi Rich,
> >> >
> >> > Thank you for your answer.
> >> > The sentences are strings (likert scale: 'the situation is highly
> >> > applicable to me' etc - in Dutch), or column labels; it may be
> confusing as
> >> > it is in Dutch. Below I show you part of the dataframe with my
> annotation
> >> > added (string/column lable) to give you an idea.
> >> > I need to change the likert strings into numeric (1:5). And this is a
> >> > challenge somehow.
> >> > With dplyr, plyr it did not work.
> >> > After I have the numeric version then I can stack them as suggested by
> >> > David.
> >> >
>

	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Thu Nov  1 11:03:18 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 1 Nov 2018 21:03:18 +1100
Subject: [R] Different stack barplots - same color legends
In-Reply-To: <CAKDq9_MEoEguz-k78bPhT+dKTP5GzPDWprTQ22B3Fe58Q8Dekw@mail.gmail.com>
References: <CAKDq9_N16xaeL4O2j=v2bVuMb=tuHfu0Ao+yuLQcEq6B-ngq1A@mail.gmail.com>
 <af9001d319ac4992b0bfc5526150f03b@tamu.edu>
 <CAKDq9_P8hQEHWFH=c_86bG81fU0GS+EUCOmtZ9gJa_7kY-2uhA@mail.gmail.com>
 <CAGx1TMAYybconxY7ZVVJcdiYW6+WOjr_D+=GHOA=Xxv2AWRCqQ@mail.gmail.com>
 <CAKDq9_Oi0HGNV7qLnmi4HgVr7orF_gpC7Sys8mLKAxMfjHVtvQ@mail.gmail.com>
 <CAGx1TMB+=RnNeoBmzF=_-gxZ2bzaabExs2Gf-8dKE2vAcpiHpA@mail.gmail.com>
 <CAKDq9_P3GfHXbFbChQwrDUm=E+RuuWGP89tf_KPFXRjYAsrA+A@mail.gmail.com>
 <CAGx1TMByCiZvwOPm06qo4bssWjh=UP9ZPvkX5zi+6dNE=wggaA@mail.gmail.com>
 <CAKDq9_OkLfiP98cuYUg0BU_+cCXmKi9gKHqxSm+Eu16eC3WWyg@mail.gmail.com>
 <CAGx1TMCF8bg64+UOP9ULygHcRnna505RO+1WCWxWJuuFaNp4fQ@mail.gmail.com>
 <CAKDq9_OU8bNq4p8zLr45JADz=SWvGAhG+-ACqdu+qC4a+D8FUw@mail.gmail.com>
 <CA+8X3fXCOPecub-SzuXcp2r4sxQz9TVp2Tr6V_RM2FaX3=5BmA@mail.gmail.com>
 <CAKDq9_O2nRxSW6+dHyhk5P_qpEzkDJafQZZU2aLQF=eAuKRmYg@mail.gmail.com>
 <CA+8X3fUUFwx2YDUMxLvpOCpmS6wnWtUg+W=eo+EYt74u1cx8+Q@mail.gmail.com>
 <CAKDq9_MEoEguz-k78bPhT+dKTP5GzPDWprTQ22B3Fe58Q8Dekw@mail.gmail.com>
Message-ID: <CA+8X3fX2mVhMbKNYABM38E5qaTVUV1ASrsM25mATzFu4PVeEcA@mail.gmail.com>

I would use the "names" or "colnames" functions to change them to Q1,
Q2, ... as I did.

Jim

On Thu, Nov 1, 2018 at 9:01 PM P. Roberto Bakker
<robertobakker at gmail.com> wrote:
>
> Hi Jim,
>
> Thank you for your quick reply. It is a great procedure.
> The response options in my data.frame are (fortunately) similar in all columns.
> It would be nice if I could use your procedure in all columns at once instead of each column.
> My data.frame contains 48 columns, each with long column names.
> This means that I need to put each (long) column name after "$:  dataname$"very long name".
> So, is ther a way to do this procedure for all columns?
>
> Roberto
>
>
> Op do 1 nov. 2018 om 10:50 schreef Jim Lemon <drjimlemon at gmail.com>:
>>
>> Hi Roberto,
>> What I suggested is a brute force method of translating response
>> options into ordinal numbers. Fortunately for me, the Barratt
>> Impulsivity Scale has relatively short and constant response options.
>> As I programmed the test myself, I already had the questions in plain
>> text, so I simply added the "as.numeric(factor(" and "levels=..."
>> commands to the forward and reversed response options to create the
>> whole transformation code. With a bit of cut-and-paste work, it didn't
>> take that long. Because the BIS-11 is used quite a bit where I am
>> working. it was worth the trouble.
>>
>> Jim
>>
>> On Thu, Nov 1, 2018 at 8:38 PM P. Roberto Bakker
>> <robertobakker at gmail.com> wrote:
>> >
>> > Hi Jim,
>> >
>> > Thank you.
>> > An additional question: as I have many columns to change in numeric, and the columns are long sentences, what is an efficient way to do this?
>> > I checked in StackOverflow but could not find the right answer
>> > Best Roberto
>> >
>> >
>> > Op do 1 nov. 2018 om 00:25 schreef Jim Lemon <drjimlemon at gmail.com>:
>> >>
>> >> Hi Roberto,
>> >> Here is a snippet of code that translates the text responses of the
>> >> BIS-11 into numeric values. Note the reversal of the order in the
>> >> second item:
>> >>
>> >> BIS$Q1<-as.numeric(factor(BIS$Q1,
>> >>  levels=c("Almost","Often","Occasionally","Rarely/Never")))
>> >> BIS$Q2<-as.numeric(factor(BIS$Q2,
>> >>  levels=c("Rarely/Never","Occasionally","Often","Almost")))
>> >> ...
>> >>
>> >> Jim
>> >> On Thu, Nov 1, 2018 at 8:57 AM P. Roberto Bakker
>> >> <robertobakker at gmail.com> wrote:
>> >> >
>> >> > Hi Rich,
>> >> >
>> >> > Thank you for your answer.
>> >> > The sentences are strings (likert scale: 'the situation is highly
>> >> > applicable to me' etc - in Dutch), or column labels; it may be confusing as
>> >> > it is in Dutch. Below I show you part of the dataframe with my annotation
>> >> > added (string/column lable) to give you an idea.
>> >> > I need to change the likert strings into numeric (1:5). And this is a
>> >> > challenge somehow.
>> >> > With dplyr, plyr it did not work.
>> >> > After I have the numeric version then I can stack them as suggested by
>> >> > David.
>> >> >



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Nov  1 11:27:16 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 1 Nov 2018 10:27:16 +0000
Subject: [R] Plot a path
In-Reply-To: <trinity-c72faedf-333b-472d-83c1-16c528a67f1b-1541021239921@3c-app-gmx-bs72>
References: <trinity-c72faedf-333b-472d-83c1-16c528a67f1b-1541021239921@3c-app-gmx-bs72>
Message-ID: <be072d96-a173-40e5-a744-594cbd2ec51e@sapo.pt>

Hello,

The following uses ggplot2.

First, make up a dataset, since you have not posted one.



lat0 <- 38.736946
lon0 <- -9.142685
n <- 10

set.seed(1)
Date <- seq(Sys.Date() - n + 1, Sys.Date(), by = "days")
Lat <- lat0 + cumsum(c(0, runif(n - 1)))
Lon <- lon0 + cumsum(c(0, runif(n - 1)))
Placename <- rep(c("A", "B"), n/2)

path <- data.frame(Date, Placename, Lat, Lon)
path <- path[order(path$Date), ]


Now, two graphs, one with just one line of all the lon/lat and the other 
with a line for each Placename.

library(ggplot2)

ggplot(path, aes(x = Lon, y = Lat)) +
   geom_point() +
   geom_line()


ggplot(path, aes(x = Lon, y = Lat, colour = Placename)) +
   geom_point(aes(fill = Placename)) +
   geom_line()


Hope this helps,

Rui Barradas

?s 21:27 de 31/10/2018, Ferri Leberl escreveu:
> 
> Dear All,
> I have a dataframe with four cols: Date, Placename, geogr. latitude, geogr. longitude.
> How can I plot the path as a line, ordered by the date, with the longitude as the x-axis and the latitude as the y-axis?
> Thank you in advance!
> Yours, Ferri
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From @r|n|v@@@kott@116 @end|ng |rom gm@||@com  Thu Nov  1 10:58:50 2018
From: @r|n|v@@@kott@116 @end|ng |rom gm@||@com (srinivas kotta)
Date: Thu, 1 Nov 2018 15:28:50 +0530
Subject: [R] Plotting error:
Message-ID: <CADDb+48emBkF1UrOmkacgjS=QrZUEsk_WfErDd_OT1DMXYKD_Q@mail.gmail.com>

Dear Members,

Can anybody help me to solve the errors in R-script. I am plotting wavelet
image using  waveletcomp  library . I am trying define maximum and minimum
(range) of the color scale.


*command is*:
wt.image(my.w, color.key = "interval", n.levels = 250,
         legend.params = list(lab = "wavelet power levels", label.digits =
2), periodlab = "periods (days)", maximum.level = 1.5, exponent = 0.5,
show.date = TRUE, date.format = "%F", timelab = "")


*error is:*
Error in wt.image(my.w, color.key = "interval", n.levels = 250,
legend.params = list(lab = "wavelet power levels",  :
  unused arguments (maximum.level = 1.5, exponent = 0.5)

Thanks if anybody solve this.

Thanking you and with Regards,
 Srinivas,

	[[alternative HTML version deleted]]



From rhe|p @end|ng |rom eoo@@dd@@n|  Thu Nov  1 14:38:52 2018
From: rhe|p @end|ng |rom eoo@@dd@@n| (Jan van der Laan)
Date: Thu, 1 Nov 2018 14:38:52 +0100
Subject: [R] Plot a path
In-Reply-To: <be072d96-a173-40e5-a744-594cbd2ec51e@sapo.pt>
References: <trinity-c72faedf-333b-472d-83c1-16c528a67f1b-1541021239921@3c-app-gmx-bs72>
 <be072d96-a173-40e5-a744-594cbd2ec51e@sapo.pt>
Message-ID: <4620d8e8-33b5-0f57-6be0-ff508ce805f0@eoos.dds.nl>

Below a similar example, using sf and leaflet; plotting the trajectory 
on a background map.


library(leaflet)
library(sf)
library(dplyr)

# Generate example data
gen_data <- function(id, n) {
   data.frame(
     id = id,
     date = 1:n,
     lat = runif(10, min = -90, max = 90),
     lon = runif(10, min = -180, max = 180)
   )
}

dta <- lapply(1:2, gen_data, n = 10) %>% bind_rows()

# Transform all records of one object/person to a st_linestring, then
# combine into one sf column
lines <- dta %>%
   arrange(id, date) %>%
   split(dta$id) %>%
   lapply(function(d) st_linestring(cbind(d$lon, d$lat))) %>%
   unname() %>%   # Without the unname it doesn't work for some reason
   st_sfc()

# Plot using leaflet
leaflet() %>%
   addTiles() %>%
   addPolylines(data = lines)


HTH - Jan


On 01-11-18 11:27, Rui Barradas wrote:
> Hello,
> 
> The following uses ggplot2.
> 
> First, make up a dataset, since you have not posted one.
> 
> 
> 
> lat0 <- 38.736946
> lon0 <- -9.142685
> n <- 10
> 
> set.seed(1)
> Date <- seq(Sys.Date() - n + 1, Sys.Date(), by = "days")
> Lat <- lat0 + cumsum(c(0, runif(n - 1)))
> Lon <- lon0 + cumsum(c(0, runif(n - 1)))
> Placename <- rep(c("A", "B"), n/2)
> 
> path <- data.frame(Date, Placename, Lat, Lon)
> path <- path[order(path$Date), ]
> 
> 
> Now, two graphs, one with just one line of all the lon/lat and the other 
> with a line for each Placename.
> 
> library(ggplot2)
> 
> ggplot(path, aes(x = Lon, y = Lat)) +
>  ? geom_point() +
>  ? geom_line()
> 
> 
> ggplot(path, aes(x = Lon, y = Lat, colour = Placename)) +
>  ? geom_point(aes(fill = Placename)) +
>  ? geom_line()
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 21:27 de 31/10/2018, Ferri Leberl escreveu:
>>
>> Dear All,
>> I have a dataframe with four cols: Date, Placename, geogr. latitude, 
>> geogr. longitude.
>> How can I plot the path as a line, ordered by the date, with the 
>> longitude as the x-axis and the latitude as the y-axis?
>> Thank you in advance!
>> Yours, Ferri
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From dc@r|@on @end|ng |rom t@mu@edu  Thu Nov  1 15:41:29 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Thu, 1 Nov 2018 14:41:29 +0000
Subject: [R] Plot a matrix
In-Reply-To: <CA+8X3fV3w-R4GWTvZ+gqd_sx1aGwHXFy5S4TWaPeRmnoE5suaw@mail.gmail.com>
References: <CAMKaf34G0TBbGMDbp8Wzm=jAen_FXQw3NAKOWRDaG-pt_qjaQw@mail.gmail.com>
 <CA+8X3fV3w-R4GWTvZ+gqd_sx1aGwHXFy5S4TWaPeRmnoE5suaw@mail.gmail.com>
Message-ID: <8455cab7d4564c02857ee5f68b9c8268@tamu.edu>

It would be much better if you had pasted the original .csv file into your message or read the file in R and used dput() to send us the result. It looks like you have a lower triangular matrix and I had to do a little editing to get it to work. I am showing the steps, but commenting them out since you will only need the command following dput(mcdf2). The first row should end with 41848 and every row show begin with #. 

# dta <- "rows 41540 41442 41599 41709 41823 41806 41837 41898 41848
#  41540 NA
#  41442 0.001
#  41599 0.002 0.001
#  41709 0.004 0.003 0.003
#  41823 0.002 0.001 0.002 0.001
#  41806 0.004 0.004 0.005 0.006 0.005
#  41837 0.004 0.004 0.005 0.006 0.005 0.001
#  41898 0.004 0.004 0.005 0.006 0.005 0.001 0.001
#  41848 0.005 0.004 0.005 0.007 0.005 0.001 0.001 0.001 NA"
# mcdf<-read.table(text=dta, header=TRUE, fill=TRUE)
# mcdf
# rownames(mcdf) <- mcdf$rows
# mcdf <- mcdf[, -1]
# mcdf2 <- as.dist(mcdf)
# mcdf2
# dput(mcdf2)

mcdf2 <- structure(c(0.001, 0.002, 0.004, 0.002, 0.004, 0.004, 0.004, 
0.005, 0.001, 0.003, 0.001, 0.004, 0.004, 0.004, 0.004, 0.003, 
0.002, 0.005, 0.005, 0.005, 0.005, 0.001, 0.006, 0.006, 0.006, 
0.007, 0.005, 0.005, 0.005, 0.005, 0.001, 0.001, 0.001, 0.001, 
0.001, 0.001), Labels = c("41540", "41442", "41599", "41709", 
"41823", "41806", "41837", "41898", "41848"), Size = 9L,
call = as.dist.default(m = mcdf), class = "dist", Diag = FALSE,
Upper = FALSE)

Now mcdf2 is a lower triangular distance matrix:

str(mcdf2)
#  'dist' num [1:36] 0.001 0.002 0.004 0.002 0.004 0.004 0.004 0.005 0.001 0.003 ...
#  - attr(*, "Labels")= chr [1:9] "41540" "41442" "41599" "41709" ...
#  - attr(*, "Size")= int 9
#  - attr(*, "call")= language as.dist.default(m = mcdf)
#  - attr(*, "Diag")= logi FALSE
# - attr(*, "Upper")= logi FALSE

The days are stored as an attribute called "Labels" so we need to extract them and compute the differences between them:

days <- as.numeric(attributes(mcdf2)$Labels)
daydiff <- dist(days, method="manhattan")
daydiff
#     1   2   3   4   5   6   7   8
# 2  98                            
# 3  59 157                        
# 4 169 267 110                    
# 5 283 381 224 114                
# 6 266 364 207  97  17            
# 7 297 395 238 128  14  31        
# 8 358 456 299 189  75  92  61    
# 9 308 406 249 139  25  42  11  50

Now we can plot. I've attached a copy:

plot(daydiff, mcdf2)

You need to read the following manual pages to understand what we are doing:

?read.table
?rownames
?as.dist
?dput
?as.numeric
?attributes
?dist
?plot
?Extract (to understand what the "$" is all about.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jim Lemon
Sent: Thursday, November 1, 2018 1:56 AM
To: myriam.croze07 at gmail.com
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Plot a matrix

Hi Myriam,
This may not be the ideal way to do this, but I think it works:

mcdf<-read.table(text="41540 41540 41442 41599 41709 41823 41806 41837
41898 41848
41442 0.001
41599 0.002 0.001
41709 0.004 0.003 0.003
41823 0.002 0.001 0.002 0.001
41806 0.004 0.004 0.005 0.006 0.005
41837 0.004 0.004 0.005 0.006 0.005 0.001
41898 0.004 0.004 0.005 0.006 0.005 0.001 0.001
41848 0.005 0.004 0.005 0.007 0.005 0.001 0.001 0.001",
fill=TRUE)
nrows<-nrow(mcdf)
ncols<-ncol(mcdf)
mcdf2<-mcdf
for(row in 2:nrows) {
 for(col in 2:ncols) {
  if(!is.na(mcdf2[row,col])) mcdf2[row,col]<-mcdf[row,1]-mcdf[1,col]
 }
}
plot(0,xlim=range(as.numeric(unlist(mcdf2[2:nrows,2:ncols])),na.rm=TRUE),
 ylim=range(as.numeric(unlist(mcdf[2:nrows,2:ncols])),na.rm=TRUE),
 xlab="Difference in days",ylab="Distance",type="n")
for(row in 2:nrows) {
 for(col in 2:ncols) {
  if(!is.na(mcdf2[row,col])) points(mcdf2[row,col],mcdf[row,col])
 }
}

Jim
On Thu, Nov 1, 2018 at 5:21 PM Myriam Croze <myriam.croze07 at gmail.com> wrote:
>
> Hello!
>
> I need your help to plot my data. I have a file .csv which looks like that:
>
> 41540 41540 41442 41599 41709 41823 41806 41837 41898 41848
> 41442 0.001
> 41599 0.002 0.001
> 41709 0.004 0.003 0.003
> 41823 0.002 0.001 0.002 0.001
> 41806 0.004 0.004 0.005 0.006 0.005
> 41837 0.004 0.004 0.005 0.006 0.005 0.001
> 41898 0.004 0.004 0.005 0.006 0.005 0.001 0.001
> 41848 0.005 0.004 0.005 0.007 0.005 0.001 0.001 0.001
>
> It is a matrix of distance with in the 1st column and row the days of
> sampling and then the distance values.
> I would like to do a scatterplot of the data with for the y axis the
> distance values and for the x axis the difference between the days of
> sampling (e.g. x = |41442-41540| and y = 0.001).
> Do you know how I could do that with r?
> Thanks in advance for your help.
>
> Best regards,
> Myriam
>
> --
> Myriam Croze
> Post-doctorante
> Division of EcoScience,
> Ewha Womans University
> Seoul, South Korea
>
> Email: myriam.croze07 at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Plot.png
Type: image/png
Size: 4476 bytes
Desc: Plot.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20181101/af1b50d5/attachment-0002.png>

From dc@r|@on @end|ng |rom t@mu@edu  Thu Nov  1 15:52:55 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Thu, 1 Nov 2018 14:52:55 +0000
Subject: [R] Plotting error:
In-Reply-To: <CADDb+48emBkF1UrOmkacgjS=QrZUEsk_WfErDd_OT1DMXYKD_Q@mail.gmail.com>
References: <CADDb+48emBkF1UrOmkacgjS=QrZUEsk_WfErDd_OT1DMXYKD_Q@mail.gmail.com>
Message-ID: <a913513ccee9462e9b02688ce60b71ff@tamu.edu>

You should probably contact the packages maintainer about this.

 maintainer("WaveletComp")  # Notice capitalization
[1] Angi Roesch <angi at angi-stat.com>

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of srinivas kotta
Sent: Thursday, November 1, 2018 4:59 AM
To: r-help at r-project.org
Subject: [R] Plotting error:

Dear Members,

Can anybody help me to solve the errors in R-script. I am plotting wavelet
image using  waveletcomp  library . I am trying define maximum and minimum
(range) of the color scale.


*command is*:
wt.image(my.w, color.key = "interval", n.levels = 250,
         legend.params = list(lab = "wavelet power levels", label.digits =
2), periodlab = "periods (days)", maximum.level = 1.5, exponent = 0.5,
show.date = TRUE, date.format = "%F", timelab = "")


*error is:*
Error in wt.image(my.w, color.key = "interval", n.levels = 250,
legend.params = list(lab = "wavelet power levels",  :
  unused arguments (maximum.level = 1.5, exponent = 0.5)

Thanks if anybody solve this.

Thanking you and with Regards,
 Srinivas,

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From robertob@kker @end|ng |rom gm@||@com  Thu Nov  1 15:55:54 2018
From: robertob@kker @end|ng |rom gm@||@com (P. Roberto Bakker)
Date: Thu, 1 Nov 2018 15:55:54 +0100
Subject: [R] Different stack barplots - same color legends
In-Reply-To: <CA+8X3fX2mVhMbKNYABM38E5qaTVUV1ASrsM25mATzFu4PVeEcA@mail.gmail.com>
References: <CAKDq9_N16xaeL4O2j=v2bVuMb=tuHfu0Ao+yuLQcEq6B-ngq1A@mail.gmail.com>
 <af9001d319ac4992b0bfc5526150f03b@tamu.edu>
 <CAKDq9_P8hQEHWFH=c_86bG81fU0GS+EUCOmtZ9gJa_7kY-2uhA@mail.gmail.com>
 <CAGx1TMAYybconxY7ZVVJcdiYW6+WOjr_D+=GHOA=Xxv2AWRCqQ@mail.gmail.com>
 <CAKDq9_Oi0HGNV7qLnmi4HgVr7orF_gpC7Sys8mLKAxMfjHVtvQ@mail.gmail.com>
 <CAGx1TMB+=RnNeoBmzF=_-gxZ2bzaabExs2Gf-8dKE2vAcpiHpA@mail.gmail.com>
 <CAKDq9_P3GfHXbFbChQwrDUm=E+RuuWGP89tf_KPFXRjYAsrA+A@mail.gmail.com>
 <CAGx1TMByCiZvwOPm06qo4bssWjh=UP9ZPvkX5zi+6dNE=wggaA@mail.gmail.com>
 <CAKDq9_OkLfiP98cuYUg0BU_+cCXmKi9gKHqxSm+Eu16eC3WWyg@mail.gmail.com>
 <CAGx1TMCF8bg64+UOP9ULygHcRnna505RO+1WCWxWJuuFaNp4fQ@mail.gmail.com>
 <CAKDq9_OU8bNq4p8zLr45JADz=SWvGAhG+-ACqdu+qC4a+D8FUw@mail.gmail.com>
 <CA+8X3fXCOPecub-SzuXcp2r4sxQz9TVp2Tr6V_RM2FaX3=5BmA@mail.gmail.com>
 <CAKDq9_O2nRxSW6+dHyhk5P_qpEzkDJafQZZU2aLQF=eAuKRmYg@mail.gmail.com>
 <CA+8X3fUUFwx2YDUMxLvpOCpmS6wnWtUg+W=eo+EYt74u1cx8+Q@mail.gmail.com>
 <CAKDq9_MEoEguz-k78bPhT+dKTP5GzPDWprTQ22B3Fe58Q8Dekw@mail.gmail.com>
 <CA+8X3fX2mVhMbKNYABM38E5qaTVUV1ASrsM25mATzFu4PVeEcA@mail.gmail.com>
Message-ID: <CAKDq9_OmMBqDf2wqar-9rgwxRYq64+pa66xfyAzenXGfNskXMQ@mail.gmail.com>

Yes, that is an good idea, only then I loose the original column lables
which I need in my barplot. Isn't it?

Op do 1 nov. 2018 om 11:03 schreef Jim Lemon <drjimlemon at gmail.com>:

> I would use the "names" or "colnames" functions to change them to Q1,
> Q2, ... as I did.
>
> Jim
>
> On Thu, Nov 1, 2018 at 9:01 PM P. Roberto Bakker
> <robertobakker at gmail.com> wrote:
> >
> > Hi Jim,
> >
> > Thank you for your quick reply. It is a great procedure.
> > The response options in my data.frame are (fortunately) similar in all
> columns.
> > It would be nice if I could use your procedure in all columns at once
> instead of each column.
> > My data.frame contains 48 columns, each with long column names.
> > This means that I need to put each (long) column name after "$:
> dataname$"very long name".
> > So, is ther a way to do this procedure for all columns?
> >
> > Roberto
> >
> >
> > Op do 1 nov. 2018 om 10:50 schreef Jim Lemon <drjimlemon at gmail.com>:
> >>
> >> Hi Roberto,
> >> What I suggested is a brute force method of translating response
> >> options into ordinal numbers. Fortunately for me, the Barratt
> >> Impulsivity Scale has relatively short and constant response options.
> >> As I programmed the test myself, I already had the questions in plain
> >> text, so I simply added the "as.numeric(factor(" and "levels=..."
> >> commands to the forward and reversed response options to create the
> >> whole transformation code. With a bit of cut-and-paste work, it didn't
> >> take that long. Because the BIS-11 is used quite a bit where I am
> >> working. it was worth the trouble.
> >>
> >> Jim
> >>
> >> On Thu, Nov 1, 2018 at 8:38 PM P. Roberto Bakker
> >> <robertobakker at gmail.com> wrote:
> >> >
> >> > Hi Jim,
> >> >
> >> > Thank you.
> >> > An additional question: as I have many columns to change in numeric,
> and the columns are long sentences, what is an efficient way to do this?
> >> > I checked in StackOverflow but could not find the right answer
> >> > Best Roberto
> >> >
> >> >
> >> > Op do 1 nov. 2018 om 00:25 schreef Jim Lemon <drjimlemon at gmail.com>:
> >> >>
> >> >> Hi Roberto,
> >> >> Here is a snippet of code that translates the text responses of the
> >> >> BIS-11 into numeric values. Note the reversal of the order in the
> >> >> second item:
> >> >>
> >> >> BIS$Q1<-as.numeric(factor(BIS$Q1,
> >> >>  levels=c("Almost","Often","Occasionally","Rarely/Never")))
> >> >> BIS$Q2<-as.numeric(factor(BIS$Q2,
> >> >>  levels=c("Rarely/Never","Occasionally","Often","Almost")))
> >> >> ...
> >> >>
> >> >> Jim
> >> >> On Thu, Nov 1, 2018 at 8:57 AM P. Roberto Bakker
> >> >> <robertobakker at gmail.com> wrote:
> >> >> >
> >> >> > Hi Rich,
> >> >> >
> >> >> > Thank you for your answer.
> >> >> > The sentences are strings (likert scale: 'the situation is highly
> >> >> > applicable to me' etc - in Dutch), or column labels; it may be
> confusing as
> >> >> > it is in Dutch. Below I show you part of the dataframe with my
> annotation
> >> >> > added (string/column lable) to give you an idea.
> >> >> > I need to change the likert strings into numeric (1:5). And this
> is a
> >> >> > challenge somehow.
> >> >> > With dplyr, plyr it did not work.
> >> >> > After I have the numeric version then I can stack them as
> suggested by
> >> >> > David.
> >> >> >
>

	[[alternative HTML version deleted]]



From B|||@Po||ng @end|ng |rom ze||@@com  Thu Nov  1 17:02:11 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Thu, 1 Nov 2018 16:02:11 +0000
Subject: [R] glmulti and plot highlight=
Message-ID: <BN7PR02MB5073D5A3C73CBB7CE7AA059EEACE0@BN7PR02MB5073.namprd02.prod.outlook.com>

Windows

sessionInfo() #R version 3.5.1 (2018-07-02)


Hi I am following along (using my own data) the processes described by  "glmulti: An R Package for Easy Automated Model Selection with ( Generalized ) Linear Models"
Journal of Statistical Software
May 2010, Volume 34, Issue 12. http://www.jstatsoft.org/

I will send the pdf if requested, however, I doubt it will get though attached here.

I am having trouble understanding why I am getting these warnings:

ga1 <- glmulti(y ~ a+b+c+d, fitfunc = glm, crit = aic, method = "h")

plot(ga1, type = "p", highlight = c("d:a","d:b"))
Warning messages:
1: In plot.window(...) : "highlight" is not a graphical parameter
2: In plot.xy(xy, type, ...) : "highlight" is not a graphical parameter
3: In axis(side = side, at = at, labels = labels, ...) :
  "highlight.3d" is not a graphical parameter
4: In axis(side = side, at = at, labels = labels, ...) :
  "highlight.3d" is not a graphical parameter
5: In box(...) : "highlight" is not a graphical parameter
6: In title(...) : "highlight" is not a graphical parameter

The authors describe the plots on pg. 15

Also I am not getting the highlights in my plots as is shown in the author's document?

I suppose I could reach out to the authors, assuming 8 years later the e-mail address is the same, however before I did that I thought maybe someone out here might know why this is happening for me.

Here is my structure
dim(r1)
[1] 23189     6
 str(r1)
Classes 'data.table' and 'data.frame':  23189 obs. of  6 variables:
$ SavingsReversed: num  0 0 0 0 0 0 0 0 0 0 ...
$ productID      : int  3 3 3 3 3 3 3 3 1 1 ...
$ ProviderID     : int  113676 113676 113964 113964 114278 114278 114278 114278 114278 114278 ...
$ Editnumber     : int  502 502 504 504 504 504 504 504 504 504 ...
$ PatientGender  : Factor w/ 3 levels "F","M","U": 1 1 2 2 2 2 1 1 1 1 ...
$ Editnumber2    : num  0 0 1 1 1 1 1 1 1 1 ...
 - attr(*, ".internal.selfref")=<externalptr

         SavingsReversed productID ProviderID Editnumber PatientGender Editnumber2
 1:               0         3     113676        502             F           0
 2:               0         3     113676        502             F           0
 3:               0         3     113964        504             M           1
 4:               0         3     113964        504             M           1
 5:               0         3     114278        504             M           1
 6:               0         3     114278        504             M           1
 7:               0         3     114278        504             F           1
 8:               0         3     114278        504             F           1
 9:               0         1     114278        504             F           1
10:               0         1     114278        504             F           1


>




y <- r1$Editnumber2
a <- r1$productID
b <- r1$ProviderID
c <- r1$SavingsReversed
d <- r1$PatientGender

ga1 <- glmulti(y ~ a+b+c+d, fitfunc = glm, crit = aic, method = "h")


I have looked at https://cran.r-project.org/web/packages/scatterplot3d/scatterplot3d.pdf for more info on highlight and it refers to highlight.3d which I also tried, no difference.

Thank you for any insight.




Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From ne||@redu @end|ng |rom hotm@||@|r  Thu Nov  1 20:35:15 2018
From: ne||@redu @end|ng |rom hotm@||@|r (Nelly Reduan)
Date: Thu, 1 Nov 2018 19:35:15 +0000
Subject: [R] Speeding up R code - Apply a function to each row of a matrix
 using the dplyr package
Message-ID: <DM5PR05MB27931285913943F982FFE03F99CE0@DM5PR05MB2793.namprd05.prod.outlook.com>

Hello,

I have a input data frame with multiple rows. For each row, I want to apply a function. The input data frame has 1,000,000+ rows. How can I speed up my code ? I would like to keep the function "func".

Here is a reproducible example with a simple function:

    library(tictoc)
    library(dplyr)

func <- function(coord, a, b, c){

      X1 <- as.vector(coord[1])
      Y1 <- as.vector(coord[2])
      X2 <- as.vector(coord[3])
      Y2 <- as.vector(coord[4])

      if(c == 0) {

        res1 <- mean(c((X1 - a) : (X1 - 1), (Y1 + 1) : (Y1 + 40)))
        res2 <- mean(c((X2 - a) : (X2 - 1), (Y2 + 1) : (Y2 + 40)))
        res <- matrix(c(res1, res2), ncol=2, nrow=1)

      } else {

        res1 <- mean(c((X1 - a) : (X1 - 1), (Y1 + 1) : (Y1 + 40)))*b
        res2 <- mean(c((X2 - a) : (X2 - 1), (Y2 + 1) : (Y2 + 40)))*b
        res <- matrix(c(res1, res2), ncol=2, nrow=1)

      }

      return(res)
    }

    ## Apply the function
    set.seed(1)
    n = 10000000
    tab <- as.matrix(data.frame(x1 = sample(1:100, n, replace = T), y1 = sample(1:100, n, replace = T), x2 = sample(1:100, n, replace = T), y2 = sample(1:100, n, replace = T)))


  tic("test 1")
  test <- tab %>%
    split(1:nrow(tab)) %>%
    map(~ func(.x, 40, 5, 1)) %>%
    do.call("rbind", .)
  toc()

test 1: 599.2 sec elapsed

Thanks very much for your time
Have a nice day
Nell

	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Thu Nov  1 21:26:46 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 2 Nov 2018 07:26:46 +1100
Subject: [R] Different stack barplots - same color legends
In-Reply-To: <CAKDq9_OmMBqDf2wqar-9rgwxRYq64+pa66xfyAzenXGfNskXMQ@mail.gmail.com>
References: <CAKDq9_N16xaeL4O2j=v2bVuMb=tuHfu0Ao+yuLQcEq6B-ngq1A@mail.gmail.com>
 <af9001d319ac4992b0bfc5526150f03b@tamu.edu>
 <CAKDq9_P8hQEHWFH=c_86bG81fU0GS+EUCOmtZ9gJa_7kY-2uhA@mail.gmail.com>
 <CAGx1TMAYybconxY7ZVVJcdiYW6+WOjr_D+=GHOA=Xxv2AWRCqQ@mail.gmail.com>
 <CAKDq9_Oi0HGNV7qLnmi4HgVr7orF_gpC7Sys8mLKAxMfjHVtvQ@mail.gmail.com>
 <CAGx1TMB+=RnNeoBmzF=_-gxZ2bzaabExs2Gf-8dKE2vAcpiHpA@mail.gmail.com>
 <CAKDq9_P3GfHXbFbChQwrDUm=E+RuuWGP89tf_KPFXRjYAsrA+A@mail.gmail.com>
 <CAGx1TMByCiZvwOPm06qo4bssWjh=UP9ZPvkX5zi+6dNE=wggaA@mail.gmail.com>
 <CAKDq9_OkLfiP98cuYUg0BU_+cCXmKi9gKHqxSm+Eu16eC3WWyg@mail.gmail.com>
 <CAGx1TMCF8bg64+UOP9ULygHcRnna505RO+1WCWxWJuuFaNp4fQ@mail.gmail.com>
 <CAKDq9_OU8bNq4p8zLr45JADz=SWvGAhG+-ACqdu+qC4a+D8FUw@mail.gmail.com>
 <CA+8X3fXCOPecub-SzuXcp2r4sxQz9TVp2Tr6V_RM2FaX3=5BmA@mail.gmail.com>
 <CAKDq9_O2nRxSW6+dHyhk5P_qpEzkDJafQZZU2aLQF=eAuKRmYg@mail.gmail.com>
 <CA+8X3fUUFwx2YDUMxLvpOCpmS6wnWtUg+W=eo+EYt74u1cx8+Q@mail.gmail.com>
 <CAKDq9_MEoEguz-k78bPhT+dKTP5GzPDWprTQ22B3Fe58Q8Dekw@mail.gmail.com>
 <CA+8X3fX2mVhMbKNYABM38E5qaTVUV1ASrsM25mATzFu4PVeEcA@mail.gmail.com>
 <CAKDq9_OmMBqDf2wqar-9rgwxRYq64+pa66xfyAzenXGfNskXMQ@mail.gmail.com>
Message-ID: <CA+8X3fXhOrcUOtHmFb=mo8rfPJkmKday+EvCL1XKmne=GTg-hA@mail.gmail.com>

Say your dataframe is named prb.df:

oldnames<-names(prb.df)
ncol<-ncols(prb.df)
names(prb.df)<-paste0("Q",1:ncol)
barplot(...,names.arg=oldnames,...)

Jim

On Fri, Nov 2, 2018 at 1:56 AM P. Roberto Bakker
<robertobakker at gmail.com> wrote:
>
> Yes, that is an good idea, only then I loose the original column lables which I need in my barplot. Isn't it?
>
> Op do 1 nov. 2018 om 11:03 schreef Jim Lemon <drjimlemon at gmail.com>:
>>
>> I would use the "names" or "colnames" functions to change them to Q1,
>> Q2, ... as I did.
>>
>> Jim
>>
>> On Thu, Nov 1, 2018 at 9:01 PM P. Roberto Bakker
>> <robertobakker at gmail.com> wrote:
>> >
>> > Hi Jim,
>> >
>> > Thank you for your quick reply. It is a great procedure.
>> > The response options in my data.frame are (fortunately) similar in all columns.
>> > It would be nice if I could use your procedure in all columns at once instead of each column.
>> > My data.frame contains 48 columns, each with long column names.
>> > This means that I need to put each (long) column name after "$:  dataname$"very long name".
>> > So, is ther a way to do this procedure for all columns?
>> >
>> > Roberto
>> >
>> >
>> > Op do 1 nov. 2018 om 10:50 schreef Jim Lemon <drjimlemon at gmail.com>:
>> >>
>> >> Hi Roberto,
>> >> What I suggested is a brute force method of translating response
>> >> options into ordinal numbers. Fortunately for me, the Barratt
>> >> Impulsivity Scale has relatively short and constant response options.
>> >> As I programmed the test myself, I already had the questions in plain
>> >> text, so I simply added the "as.numeric(factor(" and "levels=..."
>> >> commands to the forward and reversed response options to create the
>> >> whole transformation code. With a bit of cut-and-paste work, it didn't
>> >> take that long. Because the BIS-11 is used quite a bit where I am
>> >> working. it was worth the trouble.
>> >>
>> >> Jim
>> >>
>> >> On Thu, Nov 1, 2018 at 8:38 PM P. Roberto Bakker
>> >> <robertobakker at gmail.com> wrote:
>> >> >
>> >> > Hi Jim,
>> >> >
>> >> > Thank you.
>> >> > An additional question: as I have many columns to change in numeric, and the columns are long sentences, what is an efficient way to do this?
>> >> > I checked in StackOverflow but could not find the right answer
>> >> > Best Roberto
>> >> >
>> >> >
>> >> > Op do 1 nov. 2018 om 00:25 schreef Jim Lemon <drjimlemon at gmail.com>:
>> >> >>
>> >> >> Hi Roberto,
>> >> >> Here is a snippet of code that translates the text responses of the
>> >> >> BIS-11 into numeric values. Note the reversal of the order in the
>> >> >> second item:
>> >> >>
>> >> >> BIS$Q1<-as.numeric(factor(BIS$Q1,
>> >> >>  levels=c("Almost","Often","Occasionally","Rarely/Never")))
>> >> >> BIS$Q2<-as.numeric(factor(BIS$Q2,
>> >> >>  levels=c("Rarely/Never","Occasionally","Often","Almost")))
>> >> >> ...
>> >> >>
>> >> >> Jim
>> >> >> On Thu, Nov 1, 2018 at 8:57 AM P. Roberto Bakker
>> >> >> <robertobakker at gmail.com> wrote:
>> >> >> >
>> >> >> > Hi Rich,
>> >> >> >
>> >> >> > Thank you for your answer.
>> >> >> > The sentences are strings (likert scale: 'the situation is highly
>> >> >> > applicable to me' etc - in Dutch), or column labels; it may be confusing as
>> >> >> > it is in Dutch. Below I show you part of the dataframe with my annotation
>> >> >> > added (string/column lable) to give you an idea.
>> >> >> > I need to change the likert strings into numeric (1:5). And this is a
>> >> >> > challenge somehow.
>> >> >> > With dplyr, plyr it did not work.
>> >> >> > After I have the numeric version then I can stack them as suggested by
>> >> >> > David.
>> >> >> >



From m@cqueen1 @end|ng |rom ||n|@gov  Thu Nov  1 23:07:01 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Thu, 1 Nov 2018 22:07:01 +0000
Subject: [R] 
 Speeding up R code - Apply a function to each row of a matrix
 using the dplyr package
Message-ID: <A3E9AC3F-43E0-45A3-BF5B-262CA6270CED@llnl.gov>

Without more study, I can only give some general pointers.

The as.vector() in X1 <- as.vector(coord[1]) is almost certainly not needed. It will add a little bit to your execution time.
Converting the output of func() to a one row matrix is almost certainly not needed. Just return c(res1, res2).

Your data frame appears to be entirely numeric, in which case you don't need to ever use a data frame. 

Try
  apply( tab, 1, func, a=40, b=5, c=1 )
instead of all that dplyr stuff.


Your function can be redefined as

func <- function(coord, a, b, c){
    
          X1 <- as.vector(coord[1])
          Y1 <- as.vector(coord[2])
          X2 <- as.vector(coord[3])
          Y2 <- as.vector(coord[4])
    
           res1 <- mean(c((X1 - a) : (X1 - 1), (Y1 + 1) : (Y1 + 40)))
           res2 <- mean(c((X2 - a) : (X2 - 1), (Y2 + 1) : (Y2 + 40)))    
    
            if (c==0) c(res1, res2) else c(res1, res2)*b
        }

I suspect you can operate on the entire matrix, without looping (which both the apply() method, and the split/rbind method do, in effect), and if so it will be much faster. But I can't say for sure without more study.

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 11/1/18, 12:35 PM, "R-help on behalf of Nelly Reduan" <r-help-bounces at r-project.org on behalf of nell.redu at hotmail.fr> wrote:

    Hello,
    
    I have a input data frame with multiple rows. For each row, I want to apply a function. The input data frame has 1,000,000+ rows. How can I speed up my code ? I would like to keep the function "func".
    
    Here is a reproducible example with a simple function:
    
        library(tictoc)
        library(dplyr)
    
    func <- function(coord, a, b, c){
    
          X1 <- as.vector(coord[1])
          Y1 <- as.vector(coord[2])
          X2 <- as.vector(coord[3])
          Y2 <- as.vector(coord[4])
    
          if(c == 0) {
    
            res1 <- mean(c((X1 - a) : (X1 - 1), (Y1 + 1) : (Y1 + 40)))
            res2 <- mean(c((X2 - a) : (X2 - 1), (Y2 + 1) : (Y2 + 40)))
            res <- matrix(c(res1, res2), ncol=2, nrow=1)
    
          } else {
    
            res1 <- mean(c((X1 - a) : (X1 - 1), (Y1 + 1) : (Y1 + 40)))*b
            res2 <- mean(c((X2 - a) : (X2 - 1), (Y2 + 1) : (Y2 + 40)))*b
            res <- matrix(c(res1, res2), ncol=2, nrow=1)
    
          }
    
          return(res)
        }
    
        ## Apply the function
        set.seed(1)
        n = 10000000
        tab <- as.matrix(data.frame(x1 = sample(1:100, n, replace = T), y1 = sample(1:100, n, replace = T), x2 = sample(1:100, n, replace = T), y2 = sample(1:100, n, replace = T)))
    
    
      tic("test 1")
      test <- tab %>%
        split(1:nrow(tab)) %>%
        map(~ func(.x, 40, 5, 1)) %>%
        do.call("rbind", .)
      toc()
    
    test 1: 599.2 sec elapsed
    
    Thanks very much for your time
    Have a nice day
    Nell
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From rmh @end|ng |rom temp|e@edu  Thu Nov  1 23:42:07 2018
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Thu, 1 Nov 2018 18:42:07 -0400
Subject: [R] Different stack barplots - same color legends
In-Reply-To: <CAKDq9_OU8bNq4p8zLr45JADz=SWvGAhG+-ACqdu+qC4a+D8FUw@mail.gmail.com>
References: <CAKDq9_N16xaeL4O2j=v2bVuMb=tuHfu0Ao+yuLQcEq6B-ngq1A@mail.gmail.com>
 <af9001d319ac4992b0bfc5526150f03b@tamu.edu>
 <CAKDq9_P8hQEHWFH=c_86bG81fU0GS+EUCOmtZ9gJa_7kY-2uhA@mail.gmail.com>
 <CAGx1TMAYybconxY7ZVVJcdiYW6+WOjr_D+=GHOA=Xxv2AWRCqQ@mail.gmail.com>
 <CAKDq9_Oi0HGNV7qLnmi4HgVr7orF_gpC7Sys8mLKAxMfjHVtvQ@mail.gmail.com>
 <CAGx1TMB+=RnNeoBmzF=_-gxZ2bzaabExs2Gf-8dKE2vAcpiHpA@mail.gmail.com>
 <CAKDq9_P3GfHXbFbChQwrDUm=E+RuuWGP89tf_KPFXRjYAsrA+A@mail.gmail.com>
 <CAGx1TMByCiZvwOPm06qo4bssWjh=UP9ZPvkX5zi+6dNE=wggaA@mail.gmail.com>
 <CAKDq9_OkLfiP98cuYUg0BU_+cCXmKi9gKHqxSm+Eu16eC3WWyg@mail.gmail.com>
 <CAGx1TMCF8bg64+UOP9ULygHcRnna505RO+1WCWxWJuuFaNp4fQ@mail.gmail.com>
 <CAKDq9_OU8bNq4p8zLr45JADz=SWvGAhG+-ACqdu+qC4a+D8FUw@mail.gmail.com>
Message-ID: <CAGx1TMABVMuhWzqF=0G7R8KqRLNL=-H7u_XNjwsogPCeY09zjw@mail.gmail.com>

## reminder on how the levels= argument to factor works

mydata <- matrix(1:8,  nrow=4, ncol=2, dimnames=list(letters[1:4],
LETTERS[1:2]))
dput(mydata)

Factor.wrong <- factor(c("mm", "cm", "m", "km"))
levels(Factor.wrong) ## alphabetical order, not meaning order

Factor.right <- factor(c("mm", "cm", "m", "km"),
                       levels=c("mm", "cm", "m", "km"))
levels(Factor.right) ## meaning order



library(HH) ## for the likert function

## dput(teamq[1:10,7:8])
teamq10x78 <-
structure(list(`Ik volg bijscholing om mijn opleiders-kwaliteiten op
peil te houden` = c("de situatie in hoge mate van toepassing is voor u
of uw supervisorengroep",
"de situatie in hoge mate van toepassing is voor u of uw supervisorengroep",
"de situatie in zeer hoge mate van toepassing is voor u of uw
supervisorengroep",
"de situatie in zeer hoge mate van toepassing is voor u of uw
supervisorengroep",
"de situatie in geringe mate van toepassing is voor u of uw supervisorengroep",
"de situatie enigszins van toepassing is voor u of uw supervisorengroep",
"de situatie in zeer hoge mate van toepassing is voor u of uw
supervisorengroep",
"de situatie in hoge mate van toepassing is voor u of uw supervisorengroep",
"de situatie in hoge mate van toepassing is voor u of uw supervisorengroep",
"de situatie in zeer hoge mate van toepassing is voor u of uw supervisorengroep"
), `Ik weet precies wat de ?modernisering van de opleiding? inhoudt` =
c("de situatie in hoge mate van toepassing is voor u of uw
supervisorengroep",
"de situatie in hoge mate van toepassing is voor u of uw supervisorengroep",
"de situatie in zeer hoge mate van toepassing is voor u of uw
supervisorengroep",
"de situatie in zeer hoge mate van toepassing is voor u of uw
supervisorengroep",
"de situatie in geringe mate van toepassing is voor u of uw supervisorengroep",
"de situatie enigszins van toepassing is voor u of uw supervisorengroep",
"de situatie in geringe mate van toepassing is voor u of uw supervisorengroep",
"de situatie in geringe mate van toepassing is voor u of uw supervisorengroep",
"de situatie enigszins van toepassing is voor u of uw supervisorengroep",
"de situatie in hoge mate van toepassing is voor u of uw supervisorengroep"
)), row.names = c(NA, -10L), class = c("tbl_df", "tbl", "data.frame"
))


## This is from Google translate

## Ik weet precies wat de ?modernisering van de opleiding? inhoudt
## I know exactly what the "modernization of the training"

## Ik volg bijscholing om mijn opleiders-kwaliteiten op peil te houden
## I follow training to keep my grades at level trainers


## ## This is your order of levels from Mon, Oct 22, 2018 at 1:30 PM
## "de situatie in zeer geringe mate van toepassing is voor u of uw
supervisorengroep"
## "de situatie in geringe mate van toepassing is voor u of uw
supervisorengroep"
## "de situatie enigszins van toepassing is voor u of uw supervisorengroep"
## "de situatie in hoge mate van toepassing is voor u of uw supervisorengroep"
## "de situatie in zeer hoge mate van toepassing is voor u of uw
supervisorengroep"

## ## This is from Google translate
## the situation very little applies to you or your group supervisor
## the situation slightly applies to you or your group supervisor
## the situation somewhat applies to you or your group supervisor
## the situation is highly applicable to you or your group supervisor
## the situation very largely applies to you or your group supervisor



sapply(teamq10x78, table)
likert(t(sapply(teamq10x78, table)))
likert(t(sapply(teamq10x78, table)),
       auto.key=list(columns=1, border=TRUE),
       main="character values are sorted alphabetically, we will use
factors in the next figure")

object.size(teamq10x78)
## more rows
object.size(rbind(teamq10x78,teamq10x78,teamq10x78,teamq10x78,teamq10x78,
                  teamq10x78,teamq10x78,teamq10x78,teamq10x78,teamq10x78,
                  teamq10x78,teamq10x78,teamq10x78,teamq10x78,teamq10x78,
                  teamq10x78,teamq10x78,teamq10x78,teamq10x78,teamq10x78))

situatie.levels <- c(
  "de situatie in zeer geringe mate van toepassing is voor u of uw
supervisorengroep",
  "de situatie in geringe mate van toepassing is voor u of uw
supervisorengroep",
  "de situatie enigszins van toepassing is voor u of uw supervisorengroep",
  "de situatie in hoge mate van toepassing is voor u of uw supervisorengroep",
  "de situatie in zeer hoge mate van toepassing is voor u of uw
supervisorengroep")

teamf <- tibble::as.tibble(
  lapply(teamq10x78,
         function(x, levels) factor(x, levels=levels),
         levels=situatie.levels)
)
names(teamf) <- names(teamq10x78) ## lapply replaced space and quote
characters with "."
## and each column is a factor with properly ordered labels.
sapply(teamf, class)
sapply(teamf, levels) ## all five levels appear even though this
example observed only four

object.size(teamf) ## bigger here
## significantly smaller for more rows
object.size(rbind(teamf,teamf,teamf,teamf,teamf,
                  teamf,teamf,teamf,teamf,teamf,
                  teamf,teamf,teamf,teamf,teamf,
                  teamf,teamf,teamf,teamf,teamf))

sapply(teamf, table) ## these are the counts of responses by question

likert(t(sapply(teamf, table)),
       auto.key=list(columns=1, border=TRUE),
       main="the middle group enigszins is by default split equally
between negative and positive")

likert(t(sapply(teamf, table)),
       auto.key=list(columns=1, border=TRUE),
       main="based on your color scheme, I am putting enigszins on the
negative side",
       ReferenceZero=3.5,
       col=c("yellow","sandybrown","orange", "darkolivegreen","green"))


## I am adding a third question with some "zeer geringe" values

teamf[,"Extra Question"] <- teamf[,2]
teamf[1:2, 3] <- situatie.levels[1]

likert(t(sapply(teamf, table)),
       auto.key=list(columns=1, border=TRUE),
       main="based on your color scheme, I am putting enigszins on the
negative side",
       ReferenceZero=3.5,
       col=c("yellow","sandybrown","orange", "darkolivegreen","green"))


## I find the color scheme unsatisfactory.
## The break point between sandybrown and orange is not distinct.
## I would prefer a darker green on the right side.
## try
RColorBrewer::display.brewer.all()
## and see if sny of them work for you.

display.brewer.pal(6, "RdYlGn")

RYG5 <- brewer.pal(6, "RdYlGn")[-4]

likert(t(sapply(teamf, table)),
       auto.key=list(columns=1, border=TRUE),
       main="based on your color scheme, I am putting enigszins on the
negative side",
       ReferenceZero=3.5,
       col=RYG5)



On Wed, Oct 31, 2018 at 5:56 PM, P. Roberto Bakker
<robertobakker at gmail.com> wrote:
> Hi Rich,
>
> Thank you for your answer.
> The sentences are strings (likert scale: 'the situation is highly applicable
> to me' etc - in Dutch), or column labels; it may be confusing as it is in
> Dutch. Below I show you part of the dataframe with my annotation added
> (string/column lable) to give you an idea.
> I need to change the likert strings into numeric (1:5). And this is a
> challenge somehow.
> With dplyr, plyr it did not work.
> After I have the numeric version then I can stack them as suggested by
> David.
>
> PART OF THE DATAFRAME
>>> >>>> >   `Ik volg bijscholing om mijn opleiders-kwaliteiten op peil te
>>> >>>> > houden` COLUMN LABEL
>>> >>>> >
>>> >>>> >   <chr>
>>> >>>> >
>>> >>>> > 1 de situatie in hoge mate van toepassing is voor u of uw
>>> >>>> > supervisorengroep LIKERT STRING
>>> >>>> > 2 de situatie in zeer hoge mate van toepassing is voor u of uw
>>> >>>> > supervisorengroep LIKERT STRING
>>> >>>> > 3 de situatie in zeer hoge mate van toepassing is voor u of uw
>>> >>>> > supervisorengroep LIKERT STRING
>>> >>>> > 4 de situatie in geringe mate van toepassing is voor u of uw
>>> >>>> > supervisorengroep LIKERT STRING
>>> >>>> >   `Ik weet precies wat de ?modernisering van de opleiding?
>>> >>>> > inhoudt` COLUMN LABEL
>>> >>>> >
>>> >>>> >   <chr>
>>> >>>> >
>>> >>>> > 1 de situatie in hoge mate van toepassing is voor u of uw
>>> >>>> > supervisorengroep LIKERT STRING
>>> >>>> > 2 de situatie in zeer hoge mate van toepassing is voor u of uw
>>> >>>> > supervisorengroep LIKERT STRING
>>> >>>> > 3 de situatie in zeer hoge mate van toepassing is voor u of uw
>>> >>>> > supervisorengroep LIKERT STRING
>>> >>>> > 4 de situatie in geringe mate van toepassing is voor u of uw
>>> >>>> > supervisorengroep LIKERT STRING
>
>
>
> Op wo 31 okt. 2018 om 20:28 schreef Richard M. Heiberger <rmh at temple.edu>:
>>
>> What you sent looks like a set of column labels, not the actual numeric
>> data.
>>
>> You might want to convert them to factors where you control the order
>> of the levels.
>> > Factor.wrong <- factor(c("mm", "cm", "m", "km"))
>> > levels(Factor.wrong) ## alphabetical order, not meaning order
>> [1] "cm" "km" "m"  "mm"
>> >
>> > Factor.right <- factor(c("mm", "cm", "m", "km"),
>> +                        levels=c("mm", "cm", "m", "km"))
>> > levels(Factor.right) ## meaning order
>> [1] "mm" "cm" "m"  "km"
>>
>> Or you might want to construct a matrix of counts of your data and plot
>> that.
>>
>> Rich
>>
>>
>> On Wed, Oct 31, 2018 at 1:53 PM, P. Roberto Bakker
>> <robertobakker at gmail.com> wrote:
>> > This is part of the output text
>> >
>> > "de situatie in hoge mate van toepassing is voor u of uw
>> > supervisorengroep", STRING
>> > "de situatie in hoge mate van toepassing is voor u of uw
>> > supervisorengroep", STRING
>> > "de situatie enigszins van toepassing is voor u of uw
>> > supervisorengroep", STRING
>> > "de situatie in hoge mate van toepassing is voor u of uw
>> > supervisorengroep" STRINK
>> > ), `Ik waardeer de inbreng van de aios in de afdelingsvergadering`
>> > COLUMN LABEL= c("de
>> > situatie in hoge mate van toepassing is voor u of uw supervisorengroep",
>> > STRING
>>
>> > "de situatie in hoge mate van toepassing is voor u of uw
>> > supervisorengroep",
>> > "de situatie in zeer hoge mate van toepassing is voor u of uw
>> > supervisorengroep",
>> > "de situatie in zeer hoge mate van toepassing is voor u of uw
>> > supervisorengroep",
>> > "de situatie enigszins van toepassing is voor u of uw
>> > supervisorengroep",
>> > "de situatie in zeer hoge mate van toepassing is voor u of uw
>> > supervisorengroep",
>> > "de situatie in zeer hoge mate van toepassing is voor u of uw
>> > supervisorengroep",
>> > "de situatie in zeer hoge mate van toepassing is voor u of uw
>> > supervisorengroep",
>> > "de situatie enigszins van toepassing is voor u of uw
>> > supervisorengroep",
>> > "de situatie in hoge mate van toepassing is voor u of uw
>> > supervisorengroep",
>> > "de situatie in hoge mate van toepassing is voor u of uw
>> > supervisorengroep",
>> > "de situatie in hoge mate van toepassing is voor u of uw
>> > supervisorengroep",
>> >
>> > Op wo 31 okt. 2018 om 16:24 schreef Richard M. Heiberger
>> > <rmh at temple.edu>:
>> >>
>> >> part is fine.  just be sure that the small part causes the problem.
>> >> I will need that to investigate what is happening.
>> >>
>> >>
>> >> On Wed, Oct 31, 2018 at 11:15 AM, P. Roberto Bakker
>> >> <robertobakker at gmail.com> wrote:
>> >> > It is a very long result text. I can send it to you, or is part of it
>> >> > ok?[
>> >> >
>> >> > Op wo 31 okt. 2018 om 14:27 schreef Richard M. Heiberger
>> >> > <rmh at temple.edu>:
>> >> >>
>> >> >> Please send me the
>> >> >> dput(teamq)
>> >> >>
>> >> >>
>> >> >> On Wed, Oct 31, 2018 at 03:51 P. Roberto Bakker
>> >> >> <robertobakker at gmail.com>
>> >> >> wrote:
>> >> >>>
>> >> >>> Thank you for you information. Package 'HH' is interesting.
>> >> >>>
>> >> >>> Now I find another problem when using 'likert(teamq)'
>> >> >>> I get an error message:
>> >> >>> > likert(teamq)
>> >> >>> Error in dimnames(x) <- `*vtmp*` :
>> >> >>>   length of 'dimnames' [2] not equal to array extent
>> >> >>>
>> >> >>> I checked:
>> >> >>> > dim(teamq)
>> >> >>> [1] 4 2
>> >> >>> > ncol(teamq)
>> >> >>> [1] 2
>> >> >>> So it should be good.
>> >> >>>
>> >> >>> I used 'make.names' , in case the spaces in the variable names
>> >> >>> would
>> >> >>> be a
>> >> >>> problem.
>> >> >>> Same error.
>> >> >>>
>> >> >>> What could I do?
>> >> >>>
>> >> >>> Best and thank you in advance.
>> >> >>> Roberto
>> >> >>>
>> >> >>>
>> >> >>> Op ma 22 okt. 2018 om 20:10 schreef Richard M. Heiberger
>> >> >>> <rmh at temple.edu>:
>> >> >>>>
>> >> >>>> Try the likert function in
>> >> >>>> install.packages("HH) ## if necessary
>> >> >>>> library(HH)
>> >> >>>>
>> >> >>>> Then using David Carlson's example teamq
>> >> >>>> likert(teamq)
>> >> >>>>
>> >> >>>> Your example in the 1:30PM (Eastern Daylight Time) doesn't work.
>> >> >>>> Error in revalue(teamq, c(`de situatie in zeer geringe mate van
>> >> >>>> toepassing is\nvoor u of uw supervisorengroep` = "1",  :
>> >> >>>>   x is not a factor or a character vector.
>> >> >>>>
>> >> >>>> There are many examples in
>> >> >>>> ?likert
>> >> >>>>
>> >> >>>> Rich
>> >> >>>>
>> >> >>>>
>> >> >>>> On Mon, Oct 22, 2018 at 1:30 PM, P. Roberto Bakker
>> >> >>>> <robertobakker at gmail.com> wrote:
>> >> >>>> > Dear David,
>> >> >>>> >
>> >> >>>> > Thank you for you quite response.
>> >> >>>> > My apologies for not giving some sample data - this is due to
>> >> >>>> > AVG.
>> >> >>>> > *But this minisample should not be a problem (all in Dutch)*:
>> >> >>>> >  teamq
>> >> >>>> > # A tibble: 4 x 2
>> >> >>>> >   `Ik volg bijscholing om mijn opleiders-kwaliteiten op peil te
>> >> >>>> > houden`
>> >> >>>> >
>> >> >>>> >   <chr>
>> >> >>>> >
>> >> >>>> > 1 de situatie in hoge mate van toepassing is voor u of uw
>> >> >>>> > supervisorengroep
>> >> >>>> > 2 de situatie in zeer hoge mate van toepassing is voor u of uw
>> >> >>>> > supervisorengroep
>> >> >>>> > 3 de situatie in zeer hoge mate van toepassing is voor u of uw
>> >> >>>> > supervisorengroep
>> >> >>>> > 4 de situatie in geringe mate van toepassing is voor u of uw
>> >> >>>> > supervisorengroep
>> >> >>>> >   `Ik weet precies wat de ?modernisering van de opleiding?
>> >> >>>> > inhoudt`
>> >> >>>> >
>> >> >>>> >   <chr>
>> >> >>>> >
>> >> >>>> > 1 de situatie in hoge mate van toepassing is voor u of uw
>> >> >>>> > supervisorengroep
>> >> >>>> > 2 de situatie in zeer hoge mate van toepassing is voor u of uw
>> >> >>>> > supervisorengroep
>> >> >>>> > 3 de situatie in zeer hoge mate van toepassing is voor u of uw
>> >> >>>> > supervisorengroep
>> >> >>>> > 4 de situatie in geringe mate van toepassing is voor u of uw
>> >> >>>> > supervisorengroep
>> >> >>>> >
>> >> >>>> > As you see the likert items are in words, and I should change
>> >> >>>> > them
>> >> >>>> > in
>> >> >>>> > nummeric - Am I correct?
>> >> >>>> >
>> >> >>>> > *To do this, I tried (see further below):*
>> >> >>>> > plyr rename() ; I receive the message it should be a factor or
>> >> >>>> > character
>> >> >>>> > dplyr recode() ; same message
>> >> >>>> > mapvalues() ; it should be atomic, so I used as.atomic(teamq)
>> >> >>>> > but
>> >> >>>> > then
>> >> >>>> > I
>> >> >>>> > receive the nummers a strings.
>> >> >>>> >
>> >> >>>> > *The syntaxes*
>> >> >>>> > require(plyr)
>> >> >>>> > example2 <- revalue(teamq,
>> >> >>>> >                     c("de situatie in zeer geringe mate van
>> >> >>>> > toepassing
>> >> >>>> > is
>> >> >>>> > voor u of uw supervisorengroep"= "1",
>> >> >>>> >                         "de situatie in geringe mate van
>> >> >>>> > toepassing
>> >> >>>> > is
>> >> >>>> > voor
>> >> >>>> > u of uw supervisorengroep"= "2",
>> >> >>>> >                         "de situatie enigszins van toepassing is
>> >> >>>> > voor
>> >> >>>> > u of
>> >> >>>> > uw supervisorengroep"= "3",
>> >> >>>> >                         "de situatie in hoge mate van toepassing
>> >> >>>> > is
>> >> >>>> > voor u
>> >> >>>> > of uw supervisorengroep"= "4",
>> >> >>>> >                         "de situatie in zeer hoge mate van
>> >> >>>> > toepassing
>> >> >>>> > is
>> >> >>>> > voor u of uw supervisorengroep"= "5"))
>> >> >>>> >
>> >> >>>> > require(dplyr)
>> >> >>>> > example2 <- recode(teamq,
>> >> >>>> >                     c("de situatie in zeer geringe mate van
>> >> >>>> > toepassing
>> >> >>>> > is
>> >> >>>> > voor u of uw supervisorengroep"= "1",
>> >> >>>> >                       "de situatie in geringe mate van
>> >> >>>> > toepassing
>> >> >>>> > is
>> >> >>>> > voor u
>> >> >>>> > of uw supervisorengroep"= "2",
>> >> >>>> >                       "de situatie enigszins van toepassing is
>> >> >>>> > voor
>> >> >>>> > u
>> >> >>>> > of uw
>> >> >>>> > supervisorengroep"= "3",
>> >> >>>> >                       "de situatie in hoge mate van toepassing
>> >> >>>> > is
>> >> >>>> > voor
>> >> >>>> > u of
>> >> >>>> > uw supervisorengroep"= "4",
>> >> >>>> >                       "de situatie in zeer hoge mate van
>> >> >>>> > toepassing
>> >> >>>> > is
>> >> >>>> > voor
>> >> >>>> > u of uw supervisorengroep"= "5"))
>> >> >>>> >
>> >> >>>> > mapvalues(as.matrix(teamq), from = c("de situatie in zeer
>> >> >>>> > geringe
>> >> >>>> > mate
>> >> >>>> > van
>> >> >>>> > toepassing is voor u of uw supervisorengroep",
>> >> >>>> >                         "de situatie in geringe mate van
>> >> >>>> > toepassing
>> >> >>>> > is
>> >> >>>> > voor
>> >> >>>> > u of uw supervisorengroep",
>> >> >>>> >                         "de situatie enigszins van toepassing is
>> >> >>>> > voor
>> >> >>>> > u of
>> >> >>>> > uw supervisorengroep",
>> >> >>>> >                         "de situatie in hoge mate van toepassing
>> >> >>>> > is
>> >> >>>> > voor u
>> >> >>>> > of uw supervisorengroep",
>> >> >>>> >                         "de situatie in zeer hoge mate van
>> >> >>>> > toepassing
>> >> >>>> > is
>> >> >>>> > voor u of uw supervisorengroep"),
>> >> >>>> >           to = c(1,2,3,4,5))
>> >> >>>> >
>> >> >>>> > What should I do?
>> >> >>>> > Thank you in advance, Roberto
>> >> >>>> >
>> >> >>>> > Op ma 22 okt. 2018 om 17:13 schreef David L Carlson
>> >> >>>> > <dcarlson at tamu.edu>:
>> >> >>>> >
>> >> >>>> >> Your example is not reproducible since you did not give us some
>> >> >>>> >> sample
>> >> >>>> >> data. I suspect that your data frame consists of columns that
>> >> >>>> >> represent
>> >> >>>> >> questions and rows that represent individuals who answered the
>> >> >>>> >> questions.
>> >> >>>> >> First create a simple example:
>> >> >>>> >>
>> >> >>>> >> set.seed(42)
>> >> >>>> >> teamq <- data.frame(V1=sample(c(1, 2, 4, 5), 25, replace =
>> >> >>>> >> TRUE),
>> >> >>>> >>      V2=sample(c(1, 2, 3, 4, 5), 25, replace=TRUE),
>> >> >>>> >>      V3=sample(c(2, 3, 4, 5), 25, replace=TRUE))
>> >> >>>> >>
>> >> >>>> >> Notice that this data frame ONLY contains questions (and only 3
>> >> >>>> >> questions). Here are 2 ways to get what you want. The first one
>> >> >>>> >> stacks the
>> >> >>>> >> data:
>> >> >>>> >>
>> >> >>>> >> teamq.stack <- stack(teamq)
>> >> >>>> >> str(teamq.stack)
>> >> >>>> >> counts <- table(teamq.stack)
>> >> >>>> >> str(counts)
>> >> >>>> >>
>> >> >>>> >> The second one converts each column to a factor with levels 1 -
>> >> >>>> >> 5:
>> >> >>>> >>
>> >> >>>> >> teamq2 <- data.frame(lapply(teamq, factor, levels=1:5))
>> >> >>>> >> str(teamq2)
>> >> >>>> >> counts <- sapply(teamq2, table)
>> >> >>>> >> str(counts)
>> >> >>>> >>
>> >> >>>> >> Now make the plots:
>> >> >>>> >>
>> >> >>>> >> cols <- c("yellow","sandybrown","orange",
>> >> >>>> >> "darkolivegreen","green")
>> >> >>>> >> barplot(counts[, 1], horiz=TRUE, col=cols, legend=TRUE)
>> >> >>>> >> barplot(counts[, 2], horiz=TRUE, col=cols, legend=TRUE)
>> >> >>>> >> barplot(counts[, 3], horiz=TRUE, col=cols, legend=TRUE)
>> >> >>>> >>
>> >> >>>> >> You will need to adjust the xlim= argument so that the legend
>> >> >>>> >> does
>> >> >>>> >> not
>> >> >>>> >> print on top of the bars.
>> >> >>>> >>
>> >> >>>> >> ----------------------------------------
>> >> >>>> >> David L Carlson
>> >> >>>> >> Department of Anthropology
>> >> >>>> >> Texas A&M University
>> >> >>>> >> College Station, TX 77843-4352
>> >> >>>> >>
>> >> >>>> >>
>> >> >>>> >> -----Original Message-----
>> >> >>>> >> From: R-help <r-help-bounces at r-project.org> On Behalf Of P.
>> >> >>>> >> Roberto
>> >> >>>> >> Bakker
>> >> >>>> >> Sent: Monday, October 22, 2018 9:04 AM
>> >> >>>> >> To: R mailing list <r-help at r-project.org>
>> >> >>>> >> Subject: [R] Different stack barplots - same color legends
>> >> >>>> >>
>> >> >>>> >> Hi,
>> >> >>>> >>
>> >> >>>> >> I want to make barplots from different questions (columns) in
>> >> >>>> >> one
>> >> >>>> >> data.frame.
>> >> >>>> >> Each question has the same 5 likert items.
>> >> >>>> >> Now the problem: in some questions all items are answered; in
>> >> >>>> >> other
>> >> >>>> >> less.
>> >> >>>> >> From the syntax below I get nice stack barplots - *but the
>> >> >>>> >> legend
>> >> >>>> >> colors do
>> >> >>>> >> not* refer to the same likert-item, which I understand - the
>> >> >>>> >> colors
>> >> >>>> >> go in
>> >> >>>> >> sequence along the table.
>> >> >>>> >> Question: how can I write a syntax that each likert-item has
>> >> >>>> >> the
>> >> >>>> >> same
>> >> >>>> >> legend color?
>> >> >>>> >> Thank you in advance,
>> >> >>>> >>
>> >> >>>> >> Roberto
>> >> >>>> >>
>> >> >>>> >> SYNTAX:
>> >> >>>> >> counts19 <- table(teamq[,19])
>> >> >>>> >> counts20 <- table(teamq[,20])
>> >> >>>> >> barplot(as.matrix(counts19), horiz = T,
>> >> >>>> >>         col=c("yellow","sandybrown","orange",
>> >> >>>> >> "darkolivegreen","green"),
>> >> >>>> >> legend=T)
>> >> >>>> >> barplot(as.matrix(counts20), horiz = T,
>> >> >>>> >>         col=c("yellow","sandybrown","orange",
>> >> >>>> >> "darkolivegreen","green"),
>> >> >>>> >> legend=T)
>> >> >>>> >>
>> >> >>>> >>         [[alternative HTML version deleted]]
>> >> >>>> >>
>> >> >>>> >> ______________________________________________
>> >> >>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >> >>>> >> see
>> >> >>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >>>> >> PLEASE do read the posting guide
>> >> >>>> >> http://www.R-project.org/posting-guide.html
>> >> >>>> >> and provide commented, minimal, self-contained, reproducible
>> >> >>>> >> code.
>> >> >>>> >>
>> >> >>>> >
>> >> >>>> >         [[alternative HTML version deleted]]
>> >> >>>> >
>> >> >>>> > ______________________________________________
>> >> >>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >> >>>> > see
>> >> >>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >>>> > PLEASE do read the posting guide
>> >> >>>> > http://www.R-project.org/posting-guide.html
>> >> >>>> > and provide commented, minimal, self-contained, reproducible
>> >> >>>> > code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Nov  2 00:06:23 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 1 Nov 2018 16:06:23 -0700 (PDT)
Subject: [R] 
 Speeding up R code - Apply a function to each row of a matrix
 using the dplyr package
In-Reply-To: <A3E9AC3F-43E0-45A3-BF5B-262CA6270CED@llnl.gov>
References: <A3E9AC3F-43E0-45A3-BF5B-262CA6270CED@llnl.gov>
Message-ID: <alpine.BSF.2.00.1811011600170.18625@pedal.dcn.davis.ca.us>

As Don suggests, looking for ways to do the whole calculation at once is a 
big efficiency booster. Also, avoiding unnecessary calculations (e.g. mean 
of 1:n is (n+1)/2 and mean(x+a) where a is a constant is mean(x)+a.

Reproducible example:

####################
#library(tictoc)
library(microbenchmark)
library(dplyr)
#>
#> Attaching package: 'dplyr'
#> The following objects are masked from 
'package:stats':
#>
#>     filter, lag
#> The following objects are masked from 
'package:base':
#>
#>     intersect, setdiff, setequal, union
library(purrr)

func1 <- function( coord, A, B, C ) {

   X1 <- as.vector( coord[ 1 ] )
   Y1 <- as.vector( coord[ 2 ] )
   X2 <- as.vector( coord[ 3 ] )
   Y2 <- as.vector( coord[ 4 ] )

   if( C == 0 ) {
     res1 <- mean( c( ( X1 - A ) : ( X1 - 1 )
                    , ( Y1 + 1 ) : ( Y1 + 40 )
                    )
                 )
     res2 <- mean( c( ( X2 - A ) : ( X2 - 1 )
                    , ( Y2 + 1 ) : ( Y2 + 40 )
                    )
                 )
     res <- matrix( c( res1, res2 )
                  , ncol=2
                  , nrow=1
                  )

   } else {

     res1 <- mean( c( ( X1 - A ) : ( X1 - 1 )
                    , ( Y1 + 1 ) : ( Y1 + 40 )
                    )
                 )*B
     res2 <- mean( c( ( X2 - A ) : ( X2 - 1 )
                    , ( Y2 + 1 ) : ( Y2 + 40 )
                    )
                 )*B
     res <- matrix( c( res1, res2 )
                  , ncol=2
                  , nrow=1
                  )

   }

   res
}

#' @param coord is a one-row data frame
func2 <- function( coord, A, B, C ) {
   X1 <- coord[[ 1 ]]
   Y1 <- coord[[ 2 ]]
   X2 <- coord[[ 3 ]]
   Y2 <- coord[[ 4 ]]

   res <- matrix( c( mean( c( X1, Y1 ) )
                   , mean( c( X2, Y2 ) )
                   )
                , ncol=2
                , nrow=1
                ) + ( 40 - A ) / 2

   if ( C != 0 ) {
     res <- res * B
   }

   setNames( as.data.frame( res ), c( "V1", "V2" ) )
}

#' @param coord is a numeric vector of length 4
#' @return Numeric vector of length 2
func3 <- function( coord, A, B, C ) {
   res <- ( c( ( coord[ 1 ] + coord[ 2 ] )
             , ( coord[ 3 ] + coord[ 4 ] )
             )
          + ( 40 - A )
          ) / 2

   if ( C != 0 ) {
     res <- res * B
   }

   res
}

#' @param coord is a matrix with four columns
func4 <- function( coord, A, B, C ) {
   res <- ( cbind( ( coord[ , 1 ] + coord[ , 2 ] )
                 , ( coord[ , 3 ] + coord[ , 4 ] )
                 )
          + ( 40 - A )
          ) / 2

   if ( length( C ) == nrow( coord ) || length( C ) == 1 ) {
     idx <- C == 1
     res[ idx, ] <- res[ idx, ] * B
   }

   res
}

## Apply the function
set.seed( 1 )
n <- 1000
N <- 100
Nseq <- seq.int( N )
# Using T instead of TRUE is asking to get an 
unexpected result someday
tabDF <- data.frame( x1 = sample( Nseq, n, replace = TRUE )
                    , y1 = sample( Nseq, n, replace = TRUE )
                    , x2 = sample( Nseq, n, replace = TRUE )
                    , y2 = sample( Nseq, n, replace = TRUE )
                    )
tab <- as.matrix( tabDF )

fTest1 <- function() {
   test <- tab %>%
     split( 1:nrow(tab) ) %>%
     map(~ func1(.x, 40, 5, 1) ) %>%
     do.call( "rbind", . )
}

fTest2 <- function() {
   # conventional dplyr approach
   test <- tabDF %>%
     rowwise %>%
     do({
       func2( ., 40, 5, 1 )
     }) %>%
     ungroup
}

fTest3 <- function() {
   t( apply( tab, 1, func3, A=40, B=5, C=1 ) )
}

fTest4 <- function() {
   func4( tabDF, A=40, B=5, C=1 )
}

microbenchmark( result1 <- fTest1()
               , result2 <- fTest2()
               , result3 <- fTest3()
               , result4 <- fTest4()
               )
#> Unit: microseconds
#>                 expr        min         lq        mean      median
#>  result1 <- fTest1()  20305.562  23384.359  26939.6559  26262.8495
#>  result2 <- fTest2() 255441.229 276794.201 290628.3221 286046.6385
#>  result3 <- fTest3()   4869.288   5772.462   7242.2194   6615.7900
#>  result4 <- fTest4()     52.862     94.962    216.3508    105.7235
#>           uq        max neval
#>   29324.2775  46207.632   100
#>  294248.0795 473898.379   100
#>    7874.6455  21288.783   100
#>     127.0565   9253.006   100

stopifnot( result1[ , 1 ] == result2[[ 1 ]] )
stopifnot( result1[ , 2 ] == result2[[ 2 ]] )
stopifnot( result1 == result3 )
stopifnot( result1 == result4 )
####################

On Thu, 1 Nov 2018, MacQueen, Don via R-help wrote:

> Without more study, I can only give some general pointers.
>
> The as.vector() in X1 <- as.vector(coord[1]) is almost certainly not needed. It will add a little bit to your execution time.
> Converting the output of func() to a one row matrix is almost certainly not needed. Just return c(res1, res2).
>
> Your data frame appears to be entirely numeric, in which case you don't need to ever use a data frame.
>
> Try
>  apply( tab, 1, func, a=40, b=5, c=1 )
> instead of all that dplyr stuff.
>
>
> Your function can be redefined as
>
> func <- function(coord, a, b, c){
>
>          X1 <- as.vector(coord[1])
>          Y1 <- as.vector(coord[2])
>          X2 <- as.vector(coord[3])
>          Y2 <- as.vector(coord[4])
>
>           res1 <- mean(c((X1 - a) : (X1 - 1), (Y1 + 1) : (Y1 + 40)))
>           res2 <- mean(c((X2 - a) : (X2 - 1), (Y2 + 1) : (Y2 + 40)))
>
>            if (c==0) c(res1, res2) else c(res1, res2)*b
>        }
>
> I suspect you can operate on the entire matrix, without looping (which both the apply() method, and the split/rbind method do, in effect), and if so it will be much faster. But I can't say for sure without more study.
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ?On 11/1/18, 12:35 PM, "R-help on behalf of Nelly Reduan" <r-help-bounces at r-project.org on behalf of nell.redu at hotmail.fr> wrote:
>
>    Hello,
>
>    I have a input data frame with multiple rows. For each row, I want to apply a function. The input data frame has 1,000,000+ rows. How can I speed up my code ? I would like to keep the function "func".
>
>    Here is a reproducible example with a simple function:
>
>        library(tictoc)
>        library(dplyr)
>
>    func <- function(coord, a, b, c){
>
>          X1 <- as.vector(coord[1])
>          Y1 <- as.vector(coord[2])
>          X2 <- as.vector(coord[3])
>          Y2 <- as.vector(coord[4])
>
>          if(c == 0) {
>
>            res1 <- mean(c((X1 - a) : (X1 - 1), (Y1 + 1) : (Y1 + 40)))
>            res2 <- mean(c((X2 - a) : (X2 - 1), (Y2 + 1) : (Y2 + 40)))
>            res <- matrix(c(res1, res2), ncol=2, nrow=1)
>
>          } else {
>
>            res1 <- mean(c((X1 - a) : (X1 - 1), (Y1 + 1) : (Y1 + 40)))*b
>            res2 <- mean(c((X2 - a) : (X2 - 1), (Y2 + 1) : (Y2 + 40)))*b
>            res <- matrix(c(res1, res2), ncol=2, nrow=1)
>
>          }
>
>          return(res)
>        }
>
>        ## Apply the function
>        set.seed(1)
>        n = 10000000
>        tab <- as.matrix(data.frame(x1 = sample(1:100, n, replace = T), y1 = sample(1:100, n, replace = T), x2 = sample(1:100, n, replace = T), y2 = sample(1:100, n, replace = T)))
>
>
>      tic("test 1")
>      test <- tab %>%
>        split(1:nrow(tab)) %>%
>        map(~ func(.x, 40, 5, 1)) %>%
>        do.call("rbind", .)
>      toc()
>
>    test 1: 599.2 sec elapsed
>
>    Thanks very much for your time
>    Have a nice day
>    Nell
>
>    	[[alternative HTML version deleted]]
>
>    ______________________________________________
>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    https://stat.ethz.ch/mailman/listinfo/r-help
>    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>    and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From t@n@@@ @end|ng |rom gm@||@com  Fri Nov  2 01:45:44 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Thu, 1 Nov 2018 17:45:44 -0700
Subject: [R] selecting the COLUMNS in a dataframe function of the numerical
 values in a ROW
Message-ID: <CA+JEM00a-OGutR4zi2ZBBZ-fWUR9metmF+wvq6Q6KCFcwCuDfg@mail.gmail.com>

Dear all, please may I ask for a suggestion :

considering a dataframe  that contains the numerical values for gene
expression, for example :

 x = data.frame(TTT=c(0,1,0,0),
               TTA=c(0,1,1,0),
               ATA=c(1,0,0,0),
               gene=c("gene1", "gene2", "gene3", "gene4"))

how could I select only the COLUMNS where the value of a GENE (a ROW) is
non-zero ?

thank you !

-- bogdan

	[[alternative HTML version deleted]]



From wdun|@p @end|ng |rom t|bco@com  Fri Nov  2 02:08:20 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Thu, 1 Nov 2018 18:08:20 -0700
Subject: [R] 
 selecting the COLUMNS in a dataframe function of the numerical
 values in a ROW
In-Reply-To: <CA+JEM00a-OGutR4zi2ZBBZ-fWUR9metmF+wvq6Q6KCFcwCuDfg@mail.gmail.com>
References: <CA+JEM00a-OGutR4zi2ZBBZ-fWUR9metmF+wvq6Q6KCFcwCuDfg@mail.gmail.com>
Message-ID: <CAF8bMcaeEeZ9U31w1g0Z7sLA_0MiW17ETekVquOOcro7aCviWg@mail.gmail.com>

This would be a bit simpler if 'gene' were the rownames of the data.frame.
The '-4' is to remove the gene column from the calculations.

> x[ x[,"gene"]=="gene2",]
  TTT TTA ATA  gene
2   1   1   0 gene2
> colnames(x)[-4][ 1 == x[ x[,"gene"]=="gene2",-4] ]
[1] "TTT" "TTA"
> colnames(x)[-4][ 1 == x[ x[,"gene"]=="gene3",-4] ]
[1] "TTA"
> x
  TTT TTA ATA  gene
1   0   0   1 gene1
2   1   1   0 gene2
3   0   1   0 gene3
4   0   0   0 gene4



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Nov 1, 2018 at 5:45 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:

> Dear all, please may I ask for a suggestion :
>
> considering a dataframe  that contains the numerical values for gene
> expression, for example :
>
>  x = data.frame(TTT=c(0,1,0,0),
>                TTA=c(0,1,1,0),
>                ATA=c(1,0,0,0),
>                gene=c("gene1", "gene2", "gene3", "gene4"))
>
> how could I select only the COLUMNS where the value of a GENE (a ROW) is
> non-zero ?
>
> thank you !
>
> -- bogdan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From wjm1 @end|ng |rom c@@@co|umb|@@edu  Fri Nov  2 02:33:31 2018
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Thu, 1 Nov 2018 18:33:31 -0700
Subject: [R] 
 selecting the COLUMNS in a dataframe function of the numerical
 values in a ROW
In-Reply-To: <CA+JEM00a-OGutR4zi2ZBBZ-fWUR9metmF+wvq6Q6KCFcwCuDfg@mail.gmail.com>
References: <CA+JEM00a-OGutR4zi2ZBBZ-fWUR9metmF+wvq6Q6KCFcwCuDfg@mail.gmail.com>
Message-ID: <CAA99HCxcSqfPU-5_2eKuOggpHjELfaP63WjPLN9tm5sq99SV6Q@mail.gmail.com>

Hi Bogdan,

Are you saying you want to drop columns that sum to zero? If so, I'm
not sure you've given us a good example dataframe, since all your
numeric columns give non-zero sums.

Otherwise, what you're asking for is trivial. Below is an example
dataframe ("ygene") with an example "AGA" column that gets dropped:

> xgene <- data.frame(TTT=c(0,1,0,0),
+                TTA=c(0,1,1,0),
+                ATA=c(1,0,0,0),
+                gene=c("gene1", "gene2", "gene3", "gene4"))
>
> xgene[ , colSums(xgene[,1:3]) > 0 ]
  TTT TTA ATA  gene
1   0   0   1 gene1
2   1   1   0 gene2
3   0   1   0 gene3
4   0   0   0 gene4
>
> ygene <- data.frame(TTT=c(0,1,0,0),
+                 TTA=c(0,1,1,0),
+                 AGA=c(0,0,0,0),
+                 gene=c("gene1", "gene2", "gene3", "gene4"))
>
> ygene[ , colSums(ygene[,1:3]) > 0 ]
  TTT TTA  gene
1   0   0 gene1
2   1   1 gene2
3   0   1 gene3
4   0   0 gene4


HTH,

Bill.

William Michels, Ph.D.


On Thu, Nov 1, 2018 at 5:45 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> Dear all, please may I ask for a suggestion :
>
> considering a dataframe  that contains the numerical values for gene
> expression, for example :
>
>  x = data.frame(TTT=c(0,1,0,0),
>                TTA=c(0,1,1,0),
>                ATA=c(1,0,0,0),
>                gene=c("gene1", "gene2", "gene3", "gene4"))
>
> how could I select only the COLUMNS where the value of a GENE (a ROW) is
> non-zero ?
>
> thank you !
>
> -- bogdan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From t@n@@@ @end|ng |rom gm@||@com  Fri Nov  2 05:07:26 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Thu, 1 Nov 2018 21:07:26 -0700
Subject: [R] 
 selecting the COLUMNS in a dataframe function of the numerical
 values in a ROW
In-Reply-To: <CAA99HCxcSqfPU-5_2eKuOggpHjELfaP63WjPLN9tm5sq99SV6Q@mail.gmail.com>
References: <CA+JEM00a-OGutR4zi2ZBBZ-fWUR9metmF+wvq6Q6KCFcwCuDfg@mail.gmail.com>
 <CAA99HCxcSqfPU-5_2eKuOggpHjELfaP63WjPLN9tm5sq99SV6Q@mail.gmail.com>
Message-ID: <CA+JEM01JR0Kpp2vJeGa1v49DSoUBmBAHtucVvATMeqXPw286Kw@mail.gmail.com>

Dear Bill, and Bill,

many thanks for taking the time to advice, and for your suggestions. I
believe that I shall rephrase a bit my question, with a better example :
thank you again in advance for your help.

Let's assume that we start from a data frame :

x = data.frame(  TTT=c(0,1,0,0),
               TTA=c(0,1,1,0),
                ATA=c(1,0,0,0),
                 ATT=c(0,0,0,0),
                row.names=c("gene1", "gene2", "gene3", "gene4"))

Shall we select "gene2", at the end, we would like to have ONLY the
COLUMNS, where "gene2" is NOT-ZERO. In other words, the output contains
only the first 2 columns :

output = data.frame(  TTT=c(0,1,0,0),
                                   TTA=c(0,1,1,0),
                                   row.names=c("gene1", "gene2", "gene3",
"gene4"))

 with much appreciation,

-- bogdan

On Thu, Nov 1, 2018 at 6:34 PM William Michels <wjm1 at caa.columbia.edu>
wrote:

> Hi Bogdan,
>
> Are you saying you want to drop columns that sum to zero? If so, I'm
> not sure you've given us a good example dataframe, since all your
> numeric columns give non-zero sums.
>
> Otherwise, what you're asking for is trivial. Below is an example
> dataframe ("ygene") with an example "AGA" column that gets dropped:
>
> > xgene <- data.frame(TTT=c(0,1,0,0),
> +                TTA=c(0,1,1,0),
> +                ATA=c(1,0,0,0),
> +                gene=c("gene1", "gene2", "gene3", "gene4"))
> >
> > xgene[ , colSums(xgene[,1:3]) > 0 ]
>   TTT TTA ATA  gene
> 1   0   0   1 gene1
> 2   1   1   0 gene2
> 3   0   1   0 gene3
> 4   0   0   0 gene4
> >
> > ygene <- data.frame(TTT=c(0,1,0,0),
> +                 TTA=c(0,1,1,0),
> +                 AGA=c(0,0,0,0),
> +                 gene=c("gene1", "gene2", "gene3", "gene4"))
> >
> > ygene[ , colSums(ygene[,1:3]) > 0 ]
>   TTT TTA  gene
> 1   0   0 gene1
> 2   1   1 gene2
> 3   0   1 gene3
> 4   0   0 gene4
>
>
> HTH,
>
> Bill.
>
> William Michels, Ph.D.
>
>
> On Thu, Nov 1, 2018 at 5:45 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> > Dear all, please may I ask for a suggestion :
> >
> > considering a dataframe  that contains the numerical values for gene
> > expression, for example :
> >
> >  x = data.frame(TTT=c(0,1,0,0),
> >                TTA=c(0,1,1,0),
> >                ATA=c(1,0,0,0),
> >                gene=c("gene1", "gene2", "gene3", "gene4"))
> >
> > how could I select only the COLUMNS where the value of a GENE (a ROW) is
> > non-zero ?
> >
> > thank you !
> >
> > -- bogdan
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From wjm1 @end|ng |rom c@@@co|umb|@@edu  Fri Nov  2 05:59:13 2018
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Thu, 1 Nov 2018 21:59:13 -0700
Subject: [R] 
 selecting the COLUMNS in a dataframe function of the numerical
 values in a ROW
In-Reply-To: <CA+JEM01JR0Kpp2vJeGa1v49DSoUBmBAHtucVvATMeqXPw286Kw@mail.gmail.com>
References: <CA+JEM00a-OGutR4zi2ZBBZ-fWUR9metmF+wvq6Q6KCFcwCuDfg@mail.gmail.com>
 <CAA99HCxcSqfPU-5_2eKuOggpHjELfaP63WjPLN9tm5sq99SV6Q@mail.gmail.com>
 <CA+JEM01JR0Kpp2vJeGa1v49DSoUBmBAHtucVvATMeqXPw286Kw@mail.gmail.com>
Message-ID: <CAA99HCxXR6vQqDYE9hvg74=Lh3i0LxZjWJrvBHGoyfH47=HCDA@mail.gmail.com>

Perhaps one of the following two methods:

> zgene = data.frame(  TTT=c(0,1,0,0),
+                TTA=c(0,1,1,0),
+                 ATA=c(1,0,0,0),
+                  ATT=c(0,0,0,0),
+                 row.names=c("gene1", "gene2", "gene3", "gene4"))
> zgene
      TTT TTA ATA ATT
gene1   0   0   1   0
gene2   1   1   0   0
gene3   0   1   0   0
gene4   0   0   0   0
>
> zgene[ , zgene[2,1:4] > 0]
      TTT TTA
gene1   0   0
gene2   1   1
gene3   0   1
gene4   0   0
>
> zgene[ , zgene[rownames(zgene) == "gene2",1:4] > 0]
      TTT TTA
gene1   0   0
gene2   1   1
gene3   0   1
gene4   0   0
>

Best Regards,

Bill.

William Michels, Ph.D.



On Thu, Nov 1, 2018 at 9:07 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> Dear Bill, and Bill,
>
> many thanks for taking the time to advice, and for your suggestions. I
> believe that I shall rephrase a bit my question, with a better example :
> thank you again in advance for your help.
>
> Let's assume that we start from a data frame :
>
> x = data.frame(  TTT=c(0,1,0,0),
>                TTA=c(0,1,1,0),
>                 ATA=c(1,0,0,0),
>                  ATT=c(0,0,0,0),
>                 row.names=c("gene1", "gene2", "gene3", "gene4"))
>
> Shall we select "gene2", at the end, we would like to have ONLY the COLUMNS,
> where "gene2" is NOT-ZERO. In other words, the output contains only the
> first 2 columns :
>
> output = data.frame(  TTT=c(0,1,0,0),
>                                    TTA=c(0,1,1,0),
>                                    row.names=c("gene1", "gene2", "gene3",
> "gene4"))
>
>  with much appreciation,
>
> -- bogdan
>
> On Thu, Nov 1, 2018 at 6:34 PM William Michels <wjm1 at caa.columbia.edu>
> wrote:
>>
>> Hi Bogdan,
>>
>> Are you saying you want to drop columns that sum to zero? If so, I'm
>> not sure you've given us a good example dataframe, since all your
>> numeric columns give non-zero sums.
>>
>> Otherwise, what you're asking for is trivial. Below is an example
>> dataframe ("ygene") with an example "AGA" column that gets dropped:
>>
>> > xgene <- data.frame(TTT=c(0,1,0,0),
>> +                TTA=c(0,1,1,0),
>> +                ATA=c(1,0,0,0),
>> +                gene=c("gene1", "gene2", "gene3", "gene4"))
>> >
>> > xgene[ , colSums(xgene[,1:3]) > 0 ]
>>   TTT TTA ATA  gene
>> 1   0   0   1 gene1
>> 2   1   1   0 gene2
>> 3   0   1   0 gene3
>> 4   0   0   0 gene4
>> >
>> > ygene <- data.frame(TTT=c(0,1,0,0),
>> +                 TTA=c(0,1,1,0),
>> +                 AGA=c(0,0,0,0),
>> +                 gene=c("gene1", "gene2", "gene3", "gene4"))
>> >
>> > ygene[ , colSums(ygene[,1:3]) > 0 ]
>>   TTT TTA  gene
>> 1   0   0 gene1
>> 2   1   1 gene2
>> 3   0   1 gene3
>> 4   0   0 gene4
>>
>>
>> HTH,
>>
>> Bill.
>>
>> William Michels, Ph.D.
>>
>>
>> On Thu, Nov 1, 2018 at 5:45 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
>> > Dear all, please may I ask for a suggestion :
>> >
>> > considering a dataframe  that contains the numerical values for gene
>> > expression, for example :
>> >
>> >  x = data.frame(TTT=c(0,1,0,0),
>> >                TTA=c(0,1,1,0),
>> >                ATA=c(1,0,0,0),
>> >                gene=c("gene1", "gene2", "gene3", "gene4"))
>> >
>> > how could I select only the COLUMNS where the value of a GENE (a ROW) is
>> > non-zero ?
>> >
>> > thank you !
>> >
>> > -- bogdan
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.



From t@n@@@ @end|ng |rom gm@||@com  Fri Nov  2 06:02:40 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Thu, 1 Nov 2018 22:02:40 -0700
Subject: [R] 
 selecting the COLUMNS in a dataframe function of the numerical
 values in a ROW
In-Reply-To: <CAA99HCxXR6vQqDYE9hvg74=Lh3i0LxZjWJrvBHGoyfH47=HCDA@mail.gmail.com>
References: <CA+JEM00a-OGutR4zi2ZBBZ-fWUR9metmF+wvq6Q6KCFcwCuDfg@mail.gmail.com>
 <CAA99HCxcSqfPU-5_2eKuOggpHjELfaP63WjPLN9tm5sq99SV6Q@mail.gmail.com>
 <CA+JEM01JR0Kpp2vJeGa1v49DSoUBmBAHtucVvATMeqXPw286Kw@mail.gmail.com>
 <CAA99HCxXR6vQqDYE9hvg74=Lh3i0LxZjWJrvBHGoyfH47=HCDA@mail.gmail.com>
Message-ID: <CA+JEM01mnP2uZ7wUxgoTNyFLxucYO=XGkaDDYqu=pxO77Odxmw@mail.gmail.com>

very helpful, thanks a lot !

On Thu, Nov 1, 2018 at 9:59 PM William Michels <wjm1 at caa.columbia.edu>
wrote:

> Perhaps one of the following two methods:
>
> > zgene = data.frame(  TTT=c(0,1,0,0),
> +                TTA=c(0,1,1,0),
> +                 ATA=c(1,0,0,0),
> +                  ATT=c(0,0,0,0),
> +                 row.names=c("gene1", "gene2", "gene3", "gene4"))
> > zgene
>       TTT TTA ATA ATT
> gene1   0   0   1   0
> gene2   1   1   0   0
> gene3   0   1   0   0
> gene4   0   0   0   0
> >
> > zgene[ , zgene[2,1:4] > 0]
>       TTT TTA
> gene1   0   0
> gene2   1   1
> gene3   0   1
> gene4   0   0
> >
> > zgene[ , zgene[rownames(zgene) == "gene2",1:4] > 0]
>       TTT TTA
> gene1   0   0
> gene2   1   1
> gene3   0   1
> gene4   0   0
> >
>
> Best Regards,
>
> Bill.
>
> William Michels, Ph.D.
>
>
>
> On Thu, Nov 1, 2018 at 9:07 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> > Dear Bill, and Bill,
> >
> > many thanks for taking the time to advice, and for your suggestions. I
> > believe that I shall rephrase a bit my question, with a better example :
> > thank you again in advance for your help.
> >
> > Let's assume that we start from a data frame :
> >
> > x = data.frame(  TTT=c(0,1,0,0),
> >                TTA=c(0,1,1,0),
> >                 ATA=c(1,0,0,0),
> >                  ATT=c(0,0,0,0),
> >                 row.names=c("gene1", "gene2", "gene3", "gene4"))
> >
> > Shall we select "gene2", at the end, we would like to have ONLY the
> COLUMNS,
> > where "gene2" is NOT-ZERO. In other words, the output contains only the
> > first 2 columns :
> >
> > output = data.frame(  TTT=c(0,1,0,0),
> >                                    TTA=c(0,1,1,0),
> >                                    row.names=c("gene1", "gene2", "gene3",
> > "gene4"))
> >
> >  with much appreciation,
> >
> > -- bogdan
> >
> > On Thu, Nov 1, 2018 at 6:34 PM William Michels <wjm1 at caa.columbia.edu>
> > wrote:
> >>
> >> Hi Bogdan,
> >>
> >> Are you saying you want to drop columns that sum to zero? If so, I'm
> >> not sure you've given us a good example dataframe, since all your
> >> numeric columns give non-zero sums.
> >>
> >> Otherwise, what you're asking for is trivial. Below is an example
> >> dataframe ("ygene") with an example "AGA" column that gets dropped:
> >>
> >> > xgene <- data.frame(TTT=c(0,1,0,0),
> >> +                TTA=c(0,1,1,0),
> >> +                ATA=c(1,0,0,0),
> >> +                gene=c("gene1", "gene2", "gene3", "gene4"))
> >> >
> >> > xgene[ , colSums(xgene[,1:3]) > 0 ]
> >>   TTT TTA ATA  gene
> >> 1   0   0   1 gene1
> >> 2   1   1   0 gene2
> >> 3   0   1   0 gene3
> >> 4   0   0   0 gene4
> >> >
> >> > ygene <- data.frame(TTT=c(0,1,0,0),
> >> +                 TTA=c(0,1,1,0),
> >> +                 AGA=c(0,0,0,0),
> >> +                 gene=c("gene1", "gene2", "gene3", "gene4"))
> >> >
> >> > ygene[ , colSums(ygene[,1:3]) > 0 ]
> >>   TTT TTA  gene
> >> 1   0   0 gene1
> >> 2   1   1 gene2
> >> 3   0   1 gene3
> >> 4   0   0 gene4
> >>
> >>
> >> HTH,
> >>
> >> Bill.
> >>
> >> William Michels, Ph.D.
> >>
> >>
> >> On Thu, Nov 1, 2018 at 5:45 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> >> > Dear all, please may I ask for a suggestion :
> >> >
> >> > considering a dataframe  that contains the numerical values for gene
> >> > expression, for example :
> >> >
> >> >  x = data.frame(TTT=c(0,1,0,0),
> >> >                TTA=c(0,1,1,0),
> >> >                ATA=c(1,0,0,0),
> >> >                gene=c("gene1", "gene2", "gene3", "gene4"))
> >> >
> >> > how could I select only the COLUMNS where the value of a GENE (a ROW)
> is
> >> > non-zero ?
> >> >
> >> > thank you !
> >> >
> >> > -- bogdan
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m|@ojpm @end|ng |rom gm@||@com  Fri Nov  2 09:59:58 2018
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Fri, 2 Nov 2018 16:59:58 +0800
Subject: [R] Granger causality: lag selection
Message-ID: <CABcx46C2DCjXEBN_Mmx3vuvBzZ8Bj2fTsizV+f4cqLvZEXk3mg@mail.gmail.com>

Hi,

   I see an R user chooses the lag of Granger causality by finding out the
lag for the most significant result
   https://www.r-bloggers.com/granger-causality-test/

   Is it generally legitimate to do so, without determining the lag first
by AIC or BIC?

   Thanks,

John

	[[alternative HTML version deleted]]



From @ubh@m|tr@@p@tr@ @end|ng |rom gm@||@com  Fri Nov  2 10:16:09 2018
From: @ubh@m|tr@@p@tr@ @end|ng |rom gm@||@com (Subhamitra Patra)
Date: Fri, 2 Nov 2018 14:46:09 +0530
Subject: [R] Application of rolling window in entropy analysis
Message-ID: <CAOFE=kNmwcP4uPykFp7DXm-=myZpMCix-69hDufeutAN_HLsDg@mail.gmail.com>

Dear all R users,

I want to apply the entropy methods in rolling window analysis. I tried
with the rollapply function, but it is not working. For your convenience, I
am providing my code so that you can easily suggest me the application of
rolling window in the particular methodology. Here is my code

N<-nrow(ts)
r<-matrix(0, nrow = N, ncol = 1)
for (i in 1:N){
     r[i]<-approx_entropy(ts[,i], edim = 2, r = 0.2*sd(ts[,i]), elag = 1)
}

Kindly suggest me how to apply rolling window size of 500 in the particular
time series model?

I expect positive help from you.

Thanks in advance.

-- 
*Best Regards,*
*Subhamitra Patra*
*Phd. Research Scholar*
*Department of Humanities and Social Sciences*
*Indian Institute of Technology, Kharagpur*
*INDIA*


[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
11/02/18,
2:44:12 PM

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Fri Nov  2 11:11:41 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 2 Nov 2018 12:11:41 +0200
Subject: [R] Application of rolling window in entropy analysis
In-Reply-To: <CAOFE=kNmwcP4uPykFp7DXm-=myZpMCix-69hDufeutAN_HLsDg@mail.gmail.com>
References: <CAOFE=kNmwcP4uPykFp7DXm-=myZpMCix-69hDufeutAN_HLsDg@mail.gmail.com>
Message-ID: <CAGgJW77cu+EhoeuhFF61Wv8qT3_pji1dJubK60YXQ3_-zeHOFw@mail.gmail.com>

Hi,
You have some problems with your setup. You set N based on the number of
rows in ts, but then in the call to approx_entropy you write ts[,i].
Note that ts[,i] is the i'th column of ts, whereas your definition of i
implies it is based on row numbers.

Maybe this is leading you to see problems elsewhere. From the rollapply
documentation I don't see any reason why it would not work with the
approx_entropy function.

Best,
Eric


On Fri, Nov 2, 2018 at 11:16 AM Subhamitra Patra <subhamitra.patra at gmail.com>
wrote:

> Dear all R users,
>
> I want to apply the entropy methods in rolling window analysis. I tried
> with the rollapply function, but it is not working. For your convenience, I
> am providing my code so that you can easily suggest me the application of
> rolling window in the particular methodology. Here is my code
>
> N<-nrow(ts)
> r<-matrix(0, nrow = N, ncol = 1)
> for (i in 1:N){
>      r[i]<-approx_entropy(ts[,i], edim = 2, r = 0.2*sd(ts[,i]), elag = 1)
> }
>
> Kindly suggest me how to apply rolling window size of 500 in the particular
> time series model?
>
> I expect positive help from you.
>
> Thanks in advance.
>
> --
> *Best Regards,*
> *Subhamitra Patra*
> *Phd. Research Scholar*
> *Department of Humanities and Social Sciences*
> *Indian Institute of Technology, Kharagpur*
> *INDIA*
>
>
> [image: Mailtrack]
> <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> Sender
> notified by
> Mailtrack
> <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> 11/02/18,
> 2:44:12 PM
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @ubh@m|tr@@p@tr@ @end|ng |rom gm@||@com  Fri Nov  2 11:15:13 2018
From: @ubh@m|tr@@p@tr@ @end|ng |rom gm@||@com (Subhamitra Patra)
Date: Fri, 2 Nov 2018 15:45:13 +0530
Subject: [R] Application of rolling window in entropy analysis
In-Reply-To: <CAGgJW77cu+EhoeuhFF61Wv8qT3_pji1dJubK60YXQ3_-zeHOFw@mail.gmail.com>
References: <CAOFE=kNmwcP4uPykFp7DXm-=myZpMCix-69hDufeutAN_HLsDg@mail.gmail.com>
 <CAGgJW77cu+EhoeuhFF61Wv8qT3_pji1dJubK60YXQ3_-zeHOFw@mail.gmail.com>
Message-ID: <CAOFE=kMtj51stoMVfTG2885GXnfv_Ywu6CtzJFzu8QiZ=QUpnQ@mail.gmail.com>

Thank you for the clarification. I checked and there was a small
mistakes in the code. Now my code is

ts= India[-1,]   #####For deleting the year row
N<-ncol(ts)
r<-matrix(0, ncol = N, nrow = 1)
library(pracma)
for (i in 1:N){
       r[i]<-approx_entropy(ts[,i], edim = 2, r = 0.2*sd(ts[,i]), elag = 1)
}

Even with this code also, I am unable to apply rollapply function.

Kindly help me.


[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
11/02/18,
3:44:26 PM

On Fri, Nov 2, 2018 at 3:42 PM Eric Berger <ericjberger at gmail.com> wrote:

> Hi,
> You have some problems with your setup. You set N based on the number of
> rows in ts, but then in the call to approx_entropy you write ts[,i].
> Note that ts[,i] is the i'th column of ts, whereas your definition of i
> implies it is based on row numbers.
>
> Maybe this is leading you to see problems elsewhere. From the rollapply
> documentation I don't see any reason why it would not work with the
> approx_entropy function.
>
> Best,
> Eric
>
>
> On Fri, Nov 2, 2018 at 11:16 AM Subhamitra Patra <
> subhamitra.patra at gmail.com> wrote:
>
>> Dear all R users,
>>
>> I want to apply the entropy methods in rolling window analysis. I tried
>> with the rollapply function, but it is not working. For your convenience,
>> I
>> am providing my code so that you can easily suggest me the application of
>> rolling window in the particular methodology. Here is my code
>>
>> N<-nrow(ts)
>> r<-matrix(0, nrow = N, ncol = 1)
>> for (i in 1:N){
>>      r[i]<-approx_entropy(ts[,i], edim = 2, r = 0.2*sd(ts[,i]), elag = 1)
>> }
>>
>> Kindly suggest me how to apply rolling window size of 500 in the
>> particular
>> time series model?
>>
>> I expect positive help from you.
>>
>> Thanks in advance.
>>
>> --
>> *Best Regards,*
>> *Subhamitra Patra*
>> *Phd. Research Scholar*
>> *Department of Humanities and Social Sciences*
>> *Indian Institute of Technology, Kharagpur*
>> *INDIA*
>>
>>
>> [image: Mailtrack]
>> <
>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>> >
>> Sender
>> notified by
>> Mailtrack
>> <
>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>> >
>> 11/02/18,
>> 2:44:12 PM
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 
*Best Regards,*
*Subhamitra Patra*
*Phd. Research Scholar*
*Department of Humanities and Social Sciences*
*Indian Institute of Technology, Kharagpur*
*INDIA*

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Fri Nov  2 11:28:40 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 2 Nov 2018 12:28:40 +0200
Subject: [R] Application of rolling window in entropy analysis
In-Reply-To: <CAOFE=kMtj51stoMVfTG2885GXnfv_Ywu6CtzJFzu8QiZ=QUpnQ@mail.gmail.com>
References: <CAOFE=kNmwcP4uPykFp7DXm-=myZpMCix-69hDufeutAN_HLsDg@mail.gmail.com>
 <CAGgJW77cu+EhoeuhFF61Wv8qT3_pji1dJubK60YXQ3_-zeHOFw@mail.gmail.com>
 <CAOFE=kMtj51stoMVfTG2885GXnfv_Ywu6CtzJFzu8QiZ=QUpnQ@mail.gmail.com>
Message-ID: <CAGgJW75-h=CA+VG7ewmGqPfWxjz00673+PRThk7PtArLkuFSUA@mail.gmail.com>

How about something like this:

ts= India[-1,]   #####For deleting the year row
N<-ncol(ts)
width <- 500
M <- nrow(ts) - width
r<-matrix(0, ncol = N, nrow = M)
library(pracma)
for (i in 1:N){
       r[,i]<-rollapply( data=ts[,i], width=width, FUN=approx_entropy, edim
= 2, r = 0.2*sd(ts[,i]), elag = 1, align="right")
}

Best,
Eric



On Fri, Nov 2, 2018 at 12:15 PM Subhamitra Patra <subhamitra.patra at gmail.com>
wrote:

> Thank you for the clarification. I checked and there was a small
> mistakes in the code. Now my code is
>
> ts= India[-1,]   #####For deleting the year row
> N<-ncol(ts)
> r<-matrix(0, ncol = N, nrow = 1)
> library(pracma)
> for (i in 1:N){
>        r[i]<-approx_entropy(ts[,i], edim = 2, r = 0.2*sd(ts[,i]), elag = 1)
> }
>
> Even with this code also, I am unable to apply rollapply function.
>
> Kindly help me.
>
>
> [image: Mailtrack]
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
> notified by
> Mailtrack
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/02/18,
> 3:44:26 PM
>
> On Fri, Nov 2, 2018 at 3:42 PM Eric Berger <ericjberger at gmail.com> wrote:
>
>> Hi,
>> You have some problems with your setup. You set N based on the number of
>> rows in ts, but then in the call to approx_entropy you write ts[,i].
>> Note that ts[,i] is the i'th column of ts, whereas your definition of i
>> implies it is based on row numbers.
>>
>> Maybe this is leading you to see problems elsewhere. From the rollapply
>> documentation I don't see any reason why it would not work with the
>> approx_entropy function.
>>
>> Best,
>> Eric
>>
>>
>> On Fri, Nov 2, 2018 at 11:16 AM Subhamitra Patra <
>> subhamitra.patra at gmail.com> wrote:
>>
>>> Dear all R users,
>>>
>>> I want to apply the entropy methods in rolling window analysis. I tried
>>> with the rollapply function, but it is not working. For your
>>> convenience, I
>>> am providing my code so that you can easily suggest me the application of
>>> rolling window in the particular methodology. Here is my code
>>>
>>> N<-nrow(ts)
>>> r<-matrix(0, nrow = N, ncol = 1)
>>> for (i in 1:N){
>>>      r[i]<-approx_entropy(ts[,i], edim = 2, r = 0.2*sd(ts[,i]), elag = 1)
>>> }
>>>
>>> Kindly suggest me how to apply rolling window size of 500 in the
>>> particular
>>> time series model?
>>>
>>> I expect positive help from you.
>>>
>>> Thanks in advance.
>>>
>>> --
>>> *Best Regards,*
>>> *Subhamitra Patra*
>>> *Phd. Research Scholar*
>>> *Department of Humanities and Social Sciences*
>>> *Indian Institute of Technology, Kharagpur*
>>> *INDIA*
>>>
>>>
>>> [image: Mailtrack]
>>> <
>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>> >
>>> Sender
>>> notified by
>>> Mailtrack
>>> <
>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>> >
>>> 11/02/18,
>>> 2:44:12 PM
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
> --
> *Best Regards,*
> *Subhamitra Patra*
> *Phd. Research Scholar*
> *Department of Humanities and Social Sciences*
> *Indian Institute of Technology, Kharagpur*
> *INDIA*
>

	[[alternative HTML version deleted]]



From @ubh@m|tr@@p@tr@ @end|ng |rom gm@||@com  Fri Nov  2 11:33:31 2018
From: @ubh@m|tr@@p@tr@ @end|ng |rom gm@||@com (Subhamitra Patra)
Date: Fri, 2 Nov 2018 16:03:31 +0530
Subject: [R] Application of rolling window in entropy analysis
In-Reply-To: <CAGgJW75-h=CA+VG7ewmGqPfWxjz00673+PRThk7PtArLkuFSUA@mail.gmail.com>
References: <CAOFE=kNmwcP4uPykFp7DXm-=myZpMCix-69hDufeutAN_HLsDg@mail.gmail.com>
 <CAGgJW77cu+EhoeuhFF61Wv8qT3_pji1dJubK60YXQ3_-zeHOFw@mail.gmail.com>
 <CAOFE=kMtj51stoMVfTG2885GXnfv_Ywu6CtzJFzu8QiZ=QUpnQ@mail.gmail.com>
 <CAGgJW75-h=CA+VG7ewmGqPfWxjz00673+PRThk7PtArLkuFSUA@mail.gmail.com>
Message-ID: <CAOFE=kMmL0=hWQTr7Nc9h+zv_GT-a8aLuDLfipOGf6mqUsySxw@mail.gmail.com>

ts= India[-1,]
N<-ncol(ts)
width <- 500
M <- nrow(ts) - width
r<-matrix(0, ncol = N, nrow = M)
library(pracma)
for (i in 1:N){
       r[,i]<-rollapply( data=ts[,i], width=width, FUN=approx_entropy, edim
= 2, r = 0.2*sd(ts[,i]), elag = 1, align="right")
}

This is my entropy value which I am interested to use in rolling window
size of 500. I applied rollapply function, but it is not working.

Kindly help me out


[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
11/02/18,
4:02:18 PM

On Fri, Nov 2, 2018 at 3:59 PM Eric Berger <ericjberger at gmail.com> wrote:

> How about something like this:
>
> ts= India[-1,]   #####For deleting the year row
> N<-ncol(ts)
> width <- 500
> M <- nrow(ts) - width
> r<-matrix(0, ncol = N, nrow = M)
> library(pracma)
> for (i in 1:N){
>        r[,i]<-rollapply( data=ts[,i], width=width, FUN=approx_entropy,
> edim = 2, r = 0.2*sd(ts[,i]), elag = 1, align="right")
> }
>
> Best,
> Eric
>
>
>
> On Fri, Nov 2, 2018 at 12:15 PM Subhamitra Patra <
> subhamitra.patra at gmail.com> wrote:
>
>> Thank you for the clarification. I checked and there was a small
>> mistakes in the code. Now my code is
>>
>> ts= India[-1,]   #####For deleting the year row
>> N<-ncol(ts)
>> r<-matrix(0, ncol = N, nrow = 1)
>> library(pracma)
>> for (i in 1:N){
>>        r[i]<-approx_entropy(ts[,i], edim = 2, r = 0.2*sd(ts[,i]), elag =
>> 1)
>> }
>>
>> Even with this code also, I am unable to apply rollapply function.
>>
>> Kindly help me.
>>
>>
>> [image: Mailtrack]
>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
>> notified by
>> Mailtrack
>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/02/18,
>> 3:44:26 PM
>>
>> On Fri, Nov 2, 2018 at 3:42 PM Eric Berger <ericjberger at gmail.com> wrote:
>>
>>> Hi,
>>> You have some problems with your setup. You set N based on the number of
>>> rows in ts, but then in the call to approx_entropy you write ts[,i].
>>> Note that ts[,i] is the i'th column of ts, whereas your definition of i
>>> implies it is based on row numbers.
>>>
>>> Maybe this is leading you to see problems elsewhere. From the rollapply
>>> documentation I don't see any reason why it would not work with the
>>> approx_entropy function.
>>>
>>> Best,
>>> Eric
>>>
>>>
>>> On Fri, Nov 2, 2018 at 11:16 AM Subhamitra Patra <
>>> subhamitra.patra at gmail.com> wrote:
>>>
>>>> Dear all R users,
>>>>
>>>> I want to apply the entropy methods in rolling window analysis. I tried
>>>> with the rollapply function, but it is not working. For your
>>>> convenience, I
>>>> am providing my code so that you can easily suggest me the application
>>>> of
>>>> rolling window in the particular methodology. Here is my code
>>>>
>>>> N<-nrow(ts)
>>>> r<-matrix(0, nrow = N, ncol = 1)
>>>> for (i in 1:N){
>>>>      r[i]<-approx_entropy(ts[,i], edim = 2, r = 0.2*sd(ts[,i]), elag =
>>>> 1)
>>>> }
>>>>
>>>> Kindly suggest me how to apply rolling window size of 500 in the
>>>> particular
>>>> time series model?
>>>>
>>>> I expect positive help from you.
>>>>
>>>> Thanks in advance.
>>>>
>>>> --
>>>> *Best Regards,*
>>>> *Subhamitra Patra*
>>>> *Phd. Research Scholar*
>>>> *Department of Humanities and Social Sciences*
>>>> *Indian Institute of Technology, Kharagpur*
>>>> *INDIA*
>>>>
>>>>
>>>> [image: Mailtrack]
>>>> <
>>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>>> >
>>>> Sender
>>>> notified by
>>>> Mailtrack
>>>> <
>>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>>> >
>>>> 11/02/18,
>>>> 2:44:12 PM
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>
>> --
>> *Best Regards,*
>> *Subhamitra Patra*
>> *Phd. Research Scholar*
>> *Department of Humanities and Social Sciences*
>> *Indian Institute of Technology, Kharagpur*
>> *INDIA*
>>
>

-- 
*Best Regards,*
*Subhamitra Patra*
*Phd. Research Scholar*
*Department of Humanities and Social Sciences*
*Indian Institute of Technology, Kharagpur*
*INDIA*

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Fri Nov  2 13:33:15 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 2 Nov 2018 14:33:15 +0200
Subject: [R] Application of rolling window in entropy analysis
In-Reply-To: <CAOFE=kMmL0=hWQTr7Nc9h+zv_GT-a8aLuDLfipOGf6mqUsySxw@mail.gmail.com>
References: <CAOFE=kNmwcP4uPykFp7DXm-=myZpMCix-69hDufeutAN_HLsDg@mail.gmail.com>
 <CAGgJW77cu+EhoeuhFF61Wv8qT3_pji1dJubK60YXQ3_-zeHOFw@mail.gmail.com>
 <CAOFE=kMtj51stoMVfTG2885GXnfv_Ywu6CtzJFzu8QiZ=QUpnQ@mail.gmail.com>
 <CAGgJW75-h=CA+VG7ewmGqPfWxjz00673+PRThk7PtArLkuFSUA@mail.gmail.com>
 <CAOFE=kMmL0=hWQTr7Nc9h+zv_GT-a8aLuDLfipOGf6mqUsySxw@mail.gmail.com>
Message-ID: <CAGgJW74YLjwmnt7ngGMP4PvjxHgxxtkMQaHcQSTJisk+E2qH=A@mail.gmail.com>

You have not provided any information that leads you to write 'it is not
working'.
Can you be specific?
Are you getting error messages? What are they?
etc
etc


On Fri, Nov 2, 2018 at 12:33 PM Subhamitra Patra <subhamitra.patra at gmail.com>
wrote:

> ts= India[-1,]
> N<-ncol(ts)
> width <- 500
> M <- nrow(ts) - width
> r<-matrix(0, ncol = N, nrow = M)
> library(pracma)
> for (i in 1:N){
>        r[,i]<-rollapply( data=ts[,i], width=width, FUN=approx_entropy,
> edim = 2, r = 0.2*sd(ts[,i]), elag = 1, align="right")
> }
>
> This is my entropy value which I am interested to use in rolling window
> size of 500. I applied rollapply function, but it is not working.
>
> Kindly help me out
>
>
> [image: Mailtrack]
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
> notified by
> Mailtrack
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/02/18,
> 4:02:18 PM
>
> On Fri, Nov 2, 2018 at 3:59 PM Eric Berger <ericjberger at gmail.com> wrote:
>
>> How about something like this:
>>
>> ts= India[-1,]   #####For deleting the year row
>> N<-ncol(ts)
>> width <- 500
>> M <- nrow(ts) - width
>> r<-matrix(0, ncol = N, nrow = M)
>> library(pracma)
>> for (i in 1:N){
>>        r[,i]<-rollapply( data=ts[,i], width=width, FUN=approx_entropy,
>> edim = 2, r = 0.2*sd(ts[,i]), elag = 1, align="right")
>> }
>>
>> Best,
>> Eric
>>
>>
>>
>> On Fri, Nov 2, 2018 at 12:15 PM Subhamitra Patra <
>> subhamitra.patra at gmail.com> wrote:
>>
>>> Thank you for the clarification. I checked and there was a small
>>> mistakes in the code. Now my code is
>>>
>>> ts= India[-1,]   #####For deleting the year row
>>> N<-ncol(ts)
>>> r<-matrix(0, ncol = N, nrow = 1)
>>> library(pracma)
>>> for (i in 1:N){
>>>        r[i]<-approx_entropy(ts[,i], edim = 2, r = 0.2*sd(ts[,i]), elag =
>>> 1)
>>> }
>>>
>>> Even with this code also, I am unable to apply rollapply function.
>>>
>>> Kindly help me.
>>>
>>>
>>> [image: Mailtrack]
>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
>>> notified by
>>> Mailtrack
>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/02/18,
>>> 3:44:26 PM
>>>
>>> On Fri, Nov 2, 2018 at 3:42 PM Eric Berger <ericjberger at gmail.com>
>>> wrote:
>>>
>>>> Hi,
>>>> You have some problems with your setup. You set N based on the number
>>>> of rows in ts, but then in the call to approx_entropy you write ts[,i].
>>>> Note that ts[,i] is the i'th column of ts, whereas your definition of i
>>>> implies it is based on row numbers.
>>>>
>>>> Maybe this is leading you to see problems elsewhere. From the rollapply
>>>> documentation I don't see any reason why it would not work with the
>>>> approx_entropy function.
>>>>
>>>> Best,
>>>> Eric
>>>>
>>>>
>>>> On Fri, Nov 2, 2018 at 11:16 AM Subhamitra Patra <
>>>> subhamitra.patra at gmail.com> wrote:
>>>>
>>>>> Dear all R users,
>>>>>
>>>>> I want to apply the entropy methods in rolling window analysis. I tried
>>>>> with the rollapply function, but it is not working. For your
>>>>> convenience, I
>>>>> am providing my code so that you can easily suggest me the application
>>>>> of
>>>>> rolling window in the particular methodology. Here is my code
>>>>>
>>>>> N<-nrow(ts)
>>>>> r<-matrix(0, nrow = N, ncol = 1)
>>>>> for (i in 1:N){
>>>>>      r[i]<-approx_entropy(ts[,i], edim = 2, r = 0.2*sd(ts[,i]), elag =
>>>>> 1)
>>>>> }
>>>>>
>>>>> Kindly suggest me how to apply rolling window size of 500 in the
>>>>> particular
>>>>> time series model?
>>>>>
>>>>> I expect positive help from you.
>>>>>
>>>>> Thanks in advance.
>>>>>
>>>>> --
>>>>> *Best Regards,*
>>>>> *Subhamitra Patra*
>>>>> *Phd. Research Scholar*
>>>>> *Department of Humanities and Social Sciences*
>>>>> *Indian Institute of Technology, Kharagpur*
>>>>> *INDIA*
>>>>>
>>>>>
>>>>> [image: Mailtrack]
>>>>> <
>>>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>>>> >
>>>>> Sender
>>>>> notified by
>>>>> Mailtrack
>>>>> <
>>>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>>>> >
>>>>> 11/02/18,
>>>>> 2:44:12 PM
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>
>>> --
>>> *Best Regards,*
>>> *Subhamitra Patra*
>>> *Phd. Research Scholar*
>>> *Department of Humanities and Social Sciences*
>>> *Indian Institute of Technology, Kharagpur*
>>> *INDIA*
>>>
>>
>
> --
> *Best Regards,*
> *Subhamitra Patra*
> *Phd. Research Scholar*
> *Department of Humanities and Social Sciences*
> *Indian Institute of Technology, Kharagpur*
> *INDIA*
>

	[[alternative HTML version deleted]]



From e@@w|ek @end|ng |rom gm@||@com  Fri Nov  2 16:00:08 2018
From: e@@w|ek @end|ng |rom gm@||@com (Ek Esawi)
Date: Fri, 2 Nov 2018 11:00:08 -0400
Subject: [R] Remove specific rows from nested list of matrices
Message-ID: <CA+ZkTxv=BXPK0QHrucvFb9JW_=4EfiLVzbFu_8PsnG3Brpa4jg@mail.gmail.com>

Hi All,

I have a list that is made up of nested lists, as shown below. I want
to remove all rows in each sub-list that start with an empty space,
that?s the first entry of a row is blank; for example, on
[[1]][[1]][[1]] Remove row 4,on [[1]][[1]][[3]] remove row 5, on
[[1]][[2]][[1]] remove row 6, etc.. All rows start with 2 digits/ 2
digits. My formula works on individual sublist but not the whole
list.. I know my indexing is wrong, but don?t know how to fix it.


> FF

[[1]]
[[1]][[1]]
[[1]][[1]][[1]]
[,1]    [,2]   [,3]    [,4] [,5]
[1,] "30/20"   "AAAAAAAA" ?    ?   "-89"
[2,] "02/20"   "AAAAAAAA? ?    ?   "-98"
[3,] "02/20"   ?AAAAAAA? ?    ?   "-84"
[4,] ?  ? ?  ?   ?
[[1]][[1]][[2]]
[,1]    [,2]
[1,] "02/23" ?AAAAAAAA? : 29" ?
[2,] "02/23" ?AAAAAAAA? ." ?
[3,] "02/23" ?AAAAAAAA? " ?
[4,] "02/23" ?AAAAAAAA? "
[[1]][[1]][[3]]
[,1]    [,2]    [,3] [,4] [,5] [,6] [,7]
[1,] "01/09" ?AAAAAAAA"    ?   ?   ?   "53"
[2,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "403"
[3,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "83"
[4,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "783"
[5,] ?  ?  ?AAAAAAAA?  3042742181"   ?   ?   ?   ?
[[1]][[2]]
[[1]][[2]][[1]]
[,1]  [,2] [,3] [,4] [,5]
[1,] ?    ?   ?   ?   ?AAAAAAAA? "
[2,] "Standard Purchases"  ?   ?   ?   "
[3,] "24/90 "AAAAAAAA? ?   "243"  "
[4,] "24/90 "AAAAAAAA? "   "143"  "
[5,] "24/91 "AAAAAAAA? " ?   "143" ?
[6,] ?    ?   ?   ?   "792"
[[1]][[2]][[2]]
[,1]    [,2]
[1,] "02/23" ?AAAAAAAA?: 31" ?
[2,] "02/23" ?AAAAAAAA?." ?
[3,] "02/23" ?AAAAAAAA? " ?
[4,] "02/23" ?AAAAAAAA?
[5,] "02/23" ?AAAAAAAA?
[6,] "02/23" ?AAAAAAAA? 20"
[7,] "02/23" ?AAAAAAAA?  ?
[8,] "02/23" ?AAAAAAAA? "33"
[[1]][[3]]
[[1]][[3]][[1]]
[,1]    [,2]
[1,] "02/23" ?AAAAAAAA?: 28" ?
[2,] "02/23" ?AAAAAAAA?." ?
[3,] "02/23" ?AAAAAAAA? " ?
[4,] "02/23" ?AAAAAAAA? "
[[1]][[3]][[2]]
[,1]    [,2]    [,3]    [,4] [,5] [,6] [,7]    [,8]    [,9]
[1,] "02/23" ?AAAAAAAA? " ?   ?   "53" "
[2,] "02/24" ?AAAAAAAA? " ?   ?   "
[3,] ?  ?  ?  ?   ?   ?   ?  ?  "1,241"
[4,] "02/24" "AAAAAAAA?  ?   "33?

My Formula,:

G <- lapply(FF, function(x) lapply(x, function (y) lapply(y,
function(z)  z[grepl("^[0-9][0-9]/",z[,1]),])))

The error: Error in z[, 1] : incorrect number of dimensions



Thanks in advance--EK



From bgunter@4567 @end|ng |rom gm@||@com  Fri Nov  2 16:14:57 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 2 Nov 2018 08:14:57 -0700
Subject: [R] Remove specific rows from nested list of matrices
In-Reply-To: <CA+ZkTxv=BXPK0QHrucvFb9JW_=4EfiLVzbFu_8PsnG3Brpa4jg@mail.gmail.com>
References: <CA+ZkTxv=BXPK0QHrucvFb9JW_=4EfiLVzbFu_8PsnG3Brpa4jg@mail.gmail.com>
Message-ID: <CAGxFJbQSFEi50coe8ZNasV4EP+Js4XJEc5114C-BOLB7358Btg@mail.gmail.com>

If you learn to use dput() to provide useful examples in your posts, you
are more likely to receive useful help. It is rather difficult to make much
sense of your messy text, though some brave soul(s) may try to help.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Nov 2, 2018 at 8:00 AM Ek Esawi <esawiek at gmail.com> wrote:

> Hi All,
>
> I have a list that is made up of nested lists, as shown below. I want
> to remove all rows in each sub-list that start with an empty space,
> that?s the first entry of a row is blank; for example, on
> [[1]][[1]][[1]] Remove row 4,on [[1]][[1]][[3]] remove row 5, on
> [[1]][[2]][[1]] remove row 6, etc.. All rows start with 2 digits/ 2
> digits. My formula works on individual sublist but not the whole
> list.. I know my indexing is wrong, but don?t know how to fix it.
>
>
> > FF
>
> [[1]]
> [[1]][[1]]
> [[1]][[1]][[1]]
> [,1]    [,2]   [,3]    [,4] [,5]
> [1,] "30/20"   "AAAAAAAA" ?    ?   "-89"
> [2,] "02/20"   "AAAAAAAA? ?    ?   "-98"
> [3,] "02/20"   ?AAAAAAA? ?    ?   "-84"
> [4,] ?  ? ?  ?   ?
> [[1]][[1]][[2]]
> [,1]    [,2]
> [1,] "02/23" ?AAAAAAAA? : 29" ?
> [2,] "02/23" ?AAAAAAAA? ." ?
> [3,] "02/23" ?AAAAAAAA? " ?
> [4,] "02/23" ?AAAAAAAA? "
> [[1]][[1]][[3]]
> [,1]    [,2]    [,3] [,4] [,5] [,6] [,7]
> [1,] "01/09" ?AAAAAAAA"    ?   ?   ?   "53"
> [2,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "403"
> [3,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "83"
> [4,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "783"
> [5,] ?  ?  ?AAAAAAAA?  3042742181"   ?   ?   ?   ?
> [[1]][[2]]
> [[1]][[2]][[1]]
> [,1]  [,2] [,3] [,4] [,5]
> [1,] ?    ?   ?   ?   ?AAAAAAAA? "
> [2,] "Standard Purchases"  ?   ?   ?   "
> [3,] "24/90 "AAAAAAAA? ?   "243"  "
> [4,] "24/90 "AAAAAAAA? "   "143"  "
> [5,] "24/91 "AAAAAAAA? " ?   "143" ?
> [6,] ?    ?   ?   ?   "792"
> [[1]][[2]][[2]]
> [,1]    [,2]
> [1,] "02/23" ?AAAAAAAA?: 31" ?
> [2,] "02/23" ?AAAAAAAA?." ?
> [3,] "02/23" ?AAAAAAAA? " ?
> [4,] "02/23" ?AAAAAAAA?
> [5,] "02/23" ?AAAAAAAA?
> [6,] "02/23" ?AAAAAAAA? 20"
> [7,] "02/23" ?AAAAAAAA?  ?
> [8,] "02/23" ?AAAAAAAA? "33"
> [[1]][[3]]
> [[1]][[3]][[1]]
> [,1]    [,2]
> [1,] "02/23" ?AAAAAAAA?: 28" ?
> [2,] "02/23" ?AAAAAAAA?." ?
> [3,] "02/23" ?AAAAAAAA? " ?
> [4,] "02/23" ?AAAAAAAA? "
> [[1]][[3]][[2]]
> [,1]    [,2]    [,3]    [,4] [,5] [,6] [,7]    [,8]    [,9]
> [1,] "02/23" ?AAAAAAAA? " ?   ?   "53" "
> [2,] "02/24" ?AAAAAAAA? " ?   ?   "
> [3,] ?  ?  ?  ?   ?   ?   ?  ?  "1,241"
> [4,] "02/24" "AAAAAAAA?  ?   "33?
>
> My Formula,:
>
> G <- lapply(FF, function(x) lapply(x, function (y) lapply(y,
> function(z)  z[grepl("^[0-9][0-9]/",z[,1]),])))
>
> The error: Error in z[, 1] : incorrect number of dimensions
>
>
>
> Thanks in advance--EK
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Nov  2 16:21:25 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 02 Nov 2018 08:21:25 -0700
Subject: [R] Remove specific rows from nested list of matrices
In-Reply-To: <CA+ZkTxv=BXPK0QHrucvFb9JW_=4EfiLVzbFu_8PsnG3Brpa4jg@mail.gmail.com>
References: <CA+ZkTxv=BXPK0QHrucvFb9JW_=4EfiLVzbFu_8PsnG3Brpa4jg@mail.gmail.com>
Message-ID: <FD5A8CEA-B32F-426C-9C1F-772FAAC89F38@dcn.davis.ca.us>

Can you supply the output of

dput(FF)

?

On November 2, 2018 8:00:08 AM PDT, Ek Esawi <esawiek at gmail.com> wrote:
>Hi All,
>
>I have a list that is made up of nested lists, as shown below. I want
>to remove all rows in each sub-list that start with an empty space,
>that?s the first entry of a row is blank; for example, on
>[[1]][[1]][[1]] Remove row 4,on [[1]][[1]][[3]] remove row 5, on
>[[1]][[2]][[1]] remove row 6, etc.. All rows start with 2 digits/ 2
>digits. My formula works on individual sublist but not the whole
>list.. I know my indexing is wrong, but don?t know how to fix it.
>
>
>> FF
>
>[[1]]
>[[1]][[1]]
>[[1]][[1]][[1]]
>[,1]    [,2]   [,3]    [,4] [,5]
>[1,] "30/20"   "AAAAAAAA" ?    ?   "-89"
>[2,] "02/20"   "AAAAAAAA? ?    ?   "-98"
>[3,] "02/20"   ?AAAAAAA? ?    ?   "-84"
>[4,] ?  ? ?  ?   ?
>[[1]][[1]][[2]]
>[,1]    [,2]
>[1,] "02/23" ?AAAAAAAA? : 29" ?
>[2,] "02/23" ?AAAAAAAA? ." ?
>[3,] "02/23" ?AAAAAAAA? " ?
>[4,] "02/23" ?AAAAAAAA? "
>[[1]][[1]][[3]]
>[,1]    [,2]    [,3] [,4] [,5] [,6] [,7]
>[1,] "01/09" ?AAAAAAAA"    ?   ?   ?   "53"
>[2,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "403"
>[3,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "83"
>[4,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "783"
>[5,] ?  ?  ?AAAAAAAA?  3042742181"   ?   ?   ?   ?
>[[1]][[2]]
>[[1]][[2]][[1]]
>[,1]  [,2] [,3] [,4] [,5]
>[1,] ?    ?   ?   ?   ?AAAAAAAA? "
>[2,] "Standard Purchases"  ?   ?   ?   "
>[3,] "24/90 "AAAAAAAA? ?   "243"  "
>[4,] "24/90 "AAAAAAAA? "   "143"  "
>[5,] "24/91 "AAAAAAAA? " ?   "143" ?
>[6,] ?    ?   ?   ?   "792"
>[[1]][[2]][[2]]
>[,1]    [,2]
>[1,] "02/23" ?AAAAAAAA?: 31" ?
>[2,] "02/23" ?AAAAAAAA?." ?
>[3,] "02/23" ?AAAAAAAA? " ?
>[4,] "02/23" ?AAAAAAAA?
>[5,] "02/23" ?AAAAAAAA?
>[6,] "02/23" ?AAAAAAAA? 20"
>[7,] "02/23" ?AAAAAAAA?  ?
>[8,] "02/23" ?AAAAAAAA? "33"
>[[1]][[3]]
>[[1]][[3]][[1]]
>[,1]    [,2]
>[1,] "02/23" ?AAAAAAAA?: 28" ?
>[2,] "02/23" ?AAAAAAAA?." ?
>[3,] "02/23" ?AAAAAAAA? " ?
>[4,] "02/23" ?AAAAAAAA? "
>[[1]][[3]][[2]]
>[,1]    [,2]    [,3]    [,4] [,5] [,6] [,7]    [,8]    [,9]
>[1,] "02/23" ?AAAAAAAA? " ?   ?   "53" "
>[2,] "02/24" ?AAAAAAAA? " ?   ?   "
>[3,] ?  ?  ?  ?   ?   ?   ?  ?  "1,241"
>[4,] "02/24" "AAAAAAAA?  ?   "33?
>
>My Formula,:
>
>G <- lapply(FF, function(x) lapply(x, function (y) lapply(y,
>function(z)  z[grepl("^[0-9][0-9]/",z[,1]),])))
>
>The error: Error in z[, 1] : incorrect number of dimensions
>
>
>
>Thanks in advance--EK
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From e@@w|ek @end|ng |rom gm@||@com  Fri Nov  2 18:50:06 2018
From: e@@w|ek @end|ng |rom gm@||@com (Ek Esawi)
Date: Fri, 2 Nov 2018 13:50:06 -0400
Subject: [R] Remove specific rows from nested list of matrices
In-Reply-To: <FD5A8CEA-B32F-426C-9C1F-772FAAC89F38@dcn.davis.ca.us>
References: <CA+ZkTxv=BXPK0QHrucvFb9JW_=4EfiLVzbFu_8PsnG3Brpa4jg@mail.gmail.com>
 <FD5A8CEA-B32F-426C-9C1F-772FAAC89F38@dcn.davis.ca.us>
Message-ID: <CA+ZkTxuFCUgXhvZai=K37M3Qz8zqyH=DUnVWqQG9oCiCXNbf2g@mail.gmail.com>

Thank you Jeff and Bert. I know i have to use dput add  provide a
reproducible example. The problem is that the output,is huge, has many
nested lists, and the info is private.

Here is the first line of dput(FF) if it helps:
dput(FF)
list(list(list(structure(c("12/30 12/30", "01/02 01/02", "01/02 01/02",

Thanks again--EK
On Fri, Nov 2, 2018 at 11:21 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Can you supply the output of
>
> dput(FF)
>
> ?
>
> On November 2, 2018 8:00:08 AM PDT, Ek Esawi <esawiek at gmail.com> wrote:
> >Hi All,
> >
> >I have a list that is made up of nested lists, as shown below. I want
> >to remove all rows in each sub-list that start with an empty space,
> >that?s the first entry of a row is blank; for example, on
> >[[1]][[1]][[1]] Remove row 4,on [[1]][[1]][[3]] remove row 5, on
> >[[1]][[2]][[1]] remove row 6, etc.. All rows start with 2 digits/ 2
> >digits. My formula works on individual sublist but not the whole
> >list.. I know my indexing is wrong, but don?t know how to fix it.
> >
> >
> >> FF
> >
> >[[1]]
> >[[1]][[1]]
> >[[1]][[1]][[1]]
> >[,1]    [,2]   [,3]    [,4] [,5]
> >[1,] "30/20"   "AAAAAAAA" ?    ?   "-89"
> >[2,] "02/20"   "AAAAAAAA? ?    ?   "-98"
> >[3,] "02/20"   ?AAAAAAA? ?    ?   "-84"
> >[4,] ?  ? ?  ?   ?
> >[[1]][[1]][[2]]
> >[,1]    [,2]
> >[1,] "02/23" ?AAAAAAAA? : 29" ?
> >[2,] "02/23" ?AAAAAAAA? ." ?
> >[3,] "02/23" ?AAAAAAAA? " ?
> >[4,] "02/23" ?AAAAAAAA? "
> >[[1]][[1]][[3]]
> >[,1]    [,2]    [,3] [,4] [,5] [,6] [,7]
> >[1,] "01/09" ?AAAAAAAA"    ?   ?   ?   "53"
> >[2,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "403"
> >[3,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "83"
> >[4,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "783"
> >[5,] ?  ?  ?AAAAAAAA?  3042742181"   ?   ?   ?   ?
> >[[1]][[2]]
> >[[1]][[2]][[1]]
> >[,1]  [,2] [,3] [,4] [,5]
> >[1,] ?    ?   ?   ?   ?AAAAAAAA? "
> >[2,] "Standard Purchases"  ?   ?   ?   "
> >[3,] "24/90 "AAAAAAAA? ?   "243"  "
> >[4,] "24/90 "AAAAAAAA? "   "143"  "
> >[5,] "24/91 "AAAAAAAA? " ?   "143" ?
> >[6,] ?    ?   ?   ?   "792"
> >[[1]][[2]][[2]]
> >[,1]    [,2]
> >[1,] "02/23" ?AAAAAAAA?: 31" ?
> >[2,] "02/23" ?AAAAAAAA?." ?
> >[3,] "02/23" ?AAAAAAAA? " ?
> >[4,] "02/23" ?AAAAAAAA?
> >[5,] "02/23" ?AAAAAAAA?
> >[6,] "02/23" ?AAAAAAAA? 20"
> >[7,] "02/23" ?AAAAAAAA?  ?
> >[8,] "02/23" ?AAAAAAAA? "33"
> >[[1]][[3]]
> >[[1]][[3]][[1]]
> >[,1]    [,2]
> >[1,] "02/23" ?AAAAAAAA?: 28" ?
> >[2,] "02/23" ?AAAAAAAA?." ?
> >[3,] "02/23" ?AAAAAAAA? " ?
> >[4,] "02/23" ?AAAAAAAA? "
> >[[1]][[3]][[2]]
> >[,1]    [,2]    [,3]    [,4] [,5] [,6] [,7]    [,8]    [,9]
> >[1,] "02/23" ?AAAAAAAA? " ?   ?   "53" "
> >[2,] "02/24" ?AAAAAAAA? " ?   ?   "
> >[3,] ?  ?  ?  ?   ?   ?   ?  ?  "1,241"
> >[4,] "02/24" "AAAAAAAA?  ?   "33?
> >
> >My Formula,:
> >
> >G <- lapply(FF, function(x) lapply(x, function (y) lapply(y,
> >function(z)  z[grepl("^[0-9][0-9]/",z[,1]),])))
> >
> >The error: Error in z[, 1] : incorrect number of dimensions
> >
> >
> >
> >Thanks in advance--EK
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Nov  2 19:12:41 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 02 Nov 2018 11:12:41 -0700
Subject: [R] Remove specific rows from nested list of matrices
In-Reply-To: <CA+ZkTxuFCUgXhvZai=K37M3Qz8zqyH=DUnVWqQG9oCiCXNbf2g@mail.gmail.com>
References: <CA+ZkTxv=BXPK0QHrucvFb9JW_=4EfiLVzbFu_8PsnG3Brpa4jg@mail.gmail.com>
 <FD5A8CEA-B32F-426C-9C1F-772FAAC89F38@dcn.davis.ca.us>
 <CA+ZkTxuFCUgXhvZai=K37M3Qz8zqyH=DUnVWqQG9oCiCXNbf2g@mail.gmail.com>
Message-ID: <0751934E-DADF-4032-9495-51DB39B57C11@dcn.davis.ca.us>

A partial dput is no help at all. A complete dput of part of your data is much more likely to be helpful, but only if you see the same problem in it as you do in the full data set.

As to private data... if you want data handling help in a public forum then you need to create a small set of data that illustrates the problem. If you have to manufacture the data by hand we don't care, but it is up to you to communicate a clear question somehow.

On November 2, 2018 10:50:06 AM PDT, Ek Esawi <esawiek at gmail.com> wrote:
>Thank you Jeff and Bert. I know i have to use dput add  provide a
>reproducible example. The problem is that the output,is huge, has many
>nested lists, and the info is private.
>
>Here is the first line of dput(FF) if it helps:
>dput(FF)
>list(list(list(structure(c("12/30 12/30", "01/02 01/02", "01/02 01/02",
>
>Thanks again--EK
>On Fri, Nov 2, 2018 at 11:21 AM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>>
>> Can you supply the output of
>>
>> dput(FF)
>>
>> ?
>>
>> On November 2, 2018 8:00:08 AM PDT, Ek Esawi <esawiek at gmail.com>
>wrote:
>> >Hi All,
>> >
>> >I have a list that is made up of nested lists, as shown below. I
>want
>> >to remove all rows in each sub-list that start with an empty space,
>> >that?s the first entry of a row is blank; for example, on
>> >[[1]][[1]][[1]] Remove row 4,on [[1]][[1]][[3]] remove row 5, on
>> >[[1]][[2]][[1]] remove row 6, etc.. All rows start with 2 digits/ 2
>> >digits. My formula works on individual sublist but not the whole
>> >list.. I know my indexing is wrong, but don?t know how to fix it.
>> >
>> >
>> >> FF
>> >
>> >[[1]]
>> >[[1]][[1]]
>> >[[1]][[1]][[1]]
>> >[,1]    [,2]   [,3]    [,4] [,5]
>> >[1,] "30/20"   "AAAAAAAA" ?    ?   "-89"
>> >[2,] "02/20"   "AAAAAAAA? ?    ?   "-98"
>> >[3,] "02/20"   ?AAAAAAA? ?    ?   "-84"
>> >[4,] ?  ? ?  ?   ?
>> >[[1]][[1]][[2]]
>> >[,1]    [,2]
>> >[1,] "02/23" ?AAAAAAAA? : 29" ?
>> >[2,] "02/23" ?AAAAAAAA? ." ?
>> >[3,] "02/23" ?AAAAAAAA? " ?
>> >[4,] "02/23" ?AAAAAAAA? "
>> >[[1]][[1]][[3]]
>> >[,1]    [,2]    [,3] [,4] [,5] [,6] [,7]
>> >[1,] "01/09" ?AAAAAAAA"    ?   ?   ?   "53"
>> >[2,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "403"
>> >[3,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "83"
>> >[4,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "783"
>> >[5,] ?  ?  ?AAAAAAAA?  3042742181"   ?   ?   ?   ?
>> >[[1]][[2]]
>> >[[1]][[2]][[1]]
>> >[,1]  [,2] [,3] [,4] [,5]
>> >[1,] ?    ?   ?   ?   ?AAAAAAAA? "
>> >[2,] "Standard Purchases"  ?   ?   ?   "
>> >[3,] "24/90 "AAAAAAAA? ?   "243"  "
>> >[4,] "24/90 "AAAAAAAA? "   "143"  "
>> >[5,] "24/91 "AAAAAAAA? " ?   "143" ?
>> >[6,] ?    ?   ?   ?   "792"
>> >[[1]][[2]][[2]]
>> >[,1]    [,2]
>> >[1,] "02/23" ?AAAAAAAA?: 31" ?
>> >[2,] "02/23" ?AAAAAAAA?." ?
>> >[3,] "02/23" ?AAAAAAAA? " ?
>> >[4,] "02/23" ?AAAAAAAA?
>> >[5,] "02/23" ?AAAAAAAA?
>> >[6,] "02/23" ?AAAAAAAA? 20"
>> >[7,] "02/23" ?AAAAAAAA?  ?
>> >[8,] "02/23" ?AAAAAAAA? "33"
>> >[[1]][[3]]
>> >[[1]][[3]][[1]]
>> >[,1]    [,2]
>> >[1,] "02/23" ?AAAAAAAA?: 28" ?
>> >[2,] "02/23" ?AAAAAAAA?." ?
>> >[3,] "02/23" ?AAAAAAAA? " ?
>> >[4,] "02/23" ?AAAAAAAA? "
>> >[[1]][[3]][[2]]
>> >[,1]    [,2]    [,3]    [,4] [,5] [,6] [,7]    [,8]    [,9]
>> >[1,] "02/23" ?AAAAAAAA? " ?   ?   "53" "
>> >[2,] "02/24" ?AAAAAAAA? " ?   ?   "
>> >[3,] ?  ?  ?  ?   ?   ?   ?  ?  "1,241"
>> >[4,] "02/24" "AAAAAAAA?  ?   "33?
>> >
>> >My Formula,:
>> >
>> >G <- lapply(FF, function(x) lapply(x, function (y) lapply(y,
>> >function(z)  z[grepl("^[0-9][0-9]/",z[,1]),])))
>> >
>> >The error: Error in z[, 1] : incorrect number of dimensions
>> >
>> >
>> >
>> >Thanks in advance--EK
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.



From wdun|@p @end|ng |rom t|bco@com  Fri Nov  2 19:15:24 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 2 Nov 2018 11:15:24 -0700
Subject: [R] Remove specific rows from nested list of matrices
In-Reply-To: <CA+ZkTxuFCUgXhvZai=K37M3Qz8zqyH=DUnVWqQG9oCiCXNbf2g@mail.gmail.com>
References: <CA+ZkTxv=BXPK0QHrucvFb9JW_=4EfiLVzbFu_8PsnG3Brpa4jg@mail.gmail.com>
 <FD5A8CEA-B32F-426C-9C1F-772FAAC89F38@dcn.davis.ca.us>
 <CA+ZkTxuFCUgXhvZai=K37M3Qz8zqyH=DUnVWqQG9oCiCXNbf2g@mail.gmail.com>
Message-ID: <CAF8bMcZvAgiTCxdJYEmSt5x9Jr9-_f9KAUfJQstbDJLchFptpw@mail.gmail.com>

Since you cannot show the data you have have to learn some R debugging
techniques.

Here is some data that look something like yours and I want to delete rows
of character
matrices whose first entry starts with a space.

  FF <- lapply(1:2,function(i)lapply(1:3, function(j) lapply(1:2,
function(k) if (identical(c(i,j,k), c(2L,3L,1L))) c(" X", "YZ") else
rbind(c("A", "BC", "DE"), c(" P", "QR", "ST")))))
  G <- lapply(FF, function(x) lapply(x, function (y) lapply(y, function(z)
z[grepl("^ ", z[,1]),])))
  #Error in z[, 1] : incorrect number of dimensions

If you don't recognize the problem right away, try setting
  options(error=recover)
which lets you look at objects and evaluate expressions at the time of the
error.   Look at ?recover for details.

  G <- lapply(FF, function(x) lapply(x, function (y) lapply(y, function(z)
z[grepl("^ ", z[,1]),])))
  #Error in z[, 1] : incorrect number of dimensions
  #
  #Enter a frame number, or 0 to exit
  #
  #1: lapply(FF, function(x) lapply(x, function(y) lapply(y, function(z)
z[grepl(
  #2: FUN(X[[i]], ...)
  #3: #1: lapply(x, function(y) lapply(y, function(z) z[grepl("^ ", z[,
1]), ]))
  #4: FUN(X[[i]], ...)
  #5: #1: lapply(y, function(z) z[grepl("^ ", z[, 1]), ])
  #6: FUN(X[[i]], ...)
  #7: #1: grepl("^ ", z[, 1])
  #
  Selection: 6
  #Called from: eval(substitute(browser(skipCalls = skip), list(skip = 7 -
which)),
  #  envir = sys.frame(which))
  #Browse[1]> objects()
  #[1] "z"
  #Browse[1]> str(z)
  # chr [1:2] " X" "YZ"
  #Browse[1]> str(z[,1])
  #Error during wrapup: incorrect number of dimensions
  #Browse[1]>

My guess is that your list includes a mix of matrices and vectors, perhaps
from not using drop=FALSE when you subscripted them earlier.  Add drop=FALSE
to all your calls to "[" when using matrices.






Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Nov 2, 2018 at 10:50 AM, Ek Esawi <esawiek at gmail.com> wrote:

> Thank you Jeff and Bert. I know i have to use dput add  provide a
> reproducible example. The problem is that the output,is huge, has many
> nested lists, and the info is private.
>
> Here is the first line of dput(FF) if it helps:
> dput(FF)
> list(list(list(structure(c("12/30 12/30", "01/02 01/02", "01/02 01/02",
>
> Thanks again--EK
> On Fri, Nov 2, 2018 at 11:21 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> >
> > Can you supply the output of
> >
> > dput(FF)
> >
> > ?
> >
> > On November 2, 2018 8:00:08 AM PDT, Ek Esawi <esawiek at gmail.com> wrote:
> > >Hi All,
> > >
> > >I have a list that is made up of nested lists, as shown below. I want
> > >to remove all rows in each sub-list that start with an empty space,
> > >that?s the first entry of a row is blank; for example, on
> > >[[1]][[1]][[1]] Remove row 4,on [[1]][[1]][[3]] remove row 5, on
> > >[[1]][[2]][[1]] remove row 6, etc.. All rows start with 2 digits/ 2
> > >digits. My formula works on individual sublist but not the whole
> > >list.. I know my indexing is wrong, but don?t know how to fix it.
> > >
> > >
> > >> FF
> > >
> > >[[1]]
> > >[[1]][[1]]
> > >[[1]][[1]][[1]]
> > >[,1]    [,2]   [,3]    [,4] [,5]
> > >[1,] "30/20"   "AAAAAAAA" ?    ?   "-89"
> > >[2,] "02/20"   "AAAAAAAA? ?    ?   "-98"
> > >[3,] "02/20"   ?AAAAAAA? ?    ?   "-84"
> > >[4,] ?  ? ?  ?   ?
> > >[[1]][[1]][[2]]
> > >[,1]    [,2]
> > >[1,] "02/23" ?AAAAAAAA? : 29" ?
> > >[2,] "02/23" ?AAAAAAAA? ." ?
> > >[3,] "02/23" ?AAAAAAAA? " ?
> > >[4,] "02/23" ?AAAAAAAA? "
> > >[[1]][[1]][[3]]
> > >[,1]    [,2]    [,3] [,4] [,5] [,6] [,7]
> > >[1,] "01/09" ?AAAAAAAA"    ?   ?   ?   "53"
> > >[2,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "403"
> > >[3,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "83"
> > >[4,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "783"
> > >[5,] ?  ?  ?AAAAAAAA?  3042742181"   ?   ?   ?   ?
> > >[[1]][[2]]
> > >[[1]][[2]][[1]]
> > >[,1]  [,2] [,3] [,4] [,5]
> > >[1,] ?    ?   ?   ?   ?AAAAAAAA? "
> > >[2,] "Standard Purchases"  ?   ?   ?   "
> > >[3,] "24/90 "AAAAAAAA? ?   "243"  "
> > >[4,] "24/90 "AAAAAAAA? "   "143"  "
> > >[5,] "24/91 "AAAAAAAA? " ?   "143" ?
> > >[6,] ?    ?   ?   ?   "792"
> > >[[1]][[2]][[2]]
> > >[,1]    [,2]
> > >[1,] "02/23" ?AAAAAAAA?: 31" ?
> > >[2,] "02/23" ?AAAAAAAA?." ?
> > >[3,] "02/23" ?AAAAAAAA? " ?
> > >[4,] "02/23" ?AAAAAAAA?
> > >[5,] "02/23" ?AAAAAAAA?
> > >[6,] "02/23" ?AAAAAAAA? 20"
> > >[7,] "02/23" ?AAAAAAAA?  ?
> > >[8,] "02/23" ?AAAAAAAA? "33"
> > >[[1]][[3]]
> > >[[1]][[3]][[1]]
> > >[,1]    [,2]
> > >[1,] "02/23" ?AAAAAAAA?: 28" ?
> > >[2,] "02/23" ?AAAAAAAA?." ?
> > >[3,] "02/23" ?AAAAAAAA? " ?
> > >[4,] "02/23" ?AAAAAAAA? "
> > >[[1]][[3]][[2]]
> > >[,1]    [,2]    [,3]    [,4] [,5] [,6] [,7]    [,8]    [,9]
> > >[1,] "02/23" ?AAAAAAAA? " ?   ?   "53" "
> > >[2,] "02/24" ?AAAAAAAA? " ?   ?   "
> > >[3,] ?  ?  ?  ?   ?   ?   ?  ?  "1,241"
> > >[4,] "02/24" "AAAAAAAA?  ?   "33?
> > >
> > >My Formula,:
> > >
> > >G <- lapply(FF, function(x) lapply(x, function (y) lapply(y,
> > >function(z)  z[grepl("^[0-9][0-9]/",z[,1]),])))
> > >
> > >The error: Error in z[, 1] : incorrect number of dimensions
> > >
> > >
> > >
> > >Thanks in advance--EK
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m@cqueen1 @end|ng |rom ||n|@gov  Fri Nov  2 20:53:05 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Fri, 2 Nov 2018 19:53:05 +0000
Subject: [R] Remove specific rows from nested list of matrices
In-Reply-To: <CA+ZkTxv=BXPK0QHrucvFb9JW_=4EfiLVzbFu_8PsnG3Brpa4jg@mail.gmail.com>
References: <CA+ZkTxv=BXPK0QHrucvFb9JW_=4EfiLVzbFu_8PsnG3Brpa4jg@mail.gmail.com>
Message-ID: <27FB2B3A-90B4-4350-8C7C-47C1F656AC1E@llnl.gov>

It appears that at the bottom of the nesting, so to speak, you have a character matrix.
That is, the contents of the [[1]][[1]][[1]] element is a character matrix that, according to the row and column labels, has 4 rows and 5 columns.
However, the matrix itself, as printed, has, apparently, 4 column in row one, not 5 -- and five quote marks in row 4, so the number of columns is ambiguous (quote marks have to be balanced).

None the less, assuming you really do have character matrices that you're trying to modify, I'd be inclined to take a brute force approach.

I would also use for() loops instead of lapply(), because the code will be easier to follow.

Do you know, or can you assume, the maximum depth of nesting? Let's say it's three.

Here's an outline. I can't test it without an actual object to work on, and it probably has some details wrong. My intent is to present the concept.
(I believe I have the 'next' statements in the right place...)

for (i1 in length(FF)) {
  ## the "1" in "ff1" means first level of nesting, not first element of the list
  ff1 <- FF[[i1]]

  if ( !is.list(ff1) ) {
     ## the current element is not nested list
     {apply the function that removes the appropriate rows}
      ## this 'next' statement is supposed to move us to the 2nd element of FF
     next
  } else {
    ## the current element (of FF) is a list, therefore, have to loop through its elements

  for (i2 in length(ff1)) {
     ff2 <- ff1[[i2]]

     if ( !is.list(ff2) ) {
        ## the current element is not a nested list
        {apply the removal function}
        next
        } else {
        ## the current element is a nested list
       for (i3 in length(ff2) {
      ## if I've kept track correctly, we're now looking at the third level down of nesting,
      ## and if that's the max depth, we don't have to go any further

---- etc, and close all the loops ---


This brute force approach consists of nested for() loops.
The outer loop is for the top level list.
The next nested loop is for the second level lists, within each element of the top level
The next nested loop is for the third level lists, within each second level element
Since not all elements are nested to the same depth, it has to be noticed when a non-list element is reached. That element gets modified and that level is done; move up to the previous level and continue to its next element.
At least, that's an approach that I think can work, but getting all the details correct will take some work.

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 11/2/18, 8:00 AM, "R-help on behalf of Ek Esawi" <r-help-bounces at r-project.org on behalf of esawiek at gmail.com> wrote:

    Hi All,
    
    I have a list that is made up of nested lists, as shown below. I want
    to remove all rows in each sub-list that start with an empty space,
    that?s the first entry of a row is blank; for example, on
    [[1]][[1]][[1]] Remove row 4,on [[1]][[1]][[3]] remove row 5, on
    [[1]][[2]][[1]] remove row 6, etc.. All rows start with 2 digits/ 2
    digits. My formula works on individual sublist but not the whole
    list.. I know my indexing is wrong, but don?t know how to fix it.
    
    
    > FF
    
    [[1]]
    [[1]][[1]]
    [[1]][[1]][[1]]
    [,1]    [,2]   [,3]    [,4] [,5]
    [1,] "30/20"   "AAAAAAAA" ?    ?   "-89"
    [2,] "02/20"   "AAAAAAAA? ?    ?   "-98"
    [3,] "02/20"   ?AAAAAAA? ?    ?   "-84"
    [4,] ?  ? ?  ?   ?
    [[1]][[1]][[2]]
    [,1]    [,2]
    [1,] "02/23" ?AAAAAAAA? : 29" ?
    [2,] "02/23" ?AAAAAAAA? ." ?
    [3,] "02/23" ?AAAAAAAA? " ?
    [4,] "02/23" ?AAAAAAAA? "
    [[1]][[1]][[3]]
    [,1]    [,2]    [,3] [,4] [,5] [,6] [,7]
    [1,] "01/09" ?AAAAAAAA"    ?   ?   ?   "53"
    [2,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "403"
    [3,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "83"
    [4,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "783"
    [5,] ?  ?  ?AAAAAAAA?  3042742181"   ?   ?   ?   ?
    [[1]][[2]]
    [[1]][[2]][[1]]
    [,1]  [,2] [,3] [,4] [,5]
    [1,] ?    ?   ?   ?   ?AAAAAAAA? "
    [2,] "Standard Purchases"  ?   ?   ?   "
    [3,] "24/90 "AAAAAAAA? ?   "243"  "
    [4,] "24/90 "AAAAAAAA? "   "143"  "
    [5,] "24/91 "AAAAAAAA? " ?   "143" ?
    [6,] ?    ?   ?   ?   "792"
    [[1]][[2]][[2]]
    [,1]    [,2]
    [1,] "02/23" ?AAAAAAAA?: 31" ?
    [2,] "02/23" ?AAAAAAAA?." ?
    [3,] "02/23" ?AAAAAAAA? " ?
    [4,] "02/23" ?AAAAAAAA?
    [5,] "02/23" ?AAAAAAAA?
    [6,] "02/23" ?AAAAAAAA? 20"
    [7,] "02/23" ?AAAAAAAA?  ?
    [8,] "02/23" ?AAAAAAAA? "33"
    [[1]][[3]]
    [[1]][[3]][[1]]
    [,1]    [,2]
    [1,] "02/23" ?AAAAAAAA?: 28" ?
    [2,] "02/23" ?AAAAAAAA?." ?
    [3,] "02/23" ?AAAAAAAA? " ?
    [4,] "02/23" ?AAAAAAAA? "
    [[1]][[3]][[2]]
    [,1]    [,2]    [,3]    [,4] [,5] [,6] [,7]    [,8]    [,9]
    [1,] "02/23" ?AAAAAAAA? " ?   ?   "53" "
    [2,] "02/24" ?AAAAAAAA? " ?   ?   "
    [3,] ?  ?  ?  ?   ?   ?   ?  ?  "1,241"
    [4,] "02/24" "AAAAAAAA?  ?   "33?
    
    My Formula,:
    
    G <- lapply(FF, function(x) lapply(x, function (y) lapply(y,
    function(z)  z[grepl("^[0-9][0-9]/",z[,1]),])))
    
    The error: Error in z[, 1] : incorrect number of dimensions
    
    
    
    Thanks in advance--EK
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From tg@|o|@ @end|ng |rom gm@||@com  Fri Nov  2 20:44:16 2018
From: tg@|o|@ @end|ng |rom gm@||@com (Evarite Galois)
Date: Fri, 2 Nov 2018 15:44:16 -0400
Subject: [R] Exact Poly-K Test
Message-ID: <CAGe3viMRe9KijSgOYaHhdqvW4fnFppzyKS=6NsdtzbFcommSwQ@mail.gmail.com>

Hello All,

I am looking for a package with an R implementation of the Exact Poly-K
Test; any feedback will be greatly appreciated.

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Fri Nov  2 21:13:41 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 2 Nov 2018 13:13:41 -0700
Subject: [R] Exact Poly-K Test
In-Reply-To: <CAGe3viMRe9KijSgOYaHhdqvW4fnFppzyKS=6NsdtzbFcommSwQ@mail.gmail.com>
References: <CAGe3viMRe9KijSgOYaHhdqvW4fnFppzyKS=6NsdtzbFcommSwQ@mail.gmail.com>
Message-ID: <CAGxFJbSL-be5S7u4ojQuS5piWVWCzFArhgo3FGvViSJo074m5w@mail.gmail.com>

A search on rseek.org on "exact poly-k test" brought up several hits. Did
you not try this? Are none of the hits suitable?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Nov 2, 2018 at 1:07 PM Evarite Galois <tgalois at gmail.com> wrote:

> Hello All,
>
> I am looking for a package with an R implementation of the Exact Poly-K
> Test; any feedback will be greatly appreciated.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Fri Nov  2 21:25:21 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 2 Nov 2018 13:25:21 -0700
Subject: [R] Exact Poly-K Test
In-Reply-To: <CAGxFJbSL-be5S7u4ojQuS5piWVWCzFArhgo3FGvViSJo074m5w@mail.gmail.com>
References: <CAGe3viMRe9KijSgOYaHhdqvW4fnFppzyKS=6NsdtzbFcommSwQ@mail.gmail.com>
 <CAGxFJbSL-be5S7u4ojQuS5piWVWCzFArhgo3FGvViSJo074m5w@mail.gmail.com>
Message-ID: <CAGxFJbTGp2xNCvf2nkxj5pdQ1sT9C0gi1CYeHT1fJAgKWhbqjw@mail.gmail.com>

Oh, and if you wish to fake a famous name for your signature, you should
get it right: it's ?variste Galois.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Nov 2, 2018 at 1:13 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> A search on rseek.org on "exact poly-k test" brought up several hits. Did
> you not try this? Are none of the hits suitable?
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Nov 2, 2018 at 1:07 PM Evarite Galois <tgalois at gmail.com> wrote:
>
>> Hello All,
>>
>> I am looking for a package with an R implementation of the Exact Poly-K
>> Test; any feedback will be greatly appreciated.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]



From m@|||p@dpo@t @end|ng |rom gm@||@com  Fri Nov  2 22:21:06 2018
From: m@|||p@dpo@t @end|ng |rom gm@||@com (post .)
Date: Sat, 3 Nov 2018 00:21:06 +0300
Subject: [R] cox model
Message-ID: <CAF-ms1o1HUw5UUTdSKZSrgH9zh2=Y31qf35jU-UkLrSw=ACYrg@mail.gmail.com>

I need a R-code for a situation that is well described in the sas help. I
would be very grateful for the help!
"Time-dependent variables can be used to model the effects of subjects
transferring from one treatment group to another. One example of the need
for such strategies is the Stanford heart transplant program. Patients are
accepted if physicians judge them suitable for heart transplant. Then, when
a donor becomes available, physicians choose transplant recipients
according to various medical criteria. A patient?s status can be changed
during the study from waiting for a transplant to being a transplant
recipient. Transplant status can be defined by the time-dependent covariate
function z=z(t) as:
z(t)= 0 (if the patient has not received the transplant at time t)
and 1 (if has received)


<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
???
???????. www.avast.ru
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]



From m@|||p@dpo@t @end|ng |rom gm@||@com  Fri Nov  2 22:24:17 2018
From: m@|||p@dpo@t @end|ng |rom gm@||@com (post .)
Date: Sat, 3 Nov 2018 00:24:17 +0300
Subject: [R] cox model
Message-ID: <CAF-ms1rX+2OWD_HbFsj_RAqqGK2TEk=Vhm4argFuQbgdebPqoA@mail.gmail.com>

I need a R-code for a situation that is well described in the sas help. I
would be very grateful for the help!
"Time-dependent variables can be used to model the effects of subjects
transferring from one treatment group to another. One example of the need
for such strategies is the Stanford heart transplant program. Patients are
accepted if physicians judge them suitable for heart transplant. Then, when
a donor becomes available, physicians choose transplant recipients
according to various medical criteria. A patient?s status can be changed
during the study from waiting for a transplant to being a transplant
recipient. Transplant status can be defined by the time-dependent covariate
function z=z(t) as:
z(t)= 0 (if the patient has not received the transplant at time t)
and 1 (if has received)

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
???
???????. www.avast.ru
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]



From |err|@|eber| @end|ng |rom gmx@@t  Sat Nov  3 10:43:14 2018
From: |err|@|eber| @end|ng |rom gmx@@t (Ferri Leberl)
Date: Sat, 3 Nov 2018 10:43:14 +0100
Subject: [R] rnaturalearth: detail by degrees
Message-ID: <trinity-581dd2a6-4338-4618-b05a-e98497cd8f21-1541238194073@3c-app-gmx-bs41>


Dear all,
I have the graph of a path, walking a number of places specified by name, logitude and latitude ? thanks to Don MacQueen.
xliam and ylim define a certain section of the earth.
How can I put this section of a political map into the background?
Thank you in advance.
Yours, Ferri
?



From robertob@kker @end|ng |rom gm@||@com  Sat Nov  3 14:06:59 2018
From: robertob@kker @end|ng |rom gm@||@com (P. Roberto Bakker)
Date: Sat, 3 Nov 2018 14:06:59 +0100
Subject: [R] Different stack barplots - same color legends
In-Reply-To: <CAGx1TMABVMuhWzqF=0G7R8KqRLNL=-H7u_XNjwsogPCeY09zjw@mail.gmail.com>
References: <CAKDq9_N16xaeL4O2j=v2bVuMb=tuHfu0Ao+yuLQcEq6B-ngq1A@mail.gmail.com>
 <af9001d319ac4992b0bfc5526150f03b@tamu.edu>
 <CAKDq9_P8hQEHWFH=c_86bG81fU0GS+EUCOmtZ9gJa_7kY-2uhA@mail.gmail.com>
 <CAGx1TMAYybconxY7ZVVJcdiYW6+WOjr_D+=GHOA=Xxv2AWRCqQ@mail.gmail.com>
 <CAKDq9_Oi0HGNV7qLnmi4HgVr7orF_gpC7Sys8mLKAxMfjHVtvQ@mail.gmail.com>
 <CAGx1TMB+=RnNeoBmzF=_-gxZ2bzaabExs2Gf-8dKE2vAcpiHpA@mail.gmail.com>
 <CAKDq9_P3GfHXbFbChQwrDUm=E+RuuWGP89tf_KPFXRjYAsrA+A@mail.gmail.com>
 <CAGx1TMByCiZvwOPm06qo4bssWjh=UP9ZPvkX5zi+6dNE=wggaA@mail.gmail.com>
 <CAKDq9_OkLfiP98cuYUg0BU_+cCXmKi9gKHqxSm+Eu16eC3WWyg@mail.gmail.com>
 <CAGx1TMCF8bg64+UOP9ULygHcRnna505RO+1WCWxWJuuFaNp4fQ@mail.gmail.com>
 <CAKDq9_OU8bNq4p8zLr45JADz=SWvGAhG+-ACqdu+qC4a+D8FUw@mail.gmail.com>
 <CAGx1TMABVMuhWzqF=0G7R8KqRLNL=-H7u_XNjwsogPCeY09zjw@mail.gmail.com>
Message-ID: <CAKDq9_NMVvo-xJuNMDeGno+TATNNmyOr=nExmNC1t6LMuNdz6Q@mail.gmail.com>

Dear Richard,

Thank you so much for all your work and time you punt in it.
I will start with your suggestions and let you know how far I come.
Also thanks to the others who helpt me.

Best Roberto

Op do 1 nov. 2018 om 23:42 schreef Richard M. Heiberger <rmh at temple.edu>:

> ## reminder on how the levels= argument to factor works
>
> mydata <- matrix(1:8,  nrow=4, ncol=2, dimnames=list(letters[1:4],
> LETTERS[1:2]))
> dput(mydata)
>
> Factor.wrong <- factor(c("mm", "cm", "m", "km"))
> levels(Factor.wrong) ## alphabetical order, not meaning order
>
> Factor.right <- factor(c("mm", "cm", "m", "km"),
>                        levels=c("mm", "cm", "m", "km"))
> levels(Factor.right) ## meaning order
>
>
>
> library(HH) ## for the likert function
>
> ## dput(teamq[1:10,7:8])
> teamq10x78 <-
> structure(list(`Ik volg bijscholing om mijn opleiders-kwaliteiten op
> peil te houden` = c("de situatie in hoge mate van toepassing is voor u
> of uw supervisorengroep",
> "de situatie in hoge mate van toepassing is voor u of uw
> supervisorengroep",
> "de situatie in zeer hoge mate van toepassing is voor u of uw
> supervisorengroep",
> "de situatie in zeer hoge mate van toepassing is voor u of uw
> supervisorengroep",
> "de situatie in geringe mate van toepassing is voor u of uw
> supervisorengroep",
> "de situatie enigszins van toepassing is voor u of uw supervisorengroep",
> "de situatie in zeer hoge mate van toepassing is voor u of uw
> supervisorengroep",
> "de situatie in hoge mate van toepassing is voor u of uw
> supervisorengroep",
> "de situatie in hoge mate van toepassing is voor u of uw
> supervisorengroep",
> "de situatie in zeer hoge mate van toepassing is voor u of uw
> supervisorengroep"
> ), `Ik weet precies wat de ?modernisering van de opleiding? inhoudt` =
> c("de situatie in hoge mate van toepassing is voor u of uw
> supervisorengroep",
> "de situatie in hoge mate van toepassing is voor u of uw
> supervisorengroep",
> "de situatie in zeer hoge mate van toepassing is voor u of uw
> supervisorengroep",
> "de situatie in zeer hoge mate van toepassing is voor u of uw
> supervisorengroep",
> "de situatie in geringe mate van toepassing is voor u of uw
> supervisorengroep",
> "de situatie enigszins van toepassing is voor u of uw supervisorengroep",
> "de situatie in geringe mate van toepassing is voor u of uw
> supervisorengroep",
> "de situatie in geringe mate van toepassing is voor u of uw
> supervisorengroep",
> "de situatie enigszins van toepassing is voor u of uw supervisorengroep",
> "de situatie in hoge mate van toepassing is voor u of uw supervisorengroep"
> )), row.names = c(NA, -10L), class = c("tbl_df", "tbl", "data.frame"
> ))
>
>
> ## This is from Google translate
>
> ## Ik weet precies wat de ?modernisering van de opleiding? inhoudt
> ## I know exactly what the "modernization of the training"
>
> ## Ik volg bijscholing om mijn opleiders-kwaliteiten op peil te houden
> ## I follow training to keep my grades at level trainers
>
>
> ## ## This is your order of levels from Mon, Oct 22, 2018 at 1:30 PM
> ## "de situatie in zeer geringe mate van toepassing is voor u of uw
> supervisorengroep"
> ## "de situatie in geringe mate van toepassing is voor u of uw
> supervisorengroep"
> ## "de situatie enigszins van toepassing is voor u of uw supervisorengroep"
> ## "de situatie in hoge mate van toepassing is voor u of uw
> supervisorengroep"
> ## "de situatie in zeer hoge mate van toepassing is voor u of uw
> supervisorengroep"
>
> ## ## This is from Google translate
> ## the situation very little applies to you or your group supervisor
> ## the situation slightly applies to you or your group supervisor
> ## the situation somewhat applies to you or your group supervisor
> ## the situation is highly applicable to you or your group supervisor
> ## the situation very largely applies to you or your group supervisor
>
>
>
> sapply(teamq10x78, table)
> likert(t(sapply(teamq10x78, table)))
> likert(t(sapply(teamq10x78, table)),
>        auto.key=list(columns=1, border=TRUE),
>        main="character values are sorted alphabetically, we will use
> factors in the next figure")
>
> object.size(teamq10x78)
> ## more rows
> object.size(rbind(teamq10x78,teamq10x78,teamq10x78,teamq10x78,teamq10x78,
>                   teamq10x78,teamq10x78,teamq10x78,teamq10x78,teamq10x78,
>                   teamq10x78,teamq10x78,teamq10x78,teamq10x78,teamq10x78,
>                   teamq10x78,teamq10x78,teamq10x78,teamq10x78,teamq10x78))
>
> situatie.levels <- c(
>   "de situatie in zeer geringe mate van toepassing is voor u of uw
> supervisorengroep",
>   "de situatie in geringe mate van toepassing is voor u of uw
> supervisorengroep",
>   "de situatie enigszins van toepassing is voor u of uw supervisorengroep",
>   "de situatie in hoge mate van toepassing is voor u of uw
> supervisorengroep",
>   "de situatie in zeer hoge mate van toepassing is voor u of uw
> supervisorengroep")
>
> teamf <- tibble::as.tibble(
>   lapply(teamq10x78,
>          function(x, levels) factor(x, levels=levels),
>          levels=situatie.levels)
> )
> names(teamf) <- names(teamq10x78) ## lapply replaced space and quote
> characters with "."
> ## and each column is a factor with properly ordered labels.
> sapply(teamf, class)
> sapply(teamf, levels) ## all five levels appear even though this
> example observed only four
>
> object.size(teamf) ## bigger here
> ## significantly smaller for more rows
> object.size(rbind(teamf,teamf,teamf,teamf,teamf,
>                   teamf,teamf,teamf,teamf,teamf,
>                   teamf,teamf,teamf,teamf,teamf,
>                   teamf,teamf,teamf,teamf,teamf))
>
> sapply(teamf, table) ## these are the counts of responses by question
>
> likert(t(sapply(teamf, table)),
>        auto.key=list(columns=1, border=TRUE),
>        main="the middle group enigszins is by default split equally
> between negative and positive")
>
> likert(t(sapply(teamf, table)),
>        auto.key=list(columns=1, border=TRUE),
>        main="based on your color scheme, I am putting enigszins on the
> negative side",
>        ReferenceZero=3.5,
>        col=c("yellow","sandybrown","orange", "darkolivegreen","green"))
>
>
> ## I am adding a third question with some "zeer geringe" values
>
> teamf[,"Extra Question"] <- teamf[,2]
> teamf[1:2, 3] <- situatie.levels[1]
>
> likert(t(sapply(teamf, table)),
>        auto.key=list(columns=1, border=TRUE),
>        main="based on your color scheme, I am putting enigszins on the
> negative side",
>        ReferenceZero=3.5,
>        col=c("yellow","sandybrown","orange", "darkolivegreen","green"))
>
>
> ## I find the color scheme unsatisfactory.
> ## The break point between sandybrown and orange is not distinct.
> ## I would prefer a darker green on the right side.
> ## try
> RColorBrewer::display.brewer.all()
> ## and see if sny of them work for you.
>
> display.brewer.pal(6, "RdYlGn")
>
> RYG5 <- brewer.pal(6, "RdYlGn")[-4]
>
> likert(t(sapply(teamf, table)),
>        auto.key=list(columns=1, border=TRUE),
>        main="based on your color scheme, I am putting enigszins on the
> negative side",
>        ReferenceZero=3.5,
>        col=RYG5)
>
>
>
> On Wed, Oct 31, 2018 at 5:56 PM, P. Roberto Bakker
> <robertobakker at gmail.com> wrote:
> > Hi Rich,
> >
> > Thank you for your answer.
> > The sentences are strings (likert scale: 'the situation is highly
> applicable
> > to me' etc - in Dutch), or column labels; it may be confusing as it is in
> > Dutch. Below I show you part of the dataframe with my annotation added
> > (string/column lable) to give you an idea.
> > I need to change the likert strings into numeric (1:5). And this is a
> > challenge somehow.
> > With dplyr, plyr it did not work.
> > After I have the numeric version then I can stack them as suggested by
> > David.
> >
> > PART OF THE DATAFRAME
> >>> >>>> >   `Ik volg bijscholing om mijn opleiders-kwaliteiten op peil te
> >>> >>>> > houden` COLUMN LABEL
> >>> >>>> >
> >>> >>>> >   <chr>
> >>> >>>> >
> >>> >>>> > 1 de situatie in hoge mate van toepassing is voor u of uw
> >>> >>>> > supervisorengroep LIKERT STRING
> >>> >>>> > 2 de situatie in zeer hoge mate van toepassing is voor u of uw
> >>> >>>> > supervisorengroep LIKERT STRING
> >>> >>>> > 3 de situatie in zeer hoge mate van toepassing is voor u of uw
> >>> >>>> > supervisorengroep LIKERT STRING
> >>> >>>> > 4 de situatie in geringe mate van toepassing is voor u of uw
> >>> >>>> > supervisorengroep LIKERT STRING
> >>> >>>> >   `Ik weet precies wat de ?modernisering van de opleiding?
> >>> >>>> > inhoudt` COLUMN LABEL
> >>> >>>> >
> >>> >>>> >   <chr>
> >>> >>>> >
> >>> >>>> > 1 de situatie in hoge mate van toepassing is voor u of uw
> >>> >>>> > supervisorengroep LIKERT STRING
> >>> >>>> > 2 de situatie in zeer hoge mate van toepassing is voor u of uw
> >>> >>>> > supervisorengroep LIKERT STRING
> >>> >>>> > 3 de situatie in zeer hoge mate van toepassing is voor u of uw
> >>> >>>> > supervisorengroep LIKERT STRING
> >>> >>>> > 4 de situatie in geringe mate van toepassing is voor u of uw
> >>> >>>> > supervisorengroep LIKERT STRING
> >
> >
> >
> > Op wo 31 okt. 2018 om 20:28 schreef Richard M. Heiberger <rmh at temple.edu
> >:
> >>
> >> What you sent looks like a set of column labels, not the actual numeric
> >> data.
> >>
> >> You might want to convert them to factors where you control the order
> >> of the levels.
> >> > Factor.wrong <- factor(c("mm", "cm", "m", "km"))
> >> > levels(Factor.wrong) ## alphabetical order, not meaning order
> >> [1] "cm" "km" "m"  "mm"
> >> >
> >> > Factor.right <- factor(c("mm", "cm", "m", "km"),
> >> +                        levels=c("mm", "cm", "m", "km"))
> >> > levels(Factor.right) ## meaning order
> >> [1] "mm" "cm" "m"  "km"
> >>
> >> Or you might want to construct a matrix of counts of your data and plot
> >> that.
> >>
> >> Rich
> >>
> >>
> >> On Wed, Oct 31, 2018 at 1:53 PM, P. Roberto Bakker
> >> <robertobakker at gmail.com> wrote:
> >> > This is part of the output text
> >> >
> >> > "de situatie in hoge mate van toepassing is voor u of uw
> >> > supervisorengroep", STRING
> >> > "de situatie in hoge mate van toepassing is voor u of uw
> >> > supervisorengroep", STRING
> >> > "de situatie enigszins van toepassing is voor u of uw
> >> > supervisorengroep", STRING
> >> > "de situatie in hoge mate van toepassing is voor u of uw
> >> > supervisorengroep" STRINK
> >> > ), `Ik waardeer de inbreng van de aios in de afdelingsvergadering`
> >> > COLUMN LABEL= c("de
> >> > situatie in hoge mate van toepassing is voor u of uw
> supervisorengroep",
> >> > STRING
> >>
> >> > "de situatie in hoge mate van toepassing is voor u of uw
> >> > supervisorengroep",
> >> > "de situatie in zeer hoge mate van toepassing is voor u of uw
> >> > supervisorengroep",
> >> > "de situatie in zeer hoge mate van toepassing is voor u of uw
> >> > supervisorengroep",
> >> > "de situatie enigszins van toepassing is voor u of uw
> >> > supervisorengroep",
> >> > "de situatie in zeer hoge mate van toepassing is voor u of uw
> >> > supervisorengroep",
> >> > "de situatie in zeer hoge mate van toepassing is voor u of uw
> >> > supervisorengroep",
> >> > "de situatie in zeer hoge mate van toepassing is voor u of uw
> >> > supervisorengroep",
> >> > "de situatie enigszins van toepassing is voor u of uw
> >> > supervisorengroep",
> >> > "de situatie in hoge mate van toepassing is voor u of uw
> >> > supervisorengroep",
> >> > "de situatie in hoge mate van toepassing is voor u of uw
> >> > supervisorengroep",
> >> > "de situatie in hoge mate van toepassing is voor u of uw
> >> > supervisorengroep",
> >> >
> >> > Op wo 31 okt. 2018 om 16:24 schreef Richard M. Heiberger
> >> > <rmh at temple.edu>:
> >> >>
> >> >> part is fine.  just be sure that the small part causes the problem.
> >> >> I will need that to investigate what is happening.
> >> >>
> >> >>
> >> >> On Wed, Oct 31, 2018 at 11:15 AM, P. Roberto Bakker
> >> >> <robertobakker at gmail.com> wrote:
> >> >> > It is a very long result text. I can send it to you, or is part of
> it
> >> >> > ok?[
> >> >> >
> >> >> > Op wo 31 okt. 2018 om 14:27 schreef Richard M. Heiberger
> >> >> > <rmh at temple.edu>:
> >> >> >>
> >> >> >> Please send me the
> >> >> >> dput(teamq)
> >> >> >>
> >> >> >>
> >> >> >> On Wed, Oct 31, 2018 at 03:51 P. Roberto Bakker
> >> >> >> <robertobakker at gmail.com>
> >> >> >> wrote:
> >> >> >>>
> >> >> >>> Thank you for you information. Package 'HH' is interesting.
> >> >> >>>
> >> >> >>> Now I find another problem when using 'likert(teamq)'
> >> >> >>> I get an error message:
> >> >> >>> > likert(teamq)
> >> >> >>> Error in dimnames(x) <- `*vtmp*` :
> >> >> >>>   length of 'dimnames' [2] not equal to array extent
> >> >> >>>
> >> >> >>> I checked:
> >> >> >>> > dim(teamq)
> >> >> >>> [1] 4 2
> >> >> >>> > ncol(teamq)
> >> >> >>> [1] 2
> >> >> >>> So it should be good.
> >> >> >>>
> >> >> >>> I used 'make.names' , in case the spaces in the variable names
> >> >> >>> would
> >> >> >>> be a
> >> >> >>> problem.
> >> >> >>> Same error.
> >> >> >>>
> >> >> >>> What could I do?
> >> >> >>>
> >> >> >>> Best and thank you in advance.
> >> >> >>> Roberto
> >> >> >>>
> >> >> >>>
> >> >> >>> Op ma 22 okt. 2018 om 20:10 schreef Richard M. Heiberger
> >> >> >>> <rmh at temple.edu>:
> >> >> >>>>
> >> >> >>>> Try the likert function in
> >> >> >>>> install.packages("HH) ## if necessary
> >> >> >>>> library(HH)
> >> >> >>>>
> >> >> >>>> Then using David Carlson's example teamq
> >> >> >>>> likert(teamq)
> >> >> >>>>
> >> >> >>>> Your example in the 1:30PM (Eastern Daylight Time) doesn't work.
> >> >> >>>> Error in revalue(teamq, c(`de situatie in zeer geringe mate van
> >> >> >>>> toepassing is\nvoor u of uw supervisorengroep` = "1",  :
> >> >> >>>>   x is not a factor or a character vector.
> >> >> >>>>
> >> >> >>>> There are many examples in
> >> >> >>>> ?likert
> >> >> >>>>
> >> >> >>>> Rich
> >> >> >>>>
> >> >> >>>>
> >> >> >>>> On Mon, Oct 22, 2018 at 1:30 PM, P. Roberto Bakker
> >> >> >>>> <robertobakker at gmail.com> wrote:
> >> >> >>>> > Dear David,
> >> >> >>>> >
> >> >> >>>> > Thank you for you quite response.
> >> >> >>>> > My apologies for not giving some sample data - this is due to
> >> >> >>>> > AVG.
> >> >> >>>> > *But this minisample should not be a problem (all in Dutch)*:
> >> >> >>>> >  teamq
> >> >> >>>> > # A tibble: 4 x 2
> >> >> >>>> >   `Ik volg bijscholing om mijn opleiders-kwaliteiten op peil
> te
> >> >> >>>> > houden`
> >> >> >>>> >
> >> >> >>>> >   <chr>
> >> >> >>>> >
> >> >> >>>> > 1 de situatie in hoge mate van toepassing is voor u of uw
> >> >> >>>> > supervisorengroep
> >> >> >>>> > 2 de situatie in zeer hoge mate van toepassing is voor u of uw
> >> >> >>>> > supervisorengroep
> >> >> >>>> > 3 de situatie in zeer hoge mate van toepassing is voor u of uw
> >> >> >>>> > supervisorengroep
> >> >> >>>> > 4 de situatie in geringe mate van toepassing is voor u of uw
> >> >> >>>> > supervisorengroep
> >> >> >>>> >   `Ik weet precies wat de ?modernisering van de opleiding?
> >> >> >>>> > inhoudt`
> >> >> >>>> >
> >> >> >>>> >   <chr>
> >> >> >>>> >
> >> >> >>>> > 1 de situatie in hoge mate van toepassing is voor u of uw
> >> >> >>>> > supervisorengroep
> >> >> >>>> > 2 de situatie in zeer hoge mate van toepassing is voor u of uw
> >> >> >>>> > supervisorengroep
> >> >> >>>> > 3 de situatie in zeer hoge mate van toepassing is voor u of uw
> >> >> >>>> > supervisorengroep
> >> >> >>>> > 4 de situatie in geringe mate van toepassing is voor u of uw
> >> >> >>>> > supervisorengroep
> >> >> >>>> >
> >> >> >>>> > As you see the likert items are in words, and I should change
> >> >> >>>> > them
> >> >> >>>> > in
> >> >> >>>> > nummeric - Am I correct?
> >> >> >>>> >
> >> >> >>>> > *To do this, I tried (see further below):*
> >> >> >>>> > plyr rename() ; I receive the message it should be a factor or
> >> >> >>>> > character
> >> >> >>>> > dplyr recode() ; same message
> >> >> >>>> > mapvalues() ; it should be atomic, so I used as.atomic(teamq)
> >> >> >>>> > but
> >> >> >>>> > then
> >> >> >>>> > I
> >> >> >>>> > receive the nummers a strings.
> >> >> >>>> >
> >> >> >>>> > *The syntaxes*
> >> >> >>>> > require(plyr)
> >> >> >>>> > example2 <- revalue(teamq,
> >> >> >>>> >                     c("de situatie in zeer geringe mate van
> >> >> >>>> > toepassing
> >> >> >>>> > is
> >> >> >>>> > voor u of uw supervisorengroep"= "1",
> >> >> >>>> >                         "de situatie in geringe mate van
> >> >> >>>> > toepassing
> >> >> >>>> > is
> >> >> >>>> > voor
> >> >> >>>> > u of uw supervisorengroep"= "2",
> >> >> >>>> >                         "de situatie enigszins van toepassing
> is
> >> >> >>>> > voor
> >> >> >>>> > u of
> >> >> >>>> > uw supervisorengroep"= "3",
> >> >> >>>> >                         "de situatie in hoge mate van
> toepassing
> >> >> >>>> > is
> >> >> >>>> > voor u
> >> >> >>>> > of uw supervisorengroep"= "4",
> >> >> >>>> >                         "de situatie in zeer hoge mate van
> >> >> >>>> > toepassing
> >> >> >>>> > is
> >> >> >>>> > voor u of uw supervisorengroep"= "5"))
> >> >> >>>> >
> >> >> >>>> > require(dplyr)
> >> >> >>>> > example2 <- recode(teamq,
> >> >> >>>> >                     c("de situatie in zeer geringe mate van
> >> >> >>>> > toepassing
> >> >> >>>> > is
> >> >> >>>> > voor u of uw supervisorengroep"= "1",
> >> >> >>>> >                       "de situatie in geringe mate van
> >> >> >>>> > toepassing
> >> >> >>>> > is
> >> >> >>>> > voor u
> >> >> >>>> > of uw supervisorengroep"= "2",
> >> >> >>>> >                       "de situatie enigszins van toepassing is
> >> >> >>>> > voor
> >> >> >>>> > u
> >> >> >>>> > of uw
> >> >> >>>> > supervisorengroep"= "3",
> >> >> >>>> >                       "de situatie in hoge mate van toepassing
> >> >> >>>> > is
> >> >> >>>> > voor
> >> >> >>>> > u of
> >> >> >>>> > uw supervisorengroep"= "4",
> >> >> >>>> >                       "de situatie in zeer hoge mate van
> >> >> >>>> > toepassing
> >> >> >>>> > is
> >> >> >>>> > voor
> >> >> >>>> > u of uw supervisorengroep"= "5"))
> >> >> >>>> >
> >> >> >>>> > mapvalues(as.matrix(teamq), from = c("de situatie in zeer
> >> >> >>>> > geringe
> >> >> >>>> > mate
> >> >> >>>> > van
> >> >> >>>> > toepassing is voor u of uw supervisorengroep",
> >> >> >>>> >                         "de situatie in geringe mate van
> >> >> >>>> > toepassing
> >> >> >>>> > is
> >> >> >>>> > voor
> >> >> >>>> > u of uw supervisorengroep",
> >> >> >>>> >                         "de situatie enigszins van toepassing
> is
> >> >> >>>> > voor
> >> >> >>>> > u of
> >> >> >>>> > uw supervisorengroep",
> >> >> >>>> >                         "de situatie in hoge mate van
> toepassing
> >> >> >>>> > is
> >> >> >>>> > voor u
> >> >> >>>> > of uw supervisorengroep",
> >> >> >>>> >                         "de situatie in zeer hoge mate van
> >> >> >>>> > toepassing
> >> >> >>>> > is
> >> >> >>>> > voor u of uw supervisorengroep"),
> >> >> >>>> >           to = c(1,2,3,4,5))
> >> >> >>>> >
> >> >> >>>> > What should I do?
> >> >> >>>> > Thank you in advance, Roberto
> >> >> >>>> >
> >> >> >>>> > Op ma 22 okt. 2018 om 17:13 schreef David L Carlson
> >> >> >>>> > <dcarlson at tamu.edu>:
> >> >> >>>> >
> >> >> >>>> >> Your example is not reproducible since you did not give us
> some
> >> >> >>>> >> sample
> >> >> >>>> >> data. I suspect that your data frame consists of columns that
> >> >> >>>> >> represent
> >> >> >>>> >> questions and rows that represent individuals who answered
> the
> >> >> >>>> >> questions.
> >> >> >>>> >> First create a simple example:
> >> >> >>>> >>
> >> >> >>>> >> set.seed(42)
> >> >> >>>> >> teamq <- data.frame(V1=sample(c(1, 2, 4, 5), 25, replace =
> >> >> >>>> >> TRUE),
> >> >> >>>> >>      V2=sample(c(1, 2, 3, 4, 5), 25, replace=TRUE),
> >> >> >>>> >>      V3=sample(c(2, 3, 4, 5), 25, replace=TRUE))
> >> >> >>>> >>
> >> >> >>>> >> Notice that this data frame ONLY contains questions (and
> only 3
> >> >> >>>> >> questions). Here are 2 ways to get what you want. The first
> one
> >> >> >>>> >> stacks the
> >> >> >>>> >> data:
> >> >> >>>> >>
> >> >> >>>> >> teamq.stack <- stack(teamq)
> >> >> >>>> >> str(teamq.stack)
> >> >> >>>> >> counts <- table(teamq.stack)
> >> >> >>>> >> str(counts)
> >> >> >>>> >>
> >> >> >>>> >> The second one converts each column to a factor with levels
> 1 -
> >> >> >>>> >> 5:
> >> >> >>>> >>
> >> >> >>>> >> teamq2 <- data.frame(lapply(teamq, factor, levels=1:5))
> >> >> >>>> >> str(teamq2)
> >> >> >>>> >> counts <- sapply(teamq2, table)
> >> >> >>>> >> str(counts)
> >> >> >>>> >>
> >> >> >>>> >> Now make the plots:
> >> >> >>>> >>
> >> >> >>>> >> cols <- c("yellow","sandybrown","orange",
> >> >> >>>> >> "darkolivegreen","green")
> >> >> >>>> >> barplot(counts[, 1], horiz=TRUE, col=cols, legend=TRUE)
> >> >> >>>> >> barplot(counts[, 2], horiz=TRUE, col=cols, legend=TRUE)
> >> >> >>>> >> barplot(counts[, 3], horiz=TRUE, col=cols, legend=TRUE)
> >> >> >>>> >>
> >> >> >>>> >> You will need to adjust the xlim= argument so that the legend
> >> >> >>>> >> does
> >> >> >>>> >> not
> >> >> >>>> >> print on top of the bars.
> >> >> >>>> >>
> >> >> >>>> >> ----------------------------------------
> >> >> >>>> >> David L Carlson
> >> >> >>>> >> Department of Anthropology
> >> >> >>>> >> Texas A&M University
> >> >> >>>> >> College Station, TX 77843-4352
> >> >> >>>> >>
> >> >> >>>> >>
> >> >> >>>> >> -----Original Message-----
> >> >> >>>> >> From: R-help <r-help-bounces at r-project.org> On Behalf Of P.
> >> >> >>>> >> Roberto
> >> >> >>>> >> Bakker
> >> >> >>>> >> Sent: Monday, October 22, 2018 9:04 AM
> >> >> >>>> >> To: R mailing list <r-help at r-project.org>
> >> >> >>>> >> Subject: [R] Different stack barplots - same color legends
> >> >> >>>> >>
> >> >> >>>> >> Hi,
> >> >> >>>> >>
> >> >> >>>> >> I want to make barplots from different questions (columns) in
> >> >> >>>> >> one
> >> >> >>>> >> data.frame.
> >> >> >>>> >> Each question has the same 5 likert items.
> >> >> >>>> >> Now the problem: in some questions all items are answered; in
> >> >> >>>> >> other
> >> >> >>>> >> less.
> >> >> >>>> >> From the syntax below I get nice stack barplots - *but the
> >> >> >>>> >> legend
> >> >> >>>> >> colors do
> >> >> >>>> >> not* refer to the same likert-item, which I understand - the
> >> >> >>>> >> colors
> >> >> >>>> >> go in
> >> >> >>>> >> sequence along the table.
> >> >> >>>> >> Question: how can I write a syntax that each likert-item has
> >> >> >>>> >> the
> >> >> >>>> >> same
> >> >> >>>> >> legend color?
> >> >> >>>> >> Thank you in advance,
> >> >> >>>> >>
> >> >> >>>> >> Roberto
> >> >> >>>> >>
> >> >> >>>> >> SYNTAX:
> >> >> >>>> >> counts19 <- table(teamq[,19])
> >> >> >>>> >> counts20 <- table(teamq[,20])
> >> >> >>>> >> barplot(as.matrix(counts19), horiz = T,
> >> >> >>>> >>         col=c("yellow","sandybrown","orange",
> >> >> >>>> >> "darkolivegreen","green"),
> >> >> >>>> >> legend=T)
> >> >> >>>> >> barplot(as.matrix(counts20), horiz = T,
> >> >> >>>> >>         col=c("yellow","sandybrown","orange",
> >> >> >>>> >> "darkolivegreen","green"),
> >> >> >>>> >> legend=T)
> >> >> >>>> >>
> >> >> >>>> >>         [[alternative HTML version deleted]]
> >> >> >>>> >>
> >> >> >>>> >> ______________________________________________
> >> >> >>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> more,
> >> >> >>>> >> see
> >> >> >>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >>>> >> PLEASE do read the posting guide
> >> >> >>>> >> http://www.R-project.org/posting-guide.html
> >> >> >>>> >> and provide commented, minimal, self-contained, reproducible
> >> >> >>>> >> code.
> >> >> >>>> >>
> >> >> >>>> >
> >> >> >>>> >         [[alternative HTML version deleted]]
> >> >> >>>> >
> >> >> >>>> > ______________________________________________
> >> >> >>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >> >> >>>> > see
> >> >> >>>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >>>> > PLEASE do read the posting guide
> >> >> >>>> > http://www.R-project.org/posting-guide.html
> >> >> >>>> > and provide commented, minimal, self-contained, reproducible
> >> >> >>>> > code.
>

	[[alternative HTML version deleted]]



From robertob@kker @end|ng |rom gm@||@com  Sat Nov  3 14:08:03 2018
From: robertob@kker @end|ng |rom gm@||@com (P. Roberto Bakker)
Date: Sat, 3 Nov 2018 14:08:03 +0100
Subject: [R] Different stack barplots - same color legends
In-Reply-To: <CA+8X3fXCOPecub-SzuXcp2r4sxQz9TVp2Tr6V_RM2FaX3=5BmA@mail.gmail.com>
References: <CAKDq9_N16xaeL4O2j=v2bVuMb=tuHfu0Ao+yuLQcEq6B-ngq1A@mail.gmail.com>
 <af9001d319ac4992b0bfc5526150f03b@tamu.edu>
 <CAKDq9_P8hQEHWFH=c_86bG81fU0GS+EUCOmtZ9gJa_7kY-2uhA@mail.gmail.com>
 <CAGx1TMAYybconxY7ZVVJcdiYW6+WOjr_D+=GHOA=Xxv2AWRCqQ@mail.gmail.com>
 <CAKDq9_Oi0HGNV7qLnmi4HgVr7orF_gpC7Sys8mLKAxMfjHVtvQ@mail.gmail.com>
 <CAGx1TMB+=RnNeoBmzF=_-gxZ2bzaabExs2Gf-8dKE2vAcpiHpA@mail.gmail.com>
 <CAKDq9_P3GfHXbFbChQwrDUm=E+RuuWGP89tf_KPFXRjYAsrA+A@mail.gmail.com>
 <CAGx1TMByCiZvwOPm06qo4bssWjh=UP9ZPvkX5zi+6dNE=wggaA@mail.gmail.com>
 <CAKDq9_OkLfiP98cuYUg0BU_+cCXmKi9gKHqxSm+Eu16eC3WWyg@mail.gmail.com>
 <CAGx1TMCF8bg64+UOP9ULygHcRnna505RO+1WCWxWJuuFaNp4fQ@mail.gmail.com>
 <CAKDq9_OU8bNq4p8zLr45JADz=SWvGAhG+-ACqdu+qC4a+D8FUw@mail.gmail.com>
 <CA+8X3fXCOPecub-SzuXcp2r4sxQz9TVp2Tr6V_RM2FaX3=5BmA@mail.gmail.com>
Message-ID: <CAKDq9_OPXpTEDznyfH2aSY6zofhPUiQM8-MpY9A7ETGn3MH6hQ@mail.gmail.com>

Thank you

Op do 1 nov. 2018 om 00:25 schreef Jim Lemon <drjimlemon at gmail.com>:

> Hi Roberto,
> Here is a snippet of code that translates the text responses of the
> BIS-11 into numeric values. Note the reversal of the order in the
> second item:
>
> BIS$Q1<-as.numeric(factor(BIS$Q1,
>  levels=c("Almost","Often","Occasionally","Rarely/Never")))
> BIS$Q2<-as.numeric(factor(BIS$Q2,
>  levels=c("Rarely/Never","Occasionally","Often","Almost")))
> ...
>
> Jim
> On Thu, Nov 1, 2018 at 8:57 AM P. Roberto Bakker
> <robertobakker at gmail.com> wrote:
> >
> > Hi Rich,
> >
> > Thank you for your answer.
> > The sentences are strings (likert scale: 'the situation is highly
> > applicable to me' etc - in Dutch), or column labels; it may be confusing
> as
> > it is in Dutch. Below I show you part of the dataframe with my annotation
> > added (string/column lable) to give you an idea.
> > I need to change the likert strings into numeric (1:5). And this is a
> > challenge somehow.
> > With dplyr, plyr it did not work.
> > After I have the numeric version then I can stack them as suggested by
> > David.
> >
>

	[[alternative HTML version deleted]]



From ok@n@k@t|pog|u @end|ng |rom @t@un|@edu@tr  Sat Nov  3 11:48:23 2018
From: ok@n@k@t|pog|u @end|ng |rom @t@un|@edu@tr (Okan Mert Katipoglu)
Date: Sat, 3 Nov 2018 13:48:23 +0300 (MSK)
Subject: [R] spi package
Message-ID: <1312544585.24817174.1541242103746.JavaMail.zimbra@atauni.edu.tr>

 
  Hi,Can I get information about following spi error,

  spi(1,"tercanspi.txt",1966,2017)

  spi(9,"tercanspi.txt",1966,2017,"Tercan Standart Ya??? ?ndeksi",2,"Y?llar","Aylar")

  spi(12,"tercanspi.txt",1966,2017,"Tercan Standart Ya??? ?ndeksi",2,"Y?llar","Aylar")

  spi(24,"tercanspi.txt",1966,2017,"Tercan Standart Ya??? ?ndeksi",2,"Y?llar","Aylar")
  
  how do I run these commands.
   
  Thanks so much.
Bu e-posta mesaji ve ekleri sadece gonderildigi kisi veya kuruma ozeldir. Mesajin alicisi siz degilseniz, bu mesajin yonlendirilmesi, kopyalanmasi veya herhangi bir sekilde kullanilmasi yasaktir.Mesaj iceriginde bulunan fikir ve yorumlar, sadece gondericiye aittir. Bu mesaj bilinen tum viruslere karsi taranmistir.

This e-mail and any files transmitted with it are confid...{{dropped:2}}



From @@r@h@go@|ee @end|ng |rom gm@||@com  Sat Nov  3 16:20:33 2018
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Sat, 3 Nov 2018 11:20:33 -0400
Subject: [R] spi package
In-Reply-To: <1312544585.24817174.1541242103746.JavaMail.zimbra@atauni.edu.tr>
References: <1312544585.24817174.1541242103746.JavaMail.zimbra@atauni.edu.tr>
Message-ID: <CAM_vjunSfDox+hzNZrDvp5FzL3V9g3aV91XXLPrK0yJjR5rg0A@mail.gmail.com>

It would help a lot if you actually told us what your error was.

Based on ?spi::spi your command looks correct, so we need more information.

Sarah
On Sat, Nov 3, 2018 at 10:02 AM Okan Mert Katipoglu
<okan.katipoglu at atauni.edu.tr> wrote:
>
>
>   Hi,Can I get information about following spi error,
>
>   spi(1,"tercanspi.txt",1966,2017)
>
>   spi(9,"tercanspi.txt",1966,2017,"Tercan Standart Ya??? ?ndeksi",2,"Y?llar","Aylar")
>
>   spi(12,"tercanspi.txt",1966,2017,"Tercan Standart Ya??? ?ndeksi",2,"Y?llar","Aylar")
>
>   spi(24,"tercanspi.txt",1966,2017,"Tercan Standart Ya??? ?ndeksi",2,"Y?llar","Aylar")
>
>   how do I run these commands.
>
>   Thanks so much.

-- 
Sarah Goslee (she/her)
http://www.numberwright.com



From |r@|nj @end|ng |rom gm@||@com  Sat Nov  3 17:53:16 2018
From: |r@|nj @end|ng |rom gm@||@com (John C Frain)
Date: Sat, 3 Nov 2018 16:53:16 +0000
Subject: [R] Granger causality: lag selection
In-Reply-To: <CABcx46C2DCjXEBN_Mmx3vuvBzZ8Bj2fTsizV+f4cqLvZEXk3mg@mail.gmail.com>
References: <CABcx46C2DCjXEBN_Mmx3vuvBzZ8Bj2fTsizV+f4cqLvZEXk3mg@mail.gmail.com>
Message-ID: <CAHrK517c7EED6J9wdy5AEkKnsCrjThkU-4pyO=v2bpU1Bsuk6A@mail.gmail.com>

This is probably a question about econometric methods rather than one about
R,  While I would probably use an information criterion this would only be
my first step in determining an appropriate lag length.  One needs to check
1. The whiteness of the residuals
2. Non-normality and
3. Structural Change.
One then may need to amend the selected lag to take account of any problems
that are revealed by the relevant tests.  Only when you are satisfied that
your model is correct you should proceed with your  causality tests.
These matters are well covered in texts such as Lutkepohl (2005), New
introduction to multiple time series analysis, Springer (see Chapter 4)

Looking at the example you quote I might say that the automatic first
differencing of I(1) series and doing granger causality tests on the
differenced series is not a valid option if there is cointegration.  When
there is cointegration the usual test statistics do not have the standard
distributions.  This is covered in section 6.6 and chapter 7 of Lutkepohl's
book.
John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com


On Fri, 2 Nov 2018 at 09:00, John <miaojpm at gmail.com> wrote:

> Hi,
>
>    I see an R user chooses the lag of Granger causality by finding out the
> lag for the most significant result
>    https://www.r-bloggers.com/granger-causality-test/
>
>    Is it generally legitimate to do so, without determining the lag first
> by AIC or BIC?
>
>    Thanks,
>
> John
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m@|||p@dpo@t @end|ng |rom gm@||@com  Sat Nov  3 20:51:23 2018
From: m@|||p@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Sat, 3 Nov 2018 22:51:23 +0300
Subject: [R] cox model
Message-ID: <CAF-ms1p9weyiF0GNsbUtDRvpAtwgszhEoF9R85Q4CkokBbXBxg@mail.gmail.com>

I need a R-code for a situation that is well described in the sas help. I
would be very grateful for the help!
"Time-dependent variables can be used to model the effects of subjects
transferring from one treatment group to another. One example of the need
for such strategies is the Stanford heart transplant program. Patients are
accepted if physicians judge them suitable for heart transplant. Then, when
a donor becomes available, physicians choose transplant recipients
according to various medical criteria. A patient?s status can be changed
during the study from waiting for a transplant to being a transplant
recipient. Transplant status can be defined by the time-dependent covariate
function z=z(t) as:
z(t)= 0 (if the patient has not received the transplant at time t)
and 1 (if has received)



From |@r@4884 @end|ng |rom gm@||@com  Sat Nov  3 20:59:58 2018
From: |@r@4884 @end|ng |rom gm@||@com (Israel Ortiz)
Date: Sat, 3 Nov 2018 13:59:58 -0600
Subject: [R] Predict follow up time using parametric model in r
Message-ID: <CAMESY2jmYNeWjdjFFH5sNYD1mEuSi5uUh9grus=4Laem70jwyg@mail.gmail.com>

I am trying to predict follow-up time using several survival models, both
parametric and semi-parametric. I achieve it for semi parametric models
using predict.coxph function in R from survival package using type =
"expected" as indicated in help. However, for parametric models, this
option doesn't exist for the predict.survreg function. Is there any other
option? Maybe using rms package?

	[[alternative HTML version deleted]]



From dw|n@em|u@ @end|ng |rom comc@@t@net  Sat Nov  3 21:20:30 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 3 Nov 2018 13:20:30 -0700
Subject: [R] cox model
In-Reply-To: <CAF-ms1p9weyiF0GNsbUtDRvpAtwgszhEoF9R85Q4CkokBbXBxg@mail.gmail.com>
References: <CAF-ms1p9weyiF0GNsbUtDRvpAtwgszhEoF9R85Q4CkokBbXBxg@mail.gmail.com>
Message-ID: <8d380c82-e985-850e-5900-b2515f47abd7@comcast.net>

It's also "well described" in the help materials for the obvious 
recommended package that ships with every copy of R. My copy sits at 
http://127.0.0.1:29434/library/survival/doc/timedep.pdf. Therneau's S 
package was first ported to R by Thomas Lumley and later Therneau took 
over maintenance.

-- 

David.

On 11/3/18 12:51 PM, Medic wrote:
> I need a R-code for a situation that is well described in the sas help. I
> would be very grateful for the help!
> "Time-dependent variables can be used to model the effects of subjects
> transferring from one treatment group to another. One example of the need
> for such strategies is the Stanford heart transplant program. Patients are
> accepted if physicians judge them suitable for heart transplant. Then, when
> a donor becomes available, physicians choose transplant recipients
> according to various medical criteria. A patient?s status can be changed
> during the study from waiting for a transplant to being a transplant
> recipient. Transplant status can be defined by the time-dependent covariate
> function z=z(t) as:
> z(t)= 0 (if the patient has not received the transplant at time t)
> and 1 (if has received)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Nov  3 21:26:22 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 03 Nov 2018 13:26:22 -0700
Subject: [R] cox model
In-Reply-To: <CAF-ms1p9weyiF0GNsbUtDRvpAtwgszhEoF9R85Q4CkokBbXBxg@mail.gmail.com>
References: <CAF-ms1p9weyiF0GNsbUtDRvpAtwgszhEoF9R85Q4CkokBbXBxg@mail.gmail.com>
Message-ID: <0A2D1180-6194-4793-B21B-1D5E21DA430C@dcn.davis.ca.us>

Stop re-posting this question.  It only irritates people... it does not improve your chances of getting help.

What does improve your chances is reading the Posting Guide and following the advice given there. Your question amounts to asking someone to figure out what theory you should apply to a problem domain... which is not really on topic here, though someone might recommend something to you anyway.

The better strategy would be to seek out (elsewhere) what textbook/papers you want to apply (SAS should suggest references if they claim to implement solutions) and then use Google or rseek.org to find contributed packages that implement some or all of the steps in that approach. You can also peruse the Task Views on CRAN. When you get error messages trying to apply those tools in R, ask here how to resolve those problems, since this list is about the language not your problem domain.

On November 3, 2018 12:51:23 PM PDT, Medic <mailipadpost at gmail.com> wrote:
>I need a R-code for a situation that is well described in the sas help.
>I
>would be very grateful for the help!
>"Time-dependent variables can be used to model the effects of subjects
>transferring from one treatment group to another. One example of the
>need
>for such strategies is the Stanford heart transplant program. Patients
>are
>accepted if physicians judge them suitable for heart transplant. Then,
>when
>a donor becomes available, physicians choose transplant recipients
>according to various medical criteria. A patient?s status can be
>changed
>during the study from waiting for a transplant to being a transplant
>recipient. Transplant status can be defined by the time-dependent
>covariate
>function z=z(t) as:
>z(t)= 0 (if the patient has not received the transplant at time t)
>and 1 (if has received)
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From dw|n@em|u@ @end|ng |rom comc@@t@net  Sat Nov  3 21:33:37 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 3 Nov 2018 13:33:37 -0700
Subject: [R] Predict follow up time using parametric model in r
In-Reply-To: <CAMESY2jmYNeWjdjFFH5sNYD1mEuSi5uUh9grus=4Laem70jwyg@mail.gmail.com>
References: <CAMESY2jmYNeWjdjFFH5sNYD1mEuSi5uUh9grus=4Laem70jwyg@mail.gmail.com>
Message-ID: <7f6f1ee2-0ac0-0443-3724-5d925b7bc0bc@comcast.net>


On 11/3/18 12:59 PM, Israel Ortiz wrote:
> I am trying to predict follow-up time using several survival models, both
> parametric and semi-parametric. I achieve it for semi parametric models
> using predict.coxph function in R from survival package using type =
> "expected" as indicated in help. However, for parametric models, this
> option doesn't exist for the predict.survreg function. Is there any other
> option? Maybe using rms package?

I would imagine that the author thought that you should be able to 
rather simple construct a function that would return an estimate simply 
from the coefficients and the parametric equation for S(t).


That was also what Harrell does in his "Regression? Modeling Strategies" 
text. In the first edition the code is on page 437.

-- 

David


>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From dw|n@em|u@ @end|ng |rom comc@@t@net  Sat Nov  3 21:41:31 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 3 Nov 2018 13:41:31 -0700
Subject: [R] Predict follow up time using parametric model in r
In-Reply-To: <CAMESY2jmYNeWjdjFFH5sNYD1mEuSi5uUh9grus=4Laem70jwyg@mail.gmail.com>
References: <CAMESY2jmYNeWjdjFFH5sNYD1mEuSi5uUh9grus=4Laem70jwyg@mail.gmail.com>
Message-ID: <5c0e69cd-adf1-eb61-9bea-8422eb858aeb@comcast.net>


On 11/3/18 12:59 PM, Israel Ortiz wrote:
> I am trying to predict follow-up time using several survival models, both
> parametric and semi-parametric. I achieve it for semi parametric models
> using predict.coxph function in R from survival package using type =
> "expected" as indicated in help. However, for parametric models, this
> option doesn't exist for the predict.survreg function. Is there any other
> option? Maybe using rms package?

I would imagine that the author thought that you should be able to 
rather simple construct a function that would return an estimate simply 
from the coefficients and the parametric equation for S(t).


That was also what Harrell does in his "Regression? Modeling Strategies" 
text. In the first edition the code is on page 437.

-- 

David


>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From dw|n@em|u@ @end|ng |rom comc@@t@net  Sat Nov  3 21:41:15 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 3 Nov 2018 13:41:15 -0700
Subject: [R] cox model
In-Reply-To: <CAF-ms1p9weyiF0GNsbUtDRvpAtwgszhEoF9R85Q4CkokBbXBxg@mail.gmail.com>
References: <CAF-ms1p9weyiF0GNsbUtDRvpAtwgszhEoF9R85Q4CkokBbXBxg@mail.gmail.com>
Message-ID: <36ae5cc4-a151-9769-5101-1273026ac14c@comcast.net>

It's also "well described" in the help materials for the obvious 
recommended package that ships with every copy of R. My copy sits at 
http://127.0.0.1:29434/library/survival/doc/timedep.pdf. Therneau's S 
package was first ported to R by Thomas Lumley and later Therneau took 
over maintenance.

-- 

David.

On 11/3/18 12:51 PM, Medic wrote:
> I need a R-code for a situation that is well described in the sas help. I
> would be very grateful for the help!
> "Time-dependent variables can be used to model the effects of subjects
> transferring from one treatment group to another. One example of the need
> for such strategies is the Stanford heart transplant program. Patients are
> accepted if physicians judge them suitable for heart transplant. Then, when
> a donor becomes available, physicians choose transplant recipients
> according to various medical criteria. A patient?s status can be changed
> during the study from waiting for a transplant to being a transplant
> recipient. Transplant status can be defined by the time-dependent covariate
> function z=z(t) as:
> z(t)= 0 (if the patient has not received the transplant at time t)
> and 1 (if has received)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From @nowb@||0916 @end|ng |rom 163@com  Sun Nov  4 02:47:29 2018
From: @nowb@||0916 @end|ng |rom 163@com (snowball0916)
Date: Sun, 4 Nov 2018 09:47:29 +0800
Subject: [R] date and time data on x axis
References: <2018102823163020889853@163.com>, 
 <676F6E37-0980-4540-B5C1-8F25A7DB1E3C@llnl.gov>
Message-ID: <2018110409472870111665@163.com>

Hi, Don
After I've tried 1 month data. It show me like attachment.

The problem is it's hard to identify the the high point from the graph.
Is there possible, when my cursor move on some point , it will show me both x axis and y axis data?
OR 
Is there other way to get the same goal?

Thanks very much.
 
 


 
From: MacQueen, Don
Date: 2018-10-30 00:01
To: snowball0916; r-help
Subject: Re: [R] date and time data on x axis
Here's an example of 24 hours of data at one second intervals.
 
npts <- 24*60*60
 
df <- data.frame(
                 tm = seq( Sys.time(), by='1 sec', length=npts),
                 yd = round(runif(npts),2)
                 )
 
head(df)
 
with(df, plot(tm,yd))
 
The x axis appears to me to be displayed in a neat and clean way. I don't understand what the problem is.
(The data itself is illegible, but that's a different problem.)
 
The default axis may not be what you want, but it is neat and clean. To choose the axis tick marks and labels yourself, use axis() or axis.POSIXct, as Rui mentioned.  help(axis.POSIXct) provides examples of actual use.
 
I prefer to do as much as possible with base R, so look at this example:
 
> as.POSIXct( '20181028_10:00:00' , format='%Y%m%d_%H:%M:%S')
[1] "2018-10-28 10:00:00 PDT"
 
Therefore 
  xdata <- as.POSIXct(mydata$V1, format='%Y%m%d_%H:%M:%S')
is perfectly adequate (the lubridate package is not essential here)
 
 
par() is the function that sets graphical parameters. There are many graphical parameters.
"mar" is the parameter that specifies the sizes of the plot margins  ( see ?par )
 
This expression
   op <- par(mar = c(4, 0, 0, 0) + par("mar"))
is a way to modify the values of the "mar" parameter.
 
Type the following commands
   par('mar')
   par()$mar        ## an alternative
   c(4,0,0,0) + par('mar')
   par(mar = c(4, 0, 0, 0) + par("mar"))
   par('mar')        ## to see that the margins have been changed
 
--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
?On 10/28/18, 8:16 AM, "R-help on behalf of snowball0916" <r-help-bounces at r-project.org on behalf of snowball0916 at 163.com> wrote:
 
    Hi, guys
    How do you guys deal with the date and time data on x axis?
    I have some trouble with it. Could you help with this?
    
    =============
    Sample Data
    =============
    The sample data look like this:
    
    20181028_10:00:00 600 
    20181028_10:00:01 500 
    20181028_10:00:02 450 
    20181028_10:00:03 660
    ......
    
    =============
    My Code
    =============
    
    library(lubridate)
    mydata <- read.table("e:/R_study/graph_test2.txt")
    xdata <- ymd_hms(mydata$V1)
    ydata <- mydata$V2
    plot(xdata, ydata, type="o")
    
    
    =============
    Questions:
    =============
    
    1. Why my x axis does not show me the correct date time like ""2018-10-28 10:00:00 UTC" ?
    2. If my data is very huge(like data in every second and the data has the whole day , even the whole month), how can I display the x axis in a neat and clean way?
    
    Thanks very much.
     
    
    
    
    [[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    
 

From bgunter@4567 @end|ng |rom gm@||@com  Sun Nov  4 03:07:39 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 3 Nov 2018 19:07:39 -0700
Subject: [R] date and time data on x axis
In-Reply-To: <2018110409472870111665@163.com>
References: <2018102823163020889853@163.com>
 <676F6E37-0980-4540-B5C1-8F25A7DB1E3C@llnl.gov>
 <2018110409472870111665@163.com>
Message-ID: <CAGxFJbTc9eFTz6vWcroLL83xiZNG4UdhVsteOH6k7CDhk31yUA@mail.gmail.com>

See ?identify and ?locator

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Nov 3, 2018 at 6:47 PM snowball0916 <snowball0916 at 163.com> wrote:

> Hi, Don
> After I've tried 1 month data. It show me like attachment.
>
> The problem is it's hard to identify the the high point from the graph.
> Is there possible, when my cursor move on some point , it will show me
> both x axis and y axis data?
> OR
> Is there other way to get the same goal?
>
> Thanks very much.
>
>
>
>
>
> From: MacQueen, Don
> Date: 2018-10-30 00:01
> To: snowball0916; r-help
> Subject: Re: [R] date and time data on x axis
> Here's an example of 24 hours of data at one second intervals.
>
> npts <- 24*60*60
>
> df <- data.frame(
>                  tm = seq( Sys.time(), by='1 sec', length=npts),
>                  yd = round(runif(npts),2)
>                  )
>
> head(df)
>
> with(df, plot(tm,yd))
>
> The x axis appears to me to be displayed in a neat and clean way. I don't
> understand what the problem is.
> (The data itself is illegible, but that's a different problem.)
>
> The default axis may not be what you want, but it is neat and clean. To
> choose the axis tick marks and labels yourself, use axis() or axis.POSIXct,
> as Rui mentioned.  help(axis.POSIXct) provides examples of actual use.
>
> I prefer to do as much as possible with base R, so look at this example:
>
> > as.POSIXct( '20181028_10:00:00' , format='%Y%m%d_%H:%M:%S')
> [1] "2018-10-28 10:00:00 PDT"
>
> Therefore
>   xdata <- as.POSIXct(mydata$V1, format='%Y%m%d_%H:%M:%S')
> is perfectly adequate (the lubridate package is not essential here)
>
>
> par() is the function that sets graphical parameters. There are many
> graphical parameters.
> "mar" is the parameter that specifies the sizes of the plot margins  ( see
> ?par )
>
> This expression
>    op <- par(mar = c(4, 0, 0, 0) + par("mar"))
> is a way to modify the values of the "mar" parameter.
>
> Type the following commands
>    par('mar')
>    par()$mar        ## an alternative
>    c(4,0,0,0) + par('mar')
>    par(mar = c(4, 0, 0, 0) + par("mar"))
>    par('mar')        ## to see that the margins have been changed
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
> ?On 10/28/18, 8:16 AM, "R-help on behalf of snowball0916" <
> r-help-bounces at r-project.org on behalf of snowball0916 at 163.com> wrote:
>
>     Hi, guys
>     How do you guys deal with the date and time data on x axis?
>     I have some trouble with it. Could you help with this?
>
>     =============
>     Sample Data
>     =============
>     The sample data look like this:
>
>     20181028_10:00:00 600
>     20181028_10:00:01 500
>     20181028_10:00:02 450
>     20181028_10:00:03 660
>     ......
>
>     =============
>     My Code
>     =============
>
>     library(lubridate)
>     mydata <- read.table("e:/R_study/graph_test2.txt")
>     xdata <- ymd_hms(mydata$V1)
>     ydata <- mydata$V2
>     plot(xdata, ydata, type="o")
>
>
>     =============
>     Questions:
>     =============
>
>     1. Why my x axis does not show me the correct date time like
> ""2018-10-28 10:00:00 UTC" ?
>     2. If my data is very huge(like data in every second and the data has
> the whole day , even the whole month), how can I display the x axis in a
> neat and clean way?
>
>     Thanks very much.
>
>
>
>
>     [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @nowb@||0916 @end|ng |rom 163@com  Sun Nov  4 03:40:39 2018
From: @nowb@||0916 @end|ng |rom 163@com (snowball0916)
Date: Sun, 4 Nov 2018 10:40:39 +0800
Subject: [R] date and time data on x axis
References: <2018102823163020889853@163.com>, 
 <676F6E37-0980-4540-B5C1-8F25A7DB1E3C@llnl.gov>, 
 <2018110409472870111665@163.com>, 
 <CAGxFJbTc9eFTz6vWcroLL83xiZNG4UdhVsteOH6k7CDhk31yUA@mail.gmail.com>
Message-ID: <2018110410403743232867@163.com>

Hi, Bert
I will check those two, by the way, how can you find the two function? have you used them before?
Thanks very much.
 


 
From: Bert Gunter
Date: 2018-11-04 10:07
To: snowball0916
CC: MacQueen, Don; R-help
Subject: Re: [R] date and time data on x axis
See ?identify and ?locator

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Nov 3, 2018 at 6:47 PM snowball0916 <snowball0916 at 163.com> wrote:
Hi, Don
After I've tried 1 month data. It show me like attachment.

The problem is it's hard to identify the the high point from the graph.
Is there possible, when my cursor move on some point , it will show me both x axis and y axis data?
OR 
Is there other way to get the same goal?

Thanks very much.





From: MacQueen, Don
Date: 2018-10-30 00:01
To: snowball0916; r-help
Subject: Re: [R] date and time data on x axis
Here's an example of 24 hours of data at one second intervals.

npts <- 24*60*60

df <- data.frame(
                 tm = seq( Sys.time(), by='1 sec', length=npts),
                 yd = round(runif(npts),2)
                 )

head(df)

with(df, plot(tm,yd))

The x axis appears to me to be displayed in a neat and clean way. I don't understand what the problem is.
(The data itself is illegible, but that's a different problem.)

The default axis may not be what you want, but it is neat and clean. To choose the axis tick marks and labels yourself, use axis() or axis.POSIXct, as Rui mentioned.  help(axis.POSIXct) provides examples of actual use.

I prefer to do as much as possible with base R, so look at this example:

> as.POSIXct( '20181028_10:00:00' , format='%Y%m%d_%H:%M:%S')
[1] "2018-10-28 10:00:00 PDT"

Therefore 
  xdata <- as.POSIXct(mydata$V1, format='%Y%m%d_%H:%M:%S')
is perfectly adequate (the lubridate package is not essential here)


par() is the function that sets graphical parameters. There are many graphical parameters.
"mar" is the parameter that specifies the sizes of the plot margins  ( see ?par )

This expression
   op <- par(mar = c(4, 0, 0, 0) + par("mar"))
is a way to modify the values of the "mar" parameter.

Type the following commands
   par('mar')
   par()$mar        ## an alternative
   c(4,0,0,0) + par('mar')
   par(mar = c(4, 0, 0, 0) + par("mar"))
   par('mar')        ## to see that the margins have been changed

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509

?On 10/28/18, 8:16 AM, "R-help on behalf of snowball0916" <r-help-bounces at r-project.org on behalf of snowball0916 at 163.com> wrote:

    Hi, guys
    How do you guys deal with the date and time data on x axis?
    I have some trouble with it. Could you help with this?

    =============
    Sample Data
    =============
    The sample data look like this:

    20181028_10:00:00 600 
    20181028_10:00:01 500 
    20181028_10:00:02 450 
    20181028_10:00:03 660
    ......

    =============
    My Code
    =============

    library(lubridate)
    mydata <- read.table("e:/R_study/graph_test2.txt")
    xdata <- ymd_hms(mydata$V1)
    ydata <- mydata$V2
    plot(xdata, ydata, type="o")


    =============
    Questions:
    =============

    1. Why my x axis does not show me the correct date time like ""2018-10-28 10:00:00 UTC" ?
    2. If my data is very huge(like data in every second and the data has the whole day , even the whole month), how can I display the x axis in a neat and clean way?

    Thanks very much.




    [[alternative HTML version deleted]]

    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From robertob@kker @end|ng |rom gm@||@com  Sun Nov  4 11:32:14 2018
From: robertob@kker @end|ng |rom gm@||@com (P. Roberto Bakker)
Date: Sun, 4 Nov 2018 11:32:14 +0100
Subject: [R] Different stack barplots - same color legends
In-Reply-To: <CAKDq9_NMVvo-xJuNMDeGno+TATNNmyOr=nExmNC1t6LMuNdz6Q@mail.gmail.com>
References: <CAKDq9_N16xaeL4O2j=v2bVuMb=tuHfu0Ao+yuLQcEq6B-ngq1A@mail.gmail.com>
 <af9001d319ac4992b0bfc5526150f03b@tamu.edu>
 <CAKDq9_P8hQEHWFH=c_86bG81fU0GS+EUCOmtZ9gJa_7kY-2uhA@mail.gmail.com>
 <CAGx1TMAYybconxY7ZVVJcdiYW6+WOjr_D+=GHOA=Xxv2AWRCqQ@mail.gmail.com>
 <CAKDq9_Oi0HGNV7qLnmi4HgVr7orF_gpC7Sys8mLKAxMfjHVtvQ@mail.gmail.com>
 <CAGx1TMB+=RnNeoBmzF=_-gxZ2bzaabExs2Gf-8dKE2vAcpiHpA@mail.gmail.com>
 <CAKDq9_P3GfHXbFbChQwrDUm=E+RuuWGP89tf_KPFXRjYAsrA+A@mail.gmail.com>
 <CAGx1TMByCiZvwOPm06qo4bssWjh=UP9ZPvkX5zi+6dNE=wggaA@mail.gmail.com>
 <CAKDq9_OkLfiP98cuYUg0BU_+cCXmKi9gKHqxSm+Eu16eC3WWyg@mail.gmail.com>
 <CAGx1TMCF8bg64+UOP9ULygHcRnna505RO+1WCWxWJuuFaNp4fQ@mail.gmail.com>
 <CAKDq9_OU8bNq4p8zLr45JADz=SWvGAhG+-ACqdu+qC4a+D8FUw@mail.gmail.com>
 <CAGx1TMABVMuhWzqF=0G7R8KqRLNL=-H7u_XNjwsogPCeY09zjw@mail.gmail.com>
 <CAKDq9_NMVvo-xJuNMDeGno+TATNNmyOr=nExmNC1t6LMuNdz6Q@mail.gmail.com>
Message-ID: <CAKDq9_NXfax606caNC2CVnVuuz50fwTdnTEcVPuidSB+RtwQrw@mail.gmail.com>

Dear Richard,

I ran your syntax and the plots look great and cool.
Again, thank you so much for helping me out a lot and for all the
programming.
And again, Jim en David, thank you also so much.
Now, I can continue with my work and I learned a lot from you.

Best,
Roberto

Op za 3 nov. 2018 om 14:06 schreef P. Roberto Bakker <
robertobakker at gmail.com>:

> Dear Richard,
>
> Thank you so much for all your work and time you punt in it.
> I will start with your suggestions and let you know how far I come.
> Also thanks to the others who helpt me.
>
> Best Roberto
>
> Op do 1 nov. 2018 om 23:42 schreef Richard M. Heiberger <rmh at temple.edu>:
>
>> ## reminder on how the levels= argument to factor works
>>
>> mydata <- matrix(1:8,  nrow=4, ncol=2, dimnames=list(letters[1:4],
>> LETTERS[1:2]))
>> dput(mydata)
>>
>> Factor.wrong <- factor(c("mm", "cm", "m", "km"))
>> levels(Factor.wrong) ## alphabetical order, not meaning order
>>
>> Factor.right <- factor(c("mm", "cm", "m", "km"),
>>                        levels=c("mm", "cm", "m", "km"))
>> levels(Factor.right) ## meaning order
>>
>>
>>
>> library(HH) ## for the likert function
>>
>> ## dput(teamq[1:10,7:8])
>> teamq10x78 <-
>> structure(list(`Ik volg bijscholing om mijn opleiders-kwaliteiten op
>> peil te houden` = c("de situatie in hoge mate van toepassing is voor u
>> of uw supervisorengroep",
>> "de situatie in hoge mate van toepassing is voor u of uw
>> supervisorengroep",
>> "de situatie in zeer hoge mate van toepassing is voor u of uw
>> supervisorengroep",
>> "de situatie in zeer hoge mate van toepassing is voor u of uw
>> supervisorengroep",
>> "de situatie in geringe mate van toepassing is voor u of uw
>> supervisorengroep",
>> "de situatie enigszins van toepassing is voor u of uw supervisorengroep",
>> "de situatie in zeer hoge mate van toepassing is voor u of uw
>> supervisorengroep",
>> "de situatie in hoge mate van toepassing is voor u of uw
>> supervisorengroep",
>> "de situatie in hoge mate van toepassing is voor u of uw
>> supervisorengroep",
>> "de situatie in zeer hoge mate van toepassing is voor u of uw
>> supervisorengroep"
>> ), `Ik weet precies wat de ?modernisering van de opleiding? inhoudt` =
>> c("de situatie in hoge mate van toepassing is voor u of uw
>> supervisorengroep",
>> "de situatie in hoge mate van toepassing is voor u of uw
>> supervisorengroep",
>> "de situatie in zeer hoge mate van toepassing is voor u of uw
>> supervisorengroep",
>> "de situatie in zeer hoge mate van toepassing is voor u of uw
>> supervisorengroep",
>> "de situatie in geringe mate van toepassing is voor u of uw
>> supervisorengroep",
>> "de situatie enigszins van toepassing is voor u of uw supervisorengroep",
>> "de situatie in geringe mate van toepassing is voor u of uw
>> supervisorengroep",
>> "de situatie in geringe mate van toepassing is voor u of uw
>> supervisorengroep",
>> "de situatie enigszins van toepassing is voor u of uw supervisorengroep",
>> "de situatie in hoge mate van toepassing is voor u of uw
>> supervisorengroep"
>> )), row.names = c(NA, -10L), class = c("tbl_df", "tbl", "data.frame"
>> ))
>>
>>
>> ## This is from Google translate
>>
>> ## Ik weet precies wat de ?modernisering van de opleiding? inhoudt
>> ## I know exactly what the "modernization of the training"
>>
>> ## Ik volg bijscholing om mijn opleiders-kwaliteiten op peil te houden
>> ## I follow training to keep my grades at level trainers
>>
>>
>> ## ## This is your order of levels from Mon, Oct 22, 2018 at 1:30 PM
>> ## "de situatie in zeer geringe mate van toepassing is voor u of uw
>> supervisorengroep"
>> ## "de situatie in geringe mate van toepassing is voor u of uw
>> supervisorengroep"
>> ## "de situatie enigszins van toepassing is voor u of uw
>> supervisorengroep"
>> ## "de situatie in hoge mate van toepassing is voor u of uw
>> supervisorengroep"
>> ## "de situatie in zeer hoge mate van toepassing is voor u of uw
>> supervisorengroep"
>>
>> ## ## This is from Google translate
>> ## the situation very little applies to you or your group supervisor
>> ## the situation slightly applies to you or your group supervisor
>> ## the situation somewhat applies to you or your group supervisor
>> ## the situation is highly applicable to you or your group supervisor
>> ## the situation very largely applies to you or your group supervisor
>>
>>
>>
>> sapply(teamq10x78, table)
>> likert(t(sapply(teamq10x78, table)))
>> likert(t(sapply(teamq10x78, table)),
>>        auto.key=list(columns=1, border=TRUE),
>>        main="character values are sorted alphabetically, we will use
>> factors in the next figure")
>>
>> object.size(teamq10x78)
>> ## more rows
>> object.size(rbind(teamq10x78,teamq10x78,teamq10x78,teamq10x78,teamq10x78,
>>                   teamq10x78,teamq10x78,teamq10x78,teamq10x78,teamq10x78,
>>                   teamq10x78,teamq10x78,teamq10x78,teamq10x78,teamq10x78,
>>                   teamq10x78,teamq10x78,teamq10x78,teamq10x78,teamq10x78))
>>
>> situatie.levels <- c(
>>   "de situatie in zeer geringe mate van toepassing is voor u of uw
>> supervisorengroep",
>>   "de situatie in geringe mate van toepassing is voor u of uw
>> supervisorengroep",
>>   "de situatie enigszins van toepassing is voor u of uw
>> supervisorengroep",
>>   "de situatie in hoge mate van toepassing is voor u of uw
>> supervisorengroep",
>>   "de situatie in zeer hoge mate van toepassing is voor u of uw
>> supervisorengroep")
>>
>> teamf <- tibble::as.tibble(
>>   lapply(teamq10x78,
>>          function(x, levels) factor(x, levels=levels),
>>          levels=situatie.levels)
>> )
>> names(teamf) <- names(teamq10x78) ## lapply replaced space and quote
>> characters with "."
>> ## and each column is a factor with properly ordered labels.
>> sapply(teamf, class)
>> sapply(teamf, levels) ## all five levels appear even though this
>> example observed only four
>>
>> object.size(teamf) ## bigger here
>> ## significantly smaller for more rows
>> object.size(rbind(teamf,teamf,teamf,teamf,teamf,
>>                   teamf,teamf,teamf,teamf,teamf,
>>                   teamf,teamf,teamf,teamf,teamf,
>>                   teamf,teamf,teamf,teamf,teamf))
>>
>> sapply(teamf, table) ## these are the counts of responses by question
>>
>> likert(t(sapply(teamf, table)),
>>        auto.key=list(columns=1, border=TRUE),
>>        main="the middle group enigszins is by default split equally
>> between negative and positive")
>>
>> likert(t(sapply(teamf, table)),
>>        auto.key=list(columns=1, border=TRUE),
>>        main="based on your color scheme, I am putting enigszins on the
>> negative side",
>>        ReferenceZero=3.5,
>>        col=c("yellow","sandybrown","orange", "darkolivegreen","green"))
>>
>>
>> ## I am adding a third question with some "zeer geringe" values
>>
>> teamf[,"Extra Question"] <- teamf[,2]
>> teamf[1:2, 3] <- situatie.levels[1]
>>
>> likert(t(sapply(teamf, table)),
>>        auto.key=list(columns=1, border=TRUE),
>>        main="based on your color scheme, I am putting enigszins on the
>> negative side",
>>        ReferenceZero=3.5,
>>        col=c("yellow","sandybrown","orange", "darkolivegreen","green"))
>>
>>
>> ## I find the color scheme unsatisfactory.
>> ## The break point between sandybrown and orange is not distinct.
>> ## I would prefer a darker green on the right side.
>> ## try
>> RColorBrewer::display.brewer.all()
>> ## and see if sny of them work for you.
>>
>> display.brewer.pal(6, "RdYlGn")
>>
>> RYG5 <- brewer.pal(6, "RdYlGn")[-4]
>>
>> likert(t(sapply(teamf, table)),
>>        auto.key=list(columns=1, border=TRUE),
>>        main="based on your color scheme, I am putting enigszins on the
>> negative side",
>>        ReferenceZero=3.5,
>>        col=RYG5)
>>
>>
>>
>> On Wed, Oct 31, 2018 at 5:56 PM, P. Roberto Bakker
>> <robertobakker at gmail.com> wrote:
>> > Hi Rich,
>> >
>> > Thank you for your answer.
>> > The sentences are strings (likert scale: 'the situation is highly
>> applicable
>> > to me' etc - in Dutch), or column labels; it may be confusing as it is
>> in
>> > Dutch. Below I show you part of the dataframe with my annotation added
>> > (string/column lable) to give you an idea.
>> > I need to change the likert strings into numeric (1:5). And this is a
>> > challenge somehow.
>> > With dplyr, plyr it did not work.
>> > After I have the numeric version then I can stack them as suggested by
>> > David.
>> >
>> > PART OF THE DATAFRAME
>> >>> >>>> >   `Ik volg bijscholing om mijn opleiders-kwaliteiten op peil te
>> >>> >>>> > houden` COLUMN LABEL
>> >>> >>>> >
>> >>> >>>> >   <chr>
>> >>> >>>> >
>> >>> >>>> > 1 de situatie in hoge mate van toepassing is voor u of uw
>> >>> >>>> > supervisorengroep LIKERT STRING
>> >>> >>>> > 2 de situatie in zeer hoge mate van toepassing is voor u of uw
>> >>> >>>> > supervisorengroep LIKERT STRING
>> >>> >>>> > 3 de situatie in zeer hoge mate van toepassing is voor u of uw
>> >>> >>>> > supervisorengroep LIKERT STRING
>> >>> >>>> > 4 de situatie in geringe mate van toepassing is voor u of uw
>> >>> >>>> > supervisorengroep LIKERT STRING
>> >>> >>>> >   `Ik weet precies wat de ?modernisering van de opleiding?
>> >>> >>>> > inhoudt` COLUMN LABEL
>> >>> >>>> >
>> >>> >>>> >   <chr>
>> >>> >>>> >
>> >>> >>>> > 1 de situatie in hoge mate van toepassing is voor u of uw
>> >>> >>>> > supervisorengroep LIKERT STRING
>> >>> >>>> > 2 de situatie in zeer hoge mate van toepassing is voor u of uw
>> >>> >>>> > supervisorengroep LIKERT STRING
>> >>> >>>> > 3 de situatie in zeer hoge mate van toepassing is voor u of uw
>> >>> >>>> > supervisorengroep LIKERT STRING
>> >>> >>>> > 4 de situatie in geringe mate van toepassing is voor u of uw
>> >>> >>>> > supervisorengroep LIKERT STRING
>> >
>> >
>> >
>> > Op wo 31 okt. 2018 om 20:28 schreef Richard M. Heiberger <
>> rmh at temple.edu>:
>> >>
>> >> What you sent looks like a set of column labels, not the actual numeric
>> >> data.
>> >>
>> >> You might want to convert them to factors where you control the order
>> >> of the levels.
>> >> > Factor.wrong <- factor(c("mm", "cm", "m", "km"))
>> >> > levels(Factor.wrong) ## alphabetical order, not meaning order
>> >> [1] "cm" "km" "m"  "mm"
>> >> >
>> >> > Factor.right <- factor(c("mm", "cm", "m", "km"),
>> >> +                        levels=c("mm", "cm", "m", "km"))
>> >> > levels(Factor.right) ## meaning order
>> >> [1] "mm" "cm" "m"  "km"
>> >>
>> >> Or you might want to construct a matrix of counts of your data and plot
>> >> that.
>> >>
>> >> Rich
>> >>
>> >>
>> >> On Wed, Oct 31, 2018 at 1:53 PM, P. Roberto Bakker
>> >> <robertobakker at gmail.com> wrote:
>> >> > This is part of the output text
>> >> >
>> >> > "de situatie in hoge mate van toepassing is voor u of uw
>> >> > supervisorengroep", STRING
>> >> > "de situatie in hoge mate van toepassing is voor u of uw
>> >> > supervisorengroep", STRING
>> >> > "de situatie enigszins van toepassing is voor u of uw
>> >> > supervisorengroep", STRING
>> >> > "de situatie in hoge mate van toepassing is voor u of uw
>> >> > supervisorengroep" STRINK
>> >> > ), `Ik waardeer de inbreng van de aios in de afdelingsvergadering`
>> >> > COLUMN LABEL= c("de
>> >> > situatie in hoge mate van toepassing is voor u of uw
>> supervisorengroep",
>> >> > STRING
>> >>
>> >> > "de situatie in hoge mate van toepassing is voor u of uw
>> >> > supervisorengroep",
>> >> > "de situatie in zeer hoge mate van toepassing is voor u of uw
>> >> > supervisorengroep",
>> >> > "de situatie in zeer hoge mate van toepassing is voor u of uw
>> >> > supervisorengroep",
>> >> > "de situatie enigszins van toepassing is voor u of uw
>> >> > supervisorengroep",
>> >> > "de situatie in zeer hoge mate van toepassing is voor u of uw
>> >> > supervisorengroep",
>> >> > "de situatie in zeer hoge mate van toepassing is voor u of uw
>> >> > supervisorengroep",
>> >> > "de situatie in zeer hoge mate van toepassing is voor u of uw
>> >> > supervisorengroep",
>> >> > "de situatie enigszins van toepassing is voor u of uw
>> >> > supervisorengroep",
>> >> > "de situatie in hoge mate van toepassing is voor u of uw
>> >> > supervisorengroep",
>> >> > "de situatie in hoge mate van toepassing is voor u of uw
>> >> > supervisorengroep",
>> >> > "de situatie in hoge mate van toepassing is voor u of uw
>> >> > supervisorengroep",
>> >> >
>> >> > Op wo 31 okt. 2018 om 16:24 schreef Richard M. Heiberger
>> >> > <rmh at temple.edu>:
>> >> >>
>> >> >> part is fine.  just be sure that the small part causes the problem.
>> >> >> I will need that to investigate what is happening.
>> >> >>
>> >> >>
>> >> >> On Wed, Oct 31, 2018 at 11:15 AM, P. Roberto Bakker
>> >> >> <robertobakker at gmail.com> wrote:
>> >> >> > It is a very long result text. I can send it to you, or is part
>> of it
>> >> >> > ok?[
>> >> >> >
>> >> >> > Op wo 31 okt. 2018 om 14:27 schreef Richard M. Heiberger
>> >> >> > <rmh at temple.edu>:
>> >> >> >>
>> >> >> >> Please send me the
>> >> >> >> dput(teamq)
>> >> >> >>
>> >> >> >>
>> >> >> >> On Wed, Oct 31, 2018 at 03:51 P. Roberto Bakker
>> >> >> >> <robertobakker at gmail.com>
>> >> >> >> wrote:
>> >> >> >>>
>> >> >> >>> Thank you for you information. Package 'HH' is interesting.
>> >> >> >>>
>> >> >> >>> Now I find another problem when using 'likert(teamq)'
>> >> >> >>> I get an error message:
>> >> >> >>> > likert(teamq)
>> >> >> >>> Error in dimnames(x) <- `*vtmp*` :
>> >> >> >>>   length of 'dimnames' [2] not equal to array extent
>> >> >> >>>
>> >> >> >>> I checked:
>> >> >> >>> > dim(teamq)
>> >> >> >>> [1] 4 2
>> >> >> >>> > ncol(teamq)
>> >> >> >>> [1] 2
>> >> >> >>> So it should be good.
>> >> >> >>>
>> >> >> >>> I used 'make.names' , in case the spaces in the variable names
>> >> >> >>> would
>> >> >> >>> be a
>> >> >> >>> problem.
>> >> >> >>> Same error.
>> >> >> >>>
>> >> >> >>> What could I do?
>> >> >> >>>
>> >> >> >>> Best and thank you in advance.
>> >> >> >>> Roberto
>> >> >> >>>
>> >> >> >>>
>> >> >> >>> Op ma 22 okt. 2018 om 20:10 schreef Richard M. Heiberger
>> >> >> >>> <rmh at temple.edu>:
>> >> >> >>>>
>> >> >> >>>> Try the likert function in
>> >> >> >>>> install.packages("HH) ## if necessary
>> >> >> >>>> library(HH)
>> >> >> >>>>
>> >> >> >>>> Then using David Carlson's example teamq
>> >> >> >>>> likert(teamq)
>> >> >> >>>>
>> >> >> >>>> Your example in the 1:30PM (Eastern Daylight Time) doesn't
>> work.
>> >> >> >>>> Error in revalue(teamq, c(`de situatie in zeer geringe mate van
>> >> >> >>>> toepassing is\nvoor u of uw supervisorengroep` = "1",  :
>> >> >> >>>>   x is not a factor or a character vector.
>> >> >> >>>>
>> >> >> >>>> There are many examples in
>> >> >> >>>> ?likert
>> >> >> >>>>
>> >> >> >>>> Rich
>> >> >> >>>>
>> >> >> >>>>
>> >> >> >>>> On Mon, Oct 22, 2018 at 1:30 PM, P. Roberto Bakker
>> >> >> >>>> <robertobakker at gmail.com> wrote:
>> >> >> >>>> > Dear David,
>> >> >> >>>> >
>> >> >> >>>> > Thank you for you quite response.
>> >> >> >>>> > My apologies for not giving some sample data - this is due to
>> >> >> >>>> > AVG.
>> >> >> >>>> > *But this minisample should not be a problem (all in Dutch)*:
>> >> >> >>>> >  teamq
>> >> >> >>>> > # A tibble: 4 x 2
>> >> >> >>>> >   `Ik volg bijscholing om mijn opleiders-kwaliteiten op peil
>> te
>> >> >> >>>> > houden`
>> >> >> >>>> >
>> >> >> >>>> >   <chr>
>> >> >> >>>> >
>> >> >> >>>> > 1 de situatie in hoge mate van toepassing is voor u of uw
>> >> >> >>>> > supervisorengroep
>> >> >> >>>> > 2 de situatie in zeer hoge mate van toepassing is voor u of
>> uw
>> >> >> >>>> > supervisorengroep
>> >> >> >>>> > 3 de situatie in zeer hoge mate van toepassing is voor u of
>> uw
>> >> >> >>>> > supervisorengroep
>> >> >> >>>> > 4 de situatie in geringe mate van toepassing is voor u of uw
>> >> >> >>>> > supervisorengroep
>> >> >> >>>> >   `Ik weet precies wat de ?modernisering van de opleiding?
>> >> >> >>>> > inhoudt`
>> >> >> >>>> >
>> >> >> >>>> >   <chr>
>> >> >> >>>> >
>> >> >> >>>> > 1 de situatie in hoge mate van toepassing is voor u of uw
>> >> >> >>>> > supervisorengroep
>> >> >> >>>> > 2 de situatie in zeer hoge mate van toepassing is voor u of
>> uw
>> >> >> >>>> > supervisorengroep
>> >> >> >>>> > 3 de situatie in zeer hoge mate van toepassing is voor u of
>> uw
>> >> >> >>>> > supervisorengroep
>> >> >> >>>> > 4 de situatie in geringe mate van toepassing is voor u of uw
>> >> >> >>>> > supervisorengroep
>> >> >> >>>> >
>> >> >> >>>> > As you see the likert items are in words, and I should change
>> >> >> >>>> > them
>> >> >> >>>> > in
>> >> >> >>>> > nummeric - Am I correct?
>> >> >> >>>> >
>> >> >> >>>> > *To do this, I tried (see further below):*
>> >> >> >>>> > plyr rename() ; I receive the message it should be a factor
>> or
>> >> >> >>>> > character
>> >> >> >>>> > dplyr recode() ; same message
>> >> >> >>>> > mapvalues() ; it should be atomic, so I used as.atomic(teamq)
>> >> >> >>>> > but
>> >> >> >>>> > then
>> >> >> >>>> > I
>> >> >> >>>> > receive the nummers a strings.
>> >> >> >>>> >
>> >> >> >>>> > *The syntaxes*
>> >> >> >>>> > require(plyr)
>> >> >> >>>> > example2 <- revalue(teamq,
>> >> >> >>>> >                     c("de situatie in zeer geringe mate van
>> >> >> >>>> > toepassing
>> >> >> >>>> > is
>> >> >> >>>> > voor u of uw supervisorengroep"= "1",
>> >> >> >>>> >                         "de situatie in geringe mate van
>> >> >> >>>> > toepassing
>> >> >> >>>> > is
>> >> >> >>>> > voor
>> >> >> >>>> > u of uw supervisorengroep"= "2",
>> >> >> >>>> >                         "de situatie enigszins van
>> toepassing is
>> >> >> >>>> > voor
>> >> >> >>>> > u of
>> >> >> >>>> > uw supervisorengroep"= "3",
>> >> >> >>>> >                         "de situatie in hoge mate van
>> toepassing
>> >> >> >>>> > is
>> >> >> >>>> > voor u
>> >> >> >>>> > of uw supervisorengroep"= "4",
>> >> >> >>>> >                         "de situatie in zeer hoge mate van
>> >> >> >>>> > toepassing
>> >> >> >>>> > is
>> >> >> >>>> > voor u of uw supervisorengroep"= "5"))
>> >> >> >>>> >
>> >> >> >>>> > require(dplyr)
>> >> >> >>>> > example2 <- recode(teamq,
>> >> >> >>>> >                     c("de situatie in zeer geringe mate van
>> >> >> >>>> > toepassing
>> >> >> >>>> > is
>> >> >> >>>> > voor u of uw supervisorengroep"= "1",
>> >> >> >>>> >                       "de situatie in geringe mate van
>> >> >> >>>> > toepassing
>> >> >> >>>> > is
>> >> >> >>>> > voor u
>> >> >> >>>> > of uw supervisorengroep"= "2",
>> >> >> >>>> >                       "de situatie enigszins van toepassing
>> is
>> >> >> >>>> > voor
>> >> >> >>>> > u
>> >> >> >>>> > of uw
>> >> >> >>>> > supervisorengroep"= "3",
>> >> >> >>>> >                       "de situatie in hoge mate van
>> toepassing
>> >> >> >>>> > is
>> >> >> >>>> > voor
>> >> >> >>>> > u of
>> >> >> >>>> > uw supervisorengroep"= "4",
>> >> >> >>>> >                       "de situatie in zeer hoge mate van
>> >> >> >>>> > toepassing
>> >> >> >>>> > is
>> >> >> >>>> > voor
>> >> >> >>>> > u of uw supervisorengroep"= "5"))
>> >> >> >>>> >
>> >> >> >>>> > mapvalues(as.matrix(teamq), from = c("de situatie in zeer
>> >> >> >>>> > geringe
>> >> >> >>>> > mate
>> >> >> >>>> > van
>> >> >> >>>> > toepassing is voor u of uw supervisorengroep",
>> >> >> >>>> >                         "de situatie in geringe mate van
>> >> >> >>>> > toepassing
>> >> >> >>>> > is
>> >> >> >>>> > voor
>> >> >> >>>> > u of uw supervisorengroep",
>> >> >> >>>> >                         "de situatie enigszins van
>> toepassing is
>> >> >> >>>> > voor
>> >> >> >>>> > u of
>> >> >> >>>> > uw supervisorengroep",
>> >> >> >>>> >                         "de situatie in hoge mate van
>> toepassing
>> >> >> >>>> > is
>> >> >> >>>> > voor u
>> >> >> >>>> > of uw supervisorengroep",
>> >> >> >>>> >                         "de situatie in zeer hoge mate van
>> >> >> >>>> > toepassing
>> >> >> >>>> > is
>> >> >> >>>> > voor u of uw supervisorengroep"),
>> >> >> >>>> >           to = c(1,2,3,4,5))
>> >> >> >>>> >
>> >> >> >>>> > What should I do?
>> >> >> >>>> > Thank you in advance, Roberto
>> >> >> >>>> >
>> >> >> >>>> > Op ma 22 okt. 2018 om 17:13 schreef David L Carlson
>> >> >> >>>> > <dcarlson at tamu.edu>:
>> >> >> >>>> >
>> >> >> >>>> >> Your example is not reproducible since you did not give us
>> some
>> >> >> >>>> >> sample
>> >> >> >>>> >> data. I suspect that your data frame consists of columns
>> that
>> >> >> >>>> >> represent
>> >> >> >>>> >> questions and rows that represent individuals who answered
>> the
>> >> >> >>>> >> questions.
>> >> >> >>>> >> First create a simple example:
>> >> >> >>>> >>
>> >> >> >>>> >> set.seed(42)
>> >> >> >>>> >> teamq <- data.frame(V1=sample(c(1, 2, 4, 5), 25, replace =
>> >> >> >>>> >> TRUE),
>> >> >> >>>> >>      V2=sample(c(1, 2, 3, 4, 5), 25, replace=TRUE),
>> >> >> >>>> >>      V3=sample(c(2, 3, 4, 5), 25, replace=TRUE))
>> >> >> >>>> >>
>> >> >> >>>> >> Notice that this data frame ONLY contains questions (and
>> only 3
>> >> >> >>>> >> questions). Here are 2 ways to get what you want. The first
>> one
>> >> >> >>>> >> stacks the
>> >> >> >>>> >> data:
>> >> >> >>>> >>
>> >> >> >>>> >> teamq.stack <- stack(teamq)
>> >> >> >>>> >> str(teamq.stack)
>> >> >> >>>> >> counts <- table(teamq.stack)
>> >> >> >>>> >> str(counts)
>> >> >> >>>> >>
>> >> >> >>>> >> The second one converts each column to a factor with levels
>> 1 -
>> >> >> >>>> >> 5:
>> >> >> >>>> >>
>> >> >> >>>> >> teamq2 <- data.frame(lapply(teamq, factor, levels=1:5))
>> >> >> >>>> >> str(teamq2)
>> >> >> >>>> >> counts <- sapply(teamq2, table)
>> >> >> >>>> >> str(counts)
>> >> >> >>>> >>
>> >> >> >>>> >> Now make the plots:
>> >> >> >>>> >>
>> >> >> >>>> >> cols <- c("yellow","sandybrown","orange",
>> >> >> >>>> >> "darkolivegreen","green")
>> >> >> >>>> >> barplot(counts[, 1], horiz=TRUE, col=cols, legend=TRUE)
>> >> >> >>>> >> barplot(counts[, 2], horiz=TRUE, col=cols, legend=TRUE)
>> >> >> >>>> >> barplot(counts[, 3], horiz=TRUE, col=cols, legend=TRUE)
>> >> >> >>>> >>
>> >> >> >>>> >> You will need to adjust the xlim= argument so that the
>> legend
>> >> >> >>>> >> does
>> >> >> >>>> >> not
>> >> >> >>>> >> print on top of the bars.
>> >> >> >>>> >>
>> >> >> >>>> >> ----------------------------------------
>> >> >> >>>> >> David L Carlson
>> >> >> >>>> >> Department of Anthropology
>> >> >> >>>> >> Texas A&M University
>> >> >> >>>> >> College Station, TX 77843-4352
>> >> >> >>>> >>
>> >> >> >>>> >>
>> >> >> >>>> >> -----Original Message-----
>> >> >> >>>> >> From: R-help <r-help-bounces at r-project.org> On Behalf Of P.
>> >> >> >>>> >> Roberto
>> >> >> >>>> >> Bakker
>> >> >> >>>> >> Sent: Monday, October 22, 2018 9:04 AM
>> >> >> >>>> >> To: R mailing list <r-help at r-project.org>
>> >> >> >>>> >> Subject: [R] Different stack barplots - same color legends
>> >> >> >>>> >>
>> >> >> >>>> >> Hi,
>> >> >> >>>> >>
>> >> >> >>>> >> I want to make barplots from different questions (columns)
>> in
>> >> >> >>>> >> one
>> >> >> >>>> >> data.frame.
>> >> >> >>>> >> Each question has the same 5 likert items.
>> >> >> >>>> >> Now the problem: in some questions all items are answered;
>> in
>> >> >> >>>> >> other
>> >> >> >>>> >> less.
>> >> >> >>>> >> From the syntax below I get nice stack barplots - *but the
>> >> >> >>>> >> legend
>> >> >> >>>> >> colors do
>> >> >> >>>> >> not* refer to the same likert-item, which I understand - the
>> >> >> >>>> >> colors
>> >> >> >>>> >> go in
>> >> >> >>>> >> sequence along the table.
>> >> >> >>>> >> Question: how can I write a syntax that each likert-item has
>> >> >> >>>> >> the
>> >> >> >>>> >> same
>> >> >> >>>> >> legend color?
>> >> >> >>>> >> Thank you in advance,
>> >> >> >>>> >>
>> >> >> >>>> >> Roberto
>> >> >> >>>> >>
>> >> >> >>>> >> SYNTAX:
>> >> >> >>>> >> counts19 <- table(teamq[,19])
>> >> >> >>>> >> counts20 <- table(teamq[,20])
>> >> >> >>>> >> barplot(as.matrix(counts19), horiz = T,
>> >> >> >>>> >>         col=c("yellow","sandybrown","orange",
>> >> >> >>>> >> "darkolivegreen","green"),
>> >> >> >>>> >> legend=T)
>> >> >> >>>> >> barplot(as.matrix(counts20), horiz = T,
>> >> >> >>>> >>         col=c("yellow","sandybrown","orange",
>> >> >> >>>> >> "darkolivegreen","green"),
>> >> >> >>>> >> legend=T)
>> >> >> >>>> >>
>> >> >> >>>> >>         [[alternative HTML version deleted]]
>> >> >> >>>> >>
>> >> >> >>>> >> ______________________________________________
>> >> >> >>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>> more,
>> >> >> >>>> >> see
>> >> >> >>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> >>>> >> PLEASE do read the posting guide
>> >> >> >>>> >> http://www.R-project.org/posting-guide.html
>> >> >> >>>> >> and provide commented, minimal, self-contained, reproducible
>> >> >> >>>> >> code.
>> >> >> >>>> >>
>> >> >> >>>> >
>> >> >> >>>> >         [[alternative HTML version deleted]]
>> >> >> >>>> >
>> >> >> >>>> > ______________________________________________
>> >> >> >>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>> more,
>> >> >> >>>> > see
>> >> >> >>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> >>>> > PLEASE do read the posting guide
>> >> >> >>>> > http://www.R-project.org/posting-guide.html
>> >> >> >>>> > and provide commented, minimal, self-contained, reproducible
>> >> >> >>>> > code.
>>
>

	[[alternative HTML version deleted]]



From nourd|nek@bouch @end|ng |rom y@hoo@com  Sun Nov  4 15:05:28 2018
From: nourd|nek@bouch @end|ng |rom y@hoo@com (Kabouch Nourdine)
Date: Sun, 4 Nov 2018 14:05:28 +0000 (UTC)
Subject: [R] HMM-Classification
References: <1572626073.21969683.1541340328107.ref@mail.yahoo.com>
Message-ID: <1572626073.21969683.1541340328107@mail.yahoo.com>

Hi,
I would like to use HMM for a time serie (solar radiation) classification.I would like to know what are the steps I should follow?For the states i have to chose between 3 or 5, I do not have other informations.
Regards.
	[[alternative HTML version deleted]]



From |@v|@@er @end|ng |rom uv@@n|  Sun Nov  4 16:31:20 2018
From: |@v|@@er @end|ng |rom uv@@n| (Ingmar Visser)
Date: Sun, 4 Nov 2018 16:31:20 +0100
Subject: [R] HMM-Classification
In-Reply-To: <1572626073.21969683.1541340328107@mail.yahoo.com>
References: <1572626073.21969683.1541340328107.ref@mail.yahoo.com>
 <1572626073.21969683.1541340328107@mail.yahoo.com>
Message-ID: <CABmqZHMg3n5pqJZfXuyBKs573sTcp1FNBMdABqBTx8S1JEj3OQ@mail.gmail.com>

There are several packages that allow fitting hidden Markov models
(assuming that that is what you mean by HMM ...), which you can find here:
https://cran.r-project.org/web/packages/
Best, Ingmar

Ingmar Visser
Universitair Hoofddocent ontwikkelingspsychologie | Directeur College
Psychologie
Afdeling Psychologie | Faculteit Maatschappij- en Gedragswetenschappen |
Universiteit van Amsterdam
Bezoek | Nieuwe Achtergracht 129B | Kamer G 1.18
Post | Postbus 15933 | 1001 NK Amsterdam
Pakketpost | Valckenierstraat 59 | 1018 XE Amsterdam
T: +31205256723 | M: +31647260824 | e: i.visser at uva.nl


On Sun, Nov 4, 2018 at 3:06 PM Kabouch Nourdine via R-help <
r-help at r-project.org> wrote:

> Hi,
> I would like to use HMM for a time serie (solar radiation)
> classification.I would like to know what are the steps I should follow?For
> the states i have to chose between 3 or 5, I do not have other informations.
> Regards.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Nov  4 18:16:59 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 04 Nov 2018 09:16:59 -0800
Subject: [R] HMM-Classification
In-Reply-To: <CABmqZHMg3n5pqJZfXuyBKs573sTcp1FNBMdABqBTx8S1JEj3OQ@mail.gmail.com>
References: <1572626073.21969683.1541340328107.ref@mail.yahoo.com>
 <1572626073.21969683.1541340328107@mail.yahoo.com>
 <CABmqZHMg3n5pqJZfXuyBKs573sTcp1FNBMdABqBTx8S1JEj3OQ@mail.gmail.com>
Message-ID: <476F7EBD-DC0E-4580-B19F-5F19C87C8310@dcn.davis.ca.us>

The SpatioTemporal Task View may help narrow the search a bit, as might using a using a search engine:

https://cran.r-project.org/web/views/SpatioTemporal.html

rseek.org

package "sos"

On November 4, 2018 7:31:20 AM PST, Ingmar Visser <i.visser at uva.nl> wrote:
>There are several packages that allow fitting hidden Markov models
>(assuming that that is what you mean by HMM ...), which you can find
>here:
>https://cran.r-project.org/web/packages/
>Best, Ingmar
>
>Ingmar Visser
>Universitair Hoofddocent ontwikkelingspsychologie | Directeur College
>Psychologie
>Afdeling Psychologie | Faculteit Maatschappij- en Gedragswetenschappen
>|
>Universiteit van Amsterdam
>Bezoek | Nieuwe Achtergracht 129B | Kamer G 1.18
>Post | Postbus 15933 | 1001 NK Amsterdam
>Pakketpost | Valckenierstraat 59 | 1018 XE Amsterdam
>T: +31205256723 | M: +31647260824 | e: i.visser at uva.nl
>
>
>On Sun, Nov 4, 2018 at 3:06 PM Kabouch Nourdine via R-help <
>r-help at r-project.org> wrote:
>
>> Hi,
>> I would like to use HMM for a time serie (solar radiation)
>> classification.I would like to know what are the steps I should
>follow?For
>> the states i have to chose between 3 or 5, I do not have other
>informations.
>> Regards.
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From bgunter@4567 @end|ng |rom gm@||@com  Sun Nov  4 18:40:58 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 4 Nov 2018 09:40:58 -0800
Subject: [R] HMM-Classification
In-Reply-To: <CABmqZHMg3n5pqJZfXuyBKs573sTcp1FNBMdABqBTx8S1JEj3OQ@mail.gmail.com>
References: <1572626073.21969683.1541340328107.ref@mail.yahoo.com>
 <1572626073.21969683.1541340328107@mail.yahoo.com>
 <CABmqZHMg3n5pqJZfXuyBKs573sTcp1FNBMdABqBTx8S1JEj3OQ@mail.gmail.com>
Message-ID: <CAGxFJbRkcbsLhbYQn79N+46YzrV60kpkAYgcqC9jyp3bv_np-w@mail.gmail.com>

Indeed! There is even a HMM package!

A web search on "hidden markov models" on rseek.org brought up many
relevant looking hits.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Nov 4, 2018 at 7:31 AM Ingmar Visser <i.visser at uva.nl> wrote:

> There are several packages that allow fitting hidden Markov models
> (assuming that that is what you mean by HMM ...), which you can find here:
> https://cran.r-project.org/web/packages/
> Best, Ingmar
>
> Ingmar Visser
> Universitair Hoofddocent ontwikkelingspsychologie | Directeur College
> Psychologie
> Afdeling Psychologie | Faculteit Maatschappij- en Gedragswetenschappen |
> Universiteit van Amsterdam
> Bezoek | Nieuwe Achtergracht 129B | Kamer G 1.18
> Post | Postbus 15933 | 1001 NK Amsterdam
> Pakketpost | Valckenierstraat 59 | 1018 XE Amsterdam
> T: +31205256723 | M: +31647260824 | e: i.visser at uva.nl
>
>
> On Sun, Nov 4, 2018 at 3:06 PM Kabouch Nourdine via R-help <
> r-help at r-project.org> wrote:
>
> > Hi,
> > I would like to use HMM for a time serie (solar radiation)
> > classification.I would like to know what are the steps I should
> follow?For
> > the states i have to chose between 3 or 5, I do not have other
> informations.
> > Regards.
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From yune@@ng@|ee @end|ng |rom gm@||@com  Sun Nov  4 22:34:26 2018
From: yune@@ng@|ee @end|ng |rom gm@||@com (Yune S. Lee)
Date: Sun, 4 Nov 2018 16:34:26 -0500
Subject: [R] How to add a dummy code for (G)LMER
Message-ID: <CAEO-rZmYoQUPqC6dThX9VV3qMUO7Y68Xm5wQ5V18+OT1iXR5Ag@mail.gmail.com>

Dear R experts --

I never needed to add a dummy column and always query statistical results
by querying summary(model) for GLMER. However, I was recently asked to add
a dummy column for interaction variables when performing GLMER. Could
anyone tell me if it's necessary to add a dummy column for GLMER or R
automatically handles it when outputting results?

Best,
Yune

	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Sun Nov  4 22:41:50 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 5 Nov 2018 08:41:50 +1100
Subject: [R] rnaturalearth: detail by degrees
In-Reply-To: <trinity-581dd2a6-4338-4618-b05a-e98497cd8f21-1541238194073@3c-app-gmx-bs41>
References: <trinity-581dd2a6-4338-4618-b05a-e98497cd8f21-1541238194073@3c-app-gmx-bs41>
Message-ID: <CA+8X3fX-1DjOzdTWGtEp1OCHZrJHM-zOgth-ctWA_0CM4ik4nw@mail.gmail.com>

Hi Ferri,
One way is to snip out a Google Maps image of the area you want, then
using the "maps" package, start a plot bounded by the corner
coordinates of your Google Maps image. You can get those by clicking
on the corners of the area that you selected. Then use the
"readbitmap" package to create a raster object of your GM image and
display it on the plot made by "map". Finally, use either "points" or
"lines" to display the coordinates of your path.

Jim

On Sat, Nov 3, 2018 at 8:43 PM Ferri Leberl <ferri.leberl at gmx.at> wrote:
>
>
> Dear all,
> I have the graph of a path, walking a number of places specified by name, logitude and latitude ? thanks to Don MacQueen.
> xliam and ylim define a certain section of the earth.
> How can I put this section of a political map into the background?
> Thank you in advance.
> Yours, Ferri
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bgunter@4567 @end|ng |rom gm@||@com  Mon Nov  5 00:22:56 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 4 Nov 2018 15:22:56 -0800
Subject: [R] How to add a dummy code for (G)LMER
In-Reply-To: <CAEO-rZmYoQUPqC6dThX9VV3qMUO7Y68Xm5wQ5V18+OT1iXR5Ag@mail.gmail.com>
References: <CAEO-rZmYoQUPqC6dThX9VV3qMUO7Y68Xm5wQ5V18+OT1iXR5Ag@mail.gmail.com>
Message-ID: <CAGxFJbRApD0JZQF3SenKzPkbS6LzSSMD_BEoG_WAxETCVGD6DQ@mail.gmail.com>

I am almost certain that no dummy variables are necessary -- but mixed
models questions are always better posed on the r-sig-mixed-models list.

Bert



On Sun, Nov 4, 2018 at 1:38 PM Yune S. Lee <yunesang.lee at gmail.com> wrote:

> Dear R experts --
>
> I never needed to add a dummy column and always query statistical results
> by querying summary(model) for GLMER. However, I was recently asked to add
> a dummy column for interaction variables when performing GLMER. Could
> anyone tell me if it's necessary to add a dummy column for GLMER or R
> automatically handles it when outputting results?
>
> Best,
> Yune
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @teph@ne@gu|||ou @end|ng |rom member@|@|@org  Mon Nov  5 01:56:19 2018
From: @teph@ne@gu|||ou @end|ng |rom member@|@|@org (=?UTF-8?Q?St=c3=a9phane_Guillou?=)
Date: Mon, 5 Nov 2018 10:56:19 +1000
Subject: [R] potential issue in download.file() help page
Message-ID: <5f6e0b7d-8edf-2212-ed49-2d9d4e46f12f@member.fsf.org>

Hi there

I was told by Martin Maechler that I should send this request to R-help 
rather than R-core, so here it is.

I noticed that the download.file() documentation does not show a default 
value passed on to the `method` argument in the "Usage" section, even 
though it is stated underneath that the default method is `"auto"`.

Does this need fixing?

Cheers

-- 
St?phane Guillou
http://stragu.gitlab.io/

You can encrypt our communications by using OpenPGP. My public key 4E211060 is available on the keys.gnupg.net server.

Other ways to interact with me are listed on my contact page: http://stragu.gitlab.io/contact/



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Nov  5 06:20:39 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 04 Nov 2018 21:20:39 -0800
Subject: [R] potential issue in download.file() help page
In-Reply-To: <5f6e0b7d-8edf-2212-ed49-2d9d4e46f12f@member.fsf.org>
References: <5f6e0b7d-8edf-2212-ed49-2d9d4e46f12f@member.fsf.org>
Message-ID: <B1B953B6-BCBA-4E2C-A958-FAF3E7591907@dcn.davis.ca.us>

The documentation describes the behavior of the program. The function signature shows how the arguments are declared. Both are correct.

If you read an implementation [1] you will see that the missing() function is used to implement the described behavior, rather than using a default value for the argument. I don't know why this choice was made (changes in language over time?), but setting up argument default values is only one way to accomplish the described behavior.

[1] https://github.com/wch/r-source/blob/trunk/src/library/utils/R/windows/download.file.R

On November 4, 2018 4:56:19 PM PST, "St?phane Guillou" <stephane.guillou at member.fsf.org> wrote:
>Hi there
>
>I was told by Martin Maechler that I should send this request to R-help
>
>rather than R-core, so here it is.
>
>I noticed that the download.file() documentation does not show a
>default 
>value passed on to the `method` argument in the "Usage" section, even 
>though it is stated underneath that the default method is `"auto"`.
>
>Does this need fixing?
>
>Cheers

-- 
Sent from my phone. Please excuse my brevity.



From p_conno||y @end|ng |rom @||ng@hot@co@nz  Mon Nov  5 08:01:29 2018
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Mon, 5 Nov 2018 20:01:29 +1300
Subject: [R] Corrupted package?[solved]
In-Reply-To: <20181101075105.GB8540@slingshot.co.nz>
References: <20181031072248.GA8540@slingshot.co.nz>
 <41FEDABD-D3DF-4BEF-8BB1-152F6342617A@gmail.com>
 <20181101075105.GB8540@slingshot.co.nz>
Message-ID: <20181105070129.GC8540@slingshot.co.nz>

On Thu, 01-Nov-2018 at 08:51PM +1300, Patrick Connolly wrote:

|> On Wed, 31-Oct-2018 at 07:30PM +0100, peter dalgaard wrote:
|> 
|> |> Hm, a source install to r-devel gave me 
|> |> 
|> |> Peter-Dalgaards-MacBook-Air:BUILD pd$ ls -l library/pkgconfig/R/pkgconfig.rdb
|> |> -rw-r--r--  1 pd  staff  4515 Oct 31 19:15 library/pkgconfig/R/pkgconfig.rdb
|> |> Peter-Dalgaards-MacBook-Air:BUILD pd$ ls -l library/pkgconfig/help/pkgconfig.rdb
|> |> -rw-r--r--  1 pd  staff  5748 Oct 31 19:15 library/pkgconfig/help/pkgconfig.rdb
|> |> 
|> |> and an install to R_3.4.1 (yes, 4...) said

[...]

I searched and found someone had a message about a corrupted package
and found the problem disappeared when R was restarted.  So, I tried
that, And. sure enough, it worked!

It would have been good to get some understanding of those strange
file sizes, but I suspect it will remain one of Life's little
mysteries.

That might help someone else who gets a corrupt package message.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.



From ch@|@b|@e|@he @end|ng |rom y@hoo@de  Mon Nov  5 13:38:17 2018
From: ch@|@b|@e|@he @end|ng |rom y@hoo@de (Elahe chalabi)
Date: Mon, 5 Nov 2018 12:38:17 +0000 (UTC)
Subject: [R] POS counting number of verbs
References: <1401187708.1569005.1541421497267.ref@mail.yahoo.com>
Message-ID: <1401187708.1569005.1541421497267@mail.yahoo.com>

Hi all,
I have 16630 Messages in my data frame and I would like to count number of verbs in each message, to do so I have the following code:

> str(tar)
'data.frame': 16630 obs. of? 2 variables:
$ Message? ? ? ? ? ? : Factor w/ 13412 levels "","'alter database? datafile' needs to be executed",..: 11163 1 9715 10110 9683 11364 12952 2242 7153 6907 ...
$ group? ? ? ? ? ? ? ? ? ?: Factor w/ 16630 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9 10 ...

> tagPOS <-? function(x, ...) {+? ? ?s <- as.String(x)+? ? ?word_token_annotator <- Maxent_Word_Token_Annotator()+? ? ?a2 <- Annotation(1L, "sentence", 1L, nchar(s))+? ? ?a2 <- annotate(s, word_token_annotator, a2)+? ? ?a3 <- annotate(s, Maxent_POS_Tag_Annotator(), a2)+? ? ?a3w <- a3[a3$type == "word"]+? ? ?POStags <- unlist(lapply(a3w$features, `[[`, "POS"))+? ? ?POStagged <- paste(sprintf("%s/%s", s[a3w], POStags), collapse = " ")+? ? ?list(POStagged = POStagged, POStags = POStags)+ }> count_verbs <-function(x) {+? ? ?pos_tags <- tagPOS(x)$POStags+? ? ?sum(grepl("VB", pos_tags))+ }> library(dplyr)> tar %>%?+? ? ?group_by(group) %>%+? ? ?summarise(num_verbs = count_verbs(Message))
And here is the error I get:Error in summarise_impl(.data, dots) :?? Evaluation error: no word token annotations found.

Does anyone know about this error??Thanks for any help.Elahe
	[[alternative HTML version deleted]]



From @eb@@t|en@b|hore| @end|ng |rom cogn|gencorp@com  Mon Nov  5 14:36:13 2018
From: @eb@@t|en@b|hore| @end|ng |rom cogn|gencorp@com (Sebastien Bihorel)
Date: Mon, 5 Nov 2018 08:36:13 -0500 (EST)
Subject: [R] Encoding issue
Message-ID: <2076839781.1608507.1541424973246.JavaMail.zimbra@cognigencorp.com>

Hi,

I am having problems getting similar output when processing the same markdown files on 2 different Linux systems (one is a laptop with Linux Mint 18.3, the other is a production server running on CentOS 7). I think this boils down to an encoding issue but I am not sure if this is a system-wide issue or an R issue. So, this is what I have so far.

I have this very small dummy html file (with the same md5sum on both systems) which only contains 3 characters. A "od -cx" call provides the same output in both systems:
0000000   r 342 200 231   s  \n
           e272    9980    0a73

The middle character is some form of single quote produced by the conversion of a ' character from markdown to html. Reading the same file in both systems and applying a gsub replace provide widely different results.

####On my laptop
# environment variable: echo $LANG: en_US.UTF-8
> x <- scan('test.html', what='character', sep='\n')
Read 1 item
> x
[1] "r?s"
> gsub('\\s{2,}', ' ', x)
[1] "r?s"
> sessionInfo()
R version 3.4.4 (2018-03-15)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Linux Mint 18.3

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.6.0
LAPACK: /usr/lib/lapack/liblapack.so.3.6.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_3.4.4

####On the server
# environment variable: echo $LANG: en_US.UTF-8
> x <- scan('test.html', what='character', sep='\n')
Read 1 item
> x
[1] "r?s"
> gsub('\\s{2,}', ' ', x)
[1] " "
> sessionInfo()
R version 3.4.3 (2017-11-30)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: CentOS Linux 7 (Core)

Matrix products: default
BLAS: /usr/lib64/R/lib/libRblas.so
LAPACK: /usr/lib64/R/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.3

(The overarching issue is that I have to use the production server for SOP reasons, so I cannot simply ignore the problem and use my laptop).

I would appreciate any suggestions on how to approach this issue.



From @@r@h@go@|ee @end|ng |rom gm@||@com  Mon Nov  5 15:11:37 2018
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Mon, 5 Nov 2018 09:11:37 -0500
Subject: [R] spi package
In-Reply-To: <1698014502.25036986.1541400005877.JavaMail.zimbra@atauni.edu.tr>
References: <1312544585.24817174.1541242103746.JavaMail.zimbra@atauni.edu.tr>
 <CAM_vjunSfDox+hzNZrDvp5FzL3V9g3aV91XXLPrK0yJjR5rg0A@mail.gmail.com>
 <1698014502.25036986.1541400005877.JavaMail.zimbra@atauni.edu.tr>
Message-ID: <CAM_vjum8VDeJ3kA4rBS9yNbb3V5LipRo=mmGXK5w9CXNz6BihQ@mail.gmail.com>

The authors of the spi package are clearly coming from some other
programming language, and did some un-Rish things.

Where you are assuming that nargs, the first argument, is the number
of months, in fact it is literally the number of arguments you're
passing to the function, not counting itself, and so must be in the
range 3-7.

So you actually need:

spi(3,"tercanspi.txt",1966,2017)
spi(7,"tercanspi.txt",1966,2017,"Tercan Standart Ya???
?ndeksi",2,"Y?llar","Aylar")
spi(7,"tercanspi.txt",1966,2017,"Tercan Standart Ya???
?ndeksi",2,"Y?llar","Aylar")
spi(7,"tercanspi.txt",1966,2017,"Tercan Standart Ya???
?ndeksi",2,"Y?llar","Aylar")

No matter what the help implies, you apparently can't choose your own timescale.

I think you might have more success with the SPEI package, on CRAN,
which includes both SPEI and SPI.

Sarah

On Mon, Nov 5, 2018 at 1:43 AM Okan Mert Katipoglu
<okan.katipoglu at atauni.edu.tr> wrote:
>
>
>   When I used ''spi(1,"tercanspi.txt",1966,2017)''
>
>   "Error: very small number of arguments
>
>
>   When I used
>   spi(9,"tercanspi.txt",1966,2017,"Tercan Standart Ya??? ?ndeksi",2,"Y?llar","Aylar")
>   spi(12,"tercanspi.txt",1966,2017,"Tercan Standart Ya??? ?ndeksi",2,"Y?llar","Aylar")
>   spi(24,"tercanspi.txt",1966,2017,"Tercan Standart Ya??? ?ndeksi",2,"Y?llar","Aylar")
>
>   Error: very large number of arguments
>
>
> ----- Orijinal Mesaj -----
> Kimden: "Sarah Goslee" <sarah.goslee at gmail.com>
> Kime: "okan katipoglu" <okan.katipoglu at atauni.edu.tr>
> Kk: "r-help" <r-help at r-project.org>
> G?nderilenler: 3 Kas?m Cumartesi 2018 17:20:33
> Konu: Re: [R] spi package
>
> It would help a lot if you actually told us what your error was.
>
> Based on ?spi::spi your command looks correct, so we need more information.
>
> Sarah
> On Sat, Nov 3, 2018 at 10:02 AM Okan Mert Katipoglu
> <okan.katipoglu at atauni.edu.tr> wrote:
> >
> >
> >   Hi,Can I get information about following spi error,
> >
> >   spi(1,"tercanspi.txt",1966,2017)
> >
> >   spi(9,"tercanspi.txt",1966,2017,"Tercan Standart Ya??? ?ndeksi",2,"Y?llar","Aylar")
> >
> >   spi(12,"tercanspi.txt",1966,2017,"Tercan Standart Ya??? ?ndeksi",2,"Y?llar","Aylar")
> >
> >   spi(24,"tercanspi.txt",1966,2017,"Tercan Standart Ya??? ?ndeksi",2,"Y?llar","Aylar")
> >
> >   how do I run these commands.
> >
> >   Thanks so much.
>


-- 
Sarah Goslee (she/her)
http://www.numberwright.com



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Nov  5 16:40:48 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 05 Nov 2018 07:40:48 -0800
Subject: [R] potential issue in download.file() help page
In-Reply-To: <eacfd944-b102-448a-d4ea-970cd399560f@member.fsf.org>
References: <5f6e0b7d-8edf-2212-ed49-2d9d4e46f12f@member.fsf.org>
 <B1B953B6-BCBA-4E2C-A958-FAF3E7591907@dcn.davis.ca.us>
 <eacfd944-b102-448a-d4ea-970cd399560f@member.fsf.org>
Message-ID: <C12E365C-991B-4FBC-859B-8ED4F29E0292@dcn.davis.ca.us>

cc'ing the list for archive thread closure and possible additional comments.

My own preference leans toward simple default values as well, but if you are hoping to warn students about alternative interpretations of function signatures then be sure to point out the match.arg [1][2] convention also, in which the function author can specify that the default value listed in the signature is a vector of values that is interpreted to constrain the legal values that can be specified for an argument and omitting any value for that argument defaults to the function assuming the first value in the vector. This behavior relies on some advanced features of R to work (how does the function refer to both the user-specified argument values and the programmer's default vector at the same time?) so it tends to look like magic to a beginner. I think it looks inconsistent, but it is fairly common and students should be forewarned that it represents one of the four (I think) ways default arguments might be portrayed in a function signature: simple, missing, match.arg, and ellipsis.

Ellipsis arguments are indicated with ... and you have to read the documentation (usually via See Also) to know what other function documentation you need to read in order to find all possible argument and default signatures. The read.csv function is a classic example where you need to know that it is a wrapper around read.table and (almost) any of the arguments to read.table may be specified when calling read.csv. (Read.csv forces some arguments to specific values to enforce the definition of that format.)

[1] https://stat.ethz.ch/R-manual/R-devel/library/base/html/match.arg.html

[2] http://mazamascience.com/WorkingWithData/?p=1659


On November 5, 2018 3:38:14 AM PST, "St?phane Guillou" <stephane.guillou at member.fsf.org> wrote:
>Hi Jeff
>
>Thank you very much for the explanation.
>
>In my experience (i.e. from what I have seen so far in a few years of 
>using R), this is such an unusual way to set a default that I thought
>it 
>was a solid rule that arguments without a default value in "Usage"
>meant 
>the user absolutely had to specify a value.
>
>Good to know that it is not a strict rule, but unfortunate it's making 
>it slightly less straight-forward for my students! :)
>
>Cheers, all the best
>
>On 5/11/18 3:20 pm, Jeff Newmiller wrote:
>> The documentation describes the behavior of the program. The function
>signature shows how the arguments are declared. Both are correct.
>>
>> If you read an implementation [1] you will see that the missing()
>function is used to implement the described behavior, rather than using
>a default value for the argument. I don't know why this choice was made
>(changes in language over time?), but setting up argument default
>values is only one way to accomplish the described behavior.
>>
>> [1]
>https://github.com/wch/r-source/blob/trunk/src/library/utils/R/windows/download.file.R
>>
>> On November 4, 2018 4:56:19 PM PST, "St?phane Guillou"
><stephane.guillou at member.fsf.org> wrote:
>>> Hi there
>>>
>>> I was told by Martin Maechler that I should send this request to
>R-help
>>>
>>> rather than R-core, so here it is.
>>>
>>> I noticed that the download.file() documentation does not show a
>>> default
>>> value passed on to the `method` argument in the "Usage" section,
>even
>>> though it is stated underneath that the default method is `"auto"`.
>>>
>>> Does this need fixing?
>>>
>>> Cheers

-- 
Sent from my phone. Please excuse my brevity.



From robertburb|dged@t@ @end|ng |rom y@hoo@co@uk  Mon Nov  5 14:24:25 2018
From: robertburb|dged@t@ @end|ng |rom y@hoo@co@uk (Robert David Burbidge Ltd)
Date: Mon, 5 Nov 2018 13:24:25 +0000
Subject: [R] POS counting number of verbs
In-Reply-To: <1401187708.1569005.1541421497267@mail.yahoo.com>
References: <1401187708.1569005.1541421497267.ref@mail.yahoo.com>
 <1401187708.1569005.1541421497267@mail.yahoo.com>
Message-ID: <e808e4b3-12fe-de2c-7882-b530ce977a98@yahoo.co.uk>

Hi Elahe,

First, please post in plain text and make sure the code in your message 
is properly formatted.

Second, please state which libraries you are using.

Third, your problem appears to be with empty Messages, this can be 
resolved as follows.

 >>>>>>>>>>>
tar <- data.frame(Message=c("","'alter database? datafile' needs to be 
executed"), group=c("1","2"),
 ????????????????? stringsAsFactors=TRUE)
str(tar)

library(openNLP)
library(NLP)

tagPOS <- function(x, ...) {
 ? s <- as.String(x)
 ? if(s=="") return(list())
 ? word_token_annotator <- Maxent_Word_Token_Annotator()
 ? a2 <- Annotation(1L, "sentence", 1L, nchar(s))
 ? a2 <- annotate(s, word_token_annotator, a2)
 ? a3 <- annotate(s, Maxent_POS_Tag_Annotator(), a2)
 ? a3w <- a3[a3$type == "word"]
 ? POStags <- unlist(lapply(a3w$features, `[[`, "POS"))
 ? POStagged <- paste(sprintf("%s/%s", s[a3w], POStags), collapse = " ")
 ? list(POStagged = POStagged, POStags = POStags)
}

count_verbs <-function(x) {
 ? pos_tags <- tagPOS(x)$POStags
 ? sum(grepl("VB", pos_tags))
}

library(dplyr)

tar %>% group_by(group) %>% summarise(num_verbs = count_verbs(Message))
<<<<<<<<<<<<<<<<

Rgds,
Robert

On 05/11/18 12:38, Elahe chalabi via R-help wrote:
> Hi all, I have 16630 Messages in my data frame and I would like to 
> count number of verbs in each message, to do so I have the following 
> code:
>> str(tar) 
> 'data.frame': 16630 obs. of? 2 variables: $ Message? ? ? ? ? ? : 
> Factor w/ 13412 levels "","'alter database? datafile' needs to be 
> executed",..: 11163 1 9715 10110 9683 11364 12952 2242 7153 6907 ... $ 
> group? ? ? ? ? ? ? ? ? ?: Factor w/ 16630 levels "1","2","3","4",..: 1 
> 2 3 4 5 6 7 8 9 10 ...
>> tagPOS <-? function(x, ...) {+ ?s <- as.String(x)+? ? 
>> ?word_token_annotator <- Maxent_Word_Token_Annotator()+? ? ?a2 <- 
>> Annotation(1L, "sentence", 1L, nchar(s))+? ? ?a2 <- annotate(s, 
>> word_token_annotator, a2)+? ? ?a3 <- annotate(s, 
>> Maxent_POS_Tag_Annotator(), a2)+? ? ?a3w <- a3[a3$type == "word"]+? ? 
>> ?POStags <- unlist(lapply(a3w$features, `[[`, "POS"))+? ? ?POStagged 
>> <- paste(sprintf("%s/%s", s[a3w], POStags), collapse = " ")+? ? 
>> ?list(POStagged = POStagged, POStags = POStags)+ }> count_verbs 
>> <-function(x) {+ ?pos_tags <- tagPOS(x)$POStags+? ? ?sum(grepl("VB", 
>> pos_tags))+ }> library(dplyr)> tar %>%?+ ?group_by(group) %>%+? ? 
>> ?summarise(num_verbs = count_verbs(Message)) 
> And here is the error I get:Error in summarise_impl(.data, dots) :?? 
> Evaluation error: no word token annotations found. Does anyone know 
> about this error??Thanks for any help.Elahe [[alternative HTML version 
> deleted]] ______________________________________________ 
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the 
> posting guide http://www.R-project.org/posting-guide.html and provide 
> commented, minimal, self-contained, reproducible code.



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Mon Nov  5 20:00:35 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (JEFFERY REICHMAN)
Date: Mon, 5 Nov 2018 19:00:35 +0000 (UTC)
Subject: [R] Importing JSON Files
References: <1943347829.1115355.1541444435241.ref@mail.yahoo.com>
Message-ID: <1943347829.1115355.1541444435241@mail.yahoo.com>

r-help Forum

Struggling with importing and creating a data.fram from a JSON file.  I used the jsonlite package (fromJSON function) and I can see the resulting table but one of the attributes is a list (of lists) So I have something that looks like .....

favorites (attribute)
list(favoriteValue = c("12345", 23456"), resourceType = c("abc", "def"), classification = c("xxx","yyy"))

So when I attempt to create a data.frame R errors out.  I'm assuming it is because of the list(s).  Don't know what to do with it (the list).  I need the "favoriteValue (s)."

Ultimate I want to run the arules package

Jeff Reichman



From m@||||@t@ @end|ng |rom pp@|net@||  Mon Nov  5 20:14:10 2018
From: m@||||@t@ @end|ng |rom pp@|net@|| (K. Elo)
Date: Mon, 05 Nov 2018 21:14:10 +0200
Subject: [R] Importing JSON Files
In-Reply-To: <1943347829.1115355.1541444435241@mail.yahoo.com>
References: <1943347829.1115355.1541444435241.ref@mail.yahoo.com>
 <1943347829.1115355.1541444435241@mail.yahoo.com>
Message-ID: <9d9bd4dd3995bb7a84dfab174812a864d3bc6b2e.camel@pp.inet.fi>

Hi!

Have you tried to use 'fromJSON' with the parameter 'simplifyDataFrame'
set to TRUE?

See: 
https://cran.r-project.org/web/packages/jsonlite/vignettes/json-aaquickstart.html
 -> Section "Data Frames" explains how this affects the data frame
structure. IMHO this should solve your problem...

Best,
Kimmo

2018-11-05 19:00 +0000, JEFFERY REICHMAN wrote:
> r-help Forum
> 
> Struggling with importing and creating a data.fram from a JSON
> file.  I used the jsonlite package (fromJSON function) and I can see
> the resulting table but one of the attributes is a list (of lists) So
> I have something that looks like .....
> 
> favorites (attribute)
> list(favoriteValue = c("12345", 23456"), resourceType = c("abc",
> "def"), classification = c("xxx","yyy"))
> 
> So when I attempt to create a data.frame R errors out.  I'm assuming
> it is because of the list(s).  Don't know what to do with it (the
> list).  I need the "favoriteValue (s)."
> 
> Ultimate I want to run the arules package
> 
> Jeff Reichman
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From kry|ov@r00t @end|ng |rom gm@||@com  Mon Nov  5 20:34:02 2018
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 5 Nov 2018 22:34:02 +0300
Subject: [R] Encoding issue
In-Reply-To: <2076839781.1608507.1541424973246.JavaMail.zimbra@cognigencorp.com>
References: <2076839781.1608507.1541424973246.JavaMail.zimbra@cognigencorp.com>
Message-ID: <20181105223402.445401c0@Tarkus>

On Mon, 5 Nov 2018 08:36:13 -0500 (EST)
Sebastien Bihorel <sebastien.bihorel at cognigencorp.com> wrote:

> [1] "r?s"

Interesting. This is what I get if I decode the bytes 72 e2 80 99 73 0a
as latin-1 instead of UTF-8. They look like there is only three
characters, but, actually, there is more:

$ perl -CSD -Mcharnames=:full -MEncode=decode \
 -E'for (split //, decode latin1 => pack "H*", "72e28099730a")
 { say ord, " ", $_, " ", charnames::viacode(ord) }'
114 r LATIN SMALL LETTER R
226 ? LATIN SMALL LETTER A WITH CIRCUMFLEX
128  PADDING CHARACTER
153  SINGLE GRAPHIC CHARACTER INTRODUCER
115 s LATIN SMALL LETTER S
10 
 LINE FEED

Does it help if you explicitly specify the file encoding by passing
fileEncoding="UTF-8" argument to scan()?

-- 
Best regards,
Ivan



From @eb@@t|en@b|hore| @end|ng |rom cogn|gencorp@com  Mon Nov  5 21:18:56 2018
From: @eb@@t|en@b|hore| @end|ng |rom cogn|gencorp@com (Sebastien Bihorel)
Date: Mon, 5 Nov 2018 15:18:56 -0500 (EST)
Subject: [R] Encoding issue
In-Reply-To: <20181105223402.445401c0@Tarkus>
References: <2076839781.1608507.1541424973246.JavaMail.zimbra@cognigencorp.com>
 <20181105223402.445401c0@Tarkus>
Message-ID: <927769748.1644602.1541449136643.JavaMail.zimbra@cognigencorp.com>


Hi Ivan,

0xe2 0x80 0x99 seems to be the UTF-8 hex code for Unicode Character 'RIGHT SINGLE QUOTATION MARK', which would make sense in the context.

Using the encoding argument for the scan call does not change the outcome.

Looking at the server side a bit more, some colleagues pointed out that the "r?s" display could be a side-effect of encoding issue with Putty (which I used to connect to the remote server). Changing the setting of Putty display, I get the correct display "r?s"... However, that does not change anything to the gsub issue...

Sebastien

----- Original Message -----
From: "Ivan Krylov" <krylov.r00t at gmail.com>
To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>
Cc: r-help at r-project.org
Sent: Monday, November 5, 2018 2:34:02 PM
Subject: Re: [R] Encoding issue

On Mon, 5 Nov 2018 08:36:13 -0500 (EST)
Sebastien Bihorel <sebastien.bihorel at cognigencorp.com> wrote:

> [1] "r?s"

Interesting. This is what I get if I decode the bytes 72 e2 80 99 73 0a
as latin-1 instead of UTF-8. They look like there is only three
characters, but, actually, there is more:

$ perl -CSD -Mcharnames=:full -MEncode=decode \
 -E'for (split //, decode latin1 => pack "H*", "72e28099730a")
 { say ord, " ", $_, " ", charnames::viacode(ord) }'
114 r LATIN SMALL LETTER R
226 ? LATIN SMALL LETTER A WITH CIRCUMFLEX
128  PADDING CHARACTER
153  SINGLE GRAPHIC CHARACTER INTRODUCER
115 s LATIN SMALL LETTER S
10 
 LINE FEED

Does it help if you explicitly specify the file encoding by passing
fileEncoding="UTF-8" argument to scan()?

-- 
Best regards,
Ivan



From b|cr@p @end|ng |rom gm@||@com  Mon Nov  5 22:53:42 2018
From: b|cr@p @end|ng |rom gm@||@com (Ben)
Date: Mon, 5 Nov 2018 13:53:42 -0800
Subject: [R] R command prompt newline treatment
Message-ID: <CAMJGS4qE7zYyXO5Zg6qRCZ8KgEmQWD0-Ms1zYN5SXkSSrV7yTQ@mail.gmail.com>

Hi all -

I?m seeing a weird issue. I?m running R v3.3.2 on CentOS 7 Linux. The
behavior of the command prompt when entering very long commands on a single
line is strange compared to my use in older versions. Specifically, after
hitting enter, the prompt continues on the line immediately after the
previous prompt. In other words, it skips back up past all of the previous
input on that one wrapped line.

One way to see it clearly is to force it to display many newline characters
with ctrl-v ctrl-j and then hit enter. In bash and my earlier R console,
the new prompt is right at the end of the newline sequence, but in the new
versions the prompt jumps back up to the line after the previous prompt.

If anyone has ideas on whats going on, I?d love to hear them! Thanks,

Ben

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Nov  5 23:44:08 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 05 Nov 2018 14:44:08 -0800
Subject: [R] R command prompt newline treatment
In-Reply-To: <CAMJGS4qE7zYyXO5Zg6qRCZ8KgEmQWD0-Ms1zYN5SXkSSrV7yTQ@mail.gmail.com>
References: <CAMJGS4qE7zYyXO5Zg6qRCZ8KgEmQWD0-Ms1zYN5SXkSSrV7yTQ@mail.gmail.com>
Message-ID: <4D3DE05E-B208-45BC-B696-9536D3C1D3A2@dcn.davis.ca.us>

I am pretty sure this is not an R issue (so it is off-topic here)... it sounds like the kind of misconfiguration that was common back when there were dozens of competing terminal manufacturers and the solution was to configure your Linux TERM variable and/or terminfo database to match up with your terminal emulator program (e.g. [1]). With modem autocofiguration on the OS side it may be as simple as changing your terminal emulator settings and logging in again... or not.

[1] https://www.tldp.org/HOWTO/Text-Terminal-HOWTO-7.html

On November 5, 2018 1:53:42 PM PST, Ben <bfcrap at gmail.com> wrote:
>Hi all -
>
>I?m seeing a weird issue. I?m running R v3.3.2 on CentOS 7 Linux. The
>behavior of the command prompt when entering very long commands on a
>single
>line is strange compared to my use in older versions. Specifically,
>after
>hitting enter, the prompt continues on the line immediately after the
>previous prompt. In other words, it skips back up past all of the
>previous
>input on that one wrapped line.
>
>One way to see it clearly is to force it to display many newline
>characters
>with ctrl-v ctrl-j and then hit enter. In bash and my earlier R
>console,
>the new prompt is right at the end of the newline sequence, but in the
>new
>versions the prompt jumps back up to the line after the previous
>prompt.
>
>If anyone has ideas on whats going on, I?d love to hear them! Thanks,
>
>Ben
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From b|cr@p @end|ng |rom gm@||@com  Tue Nov  6 00:12:59 2018
From: b|cr@p @end|ng |rom gm@||@com (Ben)
Date: Mon, 5 Nov 2018 15:12:59 -0800
Subject: [R] R command prompt newline treatment
In-Reply-To: <4D3DE05E-B208-45BC-B696-9536D3C1D3A2@dcn.davis.ca.us>
References: <CAMJGS4qE7zYyXO5Zg6qRCZ8KgEmQWD0-Ms1zYN5SXkSSrV7yTQ@mail.gmail.com>
 <4D3DE05E-B208-45BC-B696-9536D3C1D3A2@dcn.davis.ca.us>
Message-ID: <CAMJGS4pmk0Wb2yO-UrXCyw0uW5T5xEWnfY+XxD7mtbGKM-n1UA@mail.gmail.com>

Hi Jeff - thanks.  I forgot to add originally that I use putty as a
terminal for the old version of R I mentioned as well as the new, and also
I can see the same issue with the new version of R when run in xterm.  I?ve
messed with some of the options putty offers and it doesnt change the new R
behavior. Also this behavior does not occur at the shell prompt, or in
other prompts, like interactive python. So while I agree that it doesnt
seem like an R issue on the surface, it only happens in R as far as I can
tell!


On Mon, Nov 5, 2018 at 2:44 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I am pretty sure this is not an R issue (so it is off-topic here)... it
> sounds like the kind of misconfiguration that was common back when there
> were dozens of competing terminal manufacturers and the solution was to
> configure your Linux TERM variable and/or terminfo database to match up
> with your terminal emulator program (e.g. [1]). With modem autocofiguration
> on the OS side it may be as simple as changing your terminal emulator
> settings and logging in again... or not.
>
> [1] https://www.tldp.org/HOWTO/Text-Terminal-HOWTO-7.html
>
> On November 5, 2018 1:53:42 PM PST, Ben <bfcrap at gmail.com> wrote:
> >Hi all -
> >
> >I?m seeing a weird issue. I?m running R v3.3.2 on CentOS 7 Linux. The
> >behavior of the command prompt when entering very long commands on a
> >single
> >line is strange compared to my use in older versions. Specifically,
> >after
> >hitting enter, the prompt continues on the line immediately after the
> >previous prompt. In other words, it skips back up past all of the
> >previous
> >input on that one wrapped line.
> >
> >One way to see it clearly is to force it to display many newline
> >characters
> >with ctrl-v ctrl-j and then hit enter. In bash and my earlier R
> >console,
> >the new prompt is right at the end of the newline sequence, but in the
> >new
> >versions the prompt jumps back up to the line after the previous
> >prompt.
> >
> >If anyone has ideas on whats going on, I?d love to hear them! Thanks,
> >
> >Ben
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Nov  6 03:47:00 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 05 Nov 2018 18:47:00 -0800
Subject: [R] R command prompt newline treatment
In-Reply-To: <CAMJGS4pmk0Wb2yO-UrXCyw0uW5T5xEWnfY+XxD7mtbGKM-n1UA@mail.gmail.com>
References: <CAMJGS4qE7zYyXO5Zg6qRCZ8KgEmQWD0-Ms1zYN5SXkSSrV7yTQ@mail.gmail.com>
 <4D3DE05E-B208-45BC-B696-9536D3C1D3A2@dcn.davis.ca.us>
 <CAMJGS4pmk0Wb2yO-UrXCyw0uW5T5xEWnfY+XxD7mtbGKM-n1UA@mail.gmail.com>
Message-ID: <99AC9E8B-587B-466A-9B4B-E1A8FCE2F723@dcn.davis.ca.us>

Well, you may or may not have ruled out the Putty settings (your hand waving is a bit hard for me to interpret), and there may still be host side terminal settings involved, or if you compiled R yourself you may have setup something wrong. However, in either case the R-sig-fedora mailing list would be more appropriate than R-help for discussing configure options under Red Hat-derived distributions.

On November 5, 2018 3:12:59 PM PST, Ben <bfcrap at gmail.com> wrote:
>Hi Jeff - thanks.  I forgot to add originally that I use putty as a
>terminal for the old version of R I mentioned as well as the new, and
>also
>I can see the same issue with the new version of R when run in xterm. 
>I?ve
>messed with some of the options putty offers and it doesnt change the
>new R
>behavior. Also this behavior does not occur at the shell prompt, or in
>other prompts, like interactive python. So while I agree that it doesnt
>seem like an R issue on the surface, it only happens in R as far as I
>can
>tell!
>
>
>On Mon, Nov 5, 2018 at 2:44 PM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> I am pretty sure this is not an R issue (so it is off-topic here)...
>it
>> sounds like the kind of misconfiguration that was common back when
>there
>> were dozens of competing terminal manufacturers and the solution was
>to
>> configure your Linux TERM variable and/or terminfo database to match
>up
>> with your terminal emulator program (e.g. [1]). With modem
>autocofiguration
>> on the OS side it may be as simple as changing your terminal emulator
>> settings and logging in again... or not.
>>
>> [1] https://www.tldp.org/HOWTO/Text-Terminal-HOWTO-7.html
>>
>> On November 5, 2018 1:53:42 PM PST, Ben <bfcrap at gmail.com> wrote:
>> >Hi all -
>> >
>> >I?m seeing a weird issue. I?m running R v3.3.2 on CentOS 7 Linux.
>The
>> >behavior of the command prompt when entering very long commands on a
>> >single
>> >line is strange compared to my use in older versions. Specifically,
>> >after
>> >hitting enter, the prompt continues on the line immediately after
>the
>> >previous prompt. In other words, it skips back up past all of the
>> >previous
>> >input on that one wrapped line.
>> >
>> >One way to see it clearly is to force it to display many newline
>> >characters
>> >with ctrl-v ctrl-j and then hit enter. In bash and my earlier R
>> >console,
>> >the new prompt is right at the end of the newline sequence, but in
>the
>> >new
>> >versions the prompt jumps back up to the line after the previous
>> >prompt.
>> >
>> >If anyone has ideas on whats going on, I?d love to hear them!
>Thanks,
>> >
>> >Ben
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.


From m@echler @ending from @t@t@m@th@ethz@ch  Tue Nov  6 09:32:47 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 6 Nov 2018 09:32:47 +0100
Subject: [R] R command prompt newline treatment
In-Reply-To: <99AC9E8B-587B-466A-9B4B-E1A8FCE2F723@dcn.davis.ca.us>
References: <CAMJGS4qE7zYyXO5Zg6qRCZ8KgEmQWD0-Ms1zYN5SXkSSrV7yTQ@mail.gmail.com>
 <4D3DE05E-B208-45BC-B696-9536D3C1D3A2@dcn.davis.ca.us>
 <CAMJGS4pmk0Wb2yO-UrXCyw0uW5T5xEWnfY+XxD7mtbGKM-n1UA@mail.gmail.com>
 <99AC9E8B-587B-466A-9B4B-E1A8FCE2F723@dcn.davis.ca.us>
Message-ID: <23521.20911.570865.109761@stat.math.ethz.ch>

>>>>> Jeff Newmiller 
>>>>>     on Mon, 5 Nov 2018 18:47:00 -0800 writes:

    > Well, you may or may not have ruled out the Putty settings
    > (your hand waving is a bit hard for me to interpret), and
    > there may still be host side terminal settings involved,
    > or if you compiled R yourself you may have setup something
    > wrong. However, in either case the R-sig-fedora mailing
    > list would be more appropriate than R-help for discussing
    > configure options under Red Hat-derived distributions.  

Also, why are you using R 3.3.2  when current R is 3.5.1 ?

Even if there might have been problematic behavior of R's
"console" in that version of R, we will not be able to improve
that version retrospectively... but rather the next version of
R.

So please update your R to 3.5.1 (or even "R-devel" ideally, for
checking about potential bugs).

    > On November 5, 2018 3:12:59 PM PST, Ben <bfcrap at gmail.com>
    > wrote:
    >> Hi Jeff - thanks.  I forgot to add originally that I use
    >> putty as a terminal for the old version of R I mentioned
    >> as well as the new, and also I can see the same issue
    >> with the new version of R when run in xterm.  I?ve messed
    >> with some of the options putty offers and it doesnt
    >> change the new R behavior. Also this behavior does not
    >> occur at the shell prompt, or in other prompts, like
    >> interactive python. So while I agree that it doesnt seem
    >> like an R issue on the surface, it only happens in R as
    >> far as I can tell!
    >> 
    >> 
    >> On Mon, Nov 5, 2018 at 2:44 PM Jeff Newmiller
    >> <jdnewmil at dcn.davis.ca.us> wrote:
    >> 
    >>> I am pretty sure this is not an R issue (so it is
    >>> off-topic here)...
    >> it
    >>> sounds like the kind of misconfiguration that was common
    >>> back when
    >> there
    >>> were dozens of competing terminal manufacturers and the
    >>> solution was
    >> to
    >>> configure your Linux TERM variable and/or terminfo
    >>> database to match
    >> up
    >>> with your terminal emulator program (e.g. [1]). With
    >>> modem
    >> autocofiguration
    >>> on the OS side it may be as simple as changing your
    >>> terminal emulator settings and logging in again... or
    >>> not.
    >>> 
    >>> [1]
    >>> https://www.tldp.org/HOWTO/Text-Terminal-HOWTO-7.html
    >>> 
    >>> On November 5, 2018 1:53:42 PM PST, Ben
    >>> <bfcrap at gmail.com> wrote: >Hi all -
    >>> >
    >>> >I?m seeing a weird issue. I?m running R v3.3.2 on
    >>> CentOS 7 Linux.
    >> The
    >>> >behavior of the command prompt when entering very long
    >>> commands on a >single >line is strange compared to my
    >>> use in older versions. Specifically, >after >hitting
    >>> enter, the prompt continues on the line immediately
    >>> after
    >> the
    >>> >previous prompt. In other words, it skips back up past
    >>> all of the >previous >input on that one wrapped line.
    >>> >
    >>> >One way to see it clearly is to force it to display
    >>> many newline >characters >with ctrl-v ctrl-j and then
    >>> hit enter. In bash and my earlier R >console, >the new
    >>> prompt is right at the end of the newline sequence, but
    >>> in
    >> the
    >>> >new >versions the prompt jumps back up to the line
    >>> after the previous >prompt.
    >>> >
    >>> >If anyone has ideas on whats going on, I?d love to hear
    >>> them!
    >> Thanks,
    >>> >
    >>> >Ben
    >>> >
    >>> > [[alternative HTML version deleted]]
    >>> >
    >>> >______________________________________________
    >>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >>> more, see >https://stat.ethz.ch/mailman/listinfo/r-help
    >>> >PLEASE do read the posting guide
    >>> >http://www.R-project.org/posting-guide.html >and
    >>> provide commented, minimal, self-contained, reproducible
    >>> code.
    >>> 
    >>> --
    >>> Sent from my phone. Please excuse my brevity.
    >>> 

    > -- 
    > Sent from my phone. Please excuse my brevity.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From ch@l@bi@el@he @ending from y@hoo@de  Tue Nov  6 11:26:04 2018
From: ch@l@bi@el@he @ending from y@hoo@de (Elahe chalabi)
Date: Tue, 6 Nov 2018 10:26:04 +0000 (UTC)
Subject: [R] POS tagging generating a string
References: <1394154020.2564506.1541499964758.ref@mail.yahoo.com>
Message-ID: <1394154020.2564506.1541499964758@mail.yahoo.com>

Hi all,

In my df I would like to generate a new column which contains a string showing all the verbs in each row of df$Message.



> library(openNLP) 
> library(NLP) 
> dput(df) 
structure(list(DocumentID = c(478920L, 510133L, 499497L, 930234L 
), Message = structure(c(4L, 2L, 3L, 1L), .Label = c("Thank you very much for your nice feedback.\n", 
"THank you, added it", "Thanks for the well explained article.", 
"The solution has been updated"), class = "factor")), class = "data.frame", row.names = c(NA, 
-4L)) 

tagPOS <-  function(x, ...) { 
s <- as.String(x) 
word_token_annotator <- Maxent_Word_Token_Annotator() 
a2 <- Annotation(1L, "sentence", 1L, nchar(s)) 
a2 <- annotate(s, word_token_annotator, a2) 
a3 <- annotate(s, Maxent_POS_Tag_Annotator(), a2) 
a3w <- a3[a3$type == "word"] 
POStags <- unlist(lapply(a3w$features, `[[`, "POS")) 
POStagged <- paste(sprintf("%s/%s", s[a3w], POStags), collapse = " ") 
list(POStagged = POStagged, POStags = POStags) 
} 



Any help?
Thanks in advance!
Elahe


From d@v@@job @ending from gm@il@com  Mon Nov  5 21:03:16 2018
From: d@v@@job @ending from gm@il@com (=?utf-8?Q?David_sj=C3=B6berg?=)
Date: Mon, 5 Nov 2018 21:03:16 +0100
Subject: [R] [R-pkgs] Repost: New CRAN package: hablar
Message-ID: <7C49886C-DF20-4FBD-939F-CD80DAB19403@gmail.com>

Dear R-users,

The new package hablar help R-users to convert columns to new data types. 
Also helps with summary functions like min and mean with vectors that contain NA, Inf, NaN or when they are empty.

Three functions you may consider to use:
  
install.packages("hablar")
library(hablar)


1. convert()

mtcars %>%
  convert(num(vs),
          int(am, gear),
          chr(cyl:drat))

this simple code chunk converts column 'vs' to numeric, 
'am' and 'gear' to integer and 'cyl' through 'drat' to character.


2. retype()

mtcars <- mtcars %>%
  convert(chr(everything()))

mtcars %>% retype()

This function is for us lazy R-programmers. It converts columns 
to the simplest data type possible, without loosing information.

3. s()

min(c()) # base R returns Inf
min(s(c())) # with s it returns NA

max(c(NaN, Inf)) # base R returns NaN
max(s(c(NaN, Inf))) # with s it returns NA

mean(c(NA, 2, 4, NA)) # base R returns NA
mean(c(NA, 2, 4, NA), na.rm = TRUE) # base R with na.rm = T returns 3
mean(s(c(NA, 2, 4, NA))) # with s it returns 3 without using na.rm = TRUE
mean_(c(NA, 2, 4, NA)) # s-wrapper mean_  returns 3

s always returns a real value, otherwise NA. This helps you
avoid the problem of getting Inf when trying to minimize 
empty or vectors with infinite or NaN values. You can also skip na.rm = T
to simplify code syntax.


More information on hablar:
https://cran.r-project.org/web/packages/hablar/readme/README.html
https://github.com/davidsjoberg/hablar
https://davidsjoberg.github.io/blog/
  
Happy coding!
David

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From reichm@nj @ending from @bcglob@l@net  Tue Nov  6 20:06:44 2018
From: reichm@nj @ending from @bcglob@l@net (JEFFERY REICHMAN)
Date: Tue, 6 Nov 2018 19:06:44 +0000 (UTC)
Subject: [R] jsonlite
References: <318996031.499481.1541531204356.ref@mail.yahoo.com>
Message-ID: <318996031.499481.1541531204356@mail.yahoo.com>

r-help Forum

With a bit of r-help yesterday I was able to structure a JSON file such that I can read it within the R environment and export what I need except for one list object.

So when I run ....

location <- json.raw[["favorites"]]
thead(location)

# R returns something like ...

[[1]]
  favoriteValue          favoriteType          Classification
1          23527           https:// .....                xxxx
2          21837           https:// .....                xyxy

[[2]]
  favoriteValue          favoriteType          Classification
1          25427           https:// .....                xxxx
2          21237           https:// .....                xyxy
3          21997           https:// .....                xyxy

[[3]]
  favoriteValue          favoriteType          Classification
1          99427           https:// .....                xxxx


What I want (need) is a data frame that looks like 

    favoriteValue
1  23527, 21837
2  25427, 21237, 21997
3  99427

Jeff Reichman


From wdunl@p @ending from tibco@com  Tue Nov  6 20:41:04 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Tue, 6 Nov 2018 11:41:04 -0800
Subject: [R] jsonlite
In-Reply-To: <318996031.499481.1541531204356@mail.yahoo.com>
References: <318996031.499481.1541531204356.ref@mail.yahoo.com>
 <318996031.499481.1541531204356@mail.yahoo.com>
Message-ID: <CAF8bMcYtWkGn3_K1hyONSWitFNFSKF+0bNFvyxQDsioNWhgT8g@mail.gmail.com>

It would make helping you easier if you presented your data
in a format that others could copy and paste into R.  E.g.,

z <- list(data.frame(favoriteValue=c(23527,21837),
Classification=c("xxxx","xyxy")),
           data.frame(favoriteValue=c(25427,21237,21997),
Classification=c("xxxx","xyxy","xyxy")),
           data.frame(favoriteValue=c(99427), Classification=c("xxxx")))

You asked from something that "looks like" comma-separated strings of
numerals.

> zAll <- do.call(rbind, z)
> zAll$ID <- rep(seq_along(z), vapply(z, nrow, 0)) # which data.frame each
row came from
> zAll
  favoriteValue Classification ID
1         23527           xxxx  1
2         21837           xyxy  1
3         25427           xxxx  2
4         21237           xyxy  2
5         21997           xyxy  2
6         99427           xxxx  3
> library(dplyr)
> zAll %>% group_by(ID) %>% summarize(favoriteValue = paste(favoriteValue,
collapse=","))
# A tibble: 3 x 2
     ID favoriteValue
  <int> <chr>
1     1 23527,21837
2     2 25427,21237,21997
3     3 99427

It is usually better say how you intend the use the result of your data
manipulation, rather that how it looks when printed.  The comma-separated
strings are not handy for answering questions like "what are the most
common favoriteValues?" or "who has the most favoriteValues?" - the format
used in zAll is better for that.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Nov 6, 2018 at 11:06 AM, JEFFERY REICHMAN <reichmanj at sbcglobal.net>
wrote:

> r-help Forum
>
> With a bit of r-help yesterday I was able to structure a JSON file such
> that I can read it within the R environment and export what I need except
> for one list object.
>
> So when I run ....
>
> location <- json.raw[["favorites"]]
> thead(location)
>
> # R returns something like ...
>
> [[1]]
>   favoriteValue          favoriteType          Classification
> 1          23527           https:// .....                xxxx
> 2          21837           https:// .....                xyxy
>
> [[2]]
>   favoriteValue          favoriteType          Classification
> 1          25427           https:// .....                xxxx
> 2          21237           https:// .....                xyxy
> 3          21997           https:// .....                xyxy
>
> [[3]]
>   favoriteValue          favoriteType          Classification
> 1          99427           https:// .....                xxxx
>
>
> What I want (need) is a data frame that looks like
>
>     favoriteValue
> 1  23527, 21837
> 2  25427, 21237, 21997
> 3  99427
>
> Jeff Reichman
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From miluji@b @ending from gm@il@com  Tue Nov  6 22:01:27 2018
From: miluji@b @ending from gm@il@com (Miluji Sb)
Date: Tue, 6 Nov 2018 22:01:27 +0100
Subject: [R] Obtain coordinates for city names
Message-ID: <CAMLwc7OLUvka7oXxynYWBAeA4UFU2ermR1ta1M-V3unQigTvNA@mail.gmail.com>

I have a dataframe (more than 50,000 observations), of cities in the EU.

My goal is to assign NUTS-2 code to each of these cities. However, I am not
aware of any direct way of achieving this, so I wanted to first assign
coordinates to the cities and then use the 'over' function to match with
NUTS regions from EU shapefile.

I have tried to use 'geocode' from the ggmap package but there is a 2,500
per day limit. Is there any other solution? Any help will be greatly
appreciated.

Cross-posed yesterday on r-sig-ge,

Sincerely,

Milu

	[[alternative HTML version deleted]]


From reichm@nj @ending from @bcglob@l@net  Tue Nov  6 22:57:31 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Tue, 6 Nov 2018 15:57:31 -0600
Subject: [R] Importing JSON Files
In-Reply-To: <9d9bd4dd3995bb7a84dfab174812a864d3bc6b2e.camel@pp.inet.fi>
References: <1943347829.1115355.1541444435241.ref@mail.yahoo.com>
 <1943347829.1115355.1541444435241@mail.yahoo.com>
 <9d9bd4dd3995bb7a84dfab174812a864d3bc6b2e.camel@pp.inet.fi>
Message-ID: <000001d4761b$b7e5eb00$27b1c100$@sbcglobal.net>

Kimmo

Didn't perform exactly how I wanted but got me looking in the right area.
Thank you

Jeff

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of K. Elo
Sent: Monday, November 5, 2018 1:14 PM
To: r-help at r-project.org
Subject: Re: [R] Importing JSON Files

Hi!

Have you tried to use 'fromJSON' with the parameter 'simplifyDataFrame'
set to TRUE?

See: 
https://cran.r-project.org/web/packages/jsonlite/vignettes/json-aaquickstart
.html
 -> Section "Data Frames" explains how this affects the data frame
structure. IMHO this should solve your problem...

Best,
Kimmo

2018-11-05 19:00 +0000, JEFFERY REICHMAN wrote:
> r-help Forum
> 
> Struggling with importing and creating a data.fram from a JSON file.  
> I used the jsonlite package (fromJSON function) and I can see the 
> resulting table but one of the attributes is a list (of lists) So I 
> have something that looks like .....
> 
> favorites (attribute)
> list(favoriteValue = c("12345", 23456"), resourceType = c("abc", 
> "def"), classification = c("xxx","yyy"))
> 
> So when I attempt to create a data.frame R errors out.  I'm assuming 
> it is because of the list(s).  Don't know what to do with it (the 
> list).  I need the "favoriteValue (s)."
> 
> Ultimate I want to run the arules package
> 
> Jeff Reichman
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From m@@ternh@ttt @ending from gm@il@com  Wed Nov  7 00:58:23 2018
From: m@@ternh@ttt @ending from gm@il@com (Thanh Tran)
Date: Wed, 7 Nov 2018 08:58:23 +0900
Subject: [R] Sum of Squares Type I, II, III for ANOVA
Message-ID: <CAHjanSBaqnOU+Ms1icv3aihSVq7H7QgmE6vZt7F_GxuAvDODMw@mail.gmail.com>

Hi everyone,
I'm studying the ANOVA in R and have some questions to share. I investigate
the effects of 4 factors (temperature-3 levels, asphalt content-3 levels,
air voids-2 levels, and sample thickness-3 levels) on the hardness of
asphalt concrete in the tensile test (abbreviated as KIC). These data were
taken from a acticle paper. The codes were wrriten as the follows:

> data = read.csv("Saha research.csv", header =T)
> attach(data)
> tem = as.factor(temperature)
> ac= as.factor (AC)
> av = as.factor(AV)
> thick = as.factor(Thickness)
> model =
lm(KIC~tem+ac+av+thick+tem:ac+tem:av+tem:thick+ac:av+ac:thick+av:thick)
> anova(model) #Type I tests
> library(car) Loading required package: carData >
anova(lm(KIC~tem+ac+av+thick+tem:ac+tem:av+tem:thick+ac:av+ac:thick+av:thick),type=2)
Error: $ operator is invalid for atomic vectors
> options(contrasts = c("contr.sum", "contr.poly"))
> Anova(model,type="3") # Type III tests
> Anova(model,type="2") # Type II tests

With R, three results from Type I, II, and III almost have the same as
follows.

Analysis of Variance Table Response: KIC Df Sum Sq Mean Sq F value Pr(>F)
tem 2 15.3917 7.6958 427.9926 < 2.2e-16 *** ac 2 0.1709 0.0854 4.7510
0.0096967 ** av 1 1.9097 1.9097 106.2055 < 2.2e-16 *** thick 2 0.2041
0.1021 5.6756 0.0040359 ** tem:ac 4 0.5653 0.1413 7.8598 6.973e-06 ***
tem:av 2 1.7192 0.8596 47.8046 < 2.2e-16 *** tem:thick 4 0.0728 0.0182
1.0120 0.4024210 ac:av 2 0.3175 0.1588 8.8297 0.0002154 *** ac:thick 4
0.0883 0.0221 1.2280 0.3003570 av:thick 2 0.0662 0.0331 1.8421 0.1613058
Residuals 190 3.4164 0.0180 --- Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*?
0.05 ?.? 0.1 ? ? 1

However, these results are different from the results in the article,
especially for the interaction (air voids and sample thickness). The
results presented in the article are as follows:
Analysis of variance for KIC, using Adjusted SS for tests. Source DF Seq SS
Adj MS F-stat P-value Model findings Temperature 2 15.39355 7.69677 426.68
<0.01 Significant AC 2 0.95784 0.47892 26.55 <0.01 Significant AV 1 0.57035
0.57035 31.62 <0.01 Significant Thickness 2 0.20269 0.10135 5.62 <0.01
Significant Temperature?AC 4 1.37762 0.34441 19.09 <0.01 Significant
Temperature?AV 2 0.8329 0.41645 23.09 <0.01 Significant
Temperature?thickness 4 0.07135 0.01784 0.99 0.415 Not significant AC?AV 2
0.86557 0.43279 23.99 <0.01 Significant AC?thickness 4 0.04337 0.01084 0.6
0.662 Not significant AV?thickness 2 0.17394 0.08697 4.82 <0.01 Significant
Error 190 3.42734 0.01804 Total 215 23.91653

Therefore, I wonder that whether there is an error in my code or there is
another type of ANOVA in R. If you could answer my problems, I would be
most grateful.
Best regards,
Nhat Tran
Ps: I also added a CSV file and the paper for practicing R.

From jfox @ending from mcm@@ter@c@  Wed Nov  7 02:41:24 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Wed, 7 Nov 2018 01:41:24 +0000
Subject: [R] Sum of Squares Type I, II, III for ANOVA
In-Reply-To: <29707_1541548741_wA6Nx06M002572_CAHjanSBaqnOU+Ms1icv3aihSVq7H7QgmE6vZt7F_GxuAvDODMw@mail.gmail.com>
References: <29707_1541548741_wA6Nx06M002572_CAHjanSBaqnOU+Ms1icv3aihSVq7H7QgmE6vZt7F_GxuAvDODMw@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83692A359@FHSDB2D11-2.csu.mcmaster.ca>

Dear Nhat Tran,

The output that you show is unreadable and as far as I can see, the data aren't attached, but perhaps the following will help: First, if you want Anova() to compute type III tests, then you have to set the contrasts properly *before* you fit the model, not after. Second, you can specify the model much more compactly as

  mod <- lm(KIC ~ tem*ac + tem*av + tem*thick + ac*av +ac*thick + av*thick)

Finally, as sound general practice, I'd not attach the data, but rather put your recoded variables in the data frame and then specify the data argument to lm().

I hope that this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Thanh Tran
> Sent: Tuesday, November 6, 2018 6:58 PM
> To: r-help at r-project.org
> Subject: [R] Sum of Squares Type I, II, III for ANOVA
> 
> Hi everyone,
> I'm studying the ANOVA in R and have some questions to share. I investigate
> the effects of 4 factors (temperature-3 levels, asphalt content-3 levels, air
> voids-2 levels, and sample thickness-3 levels) on the hardness of asphalt
> concrete in the tensile test (abbreviated as KIC). These data were taken from a
> acticle paper. The codes were wrriten as the follows:
> 
> > data = read.csv("Saha research.csv", header =T)
> > attach(data)
> > tem = as.factor(temperature)
> > ac= as.factor (AC)
> > av = as.factor(AV)
> > thick = as.factor(Thickness)
> > model =
> lm(KIC~tem+ac+av+thick+tem:ac+tem:av+tem:thick+ac:av+ac:thick+av:thick)
> > anova(model) #Type I tests
> > library(car) Loading required package: carData >
> anova(lm(KIC~tem+ac+av+thick+tem:ac+tem:av+tem:thick+ac:av+ac:thick+av
> :thick),type=2)
> Error: $ operator is invalid for atomic vectors
> > options(contrasts = c("contr.sum", "contr.poly"))
> > Anova(model,type="3") # Type III tests
> > Anova(model,type="2") # Type II tests
> 
> With R, three results from Type I, II, and III almost have the same as follows.
> 
> Analysis of Variance Table Response: KIC Df Sum Sq Mean Sq F value Pr(>F)
> tem 2 15.3917 7.6958 427.9926 < 2.2e-16 *** ac 2 0.1709 0.0854 4.7510
> 0.0096967 ** av 1 1.9097 1.9097 106.2055 < 2.2e-16 *** thick 2 0.2041
> 0.1021 5.6756 0.0040359 ** tem:ac 4 0.5653 0.1413 7.8598 6.973e-06 ***
> tem:av 2 1.7192 0.8596 47.8046 < 2.2e-16 *** tem:thick 4 0.0728 0.0182
> 1.0120 0.4024210 ac:av 2 0.3175 0.1588 8.8297 0.0002154 *** ac:thick 4
> 0.0883 0.0221 1.2280 0.3003570 av:thick 2 0.0662 0.0331 1.8421 0.1613058
> Residuals 190 3.4164 0.0180 --- Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*?
> 0.05 ?.? 0.1 ? ? 1
> 
> However, these results are different from the results in the article, especially
> for the interaction (air voids and sample thickness). The results presented in
> the article are as follows:
> Analysis of variance for KIC, using Adjusted SS for tests. Source DF Seq SS Adj
> MS F-stat P-value Model findings Temperature 2 15.39355 7.69677 426.68
> <0.01 Significant AC 2 0.95784 0.47892 26.55 <0.01 Significant AV 1 0.57035
> 0.57035 31.62 <0.01 Significant Thickness 2 0.20269 0.10135 5.62 <0.01
> Significant Temperature?AC 4 1.37762 0.34441 19.09 <0.01 Significant
> Temperature?AV 2 0.8329 0.41645 23.09 <0.01 Significant
> Temperature?thickness 4 0.07135 0.01784 0.99 0.415 Not significant AC?AV 2
> 0.86557 0.43279 23.99 <0.01 Significant AC?thickness 4 0.04337 0.01084 0.6
> 0.662 Not significant AV?thickness 2 0.17394 0.08697 4.82 <0.01 Significant
> Error 190 3.42734 0.01804 Total 215 23.91653
> 
> Therefore, I wonder that whether there is an error in my code or there is
> another type of ANOVA in R. If you could answer my problems, I would be
> most grateful.
> Best regards,
> Nhat Tran
> Ps: I also added a CSV file and the paper for practicing R.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From jfox @ending from mcm@@ter@c@  Wed Nov  7 03:09:05 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Wed, 7 Nov 2018 02:09:05 +0000
Subject: [R] Sum of Squares Type I, II, III for ANOVA
In-Reply-To: <32098_1541554905_wA71fjl8013246_ACD1644AA6C67E4FBD0C350625508EC83692A359@FHSDB2D11-2.csu.mcmaster.ca>
References: <29707_1541548741_wA6Nx06M002572_CAHjanSBaqnOU+Ms1icv3aihSVq7H7QgmE6vZt7F_GxuAvDODMw@mail.gmail.com>
 <32098_1541554905_wA71fjl8013246_ACD1644AA6C67E4FBD0C350625508EC83692A359@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83692A40A@FHSDB2D11-2.csu.mcmaster.ca>

Dear Nhat Tran,

One more thing: You could specify the model even more compactly as

  mod <- lm(KIC ~ (tem + ac + av + thick)^2)

Best,
 John

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Fox, John
> Sent: Tuesday, November 6, 2018 8:41 PM
> To: Thanh Tran <masternhattt at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Sum of Squares Type I, II, III for ANOVA
> 
> Dear Nhat Tran,
> 
> The output that you show is unreadable and as far as I can see, the data aren't
> attached, but perhaps the following will help: First, if you want Anova() to
> compute type III tests, then you have to set the contrasts properly *before*
> you fit the model, not after. Second, you can specify the model much more
> compactly as
> 
>   mod <- lm(KIC ~ tem*ac + tem*av + tem*thick + ac*av +ac*thick + av*thick)
> 
> Finally, as sound general practice, I'd not attach the data, but rather put your
> recoded variables in the data frame and then specify the data argument to
> lm().
> 
> I hope that this helps,
>  John
> 
> -----------------------------------------------------------------
> John Fox
> Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: https://socialsciences.mcmaster.ca/jfox/
> 
> 
> 
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Thanh
> > Tran
> > Sent: Tuesday, November 6, 2018 6:58 PM
> > To: r-help at r-project.org
> > Subject: [R] Sum of Squares Type I, II, III for ANOVA
> >
> > Hi everyone,
> > I'm studying the ANOVA in R and have some questions to share. I
> > investigate the effects of 4 factors (temperature-3 levels, asphalt
> > content-3 levels, air
> > voids-2 levels, and sample thickness-3 levels) on the hardness of
> > asphalt concrete in the tensile test (abbreviated as KIC). These data
> > were taken from a acticle paper. The codes were wrriten as the follows:
> >
> > > data = read.csv("Saha research.csv", header =T)
> > > attach(data)
> > > tem = as.factor(temperature)
> > > ac= as.factor (AC)
> > > av = as.factor(AV)
> > > thick = as.factor(Thickness)
> > > model =
> > lm(KIC~tem+ac+av+thick+tem:ac+tem:av+tem:thick+ac:av+ac:thick+av:thick
> > )
> > > anova(model) #Type I tests
> > > library(car) Loading required package: carData >
> >
> anova(lm(KIC~tem+ac+av+thick+tem:ac+tem:av+tem:thick+ac:av+ac:thick+av
> > :thick),type=2)
> > Error: $ operator is invalid for atomic vectors
> > > options(contrasts = c("contr.sum", "contr.poly"))
> > > Anova(model,type="3") # Type III tests
> > > Anova(model,type="2") # Type II tests
> >
> > With R, three results from Type I, II, and III almost have the same as follows.
> >
> > Analysis of Variance Table Response: KIC Df Sum Sq Mean Sq F value
> > Pr(>F) tem 2 15.3917 7.6958 427.9926 < 2.2e-16 *** ac 2 0.1709 0.0854
> > 4.7510
> > 0.0096967 ** av 1 1.9097 1.9097 106.2055 < 2.2e-16 *** thick 2 0.2041
> > 0.1021 5.6756 0.0040359 ** tem:ac 4 0.5653 0.1413 7.8598 6.973e-06 ***
> > tem:av 2 1.7192 0.8596 47.8046 < 2.2e-16 *** tem:thick 4 0.0728 0.0182
> > 1.0120 0.4024210 ac:av 2 0.3175 0.1588 8.8297 0.0002154 *** ac:thick 4
> > 0.0883 0.0221 1.2280 0.3003570 av:thick 2 0.0662 0.0331 1.8421
> > 0.1613058 Residuals 190 3.4164 0.0180 --- Signif. codes: 0 ?***? 0.001 ?**?
> 0.01 ?*?
> > 0.05 ?.? 0.1 ? ? 1
> >
> > However, these results are different from the results in the article,
> > especially for the interaction (air voids and sample thickness). The
> > results presented in the article are as follows:
> > Analysis of variance for KIC, using Adjusted SS for tests. Source DF
> > Seq SS Adj MS F-stat P-value Model findings Temperature 2 15.39355
> > 7.69677 426.68
> > <0.01 Significant AC 2 0.95784 0.47892 26.55 <0.01 Significant AV 1
> > 0.57035
> > 0.57035 31.62 <0.01 Significant Thickness 2 0.20269 0.10135 5.62 <0.01
> > Significant Temperature?AC 4 1.37762 0.34441 19.09 <0.01 Significant
> > Temperature?AV 2 0.8329 0.41645 23.09 <0.01 Significant
> > Temperature?thickness 4 0.07135 0.01784 0.99 0.415 Not significant
> > AC?AV 2
> > 0.86557 0.43279 23.99 <0.01 Significant AC?thickness 4 0.04337 0.01084
> > 0.6
> > 0.662 Not significant AV?thickness 2 0.17394 0.08697 4.82 <0.01
> > Significant Error 190 3.42734 0.01804 Total 215 23.91653
> >
> > Therefore, I wonder that whether there is an error in my code or there
> > is another type of ANOVA in R. If you could answer my problems, I
> > would be most grateful.
> > Best regards,
> > Nhat Tran
> > Ps: I also added a CSV file and the paper for practicing R.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From jfox @ending from mcm@@ter@c@  Wed Nov  7 03:41:20 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Wed, 7 Nov 2018 02:41:20 +0000
Subject: [R] Sum of Squares Type I, II, III for ANOVA
In-Reply-To: <CAHjanSC-iBPmwyMTc+8Qj2XEEfz+3wc7j3sdZOsyOEqWeazzUw@mail.gmail.com>
References: <29707_1541548741_wA6Nx06M002572_CAHjanSBaqnOU+Ms1icv3aihSVq7H7QgmE6vZt7F_GxuAvDODMw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC83692A359@FHSDB2D11-2.csu.mcmaster.ca>
 <CAHjanSC-iBPmwyMTc+8Qj2XEEfz+3wc7j3sdZOsyOEqWeazzUw@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83692A56B@FHSDB2D11-2.csu.mcmaster.ca>

Dear Thanh Tran,

When you start a discussion on r-help, it's polite to keep it there so other people can see what transpires. I'm consequently cc'ing this response to the r-help list.

The problem with your code is that anova(), as opposed to Anova(), has no type argument.

Here's what I get with your data. I hope that the code and output don't get too mangled:

> data <- read.csv("Saha research.csv", header=TRUE)

> data <- within(data, {
+     tem <- as.factor(temperature)
+     ac <- as.factor (AC)
+     av <- as.factor(AV)
+     thick <- as.factor(Thickness)
+ })

> library(car)
Loading required package: carData

> options(contrasts = c("contr.sum", "contr.poly"))

> mod <- lm(KIC ~ tem*ac + tem*av + tem*thick + ac*av +ac*thick + av*thick, 
+           data=data)

> anova(mod) # type I (sequential)
Analysis of Variance Table

Response: KIC
           Df  Sum Sq Mean Sq  F value    Pr(>F)    
tem         2 15.3917  7.6958 427.9926 < 2.2e-16 ***
ac          2  0.1709  0.0854   4.7510 0.0096967 ** 
av          1  1.9097  1.9097 106.2055 < 2.2e-16 ***
thick       2  0.2041  0.1021   5.6756 0.0040359 ** 
tem:ac      4  0.5653  0.1413   7.8598 6.973e-06 ***
tem:av      2  1.7192  0.8596  47.8046 < 2.2e-16 ***
tem:thick   4  0.0728  0.0182   1.0120 0.4024210    
ac:av       2  0.3175  0.1588   8.8297 0.0002154 ***
ac:thick    4  0.0883  0.0221   1.2280 0.3003570    
av:thick    2  0.0662  0.0331   1.8421 0.1613058    
Residuals 190  3.4164  0.0180                       
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

> Anova(mod) # type II
Anova Table (Type II tests)

Response: KIC
           Sum Sq  Df  F value    Pr(>F)    
tem       15.3917   2 427.9926 < 2.2e-16 ***
ac         0.1709   2   4.7510 0.0096967 ** 
av         1.9097   1 106.2055 < 2.2e-16 ***
thick      0.2041   2   5.6756 0.0040359 ** 
tem:ac     0.5653   4   7.8598 6.973e-06 ***
tem:av     1.7192   2  47.8046 < 2.2e-16 ***
tem:thick  0.0728   4   1.0120 0.4024210    
ac:av      0.3175   2   8.8297 0.0002154 ***
ac:thick   0.0883   4   1.2280 0.3003570    
av:thick   0.0662   2   1.8421 0.1613058    
Residuals  3.4164 190                       
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

> Anova(mod, type=3) # type III
Anova Table (Type III tests)

Response: KIC
             Sum Sq  Df   F value    Pr(>F)    
(Intercept) 102.430   1 5696.4740 < 2.2e-16 ***
tem          15.392   2  427.9926 < 2.2e-16 ***
ac            0.171   2    4.7510 0.0096967 ** 
av            1.910   1  106.2055 < 2.2e-16 ***
thick         0.204   2    5.6756 0.0040359 ** 
tem:ac        0.565   4    7.8598 6.973e-06 ***
tem:av        1.719   2   47.8046 < 2.2e-16 ***
tem:thick     0.073   4    1.0120 0.4024210    
ac:av         0.318   2    8.8297 0.0002154 ***
ac:thick      0.088   4    1.2280 0.3003570    
av:thick      0.066   2    1.8421 0.1613058    
Residuals     3.416 190                        
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

If you have questions about Minitab there's probably another place to ask. It's not my opinion that type-III tests are generally preferable to type-II tests. Focus, in my opinion, should be on what hypotheses are being tested. If you want to see more detail, you could consult the book with which the car package is associated: see citation(package="car").

Best,
 John

> -----Original Message-----
> From: Thanh Tran [mailto:masternhattt at gmail.com]
> Sent: Tuesday, November 6, 2018 9:15 PM
> To: Fox, John <jfox at mcmaster.ca>
> Subject: Re: [R] Sum of Squares Type I, II, III for ANOVA
> 
> Dear  Prof. John Fox,
> Thank you for your answer. The CSV data was added as the attached file again.
> I try to set the contrasts properly *before* I fit the model but I received a
> problem as follows.
> 
> >  setwd("C:/NHAT/HOC TAP/R/Test/Anova") data = read.csv("Saha
> > research.csv", header =T)
> > attach(data)
> > tem = as.factor(temperature)
> > ac= as.factor (AC)
> >  av = as.factor(AV)
> >  thick = as.factor(Thickness)
> > library(car)
> Loading required package: carData
> > options(contrasts = c("contr.sum", "contr.poly")) mod <- lm(KIC ~
> > tem*ac + tem*av + tem*thick + ac*av +ac*thick + av*thick)
> > anova(mod,type= 3)
> Error: $ operator is invalid for atomic vectors
> 
> 
> Another problem is that in the paper that I read, the authors used MINITAB to
> analyze Anova. The authors use "adjusted sums of squares" calculate the p-
> value. So which should I use? Type I adjusted SS or Type III sequential SS?
> Minitab help tells me that I would "usually" want to use type III adjusted SS, as
> type I sequential "sums of squares can differ when your design is unbalanced"
> - which mine is. The R functions I am using are clearly using the type I
> sequential SS.
> 
> Thanks
> Nhat Tran
> 
> 
> V?o Th 4, 7 thg 11, 2018 va?o lu?c 10:41 Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca> > ?? vi?t:
> 
> 
> 	Dear Nhat Tran,
> 
> 	The output that you show is unreadable and as far as I can see, the
> data aren't attached, but perhaps the following will help: First, if you want
> Anova() to compute type III tests, then you have to set the contrasts properly
> *before* you fit the model, not after. Second, you can specify the model much
> more compactly as
> 
> 	  mod <- lm(KIC ~ tem*ac + tem*av + tem*thick + ac*av +ac*thick +
> av*thick)
> 
> 	Finally, as sound general practice, I'd not attach the data, but rather
> put your recoded variables in the data frame and then specify the data
> argument to lm().
> 
> 	I hope that this helps,
> 	 John
> 
> 	-----------------------------------------------------------------
> 	John Fox
> 	Professor Emeritus
> 	McMaster University
> 	Hamilton, Ontario, Canada
> 	Web: https://socialsciences.mcmaster.ca/jfox/
> 
> 
> 
> 	> -----Original Message-----
> 	> From: R-help [mailto:r-help-bounces at r-project.org <mailto:r-help-
> bounces at r-project.org> ] On Behalf Of Thanh Tran
> 	> Sent: Tuesday, November 6, 2018 6:58 PM
> 	> To: r-help at r-project.org <mailto:r-help at r-project.org>
> 	> Subject: [R] Sum of Squares Type I, II, III for ANOVA
> 	>
> 	> Hi everyone,
> 	> I'm studying the ANOVA in R and have some questions to share. I
> investigate
> 	> the effects of 4 factors (temperature-3 levels, asphalt content-3
> levels, air
> 	> voids-2 levels, and sample thickness-3 levels) on the hardness of
> asphalt
> 	> concrete in the tensile test (abbreviated as KIC). These data were
> taken from a
> 	> acticle paper. The codes were wrriten as the follows:
> 	>
> 	> > data = read.csv("Saha research.csv", header =T)
> 	> > attach(data)
> 	> > tem = as.factor(temperature)
> 	> > ac= as.factor (AC)
> 	> > av = as.factor(AV)
> 	> > thick = as.factor(Thickness)
> 	> > model =
> 	>
> lm(KIC~tem+ac+av+thick+tem:ac+tem:av+tem:thick+ac:av+ac:thick+av:thick)
> 	> > anova(model) #Type I tests
> 	> > library(car) Loading required package: carData >
> 	>
> anova(lm(KIC~tem+ac+av+thick+tem:ac+tem:av+tem:thick+ac:av+ac:thick+av
> 	> :thick),type=2)
> 	> Error: $ operator is invalid for atomic vectors
> 	> > options(contrasts = c("contr.sum", "contr.poly"))
> 	> > Anova(model,type="3") # Type III tests
> 	> > Anova(model,type="2") # Type II tests
> 	>
> 	> With R, three results from Type I, II, and III almost have the same as
> follows.
> 	>
> 	> Analysis of Variance Table Response: KIC Df Sum Sq Mean Sq F value
> Pr(>F)
> 	> tem 2 15.3917 7.6958 427.9926 < 2.2e-16 *** ac 2 0.1709 0.0854
> 4.7510
> 	> 0.0096967 ** av 1 1.9097 1.9097 106.2055 < 2.2e-16 *** thick 2
> 0.2041
> 	> 0.1021 5.6756 0.0040359 ** tem:ac 4 0.5653 0.1413 7.8598 6.973e-
> 06 ***
> 	> tem:av 2 1.7192 0.8596 47.8046 < 2.2e-16 *** tem:thick 4 0.0728
> 0.0182
> 	> 1.0120 0.4024210 ac:av 2 0.3175 0.1588 8.8297 0.0002154 ***
> ac:thick 4
> 	> 0.0883 0.0221 1.2280 0.3003570 av:thick 2 0.0662 0.0331 1.8421
> 0.1613058
> 	> Residuals 190 3.4164 0.0180 --- Signif. codes: 0 ?***? 0.001 ?**? 0.01
> ?*?
> 	> 0.05 ?.? 0.1 ? ? 1
> 	>
> 	> However, these results are different from the results in the article,
> especially
> 	> for the interaction (air voids and sample thickness). The results
> presented in
> 	> the article are as follows:
> 	> Analysis of variance for KIC, using Adjusted SS for tests. Source DF
> Seq SS Adj
> 	> MS F-stat P-value Model findings Temperature 2 15.39355 7.69677
> 426.68
> 	> <0.01 Significant AC 2 0.95784 0.47892 26.55 <0.01 Significant AV 1
> 0.57035
> 	> 0.57035 31.62 <0.01 Significant Thickness 2 0.20269 0.10135 5.62
> <0.01
> 	> Significant Temperature?AC 4 1.37762 0.34441 19.09 <0.01
> Significant
> 	> Temperature?AV 2 0.8329 0.41645 23.09 <0.01 Significant
> 	> Temperature?thickness 4 0.07135 0.01784 0.99 0.415 Not
> significant AC?AV 2
> 	> 0.86557 0.43279 23.99 <0.01 Significant AC?thickness 4 0.04337
> 0.01084 0.6
> 	> 0.662 Not significant AV?thickness 2 0.17394 0.08697 4.82 <0.01
> Significant
> 	> Error 190 3.42734 0.01804 Total 215 23.91653
> 	>
> 	> Therefore, I wonder that whether there is an error in my code or
> there is
> 	> another type of ANOVA in R. If you could answer my problems, I
> would be
> 	> most grateful.
> 	> Best regards,
> 	> Nhat Tran
> 	> Ps: I also added a CSV file and the paper for practicing R.
> 	> ______________________________________________
> 	> R-help at r-project.org <mailto:R-help at r-project.org>  mailing list --
> To UNSUBSCRIBE and more, see
> 	> https://stat.ethz.ch/mailman/listinfo/r-help
> 	> PLEASE do read the posting guide http://www.R-project.org/posting-
> 	> guide.html
> 	> and provide commented, minimal, self-contained, reproducible
> code.
> 


From m@@ternh@ttt @ending from gm@il@com  Wed Nov  7 04:08:11 2018
From: m@@ternh@ttt @ending from gm@il@com (Thanh Tran)
Date: Wed, 7 Nov 2018 12:08:11 +0900
Subject: [R] Sum of Squares Type I, II, III for ANOVA
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC83692A56B@FHSDB2D11-2.csu.mcmaster.ca>
References: <29707_1541548741_wA6Nx06M002572_CAHjanSBaqnOU+Ms1icv3aihSVq7H7QgmE6vZt7F_GxuAvDODMw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC83692A359@FHSDB2D11-2.csu.mcmaster.ca>
 <CAHjanSC-iBPmwyMTc+8Qj2XEEfz+3wc7j3sdZOsyOEqWeazzUw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC83692A56B@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAHjanSDgChhaydEL-y4CU7HA5_rYsuNejwve0hn8Ndin_eysUQ@mail.gmail.com>

Dear   Prof. John Fox,

Thank you for your advice. I will take care in the future post.

Best regards,
Nhat Tran

V?o Th 4, 7 thg 11, 2018 va?o lu?c 11:41 Fox, John <jfox at mcmaster.ca> ??
vi?t:

> Dear Thanh Tran,
>
> When you start a discussion on r-help, it's polite to keep it there so
> other people can see what transpires. I'm consequently cc'ing this response
> to the r-help list.
>
> The problem with your code is that anova(), as opposed to Anova(), has no
> type argument.
>
> Here's what I get with your data. I hope that the code and output don't
> get too mangled:
>
> > data <- read.csv("Saha research.csv", header=TRUE)
>
> > data <- within(data, {
> +     tem <- as.factor(temperature)
> +     ac <- as.factor (AC)
> +     av <- as.factor(AV)
> +     thick <- as.factor(Thickness)
> + })
>
> > library(car)
> Loading required package: carData
>
> > options(contrasts = c("contr.sum", "contr.poly"))
>
> > mod <- lm(KIC ~ tem*ac + tem*av + tem*thick + ac*av +ac*thick +
> av*thick,
> +           data=data)
>
> > anova(mod) # type I (sequential)
> Analysis of Variance Table
>
> Response: KIC
>            Df  Sum Sq Mean Sq  F value    Pr(>F)
> tem         2 15.3917  7.6958 427.9926 < 2.2e-16 ***
> ac          2  0.1709  0.0854   4.7510 0.0096967 **
> av          1  1.9097  1.9097 106.2055 < 2.2e-16 ***
> thick       2  0.2041  0.1021   5.6756 0.0040359 **
> tem:ac      4  0.5653  0.1413   7.8598 6.973e-06 ***
> tem:av      2  1.7192  0.8596  47.8046 < 2.2e-16 ***
> tem:thick   4  0.0728  0.0182   1.0120 0.4024210
> ac:av       2  0.3175  0.1588   8.8297 0.0002154 ***
> ac:thick    4  0.0883  0.0221   1.2280 0.3003570
> av:thick    2  0.0662  0.0331   1.8421 0.1613058
> Residuals 190  3.4164  0.0180
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> > Anova(mod) # type II
> Anova Table (Type II tests)
>
> Response: KIC
>            Sum Sq  Df  F value    Pr(>F)
> tem       15.3917   2 427.9926 < 2.2e-16 ***
> ac         0.1709   2   4.7510 0.0096967 **
> av         1.9097   1 106.2055 < 2.2e-16 ***
> thick      0.2041   2   5.6756 0.0040359 **
> tem:ac     0.5653   4   7.8598 6.973e-06 ***
> tem:av     1.7192   2  47.8046 < 2.2e-16 ***
> tem:thick  0.0728   4   1.0120 0.4024210
> ac:av      0.3175   2   8.8297 0.0002154 ***
> ac:thick   0.0883   4   1.2280 0.3003570
> av:thick   0.0662   2   1.8421 0.1613058
> Residuals  3.4164 190
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> > Anova(mod, type=3) # type III
> Anova Table (Type III tests)
>
> Response: KIC
>              Sum Sq  Df   F value    Pr(>F)
> (Intercept) 102.430   1 5696.4740 < 2.2e-16 ***
> tem          15.392   2  427.9926 < 2.2e-16 ***
> ac            0.171   2    4.7510 0.0096967 **
> av            1.910   1  106.2055 < 2.2e-16 ***
> thick         0.204   2    5.6756 0.0040359 **
> tem:ac        0.565   4    7.8598 6.973e-06 ***
> tem:av        1.719   2   47.8046 < 2.2e-16 ***
> tem:thick     0.073   4    1.0120 0.4024210
> ac:av         0.318   2    8.8297 0.0002154 ***
> ac:thick      0.088   4    1.2280 0.3003570
> av:thick      0.066   2    1.8421 0.1613058
> Residuals     3.416 190
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> If you have questions about Minitab there's probably another place to ask.
> It's not my opinion that type-III tests are generally preferable to type-II
> tests. Focus, in my opinion, should be on what hypotheses are being tested.
> If you want to see more detail, you could consult the book with which the
> car package is associated: see citation(package="car").
>
> Best,
>  John
>
> > -----Original Message-----
> > From: Thanh Tran [mailto:masternhattt at gmail.com]
> > Sent: Tuesday, November 6, 2018 9:15 PM
> > To: Fox, John <jfox at mcmaster.ca>
> > Subject: Re: [R] Sum of Squares Type I, II, III for ANOVA
> >
> > Dear  Prof. John Fox,
> > Thank you for your answer. The CSV data was added as the attached file
> again.
> > I try to set the contrasts properly *before* I fit the model but I
> received a
> > problem as follows.
> >
> > >  setwd("C:/NHAT/HOC TAP/R/Test/Anova") data = read.csv("Saha
> > > research.csv", header =T)
> > > attach(data)
> > > tem = as.factor(temperature)
> > > ac= as.factor (AC)
> > >  av = as.factor(AV)
> > >  thick = as.factor(Thickness)
> > > library(car)
> > Loading required package: carData
> > > options(contrasts = c("contr.sum", "contr.poly")) mod <- lm(KIC ~
> > > tem*ac + tem*av + tem*thick + ac*av +ac*thick + av*thick)
> > > anova(mod,type= 3)
> > Error: $ operator is invalid for atomic vectors
> >
> >
> > Another problem is that in the paper that I read, the authors used
> MINITAB to
> > analyze Anova. The authors use "adjusted sums of squares" calculate the
> p-
> > value. So which should I use? Type I adjusted SS or Type III sequential
> SS?
> > Minitab help tells me that I would "usually" want to use type III
> adjusted SS, as
> > type I sequential "sums of squares can differ when your design is
> unbalanced"
> > - which mine is. The R functions I am using are clearly using the type I
> > sequential SS.
> >
> > Thanks
> > Nhat Tran
> >
> >
> > V?o Th 4, 7 thg 11, 2018 va?o lu?c 10:41 Fox, John <jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca> > ?? vi?t:
> >
> >
> >       Dear Nhat Tran,
> >
> >       The output that you show is unreadable and as far as I can see, the
> > data aren't attached, but perhaps the following will help: First, if you
> want
> > Anova() to compute type III tests, then you have to set the contrasts
> properly
> > *before* you fit the model, not after. Second, you can specify the model
> much
> > more compactly as
> >
> >         mod <- lm(KIC ~ tem*ac + tem*av + tem*thick + ac*av +ac*thick +
> > av*thick)
> >
> >       Finally, as sound general practice, I'd not attach the data, but
> rather
> > put your recoded variables in the data frame and then specify the data
> > argument to lm().
> >
> >       I hope that this helps,
> >        John
> >
> >       -----------------------------------------------------------------
> >       John Fox
> >       Professor Emeritus
> >       McMaster University
> >       Hamilton, Ontario, Canada
> >       Web: https://socialsciences.mcmaster.ca/jfox/
> >
> >
> >
> >       > -----Original Message-----
> >       > From: R-help [mailto:r-help-bounces at r-project.org <mailto:
> r-help-
> > bounces at r-project.org> ] On Behalf Of Thanh Tran
> >       > Sent: Tuesday, November 6, 2018 6:58 PM
> >       > To: r-help at r-project.org <mailto:r-help at r-project.org>
> >       > Subject: [R] Sum of Squares Type I, II, III for ANOVA
> >       >
> >       > Hi everyone,
> >       > I'm studying the ANOVA in R and have some questions to share. I
> > investigate
> >       > the effects of 4 factors (temperature-3 levels, asphalt content-3
> > levels, air
> >       > voids-2 levels, and sample thickness-3 levels) on the hardness of
> > asphalt
> >       > concrete in the tensile test (abbreviated as KIC). These data
> were
> > taken from a
> >       > acticle paper. The codes were wrriten as the follows:
> >       >
> >       > > data = read.csv("Saha research.csv", header =T)
> >       > > attach(data)
> >       > > tem = as.factor(temperature)
> >       > > ac= as.factor (AC)
> >       > > av = as.factor(AV)
> >       > > thick = as.factor(Thickness)
> >       > > model =
> >       >
> > lm(KIC~tem+ac+av+thick+tem:ac+tem:av+tem:thick+ac:av+ac:thick+av:thick)
> >       > > anova(model) #Type I tests
> >       > > library(car) Loading required package: carData >
> >       >
> > anova(lm(KIC~tem+ac+av+thick+tem:ac+tem:av+tem:thick+ac:av+ac:thick+av
> >       > :thick),type=2)
> >       > Error: $ operator is invalid for atomic vectors
> >       > > options(contrasts = c("contr.sum", "contr.poly"))
> >       > > Anova(model,type="3") # Type III tests
> >       > > Anova(model,type="2") # Type II tests
> >       >
> >       > With R, three results from Type I, II, and III almost have the
> same as
> > follows.
> >       >
> >       > Analysis of Variance Table Response: KIC Df Sum Sq Mean Sq F
> value
> > Pr(>F)
> >       > tem 2 15.3917 7.6958 427.9926 < 2.2e-16 *** ac 2 0.1709 0.0854
> > 4.7510
> >       > 0.0096967 ** av 1 1.9097 1.9097 106.2055 < 2.2e-16 *** thick 2
> > 0.2041
> >       > 0.1021 5.6756 0.0040359 ** tem:ac 4 0.5653 0.1413 7.8598 6.973e-
> > 06 ***
> >       > tem:av 2 1.7192 0.8596 47.8046 < 2.2e-16 *** tem:thick 4 0.0728
> > 0.0182
> >       > 1.0120 0.4024210 ac:av 2 0.3175 0.1588 8.8297 0.0002154 ***
> > ac:thick 4
> >       > 0.0883 0.0221 1.2280 0.3003570 av:thick 2 0.0662 0.0331 1.8421
> > 0.1613058
> >       > Residuals 190 3.4164 0.0180 --- Signif. codes: 0 ?***? 0.001
> ?**? 0.01
> > ?*?
> >       > 0.05 ?.? 0.1 ? ? 1
> >       >
> >       > However, these results are different from the results in the
> article,
> > especially
> >       > for the interaction (air voids and sample thickness). The results
> > presented in
> >       > the article are as follows:
> >       > Analysis of variance for KIC, using Adjusted SS for tests.
> Source DF
> > Seq SS Adj
> >       > MS F-stat P-value Model findings Temperature 2 15.39355 7.69677
> > 426.68
> >       > <0.01 Significant AC 2 0.95784 0.47892 26.55 <0.01 Significant
> AV 1
> > 0.57035
> >       > 0.57035 31.62 <0.01 Significant Thickness 2 0.20269 0.10135 5.62
> > <0.01
> >       > Significant Temperature?AC 4 1.37762 0.34441 19.09 <0.01
> > Significant
> >       > Temperature?AV 2 0.8329 0.41645 23.09 <0.01 Significant
> >       > Temperature?thickness 4 0.07135 0.01784 0.99 0.415 Not
> > significant AC?AV 2
> >       > 0.86557 0.43279 23.99 <0.01 Significant AC?thickness 4 0.04337
> > 0.01084 0.6
> >       > 0.662 Not significant AV?thickness 2 0.17394 0.08697 4.82 <0.01
> > Significant
> >       > Error 190 3.42734 0.01804 Total 215 23.91653
> >       >
> >       > Therefore, I wonder that whether there is an error in my code or
> > there is
> >       > another type of ANOVA in R. If you could answer my problems, I
> > would be
> >       > most grateful.
> >       > Best regards,
> >       > Nhat Tran
> >       > Ps: I also added a CSV file and the paper for practicing R.
> >       > ______________________________________________
> >       > R-help at r-project.org <mailto:R-help at r-project.org>  mailing
> list --
> > To UNSUBSCRIBE and more, see
> >       > https://stat.ethz.ch/mailman/listinfo/r-help
> >       > PLEASE do read the posting guide
> http://www.R-project.org/posting-
> >       > guide.html
> >       > and provide commented, minimal, self-contained, reproducible
> > code.
> >
>
>

	[[alternative HTML version deleted]]


From robertburbidged@t@ @ending from y@hoo@co@uk  Wed Nov  7 07:32:55 2018
From: robertburbidged@t@ @ending from y@hoo@co@uk (Robert David Burbidge)
Date: Wed, 7 Nov 2018 06:32:55 +0000
Subject: [R] POS tagging generating a string
In-Reply-To: <05ceb9e2-713f-34f4-5950-3a980f0d04b5@yahoo.co.uk>
References: <1394154020.2564506.1541499964758.ref@mail.yahoo.com>
 <1394154020.2564506.1541499964758@mail.yahoo.com>
 <05ceb9e2-713f-34f4-5950-3a980f0d04b5@yahoo.co.uk>
Message-ID: <2231ce74-442c-cd68-6659-c38ba6fdbca6@yahoo.co.uk>

Hi Elahe,
You could modify your count_verbs function from your previous post:

  * use scan to extract the tokens (words) from Message
  * use your previous grepl expression to index the tokens that are verbs
  * paste the verbs together to form the entries of a new column.

Here is one solution:

 >>>>>>>>>>>>>>>
library(openNLP)
library(NLP)

df <- data.frame(DocumentID = c(478920L, 510133L, 499497L, 930234L),
 ???????????????? Message = structure(c(4L, 2L, 3L, 1L), .Label = 
c("Thank you very much for your nice feedback.\n",
"THank you, added it", "Thanks for the well explained article.",
"The solution has been updated"), class = "factor"))


dput(df)

tagPOS <-? function(x, ...) {
 ? s <- as.String(x)
 ? if(s=="") return(list())
 ? word_token_annotator <- Maxent_Word_Token_Annotator()
 ? a2 <- Annotation(1L, "sentence", 1L, nchar(s))
 ? a2 <- annotate(s, word_token_annotator, a2)
 ? a3 <- annotate(s, Maxent_POS_Tag_Annotator(), a2)
 ? a3w <- a3[a3$type == "word"]
 ? POStags <- unlist(lapply(a3w$features, `[[`, "POS"))
 ? POStagged <- paste(sprintf("%s/%s", s[a3w], POStags), collapse = " ")
 ? list(POStagged = POStagged, POStags = POStags)
}

verbs <-function(x) {
 ? tagPOSx <- tagPOS(x)
 ? scanx <- scan(text=as.character(x), what="character")
 ? n <- length(scanx)
 ? paste(scanx[(1:n)[grepl("VB", tagPOSx$POStags)]], collapse="|")
}

library(dplyr)

df %>% group_by(DocumentID) %>% summarise(verbs = verbs(Message))
<<<<<<<<<<<<<<<<<<<<<

I'll leave it to you to extract a column of verbs from the result and 
rbind it to the original data.frame.

Btw, I don't this solution is efficient, I would guess that the 
processing that scan does in the verbs function is duplicating work 
already done in the tagPOS function by annotate, so you may want to 
return a list of tokens from tagPOS and use that instead of scan.

Rgds,
Robert

On 06/11/18 10:26, Elahe chalabi via R-help wrote:
> Hi all, In my df I would like to generate a new column which contains 
> a string showing all the verbs in each row of df$Message.
>> library(openNLP) library(NLP) dput(df) 
> structure(list(DocumentID = c(478920L, 510133L, 499497L, 930234L ), 
> Message = structure(c(4L, 2L, 3L, 1L), .Label = c("Thank you very much 
> for your nice feedback.\n", "THank you, added it", "Thanks for the 
> well explained article.", "The solution has been updated"), class = 
> "factor")), class = "data.frame", row.names = c(NA, -4L)) tagPOS <- 
> function(x, ...) { s <- as.String(x) word_token_annotator <- 
> Maxent_Word_Token_Annotator() a2 <- Annotation(1L, "sentence", 1L, 
> nchar(s)) a2 <- annotate(s, word_token_annotator, a2) a3 <- 
> annotate(s, Maxent_POS_Tag_Annotator(), a2) a3w <- a3[a3$type == 
> "word"] POStags <- unlist(lapply(a3w$features, `[[`, "POS")) POStagged 
> <- paste(sprintf("%s/%s", s[a3w], POStags), collapse = " ") 
> list(POStagged = POStagged, POStags = POStags) } Any help? Thanks in 
> advance! Elahe ______________________________________________ 
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the 
> posting guide http://www.R-project.org/posting-guide.html and provide 
> commented, minimal, self-contained, reproducible code.




	[[alternative HTML version deleted]]


From p_connolly @ending from @ling@hot@co@nz  Wed Nov  7 08:56:21 2018
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Wed, 7 Nov 2018 20:56:21 +1300
Subject: [R] saveRDS() and readRDS()  Why?
Message-ID: <20181107075621.GD8540@slingshot.co.nz>

>From a Windows R session, I do
 
> object.size(rawData)
31736 bytes  # from scraping a non-reproducible web address.
> saveRDS(rawData, file = "rawData.rds")

Then copy to a Linux session

> rawData <- readRDS(file = "rawData.rds")
> rawData
[1] "rawData"
> object.size(rawData)
112 bytes
> rawData
[1] "rawData" # only the name and something to make up 112 bytes
> 

Have I misunderstood the syntax?

It's an old version on Windows.  I haven't used Windows R since then.

major          3                                          
minor          2.4                                        
year           2016                                       
month          03                                         
day            16                                         


I've tried R-3.5.0 and R-3.5.1 Linux versions.

In case it's material ... 

I couldn't get the scraping to work on either of the R installations
but Windows users told me it worked for them.  So I thought I'd get
the R object and use it.  I could understand accessing the web address
could have different permissions for different OSes, but should that
affect the R objects?

TIA

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From ericjberger @ending from gm@il@com  Wed Nov  7 09:13:40 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Wed, 7 Nov 2018 10:13:40 +0200
Subject: [R] saveRDS() and readRDS() Why?
In-Reply-To: <20181107075621.GD8540@slingshot.co.nz>
References: <20181107075621.GD8540@slingshot.co.nz>
Message-ID: <CAGgJW76oOcdX8fFRcVpfWQgo5_VRx3HQ=4rwS8DG4LCDE4=mLA@mail.gmail.com>

What do you see at the OS level?
i.e. on windows
DIR rawData.rds
on linux
ls -l rawData.rds
compare the file sizes on both.


On Wed, Nov 7, 2018 at 9:56 AM Patrick Connolly <p_connolly at slingshot.co.nz>
wrote:

> From a Windows R session, I do
>
> > object.size(rawData)
> 31736 bytes  # from scraping a non-reproducible web address.
> > saveRDS(rawData, file = "rawData.rds")
>
> Then copy to a Linux session
>
> > rawData <- readRDS(file = "rawData.rds")
> > rawData
> [1] "rawData"
> > object.size(rawData)
> 112 bytes
> > rawData
> [1] "rawData" # only the name and something to make up 112 bytes
> >
>
> Have I misunderstood the syntax?
>
> It's an old version on Windows.  I haven't used Windows R since then.
>
> major          3
> minor          2.4
> year           2016
> month          03
> day            16
>
>
> I've tried R-3.5.0 and R-3.5.1 Linux versions.
>
> In case it's material ...
>
> I couldn't get the scraping to work on either of the R installations
> but Windows users told me it worked for them.  So I thought I'd get
> the R object and use it.  I could understand accessing the web address
> could have different permissions for different OSes, but should that
> affect the R objects?
>
> TIA
>
> --
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>    ___    Patrick Connolly
>  {~._.~}                   Great minds discuss ideas
>  _( Y )_                 Average minds discuss events
> (:_~*~_:)                  Small minds discuss people
>  (_)-(_)                              ..... Eleanor Roosevelt
>
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From robertburbidged@t@ @ending from y@hoo@co@uk  Wed Nov  7 09:27:51 2018
From: robertburbidged@t@ @ending from y@hoo@co@uk (Robert David Burbidge)
Date: Wed, 7 Nov 2018 08:27:51 +0000
Subject: [R] saveRDS() and readRDS() Why?
In-Reply-To: <CAGgJW76oOcdX8fFRcVpfWQgo5_VRx3HQ=4rwS8DG4LCDE4=mLA@mail.gmail.com>
References: <20181107075621.GD8540@slingshot.co.nz>
 <CAGgJW76oOcdX8fFRcVpfWQgo5_VRx3HQ=4rwS8DG4LCDE4=mLA@mail.gmail.com>
Message-ID: <d259aef4-0e7c-e042-01fe-efc99cf21173@yahoo.co.uk>

Hi Patrick,

 From the help: "save writes a single line header (typically "RDXs\n") 
before the serialization of a single object".

If the file sizes are the same (see Eric's message), then the problem 
may be due to different line terminators. Try serialize and unserialize 
for low-level control of saving/reading objects.

Rgds,

Robert


On 07/11/18 08:13, Eric Berger wrote:
> What do you see at the OS level?
> i.e. on windows
> DIR rawData.rds
> on linux
> ls -l rawData.rds
> compare the file sizes on both.
>
>
> On Wed, Nov 7, 2018 at 9:56 AM Patrick Connolly <p_connolly at slingshot.co.nz>
> wrote:
>
>>  From a Windows R session, I do
>>
>>> object.size(rawData)
>> 31736 bytes  # from scraping a non-reproducible web address.
>>> saveRDS(rawData, file = "rawData.rds")
>> Then copy to a Linux session
>>
>>> rawData <- readRDS(file = "rawData.rds")
>>> rawData
>> [1] "rawData"
>>> object.size(rawData)
>> 112 bytes
>>> rawData
>> [1] "rawData" # only the name and something to make up 112 bytes
>> Have I misunderstood the syntax?
>>
>> It's an old version on Windows.  I haven't used Windows R since then.
>>
>> major          3
>> minor          2.4
>> year           2016
>> month          03
>> day            16
>>
>>
>> I've tried R-3.5.0 and R-3.5.1 Linux versions.
>>
>> In case it's material ...
>>
>> I couldn't get the scraping to work on either of the R installations
>> but Windows users told me it worked for them.  So I thought I'd get
>> the R object and use it.  I could understand accessing the web address
>> could have different permissions for different OSes, but should that
>> affect the R objects?
>>
>> TIA
>>
>> --
>> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>>     ___    Patrick Connolly
>>   {~._.~}                   Great minds discuss ideas
>>   _( Y )_                 Average minds discuss events
>> (:_~*~_:)                  Small minds discuss people
>>   (_)-(_)                              ..... Eleanor Roosevelt
>>
>> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p_connolly @ending from @ling@hot@co@nz  Wed Nov  7 09:28:13 2018
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Wed, 7 Nov 2018 21:28:13 +1300
Subject: [R] saveRDS() and readRDS() Why?
In-Reply-To: <CAGgJW76oOcdX8fFRcVpfWQgo5_VRx3HQ=4rwS8DG4LCDE4=mLA@mail.gmail.com>
References: <20181107075621.GD8540@slingshot.co.nz>
 <CAGgJW76oOcdX8fFRcVpfWQgo5_VRx3HQ=4rwS8DG4LCDE4=mLA@mail.gmail.com>
Message-ID: <497cbb5c-0807-639a-52e2-cf4192179844@slingshot.co.nz>

They're both about 3kb.

On 7/11/18 9:13 PM, Eric Berger wrote:
> What do you see at the OS level?
> i.e. on windows
> DIR rawData.rds
> on linux
> ls -l rawData.rds
> compare the file sizes on both.
>
>
> On Wed, Nov 7, 2018 at 9:56 AM Patrick Connolly 
> <p_connolly at slingshot.co.nz <mailto:p_connolly at slingshot.co.nz>> wrote:
>
>     From a Windows R session, I do
>
>     > object.size(rawData)
>     31736 bytes? # from scraping a non-reproducible web address.
>     > saveRDS(rawData, file = "rawData.rds")
>
>     Then copy to a Linux session
>
>     > rawData <- readRDS(file = "rawData.rds")
>     > rawData
>     [1] "rawData"
>     > object.size(rawData)
>     112 bytes
>     > rawData
>     [1] "rawData" # only the name and something to make up 112 bytes
>     >
>
>     Have I misunderstood the syntax?
>
>     It's an old version on Windows.? I haven't used Windows R since then.
>
>     major? ? ? ? ? 3
>     minor? ? ? ? ? 2.4
>     year? ? ? ? ? ?2016
>     month? ? ? ? ? 03
>     day? ? ? ? ? ? 16
>
>
>     I've tried R-3.5.0 and R-3.5.1 Linux versions.
>
>     In case it's material ...
>
>     I couldn't get the scraping to work on either of the R installations
>     but Windows users told me it worked for them.? So I thought I'd get
>     the R object and use it.? I could understand accessing the web address
>     could have different permissions for different OSes, but should that
>     affect the R objects?
>
>     TIA
>
>     -- 
>     ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
>     ? ?___? ? Patrick Connolly
>     ?{~._.~}? ? ? ? ? ? ? ? ? ?Great minds discuss ideas
>     ?_( Y )_? ? ? ? ? ? ? ? ?Average minds discuss events
>     (:_~*~_:)? ? ? ? ? ? ? ? ? Small minds discuss people
>     ?(_)-(_)? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ..... Eleanor Roosevelt
>
>     ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From p_connolly @ending from @ling@hot@co@nz  Wed Nov  7 09:45:30 2018
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Wed, 7 Nov 2018 21:45:30 +1300
Subject: [R] saveRDS() and readRDS() Why?
In-Reply-To: <d259aef4-0e7c-e042-01fe-efc99cf21173@yahoo.co.uk>
References: <20181107075621.GD8540@slingshot.co.nz>
 <CAGgJW76oOcdX8fFRcVpfWQgo5_VRx3HQ=4rwS8DG4LCDE4=mLA@mail.gmail.com>
 <d259aef4-0e7c-e042-01fe-efc99cf21173@yahoo.co.uk>
Message-ID: <20181107084530.GE8540@slingshot.co.nz>

On Wed, 07-Nov-2018 at 08:27AM +0000, Robert David Burbidge wrote:

|> Hi Patrick,
|> 
|> From the help: "save writes a single line header (typically
|> "RDXs\n") before the serialization of a single object".
|> 
|> If the file sizes are the same (see Eric's message), then the
|> problem may be due to different line terminators. Try serialize and
|> unserialize for low-level control of saving/reading objects.

I'll have to find out what 'serialize' means.

On Windows, it's a huge table, looks like it's all hexadecimal.  

On Linux, it's just the text string 'rawData' -- a lot more than line
terminators.

Have I misunderstood what the idea is?  I thought I'd get an identical
object, irrespective of how different the OS stores and zips it.



|> 
|> Rgds,
|> 
|> Robert
|> 
|> 
|> On 07/11/18 08:13, Eric Berger wrote:
|> >What do you see at the OS level?
|> >i.e. on windows
|> >DIR rawData.rds
|> >on linux
|> >ls -l rawData.rds
|> >compare the file sizes on both.
|> >
|> >
|> >On Wed, Nov 7, 2018 at 9:56 AM Patrick Connolly <p_connolly at slingshot.co.nz>
|> >wrote:
|> >
|> >> From a Windows R session, I do
|> >>
|> >>>object.size(rawData)
|> >>31736 bytes  # from scraping a non-reproducible web address.
|> >>>saveRDS(rawData, file = "rawData.rds")
|> >>Then copy to a Linux session
|> >>
|> >>>rawData <- readRDS(file = "rawData.rds")
|> >>>rawData
|> >>[1] "rawData"
|> >>>object.size(rawData)
|> >>112 bytes
|> >>>rawData
|> >>[1] "rawData" # only the name and something to make up 112 bytes
|> >>Have I misunderstood the syntax?
|> >>
|> >>It's an old version on Windows.  I haven't used Windows R since then.
|> >>
|> >>major          3
|> >>minor          2.4
|> >>year           2016
|> >>month          03
|> >>day            16
|> >>
|> >>
|> >>I've tried R-3.5.0 and R-3.5.1 Linux versions.
|> >>
|> >>In case it's material ...
|> >>
|> >>I couldn't get the scraping to work on either of the R installations
|> >>but Windows users told me it worked for them.  So I thought I'd get
|> >>the R object and use it.  I could understand accessing the web address
|> >>could have different permissions for different OSes, but should that
|> >>affect the R objects?
|> >>
|> >>TIA
|> >>
|> >>--
|> >>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
|> >>    ___    Patrick Connolly
|> >>  {~._.~}                   Great minds discuss ideas
|> >>  _( Y )_                 Average minds discuss events
|> >>(:_~*~_:)                  Small minds discuss people
|> >>  (_)-(_)                              ..... Eleanor Roosevelt
|> >>
|> >>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
|> >>
|> >>______________________________________________
|> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> >>https://stat.ethz.ch/mailman/listinfo/r-help
|> >>PLEASE do read the posting guide
|> >>http://www.R-project.org/posting-guide.html
|> >>and provide commented, minimal, self-contained, reproducible code.
|> >>
|> >	[[alternative HTML version deleted]]
|> >
|> >______________________________________________
|> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> >https://stat.ethz.ch/mailman/listinfo/r-help
|> >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> >and provide commented, minimal, self-contained, reproducible code.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From ericjberger @ending from gm@il@com  Wed Nov  7 10:01:16 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Wed, 7 Nov 2018 11:01:16 +0200
Subject: [R] saveRDS() and readRDS() Why?
In-Reply-To: <20181107084530.GE8540@slingshot.co.nz>
References: <20181107075621.GD8540@slingshot.co.nz>
 <CAGgJW76oOcdX8fFRcVpfWQgo5_VRx3HQ=4rwS8DG4LCDE4=mLA@mail.gmail.com>
 <d259aef4-0e7c-e042-01fe-efc99cf21173@yahoo.co.uk>
 <20181107084530.GE8540@slingshot.co.nz>
Message-ID: <CAGgJW768pFtWqkYxGiFoQ_GNUnE6gSDvDJR75VYoArTsAMAcXA@mail.gmail.com>

Your understanding is correct. It works fine for me.

On Wed, Nov 7, 2018 at 10:48 AM Patrick Connolly <p_connolly at slingshot.co.nz>
wrote:

> On Wed, 07-Nov-2018 at 08:27AM +0000, Robert David Burbidge wrote:
>
> |> Hi Patrick,
> |>
> |> From the help: "save writes a single line header (typically
> |> "RDXs\n") before the serialization of a single object".
> |>
> |> If the file sizes are the same (see Eric's message), then the
> |> problem may be due to different line terminators. Try serialize and
> |> unserialize for low-level control of saving/reading objects.
>
> I'll have to find out what 'serialize' means.
>
> On Windows, it's a huge table, looks like it's all hexadecimal.
>
> On Linux, it's just the text string 'rawData' -- a lot more than line
> terminators.
>
> Have I misunderstood what the idea is?  I thought I'd get an identical
> object, irrespective of how different the OS stores and zips it.
>
>
>
> |>
> |> Rgds,
> |>
> |> Robert
> |>
> |>
> |> On 07/11/18 08:13, Eric Berger wrote:
> |> >What do you see at the OS level?
> |> >i.e. on windows
> |> >DIR rawData.rds
> |> >on linux
> |> >ls -l rawData.rds
> |> >compare the file sizes on both.
> |> >
> |> >
> |> >On Wed, Nov 7, 2018 at 9:56 AM Patrick Connolly <
> p_connolly at slingshot.co.nz>
> |> >wrote:
> |> >
> |> >> From a Windows R session, I do
> |> >>
> |> >>>object.size(rawData)
> |> >>31736 bytes  # from scraping a non-reproducible web address.
> |> >>>saveRDS(rawData, file = "rawData.rds")
> |> >>Then copy to a Linux session
> |> >>
> |> >>>rawData <- readRDS(file = "rawData.rds")
> |> >>>rawData
> |> >>[1] "rawData"
> |> >>>object.size(rawData)
> |> >>112 bytes
> |> >>>rawData
> |> >>[1] "rawData" # only the name and something to make up 112 bytes
> |> >>Have I misunderstood the syntax?
> |> >>
> |> >>It's an old version on Windows.  I haven't used Windows R since then.
> |> >>
> |> >>major          3
> |> >>minor          2.4
> |> >>year           2016
> |> >>month          03
> |> >>day            16
> |> >>
> |> >>
> |> >>I've tried R-3.5.0 and R-3.5.1 Linux versions.
> |> >>
> |> >>In case it's material ...
> |> >>
> |> >>I couldn't get the scraping to work on either of the R installations
> |> >>but Windows users told me it worked for them.  So I thought I'd get
> |> >>the R object and use it.  I could understand accessing the web address
> |> >>could have different permissions for different OSes, but should that
> |> >>affect the R objects?
> |> >>
> |> >>TIA
> |> >>
> |> >>--
> |>
> >>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
> |> >>    ___    Patrick Connolly
> |> >>  {~._.~}                   Great minds discuss ideas
> |> >>  _( Y )_                 Average minds discuss events
> |> >>(:_~*~_:)                  Small minds discuss people
> |> >>  (_)-(_)                              ..... Eleanor Roosevelt
> |> >>
> |>
> >>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
> |> >>
> |> >>______________________________________________
> |> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> |> >>https://stat.ethz.ch/mailman/listinfo/r-help
> |> >>PLEASE do read the posting guide
> |> >>http://www.R-project.org/posting-guide.html
> |> >>and provide commented, minimal, self-contained, reproducible code.
> |> >>
> |> >    [[alternative HTML version deleted]]
> |> >
> |> >______________________________________________
> |> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> |> >https://stat.ethz.ch/mailman/listinfo/r-help
> |> >PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> |> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>    ___    Patrick Connolly
>  {~._.~}                   Great minds discuss ideas
>  _( Y )_                 Average minds discuss events
> (:_~*~_:)                  Small minds discuss people
>  (_)-(_)                              ..... Eleanor Roosevelt
>
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From robertburbidged@t@ @ending from y@hoo@co@uk  Wed Nov  7 10:10:56 2018
From: robertburbidged@t@ @ending from y@hoo@co@uk (Robert David Burbidge)
Date: Wed, 7 Nov 2018 09:10:56 +0000
Subject: [R] saveRDS() and readRDS() Why?
In-Reply-To: <20181107084530.GE8540@slingshot.co.nz>
References: <20181107075621.GD8540@slingshot.co.nz>
 <CAGgJW76oOcdX8fFRcVpfWQgo5_VRx3HQ=4rwS8DG4LCDE4=mLA@mail.gmail.com>
 <d259aef4-0e7c-e042-01fe-efc99cf21173@yahoo.co.uk>
 <20181107084530.GE8540@slingshot.co.nz>
Message-ID: <924664eb-54a6-c478-a190-a3a8e4679bf7@yahoo.co.uk>

If the file sizes are the same, then presumably both contain the binary data. From the serialize function help:

"As almost all systems in current use are little-endian, xdr = FALSE can be used to avoid byte-shuffling at both ends when transferring data from one little-endian machine to another (or between processes on the same machine). Depending on the system, this can speed up serialization and unserialization by a factor of up to 3x."

So you could try:

# windows (not run)
f <- file("rawData.rds", open="w")
serialize(rawData, f, xdr = FALSE)
close(f)

# linux
rawData <- unserialize(file = "rawData.rds")

HTH

On 07/11/18 08:45, Patrick Connolly wrote:

> On Wed, 07-Nov-2018 at 08:27AM +0000, Robert David Burbidge wrote:
>
> |> Hi Patrick,
> |>
> |> From the help: "save writes a single line header (typically
> |> "RDXs\n") before the serialization of a single object".
> |>
> |> If the file sizes are the same (see Eric's message), then the
> |> problem may be due to different line terminators. Try serialize and
> |> unserialize for low-level control of saving/reading objects.
>
> I'll have to find out what 'serialize' means.
>
> On Windows, it's a huge table, looks like it's all hexadecimal.
>
> On Linux, it's just the text string 'rawData' -- a lot more than line
> terminators.
>
> Have I misunderstood what the idea is?  I thought I'd get an identical
> object, irrespective of how different the OS stores and zips it.
>
>
>
> |>
> |> Rgds,
> |>
> |> Robert
> |>
> |>
> |> On 07/11/18 08:13, Eric Berger wrote:
> |> >What do you see at the OS level?
> |> >i.e. on windows
> |> >DIR rawData.rds
> |> >on linux
> |> >ls -l rawData.rds
> |> >compare the file sizes on both.
> |> >
> |> >
> |> >On Wed, Nov 7, 2018 at 9:56 AM Patrick Connolly <p_connolly at slingshot.co.nz>
> |> >wrote:
> |> >
> |> >> From a Windows R session, I do
> |> >>
> |> >>>object.size(rawData)
> |> >>31736 bytes  # from scraping a non-reproducible web address.
> |> >>>saveRDS(rawData, file = "rawData.rds")
> |> >>Then copy to a Linux session
> |> >>
> |> >>>rawData <- readRDS(file = "rawData.rds")
> |> >>>rawData
> |> >>[1] "rawData"
> |> >>>object.size(rawData)
> |> >>112 bytes
> |> >>>rawData
> |> >>[1] "rawData" # only the name and something to make up 112 bytes
> |> >>Have I misunderstood the syntax?
> |> >>
> |> >>It's an old version on Windows.  I haven't used Windows R since then.
> |> >>
> |> >>major          3
> |> >>minor          2.4
> |> >>year           2016
> |> >>month          03
> |> >>day            16
> |> >>
> |> >>
> |> >>I've tried R-3.5.0 and R-3.5.1 Linux versions.
> |> >>
> |> >>In case it's material ...
> |> >>
> |> >>I couldn't get the scraping to work on either of the R installations
> |> >>but Windows users told me it worked for them.  So I thought I'd get
> |> >>the R object and use it.  I could understand accessing the web address
> |> >>could have different permissions for different OSes, but should that
> |> >>affect the R objects?
> |> >>
> |> >>TIA
> |> >>
> |> >>-
>


From rhelp @ending from eoo@@dd@@nl  Wed Nov  7 10:15:33 2018
From: rhelp @ending from eoo@@dd@@nl (Jan van der Laan)
Date: Wed, 7 Nov 2018 10:15:33 +0100
Subject: [R] saveRDS() and readRDS() Why?
In-Reply-To: <20181107084530.GE8540@slingshot.co.nz>
References: <20181107075621.GD8540@slingshot.co.nz>
 <CAGgJW76oOcdX8fFRcVpfWQgo5_VRx3HQ=4rwS8DG4LCDE4=mLA@mail.gmail.com>
 <d259aef4-0e7c-e042-01fe-efc99cf21173@yahoo.co.uk>
 <20181107084530.GE8540@slingshot.co.nz>
Message-ID: <39139a1a-83e8-a894-d755-be5a6b1158a1@eoos.dds.nl>


Are you sure you didn't do saveRDS("rawData", file = "rawData.rds") 
instead of saveRDS(rawData, file = "rawData.rds") ? This would explain 
the result you have under linux.

In principle saveRDS and readRDS can be used to copy objects between 
R-sessions without loosing information.

What does readRDS return on windows with the same file?

What type of object is rawData? Do str(rawData). Some objects created by 
packages cannot be serialized, e.g. objects that point to memory 
allocated by a package. The pointer is then serialized not the memory 
pointed to.

Also, if the object is generated by a package, you might need to load 
the package to get the printing etc. of the object right.

HTH,

Jan







On 07-11-18 09:45, Patrick Connolly wrote:
> On Wed, 07-Nov-2018 at 08:27AM +0000, Robert David Burbidge wrote:
> 
> |> Hi Patrick,
> |>
> |> From the help: "save writes a single line header (typically
> |> "RDXs\n") before the serialization of a single object".
> |>
> |> If the file sizes are the same (see Eric's message), then the
> |> problem may be due to different line terminators. Try serialize and
> |> unserialize for low-level control of saving/reading objects.
> 
> I'll have to find out what 'serialize' means.
> 
> On Windows, it's a huge table, looks like it's all hexadecimal.
> 
> On Linux, it's just the text string 'rawData' -- a lot more than line
> terminators.
> 
> Have I misunderstood what the idea is?  I thought I'd get an identical
> object, irrespective of how different the OS stores and zips it.
> 
> 
> 
> |>
> |> Rgds,
> |>
> |> Robert
> |>
> |>
> |> On 07/11/18 08:13, Eric Berger wrote:
> |> >What do you see at the OS level?
> |> >i.e. on windows
> |> >DIR rawData.rds
> |> >on linux
> |> >ls -l rawData.rds
> |> >compare the file sizes on both.
> |> >
> |> >
> |> >On Wed, Nov 7, 2018 at 9:56 AM Patrick Connolly <p_connolly at slingshot.co.nz>
> |> >wrote:
> |> >
> |> >> From a Windows R session, I do
> |> >>
> |> >>>object.size(rawData)
> |> >>31736 bytes  # from scraping a non-reproducible web address.
> |> >>>saveRDS(rawData, file = "rawData.rds")
> |> >>Then copy to a Linux session
> |> >>
> |> >>>rawData <- readRDS(file = "rawData.rds")
> |> >>>rawData
> |> >>[1] "rawData"
> |> >>>object.size(rawData)
> |> >>112 bytes
> |> >>>rawData
> |> >>[1] "rawData" # only the name and something to make up 112 bytes
> |> >>Have I misunderstood the syntax?
> |> >>
> |> >>It's an old version on Windows.  I haven't used Windows R since then.
> |> >>
> |> >>major          3
> |> >>minor          2.4
> |> >>year           2016
> |> >>month          03
> |> >>day            16
> |> >>
> |> >>
> |> >>I've tried R-3.5.0 and R-3.5.1 Linux versions.
> |> >>
> |> >>In case it's material ...
> |> >>
> |> >>I couldn't get the scraping to work on either of the R installations
> |> >>but Windows users told me it worked for them.  So I thought I'd get
> |> >>the R object and use it.  I could understand accessing the web address
> |> >>could have different permissions for different OSes, but should that
> |> >>affect the R objects?
> |> >>
> |> >>TIA
> |> >>
> |> >>--
> |> >>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
> |> >>    ___    Patrick Connolly
> |> >>  {~._.~}                   Great minds discuss ideas
> |> >>  _( Y )_                 Average minds discuss events
> |> >>(:_~*~_:)                  Small minds discuss people
> |> >>  (_)-(_)                              ..... Eleanor Roosevelt
> |> >>
> |> >>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
> |> >>
> |> >>______________________________________________
> |> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> |> >>https://stat.ethz.ch/mailman/listinfo/r-help
> |> >>PLEASE do read the posting guide
> |> >>http://www.R-project.org/posting-guide.html
> |> >>and provide commented, minimal, self-contained, reproducible code.
> |> >>
> |> >	[[alternative HTML version deleted]]
> |> >
> |> >______________________________________________
> |> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> |> >https://stat.ethz.ch/mailman/listinfo/r-help
> |> >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> |> >and provide commented, minimal, self-contained, reproducible code.
>


From robertburbidged@t@ @ending from y@hoo@co@uk  Wed Nov  7 12:03:18 2018
From: robertburbidged@t@ @ending from y@hoo@co@uk (Robert David Burbidge)
Date: Wed, 7 Nov 2018 11:03:18 +0000
Subject: [R] saveRDS() and readRDS() Why?
In-Reply-To: <20181107075621.GD8540@slingshot.co.nz>
References: <20181107075621.GD8540@slingshot.co.nz>
Message-ID: <ae7f4bb2-f6bd-9ec8-19f8-8505f8a98c24@yahoo.co.uk>

Patrick,

I cannot reproduce this behaviour. I'm using:

Windows 8.1; R 3.5.1; RStudio 1.1.463

running in a VirtualBox on Ubuntu 18.04 with R 3.4.4; RStudio 1.1.456

The file size of rawData.rds is always 88 bytes in my example and od 
gives the same results on Windows and Linux.

I am using a VirtualBox shared folder to transfer from Windows to Linux.

Could you provide details of your machines?

Rgds,

Robert


On 07/11/18 07:56, Patrick Connolly wrote:
>  From a Windows R session, I do
>   
>> object.size(rawData)
> 31736 bytes  # from scraping a non-reproducible web address.
>> saveRDS(rawData, file = "rawData.rds")
> Then copy to a Linux session
>
>> rawData <- readRDS(file = "rawData.rds")
>> rawData
> [1] "rawData"
>> object.size(rawData)
> 112 bytes
>> rawData
> [1] "rawData" # only the name and something to make up 112 bytes
> Have I misunderstood the syntax?
>
> It's an old version on Windows.  I haven't used Windows R since then.
>
> major          3
> minor          2.4
> year           2016
> month          03
> day            16
>
>
> I've tried R-3.5.0 and R-3.5.1 Linux versions.
>
> In case it's material ...
>
> I couldn't get the scraping to work on either of the R installations
> but Windows users told me it worked for them.  So I thought I'd get
> the R object and use it.  I could understand accessing the web address
> could have different permissions for different OSes, but should that
> affect the R objects?
>
> TIA
>


From HDor@n @ending from @ir@org  Wed Nov  7 19:24:33 2018
From: HDor@n @ending from @ir@org (Doran, Harold)
Date: Wed, 7 Nov 2018 18:24:33 +0000
Subject: [R] Optimization with Parallel Processing Functions/Packages
Message-ID: <BN7PR05MB58571D2F8F3EF59C979F72CDCAC40@BN7PR05MB5857.namprd05.prod.outlook.com>

More of a general query, but looking to see if others have successfully used something like the foreach package (or other parallel style functions) with certain functions that minimize likelihood or objective functions (e.g., optim/nlminb).

I have had great success with embarrassingly parallel problems and my R packages have benefited greatly. However, optimization doesn't fit as nicely within that context as the values at iteration t depend on the values found at iteration t-1 and such. So, I'm assuming the cost of splitting and combining might be more expensive in this context that simply doing minimization on a single core.

If others have experiences or even possibly R-specific resources that implement this that I would be able to study, I would appreciate seeing how this might be implemented.

Regards
Harold


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Nov  7 20:24:50 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 07 Nov 2018 11:24:50 -0800
Subject: [R] Optimization with Parallel Processing Functions/Packages
In-Reply-To: <BN7PR05MB58571D2F8F3EF59C979F72CDCAC40@BN7PR05MB5857.namprd05.prod.outlook.com>
References: <BN7PR05MB58571D2F8F3EF59C979F72CDCAC40@BN7PR05MB5857.namprd05.prod.outlook.com>
Message-ID: <E27DA128-3F25-4B16-9475-2DF732A83D02@dcn.davis.ca.us>

This is highly problem dependent... and you appear to already know the answer. Note that some differential evolution solution approaches may benefit from parallelizing evaluation of generations since within that sub-problem the optimization dependencies don't apply. 

A theoretical discussion forum such as stats.stackexchange.com might be better for this... though even they may complain that the question is too vague.

On November 7, 2018 10:24:33 AM PST, "Doran, Harold" <HDoran at air.org> wrote:
>More of a general query, but looking to see if others have successfully
>used something like the foreach package (or other parallel style
>functions) with certain functions that minimize likelihood or objective
>functions (e.g., optim/nlminb).
>
>I have had great success with embarrassingly parallel problems and my R
>packages have benefited greatly. However, optimization doesn't fit as
>nicely within that context as the values at iteration t depend on the
>values found at iteration t-1 and such. So, I'm assuming the cost of
>splitting and combining might be more expensive in this context that
>simply doing minimization on a single core.
>
>If others have experiences or even possibly R-specific resources that
>implement this that I would be able to study, I would appreciate seeing
>how this might be implemented.
>
>Regards
>Harold
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From r@turner @ending from @uckl@nd@@c@nz  Wed Nov  7 21:33:37 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Thu, 8 Nov 2018 09:33:37 +1300
Subject: [R] Problem with the matrix() function.
Message-ID: <2248a612-6c0c-aaf6-1699-a93029b31c2d@auckland.ac.nz>


In the course of writing a bit of somewhat convoluted code I recently 
made a silly error that revealed the following phenomenon:

m <- matrix(1:10,nrow=2,ncol=c(5,4))

produces

>      [,1] [,2] [,3] [,4] [,5]
> [1,]    1    3    5    7    9
> [2,]    2    4    6    8   10

That is, the nonsense value of c(5,4) for the "ncol" argument is 
accepted, without comment --- the first entry of the given ncol argument 
is used.

It might be argued that this is a reasonable accommodation of the user's 
ineptitude.  I am of the opinion that an error should be thrown if the
value of ncol is not an integer scalar.

I have also discerned that if ncol is not an integer, it is replaced by 
its floor value.

Is this a Good Thing?

What do others think?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bgunter@4567 @ending from gm@il@com  Wed Nov  7 21:49:25 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 7 Nov 2018 12:49:25 -0800
Subject: [R] Problem with the matrix() function.
In-Reply-To: <2248a612-6c0c-aaf6-1699-a93029b31c2d@auckland.ac.nz>
References: <2248a612-6c0c-aaf6-1699-a93029b31c2d@auckland.ac.nz>
Message-ID: <CAGxFJbQBFY0M1S+6jzVShi1TJugC=P=CvCZKPq7PLnVNQVOjWA@mail.gmail.com>

I have no opinion on your queries, but whatever is done, it should be
properly documented, which appears not to be the case presently afaics.

-- Bert



On Wed, Nov 7, 2018 at 12:33 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> In the course of writing a bit of somewhat convoluted code I recently
> made a silly error that revealed the following phenomenon:
>
> m <- matrix(1:10,nrow=2,ncol=c(5,4))
>
> produces
>
> >      [,1] [,2] [,3] [,4] [,5]
> > [1,]    1    3    5    7    9
> > [2,]    2    4    6    8   10
>
> That is, the nonsense value of c(5,4) for the "ncol" argument is
> accepted, without comment --- the first entry of the given ncol argument
> is used.
>
> It might be argued that this is a reasonable accommodation of the user's
> ineptitude.  I am of the opinion that an error should be thrown if the
> value of ncol is not an integer scalar.
>
> I have also discerned that if ncol is not an integer, it is replaced by
> its floor value.
>
> Is this a Good Thing?
>
> What do others think?
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dc@rl@on @ending from t@mu@edu  Wed Nov  7 22:00:50 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Wed, 7 Nov 2018 21:00:50 +0000
Subject: [R] Problem with the matrix() function.
In-Reply-To: <CAGxFJbQBFY0M1S+6jzVShi1TJugC=P=CvCZKPq7PLnVNQVOjWA@mail.gmail.com>
References: <2248a612-6c0c-aaf6-1699-a93029b31c2d@auckland.ac.nz>
 <CAGxFJbQBFY0M1S+6jzVShi1TJugC=P=CvCZKPq7PLnVNQVOjWA@mail.gmail.com>
Message-ID: <e6e99250872148b291324339e7c01608@tamu.edu>

There are other functions where R handles a vector argument differently. The first value may be silently used, used with a warning, or trigger an error. 

> x <- 1:3
> x:9
[1] 1 2 3 4 5 6 7 8 9
Warning message:
In x:9 : numerical expression has 3 elements: only the first used
> seq(x, 9)
Error in seq.default(x, 9) : 'from' must be of length 1
> rep(1, x)
Error in rep(1, x) : invalid 'times' argument

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
Sent: Wednesday, November 7, 2018 2:49 PM
To: Rolf Turner <r.turner at auckland.ac.nz>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] Problem with the matrix() function.

I have no opinion on your queries, but whatever is done, it should be
properly documented, which appears not to be the case presently afaics.

-- Bert



On Wed, Nov 7, 2018 at 12:33 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> In the course of writing a bit of somewhat convoluted code I recently
> made a silly error that revealed the following phenomenon:
>
> m <- matrix(1:10,nrow=2,ncol=c(5,4))
>
> produces
>
> >      [,1] [,2] [,3] [,4] [,5]
> > [1,]    1    3    5    7    9
> > [2,]    2    4    6    8   10
>
> That is, the nonsense value of c(5,4) for the "ncol" argument is
> accepted, without comment --- the first entry of the given ncol argument
> is used.
>
> It might be argued that this is a reasonable accommodation of the user's
> ineptitude.  I am of the opinion that an error should be thrown if the
> value of ncol is not an integer scalar.
>
> I have also discerned that if ncol is not an integer, it is replaced by
> its floor value.
>
> Is this a Good Thing?
>
> What do others think?
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From h@nn@h@hlx @ending from gm@il@com  Thu Nov  8 04:55:42 2018
From: h@nn@h@hlx @ending from gm@il@com (li li)
Date: Wed, 7 Nov 2018 22:55:42 -0500
Subject: [R] Identify row indices corresponding to each distinct row of a
 matrix
Message-ID: <CAHLnndYRFRysTCZEbHpTsfb-TsCXHYCa2CN_AmMR4Ork2P6Rog@mail.gmail.com>

Hi all,
   I use the following example to illustrate my question. As you can see,
in matrix C some rows are repeated and I would like to find the indices of
the rows corresponding to each of the distinct rows.
  For example, for the row c(1,9), I have used the "which" function to
identify the row indices corresponding to c(1,9). Using this approach, in
order to cover all distinct rows, I need to use a for loop.
   I am wondering whether there is an easier way where a for loop can be
avoided?
   Thanks very much!
      Hanna



> A <- matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16),8,2)> B <- rbind(A,A,A)> C <- as.data.frame(B[sample(nrow(B)),])> C   V1 V2
1   1  9
2   2 10
3   3 11
4   5 13
5   7 15
6   6 14
7   4 12
8   3 11
9   8 16
10  5 13
11  7 15
12  2 10
13  1  9
14  8 16
15  1  9
16  3 11
17  7 15
18  4 12
19  2 10
20  6 14
21  4 12
22  8 16
23  5 13
24  6 14> T <- unique(C)> T  V1 V2
1  1  9
2  2 10
3  3 11
4  5 13
5  7 15
6  6 14
7  4 12
9  8 16> > i <- 1                    > which(C[,1]==T[i,1]&
C[,2]==T[i,2])[1]  1 13 15

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Thu Nov  8 06:20:57 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 7 Nov 2018 21:20:57 -0800
Subject: [R] 
 Identify row indices corresponding to each distinct row of a matrix
In-Reply-To: <CAHLnndYRFRysTCZEbHpTsfb-TsCXHYCa2CN_AmMR4Ork2P6Rog@mail.gmail.com>
References: <CAHLnndYRFRysTCZEbHpTsfb-TsCXHYCa2CN_AmMR4Ork2P6Rog@mail.gmail.com>
Message-ID: <CAGxFJbTgZC4qVgxpCx7fVTu3nwaET+FoKWXE=iH2xWRzzGw52A@mail.gmail.com>

A mess -- due to your continued use of html formatting.

But something like this may do what you want (hard to tell with the mess):

> m <- matrix(1:16,nrow=8)[rep(1:8,2),]
> m
      [,1] [,2]
 [1,]    1    9
 [2,]    2   10
 [3,]    3   11
 [4,]    4   12
 [5,]    5   13
 [6,]    6   14
 [7,]    7   15
 [8,]    8   16
 [9,]    1    9
[10,]    2   10
[11,]    3   11
[12,]    4   12
[13,]    5   13
[14,]    6   14
[15,]    7   15
[16,]    8   16
> vec <- apply(m,1,paste,collapse="-") ## converts rows into character
vector
> vec
 [1] "1-9"  "2-10" "3-11" "4-12" "5-13" "6-14" "7-15" "8-16" "1-9"  "2-10"
"3-11" "4-12" "5-13" "6-14"
[15] "7-15" "8-16"
> ## Then maybe:
> tapply(seq_along(vec),vec, I)
$`1-9`
[1] 1 9

$`2-10`
[1]  2 10

$`3-11`
[1]  3 11

$`4-12`
[1]  4 12

$`5-13`
[1]  5 13

$`6-14`
[1]  6 14

$`7-15`
[1]  7 15

$`8-16`
[1]  8 16

> ## gives the row numbers for each unique row

There may well be slicker ways to do this -- if this is actually what you
want to do.

-- Bert



On Wed, Nov 7, 2018 at 7:56 PM li li <hannah.hlx at gmail.com> wrote:

> Hi all,
>    I use the following example to illustrate my question. As you can see,
> in matrix C some rows are repeated and I would like to find the indices of
> the rows corresponding to each of the distinct rows.
>   For example, for the row c(1,9), I have used the "which" function to
> identify the row indices corresponding to c(1,9). Using this approach, in
> order to cover all distinct rows, I need to use a for loop.
>    I am wondering whether there is an easier way where a for loop can be
> avoided?
>    Thanks very much!
>       Hanna
>
>
>
> > A <- matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16),8,2)> B <-
> rbind(A,A,A)> C <- as.data.frame(B[sample(nrow(B)),])> C   V1 V2
> 1   1  9
> 2   2 10
> 3   3 11
> 4   5 13
> 5   7 15
> 6   6 14
> 7   4 12
> 8   3 11
> 9   8 16
> 10  5 13
> 11  7 15
> 12  2 10
> 13  1  9
> 14  8 16
> 15  1  9
> 16  3 11
> 17  7 15
> 18  4 12
> 19  2 10
> 20  6 14
> 21  4 12
> 22  8 16
> 23  5 13
> 24  6 14> T <- unique(C)> T  V1 V2
> 1  1  9
> 2  2 10
> 3  3 11
> 4  5 13
> 5  7 15
> 6  6 14
> 7  4 12
> 9  8 16> > i <- 1                    > which(C[,1]==T[i,1]&
> C[,2]==T[i,2])[1]  1 13 15
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Nov  8 07:32:12 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 07 Nov 2018 22:32:12 -0800
Subject: [R] 
 Identify row indices corresponding to each distinct row of a matrix
In-Reply-To: <CAGxFJbTgZC4qVgxpCx7fVTu3nwaET+FoKWXE=iH2xWRzzGw52A@mail.gmail.com>
References: <CAHLnndYRFRysTCZEbHpTsfb-TsCXHYCa2CN_AmMR4Ork2P6Rog@mail.gmail.com>
 <CAGxFJbTgZC4qVgxpCx7fVTu3nwaET+FoKWXE=iH2xWRzzGw52A@mail.gmail.com>
Message-ID: <009DC65B-161A-4891-89DF-7660321BD8EE@dcn.davis.ca.us>

Perhaps

which( ! duplicated( m, MARGIN=1 ) )

? (untested)

On November 7, 2018 9:20:57 PM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>A mess -- due to your continued use of html formatting.
>
>But something like this may do what you want (hard to tell with the
>mess):
>
>> m <- matrix(1:16,nrow=8)[rep(1:8,2),]
>> m
>      [,1] [,2]
> [1,]    1    9
> [2,]    2   10
> [3,]    3   11
> [4,]    4   12
> [5,]    5   13
> [6,]    6   14
> [7,]    7   15
> [8,]    8   16
> [9,]    1    9
>[10,]    2   10
>[11,]    3   11
>[12,]    4   12
>[13,]    5   13
>[14,]    6   14
>[15,]    7   15
>[16,]    8   16
>> vec <- apply(m,1,paste,collapse="-") ## converts rows into character
>vector
>> vec
>[1] "1-9"  "2-10" "3-11" "4-12" "5-13" "6-14" "7-15" "8-16" "1-9" 
>"2-10"
>"3-11" "4-12" "5-13" "6-14"
>[15] "7-15" "8-16"
>> ## Then maybe:
>> tapply(seq_along(vec),vec, I)
>$`1-9`
>[1] 1 9
>
>$`2-10`
>[1]  2 10
>
>$`3-11`
>[1]  3 11
>
>$`4-12`
>[1]  4 12
>
>$`5-13`
>[1]  5 13
>
>$`6-14`
>[1]  6 14
>
>$`7-15`
>[1]  7 15
>
>$`8-16`
>[1]  8 16
>
>> ## gives the row numbers for each unique row
>
>There may well be slicker ways to do this -- if this is actually what
>you
>want to do.
>
>-- Bert
>
>
>
>On Wed, Nov 7, 2018 at 7:56 PM li li <hannah.hlx at gmail.com> wrote:
>
>> Hi all,
>>    I use the following example to illustrate my question. As you can
>see,
>> in matrix C some rows are repeated and I would like to find the
>indices of
>> the rows corresponding to each of the distinct rows.
>>   For example, for the row c(1,9), I have used the "which" function
>to
>> identify the row indices corresponding to c(1,9). Using this
>approach, in
>> order to cover all distinct rows, I need to use a for loop.
>>    I am wondering whether there is an easier way where a for loop can
>be
>> avoided?
>>    Thanks very much!
>>       Hanna
>>
>>
>>
>> > A <- matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16),8,2)> B <-
>> rbind(A,A,A)> C <- as.data.frame(B[sample(nrow(B)),])> C   V1 V2
>> 1   1  9
>> 2   2 10
>> 3   3 11
>> 4   5 13
>> 5   7 15
>> 6   6 14
>> 7   4 12
>> 8   3 11
>> 9   8 16
>> 10  5 13
>> 11  7 15
>> 12  2 10
>> 13  1  9
>> 14  8 16
>> 15  1  9
>> 16  3 11
>> 17  7 15
>> 18  4 12
>> 19  2 10
>> 20  6 14
>> 21  4 12
>> 22  8 16
>> 23  5 13
>> 24  6 14> T <- unique(C)> T  V1 V2
>> 1  1  9
>> 2  2 10
>> 3  3 11
>> 4  5 13
>> 5  7 15
>> 6  6 14
>> 7  4 12
>> 9  8 16> > i <- 1                    > which(C[,1]==T[i,1]&
>> C[,2]==T[i,2])[1]  1 13 15
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From p_connolly @ending from @ling@hot@co@nz  Thu Nov  8 08:27:24 2018
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Thu, 8 Nov 2018 20:27:24 +1300
Subject: [R] saveRDS() and readRDS()  Why? [solved, kind of]
In-Reply-To: <20181107075621.GD8540@slingshot.co.nz>
References: <20181107075621.GD8540@slingshot.co.nz>
Message-ID: <20181108072724.GF8540@slingshot.co.nz>


Many thanks to Berwin, Eric, Robert, and Jan for their input.

I had hoped it was as simple as because I typed 

saveRDS("rawData", file = "rawData.rds") on the Windows side.
but that wasn't the case.

Robert Burbridge suggested:

 windows (not run)
f <- file("rawData.rds", open="w")
serialize(rawData, f, xdr = FALSE)
close(f)

# linux
rawData <- unserialize(file = "rawData.rds")

That didn't work: 
Error in unserialize(file = "rawData.rds") : 
  unused argument (file = "rawData.rds")
(the argument isn't 'file')

Nor did 
> rawData <- unserialize("rawData.rds")
Error in unserialize("rawData.rds") : 
  character vectors are no longer accepted by unserialize()

However 

readRDS(file = "rawData.rds") did!

So what I needed was serialize but not unserialize.

I still don't know Why, but I know How.
-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From m@echler @ending from @t@t@m@th@ethz@ch  Thu Nov  8 11:06:28 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 8 Nov 2018 11:06:28 +0100
Subject: [R] saveRDS() and readRDS()  Why? [solved, kind of]
In-Reply-To: <20181108072724.GF8540@slingshot.co.nz>
References: <20181107075621.GD8540@slingshot.co.nz>
 <20181108072724.GF8540@slingshot.co.nz>
Message-ID: <23524.2724.270930.705139@stat.math.ethz.ch>

>>>>> Patrick Connolly 
>>>>>     on Thu, 8 Nov 2018 20:27:24 +1300 writes:

> Many thanks to Berwin, Eric, Robert, and Jan for their input.
> 
> I had hoped it was as simple as because I typed 
> 
> saveRDS("rawData", file = "rawData.rds") on the Windows side.

> but that wasn't the case.
> 
> Robert Burbridge suggested:
> 
>  windows (not run)
> f <- file("rawData.rds", open="w")
> serialize(rawData, f, xdr = FALSE)
> close(f)
> 
> # linux
> rawData <- unserialize(file = "rawData.rds")
> 
> That didn't work: 
> Error in unserialize(file = "rawData.rds") : 
>   unused argument (file = "rawData.rds")
> (the argument isn't 'file')
> 
> Nor did 
> > rawData <- unserialize("rawData.rds")
> Error in unserialize("rawData.rds") : 
>   character vectors are no longer accepted by unserialize()
> 
> However 
> 
> readRDS(file = "rawData.rds") did!
> 
> So what I needed was serialize but not unserialize.
> 
> I still don't know Why, but I know How.

Hmm.. and nobody has been able to reproduce your problem, right?

IIUC, currently you are suggesting that [on Windows], if you do

      saveRDS(rawdata, file="rawdata.rds")

the resulting file is does not work with    readRDS()  on Linux.
What again are your R versions on the two platforms?

Could you  dput() -- provide a (short if possible) version of rawdata where
that problem occurs ?

Best,
Martin


> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
>    ___    Patrick Connolly   
>  {~._.~}                   Great minds discuss ideas    
>  _( Y )_  	         Average minds discuss events 
> (:_~*~_:)                  Small minds discuss people  
>  (_)-(_)  	                      ..... Eleanor Roosevelt
> 	  
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From robertburbidged@t@ @ending from y@hoo@co@uk  Thu Nov  8 13:51:23 2018
From: robertburbidged@t@ @ending from y@hoo@co@uk (Robert David Burbidge)
Date: Thu, 8 Nov 2018 12:51:23 +0000
Subject: [R] saveRDS() and readRDS() Why? [solved, kind of]
In-Reply-To: <20181108072724.GF8540@slingshot.co.nz>
References: <20181107075621.GD8540@slingshot.co.nz>
 <20181108072724.GF8540@slingshot.co.nz>
Message-ID: <4aef2307-c3c3-f926-9877-87d5944e7e2c@yahoo.co.uk>

Apologies, unserialize takes a connection, not a file, so you would need 
something like:

# linux (not run)
f <- file("rawData.rds", open="r")
rawData <- unserialize(f)
close(f)

The help file states that readRDS will read a file created by serialize 
(saveRDS is a wrapper for serialize).

It appears that the problem was "byte-shuffling at both ends when 
transferring data from one little-endian machine to another" and was 
worked around by using xdr = FALSE. So, this wouldn't necessarily work 
when transferring between big-endian and little-endian machines.

On 08/11/18 07:27, Patrick Connolly wrote:
> Many thanks to Berwin, Eric, Robert, and Jan for their input.
>
> I had hoped it was as simple as because I typed
>
> saveRDS("rawData", file = "rawData.rds") on the Windows side.
> but that wasn't the case.
>
> Robert Burbridge suggested:
>
>   windows (not run)
> f <- file("rawData.rds", open="w")
> serialize(rawData, f, xdr = FALSE)
> close(f)
>
> # linux
> rawData <- unserialize(file = "rawData.rds")
>
> That didn't work:
> Error in unserialize(file = "rawData.rds") :
>    unused argument (file = "rawData.rds")
> (the argument isn't 'file')
>
> Nor did
>> rawData <- unserialize("rawData.rds")
> Error in unserialize("rawData.rds") :
>    character vectors are no longer accepted by unserialize()
>
> However
>
> readRDS(file = "rawData.rds") did!
>
> So what I needed was serialize but not unserialize.
>
> I still don't know Why, but I know How.


From m@rkp@yne@twork @ending from gm@il@com  Thu Nov  8 16:26:32 2018
From: m@rkp@yne@twork @ending from gm@il@com (Mark R Payne)
Date: Thu, 8 Nov 2018 16:26:32 +0100
Subject: [R] MGCV:: boundary conditions in gam
Message-ID: <CAGBzUO9E7KG8Pp_ahb48bAYFTj_HEMhmHw5jDscXJ7Bn+QthLw@mail.gmail.com>

Dear R-help,

I have a problem where I am using the mgcv package to in a situation where
I am fitting a gam model with a 1-D spline smoother model over a domain
[a,b] but then need to make predictions and extrapolate beyond b. Is there
anyway where I force the first derivative of the spline to be zero at
boundaries, so that I simply get a constant value outside the domain?

Best wishes,

Mark

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Thu Nov  8 16:42:56 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 8 Nov 2018 07:42:56 -0800
Subject: [R] 
 Identify row indices corresponding to each distinct row of a matrix
In-Reply-To: <009DC65B-161A-4891-89DF-7660321BD8EE@dcn.davis.ca.us>
References: <CAHLnndYRFRysTCZEbHpTsfb-TsCXHYCa2CN_AmMR4Ork2P6Rog@mail.gmail.com>
 <CAGxFJbTgZC4qVgxpCx7fVTu3nwaET+FoKWXE=iH2xWRzzGw52A@mail.gmail.com>
 <009DC65B-161A-4891-89DF-7660321BD8EE@dcn.davis.ca.us>
Message-ID: <CAGxFJbTPdac0YSg+tApKaf+TvmSBZKS1HqyeR2WaKr+LUD4FnQ@mail.gmail.com>

Yes -- much better than mine. I didn't know about the MARGIN argument of
duplicated().

-- Bert


On Wed, Nov 7, 2018 at 10:32 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Perhaps
>
> which( ! duplicated( m, MARGIN=1 ) )
>
> ? (untested)
>
> On November 7, 2018 9:20:57 PM PST, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >A mess -- due to your continued use of html formatting.
> >
> >But something like this may do what you want (hard to tell with the
> >mess):
> >
> >> m <- matrix(1:16,nrow=8)[rep(1:8,2),]
> >> m
> >      [,1] [,2]
> > [1,]    1    9
> > [2,]    2   10
> > [3,]    3   11
> > [4,]    4   12
> > [5,]    5   13
> > [6,]    6   14
> > [7,]    7   15
> > [8,]    8   16
> > [9,]    1    9
> >[10,]    2   10
> >[11,]    3   11
> >[12,]    4   12
> >[13,]    5   13
> >[14,]    6   14
> >[15,]    7   15
> >[16,]    8   16
> >> vec <- apply(m,1,paste,collapse="-") ## converts rows into character
> >vector
> >> vec
> >[1] "1-9"  "2-10" "3-11" "4-12" "5-13" "6-14" "7-15" "8-16" "1-9"
> >"2-10"
> >"3-11" "4-12" "5-13" "6-14"
> >[15] "7-15" "8-16"
> >> ## Then maybe:
> >> tapply(seq_along(vec),vec, I)
> >$`1-9`
> >[1] 1 9
> >
> >$`2-10`
> >[1]  2 10
> >
> >$`3-11`
> >[1]  3 11
> >
> >$`4-12`
> >[1]  4 12
> >
> >$`5-13`
> >[1]  5 13
> >
> >$`6-14`
> >[1]  6 14
> >
> >$`7-15`
> >[1]  7 15
> >
> >$`8-16`
> >[1]  8 16
> >
> >> ## gives the row numbers for each unique row
> >
> >There may well be slicker ways to do this -- if this is actually what
> >you
> >want to do.
> >
> >-- Bert
> >
> >
> >
> >On Wed, Nov 7, 2018 at 7:56 PM li li <hannah.hlx at gmail.com> wrote:
> >
> >> Hi all,
> >>    I use the following example to illustrate my question. As you can
> >see,
> >> in matrix C some rows are repeated and I would like to find the
> >indices of
> >> the rows corresponding to each of the distinct rows.
> >>   For example, for the row c(1,9), I have used the "which" function
> >to
> >> identify the row indices corresponding to c(1,9). Using this
> >approach, in
> >> order to cover all distinct rows, I need to use a for loop.
> >>    I am wondering whether there is an easier way where a for loop can
> >be
> >> avoided?
> >>    Thanks very much!
> >>       Hanna
> >>
> >>
> >>
> >> > A <- matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16),8,2)> B <-
> >> rbind(A,A,A)> C <- as.data.frame(B[sample(nrow(B)),])> C   V1 V2
> >> 1   1  9
> >> 2   2 10
> >> 3   3 11
> >> 4   5 13
> >> 5   7 15
> >> 6   6 14
> >> 7   4 12
> >> 8   3 11
> >> 9   8 16
> >> 10  5 13
> >> 11  7 15
> >> 12  2 10
> >> 13  1  9
> >> 14  8 16
> >> 15  1  9
> >> 16  3 11
> >> 17  7 15
> >> 18  4 12
> >> 19  2 10
> >> 20  6 14
> >> 21  4 12
> >> 22  8 16
> >> 23  5 13
> >> 24  6 14> T <- unique(C)> T  V1 V2
> >> 1  1  9
> >> 2  2 10
> >> 3  3 11
> >> 4  5 13
> >> 5  7 15
> >> 6  6 14
> >> 7  4 12
> >> 9  8 16> > i <- 1                    > which(C[,1]==T[i,1]&
> >> C[,2]==T[i,2])[1]  1 13 15
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From e@@wiek @ending from gm@il@com  Thu Nov  8 17:14:51 2018
From: e@@wiek @ending from gm@il@com (Ek Esawi)
Date: Thu, 8 Nov 2018 11:14:51 -0500
Subject: [R] Remove specific rows from nested list of matrices
In-Reply-To: <CA+ZkTxv=BXPK0QHrucvFb9JW_=4EfiLVzbFu_8PsnG3Brpa4jg@mail.gmail.com>
References: <CA+ZkTxv=BXPK0QHrucvFb9JW_=4EfiLVzbFu_8PsnG3Brpa4jg@mail.gmail.com>
Message-ID: <CA+ZkTxvUKuUt+vNPNFNWUULJM+neotrxUzrhPv9oJ8+vpe1f_g@mail.gmail.com>

Thank you all, Bert, Jeff, Bill an Don. I realized I made a silly
mistake in list indexing. Once I saw Bills? suggestion and was able to
wrap my head around indexing recursive lists, I resolved the problem.
For future readers, here is the answers, even though the question may
not have been clear. I tried Don?s idea and it worked too.

 To filter out rows that start with an empty (i.e. start with numbers,
in this case) string, I used Bill?s suggestion.
G <- lapply(FF, function(x) lapply(x, function (y) lapply(y,
function(z)   z[grepl("^[0-9][0-9]/",z[,1]),])))
S1 <-"\\s?.*\\s|^[0-9]x.*|.*[P-p]oints.*|.*\\sto\\s.*"
To remove some unwanted entries, I used this formula.
F <- lapply(G, function(x) lapply(x, function (y) lapply(y,
function(z) gsub(S1,"",z))))

Thanks again--EK
On Fri, Nov 2, 2018 at 11:00 AM Ek Esawi <esawiek at gmail.com> wrote:
>
> Hi All,
>
> I have a list that is made up of nested lists, as shown below. I want
> to remove all rows in each sub-list that start with an empty space,
> that?s the first entry of a row is blank; for example, on
> [[1]][[1]][[1]] Remove row 4,on [[1]][[1]][[3]] remove row 5, on
> [[1]][[2]][[1]] remove row 6, etc.. All rows start with 2 digits/ 2
> digits. My formula works on individual sublist but not the whole
> list.. I know my indexing is wrong, but don?t know how to fix it.
>
>
> > FF
>
> [[1]]
> [[1]][[1]]
> [[1]][[1]][[1]]
> [,1]    [,2]   [,3]    [,4] [,5]
> [1,] "30/20"   "AAAAAAAA" ?    ?   "-89"
> [2,] "02/20"   "AAAAAAAA? ?    ?   "-98"
> [3,] "02/20"   ?AAAAAAA? ?    ?   "-84"
> [4,] ?  ? ?  ?   ?
> [[1]][[1]][[2]]
> [,1]    [,2]
> [1,] "02/23" ?AAAAAAAA? : 29" ?
> [2,] "02/23" ?AAAAAAAA? ." ?
> [3,] "02/23" ?AAAAAAAA? " ?
> [4,] "02/23" ?AAAAAAAA? "
> [[1]][[1]][[3]]
> [,1]    [,2]    [,3] [,4] [,5] [,6] [,7]
> [1,] "01/09" ?AAAAAAAA"    ?   ?   ?   "53"
> [2,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "403"
> [3,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "83"
> [4,] "01/09" ?AAAAAAAA? "   ?   ?   ?   "783"
> [5,] ?  ?  ?AAAAAAAA?  3042742181"   ?   ?   ?   ?
> [[1]][[2]]
> [[1]][[2]][[1]]
> [,1]  [,2] [,3] [,4] [,5]
> [1,] ?    ?   ?   ?   ?AAAAAAAA? "
> [2,] "Standard Purchases"  ?   ?   ?   "
> [3,] "24/90 "AAAAAAAA? ?   "243"  "
> [4,] "24/90 "AAAAAAAA? "   "143"  "
> [5,] "24/91 "AAAAAAAA? " ?   "143" ?
> [6,] ?    ?   ?   ?   "792"
> [[1]][[2]][[2]]
> [,1]    [,2]
> [1,] "02/23" ?AAAAAAAA?: 31" ?
> [2,] "02/23" ?AAAAAAAA?." ?
> [3,] "02/23" ?AAAAAAAA? " ?
> [4,] "02/23" ?AAAAAAAA?
> [5,] "02/23" ?AAAAAAAA?
> [6,] "02/23" ?AAAAAAAA? 20"
> [7,] "02/23" ?AAAAAAAA?  ?
> [8,] "02/23" ?AAAAAAAA? "33"
> [[1]][[3]]
> [[1]][[3]][[1]]
> [,1]    [,2]
> [1,] "02/23" ?AAAAAAAA?: 28" ?
> [2,] "02/23" ?AAAAAAAA?." ?
> [3,] "02/23" ?AAAAAAAA? " ?
> [4,] "02/23" ?AAAAAAAA? "
> [[1]][[3]][[2]]
> [,1]    [,2]    [,3]    [,4] [,5] [,6] [,7]    [,8]    [,9]
> [1,] "02/23" ?AAAAAAAA? " ?   ?   "53" "
> [2,] "02/24" ?AAAAAAAA? " ?   ?   "
> [3,] ?  ?  ?  ?   ?   ?   ?  ?  "1,241"
> [4,] "02/24" "AAAAAAAA?  ?   "33?
>
> My Formula,:
>
> G <- lapply(FF, function(x) lapply(x, function (y) lapply(y,
> function(z)  z[grepl("^[0-9][0-9]/",z[,1]),])))
>
> The error: Error in z[, 1] : incorrect number of dimensions
>
>
>
> Thanks in advance--EK


From r@f4 @ending from cumc@columbi@@edu  Thu Nov  8 18:10:50 2018
From: r@f4 @ending from cumc@columbi@@edu (Friedman, Richard A.)
Date: Thu, 8 Nov 2018 17:10:50 +0000
Subject: [R] summary function does not work with Westfall correction in
 multcomp with 27 comparisons
Message-ID: <1DD1E628-D815-405A-868D-9C5E158B13CC@cumc.columbia.edu>

Dear List.

I ran multcomp with 27 comaprisons. The glht command returned an mcp object,
but the summary command with the Westfall correction ddi not give a summary.
When I ran the same dataset with 4 comparisons I got p-values. When I sued a summary with
univariate or Bonferroni?s method with all 27 comarisons I got p-values. But all 27 did not
work for Wesrfall. Please advise.
Here is a record of my session with 27 comparisons and Westfall:

R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[R.app GUI 1.70 (7543) x86_64-apple-darwin15.6.0]

[History restored from /Users/friedman/.Rapp.history]

objc[31790]: Class FIFinderSyncExtensionHost is implemented in both /System/Library/PrivateFrameworks/FinderKit.framework/Versions/A/FinderKit (0x7fff9c2b7c90) and /System/Library/PrivateFrameworks/FileProvider.framework/OverrideBundles/FinderSyncCollaborationFileProviderOverride.bundle/Contents/MacOS/FinderSyncCollaborationFileProviderOverride (0x119bf8cd8). One of the two will be used. Which one is undefined.
> library(multcomp)
Loading required package: mvtnorm
Loading required package: survival
Loading required package: TH.data
Loading required package: MASS

Attaching package: ?TH.data?

The following object is masked from ?package:MASS?:

    geyser

> tumor<-read.table("a8_1wayall_input.txt",sep="\t",header=T)
> class(tumor)
[1] "data.frame"
> dim(tumor)
[1] 309   2
> tumor[1,]
     condition  log2vol
1 aa.vector.4w 7.297375
>
> model<-lm(log2vol~condition,data=tumor)
> summary(model)

Call:
lm(formula = log2vol ~ condition, data = tumor)

Residuals:
   Min     1Q Median     3Q    Max
-7.997 -2.414  0.291  2.164  8.059

Coefficients:
                             Estimate Std. Error t value Pr(>|t|)
(Intercept)                   4.58776    0.60457   7.588  4.3e-13 ***
conditionab.vector.6w         1.39818    0.85499   1.635 0.103054
conditionac.vector.8w         2.89085    0.85499   3.381 0.000820 ***
conditionba.dnmt1kd.4w       -2.67491    0.84733  -3.157 0.001760 **
conditionbb.dnmt1kd.6w       -1.43390    0.84733  -1.692 0.091654 .
conditionbc.dnmt1kd.8w       -0.47188    0.84733  -0.557 0.578020
conditionca.dnmt3bkd.4w      -3.15325    0.89139  -3.537 0.000469 ***
conditioncb.dnmt3bkd.6w      -2.17334    0.89139  -2.438 0.015355 *
conditioncc.dnmt3bkd.8w      -1.50187    0.89139  -1.685 0.093078 .
conditionda.dnmt1kdhrad9.4w   1.08153    1.08991   0.992 0.321863
conditiondb.dnmt1kdhrad9.6w   2.38383    1.08991   2.187 0.029517 *
conditiondc.dnmt1kdhrad9.8w   3.53990    1.08991   3.248 0.001297 **
conditionea.dnmt3bkdhrad9.4w  0.02795    1.06049   0.026 0.978991
conditioneb.dnmt3bkdhrad9.6w  1.34037    1.06049   1.264 0.207263
conditionec.dnmt3bkdhrad9.8w  3.40955    1.06049   3.215 0.001449 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 3.141 on 294 degrees of freedom
Multiple R-squared:  0.3155, Adjusted R-squared:  0.2829
F-statistic: 9.678 on 14 and 294 DF,  p-value: < 2.2e-16

> model.mc<-glht(model,linfct=mcp(condition=c("ab.vector.6w-aa.vector.4w=0",
+                        "ac.vector.8w-aa.vector.4w=0",
+                        "ac.vector.8w-ab.vector.6w=0",
+       "bb.dnmt1kd.6w-ba.dnmt1kd.4w=0",
+                        "bc.dnmt1kd.8w-ba.dnmt1kd.4w=0",
+                        "bc.dnmt1kd.8w-bb.dnmt1kd.6w=0",
+         "cb.dnmt3bkd.6w-ca.dnmt3bkd.4w=0",
+                        "cc.dnmt3bkd.8w-ca.dnmt3bkd.4w=0",
+                        "cc.dnmt3bkd.8w-cb.dnmt3bkd.6w=0",
+         "db.dnmt1kdhrad9.6w-da.dnmt1kdhrad9.4w=0",
+                        "dc.dnmt1kdhrad9.8w-da.dnmt1kdhrad9.4w=0",
+                        "dc.dnmt1kdhrad9.8w-db.dnmt1kdhrad9.6w=0",
+         "eb.dnmt3bkdhrad9.6w-ea.dnmt3bkdhrad9.4w=0",
+                        "ec.dnmt3bkdhrad9.8w-ea.dnmt3bkdhrad9.4w=0",
+                        "ec.dnmt3bkdhrad9.8w-eb.dnmt3bkdhrad9.6w=0",
+       "ba.dnmt1kd.4w-aa.vector.4w=0",
+                        "ca.dnmt3bkd.4w-aa.vector.4w=0",
+                        "da.dnmt1kdhrad9.4w-ba.dnmt1kd.4w=0",
+                        "ea.dnmt3bkdhrad9.4w-ca.dnmt3bkd.4w=0",
+       "bb.dnmt1kd.6w-ab.vector.6w=0",
+                        "cb.dnmt3bkd.6w-ab.vector.6w=0",
+                        "db.dnmt1kdhrad9.6w-bb.dnmt1kd.6w=0",
+                        "eb.dnmt3bkdhrad9.6w-cb.dnmt3bkd.6w=0",
+       "bc.dnmt1kd.8w-ac.vector.8w=0",
+                        "cc.dnmt3bkd.8w-ac.vector.8w=0",
+                        "dc.dnmt1kdhrad9.8w-bc.dnmt1kd.8w=0",
+                        "ec.dnmt3bkdhrad9.8w-cc.dnmt3bkd.8w=0")))
>
> summary(model.mc,test=adjusted(type="Westfall"))

######################
THE PROGRAM FROZE AT THIS POINT AND DID NOT RETURN ANYTHING
HERE IS MY SESSION INFO

######################

> sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS High Sierra 10.13.6

Matrix products: default
BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] multcomp_1.4-8  TH.data_1.0-9   MASS_7.3-50     survival_2.42-6 mvtnorm_1.0-8

loaded via a namespace (and not attached):
[1] zoo_1.8-3        compiler_3.5.1   Matrix_1.2-14    sandwich_2.4-0   codetools_0.2-15 splines_3.5.1    grid_3.5.1       lattice_0.20-35

#############################

Why would the summary function not work with 27 comparisons with Westfall but work with 4 comparisons?
Why would the summary function not work with 27 comparisons with Westfall but work with the same  comparisons with Bonferroni?
Is the problem intrinsic to
A. Westfall?s , method with a large number of comarisons.
B, The impkementation of Westfall?s method in multcomp?
C. Machine requirements for Westfall?s method with so many comparisons?
D. My coding
E. Other.

I have used Westsall;?s method throught the paper which I am now working and would prefer to use it for this
problem for consistency.
I would appreciate any advice.


Thanks and best wishes,
Rich
Richard A. Friedman, PhD
Associate Research Scientist,
Biomedical Informatics Shared Resource
Herbert Irving Comprehensive Cancer Center (HICCC)
Lecturer,
Department of Biomedical Informatics (DBMI)
Room 825
Irving Cancer Research Center
Columbia University Herbert and Florence Irving Medical Center
1130 St. Nicholas Ave
New York, NY 10032
(212)851-4765 (voice)
raf4 at cumc.columbia.edu<mailto:raf4 at cumc.columbia.edu>

http://www.columbia.edu/~raf4/index.html


In memoriam, Steve Ditko


	[[alternative HTML version deleted]]


From gerrit@eichner @ending from m@th@uni-gie@@en@de  Thu Nov  8 18:46:48 2018
From: gerrit@eichner @ending from m@th@uni-gie@@en@de (Gerrit Eichner)
Date: Thu, 8 Nov 2018 18:46:48 +0100
Subject: [R] summary function does not work with Westfall correction in
 multcomp with 27 comparisons
In-Reply-To: <1DD1E628-D815-405A-868D-9C5E158B13CC@cumc.columbia.edu>
References: <1DD1E628-D815-405A-868D-9C5E158B13CC@cumc.columbia.edu>
Message-ID: <61f60b51-2098-1670-1a81-5cc9d5a195bc@math.uni-giessen.de>

Dear Rich,

w/o the original data we can actually only guess, but I think you
may haven't been patient enough to let summary.glht finish its
job. Have you tried to increase the number of contrasts, i.e.
comparisons, step by step to see how the computational burden and
hence the required computing time increases?

Internally, a lot effort goes into the computation of probabilities
and/or quantiles of multivariate normal or t distributions, and in
your setting they *are* high-dimensional. For more reliable and
elaborate details you may have to consult the cited references in
?summary.glht, or wait/hope for a more knowledgeable list member to
"jump in".

  Hth --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 08.11.2018 um 18:10 schrieb Friedman, Richard A.:
> Dear List.
> 
> I ran multcomp with 27 comaprisons. The glht command returned an mcp object,
> but the summary command with the Westfall correction ddi not give a summary.
> When I ran the same dataset with 4 comparisons I got p-values. When I sued a summary with
> univariate or Bonferroni?s method with all 27 comarisons I got p-values. But all 27 did not
> work for Wesrfall. Please advise.
> Here is a record of my session with 27 comparisons and Westfall:
> 
> R version 3.5.1 (2018-07-02) -- "Feather Spray"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
>    Natural language support but running in an English locale
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
> [R.app GUI 1.70 (7543) x86_64-apple-darwin15.6.0]
> 
> [History restored from /Users/friedman/.Rapp.history]
> 
> objc[31790]: Class FIFinderSyncExtensionHost is implemented in both /System/Library/PrivateFrameworks/FinderKit.framework/Versions/A/FinderKit (0x7fff9c2b7c90) and /System/Library/PrivateFrameworks/FileProvider.framework/OverrideBundles/FinderSyncCollaborationFileProviderOverride.bundle/Contents/MacOS/FinderSyncCollaborationFileProviderOverride (0x119bf8cd8). One of the two will be used. Which one is undefined.
>> library(multcomp)
> Loading required package: mvtnorm
> Loading required package: survival
> Loading required package: TH.data
> Loading required package: MASS
> 
> Attaching package: ?TH.data?
> 
> The following object is masked from ?package:MASS?:
> 
>      geyser
> 
>> tumor<-read.table("a8_1wayall_input.txt",sep="\t",header=T)
>> class(tumor)
> [1] "data.frame"
>> dim(tumor)
> [1] 309   2
>> tumor[1,]
>       condition  log2vol
> 1 aa.vector.4w 7.297375
>>
>> model<-lm(log2vol~condition,data=tumor)
>> summary(model)
> 
> Call:
> lm(formula = log2vol ~ condition, data = tumor)
> 
> Residuals:
>     Min     1Q Median     3Q    Max
> -7.997 -2.414  0.291  2.164  8.059
> 
> Coefficients:
>                               Estimate Std. Error t value Pr(>|t|)
> (Intercept)                   4.58776    0.60457   7.588  4.3e-13 ***
> conditionab.vector.6w         1.39818    0.85499   1.635 0.103054
> conditionac.vector.8w         2.89085    0.85499   3.381 0.000820 ***
> conditionba.dnmt1kd.4w       -2.67491    0.84733  -3.157 0.001760 **
> conditionbb.dnmt1kd.6w       -1.43390    0.84733  -1.692 0.091654 .
> conditionbc.dnmt1kd.8w       -0.47188    0.84733  -0.557 0.578020
> conditionca.dnmt3bkd.4w      -3.15325    0.89139  -3.537 0.000469 ***
> conditioncb.dnmt3bkd.6w      -2.17334    0.89139  -2.438 0.015355 *
> conditioncc.dnmt3bkd.8w      -1.50187    0.89139  -1.685 0.093078 .
> conditionda.dnmt1kdhrad9.4w   1.08153    1.08991   0.992 0.321863
> conditiondb.dnmt1kdhrad9.6w   2.38383    1.08991   2.187 0.029517 *
> conditiondc.dnmt1kdhrad9.8w   3.53990    1.08991   3.248 0.001297 **
> conditionea.dnmt3bkdhrad9.4w  0.02795    1.06049   0.026 0.978991
> conditioneb.dnmt3bkdhrad9.6w  1.34037    1.06049   1.264 0.207263
> conditionec.dnmt3bkdhrad9.8w  3.40955    1.06049   3.215 0.001449 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Residual standard error: 3.141 on 294 degrees of freedom
> Multiple R-squared:  0.3155, Adjusted R-squared:  0.2829
> F-statistic: 9.678 on 14 and 294 DF,  p-value: < 2.2e-16
> 
>> model.mc<-glht(model,linfct=mcp(condition=c("ab.vector.6w-aa.vector.4w=0",
> +                        "ac.vector.8w-aa.vector.4w=0",
> +                        "ac.vector.8w-ab.vector.6w=0",
> +       "bb.dnmt1kd.6w-ba.dnmt1kd.4w=0",
> +                        "bc.dnmt1kd.8w-ba.dnmt1kd.4w=0",
> +                        "bc.dnmt1kd.8w-bb.dnmt1kd.6w=0",
> +         "cb.dnmt3bkd.6w-ca.dnmt3bkd.4w=0",
> +                        "cc.dnmt3bkd.8w-ca.dnmt3bkd.4w=0",
> +                        "cc.dnmt3bkd.8w-cb.dnmt3bkd.6w=0",
> +         "db.dnmt1kdhrad9.6w-da.dnmt1kdhrad9.4w=0",
> +                        "dc.dnmt1kdhrad9.8w-da.dnmt1kdhrad9.4w=0",
> +                        "dc.dnmt1kdhrad9.8w-db.dnmt1kdhrad9.6w=0",
> +         "eb.dnmt3bkdhrad9.6w-ea.dnmt3bkdhrad9.4w=0",
> +                        "ec.dnmt3bkdhrad9.8w-ea.dnmt3bkdhrad9.4w=0",
> +                        "ec.dnmt3bkdhrad9.8w-eb.dnmt3bkdhrad9.6w=0",
> +       "ba.dnmt1kd.4w-aa.vector.4w=0",
> +                        "ca.dnmt3bkd.4w-aa.vector.4w=0",
> +                        "da.dnmt1kdhrad9.4w-ba.dnmt1kd.4w=0",
> +                        "ea.dnmt3bkdhrad9.4w-ca.dnmt3bkd.4w=0",
> +       "bb.dnmt1kd.6w-ab.vector.6w=0",
> +                        "cb.dnmt3bkd.6w-ab.vector.6w=0",
> +                        "db.dnmt1kdhrad9.6w-bb.dnmt1kd.6w=0",
> +                        "eb.dnmt3bkdhrad9.6w-cb.dnmt3bkd.6w=0",
> +       "bc.dnmt1kd.8w-ac.vector.8w=0",
> +                        "cc.dnmt3bkd.8w-ac.vector.8w=0",
> +                        "dc.dnmt1kdhrad9.8w-bc.dnmt1kd.8w=0",
> +                        "ec.dnmt3bkdhrad9.8w-cc.dnmt3bkd.8w=0")))
>>
>> summary(model.mc,test=adjusted(type="Westfall"))
> 
> ######################
> THE PROGRAM FROZE AT THIS POINT AND DID NOT RETURN ANYTHING
> HERE IS MY SESSION INFO
> 
> ######################
> 
>> sessionInfo()
> R version 3.5.1 (2018-07-02)
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
> Running under: macOS High Sierra 10.13.6
> 
> Matrix products: default
> BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
> LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] multcomp_1.4-8  TH.data_1.0-9   MASS_7.3-50     survival_2.42-6 mvtnorm_1.0-8
> 
> loaded via a namespace (and not attached):
> [1] zoo_1.8-3        compiler_3.5.1   Matrix_1.2-14    sandwich_2.4-0   codetools_0.2-15 splines_3.5.1    grid_3.5.1       lattice_0.20-35
> 
> #############################
> 
> Why would the summary function not work with 27 comparisons with Westfall but work with 4 comparisons?
> Why would the summary function not work with 27 comparisons with Westfall but work with the same  comparisons with Bonferroni?
> Is the problem intrinsic to
> A. Westfall?s , method with a large number of comarisons.
> B, The impkementation of Westfall?s method in multcomp?
> C. Machine requirements for Westfall?s method with so many comparisons?
> D. My coding
> E. Other.
> 
> I have used Westsall;?s method throught the paper which I am now working and would prefer to use it for this
> problem for consistency.
> I would appreciate any advice.
> 
> 
> Thanks and best wishes,
> Rich
> Richard A. Friedman, PhD
> Associate Research Scientist,
> Biomedical Informatics Shared Resource
> Herbert Irving Comprehensive Cancer Center (HICCC)
> Lecturer,
> Department of Biomedical Informatics (DBMI)
> Room 825
> Irving Cancer Research Center
> Columbia University Herbert and Florence Irving Medical Center
> 1130 St. Nicholas Ave
> New York, NY 10032
> (212)851-4765 (voice)
> raf4 at cumc.columbia.edu<mailto:raf4 at cumc.columbia.edu>
> 
> http://www.columbia.edu/~raf4/index.html
> 
> 
> In memoriam, Steve Ditko
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @imon@wood @ending from b@th@edu  Thu Nov  8 22:08:20 2018
From: @imon@wood @ending from b@th@edu (Simon Wood)
Date: Thu, 8 Nov 2018 21:08:20 +0000
Subject: [R] MGCV:: boundary conditions in gam
In-Reply-To: <CAGBzUO9E7KG8Pp_ahb48bAYFTj_HEMhmHw5jDscXJ7Bn+QthLw@mail.gmail.com>
References: <CAGBzUO9E7KG8Pp_ahb48bAYFTj_HEMhmHw5jDscXJ7Bn+QthLw@mail.gmail.com>
Message-ID: <704186bc-4d4f-e6c3-4311-5276703445d7@bath.edu>

This first derivative penalty spline will do it, but the price paid is 
that the curves are often quite wiggly.


library(mgcv); set.seed(5)

x <- runif(100); y <- x^4 + rnorm(100)*.1

b <- gam(y~s(x,m=1))

pd <- data.frame(x=seq(-.5,1.5,length=200))

ff <- predict(b,pd,se=TRUE)

plot(x,y,xlim=c(-.5,1.5));lines(pd$x,ff$fit)

lines(pd$x,ff$fit+2*ff$se.fit,lty=2)

lines(pd$x,ff$fit-2*ff$se.fit,lty=2)


On 08/11/2018 15:26, Mark R Payne wrote:
> Dear R-help,
>
> I have a problem where I am using the mgcv package to in a situation where
> I am fitting a gam model with a 1-D spline smoother model over a domain
> [a,b] but then need to make predictions and extrapolate beyond b. Is there
> anyway where I force the first derivative of the spline to be zero at
> boundaries, so that I simply get a constant value outside the domain?
>
> Best wishes,
>
> Mark
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From h@nn@h@hlx @ending from gm@il@com  Thu Nov  8 22:42:40 2018
From: h@nn@h@hlx @ending from gm@il@com (li li)
Date: Thu, 8 Nov 2018 16:42:40 -0500
Subject: [R] 
 Identify row indices corresponding to each distinct row of a matrix
In-Reply-To: <CAGxFJbTPdac0YSg+tApKaf+TvmSBZKS1HqyeR2WaKr+LUD4FnQ@mail.gmail.com>
References: <CAHLnndYRFRysTCZEbHpTsfb-TsCXHYCa2CN_AmMR4Ork2P6Rog@mail.gmail.com>
 <CAGxFJbTgZC4qVgxpCx7fVTu3nwaET+FoKWXE=iH2xWRzzGw52A@mail.gmail.com>
 <009DC65B-161A-4891-89DF-7660321BD8EE@dcn.davis.ca.us>
 <CAGxFJbTPdac0YSg+tApKaf+TvmSBZKS1HqyeR2WaKr+LUD4FnQ@mail.gmail.com>
Message-ID: <CAHLnndYz53bFML+WoEckuEAojC_XJ6_h82qLfpjz-3cWLUy=_w@mail.gmail.com>

Thanks to all the reply. I will try to use plain text in the future.
One question regarding using "which( ! duplicated( m, MARGIN=1 ) )".
This seems to return the fist row indices corresponding to the distinct
rows but it does not give all the row indices
corresponding to each of the distinct rows. For example, in the my example
below, rows 1, 13 15 are all (1,9).
Thanks.
  Hanna
> A <- matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16),8,2)
> B <- rbind(A,A,A)
> C <- as.data.frame(B[sample(nrow(B)),])
> C
   V1 V2
1   1  9
2   2 10
3   3 11
4   5 13
5   7 15
6   6 14
7   4 12
8   3 11
9   8 16
10  5 13
11  7 15
12  2 10
13  1  9
14  8 16
15  1  9
16  3 11
17  7 15
18  4 12
19  2 10
20  6 14
21  4 12
22  8 16
23  5 13
24  6 14
> T <- unique(C)
> T
  V1 V2
1  1  9
2  2 10
3  3 11
4  5 13
5  7 15
6  6 14
7  4 12
9  8 16
>
> i <- 1
> which(C[,1]==T[i,1]& C[,2]==T[i,2])
[1]  1 13 15


Bert Gunter <bgunter.4567 at gmail.com> ?2018?11?8??? ??10:43???

> Yes -- much better than mine. I didn't know about the MARGIN argument of
> duplicated().
>
> -- Bert
>
>
> On Wed, Nov 7, 2018 at 10:32 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
>> Perhaps
>>
>> which( ! duplicated( m, MARGIN=1 ) )
>>
>> ? (untested)
>>
>> On November 7, 2018 9:20:57 PM PST, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> >A mess -- due to your continued use of html formatting.
>> >
>> >But something like this may do what you want (hard to tell with the
>> >mess):
>> >
>> >> m <- matrix(1:16,nrow=8)[rep(1:8,2),]
>> >> m
>> >      [,1] [,2]
>> > [1,]    1    9
>> > [2,]    2   10
>> > [3,]    3   11
>> > [4,]    4   12
>> > [5,]    5   13
>> > [6,]    6   14
>> > [7,]    7   15
>> > [8,]    8   16
>> > [9,]    1    9
>> >[10,]    2   10
>> >[11,]    3   11
>> >[12,]    4   12
>> >[13,]    5   13
>> >[14,]    6   14
>> >[15,]    7   15
>> >[16,]    8   16
>> >> vec <- apply(m,1,paste,collapse="-") ## converts rows into character
>> >vector
>> >> vec
>> >[1] "1-9"  "2-10" "3-11" "4-12" "5-13" "6-14" "7-15" "8-16" "1-9"
>> >"2-10"
>> >"3-11" "4-12" "5-13" "6-14"
>> >[15] "7-15" "8-16"
>> >> ## Then maybe:
>> >> tapply(seq_along(vec),vec, I)
>> >$`1-9`
>> >[1] 1 9
>> >
>> >$`2-10`
>> >[1]  2 10
>> >
>> >$`3-11`
>> >[1]  3 11
>> >
>> >$`4-12`
>> >[1]  4 12
>> >
>> >$`5-13`
>> >[1]  5 13
>> >
>> >$`6-14`
>> >[1]  6 14
>> >
>> >$`7-15`
>> >[1]  7 15
>> >
>> >$`8-16`
>> >[1]  8 16
>> >
>> >> ## gives the row numbers for each unique row
>> >
>> >There may well be slicker ways to do this -- if this is actually what
>> >you
>> >want to do.
>> >
>> >-- Bert
>> >
>> >
>> >
>> >On Wed, Nov 7, 2018 at 7:56 PM li li <hannah.hlx at gmail.com> wrote:
>> >
>> >> Hi all,
>> >>    I use the following example to illustrate my question. As you can
>> >see,
>> >> in matrix C some rows are repeated and I would like to find the
>> >indices of
>> >> the rows corresponding to each of the distinct rows.
>> >>   For example, for the row c(1,9), I have used the "which" function
>> >to
>> >> identify the row indices corresponding to c(1,9). Using this
>> >approach, in
>> >> order to cover all distinct rows, I need to use a for loop.
>> >>    I am wondering whether there is an easier way where a for loop can
>> >be
>> >> avoided?
>> >>    Thanks very much!
>> >>       Hanna
>> >>
>> >>
>> >>
>> >> > A <- matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16),8,2)> B <-
>> >> rbind(A,A,A)> C <- as.data.frame(B[sample(nrow(B)),])> C   V1 V2
>> >> 1   1  9
>> >> 2   2 10
>> >> 3   3 11
>> >> 4   5 13
>> >> 5   7 15
>> >> 6   6 14
>> >> 7   4 12
>> >> 8   3 11
>> >> 9   8 16
>> >> 10  5 13
>> >> 11  7 15
>> >> 12  2 10
>> >> 13  1  9
>> >> 14  8 16
>> >> 15  1  9
>> >> 16  3 11
>> >> 17  7 15
>> >> 18  4 12
>> >> 19  2 10
>> >> 20  6 14
>> >> 21  4 12
>> >> 22  8 16
>> >> 23  5 13
>> >> 24  6 14> T <- unique(C)> T  V1 V2
>> >> 1  1  9
>> >> 2  2 10
>> >> 3  3 11
>> >> 4  5 13
>> >> 5  7 15
>> >> 6  6 14
>> >> 7  4 12
>> >> 9  8 16> > i <- 1                    > which(C[,1]==T[i,1]&
>> >> C[,2]==T[i,2])[1]  1 13 15
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Thu Nov  8 23:16:41 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Thu, 8 Nov 2018 14:16:41 -0800
Subject: [R] 
 Identify row indices corresponding to each distinct row of a matrix
In-Reply-To: <CAHLnndYz53bFML+WoEckuEAojC_XJ6_h82qLfpjz-3cWLUy=_w@mail.gmail.com>
References: <CAHLnndYRFRysTCZEbHpTsfb-TsCXHYCa2CN_AmMR4Ork2P6Rog@mail.gmail.com>
 <CAGxFJbTgZC4qVgxpCx7fVTu3nwaET+FoKWXE=iH2xWRzzGw52A@mail.gmail.com>
 <009DC65B-161A-4891-89DF-7660321BD8EE@dcn.davis.ca.us>
 <CAGxFJbTPdac0YSg+tApKaf+TvmSBZKS1HqyeR2WaKr+LUD4FnQ@mail.gmail.com>
 <CAHLnndYz53bFML+WoEckuEAojC_XJ6_h82qLfpjz-3cWLUy=_w@mail.gmail.com>
Message-ID: <CAF8bMcap0CGxgtrwt+--SV2=0+8oj-jroZ+ZJSaH3CmtdGexLA@mail.gmail.com>

One way, rather clumsy, is to convert your data.frame in a character vector
or list. via an invertible tranformation, and use match on it.  E.g.,

> tmp <- do.call(paste, c(list(sep="\001"), unname(C))) # convert to
character
> # or tmp <- split(C, seq_len(nrow(C))) # convert to list of its rows
> g <- match(tmp, unique(tmp))
> g
 [1] 1 2 3 4 5 6 7 3 8 4 5 2 1 8 1 3 5 7 2 6 7 8 4 6
> split(seq_along(g), g)
$`1`
[1]  1 13 15

$`2`
[1]  2 12 19
...
$`8`
[1]  9 14 22

Both ways work for nice enough inputs, but converting to text can cause
problems if the 'sep' is in any of input text and match() on lists of lists
used
to have problems when the inner lists were big.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Nov 8, 2018 at 1:42 PM, li li <hannah.hlx at gmail.com> wrote:

> Thanks to all the reply. I will try to use plain text in the future.
> One question regarding using "which( ! duplicated( m, MARGIN=1 ) )".
> This seems to return the fist row indices corresponding to the distinct
> rows but it does not give all the row indices
> corresponding to each of the distinct rows. For example, in the my example
> below, rows 1, 13 15 are all (1,9).
> Thanks.
>   Hanna
> > A <- matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16),8,2)
> > B <- rbind(A,A,A)
> > C <- as.data.frame(B[sample(nrow(B)),])
> > C
>    V1 V2
> 1   1  9
> 2   2 10
> 3   3 11
> 4   5 13
> 5   7 15
> 6   6 14
> 7   4 12
> 8   3 11
> 9   8 16
> 10  5 13
> 11  7 15
> 12  2 10
> 13  1  9
> 14  8 16
> 15  1  9
> 16  3 11
> 17  7 15
> 18  4 12
> 19  2 10
> 20  6 14
> 21  4 12
> 22  8 16
> 23  5 13
> 24  6 14
> > T <- unique(C)
> > T
>   V1 V2
> 1  1  9
> 2  2 10
> 3  3 11
> 4  5 13
> 5  7 15
> 6  6 14
> 7  4 12
> 9  8 16
> >
> > i <- 1
> > which(C[,1]==T[i,1]& C[,2]==T[i,2])
> [1]  1 13 15
>
>
> Bert Gunter <bgunter.4567 at gmail.com> ?2018?11?8??? ??10:43???
>
> > Yes -- much better than mine. I didn't know about the MARGIN argument of
> > duplicated().
> >
> > -- Bert
> >
> >
> > On Wed, Nov 7, 2018 at 10:32 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us
> >
> > wrote:
> >
> >> Perhaps
> >>
> >> which( ! duplicated( m, MARGIN=1 ) )
> >>
> >> ? (untested)
> >>
> >> On November 7, 2018 9:20:57 PM PST, Bert Gunter <bgunter.4567 at gmail.com
> >
> >> wrote:
> >> >A mess -- due to your continued use of html formatting.
> >> >
> >> >But something like this may do what you want (hard to tell with the
> >> >mess):
> >> >
> >> >> m <- matrix(1:16,nrow=8)[rep(1:8,2),]
> >> >> m
> >> >      [,1] [,2]
> >> > [1,]    1    9
> >> > [2,]    2   10
> >> > [3,]    3   11
> >> > [4,]    4   12
> >> > [5,]    5   13
> >> > [6,]    6   14
> >> > [7,]    7   15
> >> > [8,]    8   16
> >> > [9,]    1    9
> >> >[10,]    2   10
> >> >[11,]    3   11
> >> >[12,]    4   12
> >> >[13,]    5   13
> >> >[14,]    6   14
> >> >[15,]    7   15
> >> >[16,]    8   16
> >> >> vec <- apply(m,1,paste,collapse="-") ## converts rows into character
> >> >vector
> >> >> vec
> >> >[1] "1-9"  "2-10" "3-11" "4-12" "5-13" "6-14" "7-15" "8-16" "1-9"
> >> >"2-10"
> >> >"3-11" "4-12" "5-13" "6-14"
> >> >[15] "7-15" "8-16"
> >> >> ## Then maybe:
> >> >> tapply(seq_along(vec),vec, I)
> >> >$`1-9`
> >> >[1] 1 9
> >> >
> >> >$`2-10`
> >> >[1]  2 10
> >> >
> >> >$`3-11`
> >> >[1]  3 11
> >> >
> >> >$`4-12`
> >> >[1]  4 12
> >> >
> >> >$`5-13`
> >> >[1]  5 13
> >> >
> >> >$`6-14`
> >> >[1]  6 14
> >> >
> >> >$`7-15`
> >> >[1]  7 15
> >> >
> >> >$`8-16`
> >> >[1]  8 16
> >> >
> >> >> ## gives the row numbers for each unique row
> >> >
> >> >There may well be slicker ways to do this -- if this is actually what
> >> >you
> >> >want to do.
> >> >
> >> >-- Bert
> >> >
> >> >
> >> >
> >> >On Wed, Nov 7, 2018 at 7:56 PM li li <hannah.hlx at gmail.com> wrote:
> >> >
> >> >> Hi all,
> >> >>    I use the following example to illustrate my question. As you can
> >> >see,
> >> >> in matrix C some rows are repeated and I would like to find the
> >> >indices of
> >> >> the rows corresponding to each of the distinct rows.
> >> >>   For example, for the row c(1,9), I have used the "which" function
> >> >to
> >> >> identify the row indices corresponding to c(1,9). Using this
> >> >approach, in
> >> >> order to cover all distinct rows, I need to use a for loop.
> >> >>    I am wondering whether there is an easier way where a for loop can
> >> >be
> >> >> avoided?
> >> >>    Thanks very much!
> >> >>       Hanna
> >> >>
> >> >>
> >> >>
> >> >> > A <- matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16),8,2)> B <-
> >> >> rbind(A,A,A)> C <- as.data.frame(B[sample(nrow(B)),])> C   V1 V2
> >> >> 1   1  9
> >> >> 2   2 10
> >> >> 3   3 11
> >> >> 4   5 13
> >> >> 5   7 15
> >> >> 6   6 14
> >> >> 7   4 12
> >> >> 8   3 11
> >> >> 9   8 16
> >> >> 10  5 13
> >> >> 11  7 15
> >> >> 12  2 10
> >> >> 13  1  9
> >> >> 14  8 16
> >> >> 15  1  9
> >> >> 16  3 11
> >> >> 17  7 15
> >> >> 18  4 12
> >> >> 19  2 10
> >> >> 20  6 14
> >> >> 21  4 12
> >> >> 22  8 16
> >> >> 23  5 13
> >> >> 24  6 14> T <- unique(C)> T  V1 V2
> >> >> 1  1  9
> >> >> 2  2 10
> >> >> 3  3 11
> >> >> 4  5 13
> >> >> 5  7 15
> >> >> 6  6 14
> >> >> 7  4 12
> >> >> 9  8 16> > i <- 1                    > which(C[,1]==T[i,1]&
> >> >> C[,2]==T[i,2])[1]  1 13 15
> >> >>
> >> >>         [[alternative HTML version deleted]]
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Nov  9 02:05:12 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 08 Nov 2018 17:05:12 -0800
Subject: [R] 
 Identify row indices corresponding to each distinct row of a matrix
In-Reply-To: <CAHLnndYz53bFML+WoEckuEAojC_XJ6_h82qLfpjz-3cWLUy=_w@mail.gmail.com>
References: <CAHLnndYRFRysTCZEbHpTsfb-TsCXHYCa2CN_AmMR4Ork2P6Rog@mail.gmail.com>
 <CAGxFJbTgZC4qVgxpCx7fVTu3nwaET+FoKWXE=iH2xWRzzGw52A@mail.gmail.com>
 <009DC65B-161A-4891-89DF-7660321BD8EE@dcn.davis.ca.us>
 <CAGxFJbTPdac0YSg+tApKaf+TvmSBZKS1HqyeR2WaKr+LUD4FnQ@mail.gmail.com>
 <CAHLnndYz53bFML+WoEckuEAojC_XJ6_h82qLfpjz-3cWLUy=_w@mail.gmail.com>
Message-ID: <B2F0DEFE-AE33-46FB-B14B-0B8E33A68D9E@dcn.davis.ca.us>

The duplicated function returns TRUE for rows that have already appeared... exactly one of the rows is not represented in the output of duplicated. For the intended purpose of removing duplicates this behavior is ideal. I have no idea what your intended purpose is, since every row has duplicates elsewhere in the matrix. If you really want every set identified this way then a loop/apply seems inevitable (most opportunities for optimization come about by not visiting every combination).

Cm <- as.matrix( C )
D <- which( !duplicated( Cm, MARGIN=1 ) )
nCm <- nrow( Cm )
F <- lapply( D, function(d) {
   idxrep <- rep( d, nCm )
   which( 0 == unname( rowSums( Cm[idxrep,] != Cm ) ) )
  } )


On November 8, 2018 1:42:40 PM PST, li li <hannah.hlx at gmail.com> wrote:
>Thanks to all the reply. I will try to use plain text in the future.
>One question regarding using "which( ! duplicated( m, MARGIN=1 ) )".
>This seems to return the fist row indices corresponding to the distinct
>rows but it does not give all the row indices
>corresponding to each of the distinct rows. For example, in the my
>example
>below, rows 1, 13 15 are all (1,9).
>Thanks.
>  Hanna
>> A <- matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16),8,2)
>> B <- rbind(A,A,A)
>> C <- as.data.frame(B[sample(nrow(B)),])
>> C
>   V1 V2
>1   1  9
>2   2 10
>3   3 11
>4   5 13
>5   7 15
>6   6 14
>7   4 12
>8   3 11
>9   8 16
>10  5 13
>11  7 15
>12  2 10
>13  1  9
>14  8 16
>15  1  9
>16  3 11
>17  7 15
>18  4 12
>19  2 10
>20  6 14
>21  4 12
>22  8 16
>23  5 13
>24  6 14
>> T <- unique(C)
>> T
>  V1 V2
>1  1  9
>2  2 10
>3  3 11
>4  5 13
>5  7 15
>6  6 14
>7  4 12
>9  8 16
>>
>> i <- 1
>> which(C[,1]==T[i,1]& C[,2]==T[i,2])
>[1]  1 13 15
>
>
>Bert Gunter <bgunter.4567 at gmail.com> ?2018?11?8??? ??10:43???
>
>> Yes -- much better than mine. I didn't know about the MARGIN argument
>of
>> duplicated().
>>
>> -- Bert
>>
>>
>> On Wed, Nov 7, 2018 at 10:32 PM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>> wrote:
>>
>>> Perhaps
>>>
>>> which( ! duplicated( m, MARGIN=1 ) )
>>>
>>> ? (untested)
>>>
>>> On November 7, 2018 9:20:57 PM PST, Bert Gunter
><bgunter.4567 at gmail.com>
>>> wrote:
>>> >A mess -- due to your continued use of html formatting.
>>> >
>>> >But something like this may do what you want (hard to tell with the
>>> >mess):
>>> >
>>> >> m <- matrix(1:16,nrow=8)[rep(1:8,2),]
>>> >> m
>>> >      [,1] [,2]
>>> > [1,]    1    9
>>> > [2,]    2   10
>>> > [3,]    3   11
>>> > [4,]    4   12
>>> > [5,]    5   13
>>> > [6,]    6   14
>>> > [7,]    7   15
>>> > [8,]    8   16
>>> > [9,]    1    9
>>> >[10,]    2   10
>>> >[11,]    3   11
>>> >[12,]    4   12
>>> >[13,]    5   13
>>> >[14,]    6   14
>>> >[15,]    7   15
>>> >[16,]    8   16
>>> >> vec <- apply(m,1,paste,collapse="-") ## converts rows into
>character
>>> >vector
>>> >> vec
>>> >[1] "1-9"  "2-10" "3-11" "4-12" "5-13" "6-14" "7-15" "8-16" "1-9"
>>> >"2-10"
>>> >"3-11" "4-12" "5-13" "6-14"
>>> >[15] "7-15" "8-16"
>>> >> ## Then maybe:
>>> >> tapply(seq_along(vec),vec, I)
>>> >$`1-9`
>>> >[1] 1 9
>>> >
>>> >$`2-10`
>>> >[1]  2 10
>>> >
>>> >$`3-11`
>>> >[1]  3 11
>>> >
>>> >$`4-12`
>>> >[1]  4 12
>>> >
>>> >$`5-13`
>>> >[1]  5 13
>>> >
>>> >$`6-14`
>>> >[1]  6 14
>>> >
>>> >$`7-15`
>>> >[1]  7 15
>>> >
>>> >$`8-16`
>>> >[1]  8 16
>>> >
>>> >> ## gives the row numbers for each unique row
>>> >
>>> >There may well be slicker ways to do this -- if this is actually
>what
>>> >you
>>> >want to do.
>>> >
>>> >-- Bert
>>> >
>>> >
>>> >
>>> >On Wed, Nov 7, 2018 at 7:56 PM li li <hannah.hlx at gmail.com> wrote:
>>> >
>>> >> Hi all,
>>> >>    I use the following example to illustrate my question. As you
>can
>>> >see,
>>> >> in matrix C some rows are repeated and I would like to find the
>>> >indices of
>>> >> the rows corresponding to each of the distinct rows.
>>> >>   For example, for the row c(1,9), I have used the "which"
>function
>>> >to
>>> >> identify the row indices corresponding to c(1,9). Using this
>>> >approach, in
>>> >> order to cover all distinct rows, I need to use a for loop.
>>> >>    I am wondering whether there is an easier way where a for loop
>can
>>> >be
>>> >> avoided?
>>> >>    Thanks very much!
>>> >>       Hanna
>>> >>
>>> >>
>>> >>
>>> >> > A <- matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16),8,2)> B
><-
>>> >> rbind(A,A,A)> C <- as.data.frame(B[sample(nrow(B)),])> C   V1 V2
>>> >> 1   1  9
>>> >> 2   2 10
>>> >> 3   3 11
>>> >> 4   5 13
>>> >> 5   7 15
>>> >> 6   6 14
>>> >> 7   4 12
>>> >> 8   3 11
>>> >> 9   8 16
>>> >> 10  5 13
>>> >> 11  7 15
>>> >> 12  2 10
>>> >> 13  1  9
>>> >> 14  8 16
>>> >> 15  1  9
>>> >> 16  3 11
>>> >> 17  7 15
>>> >> 18  4 12
>>> >> 19  2 10
>>> >> 20  6 14
>>> >> 21  4 12
>>> >> 22  8 16
>>> >> 23  5 13
>>> >> 24  6 14> T <- unique(C)> T  V1 V2
>>> >> 1  1  9
>>> >> 2  2 10
>>> >> 3  3 11
>>> >> 4  5 13
>>> >> 5  7 15
>>> >> 6  6 14
>>> >> 7  4 12
>>> >> 9  8 16> > i <- 1                    > which(C[,1]==T[i,1]&
>>> >> C[,2]==T[i,2])[1]  1 13 15
>>> >>
>>> >>         [[alternative HTML version deleted]]
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide
>>> >> http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible
>code.
>>> >>
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> >______________________________________________
>>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>> >PLEASE do read the posting guide
>>> >http://www.R-project.org/posting-guide.html
>>> >and provide commented, minimal, self-contained, reproducible code.
>>>
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>

-- 
Sent from my phone. Please excuse my brevity.


From h@nn@h@hlx @ending from gm@il@com  Fri Nov  9 04:23:42 2018
From: h@nn@h@hlx @ending from gm@il@com (li li)
Date: Thu, 8 Nov 2018 22:23:42 -0500
Subject: [R] 
 Identify row indices corresponding to each distinct row of a matrix
In-Reply-To: <B2F0DEFE-AE33-46FB-B14B-0B8E33A68D9E@dcn.davis.ca.us>
References: <CAHLnndYRFRysTCZEbHpTsfb-TsCXHYCa2CN_AmMR4Ork2P6Rog@mail.gmail.com>
 <CAGxFJbTgZC4qVgxpCx7fVTu3nwaET+FoKWXE=iH2xWRzzGw52A@mail.gmail.com>
 <009DC65B-161A-4891-89DF-7660321BD8EE@dcn.davis.ca.us>
 <CAGxFJbTPdac0YSg+tApKaf+TvmSBZKS1HqyeR2WaKr+LUD4FnQ@mail.gmail.com>
 <CAHLnndYz53bFML+WoEckuEAojC_XJ6_h82qLfpjz-3cWLUy=_w@mail.gmail.com>
 <B2F0DEFE-AE33-46FB-B14B-0B8E33A68D9E@dcn.davis.ca.us>
Message-ID: <CAHLnndZOSBZHy196FP-ZygLhxCETj_CxdTX8haX0oxmO6RLWSA@mail.gmail.com>

Thanks. It makes sense.

Jeff Newmiller <jdnewmil at dcn.davis.ca.us> ?2018?11?8??? ??8:05???

> The duplicated function returns TRUE for rows that have already
> appeared... exactly one of the rows is not represented in the output of
> duplicated. For the intended purpose of removing duplicates this behavior
> is ideal. I have no idea what your intended purpose is, since every row has
> duplicates elsewhere in the matrix. If you really want every set identified
> this way then a loop/apply seems inevitable (most opportunities for
> optimization come about by not visiting every combination).
>
> Cm <- as.matrix( C )
> D <- which( !duplicated( Cm, MARGIN=1 ) )
> nCm <- nrow( Cm )
> F <- lapply( D, function(d) {
>    idxrep <- rep( d, nCm )
>    which( 0 == unname( rowSums( Cm[idxrep,] != Cm ) ) )
>   } )
>
>
> On November 8, 2018 1:42:40 PM PST, li li <hannah.hlx at gmail.com> wrote:
> >Thanks to all the reply. I will try to use plain text in the future.
> >One question regarding using "which( ! duplicated( m, MARGIN=1 ) )".
> >This seems to return the fist row indices corresponding to the distinct
> >rows but it does not give all the row indices
> >corresponding to each of the distinct rows. For example, in the my
> >example
> >below, rows 1, 13 15 are all (1,9).
> >Thanks.
> >  Hanna
> >> A <- matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16),8,2)
> >> B <- rbind(A,A,A)
> >> C <- as.data.frame(B[sample(nrow(B)),])
> >> C
> >   V1 V2
> >1   1  9
> >2   2 10
> >3   3 11
> >4   5 13
> >5   7 15
> >6   6 14
> >7   4 12
> >8   3 11
> >9   8 16
> >10  5 13
> >11  7 15
> >12  2 10
> >13  1  9
> >14  8 16
> >15  1  9
> >16  3 11
> >17  7 15
> >18  4 12
> >19  2 10
> >20  6 14
> >21  4 12
> >22  8 16
> >23  5 13
> >24  6 14
> >> T <- unique(C)
> >> T
> >  V1 V2
> >1  1  9
> >2  2 10
> >3  3 11
> >4  5 13
> >5  7 15
> >6  6 14
> >7  4 12
> >9  8 16
> >>
> >> i <- 1
> >> which(C[,1]==T[i,1]& C[,2]==T[i,2])
> >[1]  1 13 15
> >
> >
> >Bert Gunter <bgunter.4567 at gmail.com> ?2018?11?8??? ??10:43???
> >
> >> Yes -- much better than mine. I didn't know about the MARGIN argument
> >of
> >> duplicated().
> >>
> >> -- Bert
> >>
> >>
> >> On Wed, Nov 7, 2018 at 10:32 PM Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >> wrote:
> >>
> >>> Perhaps
> >>>
> >>> which( ! duplicated( m, MARGIN=1 ) )
> >>>
> >>> ? (untested)
> >>>
> >>> On November 7, 2018 9:20:57 PM PST, Bert Gunter
> ><bgunter.4567 at gmail.com>
> >>> wrote:
> >>> >A mess -- due to your continued use of html formatting.
> >>> >
> >>> >But something like this may do what you want (hard to tell with the
> >>> >mess):
> >>> >
> >>> >> m <- matrix(1:16,nrow=8)[rep(1:8,2),]
> >>> >> m
> >>> >      [,1] [,2]
> >>> > [1,]    1    9
> >>> > [2,]    2   10
> >>> > [3,]    3   11
> >>> > [4,]    4   12
> >>> > [5,]    5   13
> >>> > [6,]    6   14
> >>> > [7,]    7   15
> >>> > [8,]    8   16
> >>> > [9,]    1    9
> >>> >[10,]    2   10
> >>> >[11,]    3   11
> >>> >[12,]    4   12
> >>> >[13,]    5   13
> >>> >[14,]    6   14
> >>> >[15,]    7   15
> >>> >[16,]    8   16
> >>> >> vec <- apply(m,1,paste,collapse="-") ## converts rows into
> >character
> >>> >vector
> >>> >> vec
> >>> >[1] "1-9"  "2-10" "3-11" "4-12" "5-13" "6-14" "7-15" "8-16" "1-9"
> >>> >"2-10"
> >>> >"3-11" "4-12" "5-13" "6-14"
> >>> >[15] "7-15" "8-16"
> >>> >> ## Then maybe:
> >>> >> tapply(seq_along(vec),vec, I)
> >>> >$`1-9`
> >>> >[1] 1 9
> >>> >
> >>> >$`2-10`
> >>> >[1]  2 10
> >>> >
> >>> >$`3-11`
> >>> >[1]  3 11
> >>> >
> >>> >$`4-12`
> >>> >[1]  4 12
> >>> >
> >>> >$`5-13`
> >>> >[1]  5 13
> >>> >
> >>> >$`6-14`
> >>> >[1]  6 14
> >>> >
> >>> >$`7-15`
> >>> >[1]  7 15
> >>> >
> >>> >$`8-16`
> >>> >[1]  8 16
> >>> >
> >>> >> ## gives the row numbers for each unique row
> >>> >
> >>> >There may well be slicker ways to do this -- if this is actually
> >what
> >>> >you
> >>> >want to do.
> >>> >
> >>> >-- Bert
> >>> >
> >>> >
> >>> >
> >>> >On Wed, Nov 7, 2018 at 7:56 PM li li <hannah.hlx at gmail.com> wrote:
> >>> >
> >>> >> Hi all,
> >>> >>    I use the following example to illustrate my question. As you
> >can
> >>> >see,
> >>> >> in matrix C some rows are repeated and I would like to find the
> >>> >indices of
> >>> >> the rows corresponding to each of the distinct rows.
> >>> >>   For example, for the row c(1,9), I have used the "which"
> >function
> >>> >to
> >>> >> identify the row indices corresponding to c(1,9). Using this
> >>> >approach, in
> >>> >> order to cover all distinct rows, I need to use a for loop.
> >>> >>    I am wondering whether there is an easier way where a for loop
> >can
> >>> >be
> >>> >> avoided?
> >>> >>    Thanks very much!
> >>> >>       Hanna
> >>> >>
> >>> >>
> >>> >>
> >>> >> > A <- matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16),8,2)> B
> ><-
> >>> >> rbind(A,A,A)> C <- as.data.frame(B[sample(nrow(B)),])> C   V1 V2
> >>> >> 1   1  9
> >>> >> 2   2 10
> >>> >> 3   3 11
> >>> >> 4   5 13
> >>> >> 5   7 15
> >>> >> 6   6 14
> >>> >> 7   4 12
> >>> >> 8   3 11
> >>> >> 9   8 16
> >>> >> 10  5 13
> >>> >> 11  7 15
> >>> >> 12  2 10
> >>> >> 13  1  9
> >>> >> 14  8 16
> >>> >> 15  1  9
> >>> >> 16  3 11
> >>> >> 17  7 15
> >>> >> 18  4 12
> >>> >> 19  2 10
> >>> >> 20  6 14
> >>> >> 21  4 12
> >>> >> 22  8 16
> >>> >> 23  5 13
> >>> >> 24  6 14> T <- unique(C)> T  V1 V2
> >>> >> 1  1  9
> >>> >> 2  2 10
> >>> >> 3  3 11
> >>> >> 4  5 13
> >>> >> 5  7 15
> >>> >> 6  6 14
> >>> >> 7  4 12
> >>> >> 9  8 16> > i <- 1                    > which(C[,1]==T[i,1]&
> >>> >> C[,2]==T[i,2])[1]  1 13 15
> >>> >>
> >>> >>         [[alternative HTML version deleted]]
> >>> >>
> >>> >> ______________________________________________
> >>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >> PLEASE do read the posting guide
> >>> >> http://www.R-project.org/posting-guide.html
> >>> >> and provide commented, minimal, self-contained, reproducible
> >code.
> >>> >>
> >>> >
> >>> >       [[alternative HTML version deleted]]
> >>> >
> >>> >______________________________________________
> >>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> >https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >PLEASE do read the posting guide
> >>> >http://www.R-project.org/posting-guide.html
> >>> >and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> --
> >>> Sent from my phone. Please excuse my brevity.
> >>>
> >>
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From h@nn@h@hlx @ending from gm@il@com  Fri Nov  9 05:05:39 2018
From: h@nn@h@hlx @ending from gm@il@com (li li)
Date: Thu, 8 Nov 2018 23:05:39 -0500
Subject: [R] list contingency tables
Message-ID: <CAHLnndaNEwtrif9SJXaWqF4eT6TABwjSABLCpEo7XMTFX0G-Pg@mail.gmail.com>

Hi all,
  I am trying to list all the 4 by 2 tables with some fixed margins.
  For example, consider 4 by 2 tables with row margins 1,2,2,1 and
column margins 3,3. I was able to do it using the code below. However,
as seen below, I had to first count the total number of tables with
the specific row margins and column margins in order to create space
to store the tables.
Is there a way to skip the step of counting the number of tables?
  Also, wanted to avoid for loops as much as possible since it can be
extremely slow and inefficient.
   Thanks so much in advance for you insight and help.
       Hanna



> library(gtools)
> A <- permutations(n=4,r=2,v=0:3, repeats.allowed=TRUE)
> B <- apply(A, 1, sum)
> rmg <- c(1,2,2,1)
> cmg <- c(3,3)
> m1 <- t(A[which(B==1),])
> m2 <- t(A[which(B==2),])
> m3 <- t(A[which(B==2),])
>
> ##count number of tables with row margins 1,2,2,1 and column margins 3,3.
> num <- 0
> for (i in 1:ncol(m1)){
+     for (j in 1:ncol(m2)){
+         for (k in 1:ncol(m3)){
+             M <- t(cbind(m1[,i], m2[,j], m3[,k]))
+             M1 <- rbind(M, cmg-apply(M,2,sum))
+             num <- num+(sum(M1[4,] < 0) == 0)
+         }}}
>
>
> #create space to store the tables
> C <- array(NA, dim=c(4,2,num))
>
> # list all the tables with fixed margins
> num <- 0
> for (i in 1:ncol(m1)){
+     for (j in 1:ncol(m2)){
+         for (k in 1:ncol(m3)){
+             M <- t(cbind(m1[,i], m2[,j], m3[,k]))
+             M1 <- rbind(M,cmg-apply(M,2,sum))
+             if (sum(M1[4,] < 0) == 0) {
+                 num <- num+1
+                C[,,num] <- M1
+             }
+         }}}
>
> C
, , 1

     [,1] [,2]
[1,]    0    1
[2,]    0    2
[3,]    2    0
[4,]    1    0

, , 2

     [,1] [,2]
[1,]    0    1
[2,]    1    1
[3,]    1    1
[4,]    1    0

, , 3

     [,1] [,2]
[1,]    0    1
[2,]    1    1
[3,]    2    0
[4,]    0    1

, , 4

     [,1] [,2]
[1,]    0    1
[2,]    2    0
[3,]    0    2
[4,]    1    0

, , 5

     [,1] [,2]
[1,]    0    1
[2,]    2    0
[3,]    1    1
[4,]    0    1

, , 6

     [,1] [,2]
[1,]    1    0
[2,]    0    2
[3,]    1    1
[4,]    1    0

, , 7

     [,1] [,2]
[1,]    1    0
[2,]    0    2
[3,]    2    0
[4,]    0    1

, , 8

     [,1] [,2]
[1,]    1    0
[2,]    1    1
[3,]    0    2
[4,]    1    0

, , 9

     [,1] [,2]
[1,]    1    0
[2,]    1    1
[3,]    1    1
[4,]    0    1

, , 10

     [,1] [,2]
[1,]    1    0
[2,]    2    0
[3,]    0    2
[4,]    0    1


From pob@rrett @ending from gm@il@com  Thu Nov  8 16:28:26 2018
From: pob@rrett @ending from gm@il@com (Philip Barrett)
Date: Thu, 8 Nov 2018 15:28:26 +0000
Subject: [R] [R-pkgs] New Package pgsc
Message-ID: <CAHprtLT-5NBm6Qw0_Fsf==H_5UiHfbrVbVUd+wUUa73V3SJ5fg@mail.gmail.com>

Dear all,

I am pleased to announce a new CRAN package, "pgsc" version 1.0.0 <
https://cran.r-project.org/package=pgsc>.

This package implements the extension of the synthetic control method to
allow for continuous and time-varying treatments described in Powell (2017)
<doi:10.7249/WR1142>.  Functions for both estimation and general hypothesis
testing are provided.

The vignette presents an extended example where panel regression suffers
from omitted variables bias -- even with time and unit fixed effects -- and
shows how the generalized synthetic control method produces unbiased
estimates of treatment effects.  The vignette can be found at <
https://cran.r-project.org/web/packages/pgsc/vignettes/pgsc_vignette.pdf>.

Suggestions and comments much appreciated,

Philip Barrett

Email: pobarrett at gmail dot com
Github: https://github.com/philipbarrett/pgsc

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From rebecc@@bingert @ending from gmx@de  Fri Nov  9 13:11:04 2018
From: rebecc@@bingert @ending from gmx@de (Rebecca Bingert)
Date: Fri, 9 Nov 2018 13:11:04 +0100
Subject: [R] randomForrest-imputation
Message-ID: <269a8d6e-fdb5-27b9-4d0d-411d75257d7c@gmx.de>

Hi!

How can I generate only positive data with randomForrest-imputation? I'm
working with laboratory values which are always positive.

Can anybody help out?

Thanks!

(P.S.: I needed to send this request again because there were problems by delivering it)


From toth@dene@ @ending from kogentum@hu  Fri Nov  9 16:05:15 2018
From: toth@dene@ @ending from kogentum@hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Fri, 9 Nov 2018 16:05:15 +0100
Subject: [R] randomForrest-imputation
In-Reply-To: <269a8d6e-fdb5-27b9-4d0d-411d75257d7c@gmx.de>
References: <269a8d6e-fdb5-27b9-4d0d-411d75257d7c@gmx.de>
Message-ID: <12c7b3a2-b6ed-ccbd-1cb7-3dd026664444@kogentum.hu>

Hi,

The missRanger package performs predictive mean matching which should 
generate positive values if the non-missing values are positive.

Regards,
Denes


On 11/09/2018 01:11 PM, Rebecca Bingert wrote:
> Hi!
> 
> How can I generate only positive data with randomForrest-imputation? I'm
> working with laboratory values which are always positive.
> 
> Can anybody help out?
> 
> Thanks!
> 
> (P.S.: I needed to send this request again because there were problems 
> by delivering it)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@iliP@dpo@t @ending from gm@il@com  Fri Nov  9 19:45:10 2018
From: m@iliP@dpo@t @ending from gm@il@com (Medic)
Date: Fri, 9 Nov 2018 21:45:10 +0300
Subject: [R] HISTOGRAM
Message-ID: <CAH6117+3tOS9=ofXkiaY2qnRpWrQOFzR9=GQdF+JG3ckfzrUDA@mail.gmail.com>

What would be the correct code (simplest version) (without gplot())
for histogram (with 7 bars), which would include 7 names of bars under
the X-axis. The data are:

name number
ds    6277
lk     24375
ax    46049
dd    70656
az    216544
df     220620
gh    641827

(I'm attaching mydata.r, making with dput.)

My attempt is:

options(scipen=999)
with (mydata, hist(number))

P.S. I can't understand how the column "name" to include in a code

From ruipb@rr@d@@ @ending from @@po@pt  Fri Nov  9 21:25:31 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Fri, 9 Nov 2018 20:25:31 +0000
Subject: [R] HISTOGRAM
In-Reply-To: <CAH6117+3tOS9=ofXkiaY2qnRpWrQOFzR9=GQdF+JG3ckfzrUDA@mail.gmail.com>
References: <CAH6117+3tOS9=ofXkiaY2qnRpWrQOFzR9=GQdF+JG3ckfzrUDA@mail.gmail.com>
Message-ID: <8d26fc9f-7b4a-b636-0fcb-9ba098676777@sapo.pt>

Hello,

You probably want a bar plot, not a histogram.

old.sci <- options(scipen=999)
with(mydata, barplot(number, space = 0, names.arg = name, beside = TRUE))
options(scipen = old.sci)


#-----------------

mydata <- read.table(text = "
name number
ds    6277
lk     24375
ax    46049
dd    70656
az    216544
df     220620
gh    641827
", header = TRUE)
mydata


Hope this helps,

Rui Barradas

?s 18:45 de 09/11/2018, Medic escreveu:
> What would be the correct code (simplest version) (without gplot())
> for histogram (with 7 bars), which would include 7 names of bars under
> the X-axis. The data are:
> 
> name number
> ds    6277
> lk     24375
> ax    46049
> dd    70656
> az    216544
> df     220620
> gh    641827
> 
> (I'm attaching mydata.r, making with dput.)
> 
> My attempt is:
> 
> options(scipen=999)
> with (mydata, hist(number))
> 
> P.S. I can't understand how the column "name" to include in a code
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Nov  9 21:26:27 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Fri, 09 Nov 2018 12:26:27 -0800
Subject: [R] list contingency tables
In-Reply-To: <CAHLnndaNEwtrif9SJXaWqF4eT6TABwjSABLCpEo7XMTFX0G-Pg@mail.gmail.com>
References: <CAHLnndaNEwtrif9SJXaWqF4eT6TABwjSABLCpEo7XMTFX0G-Pg@mail.gmail.com>
Message-ID: <C66018A3-DA32-4C28-A98A-9FEDF0BEDD90@dcn.davis.ca.us>

Don't give up on for loops entirely... some of the largest time savings in optimizing loops are achieved by managing memory effectively. [1]

[1] https://www.r-bloggers.com/r-tip-use-vectormode-list-to-pre-allocate-lists


On November 8, 2018 8:05:39 PM PST, li li <hannah.hlx at gmail.com> wrote:
>Hi all,
>  I am trying to list all the 4 by 2 tables with some fixed margins.
>  For example, consider 4 by 2 tables with row margins 1,2,2,1 and
>column margins 3,3. I was able to do it using the code below. However,
>as seen below, I had to first count the total number of tables with
>the specific row margins and column margins in order to create space
>to store the tables.
>Is there a way to skip the step of counting the number of tables?
>  Also, wanted to avoid for loops as much as possible since it can be
>extremely slow and inefficient.
>   Thanks so much in advance for you insight and help.
>       Hanna
>
>
>
>> library(gtools)
>> A <- permutations(n=4,r=2,v=0:3, repeats.allowed=TRUE)
>> B <- apply(A, 1, sum)
>> rmg <- c(1,2,2,1)
>> cmg <- c(3,3)
>> m1 <- t(A[which(B==1),])
>> m2 <- t(A[which(B==2),])
>> m3 <- t(A[which(B==2),])
>>
>> ##count number of tables with row margins 1,2,2,1 and column margins
>3,3.
>> num <- 0
>> for (i in 1:ncol(m1)){
>+     for (j in 1:ncol(m2)){
>+         for (k in 1:ncol(m3)){
>+             M <- t(cbind(m1[,i], m2[,j], m3[,k]))
>+             M1 <- rbind(M, cmg-apply(M,2,sum))
>+             num <- num+(sum(M1[4,] < 0) == 0)
>+         }}}
>>
>>
>> #create space to store the tables
>> C <- array(NA, dim=c(4,2,num))
>>
>> # list all the tables with fixed margins
>> num <- 0
>> for (i in 1:ncol(m1)){
>+     for (j in 1:ncol(m2)){
>+         for (k in 1:ncol(m3)){
>+             M <- t(cbind(m1[,i], m2[,j], m3[,k]))
>+             M1 <- rbind(M,cmg-apply(M,2,sum))
>+             if (sum(M1[4,] < 0) == 0) {
>+                 num <- num+1
>+                C[,,num] <- M1
>+             }
>+         }}}
>>
>> C
>, , 1
>
>     [,1] [,2]
>[1,]    0    1
>[2,]    0    2
>[3,]    2    0
>[4,]    1    0
>
>, , 2
>
>     [,1] [,2]
>[1,]    0    1
>[2,]    1    1
>[3,]    1    1
>[4,]    1    0
>
>, , 3
>
>     [,1] [,2]
>[1,]    0    1
>[2,]    1    1
>[3,]    2    0
>[4,]    0    1
>
>, , 4
>
>     [,1] [,2]
>[1,]    0    1
>[2,]    2    0
>[3,]    0    2
>[4,]    1    0
>
>, , 5
>
>     [,1] [,2]
>[1,]    0    1
>[2,]    2    0
>[3,]    1    1
>[4,]    0    1
>
>, , 6
>
>     [,1] [,2]
>[1,]    1    0
>[2,]    0    2
>[3,]    1    1
>[4,]    1    0
>
>, , 7
>
>     [,1] [,2]
>[1,]    1    0
>[2,]    0    2
>[3,]    2    0
>[4,]    0    1
>
>, , 8
>
>     [,1] [,2]
>[1,]    1    0
>[2,]    1    1
>[3,]    0    2
>[4,]    1    0
>
>, , 9
>
>     [,1] [,2]
>[1,]    1    0
>[2,]    1    1
>[3,]    1    1
>[4,]    0    1
>
>, , 10
>
>     [,1] [,2]
>[1,]    1    0
>[2,]    2    0
>[3,]    0    2
>[4,]    0    1
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From dwin@emiu@ @ending from comc@@t@net  Fri Nov  9 21:28:58 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Fri, 9 Nov 2018 12:28:58 -0800
Subject: [R] list contingency tables
In-Reply-To: <CAHLnndaNEwtrif9SJXaWqF4eT6TABwjSABLCpEo7XMTFX0G-Pg@mail.gmail.com>
References: <CAHLnndaNEwtrif9SJXaWqF4eT6TABwjSABLCpEo7XMTFX0G-Pg@mail.gmail.com>
Message-ID: <29fd0c62-bf21-0ea1-6220-b65858555a94@comcast.net>

Seems like you are trying to recreate the calculations needed to perform 
an exact test. Why not look at the code for that or even easier, just 
use the function.

-- 

David.

On 11/8/18 8:05 PM, li li wrote:
> Hi all,
>    I am trying to list all the 4 by 2 tables with some fixed margins.
>    For example, consider 4 by 2 tables with row margins 1,2,2,1 and
> column margins 3,3. I was able to do it using the code below. However,
> as seen below, I had to first count the total number of tables with
> the specific row margins and column margins in order to create space
> to store the tables.
> Is there a way to skip the step of counting the number of tables?
>    Also, wanted to avoid for loops as much as possible since it can be
> extremely slow and inefficient.
>     Thanks so much in advance for you insight and help.
>         Hanna
>
>
>
>> library(gtools)
>> A <- permutations(n=4,r=2,v=0:3, repeats.allowed=TRUE)
>> B <- apply(A, 1, sum)
>> rmg <- c(1,2,2,1)
>> cmg <- c(3,3)
>> m1 <- t(A[which(B==1),])
>> m2 <- t(A[which(B==2),])
>> m3 <- t(A[which(B==2),])
>>
>> ##count number of tables with row margins 1,2,2,1 and column margins 3,3.
>> num <- 0
>> for (i in 1:ncol(m1)){
> +     for (j in 1:ncol(m2)){
> +         for (k in 1:ncol(m3)){
> +             M <- t(cbind(m1[,i], m2[,j], m3[,k]))
> +             M1 <- rbind(M, cmg-apply(M,2,sum))
> +             num <- num+(sum(M1[4,] < 0) == 0)
> +         }}}
>>
>> #create space to store the tables
>> C <- array(NA, dim=c(4,2,num))
>>
>> # list all the tables with fixed margins
>> num <- 0
>> for (i in 1:ncol(m1)){
> +     for (j in 1:ncol(m2)){
> +         for (k in 1:ncol(m3)){
> +             M <- t(cbind(m1[,i], m2[,j], m3[,k]))
> +             M1 <- rbind(M,cmg-apply(M,2,sum))
> +             if (sum(M1[4,] < 0) == 0) {
> +                 num <- num+1
> +                C[,,num] <- M1
> +             }
> +         }}}
>> C
> , , 1
>
>       [,1] [,2]
> [1,]    0    1
> [2,]    0    2
> [3,]    2    0
> [4,]    1    0
>
> , , 2
>
>       [,1] [,2]
> [1,]    0    1
> [2,]    1    1
> [3,]    1    1
> [4,]    1    0
>
> , , 3
>
>       [,1] [,2]
> [1,]    0    1
> [2,]    1    1
> [3,]    2    0
> [4,]    0    1
>
> , , 4
>
>       [,1] [,2]
> [1,]    0    1
> [2,]    2    0
> [3,]    0    2
> [4,]    1    0
>
> , , 5
>
>       [,1] [,2]
> [1,]    0    1
> [2,]    2    0
> [3,]    1    1
> [4,]    0    1
>
> , , 6
>
>       [,1] [,2]
> [1,]    1    0
> [2,]    0    2
> [3,]    1    1
> [4,]    1    0
>
> , , 7
>
>       [,1] [,2]
> [1,]    1    0
> [2,]    0    2
> [3,]    2    0
> [4,]    0    1
>
> , , 8
>
>       [,1] [,2]
> [1,]    1    0
> [2,]    1    1
> [3,]    0    2
> [4,]    1    0
>
> , , 9
>
>       [,1] [,2]
> [1,]    1    0
> [2,]    1    1
> [3,]    1    1
> [4,]    0    1
>
> , , 10
>
>       [,1] [,2]
> [1,]    1    0
> [2,]    2    0
> [3,]    0    2
> [4,]    0    1
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @ending from gm@il@com  Fri Nov  9 21:55:52 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 9 Nov 2018 12:55:52 -0800
Subject: [R] list contingency tables
In-Reply-To: <29fd0c62-bf21-0ea1-6220-b65858555a94@comcast.net>
References: <CAHLnndaNEwtrif9SJXaWqF4eT6TABwjSABLCpEo7XMTFX0G-Pg@mail.gmail.com>
 <29fd0c62-bf21-0ea1-6220-b65858555a94@comcast.net>
Message-ID: <CAGxFJbQGnaXmSJ9zvJcGaxBfW=SOWV4B83Q1zfOYocBF4_NjgQ@mail.gmail.com>

Yes, exactly (heh, heh).

?fisher.test

is probably what is wanted.

For arbitrary rxc tables with fixed marginals, this is a difficult problem.
Mehta's efficient network algorithm to solve it can be found by a web
search on "algorithm for Fisher exact test."

-- Bert



On Fri, Nov 9, 2018 at 12:36 PM David Winsemius <dwinsemius at comcast.net>
wrote:

> Seems like you are trying to recreate the calculations needed to perform
> an exact test. Why not look at the code for that or even easier, just
> use the function.
>
> --
>
> David.
>
> On 11/8/18 8:05 PM, li li wrote:
> > Hi all,
> >    I am trying to list all the 4 by 2 tables with some fixed margins.
> >    For example, consider 4 by 2 tables with row margins 1,2,2,1 and
> > column margins 3,3. I was able to do it using the code below. However,
> > as seen below, I had to first count the total number of tables with
> > the specific row margins and column margins in order to create space
> > to store the tables.
> > Is there a way to skip the step of counting the number of tables?
> >    Also, wanted to avoid for loops as much as possible since it can be
> > extremely slow and inefficient.
> >     Thanks so much in advance for you insight and help.
> >         Hanna
> >
> >
> >
> >> library(gtools)
> >> A <- permutations(n=4,r=2,v=0:3, repeats.allowed=TRUE)
> >> B <- apply(A, 1, sum)
> >> rmg <- c(1,2,2,1)
> >> cmg <- c(3,3)
> >> m1 <- t(A[which(B==1),])
> >> m2 <- t(A[which(B==2),])
> >> m3 <- t(A[which(B==2),])
> >>
> >> ##count number of tables with row margins 1,2,2,1 and column margins
> 3,3.
> >> num <- 0
> >> for (i in 1:ncol(m1)){
> > +     for (j in 1:ncol(m2)){
> > +         for (k in 1:ncol(m3)){
> > +             M <- t(cbind(m1[,i], m2[,j], m3[,k]))
> > +             M1 <- rbind(M, cmg-apply(M,2,sum))
> > +             num <- num+(sum(M1[4,] < 0) == 0)
> > +         }}}
> >>
> >> #create space to store the tables
> >> C <- array(NA, dim=c(4,2,num))
> >>
> >> # list all the tables with fixed margins
> >> num <- 0
> >> for (i in 1:ncol(m1)){
> > +     for (j in 1:ncol(m2)){
> > +         for (k in 1:ncol(m3)){
> > +             M <- t(cbind(m1[,i], m2[,j], m3[,k]))
> > +             M1 <- rbind(M,cmg-apply(M,2,sum))
> > +             if (sum(M1[4,] < 0) == 0) {
> > +                 num <- num+1
> > +                C[,,num] <- M1
> > +             }
> > +         }}}
> >> C
> > , , 1
> >
> >       [,1] [,2]
> > [1,]    0    1
> > [2,]    0    2
> > [3,]    2    0
> > [4,]    1    0
> >
> > , , 2
> >
> >       [,1] [,2]
> > [1,]    0    1
> > [2,]    1    1
> > [3,]    1    1
> > [4,]    1    0
> >
> > , , 3
> >
> >       [,1] [,2]
> > [1,]    0    1
> > [2,]    1    1
> > [3,]    2    0
> > [4,]    0    1
> >
> > , , 4
> >
> >       [,1] [,2]
> > [1,]    0    1
> > [2,]    2    0
> > [3,]    0    2
> > [4,]    1    0
> >
> > , , 5
> >
> >       [,1] [,2]
> > [1,]    0    1
> > [2,]    2    0
> > [3,]    1    1
> > [4,]    0    1
> >
> > , , 6
> >
> >       [,1] [,2]
> > [1,]    1    0
> > [2,]    0    2
> > [3,]    1    1
> > [4,]    1    0
> >
> > , , 7
> >
> >       [,1] [,2]
> > [1,]    1    0
> > [2,]    0    2
> > [3,]    2    0
> > [4,]    0    1
> >
> > , , 8
> >
> >       [,1] [,2]
> > [1,]    1    0
> > [2,]    1    1
> > [3,]    0    2
> > [4,]    1    0
> >
> > , , 9
> >
> >       [,1] [,2]
> > [1,]    1    0
> > [2,]    1    1
> > [3,]    1    1
> > [4,]    0    1
> >
> > , , 10
> >
> >       [,1] [,2]
> > [1,]    1    0
> > [2,]    2    0
> > [3,]    0    2
> > [4,]    0    1
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From v@lkremk @ending from gm@il@com  Sat Nov 10 02:40:24 2018
From: v@lkremk @ending from gm@il@com (Val)
Date: Fri, 9 Nov 2018 19:40:24 -0600
Subject: [R] Read
Message-ID: <CAJOiR6aQy6cVTM54KA2=ov5bNFvTyfW7kUet_XMTnYUBSLMexA@mail.gmail.com>

HI all,
I am trying to read a csv file, but  have a problem in the row names.
After reading, the name of the first column is now "row.names" and
all other column names are shifted to the right. The value of the last
column become all NAs( as an extra column).

My sample data looks like as follow,
filename = dat.csv
The first row has a missing value at column 3 and 5. The last row has
a missing value at column 1 and  5
x1,x2,x3,x4,x5
12,13,,14,,
22,23,24,25,26
,33,34,34,
To read the file I used this

dsh<-read.csv(file="dat.csv",sep=",",row.names=NULL,fill=TRUE,header=TRUE,comment.char
= "", quote = "", stringsAsFactors = FALSE)

The output  from the above  is
dsh

 row.names x1 x2 x3 x4 x5
1        12 13 NA 14 NA  NA
2        22 23 24 25 26  NA
3             33 34 34 NA  NA

The name of teh frist column is row,banes and all values of last columns is NAs


However, the desired output should be
 x1 x2 x3 x4 x5
 12 13 NA 14 NA
 22 23 24 25 26
 NA 33 34 34 NA


How can I fix this?
Thank you in advance


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Nov 10 03:46:37 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Fri, 9 Nov 2018 18:46:37 -0800 (PST)
Subject: [R] Read
In-Reply-To: <CAJOiR6aQy6cVTM54KA2=ov5bNFvTyfW7kUet_XMTnYUBSLMexA@mail.gmail.com>
References: <CAJOiR6aQy6cVTM54KA2=ov5bNFvTyfW7kUet_XMTnYUBSLMexA@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1811091833001.22361@pedal.dcn.davis.ca.us>

Your file has 5 commas in the first data row, but only 4 in the header. R 
interprets this to mean your first column is intended to be row names (has 
no corresponding column label) rather than data. (Row names are "outside" 
the data frame... use str(dsh) to get a better picture.)

Basically, your file does not conform to consistent practices for csv 
files of having the same number of commas in every row. If at all possible 
I would eliminate the extra comma. If you have many of these broken files, 
you might need to read the data in pieces... e.g.

dsh <- read.csv( "dat.csv", header=FALSE, skip=1 )
dsh <- dsh[ , -length( dsh ) ]
dshh <- read.csv( "dat.csv", header=TRUE, nrow=1)
names( dsh ) <- names( dshh )

On Fri, 9 Nov 2018, Val wrote:

> HI all,
> I am trying to read a csv file, but  have a problem in the row names.
> After reading, the name of the first column is now "row.names" and
> all other column names are shifted to the right. The value of the last
> column become all NAs( as an extra column).
>
> My sample data looks like as follow,
> filename = dat.csv
> The first row has a missing value at column 3 and 5. The last row has
> a missing value at column 1 and  5
> x1,x2,x3,x4,x5
> 12,13,,14,,
> 22,23,24,25,26
> ,33,34,34,
> To read the file I used this
>
> dsh<-read.csv(file="dat.csv",sep=",",row.names=NULL,fill=TRUE,header=TRUE,comment.char
> = "", quote = "", stringsAsFactors = FALSE)
>
> The output  from the above  is
> dsh
>
> row.names x1 x2 x3 x4 x5
> 1        12 13 NA 14 NA  NA
> 2        22 23 24 25 26  NA
> 3             33 34 34 NA  NA
>
> The name of teh frist column is row,banes and all values of last columns is NAs
>
>
> However, the desired output should be
> x1 x2 x3 x4 x5
> 12 13 NA 14 NA
> 22 23 24 25 26
> NA 33 34 34 NA
>
>
> How can I fix this?
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From ruipb@rr@d@@ @ending from @@po@pt  Sat Nov 10 07:41:45 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Sat, 10 Nov 2018 06:41:45 +0000
Subject: [R] Read
In-Reply-To: <alpine.BSF.2.00.1811091833001.22361@pedal.dcn.davis.ca.us>
References: <CAJOiR6aQy6cVTM54KA2=ov5bNFvTyfW7kUet_XMTnYUBSLMexA@mail.gmail.com>
 <alpine.BSF.2.00.1811091833001.22361@pedal.dcn.davis.ca.us>
Message-ID: <f8cca72a-48d1-7833-e011-38c344ed5462@sapo.pt>

Hello,

I've just tested Jeff's solution, it works but the second code line 
should be

dsh <- sh[ , -length( sh ) ]


(dsh doesn't exist yet.)

Hope this helps,

Rui Barradas

?s 02:46 de 10/11/2018, Jeff Newmiller escreveu:
> Your file has 5 commas in the first data row, but only 4 in the header. 
> R interprets this to mean your first column is intended to be row names 
> (has no corresponding column label) rather than data. (Row names are 
> "outside" the data frame... use str(dsh) to get a better picture.)
> 
> Basically, your file does not conform to consistent practices for csv 
> files of having the same number of commas in every row. If at all 
> possible I would eliminate the extra comma. If you have many of these 
> broken files, you might need to read the data in pieces... e.g.
> 
> dsh <- read.csv( "dat.csv", header=FALSE, skip=1 )
> dsh <- dsh[ , -length( dsh ) ]
> dshh <- read.csv( "dat.csv", header=TRUE, nrow=1)
> names( dsh ) <- names( dshh )
> 
> On Fri, 9 Nov 2018, Val wrote:
> 
>> HI all,
>> I am trying to read a csv file, but? have a problem in the row names.
>> After reading, the name of the first column is now "row.names" and
>> all other column names are shifted to the right. The value of the last
>> column become all NAs( as an extra column).
>>
>> My sample data looks like as follow,
>> filename = dat.csv
>> The first row has a missing value at column 3 and 5. The last row has
>> a missing value at column 1 and? 5
>> x1,x2,x3,x4,x5
>> 12,13,,14,,
>> 22,23,24,25,26
>> ,33,34,34,
>> To read the file I used this
>>
>> dsh<-read.csv(file="dat.csv",sep=",",row.names=NULL,fill=TRUE,header=TRUE,comment.char 
>>
>> = "", quote = "", stringsAsFactors = FALSE)
>>
>> The output? from the above? is
>> dsh
>>
>> row.names x1 x2 x3 x4 x5
>> 1??????? 12 13 NA 14 NA? NA
>> 2??????? 22 23 24 25 26? NA
>> 3???????????? 33 34 34 NA? NA
>>
>> The name of teh frist column is row,banes and all values of last 
>> columns is NAs
>>
>>
>> However, the desired output should be
>> x1 x2 x3 x4 x5
>> 12 13 NA 14 NA
>> 22 23 24 25 26
>> NA 33 34 34 NA
>>
>>
>> How can I fix this?
>> Thank you in advance
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller??????????????????????? The???? .....?????? .....? Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>??????? Basics: ##.#.?????? ##.#.? Live Go...
>  ????????????????????????????????????? Live:?? OO#.. Dead: OO#..? Playing
> Research Engineer (Solar/Batteries??????????? O.O#.?????? #.O#.? with
> /Software/Embedded Controllers)?????????????? .OO#.?????? .OO#.? rocks...1k
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@bilonick @ending from gm@il@com  Sat Nov 10 01:25:52 2018
From: r@bilonick @ending from gm@il@com (Rick Bilonick)
Date: Fri, 9 Nov 2018 19:25:52 -0500
Subject: [R] HISTOGRAM
In-Reply-To: <CAH6117+3tOS9=ofXkiaY2qnRpWrQOFzR9=GQdF+JG3ckfzrUDA@mail.gmail.com>
References: <CAH6117+3tOS9=ofXkiaY2qnRpWrQOFzR9=GQdF+JG3ckfzrUDA@mail.gmail.com>
Message-ID: <CAPQaafkpiH6N7oxNa+93-xkcs2j9JQhxrofbN5ReUD3NVzyGgA@mail.gmail.com>

First, a histogram would not be appropriate (your data appear to be
categorical - a histogram is for continuous numeric vales) - you would need
a bar plot. You should make two vectors (one for the category names and the
other for the frequencies) and use the barplot function.

On Fri, Nov 9, 2018 at 1:46 PM Medic <mailiPadpost at gmail.com> wrote:

> What would be the correct code (simplest version) (without gplot())
> for histogram (with 7 bars), which would include 7 names of bars under
> the X-axis. The data are:
>
> name number
> ds    6277
> lk     24375
> ax    46049
> dd    70656
> az    216544
> df     220620
> gh    641827
>
> (I'm attaching mydata.r, making with dput.)
>
> My attempt is:
>
> options(scipen=999)
> with (mydata, hist(number))
>
> P.S. I can't understand how the column "name" to include in a code
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7Crab45%40pitt.edu%7C55f2571738b246f9dc1e08d646739b27%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C636773859721875419&amp;sdata=haHuxll2%2FO0Dci0fSpd0evjfi0MTmLi0JoghvHxlz3o%3D&amp;reserved=0
> PLEASE do read the posting guide
> https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&amp;data=02%7C01%7Crab45%40pitt.edu%7C55f2571738b246f9dc1e08d646739b27%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C636773859721875419&amp;sdata=aL6arSyKx4m9LBdOMhdhSpsdJmGCHubfdI%2Fns4Rgytw%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Sat Nov 10 10:45:38 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Sat, 10 Nov 2018 20:45:38 +1100
Subject: [R] HISTOGRAM
In-Reply-To: <CAH6117+3tOS9=ofXkiaY2qnRpWrQOFzR9=GQdF+JG3ckfzrUDA@mail.gmail.com>
References: <CAH6117+3tOS9=ofXkiaY2qnRpWrQOFzR9=GQdF+JG3ckfzrUDA@mail.gmail.com>
Message-ID: <CA+8X3fVFYqgK1ad4dLFiTP7p9psps8poaYr6jNxWBg4CLzrAfQ@mail.gmail.com>

Hi Medic,
Perhaps this:

medic_df<-read.table(text="name number
ds    6277
lk     24375
ax    46049
dd    70656
az    216544
df     220620
gh    641827",
header=TRUE)
library(plotrix)
options(scipen=10)
barp(medic_df$number,names.arg=medic_df$name,width=0.5)

As others have noted, this is really a barplot with no spaces between the bars.

Jim
On Sat, Nov 10, 2018 at 5:46 AM Medic <mailiPadpost at gmail.com> wrote:
>
> What would be the correct code (simplest version) (without gplot())
> for histogram (with 7 bars), which would include 7 names of bars under
> the X-axis. The data are:
>
> name number
> ds    6277
> lk     24375
> ax    46049
> dd    70656
> az    216544
> df     220620
> gh    641827
>
> (I'm attaching mydata.r, making with dput.)
>
> My attempt is:
>
> options(scipen=999)
> with (mydata, hist(number))
>
> P.S. I can't understand how the column "name" to include in a code
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From i@t@z@hn @ending from gm@il@com  Sat Nov 10 13:33:39 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Sat, 10 Nov 2018 07:33:39 -0500
Subject: [R] Read
In-Reply-To: <CAJOiR6aQy6cVTM54KA2=ov5bNFvTyfW7kUet_XMTnYUBSLMexA@mail.gmail.com>
References: <CAJOiR6aQy6cVTM54KA2=ov5bNFvTyfW7kUet_XMTnYUBSLMexA@mail.gmail.com>
Message-ID: <CA+vqiLGcLQAxSjW0kUVxRC7xPqCLuwKqJNE2Hv0tv4Q9r=c0=g@mail.gmail.com>

readr::read_csv produces the desired result by default:

readr::read_csv("x1,x2,x3,x4,x5
12,13,,14,,
22,23,24,25,26
,33,34,34,")

Best,
Ista
On Fri, Nov 9, 2018 at 8:40 PM Val <valkremk at gmail.com> wrote:
>
> HI all,
> I am trying to read a csv file, but  have a problem in the row names.
> After reading, the name of the first column is now "row.names" and
> all other column names are shifted to the right. The value of the last
> column become all NAs( as an extra column).
>
> My sample data looks like as follow,
> filename = dat.csv
> The first row has a missing value at column 3 and 5. The last row has
> a missing value at column 1 and  5
> x1,x2,x3,x4,x5
> 12,13,,14,,
> 22,23,24,25,26
> ,33,34,34,
> To read the file I used this
>
> dsh<-read.csv(file="dat.csv",sep=",",row.names=NULL,fill=TRUE,header=TRUE,comment.char
> = "", quote = "", stringsAsFactors = FALSE)
>
> The output  from the above  is
> dsh
>
>  row.names x1 x2 x3 x4 x5
> 1        12 13 NA 14 NA  NA
> 2        22 23 24 25 26  NA
> 3             33 34 34 NA  NA
>
> The name of teh frist column is row,banes and all values of last columns is NAs
>
>
> However, the desired output should be
>  x1 x2 x3 x4 x5
>  12 13 NA 14 NA
>  22 23 24 25 26
>  NA 33 34 34 NA
>
>
> How can I fix this?
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@ilip@dpo@t @ending from gm@il@com  Sat Nov 10 18:35:41 2018
From: m@ilip@dpo@t @ending from gm@il@com (Medic)
Date: Sat, 10 Nov 2018 20:35:41 +0300
Subject: [R] HISTOGRAM
Message-ID: <CAF-ms1o-Ds1eUHN5LdhRyZ3TjhfV28qCbJdomRP_T8q=TDP4Dw@mail.gmail.com>

Rui Barradas,
thank you for your prompt response, your code will be useful to me in
the future!

Rick Bilonick ("your data appear to be categorical"),
thank you very much for your comment (I would have to more correctly
express my task).

JIM Lemon,
THANKS!!! THIS IS EXACTLY what I needed!


From v@lkremk @ending from gm@il@com  Sat Nov 10 19:23:45 2018
From: v@lkremk @ending from gm@il@com (Val)
Date: Sat, 10 Nov 2018 12:23:45 -0600
Subject: [R] Read
In-Reply-To: <alpine.BSF.2.00.1811091833001.22361@pedal.dcn.davis.ca.us>
References: <CAJOiR6aQy6cVTM54KA2=ov5bNFvTyfW7kUet_XMTnYUBSLMexA@mail.gmail.com>
 <alpine.BSF.2.00.1811091833001.22361@pedal.dcn.davis.ca.us>
Message-ID: <CAJOiR6a4U0L8VbmXOPmqA6BfRd1ueYnaxADcSUAf-trcnO4Y8A@mail.gmail.com>

Thank you Jeff and all.

My data is very messy and it is nice trick suggested by Jeff to handle it

On Fri, Nov 9, 2018 at 8:42 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Your file has 5 commas in the first data row, but only 4 in the header. R
> interprets this to mean your first column is intended to be row names (has
> no corresponding column label) rather than data. (Row names are "outside"
> the data frame... use str(dsh) to get a better picture.)
>
> Basically, your file does not conform to consistent practices for csv
> files of having the same number of commas in every row. If at all possible
> I would eliminate the extra comma. If you have many of these broken files,
> you might need to read the data in pieces... e.g.
>
> dsh <- read.csv( "dat.csv", header=FALSE, skip=1 )
> dsh <- dsh[ , -length( dsh ) ]
> dshh <- read.csv( "dat.csv", header=TRUE, nrow=1)
> names( dsh ) <- names( dshh )
>
> On Fri, 9 Nov 2018, Val wrote:
>
> > HI all,
> > I am trying to read a csv file, but  have a problem in the row names.
> > After reading, the name of the first column is now "row.names" and
> > all other column names are shifted to the right. The value of the last
> > column become all NAs( as an extra column).
> >
> > My sample data looks like as follow,
> > filename = dat.csv
> > The first row has a missing value at column 3 and 5. The last row has
> > a missing value at column 1 and  5
> > x1,x2,x3,x4,x5
> > 12,13,,14,,
> > 22,23,24,25,26
> > ,33,34,34,
> > To read the file I used this
> >
> > dsh<-read.csv(file="dat.csv",sep=",",row.names=NULL,fill=TRUE,header=TRUE,comment.char
> > = "", quote = "", stringsAsFactors = FALSE)
> >
> > The output  from the above  is
> > dsh
> >
> > row.names x1 x2 x3 x4 x5
> > 1        12 13 NA 14 NA  NA
> > 2        22 23 24 25 26  NA
> > 3             33 34 34 NA  NA
> >
> > The name of teh frist column is row,banes and all values of last columns is NAs
> >
> >
> > However, the desired output should be
> > x1 x2 x3 x4 x5
> > 12 13 NA 14 NA
> > 22 23 24 25 26
> > NA 33 34 34 NA
> >
> >
> > How can I fix this?
> > Thank you in advance
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------


From r@f4 @ending from cumc@columbi@@edu  Sun Nov 11 01:51:39 2018
From: r@f4 @ending from cumc@columbi@@edu (Friedman, Richard A.)
Date: Sun, 11 Nov 2018 00:51:39 +0000
Subject: [R] summary function did not work with multcomp with 27 comparisons
Message-ID: <SN6PR02MB41751968F9FBECCE87ECD867C5C00@SN6PR02MB4175.namprd02.prod.outlook.com>

Dear List.

I submitted this inquiry on Thursday but it bounced because I wasn;s a memeber under my current e-mail address; I since joined, but did not receive Friday's issue. So
please excuse me if you have seen this query before.

I ran multcomp with 27 comparisons. The glht command returned an mcp object,
but the summary command with the Westfall correction ddi not give a summary.
When I ran the same dataset with 4 comparisons I got p-values. When I sued a summary with
univariate or Bonferroni?s method with all 27 comarisons I got p-values. But all 27 did not
work for Wesrfall. Please advise.
Here is a record of my session with 27 comparisons and Westfall:

R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[R.app GUI 1.70 (7543) x86_64-apple-darwin15.6.0]

[History restored from /Users/friedman/.Rapp.history]

objc[31790]: Class FIFinderSyncExtensionHost is implemented in both /System/Library/PrivateFrameworks/FinderKit.framework/Versions/A/FinderKit (0x7fff9c2b7c90) and /System/Library/PrivateFrameworks/FileProvider.framework/OverrideBundles/FinderSyncCollaborationFileProviderOverride.bundle/Contents/MacOS/FinderSyncCollaborationFileProviderOverride (0x119bf8cd8). One of the two will be used. Which one is undefined.
> library(multcomp)
Loading required package: mvtnorm
Loading required package: survival
Loading required package: TH.data
Loading required package: MASS

Attaching package: ?TH.data?

The following object is masked from ?package:MASS?:

    geyser

> tumor<-read.table("a8_1wayall_input.txt",sep="\t",header=T)
> class(tumor)
[1] "data.frame"
> dim(tumor)
[1] 309   2
> tumor[1,]
     condition  log2vol
1 aa.vector.4w 7.297375
>
> model<-lm(log2vol~condition,data=tumor)
> summary(model)

Call:
lm(formula = log2vol ~ condition, data = tumor)

Residuals:
   Min     1Q Median     3Q    Max
-7.997 -2.414  0.291  2.164  8.059

Coefficients:
                             Estimate Std. Error t value Pr(>|t|)
(Intercept)                   4.58776    0.60457   7.588  4.3e-13 ***
conditionab.vector.6w         1.39818    0.85499   1.635 0.103054
conditionac.vector.8w         2.89085    0.85499   3.381 0.000820 ***
conditionba.dnmt1kd.4w       -2.67491    0.84733  -3.157 0.001760 **
conditionbb.dnmt1kd.6w       -1.43390    0.84733  -1.692 0.091654 .
conditionbc.dnmt1kd.8w       -0.47188    0.84733  -0.557 0.578020
conditionca.dnmt3bkd.4w      -3.15325    0.89139  -3.537 0.000469 ***
conditioncb.dnmt3bkd.6w      -2.17334    0.89139  -2.438 0.015355 *
conditioncc.dnmt3bkd.8w      -1.50187    0.89139  -1.685 0.093078 .
conditionda.dnmt1kdhrad9.4w   1.08153    1.08991   0.992 0.321863
conditiondb.dnmt1kdhrad9.6w   2.38383    1.08991   2.187 0.029517 *
conditiondc.dnmt1kdhrad9.8w   3.53990    1.08991   3.248 0.001297 **
conditionea.dnmt3bkdhrad9.4w  0.02795    1.06049   0.026 0.978991
conditioneb.dnmt3bkdhrad9.6w  1.34037    1.06049   1.264 0.207263
conditionec.dnmt3bkdhrad9.8w  3.40955    1.06049   3.215 0.001449 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 3.141 on 294 degrees of freedom
Multiple R-squared:  0.3155, Adjusted R-squared:  0.2829
F-statistic: 9.678 on 14 and 294 DF,  p-value: < 2.2e-16

> model.mc<-glht(model,linfct=mcp(condition=c("ab.vector.6w-aa.vector.4w=0",
+                        "ac.vector.8w-aa.vector.4w=0",
+                        "ac.vector.8w-ab.vector.6w=0",
+       "bb.dnmt1kd.6w-ba.dnmt1kd.4w=0",
+                        "bc.dnmt1kd.8w-ba.dnmt1kd.4w=0",
+                        "bc.dnmt1kd.8w-bb.dnmt1kd.6w=0",
+         "cb.dnmt3bkd.6w-ca.dnmt3bkd.4w=0",
+                        "cc.dnmt3bkd.8w-ca.dnmt3bkd.4w=0",
+                        "cc.dnmt3bkd.8w-cb.dnmt3bkd.6w=0",
+         "db.dnmt1kdhrad9.6w-da.dnmt1kdhrad9.4w=0",
+                        "dc.dnmt1kdhrad9.8w-da.dnmt1kdhrad9.4w=0",
+                        "dc.dnmt1kdhrad9.8w-db.dnmt1kdhrad9.6w=0",
+         "eb.dnmt3bkdhrad9.6w-ea.dnmt3bkdhrad9.4w=0",
+                        "ec.dnmt3bkdhrad9.8w-ea.dnmt3bkdhrad9.4w=0",
+                        "ec.dnmt3bkdhrad9.8w-eb.dnmt3bkdhrad9.6w=0",
+       "ba.dnmt1kd.4w-aa.vector.4w=0",
+                        "ca.dnmt3bkd.4w-aa.vector.4w=0",
+                        "da.dnmt1kdhrad9.4w-ba.dnmt1kd.4w=0",
+                        "ea.dnmt3bkdhrad9.4w-ca.dnmt3bkd.4w=0",
+       "bb.dnmt1kd.6w-ab.vector.6w=0",
+                        "cb.dnmt3bkd.6w-ab.vector.6w=0",
+                        "db.dnmt1kdhrad9.6w-bb.dnmt1kd.6w=0",
+                        "eb.dnmt3bkdhrad9.6w-cb.dnmt3bkd.6w=0",
+       "bc.dnmt1kd.8w-ac.vector.8w=0",
+                        "cc.dnmt3bkd.8w-ac.vector.8w=0",
+                        "dc.dnmt1kdhrad9.8w-bc.dnmt1kd.8w=0",
+                        "ec.dnmt3bkdhrad9.8w-cc.dnmt3bkd.8w=0")))
>
> summary(model.mc,test=adjusted(type="Westfall"))

######################
THE PROGRAM FROZE AT THIS POINT AND DID NOT RETURN ANYTHING
HERE IS MY SESSION INFO

######################

> sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS High Sierra 10.13.6

Matrix products: default
BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] multcomp_1.4-8  TH.data_1.0-9   MASS_7.3-50     survival_2.42-6 mvtnorm_1.0-8

loaded via a namespace (and not attached):
[1] zoo_1.8-3        compiler_3.5.1   Matrix_1.2-14    sandwich_2.4-0   codetools_0.2-15 splines_3.5.1    grid_3.5.1       lattice_0.20-35

#############################

Why would the summary function not work with 27 comparisons with Westfall but work with 4 comparisons?
Why would the summary function not work with 27 comparisons with Westfall but work with the same  comparisons with Bonferroni?
Is the problem intrinsic to
A. Westfall?s , method with a large number of comarisons.
B, The impkementation of Westfall?s method in multcomp?
C. Machine requirements for Westfall?s method with so many comparisons?
D. My coding
E. Other.

I have used Westsall;?s method throught the paper which I am now working and would prefer to use it for this
problem for consistency.
I would appreciate any advice.


Thanks and best wishes,
Rich
Richard A. Friedman, PhD
Associate Research Scientist,
Biomedical Informatics Shared Resource
Herbert Irving Comprehensive Cancer Center (HICCC)
Lecturer,
Department of Biomedical Informatics (DBMI)
Room 825
Irving Cancer Research Center
Columbia University Herbert and Florence Irving Medical Center
1130 St. Nicholas Ave
New York, NY 10032
(212)851-4765 (voice)
raf4 at cumc.columbia.edu<mailto:raf4 at cumc.columbia.edu>

http://www.columbia.edu/~raf4/index.html


In memoriam, Steve Ditko


	[[alternative HTML version deleted]]


From p_connolly @ending from @ling@hot@co@nz  Sat Nov 10 08:48:34 2018
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Sat, 10 Nov 2018 20:48:34 +1300
Subject: [R] saveRDS() and readRDS()  Why? [solved, kind of]
In-Reply-To: <23524.2724.270930.705139@stat.math.ethz.ch>
References: <20181107075621.GD8540@slingshot.co.nz>
 <20181108072724.GF8540@slingshot.co.nz>
 <23524.2724.270930.705139@stat.math.ethz.ch>
Message-ID: <20181110074834.GG8540@slingshot.co.nz>

On Thu, 08-Nov-2018 at 11:06AM +0100, Martin Maechler wrote:

|> >>>>> Patrick Connolly 
|> >>>>>     on Thu, 8 Nov 2018 20:27:24 +1300 writes:

[...]

|> > 
|> > I still don't know Why, but I know How.
|> 
|> Hmm.. and nobody has been able to reproduce your problem, right?
|> 
|> IIUC, currently you are suggesting that [on Windows], if you do
|> 
|>       saveRDS(rawdata, file="rawdata.rds")
|> 
|> the resulting file is does not work with    readRDS()  on Linux.
|> What again are your R versions on the two platforms?


It's an old version on Windows.  I haven't used Windows R since then.

major          3                                          
minor          2.4                                        
year           2016                                       
month          03                                         
day            16                                         


I've tried R-3.5.0 and R-3.5.1 Linux versions.  The problem might be
entirely because of the ancient Windows version. 


|> 
|> Could you  dput() -- provide a (short if possible) version of rawdata where
|> that problem occurs ?

I can't make a smaller version of rawdata which comes from scraping a
non-public web address, but next week when I'm back where those
machines are, I'll try it with a small data frame which is
reproducible.



|> 
|> Best,
|> Martin
|> 
|> 
|> > ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
|> >    ___    Patrick Connolly   
|> >  {~._.~}                   Great minds discuss ideas    
|> >  _( Y )_  	         Average minds discuss events 
|> > (:_~*~_:)                  Small minds discuss people  
|> >  (_)-(_)  	                      ..... Eleanor Roosevelt
|> > 	  
|> > ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
|> > 
|> > ______________________________________________
|> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> > https://stat.ethz.ch/mailman/listinfo/r-help
|> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> > and provide commented, minimal, self-contained, reproducible code.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From ferri@leberl @ending from gmx@@t  Sun Nov 11 11:36:45 2018
From: ferri@leberl @ending from gmx@@t (Ferri Leberl)
Date: Sun, 11 Nov 2018 11:36:45 +0100
Subject: [R] rnaturalearth: detail by degrees
In-Reply-To: <CA+8X3fX-1DjOzdTWGtEp1OCHZrJHM-zOgth-ctWA_0CM4ik4nw@mail.gmail.com>
References: <trinity-581dd2a6-4338-4618-b05a-e98497cd8f21-1541238194073@3c-app-gmx-bs41>
 <CA+8X3fX-1DjOzdTWGtEp1OCHZrJHM-zOgth-ctWA_0CM4ik4nw@mail.gmail.com>
Message-ID: <trinity-b2e7c6a7-b199-4d26-acd2-bfde324ab05f-1541932605662@3c-app-gmx-bs73>

Dear Jim,
Thank you for your help.
Meanwhile I found a solution that works about like this:
?
library(rnaturalearth)
mittex<--59.75#central meridian
mittey<--62.316667#central latitude
band<-2#halve edge length of the depicted square, in degrees
map<-ne_countries(scale=10)#the source map
if(require(sp)){plot(map,ylim=c(mittey-band,mittey+band),xlim=c(mittex-band,mittex+band))}#plot the map
#Now plot the path with lines(). The points are described by their geocoords.

Yours, Ferri
?
?
?

Gesendet:?Sonntag, 04. November 2018 um 22:41 Uhr
Von:?"Jim Lemon" <drjimlemon at gmail.com>
An:?"Ferri Leberl" <ferri.leberl at gmx.at>
Cc:?"r-help mailing list" <r-help at r-project.org>
Betreff:?Re: [R] rnaturalearth: detail by degrees
Hi Ferri,
One way is to snip out a Google Maps image of the area you want, then
using the "maps" package, start a plot bounded by the corner
coordinates of your Google Maps image. You can get those by clicking
on the corners of the area that you selected. Then use the
"readbitmap" package to create a raster object of your GM image and
display it on the plot made by "map". Finally, use either "points" or
"lines" to display the coordinates of your path.

Jim

On Sat, Nov 3, 2018 at 8:43 PM Ferri Leberl <ferri.leberl at gmx.at> wrote:
>
>
> Dear all,
> I have the graph of a path, walking a number of places specified by name, logitude and latitude ? thanks to Don MacQueen.
> xliam and ylim define a certain section of the earth.
> How can I put this section of a political map into the background?
> Thank you in advance.
> Yours, Ferri
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
> and provide commented, minimal, self-contained, reproducible code.


From ferri@leberl @ending from gmx@@t  Sun Nov 11 11:44:12 2018
From: ferri@leberl @ending from gmx@@t (Ferri Leberl)
Date: Sun, 11 Nov 2018 11:44:12 +0100
Subject: [R] Line with linearly changing thickness
Message-ID: <trinity-b2f29944-6c08-4b56-93b1-10923efaebf1-1541933052303@3c-app-gmx-bs73>


Dear All,
I want to depict flows: At point x there is an input of a units. at point y, b units arrive.
Obviously, the line thicknes can be manipulated with (a constant) cex. But I want the thickness to change linearly from?~a in x to ~b in y.
Is there an out of the box solution for this?
Thank you in advance!
Yours, Ferri


From li@t@ @ending from dewey@myzen@co@uk  Sun Nov 11 13:09:10 2018
From: li@t@ @ending from dewey@myzen@co@uk (Michael Dewey)
Date: Sun, 11 Nov 2018 12:09:10 +0000
Subject: [R] 
 summary function did not work with multcomp with 27 comparisons
In-Reply-To: <SN6PR02MB41751968F9FBECCE87ECD867C5C00@SN6PR02MB4175.namprd02.prod.outlook.com>
References: <SN6PR02MB41751968F9FBECCE87ECD867C5C00@SN6PR02MB4175.namprd02.prod.outlook.com>
Message-ID: <946cc642-a783-3740-7918-33a2ca1c9068@dewey.myzen.co.uk>

Dear Richard

If you look in the R-help archives you will find that Gerrit Eichner 
suggested that you might need to be more patient. Try using increasing 
numbers of comparisons from 4 and plot time taken against n of 
comparisons then extrapolate to 27.

Michael

On 11/11/2018 00:51, Friedman, Richard A. wrote:
> Dear List.
> 
> I submitted this inquiry on Thursday but it bounced because I wasn;s a memeber under my current e-mail address; I since joined, but did not receive Friday's issue. So
> please excuse me if you have seen this query before.
> 
> I ran multcomp with 27 comparisons. The glht command returned an mcp object,
> but the summary command with the Westfall correction ddi not give a summary.
> When I ran the same dataset with 4 comparisons I got p-values. When I sued a summary with
> univariate or Bonferroni?s method with all 27 comarisons I got p-values. But all 27 did not
> work for Wesrfall. Please advise.
> Here is a record of my session with 27 comparisons and Westfall:
> 
> R version 3.5.1 (2018-07-02) -- "Feather Spray"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
>    Natural language support but running in an English locale
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
> [R.app GUI 1.70 (7543) x86_64-apple-darwin15.6.0]
> 
> [History restored from /Users/friedman/.Rapp.history]
> 
> objc[31790]: Class FIFinderSyncExtensionHost is implemented in both /System/Library/PrivateFrameworks/FinderKit.framework/Versions/A/FinderKit (0x7fff9c2b7c90) and /System/Library/PrivateFrameworks/FileProvider.framework/OverrideBundles/FinderSyncCollaborationFileProviderOverride.bundle/Contents/MacOS/FinderSyncCollaborationFileProviderOverride (0x119bf8cd8). One of the two will be used. Which one is undefined.
>> library(multcomp)
> Loading required package: mvtnorm
> Loading required package: survival
> Loading required package: TH.data
> Loading required package: MASS
> 
> Attaching package: ?TH.data?
> 
> The following object is masked from ?package:MASS?:
> 
>      geyser
> 
>> tumor<-read.table("a8_1wayall_input.txt",sep="\t",header=T)
>> class(tumor)
> [1] "data.frame"
>> dim(tumor)
> [1] 309   2
>> tumor[1,]
>       condition  log2vol
> 1 aa.vector.4w 7.297375
>>
>> model<-lm(log2vol~condition,data=tumor)
>> summary(model)
> 
> Call:
> lm(formula = log2vol ~ condition, data = tumor)
> 
> Residuals:
>     Min     1Q Median     3Q    Max
> -7.997 -2.414  0.291  2.164  8.059
> 
> Coefficients:
>                               Estimate Std. Error t value Pr(>|t|)
> (Intercept)                   4.58776    0.60457   7.588  4.3e-13 ***
> conditionab.vector.6w         1.39818    0.85499   1.635 0.103054
> conditionac.vector.8w         2.89085    0.85499   3.381 0.000820 ***
> conditionba.dnmt1kd.4w       -2.67491    0.84733  -3.157 0.001760 **
> conditionbb.dnmt1kd.6w       -1.43390    0.84733  -1.692 0.091654 .
> conditionbc.dnmt1kd.8w       -0.47188    0.84733  -0.557 0.578020
> conditionca.dnmt3bkd.4w      -3.15325    0.89139  -3.537 0.000469 ***
> conditioncb.dnmt3bkd.6w      -2.17334    0.89139  -2.438 0.015355 *
> conditioncc.dnmt3bkd.8w      -1.50187    0.89139  -1.685 0.093078 .
> conditionda.dnmt1kdhrad9.4w   1.08153    1.08991   0.992 0.321863
> conditiondb.dnmt1kdhrad9.6w   2.38383    1.08991   2.187 0.029517 *
> conditiondc.dnmt1kdhrad9.8w   3.53990    1.08991   3.248 0.001297 **
> conditionea.dnmt3bkdhrad9.4w  0.02795    1.06049   0.026 0.978991
> conditioneb.dnmt3bkdhrad9.6w  1.34037    1.06049   1.264 0.207263
> conditionec.dnmt3bkdhrad9.8w  3.40955    1.06049   3.215 0.001449 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Residual standard error: 3.141 on 294 degrees of freedom
> Multiple R-squared:  0.3155, Adjusted R-squared:  0.2829
> F-statistic: 9.678 on 14 and 294 DF,  p-value: < 2.2e-16
> 
>> model.mc<-glht(model,linfct=mcp(condition=c("ab.vector.6w-aa.vector.4w=0",
> +                        "ac.vector.8w-aa.vector.4w=0",
> +                        "ac.vector.8w-ab.vector.6w=0",
> +       "bb.dnmt1kd.6w-ba.dnmt1kd.4w=0",
> +                        "bc.dnmt1kd.8w-ba.dnmt1kd.4w=0",
> +                        "bc.dnmt1kd.8w-bb.dnmt1kd.6w=0",
> +         "cb.dnmt3bkd.6w-ca.dnmt3bkd.4w=0",
> +                        "cc.dnmt3bkd.8w-ca.dnmt3bkd.4w=0",
> +                        "cc.dnmt3bkd.8w-cb.dnmt3bkd.6w=0",
> +         "db.dnmt1kdhrad9.6w-da.dnmt1kdhrad9.4w=0",
> +                        "dc.dnmt1kdhrad9.8w-da.dnmt1kdhrad9.4w=0",
> +                        "dc.dnmt1kdhrad9.8w-db.dnmt1kdhrad9.6w=0",
> +         "eb.dnmt3bkdhrad9.6w-ea.dnmt3bkdhrad9.4w=0",
> +                        "ec.dnmt3bkdhrad9.8w-ea.dnmt3bkdhrad9.4w=0",
> +                        "ec.dnmt3bkdhrad9.8w-eb.dnmt3bkdhrad9.6w=0",
> +       "ba.dnmt1kd.4w-aa.vector.4w=0",
> +                        "ca.dnmt3bkd.4w-aa.vector.4w=0",
> +                        "da.dnmt1kdhrad9.4w-ba.dnmt1kd.4w=0",
> +                        "ea.dnmt3bkdhrad9.4w-ca.dnmt3bkd.4w=0",
> +       "bb.dnmt1kd.6w-ab.vector.6w=0",
> +                        "cb.dnmt3bkd.6w-ab.vector.6w=0",
> +                        "db.dnmt1kdhrad9.6w-bb.dnmt1kd.6w=0",
> +                        "eb.dnmt3bkdhrad9.6w-cb.dnmt3bkd.6w=0",
> +       "bc.dnmt1kd.8w-ac.vector.8w=0",
> +                        "cc.dnmt3bkd.8w-ac.vector.8w=0",
> +                        "dc.dnmt1kdhrad9.8w-bc.dnmt1kd.8w=0",
> +                        "ec.dnmt3bkdhrad9.8w-cc.dnmt3bkd.8w=0")))
>>
>> summary(model.mc,test=adjusted(type="Westfall"))
> 
> ######################
> THE PROGRAM FROZE AT THIS POINT AND DID NOT RETURN ANYTHING
> HERE IS MY SESSION INFO
> 
> ######################
> 
>> sessionInfo()
> R version 3.5.1 (2018-07-02)
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
> Running under: macOS High Sierra 10.13.6
> 
> Matrix products: default
> BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
> LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] multcomp_1.4-8  TH.data_1.0-9   MASS_7.3-50     survival_2.42-6 mvtnorm_1.0-8
> 
> loaded via a namespace (and not attached):
> [1] zoo_1.8-3        compiler_3.5.1   Matrix_1.2-14    sandwich_2.4-0   codetools_0.2-15 splines_3.5.1    grid_3.5.1       lattice_0.20-35
> 
> #############################
> 
> Why would the summary function not work with 27 comparisons with Westfall but work with 4 comparisons?
> Why would the summary function not work with 27 comparisons with Westfall but work with the same  comparisons with Bonferroni?
> Is the problem intrinsic to
> A. Westfall?s , method with a large number of comarisons.
> B, The impkementation of Westfall?s method in multcomp?
> C. Machine requirements for Westfall?s method with so many comparisons?
> D. My coding
> E. Other.
> 
> I have used Westsall;?s method throught the paper which I am now working and would prefer to use it for this
> problem for consistency.
> I would appreciate any advice.
> 
> 
> Thanks and best wishes,
> Rich
> Richard A. Friedman, PhD
> Associate Research Scientist,
> Biomedical Informatics Shared Resource
> Herbert Irving Comprehensive Cancer Center (HICCC)
> Lecturer,
> Department of Biomedical Informatics (DBMI)
> Room 825
> Irving Cancer Research Center
> Columbia University Herbert and Florence Irving Medical Center
> 1130 St. Nicholas Ave
> New York, NY 10032
> (212)851-4765 (voice)
> raf4 at cumc.columbia.edu<mailto:raf4 at cumc.columbia.edu>
> 
> http://www.columbia.edu/~raf4/index.html
> 
> 
> In memoriam, Steve Ditko
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From pd@lgd @ending from gm@il@com  Sun Nov 11 15:38:51 2018
From: pd@lgd @ending from gm@il@com (Peter Dalgaard)
Date: Sun, 11 Nov 2018 15:38:51 +0100
Subject: [R] Line with linearly changing thickness
In-Reply-To: <trinity-b2f29944-6c08-4b56-93b1-10923efaebf1-1541933052303@3c-app-gmx-bs73>
References: <trinity-b2f29944-6c08-4b56-93b1-10923efaebf1-1541933052303@3c-app-gmx-bs73>
Message-ID: <C8500E35-3FA0-45B3-BD78-B42B44C3BA2A@gmail.com>

Hmm... I don't recall whether this has been packaged up, but Paul Murrell talked about it at useR in Brisbane. 

https://www.youtube.com/watch?v=L6FawdEA3W0

-pd

> On 11 Nov 2018, at 11:44 , Ferri Leberl <ferri.leberl at gmx.at> wrote:
> 
> 
> Dear All,
> I want to depict flows: At point x there is an input of a units. at point y, b units arrive.
> Obviously, the line thicknes can be manipulated with (a constant) cex. But I want the thickness to change linearly from ~a in x to ~b in y.
> Is there an out of the box solution for this?
> Thank you in advance!
> Yours, Ferri
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ferri@leberl @ending from gmx@@t  Sun Nov 11 17:30:43 2018
From: ferri@leberl @ending from gmx@@t (Ferri Leberl)
Date: Sun, 11 Nov 2018 17:30:43 +0100
Subject: [R] 
 =?utf-8?q?Line_with_linearly_changing_thickness_=E2=80=93_in?=
 =?utf-8?q?stallation_issues?=
In-Reply-To: <C8500E35-3FA0-45B3-BD78-B42B44C3BA2A@gmail.com>
References: <trinity-b2f29944-6c08-4b56-93b1-10923efaebf1-1541933052303@3c-app-gmx-bs73>
 <C8500E35-3FA0-45B3-BD78-B42B44C3BA2A@gmail.com>
Message-ID: <trinity-2eb29beb-e001-4395-8af8-d1f36b369a6e-1541953843170@3c-app-gmx-bs73>

Dear All,
Thanks to Peter for his hint to the lwline package.
As a pitty, I have difficulties to get it installed, as it requires https://github.com/Gibbsdavidl/twine which failes for me.

install_github("git at github.com:Gibbsdavidl/twine.git")
?
ends with

** building package indices
Error in read.table(zfile, header = TRUE, as.is = FALSE) : 
  more columns than column names
ERROR: installing package indices failed
* removing ?/usr/local/lib/R/site-library/twine?
Fehler in i.p(...) : 
  (konvertiert von Warnung) installation of package ?/tmp/RtmpD3exKe/file730c303b4c3/twine_0.1.tar.gz? had non-zero exit status

I found hints like
https://community.rstudio.com/t/lazydata-failed-for-for-package/4196 and
https://stat.ethz.ch/pipermail/r-help/2011-March/272829.html
that boil down to problems within the data subdir of the project ? but I cannot (and should not) edit the project, can I?

Can anybody help me solving the problem?
Thank you in advance!
Yours, Ferri

?

Gesendet:?Sonntag, 11. November 2018 um 15:38 Uhr
Von:?"Peter Dalgaard" <pdalgd at gmail.com>
An:?"Ferri Leberl" <ferri.leberl at gmx.at>
Cc:?r-help at r-project.org
Betreff:?Re: [R] Line with linearly changing thickness
Hmm... I don't recall whether this has been packaged up, but Paul Murrell talked about it at useR in Brisbane.

https://www.youtube.com/watch?v=L6FawdEA3W0

-pd

> On 11 Nov 2018, at 11:44 , Ferri Leberl <ferri.leberl at gmx.at> wrote:
>
>
> Dear All,
> I want to depict flows: At point x there is an input of a units. at point y, b units arrive.
> Obviously, the line thicknes can be manipulated with (a constant) cex. But I want the thickness to change linearly from ~a in x to ~b in y.
> Is there an out of the box solution for this?
> Thank you in advance!
> Yours, Ferri
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help]
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com








?


From dwin@emiu@ @ending from comc@@t@net  Sun Nov 11 18:22:58 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Sun, 11 Nov 2018 09:22:58 -0800
Subject: [R] 
 =?utf-8?q?Line_with_linearly_changing_thickness_=E2=80=93_in?=
 =?utf-8?q?stallation_issues?=
In-Reply-To: <trinity-2eb29beb-e001-4395-8af8-d1f36b369a6e-1541953843170@3c-app-gmx-bs73>
References: <trinity-b2f29944-6c08-4b56-93b1-10923efaebf1-1541933052303@3c-app-gmx-bs73>
 <C8500E35-3FA0-45B3-BD78-B42B44C3BA2A@gmail.com>
 <trinity-2eb29beb-e001-4395-8af8-d1f36b369a6e-1541953843170@3c-app-gmx-bs73>
Message-ID: <603ecaaf-9711-7238-ba41-4510bbb37b85@comcast.net>

I would have imagined that drawing a polygon would be the way most 
people would have attempted.

Regarding Murrell's package:

I thought the package name was "vwline". My attempt to install was 
unsuccessful>

 > devtools::install_github("pmur002/vwline")
Error in utils::download.file(url, path, method = download_method(), 
quiet = quiet,? :
 ? cannot open URL 
'https://api.github.com/repos/pmur002/vwline/contents/DESCRIPTION?ref=master'
 > install.packages("~/vwline-0.2-1.tar.gz", repo=NULL)
Installing package into ?/home/david/R/x86_64-pc-linux-gnu-library/3.5.1?
(as ?lib? is unspecified)
Warning in untar2(tarfile, files, list, exdir, restore_times) :
 ? skipping pax global extended headers
ERROR: cannot extract package from ?/home/david/vwline-0.2-1.tar.gz?
Warning in install.packages :
 ? installation of package ?/home/david/vwline-0.2-1.tar.gz? had 
non-zero exit status


Furthermore, I do get the same error from attempting to install 
pkg:twine from github.

-- David

Doing this from an Rstudio console running R 3.5.1 in Ubuntu 18.04

On 11/11/18 8:30 AM, Ferri Leberl wrote:
> Dear All,
> Thanks to Peter for his hint to the lwline package.
> As a pitty, I have difficulties to get it installed, as it requires https://github.com/Gibbsdavidl/twine which failes for me.
>
> install_github("git at github.com:Gibbsdavidl/twine.git")
>   
> ends with
>
> ** building package indices
> Error in read.table(zfile, header = TRUE, as.is = FALSE) :
>    more columns than column names
> ERROR: installing package indices failed
> * removing ?/usr/local/lib/R/site-library/twine?
> Fehler in i.p(...) :
>    (konvertiert von Warnung) installation of package ?/tmp/RtmpD3exKe/file730c303b4c3/twine_0.1.tar.gz? had non-zero exit status
>
> I found hints like
> https://community.rstudio.com/t/lazydata-failed-for-for-package/4196 and
> https://stat.ethz.ch/pipermail/r-help/2011-March/272829.html
> that boil down to problems within the data subdir of the project ? but I cannot (and should not) edit the project, can I?
>
> Can anybody help me solving the problem?
> Thank you in advance!
> Yours, Ferri
>
>   
>
> Gesendet:?Sonntag, 11. November 2018 um 15:38 Uhr
> Von:?"Peter Dalgaard" <pdalgd at gmail.com>
> An:?"Ferri Leberl" <ferri.leberl at gmx.at>
> Cc:?r-help at r-project.org
> Betreff:?Re: [R] Line with linearly changing thickness
> Hmm... I don't recall whether this has been packaged up, but Paul Murrell talked about it at useR in Brisbane.
>
> https://www.youtube.com/watch?v=L6FawdEA3W0
>
> -pd
>
>> On 11 Nov 2018, at 11:44 , Ferri Leberl <ferri.leberl at gmx.at> wrote:
>>
>>
>> Dear All,
>> I want to depict flows: At point x there is an input of a units. at point y, b units arrive.
>> Obviously, the line thicknes can be manipulated with (a constant) cex. But I want the thickness to change linearly from ~a in x to ~b in y.
>> Is there an out of the box solution for this?
>> Thank you in advance!
>> Yours, Ferri
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help]
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
>> and provide commented, minimal, self-contained, reproducible code.
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>   
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox @ending from mcm@@ter@c@  Sun Nov 11 19:29:47 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Sun, 11 Nov 2018 18:29:47 +0000
Subject: [R] 
 =?utf-8?q?Line_with_linearly_changing_thickness_=E2=80=93_in?=
 =?utf-8?q?stallation_issues?=
In-Reply-To: <15467_1541957002_wABHNKVm024865_603ecaaf-9711-7238-ba41-4510bbb37b85@comcast.net>
References: <trinity-b2f29944-6c08-4b56-93b1-10923efaebf1-1541933052303@3c-app-gmx-bs73>
 <C8500E35-3FA0-45B3-BD78-B42B44C3BA2A@gmail.com>
 <trinity-2eb29beb-e001-4395-8af8-d1f36b369a6e-1541953843170@3c-app-gmx-bs73>
 <15467_1541957002_wABHNKVm024865_603ecaaf-9711-7238-ba41-4510bbb37b85@comcast.net>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836933505@FHSDB2D11-2.csu.mcmaster.ca>

Dear David and Ferri,

Here's a simple implementation using polygon() (as David suggested). It's much less sophisticated than Paul Murrell's -- in particular, the ends of the line are simply vertical (but, with a bit more work, that too could be addressed) -- and uses standard R graphics rather than grid.

tline <- function(x, y, thickness, col="black", unit=0.005){
    # line of varying thickness
    #   x: vector of x coordinates
    #   y: vector of y coordinates
    #   thickness: units of thickness at each set of coordinates
    #   col: line colour
    #   unit: unit of thickness as fraction of vertical axis
    tl <- function(x1, x2, y1, y2, start, end){
        polygon(x=c(x1, x1, x2, x2, x1), 
                y=c(y1 - start*units, y1 + start*units, 
                    y2 + end*units, y2 - end*units, 
                    y1 - start*units),
                col=col, border=col)
    }
    if (length(x) != length(y)) "x and y are of different lengths"
    if (length(x) != length(thickness)) 
        "length of thickness is different from x and y"
    if (length(x) < 2) "x and y are too short"
    usr <- par("usr")
    units <- (usr[4] - usr[3])*unit/2
    for (i in 2:length(x)){
        tl(x[i - 1], x[i], y[i - 1], y[i], thickness[i - 1], thickness[i])
    }
}

# example:

plot(c(-1, 1), c(0, 100), type="n")
tline(seq(-1, 1, by=0.1), y=(seq(1, 9.5, length=21))^2, 
      thickness=seq(1, 20, length=21), col="blue")

I hope this helps,
 John

--------------------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David
> Winsemius
> Sent: Sunday, November 11, 2018 12:23 PM
> To: r-help at r-project.org
> Subject: Re: [R] Line with linearly changing thickness ? installation
> issues
> 
> I would have imagined that drawing a polygon would be the way most
> people would have attempted.
> 
> Regarding Murrell's package:
> 
> I thought the package name was "vwline". My attempt to install was
> unsuccessful>
> 
>  > devtools::install_github("pmur002/vwline")
> Error in utils::download.file(url, path, method = download_method(),
> quiet = quiet,? :
>  ? cannot open URL
> 'https://api.github.com/repos/pmur002/vwline/contents/DESCRIPTION?ref=ma
> ster'
>  > install.packages("~/vwline-0.2-1.tar.gz", repo=NULL) Installing
> package into ?/home/david/R/x86_64-pc-linux-gnu-library/3.5.1?
> (as ?lib? is unspecified)
> Warning in untar2(tarfile, files, list, exdir, restore_times) :
>  ? skipping pax global extended headers
> ERROR: cannot extract package from ?/home/david/vwline-0.2-1.tar.gz?
> Warning in install.packages :
>  ? installation of package ?/home/david/vwline-0.2-1.tar.gz? had non-
> zero exit status
> 
> 
> Furthermore, I do get the same error from attempting to install
> pkg:twine from github.
> 
> -- David
> 
> Doing this from an Rstudio console running R 3.5.1 in Ubuntu 18.04
> 
> On 11/11/18 8:30 AM, Ferri Leberl wrote:
> > Dear All,
> > Thanks to Peter for his hint to the lwline package.
> > As a pitty, I have difficulties to get it installed, as it requires
> https://github.com/Gibbsdavidl/twine which failes for me.
> >
> > install_github("git at github.com:Gibbsdavidl/twine.git")
> >
> > ends with
> >
> > ** building package indices
> > Error in read.table(zfile, header = TRUE, as.is = FALSE) :
> >    more columns than column names
> > ERROR: installing package indices failed
> > * removing ?/usr/local/lib/R/site-library/twine?
> > Fehler in i.p(...) :
> >    (konvertiert von Warnung) installation of package
> > ?/tmp/RtmpD3exKe/file730c303b4c3/twine_0.1.tar.gz? had non-zero exit
> > status
> >
> > I found hints like
> > https://community.rstudio.com/t/lazydata-failed-for-for-package/4196
> > and https://stat.ethz.ch/pipermail/r-help/2011-March/272829.html
> > that boil down to problems within the data subdir of the project ? but
> I cannot (and should not) edit the project, can I?
> >
> > Can anybody help me solving the problem?
> > Thank you in advance!
> > Yours, Ferri
> >
> >
> >
> > Gesendet:?Sonntag, 11. November 2018 um 15:38 Uhr
> > Von:?"Peter Dalgaard" <pdalgd at gmail.com>
> > An:?"Ferri Leberl" <ferri.leberl at gmx.at>
> > Cc:?r-help at r-project.org
> > Betreff:?Re: [R] Line with linearly changing thickness Hmm... I don't
> > recall whether this has been packaged up, but Paul Murrell talked
> about it at useR in Brisbane.
> >
> > https://www.youtube.com/watch?v=L6FawdEA3W0
> >
> > -pd
> >
> >> On 11 Nov 2018, at 11:44 , Ferri Leberl <ferri.leberl at gmx.at> wrote:
> >>
> >>
> >> Dear All,
> >> I want to depict flows: At point x there is an input of a units. at
> point y, b units arrive.
> >> Obviously, the line thicknes can be manipulated with (a constant)
> cex. But I want the thickness to change linearly from ~a in x to ~b in
> y.
> >> Is there an out of the box solution for this?
> >> Thank you in advance!
> >> Yours, Ferri
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mai
> >> lman/listinfo/r-help] PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html[http://www.R-project.org/
> >> posting-guide.html] and provide commented, minimal, self-contained,
> >> reproducible code.
> > --
> > Peter Dalgaard, Professor,
> > Center for Statistics, Copenhagen Business School Solbjerg Plads 3,
> > 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Office: A 4.23
> > Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From jfox @ending from mcm@@ter@c@  Sun Nov 11 20:53:12 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Sun, 11 Nov 2018 19:53:12 +0000
Subject: [R] 
 =?utf-8?q?Line_with_linearly_changing_thickness_=E2=80=93_in?=
 =?utf-8?q?stallation_issues?=
In-Reply-To: <13337_1541961008_wABIU72A001665_ACD1644AA6C67E4FBD0C350625508EC836933505@FHSDB2D11-2.csu.mcmaster.ca>
References: <trinity-b2f29944-6c08-4b56-93b1-10923efaebf1-1541933052303@3c-app-gmx-bs73>
 <C8500E35-3FA0-45B3-BD78-B42B44C3BA2A@gmail.com>
 <trinity-2eb29beb-e001-4395-8af8-d1f36b369a6e-1541953843170@3c-app-gmx-bs73>
 <15467_1541957002_wABHNKVm024865_603ecaaf-9711-7238-ba41-4510bbb37b85@comcast.net>
 <13337_1541961008_wABIU72A001665_ACD1644AA6C67E4FBD0C350625508EC836933505@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836933694@FHSDB2D11-2.csu.mcmaster.ca>

And here's a simpler, loopless version:

tlines <- function(x, y, thickness, col="black", unit=0.005){
    # line of varying thickness
    #   x: vector of x coordinates
    #   y: vector of y coordinates
    #   thickness: units of thickness at each set of coordinates
    #   col: line colour
    #   unit: unit of thickness as fraction of vertical axis
    if (length(x) != length(y)) "x and y are of different lengths"
    if (length(x) != length(thickness)) 
        "length of thickness is different from x and y"
    if (length(x) < 2) "x and y are too short"
    usr <- par("usr")
    units <- (usr[4] - usr[3])*unit/2
    x <- c(x, rev(x))
    y <- c(y + thickness*units, rev(y) - rev(thickness)*units)
    polygon(x=x, y=y, col=col, border=col)
}

Best,
 John

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Fox, John
> Sent: Sunday, November 11, 2018 1:30 PM
> To: David Winsemius <dwinsemius at comcast.net>; Ferri Leberl
> <ferri.leberl at gmx.at>
> Cc: r-help at r-project.org
> Subject: Re: [R] Line with linearly changing thickness ? installation issues
> 
> Dear David and Ferri,
> 
> Here's a simple implementation using polygon() (as David suggested). It's
> much less sophisticated than Paul Murrell's -- in particular, the ends of the line
> are simply vertical (but, with a bit more work, that too could be addressed) --
> and uses standard R graphics rather than grid.
> 
> tline <- function(x, y, thickness, col="black", unit=0.005){
>     # line of varying thickness
>     #   x: vector of x coordinates
>     #   y: vector of y coordinates
>     #   thickness: units of thickness at each set of coordinates
>     #   col: line colour
>     #   unit: unit of thickness as fraction of vertical axis
>     tl <- function(x1, x2, y1, y2, start, end){
>         polygon(x=c(x1, x1, x2, x2, x1),
>                 y=c(y1 - start*units, y1 + start*units,
>                     y2 + end*units, y2 - end*units,
>                     y1 - start*units),
>                 col=col, border=col)
>     }
>     if (length(x) != length(y)) "x and y are of different lengths"
>     if (length(x) != length(thickness))
>         "length of thickness is different from x and y"
>     if (length(x) < 2) "x and y are too short"
>     usr <- par("usr")
>     units <- (usr[4] - usr[3])*unit/2
>     for (i in 2:length(x)){
>         tl(x[i - 1], x[i], y[i - 1], y[i], thickness[i - 1], thickness[i])
>     }
> }
> 
> # example:
> 
> plot(c(-1, 1), c(0, 100), type="n")
> tline(seq(-1, 1, by=0.1), y=(seq(1, 9.5, length=21))^2,
>       thickness=seq(1, 20, length=21), col="blue")
> 
> I hope this helps,
>  John
> 
> --------------------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socialsciences.mcmaster.ca/jfox/
> 
> 
> 
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David
> > Winsemius
> > Sent: Sunday, November 11, 2018 12:23 PM
> > To: r-help at r-project.org
> > Subject: Re: [R] Line with linearly changing thickness ? installation
> > issues
> >
> > I would have imagined that drawing a polygon would be the way most
> > people would have attempted.
> >
> > Regarding Murrell's package:
> >
> > I thought the package name was "vwline". My attempt to install was
> > unsuccessful>
> >
> >  > devtools::install_github("pmur002/vwline")
> > Error in utils::download.file(url, path, method = download_method(),
> > quiet = quiet,? :
> >  ? cannot open URL
> > 'https://api.github.com/repos/pmur002/vwline/contents/DESCRIPTION?ref=
> > ma
> > ster'
> >  > install.packages("~/vwline-0.2-1.tar.gz", repo=NULL) Installing
> > package into ?/home/david/R/x86_64-pc-linux-gnu-library/3.5.1?
> > (as ?lib? is unspecified)
> > Warning in untar2(tarfile, files, list, exdir, restore_times) :
> >  ? skipping pax global extended headers
> > ERROR: cannot extract package from ?/home/david/vwline-0.2-1.tar.gz?
> > Warning in install.packages :
> >  ? installation of package ?/home/david/vwline-0.2-1.tar.gz? had non-
> > zero exit status
> >
> >
> > Furthermore, I do get the same error from attempting to install
> > pkg:twine from github.
> >
> > -- David
> >
> > Doing this from an Rstudio console running R 3.5.1 in Ubuntu 18.04
> >
> > On 11/11/18 8:30 AM, Ferri Leberl wrote:
> > > Dear All,
> > > Thanks to Peter for his hint to the lwline package.
> > > As a pitty, I have difficulties to get it installed, as it requires
> > https://github.com/Gibbsdavidl/twine which failes for me.
> > >
> > > install_github("git at github.com:Gibbsdavidl/twine.git")
> > >
> > > ends with
> > >
> > > ** building package indices
> > > Error in read.table(zfile, header = TRUE, as.is = FALSE) :
> > >    more columns than column names
> > > ERROR: installing package indices failed
> > > * removing ?/usr/local/lib/R/site-library/twine?
> > > Fehler in i.p(...) :
> > >    (konvertiert von Warnung) installation of package
> > > ?/tmp/RtmpD3exKe/file730c303b4c3/twine_0.1.tar.gz? had non-zero exit
> > > status
> > >
> > > I found hints like
> > > https://community.rstudio.com/t/lazydata-failed-for-for-package/4196
> > > and https://stat.ethz.ch/pipermail/r-help/2011-March/272829.html
> > > that boil down to problems within the data subdir of the project ?
> > > but
> > I cannot (and should not) edit the project, can I?
> > >
> > > Can anybody help me solving the problem?
> > > Thank you in advance!
> > > Yours, Ferri
> > >
> > >
> > >
> > > Gesendet:?Sonntag, 11. November 2018 um 15:38 Uhr
> > > Von:?"Peter Dalgaard" <pdalgd at gmail.com>
> > > An:?"Ferri Leberl" <ferri.leberl at gmx.at>
> > > Cc:?r-help at r-project.org
> > > Betreff:?Re: [R] Line with linearly changing thickness Hmm... I
> > > don't recall whether this has been packaged up, but Paul Murrell
> > > talked
> > about it at useR in Brisbane.
> > >
> > > https://www.youtube.com/watch?v=L6FawdEA3W0
> > >
> > > -pd
> > >
> > >> On 11 Nov 2018, at 11:44 , Ferri Leberl <ferri.leberl at gmx.at> wrote:
> > >>
> > >>
> > >> Dear All,
> > >> I want to depict flows: At point x there is an input of a units. at
> > point y, b units arrive.
> > >> Obviously, the line thicknes can be manipulated with (a constant)
> > cex. But I want the thickness to change linearly from ~a in x to ~b in
> > y.
> > >> Is there an out of the box solution for this?
> > >> Thank you in advance!
> > >> Yours, Ferri
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/m
> > >> ai lman/listinfo/r-help] PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html[http://www.R-project.or
> > >> g/ posting-guide.html] and provide commented, minimal,
> > >> self-contained, reproducible code.
> > > --
> > > Peter Dalgaard, Professor,
> > > Center for Statistics, Copenhagen Business School Solbjerg Plads 3,
> > > 2000 Frederiksberg, Denmark
> > > Phone: (+45)38153501
> > > Office: A 4.23
> > > Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From p@ul @ending from @t@t@@uckl@nd@@c@nz  Sun Nov 11 21:05:56 2018
From: p@ul @ending from @t@t@@uckl@nd@@c@nz (Paul Murrell)
Date: Mon, 12 Nov 2018 09:05:56 +1300
Subject: [R] 
 =?utf-8?q?=5BFORGED=5D_Re=3A__Line_with_linearly_changing_th?=
 =?utf-8?q?ickness_=E2=80=93_installation_issues?=
In-Reply-To: <603ecaaf-9711-7238-ba41-4510bbb37b85@comcast.net>
References: <trinity-b2f29944-6c08-4b56-93b1-10923efaebf1-1541933052303@3c-app-gmx-bs73>
 <C8500E35-3FA0-45B3-BD78-B42B44C3BA2A@gmail.com>
 <trinity-2eb29beb-e001-4395-8af8-d1f36b369a6e-1541953843170@3c-app-gmx-bs73>
 <603ecaaf-9711-7238-ba41-4510bbb37b85@comcast.net>
Message-ID: <8fca417b-9671-a1a6-0e4a-20382702f532@stat.auckland.ac.nz>

Hi

This should hopefully work ...

library(devtools); install_github("pmur002/vwline/pkg at v0.1")

You can also do ...

library(devtools); install_github("pmur002/gridBezier at v1.0-0")
library(devtools); install_github("pmur002/vwline/pkg at v0.2-1")

... to get the latest version.

There is more info at ...

https://www.stat.auckland.ac.nz/~paul/Reports/VWline/vwline-intro/power-curve.html

... and even more in several other reports at ...

https://www.stat.auckland.ac.nz/~paul/index.html

Paul

On 12/11/18 6:22 AM, David Winsemius wrote:
> I would have imagined that drawing a polygon would be the way most 
> people would have attempted.
> 
> Regarding Murrell's package:
> 
> I thought the package name was "vwline". My attempt to install was 
> unsuccessful>
> 
>  > devtools::install_github("pmur002/vwline")
> Error in utils::download.file(url, path, method = download_method(), 
> quiet = quiet,? :
>  ? cannot open URL 
> 'https://api.github.com/repos/pmur002/vwline/contents/DESCRIPTION?ref=master' 
> 
>  > install.packages("~/vwline-0.2-1.tar.gz", repo=NULL)
> Installing package into ?/home/david/R/x86_64-pc-linux-gnu-library/3.5.1?
> (as ?lib? is unspecified)
> Warning in untar2(tarfile, files, list, exdir, restore_times) :
>  ? skipping pax global extended headers
> ERROR: cannot extract package from ?/home/david/vwline-0.2-1.tar.gz?
> Warning in install.packages :
>  ? installation of package ?/home/david/vwline-0.2-1.tar.gz? had 
> non-zero exit status
> 
> 
> Furthermore, I do get the same error from attempting to install 
> pkg:twine from github.
> 
> -- David
> 
> Doing this from an Rstudio console running R 3.5.1 in Ubuntu 18.04
> 
> On 11/11/18 8:30 AM, Ferri Leberl wrote:
>> Dear All,
>> Thanks to Peter for his hint to the lwline package.
>> As a pitty, I have difficulties to get it installed, as it requires 
>> https://github.com/Gibbsdavidl/twine which failes for me.
>>
>> install_github("git at github.com:Gibbsdavidl/twine.git")
>> ends with
>>
>> ** building package indices
>> Error in read.table(zfile, header = TRUE, as.is = FALSE) :
>> ?? more columns than column names
>> ERROR: installing package indices failed
>> * removing ?/usr/local/lib/R/site-library/twine?
>> Fehler in i.p(...) :
>> ?? (konvertiert von Warnung) installation of package 
>> ?/tmp/RtmpD3exKe/file730c303b4c3/twine_0.1.tar.gz? had non-zero exit 
>> status
>>
>> I found hints like
>> https://community.rstudio.com/t/lazydata-failed-for-for-package/4196 and
>> https://stat.ethz.ch/pipermail/r-help/2011-March/272829.html
>> that boil down to problems within the data subdir of the project ? but 
>> I cannot (and should not) edit the project, can I?
>>
>> Can anybody help me solving the problem?
>> Thank you in advance!
>> Yours, Ferri
>>
>>
>> Gesendet:?Sonntag, 11. November 2018 um 15:38 Uhr
>> Von:?"Peter Dalgaard" <pdalgd at gmail.com>
>> An:?"Ferri Leberl" <ferri.leberl at gmx.at>
>> Cc:?r-help at r-project.org
>> Betreff:?Re: [R] Line with linearly changing thickness
>> Hmm... I don't recall whether this has been packaged up, but Paul 
>> Murrell talked about it at useR in Brisbane.
>>
>> https://www.youtube.com/watch?v=L6FawdEA3W0
>>
>> -pd
>>
>>> On 11 Nov 2018, at 11:44 , Ferri Leberl <ferri.leberl at gmx.at> wrote:
>>>
>>>
>>> Dear All,
>>> I want to depict flows: At point x there is an input of a units. at 
>>> point y, b units arrive.
>>> Obviously, the line thicknes can be manipulated with (a constant) 
>>> cex. But I want the thickness to change linearly from ~a in x to ~b 
>>> in y.
>>> Is there an out of the box solution for this?
>>> Thank you in advance!
>>> Yours, Ferri
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help] 
>>>
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html] 
>>>
>>> and provide commented, minimal, self-contained, reproducible code.
>> -- 
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ferri@leberl @ending from gmx@@t  Sun Nov 11 21:49:29 2018
From: ferri@leberl @ending from gmx@@t (Ferri Leberl)
Date: Sun, 11 Nov 2018 21:49:29 +0100
Subject: [R] 
 =?utf-8?q?=5BFORGED=5D_Re=3A__Line_with_linearly_changing_th?=
 =?utf-8?q?ickness_=E2=80=93_installation_issues?=
In-Reply-To: <8fca417b-9671-a1a6-0e4a-20382702f532@stat.auckland.ac.nz>
References: <trinity-b2f29944-6c08-4b56-93b1-10923efaebf1-1541933052303@3c-app-gmx-bs73>
 <C8500E35-3FA0-45B3-BD78-B42B44C3BA2A@gmail.com>
 <trinity-2eb29beb-e001-4395-8af8-d1f36b369a6e-1541953843170@3c-app-gmx-bs73>
 <603ecaaf-9711-7238-ba41-4510bbb37b85@comcast.net>
 <8fca417b-9671-a1a6-0e4a-20382702f532@stat.auckland.ac.nz>
Message-ID: <trinity-32143c29-37ab-4879-a1ac-0d17da656dc0-1541969369367@3c-app-gmx-bs27>

Dear Paul,
Thank you for your help.
With your command, the package got installed immediately.
Yours, Ferri
?



Gesendet:?Sonntag, 11. November 2018 um 21:05 Uhr
Von:?"Paul Murrell" <paul at stat.auckland.ac.nz>
An:?"David Winsemius" <dwinsemius at comcast.net>, r-help at r-project.org
Betreff:?Re: [R] [FORGED] Re: Line with linearly changing thickness ? installation issues
Hi

This should hopefully work ...

library(devtools); install_github("pmur002/vwline/pkg at v0.1")

You can also do ...

library(devtools); install_github("pmur002/gridBezier at v1.0-0")
library(devtools); install_github("pmur002/vwline/pkg at v0.2-1")

... to get the latest version.

There is more info at ...

https://www.stat.auckland.ac.nz/~paul/Reports/VWline/vwline-intro/power-curve.html

... and even more in several other reports at ...

https://www.stat.auckland.ac.nz/~paul/index.html[https://www.stat.auckland.ac.nz/~paul/index.html]

Paul

On 12/11/18 6:22 AM, David Winsemius wrote:
> I would have imagined that drawing a polygon would be the way most
> people would have attempted.
>
> Regarding Murrell's package:
>
> I thought the package name was "vwline". My attempt to install was
> unsuccessful>
>
> > devtools::install_github("pmur002/vwline")
> Error in utils::download.file(url, path, method = download_method(),
> quiet = quiet,? :
> ? cannot open URL
> 'https://api.github.com/repos/pmur002/vwline/contents/DESCRIPTION?ref=master'[https://api.github.com/repos/pmur002/vwline/contents/DESCRIPTION?ref=master']
>
> > install.packages("~/vwline-0.2-1.tar.gz", repo=NULL)
> Installing package into ?/home/david/R/x86_64-pc-linux-gnu-library/3.5.1?
> (as ?lib? is unspecified)
> Warning in untar2(tarfile, files, list, exdir, restore_times) :
> ? skipping pax global extended headers
> ERROR: cannot extract package from ?/home/david/vwline-0.2-1.tar.gz?
> Warning in install.packages :
> ? installation of package ?/home/david/vwline-0.2-1.tar.gz? had
> non-zero exit status
>
>
> Furthermore, I do get the same error from attempting to install
> pkg:twine from github.
>
> -- David
>
> Doing this from an Rstudio console running R 3.5.1 in Ubuntu 18.04
>
> On 11/11/18 8:30 AM, Ferri Leberl wrote:
>> Dear All,
>> Thanks to Peter for his hint to the lwline package.
>> As a pitty, I have difficulties to get it installed, as it requires
>> https://github.com/Gibbsdavidl/twine[https://github.com/Gibbsdavidl/twine] which failes for me.
>>
>> install_github("git at github.com:Gibbsdavidl/twine.git")
>> ends with
>>
>> ** building package indices
>> Error in read.table(zfile, header = TRUE, as.is = FALSE) :
>> ?? more columns than column names
>> ERROR: installing package indices failed
>> * removing ?/usr/local/lib/R/site-library/twine?
>> Fehler in i.p(...) :
>> ?? (konvertiert von Warnung) installation of package
>> ?/tmp/RtmpD3exKe/file730c303b4c3/twine_0.1.tar.gz? had non-zero exit
>> status
>>
>> I found hints like
>> https://community.rstudio.com/t/lazydata-failed-for-for-package/4196[https://community.rstudio.com/t/lazydata-failed-for-for-package/4196] and
>> https://stat.ethz.ch/pipermail/r-help/2011-March/272829.html[https://stat.ethz.ch/pipermail/r-help/2011-March/272829.html]
>> that boil down to problems within the data subdir of the project ? but
>> I cannot (and should not) edit the project, can I?
>>
>> Can anybody help me solving the problem?
>> Thank you in advance!
>> Yours, Ferri
>>
>>
>> Gesendet:?Sonntag, 11. November 2018 um 15:38 Uhr
>> Von:?"Peter Dalgaard" <pdalgd at gmail.com>
>> An:?"Ferri Leberl" <ferri.leberl at gmx.at>
>> Cc:?r-help at r-project.org
>> Betreff:?Re: [R] Line with linearly changing thickness
>> Hmm... I don't recall whether this has been packaged up, but Paul
>> Murrell talked about it at useR in Brisbane.
>>
>> https://www.youtube.com/watch?v=L6FawdEA3W0[https://www.youtube.com/watch?v=L6FawdEA3W0]
>>
>> -pd
>>
>>> On 11 Nov 2018, at 11:44 , Ferri Leberl <ferri.leberl at gmx.at> wrote:
>>>
>>>
>>> Dear All,
>>> I want to depict flows: At point x there is an input of a units. at
>>> point y, b units arrive.
>>> Obviously, the line thicknes can be manipulated with (a constant)
>>> cex. But I want the thickness to change linearly from ~a in x to ~b
>>> in y.
>>> Is there an out of the box solution for this?
>>> Thank you in advance!
>>> Yours, Ferri
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help][https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help]]
>>>
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html][http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]]
>>>
>>> and provide commented, minimal, self-contained, reproducible code.
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help]
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help]
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help]
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
and provide commented, minimal, self-contained, reproducible code.


From frodojedi@m@ilingli@t @ending from gm@il@com  Mon Nov 12 02:07:39 2018
From: frodojedi@m@ilingli@t @ending from gm@il@com (Frodo Jedi)
Date: Mon, 12 Nov 2018 01:07:39 +0000
Subject: [R] Reporting binomial logistic regression from R results
Message-ID: <CAGkY2upGHsV1OSceHNxUv2-D8L1dQcf7QJF6P2WHJPPU0G6-ag@mail.gmail.com>

Dear list members,
I need some help in understanding whether I am doing correctly a binomial
logistic regression and whether I am interpreting the results in the
correct way. Also I would need an advice regarding the reporting of the
results from the R functions.

I want to report the results of a binomial logistic regression where I want
to assess difference between the 3 levels of a factor (called System) on
the dependent variable (called Response) taking two values, 0 and 1. My
goal is to understand if the effect of the 3 systems (A,B,C) in System
affect differently Response in a significant way. I am basing my analysis
on this URL: https://stats.idre.ucla.edu/r/dae/logit-regression/

This is the result of my analysis:

> fit <- glm(Response ~ System, data = scrd, family = "binomial")
> summary(fit)

Call:
glm(formula = Response ~ System, family = "binomial", data = scrd)

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-2.8840   0.1775   0.2712   0.2712   0.5008

Coefficients:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)    3.2844     0.2825  11.626  < 2e-16 ***
SystemB  -1.2715     0.3379  -3.763 0.000168 ***
SystemC    0.8588     0.4990   1.721 0.085266 .
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 411.26  on 1023  degrees of freedom
Residual deviance: 376.76  on 1021  degrees of freedom
AIC: 382.76

Number of Fisher Scoring iterations: 6
Following this analysis I perform the wald test in order to understand
whether there is an overall effect of System:

library(aod)

> wald.test(b = coef(fit), Sigma = vcov(fit), Terms = 1:3)
Wald test:
----------

Chi-squared test:
X2 = 354.6, df = 3, P(> X2) = 0.0
The chi-squared test statistic of 354.6, with 3 degrees of freedom is
associated with a p-value < 0.001 indicating that the overall effect of
System is statistically significant.

Now I check whether there are differences between the coefficients using
again the wald test:

# Here difference between system B and C:

> l <- cbind(0, 1, -1)
> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
Wald test:
----------

Chi-squared test:
X2 = 22.3, df = 1, P(> X2) = 2.3e-06



# Here difference between system A and C:

> l <- cbind(1, 0, -1)
> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
Wald test:
----------

Chi-squared test:
X2 = 12.0, df = 1, P(> X2) = 0.00052



# Here difference between system A and B:

> l <- cbind(1, -1, 0)
> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
Wald test:
----------

Chi-squared test:
X2 = 58.7, df = 1, P(> X2) = 1.8e-14

My understanding is that from this analysis I can state that the three
systems lead to a significantly different Response. Am I right? If so, how
should I report the results of this analysis? What is the correct way?


Thanks in advance

Best wishes

FJ

	[[alternative HTML version deleted]]


From p_connolly @ending from @ling@hot@co@nz  Mon Nov 12 08:28:06 2018
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Mon, 12 Nov 2018 20:28:06 +1300
Subject: [R] saveRDS() and readRDS()  Why? [solved, pretty much anyway)
In-Reply-To: <20181110074834.GG8540@slingshot.co.nz>
References: <20181107075621.GD8540@slingshot.co.nz>
 <20181108072724.GF8540@slingshot.co.nz>
 <23524.2724.270930.705139@stat.math.ethz.ch>
 <20181110074834.GG8540@slingshot.co.nz>
Message-ID: <20181112072806.GH8540@slingshot.co.nz>

The solution was very simple.  Don't use the same name for the rds
file  as used for the R object, viz a vie:

saveRDS(x, file = "x.rds")
and
x <- readRDS(file = "x.rds")

will not work; however

saveRDS(x, file = "y.rds")
and
x <- readRDS(file = "y.rds")
will work.

An undocumented feature?

Thanks to all who contributed.



On Sat, 10-Nov-2018 at 08:48PM +1300, Patrick Connolly wrote:

|> On Thu, 08-Nov-2018 at 11:06AM +0100, Martin Maechler wrote:
|> 
|> |> >>>>> Patrick Connolly 
|> |> >>>>>     on Thu, 8 Nov 2018 20:27:24 +1300 writes:
|> 
|> [...]
|> 
|> |> > 
|> |> > I still don't know Why, but I know How.
|> |> 
|> |> Hmm.. and nobody has been able to reproduce your problem, right?
|> |> 
|> |> IIUC, currently you are suggesting that [on Windows], if you do
|> |> 
|> |>       saveRDS(rawdata, file="rawdata.rds")
|> |> 
|> |> the resulting file is does not work with    readRDS()  on Linux.
|> |> What again are your R versions on the two platforms?
|> 
|> 
|> It's an old version on Windows.  I haven't used Windows R since then.
|> 
|> major          3                                          
|> minor          2.4                                        
|> year           2016                                       
|> month          03                                         
|> day            16                                         
|> 
|> 
|> I've tried R-3.5.0 and R-3.5.1 Linux versions.  The problem might be
|> entirely because of the ancient Windows version. 
|> 
|> 
|> |> 
|> |> Could you  dput() -- provide a (short if possible) version of rawdata where
|> |> that problem occurs ?
|> 
|> I can't make a smaller version of rawdata which comes from scraping a
|> non-public web address, but next week when I'm back where those
|> machines are, I'll try it with a small data frame which is
|> reproducible.
|> 
|> 
|> 
|> |> 
|> |> Best,
|> |> Martin
|> |> 
|> |> 
|> |> > ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
|> |> >    ___    Patrick Connolly   
|> |> >  {~._.~}                   Great minds discuss ideas    
|> |> >  _( Y )_  	         Average minds discuss events 
|> |> > (:_~*~_:)                  Small minds discuss people  
|> |> >  (_)-(_)  	                      ..... Eleanor Roosevelt
|> |> > 	  
|> |> > ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
|> |> > 
|> |> > ______________________________________________
|> |> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> |> > https://stat.ethz.ch/mailman/listinfo/r-help
|> |> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> |> > and provide commented, minimal, self-contained, reproducible code.
|> 
|> -- 
|> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
|>    ___    Patrick Connolly   
|>  {~._.~}                   Great minds discuss ideas    
|>  _( Y )_  	         Average minds discuss events 
|> (:_~*~_:)                  Small minds discuss people  
|>  (_)-(_)  	                      ..... Eleanor Roosevelt
|> 	  
|> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
|> 
|> ______________________________________________
|> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> https://stat.ethz.ch/mailman/listinfo/r-help
|> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> and provide commented, minimal, self-contained, reproducible code.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From petr@pik@l @ending from prechez@@cz  Mon Nov 12 11:05:25 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Mon, 12 Nov 2018 10:05:25 +0000
Subject: [R] Reporting binomial logistic regression from R results
In-Reply-To: <CAGkY2upGHsV1OSceHNxUv2-D8L1dQcf7QJF6P2WHJPPU0G6-ag@mail.gmail.com>
References: <CAGkY2upGHsV1OSceHNxUv2-D8L1dQcf7QJF6P2WHJPPU0G6-ag@mail.gmail.com>
Message-ID: <7ea4c451d69d47759c21ec4c36b6092b@SRVEXCHCM1301.precheza.cz>

Dear Frodo (or Jedi)

The results seems to confirm your assumption that 3 systems are different. How you should present results probably depends on how it is usual to report such results in your environment.

BTW. It seems to me like homework and this list has no homework policy (Sorry, if I am mistaken).

Cheers
Petr
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Frodo Jedi
> Sent: Monday, November 12, 2018 2:08 AM
> To: r-help at r-project.org
> Subject: [R] Reporting binomial logistic regression from R results
>
> Dear list members,
> I need some help in understanding whether I am doing correctly a binomial
> logistic regression and whether I am interpreting the results in the correct way.
> Also I would need an advice regarding the reporting of the results from the R
> functions.
>
> I want to report the results of a binomial logistic regression where I want to
> assess difference between the 3 levels of a factor (called System) on the
> dependent variable (called Response) taking two values, 0 and 1. My goal is to
> understand if the effect of the 3 systems (A,B,C) in System affect differently
> Response in a significant way. I am basing my analysis on this URL:
> https://stats.idre.ucla.edu/r/dae/logit-regression/
>
> This is the result of my analysis:
>
> > fit <- glm(Response ~ System, data = scrd, family = "binomial")
> > summary(fit)
>
> Call:
> glm(formula = Response ~ System, family = "binomial", data = scrd)
>
> Deviance Residuals:
>     Min       1Q   Median       3Q      Max
> -2.8840   0.1775   0.2712   0.2712   0.5008
>
> Coefficients:
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept)    3.2844     0.2825  11.626  < 2e-16 ***
> SystemB  -1.2715     0.3379  -3.763 0.000168 ***
> SystemC    0.8588     0.4990   1.721 0.085266 .
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> (Dispersion parameter for binomial family taken to be 1)
>
>     Null deviance: 411.26  on 1023  degrees of freedom Residual deviance:
> 376.76  on 1021  degrees of freedom
> AIC: 382.76
>
> Number of Fisher Scoring iterations: 6
> Following this analysis I perform the wald test in order to understand whether
> there is an overall effect of System:
>
> library(aod)
>
> > wald.test(b = coef(fit), Sigma = vcov(fit), Terms = 1:3)
> Wald test:
> ----------
>
> Chi-squared test:
> X2 = 354.6, df = 3, P(> X2) = 0.0
> The chi-squared test statistic of 354.6, with 3 degrees of freedom is associated
> with a p-value < 0.001 indicating that the overall effect of System is statistically
> significant.
>
> Now I check whether there are differences between the coefficients using again
> the wald test:
>
> # Here difference between system B and C:
>
> > l <- cbind(0, 1, -1)
> > wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> Wald test:
> ----------
>
> Chi-squared test:
> X2 = 22.3, df = 1, P(> X2) = 2.3e-06
>
>
>
> # Here difference between system A and C:
>
> > l <- cbind(1, 0, -1)
> > wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> Wald test:
> ----------
>
> Chi-squared test:
> X2 = 12.0, df = 1, P(> X2) = 0.00052
>
>
>
> # Here difference between system A and B:
>
> > l <- cbind(1, -1, 0)
> > wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> Wald test:
> ----------
>
> Chi-squared test:
> X2 = 58.7, df = 1, P(> X2) = 1.8e-14
>
> My understanding is that from this analysis I can state that the three systems
> lead to a significantly different Response. Am I right? If so, how should I report
> the results of this analysis? What is the correct way?
>
>
> Thanks in advance
>
> Best wishes
>
> FJ
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From petr@pik@l @ending from prechez@@cz  Mon Nov 12 14:02:17 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Mon, 12 Nov 2018 13:02:17 +0000
Subject: [R] Reporting binomial logistic regression from R results
In-Reply-To: <CAGkY2uoR32=uLaMcWsTq+-qZb1+HNHVQJhUeh2x6RQnVa4u-9Q@mail.gmail.com>
References: <CAGkY2upGHsV1OSceHNxUv2-D8L1dQcf7QJF6P2WHJPPU0G6-ag@mail.gmail.com>
 <7ea4c451d69d47759c21ec4c36b6092b@SRVEXCHCM1301.precheza.cz>
 <CAGkY2uoR32=uLaMcWsTq+-qZb1+HNHVQJhUeh2x6RQnVa4u-9Q@mail.gmail.com>
Message-ID: <2308a7b97b2e4f728acbfd64f78170d2@SRVEXCHCM1301.precheza.cz>

Hi Frodo

I do not consider myself as an arbiter in statistical results and their presentation. Again your text seems to as good as any other.

You should keep responses to mailing list as others could have another opinion.

Cheers
Petr


From: Frodo Jedi <frodojedi.mailinglist at gmail.com>
Sent: Monday, November 12, 2018 1:48 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Subject: Re: [R] Reporting binomial logistic regression from R results

Dear Petr,
many thanks for your reply. I was wondering whether in your opinion it is correct to report in a journal the following text:


?A logistic regression was performed to ascertain the effects of the system type on the likelihood that participants report correct identifications. The logistic regression model was statistically significant, ?2(3) = 354.6, p < 0.001, indicating an overall effect of the system type on participants' identification performances. The Wald test was used to compare the model coefficients related to the three systems. Results showed that participants? accuracy was significantly lower for the system B compared to both the system C (?2(1) = 22.3, p < 0.001) and the system A (?2(1) = 58.7, p < 0.001), as well as that the system C led to significantly higher identification accuracies than the system A (?2(1) = 12, p < 0.001).?


Best wishes

FJ





On Mon, Nov 12, 2018 at 10:05 AM PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Dear Frodo (or Jedi)

The results seems to confirm your assumption that 3 systems are different. How you should present results probably depends on how it is usual to report such results in your environment.

BTW. It seems to me like homework and this list has no homework policy (Sorry, if I am mistaken).

Cheers
Petr
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of Frodo Jedi
> Sent: Monday, November 12, 2018 2:08 AM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] Reporting binomial logistic regression from R results
>
> Dear list members,
> I need some help in understanding whether I am doing correctly a binomial
> logistic regression and whether I am interpreting the results in the correct way.
> Also I would need an advice regarding the reporting of the results from the R
> functions.
>
> I want to report the results of a binomial logistic regression where I want to
> assess difference between the 3 levels of a factor (called System) on the
> dependent variable (called Response) taking two values, 0 and 1. My goal is to
> understand if the effect of the 3 systems (A,B,C) in System affect differently
> Response in a significant way. I am basing my analysis on this URL:
> https://stats.idre.ucla.edu/r/dae/logit-regression/
>
> This is the result of my analysis:
>
> > fit <- glm(Response ~ System, data = scrd, family = "binomial")
> > summary(fit)
>
> Call:
> glm(formula = Response ~ System, family = "binomial", data = scrd)
>
> Deviance Residuals:
>     Min       1Q   Median       3Q      Max
> -2.8840   0.1775   0.2712   0.2712   0.5008
>
> Coefficients:
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept)    3.2844     0.2825  11.626  < 2e-16 ***
> SystemB  -1.2715     0.3379  -3.763 0.000168 ***
> SystemC    0.8588     0.4990   1.721 0.085266 .
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> (Dispersion parameter for binomial family taken to be 1)
>
>     Null deviance: 411.26  on 1023  degrees of freedom Residual deviance:
> 376.76  on 1021  degrees of freedom
> AIC: 382.76
>
> Number of Fisher Scoring iterations: 6
> Following this analysis I perform the wald test in order to understand whether
> there is an overall effect of System:
>
> library(aod)
>
> > wald.test(b = coef(fit), Sigma = vcov(fit), Terms = 1:3)
> Wald test:
> ----------
>
> Chi-squared test:
> X2 = 354.6, df = 3, P(> X2) = 0.0
> The chi-squared test statistic of 354.6, with 3 degrees of freedom is associated
> with a p-value < 0.001 indicating that the overall effect of System is statistically
> significant.
>
> Now I check whether there are differences between the coefficients using again
> the wald test:
>
> # Here difference between system B and C:
>
> > l <- cbind(0, 1, -1)
> > wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> Wald test:
> ----------
>
> Chi-squared test:
> X2 = 22.3, df = 1, P(> X2) = 2.3e-06
>
>
>
> # Here difference between system A and C:
>
> > l <- cbind(1, 0, -1)
> > wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> Wald test:
> ----------
>
> Chi-squared test:
> X2 = 12.0, df = 1, P(> X2) = 0.00052
>
>
>
> # Here difference between system A and B:
>
> > l <- cbind(1, -1, 0)
> > wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> Wald test:
> ----------
>
> Chi-squared test:
> X2 = 58.7, df = 1, P(> X2) = 1.8e-14
>
> My understanding is that from this analysis I can state that the three systems
> lead to a significantly different Response. Am I right? If so, how should I report
> the results of this analysis? What is the correct way?
>
>
> Thanks in advance
>
> Best wishes
>
> FJ
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

	[[alternative HTML version deleted]]


From frodojedi@m@ilingli@t @ending from gm@il@com  Mon Nov 12 14:06:24 2018
From: frodojedi@m@ilingli@t @ending from gm@il@com (Frodo Jedi)
Date: Mon, 12 Nov 2018 13:06:24 +0000
Subject: [R] Reporting binomial logistic regression from R results
In-Reply-To: <2308a7b97b2e4f728acbfd64f78170d2@SRVEXCHCM1301.precheza.cz>
References: <CAGkY2upGHsV1OSceHNxUv2-D8L1dQcf7QJF6P2WHJPPU0G6-ag@mail.gmail.com>
 <7ea4c451d69d47759c21ec4c36b6092b@SRVEXCHCM1301.precheza.cz>
 <CAGkY2uoR32=uLaMcWsTq+-qZb1+HNHVQJhUeh2x6RQnVa4u-9Q@mail.gmail.com>
 <2308a7b97b2e4f728acbfd64f78170d2@SRVEXCHCM1301.precheza.cz>
Message-ID: <CAGkY2uo45gc-gmCaex=mEBKvwU05PFo89Gq8ovC43fZAtw06FQ@mail.gmail.com>

Dear Petr,
thank you very much for your feedback.

Can anyone in the list advise me if the way I report the results is correct?

Kind regards

FJ


On Mon, Nov 12, 2018 at 1:02 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi Frodo
>
>
>
> I do not consider myself as an arbiter in statistical results and their
> presentation. Again your text seems to as good as any other.
>
>
>
> You should keep responses to mailing list as others could have another
> opinion.
>
>
>
> Cheers
>
> Petr
>
>
>
>
>
> *From:* Frodo Jedi <frodojedi.mailinglist at gmail.com>
> *Sent:* Monday, November 12, 2018 1:48 PM
> *To:* PIKAL Petr <petr.pikal at precheza.cz>
> *Subject:* Re: [R] Reporting binomial logistic regression from R results
>
>
>
> Dear Petr,
>
> many thanks for your reply. I was wondering whether in your opinion it is
> correct to report in a journal the following text:
>
>
>
>
>
> ?A logistic regression was performed to ascertain the effects of the
> system type on the likelihood that participants report correct
> identifications. The logistic regression model was statistically
> significant, ?2(3) = 354.6, p < 0.001, indicating an overall effect of the
> system type on participants' identification performances. The Wald test was
> used to compare the model coefficients related to the three systems.
> Results showed that participants? accuracy was significantly lower for the
> system B compared to both the system C (?2(1) = 22.3, p < 0.001) and the
> system A (?2(1) = 58.7, p < 0.001), as well as that the system C led to
> significantly higher identification accuracies than the system A (?2(1) =
> 12, p < 0.001).?
>
>
>
>
>
> Best wishes
>
>
>
> FJ
>
>
>
>
>
>
>
>
>
>
>
> On Mon, Nov 12, 2018 at 10:05 AM PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
>
> Dear Frodo (or Jedi)
>
> The results seems to confirm your assumption that 3 systems are different.
> How you should present results probably depends on how it is usual to
> report such results in your environment.
>
> BTW. It seems to me like homework and this list has no homework policy
> (Sorry, if I am mistaken).
>
> Cheers
> Petr
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Frodo Jedi
> > Sent: Monday, November 12, 2018 2:08 AM
> > To: r-help at r-project.org
> > Subject: [R] Reporting binomial logistic regression from R results
> >
> > Dear list members,
> > I need some help in understanding whether I am doing correctly a binomial
> > logistic regression and whether I am interpreting the results in the
> correct way.
> > Also I would need an advice regarding the reporting of the results from
> the R
> > functions.
> >
> > I want to report the results of a binomial logistic regression where I
> want to
> > assess difference between the 3 levels of a factor (called System) on the
> > dependent variable (called Response) taking two values, 0 and 1. My goal
> is to
> > understand if the effect of the 3 systems (A,B,C) in System affect
> differently
> > Response in a significant way. I am basing my analysis on this URL:
> > https://stats.idre.ucla.edu/r/dae/logit-regression/
> >
> > This is the result of my analysis:
> >
> > > fit <- glm(Response ~ System, data = scrd, family = "binomial")
> > > summary(fit)
> >
> > Call:
> > glm(formula = Response ~ System, family = "binomial", data = scrd)
> >
> > Deviance Residuals:
> >     Min       1Q   Median       3Q      Max
> > -2.8840   0.1775   0.2712   0.2712   0.5008
> >
> > Coefficients:
> >              Estimate Std. Error z value Pr(>|z|)
> > (Intercept)    3.2844     0.2825  11.626  < 2e-16 ***
> > SystemB  -1.2715     0.3379  -3.763 0.000168 ***
> > SystemC    0.8588     0.4990   1.721 0.085266 .
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > (Dispersion parameter for binomial family taken to be 1)
> >
> >     Null deviance: 411.26  on 1023  degrees of freedom Residual deviance:
> > 376.76  on 1021  degrees of freedom
> > AIC: 382.76
> >
> > Number of Fisher Scoring iterations: 6
> > Following this analysis I perform the wald test in order to understand
> whether
> > there is an overall effect of System:
> >
> > library(aod)
> >
> > > wald.test(b = coef(fit), Sigma = vcov(fit), Terms = 1:3)
> > Wald test:
> > ----------
> >
> > Chi-squared test:
> > X2 = 354.6, df = 3, P(> X2) = 0.0
> > The chi-squared test statistic of 354.6, with 3 degrees of freedom is
> associated
> > with a p-value < 0.001 indicating that the overall effect of System is
> statistically
> > significant.
> >
> > Now I check whether there are differences between the coefficients using
> again
> > the wald test:
> >
> > # Here difference between system B and C:
> >
> > > l <- cbind(0, 1, -1)
> > > wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> > Wald test:
> > ----------
> >
> > Chi-squared test:
> > X2 = 22.3, df = 1, P(> X2) = 2.3e-06
> >
> >
> >
> > # Here difference between system A and C:
> >
> > > l <- cbind(1, 0, -1)
> > > wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> > Wald test:
> > ----------
> >
> > Chi-squared test:
> > X2 = 12.0, df = 1, P(> X2) = 0.00052
> >
> >
> >
> > # Here difference between system A and B:
> >
> > > l <- cbind(1, -1, 0)
> > > wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> > Wald test:
> > ----------
> >
> > Chi-squared test:
> > X2 = 58.7, df = 1, P(> X2) = 1.8e-14
> >
> > My understanding is that from this analysis I can state that the three
> systems
> > lead to a significantly different Response. Am I right? If so, how
> should I report
> > the results of this analysis? What is the correct way?
> >
> >
> > Thanks in advance
> >
> > Best wishes
> >
> > FJ
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> about processing and protection of business partner?s personal data are
> available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>

	[[alternative HTML version deleted]]


From E@Vettor@zzi @ending from uke@de  Mon Nov 12 14:15:19 2018
From: E@Vettor@zzi @ending from uke@de (Eik Vettorazzi)
Date: Mon, 12 Nov 2018 14:15:19 +0100
Subject: [R] Reporting binomial logistic regression from R results
In-Reply-To: <CAGkY2upGHsV1OSceHNxUv2-D8L1dQcf7QJF6P2WHJPPU0G6-ag@mail.gmail.com>
References: <CAGkY2upGHsV1OSceHNxUv2-D8L1dQcf7QJF6P2WHJPPU0G6-ag@mail.gmail.com>
Message-ID: <3f6e03ad-1562-91d0-280b-9c79d84503ac@uke.de>

Dear Jedi,
please use the source carefully. A and C are not statistically different 
at the 5% level, which can be inferred from glm output. Your last two 
wald.tests don't test what you want to, since your model contains an 
intercept term. You specified contrasts which tests A vs B-A, ie A- 
(B-A)==0 <-> 2*A-B==0 which is not intended I think. Have a look at 
?contr.treatment and re-read your source doc to get an idea what dummy 
coding and indicatr variables are about.

Cheers


Am 12.11.2018 um 02:07 schrieb Frodo Jedi:
> Dear list members,
> I need some help in understanding whether I am doing correctly a binomial
> logistic regression and whether I am interpreting the results in the
> correct way. Also I would need an advice regarding the reporting of the
> results from the R functions.
> 
> I want to report the results of a binomial logistic regression where I want
> to assess difference between the 3 levels of a factor (called System) on
> the dependent variable (called Response) taking two values, 0 and 1. My
> goal is to understand if the effect of the 3 systems (A,B,C) in System
> affect differently Response in a significant way. I am basing my analysis
> on this URL: https://stats.idre.ucla.edu/r/dae/logit-regression/
> 
> This is the result of my analysis:
> 
>> fit <- glm(Response ~ System, data = scrd, family = "binomial")
>> summary(fit)
> 
> Call:
> glm(formula = Response ~ System, family = "binomial", data = scrd)
> 
> Deviance Residuals:
>      Min       1Q   Median       3Q      Max
> -2.8840   0.1775   0.2712   0.2712   0.5008
> 
> Coefficients:
>               Estimate Std. Error z value Pr(>|z|)
> (Intercept)    3.2844     0.2825  11.626  < 2e-16 ***
> SystemB  -1.2715     0.3379  -3.763 0.000168 ***
> SystemC    0.8588     0.4990   1.721 0.085266 .
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> (Dispersion parameter for binomial family taken to be 1)
> 
>      Null deviance: 411.26  on 1023  degrees of freedom
> Residual deviance: 376.76  on 1021  degrees of freedom
> AIC: 382.76
> 
> Number of Fisher Scoring iterations: 6
> Following this analysis I perform the wald test in order to understand
> whether there is an overall effect of System:
> 
> library(aod)
> 
>> wald.test(b = coef(fit), Sigma = vcov(fit), Terms = 1:3)
> Wald test:
> ----------
> 
> Chi-squared test:
> X2 = 354.6, df = 3, P(> X2) = 0.0
> The chi-squared test statistic of 354.6, with 3 degrees of freedom is
> associated with a p-value < 0.001 indicating that the overall effect of
> System is statistically significant.
> 
> Now I check whether there are differences between the coefficients using
> again the wald test:
> 
> # Here difference between system B and C:
> 
>> l <- cbind(0, 1, -1)
>> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> Wald test:
> ----------
> 
> Chi-squared test:
> X2 = 22.3, df = 1, P(> X2) = 2.3e-06
> 
> 
> 
> # Here difference between system A and C:
> 
>> l <- cbind(1, 0, -1)
>> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> Wald test:
> ----------
> 
> Chi-squared test:
> X2 = 12.0, df = 1, P(> X2) = 0.00052
> 
> 
> 
> # Here difference between system A and B:
> 
>> l <- cbind(1, -1, 0)
>> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> Wald test:
> ----------
> 
> Chi-squared test:
> X2 = 58.7, df = 1, P(> X2) = 1.8e-14
> 
> My understanding is that from this analysis I can state that the three
> systems lead to a significantly different Response. Am I right? If so, how
> should I report the results of this analysis? What is the correct way?
> 
> 
> Thanks in advance
> 
> Best wishes
> 
> FJ
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Eik Vettorazzi

Department of Medical Biometry and Epidemiology
University Medical Center Hamburg-Eppendorf

Martinistrasse 52
building W 34
20246 Hamburg

Phone: +49 (0) 40 7410 - 58243
Fax:   +49 (0) 40 7410 - 57790
Web: www.uke.de/imbe
--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From pd@lgd @ending from gm@il@com  Mon Nov 12 14:46:07 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Mon, 12 Nov 2018 14:46:07 +0100
Subject: [R] Reporting binomial logistic regression from R results
In-Reply-To: <3f6e03ad-1562-91d0-280b-9c79d84503ac@uke.de>
References: <CAGkY2upGHsV1OSceHNxUv2-D8L1dQcf7QJF6P2WHJPPU0G6-ag@mail.gmail.com>
 <3f6e03ad-1562-91d0-280b-9c79d84503ac@uke.de>
Message-ID: <89A55A4F-3B09-467D-BDCA-5B304AC7D4CD@gmail.com>

Yes, only one of the pairwise comparisons (B vs. C) is right. Also, the overall test has 3 degrees of freedom whereas a comparison of 3 groups should have 2. You (meaning Frodo) are testing that _all 3_ regression coefficients are zero, intercept included. That would imply that all three systems have response probablilities og 0.5, which is not likely what you want.

This all suggests that you are struggling with the interpretation of the regression coefficients and their role in the linear predictor. This should be covered by any good book on logistic regression.

-pd  

> On 12 Nov 2018, at 14:15 , Eik Vettorazzi <E.Vettorazzi at uke.de> wrote:
> 
> Dear Jedi,
> please use the source carefully. A and C are not statistically different at the 5% level, which can be inferred from glm output. Your last two wald.tests don't test what you want to, since your model contains an intercept term. You specified contrasts which tests A vs B-A, ie A- (B-A)==0 <-> 2*A-B==0 which is not intended I think. Have a look at ?contr.treatment and re-read your source doc to get an idea what dummy coding and indicatr variables are about.
> 
> Cheers
> 
> 
> Am 12.11.2018 um 02:07 schrieb Frodo Jedi:
>> Dear list members,
>> I need some help in understanding whether I am doing correctly a binomial
>> logistic regression and whether I am interpreting the results in the
>> correct way. Also I would need an advice regarding the reporting of the
>> results from the R functions.
>> I want to report the results of a binomial logistic regression where I want
>> to assess difference between the 3 levels of a factor (called System) on
>> the dependent variable (called Response) taking two values, 0 and 1. My
>> goal is to understand if the effect of the 3 systems (A,B,C) in System
>> affect differently Response in a significant way. I am basing my analysis
>> on this URL: https://stats.idre.ucla.edu/r/dae/logit-regression/
>> This is the result of my analysis:
>>> fit <- glm(Response ~ System, data = scrd, family = "binomial")
>>> summary(fit)
>> Call:
>> glm(formula = Response ~ System, family = "binomial", data = scrd)
>> Deviance Residuals:
>>     Min       1Q   Median       3Q      Max
>> -2.8840   0.1775   0.2712   0.2712   0.5008
>> Coefficients:
>>              Estimate Std. Error z value Pr(>|z|)
>> (Intercept)    3.2844     0.2825  11.626  < 2e-16 ***
>> SystemB  -1.2715     0.3379  -3.763 0.000168 ***
>> SystemC    0.8588     0.4990   1.721 0.085266 .
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> (Dispersion parameter for binomial family taken to be 1)
>>     Null deviance: 411.26  on 1023  degrees of freedom
>> Residual deviance: 376.76  on 1021  degrees of freedom
>> AIC: 382.76
>> Number of Fisher Scoring iterations: 6
>> Following this analysis I perform the wald test in order to understand
>> whether there is an overall effect of System:
>> library(aod)
>>> wald.test(b = coef(fit), Sigma = vcov(fit), Terms = 1:3)
>> Wald test:
>> ----------
>> Chi-squared test:
>> X2 = 354.6, df = 3, P(> X2) = 0.0
>> The chi-squared test statistic of 354.6, with 3 degrees of freedom is
>> associated with a p-value < 0.001 indicating that the overall effect of
>> System is statistically significant.
>> Now I check whether there are differences between the coefficients using
>> again the wald test:
>> # Here difference between system B and C:
>>> l <- cbind(0, 1, -1)
>>> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
>> Wald test:
>> ----------
>> Chi-squared test:
>> X2 = 22.3, df = 1, P(> X2) = 2.3e-06
>> # Here difference between system A and C:
>>> l <- cbind(1, 0, -1)
>>> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
>> Wald test:
>> ----------
>> Chi-squared test:
>> X2 = 12.0, df = 1, P(> X2) = 0.00052
>> # Here difference between system A and B:
>>> l <- cbind(1, -1, 0)
>>> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
>> Wald test:
>> ----------
>> Chi-squared test:
>> X2 = 58.7, df = 1, P(> X2) = 1.8e-14
>> My understanding is that from this analysis I can state that the three
>> systems lead to a significantly different Response. Am I right? If so, how
>> should I report the results of this analysis? What is the correct way?
>> Thanks in advance
>> Best wishes
>> FJ
>> 	[[alternative HTML version deleted]]
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Eik Vettorazzi
> 
> Department of Medical Biometry and Epidemiology
> University Medical Center Hamburg-Eppendorf
> 
> Martinistrasse 52
> building W 34
> 20246 Hamburg
> 
> Phone: +49 (0) 40 7410 - 58243
> Fax:   +49 (0) 40 7410 - 57790
> Web: www.uke.de/imbe
> --
> 
> _____________________________________________________________________
> 
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
> _____________________________________________________________________
> 
> SAVE PAPER - THINK BEFORE PRINTING
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From frodojedi@m@ilingli@t @ending from gm@il@com  Mon Nov 12 20:09:03 2018
From: frodojedi@m@ilingli@t @ending from gm@il@com (Frodo Jedi)
Date: Mon, 12 Nov 2018 19:09:03 +0000
Subject: [R] Reporting binomial logistic regression from R results
In-Reply-To: <89A55A4F-3B09-467D-BDCA-5B304AC7D4CD@gmail.com>
References: <CAGkY2upGHsV1OSceHNxUv2-D8L1dQcf7QJF6P2WHJPPU0G6-ag@mail.gmail.com>
 <3f6e03ad-1562-91d0-280b-9c79d84503ac@uke.de>
 <89A55A4F-3B09-467D-BDCA-5B304AC7D4CD@gmail.com>
Message-ID: <CAGkY2uqHHGkuQ73SfyW4jw0wb5WWxakYNR=z9-5KVy3puSpC9A@mail.gmail.com>

Dear Peter and Eik,
I am very grateful to you for your replies.
My current understanding is that from the GLM analysis I can indeed
conclude that the response predicted by System A is significantly different
from that of System B, while the pairwise comparison A vs C leads to non
significance. Now the Wald test seems to be correct only for Systems B vs
C, indicating that the pairwise System B vs System C is significant. Am I
correct?

However, my current understanding is also that I should use contrasts
instead of the wald test. So the default contrasts is with the System A,
now I should re-perform the GLM with another base. I tried to use the
option "contrasts" of the glm:

> fit1 <- glm(Response ~ System, data = scrd, family = "binomial",
contrasts = contr.treatment(3, base=1,contrasts=TRUE))
> summary(fit1)

> fit2 <- glm(Response ~ System, data = scrd, family = "binomial",
contrasts = contr.treatment(3, base=2,contrasts=TRUE))
> summary(fit2)

> fit3 <- glm(Response ~ System, data = scrd, family = "binomial",
contrasts = contr.treatment(3, base=3,contrasts=TRUE))
> summary(fit3)

However, the output of these three summary functions are identical. Why?
That option should have changed the base, but apparently this is not the
case.


Another analysis I found online (at this link
https://stats.stackexchange.com/questions/60352/comparing-levels-of-factors-after-a-glm-in-r
)
to understand the differences between the 3 levels is to use glth with
Tuckey. I performed the following:

> library(multcomp)
> summary(glht(fit, mcp(System="Tukey")))

Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: glm(formula = Response ~ System, family = "binomial", data = scrd)

Linear Hypotheses:
                      Estimate Std. Error z value Pr(>|z|)
B - A == 0  -1.2715     0.3379  -3.763 0.000445 ***
C - A == 0    0.8588     0.4990   1.721 0.192472
C - B == 0     2.1303     0.4512   4.722  < 1e-04 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
(Adjusted p values reported -- single-step method)


Is this Tukey analysis correct?


I am a bit confused on what analysis I should do. I am doing my very best
to study all resources I can find, but I would really need some help from
experts, especially in using R.


Best wishes

FJ






On Mon, Nov 12, 2018 at 1:46 PM peter dalgaard <pdalgd at gmail.com> wrote:

> Yes, only one of the pairwise comparisons (B vs. C) is right. Also, the
> overall test has 3 degrees of freedom whereas a comparison of 3 groups
> should have 2. You (meaning Frodo) are testing that _all 3_ regression
> coefficients are zero, intercept included. That would imply that all three
> systems have response probablilities og 0.5, which is not likely what you
> want.
>
> This all suggests that you are struggling with the interpretation of the
> regression coefficients and their role in the linear predictor. This should
> be covered by any good book on logistic regression.
>
> -pd
>
> > On 12 Nov 2018, at 14:15 , Eik Vettorazzi <E.Vettorazzi at uke.de> wrote:
> >
> > Dear Jedi,
> > please use the source carefully. A and C are not statistically different
> at the 5% level, which can be inferred from glm output. Your last two
> wald.tests don't test what you want to, since your model contains an
> intercept term. You specified contrasts which tests A vs B-A, ie A-
> (B-A)==0 <-> 2*A-B==0 which is not intended I think. Have a look at
> ?contr.treatment and re-read your source doc to get an idea what dummy
> coding and indicatr variables are about.
> >
> > Cheers
> >
> >
> > Am 12.11.2018 um 02:07 schrieb Frodo Jedi:
> >> Dear list members,
> >> I need some help in understanding whether I am doing correctly a
> binomial
> >> logistic regression and whether I am interpreting the results in the
> >> correct way. Also I would need an advice regarding the reporting of the
> >> results from the R functions.
> >> I want to report the results of a binomial logistic regression where I
> want
> >> to assess difference between the 3 levels of a factor (called System) on
> >> the dependent variable (called Response) taking two values, 0 and 1. My
> >> goal is to understand if the effect of the 3 systems (A,B,C) in System
> >> affect differently Response in a significant way. I am basing my
> analysis
> >> on this URL: https://stats.idre.ucla.edu/r/dae/logit-regression/
> >> This is the result of my analysis:
> >>> fit <- glm(Response ~ System, data = scrd, family = "binomial")
> >>> summary(fit)
> >> Call:
> >> glm(formula = Response ~ System, family = "binomial", data = scrd)
> >> Deviance Residuals:
> >>     Min       1Q   Median       3Q      Max
> >> -2.8840   0.1775   0.2712   0.2712   0.5008
> >> Coefficients:
> >>              Estimate Std. Error z value Pr(>|z|)
> >> (Intercept)    3.2844     0.2825  11.626  < 2e-16 ***
> >> SystemB  -1.2715     0.3379  -3.763 0.000168 ***
> >> SystemC    0.8588     0.4990   1.721 0.085266 .
> >> ---
> >> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >> (Dispersion parameter for binomial family taken to be 1)
> >>     Null deviance: 411.26  on 1023  degrees of freedom
> >> Residual deviance: 376.76  on 1021  degrees of freedom
> >> AIC: 382.76
> >> Number of Fisher Scoring iterations: 6
> >> Following this analysis I perform the wald test in order to understand
> >> whether there is an overall effect of System:
> >> library(aod)
> >>> wald.test(b = coef(fit), Sigma = vcov(fit), Terms = 1:3)
> >> Wald test:
> >> ----------
> >> Chi-squared test:
> >> X2 = 354.6, df = 3, P(> X2) = 0.0
> >> The chi-squared test statistic of 354.6, with 3 degrees of freedom is
> >> associated with a p-value < 0.001 indicating that the overall effect of
> >> System is statistically significant.
> >> Now I check whether there are differences between the coefficients using
> >> again the wald test:
> >> # Here difference between system B and C:
> >>> l <- cbind(0, 1, -1)
> >>> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> >> Wald test:
> >> ----------
> >> Chi-squared test:
> >> X2 = 22.3, df = 1, P(> X2) = 2.3e-06
> >> # Here difference between system A and C:
> >>> l <- cbind(1, 0, -1)
> >>> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> >> Wald test:
> >> ----------
> >> Chi-squared test:
> >> X2 = 12.0, df = 1, P(> X2) = 0.00052
> >> # Here difference between system A and B:
> >>> l <- cbind(1, -1, 0)
> >>> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> >> Wald test:
> >> ----------
> >> Chi-squared test:
> >> X2 = 58.7, df = 1, P(> X2) = 1.8e-14
> >> My understanding is that from this analysis I can state that the three
> >> systems lead to a significantly different Response. Am I right? If so,
> how
> >> should I report the results of this analysis? What is the correct way?
> >> Thanks in advance
> >> Best wishes
> >> FJ
> >>      [[alternative HTML version deleted]]
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Eik Vettorazzi
> >
> > Department of Medical Biometry and Epidemiology
> > University Medical Center Hamburg-Eppendorf
> >
> > Martinistrasse 52
> > building W 34
> > 20246 Hamburg
> >
> > Phone: +49 (0) 40 7410 - 58243
> > Fax:   +49 (0) 40 7410 - 57790
> > Web: www.uke.de/imbe
> > --
> >
> > _____________________________________________________________________
> >
> > Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
> Rechts; Gerichtsstand: Hamburg | www.uke.de
> > Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr.
> Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
> > _____________________________________________________________________
> >
> > SAVE PAPER - THINK BEFORE PRINTING
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Mon Nov 12 20:48:01 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 12 Nov 2018 11:48:01 -0800
Subject: [R] Reporting binomial logistic regression from R results
In-Reply-To: <CAGkY2uqHHGkuQ73SfyW4jw0wb5WWxakYNR=z9-5KVy3puSpC9A@mail.gmail.com>
References: <CAGkY2upGHsV1OSceHNxUv2-D8L1dQcf7QJF6P2WHJPPU0G6-ag@mail.gmail.com>
 <3f6e03ad-1562-91d0-280b-9c79d84503ac@uke.de>
 <89A55A4F-3B09-467D-BDCA-5B304AC7D4CD@gmail.com>
 <CAGkY2uqHHGkuQ73SfyW4jw0wb5WWxakYNR=z9-5KVy3puSpC9A@mail.gmail.com>
Message-ID: <CAGxFJbS1WcANxxOW8McBJCH+N5VqYwXwQOJ65cJDj8Js+trseg@mail.gmail.com>

Generally speaking, this list is about questions on R programming, not
statistical issues. However, I grant you that your queries are in something
of a gray area intersecting both.

Nevertheless, based on your admitted confusion, I would recommend that you
find a local statistical expert with whom you can consult 1-1 if at all
possible. As others have already noted, you statistical understanding is
muddy, and it can be quite difficult to resolve such confusion in online
forums like this that cannot provide the close back and forth that may be
required (as well as further appropriate study).

Best,
Bert

On Mon, Nov 12, 2018 at 11:09 AM Frodo Jedi <frodojedi.mailinglist at gmail.com>
wrote:

> Dear Peter and Eik,
> I am very grateful to you for your replies.
> My current understanding is that from the GLM analysis I can indeed
> conclude that the response predicted by System A is significantly different
> from that of System B, while the pairwise comparison A vs C leads to non
> significance. Now the Wald test seems to be correct only for Systems B vs
> C, indicating that the pairwise System B vs System C is significant. Am I
> correct?
>
> However, my current understanding is also that I should use contrasts
> instead of the wald test. So the default contrasts is with the System A,
> now I should re-perform the GLM with another base. I tried to use the
> option "contrasts" of the glm:
>
> > fit1 <- glm(Response ~ System, data = scrd, family = "binomial",
> contrasts = contr.treatment(3, base=1,contrasts=TRUE))
> > summary(fit1)
>
> > fit2 <- glm(Response ~ System, data = scrd, family = "binomial",
> contrasts = contr.treatment(3, base=2,contrasts=TRUE))
> > summary(fit2)
>
> > fit3 <- glm(Response ~ System, data = scrd, family = "binomial",
> contrasts = contr.treatment(3, base=3,contrasts=TRUE))
> > summary(fit3)
>
> However, the output of these three summary functions are identical. Why?
> That option should have changed the base, but apparently this is not the
> case.
>
>
> Another analysis I found online (at this link
>
> https://stats.stackexchange.com/questions/60352/comparing-levels-of-factors-after-a-glm-in-r
> )
> to understand the differences between the 3 levels is to use glth with
> Tuckey. I performed the following:
>
> > library(multcomp)
> > summary(glht(fit, mcp(System="Tukey")))
>
> Simultaneous Tests for General Linear Hypotheses
>
> Multiple Comparisons of Means: Tukey Contrasts
>
>
> Fit: glm(formula = Response ~ System, family = "binomial", data = scrd)
>
> Linear Hypotheses:
>                       Estimate Std. Error z value Pr(>|z|)
> B - A == 0  -1.2715     0.3379  -3.763 0.000445 ***
> C - A == 0    0.8588     0.4990   1.721 0.192472
> C - B == 0     2.1303     0.4512   4.722  < 1e-04 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> (Adjusted p values reported -- single-step method)
>
>
> Is this Tukey analysis correct?
>
>
> I am a bit confused on what analysis I should do. I am doing my very best
> to study all resources I can find, but I would really need some help from
> experts, especially in using R.
>
>
> Best wishes
>
> FJ
>
>
>
>
>
>
> On Mon, Nov 12, 2018 at 1:46 PM peter dalgaard <pdalgd at gmail.com> wrote:
>
> > Yes, only one of the pairwise comparisons (B vs. C) is right. Also, the
> > overall test has 3 degrees of freedom whereas a comparison of 3 groups
> > should have 2. You (meaning Frodo) are testing that _all 3_ regression
> > coefficients are zero, intercept included. That would imply that all
> three
> > systems have response probablilities og 0.5, which is not likely what you
> > want.
> >
> > This all suggests that you are struggling with the interpretation of the
> > regression coefficients and their role in the linear predictor. This
> should
> > be covered by any good book on logistic regression.
> >
> > -pd
> >
> > > On 12 Nov 2018, at 14:15 , Eik Vettorazzi <E.Vettorazzi at uke.de> wrote:
> > >
> > > Dear Jedi,
> > > please use the source carefully. A and C are not statistically
> different
> > at the 5% level, which can be inferred from glm output. Your last two
> > wald.tests don't test what you want to, since your model contains an
> > intercept term. You specified contrasts which tests A vs B-A, ie A-
> > (B-A)==0 <-> 2*A-B==0 which is not intended I think. Have a look at
> > ?contr.treatment and re-read your source doc to get an idea what dummy
> > coding and indicatr variables are about.
> > >
> > > Cheers
> > >
> > >
> > > Am 12.11.2018 um 02:07 schrieb Frodo Jedi:
> > >> Dear list members,
> > >> I need some help in understanding whether I am doing correctly a
> > binomial
> > >> logistic regression and whether I am interpreting the results in the
> > >> correct way. Also I would need an advice regarding the reporting of
> the
> > >> results from the R functions.
> > >> I want to report the results of a binomial logistic regression where I
> > want
> > >> to assess difference between the 3 levels of a factor (called System)
> on
> > >> the dependent variable (called Response) taking two values, 0 and 1.
> My
> > >> goal is to understand if the effect of the 3 systems (A,B,C) in System
> > >> affect differently Response in a significant way. I am basing my
> > analysis
> > >> on this URL: https://stats.idre.ucla.edu/r/dae/logit-regression/
> > >> This is the result of my analysis:
> > >>> fit <- glm(Response ~ System, data = scrd, family = "binomial")
> > >>> summary(fit)
> > >> Call:
> > >> glm(formula = Response ~ System, family = "binomial", data = scrd)
> > >> Deviance Residuals:
> > >>     Min       1Q   Median       3Q      Max
> > >> -2.8840   0.1775   0.2712   0.2712   0.5008
> > >> Coefficients:
> > >>              Estimate Std. Error z value Pr(>|z|)
> > >> (Intercept)    3.2844     0.2825  11.626  < 2e-16 ***
> > >> SystemB  -1.2715     0.3379  -3.763 0.000168 ***
> > >> SystemC    0.8588     0.4990   1.721 0.085266 .
> > >> ---
> > >> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > >> (Dispersion parameter for binomial family taken to be 1)
> > >>     Null deviance: 411.26  on 1023  degrees of freedom
> > >> Residual deviance: 376.76  on 1021  degrees of freedom
> > >> AIC: 382.76
> > >> Number of Fisher Scoring iterations: 6
> > >> Following this analysis I perform the wald test in order to understand
> > >> whether there is an overall effect of System:
> > >> library(aod)
> > >>> wald.test(b = coef(fit), Sigma = vcov(fit), Terms = 1:3)
> > >> Wald test:
> > >> ----------
> > >> Chi-squared test:
> > >> X2 = 354.6, df = 3, P(> X2) = 0.0
> > >> The chi-squared test statistic of 354.6, with 3 degrees of freedom is
> > >> associated with a p-value < 0.001 indicating that the overall effect
> of
> > >> System is statistically significant.
> > >> Now I check whether there are differences between the coefficients
> using
> > >> again the wald test:
> > >> # Here difference between system B and C:
> > >>> l <- cbind(0, 1, -1)
> > >>> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> > >> Wald test:
> > >> ----------
> > >> Chi-squared test:
> > >> X2 = 22.3, df = 1, P(> X2) = 2.3e-06
> > >> # Here difference between system A and C:
> > >>> l <- cbind(1, 0, -1)
> > >>> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> > >> Wald test:
> > >> ----------
> > >> Chi-squared test:
> > >> X2 = 12.0, df = 1, P(> X2) = 0.00052
> > >> # Here difference between system A and B:
> > >>> l <- cbind(1, -1, 0)
> > >>> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
> > >> Wald test:
> > >> ----------
> > >> Chi-squared test:
> > >> X2 = 58.7, df = 1, P(> X2) = 1.8e-14
> > >> My understanding is that from this analysis I can state that the three
> > >> systems lead to a significantly different Response. Am I right? If so,
> > how
> > >> should I report the results of this analysis? What is the correct way?
> > >> Thanks in advance
> > >> Best wishes
> > >> FJ
> > >>      [[alternative HTML version deleted]]
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >
> > > --
> > > Eik Vettorazzi
> > >
> > > Department of Medical Biometry and Epidemiology
> > > University Medical Center Hamburg-Eppendorf
> > >
> > > Martinistrasse 52
> > > building W 34
> > > 20246 Hamburg
> > >
> > > Phone: +49 (0) 40 7410 - 58243
> > > Fax:   +49 (0) 40 7410 - 57790
> > > Web: www.uke.de/imbe
> > > --
> > >
> > > _____________________________________________________________________
> > >
> > > Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
> > Rechts; Gerichtsstand: Hamburg | www.uke.de
> > > Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr.
> > Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
> > > _____________________________________________________________________
> > >
> > > SAVE PAPER - THINK BEFORE PRINTING
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Peter Dalgaard, Professor,
> > Center for Statistics, Copenhagen Business School
> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Office: A 4.23
> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rebecc@@bingert @ending from gmx@de  Mon Nov 12 15:13:07 2018
From: rebecc@@bingert @ending from gmx@de (Rebecca Bingert)
Date: Mon, 12 Nov 2018 15:13:07 +0100
Subject: [R] missRanger package
Message-ID: <1921c2ad-6e02-3262-1ade-e21def94f738@gmx.de>

Hi,
does anybody know where I need to insert the censoring in the missRanger 
package?
Regards,
Rebecca


From bgunter@4567 @ending from gm@il@com  Mon Nov 12 21:12:13 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 12 Nov 2018 12:12:13 -0800
Subject: [R] missRanger package
In-Reply-To: <1921c2ad-6e02-3262-1ade-e21def94f738@gmx.de>
References: <1921c2ad-6e02-3262-1ade-e21def94f738@gmx.de>
Message-ID: <CAGxFJbRjYEsdizUC7mt37WmaX8LPs7FE7ME9CcBrxdTBv0Un_g@mail.gmail.com>

You have asked what I believe is an incoherent question, and thus are
unlikely to receive any useful replies (of course, I may be wrong about
this...).

Please read and follow the posting guide linked below to to ask a question
that can be answered.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Nov 12, 2018 at 12:03 PM Rebecca Bingert <rebecca.bingert at gmx.de>
wrote:

> Hi,
> does anybody know where I need to insert the censoring in the missRanger
> package?
> Regards,
> Rebecca
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From huert@y@ @ending from protonm@il@com  Mon Nov 12 21:37:45 2018
From: huert@y@ @ending from protonm@il@com (Yectli Huerta)
Date: Mon, 12 Nov 2018 20:37:45 +0000
Subject: [R] semiparametric manova
Message-ID: <nZHPMpPcaDAttf_2CeWpRPHXuE776jVeeFvfuY1JwxwK541qPyNp7_x9puqkxTSdlZ5WXuCQRniPzT87DKAvXHgWxTgQ_lMn8m6D8nqbckY=@protonmail.com>

Hello,

I was wondering if there are other packages like MANOVA.RM that could be used to analysis non normal distributions. I have to analyze data with more than 2 predictor variables and a similar number of response variables. When I try the function MANOVA.wide with more than 2 predictor variables, I get

There is at least one factor-level combination
?????????? with less than 2 observations!

Is there another package out there that can be used to analyze the significance of more than 2 predictor variables?

thanks,

yah
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 509 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20181112/a35bad39/attachment.sig>

From p_connolly @ending from @ling@hot@co@nz  Mon Nov 12 21:42:19 2018
From: p_connolly @ending from @ling@hot@co@nz (p_connolly)
Date: Tue, 13 Nov 2018 09:42:19 +1300
Subject: [R] saveRDS() and readRDS()  Why? [solved, pretty much anyway)
In-Reply-To: <9795CBFC-5F8C-4084-9704-98614BA2A626@gmail.com>
References: <20181107075621.GD8540@slingshot.co.nz>
 <20181108072724.GF8540@slingshot.co.nz>
 <23524.2724.270930.705139@stat.math.ethz.ch>
 <20181110074834.GG8540@slingshot.co.nz>
 <20181112072806.GH8540@slingshot.co.nz>
 <9795CBFC-5F8C-4084-9704-98614BA2A626@gmail.com>
Message-ID: <46f6c0217cf594e544eef3257376d598@slingshot.co.nz>

On 2018-11-12 22:49, peter dalgaard wrote:
> Er, where, what, how? I can't reproduce that, at least not on 3.5.1 on 
> MacOS:
> 
>> x <- airquality
>> saveRDS(x, file = "x.rds")
>> x <- NULL
>> x <- readRDS(file = "x.rds")
>> x
>     Ozone Solar.R Wind Temp Month Day
> 1      41     190  7.4   67     5   1
> 2      36     118  8.0   72     5   2
> 3      12     149 12.6   74     5   3
> ...
> 
> Looks fine to me.
> 

It seems to work fine using the same installation to read as used for 
the save.
But it's a different story if the save was done on a Windows 
installation and read on a Linux installation.

## On Windows 3.4.2
> x <- airquality
> saveRDS(x, file = "x.rds")
> saveRDS(x, file = "y.rds")

Files x.rds and y.rds are identical in size but utterly different in 
content.

## On Linux 3.5.1

> x <- readRDS(file =  "x.rds")
Error in readRDS(file = "x.rds") : error reading from connection
> x <- readRDS(file =  "y.rds")
> head(x)
   Ozone Solar.R Wind Temp Month Day
1    41     190  7.4   67     5   1
2    36     118  8.0   72     5   2
3    12     149 12.6   74     5   3
4    18     313 11.5   62     5   4
5    NA      NA 14.3   56     5   5
6    28      NA 14.9   66     5   6

It might just be the age of the Windows installation.  I don't have much 
use for Windows, so I haven't had much inclination to install a newer 
version.

YMMV



> ?
> -pd
> 
> 
>> On 12 Nov 2018, at 08:28 , Patrick Connolly 
>> <p_connolly at slingshot.co.nz> wrote:
>> 
>> The solution was very simple.  Don't use the same name for the rds
>> file  as used for the R object, viz a vie:
>> 
>> saveRDS(x, file = "x.rds")
>> and
>> x <- readRDS(file = "x.rds")
>> 
>> will not work; however
>> 
>> saveRDS(x, file = "y.rds")
>> and
>> x <- readRDS(file = "y.rds")
>> will work.
>> 
>> An undocumented feature?
>> 
>> Thanks to all who contributed.
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From m@cqueen1 @ending from llnl@gov  Mon Nov 12 22:20:16 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Mon, 12 Nov 2018 21:20:16 +0000
Subject: [R] missRanger package
In-Reply-To: <1921c2ad-6e02-3262-1ade-e21def94f738@gmx.de>
References: <1921c2ad-6e02-3262-1ade-e21def94f738@gmx.de>
Message-ID: <FDE110E8-6398-4DD3-84E0-027CBD3E2CFE@llnl.gov>

I could not find the word "censor" in the documentation for the missRanger package, so I think additional explanation is needed.

Also, I would expect information about censoring to be included in data provided to a function in a package -- inserting censoring into a package doesn't make sense.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 11/12/18, 6:13 AM, "R-help on behalf of Rebecca Bingert" <r-help-bounces at r-project.org on behalf of rebecca.bingert at gmx.de> wrote:

    Hi,
    does anybody know where I need to insert the censoring in the missRanger 
    package?
    Regards,
    Rebecca
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From frodojedi@m@ilingli@t @ending from gm@il@com  Mon Nov 12 22:45:04 2018
From: frodojedi@m@ilingli@t @ending from gm@il@com (Frodo Jedi)
Date: Mon, 12 Nov 2018 21:45:04 +0000
Subject: [R] Reporting binomial logistic regression from R results
In-Reply-To: <CAGxFJbS1WcANxxOW8McBJCH+N5VqYwXwQOJ65cJDj8Js+trseg@mail.gmail.com>
References: <CAGkY2upGHsV1OSceHNxUv2-D8L1dQcf7QJF6P2WHJPPU0G6-ag@mail.gmail.com>
 <3f6e03ad-1562-91d0-280b-9c79d84503ac@uke.de>
 <89A55A4F-3B09-467D-BDCA-5B304AC7D4CD@gmail.com>
 <CAGkY2uqHHGkuQ73SfyW4jw0wb5WWxakYNR=z9-5KVy3puSpC9A@mail.gmail.com>
 <CAGxFJbS1WcANxxOW8McBJCH+N5VqYwXwQOJ65cJDj8Js+trseg@mail.gmail.com>
Message-ID: <CAGkY2uogrOSbTxwJp6-mHa82jp33_CUNCQ-F55onkBciYqaonQ@mail.gmail.com>

Dear Bert,
I understand and thanks for your recommendation. Unfortunately I do not
have any possibility to contact a statistical expert at the moment. So this
forum experts' recommendation would be crucial to me to understand how R
works in relation to my question.
I hope that someone could reply to my last questions.

Best regards

FJ

On Mon, Nov 12, 2018 at 7:48 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Generally speaking, this list is about questions on R programming, not
> statistical issues. However, I grant you that your queries are in something
> of a gray area intersecting both.
>
> Nevertheless, based on your admitted confusion, I would recommend that you
> find a local statistical expert with whom you can consult 1-1 if at all
> possible. As others have already noted, you statistical understanding is
> muddy, and it can be quite difficult to resolve such confusion in online
> forums like this that cannot provide the close back and forth that may be
> required (as well as further appropriate study).
>
> Best,
> Bert
>
> On Mon, Nov 12, 2018 at 11:09 AM Frodo Jedi <
> frodojedi.mailinglist at gmail.com> wrote:
>
>> Dear Peter and Eik,
>> I am very grateful to you for your replies.
>> My current understanding is that from the GLM analysis I can indeed
>> conclude that the response predicted by System A is significantly
>> different
>> from that of System B, while the pairwise comparison A vs C leads to non
>> significance. Now the Wald test seems to be correct only for Systems B vs
>> C, indicating that the pairwise System B vs System C is significant. Am I
>> correct?
>>
>> However, my current understanding is also that I should use contrasts
>> instead of the wald test. So the default contrasts is with the System A,
>> now I should re-perform the GLM with another base. I tried to use the
>> option "contrasts" of the glm:
>>
>> > fit1 <- glm(Response ~ System, data = scrd, family = "binomial",
>> contrasts = contr.treatment(3, base=1,contrasts=TRUE))
>> > summary(fit1)
>>
>> > fit2 <- glm(Response ~ System, data = scrd, family = "binomial",
>> contrasts = contr.treatment(3, base=2,contrasts=TRUE))
>> > summary(fit2)
>>
>> > fit3 <- glm(Response ~ System, data = scrd, family = "binomial",
>> contrasts = contr.treatment(3, base=3,contrasts=TRUE))
>> > summary(fit3)
>>
>> However, the output of these three summary functions are identical. Why?
>> That option should have changed the base, but apparently this is not the
>> case.
>>
>>
>> Another analysis I found online (at this link
>>
>> https://stats.stackexchange.com/questions/60352/comparing-levels-of-factors-after-a-glm-in-r
>> )
>> to understand the differences between the 3 levels is to use glth with
>> Tuckey. I performed the following:
>>
>> > library(multcomp)
>> > summary(glht(fit, mcp(System="Tukey")))
>>
>> Simultaneous Tests for General Linear Hypotheses
>>
>> Multiple Comparisons of Means: Tukey Contrasts
>>
>>
>> Fit: glm(formula = Response ~ System, family = "binomial", data = scrd)
>>
>> Linear Hypotheses:
>>                       Estimate Std. Error z value Pr(>|z|)
>> B - A == 0  -1.2715     0.3379  -3.763 0.000445 ***
>> C - A == 0    0.8588     0.4990   1.721 0.192472
>> C - B == 0     2.1303     0.4512   4.722  < 1e-04 ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> (Adjusted p values reported -- single-step method)
>>
>>
>> Is this Tukey analysis correct?
>>
>>
>> I am a bit confused on what analysis I should do. I am doing my very best
>> to study all resources I can find, but I would really need some help from
>> experts, especially in using R.
>>
>>
>> Best wishes
>>
>> FJ
>>
>>
>>
>>
>>
>>
>> On Mon, Nov 12, 2018 at 1:46 PM peter dalgaard <pdalgd at gmail.com> wrote:
>>
>> > Yes, only one of the pairwise comparisons (B vs. C) is right. Also, the
>> > overall test has 3 degrees of freedom whereas a comparison of 3 groups
>> > should have 2. You (meaning Frodo) are testing that _all 3_ regression
>> > coefficients are zero, intercept included. That would imply that all
>> three
>> > systems have response probablilities og 0.5, which is not likely what
>> you
>> > want.
>> >
>> > This all suggests that you are struggling with the interpretation of the
>> > regression coefficients and their role in the linear predictor. This
>> should
>> > be covered by any good book on logistic regression.
>> >
>> > -pd
>> >
>> > > On 12 Nov 2018, at 14:15 , Eik Vettorazzi <E.Vettorazzi at uke.de>
>> wrote:
>> > >
>> > > Dear Jedi,
>> > > please use the source carefully. A and C are not statistically
>> different
>> > at the 5% level, which can be inferred from glm output. Your last two
>> > wald.tests don't test what you want to, since your model contains an
>> > intercept term. You specified contrasts which tests A vs B-A, ie A-
>> > (B-A)==0 <-> 2*A-B==0 which is not intended I think. Have a look at
>> > ?contr.treatment and re-read your source doc to get an idea what dummy
>> > coding and indicatr variables are about.
>> > >
>> > > Cheers
>> > >
>> > >
>> > > Am 12.11.2018 um 02:07 schrieb Frodo Jedi:
>> > >> Dear list members,
>> > >> I need some help in understanding whether I am doing correctly a
>> > binomial
>> > >> logistic regression and whether I am interpreting the results in the
>> > >> correct way. Also I would need an advice regarding the reporting of
>> the
>> > >> results from the R functions.
>> > >> I want to report the results of a binomial logistic regression where
>> I
>> > want
>> > >> to assess difference between the 3 levels of a factor (called
>> System) on
>> > >> the dependent variable (called Response) taking two values, 0 and 1.
>> My
>> > >> goal is to understand if the effect of the 3 systems (A,B,C) in
>> System
>> > >> affect differently Response in a significant way. I am basing my
>> > analysis
>> > >> on this URL: https://stats.idre.ucla.edu/r/dae/logit-regression/
>> > >> This is the result of my analysis:
>> > >>> fit <- glm(Response ~ System, data = scrd, family = "binomial")
>> > >>> summary(fit)
>> > >> Call:
>> > >> glm(formula = Response ~ System, family = "binomial", data = scrd)
>> > >> Deviance Residuals:
>> > >>     Min       1Q   Median       3Q      Max
>> > >> -2.8840   0.1775   0.2712   0.2712   0.5008
>> > >> Coefficients:
>> > >>              Estimate Std. Error z value Pr(>|z|)
>> > >> (Intercept)    3.2844     0.2825  11.626  < 2e-16 ***
>> > >> SystemB  -1.2715     0.3379  -3.763 0.000168 ***
>> > >> SystemC    0.8588     0.4990   1.721 0.085266 .
>> > >> ---
>> > >> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> > >> (Dispersion parameter for binomial family taken to be 1)
>> > >>     Null deviance: 411.26  on 1023  degrees of freedom
>> > >> Residual deviance: 376.76  on 1021  degrees of freedom
>> > >> AIC: 382.76
>> > >> Number of Fisher Scoring iterations: 6
>> > >> Following this analysis I perform the wald test in order to
>> understand
>> > >> whether there is an overall effect of System:
>> > >> library(aod)
>> > >>> wald.test(b = coef(fit), Sigma = vcov(fit), Terms = 1:3)
>> > >> Wald test:
>> > >> ----------
>> > >> Chi-squared test:
>> > >> X2 = 354.6, df = 3, P(> X2) = 0.0
>> > >> The chi-squared test statistic of 354.6, with 3 degrees of freedom is
>> > >> associated with a p-value < 0.001 indicating that the overall effect
>> of
>> > >> System is statistically significant.
>> > >> Now I check whether there are differences between the coefficients
>> using
>> > >> again the wald test:
>> > >> # Here difference between system B and C:
>> > >>> l <- cbind(0, 1, -1)
>> > >>> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
>> > >> Wald test:
>> > >> ----------
>> > >> Chi-squared test:
>> > >> X2 = 22.3, df = 1, P(> X2) = 2.3e-06
>> > >> # Here difference between system A and C:
>> > >>> l <- cbind(1, 0, -1)
>> > >>> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
>> > >> Wald test:
>> > >> ----------
>> > >> Chi-squared test:
>> > >> X2 = 12.0, df = 1, P(> X2) = 0.00052
>> > >> # Here difference between system A and B:
>> > >>> l <- cbind(1, -1, 0)
>> > >>> wald.test(b = coef(fit), Sigma = vcov(fit), L = l)
>> > >> Wald test:
>> > >> ----------
>> > >> Chi-squared test:
>> > >> X2 = 58.7, df = 1, P(> X2) = 1.8e-14
>> > >> My understanding is that from this analysis I can state that the
>> three
>> > >> systems lead to a significantly different Response. Am I right? If
>> so,
>> > how
>> > >> should I report the results of this analysis? What is the correct
>> way?
>> > >> Thanks in advance
>> > >> Best wishes
>> > >> FJ
>> > >>      [[alternative HTML version deleted]]
>> > >> ______________________________________________
>> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >> PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > >> and provide commented, minimal, self-contained, reproducible code.
>> > >
>> > > --
>> > > Eik Vettorazzi
>> > >
>> > > Department of Medical Biometry and Epidemiology
>> > > University Medical Center Hamburg-Eppendorf
>> > >
>> > > Martinistrasse 52
>> > > building W 34
>> > > 20246 Hamburg
>> > >
>> > > Phone: +49 (0) 40 7410 - 58243
>> > > Fax:   +49 (0) 40 7410 - 57790
>> > > Web: www.uke.de/imbe
>> > > --
>> > >
>> > > _____________________________________________________________________
>> > >
>> > > Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
>> > Rechts; Gerichtsstand: Hamburg | www.uke.de
>> > > Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr.
>> > Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
>> > > _____________________________________________________________________
>> > >
>> > > SAVE PAPER - THINK BEFORE PRINTING
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > --
>> > Peter Dalgaard, Professor,
>> > Center for Statistics, Copenhagen Business School
>> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> > Phone: (+45)38153501
>> > Office: A 4.23
>> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From dc@rl@on @ending from t@mu@edu  Mon Nov 12 22:53:47 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Mon, 12 Nov 2018 21:53:47 +0000
Subject: [R] semiparametric manova
Message-ID: <73b1bdf3ae094f57b1df25dd1dfdd270@tamu.edu>

The error message does not say anything about having more than two predictor variables. It says that one of the combinations of the predictor variables has less than 2 observations (i.e. 1 or 0 observations). That is probably an issue of your sample size. You may need to consider combining some of the categories in your predictor variables or increasing your sample size. Are your predictor variables coded as factors? 

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Yectli Huerta via R-help
Sent: Monday, November 12, 2018 2:38 PM
To: r-help at r-project.org
Subject: [R] semiparametric manova

Hello,

I was wondering if there are other packages like MANOVA.RM that could be used to analysis non normal distributions. I have to analyze data with more than 2 predictor variables and a similar number of response variables. When I try the function MANOVA.wide with more than 2 predictor variables, I get

There is at least one factor-level combination
?????????? with less than 2 observations!

Is there another package out there that can be used to analyze the significance of more than 2 predictor variables?

thanks,

yah

From dwin@emiu@ @ending from comc@@t@net  Tue Nov 13 00:41:10 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Mon, 12 Nov 2018 15:41:10 -0800
Subject: [R] semiparametric manova
In-Reply-To: <nZHPMpPcaDAttf_2CeWpRPHXuE776jVeeFvfuY1JwxwK541qPyNp7_x9puqkxTSdlZ5WXuCQRniPzT87DKAvXHgWxTgQ_lMn8m6D8nqbckY=@protonmail.com>
References: <nZHPMpPcaDAttf_2CeWpRPHXuE776jVeeFvfuY1JwxwK541qPyNp7_x9puqkxTSdlZ5WXuCQRniPzT87DKAvXHgWxTgQ_lMn8m6D8nqbckY=@protonmail.com>
Message-ID: <2235fce5-c3fe-c595-84b8-21dc4d635213@comcast.net>


On 11/12/18 12:37 PM, Yectli Huerta via R-help wrote:
> Hello,
>
> I was wondering if there are other packages like MANOVA.RM that could be used to analysis non normal distributions. I have to analyze data with more than 2 predictor variables and a similar number of response variables. When I try the function MANOVA.wide with more than 2 predictor variables, I get
>
> There is at least one factor-level combination
>  ?????????? with less than 2 observations!
>
> Is there another package out there that can be used to analyze the significance of more than 2 predictor variables?


That is a warning about a problem with your data in one or more of the 
"cells" defined by your factor levels. It's not going to be solved by 
choosing another package. You should be able to determine which variable 
is causing this warning by first looking at the data, a step should 
_always_ precede running any multivariate procedure.

-- 

David.

> thanks,
>
> yah
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Tue Nov 13 00:55:33 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Mon, 12 Nov 2018 15:55:33 -0800
Subject: [R] saveRDS() and readRDS() Why? [solved, pretty much anyway)
In-Reply-To: <46f6c0217cf594e544eef3257376d598@slingshot.co.nz>
References: <20181107075621.GD8540@slingshot.co.nz>
 <20181108072724.GF8540@slingshot.co.nz>
 <23524.2724.270930.705139@stat.math.ethz.ch>
 <20181110074834.GG8540@slingshot.co.nz>
 <20181112072806.GH8540@slingshot.co.nz>
 <9795CBFC-5F8C-4084-9704-98614BA2A626@gmail.com>
 <46f6c0217cf594e544eef3257376d598@slingshot.co.nz>
Message-ID: <CAF8bMcaejV7GdwwFFB7fro2AHD9FfqHJ2J26EZG56kyQ08UP=A@mail.gmail.com>

You wrote:
  ## On Windows 3.4.2

>   x <- airquality
>   saveRDS(x, file = "x.rds")
>   saveRDS(x, file = "y.rds")
>

  Files x.rds and y.rds are identical in size but utterly different in
content.

Wow!  Can you show us the results of
  x <- datasets::airquality
  saveRDS(x, file="x.rds")
  saveRDS(x, file="y.rds")
  tools::md5sum(c("x.rds", "y.rds"))
  dput(readBin("x.rds", what="raw", n=file.size("x.rds")))
  dput(readBin("y.rds", what="raw", n=file.size("y.rds")))

(Copy and paste, as text, from the R session, so we can see the input and
the output in context.





Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Nov 12, 2018 at 12:42 PM, p_connolly <p_connolly at slingshot.co.nz>
wrote:

> On 2018-11-12 22:49, peter dalgaard wrote:
>
>> Er, where, what, how? I can't reproduce that, at least not on 3.5.1 on
>> MacOS:
>>
>> x <- airquality
>>> saveRDS(x, file = "x.rds")
>>> x <- NULL
>>> x <- readRDS(file = "x.rds")
>>> x
>>>
>>     Ozone Solar.R Wind Temp Month Day
>> 1      41     190  7.4   67     5   1
>> 2      36     118  8.0   72     5   2
>> 3      12     149 12.6   74     5   3
>> ...
>>
>> Looks fine to me.
>>
>>
> It seems to work fine using the same installation to read as used for the
> save.
> But it's a different story if the save was done on a Windows installation
> and read on a Linux installation.
>
> ## On Windows 3.4.2
>
>> x <- airquality
>> saveRDS(x, file = "x.rds")
>> saveRDS(x, file = "y.rds")
>>
>
> Files x.rds and y.rds are identical in size but utterly different in
> content.
>
> ## On Linux 3.5.1
>
> x <- readRDS(file =  "x.rds")
>>
> Error in readRDS(file = "x.rds") : error reading from connection
>
>> x <- readRDS(file =  "y.rds")
>> head(x)
>>
>   Ozone Solar.R Wind Temp Month Day
> 1    41     190  7.4   67     5   1
> 2    36     118  8.0   72     5   2
> 3    12     149 12.6   74     5   3
> 4    18     313 11.5   62     5   4
> 5    NA      NA 14.3   56     5   5
> 6    28      NA 14.9   66     5   6
>
> It might just be the age of the Windows installation.  I don't have much
> use for Windows, so I haven't had much inclination to install a newer
> version.
>
> YMMV
>
>
>
> ?
>> -pd
>>
>>
>> On 12 Nov 2018, at 08:28 , Patrick Connolly <p_connolly at slingshot.co.nz>
>>> wrote:
>>>
>>> The solution was very simple.  Don't use the same name for the rds
>>> file  as used for the R object, viz a vie:
>>>
>>> saveRDS(x, file = "x.rds")
>>> and
>>> x <- readRDS(file = "x.rds")
>>>
>>> will not work; however
>>>
>>> saveRDS(x, file = "y.rds")
>>> and
>>> x <- readRDS(file = "y.rds")
>>> will work.
>>>
>>> An undocumented feature?
>>>
>>> Thanks to all who contributed.
>>>
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From huert@y@ @ending from protonm@il@com  Tue Nov 13 01:24:58 2018
From: huert@y@ @ending from protonm@il@com (Yectli Huerta)
Date: Tue, 13 Nov 2018 00:24:58 +0000
Subject: [R] semiparametric manova
In-Reply-To: <2235fce5-c3fe-c595-84b8-21dc4d635213@comcast.net>
References: <nZHPMpPcaDAttf_2CeWpRPHXuE776jVeeFvfuY1JwxwK541qPyNp7_x9puqkxTSdlZ5WXuCQRniPzT87DKAvXHgWxTgQ_lMn8m6D8nqbckY=@protonmail.com>
 <2235fce5-c3fe-c595-84b8-21dc4d635213@comcast.net>
Message-ID: <elvKFTZpJcbVW35mUngKukQFiT3bGLVBaiDaJ98ButrpofTPFq7jvWo8LUyxlSSBiktd9pYY3SofN3Oe0zxt3TU5tizUcgSj7t5zhy11hL4=@protonmail.com>

thanks for the replies.

i don't believe the data is the problem. here you see how i used 3 variables and it fails,
but when i use any combination of 2 variables, it does work

> head(df)
?? V1 V2 V3 V4 V5?????????? V6?????????? V7
1 200 16 16? 3 64 5.584092e+13 1.616745e+12
2 200 16 16? 3 64 5.589262e+13 1.715906e+12
3 200 16 16? 3 64 5.588578e+13 1.714084e+12
4 200 16 16? 3 64 5.588061e+13 1.651920e+12
5 200 16 16? 3 64 5.589810e+13 1.624824e+12
6 200? 8 16? 1 48 5.585124e+13 1.689478e+12
> library(MANOVA.RM)
> df$V1
[1] 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 500 500 500 500
[20] 500 500 500 500 500 500 350 350 350 350 350 200 200 200 200 200 200 200 200
[39] 200 200 200 200 200 200 200 500 500 500 500 500 350 350 350 350 350 350 350
[58] 350 350 350 350 350 350 350 350 350 350 350 350 350 500 500 500 500 500 500
[77] 500 500 500 500 350 350 350 350 350 500 500 500 500 500
> df$V2
[1] 16 16 16 16 16? 8? 8? 8? 8? 8? 8? 8? 8? 8? 8 16 16 16 16 16? 8? 8? 8? 8? 8
[26]? 8? 8? 8? 8? 8 24 24 24 24 24 24 24 24 24 24 16 16 16 16 16? 8? 8? 8? 8? 8
[51] 16 16 16 16 16? 8? 8? 8? 8? 8 16 16 16 16 16 24 24 24 24 24 24 24 24 24 24
[76] 16 16 16 16 16 24 24 24 24 24 24 24 24 24 24
> df$V3
[1] 16 16 16 16 16 16 16 16 16 16? 9? 9? 9? 9? 9? 9? 9? 9? 9? 9 23 23 23 23 23
[26]? 9? 9? 9? 9? 9? 9? 9? 9? 9? 9 23 23 23 23 23 23 23 23 23 23 16 16 16 16 16
[51]? 9? 9? 9? 9? 9 23 23 23 23 23 16 16 16 16 16 23 23 23 23 23 16 16 16 16 16
[76] 23 23 23 23 23 16 16 16 16 16? 9? 9? 9? 9? 9
>
> MANOVA.wide(cbind(V6,V7)~V1*V2*V3,data=df,seed=1234)
Error in MANOVA.wide(cbind(V6, V7) ~ V1 * V2 * V3, data = df, seed = 1234) :
? There is at least one factor-level combination
?????????? with less than 2 observations!

> MANOVA.wide(cbind(V6,V7)~V1*V2,data=df,seed=1234)
Call:
cbind(V6, V7) ~ V1 * V2

Wald-Type Statistic (WTS):
????? Test statistic df p-value
V1??????????? 17.870? 4?? 0.001
V2??????????? 20.392? 4?? 0.000
V1:V2???????? 24.127? 8?? 0.002

....

> MANOVA.wide(cbind(V6,V7)~V1*V3,data=df,seed=1234)
Call:
cbind(V6, V7) ~ V1 * V3

Wald-Type Statistic (WTS):
????? Test statistic df p-value
V1??????????? 18.566? 4?? 0.001
V3??????????? 19.894? 4?? 0.001
V1:V3???????? 27.330? 8?? 0.001

...
> MANOVA.wide(cbind(V6,V7)~V2*V3,data=df,seed=1234)
Call:
cbind(V6, V7) ~ V2 * V3

Wald-Type Statistic (WTS):
????? Test statistic df p-value
V2??????????? 20.139? 4?? 0.000
V3??????????? 19.947? 4?? 0.001
V2:V3???????? 32.088? 8?? 0.000

....
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 509 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20181113/621bea75/attachment.sig>

From murdoch@dunc@n @ending from gm@il@com  Tue Nov 13 02:08:35 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Mon, 12 Nov 2018 20:08:35 -0500
Subject: [R] which element is duplicated?
Message-ID: <9f0b4102-53fd-c751-09b2-92d9c78a5ec4@gmail.com>

The duplicated() function gives TRUE if an item in a vector (or row in a 
matrix, etc.) is a duplicate of an earlier item.  But what I would like 
to know is which item does it duplicate?

For example,

v <- c("a", "b", "b", "a")
duplicated(v)

returns

[1] FALSE FALSE  TRUE  TRUE

What I want is a fast way to calculate

  [1] NA NA 2 1

or (equally useful to me)

  [1] 1 2 2 1

The result should have the property that if result[i] == j, then v[i] == 
v[j], at least for i != j.

Does this already exist somewhere, or is it easy to write?

Duncan Murdoch


From md@umner @ending from gm@il@com  Tue Nov 13 02:46:15 2018
From: md@umner @ending from gm@il@com (Michael Sumner)
Date: Tue, 13 Nov 2018 12:46:15 +1100
Subject: [R] which element is duplicated?
In-Reply-To: <9f0b4102-53fd-c751-09b2-92d9c78a5ec4@gmail.com>
References: <9f0b4102-53fd-c751-09b2-92d9c78a5ec4@gmail.com>
Message-ID: <CAAcGz9-G3aKqbA7-hdfbwi98BN6huNDMrUCTn1cmyESCsvcLLQ@mail.gmail.com>

what about   as.integer(factor(v, levels = unique(v)))

I recall very clearly when I realized the power of this feature of
factor(), but I've not seen it discussed much.

Cheers, Mike.

On Tue, 13 Nov 2018 at 12:08 Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> The duplicated() function gives TRUE if an item in a vector (or row in a
> matrix, etc.) is a duplicate of an earlier item.  But what I would like
> to know is which item does it duplicate?
>
> For example,
>
> v <- c("a", "b", "b", "a")
> duplicated(v)
>
> returns
>
> [1] FALSE FALSE  TRUE  TRUE
>
> What I want is a fast way to calculate
>
>   [1] NA NA 2 1
>
> or (equally useful to me)
>
>   [1] 1 2 2 1
>
> The result should have the property that if result[i] == j, then v[i] ==
> v[j], at least for i != j.
>
> Does this already exist somewhere, or is it easy to write?
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From p_connolly @ending from @ling@hot@co@nz  Tue Nov 13 04:10:20 2018
From: p_connolly @ending from @ling@hot@co@nz (p_connolly)
Date: Tue, 13 Nov 2018 16:10:20 +1300
Subject: [R] saveRDS() and readRDS() Why? [solved, pretty much anyway)
In-Reply-To: <CAF8bMcaejV7GdwwFFB7fro2AHD9FfqHJ2J26EZG56kyQ08UP=A@mail.gmail.com>
References: <20181107075621.GD8540@slingshot.co.nz>
 <20181108072724.GF8540@slingshot.co.nz>
 <23524.2724.270930.705139@stat.math.ethz.ch>
 <20181110074834.GG8540@slingshot.co.nz>
 <20181112072806.GH8540@slingshot.co.nz>
 <9795CBFC-5F8C-4084-9704-98614BA2A626@gmail.com>
 <46f6c0217cf594e544eef3257376d598@slingshot.co.nz>
 <CAF8bMcaejV7GdwwFFB7fro2AHD9FfqHJ2J26EZG56kyQ08UP=A@mail.gmail.com>
Message-ID: <3b49eb752bb2b108a72683df1d30f50b@slingshot.co.nz>

On 2018-11-13 12:55, William Dunlap wrote:
> You wrote:
>   ## On Windows 3.4.2
> 
>> x <- airquality
>> saveRDS(x, file = "x.rds")
>> saveRDS(x, file = "y.rds")
> 
>   Files x.rds and y.rds are identical in size but utterly different in
> content.
> 
>  Wow!  Can you show us the results of
>   x <- datasets::airquality
>   saveRDS(x, file="x.rds")
>   saveRDS(x, file="y.rds")
>   tools::md5sum(c("x.rds", "y.rds"))
>   dput(readBin("x.rds", what="raw", n=file.size("x.rds")))
>   dput(readBin("y.rds", what="raw", n=file.size("y.rds")))
> 
> (Copy and paste, as text, from the R session, so we can see the input
> and the output in context.

If I do that on Linux or Windows, I get identical files.

If I copy x.rds and y.rds from Windows to Linux (which is what I wish to 
be able to do) using a shared folder between the Windows VirtualBox host 
to the Linux guest, I  get this:


> x <- readRDS(file =  "x.rds")
Error in readRDS(file = "x.rds") : error reading from connection
> x <- readRDS(file =  "y.rds")
>   tools::md5sum(c("x.rds", "y.rds"))
                              x.rds                              y.rds
"5fef054848f39b4be02b7c54f1c71a20" "978a64d1dd342d16a381c9ca728d3665"
>   dput(readBin("x.rds", what="raw", n=file.size("x.rds")))
as.raw(c(0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x06, 0x03, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00))
>   dput(readBin("y.rds", what="raw", n=file.size("y.rds")))
as.raw(c(0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x06, 0xe5, 0x97, 0x4b, 0x6c, 0x54, 0x55, 0x18, 0xc7, 0xcf, 0x9d,
0x0e, 0x7d, 0x41, 0x71, 0x2c, 0x15, 0xac, 0x65, 0xa0, 0x94, 0xa9,
0x80, 0x94, 0x52, 0xa1, 0x0b, 0xa9, 0x01, 0xa6, 0x58, 0xc4, 0xda,
0x76, 0x68, 0x99, 0x42, 0x0b, 0x2d, 0xe8, 0x08, 0x45, 0x4d, 0xca,
0x94, 0xb4, 0xc4, 0x07, 0x1b, 0x49, 0x5c, 0x10, 0x75, 0x65, 0xa2,
0x26, 0x35, 0x71, 0xad, 0x3b, 0x16, 0x2e, 0x4c, 0x7c, 0x6b, 0xc2,
0x82, 0xa8, 0x71, 0xa3, 0x71, 0x63, 0x7c, 0x2c, 0x74, 0x85, 0x2c,
0x8c, 0x0b, 0xa3, 0x40, 0xfd, 0x7f, 0xf7, 0xfc, 0xff, 0xed, 0xcd,
0x49, 0x59, 0xcf, 0xc2, 0x9b, 0xfc, 0xe6, 0xbb, 0xe7, 0x3b, 0xe7,
0x7c, 0xaf, 0x73, 0xee, 0xdc, 0x73, 0xc7, 0xeb, 0x9d, 0x73, 0x29,
0x57, 0x95, 0x4a, 0xbb, 0x54, 0x15, 0x6e, 0xab, 0xd6, 0xe0, 0xa7,
0x1a, 0x34, 0x80, 0x79, 0xb0, 0x0d, 0xe4, 0xc0, 0x2a, 0xd0, 0x78,
0xc9, 0xc5, 0xd7, 0x7a, 0xb0, 0x0e, 0xd8, 0xd8, 0x5a, 0xea, 0x6a,
0x40, 0x06, 0xac, 0x04, 0xab, 0x6d, 0x2c, 0x65, 0x1b, 0xed, 0x6d,
0x60, 0x5f, 0x44, 0x99, 0x06, 0xad, 0x36, 0x57, 0xd0, 0xe6, 0x0e,
0x30, 0x07, 0xda, 0x93, 0x7d, 0xc1, 0xb8, 0x2c, 0xe5, 0x21, 0xb0,
0x25, 0x39, 0x3f, 0x71, 0x7f, 0x8f, 0xd9, 0x00, 0x4d, 0x8c, 0xbd,
0xe1, 0x4e, 0xf6, 0x96, 0xb1, 0x7f, 0x19, 0x3c, 0xa8, 0xf8, 0x70,
0xe5, 0xc1, 0x56, 0x30, 0x04, 0x4a, 0xe4, 0x28, 0xfb, 0xac, 0x7e,
0x2d, 0x89, 0x1a, 0x74, 0x81, 0xcd, 0x60, 0x2f, 0x38, 0x0c, 0xf6,
0x5b, 0x5d, 0x12, 0xb6, 0x87, 0xc1, 0x34, 0xe3, 0xea, 0x06, 0x47,
0xc0, 0x2e, 0xfa, 0x78, 0xd8, 0xf2, 0x01, 0x75, 0xce, 0xd7, 0xb2,
0x40, 0x5b, 0x07, 0xc0, 0x45, 0x70, 0x1c, 0x94, 0x13, 0xb6, 0x3a,
0x9c, 0x5f, 0x8b, 0x5e, 0xb6, 0xd7, 0xd2, 0x86, 0xd5, 0x71, 0x23,
0xfb, 0xad, 0x0e, 0x75, 0xec, 0xb7, 0xda, 0xbe, 0x07, 0xfa, 0xd9,
0x1e, 0x04, 0xcf, 0x81, 0x51, 0xcb, 0x07, 0x3c, 0x49, 0x9f, 0xfd,
0x60, 0x02, 0xec, 0xb4, 0x1a, 0x30, 0xd6, 0x75, 0xb4, 0x75, 0x6f,
0xc2, 0xee, 0x7a, 0xc6, 0x6a, 0x7b, 0xa5, 0xd3, 0xf9, 0x35, 0x6f,
0xe0, 0x98, 0x0c, 0xef, 0x6d, 0x5e, 0x8e, 0xb5, 0xb1, 0xfd, 0xb0,
0x81, 0xbe, 0xb5, 0x47, 0x9a, 0xdc, 0xd2, 0x5e, 0xfb, 0x94, 0xf1,
0xbc, 0x89, 0x6d, 0xb2, 0x67, 0x29, 0xcf, 0x68, 0x3b, 0x7e, 0x4e,
0x3b, 0xbf, 0xdf, 0xbe, 0xa4, 0xce, 0xc0, 0xde, 0x8a, 0xcc, 0x46,
0x2f, 0x24, 0xe2, 0x8e, 0x76, 0xfb, 0xf8, 0xa3, 0x03, 0x8c, 0xb1,
0x16, 0xf7, 0x56, 0xd7, 0x66, 0x30, 0xe9, 0xeb, 0x18, 0xd5, 0xd3,
0xbf, 0xf9, 0xbc, 0x09, 0x7e, 0x86, 0x0e, 0x31, 0x46, 0xd8, 0x9f,
0x91, 0xd5, 0xec, 0x4f, 0xf0, 0x21, 0xf8, 0x11, 0x6d, 0xcc, 0x77,
0x2f, 0x41, 0xde, 0x0d, 0xb0, 0x0e, 0xd1, 0x23, 0xc0, 0x1e, 0x92,
0x7f, 0xc0, 0x1b, 0xb8, 0x1f, 0xa4, 0xaf, 0xcf, 0x20, 0xad, 0x16,
0xb6, 0xdf, 0x5e, 0x00, 0xaf, 0x80, 0xb7, 0xb8, 0x16, 0x13, 0x1c,
0x7f, 0xd9, 0xdb, 0x8a, 0x6b, 0xfa, 0x14, 0xd7, 0xe7, 0x55, 0xcc,
0xb3, 0x38, 0xfe, 0x06, 0xd7, 0xc1, 0x14, 0xb8, 0x02, 0x5d, 0x0f,
0x40, 0x5d, 0x22, 0x3c, 0x27, 0x51, 0xc6, 0xeb, 0xdc, 0x6b, 0x8c,
0xe7, 0x8a, 0x8f, 0xc5, 0xf6, 0x59, 0x94, 0xf6, 0xf9, 0x47, 0x59,
0xb4, 0x3f, 0xf2, 0x31, 0x5b, 0x9d, 0xa3, 0x14, 0xc0, 0x3e, 0x8a,
0xee, 0xf7, 0xf9, 0xb9, 0x11, 0xe7, 0xf7, 0xd9, 0xf7, 0xd0, 0x59,
0x0d, 0x6f, 0x81, 0xdb, 0xa0, 0xc8, 0xb5, 0x1a, 0x52, 0xad, 0x59,
0x9b, 0x05, 0xf0, 0x1b, 0xf8, 0x16, 0xfc, 0xc4, 0x7c, 0x3e, 0xf7,
0x75, 0x70, 0xef, 0x38, 0xbf, 0x57, 0xed, 0xd9, 0xb3, 0x7a, 0xdb,
0xb3, 0xfa, 0x97, 0x5f, 0xbb, 0xb8, 0x36, 0x39, 0xce, 0xff, 0x0e,
0xdc, 0x00, 0x3f, 0x70, 0x6d, 0xbf, 0x02, 0xbf, 0x82, 0x3f, 0xc0,
0xc7, 0xe0, 0x5d, 0x70, 0x15, 0x7c, 0x00, 0x3e, 0x01, 0x4f, 0x70,
0x8d, 0x6e, 0x32, 0x8f, 0xdf, 0x69, 0xef, 0x3a, 0xe5, 0x0d, 0xc6,
0x7a, 0x9e, 0x36, 0x7e, 0x01, 0x2d, 0xd4, 0x5f, 0xa3, 0x5c, 0xed,
0xeb, 0x14, 0x3f, 0xbb, 0xb6, 0xaf, 0xbe, 0x00, 0xaf, 0xfb, 0xf5,
0x71, 0x2f, 0xb3, 0x16, 0x36, 0x66, 0x3e, 0x9f, 0x9d, 0xb7, 0xeb,
0xed, 0x7c, 0xab, 0x4f, 0x38, 0xbf, 0x6d, 0x77, 0x7c, 0xe5, 0xb7,
0xb0, 0xdd, 0xc1, 0xfe, 0x1d, 0x5f, 0xdb, 0xf5, 0x4d, 0x7e, 0x13,
0xfb, 0xb7, 0x53, 0xdf, 0xdd, 0xec, 0xa5, 0xf4, 0x2d, 0xd4, 0x6f,
0x3e, 0x1b, 0x5f, 0xf9, 0x36, 0xca, 0x76, 0xce, 0x7f, 0x80, 0x6d,
0xd9, 0xdf, 0x4a, 0xb9, 0x2b, 0xd0, 0x6b, 0xbe, 0x64, 0x57, 0x60,
0x57, 0xf3, 0xba, 0x82, 0xf8, 0x5a, 0x03, 0xbb, 0xd2, 0xaf, 0xa5,
0x54, 0xbe, 0x8a, 0x77, 0xd1, 0x3e, 0xf3, 0x50, 0xbc, 0xea, 0xef,
0x08, 0xfc, 0x2a, 0x3f, 0xe5, 0xaf, 0x78, 0x95, 0x9f, 0xe6, 0x2b,
0x8e, 0x70, 0x9c, 0xe2, 0xe9, 0x7e, 0xdf, 0xdb, 0x6f, 0x0b, 0xf2,
0xce, 0x71, 0x7c, 0xb3, 0xf7, 0xbf, 0xff, 0x5f, 0xc6, 0xd1, 0xc8,
0x71, 0xd4, 0x2f, 0xda, 0x6f, 0x0d, 0xe6, 0x85, 0x7e, 0xd4, 0x9f,
0x09, 0xd6, 0x23, 0x5c, 0x97, 0xc6, 0xa0, 0xdd, 0x14, 0xf8, 0xbb,
0x53, 0xfd, 0xc2, 0xfd, 0x21, 0x29, 0xbd, 0xea, 0x15, 0xe4, 0xb5,
0x68, 0x5f, 0xf1, 0x86, 0xfb, 0x46, 0xfa, 0x4d, 0x41, 0xbe, 0x6a,
0x6b, 0x7d, 0x15, 0x4f, 0x28, 0x95, 0x5f, 0xb8, 0x5e, 0xd9, 0x20,
0x2e, 0xb5, 0x95, 0x7f, 0x26, 0xa8, 0x67, 0xe8, 0x57, 0x71, 0x85,
0x32, 0x8c, 0x3b, 0xcc, 0x57, 0x7e, 0x54, 0x5f, 0xf5, 0xef, 0x0c,
0x9e, 0x33, 0x3d, 0x7f, 0xb2, 0xb7, 0x32, 0xc8, 0x5f, 0xeb, 0xa0,
0xfe, 0x54, 0xb0, 0x4e, 0x92, 0xca, 0x4f, 0x75, 0xae, 0xa6, 0x54,
0x9e, 0xd9, 0xc0, 0x7f, 0x18, 0x57, 0x7b, 0xe0, 0x47, 0xeb, 0xaa,
0xf1, 0xf2, 0xa3, 0x71, 0xe1, 0x3a, 0xaa, 0xde, 0xb9, 0x40, 0x2a,
0x0f, 0xe5, 0xa9, 0x75, 0x0a, 0xc7, 0xe9, 0xb9, 0x96, 0x3d, 0xfd,
0x6f, 0x74, 0x04, 0x76, 0xe8, 0xd7, 0x2d, 0xbd, 0x3b, 0xf1, 0x6e,
0x72, 0x8f, 0x81, 0xc7, 0xc1, 0x3e, 0xf0, 0x90, 0xf3, 0xe7, 0x06,
0xbc, 0x1b, 0xe3, 0xf7, 0x90, 0x9d, 0x47, 0x0e, 0xb2, 0xff, 0x20,
0xfb, 0xfa, 0x40, 0x8f, 0xf3, 0xff, 0xe7, 0xd6, 0xde, 0x43, 0xdd,
0x3e, 0xce, 0xe9, 0xe7, 0xbc, 0xbd, 0xec, 0xeb, 0xa1, 0x34, 0x5f,
0xf6, 0x4e, 0xb1, 0xf3, 0x8d, 0x9d, 0x21, 0x0a, 0xb4, 0x6b, 0x7a,
0x9d, 0x25, 0xac, 0xcf, 0xde, 0x39, 0x63, 0xe0, 0x04, 0xe5, 0x49,
0xe7, 0xff, 0xe3, 0x4d, 0x3f, 0xcc, 0x31, 0x43, 0x8c, 0xbb, 0x97,
0xfe, 0x06, 0xa9, 0x1b, 0x4c, 0x30, 0xe0, 0x96, 0xce, 0x25, 0xc3,
0xec, 0x2f, 0x26, 0x7c, 0x8d, 0xf0, 0xbe, 0x48, 0xc6, 0xe9, 0xc7,
0x38, 0x4e, 0x7f, 0xfd, 0x1c, 0x37, 0x41, 0x1b, 0x7a, 0x27, 0x8e,
0x32, 0xb6, 0xa3, 0xcc, 0x41, 0xfa, 0x63, 0xd4, 0xe9, 0x7e, 0x9c,
0xb2, 0xc8, 0x31, 0x23, 0xcb, 0x8c, 0x1d, 0xa3, 0xbf, 0x13, 0x64,
0x92, 0x7d, 0xc7, 0x96, 0xc9, 0x39, 0x59, 0xbb, 0x42, 0xa2, 0x0e,
0x03, 0xec, 0x1b, 0x49, 0xf8, 0xb5, 0xf3, 0xe6, 0x29, 0xe7, 0xcf,
0x67, 0xa7, 0x98, 0xc3, 0x24, 0xeb, 0x79, 0x92, 0x7e, 0x47, 0x69,
0xbf, 0x40, 0x1b, 0xca, 0x57, 0xf5, 0x3c, 0x44, 0x0a, 0x5c, 0x27,
0xd3, 0xf7, 0x31, 0xae, 0x3c, 0xfb, 0x6c, 0xbc, 0xed, 0x0d, 0x3b,
0xb3, 0x3e, 0xca, 0x79, 0x03, 0x89, 0xb1, 0xda, 0x6b, 0x2b, 0x2a,
0x48, 0x75, 0x85, 0xa8, 0xa9, 0x20, 0xb5, 0x15, 0xa4, 0xae, 0x42,
0x68, 0xaf, 0xd9, 0x41, 0x1f, 0xe7, 0x59, 0x67, 0x67, 0x40, 0xfb,
0x66, 0xd4, 0x1e, 0x50, 0x5d, 0x6c, 0xac, 0x7d, 0x83, 0xd9, 0x37,
0xe5, 0x2a, 0xce, 0xb3, 0x33, 0xde, 0x5d, 0xce, 0x7f, 0x83, 0xd8,
0x99, 0xd5, 0xbe, 0x11, 0xec, 0xdc, 0x6b, 0x67, 0x42, 0xfb, 0x6e,
0xb1, 0xef, 0x24, 0xfb, 0x2e, 0xb1, 0xf3, 0xa4, 0x7d, 0x1b, 0xdc,
0xe7, 0xfc, 0x59, 0xd2, 0xce, 0xf0, 0x76, 0x96, 0xb6, 0x6f, 0xd5,
0x8d, 0x15, 0xf4, 0xfd, 0x7f, 0xcc, 0xb9, 0x82, 0xbe, 0xd3, 0xa9,
0xd8, 0x77, 0x3a, 0xb6, 0xbf, 0xa2, 0x5c, 0x3a, 0x37, 0x35, 0x47,
0x83, 0xd5, 0x52, 0x1e, 0xbe, 0x38, 0x53, 0x9e, 0x62, 0xa3, 0xa6,
0x38, 0x33, 0x5d, 0x9a, 0xed, 0x3c, 0xc2, 0x66, 0x7a, 0xec, 0xd9,
0xf2, 0x19, 0xdd, 0x8f, 0x4e, 0x9d, 0x3b, 0xaf, 0x39, 0x43, 0x33,
0xe5, 0x0b, 0xcf, 0xb0, 0x51, 0xd5, 0x57, 0x7a, 0x31, 0x74, 0x74,
0x7a, 0xba, 0x34, 0x27, 0x47, 0x52, 0xd6, 0x9f, 0x29, 0x5d, 0x28,
0x75, 0x9e, 0x9d, 0x45, 0x0c, 0xc1, 0xf0, 0xba, 0xd9, 0x99, 0xe7,
0x3b, 0x15, 0x9b, 0x25, 0x9e, 0xba, 0x84, 0x9f, 0x85, 0x85, 0x85,
0xa7, 0x21, 0x6e, 0xff, 0x07, 0x03, 0xf3, 0xcf, 0x7e, 0xc7, 0x11,
0x00, 0x00))
> 

The issue is evidently with the shared folder. I've been doing that 
(sharing the folder) for years and never encountered a problem.


> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com [1]
> On Mon, Nov 12, 2018 at 12:42 PM, p_connolly
> <p_connolly at slingshot.co.nz> wrote:
> 
>> On 2018-11-12 22:49, peter dalgaard wrote:
>> Er, where, what, how? I can't reproduce that, at least not on 3.5.1
>> on MacOS:
>> 
>> x <- airquality
>> saveRDS(x, file = "x.rds")
>> x <- NULL
>> x <- readRDS(file = "x.rds")
>> x
>> Ozone Solar.R Wind Temp Month Day
>> 1      41     190  7.4   67     5   1
>> 2      36     118  8.0   72     5   2
>> 3      12     149 12.6   74     5   3
>> ...
>> 
>> Looks fine to me.
> 
> It seems to work fine using the same installation to read as used for
> the save.
> But it's a different story if the save was done on a Windows
> installation and read on a Linux installation.
> 
> ## On Windows 3.4.2
> 
>> x <- airquality
>> saveRDS(x, file = "x.rds")
>> saveRDS(x, file = "y.rds")
> 
> Files x.rds and y.rds are identical in size but utterly different in
> content.
> 
> ## On Linux 3.5.1
> 
>> x <- readRDS(file =  "x.rds")
>  Error in readRDS(file = "x.rds") : error reading from connection
> 
>> x <- readRDS(file =  "y.rds")
>> head(x)
>    Ozone Solar.R Wind Temp Month Day
> 1    41     190  7.4   67     5   1
> 2    36     118  8.0   72     5   2
> 3    12     149 12.6   74     5   3
> 4    18     313 11.5   62     5   4
> 5    NA      NA 14.3   56     5   5
> 6    28      NA 14.9   66     5   6
> 
> It might just be the age of the Windows installation.  I don't have
> much use for Windows, so I haven't had much inclination to install a
> newer version.
> 
> YMMV
> 
>> ?
>> -pd
>> 
>>> On 12 Nov 2018, at 08:28 , Patrick Connolly
>>> <p_connolly at slingshot.co.nz> wrote:
>>> 
>>> The solution was very simple.  Don't use the same name for the rds
>>> file  as used for the R object, viz a vie:
>>> 
>>> saveRDS(x, file = "x.rds")
>>> and
>>> x <- readRDS(file = "x.rds")
>>> 
>>> will not work; however
>>> 
>>> saveRDS(x, file = "y.rds")
>>> and
>>> x <- readRDS(file = "y.rds")
>>> will work.
>>> 
>>> An undocumented feature?
>>> 
>>> Thanks to all who contributed.
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help [2]
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html [3]
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> Links:
> ------
> [1] http://tibco.com
> [2] https://stat.ethz.ch/mailman/listinfo/r-help
> [3] http://www.R-project.org/posting-guide.html


From dc@rl@on @ending from t@mu@edu  Tue Nov 13 04:19:11 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Tue, 13 Nov 2018 03:19:11 +0000
Subject: [R] semiparametric manova
In-Reply-To: <elvKFTZpJcbVW35mUngKukQFiT3bGLVBaiDaJ98ButrpofTPFq7jvWo8LUyxlSSBiktd9pYY3SofN3Oe0zxt3TU5tizUcgSj7t5zhy11hL4=@protonmail.com>
References: <nZHPMpPcaDAttf_2CeWpRPHXuE776jVeeFvfuY1JwxwK541qPyNp7_x9puqkxTSdlZ5WXuCQRniPzT87DKAvXHgWxTgQ_lMn8m6D8nqbckY=@protonmail.com>
 <2235fce5-c3fe-c595-84b8-21dc4d635213@comcast.net>
 <elvKFTZpJcbVW35mUngKukQFiT3bGLVBaiDaJ98ButrpofTPFq7jvWo8LUyxlSSBiktd9pYY3SofN3Oe0zxt3TU5tizUcgSj7t5zhy11hL4=@protonmail.com>
Message-ID: <c0c902f5fffa4c0b98f91f7a2df4366f@tamu.edu>

With two variables there are no combinations with less than 2 observations. Here's the part of the data you provided:

> df <- structure(list(V1 = c(200, 200, 200, 200, 200, 200, 200, 200, 
200, 200, 200, 200, 200, 200, 200, 500, 500, 500, 500, 500, 500, 
500, 500, 500, 500, 350, 350, 350, 350, 350, 200, 200, 200, 200, 
200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 500, 500, 
500, 500, 500, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 
350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 500, 500, 500, 
500, 500, 500, 500, 500, 500, 500, 350, 350, 350, 350, 350, 500, 
500, 500, 500, 500), V2 = c(16, 16, 16, 16, 16, 8, 8, 8, 8, 8, 
8, 8, 8, 8, 8, 16, 16, 16, 16, 16, 8, 8, 8, 8, 8, 8, 8, 8, 8, 
8, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 16, 16, 16, 16, 16, 
8, 8, 8, 8, 8, 16, 16, 16, 16, 16, 8, 8, 8, 8, 8, 16, 16, 16, 
16, 16, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 16, 16, 16, 16, 
16, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24), V3 = c(16, 16, 16, 
16, 16, 16, 16, 16, 16, 16, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 23, 
23, 23, 23, 23, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 23, 23, 23, 23, 
23, 23, 23, 23, 23, 23, 16, 16, 16, 16, 16, 9, 9, 9, 9, 9, 23, 
23, 23, 23, 23, 16, 16, 16, 16, 16, 23, 23, 23, 23, 23, 16, 16, 
16, 16, 16, 23, 23, 23, 23, 23, 16, 16, 16, 16, 16, 9, 9, 9, 
9, 9)), class = "data.frame", row.names = c(NA, -90L))

> xtabs(~V1+V2+V3, df) # There are 9 cells with 0 entries. That is the problem.
, , V3 = 9

     V2
V1    8 16 24
  200 5  0  5
  350 5  5  0
  500 0  5  5

, , V3 = 16

     V2
V1    8 16 24
  200 5  5  0
  350 0  5  5
  500 5  0  5

, , V3 = 23

     V2
V1    8 16 24
  200 0  5  5
  350 5  0  5
  500 5  5  0

> xtabs(~V1+V2, df)  # No cells < 2 with V1, V2
     V2
V1     8 16 24
  200 10 10 10
  350 10 10 10
  500 10 10 10
> xtabs(~V1+V3, df)  # No cells < 2 with V1, V3
     V3
V1     9 16 23
  200 10 10 10
  350 10 10 10
  500 10 10 10
> xtabs(~V2+V3, df)  # No cells < 2 with V2, V3
    V3
V2    9 16 23
  8  10 10 10
  16 10 10 10
  24 10 10 10


David L. Carlson
Department of Anthropology
Texas A&M University



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Yectli Huerta via R-help
Sent: Monday, November 12, 2018 6:25 PM
To: r-help at r-project.org
Subject: Re: [R] semiparametric manova

thanks for the replies.

i don't believe the data is the problem. here you see how i used 3 variables and it fails,
but when i use any combination of 2 variables, it does work

> head(df)
?? V1 V2 V3 V4 V5?????????? V6?????????? V7
1 200 16 16? 3 64 5.584092e+13 1.616745e+12
2 200 16 16? 3 64 5.589262e+13 1.715906e+12
3 200 16 16? 3 64 5.588578e+13 1.714084e+12
4 200 16 16? 3 64 5.588061e+13 1.651920e+12
5 200 16 16? 3 64 5.589810e+13 1.624824e+12
6 200? 8 16? 1 48 5.585124e+13 1.689478e+12
> library(MANOVA.RM)
> df$V1
[1] 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 500 500 500 500
[20] 500 500 500 500 500 500 350 350 350 350 350 200 200 200 200 200 200 200 200
[39] 200 200 200 200 200 200 200 500 500 500 500 500 350 350 350 350 350 350 350
[58] 350 350 350 350 350 350 350 350 350 350 350 350 350 500 500 500 500 500 500
[77] 500 500 500 500 350 350 350 350 350 500 500 500 500 500
> df$V2
[1] 16 16 16 16 16? 8? 8? 8? 8? 8? 8? 8? 8? 8? 8 16 16 16 16 16? 8? 8? 8? 8? 8
[26]? 8? 8? 8? 8? 8 24 24 24 24 24 24 24 24 24 24 16 16 16 16 16? 8? 8? 8? 8? 8
[51] 16 16 16 16 16? 8? 8? 8? 8? 8 16 16 16 16 16 24 24 24 24 24 24 24 24 24 24
[76] 16 16 16 16 16 24 24 24 24 24 24 24 24 24 24
> df$V3
[1] 16 16 16 16 16 16 16 16 16 16? 9? 9? 9? 9? 9? 9? 9? 9? 9? 9 23 23 23 23 23
[26]? 9? 9? 9? 9? 9? 9? 9? 9? 9? 9 23 23 23 23 23 23 23 23 23 23 16 16 16 16 16
[51]? 9? 9? 9? 9? 9 23 23 23 23 23 16 16 16 16 16 23 23 23 23 23 16 16 16 16 16
[76] 23 23 23 23 23 16 16 16 16 16? 9? 9? 9? 9? 9
>
> MANOVA.wide(cbind(V6,V7)~V1*V2*V3,data=df,seed=1234)
Error in MANOVA.wide(cbind(V6, V7) ~ V1 * V2 * V3, data = df, seed = 1234) :
? There is at least one factor-level combination
?????????? with less than 2 observations!

> MANOVA.wide(cbind(V6,V7)~V1*V2,data=df,seed=1234)
Call:
cbind(V6, V7) ~ V1 * V2

Wald-Type Statistic (WTS):
????? Test statistic df p-value
V1??????????? 17.870? 4?? 0.001
V2??????????? 20.392? 4?? 0.000
V1:V2???????? 24.127? 8?? 0.002

....

> MANOVA.wide(cbind(V6,V7)~V1*V3,data=df,seed=1234)
Call:
cbind(V6, V7) ~ V1 * V3

Wald-Type Statistic (WTS):
????? Test statistic df p-value
V1??????????? 18.566? 4?? 0.001
V3??????????? 19.894? 4?? 0.001
V1:V3???????? 27.330? 8?? 0.001

...
> MANOVA.wide(cbind(V6,V7)~V2*V3,data=df,seed=1234)
Call:
cbind(V6, V7) ~ V2 * V3

Wald-Type Statistic (WTS):
????? Test statistic df p-value
V2??????????? 20.139? 4?? 0.000
V3??????????? 19.947? 4?? 0.001
V2:V3???????? 32.088? 8?? 0.000

....

From bgunter@4567 @ending from gm@il@com  Tue Nov 13 05:33:30 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 12 Nov 2018 20:33:30 -0800
Subject: [R] which element is duplicated?
In-Reply-To: <9f0b4102-53fd-c751-09b2-92d9c78a5ec4@gmail.com>
References: <9f0b4102-53fd-c751-09b2-92d9c78a5ec4@gmail.com>
Message-ID: <CAGxFJbRvphQGQ3Adk2KfAMmX1VnCkuLzMFEB36jN+nNYB=-uwQ@mail.gmail.com>

> match(v, unique(v))
[1] 1 2 2 1

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Nov 12, 2018 at 5:08 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> The duplicated() function gives TRUE if an item in a vector (or row in a
> matrix, etc.) is a duplicate of an earlier item.  But what I would like
> to know is which item does it duplicate?
>
> For example,
>
> v <- c("a", "b", "b", "a")
> duplicated(v)
>
> returns
>
> [1] FALSE FALSE  TRUE  TRUE
>
> What I want is a fast way to calculate
>
>   [1] NA NA 2 1
>
> or (equally useful to me)
>
>   [1] 1 2 2 1
>
> The result should have the property that if result[i] == j, then v[i] ==
> v[j], at least for i != j.
>
> Does this already exist somewhere, or is it easy to write?
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hp@ge@ @ending from fredhutch@org  Tue Nov 13 06:35:19 2018
From: hp@ge@ @ending from fredhutch@org (Pages, Herve)
Date: Tue, 13 Nov 2018 05:35:19 +0000
Subject: [R] which element is duplicated?
In-Reply-To: <9f0b4102-53fd-c751-09b2-92d9c78a5ec4@gmail.com>
References: <9f0b4102-53fd-c751-09b2-92d9c78a5ec4@gmail.com>
Message-ID: <83a637dc-2605-fa4f-6a3a-8949f85e2122@fredhutch.org>

Hi,

On 11/12/18 17:08, Duncan Murdoch wrote:
> The duplicated() function gives TRUE if an item in a vector (or row in 
> a matrix, etc.) is a duplicate of an earlier item.? But what I would 
> like to know is which item does it duplicate?
>
> For example,
>
> v <- c("a", "b", "b", "a")
> duplicated(v)
>
> returns
>
> [1] FALSE FALSE? TRUE? TRUE
>
> What I want is a fast way to calculate
>
> ?[1] NA NA 2 1
>
> or (equally useful to me)
>
> ?[1] 1 2 2 1
>
> The result should have the property that if result[i] == j, then v[i] 
> == v[j], at least for i != j.
>
> Does this already exist somewhere, or is it easy to write?

I generally use match() for that:

 > v <- c("a", "b", "b", "a")

 > match(v, v)

[1] 1 2 2 1

H.

>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=APEsp-OzJs6YdfshtiYe715BsAor8xTu26lpN4KGOrU&s=opxT_5og2YaWKdiXD-cRz0gWxGGMRG6kq20Jo8711qA&e= 
>
> PLEASE do read the posting guide 
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=APEsp-OzJs6YdfshtiYe715BsAor8xTu26lpN4KGOrU&s=ZaPnASTzuEmE8EHqFL6F5wYkPhhg_uv-CMrGjY2-_Q4&e=
> and provide commented, minimal, self-contained, reproducible code.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From bgunter@4567 @ending from gm@il@com  Tue Nov 13 06:43:31 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 12 Nov 2018 21:43:31 -0800
Subject: [R] which element is duplicated?
In-Reply-To: <CAGxFJbRvphQGQ3Adk2KfAMmX1VnCkuLzMFEB36jN+nNYB=-uwQ@mail.gmail.com>
References: <9f0b4102-53fd-c751-09b2-92d9c78a5ec4@gmail.com>
 <CAGxFJbRvphQGQ3Adk2KfAMmX1VnCkuLzMFEB36jN+nNYB=-uwQ@mail.gmail.com>
Message-ID: <CAGxFJbTDkjgOQU=OF15zO5-igDW=7jYH5_TZ+FYzWNC0b7-2gg@mail.gmail.com>

It is not clear to what you want for the general case. Perhaps:

> v <- letters[c(2,2,1,2,1,1)]
> wh <- tapply(seq_along(v),factor(v), '[',1)
> w <- wh[match(v,v[wh])]
> w
b b a b a a
1 1 3 1 3 3
> ## and if you want NA's for the first occurences of unique values
> ## of course:
> w[wh] <- NA
> w
 b  b  a  b  a  a
NA  1 NA  1  3  3

I'd like to see a cleverer solution that vectorizes and avoids the
tapply(), though.

Cheers,
Bert




On Mon, Nov 12, 2018 at 8:33 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> > match(v, unique(v))
> [1] 1 2 2 1
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Nov 12, 2018 at 5:08 PM Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
>> The duplicated() function gives TRUE if an item in a vector (or row in a
>> matrix, etc.) is a duplicate of an earlier item.  But what I would like
>> to know is which item does it duplicate?
>>
>> For example,
>>
>> v <- c("a", "b", "b", "a")
>> duplicated(v)
>>
>> returns
>>
>> [1] FALSE FALSE  TRUE  TRUE
>>
>> What I want is a fast way to calculate
>>
>>   [1] NA NA 2 1
>>
>> or (equally useful to me)
>>
>>   [1] 1 2 2 1
>>
>> The result should have the property that if result[i] == j, then v[i] ==
>> v[j], at least for i != j.
>>
>> Does this already exist somewhere, or is it easy to write?
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Tue Nov 13 06:49:28 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 12 Nov 2018 21:49:28 -0800
Subject: [R] which element is duplicated?
In-Reply-To: <CAGxFJbTDkjgOQU=OF15zO5-igDW=7jYH5_TZ+FYzWNC0b7-2gg@mail.gmail.com>
References: <9f0b4102-53fd-c751-09b2-92d9c78a5ec4@gmail.com>
 <CAGxFJbRvphQGQ3Adk2KfAMmX1VnCkuLzMFEB36jN+nNYB=-uwQ@mail.gmail.com>
 <CAGxFJbTDkjgOQU=OF15zO5-igDW=7jYH5_TZ+FYzWNC0b7-2gg@mail.gmail.com>
Message-ID: <CAGxFJbSbkfgRZUTHw-k852-n-aRSPCF93s9Qsw-NoWU=-uNRzw@mail.gmail.com>

"I'd like to see a cleverer solution that vectorizes..."

and Herve provided it.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Nov 12, 2018 at 9:43 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> It is not clear to what you want for the general case. Perhaps:
>
> > v <- letters[c(2,2,1,2,1,1)]
> > wh <- tapply(seq_along(v),factor(v), '[',1)
> > w <- wh[match(v,v[wh])]
> > w
> b b a b a a
> 1 1 3 1 3 3
> > ## and if you want NA's for the first occurences of unique values
> > ## of course:
> > w[wh] <- NA
> > w
>  b  b  a  b  a  a
> NA  1 NA  1  3  3
>
> I'd like to see a cleverer solution that vectorizes and avoids the
> tapply(), though.
>
> Cheers,
> Bert
>
>
>
>
> On Mon, Nov 12, 2018 at 8:33 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> > match(v, unique(v))
>> [1] 1 2 2 1
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Nov 12, 2018 at 5:08 PM Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>>
>>> The duplicated() function gives TRUE if an item in a vector (or row in a
>>> matrix, etc.) is a duplicate of an earlier item.  But what I would like
>>> to know is which item does it duplicate?
>>>
>>> For example,
>>>
>>> v <- c("a", "b", "b", "a")
>>> duplicated(v)
>>>
>>> returns
>>>
>>> [1] FALSE FALSE  TRUE  TRUE
>>>
>>> What I want is a fast way to calculate
>>>
>>>   [1] NA NA 2 1
>>>
>>> or (equally useful to me)
>>>
>>>   [1] 1 2 2 1
>>>
>>> The result should have the property that if result[i] == j, then v[i] ==
>>> v[j], at least for i != j.
>>>
>>> Does this already exist somewhere, or is it easy to write?
>>>
>>> Duncan Murdoch
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From chocold12 @ending from gm@il@com  Tue Nov 13 08:21:41 2018
From: chocold12 @ending from gm@il@com (lily li)
Date: Tue, 13 Nov 2018 15:21:41 +0800
Subject: [R] How to create gridded data
Message-ID: <CAN5afy9jzOCZDzvTuzXBzeTzi_aZLsnVnYM1VuBWe0e5ziUWsQ@mail.gmail.com>

Hi R users,

I have a question about manipulating data. For example, I have DF1 as the
following, how to transform it to a gridded dataset DF2? In DF2, each value
Precip is an attribute of the corresponding grid cell. So DF2 is like a
spatial surface, and can be imported to ArcGIS. Thanks for your help.

DF1
latitude   longitude   Precip
45.5           110.5         3.2
45.5           111            5.0
45.5           111.5         1.8
45.5           112            2.0
46              110.5         6.1
46              111            4.5
46              111.5         7.8
46              112            5.5
...


DF2
6.1   4.5   7.8   5.5
3.2   5.0   1.8   2.0
...

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Tue Nov 13 09:02:24 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Tue, 13 Nov 2018 19:02:24 +1100
Subject: [R] How to create gridded data
In-Reply-To: <CAN5afy9jzOCZDzvTuzXBzeTzi_aZLsnVnYM1VuBWe0e5ziUWsQ@mail.gmail.com>
References: <CAN5afy9jzOCZDzvTuzXBzeTzi_aZLsnVnYM1VuBWe0e5ziUWsQ@mail.gmail.com>
Message-ID: <CA+8X3fWCGmA6wCtVTacm6StERzF3Cdmm9pKmr3Lym3U-TjHJtA@mail.gmail.com>

Hi lily,
Something like this should work:

DF1<-read.table(text=
"latitude   longitude   Precip
45.5           110.5         3.2
45.5           111            5.0
45.5           111.5         1.8
45.5           112            2.0
46              110.5         6.1
46              111            4.5
46              111.5         7.8
46              112            5.5",
header=TRUE)
lats<-sort(unique(DF1$latitude),decreasing=TRUE)
lons<-sort(unique(DF1$longitude))
DF2<-matrix(NA,nrow=length(lats),ncol=length(lons))
rownames(DF2)<-lats
colnames(DF2)<-lons
nval<-dim(DF1)[1]
for(val in 1:nval) {
 row<-which(lats == DF1$latitude[val])
 col<-which(lons == DF1$longitude[val])
 DF2[row,col]<-DF1$Precip[val]
}

Jim

On Tue, Nov 13, 2018 at 6:22 PM lily li <chocold12 at gmail.com> wrote:
>
> Hi R users,
>
> I have a question about manipulating data. For example, I have DF1 as the
> following, how to transform it to a gridded dataset DF2? In DF2, each value
> Precip is an attribute of the corresponding grid cell. So DF2 is like a
> spatial surface, and can be imported to ArcGIS. Thanks for your help.
>
> DF1
> latitude   longitude   Precip
> 45.5           110.5         3.2
> 45.5           111            5.0
> 45.5           111.5         1.8
> 45.5           112            2.0
> 46              110.5         6.1
> 46              111            4.5
> 46              111.5         7.8
> 46              112            5.5
> ...
>
>
> DF2
> 6.1   4.5   7.8   5.5
> 3.2   5.0   1.8   2.0
> ...
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From toth@dene@ @ending from kogentum@hu  Tue Nov 13 09:41:59 2018
From: toth@dene@ @ending from kogentum@hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Tue, 13 Nov 2018 09:41:59 +0100
Subject: [R] missRanger package
In-Reply-To: <CAGxFJbRjYEsdizUC7mt37WmaX8LPs7FE7ME9CcBrxdTBv0Un_g@mail.gmail.com>
References: <1921c2ad-6e02-3262-1ade-e21def94f738@gmx.de>
 <CAGxFJbRjYEsdizUC7mt37WmaX8LPs7FE7ME9CcBrxdTBv0Un_g@mail.gmail.com>
Message-ID: <bf1c09b5-9265-f50c-9430-868eac99bf58@kogentum.hu>

Hi Rebecca,

I think it was me how suggested you the missRanger package, so this is 
actually a follow-up of you previous question about censored imputation 
of missing values (as far as I can remember).

The missRanger package uses predictive mean matching, so take a look at 
?missRanger::pmm and in general read a bit about what 'predictive mean 
matching' means.

In a nutshell: If your data is appropriate for this technique, you do 
not need to take care of explicit censoring - it will be done implicitly 
by the package.

Cheers,
Denes


On 11/12/2018 09:12 PM, Bert Gunter wrote:
> You have asked what I believe is an incoherent question, and thus are
> unlikely to receive any useful replies (of course, I may be wrong about
> this...).
> 
> Please read and follow the posting guide linked below to to ask a question
> that can be answered.
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Nov 12, 2018 at 12:03 PM Rebecca Bingert <rebecca.bingert at gmx.de>
> wrote:
> 
>> Hi,
>> does anybody know where I need to insert the censoring in the missRanger
>> package?
>> Regards,
>> Rebecca
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr@pik@l @ending from prechez@@cz  Tue Nov 13 09:42:22 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Tue, 13 Nov 2018 08:42:22 +0000
Subject: [R] which element is duplicated?
In-Reply-To: <CAGxFJbTDkjgOQU=OF15zO5-igDW=7jYH5_TZ+FYzWNC0b7-2gg@mail.gmail.com>
References: <9f0b4102-53fd-c751-09b2-92d9c78a5ec4@gmail.com>
 <CAGxFJbRvphQGQ3Adk2KfAMmX1VnCkuLzMFEB36jN+nNYB=-uwQ@mail.gmail.com>
 <CAGxFJbTDkjgOQU=OF15zO5-igDW=7jYH5_TZ+FYzWNC0b7-2gg@mail.gmail.com>
Message-ID: <8c137dff0ca448a4b698039a4a99fbd5@SRVEXCHCM1301.precheza.cz>

Hi

similar result (with different numerical values) could be achieved by making v a factor.

> v <- letters[c(2,2,1,2,1,1)]
> vf<-factor(v)
> as.numeric(vf)
[1] 2 2 1 2 1 1

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
> Sent: Tuesday, November 13, 2018 6:44 AM
> To: Duncan Murdoch <murdoch.duncan at gmail.com>
> Cc: R-help <R-help at r-project.org>
> Subject: Re: [R] which element is duplicated?
>
> It is not clear to what you want for the general case. Perhaps:
>
> > v <- letters[c(2,2,1,2,1,1)]
> > wh <- tapply(seq_along(v),factor(v), '[',1) w <- wh[match(v,v[wh])] w
> b b a b a a
> 1 1 3 1 3 3
> > ## and if you want NA's for the first occurences of unique values ##
> > of course:
> > w[wh] <- NA
> > w
>  b  b  a  b  a  a
> NA  1 NA  1  3  3
>
> I'd like to see a cleverer solution that vectorizes and avoids the tapply(),
> though.
>
> Cheers,
> Bert
>
>
>
>
> On Mon, Nov 12, 2018 at 8:33 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
> > > match(v, unique(v))
> > [1] 1 2 2 1
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Mon, Nov 12, 2018 at 5:08 PM Duncan Murdoch
> > <murdoch.duncan at gmail.com>
> > wrote:
> >
> >> The duplicated() function gives TRUE if an item in a vector (or row
> >> in a matrix, etc.) is a duplicate of an earlier item.  But what I
> >> would like to know is which item does it duplicate?
> >>
> >> For example,
> >>
> >> v <- c("a", "b", "b", "a")
> >> duplicated(v)
> >>
> >> returns
> >>
> >> [1] FALSE FALSE  TRUE  TRUE
> >>
> >> What I want is a fast way to calculate
> >>
> >>   [1] NA NA 2 1
> >>
> >> or (equally useful to me)
> >>
> >>   [1] 1 2 2 1
> >>
> >> The result should have the property that if result[i] == j, then v[i]
> >> == v[j], at least for i != j.
> >>
> >> Does this already exist somewhere, or is it easy to write?
> >>
> >> Duncan Murdoch
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From m@echler @ending from @t@t@m@th@ethz@ch  Tue Nov 13 10:08:12 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 13 Nov 2018 10:08:12 +0100
Subject: [R] which element is duplicated?
In-Reply-To: <8c137dff0ca448a4b698039a4a99fbd5@SRVEXCHCM1301.precheza.cz>
References: <9f0b4102-53fd-c751-09b2-92d9c78a5ec4@gmail.com>
 <CAGxFJbRvphQGQ3Adk2KfAMmX1VnCkuLzMFEB36jN+nNYB=-uwQ@mail.gmail.com>
 <CAGxFJbTDkjgOQU=OF15zO5-igDW=7jYH5_TZ+FYzWNC0b7-2gg@mail.gmail.com>
 <8c137dff0ca448a4b698039a4a99fbd5@SRVEXCHCM1301.precheza.cz>
Message-ID: <23530.38012.969244.871671@stat.math.ethz.ch>

>>>>> PIKAL Petr 
>>>>>     on Tue, 13 Nov 2018 08:42:22 +0000 writes:

    > Hi
    > similar result (with different numerical values) could
    > be achieved by making v a factor.

> > v <- letters[c(2,2,1,2,1,1)]
> > vf<-factor(v)
> > as.numeric(vf)
> [1] 2 2 1 2 1 1
> 
> Cheers
> Petr

Yes, as was already remarked by Michael Sumner.

But really the power is in  match() :  It is called at *twice* by factor().

Martin

> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
> > Sent: Tuesday, November 13, 2018 6:44 AM
> > To: Duncan Murdoch <murdoch.duncan at gmail.com>
> > Cc: R-help <R-help at r-project.org>
> > Subject: Re: [R] which element is duplicated?
> >
> > It is not clear to what you want for the general case. Perhaps:
> >
> > > v <- letters[c(2,2,1,2,1,1)]
> > > wh <- tapply(seq_along(v),factor(v), '[',1) w <- wh[match(v,v[wh])] w
> > b b a b a a
> > 1 1 3 1 3 3
> > > ## and if you want NA's for the first occurences of unique values ##
> > > of course:
> > > w[wh] <- NA
> > > w
> >  b  b  a  b  a  a
> > NA  1 NA  1  3  3
> >
> > I'd like to see a cleverer solution that vectorizes and avoids the tapply(),
> > though.
> >
> > Cheers,
> > Bert
> >
> >
> >
> >
> > On Mon, Nov 12, 2018 at 8:33 PM Bert Gunter <bgunter.4567 at gmail.com>
> > wrote:
> >
> > > > match(v, unique(v))
> > > [1] 1 2 2 1
> > >
> > > Bert Gunter
> > >
> > > "The trouble with having an open mind is that people keep coming along
> > > and sticking things into it."
> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >
> > >
> > > On Mon, Nov 12, 2018 at 5:08 PM Duncan Murdoch
> > > <murdoch.duncan at gmail.com>
> > > wrote:
> > >
> > >> The duplicated() function gives TRUE if an item in a vector (or row
> > >> in a matrix, etc.) is a duplicate of an earlier item.  But what I
> > >> would like to know is which item does it duplicate?
> > >>
> > >> For example,
> > >>
> > >> v <- c("a", "b", "b", "a")
> > >> duplicated(v)
> > >>
> > >> returns
> > >>
> > >> [1] FALSE FALSE  TRUE  TRUE
> > >>
> > >> What I want is a fast way to calculate
> > >>
> > >>   [1] NA NA 2 1
> > >>
> > >> or (equally useful to me)
> > >>
> > >>   [1] 1 2 2 1
> > >>
> > >> The result should have the property that if result[i] == j, then v[i]
> > >> == v[j], at least for i != j.
> > >>
> > >> Does this already exist somewhere, or is it easy to write?
> > >>
> > >> Duncan Murdoch
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @ending from gm@il@com  Tue Nov 13 11:15:40 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Tue, 13 Nov 2018 05:15:40 -0500
Subject: [R] which element is duplicated?
In-Reply-To: <83a637dc-2605-fa4f-6a3a-8949f85e2122@fredhutch.org>
References: <9f0b4102-53fd-c751-09b2-92d9c78a5ec4@gmail.com>
 <83a637dc-2605-fa4f-6a3a-8949f85e2122@fredhutch.org>
Message-ID: <728b3945-333c-36f7-d385-480c5cdb8926@gmail.com>

On 13/11/2018 12:35 AM, Pages, Herve wrote:
> Hi,
> 
> On 11/12/18 17:08, Duncan Murdoch wrote:
>> The duplicated() function gives TRUE if an item in a vector (or row in
>> a matrix, etc.) is a duplicate of an earlier item.? But what I would
>> like to know is which item does it duplicate?
>>
>> For example,
>>
>> v <- c("a", "b", "b", "a")
>> duplicated(v)
>>
>> returns
>>
>> [1] FALSE FALSE? TRUE? TRUE
>>
>> What I want is a fast way to calculate
>>
>>  ?[1] NA NA 2 1
>>
>> or (equally useful to me)
>>
>>  ?[1] 1 2 2 1
>>
>> The result should have the property that if result[i] == j, then v[i]
>> == v[j], at least for i != j.
>>
>> Does this already exist somewhere, or is it easy to write?
> 
> I generally use match() for that:
> 
>   > v <- c("a", "b", "b", "a")
> 
>   > match(v, v)
> 
> [1] 1 2 2 1

Yes, this is perfect.  Thanks to you (and the private answer I received 
that suggested the same).

Duncan Murdoch


From m@rkp@yne@twork @ending from gm@il@com  Tue Nov 13 12:22:24 2018
From: m@rkp@yne@twork @ending from gm@il@com (Mark R Payne)
Date: Tue, 13 Nov 2018 12:22:24 +0100
Subject: [R] MGCV:: boundary conditions in gam
In-Reply-To: <704186bc-4d4f-e6c3-4311-5276703445d7@bath.edu>
References: <CAGBzUO9E7KG8Pp_ahb48bAYFTj_HEMhmHw5jDscXJ7Bn+QthLw@mail.gmail.com>
 <704186bc-4d4f-e6c3-4311-5276703445d7@bath.edu>
Message-ID: <CAGBzUO8Fwshms=ZFW18wtUD64Ta3c+BVY6_hkvULw=QptEaGQw@mail.gmail.com>

Perfect! This might be a good example to add to the documentation of mgcv
somewhere....

Thanks.

Mark


On Thu, 8 Nov 2018 at 22:08, Simon Wood <simon.wood at bath.edu> wrote:

> This first derivative penalty spline will do it, but the price paid is
> that the curves are often quite wiggly.
>
>
> library(mgcv); set.seed(5)
>
> x <- runif(100); y <- x^4 + rnorm(100)*.1
>
> b <- gam(y~s(x,m=1))
>
> pd <- data.frame(x=seq(-.5,1.5,length=200))
>
> ff <- predict(b,pd,se=TRUE)
>
> plot(x,y,xlim=c(-.5,1.5));lines(pd$x,ff$fit)
>
> lines(pd$x,ff$fit+2*ff$se.fit,lty=2)
>
> lines(pd$x,ff$fit-2*ff$se.fit,lty=2)
>
>
> On 08/11/2018 15:26, Mark R Payne wrote:
> > Dear R-help,
> >
> > I have a problem where I am using the mgcv package to in a situation
> where
> > I am fitting a gam model with a 1-D spline smoother model over a domain
> > [a,b] but then need to make predictions and extrapolate beyond b. Is
> there
> > anyway where I force the first derivative of the spline to be zero at
> > boundaries, so that I simply get a constant value outside the domain?
> >
> > Best wishes,
> >
> > Mark
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@himk@poor @ending from gm@il@com  Tue Nov 13 13:02:23 2018
From: @@himk@poor @ending from gm@il@com (Ashim Kapoor)
Date: Tue, 13 Nov 2018 17:32:23 +0530
Subject: [R] Output of arima
Message-ID: <CAC8=1ervy1GgrW17FrzwOnYgEQJbiE16uiYH_DoCP4H4Ga-b8Q@mail.gmail.com>

Dear All,

Here is a reprex:

set.seed(123)
b <- arima.sim(list(order = c(1,0,0),ar= .9),n=1000,sd=1)
arima(b)

Call:
arima(x = b)

Coefficients:
      intercept
         0.2250
s.e.     0.0688

sigma^2 estimated as 4.735:  log likelihood = -2196.4,  aic = 4396.81
>

Should sigma^2 not be equal to 1 ? Where do I misunderstand ?

Many thanks,
Ashim

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Tue Nov 13 13:37:24 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Tue, 13 Nov 2018 14:37:24 +0200
Subject: [R] Output of arima
In-Reply-To: <CAC8=1ervy1GgrW17FrzwOnYgEQJbiE16uiYH_DoCP4H4Ga-b8Q@mail.gmail.com>
References: <CAC8=1ervy1GgrW17FrzwOnYgEQJbiE16uiYH_DoCP4H4Ga-b8Q@mail.gmail.com>
Message-ID: <CAGgJW76nXLRGgCQwi4V18sHSEdfL44kwLhtgKHfYGFBE7mehDg@mail.gmail.com>

Try google'ing for 'variance of an AR(1) process'.
With the same seed, if you set n=1000000, you will get something that will
compare well with what you discover from your search.

On Tue, Nov 13, 2018 at 2:04 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear All,
>
> Here is a reprex:
>
> set.seed(123)
> b <- arima.sim(list(order = c(1,0,0),ar= .9),n=1000,sd=1)
> arima(b)
>
> Call:
> arima(x = b)
>
> Coefficients:
>       intercept
>          0.2250
> s.e.     0.0688
>
> sigma^2 estimated as 4.735:  log likelihood = -2196.4,  aic = 4396.81
> >
>
> Should sigma^2 not be equal to 1 ? Where do I misunderstand ?
>
> Many thanks,
> Ashim
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From S@Elli@on @ending from LGCGroup@com  Tue Nov 13 14:37:22 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Tue, 13 Nov 2018 13:37:22 +0000
Subject: [R] How to create gridded data
In-Reply-To: <CAN5afy9jzOCZDzvTuzXBzeTzi_aZLsnVnYM1VuBWe0e5ziUWsQ@mail.gmail.com>
References: <CAN5afy9jzOCZDzvTuzXBzeTzi_aZLsnVnYM1VuBWe0e5ziUWsQ@mail.gmail.com>
Message-ID: <54045019e3b24853970d2e20e9bd91d0@GBDCVPEXC04.corp.lgc-group.com>

You might take a look at the reshape package, which switches from 'long' to 'wide' formats and vice versa in a fairly flexible way.

S Ellison

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
> Sent: 13 November 2018 07:22
> To: R mailing list
> Subject: [R] How to create gridded data
> 
> Hi R users,
> 
> I have a question about manipulating data. For example, I have DF1 as the
> following, how to transform it to a gridded dataset DF2? In DF2, each value
> Precip is an attribute of the corresponding grid cell. So DF2 is like a
> spatial surface, and can be imported to ArcGIS. Thanks for your help.
> 
> DF1
> latitude   longitude   Precip
> 45.5           110.5         3.2
> 45.5           111            5.0
> 45.5           111.5         1.8
> 45.5           112            2.0
> 46              110.5         6.1
> 46              111            4.5
> 46              111.5         7.8
> 46              112            5.5
> ...
> 
> 
> DF2
> 6.1   4.5   7.8   5.5
> 3.2   5.0   1.8   2.0
> ...
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From @@r@h@go@lee @ending from gm@il@com  Tue Nov 13 15:16:26 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Tue, 13 Nov 2018 09:16:26 -0500
Subject: [R] How to create gridded data
In-Reply-To: <CAN5afy9jzOCZDzvTuzXBzeTzi_aZLsnVnYM1VuBWe0e5ziUWsQ@mail.gmail.com>
References: <CAN5afy9jzOCZDzvTuzXBzeTzi_aZLsnVnYM1VuBWe0e5ziUWsQ@mail.gmail.com>
Message-ID: <CAM_vjumM-nNbQBp-6vRbFKqWHpap9SQxwPBqsfkAs0+-XNj_tA@mail.gmail.com>

If you want an actual spatial dataset, the best place to ask is R-sig-geo

R has substantial capabilities for dealing with gridded spatial data,
including in the sp, raster, and sf packages.

Here's one approach, creating a SpatialGridDataFrame, which can be
exported in any standard raster format using the rgdal package.

DF2 <- DF1
coordinates(DF2) <- ~longitude + latitude
gridded(DF2) <- TRUE
fullgrid(DF2) <- TRUE

I recommend Roger Bivand's excellent book:
https://www.springer.com/us/book/9781461476177

and there are abundant web tutorials.

Sarah
On Tue, Nov 13, 2018 at 2:22 AM lily li <chocold12 at gmail.com> wrote:
>
> Hi R users,
>
> I have a question about manipulating data. For example, I have DF1 as the
> following, how to transform it to a gridded dataset DF2? In DF2, each value
> Precip is an attribute of the corresponding grid cell. So DF2 is like a
> spatial surface, and can be imported to ArcGIS. Thanks for your help.
>
> DF1
> latitude   longitude   Precip
> 45.5           110.5         3.2
> 45.5           111            5.0
> 45.5           111.5         1.8
> 45.5           112            2.0
> 46              110.5         6.1
> 46              111            4.5
> 46              111.5         7.8
> 46              112            5.5
> ...
>
>
> DF2
> 6.1   4.5   7.8   5.5
> 3.2   5.0   1.8   2.0
> ...
>


-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From dc@rl@on @ending from t@mu@edu  Tue Nov 13 15:56:02 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Tue, 13 Nov 2018 14:56:02 +0000
Subject: [R] How to create gridded data
In-Reply-To: <CAM_vjumM-nNbQBp-6vRbFKqWHpap9SQxwPBqsfkAs0+-XNj_tA@mail.gmail.com>
References: <CAN5afy9jzOCZDzvTuzXBzeTzi_aZLsnVnYM1VuBWe0e5ziUWsQ@mail.gmail.com>
 <CAM_vjumM-nNbQBp-6vRbFKqWHpap9SQxwPBqsfkAs0+-XNj_tA@mail.gmail.com>
Message-ID: <966004e209f949dba2ccf205bcef9983@tamu.edu>

Sarah's answer is probably better depending on what you want to do with the resulting data, but here's a way to go from your original DF1 to DF2:

> DF1 <- structure(list(latitude = c(45.5, 45.5, 45.5, 45.5, 46, 46, 46, 
+         46), longitude = c(110.5, 111, 111.5, 112, 110.5, 111, 111.5, 
+         112), Precip = c(3.2, 5, 1.8, 2, 6.1, 4.5, 7.8, 5.5)),
+         class = "data.frame", row.names = c(NA, -8L))
> 
# Convert to table with xtabs()
> DF2 <- xtabs(Precip~latitude+longitude, DF1)
> 

# Reverse the order of the latitudes
> DF2 <- DF2[rev(rownames(DF2)), ]
> DF2
        longitude
latitude 110.5 111 111.5 112
    46     6.1 4.5   7.8 5.5
    45.5   3.2 5.0   1.8 2.0

# Convert to a data frame
> DF2 <- as.data.frame.matrix(DF2)
> DF2
     110.5 111 111.5 112
46     6.1 4.5   7.8 5.5
45.5   3.2 5.0   1.8 2.0

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Sarah Goslee
Sent: Tuesday, November 13, 2018 8:16 AM
To: lily li <chocold12 at gmail.com>
Cc: r-help <r-help at r-project.org>
Subject: Re: [R] How to create gridded data

If you want an actual spatial dataset, the best place to ask is R-sig-geo

R has substantial capabilities for dealing with gridded spatial data,
including in the sp, raster, and sf packages.

Here's one approach, creating a SpatialGridDataFrame, which can be
exported in any standard raster format using the rgdal package.

DF2 <- DF1
coordinates(DF2) <- ~longitude + latitude
gridded(DF2) <- TRUE
fullgrid(DF2) <- TRUE

I recommend Roger Bivand's excellent book:
https://www.springer.com/us/book/9781461476177

and there are abundant web tutorials.

Sarah
On Tue, Nov 13, 2018 at 2:22 AM lily li <chocold12 at gmail.com> wrote:
>
> Hi R users,
>
> I have a question about manipulating data. For example, I have DF1 as the
> following, how to transform it to a gridded dataset DF2? In DF2, each value
> Precip is an attribute of the corresponding grid cell. So DF2 is like a
> spatial surface, and can be imported to ArcGIS. Thanks for your help.
>
> DF1
> latitude   longitude   Precip
> 45.5           110.5         3.2
> 45.5           111            5.0
> 45.5           111.5         1.8
> 45.5           112            2.0
> 46              110.5         6.1
> 46              111            4.5
> 46              111.5         7.8
> 46              112            5.5
> ...
>
>
> DF2
> 6.1   4.5   7.8   5.5
> 3.2   5.0   1.8   2.0
> ...
>


-- 
Sarah Goslee (she/her)
http://www.numberwright.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From p@uljohn32 @ending from gm@il@com  Tue Nov 13 16:19:11 2018
From: p@uljohn32 @ending from gm@il@com (Paul Johnson)
Date: Tue, 13 Nov 2018 09:19:11 -0600
Subject: [R] lm equivalent of Welch-corrected t-test?
Message-ID: <CAErODj_eXvaB-B7yU7BGAPPassNtLN0F6RLV8hCVpE+Fn_a3Bw@mail.gmail.com>

Long ago, when R's t.test had var.equal=TRUE by default, I wrote some
class notes showing that the result was equivalent to a one predictor
regression model.  Because t.test does not default to var.equal=TRUE
these days, I'm curious to know if there is a way to specify weights
in an lm to obtain the same result as the Welch-adjusted values
reported by t.test at the current time.  Is there a WLS equivalent
adjustment with lm?

Here's example code to show that lm is same as t.test with var.equal.
The signs come out differently, but otherwise the effect estimate,
standard error, t value are same:


set.seed(234234)
dat <- data.frame(x = gl(2, 50, labels = c("F", "M")))
dat$err <- rnorm(100, 0, 1)
dat$y <- ifelse(dat$x == "F", 40 + dat$err, 44 + dat$err)
m1 <- lm(y ~ x, dat)
summary(m1)
m1.t <- t.test(y ~ x, dat, var.equal = TRUE)
m1.t
## diff matches regression coefficient
(m1.t.effect <- diff(m1.t$estimate))
## standard error matches regression se
m1.t.stderr <- m1.t.effect/m1.t$statistic

If you run that, you see lm output:

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  39.9456     0.1180  338.65   <2e-16 ***
xM            3.9080     0.1668   23.43   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.8341 on 98 degrees of freedom
Multiple R-squared:  0.8485,    Adjusted R-squared:  0.8469
F-statistic: 548.8 on 1 and 98 DF,  p-value: < 2.2e-16

and t.test:

> m1.t <- t.test(y ~ x, dat, var.equal = TRUE)
> m1.t

    Two Sample t-test

data:  y by x
t = -23.427, df = 98, p-value < 2.2e-16
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -4.239038 -3.576968
sample estimates:
mean in group F mean in group M
       39.94558        43.85358

> (m1.t.effect <- diff(m1.t$estimate))
mean in group M
       3.908003
> m1.t.effect/m1.t$statistic
mean in group M
     -0.1668129




-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From g@briel@hoffm@n @ending from m@@m@edu  Tue Nov 13 16:30:49 2018
From: g@briel@hoffm@n @ending from m@@m@edu (Hoffman, Gabriel)
Date: Tue, 13 Nov 2018 15:30:49 +0000
Subject: [R] Unexpected failure of Cholesky docomposition
Message-ID: <D810585E.3112E%gabriel.hoffman@mssm.edu>

My understanding is that a Cholesky decomposition should work on any square, positive definite matrix.  I am encountering an issue where chol() fails and give the error: "the leading minor of order 3 is not positive definite"

This occurs on multiple machines and version of R.

Here is a minimal reproducible example:

# initialize matrix
values = c(1,0.725,0,0,0.725,1,0.692,0,0,0.692,1,0.644,0,0,0.664,1)
B = matrix(values, 4,4)

# show that singular values are positive
svd(B)$d

# show that matrix is symmetric
isSymmetric(B)

# B is symmetric positive definite, but Cholesky still fails
chol(B)

Is this a numerical stability issue?  How can I predict which matrices will fail?

- Gabriel






	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Tue Nov 13 16:44:42 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Tue, 13 Nov 2018 17:44:42 +0200
Subject: [R] Unexpected failure of Cholesky docomposition
In-Reply-To: <D810585E.3112E%gabriel.hoffman@mssm.edu>
References: <D810585E.3112E%gabriel.hoffman@mssm.edu>
Message-ID: <CAGgJW77Ahf4RW0AaP8++c7Qmm--DEAeLUgfam3p7ayzg258JrA@mail.gmail.com>

Eigen shows that the matrix is not positive definite (it has a negative
eigenvalue).
And isSymmetric() also shows it is not symmetric - compare (3,4) and (4,3)

On Tue, Nov 13, 2018 at 5:39 PM Hoffman, Gabriel <gabriel.hoffman at mssm.edu>
wrote:

> My understanding is that a Cholesky decomposition should work on any
> square, positive definite matrix.  I am encountering an issue where chol()
> fails and give the error: "the leading minor of order 3 is not positive
> definite"
>
> This occurs on multiple machines and version of R.
>
> Here is a minimal reproducible example:
>
> # initialize matrix
> values = c(1,0.725,0,0,0.725,1,0.692,0,0,0.692,1,0.644,0,0,0.664,1)
> B = matrix(values, 4,4)
>
> # show that singular values are positive
> svd(B)$d
>
> # show that matrix is symmetric
> isSymmetric(B)
>
> # B is symmetric positive definite, but Cholesky still fails
> chol(B)
>
> Is this a numerical stability issue?  How can I predict which matrices
> will fail?
>
> - Gabriel
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Tue Nov 13 16:48:51 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 13 Nov 2018 07:48:51 -0800
Subject: [R] Unexpected failure of Cholesky docomposition
In-Reply-To: <D810585E.3112E%gabriel.hoffman@mssm.edu>
References: <D810585E.3112E%gabriel.hoffman@mssm.edu>
Message-ID: <CAGxFJbT4BVkHzUAixMtVWq7N2pk2zWkQsJQw+oJ9a2UQib+atA@mail.gmail.com>

Your understanding is wrong. The eigenvalues, not singular values, must be
positive, and they are not.

Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Nov 13, 2018 at 7:39 AM Hoffman, Gabriel <gabriel.hoffman at mssm.edu>
wrote:

> My understanding is that a Cholesky decomposition should work on any
> square, positive definite matrix.  I am encountering an issue where chol()
> fails and give the error: "the leading minor of order 3 is not positive
> definite"
>
> This occurs on multiple machines and version of R.
>
> Here is a minimal reproducible example:
>
> # initialize matrix
> values = c(1,0.725,0,0,0.725,1,0.692,0,0,0.692,1,0.644,0,0,0.664,1)
> B = matrix(values, 4,4)
>
> # show that singular values are positive
> svd(B)$d
>
> # show that matrix is symmetric
> isSymmetric(B)
>
> # B is symmetric positive definite, but Cholesky still fails
> chol(B)
>
> Is this a numerical stability issue?  How can I predict which matrices
> will fail?
>
> - Gabriel
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From huert@y@ @ending from protonm@il@com  Tue Nov 13 17:20:58 2018
From: huert@y@ @ending from protonm@il@com (Yectli Huerta)
Date: Tue, 13 Nov 2018 16:20:58 +0000
Subject: [R] semiparametric manova
In-Reply-To: <c0c902f5fffa4c0b98f91f7a2df4366f@tamu.edu>
References: <nZHPMpPcaDAttf_2CeWpRPHXuE776jVeeFvfuY1JwxwK541qPyNp7_x9puqkxTSdlZ5WXuCQRniPzT87DKAvXHgWxTgQ_lMn8m6D8nqbckY=@protonmail.com>
 <2235fce5-c3fe-c595-84b8-21dc4d635213@comcast.net>
 <elvKFTZpJcbVW35mUngKukQFiT3bGLVBaiDaJ98ButrpofTPFq7jvWo8LUyxlSSBiktd9pYY3SofN3Oe0zxt3TU5tizUcgSj7t5zhy11hL4=@protonmail.com>
 <c0c902f5fffa4c0b98f91f7a2df4366f@tamu.edu>
Message-ID: <ZHJXteyKNIjyzRavIdXYhsalnrkZGVlhNYquTNkGE3C6QHdnpdZvwG4mVtS5Dk0AjUlcurxYwQyrVTJgRdFWr0uL-XWFRGL5_0-MOaRO38Y=@protonmail.com>




> > xtabs(~V1+V2+V3, df) # There are 9 cells with 0 entries. That is the problem.
> 

> , , V3 = 9
> 

> V2
> V1 8 16 24
> 200 5 0 5
> 350 5 5 0
> 500 0 5 5


thanks for the insight

yah
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 509 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20181113/9d3c7d87/attachment.sig>

From ferri@leberl @ending from gmx@@t  Tue Nov 13 18:02:29 2018
From: ferri@leberl @ending from gmx@@t (Ferri Leberl)
Date: Tue, 13 Nov 2018 18:02:29 +0100
Subject: [R] Interplay rnaturalearth, vwline
Message-ID: <trinity-1efa809e-9029-433f-bcc7-4100682acf08-1542128549299@3c-app-gmx-bs35>

Dear All,
There is something I don't understand fundamentally about handling geocoords with vwlines, as the axample below may illustrate.
vwlines seems to require values somewhere between 0 and 1 as shares of the plot length and width, but obviously that's not the complete story: Point (1,1) is slightly outside.
Which spacial framework does vwlines employ? 
How do I have to transform geoocoords to fit them into vwline?
Thank you in advance!
Yours, Ferri




library(rnaturalearth)
library(grid)
library(vwline)
# Install vwline via:
#library(devtools); install_github("pmur002/vwline/pkg at v0.1")
#mittex<--59.75#central meridian
#mittey<--62.316667#central latitude
mittex<--60.5617;mittey<--62.9832#Whalers Bay
#mittex<-120;mittey<-0#Sulawesi
band<-2#halve edge length of the depicted square, in degrees
map<-ne_countries(scale=10)#the source map
if(require(sp)){plot(map,ylim=c(mittey-band,mittey+band),xlim=c(mittex-band,mittex+band))}#plot the map
X<-c(-1,-1,-1,0,0,0,1,1,1)
Y<-c(-1,0,1,-1,0,1,-1,0,1)
points(mittex+X*band,mittey+Y*band,col="red")#The map does NOT end at xlim and ylim
grid.vwline(c(0,1),c(0,1),c(1/1000,1/1000))
grid.vwline(c(0,1),c(1,0),c(1/1000,1/1000))
#The vwlines miss the central dot; (1,1) is outside the plot


From wdunl@p @ending from tibco@com  Tue Nov 13 18:26:09 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Tue, 13 Nov 2018 09:26:09 -0800
Subject: [R] saveRDS() and readRDS() Why? [solved, pretty much anyway)
In-Reply-To: <3b49eb752bb2b108a72683df1d30f50b@slingshot.co.nz>
References: <20181107075621.GD8540@slingshot.co.nz>
 <20181108072724.GF8540@slingshot.co.nz>
 <23524.2724.270930.705139@stat.math.ethz.ch>
 <20181110074834.GG8540@slingshot.co.nz>
 <20181112072806.GH8540@slingshot.co.nz>
 <9795CBFC-5F8C-4084-9704-98614BA2A626@gmail.com>
 <46f6c0217cf594e544eef3257376d598@slingshot.co.nz>
 <CAF8bMcaejV7GdwwFFB7fro2AHD9FfqHJ2J26EZG56kyQ08UP=A@mail.gmail.com>
 <3b49eb752bb2b108a72683df1d30f50b@slingshot.co.nz>
Message-ID: <CAF8bMcYaXYB=PAZ9D2sDHqP1oH2To8u4A1EMrk0EGGdLdCMb=g@mail.gmail.com>

It seems like copying the files corrupted them. How did you copy them (with
R
or cp or copy or ftp, etc.)?  I don't see how this has anything to do with
R.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Nov 12, 2018 at 7:10 PM, p_connolly <p_connolly at slingshot.co.nz>
wrote:

> On 2018-11-13 12:55, William Dunlap wrote:
>
>> You wrote:
>>   ## On Windows 3.4.2
>>
>> x <- airquality
>>> saveRDS(x, file = "x.rds")
>>> saveRDS(x, file = "y.rds")
>>>
>>
>>   Files x.rds and y.rds are identical in size but utterly different in
>> content.
>>
>>  Wow!  Can you show us the results of
>>   x <- datasets::airquality
>>   saveRDS(x, file="x.rds")
>>   saveRDS(x, file="y.rds")
>>   tools::md5sum(c("x.rds", "y.rds"))
>>   dput(readBin("x.rds", what="raw", n=file.size("x.rds")))
>>   dput(readBin("y.rds", what="raw", n=file.size("y.rds")))
>>
>> (Copy and paste, as text, from the R session, so we can see the input
>> and the output in context.
>>
>
> If I do that on Linux or Windows, I get identical files.
>
> If I copy x.rds and y.rds from Windows to Linux (which is what I wish to
> be able to do) using a shared folder between the Windows VirtualBox host to
> the Linux guest, I  get this:
>
>
> x <- readRDS(file =  "x.rds")
>>
> Error in readRDS(file = "x.rds") : error reading from connection
>
>> x <- readRDS(file =  "y.rds")
>>   tools::md5sum(c("x.rds", "y.rds"))
>>
>                              x.rds                              y.rds
> "5fef054848f39b4be02b7c54f1c71a20" "978a64d1dd342d16a381c9ca728d3665"
>
>>   dput(readBin("x.rds", what="raw", n=file.size("x.rds")))
>>
> as.raw(c(0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x06, 0x03, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x00, 0x00))
>
>>   dput(readBin("y.rds", what="raw", n=file.size("y.rds")))
>>
> as.raw(c(0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
> 0x06, 0xe5, 0x97, 0x4b, 0x6c, 0x54, 0x55, 0x18, 0xc7, 0xcf, 0x9d,
> 0x0e, 0x7d, 0x41, 0x71, 0x2c, 0x15, 0xac, 0x65, 0xa0, 0x94, 0xa9,
> 0x80, 0x94, 0x52, 0xa1, 0x0b, 0xa9, 0x01, 0xa6, 0x58, 0xc4, 0xda,
> 0x76, 0x68, 0x99, 0x42, 0x0b, 0x2d, 0xe8, 0x08, 0x45, 0x4d, 0xca,
> 0x94, 0xb4, 0xc4, 0x07, 0x1b, 0x49, 0x5c, 0x10, 0x75, 0x65, 0xa2,
> 0x26, 0x35, 0x71, 0xad, 0x3b, 0x16, 0x2e, 0x4c, 0x7c, 0x6b, 0xc2,
> 0x82, 0xa8, 0x71, 0xa3, 0x71, 0x63, 0x7c, 0x2c, 0x74, 0x85, 0x2c,
> 0x8c, 0x0b, 0xa3, 0x40, 0xfd, 0x7f, 0xf7, 0xfc, 0xff, 0xed, 0xcd,
> 0x49, 0x59, 0xcf, 0xc2, 0x9b, 0xfc, 0xe6, 0xbb, 0xe7, 0x3b, 0xe7,
> 0x7c, 0xaf, 0x73, 0xee, 0xdc, 0x73, 0xc7, 0xeb, 0x9d, 0x73, 0x29,
> 0x57, 0x95, 0x4a, 0xbb, 0x54, 0x15, 0x6e, 0xab, 0xd6, 0xe0, 0xa7,
> 0x1a, 0x34, 0x80, 0x79, 0xb0, 0x0d, 0xe4, 0xc0, 0x2a, 0xd0, 0x78,
> 0xc9, 0xc5, 0xd7, 0x7a, 0xb0, 0x0e, 0xd8, 0xd8, 0x5a, 0xea, 0x6a,
> 0x40, 0x06, 0xac, 0x04, 0xab, 0x6d, 0x2c, 0x65, 0x1b, 0xed, 0x6d,
> 0x60, 0x5f, 0x44, 0x99, 0x06, 0xad, 0x36, 0x57, 0xd0, 0xe6, 0x0e,
> 0x30, 0x07, 0xda, 0x93, 0x7d, 0xc1, 0xb8, 0x2c, 0xe5, 0x21, 0xb0,
> 0x25, 0x39, 0x3f, 0x71, 0x7f, 0x8f, 0xd9, 0x00, 0x4d, 0x8c, 0xbd,
> 0xe1, 0x4e, 0xf6, 0x96, 0xb1, 0x7f, 0x19, 0x3c, 0xa8, 0xf8, 0x70,
> 0xe5, 0xc1, 0x56, 0x30, 0x04, 0x4a, 0xe4, 0x28, 0xfb, 0xac, 0x7e,
> 0x2d, 0x89, 0x1a, 0x74, 0x81, 0xcd, 0x60, 0x2f, 0x38, 0x0c, 0xf6,
> 0x5b, 0x5d, 0x12, 0xb6, 0x87, 0xc1, 0x34, 0xe3, 0xea, 0x06, 0x47,
> 0xc0, 0x2e, 0xfa, 0x78, 0xd8, 0xf2, 0x01, 0x75, 0xce, 0xd7, 0xb2,
> 0x40, 0x5b, 0x07, 0xc0, 0x45, 0x70, 0x1c, 0x94, 0x13, 0xb6, 0x3a,
> 0x9c, 0x5f, 0x8b, 0x5e, 0xb6, 0xd7, 0xd2, 0x86, 0xd5, 0x71, 0x23,
> 0xfb, 0xad, 0x0e, 0x75, 0xec, 0xb7, 0xda, 0xbe, 0x07, 0xfa, 0xd9,
> 0x1e, 0x04, 0xcf, 0x81, 0x51, 0xcb, 0x07, 0x3c, 0x49, 0x9f, 0xfd,
> 0x60, 0x02, 0xec, 0xb4, 0x1a, 0x30, 0xd6, 0x75, 0xb4, 0x75, 0x6f,
> 0xc2, 0xee, 0x7a, 0xc6, 0x6a, 0x7b, 0xa5, 0xd3, 0xf9, 0x35, 0x6f,
> 0xe0, 0x98, 0x0c, 0xef, 0x6d, 0x5e, 0x8e, 0xb5, 0xb1, 0xfd, 0xb0,
> 0x81, 0xbe, 0xb5, 0x47, 0x9a, 0xdc, 0xd2, 0x5e, 0xfb, 0x94, 0xf1,
> 0xbc, 0x89, 0x6d, 0xb2, 0x67, 0x29, 0xcf, 0x68, 0x3b, 0x7e, 0x4e,
> 0x3b, 0xbf, 0xdf, 0xbe, 0xa4, 0xce, 0xc0, 0xde, 0x8a, 0xcc, 0x46,
> 0x2f, 0x24, 0xe2, 0x8e, 0x76, 0xfb, 0xf8, 0xa3, 0x03, 0x8c, 0xb1,
> 0x16, 0xf7, 0x56, 0xd7, 0x66, 0x30, 0xe9, 0xeb, 0x18, 0xd5, 0xd3,
> 0xbf, 0xf9, 0xbc, 0x09, 0x7e, 0x86, 0x0e, 0x31, 0x46, 0xd8, 0x9f,
> 0x91, 0xd5, 0xec, 0x4f, 0xf0, 0x21, 0xf8, 0x11, 0x6d, 0xcc, 0x77,
> 0x2f, 0x41, 0xde, 0x0d, 0xb0, 0x0e, 0xd1, 0x23, 0xc0, 0x1e, 0x92,
> 0x7f, 0xc0, 0x1b, 0xb8, 0x1f, 0xa4, 0xaf, 0xcf, 0x20, 0xad, 0x16,
> 0xb6, 0xdf, 0x5e, 0x00, 0xaf, 0x80, 0xb7, 0xb8, 0x16, 0x13, 0x1c,
> 0x7f, 0xd9, 0xdb, 0x8a, 0x6b, 0xfa, 0x14, 0xd7, 0xe7, 0x55, 0xcc,
> 0xb3, 0x38, 0xfe, 0x06, 0xd7, 0xc1, 0x14, 0xb8, 0x02, 0x5d, 0x0f,
> 0x40, 0x5d, 0x22, 0x3c, 0x27, 0x51, 0xc6, 0xeb, 0xdc, 0x6b, 0x8c,
> 0xe7, 0x8a, 0x8f, 0xc5, 0xf6, 0x59, 0x94, 0xf6, 0xf9, 0x47, 0x59,
> 0xb4, 0x3f, 0xf2, 0x31, 0x5b, 0x9d, 0xa3, 0x14, 0xc0, 0x3e, 0x8a,
> 0xee, 0xf7, 0xf9, 0xb9, 0x11, 0xe7, 0xf7, 0xd9, 0xf7, 0xd0, 0x59,
> 0x0d, 0x6f, 0x81, 0xdb, 0xa0, 0xc8, 0xb5, 0x1a, 0x52, 0xad, 0x59,
> 0x9b, 0x05, 0xf0, 0x1b, 0xf8, 0x16, 0xfc, 0xc4, 0x7c, 0x3e, 0xf7,
> 0x75, 0x70, 0xef, 0x38, 0xbf, 0x57, 0xed, 0xd9, 0xb3, 0x7a, 0xdb,
> 0xb3, 0xfa, 0x97, 0x5f, 0xbb, 0xb8, 0x36, 0x39, 0xce, 0xff, 0x0e,
> 0xdc, 0x00, 0x3f, 0x70, 0x6d, 0xbf, 0x02, 0xbf, 0x82, 0x3f, 0xc0,
> 0xc7, 0xe0, 0x5d, 0x70, 0x15, 0x7c, 0x00, 0x3e, 0x01, 0x4f, 0x70,
> 0x8d, 0x6e, 0x32, 0x8f, 0xdf, 0x69, 0xef, 0x3a, 0xe5, 0x0d, 0xc6,
> 0x7a, 0x9e, 0x36, 0x7e, 0x01, 0x2d, 0xd4, 0x5f, 0xa3, 0x5c, 0xed,
> 0xeb, 0x14, 0x3f, 0xbb, 0xb6, 0xaf, 0xbe, 0x00, 0xaf, 0xfb, 0xf5,
> 0x71, 0x2f, 0xb3, 0x16, 0x36, 0x66, 0x3e, 0x9f, 0x9d, 0xb7, 0xeb,
> 0xed, 0x7c, 0xab, 0x4f, 0x38, 0xbf, 0x6d, 0x77, 0x7c, 0xe5, 0xb7,
> 0xb0, 0xdd, 0xc1, 0xfe, 0x1d, 0x5f, 0xdb, 0xf5, 0x4d, 0x7e, 0x13,
> 0xfb, 0xb7, 0x53, 0xdf, 0xdd, 0xec, 0xa5, 0xf4, 0x2d, 0xd4, 0x6f,
> 0x3e, 0x1b, 0x5f, 0xf9, 0x36, 0xca, 0x76, 0xce, 0x7f, 0x80, 0x6d,
> 0xd9, 0xdf, 0x4a, 0xb9, 0x2b, 0xd0, 0x6b, 0xbe, 0x64, 0x57, 0x60,
> 0x57, 0xf3, 0xba, 0x82, 0xf8, 0x5a, 0x03, 0xbb, 0xd2, 0xaf, 0xa5,
> 0x54, 0xbe, 0x8a, 0x77, 0xd1, 0x3e, 0xf3, 0x50, 0xbc, 0xea, 0xef,
> 0x08, 0xfc, 0x2a, 0x3f, 0xe5, 0xaf, 0x78, 0x95, 0x9f, 0xe6, 0x2b,
> 0x8e, 0x70, 0x9c, 0xe2, 0xe9, 0x7e, 0xdf, 0xdb, 0x6f, 0x0b, 0xf2,
> 0xce, 0x71, 0x7c, 0xb3, 0xf7, 0xbf, 0xff, 0x5f, 0xc6, 0xd1, 0xc8,
> 0x71, 0xd4, 0x2f, 0xda, 0x6f, 0x0d, 0xe6, 0x85, 0x7e, 0xd4, 0x9f,
> 0x09, 0xd6, 0x23, 0x5c, 0x97, 0xc6, 0xa0, 0xdd, 0x14, 0xf8, 0xbb,
> 0x53, 0xfd, 0xc2, 0xfd, 0x21, 0x29, 0xbd, 0xea, 0x15, 0xe4, 0xb5,
> 0x68, 0x5f, 0xf1, 0x86, 0xfb, 0x46, 0xfa, 0x4d, 0x41, 0xbe, 0x6a,
> 0x6b, 0x7d, 0x15, 0x4f, 0x28, 0x95, 0x5f, 0xb8, 0x5e, 0xd9, 0x20,
> 0x2e, 0xb5, 0x95, 0x7f, 0x26, 0xa8, 0x67, 0xe8, 0x57, 0x71, 0x85,
> 0x32, 0x8c, 0x3b, 0xcc, 0x57, 0x7e, 0x54, 0x5f, 0xf5, 0xef, 0x0c,
> 0x9e, 0x33, 0x3d, 0x7f, 0xb2, 0xb7, 0x32, 0xc8, 0x5f, 0xeb, 0xa0,
> 0xfe, 0x54, 0xb0, 0x4e, 0x92, 0xca, 0x4f, 0x75, 0xae, 0xa6, 0x54,
> 0x9e, 0xd9, 0xc0, 0x7f, 0x18, 0x57, 0x7b, 0xe0, 0x47, 0xeb, 0xaa,
> 0xf1, 0xf2, 0xa3, 0x71, 0xe1, 0x3a, 0xaa, 0xde, 0xb9, 0x40, 0x2a,
> 0x0f, 0xe5, 0xa9, 0x75, 0x0a, 0xc7, 0xe9, 0xb9, 0x96, 0x3d, 0xfd,
> 0x6f, 0x74, 0x04, 0x76, 0xe8, 0xd7, 0x2d, 0xbd, 0x3b, 0xf1, 0x6e,
> 0x72, 0x8f, 0x81, 0xc7, 0xc1, 0x3e, 0xf0, 0x90, 0xf3, 0xe7, 0x06,
> 0xbc, 0x1b, 0xe3, 0xf7, 0x90, 0x9d, 0x47, 0x0e, 0xb2, 0xff, 0x20,
> 0xfb, 0xfa, 0x40, 0x8f, 0xf3, 0xff, 0xe7, 0xd6, 0xde, 0x43, 0xdd,
> 0x3e, 0xce, 0xe9, 0xe7, 0xbc, 0xbd, 0xec, 0xeb, 0xa1, 0x34, 0x5f,
> 0xf6, 0x4e, 0xb1, 0xf3, 0x8d, 0x9d, 0x21, 0x0a, 0xb4, 0x6b, 0x7a,
> 0x9d, 0x25, 0xac, 0xcf, 0xde, 0x39, 0x63, 0xe0, 0x04, 0xe5, 0x49,
> 0xe7, 0xff, 0xe3, 0x4d, 0x3f, 0xcc, 0x31, 0x43, 0x8c, 0xbb, 0x97,
> 0xfe, 0x06, 0xa9, 0x1b, 0x4c, 0x30, 0xe0, 0x96, 0xce, 0x25, 0xc3,
> 0xec, 0x2f, 0x26, 0x7c, 0x8d, 0xf0, 0xbe, 0x48, 0xc6, 0xe9, 0xc7,
> 0x38, 0x4e, 0x7f, 0xfd, 0x1c, 0x37, 0x41, 0x1b, 0x7a, 0x27, 0x8e,
> 0x32, 0xb6, 0xa3, 0xcc, 0x41, 0xfa, 0x63, 0xd4, 0xe9, 0x7e, 0x9c,
> 0xb2, 0xc8, 0x31, 0x23, 0xcb, 0x8c, 0x1d, 0xa3, 0xbf, 0x13, 0x64,
> 0x92, 0x7d, 0xc7, 0x96, 0xc9, 0x39, 0x59, 0xbb, 0x42, 0xa2, 0x0e,
> 0x03, 0xec, 0x1b, 0x49, 0xf8, 0xb5, 0xf3, 0xe6, 0x29, 0xe7, 0xcf,
> 0x67, 0xa7, 0x98, 0xc3, 0x24, 0xeb, 0x79, 0x92, 0x7e, 0x47, 0x69,
> 0xbf, 0x40, 0x1b, 0xca, 0x57, 0xf5, 0x3c, 0x44, 0x0a, 0x5c, 0x27,
> 0xd3, 0xf7, 0x31, 0xae, 0x3c, 0xfb, 0x6c, 0xbc, 0xed, 0x0d, 0x3b,
> 0xb3, 0x3e, 0xca, 0x79, 0x03, 0x89, 0xb1, 0xda, 0x6b, 0x2b, 0x2a,
> 0x48, 0x75, 0x85, 0xa8, 0xa9, 0x20, 0xb5, 0x15, 0xa4, 0xae, 0x42,
> 0x68, 0xaf, 0xd9, 0x41, 0x1f, 0xe7, 0x59, 0x67, 0x67, 0x40, 0xfb,
> 0x66, 0xd4, 0x1e, 0x50, 0x5d, 0x6c, 0xac, 0x7d, 0x83, 0xd9, 0x37,
> 0xe5, 0x2a, 0xce, 0xb3, 0x33, 0xde, 0x5d, 0xce, 0x7f, 0x83, 0xd8,
> 0x99, 0xd5, 0xbe, 0x11, 0xec, 0xdc, 0x6b, 0x67, 0x42, 0xfb, 0x6e,
> 0xb1, 0xef, 0x24, 0xfb, 0x2e, 0xb1, 0xf3, 0xa4, 0x7d, 0x1b, 0xdc,
> 0xe7, 0xfc, 0x59, 0xd2, 0xce, 0xf0, 0x76, 0x96, 0xb6, 0x6f, 0xd5,
> 0x8d, 0x15, 0xf4, 0xfd, 0x7f, 0xcc, 0xb9, 0x82, 0xbe, 0xd3, 0xa9,
> 0xd8, 0x77, 0x3a, 0xb6, 0xbf, 0xa2, 0x5c, 0x3a, 0x37, 0x35, 0x47,
> 0x83, 0xd5, 0x52, 0x1e, 0xbe, 0x38, 0x53, 0x9e, 0x62, 0xa3, 0xa6,
> 0x38, 0x33, 0x5d, 0x9a, 0xed, 0x3c, 0xc2, 0x66, 0x7a, 0xec, 0xd9,
> 0xf2, 0x19, 0xdd, 0x8f, 0x4e, 0x9d, 0x3b, 0xaf, 0x39, 0x43, 0x33,
> 0xe5, 0x0b, 0xcf, 0xb0, 0x51, 0xd5, 0x57, 0x7a, 0x31, 0x74, 0x74,
> 0x7a, 0xba, 0x34, 0x27, 0x47, 0x52, 0xd6, 0x9f, 0x29, 0x5d, 0x28,
> 0x75, 0x9e, 0x9d, 0x45, 0x0c, 0xc1, 0xf0, 0xba, 0xd9, 0x99, 0xe7,
> 0x3b, 0x15, 0x9b, 0x25, 0x9e, 0xba, 0x84, 0x9f, 0x85, 0x85, 0x85,
> 0xa7, 0x21, 0x6e, 0xff, 0x07, 0x03, 0xf3, 0xcf, 0x7e, 0xc7, 0x11,
> 0x00, 0x00))
>
>>
>>
> The issue is evidently with the shared folder. I've been doing that
> (sharing the folder) for years and never encountered a problem.
>
>
>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com [1]
>>
>> On Mon, Nov 12, 2018 at 12:42 PM, p_connolly
>> <p_connolly at slingshot.co.nz> wrote:
>>
>> On 2018-11-12 22:49, peter dalgaard wrote:
>>> Er, where, what, how? I can't reproduce that, at least not on 3.5.1
>>> on MacOS:
>>>
>>> x <- airquality
>>> saveRDS(x, file = "x.rds")
>>> x <- NULL
>>> x <- readRDS(file = "x.rds")
>>> x
>>> Ozone Solar.R Wind Temp Month Day
>>> 1      41     190  7.4   67     5   1
>>> 2      36     118  8.0   72     5   2
>>> 3      12     149 12.6   74     5   3
>>> ...
>>>
>>> Looks fine to me.
>>>
>>
>> It seems to work fine using the same installation to read as used for
>> the save.
>> But it's a different story if the save was done on a Windows
>> installation and read on a Linux installation.
>>
>> ## On Windows 3.4.2
>>
>> x <- airquality
>>> saveRDS(x, file = "x.rds")
>>> saveRDS(x, file = "y.rds")
>>>
>>
>> Files x.rds and y.rds are identical in size but utterly different in
>> content.
>>
>> ## On Linux 3.5.1
>>
>> x <- readRDS(file =  "x.rds")
>>>
>>  Error in readRDS(file = "x.rds") : error reading from connection
>>
>> x <- readRDS(file =  "y.rds")
>>> head(x)
>>>
>>    Ozone Solar.R Wind Temp Month Day
>> 1    41     190  7.4   67     5   1
>> 2    36     118  8.0   72     5   2
>> 3    12     149 12.6   74     5   3
>> 4    18     313 11.5   62     5   4
>> 5    NA      NA 14.3   56     5   5
>> 6    28      NA 14.9   66     5   6
>>
>> It might just be the age of the Windows installation.  I don't have
>> much use for Windows, so I haven't had much inclination to install a
>> newer version.
>>
>> YMMV
>>
>> ?
>>> -pd
>>>
>>> On 12 Nov 2018, at 08:28 , Patrick Connolly
>>>> <p_connolly at slingshot.co.nz> wrote:
>>>>
>>>> The solution was very simple.  Don't use the same name for the rds
>>>> file  as used for the R object, viz a vie:
>>>>
>>>> saveRDS(x, file = "x.rds")
>>>> and
>>>> x <- readRDS(file = "x.rds")
>>>>
>>>> will not work; however
>>>>
>>>> saveRDS(x, file = "y.rds")
>>>> and
>>>> x <- readRDS(file = "y.rds")
>>>> will work.
>>>>
>>>> An undocumented feature?
>>>>
>>>> Thanks to all who contributed.
>>>>
>>>
>>> --
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Office: A 4.23
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help [2]
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html [3]
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> Links:
>> ------
>> [1] http://tibco.com
>> [2] https://stat.ethz.ch/mailman/listinfo/r-help
>> [3] http://www.R-project.org/posting-guide.html
>>
>

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Tue Nov 13 18:31:47 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Tue, 13 Nov 2018 09:31:47 -0800
Subject: [R] Unexpected failure of Cholesky docomposition
In-Reply-To: <D810585E.3112E%gabriel.hoffman@mssm.edu>
References: <D810585E.3112E%gabriel.hoffman@mssm.edu>
Message-ID: <CAF8bMcaYNFdt3+-e-izhmDzdDxD=OUWuoi1dDmsJfQVe9V_9Vg@mail.gmail.com>

Aren't singular values always positive or zero?  Look at eigen(B)$values to
check for positive definiteness.

Fix your example - your B is not symmetric.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Nov 13, 2018 at 7:30 AM, Hoffman, Gabriel <gabriel.hoffman at mssm.edu>
wrote:

> My understanding is that a Cholesky decomposition should work on any
> square, positive definite matrix.  I am encountering an issue where chol()
> fails and give the error: "the leading minor of order 3 is not positive
> definite"
>
> This occurs on multiple machines and version of R.
>
> Here is a minimal reproducible example:
>
> # initialize matrix
> values = c(1,0.725,0,0,0.725,1,0.692,0,0,0.692,1,0.644,0,0,0.664,1)
> B = matrix(values, 4,4)
>
> # show that singular values are positive
> svd(B)$d
>
> # show that matrix is symmetric
> isSymmetric(B)
>
> # B is symmetric positive definite, but Cholesky still fails
> chol(B)
>
> Is this a numerical stability issue?  How can I predict which matrices
> will fail?
>
> - Gabriel
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Tue Nov 13 18:36:52 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Tue, 13 Nov 2018 09:36:52 -0800
Subject: [R] Output of arima
In-Reply-To: <CAC8=1ervy1GgrW17FrzwOnYgEQJbiE16uiYH_DoCP4H4Ga-b8Q@mail.gmail.com>
References: <CAC8=1ervy1GgrW17FrzwOnYgEQJbiE16uiYH_DoCP4H4Ga-b8Q@mail.gmail.com>
Message-ID: <CAF8bMcY7z_44w3Ja2a__jZnSqDqYqnFYLXygvVG03RFTjjicwA@mail.gmail.com>

Try supplying the order argument to arima.  It looks like the default is to
estimate only the mean.

> arima(b, order=c(1,0,0))

Call:
arima(x = b, order = c(1, 0, 0))

Coefficients:
         ar1  intercept
      0.8871     0.2369
s.e.  0.0145     0.2783

sigma^2 estimated as 1.002:  log likelihood = -1420.82,  aic = 2847.63


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Nov 13, 2018 at 4:02 AM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear All,
>
> Here is a reprex:
>
> set.seed(123)
> b <- arima.sim(list(order = c(1,0,0),ar= .9),n=1000,sd=1)
> arima(b)
>
> Call:
> arima(x = b)
>
> Coefficients:
>       intercept
>          0.2250
> s.e.     0.0688
>
> sigma^2 estimated as 4.735:  log likelihood = -2196.4,  aic = 4396.81
> >
>
> Should sigma^2 not be equal to 1 ? Where do I misunderstand ?
>
> Many thanks,
> Ashim
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From g@briel@hoffm@n @ending from m@@m@edu  Tue Nov 13 18:41:32 2018
From: g@briel@hoffm@n @ending from m@@m@edu (Hoffman, Gabriel)
Date: Tue, 13 Nov 2018 17:41:32 +0000
Subject: [R] Unexpected failure of Cholesky docomposition
In-Reply-To: <CAF8bMcaYNFdt3+-e-izhmDzdDxD=OUWuoi1dDmsJfQVe9V_9Vg@mail.gmail.com>
References: <D810585E.3112E%gabriel.hoffman@mssm.edu>
 <CAF8bMcaYNFdt3+-e-izhmDzdDxD=OUWuoi1dDmsJfQVe9V_9Vg@mail.gmail.com>
Message-ID: <D81076EF.3113C%gabriel.hoffman@mssm.edu>

There was a typo in my example.  Here is the fixed version:

# initialize matrix
values = c(1,0.725,0,0,0.725,1,0.692,0,0,0.692,1,0.664,0,0,0.664,1)
B = matrix(values, 4,4)

# show that singular values are positive
svd(B)$d

# show that matrix is symmetric
isSymmetric(B)

# B is symmetric positive definite, but Cholesky still fails
chol(B)


# It turns out the the *eigen* values are mixed sign.
# That explains the issue
eigen(B)$values

Thanks for you help, especially Bert.

- Gabriel


From: William Dunlap <wdunlap at tibco.com<mailto:wdunlap at tibco.com>>
Date: Tuesday, November 13, 2018 at 12:31 PM
To: Gabriel Hoffman <gabriel.hoffman at mssm.edu<mailto:gabriel.hoffman at mssm.edu>>
Cc: "r-help at r-project.org<mailto:r-help at r-project.org>" <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] Unexpected failure of Cholesky docomposition

Aren't singular values always positive or zero?  Look at eigen(B)$values to check for positive definiteness.

Fix your example - your B is not symmetric.

Bill Dunlap
TIBCO Software
wdunlap tibco.com<https://urldefense.proofpoint.com/v2/url?u=http-3A__tibco.com&d=DwMFaQ&c=shNJtf5dKgNcPZ6Yh64b-A&r=KdYcmw5SdXylMrTGSuNVkNJulowod64k0PTDC5BHZkk&m=Vq3YaG1EYDN2Fp8XpmcP8kVgEmHvlDEIwLveBpn4R4Q&s=1NN3MX73Jjmlphkfkm-NlTB-XWOrrMMN3zOGzX3y0RE&e=>

On Tue, Nov 13, 2018 at 7:30 AM, Hoffman, Gabriel <gabriel.hoffman at mssm.edu<mailto:gabriel.hoffman at mssm.edu>> wrote:
My understanding is that a Cholesky decomposition should work on any square, positive definite matrix.  I am encountering an issue where chol() fails and give the error: "the leading minor of order 3 is not positive definite"

This occurs on multiple machines and version of R.

Here is a minimal reproducible example:

# initialize matrix
values = c(1,0.725,0,0,0.725,1,0.692,0,0,0.692,1,0.644,0,0,0.664,1)
B = matrix(values, 4,4)

# show that singular values are positive
svd(B)$d

# show that matrix is symmetric
isSymmetric(B)

# B is symmetric positive definite, but Cholesky still fails
chol(B)

Is this a numerical stability issue?  How can I predict which matrices will fail?

- Gabriel






        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwMFaQ&c=shNJtf5dKgNcPZ6Yh64b-A&r=KdYcmw5SdXylMrTGSuNVkNJulowod64k0PTDC5BHZkk&m=Vq3YaG1EYDN2Fp8XpmcP8kVgEmHvlDEIwLveBpn4R4Q&s=NwgJPwLPzWkHUywq-roE7bv0dcwMA2p5a3-ON2AbycQ&e=>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwMFaQ&c=shNJtf5dKgNcPZ6Yh64b-A&r=KdYcmw5SdXylMrTGSuNVkNJulowod64k0PTDC5BHZkk&m=Vq3YaG1EYDN2Fp8XpmcP8kVgEmHvlDEIwLveBpn4R4Q&s=6s9m-E3Y4eRcJL-jWgz1Pbf4nQED9bgK0CB3r3KAhp8&e=>
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Tue Nov 13 18:58:37 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Tue, 13 Nov 2018 09:58:37 -0800
Subject: [R] which element is duplicated?
In-Reply-To: <728b3945-333c-36f7-d385-480c5cdb8926@gmail.com>
References: <9f0b4102-53fd-c751-09b2-92d9c78a5ec4@gmail.com>
 <83a637dc-2605-fa4f-6a3a-8949f85e2122@fredhutch.org>
 <728b3945-333c-36f7-d385-480c5cdb8926@gmail.com>
Message-ID: <CAF8bMcYfvR74f1mgC57gVc7Yn2vp6axTmVBLqKVNLGghqy=3qQ@mail.gmail.com>

You also asked about doing this for the rows of a matrix.  unique() give
the unique rows but match operates on a per element, not per row,
basis.  You can use split, which operates on rows of a matrix, to help.

> m <- cbind( A=c(i=5,ii=5,iii=5,iv=4,v=4,vi=4), B=c(2,3,2,2,2,2) )
> unique(m)
   A B
i  5 2
ii 5 3
iv 4 2
> match(m, unique(m)) # bad
 [1] 1 1 1 3 3 3 4 5 4 4 4 4
> asRows <- function(x) split(x, seq_len(NROW(x))) # convert to list of rows
> match(asRows(m), unique(asRows(m)))
[1] 1 2 1 3 3 3


For data.frames unique works on rows but match works on columns, and
converting
to a list of rows does not quite work, because unique looks at the row
names.  A
modification of asRoiws works around that:

> d <- data.frame(m)
> unique(d)
   A B
i  5 2
ii 5 3
iv 4 2
> match(d, unique(d))
[1] NA NA
> asRows <- function(x) lapply(split(x, seq_len(NROW(x))), as.list)
> match(asRows(d), unique(asRows(d)))
[1] 1 2 1 3 3 3


Is this the sort of issue that Hadley's vectors package is addressing?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Nov 13, 2018 at 2:15 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 13/11/2018 12:35 AM, Pages, Herve wrote:
>
>> Hi,
>>
>> On 11/12/18 17:08, Duncan Murdoch wrote:
>>
>>> The duplicated() function gives TRUE if an item in a vector (or row in
>>> a matrix, etc.) is a duplicate of an earlier item.  But what I would
>>> like to know is which item does it duplicate?
>>>
>>> For example,
>>>
>>> v <- c("a", "b", "b", "a")
>>> duplicated(v)
>>>
>>> returns
>>>
>>> [1] FALSE FALSE  TRUE  TRUE
>>>
>>> What I want is a fast way to calculate
>>>
>>>   [1] NA NA 2 1
>>>
>>> or (equally useful to me)
>>>
>>>   [1] 1 2 2 1
>>>
>>> The result should have the property that if result[i] == j, then v[i]
>>> == v[j], at least for i != j.
>>>
>>> Does this already exist somewhere, or is it easy to write?
>>>
>>
>> I generally use match() for that:
>>
>>   > v <- c("a", "b", "b", "a")
>>
>>   > match(v, v)
>>
>> [1] 1 2 2 1
>>
>
> Yes, this is perfect.  Thanks to you (and the private answer I received
> that suggested the same).
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@@@@ko@@nic @ending from gm@il@com  Tue Nov 13 10:51:22 2018
From: @@@@@ko@@nic @ending from gm@il@com (sasa kosanic)
Date: Tue, 13 Nov 2018 10:51:22 +0100
Subject: [R] Help with Centroids
Message-ID: <CAJanvzEnCFKU3B7P_F7eZocLc1G+eBCd1Ev9595QW81Hqk0kmg@mail.gmail.com>

Dear All,

I am pretty new to R and  would appreciate a help how to calculate
centroids  from  the latitude and longitude of existing cells (e.g.  to get
centroid for a new cell I would need to combine  latitude and
9161,9162,9163,9164 to  9160  or 10152, 10154 to 10150 etc.)
Please see attached table.

Thank you very much!

Best,
Sasha


-- 

Dr Sasha Kosanic
Ecology Lab (Biology Department)
Room M644
University of Konstanz
Universit?tsstra?e 10
D-78464 Konstanz
Phone: +49 7531 883321

http://cms.uni-konstanz.de/vkleunen/
https://tinyurl.com/y8u5wyoj
https://tinyurl.com/cgec6tu

From g@@@burger @ending from l@cdr@leidenuniv@nl  Tue Nov 13 18:24:32 2018
From: g@@@burger @ending from l@cdr@leidenuniv@nl (Gerhard Burger)
Date: Tue, 13 Nov 2018 18:24:32 +0100
Subject: [R] Using lm on data.frame with categorical data as character
 column results in error in plot.lm
Message-ID: <CA+4YCLeN9msAQ3CrU3-F6wPUNOfkgUnTuKmHkraTZxnns+=YRg@mail.gmail.com>

Hi all,

Not sure if the following could be considered a bug, or just a user error
but here goes:

We're teaching our students to use the tidyverse for most of their R stuff
and the following gives problems (code adapted/shortened to pinpoint
problem):

```
iris_long = tidyr::gather(iris, key ="variable", value = "value", -Species)
iris_lm = lm( value ~ Species + variable, data = iris_long)
stats:::plot.lm(iris_lm, which = 5)
```

whereas, if we use reshape::melt instead of tidyr::gather it works fine:

```
iris_long = reshape2::melt(iris)
iris_lm = lm( value ~ Species + variable, data = iris_long)
stats:::plot.lm(iris_lm, which = 5)
```

Now the only difference between the output from melt and gather is that the
resulting "variable" column is a factor column in melt, but a character
column in gather:

```
testthat::expect_identical(reshape2::melt(iris), tidyr::gather(iris, key
="variable", value = "value", -Species))
```

This can be fixed by adding `factor_key = T` to the gather call, after
which everything works fine. Are categorical variables required to be in a
factor column? Because `lm` seems to handle it fine, but `plot.lm` gives
problems... Is this something that might need a fix in plot.lm?

Any insight appreciated!

Kind regards,
Gerhard

For completeness, my sessionInfo:

```
R version 3.5.1 (2018-07-02)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 18.04.1 LTS

Matrix products: default
BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
LC_TIME=nl_NL.UTF-8        LC_COLLATE=en_US.UTF-8
LC_MONETARY=nl_NL.UTF-8
 [6] LC_MESSAGES=en_US.UTF-8    LC_PAPER=nl_NL.UTF-8       LC_NAME=C
           LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=nl_NL.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.18     tidyr_0.8.1      crayon_1.3.4     R6_2.2.2
plyr_1.8.4       magrittr_1.5     pillar_1.3.0     rlang_0.2.2
 [9] stringi_1.2.4    reshape2_1.4.3   rstudioapi_0.7   testthat_2.0.0
tools_3.5.1      stringr_1.3.1    glue_1.3.0       purrr_0.2.5
[17] compiler_3.5.1   tidyselect_0.2.4 tibble_1.4.2
```

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Tue Nov 13 21:25:06 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Tue, 13 Nov 2018 15:25:06 -0500
Subject: [R] which element is duplicated?
In-Reply-To: <CAF8bMcYfvR74f1mgC57gVc7Yn2vp6axTmVBLqKVNLGghqy=3qQ@mail.gmail.com>
References: <9f0b4102-53fd-c751-09b2-92d9c78a5ec4@gmail.com>
 <83a637dc-2605-fa4f-6a3a-8949f85e2122@fredhutch.org>
 <728b3945-333c-36f7-d385-480c5cdb8926@gmail.com>
 <CAF8bMcYfvR74f1mgC57gVc7Yn2vp6axTmVBLqKVNLGghqy=3qQ@mail.gmail.com>
Message-ID: <7d8696f6-b737-875a-d448-a148c6dde908@gmail.com>

On 13/11/2018 12:58 PM, William Dunlap wrote:
> You also asked about doing this for the rows of a matrix.? unique() give
> the unique rows but match operates on a per element, not per row,
> basis.? You can use split, which operates on rows of a matrix, to help.
> 
>      > m <- cbind( A=c(i=5,ii=5,iii=5,iv=4,v=4,vi=4), B=c(2,3,2,2,2,2) )
>      > unique(m)
>      ? ?A B
>     i? 5 2
>     ii 5 3
>     iv 4 2
>      > match(m, unique(m)) # bad
>      ?[1] 1 1 1 3 3 3 4 5 4 4 4 4
>      > asRows <- function(x) split(x, seq_len(NROW(x))) # convert to
>     list of rows
>      > match(asRows(m), unique(asRows(m)))
>     [1] 1 2 1 3 3 3
> 
> 
> For data.frames unique works on rows but match works on columns, and 
> converting
> to a list of rows does not quite work, because unique looks at the row 
> names.? A
> modification of asRoiws works around that:
> 
>      > d <- data.frame(m)
>      > unique(d)
>      ? ?A B
>     i? 5 2
>     ii 5 3
>     iv 4 2
>      > match(d, unique(d))
>     [1] NA NA
>      > asRows <- function(x) lapply(split(x, seq_len(NROW(x))), as.list)
>      > match(asRows(d), unique(asRows(d)))
>     [1] 1 2 1 3 3 3
> 

Thanks!  That's very nice.

> 
> Is this the sort of issue that Hadley's vectors package is addressing?
I don't know; hopefully someone else will respond...

Duncan Murdoch

> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
> 
> On Tue, Nov 13, 2018 at 2:15 AM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 13/11/2018 12:35 AM, Pages, Herve wrote:
> 
>         Hi,
> 
>         On 11/12/18 17:08, Duncan Murdoch wrote:
> 
>             The duplicated() function gives TRUE if an item in a vector
>             (or row in
>             a matrix, etc.) is a duplicate of an earlier item.? But what
>             I would
>             like to know is which item does it duplicate?
> 
>             For example,
> 
>             v <- c("a", "b", "b", "a")
>             duplicated(v)
> 
>             returns
> 
>             [1] FALSE FALSE? TRUE? TRUE
> 
>             What I want is a fast way to calculate
> 
>              ??[1] NA NA 2 1
> 
>             or (equally useful to me)
> 
>              ??[1] 1 2 2 1
> 
>             The result should have the property that if result[i] == j,
>             then v[i]
>             == v[j], at least for i != j.
> 
>             Does this already exist somewhere, or is it easy to write?
> 
> 
>         I generally use match() for that:
> 
>          ? > v <- c("a", "b", "b", "a")
> 
>          ? > match(v, v)
> 
>         [1] 1 2 2 1
> 
> 
>     Yes, this is perfect.? Thanks to you (and the private answer I
>     received that suggested the same).
> 
>     Duncan Murdoch
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
> 
>


From p@ul @ending from @t@t@@uckl@nd@@c@nz  Tue Nov 13 23:03:10 2018
From: p@ul @ending from @t@t@@uckl@nd@@c@nz (Paul Murrell)
Date: Wed, 14 Nov 2018 11:03:10 +1300
Subject: [R] Interplay rnaturalearth, vwline
In-Reply-To: <trinity-1efa809e-9029-433f-bcc7-4100682acf08-1542128549299@3c-app-gmx-bs35>
References: <trinity-1efa809e-9029-433f-bcc7-4100682acf08-1542128549299@3c-app-gmx-bs35>
Message-ID: <db7af9c7-bb4b-6010-7f86-974f1bc13c06@stat.auckland.ac.nz>



There are a couple of important concepts in play here:

1.
You are drawing the map with the 'graphics' system, but 'vwline' works 
in the 'grid' system.

2.
In the 'grid' system, you can work with lots of different coordinate 
systems.  The default is usually "npc" (which is 0 to 1), but you can 
choose to use others, for example, "native" draws relative to scales on 
the axes (roughly speaking).

If you change the last two lines of your example to the following, it 
might look more like what you expect (?) ...

## Convert the 'graphics' map to a 'grid' equivalent
library(gridGraphics)
grid.echo()
## Navigate to the 'grid' viewport that corresponds to the map
## region
downViewport("graphics-plot-1")
## Draw lines between the corners of the map region
grid.vwline(c(0,1), c(0,1), c(1/1000,1/1000))
grid.vwline(c(0,1), c(1,0), c(1/1000,1/1000))

The next code provides an example of drawing relative to the map 
coordinates (NOTE the use of "native" units) ...

## Navigate to the 'grid' viewport that corresponds to the map
## coordinate system
downViewport("graphics-window-1-1")
## Draw lines relative to the map coordinate system
grid.vwline(mittex + X*band, mittey + Y*band, default.units="native",
             unit(1:9, "mm"), gp=gpar(fill=rgb(1,0,0,.2)))


Hope that helps

Paul


On 14/11/18 6:02 AM, Ferri Leberl wrote:
> Dear All,
> There is something I don't understand fundamentally about handling geocoords with vwlines, as the axample below may illustrate.
> vwlines seems to require values somewhere between 0 and 1 as shares of the plot length and width, but obviously that's not the complete story: Point (1,1) is slightly outside.
> Which spacial framework does vwlines employ?
> How do I have to transform geoocoords to fit them into vwline?
> Thank you in advance!
> Yours, Ferri
> 
> 
> 
> 
> library(rnaturalearth)
> library(grid)
> library(vwline)
> # Install vwline via:
> #library(devtools); install_github("pmur002/vwline/pkg at v0.1")
> #mittex<--59.75#central meridian
> #mittey<--62.316667#central latitude
> mittex<--60.5617;mittey<--62.9832#Whalers Bay
> #mittex<-120;mittey<-0#Sulawesi
> band<-2#halve edge length of the depicted square, in degrees
> map<-ne_countries(scale=10)#the source map
> if(require(sp)){plot(map,ylim=c(mittey-band,mittey+band),xlim=c(mittex-band,mittex+band))}#plot the map
> X<-c(-1,-1,-1,0,0,0,1,1,1)
> Y<-c(-1,0,1,-1,0,1,-1,0,1)
> points(mittex+X*band,mittey+Y*band,col="red")#The map does NOT end at xlim and ylim
> grid.vwline(c(0,1),c(0,1),c(1/1000,1/1000))
> grid.vwline(c(0,1),c(1,0),c(1/1000,1/1000))
> #The vwlines miss the central dot; (1,1) is outside the plot
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From p_connolly @ending from @ling@hot@co@nz  Tue Nov 13 23:10:11 2018
From: p_connolly @ending from @ling@hot@co@nz (p_connolly)
Date: Wed, 14 Nov 2018 11:10:11 +1300
Subject: [R] saveRDS() and readRDS() Why? [solved, pretty much anyway)
In-Reply-To: <CAF8bMcYaXYB=PAZ9D2sDHqP1oH2To8u4A1EMrk0EGGdLdCMb=g@mail.gmail.com>
References: <20181107075621.GD8540@slingshot.co.nz>
 <20181108072724.GF8540@slingshot.co.nz>
 <23524.2724.270930.705139@stat.math.ethz.ch>
 <20181110074834.GG8540@slingshot.co.nz>
 <20181112072806.GH8540@slingshot.co.nz>
 <9795CBFC-5F8C-4084-9704-98614BA2A626@gmail.com>
 <46f6c0217cf594e544eef3257376d598@slingshot.co.nz>
 <CAF8bMcaejV7GdwwFFB7fro2AHD9FfqHJ2J26EZG56kyQ08UP=A@mail.gmail.com>
 <3b49eb752bb2b108a72683df1d30f50b@slingshot.co.nz>
 <CAF8bMcYaXYB=PAZ9D2sDHqP1oH2To8u4A1EMrk0EGGdLdCMb=g@mail.gmail.com>
Message-ID: <d036a9b8893a1ade51c78e7325d8c89b@slingshot.co.nz>

This is getting more strange.

I normally copy from the shared folder to the appropriate directory 
using Dolphin, the KDE file manager.  If instead I use the standard bash 
cp command, no corruption happens -- at least with the limited testing I 
have done.  There also seems to be no problem copying from Linux to 
Windows.  I installed R-3.5.1 for Windows just to eliminate that 
possible issue.

However, R has *something* to do with it because it was used to make the 
.rds file.  Just how the relationship between the name of the R object 
and the name of the .rds file comes into it, I can't imagine.

Thanks for the suggestion William.


On 2018-11-14 06:26, William Dunlap wrote:
> It seems like copying the files corrupted them. How did you copy them
> (with R
> or cp or copy or ftp, etc.)?  I don't see how this has anything to do
> with R.
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com [1]
> On Mon, Nov 12, 2018 at 7:10 PM, p_connolly
> <p_connolly at slingshot.co.nz> wrote:
[...]


From wdunl@p @ending from tibco@com  Tue Nov 13 23:22:05 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Tue, 13 Nov 2018 14:22:05 -0800
Subject: [R] saveRDS() and readRDS() Why? [solved, pretty much anyway)
In-Reply-To: <d036a9b8893a1ade51c78e7325d8c89b@slingshot.co.nz>
References: <20181107075621.GD8540@slingshot.co.nz>
 <20181108072724.GF8540@slingshot.co.nz>
 <23524.2724.270930.705139@stat.math.ethz.ch>
 <20181110074834.GG8540@slingshot.co.nz>
 <20181112072806.GH8540@slingshot.co.nz>
 <9795CBFC-5F8C-4084-9704-98614BA2A626@gmail.com>
 <46f6c0217cf594e544eef3257376d598@slingshot.co.nz>
 <CAF8bMcaejV7GdwwFFB7fro2AHD9FfqHJ2J26EZG56kyQ08UP=A@mail.gmail.com>
 <3b49eb752bb2b108a72683df1d30f50b@slingshot.co.nz>
 <CAF8bMcYaXYB=PAZ9D2sDHqP1oH2To8u4A1EMrk0EGGdLdCMb=g@mail.gmail.com>
 <d036a9b8893a1ade51c78e7325d8c89b@slingshot.co.nz>
Message-ID: <CAF8bMcY_fauLbmKNY-yb0JJJu2c-Oz0tngHhHkdyFwo7ajVDyg@mail.gmail.com>

Perhaps you got bitten by Dolphin's non-modal dialogs, as described in
https://userbase.kde.org/Dolphin/File_Management:

Non Modal Dialogs

When Moving, Copying or Deleting files/directories the dialog disappears
even when the operation has not yet completed. A progress bar then appears
in the bottom right of the screen, this then disappears also, if you want
see the progress you need to click a small (i) information icon in the
system tray.


Warning
New users who are not used to this way of working (and even experienced
users) can get caught out by this, if you are Moving, Copying or Deleting
large directories then you need to use the icon to monitor the progress of
your operation. If you don't then any subsequent actions you do, may well
use an incomplete file structure resulting in corrupted files. You have
been warned!

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Nov 13, 2018 at 2:10 PM, p_connolly <p_connolly at slingshot.co.nz>
wrote:

> This is getting more strange.
>
> I normally copy from the shared folder to the appropriate directory using
> Dolphin, the KDE file manager.  If instead I use the standard bash cp
> command, no corruption happens -- at least with the limited testing I have
> done.  There also seems to be no problem copying from Linux to Windows.  I
> installed R-3.5.1 for Windows just to eliminate that possible issue.
>
> However, R has *something* to do with it because it was used to make the
> .rds file.  Just how the relationship between the name of the R object and
> the name of the .rds file comes into it, I can't imagine.
>
> Thanks for the suggestion William.
>
>
> On 2018-11-14 06:26, William Dunlap wrote:
>
>> It seems like copying the files corrupted them. How did you copy them
>> (with R
>> or cp or copy or ftp, etc.)?  I don't see how this has anything to do
>> with R.
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com [1]
>> On Mon, Nov 12, 2018 at 7:10 PM, p_connolly
>> <p_connolly at slingshot.co.nz> wrote:
>>
> [...]
>
>

	[[alternative HTML version deleted]]


From chocold12 @ending from gm@il@com  Wed Nov 14 05:50:12 2018
From: chocold12 @ending from gm@il@com (lily li)
Date: Wed, 14 Nov 2018 12:50:12 +0800
Subject: [R] How to create gridded data
In-Reply-To: <966004e209f949dba2ccf205bcef9983@tamu.edu>
References: <CAN5afy9jzOCZDzvTuzXBzeTzi_aZLsnVnYM1VuBWe0e5ziUWsQ@mail.gmail.com>
 <CAM_vjumM-nNbQBp-6vRbFKqWHpap9SQxwPBqsfkAs0+-XNj_tA@mail.gmail.com>
 <966004e209f949dba2ccf205bcef9983@tamu.edu>
Message-ID: <CAN5afy-Ts_3fUmTptkCXxTpxRVe5z-Jk07RmxtfO=JaV6phkNg@mail.gmail.com>

Thanks, Sarah's answer helps the question. Now how to change the gridded
data back to DF1 format? I don't know how to name the format, thanks.

On Tue, Nov 13, 2018 at 10:56 PM David L Carlson <dcarlson at tamu.edu> wrote:

> Sarah's answer is probably better depending on what you want to do with
> the resulting data, but here's a way to go from your original DF1 to DF2:
>
> > DF1 <- structure(list(latitude = c(45.5, 45.5, 45.5, 45.5, 46, 46, 46,
> +         46), longitude = c(110.5, 111, 111.5, 112, 110.5, 111, 111.5,
> +         112), Precip = c(3.2, 5, 1.8, 2, 6.1, 4.5, 7.8, 5.5)),
> +         class = "data.frame", row.names = c(NA, -8L))
> >
> # Convert to table with xtabs()
> > DF2 <- xtabs(Precip~latitude+longitude, DF1)
> >
>
> # Reverse the order of the latitudes
> > DF2 <- DF2[rev(rownames(DF2)), ]
> > DF2
>         longitude
> latitude 110.5 111 111.5 112
>     46     6.1 4.5   7.8 5.5
>     45.5   3.2 5.0   1.8 2.0
>
> # Convert to a data frame
> > DF2 <- as.data.frame.matrix(DF2)
> > DF2
>      110.5 111 111.5 112
> 46     6.1 4.5   7.8 5.5
> 45.5   3.2 5.0   1.8 2.0
>
> ----------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77843-4352
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Sarah Goslee
> Sent: Tuesday, November 13, 2018 8:16 AM
> To: lily li <chocold12 at gmail.com>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] How to create gridded data
>
> If you want an actual spatial dataset, the best place to ask is R-sig-geo
>
> R has substantial capabilities for dealing with gridded spatial data,
> including in the sp, raster, and sf packages.
>
> Here's one approach, creating a SpatialGridDataFrame, which can be
> exported in any standard raster format using the rgdal package.
>
> DF2 <- DF1
> coordinates(DF2) <- ~longitude + latitude
> gridded(DF2) <- TRUE
> fullgrid(DF2) <- TRUE
>
> I recommend Roger Bivand's excellent book:
> https://www.springer.com/us/book/9781461476177
>
> and there are abundant web tutorials.
>
> Sarah
> On Tue, Nov 13, 2018 at 2:22 AM lily li <chocold12 at gmail.com> wrote:
> >
> > Hi R users,
> >
> > I have a question about manipulating data. For example, I have DF1 as the
> > following, how to transform it to a gridded dataset DF2? In DF2, each
> value
> > Precip is an attribute of the corresponding grid cell. So DF2 is like a
> > spatial surface, and can be imported to ArcGIS. Thanks for your help.
> >
> > DF1
> > latitude   longitude   Precip
> > 45.5           110.5         3.2
> > 45.5           111            5.0
> > 45.5           111.5         1.8
> > 45.5           112            2.0
> > 46              110.5         6.1
> > 46              111            4.5
> > 46              111.5         7.8
> > 46              112            5.5
> > ...
> >
> >
> > DF2
> > 6.1   4.5   7.8   5.5
> > 3.2   5.0   1.8   2.0
> > ...
> >
>
>
> --
> Sarah Goslee (she/her)
> http://www.numberwright.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From robertburbidged@t@ @ending from y@hoo@co@uk  Wed Nov 14 07:58:46 2018
From: robertburbidged@t@ @ending from y@hoo@co@uk (Robert David Burbidge)
Date: Wed, 14 Nov 2018 06:58:46 +0000
Subject: [R] Help with Centroids
In-Reply-To: <CAJanvzEnCFKU3B7P_F7eZocLc1G+eBCd1Ev9595QW81Hqk0kmg@mail.gmail.com>
References: <CAJanvzEnCFKU3B7P_F7eZocLc1G+eBCd1Ev9595QW81Hqk0kmg@mail.gmail.com>
Message-ID: <abe9a802-1247-1250-1de4-0a6a6ad45a48@yahoo.co.uk>

Hi Sasha,

Your attached table did not come through, please see the posting guidelines:
"No binary attachments except for PS, PDF, and some image and archive 
formats (others are automatically stripped off because they can contain 
malicious software). Files in other formats and larger ones should 
rather be put on the web and have only their URLs posted. This way a 
reader has the option to download them or not."
https://www.r-project.org/posting-guide.html

It is not clear what you are trying to do. As a first step it looks like 
you want something like:
 >>>>>>>>>>>>>>>>
lat <- c(9161,9162,9163,9164,10152,10154)
floor(lat/10)*10
<<<<<<<<<<<<<<<<

Please provide further details on what you are trying to do.

Rgds,

Robert


On 13/11/2018 09:51, sasa kosanic wrote:
> Dear All, I am pretty new to R and would appreciate a help how to 
> calculate centroids from the latitude and longitude of existing cells 
> (e.g. to get centroid for a new cell I would need to combine latitude 
> and 9161,9162,9163,9164 to 9160 or 10152, 10154 to 10150 etc.) Please 
> see attached table. Thank you very much! Best, Sasha


From robertburbidged@t@ @ending from y@hoo@co@uk  Wed Nov 14 08:21:45 2018
From: robertburbidged@t@ @ending from y@hoo@co@uk (Robert David Burbidge)
Date: Wed, 14 Nov 2018 07:21:45 +0000
Subject: [R] POS tagging generating a string
In-Reply-To: <220696598.2779144.1542112319818@mail.yahoo.com>
References: <1394154020.2564506.1541499964758.ref@mail.yahoo.com>
 <1394154020.2564506.1541499964758@mail.yahoo.com>
 <05ceb9e2-713f-34f4-5950-3a980f0d04b5@yahoo.co.uk>
 <220696598.2779144.1542112319818@mail.yahoo.com>
Message-ID: <f3636b63-4f22-7ba8-c796-ebaa8a36ba12@yahoo.co.uk>

On 13/11/2018 12:31, Elahe chalabi wrote:

> Hi Robert,
>
> Thanks for your reply but your code returns the number of verbs in each massage. What I want is a string showing verbs in each massage.
>
The output of my code (below) is:

# A tibble: 4 x 2
 ? DocumentID verbs
 ?????? <int> <chr>
1???? 478920 has|been|updated
2???? 499497 explained
3???? 510133 it
4???? 930234 Thank

Is this not what you wanted?

Rgds,

Robert

> On Wednesday, November 7, 2018 7:31 AM, Robert David Burbidge <robertburbidgedata at yahoo.co.uk> wrote:
>
>
>
> Hi Elahe,
> You could modify your count_verbs function from your previous post:
>      * use scan to extract the tokens (words) from Message
>      * use your previous grepl expression to index the tokens that are verbs
>      * paste the verbs together to form the entries of a new column.Here is one solution:
>
> library(openNLP)
> library(NLP)
>
> df <- data.frame(DocumentID = c(478920L, 510133L, 499497L, 930234L),
>                   Message = structure(c(4L, 2L, 3L, 1L), .Label = c("Thank you very much for your nice feedback.\n",
>                                                                     "THank you, added it", "Thanks for the well explained article.",
>                                                                     "The solution has been updated"), class = "factor"))
>
>
> dput(df)
>
> tagPOS <-  function(x, ...) {
>    s <- as.String(x)
>    if(s=="") return(list())
>    word_token_annotator <- Maxent_Word_Token_Annotator()
>    a2 <- Annotation(1L, "sentence", 1L, nchar(s))
>    a2 <- annotate(s, word_token_annotator, a2)
>    a3 <- annotate(s, Maxent_POS_Tag_Annotator(), a2)
>    a3w <- a3[a3$type == "word"]
>    POStags <- unlist(lapply(a3w$features, `[[`, "POS"))
>    POStagged <- paste(sprintf("%s/%s", s[a3w], POStags), collapse = " ")
>    list(POStagged = POStagged, POStags = POStags)
> }
>
> verbs <-function(x) {
>    tagPOSx <- tagPOS(x)
>    scanx <- scan(text=as.character(x), what="character")
>    n <- length(scanx)
>    paste(scanx[(1:n)[grepl("VB", tagPOSx$POStags)]], collapse="|")
> }
>
> library(dplyr)
>
> df %>% group_by(DocumentID) %>% summarise(verbs = verbs(Message))
> <<<<<<<<<<<<<<<<<<<<<
>
> I'll leave it to you to extract a column of verbs from the result
>      and rbind it to the original data.frame.
>
> Btw, I don't this solution is efficient, I would guess that the
>      processing that scan does in the verbs function is duplicating
>      work already done in the tagPOS function by annotate, so you may
>      want to return a list of tokens from tagPOS and use that instead
>      of scan.
>
> Rgds,
> Robert
>
>
> On 06/11/18 10:26, Elahe chalabi via R-help wrote:
>
> Hi all, In my df I would like to generate a new column which contains a string showing all the verbs in each row of df$Message.
>> library(openNLP) library(NLP) dput(df) structure(list(DocumentID = c(478920L, 510133L, 499497L, 930234L ), Message = structure(c(4L, 2L, 3L, 1L), .Label = c("Thank you very much for your nice feedback.\n", "THank you, added it", "Thanks for the well explained article.", "The solution has been updated"), class = "factor")), class = "data.frame", row.names = c(NA, -4L)) tagPOS <- function(x, ...) { s <- as.String(x) word_token_annotator <- Maxent_Word_Token_Annotator() a2 <- Annotation(1L, "sentence", 1L, nchar(s)) a2 <- annotate(s, word_token_annotator, a2) a3 <- annotate(s, Maxent_POS_Tag_Annotator(), a2) a3w <- a3[a3$type == "word"] POStags <- unlist(lapply(a3w$features, `[[`, "POS")) POStagged <- paste(sprintf("%s/%s", s[a3w], POStags), collapse = " ") list(POStagged = POStagged, POStags = POStags) } Any help? Thanks in advance! Elahe ______________________________________________ R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting guide http://www.R-project.org/posting-guide.html and provide commented, minimal, self-contained, reproducible code.
>>


From p_connolly @ending from @ling@hot@co@nz  Wed Nov 14 08:35:55 2018
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Wed, 14 Nov 2018 20:35:55 +1300
Subject: [R] Corrupting files while copying (was Re: saveRDS() and readRDS()
 Why? [solved, pretty much anyway])
In-Reply-To: <CAF8bMcY_fauLbmKNY-yb0JJJu2c-Oz0tngHhHkdyFwo7ajVDyg@mail.gmail.com>
References: <23524.2724.270930.705139@stat.math.ethz.ch>
 <20181110074834.GG8540@slingshot.co.nz>
 <20181112072806.GH8540@slingshot.co.nz>
 <9795CBFC-5F8C-4084-9704-98614BA2A626@gmail.com>
 <46f6c0217cf594e544eef3257376d598@slingshot.co.nz>
 <CAF8bMcaejV7GdwwFFB7fro2AHD9FfqHJ2J26EZG56kyQ08UP=A@mail.gmail.com>
 <3b49eb752bb2b108a72683df1d30f50b@slingshot.co.nz>
 <CAF8bMcYaXYB=PAZ9D2sDHqP1oH2To8u4A1EMrk0EGGdLdCMb=g@mail.gmail.com>
 <d036a9b8893a1ade51c78e7325d8c89b@slingshot.co.nz>
 <CAF8bMcY_fauLbmKNY-yb0JJJu2c-Oz0tngHhHkdyFwo7ajVDyg@mail.gmail.com>
Message-ID: <20181114073555.GI8540@slingshot.co.nz>

Thanks William,

I've used Dolphin for years and never encountered that phenomenon.
Even so, that description doesn't fit what's going on here.  1.7
kilobytes is hardly a 'large directory'.

The problem seems to be with the way VirtualBox mounts directories
which isn't an R issue, nor is the fact that copying from Linux to
Windows isn't affected.  But the fact that it happens only with rds
files that use the name of the R object as part of their own names
must be an R issue (that surfaces only when other conditions are
present).

Theories short of divine intervention appreciated.



On Tue, 13-Nov-2018 at 02:22PM -0800, William Dunlap wrote:

|> Perhaps you got bitten by Dolphin's non-modal dialogs, as described in
|> https://userbase.kde.org/Dolphin/File_Management:
|> 
|> Non Modal Dialogs
|> 
|> When Moving, Copying or Deleting files/directories the dialog disappears
|> even when the operation has not yet completed. A progress bar then appears
|> in the bottom right of the screen, this then disappears also, if you want
|> see the progress you need to click a small (i) information icon in the
|> system tray.
|> 
|> 
|> Warning
|> New users who are not used to this way of working (and even experienced
|> users) can get caught out by this, if you are Moving, Copying or Deleting
|> large directories then you need to use the icon to monitor the progress of
|> your operation. If you don't then any subsequent actions you do, may well
|> use an incomplete file structure resulting in corrupted files. You have
|> been warned!
|> 
|> Bill Dunlap
|> TIBCO Software
|> wdunlap tibco.com
|> 
|> On Tue, Nov 13, 2018 at 2:10 PM, p_connolly <p_connolly at slingshot.co.nz>
|> wrote:
|> 
|> > This is getting more strange.
|> >
|> > I normally copy from the shared folder to the appropriate directory using
|> > Dolphin, the KDE file manager.  If instead I use the standard bash cp
|> > command, no corruption happens -- at least with the limited testing I have
|> > done.  There also seems to be no problem copying from Linux to Windows.  I
|> > installed R-3.5.1 for Windows just to eliminate that possible issue.
|> >
|> > However, R has *something* to do with it because it was used to make the
|> > .rds file.  Just how the relationship between the name of the R object and
|> > the name of the .rds file comes into it, I can't imagine.
|> >
|> > Thanks for the suggestion William.
|> >
|> >
|> > On 2018-11-14 06:26, William Dunlap wrote:
|> >
|> >> It seems like copying the files corrupted them. How did you copy them
|> >> (with R
|> >> or cp or copy or ftp, etc.)?  I don't see how this has anything to do
|> >> with R.
|> >>
|> >> Bill Dunlap
|> >> TIBCO Software
|> >> wdunlap tibco.com [1]
|> >> On Mon, Nov 12, 2018 at 7:10 PM, p_connolly
|> >> <p_connolly at slingshot.co.nz> wrote:
|> >>
|> > [...]
|> >
|> >

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From @@himk@poor @ending from gm@il@com  Wed Nov 14 11:07:32 2018
From: @@himk@poor @ending from gm@il@com (Ashim Kapoor)
Date: Wed, 14 Nov 2018 15:37:32 +0530
Subject: [R] Output of arima
In-Reply-To: <CAF8bMcY7z_44w3Ja2a__jZnSqDqYqnFYLXygvVG03RFTjjicwA@mail.gmail.com>
References: <CAC8=1ervy1GgrW17FrzwOnYgEQJbiE16uiYH_DoCP4H4Ga-b8Q@mail.gmail.com>
 <CAF8bMcY7z_44w3Ja2a__jZnSqDqYqnFYLXygvVG03RFTjjicwA@mail.gmail.com>
Message-ID: <CAC8=1eqbEbgx5Rs982uJM9fX9kYAt71KK=VHvDf9Y=tHhTGVFg@mail.gmail.com>

Dear Eric and William,

Why do the 1st and 2nd incantation of arima return sigma^2 as 5.233 vs
.9999?
The help for arima says  --->  sigma2: the MLE of the innovations variance.
By that account the 1st result is incorrect. I am a little confused.

set.seed(123)
b <- arima.sim(list(order = c(1,0,0),ar= .9),n=1000000,sd=1)

# Variance of the innovations, e_t = 1

# Variance of b = Var(e_t)/(1-Phi^2) = 1 / (1-.81) = 5.263158

arima(b)

> arima(b)

Call:
arima(x = b)

Coefficients:
      intercept
        -0.0051
s.e.     0.0023

sigma^2 estimated as 5.233:  log likelihood = -2246450,  aic = 4492903
>


arima(b,order= c(1,0,0))

Call:
arima(x = b, order = c(1, 0, 0))

Coefficients:
         ar1  intercept
      0.8994    -0.0051
s.e.  0.0004     0.0099

sigma^2 estimated as 0.9999:  log likelihood = -1418870,  aic = 2837747
>

On Tue, Nov 13, 2018 at 11:07 PM William Dunlap <wdunlap at tibco.com> wrote:

> Try supplying the order argument to arima.  It looks like the default is
> to estimate only the mean.
>
> > arima(b, order=c(1,0,0))
>
> Call:
> arima(x = b, order = c(1, 0, 0))
>
> Coefficients:
>          ar1  intercept
>       0.8871     0.2369
> s.e.  0.0145     0.2783
>
> sigma^2 estimated as 1.002:  log likelihood = -1420.82,  aic = 2847.63
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Nov 13, 2018 at 4:02 AM, Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
>
>> Dear All,
>>
>> Here is a reprex:
>>
>> set.seed(123)
>> b <- arima.sim(list(order = c(1,0,0),ar= .9),n=1000,sd=1)
>> arima(b)
>>
>> Call:
>> arima(x = b)
>>
>> Coefficients:
>>       intercept
>>          0.2250
>> s.e.     0.0688
>>
>> sigma^2 estimated as 4.735:  log likelihood = -2196.4,  aic = 4396.81
>> >
>>
>> Should sigma^2 not be equal to 1 ? Where do I misunderstand ?
>>
>> Many thanks,
>> Ashim
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Wed Nov 14 11:35:26 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Wed, 14 Nov 2018 12:35:26 +0200
Subject: [R] Output of arima
In-Reply-To: <CAC8=1eqbEbgx5Rs982uJM9fX9kYAt71KK=VHvDf9Y=tHhTGVFg@mail.gmail.com>
References: <CAC8=1ervy1GgrW17FrzwOnYgEQJbiE16uiYH_DoCP4H4Ga-b8Q@mail.gmail.com>
 <CAF8bMcY7z_44w3Ja2a__jZnSqDqYqnFYLXygvVG03RFTjjicwA@mail.gmail.com>
 <CAC8=1eqbEbgx5Rs982uJM9fX9kYAt71KK=VHvDf9Y=tHhTGVFg@mail.gmail.com>
Message-ID: <CAGgJW777iW7yFbpG=7JD8Sr3P+0MSmSBuv1axtGvWJVeEAuPeQ@mail.gmail.com>

Hi Ashim,
Per the help page for arima(), it fits an ARIMA model to the specified time
series - but the caller has to specify the order - i.e. (p,d,q) - of the
model.
The default order is (0,0,0) (per the help page). Hence your two calls are
different. The first call is equivalent to order=c(0,0,0) and the second
specifies order=c(1,0,0).
In the first, since there is no auto-regression, all the variance is
"assigned" to the innovations, hence sigma^2 = 5.233.
The second case you understand.
A clue that this was happening is that the first call only returns a single
coefficient (where is the autoregressive coefficient? - not there because
you didn't ask for it).
The second call returns two coefficients, as requested/expected.

HTH,
Eric


On Wed, Nov 14, 2018 at 12:08 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear Eric and William,
>
> Why do the 1st and 2nd incantation of arima return sigma^2 as 5.233 vs
> .9999?
> The help for arima says  --->  sigma2: the MLE of the innovations variance.
> By that account the 1st result is incorrect. I am a little confused.
>
> set.seed(123)
> b <- arima.sim(list(order = c(1,0,0),ar= .9),n=1000000,sd=1)
>
> # Variance of the innovations, e_t = 1
>
> # Variance of b = Var(e_t)/(1-Phi^2) = 1 / (1-.81) = 5.263158
>
> arima(b)
>
> > arima(b)
>
> Call:
> arima(x = b)
>
> Coefficients:
>       intercept
>         -0.0051
> s.e.     0.0023
>
> sigma^2 estimated as 5.233:  log likelihood = -2246450,  aic = 4492903
> >
>
>
> arima(b,order= c(1,0,0))
>
> Call:
> arima(x = b, order = c(1, 0, 0))
>
> Coefficients:
>          ar1  intercept
>       0.8994    -0.0051
> s.e.  0.0004     0.0099
>
> sigma^2 estimated as 0.9999:  log likelihood = -1418870,  aic = 2837747
> >
>
> On Tue, Nov 13, 2018 at 11:07 PM William Dunlap <wdunlap at tibco.com> wrote:
>
> > Try supplying the order argument to arima.  It looks like the default is
> > to estimate only the mean.
> >
> > > arima(b, order=c(1,0,0))
> >
> > Call:
> > arima(x = b, order = c(1, 0, 0))
> >
> > Coefficients:
> >          ar1  intercept
> >       0.8871     0.2369
> > s.e.  0.0145     0.2783
> >
> > sigma^2 estimated as 1.002:  log likelihood = -1420.82,  aic = 2847.63
> >
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Tue, Nov 13, 2018 at 4:02 AM, Ashim Kapoor <ashimkapoor at gmail.com>
> > wrote:
> >
> >> Dear All,
> >>
> >> Here is a reprex:
> >>
> >> set.seed(123)
> >> b <- arima.sim(list(order = c(1,0,0),ar= .9),n=1000,sd=1)
> >> arima(b)
> >>
> >> Call:
> >> arima(x = b)
> >>
> >> Coefficients:
> >>       intercept
> >>          0.2250
> >> s.e.     0.0688
> >>
> >> sigma^2 estimated as 4.735:  log likelihood = -2196.4,  aic = 4396.81
> >> >
> >>
> >> Should sigma^2 not be equal to 1 ? Where do I misunderstand ?
> >>
> >> Many thanks,
> >> Ashim
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From y@@@@_m@lik@ @ending from y@hoo@fr  Wed Nov 14 12:19:54 2018
From: y@@@@_m@lik@ @ending from y@hoo@fr (malika yassa)
Date: Wed, 14 Nov 2018 11:19:54 +0000 (UTC)
Subject: [R] extrat non diagonal value
References: <1177952290.451814.1542194394101.ref@mail.yahoo.com>
Message-ID: <1177952290.451814.1542194394101@mail.yahoo.com>

helloplease i have this matrixx<-rnorm(6,0,1)

aa<-matrix(x,nrow=6,ncol=6)

i have to extrat non diagonal value, i use this code
matrix(as.numeric(aa)[!as.numeric(aa) %in% diag(aa)],5,6)

but i didn't get the resultthank you 

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Wed Nov 14 12:54:30 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Wed, 14 Nov 2018 11:54:30 +0000
Subject: [R] extrat non diagonal value
In-Reply-To: <1177952290.451814.1542194394101@mail.yahoo.com>
References: <1177952290.451814.1542194394101.ref@mail.yahoo.com>
 <1177952290.451814.1542194394101@mail.yahoo.com>
Message-ID: <2385a606cf1e4a82a3bc777c02576906@SRVEXCHCM1301.precheza.cz>

Hi.

You did not specify what do you want to do with the result.

functions

upper.tri, lower.tri and diag can manipulate parts of matrices.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of malika yassa via R-
> help
> Sent: Wednesday, November 14, 2018 12:20 PM
> To: R-help Mailing List <r-help at r-project.org>
> Subject: [R] extrat non diagonal value
>
> helloplease i have this matrixx<-rnorm(6,0,1)
>
> aa<-matrix(x,nrow=6,ncol=6)
>
> i have to extrat non diagonal value, i use this code
> matrix(as.numeric(aa)[!as.numeric(aa) %in% diag(aa)],5,6)
>
> but i didn't get the resultthank you
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From li@t@ @ending from dewey@myzen@co@uk  Wed Nov 14 12:59:03 2018
From: li@t@ @ending from dewey@myzen@co@uk (Michael Dewey)
Date: Wed, 14 Nov 2018 11:59:03 +0000
Subject: [R] extrat non diagonal value
In-Reply-To: <1177952290.451814.1542194394101@mail.yahoo.com>
References: <1177952290.451814.1542194394101.ref@mail.yahoo.com>
 <1177952290.451814.1542194394101@mail.yahoo.com>
Message-ID: <8f7b97de-a696-f011-4877-087985a2b589@dewey.myzen.co.uk>

When that arrived it was a complete mess since you posted in HTML which 
scrambles your code and you sent code which had syntax errors. Please 
try again by posting in plain text and cut and paste your code. It would 
also help if you stated exactly what you expected your output to consist of.

Michael

On 14/11/2018 11:19, malika yassa via R-help wrote:
> helloplease i have this matrixx<-rnorm(6,0,1)
> 
> aa<-matrix(x,nrow=6,ncol=6)
> 
> i have to extrat non diagonal value, i use this code
> matrix(as.numeric(aa)[!as.numeric(aa) %in% diag(aa)],5,6)
> 
> but i didn't get the resultthank you
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From robertburbidged@t@ @ending from y@hoo@co@uk  Wed Nov 14 13:09:13 2018
From: robertburbidged@t@ @ending from y@hoo@co@uk (Robert David Burbidge)
Date: Wed, 14 Nov 2018 12:09:13 +0000
Subject: [R] Help with Centroids
In-Reply-To: <CAJanvzFp-u8W8-ozV6RroRQ_PbeVbX64JujqLbm+33nWoeZ2Dg@mail.gmail.com>
References: <CAJanvzEnCFKU3B7P_F7eZocLc1G+eBCd1Ev9595QW81Hqk0kmg@mail.gmail.com>
 <abe9a802-1247-1250-1de4-0a6a6ad45a48@yahoo.co.uk>
 <CAJanvzFp-u8W8-ozV6RroRQ_PbeVbX64JujqLbm+33nWoeZ2Dg@mail.gmail.com>
Message-ID: <da9325c8-20e1-d775-10a1-eab11227961e@yahoo.co.uk>

# construct the dataframe
`TK-QUADRANT` <- c(9161,9162,9163,9164,10152,10154,10161,10163)
LAT <- 
c(55.07496,55.07496,55.02495,55.02496,54.97496,54.92495,54.97496,54.92496)
LON <- 
c(8.37477,8.458109,8.37477,8.45811,8.291435,8.291437,8.374774,8.374774)
df <- data.frame(`TK-QUADRANT`=`TK-QUADRANT`,LAT=LAT,LON=LON)

# group the data and calculate means by group
df$group <- floor(df$TK.QUADRANT/10)*10
out <- aggregate(df[c('LAT','LON')],by=list(df$group),mean)
print(out)

# see also:
# 
https://livefreeordichotomize.com/2018/06/27/bringing-the-family-together-finding-the-center-of-geographic-points-in-r/

Rgds,
Robert
On 14/11/2018 11:13, sasa kosanic wrote:
> ?Dear Robert,
> Thank? you for your very much for your reply. Please see attached pdf? 
> fille.
> I hope now it is more clear what I am trying to do:
> calculate new latitude and? longitude? of the centroids from the 
> existing cells...
> as you can see from the attached pdf.? from Lat/ Long of 
> 9161,9162,9163,9164 I need to calculate a single Lat/Long that could 
> be fore example called 9160
> and then from lat/ long of 10152 and 10154 a? new single lat/long 
> called 10150 .
> But guess I would need some kind of loop as this is just an example 
> table? and the the whole table is covering whole Germany.
> Please let me know if it is still not clear what I am trying to do here.
>
> Best wishes,
> Sasha
>
> On Wed, 14 Nov 2018 at 07:58, Robert David Burbidge 
> <robertburbidgedata at yahoo.co.uk 
> <mailto:robertburbidgedata at yahoo.co.uk>> wrote:
>
>     Hi Sasha,
>
>     Your attached table did not come through, please see the posting
>     guidelines:
>     "No binary attachments except for PS, PDF, and some image and archive
>     formats (others are automatically stripped off because they can
>     contain
>     malicious software). Files in other formats and larger ones should
>     rather be put on the web and have only their URLs posted. This way a
>     reader has the option to download them or not."
>     https://www.r-project.org/posting-guide.html
>
>     It is not clear what you are trying to do. As a first step it
>     looks like
>     you want something like:
>     ?>>>>>>>>>>>>>>>>
>     lat <- c(9161,9162,9163,9164,10152,10154)
>     floor(lat/10)*10
>     <<<<<<<<<<<<<<<<
>
>     Please provide further details on what you are trying to do.
>
>     Rgds,
>
>     Robert
>
>
>     On 13/11/2018 09:51, sasa kosanic wrote:
>     > Dear All, I am pretty new to R and would appreciate a help how to
>     > calculate centroids from the latitude and longitude of existing
>     cells
>     > (e.g. to get centroid for a new cell I would need to combine
>     latitude
>     > and 9161,9162,9163,9164 to 9160 or 10152, 10154 to 10150 etc.)
>     Please
>     > see attached table. Thank you very much! Best, Sasha
>
>
>
> -- 
>
> Dr Sasha Kosanic
> Ecology Lab (Biology Department)
> Room M644
> University of Konstanz
> Universit?tsstra?e 10
> D-78464 Konstanz
> Phone: +49 7531 883321 & +49 (0)175 9172503
>
> http://cms.uni-konstanz.de/vkleunen/
> https://tinyurl.com/y8u5wyoj
> https://tinyurl.com/cgec6tu
>
>

	[[alternative HTML version deleted]]


From y@@@@_m@lik@ @ending from y@hoo@fr  Wed Nov 14 13:09:21 2018
From: y@@@@_m@lik@ @ending from y@hoo@fr (malika yassa)
Date: Wed, 14 Nov 2018 12:09:21 +0000 (UTC)
Subject: [R] extrat non diagonal
References: <1498258127.556770.1542197362002.ref@mail.yahoo.com>
Message-ID: <1498258127.556770.1542197362002@mail.yahoo.com>

helloi didn't obtaine the matrix after extrat non diagonalmy programx<-rnorm(6,0,1)

aa<-matrix(x,nrow=6,ncol=6)
matrix(as.numeric(aa)[!as.numeric(aa) %in% diag(aa)],5,6)

nrow=5ncol=6thank you

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Wed Nov 14 13:25:17 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Wed, 14 Nov 2018 12:25:17 +0000
Subject: [R] extrat non diagonal
In-Reply-To: <1498258127.556770.1542197362002@mail.yahoo.com>
References: <1498258127.556770.1542197362002.ref@mail.yahoo.com>
 <1498258127.556770.1542197362002@mail.yahoo.com>
Message-ID: <9130e96160d34e4a93557e9e0154ca7b@SRVEXCHCM1301.precheza.cz>

Hi

Your mail is mess due to HTML formating. Please use plain taxt mail.
You got an advice, did you try it?

With your code you just remove diagonal elements from your matrix. If this is not your intention, you should specify more clearly what do you want to achieve as the result.

Cheers
Petr
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of malika yassa via R-
> help
> Sent: Wednesday, November 14, 2018 1:09 PM
> To: R-help Mailing List <r-help at r-project.org>
> Subject: [R] extrat non diagonal
>
> helloi didn't obtaine the matrix after extrat non diagonalmy programx<-
> rnorm(6,0,1)
>
> aa<-matrix(x,nrow=6,ncol=6)
> matrix(as.numeric(aa)[!as.numeric(aa) %in% diag(aa)],5,6)
>
> nrow=5ncol=6thank you
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From pd@lgd @ending from gm@il@com  Wed Nov 14 13:56:03 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Wed, 14 Nov 2018 13:56:03 +0100
Subject: [R] lm equivalent of Welch-corrected t-test?
In-Reply-To: <CAErODj_eXvaB-B7yU7BGAPPassNtLN0F6RLV8hCVpE+Fn_a3Bw@mail.gmail.com>
References: <CAErODj_eXvaB-B7yU7BGAPPassNtLN0F6RLV8hCVpE+Fn_a3Bw@mail.gmail.com>
Message-ID: <4E831576-866C-4FD8-BA66-402E63DFE7BA@gmail.com>



> On 13 Nov 2018, at 16:19 , Paul Johnson <pauljohn32 at gmail.com> wrote:
> 
> Long ago, when R's t.test had var.equal=TRUE by default, I wrote some
> class notes showing that the result was equivalent to a one predictor
> regression model.  Because t.test does not default to var.equal=TRUE
> these days, I'm curious to know if there is a way to specify weights
> in an lm to obtain the same result as the Welch-adjusted values
> reported by t.test at the current time.  Is there a WLS equivalent
> adjustment with lm?
> 

The short answer is no. The long answer is to look into heteroscedasticity adjustments or lmer combined with pbkrtest. 

Well, you can do the weights in lm() and get the right t statistic, but not the Satterthwaite oddball-df thing (the sleep data are actually paired, but ignore that here)

variances <- tapply(sleep$extra, sleep$group, var)
sleep$wt <- 1/variances[sleep$group]
t.test(extra~group, sleep)
summary(lm(extra~factor(group), weight=wt, sleep))


The pbkrtest approach goes like this:

library(lme4)
library(pbkrtest)
sleep$gdummy <- sleep$group-1 # arrange that this is 1 in the group with larger variance
fit1 <-  lmer(extra ~ group + (gdummy+0 | ID), sleep)
fit0 <-  lmer(extra ~ 1 + (gdummy+0 | ID), sleep)
KRmodcomp(fit0, fit1)

(This somewhat abuses the existing sleep$ID -- all you really need is something that has a level for each record where gdummy==1)

This ends up with 

         stat     ndf     ddf F.scaling p.value  
Ftest  3.4626  1.0000 17.7765         1 0.07939 .

to be compared with the Welch test

t = -1.8608, df = 17.776, p-value = 0.07939


-pd 


> Here's example code to show that lm is same as t.test with var.equal.
> The signs come out differently, but otherwise the effect estimate,
> standard error, t value are same:
> 
> 
> set.seed(234234)
> dat <- data.frame(x = gl(2, 50, labels = c("F", "M")))
> dat$err <- rnorm(100, 0, 1)
> dat$y <- ifelse(dat$x == "F", 40 + dat$err, 44 + dat$err)
> m1 <- lm(y ~ x, dat)
> summary(m1)
> m1.t <- t.test(y ~ x, dat, var.equal = TRUE)
> m1.t
> ## diff matches regression coefficient
> (m1.t.effect <- diff(m1.t$estimate))
> ## standard error matches regression se
> m1.t.stderr <- m1.t.effect/m1.t$statistic
> 
> If you run that, you see lm output:
> 
> Coefficients:
>            Estimate Std. Error t value Pr(>|t|)
> (Intercept)  39.9456     0.1180  338.65   <2e-16 ***
> xM            3.9080     0.1668   23.43   <2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Residual standard error: 0.8341 on 98 degrees of freedom
> Multiple R-squared:  0.8485,    Adjusted R-squared:  0.8469
> F-statistic: 548.8 on 1 and 98 DF,  p-value: < 2.2e-16
> 
> and t.test:
> 
>> m1.t <- t.test(y ~ x, dat, var.equal = TRUE)
>> m1.t
> 
>    Two Sample t-test
> 
> data:  y by x
> t = -23.427, df = 98, p-value < 2.2e-16
> alternative hypothesis: true difference in means is not equal to 0
> 95 percent confidence interval:
> -4.239038 -3.576968
> sample estimates:
> mean in group F mean in group M
>       39.94558        43.85358
> 
>> (m1.t.effect <- diff(m1.t$estimate))
> mean in group M
>       3.908003
>> m1.t.effect/m1.t$statistic
> mean in group M
>     -0.1668129
> 
> 
> 
> 
> -- 
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
> 
> To write to me directly, please address me at pauljohn at ku.edu.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From y@@@@_m@lik@ @ending from y@hoo@fr  Wed Nov 14 15:24:01 2018
From: y@@@@_m@lik@ @ending from y@hoo@fr (malika yassa)
Date: Wed, 14 Nov 2018 14:24:01 +0000 (UTC)
Subject: [R] extrat non diagonal
References: <79115083.696429.1542205441415.ref@mail.yahoo.com>
Message-ID: <79115083.696429.1542205441415@mail.yahoo.com>

hello
for examplei have this matrix
w2<-c(0.1,0.2,0.4,0.2,0.4,0.1)aa<-matrix(w1,nrow=3,ncol=3)aa
???? [,1] [,2] [,3]
[1,]? 0.4? 0.4? 0.4
[2,]? 0.1? 0.1? 0.1
[3,]? 0.2? 0.2? 0.2

if i use this code 
matrix(as.numeric(aa)[!as.numeric(aa) %in% diag(aa)],2,3)

i will obtaine this matrix[,1] [,2] [,3]
[1,]?? NA?? NA?? NA
[2,]?? NA?? NA?? NA

but me i want this matrix[,1] [,2] [,3]
[1,]? 0.1? 0.4? 0.4
[2,]? 0.2? 0.2? 0.1

thank you

	[[alternative HTML version deleted]]


From S@Elli@on @ending from LGCGroup@com  Wed Nov 14 17:04:03 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Wed, 14 Nov 2018 16:04:03 +0000
Subject: [R] extrat non diagonal
In-Reply-To: <79115083.696429.1542205441415@mail.yahoo.com>
References: <79115083.696429.1542205441415.ref@mail.yahoo.com>
 <79115083.696429.1542205441415@mail.yahoo.com>
Message-ID: <f55d001154f248bd87c5e04316bcf2c5@GBDCVPEXC04.corp.lgc-group.com>

i) Your code creates w2 but references w1 to create aa.

So you needed 
aa <- matrix(rep(c(0.4, 0.1, 0.2), 3), 3,3)
for a working example.

ii) This
> matrix(as.numeric(aa)[!as.numeric(aa) %in% diag(aa)],2,3)
removes any value that is present in the diagonal of aa. Look up ?"%in%" to see what that does; it returns TRUE whenever anything in as.numeric(aa) matches anything in your diagonal. All the values in aa match one of c(0.4, 0.1, 0.2). So since your whole matrix consists of these three numbers, you told R to leave out everything in aa and then create a 2x3 matrix with the result. Hence the NAs

iii) If you want to extract odd parts of a matrix explicitly, see ?"[" and particularly the section on indexing using arrays

iv) You can use logical indexing. In the special case of the diagonal, you can use diag() to create a matrix of logicals, logically negate that and apply that to your matrix:
aa[ !diag(rep(TRUE, 3)) ]

and, in twoi rows:
matrix( aa[ !diag(rep(TRUE, 3)) ], 2,3)

> for examplei have this matrix
> w2<-c(0.1,0.2,0.4,0.2,0.4,0.1)
> aa<-matrix(w1,nrow=3,ncol=3)
> aa
> ???? [,1] [,2] [,3]
> [1,]? 0.4? 0.4? 0.4
> [2,]? 0.1? 0.1? 0.1
> [3,]? 0.2? 0.2? 0.2
> 
> if i use this code
> matrix(as.numeric(aa)[!as.numeric(aa) %in% diag(aa)],2,3)
> 
> i will obtaine this matrix[,1] [,2] [,3]
> [1,]?? NA?? NA?? NA
> [2,]?? NA?? NA?? NA
> 
> but me i want this matrix[,1] [,2] [,3]
> [1,]? 0.1? 0.4? 0.4
> [2,]? 0.2? 0.2? 0.1
> 
> thank you
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From S@Elli@on @ending from LGCGroup@com  Wed Nov 14 17:05:24 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Wed, 14 Nov 2018 16:05:24 +0000
Subject: [R] extrat non diagonal
In-Reply-To: <9130e96160d34e4a93557e9e0154ca7b@SRVEXCHCM1301.precheza.cz>
References: <1498258127.556770.1542197362002.ref@mail.yahoo.com>
 <1498258127.556770.1542197362002@mail.yahoo.com>
 <9130e96160d34e4a93557e9e0154ca7b@SRVEXCHCM1301.precheza.cz>
Message-ID: <44906965d7ff487d94a67ef9ddd64767@GBDCVPEXC04.corp.lgc-group.com>

> With your code you just remove diagonal elements from your matrix. 
Worse; it removed _all_ elements from the matrix that match _anything_ in the diagonal!
Which, in that example, was everything ...




*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From m@cqueen1 @ending from llnl@gov  Wed Nov 14 17:48:55 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Wed, 14 Nov 2018 16:48:55 +0000
Subject: [R] How to create gridded data
In-Reply-To: <CAN5afy-Ts_3fUmTptkCXxTpxRVe5z-Jk07RmxtfO=JaV6phkNg@mail.gmail.com>
References: <CAN5afy9jzOCZDzvTuzXBzeTzi_aZLsnVnYM1VuBWe0e5ziUWsQ@mail.gmail.com>
 <CAM_vjumM-nNbQBp-6vRbFKqWHpap9SQxwPBqsfkAs0+-XNj_tA@mail.gmail.com>
 <966004e209f949dba2ccf205bcef9983@tamu.edu>
 <CAN5afy-Ts_3fUmTptkCXxTpxRVe5z-Jk07RmxtfO=JaV6phkNg@mail.gmail.com>
Message-ID: <383B8E34-B0D2-4CDC-B84E-EE03388EAEC5@llnl.gov>

Sarah's answer is probably the best approach, but to do it using very basic R methods that predate the very good spatial support that R now has, I would likely do this:

## Thanks, Jim Lemon, for this step:
df1 <- read.table(text=
"latitude   longitude   Precip
45.5           110.5         3.2
45.5           111            5.0
45.5           111.5         1.8
45.5           112            2.0
46              110.5         6.1
46              111            4.5
46              111.5         7.8
46              112            5.5",
header=TRUE)

## first sort
df1 <- df1[order(df1$latitude, df1$longitude) , ]

## convert vector of precipitations to matrix
df2 <- matrix(df1$Precip, nrow=length(unique(df1$latitude)), byrow=TRUE)

## reorder the latitudes (rows)
df2 <- df2[ nrow(df2):1 , ]

## > df2
##      [,1] [,2] [,3] [,4]
## [1,]  6.1  4.5  7.8  5.5
## [2,]  3.2  5.0  1.8  2.0

## From the original question:
## DF2
## 6.1   4.5   7.8   5.5
## 3.2   5.0   1.8   2.0
## ...

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 11/13/18, 8:50 PM, "R-help on behalf of lily li" <r-help-bounces at r-project.org on behalf of chocold12 at gmail.com> wrote:

    Thanks, Sarah's answer helps the question. Now how to change the gridded
    data back to DF1 format? I don't know how to name the format, thanks.
    
    On Tue, Nov 13, 2018 at 10:56 PM David L Carlson <dcarlson at tamu.edu> wrote:
    
    > Sarah's answer is probably better depending on what you want to do with
    > the resulting data, but here's a way to go from your original DF1 to DF2:
    >
    > > DF1 <- structure(list(latitude = c(45.5, 45.5, 45.5, 45.5, 46, 46, 46,
    > +         46), longitude = c(110.5, 111, 111.5, 112, 110.5, 111, 111.5,
    > +         112), Precip = c(3.2, 5, 1.8, 2, 6.1, 4.5, 7.8, 5.5)),
    > +         class = "data.frame", row.names = c(NA, -8L))
    > >
    > # Convert to table with xtabs()
    > > DF2 <- xtabs(Precip~latitude+longitude, DF1)
    > >
    >
    > # Reverse the order of the latitudes
    > > DF2 <- DF2[rev(rownames(DF2)), ]
    > > DF2
    >         longitude
    > latitude 110.5 111 111.5 112
    >     46     6.1 4.5   7.8 5.5
    >     45.5   3.2 5.0   1.8 2.0
    >
    > # Convert to a data frame
    > > DF2 <- as.data.frame.matrix(DF2)
    > > DF2
    >      110.5 111 111.5 112
    > 46     6.1 4.5   7.8 5.5
    > 45.5   3.2 5.0   1.8 2.0
    >
    > ----------------------------------------
    > David L Carlson
    > Department of Anthropology
    > Texas A&M University
    > College Station, TX 77843-4352
    >
    >
    > -----Original Message-----
    > From: R-help <r-help-bounces at r-project.org> On Behalf Of Sarah Goslee
    > Sent: Tuesday, November 13, 2018 8:16 AM
    > To: lily li <chocold12 at gmail.com>
    > Cc: r-help <r-help at r-project.org>
    > Subject: Re: [R] How to create gridded data
    >
    > If you want an actual spatial dataset, the best place to ask is R-sig-geo
    >
    > R has substantial capabilities for dealing with gridded spatial data,
    > including in the sp, raster, and sf packages.
    >
    > Here's one approach, creating a SpatialGridDataFrame, which can be
    > exported in any standard raster format using the rgdal package.
    >
    > DF2 <- DF1
    > coordinates(DF2) <- ~longitude + latitude
    > gridded(DF2) <- TRUE
    > fullgrid(DF2) <- TRUE
    >
    > I recommend Roger Bivand's excellent book:
    > https://www.springer.com/us/book/9781461476177
    >
    > and there are abundant web tutorials.
    >
    > Sarah
    > On Tue, Nov 13, 2018 at 2:22 AM lily li <chocold12 at gmail.com> wrote:
    > >
    > > Hi R users,
    > >
    > > I have a question about manipulating data. For example, I have DF1 as the
    > > following, how to transform it to a gridded dataset DF2? In DF2, each
    > value
    > > Precip is an attribute of the corresponding grid cell. So DF2 is like a
    > > spatial surface, and can be imported to ArcGIS. Thanks for your help.
    > >
    > > DF1
    > > latitude   longitude   Precip
    > > 45.5           110.5         3.2
    > > 45.5           111            5.0
    > > 45.5           111.5         1.8
    > > 45.5           112            2.0
    > > 46              110.5         6.1
    > > 46              111            4.5
    > > 46              111.5         7.8
    > > 46              112            5.5
    > > ...
    > >
    > >
    > > DF2
    > > 6.1   4.5   7.8   5.5
    > > 3.2   5.0   1.8   2.0
    > > ...
    > >
    >
    >
    > --
    > Sarah Goslee (she/her)
    > http://www.numberwright.com
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    >
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From friendly @ending from yorku@c@  Wed Nov 14 18:27:23 2018
From: friendly @ending from yorku@c@ (Michael Friendly)
Date: Wed, 14 Nov 2018 12:27:23 -0500
Subject: [R] ANNOUNCE: ASA Data Challenge Expo, 2019
Message-ID: <00ffa577-61bd-ea4b-5fc3-8829dcd612f5@yorku.ca>

On behalf of the American Statistical Association sections mentioned 
below,? I am forwarding the information that recently appeared on the 
Statistical Computing Section web? at 
https://community.amstat.org/stat-computing/data-expo/data-expo-2019.

Old-timers will know that the ASA Data Challenge Expo has been important 
in the history of R development, and a number of these have been used as 
examples in a wide range of teaching and R packages.? Encourage your 
colleagues and students to consider this!

-Michael

Three ASA sections (Computing, Government, and Graphics) are proud to 
sponsor the, now annual, Data Challenge Expo 2019 at the JSM 2019 
meetings. The contest is open to anyone who is interested in 
participating, including college students and professionals from the 
private or public sector. This contest challenges participants to 
analyze a government data set using statistical and visualization tools 
and methods. There will be two award categories ? Professional (one 
level with a $500 award) and Student (three levels with awards at 
$1,500, $1,000, and $500).

Contestants will present their results in a speed poster session at the 
JSM and must submit their abstracts to the JSM online system. Presenters 
are responsible for their own JSM registration and travel costs, and any 
other costs associated with JSM attendance. Group submissions are 
acceptable. To enter, contestants must do the following by _February 4, 
2019_.

  * Submit abstract for Speed Poster session to the JSM 2019 website
    (http://ww2.amstat.org/meetings/jsm/2019/submissions.cfm). Specify
    the Government Statistics Section (GSS) as the main sponsor.
    Abstract submission starts _December 3, 2018_.
  * Forward the JSM abstract submission email to Wendy Martinez
    (martinez.wendy at bls.gov <mailto:martinez.wendy at bls.gov>).

The data set for the Data Challenge Expo 2019 will be the New York City 
Housing and Vacancy Survey. Public use data files and documentation are 
available here: https://www.census.gov/programs-surveys/nychvs.html. 
Contestants must use some portion of the New York City Housing and 
Vacancy Survey data, but can also combine other data sources in the 
analysis. If you have any questions on the Data Challenge Expo 2019 
please reach out to Wendy Martinez.

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, ASA Statistical Graphics Section
York University      Voice: 416 736-2100 x66249
4700 Keele Street    Web: http://www.datavis.ca | @datavisFriendly
Toronto, ONT  M3J 1P3 CANADA


	[[alternative HTML version deleted]]


From rmh @ending from temple@edu  Wed Nov 14 20:09:04 2018
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Wed, 14 Nov 2018 14:09:04 -0500
Subject: [R] extrat non diagonal
In-Reply-To: <f55d001154f248bd87c5e04316bcf2c5@GBDCVPEXC04.corp.lgc-group.com>
References: <79115083.696429.1542205441415.ref@mail.yahoo.com>
 <79115083.696429.1542205441415@mail.yahoo.com>
 <f55d001154f248bd87c5e04316bcf2c5@GBDCVPEXC04.corp.lgc-group.com>
Message-ID: <CAGx1TMDX-X0Me5CcRuj7brs-BLMVsPHvqh7pZqcfWo2Pv1BSdA@mail.gmail.com>

Steve's method is very slick.

I think this is a bit easier to understand.

A <- matrix(1:9, 3, 3)
A
B <- matrix(nrow=2, ncol=3)
B[lower.tri(B, diag=TRUE)] <- A[lower.tri(A)]
B[upper.tri(B, diag=FALSE)] <- A[upper.tri(A)]
B

> A <- matrix(1:9, 3, 3)
> A
     [,1] [,2] [,3]
[1,]    1    4    7
[2,]    2    5    8
[3,]    3    6    9
> B <- matrix(nrow=2, ncol=3)
> B[lower.tri(B, diag=TRUE)] <- A[lower.tri(A)]
> B[upper.tri(B, diag=FALSE)] <- A[upper.tri(A)]
> B
     [,1] [,2] [,3]
[1,]    2    4    7
[2,]    3    6    8
>
On Wed, Nov 14, 2018 at 11:04 AM S Ellison <S.Ellison at lgcgroup.com> wrote:
>
> i) Your code creates w2 but references w1 to create aa.
>
> So you needed
> aa <- matrix(rep(c(0.4, 0.1, 0.2), 3), 3,3)
> for a working example.
>
> ii) This
> > matrix(as.numeric(aa)[!as.numeric(aa) %in% diag(aa)],2,3)
> removes any value that is present in the diagonal of aa. Look up ?"%in%" to see what that does; it returns TRUE whenever anything in as.numeric(aa) matches anything in your diagonal. All the values in aa match one of c(0.4, 0.1, 0.2). So since your whole matrix consists of these three numbers, you told R to leave out everything in aa and then create a 2x3 matrix with the result. Hence the NAs
>
> iii) If you want to extract odd parts of a matrix explicitly, see ?"[" and particularly the section on indexing using arrays
>
> iv) You can use logical indexing. In the special case of the diagonal, you can use diag() to create a matrix of logicals, logically negate that and apply that to your matrix:
> aa[ !diag(rep(TRUE, 3)) ]
>
> and, in twoi rows:
> matrix( aa[ !diag(rep(TRUE, 3)) ], 2,3)
>
> > for examplei have this matrix
> > w2<-c(0.1,0.2,0.4,0.2,0.4,0.1)
> > aa<-matrix(w1,nrow=3,ncol=3)
> > aa
> >      [,1] [,2] [,3]
> > [1,]  0.4  0.4  0.4
> > [2,]  0.1  0.1  0.1
> > [3,]  0.2  0.2  0.2
> >
> > if i use this code
> > matrix(as.numeric(aa)[!as.numeric(aa) %in% diag(aa)],2,3)
> >
> > i will obtaine this matrix[,1] [,2] [,3]
> > [1,]   NA   NA   NA
> > [2,]   NA   NA   NA
> >
> > but me i want this matrix[,1] [,2] [,3]
> > [1,]  0.1  0.4  0.4
> > [2,]  0.2  0.2  0.1
> >
> > thank you
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:14}}


From rmh @ending from temple@edu  Wed Nov 14 23:32:56 2018
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Wed, 14 Nov 2018 17:32:56 -0500
Subject: [R] extrat non diagonal
In-Reply-To: <CAGx1TMDX-X0Me5CcRuj7brs-BLMVsPHvqh7pZqcfWo2Pv1BSdA@mail.gmail.com>
References: <79115083.696429.1542205441415.ref@mail.yahoo.com>
 <79115083.696429.1542205441415@mail.yahoo.com>
 <f55d001154f248bd87c5e04316bcf2c5@GBDCVPEXC04.corp.lgc-group.com>
 <CAGx1TMDX-X0Me5CcRuj7brs-BLMVsPHvqh7pZqcfWo2Pv1BSdA@mail.gmail.com>
Message-ID: <CAGx1TMBgcVxbn5LJZ1uVn=Ky9iLicE27DciHDr_tBdw1x57YcQ@mail.gmail.com>

An even better solution because it has fewer steps.

A <- matrix(1:9, 3, 3)
A
B <- A[-1, ]
B[upper.tri(B, diag=FALSE)] <- A[upper.tri(A)]
B

> A <- matrix(1:9, 3, 3)
> A
     [,1] [,2] [,3]
[1,]    1    4    7
[2,]    2    5    8
[3,]    3    6    9
> B <- A[-1, ]
> B[upper.tri(B, diag=FALSE)] <- A[upper.tri(A)]
> B
     [,1] [,2] [,3]
[1,]    2    4    7
[2,]    3    6    8
>
On Wed, Nov 14, 2018 at 2:09 PM Richard M. Heiberger <rmh at temple.edu> wrote:
>
> Steve's method is very slick.
>
> I think this is a bit easier to understand.
>
> A <- matrix(1:9, 3, 3)
> A
> B <- matrix(nrow=2, ncol=3)
> B[lower.tri(B, diag=TRUE)] <- A[lower.tri(A)]
> B[upper.tri(B, diag=FALSE)] <- A[upper.tri(A)]
> B
>
> > A <- matrix(1:9, 3, 3)
> > A
>      [,1] [,2] [,3]
> [1,]    1    4    7
> [2,]    2    5    8
> [3,]    3    6    9
> > B <- matrix(nrow=2, ncol=3)
> > B[lower.tri(B, diag=TRUE)] <- A[lower.tri(A)]
> > B[upper.tri(B, diag=FALSE)] <- A[upper.tri(A)]
> > B
>      [,1] [,2] [,3]
> [1,]    2    4    7
> [2,]    3    6    8
> >
> On Wed, Nov 14, 2018 at 11:04 AM S Ellison <S.Ellison at lgcgroup.com> wrote:
> >
> > i) Your code creates w2 but references w1 to create aa.
> >
> > So you needed
> > aa <- matrix(rep(c(0.4, 0.1, 0.2), 3), 3,3)
> > for a working example.
> >
> > ii) This
> > > matrix(as.numeric(aa)[!as.numeric(aa) %in% diag(aa)],2,3)
> > removes any value that is present in the diagonal of aa. Look up ?"%in%" to see what that does; it returns TRUE whenever anything in as.numeric(aa) matches anything in your diagonal. All the values in aa match one of c(0.4, 0.1, 0.2). So since your whole matrix consists of these three numbers, you told R to leave out everything in aa and then create a 2x3 matrix with the result. Hence the NAs
> >
> > iii) If you want to extract odd parts of a matrix explicitly, see ?"[" and particularly the section on indexing using arrays
> >
> > iv) You can use logical indexing. In the special case of the diagonal, you can use diag() to create a matrix of logicals, logically negate that and apply that to your matrix:
> > aa[ !diag(rep(TRUE, 3)) ]
> >
> > and, in twoi rows:
> > matrix( aa[ !diag(rep(TRUE, 3)) ], 2,3)
> >
> > > for examplei have this matrix
> > > w2<-c(0.1,0.2,0.4,0.2,0.4,0.1)
> > > aa<-matrix(w1,nrow=3,ncol=3)
> > > aa
> > >      [,1] [,2] [,3]
> > > [1,]  0.4  0.4  0.4
> > > [2,]  0.1  0.1  0.1
> > > [3,]  0.2  0.2  0.2
> > >
> > > if i use this code
> > > matrix(as.numeric(aa)[!as.numeric(aa) %in% diag(aa)],2,3)
> > >
> > > i will obtaine this matrix[,1] [,2] [,3]
> > > [1,]   NA   NA   NA
> > > [2,]   NA   NA   NA
> > >
> > > but me i want this matrix[,1] [,2] [,3]
> > > [1,]  0.1  0.4  0.4
> > > [2,]  0.2  0.2  0.1
> > >
> > > thank you
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > > guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > *******************************************************************
> > This email and any attachments are confidential. Any use, copying or
> > disclosure other than by the intended recipient is unauthorised. If
> > you have received this message in error, please notify the sender
> > immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com
> > and delete this message and any copies from your computer and network.
> > LGC Limited. Registered in England 2991879.
> > Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From wdunl@p @ending from tibco@com  Wed Nov 14 23:55:19 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Wed, 14 Nov 2018 14:55:19 -0800
Subject: [R] extrat non diagonal
In-Reply-To: <CAGx1TMBgcVxbn5LJZ1uVn=Ky9iLicE27DciHDr_tBdw1x57YcQ@mail.gmail.com>
References: <79115083.696429.1542205441415.ref@mail.yahoo.com>
 <79115083.696429.1542205441415@mail.yahoo.com>
 <f55d001154f248bd87c5e04316bcf2c5@GBDCVPEXC04.corp.lgc-group.com>
 <CAGx1TMDX-X0Me5CcRuj7brs-BLMVsPHvqh7pZqcfWo2Pv1BSdA@mail.gmail.com>
 <CAGx1TMBgcVxbn5LJZ1uVn=Ky9iLicE27DciHDr_tBdw1x57YcQ@mail.gmail.com>
Message-ID: <CAF8bMcbtW1nocj9nK1rVjVKquiJVKiRhkApOn=eoFCzgsMnNgw@mail.gmail.com>

Another way:

> A <- matrix(1:9,3,3,
dimnames=list(Row=paste0("r",1:3),Col=paste0("c",1:3)))
> A
    Col
Row  c1 c2 c3
  r1  1  4  7
  r2  2  5  8
  r3  3  6  9
> matrix( A[row(A)!=col(A)], nrow(A)-1, ncol(A), dimnames=list(NULL,
colnames(A)))
     c1 c2 c3
[1,]  2  4  7
[2,]  3  6  8


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Nov 14, 2018 at 2:32 PM, Richard M. Heiberger <rmh at temple.edu>
wrote:

> An even better solution because it has fewer steps.
>
> A <- matrix(1:9, 3, 3)
> A
> B <- A[-1, ]
> B[upper.tri(B, diag=FALSE)] <- A[upper.tri(A)]
> B
>
> > A <- matrix(1:9, 3, 3)
> > A
>      [,1] [,2] [,3]
> [1,]    1    4    7
> [2,]    2    5    8
> [3,]    3    6    9
> > B <- A[-1, ]
> > B[upper.tri(B, diag=FALSE)] <- A[upper.tri(A)]
> > B
>      [,1] [,2] [,3]
> [1,]    2    4    7
> [2,]    3    6    8
> >
> On Wed, Nov 14, 2018 at 2:09 PM Richard M. Heiberger <rmh at temple.edu>
> wrote:
> >
> > Steve's method is very slick.
> >
> > I think this is a bit easier to understand.
> >
> > A <- matrix(1:9, 3, 3)
> > A
> > B <- matrix(nrow=2, ncol=3)
> > B[lower.tri(B, diag=TRUE)] <- A[lower.tri(A)]
> > B[upper.tri(B, diag=FALSE)] <- A[upper.tri(A)]
> > B
> >
> > > A <- matrix(1:9, 3, 3)
> > > A
> >      [,1] [,2] [,3]
> > [1,]    1    4    7
> > [2,]    2    5    8
> > [3,]    3    6    9
> > > B <- matrix(nrow=2, ncol=3)
> > > B[lower.tri(B, diag=TRUE)] <- A[lower.tri(A)]
> > > B[upper.tri(B, diag=FALSE)] <- A[upper.tri(A)]
> > > B
> >      [,1] [,2] [,3]
> > [1,]    2    4    7
> > [2,]    3    6    8
> > >
> > On Wed, Nov 14, 2018 at 11:04 AM S Ellison <S.Ellison at lgcgroup.com>
> wrote:
> > >
> > > i) Your code creates w2 but references w1 to create aa.
> > >
> > > So you needed
> > > aa <- matrix(rep(c(0.4, 0.1, 0.2), 3), 3,3)
> > > for a working example.
> > >
> > > ii) This
> > > > matrix(as.numeric(aa)[!as.numeric(aa) %in% diag(aa)],2,3)
> > > removes any value that is present in the diagonal of aa. Look up
> ?"%in%" to see what that does; it returns TRUE whenever anything in
> as.numeric(aa) matches anything in your diagonal. All the values in aa
> match one of c(0.4, 0.1, 0.2). So since your whole matrix consists of these
> three numbers, you told R to leave out everything in aa and then create a
> 2x3 matrix with the result. Hence the NAs
> > >
> > > iii) If you want to extract odd parts of a matrix explicitly, see ?"["
> and particularly the section on indexing using arrays
> > >
> > > iv) You can use logical indexing. In the special case of the diagonal,
> you can use diag() to create a matrix of logicals, logically negate that
> and apply that to your matrix:
> > > aa[ !diag(rep(TRUE, 3)) ]
> > >
> > > and, in twoi rows:
> > > matrix( aa[ !diag(rep(TRUE, 3)) ], 2,3)
> > >
> > > > for examplei have this matrix
> > > > w2<-c(0.1,0.2,0.4,0.2,0.4,0.1)
> > > > aa<-matrix(w1,nrow=3,ncol=3)
> > > > aa
> > > >      [,1] [,2] [,3]
> > > > [1,]  0.4  0.4  0.4
> > > > [2,]  0.1  0.1  0.1
> > > > [3,]  0.2  0.2  0.2
> > > >
> > > > if i use this code
> > > > matrix(as.numeric(aa)[!as.numeric(aa) %in% diag(aa)],2,3)
> > > >
> > > > i will obtaine this matrix[,1] [,2] [,3]
> > > > [1,]   NA   NA   NA
> > > > [2,]   NA   NA   NA
> > > >
> > > > but me i want this matrix[,1] [,2] [,3]
> > > > [1,]  0.1  0.4  0.4
> > > > [2,]  0.2  0.2  0.1
> > > >
> > > > thank you
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > > > guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > > *******************************************************************
> > > This email and any attachments are confidential. Any use, copying or
> > > disclosure other than by the intended recipient is unauthorised. If
> > > you have received this message in error, please notify the sender
> > > immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com
> > > and delete this message and any copies from your computer and network.
> > > LGC Limited. Registered in England 2991879.
> > > Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@himk@poor @ending from gm@il@com  Thu Nov 15 06:58:33 2018
From: @@himk@poor @ending from gm@il@com (Ashim Kapoor)
Date: Thu, 15 Nov 2018 11:28:33 +0530
Subject: [R] Output of arima
In-Reply-To: <CAGgJW777iW7yFbpG=7JD8Sr3P+0MSmSBuv1axtGvWJVeEAuPeQ@mail.gmail.com>
References: <CAC8=1ervy1GgrW17FrzwOnYgEQJbiE16uiYH_DoCP4H4Ga-b8Q@mail.gmail.com>
 <CAF8bMcY7z_44w3Ja2a__jZnSqDqYqnFYLXygvVG03RFTjjicwA@mail.gmail.com>
 <CAC8=1eqbEbgx5Rs982uJM9fX9kYAt71KK=VHvDf9Y=tHhTGVFg@mail.gmail.com>
 <CAGgJW777iW7yFbpG=7JD8Sr3P+0MSmSBuv1axtGvWJVeEAuPeQ@mail.gmail.com>
Message-ID: <CAC8=1eoEMgRH_QTvt=wv03-eQENWwaXOBbXCQkZVzOHUEzrGDQ@mail.gmail.com>

Dear Eric,

Many thanks for your reply.

Best Regards,
Ashim

On Wed, Nov 14, 2018 at 4:05 PM Eric Berger <ericjberger at gmail.com> wrote:

> Hi Ashim,
> Per the help page for arima(), it fits an ARIMA model to the specified
> time series - but the caller has to specify the order - i.e. (p,d,q) - of
> the model.
> The default order is (0,0,0) (per the help page). Hence your two calls are
> different. The first call is equivalent to order=c(0,0,0) and the second
> specifies order=c(1,0,0).
> In the first, since there is no auto-regression, all the variance is
> "assigned" to the innovations, hence sigma^2 = 5.233.
> The second case you understand.
> A clue that this was happening is that the first call only returns a
> single coefficient (where is the autoregressive coefficient? - not there
> because you didn't ask for it).
> The second call returns two coefficients, as requested/expected.
>
> HTH,
> Eric
>
>
> On Wed, Nov 14, 2018 at 12:08 PM Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
>
>> Dear Eric and William,
>>
>> Why do the 1st and 2nd incantation of arima return sigma^2 as 5.233 vs
>> .9999?
>> The help for arima says  --->  sigma2: the MLE of the innovations
>> variance.
>> By that account the 1st result is incorrect. I am a little confused.
>>
>> set.seed(123)
>> b <- arima.sim(list(order = c(1,0,0),ar= .9),n=1000000,sd=1)
>>
>> # Variance of the innovations, e_t = 1
>>
>> # Variance of b = Var(e_t)/(1-Phi^2) = 1 / (1-.81) = 5.263158
>>
>> arima(b)
>>
>> > arima(b)
>>
>> Call:
>> arima(x = b)
>>
>> Coefficients:
>>       intercept
>>         -0.0051
>> s.e.     0.0023
>>
>> sigma^2 estimated as 5.233:  log likelihood = -2246450,  aic = 4492903
>> >
>>
>>
>> arima(b,order= c(1,0,0))
>>
>> Call:
>> arima(x = b, order = c(1, 0, 0))
>>
>> Coefficients:
>>          ar1  intercept
>>       0.8994    -0.0051
>> s.e.  0.0004     0.0099
>>
>> sigma^2 estimated as 0.9999:  log likelihood = -1418870,  aic = 2837747
>> >
>>
>> On Tue, Nov 13, 2018 at 11:07 PM William Dunlap <wdunlap at tibco.com>
>> wrote:
>>
>> > Try supplying the order argument to arima.  It looks like the default is
>> > to estimate only the mean.
>> >
>> > > arima(b, order=c(1,0,0))
>> >
>> > Call:
>> > arima(x = b, order = c(1, 0, 0))
>> >
>> > Coefficients:
>> >          ar1  intercept
>> >       0.8871     0.2369
>> > s.e.  0.0145     0.2783
>> >
>> > sigma^2 estimated as 1.002:  log likelihood = -1420.82,  aic = 2847.63
>> >
>> >
>> > Bill Dunlap
>> > TIBCO Software
>> > wdunlap tibco.com
>> >
>> > On Tue, Nov 13, 2018 at 4:02 AM, Ashim Kapoor <ashimkapoor at gmail.com>
>> > wrote:
>> >
>> >> Dear All,
>> >>
>> >> Here is a reprex:
>> >>
>> >> set.seed(123)
>> >> b <- arima.sim(list(order = c(1,0,0),ar= .9),n=1000,sd=1)
>> >> arima(b)
>> >>
>> >> Call:
>> >> arima(x = b)
>> >>
>> >> Coefficients:
>> >>       intercept
>> >>          0.2250
>> >> s.e.     0.0688
>> >>
>> >> sigma^2 estimated as 4.735:  log likelihood = -2196.4,  aic = 4396.81
>> >> >
>> >>
>> >> Should sigma^2 not be equal to 1 ? Where do I misunderstand ?
>> >>
>> >> Many thanks,
>> >> Ashim
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Thu Nov 15 12:46:48 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 15 Nov 2018 11:46:48 +0000
Subject: [R] glmutli package assistance please
Message-ID: <BN7PR02MB507331821C148180EEB4951CEADC0@BN7PR02MB5073.namprd02.prod.outlook.com>

Hi, I have removed the pdf which was causing my e-mail to be blocked by moderators, my apologies.

https://www.jstatsoft.org/article/view/v034i12/v34i12.pdf

Original post:

Hello. I am still trying to get some of the examples in this glmulti pdf to work with my data.

I have sent e-mails to author addresses provided but no response or bounced back as in valid.

I am not sure if this is more likely to receive support on r-help or r-sig-mixed-models, hence the double posting, my apologies in advance.

I am windows 10 -- R3.5.1 -- RStudio Version 1.1.456

glmulti: An R Package for Easy Automated Model Selection with (Generalized) Linear Models

pdf Attached:

On page 13 section 3.1 of the pdf they describe a routine to estimate the candidate models possible.

Their data description:
The number of levels factors have does not affect the number of candidate models, only their complexity. We use a data frame dod, containing as a first column a dummy response variable, the next 6 columns are dummy factors with three levels, and the last six are dummy covariates.
To compute the number of candidate models when there are between 1 and 6 factors and 1 and 6 covariates, we call glmulti with method = "d" and data = dod. We use names(dod) to specify the names of the response variable and of the predictors. We vary the number of factors and covariates, this way:


Their routine:
dd <- matrix(nc = 6, nr = 6) for(i in 1:6) for(j in 1:6) dd[i, j] <- glmulti(names(dod)[1],
+ names(dod)[c(2:(1 + i), 8:(7 + j))], data = dod, method = "d")

My data, I organized it similar to the example, Response, Factor, Factor, 5 covariates

Classes 'data.table' and 'data.frame':23141 obs. of  8 variables:
 $ Editnumber2    : num  0 0 1 1 1 1 1 1 1 1 ...
 $ PatientGender  : Factor w/ 3 levels "F","M","U": 1 1 2 2 2 2 1 1 1 1 ...
 $ B1             : Factor w/ 14 levels "Z","A","C","D",..: 2 2 3 3 2 2 2 2 2 2 ...
 $ SavingsReversed: num  -0.139 -0.139 -0.139 -0.139 -0.139 ...
 $ productID      : int  3 3 3 3 3 3 3 3 1 1 ...
 $ ProviderID     : int  113676 113676 113964 113964 114278 114278 114278 114278 114278 114278 ...
 $ ModCnt         : int  0 0 0 0 1 1 1 1 1 1 ...
 $ B2             : num  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
 - attr(*, ".internal.selfref")=<externalptr>

Trying to follow what they did, my routine, Editnumber2 is the response variable:

dd <- matrix(nc = 2, nr = 5)
for(i in 1:2) for(j in 1:5) dd[i, j] <- glmulti(names(r1)[1], names(r1)[c(2:(1 + i), 7:(6 + j))], data = r1, method = "d")

The error: Error in terms.formula(formula, data = data) :
  invalid model formula in ExtractVars

I have tried changing the numbers around but get results like this:

Initialization...
TASK: Diagnostic of candidate set.
Sample size: 23141
2 factor(s).
2 covariate(s). <--appears to be missing 3 of the covariates for some reason?
0 f exclusion(s).
0 c exclusion(s).
0 f:f exclusion(s).
0 c:c exclusion(s).
0 f:c exclusion(s).
Size constraints: min =  0 max = -1
Complexity constraints: min =  0 max = -1 Your candidate set contains 250 models.
Error in `[<-`(`*tmp*`, i, j, value = glmulti(names(r1)[1], names(r1)[c(2:(1 +  :
  subscript out of bounds


I hope someone can help straighten out my code, thank you.


WHP



Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From li@t@ @ending from dewey@myzen@co@uk  Thu Nov 15 13:24:13 2018
From: li@t@ @ending from dewey@myzen@co@uk (Michael Dewey)
Date: Thu, 15 Nov 2018 12:24:13 +0000
Subject: [R] glmutli package assistance please
In-Reply-To: <BN7PR02MB507331821C148180EEB4951CEADC0@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB507331821C148180EEB4951CEADC0@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <faa912fb-7ed3-3a81-7a9f-8193d0f262d7@dewey.myzen.co.uk>

Dear Bill

I am not sure what is going on here but I notice that 2 of your 
covariates are numeric and 3 integer. What happens if you make them all 
numeric?

Michael

On 15/11/2018 11:46, Bill Poling wrote:
> Hi, I have removed the pdf which was causing my e-mail to be blocked by moderators, my apologies.
> 
> https://www.jstatsoft.org/article/view/v034i12/v34i12.pdf
> 
> Original post:
> 
> Hello. I am still trying to get some of the examples in this glmulti pdf to work with my data.
> 
> I have sent e-mails to author addresses provided but no response or bounced back as in valid.
> 
> I am not sure if this is more likely to receive support on r-help or r-sig-mixed-models, hence the double posting, my apologies in advance.
> 
> I am windows 10 -- R3.5.1 -- RStudio Version 1.1.456
> 
> glmulti: An R Package for Easy Automated Model Selection with (Generalized) Linear Models
> 
> pdf Attached:
> 
> On page 13 section 3.1 of the pdf they describe a routine to estimate the candidate models possible.
> 
> Their data description:
> The number of levels factors have does not affect the number of candidate models, only their complexity. We use a data frame dod, containing as a first column a dummy response variable, the next 6 columns are dummy factors with three levels, and the last six are dummy covariates.
> To compute the number of candidate models when there are between 1 and 6 factors and 1 and 6 covariates, we call glmulti with method = "d" and data = dod. We use names(dod) to specify the names of the response variable and of the predictors. We vary the number of factors and covariates, this way:
> 
> 
> Their routine:
> dd <- matrix(nc = 6, nr = 6) for(i in 1:6) for(j in 1:6) dd[i, j] <- glmulti(names(dod)[1],
> + names(dod)[c(2:(1 + i), 8:(7 + j))], data = dod, method = "d")
> 
> My data, I organized it similar to the example, Response, Factor, Factor, 5 covariates
> 
> Classes 'data.table' and 'data.frame':23141 obs. of  8 variables:
>   $ Editnumber2    : num  0 0 1 1 1 1 1 1 1 1 ...
>   $ PatientGender  : Factor w/ 3 levels "F","M","U": 1 1 2 2 2 2 1 1 1 1 ...
>   $ B1             : Factor w/ 14 levels "Z","A","C","D",..: 2 2 3 3 2 2 2 2 2 2 ...
>   $ SavingsReversed: num  -0.139 -0.139 -0.139 -0.139 -0.139 ...
>   $ productID      : int  3 3 3 3 3 3 3 3 1 1 ...
>   $ ProviderID     : int  113676 113676 113964 113964 114278 114278 114278 114278 114278 114278 ...
>   $ ModCnt         : int  0 0 0 0 1 1 1 1 1 1 ...
>   $ B2             : num  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
>   - attr(*, ".internal.selfref")=<externalptr>
> 
> Trying to follow what they did, my routine, Editnumber2 is the response variable:
> 
> dd <- matrix(nc = 2, nr = 5)
> for(i in 1:2) for(j in 1:5) dd[i, j] <- glmulti(names(r1)[1], names(r1)[c(2:(1 + i), 7:(6 + j))], data = r1, method = "d")
> 
> The error: Error in terms.formula(formula, data = data) :
>    invalid model formula in ExtractVars
> 
> I have tried changing the numbers around but get results like this:
> 
> Initialization...
> TASK: Diagnostic of candidate set.
> Sample size: 23141
> 2 factor(s).
> 2 covariate(s). <--appears to be missing 3 of the covariates for some reason?
> 0 f exclusion(s).
> 0 c exclusion(s).
> 0 f:f exclusion(s).
> 0 c:c exclusion(s).
> 0 f:c exclusion(s).
> Size constraints: min =  0 max = -1
> Complexity constraints: min =  0 max = -1 Your candidate set contains 250 models.
> Error in `[<-`(`*tmp*`, i, j, value = glmulti(names(r1)[1], names(r1)[c(2:(1 +  :
>    subscript out of bounds
> 
> 
> I hope someone can help straighten out my code, thank you.
> 
> 
> WHP
> 
> 
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From tr@xpl@yer @ending from gm@il@com  Thu Nov 15 13:44:05 2018
From: tr@xpl@yer @ending from gm@il@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Thu, 15 Nov 2018 13:44:05 +0100
Subject: [R] very slow "memoise"
Message-ID: <CAGAA5beZ-x2jJrOiO+59kjjnYa1HMLFyng2SRNUZtHLPC3dWXA@mail.gmail.com>

Hi,

  I want to compute a lot of values and I have tried to use
memoise::memoise to speed-up the computation.
  However it is much slower using the memoised version.

I guess I have misunderstood how to use the package memoise or the
purpose of the package.

The code takes more than 2 minutes to finish but if I remove the line:
"nextstep <- memoise(nextstep)" the code runs in less than 1 second. I
was expecting a
total different result.

Here are the code:

library(memoise)

nextstep <- function(num) {
    if (num %% 2 == 0) {
        return(num/2)
    }
    num*3+1
}

nextstep <- memoise(nextstep)

for (idx in 1:1e4) {
    steps <- 0
    current <- idx
    while (current != 1) {
      steps <- steps + 1
      current <- nextstep(current)
    }
    cat(idx,steps,"\n")
}


Regards
Martin


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Nov 15 15:22:59 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 15 Nov 2018 06:22:59 -0800
Subject: [R] very slow "memoise"
In-Reply-To: <CAGAA5beZ-x2jJrOiO+59kjjnYa1HMLFyng2SRNUZtHLPC3dWXA@mail.gmail.com>
References: <CAGAA5beZ-x2jJrOiO+59kjjnYa1HMLFyng2SRNUZtHLPC3dWXA@mail.gmail.com>
Message-ID: <029BD16D-8D1C-46A4-97F9-05CBBB0E3EBF@dcn.davis.ca.us>

Yes, you have misunderstood what memoise is for.

First, it is for when you call your function with the same inputs frequently as part of your calling-level algorithm. For your iterative calculation you would have  a stuck (cycling) process if the same value of current were  to be revisited... ever.

Second, it is for when your nextstep function is very slow to compute, since the memoisation process is non-trivial... certainly it takes much more work to keep the previous results around than your example nextstep algorithm would take to simply recompute the answer.

On November 15, 2018 4:44:05 AM PST, "Martin M?ller Skarbiniks Pedersen" <traxplayer at gmail.com> wrote:
>Hi,
>
>  I want to compute a lot of values and I have tried to use
>memoise::memoise to speed-up the computation.
>  However it is much slower using the memoised version.
>
>I guess I have misunderstood how to use the package memoise or the
>purpose of the package.
>
>The code takes more than 2 minutes to finish but if I remove the line:
>"nextstep <- memoise(nextstep)" the code runs in less than 1 second. I
>was expecting a
>total different result.
>
>Here are the code:
>
>library(memoise)
>
>nextstep <- function(num) {
>    if (num %% 2 == 0) {
>        return(num/2)
>    }
>    num*3+1
>}
>
>nextstep <- memoise(nextstep)
>
>for (idx in 1:1e4) {
>    steps <- 0
>    current <- idx
>    while (current != 1) {
>      steps <- steps + 1
>      current <- nextstep(current)
>    }
>    cat(idx,steps,"\n")
>}
>
>
>Regards
>Martin
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From i@t@z@hn @ending from gm@il@com  Thu Nov 15 15:53:50 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Thu, 15 Nov 2018 09:53:50 -0500
Subject: [R] 
 Corrupting files while copying (was Re: saveRDS() and readRDS()
 Why? [solved, pretty much anyway])
In-Reply-To: <20181114073555.GI8540@slingshot.co.nz>
References: <23524.2724.270930.705139@stat.math.ethz.ch>
 <20181110074834.GG8540@slingshot.co.nz>
 <20181112072806.GH8540@slingshot.co.nz>
 <9795CBFC-5F8C-4084-9704-98614BA2A626@gmail.com>
 <46f6c0217cf594e544eef3257376d598@slingshot.co.nz>
 <CAF8bMcaejV7GdwwFFB7fro2AHD9FfqHJ2J26EZG56kyQ08UP=A@mail.gmail.com>
 <3b49eb752bb2b108a72683df1d30f50b@slingshot.co.nz>
 <CAF8bMcYaXYB=PAZ9D2sDHqP1oH2To8u4A1EMrk0EGGdLdCMb=g@mail.gmail.com>
 <d036a9b8893a1ade51c78e7325d8c89b@slingshot.co.nz>
 <CAF8bMcY_fauLbmKNY-yb0JJJu2c-Oz0tngHhHkdyFwo7ajVDyg@mail.gmail.com>
 <20181114073555.GI8540@slingshot.co.nz>
Message-ID: <CA+vqiLE2D2R-AYfNA8EPZFPtxuwnUcsCCuADTqCq8c=0xeVPng@mail.gmail.com>

Hi Patrick,

I think it would help to start from the beginning and give complete
(but concise!) replication instructions, including telling us what
host and gest operating systems you are using (including the
versions), the version
 of virtualbox you used, and exactly what steps are needed to
reproduce the surprising behavior.

Best,
Ista
On Wed, Nov 14, 2018 at 2:36 AM Patrick Connolly
<p_connolly at slingshot.co.nz> wrote:
>
> Thanks William,
>
> I've used Dolphin for years and never encountered that phenomenon.
> Even so, that description doesn't fit what's going on here.  1.7
> kilobytes is hardly a 'large directory'.
>
> The problem seems to be with the way VirtualBox mounts directories
> which isn't an R issue, nor is the fact that copying from Linux to
> Windows isn't affected.  But the fact that it happens only with rds
> files that use the name of the R object as part of their own names
> must be an R issue (that surfaces only when other conditions are
> present).
>
> Theories short of divine intervention appreciated.
>
>
>
> On Tue, 13-Nov-2018 at 02:22PM -0800, William Dunlap wrote:
>
> |> Perhaps you got bitten by Dolphin's non-modal dialogs, as described in
> |> https://userbase.kde.org/Dolphin/File_Management:
> |>
> |> Non Modal Dialogs
> |>
> |> When Moving, Copying or Deleting files/directories the dialog disappears
> |> even when the operation has not yet completed. A progress bar then appears
> |> in the bottom right of the screen, this then disappears also, if you want
> |> see the progress you need to click a small (i) information icon in the
> |> system tray.
> |>
> |>
> |> Warning
> |> New users who are not used to this way of working (and even experienced
> |> users) can get caught out by this, if you are Moving, Copying or Deleting
> |> large directories then you need to use the icon to monitor the progress of
> |> your operation. If you don't then any subsequent actions you do, may well
> |> use an incomplete file structure resulting in corrupted files. You have
> |> been warned!
> |>
> |> Bill Dunlap
> |> TIBCO Software
> |> wdunlap tibco.com
> |>
> |> On Tue, Nov 13, 2018 at 2:10 PM, p_connolly <p_connolly at slingshot.co.nz>
> |> wrote:
> |>
> |> > This is getting more strange.
> |> >
> |> > I normally copy from the shared folder to the appropriate directory using
> |> > Dolphin, the KDE file manager.  If instead I use the standard bash cp
> |> > command, no corruption happens -- at least with the limited testing I have
> |> > done.  There also seems to be no problem copying from Linux to Windows.  I
> |> > installed R-3.5.1 for Windows just to eliminate that possible issue.
> |> >
> |> > However, R has *something* to do with it because it was used to make the
> |> > .rds file.  Just how the relationship between the name of the R object and
> |> > the name of the .rds file comes into it, I can't imagine.
> |> >
> |> > Thanks for the suggestion William.
> |> >
> |> >
> |> > On 2018-11-14 06:26, William Dunlap wrote:
> |> >
> |> >> It seems like copying the files corrupted them. How did you copy them
> |> >> (with R
> |> >> or cp or copy or ftp, etc.)?  I don't see how this has anything to do
> |> >> with R.
> |> >>
> |> >> Bill Dunlap
> |> >> TIBCO Software
> |> >> wdunlap tibco.com [1]
> |> >> On Mon, Nov 12, 2018 at 7:10 PM, p_connolly
> |> >> <p_connolly at slingshot.co.nz> wrote:
> |> >>
> |> > [...]
> |> >
> |> >
>
> --
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>    ___    Patrick Connolly
>  {~._.~}                   Great minds discuss ideas
>  _( Y )_                 Average minds discuss events
> (:_~*~_:)                  Small minds discuss people
>  (_)-(_)                              ..... Eleanor Roosevelt
>
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dc@rl@on @ending from t@mu@edu  Thu Nov 15 15:57:47 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Thu, 15 Nov 2018 14:57:47 +0000
Subject: [R] How to create gridded data
In-Reply-To: <CAN5afy-Ts_3fUmTptkCXxTpxRVe5z-Jk07RmxtfO=JaV6phkNg@mail.gmail.com>
References: <CAN5afy9jzOCZDzvTuzXBzeTzi_aZLsnVnYM1VuBWe0e5ziUWsQ@mail.gmail.com>
 <CAM_vjumM-nNbQBp-6vRbFKqWHpap9SQxwPBqsfkAs0+-XNj_tA@mail.gmail.com>
 <966004e209f949dba2ccf205bcef9983@tamu.edu>
 <CAN5afy-Ts_3fUmTptkCXxTpxRVe5z-Jk07RmxtfO=JaV6phkNg@mail.gmail.com>
Message-ID: <ca572c18ecad45eba5e74225c33f29f3@tamu.edu>

It would depend on the format of the gridded data. Assuming it is a data frame like DF2 in my earlier answer, you just reverse the steps:

> DF2
     110.5 111 111.5 112
46     6.1 4.5   7.8 5.5
45.5   3.2 5.0   1.8 2.0

> DF3 <- data.frame(as.table(as.matrix(DF2)))
  Var1  Var2 Freq
1   46 110.5  6.1
2 45.5 110.5  3.2
3   46   111  4.5
4 45.5   111  5.0
5   46 111.5  7.8
6 45.5 111.5  1.8
7   46   112  5.5
8 45.5   112  2.0

But the latitude and longitude get converted to factors and we lose the column names:

> DF3 <- data.frame(as.table(as.matrix(DF2)))
> colnames(DF3) <- c("latitude", "longitude", "Precip")
> DF3$latitude <- as.numeric(as.character(DF3$latitude))
> DF3$longitude <- as.numeric(as.character(DF3$longitude))

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

From: lily li <chocold12 at gmail.com> 
Sent: Tuesday, November 13, 2018 10:50 PM
To: David L Carlson <dcarlson at tamu.edu>
Cc: Sarah Goslee <sarah.goslee at gmail.com>; R mailing list <r-help at r-project.org>
Subject: Re: [R] How to create gridded data

Thanks, Sarah's answer helps the question. Now how to change the gridded data back to DF1 format? I don't know how to name the format, thanks.

On Tue, Nov 13, 2018 at 10:56 PM David L Carlson <mailto:dcarlson at tamu.edu> wrote:
Sarah's answer is probably better depending on what you want to do with the resulting data, but here's a way to go from your original DF1 to DF2:

> DF1 <- structure(list(latitude = c(45.5, 45.5, 45.5, 45.5, 46, 46, 46, 
+? ? ? ? ?46), longitude = c(110.5, 111, 111.5, 112, 110.5, 111, 111.5, 
+? ? ? ? ?112), Precip = c(3.2, 5, 1.8, 2, 6.1, 4.5, 7.8, 5.5)),
+? ? ? ? ?class = "data.frame", row.names = c(NA, -8L))
> 
# Convert to table with xtabs()
> DF2 <- xtabs(Precip~latitude+longitude, DF1)
> 

# Reverse the order of the latitudes
> DF2 <- DF2[rev(rownames(DF2)), ]
> DF2
? ? ? ? longitude
latitude 110.5 111 111.5 112
? ? 46? ? ?6.1 4.5? ?7.8 5.5
? ? 45.5? ?3.2 5.0? ?1.8 2.0

# Convert to a data frame
> DF2 <- as.data.frame.matrix(DF2)
> DF2
? ? ?110.5 111 111.5 112
46? ? ?6.1 4.5? ?7.8 5.5
45.5? ?3.2 5.0? ?1.8 2.0

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352


-----Original Message-----
From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of Sarah Goslee
Sent: Tuesday, November 13, 2018 8:16 AM
To: lily li <mailto:chocold12 at gmail.com>
Cc: r-help <mailto:r-help at r-project.org>
Subject: Re: [R] How to create gridded data

If you want an actual spatial dataset, the best place to ask is R-sig-geo

R has substantial capabilities for dealing with gridded spatial data,
including in the sp, raster, and sf packages.

Here's one approach, creating a SpatialGridDataFrame, which can be
exported in any standard raster format using the rgdal package.

DF2 <- DF1
coordinates(DF2) <- ~longitude + latitude
gridded(DF2) <- TRUE
fullgrid(DF2) <- TRUE

I recommend Roger Bivand's excellent book:
https://urldefense.proofpoint.com/v2/url?u=https-3A__www.springer.com_us_book_9781461476177&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=vZqNKoDe8N1TzBzeK12g2oa0cBS8VD6NDCs-hUhvt5o&s=B73PwZQrdKUmM1ML2Y5zjaEz7xqkHlzBDCrhluogK2U&e=

and there are abundant web tutorials.

Sarah
On Tue, Nov 13, 2018 at 2:22 AM lily li <mailto:chocold12 at gmail.com> wrote:
>
> Hi R users,
>
> I have a question about manipulating data. For example, I have DF1 as the
> following, how to transform it to a gridded dataset DF2? In DF2, each value
> Precip is an attribute of the corresponding grid cell. So DF2 is like a
> spatial surface, and can be imported to ArcGIS. Thanks for your help.
>
> DF1
> latitude? ?longitude? ?Precip
> 45.5? ? ? ? ? ?110.5? ? ? ? ?3.2
> 45.5? ? ? ? ? ?111? ? ? ? ? ? 5.0
> 45.5? ? ? ? ? ?111.5? ? ? ? ?1.8
> 45.5? ? ? ? ? ?112? ? ? ? ? ? 2.0
> 46? ? ? ? ? ? ? 110.5? ? ? ? ?6.1
> 46? ? ? ? ? ? ? 111? ? ? ? ? ? 4.5
> 46? ? ? ? ? ? ? 111.5? ? ? ? ?7.8
> 46? ? ? ? ? ? ? 112? ? ? ? ? ? 5.5
> ...
>
>
> DF2
> 6.1? ?4.5? ?7.8? ?5.5
> 3.2? ?5.0? ?1.8? ?2.0
> ...
>


-- 
Sarah Goslee (she/her)
https://urldefense.proofpoint.com/v2/url?u=http-3A__www.numberwright.com&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=vZqNKoDe8N1TzBzeK12g2oa0cBS8VD6NDCs-hUhvt5o&s=qSosThG59aeSFYzVFf1e-YQGbuBKVbvgVi1z9nFm884&e=

______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=vZqNKoDe8N1TzBzeK12g2oa0cBS8VD6NDCs-hUhvt5o&s=2pS9yFu5bpcRyCi1vX_OEDD2Ie8ZihvOQrkDQSNu8RM&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=vZqNKoDe8N1TzBzeK12g2oa0cBS8VD6NDCs-hUhvt5o&s=1brzEOjZ4EUr_llqwyO274DfJfsOpRBI-pmd-hp0WAQ&e=
and provide commented, minimal, self-contained, reproducible code.

From ch@l@bi@el@he @ending from y@hoo@de  Thu Nov 15 16:14:02 2018
From: ch@l@bi@el@he @ending from y@hoo@de (Elahe chalabi)
Date: Thu, 15 Nov 2018 15:14:02 +0000 (UTC)
Subject: [R] create a heatmap for findAssocs results based on time
References: <1328068918.1880331.1542294842233.ref@mail.yahoo.com>
Message-ID: <1328068918.1880331.1542294842233@mail.yahoo.com>

Hi all, 

I have the following data for which I create a document term matrix first and then I add the time available to the dtm. In order to see the correlations to the term "updat" in the different years, I would like to have a heat-map for findassoc in a way that x-axis shows the time. 


  
> library(tm)  
library(ggplot2)
  > dput(df) 
structure(list(Description = structure(c(5L, 8L, 6L, 4L, 1L, 
2L, 7L, 9L, 10L, 3L), .Label = c("general topics done", "keep the general topics updated", 
"rejected topic ", "several topics in hand", "this is a genetal topic", 
"topic 333555 needs to be updated", "topic 5647 is handed over", 
"topic is updated", "update the topic ", "updating the topic is done " 
), class = "factor")), class = "data.frame", row.names = c(NA, 
-10L))
> corpus=Corpus(VectorSource(df$Description)) 
> corpus=tm_map(corpus,tolower)
> corpus=tm_map(corpus,removePunctuation)
corpus=tm_map(corpus,removeWords,c(stopwords("english")))
> corpus=tm_map(corpus,stemDocument,"english")
> frequenciescontrol=DocumentTermMatrix(corpus)
frequenciescontrol$time=c("2015","2015","2015","2015","2015","2016","2016","2016","2016","2016")
findAssocs(frequenciescontrol, "updat", 0.01)


Heatmap looking: y axis-> all the words correlated to "updat"      x axis: years               legend:correlation  

Thanks for any help.
Elahe!


From bgunter@4567 @ending from gm@il@com  Thu Nov 15 16:43:00 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 15 Nov 2018 07:43:00 -0800
Subject: [R] glmutli package assistance please
In-Reply-To: <BN7PR02MB507331821C148180EEB4951CEADC0@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB507331821C148180EEB4951CEADC0@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbSVZaUeubfuxdbk1JSESg2sZFNDR9hT=DDU52y18zJqrQ@mail.gmail.com>

Please do not cross post (see te posting guide). This should go only
to the mixed models list.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Nov 15, 2018 at 3:47 AM Bill Poling <Bill.Poling at zelis.com> wrote:
>
> Hi, I have removed the pdf which was causing my e-mail to be blocked by moderators, my apologies.
>
> https://www.jstatsoft.org/article/view/v034i12/v34i12.pdf
>
> Original post:
>
> Hello. I am still trying to get some of the examples in this glmulti pdf to work with my data.
>
> I have sent e-mails to author addresses provided but no response or bounced back as in valid.
>
> I am not sure if this is more likely to receive support on r-help or r-sig-mixed-models, hence the double posting, my apologies in advance.
>
> I am windows 10 -- R3.5.1 -- RStudio Version 1.1.456
>
> glmulti: An R Package for Easy Automated Model Selection with (Generalized) Linear Models
>
> pdf Attached:
>
> On page 13 section 3.1 of the pdf they describe a routine to estimate the candidate models possible.
>
> Their data description:
> The number of levels factors have does not affect the number of candidate models, only their complexity. We use a data frame dod, containing as a first column a dummy response variable, the next 6 columns are dummy factors with three levels, and the last six are dummy covariates.
> To compute the number of candidate models when there are between 1 and 6 factors and 1 and 6 covariates, we call glmulti with method = "d" and data = dod. We use names(dod) to specify the names of the response variable and of the predictors. We vary the number of factors and covariates, this way:
>
>
> Their routine:
> dd <- matrix(nc = 6, nr = 6) for(i in 1:6) for(j in 1:6) dd[i, j] <- glmulti(names(dod)[1],
> + names(dod)[c(2:(1 + i), 8:(7 + j))], data = dod, method = "d")
>
> My data, I organized it similar to the example, Response, Factor, Factor, 5 covariates
>
> Classes 'data.table' and 'data.frame':23141 obs. of  8 variables:
>  $ Editnumber2    : num  0 0 1 1 1 1 1 1 1 1 ...
>  $ PatientGender  : Factor w/ 3 levels "F","M","U": 1 1 2 2 2 2 1 1 1 1 ...
>  $ B1             : Factor w/ 14 levels "Z","A","C","D",..: 2 2 3 3 2 2 2 2 2 2 ...
>  $ SavingsReversed: num  -0.139 -0.139 -0.139 -0.139 -0.139 ...
>  $ productID      : int  3 3 3 3 3 3 3 3 1 1 ...
>  $ ProviderID     : int  113676 113676 113964 113964 114278 114278 114278 114278 114278 114278 ...
>  $ ModCnt         : int  0 0 0 0 1 1 1 1 1 1 ...
>  $ B2             : num  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
>  - attr(*, ".internal.selfref")=<externalptr>
>
> Trying to follow what they did, my routine, Editnumber2 is the response variable:
>
> dd <- matrix(nc = 2, nr = 5)
> for(i in 1:2) for(j in 1:5) dd[i, j] <- glmulti(names(r1)[1], names(r1)[c(2:(1 + i), 7:(6 + j))], data = r1, method = "d")
>
> The error: Error in terms.formula(formula, data = data) :
>   invalid model formula in ExtractVars
>
> I have tried changing the numbers around but get results like this:
>
> Initialization...
> TASK: Diagnostic of candidate set.
> Sample size: 23141
> 2 factor(s).
> 2 covariate(s). <--appears to be missing 3 of the covariates for some reason?
> 0 f exclusion(s).
> 0 c exclusion(s).
> 0 f:f exclusion(s).
> 0 c:c exclusion(s).
> 0 f:c exclusion(s).
> Size constraints: min =  0 max = -1
> Complexity constraints: min =  0 max = -1 Your candidate set contains 250 models.
> Error in `[<-`(`*tmp*`, i, j, value = glmulti(names(r1)[1], names(r1)[c(2:(1 +  :
>   subscript out of bounds
>
>
> I hope someone can help straighten out my code, thank you.
>
>
> WHP
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From li@t@ @ending from dewey@myzen@co@uk  Thu Nov 15 16:52:48 2018
From: li@t@ @ending from dewey@myzen@co@uk (Michael Dewey)
Date: Thu, 15 Nov 2018 15:52:48 +0000
Subject: [R] glmutli package assistance please
In-Reply-To: <CAGxFJbSVZaUeubfuxdbk1JSESg2sZFNDR9hT=DDU52y18zJqrQ@mail.gmail.com>
References: <BN7PR02MB507331821C148180EEB4951CEADC0@BN7PR02MB5073.namprd02.prod.outlook.com>
 <CAGxFJbSVZaUeubfuxdbk1JSESg2sZFNDR9hT=DDU52y18zJqrQ@mail.gmail.com>
Message-ID: <626a2e4a-93ef-b4bf-83b8-5b2424c974c6@dewey.myzen.co.uk>

Dear Bert

Since glmulti operates on glm/lm models I think, although I agree about 
not cross-posting, that it was OK here. Perhaps I do not understand the 
full significance of mixed models though.

Michael

On 15/11/2018 15:43, Bert Gunter wrote:
> Please do not cross post (see te posting guide). This should go only
> to the mixed models list.
> 
> -- Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Thu, Nov 15, 2018 at 3:47 AM Bill Poling <Bill.Poling at zelis.com> wrote:
>>
>> Hi, I have removed the pdf which was causing my e-mail to be blocked by moderators, my apologies.
>>
>> https://www.jstatsoft.org/article/view/v034i12/v34i12.pdf
>>
>> Original post:
>>
>> Hello. I am still trying to get some of the examples in this glmulti pdf to work with my data.
>>
>> I have sent e-mails to author addresses provided but no response or bounced back as in valid.
>>
>> I am not sure if this is more likely to receive support on r-help or r-sig-mixed-models, hence the double posting, my apologies in advance.
>>
>> I am windows 10 -- R3.5.1 -- RStudio Version 1.1.456
>>
>> glmulti: An R Package for Easy Automated Model Selection with (Generalized) Linear Models
>>
>> pdf Attached:
>>
>> On page 13 section 3.1 of the pdf they describe a routine to estimate the candidate models possible.
>>
>> Their data description:
>> The number of levels factors have does not affect the number of candidate models, only their complexity. We use a data frame dod, containing as a first column a dummy response variable, the next 6 columns are dummy factors with three levels, and the last six are dummy covariates.
>> To compute the number of candidate models when there are between 1 and 6 factors and 1 and 6 covariates, we call glmulti with method = "d" and data = dod. We use names(dod) to specify the names of the response variable and of the predictors. We vary the number of factors and covariates, this way:
>>
>>
>> Their routine:
>> dd <- matrix(nc = 6, nr = 6) for(i in 1:6) for(j in 1:6) dd[i, j] <- glmulti(names(dod)[1],
>> + names(dod)[c(2:(1 + i), 8:(7 + j))], data = dod, method = "d")
>>
>> My data, I organized it similar to the example, Response, Factor, Factor, 5 covariates
>>
>> Classes 'data.table' and 'data.frame':23141 obs. of  8 variables:
>>   $ Editnumber2    : num  0 0 1 1 1 1 1 1 1 1 ...
>>   $ PatientGender  : Factor w/ 3 levels "F","M","U": 1 1 2 2 2 2 1 1 1 1 ...
>>   $ B1             : Factor w/ 14 levels "Z","A","C","D",..: 2 2 3 3 2 2 2 2 2 2 ...
>>   $ SavingsReversed: num  -0.139 -0.139 -0.139 -0.139 -0.139 ...
>>   $ productID      : int  3 3 3 3 3 3 3 3 1 1 ...
>>   $ ProviderID     : int  113676 113676 113964 113964 114278 114278 114278 114278 114278 114278 ...
>>   $ ModCnt         : int  0 0 0 0 1 1 1 1 1 1 ...
>>   $ B2             : num  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
>>   - attr(*, ".internal.selfref")=<externalptr>
>>
>> Trying to follow what they did, my routine, Editnumber2 is the response variable:
>>
>> dd <- matrix(nc = 2, nr = 5)
>> for(i in 1:2) for(j in 1:5) dd[i, j] <- glmulti(names(r1)[1], names(r1)[c(2:(1 + i), 7:(6 + j))], data = r1, method = "d")
>>
>> The error: Error in terms.formula(formula, data = data) :
>>    invalid model formula in ExtractVars
>>
>> I have tried changing the numbers around but get results like this:
>>
>> Initialization...
>> TASK: Diagnostic of candidate set.
>> Sample size: 23141
>> 2 factor(s).
>> 2 covariate(s). <--appears to be missing 3 of the covariates for some reason?
>> 0 f exclusion(s).
>> 0 c exclusion(s).
>> 0 f:f exclusion(s).
>> 0 c:c exclusion(s).
>> 0 f:c exclusion(s).
>> Size constraints: min =  0 max = -1
>> Complexity constraints: min =  0 max = -1 Your candidate set contains 250 models.
>> Error in `[<-`(`*tmp*`, i, j, value = glmulti(names(r1)[1], names(r1)[c(2:(1 +  :
>>    subscript out of bounds
>>
>>
>> I hope someone can help straighten out my code, thank you.
>>
>>
>> WHP
>>
>>
>>
>> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From bgunter@4567 @ending from gm@il@com  Thu Nov 15 17:03:09 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 15 Nov 2018 08:03:09 -0800
Subject: [R] glmutli package assistance please
In-Reply-To: <626a2e4a-93ef-b4bf-83b8-5b2424c974c6@dewey.myzen.co.uk>
References: <BN7PR02MB507331821C148180EEB4951CEADC0@BN7PR02MB5073.namprd02.prod.outlook.com>
 <CAGxFJbSVZaUeubfuxdbk1JSESg2sZFNDR9hT=DDU52y18zJqrQ@mail.gmail.com>
 <626a2e4a-93ef-b4bf-83b8-5b2424c974c6@dewey.myzen.co.uk>
Message-ID: <CAGxFJbQRYW8uR=R+K1cM46XmyVima0BcDHynwYd9iS42GdGSEg@mail.gmail.com>

OK. Then post here but *not* on mixed models list. One or the other,
exclusive or.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Nov 15, 2018 at 7:52 AM Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>
> Dear Bert
>
> Since glmulti operates on glm/lm models I think, although I agree about
> not cross-posting, that it was OK here. Perhaps I do not understand the
> full significance of mixed models though.
>
> Michael
>
> On 15/11/2018 15:43, Bert Gunter wrote:
> > Please do not cross post (see te posting guide). This should go only
> > to the mixed models list.
> >
> > -- Bert
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Thu, Nov 15, 2018 at 3:47 AM Bill Poling <Bill.Poling at zelis.com> wrote:
> >>
> >> Hi, I have removed the pdf which was causing my e-mail to be blocked by moderators, my apologies.
> >>
> >> https://www.jstatsoft.org/article/view/v034i12/v34i12.pdf
> >>
> >> Original post:
> >>
> >> Hello. I am still trying to get some of the examples in this glmulti pdf to work with my data.
> >>
> >> I have sent e-mails to author addresses provided but no response or bounced back as in valid.
> >>
> >> I am not sure if this is more likely to receive support on r-help or r-sig-mixed-models, hence the double posting, my apologies in advance.
> >>
> >> I am windows 10 -- R3.5.1 -- RStudio Version 1.1.456
> >>
> >> glmulti: An R Package for Easy Automated Model Selection with (Generalized) Linear Models
> >>
> >> pdf Attached:
> >>
> >> On page 13 section 3.1 of the pdf they describe a routine to estimate the candidate models possible.
> >>
> >> Their data description:
> >> The number of levels factors have does not affect the number of candidate models, only their complexity. We use a data frame dod, containing as a first column a dummy response variable, the next 6 columns are dummy factors with three levels, and the last six are dummy covariates.
> >> To compute the number of candidate models when there are between 1 and 6 factors and 1 and 6 covariates, we call glmulti with method = "d" and data = dod. We use names(dod) to specify the names of the response variable and of the predictors. We vary the number of factors and covariates, this way:
> >>
> >>
> >> Their routine:
> >> dd <- matrix(nc = 6, nr = 6) for(i in 1:6) for(j in 1:6) dd[i, j] <- glmulti(names(dod)[1],
> >> + names(dod)[c(2:(1 + i), 8:(7 + j))], data = dod, method = "d")
> >>
> >> My data, I organized it similar to the example, Response, Factor, Factor, 5 covariates
> >>
> >> Classes 'data.table' and 'data.frame':23141 obs. of  8 variables:
> >>   $ Editnumber2    : num  0 0 1 1 1 1 1 1 1 1 ...
> >>   $ PatientGender  : Factor w/ 3 levels "F","M","U": 1 1 2 2 2 2 1 1 1 1 ...
> >>   $ B1             : Factor w/ 14 levels "Z","A","C","D",..: 2 2 3 3 2 2 2 2 2 2 ...
> >>   $ SavingsReversed: num  -0.139 -0.139 -0.139 -0.139 -0.139 ...
> >>   $ productID      : int  3 3 3 3 3 3 3 3 1 1 ...
> >>   $ ProviderID     : int  113676 113676 113964 113964 114278 114278 114278 114278 114278 114278 ...
> >>   $ ModCnt         : int  0 0 0 0 1 1 1 1 1 1 ...
> >>   $ B2             : num  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
> >>   - attr(*, ".internal.selfref")=<externalptr>
> >>
> >> Trying to follow what they did, my routine, Editnumber2 is the response variable:
> >>
> >> dd <- matrix(nc = 2, nr = 5)
> >> for(i in 1:2) for(j in 1:5) dd[i, j] <- glmulti(names(r1)[1], names(r1)[c(2:(1 + i), 7:(6 + j))], data = r1, method = "d")
> >>
> >> The error: Error in terms.formula(formula, data = data) :
> >>    invalid model formula in ExtractVars
> >>
> >> I have tried changing the numbers around but get results like this:
> >>
> >> Initialization...
> >> TASK: Diagnostic of candidate set.
> >> Sample size: 23141
> >> 2 factor(s).
> >> 2 covariate(s). <--appears to be missing 3 of the covariates for some reason?
> >> 0 f exclusion(s).
> >> 0 c exclusion(s).
> >> 0 f:f exclusion(s).
> >> 0 c:c exclusion(s).
> >> 0 f:c exclusion(s).
> >> Size constraints: min =  0 max = -1
> >> Complexity constraints: min =  0 max = -1 Your candidate set contains 250 models.
> >> Error in `[<-`(`*tmp*`, i, j, value = glmulti(names(r1)[1], names(r1)[c(2:(1 +  :
> >>    subscript out of bounds
> >>
> >>
> >> I hope someone can help straighten out my code, thank you.
> >>
> >>
> >> WHP
> >>
> >>
> >>
> >> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html


From victorchikw@pulo @ending from gm@il@com  Wed Nov 14 18:40:39 2018
From: victorchikw@pulo @ending from gm@il@com (Victor Chikwapulo)
Date: Wed, 14 Nov 2018 19:40:39 +0200
Subject: [R] how to read association of variable in multiple outcomes using
 MCMCMGLMM
Message-ID: <CALgjeV24q8QVuotvXTD1dPPw8Ts9mnpsmxgMuPPPaO9EjKAn9A@mail.gmail.com>

Dear all,
 I am? using package MCMCglmm and I would like to request for an
assistant on? what
to look? ?in the output which can tell me? whether there is
significant? association among the three antibody
titers(logiga,logigm,logigg)? for example association between antibody
titers and exposure I can look at pMCMC and confidence interval if
pMCMC is less than 0.05 then? the association is significant and this
is clearly explained in  mcmcglmm course notes but for association between
outcome variables? is not clearly stated on how one can tell whether
there is significant association between the outcome variable. Please
help me, I have been looking for this answer on internet for? month
now and I tried to simulate the data just to learn the interpretation
but I could not make sense of the output.

here is the model:
m1<- MCMCglmm(cbind(logiga,logigm,logigg) ~1+trait:exposure, random =
~us(trait):ptid,
? ? ? ? ? ? ? ? rcov = ~idh(trait):units, family = c("gaussian",
"gaussian","gaussian"),
? ? ? ? ? ? ? ? data = dat, prior = pri, verbose = FALSE)


summary(m1)
Iterations = 3001:12991
?Thinning interval? = 10
?Sample size? = 1000

?DIC: 772.0578

?G-structure:? ~us(trait):ptid

? ? ? ? ? ? ? ? ? ? ? ? ? ? ?post.mean l-95% CI u-95% CI eff.samp
traitlogiga:traitlogiga.ptid? ?0.26776? 0.14159? 0.43126? ? 906.8
traitlogigm:traitlogiga.ptid? -0.16155 -0.26484 -0.06026? ?1000.0
traitlogigg:traitlogiga.ptid? -0.01804 -0.09317? 0.05087? ? 872.0
traitlogiga:traitlogigm.ptid? -0.16155 -0.26484 -0.06026? ?1000.0
traitlogigm:traitlogigm.ptid? ?0.34228? 0.14773? 0.54208? ? 834.4
traitlogigg:traitlogigm.ptid? ?0.06099 -0.03872? 0.16586? ? 855.3
traitlogiga:traitlogigg.ptid? -0.01804 -0.09317? 0.05087? ? 872.0
traitlogigm:traitlogigg.ptid? ?0.06099 -0.03872? 0.16586? ? 855.3
traitlogigg:traitlogigg.ptid? ?0.14241? 0.08026? 0.23024? ?1000.0

?R-structure:? ~idh(trait):units

? ? ? ? ? ? ? ? ? post.mean l-95% CI u-95% CI eff.samp
traitlogiga.units? ?0.09538? 0.07516? ?0.1181? ? ?1000
traitlogigm.units? ?0.37488? 0.28979? ?0.4623? ? ?1000
traitlogigg.units? ?0.17954? 0.13917? ?0.2199? ? ?1126

?Location effects: cbind(logiga, logigm, logigg) ~ 1 + trait:exposure

? ? ? ? ? ? ? ? ? ? ?post.mean l-95% CI u-95% CI eff.samp? pMCMC
(Intercept)? ? ? ? ? ? 1.35329? 1.21504? 1.48696? ? 799.8 <0.001 ***
traitlogiga:exposure? ?0.09773 -0.07234? 0.30338? ?1000.0? 0.322
traitlogigm:exposure? ?0.60556? 0.26668? 0.97050? ?1000.0 <0.001 ***
traitlogigg:exposure? ?0.22682 -0.01893? 0.49654? ?1000.0? 0.090 .


From Bill@Poling @ending from zeli@@com  Thu Nov 15 19:00:18 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 15 Nov 2018 18:00:18 +0000
Subject: [R] glmutli package assistance please
Message-ID: <BN7PR02MB5073722F7B0AAAE5ACC71116EADC0@BN7PR02MB5073.namprd02.prod.outlook.com>

Hello Michael, thank you for your responses.

I will have to look through the myriad of iterations of attempts at all this on this project but it seems to me that I tried that? Or tried to convert the integers to numeric and it errored out?

If not I certainly will do so and let know, thank you Sir!

WHP



From: Michael Dewey <lists at dewey.myzen.co.uk>
Sent: Thursday, November 15, 2018 7:24 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-sig-mixed-models at r-project.org; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] glmutli package assistance please

Dear Bill

I am not sure what is going on here but I notice that 2 of your
covariates are numeric and 3 integer. What happens if you make them all
numeric?

Michael

On 15/11/2018 11:46, Bill Poling wrote:
> Hi, I have removed the pdf which was causing my e-mail to be blocked by moderators, my apologies.
>
> https://www.jstatsoft.org/article/view/v034i12/v34i12.pdf
>
> Original post:
>
> Hello. I am still trying to get some of the examples in this glmulti pdf to work with my data.
>
> I have sent e-mails to author addresses provided but no response or bounced back as in valid.
>
> I am not sure if this is more likely to receive support on r-help or r-sig-mixed-models, hence the double posting, my apologies in advance.
>
> I am windows 10 -- R3.5.1 -- RStudio Version 1.1.456
>
> glmulti: An R Package for Easy Automated Model Selection with (Generalized) Linear Models
>
> pdf Attached:
>
> On page 13 section 3.1 of the pdf they describe a routine to estimate the candidate models possible.
>
> Their data description:
> The number of levels factors have does not affect the number of candidate models, only their complexity. We use a data frame dod, containing as a first column a dummy response variable, the next 6 columns are dummy factors with three levels, and the last six are dummy covariates.
> To compute the number of candidate models when there are between 1 and 6 factors and 1 and 6 covariates, we call glmulti with method = "d" and data = dod. We use names(dod) to specify the names of the response variable and of the predictors. We vary the number of factors and covariates, this way:
>
>
> Their routine:
> dd <- matrix(nc = 6, nr = 6) for(i in 1:6) for(j in 1:6) dd[i, j] <- glmulti(names(dod)[1],
> + names(dod)[c(2:(1 + i), 8:(7 + j))], data = dod, method = "d")
>
> My data, I organized it similar to the example, Response, Factor, Factor, 5 covariates
>
> Classes 'data.table' and 'data.frame':23141 obs. of 8 variables:
> $ Editnumber2 : num 0 0 1 1 1 1 1 1 1 1 ...
> $ PatientGender : Factor w/ 3 levels "F","M","U": 1 1 2 2 2 2 1 1 1 1 ...
> $ B1 : Factor w/ 14 levels "Z","A","C","D",..: 2 2 3 3 2 2 2 2 2 2 ...
> $ SavingsReversed: num -0.139 -0.139 -0.139 -0.139 -0.139 ...
> $ productID : int 3 3 3 3 3 3 3 3 1 1 ...
> $ ProviderID : int 113676 113676 113964 113964 114278 114278 114278 114278 114278 114278 ...
> $ ModCnt : int 0 0 0 0 1 1 1 1 1 1 ...
> $ B2 : num -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
> - attr(*, ".internal.selfref")=<externalptr>
>
> Trying to follow what they did, my routine, Editnumber2 is the response variable:
>
> dd <- matrix(nc = 2, nr = 5)
> for(i in 1:2) for(j in 1:5) dd[i, j] <- glmulti(names(r1)[1], names(r1)[c(2:(1 + i), 7:(6 + j))], data = r1, method = "d")
>
> The error: Error in terms.formula(formula, data = data) :
> invalid model formula in ExtractVars
>
> I have tried changing the numbers around but get results like this:
>
> Initialization...
> TASK: Diagnostic of candidate set.
> Sample size: 23141
> 2 factor(s).
> 2 covariate(s). <--appears to be missing 3 of the covariates for some reason?
> 0 f exclusion(s).
> 0 c exclusion(s).
> 0 f:f exclusion(s).
> 0 c:c exclusion(s).
> 0 f:c exclusion(s).
> Size constraints: min = 0 max = -1
> Complexity constraints: min = 0 max = -1 Your candidate set contains 250 models.
> Error in `[<-`(`*tmp*`, i, j, value = glmulti(names(r1)[1], names(r1)[c(2:(1 + :
> subscript out of bounds
>
>
> I hope someone can help straighten out my code, thank you.
>
>
> WHP
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

--
Michael
http://www.dewey.myzen.co.uk/home.html

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

From Bill@Poling @ending from zeli@@com  Wed Nov 14 19:30:23 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Wed, 14 Nov 2018 18:30:23 +0000
Subject: [R] glmutli
Message-ID: <BN7PR02MB507332BCAA75659FD23607FBEAC30@BN7PR02MB5073.namprd02.prod.outlook.com>

Hello. I am still trying to get some of the examples in this glmulti pdf to work with my data.

I have sent e-mails to author addresses provided but no response or bounced back as in valid.

I am not sure if this is more likely to receive support on r-help or r-sig-mixed-models, hence the double posting, my apologies in advance.

I am windows 10 -- R3.5.1 -- RStudio Version 1.1.456

glmulti: An R Package for Easy Automated Model Selection with (Generalized) Linear Models

pdf Attached:

On page 13 section 3.1 of the pdf they describe a routine to estimate the candidate models possible.

Their data description:
The number of levels factors have does not affect the number of candidate models, only
their complexity. We use a data frame dod, containing as a first column a dummy response
variable, the next 6 columns are dummy factors with three levels, and the last six are dummy
covariates.
To compute the number of candidate models when there are between 1 and 6 factors and 1
and 6 covariates, we call glmulti with method = "d" and data = dod. We use names(dod)
to specify the names of the response variable and of the predictors. We vary the number of
factors and covariates, this way:


Their routine:
dd <- matrix(nc = 6, nr = 6) for(i in 1:6) for(j in 1:6) dd[i, j] <- glmulti(names(dod)[1],
+ names(dod)[c(2:(1 + i), 8:(7 + j))], data = dod, method = "d")

My data, I organized it similar to the example, Response, Factor, Factor, 5 covariates

Classes 'data.table' and 'data.frame':23141 obs. of  8 variables:
 $ Editnumber2    : num  0 0 1 1 1 1 1 1 1 1 ...
 $ PatientGender  : Factor w/ 3 levels "F","M","U": 1 1 2 2 2 2 1 1 1 1 ...
 $ B1             : Factor w/ 14 levels "Z","A","C","D",..: 2 2 3 3 2 2 2 2 2 2 ...
 $ SavingsReversed: num  -0.139 -0.139 -0.139 -0.139 -0.139 ...
 $ productID      : int  3 3 3 3 3 3 3 3 1 1 ...
 $ ProviderID     : int  113676 113676 113964 113964 114278 114278 114278 114278 114278 114278 ...
 $ ModCnt         : int  0 0 0 0 1 1 1 1 1 1 ...
 $ B2             : num  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
 - attr(*, ".internal.selfref")=<externalptr>

Trying to follow what they did, my routine, Editnumber2 is the response variable:

dd <- matrix(nc = 2, nr = 5)
for(i in 1:2) for(j in 1:5) dd[i, j] <- glmulti(names(r1)[1], names(r1)[c(2:(1 + i), 7:(6 + j))], data = r1, method = "d")

The error: Error in terms.formula(formula, data = data) :
  invalid model formula in ExtractVars

I have tried changing the numbers around but get results like this:

Initialization...
TASK: Diagnostic of candidate set.
Sample size: 23141
2 factor(s).
2 covariate(s). <--appears to be missing 3 of the covariates for some reason?
0 f exclusion(s).
0 c exclusion(s).
0 f:f exclusion(s).
0 c:c exclusion(s).
0 f:c exclusion(s).
Size constraints: min =  0 max = -1
Complexity constraints: min =  0 max = -1
Your candidate set contains 250 models.
Error in `[<-`(`*tmp*`, i, j, value = glmulti(names(r1)[1], names(r1)[c(2:(1 +  :
  subscript out of bounds


I hope someone can help straighten out my code, thank you.


WHP



Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.




This message was secured by Zix(R).

-------------- next part --------------
A non-text attachment was scrubbed...
Name: glmutli.pdf
Type: application/pdf
Size: 1191543 bytes
Desc: glmutli.pdf
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20181114/4c55dbcc/attachment-0001.pdf>

From @@@@@ko@@nic @ending from gm@il@com  Thu Nov 15 17:48:37 2018
From: @@@@@ko@@nic @ending from gm@il@com (sasa kosanic)
Date: Thu, 15 Nov 2018 17:48:37 +0100
Subject: [R] help with grouping data and calculating the means
Message-ID: <CAJanvzGg1cf_1sjoQxKZ1U++8iA0Nh2LVdkuMUaUoDUfuhx-HQ@mail.gmail.com>

Dear All,

I would very much appreciate the help with following:
I need to calculate the mean of  different lat/long points that should be
grouped.
However I would like that r excludes taking  values that are different in
only last decimal.
So instead 4 values in the group it would calculate the mean for only 3(
excluding the ones that differs in only one decimal).
# construct the dataframe
`TK-QUADRANT` <- c(9161,9162,9163,9164,10152,10154,10161,10163)
LAT <- c(55.07496,55.07496,55.02495,55.02496
,54.97496,54.92495,54.97496,54.92496)
LON <-
c(8.37477,8.458109,8.37477,8.45811,8.291435,8.291437,8.374774,8.374774)
df <- data.frame(`TK-QUADRANT`=`TK-QUADRANT`,LAT=LAT,LON=LON)


I would like to group the data and calculate means by group but in a way to
exclude every number that differs in only last decimal.


Also please see pdf. example-attached .

Many thanks!
Best wishes,
Sasha

-- 

Dr Sasha Kosanic
Ecology Lab (Biology Department)
Room M644
University of Konstanz
Universit?tsstra?e 10
D-78464 Konstanz
Phone: +49 7531 883321 & +49 (0)175 9172503

http://cms.uni-konstanz.de/vkleunen/
https://tinyurl.com/y8u5wyoj
https://tinyurl.com/cgec6tu

-------------- next part --------------
A non-text attachment was scrubbed...
Name: dataset example.pdf
Type: application/pdf
Size: 236074 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20181115/128cc993/attachment.pdf>

From bori@@@teipe @ending from utoronto@c@  Thu Nov 15 19:40:25 2018
From: bori@@@teipe @ending from utoronto@c@ (Boris Steipe)
Date: Thu, 15 Nov 2018 18:40:25 +0000
Subject: [R] help with grouping data and calculating the means
In-Reply-To: <CAJanvzGg1cf_1sjoQxKZ1U++8iA0Nh2LVdkuMUaUoDUfuhx-HQ@mail.gmail.com>
References: <CAJanvzGg1cf_1sjoQxKZ1U++8iA0Nh2LVdkuMUaUoDUfuhx-HQ@mail.gmail.com>
Message-ID: <C2EAA9D1-4799-43ED-9781-2603F29C39A4@utoronto.ca>

Use round() with the appropriate  "digits" argument. Then use unique() to define your groups.

HTH,
B.


> On 2018-11-15, at 11:48, sasa kosanic <sasa.kosanic at gmail.com> wrote:
> 
> Dear All,
> 
> I would very much appreciate the help with following:
> I need to calculate the mean of  different lat/long points that should be
> grouped.
> However I would like that r excludes taking  values that are different in
> only last decimal.
> So instead 4 values in the group it would calculate the mean for only 3(
> excluding the ones that differs in only one decimal).
> # construct the dataframe
> `TK-QUADRANT` <- c(9161,9162,9163,9164,10152,10154,10161,10163)
> LAT <- c(55.07496,55.07496,55.02495,55.02496
> ,54.97496,54.92495,54.97496,54.92496)
> LON <-
> c(8.37477,8.458109,8.37477,8.45811,8.291435,8.291437,8.374774,8.374774)
> df <- data.frame(`TK-QUADRANT`=`TK-QUADRANT`,LAT=LAT,LON=LON)
> 
> 
> I would like to group the data and calculate means by group but in a way to
> exclude every number that differs in only last decimal.
> 
> 
> Also please see pdf. example-attached .
> 
> Many thanks!
> Best wishes,
> Sasha
> 
> -- 
> 
> Dr Sasha Kosanic
> Ecology Lab (Biology Department)
> Room M644
> University of Konstanz
> Universit?tsstra?e 10
> D-78464 Konstanz
> Phone: +49 7531 883321 & +49 (0)175 9172503
> 
> http://cms.uni-konstanz.de/vkleunen/
> https://tinyurl.com/y8u5wyoj
> https://tinyurl.com/cgec6tu
> <dataset example.pdf>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Bill@Poling @ending from zeli@@com  Thu Nov 15 21:01:11 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 15 Nov 2018 20:01:11 +0000
Subject: [R] glmutli package assistance please - error Solved
Message-ID: <BN7PR02MB5073EDC4B657D6AEB8F10E6FEADC0@BN7PR02MB5073.namprd02.prod.outlook.com>

Hello Michael and all.

1. I replaced INT with Numeric that did not solve the error  problem.
2. However I discovered that my matrix was the problem, I had it set to 2,5 and when I set it to 6,6 I no longer get the error, which was due to not having the correct or more than necessary fields in the matrix.
Clues came from: https://stackoverflow.com/questions/15031338/subscript-out-of-bounds-general-definition-and-solution

Following the author's pattern they described their data as needing matrix = 6,6 due to 6 factors and 6 covariates .

I set my matrix to the number of Factors and Covariates, 2-5 and that caused the error.
[,1]  [,2]
[1,] 497664 10368
[2,]     NA    NA
[3,]     NA    NA
[4,]     NA    NA
[5,]     NA    NA

dd <- matrix(nc = 6, nr = 6) View(dd)
for(i in 1:2) for(j in 1:5) dd[i, j] <- glmulti(names(r1a)[1], names(r1a)[c(2:(1 + i), 8:(3 + j))], data = r1a, method = "d")

[,1]   [,2] [,3] [,4] [,5] [,6]
[1,]   497664  10368  432   36    6   NA
[2,] 16000000 200000 5000  250   25   NA
[3,]       NA     NA   NA   NA   NA   NA
[4,]       NA     NA   NA   NA   NA   NA
[5,]       NA     NA   NA   NA   NA   NA
[6,]       NA     NA   NA   NA   NA   NA

Thank you for your support!

WHP

From: Michael Dewey <lists at dewey.myzen.co.uk>
Sent: Thursday, November 15, 2018 7:24 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-sig-mixed-models at r-project.org; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] glmutli package assistance please

Dear Bill

I am not sure what is going on here but I notice that 2 of your
covariates are numeric and 3 integer. What happens if you make them all
numeric?

Michael

On 15/11/2018 11:46, Bill Poling wrote:
> Hi, I have removed the pdf which was causing my e-mail to be blocked by moderators, my apologies.
>
> https://www.jstatsoft.org/article/view/v034i12/v34i12.pdf
>
> Original post:
>
> Hello. I am still trying to get some of the examples in this glmulti pdf to work with my data.
>
> I have sent e-mails to author addresses provided but no response or bounced back as in valid.
>
> I am not sure if this is more likely to receive support on r-help or r-sig-mixed-models, hence the double posting, my apologies in advance.
>
> I am windows 10 -- R3.5.1 -- RStudio Version 1.1.456
>
> glmulti: An R Package for Easy Automated Model Selection with (Generalized) Linear Models
>
> pdf Attached:
>
> On page 13 section 3.1 of the pdf they describe a routine to estimate the candidate models possible.
>
> Their data description:
> The number of levels factors have does not affect the number of candidate models, only their complexity. We use a data frame dod, containing as a first column a dummy response variable, the next 6 columns are dummy factors with three levels, and the last six are dummy covariates.
> To compute the number of candidate models when there are between 1 and 6 factors and 1 and 6 covariates, we call glmulti with method = "d" and data = dod. We use names(dod) to specify the names of the response variable and of the predictors. We vary the number of factors and covariates, this way:
>
>
> Their routine:
> dd <- matrix(nc = 6, nr = 6) for(i in 1:6) for(j in 1:6) dd[i, j] <- glmulti(names(dod)[1],
> + names(dod)[c(2:(1 + i), 8:(7 + j))], data = dod, method = "d")
>
> My data, I organized it similar to the example, Response, Factor, Factor, 5 covariates
>
> Classes 'data.table' and 'data.frame':23141 obs. of 8 variables:
> $ Editnumber2 : num 0 0 1 1 1 1 1 1 1 1 ...
> $ PatientGender : Factor w/ 3 levels "F","M","U": 1 1 2 2 2 2 1 1 1 1 ...
> $ B1 : Factor w/ 14 levels "Z","A","C","D",..: 2 2 3 3 2 2 2 2 2 2 ...
> $ SavingsReversed: num -0.139 -0.139 -0.139 -0.139 -0.139 ...
> $ productID : int 3 3 3 3 3 3 3 3 1 1 ...
> $ ProviderID : int 113676 113676 113964 113964 114278 114278 114278 114278 114278 114278 ...
> $ ModCnt : int 0 0 0 0 1 1 1 1 1 1 ...
> $ B2 : num -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
> - attr(*, ".internal.selfref")=<externalptr>
>
> Trying to follow what they did, my routine, Editnumber2 is the response variable:
>
> dd <- matrix(nc = 2, nr = 5)
> for(i in 1:2) for(j in 1:5) dd[i, j] <- glmulti(names(r1)[1], names(r1)[c(2:(1 + i), 7:(6 + j))], data = r1, method = "d")
>
> The error: Error in terms.formula(formula, data = data) :
> invalid model formula in ExtractVars
>
> I have tried changing the numbers around but get results like this:
>
> Initialization...
> TASK: Diagnostic of candidate set.
> Sample size: 23141
> 2 factor(s).
> 2 covariate(s). <--appears to be missing 3 of the covariates for some reason?
> 0 f exclusion(s).
> 0 c exclusion(s).
> 0 f:f exclusion(s).
> 0 c:c exclusion(s).
> 0 f:c exclusion(s).
> Size constraints: min = 0 max = -1
> Complexity constraints: min = 0 max = -1 Your candidate set contains 250 models.
> Error in `[<-`(`*tmp*`, i, j, value = glmulti(names(r1)[1], names(r1)[c(2:(1 + :
> subscript out of bounds
>
>
> I hope someone can help straighten out my code, thank you.
>
>
> WHP
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

--
Michael
http://www.dewey.myzen.co.uk/home.html

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

From bgunter@4567 @ending from gm@il@com  Thu Nov 15 21:19:43 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 15 Nov 2018 12:19:43 -0800
Subject: [R] help with grouping data and calculating the means
In-Reply-To: <C2EAA9D1-4799-43ED-9781-2603F29C39A4@utoronto.ca>
References: <CAJanvzGg1cf_1sjoQxKZ1U++8iA0Nh2LVdkuMUaUoDUfuhx-HQ@mail.gmail.com>
 <C2EAA9D1-4799-43ED-9781-2603F29C39A4@utoronto.ca>
Message-ID: <CAGxFJbRthFpM=-enQR5wgijXtaBA80x09=yPJpd_fdbnm-XECQ@mail.gmail.com>

On Thu, Nov 15, 2018 at 10:40 AM Boris Steipe <boris.steipe at utoronto.ca> wrote:
>
> Use round() with the appropriate  "digits" argument. Then use unique() to define your groups.

No.
> round(c(.124,.126),2)
[1] 0.12 0.13

As I understand it, the OP said he wanted the last decimal to be ignored.

The OP also did not specify what he wanted to calculate means of. I
assume TK-QUADRANT. It is also not clear whether the calculations are
to be done separately by latitude and longitude, or both together.
I'll assume separately. In which case, the calculation of TK-QUADRANT
means by e.g. grouped according to 4 decimal digit values of latitude
could be done using(using the provided example data):
(Note: ignore all that follows if my interpretation is incorrect)

> with(df, tapply(TK.QUADRANT, floor(1e4*LAT),mean))
 549249  549749  550249  550749
10158.5 10156.5  9163.5  9161.5

## Note that this assumes positive values of latitude, because:
> floor(c(-1.2,1.2))
[1] -2  1

This could be easily modifed if both positive and negative values were
used: e.g.
> x <-c(-1.2,1.2)
> sign(x)*floor(abs(x))
[1] -1  1

Confession: I suspect that this exponentiate and floor() procedure
might fail with lots of decimal places due to the usual issues of
binary representations of decimals. But maybe it fails even here. If
so, I would appreciate someone pointing this out and, if possible,
providing a better strategy.

Cheers,
Bert



>
> HTH,
> B.
>
>
> > On 2018-11-15, at 11:48, sasa kosanic <sasa.kosanic at gmail.com> wrote:
> >
> > Dear All,
> >
> > I would very much appreciate the help with following:
> > I need to calculate the mean of  different lat/long points that should be
> > grouped.
> > However I would like that r excludes taking  values that are different in
> > only last decimal.
> > So instead 4 values in the group it would calculate the mean for only 3(
> > excluding the ones that differs in only one decimal).
> > # construct the dataframe
> > `TK-QUADRANT` <- c(9161,9162,9163,9164,10152,10154,10161,10163)
> > LAT <- c(55.07496,55.07496,55.02495,55.02496
> > ,54.97496,54.92495,54.97496,54.92496)
> > LON <-
> > c(8.37477,8.458109,8.37477,8.45811,8.291435,8.291437,8.374774,8.374774)
> > df <- data.frame(`TK-QUADRANT`=`TK-QUADRANT`,LAT=LAT,LON=LON)
> >
> >
> > I would like to group the data and calculate means by group but in a way to
> > exclude every number that differs in only last decimal.
> >
> >
> > Also please see pdf. example-attached .
> >
> > Many thanks!
> > Best wishes,
> > Sasha
> >
> > --
> >
> > Dr Sasha Kosanic
> > Ecology Lab (Biology Department)
> > Room M644
> > University of Konstanz
> > Universit?tsstra?e 10
> > D-78464 Konstanz
> > Phone: +49 7531 883321 & +49 (0)175 9172503
> >
> > http://cms.uni-konstanz.de/vkleunen/
> > https://tinyurl.com/y8u5wyoj
> > https://tinyurl.com/cgec6tu
> > <dataset example.pdf>______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @ending from gm@il@com  Thu Nov 15 21:50:55 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 15 Nov 2018 12:50:55 -0800
Subject: [R] help with grouping data and calculating the means
In-Reply-To: <CAGxFJbRthFpM=-enQR5wgijXtaBA80x09=yPJpd_fdbnm-XECQ@mail.gmail.com>
References: <CAJanvzGg1cf_1sjoQxKZ1U++8iA0Nh2LVdkuMUaUoDUfuhx-HQ@mail.gmail.com>
 <C2EAA9D1-4799-43ED-9781-2603F29C39A4@utoronto.ca>
 <CAGxFJbRthFpM=-enQR5wgijXtaBA80x09=yPJpd_fdbnm-XECQ@mail.gmail.com>
Message-ID: <CAGxFJbRG5U5R6gMB366N6WYQcDKyiLPPK0317k5YjhRff-o4Fw@mail.gmail.com>

On further thought -- and subject to my prior interpretation -- I
think a foolproof way of truncating to 4 decimal digits is to treat
them as character strings rather than numerics and use regex
operations:

> with(df,tapply(TK.QUADRANT, sub("(\\.[[:digit:]]{4}).*","\\1",as.character(LAT)),mean))
54.9249 54.9749 55.0249 55.0749
10158.5 10156.5  9163.5  9161.5

I should have realized this before!!!!

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
On Thu, Nov 15, 2018 at 12:19 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> On Thu, Nov 15, 2018 at 10:40 AM Boris Steipe <boris.steipe at utoronto.ca> wrote:
> >
> > Use round() with the appropriate  "digits" argument. Then use unique() to define your groups.
>
> No.
> > round(c(.124,.126),2)
> [1] 0.12 0.13
>
> As I understand it, the OP said he wanted the last decimal to be ignored.
>
> The OP also did not specify what he wanted to calculate means of. I
> assume TK-QUADRANT. It is also not clear whether the calculations are
> to be done separately by latitude and longitude, or both together.
> I'll assume separately. In which case, the calculation of TK-QUADRANT
> means by e.g. grouped according to 4 decimal digit values of latitude
> could be done using(using the provided example data):
> (Note: ignore all that follows if my interpretation is incorrect)
>
> > with(df, tapply(TK.QUADRANT, floor(1e4*LAT),mean))
>  549249  549749  550249  550749
> 10158.5 10156.5  9163.5  9161.5
>
> ## Note that this assumes positive values of latitude, because:
> > floor(c(-1.2,1.2))
> [1] -2  1
>
> This could be easily modifed if both positive and negative values were
> used: e.g.
> > x <-c(-1.2,1.2)
> > sign(x)*floor(abs(x))
> [1] -1  1
>
> Confession: I suspect that this exponentiate and floor() procedure
> might fail with lots of decimal places due to the usual issues of
> binary representations of decimals. But maybe it fails even here. If
> so, I would appreciate someone pointing this out and, if possible,
> providing a better strategy.
>
> Cheers,
> Bert
>
>
>
> >
> > HTH,
> > B.
> >
> >
> > > On 2018-11-15, at 11:48, sasa kosanic <sasa.kosanic at gmail.com> wrote:
> > >
> > > Dear All,
> > >
> > > I would very much appreciate the help with following:
> > > I need to calculate the mean of  different lat/long points that should be
> > > grouped.
> > > However I would like that r excludes taking  values that are different in
> > > only last decimal.
> > > So instead 4 values in the group it would calculate the mean for only 3(
> > > excluding the ones that differs in only one decimal).
> > > # construct the dataframe
> > > `TK-QUADRANT` <- c(9161,9162,9163,9164,10152,10154,10161,10163)
> > > LAT <- c(55.07496,55.07496,55.02495,55.02496
> > > ,54.97496,54.92495,54.97496,54.92496)
> > > LON <-
> > > c(8.37477,8.458109,8.37477,8.45811,8.291435,8.291437,8.374774,8.374774)
> > > df <- data.frame(`TK-QUADRANT`=`TK-QUADRANT`,LAT=LAT,LON=LON)
> > >
> > >
> > > I would like to group the data and calculate means by group but in a way to
> > > exclude every number that differs in only last decimal.
> > >
> > >
> > > Also please see pdf. example-attached .
> > >
> > > Many thanks!
> > > Best wishes,
> > > Sasha
> > >
> > > --
> > >
> > > Dr Sasha Kosanic
> > > Ecology Lab (Biology Department)
> > > Room M644
> > > University of Konstanz
> > > Universit?tsstra?e 10
> > > D-78464 Konstanz
> > > Phone: +49 7531 883321 & +49 (0)175 9172503
> > >
> > > http://cms.uni-konstanz.de/vkleunen/
> > > https://tinyurl.com/y8u5wyoj
> > > https://tinyurl.com/cgec6tu
> > > <dataset example.pdf>______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From peter@@nthoni @ending from kit@edu  Fri Nov 16 07:39:22 2018
From: peter@@nthoni @ending from kit@edu (Anthoni, Peter (IMK))
Date: Fri, 16 Nov 2018 06:39:22 +0000
Subject: [R] help with grouping data and calculating the means
In-Reply-To: <CAJanvzGg1cf_1sjoQxKZ1U++8iA0Nh2LVdkuMUaUoDUfuhx-HQ@mail.gmail.com>
References: <CAJanvzGg1cf_1sjoQxKZ1U++8iA0Nh2LVdkuMUaUoDUfuhx-HQ@mail.gmail.com>
Message-ID: <6D781055-3752-40C6-92FC-A8A3CBCC5B95@kit.edu>

Hi Sasa,

Those latitude look equidistant with a separation of 0.05.
I guess you want to calculate the zonal mean along the latitude, right?

#estimate the lower and upper latitude for the cut
lat.dist=0.05 #equidistant spacing along latitude
lat.min=min(df$LAT,na.rm=T)-lat.dist/2
lat.max=max(df$LAT,na.rm=T)+lat.dist/2
cat.lat=cut(df$LAT,breaks=seq(lat.min,lat.max,by=lat.dist));cat.lat

#just show which indices are grouped
tapply(df$TK.QUADRANT,cat.lat, paste,collapse=",")

#calculate the mean of whatever column. The lat.mean will have NA for any latitude cell where the df column has no data
lat.mean=tapply(df$TK.QUADRANT,cat.lat, mean)

#if you need to remove any potential NAs
lat.mean[!is.na(lat.mean)]

cheers/beste Gr??e
Peter

On 15. Nov 2018, at 17:48, sasa kosanic <sasa.kosanic at gmail.com<mailto:sasa.kosanic at gmail.com>> wrote:

`TK-QUADRANT` <- c(9161,9162,9163,9164,10152,10154,10161,10163)
LAT <- c(55.07496,55.07496,55.02495,55.02496
,54.97496,54.92495,54.97496,54.92496)
LON <-
c(8.37477,8.458109,8.37477,8.45811,8.291435,8.291437,8.374774,8.374774)
df <- data.frame(`TK-QUADRANT`=`TK-QUADRANT`,LAT=LAT,LON=LON)


	[[alternative HTML version deleted]]


From ige@inform@tic@ @ending from ige@eu  Fri Nov 16 11:08:58 2018
From: ige@inform@tic@ @ending from ige@eu (buzon informatica, ige)
Date: Fri, 16 Nov 2018 10:08:58 +0000
Subject: [R] which() function help page precision
Message-ID: <da1b0b8760a64572a340166d731c2353@SERV-EXCH11.cixtec.l>

The which() function help page states that, in the default case, what the function returns  is:
" Basically, the result is (1:length(x))[x]."
That would only be true if there are not any NA values in x. I think it would be more accurate to say:
"Basically, the result is (1:length(x))[!is.na(x) & x]."

The "strange" (IMHO) behavior of logical indexing in R makes it necessary to exclude NA values.
For this reason, I  use to wrap logical indices with  which(). I would have written the above expression as:
(1:length(x))[which(x)]
But that would have been a really bad explanation of how the which() function works ;)

	[[alternative HTML version deleted]]


From pd@lgd @ending from gm@il@com  Fri Nov 16 13:39:27 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Fri, 16 Nov 2018 13:39:27 +0100
Subject: [R] which() function help page precision
In-Reply-To: <da1b0b8760a64572a340166d731c2353@SERV-EXCH11.cixtec.l>
References: <da1b0b8760a64572a340166d731c2353@SERV-EXCH11.cixtec.l>
Message-ID: <129828AC-9637-4237-87DD-87D7E2199A50@gmail.com>


Well, "Basically, " is an excuse for not being accurate. Making the code more complex doesn't really help the explanation. It could be better to just add "(except for NA handling)" or so.

-pd
 
> On 16 Nov 2018, at 11:08 , buzon informatica, ige <ige.informatica at ige.eu> wrote:
> 
> The which() function help page states that, in the default case, what the function returns  is:
> " Basically, the result is (1:length(x))[x]."
> That would only be true if there are not any NA values in x. I think it would be more accurate to say:
> "Basically, the result is (1:length(x))[!is.na(x) & x]."
> 
> The "strange" (IMHO) behavior of logical indexing in R makes it necessary to exclude NA values.
> For this reason, I  use to wrap logical indices with  which(). I would have written the above expression as:
> (1:length(x))[which(x)]
> But that would have been a really bad explanation of how the which() function works ;)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From D@vid@M@Smith @ending from micro@oft@com  Thu Nov 15 20:49:45 2018
From: D@vid@M@Smith @ending from micro@oft@com (David Smith (CDA))
Date: Thu, 15 Nov 2018 19:49:45 +0000
Subject: [R] Revolutions blog roundup: October 2018
Message-ID: <DM5PR2101MB1096B040A8C0711B89A82204B9DC0@DM5PR2101MB1096.namprd21.prod.outlook.com>

For almost 10 years, Microsoft staff and guests have written about R at the
Revolutions blog (http://blog.revolutionanalytics.com) and every month I post a
summary of articles from the previous month of particular interest to readers of
r-help.

In case you missed them, here are some articles related to R from the
month of October:

Peter Provost ports some 80's-era BASIC programs for kids to R:
https://blog.revolutionanalytics.com/2018/10/gravedigger-in-r.html

In a podcast for Fringe FM, I discuss the ethics of AI, Microsoft and Open
Source, and the R Community:
https://blog.revolutionanalytics.com/2018/10/fringe-fm-podcast.html

Roundup of AI, Machine Learning and Data Science news from September 2018:
https://blog.revolutionanalytics.com/2018/10/ai-roundup-oct-2018.html

In this episode of "Guy in a Cube", R is used to visualize Anscombe's Quartet
via Power BI:
https://blog.revolutionanalytics.com/2018/10/anscombes-quartet.html

Di Cook suggests using computer vision to automate statistical model assessment
for machine learning in the 2018 Belz Lecture:
https://blog.revolutionanalytics.com/2018/10/human-vs-computer.html

R provides the analysis behind a front-page story on bridge safety in the
Baltimore Sun:
https://blog.revolutionanalytics.com/2018/10/bridge-safety-in-r.html

Tomas Kalibera describes the big impacts of a small tweak to the logical
comparison operators in R:
https://blog.revolutionanalytics.com/2018/10/index.html

The Economist is now using R to calculate its famous "Big Mac Index":
https://blog.revolutionanalytics.com/2018/10/big-mac-index.html

Behind-the-scenes details of how R gets built on Windows, from a presentation by
Jeroen Ooms:
https://blog.revolutionanalytics.com/2018/10/how-r-gets-built-on-windows.html

The R Consortium has accepted another round of grant applications for R
community projects:
https://blog.revolutionanalytics.com/2018/10/r-consortium-grant-applications-due-october-31.html

A list of upcoming R conferences:
https://blog.revolutionanalytics.com/2018/10/a-few-upcoming-r-conferences.html

A recap of AI, Machine Learning and Data Science announcements from the
Microsoft Ignite conference:
https://blog.revolutionanalytics.com/2018/10/ignite-ai-announcements.html

And some general interest stories (not necessarily related to R):

* A lesson on diversity: the Parable of the Polygons
https://blog.revolutionanalytics.com/2018/10/because-its-friday-parable-of-the-polygons.html

* The story behind the baseball scene in The Naked Gun:
https://blog.revolutionanalytics.com/2018/10/because-its-friday-hey-its-enrico-palazzo.html

* Public Key Cryptography, as explained by IKEA:
https://blog.revolutionanalytics.com/2018/10/because-its-friday-if-ikea-did-algorithms.html

As always, thanks for the comments and please keep sending suggestions to me at
davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
Developer Advocate, Microsoft Cloud & Enterprise 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From Bill@Poling @ending from zeli@@com  Fri Nov 16 16:38:11 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Fri, 16 Nov 2018 15:38:11 +0000
Subject: [R] Help with factor column replacement value issue
Message-ID: <BN7PR02MB50730DC2CE20AA5282EF53C3EADD0@BN7PR02MB5073.namprd02.prod.outlook.com>

Hello:

I am running windows 10 -- R3.5.1 -- RStudio Version 1.1.456

I would like to know why when I replace a column value it still appears in subsequent routines:

My example:

r1$B1 is a Factor: It is created from the first character of a list of CPT codes, r1$CPT.

head(r1$CPT, N= 25)
[1] A4649 A4649 C9359 C1713 A0394 A0398
903 Levels: 00000 00001 00140 00160 00670 00810 00940 01400 01470 01961 01968 10160 11000 11012 11042 11043 11044 11045 11100 11101 11200 11201 11401 11402 ... l8699

str(r1$CPT)
 Factor w/ 903 levels "00000","00001",..: 773 773 816 783 739 741 743 739 739 741 ...


And I want only those CPT's with leading alpha char in this column so I set the numeric leading char to Z

r1$B1 <- str_sub(r1$CPT,1,1)

r1$B1 <- as.factor(r1$B1) #Redundant
levels(r1$B1)[levels(r1$B1) %in%  c('1','2','3','4','5','6','7','8','9','0')] <- 'Z'

When I check what I have done I find l & L

unique(r1$B1)
#[1] A C Z L G Q U J V E S l D P
#Levels: Z A C D E G J l L P Q S U V

So I change l to L
r1$B1[r1$B1 == 'l'] <- 'L'

When I check again I have l & L but l = 0
table(r1$B1)
#   Z          A          C      D     E     G      J           l     L         P     Q     S     U     V
#19639  1673   546     2     8   147   281     0    664     1    64    36   114    14

When I go to find those rows as if they existed, they are not accounted for?

tmp <- subset(r1, B1 == "l")
print(tmp)
Empty data.table (0 rows) of 9 cols: SavingsReversed,productID,ProviderID,PatientGender,ModCnt,Editnumber2...

And I have actually visually inspected the whole darn column, sheesh!

So I ignore it temporarily.

Now later on it resurfaces in a tutorial I am following for caret pkg.

preProcess(r1b, method = c("center", "scale"),
           thresh = 0.95, pcaComp = NULL, na.remove = TRUE, k = 5,
           knnSummary = mean, outcome = NULL, fudge = 0.2, numUnique = 3,
           verbose = FALSE, freqCut = 95/5, uniqueCut = 10, cutoff = 0.9,
           rangeBounds = c(0, 1))
# Warning in preProcess.default(r1b, method = c("center", "scale"), thresh = 0.95,  :
#                                 These variables have zero variances: B1l  <-------------yes this is a remnant of the r1$B1 clean-up
#                               Created from 23141 samples and 22 variables
#
#                               Pre-processing:
#                                 - centered (22)
#                                 - ignored (0)
#                                 - scaled (22)


So my questions are, in consideration of regression modelling accuracy:

Why is this happening?
How do I remove it?
Or is it irrelevant and leave it be?

As always, thank you for you support.

WHP












Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From bgunter@4567 @ending from gm@il@com  Fri Nov 16 17:09:47 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 16 Nov 2018 08:09:47 -0800
Subject: [R] Help with factor column replacement value issue
In-Reply-To: <BN7PR02MB50730DC2CE20AA5282EF53C3EADD0@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB50730DC2CE20AA5282EF53C3EADD0@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbSVQH0Fmyx4D+rQjBERPDxxduvDwfet2AJtw5+zWhBa8Q@mail.gmail.com>

As usual, careful reading of the relevant Help page would resolve the confusion.

from ?factor:

"factor(x, exclude = NULL) applied to a factor without NAs is a
no-operation unless there are unused levels: in that case, a factor
with the reduced level set is returned. If exclude is used, since R
version 3.4.0, excluding non-existing character levels is equivalent
to excluding nothing, and when excludeis a character vector, that is
applied to the levels of x. Alternatively, excludecan be factor with
the same level set as x and will exclude the levels present in
exclude."

In, subsetting a factor does not change the levels attribute, even if
some levels are not present. One must explicitly remove them, e.g.:

> f <- factor(letters[1:3])
## 3 levels, all present

> f[1:2]
[1] a b
Levels: a b c
## 3 levels, but one empty

> factor(f[1:2], exclude = NULL)
[1] a b
Levels: a b
## Now only two levels


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
On Fri, Nov 16, 2018 at 7:38 AM Bill Poling <Bill.Poling at zelis.com> wrote:
>
> Hello:
>
> I am running windows 10 -- R3.5.1 -- RStudio Version 1.1.456
>
> I would like to know why when I replace a column value it still appears in subsequent routines:
>
> My example:
>
> r1$B1 is a Factor: It is created from the first character of a list of CPT codes, r1$CPT.
>
> head(r1$CPT, N= 25)
> [1] A4649 A4649 C9359 C1713 A0394 A0398
> 903 Levels: 00000 00001 00140 00160 00670 00810 00940 01400 01470 01961 01968 10160 11000 11012 11042 11043 11044 11045 11100 11101 11200 11201 11401 11402 ... l8699
>
> str(r1$CPT)
>  Factor w/ 903 levels "00000","00001",..: 773 773 816 783 739 741 743 739 739 741 ...
>
>
> And I want only those CPT's with leading alpha char in this column so I set the numeric leading char to Z
>
> r1$B1 <- str_sub(r1$CPT,1,1)
>
> r1$B1 <- as.factor(r1$B1) #Redundant
> levels(r1$B1)[levels(r1$B1) %in%  c('1','2','3','4','5','6','7','8','9','0')] <- 'Z'
>
> When I check what I have done I find l & L
>
> unique(r1$B1)
> #[1] A C Z L G Q U J V E S l D P
> #Levels: Z A C D E G J l L P Q S U V
>
> So I change l to L
> r1$B1[r1$B1 == 'l'] <- 'L'
>
> When I check again I have l & L but l = 0
> table(r1$B1)
> #   Z          A          C      D     E     G      J           l     L         P     Q     S     U     V
> #19639  1673   546     2     8   147   281     0    664     1    64    36   114    14
>
> When I go to find those rows as if they existed, they are not accounted for?
>
> tmp <- subset(r1, B1 == "l")
> print(tmp)
> Empty data.table (0 rows) of 9 cols: SavingsReversed,productID,ProviderID,PatientGender,ModCnt,Editnumber2...
>
> And I have actually visually inspected the whole darn column, sheesh!
>
> So I ignore it temporarily.
>
> Now later on it resurfaces in a tutorial I am following for caret pkg.
>
> preProcess(r1b, method = c("center", "scale"),
>            thresh = 0.95, pcaComp = NULL, na.remove = TRUE, k = 5,
>            knnSummary = mean, outcome = NULL, fudge = 0.2, numUnique = 3,
>            verbose = FALSE, freqCut = 95/5, uniqueCut = 10, cutoff = 0.9,
>            rangeBounds = c(0, 1))
> # Warning in preProcess.default(r1b, method = c("center", "scale"), thresh = 0.95,  :
> #                                 These variables have zero variances: B1l  <-------------yes this is a remnant of the r1$B1 clean-up
> #                               Created from 23141 samples and 22 variables
> #
> #                               Pre-processing:
> #                                 - centered (22)
> #                                 - ignored (0)
> #                                 - scaled (22)
>
>
> So my questions are, in consideration of regression modelling accuracy:
>
> Why is this happening?
> How do I remove it?
> Or is it irrelevant and leave it be?
>
> As always, thank you for you support.
>
> WHP
>
>
>
>
>
>
>
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From li@t@ @ending from dewey@myzen@co@uk  Fri Nov 16 17:16:22 2018
From: li@t@ @ending from dewey@myzen@co@uk (Michael Dewey)
Date: Fri, 16 Nov 2018 16:16:22 +0000
Subject: [R] Help with factor column replacement value issue
In-Reply-To: <BN7PR02MB50730DC2CE20AA5282EF53C3EADD0@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB50730DC2CE20AA5282EF53C3EADD0@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <f9a594f7-c273-af25-23c4-6b5b756d935a@dewey.myzen.co.uk>

Dear Bill

When you do your step of replacing lower case l with upper case L the 
level still stays in the factor even though it is empty. If that is a 
nuisance x <- factor(x) will drop the unused levels. There are other 
ways of doing this.

Michael

On 16/11/2018 15:38, Bill Poling wrote:
> Hello:
> 
> I am running windows 10 -- R3.5.1 -- RStudio Version 1.1.456
> 
> I would like to know why when I replace a column value it still appears in subsequent routines:
> 
> My example:
> 
> r1$B1 is a Factor: It is created from the first character of a list of CPT codes, r1$CPT.
> 
> head(r1$CPT, N= 25)
> [1] A4649 A4649 C9359 C1713 A0394 A0398
> 903 Levels: 00000 00001 00140 00160 00670 00810 00940 01400 01470 01961 01968 10160 11000 11012 11042 11043 11044 11045 11100 11101 11200 11201 11401 11402 ... l8699
> 
> str(r1$CPT)
>   Factor w/ 903 levels "00000","00001",..: 773 773 816 783 739 741 743 739 739 741 ...
> 
> 
> And I want only those CPT's with leading alpha char in this column so I set the numeric leading char to Z
> 
> r1$B1 <- str_sub(r1$CPT,1,1)
> 
> r1$B1 <- as.factor(r1$B1) #Redundant
> levels(r1$B1)[levels(r1$B1) %in%  c('1','2','3','4','5','6','7','8','9','0')] <- 'Z'
> 
> When I check what I have done I find l & L
> 
> unique(r1$B1)
> #[1] A C Z L G Q U J V E S l D P
> #Levels: Z A C D E G J l L P Q S U V
> 
> So I change l to L
> r1$B1[r1$B1 == 'l'] <- 'L'
> 
> When I check again I have l & L but l = 0
> table(r1$B1)
> #   Z          A          C      D     E     G      J           l     L         P     Q     S     U     V
> #19639  1673   546     2     8   147   281     0    664     1    64    36   114    14
> 
> When I go to find those rows as if they existed, they are not accounted for?
> 
> tmp <- subset(r1, B1 == "l")
> print(tmp)
> Empty data.table (0 rows) of 9 cols: SavingsReversed,productID,ProviderID,PatientGender,ModCnt,Editnumber2...
> 
> And I have actually visually inspected the whole darn column, sheesh!
> 
> So I ignore it temporarily.
> 
> Now later on it resurfaces in a tutorial I am following for caret pkg.
> 
> preProcess(r1b, method = c("center", "scale"),
>             thresh = 0.95, pcaComp = NULL, na.remove = TRUE, k = 5,
>             knnSummary = mean, outcome = NULL, fudge = 0.2, numUnique = 3,
>             verbose = FALSE, freqCut = 95/5, uniqueCut = 10, cutoff = 0.9,
>             rangeBounds = c(0, 1))
> # Warning in preProcess.default(r1b, method = c("center", "scale"), thresh = 0.95,  :
> #                                 These variables have zero variances: B1l  <-------------yes this is a remnant of the r1$B1 clean-up
> #                               Created from 23141 samples and 22 variables
> #
> #                               Pre-processing:
> #                                 - centered (22)
> #                                 - ignored (0)
> #                                 - scaled (22)
> 
> 
> So my questions are, in consideration of regression modelling accuracy:
> 
> Why is this happening?
> How do I remove it?
> Or is it irrelevant and leave it be?
> 
> As always, thank you for you support.
> 
> WHP
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Nov 16 17:26:22 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Fri, 16 Nov 2018 08:26:22 -0800
Subject: [R] Help with factor column replacement value issue
In-Reply-To: <f9a594f7-c273-af25-23c4-6b5b756d935a@dewey.myzen.co.uk>
References: <BN7PR02MB50730DC2CE20AA5282EF53C3EADD0@BN7PR02MB5073.namprd02.prod.outlook.com>
 <f9a594f7-c273-af25-23c4-6b5b756d935a@dewey.myzen.co.uk>
Message-ID: <286C4D7F-A5F1-4702-B1DD-CD0906CF9C7A@dcn.davis.ca.us>

My suggestion is to avoid converting the column to a factor until it is cleaned up the way you want it. There is also the forcats package, but I still prefer to work with character data for cleaning. The stringsAsFactors=FALSE argument to read.table and friends helps with this.

On November 16, 2018 8:16:22 AM PST, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>Dear Bill
>
>When you do your step of replacing lower case l with upper case L the 
>level still stays in the factor even though it is empty. If that is a 
>nuisance x <- factor(x) will drop the unused levels. There are other 
>ways of doing this.
>
>Michael
>
>On 16/11/2018 15:38, Bill Poling wrote:
>> Hello:
>> 
>> I am running windows 10 -- R3.5.1 -- RStudio Version 1.1.456
>> 
>> I would like to know why when I replace a column value it still
>appears in subsequent routines:
>> 
>> My example:
>> 
>> r1$B1 is a Factor: It is created from the first character of a list
>of CPT codes, r1$CPT.
>> 
>> head(r1$CPT, N= 25)
>> [1] A4649 A4649 C9359 C1713 A0394 A0398
>> 903 Levels: 00000 00001 00140 00160 00670 00810 00940 01400 01470
>01961 01968 10160 11000 11012 11042 11043 11044 11045 11100 11101 11200
>11201 11401 11402 ... l8699
>> 
>> str(r1$CPT)
>>   Factor w/ 903 levels "00000","00001",..: 773 773 816 783 739 741
>743 739 739 741 ...
>> 
>> 
>> And I want only those CPT's with leading alpha char in this column so
>I set the numeric leading char to Z
>> 
>> r1$B1 <- str_sub(r1$CPT,1,1)
>> 
>> r1$B1 <- as.factor(r1$B1) #Redundant
>> levels(r1$B1)[levels(r1$B1) %in% 
>c('1','2','3','4','5','6','7','8','9','0')] <- 'Z'
>> 
>> When I check what I have done I find l & L
>> 
>> unique(r1$B1)
>> #[1] A C Z L G Q U J V E S l D P
>> #Levels: Z A C D E G J l L P Q S U V
>> 
>> So I change l to L
>> r1$B1[r1$B1 == 'l'] <- 'L'
>> 
>> When I check again I have l & L but l = 0
>> table(r1$B1)
>> #   Z          A          C      D     E     G      J           l    
>L         P     Q     S     U     V
>> #19639  1673   546     2     8   147   281     0    664     1    64  
> 36   114    14
>> 
>> When I go to find those rows as if they existed, they are not
>accounted for?
>> 
>> tmp <- subset(r1, B1 == "l")
>> print(tmp)
>> Empty data.table (0 rows) of 9 cols:
>SavingsReversed,productID,ProviderID,PatientGender,ModCnt,Editnumber2...
>> 
>> And I have actually visually inspected the whole darn column, sheesh!
>> 
>> So I ignore it temporarily.
>> 
>> Now later on it resurfaces in a tutorial I am following for caret
>pkg.
>> 
>> preProcess(r1b, method = c("center", "scale"),
>>             thresh = 0.95, pcaComp = NULL, na.remove = TRUE, k = 5,
>>             knnSummary = mean, outcome = NULL, fudge = 0.2, numUnique
>= 3,
>>             verbose = FALSE, freqCut = 95/5, uniqueCut = 10, cutoff =
>0.9,
>>             rangeBounds = c(0, 1))
>> # Warning in preProcess.default(r1b, method = c("center", "scale"),
>thresh = 0.95,  :
>> #                                 These variables have zero
>variances: B1l  <-------------yes this is a remnant of the r1$B1
>clean-up
>> #                               Created from 23141 samples and 22
>variables
>> #
>> #                               Pre-processing:
>> #                                 - centered (22)
>> #                                 - ignored (0)
>> #                                 - scaled (22)
>> 
>> 
>> So my questions are, in consideration of regression modelling
>accuracy:
>> 
>> Why is this happening?
>> How do I remove it?
>> Or is it irrelevant and leave it be?
>> 
>> As always, thank you for you support.
>> 
>> WHP
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> Confidentiality Notice This message is sent from Zelis.
>...{{dropped:13}}
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 

-- 
Sent from my phone. Please excuse my brevity.


From Bill@Poling @ending from zeli@@com  Fri Nov 16 17:47:27 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Fri, 16 Nov 2018 16:47:27 +0000
Subject: [R] Help with factor column replacement value issue
In-Reply-To: <CAGxFJbSVQH0Fmyx4D+rQjBERPDxxduvDwfet2AJtw5+zWhBa8Q@mail.gmail.com>
References: <BN7PR02MB50730DC2CE20AA5282EF53C3EADD0@BN7PR02MB5073.namprd02.prod.outlook.com>
 <CAGxFJbSVQH0Fmyx4D+rQjBERPDxxduvDwfet2AJtw5+zWhBa8Q@mail.gmail.com>
Message-ID: <BN7PR02MB50731F1BBB75B8B2A30CA34FEADD0@BN7PR02MB5073.namprd02.prod.outlook.com>

Thank you Bert.

WHP


As usual, careful reading of the relevant Help page would resolve the confusion.

from ?factor:

"factor(x, exclude = NULL) applied to a factor without NAs is a
no-operation unless there are unused levels: in that case, a factor
with the reduced level set is returned. If exclude is used, since R
version 3.4.0, excluding non-existing character levels is equivalent
to excluding nothing, and when excludeis a character vector, that is
applied to the levels of x. Alternatively, excludecan be factor with
the same level set as x and will exclude the levels present in
exclude."

In, subsetting a factor does not change the levels attribute, even if
some levels are not present. One must explicitly remove them, e.g.:

> f <- factor(letters[1:3])
## 3 levels, all present

> f[1:2]
[1] a b
Levels: a b c
## 3 levels, but one empty

> factor(f[1:2], exclude = NULL)
[1] a b
Levels: a b
## Now only two levels


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
On Fri, Nov 16, 2018 at 7:38 AM Bill Poling <mailto:Bill.Poling at zelis.com> wrote:
>
> Hello:
>
> I am running windows 10 -- R3.5.1 -- RStudio Version 1.1.456
>
> I would like to know why when I replace a column value it still appears in subsequent routines:
>
> My example:
>
> r1$B1 is a Factor: It is created from the first character of a list of CPT codes, r1$CPT.
>
> head(r1$CPT, N= 25)
> [1] A4649 A4649 C9359 C1713 A0394 A0398
> 903 Levels: 00000 00001 00140 00160 00670 00810 00940 01400 01470 01961 01968 10160 11000 11012 11042 11043 11044 11045 11100 11101 11200 11201 11401 11402 ... l8699
>
> str(r1$CPT)
> Factor w/ 903 levels "00000","00001",..: 773 773 816 783 739 741 743 739 739 741 ...
>
>
> And I want only those CPT's with leading alpha char in this column so I set the numeric leading char to Z
>
> r1$B1 <- str_sub(r1$CPT,1,1)
>
> r1$B1 <- as.factor(r1$B1) #Redundant
> levels(r1$B1)[levels(r1$B1) %in% c('1','2','3','4','5','6','7','8','9','0')] <- 'Z'
>
> When I check what I have done I find l & L
>
> unique(r1$B1)
> #[1] A C Z L G Q U J V E S l D P
> #Levels: Z A C D E G J l L P Q S U V
>
> So I change l to L
> r1$B1[r1$B1 == 'l'] <- 'L'
>
> When I check again I have l & L but l = 0
> table(r1$B1)
> # Z A C D E G J l L P Q S U V
> #19639 1673 546 2 8 147 281 0 664 1 64 36 114 14
>
> When I go to find those rows as if they existed, they are not accounted for?
>
> tmp <- subset(r1, B1 == "l")
> print(tmp)
> Empty data.table (0 rows) of 9 cols: SavingsReversed,productID,ProviderID,PatientGender,ModCnt,Editnumber2...
>
> And I have actually visually inspected the whole darn column, sheesh!
>
> So I ignore it temporarily.
>
> Now later on it resurfaces in a tutorial I am following for caret pkg.
>
> preProcess(r1b, method = c("center", "scale"),
> thresh = 0.95, pcaComp = NULL, na.remove = TRUE, k = 5,
> knnSummary = mean, outcome = NULL, fudge = 0.2, numUnique = 3,
> verbose = FALSE, freqCut = 95/5, uniqueCut = 10, cutoff = 0.9,
> rangeBounds = c(0, 1))
> # Warning in preProcess.default(r1b, method = c("center", "scale"), thresh = 0.95, :
> # These variables have zero variances: B1l <-------------yes this is a remnant of the r1$B1 clean-up
> # Created from 23141 samples and 22 variables
> #
> # Pre-processing:
> # - centered (22)
> # - ignored (0)
> # - scaled (22)
>
>
> So my questions are, in consideration of regression modelling accuracy:
>
> Why is this happening?
> How do I remove it?
> Or is it irrelevant and leave it be?
>
> As always, thank you for you support.
>
> WHP
>
>
>
>
>
>
>
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

From Bill@Poling @ending from zeli@@com  Fri Nov 16 18:13:43 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Fri, 16 Nov 2018 17:13:43 +0000
Subject: [R] Help with factor column replacement value issue
In-Reply-To: <286C4D7F-A5F1-4702-B1DD-CD0906CF9C7A@dcn.davis.ca.us>
References: <BN7PR02MB50730DC2CE20AA5282EF53C3EADD0@BN7PR02MB5073.namprd02.prod.outlook.com>
 <f9a594f7-c273-af25-23c4-6b5b756d935a@dewey.myzen.co.uk>
 <286C4D7F-A5F1-4702-B1DD-CD0906CF9C7A@dcn.davis.ca.us>
Message-ID: <BN7PR02MB5073617CA2E4C4B3027EA34CEADD0@BN7PR02MB5073.namprd02.prod.outlook.com>


Hi Jeff and Michael, thank you for your quick responses and suggestions I will try them out.

Appreciate everyone's time!

WHP

My suggestion is to avoid converting the column to a factor until it is cleaned up the way you want it. There is also the forcats package, but I still prefer to work with character data for cleaning. The stringsAsFactors=FALSE argument to read.table and friends helps with this.

On November 16, 2018 8:16:22 AM PST, Michael Dewey <mailto:lists at dewey.myzen.co.uk> wrote:
>Dear Bill
>
>When you do your step of replacing lower case l with upper case L the
>level still stays in the factor even though it is empty. If that is a
>nuisance x <- factor(x) will drop the unused levels. There are other
>ways of doing this.
>
>Michael
>
>On 16/11/2018 15:38, Bill Poling wrote:
>> Hello:
>>
>> I am running windows 10 -- R3.5.1 -- RStudio Version 1.1.456
>>
>> I would like to know why when I replace a column value it still
>appears in subsequent routines:
>>
>> My example:
>>
>> r1$B1 is a Factor: It is created from the first character of a list
>of CPT codes, r1$CPT.
>>
>> head(r1$CPT, N= 25)
>> [1] A4649 A4649 C9359 C1713 A0394 A0398
>> 903 Levels: 00000 00001 00140 00160 00670 00810 00940 01400 01470
>01961 01968 10160 11000 11012 11042 11043 11044 11045 11100 11101 11200
>11201 11401 11402 ... l8699
>>
>> str(r1$CPT)
>> Factor w/ 903 levels "00000","00001",..: 773 773 816 783 739 741
>743 739 739 741 ...
>>
>>
>> And I want only those CPT's with leading alpha char in this column so
>I set the numeric leading char to Z
>>
>> r1$B1 <- str_sub(r1$CPT,1,1)
>>
>> r1$B1 <- as.factor(r1$B1) #Redundant
>> levels(r1$B1)[levels(r1$B1) %in%
>c('1','2','3','4','5','6','7','8','9','0')] <- 'Z'
>>
>> When I check what I have done I find l & L
>>
>> unique(r1$B1)
>> #[1] A C Z L G Q U J V E S l D P
>> #Levels: Z A C D E G J l L P Q S U V
>>
>> So I change l to L
>> r1$B1[r1$B1 == 'l'] <- 'L'
>>
>> When I check again I have l & L but l = 0
>> table(r1$B1)
>> # Z A C D E G J l
>L P Q S U V
>> #19639 1673 546 2 8 147 281 0 664 1 64
> 36 114 14
>>
>> When I go to find those rows as if they existed, they are not
>accounted for?
>>
>> tmp <- subset(r1, B1 == "l")
>> print(tmp)
>> Empty data.table (0 rows) of 9 cols:
>SavingsReversed,productID,ProviderID,PatientGender,ModCnt,Editnumber2...
>>
>> And I have actually visually inspected the whole darn column, sheesh!
>>
>> So I ignore it temporarily.
>>
>> Now later on it resurfaces in a tutorial I am following for caret
>pkg.
>>
>> preProcess(r1b, method = c("center", "scale"),
>> thresh = 0.95, pcaComp = NULL, na.remove = TRUE, k = 5,
>> knnSummary = mean, outcome = NULL, fudge = 0.2, numUnique
>= 3,
>> verbose = FALSE, freqCut = 95/5, uniqueCut = 10, cutoff =
>0.9,
>> rangeBounds = c(0, 1))
>> # Warning in preProcess.default(r1b, method = c("center", "scale"),
>thresh = 0.95, :
>> # These variables have zero
>variances: B1l <-------------yes this is a remnant of the r1$B1
>clean-up
>> # Created from 23141 samples and 22
>variables
>> #
>> # Pre-processing:
>> # - centered (22)
>> # - ignored (0)
>> # - scaled (22)
>>
>>
>> So my questions are, in consideration of regression modelling
>accuracy:
>>
>> Why is this happening?
>> How do I remove it?
>> Or is it irrelevant and leave it be?
>>
>> As always, thank you for you support.
>>
>> WHP
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> Confidentiality Notice This message is sent from Zelis.
>...{{dropped:13}}
>>
>> ______________________________________________
>> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>

--
Sent from my phone. Please excuse my brevity.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

From Bill@Poling @ending from zeli@@com  Fri Nov 16 18:31:49 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Fri, 16 Nov 2018 17:31:49 +0000
Subject: [R] Help with factor column replacement value issue-SOLVED
Message-ID: <BN7PR02MB507332250D21839DDE839C55EADD0@BN7PR02MB5073.namprd02.prod.outlook.com>

Thanks again Michael, simple enough!

r1z <- r1
str(r1z$B1)
#Factor w/ 14 levels "Z","A","C","D",..: 2 2 3 3 2 2 2 2 2 2 ...

# When you do your step of replacing lower case l with upper case L the
# level still stays in the factor even though it is empty. If that is a nuisance
r1z$B1 <- factor(r1z$B1)
#will drop the unused levels. There are other ways of doing this.
str(r1z$B1)
#Factor w/ 13 levels "Z","A","C","D",..: 2 2 3 3 2 2 2 2 2 2 ...
table(r1z$B1)
# Z     A     C     D     E     G     J     L     P     Q     S     U     V
# 19600  1671   543     2     8   147   281   660     1    64    36   114    14


Dear Bill

When you do your step of replacing lower case l with upper case L the
level still stays in the factor even though it is empty. If that is a
nuisance x <- factor(x) will drop the unused levels. There are other
ways of doing this.

Michael

On 16/11/2018 15:38, Bill Poling wrote:
> Hello:
>
> I am running windows 10 -- R3.5.1 -- RStudio Version 1.1.456
>
> I would like to know why when I replace a column value it still appears in subsequent routines:
>
> My example:
>
> r1$B1 is a Factor: It is created from the first character of a list of CPT codes, r1$CPT.
>
> head(r1$CPT, N= 25)
> [1] A4649 A4649 C9359 C1713 A0394 A0398
> 903 Levels: 00000 00001 00140 00160 00670 00810 00940 01400 01470 01961 01968 10160 11000 11012 11042 11043 11044 11045 11100 11101 11200 11201 11401 11402 ... l8699
>
> str(r1$CPT)
> Factor w/ 903 levels "00000","00001",..: 773 773 816 783 739 741 743 739 739 741 ...
>
>
> And I want only those CPT's with leading alpha char in this column so I set the numeric leading char to Z
>
> r1$B1 <- str_sub(r1$CPT,1,1)
>
> r1$B1 <- as.factor(r1$B1) #Redundant
> levels(r1$B1)[levels(r1$B1) %in% c('1','2','3','4','5','6','7','8','9','0')] <- 'Z'
>
> When I check what I have done I find l & L
>
> unique(r1$B1)
> #[1] A C Z L G Q U J V E S l D P
> #Levels: Z A C D E G J l L P Q S U V
>
> So I change l to L
> r1$B1[r1$B1 == 'l'] <- 'L'
>
> When I check again I have l & L but l = 0
> table(r1$B1)
> # Z A C D E G J l L P Q S U V
> #19639 1673 546 2 8 147 281 0 664 1 64 36 114 14
>
> When I go to find those rows as if they existed, they are not accounted for?
>
> tmp <- subset(r1, B1 == "l")
> print(tmp)
> Empty data.table (0 rows) of 9 cols: SavingsReversed,productID,ProviderID,PatientGender,ModCnt,Editnumber2...
>
> And I have actually visually inspected the whole darn column, sheesh!
>
> So I ignore it temporarily.
>
> Now later on it resurfaces in a tutorial I am following for caret pkg.
>
> preProcess(r1b, method = c("center", "scale"),
> thresh = 0.95, pcaComp = NULL, na.remove = TRUE, k = 5,
> knnSummary = mean, outcome = NULL, fudge = 0.2, numUnique = 3,
> verbose = FALSE, freqCut = 95/5, uniqueCut = 10, cutoff = 0.9,
> rangeBounds = c(0, 1))
> # Warning in preProcess.default(r1b, method = c("center", "scale"), thresh = 0.95, :
> # These variables have zero variances: B1l <-------------yes this is a remnant of the r1$B1 clean-up
> # Created from 23141 samples and 22 variables
> #
> # Pre-processing:
> # - centered (22)
> # - ignored (0)
> # - scaled (22)
>
>
> So my questions are, in consideration of regression modelling accuracy:
>
> Why is this happening?
> How do I remove it?
> Or is it irrelevant and leave it be?
>
> As always, thank you for you support.
>
> WHP
>
>
>
>
>
>
>
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

--
Michael
http://www.dewey.myzen.co.uk/home.html

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

From m@echler @ending from @t@t@m@th@ethz@ch  Fri Nov 16 18:52:33 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 16 Nov 2018 18:52:33 +0100
Subject: [R] which() function help page precision
In-Reply-To: <129828AC-9637-4237-87DD-87D7E2199A50@gmail.com>
References: <da1b0b8760a64572a340166d731c2353@SERV-EXCH11.cixtec.l>
 <129828AC-9637-4237-87DD-87D7E2199A50@gmail.com>
Message-ID: <23535.993.632344.989070@stat.math.ethz.ch>

>>>>> peter dalgaard 
>>>>>     on Fri, 16 Nov 2018 13:39:27 +0100 writes:

    > Well, "Basically, " is an excuse for not being
    > accurate. Making the code more complex doesn't really help
    > the explanation. It could be better to just add "(except
    > for NA handling)" or so.
    > -pd

or --- applying Swiss diplomacy finding a way-between ;-) --- 

" Basically, the result is (1:length(x))[x], or to cover more
  cases, including when x has NA's,
  seq_along(x)[!is.na(x) & x] "

to also cover the 0-length case and come pretty close to the "truth".

Martin


 
    >> On 16 Nov 2018, at 11:08 , buzon informatica, ige
    >> <ige.informatica at ige.eu> wrote:
    >> 
    >> The which() function help page states that, in the
    >> default case, what the function returns is: " Basically,
    >> the result is (1:length(x))[x]."  That would only be true
    >> if there are not any NA values in x. I think it would be
    >> more accurate to say: "Basically, the result is
    >> (1:length(x))[!is.na(x) & x]."
    >> 
    >> The "strange" (IMHO) behavior of logical indexing in R
    >> makes it necessary to exclude NA values.  For this
    >> reason, I use to wrap logical indices with which(). I
    >> would have written the above expression as:
    >> (1:length(x))[which(x)] But that would have been a really
    >> bad explanation of how the which() function works ;)
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.

    > -- 
    > Peter Dalgaard, Professor, Center for Statistics,
    > Copenhagen Business School Solbjerg Plads 3, 2000
    > Frederiksberg, Denmark Phone: (+45)38153501 Office: A 4.23
    > Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From ju@ngomezdu@@o @ending from gm@il@com  Sat Nov 17 12:06:42 2018
From: ju@ngomezdu@@o @ending from gm@il@com (Juan Gomez)
Date: Sat, 17 Nov 2018 12:06:42 +0100
Subject: [R] which() function help page precision
Message-ID: <CAN+qQ09NgxwTGpcSqb8U0mpf4McjEdDUp322XUbttL97jSeGZQ@mail.gmail.com>

Hi again (, I am the PO from my own email account)
I agree that the word  "basically" puts the NA issues aside. But my
point is that  R subsetting  behavior when there are  NAs in a logical
index is quite tricky to say the less, and deserves the trouble of
pointing it out in every place it is appropiate. As  "which()" is the
function I use to overcome this issue, I thought it would be good to
emphasize that  it solves this situation in a different way that the
subsetting operation does.
I am aware that it is clearly stated  above in the help page though.
But I still would change the expression rather than "hiding" this distinction.
And the "diplomatic refinement seems even better to me.


From juli@n@righ@@@mpedro @ending from gm@il@com  Sat Nov 17 21:01:12 2018
From: juli@n@righ@@@mpedro @ending from gm@il@com (Julian Righ Sampedro)
Date: Sat, 17 Nov 2018 21:01:12 +0100
Subject: [R] Multiplication of regression coefficient by factor type variable
Message-ID: <CAMbzGaiL=wVSiu0Qu_KhzdOkxZkqaaJO=53VRWeLQrBedi-h-A@mail.gmail.com>

Dear all,

In a context of regression, I have three regressors, two of which are
categorical variables (sex and education) and have class 'factor'.

y = data$income
x1 = as.factor(data$sex)  # 2 levels
x2 = data$age  # continuous
x3 = as.factor(data$ed)  # 8 levels

for example, the first entries of x3 are

head(x3)[1] 5 3 5 5 4 2
Levels: 1 2 3 4 5 6 7 8

When we call the model, the output looks like this

model1=lm(y ~ x1 + x2 + x3, data = data)
summary(model1)

Residuals:
Min     1Q Median     3Q    Max -31220  -6300   -594   4429 190731

Coefficients:
        Estimate Std. Error t value Pr(>|t|)    (Intercept)  1440.66
 3809.99   0.378 0.705417
x1          -4960.88     772.96  -6.418 2.13e-10 ***
x2            181.45      25.03   7.249 8.41e-13 ***
x32          2174.95    3453.22   0.630 0.528948
x33          7497.68    3428.94   2.187 0.029004 *
x34          8278.97    3576.30   2.315 0.020817 *
x35         13686.88    3454.93   3.962 7.97e-05 ***
x36         15902.92    4408.49   3.607 0.000325 ***
x37         28773.13    3696.77   7.783 1.76e-14 ***
x38         31455.55    5448.11   5.774 1.03e-08 ***---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 12060 on 1001 degrees of freedom
Multiple R-squared:  0.2486,    Adjusted R-squared:  0.2418
F-statistic: 36.79 on 9 and 1001 DF,  p-value: < 2.2e-16

Now suppose I want to compute the residuals. To do so I first need to
compute the prediction by the model. (I use it in a cross validation
context so it is a partial display of the code)

yhat1 = model1$coef[1] + model1$coef[2]*x1[i] + model1$coef[3]*x2[i] +
model1$coef[4]*x3[i]

But I get the following warnings

Warning messages:1: In Ops.factor(model1$coef[2], x1[i]) : ?*? not
meaningful for factors2: In Ops.factor(model1$coef[4], x3[i]) : ?*?
not meaningful for factors

1st question: Is there a way to multiply the coefficient by the 'factor'
without having to transform my 'factor' into a 'numeric' type variable ?

2nd question: Since x3 is associated with 7 parameters (one for x32, one
for x33, ... , one for x38), how do I multiply the 'correct' parameter
coefficient with my 'factor' x3 ?

I have been considering a 'if then' solution, but to no avail. I also have
considered splitting my x3 variable into 8 binary variables without
succeeding. What may be the best approach ? Thank you for your help.

Since I understand this my not be specific enough, I add here the complete
code

# for n-fold cross validation# fit models on leave-one-out samples
x1= as.factor(data$sex)
x2= data$age
x3= as.factor(data$ed)
yn=data$income
n = length(yn)
e1 = e2 = numeric(n)

for (i in 1:n) {
  # the ith observation is excluded
  y = yn[-i]
  x_1 = x1[-i]
  x_2 = x2[-i]
  x_3 = x3[-i]
  x_4 = as.factor(cf4)[-i]
  # fit the first model without the ith observation
  J1 = lm(y ~ x_1 + x_2 + x_3)
  yhat1 = J1$coef[1] + J1$coef[2]*x1[i] + J1$coef[3]*x2[i] + J1$coef[4]*x3[i]
  # construct the ith part of the loss function for model 1
  e1[i] = yn[i] - yhat1
  # fit the second model without the ith observation
  J2 = lm(y ~ x_1 + x_2 + x_3  + x_4)
  yhat2=J2$coef[1]+J2$coef[2]*x1[i]+J2$coef[3]*x2[i]+J2$coef[4]*x3[i]+J2$coef[5]*cf4[i]
  e2[i] = yn[i] - yhat2
 }
 sqrt(c(mean(e1^2),mean(e2^2))) # RMSE

cf4 is a variable corresponding to groups (using mixtures) . What we want
to demonstrate is that the prediction error after cross-validation is lower
when we include this latent grouping variable. It works wonders when the
categorical variables are treated as 'numeric' variables. Though the ols
estimates are obviously very different.

Thank you in advance for your views on the problem.

Best Regards,

julian

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Sat Nov 17 22:58:26 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sat, 17 Nov 2018 13:58:26 -0800
Subject: [R] Multiplication of regression coefficient by factor type
 variable
In-Reply-To: <CAMbzGaiL=wVSiu0Qu_KhzdOkxZkqaaJO=53VRWeLQrBedi-h-A@mail.gmail.com>
References: <CAMbzGaiL=wVSiu0Qu_KhzdOkxZkqaaJO=53VRWeLQrBedi-h-A@mail.gmail.com>
Message-ID: <CAGxFJbR94XsipRJum59=Ze3i5FMuzwyyxtOL96V2ErpvpUrXKQ@mail.gmail.com>

You shouldn't have to do any of what you are doing.

See ?predict.lm  and note the "newdata" argument.

Also, you should spend some time studying a linear model text, as your
question appears to indicate some basic confusion (e.g. about
"contrasts" ) about how they work.


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Nov 17, 2018 at 1:24 PM Julian Righ Sampedro
<julian.righ.sampedro at gmail.com> wrote:
>
> Dear all,
>
> In a context of regression, I have three regressors, two of which are
> categorical variables (sex and education) and have class 'factor'.
>
> y = data$income
> x1 = as.factor(data$sex)  # 2 levels
> x2 = data$age  # continuous
> x3 = as.factor(data$ed)  # 8 levels
>
> for example, the first entries of x3 are
>
> head(x3)[1] 5 3 5 5 4 2
> Levels: 1 2 3 4 5 6 7 8
>
> When we call the model, the output looks like this
>
> model1=lm(y ~ x1 + x2 + x3, data = data)
> summary(model1)
>
> Residuals:
> Min     1Q Median     3Q    Max -31220  -6300   -594   4429 190731
>
> Coefficients:
>         Estimate Std. Error t value Pr(>|t|)    (Intercept)  1440.66
>  3809.99   0.378 0.705417
> x1          -4960.88     772.96  -6.418 2.13e-10 ***
> x2            181.45      25.03   7.249 8.41e-13 ***
> x32          2174.95    3453.22   0.630 0.528948
> x33          7497.68    3428.94   2.187 0.029004 *
> x34          8278.97    3576.30   2.315 0.020817 *
> x35         13686.88    3454.93   3.962 7.97e-05 ***
> x36         15902.92    4408.49   3.607 0.000325 ***
> x37         28773.13    3696.77   7.783 1.76e-14 ***
> x38         31455.55    5448.11   5.774 1.03e-08 ***---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Residual standard error: 12060 on 1001 degrees of freedom
> Multiple R-squared:  0.2486,    Adjusted R-squared:  0.2418
> F-statistic: 36.79 on 9 and 1001 DF,  p-value: < 2.2e-16
>
> Now suppose I want to compute the residuals. To do so I first need to
> compute the prediction by the model. (I use it in a cross validation
> context so it is a partial display of the code)
>
> yhat1 = model1$coef[1] + model1$coef[2]*x1[i] + model1$coef[3]*x2[i] +
> model1$coef[4]*x3[i]
>
> But I get the following warnings
>
> Warning messages:1: In Ops.factor(model1$coef[2], x1[i]) : ?*? not
> meaningful for factors2: In Ops.factor(model1$coef[4], x3[i]) : ?*?
> not meaningful for factors
>
> 1st question: Is there a way to multiply the coefficient by the 'factor'
> without having to transform my 'factor' into a 'numeric' type variable ?
>
> 2nd question: Since x3 is associated with 7 parameters (one for x32, one
> for x33, ... , one for x38), how do I multiply the 'correct' parameter
> coefficient with my 'factor' x3 ?
>
> I have been considering a 'if then' solution, but to no avail. I also have
> considered splitting my x3 variable into 8 binary variables without
> succeeding. What may be the best approach ? Thank you for your help.
>
> Since I understand this my not be specific enough, I add here the complete
> code
>
> # for n-fold cross validation# fit models on leave-one-out samples
> x1= as.factor(data$sex)
> x2= data$age
> x3= as.factor(data$ed)
> yn=data$income
> n = length(yn)
> e1 = e2 = numeric(n)
>
> for (i in 1:n) {
>   # the ith observation is excluded
>   y = yn[-i]
>   x_1 = x1[-i]
>   x_2 = x2[-i]
>   x_3 = x3[-i]
>   x_4 = as.factor(cf4)[-i]
>   # fit the first model without the ith observation
>   J1 = lm(y ~ x_1 + x_2 + x_3)
>   yhat1 = J1$coef[1] + J1$coef[2]*x1[i] + J1$coef[3]*x2[i] + J1$coef[4]*x3[i]
>   # construct the ith part of the loss function for model 1
>   e1[i] = yn[i] - yhat1
>   # fit the second model without the ith observation
>   J2 = lm(y ~ x_1 + x_2 + x_3  + x_4)
>   yhat2=J2$coef[1]+J2$coef[2]*x1[i]+J2$coef[3]*x2[i]+J2$coef[4]*x3[i]+J2$coef[5]*cf4[i]
>   e2[i] = yn[i] - yhat2
>  }
>  sqrt(c(mean(e1^2),mean(e2^2))) # RMSE
>
> cf4 is a variable corresponding to groups (using mixtures) . What we want
> to demonstrate is that the prediction error after cross-validation is lower
> when we include this latent grouping variable. It works wonders when the
> categorical variables are treated as 'numeric' variables. Though the ols
> estimates are obviously very different.
>
> Thank you in advance for your views on the problem.
>
> Best Regards,
>
> julian
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @ending from @uckl@nd@@c@nz  Sat Nov 17 23:16:46 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sun, 18 Nov 2018 11:16:46 +1300
Subject: [R] The Suggests field in a DESCRIPTION file.
Message-ID: <e0dc2d56-0080-5fe0-f832-d8c0fe39becb@auckland.ac.nz>


I am building a package which contains a function from which I wish to 
call the fortune() function from the fortunes package --- if that 
package is available.

I have place the line

    Suggests: fortunes

in the DESCRIPTION file.

In my code for the function that I am writing (let's call it "foo")
I put

> fortOK <- requireNamespace(fortunes,quietly=TRUE)
>         if(fortOK) {
>             fortunes::fortune()
>         }

thinking that I was following all of the prescriptions in "Writing R 
Extensions".  Yet when I do R CMD check on the package I get

> * checking R code for possible problems ... NOTE
> foo: no visible binding for global variable ?fortunes?
> Undefined global functions or variables:
>   fortunes

What am I doing wrong?

Thanks for any insight.

cheers,

Rolf Turner

P. S.  I tried putting an "imports(fortunes)" in the NAMESPACE file, but 
this just made matters worse:

> * checking package dependencies ... ERROR
> Namespace dependency not required: ?fortunes?

Huh?  What on earth is this actually saying?  I cannot parse this error 
message.

R. T.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jfox @ending from mcm@@ter@c@  Sat Nov 17 23:22:32 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Sat, 17 Nov 2018 22:22:32 +0000
Subject: [R] The Suggests field in a DESCRIPTION file.
In-Reply-To: <15223_1542493030_wAHMH8uY028566_e0dc2d56-0080-5fe0-f832-d8c0fe39becb@auckland.ac.nz>
References: <15223_1542493030_wAHMH8uY028566_e0dc2d56-0080-5fe0-f832-d8c0fe39becb@auckland.ac.nz>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836942F55@FHSDB2D11-2.csu.mcmaster.ca>

Dear Rolf,

"fortunes" needs to be quoted in requireNamespace("fortunes", quietly=TRUE).

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rolf Turner
> Sent: Saturday, November 17, 2018 5:17 PM
> To: r-help at r-project.org
> Subject: [R] The Suggests field in a DESCRIPTION file.
> 
> 
> I am building a package which contains a function from which I wish to call the
> fortune() function from the fortunes package --- if that package is available.
> 
> I have place the line
> 
>     Suggests: fortunes
> 
> in the DESCRIPTION file.
> 
> In my code for the function that I am writing (let's call it "foo") I put
> 
> > fortOK <- requireNamespace(fortunes,quietly=TRUE)
> >         if(fortOK) {
> >             fortunes::fortune()
> >         }
> 
> thinking that I was following all of the prescriptions in "Writing R Extensions".
> Yet when I do R CMD check on the package I get
> 
> > * checking R code for possible problems ... NOTE
> > foo: no visible binding for global variable ?fortunes?
> > Undefined global functions or variables:
> >   fortunes
> 
> What am I doing wrong?
> 
> Thanks for any insight.
> 
> cheers,
> 
> Rolf Turner
> 
> P. S.  I tried putting an "imports(fortunes)" in the NAMESPACE file, but this just
> made matters worse:
> 
> > * checking package dependencies ... ERROR Namespace dependency not
> > required: ?fortunes?
> 
> Huh?  What on earth is this actually saying?  I cannot parse this error
> message.
> 
> R. T.
> 
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From r@turner @ending from @uckl@nd@@c@nz  Sat Nov 17 23:30:08 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sun, 18 Nov 2018 11:30:08 +1300
Subject: [R] The Suggests field in a DESCRIPTION file --- never mind!!!
In-Reply-To: <e0dc2d56-0080-5fe0-f832-d8c0fe39becb@auckland.ac.nz>
References: <e0dc2d56-0080-5fe0-f832-d8c0fe39becb@auckland.ac.nz>
Message-ID: <6897563c-1343-0401-e642-5b7abe97f6f8@auckland.ac.nz>


I figured it out.  The package name in the call to requireNamespace() 
has to be a *text string*.  I should've had:

     fortOK <- requireNamespace("fortunes",quietly=TRUE)

So require() takes a package name, but requireNamespace() takes a 
*string* specifying the package name.  Trap for young players.

Psigh.

cheers,

Rolf Turner

On 11/18/18 11:16 AM, Rolf Turner wrote:
> 
> I am building a package which contains a function from which I wish to 
> call the fortune() function from the fortunes package --- if that 
> package is available.
> 
> I have place the line
> 
>  ?? Suggests: fortunes
> 
> in the DESCRIPTION file.
> 
> In my code for the function that I am writing (let's call it "foo")
> I put
> 
>> fortOK <- requireNamespace(fortunes,quietly=TRUE)
>> ??????? if(fortOK) {
>> ??????????? fortunes::fortune()
>> ??????? }
> 
> thinking that I was following all of the prescriptions in "Writing R 
> Extensions".? Yet when I do R CMD check on the package I get
> 
>> * checking R code for possible problems ... NOTE
>> foo: no visible binding for global variable ?fortunes?
>> Undefined global functions or variables:
>> ? fortunes
> 
> What am I doing wrong?
> 
> Thanks for any insight.
> 
> cheers,
> 
> Rolf Turner
> 
> P. S.? I tried putting an "imports(fortunes)" in the NAMESPACE file, but 
> this just made matters worse:
> 
>> * checking package dependencies ... ERROR
>> Namespace dependency not required: ?fortunes?
> 
> Huh?? What on earth is this actually saying?? I cannot parse this error 
> message.
> 
> R. T.
> 


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @ending from @uckl@nd@@c@nz  Sat Nov 17 23:31:27 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sun, 18 Nov 2018 11:31:27 +1300
Subject: [R] The Suggests field in a DESCRIPTION file.
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836942F55@FHSDB2D11-2.csu.mcmaster.ca>
References: <15223_1542493030_wAHMH8uY028566_e0dc2d56-0080-5fe0-f832-d8c0fe39becb@auckland.ac.nz>
 <ACD1644AA6C67E4FBD0C350625508EC836942F55@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <4d02d071-b01d-781c-7d66-f19c40e786ac@auckland.ac.nz>

On 11/18/18 11:22 AM, Fox, John wrote:
> Dear Rolf,
> 
> "fortunes" needs to be quoted in requireNamespace("fortunes", quietly=TRUE).
> 
> I hope this helps,
>   John

Thanks.  I actually figured this out myself, just before getting your 
message!

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From p_connolly @ending from @ling@hot@co@nz  Sun Nov 18 09:44:38 2018
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Sun, 18 Nov 2018 21:44:38 +1300
Subject: [R] 
 Corrupting files while copying (was Re: saveRDS() and readRDS()
 Why? [solved, pretty much anyway])
In-Reply-To: <CA+vqiLE2D2R-AYfNA8EPZFPtxuwnUcsCCuADTqCq8c=0xeVPng@mail.gmail.com>
References: <20181112072806.GH8540@slingshot.co.nz>
 <9795CBFC-5F8C-4084-9704-98614BA2A626@gmail.com>
 <46f6c0217cf594e544eef3257376d598@slingshot.co.nz>
 <CAF8bMcaejV7GdwwFFB7fro2AHD9FfqHJ2J26EZG56kyQ08UP=A@mail.gmail.com>
 <3b49eb752bb2b108a72683df1d30f50b@slingshot.co.nz>
 <CAF8bMcYaXYB=PAZ9D2sDHqP1oH2To8u4A1EMrk0EGGdLdCMb=g@mail.gmail.com>
 <d036a9b8893a1ade51c78e7325d8c89b@slingshot.co.nz>
 <CAF8bMcY_fauLbmKNY-yb0JJJu2c-Oz0tngHhHkdyFwo7ajVDyg@mail.gmail.com>
 <20181114073555.GI8540@slingshot.co.nz>
 <CA+vqiLE2D2R-AYfNA8EPZFPtxuwnUcsCCuADTqCq8c=0xeVPng@mail.gmail.com>
Message-ID: <20181118084438.GJ8540@slingshot.co.nz>

Sequence of steps:

Using R-3.5.1 and Windows 7 with the latest Rstudio, shared directory
as working directory on Virtual Box host machine:

> x <- airquality
> saveRDS(x, file = "x.rds")
> saveRDS(x, file = "y.rds")

On guest machine Mint Linux 17.3, KDE desktop, copy x.rds & y.rds to
working directory PWD using file manager Dolphin.

(Don't have the precise version of VirtualBox right now.)

> x <- readRDS(file =  "x.rds")
Error in readRDS(file = "x.rds") : error reading from connection
> x <- readRDS(file =  "y.rds")

>   tools::md5sum(c("x.rds", "y.rds"))
                             x.rds                              y.rds
"5fef054848f39b4be02b7c54f1c71a20" "978a64d1dd342d16a381c9ca728d3665"

Yet, if instead of using Dolphin, use bash commands from the shared
directory 

$ cp *.rds ~/PWD/

no error reading from the connection or other differences between
x.rds and y.rds.

head(x)

> head(datasets::airquality)
  Ozone Solar.R Wind Temp Month Day
1    41     190  7.4   67     5   1
2    36     118  8.0   72     5   2
3    12     149 12.6   74     5   3
4    18     313 11.5   62     5   4
5    NA      NA 14.3   56     5   5
6    28      NA 14.9   66     5   6
> 

On Thu, 15-Nov-2018 at 09:53AM -0500, Ista Zahn wrote:

|> Hi Patrick,
|> 
|> I think it would help to start from the beginning and give complete
|> (but concise!) replication instructions, including telling us what
|> host and gest operating systems you are using (including the
|> versions), the version
|>  of virtualbox you used, and exactly what steps are needed to
|> reproduce the surprising behavior.
|> 
|> Best,
|> Ista
|> On Wed, Nov 14, 2018 at 2:36 AM Patrick Connolly
|> <p_connolly at slingshot.co.nz> wrote:
|> >
|> > Thanks William,
|> >
|> > I've used Dolphin for years and never encountered that phenomenon.
|> > Even so, that description doesn't fit what's going on here.  1.7
|> > kilobytes is hardly a 'large directory'.
|> >
|> > The problem seems to be with the way VirtualBox mounts directories
|> > which isn't an R issue, nor is the fact that copying from Linux to
|> > Windows isn't affected.  But the fact that it happens only with rds
|> > files that use the name of the R object as part of their own names
|> > must be an R issue (that surfaces only when other conditions are
|> > present).
|> >
|> > Theories short of divine intervention appreciated.
|> >
|> >
|> >
|> > On Tue, 13-Nov-2018 at 02:22PM -0800, William Dunlap wrote:
|> >
|> > |> Perhaps you got bitten by Dolphin's non-modal dialogs, as described in
|> > |> https://userbase.kde.org/Dolphin/File_Management:
|> > |>
|> > |> Non Modal Dialogs
|> > |>
|> > |> When Moving, Copying or Deleting files/directories the dialog disappears
|> > |> even when the operation has not yet completed. A progress bar then appears
|> > |> in the bottom right of the screen, this then disappears also, if you want
|> > |> see the progress you need to click a small (i) information icon in the
|> > |> system tray.
|> > |>
|> > |>
|> > |> Warning
|> > |> New users who are not used to this way of working (and even experienced
|> > |> users) can get caught out by this, if you are Moving, Copying or Deleting
|> > |> large directories then you need to use the icon to monitor the progress of
|> > |> your operation. If you don't then any subsequent actions you do, may well
|> > |> use an incomplete file structure resulting in corrupted files. You have
|> > |> been warned!
|> > |>
|> > |> Bill Dunlap
|> > |> TIBCO Software
|> > |> wdunlap tibco.com
|> > |>
|> > |> On Tue, Nov 13, 2018 at 2:10 PM, p_connolly <p_connolly at slingshot.co.nz>
|> > |> wrote:
|> > |>
|> > |> > This is getting more strange.
|> > |> >
|> > |> > I normally copy from the shared folder to the appropriate directory using
|> > |> > Dolphin, the KDE file manager.  If instead I use the standard bash cp
|> > |> > command, no corruption happens -- at least with the limited testing I have
|> > |> > done.  There also seems to be no problem copying from Linux to Windows.  I
|> > |> > installed R-3.5.1 for Windows just to eliminate that possible issue.
|> > |> >
|> > |> > However, R has *something* to do with it because it was used to make the
|> > |> > .rds file.  Just how the relationship between the name of the R object and
|> > |> > the name of the .rds file comes into it, I can't imagine.
|> > |> >
|> > |> > Thanks for the suggestion William.
|> > |> >
|> > |> >
|> > |> > On 2018-11-14 06:26, William Dunlap wrote:
|> > |> >
|> > |> >> It seems like copying the files corrupted them. How did you copy them
|> > |> >> (with R
|> > |> >> or cp or copy or ftp, etc.)?  I don't see how this has anything to do
|> > |> >> with R.
|> > |> >>
|> > |> >> Bill Dunlap
|> > |> >> TIBCO Software
|> > |> >> wdunlap tibco.com [1]
|> > |> >> On Mon, Nov 12, 2018 at 7:10 PM, p_connolly
|> > |> >> <p_connolly at slingshot.co.nz> wrote:
|> > |> >>
|> > |> > [...]
|> > |> >
|> > |> >
|> >
|> > --
|> > ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
|> >    ___    Patrick Connolly
|> >  {~._.~}                   Great minds discuss ideas
|> >  _( Y )_                 Average minds discuss events
|> > (:_~*~_:)                  Small minds discuss people
|> >  (_)-(_)                              ..... Eleanor Roosevelt
|> >
|> > ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
|> >
|> > ______________________________________________
|> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> > https://stat.ethz.ch/mailman/listinfo/r-help
|> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> > and provide commented, minimal, self-contained, reproducible code.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From ch@l@bi@el@he @ending from y@hoo@de  Mon Nov 19 10:48:40 2018
From: ch@l@bi@el@he @ending from y@hoo@de (Elahe chalabi)
Date: Mon, 19 Nov 2018 09:48:40 +0000 (UTC)
Subject: [R] subset English language using textcat package
References: <1272487832.4543659.1542620920563.ref@mail.yahoo.com>
Message-ID: <1272487832.4543659.1542620920563@mail.yahoo.com>

Hi all, 

How is it possible to subset English text from a df containing German and English texts using textcat package?



    > library(textcat)
    > dput(data) 
    structure(list(x = structure(c(2L, 6L, 5L, 3L, 1L, 4L), .Label = c("Dieses Buch ist erstaunlich", 
    "I love this book", "ich liebe dieses Buch", "mehrere b?cher in prozess", 
    "several books in proccess", "This book is amazing"), class = "factor")), row.names = c(NA, 
    -6L), class = "data.frame")

I want the output to be like the following:


    "I love this book"  "This book is amazing"  "several books in proccess"


Thanks for any help!
Elahe


From rui@kepler @ending from gm@il@com  Mon Nov 19 11:00:54 2018
From: rui@kepler @ending from gm@il@com (Rui Fernandes)
Date: Mon, 19 Nov 2018 10:00:54 +0000
Subject: [R] Request for aid in first R script
Message-ID: <CAFXK4YfT-1C3Xm8y128Nvm-iek8RPScot3v2mPL6v-CkG0k2qg@mail.gmail.com>

Good morning

My compliments to all.

Since I'm a newbie on R, I was wondering if you could help me to achieve a
small project that I think it's possible with this project (I cant seem to
find a similar tool)

I have a data file with about 2000 value lines, organized like this:

x;y;z;j;
...

I want to find diferent correlations (linear regression with
Levenberg?Marquardt or least squares) between the x values and a y or z
pair. For instance, between x and y.

So, what I'm trying to do is:

1) Load the file (is there a limit on the load size? If yes, can I load it
in sequence by parts?)
2) Define 100 sets of 20 values each (also sequence, from x1 to xn: first
from x1 to x20, next from x21 to x41, etc.) or process one set at the time
in case of file limits in 1)
3) Define a fitting function
4) Use the same function model to find the best fit for each set
5) Save in a file, the coefficients of those fits.

Can this be done accurately with R?

It would save me a lot of programming. The files will soon have about 1
million lines, which is a lot to process.

I would apreciate very much if someone could help me.

Kind regards

Kepler

	[[alternative HTML version deleted]]


From robertburbidged@t@ @ending from y@hoo@co@uk  Mon Nov 19 12:13:29 2018
From: robertburbidged@t@ @ending from y@hoo@co@uk (Robert David Burbidge)
Date: Mon, 19 Nov 2018 11:13:29 +0000
Subject: [R] subset English language using textcat package
In-Reply-To: <1272487832.4543659.1542620920563@mail.yahoo.com>
References: <1272487832.4543659.1542620920563.ref@mail.yahoo.com>
 <1272487832.4543659.1542620920563@mail.yahoo.com>
Message-ID: <7633e871-766d-ed35-ccff-deb3379af499@yahoo.co.uk>

Look at the help docs and examples for textcat and sapply:

print(as.character(data$x[sapply(data$x, textcat)=="english"]))

Although textcat defaults classify "This book is amazing" as dutch, so 
you may want to read the help for textcat and change the profile db 
("p") or "method".

On 19/11/2018 09:48, Elahe chalabi via R-help wrote:
> Hi all,
>
> How is it possible to subset English text from a df containing German and English texts using textcat package?
>
>
>
>      > library(textcat)
>      > dput(data)
>      structure(list(x = structure(c(2L, 6L, 5L, 3L, 1L, 4L), .Label = c("Dieses Buch ist erstaunlich",
>      "I love this book", "ich liebe dieses Buch", "mehrere b?cher in prozess",
>      "several books in proccess", "This book is amazing"), class = "factor")), row.names = c(NA,
>      -6L), class = "data.frame")
>
> I want the output to be like the following:
>
>
>      "I love this book"  "This book is amazing"  "several books in proccess"
>
>
> Thanks for any help!
> Elahe
>


From thierry@onkelinx @ending from inbo@be  Mon Nov 19 12:24:26 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Mon, 19 Nov 2018 12:24:26 +0100
Subject: [R] Request for aid in first R script
In-Reply-To: <CAFXK4YfT-1C3Xm8y128Nvm-iek8RPScot3v2mPL6v-CkG0k2qg@mail.gmail.com>
References: <CAFXK4YfT-1C3Xm8y128Nvm-iek8RPScot3v2mPL6v-CkG0k2qg@mail.gmail.com>
Message-ID: <CAJuCY5zpH-82ROmJY1X7+AqtSmXNGFR46oSqa6-Oo0Zc6jGdGQ@mail.gmail.com>

Dear Kepler,

Yes, R can do this all. But this is is to help you when you get stuck, not
to do all the work for you... You are asking basic stuff, so any
introduction book on R should contain sufficient information to get you
going. So please do read on of those first.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 19 nov. 2018 om 11:39 schreef Rui Fernandes <rui.kepler at gmail.com>:

> Good morning
>
> My compliments to all.
>
> Since I'm a newbie on R, I was wondering if you could help me to achieve a
> small project that I think it's possible with this project (I cant seem to
> find a similar tool)
>
> I have a data file with about 2000 value lines, organized like this:
>
> x;y;z;j;
> ...
>
> I want to find diferent correlations (linear regression with
> Levenberg?Marquardt or least squares) between the x values and a y or z
> pair. For instance, between x and y.
>
> So, what I'm trying to do is:
>
> 1) Load the file (is there a limit on the load size? If yes, can I load it
> in sequence by parts?)
> 2) Define 100 sets of 20 values each (also sequence, from x1 to xn: first
> from x1 to x20, next from x21 to x41, etc.) or process one set at the time
> in case of file limits in 1)
> 3) Define a fitting function
> 4) Use the same function model to find the best fit for each set
> 5) Save in a file, the coefficients of those fits.
>
> Can this be done accurately with R?
>
> It would save me a lot of programming. The files will soon have about 1
> million lines, which is a lot to process.
>
> I would apreciate very much if someone could help me.
>
> Kind regards
>
> Kepler
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From S@Elli@on @ending from LGCGroup@com  Mon Nov 19 12:46:00 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Mon, 19 Nov 2018 11:46:00 +0000
Subject: [R] Request for aid in first R script
In-Reply-To: <CAJuCY5zpH-82ROmJY1X7+AqtSmXNGFR46oSqa6-Oo0Zc6jGdGQ@mail.gmail.com>
References: <CAFXK4YfT-1C3Xm8y128Nvm-iek8RPScot3v2mPL6v-CkG0k2qg@mail.gmail.com>
 <CAJuCY5zpH-82ROmJY1X7+AqtSmXNGFR46oSqa6-Oo0Zc6jGdGQ@mail.gmail.com>
Message-ID: <8b66e06e42b64e448543feaa5d627982@GBDCVPEXC04.corp.lgc-group.com>

Pointers inline below:

> > Since I'm a newbie on R, I was wondering if you could help me to achieve a
> > small project that I think it's possible with this project (I cant seem to
> > find a similar tool)
> >
> > I have a data file with about 2000 value lines, organized like this:
> >
> > x;y;z;j;
> > ...
> >
> > I want to find diferent correlations (linear regression with
> > Levenberg?Marquardt or least squares) between the x values and a y or z
> > pair. For instance, between x and y.
> >
> > So, what I'm trying to do is:
> >
> > 1) Load the file (is there a limit on the load size? If yes, can I load it
> > in sequence by parts?)
See ?read.table and note that you can define a separator. Using read.table() with sep=";" should work
Load limits are memory size; I have read 800,000 lines on a 4Gb system

> > 2) Define 100 sets of 20 values each (also sequence, from x1 to xn: first
> > from x1 to x20, next from x21 to x41, etc.) or process one set at the time
> > in case of file limits in 1)
You can say something like
mydata[i:(i+20), ]
to get row-wise slices of your data, but an R user would perhaps consider setting up an ancillary variable using
mydata$chunks <- gl(100,20)
and use a variant of aggregate() or ddply to apply a function to each subset

> > 3) Define a fitting function
er... anything you can write, either as an expression or a function.

> > 4) Use the same function model to find the best fit for each set
Look at, for example, lm for linear models (including polynomials), nls or nlm for non-linear models, and a decent book on R for a much, much, much wider range, including splines, generalised additive models, generalised linear models, mixed effects models (linear and otherwise) ...

> > 5) Save in a file, the coefficients of those fits.
Something like sapply or ddply should be able to give you a table of coefficients, especially if you write a wrapper function like
mywrap <- function(x) coef( nls(y~fitfun)) 
to return a vector of coefficients from a chunk x

> > Can this be done accurately with R?
Yes; R has well-characterised numerically stable core functions, which is more than can be said for most spreadsheets.

> > It would save me a lot of programming. 
You'll still have to do that, but doing it in R will be a lot faster than C

> > The files will soon have about 1
> > million lines, which is a lot to process.
If you can?t load it all at once, you can use read.table with start and end rows.
or you can puch the whole lot to a database and use any of R's database packages to read from that; Rmysql and the like.



*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From rhelp @ending from krueger-f@mily@de  Mon Nov 19 15:41:59 2018
From: rhelp @ending from krueger-f@mily@de (Knut Krueger)
Date: Mon, 19 Nov 2018 15:41:59 +0100
Subject: [R] unique() duplicate() not what i am looking for
Message-ID: <5e592250-b19c-5610-1ea7-cb981182aabd@krueger-family.de>

It should be simple but i do not find the right keywords:


Dup =  c(1,2,3,4,1,2,3,5)

I need 4,5 as result

unique(Dup) gives me [1] 4 1 2 3 5

duplicated(Dup) gives me
[1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE

I need
[1] TRUE TRUE TRUE FALSE  TRUE  TRUE  TRUE FALSE


Kind regards Knut


From petr@pik@l @ending from prechez@@cz  Mon Nov 19 15:50:05 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Mon, 19 Nov 2018 14:50:05 +0000
Subject: [R] unique() duplicate() not what i am looking for
In-Reply-To: <5e592250-b19c-5610-1ea7-cb981182aabd@krueger-family.de>
References: <5e592250-b19c-5610-1ea7-cb981182aabd@krueger-family.de>
Message-ID: <ac6e5e3b098847168099e4c6dd5823b7@SRVEXCHCM1302.precheza.cz>

Hi

Dup %in% Dup[duplicated(Dup)]

Dup[!(Dup %in% Dup[duplicated(Dup)])]

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Knut Krueger
> Sent: Monday, November 19, 2018 3:42 PM
> To: r-help at r-project.org >> r-help mailing list <r-help at r-project.org>
> Subject: [R] unique() duplicate() not what i am looking for
>
> It should be simple but i do not find the right keywords:
>
>
> Dup =  c(1,2,3,4,1,2,3,5)
>
> I need 4,5 as result
>
> unique(Dup) gives me [1] 4 1 2 3 5
>
> duplicated(Dup) gives me
> [1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE
>
> I need
> [1] TRUE TRUE TRUE FALSE  TRUE  TRUE  TRUE FALSE
>
>
> Kind regards Knut
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From petr@pik@l @ending from prechez@@cz  Mon Nov 19 15:53:12 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Mon, 19 Nov 2018 14:53:12 +0000
Subject: [R] unique() duplicate() not what i am looking for
In-Reply-To: <5e592250-b19c-5610-1ea7-cb981182aabd@krueger-family.de>
References: <5e592250-b19c-5610-1ea7-cb981182aabd@krueger-family.de>
Message-ID: <554d388ccd394e6fb23cf8132cf8a9bc@SRVEXCHCM1302.precheza.cz>

Hi

and maybe sloightly less complicated

setdiff(Dup,Dup[duplicated(Dup)])

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Knut Krueger
> Sent: Monday, November 19, 2018 3:42 PM
> To: r-help at r-project.org >> r-help mailing list <r-help at r-project.org>
> Subject: [R] unique() duplicate() not what i am looking for
>
> It should be simple but i do not find the right keywords:
>
>
> Dup =  c(1,2,3,4,1,2,3,5)
>
> I need 4,5 as result
>
> unique(Dup) gives me [1] 4 1 2 3 5
>
> duplicated(Dup) gives me
> [1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE
>
> I need
> [1] TRUE TRUE TRUE FALSE  TRUE  TRUE  TRUE FALSE
>
>
> Kind regards Knut
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From ruipb@rr@d@@ @ending from @@po@pt  Mon Nov 19 16:00:53 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Mon, 19 Nov 2018 15:00:53 +0000
Subject: [R] unique() duplicate() not what i am looking for
In-Reply-To: <5e592250-b19c-5610-1ea7-cb981182aabd@krueger-family.de>
References: <5e592250-b19c-5610-1ea7-cb981182aabd@krueger-family.de>
Message-ID: <d4b45f2d-c838-a185-396f-19508fa2eb1f@sapo.pt>

Hello,

Try

i <- !(duplicated(Dup) | duplicated(Dup, fromLast = TRUE))
Dup[i]


or in one line, I post it like this to make it more clear.

Hope this helps,

Rui Barradas

?s 14:41 de 19/11/2018, Knut Krueger escreveu:
> It should be simple but i do not find the right keywords:
> 
> 
> Dup =? c(1,2,3,4,1,2,3,5)
> 
> I need 4,5 as result
> 
> unique(Dup) gives me [1] 4 1 2 3 5
> 
> duplicated(Dup) gives me
> [1] FALSE FALSE FALSE FALSE? TRUE? TRUE? TRUE FALSE
> 
> I need
> [1] TRUE TRUE TRUE FALSE? TRUE? TRUE? TRUE FALSE
> 
> 
> Kind regards Knut
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox @ending from mcm@@ter@c@  Mon Nov 19 17:51:38 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Mon, 19 Nov 2018 16:51:38 +0000
Subject: [R] unique() duplicate() not what i am looking for
In-Reply-To: <27531_1542645666_wAJGY3Ud003860_5e592250-b19c-5610-1ea7-cb981182aabd@krueger-family.de>
References: <27531_1542645666_wAJGY3Ud003860_5e592250-b19c-5610-1ea7-cb981182aabd@krueger-family.de>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83694F6AA@FHSDB2D11-2.csu.mcmaster.ca>

Dear Knut,

Here's one way:

> as.vector((table(Dup) > 1)[Dup])
[1]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE

Someone will probably think of something cleverer.

I hope this helps,
 John

--------------------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Knut
> Krueger
> Sent: Monday, November 19, 2018 9:42 AM
> To: r-help at r-project.org >> r-help mailing list <r-help at r-project.org>
> Subject: [R] unique() duplicate() not what i am looking for
> 
> It should be simple but i do not find the right keywords:
> 
> 
> Dup =  c(1,2,3,4,1,2,3,5)
> 
> I need 4,5 as result
> 
> unique(Dup) gives me [1] 4 1 2 3 5
> 
> duplicated(Dup) gives me
> [1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE
> 
> I need
> [1] TRUE TRUE TRUE FALSE  TRUE  TRUE  TRUE FALSE
> 
> 
> Kind regards Knut
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Scott@W@ichler @ending from pnnl@gov  Mon Nov 19 22:13:39 2018
From: Scott@W@ichler @ending from pnnl@gov (Waichler, Scott R)
Date: Mon, 19 Nov 2018 21:13:39 +0000
Subject: [R] plot one levelplot over another
Message-ID: <074C83DAD4825242A20B2D83FDBCB8881BB8AB5B@EX10MBOX03.pnnl.gov>

Hi, I am using levelplot() to plot a primary response surface, z1.  I wish to write a custom panel function that will let me plot another surface z2 = f(x,y) over z1.  The second surface z2 is either NA or 1, and at locations where z2 = 1, I will use a color with low alpha to let the the z1 surface show through.  How can I do this?

Regards,
Scott Waichler
Pacific Northwest National Laboratory
Richland, WA USA


From klebyn @ending from y@hoo@com@br  Mon Nov 19 21:57:09 2018
From: klebyn @ending from y@hoo@com@br (Cleber N.Borges)
Date: Mon, 19 Nov 2018 18:57:09 -0200
Subject: [R] Use of C functions inside the DLL object
Message-ID: <65df203a-faa2-e1bd-8c43-4110cf857636@yahoo.com.br>

hello everybody and good night ...
I'm trying to learn how to use a DLL, via "dyn.load" and ".C" inside the R.
I did some testing (below is a part of what I tried) and I could not 
figure out how to do this.
If anyone can give a hint on how to do this manipulation, it would be a 
lot of help!
And thanks in advance for any tip.
Thank you!
Cleber

###

In the pdf explaining the SDK, it has function detail:

FDwfGetVersion(char szVersion[32])
Description: Retrieves the version string. The version string is 
composed of major, minor, and build numbers (i.e.,
?2.0.19?).


##############################################################

### In R, I tried:

 > dwf <- dyn.load("C:\\Windows\\System32\\dwf")
 > is.loaded("FDwfGetVersion")
[1] TRUE
 > result <- .C("FDwfGetVersion", version=as.character() )
 > result
$`version`
character(0)

 > str(result)
List of 1
 ?$ version: chr(0)

#################################

But in Python, I saw that the result is as follows (examples in Python 
are made available by the manufacturer)

#################################

 >>> from ctypes import *
 >>> dwf = cdll.dwf
 >>> version = create_string_buffer(16)
 >>> dwf.FDwfGetVersion(version)
1
 >>> print("DWF Version: "+str(version.value))
DWF Version: 3.8.22
 >>>








---
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus

From i@p@nyolcom @ending from gm@il@com  Tue Nov 20 09:42:46 2018
From: i@p@nyolcom @ending from gm@il@com (=?UTF-8?Q?Engin_Y=C4=B1lmaz?=)
Date: Tue, 20 Nov 2018 11:42:46 +0300
Subject: [R] system solver in R
Message-ID: <CAMUSX8rwvVkitcFe6MmRpE+bJVTaoVHL4Ank+Jd52oyaRqP=Xg@mail.gmail.com>

Dea(R)

Do you know any system solver in R ?

For example, in matlab, is very easy

syms a b c x eqn = a*x^2 + b*x + c == 0; sol = solve(eqn)

How can I  find this type code in R (or directly solver)?

*Since(R)ely*
Engin YILMAZ

	[[alternative HTML version deleted]]


From bhh @ending from x@4@ll@nl  Tue Nov 20 10:02:44 2018
From: bhh @ending from x@4@ll@nl (Berend Hasselman)
Date: Tue, 20 Nov 2018 10:02:44 +0100
Subject: [R] system solver in R
In-Reply-To: <CAMUSX8rwvVkitcFe6MmRpE+bJVTaoVHL4Ank+Jd52oyaRqP=Xg@mail.gmail.com>
References: <CAMUSX8rwvVkitcFe6MmRpE+bJVTaoVHL4Ank+Jd52oyaRqP=Xg@mail.gmail.com>
Message-ID: <3577E651-4A38-4F2C-835A-BA9B9177905B@xs4all.nl>



R package Ryacas may be what you want.

Berend


> On 20 Nov 2018, at 09:42, Engin Y?lmaz <ispanyolcom at gmail.com> wrote:
> 
> Dea(R)
> 
> Do you know any system solver in R ?
> 
> For example, in matlab, is very easy
> 
> syms a b c x eqn = a*x^2 + b*x + c == 0; sol = solve(eqn)
> 
> How can I  find this type code in R (or directly solver)?
> 
> *Since(R)ely*
> Engin YILMAZ
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From me @ending from ren@@@co  Mon Nov 19 23:14:49 2018
From: me @ending from ren@@@co (James Goldie)
Date: Tue, 20 Nov 2018 09:14:49 +1100
Subject: [R] [R-pkgs] New package: collateral 0.4.2 on CRAN
Message-ID: <CADg8+HhdD-zoATLCouqW9BFfE2nSrJutTZgBW3bUGHKSRR=c9g@mail.gmail.com>

Hi everyone,

Collateral is now available on CRAN. If you've used purrr's side effect
capturing functions before, you'll love collateral: it provides you with
map variants that automatically wrap your mapped function in safely() or
quietly() and provide nicely printed output, allowing you to quickly see
which elements of a list returned results, and which returned errors,
warnings or messages. The package also provides helpers to let you
summarise your results and filter or aggregate the captured side effects.

If you haven't used a list-column workflow before, I've included a vignette
with collateral to get you started:
https://rensa.co/collateral/articles/collateral.html

If you'd like to contribute to collateral, you can find it on GitHub:
https://github.com/rensa/collateral

Thanks very much!

<https://rensa.co/collateral/articles/collateral.html>
-- 
=================================================
James Goldie: PhD Student, Climate Change Research Centre
Email: j.goldie at unsw.edu.au, me at rensa.co
Tel: +61 421 747 208
Skype: james-goldie
Web: https://rensa.co

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From rhelp @ending from krueger-f@mily@de  Tue Nov 20 10:16:48 2018
From: rhelp @ending from krueger-f@mily@de (Knut Krueger)
Date: Tue, 20 Nov 2018 10:16:48 +0100
Subject: [R] time mathematics
Message-ID: <66fc5077-3011-732e-2d51-5f58628be5a0@krueger-family.de>


I have an dataframe from with a given time format:

"23:01:19"

to change some given data:

x=data.frame 
("Y"=c(1:5),"TIME"=c("23:01:18","23:01:18","23:01:18","23:01:18","23:01:18"))

I need to change  the time increasing in seconds

x=data.frame 
("Y"=c(1:5),"TIME"=c("23:01:18","23:01:19","23:01:20","23:01:21","23:01:22"))


Is it possible without any additional package ?


Kind Regards Knut


From i@p@nyolcom @ending from gm@il@com  Tue Nov 20 10:53:05 2018
From: i@p@nyolcom @ending from gm@il@com (=?UTF-8?Q?Engin_Y=C4=B1lmaz?=)
Date: Tue, 20 Nov 2018 12:53:05 +0300
Subject: [R] system solver in R
In-Reply-To: <3577E651-4A38-4F2C-835A-BA9B9177905B@xs4all.nl>
References: <CAMUSX8rwvVkitcFe6MmRpE+bJVTaoVHL4Ank+Jd52oyaRqP=Xg@mail.gmail.com>
 <3577E651-4A38-4F2C-835A-BA9B9177905B@xs4all.nl>
Message-ID: <CAMUSX8r5c=PemFaD1Ew5Q-2czvbPgk7kEj7vocqZV76POFvksQ@mail.gmail.com>

Thanks a lot!

Berend Hasselman <bhh at xs4all.nl>, 20 Kas 2018 Sal, 12:02 tarihinde ?unu
yazd?:

>
>
> R package Ryacas may be what you want.
>
> Berend
>
>
> > On 20 Nov 2018, at 09:42, Engin Y?lmaz <ispanyolcom at gmail.com> wrote:
> >
> > Dea(R)
> >
> > Do you know any system solver in R ?
> >
> > For example, in matlab, is very easy
> >
> > syms a b c x eqn = a*x^2 + b*x + c == 0; sol = solve(eqn)
> >
> > How can I  find this type code in R (or directly solver)?
> >
> > *Since(R)ely*
> > Engin YILMAZ
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
*Sayg?lar?mla*
Engin YILMAZ

	[[alternative HTML version deleted]]


From e@ @ending from enrico@chum@nn@net  Tue Nov 20 11:23:28 2018
From: e@ @ending from enrico@chum@nn@net (Enrico Schumann)
Date: Tue, 20 Nov 2018 11:23:28 +0100
Subject: [R] time mathematics
In-Reply-To: <66fc5077-3011-732e-2d51-5f58628be5a0@krueger-family.de> (Knut
 Krueger's message of "Tue, 20 Nov 2018 10:16:48 +0100")
References: <66fc5077-3011-732e-2d51-5f58628be5a0@krueger-family.de>
Message-ID: <878t1o82u7.fsf@enricoschumann.net>

On Tue, 20 Nov 2018, Knut Krueger writes:

> I have an dataframe from with a given time format:
>
> "23:01:19"
>
> to change some given data:
>
> x=data.frame
> ("Y"=c(1:5),"TIME"=c("23:01:18","23:01:18","23:01:18","23:01:18","23:01:18"))
>
> I need to change  the time increasing in seconds
>
> x=data.frame
> ("Y"=c(1:5),"TIME"=c("23:01:18","23:01:19","23:01:20","23:01:21","23:01:22"))
>
>
> Is it possible without any additional package ?
>
>
> Kind Regards Knut
>

Like so?

    start <- "23:01:18"
    Y <- 1:5
    tmp <- as.POSIXct(paste(Sys.Date(), start))
    tmp <- tmp + seq(from = 0, length.out = length(Y))
    format(tmp, "%H:%M:%S")
    ## [1] "23:01:18" "23:01:19" "23:01:20" "23:01:21" "23:01:22"

    data.frame(Y, TIME = format(tmp, "%H:%M:%S"))



-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From b@h@mevik @ending from u@it@uio@no  Tue Nov 20 11:25:39 2018
From: b@h@mevik @ending from u@it@uio@no (=?utf-8?Q?Bj=C3=B8rn-Helge_Mevik?=)
Date: Tue, 20 Nov 2018 11:25:39 +0100
Subject: [R] time mathematics
In-Reply-To: <66fc5077-3011-732e-2d51-5f58628be5a0@krueger-family.de> (Knut
 Krueger's message of "Tue, 20 Nov 2018 10:16:48 +0100")
References: <66fc5077-3011-732e-2d51-5f58628be5a0@krueger-family.de>
Message-ID: <s3s5zwsyrj0.fsf@varelg.uio.no>

Well, this is not an elegant (or robust) solution, but this would work
for the example you give, at least:

starttime <- as.POSIXct("2018-11-20 23:01:18") # Just pick a random date
format(starttime + c(0:4), format = "%T")

There are probably better ways. :)

-- 
Regards,
Bj?rn-Helge Mevik

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 832 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20181120/197b5959/attachment-0001.sig>

From i@p@nyolcom @ending from gm@il@com  Tue Nov 20 13:09:47 2018
From: i@p@nyolcom @ending from gm@il@com (=?UTF-8?Q?Engin_Y=C4=B1lmaz?=)
Date: Tue, 20 Nov 2018 15:09:47 +0300
Subject: [R] system solver in R
In-Reply-To: <CAMUSX8r5c=PemFaD1Ew5Q-2czvbPgk7kEj7vocqZV76POFvksQ@mail.gmail.com>
References: <CAMUSX8rwvVkitcFe6MmRpE+bJVTaoVHL4Ank+Jd52oyaRqP=Xg@mail.gmail.com>
 <3577E651-4A38-4F2C-835A-BA9B9177905B@xs4all.nl>
 <CAMUSX8r5c=PemFaD1Ew5Q-2czvbPgk7kEj7vocqZV76POFvksQ@mail.gmail.com>
Message-ID: <CAMUSX8ptu+b=SFZAA+FQw4aPfu5eqzgWTVHkCuRm92Xj9srqcA@mail.gmail.com>

Dea(R)
I try to solve one equation but this program did not give me real roots
for example
yacas("Solve( 5/((1+x)^1) + 5/((1+x)^2) + 5/((1+x)^3) + 105/((1+x)^4) -105
==0, x)")
gave me following results
How can I find real roots?

expression(list(x == complex_cartesian((1/42 - ((1/63 -
((root(7339451281/3087580356,
    2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
    2))^(1/3)))/21 - -2/21)/(4 * root(((root(7339451281/3087580356,
    2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
    2))^(1/3) - 1/63)^2/4 + 1, 2)))/2 - 1, root(4 *
(((root(7339451281/3087580356,
    2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
    2))^(1/3) - 1/63)/2 + root(((root(7339451281/3087580356,
    2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
    2))^(1/3) - 1/63)^2/4 + 1, 2)) - (((1/63 -
((root(7339451281/3087580356,
    2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
    2))^(1/3)))/21 - -2/21)/(4 * root(((root(7339451281/3087580356,
    2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
    2))^(1/3) - 1/63)^2/4 + 1, 2)) - 1/42)^2, 2)/2),...more




Engin Y?lmaz <ispanyolcom at gmail.com>, 20 Kas 2018 Sal, 12:53 tarihinde ?unu
yazd?:

> Thanks a lot!
>
> Berend Hasselman <bhh at xs4all.nl>, 20 Kas 2018 Sal, 12:02 tarihinde ?unu
> yazd?:
>
>>
>>
>> R package Ryacas may be what you want.
>>
>> Berend
>>
>>
>> > On 20 Nov 2018, at 09:42, Engin Y?lmaz <ispanyolcom at gmail.com> wrote:
>> >
>> > Dea(R)
>> >
>> > Do you know any system solver in R ?
>> >
>> > For example, in matlab, is very easy
>> >
>> > syms a b c x eqn = a*x^2 + b*x + c == 0; sol = solve(eqn)
>> >
>> > How can I  find this type code in R (or directly solver)?
>> >
>> > *Since(R)ely*
>> > Engin YILMAZ
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> --
> *Sayg?lar?mla*
> Engin YILMAZ
>


-- 
*Sayg?lar?mla*
Engin YILMAZ

	[[alternative HTML version deleted]]


From profjcn@@h @ending from gm@il@com  Tue Nov 20 15:21:34 2018
From: profjcn@@h @ending from gm@il@com (J C Nash)
Date: Tue, 20 Nov 2018 09:21:34 -0500
Subject: [R] system solver in R
In-Reply-To: <CAMUSX8ptu+b=SFZAA+FQw4aPfu5eqzgWTVHkCuRm92Xj9srqcA@mail.gmail.com>
References: <CAMUSX8rwvVkitcFe6MmRpE+bJVTaoVHL4Ank+Jd52oyaRqP=Xg@mail.gmail.com>
 <3577E651-4A38-4F2C-835A-BA9B9177905B@xs4all.nl>
 <CAMUSX8r5c=PemFaD1Ew5Q-2czvbPgk7kEj7vocqZV76POFvksQ@mail.gmail.com>
 <CAMUSX8ptu+b=SFZAA+FQw4aPfu5eqzgWTVHkCuRm92Xj9srqcA@mail.gmail.com>
Message-ID: <b3cfafba-467e-4dba-692a-0fa8858f4670@gmail.com>

A bit pedestrian, but you might try

pf <- function(x){5/((1+x)^1) + 5/((1+x)^2) + 5/((1+x)^3) + 105/((1+x)^4) -105}
uniroot(pf,c(-10,10))
curve(pf, c(-10,10))
require(pracma)
tryn <- newton(pf, 0)
tryn
pf(0)
pf(0.03634399)
yc <- c(-105, 5,5,5,105)
rooty <- polyroot(yc)
rooty
rootx <- 1/rooty - 1
rootx

There are lots of rootfinders, and the histoRicalg project (https://gitlab.com/nashjc/histoRicalg)
that is supported by the R Consortium to look into older codes has quite a bit on rootfinders.

JN

On 2018-11-20 7:09 a.m., Engin Y?lmaz wrote:
> 
> 
> Dea(R)
> I try to solve one equation but this program did not give me real roots
> for example
> yacas("Solve( 5/((1+x)^1) + 5/((1+x)^2) + 5/((1+x)^3) + 105/((1+x)^4) -105
> ==0, x)")
> gave me following results
> How can I find real roots?
> 
> expression(list(x == complex_cartesian((1/42 - ((1/63 -
> ((root(7339451281/3087580356,
>     2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>     2))^(1/3)))/21 - -2/21)/(4 * root(((root(7339451281/3087580356,
>     2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>     2))^(1/3) - 1/63)^2/4 + 1, 2)))/2 - 1, root(4 *
> (((root(7339451281/3087580356,
>     2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>     2))^(1/3) - 1/63)/2 + root(((root(7339451281/3087580356,
>     2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>     2))^(1/3) - 1/63)^2/4 + 1, 2)) - (((1/63 -
> ((root(7339451281/3087580356,
>     2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>     2))^(1/3)))/21 - -2/21)/(4 * root(((root(7339451281/3087580356,
>     2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>     2))^(1/3) - 1/63)^2/4 + 1, 2)) - 1/42)^2, 2)/2),...more
> 
> 
> 
> 
> Engin Y?lmaz <ispanyolcom at gmail.com>, 20 Kas 2018 Sal, 12:53 tarihinde ?unu
> yazd?:
> 
>> Thanks a lot!
>>
>> Berend Hasselman <bhh at xs4all.nl>, 20 Kas 2018 Sal, 12:02 tarihinde ?unu
>> yazd?:
>>
>>>
>>>
>>> R package Ryacas may be what you want.
>>>
>>> Berend
>>>
>>>
>>>> On 20 Nov 2018, at 09:42, Engin Y?lmaz <ispanyolcom at gmail.com> wrote:
>>>>
>>>> Dea(R)
>>>>
>>>> Do you know any system solver in R ?
>>>>
>>>> For example, in matlab, is very easy
>>>>
>>>> syms a b c x eqn = a*x^2 + b*x + c == 0; sol = solve(eqn)
>>>>
>>>> How can I  find this type code in R (or directly solver)?
>>>>
>>>> *Since(R)ely*
>>>> Engin YILMAZ
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>> --
>> *Sayg?lar?mla*
>> Engin YILMAZ
>>
> 
> 
> -- 
> *Sayg?lar?mla*
> Engin YILMAZ
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @ubh@mitr@@p@tr@ @ending from gm@il@com  Tue Nov 20 19:20:05 2018
From: @ubh@mitr@@p@tr@ @ending from gm@il@com (Subhamitra Patra)
Date: Tue, 20 Nov 2018 23:50:05 +0530
Subject: [R] [R studio] Plotting of line chart for each columns at 1 page
Message-ID: <CAOFE=kOWXrnRnUVtL7A0vLKjL03571WQy5W_865hTFeBz28+tA@mail.gmail.com>

Dear R users,

I have one excel file with 5 sheets. The no. of columns vary for each
sheet. The 1st sheet consists of 38 columns. So, I want to plot 38 separate
line charts and arrange them in par(mfrow = c(4, 10)) order. Please suggest
me how to do this. I have tried with the following code by running a loop
inside of a sheet, but it is not working. Further, I want to run loops for
each sheet.

par(mfrow = c(4, 10))
loop.vector <- 1:38
for (i in loop.vector)
x <- JJ[,i]
library(ggplot2)
  library(cowplot)
  plot.mpg <- ggplot(mpg, aes(x,
                              main = paste ("country", i),
                              xlab = "Scores",
                              xlim = c(1,500)
                              y = colnames[i,], colour = factor(cyl))) +
  geom_line(size=2.5)
save_plot("mpg.png", plot.mpg,
          base_aspect_ratio = 1.3)

I want to give my X axis name as scores of (1,500) and Y axis as the
particular column names for all graphs.

Please suggest.

Thanks in advance.

-- 
*Best Regards,*
*Subhamitra Patra*
*Phd. Research Scholar*
*Department of Humanities and Social Sciences*
*Indian Institute of Technology, Kharagpur*
*INDIA*








[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
11/20/18,
11:49:42 PM

	[[alternative HTML version deleted]]


From gkchimz28 @ending from hotm@il@com  Tue Nov 20 17:06:17 2018
From: gkchimz28 @ending from hotm@il@com (gary chimuzinga)
Date: Tue, 20 Nov 2018 16:06:17 +0000
Subject: [R] Partial LookUP
Message-ID: <VI1PR08MB359975EC70C20D39EFB4FEBCBCD90@VI1PR08MB3599.eurprd08.prod.outlook.com>

I am working n R, using R studio,
I have a dataframe with 4 columns. Column A contains passenger iD, B contains passenger name, C contains husband name.
I am attempting to create a new column which look to see if the husband name in column C is listed in any of the records in column B. If so it should then return to me the passenger iD of the husband from column A.
To make things more complicated, as in the first example in some cases, the husband's given in column C might not include the his second name, which would be included in column B.

Reproducible Example
library(stringr)
rm(list=ls())
passengerid <- c(0908,9883,7767,3302)

Name<- c("Backstrom, Mrs. Karl Alfred (Maria Mathilda Gustafsson)",
          "Backstrom, Mr. Karl Alfred John",
          "Cumings, Mrs. John Bradley (Florence Briggs Thayer)",
          "Cumings, Mr. John Bradley")

HusbandName <- c("Backstrom, Mr. Karl Alfred","","Cumings, Mr. John
Bradley","")



df1<- data.frame(cbind(passengerid,Name,HusbandName))
df1$Name <- as.character(df1$Name)
df1$HusbandName <- as.character(df1$HusbandName)

I have tried using Stringr, but facing problems because 1)I need the code to look at only 1 element of the vector HusbandName and search for it in the whole vector Name. 2) I found it difficult to use regular expressions given that the pattern I am looking for is vectorised (as HusbandName)
This is what I have tried so far:

Attempt 1 - only finds exact matches & doesn't return the passengerID & doesn't add column to df
df1$Husbandid < - for (i in 1:NROW(df1$HusbandName)) {
print(HusbandName[i] %in% Name)}


Attempt 2 - finds partial matches, but does not ignore blanks & does not tell me passenger id & doesn't add column to df
df1$Husbandid <- for (i in 1:NROW(df1$HusbandName)) {
print(which(str_detect(df1$Name,df1$HusbandName[i])))}


#Attempt 3 - almost works but - the printed results are different from those added into the dataframe as a new column. how can i correct for this? Ultimately I need the ones in the df to be correct. the error is that those without husbands are showing husbandiD when this should be blank or na. can this be corrected or is there a way to convert the output of the for loop into a vector we can add to the df?
for (i in 1:NROW(df1$HusbandName)) {
     if (df1$HusbandName[i] =="") {
      print("Man") & next()
      }
    FoundHusbandNames<- c(which(str_detect(df1$Name,df1$HusbandName[i])))
    print(df1$passengerid[FoundHusbandNames]) -> df1$Husbandid[i] }


	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Tue Nov 20 20:13:17 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 20 Nov 2018 11:13:17 -0800
Subject: [R] 
 [R studio] Plotting of line chart for each columns at 1 page
In-Reply-To: <CAOFE=kOWXrnRnUVtL7A0vLKjL03571WQy5W_865hTFeBz28+tA@mail.gmail.com>
References: <CAOFE=kOWXrnRnUVtL7A0vLKjL03571WQy5W_865hTFeBz28+tA@mail.gmail.com>
Message-ID: <CAGxFJbQT3EXrsMOFchkfbrk0afactxi6zrwW86WuMPhOva2LyQ@mail.gmail.com>

You need to do some studying! ggplot is built on the grid graphics system,
which is separate from the base graphics system. The par() function is part
of the *base* graphics system and so ignored by ggplot.

Others may offer you solutions using the "faceting" functionality of
ggplot. But you really should reading up on this on your own. There are
many good tutorials on ggplot2 that are available on the web.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Nov 20, 2018 at 10:19 AM Subhamitra Patra <
subhamitra.patra at gmail.com> wrote:

> Dear R users,
>
> I have one excel file with 5 sheets. The no. of columns vary for each
> sheet. The 1st sheet consists of 38 columns. So, I want to plot 38 separate
> line charts and arrange them in par(mfrow = c(4, 10)) order. Please suggest
> me how to do this. I have tried with the following code by running a loop
> inside of a sheet, but it is not working. Further, I want to run loops for
> each sheet.
>
> par(mfrow = c(4, 10))
> loop.vector <- 1:38
> for (i in loop.vector)
> x <- JJ[,i]
> library(ggplot2)
>   library(cowplot)
>   plot.mpg <- ggplot(mpg, aes(x,
>                               main = paste ("country", i),
>                               xlab = "Scores",
>                               xlim = c(1,500)
>                               y = colnames[i,], colour = factor(cyl))) +
>   geom_line(size=2.5)
> save_plot("mpg.png", plot.mpg,
>           base_aspect_ratio = 1.3)
>
> I want to give my X axis name as scores of (1,500) and Y axis as the
> particular column names for all graphs.
>
> Please suggest.
>
> Thanks in advance.
>
> --
> *Best Regards,*
> *Subhamitra Patra*
> *Phd. Research Scholar*
> *Department of Humanities and Social Sciences*
> *Indian Institute of Technology, Kharagpur*
> *INDIA*
>
>
>
>
>
>
>
>
> [image: Mailtrack]
> <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> Sender
> notified by
> Mailtrack
> <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> 11/20/18,
> 11:49:42 PM
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From E@Vettor@zzi @ending from uke@de  Tue Nov 20 22:19:11 2018
From: E@Vettor@zzi @ending from uke@de (Eik Vettorazzi)
Date: Tue, 20 Nov 2018 22:19:11 +0100
Subject: [R] system solver in R
In-Reply-To: <CAMUSX8ptu+b=SFZAA+FQw4aPfu5eqzgWTVHkCuRm92Xj9srqcA@mail.gmail.com>
References: <CAMUSX8rwvVkitcFe6MmRpE+bJVTaoVHL4Ank+Jd52oyaRqP=Xg@mail.gmail.com>
 <3577E651-4A38-4F2C-835A-BA9B9177905B@xs4all.nl>
 <CAMUSX8r5c=PemFaD1Ew5Q-2czvbPgk7kEj7vocqZV76POFvksQ@mail.gmail.com>
 <CAMUSX8ptu+b=SFZAA+FQw4aPfu5eqzgWTVHkCuRm92Xj9srqcA@mail.gmail.com>
Message-ID: <6ee32441-7839-120f-feab-7c2af7d7f18a@uke.de>

How about this:

library(rootSolve)
f1<-function(x)5/((1+x)^1) + 5/((1+x)^2) + 5/((1+x)^3) + 105/((1+x)^4) -105
uniroot.all( f1,c(-1e6,1e6))

[1] -1.9881665  0.0363435

Cheers


Am 20.11.2018 um 13:09 schrieb Engin Y?lmaz:
> Dea(R)
> I try to solve one equation but this program did not give me real roots
> for example
> yacas("Solve( 5/((1+x)^1) + 5/((1+x)^2) + 5/((1+x)^3) + 105/((1+x)^4) -105
> ==0, x)")
> gave me following results
> How can I find real roots?
> 
> expression(list(x == complex_cartesian((1/42 - ((1/63 -
> ((root(7339451281/3087580356,
>      2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>      2))^(1/3)))/21 - -2/21)/(4 * root(((root(7339451281/3087580356,
>      2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>      2))^(1/3) - 1/63)^2/4 + 1, 2)))/2 - 1, root(4 *
> (((root(7339451281/3087580356,
>      2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>      2))^(1/3) - 1/63)/2 + root(((root(7339451281/3087580356,
>      2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>      2))^(1/3) - 1/63)^2/4 + 1, 2)) - (((1/63 -
> ((root(7339451281/3087580356,
>      2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>      2))^(1/3)))/21 - -2/21)/(4 * root(((root(7339451281/3087580356,
>      2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>      2))^(1/3) - 1/63)^2/4 + 1, 2)) - 1/42)^2, 2)/2),...more
> 
> 
> 
> 
> Engin Y?lmaz <ispanyolcom at gmail.com>, 20 Kas 2018 Sal, 12:53 tarihinde ?unu
> yazd?:
> 
>> Thanks a lot!
>>
>> Berend Hasselman <bhh at xs4all.nl>, 20 Kas 2018 Sal, 12:02 tarihinde ?unu
>> yazd?:
>>
>>>
>>>
>>> R package Ryacas may be what you want.
>>>
>>> Berend
>>>
>>>
>>>> On 20 Nov 2018, at 09:42, Engin Y?lmaz <ispanyolcom at gmail.com> wrote:
>>>>
>>>> Dea(R)
>>>>
>>>> Do you know any system solver in R ?
>>>>
>>>> For example, in matlab, is very easy
>>>>
>>>> syms a b c x eqn = a*x^2 + b*x + c == 0; sol = solve(eqn)
>>>>
>>>> How can I  find this type code in R (or directly solver)?
>>>>
>>>> *Since(R)ely*
>>>> Engin YILMAZ
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>> --
>> *Sayg?lar?mla*
>> Engin YILMAZ
>>
> 
> 

-- 
Eik Vettorazzi

Universit?tsklinikum Hamburg-Eppendorf
Institut f?r Medizinische Biometrie und Epidemiologie

Martinistra?e 52
Geb?ude W 34
20246 Hamburg

Telefon: +49 (0) 40 7410 - 58243
Fax:     +49 (0) 40 7410 - 57790

Web: www.uke.de/imbe


--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From drjimlemon @ending from gm@il@com  Wed Nov 21 00:08:02 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Wed, 21 Nov 2018 10:08:02 +1100
Subject: [R] 
 [R studio] Plotting of line chart for each columns at 1 page
In-Reply-To: <CAOFE=kOWXrnRnUVtL7A0vLKjL03571WQy5W_865hTFeBz28+tA@mail.gmail.com>
References: <CAOFE=kOWXrnRnUVtL7A0vLKjL03571WQy5W_865hTFeBz28+tA@mail.gmail.com>
Message-ID: <CA+8X3fW3Op8icpvA68O2sYPpBi=rpO2DWVXwL5UrPOHtDqDzpw@mail.gmail.com>

Hi Subhamitra,
As Bert noted, you are mixing base and grid graphics. Here is a simple
way to get a plot like what you described. It will probably take more
work to find what you actually do want and discover how to get it.

for(i in 1:38) assign(paste0("veh",i),rep(sample(10:35,1),10)+runif(10,-4,4))
mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,
 veh11,veh12,veh13,veh14,veh15,veh16,veh17,veh18,veh19,veh20,
 veh21,veh22,veh23,veh24,veh25,veh26,veh27,veh28,veh29,veh30,
 veh31,veh32,veh33,veh34,veh35,veh36,veh37,veh38)
pdf("mpg.pdf",width=30,height=12)
par(mfrow=c(4,10))
for(i in 1:38)
 plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
  ylab=names(mpg)[i],main="MPG by distance")
dev.off()

Jim

On Wed, Nov 21, 2018 at 5:19 AM Subhamitra Patra
<subhamitra.patra at gmail.com> wrote:
>
> Dear R users,
>
> I have one excel file with 5 sheets. The no. of columns vary for each
> sheet. The 1st sheet consists of 38 columns. So, I want to plot 38 separate
> line charts and arrange them in par(mfrow = c(4, 10)) order. Please suggest
> me how to do this. I have tried with the following code by running a loop
> inside of a sheet, but it is not working. Further, I want to run loops for
> each sheet.
>
> par(mfrow = c(4, 10))
> loop.vector <- 1:38
> for (i in loop.vector)
> x <- JJ[,i]
> library(ggplot2)
>   library(cowplot)
>   plot.mpg <- ggplot(mpg, aes(x,
>                               main = paste ("country", i),
>                               xlab = "Scores",
>                               xlim = c(1,500)
>                               y = colnames[i,], colour = factor(cyl))) +
>   geom_line(size=2.5)
> save_plot("mpg.png", plot.mpg,
>           base_aspect_ratio = 1.3)
>
> I want to give my X axis name as scores of (1,500) and Y axis as the
> particular column names for all graphs.
>
> Please suggest.
>
> Thanks in advance.
>
> --
> *Best Regards,*
> *Subhamitra Patra*
> *Phd. Research Scholar*
> *Department of Humanities and Social Sciences*
> *Indian Institute of Technology, Kharagpur*
> *INDIA*
>
>
>
>
>
>
>
>
> [image: Mailtrack]
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
> Sender
> notified by
> Mailtrack
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
> 11/20/18,
> 11:49:42 PM
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @ubh@mitr@@p@tr@ @ending from gm@il@com  Wed Nov 21 02:37:49 2018
From: @ubh@mitr@@p@tr@ @ending from gm@il@com (Subhamitra Patra)
Date: Wed, 21 Nov 2018 07:07:49 +0530
Subject: [R] 
 [R studio] Plotting of line chart for each columns at 1 page
In-Reply-To: <CA+8X3fW3Op8icpvA68O2sYPpBi=rpO2DWVXwL5UrPOHtDqDzpw@mail.gmail.com>
References: <CAOFE=kOWXrnRnUVtL7A0vLKjL03571WQy5W_865hTFeBz28+tA@mail.gmail.com>
 <CA+8X3fW3Op8icpvA68O2sYPpBi=rpO2DWVXwL5UrPOHtDqDzpw@mail.gmail.com>
Message-ID: <CAOFE=kNV6P4jRtrYS9K1E76pn+tW_aVpQ4Kq25ZHtQ6v-m=TkQ@mail.gmail.com>

Hello Sir,

Thanks, I'll check them out.

But, I am not understanding 2 points of your suggestion.

1. In the line,* "*for(i in 1:38) assign(paste0("veh",i),rep(sam
ple(10:35,1),10)+runif(10,-4,*4))", *what veh, rep(sample(10:35,1),10)
+runif(10,-4,4)) indicate? Here veh indicates columns right?
*2. In the
line, mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,*
* veh11,veh12,veh13,veh14,**veh15,veh16,veh17,veh18,veh19,**veh20,*
* veh21,veh22,veh23,veh24,**veh25,veh26,veh27,veh28,veh29,**veh30,*
* veh31,veh32,veh33,veh34,**veh35,veh36,veh37,veh38)  ** , *veh[i]
indicates column sequence, right? I need to give column names as the header
of their respective graphs. Please suggest me How to add this?


I am very new to R and therefore asking you these queries which might be
simple for you.

I expect positive help from you.

Thanks for your kind help.
[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
11/21/18,
7:02:18 AM


On Wed, Nov 21, 2018 at 4:38 AM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Subhamitra,
> As Bert noted, you are mixing base and grid graphics. Here is a simple
> way to get a plot like what you described. It will probably take more
> work to find what you actually do want and discover how to get it.
>
> for(i in 1:38)
> assign(paste0("veh",i),rep(sample(10:35,1),10)+runif(10,-4,4))
> mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,
>  veh11,veh12,veh13,veh14,veh15,veh16,veh17,veh18,veh19,veh20,
>  veh21,veh22,veh23,veh24,veh25,veh26,veh27,veh28,veh29,veh30,
>  veh31,veh32,veh33,veh34,veh35,veh36,veh37,veh38)
> pdf("mpg.pdf",width=30,height=12)
> par(mfrow=c(4,10))
> for(i in 1:38)
>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>   ylab=names(mpg)[i],main="MPG by distance")
> dev.off()
>
> Jim
>
> On Wed, Nov 21, 2018 at 5:19 AM Subhamitra Patra
> <subhamitra.patra at gmail.com> wrote:
> >
> > Dear R users,
> >
> > I have one excel file with 5 sheets. The no. of columns vary for each
> > sheet. The 1st sheet consists of 38 columns. So, I want to plot 38
> separate
> > line charts and arrange them in par(mfrow = c(4, 10)) order. Please
> suggest
> > me how to do this. I have tried with the following code by running a loop
> > inside of a sheet, but it is not working. Further, I want to run loops
> for
> > each sheet.
> >
> > par(mfrow = c(4, 10))
> > loop.vector <- 1:38
> > for (i in loop.vector)
> > x <- JJ[,i]
> > library(ggplot2)
> >   library(cowplot)
> >   plot.mpg <- ggplot(mpg, aes(x,
> >                               main = paste ("country", i),
> >                               xlab = "Scores",
> >                               xlim = c(1,500)
> >                               y = colnames[i,], colour = factor(cyl))) +
> >   geom_line(size=2.5)
> > save_plot("mpg.png", plot.mpg,
> >           base_aspect_ratio = 1.3)
> >
> > I want to give my X axis name as scores of (1,500) and Y axis as the
> > particular column names for all graphs.
> >
> > Please suggest.
> >
> > Thanks in advance.
> >
> > --
> > *Best Regards,*
> > *Subhamitra Patra*
> > *Phd. Research Scholar*
> > *Department of Humanities and Social Sciences*
> > *Indian Institute of Technology, Kharagpur*
> > *INDIA*
> >
> >
> >
> >
> >
> >
> >
> >
> > [image: Mailtrack]
> > <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> > Sender
> > notified by
> > Mailtrack
> > <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> > 11/20/18,
> > 11:49:42 PM
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


-- 
*Best Regards,*
*Subhamitra Patra*
*Phd. Research Scholar*
*Department of Humanities and Social Sciences*
*Indian Institute of Technology, Kharagpur*
*INDIA*

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Wed Nov 21 02:47:07 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Wed, 21 Nov 2018 12:47:07 +1100
Subject: [R] 
 [R studio] Plotting of line chart for each columns at 1 page
In-Reply-To: <CAOFE=kNV6P4jRtrYS9K1E76pn+tW_aVpQ4Kq25ZHtQ6v-m=TkQ@mail.gmail.com>
References: <CAOFE=kOWXrnRnUVtL7A0vLKjL03571WQy5W_865hTFeBz28+tA@mail.gmail.com>
 <CA+8X3fW3Op8icpvA68O2sYPpBi=rpO2DWVXwL5UrPOHtDqDzpw@mail.gmail.com>
 <CAOFE=kNV6P4jRtrYS9K1E76pn+tW_aVpQ4Kq25ZHtQ6v-m=TkQ@mail.gmail.com>
Message-ID: <CA+8X3fXM9KEb8=U1y-E_DFy9UuXk7NXDyRo6VppnEEAbAtGDDQ@mail.gmail.com>

Hi Subhamitra,

1. Here I manufacture some data so that the example is "reproducible", that
is anyone can run the code and get the same output that I do. Yes,
veh1...veh38 are the names of the variables.

2. Here I join the 38 variables I created into a data frame, which I think
is the input for your plotting routine. This names of the columns of the
data frame become the names of the variables.

When you say that you want the column names as the "header" (title) of each
plot, I think if you change the plotting loop to this:

pdf("mpg.pdf",width=30,height=12)
par(mfrow=c(4,10))
for(i in 1:38)
 plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
  ylab="MPG",main=names(mpg)[i])
dev.off()

you will get what you requested. Remember that I have done this in base
graphics, not ggplot.

Jim

On Wed, Nov 21, 2018 at 12:37 PM Subhamitra Patra <
subhamitra.patra at gmail.com> wrote:

> Hello Sir,
>
> Thanks, I'll check them out.
>
> But, I am not understanding 2 points of your suggestion.
>
> 1. In the line,* "*for(i in 1:38) assign(paste0("veh",i),rep(sam
> ple(10:35,1),10)+runif(10,-4,*4))", *what veh, rep(sample(10:35,1),10)
> +runif(10,-4,4)) indicate? Here veh indicates columns right?
> *2. In the
> line, mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,*
> * veh11,veh12,veh13,veh14,**veh15,veh16,veh17,veh18,veh19,**veh20,*
> * veh21,veh22,veh23,veh24,**veh25,veh26,veh27,veh28,veh29,**veh30,*
> * veh31,veh32,veh33,veh34,**veh35,veh36,veh37,veh38)  ** , *veh[i]
> indicates column sequence, right? I need to give column names as the header
> of their respective graphs. Please suggest me How to add this?
>
>
> I am very new to R and therefore asking you these queries which might be
> simple for you.
>
> I expect positive help from you.
>
> Thanks for your kind help.
> [image: Mailtrack]
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
> notified by
> Mailtrack
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
> 7:02:18 AM
>
>
> On Wed, Nov 21, 2018 at 4:38 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Subhamitra,
>> As Bert noted, you are mixing base and grid graphics. Here is a simple
>> way to get a plot like what you described. It will probably take more
>> work to find what you actually do want and discover how to get it.
>>
>> for(i in 1:38)
>> assign(paste0("veh",i),rep(sample(10:35,1),10)+runif(10,-4,4))
>> mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,
>>  veh11,veh12,veh13,veh14,veh15,veh16,veh17,veh18,veh19,veh20,
>>  veh21,veh22,veh23,veh24,veh25,veh26,veh27,veh28,veh29,veh30,
>>  veh31,veh32,veh33,veh34,veh35,veh36,veh37,veh38)
>> pdf("mpg.pdf",width=30,height=12)
>> par(mfrow=c(4,10))
>> for(i in 1:38)
>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>   ylab=names(mpg)[i],main="MPG by distance")
>> dev.off()
>>
>> Jim
>>
>> On Wed, Nov 21, 2018 at 5:19 AM Subhamitra Patra
>> <subhamitra.patra at gmail.com> wrote:
>> >
>> > Dear R users,
>> >
>> > I have one excel file with 5 sheets. The no. of columns vary for each
>> > sheet. The 1st sheet consists of 38 columns. So, I want to plot 38
>> separate
>> > line charts and arrange them in par(mfrow = c(4, 10)) order. Please
>> suggest
>> > me how to do this. I have tried with the following code by running a
>> loop
>> > inside of a sheet, but it is not working. Further, I want to run loops
>> for
>> > each sheet.
>> >
>> > par(mfrow = c(4, 10))
>> > loop.vector <- 1:38
>> > for (i in loop.vector)
>> > x <- JJ[,i]
>> > library(ggplot2)
>> >   library(cowplot)
>> >   plot.mpg <- ggplot(mpg, aes(x,
>> >                               main = paste ("country", i),
>> >                               xlab = "Scores",
>> >                               xlim = c(1,500)
>> >                               y = colnames[i,], colour = factor(cyl))) +
>> >   geom_line(size=2.5)
>> > save_plot("mpg.png", plot.mpg,
>> >           base_aspect_ratio = 1.3)
>> >
>> > I want to give my X axis name as scores of (1,500) and Y axis as the
>> > particular column names for all graphs.
>> >
>> > Please suggest.
>> >
>> > Thanks in advance.
>> >
>> > --
>> > *Best Regards,*
>> > *Subhamitra Patra*
>> > *Phd. Research Scholar*
>> > *Department of Humanities and Social Sciences*
>> > *Indian Institute of Technology, Kharagpur*
>> > *INDIA*
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > [image: Mailtrack]
>> > <
>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>> >
>> > Sender
>> > notified by
>> > Mailtrack
>> > <
>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>> >
>> > 11/20/18,
>> > 11:49:42 PM
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> *Best Regards,*
> *Subhamitra Patra*
> *Phd. Research Scholar*
> *Department of Humanities and Social Sciences*
> *Indian Institute of Technology, Kharagpur*
> *INDIA*
>

	[[alternative HTML version deleted]]


From @ubh@mitr@@p@tr@ @ending from gm@il@com  Wed Nov 21 03:21:36 2018
From: @ubh@mitr@@p@tr@ @ending from gm@il@com (Subhamitra Patra)
Date: Wed, 21 Nov 2018 07:51:36 +0530
Subject: [R] 
 [R studio] Plotting of line chart for each columns at 1 page
In-Reply-To: <CA+8X3fXM9KEb8=U1y-E_DFy9UuXk7NXDyRo6VppnEEAbAtGDDQ@mail.gmail.com>
References: <CAOFE=kOWXrnRnUVtL7A0vLKjL03571WQy5W_865hTFeBz28+tA@mail.gmail.com>
 <CA+8X3fW3Op8icpvA68O2sYPpBi=rpO2DWVXwL5UrPOHtDqDzpw@mail.gmail.com>
 <CAOFE=kNV6P4jRtrYS9K1E76pn+tW_aVpQ4Kq25ZHtQ6v-m=TkQ@mail.gmail.com>
 <CA+8X3fXM9KEb8=U1y-E_DFy9UuXk7NXDyRo6VppnEEAbAtGDDQ@mail.gmail.com>
Message-ID: <CAOFE=kO20RsVsvVL2ZXpsH51aw9bzgCc3tDJ7DX8fM-tgkkbdQ@mail.gmail.com>

Hello Sir,

Thanks, now I understood and will check them out.

One more thing I want to ask that I have 1 excel file with multiple (i.e.
12 sheets). Each sheet contains different number of columns, for instance,
1st sheet contains 38 columns, 2nd sheet contains 10 columns, Third 2
columns, 4th 1 column and so on. Actually, due to some missing observations
in these columns, I couldn't add them in 1 sheet.

As you suggested the below code in the last mail,

par(mfrow=c(4,10))
for(i in 1:38)
 plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
  ylab="MPG",main=names(mpg)[i])
dev.off()

Do I need to run the code separately for each sheet?

Actually, in par (mfrow=c(4,10)), the plot for 38 columns will be added,
the space for extra 2 will remain as empty. So, I thought to add plots for
the columns from the next sheet in those emptied space.

Is there any way that I can add plots from the next sheets of the same
excel file in the emptied space? In other words, Is there any way to append
plots from all sheets?

Kindly help a new R learner Sir for which I shall be always grateful to you.

Thank you very much for your kind help.



[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
11/21/18,
7:30:30 AM

On Wed, Nov 21, 2018 at 7:17 AM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Subhamitra,
>
> 1. Here I manufacture some data so that the example is "reproducible",
> that is anyone can run the code and get the same output that I do. Yes,
> veh1...veh38 are the names of the variables.
>
> 2. Here I join the 38 variables I created into a data frame, which I think
> is the input for your plotting routine. This names of the columns of the
> data frame become the names of the variables.
>
> When you say that you want the column names as the "header" (title) of
> each plot, I think if you change the plotting loop to this:
>
> pdf("mpg.pdf",width=30,height=12)
> par(mfrow=c(4,10))
> for(i in 1:38)
>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>   ylab="MPG",main=names(mpg)[i])
> dev.off()
>
> you will get what you requested. Remember that I have done this in base
> graphics, not ggplot.
>
> Jim
>
> On Wed, Nov 21, 2018 at 12:37 PM Subhamitra Patra <
> subhamitra.patra at gmail.com> wrote:
>
>> Hello Sir,
>>
>> Thanks, I'll check them out.
>>
>> But, I am not understanding 2 points of your suggestion.
>>
>> 1. In the line,* "*for(i in 1:38) assign(paste0("veh",i),rep(sam
>> ple(10:35,1),10)+runif(10,-4,*4))", *what veh, rep(sample(10:35,1),10)
>> +runif(10,-4,4)) indicate? Here veh indicates columns right?
>> *2. In the
>> line, mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,*
>> * veh11,veh12,veh13,veh14,**veh15,veh16,veh17,veh18,veh19,**veh20,*
>> * veh21,veh22,veh23,veh24,**veh25,veh26,veh27,veh28,veh29,**veh30,*
>> * veh31,veh32,veh33,veh34,**veh35,veh36,veh37,veh38)  ** , *veh[i]
>> indicates column sequence, right? I need to give column names as the header
>> of their respective graphs. Please suggest me How to add this?
>>
>>
>> I am very new to R and therefore asking you these queries which might be
>> simple for you.
>>
>> I expect positive help from you.
>>
>> Thanks for your kind help.
>> [image: Mailtrack]
>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
>> notified by
>> Mailtrack
>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
>> 7:02:18 AM
>>
>>
>> On Wed, Nov 21, 2018 at 4:38 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>>> Hi Subhamitra,
>>> As Bert noted, you are mixing base and grid graphics. Here is a simple
>>> way to get a plot like what you described. It will probably take more
>>> work to find what you actually do want and discover how to get it.
>>>
>>> for(i in 1:38)
>>> assign(paste0("veh",i),rep(sample(10:35,1),10)+runif(10,-4,4))
>>> mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,
>>>  veh11,veh12,veh13,veh14,veh15,veh16,veh17,veh18,veh19,veh20,
>>>  veh21,veh22,veh23,veh24,veh25,veh26,veh27,veh28,veh29,veh30,
>>>  veh31,veh32,veh33,veh34,veh35,veh36,veh37,veh38)
>>> pdf("mpg.pdf",width=30,height=12)
>>> par(mfrow=c(4,10))
>>> for(i in 1:38)
>>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>>   ylab=names(mpg)[i],main="MPG by distance")
>>> dev.off()
>>>
>>> Jim
>>>
>>> On Wed, Nov 21, 2018 at 5:19 AM Subhamitra Patra
>>> <subhamitra.patra at gmail.com> wrote:
>>> >
>>> > Dear R users,
>>> >
>>> > I have one excel file with 5 sheets. The no. of columns vary for each
>>> > sheet. The 1st sheet consists of 38 columns. So, I want to plot 38
>>> separate
>>> > line charts and arrange them in par(mfrow = c(4, 10)) order. Please
>>> suggest
>>> > me how to do this. I have tried with the following code by running a
>>> loop
>>> > inside of a sheet, but it is not working. Further, I want to run loops
>>> for
>>> > each sheet.
>>> >
>>> > par(mfrow = c(4, 10))
>>> > loop.vector <- 1:38
>>> > for (i in loop.vector)
>>> > x <- JJ[,i]
>>> > library(ggplot2)
>>> >   library(cowplot)
>>> >   plot.mpg <- ggplot(mpg, aes(x,
>>> >                               main = paste ("country", i),
>>> >                               xlab = "Scores",
>>> >                               xlim = c(1,500)
>>> >                               y = colnames[i,], colour = factor(cyl)))
>>> +
>>> >   geom_line(size=2.5)
>>> > save_plot("mpg.png", plot.mpg,
>>> >           base_aspect_ratio = 1.3)
>>> >
>>> > I want to give my X axis name as scores of (1,500) and Y axis as the
>>> > particular column names for all graphs.
>>> >
>>> > Please suggest.
>>> >
>>> > Thanks in advance.
>>> >
>>> > --
>>> > *Best Regards,*
>>> > *Subhamitra Patra*
>>> > *Phd. Research Scholar*
>>> > *Department of Humanities and Social Sciences*
>>> > *Indian Institute of Technology, Kharagpur*
>>> > *INDIA*
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> > [image: Mailtrack]
>>> > <
>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>> >
>>> > Sender
>>> > notified by
>>> > Mailtrack
>>> > <
>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>> >
>>> > 11/20/18,
>>> > 11:49:42 PM
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> *Best Regards,*
>> *Subhamitra Patra*
>> *Phd. Research Scholar*
>> *Department of Humanities and Social Sciences*
>> *Indian Institute of Technology, Kharagpur*
>> *INDIA*
>>
>

-- 
*Best Regards,*
*Subhamitra Patra*
*Phd. Research Scholar*
*Department of Humanities and Social Sciences*
*Indian Institute of Technology, Kharagpur*
*INDIA*

	[[alternative HTML version deleted]]


From i@r@4884 @ending from gm@il@com  Wed Nov 21 03:34:59 2018
From: i@r@4884 @ending from gm@il@com (Israel Ortiz)
Date: Tue, 20 Nov 2018 20:34:59 -0600
Subject: [R] Predict follow up time using parametric model in r
In-Reply-To: <bb6fa2$adn3p3@ironport10.mayo.edu>
References: <mailman.352315.1.1541329201.2929.r-help@r-project.org>
 <bb6fa2$adn3p3@ironport10.mayo.edu>
Message-ID: <CAMESY2hHNw4skjcK4bo8AFxSDOr+0b=qg3R4Z3ABMeu5haVHRg@mail.gmail.com>

You are right. Specifically, I need to predict the mean and median time to
failure from a coxph model and several parametric models using new data.

Thanks.

El lun., 5 nov. 2018 a las 7:11, Therneau, Terry M., Ph.D. (<
therneau at mayo.edu>) escribi?:

> First, type='expected' gives the expected cumulative hazard for each
> subject, given their follow-up time and covariates.  It is not the expected
> follow-up time, the expected time to death, or the probability of death.
> I suspect you are not getting what you think you are.
>
>  A survival model predicts a survival curve for each subject.  For Cox
> models you get the entire curve with the survfit() method, for survreg
> models you get the curve with predict().    To get a better answer about
> how to "predict follow-up time" you will need to be more clear about what
> you actually want, statistically.  Mean time to failure?  Median?  RMST?
> ....
>
> Terry T.
>
>
> On 11/4/18 5:00 AM, r-help-request at r-project.org wrote:
>
> I am trying to predict follow-up time using several survival models, both
> parametric and semi-parametric. I achieve it for semi parametric models
> using predict.coxph function in R from survival package using type =
> "expected" as indicated in help. However, for parametric models, this
> option doesn't exist for the predict.survreg function. Is there any other
> option? Maybe using rms package?
>
>
>
>

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Wed Nov 21 03:48:08 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Wed, 21 Nov 2018 13:48:08 +1100
Subject: [R] 
 [R studio] Plotting of line chart for each columns at 1 page
In-Reply-To: <CAOFE=kO20RsVsvVL2ZXpsH51aw9bzgCc3tDJ7DX8fM-tgkkbdQ@mail.gmail.com>
References: <CAOFE=kOWXrnRnUVtL7A0vLKjL03571WQy5W_865hTFeBz28+tA@mail.gmail.com>
 <CA+8X3fW3Op8icpvA68O2sYPpBi=rpO2DWVXwL5UrPOHtDqDzpw@mail.gmail.com>
 <CAOFE=kNV6P4jRtrYS9K1E76pn+tW_aVpQ4Kq25ZHtQ6v-m=TkQ@mail.gmail.com>
 <CA+8X3fXM9KEb8=U1y-E_DFy9UuXk7NXDyRo6VppnEEAbAtGDDQ@mail.gmail.com>
 <CAOFE=kO20RsVsvVL2ZXpsH51aw9bzgCc3tDJ7DX8fM-tgkkbdQ@mail.gmail.com>
Message-ID: <CA+8X3fUh8bug_m8iGBGcdPdb=PeGXY0xG48NTwBHC2XzXrtyhg@mail.gmail.com>

I assume that you are importing the Excel sheets separately. When you
import a sheet, you can get the number of columns with this:

ncol(<name of data frame>)

Using the data frame "mpg" that I created:

ncolumns<-ncol(mpg)
ncolumns
[1] 38

You can then substitute "ncolumns" each time you import another sheet. How
you want to deal with the varying numbers of columns you will get is
another matter. One way is to work out the total number of plots you want
and put them all onto one PDF page. Say you have 50 plots overall. You
could start a very big PDF page:

pdf("allplots.pdf",width=30,height=15)
par(mfrow=c(5,10))
# import your first sheet here (38 columns)
ncolumns<-ncol(mpg)
for(i in 1:ncolumns)
 plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
  ylab="MPG",main=names(mpg)[i])# import your second sheet here, say 10
columns
# import your second sheet here, (10 columns)
ncolumns<-ncol(mpg1)
for(i in 1:ncolumns)
 plot(seq(1,500,length.out=10),mpg1[,i],type="l",xlab="Distance",
  ylab="MPG",main=names(mpg)[i])# import your third sheet here, say 2
columns
# import your second sheet here, (2 columns)
ncolumns<-ncol(mpg2)
for(i in 1:ncolumns)
 plot(seq(1,500,length.out=10),mpg2[,i],type="l",xlab="Distance",
  ylab="MPG",main=names(mpg)[i])
# finish plotting
dev.off()

You would then have 50 plots on the PDF page. I am assuming that all of
your sheets have the same number of rows and a few other things. This seems
like a lot of plots, and I suspect that you could work out a better way to
display all this information.

Jim


On Wed, Nov 21, 2018 at 1:20 PM Subhamitra Patra <subhamitra.patra at gmail.com>
wrote:

> Hello Sir,
>
> Thanks, now I understood and will check them out.
>
> One more thing I want to ask that I have 1 excel file with multiple (i.e.
> 12 sheets). Each sheet contains different number of columns, for instance,
> 1st sheet contains 38 columns, 2nd sheet contains 10 columns, Third 2
> columns, 4th 1 column and so on. Actually, due to some missing observations
> in these columns, I couldn't add them in 1 sheet.
>
> As you suggested the below code in the last mail,
>
> par(mfrow=c(4,10))
> for(i in 1:38)
>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>   ylab="MPG",main=names(mpg)[i])
> dev.off()
>
> Do I need to run the code separately for each sheet?
>
> Actually, in par (mfrow=c(4,10)), the plot for 38 columns will be added,
> the space for extra 2 will remain as empty. So, I thought to add plots for
> the columns from the next sheet in those emptied space.
>
> Is there any way that I can add plots from the next sheets of the same
> excel file in the emptied space? In other words, Is there any way to append
> plots from all sheets?
>
> Kindly help a new R learner Sir for which I shall be always grateful to
> you.
>
> Thank you very much for your kind help.
>
>
>
> [image: Mailtrack]
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
> notified by
> Mailtrack
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
> 7:30:30 AM
>
> On Wed, Nov 21, 2018 at 7:17 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Subhamitra,
>>
>> 1. Here I manufacture some data so that the example is "reproducible",
>> that is anyone can run the code and get the same output that I do. Yes,
>> veh1...veh38 are the names of the variables.
>>
>> 2. Here I join the 38 variables I created into a data frame, which I
>> think is the input for your plotting routine. This names of the columns of
>> the data frame become the names of the variables.
>>
>> When you say that you want the column names as the "header" (title) of
>> each plot, I think if you change the plotting loop to this:
>>
>> pdf("mpg.pdf",width=30,height=12)
>> par(mfrow=c(4,10))
>> for(i in 1:38)
>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>   ylab="MPG",main=names(mpg)[i])
>> dev.off()
>>
>> you will get what you requested. Remember that I have done this in base
>> graphics, not ggplot.
>>
>> Jim
>>
>> On Wed, Nov 21, 2018 at 12:37 PM Subhamitra Patra <
>> subhamitra.patra at gmail.com> wrote:
>>
>>> Hello Sir,
>>>
>>> Thanks, I'll check them out.
>>>
>>> But, I am not understanding 2 points of your suggestion.
>>>
>>> 1. In the line,* "*for(i in 1:38) assign(paste0("veh",i),rep(sam
>>> ple(10:35,1),10)+runif(10,-4,*4))", *what veh, rep(sample(10:35,1),10)
>>> +runif(10,-4,4)) indicate? Here veh indicates columns right?
>>> *2. In the
>>> line, mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,*
>>> * veh11,veh12,veh13,veh14,**veh15,veh16,veh17,veh18,veh19,**veh20,*
>>> * veh21,veh22,veh23,veh24,**veh25,veh26,veh27,veh28,veh29,**veh30,*
>>> * veh31,veh32,veh33,veh34,**veh35,veh36,veh37,veh38)  ** , *veh[i]
>>> indicates column sequence, right? I need to give column names as the header
>>> of their respective graphs. Please suggest me How to add this?
>>>
>>>
>>> I am very new to R and therefore asking you these queries which might be
>>> simple for you.
>>>
>>> I expect positive help from you.
>>>
>>> Thanks for your kind help.
>>> [image: Mailtrack]
>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
>>> notified by
>>> Mailtrack
>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
>>> 7:02:18 AM
>>>
>>>
>>> On Wed, Nov 21, 2018 at 4:38 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>>> Hi Subhamitra,
>>>> As Bert noted, you are mixing base and grid graphics. Here is a simple
>>>> way to get a plot like what you described. It will probably take more
>>>> work to find what you actually do want and discover how to get it.
>>>>
>>>> for(i in 1:38)
>>>> assign(paste0("veh",i),rep(sample(10:35,1),10)+runif(10,-4,4))
>>>> mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,
>>>>  veh11,veh12,veh13,veh14,veh15,veh16,veh17,veh18,veh19,veh20,
>>>>  veh21,veh22,veh23,veh24,veh25,veh26,veh27,veh28,veh29,veh30,
>>>>  veh31,veh32,veh33,veh34,veh35,veh36,veh37,veh38)
>>>> pdf("mpg.pdf",width=30,height=12)
>>>> par(mfrow=c(4,10))
>>>> for(i in 1:38)
>>>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>>>   ylab=names(mpg)[i],main="MPG by distance")
>>>> dev.off()
>>>>
>>>> Jim
>>>>
>>>> On Wed, Nov 21, 2018 at 5:19 AM Subhamitra Patra
>>>> <subhamitra.patra at gmail.com> wrote:
>>>> >
>>>> > Dear R users,
>>>> >
>>>> > I have one excel file with 5 sheets. The no. of columns vary for each
>>>> > sheet. The 1st sheet consists of 38 columns. So, I want to plot 38
>>>> separate
>>>> > line charts and arrange them in par(mfrow = c(4, 10)) order. Please
>>>> suggest
>>>> > me how to do this. I have tried with the following code by running a
>>>> loop
>>>> > inside of a sheet, but it is not working. Further, I want to run
>>>> loops for
>>>> > each sheet.
>>>> >
>>>> > par(mfrow = c(4, 10))
>>>> > loop.vector <- 1:38
>>>> > for (i in loop.vector)
>>>> > x <- JJ[,i]
>>>> > library(ggplot2)
>>>> >   library(cowplot)
>>>> >   plot.mpg <- ggplot(mpg, aes(x,
>>>> >                               main = paste ("country", i),
>>>> >                               xlab = "Scores",
>>>> >                               xlim = c(1,500)
>>>> >                               y = colnames[i,], colour =
>>>> factor(cyl))) +
>>>> >   geom_line(size=2.5)
>>>> > save_plot("mpg.png", plot.mpg,
>>>> >           base_aspect_ratio = 1.3)
>>>> >
>>>> > I want to give my X axis name as scores of (1,500) and Y axis as the
>>>> > particular column names for all graphs.
>>>> >
>>>> > Please suggest.
>>>> >
>>>> > Thanks in advance.
>>>> >
>>>> > --
>>>> > *Best Regards,*
>>>> > *Subhamitra Patra*
>>>> > *Phd. Research Scholar*
>>>> > *Department of Humanities and Social Sciences*
>>>> > *Indian Institute of Technology, Kharagpur*
>>>> > *INDIA*
>>>> >
>>>> >
>>>> >
>>>> >
>>>> >
>>>> >
>>>> >
>>>> >
>>>> > [image: Mailtrack]
>>>> > <
>>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>>> >
>>>> > Sender
>>>> > notified by
>>>> > Mailtrack
>>>> > <
>>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>>> >
>>>> > 11/20/18,
>>>> > 11:49:42 PM
>>>> >
>>>> >         [[alternative HTML version deleted]]
>>>> >
>>>> > ______________________________________________
>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>> > PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> > and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>> --
>>> *Best Regards,*
>>> *Subhamitra Patra*
>>> *Phd. Research Scholar*
>>> *Department of Humanities and Social Sciences*
>>> *Indian Institute of Technology, Kharagpur*
>>> *INDIA*
>>>
>>
>
> --
> *Best Regards,*
> *Subhamitra Patra*
> *Phd. Research Scholar*
> *Department of Humanities and Social Sciences*
> *Indian Institute of Technology, Kharagpur*
> *INDIA*
>

	[[alternative HTML version deleted]]


From @ubh@mitr@@p@tr@ @ending from gm@il@com  Wed Nov 21 04:52:04 2018
From: @ubh@mitr@@p@tr@ @ending from gm@il@com (Subhamitra Patra)
Date: Wed, 21 Nov 2018 09:22:04 +0530
Subject: [R] 
 [R studio] Plotting of line chart for each columns at 1 page
In-Reply-To: <CA+8X3fUh8bug_m8iGBGcdPdb=PeGXY0xG48NTwBHC2XzXrtyhg@mail.gmail.com>
References: <CAOFE=kOWXrnRnUVtL7A0vLKjL03571WQy5W_865hTFeBz28+tA@mail.gmail.com>
 <CA+8X3fW3Op8icpvA68O2sYPpBi=rpO2DWVXwL5UrPOHtDqDzpw@mail.gmail.com>
 <CAOFE=kNV6P4jRtrYS9K1E76pn+tW_aVpQ4Kq25ZHtQ6v-m=TkQ@mail.gmail.com>
 <CA+8X3fXM9KEb8=U1y-E_DFy9UuXk7NXDyRo6VppnEEAbAtGDDQ@mail.gmail.com>
 <CAOFE=kO20RsVsvVL2ZXpsH51aw9bzgCc3tDJ7DX8fM-tgkkbdQ@mail.gmail.com>
 <CA+8X3fUh8bug_m8iGBGcdPdb=PeGXY0xG48NTwBHC2XzXrtyhg@mail.gmail.com>
Message-ID: <CAOFE=kNda7BE7cnkUg3nTZNAZbG0-dq=ir2ddXy_1pRMwySpcg@mail.gmail.com>

Hello Sir,

Thank you very much. I will try it out and will let you the result.

The no. of rows varies per sheet by a different number of observations. Due
to different no. of rows or observations, I separated the columns in
different sheets.

*Will a different number of rows create a problem for appending all plots?*

Concerning your last suggestion "*This seems like a lot of plots, and I
suspect that you could work out a better way to display all this
information.*",  I am doing a multi-country study and obtained results for
each country. I would summarize the final result at the end. But, for
displaying the information for each country, I thought the plot is the best
way to give a supplementary result on each country. Sir, in this context, I
would like to take your suggestion that Is the way what I am doing, right
to proceed? If any alternative way is available, please suggest me.

Thank you very much, Sir, for your kind help and suggestions.

[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
11/21/18,
9:12:14 AM

On Wed, Nov 21, 2018 at 8:18 AM Jim Lemon <drjimlemon at gmail.com> wrote:

> I assume that you are importing the Excel sheets separately. When you
> import a sheet, you can get the number of columns with this:
>
> ncol(<name of data frame>)
>
> Using the data frame "mpg" that I created:
>
> ncolumns<-ncol(mpg)
> ncolumns
> [1] 38
>
> You can then substitute "ncolumns" each time you import another sheet. How
> you want to deal with the varying numbers of columns you will get is
> another matter. One way is to work out the total number of plots you want
> and put them all onto one PDF page. Say you have 50 plots overall. You
> could start a very big PDF page:
>
> pdf("allplots.pdf",width=30,height=15)
> par(mfrow=c(5,10))
> # import your first sheet here (38 columns)
> ncolumns<-ncol(mpg)
> for(i in 1:ncolumns)
>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>   ylab="MPG",main=names(mpg)[i])# import your second sheet here, say 10
> columns
> # import your second sheet here, (10 columns)
> ncolumns<-ncol(mpg1)
> for(i in 1:ncolumns)
>  plot(seq(1,500,length.out=10),mpg1[,i],type="l",xlab="Distance",
>   ylab="MPG",main=names(mpg)[i])# import your third sheet here, say 2
> columns
> # import your second sheet here, (2 columns)
> ncolumns<-ncol(mpg2)
> for(i in 1:ncolumns)
>  plot(seq(1,500,length.out=10),mpg2[,i],type="l",xlab="Distance",
>   ylab="MPG",main=names(mpg)[i])
> # finish plotting
> dev.off()
>
> You would then have 50 plots on the PDF page. I am assuming that all of
> your sheets have the same number of rows and a few other things. This seems
> like a lot of plots, and I suspect that you could work out a better way to
> display all this information.
>
> Jim
>
>
> On Wed, Nov 21, 2018 at 1:20 PM Subhamitra Patra <
> subhamitra.patra at gmail.com> wrote:
>
>> Hello Sir,
>>
>> Thanks, now I understood and will check them out.
>>
>> One more thing I want to ask that I have 1 excel file with multiple (i.e.
>> 12 sheets). Each sheet contains different number of columns, for instance,
>> 1st sheet contains 38 columns, 2nd sheet contains 10 columns, Third 2
>> columns, 4th 1 column and so on. Actually, due to some missing observations
>> in these columns, I couldn't add them in 1 sheet.
>>
>> As you suggested the below code in the last mail,
>>
>> par(mfrow=c(4,10))
>> for(i in 1:38)
>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>   ylab="MPG",main=names(mpg)[i])
>> dev.off()
>>
>> Do I need to run the code separately for each sheet?
>>
>> Actually, in par (mfrow=c(4,10)), the plot for 38 columns will be added,
>> the space for extra 2 will remain as empty. So, I thought to add plots for
>> the columns from the next sheet in those emptied space.
>>
>> Is there any way that I can add plots from the next sheets of the same
>> excel file in the emptied space? In other words, Is there any way to append
>> plots from all sheets?
>>
>> Kindly help a new R learner Sir for which I shall be always grateful to
>> you.
>>
>> Thank you very much for your kind help.
>>
>>
>>
>> [image: Mailtrack]
>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
>> notified by
>> Mailtrack
>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
>> 7:30:30 AM
>>
>> On Wed, Nov 21, 2018 at 7:17 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>>> Hi Subhamitra,
>>>
>>> 1. Here I manufacture some data so that the example is "reproducible",
>>> that is anyone can run the code and get the same output that I do. Yes,
>>> veh1...veh38 are the names of the variables.
>>>
>>> 2. Here I join the 38 variables I created into a data frame, which I
>>> think is the input for your plotting routine. This names of the columns of
>>> the data frame become the names of the variables.
>>>
>>> When you say that you want the column names as the "header" (title) of
>>> each plot, I think if you change the plotting loop to this:
>>>
>>> pdf("mpg.pdf",width=30,height=12)
>>> par(mfrow=c(4,10))
>>> for(i in 1:38)
>>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>>   ylab="MPG",main=names(mpg)[i])
>>> dev.off()
>>>
>>> you will get what you requested. Remember that I have done this in base
>>> graphics, not ggplot.
>>>
>>> Jim
>>>
>>> On Wed, Nov 21, 2018 at 12:37 PM Subhamitra Patra <
>>> subhamitra.patra at gmail.com> wrote:
>>>
>>>> Hello Sir,
>>>>
>>>> Thanks, I'll check them out.
>>>>
>>>> But, I am not understanding 2 points of your suggestion.
>>>>
>>>> 1. In the line,* "*for(i in 1:38) assign(paste0("veh",i),rep(sam
>>>> ple(10:35,1),10)+runif(10,-4,*4))", *what veh, rep(sample(10:35,1),10)
>>>> +runif(10,-4,4)) indicate? Here veh indicates columns right?
>>>> *2. In the
>>>> line, mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,*
>>>> * veh11,veh12,veh13,veh14,**veh15,veh16,veh17,veh18,veh19,**veh20,*
>>>> * veh21,veh22,veh23,veh24,**veh25,veh26,veh27,veh28,veh29,**veh30,*
>>>> * veh31,veh32,veh33,veh34,**veh35,veh36,veh37,veh38)  ** , *veh[i]
>>>> indicates column sequence, right? I need to give column names as the header
>>>> of their respective graphs. Please suggest me How to add this?
>>>>
>>>>
>>>> I am very new to R and therefore asking you these queries which might
>>>> be simple for you.
>>>>
>>>> I expect positive help from you.
>>>>
>>>> Thanks for your kind help.
>>>> [image: Mailtrack]
>>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
>>>> notified by
>>>> Mailtrack
>>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
>>>> 7:02:18 AM
>>>>
>>>>
>>>> On Wed, Nov 21, 2018 at 4:38 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>>>>
>>>>> Hi Subhamitra,
>>>>> As Bert noted, you are mixing base and grid graphics. Here is a simple
>>>>> way to get a plot like what you described. It will probably take more
>>>>> work to find what you actually do want and discover how to get it.
>>>>>
>>>>> for(i in 1:38)
>>>>> assign(paste0("veh",i),rep(sample(10:35,1),10)+runif(10,-4,4))
>>>>> mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,
>>>>>  veh11,veh12,veh13,veh14,veh15,veh16,veh17,veh18,veh19,veh20,
>>>>>  veh21,veh22,veh23,veh24,veh25,veh26,veh27,veh28,veh29,veh30,
>>>>>  veh31,veh32,veh33,veh34,veh35,veh36,veh37,veh38)
>>>>> pdf("mpg.pdf",width=30,height=12)
>>>>> par(mfrow=c(4,10))
>>>>> for(i in 1:38)
>>>>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>>>>   ylab=names(mpg)[i],main="MPG by distance")
>>>>> dev.off()
>>>>>
>>>>> Jim
>>>>>
>>>>> On Wed, Nov 21, 2018 at 5:19 AM Subhamitra Patra
>>>>> <subhamitra.patra at gmail.com> wrote:
>>>>> >
>>>>> > Dear R users,
>>>>> >
>>>>> > I have one excel file with 5 sheets. The no. of columns vary for each
>>>>> > sheet. The 1st sheet consists of 38 columns. So, I want to plot 38
>>>>> separate
>>>>> > line charts and arrange them in par(mfrow = c(4, 10)) order. Please
>>>>> suggest
>>>>> > me how to do this. I have tried with the following code by running a
>>>>> loop
>>>>> > inside of a sheet, but it is not working. Further, I want to run
>>>>> loops for
>>>>> > each sheet.
>>>>> >
>>>>> > par(mfrow = c(4, 10))
>>>>> > loop.vector <- 1:38
>>>>> > for (i in loop.vector)
>>>>> > x <- JJ[,i]
>>>>> > library(ggplot2)
>>>>> >   library(cowplot)
>>>>> >   plot.mpg <- ggplot(mpg, aes(x,
>>>>> >                               main = paste ("country", i),
>>>>> >                               xlab = "Scores",
>>>>> >                               xlim = c(1,500)
>>>>> >                               y = colnames[i,], colour =
>>>>> factor(cyl))) +
>>>>> >   geom_line(size=2.5)
>>>>> > save_plot("mpg.png", plot.mpg,
>>>>> >           base_aspect_ratio = 1.3)
>>>>> >
>>>>> > I want to give my X axis name as scores of (1,500) and Y axis as the
>>>>> > particular column names for all graphs.
>>>>> >
>>>>> > Please suggest.
>>>>> >
>>>>> > Thanks in advance.
>>>>> >
>>>>> > --
>>>>> > *Best Regards,*
>>>>> > *Subhamitra Patra*
>>>>> > *Phd. Research Scholar*
>>>>> > *Department of Humanities and Social Sciences*
>>>>> > *Indian Institute of Technology, Kharagpur*
>>>>> > *INDIA*
>>>>> >
>>>>> >
>>>>> >
>>>>> >
>>>>> >
>>>>> >
>>>>> >
>>>>> >
>>>>> > [image: Mailtrack]
>>>>> > <
>>>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>>>> >
>>>>> > Sender
>>>>> > notified by
>>>>> > Mailtrack
>>>>> > <
>>>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>>>> >
>>>>> > 11/20/18,
>>>>> > 11:49:42 PM
>>>>> >
>>>>> >         [[alternative HTML version deleted]]
>>>>> >
>>>>> > ______________________________________________
>>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> > PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> > and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>> --
>>>> *Best Regards,*
>>>> *Subhamitra Patra*
>>>> *Phd. Research Scholar*
>>>> *Department of Humanities and Social Sciences*
>>>> *Indian Institute of Technology, Kharagpur*
>>>> *INDIA*
>>>>
>>>
>>
>> --
>> *Best Regards,*
>> *Subhamitra Patra*
>> *Phd. Research Scholar*
>> *Department of Humanities and Social Sciences*
>> *Indian Institute of Technology, Kharagpur*
>> *INDIA*
>>
>

-- 
*Best Regards,*
*Subhamitra Patra*
*Phd. Research Scholar*
*Department of Humanities and Social Sciences*
*Indian Institute of Technology, Kharagpur*
*INDIA*

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Wed Nov 21 05:09:47 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Wed, 21 Nov 2018 15:09:47 +1100
Subject: [R] 
 [R studio] Plotting of line chart for each columns at 1 page
In-Reply-To: <CAOFE=kNda7BE7cnkUg3nTZNAZbG0-dq=ir2ddXy_1pRMwySpcg@mail.gmail.com>
References: <CAOFE=kOWXrnRnUVtL7A0vLKjL03571WQy5W_865hTFeBz28+tA@mail.gmail.com>
 <CA+8X3fW3Op8icpvA68O2sYPpBi=rpO2DWVXwL5UrPOHtDqDzpw@mail.gmail.com>
 <CAOFE=kNV6P4jRtrYS9K1E76pn+tW_aVpQ4Kq25ZHtQ6v-m=TkQ@mail.gmail.com>
 <CA+8X3fXM9KEb8=U1y-E_DFy9UuXk7NXDyRo6VppnEEAbAtGDDQ@mail.gmail.com>
 <CAOFE=kO20RsVsvVL2ZXpsH51aw9bzgCc3tDJ7DX8fM-tgkkbdQ@mail.gmail.com>
 <CA+8X3fUh8bug_m8iGBGcdPdb=PeGXY0xG48NTwBHC2XzXrtyhg@mail.gmail.com>
 <CAOFE=kNda7BE7cnkUg3nTZNAZbG0-dq=ir2ddXy_1pRMwySpcg@mail.gmail.com>
Message-ID: <CA+8X3fVsMos2cafXXk7seO=fpM+JFgufmQpcUhGqJ9nNm4BFmQ@mail.gmail.com>

For your first question, yes, you will need to adjust the number of "x"
values to match the number of "y" values. You can use the "nrow" function
to get that number. I don't really know what the abscissa scale is on your
plots, I just made up the data I used.

If you are comparing countries, you may want to divide the results into
countries of different characteristics, perhaps GDP or similar. Otherwise
you will end up with a quite large PDF page. This is okay if you are
viewing it electronically, but will present a challenge in hard copy.

Jim

On Wed, Nov 21, 2018 at 2:51 PM Subhamitra Patra <subhamitra.patra at gmail.com>
wrote:

> Hello Sir,
>
> Thank you very much. I will try it out and will let you the result.
>
> The no. of rows varies per sheet by a different number of observations.
> Due to different no. of rows or observations, I separated the columns in
> different sheets.
>
> *Will a different number of rows create a problem for appending all plots?*
>
> Concerning your last suggestion "*This seems like a lot of plots, and I
> suspect that you could work out a better way to display all this
> information.*",  I am doing a multi-country study and obtained results
> for each country. I would summarize the final result at the end. But, for
> displaying the information for each country, I thought the plot is the best
> way to give a supplementary result on each country. Sir, in this context, I
> would like to take your suggestion that Is the way what I am doing, right
> to proceed? If any alternative way is available, please suggest me.
>
> Thank you very much, Sir, for your kind help and suggestions.
>
> [image: Mailtrack]
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
> notified by
> Mailtrack
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
> 9:12:14 AM
>
> On Wed, Nov 21, 2018 at 8:18 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> I assume that you are importing the Excel sheets separately. When you
>> import a sheet, you can get the number of columns with this:
>>
>> ncol(<name of data frame>)
>>
>> Using the data frame "mpg" that I created:
>>
>> ncolumns<-ncol(mpg)
>> ncolumns
>> [1] 38
>>
>> You can then substitute "ncolumns" each time you import another sheet.
>> How you want to deal with the varying numbers of columns you will get is
>> another matter. One way is to work out the total number of plots you want
>> and put them all onto one PDF page. Say you have 50 plots overall. You
>> could start a very big PDF page:
>>
>> pdf("allplots.pdf",width=30,height=15)
>> par(mfrow=c(5,10))
>> # import your first sheet here (38 columns)
>> ncolumns<-ncol(mpg)
>> for(i in 1:ncolumns)
>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>   ylab="MPG",main=names(mpg)[i])# import your second sheet here, say 10
>> columns
>> # import your second sheet here, (10 columns)
>> ncolumns<-ncol(mpg1)
>> for(i in 1:ncolumns)
>>  plot(seq(1,500,length.out=10),mpg1[,i],type="l",xlab="Distance",
>>   ylab="MPG",main=names(mpg)[i])# import your third sheet here, say 2
>> columns
>> # import your second sheet here, (2 columns)
>> ncolumns<-ncol(mpg2)
>> for(i in 1:ncolumns)
>>  plot(seq(1,500,length.out=10),mpg2[,i],type="l",xlab="Distance",
>>   ylab="MPG",main=names(mpg)[i])
>> # finish plotting
>> dev.off()
>>
>> You would then have 50 plots on the PDF page. I am assuming that all of
>> your sheets have the same number of rows and a few other things. This seems
>> like a lot of plots, and I suspect that you could work out a better way to
>> display all this information.
>>
>> Jim
>>
>>
>> On Wed, Nov 21, 2018 at 1:20 PM Subhamitra Patra <
>> subhamitra.patra at gmail.com> wrote:
>>
>>> Hello Sir,
>>>
>>> Thanks, now I understood and will check them out.
>>>
>>> One more thing I want to ask that I have 1 excel file with multiple
>>> (i.e. 12 sheets). Each sheet contains different number of columns, for
>>> instance, 1st sheet contains 38 columns, 2nd sheet contains 10 columns,
>>> Third 2 columns, 4th 1 column and so on. Actually, due to some missing
>>> observations in these columns, I couldn't add them in 1 sheet.
>>>
>>> As you suggested the below code in the last mail,
>>>
>>> par(mfrow=c(4,10))
>>> for(i in 1:38)
>>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>>   ylab="MPG",main=names(mpg)[i])
>>> dev.off()
>>>
>>> Do I need to run the code separately for each sheet?
>>>
>>> Actually, in par (mfrow=c(4,10)), the plot for 38 columns will be
>>> added, the space for extra 2 will remain as empty. So, I thought to add
>>> plots for the columns from the next sheet in those emptied space.
>>>
>>> Is there any way that I can add plots from the next sheets of the same
>>> excel file in the emptied space? In other words, Is there any way to append
>>> plots from all sheets?
>>>
>>> Kindly help a new R learner Sir for which I shall be always grateful to
>>> you.
>>>
>>> Thank you very much for your kind help.
>>>
>>>
>>>
>>> [image: Mailtrack]
>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
>>> notified by
>>> Mailtrack
>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
>>> 7:30:30 AM
>>>
>>> On Wed, Nov 21, 2018 at 7:17 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>>> Hi Subhamitra,
>>>>
>>>> 1. Here I manufacture some data so that the example is "reproducible",
>>>> that is anyone can run the code and get the same output that I do. Yes,
>>>> veh1...veh38 are the names of the variables.
>>>>
>>>> 2. Here I join the 38 variables I created into a data frame, which I
>>>> think is the input for your plotting routine. This names of the columns of
>>>> the data frame become the names of the variables.
>>>>
>>>> When you say that you want the column names as the "header" (title) of
>>>> each plot, I think if you change the plotting loop to this:
>>>>
>>>> pdf("mpg.pdf",width=30,height=12)
>>>> par(mfrow=c(4,10))
>>>> for(i in 1:38)
>>>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>>>   ylab="MPG",main=names(mpg)[i])
>>>> dev.off()
>>>>
>>>> you will get what you requested. Remember that I have done this in base
>>>> graphics, not ggplot.
>>>>
>>>> Jim
>>>>
>>>> On Wed, Nov 21, 2018 at 12:37 PM Subhamitra Patra <
>>>> subhamitra.patra at gmail.com> wrote:
>>>>
>>>>> Hello Sir,
>>>>>
>>>>> Thanks, I'll check them out.
>>>>>
>>>>> But, I am not understanding 2 points of your suggestion.
>>>>>
>>>>> 1. In the line,* "*for(i in 1:38) assign(paste0("veh",i),rep(sam
>>>>> ple(10:35,1),10)+runif(10,-4,*4))", *what veh, rep(sample(10:35,1),10)
>>>>> +runif(10,-4,4)) indicate? Here veh indicates columns right?
>>>>> *2. In the
>>>>> line, mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,*
>>>>> * veh11,veh12,veh13,veh14,**veh15,veh16,veh17,veh18,veh19,**veh20,*
>>>>> * veh21,veh22,veh23,veh24,**veh25,veh26,veh27,veh28,veh29,**veh30,*
>>>>> * veh31,veh32,veh33,veh34,**veh35,veh36,veh37,veh38)  ** , *veh[i]
>>>>> indicates column sequence, right? I need to give column names as the header
>>>>> of their respective graphs. Please suggest me How to add this?
>>>>>
>>>>>
>>>>> I am very new to R and therefore asking you these queries which might
>>>>> be simple for you.
>>>>>
>>>>> I expect positive help from you.
>>>>>
>>>>> Thanks for your kind help.
>>>>> [image: Mailtrack]
>>>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
>>>>> notified by
>>>>> Mailtrack
>>>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
>>>>> 7:02:18 AM
>>>>>
>>>>>
>>>>> On Wed, Nov 21, 2018 at 4:38 AM Jim Lemon <drjimlemon at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Hi Subhamitra,
>>>>>> As Bert noted, you are mixing base and grid graphics. Here is a simple
>>>>>> way to get a plot like what you described. It will probably take more
>>>>>> work to find what you actually do want and discover how to get it.
>>>>>>
>>>>>> for(i in 1:38)
>>>>>> assign(paste0("veh",i),rep(sample(10:35,1),10)+runif(10,-4,4))
>>>>>> mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,
>>>>>>  veh11,veh12,veh13,veh14,veh15,veh16,veh17,veh18,veh19,veh20,
>>>>>>  veh21,veh22,veh23,veh24,veh25,veh26,veh27,veh28,veh29,veh30,
>>>>>>  veh31,veh32,veh33,veh34,veh35,veh36,veh37,veh38)
>>>>>> pdf("mpg.pdf",width=30,height=12)
>>>>>> par(mfrow=c(4,10))
>>>>>> for(i in 1:38)
>>>>>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>>>>>   ylab=names(mpg)[i],main="MPG by distance")
>>>>>> dev.off()
>>>>>>
>>>>>> Jim
>>>>>>
>>>>>> On Wed, Nov 21, 2018 at 5:19 AM Subhamitra Patra
>>>>>> <subhamitra.patra at gmail.com> wrote:
>>>>>> >
>>>>>> > Dear R users,
>>>>>> >
>>>>>> > I have one excel file with 5 sheets. The no. of columns vary for
>>>>>> each
>>>>>> > sheet. The 1st sheet consists of 38 columns. So, I want to plot 38
>>>>>> separate
>>>>>> > line charts and arrange them in par(mfrow = c(4, 10)) order. Please
>>>>>> suggest
>>>>>> > me how to do this. I have tried with the following code by running
>>>>>> a loop
>>>>>> > inside of a sheet, but it is not working. Further, I want to run
>>>>>> loops for
>>>>>> > each sheet.
>>>>>> >
>>>>>> > par(mfrow = c(4, 10))
>>>>>> > loop.vector <- 1:38
>>>>>> > for (i in loop.vector)
>>>>>> > x <- JJ[,i]
>>>>>> > library(ggplot2)
>>>>>> >   library(cowplot)
>>>>>> >   plot.mpg <- ggplot(mpg, aes(x,
>>>>>> >                               main = paste ("country", i),
>>>>>> >                               xlab = "Scores",
>>>>>> >                               xlim = c(1,500)
>>>>>> >                               y = colnames[i,], colour =
>>>>>> factor(cyl))) +
>>>>>> >   geom_line(size=2.5)
>>>>>> > save_plot("mpg.png", plot.mpg,
>>>>>> >           base_aspect_ratio = 1.3)
>>>>>> >
>>>>>> > I want to give my X axis name as scores of (1,500) and Y axis as the
>>>>>> > particular column names for all graphs.
>>>>>> >
>>>>>> > Please suggest.
>>>>>> >
>>>>>> > Thanks in advance.
>>>>>> >
>>>>>> > --
>>>>>> > *Best Regards,*
>>>>>> > *Subhamitra Patra*
>>>>>> > *Phd. Research Scholar*
>>>>>> > *Department of Humanities and Social Sciences*
>>>>>> > *Indian Institute of Technology, Kharagpur*
>>>>>> > *INDIA*
>>>>>> >
>>>>>> >
>>>>>> >
>>>>>> >
>>>>>> >
>>>>>> >
>>>>>> >
>>>>>> >
>>>>>> > [image: Mailtrack]
>>>>>> > <
>>>>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>>>>> >
>>>>>> > Sender
>>>>>> > notified by
>>>>>> > Mailtrack
>>>>>> > <
>>>>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>>>>> >
>>>>>> > 11/20/18,
>>>>>> > 11:49:42 PM
>>>>>> >
>>>>>> >         [[alternative HTML version deleted]]
>>>>>> >
>>>>>> > ______________________________________________
>>>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> > PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> > and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> *Best Regards,*
>>>>> *Subhamitra Patra*
>>>>> *Phd. Research Scholar*
>>>>> *Department of Humanities and Social Sciences*
>>>>> *Indian Institute of Technology, Kharagpur*
>>>>> *INDIA*
>>>>>
>>>>
>>>
>>> --
>>> *Best Regards,*
>>> *Subhamitra Patra*
>>> *Phd. Research Scholar*
>>> *Department of Humanities and Social Sciences*
>>> *Indian Institute of Technology, Kharagpur*
>>> *INDIA*
>>>
>>
>
> --
> *Best Regards,*
> *Subhamitra Patra*
> *Phd. Research Scholar*
> *Department of Humanities and Social Sciences*
> *Indian Institute of Technology, Kharagpur*
> *INDIA*
>

	[[alternative HTML version deleted]]


From i@p@nyolcom @ending from gm@il@com  Wed Nov 21 07:06:30 2018
From: i@p@nyolcom @ending from gm@il@com (=?UTF-8?Q?Engin_Y=C4=B1lmaz?=)
Date: Wed, 21 Nov 2018 09:06:30 +0300
Subject: [R] system solver in R
In-Reply-To: <6ee32441-7839-120f-feab-7c2af7d7f18a@uke.de>
References: <CAMUSX8rwvVkitcFe6MmRpE+bJVTaoVHL4Ank+Jd52oyaRqP=Xg@mail.gmail.com>
 <3577E651-4A38-4F2C-835A-BA9B9177905B@xs4all.nl>
 <CAMUSX8r5c=PemFaD1Ew5Q-2czvbPgk7kEj7vocqZV76POFvksQ@mail.gmail.com>
 <CAMUSX8ptu+b=SFZAA+FQw4aPfu5eqzgWTVHkCuRm92Xj9srqcA@mail.gmail.com>
 <6ee32441-7839-120f-feab-7c2af7d7f18a@uke.de>
Message-ID: <CAMUSX8q6qKJBpoFrdvdLL7=3dHyjiyYbvjK03ODOgVxK3YM+Og@mail.gmail.com>

Yes, it works for me.

Eik Vettorazzi <E.Vettorazzi at uke.de>, 21 Kas 2018 ?ar, 00:19 tarihinde ?unu
yazd?:

> How about this:
>
> library(rootSolve)
> f1<-function(x)5/((1+x)^1) + 5/((1+x)^2) + 5/((1+x)^3) + 105/((1+x)^4) -105
> uniroot.all( f1,c(-1e6,1e6))
>
> [1] -1.9881665  0.0363435
>
> Cheers
>
>
> Am 20.11.2018 um 13:09 schrieb Engin Y?lmaz:
> > Dea(R)
> > I try to solve one equation but this program did not give me real roots
> > for example
> > yacas("Solve( 5/((1+x)^1) + 5/((1+x)^2) + 5/((1+x)^3) + 105/((1+x)^4)
> -105
> > ==0, x)")
> > gave me following results
> > How can I find real roots?
> >
> > expression(list(x == complex_cartesian((1/42 - ((1/63 -
> > ((root(7339451281/3087580356,
> >      2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
> >      2))^(1/3)))/21 - -2/21)/(4 * root(((root(7339451281/3087580356,
> >      2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
> >      2))^(1/3) - 1/63)^2/4 + 1, 2)))/2 - 1, root(4 *
> > (((root(7339451281/3087580356,
> >      2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
> >      2))^(1/3) - 1/63)/2 + root(((root(7339451281/3087580356,
> >      2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
> >      2))^(1/3) - 1/63)^2/4 + 1, 2)) - (((1/63 -
> > ((root(7339451281/3087580356,
> >      2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
> >      2))^(1/3)))/21 - -2/21)/(4 * root(((root(7339451281/3087580356,
> >      2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
> >      2))^(1/3) - 1/63)^2/4 + 1, 2)) - 1/42)^2, 2)/2),...more
> >
> >
> >
> >
> > Engin Y?lmaz <ispanyolcom at gmail.com>, 20 Kas 2018 Sal, 12:53 tarihinde
> ?unu
> > yazd?:
> >
> >> Thanks a lot!
> >>
> >> Berend Hasselman <bhh at xs4all.nl>, 20 Kas 2018 Sal, 12:02 tarihinde ?unu
> >> yazd?:
> >>
> >>>
> >>>
> >>> R package Ryacas may be what you want.
> >>>
> >>> Berend
> >>>
> >>>
> >>>> On 20 Nov 2018, at 09:42, Engin Y?lmaz <ispanyolcom at gmail.com> wrote:
> >>>>
> >>>> Dea(R)
> >>>>
> >>>> Do you know any system solver in R ?
> >>>>
> >>>> For example, in matlab, is very easy
> >>>>
> >>>> syms a b c x eqn = a*x^2 + b*x + c == 0; sol = solve(eqn)
> >>>>
> >>>> How can I  find this type code in R (or directly solver)?
> >>>>
> >>>> *Since(R)ely*
> >>>> Engin YILMAZ
> >>>>
> >>>>        [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >>
> >> --
> >> *Sayg?lar?mla*
> >> Engin YILMAZ
> >>
> >
> >
>
> --
> Eik Vettorazzi
>
> Universit?tsklinikum Hamburg-Eppendorf
> Institut f?r Medizinische Biometrie und Epidemiologie
>
> Martinistra?e 52
> Geb?ude W 34
> 20246 Hamburg
>
> Telefon: +49 (0) 40 7410 - 58243
> Fax:     +49 (0) 40 7410 - 57790
>
> Web: www.uke.de/imbe
>
>
> --
>
> _____________________________________________________________________
>
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
> Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr.
> Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
> _____________________________________________________________________
>
> SAVE PAPER - THINK BEFORE PRINTING
>


-- 
*Sayg?lar?mla*
Engin YILMAZ

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Wed Nov 21 08:43:14 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Wed, 21 Nov 2018 07:43:14 +0000
Subject: [R] 
 [R studio] Plotting of line chart for each columns at 1 page
In-Reply-To: <CAOFE=kNda7BE7cnkUg3nTZNAZbG0-dq=ir2ddXy_1pRMwySpcg@mail.gmail.com>
References: <CAOFE=kOWXrnRnUVtL7A0vLKjL03571WQy5W_865hTFeBz28+tA@mail.gmail.com>
 <CA+8X3fW3Op8icpvA68O2sYPpBi=rpO2DWVXwL5UrPOHtDqDzpw@mail.gmail.com>
 <CAOFE=kNV6P4jRtrYS9K1E76pn+tW_aVpQ4Kq25ZHtQ6v-m=TkQ@mail.gmail.com>
 <CA+8X3fXM9KEb8=U1y-E_DFy9UuXk7NXDyRo6VppnEEAbAtGDDQ@mail.gmail.com>
 <CAOFE=kO20RsVsvVL2ZXpsH51aw9bzgCc3tDJ7DX8fM-tgkkbdQ@mail.gmail.com>
 <CA+8X3fUh8bug_m8iGBGcdPdb=PeGXY0xG48NTwBHC2XzXrtyhg@mail.gmail.com>
 <CAOFE=kNda7BE7cnkUg3nTZNAZbG0-dq=ir2ddXy_1pRMwySpcg@mail.gmail.com>
Message-ID: <ea980d83208844259e45bbc76a652f45@SRVEXCHCM1302.precheza.cz>

Hi

When I do multiple plots of similar data I usually put the plots into the multipage pdf file

pdf("somename.pdf")
for (i in columns) {
p<-ggplot(something)
print(p+geom_point(size=4)+stat_smooth(se=F, span=0.5, size=1.3)+
facet_grid(al2o3~teplota, labeller="label_both"))

or

plot(something)

}
dev.off()

This will generate somename.pdf in your working directory and plots will be definitelly bigger than 40 plots in one page.

Another approach could be to store plots as objects in a list (which is easy done with ggplot) but rather trickier with base graphics and make actual plotting after the whole list is populated with your plots.

https://www.andrewheiss.com/blog/2016/12/08/save-base-graphics-as-pseudo-objects-in-r/

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Subhamitra Patra
> Sent: Wednesday, November 21, 2018 4:52 AM
> To: Jim Lemon <drjimlemon at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] [R studio] Plotting of line chart for each columns at 1 page
>
> Hello Sir,
>
> Thank you very much. I will try it out and will let you the result.
>
> The no. of rows varies per sheet by a different number of observations. Due to
> different no. of rows or observations, I separated the columns in different
> sheets.
>
> *Will a different number of rows create a problem for appending all plots?*
>
> Concerning your last suggestion "*This seems like a lot of plots, and I suspect
> that you could work out a better way to display all this information.*",  I am
> doing a multi-country study and obtained results for each country. I would
> summarize the final result at the end. But, for displaying the information for
> each country, I thought the plot is the best way to give a supplementary result
> on each country. Sir, in this context, I would like to take your suggestion that Is
> the way what I am doing, right to proceed? If any alternative way is available,
> please suggest me.
>
> Thank you very much, Sir, for your kind help and suggestions.
>
> [image: Mailtrack]
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campa
> ign=signaturevirality5&>
> Sender
> notified by
> Mailtrack
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campa
> ign=signaturevirality5&>
> 11/21/18,
> 9:12:14 AM
>
> On Wed, Nov 21, 2018 at 8:18 AM Jim Lemon <drjimlemon at gmail.com>
> wrote:
>
> > I assume that you are importing the Excel sheets separately. When you
> > import a sheet, you can get the number of columns with this:
> >
> > ncol(<name of data frame>)
> >
> > Using the data frame "mpg" that I created:
> >
> > ncolumns<-ncol(mpg)
> > ncolumns
> > [1] 38
> >
> > You can then substitute "ncolumns" each time you import another sheet.
> > How you want to deal with the varying numbers of columns you will get
> > is another matter. One way is to work out the total number of plots
> > you want and put them all onto one PDF page. Say you have 50 plots
> > overall. You could start a very big PDF page:
> >
> > pdf("allplots.pdf",width=30,height=15)
> > par(mfrow=c(5,10))
> > # import your first sheet here (38 columns)
> > ncolumns<-ncol(mpg)
> > for(i in 1:ncolumns)
> >  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
> >   ylab="MPG",main=names(mpg)[i])# import your second sheet here, say
> > 10 columns # import your second sheet here, (10 columns)
> > ncolumns<-ncol(mpg1)
> > for(i in 1:ncolumns)
> >  plot(seq(1,500,length.out=10),mpg1[,i],type="l",xlab="Distance",
> >   ylab="MPG",main=names(mpg)[i])# import your third sheet here, say 2
> > columns # import your second sheet here, (2 columns)
> > ncolumns<-ncol(mpg2)
> > for(i in 1:ncolumns)
> >  plot(seq(1,500,length.out=10),mpg2[,i],type="l",xlab="Distance",
> >   ylab="MPG",main=names(mpg)[i])
> > # finish plotting
> > dev.off()
> >
> > You would then have 50 plots on the PDF page. I am assuming that all
> > of your sheets have the same number of rows and a few other things.
> > This seems like a lot of plots, and I suspect that you could work out
> > a better way to display all this information.
> >
> > Jim
> >
> >
> > On Wed, Nov 21, 2018 at 1:20 PM Subhamitra Patra <
> > subhamitra.patra at gmail.com> wrote:
> >
> >> Hello Sir,
> >>
> >> Thanks, now I understood and will check them out.
> >>
> >> One more thing I want to ask that I have 1 excel file with multiple (i.e.
> >> 12 sheets). Each sheet contains different number of columns, for
> >> instance, 1st sheet contains 38 columns, 2nd sheet contains 10
> >> columns, Third 2 columns, 4th 1 column and so on. Actually, due to
> >> some missing observations in these columns, I couldn't add them in 1 sheet.
> >>
> >> As you suggested the below code in the last mail,
> >>
> >> par(mfrow=c(4,10))
> >> for(i in 1:38)
> >>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
> >>   ylab="MPG",main=names(mpg)[i])
> >> dev.off()
> >>
> >> Do I need to run the code separately for each sheet?
> >>
> >> Actually, in par (mfrow=c(4,10)), the plot for 38 columns will be
> >> added, the space for extra 2 will remain as empty. So, I thought to
> >> add plots for the columns from the next sheet in those emptied space.
> >>
> >> Is there any way that I can add plots from the next sheets of the
> >> same excel file in the emptied space? In other words, Is there any
> >> way to append plots from all sheets?
> >>
> >> Kindly help a new R learner Sir for which I shall be always grateful
> >> to you.
> >>
> >> Thank you very much for your kind help.
> >>
> >>
> >>
> >> [image: Mailtrack]
> >>
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campa
> >> ign=signaturevirality5&> Sender notified by Mailtrack
> >>
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campa
> >> ign=signaturevirality5&> 11/21/18,
> >> 7:30:30 AM
> >>
> >> On Wed, Nov 21, 2018 at 7:17 AM Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >>
> >>> Hi Subhamitra,
> >>>
> >>> 1. Here I manufacture some data so that the example is
> >>> "reproducible", that is anyone can run the code and get the same
> >>> output that I do. Yes,
> >>> veh1...veh38 are the names of the variables.
> >>>
> >>> 2. Here I join the 38 variables I created into a data frame, which I
> >>> think is the input for your plotting routine. This names of the
> >>> columns of the data frame become the names of the variables.
> >>>
> >>> When you say that you want the column names as the "header" (title)
> >>> of each plot, I think if you change the plotting loop to this:
> >>>
> >>> pdf("mpg.pdf",width=30,height=12)
> >>> par(mfrow=c(4,10))
> >>> for(i in 1:38)
> >>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
> >>>   ylab="MPG",main=names(mpg)[i])
> >>> dev.off()
> >>>
> >>> you will get what you requested. Remember that I have done this in
> >>> base graphics, not ggplot.
> >>>
> >>> Jim
> >>>
> >>> On Wed, Nov 21, 2018 at 12:37 PM Subhamitra Patra <
> >>> subhamitra.patra at gmail.com> wrote:
> >>>
> >>>> Hello Sir,
> >>>>
> >>>> Thanks, I'll check them out.
> >>>>
> >>>> But, I am not understanding 2 points of your suggestion.
> >>>>
> >>>> 1. In the line,* "*for(i in 1:38) assign(paste0("veh",i),rep(sam
> >>>> ple(10:35,1),10)+runif(10,-4,*4))", *what veh,
> >>>> rep(sample(10:35,1),10)
> >>>> +runif(10,-4,4)) indicate? Here veh indicates columns right?
> >>>> *2. In the
> >>>> line,
> >>>> mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,
> >>>> *
> >>>> *
> veh11,veh12,veh13,veh14,**veh15,veh16,veh17,veh18,veh19,**veh20,*
> >>>> *
> veh21,veh22,veh23,veh24,**veh25,veh26,veh27,veh28,veh29,**veh30,*
> >>>> * veh31,veh32,veh33,veh34,**veh35,veh36,veh37,veh38)  ** , *veh[i]
> >>>> indicates column sequence, right? I need to give column names as
> >>>> the header of their respective graphs. Please suggest me How to add this?
> >>>>
> >>>>
> >>>> I am very new to R and therefore asking you these queries which
> >>>> might be simple for you.
> >>>>
> >>>> I expect positive help from you.
> >>>>
> >>>> Thanks for your kind help.
> >>>> [image: Mailtrack]
> >>>>
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_cam
> >>>> paign=signaturevirality5&> Sender notified by Mailtrack
> >>>>
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_cam
> >>>> paign=signaturevirality5&> 11/21/18,
> >>>> 7:02:18 AM
> >>>>
> >>>>
> >>>> On Wed, Nov 21, 2018 at 4:38 AM Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >>>>
> >>>>> Hi Subhamitra,
> >>>>> As Bert noted, you are mixing base and grid graphics. Here is a
> >>>>> simple way to get a plot like what you described. It will probably
> >>>>> take more work to find what you actually do want and discover how to
> get it.
> >>>>>
> >>>>> for(i in 1:38)
> >>>>> assign(paste0("veh",i),rep(sample(10:35,1),10)+runif(10,-4,4))
> >>>>> mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10
> >>>>> ,  veh11,veh12,veh13,veh14,veh15,veh16,veh17,veh18,veh19,veh20,
> >>>>>  veh21,veh22,veh23,veh24,veh25,veh26,veh27,veh28,veh29,veh30,
> >>>>>  veh31,veh32,veh33,veh34,veh35,veh36,veh37,veh38)
> >>>>> pdf("mpg.pdf",width=30,height=12)
> >>>>> par(mfrow=c(4,10))
> >>>>> for(i in 1:38)
> >>>>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
> >>>>>   ylab=names(mpg)[i],main="MPG by distance")
> >>>>> dev.off()
> >>>>>
> >>>>> Jim
> >>>>>
> >>>>> On Wed, Nov 21, 2018 at 5:19 AM Subhamitra Patra
> >>>>> <subhamitra.patra at gmail.com> wrote:
> >>>>> >
> >>>>> > Dear R users,
> >>>>> >
> >>>>> > I have one excel file with 5 sheets. The no. of columns vary for
> >>>>> > each sheet. The 1st sheet consists of 38 columns. So, I want to
> >>>>> > plot 38
> >>>>> separate
> >>>>> > line charts and arrange them in par(mfrow = c(4, 10)) order.
> >>>>> > Please
> >>>>> suggest
> >>>>> > me how to do this. I have tried with the following code by
> >>>>> > running a
> >>>>> loop
> >>>>> > inside of a sheet, but it is not working. Further, I want to run
> >>>>> loops for
> >>>>> > each sheet.
> >>>>> >
> >>>>> > par(mfrow = c(4, 10))
> >>>>> > loop.vector <- 1:38
> >>>>> > for (i in loop.vector)
> >>>>> > x <- JJ[,i]
> >>>>> > library(ggplot2)
> >>>>> >   library(cowplot)
> >>>>> >   plot.mpg <- ggplot(mpg, aes(x,
> >>>>> >                               main = paste ("country", i),
> >>>>> >                               xlab = "Scores",
> >>>>> >                               xlim = c(1,500)
> >>>>> >                               y = colnames[i,], colour =
> >>>>> factor(cyl))) +
> >>>>> >   geom_line(size=2.5)
> >>>>> > save_plot("mpg.png", plot.mpg,
> >>>>> >           base_aspect_ratio = 1.3)
> >>>>> >
> >>>>> > I want to give my X axis name as scores of (1,500) and Y axis as
> >>>>> > the particular column names for all graphs.
> >>>>> >
> >>>>> > Please suggest.
> >>>>> >
> >>>>> > Thanks in advance.
> >>>>> >
> >>>>> > --
> >>>>> > *Best Regards,*
> >>>>> > *Subhamitra Patra*
> >>>>> > *Phd. Research Scholar*
> >>>>> > *Department of Humanities and Social Sciences* *Indian Institute
> >>>>> > of Technology, Kharagpur*
> >>>>> > *INDIA*
> >>>>> >
> >>>>> >
> >>>>> >
> >>>>> >
> >>>>> >
> >>>>> >
> >>>>> >
> >>>>> >
> >>>>> > [image: Mailtrack]
> >>>>> > <
> >>>>>
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_cam
> >>>>> paign=signaturevirality5&
> >>>>> >
> >>>>> > Sender
> >>>>> > notified by
> >>>>> > Mailtrack
> >>>>> > <
> >>>>>
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_cam
> >>>>> paign=signaturevirality5&
> >>>>> >
> >>>>> > 11/20/18,
> >>>>> > 11:49:42 PM
> >>>>> >
> >>>>> >         [[alternative HTML version deleted]]
> >>>>> >
> >>>>> > ______________________________________________
> >>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>>>> > see https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> > PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>> > and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>
> >>>>
> >>>> --
> >>>> *Best Regards,*
> >>>> *Subhamitra Patra*
> >>>> *Phd. Research Scholar*
> >>>> *Department of Humanities and Social Sciences* *Indian Institute of
> >>>> Technology, Kharagpur*
> >>>> *INDIA*
> >>>>
> >>>
> >>
> >> --
> >> *Best Regards,*
> >> *Subhamitra Patra*
> >> *Phd. Research Scholar*
> >> *Department of Humanities and Social Sciences* *Indian Institute of
> >> Technology, Kharagpur*
> >> *INDIA*
> >>
> >
>
> --
> *Best Regards,*
> *Subhamitra Patra*
> *Phd. Research Scholar*
> *Department of Humanities and Social Sciences* *Indian Institute of
> Technology, Kharagpur*
> *INDIA*
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From drjimlemon @ending from gm@il@com  Wed Nov 21 08:51:07 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Wed, 21 Nov 2018 18:51:07 +1100
Subject: [R] 
 [R studio] Plotting of line chart for each columns at 1 page
In-Reply-To: <CAOFE=kOiTHOzcQ+dL2Tak2WnGBx1JAXpryj5CbLefdofa-7x5Q@mail.gmail.com>
References: <CAOFE=kOWXrnRnUVtL7A0vLKjL03571WQy5W_865hTFeBz28+tA@mail.gmail.com>
 <CA+8X3fW3Op8icpvA68O2sYPpBi=rpO2DWVXwL5UrPOHtDqDzpw@mail.gmail.com>
 <CAOFE=kNV6P4jRtrYS9K1E76pn+tW_aVpQ4Kq25ZHtQ6v-m=TkQ@mail.gmail.com>
 <CA+8X3fXM9KEb8=U1y-E_DFy9UuXk7NXDyRo6VppnEEAbAtGDDQ@mail.gmail.com>
 <CAOFE=kO20RsVsvVL2ZXpsH51aw9bzgCc3tDJ7DX8fM-tgkkbdQ@mail.gmail.com>
 <CA+8X3fUh8bug_m8iGBGcdPdb=PeGXY0xG48NTwBHC2XzXrtyhg@mail.gmail.com>
 <CAOFE=kNda7BE7cnkUg3nTZNAZbG0-dq=ir2ddXy_1pRMwySpcg@mail.gmail.com>
 <CA+8X3fVsMos2cafXXk7seO=fpM+JFgufmQpcUhGqJ9nNm4BFmQ@mail.gmail.com>
 <CAOFE=kOiTHOzcQ+dL2Tak2WnGBx1JAXpryj5CbLefdofa-7x5Q@mail.gmail.com>
Message-ID: <CA+8X3fVYFJ9GUzY5ujH38zEQhWKKrkUpRzf1UjC-Cc=GHMe0VA@mail.gmail.com>

Now we're getting somewhere. I suspect that each Excel sheet looks
something like this:

Year    Tonga    Samoa    Fiji
2008    21.2      32.0       18.7
...
2017    23.7      31.9       19.3
# in the above there are three columns (countries) and ten rows
# import this sheet as "MPG3"
nrows<-nrow(MPG3) # nrows equals 10
ncols<-ncol(MPG3)  # ncols equals 3
for(i in 1:ncols)
 plot(seq(1:nrows,MPG3[,i],type="l",xlab="Distance",
  ylab="MPG",main=names(MPG3)[i],xaxt="n")
 axis(1,at=1:nrows,labels=MPG3$Year)

I probably have the structure of the imported data frame wrong, but I think
you can work that out.

Jim



On Wed, Nov 21, 2018 at 4:08 PM Subhamitra Patra <subhamitra.patra at gmail.com>
wrote:

> As per your suggestion, *"you will need to adjust the number of "x"
> values to match the number of "y" values.  Now with the addition of the
> nrow function, the code for each sheet will be*
>
>
> *ncolumns<-ncol(mpg)*
> *   nrows<-nrow(mpg) *
>
>
> *for(i in
> 1:ncolumns) plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
> ylab="MPG",main=names(mpg)[i])  *
>
> #####The no. of rows for the columns in one sheet will be the same. In the
> X-axis, I need to mention Year which is the same for all columns in a
> sheet. But, the starting year varies from one sheet to other.
>
> *Sir, please suggest in case of any mistakes.*
>
> Second, I will definitely consider your suggestions about the division of
> sample by similar characteristics so that it can be easier to show in
> graphical. Thank you very much, sir, for such creative and wonderful
> suggestions.
>
>
>
> [image: Mailtrack]
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
> notified by
> Mailtrack
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
> 10:35:03 AM
>
> On Wed, Nov 21, 2018 at 9:40 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> For your first question, yes, you will need to adjust the number of "x"
>> values to match the number of "y" values. You can use the "nrow" function
>> to get that number. I don't really know what the abscissa scale is on your
>> plots, I just made up the data I used.
>>
>> If you are comparing countries, you may want to divide the results into
>> countries of different characteristics, perhaps GDP or similar. Otherwise
>> you will end up with a quite large PDF page. This is okay if you are
>> viewing it electronically, but will present a challenge in hard copy.
>>
>> Jim
>>
>> On Wed, Nov 21, 2018 at 2:51 PM Subhamitra Patra <
>> subhamitra.patra at gmail.com> wrote:
>>
>>> Hello Sir,
>>>
>>> Thank you very much. I will try it out and will let you the result.
>>>
>>> The no. of rows varies per sheet by a different number of observations.
>>> Due to different no. of rows or observations, I separated the columns in
>>> different sheets.
>>>
>>> *Will a different number of rows create a problem for appending all
>>> plots?*
>>>
>>> Concerning your last suggestion "*This seems like a lot of plots, and I
>>> suspect that you could work out a better way to display all this
>>> information.*",  I am doing a multi-country study and obtained results
>>> for each country. I would summarize the final result at the end. But, for
>>> displaying the information for each country, I thought the plot is the best
>>> way to give a supplementary result on each country. Sir, in this context, I
>>> would like to take your suggestion that Is the way what I am doing, right
>>> to proceed? If any alternative way is available, please suggest me.
>>>
>>> Thank you very much, Sir, for your kind help and suggestions.
>>>
>>> [image: Mailtrack]
>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
>>> notified by
>>> Mailtrack
>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
>>> 9:12:14 AM
>>>
>>> On Wed, Nov 21, 2018 at 8:18 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>>> I assume that you are importing the Excel sheets separately. When you
>>>> import a sheet, you can get the number of columns with this:
>>>>
>>>> ncol(<name of data frame>)
>>>>
>>>> Using the data frame "mpg" that I created:
>>>>
>>>> ncolumns<-ncol(mpg)
>>>> ncolumns
>>>> [1] 38
>>>>
>>>> You can then substitute "ncolumns" each time you import another sheet.
>>>> How you want to deal with the varying numbers of columns you will get is
>>>> another matter. One way is to work out the total number of plots you want
>>>> and put them all onto one PDF page. Say you have 50 plots overall. You
>>>> could start a very big PDF page:
>>>>
>>>> pdf("allplots.pdf",width=30,height=15)
>>>> par(mfrow=c(5,10))
>>>> # import your first sheet here (38 columns)
>>>> ncolumns<-ncol(mpg)
>>>> for(i in 1:ncolumns)
>>>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>>>   ylab="MPG",main=names(mpg)[i])# import your second sheet here, say
>>>> 10 columns
>>>> # import your second sheet here, (10 columns)
>>>> ncolumns<-ncol(mpg1)
>>>> for(i in 1:ncolumns)
>>>>  plot(seq(1,500,length.out=10),mpg1[,i],type="l",xlab="Distance",
>>>>   ylab="MPG",main=names(mpg)[i])# import your third sheet here, say 2
>>>> columns
>>>> # import your second sheet here, (2 columns)
>>>> ncolumns<-ncol(mpg2)
>>>> for(i in 1:ncolumns)
>>>>  plot(seq(1,500,length.out=10),mpg2[,i],type="l",xlab="Distance",
>>>>   ylab="MPG",main=names(mpg)[i])
>>>> # finish plotting
>>>> dev.off()
>>>>
>>>> You would then have 50 plots on the PDF page. I am assuming that all of
>>>> your sheets have the same number of rows and a few other things. This seems
>>>> like a lot of plots, and I suspect that you could work out a better way to
>>>> display all this information.
>>>>
>>>> Jim
>>>>
>>>>
>>>> On Wed, Nov 21, 2018 at 1:20 PM Subhamitra Patra <
>>>> subhamitra.patra at gmail.com> wrote:
>>>>
>>>>> Hello Sir,
>>>>>
>>>>> Thanks, now I understood and will check them out.
>>>>>
>>>>> One more thing I want to ask that I have 1 excel file with multiple
>>>>> (i.e. 12 sheets). Each sheet contains different number of columns, for
>>>>> instance, 1st sheet contains 38 columns, 2nd sheet contains 10 columns,
>>>>> Third 2 columns, 4th 1 column and so on. Actually, due to some missing
>>>>> observations in these columns, I couldn't add them in 1 sheet.
>>>>>
>>>>> As you suggested the below code in the last mail,
>>>>>
>>>>> par(mfrow=c(4,10))
>>>>> for(i in 1:38)
>>>>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>>>>   ylab="MPG",main=names(mpg)[i])
>>>>> dev.off()
>>>>>
>>>>> Do I need to run the code separately for each sheet?
>>>>>
>>>>> Actually, in par (mfrow=c(4,10)), the plot for 38 columns will be
>>>>> added, the space for extra 2 will remain as empty. So, I thought to add
>>>>> plots for the columns from the next sheet in those emptied space.
>>>>>
>>>>> Is there any way that I can add plots from the next sheets of the same
>>>>> excel file in the emptied space? In other words, Is there any way to append
>>>>> plots from all sheets?
>>>>>
>>>>> Kindly help a new R learner Sir for which I shall be always grateful
>>>>> to you.
>>>>>
>>>>> Thank you very much for your kind help.
>>>>>
>>>>>
>>>>>
>>>>> [image: Mailtrack]
>>>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
>>>>> notified by
>>>>> Mailtrack
>>>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
>>>>> 7:30:30 AM
>>>>>
>>>>> On Wed, Nov 21, 2018 at 7:17 AM Jim Lemon <drjimlemon at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Hi Subhamitra,
>>>>>>
>>>>>> 1. Here I manufacture some data so that the example is
>>>>>> "reproducible", that is anyone can run the code and get the same output
>>>>>> that I do. Yes, veh1...veh38 are the names of the variables.
>>>>>>
>>>>>> 2. Here I join the 38 variables I created into a data frame, which I
>>>>>> think is the input for your plotting routine. This names of the columns of
>>>>>> the data frame become the names of the variables.
>>>>>>
>>>>>> When you say that you want the column names as the "header" (title)
>>>>>> of each plot, I think if you change the plotting loop to this:
>>>>>>
>>>>>> pdf("mpg.pdf",width=30,height=12)
>>>>>> par(mfrow=c(4,10))
>>>>>> for(i in 1:38)
>>>>>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>>>>>   ylab="MPG",main=names(mpg)[i])
>>>>>> dev.off()
>>>>>>
>>>>>> you will get what you requested. Remember that I have done this in
>>>>>> base graphics, not ggplot.
>>>>>>
>>>>>> Jim
>>>>>>
>>>>>> On Wed, Nov 21, 2018 at 12:37 PM Subhamitra Patra <
>>>>>> subhamitra.patra at gmail.com> wrote:
>>>>>>
>>>>>>> Hello Sir,
>>>>>>>
>>>>>>> Thanks, I'll check them out.
>>>>>>>
>>>>>>> But, I am not understanding 2 points of your suggestion.
>>>>>>>
>>>>>>> 1. In the line,* "*for(i in 1:38) assign(paste0("veh",i),rep(sam
>>>>>>> ple(10:35,1),10)+runif(10,-4,*4))", *what veh, rep(sam
>>>>>>> ple(10:35,1),10)+runif(10,-4,4)) indicate? Here veh indicates
>>>>>>> columns right?
>>>>>>> *2. In the
>>>>>>> line, mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,*
>>>>>>> * veh11,veh12,veh13,veh14,**veh15,veh16,veh17,veh18,veh19,**veh20,*
>>>>>>> * veh21,veh22,veh23,veh24,**veh25,veh26,veh27,veh28,veh29,**veh30,*
>>>>>>> * veh31,veh32,veh33,veh34,**veh35,veh36,veh37,veh38)  ** , *veh[i]
>>>>>>> indicates column sequence, right? I need to give column names as the header
>>>>>>> of their respective graphs. Please suggest me How to add this?
>>>>>>>
>>>>>>>
>>>>>>> I am very new to R and therefore asking you these queries which
>>>>>>> might be simple for you.
>>>>>>>
>>>>>>> I expect positive help from you.
>>>>>>>
>>>>>>> Thanks for your kind help.
>>>>>>> [image: Mailtrack]
>>>>>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
>>>>>>> notified by
>>>>>>> Mailtrack
>>>>>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
>>>>>>> 7:02:18 AM
>>>>>>>
>>>>>>>
>>>>>>> On Wed, Nov 21, 2018 at 4:38 AM Jim Lemon <drjimlemon at gmail.com>
>>>>>>> wrote:
>>>>>>>
>>>>>>>> Hi Subhamitra,
>>>>>>>> As Bert noted, you are mixing base and grid graphics. Here is a
>>>>>>>> simple
>>>>>>>> way to get a plot like what you described. It will probably take
>>>>>>>> more
>>>>>>>> work to find what you actually do want and discover how to get it.
>>>>>>>>
>>>>>>>> for(i in 1:38)
>>>>>>>> assign(paste0("veh",i),rep(sample(10:35,1),10)+runif(10,-4,4))
>>>>>>>> mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,
>>>>>>>>  veh11,veh12,veh13,veh14,veh15,veh16,veh17,veh18,veh19,veh20,
>>>>>>>>  veh21,veh22,veh23,veh24,veh25,veh26,veh27,veh28,veh29,veh30,
>>>>>>>>  veh31,veh32,veh33,veh34,veh35,veh36,veh37,veh38)
>>>>>>>> pdf("mpg.pdf",width=30,height=12)
>>>>>>>> par(mfrow=c(4,10))
>>>>>>>> for(i in 1:38)
>>>>>>>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>>>>>>>   ylab=names(mpg)[i],main="MPG by distance")
>>>>>>>> dev.off()
>>>>>>>>
>>>>>>>> Jim
>>>>>>>>
>>>>>>>> On Wed, Nov 21, 2018 at 5:19 AM Subhamitra Patra
>>>>>>>> <subhamitra.patra at gmail.com> wrote:
>>>>>>>> >
>>>>>>>> > Dear R users,
>>>>>>>> >
>>>>>>>> > I have one excel file with 5 sheets. The no. of columns vary for
>>>>>>>> each
>>>>>>>> > sheet. The 1st sheet consists of 38 columns. So, I want to plot
>>>>>>>> 38 separate
>>>>>>>> > line charts and arrange them in par(mfrow = c(4, 10)) order.
>>>>>>>> Please suggest
>>>>>>>> > me how to do this. I have tried with the following code by
>>>>>>>> running a loop
>>>>>>>> > inside of a sheet, but it is not working. Further, I want to run
>>>>>>>> loops for
>>>>>>>> > each sheet.
>>>>>>>> >
>>>>>>>> > par(mfrow = c(4, 10))
>>>>>>>> > loop.vector <- 1:38
>>>>>>>> > for (i in loop.vector)
>>>>>>>> > x <- JJ[,i]
>>>>>>>> > library(ggplot2)
>>>>>>>> >   library(cowplot)
>>>>>>>> >   plot.mpg <- ggplot(mpg, aes(x,
>>>>>>>> >                               main = paste ("country", i),
>>>>>>>> >                               xlab = "Scores",
>>>>>>>> >                               xlim = c(1,500)
>>>>>>>> >                               y = colnames[i,], colour =
>>>>>>>> factor(cyl))) +
>>>>>>>> >   geom_line(size=2.5)
>>>>>>>> > save_plot("mpg.png", plot.mpg,
>>>>>>>> >           base_aspect_ratio = 1.3)
>>>>>>>> >
>>>>>>>> > I want to give my X axis name as scores of (1,500) and Y axis as
>>>>>>>> the
>>>>>>>> > particular column names for all graphs.
>>>>>>>> >
>>>>>>>> > Please suggest.
>>>>>>>> >
>>>>>>>> > Thanks in advance.
>>>>>>>> >
>>>>>>>> > --
>>>>>>>> > *Best Regards,*
>>>>>>>> > *Subhamitra Patra*
>>>>>>>> > *Phd. Research Scholar*
>>>>>>>> > *Department of Humanities and Social Sciences*
>>>>>>>> > *Indian Institute of Technology, Kharagpur*
>>>>>>>> > *INDIA*
>>>>>>>> >
>>>>>>>> >
>>>>>>>> >
>>>>>>>> >
>>>>>>>> >
>>>>>>>> >
>>>>>>>> >
>>>>>>>> >
>>>>>>>> > [image: Mailtrack]
>>>>>>>> > <
>>>>>>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>>>>>>> >
>>>>>>>> > Sender
>>>>>>>> > notified by
>>>>>>>> > Mailtrack
>>>>>>>> > <
>>>>>>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>>>>>>> >
>>>>>>>> > 11/20/18,
>>>>>>>> > 11:49:42 PM
>>>>>>>> >
>>>>>>>> >         [[alternative HTML version deleted]]
>>>>>>>> >
>>>>>>>> > ______________________________________________
>>>>>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> > PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> > and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> *Best Regards,*
>>>>>>> *Subhamitra Patra*
>>>>>>> *Phd. Research Scholar*
>>>>>>> *Department of Humanities and Social Sciences*
>>>>>>> *Indian Institute of Technology, Kharagpur*
>>>>>>> *INDIA*
>>>>>>>
>>>>>>
>>>>>
>>>>> --
>>>>> *Best Regards,*
>>>>> *Subhamitra Patra*
>>>>> *Phd. Research Scholar*
>>>>> *Department of Humanities and Social Sciences*
>>>>> *Indian Institute of Technology, Kharagpur*
>>>>> *INDIA*
>>>>>
>>>>
>>>
>>> --
>>> *Best Regards,*
>>> *Subhamitra Patra*
>>> *Phd. Research Scholar*
>>> *Department of Humanities and Social Sciences*
>>> *Indian Institute of Technology, Kharagpur*
>>> *INDIA*
>>>
>>
>
> --
> *Best Regards,*
> *Subhamitra Patra*
> *Phd. Research Scholar*
> *Department of Humanities and Social Sciences*
> *Indian Institute of Technology, Kharagpur*
> *INDIA*
>

	[[alternative HTML version deleted]]


From @ubh@mitr@@p@tr@ @ending from gm@il@com  Wed Nov 21 09:27:13 2018
From: @ubh@mitr@@p@tr@ @ending from gm@il@com (Subhamitra Patra)
Date: Wed, 21 Nov 2018 13:57:13 +0530
Subject: [R] 
 [R studio] Plotting of line chart for each columns at 1 page
In-Reply-To: <CA+8X3fVYFJ9GUzY5ujH38zEQhWKKrkUpRzf1UjC-Cc=GHMe0VA@mail.gmail.com>
References: <CAOFE=kOWXrnRnUVtL7A0vLKjL03571WQy5W_865hTFeBz28+tA@mail.gmail.com>
 <CA+8X3fW3Op8icpvA68O2sYPpBi=rpO2DWVXwL5UrPOHtDqDzpw@mail.gmail.com>
 <CAOFE=kNV6P4jRtrYS9K1E76pn+tW_aVpQ4Kq25ZHtQ6v-m=TkQ@mail.gmail.com>
 <CA+8X3fXM9KEb8=U1y-E_DFy9UuXk7NXDyRo6VppnEEAbAtGDDQ@mail.gmail.com>
 <CAOFE=kO20RsVsvVL2ZXpsH51aw9bzgCc3tDJ7DX8fM-tgkkbdQ@mail.gmail.com>
 <CA+8X3fUh8bug_m8iGBGcdPdb=PeGXY0xG48NTwBHC2XzXrtyhg@mail.gmail.com>
 <CAOFE=kNda7BE7cnkUg3nTZNAZbG0-dq=ir2ddXy_1pRMwySpcg@mail.gmail.com>
 <CA+8X3fVsMos2cafXXk7seO=fpM+JFgufmQpcUhGqJ9nNm4BFmQ@mail.gmail.com>
 <CAOFE=kOiTHOzcQ+dL2Tak2WnGBx1JAXpryj5CbLefdofa-7x5Q@mail.gmail.com>
 <CA+8X3fVYFJ9GUzY5ujH38zEQhWKKrkUpRzf1UjC-Cc=GHMe0VA@mail.gmail.com>
Message-ID: <CAOFE=kOBPM-6bdaQKC3NXTXuAn_9OOA8oEvOGKhrGdUxBUAVkw@mail.gmail.com>

 Sir, in the bold portion of the below code, I have some confusion which I
am mentioning below that

"ylab="MPG",main=names(MPG3)[i],*xaxt="n"*)
 axis(*1*,at=1:nrows,*labels=MPG3$Year*)"

1. Here, what *xaxt="n"* indicates? I think it indicates the no. of rows,
right?
2. 1 in the 2nd line represents the no. of graphs. Let suppose, 38
plots are having the same row, I need to mention them as *axis(38,
at=1:nrows)*, right?
3. *labels=**MPG3$Year *will give the name of all years in the X-axis,
right?

Kindly correct me if I am wrong.

Sir, here one thing I would like to ask, my data frequency is not yearly. I
obtained results from the daily data of the period from 1994-2017 (that
means the no. of rows will be 5655). But, as the daily period is very
unclear to mention in the X-axis, I wanted to give year name as the name of
the X-axis (that means, 1995, 1997, 1999 with the increment of 2 years up
to 2017).

Sir, please suggest me how to proceed with this?

Thank you very much for your kind help.


[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
11/21/18,
1:46:50 PM

On Wed, Nov 21, 2018 at 1:21 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Now we're getting somewhere. I suspect that each Excel sheet looks
> something like this:
>
> Year    Tonga    Samoa    Fiji
> 2008    21.2      32.0       18.7
> ...
> 2017    23.7      31.9       19.3
> # in the above there are three columns (countries) and ten rows
> # import this sheet as "MPG3"
> nrows<-nrow(MPG3) # nrows equals 10
> ncols<-ncol(MPG3)  # ncols equals 3
> for(i in 1:ncols)
>  plot(seq(1:nrows,MPG3[,i],type="l",xlab="Distance",
>   ylab="MPG",main=names(MPG3)[i],xaxt="n")
>  axis(1,at=1:nrows,labels=MPG3$Year)
>
> I probably have the structure of the imported data frame wrong, but I
> think you can work that out.
>
> Jim
>
>
>
> On Wed, Nov 21, 2018 at 4:08 PM Subhamitra Patra <
> subhamitra.patra at gmail.com> wrote:
>
>> As per your suggestion, *"you will need to adjust the number of "x"
>> values to match the number of "y" values.  Now with the addition of the
>> nrow function, the code for each sheet will be*
>>
>>
>> *ncolumns<-ncol(mpg)*
>> *   nrows<-nrow(mpg) *
>>
>>
>> *for(i in
>> 1:ncolumns) plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>> ylab="MPG",main=names(mpg)[i])  *
>>
>> #####The no. of rows for the columns in one sheet will be the same. In
>> the X-axis, I need to mention Year which is the same for all columns in a
>> sheet. But, the starting year varies from one sheet to other.
>>
>> *Sir, please suggest in case of any mistakes.*
>>
>> Second, I will definitely consider your suggestions about the division of
>> sample by similar characteristics so that it can be easier to show in
>> graphical. Thank you very much, sir, for such creative and wonderful
>> suggestions.
>>
>>
>>
>> [image: Mailtrack]
>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
>> notified by
>> Mailtrack
>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
>> 10:35:03 AM
>>
>> On Wed, Nov 21, 2018 at 9:40 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>>> For your first question, yes, you will need to adjust the number of "x"
>>> values to match the number of "y" values. You can use the "nrow" function
>>> to get that number. I don't really know what the abscissa scale is on your
>>> plots, I just made up the data I used.
>>>
>>> If you are comparing countries, you may want to divide the results into
>>> countries of different characteristics, perhaps GDP or similar. Otherwise
>>> you will end up with a quite large PDF page. This is okay if you are
>>> viewing it electronically, but will present a challenge in hard copy.
>>>
>>> Jim
>>>
>>> On Wed, Nov 21, 2018 at 2:51 PM Subhamitra Patra <
>>> subhamitra.patra at gmail.com> wrote:
>>>
>>>> Hello Sir,
>>>>
>>>> Thank you very much. I will try it out and will let you the result.
>>>>
>>>> The no. of rows varies per sheet by a different number of observations.
>>>> Due to different no. of rows or observations, I separated the columns in
>>>> different sheets.
>>>>
>>>> *Will a different number of rows create a problem for appending all
>>>> plots?*
>>>>
>>>> Concerning your last suggestion "*This seems like a lot of plots, and
>>>> I suspect that you could work out a better way to display all this
>>>> information.*",  I am doing a multi-country study and obtained results
>>>> for each country. I would summarize the final result at the end. But, for
>>>> displaying the information for each country, I thought the plot is the best
>>>> way to give a supplementary result on each country. Sir, in this context, I
>>>> would like to take your suggestion that Is the way what I am doing, right
>>>> to proceed? If any alternative way is available, please suggest me.
>>>>
>>>> Thank you very much, Sir, for your kind help and suggestions.
>>>>
>>>> [image: Mailtrack]
>>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
>>>> notified by
>>>> Mailtrack
>>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
>>>> 9:12:14 AM
>>>>
>>>> On Wed, Nov 21, 2018 at 8:18 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>>>>
>>>>> I assume that you are importing the Excel sheets separately. When you
>>>>> import a sheet, you can get the number of columns with this:
>>>>>
>>>>> ncol(<name of data frame>)
>>>>>
>>>>> Using the data frame "mpg" that I created:
>>>>>
>>>>> ncolumns<-ncol(mpg)
>>>>> ncolumns
>>>>> [1] 38
>>>>>
>>>>> You can then substitute "ncolumns" each time you import another sheet.
>>>>> How you want to deal with the varying numbers of columns you will get is
>>>>> another matter. One way is to work out the total number of plots you want
>>>>> and put them all onto one PDF page. Say you have 50 plots overall. You
>>>>> could start a very big PDF page:
>>>>>
>>>>> pdf("allplots.pdf",width=30,height=15)
>>>>> par(mfrow=c(5,10))
>>>>> # import your first sheet here (38 columns)
>>>>> ncolumns<-ncol(mpg)
>>>>> for(i in 1:ncolumns)
>>>>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>>>>   ylab="MPG",main=names(mpg)[i])# import your second sheet here, say
>>>>> 10 columns
>>>>> # import your second sheet here, (10 columns)
>>>>> ncolumns<-ncol(mpg1)
>>>>> for(i in 1:ncolumns)
>>>>>  plot(seq(1,500,length.out=10),mpg1[,i],type="l",xlab="Distance",
>>>>>   ylab="MPG",main=names(mpg)[i])# import your third sheet here, say 2
>>>>> columns
>>>>> # import your second sheet here, (2 columns)
>>>>> ncolumns<-ncol(mpg2)
>>>>> for(i in 1:ncolumns)
>>>>>  plot(seq(1,500,length.out=10),mpg2[,i],type="l",xlab="Distance",
>>>>>   ylab="MPG",main=names(mpg)[i])
>>>>> # finish plotting
>>>>> dev.off()
>>>>>
>>>>> You would then have 50 plots on the PDF page. I am assuming that all
>>>>> of your sheets have the same number of rows and a few other things. This
>>>>> seems like a lot of plots, and I suspect that you could work out a better
>>>>> way to display all this information.
>>>>>
>>>>> Jim
>>>>>
>>>>>
>>>>> On Wed, Nov 21, 2018 at 1:20 PM Subhamitra Patra <
>>>>> subhamitra.patra at gmail.com> wrote:
>>>>>
>>>>>> Hello Sir,
>>>>>>
>>>>>> Thanks, now I understood and will check them out.
>>>>>>
>>>>>> One more thing I want to ask that I have 1 excel file with multiple
>>>>>> (i.e. 12 sheets). Each sheet contains different number of columns, for
>>>>>> instance, 1st sheet contains 38 columns, 2nd sheet contains 10 columns,
>>>>>> Third 2 columns, 4th 1 column and so on. Actually, due to some missing
>>>>>> observations in these columns, I couldn't add them in 1 sheet.
>>>>>>
>>>>>> As you suggested the below code in the last mail,
>>>>>>
>>>>>> par(mfrow=c(4,10))
>>>>>> for(i in 1:38)
>>>>>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>>>>>   ylab="MPG",main=names(mpg)[i])
>>>>>> dev.off()
>>>>>>
>>>>>> Do I need to run the code separately for each sheet?
>>>>>>
>>>>>> Actually, in par (mfrow=c(4,10)), the plot for 38 columns will be
>>>>>> added, the space for extra 2 will remain as empty. So, I thought to add
>>>>>> plots for the columns from the next sheet in those emptied space.
>>>>>>
>>>>>> Is there any way that I can add plots from the next sheets of the
>>>>>> same excel file in the emptied space? In other words, Is there any way to
>>>>>> append plots from all sheets?
>>>>>>
>>>>>> Kindly help a new R learner Sir for which I shall be always grateful
>>>>>> to you.
>>>>>>
>>>>>> Thank you very much for your kind help.
>>>>>>
>>>>>>
>>>>>>
>>>>>> [image: Mailtrack]
>>>>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
>>>>>> notified by
>>>>>> Mailtrack
>>>>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
>>>>>> 7:30:30 AM
>>>>>>
>>>>>> On Wed, Nov 21, 2018 at 7:17 AM Jim Lemon <drjimlemon at gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>>> Hi Subhamitra,
>>>>>>>
>>>>>>> 1. Here I manufacture some data so that the example is
>>>>>>> "reproducible", that is anyone can run the code and get the same output
>>>>>>> that I do. Yes, veh1...veh38 are the names of the variables.
>>>>>>>
>>>>>>> 2. Here I join the 38 variables I created into a data frame, which I
>>>>>>> think is the input for your plotting routine. This names of the columns of
>>>>>>> the data frame become the names of the variables.
>>>>>>>
>>>>>>> When you say that you want the column names as the "header" (title)
>>>>>>> of each plot, I think if you change the plotting loop to this:
>>>>>>>
>>>>>>> pdf("mpg.pdf",width=30,height=12)
>>>>>>> par(mfrow=c(4,10))
>>>>>>> for(i in 1:38)
>>>>>>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>>>>>>   ylab="MPG",main=names(mpg)[i])
>>>>>>> dev.off()
>>>>>>>
>>>>>>> you will get what you requested. Remember that I have done this in
>>>>>>> base graphics, not ggplot.
>>>>>>>
>>>>>>> Jim
>>>>>>>
>>>>>>> On Wed, Nov 21, 2018 at 12:37 PM Subhamitra Patra <
>>>>>>> subhamitra.patra at gmail.com> wrote:
>>>>>>>
>>>>>>>> Hello Sir,
>>>>>>>>
>>>>>>>> Thanks, I'll check them out.
>>>>>>>>
>>>>>>>> But, I am not understanding 2 points of your suggestion.
>>>>>>>>
>>>>>>>> 1. In the line,* "*for(i in 1:38) assign(paste0("veh",i),rep(sam
>>>>>>>> ple(10:35,1),10)+runif(10,-4,*4))", *what veh, rep(sam
>>>>>>>> ple(10:35,1),10)+runif(10,-4,4)) indicate? Here veh indicates
>>>>>>>> columns right?
>>>>>>>> *2. In the
>>>>>>>> line, mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,*
>>>>>>>> * veh11,veh12,veh13,veh14,**veh15,veh16,veh17,veh18,veh19,**veh20,*
>>>>>>>> * veh21,veh22,veh23,veh24,**veh25,veh26,veh27,veh28,veh29,**veh30,*
>>>>>>>> * veh31,veh32,veh33,veh34,**veh35,veh36,veh37,veh38)  ** , *veh[i]
>>>>>>>> indicates column sequence, right? I need to give column names as the header
>>>>>>>> of their respective graphs. Please suggest me How to add this?
>>>>>>>>
>>>>>>>>
>>>>>>>> I am very new to R and therefore asking you these queries which
>>>>>>>> might be simple for you.
>>>>>>>>
>>>>>>>> I expect positive help from you.
>>>>>>>>
>>>>>>>> Thanks for your kind help.
>>>>>>>> [image: Mailtrack]
>>>>>>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
>>>>>>>> notified by
>>>>>>>> Mailtrack
>>>>>>>> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 11/21/18,
>>>>>>>> 7:02:18 AM
>>>>>>>>
>>>>>>>>
>>>>>>>> On Wed, Nov 21, 2018 at 4:38 AM Jim Lemon <drjimlemon at gmail.com>
>>>>>>>> wrote:
>>>>>>>>
>>>>>>>>> Hi Subhamitra,
>>>>>>>>> As Bert noted, you are mixing base and grid graphics. Here is a
>>>>>>>>> simple
>>>>>>>>> way to get a plot like what you described. It will probably take
>>>>>>>>> more
>>>>>>>>> work to find what you actually do want and discover how to get it.
>>>>>>>>>
>>>>>>>>> for(i in 1:38)
>>>>>>>>> assign(paste0("veh",i),rep(sample(10:35,1),10)+runif(10,-4,4))
>>>>>>>>> mpg<-data.frame(veh1,veh2,veh3,veh4,veh5,veh6,veh7,veh8,veh9,veh10,
>>>>>>>>>  veh11,veh12,veh13,veh14,veh15,veh16,veh17,veh18,veh19,veh20,
>>>>>>>>>  veh21,veh22,veh23,veh24,veh25,veh26,veh27,veh28,veh29,veh30,
>>>>>>>>>  veh31,veh32,veh33,veh34,veh35,veh36,veh37,veh38)
>>>>>>>>> pdf("mpg.pdf",width=30,height=12)
>>>>>>>>> par(mfrow=c(4,10))
>>>>>>>>> for(i in 1:38)
>>>>>>>>>  plot(seq(1,500,length.out=10),mpg[,i],type="l",xlab="Distance",
>>>>>>>>>   ylab=names(mpg)[i],main="MPG by distance")
>>>>>>>>> dev.off()
>>>>>>>>>
>>>>>>>>> Jim
>>>>>>>>>
>>>>>>>>> On Wed, Nov 21, 2018 at 5:19 AM Subhamitra Patra
>>>>>>>>> <subhamitra.patra at gmail.com> wrote:
>>>>>>>>> >
>>>>>>>>> > Dear R users,
>>>>>>>>> >
>>>>>>>>> > I have one excel file with 5 sheets. The no. of columns vary for
>>>>>>>>> each
>>>>>>>>> > sheet. The 1st sheet consists of 38 columns. So, I want to plot
>>>>>>>>> 38 separate
>>>>>>>>> > line charts and arrange them in par(mfrow = c(4, 10)) order.
>>>>>>>>> Please suggest
>>>>>>>>> > me how to do this. I have tried with the following code by
>>>>>>>>> running a loop
>>>>>>>>> > inside of a sheet, but it is not working. Further, I want to run
>>>>>>>>> loops for
>>>>>>>>> > each sheet.
>>>>>>>>> >
>>>>>>>>> > par(mfrow = c(4, 10))
>>>>>>>>> > loop.vector <- 1:38
>>>>>>>>> > for (i in loop.vector)
>>>>>>>>> > x <- JJ[,i]
>>>>>>>>> > library(ggplot2)
>>>>>>>>> >   library(cowplot)
>>>>>>>>> >   plot.mpg <- ggplot(mpg, aes(x,
>>>>>>>>> >                               main = paste ("country", i),
>>>>>>>>> >                               xlab = "Scores",
>>>>>>>>> >                               xlim = c(1,500)
>>>>>>>>> >                               y = colnames[i,], colour =
>>>>>>>>> factor(cyl))) +
>>>>>>>>> >   geom_line(size=2.5)
>>>>>>>>> > save_plot("mpg.png", plot.mpg,
>>>>>>>>> >           base_aspect_ratio = 1.3)
>>>>>>>>> >
>>>>>>>>> > I want to give my X axis name as scores of (1,500) and Y axis as
>>>>>>>>> the
>>>>>>>>> > particular column names for all graphs.
>>>>>>>>> >
>>>>>>>>> > Please suggest.
>>>>>>>>> >
>>>>>>>>> > Thanks in advance.
>>>>>>>>> >
>>>>>>>>> > --
>>>>>>>>> > *Best Regards,*
>>>>>>>>> > *Subhamitra Patra*
>>>>>>>>> > *Phd. Research Scholar*
>>>>>>>>> > *Department of Humanities and Social Sciences*
>>>>>>>>> > *Indian Institute of Technology, Kharagpur*
>>>>>>>>> > *INDIA*
>>>>>>>>> >
>>>>>>>>> >
>>>>>>>>> >
>>>>>>>>> >
>>>>>>>>> >
>>>>>>>>> >
>>>>>>>>> >
>>>>>>>>> >
>>>>>>>>> > [image: Mailtrack]
>>>>>>>>> > <
>>>>>>>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>>>>>>>> >
>>>>>>>>> > Sender
>>>>>>>>> > notified by
>>>>>>>>> > Mailtrack
>>>>>>>>> > <
>>>>>>>>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>>>>>>>>> >
>>>>>>>>> > 11/20/18,
>>>>>>>>> > 11:49:42 PM
>>>>>>>>> >
>>>>>>>>> >         [[alternative HTML version deleted]]
>>>>>>>>> >
>>>>>>>>> > ______________________________________________
>>>>>>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>>>>>>> see
>>>>>>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> > PLEASE do read the posting guide
>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>> > and provide commented, minimal, self-contained, reproducible
>>>>>>>>> code.
>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> --
>>>>>>>> *Best Regards,*
>>>>>>>> *Subhamitra Patra*
>>>>>>>> *Phd. Research Scholar*
>>>>>>>> *Department of Humanities and Social Sciences*
>>>>>>>> *Indian Institute of Technology, Kharagpur*
>>>>>>>> *INDIA*
>>>>>>>>
>>>>>>>
>>>>>>
>>>>>> --
>>>>>> *Best Regards,*
>>>>>> *Subhamitra Patra*
>>>>>> *Phd. Research Scholar*
>>>>>> *Department of Humanities and Social Sciences*
>>>>>> *Indian Institute of Technology, Kharagpur*
>>>>>> *INDIA*
>>>>>>
>>>>>
>>>>
>>>> --
>>>> *Best Regards,*
>>>> *Subhamitra Patra*
>>>> *Phd. Research Scholar*
>>>> *Department of Humanities and Social Sciences*
>>>> *Indian Institute of Technology, Kharagpur*
>>>> *INDIA*
>>>>
>>>
>>
>> --
>> *Best Regards,*
>> *Subhamitra Patra*
>> *Phd. Research Scholar*
>> *Department of Humanities and Social Sciences*
>> *Indian Institute of Technology, Kharagpur*
>> *INDIA*
>>
>

-- 
*Best Regards,*
*Subhamitra Patra*
*Phd. Research Scholar*
*Department of Humanities and Social Sciences*
*Indian Institute of Technology, Kharagpur*
*INDIA*

	[[alternative HTML version deleted]]


From pd@lgd @ending from gm@il@com  Wed Nov 21 09:33:46 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Wed, 21 Nov 2018 09:33:46 +0100
Subject: [R] system solver in R
In-Reply-To: <CAMUSX8ptu+b=SFZAA+FQw4aPfu5eqzgWTVHkCuRm92Xj9srqcA@mail.gmail.com>
References: <CAMUSX8rwvVkitcFe6MmRpE+bJVTaoVHL4Ank+Jd52oyaRqP=Xg@mail.gmail.com>
 <3577E651-4A38-4F2C-835A-BA9B9177905B@xs4all.nl>
 <CAMUSX8r5c=PemFaD1Ew5Q-2czvbPgk7kEj7vocqZV76POFvksQ@mail.gmail.com>
 <CAMUSX8ptu+b=SFZAA+FQw4aPfu5eqzgWTVHkCuRm92Xj9srqcA@mail.gmail.com>
Message-ID: <76740B88-D052-4DF7-B367-423CC4DB44D0@gmail.com>

Once you figure out how to decipher the output, you realise that it actually does give you all 4 roots, including the two real ones:

...
> a <- .Last.value
> complex_cartesian <- function(x,y) x+(0+1i)*y
> eval(a$text[[1]][[2]][[3]])
[1] -1.00028+0.988174i
> eval(a$text[[1]][[3]][[3]])
[1] -1.00028-0.988174i
> eval(a$text[[1]][[4]][[3]])
[1] 0.03634399
> eval(a$text[[1]][[5]][[3]])
[1] -1.988165

(No, I don't quite know what I am doing either...)

-pd


> On 20 Nov 2018, at 13:09 , Engin Y?lmaz <ispanyolcom at gmail.com> wrote:
> 
> Dea(R)
> I try to solve one equation but this program did not give me real roots
> for example
> yacas("Solve( 5/((1+x)^1) + 5/((1+x)^2) + 5/((1+x)^3) + 105/((1+x)^4) -105
> ==0, x)")
> gave me following results
> How can I find real roots?
> 
> expression(list(x == complex_cartesian((1/42 - ((1/63 -
> ((root(7339451281/3087580356,
>    2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>    2))^(1/3)))/21 - -2/21)/(4 * root(((root(7339451281/3087580356,
>    2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>    2))^(1/3) - 1/63)^2/4 + 1, 2)))/2 - 1, root(4 *
> (((root(7339451281/3087580356,
>    2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>    2))^(1/3) - 1/63)/2 + root(((root(7339451281/3087580356,
>    2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>    2))^(1/3) - 1/63)^2/4 + 1, 2)) - (((1/63 -
> ((root(7339451281/3087580356,
>    2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>    2))^(1/3)))/21 - -2/21)/(4 * root(((root(7339451281/3087580356,
>    2) - 4535/71442)^(1/3) - (4535/71442 + root(7339451281/3087580356,
>    2))^(1/3) - 1/63)^2/4 + 1, 2)) - 1/42)^2, 2)/2),...more
> 
> 
> 
> 
> Engin Y?lmaz <ispanyolcom at gmail.com>, 20 Kas 2018 Sal, 12:53 tarihinde ?unu
> yazd?:
> 
>> Thanks a lot!
>> 
>> Berend Hasselman <bhh at xs4all.nl>, 20 Kas 2018 Sal, 12:02 tarihinde ?unu
>> yazd?:
>> 
>>> 
>>> 
>>> R package Ryacas may be what you want.
>>> 
>>> Berend
>>> 
>>> 
>>>> On 20 Nov 2018, at 09:42, Engin Y?lmaz <ispanyolcom at gmail.com> wrote:
>>>> 
>>>> Dea(R)
>>>> 
>>>> Do you know any system solver in R ?
>>>> 
>>>> For example, in matlab, is very easy
>>>> 
>>>> syms a b c x eqn = a*x^2 + b*x + c == 0; sol = solve(eqn)
>>>> 
>>>> How can I  find this type code in R (or directly solver)?
>>>> 
>>>> *Since(R)ely*
>>>> Engin YILMAZ
>>>> 
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>> 
>> --
>> *Sayg?lar?mla*
>> Engin YILMAZ
>> 
> 
> 
> -- 
> *Sayg?lar?mla*
> Engin YILMAZ
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From drjimlemon @ending from gm@il@com  Wed Nov 21 10:11:08 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Wed, 21 Nov 2018 20:11:08 +1100
Subject: [R] 
 [R studio] Plotting of line chart for each columns at 1 page
In-Reply-To: <CAOFE=kOBPM-6bdaQKC3NXTXuAn_9OOA8oEvOGKhrGdUxBUAVkw@mail.gmail.com>
References: <CAOFE=kOWXrnRnUVtL7A0vLKjL03571WQy5W_865hTFeBz28+tA@mail.gmail.com>
 <CA+8X3fW3Op8icpvA68O2sYPpBi=rpO2DWVXwL5UrPOHtDqDzpw@mail.gmail.com>
 <CAOFE=kNV6P4jRtrYS9K1E76pn+tW_aVpQ4Kq25ZHtQ6v-m=TkQ@mail.gmail.com>
 <CA+8X3fXM9KEb8=U1y-E_DFy9UuXk7NXDyRo6VppnEEAbAtGDDQ@mail.gmail.com>
 <CAOFE=kO20RsVsvVL2ZXpsH51aw9bzgCc3tDJ7DX8fM-tgkkbdQ@mail.gmail.com>
 <CA+8X3fUh8bug_m8iGBGcdPdb=PeGXY0xG48NTwBHC2XzXrtyhg@mail.gmail.com>
 <CAOFE=kNda7BE7cnkUg3nTZNAZbG0-dq=ir2ddXy_1pRMwySpcg@mail.gmail.com>
 <CA+8X3fVsMos2cafXXk7seO=fpM+JFgufmQpcUhGqJ9nNm4BFmQ@mail.gmail.com>
 <CAOFE=kOiTHOzcQ+dL2Tak2WnGBx1JAXpryj5CbLefdofa-7x5Q@mail.gmail.com>
 <CA+8X3fVYFJ9GUzY5ujH38zEQhWKKrkUpRzf1UjC-Cc=GHMe0VA@mail.gmail.com>
 <CAOFE=kOBPM-6bdaQKC3NXTXuAn_9OOA8oEvOGKhrGdUxBUAVkw@mail.gmail.com>
Message-ID: <CA+8X3fUSY13o=khzBy9RA1_qsP1vkVqNAm=UP-xAd_cyLNrAVw@mail.gmail.com>

1. xaxt="n" means "Don't display the X axis". See the help for "par" in the
graphics package

2. axis(1,at=1:nrows,labels=names(MPG3))
This means, "Display the bottom axis (1) with ticks at 1 to the number of
rows in the data frame"
"Use the values of MPG$Year as labels for the ticks". see the help for
"axis" in the graphics package
Note that this should be in the same loop as "plot"

Now I can see that my guess at the structure of the data was wrong. What
you could do is to collapse the daily records into the means for the years.
As I don't know what your spreadsheet looks like, I could only guess a
method for this.

You seem to be saying that you plot all 5655 values, but you want the axis
to show just the years.Rather than tell you to convert your data to a time
series, I'll suggest a quick hack.

axis(1,at=seq(1,5655,by=365),labels=1994:2014)

This _may_ work for you. I offer it because I can see that you do not have
a lot of experience in R and you want to get the job done. If you can't get
it to work, I apologize and you can blamelessly move to something else.

Jim

PS - If you don't know how to start HTML help - help.start()

On Wed, Nov 21, 2018 at 7:26 PM Subhamitra Patra <subhamitra.patra at gmail.com>
wrote:

>  Sir, in the bold portion of the below code, I have some confusion which I
> am mentioning below that
>
> "ylab="MPG",main=names(MPG3)[i],*xaxt="n"*)
>  axis(*1*,at=1:nrows,*labels=MPG3$Year*)"
>
> 1. Here, what *xaxt="n"* indicates? I think it indicates the no. of rows,
> right?
> 2. 1 in the 2nd line represents the no. of graphs. Let suppose, 38
> plots are having the same row, I need to mention them as *axis(38,
> at=1:nrows)*, right?
> 3. *labels=**MPG3$Year *will give the name of all years in the X-axis,
> right?
>
> Kindly correct me if I am wrong.
>
> Sir, here one thing I would like to ask, my data frequency is not yearly.
> I obtained results from the daily data of the period from 1994-2017 (that
> means the no. of rows will be 5655). But, as the daily period is very
> unclear to mention in the X-axis, I wanted to give year name as the name of
> the X-axis (that means, 1995, 1997, 1999 with the increment of 2 years up
> to 2017).
>
> Sir, please suggest me how to proceed with this?
>
>

	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Wed Nov 21 10:22:20 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Wed, 21 Nov 2018 09:22:20 +0000
Subject: [R] Use of C functions inside the DLL object
In-Reply-To: <65df203a-faa2-e1bd-8c43-4110cf857636@yahoo.com.br>
References: <65df203a-faa2-e1bd-8c43-4110cf857636@yahoo.com.br>
Message-ID: <d7ed3dce-35bc-475d-06c7-8418caf96f4d@sapo.pt>

Hello,

You must pass a string with a number of characters large enough to 
accomodate the return value you want. This is one of the shortcomings of 
the .C interface.

The string ?2.0.19? ahs 6 characters, so try

.C("FDwfGetVersion", version = character(6) )


Hope this helps,

Rui Barradas

?s 20:57 de 19/11/2018, Cleber N.Borges via R-help escreveu:
> .C("FDwfGetVersion", version=as.character() )


From @ubh@mitr@@p@tr@ @ending from gm@il@com  Wed Nov 21 10:39:33 2018
From: @ubh@mitr@@p@tr@ @ending from gm@il@com (Subhamitra Patra)
Date: Wed, 21 Nov 2018 15:09:33 +0530
Subject: [R] 
 [R studio] Plotting of line chart for each columns at 1 page
In-Reply-To: <CA+8X3fUSY13o=khzBy9RA1_qsP1vkVqNAm=UP-xAd_cyLNrAVw@mail.gmail.com>
References: <CAOFE=kOWXrnRnUVtL7A0vLKjL03571WQy5W_865hTFeBz28+tA@mail.gmail.com>
 <CA+8X3fW3Op8icpvA68O2sYPpBi=rpO2DWVXwL5UrPOHtDqDzpw@mail.gmail.com>
 <CAOFE=kNV6P4jRtrYS9K1E76pn+tW_aVpQ4Kq25ZHtQ6v-m=TkQ@mail.gmail.com>
 <CA+8X3fXM9KEb8=U1y-E_DFy9UuXk7NXDyRo6VppnEEAbAtGDDQ@mail.gmail.com>
 <CAOFE=kO20RsVsvVL2ZXpsH51aw9bzgCc3tDJ7DX8fM-tgkkbdQ@mail.gmail.com>
 <CA+8X3fUh8bug_m8iGBGcdPdb=PeGXY0xG48NTwBHC2XzXrtyhg@mail.gmail.com>
 <CAOFE=kNda7BE7cnkUg3nTZNAZbG0-dq=ir2ddXy_1pRMwySpcg@mail.gmail.com>
 <CA+8X3fVsMos2cafXXk7seO=fpM+JFgufmQpcUhGqJ9nNm4BFmQ@mail.gmail.com>
 <CAOFE=kOiTHOzcQ+dL2Tak2WnGBx1JAXpryj5CbLefdofa-7x5Q@mail.gmail.com>
 <CA+8X3fVYFJ9GUzY5ujH38zEQhWKKrkUpRzf1UjC-Cc=GHMe0VA@mail.gmail.com>
 <CAOFE=kOBPM-6bdaQKC3NXTXuAn_9OOA8oEvOGKhrGdUxBUAVkw@mail.gmail.com>
 <CA+8X3fUSY13o=khzBy9RA1_qsP1vkVqNAm=UP-xAd_cyLNrAVw@mail.gmail.com>
Message-ID: <CAOFE=kPwv6LspZ=4RvL9x2JE7YSE9Ad+4Rrdhpmj0hyEHmVhxA@mail.gmail.com>

OK, Sir.  I will try as per your suggestions.

Thank you very much for your kind help.

[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
11/21/18,
3:07:47 PM

On Wed, Nov 21, 2018 at 2:41 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> 1. xaxt="n" means "Don't display the X axis". See the help for "par" in
> the graphics package
>
> 2. axis(1,at=1:nrows,labels=names(MPG3))
> This means, "Display the bottom axis (1) with ticks at 1 to the number of
> rows in the data frame"
> "Use the values of MPG$Year as labels for the ticks". see the help for
> "axis" in the graphics package
> Note that this should be in the same loop as "plot"
>
> Now I can see that my guess at the structure of the data was wrong. What
> you could do is to collapse the daily records into the means for the years.
> As I don't know what your spreadsheet looks like, I could only guess a
> method for this.
>
> You seem to be saying that you plot all 5655 values, but you want the axis
> to show just the years.Rather than tell you to convert your data to a time
> series, I'll suggest a quick hack.
>
> axis(1,at=seq(1,5655,by=365),labels=1994:2014)
>
> This _may_ work for you. I offer it because I can see that you do not have
> a lot of experience in R and you want to get the job done. If you can't get
> it to work, I apologize and you can blamelessly move to something else.
>
> Jim
>
> PS - If you don't know how to start HTML help - help.start()
>
> On Wed, Nov 21, 2018 at 7:26 PM Subhamitra Patra <
> subhamitra.patra at gmail.com> wrote:
>
>>  Sir, in the bold portion of the below code, I have some confusion which
>> I am mentioning below that
>>
>> "ylab="MPG",main=names(MPG3)[i],*xaxt="n"*)
>>  axis(*1*,at=1:nrows,*labels=MPG3$Year*)"
>>
>> 1. Here, what *xaxt="n"* indicates? I think it indicates the no. of
>> rows, right?
>> 2. 1 in the 2nd line represents the no. of graphs. Let suppose, 38
>> plots are having the same row, I need to mention them as *axis(38,
>> at=1:nrows)*, right?
>> 3. *labels=**MPG3$Year *will give the name of all years in the X-axis,
>> right?
>>
>> Kindly correct me if I am wrong.
>>
>> Sir, here one thing I would like to ask, my data frequency is not yearly.
>> I obtained results from the daily data of the period from 1994-2017 (that
>> means the no. of rows will be 5655). But, as the daily period is very
>> unclear to mention in the X-axis, I wanted to give year name as the name of
>> the X-axis (that means, 1995, 1997, 1999 with the increment of 2 years up
>> to 2017).
>>
>> Sir, please suggest me how to proceed with this?
>>
>>

-- 
*Best Regards,*
*Subhamitra Patra*
*Phd. Research Scholar*
*Department of Humanities and Social Sciences*
*Indian Institute of Technology, Kharagpur*
*INDIA*

	[[alternative HTML version deleted]]


From g@briel@hoffm@n @ending from m@@m@edu  Wed Nov 21 19:34:33 2018
From: g@briel@hoffm@n @ending from m@@m@edu (Hoffman, Gabriel)
Date: Wed, 21 Nov 2018 18:34:33 +0000
Subject: [R] Speed of RCppEigen Cholesky decomposition on sparse matrix
Message-ID: <D81B0F66.314E1%gabriel.hoffman@mssm.edu>

I am developing a statistical model and I have a prototype working in R code.  I make extensive use of sparse matrices, so the R code is pretty fast, but hoped that using RCppEigen to evaluate the log-likelihood function could avoid a lot of memory copying and be substantially faster.  However, in a simple  example I am seeing that RCppEigen is 3-5x slower than standard R code for cholesky decomposition of a sparse matrix.  This is the case on R 3.5.1 using RcppEigen_0.3.3.4.0 on both OS X and CentOS 6.9.

Since this simple operation is so much slower it doesn?t seem like using RCppEigen is worth it in this case.  Is this an issue with BLAS, some libraries or compiler options, or is R code really the fastest option?

Here is my example:

library(Matrix)
library(inline)

# construct sparse matrix
#########################

# construct a matrix C that is N x X with S total entries
N = 10000
S = 1000000
i = sample(1:1000, S, replace=TRUE)
j = sample(1:1000, S, replace=TRUE)
idx = i >= j
values = runif(S, 0, .3)
X = sparseMatrix(i=i, j=j, x = values, symmetric=FALSE )

C = as(crossprod(X), "dgCMatrix")

# check sparsity fraction
S / N^2

# define RCppEigen code
CholeskyCppSparse<-'
using Rcpp::as;
using Eigen::Map;
using Eigen::SparseMatrix;
using Eigen::MappedSparseMatrix;
using Eigen::SimplicialLLT;

// get data into RcppEigen
const MappedSparseMatrix<double> Sigma(as<MappedSparseMatrix<double> >(Sigma_in));

// compute Cholesky
typedef SimplicialLLT<SparseMatrix<double> > SpChol;
const SpChol Ch(Sigma);
'

CholSparse <- cxxfunction(signature(Sigma_in = "dgCMatrix"), CholeskyCppSparse, plugin = "RcppEigen")

# compare times
system.time(replicate(10, chol( C )))
# output:
#   user  system elapsed
#  0.341   0.014   0.355

system.time(replicate(10, CholSparse( C )))
# output:
#   user  system elapsed
# 1.639   0.046   1.687

> sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS  10.14

Matrix products: default
BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base

other attached packages:
[1] inline_0.3.15 Matrix_1.2-15

loaded via a namespace (and not attached):
[1] compiler_3.5.1      RcppEigen_0.3.3.4.0 Rcpp_1.0.0
[4] grid_3.5.1          lattice_0.20-38

Changing the size of the matrix and the number of entries does not change the relative times

Thanks,
- Gabriel




	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Nov 22 00:09:20 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 21 Nov 2018 15:09:20 -0800
Subject: [R] Speed of RCppEigen Cholesky decomposition on sparse matrix
In-Reply-To: <D81B0F66.314E1%gabriel.hoffman@mssm.edu>
References: <D81B0F66.314E1%gabriel.hoffman@mssm.edu>
Message-ID: <3AE288E1-1072-47B6-937C-885968411757@dcn.davis.ca.us>

I believe you have the wrong list. (Read the Posting Guide... you seem to have R under control.)  Try Rcpp-devel.

FWIW You probably need to spend some time with a C++ profiler... any language can be unintentionally mis-used, and you first need to identify whether your calling code is inefficiently handling memory or invoking setup code repetitively before blaming BLAS. A reproducible example will probably help when you ask at Rcpp-devel.

On November 21, 2018 10:34:33 AM PST, "Hoffman, Gabriel" <gabriel.hoffman at mssm.edu> wrote:
>I am developing a statistical model and I have a prototype working in R
>code.  I make extensive use of sparse matrices, so the R code is pretty
>fast, but hoped that using RCppEigen to evaluate the log-likelihood
>function could avoid a lot of memory copying and be substantially
>faster.  However, in a simple  example I am seeing that RCppEigen is
>3-5x slower than standard R code for cholesky decomposition of a sparse
>matrix.  This is the case on R 3.5.1 using RcppEigen_0.3.3.4.0 on both
>OS X and CentOS 6.9.
>
>Since this simple operation is so much slower it doesn?t seem like
>using RCppEigen is worth it in this case.  Is this an issue with BLAS,
>some libraries or compiler options, or is R code really the fastest
>option?
>
>Here is my example:
>
>library(Matrix)
>library(inline)
>
># construct sparse matrix
>#########################
>
># construct a matrix C that is N x X with S total entries
>N = 10000
>S = 1000000
>i = sample(1:1000, S, replace=TRUE)
>j = sample(1:1000, S, replace=TRUE)
>idx = i >= j
>values = runif(S, 0, .3)
>X = sparseMatrix(i=i, j=j, x = values, symmetric=FALSE )
>
>C = as(crossprod(X), "dgCMatrix")
>
># check sparsity fraction
>S / N^2
>
># define RCppEigen code
>CholeskyCppSparse<-'
>using Rcpp::as;
>using Eigen::Map;
>using Eigen::SparseMatrix;
>using Eigen::MappedSparseMatrix;
>using Eigen::SimplicialLLT;
>
>// get data into RcppEigen
>const MappedSparseMatrix<double> Sigma(as<MappedSparseMatrix<double>
>>(Sigma_in));
>
>// compute Cholesky
>typedef SimplicialLLT<SparseMatrix<double> > SpChol;
>const SpChol Ch(Sigma);
>'
>
>CholSparse <- cxxfunction(signature(Sigma_in = "dgCMatrix"),
>CholeskyCppSparse, plugin = "RcppEigen")
>
># compare times
>system.time(replicate(10, chol( C )))
># output:
>#   user  system elapsed
>#  0.341   0.014   0.355
>
>system.time(replicate(10, CholSparse( C )))
># output:
>#   user  system elapsed
># 1.639   0.046   1.687
>
>> sessionInfo()
>R version 3.5.1 (2018-07-02)
>Platform: x86_64-apple-darwin15.6.0 (64-bit)
>Running under: macOS  10.14
>
>Matrix products: default
>BLAS:
>/Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
>LAPACK:
>/Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
>
>locale:
>[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
>attached base packages:
>[1] stats     graphics  grDevices datasets  utils     methods   base
>
>other attached packages:
>[1] inline_0.3.15 Matrix_1.2-15
>
>loaded via a namespace (and not attached):
>[1] compiler_3.5.1      RcppEigen_0.3.3.4.0 Rcpp_1.0.0
>[4] grid_3.5.1          lattice_0.20-38
>
>Changing the size of the matrix and the number of entries does not
>change the relative times
>
>Thanks,
>- Gabriel
>
>
>
>
>	[[alternative HTML version deleted]]

-- 
Sent from my phone. Please excuse my brevity.


From petr@pik@l @ending from prechez@@cz  Thu Nov 22 08:27:15 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Thu, 22 Nov 2018 07:27:15 +0000
Subject: [R] Partial LookUP
In-Reply-To: <VI1PR08MB359975EC70C20D39EFB4FEBCBCD90@VI1PR08MB3599.eurprd08.prod.outlook.com>
References: <VI1PR08MB359975EC70C20D39EFB4FEBCBCD90@VI1PR08MB3599.eurprd08.prod.outlook.com>
Message-ID: <dfac6fd4243a48b188e1a8d49f4a2cc4@SRVEXCHCM1302.precheza.cz>

Hi

I did not see any answer so I try to generate some answer.
It seems to me that your second attempt was quite close.

If passengerid was numeric, following code could probably give you the required result.

res <- rep(NA, nrow(df1))
for (i in 1:NROW(df1)) {
sel <- which(str_detect(df1$Name,coll(df1$HusbandName[i])))
if (length(sel) > 0) { res[i] <- df1$passengerid[sel]}
}

res should contain passengerid for each relevant line and NA if there is no match. You just could add it to your data frame as a new column.

The problem is that although you provide "a kind of" example, HTML format probably scrambled it somehow. Better is to use dput for sending test data and not  use HTML formating.

This is data frame I got from your mail.

> dput(df1)
structure(list(passengerid = structure(c(3L, 4L, 2L, 1L), .Label = c("3302",
"7767", "908", "9883"), class = "factor"), Name = c("Backstrom, Mrs. Karl Alfred (Maria Mathilda Gustafsson)",
"Backstrom, Mr. Karl Alfred John", "Cumings, Mrs. John Bradley (Florence Briggs Thayer)",
"Cumings, Mr. John Bradley"), HusbandName = c("Backstrom, Mr. Karl Alfred",
"", "Cumings, Mr. John\nBradley", "")), row.names = c(NA, -4L
), class = "data.frame")

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of gary chimuzinga
> Sent: Tuesday, November 20, 2018 5:06 PM
> To: r-help at r-project.org
> Subject: [R] Partial LookUP
>
> I am working n R, using R studio,
> I have a dataframe with 4 columns. Column A contains passenger iD, B contains
> passenger name, C contains husband name.
> I am attempting to create a new column which look to see if the husband name
> in column C is listed in any of the records in column B. If so it should then
> return to me the passenger iD of the husband from column A.
> To make things more complicated, as in the first example in some cases, the
> husband's given in column C might not include the his second name, which
> would be included in column B.
>
> Reproducible Example
> library(stringr)
> rm(list=ls())
> passengerid <- c(0908,9883,7767,3302)
>
> Name<- c("Backstrom, Mrs. Karl Alfred (Maria Mathilda Gustafsson)",
>           "Backstrom, Mr. Karl Alfred John",
>           "Cumings, Mrs. John Bradley (Florence Briggs Thayer)",
>           "Cumings, Mr. John Bradley")
>
> HusbandName <- c("Backstrom, Mr. Karl Alfred","","Cumings, Mr. John
> Bradley","")
>
>
>
> df1<- data.frame(cbind(passengerid,Name,HusbandName))
> df1$Name <- as.character(df1$Name)
> df1$HusbandName <- as.character(df1$HusbandName)
>
> I have tried using Stringr, but facing problems because 1)I need the code to look
> at only 1 element of the vector HusbandName and search for it in the whole
> vector Name. 2) I found it difficult to use regular expressions given that the
> pattern I am looking for is vectorised (as HusbandName)
> This is what I have tried so far:
>
> Attempt 1 - only finds exact matches & doesn't return the passengerID &
> doesn't add column to df
> df1$Husbandid < - for (i in 1:NROW(df1$HusbandName)) {
> print(HusbandName[i] %in% Name)}
>
>
> Attempt 2 - finds partial matches, but does not ignore blanks & does not tell
> me passenger id & doesn't add column to df
> df1$Husbandid <- for (i in 1:NROW(df1$HusbandName)) {
> print(which(str_detect(df1$Name,df1$HusbandName[i])))}
>
>
> #Attempt 3 - almost works but - the printed results are different from those
> added into the dataframe as a new column. how can i correct for this?
> Ultimately I need the ones in the df to be correct. the error is that those
> without husbands are showing husbandiD when this should be blank or na. can
> this be corrected or is there a way to convert the output of the for loop into a
> vector we can add to the df?
> for (i in 1:NROW(df1$HusbandName)) {
>      if (df1$HusbandName[i] =="") {
>       print("Man") & next()
>       }
>     FoundHusbandNames<-
> c(which(str_detect(df1$Name,df1$HusbandName[i])))
>     print(df1$passengerid[FoundHusbandNames]) -> df1$Husbandid[i] }
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From ro@reh@chuh @ending from googlem@il@com  Thu Nov 22 10:33:39 2018
From: ro@reh@chuh @ending from googlem@il@com (Romy Rehschuh)
Date: Thu, 22 Nov 2018 10:33:39 +0100
Subject: [R] detecting measurement of specific id in column in R
Message-ID: <CAPYt5uEpt0ZjEZM6SXYFQEo1KJ8umgyVsRdNkjKvgzku8ZPBHw@mail.gmail.com>

Dear all,

I hope this is the right way to ask questions.
I have a problem with R regarding the detection of the measurement of a
specific sample_id (see example file attached). I have to substract the
"IN" values (means the air which goes into the chambers) from the values of
"d13C", "ppm_CO2" and "ppm_13CO2" for every single chamber (=sample ID).
The "IN" values have to be the ones which were measured* before *the
measurements of the single chambers in time. I measured "IN" once and then
up to 10 chambers in a row to safe time, then "IN" again, but it can change.
Therefore, searching for the closest "IN" does not work.

Do you have any suggestions? Would it be possible to write a loop for this?
I would really much appreciate your help!

Best, Vicci

From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Nov 22 17:53:09 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 22 Nov 2018 08:53:09 -0800
Subject: [R] detecting measurement of specific id in column in R
In-Reply-To: <CAPYt5uEpt0ZjEZM6SXYFQEo1KJ8umgyVsRdNkjKvgzku8ZPBHw@mail.gmail.com>
References: <CAPYt5uEpt0ZjEZM6SXYFQEo1KJ8umgyVsRdNkjKvgzku8ZPBHw@mail.gmail.com>
Message-ID: <46966605-884E-4A8F-A2FF-7044CE4E14D4@dcn.davis.ca.us>

You hope... but no... not really. You need to enhance your question with a (minimal) example of the data just after importing into R, and another example of what you think the result should look like. Also, you should provide your current best guess at what a calculation would include expressed in R to help clarify your description. In your case you might be able to separate your problem into "find a row number for the first reading" and then what calculations would make if you knew "n" was that row number... but those are guesses because I don't know what your data look like.

A recommended technique to provide data is to use the dput function to format R data and paste it into your email... read more at [1][2][3].

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 

On November 22, 2018 1:33:39 AM PST, Romy Rehschuh via R-help <r-help at r-project.org> wrote:
>Dear all,
>
>I hope this is the right way to ask questions.
>I have a problem with R regarding the detection of the measurement of a
>specific sample_id (see example file attached). I have to substract the
>"IN" values (means the air which goes into the chambers) from the
>values of
>"d13C", "ppm_CO2" and "ppm_13CO2" for every single chamber (=sample
>ID).
>The "IN" values have to be the ones which were measured* before *the
>measurements of the single chambers in time. I measured "IN" once and
>then
>up to 10 chambers in a row to safe time, then "IN" again, but it can
>change.
>Therefore, searching for the closest "IN" does not work.
>
>Do you have any suggestions? Would it be possible to write a loop for
>this?
>I would really much appreciate your help!
>
>Best, Vicci
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ruipb@rr@d@@ @ending from @@po@pt  Thu Nov 22 17:53:51 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Thu, 22 Nov 2018 16:53:51 +0000
Subject: [R] detecting measurement of specific id in column in R
In-Reply-To: <CAPYt5uEpt0ZjEZM6SXYFQEo1KJ8umgyVsRdNkjKvgzku8ZPBHw@mail.gmail.com>
References: <CAPYt5uEpt0ZjEZM6SXYFQEo1KJ8umgyVsRdNkjKvgzku8ZPBHw@mail.gmail.com>
Message-ID: <66c63c99-6a51-e5f5-52fb-50c28827af9c@sapo.pt>

Hello,

No attachment arrived.
R-help allows only a limited number of file types to be attached, if you 
file is a text file, change its extension to .txt an try again, please.

Hope this helps,

Rui Barradas

?s 09:33 de 22/11/2018, Romy Rehschuh via R-help escreveu:
> Dear all,
> 
> I hope this is the right way to ask questions.
> I have a problem with R regarding the detection of the measurement of a
> specific sample_id (see example file attached). I have to substract the
> "IN" values (means the air which goes into the chambers) from the values of
> "d13C", "ppm_CO2" and "ppm_13CO2" for every single chamber (=sample ID).
> The "IN" values have to be the ones which were measured* before *the
> measurements of the single chambers in time. I measured "IN" once and then
> up to 10 chambers in a row to safe time, then "IN" again, but it can change.
> Therefore, searching for the closest "IN" does not work.
> 
> Do you have any suggestions? Would it be possible to write a loop for this?
> I would really much appreciate your help!
> 
> Best, Vicci
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @ending from gm@il@com  Thu Nov 22 19:06:24 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 22 Nov 2018 10:06:24 -0800
Subject: [R] detecting measurement of specific id in column in R
In-Reply-To: <CAPYt5uEpt0ZjEZM6SXYFQEo1KJ8umgyVsRdNkjKvgzku8ZPBHw@mail.gmail.com>
References: <CAPYt5uEpt0ZjEZM6SXYFQEo1KJ8umgyVsRdNkjKvgzku8ZPBHw@mail.gmail.com>
Message-ID: <CAGxFJbRvoXPuBY24k+zkzhakh+ppBQ7KqFn257VksFSA_QhYwA@mail.gmail.com>

Jeff's advice is sound, but as I have a bit of time on my hand, I'll take a
guess at it. If it's wrong, then follow Jeff's advice so that we don't have
to continue to guess -- and do as he describes in any future posts, of
course. Note also that the mail server strips off attachments (except for a
few special types -- see the mailing list instructions for which), so you
need to follow the posting guide to post example data (see ?dput) .

It sounds to me as if your data are in a data frame, d, that looks like
this:

Sample_ID    IN       d13c        ppm_CO2    ppm_13CO2  .......
1                    v1        x1               y1             z1
1                    v2        x2               y2             z2
.      ...........      ..................................
.      ...................................................
1
2                   vm        xm               ym          zm
.
.
2                                     etc.
3
.
.

If so, then something like

nm <- c("d13c", "ppm_CO2", "ppm_13CO2")
by(d, d$Sample_ID, function(x){ x[, nm] - x[1, "IN"] }, simplify = FALSE )

would do what you seem to request. See ?by and associated links for details.

Again, if this is not what you want, do not ask me for further help. I'm
done guessing.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Nov 22, 2018 at 8:14 AM Romy Rehschuh via R-help <
r-help at r-project.org> wrote:

> Dear all,
>
> I hope this is the right way to ask questions.
> I have a problem with R regarding the detection of the measurement of a
> specific sample_id (see example file attached). I have to substract the
> "IN" values (means the air which goes into the chambers) from the values of
> "d13C", "ppm_CO2" and "ppm_13CO2" for every single chamber (=sample ID).
> The "IN" values have to be the ones which were measured* before *the
> measurements of the single chambers in time. I measured "IN" once and then
> up to 10 chambers in a row to safe time, then "IN" again, but it can
> change.
> Therefore, searching for the closest "IN" does not work.
>
> Do you have any suggestions? Would it be possible to write a loop for this?
> I would really much appreciate your help!
>
> Best, Vicci
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From v@rin@@ch@ @ending from y@hoo@fr  Thu Nov 22 21:36:18 2018
From: v@rin@@ch@ @ending from y@hoo@fr (varin sacha)
Date: Thu, 22 Nov 2018 20:36:18 +0000 (UTC)
Subject: [R] Bootstrapped CIs of MSE for (G)AM model
References: <1399535201.8641093.1542918978430.ref@mail.yahoo.com>
Message-ID: <1399535201.8641093.1542918978430@mail.yahoo.com>

Dear R-experts,

I am trying to get the bootstrapped confidence intervals of Mean squared error (MSE) for a (G)AM model. I get an error message.
Here below the reproducible R code. Many thanks for your response.

####################


install.packages("ISLR")

library(ISLR)

install.packages("mgcv")

library(mgcv)

install.packages("boot")

library(boot)

#MSE calculation

n=dim(Wage)[1]

p=0.667

GAM1<-gam(wage ~education+s(age,bs="ps")+year,data=Wage)

sam=sample(1?:n,floor(p*n),replace=FALSE)

?

Training =Wage [sam,]

Testing = Wage [-sam,]

?

ypred=predict(GAM1,newdata=Testing)

y=Testing$wage

MSE = mean((y-ypred)^2)


# Bootstrap 95% CI for MSE

# function to obtain MSE
MSE <- function(formula, data, indices) {
??d <- data[indices,] # allows boot to select sample 
??fit <- gam(formula, data=d)
??return(MSE(fit)) 

} # bootstrapping with 1000 replications 
results <- boot(data=Wage, statistic=MSE, 
?? R=1000, formula=gam(wage ~education+s(age,bs="ps")+year,data=Wage)

)
# get 95% confidence intervals 
boot.ci(results, type="bca")

##########################


From ro@reh@chuh @ending from googlem@il@com  Thu Nov 22 18:42:38 2018
From: ro@reh@chuh @ending from googlem@il@com (Romy Rehschuh)
Date: Thu, 22 Nov 2018 18:42:38 +0100
Subject: [R] detecting measurement of specific id in column in R
In-Reply-To: <66c63c99-6a51-e5f5-52fb-50c28827af9c@sapo.pt>
References: <CAPYt5uEpt0ZjEZM6SXYFQEo1KJ8umgyVsRdNkjKvgzku8ZPBHw@mail.gmail.com>
 <66c63c99-6a51-e5f5-52fb-50c28827af9c@sapo.pt>
Message-ID: <CAPYt5uEZgvo_gb8Gq6O03y_A08xRiOhkkVEWSzp2xHPm5N55Tg@mail.gmail.com>

Dear all,

if the attachment didn?t arrive, maybe it works now.
I would like to substract the "IN" values (= the air which goes into the
chambers) for "d13C", "ppm_CO2" and "ppm_13CO2"
from the "d13C", "ppm_CO2" and "ppm_13CO2" for every single chamber.
I need to substract the "IN" values which were measured *before* the
chamber.

So the calculation would look like df$d13C [chambers] - df$d13C [IN]
                                                       df$ppm_CO2
[chambers] - df$ppm_13CO2 [IN]
                                                       df$ppm_13CO2
[chambers] - df$ ppm_13CO2 [IN]
--> for chamber 101-111 this should be the first "IN" (No 1)
--> for chamber 1-11 this should be the second "IN" (No 12)
...and so on

I tried sth. like which(abs(date-x) == min(abs(date-x), but it just gives
me the closest "IN" in time and not the "IN" before.

I would appreciate any help!
Thank you so much, Vicci

Am Do., 22. Nov. 2018 um 17:53 Uhr schrieb Rui Barradas <
ruipbarradas at sapo.pt>:

> Hello,
>
> No attachment arrived.
> R-help allows only a limited number of file types to be attached, if you
> file is a text file, change its extension to .txt an try again, please.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 09:33 de 22/11/2018, Romy Rehschuh via R-help escreveu:
> > Dear all,
> >
> > I hope this is the right way to ask questions.
> > I have a problem with R regarding the detection of the measurement of a
> > specific sample_id (see example file attached). I have to substract the
> > "IN" values (means the air which goes into the chambers) from the values
> of
> > "d13C", "ppm_CO2" and "ppm_13CO2" for every single chamber (=sample ID).
> > The "IN" values have to be the ones which were measured* before *the
> > measurements of the single chambers in time. I measured "IN" once and
> then
> > up to 10 chambers in a row to safe time, then "IN" again, but it can
> change.
> > Therefore, searching for the closest "IN" does not work.
> >
> > Do you have any suggestions? Would it be possible to write a loop for
> this?
> > I would really much appreciate your help!
> >
> > Best, Vicci
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Example.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20181122/926dbcef/attachment.txt>

From ruipb@rr@d@@ @ending from @@po@pt  Thu Nov 22 22:55:22 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Thu, 22 Nov 2018 21:55:22 +0000
Subject: [R] Bootstrapped CIs of MSE for (G)AM model
In-Reply-To: <1399535201.8641093.1542918978430@mail.yahoo.com>
References: <1399535201.8641093.1542918978430.ref@mail.yahoo.com>
 <1399535201.8641093.1542918978430@mail.yahoo.com>
Message-ID: <15a3ca63-6af4-2818-01b7-3c4186676201@sapo.pt>

Hello,

There were several errors with your code. The following works but with 
the other CI types.


library(ISLR)
library(mgcv)
library(boot)

# function to obtain MSE
MSE <- function(data, indices, formula) {
   d <- data[indices, ] # allows boot to select sample
   fit <- gam(formula, data = d)
   ypred <- predict(fit)
   mean((d[["wage"]] - ypred)^2)
}

data(Wage)

# Make the results reproducible
set.seed(1234)

# bootstrapping with 1000 replications
results <- boot(data = Wage, statistic = MSE,
                 R = 1000, formula = wage ~ education + s(age, bs = 
"ps") + year))

# get 95% confidence intervals
# type = "bca" is throwing an error
ci.type <- c("norm","basic", "stud", "perc")
boot.ci(results, type = ci.type)



Hope this helps,

Rui Barradas

?s 20:36 de 22/11/2018, varin sacha via R-help escreveu:
> Dear R-experts,
> 
> I am trying to get the bootstrapped confidence intervals of Mean squared error (MSE) for a (G)AM model. I get an error message.
> Here below the reproducible R code. Many thanks for your response.
> 
> ####################
> 
> 
> install.packages("ISLR")
> 
> library(ISLR)
> 
> install.packages("mgcv")
> 
> library(mgcv)
> 
> install.packages("boot")
> 
> library(boot)
> 
> #MSE calculation
> 
> n=dim(Wage)[1]
> 
> p=0.667
> 
> GAM1<-gam(wage ~education+s(age,bs="ps")+year,data=Wage)
> 
> sam=sample(1?:n,floor(p*n),replace=FALSE)
> 
>   
> 
> Training =Wage [sam,]
> 
> Testing = Wage [-sam,]
> 
>   
> 
> ypred=predict(GAM1,newdata=Testing)
> 
> y=Testing$wage
> 
> MSE = mean((y-ypred)^2)
> 
> 
> # Bootstrap 95% CI for MSE
> 
> # function to obtain MSE
> MSE <- function(formula, data, indices) {
>  ??d <- data[indices,] # allows boot to select sample
>  ??fit <- gam(formula, data=d)
>  ??return(MSE(fit))
> 
> } # bootstrapping with 1000 replications
> results <- boot(data=Wage, statistic=MSE,
>  ?? R=1000, formula=gam(wage ~education+s(age,bs="ps")+year,data=Wage)
> 
> )
> # get 95% confidence intervals
> boot.ci(results, type="bca")
> 
> ##########################
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon @ending from gm@il@com  Thu Nov 22 23:34:17 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Fri, 23 Nov 2018 09:34:17 +1100
Subject: [R] detecting measurement of specific id in column in R
In-Reply-To: <CAPYt5uEZgvo_gb8Gq6O03y_A08xRiOhkkVEWSzp2xHPm5N55Tg@mail.gmail.com>
References: <CAPYt5uEpt0ZjEZM6SXYFQEo1KJ8umgyVsRdNkjKvgzku8ZPBHw@mail.gmail.com>
 <66c63c99-6a51-e5f5-52fb-50c28827af9c@sapo.pt>
 <CAPYt5uEZgvo_gb8Gq6O03y_A08xRiOhkkVEWSzp2xHPm5N55Tg@mail.gmail.com>
Message-ID: <CA+8X3fWUFFWnMqRuCpHzNO=Gr=q3z8UNG3Pp=GBsdBdM8HvKjQ@mail.gmail.com>

Hi Vicci,
It's very clunky, but I think it will do what you want.
rrdf<-read.csv(text="No,date,chamber,d13C,ppm_CO2,ppm_13CO2
 1,10.14.2018 10:43 PM,IN,-0.192,439.6908,4.9382
 2,10.14.2018 10:47 PM,101,-0.058,440.7646,4.9509
 3,10.14.2018 10:50 PM,103,-1.368,535.6602,5.9967
 4,10.14.2018 10:53 PM,104,-1.601,542.4841,6.0702
 5,10.14.2018 10:57 PM,105,-1.353,475.2809,5.3299
 6,10.14.2018 11:00 PM,106,-1.184,530.6732,5.9430
 7,10.14.2018 11:03 PM,107,-1.582,512.5939,5.7418
 8,10.14.2018 11:07 PM,108,-1.359,544.0658,6.0889
 9,10.14.2018 11:10 PM,109,-1.557,543.2651,6.0790
 10,10.14.2018 11:13 PM,110,-1.638,477.0006,5.3476
 11,10.14.2018 11:17 PM,111,-1.475,530.1569,5.9357
 12,10.14.2018 11:20 PM,IN,-0.039,439.3367,4.9350
 13,10.14.2018 11:23 PM,1,-0.061,439.7931,4.9400
 14,10.14.2018 11:26 PM,3,-0.510,456.0714,5.1201
 15,10.14.2018 11:30 PM,4,-0.510,456.5144,5.1250
 16,10.14.2018 11:33 PM,5,-0.767,454.4449,5.1005
 17,10.14.2018 11:37 PM,6,-0.788,459.7679,5.1600
 18,10.14.2018 11:40 PM,7,-0.978,456.6323,5.1240
 19,10.14.2018 11:43 PM,8,-0.742,450.4059,5.0556
 20,10.14.2018 11:47 PM,9,-0.675,451.6678,5.0700
 21,10.14.2018 11:50 PM,10,-0.880,455.5837,5.1127
 22,10.14.2018 11:53 PM,11,-0.912,463.0478,5.1960
 23,10.15.2018 12:01 AM,IN,-0.368,439.5525,4.9359
 24,10.15.2018 12:12 AM,102,-0.205,439.9343,4.9409
 25,10.15.2018 12:15 AM,112,-1.685,474.5002,5.3196
 26,10.15.2018 12:19 AM,113,-1.714,474.4248,5.3186
 27,10.15.2018 12:22 AM,114,-2.032,496.5623,5.5623
 28,10.15.2018 12:26 AM,115,-1.602,471.2034,5.2834
 29,10.15.2018 12:29 AM,116,-1.303,554.4268,6.2028
 30,10.15.2018 12:32 AM,117,-1.833,501.2357,5.6151
 31,10.15.2018 12:36 AM,118,-1.745,496.0126,5.5578
 32,10.15.2018 12:39 AM,119,-1.537,467.5305,5.2428
 33,10.15.2018 12:42 AM,120,-2.109,507.5778,5.6836",
 stringsAsFactors=FALSE)


rrdf$ppm_13CO2_delta<-rrdf$ppm_CO2_delta<-rrdf$d13C_delta<-NA
for(row in 1:nrow(rrdf)) {
 if(rrdf$chamber[row] == "IN")
  INval<-c(rrdf$d13C[row],rrdf$ppm_CO2[row],rrdf$ppm_13CO2[row])
 rrdf[row,c("d13C_delta","ppm_CO2_delta","ppm_13CO2_delta")]<-
  rrdf[row,c("d13C","ppm_CO2","ppm_13CO2")]-INval
}

Jim

On Fri, Nov 23, 2018 at 8:52 AM Romy Rehschuh via R-help
<r-help at r-project.org> wrote:
>
> Dear all,
>
> if the attachment didn?t arrive, maybe it works now.
> I would like to substract the "IN" values (= the air which goes into the
> chambers) for "d13C", "ppm_CO2" and "ppm_13CO2"
> from the "d13C", "ppm_CO2" and "ppm_13CO2" for every single chamber.
> I need to substract the "IN" values which were measured *before* the
> chamber.
>
> So the calculation would look like df$d13C [chambers] - df$d13C [IN]
>                                                        df$ppm_CO2
> [chambers] - df$ppm_13CO2 [IN]
>                                                        df$ppm_13CO2
> [chambers] - df$ ppm_13CO2 [IN]
> --> for chamber 101-111 this should be the first "IN" (No 1)
> --> for chamber 1-11 this should be the second "IN" (No 12)
> ...and so on
>
> I tried sth. like which(abs(date-x) == min(abs(date-x), but it just gives
> me the closest "IN" in time and not the "IN" before.
>
> I would appreciate any help!
> Thank you so much, Vicci


From ruipb@rr@d@@ @ending from @@po@pt  Thu Nov 22 23:45:14 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Thu, 22 Nov 2018 22:45:14 +0000
Subject: [R] Bootstrapped CIs of MSE for (G)AM model
In-Reply-To: <15a3ca63-6af4-2818-01b7-3c4186676201@sapo.pt>
References: <1399535201.8641093.1542918978430.ref@mail.yahoo.com>
 <1399535201.8641093.1542918978430@mail.yahoo.com>
 <15a3ca63-6af4-2818-01b7-3c4186676201@sapo.pt>
Message-ID: <d48f6ff0-2659-33c2-1386-7c2cb03afe0b@sapo.pt>

Hello,

Sorry, there's a close parenthesis too many in the call to boot, the 
very last one.
Delete it and it runs with no errors.

Rui Barradas

?s 21:55 de 22/11/2018, Rui Barradas escreveu:
> Hello,
> 
> There were several errors with your code. The following works but with 
> the other CI types.
> 
> 
> library(ISLR)
> library(mgcv)
> library(boot)
> 
> # function to obtain MSE
> MSE <- function(data, indices, formula) {
>  ? d <- data[indices, ] # allows boot to select sample
>  ? fit <- gam(formula, data = d)
>  ? ypred <- predict(fit)
>  ? mean((d[["wage"]] - ypred)^2)
> }
> 
> data(Wage)
> 
> # Make the results reproducible
> set.seed(1234)
> 
> # bootstrapping with 1000 replications
> results <- boot(data = Wage, statistic = MSE,
>  ??????????????? R = 1000, formula = wage ~ education + s(age, bs = 
> "ps") + year))
> 
> # get 95% confidence intervals
> # type = "bca" is throwing an error
> ci.type <- c("norm","basic", "stud", "perc")
> boot.ci(results, type = ci.type)
> 
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 20:36 de 22/11/2018, varin sacha via R-help escreveu:
>> Dear R-experts,
>>
>> I am trying to get the bootstrapped confidence intervals of Mean 
>> squared error (MSE) for a (G)AM model. I get an error message.
>> Here below the reproducible R code. Many thanks for your response.
>>
>> ####################
>>
>>
>> install.packages("ISLR")
>>
>> library(ISLR)
>>
>> install.packages("mgcv")
>>
>> library(mgcv)
>>
>> install.packages("boot")
>>
>> library(boot)
>>
>> #MSE calculation
>>
>> n=dim(Wage)[1]
>>
>> p=0.667
>>
>> GAM1<-gam(wage ~education+s(age,bs="ps")+year,data=Wage)
>>
>> sam=sample(1?:n,floor(p*n),replace=FALSE)
>>
>>
>> Training =Wage [sam,]
>>
>> Testing = Wage [-sam,]
>>
>>
>> ypred=predict(GAM1,newdata=Testing)
>>
>> y=Testing$wage
>>
>> MSE = mean((y-ypred)^2)
>>
>>
>> # Bootstrap 95% CI for MSE
>>
>> # function to obtain MSE
>> MSE <- function(formula, data, indices) {
>> ???d <- data[indices,] # allows boot to select sample
>> ???fit <- gam(formula, data=d)
>> ???return(MSE(fit))
>>
>> } # bootstrapping with 1000 replications
>> results <- boot(data=Wage, statistic=MSE,
>> ??? R=1000, formula=gam(wage ~education+s(age,bs="ps")+year,data=Wage)
>>
>> )
>> # get 95% confidence intervals
>> boot.ci(results, type="bca")
>>
>> ##########################
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From v@rin@@ch@ @ending from y@hoo@fr  Fri Nov 23 00:19:53 2018
From: v@rin@@ch@ @ending from y@hoo@fr (varin sacha)
Date: Thu, 22 Nov 2018 23:19:53 +0000 (UTC)
Subject: [R] Bootstrapped CIs of MSE for (G)AM model
In-Reply-To: <d48f6ff0-2659-33c2-1386-7c2cb03afe0b@sapo.pt>
References: <1399535201.8641093.1542918978430.ref@mail.yahoo.com>
 <1399535201.8641093.1542918978430@mail.yahoo.com>
 <15a3ca63-6af4-2818-01b7-3c4186676201@sapo.pt>
 <d48f6ff0-2659-33c2-1386-7c2cb03afe0b@sapo.pt>
Message-ID: <986486484.8767958.1542928793315@mail.yahoo.com>

Great, many thanks Rui, it perfectly works.

Best,








Le jeudi 22 novembre 2018 ? 23:45:15 UTC+1, Rui Barradas <ruipbarradas at sapo.pt> a ?crit : 





Hello,

Sorry, there's a close parenthesis too many in the call to boot, the 
very last one.
Delete it and it runs with no errors.

Rui Barradas

?s 21:55 de 22/11/2018, Rui Barradas escreveu:
> Hello,
> 
> There were several errors with your code. The following works but with 
> the other CI types.
> 
> 
> library(ISLR)
> library(mgcv)
> library(boot)
> 
> # function to obtain MSE
> MSE <- function(data, indices, formula) {
>? ? d <- data[indices, ] # allows boot to select sample
>? ? fit <- gam(formula, data = d)
>? ? ypred <- predict(fit)
>? ? mean((d[["wage"]] - ypred)^2)
> }
> 
> data(Wage)
> 
> # Make the results reproducible
> set.seed(1234)
> 
> # bootstrapping with 1000 replications
> results <- boot(data = Wage, statistic = MSE,
>? ??????????????? R = 1000, formula = wage ~ education + s(age, bs = 
> "ps") + year))
> 
> # get 95% confidence intervals
> # type = "bca" is throwing an error
> ci.type <- c("norm","basic", "stud", "perc")
> boot.ci(results, type = ci.type)
> 
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 20:36 de 22/11/2018, varin sacha via R-help escreveu:
>> Dear R-experts,
>>
>> I am trying to get the bootstrapped confidence intervals of Mean 
>> squared error (MSE) for a (G)AM model. I get an error message.
>> Here below the reproducible R code. Many thanks for your response.
>>
>> ####################
>>
>>
>> install.packages("ISLR")
>>
>> library(ISLR)
>>
>> install.packages("mgcv")
>>
>> library(mgcv)
>>
>> install.packages("boot")
>>
>> library(boot)
>>
>> #MSE calculation
>>
>> n=dim(Wage)[1]
>>
>> p=0.667
>>
>> GAM1<-gam(wage ~education+s(age,bs="ps")+year,data=Wage)
>>
>> sam=sample(1?:n,floor(p*n),replace=FALSE)
>>
>>
>> Training =Wage [sam,]
>>
>> Testing = Wage [-sam,]
>>
>>
>> ypred=predict(GAM1,newdata=Testing)
>>
>> y=Testing$wage
>>
>> MSE = mean((y-ypred)^2)
>>
>>
>> # Bootstrap 95% CI for MSE
>>
>> # function to obtain MSE
>> MSE <- function(formula, data, indices) {
>> ???d <- data[indices,] # allows boot to select sample
>> ???fit <- gam(formula, data=d)
>> ???return(MSE(fit))
>>
>> } # bootstrapping with 1000 replications
>> results <- boot(data=Wage, statistic=MSE,
>> ??? R=1000, formula=gam(wage ~education+s(age,bs="ps")+year,data=Wage)
>>
>> )
>> # get 95% confidence intervals
>> boot.ci(results, type="bca")
>>
>> ##########################
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 407600@b @ending from @tudent@eur@nl  Fri Nov 23 11:43:35 2018
From: 407600@b @ending from @tudent@eur@nl (Lisa van der Burgh)
Date: Fri, 23 Nov 2018 10:43:35 +0000
Subject: [R] Question Mixed-Design Anova in R
Message-ID: <HE1PR0201MB21564DE830449F6C7B1C2AF3F5D40@HE1PR0201MB2156.eurprd02.prod.outlook.com>

Hi Everyone,



I have a question about Mixed-Design Anova in R. I want to obtain Mauchly?s test of Sphericity and the Greenhouse-Geisser correction. I have managed to do it in SPSS:



GLM Measure1 Measure2 Measure3 Measure4 Measure5 Measure6 BY Grouping

  /WSFACTOR=Measure 6 Polynomial

  /METHOD=SSTYPE(3)

  /PLOT=PROFILE(Measure*Grouping)

  /CRITERIA=ALPHA(.05)

  /WSDESIGN=Measure

  /DESIGN=Grouping.



I have tried to replicate this in R:

library("dplyr")

library("tidyr")

library("ggplot2")

library("ez")



PatientID <- c(1:10)

Measure1 <- c(3,5,7,4,NA,7,4,4,7,2)

Measure2 <- c(1,2,5,6,8,9,5,NA,6,7)

Measure3 <- c(3,3,5,7,NA,4,5,7,8,1)

Measure4 <- c(1,2,5,NA,3,NA,6,7,3,6)

Measure5 <- c(2,3,NA,8,3,5,6,3,6,4)

Measure6 <- c(1,2,4,6,8,3,5,6,NA,4)

Grouping <- c(1,0,1,1,1,0,0,1,1,0)

dataframe <- data.frame(PatientID, Measure1, Measure2, Measure3, Measure4, Measure5, Measure6, Grouping)

dataframe$Grouping <- as.factor(dataframe$Grouping)

dataframe



ezPrecis(dataframe)

glimpse(dataframe)



dataframe %>% count(PatientID)



dataframe %>% count(PatientID, Grouping, Measure1, Measure2, Measure3, Measure4, Measure5, Measure6) %>%

  filter(PatientID %in% c(1:243)) %>%

  print(n = 10)



# So, we have a mixed design with one between factor (Grouping) and 6 within factors (Measure 1 to 6).



dat_means <- dataframe %>%

  group_by(Grouping, Measure1, Measure2, Measure3, Measure4, Measure5, Measure6) %>%

  summarise(mRT = mean(c(Measure1, Measure2, Measure3, Measure4, Measure5, Measure6))) %>% ungroup()

View(dat_means)



ggplot(dat_means, aes(c(Measure1, Measure2, Measure3, Measure4, Measure5, Measure6), mRT, colour = Grouping)) +

  geom_line(aes(group = Grouping)) +

  geom_point(aes(shape = Grouping), size = 3) +

  facet_wrap(~group)



ANOVA <- ezANOVA(dat, x, PatientID, within = .( c(Measure1, Measure2, Measure3, Measure4, Measure5, Measure6)),

                    between = Grouping, type = 3)



print(ANOVA)





However, this does not work. I know I am probably doing it completely wrong, but I do not know how to solve it. Besides that, I do not know what to fill in at the ?x?.

Can somebody help me?



Thank you in advance.

Lisa


	[[alternative HTML version deleted]]


From ro@reh@chuh @ending from googlem@il@com  Fri Nov 23 11:55:42 2018
From: ro@reh@chuh @ending from googlem@il@com (Romy Rehschuh)
Date: Fri, 23 Nov 2018 11:55:42 +0100
Subject: [R] detecting measurement of specific id in column in R
In-Reply-To: <CA+8X3fWUFFWnMqRuCpHzNO=Gr=q3z8UNG3Pp=GBsdBdM8HvKjQ@mail.gmail.com>
References: <CAPYt5uEpt0ZjEZM6SXYFQEo1KJ8umgyVsRdNkjKvgzku8ZPBHw@mail.gmail.com>
 <66c63c99-6a51-e5f5-52fb-50c28827af9c@sapo.pt>
 <CAPYt5uEZgvo_gb8Gq6O03y_A08xRiOhkkVEWSzp2xHPm5N55Tg@mail.gmail.com>
 <CA+8X3fWUFFWnMqRuCpHzNO=Gr=q3z8UNG3Pp=GBsdBdM8HvKjQ@mail.gmail.com>
Message-ID: <CAPYt5uH41Ne_KeQvf+=2uL6n2w-BizmK8cwGx4DnXojjaR9prg@mail.gmail.com>

Dear all, dear Jim,

thanks so much for your efforts! The code seems to work well :)

All the best,

Vicci

Am Do., 22. Nov. 2018 um 23:34 Uhr schrieb Jim Lemon <drjimlemon at gmail.com>:

> Hi Vicci,
> It's very clunky, but I think it will do what you want.
> rrdf<-read.csv(text="No,date,chamber,d13C,ppm_CO2,ppm_13CO2
>  1,10.14.2018 10:43 PM,IN,-0.192,439.6908,4.9382
>  2,10.14.2018 10:47 PM,101,-0.058,440.7646,4.9509
>  3,10.14.2018 10:50 PM,103,-1.368,535.6602,5.9967
>  4,10.14.2018 10:53 PM,104,-1.601,542.4841,6.0702
>  5,10.14.2018 10:57 PM,105,-1.353,475.2809,5.3299
>  6,10.14.2018 11:00 PM,106,-1.184,530.6732,5.9430
>  7,10.14.2018 11:03 PM,107,-1.582,512.5939,5.7418
>  8,10.14.2018 11:07 PM,108,-1.359,544.0658,6.0889
>  9,10.14.2018 11:10 PM,109,-1.557,543.2651,6.0790
>  10,10.14.2018 11:13 PM,110,-1.638,477.0006,5.3476
>  11,10.14.2018 11:17 PM,111,-1.475,530.1569,5.9357
>  12,10.14.2018 11:20 PM,IN,-0.039,439.3367,4.9350
>  13,10.14.2018 11:23 PM,1,-0.061,439.7931,4.9400
>  14,10.14.2018 11:26 PM,3,-0.510,456.0714,5.1201
>  15,10.14.2018 11:30 PM,4,-0.510,456.5144,5.1250
>  16,10.14.2018 11:33 PM,5,-0.767,454.4449,5.1005
>  17,10.14.2018 11:37 PM,6,-0.788,459.7679,5.1600
>  18,10.14.2018 11:40 PM,7,-0.978,456.6323,5.1240
>  19,10.14.2018 11:43 PM,8,-0.742,450.4059,5.0556
>  20,10.14.2018 11:47 PM,9,-0.675,451.6678,5.0700
>  21,10.14.2018 11:50 PM,10,-0.880,455.5837,5.1127
>  22,10.14.2018 11:53 PM,11,-0.912,463.0478,5.1960
>  23,10.15.2018 12:01 AM,IN,-0.368,439.5525,4.9359
>  24,10.15.2018 12:12 AM,102,-0.205,439.9343,4.9409
>  25,10.15.2018 12:15 AM,112,-1.685,474.5002,5.3196
>  26,10.15.2018 12:19 AM,113,-1.714,474.4248,5.3186
>  27,10.15.2018 12:22 AM,114,-2.032,496.5623,5.5623
>  28,10.15.2018 12:26 AM,115,-1.602,471.2034,5.2834
>  29,10.15.2018 12:29 AM,116,-1.303,554.4268,6.2028
>  30,10.15.2018 12:32 AM,117,-1.833,501.2357,5.6151
>  31,10.15.2018 12:36 AM,118,-1.745,496.0126,5.5578
>  32,10.15.2018 12:39 AM,119,-1.537,467.5305,5.2428
>  33,10.15.2018 12:42 AM,120,-2.109,507.5778,5.6836",
>  stringsAsFactors=FALSE)
>
>
> rrdf$ppm_13CO2_delta<-rrdf$ppm_CO2_delta<-rrdf$d13C_delta<-NA
> for(row in 1:nrow(rrdf)) {
>  if(rrdf$chamber[row] == "IN")
>   INval<-c(rrdf$d13C[row],rrdf$ppm_CO2[row],rrdf$ppm_13CO2[row])
>  rrdf[row,c("d13C_delta","ppm_CO2_delta","ppm_13CO2_delta")]<-
>   rrdf[row,c("d13C","ppm_CO2","ppm_13CO2")]-INval
> }
>
> Jim
>
> On Fri, Nov 23, 2018 at 8:52 AM Romy Rehschuh via R-help
> <r-help at r-project.org> wrote:
> >
> > Dear all,
> >
> > if the attachment didn?t arrive, maybe it works now.
> > I would like to substract the "IN" values (= the air which goes into the
> > chambers) for "d13C", "ppm_CO2" and "ppm_13CO2"
> > from the "d13C", "ppm_CO2" and "ppm_13CO2" for every single chamber.
> > I need to substract the "IN" values which were measured *before* the
> > chamber.
> >
> > So the calculation would look like df$d13C [chambers] - df$d13C [IN]
> >                                                        df$ppm_CO2
> > [chambers] - df$ppm_13CO2 [IN]
> >                                                        df$ppm_13CO2
> > [chambers] - df$ ppm_13CO2 [IN]
> > --> for chamber 101-111 this should be the first "IN" (No 1)
> > --> for chamber 1-11 this should be the second "IN" (No 12)
> > ...and so on
> >
> > I tried sth. like which(abs(date-x) == min(abs(date-x), but it just gives
> > me the closest "IN" in time and not the "IN" before.
> >
> > I would appreciate any help!
> > Thank you so much, Vicci
>

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Fri Nov 23 14:02:32 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Fri, 23 Nov 2018 13:02:32 +0000
Subject: [R] detecting measurement of specific id in column in R
In-Reply-To: <CA+8X3fWUFFWnMqRuCpHzNO=Gr=q3z8UNG3Pp=GBsdBdM8HvKjQ@mail.gmail.com>
References: <CAPYt5uEpt0ZjEZM6SXYFQEo1KJ8umgyVsRdNkjKvgzku8ZPBHw@mail.gmail.com>
 <66c63c99-6a51-e5f5-52fb-50c28827af9c@sapo.pt>
 <CAPYt5uEZgvo_gb8Gq6O03y_A08xRiOhkkVEWSzp2xHPm5N55Tg@mail.gmail.com>
 <CA+8X3fWUFFWnMqRuCpHzNO=Gr=q3z8UNG3Pp=GBsdBdM8HvKjQ@mail.gmail.com>
Message-ID: <56c786a2ea5f43678119f7fa1507a86c@SRVEXCHCM1302.precheza.cz>

Hi

It could be done by ave function if you prepare chamber column to such task

library(zoo)
#make new column ch
rrdf$ch<-rrdf$chamber
#change what is not IN to NA
rrdf$ch[which(rrdf$chamber!="IN")]<-NA
#make distinct identifier for each IN chunk
rrdf$ch[which(rrdf$chamber=="IN")]<-paste("IN", 1:3, sep="")
fill NA values
rrdf$ch<-na.locf(rrdf$ch)

ave(rrdf[,4], rrdf$ch, FUN=function(x) x-x[1])

gives you values which could be added to original data e.g.

rrdf$ppm_13CO2_delta <- ave(rrdf$ ppm_13CO2, rrdf$ch, FUN=function(x) x-x[1])

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jim Lemon
> Sent: Thursday, November 22, 2018 11:34 PM
> To: ro.rehschuh at googlemail.com
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] detecting measurement of specific id in column in R
>
> Hi Vicci,
> It's very clunky, but I think it will do what you want.
> rrdf<-read.csv(text="No,date,chamber,d13C,ppm_CO2,ppm_13CO2
>  1,10.14.2018 10:43 PM,IN,-0.192,439.6908,4.9382
>  2,10.14.2018 10:47 PM,101,-0.058,440.7646,4.9509
>  3,10.14.2018 10:50 PM,103,-1.368,535.6602,5.9967
>  4,10.14.2018 10:53 PM,104,-1.601,542.4841,6.0702
>  5,10.14.2018 10:57 PM,105,-1.353,475.2809,5.3299
>  6,10.14.2018 11:00 PM,106,-1.184,530.6732,5.9430
>  7,10.14.2018 11:03 PM,107,-1.582,512.5939,5.7418
>  8,10.14.2018 11:07 PM,108,-1.359,544.0658,6.0889
>  9,10.14.2018 11:10 PM,109,-1.557,543.2651,6.0790
>  10,10.14.2018 11:13 PM,110,-1.638,477.0006,5.3476
>  11,10.14.2018 11:17 PM,111,-1.475,530.1569,5.9357
>  12,10.14.2018 11:20 PM,IN,-0.039,439.3367,4.9350
>  13,10.14.2018 11:23 PM,1,-0.061,439.7931,4.9400
>  14,10.14.2018 11:26 PM,3,-0.510,456.0714,5.1201
>  15,10.14.2018 11:30 PM,4,-0.510,456.5144,5.1250
>  16,10.14.2018 11:33 PM,5,-0.767,454.4449,5.1005
>  17,10.14.2018 11:37 PM,6,-0.788,459.7679,5.1600
>  18,10.14.2018 11:40 PM,7,-0.978,456.6323,5.1240
>  19,10.14.2018 11:43 PM,8,-0.742,450.4059,5.0556
>  20,10.14.2018 11:47 PM,9,-0.675,451.6678,5.0700
>  21,10.14.2018 11:50 PM,10,-0.880,455.5837,5.1127
>  22,10.14.2018 11:53 PM,11,-0.912,463.0478,5.1960
>  23,10.15.2018 12:01 AM,IN,-0.368,439.5525,4.9359
>  24,10.15.2018 12:12 AM,102,-0.205,439.9343,4.9409
>  25,10.15.2018 12:15 AM,112,-1.685,474.5002,5.3196
>  26,10.15.2018 12:19 AM,113,-1.714,474.4248,5.3186
>  27,10.15.2018 12:22 AM,114,-2.032,496.5623,5.5623
>  28,10.15.2018 12:26 AM,115,-1.602,471.2034,5.2834
>  29,10.15.2018 12:29 AM,116,-1.303,554.4268,6.2028
>  30,10.15.2018 12:32 AM,117,-1.833,501.2357,5.6151
>  31,10.15.2018 12:36 AM,118,-1.745,496.0126,5.5578
>  32,10.15.2018 12:39 AM,119,-1.537,467.5305,5.2428
>  33,10.15.2018 12:42 AM,120,-2.109,507.5778,5.6836",
>  stringsAsFactors=FALSE)
>
>
> rrdf$ppm_13CO2_delta<-rrdf$ppm_CO2_delta<-rrdf$d13C_delta<-NA
> for(row in 1:nrow(rrdf)) {
>  if(rrdf$chamber[row] == "IN")
>   INval<-c(rrdf$d13C[row],rrdf$ppm_CO2[row],rrdf$ppm_13CO2[row])
>  rrdf[row,c("d13C_delta","ppm_CO2_delta","ppm_13CO2_delta")]<-
>   rrdf[row,c("d13C","ppm_CO2","ppm_13CO2")]-INval
> }
>
> Jim
>
> On Fri, Nov 23, 2018 at 8:52 AM Romy Rehschuh via R-help <r-help at r-
> project.org> wrote:
> >
> > Dear all,
> >
> > if the attachment didn?t arrive, maybe it works now.
> > I would like to substract the "IN" values (= the air which goes into
> > the
> > chambers) for "d13C", "ppm_CO2" and "ppm_13CO2"
> > from the "d13C", "ppm_CO2" and "ppm_13CO2" for every single chamber.
> > I need to substract the "IN" values which were measured *before* the
> > chamber.
> >
> > So the calculation would look like df$d13C [chambers] - df$d13C [IN]
> >                                                        df$ppm_CO2
> > [chambers] - df$ppm_13CO2 [IN]
> >                                                        df$ppm_13CO2
> > [chambers] - df$ ppm_13CO2 [IN]
> > --> for chamber 101-111 this should be the first "IN" (No 1) for
> > --> chamber 1-11 this should be the second "IN" (No 12)
> > ...and so on
> >
> > I tried sth. like which(abs(date-x) == min(abs(date-x), but it just
> > gives me the closest "IN" in time and not the "IN" before.
> >
> > I would appreciate any help!
> > Thank you so much, Vicci
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From pd@me@ @ending from cb@@dk  Fri Nov 23 15:27:51 2018
From: pd@me@ @ending from cb@@dk (Peter Dalgaard)
Date: Fri, 23 Nov 2018 14:27:51 +0000
Subject: [R] R 3.5.2 scheduled for December 20
Message-ID: <F77674D5-9E76-4052-BE92-567A4B61EB1B@cbs.dk>

Full schedule available on developer.r-project.org

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From pd@lgd @ending from gm@il@com  Fri Nov 23 16:16:10 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Fri, 23 Nov 2018 16:16:10 +0100
Subject: [R] Question Mixed-Design Anova in R
In-Reply-To: <HE1PR0201MB21564DE830449F6C7B1C2AF3F5D40@HE1PR0201MB2156.eurprd02.prod.outlook.com>
References: <HE1PR0201MB21564DE830449F6C7B1C2AF3F5D40@HE1PR0201MB2156.eurprd02.prod.outlook.com>
Message-ID: <EFC4D978-C7D1-4DA5-8681-BAF817E030AF@gmail.com>

You seem to be bringing in a ton of stuff without looking at features in base R...

Check 

help(mauchly.test)
help(anova.mlm)

and examples therein. There are also options in the "car" package.

-pd

> On 23 Nov 2018, at 11:43 , Lisa van der Burgh <407600ab at student.eur.nl> wrote:
> 
> Hi Everyone,
> 
> 
> 
> I have a question about Mixed-Design Anova in R. I want to obtain Mauchly?s test of Sphericity and the Greenhouse-Geisser correction. I have managed to do it in SPSS:
> 
> 
> 
> GLM Measure1 Measure2 Measure3 Measure4 Measure5 Measure6 BY Grouping
> 
>  /WSFACTOR=Measure 6 Polynomial
> 
>  /METHOD=SSTYPE(3)
> 
>  /PLOT=PROFILE(Measure*Grouping)
> 
>  /CRITERIA=ALPHA(.05)
> 
>  /WSDESIGN=Measure
> 
>  /DESIGN=Grouping.
> 
> 
> 
> I have tried to replicate this in R:
> 
> library("dplyr")
> 
> library("tidyr")
> 
> library("ggplot2")
> 
> library("ez")
> 
> 
> 
> PatientID <- c(1:10)
> 
> Measure1 <- c(3,5,7,4,NA,7,4,4,7,2)
> 
> Measure2 <- c(1,2,5,6,8,9,5,NA,6,7)
> 
> Measure3 <- c(3,3,5,7,NA,4,5,7,8,1)
> 
> Measure4 <- c(1,2,5,NA,3,NA,6,7,3,6)
> 
> Measure5 <- c(2,3,NA,8,3,5,6,3,6,4)
> 
> Measure6 <- c(1,2,4,6,8,3,5,6,NA,4)
> 
> Grouping <- c(1,0,1,1,1,0,0,1,1,0)
> 
> dataframe <- data.frame(PatientID, Measure1, Measure2, Measure3, Measure4, Measure5, Measure6, Grouping)
> 
> dataframe$Grouping <- as.factor(dataframe$Grouping)
> 
> dataframe
> 
> 
> 
> ezPrecis(dataframe)
> 
> glimpse(dataframe)
> 
> 
> 
> dataframe %>% count(PatientID)
> 
> 
> 
> dataframe %>% count(PatientID, Grouping, Measure1, Measure2, Measure3, Measure4, Measure5, Measure6) %>%
> 
>  filter(PatientID %in% c(1:243)) %>%
> 
>  print(n = 10)
> 
> 
> 
> # So, we have a mixed design with one between factor (Grouping) and 6 within factors (Measure 1 to 6).
> 
> 
> 
> dat_means <- dataframe %>%
> 
>  group_by(Grouping, Measure1, Measure2, Measure3, Measure4, Measure5, Measure6) %>%
> 
>  summarise(mRT = mean(c(Measure1, Measure2, Measure3, Measure4, Measure5, Measure6))) %>% ungroup()
> 
> View(dat_means)
> 
> 
> 
> ggplot(dat_means, aes(c(Measure1, Measure2, Measure3, Measure4, Measure5, Measure6), mRT, colour = Grouping)) +
> 
>  geom_line(aes(group = Grouping)) +
> 
>  geom_point(aes(shape = Grouping), size = 3) +
> 
>  facet_wrap(~group)
> 
> 
> 
> ANOVA <- ezANOVA(dat, x, PatientID, within = .( c(Measure1, Measure2, Measure3, Measure4, Measure5, Measure6)),
> 
>                    between = Grouping, type = 3)
> 
> 
> 
> print(ANOVA)
> 
> 
> 
> 
> 
> However, this does not work. I know I am probably doing it completely wrong, but I do not know how to solve it. Besides that, I do not know what to fill in at the ?x?.
> 
> Can somebody help me?
> 
> 
> 
> Thank you in advance.
> 
> Lisa
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From f@rz@neh@@hm@dz@deh @ending from @c@ni@@com  Fri Nov 23 15:59:09 2018
From: f@rz@neh@@hm@dz@deh @ending from @c@ni@@com (Ahmadzadeh Siahrood Farzaneh)
Date: Fri, 23 Nov 2018 14:59:09 +0000
Subject: [R] question about R
Message-ID: <AM6PR04MB5719F06E0E8FEE075804295A92D40@AM6PR04MB5719.eurprd04.prod.outlook.com>

Dear all,
I have a problem which I have stucked for a while and I didn't find any solution. Would you please take your time and see if you could help me for the following R code.
I am using Survival analysis to fit the distribution to my data. My data ranges changes from smaller than 0 to a very big number like (yearly average mileage ). When I add data which are very big in range I receive following error. First I taught by normalizing data it would be solved but it didn't.
If anyone has any experience about what would be the reason for error or how I can solve it ? I really appreciate your support and help.
f<- Surv(time, status) ~ covariates (there are 56)
weibul  <- flexsurvreg(f ,dist='weibull' ,data=Data)
Error in optim(method = "BFGS", par = c(0.566003631595269, 0, 0, 0, 0,  :
  initial value in 'vmmin' is not finite

Med V?nliga H?lsningar
Best Regards,

Farzaneh Ahmadzadeh, PhD. IE.

	[[alternative HTML version deleted]]


From legidi m@ili@g off u@its@it  Fri Nov 23 13:13:27 2018
From: legidi m@ili@g off u@its@it (legidi m@ili@g off u@its@it)
Date: Fri, 23 Nov 2018 13:13:27 +0100
Subject: [R] [R-pkgs] New package pivmet: relabelling and K-means seeding
 via pivotal methods
Message-ID: <20181123131327.Horde.QTZrPs4g2nq45UnqXROcqUo@wmail4.units.it>


Dear R users,

I am glad to announce the release (version 0.1) of the pivmet package,  
which proposes some pivotal methods in order to:


* undo the label switching problem which naturally arises during the  
MCMC sampling in Bayesian mixture models [pivotal relabelling] (Egidi  
et al. 2018a)

* initialize the K-means algorithm aimed at obtaining a good  
clustering solution [pivotal seeding] (Egidi et al. 2018b)

The package includes two vignettes for easing its use and is here available:

https://cran.r-project.org/web/packages/pivmet/index.html

and developed in github at:

https://github.com/LeoEgidi/pivmet


Here are the two referred articles:

Egidi et al. (2018a)
https://link.springer.com/article/10.1007/s11222-017-9774-2

Egidi et al. (2018b)
https://www.researchgate.net/profile/Leonardo_Egidi/publication/326225330_K-means_seeding_via_MUS_algorithm_-_Inizializzazione_del_K-means_tramite_l%27algoritmo_MUS/links/5b3f2c2caca27207851c7865/K-means-seeding-via-MUS-algorithm-Inizializzazione-del-K-means-tramite-lalgoritmo-MUS.pdf


All the best

Leonardo Egidi
Postdoctoral researcher, University of Trieste

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From m@@lem33 @ending from gm@il@com  Fri Nov 23 15:47:16 2018
From: m@@lem33 @ending from gm@il@com (Mohamed Salem)
Date: Fri, 23 Nov 2018 16:47:16 +0200
Subject: [R] Implementation of the "Shuffled Complex Evolution" (SCE-UA)
 Algorithm
Message-ID: <CAEiX4vSF4wsmC72nNkipipb+QE0TXWZG=EQo83hWFFbb08yUzA@mail.gmail.com>

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From jo@n@m@rtelo @ending from gm@il@com  Fri Nov 23 16:43:31 2018
From: jo@n@m@rtelo @ending from gm@il@com (Joana Martelo)
Date: Fri, 23 Nov 2018 15:43:31 -0000
Subject: [R] warnings when using binomial models and offset
Message-ID: <003801d48343$4a066e90$de134bb0$@com>

Hello everyone

 

I'm trying to model fish capture success using length, velocity and group
composition as explanatory variables, density as an offset variable, and
fish.id. as random effect. I'm getting the follow warnings:

 

Model1<-glmer(capture~length+offset(density)+(1|fish.id),family=binomial,dat
a=cap)

 

Warning messages:

1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :

  Model failed to converge with max|grad| = 0.260123 (tol = 0.001, component
1)

2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :

  Model is nearly unidentifiable: very large eigenvalue

- Rescale variables?

 

 

-          I only get the warnings when I use length and group composition,
not with velocity.

-          I don't get any warning if I don't use the offset.

 

I've tried:

Model1<-glmer(capture~length+offset(log(density))+(1|fish.id.c),family=binom
ial(link="cloglog"),data=cap)

 

But still get the warning.

 

Any ideas of what might be the problem?

 

Many thanks!

 

 

Joana Martelo

 

 

 


	[[alternative HTML version deleted]]


From jfox @ending from mcm@@ter@c@  Fri Nov 23 16:54:49 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Fri, 23 Nov 2018 15:54:49 +0000
Subject: [R] Question Mixed-Design Anova in R
In-Reply-To: <15973_1542986588_wANFN77d006406_EFC4D978-C7D1-4DA5-8681-BAF817E030AF@gmail.com>
References: <HE1PR0201MB21564DE830449F6C7B1C2AF3F5D40@HE1PR0201MB2156.eurprd02.prod.outlook.com>
 <15973_1542986588_wANFN77d006406_EFC4D978-C7D1-4DA5-8681-BAF817E030AF@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83695CFE0@FHSDB2D11-2.csu.mcmaster.ca>

Dear Lisa,

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of peter
> dalgaard
> Sent: Friday, November 23, 2018 10:16 AM
> To: Lisa van der Burgh <407600ab at student.eur.nl>
> Cc: r-help at R-project.org
> Subject: Re: [R] Question Mixed-Design Anova in R
> 
> You seem to be bringing in a ton of stuff without looking at features in base
> R...
> 
> Check
> 
> help(mauchly.test)
> help(anova.mlm)
> 
> and examples therein. There are also options in the "car" package.

With respect to the latter, see in particular the O'Brien-Kaiser example in ?Anova.

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/


> 
> -pd
> 
> > On 23 Nov 2018, at 11:43 , Lisa van der Burgh <407600ab at student.eur.nl>
> wrote:
> >
> > Hi Everyone,
> >
> >
> >
> > I have a question about Mixed-Design Anova in R. I want to obtain Mauchly s
> test of Sphericity and the Greenhouse-Geisser correction. I have managed to
> do it in SPSS:
> >
> >
> >
> > GLM Measure1 Measure2 Measure3 Measure4 Measure5 Measure6 BY
> Grouping
> >
> >  /WSFACTOR=Measure 6 Polynomial
> >
> >  /METHOD=SSTYPE(3)
> >
> >  /PLOT=PROFILE(Measure*Grouping)
> >
> >  /CRITERIA=ALPHA(.05)
> >
> >  /WSDESIGN=Measure
> >
> >  /DESIGN=Grouping.
> >
> >
> >
> > I have tried to replicate this in R:
> >
> > library("dplyr")
> >
> > library("tidyr")
> >
> > library("ggplot2")
> >
> > library("ez")
> >
> >
> >
> > PatientID <- c(1:10)
> >
> > Measure1 <- c(3,5,7,4,NA,7,4,4,7,2)
> >
> > Measure2 <- c(1,2,5,6,8,9,5,NA,6,7)
> >
> > Measure3 <- c(3,3,5,7,NA,4,5,7,8,1)
> >
> > Measure4 <- c(1,2,5,NA,3,NA,6,7,3,6)
> >
> > Measure5 <- c(2,3,NA,8,3,5,6,3,6,4)
> >
> > Measure6 <- c(1,2,4,6,8,3,5,6,NA,4)
> >
> > Grouping <- c(1,0,1,1,1,0,0,1,1,0)
> >
> > dataframe <- data.frame(PatientID, Measure1, Measure2, Measure3,
> > Measure4, Measure5, Measure6, Grouping)
> >
> > dataframe$Grouping <- as.factor(dataframe$Grouping)
> >
> > dataframe
> >
> >
> >
> > ezPrecis(dataframe)
> >
> > glimpse(dataframe)
> >
> >
> >
> > dataframe %>% count(PatientID)
> >
> >
> >
> > dataframe %>% count(PatientID, Grouping, Measure1, Measure2,
> Measure3,
> > Measure4, Measure5, Measure6) %>%
> >
> >  filter(PatientID %in% c(1:243)) %>%
> >
> >  print(n = 10)
> >
> >
> >
> > # So, we have a mixed design with one between factor (Grouping) and 6
> within factors (Measure 1 to 6).
> >
> >
> >
> > dat_means <- dataframe %>%
> >
> >  group_by(Grouping, Measure1, Measure2, Measure3, Measure4,
> Measure5,
> > Measure6) %>%
> >
> >  summarise(mRT = mean(c(Measure1, Measure2, Measure3, Measure4,
> > Measure5, Measure6))) %>% ungroup()
> >
> > View(dat_means)
> >
> >
> >
> > ggplot(dat_means, aes(c(Measure1, Measure2, Measure3, Measure4,
> > Measure5, Measure6), mRT, colour = Grouping)) +
> >
> >  geom_line(aes(group = Grouping)) +
> >
> >  geom_point(aes(shape = Grouping), size = 3) +
> >
> >  facet_wrap(~group)
> >
> >
> >
> > ANOVA <- ezANOVA(dat, x, PatientID, within = .( c(Measure1, Measure2,
> > Measure3, Measure4, Measure5, Measure6)),
> >
> >                    between = Grouping, type = 3)
> >
> >
> >
> > print(ANOVA)
> >
> >
> >
> >
> >
> > However, this does not work. I know I am probably doing it completely
> wrong, but I do not know how to solve it. Besides that, I do not know what to
> fill in at the  x .
> >
> > Can somebody help me?
> >
> >
> >
> > Thank you in advance.
> >
> > Lisa
> >
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000
> Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From bgunter@4567 @ending from gm@il@com  Fri Nov 23 17:11:52 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 23 Nov 2018 08:11:52 -0800
Subject: [R] warnings when using binomial models and offset
In-Reply-To: <003801d48343$4a066e90$de134bb0$@com>
References: <003801d48343$4a066e90$de134bb0$@com>
Message-ID: <CAGxFJbS7k0UXEi3QFcZtwxobjg_cnvBSRmMacd+=bCfp7WqSJQ@mail.gmail.com>

You should post this on the r-sig-mixed-models list, which is (obviously)
specifically concerned with mixed models, and where you are more likely to
find the expertise and help you seek.

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Nov 23, 2018 at 7:57 AM Joana Martelo <joanamartelo at gmail.com>
wrote:

> Hello everyone
>
>
>
> I'm trying to model fish capture success using length, velocity and group
> composition as explanatory variables, density as an offset variable, and
> fish.id. as random effect. I'm getting the follow warnings:
>
>
>
> Model1<-glmer(capture~length+offset(density)+(1|fish.id
> ),family=binomial,dat
> a=cap)
>
>
>
> Warning messages:
>
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>
>   Model failed to converge with max|grad| = 0.260123 (tol = 0.001,
> component
> 1)
>
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>
>   Model is nearly unidentifiable: very large eigenvalue
>
> - Rescale variables?
>
>
>
>
>
> -          I only get the warnings when I use length and group composition,
> not with velocity.
>
> -          I don't get any warning if I don't use the offset.
>
>
>
> I've tried:
>
>
> Model1<-glmer(capture~length+offset(log(density))+(1|fish.id.c),family=binom
> ial(link="cloglog"),data=cap)
>
>
>
> But still get the warning.
>
>
>
> Any ideas of what might be the problem?
>
>
>
> Many thanks!
>
>
>
>
>
> Joana Martelo
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From 407600@b @ending from @tudent@eur@nl  Fri Nov 23 17:03:02 2018
From: 407600@b @ending from @tudent@eur@nl (Lisa van der Burgh)
Date: Fri, 23 Nov 2018 16:03:02 +0000
Subject: [R] Question Mixed-Design Anova in R
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC83695CFE0@FHSDB2D11-2.csu.mcmaster.ca>
References: <HE1PR0201MB21564DE830449F6C7B1C2AF3F5D40@HE1PR0201MB2156.eurprd02.prod.outlook.com>
 <15973_1542986588_wANFN77d006406_EFC4D978-C7D1-4DA5-8681-BAF817E030AF@gmail.com>,
 <ACD1644AA6C67E4FBD0C350625508EC83695CFE0@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <HE1PR0201MB21560C1E77542B3F9843E9B8F5D40@HE1PR0201MB2156.eurprd02.prod.outlook.com>

Dear John and Peter,


Thank you both for your answers. I am going to try the solutions you gave me!


Thanks again,

Lisa

________________________________
From: Fox, John <jfox at mcmaster.ca>
Sent: 23 November 2018 16:54:49
To: Lisa van der Burgh
Cc: r-help at R-project.org; peter dalgaard
Subject: RE: [R] Question Mixed-Design Anova in R

Dear Lisa,

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of peter
> dalgaard
> Sent: Friday, November 23, 2018 10:16 AM
> To: Lisa van der Burgh <407600ab at student.eur.nl>
> Cc: r-help at R-project.org
> Subject: Re: [R] Question Mixed-Design Anova in R
>
> You seem to be bringing in a ton of stuff without looking at features in base
> R...
>
> Check
>
> help(mauchly.test)
> help(anova.mlm)
>
> and examples therein. There are also options in the "car" package.

With respect to the latter, see in particular the O'Brien-Kaiser example in ?Anova.

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/


>
> -pd
>
> > On 23 Nov 2018, at 11:43 , Lisa van der Burgh <407600ab at student.eur.nl>
> wrote:
> >
> > Hi Everyone,
> >
> >
> >
> > I have a question about Mixed-Design Anova in R. I want to obtain Mauchly s
> test of Sphericity and the Greenhouse-Geisser correction. I have managed to
> do it in SPSS:
> >
> >
> >
> > GLM Measure1 Measure2 Measure3 Measure4 Measure5 Measure6 BY
> Grouping
> >
> >  /WSFACTOR=Measure 6 Polynomial
> >
> >  /METHOD=SSTYPE(3)
> >
> >  /PLOT=PROFILE(Measure*Grouping)
> >
> >  /CRITERIA=ALPHA(.05)
> >
> >  /WSDESIGN=Measure
> >
> >  /DESIGN=Grouping.
> >
> >
> >
> > I have tried to replicate this in R:
> >
> > library("dplyr")
> >
> > library("tidyr")
> >
> > library("ggplot2")
> >
> > library("ez")
> >
> >
> >
> > PatientID <- c(1:10)
> >
> > Measure1 <- c(3,5,7,4,NA,7,4,4,7,2)
> >
> > Measure2 <- c(1,2,5,6,8,9,5,NA,6,7)
> >
> > Measure3 <- c(3,3,5,7,NA,4,5,7,8,1)
> >
> > Measure4 <- c(1,2,5,NA,3,NA,6,7,3,6)
> >
> > Measure5 <- c(2,3,NA,8,3,5,6,3,6,4)
> >
> > Measure6 <- c(1,2,4,6,8,3,5,6,NA,4)
> >
> > Grouping <- c(1,0,1,1,1,0,0,1,1,0)
> >
> > dataframe <- data.frame(PatientID, Measure1, Measure2, Measure3,
> > Measure4, Measure5, Measure6, Grouping)
> >
> > dataframe$Grouping <- as.factor(dataframe$Grouping)
> >
> > dataframe
> >
> >
> >
> > ezPrecis(dataframe)
> >
> > glimpse(dataframe)
> >
> >
> >
> > dataframe %>% count(PatientID)
> >
> >
> >
> > dataframe %>% count(PatientID, Grouping, Measure1, Measure2,
> Measure3,
> > Measure4, Measure5, Measure6) %>%
> >
> >  filter(PatientID %in% c(1:243)) %>%
> >
> >  print(n = 10)
> >
> >
> >
> > # So, we have a mixed design with one between factor (Grouping) and 6
> within factors (Measure 1 to 6).
> >
> >
> >
> > dat_means <- dataframe %>%
> >
> >  group_by(Grouping, Measure1, Measure2, Measure3, Measure4,
> Measure5,
> > Measure6) %>%
> >
> >  summarise(mRT = mean(c(Measure1, Measure2, Measure3, Measure4,
> > Measure5, Measure6))) %>% ungroup()
> >
> > View(dat_means)
> >
> >
> >
> > ggplot(dat_means, aes(c(Measure1, Measure2, Measure3, Measure4,
> > Measure5, Measure6), mRT, colour = Grouping)) +
> >
> >  geom_line(aes(group = Grouping)) +
> >
> >  geom_point(aes(shape = Grouping), size = 3) +
> >
> >  facet_wrap(~group)
> >
> >
> >
> > ANOVA <- ezANOVA(dat, x, PatientID, within = .( c(Measure1, Measure2,
> > Measure3, Measure4, Measure5, Measure6)),
> >
> >                    between = Grouping, type = 3)
> >
> >
> >
> > print(ANOVA)
> >
> >
> >
> >
> >
> > However, this does not work. I know I am probably doing it completely
> wrong, but I do not know how to solve it. Besides that, I do not know what to
> fill in at the  x .
> >
> > Can somebody help me?
> >
> >
> >
> > Thank you in advance.
> >
> > Lisa
> >
> >
> >      [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000
> Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From j@ck@onmrodrigue@ @ending from gm@il@com  Sat Nov 24 02:02:04 2018
From: j@ck@onmrodrigue@ @ending from gm@il@com (Jackson Rodrigues)
Date: Fri, 23 Nov 2018 23:02:04 -0200
Subject: [R] TrendRaster function
Message-ID: <CAPL76w86cE4tBorbP+5xO42w_Npj1DwQcHmWgPfHj7tYh32tng@mail.gmail.com>

Dear all,

I am trying to run the codes of "greenbrown" package for detection in
raster time serie.

However the error below reported occurs.

#####
library(greenbrown)
data(ndvimap)
ndvimap
plot(ndvimap,8)

# calculate trend: annual aggregation method
AATmap <- TrendRaster(ndvimap$X1982.01.01, start=c(1982, 1), freq=12,
method="AAT", breaks=1)

Error in .calcTest(x[1:5], fun, na.rm, forcefun, forceapply) :
  cannot use this function
############

Could anyone help me to solve it?

Thank you,

Jackson

	[[alternative HTML version deleted]]


From @@himk@poor @ending from gm@il@com  Sat Nov 24 08:30:34 2018
From: @@himk@poor @ending from gm@il@com (Ashim Kapoor)
Date: Sat, 24 Nov 2018 13:00:34 +0530
Subject: [R] Help needed regarding dlm model on stats.stackexchange
Message-ID: <CAC8=1epdw3jD06KtjF6qt1sWfWWoJKXL4Jcqs4yzMwkyfWiv1g@mail.gmail.com>

Dear all,

I have created a time varying parameters regression. When I do that I have
a parameter which is AR1. I am not able to recover this parameter.

My query is posted here :

https://stats.stackexchange.com/questions/377295/unable-to-recover-time-varying-ar1-parameter-from-state-space-model

I did not receive a reply so I am posting here.

Many thanks,
Ashim.

	[[alternative HTML version deleted]]


From bpo@@en @ending from gm@il@com  Sat Nov 24 21:59:13 2018
From: bpo@@en @ending from gm@il@com (Boy Possen)
Date: Sat, 24 Nov 2018 21:59:13 +0100
Subject: [R] lme ->Error in getGroups.data.frame(dataMix, groups)
Message-ID: <CAFo30y3gsqJueRK-j93YC43qQLvceUKZ44bmESwmEP_Cy_ZFDA@mail.gmail.com>

The basic idea is to create a linear model in R such that FinH is explained
by SoilNkh, dDDSP, dDDSP2, Provenance, Site, Genotype and Block, where
SoilNkh, dDDSP and dDDSP2 are continuous covariates, Provenance, Site,
Genotype and Block are factors, Site and Provenance are fixed and Genotype
and Block are random. Also, Genotype is nested within Provenance and Block
within Site.

Since the order the variables go in is of importance, it should be a Anova
type-I with the parameters in following order:
FinH~SoilNkh,Site,dDDSP,dDDSP2,Provenance,Site:Provenance,Provenance/Genotype,Site/Block


For the fixed part I am ok? with either:

test31 <-lm(FinH~SoilNkh + Site + dDDSP + dDDSP2 + Provenance +
Site:Provenance ,data=d1)

test32 <-aov(FinH~SoilNkh + Site + dDDSP + dDDSP2 + Provenance +
Site:Provenance ,data=d1

When trying to specify the random-part, taking the above text as starting
point, trouble starts :)

I feel it should be of the form:

test64 <- lme(FinH~SoilNkh + Site + dDDSP + dDDSP2 + Provenance +
Site:Provenance,
            random = ~1|Provenance/Genotype + ~1|Site/Block,data=d1)

but I can't avoid the error

"Error in getGroups.data.frame(dataMix, groups) : invalid formula for
groups"

I am lost for clues, really, so any advice would be great! If any data
should be supplied, I'd be happy to provide of course, but can't (yet)
figure out how...

Thanks in advance for your time.


-- 
B.J.H.M. Possen

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Sat Nov 24 23:44:54 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sat, 24 Nov 2018 14:44:54 -0800
Subject: [R] lme ->Error in getGroups.data.frame(dataMix, groups)
In-Reply-To: <CAFo30y3gsqJueRK-j93YC43qQLvceUKZ44bmESwmEP_Cy_ZFDA@mail.gmail.com>
References: <CAFo30y3gsqJueRK-j93YC43qQLvceUKZ44bmESwmEP_Cy_ZFDA@mail.gmail.com>
Message-ID: <CAGxFJbT_-KnHPEK9apS8PNAfH+e=fRWYn+X8cwKj-n3oFu=1FA@mail.gmail.com>

In brief, your random effects formula syntax is wrong. You need to (re)
study ?lme or suitable tutorials for details of how to do what you want --
if you can with lme (e.g. crossed random effects are very difficult in lme,
much easier in lmer).

However, you should probably re-post on the r-sig-mixed-models list to
receive better and *more expert* help.

Cheers,
Bert


On Sat, Nov 24, 2018 at 2:31 PM Boy Possen <bpossen at gmail.com> wrote:

> The basic idea is to create a linear model in R such that FinH is explained
> by SoilNkh, dDDSP, dDDSP2, Provenance, Site, Genotype and Block, where
> SoilNkh, dDDSP and dDDSP2 are continuous covariates, Provenance, Site,
> Genotype and Block are factors, Site and Provenance are fixed and Genotype
> and Block are random. Also, Genotype is nested within Provenance and Block
> within Site.
>
> Since the order the variables go in is of importance, it should be a Anova
> type-I with the parameters in following order:
>
> FinH~SoilNkh,Site,dDDSP,dDDSP2,Provenance,Site:Provenance,Provenance/Genotype,Site/Block
>
>
> For the fixed part I am ok? with either:
>
> test31 <-lm(FinH~SoilNkh + Site + dDDSP + dDDSP2 + Provenance +
> Site:Provenance ,data=d1)
>
> test32 <-aov(FinH~SoilNkh + Site + dDDSP + dDDSP2 + Provenance +
> Site:Provenance ,data=d1
>
> When trying to specify the random-part, taking the above text as starting
> point, trouble starts :)
>
> I feel it should be of the form:
>
> test64 <- lme(FinH~SoilNkh + Site + dDDSP + dDDSP2 + Provenance +
> Site:Provenance,
>             random = ~1|Provenance/Genotype + ~1|Site/Block,data=d1)
>
> but I can't avoid the error
>
> "Error in getGroups.data.frame(dataMix, groups) : invalid formula for
> groups"
>
> I am lost for clues, really, so any advice would be great! If any data
> should be supplied, I'd be happy to provide of course, but can't (yet)
> figure out how...
>
> Thanks in advance for your time.
>
>
> --
> B.J.H.M. Possen
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @nnij@nh @ending from gm@il@com  Sun Nov 25 21:59:35 2018
From: @nnij@nh @ending from gm@il@com (Janh Anni)
Date: Sun, 25 Nov 2018 15:59:35 -0500
Subject: [R] wBoot Package
Message-ID: <CAFCoDdDExPJn7CUuFcWTw6i_9To0XOQ2Wk1HGWscGW5hVjyiPA@mail.gmail.com>

Hello R Experts!

I wonder if anyone is familiar with the wBoot package written by Neil
Weiss. I was trying to use the *boot.two.per* function in that package to
compute a bootstrapped two-sample hypothesis test for proportion.  Here"s
the *boot.two.per* script:

boot.two.per(x, y, parameter, stacked = TRUE, variable = NULL,

null.hyp = NULL, alternative = c("two.sided", "less", "greater"),

conf.level = 0.95, type = NULL, R = 9999)

The problem is that if I specify *mean* or *median *as the parameter for
the test, the script runs fine, but if I specify *proportion*, I get an
error message that *proportion* not found

Is there another way to specify proportion as the test parameter?

Thanks a lot!

Janh

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Mon Nov 26 01:06:18 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Sun, 25 Nov 2018 16:06:18 -0800
Subject: [R] wBoot Package
In-Reply-To: <CAFCoDdDExPJn7CUuFcWTw6i_9To0XOQ2Wk1HGWscGW5hVjyiPA@mail.gmail.com>
References: <CAFCoDdDExPJn7CUuFcWTw6i_9To0XOQ2Wk1HGWscGW5hVjyiPA@mail.gmail.com>
Message-ID: <0b07c2d2-af81-85c4-7304-450a198159eb@comcast.net>

Look at the function's help page:

No help there. The "parameter" argument is not defined in any 
substantive manner, and no examples other than `parameter=mean` appear 
in the help page.

(Now) Look at the code. The parameter argument is expected to be a 
function. There is no function named `proportion` in base R that I know 
of and:

 > wBoot::proportion
Error: 'proportion' is not an exported object from 'namespace:wBoot'
 > wBoot:::proportion
Error in get(name, envir = asNamespace(pkg), inherits = FALSE) :
 ? object 'proportion' not found


The code in the function you are asking about does begin with:

 ?? {

 ???? proportion <- mean

However, that named entity, `proportion`,? is never referenced in? code 
that follows, so it appears that the package author started down one 
path and then abandoned that line of code and did something else. I 
suspect that the code was written so that `mean` was inteended to 
deliver a test of equal proportions using the normal approximation to a 
binomial test. There is a waring in the help page that would apply to 
situations where the proportion is far from 0.5.? You are advised that 
not all packages are written with scrupulous quality control and peer 
review.

You should have read the posting guide. It would have told you that you 
should have addressed your concerns to the package author first, and 
also posted in plain text.

-- 

David

On 11/25/18 12:59 PM, Janh Anni wrote:
> Hello R Experts!
>
> I wonder if anyone is familiar with the wBoot package written by Neil
> Weiss. I was trying to use the *boot.two.per* function in that package to
> compute a bootstrapped two-sample hypothesis test for proportion.  Here"s
> the *boot.two.per* script:
>
> boot.two.per(x, y, parameter, stacked = TRUE, variable = NULL,
>
> null.hyp = NULL, alternative = c("two.sided", "less", "greater"),
>
> conf.level = 0.95, type = NULL, R = 9999)
>
> The problem is that if I specify *mean* or *median *as the parameter for
> the test, the script runs fine, but if I specify *proportion*, I get an
> error message that *proportion* not found
>
> Is there another way to specify proportion as the test parameter?
>
> Thanks a lot!
>
> Janh
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From n@ture@lily40 @ending from gm@il@com  Mon Nov 26 08:02:28 2018
From: n@ture@lily40 @ending from gm@il@com (LilyNature)
Date: Sun, 25 Nov 2018 23:02:28 -0800
Subject: [R] How to fix Error in glim.fit 'fit'not found in GAMLSS regression
Message-ID: <CABnRKwUpgxsNsOJXj9=XkTFy3LtEP2h4fM3j-2vLLgbMwLJYMw@mail.gmail.com>

I am trying to execute gamlss's zero-inflated beta regression model as
below> It works fine with variable V255 but through an error for simialr
variable V256 as


     Error in glim.fit(f = nu.object, X = nu.X, y = y, w = w, fv = nu, os =
nu.offset,  :
          object 'fit' not foundim.fit. Object 'fit' not found.
Any suggestions to fix this issue ?
Code and model.

    library(tidyverse)
    library(gamlss)

    ddf<-as_tibble(structure(c(0, 0.250601410865784, 0, 0, 0, 0, 0, 0, 0,
0, 0,
                                0, 0, 0, 0.0859533622860909, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0,
                                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0.070460669696331,
                                0, 0, 0, 0.0223423503339291, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0,
                                0, 0, 0, 0, 0, 0, 0, 0, 0,
0.249115347862244, 0, 0, 0, 0, 0,
                                0, 0, 0, 0, 0, 0, 0, 0.135218366980553, 0,
0, 0, 0, 0, 0, 0,
                                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0.069370836019516,
                                0, 0, 0, 0.0225795395672321, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0,
                                0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6,
7, 8, 9, 10, 11, 12,
                                13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,
24, 25, 26, 27, 28,
                                29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,
40, 41, 42, 43, 44,
                                45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,
56, 57, 58, 59, 60,
                                61, 62, 63, 64, 65), .Dim = c(65L, 3L),
.Dimnames = list(NULL,

             c("V255", "V256", "year"))))
    ddf
    #Model for variable V255, it works
    model1<-gamlss(ddf$V255~ddf$year, sigma.fo=~ddf$year, nu.fo=~ddf$year,
tau.fo=~ddf$year, family=BEINF)
    model1
    #Model for varable V256; it through an error
    model2<-gamlss(ddf$V256~ddf$year, sigma.fo=~ddf$year, nu.fo=~ddf$year,
tau.fo=~ddf$year, family=BEINF)

	[[alternative HTML version deleted]]


From pd@lgd @ending from gm@il@com  Mon Nov 26 10:41:28 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Mon, 26 Nov 2018 10:41:28 +0100
Subject: [R] wBoot Package
In-Reply-To: <0b07c2d2-af81-85c4-7304-450a198159eb@comcast.net>
References: <CAFCoDdDExPJn7CUuFcWTw6i_9To0XOQ2Wk1HGWscGW5hVjyiPA@mail.gmail.com>
 <0b07c2d2-af81-85c4-7304-450a198159eb@comcast.net>
Message-ID: <21D6B9B9-C83E-4611-88B7-EB870A26387A@gmail.com>

This could possibly be a botched attempt at telling "the system" that one could use proportion() as synonymous with mean(). That would obviously fail due to scoping rules, but maybe an earlier version used <<- (?). Anyways, you could take the hint: proportions are just means of 0-1 variables... 

> On 26 Nov 2018, at 01:06 , David Winsemius <dwinsemius at comcast.net> wrote:
> 
> The code in the function you are asking about does begin with:
> 
>    {
> 
>      proportion <- mean
> 
> However, that named entity, `proportion`,  is never referenced in  code that follows, so it appears that the package author started down one path and then abandoned that line of code and did something else. 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From m@@ternh@ttt @ending from gm@il@com  Mon Nov 26 13:13:03 2018
From: m@@ternh@ttt @ending from gm@il@com (Thanh Tran)
Date: Mon, 26 Nov 2018 21:13:03 +0900
Subject: [R] Perspective Plotting - 3D Plotting in R
Message-ID: <CAHjanSBX+YNm_uFcUsmXxB6bC5OjCWAQMG6jL0TzrM6gkyAYHQ@mail.gmail.com>

Dear all,



I'm trying to plot a surface over the x-y plane. In my data, the response
is KIC, and four factors are AC, AV, T, and Temp. A typical second-degree
response modeling is as follows


> data<-read.csv("2.csv", header =T)

> mod <- lm(KIC~AC+I(AC^2)+AV+I(AV^2)+T+I(T^2)+Temp+I(Temp^2)+AC:AV+AC:T+AC:Temp+AV:T+AV:Temp+T:Temp,

+ data = data)



I want to have a response surface of KIC with two factors, i.e., AC and AV
as shown in the attached figure.

When I run the below code, I have a problem which indicates ?object 'AC'
not found? even though I added ?data = data?



> persp(AC,AV,KIC~ AC + I(AC^2) + AV + I(AV^2) + AC:AV,image = TRUE,theta=30,

+ data = data)

Error in persp(AC, AV, KIC ~ AC + I(AC^2) + AV + I(AV^2) + AC:AV,
image = TRUE,  :

  object 'AC' not found



If anyone has any experience about what would be the reason for error or
how I can solve it? Is there other simple function to plot the response
surface?

I really appreciate your support and help.



Best regards,

Nhat Tran



Ps: I also added a CSV file for practicing R.

From m@@ternh@ttt @ending from gm@il@com  Mon Nov 26 13:38:27 2018
From: m@@ternh@ttt @ending from gm@il@com (Thanh Tran)
Date: Mon, 26 Nov 2018 21:38:27 +0900
Subject: [R] Perspective Plotting - 3D Plotting in R
In-Reply-To: <AM6PR04MB5719254C87F21240E03291D192D70@AM6PR04MB5719.eurprd04.prod.outlook.com>
References: <CAHjanSBX+YNm_uFcUsmXxB6bC5OjCWAQMG6jL0TzrM6gkyAYHQ@mail.gmail.com>
 <AM6PR04MB5719254C87F21240E03291D192D70@AM6PR04MB5719.eurprd04.prod.outlook.com>
Message-ID: <CAHjanSDY4kLwE40tzfr3ddc7PaW7D7O6vBLebDYnGgOD_-Sk2g@mail.gmail.com>

Hi  Farzaneh
If someones answer your question, they will send to your email that you
used in the system.
Best regards,
Nhat Tran.

V?o Th 2, 26 thg 11, 2018 va?o lu?c 21:20 Ahmadzadeh Siahrood Farzaneh <
farzaneh.ahmadzadeh at scania.com> ?? vi?t:

> Hi Tran ,
> It is not relevant to your answer but I want to ask you where do you look
> for the answer ? I have posted a question but Don?t know where goes the
> relevant answers. I am new for this system if you could help me I would
> appreciate.
> Best ,
> Farzaneh
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Thanh Tran
> Sent: den 26 november 2018 13:13
> To: r-help at r-project.org
> Subject: [R] Perspective Plotting - 3D Plotting in R
>
> Dear all,
>
>
>
> I'm trying to plot a surface over the x-y plane. In my data, the response
> is KIC, and four factors are AC, AV, T, and Temp. A typical second-degree
> response modeling is as follows
>
>
> > data<-read.csv("2.csv", header =T)
>
> > mod <-
> > lm(KIC~AC+I(AC^2)+AV+I(AV^2)+T+I(T^2)+Temp+I(Temp^2)+AC:AV+AC:T+AC:Tem
> > p+AV:T+AV:Temp+T:Temp,
>
> + data = data)
>
>
>
> I want to have a response surface of KIC with two factors, i.e., AC and AV
> as shown in the attached figure.
>
> When I run the below code, I have a problem which indicates ?object 'AC'
> not found? even though I added ?data = data?
>
>
>
> > persp(AC,AV,KIC~ AC + I(AC^2) + AV + I(AV^2) + AC:AV,image =
> > TRUE,theta=30,
>
> + data = data)
>
> Error in persp(AC, AV, KIC ~ AC + I(AC^2) + AV + I(AV^2) + AC:AV, image =
> TRUE,  :
>
>   object 'AC' not found
>
>
>
> If anyone has any experience about what would be the reason for error or
> how I can solve it? Is there other simple function to plot the response
> surface?
>
> I really appreciate your support and help.
>
>
>
> Best regards,
>
> Nhat Tran
>
>
>
> Ps: I also added a CSV file for practicing R.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@r@h@go@lee @ending from gm@il@com  Mon Nov 26 15:22:02 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Mon, 26 Nov 2018 09:22:02 -0500
Subject: [R] Perspective Plotting - 3D Plotting in R
In-Reply-To: <CAHjanSBX+YNm_uFcUsmXxB6bC5OjCWAQMG6jL0TzrM6gkyAYHQ@mail.gmail.com>
References: <CAHjanSBX+YNm_uFcUsmXxB6bC5OjCWAQMG6jL0TzrM6gkyAYHQ@mail.gmail.com>
Message-ID: <CAM_vjumJ2L7pf+En+Vd9ri8FqQofyKCHHfvibKDdFyiRc5oG7Q@mail.gmail.com>

Hi,

Checking the help for persp shows that it doesn't take a data
argument. Assuming the rest of your code is correct (since no
reproducible example, it's impossible to check), you could do

with(data, persp(AC,AV,KIC~ AC + I(AC^2) + AV + I(AV^2) + AC:AV,image
= TRUE,theta=30))

But. I highly doubt that anything you're doing in that line of code is
correct. There's no image argument either, and x and y must be the
locations of grid lines in ascending order, not just all of your data.
z must be the value to be plotted at those locations.

So what you probably need to do, is figure out what grid points you
want to use, and use predict with your mod object to get the z values
at those points. Then you can plot the corresponding surface. The
first example in ?persp might give you some insight.

Sarah


On Mon, Nov 26, 2018 at 7:15 AM Thanh Tran <masternhattt at gmail.com> wrote:
>
> Dear all,
>
>
>
> I'm trying to plot a surface over the x-y plane. In my data, the response
> is KIC, and four factors are AC, AV, T, and Temp. A typical second-degree
> response modeling is as follows
>
>
> > data<-read.csv("2.csv", header =T)
>
> > mod <- lm(KIC~AC+I(AC^2)+AV+I(AV^2)+T+I(T^2)+Temp+I(Temp^2)+AC:AV+AC:T+AC:Temp+AV:T+AV:Temp+T:Temp,
>
> + data = data)
>
>
>
> I want to have a response surface of KIC with two factors, i.e., AC and AV
> as shown in the attached figure.
>
> When I run the below code, I have a problem which indicates ?object 'AC'
> not found? even though I added ?data = data?
>
>
>
> > persp(AC,AV,KIC~ AC + I(AC^2) + AV + I(AV^2) + AC:AV,image = TRUE,theta=30,
>
> + data = data)
>
> Error in persp(AC, AV, KIC ~ AC + I(AC^2) + AV + I(AV^2) + AC:AV,
> image = TRUE,  :
>
>   object 'AC' not found
>
>
>
> If anyone has any experience about what would be the reason for error or
> how I can solve it? Is there other simple function to plot the response
> surface?
>
> I really appreciate your support and help.
>
>
>
> Best regards,
>
> Nhat Tran
>



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From murdoch@dunc@n @ending from gm@il@com  Mon Nov 26 16:17:43 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Mon, 26 Nov 2018 10:17:43 -0500
Subject: [R] Perspective Plotting - 3D Plotting in R
In-Reply-To: <CAHjanSBX+YNm_uFcUsmXxB6bC5OjCWAQMG6jL0TzrM6gkyAYHQ@mail.gmail.com>
References: <CAHjanSBX+YNm_uFcUsmXxB6bC5OjCWAQMG6jL0TzrM6gkyAYHQ@mail.gmail.com>
Message-ID: <0673f654-addd-e3ce-9417-67ffd35e8de1@gmail.com>

On 26/11/2018 7:13 AM, Thanh Tran wrote:
> Dear all,
> 
> 
> 
> I'm trying to plot a surface over the x-y plane. In my data, the response
> is KIC, and four factors are AC, AV, T, and Temp. A typical second-degree
> response modeling is as follows
> 
> 
>> data<-read.csv("2.csv", header =T)
> 
>> mod <- lm(KIC~AC+I(AC^2)+AV+I(AV^2)+T+I(T^2)+Temp+I(Temp^2)+AC:AV+AC:T+AC:Temp+AV:T+AV:Temp+T:Temp,
> 
> + data = data)

For two factors, you could use this code:

pred <- function(AC, AV, Temp, T) predict(mod, newdata = data.frame(AC, 
AV, Temp, T))

library(rgl)
persp3d(pred, xlim = c(-1, 1),  # The range of values for AC
               ylim = c(-1, 1),  # The range for AV
               xlab = "AC", ylab = "AV", zlab = "KIC",
               colour = rainbow,  # or a fixed colour, or another fn
               otherargs = list(Temp = 0, T = 0))

The otherargs list should contain the values of the two factors to your 
model that you are holding fixed while plotting the two that are not fixed.

This Stackoverflow answer 
https://stackoverflow.com/questions/53349811/how-to-draw-a-response-surface-plot-for-three-factorial-design/53350259#53350259 
describes a way to plot the response to 3 factors at once.

Duncan Murdoch

> 
> 
> 
> I want to have a response surface of KIC with two factors, i.e., AC and AV
> as shown in the attached figure.
> 
> When I run the below code, I have a problem which indicates ?object 'AC'
> not found? even though I added ?data = data?
> 
> 
> 
>> persp(AC,AV,KIC~ AC + I(AC^2) + AV + I(AV^2) + AC:AV,image = TRUE,theta=30,
> 
> + data = data)
> 
> Error in persp(AC, AV, KIC ~ AC + I(AC^2) + AV + I(AV^2) + AC:AV,
> image = TRUE,  :
> 
>    object 'AC' not found
> 
> 
> 
> If anyone has any experience about what would be the reason for error or
> how I can solve it? Is there other simple function to plot the response
> surface?
> 
> I really appreciate your support and help.
> 
> 
> 
> Best regards,
> 
> Nhat Tran
> 
> 
> 
> Ps: I also added a CSV file for practicing R.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From to@inolofin14 @ending from gm@il@com  Mon Nov 26 17:10:44 2018
From: to@inolofin14 @ending from gm@il@com (Olofinsao Tosin)
Date: Mon, 26 Nov 2018 17:10:44 +0100
Subject: [R] CenReg download
Message-ID: <CALMnu6RduQGENrguAdEpPvdxBGey7KhTdZh+f0_5E2kiLibGvg@mail.gmail.com>

Greetings.

Please I need cenReg function and every package useful for Tobit regression
on R.

Kindly provide me the link for the download or attach the zip file to this
mail.

I expect your positive response soon.

Thank you very much.

Best regards,
Tosin Olofinsao

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Nov 26 18:02:49 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 26 Nov 2018 09:02:49 -0800
Subject: [R] CenReg download
In-Reply-To: <CALMnu6RduQGENrguAdEpPvdxBGey7KhTdZh+f0_5E2kiLibGvg@mail.gmail.com>
References: <CALMnu6RduQGENrguAdEpPvdxBGey7KhTdZh+f0_5E2kiLibGvg@mail.gmail.com>
Message-ID: <0734B8F8-D224-473D-8B40-34025EB3B9A7@dcn.davis.ca.us>

http://lmgtfy.com/?q=cenReg

Notice that you will need to use the install.packages function to install the package, and then the library function to attach it to the function search path.

On November 26, 2018 8:10:44 AM PST, Olofinsao Tosin <tosinolofin14 at gmail.com> wrote:
>Greetings.
>
>Please I need cenReg function and every package useful for Tobit
>regression
>on R.
>
>Kindly provide me the link for the download or attach the zip file to
>this
>mail.
>
>I expect your positive response soon.
>
>Thank you very much.
>
>Best regards,
>Tosin Olofinsao
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From dc@rl@on @ending from t@mu@edu  Mon Nov 26 18:04:52 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Mon, 26 Nov 2018 17:04:52 +0000
Subject: [R] CenReg download
In-Reply-To: <CALMnu6RduQGENrguAdEpPvdxBGey7KhTdZh+f0_5E2kiLibGvg@mail.gmail.com>
References: <CALMnu6RduQGENrguAdEpPvdxBGey7KhTdZh+f0_5E2kiLibGvg@mail.gmail.com>
Message-ID: <04093bdd4d5a40048667599caee9f37b@tamu.edu>

Perhaps you mean the censReg function in the censReg package? You obtain it using install.packages("censReg") and then loading it with library(censReg). As for other Tobit regression packages, Google "tobit regression r" works very well.

Your question suggests that you are just learning about R. You might find this list useful:

https://goo.gl/huajyf

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352



-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Olofinsao Tosin
Sent: Monday, November 26, 2018 10:11 AM
To: r-help at r-project.org
Subject: [R] CenReg download

Greetings.

Please I need cenReg function and every package useful for Tobit regression
on R.

Kindly provide me the link for the download or attach the zip file to this
mail.

I expect your positive response soon.

Thank you very much.

Best regards,
Tosin Olofinsao

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Nov 26 18:35:45 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 26 Nov 2018 09:35:45 -0800
Subject: [R] TrendRaster function
In-Reply-To: <CAPL76w86cE4tBorbP+5xO42w_Npj1DwQcHmWgPfHj7tYh32tng@mail.gmail.com>
References: <CAPL76w86cE4tBorbP+5xO42w_Npj1DwQcHmWgPfHj7tYh32tng@mail.gmail.com>
Message-ID: <8730F252-C68A-46A2-8D9B-B1074B062DA9@dcn.davis.ca.us>

a) You had to go out of your way to even install this package... it is lonly available on R-forge. This kind of question seems likely to require support from the package author. (Use the"maintainer" function to identify the author.)

b) You may find a similar functionality in a CRAN package. Try describing what you want to accomplish on the R-sig-geo mailing list.

On November 23, 2018 5:02:04 PM PST, Jackson Rodrigues <jacksonmrodrigues at gmail.com> wrote:
>Dear all,
>
>I am trying to run the codes of "greenbrown" package for detection in
>raster time serie.
>
>However the error below reported occurs.
>
>#####
>library(greenbrown)
>data(ndvimap)
>ndvimap
>plot(ndvimap,8)
>
># calculate trend: annual aggregation method
>AATmap <- TrendRaster(ndvimap$X1982.01.01, start=c(1982, 1), freq=12,
>method="AAT", breaks=1)
>
>Error in .calcTest(x[1:5], fun, na.rm, forcefun, forceapply) :
>  cannot use this function
>############
>
>Could anyone help me to solve it?
>
>Thank you,
>
>Jackson
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @nnij@nh @ending from gm@il@com  Mon Nov 26 18:50:36 2018
From: @nnij@nh @ending from gm@il@com (Janh Anni)
Date: Mon, 26 Nov 2018 12:50:36 -0500
Subject: [R] wBoot Package
In-Reply-To: <0b07c2d2-af81-85c4-7304-450a198159eb@comcast.net>
References: <CAFCoDdDExPJn7CUuFcWTw6i_9To0XOQ2Wk1HGWscGW5hVjyiPA@mail.gmail.com>
 <0b07c2d2-af81-85c4-7304-450a198159eb@comcast.net>
Message-ID: <CAFCoDdB+3TcrtRJw9h=Z6SboY+g3OVjdVRsDHv230mEFv8XZJg@mail.gmail.com>

Hello David, Peter,

Thank you so much for taking the trouble to look into this.  The user guide
for the *boot.two.per* function contains this statement:

*Obtains an independent-samples confidence interval and (optionally)
performs an independent samples*
*hypothesis test for the difference between two population means, medians,
proportions,*
*or some user-defined function, using the percentile bootstrap method*.

That was why I assumed it could handle the bootstrapped two-sample test for
proportions as well.  I actually tried to contact the author before
bringing the issue to R-Help, but found that unfortunately he passed away
in 2016.  Assuming there's no resolution to this problem, would you know of
any other package or function that can bootstrap one- and two-sample
proportion tests?

Thanks again!

Janh


On Sun, Nov 25, 2018 at 7:06 PM David Winsemius <dwinsemius at comcast.net>
wrote:

> Look at the function's help page:
>
> No help there. The "parameter" argument is not defined in any
> substantive manner, and no examples other than `parameter=mean` appear
> in the help page.
>
> (Now) Look at the code. The parameter argument is expected to be a
> function. There is no function named `proportion` in base R that I know
> of and:
>
>  > wBoot::proportion
> Error: 'proportion' is not an exported object from 'namespace:wBoot'
>  > wBoot:::proportion
> Error in get(name, envir = asNamespace(pkg), inherits = FALSE) :
>    object 'proportion' not found
>
>
> The code in the function you are asking about does begin with:
>
>     {
>
>       proportion <- mean
>
> However, that named entity, `proportion`,  is never referenced in  code
> that follows, so it appears that the package author started down one
> path and then abandoned that line of code and did something else. I
> suspect that the code was written so that `mean` was inteended to
> deliver a test of equal proportions using the normal approximation to a
> binomial test. There is a waring in the help page that would apply to
> situations where the proportion is far from 0.5.  You are advised that
> not all packages are written with scrupulous quality control and peer
> review.
>
> You should have read the posting guide. It would have told you that you
> should have addressed your concerns to the package author first, and
> also posted in plain text.
>
> --
>
> David
>
> On 11/25/18 12:59 PM, Janh Anni wrote:
> > Hello R Experts!
> >
> > I wonder if anyone is familiar with the wBoot package written by Neil
> > Weiss. I was trying to use the *boot.two.per* function in that package to
> > compute a bootstrapped two-sample hypothesis test for proportion.  Here"s
> > the *boot.two.per* script:
> >
> > boot.two.per(x, y, parameter, stacked = TRUE, variable = NULL,
> >
> > null.hyp = NULL, alternative = c("two.sided", "less", "greater"),
> >
> > conf.level = 0.95, type = NULL, R = 9999)
> >
> > The problem is that if I specify *mean* or *median *as the parameter for
> > the test, the script runs fine, but if I specify *proportion*, I get an
> > error message that *proportion* not found
> >
> > Is there another way to specify proportion as the test parameter?
> >
> > Thanks a lot!
> >
> > Janh
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From to@inolofin14 @ending from gm@il@com  Mon Nov 26 18:58:30 2018
From: to@inolofin14 @ending from gm@il@com (Olofinsao Tosin)
Date: Mon, 26 Nov 2018 18:58:30 +0100
Subject: [R] CenReg download
In-Reply-To: <04093bdd4d5a40048667599caee9f37b@tamu.edu>
References: <CALMnu6RduQGENrguAdEpPvdxBGey7KhTdZh+f0_5E2kiLibGvg@mail.gmail.com>
 <04093bdd4d5a40048667599caee9f37b@tamu.edu>
Message-ID: <CALMnu6QS2joCgK1cSfr+z6S-oj8vFPUp8VuzHSURqFidPMqGgg@mail.gmail.com>

Thanks very much.

Best regards,
Tosin Olofinsao
On Nov 26, 2018 6:04 PM, "David L Carlson" <dcarlson at tamu.edu> wrote:

> Perhaps you mean the censReg function in the censReg package? You obtain
> it using install.packages("censReg") and then loading it with
> library(censReg). As for other Tobit regression packages, Google "tobit
> regression r" works very well.
>
> Your question suggests that you are just learning about R. You might find
> this list useful:
>
> https://goo.gl/huajyf
>
> ----------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77843-4352
>
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Olofinsao Tosin
> Sent: Monday, November 26, 2018 10:11 AM
> To: r-help at r-project.org
> Subject: [R] CenReg download
>
> Greetings.
>
> Please I need cenReg function and every package useful for Tobit regression
> on R.
>
> Kindly provide me the link for the download or attach the zip file to this
> mail.
>
> I expect your positive response soon.
>
> Thank you very much.
>
> Best regards,
> Tosin Olofinsao
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From v@rin@@ch@ @ending from y@hoo@fr  Mon Nov 26 21:36:49 2018
From: v@rin@@ch@ @ending from y@hoo@fr (varin sacha)
Date: Mon, 26 Nov 2018 20:36:49 +0000 (UTC)
Subject: [R] Bootstrapped CIs of MSE for (G)AM model
In-Reply-To: <986486484.8767958.1542928793315@mail.yahoo.com>
References: <1399535201.8641093.1542918978430.ref@mail.yahoo.com>
 <1399535201.8641093.1542918978430@mail.yahoo.com>
 <15a3ca63-6af4-2818-01b7-3c4186676201@sapo.pt>
 <d48f6ff0-2659-33c2-1386-7c2cb03afe0b@sapo.pt>
 <986486484.8767958.1542928793315@mail.yahoo.com>
Message-ID: <1758803015.11692442.1543264609683@mail.yahoo.com>


R-experts,

I still can't get the nonparametric studentized bootstrapped CIs. How can I solve the problem ?
Here is the reproducible example :

?#?#?#?#?#?#?#?#?#?#?#?#?#?#?# #
library(ISLR)
library(earth)
library(boot)
?
?# function to obtain MSE
?MSE <- function(data, indices, formula) {
? ? d <- data[indices, ] # allows boot to select sample
? ? fit <- earth(formula, data = d)
? ? ypred <- predict(fit)
? ? mean((d[["wage"]] - ypred)^2)
?}
?
?data(Wage)
?
?# Make the results reproducible
?set.seed(1234)
?
?# bootstrapping with 1000 replications
?results <- boot(data = Wage, statistic = MSE,
? ??????????????? R = 1000, formula = wage~age+as.factor(education)+year)

?
# get 95% confidence intervals
# type = "bca" is throwing an error
ci.type <- c("norm","basic", "stud", "perc")
boot.ci(results, type = ci.type)

# view results
results
plot(results)

# get 95% confidence intervals 
boot.ci(results, type="all")
?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?# #?#?#







Le vendredi 23 novembre 2018 ? 00:20:41 UTC+1, varin sacha via R-help <r-help at r-project.org> a ?crit : 





Great, many thanks Rui, it perfectly works.

Best,








Le jeudi 22 novembre 2018 ? 23:45:15 UTC+1, Rui Barradas <ruipbarradas at sapo.pt> a ?crit : 





Hello,

Sorry, there's a close parenthesis too many in the call to boot, the 
very last one.
Delete it and it runs with no errors.

Rui Barradas

?s 21:55 de 22/11/2018, Rui Barradas escreveu:
> Hello,
> 
> There were several errors with your code. The following works but with 
> the other CI types.
> 
> 
> library(ISLR)
> library(mgcv)
> library(boot)
> 
> # function to obtain MSE
> MSE <- function(data, indices, formula) {
>? ? d <- data[indices, ] # allows boot to select sample
>? ? fit <- gam(formula, data = d)
>? ? ypred <- predict(fit)
>? ? mean((d[["wage"]] - ypred)^2)
> }
> 
> data(Wage)
> 
> # Make the results reproducible
> set.seed(1234)
> 
> # bootstrapping with 1000 replications
> results <- boot(data = Wage, statistic = MSE,
>? ??????????????? R = 1000, formula = wage ~ education + s(age, bs = 
> "ps") + year))
> 
> # get 95% confidence intervals
> # type = "bca" is throwing an error
> ci.type <- c("norm","basic", "stud", "perc")
> boot.ci(results, type = ci.type)
> 
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 20:36 de 22/11/2018, varin sacha via R-help escreveu:
>> Dear R-experts,
>>
>> I am trying to get the bootstrapped confidence intervals of Mean 
>> squared error (MSE) for a (G)AM model. I get an error message.
>> Here below the reproducible R code. Many thanks for your response.
>>
>> ####################
>>
>>
>> install.packages("ISLR")
>>
>> library(ISLR)
>>
>> install.packages("mgcv")
>>
>> library(mgcv)
>>
>> install.packages("boot")
>>
>> library(boot)
>>
>> #MSE calculation
>>
>> n=dim(Wage)[1]
>>
>> p=0.667
>>
>> GAM1<-gam(wage ~education+s(age,bs="ps")+year,data=Wage)
>>
>> sam=sample(1?:n,floor(p*n),replace=FALSE)
>>
>>
>> Training =Wage [sam,]
>>
>> Testing = Wage [-sam,]
>>
>>
>> ypred=predict(GAM1,newdata=Testing)
>>
>> y=Testing$wage
>>
>> MSE = mean((y-ypred)^2)
>>
>>
>> # Bootstrap 95% CI for MSE
>>
>> # function to obtain MSE
>> MSE <- function(formula, data, indices) {
>> ???d <- data[indices,] # allows boot to select sample
>> ???fit <- gam(formula, data=d)
>> ???return(MSE(fit))
>>
>> } # bootstrapping with 1000 replications
>> results <- boot(data=Wage, statistic=MSE,
>> ??? R=1000, formula=gam(wage ~education+s(age,bs="ps")+year,data=Wage)
>>
>> )
>> # get 95% confidence intervals
>> boot.ci(results, type="bca")
>>
>> ##########################
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From m@@ternh@ttt @ending from gm@il@com  Tue Nov 27 06:24:33 2018
From: m@@ternh@ttt @ending from gm@il@com (Thanh Tran)
Date: Tue, 27 Nov 2018 14:24:33 +0900
Subject: [R] Perspective Plotting - 3D Plotting in R
In-Reply-To: <0673f654-addd-e3ce-9417-67ffd35e8de1@gmail.com>
References: <CAHjanSBX+YNm_uFcUsmXxB6bC5OjCWAQMG6jL0TzrM6gkyAYHQ@mail.gmail.com>
 <0673f654-addd-e3ce-9417-67ffd35e8de1@gmail.com>
Message-ID: <CAHjanSDa0XOLjFpuOEbzgNjcLoRmreubuKq-FrrmTAZZrOBGPg@mail.gmail.com>

Hi Sarah Goslee and Duncan Murdoch
Thank you so much for your answers. Now I can plot the surface needed.
Best regards,
Nhat Tran.

V?o Th 3, 27 thg 11, 2018 va?o lu?c 00:17 Duncan Murdoch <
murdoch.duncan at gmail.com> ?? vi?t:

> On 26/11/2018 7:13 AM, Thanh Tran wrote:
> > Dear all,
> >
> >
> >
> > I'm trying to plot a surface over the x-y plane. In my data, the response
> > is KIC, and four factors are AC, AV, T, and Temp. A typical second-degree
> > response modeling is as follows
> >
> >
> >> data<-read.csv("2.csv", header =T)
> >
> >> mod <-
> lm(KIC~AC+I(AC^2)+AV+I(AV^2)+T+I(T^2)+Temp+I(Temp^2)+AC:AV+AC:T+AC:Temp+AV:T+AV:Temp+T:Temp,
> >
> > + data = data)
>
> For two factors, you could use this code:
>
> pred <- function(AC, AV, Temp, T) predict(mod, newdata = data.frame(AC,
> AV, Temp, T))
>
> library(rgl)
> persp3d(pred, xlim = c(-1, 1),  # The range of values for AC
>                ylim = c(-1, 1),  # The range for AV
>                xlab = "AC", ylab = "AV", zlab = "KIC",
>                colour = rainbow,  # or a fixed colour, or another fn
>                otherargs = list(Temp = 0, T = 0))
>
> The otherargs list should contain the values of the two factors to your
> model that you are holding fixed while plotting the two that are not fixed.
>
> This Stackoverflow answer
>
> https://stackoverflow.com/questions/53349811/how-to-draw-a-response-surface-plot-for-three-factorial-design/53350259#53350259
> describes a way to plot the response to 3 factors at once.
>
> Duncan Murdoch
>
> >
> >
> >
> > I want to have a response surface of KIC with two factors, i.e., AC and
> AV
> > as shown in the attached figure.
> >
> > When I run the below code, I have a problem which indicates ?object 'AC'
> > not found? even though I added ?data = data?
> >
> >
> >
> >> persp(AC,AV,KIC~ AC + I(AC^2) + AV + I(AV^2) + AC:AV,image =
> TRUE,theta=30,
> >
> > + data = data)
> >
> > Error in persp(AC, AV, KIC ~ AC + I(AC^2) + AV + I(AV^2) + AC:AV,
> > image = TRUE,  :
> >
> >    object 'AC' not found
> >
> >
> >
> > If anyone has any experience about what would be the reason for error or
> > how I can solve it? Is there other simple function to plot the response
> > surface?
> >
> > I really appreciate your support and help.
> >
> >
> >
> > Best regards,
> >
> > Nhat Tran
> >
> >
> >
> > Ps: I also added a CSV file for practicing R.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From tolulope@de@gbo @ending from gm@il@com  Tue Nov 27 10:53:03 2018
From: tolulope@de@gbo @ending from gm@il@com (Tolulope Adeagbo)
Date: Tue, 27 Nov 2018 10:53:03 +0100
Subject: [R] EXAMPLE OF HOW TO USE R FOR EXPONENTIAL DISTRIBUTION &
 EXPONENTIAL REGRESSION
Message-ID: <CAL+C-=65nn=uDJqD2qm5jOKzVTyGTkFzdqo2BvUc9wtkKVzC3g@mail.gmail.com>

Good day,
Please i nee useful materials to understand how to use R for exponential
regression.
Many thanks.

	[[alternative HTML version deleted]]


From @@r@h@go@lee @ending from gm@il@com  Tue Nov 27 12:28:03 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Tue, 27 Nov 2018 06:28:03 -0500
Subject: [R] EXAMPLE OF HOW TO USE R FOR EXPONENTIAL DISTRIBUTION &
 EXPONENTIAL REGRESSION
In-Reply-To: <CAL+C-=65nn=uDJqD2qm5jOKzVTyGTkFzdqo2BvUc9wtkKVzC3g@mail.gmail.com>
References: <CAL+C-=65nn=uDJqD2qm5jOKzVTyGTkFzdqo2BvUc9wtkKVzC3g@mail.gmail.com>
Message-ID: <CAM_vjumerzyKKwXdVJ91A+Co+meW2zPFQvM3Jo0goA-HGULBOw@mail.gmail.com>

Hi,

Using rseek.org to search for exponential regression turns up lots of
information, as does using Google.

Which tutorials have you worked thru already, and what else are you looking
for?

Sarah

On Tue, Nov 27, 2018 at 5:44 AM Tolulope Adeagbo <tolulopeadeagbo at gmail.com>
wrote:

> Good day,
> Please i nee useful materials to understand how to use R for exponential
> regression.
> Many thanks.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Sarah Goslee (she/her)
http://www.sarahgoslee.com

	[[alternative HTML version deleted]]


From m@@ternh@ttt @ending from gm@il@com  Tue Nov 27 13:53:38 2018
From: m@@ternh@ttt @ending from gm@il@com (Thanh Tran)
Date: Tue, 27 Nov 2018 21:53:38 +0900
Subject: [R] [R ]Exporting rgl.snapshot and rgl.postscript
Message-ID: <CAHjanSCc6=xcTvP6qxB-2+Dk-tS5WMnnzXkniLBjP2+iKHpUhQ@mail.gmail.com>

Dear all,



I'm trying to plot a surface over the x-y plane. In my data, the response
is KIC, and 4 factors are AC, AV, T, and Temp. I want to have response
surface of KIC with two factors, i.e., AC and AV. A typical second-degree
response modeling is as follows:



> data<-read.csv("2.csv", header =T)

> mod <- lm(KIC~AC+I(AC^2)+AV+I(AV^2)+T+I(T^2)+Temp+I(Temp^2)+AC:AV+AC:T+AC:Temp+AV:T+AV:Temp+T:Temp,

+ data = data)

> library(rgl)

> KIC <- function(AC, AV, Temp, T) predict(mod, newdata = data.frame(AC, AV, Temp, T))

> persp3d(KIC, xlim = c(4, 5),  # The range of values for AC

+ ylim = c(4, 7),  # The range for AV

+ xlab = "AC", ylab = "AV", zlab = "KIC",

+ col = "lightblue",

+ otherargs = list(Temp = 15, T = 40))

> rgl.snapshot("1.png", fmt = "png", top = TRUE )

> rgl.postscript("1.pdf","pdf")



The problem is that the figure created by *rgl.snapshot* (attached Figure
1) has low quality, while the figure created by *rgl.postscript* (attached
Figure 2) doesn?t have adequate details.



Can somebody please show me how to properly export the file? I would prefer
the Figure have the TIFF or PDF with the resolution 600 dpi. I really
appreciate your support and help.



Best regards,

Nhat Tran



Ps: I also added a CSV file for practicing R.

From murdoch@dunc@n @ending from gm@il@com  Tue Nov 27 15:06:50 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Tue, 27 Nov 2018 09:06:50 -0500
Subject: [R] [R ]Exporting rgl.snapshot and rgl.postscript
In-Reply-To: <CAHjanSCc6=xcTvP6qxB-2+Dk-tS5WMnnzXkniLBjP2+iKHpUhQ@mail.gmail.com>
References: <CAHjanSCc6=xcTvP6qxB-2+Dk-tS5WMnnzXkniLBjP2+iKHpUhQ@mail.gmail.com>
Message-ID: <023c4782-e133-ec4c-28b3-27469c12d261@gmail.com>

On 27/11/2018 7:53 AM, Thanh Tran wrote:
> Dear all,
> 
> 
> 
> I'm trying to plot a surface over the x-y plane. In my data, the response
> is KIC, and 4 factors are AC, AV, T, and Temp. I want to have response
> surface of KIC with two factors, i.e., AC and AV. A typical second-degree
> response modeling is as follows:
> 
> 
> 
>> data<-read.csv("2.csv", header =T)
> 
>> mod <- lm(KIC~AC+I(AC^2)+AV+I(AV^2)+T+I(T^2)+Temp+I(Temp^2)+AC:AV+AC:T+AC:Temp+AV:T+AV:Temp+T:Temp,
> 
> + data = data)
> 
>> library(rgl)
> 
>> KIC <- function(AC, AV, Temp, T) predict(mod, newdata = data.frame(AC, AV, Temp, T))
> 
>> persp3d(KIC, xlim = c(4, 5),  # The range of values for AC
> 
> + ylim = c(4, 7),  # The range for AV
> 
> + xlab = "AC", ylab = "AV", zlab = "KIC",
> 
> + col = "lightblue",
> 
> + otherargs = list(Temp = 15, T = 40))
> 
>> rgl.snapshot("1.png", fmt = "png", top = TRUE )
> 
>> rgl.postscript("1.pdf","pdf")
> 
> 
> 
> The problem is that the figure created by *rgl.snapshot* (attached Figure
> 1) has low quality, while the figure created by *rgl.postscript* (attached
> Figure 2) doesn?t have adequate details.

You can improve the rgl.snapshot output by starting from a large window. 
  You can do this either by using the mouse to enlarge the window, or 
specifying values for windowRect in par3d() or open3d(), e.g.

open3d(windowRect=c(0,0, 1800, 1800))

Whether very large values will be respected depends on the system.  For 
example, my Macbook Air reduces that request so the whole window is visible,

 > par3d("windowRect")
[1]    0   45 1440  901

You can set the default to be a large window using

r3dDefaults <- getr3dDefaults()
r3dDefaults$windowRect <- c(0,0, 1800, 1800)

(This will only be respected by the *3d functions like open3d(), not the 
low-level rgl.* functions like rgl.open().)

The rgl.postscript() display is limited by what the GL2PS library can 
do, so if it doesn't do what you want, there's not much you can do to 
improve it.

Duncan Murdoch

> 
> 
> 
> Can somebody please show me how to properly export the file? I would prefer
> the Figure have the TIFF or PDF with the resolution 600 dpi. I really
> appreciate your support and help.
> 
> 
> 
> Best regards,
> 
> Nhat Tran
> 
> 
> 
> Ps: I also added a CSV file for practicing R.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @@r@h@go@lee @ending from gm@il@com  Tue Nov 27 18:10:38 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Tue, 27 Nov 2018 12:10:38 -0500
Subject: [R] EXAMPLE OF HOW TO USE R FOR EXPONENTIAL DISTRIBUTION &
 EXPONENTIAL REGRESSION
In-Reply-To: <CAL+C-=7uVFxxeNs1OXr4+h+oK2CoERFS1hvs=ff=mMte2fQj4A@mail.gmail.com>
References: <CAL+C-=65nn=uDJqD2qm5jOKzVTyGTkFzdqo2BvUc9wtkKVzC3g@mail.gmail.com>
 <CAM_vjumerzyKKwXdVJ91A+Co+meW2zPFQvM3Jo0goA-HGULBOw@mail.gmail.com>
 <CAL+C-=7uVFxxeNs1OXr4+h+oK2CoERFS1hvs=ff=mMte2fQj4A@mail.gmail.com>
Message-ID: <CAM_vjukodGTO15YsTySkXxiGf4W=BrmRRSUEJiuQZsrkbwMiiQ@mail.gmail.com>

Hi,

Please also include R-help in your replies - I can't provide
one-on-one tutorials.

Without knowing where you got your sample code, it's hard to help. But
what are you trying to do?

It doesn't have to be that complicated:

x <- 1:10
y <- c(0.00, 0.00,0.0033,0.0009,0.0025,0.0653,0.1142,0.2872,0,1 )
plot(x, y, pch=20)

# basic straight line of fit
fit <- glm(y~x)

abline(fit, col="blue", lwd=2)
exp.lm <- lm(y ~ exp(x))
lines(1:10, predict(exp.lm, newdata=data.frame(x=1:10)))


On Tue, Nov 27, 2018 at 9:34 AM Tolulope Adeagbo
<tolulopeadeagbo at gmail.com> wrote:
>
> Hello,
>
> So I found this example online but there seems to be an issue with the "Start" points. the result is giving somewhat a straight line
>
> # get underlying plot
> x <- 1:10
> y <- c(0.00, 0.00,0.0033,0.0009,0.0025,0.0653,0.1142,0.2872,0,1 )
> plot(x, y, pch=20)
>
> # basic straight line of fit
> fit <- glm(y~x)
> co <- coef(fit)
> abline(fit, col="blue", lwd=2)
>
> # exponential
> f <- function(x,a,b) {a * exp(b * x)}
> fit <- nls(y ~ f(x,a,b), start = c(a=1 , b=c(0,1)))
> co <- coef(fit)
> curve(f(x, a=co[1], b=co[2]), add = TRUE, col="green", lwd=2)
>
>
> # exponential
> f <- function(x,a,b) {a * exp(b * x)}
> fit <- nls(y ~ f(x,a,b), start = c(a=1, b=1))
> co <- coef(fit)
> curve(f(x, a=co[1], b=co[2]), add = TRUE, col="green", lwd=2)
> # logarithmic
> f <- function(x,a,b) {a * log(x) + b}
> fit <- nls(y ~ f(x,a,b), start = c(a=1, b=1))
> co <- coef(fit)
> curve(f(x, a=co[1], b=co[2]), add = TRUE, col="orange", lwd=2)
>
> # polynomial
> f <- function(x,a,b,d) {(a*x^2) + (b*x) + d}
> fit <- nls(y ~ f(x,a,b,d), start = c(a=1, b=1, d=1))
> co <- coef(fit)
> curve(f(x, a=co[1], b=co[2], d=co[3]), add = TRUE, col="pink", lwd=2)
>
> On Tue, Nov 27, 2018 at 12:28 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>
>> Hi,
>>
>> Using rseek.org to search for exponential regression turns up lots of information, as does using Google.
>>
>> Which tutorials have you worked thru already, and what else are you looking for?
>>
>> Sarah
>>
>> On Tue, Nov 27, 2018 at 5:44 AM Tolulope Adeagbo <tolulopeadeagbo at gmail.com> wrote:
>>>
>>> Good day,
>>> Please i nee useful materials to understand how to use R for exponential
>>> regression.
>>> Many thanks.
>>


-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From bgunter@4567 @ending from gm@il@com  Tue Nov 27 18:38:17 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 27 Nov 2018 09:38:17 -0800
Subject: [R] EXAMPLE OF HOW TO USE R FOR EXPONENTIAL DISTRIBUTION &
 EXPONENTIAL REGRESSION
In-Reply-To: <CAM_vjukodGTO15YsTySkXxiGf4W=BrmRRSUEJiuQZsrkbwMiiQ@mail.gmail.com>
References: <CAL+C-=65nn=uDJqD2qm5jOKzVTyGTkFzdqo2BvUc9wtkKVzC3g@mail.gmail.com>
 <CAM_vjumerzyKKwXdVJ91A+Co+meW2zPFQvM3Jo0goA-HGULBOw@mail.gmail.com>
 <CAL+C-=7uVFxxeNs1OXr4+h+oK2CoERFS1hvs=ff=mMte2fQj4A@mail.gmail.com>
 <CAM_vjukodGTO15YsTySkXxiGf4W=BrmRRSUEJiuQZsrkbwMiiQ@mail.gmail.com>
Message-ID: <CAGxFJbRc5L6=cOqz6bF-AF6oOcuXhDv0-ehytgVd0b_=TxYrbQ@mail.gmail.com>

... but do note that a nonlinear fit to the raw data will give a(somewhat)
different result than a linear fit to the transformed data. In the former,
the errors are additive and in the latter they are multiplicative. Etc.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Nov 27, 2018 at 9:11 AM Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Hi,
>
> Please also include R-help in your replies - I can't provide
> one-on-one tutorials.
>
> Without knowing where you got your sample code, it's hard to help. But
> what are you trying to do?
>
> It doesn't have to be that complicated:
>
> x <- 1:10
> y <- c(0.00, 0.00,0.0033,0.0009,0.0025,0.0653,0.1142,0.2872,0,1 )
> plot(x, y, pch=20)
>
> # basic straight line of fit
> fit <- glm(y~x)
>
> abline(fit, col="blue", lwd=2)
> exp.lm <- lm(y ~ exp(x))
> lines(1:10, predict(exp.lm, newdata=data.frame(x=1:10)))
>
>
> On Tue, Nov 27, 2018 at 9:34 AM Tolulope Adeagbo
> <tolulopeadeagbo at gmail.com> wrote:
> >
> > Hello,
> >
> > So I found this example online but there seems to be an issue with the
> "Start" points. the result is giving somewhat a straight line
> >
> > # get underlying plot
> > x <- 1:10
> > y <- c(0.00, 0.00,0.0033,0.0009,0.0025,0.0653,0.1142,0.2872,0,1 )
> > plot(x, y, pch=20)
> >
> > # basic straight line of fit
> > fit <- glm(y~x)
> > co <- coef(fit)
> > abline(fit, col="blue", lwd=2)
> >
> > # exponential
> > f <- function(x,a,b) {a * exp(b * x)}
> > fit <- nls(y ~ f(x,a,b), start = c(a=1 , b=c(0,1)))
> > co <- coef(fit)
> > curve(f(x, a=co[1], b=co[2]), add = TRUE, col="green", lwd=2)
> >
> >
> > # exponential
> > f <- function(x,a,b) {a * exp(b * x)}
> > fit <- nls(y ~ f(x,a,b), start = c(a=1, b=1))
> > co <- coef(fit)
> > curve(f(x, a=co[1], b=co[2]), add = TRUE, col="green", lwd=2)
> > # logarithmic
> > f <- function(x,a,b) {a * log(x) + b}
> > fit <- nls(y ~ f(x,a,b), start = c(a=1, b=1))
> > co <- coef(fit)
> > curve(f(x, a=co[1], b=co[2]), add = TRUE, col="orange", lwd=2)
> >
> > # polynomial
> > f <- function(x,a,b,d) {(a*x^2) + (b*x) + d}
> > fit <- nls(y ~ f(x,a,b,d), start = c(a=1, b=1, d=1))
> > co <- coef(fit)
> > curve(f(x, a=co[1], b=co[2], d=co[3]), add = TRUE, col="pink", lwd=2)
> >
> > On Tue, Nov 27, 2018 at 12:28 PM Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
> >>
> >> Hi,
> >>
> >> Using rseek.org to search for exponential regression turns up lots of
> information, as does using Google.
> >>
> >> Which tutorials have you worked thru already, and what else are you
> looking for?
> >>
> >> Sarah
> >>
> >> On Tue, Nov 27, 2018 at 5:44 AM Tolulope Adeagbo <
> tolulopeadeagbo at gmail.com> wrote:
> >>>
> >>> Good day,
> >>> Please i nee useful materials to understand how to use R for
> exponential
> >>> regression.
> >>> Many thanks.
> >>
>
>
> --
> Sarah Goslee (she/her)
> http://www.numberwright.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tolulope@de@gbo @ending from gm@il@com  Tue Nov 27 19:44:19 2018
From: tolulope@de@gbo @ending from gm@il@com (Tolulope Adeagbo)
Date: Tue, 27 Nov 2018 19:44:19 +0100
Subject: [R] EXAMPLE OF HOW TO USE R FOR EXPONENTIAL DISTRIBUTION &
 EXPONENTIAL REGRESSION
In-Reply-To: <CAGxFJbRc5L6=cOqz6bF-AF6oOcuXhDv0-ehytgVd0b_=TxYrbQ@mail.gmail.com>
References: <CAL+C-=65nn=uDJqD2qm5jOKzVTyGTkFzdqo2BvUc9wtkKVzC3g@mail.gmail.com>
 <CAM_vjumerzyKKwXdVJ91A+Co+meW2zPFQvM3Jo0goA-HGULBOw@mail.gmail.com>
 <CAL+C-=7uVFxxeNs1OXr4+h+oK2CoERFS1hvs=ff=mMte2fQj4A@mail.gmail.com>
 <CAM_vjukodGTO15YsTySkXxiGf4W=BrmRRSUEJiuQZsrkbwMiiQ@mail.gmail.com>
 <CAGxFJbRc5L6=cOqz6bF-AF6oOcuXhDv0-ehytgVd0b_=TxYrbQ@mail.gmail.com>
Message-ID: <CAL+C-=4HbF79s6m6siZuQGo9Ty_MA20uS2E=8+t6USF43gPwWg@mail.gmail.com>

Thank you for the clarification.
I'll share a function I got tomorrow morning.

Regards

On Tue, 27 Nov 2018, 18:38 Bert Gunter, <bgunter.4567 at gmail.com> wrote:

> ... but do note that a nonlinear fit to the raw data will give a(somewhat)
> different result than a linear fit to the transformed data. In the former,
> the errors are additive and in the latter they are multiplicative. Etc.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Nov 27, 2018 at 9:11 AM Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>
>> Hi,
>>
>> Please also include R-help in your replies - I can't provide
>> one-on-one tutorials.
>>
>> Without knowing where you got your sample code, it's hard to help. But
>> what are you trying to do?
>>
>> It doesn't have to be that complicated:
>>
>> x <- 1:10
>> y <- c(0.00, 0.00,0.0033,0.0009,0.0025,0.0653,0.1142,0.2872,0,1 )
>> plot(x, y, pch=20)
>>
>> # basic straight line of fit
>> fit <- glm(y~x)
>>
>> abline(fit, col="blue", lwd=2)
>> exp.lm <- lm(y ~ exp(x))
>> lines(1:10, predict(exp.lm, newdata=data.frame(x=1:10)))
>>
>>
>> On Tue, Nov 27, 2018 at 9:34 AM Tolulope Adeagbo
>> <tolulopeadeagbo at gmail.com> wrote:
>> >
>> > Hello,
>> >
>> > So I found this example online but there seems to be an issue with the
>> "Start" points. the result is giving somewhat a straight line
>> >
>> > # get underlying plot
>> > x <- 1:10
>> > y <- c(0.00, 0.00,0.0033,0.0009,0.0025,0.0653,0.1142,0.2872,0,1 )
>> > plot(x, y, pch=20)
>> >
>> > # basic straight line of fit
>> > fit <- glm(y~x)
>> > co <- coef(fit)
>> > abline(fit, col="blue", lwd=2)
>> >
>> > # exponential
>> > f <- function(x,a,b) {a * exp(b * x)}
>> > fit <- nls(y ~ f(x,a,b), start = c(a=1 , b=c(0,1)))
>> > co <- coef(fit)
>> > curve(f(x, a=co[1], b=co[2]), add = TRUE, col="green", lwd=2)
>> >
>> >
>> > # exponential
>> > f <- function(x,a,b) {a * exp(b * x)}
>> > fit <- nls(y ~ f(x,a,b), start = c(a=1, b=1))
>> > co <- coef(fit)
>> > curve(f(x, a=co[1], b=co[2]), add = TRUE, col="green", lwd=2)
>> > # logarithmic
>> > f <- function(x,a,b) {a * log(x) + b}
>> > fit <- nls(y ~ f(x,a,b), start = c(a=1, b=1))
>> > co <- coef(fit)
>> > curve(f(x, a=co[1], b=co[2]), add = TRUE, col="orange", lwd=2)
>> >
>> > # polynomial
>> > f <- function(x,a,b,d) {(a*x^2) + (b*x) + d}
>> > fit <- nls(y ~ f(x,a,b,d), start = c(a=1, b=1, d=1))
>> > co <- coef(fit)
>> > curve(f(x, a=co[1], b=co[2], d=co[3]), add = TRUE, col="pink", lwd=2)
>> >
>> > On Tue, Nov 27, 2018 at 12:28 PM Sarah Goslee <sarah.goslee at gmail.com>
>> wrote:
>> >>
>> >> Hi,
>> >>
>> >> Using rseek.org to search for exponential regression turns up lots of
>> information, as does using Google.
>> >>
>> >> Which tutorials have you worked thru already, and what else are you
>> looking for?
>> >>
>> >> Sarah
>> >>
>> >> On Tue, Nov 27, 2018 at 5:44 AM Tolulope Adeagbo <
>> tolulopeadeagbo at gmail.com> wrote:
>> >>>
>> >>> Good day,
>> >>> Please i nee useful materials to understand how to use R for
>> exponential
>> >>> regression.
>> >>> Many thanks.
>> >>
>>
>>
>> --
>> Sarah Goslee (she/her)
>> http://www.numberwright.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From reith_willi@m @ending from b@h@com  Tue Nov 27 21:04:48 2018
From: reith_willi@m @ending from b@h@com (Reith, William [USA])
Date: Tue, 27 Nov 2018 20:04:48 +0000
Subject: [R] gemo_text issue
Message-ID: <BL0PR06MB4834355C489335B0E307D9D498D00@BL0PR06MB4834.namprd06.prod.outlook.com>

I am experiencing issues with trying to label points added to a ggplot via geom_point. I think an underlying issue is the fact that I already used ggplot function to create a 5x5 risk matrix "background", but I am not certain. I have tried multiple solutions online but cannot find one that has a similar the background plotting I am attempting.

I have attached the .R file and a picture of what I am creating minus the buggy text labels. Code is also pasted below.

Thanks,

William


library(ggplot2)

Project<-c("C","C","C","C","C","B","B","B","D","E","E","F","F","F","F")
Prob<-c(3,3,3,2,2,2,2,2,3,4,3,5,4,3,3)
con<-c(3.675941831,2.354582402,2.354582402,2.354582402,1.95075378,3.0602443,3.0602443,3.283695274,1.904452395,3.579022044,3.579022044,2.58190428,1.76065948,2.365243619,1.354491286)
test2<-data.frame(Project,Prob,con)

### build risk coloring matrix ###
myData <- matrix(c(1,2,3,3,3,1,2,2,3,3,1,1,2,2,3,1,1,2,2,2,1,1,1,1,2), nrow = 5, ncol = 5, byrow = TRUE)
rownames(myData) <- c("5", "4", "3", "2","1")
colnames(myData) <- c("1", "2", "3", "4","5")

### convert to data frame ###
longData <- melt(myData)
colnames(longData) <- c("Probability", "Consequence", "value")
longData$value<-as.factor(longData$value)

### define color tiles ###
color<-c("green" ,"green" ,"green","green"  ,"green",
        "yellow","yellow","green","green"  ,"green",
        "red"   ,"yellow","yellow","yellow","green",
        "red"   ,"red"   ,"yellow","yellow","green",
        "red"   ,"red"   ,"red"   ,"yellow","yellow")

### create color background 5x5 ###
zp1 <- ggplot(longData,aes(x = Consequence, y = Probability)) #, fill = value))
zp1 <- zp1 + geom_tile(fill = color)
zp1 <- zp1 + scale_x_continuous(breaks = 0:6, expand = c(0, 0))
zp1 <- zp1 + scale_y_continuous(breaks = 0:6, expand = c(0, 0))
zp1 <- zp1 + coord_fixed()
zp1 <- zp1 + theme_bw()
print(zp1)

### Add title and lines ###
zp1 <- zp1 + ggtitle("5x5 Plot")+theme(plot.title = element_text(hjust = 0.5))
zp1 <- zp1 + geom_vline(xintercept=c(1.5:5.5))
zp1 <- zp1 + geom_hline(yintercept=c(1.5:5.5))
print(zp1)

### Plot points ###
zp1 <- zp1 + geom_point(data=test2, x=test2$con, y=test2$Prob, alpha = 1, size = 9, color = "blue")
print(zp1)

### This is the line I cannot get working; tried multiple approaches ###
### intent is to add white labels to plotted points ###
zp1 <- zp1 + geom_text(data=test2, label = test2$Project, size = 6, color = "white")
print(zp1)

-------------- next part --------------
A non-text attachment was scrubbed...
Name: test.png
Type: image/png
Size: 3565 bytes
Desc: test.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20181127/6a39fe20/attachment.png>

From btupper @ending from bigelow@org  Tue Nov 27 21:30:31 2018
From: btupper @ending from bigelow@org (Ben Tupper)
Date: Tue, 27 Nov 2018 15:30:31 -0500
Subject: [R] gemo_text issue
In-Reply-To: <BL0PR06MB4834355C489335B0E307D9D498D00@BL0PR06MB4834.namprd06.prod.outlook.com>
References: <BL0PR06MB4834355C489335B0E307D9D498D00@BL0PR06MB4834.namprd06.prod.outlook.com>
Message-ID: <3E2DCE80-F3F9-45F2-ABBC-A86C680E18EC@bigelow.org>

Hi,

I had to include 

library(reshape2) 

to get things working as you use melt(). Explicitly setting the x and y values in geom_text() is needed since you are providing new data.

zp1 <- zp1 + geom_text(data=test2, x=test2$con, y=test2$Prob, label = test2$Project, size = 6, color = "white")


Cheers,
Ben

> On Nov 27, 2018, at 3:04 PM, Reith, William [USA] <reith_william at bah.com> wrote:
> 
> I am experiencing issues with trying to label points added to a ggplot via geom_point. I think an underlying issue is the fact that I already used ggplot function to create a 5x5 risk matrix "background", but I am not certain. I have tried multiple solutions online but cannot find one that has a similar the background plotting I am attempting.
> 
> I have attached the .R file and a picture of what I am creating minus the buggy text labels. Code is also pasted below.
> 
> Thanks,
> 
> William
> 
> 
> library(ggplot2)
> 
> Project<-c("C","C","C","C","C","B","B","B","D","E","E","F","F","F","F")
> Prob<-c(3,3,3,2,2,2,2,2,3,4,3,5,4,3,3)
> con<-c(3.675941831,2.354582402,2.354582402,2.354582402,1.95075378,3.0602443,3.0602443,3.283695274,1.904452395,3.579022044,3.579022044,2.58190428,1.76065948,2.365243619,1.354491286)
> test2<-data.frame(Project,Prob,con)
> 
> ### build risk coloring matrix ###
> myData <- matrix(c(1,2,3,3,3,1,2,2,3,3,1,1,2,2,3,1,1,2,2,2,1,1,1,1,2), nrow = 5, ncol = 5, byrow = TRUE)
> rownames(myData) <- c("5", "4", "3", "2","1")
> colnames(myData) <- c("1", "2", "3", "4","5")
> 
> ### convert to data frame ###
> longData <- melt(myData)
> colnames(longData) <- c("Probability", "Consequence", "value")
> longData$value<-as.factor(longData$value)
> 
> ### define color tiles ###
> color<-c("green" ,"green" ,"green","green"  ,"green",
>        "yellow","yellow","green","green"  ,"green",
>        "red"   ,"yellow","yellow","yellow","green",
>        "red"   ,"red"   ,"yellow","yellow","green",
>        "red"   ,"red"   ,"red"   ,"yellow","yellow")
> 
> ### create color background 5x5 ###
> zp1 <- ggplot(longData,aes(x = Consequence, y = Probability)) #, fill = value))
> zp1 <- zp1 + geom_tile(fill = color)
> zp1 <- zp1 + scale_x_continuous(breaks = 0:6, expand = c(0, 0))
> zp1 <- zp1 + scale_y_continuous(breaks = 0:6, expand = c(0, 0))
> zp1 <- zp1 + coord_fixed()
> zp1 <- zp1 + theme_bw()
> print(zp1)
> 
> ### Add title and lines ###
> zp1 <- zp1 + ggtitle("5x5 Plot")+theme(plot.title = element_text(hjust = 0.5))
> zp1 <- zp1 + geom_vline(xintercept=c(1.5:5.5))
> zp1 <- zp1 + geom_hline(yintercept=c(1.5:5.5))
> print(zp1)
> 
> ### Plot points ###
> zp1 <- zp1 + geom_point(data=test2, x=test2$con, y=test2$Prob, alpha = 1, size = 9, color = "blue")
> print(zp1)
> 
> ### This is the line I cannot get working; tried multiple approaches ###
> ### intent is to add white labels to plotted points ###
> zp1 <- zp1 + geom_text(data=test2, label = test2$Project, size = 6, color = "white")
> print(zp1)
> <test.png>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]


From @nnij@nh @ending from gm@il@com  Tue Nov 27 23:33:11 2018
From: @nnij@nh @ending from gm@il@com (Janh Anni)
Date: Tue, 27 Nov 2018 17:33:11 -0500
Subject: [R] Bootstrapping One- and Two-Sample Hypothesis Tests of Proportion
Message-ID: <CAFCoDdBrRC6GNR8JP_-0E2U4M1AKJTh8tRqSBqeRkK2qqemtdA@mail.gmail.com>

Hello R Experts!

Does anyone know of a relatively straightforward way to bootstrap
hypothesis tests for proportion in R?

Thanks in advance!

Janh

	[[alternative HTML version deleted]]


From @olop@r@p@gin@@123456789 @ending from gm@il@com  Wed Nov 28 00:02:33 2018
From: @olop@r@p@gin@@123456789 @ending from gm@il@com (FAIL PEDIA)
Date: Tue, 27 Nov 2018 18:02:33 -0500
Subject: [R] Basic optimization question (I'm a rookie)
Message-ID: <CAGZkDQhiVVuyJ1c6D3-HOxqash19dWsOfnHbnFrbx6TLcp5nYA@mail.gmail.com>

Hello, and thanks to anyone who takes the time to read this

I'm trying to learn to properly optimize a function with a constraint using
R. For example, maximize the area of a terrain with a maximum perimeter.
For this example the function would be:

     Area <- function(x,y){x*y}

The restriction would be the following function:

     Perimeter <- function(x,y){2*(x+y)}

The idea is to give a desired value to "Perimeter" and get the values of x
& y that maximize the area and respect the constraint.

I've searched online for some time, and only found a video of a dude that
plotted the functions toggling the values to find the tangent optimum point
(something useless, because the idea is to make the optimization more
efficiently than using a paper and a pencil)

Thanks again, and sorry if this question is silly.

	[[alternative HTML version deleted]]


From @@r@h@go@lee @ending from gm@il@com  Wed Nov 28 00:29:59 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Tue, 27 Nov 2018 18:29:59 -0500
Subject: [R] Basic optimization question (I'm a rookie)
In-Reply-To: <CAGZkDQhiVVuyJ1c6D3-HOxqash19dWsOfnHbnFrbx6TLcp5nYA@mail.gmail.com>
References: <CAGZkDQhiVVuyJ1c6D3-HOxqash19dWsOfnHbnFrbx6TLcp5nYA@mail.gmail.com>
Message-ID: <CAM_vjun9NAUs=yTqQeQQRYu09OM6JiiRYJXWD1u0fYUqEC62hQ@mail.gmail.com>

Hi,

R is quite good at optimization. Here's a basic tutorial:
https://www.is.uni-freiburg.de/resources/computational-economics/5_OptimizationR.pdf

There are a LOT of possibilities:
https://cran.r-project.org/web/views/Optimization.html

Sarah

On Tue, Nov 27, 2018 at 6:19 PM FAIL PEDIA
<soloparapaginas123456789 at gmail.com> wrote:
>
> Hello, and thanks to anyone who takes the time to read this
>
> I'm trying to learn to properly optimize a function with a constraint using
> R. For example, maximize the area of a terrain with a maximum perimeter.
> For this example the function would be:
>
>      Area <- function(x,y){x*y}
>
> The restriction would be the following function:
>
>      Perimeter <- function(x,y){2*(x+y)}
>
> The idea is to give a desired value to "Perimeter" and get the values of x
> & y that maximize the area and respect the constraint.
>
> I've searched online for some time, and only found a video of a dude that
> plotted the functions toggling the values to find the tangent optimum point
> (something useless, because the idea is to make the optimization more
> efficiently than using a paper and a pencil)
>
> Thanks again, and sorry if this question is silly.
>

-- 
Sarah Goslee (she/her)
http://www.sarahgoslee.com


From m@@ternh@ttt @ending from gm@il@com  Wed Nov 28 00:40:37 2018
From: m@@ternh@ttt @ending from gm@il@com (Thanh Tran)
Date: Wed, 28 Nov 2018 08:40:37 +0900
Subject: [R] [R ]Exporting rgl.snapshot and rgl.postscript
In-Reply-To: <023c4782-e133-ec4c-28b3-27469c12d261@gmail.com>
References: <CAHjanSCc6=xcTvP6qxB-2+Dk-tS5WMnnzXkniLBjP2+iKHpUhQ@mail.gmail.com>
 <023c4782-e133-ec4c-28b3-27469c12d261@gmail.com>
Message-ID: <CAHjanSDRj1ibME_i0b-M2pnwBpV-i9GYegyrAXmiaYUj-OGwpg@mail.gmail.com>

Hi  Duncan Murdoch
Thank you for your support.
Best regards,
Nhat Tran

V?o Th 3, 27 thg 11, 2018 va?o lu?c 23:06 Duncan Murdoch <
murdoch.duncan at gmail.com> ?? vi?t:

> On 27/11/2018 7:53 AM, Thanh Tran wrote:
> > Dear all,
> >
> >
> >
> > I'm trying to plot a surface over the x-y plane. In my data, the response
> > is KIC, and 4 factors are AC, AV, T, and Temp. I want to have response
> > surface of KIC with two factors, i.e., AC and AV. A typical second-degree
> > response modeling is as follows:
> >
> >
> >
> >> data<-read.csv("2.csv", header =T)
> >
> >> mod <-
> lm(KIC~AC+I(AC^2)+AV+I(AV^2)+T+I(T^2)+Temp+I(Temp^2)+AC:AV+AC:T+AC:Temp+AV:T+AV:Temp+T:Temp,
> >
> > + data = data)
> >
> >> library(rgl)
> >
> >> KIC <- function(AC, AV, Temp, T) predict(mod, newdata = data.frame(AC,
> AV, Temp, T))
> >
> >> persp3d(KIC, xlim = c(4, 5),  # The range of values for AC
> >
> > + ylim = c(4, 7),  # The range for AV
> >
> > + xlab = "AC", ylab = "AV", zlab = "KIC",
> >
> > + col = "lightblue",
> >
> > + otherargs = list(Temp = 15, T = 40))
> >
> >> rgl.snapshot("1.png", fmt = "png", top = TRUE )
> >
> >> rgl.postscript("1.pdf","pdf")
> >
> >
> >
> > The problem is that the figure created by *rgl.snapshot* (attached Figure
> > 1) has low quality, while the figure created by *rgl.postscript*
> (attached
> > Figure 2) doesn?t have adequate details.
>
> You can improve the rgl.snapshot output by starting from a large window.
>   You can do this either by using the mouse to enlarge the window, or
> specifying values for windowRect in par3d() or open3d(), e.g.
>
> open3d(windowRect=c(0,0, 1800, 1800))
>
> Whether very large values will be respected depends on the system.  For
> example, my Macbook Air reduces that request so the whole window is
> visible,
>
>  > par3d("windowRect")
> [1]    0   45 1440  901
>
> You can set the default to be a large window using
>
> r3dDefaults <- getr3dDefaults()
> r3dDefaults$windowRect <- c(0,0, 1800, 1800)
>
> (This will only be respected by the *3d functions like open3d(), not the
> low-level rgl.* functions like rgl.open().)
>
> The rgl.postscript() display is limited by what the GL2PS library can
> do, so if it doesn't do what you want, there's not much you can do to
> improve it.
>
> Duncan Murdoch
>
> >
> >
> >
> > Can somebody please show me how to properly export the file? I would
> prefer
> > the Figure have the TIFF or PDF with the resolution 600 dpi. I really
> > appreciate your support and help.
> >
> >
> >
> > Best regards,
> >
> > Nhat Tran
> >
> >
> >
> > Ps: I also added a CSV file for practicing R.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Wed Nov 28 01:31:18 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 27 Nov 2018 16:31:18 -0800
Subject: [R] Basic optimization question (I'm a rookie)
In-Reply-To: <CAGZkDQhiVVuyJ1c6D3-HOxqash19dWsOfnHbnFrbx6TLcp5nYA@mail.gmail.com>
References: <CAGZkDQhiVVuyJ1c6D3-HOxqash19dWsOfnHbnFrbx6TLcp5nYA@mail.gmail.com>
Message-ID: <CAGxFJbSwn40KR7N4PJBg0kJnSBBxbgcJcLnv1pVp3xQmD+NbUA@mail.gmail.com>

Of course, this particular example is trivially solvable by hand: x ==y
==p/4 , a square.
Note also that optimization with equality constraints are generally
solvable by the method of Lagrange multipliers for smooth functions and
constraints, so that numerical methods may not be needed for relatively
simple cases.

Cheers,
Bert





On Tue, Nov 27, 2018 at 3:19 PM FAIL PEDIA <
soloparapaginas123456789 at gmail.com> wrote:

> Hello, and thanks to anyone who takes the time to read this
>
> I'm trying to learn to properly optimize a function with a constraint using
> R. For example, maximize the area of a terrain with a maximum perimeter.
> For this example the function would be:
>
>      Area <- function(x,y){x*y}
>
> The restriction would be the following function:
>
>      Perimeter <- function(x,y){2*(x+y)}
>
> The idea is to give a desired value to "Perimeter" and get the values of x
> & y that maximize the area and respect the constraint.
>
> I've searched online for some time, and only found a video of a dude that
> plotted the functions toggling the values to find the tangent optimum point
> (something useless, because the idea is to make the optimization more
> efficiently than using a paper and a pencil)
>
> Thanks again, and sorry if this question is silly.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From giftedlife2014 @ending from gm@il@com  Wed Nov 28 04:05:46 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Wed, 28 Nov 2018 04:05:46 +0100
Subject: [R] Applying a certain formula to a repeated sample data
Message-ID: <CAC8ss33K==HfbLnyZRVgOhUzbgm2TzEWZ-e6H19khgEc4RS=Aw@mail.gmail.com>

Dear List,
I have three data-column data. The data is of the form:
1 8590 12516
2 8641 98143
3 8705 98916
4 8750 89911
5 8685 104835
6 8629 121963
7 8676 77655
1 8577 81081
2 8593 83385
3 8642 112164
4 8708 103684
5 8622 83982
6 8593 75944
7 8600 97036
1 8650 104911
2 8730 114098
3 8731 99421
4 8715 85707
5 8717 81273
6 8739 106462
7 8684 110635
1 8713 105214
2 8771 92456
3 8759 109270
4 8762 99150
5 8730 77306
6 8780 86324
7 8804 90214
1 8797 99894
2 8863 95177
3 8873 95910
4 8827 108511
5 8806 115636
6 8869 85542
7 8854 111018
1 8571 93247
2 8533 85105
3 8553 114725
4 8561 122195
5 8532 100945
6 8560 108552
7 8634 108707
1 8646 117420
2 8633 113823
3 8680 82763
4 8765 121072
5 8756 89835
6 8750 104578
7 8790 88429

I wish to calculate average of the second and third columns based on the
first column for each repeated 7 days. The length of the data is 1442. That
is 206 by 7. So I should arrive at 207 data points for each of the two
columns after calculating the mean of each group 1-7.

I have both tried factor/tapply and aggregate functions but seem not to be
making progress.

Thank you very much for your idea.

Best wishes
Ogbos

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Wed Nov 28 04:31:39 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Wed, 28 Nov 2018 14:31:39 +1100
Subject: [R] Applying a certain formula to a repeated sample data
In-Reply-To: <CAC8ss33K==HfbLnyZRVgOhUzbgm2TzEWZ-e6H19khgEc4RS=Aw@mail.gmail.com>
References: <CAC8ss33K==HfbLnyZRVgOhUzbgm2TzEWZ-e6H19khgEc4RS=Aw@mail.gmail.com>
Message-ID: <CA+8X3fWTQd7ftWXL-yZ8+MhvzHf5GiU00kK98x2qC1yenBe99A@mail.gmail.com>

Hi Ogbos,
If we assume that you have a 3 column data frame named oodf, how about:

oodf[,4]<-floor((cumsum(oodf[,1])-1)/28)
col2means<-by(oodf[,2],oodf[,4],mean)
col3means<-by(oodf[,3],oodf[,4],mean)

Jim

On Wed, Nov 28, 2018 at 2:06 PM Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>
> Dear List,
> I have three data-column data. The data is of the form:
> 1 8590 12516
> 2 8641 98143
> 3 8705 98916
> 4 8750 89911
> 5 8685 104835
> 6 8629 121963
> 7 8676 77655
> 1 8577 81081
> 2 8593 83385
> 3 8642 112164
> 4 8708 103684
> 5 8622 83982
> 6 8593 75944
> 7 8600 97036
> 1 8650 104911
> 2 8730 114098
> 3 8731 99421
> 4 8715 85707
> 5 8717 81273
> 6 8739 106462
> 7 8684 110635
> 1 8713 105214
> 2 8771 92456
> 3 8759 109270
> 4 8762 99150
> 5 8730 77306
> 6 8780 86324
> 7 8804 90214
> 1 8797 99894
> 2 8863 95177
> 3 8873 95910
> 4 8827 108511
> 5 8806 115636
> 6 8869 85542
> 7 8854 111018
> 1 8571 93247
> 2 8533 85105
> 3 8553 114725
> 4 8561 122195
> 5 8532 100945
> 6 8560 108552
> 7 8634 108707
> 1 8646 117420
> 2 8633 113823
> 3 8680 82763
> 4 8765 121072
> 5 8756 89835
> 6 8750 104578
> 7 8790 88429
>
> I wish to calculate average of the second and third columns based on the
> first column for each repeated 7 days. The length of the data is 1442. That
> is 206 by 7. So I should arrive at 207 data points for each of the two
> columns after calculating the mean of each group 1-7.
>
> I have both tried factor/tapply and aggregate functions but seem not to be
> making progress.
>
> Thank you very much for your idea.
>
> Best wishes
> Ogbos
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From giftedlife2014 @ending from gm@il@com  Wed Nov 28 05:01:15 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Wed, 28 Nov 2018 05:01:15 +0100
Subject: [R] Applying a certain formula to a repeated sample data: SOLVED
In-Reply-To: <CA+8X3fWTQd7ftWXL-yZ8+MhvzHf5GiU00kK98x2qC1yenBe99A@mail.gmail.com>
References: <CAC8ss33K==HfbLnyZRVgOhUzbgm2TzEWZ-e6H19khgEc4RS=Aw@mail.gmail.com>
 <CA+8X3fWTQd7ftWXL-yZ8+MhvzHf5GiU00kK98x2qC1yenBe99A@mail.gmail.com>
Message-ID: <CAC8ss33BKeY4c_9VViEDCpXH65cnLWpW5mT_p8HtTFtobCSNuw@mail.gmail.com>

On Wed, Nov 28, 2018 at 4:31 AM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Ogbos,
> If we assume that you have a 3 column data frame named oodf, how about:
>
> Dear Jim,

Thank you so much.

The code just made life very easier for me.

best regards
Ogbos



> oodf[,4]<-floor((cumsum(oodf[,1])-1)/28)
> col2means<-by(oodf[,2],oodf[,4],mean)
> col3means<-by(oodf[,3],oodf[,4],mean)
>
> Jim
>
> On Wed, Nov 28, 2018 at 2:06 PM Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> >
> > Dear List,
> > I have three data-column data. The data is of the form:
> > 1 8590 12516
> > 2 8641 98143
> > 3 8705 98916
> > 4 8750 89911
> > 5 8685 104835
> > 6 8629 121963
> > 7 8676 77655
> > 1 8577 81081
> > 2 8593 83385
> > 3 8642 112164
> > 4 8708 103684
> > 5 8622 83982
> > 6 8593 75944
> > 7 8600 97036
> > 1 8650 104911
> > 2 8730 114098
> > 3 8731 99421
> > 4 8715 85707
> > 5 8717 81273
> > 6 8739 106462
> > 7 8684 110635
> > 1 8713 105214
> > 2 8771 92456
> > 3 8759 109270
> > 4 8762 99150
> > 5 8730 77306
> > 6 8780 86324
> > 7 8804 90214
> > 1 8797 99894
> > 2 8863 95177
> > 3 8873 95910
> > 4 8827 108511
> > 5 8806 115636
> > 6 8869 85542
> > 7 8854 111018
> > 1 8571 93247
> > 2 8533 85105
> > 3 8553 114725
> > 4 8561 122195
> > 5 8532 100945
> > 6 8560 108552
> > 7 8634 108707
> > 1 8646 117420
> > 2 8633 113823
> > 3 8680 82763
> > 4 8765 121072
> > 5 8756 89835
> > 6 8750 104578
> > 7 8790 88429
> >
> > I wish to calculate average of the second and third columns based on the
> > first column for each repeated 7 days. The length of the data is 1442.
> That
> > is 206 by 7. So I should arrive at 207 data points for each of the two
> > columns after calculating the mean of each group 1-7.
> >
> > I have both tried factor/tapply and aggregate functions but seem not to
> be
> > making progress.
> >
> > Thank you very much for your idea.
> >
> > Best wishes
> > Ogbos
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From giftedlife2014 @ending from gm@il@com  Wed Nov 28 05:15:18 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Wed, 28 Nov 2018 05:15:18 +0100
Subject: [R] Applying a certain formula to a repeated sample data
In-Reply-To: <CA+8X3fWTQd7ftWXL-yZ8+MhvzHf5GiU00kK98x2qC1yenBe99A@mail.gmail.com>
References: <CAC8ss33K==HfbLnyZRVgOhUzbgm2TzEWZ-e6H19khgEc4RS=Aw@mail.gmail.com>
 <CA+8X3fWTQd7ftWXL-yZ8+MhvzHf5GiU00kK98x2qC1yenBe99A@mail.gmail.com>
Message-ID: <CAC8ss31qKe=X=D=K45oRh9iCHHK4=1kTN4KUo_f4-ZJ6vNfOvw@mail.gmail.com>

Dear Jim,

I wish also to use the means calculated and apply a certain formula on the
same data frame. In particular, I would like to subtract the means of each
of these seven days from each of the seven days and and divide the outcome
by the same means. If I represent m1 by the means of each seven days in
column 1, and c1 is taken as column 1 data. My formula will be of the form:
aa<-(c1-m1)/m1.

I tried it on the first 7 rows and I have what I am looking for.:
 -0.0089986156
  -0.0031149054
   0.0042685741
   0.0094600831
   0.0019612367
  -0.0044993078
   0.0009229349

But doing it manually will take much time.

Many thanks for going a step further to assist me.

Warmest regards.
Ogbos

On Wed, Nov 28, 2018 at 4:31 AM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Ogbos,
> If we assume that you have a 3 column data frame named oodf, how about:
>
> oodf[,4]<-floor((cumsum(oodf[,1])-1)/28)
> col2means<-by(oodf[,2],oodf[,4],mean)
> col3means<-by(oodf[,3],oodf[,4],mean)
>
> Jim
>
> On Wed, Nov 28, 2018 at 2:06 PM Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> >
> > Dear List,
> > I have three data-column data. The data is of the form:
> > 1 8590 12516
> > 2 8641 98143
> > 3 8705 98916
> > 4 8750 89911
> > 5 8685 104835
> > 6 8629 121963
> > 7 8676 77655
> > 1 8577 81081
> > 2 8593 83385
> > 3 8642 112164
> > 4 8708 103684
> > 5 8622 83982
> > 6 8593 75944
> > 7 8600 97036
> > 1 8650 104911
> > 2 8730 114098
> > 3 8731 99421
> > 4 8715 85707
> > 5 8717 81273
> > 6 8739 106462
> > 7 8684 110635
> > 1 8713 105214
> > 2 8771 92456
> > 3 8759 109270
> > 4 8762 99150
> > 5 8730 77306
> > 6 8780 86324
> > 7 8804 90214
> > 1 8797 99894
> > 2 8863 95177
> > 3 8873 95910
> > 4 8827 108511
> > 5 8806 115636
> > 6 8869 85542
> > 7 8854 111018
> > 1 8571 93247
> > 2 8533 85105
> > 3 8553 114725
> > 4 8561 122195
> > 5 8532 100945
> > 6 8560 108552
> > 7 8634 108707
> > 1 8646 117420
> > 2 8633 113823
> > 3 8680 82763
> > 4 8765 121072
> > 5 8756 89835
> > 6 8750 104578
> > 7 8790 88429
> >
> > I wish to calculate average of the second and third columns based on the
> > first column for each repeated 7 days. The length of the data is 1442.
> That
> > is 206 by 7. So I should arrive at 207 data points for each of the two
> > columns after calculating the mean of each group 1-7.
> >
> > I have both tried factor/tapply and aggregate functions but seem not to
> be
> > making progress.
> >
> > Thank you very much for your idea.
> >
> > Best wishes
> > Ogbos
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From giftedlife2014 @ending from gm@il@com  Wed Nov 28 06:17:11 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Wed, 28 Nov 2018 06:17:11 +0100
Subject: [R] Applying a certain formula to a repeated sample data
In-Reply-To: <CAC8ss31qKe=X=D=K45oRh9iCHHK4=1kTN4KUo_f4-ZJ6vNfOvw@mail.gmail.com>
References: <CAC8ss33K==HfbLnyZRVgOhUzbgm2TzEWZ-e6H19khgEc4RS=Aw@mail.gmail.com>
 <CA+8X3fWTQd7ftWXL-yZ8+MhvzHf5GiU00kK98x2qC1yenBe99A@mail.gmail.com>
 <CAC8ss31qKe=X=D=K45oRh9iCHHK4=1kTN4KUo_f4-ZJ6vNfOvw@mail.gmail.com>
Message-ID: <CAC8ss33JAiKDP6Ukxf5VGVB6HwHmtB4OxW_k744C_4LrYE3gzg@mail.gmail.com>

Dear Jim,

I don't think my problem is clear the way I put.

I have been trying to manually apply the formula to some rows.

This is what I have done.
I cut and past some rows from 1-7 and save each with a different file as
shown below:

1 8590 12516
2 8641 98143
3 8705 98916
4 8750 89911
5 8685 104835
6 8629 121963
7 8676 77655


1 8577 81081
2 8593 83385
3 8642 112164
4 8708 103684
5 8622 83982
6 8593 75944
7 8600 97036


1 8650 104911
2 8730 114098
3 8731 99421
4 8715 85707
5 8717 81273
6 8739 106462
7 8684 110635


1 8713 105214
2 8771 92456
3 8759 109270
4 8762 99150
5 8730 77306
6 8780 86324
7 8804 90214


1 8797 99894
2 8863 95177
3 8873 95910
4 8827 108511
5 8806 115636
6 8869 85542
7 8854 111018


1 8571 93247
2 8533 85105
3 8553 114725
4 8561 122195
5 8532 100945
6 8560 108552
7 8634 108707


1 8646 117420
2 8633 113823
3 8680 82763
4 8765 121072
5 8756 89835
6 8750 104578
7 8790 88429

Each of them are then read as:
d1<-read.table("dat1",col.names=c("n","CR","WW"))
d2<-read.table("dat2",col.names=c("n","CR","WW"))
d3<-read.table("dat3",col.names=c("n","CR","WW"))
d4<-read.table("dat4",col.names=c("n","CR","WW"))
d5<-read.table("dat5",col.names=c("n","CR","WW"))
d6<-read.table("dat6",col.names=c("n","CR","WW"))
d7<-read.table("dat7",col.names=c("n","CR","WW"))

And my formula for percentage change applied as follows for column 2:
a1<-((d1$CR-mean(d1$CR))/mean(CR))*100
a2<-((d2$CR-mean(d2$CR))/mean(CR))*100
a3<-((d3$CR-mean(d3$CR))/mean(CR))*100
a4<-((d4$CR-mean(d4$CR))/mean(CR))*100
a5<-((d5$CR-mean(d5$CR))/mean(CR))*100
a6<-((d6$CR-mean(d6$CR))/mean(CR))*100
a7<-((d7$CR-mean(d7$CR))/mean(CR))*100

a1-a7 actually gives percentage change in the data.

Instead of doing this one after the other, can you please give an
indication on how I may apply this formula to the data frame with probably
a code.

Thank you again.

Best
Ogbos

On Wed, Nov 28, 2018 at 5:15 AM Ogbos Okike <giftedlife2014 at gmail.com>
wrote:

> Dear Jim,
>
> I wish also to use the means calculated and apply a certain formula on
> the  same data frame. In particular, I would like to subtract the means of
> each of these seven days from each of the seven days and and divide the
> outcome by the same means. If I represent m1 by the means of each seven
> days in column 1, and c1 is taken as column 1 data. My formula will be of
> the form:
> aa<-(c1-m1)/m1.
>
> I tried it on the first 7 rows and I have what I am looking for.:
>  -0.0089986156
>   -0.0031149054
>    0.0042685741
>    0.0094600831
>    0.0019612367
>   -0.0044993078
>    0.0009229349
>
> But doing it manually will take much time.
>
> Many thanks for going a step further to assist me.
>
> Warmest regards.
> Ogbos
>
> On Wed, Nov 28, 2018 at 4:31 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Ogbos,
>> If we assume that you have a 3 column data frame named oodf, how about:
>>
>> oodf[,4]<-floor((cumsum(oodf[,1])-1)/28)
>> col2means<-by(oodf[,2],oodf[,4],mean)
>> col3means<-by(oodf[,3],oodf[,4],mean)
>>
>> Jim
>>
>> On Wed, Nov 28, 2018 at 2:06 PM Ogbos Okike <giftedlife2014 at gmail.com>
>> wrote:
>> >
>> > Dear List,
>> > I have three data-column data. The data is of the form:
>> > 1 8590 12516
>> > 2 8641 98143
>> > 3 8705 98916
>> > 4 8750 89911
>> > 5 8685 104835
>> > 6 8629 121963
>> > 7 8676 77655
>> > 1 8577 81081
>> > 2 8593 83385
>> > 3 8642 112164
>> > 4 8708 103684
>> > 5 8622 83982
>> > 6 8593 75944
>> > 7 8600 97036
>> > 1 8650 104911
>> > 2 8730 114098
>> > 3 8731 99421
>> > 4 8715 85707
>> > 5 8717 81273
>> > 6 8739 106462
>> > 7 8684 110635
>> > 1 8713 105214
>> > 2 8771 92456
>> > 3 8759 109270
>> > 4 8762 99150
>> > 5 8730 77306
>> > 6 8780 86324
>> > 7 8804 90214
>> > 1 8797 99894
>> > 2 8863 95177
>> > 3 8873 95910
>> > 4 8827 108511
>> > 5 8806 115636
>> > 6 8869 85542
>> > 7 8854 111018
>> > 1 8571 93247
>> > 2 8533 85105
>> > 3 8553 114725
>> > 4 8561 122195
>> > 5 8532 100945
>> > 6 8560 108552
>> > 7 8634 108707
>> > 1 8646 117420
>> > 2 8633 113823
>> > 3 8680 82763
>> > 4 8765 121072
>> > 5 8756 89835
>> > 6 8750 104578
>> > 7 8790 88429
>> >
>> > I wish to calculate average of the second and third columns based on the
>> > first column for each repeated 7 days. The length of the data is 1442.
>> That
>> > is 206 by 7. So I should arrive at 207 data points for each of the two
>> > columns after calculating the mean of each group 1-7.
>> >
>> > I have both tried factor/tapply and aggregate functions but seem not to
>> be
>> > making progress.
>> >
>> > Thank you very much for your idea.
>> >
>> > Best wishes
>> > Ogbos
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Nov 28 07:10:12 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 27 Nov 2018 22:10:12 -0800 (PST)
Subject: [R] Applying a certain formula to a repeated sample data
In-Reply-To: <CAC8ss33JAiKDP6Ukxf5VGVB6HwHmtB4OxW_k744C_4LrYE3gzg@mail.gmail.com>
References: <CAC8ss33K==HfbLnyZRVgOhUzbgm2TzEWZ-e6H19khgEc4RS=Aw@mail.gmail.com>
 <CA+8X3fWTQd7ftWXL-yZ8+MhvzHf5GiU00kK98x2qC1yenBe99A@mail.gmail.com>
 <CAC8ss31qKe=X=D=K45oRh9iCHHK4=1kTN4KUo_f4-ZJ6vNfOvw@mail.gmail.com>
 <CAC8ss33JAiKDP6Ukxf5VGVB6HwHmtB4OxW_k744C_4LrYE3gzg@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1811272156200.68628@pedal.dcn.davis.ca.us>

Thank you for providing a clarifying example. I think a useful function 
for you to get familiar with is the "ave" function. It is kind of like 
aggregate except that it works when the operation you want to apply to the 
group of elements will returns the same number of elements as were given 
to it.

Also, in the future please figure out how to tell gmail to send plain text 
to the mailing list instead of HTML. You were lucky this time, but often 
HTML email gets horribly mangled as it goes through the mailing list and 
gets all the formatting removed.

###############################
dta <- read.table( text =
"n CR WW
1 8590 12516
2 8641 98143
3 8705 98916
4 8750 89911
5 8685 104835
6 8629 121963
7 8676 77655
1 8577 81081
2 8593 83385
3 8642 112164
4 8708 103684
5 8622 83982
6 8593 75944
7 8600 97036
1 8650 104911
2 8730 114098
3 8731 99421
4 8715 85707
5 8717 81273
6 8739 106462
7 8684 110635
1 8713 105214
2 8771 92456
3 8759 109270
4 8762 99150
5 8730 77306
6 8780 86324
7 8804 90214
1 8797 99894
2 8863 95177
3 8873 95910
4 8827 108511
5 8806 115636
6 8869 85542
7 8854 111018
1 8571 93247
2 8533 85105
3 8553 114725
4 8561 122195
5 8532 100945
6 8560 108552
7 8634 108707
1 8646 117420
2 8633 113823
3 8680 82763
4 8765 121072
5 8756 89835
6 8750 104578
7 8790 88429
",header=TRUE)

# one way to make a grouping vector
dta$G <- cumsum( c( 1, diff( dta$n ) < 0 ) 
)
# your operation
fn <- function( x ) {
   m <- mean( x )
  ( x - m ) / m * 100
}
# your operation, computing for each group
gn <- function( x, g ) {
   ave( x, g, FUN = fn )
}
# do the computations
dta$CRpct <- gn( dta$CR, dta$G )
dta$WWpct <- gn( dta$WW, dta$G )
dta
#>    n   CR     WW G        CRpct       WWpct
#> 1  1 8590  12516 1 -0.899861560 -85.4932369
#> 2  2 8641  98143 1 -0.311490540  13.7533758
#> 3  3 8705  98916 1  0.426857407  14.6493272
#> 4  4 8750  89911 1  0.946008306   4.2120148
#> 5  5 8685 104835 1  0.196123673  21.5097882
#> 6  6 8629 121963 1 -0.449930780  41.3621243
#> 7  7 8676  77655 1  0.092293493  -9.9933934
#> 8  1 8577  81081 2 -0.490594182 -10.9385886
#> 9  2 8593  83385 2 -0.304963951  -8.4078170
#> 10 3 8642 112164 2  0.263528632  23.2037610
#> 11 4 8708 103684 2  1.029253336  13.8891155
#> 12 5 8622  83982 2  0.031490843  -7.7520572
#> 13 6 8593  75944 2 -0.304963951 -16.5811987
#> 14 7 8600  97036 2 -0.223750725   6.5867850
#> 15 1 8650 104911 3 -0.682347538   4.5366096
#> 16 2 8730 114098 3  0.236197225  13.6908244
#> 17 3 8731  99421 3  0.247679034  -0.9337985
#> 18 4 8715  85707 3  0.063970082 -14.5988581
#> 19 5 8717  81273 3  0.086933701 -19.0170347
#> 20 6 8739 106462 3  0.339533510   6.0820746
#> 21 7 8684 110635 3 -0.291966014  10.2401827
#> 22 1 8713 105214 4 -0.534907614  11.6017662
#> 23 2 8771  92456 4  0.127203640  -1.9307991
#> 24 3 8759 109270 4 -0.009784895  15.9040146
#> 25 4 8762  99150 4  0.024462238   5.1696079
#> 26 5 8730  77306 4 -0.340840523 -18.0005879
#> 27 6 8780  86324 4  0.229945042  -8.4350859
#> 28 7 8804  90214 4  0.503922112  -4.3089157
#> 29 1 8797  99894 5 -0.500896767  -1.7465519
#> 30 2 8863  95177 5  0.245600995  -6.3860849
#> 31 3 8873  95910 5  0.358706717  -5.6651229
#> 32 4 8827 108511 5 -0.161579602   6.7289318
#> 33 5 8806 115636 5 -0.399101617  13.7369184
#> 34 6 8869  85542 5  0.313464428 -15.8628500
#> 35 7 8854 111018 5  0.143805846   9.1947595
#> 36 1 8571  93247 6  0.088415855 -11.0088128
#> 37 2 8533  85105 6 -0.355331643 -18.7792102
#> 38 3 8553 114725 6 -0.121780328   9.4889267
#> 39 4 8561 122195 6 -0.028359802  16.6179943
#> 40 5 8532 100945 6 -0.367009209  -3.6621512
#> 41 6 8560 108552 6 -0.040037368   3.5976637
#> 42 7 8634 108707 6  0.824102496   3.7455895
#> 43 1 8646 117420 7 -0.816125860  14.4890796
#> 44 2 8633 113823 7 -0.965257293  10.9818643
#> 45 3 8680  82763 7 -0.426089807 -19.3028471
#> 46 4 8765 121072 7  0.549000328  18.0499220
#> 47 5 8756  89835 7  0.445755490 -12.4073713
#> 48 6 8750 104578 7  0.376925598   1.9676287
#> 49 7 8790  88429 7  0.835791544 -13.7782761

#' Created on 2018-11-27 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
###############################

On Wed, 28 Nov 2018, Ogbos Okike wrote:

> Dear Jim,
>
> I don't think my problem is clear the way I put.
>
> I have been trying to manually apply the formula to some rows.
>
> This is what I have done.
> I cut and past some rows from 1-7 and save each with a different file as
> shown below:
>
> 1 8590 12516
> 2 8641 98143
> 3 8705 98916
> 4 8750 89911
> 5 8685 104835
> 6 8629 121963
> 7 8676 77655
>
>
> 1 8577 81081
> 2 8593 83385
> 3 8642 112164
> 4 8708 103684
> 5 8622 83982
> 6 8593 75944
> 7 8600 97036
>
>
> 1 8650 104911
> 2 8730 114098
> 3 8731 99421
> 4 8715 85707
> 5 8717 81273
> 6 8739 106462
> 7 8684 110635
>
>
> 1 8713 105214
> 2 8771 92456
> 3 8759 109270
> 4 8762 99150
> 5 8730 77306
> 6 8780 86324
> 7 8804 90214
>
>
> 1 8797 99894
> 2 8863 95177
> 3 8873 95910
> 4 8827 108511
> 5 8806 115636
> 6 8869 85542
> 7 8854 111018
>
>
> 1 8571 93247
> 2 8533 85105
> 3 8553 114725
> 4 8561 122195
> 5 8532 100945
> 6 8560 108552
> 7 8634 108707
>
>
> 1 8646 117420
> 2 8633 113823
> 3 8680 82763
> 4 8765 121072
> 5 8756 89835
> 6 8750 104578
> 7 8790 88429
>
> Each of them are then read as:
> d1<-read.table("dat1",col.names=c("n","CR","WW"))
> d2<-read.table("dat2",col.names=c("n","CR","WW"))
> d3<-read.table("dat3",col.names=c("n","CR","WW"))
> d4<-read.table("dat4",col.names=c("n","CR","WW"))
> d5<-read.table("dat5",col.names=c("n","CR","WW"))
> d6<-read.table("dat6",col.names=c("n","CR","WW"))
> d7<-read.table("dat7",col.names=c("n","CR","WW"))
>
> And my formula for percentage change applied as follows for column 2:
> a1<-((d1$CR-mean(d1$CR))/mean(CR))*100
> a2<-((d2$CR-mean(d2$CR))/mean(CR))*100
> a3<-((d3$CR-mean(d3$CR))/mean(CR))*100
> a4<-((d4$CR-mean(d4$CR))/mean(CR))*100
> a5<-((d5$CR-mean(d5$CR))/mean(CR))*100
> a6<-((d6$CR-mean(d6$CR))/mean(CR))*100
> a7<-((d7$CR-mean(d7$CR))/mean(CR))*100
>
> a1-a7 actually gives percentage change in the data.
>
> Instead of doing this one after the other, can you please give an
> indication on how I may apply this formula to the data frame with probably
> a code.
>
> Thank you again.
>
> Best
> Ogbos
>
> On Wed, Nov 28, 2018 at 5:15 AM Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
>
>> Dear Jim,
>>
>> I wish also to use the means calculated and apply a certain formula on
>> the  same data frame. In particular, I would like to subtract the means of
>> each of these seven days from each of the seven days and and divide the
>> outcome by the same means. If I represent m1 by the means of each seven
>> days in column 1, and c1 is taken as column 1 data. My formula will be of
>> the form:
>> aa<-(c1-m1)/m1.
>>
>> I tried it on the first 7 rows and I have what I am looking for.:
>>  -0.0089986156
>>   -0.0031149054
>>    0.0042685741
>>    0.0094600831
>>    0.0019612367
>>   -0.0044993078
>>    0.0009229349
>>
>> But doing it manually will take much time.
>>
>> Many thanks for going a step further to assist me.
>>
>> Warmest regards.
>> Ogbos
>>
>> On Wed, Nov 28, 2018 at 4:31 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>>> Hi Ogbos,
>>> If we assume that you have a 3 column data frame named oodf, how about:
>>>
>>> oodf[,4]<-floor((cumsum(oodf[,1])-1)/28)
>>> col2means<-by(oodf[,2],oodf[,4],mean)
>>> col3means<-by(oodf[,3],oodf[,4],mean)
>>>
>>> Jim
>>>
>>> On Wed, Nov 28, 2018 at 2:06 PM Ogbos Okike <giftedlife2014 at gmail.com>
>>> wrote:
>>>>
>>>> Dear List,
>>>> I have three data-column data. The data is of the form:
>>>> 1 8590 12516
>>>> 2 8641 98143
>>>> 3 8705 98916
>>>> 4 8750 89911
>>>> 5 8685 104835
>>>> 6 8629 121963
>>>> 7 8676 77655
>>>> 1 8577 81081
>>>> 2 8593 83385
>>>> 3 8642 112164
>>>> 4 8708 103684
>>>> 5 8622 83982
>>>> 6 8593 75944
>>>> 7 8600 97036
>>>> 1 8650 104911
>>>> 2 8730 114098
>>>> 3 8731 99421
>>>> 4 8715 85707
>>>> 5 8717 81273
>>>> 6 8739 106462
>>>> 7 8684 110635
>>>> 1 8713 105214
>>>> 2 8771 92456
>>>> 3 8759 109270
>>>> 4 8762 99150
>>>> 5 8730 77306
>>>> 6 8780 86324
>>>> 7 8804 90214
>>>> 1 8797 99894
>>>> 2 8863 95177
>>>> 3 8873 95910
>>>> 4 8827 108511
>>>> 5 8806 115636
>>>> 6 8869 85542
>>>> 7 8854 111018
>>>> 1 8571 93247
>>>> 2 8533 85105
>>>> 3 8553 114725
>>>> 4 8561 122195
>>>> 5 8532 100945
>>>> 6 8560 108552
>>>> 7 8634 108707
>>>> 1 8646 117420
>>>> 2 8633 113823
>>>> 3 8680 82763
>>>> 4 8765 121072
>>>> 5 8756 89835
>>>> 6 8750 104578
>>>> 7 8790 88429
>>>>
>>>> I wish to calculate average of the second and third columns based on the
>>>> first column for each repeated 7 days. The length of the data is 1442.
>>> That
>>>> is 206 by 7. So I should arrive at 207 data points for each of the two
>>>> columns after calculating the mean of each group 1-7.
>>>>
>>>> I have both tried factor/tapply and aggregate functions but seem not to
>>> be
>>>> making progress.
>>>>
>>>> Thank you very much for your idea.
>>>>
>>>> Best wishes
>>>> Ogbos
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From ruben @ending from kfupm@edu@@@  Wed Nov 28 09:29:31 2018
From: ruben @ending from kfupm@edu@@@ (Ruben)
Date: Wed, 28 Nov 2018 11:29:31 +0300
Subject: [R] High dimensional optimization in R
In-Reply-To: <CAM_vjun9NAUs=yTqQeQQRYu09OM6JiiRYJXWD1u0fYUqEC62hQ@mail.gmail.com>
References: <CAGZkDQhiVVuyJ1c6D3-HOxqash19dWsOfnHbnFrbx6TLcp5nYA@mail.gmail.com>
 <CAM_vjun9NAUs=yTqQeQQRYu09OM6JiiRYJXWD1u0fYUqEC62hQ@mail.gmail.com>
Message-ID: <0acb74a5-e7f7-0c5e-ad98-72ded5120ce6@kfupm.edu.sa>

Hi,

Sarah Goslee (jn reply to? Basic optimization question (I'm a rookie)):? 
"R is quite good at optimization."

I wonder what is the experience of the R user community with high 
dimensional problems, various objective functions and various numerical 
methods in R.

In my experience with my package CatDyn (which depends on optimx), I 
have fitted nonlinear models with nearly 50 free parameters using 
normal, lognormal, gamma, Poisson and negative binomial exact 
loglikelihoods, and adjusted profile normal and adjusted profile 
lognormal approximate loglikelihoods.

Most numerical methods crash, but CG and spg often, and BFGS, bobyqa, 
newuoa and Nelder-Mead sometimes, do yield good results (all numerical 
gradients less than 1)? after 1 day or more running in a normal 64 bit 
PC with Ubuntu 16.04 or Windows 7.

Ruben

-- 

Ruben H. Roa-Ureta, Ph. D.
Consultant, ORCID ID 0000-0002-9620-5224
Marine Studies Section, Center for Environment and Water,
Research Institute, King Fahd University of Petroleum and Minerals,
KFUPM Box 1927, Dhahran 31261, Saudi Arabia
Office Phone : 966-3-860-7850
Cellular Phone : 966-540026401


From jrkride@u @ending from y@hoo@c@  Wed Nov 28 13:54:17 2018
From: jrkride@u @ending from y@hoo@c@ (John Kane)
Date: Wed, 28 Nov 2018 12:54:17 +0000 (UTC)
Subject: [R] detecting measurement of specific id in column in R
In-Reply-To: <CAPYt5uEpt0ZjEZM6SXYFQEo1KJ8umgyVsRdNkjKvgzku8ZPBHw@mail.gmail.com>
References: <CAPYt5uEpt0ZjEZM6SXYFQEo1KJ8umgyVsRdNkjKvgzku8ZPBHw@mail.gmail.com>
Message-ID: <463040569.7576638.1543409657231@mail.yahoo.com>

 No attached file. R-help is very fussy about what kind of file it will accept, A txt or pdf is the best bet. On the other hand it usually is best to include any code and sample data in the actual e-mail.? Use the function dput() as the best way to supply data.
    On Thursday, November 22, 2018, 11:15:00 a.m. EST, Romy Rehschuh via R-help <r-help at r-project.org> wrote:  
 
 Dear all,

I hope this is the right way to ask questions.
I have a problem with R regarding the detection of the measurement of a
specific sample_id (see example file attached). I have to substract the
"IN" values (means the air which goes into the chambers) from the values of
"d13C", "ppm_CO2" and "ppm_13CO2" for every single chamber (=sample ID).
The "IN" values have to be the ones which were measured* before *the
measurements of the single chambers in time. I measured "IN" once and then
up to 10 chambers in a row to safe time, then "IN" again, but it can change.
Therefore, searching for the closest "IN" does not work.

Do you have any suggestions? Would it be possible to write a loop for this?
I would really much appreciate your help!

Best, Vicci
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From @ndik@putr@@gu@ti@n99 @ending from gm@il@com  Wed Nov 28 11:37:04 2018
From: @ndik@putr@@gu@ti@n99 @ending from gm@il@com (Andika Putra Agustian)
Date: Wed, 28 Nov 2018 17:37:04 +0700
Subject: [R] R - Comparing BIC Results Between Expectation-Maximization (EM)
 and Linear Regression (LR) Algorithm
Message-ID: <CAEbX+tLPCMJKbORAcJkCtXjB7HY3wdiH-QHKHMQbwGnA_TunQQ@mail.gmail.com>

Hi there,

I am trying to compare result of BIC (Bayesian Information Criterion)
between Expectation-Maximization (EM) and Linear Regression (LR) Algorithm
on "Hotel Occupancy" data using R, for my college task.

The data contains data occupancy percentage from January to December 2017,
based on islands in Indonesia.

The result I got :
- for EM : -2687.035
- for LR : 225.0898

*notes :
- For EM, I use mclust packages, then I type mclustBIC(variable name)
- For LR, I type BIC(MonthA~MonthB) etc (every 2 month), then I count the
average as the BIC result.

I don't know how to compare it, which BIC result is better (EM or LR)?

Can you explain the reason please?
Thanks in advance!

Regards,
Andika.

	[[alternative HTML version deleted]]


From @@r@h@go@lee @ending from gm@il@com  Wed Nov 28 18:05:26 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Wed, 28 Nov 2018 12:05:26 -0500
Subject: [R] 
 R - Comparing BIC Results Between Expectation-Maximization (EM)
 and Linear Regression (LR) Algorithm
In-Reply-To: <CAEbX+tLPCMJKbORAcJkCtXjB7HY3wdiH-QHKHMQbwGnA_TunQQ@mail.gmail.com>
References: <CAEbX+tLPCMJKbORAcJkCtXjB7HY3wdiH-QHKHMQbwGnA_TunQQ@mail.gmail.com>
Message-ID: <CAM_vjukS3Hj3ym3fOxoXWB+crYK7LNeAWt9KuoCah=u7cNfJsg@mail.gmail.com>

Hi Andika,

We don't do homework on this list, and your question is a statistics
question rather than an R question anyway.

That said, googling "interpreting BIC" should get you going, if
talking to your professor and reading your textbook haven't helped.

Sarah

On Wed, Nov 28, 2018 at 11:30 AM Andika Putra Agustian
<andikaputraagustian99 at gmail.com> wrote:
>
> Hi there,
>
> I am trying to compare result of BIC (Bayesian Information Criterion)
> between Expectation-Maximization (EM) and Linear Regression (LR) Algorithm
> on "Hotel Occupancy" data using R, for my college task.
>
> The data contains data occupancy percentage from January to December 2017,
> based on islands in Indonesia.
>
> The result I got :
> - for EM : -2687.035
> - for LR : 225.0898
>
> *notes :
> - For EM, I use mclust packages, then I type mclustBIC(variable name)
> - For LR, I type BIC(MonthA~MonthB) etc (every 2 month), then I count the
> average as the BIC result.
>
> I don't know how to compare it, which BIC result is better (EM or LR)?
>
> Can you explain the reason please?
> Thanks in advance!
>
> Regards,
> Andika.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From upr@vitelev @ending from gm@il@com  Wed Nov 28 14:49:42 2018
From: upr@vitelev @ending from gm@il@com (Philipp Upravitelev)
Date: Wed, 28 Nov 2018 16:49:42 +0300
Subject: [R] why the base::round(0.015, 2) returns 0.02?
Message-ID: <CAHqa_9o8yJB-GwpDgFFawfiMtCx+YQmi_tusC-E9y2OYf4-9aQ@mail.gmail.com>

Dear colleagues,
could you help me with the function base::round()? I can't understand how
it works.

For example, when I want to round 0.015 to the second digit, base::round()
returns 0.02.

But the real representation of the 0.015 is different:
> sprintf('%.20f', 0.015)
[1] "0.01499999999999999944"
> 0.015 == 0.01499999999999999944
[1] TRUE
> round(0.015, 2)
[1] 0.02

Therefore, according to the arithmetic rules, rounded 0.014 to the second
digit is 0.01. Also, the round() function in other programming languages
(Python, Java) returns 0.01. It is a bit counterintuitive but
mathematically correct.

I'll be very pleased if you could help me to figure out why the
base::round(0.015, 2) returns 0.02 and what is the purpose of this feature.

Best regards,
Philipp Upravitelev

	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Wed Nov 28 18:38:18 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Wed, 28 Nov 2018 17:38:18 +0000
Subject: [R] Bootstrapping One- and Two-Sample Hypothesis Tests of
 Proportion
In-Reply-To: <CAFCoDdBrRC6GNR8JP_-0E2U4M1AKJTh8tRqSBqeRkK2qqemtdA@mail.gmail.com>
References: <CAFCoDdBrRC6GNR8JP_-0E2U4M1AKJTh8tRqSBqeRkK2qqemtdA@mail.gmail.com>
Message-ID: <bc301e6b-62b7-bb9a-25d5-c81c19182761@sapo.pt>

Hello,

What have you tried?
Reproducible example please.

http://adv-r.had.co.nz/Reproducibility.html
https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
https://www.r-bloggers.com/minimal-reproducible-examples/


Rui Barradas

?s 22:33 de 27/11/2018, Janh Anni escreveu:
> Hello R Experts!
> 
> Does anyone know of a relatively straightforward way to bootstrap
> hypothesis tests for proportion in R?
> 
> Thanks in advance!
> 
> Janh
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipb@rr@d@@ @ending from @@po@pt  Wed Nov 28 18:49:33 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Wed, 28 Nov 2018 17:49:33 +0000
Subject: [R] gemo_text issue
In-Reply-To: <3E2DCE80-F3F9-45F2-ABBC-A86C680E18EC@bigelow.org>
References: <BL0PR06MB4834355C489335B0E307D9D498D00@BL0PR06MB4834.namprd06.prod.outlook.com>
 <3E2DCE80-F3F9-45F2-ABBC-A86C680E18EC@bigelow.org>
Message-ID: <4a8d6533-762b-760c-ae3f-3d414065181c@sapo.pt>

Hello,

Your code works but I suggest the following:

1) Instead of loading reshape2 to be used just once

longData <- reshape2::melt(myData)

2) In the call to geom_text, aes() will find the x, y, etc values:

zp1 + geom_text(data=test2, aes(x = con, y = Prob, label = Project, size 
= 6, color = "white"))

3) To the OP.
By naming the graphic object zp1 in all instructions, including the last 
one where the error occurs, you are forcing us to run the previous code 
every time we test a solution. It would be better to do something like

# Ben's code
zp2 <- zp1 + geom_text(data=test2, x=test2$con, y=test2$Prob, label = 
test2$Project, size = 6, color = "white")

# An alternative
zp2 <- zp1 + geom_text(data=test2, aes(x = con, y = Prob, label = 
Project, size = 6, color = "white"))


On both cases, only one code line to run.

Hope this helps,

Rui Barradas

?s 20:30 de 27/11/2018, Ben Tupper escreveu:
> Hi,
> 
> I had to include
> 
> library(reshape2)
> 
> to get things working as you use melt(). Explicitly setting the x and y values in geom_text() is needed since you are providing new data.
> 
> zp1 <- zp1 + geom_text(data=test2, x=test2$con, y=test2$Prob, label = test2$Project, size = 6, color = "white")
> 
> 
> Cheers,
> Ben
> 
>> On Nov 27, 2018, at 3:04 PM, Reith, William [USA] <reith_william at bah.com> wrote:
>>
>> I am experiencing issues with trying to label points added to a ggplot via geom_point. I think an underlying issue is the fact that I already used ggplot function to create a 5x5 risk matrix "background", but I am not certain. I have tried multiple solutions online but cannot find one that has a similar the background plotting I am attempting.
>>
>> I have attached the .R file and a picture of what I am creating minus the buggy text labels. Code is also pasted below.
>>
>> Thanks,
>>
>> William
>>
>>
>> library(ggplot2)
>>
>> Project<-c("C","C","C","C","C","B","B","B","D","E","E","F","F","F","F")
>> Prob<-c(3,3,3,2,2,2,2,2,3,4,3,5,4,3,3)
>> con<-c(3.675941831,2.354582402,2.354582402,2.354582402,1.95075378,3.0602443,3.0602443,3.283695274,1.904452395,3.579022044,3.579022044,2.58190428,1.76065948,2.365243619,1.354491286)
>> test2<-data.frame(Project,Prob,con)
>>
>> ### build risk coloring matrix ###
>> myData <- matrix(c(1,2,3,3,3,1,2,2,3,3,1,1,2,2,3,1,1,2,2,2,1,1,1,1,2), nrow = 5, ncol = 5, byrow = TRUE)
>> rownames(myData) <- c("5", "4", "3", "2","1")
>> colnames(myData) <- c("1", "2", "3", "4","5")
>>
>> ### convert to data frame ###
>> longData <- melt(myData)
>> colnames(longData) <- c("Probability", "Consequence", "value")
>> longData$value<-as.factor(longData$value)
>>
>> ### define color tiles ###
>> color<-c("green" ,"green" ,"green","green"  ,"green",
>>         "yellow","yellow","green","green"  ,"green",
>>         "red"   ,"yellow","yellow","yellow","green",
>>         "red"   ,"red"   ,"yellow","yellow","green",
>>         "red"   ,"red"   ,"red"   ,"yellow","yellow")
>>
>> ### create color background 5x5 ###
>> zp1 <- ggplot(longData,aes(x = Consequence, y = Probability)) #, fill = value))
>> zp1 <- zp1 + geom_tile(fill = color)
>> zp1 <- zp1 + scale_x_continuous(breaks = 0:6, expand = c(0, 0))
>> zp1 <- zp1 + scale_y_continuous(breaks = 0:6, expand = c(0, 0))
>> zp1 <- zp1 + coord_fixed()
>> zp1 <- zp1 + theme_bw()
>> print(zp1)
>>
>> ### Add title and lines ###
>> zp1 <- zp1 + ggtitle("5x5 Plot")+theme(plot.title = element_text(hjust = 0.5))
>> zp1 <- zp1 + geom_vline(xintercept=c(1.5:5.5))
>> zp1 <- zp1 + geom_hline(yintercept=c(1.5:5.5))
>> print(zp1)
>>
>> ### Plot points ###
>> zp1 <- zp1 + geom_point(data=test2, x=test2$con, y=test2$Prob, alpha = 1, size = 9, color = "blue")
>> print(zp1)
>>
>> ### This is the line I cannot get working; tried multiple approaches ###
>> ### intent is to add white labels to plotted points ###
>> zp1 <- zp1 + geom_text(data=test2, label = test2$Project, size = 6, color = "white")
>> print(zp1)
>> <test.png>______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
> 
> Ecological Forecasting: https://eco.bigelow.org/
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipb@rr@d@@ @ending from @@po@pt  Wed Nov 28 18:55:21 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Wed, 28 Nov 2018 17:55:21 +0000
Subject: [R] why the base::round(0.015, 2) returns 0.02?
In-Reply-To: <CAHqa_9o8yJB-GwpDgFFawfiMtCx+YQmi_tusC-E9y2OYf4-9aQ@mail.gmail.com>
References: <CAHqa_9o8yJB-GwpDgFFawfiMtCx+YQmi_tusC-E9y2OYf4-9aQ@mail.gmail.com>
Message-ID: <71f37d02-aa8b-f7f2-7d7b-ba4ab4f5928c@sapo.pt>

Hello,

Your assumption that you can sprintf with 20 digits of precision is 
wrong, you only have 16 decimal digits. And

sprintf('%.16f', 0.015)
#[1] "0.0150000000000000"

0.015 == 0.0150000000000000
#[1] TRUE

This rounds to the nearest even number, 0.02 (IEEE-754).

Hope this helps,

Rui Barradas

?s 13:49 de 28/11/2018, Philipp Upravitelev escreveu:
> Dear colleagues,
> could you help me with the function base::round()? I can't understand how
> it works.
> 
> For example, when I want to round 0.015 to the second digit, base::round()
> returns 0.02.
> 
> But the real representation of the 0.015 is different:
>> sprintf('%.20f', 0.015)
> [1] "0.01499999999999999944"
>> 0.015 == 0.01499999999999999944
> [1] TRUE
>> round(0.015, 2)
> [1] 0.02
> 
> Therefore, according to the arithmetic rules, rounded 0.014 to the second
> digit is 0.01. Also, the round() function in other programming languages
> (Python, Java) returns 0.01. It is a bit counterintuitive but
> mathematically correct.
> 
> I'll be very pleased if you could help me to figure out why the
> base::round(0.015, 2) returns 0.02 and what is the purpose of this feature.
> 
> Best regards,
> Philipp Upravitelev
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch@dunc@n @ending from gm@il@com  Wed Nov 28 19:14:27 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Wed, 28 Nov 2018 13:14:27 -0500
Subject: [R] why the base::round(0.015, 2) returns 0.02?
In-Reply-To: <CAHqa_9o8yJB-GwpDgFFawfiMtCx+YQmi_tusC-E9y2OYf4-9aQ@mail.gmail.com>
References: <CAHqa_9o8yJB-GwpDgFFawfiMtCx+YQmi_tusC-E9y2OYf4-9aQ@mail.gmail.com>
Message-ID: <5351f659-a246-f291-725d-a5bdfe8520b0@gmail.com>

On 28/11/2018 8:49 AM, Philipp Upravitelev wrote:
> Dear colleagues,
> could you help me with the function base::round()? I can't understand how
> it works.
> 
> For example, when I want to round 0.015 to the second digit, base::round()
> returns 0.02.
> 
> But the real representation of the 0.015 is different:
>> sprintf('%.20f', 0.015)
> [1] "0.01499999999999999944"
>> 0.015 == 0.01499999999999999944
> [1] TRUE
>> round(0.015, 2)
> [1] 0.02

This calculation is informative:

100*0.015 - 1.5

which gives 0 on my system.  So even though 0.015 isn't exactly 
representable, when you multiply by 100, you get the exactly correct 
result.  Then the apparent rule for round(x, 2) is:  multiply by 100, 
round to an integer, divide by 100.

Duncan Murdoch

> 
> Therefore, according to the arithmetic rules, rounded 0.014 to the second
> digit is 0.01. Also, the round() function in other programming languages
> (Python, Java) returns 0.01. It is a bit counterintuitive but
> mathematically correct.
> 
> I'll be very pleased if you could help me to figure out why the
> base::round(0.015, 2) returns 0.02 and what is the purpose of this feature.
> 
> Best regards,
> Philipp Upravitelev
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rmh @ending from temple@edu  Wed Nov 28 19:32:19 2018
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Wed, 28 Nov 2018 13:32:19 -0500
Subject: [R] why the base::round(0.015, 2) returns 0.02?
In-Reply-To: <CAHqa_9o8yJB-GwpDgFFawfiMtCx+YQmi_tusC-E9y2OYf4-9aQ@mail.gmail.com>
References: <CAHqa_9o8yJB-GwpDgFFawfiMtCx+YQmi_tusC-E9y2OYf4-9aQ@mail.gmail.com>
Message-ID: <CAGx1TMANL+Y1UXjD=v88PJ4zmuVeGKnJy5WU4GQetXBkTn7kuA@mail.gmail.com>

interesting.  this looks like an OS problem, since ?round says
     ?round? rounds the values in its first argument to the specified
     number of decimal places (default 0).  See ?Details? about ?round
     to even? when rounding off a 5.
Details
     Note that for rounding off a 5, the IEC 60559 standard (see also
     ?IEEE 754?) is expected to be used, ?_go to the even digit_?.
     Therefore ?round(0.5)? is ?0? and ?round(-1.5)? is ?-2?.  However,
     this is dependent on OS services and on representation error
     (since e.g. ?0.15? is not represented exactly, the rounding rule
     applies to the represented number and not to the printed number,
     and so ?round(0.15, 1)? could be either ?0.1? or ?0.2?).

.015 is right on the boundary.  When we look at the internal
representation with Rmpfr,
we see a string of 9s.  the 44 at the end is just noise.  It looks
like the string of 99 is increased to 100
before rounding.
When we increase the precision from the default double precision
(precBits=53) to precBits=55, we
get the anticipated behavior.

> library(Rmpfr)
> round(.015, 2)
[1] 0.02
> getPrec(.015)
[1] 53
> mpfr(0.015, precBits=53)
1 'mpfr' number of precision  53   bits
[1] 0.015
> formatDec(mpfr(0.015, precBits=53))
[1] 0.014999999999999999
> round(0.014999999999999999, 2)
[1] 0.02
> round(0.014999999999999998, 2)
[1] 0.01
> > round(mpfr(0.015, precBits=54), 2)
1 'mpfr' number of precision  54   bits
[1] 0.02
> round(mpfr(0.015, precBits=55), 2)
1 'mpfr' number of precision  55   bits
[1] 0.01
> formatDec(mpfr(0.015, precBits=53))
[1] 0.014999999999999999
> formatDec(mpfr(0.015, precBits=54))
[1] 0.0149999999999999994
> formatDec(mpfr(0.015, precBits=55))
[1] 0.0149999999999999994
> roundMpfr(mpfr(0.014999999999999999, precBits=53), 53)
1 'mpfr' number of precision  53   bits
[1] 0.015
> roundMpfr(mpfr(0.014999999999999999, precBits=53), 54)
1 'mpfr' number of precision  54   bits
[1] 0.014999999999999999
> roundMpfr(mpfr(0.014999999999999999, precBits=53), 55)
1 'mpfr' number of precision  55   bits
[1] 0.014999999999999999
1
> formatHex(mpfr(0.015, precBits=53)*100)
[1] +0x1.8000000000000p+0
> formatHex(mpfr(0.015, precBits=54)*100)
[1] +0x1.80000000000000p+0
> formatHex(mpfr(0.015, precBits=55)*100)
[1] +0x1.7ffffffffffffcp+0
> formatHex(mpfr(0.015, precBits=53))
[1] +0x1.eb851eb851eb8p-7
> formatHex(mpfr(0.015, precBits=54))
[1] +0x1.eb851eb851eb80p-7
> formatHex(mpfr(0.015, precBits=55))
[1] +0x1.eb851eb851eb80p-7
> round(mpfr(0.015, precBits=53), 2)
1 'mpfr' number of precision  53   bits
[1] 0.02
> round(mpfr(0.015, precBits=54), 2)
1 'mpfr' number of precision  54   bits
[1] 0.02
> round(mpfr(0.015, precBits=55), 2)
1 'mpfr' number of precision  55   bits
[1] 0.01
>
>
On Wed, Nov 28, 2018 at 12:31 PM Philipp Upravitelev
<upravitelev at gmail.com> wrote:
>
> Dear colleagues,
> could you help me with the function base::round()? I can't understand how
> it works.
>
> For example, when I want to round 0.015 to the second digit, base::round()
> returns 0.02.
>
> But the real representation of the 0.015 is different:
> > sprintf('%.20f', 0.015)
> [1] "0.01499999999999999944"
> > 0.015 == 0.01499999999999999944
> [1] TRUE
> > round(0.015, 2)
> [1] 0.02
>
> Therefore, according to the arithmetic rules, rounded 0.014 to the second
> digit is 0.01. Also, the round() function in other programming languages
> (Python, Java) returns 0.01. It is a bit counterintuitive but
> mathematically correct.
>
> I'll be very pleased if you could help me to figure out why the
> base::round(0.015, 2) returns 0.02 and what is the purpose of this feature.
>
> Best regards,
> Philipp Upravitelev
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From giftedlife2014 @ending from gm@il@com  Wed Nov 28 20:51:47 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Wed, 28 Nov 2018 20:51:47 +0100
Subject: [R] ] Applying a certain formula to a repeated sample data: RESOLVED
In-Reply-To: <alpine.BSF.2.00.1811272156200.68628@pedal.dcn.davis.ca.us>
References: <CAC8ss33K==HfbLnyZRVgOhUzbgm2TzEWZ-e6H19khgEc4RS=Aw@mail.gmail.com>
 <CA+8X3fWTQd7ftWXL-yZ8+MhvzHf5GiU00kK98x2qC1yenBe99A@mail.gmail.com>
 <CAC8ss31qKe=X=D=K45oRh9iCHHK4=1kTN4KUo_f4-ZJ6vNfOvw@mail.gmail.com>
 <CAC8ss33JAiKDP6Ukxf5VGVB6HwHmtB4OxW_k744C_4LrYE3gzg@mail.gmail.com>
 <alpine.BSF.2.00.1811272156200.68628@pedal.dcn.davis.ca.us>
Message-ID: <CAC8ss30ahJVNe99fLVeDNzAEZFaQ09UFsiyNDLxYOCuBHP=2pQ@mail.gmail.com>

Dear Jeff,

This is great to me!!! Many, many thanks.

I have also clicked the send plain text mode button and I hope this
message will appear in plain text mode.

Thanks again.

Warmest regards.
Ogbos

On Wed, Nov 28, 2018 at 7:06 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Thank you for providing a clarifying example. I think a useful function
> for you to get familiar with is the "ave" function. It is kind of like
> aggregate except that it works when the operation you want to apply to the
> group of elements will returns the same number of elements as were given
> to it.
>
> Also, in the future please figure out how to tell gmail to send plain text
> to the mailing list instead of HTML. You were lucky this time, but often
> HTML email gets horribly mangled as it goes through the mailing list and
> gets all the formatting removed.
>
> ###############################
> dta <- read.table( text =
> "n CR WW
> 1 8590 12516
> 2 8641 98143
> 3 8705 98916
> 4 8750 89911
> 5 8685 104835
> 6 8629 121963
> 7 8676 77655
> 1 8577 81081
> 2 8593 83385
> 3 8642 112164
> 4 8708 103684
> 5 8622 83982
> 6 8593 75944
> 7 8600 97036
> 1 8650 104911
> 2 8730 114098
> 3 8731 99421
> 4 8715 85707
> 5 8717 81273
> 6 8739 106462
> 7 8684 110635
> 1 8713 105214
> 2 8771 92456
> 3 8759 109270
> 4 8762 99150
> 5 8730 77306
> 6 8780 86324
> 7 8804 90214
> 1 8797 99894
> 2 8863 95177
> 3 8873 95910
> 4 8827 108511
> 5 8806 115636
> 6 8869 85542
> 7 8854 111018
> 1 8571 93247
> 2 8533 85105
> 3 8553 114725
> 4 8561 122195
> 5 8532 100945
> 6 8560 108552
> 7 8634 108707
> 1 8646 117420
> 2 8633 113823
> 3 8680 82763
> 4 8765 121072
> 5 8756 89835
> 6 8750 104578
> 7 8790 88429
> ",header=TRUE)
>
> # one way to make a grouping vector
> dta$G <- cumsum( c( 1, diff( dta$n ) < 0 )
> )
> # your operation
> fn <- function( x ) {
>    m <- mean( x )
>   ( x - m ) / m * 100
> }
> # your operation, computing for each group
> gn <- function( x, g ) {
>    ave( x, g, FUN = fn )
> }
> # do the computations
> dta$CRpct <- gn( dta$CR, dta$G )
> dta$WWpct <- gn( dta$WW, dta$G )
> dta
> #>    n   CR     WW G        CRpct       WWpct
> #> 1  1 8590  12516 1 -0.899861560 -85.4932369
> #> 2  2 8641  98143 1 -0.311490540  13.7533758
> #> 3  3 8705  98916 1  0.426857407  14.6493272
> #> 4  4 8750  89911 1  0.946008306   4.2120148
> #> 5  5 8685 104835 1  0.196123673  21.5097882
> #> 6  6 8629 121963 1 -0.449930780  41.3621243
> #> 7  7 8676  77655 1  0.092293493  -9.9933934
> #> 8  1 8577  81081 2 -0.490594182 -10.9385886
> #> 9  2 8593  83385 2 -0.304963951  -8.4078170
> #> 10 3 8642 112164 2  0.263528632  23.2037610
> #> 11 4 8708 103684 2  1.029253336  13.8891155
> #> 12 5 8622  83982 2  0.031490843  -7.7520572
> #> 13 6 8593  75944 2 -0.304963951 -16.5811987
> #> 14 7 8600  97036 2 -0.223750725   6.5867850
> #> 15 1 8650 104911 3 -0.682347538   4.5366096
> #> 16 2 8730 114098 3  0.236197225  13.6908244
> #> 17 3 8731  99421 3  0.247679034  -0.9337985
> #> 18 4 8715  85707 3  0.063970082 -14.5988581
> #> 19 5 8717  81273 3  0.086933701 -19.0170347
> #> 20 6 8739 106462 3  0.339533510   6.0820746
> #> 21 7 8684 110635 3 -0.291966014  10.2401827
> #> 22 1 8713 105214 4 -0.534907614  11.6017662
> #> 23 2 8771  92456 4  0.127203640  -1.9307991
> #> 24 3 8759 109270 4 -0.009784895  15.9040146
> #> 25 4 8762  99150 4  0.024462238   5.1696079
> #> 26 5 8730  77306 4 -0.340840523 -18.0005879
> #> 27 6 8780  86324 4  0.229945042  -8.4350859
> #> 28 7 8804  90214 4  0.503922112  -4.3089157
> #> 29 1 8797  99894 5 -0.500896767  -1.7465519
> #> 30 2 8863  95177 5  0.245600995  -6.3860849
> #> 31 3 8873  95910 5  0.358706717  -5.6651229
> #> 32 4 8827 108511 5 -0.161579602   6.7289318
> #> 33 5 8806 115636 5 -0.399101617  13.7369184
> #> 34 6 8869  85542 5  0.313464428 -15.8628500
> #> 35 7 8854 111018 5  0.143805846   9.1947595
> #> 36 1 8571  93247 6  0.088415855 -11.0088128
> #> 37 2 8533  85105 6 -0.355331643 -18.7792102
> #> 38 3 8553 114725 6 -0.121780328   9.4889267
> #> 39 4 8561 122195 6 -0.028359802  16.6179943
> #> 40 5 8532 100945 6 -0.367009209  -3.6621512
> #> 41 6 8560 108552 6 -0.040037368   3.5976637
> #> 42 7 8634 108707 6  0.824102496   3.7455895
> #> 43 1 8646 117420 7 -0.816125860  14.4890796
> #> 44 2 8633 113823 7 -0.965257293  10.9818643
> #> 45 3 8680  82763 7 -0.426089807 -19.3028471
> #> 46 4 8765 121072 7  0.549000328  18.0499220
> #> 47 5 8756  89835 7  0.445755490 -12.4073713
> #> 48 6 8750 104578 7  0.376925598   1.9676287
> #> 49 7 8790  88429 7  0.835791544 -13.7782761
>
> #' Created on 2018-11-27 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
> ###############################
>
> On Wed, 28 Nov 2018, Ogbos Okike wrote:
>
> > Dear Jim,
> >
> > I don't think my problem is clear the way I put.
> >
> > I have been trying to manually apply the formula to some rows.
> >
> > This is what I have done.
> > I cut and past some rows from 1-7 and save each with a different file as
> > shown below:
> >
> > 1 8590 12516
> > 2 8641 98143
> > 3 8705 98916
> > 4 8750 89911
> > 5 8685 104835
> > 6 8629 121963
> > 7 8676 77655
> >
> >
> > 1 8577 81081
> > 2 8593 83385
> > 3 8642 112164
> > 4 8708 103684
> > 5 8622 83982
> > 6 8593 75944
> > 7 8600 97036
> >
> >
> > 1 8650 104911
> > 2 8730 114098
> > 3 8731 99421
> > 4 8715 85707
> > 5 8717 81273
> > 6 8739 106462
> > 7 8684 110635
> >
> >
> > 1 8713 105214
> > 2 8771 92456
> > 3 8759 109270
> > 4 8762 99150
> > 5 8730 77306
> > 6 8780 86324
> > 7 8804 90214
> >
> >
> > 1 8797 99894
> > 2 8863 95177
> > 3 8873 95910
> > 4 8827 108511
> > 5 8806 115636
> > 6 8869 85542
> > 7 8854 111018
> >
> >
> > 1 8571 93247
> > 2 8533 85105
> > 3 8553 114725
> > 4 8561 122195
> > 5 8532 100945
> > 6 8560 108552
> > 7 8634 108707
> >
> >
> > 1 8646 117420
> > 2 8633 113823
> > 3 8680 82763
> > 4 8765 121072
> > 5 8756 89835
> > 6 8750 104578
> > 7 8790 88429
> >
> > Each of them are then read as:
> > d1<-read.table("dat1",col.names=c("n","CR","WW"))
> > d2<-read.table("dat2",col.names=c("n","CR","WW"))
> > d3<-read.table("dat3",col.names=c("n","CR","WW"))
> > d4<-read.table("dat4",col.names=c("n","CR","WW"))
> > d5<-read.table("dat5",col.names=c("n","CR","WW"))
> > d6<-read.table("dat6",col.names=c("n","CR","WW"))
> > d7<-read.table("dat7",col.names=c("n","CR","WW"))
> >
> > And my formula for percentage change applied as follows for column 2:
> > a1<-((d1$CR-mean(d1$CR))/mean(CR))*100
> > a2<-((d2$CR-mean(d2$CR))/mean(CR))*100
> > a3<-((d3$CR-mean(d3$CR))/mean(CR))*100
> > a4<-((d4$CR-mean(d4$CR))/mean(CR))*100
> > a5<-((d5$CR-mean(d5$CR))/mean(CR))*100
> > a6<-((d6$CR-mean(d6$CR))/mean(CR))*100
> > a7<-((d7$CR-mean(d7$CR))/mean(CR))*100
> >
> > a1-a7 actually gives percentage change in the data.
> >
> > Instead of doing this one after the other, can you please give an
> > indication on how I may apply this formula to the data frame with probably
> > a code.
> >
> > Thank you again.
> >
> > Best
> > Ogbos
> >
> > On Wed, Nov 28, 2018 at 5:15 AM Ogbos Okike <giftedlife2014 at gmail.com>
> > wrote:
> >
> >> Dear Jim,
> >>
> >> I wish also to use the means calculated and apply a certain formula on
> >> the  same data frame. In particular, I would like to subtract the means of
> >> each of these seven days from each of the seven days and and divide the
> >> outcome by the same means. If I represent m1 by the means of each seven
> >> days in column 1, and c1 is taken as column 1 data. My formula will be of
> >> the form:
> >> aa<-(c1-m1)/m1.
> >>
> >> I tried it on the first 7 rows and I have what I am looking for.:
> >>  -0.0089986156
> >>   -0.0031149054
> >>    0.0042685741
> >>    0.0094600831
> >>    0.0019612367
> >>   -0.0044993078
> >>    0.0009229349
> >>
> >> But doing it manually will take much time.
> >>
> >> Many thanks for going a step further to assist me.
> >>
> >> Warmest regards.
> >> Ogbos
> >>
> >> On Wed, Nov 28, 2018 at 4:31 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >>> Hi Ogbos,
> >>> If we assume that you have a 3 column data frame named oodf, how about:
> >>>
> >>> oodf[,4]<-floor((cumsum(oodf[,1])-1)/28)
> >>> col2means<-by(oodf[,2],oodf[,4],mean)
> >>> col3means<-by(oodf[,3],oodf[,4],mean)
> >>>
> >>> Jim
> >>>
> >>> On Wed, Nov 28, 2018 at 2:06 PM Ogbos Okike <giftedlife2014 at gmail.com>
> >>> wrote:
> >>>>
> >>>> Dear List,
> >>>> I have three data-column data. The data is of the form:
> >>>> 1 8590 12516
> >>>> 2 8641 98143
> >>>> 3 8705 98916
> >>>> 4 8750 89911
> >>>> 5 8685 104835
> >>>> 6 8629 121963
> >>>> 7 8676 77655
> >>>> 1 8577 81081
> >>>> 2 8593 83385
> >>>> 3 8642 112164
> >>>> 4 8708 103684
> >>>> 5 8622 83982
> >>>> 6 8593 75944
> >>>> 7 8600 97036
> >>>> 1 8650 104911
> >>>> 2 8730 114098
> >>>> 3 8731 99421
> >>>> 4 8715 85707
> >>>> 5 8717 81273
> >>>> 6 8739 106462
> >>>> 7 8684 110635
> >>>> 1 8713 105214
> >>>> 2 8771 92456
> >>>> 3 8759 109270
> >>>> 4 8762 99150
> >>>> 5 8730 77306
> >>>> 6 8780 86324
> >>>> 7 8804 90214
> >>>> 1 8797 99894
> >>>> 2 8863 95177
> >>>> 3 8873 95910
> >>>> 4 8827 108511
> >>>> 5 8806 115636
> >>>> 6 8869 85542
> >>>> 7 8854 111018
> >>>> 1 8571 93247
> >>>> 2 8533 85105
> >>>> 3 8553 114725
> >>>> 4 8561 122195
> >>>> 5 8532 100945
> >>>> 6 8560 108552
> >>>> 7 8634 108707
> >>>> 1 8646 117420
> >>>> 2 8633 113823
> >>>> 3 8680 82763
> >>>> 4 8765 121072
> >>>> 5 8756 89835
> >>>> 6 8750 104578
> >>>> 7 8790 88429
> >>>>
> >>>> I wish to calculate average of the second and third columns based on the
> >>>> first column for each repeated 7 days. The length of the data is 1442.
> >>> That
> >>>> is 206 by 7. So I should arrive at 207 data points for each of the two
> >>>> columns after calculating the mean of each group 1-7.
> >>>>
> >>>> I have both tried factor/tapply and aggregate functions but seem not to
> >>> be
> >>>> making progress.
> >>>>
> >>>> Thank you very much for your idea.
> >>>>
> >>>> Best wishes
> >>>> Ogbos
> >>>>
> >>>>         [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------


From giftedlife2014 @ending from gm@il@com  Thu Nov 29 14:33:15 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Thu, 29 Nov 2018 14:33:15 +0100
Subject: [R] Correct x-axis of two in one graph
Message-ID: <CAC8ss30sXduG5xd=F1jh0HEbJNL0UxSQHk_9RFv_RRC8Y2agYg@mail.gmail.com>

Dear Contributors,

I have a data of the form:
4 8 10 8590 12516
4 8 11 8641 98143
4 8 12 8705 98916
4 8 13 8750 89911
4 8 14 8685 104835
4 8 15 8629 121963
4 8 16 8676 77655
4 8 17 8577 81081
4 8 18 8593 83385
4 8 19 8642 112164
4 8 20 8708 103684
4 8 21 8622 83982
4 8 22 8593 75944
4 8 23 8600 97036
4 8 24 8650 104911
4 8 25 8730 114098
4 8 26 8731 99421
4 8 27 8715 85707
4 8 28 8717 81273
4 8 29 8739 106462
4 8 30 8684 110635
4 8 31 8713 105214
4 9 1 8771 92456
4 9 2 8759 109270
4 9 3 8762 99150
4 9 4 8730 77306
4 9 5 8780 86324
4 9 6 8804 90214
4 9 7 8797 99894
4 9 8 8863 95177
4 9 9 8873 95910
4 9 10 8827 108511
4 9 11 8806 115636
4 9 12 8869 85542
4 9 13 8854 111018
4 9 14 8571 93247
4 9 15 8533 85105
4 9 16 8553 114725
4 9 17 8561 122195
4 9 18 8532 100945
4 9 19 8560 108552
4 9 20 8634 108707
4 9 21 8646 117420
4 9 22 8633 113823
4 9 23 8680 82763
4 9 24 8765 121072
4 9 25 8756 89835
4 9 26 8750 104578
4 9 27 8790 88429
4 9 28 8824 84022
4 9 29 8843 80413
4 9 30 8795 118462
4 10 1 8795 139761
4 10 2 8805 103049
4 10 3 8826 104996
4 10 4 8841 104496
4 10 5 8882 75603
4 10 6 8865 89768
4 10 7 8875 93353
4 10 8 8898 98410
4 10 9 8920 114540
4 10 10 8937 95220
4 10 11 8926 104083
4 10 12 8912 106089
4 10 13 8898 116228
4 10 14 8926 149610
4 10 15 8954 109594
4 10 16 8941 75008
4 10 17 8952 119182
4 10 18 9003 151011
4 10 19 9002 146797
4 10 20 8995 145769
4 10 21 8969 121248
4 10 22 8954 107991
4 10 23 8992 128
4 10 24 8981 23036
4 10 25 8920 137485
4 10 26 8899 131756
4 10 27 8913 108729
4 10 28 8874 109478
4 10 29 8846 119627
4 10 30 8867 89999
4 10 31 8868 64833
4 11 1 9004 95864
4 11 2 9028 82322
4 11 3 8969 95591
4 11 4 8932 69378
4 11 5 8929 74281
4 11 6 8916 103261
4 11 7 8807 92473
4 11 8 8449 84344
4 11 9 8484 127415
4 11 10 8148 123826
4 11 11 8282 100029
4 11 12 8305 76205
4 11 13 8380 105162
4 11 14 8530 119533
4 11 15 8642 106490
4 11 16 8780 114771
4 11 17 8890 55593
4 11 18 8962 227
4 11 19 8949 109699
4 11 20 8974 86004
4 11 21 8956 74496
4 11 22 8881 109350
4 11 23 8872 134020
4 11 24 8847 105212
4 11 25 8868 91512
where columns 1= year 2004, 2 = month, 3= day, 4= CR data, 5= Lightning data.

The data range is 2004/8/10 to 2008/8/22.
With the code below:
data <- read.table("CRandWWLLNremzro", col.names = c("year", "month",
"day", "CR","WW"))


new.century <- data$year < 50

data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)

data$date <- as.Date(ISOdate(data$year, data$month, data$day))
x = data$date
 CR = data$CR
WWLLN=data$WW

Year<-x
Li<-WWLLN
CR<-CR

setEPS()
 postscript("twoinone2.eps")
 par(mar = c(5, 4, 4, 4) + 2) # Leave space for z axis
library(plotrix)
plot(Year,Li,pch=16,axes=F,xlab="",ylab="",type="l",col="black")
axis(2, col="black",las=1)  ## las=1 makes horizontal labels
mtext("Lightning Stroke/day", side=2, line=4)
#box()
par(new=TRUE)
plot(Year,CR, pch=15, xlab="",ylab="",axes=FALSE,type="l",col="red")
mtext("GCR count/day",side=4,col="red",line=3)
axis(4, ylim=c(-7499,9684), col="red",col.axis="red",las=1)



axis(side=1) ##
mtext("YEAR",side=1,col="black",line=2.5)
mtext("Long-term Variation betwenn WWLLN and GCRs",side=3,col="black",line=2.5)


legend("topleft",col=c("red","black"),lty=1,legend=c("GCRs","WWLLN"))

dev.off()

  I got the correct axes except that the x-axis is not what I want. I
want the date to appear on the x-axis. i actually got that by using:
axis(side=1,at=c(1,400,800,1200,1500),labels=c("2004","2005","2006","2007","2008"))

But there is a little time shift, indicating that the above line may
not have been assigned correctly.

I then fiddled with  axis(side=1) to see if the correct date can
naturally appear. I could not succeed.

I can attach the plot I generated. Instead of date appearing on the
x-axis, ordinary numbers appeared.

I guess the best way of getting the correct date on x-axis is to allow
the system to fix the date as data points are many. But I don't know
how to do that.

Thank you in advance for your usual kind help.
Best regards
Ogbos


From petr@pik@l @ending from prechez@@cz  Thu Nov 29 15:03:15 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Thu, 29 Nov 2018 14:03:15 +0000
Subject: [R] Correct x-axis of two in one graph
In-Reply-To: <CAC8ss30sXduG5xd=F1jh0HEbJNL0UxSQHk_9RFv_RRC8Y2agYg@mail.gmail.com>
References: <CAC8ss30sXduG5xd=F1jh0HEbJNL0UxSQHk_9RFv_RRC8Y2agYg@mail.gmail.com>
Message-ID: <fe948b80a54c4e2e8ed8678cbb35d39f@SRVEXCHCM1302.precheza.cz>

Hi

If I understand correctly you want Li and CR appear in one plot with the same x axis. Although it is not usually recommended you could use twoord.plot from plotrix or undocumented code below.

plot.yy <- function (x, yright, yleft, yleftlim = NULL, yrightlim = NULL,   xlab = NULL, yylab = list(NA, NA), pch = c(1, 2), col = c(1,    2), linky = F, smooth = 0, lwds = 1, length = 10, format = "%d/%m",    rect = NULL, type = "p", ...)
{
    par(mar = c(5, 4, 4, 2), oma = c(0, 0, 0, 3))
    plot(x, yright, ylim = yrightlim, axes = F, ylab = "", xlab = xlab,  pch = pch[1], col = col[1], type = type, ...)
    if (!is.null(rect))
        rect(x[rect[1]], rect[2], x[rect[3]], rect[4], col = "grey")
    points(x, yright, ylim = yrightlim, ylab = "", xlab = xlab, pch = pch[1], col = col[1], ...)
    axis(4, pretty(range(yright, na.rm = T), 10), col = col[1])
    if (linky)
        lines(x, yright, col = col[1], ...)
    if (smooth != 0)
        lines(supsmu(x, yright, span = smooth), col = col[1],   lwd = lwds, ...)
    if (is.na(yylab[[1]]))
        mtext(deparse(substitute(yright)), side = 4, outer = T,   line = 1, col = col[1], ...)  else mtext(yylab[[1]], side = 4, outer = T, line = 1, col = col[1],    ...)
    par(new = T)
    plot(x, yleft, ylim = yleftlim, ylab = "", axes = F, xlab = xlab,
        pch = pch[2], col = col[2], ...)
    box()
    axis(2, pretty(range(yleft, na.rm = T), 10), col = col[2],
        col.axis = col[2])
    if (!inherits(x, c("Date", "POSIXt")))
        axis(1, pretty(range(x, na.rm = T), 10))
    else {
        l <- length(x)
        axis(1, at = x[seq(1, l, length = length)], labels = format(as.POSIXct(x[seq(1,  l, length = length)]), format = format))
    }
    if (is.na(yylab[[2]]))
        mtext(deparse(substitute(yleft)), side = 2, line = 2,   col = col[2], ...)
    else mtext(yylab[[2]], side = 2, line = 2, col = col[2],    ...)
    if (linky)
        lines(x, yleft, col = col[2], lty = 2, ...)
    if (smooth != 0)
        lines(supsmu(x, yleft, span = smooth), col = col[2],    lty = 2, lwd = lwds, ...)
}

something like

plot.yy(Year, Li, CR)

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ogbos Okike
> Sent: Thursday, November 29, 2018 2:33 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] Correct x-axis of two in one graph
>
> Dear Contributors,
>
> I have a data of the form:
> 4 8 10 8590 12516
> 4 8 11 8641 98143
> 4 8 12 8705 98916
> 4 8 13 8750 89911
> 4 8 14 8685 104835
> 4 8 15 8629 121963
> 4 8 16 8676 77655
> 4 8 17 8577 81081
> 4 8 18 8593 83385
> 4 8 19 8642 112164
> 4 8 20 8708 103684
> 4 8 21 8622 83982
> 4 8 22 8593 75944
> 4 8 23 8600 97036
> 4 8 24 8650 104911
> 4 8 25 8730 114098
> 4 8 26 8731 99421
> 4 8 27 8715 85707
> 4 8 28 8717 81273
> 4 8 29 8739 106462
> 4 8 30 8684 110635
> 4 8 31 8713 105214
> 4 9 1 8771 92456
> 4 9 2 8759 109270
> 4 9 3 8762 99150
> 4 9 4 8730 77306
> 4 9 5 8780 86324
> 4 9 6 8804 90214
> 4 9 7 8797 99894
> 4 9 8 8863 95177
> 4 9 9 8873 95910
> 4 9 10 8827 108511
> 4 9 11 8806 115636
> 4 9 12 8869 85542
> 4 9 13 8854 111018
> 4 9 14 8571 93247
> 4 9 15 8533 85105
> 4 9 16 8553 114725
> 4 9 17 8561 122195
> 4 9 18 8532 100945
> 4 9 19 8560 108552
> 4 9 20 8634 108707
> 4 9 21 8646 117420
> 4 9 22 8633 113823
> 4 9 23 8680 82763
> 4 9 24 8765 121072
> 4 9 25 8756 89835
> 4 9 26 8750 104578
> 4 9 27 8790 88429
> 4 9 28 8824 84022
> 4 9 29 8843 80413
> 4 9 30 8795 118462
> 4 10 1 8795 139761
> 4 10 2 8805 103049
> 4 10 3 8826 104996
> 4 10 4 8841 104496
> 4 10 5 8882 75603
> 4 10 6 8865 89768
> 4 10 7 8875 93353
> 4 10 8 8898 98410
> 4 10 9 8920 114540
> 4 10 10 8937 95220
> 4 10 11 8926 104083
> 4 10 12 8912 106089
> 4 10 13 8898 116228
> 4 10 14 8926 149610
> 4 10 15 8954 109594
> 4 10 16 8941 75008
> 4 10 17 8952 119182
> 4 10 18 9003 151011
> 4 10 19 9002 146797
> 4 10 20 8995 145769
> 4 10 21 8969 121248
> 4 10 22 8954 107991
> 4 10 23 8992 128
> 4 10 24 8981 23036
> 4 10 25 8920 137485
> 4 10 26 8899 131756
> 4 10 27 8913 108729
> 4 10 28 8874 109478
> 4 10 29 8846 119627
> 4 10 30 8867 89999
> 4 10 31 8868 64833
> 4 11 1 9004 95864
> 4 11 2 9028 82322
> 4 11 3 8969 95591
> 4 11 4 8932 69378
> 4 11 5 8929 74281
> 4 11 6 8916 103261
> 4 11 7 8807 92473
> 4 11 8 8449 84344
> 4 11 9 8484 127415
> 4 11 10 8148 123826
> 4 11 11 8282 100029
> 4 11 12 8305 76205
> 4 11 13 8380 105162
> 4 11 14 8530 119533
> 4 11 15 8642 106490
> 4 11 16 8780 114771
> 4 11 17 8890 55593
> 4 11 18 8962 227
> 4 11 19 8949 109699
> 4 11 20 8974 86004
> 4 11 21 8956 74496
> 4 11 22 8881 109350
> 4 11 23 8872 134020
> 4 11 24 8847 105212
> 4 11 25 8868 91512
> where columns 1= year 2004, 2 = month, 3= day, 4= CR data, 5= Lightning data.
>
> The data range is 2004/8/10 to 2008/8/22.
> With the code below:
> data <- read.table("CRandWWLLNremzro", col.names = c("year", "month",
> "day", "CR","WW"))
>
>
> new.century <- data$year < 50
>
> data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)
>
> data$date <- as.Date(ISOdate(data$year, data$month, data$day))
> x = data$date
>  CR = data$CR
> WWLLN=data$WW
>
> Year<-x
> Li<-WWLLN
> CR<-CR
>
> setEPS()
>  postscript("twoinone2.eps")
>  par(mar = c(5, 4, 4, 4) + 2) # Leave space for z axis
> library(plotrix)
> plot(Year,Li,pch=16,axes=F,xlab="",ylab="",type="l",col="black")
> axis(2, col="black",las=1)  ## las=1 makes horizontal labels
> mtext("Lightning Stroke/day", side=2, line=4)
> #box()
> par(new=TRUE)
> plot(Year,CR, pch=15, xlab="",ylab="",axes=FALSE,type="l",col="red")
> mtext("GCR count/day",side=4,col="red",line=3)
> axis(4, ylim=c(-7499,9684), col="red",col.axis="red",las=1)
>
>
>
> axis(side=1) ##
> mtext("YEAR",side=1,col="black",line=2.5)
> mtext("Long-term Variation betwenn WWLLN and
> GCRs",side=3,col="black",line=2.5)
>
>
> legend("topleft",col=c("red","black"),lty=1,legend=c("GCRs","WWLLN"))
>
> dev.off()
>
>   I got the correct axes except that the x-axis is not what I want. I
> want the date to appear on the x-axis. i actually got that by using:
> axis(side=1,at=c(1,400,800,1200,1500),labels=c("2004","2005","2006","2007",
> "2008"))
>
> But there is a little time shift, indicating that the above line may
> not have been assigned correctly.
>
> I then fiddled with  axis(side=1) to see if the correct date can
> naturally appear. I could not succeed.
>
> I can attach the plot I generated. Instead of date appearing on the
> x-axis, ordinary numbers appeared.
>
> I guess the best way of getting the correct date on x-axis is to allow
> the system to fix the date as data points are many. But I don't know
> how to do that.
>
> Thank you in advance for your usual kind help.
> Best regards
> Ogbos
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From 407600@b @ending from @tudent@eur@nl  Thu Nov 29 16:15:18 2018
From: 407600@b @ending from @tudent@eur@nl (Lisa van der Burgh)
Date: Thu, 29 Nov 2018 15:15:18 +0000
Subject: [R] Calculating a P for trend
Message-ID: <HE1PR0201MB215656FD742275748D7AC5DCF5D20@HE1PR0201MB2156.eurprd02.prod.outlook.com>

Hi all,



I have a question about calculating a P for trend on my data. Let?s give an example that is similar to my own situation first: I have a continuous outcome, namely BMI. I want to investigate the effect of a specific medicine, let?s call it MedA on BMI. MedA is a variable that is categorical, coded as yes/no use of the medication. A also have the duration of use of the MedA, divided in three categories: use of MedA for 1-30 days, use of MedA for 31-60 days and use of MedA for 61-120 days (categories based on literature). I have performed a linear regression analyses and it seems like there is some kind of trend: the longer the use of MedA, the higher the BMI will be (the betas increase with time of use).  So an exemplary table:






Outcome: BMI


Beta


MedA use duration





  Use for 1-30 days


0.060


  Use for 31-60 days


0.074


  Use for 61-120 da


0.081




So, I have created three variables and I modelled them in Rstudio (on a multiple imputed dataset using MICE):



mod1  <- with(imp, lm(BMI ~ MedA_1to30))

pool_ mod1  <- pool(mod1)

summary(pool_ mod1, conf.int = TRUE)



mod2  <- with(imp, lm(BMI ~ MedA_31to60))

pool_ mod2  <- pool(mod2)

summary(pool_ mod2, conf.int = TRUE)



mod3  <- with(imp, lm(BMI ~ MedA_61to120))

pool_ mod3  <- pool(mod3)

summary(pool_ mod3, conf.int = TRUE)



Now that I have done this, I want to calculate a p for trend. I do know what a P for trend measures, but I do not know how to calculate this myself. I read something about the partial.cor.trend.test() function from the trend package, but I do not know what I should fill in. Because I can only fill in an x and y, but I have three time variables. So I do not know how to solve this. Can somebody help me?



If more information is necessary, I am happy to give it to you!


	[[alternative HTML version deleted]]


From giftedlife2014 @ending from gm@il@com  Thu Nov 29 17:17:18 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Thu, 29 Nov 2018 17:17:18 +0100
Subject: [R] Correct x-axis of two in one graph
In-Reply-To: <fe948b80a54c4e2e8ed8678cbb35d39f@SRVEXCHCM1302.precheza.cz>
References: <CAC8ss30sXduG5xd=F1jh0HEbJNL0UxSQHk_9RFv_RRC8Y2agYg@mail.gmail.com>
 <fe948b80a54c4e2e8ed8678cbb35d39f@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAC8ss30ec3Y_igi3zsxnFnVmekBOgQ2EBFS9SbESS1yf0ctbww@mail.gmail.com>

Dear Petr,

Thank you so much for your contribution.

Let me show you what I have please.

I am attaching two plots. The first (twoineone) is my own while the
second (testrun) is plotted with the code you send.

The first is closer to my interest. The major problem I have is the
date. Those were set arbitrary with:
axis(side=1,at=c(1,400,800,1200,1500),labels=c("2004","2005","2006","2007","2008"))
and they seem not to be correct.

The second one does not show date and date is very important to me here.

Is there a way your code can implement the correct date on x-axis? I
would be very glad for further assistance.

Thank you again.
Best wishes
Ogbos
On Thu, Nov 29, 2018 at 3:03 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi
>
> If I understand correctly you want Li and CR appear in one plot with the same x axis. Although it is not usually recommended you could use twoord.plot from plotrix or undocumented code below.
>
> plot.yy <- function (x, yright, yleft, yleftlim = NULL, yrightlim = NULL,   xlab = NULL, yylab = list(NA, NA), pch = c(1, 2), col = c(1,    2), linky = F, smooth = 0, lwds = 1, length = 10, format = "%d/%m",    rect = NULL, type = "p", ...)
> {
>     par(mar = c(5, 4, 4, 2), oma = c(0, 0, 0, 3))
>     plot(x, yright, ylim = yrightlim, axes = F, ylab = "", xlab = xlab,  pch = pch[1], col = col[1], type = type, ...)
>     if (!is.null(rect))
>         rect(x[rect[1]], rect[2], x[rect[3]], rect[4], col = "grey")
>     points(x, yright, ylim = yrightlim, ylab = "", xlab = xlab, pch = pch[1], col = col[1], ...)
>     axis(4, pretty(range(yright, na.rm = T), 10), col = col[1])
>     if (linky)
>         lines(x, yright, col = col[1], ...)
>     if (smooth != 0)
>         lines(supsmu(x, yright, span = smooth), col = col[1],   lwd = lwds, ...)
>     if (is.na(yylab[[1]]))
>         mtext(deparse(substitute(yright)), side = 4, outer = T,   line = 1, col = col[1], ...)  else mtext(yylab[[1]], side = 4, outer = T, line = 1, col = col[1],    ...)
>     par(new = T)
>     plot(x, yleft, ylim = yleftlim, ylab = "", axes = F, xlab = xlab,
>         pch = pch[2], col = col[2], ...)
>     box()
>     axis(2, pretty(range(yleft, na.rm = T), 10), col = col[2],
>         col.axis = col[2])
>     if (!inherits(x, c("Date", "POSIXt")))
>         axis(1, pretty(range(x, na.rm = T), 10))
>     else {
>         l <- length(x)
>         axis(1, at = x[seq(1, l, length = length)], labels = format(as.POSIXct(x[seq(1,  l, length = length)]), format = format))
>     }
>     if (is.na(yylab[[2]]))
>         mtext(deparse(substitute(yleft)), side = 2, line = 2,   col = col[2], ...)
>     else mtext(yylab[[2]], side = 2, line = 2, col = col[2],    ...)
>     if (linky)
>         lines(x, yleft, col = col[2], lty = 2, ...)
>     if (smooth != 0)
>         lines(supsmu(x, yleft, span = smooth), col = col[2],    lty = 2, lwd = lwds, ...)
> }
>
> something like
>
> plot.yy(Year, Li, CR)
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Ogbos Okike
> > Sent: Thursday, November 29, 2018 2:33 PM
> > To: r-help <r-help at r-project.org>
> > Subject: [R] Correct x-axis of two in one graph
> >
> > Dear Contributors,
> >
> > I have a data of the form:
> > 4 8 10 8590 12516
> > 4 8 11 8641 98143
> > 4 8 12 8705 98916
> > 4 8 13 8750 89911
> > 4 8 14 8685 104835
> > 4 8 15 8629 121963
> > 4 8 16 8676 77655
> > 4 8 17 8577 81081
> > 4 8 18 8593 83385
> > 4 8 19 8642 112164
> > 4 8 20 8708 103684
> > 4 8 21 8622 83982
> > 4 8 22 8593 75944
> > 4 8 23 8600 97036
> > 4 8 24 8650 104911
> > 4 8 25 8730 114098
> > 4 8 26 8731 99421
> > 4 8 27 8715 85707
> > 4 8 28 8717 81273
> > 4 8 29 8739 106462
> > 4 8 30 8684 110635
> > 4 8 31 8713 105214
> > 4 9 1 8771 92456
> > 4 9 2 8759 109270
> > 4 9 3 8762 99150
> > 4 9 4 8730 77306
> > 4 9 5 8780 86324
> > 4 9 6 8804 90214
> > 4 9 7 8797 99894
> > 4 9 8 8863 95177
> > 4 9 9 8873 95910
> > 4 9 10 8827 108511
> > 4 9 11 8806 115636
> > 4 9 12 8869 85542
> > 4 9 13 8854 111018
> > 4 9 14 8571 93247
> > 4 9 15 8533 85105
> > 4 9 16 8553 114725
> > 4 9 17 8561 122195
> > 4 9 18 8532 100945
> > 4 9 19 8560 108552
> > 4 9 20 8634 108707
> > 4 9 21 8646 117420
> > 4 9 22 8633 113823
> > 4 9 23 8680 82763
> > 4 9 24 8765 121072
> > 4 9 25 8756 89835
> > 4 9 26 8750 104578
> > 4 9 27 8790 88429
> > 4 9 28 8824 84022
> > 4 9 29 8843 80413
> > 4 9 30 8795 118462
> > 4 10 1 8795 139761
> > 4 10 2 8805 103049
> > 4 10 3 8826 104996
> > 4 10 4 8841 104496
> > 4 10 5 8882 75603
> > 4 10 6 8865 89768
> > 4 10 7 8875 93353
> > 4 10 8 8898 98410
> > 4 10 9 8920 114540
> > 4 10 10 8937 95220
> > 4 10 11 8926 104083
> > 4 10 12 8912 106089
> > 4 10 13 8898 116228
> > 4 10 14 8926 149610
> > 4 10 15 8954 109594
> > 4 10 16 8941 75008
> > 4 10 17 8952 119182
> > 4 10 18 9003 151011
> > 4 10 19 9002 146797
> > 4 10 20 8995 145769
> > 4 10 21 8969 121248
> > 4 10 22 8954 107991
> > 4 10 23 8992 128
> > 4 10 24 8981 23036
> > 4 10 25 8920 137485
> > 4 10 26 8899 131756
> > 4 10 27 8913 108729
> > 4 10 28 8874 109478
> > 4 10 29 8846 119627
> > 4 10 30 8867 89999
> > 4 10 31 8868 64833
> > 4 11 1 9004 95864
> > 4 11 2 9028 82322
> > 4 11 3 8969 95591
> > 4 11 4 8932 69378
> > 4 11 5 8929 74281
> > 4 11 6 8916 103261
> > 4 11 7 8807 92473
> > 4 11 8 8449 84344
> > 4 11 9 8484 127415
> > 4 11 10 8148 123826
> > 4 11 11 8282 100029
> > 4 11 12 8305 76205
> > 4 11 13 8380 105162
> > 4 11 14 8530 119533
> > 4 11 15 8642 106490
> > 4 11 16 8780 114771
> > 4 11 17 8890 55593
> > 4 11 18 8962 227
> > 4 11 19 8949 109699
> > 4 11 20 8974 86004
> > 4 11 21 8956 74496
> > 4 11 22 8881 109350
> > 4 11 23 8872 134020
> > 4 11 24 8847 105212
> > 4 11 25 8868 91512
> > where columns 1= year 2004, 2 = month, 3= day, 4= CR data, 5= Lightning data.
> >
> > The data range is 2004/8/10 to 2008/8/22.
> > With the code below:
> > data <- read.table("CRandWWLLNremzro", col.names = c("year", "month",
> > "day", "CR","WW"))
> >
> >
> > new.century <- data$year < 50
> >
> > data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)
> >
> > data$date <- as.Date(ISOdate(data$year, data$month, data$day))
> > x = data$date
> >  CR = data$CR
> > WWLLN=data$WW
> >
> > Year<-x
> > Li<-WWLLN
> > CR<-CR
> >
> > setEPS()
> >  postscript("twoinone2.eps")
> >  par(mar = c(5, 4, 4, 4) + 2) # Leave space for z axis
> > library(plotrix)
> > plot(Year,Li,pch=16,axes=F,xlab="",ylab="",type="l",col="black")
> > axis(2, col="black",las=1)  ## las=1 makes horizontal labels
> > mtext("Lightning Stroke/day", side=2, line=4)
> > #box()
> > par(new=TRUE)
> > plot(Year,CR, pch=15, xlab="",ylab="",axes=FALSE,type="l",col="red")
> > mtext("GCR count/day",side=4,col="red",line=3)
> > axis(4, ylim=c(-7499,9684), col="red",col.axis="red",las=1)
> >
> >
> >
> > axis(side=1) ##
> > mtext("YEAR",side=1,col="black",line=2.5)
> > mtext("Long-term Variation betwenn WWLLN and
> > GCRs",side=3,col="black",line=2.5)
> >
> >
> > legend("topleft",col=c("red","black"),lty=1,legend=c("GCRs","WWLLN"))
> >
> > dev.off()
> >
> >   I got the correct axes except that the x-axis is not what I want. I
> > want the date to appear on the x-axis. i actually got that by using:
> > axis(side=1,at=c(1,400,800,1200,1500),labels=c("2004","2005","2006","2007",
> > "2008"))
> >
> > But there is a little time shift, indicating that the above line may
> > not have been assigned correctly.
> >
> > I then fiddled with  axis(side=1) to see if the correct date can
> > naturally appear. I could not succeed.
> >
> > I can attach the plot I generated. Instead of date appearing on the
> > x-axis, ordinary numbers appeared.
> >
> > I guess the best way of getting the correct date on x-axis is to allow
> > the system to fix the date as data points are many. But I don't know
> > how to do that.
> >
> > Thank you in advance for your usual kind help.
> > Best regards
> > Ogbos
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: testrun.png
Type: image/png
Size: 99905 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20181129/7d08589e/attachment.png>

From bgunter@4567 @ending from gm@il@com  Thu Nov 29 18:23:45 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 29 Nov 2018 09:23:45 -0800
Subject: [R] Calculating a P for trend
In-Reply-To: <HE1PR0201MB215656FD742275748D7AC5DCF5D20@HE1PR0201MB2156.eurprd02.prod.outlook.com>
References: <HE1PR0201MB215656FD742275748D7AC5DCF5D20@HE1PR0201MB2156.eurprd02.prod.outlook.com>
Message-ID: <CAGxFJbTXHBefiJEuNGFaK84cacy35S-r+hrUPLqOCQ6=JYnAHw@mail.gmail.com>

I would suggest that if at all possible, you find a local statistician
(your instructor??) with whom to consult. Much of what you are doing
appears likely to result in irreproducible nonsense.

This list is concerned with R programming, not statistics, although they
sometimes do intersect. So I think your post is off topic here (but others
may disagree).

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Nov 29, 2018 at 8:50 AM Lisa van der Burgh <407600ab at student.eur.nl>
wrote:

> Hi all,
>
>
>
> I have a question about calculating a P for trend on my data. Let?s give
> an example that is similar to my own situation first: I have a continuous
> outcome, namely BMI. I want to investigate the effect of a specific
> medicine, let?s call it MedA on BMI. MedA is a variable that is
> categorical, coded as yes/no use of the medication. A also have the
> duration of use of the MedA, divided in three categories: use of MedA for
> 1-30 days, use of MedA for 31-60 days and use of MedA for 61-120 days
> (categories based on literature). I have performed a linear regression
> analyses and it seems like there is some kind of trend: the longer the use
> of MedA, the higher the BMI will be (the betas increase with time of use).
> So an exemplary table:
>
>
>
>
>
>
> Outcome: BMI
>
>
> Beta
>
>
> MedA use duration
>
>
>
>
>
>   Use for 1-30 days
>
>
> 0.060
>
>
>   Use for 31-60 days
>
>
> 0.074
>
>
>   Use for 61-120 da
>
>
> 0.081
>
>
>
>
> So, I have created three variables and I modelled them in Rstudio (on a
> multiple imputed dataset using MICE):
>
>
>
> mod1  <- with(imp, lm(BMI ~ MedA_1to30))
>
> pool_ mod1  <- pool(mod1)
>
> summary(pool_ mod1, conf.int = TRUE)
>
>
>
> mod2  <- with(imp, lm(BMI ~ MedA_31to60))
>
> pool_ mod2  <- pool(mod2)
>
> summary(pool_ mod2, conf.int = TRUE)
>
>
>
> mod3  <- with(imp, lm(BMI ~ MedA_61to120))
>
> pool_ mod3  <- pool(mod3)
>
> summary(pool_ mod3, conf.int = TRUE)
>
>
>
> Now that I have done this, I want to calculate a p for trend. I do know
> what a P for trend measures, but I do not know how to calculate this
> myself. I read something about the partial.cor.trend.test() function from
> the trend package, but I do not know what I should fill in. Because I can
> only fill in an x and y, but I have three time variables. So I do not know
> how to solve this. Can somebody help me?
>
>
>
> If more information is necessary, I am happy to give it to you!
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bog@@o@chri@tofer @ending from gm@il@com  Thu Nov 29 20:13:35 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Fri, 30 Nov 2018 00:43:35 +0530
Subject: [R] Drawing a random number
Message-ID: <CA+dpOJmE_N0i3C2RsC9gfYbvQW1X+xAeJr3+PtvqDJEAVtVcNw@mail.gmail.com>

Hi,

I would like to draw an Integer from a range of [10, 1000] inclusive,
however that random integer should be outside of a pre-defined vector of
integers.

Let say I draw an integer as below

as.integer(runif(1, 10, 1000))

and my pre-defined vector is

Vec = c(563, 453, 897, 567)

The policy is my drawn random integer should never be equal to any item
from Vec

Ofcourse I can use ifelse() to achieve the same, however I was wondering if
there is any direct way to get the same.

Thanks,

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Thu Nov 29 20:24:50 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Thu, 29 Nov 2018 11:24:50 -0800
Subject: [R] Drawing a random number
In-Reply-To: <CA+dpOJmE_N0i3C2RsC9gfYbvQW1X+xAeJr3+PtvqDJEAVtVcNw@mail.gmail.com>
References: <CA+dpOJmE_N0i3C2RsC9gfYbvQW1X+xAeJr3+PtvqDJEAVtVcNw@mail.gmail.com>
Message-ID: <CAF8bMcb7nKsnyHjKRYQxdesy7L+RTjncmVO8GQ5rvoq6E26cOA@mail.gmail.com>

sample( setdiff(10:1000, Vec), size=1)

Also, note that as.integer(runif(1, min, max)) will almost never return max.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Nov 29, 2018 at 11:14 AM Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> I would like to draw an Integer from a range of [10, 1000] inclusive,
> however that random integer should be outside of a pre-defined vector of
> integers.
>
> Let say I draw an integer as below
>
> as.integer(runif(1, 10, 1000))
>
> and my pre-defined vector is
>
> Vec = c(563, 453, 897, 567)
>
> The policy is my drawn random integer should never be equal to any item
> from Vec
>
> Ofcourse I can use ifelse() to achieve the same, however I was wondering if
> there is any direct way to get the same.
>
> Thanks,
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dpweyg@nd @ending from gm@il@com  Thu Nov 29 21:16:12 2018
From: dpweyg@nd @ending from gm@il@com (Dennis Weygand)
Date: Thu, 29 Nov 2018 15:16:12 -0500
Subject: [R] rmarkdown
Message-ID: <5c00490c.1c69fb81.980f2.98eb@mx.google.com>

When I try to create an rmarkdown file in Rstudio, I get the error below. 
What am I doing wrong?

Sent from Mail for Windows 10


From bgunter@4567 @ending from gm@il@com  Thu Nov 29 21:40:02 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 29 Nov 2018 12:40:02 -0800
Subject: [R] rmarkdown
In-Reply-To: <5c00490c.1c69fb81.980f2.98eb@mx.google.com>
References: <5c00490c.1c69fb81.980f2.98eb@mx.google.com>
Message-ID: <CAGxFJbQuTJbQermMfSEDY_oT671iNc8xhPdW3LUFdPEtX0AeCg@mail.gmail.com>

1. What error?

2. This is the r-help list. RStudio is a separate product. Requests for
help in RStudio should be directed to their lists.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Nov 29, 2018 at 12:16 PM Dennis Weygand <dpweygand at gmail.com> wrote:

> When I try to create an rmarkdown file in Rstudio, I get the error below.
> What am I doing wrong?
>
> Sent from Mail for Windows 10
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rdbower@ @ending from m@il@u@f@edu  Thu Nov 29 22:23:49 2018
From: rdbower@ @ending from m@il@u@f@edu (Robert D. Bowers M.A.)
Date: Thu, 29 Nov 2018 16:23:49 -0500
Subject: [R] help with line graphs - rather lengthy to explain need
Message-ID: <02753aa6-462a-6a5c-9a24-3d6a695b3cc0@mail.usf.edu>

I am trying to figure out the best way to organize and plot data 
generated by a Excel spreadsheet (one driving a sample turntable and 
collecting optical spectra).

The output of the equipment and software is an excel spreadsheet with 
sample numbers in the first row, and in the first column there is the 
wavelength in nm.? 2048 individual measurements (per wavelength) - 2048 
rows plus the sample number row, and at present I've tested 250 samples, 
with a LOT more to follow.

After I get the spreadsheet, I add a row (just below the sample numbers) 
containing site locations.? I've collected 50 samples per site (each 
assigned a different number), so far 5 sites.? The spreadsheet ends up 
with 2050 rows, 250 columns.

What I want to do is generate a line graph of the data (which could be 
separated out into sections of the optical spectrum), with line colors 
assigned by the site name.? Once that's done, the graphs make sense 
(right now the only way I can do that is using the spreadsheet software, 
and assigning each line the color manually - a very tiresome and 
time-consuming process).

So far, I've tried everything I can to get a graph out using R, without 
luck.? I'm rusty with R and programming... I've used Rcmdr (tried 
transposing data, various settings and so on) and 'played' with ggplot - 
no success.? I'm using Rcmdr to make it easier to work out the bugs, 
then will write a short program to process data.

What I'd like to know is (1) what would be the best way to organize the 
data - sample numbers (cases) in the first row, or in the first column 
with the next row or column being the site name, (2) how would I get 
ggplot to plot the line graph showing all of the samples (number listing 
not important) and all (or a selection) of the different wavelengths, 
while assigning line color based on site name.? Once that's done, I can 
show the within-group vs between-group variation compared to wavelength.

To give an idea of what the data look like:

(name = Longwave)

Sample ??? 34900?? 34901? 34902??? 34903??? 34904??? (and so on)

Site?? ??? ???? Tp??? ???? Tc??? ??? ? Cr??? ?????? Ws Gs

200(nm) ?? 300.5??? 783.9??? 101.3????? 623.8???? 1385.7

201....

You get the idea.? (maximum measurement value is 4098, the instrument 
takes multiple scans and averages them).

If I can figure this out, it will speed up my work - which I need to do 
so I can get a grant proposal off on time.

Thank you,

Bob

Doctoral Candidate, Applied Anthropology

University of South Florida


From @nnij@nh @ending from gm@il@com  Fri Nov 30 00:30:27 2018
From: @nnij@nh @ending from gm@il@com (Janh Anni)
Date: Thu, 29 Nov 2018 18:30:27 -0500
Subject: [R] Bootstrapping One- and Two-Sample Hypothesis Tests of
 Proportion
In-Reply-To: <bc301e6b-62b7-bb9a-25d5-c81c19182761@sapo.pt>
References: <CAFCoDdBrRC6GNR8JP_-0E2U4M1AKJTh8tRqSBqeRkK2qqemtdA@mail.gmail.com>
 <bc301e6b-62b7-bb9a-25d5-c81c19182761@sapo.pt>
Message-ID: <CAFCoDdC=3E86U7hvdQUq7BOKPd7g_mPwULFxgGK3B6ucf8qr6A@mail.gmail.com>

Hi Rui,

Thanks a lot for responding and I apologize for my late response.  I tried
using the *boot.two.per* function in the wBoot package which stated that it
could bootstrap 2-sample tests for both means and proportions but it turned
out that it only works for the mean.

Thanks again,
Janh

On Wed, Nov 28, 2018 at 12:38 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> What have you tried?
> Reproducible example please.
>
> http://adv-r.had.co.nz/Reproducibility.html
>
> https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> https://www.r-bloggers.com/minimal-reproducible-examples/
>
>
> Rui Barradas
>
> ?s 22:33 de 27/11/2018, Janh Anni escreveu:
> > Hello R Experts!
> >
> > Does anyone know of a relatively straightforward way to bootstrap
> > hypothesis tests for proportion in R?
> >
> > Thanks in advance!
> >
> > Janh
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Fri Nov 30 00:45:24 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 29 Nov 2018 15:45:24 -0800
Subject: [R] Bootstrapping One- and Two-Sample Hypothesis Tests of
 Proportion
In-Reply-To: <CAFCoDdC=3E86U7hvdQUq7BOKPd7g_mPwULFxgGK3B6ucf8qr6A@mail.gmail.com>
References: <CAFCoDdBrRC6GNR8JP_-0E2U4M1AKJTh8tRqSBqeRkK2qqemtdA@mail.gmail.com>
 <bc301e6b-62b7-bb9a-25d5-c81c19182761@sapo.pt>
 <CAFCoDdC=3E86U7hvdQUq7BOKPd7g_mPwULFxgGK3B6ucf8qr6A@mail.gmail.com>
Message-ID: <CAGxFJbT5AiUW1Jn2U6WKamn6cpOLExhD-AjsWLZ6a+q=FO67QA@mail.gmail.com>

... but as Duncan pointed out already, I believe, a proportion **is** a
mean -- of 0/1 responses.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Nov 29, 2018 at 3:30 PM Janh Anni <annijanh at gmail.com> wrote:

> Hi Rui,
>
> Thanks a lot for responding and I apologize for my late response.  I tried
> using the *boot.two.per* function in the wBoot package which stated that it
> could bootstrap 2-sample tests for both means and proportions but it turned
> out that it only works for the mean.
>
> Thanks again,
> Janh
>
> On Wed, Nov 28, 2018 at 12:38 PM Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
>
> > Hello,
> >
> > What have you tried?
> > Reproducible example please.
> >
> > http://adv-r.had.co.nz/Reproducibility.html
> >
> >
> https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> > https://www.r-bloggers.com/minimal-reproducible-examples/
> >
> >
> > Rui Barradas
> >
> > ?s 22:33 de 27/11/2018, Janh Anni escreveu:
> > > Hello R Experts!
> > >
> > > Does anyone know of a relatively straightforward way to bootstrap
> > > hypothesis tests for proportion in R?
> > >
> > > Thanks in advance!
> > >
> > > Janh
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @nnij@nh @ending from gm@il@com  Fri Nov 30 00:57:19 2018
From: @nnij@nh @ending from gm@il@com (Janh Anni)
Date: Thu, 29 Nov 2018 18:57:19 -0500
Subject: [R] Bootstrapping One- and Two-Sample Hypothesis Tests of
 Proportion
In-Reply-To: <CAGxFJbT5AiUW1Jn2U6WKamn6cpOLExhD-AjsWLZ6a+q=FO67QA@mail.gmail.com>
References: <CAFCoDdBrRC6GNR8JP_-0E2U4M1AKJTh8tRqSBqeRkK2qqemtdA@mail.gmail.com>
 <bc301e6b-62b7-bb9a-25d5-c81c19182761@sapo.pt>
 <CAFCoDdC=3E86U7hvdQUq7BOKPd7g_mPwULFxgGK3B6ucf8qr6A@mail.gmail.com>
 <CAGxFJbT5AiUW1Jn2U6WKamn6cpOLExhD-AjsWLZ6a+q=FO67QA@mail.gmail.com>
Message-ID: <CAFCoDdCXSaPkoYn2tR3supgEvMkc4n_RhM7yJnN0zOq2fqLZ1Q@mail.gmail.com>

Hi Bert,

You mean, just compute the test specifying the mean as the parameter but
using 1's and 0's for the data?  Also I don't get how a proportion is a
mean of 0/1 responses.  Could you please elaborate?  Thanks!

Janh

On Thu, Nov 29, 2018 at 6:45 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> ... but as Duncan pointed out already, I believe, a proportion **is** a
> mean -- of 0/1 responses.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Nov 29, 2018 at 3:30 PM Janh Anni <annijanh at gmail.com> wrote:
>
>> Hi Rui,
>>
>> Thanks a lot for responding and I apologize for my late response.  I tried
>> using the *boot.two.per* function in the wBoot package which stated that
>> it
>> could bootstrap 2-sample tests for both means and proportions but it
>> turned
>> out that it only works for the mean.
>>
>> Thanks again,
>> Janh
>>
>> On Wed, Nov 28, 2018 at 12:38 PM Rui Barradas <ruipbarradas at sapo.pt>
>> wrote:
>>
>> > Hello,
>> >
>> > What have you tried?
>> > Reproducible example please.
>> >
>> > http://adv-r.had.co.nz/Reproducibility.html
>> >
>> >
>> https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> > https://www.r-bloggers.com/minimal-reproducible-examples/
>> >
>> >
>> > Rui Barradas
>> >
>> > ?s 22:33 de 27/11/2018, Janh Anni escreveu:
>> > > Hello R Experts!
>> > >
>> > > Does anyone know of a relatively straightforward way to bootstrap
>> > > hypothesis tests for proportion in R?
>> > >
>> > > Thanks in advance!
>> > >
>> > > Janh
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> > >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @ending from me@com  Fri Nov 30 01:07:17 2018
From: m@rc_@chw@rtz @ending from me@com (Marc Schwartz)
Date: Thu, 29 Nov 2018 19:07:17 -0500
Subject: [R] Bootstrapping One- and Two-Sample Hypothesis Tests of
 Proportion
In-Reply-To: <CAFCoDdCXSaPkoYn2tR3supgEvMkc4n_RhM7yJnN0zOq2fqLZ1Q@mail.gmail.com>
References: <CAFCoDdBrRC6GNR8JP_-0E2U4M1AKJTh8tRqSBqeRkK2qqemtdA@mail.gmail.com>
 <bc301e6b-62b7-bb9a-25d5-c81c19182761@sapo.pt>
 <CAFCoDdC=3E86U7hvdQUq7BOKPd7g_mPwULFxgGK3B6ucf8qr6A@mail.gmail.com>
 <CAGxFJbT5AiUW1Jn2U6WKamn6cpOLExhD-AjsWLZ6a+q=FO67QA@mail.gmail.com>
 <CAFCoDdCXSaPkoYn2tR3supgEvMkc4n_RhM7yJnN0zOq2fqLZ1Q@mail.gmail.com>
Message-ID: <5116BB7C-CE48-49F9-BFBB-F7C3C36253CA@me.com>

Hi,

I don't see Duncan's reply in the archive, but consider:

> 1 / 4
[1] 0.25

> mean(c(1, 0, 0, 0))
[1] 0.25


> 3 / 9
[1] 0.3333333

> mean(c(1, 1, 1, 0, 0, 0, 0, 0, 0))
[1] 0.3333333


Regards,

Marc Schwartz

> On Nov 29, 2018, at 6:57 PM, Janh Anni <annijanh at gmail.com> wrote:
> 
> Hi Bert,
> 
> You mean, just compute the test specifying the mean as the parameter but
> using 1's and 0's for the data?  Also I don't get how a proportion is a
> mean of 0/1 responses.  Could you please elaborate?  Thanks!
> 
> Janh
> 
> On Thu, Nov 29, 2018 at 6:45 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>> ... but as Duncan pointed out already, I believe, a proportion **is** a
>> mean -- of 0/1 responses.
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Thu, Nov 29, 2018 at 3:30 PM Janh Anni <annijanh at gmail.com> wrote:
>> 
>>> Hi Rui,
>>> 
>>> Thanks a lot for responding and I apologize for my late response.  I tried
>>> using the *boot.two.per* function in the wBoot package which stated that
>>> it
>>> could bootstrap 2-sample tests for both means and proportions but it
>>> turned
>>> out that it only works for the mean.
>>> 
>>> Thanks again,
>>> Janh
>>> 
>>> On Wed, Nov 28, 2018 at 12:38 PM Rui Barradas <ruipbarradas at sapo.pt>
>>> wrote:
>>> 
>>>> Hello,
>>>> 
>>>> What have you tried?
>>>> Reproducible example please.
>>>> 
>>>> http://adv-r.had.co.nz/Reproducibility.html
>>>> 
>>>> 
>>> https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>> https://www.r-bloggers.com/minimal-reproducible-examples/
>>>> 
>>>> 
>>>> Rui Barradas
>>>> 
>>>> ?s 22:33 de 27/11/2018, Janh Anni escreveu:
>>>>> Hello R Experts!
>>>>> 
>>>>> Does anyone know of a relatively straightforward way to bootstrap
>>>>> hypothesis tests for proportion in R?
>>>>> 
>>>>> Thanks in advance!
>>>>> 
>>>>> Janh


	[[alternative HTML version deleted]]


From @nnij@nh @ending from gm@il@com  Fri Nov 30 01:23:37 2018
From: @nnij@nh @ending from gm@il@com (Janh Anni)
Date: Thu, 29 Nov 2018 19:23:37 -0500
Subject: [R] Bootstrapping One- and Two-Sample Hypothesis Tests of
 Proportion
In-Reply-To: <5116BB7C-CE48-49F9-BFBB-F7C3C36253CA@me.com>
References: <CAFCoDdBrRC6GNR8JP_-0E2U4M1AKJTh8tRqSBqeRkK2qqemtdA@mail.gmail.com>
 <bc301e6b-62b7-bb9a-25d5-c81c19182761@sapo.pt>
 <CAFCoDdC=3E86U7hvdQUq7BOKPd7g_mPwULFxgGK3B6ucf8qr6A@mail.gmail.com>
 <CAGxFJbT5AiUW1Jn2U6WKamn6cpOLExhD-AjsWLZ6a+q=FO67QA@mail.gmail.com>
 <CAFCoDdCXSaPkoYn2tR3supgEvMkc4n_RhM7yJnN0zOq2fqLZ1Q@mail.gmail.com>
 <5116BB7C-CE48-49F9-BFBB-F7C3C36253CA@me.com>
Message-ID: <CAFCoDdD_a_domgu+J8rbLfQSqRUfLfGnQpm-1FOYveJR0TrX-g@mail.gmail.com>

Hi Marc,

I see what you are saying.  I will  try re-running the* boot.two.per*
function using 1's  and 0's for the data and specifying mean as the
parameter and see what happens.  I will report back.  Thanks so much for
your kind assistance!

Janh

On Thu, Nov 29, 2018 at 7:07 PM Marc Schwartz <marc_schwartz at me.com> wrote:

> Hi,
>
> I don't see Duncan's reply in the archive, but consider:
>
> > 1 / 4
> [1] 0.25
>
> > mean(c(1, 0, 0, 0))
> [1] 0.25
>
>
> > 3 / 9
> [1] 0.3333333
>
> > mean(c(1, 1, 1, 0, 0, 0, 0, 0, 0))
> [1] 0.3333333
>
>
> Regards,
>
> Marc Schwartz
>
> On Nov 29, 2018, at 6:57 PM, Janh Anni <annijanh at gmail.com> wrote:
>
> Hi Bert,
>
> You mean, just compute the test specifying the mean as the parameter but
> using 1's and 0's for the data?  Also I don't get how a proportion is a
> mean of 0/1 responses.  Could you please elaborate?  Thanks!
>
> Janh
>
> On Thu, Nov 29, 2018 at 6:45 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
> ... but as Duncan pointed out already, I believe, a proportion **is** a
> mean -- of 0/1 responses.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Nov 29, 2018 at 3:30 PM Janh Anni <annijanh at gmail.com> wrote:
>
> Hi Rui,
>
> Thanks a lot for responding and I apologize for my late response.  I tried
> using the *boot.two.per* function in the wBoot package which stated that
> it
> could bootstrap 2-sample tests for both means and proportions but it
> turned
> out that it only works for the mean.
>
> Thanks again,
> Janh
>
> On Wed, Nov 28, 2018 at 12:38 PM Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
>
> Hello,
>
> What have you tried?
> Reproducible example please.
>
> http://adv-r.had.co.nz/Reproducibility.html
>
>
>
> https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> https://www.r-bloggers.com/minimal-reproducible-examples/
>
>
> Rui Barradas
>
> ?s 22:33 de 27/11/2018, Janh Anni escreveu:
>
> Hello R Experts!
>
> Does anyone know of a relatively straightforward way to bootstrap
> hypothesis tests for proportion in R?
>
> Thanks in advance!
>
> Janh
>
>
>

	[[alternative HTML version deleted]]


From dc@rl@on @ending from t@mu@edu  Fri Nov 30 02:37:49 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Fri, 30 Nov 2018 01:37:49 +0000
Subject: [R] help with line graphs - rather lengthy to explain need
In-Reply-To: <02753aa6-462a-6a5c-9a24-3d6a695b3cc0@mail.usf.edu>
References: <02753aa6-462a-6a5c-9a24-3d6a695b3cc0@mail.usf.edu>
Message-ID: <5de5ada4138e4bb0ae8e023659c19207@tamu.edu>

I'm not sure we have enough details to answer your question, but you may need to think about organizing your spreadsheet differently. Perhaps one sheet that has just the data and a second sheet that has the sample number and the location. Import those separately into R.

Your data are in wide format so matplot() would work for what you want to do, but ggplot may easier if you organize them in long format - one long column of readings, one column of sample numbers (repeated for each of the 2048 measurements from a single sample (and the same for the location column).

If this doesn't put you on the right track, give us a .csv file of a subset of the data (e.g. 10 columns and 20 rows) to play with. You can just copy/paste it into your message. If you save it as an attachment, rename the extension to .txt so the list processor does not strip it out.

David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Robert D. Bowers M.A.
Sent: Thursday, November 29, 2018 3:24 PM
To: r-help at r-project.org
Subject: [R] help with line graphs - rather lengthy to explain need

I am trying to figure out the best way to organize and plot data 
generated by a Excel spreadsheet (one driving a sample turntable and 
collecting optical spectra).

The output of the equipment and software is an excel spreadsheet with 
sample numbers in the first row, and in the first column there is the 
wavelength in nm.? 2048 individual measurements (per wavelength) - 2048 
rows plus the sample number row, and at present I've tested 250 samples, 
with a LOT more to follow.

After I get the spreadsheet, I add a row (just below the sample numbers) 
containing site locations.? I've collected 50 samples per site (each 
assigned a different number), so far 5 sites.? The spreadsheet ends up 
with 2050 rows, 250 columns.

What I want to do is generate a line graph of the data (which could be 
separated out into sections of the optical spectrum), with line colors 
assigned by the site name.? Once that's done, the graphs make sense 
(right now the only way I can do that is using the spreadsheet software, 
and assigning each line the color manually - a very tiresome and 
time-consuming process).

So far, I've tried everything I can to get a graph out using R, without 
luck.? I'm rusty with R and programming... I've used Rcmdr (tried 
transposing data, various settings and so on) and 'played' with ggplot - 
no success.? I'm using Rcmdr to make it easier to work out the bugs, 
then will write a short program to process data.

What I'd like to know is (1) what would be the best way to organize the 
data - sample numbers (cases) in the first row, or in the first column 
with the next row or column being the site name, (2) how would I get 
ggplot to plot the line graph showing all of the samples (number listing 
not important) and all (or a selection) of the different wavelengths, 
while assigning line color based on site name.? Once that's done, I can 
show the within-group vs between-group variation compared to wavelength.

To give an idea of what the data look like:

(name = Longwave)

Sample ??? 34900?? 34901? 34902??? 34903??? 34904??? (and so on)

Site?? ??? ???? Tp??? ???? Tc??? ??? ? Cr??? ?????? Ws Gs

200(nm) ?? 300.5??? 783.9??? 101.3????? 623.8???? 1385.7

201....

You get the idea.? (maximum measurement value is 4098, the instrument 
takes multiple scans and averages them).

If I can figure this out, it will speed up my work - which I need to do 
so I can get a grant proposal off on time.

Thank you,

Bob

Doctoral Candidate, Applied Anthropology

University of South Florida

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From petr@pik@l @ending from prechez@@cz  Fri Nov 30 09:24:25 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Fri, 30 Nov 2018 08:24:25 +0000
Subject: [R] Correct x-axis of two in one graph
In-Reply-To: <CAC8ss30ec3Y_igi3zsxnFnVmekBOgQ2EBFS9SbESS1yf0ctbww@mail.gmail.com>
References: <CAC8ss30sXduG5xd=F1jh0HEbJNL0UxSQHk_9RFv_RRC8Y2agYg@mail.gmail.com>
 <fe948b80a54c4e2e8ed8678cbb35d39f@SRVEXCHCM1302.precheza.cz>
 <CAC8ss30ec3Y_igi3zsxnFnVmekBOgQ2EBFS9SbESS1yf0ctbww@mail.gmail.com>
Message-ID: <90b67fc0724b40b8b59b5d2c15dcef0c@SRVEXCHCM1302.precheza.cz>

Hi

You cannot expect any code to give you results precisely according to your wishes just out of the box.

You could modify x axis by changing format parameter. It is preset to = "%d/%m",    so you could change it to "%Y", if you want to display only year.

format parameter goes to this line in my code.

axis(1, at = x[seq(1, l, length = length)], labels = format(as.POSIXct(x[seq(1,  l, length = length)]), format = format))

The code actually has several other parameters which you could modify or you are free to modify the code itself.

Cheers
Petr

> -----Original Message-----
> From: Ogbos Okike <giftedlife2014 at gmail.com>
> Sent: Thursday, November 29, 2018 5:17 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] Correct x-axis of two in one graph
>
> Dear Petr,
>
> Thank you so much for your contribution.
>
> Let me show you what I have please.
>
> I am attaching two plots. The first (twoineone) is my own while the second
> (testrun) is plotted with the code you send.
>
> The first is closer to my interest. The major problem I have is the date. Those
> were set arbitrary with:
> axis(side=1,at=c(1,400,800,1200,1500),labels=c("2004","2005","2006","2007",
> "2008"))
> and they seem not to be correct.
>
> The second one does not show date and date is very important to me here.
>
> Is there a way your code can implement the correct date on x-axis? I would be
> very glad for further assistance.
>
> Thank you again.
> Best wishes
> Ogbos
> On Thu, Nov 29, 2018 at 3:03 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >
> > Hi
> >
> > If I understand correctly you want Li and CR appear in one plot with the same
> x axis. Although it is not usually recommended you could use twoord.plot from
> plotrix or undocumented code below.
> >
> > plot.yy <- function (x, yright, yleft, yleftlim = NULL, yrightlim = NULL,   xlab =
> NULL, yylab = list(NA, NA), pch = c(1, 2), col = c(1,    2), linky = F, smooth = 0,
> lwds = 1, length = 10, format = "%d/%m",    rect = NULL, type = "p", ...)
> > {
> >     par(mar = c(5, 4, 4, 2), oma = c(0, 0, 0, 3))
> >     plot(x, yright, ylim = yrightlim, axes = F, ylab = "", xlab = xlab,  pch = pch[1],
> col = col[1], type = type, ...)
> >     if (!is.null(rect))
> >         rect(x[rect[1]], rect[2], x[rect[3]], rect[4], col = "grey")
> >     points(x, yright, ylim = yrightlim, ylab = "", xlab = xlab, pch = pch[1], col =
> col[1], ...)
> >     axis(4, pretty(range(yright, na.rm = T), 10), col = col[1])
> >     if (linky)
> >         lines(x, yright, col = col[1], ...)
> >     if (smooth != 0)
> >         lines(supsmu(x, yright, span = smooth), col = col[1],   lwd = lwds, ...)
> >     if (is.na(yylab[[1]]))
> >         mtext(deparse(substitute(yright)), side = 4, outer = T,   line = 1, col =
> col[1], ...)  else mtext(yylab[[1]], side = 4, outer = T, line = 1, col = col[1],    ...)
> >     par(new = T)
> >     plot(x, yleft, ylim = yleftlim, ylab = "", axes = F, xlab = xlab,
> >         pch = pch[2], col = col[2], ...)
> >     box()
> >     axis(2, pretty(range(yleft, na.rm = T), 10), col = col[2],
> >         col.axis = col[2])
> >     if (!inherits(x, c("Date", "POSIXt")))
> >         axis(1, pretty(range(x, na.rm = T), 10))
> >     else {
> >         l <- length(x)
> >         axis(1, at = x[seq(1, l, length = length)], labels =
> format(as.POSIXct(x[seq(1,  l, length = length)]), format = format))
> >     }
> >     if (is.na(yylab[[2]]))
> >         mtext(deparse(substitute(yleft)), side = 2, line = 2,   col = col[2], ...)
> >     else mtext(yylab[[2]], side = 2, line = 2, col = col[2],    ...)
> >     if (linky)
> >         lines(x, yleft, col = col[2], lty = 2, ...)
> >     if (smooth != 0)
> >         lines(supsmu(x, yleft, span = smooth), col = col[2],    lty = 2, lwd = lwds,
> ...)
> > }
> >
> > something like
> >
> > plot.yy(Year, Li, CR)
> >
> > Cheers
> > Petr
> >
> > > -----Original Message-----
> > > From: R-help <r-help-bounces at r-project.org> On Behalf Of Ogbos Okike
> > > Sent: Thursday, November 29, 2018 2:33 PM
> > > To: r-help <r-help at r-project.org>
> > > Subject: [R] Correct x-axis of two in one graph
> > >
> > > Dear Contributors,
> > >
> > > I have a data of the form:
> > > 4 8 10 8590 12516
> > > 4 8 11 8641 98143
> > > 4 8 12 8705 98916
> > > 4 8 13 8750 89911
> > > 4 8 14 8685 104835
> > > 4 8 15 8629 121963
> > > 4 8 16 8676 77655
> > > 4 8 17 8577 81081
> > > 4 8 18 8593 83385
> > > 4 8 19 8642 112164
> > > 4 8 20 8708 103684
> > > 4 8 21 8622 83982
> > > 4 8 22 8593 75944
> > > 4 8 23 8600 97036
> > > 4 8 24 8650 104911
> > > 4 8 25 8730 114098
> > > 4 8 26 8731 99421
> > > 4 8 27 8715 85707
> > > 4 8 28 8717 81273
> > > 4 8 29 8739 106462
> > > 4 8 30 8684 110635
> > > 4 8 31 8713 105214
> > > 4 9 1 8771 92456
> > > 4 9 2 8759 109270
> > > 4 9 3 8762 99150
> > > 4 9 4 8730 77306
> > > 4 9 5 8780 86324
> > > 4 9 6 8804 90214
> > > 4 9 7 8797 99894
> > > 4 9 8 8863 95177
> > > 4 9 9 8873 95910
> > > 4 9 10 8827 108511
> > > 4 9 11 8806 115636
> > > 4 9 12 8869 85542
> > > 4 9 13 8854 111018
> > > 4 9 14 8571 93247
> > > 4 9 15 8533 85105
> > > 4 9 16 8553 114725
> > > 4 9 17 8561 122195
> > > 4 9 18 8532 100945
> > > 4 9 19 8560 108552
> > > 4 9 20 8634 108707
> > > 4 9 21 8646 117420
> > > 4 9 22 8633 113823
> > > 4 9 23 8680 82763
> > > 4 9 24 8765 121072
> > > 4 9 25 8756 89835
> > > 4 9 26 8750 104578
> > > 4 9 27 8790 88429
> > > 4 9 28 8824 84022
> > > 4 9 29 8843 80413
> > > 4 9 30 8795 118462
> > > 4 10 1 8795 139761
> > > 4 10 2 8805 103049
> > > 4 10 3 8826 104996
> > > 4 10 4 8841 104496
> > > 4 10 5 8882 75603
> > > 4 10 6 8865 89768
> > > 4 10 7 8875 93353
> > > 4 10 8 8898 98410
> > > 4 10 9 8920 114540
> > > 4 10 10 8937 95220
> > > 4 10 11 8926 104083
> > > 4 10 12 8912 106089
> > > 4 10 13 8898 116228
> > > 4 10 14 8926 149610
> > > 4 10 15 8954 109594
> > > 4 10 16 8941 75008
> > > 4 10 17 8952 119182
> > > 4 10 18 9003 151011
> > > 4 10 19 9002 146797
> > > 4 10 20 8995 145769
> > > 4 10 21 8969 121248
> > > 4 10 22 8954 107991
> > > 4 10 23 8992 128
> > > 4 10 24 8981 23036
> > > 4 10 25 8920 137485
> > > 4 10 26 8899 131756
> > > 4 10 27 8913 108729
> > > 4 10 28 8874 109478
> > > 4 10 29 8846 119627
> > > 4 10 30 8867 89999
> > > 4 10 31 8868 64833
> > > 4 11 1 9004 95864
> > > 4 11 2 9028 82322
> > > 4 11 3 8969 95591
> > > 4 11 4 8932 69378
> > > 4 11 5 8929 74281
> > > 4 11 6 8916 103261
> > > 4 11 7 8807 92473
> > > 4 11 8 8449 84344
> > > 4 11 9 8484 127415
> > > 4 11 10 8148 123826
> > > 4 11 11 8282 100029
> > > 4 11 12 8305 76205
> > > 4 11 13 8380 105162
> > > 4 11 14 8530 119533
> > > 4 11 15 8642 106490
> > > 4 11 16 8780 114771
> > > 4 11 17 8890 55593
> > > 4 11 18 8962 227
> > > 4 11 19 8949 109699
> > > 4 11 20 8974 86004
> > > 4 11 21 8956 74496
> > > 4 11 22 8881 109350
> > > 4 11 23 8872 134020
> > > 4 11 24 8847 105212
> > > 4 11 25 8868 91512
> > > where columns 1= year 2004, 2 = month, 3= day, 4= CR data, 5= Lightning
> data.
> > >
> > > The data range is 2004/8/10 to 2008/8/22.
> > > With the code below:
> > > data <- read.table("CRandWWLLNremzro", col.names = c("year",
> > > "month", "day", "CR","WW"))
> > >
> > >
> > > new.century <- data$year < 50
> > >
> > > data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)
> > >
> > > data$date <- as.Date(ISOdate(data$year, data$month, data$day)) x =
> > > data$date  CR = data$CR WWLLN=data$WW
> > >
> > > Year<-x
> > > Li<-WWLLN
> > > CR<-CR
> > >
> > > setEPS()
> > >  postscript("twoinone2.eps")
> > >  par(mar = c(5, 4, 4, 4) + 2) # Leave space for z axis
> > > library(plotrix)
> > > plot(Year,Li,pch=16,axes=F,xlab="",ylab="",type="l",col="black")
> > > axis(2, col="black",las=1)  ## las=1 makes horizontal labels
> > > mtext("Lightning Stroke/day", side=2, line=4)
> > > #box()
> > > par(new=TRUE)
> > > plot(Year,CR, pch=15, xlab="",ylab="",axes=FALSE,type="l",col="red")
> > > mtext("GCR count/day",side=4,col="red",line=3)
> > > axis(4, ylim=c(-7499,9684), col="red",col.axis="red",las=1)
> > >
> > >
> > >
> > > axis(side=1) ##
> > > mtext("YEAR",side=1,col="black",line=2.5)
> > > mtext("Long-term Variation betwenn WWLLN and
> > > GCRs",side=3,col="black",line=2.5)
> > >
> > >
> > > legend("topleft",col=c("red","black"),lty=1,legend=c("GCRs","WWLLN")
> > > )
> > >
> > > dev.off()
> > >
> > >   I got the correct axes except that the x-axis is not what I want.
> > > I want the date to appear on the x-axis. i actually got that by using:
> > > axis(side=1,at=c(1,400,800,1200,1500),labels=c("2004","2005","2006",
> > > "2007",
> > > "2008"))
> > >
> > > But there is a little time shift, indicating that the above line may
> > > not have been assigned correctly.
> > >
> > > I then fiddled with  axis(side=1) to see if the correct date can
> > > naturally appear. I could not succeed.
> > >
> > > I can attach the plot I generated. Instead of date appearing on the
> > > x-axis, ordinary numbers appeared.
> > >
> > > I guess the best way of getting the correct date on x-axis is to
> > > allow the system to fix the date as data points are many. But I
> > > don't know how to do that.
> > >
> > > Thank you in advance for your usual kind help.
> > > Best regards
> > > Ogbos
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
> > obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> > https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> > about processing and protection of business partner?s personal data
> > are available on website:
> > https://www.precheza.cz/en/personal-data-protection-principles/
> > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> > d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> > odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> > documents attached to it may be confidential and are subject to the
> > legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From m@rc_grt @ending from y@hoo@fr  Fri Nov 30 09:26:05 2018
From: m@rc_grt @ending from y@hoo@fr (Marc Girondot)
Date: Fri, 30 Nov 2018 09:26:05 +0100
Subject: [R] High dimensional optimization in R
In-Reply-To: <0acb74a5-e7f7-0c5e-ad98-72ded5120ce6@kfupm.edu.sa>
References: <CAGZkDQhiVVuyJ1c6D3-HOxqash19dWsOfnHbnFrbx6TLcp5nYA@mail.gmail.com>
 <CAM_vjun9NAUs=yTqQeQQRYu09OM6JiiRYJXWD1u0fYUqEC62hQ@mail.gmail.com>
 <0acb74a5-e7f7-0c5e-ad98-72ded5120ce6@kfupm.edu.sa>
Message-ID: <b285a022-f203-3def-cdb1-e839ef4bce70@yahoo.fr>

I fit also model with many variables (>100) and I get good result when I 
mix several method iteratively, for example: 500 iterations of 
Nelder-Mead followed by 500 iterations of BFGS followed by 500 
iterations of Nelder-Mead followed by 500 iterations of BFGS etc. until 
it stabilized. It can take several days.
I use or several rounds of optimx or simply succession of optim.

Marc


Le 28/11/2018 ? 09:29, Ruben a ?crit?:
> Hi,
>
> Sarah Goslee (jn reply to? Basic optimization question (I'm a 
> rookie)):? "R is quite good at optimization."
>
> I wonder what is the experience of the R user community with high 
> dimensional problems, various objective functions and various 
> numerical methods in R.
>
> In my experience with my package CatDyn (which depends on optimx), I 
> have fitted nonlinear models with nearly 50 free parameters using 
> normal, lognormal, gamma, Poisson and negative binomial exact 
> loglikelihoods, and adjusted profile normal and adjusted profile 
> lognormal approximate loglikelihoods.
>
> Most numerical methods crash, but CG and spg often, and BFGS, bobyqa, 
> newuoa and Nelder-Mead sometimes, do yield good results (all numerical 
> gradients less than 1)? after 1 day or more running in a normal 64 bit 
> PC with Ubuntu 16.04 or Windows 7.
>
> Ruben
>


From giftedlife2014 @ending from gm@il@com  Fri Nov 30 14:15:41 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Fri, 30 Nov 2018 14:15:41 +0100
Subject: [R] Correct x-axis of two in one graph
In-Reply-To: <90b67fc0724b40b8b59b5d2c15dcef0c@SRVEXCHCM1302.precheza.cz>
References: <CAC8ss30sXduG5xd=F1jh0HEbJNL0UxSQHk_9RFv_RRC8Y2agYg@mail.gmail.com>
 <fe948b80a54c4e2e8ed8678cbb35d39f@SRVEXCHCM1302.precheza.cz>
 <CAC8ss30ec3Y_igi3zsxnFnVmekBOgQ2EBFS9SbESS1yf0ctbww@mail.gmail.com>
 <90b67fc0724b40b8b59b5d2c15dcef0c@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAC8ss325vhpOgbG65cwXf6g_e_nuJpyQnqEBkycFcwcD=jzn9g@mail.gmail.com>

Dear Petr,

Great!!! It worked. The years are interestingly displayed.

Please one thing more. I want all the data points represented by lines
only and not points. I tried to change type = type to type="l". But it
did work.

Thanks for more assistance.

Ogbos
On Fri, Nov 30, 2018 at 9:24 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi
>
> You cannot expect any code to give you results precisely according to your wishes just out of the box.
>
> You could modify x axis by changing format parameter. It is preset to = "%d/%m",    so you could change it to "%Y", if you want to display only year.
>
> format parameter goes to this line in my code.
>
> axis(1, at = x[seq(1, l, length = length)], labels = format(as.POSIXct(x[seq(1,  l, length = length)]), format = format))
>
> The code actually has several other parameters which you could modify or you are free to modify the code itself.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: Ogbos Okike <giftedlife2014 at gmail.com>
> > Sent: Thursday, November 29, 2018 5:17 PM
> > To: PIKAL Petr <petr.pikal at precheza.cz>
> > Cc: r-help <r-help at r-project.org>
> > Subject: Re: [R] Correct x-axis of two in one graph
> >
> > Dear Petr,
> >
> > Thank you so much for your contribution.
> >
> > Let me show you what I have please.
> >
> > I am attaching two plots. The first (twoineone) is my own while the second
> > (testrun) is plotted with the code you send.
> >
> > The first is closer to my interest. The major problem I have is the date. Those
> > were set arbitrary with:
> > axis(side=1,at=c(1,400,800,1200,1500),labels=c("2004","2005","2006","2007",
> > "2008"))
> > and they seem not to be correct.
> >
> > The second one does not show date and date is very important to me here.
> >
> > Is there a way your code can implement the correct date on x-axis? I would be
> > very glad for further assistance.
> >
> > Thank you again.
> > Best wishes
> > Ogbos
> > On Thu, Nov 29, 2018 at 3:03 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> > >
> > > Hi
> > >
> > > If I understand correctly you want Li and CR appear in one plot with the same
> > x axis. Although it is not usually recommended you could use twoord.plot from
> > plotrix or undocumented code below.
> > >
> > > plot.yy <- function (x, yright, yleft, yleftlim = NULL, yrightlim = NULL,   xlab =
> > NULL, yylab = list(NA, NA), pch = c(1, 2), col = c(1,    2), linky = F, smooth = 0,
> > lwds = 1, length = 10, format = "%d/%m",    rect = NULL, type = "p", ...)
> > > {
> > >     par(mar = c(5, 4, 4, 2), oma = c(0, 0, 0, 3))
> > >     plot(x, yright, ylim = yrightlim, axes = F, ylab = "", xlab = xlab,  pch = pch[1],
> > col = col[1], type = type, ...)
> > >     if (!is.null(rect))
> > >         rect(x[rect[1]], rect[2], x[rect[3]], rect[4], col = "grey")
> > >     points(x, yright, ylim = yrightlim, ylab = "", xlab = xlab, pch = pch[1], col =
> > col[1], ...)
> > >     axis(4, pretty(range(yright, na.rm = T), 10), col = col[1])
> > >     if (linky)
> > >         lines(x, yright, col = col[1], ...)
> > >     if (smooth != 0)
> > >         lines(supsmu(x, yright, span = smooth), col = col[1],   lwd = lwds, ...)
> > >     if (is.na(yylab[[1]]))
> > >         mtext(deparse(substitute(yright)), side = 4, outer = T,   line = 1, col =
> > col[1], ...)  else mtext(yylab[[1]], side = 4, outer = T, line = 1, col = col[1],    ...)
> > >     par(new = T)
> > >     plot(x, yleft, ylim = yleftlim, ylab = "", axes = F, xlab = xlab,
> > >         pch = pch[2], col = col[2], ...)
> > >     box()
> > >     axis(2, pretty(range(yleft, na.rm = T), 10), col = col[2],
> > >         col.axis = col[2])
> > >     if (!inherits(x, c("Date", "POSIXt")))
> > >         axis(1, pretty(range(x, na.rm = T), 10))
> > >     else {
> > >         l <- length(x)
> > >         axis(1, at = x[seq(1, l, length = length)], labels =
> > format(as.POSIXct(x[seq(1,  l, length = length)]), format = format))
> > >     }
> > >     if (is.na(yylab[[2]]))
> > >         mtext(deparse(substitute(yleft)), side = 2, line = 2,   col = col[2], ...)
> > >     else mtext(yylab[[2]], side = 2, line = 2, col = col[2],    ...)
> > >     if (linky)
> > >         lines(x, yleft, col = col[2], lty = 2, ...)
> > >     if (smooth != 0)
> > >         lines(supsmu(x, yleft, span = smooth), col = col[2],    lty = 2, lwd = lwds,
> > ...)
> > > }
> > >
> > > something like
> > >
> > > plot.yy(Year, Li, CR)
> > >
> > > Cheers
> > > Petr
> > >
> > > > -----Original Message-----
> > > > From: R-help <r-help-bounces at r-project.org> On Behalf Of Ogbos Okike
> > > > Sent: Thursday, November 29, 2018 2:33 PM
> > > > To: r-help <r-help at r-project.org>
> > > > Subject: [R] Correct x-axis of two in one graph
> > > >
> > > > Dear Contributors,
> > > >
> > > > I have a data of the form:
> > > > 4 8 10 8590 12516
> > > > 4 8 11 8641 98143
> > > > 4 8 12 8705 98916
> > > > 4 8 13 8750 89911
> > > > 4 8 14 8685 104835
> > > > 4 8 15 8629 121963
> > > > 4 8 16 8676 77655
> > > > 4 8 17 8577 81081
> > > > 4 8 18 8593 83385
> > > > 4 8 19 8642 112164
> > > > 4 8 20 8708 103684
> > > > 4 8 21 8622 83982
> > > > 4 8 22 8593 75944
> > > > 4 8 23 8600 97036
> > > > 4 8 24 8650 104911
> > > > 4 8 25 8730 114098
> > > > 4 8 26 8731 99421
> > > > 4 8 27 8715 85707
> > > > 4 8 28 8717 81273
> > > > 4 8 29 8739 106462
> > > > 4 8 30 8684 110635
> > > > 4 8 31 8713 105214
> > > > 4 9 1 8771 92456
> > > > 4 9 2 8759 109270
> > > > 4 9 3 8762 99150
> > > > 4 9 4 8730 77306
> > > > 4 9 5 8780 86324
> > > > 4 9 6 8804 90214
> > > > 4 9 7 8797 99894
> > > > 4 9 8 8863 95177
> > > > 4 9 9 8873 95910
> > > > 4 9 10 8827 108511
> > > > 4 9 11 8806 115636
> > > > 4 9 12 8869 85542
> > > > 4 9 13 8854 111018
> > > > 4 9 14 8571 93247
> > > > 4 9 15 8533 85105
> > > > 4 9 16 8553 114725
> > > > 4 9 17 8561 122195
> > > > 4 9 18 8532 100945
> > > > 4 9 19 8560 108552
> > > > 4 9 20 8634 108707
> > > > 4 9 21 8646 117420
> > > > 4 9 22 8633 113823
> > > > 4 9 23 8680 82763
> > > > 4 9 24 8765 121072
> > > > 4 9 25 8756 89835
> > > > 4 9 26 8750 104578
> > > > 4 9 27 8790 88429
> > > > 4 9 28 8824 84022
> > > > 4 9 29 8843 80413
> > > > 4 9 30 8795 118462
> > > > 4 10 1 8795 139761
> > > > 4 10 2 8805 103049
> > > > 4 10 3 8826 104996
> > > > 4 10 4 8841 104496
> > > > 4 10 5 8882 75603
> > > > 4 10 6 8865 89768
> > > > 4 10 7 8875 93353
> > > > 4 10 8 8898 98410
> > > > 4 10 9 8920 114540
> > > > 4 10 10 8937 95220
> > > > 4 10 11 8926 104083
> > > > 4 10 12 8912 106089
> > > > 4 10 13 8898 116228
> > > > 4 10 14 8926 149610
> > > > 4 10 15 8954 109594
> > > > 4 10 16 8941 75008
> > > > 4 10 17 8952 119182
> > > > 4 10 18 9003 151011
> > > > 4 10 19 9002 146797
> > > > 4 10 20 8995 145769
> > > > 4 10 21 8969 121248
> > > > 4 10 22 8954 107991
> > > > 4 10 23 8992 128
> > > > 4 10 24 8981 23036
> > > > 4 10 25 8920 137485
> > > > 4 10 26 8899 131756
> > > > 4 10 27 8913 108729
> > > > 4 10 28 8874 109478
> > > > 4 10 29 8846 119627
> > > > 4 10 30 8867 89999
> > > > 4 10 31 8868 64833
> > > > 4 11 1 9004 95864
> > > > 4 11 2 9028 82322
> > > > 4 11 3 8969 95591
> > > > 4 11 4 8932 69378
> > > > 4 11 5 8929 74281
> > > > 4 11 6 8916 103261
> > > > 4 11 7 8807 92473
> > > > 4 11 8 8449 84344
> > > > 4 11 9 8484 127415
> > > > 4 11 10 8148 123826
> > > > 4 11 11 8282 100029
> > > > 4 11 12 8305 76205
> > > > 4 11 13 8380 105162
> > > > 4 11 14 8530 119533
> > > > 4 11 15 8642 106490
> > > > 4 11 16 8780 114771
> > > > 4 11 17 8890 55593
> > > > 4 11 18 8962 227
> > > > 4 11 19 8949 109699
> > > > 4 11 20 8974 86004
> > > > 4 11 21 8956 74496
> > > > 4 11 22 8881 109350
> > > > 4 11 23 8872 134020
> > > > 4 11 24 8847 105212
> > > > 4 11 25 8868 91512
> > > > where columns 1= year 2004, 2 = month, 3= day, 4= CR data, 5= Lightning
> > data.
> > > >
> > > > The data range is 2004/8/10 to 2008/8/22.
> > > > With the code below:
> > > > data <- read.table("CRandWWLLNremzro", col.names = c("year",
> > > > "month", "day", "CR","WW"))
> > > >
> > > >
> > > > new.century <- data$year < 50
> > > >
> > > > data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)
> > > >
> > > > data$date <- as.Date(ISOdate(data$year, data$month, data$day)) x =
> > > > data$date  CR = data$CR WWLLN=data$WW
> > > >
> > > > Year<-x
> > > > Li<-WWLLN
> > > > CR<-CR
> > > >
> > > > setEPS()
> > > >  postscript("twoinone2.eps")
> > > >  par(mar = c(5, 4, 4, 4) + 2) # Leave space for z axis
> > > > library(plotrix)
> > > > plot(Year,Li,pch=16,axes=F,xlab="",ylab="",type="l",col="black")
> > > > axis(2, col="black",las=1)  ## las=1 makes horizontal labels
> > > > mtext("Lightning Stroke/day", side=2, line=4)
> > > > #box()
> > > > par(new=TRUE)
> > > > plot(Year,CR, pch=15, xlab="",ylab="",axes=FALSE,type="l",col="red")
> > > > mtext("GCR count/day",side=4,col="red",line=3)
> > > > axis(4, ylim=c(-7499,9684), col="red",col.axis="red",las=1)
> > > >
> > > >
> > > >
> > > > axis(side=1) ##
> > > > mtext("YEAR",side=1,col="black",line=2.5)
> > > > mtext("Long-term Variation betwenn WWLLN and
> > > > GCRs",side=3,col="black",line=2.5)
> > > >
> > > >
> > > > legend("topleft",col=c("red","black"),lty=1,legend=c("GCRs","WWLLN")
> > > > )
> > > >
> > > > dev.off()
> > > >
> > > >   I got the correct axes except that the x-axis is not what I want.
> > > > I want the date to appear on the x-axis. i actually got that by using:
> > > > axis(side=1,at=c(1,400,800,1200,1500),labels=c("2004","2005","2006",
> > > > "2007",
> > > > "2008"))
> > > >
> > > > But there is a little time shift, indicating that the above line may
> > > > not have been assigned correctly.
> > > >
> > > > I then fiddled with  axis(side=1) to see if the correct date can
> > > > naturally appear. I could not succeed.
> > > >
> > > > I can attach the plot I generated. Instead of date appearing on the
> > > > x-axis, ordinary numbers appeared.
> > > >
> > > > I guess the best way of getting the correct date on x-axis is to
> > > > allow the system to fix the date as data points are many. But I
> > > > don't know how to do that.
> > > >
> > > > Thank you in advance for your usual kind help.
> > > > Best regards
> > > > Ogbos
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
> > > obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> > > https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> > > about processing and protection of business partner?s personal data
> > > are available on website:
> > > https://www.precheza.cz/en/personal-data-protection-principles/
> > > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> > > d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> > > odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> > > documents attached to it may be confidential and are subject to the
> > > legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> > >
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>


From petr@pik@l @ending from prechez@@cz  Fri Nov 30 14:44:06 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Fri, 30 Nov 2018 13:44:06 +0000
Subject: [R] Correct x-axis of two in one graph
In-Reply-To: <CAC8ss325vhpOgbG65cwXf6g_e_nuJpyQnqEBkycFcwcD=jzn9g@mail.gmail.com>
References: <CAC8ss30sXduG5xd=F1jh0HEbJNL0UxSQHk_9RFv_RRC8Y2agYg@mail.gmail.com>
 <fe948b80a54c4e2e8ed8678cbb35d39f@SRVEXCHCM1302.precheza.cz>
 <CAC8ss30ec3Y_igi3zsxnFnVmekBOgQ2EBFS9SbESS1yf0ctbww@mail.gmail.com>
 <90b67fc0724b40b8b59b5d2c15dcef0c@SRVEXCHCM1302.precheza.cz>
 <CAC8ss325vhpOgbG65cwXf6g_e_nuJpyQnqEBkycFcwcD=jzn9g@mail.gmail.com>
Message-ID: <6c1023d6b904479ea297d27114707090@SRVEXCHCM1302.precheza.cz>

Hi

If you wanted only lines you need to set parameter linky to TRUE (sorry, the code is around 15 year old and not mentioned to distribution) and it was extended rather chaotically during years.

so

plot.yy(..., linky=TRUE) add lines
plot.yy(..., linky=TRUE, pch=c(NA,NA)) add lines and remove points
plot.yy(..., linky=TRUE, pch=c(NA,NA), smooth = some number) add lines, remove points and add smoothed lines (smooth is parameter to supsmu smoother)

HTH.
Cheers
Petr

> -----Original Message-----
> From: Ogbos Okike <giftedlife2014 at gmail.com>
> Sent: Friday, November 30, 2018 2:16 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] Correct x-axis of two in one graph
>
> Dear Petr,
>
> Great!!! It worked. The years are interestingly displayed.
>
> Please one thing more. I want all the data points represented by lines only and
> not points. I tried to change type = type to type="l". But it did work.
>
> Thanks for more assistance.
>
> Ogbos
> On Fri, Nov 30, 2018 at 9:24 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >
> > Hi
> >
> > You cannot expect any code to give you results precisely according to your
> wishes just out of the box.
> >
> > You could modify x axis by changing format parameter. It is preset to =
> "%d/%m",    so you could change it to "%Y", if you want to display only year.
> >
> > format parameter goes to this line in my code.
> >
> > axis(1, at = x[seq(1, l, length = length)], labels =
> > format(as.POSIXct(x[seq(1,  l, length = length)]), format = format))
> >
> > The code actually has several other parameters which you could modify or
> you are free to modify the code itself.
> >
> > Cheers
> > Petr
> >
> > > -----Original Message-----
> > > From: Ogbos Okike <giftedlife2014 at gmail.com>
> > > Sent: Thursday, November 29, 2018 5:17 PM
> > > To: PIKAL Petr <petr.pikal at precheza.cz>
> > > Cc: r-help <r-help at r-project.org>
> > > Subject: Re: [R] Correct x-axis of two in one graph
> > >
> > > Dear Petr,
> > >
> > > Thank you so much for your contribution.
> > >
> > > Let me show you what I have please.
> > >
> > > I am attaching two plots. The first (twoineone) is my own while the
> > > second
> > > (testrun) is plotted with the code you send.
> > >
> > > The first is closer to my interest. The major problem I have is the
> > > date. Those were set arbitrary with:
> > > axis(side=1,at=c(1,400,800,1200,1500),labels=c("2004","2005","2006",
> > > "2007",
> > > "2008"))
> > > and they seem not to be correct.
> > >
> > > The second one does not show date and date is very important to me here.
> > >
> > > Is there a way your code can implement the correct date on x-axis? I
> > > would be very glad for further assistance.
> > >
> > > Thank you again.
> > > Best wishes
> > > Ogbos
> > > On Thu, Nov 29, 2018 at 3:03 PM PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > > >
> > > > Hi
> > > >
> > > > If I understand correctly you want Li and CR appear in one plot
> > > > with the same
> > > x axis. Although it is not usually recommended you could use
> > > twoord.plot from plotrix or undocumented code below.
> > > >
> > > > plot.yy <- function (x, yright, yleft, yleftlim = NULL, yrightlim = NULL,   xlab
> =
> > > NULL, yylab = list(NA, NA), pch = c(1, 2), col = c(1,    2), linky = F, smooth = 0,
> > > lwds = 1, length = 10, format = "%d/%m",    rect = NULL, type = "p", ...)
> > > > {
> > > >     par(mar = c(5, 4, 4, 2), oma = c(0, 0, 0, 3))
> > > >     plot(x, yright, ylim = yrightlim, axes = F, ylab = "", xlab =
> > > > xlab,  pch = pch[1],
> > > col = col[1], type = type, ...)
> > > >     if (!is.null(rect))
> > > >         rect(x[rect[1]], rect[2], x[rect[3]], rect[4], col = "grey")
> > > >     points(x, yright, ylim = yrightlim, ylab = "", xlab = xlab,
> > > > pch = pch[1], col =
> > > col[1], ...)
> > > >     axis(4, pretty(range(yright, na.rm = T), 10), col = col[1])
> > > >     if (linky)
> > > >         lines(x, yright, col = col[1], ...)
> > > >     if (smooth != 0)
> > > >         lines(supsmu(x, yright, span = smooth), col = col[1],   lwd = lwds, ...)
> > > >     if (is.na(yylab[[1]]))
> > > >         mtext(deparse(substitute(yright)), side = 4, outer = T,   line = 1, col =
> > > col[1], ...)  else mtext(yylab[[1]], side = 4, outer = T, line = 1, col = col[1],
> ...)
> > > >     par(new = T)
> > > >     plot(x, yleft, ylim = yleftlim, ylab = "", axes = F, xlab = xlab,
> > > >         pch = pch[2], col = col[2], ...)
> > > >     box()
> > > >     axis(2, pretty(range(yleft, na.rm = T), 10), col = col[2],
> > > >         col.axis = col[2])
> > > >     if (!inherits(x, c("Date", "POSIXt")))
> > > >         axis(1, pretty(range(x, na.rm = T), 10))
> > > >     else {
> > > >         l <- length(x)
> > > >         axis(1, at = x[seq(1, l, length = length)], labels =
> > > format(as.POSIXct(x[seq(1,  l, length = length)]), format = format))
> > > >     }
> > > >     if (is.na(yylab[[2]]))
> > > >         mtext(deparse(substitute(yleft)), side = 2, line = 2,   col = col[2], ...)
> > > >     else mtext(yylab[[2]], side = 2, line = 2, col = col[2],    ...)
> > > >     if (linky)
> > > >         lines(x, yleft, col = col[2], lty = 2, ...)
> > > >     if (smooth != 0)
> > > >         lines(supsmu(x, yleft, span = smooth), col = col[2],    lty = 2, lwd =
> lwds,
> > > ...)
> > > > }
> > > >
> > > > something like
> > > >
> > > > plot.yy(Year, Li, CR)
> > > >
> > > > Cheers
> > > > Petr
> > > >
> > > > > -----Original Message-----
> > > > > From: R-help <r-help-bounces at r-project.org> On Behalf Of Ogbos
> > > > > Okike
> > > > > Sent: Thursday, November 29, 2018 2:33 PM
> > > > > To: r-help <r-help at r-project.org>
> > > > > Subject: [R] Correct x-axis of two in one graph
> > > > >
> > > > > Dear Contributors,
> > > > >
> > > > > I have a data of the form:
> > > > > 4 8 10 8590 12516
> > > > > 4 8 11 8641 98143
> > > > > 4 8 12 8705 98916
> > > > > 4 8 13 8750 89911
> > > > > 4 8 14 8685 104835
> > > > > 4 8 15 8629 121963
> > > > > 4 8 16 8676 77655
> > > > > 4 8 17 8577 81081
> > > > > 4 8 18 8593 83385
> > > > > 4 8 19 8642 112164
> > > > > 4 8 20 8708 103684
> > > > > 4 8 21 8622 83982
> > > > > 4 8 22 8593 75944
> > > > > 4 8 23 8600 97036
> > > > > 4 8 24 8650 104911
> > > > > 4 8 25 8730 114098
> > > > > 4 8 26 8731 99421
> > > > > 4 8 27 8715 85707
> > > > > 4 8 28 8717 81273
> > > > > 4 8 29 8739 106462
> > > > > 4 8 30 8684 110635
> > > > > 4 8 31 8713 105214
> > > > > 4 9 1 8771 92456
> > > > > 4 9 2 8759 109270
> > > > > 4 9 3 8762 99150
> > > > > 4 9 4 8730 77306
> > > > > 4 9 5 8780 86324
> > > > > 4 9 6 8804 90214
> > > > > 4 9 7 8797 99894
> > > > > 4 9 8 8863 95177
> > > > > 4 9 9 8873 95910
> > > > > 4 9 10 8827 108511
> > > > > 4 9 11 8806 115636
> > > > > 4 9 12 8869 85542
> > > > > 4 9 13 8854 111018
> > > > > 4 9 14 8571 93247
> > > > > 4 9 15 8533 85105
> > > > > 4 9 16 8553 114725
> > > > > 4 9 17 8561 122195
> > > > > 4 9 18 8532 100945
> > > > > 4 9 19 8560 108552
> > > > > 4 9 20 8634 108707
> > > > > 4 9 21 8646 117420
> > > > > 4 9 22 8633 113823
> > > > > 4 9 23 8680 82763
> > > > > 4 9 24 8765 121072
> > > > > 4 9 25 8756 89835
> > > > > 4 9 26 8750 104578
> > > > > 4 9 27 8790 88429
> > > > > 4 9 28 8824 84022
> > > > > 4 9 29 8843 80413
> > > > > 4 9 30 8795 118462
> > > > > 4 10 1 8795 139761
> > > > > 4 10 2 8805 103049
> > > > > 4 10 3 8826 104996
> > > > > 4 10 4 8841 104496
> > > > > 4 10 5 8882 75603
> > > > > 4 10 6 8865 89768
> > > > > 4 10 7 8875 93353
> > > > > 4 10 8 8898 98410
> > > > > 4 10 9 8920 114540
> > > > > 4 10 10 8937 95220
> > > > > 4 10 11 8926 104083
> > > > > 4 10 12 8912 106089
> > > > > 4 10 13 8898 116228
> > > > > 4 10 14 8926 149610
> > > > > 4 10 15 8954 109594
> > > > > 4 10 16 8941 75008
> > > > > 4 10 17 8952 119182
> > > > > 4 10 18 9003 151011
> > > > > 4 10 19 9002 146797
> > > > > 4 10 20 8995 145769
> > > > > 4 10 21 8969 121248
> > > > > 4 10 22 8954 107991
> > > > > 4 10 23 8992 128
> > > > > 4 10 24 8981 23036
> > > > > 4 10 25 8920 137485
> > > > > 4 10 26 8899 131756
> > > > > 4 10 27 8913 108729
> > > > > 4 10 28 8874 109478
> > > > > 4 10 29 8846 119627
> > > > > 4 10 30 8867 89999
> > > > > 4 10 31 8868 64833
> > > > > 4 11 1 9004 95864
> > > > > 4 11 2 9028 82322
> > > > > 4 11 3 8969 95591
> > > > > 4 11 4 8932 69378
> > > > > 4 11 5 8929 74281
> > > > > 4 11 6 8916 103261
> > > > > 4 11 7 8807 92473
> > > > > 4 11 8 8449 84344
> > > > > 4 11 9 8484 127415
> > > > > 4 11 10 8148 123826
> > > > > 4 11 11 8282 100029
> > > > > 4 11 12 8305 76205
> > > > > 4 11 13 8380 105162
> > > > > 4 11 14 8530 119533
> > > > > 4 11 15 8642 106490
> > > > > 4 11 16 8780 114771
> > > > > 4 11 17 8890 55593
> > > > > 4 11 18 8962 227
> > > > > 4 11 19 8949 109699
> > > > > 4 11 20 8974 86004
> > > > > 4 11 21 8956 74496
> > > > > 4 11 22 8881 109350
> > > > > 4 11 23 8872 134020
> > > > > 4 11 24 8847 105212
> > > > > 4 11 25 8868 91512
> > > > > where columns 1= year 2004, 2 = month, 3= day, 4= CR data, 5=
> > > > > Lightning
> > > data.
> > > > >
> > > > > The data range is 2004/8/10 to 2008/8/22.
> > > > > With the code below:
> > > > > data <- read.table("CRandWWLLNremzro", col.names = c("year",
> > > > > "month", "day", "CR","WW"))
> > > > >
> > > > >
> > > > > new.century <- data$year < 50
> > > > >
> > > > > data$year <- ifelse(new.century, data$year + 2000, data$year +
> > > > > 1900)
> > > > >
> > > > > data$date <- as.Date(ISOdate(data$year, data$month, data$day)) x
> > > > > = data$date  CR = data$CR WWLLN=data$WW
> > > > >
> > > > > Year<-x
> > > > > Li<-WWLLN
> > > > > CR<-CR
> > > > >
> > > > > setEPS()
> > > > >  postscript("twoinone2.eps")
> > > > >  par(mar = c(5, 4, 4, 4) + 2) # Leave space for z axis
> > > > > library(plotrix)
> > > > > plot(Year,Li,pch=16,axes=F,xlab="",ylab="",type="l",col="black")
> > > > > axis(2, col="black",las=1)  ## las=1 makes horizontal labels
> > > > > mtext("Lightning Stroke/day", side=2, line=4)
> > > > > #box()
> > > > > par(new=TRUE)
> > > > > plot(Year,CR, pch=15,
> > > > > xlab="",ylab="",axes=FALSE,type="l",col="red")
> > > > > mtext("GCR count/day",side=4,col="red",line=3)
> > > > > axis(4, ylim=c(-7499,9684), col="red",col.axis="red",las=1)
> > > > >
> > > > >
> > > > >
> > > > > axis(side=1) ##
> > > > > mtext("YEAR",side=1,col="black",line=2.5)
> > > > > mtext("Long-term Variation betwenn WWLLN and
> > > > > GCRs",side=3,col="black",line=2.5)
> > > > >
> > > > >
> > > > > legend("topleft",col=c("red","black"),lty=1,legend=c("GCRs","WWL
> > > > > LN")
> > > > > )
> > > > >
> > > > > dev.off()
> > > > >
> > > > >   I got the correct axes except that the x-axis is not what I want.
> > > > > I want the date to appear on the x-axis. i actually got that by using:
> > > > > axis(side=1,at=c(1,400,800,1200,1500),labels=c("2004","2005","20
> > > > > 06",
> > > > > "2007",
> > > > > "2008"))
> > > > >
> > > > > But there is a little time shift, indicating that the above line
> > > > > may not have been assigned correctly.
> > > > >
> > > > > I then fiddled with  axis(side=1) to see if the correct date can
> > > > > naturally appear. I could not succeed.
> > > > >
> > > > > I can attach the plot I generated. Instead of date appearing on
> > > > > the x-axis, ordinary numbers appeared.
> > > > >
> > > > > I guess the best way of getting the correct date on x-axis is to
> > > > > allow the system to fix the date as data points are many. But I
> > > > > don't know how to do that.
> > > > >
> > > > > Thank you in advance for your usual kind help.
> > > > > Best regards
> > > > > Ogbos
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > > > see https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide
> > > > > http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
> > > > obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> > > > https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ |
> > > > Information about processing and protection of business partner?s
> > > > personal data are available on website:
> > > > https://www.precheza.cz/en/personal-data-protection-principles/
> > > > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty
> > > > jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o
> > > > vylou?en?
> > > > odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and
> > > > any documents attached to it may be confidential and are subject
> > > > to the legally binding disclaimer:
> > > > https://www.precheza.cz/en/01-disclaimer/
> > > >
> > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
> > obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> > https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> > about processing and protection of business partner?s personal data
> > are available on website:
> > https://www.precheza.cz/en/personal-data-protection-principles/
> > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> > d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> > odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> > documents attached to it may be confidential and are subject to the
> > legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From d@vid-wong912 @ending from hotm@il@com  Fri Nov 30 14:31:22 2018
From: d@vid-wong912 @ending from hotm@il@com (Wong David)
Date: Fri, 30 Nov 2018 13:31:22 +0000
Subject: [R] Seek help - plm package (Error message: duplicate 'row.names'
 are not allowed)
Message-ID: <HK0PR03MB417818C8D4F4BC7B022C0EFDB7D30@HK0PR03MB4178.apcprd03.prod.outlook.com>

Dear Madam/ Sir,

When I used the 'plm' package and import data into r last week, I found that everything was running smooth. However, when I used the 'plm' package today, I found the following error message:

> pdata <- pdata.frame(mydata, index=c("Province","Year"))
> pooling <- plm(Y~X, data=pdata,model="pooling")
Error in `row.names<-.data.frame`(`*tmp*`, value = c("Anhui-2006", "Anhui-2007",  :
  duplicate 'row.names' are not allowed
In addition: Warning message:
non-unique values when setting 'row.names':

I did not find out the above error message when running panel data regression over one year. Moreover, I attempted to manipulate the data many times in the excel data file, for example, deleting the duplicated row, and convert the data into csv file. The r program shows the same result. Please kindly advise as this problem has bothered for the whole day.

Enclosed is the data set and the respective result. Please kindly assist.

Thanks and regards,
David Wong


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Data analysis result - tourism eg CC excl IM (30 Nov.18).txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20181130/436d87bd/attachment.txt>

From permeti@eneid@ @ending from y@hoo@com  Fri Nov 30 15:21:44 2018
From: permeti@eneid@ @ending from y@hoo@com (Eneida Permeti)
Date: Fri, 30 Nov 2018 14:21:44 +0000 (UTC)
Subject: [R] Granger casuality test in r
References: <1319475140.266229.1543587704219.ref@mail.yahoo.com>
Message-ID: <1319475140.266229.1543587704219@mail.yahoo.com>


The results of my Granger causality test in r are below.?VARp?is my VAR model and I have two endogenous variables. From the results, I have only instantaneous causality. What does it mean?Thank you so much
> causality(VARp,cause="The.economic.growth")
$Granger

    Granger causality H0: The.economic.growth do not Granger-cause
    The.differenced.public.debt

data:  VAR object VARp
F-Test = 0.4038, df1 = 6, df2 = 8, p-value = 0.8573


$Instant

    H0: No instantaneous causality between: The.economic.growth and
    The.differenced.public.debt

data:  VAR object VARp
Chi-squared = 6.0964, df = 1, p-value = 0.01355


> causality(VARp,cause="The.differenced.public.debt")
$Granger

    Granger causality H0: The.differenced.public.debt do not Granger-cause
    The.economic.growth

data:  VAR object VARp
F-Test = 0.70214, df1 = 6, df2 = 8, p-value = 0.6572


$Instant

    H0: No instantaneous causality between: The.differenced.public.debt and
    The.economic.growth

data:  VAR object VARp
Chi-squared = 6.0964, df = 1, p-value = 0.01355
Inviato da Yahoo Mail su Android
	[[alternative HTML version deleted]]


From fr@inj @ending from gm@il@com  Fri Nov 30 17:16:56 2018
From: fr@inj @ending from gm@il@com (John C Frain)
Date: Fri, 30 Nov 2018 16:16:56 +0000
Subject: [R] Granger casuality test in r
In-Reply-To: <1319475140.266229.1543587704219@mail.yahoo.com>
References: <1319475140.266229.1543587704219.ref@mail.yahoo.com>
 <1319475140.266229.1543587704219@mail.yahoo.com>
Message-ID: <CAHrK515=fgLkA=u4Vc0YYBEHvo1tWxXvsL8TATuYqmxgUJsanQ@mail.gmail.com>

On Fri, 30 Nov 2018 at 14:40, Eneida Permeti via R-help <
r-help at r-project.org> wrote:

>
> The results of my Granger causality test in r are below. VARp is my VAR
> model and I have two endogenous variables. From the results, I have only
> instantaneous causality. What does it mean?Thank you so much
> > causality(VARp,cause="The.economic.growth")
> $Granger
>
>     Granger causality H0: The.economic.growth do not Granger-cause
>     The.differenced.public.debt
>
> data:  VAR object VARp
> F-Test = 0.4038, df1 = 6, df2 = 8, p-value = 0.8573
>
>
> $Instant
>
>     H0: No instantaneous causality between: The.economic.growth and
>     The.differenced.public.debt
>
> data:  VAR object VARp
> Chi-squared = 6.0964, df = 1, p-value = 0.01355
>
>
> > causality(VARp,cause="The.differenced.public.debt")
> $Granger
>
>     Granger causality H0: The.differenced.public.debt do not Granger-cause
>     The.economic.growth
>
> data:  VAR object VARp
> F-Test = 0.70214, df1 = 6, df2 = 8, p-value = 0.6572
>
>
> $Instant
>
>     H0: No instantaneous causality between: The.differenced.public.debt and
>     The.economic.growth
>
> data:  VAR object VARp
> Chi-squared = 6.0964, df = 1, p-value = 0.01355
> Inviato da Yahoo Mail su Android
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

It appears that you have not found Granger causality.  I would not be
surprised at this result.

You growth rate is almost equivalent to the log difference of GPD at
constant prices. (real GDP). I suspect that your
 The.differenced.public.debt is at current prices and is not log
transformed.

Granger Causality requires you to control for other variables.  For example
other variables may be causing both of your variables. If such is the case
your finding of Granger Causality may be spurious.

3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

	[[alternative HTML version deleted]]


From permeti@eneid@ @ending from y@hoo@com  Fri Nov 30 18:45:58 2018
From: permeti@eneid@ @ending from y@hoo@com (Eneida Permeti)
Date: Fri, 30 Nov 2018 17:45:58 +0000 (UTC)
Subject: [R] Fw:  Granger casuality test in r
In-Reply-To: <2046901733.363443.1543598641048@mail.yahoo.com>
References: <1319475140.266229.1543587704219.ref@mail.yahoo.com>
 <1319475140.266229.1543587704219@mail.yahoo.com>
 <CAHrK515=fgLkA=u4Vc0YYBEHvo1tWxXvsL8TATuYqmxgUJsanQ@mail.gmail.com>
 <2046901733.363443.1543598641048@mail.yahoo.com>
Message-ID: <1382329372.397458.1543599958423@mail.yahoo.com>

 

   ----- Forwarded Message ----- From: Eneida Permeti <permeti.eneida at yahoo.com>To: John C Frain <frainj at gmail.com>Sent: Friday, November 30, 2018, 9:24:01 AM PSTSubject: Re: [R] Granger casuality test in r
  Dear JohnThank you for responding me.I have attached my data. I am studying the relationship between Public debt and economic growth.The time series of public debt is not stationary an I have differenced it.Than I have estimated a VAR model.But by the results of Granger causality test, I am afraid that something is wrong.Please can you help me?Best regardsEneida Permeti
    On Friday, November 30, 2018, 8:17:09 AM PST, John C Frain <frainj at gmail.com> wrote:  
 
 
On Fri, 30 Nov 2018 at 14:40, Eneida Permeti via R-help <r-help at r-project.org> wrote:


The results of my Granger causality test in r are below.?VARp?is my VAR model and I have two endogenous variables. From the results, I have only instantaneous causality. What does it mean?Thank you so much
> causality(VARp,cause="The.economic.growth")
$Granger

? ? Granger causality H0: The.economic.growth do not Granger-cause
? ? The.differenced.public.debt

data:? VAR object VARp
F-Test = 0.4038, df1 = 6, df2 = 8, p-value = 0.8573


$Instant

? ? H0: No instantaneous causality between: The.economic.growth and
? ? The.differenced.public.debt

data:? VAR object VARp
Chi-squared = 6.0964, df = 1, p-value = 0.01355


> causality(VARp,cause="The.differenced.public.debt")
$Granger

? ? Granger causality H0: The.differenced.public.debt do not Granger-cause
? ? The.economic.growth

data:? VAR object VARp
F-Test = 0.70214, df1 = 6, df2 = 8, p-value = 0.6572


$Instant

? ? H0: No instantaneous causality between: The.differenced.public.debt and
? ? The.economic.growth

data:? VAR object VARp
Chi-squared = 6.0964, df = 1, p-value = 0.01355
Inviato da Yahoo Mail su Android
? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


It appears that you have not found Granger causality.? I would not be surprised at this result.
You growth rate is almost equivalent to the log difference of GPD at constant prices. (real GDP). I suspect that your? ?The.differenced.public.debt is at current prices and is not log transformed.
Granger Causality requires you to control for other variables.? For example other variables may be causing both of your variables. If such is the case your finding of Granger Causality may be spurious.
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com?    

From dc@rl@on @ending from t@mu@edu  Fri Nov 30 19:46:45 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Fri, 30 Nov 2018 18:46:45 +0000
Subject: [R] help with line graphs - rather lengthy to explain need
In-Reply-To: <e7db5a04-71cf-d653-5e41-4cfe636673e9@mail.usf.edu>
References: <02753aa6-462a-6a5c-9a24-3d6a695b3cc0@mail.usf.edu>
 <5de5ada4138e4bb0ae8e023659c19207@tamu.edu>
 <e7db5a04-71cf-d653-5e41-4cfe636673e9@mail.usf.edu>
Message-ID: <5273b8ef475f474291b7d0c4dd72ce1c@tamu.edu>

Reformatting helps because your spreadsheet as currently designed is not R-friendly or tidy. R data structures include vectors, matrices, data.frames, and lists. If you try to create your own structure you are just creating problems for yourself.

Your numeric data are a matrix - all numbers (but they could as well be all character data). They could also be viewed as a vector if you stacked all of the columns on top of one another. Your first two rows are vectors, but location is not numeric (and it is not clear if sample number is to be treated as numeric or character, e.g. sample 0056 would have to be treated as character whereas 56 could be numeric). 

A data.frame is a collection of vectors with headings (column names) and different columns can be different types, e.g. some numeric and some character, BUT all of the values in a column must be the same type. You could make this work if you combined location and sample number into a single row, but if you want to keep them separate, your spreadsheet cannot be converted into a data frame. If you try to read your data into R Commander, it will probably treat the first row (sample numbers) as column names. The second row is characters so R will convert all of your measurements to character strings (and then probably to factors). The mess that you are complaining about.

R Commander is helpful and useful, but it only helps if you use the data structures that R provides. You can also type commands into the script window in R Commander if you need to do something that is not available on the menus. If you want to use R, you are really going to have to invest a bit of time understanding how the program works. There are many free resources to help you learn more about R. 

David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: Robert D. Bowers M.A. [mailto:rdbowers at mail.usf.edu] 
Sent: Friday, November 30, 2018 10:48 AM
To: David L Carlson <dcarlson at tamu.edu>
Subject: Re: [R] help with line graphs - rather lengthy to explain need

I'm not really sure how re-formatting it like that would help - IMO that 
doesn't make sense - but then, I also have to admit that I learned 
programming LONG before I learned statistics (1974 vs 2006/2008) and 
tend to think in terms of arrays (and spreadsheets) when working with 
data - and really don't understand the difference between ggplot and the 
"standard" plotting found in Rcmdr (which can't handle more than a few 
cases - a few samples).

I've been using Rcmdr in this because it simplifies a lot of the steps, 
and is closer to the formal statistics software I studied in school.

Part of my problem is the learning curve - and I really don't have the 
time to try to re-learn a lot of the things I studied a few years ago 
(when I first experienced R and studied it on my own).? I've not done 
much statistical stuff in the last couple of years... I've been working 
on other aspects of my research (including gathering samples and 
generating data).

Matplot is a new one for me - thanks for mentioning it.? Maybe that will 
do what I want.? I'll look at it and see what it can do (and how to get 
the data properly into it - a problem I've encountered because I think 
so 'old-fashioned').

Bob

On 11/29/18 8:37 PM, David L Carlson wrote:
> I'm not sure we have enough details to answer your question, but you may need to think about organizing your spreadsheet differently. Perhaps one sheet that has just the data and a second sheet that has the sample number and the location. Import those separately into R.
>
> Your data are in wide format so matplot() would work for what you want to do, but ggplot may easier if you organize them in long format - one long column of readings, one column of sample numbers (repeated for each of the 2048 measurements from a single sample (and the same for the location column).
>
> If this doesn't put you on the right track, give us a .csv file of a subset of the data (e.g. 10 columns and 20 rows) to play with. You can just copy/paste it into your message. If you save it as an attachment, rename the extension to .txt so the list processor does not strip it out.
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Robert D. Bowers M.A.
> Sent: Thursday, November 29, 2018 3:24 PM
> To: r-help at r-project.org
> Subject: [R] help with line graphs - rather lengthy to explain need
>
> I am trying to figure out the best way to organize and plot data
> generated by a Excel spreadsheet (one driving a sample turntable and
> collecting optical spectra).
>
> The output of the equipment and software is an excel spreadsheet with
> sample numbers in the first row, and in the first column there is the
> wavelength in nm.? 2048 individual measurements (per wavelength) - 2048
> rows plus the sample number row, and at present I've tested 250 samples,
> with a LOT more to follow.
>
> After I get the spreadsheet, I add a row (just below the sample numbers)
> containing site locations.? I've collected 50 samples per site (each
> assigned a different number), so far 5 sites.? The spreadsheet ends up
> with 2050 rows, 250 columns.
>
> What I want to do is generate a line graph of the data (which could be
> separated out into sections of the optical spectrum), with line colors
> assigned by the site name.? Once that's done, the graphs make sense
> (right now the only way I can do that is using the spreadsheet software,
> and assigning each line the color manually - a very tiresome and
> time-consuming process).
>
> So far, I've tried everything I can to get a graph out using R, without
> luck.? I'm rusty with R and programming... I've used Rcmdr (tried
> transposing data, various settings and so on) and 'played' with ggplot -
> no success.? I'm using Rcmdr to make it easier to work out the bugs,
> then will write a short program to process data.
>
> What I'd like to know is (1) what would be the best way to organize the
> data - sample numbers (cases) in the first row, or in the first column
> with the next row or column being the site name, (2) how would I get
> ggplot to plot the line graph showing all of the samples (number listing
> not important) and all (or a selection) of the different wavelengths,
> while assigning line color based on site name.? Once that's done, I can
> show the within-group vs between-group variation compared to wavelength.
>
> To give an idea of what the data look like:
>
> (name = Longwave)
>
> Sample ??? 34900?? 34901? 34902??? 34903??? 34904??? (and so on)
>
> Site?? ??? ???? Tp??? ???? Tc??? ??? ? Cr??? ?????? Ws Gs
>
> 200(nm) ?? 300.5??? 783.9??? 101.3????? 623.8???? 1385.7
>
> 201....
>
> You get the idea.? (maximum measurement value is 4098, the instrument
> takes multiple scans and averages them).
>
> If I can figure this out, it will speed up my work - which I need to do
> so I can get a grant proposal off on time.
>
> Thank you,
>
> Bob
>
> Doctoral Candidate, Applied Anthropology
>
> University of South Florida
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From permeti@eneid@ @ending from y@hoo@com  Fri Nov 30 18:37:04 2018
From: permeti@eneid@ @ending from y@hoo@com (Eneida Permeti)
Date: Fri, 30 Nov 2018 17:37:04 +0000 (UTC)
Subject: [R] Fw:  Granger casuality test in r
In-Reply-To: <2046901733.363443.1543598641048@mail.yahoo.com>
References: <1319475140.266229.1543587704219.ref@mail.yahoo.com>
 <1319475140.266229.1543587704219@mail.yahoo.com>
 <CAHrK515=fgLkA=u4Vc0YYBEHvo1tWxXvsL8TATuYqmxgUJsanQ@mail.gmail.com>
 <2046901733.363443.1543598641048@mail.yahoo.com>
Message-ID: <385316845.397003.1543599425038@mail.yahoo.com>

 

   ----- Forwarded Message ----- From: Eneida Permeti <permeti.eneida at yahoo.com>To: John C Frain <frainj at gmail.com>Sent: Friday, November 30, 2018, 9:24:01 AM PSTSubject: Re: [R] Granger casuality test in r
  Dear JohnThank you for responding me.I have attached my data. I am studying the relationship between Public debt and economic growth.The time series of public debt is not stationary an I have differenced it.Than I have estimated a VAR model.But by the results of Granger causality test, I am afraid that something is wrong.Please can you help me?Best regardsEneida Permeti
    On Friday, November 30, 2018, 8:17:09 AM PST, John C Frain <frainj at gmail.com> wrote:  
 
 
On Fri, 30 Nov 2018 at 14:40, Eneida Permeti via R-help <r-help at r-project.org> wrote:


The results of my Granger causality test in r are below.?VARp?is my VAR model and I have two endogenous variables. From the results, I have only instantaneous causality. What does it mean?Thank you so much
> causality(VARp,cause="The.economic.growth")
$Granger

? ? Granger causality H0: The.economic.growth do not Granger-cause
? ? The.differenced.public.debt

data:? VAR object VARp
F-Test = 0.4038, df1 = 6, df2 = 8, p-value = 0.8573


$Instant

? ? H0: No instantaneous causality between: The.economic.growth and
? ? The.differenced.public.debt

data:? VAR object VARp
Chi-squared = 6.0964, df = 1, p-value = 0.01355


> causality(VARp,cause="The.differenced.public.debt")
$Granger

? ? Granger causality H0: The.differenced.public.debt do not Granger-cause
? ? The.economic.growth

data:? VAR object VARp
F-Test = 0.70214, df1 = 6, df2 = 8, p-value = 0.6572


$Instant

? ? H0: No instantaneous causality between: The.differenced.public.debt and
? ? The.economic.growth

data:? VAR object VARp
Chi-squared = 6.0964, df = 1, p-value = 0.01355
Inviato da Yahoo Mail su Android
? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


It appears that you have not found Granger causality.? I would not be surprised at this result.
You growth rate is almost equivalent to the log difference of GPD at constant prices. (real GDP). I suspect that your? ?The.differenced.public.debt is at current prices and is not log transformed.
Granger Causality requires you to control for other variables.? For example other variables may be causing both of your variables. If such is the case your finding of Granger Causality may be spurious.
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com?    

