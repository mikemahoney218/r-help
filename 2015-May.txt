From drjimlemon at gmail.com  Fri May  1 03:22:31 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 1 May 2015 11:22:31 +1000
Subject: [R] Inference Syntax
In-Reply-To: <5542A2AE.1020306@auckland.ac.nz>
References: <1430392961881-4706637.post@n4.nabble.com>
	<5542A2AE.1020306@auckland.ac.nz>
Message-ID: <CA+8X3fUgvMmzjHLktVbtV4mvetMHjEuO27bcZitHiUFW4tCbgw@mail.gmail.com>

Hi Shiv82,
This doesn't look like it comes from the SharpeR, iBATGCH, inference
packages and there are too many other packages using the term to
easily identify it. As Rolf pointed out, alternative hypotheses are
typically framed as:

"two-sided" - non-directional, only specifies that the comparison of
statistics shows a difference.

"less" or "greater" - specifies that one particular statistic (usually
that of an experimental group) in the comparison must be less or
greater than the other (usually the reference group).

Jim

On Fri, May 1, 2015 at 7:46 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 30/04/15 23:22, Shivi82 wrote:
>>
>> Hi All,
>>
>> This is my first post in the community.
>> I am currently working on finding some inferences from my sample data and
>> the code I have used is:
>> inference(y = nc$weight, x = nc$habit, est = "mean", type = "ht", null =
>> 0,
>> method = "theoretical"). While researching more on the code as I have just
>> started using R, online I found alternative also as a keyword for the
>> syntax
>> which has option as either less, greater or two sided. I am unsure what it
>> is referring to.
>> If someone would please explain the alterative keyword. Thank you.
>
>
> The word "alternative" refers to the alternative hypothesis in the test that
> you are carrying out.
>
> Where does the function inference() come from?  I can find no trace of it in
> a standard R installation, and the term is too broad to search for
> effectively.  Please do not expect the R-help list to be telepathic.
>
> cheers,
>
> Rolf Turner
>
> --
> Rolf Turner
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> Home phone: +64-9-480-4619
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Fri May  1 04:20:53 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 1 May 2015 12:20:53 +1000
Subject: [R] Editable plot
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68809C@mb02.ads.tamu.edu>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68809C@mb02.ads.tamu.edu>
Message-ID: <CA+8X3fXHvHp7p_31AMr0uyjUwYdZL4OA99JFy+OFd3G2O83KXw@mail.gmail.com>

Hi Ishaq,
Well, you could do something absolutely ridiculous like this:

edit_my_plot<-function(x,y,z,w,r) {
 npoints<-length(r)
 index<-1
 while(length(index)) {
  matplot(x=matrix(r,nrow=3,ncol=4),y=cbind(x,y,z,w),
   xlab="Number of iteration",ylab="Bias",
   type="b",pch=c(1,22,22,22),lwd=2,
   col=c("blue","red","green","forestgreen"))
  title(main="Estimated Bias for the optimal response ",
   col.main="red",font.main=4)
  text(rep(1000,4),c(0.15,1.10,1.52,1.4),c("PM","VM","WMSE","LT"))
  cat("Click on the point you want to move\n")
  index<-identify(rep(r,4),c(x,y,z,w),n=1,plot=FALSE)
  if(length(index)) {
   cat("Now click where you want to move it\n")
   newxy<-locator(n=1)
   if(index < npoints + 1) {
    x[index]<-newxy$y
    r[index]<-newxy$x
   }
   else {
    if(index < 2 * npoints + 1) {
     y[index-npoints]<-newxy$y
     r[index-npoints]<-newxy$x
    }
    else {
     if(index < 3 * npoints + 1) {
      z[index-2*npoints]<-newxy$y
      r[index-2*npoints]<-newxy$x
     }
     else {
      w[index-3*npoints]<-newxy$y
      r[index-3*npoints]<-newxy$x
     }
    }
   }
  }
 }
}

Jim


On Fri, May 1, 2015 at 5:25 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> Do not post in html. You need to change your email software so that it sends messages in plain text only. Look below to see why.
>
> Your plot is edited by modifying the code you gave us to change the graph. Save the code in a script file, change it in any way you want and then run the code again to get a changed plot. You cannot edit the plot by selecting an element on the plot and changing its properties in some way.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of IZHAK shabsogh via R-help
> Sent: Thursday, April 30, 2015 2:04 AM
> To: R.
> Subject: [R] Editable plot
>
>
> Hello,Kindly assist me on how to make the plot from the following programm to be editable
>
> x<-c(0.84,1.03,0.96)y<-c(1.30,1.46,1.48)z<-c(1.32,1.47,1.5)w<-c(0.07,0.07,0.07)r<-c(500,1000,2000)
> # Graph cars using a y axis that ranges from 0 to 12plot(r,x, type="o", col="blue", ylim=c(0,1.5),lwd= 2, xlab = " Number of iteration",ylab=" Bias" )
> # Graph trucks with red dashed line and square pointslines(r,y, type="o", pch=22, lty=2, col="red",lwd=2)lines(r,z, type="o", pch=22, lty=3, col="green",lwd=2)lines(r,w, type="o", pch=22, lty=4, col="forestgreen",lwd=2)
> # Create a title with a red, bold/italic font#title(main="Estimated Bias for the optimal response ", col.main="red", font.main=4)
> #legend("center", lty = 1:4, col = 1:4,       #legend = c("x","y", "z","w"))
> text(1000, 0.15, "PM")text(1000, 1.10, "VM")text(1000, 1.52, "WMSE")text(1000, 1.40, "LT")
>
> Thank youIshaq
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Fri May  1 08:59:38 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 1 May 2015 06:59:38 +0000
Subject: [R] help - hoslem.test
In-Reply-To: <1430434156.15787.YahooMailBasic@web120204.mail.ne1.yahoo.com>
References: <1292B391472.00000ED8jrkrideau@inbox.com>
	<1430434156.15787.YahooMailBasic@web120204.mail.ne1.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2C368@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: Luciane Maria Pilotto [mailto:lutipilotto at yahoo.com.br]
> Sent: Friday, May 01, 2015 12:49 AM
> To: PIKAL Petr; r-help at r-project.org; John Kane
> Subject: Re: [R] help - hoslem.test
>
> Ok, in dropbox link below you can download the bank.
> (https://www.dropbox.com/s/9qrdf4mhd6tzypi/id3.rda?dl=0)

No. Not everybody is alowed to use dropbox. Try to post result of

dput(id3)

directly to your post.

Cheers
Petr

>
> I change the script following the suggestions, but the error persists.
> I used the the na.action command to delete the lost values.
>
> #######################################################################
>
> load("id3.rda")
> attach(id3)
>
> #transformando q13 em bin?ria (o/1)
> q131<-ifelse(q13==1,0,ifelse(q13==2,1,ifelse(q13==3,1,
> ifelse(q13==4,1,ifelse(q13==5,1,NA)))))
> id3<-cbind(id3,q131)
> id3$q131 <- as.factor(id3$q131)
> str(id3)
>
> tp1 <- glm(q131 ~ q11 + q10+q12+edcat + q08+q06+ q14, family =
> binomial(link = "logit"), data=id3, na.action="na.exclude")
> tp1
> hoslem.test(tp1$q131, fitted(tp1), g=10)
>
>
>
> --------------------------------------------
> Em qui, 30/4/15, John Kane <jrkrideau at inbox.com> escreveu:
>
>  Assunto: Re: [R] help - hoslem.test
>  Para: "PIKAL Petr" <petr.pikal at precheza.cz>, "Luciane Maria Pilotto"
> <lutipilotto at yahoo.com.br>, "r-help at r-project.org" <r-help at r-
> project.org>
>  Data: Quinta-feira, 30 de Abril de 2015, 11:51
>
>  Kevin Thorpe pointed out
>  to me that there is a dropbox link at the very bottom of the
>  post that I missed. :(
>
>  I
>  just downloaded it, read it in and it looks fine.
>
>  John Kane
>  Kingston ON Canada
>
>
>  > -----Original
>  Message-----
>  > From: petr.pikal at precheza.cz
>  > Sent: Thu, 30 Apr 2015 14:25:23 +0000
>  > To: lutipilotto at yahoo.com.br,
>  r-help at r-project.org
>  > Subject: Re: [R] help - hoslem.test
>  >
>  > Hi
>  >
>  > I agree with John
>  >
>  > Just small
>  refinements in lines
>  >
>  >> -----Original Message-----
>  >>> -----Original Message-----
>  >>> From: lutipilotto at yahoo.com.br
>  >>> Sent: Thu, 30 Apr 2015 04:24:32
>  -0700
>  >>> To: r-help at r-project.org,
>  jrkrideau at inbox.com
>  >>> Subject: RE: [R] help -
>  hoslem.test
>  >>>
>  >>> load("id3.rda")
>  >> And what is this?
>  >>
>  >> We do not
>  have access to your office or computer hard disc.
>  >>
>  >> Please read
>  http://stackoverflow.com/questions/5963269/how-to-make-a-
>  >> great-r-reproducible-example, see
>  ?dput for sending data?
>  >>
>  >> It is very unlikely anyone here can
>  help if we have no data.
>  >>
>  >>
>  >>>
>  attach(id3)
>  >
>  > Do
>  not use attach. It prevents from modifiyng id3.
>  >
>  >>>
>  >>> #transformando q13 em bin?ria
>  >>>
>  q131<-ifelse(q13==1,1,ifelse(q13==2,2,ifelse(q13==3,2,
>  >>>
>  ifelse(q13==4,2,ifelse(q13==5,2,NA)))))
>  >
>
>  > q131 <- as.numeric(cut(q13,
>  c(0,1.5,5)))
>  >
>  >>
>  x<-1:7
>  >> x
>  >
>  [1] 1 2 3 4 5 6 7
>  >> as.numeric(cut(x,
>  c(0,1.5,5)))
>  > [1]  1  2  2  2  2 NA
>  NA
>  >
>  >>>
>  id3<-cbind(id3,q131)
>  >
>  > rather dangerous in case id3 is not
>  data.frame but matrix
>  >
>  >>> id3$q131 <-
>  as.factor(id3$q131)
>  >>>
>  >>> tp1 <- glm(q131 ~ q11 +
>  q10+q12+edcat + q08+q06+ q14, family =
>  >>> binomial(link =
>  "logit"), data=id3)
>  >>>
>  tp1
>  >>>
>  >>> library(ResourceSelection)
>  >>> hoslem.test(tp1$q131, fitted(tp1),
>  g=10)
>  >
>  > hoslem.test
>  expects x to be a numeric vector of observations, binary
>  > (0/1).
>  > If I
>  understand correctly tp1$q131 have values 1, 2 or NA.
>  >
>  > Cheers
>  > Petr
>  >
>  >>>
>  >>>
>  dataframe: https://www.dropbox.com/s/9qrdf4mhd6tzypi/id3.rda?dl=0
>  >>>
>  >>>
>  >>>
>  __________________________________________________
>  >>> Luciane Maria Pilotto
>  >>> Mestre e Doutoranda em Sa?de
>  Bucal Coletiva - FO/UFRGS
>  >>> NDE
>  Odontologia - UNIVATES
>  >>>
>  Telefone: (51) 84512344
>  >>>
>  >>>
>  --------------------------------------------
>  >>> Em qui, 30/4/15, John Kane <jrkrideau at inbox.com>
>  escreveu:
>  >>>
>  >>>  Assunto: RE: [R] help -
>  hoslem.test
>  >>>  Para:
>  "Luciane Maria Pilotto" <lutipilotto at yahoo.com.br>,
>  >>> r-help at r-project.org
>  >>>  Data: Quinta-feira, 30 de Abril
>  de 2015, 7:52
>  >>>
>  >>>  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-
>  >> reproducible-example
>  >>>
>  >>>
>  John Kane
>  >>>  Kingston ON
>  Canada
>  >>>
>  >>>
>  >>>
>  > -----Original Message-----
>  >>>  > From: lutipilotto at yahoo.com.br
>  >>>  > Sent: Wed, 29 Apr 2015
>  18:45:26 -0700
>  >>>  > To: r-help at r-project.org
>  >>>  > Subject: [R] help -
>  hoslem.test
>  >>>  >
>  >>>  > Hello,
>  >>>  >
>  >>>  > I'm working with
>  >>>  ordinal logistic regression
>  model (polr) and would like
>  >>>
>  > to test the proportional odds assumption.
>  >>>  For this, I ran the binary
>  >>>  > logistic
>  >>>  regressions with varying
>  cutpoints on the dependent
>  >>>
>  variable, as
>  >>>  > described
>  in the following
>  >>>  commands.
>  When running the test of Hosmer and
>  >>>  > Lemeshow (hoslem.test) for
>  residuals gives
>  >>>  error.
>  >>>  >
>  >>>  > Thanks,
>  >>>  > Luciane
>  >>>  >
>  >>>  >
>  >>>
>  ______________________________________________
>  >>>  > R-help at r-project.org
>  >>>  mailing list -- To UNSUBSCRIBE
>  and more, see
>  >>>  > https://stat.ethz.ch/mailman/listinfo/r-help
>  >>>  > PLEASE do read the posting
>  guide
>  >>>  > http://www.R-project.org/posting-guide.html
>  >>>  > and provide commented,
>  minimal,
>  >>>  self-contained,
>  reproducible code.
>  >>>
>  >>>
>  ____________________________________________________________
>  >>>  FREE ONLINE PHOTOSHARING - Share
>  your photos
>  >>>  online with your
>  friends and family!
>  >>>  Visit
>  >>>  http://www.inbox.com/photosharing to
>  >>>  find out more!
>  >>
>  >>
>  ____________________________________________________________
>  >> FREE ONLINE PHOTOSHARING - Share your
>  photos online with your friends
>  >> and
>  family!
>  >> Visit http://www.inbox.com/photosharing to
>  find out more!
>  >>
>  >>
>  ______________________________________________
>  >> R-help at r-project.org
>  mailing list -- To UNSUBSCRIBE and more, see
>  >> https://stat.ethz.ch/mailman/listinfo/r-help
>  >> PLEASE do read the posting guide http://www.R-project.org/posting-
>  >> guide.html
>  >>
>  and provide commented, minimal, self-contained, reproducible
>  code.
>  >
>  >
>  ________________________________
>  > Tento
>  e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>  d?v?rn? a jsou
>  > ur?eny pouze jeho
>  adres?t?m.
>  > Jestli?e jste obdr?el(a)
>  tento e-mail omylem, informujte laskav?
>  > neprodlen? jeho odes?latele. Obsah
>  tohoto emailu i s p??lohami a jeho
>  >
>  kopie vyma?te ze sv?ho syst?mu.
>  >
>  Nejste-li zam??len?m adres?tem tohoto emailu, nejste
>  opr?vn?ni tento
>  > email jakkoliv
>  u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>  > Odes?latel e-mailu neodpov?d? za
>  eventu?ln? ?kodu zp?sobenou modifikacemi
>  > ?i zpo?d?n?m p?enosu e-mailu.
>  >
>  > V p??pad?, ?e je
>  tento e-mail sou??st? obchodn?ho jedn?n?:
>  > - vyhrazuje si odes?latel pr?vo ukon?it
>  kdykoliv jedn?n? o uzav?en?
>  >
>  smlouvy, a to z jak?hokoliv d?vodu i bez uveden?
>  d?vodu.
>  > - a obsahuje-li nab?dku, je
>  adres?t opr?vn?n nab?dku bezodkladn?
>  > p?ijmout; Odes?latel tohoto e-mailu
>  (nab?dky) vylu?uje p?ijet? nab?dky ze
>  > strany p??jemce s dodatkem ?i
>  odchylkou.
>  > - trv? odes?latel na tom,
>  ?e p??slu?n? smlouva je uzav?ena teprve
>  > v?slovn?m dosa?en?m shody na v?ech
>  jej?ch n?le?itostech.
>  > - odes?latel
>  tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat
>  za
>  > spole?nost ??dn? smlouvy s
>  v?jimkou p??pad?, kdy k tomu byl p?semn?
>  > zmocn?n nebo p?semn? pov??en a
>  takov? pov??en? nebo pln? moc byly
>  >
>  adres?tovi tohoto emailu p??padn? osob?, kterou
>  adres?t zastupuje,
>  > p?edlo?eny nebo
>  jejich existence je adres?tovi ?i osob? j?m
>  zastoupen?
>  > zn?m?.
>  >
>  > This e-mail and any
>  documents attached to it may be confidential and are
>  > intended only for its intended
>  recipients.
>  > If you received this e-mail
>  by mistake, please immediately inform its
>  > sender. Delete the contents of this e-mail
>  with all attachments and its
>  > copies
>  from your system.
>  > If you are not the
>  intended recipient of this e-mail, you are not
>  > authorized to use, disseminate, copy or
>  disclose this e-mail in any
>  > manner.
>  > The sender of this e-mail shall not be
>  liable for any possible damage
>  > caused
>  by modifications of the e-mail or by delay with transfer of
>  the
>  > email.
>  >
>  > In case that this e-mail forms part of
>  business dealings:
>  > - the sender
>  reserves the right to end negotiations about entering into
>  a
>  > contract in any time, for any reason,
>  and without stating any reasoning.
>  > - if
>  the e-mail contains an offer, the recipient is entitled
>  to
>  > immediately accept such offer; The
>  sender of this e-mail (offer) excludes
>  >
>  any acceptance of the offer on the part of the recipient
>  containing any
>  > amendment or
>  variation.
>  > - the sender insists on that
>  the respective contract is concluded only
>  > upon an express mutual agreement on all
>  its aspects.
>  > - the sender of this
>  e-mail informs that he/she is not authorized to
>  > enter into any contracts on behalf of the
>  company except for cases in
>  > which
>  he/she is expressly authorized to do so in writing, and
>  such
>  > authorization or power of attorney
>  is submitted to the recipient or the
>  >
>  person represented by the recipient, or the existence of
>  such
>  > authorization is known to the
>  recipient of the person represented by the
>  > recipient.
>  >
>  ______________________________________________
>  > R-help at r-project.org
>  mailing list -- To UNSUBSCRIBE and more, see
>  > https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide
>  > http://www.R-project.org/posting-guide.html
>  > and provide commented, minimal,
>  self-contained, reproducible code.
>
>  ____________________________________________________________
>  Receive Notifications of Incoming Messages
>  Easily monitor multiple email accounts &
>  access them with a click.
>  Visit http://www.inbox.com/notifier and check
>  it out!
>
>

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From nashjc at uottawa.ca  Fri May  1 13:53:11 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Fri, 01 May 2015 07:53:11 -0400
Subject: [R] 'Installation of package <package> had non-zero exit,
 > status' on R-3.2.0 (RStudio Version 0.98.1103) on Ubuntu 12.04 OS
In-Reply-To: <554368B2.3040208@uottawa.ca>
References: <554368B2.3040208@uottawa.ca>
Message-ID: <55436927.6000609@uottawa.ca>

As another post has suggested, r-sig-debian may be more help.

However, it looks like you need to install a different package from the
one you tried. See

http://ubuntuforums.org/showthread.php?t=1774516

about getting libcurl on 12.04.

FYI Ubuntu 12.04 is now getting dated, and I've found people using it
get similar problems to that you encountered -- i.e., packages that more
up to date distros use are not available, or those that are available
don't have all the features needed. Maybe time to upgrade.

JN


On 15-05-01 06:00 AM, r-help-request at r-project.org wrote:
> Date: Fri, 1 May 2015 00:50:38 +0530
> From: Anirudh Jayaraman <anirudhj at igidr.ac.in>
> To: Duncan Murdoch <murdoch.duncan at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] 'Installation of package <package> had non-zero exit
> 	status' on R-3.2.0 (RStudio Version 0.98.1103) on Ubuntu 12.04 OS
> Message-ID:
> 	<CAD4HhLwRUW4jy2XerC4-zvYBDjA8RiPP=82t2k45++mr8jmfpA at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
> 
> In that case, it seems that *libcurl* is not available for R-3.2.0 as I get
> a message for
> 
> *>* *install.packages("libcurl")*
> 
>   package ?libcurl? is not available (for R version 3.2.0)
> 
> Or if on Terminal I run
> 
> *sudo apt-get install libcurl4-openssl-dev*
> 
> Package libcurl4-openssl-dev is not available, but is referred to by
> another package.
> This may mean that the package is missing, has been obsoleted, or
> is only available from another source
> 
> 
> *________________________________________________________*
> *Anirudh Jayaraman*
> M.Sc Economics (2014-16)
> Indira Gandhi Institute of Development Research (IGIDR), Mumbai
> Ph No: +91 9560476729


From masher6666 at gmail.com  Fri May  1 13:13:47 2015
From: masher6666 at gmail.com (Masher Masher)
Date: Fri, 1 May 2015 13:13:47 +0200
Subject: [R] QMLE of MGARCH
Message-ID: <CAGx7CyPBUwFdhE=pHNTQfaeqRD=WjadPD46P3tPp2AbnKxvOvA@mail.gmail.com>

Hi guys,
I've already done some research on the topic and would like to ask you for
advice. As stated in the topic, I need to estimate multivariate GARCH
parameters using QML. I've been looking for an appropriate package for R and
out of many that I've encountered the only one that seems promising is
fGarch; precisely the garchFit function. But the description of the function
states that it's a function for univariate time series. However, the example
provides a multivariate case, though it's not very specific.

So my question is: is the function garchFit the best one to estimate
parameters using the QML or should I better use other packages for
convenience.

I apologize if the question seems trivial, but I can't find a definitive
answer to it.

Best regards, Masher

	[[alternative HTML version deleted]]


From shivibhatia at ymail.com  Fri May  1 09:55:10 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Fri, 1 May 2015 00:55:10 -0700 (PDT)
Subject: [R] Inference Syntax
In-Reply-To: <CA+8X3fUgvMmzjHLktVbtV4mvetMHjEuO27bcZitHiUFW4tCbgw@mail.gmail.com>
References: <1430392961881-4706637.post@n4.nabble.com>
	<5542A2AE.1020306@auckland.ac.nz>
	<CA+8X3fUgvMmzjHLktVbtV4mvetMHjEuO27bcZitHiUFW4tCbgw@mail.gmail.com>
Message-ID: <1430466910431-4706677.post@n4.nabble.com>

Hi All,
Thanks for extending help on this one. I am able to understand how what it
refers to.
I am using R studio as I think it comes as an inbuilt capability. 



--
View this message in context: http://r.789695.n4.nabble.com/Inference-Syntax-tp4706637p4706677.html
Sent from the R help mailing list archive at Nabble.com.


From fisher at plessthan.com  Fri May  1 16:10:42 2015
From: fisher at plessthan.com (Fisher Dennis)
Date: Fri, 1 May 2015 07:10:42 -0700
Subject: [R] Missing axis labels
Message-ID: <9003CD31-0DC2-47A6-95D5-E1325CA50DC9@plessthan.com>

R 3.2.0
OS X
This is a general question, not specific to OS X.  

Colleagues

Often, one or more values on an axis will be omitted, presumably in order to prevent overlap.  However, there are situations where I would like to override that omission.  Sample code:
	pdf("labels.pdf", width=3, height=3)
	plot(0:100, 0:100)
	graphics.off()
Here, 100 is omitted from the x-axis and 20, 60, and 100 from the y-axis.  

Is there is automated way to detect which values will be omitted (i.e., without seeing the graphic)?  

If so, I see two options:
	1.  change the font size
	2.  force the entry, e.g., axis(1, 100, at=100)

Dennis


Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com


From carlo-giovanni.camarda at ined.fr  Fri May  1 16:16:21 2015
From: carlo-giovanni.camarda at ined.fr (CAMARDA Carlo Giovanni)
Date: Fri, 1 May 2015 16:16:21 +0200 (CEST)
Subject: [R] Reproducing lm outcomes with mixed effect model on augmented
 dataset
In-Reply-To: <1586243244.18332.1430489235788.JavaMail.root@ined.fr>
Message-ID: <502047385.18577.1430489781278.JavaMail.root@ined.fr>


Dear R-users, 


let's assume a simple linear model in which to each original observation one attaches random response and covariate, but with weights that are practically zero. If one runs a linear model to both original and augmented data, one obtains the same estimates, but obviously different standard errors. 
Could we reproduce the lm() outcomes in a mixed effect model setting using, for instance, lme(nlme)? Is there any way to get the lm() estimates and standard deviations by accounting for correlation within each new pseudo-observation? 
Below a reproducible and commented instance of the problem . 
Thanks in advance for your help, 
GC 






library(nlme) 
## simulating data 
m <- 1000 
x <- runif(m) 
y <- 3 + 4*x + rnorm(m, sd=0.5) 
id <- 1:m 
dati <- cbind(id=id, x=x, y=y, w=1) 
## new data: repeat n times original data 
n <- 10 
datiA <- kronecker(dati, matrix(1,n,1)) 
## trasform in dataframes with suitable names 
dati <- as.data.frame(dati) 
datiA <- as.data.frame(datiA) 
names(datiA) <- names(dati) 
## assign ~0 weight to everyone, but the original observations 
fw <- 10^-30 
datiA$w <- fw 
datiA$w[seq(1,m*n,n)] <- 1 - n*fw 
## assign random numbers to all response/covariate, but for the original observations 
datiA$x[datiA$w==fw] <- runif(m*n-m) 
datiA$y[datiA$w==fw] <- runif(m*n-m) 
## fits with lm() 
fit <- lm(y~x, weights=w, data=dati) 
summary(fit)$coef[,1:2] 
fitA <- lm(y~x, weights=w, data=datiA) 
summary(fitA)$coef[,1:2] 
## mixed model approach, lme() 
## attempting to reproduce results from "fit" 
fitMM <- lme(y ~ x, weights=varFixed(~1/w), 
random=~1|id, 
data=datiA) 

summary(fitMM)$tTable[,1:2] 




	[[alternative HTML version deleted]]


From rshepard at appl-ecosys.com  Fri May  1 17:00:16 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Fri, 1 May 2015 08:00:16 -0700 (PDT)
Subject: [R] Plot Title: Adjusting Position
Message-ID: <alpine.LNX.2.11.1505010750420.2263@localhost>

   Plots of compositional data ternary diagrams do not accept the main label
within the plot() function, but do print the label when it is specified
within the title() function. On some of these plots I need to raise the
position of the title just enough to move the text above the top row of
diagrams.

   Applying the outer=TRUE option moves the title too high; the top half of
the text is cut off from viewing. The help file, ?title, suggests that the
line option applies to sub-titles and axis labels, not the main title.
Setting character expansion to a negative value throws an error.

   How can I either move the main title sightly higher on the figure or
slightly reduce the text size so the title does not overlap part of the
ternary diagrams?

Rich


From marcelolaia at gmail.com  Fri May  1 17:00:35 2015
From: marcelolaia at gmail.com (Marcelo Laia)
Date: Fri, 1 May 2015 12:00:35 -0300
Subject: [R] qRT-PCR Sample Maximization software analysis and proper
 experimental design advice
Message-ID: <CAEEYVUDgeXV3fMkbKGfriHFNgHOL_cMPZa-qCYZC_QhqXUdO8w@mail.gmail.com>

Hello,

After a very good advice from here [1] I am learning about
experimental qRT-PCR design and I found Hellemans et al., 2007 [2], as
suggested by Jo, and Rieu and Powers 2009 [3]. So, I made a
experimental design for me [4].

However, I am not sure what software I could use to do the analysis
afterwards. There are qBase+, but we don't have grant to by it. So, we
are try a workaround in R, that is opensource.

Have you any suggestion to me about:

A. My experimental design; http://goo.gl/68h1ul

It is correct? If not, could you suggest me?

B. How I could analyse my experimental desing? What software I could
use? There are R package for that?

I was learning about EasyqPCR package, but, may be it need IRC
(Control) in all run (plate).


1. https://groups.yahoo.com/neo/groups/qpcrlistserver/conversations/topics/11975

2. http://genomebiology.com/2007/8/2/r19

3. http://dx.doi.org/10.1105%2Ftpc.109.066001

4. http://goo.gl/68h1ul


Thank you very much!

Marcelo Luiz de Laia
Universidade Federal dos Vales do Jequitinhonha e Mucuri
www.ufvjm.edu.br
Brazil

-- 
Laia, M. L.


From dcarlson at tamu.edu  Fri May  1 17:20:09 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 1 May 2015 15:20:09 +0000
Subject: [R] Plot Title: Adjusting Position
In-Reply-To: <alpine.LNX.2.11.1505010750420.2263@localhost>
References: <alpine.LNX.2.11.1505010750420.2263@localhost>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6882F1@mb02.ads.tamu.edu>

There are half a dozen implementations of ternary plots in as many R packages so it is hard to be specific. Since you are using title(), try the "further graphical parameters from par" mentioned in the manual page such as adj=c(x, y) for position (or maybe the line= argument) and cex.main= for size.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rich Shepard
Sent: Friday, May 1, 2015 10:00 AM
To: r-help at r-project.org
Subject: [R] Plot Title: Adjusting Position

   Plots of compositional data ternary diagrams do not accept the main label
within the plot() function, but do print the label when it is specified
within the title() function. On some of these plots I need to raise the
position of the title just enough to move the text above the top row of
diagrams.

   Applying the outer=TRUE option moves the title too high; the top half of
the text is cut off from viewing. The help file, ?title, suggests that the
line option applies to sub-titles and axis labels, not the main title.
Setting character expansion to a negative value throws an error.

   How can I either move the main title sightly higher on the figure or
slightly reduce the text size so the title does not overlap part of the
ternary diagrams?

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Fri May  1 17:26:55 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 1 May 2015 15:26:55 +0000
Subject: [R] Missing axis labels
In-Reply-To: <9003CD31-0DC2-47A6-95D5-E1325CA50DC9@plessthan.com>
References: <9003CD31-0DC2-47A6-95D5-E1325CA50DC9@plessthan.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D688307@mb02.ads.tamu.edu>

I don't think you can tell in advance since the details of the plot are computed when you open the plot window and they change when you plot into the window. In principal you could estimate the size requirements for the axis labels if you know the plot window size and the character size. What gets plotted is also device dependent. For example if you open a window using x11(3, 3) (I'm on windows so I haven't tried this on OS X) and produce the plot, the last x-axis is missing just as in the pdf file. But if you drag the window to make it larger, the label will appear when the device driver redraws the plot.

There is also a third option in addition to your two to getting all of the labels:

plot(0:100, 0:100, xaxp=c(0, 100, 4))

will plot at 0, 25, 50, 75, 100 which leaves room for the last label.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Fisher Dennis
Sent: Friday, May 1, 2015 9:11 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Missing axis labels

R 3.2.0
OS X
This is a general question, not specific to OS X.  

Colleagues

Often, one or more values on an axis will be omitted, presumably in order to prevent overlap.  However, there are situations where I would like to override that omission.  Sample code:
	pdf("labels.pdf", width=3, height=3)
	plot(0:100, 0:100)
	graphics.off()
Here, 100 is omitted from the x-axis and 20, 60, and 100 from the y-axis. 

Is there is automated way to detect which values will be omitted (i.e., without seeing the graphic)?  

If so, I see two options:
	1.  change the font size
	2.  force the entry, e.g., axis(1, 100, at=100)

Dennis


Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rshepard at appl-ecosys.com  Fri May  1 17:30:50 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Fri, 1 May 2015 08:30:50 -0700 (PDT)
Subject: [R] Plot Title: Adjusting Position
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6882F1@mb02.ads.tamu.edu>
References: <alpine.LNX.2.11.1505010750420.2263@localhost>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6882F1@mb02.ads.tamu.edu>
Message-ID: <alpine.LNX.2.11.1505010828360.2263@localhost>

On Fri, 1 May 2015, David L Carlson wrote:

> There are half a dozen implementations of ternary plots in as many R
> packages so it is hard to be specific.

David,

   I'm using the compositions() package.

> Since you are using title(), try the "further graphical parameters from
> par" mentioned in the manual page such as adj=c(x, y) for position (or
> maybe the line= argument) and cex.main= for size.

   Thank you. One of these parameters will do the job.

Rich


From dcarlson at tamu.edu  Fri May  1 17:54:25 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 1 May 2015 15:54:25 +0000
Subject: [R] Results Differ in Ternary Plot Matrix of Compositional
 Response Variables
In-Reply-To: <alpine.LNX.2.11.1504301355470.15872@localhost>
References: <alpine.LNX.2.11.1504301355470.15872@localhost>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D688334@mb02.ads.tamu.edu>

Add plotMissings=FALSE to the second plot and see the plot.acomp manual page description of this argument:

plot(JerrittY, pch=as.numeric(JerrittX4), col=c("black","red", "dark green",
     "dark blue","dark goldenrod","dark orange","dark grey")[JerrittX4], 
      plotMissings=FALSE)


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rich Shepard
Sent: Thursday, April 30, 2015 3:57 PM
To: r-help at r-project.org
Subject: [R] Results Differ in Ternary Plot Matrix of Compositional Response Variables

   After hours of looking for the reason why one data set plots correctly and
another one does not I am still not seeing the reason. The only differences
I see between the two data sets is the number of discrete variables (one has
6 years, the other 7 years) and one contains zeros. I wonder if the number
of discrete variables is the issue.

   I'm sure that more experienced eyes will see the reason for the different
results and will point it out to me.

   The following data and code produce a matrix of ternary plots with the
other continuous variables represented by a dot above the top point of the
triangle:

<filename = snow-regression.dat>
"Year","NO3","SO4","pH","Fi","Ga","Gr","Pr","Sh"
"2005",0.60,816,7.87,0.0556,0.5370,0.1667,0.1667,0.0741
"2006",0.40,224,7.59,0.0435,0.6739,0.0870,0.1522,0.0435
"2010",0.10,571,7.81,0.0735,0.4706,0.1029,0.1912,0.1618
"2011",0.52,130,7.42,0.0462,0.5692,0.0769,0.2462,0.0615
"2012",0.42,363,7.79,0.0548,0.5205,0.0548,0.2466,0.1233
"2013",0.42,363,7.79,0.0484,0.5323,0.1129,0.2419,0.0645

<snow-ternary-plot.R>
# Create matrix of ternary plots of FFGs as dependent variables.
# Follows 'Analyzing Compositional Data with R' sec. 5.3; pp 122 ff
# Change stream name as necessary.
# load package from library
require(compositions)
# read in raw data
SnowRegr <- read.csv('snow-regression.dat', header=T)
# extract response variables
SnowY <- acomp(SnowRegr[,5:9])
# column headings; variables
names(SnowRegr)
# continuous explanatory co-variables
SnowCovars <- SnowRegr[,c("Year","NO3","SO4","pH")]
# first continuous co-variable
SnowX1 <- SnowCovars$NO3
# second continuous co-variable
SnowX2 <- SnowCovars$SO4
# third continuous co-variable
SnowX3 <- SnowCovars$pH
# discrete co-variable
SnowX4 <- 
factor(SnowCovars$Year,c("2005","2006","2010","2011","2012","2013"),ordered=T)
# for the discrete co-var, ANOVA not specified in unique way so contrasts must 
be specified; use the
#   treatment contrasts.
contrasts(SnowX4) <- "contr.treatment"
# save figure parameters
opar <- par(xpd=NA,no.readonly=T)
# ternary plot matrix
plot(SnowY, pch=as.numeric(SnowX4), col=c("red","dark green","dark blue","dark 
goldenrod","dark orange","dark grey")[SnowX4])
# add legend
legend(x=0.83, y=-0.165, abbreviate(levels(SnowX4), 
minlength=1),pch=as.numeric(SnowX4), col=c("red","dark green","dark blue","dark 
goldenrod","dark orange","dark grey"), ncol=2, xpd=T, bty="n", yjust=0)
# reset plot parameters
par(opar)
# unload the package
detach('package:compositions')

   This data set with eqivalent code produces plots with the other continuous
variables as bars with colors on the top points of the triangles:

<filename = jerritt-regression.dat>
"Year","NO3","SO4","pH","Fi","Ga","Gr","Pr","Sh"
"2004",1.70,2200,8.70,0.0444,0.6889,0.0222,0.2222,0.0222
"2005",2.50,5000,8.43,0.0182,0.5636,0.0909,0.3091,0.0182
"2006",1.80,6670,8.57,0.0370,0.6173,0.0741,0.2469,0.0247
"2010",0.54,4000,8.00,0.0870,0.6087,0.0870,0.2174,0.0000
"2011",2.70,4300,8.47,0.0449,0.5256,0.0897,0.2949,0.0449
"2012",0.76,595,8.21,0.0000,0.4231,0.0769,0.5000,0.0000
"2013",0.76,595,8.21,0.0000,0.4545,0.0455,0.4545,0.0455

<jerritt-ternary-plot.R>
# Create matrix of ternary plots of FFGs as dependent variables.
# Follows 'Analyzing Compositional Data with R' sec. 5.3; pp 122 ff
# Change stream name as necessary.
# load package from library
require(compositions)
# read in raw data
JerrittRegr <- read.csv('jerritt-regression.dat', header=T)
# extract response variables
JerrittY <- acomp(JerrittRegr[,5:9])
# column headings; variables
names(JerrittRegr)
# continuous explanatory co-variables
JerrittCovars <- JerrittRegr[,c("Year","NO3","SO4","pH")]
# first continuous co-variable
JerrittX1 <- JerrittCovars$NO3
# second continuous co-variable
JerrittX2 <- JerrittCovars$SO4
# third continuous co-variable
JerrittX3 <- JerrittCovars$pH
# discrete co-variable
JerrittX4 <- 
factor(JerrittCovars$Year,c("2004","2005","2006","2010","2011","2012","2013"),ordered=T)
# for the discrete co-var, ANOVA not specified in unique way so contrasts must 
be specified; use the
#   treatment contrasts.
contrasts(JerrittX4) <- "contr.treatment"
# save figure parameters
opar <- par(xpd=NA,no.readonly=T)
# ternary plot matrix
plot(JerrittY, pch=as.numeric(JerrittX4), col=c("black","red","dark 
green","dark blue","dark goldenrod","dark orange","dark grey")[JerrittX4])
# add legend
legend(x=0.83, y=-0.165, abbreviate(levels(JerrittX4), 
minlength=1),pch=as.numeric(JerrittX4), col=c("black","red","dark green","dark 
blue","dark goldenrod","dark orange","dark grey"), ncol=2, xpd=T, bty="n", 
yjust=0)
# reset plot parameters
par(opar)
# unload the package
detach('package:compositions')

Thanks in advance,

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Fri May  1 20:06:22 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 1 May 2015 14:06:22 -0400
Subject: [R] Graphs for scientific publication ?
In-Reply-To: <CACyTWRZJ83Z4zix2DPUOdHNFMVf7sNRNYeGakRnqjXHgqgbbMQ@mail.gmail.com>
References: <CACyTWRZJ83Z4zix2DPUOdHNFMVf7sNRNYeGakRnqjXHgqgbbMQ@mail.gmail.com>
Message-ID: <CA+vqiLEDdNstQy6N_gg5MFsha-egqJkf+N6Z0uj2T+cqgjkANw@mail.gmail.com>

On Thu, Apr 30, 2015 at 8:05 AM, Jeremy Clark <jeremyclarkbio at gmail.com> wrote:
> Dear All,
>
> First of all, many thanks to all R contributors for a fantastic
> program, and especially to Hadley Wickham for creating ggplot2. The
> following is intended to be a warning that, if the apparently
> superficial problems described are not sorted out, R could well find
> itself being superceded.

In my opinion that can and should happen, but my prediction is that R
has such a big lead in terms of available functionality and packages
that no one will catch up for at least a decade.

The reason is that a new user wants to draw a
> graph, and perhaps publish in a scientific journal a graph created
> using R, well before wanting to do a complex regression (and the
> latter is relatively easy). So here goes:
>
> 1) The saga of the straight line. I implemented a geom_abline - it
> looked superb. Unfortunately I had to disable clip to allow text - now
> my abline looked ridiculous. My search found plotrix: ablineclip -
> fantastic I thought - but it applies to plot and not geom_plot. I
> switched to geom_segment - the rendering looked trash. I switched to
> geom_smooth - should work but as I don't know the x values beforehand
> I'll have to clip a new dataframe - it that a hassle ? - Yes it is !

As others have mentioned we can probably help you if you give us a
reproducible example and a clear description of what you are trying to
accomplish. Absent that this just sounds like complaining for the sake
of it.

>
>             So my general question is - why isn't ggplot2 already part
> of R base

I think packages are added to the base distribution relatively
infrequently these days. Is

install.packages("ggplot2")

really an issue?

- or at least if someone is to create useful packages for
> plot - perhaps a subtle hint could be made that they should also apply
> to ggplot2 (and perhaps to lattice ??

I'm not understanding what you are trying to say here.

- also personally I would scrap
> qplot as an unnecessary distraction which is not easier to implement
> than ggplot).

ggplot2 is in maintenance mode, so it is unlikely that major changes
like that will be introduced.

 In general duplication of packages for plot and ggplot
> doesn't seem like a good idea.

I'm not sure what kind of duplication you are referring to here,
though in general I also wish there was less duplicated functionality
spread across various R packages.

>
>
> 2) The saga of the italic letter. I found, to my dismay, that to
> insert an italic letter into my plot I had to learn a whole new
> language called plotmath - which wouldn't accept normal R coding, and
> didn't even have normal control functions such as /n for a new line.
> This is ridiculous (and I'm not sure how plotmath managed to get into
> R base).

library(ggplot2)

d1 <- data.frame(x = 1, y = 1, t = "some text")
d2 <- d1
d2$x <- 2

ggplot(d1, aes(x = x, y = y, label = t)) +
  geom_text(hjust = 0, size = 10) +
  geom_text(data=d2, fontface="italic", hjust=1, size = 10)

Works for me.

>
>             So my question is, when is plotmath going to have a
> complete overhaul to allow eg. "," instead of, or as well as, ~,~, and
> normal control functions such as \n ?

Probably never (though you could do it yourself if you think it is
worth spending the time to improve it).

>
> 3) A related question to (2) is: where is geom_textbox ?

I don't think there is one. You could make one following the
documentation at
https://github.com/hadley/ggplot2/wiki/Creating-a-new-geom

>
> 4) Where are examples with scientific graph defaults ?  (meaning a
> two-axis graph which is publishable - I will post my own after this is
> published in a years time, but as suggested above, while the graph
> looks good the implementation of this is not pretty).

Lot's of people publish ggplot2 graphs, standards differ from field to
field and from journal to journal.
http://scholar.google.com/scholar?cites=14238124760782644329&as_sdt=40000005&sciodt=0,22&hl=en
will give you some examples. Beyond that I think you'll have to be
more specific about what exactly you want the graphs to look like.

>
> Having said that - good luck with implementation - and many thanks for
> all your hard work !
>
> Yours sincerely,
>
> Abiologist
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From edd at debian.org  Fri May  1 15:47:40 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 1 May 2015 13:47:40 +0000
Subject: [R] QMLE of MGARCH
References: <CAGx7CyPBUwFdhE=pHNTQfaeqRD=WjadPD46P3tPp2AbnKxvOvA@mail.gmail.com>
Message-ID: <loom.20150501T154649-407@post.gmane.org>

Masher Masher <masher6666 <at> gmail.com> writes:
> So my question is: is the function garchFit the best one to estimate
> parameters using the QML or should I better use other packages for
> convenience.

You may want to look at the rmgarch package.

Dirk


From rshepard at appl-ecosys.com  Fri May  1 20:32:32 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Fri, 1 May 2015 11:32:32 -0700 (PDT)
Subject: [R] Results Differ in Ternary Plot Matrix of Compositional
 Response Variables
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D688334@mb02.ads.tamu.edu>
References: <alpine.LNX.2.11.1504301355470.15872@localhost>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D688334@mb02.ads.tamu.edu>
Message-ID: <alpine.LNX.2.11.1505011127310.2263@localhost>

On Fri, 1 May 2015, David L Carlson wrote:

> Add plotMissings=FALSE to the second plot and see the plot.acomp manual
> page description of this argument:
>
> plot(JerrittY, pch=as.numeric(JerrittX4), col=c("black","red", "dark green",
>     "dark blue","dark goldenrod","dark orange","dark grey")[JerrittX4],
>      plotMissings=FALSE)

David,

   Mea culpa! I overlooked the man page for plot.acomp.

   When I add plotMissings=FALSE I see no differences in the output despite
there being zeros for a comple of variables in two years.

   The horizontal bar with colors and labels on top of each ternary diagram
is what I want to eliminate and replace with the dot seen in plots with no
more than 6 rows (years) of data. There are 3 data sets with 6 rows, 1 with
7 rows (jerritt), and one with 8 rows and no missing data. The latter two
have the horizontal bars while the former three have dots.

Thanks,

Rich


From rshepard at appl-ecosys.com  Fri May  1 21:47:42 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Fri, 1 May 2015 12:47:42 -0700 (PDT)
Subject: [R] Plot Title: Adjusting Position [RESOLVED]
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6882F1@mb02.ads.tamu.edu>
References: <alpine.LNX.2.11.1505010750420.2263@localhost>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6882F1@mb02.ads.tamu.edu>
Message-ID: <alpine.LNX.2.11.1505011246280.2263@localhost>

On Fri, 1 May 2015, David L Carlson wrote:

> There are half a dozen implementations of ternary plots in as many R
> packages so it is hard to be specific. Since you are using title(), try
> the "further graphical parameters from par" mentioned in the manual page
> such as adj=c(x, y) for position (or maybe the line= argument) and
> cex.main= for size.

David,

   Now that the missing values are not plotted the default title position
is appropriate.

Thanks again for your help,

Rich


From dwinsemius at comcast.net  Fri May  1 22:31:05 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 1 May 2015 13:31:05 -0700
Subject: [R] New User Having Trouble Loading R Commander on Mac OS
	Yosemite
In-Reply-To: <BLU182-W3011AC773EECFA8697AD5E9AD60@phx.gbl>
References: <BLU182-W3011AC773EECFA8697AD5E9AD60@phx.gbl>
Message-ID: <59B42E50-65BA-42C1-BA77-717471AB4906@comcast.net>


On Apr 30, 2015, at 1:19 PM, Aaron wrote:

> I keep getting the same error message when trying to install R Commander.
> My operating system is Mac OS Yosemite 10.10
> I have installed R 3.2, Rstudio, XQuartz (X11), and tcltk-8.x.x-x11.dmg.
> But I keep getting the following error:Loading required package: splinesLoading required package: RcmdrMiscLoading required package: carError in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :   there is no package called ?SparseM?Error: package ?car? could not be loaded 		 	   		  
You should review the earlier exchanges this topic on the R-SIG-Mac mailing list. John Fox posted his advice there.

> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/New-User-Having-Trouble-Loading-R-Commander-on-Mac-OS-Yosemite-tp4706666.html
> Sent from the R help mailing list archive at Nabble.com.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri May  1 22:39:14 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 1 May 2015 13:39:14 -0700
Subject: [R] New User Having Trouble Loading R Commander on Mac OS
	Yosemite
In-Reply-To: <59B42E50-65BA-42C1-BA77-717471AB4906@comcast.net>
References: <BLU182-W3011AC773EECFA8697AD5E9AD60@phx.gbl>
	<59B42E50-65BA-42C1-BA77-717471AB4906@comcast.net>
Message-ID: <98D0BB51-7564-404B-998B-D079509396D1@comcast.net>


On May 1, 2015, at 1:31 PM, David Winsemius wrote:

> 
> On Apr 30, 2015, at 1:19 PM, Aaron wrote:
> 
>> I keep getting the same error message when trying to install R Commander.
>> My operating system is Mac OS Yosemite 10.10
>> I have installed R 3.2, Rstudio, XQuartz (X11), and tcltk-8.x.x-x11.dmg.
>> But I keep getting the following error:Loading required package: splinesLoading required package: RcmdrMiscLoading required package: carError in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :   there is no package called ?SparseM?Error: package ?car? could not be loaded 		 	   		  
> You should review the earlier exchanges this topic on the R-SIG-Mac mailing list. John Fox posted his advice there.

And you should, of course, install SparseM since that was identified  in the error message.

-- 
David. 
> 
>> 
>> 
>> 
>> --
>> View this message in context: http://r.789695.n4.nabble.com/New-User-Having-Trouble-Loading-R-Commander-on-Mac-OS-Yosemite-tp4706666.html
>> Sent from the R help mailing list archive at Nabble.com.
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Fri May  1 22:57:09 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 2 May 2015 06:57:09 +1000
Subject: [R] Missing axis labels
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D688307@mb02.ads.tamu.edu>
References: <9003CD31-0DC2-47A6-95D5-E1325CA50DC9@plessthan.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D688307@mb02.ads.tamu.edu>
Message-ID: <CA+8X3fXi-Bo97tWRe7b6f=pNCutk3jaGGvwLVXYbM3WWqjLHtg@mail.gmail.com>

Hi Dennis,
Perhaps you were looking for "staxlab" in the plotrix package.

Jim


On Sat, May 2, 2015 at 1:26 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> I don't think you can tell in advance since the details of the plot are computed when you open the plot window and they change when you plot into the window. In principal you could estimate the size requirements for the axis labels if you know the plot window size and the character size. What gets plotted is also device dependent. For example if you open a window using x11(3, 3) (I'm on windows so I haven't tried this on OS X) and produce the plot, the last x-axis is missing just as in the pdf file. But if you drag the window to make it larger, the label will appear when the device driver redraws the plot.
>
> There is also a third option in addition to your two to getting all of the labels:
>
> plot(0:100, 0:100, xaxp=c(0, 100, 4))
>
> will plot at 0, 25, 50, 75, 100 which leaves room for the last label.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Fisher Dennis
> Sent: Friday, May 1, 2015 9:11 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Missing axis labels
>
> R 3.2.0
> OS X
> This is a general question, not specific to OS X.
>
> Colleagues
>
> Often, one or more values on an axis will be omitted, presumably in order to prevent overlap.  However, there are situations where I would like to override that omission.  Sample code:
>         pdf("labels.pdf", width=3, height=3)
>         plot(0:100, 0:100)
>         graphics.off()
> Here, 100 is omitted from the x-axis and 20, 60, and 100 from the y-axis.
>
> Is there is automated way to detect which values will be omitted (i.e., without seeing the graphic)?
>
> If so, I see two options:
>         1.  change the font size
>         2.  force the entry, e.g., axis(1, 100, at=100)
>
> Dennis
>
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone: 1-866-PLessThan (1-866-753-7784)
> Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Fri May  1 23:01:01 2015
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 1 May 2015 17:01:01 -0400
Subject: [R] New User Having Trouble Loading R Commander on Mac
	OS	Yosemite
In-Reply-To: <59B42E50-65BA-42C1-BA77-717471AB4906@comcast.net>
References: <BLU182-W3011AC773EECFA8697AD5E9AD60@phx.gbl>
	<59B42E50-65BA-42C1-BA77-717471AB4906@comcast.net>
Message-ID: <002201d08451$eea67c50$cbf374f0$@mcmaster.ca>

Dear David and Aaron,

I apologize for not noticing Aaron's April 30 message. Please see below:

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David
> Winsemius
> Sent: Friday, May 01, 2015 4:31 PM
> To: Aaron
> Cc: r-help at r-project.org
> Subject: Re: [R] New User Having Trouble Loading R Commander on Mac OS
> Yosemite
> 
> 
> On Apr 30, 2015, at 1:19 PM, Aaron wrote:
> 
> > I keep getting the same error message when trying to install R
> Commander.
> > My operating system is Mac OS Yosemite 10.10
> > I have installed R 3.2, Rstudio, XQuartz (X11), and tcltk-8.x.x-
> x11.dmg.

Aaron didn't have to install Tcl/Tk since this is now included in the R
installation. As well, although R will run under RStudio, I suggest that you
use it instead from R.app or from R running in a terminal window. Please see
the Rcmdr Mac OS X installation notes at
<http://socserv.socsci.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html>
for more details.

> > But I keep getting the following error:Loading required package:
> splinesLoading required package: RcmdrMiscLoading required package:
> carError in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck =
> vI[[i]]) :   there is no package called 'SparseM'Error: package 'car'
> could not be loaded

Apparently the SparseM package wasn't installed when Aaron installed the
Rcmdr package. I'm not sure why that happened, but I've just installed the
Rcmdr package into a clean installation of R 3.2.0 under Mac OS X Yosemite
and experienced no problems -- perhaps the SparseM package was missing from
the CRAN mirror that Aaron used. Try installing the package directly via
install.packages("SparseM") and see whether that clears up the problem. If
the package is unavailable, try a different CRAN mirror.

> You should review the earlier exchanges this topic on the R-SIG-Mac
> mailing list. John Fox posted his advice there.

Most Mac OS X Rcmdr problem relate to failing to install XQuartz but that
doesn't seem to be the case here. There are some other troubleshooting tips
in the installation notes mentioned above.

I hope this helps,
 John

-----------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/


> 
> >
> >
> >
> > --
> > View this message in context: http://r.789695.n4.nabble.com/New-User-
> Having-Trouble-Loading-R-Commander-on-Mac-OS-Yosemite-tp4706666.html
> > Sent from the R help mailing list archive at Nabble.com.
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


---
This email has been checked for viruses by Avast antivirus software.
http://www.avast.com


From fisher at plessthan.com  Fri May  1 23:03:47 2015
From: fisher at plessthan.com (Fisher Dennis)
Date: Fri, 1 May 2015 14:03:47 -0700
Subject: [R] Missing axis labels
In-Reply-To: <CA+8X3fXi-Bo97tWRe7b6f=pNCutk3jaGGvwLVXYbM3WWqjLHtg@mail.gmail.com>
References: <9003CD31-0DC2-47A6-95D5-E1325CA50DC9@plessthan.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D688307@mb02.ads.tamu.edu>
	<CA+8X3fXi-Bo97tWRe7b6f=pNCutk3jaGGvwLVXYbM3WWqjLHtg@mail.gmail.com>
Message-ID: <0436EC84-2081-4714-A78F-C5876708A94B@plessthan.com>

Jim

Thanks for this suggestion? it looks like that accomplish my goal, although I am frustrated that there does not appear to be a simlpe answer to my initial question, i.e., is there a way to tell whether the usual manner of created labels prints all entries.

Dennis


Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com



> On May 1, 2015, at 1:57 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi Dennis,
> Perhaps you were looking for "staxlab" in the plotrix package.
> 
> Jim
> 
> 
> On Sat, May 2, 2015 at 1:26 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>> I don't think you can tell in advance since the details of the plot are computed when you open the plot window and they change when you plot into the window. In principal you could estimate the size requirements for the axis labels if you know the plot window size and the character size. What gets plotted is also device dependent. For example if you open a window using x11(3, 3) (I'm on windows so I haven't tried this on OS X) and produce the plot, the last x-axis is missing just as in the pdf file. But if you drag the window to make it larger, the label will appear when the device driver redraws the plot.
>> 
>> There is also a third option in addition to your two to getting all of the labels:
>> 
>> plot(0:100, 0:100, xaxp=c(0, 100, 4))
>> 
>> will plot at 0, 25, 50, 75, 100 which leaves room for the last label.
>> 
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>> 
>> 
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Fisher Dennis
>> Sent: Friday, May 1, 2015 9:11 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] Missing axis labels
>> 
>> R 3.2.0
>> OS X
>> This is a general question, not specific to OS X.
>> 
>> Colleagues
>> 
>> Often, one or more values on an axis will be omitted, presumably in order to prevent overlap.  However, there are situations where I would like to override that omission.  Sample code:
>>        pdf("labels.pdf", width=3, height=3)
>>        plot(0:100, 0:100)
>>        graphics.off()
>> Here, 100 is omitted from the x-axis and 20, 60, and 100 from the y-axis.
>> 
>> Is there is automated way to detect which values will be omitted (i.e., without seeing the graphic)?
>> 
>> If so, I see two options:
>>        1.  change the font size
>>        2.  force the entry, e.g., axis(1, 100, at=100)
>> 
>> Dennis
>> 
>> 
>> Dennis Fisher MD
>> P < (The "P Less Than" Company)
>> Phone: 1-866-PLessThan (1-866-753-7784)
>> Fax: 1-866-PLessThan (1-866-753-7784)
>> www.PLessThan.com
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From michael.eisenring at agroscope.admin.ch  Sat May  2 00:18:44 2015
From: michael.eisenring at agroscope.admin.ch (michael.eisenring at agroscope.admin.ch)
Date: Fri, 1 May 2015 22:18:44 +0000
Subject: [R] Black outlines for errorbar using geom_line
Message-ID: <6D5C009FB51EBD41BEE57F4C002350FD01F0FA@SB00112A.adb.intra.admin.ch>

Hi there,
 I would like to create black outlines around my errorbars in order to get especially the white errorbar better visible.
Is that even possible with ggplot2 and if yes how?
I would be very grateful if anyone could help me. I added my code and a dput() of my data,

Thank you very much,
Michael


#my code:--------------------------------------------------


#load packages
library(compute.es<http://compute.es/>);library(ggplot2);library(multcomp);library(pastecs);library(WRS)
library(pastecs);library(Hmisc)
library (car)


# Comput CI manually and produce error plots

#CI manually computed with formula summarySE
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
  library(plyr)

  # New version of length which can handle NA's: if na.rm==T, don't count them
  length2 <- function (x, na.rm=FALSE) {
    if (na.rm) sum(!is.na<http://is.na/>(x))
    else       length(x)
  }

  # This does the summary. For each group's data frame, return a vector with
  # N, mean, and sd
  datac <- ddply(data, groupvars, .drop=.drop,
                 .fun = function(xx, col) {
                   c(N    = length2(xx[[col]], na.rm=na.rm),
                     mean = mean   (xx[[col]], na.rm=na.rm),
                     sd   = sd     (xx[[col]], na.rm=na.rm)
                   )
                 },
                 measurevar
  )

  # Rename the "mean" column
  datac <- rename(datac, c("mean" = measurevar))

  datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

  # Confidence interval multiplier for standard error
  # Calculate t-statistic for confidence interval:
  # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
  ciMult <- qt(conf.interval/2 + .5, datac$N-1)
  datac$ci <- datac$se * ciMult

  return(datac)
}

#summarySE provides the standard deviation, standard error of the mean, and a (default 95%) confidence interval
CI <- summarySE(data, measurevar="cor_average", groupvars=c("damage","leaf"))
CI


#plotting in ggplot
# To prevent that errorbars overlap use position_dodge to move them horizontally
pd <- position_dodge(0.4) # move them .05 to the left and right
#Create errorbar using 95% CI
ggplot(CI, aes(x=leaf, y=cor_average, colour=damage)) +
  geom_errorbar(aes(ymin=cor_average-ci, ymax=cor_average+ci), width=.3, size=1,position=pd) +
  geom_line(position=pd) +
  scale_colour_manual(values=c("white","black","gray65"))+
  geom_point(position=pd,size=3)



#my data set: ---------------------------------------------------------------------------------------------------------------

> dput(data<-read.csv("Exp1.csv",sep=",",header=T))
structure(list(damage = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L), .Label = c("C", "L1", "L4"), class = "factor"), leaf = structure(c(1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L), .Label = c("Cot", "L1", "L2",
"L3", "L4", "L5", "L6", "L7", "L8"), class = "factor"), cor_average = c(587.6666667,
595.3333333, 858, 516, 542.6666667, 455, 530.3333333, 546.6666667,
215.1111111, 666.6666667, 680, 2361.666667, 2880, 2760, 2210,
2142, 2508, 1551.666667, 1856, 498.7777778, 2634.666667, 2380,
2338.333333, 2006.666667, 3296.666667, 2945.333333, 2720.666667,
2436, 2033, 2579.333333, 455.1111111, 2123.333333, 2033.333333,
3660.333333, 2765, 3752, 3150, 3747.333333, 3572, 3536, 3593.333333,
1178.777778, 3476, 3291.666667, 3927.333333, 3705, 4636.666667,
3720, 4080, 4828, 5280, 4495, 711.1111111, 4340, 4173, 4785,
5070, 6324, 3360, 5150, 6262.666667, 5624, 5595.333333, 1626.777778,
5869.333333, 5080, 6888, 7561.333333, 7280, 3610, 5926.666667,
6600, 6375.333333, 7831.666667, 4181.777778, 8023, 6077.333333,
14640, 13501.33333, 15383.33333, 6193, 10030, 8756.333333, 10291.66667,
16450, 33611.11111, 15138.66667, 10948, 6600, 7785, 10944, 11712,
17490, 14370, 10353, 8814.333333, 742.5, 605, 520, 728.5, 418,
650, 468.6666667, 506.6666667, 512, 518, 646, 1974, 2408, 2494,
1931.666667, 1243.666667, 2024, 1805, 2166.666667, 2408, 1613.333333,
2573, 2102.333333, 2470, 2701, 2566.666667, 2960, 2300, 2579.666667,
1785, 2223.333333, 2046, 3336.666667, 3737, 4529.666667, 3718,
3192, 4110, 3198, 4116, 2645, 3288, 3315, 4850, 4293.333333,
4972, 4641, 4370, 4933.333333, 3853.333333, 4658, 3720, 4340,
3882.666667, 5577, 7800, 7646.333333, 4200, 5418, 5324.666667,
4564, 5085, 5060, 7093.333333, 6923.333333, 7700, 14575, 14725,
6650, 12154.66667, 8254.666667, 5800, 7663.333333, 6640, 12661.66667,
12982.33333, 14025, 17148, 21960, 10418.33333, 25850, 12636,
8470, 17152, 20603.33333, 22078, 20086.66667, 24219, 18544, 13475,
23389, 22374, 10246.5, 13695, 12220, 487.5, 645, 623.3333333,
493.3333333, 555, 532, 658.6666667, 522, 492, 528, 604.3333333,
528, 1998.333333, 2016.666667, 1971.666667, 2376, 1780, 1729,
2026.666667, 2186.666667, 1860, 2112, 2300, 2054.666667, 2520,
2532.333333, 2181.666667, 2960.333333, 2220, 2472, 2555, 1392,
2826.666667, 1457, 2600, 2026.666667, 3720, 4275, 4389, 3014,
2875, 3920, 4094, 2712, 3853.333333, 2926, 4766.666667, 3948.333333,
5625, 6303.333333, 4783.666667, 4770, 3530.333333, 4840, 3760,
4656.666667, 3600, 3923.333333, 5458.333333, 3600, 5115, 5950,
5662.666667, 6075, 4307.333333, 5960, 5425, 4978, 6292, 4477.333333,
5568, 5364.333333, 8824.666667, 8520, 8000, 11293.33333, 5133.333333,
7973.333333, 5786.666667, 6006, 6766.666667, 7000, 7566, 15555,
14299.33333, 19716.66667, 24408, 11349, 17400, 13362, 19525,
23902, 15364, 16875, 10450, 17605, 22950, 19920, 12412, 21187.33333,
20425, 20710, 10280.5, 11063, 21498.66667, 22333.33333)), .Names = c("damage",
"leaf", "cor_average"), class = "data.frame", row.names = c(NA,
-297L))


From fazal.hadi at curie.fr  Fri May  1 22:05:22 2015
From: fazal.hadi at curie.fr (Hadi Fazal)
Date: Fri, 1 May 2015 20:05:22 +0000
Subject: [R] Help with making Loop
Message-ID: <8A846288B89DB64B9455DE44DD1C729523CF20@mbxparis01.recherche.curie.fr>

Hi everyone, 
I am a real beginner to R and have probably a very naive issue. I've a small data frame with three columns: Unique Sample ID, Gene 1 and Gene 2 (the columns on Gene1 and Gene2 are empty). I have two separate tables for the genes which contain the Unique Subject ID in one column and information on whether the gene is mutated or not in that particular subject (M, N/M) in another column called (Condition). I want to make a loop which can read the Unique Subject ID from my data frame, then look up for the same ID in the two tables and depending on whether the gene is mutated (M)/not mutated (N/M), inserts Yes like emoticon / No (N) in the appropriate gene column (Gene1/Gene2) for each Subject ID.
If anyone can help, I would really appreciate
Thanks in advance

Fazal,
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Gene2.png
Type: image/png
Size: 6717 bytes
Desc: Gene2.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150501/dc7de010/attachment.png>

From jrkrideau at inbox.com  Sat May  2 04:24:03 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 1 May 2015 18:24:03 -0800
Subject: [R] Help with making Loop
In-Reply-To: <8A846288B89DB64B9455DE44DD1C729523CF20@mbxparis01.recherche.curie.fr>
Message-ID: <25322E60AFA.000011EAjrkrideau@inbox.com>

Hi Fazal,

In order to help you we probably need some sample data.  Any code you have been trying is also probably useful

The png is helpful but it is much better to supply the actual data or a good sample of it).  

The best way to supply data to R-help is to use the dput() function.  See ?dput() for some basic information on how to use it.

In very simple terms, if you have a data set called mydata do

dput(mydata)

copy the output and paste into your e-mail. 
Done.  Fini!
This provides the R-help readers with an exact copy of your data. 

For general information about how to ask questions in R-help see http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

welcome to R-help

John Kane
Kingston ON Canada


> -----Original Message-----
> From: fazal.hadi at curie.fr
> Sent: Fri, 1 May 2015 20:05:22 +0000
> To: r-help at r-project.org
> Subject: [R] Help with making Loop
> 
> Hi everyone,
> I am a real beginner to R and have probably a very naive issue. I've a
> small data frame with three columns: Unique Sample ID, Gene 1 and Gene 2
> (the columns on Gene1 and Gene2 are empty). I have two separate tables
> for the genes which contain the Unique Subject ID in one column and
> information on whether the gene is mutated or not in that particular
> subject (M, N/M) in another column called (Condition). I want to make a
> loop which can read the Unique Subject ID from my data frame, then look
> up for the same ID in the two tables and depending on whether the gene is
> mutated (M)/not mutated (N/M), inserts Yes like emoticon / No (N) in the
> appropriate gene column (Gene1/Gene2) for each Subject ID.
> If anyone can help, I would really appreciate
> Thanks in advance
> 
> Fazal,
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From Pradip.Muhuri at samhsa.hhs.gov  Sat May  2 06:13:05 2015
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Sat, 2 May 2015 04:13:05 +0000
Subject: [R] R Error: wrong result size (...),
 expected ... or 1 (minimal example provided)
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C43912E77@PL-EMSMB20.ees.hhs.gov>

Hello,

I am reposting my question with a reproducible example/minimal dataset (6 rows) this time.

I have written a user-defined function (myFunc below) with ten arguments. When calling the function, I get the following message: ?Error: wrong result size (0), expected 2 or 1?.
I am not getting the desired output dataset that will have 2 rows. How would I resolve the issue?   Any hints would be appreciated.


These results are from the following code chunk  outside myFunc:

addmargins(table(xanloid_set$cohort_type))



NMPR_Cohort  OID_Cohort       Other         Sum
          2           1           3           6

.

Thanks,

Pradip Muhuri





# myFunc_rev.R
setwd ("H:/R/cis_data")
library(dplyr)
rm(list = ls())
# data object - description
temp <- "id  intdate anldate oiddate herdate cohort_type
1     2004-11-04 2002-07-18 2001-07-07 2003-11-03  NMPR_Cohort
2     2004-10-24         NA 2002-10-13 NA          OID_Cohort
3     2004-10-10         NA         NA NA          Other
4     2004-09-01 1999-08-10         NA 2002-11-04  NMPR_Cohort
5     2004-09-04 1997-10-05         NA NA          Other
6     2004-10-25         NA         NA 2011-11-04  Other"
# read the data object
xanloid_set <- read.table(textConnection(temp),
                           colClasses=c("character", "Date", "Date", "Date", "Date", "character"),
                           header=TRUE, as.is=TRUE
)
# print the data object
xanloid_set
# Define user-defined function
myFunc <- function (newdata,
                    oridata,
                    cohort,
                    value,
                    xdate_to_int_time,
                    xflag,
                    idate,
                    xdate,
                    xdate_to_int_time_cat,
                    year) {

                    newdata  <-    filter (oridata, cohort== value ) %>%
                                   mutate(xdate_to_int_time = ifelse(xflag==1, (idate-xdate)/365.25, NA),
                                   xdate_to_int_time_cat = cut(xdate_to_int_time, breaks=c(0,1,2,3,4,5,6,7),
                                                                 include.lowest=TRUE, stringsAsFactors = FALSE) )
                    addmargins(with(newdata, table(year, xdate_to_int_time_cat, na.rm=TRUE)))
                                            }
# invoke user defined function
myFunc (  newdata=nmpr_nmproid,
        oridata=xanloid_set,
        cohort=xanloid_set$cohort_type,
        value= "NMPR_Cohort",
        xdate_to_int_time=anl_to_int_time,
        xflag=xanloid_set$anlflag,
        idate=xanloid_set$intdate,
        xdate=xanloid_set$anldate,
        xdate_to_int_time_cat=xanloid_set$anl_to_int_time_cat,
        year=xanloid_set$xyear
        )
# tabulate cohort_type
  addmargins(table(xanloid_set$cohort_type))



	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Sat May  2 06:46:26 2015
From: hannah.hlx at gmail.com (li li)
Date: Sat, 2 May 2015 00:46:26 -0400
Subject: [R] Random effect in ancova model
Message-ID: <CAHLnndZ4doF+DUt87azNwqCNEe9-fz8HGRi23kekjx+DWuajmQ@mail.gmail.com>

Hi all,
  I have the following data and would like to consider the following model:
  value = type + batch (type) + beta1* month +beta2*type*month+ error
Here type is fixed effect and batch is a random effect neste within type,
and month is continuous.
Since there is a random effect in this model. I am not too sure about the
right syntax in R.
Can anyone give some suggestions?
  Thank you.
    Hanna




 > mydata
      value type  batch month
 [1,]   0.2    1 178380     0
 [2,]   0.3    1 178380     3
 [3,]   0.3    1 178380     6
 [4,]   0.3    1 178380     9
 [5,]   0.3    1 178380    12
 [6,]   0.3    1 178380    15
 [7,]   0.4    1 178380    18
 [8,]   0.5    1 178380    24
 [9,]   0.2    1 189617     0
[10,]   0.3    1 189617     3
[11,]   0.4    1 189617     6
[12,]   0.4    1 189617     9
[13,]   0.4    1 189617    12
[14,]   0.4    1 189617    15
[15,]   0.4    1 189617    18
[16,]   0.4    1 189617    24
[17,]   0.2    1 197367     0
[18,]   0.3    1 197367     3
[19,]   0.3    1 197367     6
[20,]   0.4    1 197367     9
[21,]   0.4    1 197367    12
[22,]   0.4    1 197367    15
[23,]   0.4    1 197367    18
[24,]   0.4    1 197367    24
[25,]   0.4    2 286571     0
[26,]   0.4    2 286571     3
[27,]   0.3    2 286571     6
[28,]   0.4    2 286571     9
[29,]   0.4    2 286571    12
[30,]    NA    2 286571    15
[31,]   0.4    2 297299     0
[32,]   0.4    2 297299     3
[33,]   0.4    2 297299     6
[34,]   0.4    2 297299     9
[35,]   0.4    2 297299    12
[36,]    NA    2 297299    15

	[[alternative HTML version deleted]]


From andre.rafael.roldao at gmail.com  Sat May  2 04:49:35 2015
From: andre.rafael.roldao at gmail.com (Andre Roldao)
Date: Sat, 2 May 2015 03:49:35 +0100
Subject: [R] Plotting Confidence Intervals
Message-ID: <CAHP5r1q2CoxKcGiTUO+bGGsnGpX8wOdQ-yseiE5wVuvDbmApAg@mail.gmail.com>

Hi Guys,

It's the first time i use R-Help and i hope you can help me.

How can i plot conffidence intervals? with the data bellow:

#Package Austria
library(car)
#head(States)
States1=data.frame(States)

ines=lm(SATM ~ log2(pop) + SATV , data=States1)
summary(ines)

NJ=as.data.frame(States["NJ",c(4,2,3)]) #Identifica??o do estado NJ


p_conf<- predict(ines,interval="confidence",NJ,level=0.95)
p_conf #Intervalo de confian?a para o estado NJ e para um nivel de 95%
round(p_conf, digits=3)

p_conf1<- predict(ines,interval="confidence",NJ,level=0.99)
p_conf1 #Intervalo de confian?a para o estado NJ e para um nivel de 99%
round(p_conf, digits=3)

p_pred2<- predict(ines,interval="prediction",NJ,level=0.95)
p_pred2 #Intervalo de perdi??o para o estado NJ e para um nivel de 95%
round(p_pred2,digits=3)

p_pred3<- predict(ines,interval="prediction",NJ,level=0.99)
p_pred3 #Intervalo de perdi??o para o estado NJ e para um nivel de 99%
round(p_pred3,digits=3)

Thanks

	[[alternative HTML version deleted]]


From hosseinnezami1370 at yahoo.com  Sat May  2 09:48:49 2015
From: hosseinnezami1370 at yahoo.com (Hosesin Nezami)
Date: Sat, 2 May 2015 07:48:49 +0000 (UTC)
Subject: [R] (no subject)
In-Reply-To: <232135010.84305.1430552064381.JavaMail.yahoo@mail.yahoo.com>
References: <232135010.84305.1430552064381.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1980709332.77619.1430552929413.JavaMail.yahoo@mail.yahoo.com>


Is there a package that contains "Wald Wolfowitze runs test for two sample independent"or"two sample Runs test"?

?Thank's


???
	[[alternative HTML version deleted]]


From kehld at ktk.pte.hu  Sat May  2 10:13:41 2015
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?Kehl_D=E1niel?=)
Date: Sat, 2 May 2015 08:13:41 +0000
Subject: [R] (no subject)
In-Reply-To: <1980709332.77619.1430552929413.JavaMail.yahoo@mail.yahoo.com>
References: <232135010.84305.1430552064381.JavaMail.yahoo@mail.yahoo.com>,
	<1980709332.77619.1430552929413.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D14407ED0@EMAIL.ktkdom.pte.hu>

hi,

did you try this?
http://lmgtfy.com/?q=runs+test+in+r

best,
d
________________________________________
Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Hosesin Nezami [hosseinnezami1370 at yahoo.com]
K?ldve: 2015. m?jus 2. 9:48
To: R-help at r-project.org
T?rgy: [R] (no subject)

Is there a package that contains "Wald Wolfowitze runs test for two sample independent"or"two sample Runs test"?

 Thank's



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From kehld at ktk.pte.hu  Sat May  2 10:24:42 2015
From: kehld at ktk.pte.hu (=?iso-8859-1?Q?Kehl_D=E1niel?=)
Date: Sat, 2 May 2015 08:24:42 +0000
Subject: [R] Plotting Confidence Intervals
In-Reply-To: <CAHP5r1q2CoxKcGiTUO+bGGsnGpX8wOdQ-yseiE5wVuvDbmApAg@mail.gmail.com>
References: <CAHP5r1q2CoxKcGiTUO+bGGsnGpX8wOdQ-yseiE5wVuvDbmApAg@mail.gmail.com>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D14407EDF@EMAIL.ktkdom.pte.hu>

Hi Andre,

I think you'll have to give some more information about what you want to see on your plot. The 4 intervals with labels? A bar with an interval maybe? Four bars with the intervals? Only two showing differences between conf and pred intervals?

Also you do miss a 1 here I guess:

p_conf1<- predict(ines,interval="confidence",NJ,level=0.99)
p_conf1 #Intervalo de confian?a para o estado NJ e para um nivel de 99%
round(p_conf, digits=3)

last line should read p_conf1 here?

Best,
d
________________________________________
Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Andre Roldao [andre.rafael.roldao at gmail.com]
K?ldve: 2015. m?jus 2. 4:49
To: r-help at r-project.org
T?rgy: [R] Plotting Confidence Intervals

Hi Guys,

It's the first time i use R-Help and i hope you can help me.

How can i plot conffidence intervals? with the data bellow:

#Package Austria
library(car)
#head(States)
States1=data.frame(States)

ines=lm(SATM ~ log2(pop) + SATV , data=States1)
summary(ines)

NJ=as.data.frame(States["NJ",c(4,2,3)]) #Identifica??o do estado NJ


p_conf<- predict(ines,interval="confidence",NJ,level=0.95)
p_conf #Intervalo de confian?a para o estado NJ e para um nivel de 95%
round(p_conf, digits=3)

p_conf1<- predict(ines,interval="confidence",NJ,level=0.99)
p_conf1 #Intervalo de confian?a para o estado NJ e para um nivel de 99%
round(p_conf, digits=3)

p_pred2<- predict(ines,interval="prediction",NJ,level=0.95)
p_pred2 #Intervalo de perdi??o para o estado NJ e para um nivel de 95%
round(p_pred2,digits=3)

p_pred3<- predict(ines,interval="prediction",NJ,level=0.99)
p_pred3 #Intervalo de perdi??o para o estado NJ e para um nivel de 99%
round(p_pred3,digits=3)

Thanks

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ghada.f.mm at gmail.com  Sat May  2 11:03:27 2015
From: ghada.f.mm at gmail.com (Ghada Almousa)
Date: Sat, 2 May 2015 12:03:27 +0300
Subject: [R] Problem in r help me
In-Reply-To: <CADG8gktu_zJ8Ex0Sx1yo=wYd6dV=f_ZTXrQ8BWcF+OediaYf-g@mail.gmail.com>
References: <CADG8gktu_zJ8Ex0Sx1yo=wYd6dV=f_ZTXrQ8BWcF+OediaYf-g@mail.gmail.com>
Message-ID: <CADG8gktkT7DTzjVr6f957Fcg-=9-4rhv=fFhajvz+pFoi+oFgQ@mail.gmail.com>

> hello dears
>
> I have Search to compare the results between the three types of cluster
> k-maen ,Em and  Hierarchal clusters
> How i figured the number of iterations , the time required to build each
> Cluster ,accuracy  and sum square error SSE for each cluster in the R
> programming
>

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Sat May  2 14:31:58 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sat, 02 May 2015 13:31:58 +0100
Subject: [R] Help with making Loop
In-Reply-To: <8A846288B89DB64B9455DE44DD1C729523CF20@mbxparis01.recherche.curie.fr>
References: <8A846288B89DB64B9455DE44DD1C729523CF20@mbxparis01.recherche.curie.fr>
Message-ID: <5544C3BE.1040803@dewey.myzen.co.uk>

Dear Fazal
I think part of your problem can be addressed with merge
go
?merge
at the R prompt

On 01/05/2015 21:05, Hadi Fazal wrote:
> Hi everyone,
> I am a real beginner to R and have probably a very naive issue. I've a small data frame with three columns: Unique Sample ID, Gene 1 and Gene 2 (the columns on Gene1 and Gene2 are empty). I have two separate tables for the genes which contain the Unique Subject ID in one column and information on whether the gene is mutated or not in that particular subject (M, N/M) in another column called (Condition). I want to make a loop which can read the Unique Subject ID from my data frame, then look up for the same ID in the two tables and depending on whether the gene is mutated (M)/not mutated (N/M), inserts Yes like emoticon / No (N) in the appropriate gene column (Gene1/Gene2) for each Subject ID.
> If anyone can help, I would really appreciate
> Thanks in advance
>
> Fazal,
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From btyner at gmail.com  Sat May  2 17:07:20 2015
From: btyner at gmail.com (Benjamin Tyner)
Date: Sat, 02 May 2015 11:07:20 -0400
Subject: [R] non-terminal token lacking children from utils::getParseData
In-Reply-To: <54E695DB.8010906@gmail.com>
References: <54E695DB.8010906@gmail.com>
Message-ID: <5544E828.7030309@gmail.com>

Thank you Yihui for also reporting the bug here:

https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16354

and thank you Duncan for finding the issue and fixing it! I definitely
like your idea to report a summary message instead of the long text string.

Regards
Ben

> I tried to reduce the offending portion as best I could to a
> more-or-less minimal example (1136 bytes), which can be downloaded via:
>
>     wget https://www.dropbox.com/s/74rgxr5x2aalr99/badstring.R
>
> then once in R,
>
>     > b <- parse(file = "~/badstring.R", keep.source = TRUE)
>     > d <- getParseData(b, includeText = FALSE)
>     > subset(d, line1 == 2L)
>        line1 col1 line2 col2 id parent token terminal
>     10     2    5    24    1 10     21  expr    FALSE
>     > subset(d, parent == 10)
>     [1] line1    col1     line2    col2     id       parent   token   
> terminal
>     <0 rows> (or 0-length row.names)
>    
> here is my
>
>     > sessionInfo()
>     R version 3.0.2 (2013-09-25)
>     Platform: x86_64-pc-linux-gnu (64-bit)
>    
>     locale:
>      [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C             
>      [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8   
>      [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8  
>      [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                
>      [9] LC_ADDRESS=C               LC_TELEPHONE=C           
>     [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C      
>    
>     attached base packages:
>     [1] stats     graphics  grDevices utils     datasets  methods   base
>
> note that while it says R version 3.0.2 above, I have seen the same
> behaviour under version 3.1.2 as well.
>
> Regards
> Ben
>
> On 02/19/2015 06:34 PM, Duncan Murdoch wrote:
> >/ On 19/02/2015 6:31 PM, B Tyner wrote:
> />>/ Hi,
> />>/
> />>/ I have run across a source file for which the return value
> />>/ of getParseData() includes a record having FALSE for $terminal, yet it is
> />>/ not the parent of any other tokens. Before I spend time constructing a
> />>/ reproducible example, I wanted to verify that this is in fact unexpected
> />>/ behavior (under R 3.1.2)?
> />/ Before I spend the time thinking about that, I'd like to see a
> />/ reproducible example.
> />/
> />/ Duncan Murdoch
> />/
> />



From andre.rafael.roldao at gmail.com  Sat May  2 16:16:57 2015
From: andre.rafael.roldao at gmail.com (Andre Roldao)
Date: Sat, 2 May 2015 15:16:57 +0100
Subject: [R] Plotting Confidence Intervals
In-Reply-To: <33D76D77E9AC4B438DA38B348ED6890D14407EDF@EMAIL.ktkdom.pte.hu>
References: <CAHP5r1q2CoxKcGiTUO+bGGsnGpX8wOdQ-yseiE5wVuvDbmApAg@mail.gmail.com>
	<33D76D77E9AC4B438DA38B348ED6890D14407EDF@EMAIL.ktkdom.pte.hu>
Message-ID: <CAHP5r1q=yNbrGRyV4tcgnJKpgS4Fzw1pdTSf=57uJMKU9O-YqQ@mail.gmail.com>

Hi Kehl,

First i would like to thank you for the support.

to respond your question i want rather the 4 intervals with the labels, but
another one with the 4 bars with the intervals, it was fantastic!

Thank you again!

2015-05-02 9:24 GMT+01:00 Kehl D?niel <kehld at ktk.pte.hu>:

> Hi Andre,
>
> I think you'll have to give some more information about what you want to
> see on your plot. The 4 intervals with labels? A bar with an interval
> maybe? Four bars with the intervals? Only two showing differences between
> conf and pred intervals?
>
> Also you do miss a 1 here I guess:
>
> p_conf1<- predict(ines,interval="confidence",NJ,level=0.99)
> p_conf1 #Intervalo de confian?a para o estado NJ e para um nivel de 99%
> round(p_conf, digits=3)
>
> last line should read p_conf1 here?
>
> Best,
> d
> ________________________________________
> Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Andre
> Roldao [andre.rafael.roldao at gmail.com]
> K?ldve: 2015. m?jus 2. 4:49
> To: r-help at r-project.org
> T?rgy: [R] Plotting Confidence Intervals
>
> Hi Guys,
>
> It's the first time i use R-Help and i hope you can help me.
>
> How can i plot conffidence intervals? with the data bellow:
>
> #Package Austria
> library(car)
> #head(States)
> States1=data.frame(States)
>
> ines=lm(SATM ~ log2(pop) + SATV , data=States1)
> summary(ines)
>
> NJ=as.data.frame(States["NJ",c(4,2,3)]) #Identifica??o do estado NJ
>
>
> p_conf<- predict(ines,interval="confidence",NJ,level=0.95)
> p_conf #Intervalo de confian?a para o estado NJ e para um nivel de 95%
> round(p_conf, digits=3)
>
> p_conf1<- predict(ines,interval="confidence",NJ,level=0.99)
> p_conf1 #Intervalo de confian?a para o estado NJ e para um nivel de 99%
> round(p_conf, digits=3)
>
> p_pred2<- predict(ines,interval="prediction",NJ,level=0.95)
> p_pred2 #Intervalo de perdi??o para o estado NJ e para um nivel de 95%
> round(p_pred2,digits=3)
>
> p_pred3<- predict(ines,interval="prediction",NJ,level=0.99)
> p_pred3 #Intervalo de perdi??o para o estado NJ e para um nivel de 99%
> round(p_pred3,digits=3)
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sat May  2 18:41:47 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 2 May 2015 09:41:47 -0700
Subject: [R] R Error: wrong result size (...),
 expected ... or 1 (minimal example provided)
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C43912E77@PL-EMSMB20.ees.hhs.gov>
References: <E18C153EBB81024CB60FCE9B4C34D57C43912E77@PL-EMSMB20.ees.hhs.gov>
Message-ID: <CAF8bMcbXfr3tovzVZQc4gQ39ZW7AHPRRBoJTnPpG+j6UKMbT=Q@mail.gmail.com>

  # invoke user defined function
  myFunc (  newdata=nmpr_nmproid,
          oridata=xanloid_set,
          cohort=xanloid_set$cohort_type,
          value= "NMPR_Cohort",
          xdate_to_int_time=anl_to_int_time,
          xflag=xanloid_set$anlflag,
          idate=xanloid_set$intdate,
          xdate=xanloid_set$anldate,
          xdate_to_int_time_cat=xanloid_set$anl_to_int_time_cat,
          year=xanloid_set$xyear
          )

Note that some of your arguments are NULL because xanloid_set
does not contain components by the given name.  E.g., xanloid_set$anlflag
is NULL because there is no column called 'anlflag' in xanloid_set.
The NULL's will cause various problems downstream.

You can avoid this problem by using the syntax
   xanloid_set[ , "anlflag"]
which will give an error if the requested column does not exist.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, May 1, 2015 at 9:13 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <
Pradip.Muhuri at samhsa.hhs.gov> wrote:

> Hello,
>
> I am reposting my question with a reproducible example/minimal dataset (6
> rows) this time.
>
> I have written a user-defined function (myFunc below) with ten arguments.
> When calling the function, I get the following message: ?Error: wrong
> result size (0), expected 2 or 1?.
> I am not getting the desired output dataset that will have 2 rows. How
> would I resolve the issue?   Any hints would be appreciated.
>
>
> These results are from the following code chunk  outside myFunc:
>
> addmargins(table(xanloid_set$cohort_type))
>
>
>
> NMPR_Cohort  OID_Cohort       Other         Sum
>           2           1           3           6
>
> .
>
> Thanks,
>
> Pradip Muhuri
>
>
>
>
>
> # myFunc_rev.R
> setwd ("H:/R/cis_data")
> library(dplyr)
> rm(list = ls())
> # data object - description
> temp <- "id  intdate anldate oiddate herdate cohort_type
> 1     2004-11-04 2002-07-18 2001-07-07 2003-11-03  NMPR_Cohort
> 2     2004-10-24         NA 2002-10-13 NA          OID_Cohort
> 3     2004-10-10         NA         NA NA          Other
> 4     2004-09-01 1999-08-10         NA 2002-11-04  NMPR_Cohort
> 5     2004-09-04 1997-10-05         NA NA          Other
> 6     2004-10-25         NA         NA 2011-11-04  Other"
> # read the data object
> xanloid_set <- read.table(textConnection(temp),
>                            colClasses=c("character", "Date", "Date",
> "Date", "Date", "character"),
>                            header=TRUE, as.is=TRUE
> )
> # print the data object
> xanloid_set
> # Define user-defined function
> myFunc <- function (newdata,
>                     oridata,
>                     cohort,
>                     value,
>                     xdate_to_int_time,
>                     xflag,
>                     idate,
>                     xdate,
>                     xdate_to_int_time_cat,
>                     year) {
>
>                     newdata  <-    filter (oridata, cohort== value ) %>%
>                                    mutate(xdate_to_int_time =
> ifelse(xflag==1, (idate-xdate)/365.25, NA),
>                                    xdate_to_int_time_cat =
> cut(xdate_to_int_time, breaks=c(0,1,2,3,4,5,6,7),
>
>  include.lowest=TRUE, stringsAsFactors = FALSE) )
>                     addmargins(with(newdata, table(year,
> xdate_to_int_time_cat, na.rm=TRUE)))
>                                             }
> # invoke user defined function
> myFunc (  newdata=nmpr_nmproid,
>         oridata=xanloid_set,
>         cohort=xanloid_set$cohort_type,
>         value= "NMPR_Cohort",
>         xdate_to_int_time=anl_to_int_time,
>         xflag=xanloid_set$anlflag,
>         idate=xanloid_set$intdate,
>         xdate=xanloid_set$anldate,
>         xdate_to_int_time_cat=xanloid_set$anl_to_int_time_cat,
>         year=xanloid_set$xyear
>         )
> # tabulate cohort_type
>   addmargins(table(xanloid_set$cohort_type))
>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From msharp at txbiomed.org  Sun May  3 04:12:15 2015
From: msharp at txbiomed.org (Mark Sharp)
Date: Sun, 3 May 2015 02:12:15 +0000
Subject: [R] Help with making Loop
In-Reply-To: <8A846288B89DB64B9455DE44DD1C729523CF20@mbxparis01.recherche.curie.fr>
References: <8A846288B89DB64B9455DE44DD1C729523CF20@mbxparis01.recherche.curie.fr>
Message-ID: <0D8FC2B5-7DA5-4972-BF07-D73CB1156936@txbiomed.org>

Fazal,

I am not sure what you want, but I have guessed. I have tried to provide a straight forward simplistic solution.

If you examine the intermediate results, I think what is being done will be clear.

Mark

Michael Dewey?s suggestion to look at merge is excellent. You may also need to look at the other functions used below. All are commonly used.

# Code follows
set.seed(1) # ensures you get the same results
id <- paste0("id_", 1:10) # I did not want to copy down your Ids so I made them up.
small_dataframe <- data.frame(unique_sample_id = id, 
                              g_1 = character(length(id)), 
                              g_2 = character(length(id)))
# Making up some genotypes for g_1_table and g_2_table
g_1_table <- 
  data.frame(unique_sample_id = sample(id, length(id), replace = FALSE),
             cond = sample(c("M", "N/M"), length(id), replace = TRUE, 
                                prob = c(0.5, 0.5)))
g_2_table <- 
  data.frame(unique_sample_id = sample(id, length(id), replace = FALSE),
             cond = sample(c("M", "N/M"), length(id), replace = TRUE, 
                                prob = c(0.5, 0.5)))

new_dataframe <- merge(small_dataframe, g_1_table, by = "unique_sample_id")
names(new_dataframe) <- 
  c("unique_sample_id", "g_1", "g_2", "g_1_cond")
new_dataframe <- merge(new_dataframe, g_2_table, by = "unique_sample_id")
names(new_dataframe) <- 
  c("unique_sample_id", "g_1", "g_2", "g_1_cond", 
    "g_2_cond")
new_dataframe$g_1_emoticon <- ifelse(new_dataframe$g_1_cond == "M",
                                        ":-)", "No")
new_dataframe$g_2_emoticon <- ifelse(new_dataframe$g_2_cond == "M",
                                        ":-)", "No")
new_dataframe

# End of code
# Output of last line of code.
   unique_sample_id g_1 g_2 g_1_cond g_2_cond g_1_emoticon g_2_emoticon
1              id_1                M      N/M          :-)           No
2             id_10              N/M      N/M           No           No
3              id_2                M        M          :-)          :-)
4              id_3              N/M        M           No          :-)
5              id_4              N/M      N/M           No           No
6              id_5                M      N/M          :-)           No
7              id_6                M      N/M          :-)           No
8              id_7              N/M        M           No          :-)
9              id_8              N/M        M           No          :-)
10             id_9                M        M          :-)          :-)


> On May 1, 2015, at 3:05 PM, Hadi Fazal <fazal.hadi at curie.fr> wrote:
> 
> Hi everyone, 
> I am a real beginner to R and have probably a very naive issue. I've a small data frame with three columns: Unique Sample ID, Gene 1 and Gene 2 (the columns on Gene1 and Gene2 are empty). I have two separate tables for the genes which contain the Unique Subject ID in one column and information on whether the gene is mutated or not in that particular subject (M, N/M) in another column called (Condition). I want to make a loop which can read the Unique Subject ID from my data frame, then look up for the same ID in the two tables and depending on whether the gene is mutated (M)/not mutated (N/M), inserts Yes like emoticon / No (N) in the appropriate gene column (Gene1/Gene2) for each Subject ID.
> If anyone can help, I would really appreciate
> Thanks in advance
> 
> Fazal,
> <Gene2.png>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lalitha.viswanathan79 at gmail.com  Sun May  3 11:19:39 2015
From: lalitha.viswanathan79 at gmail.com (Lalitha Viswanathan)
Date: Sun, 3 May 2015 14:49:39 +0530
Subject: [R] Request for functions to calculate correlated factors
	influencing an outcome.
Message-ID: <CAMeJHHCTWFLFBzVTZ-cooitUMWOf=OLONN=3upCGQiXNArwvfw@mail.gmail.com>

Hi
I have a dataset of the type attached.
Here's my code thus far.
dataset <-data.frame(read.delim("data", sep="\t", header=TRUE));
newData<-subset(dataset, select = c(Price, Reliability, Mileage, Weight,
Disp, HP));
cor(newData, method="pearson");
Results are
                 Price Reliability    Mileage     Weight       Disp
HP
Price        1.0000000          NA -0.6537541  0.7017999  0.4856769
 0.6536433
Reliability         NA           1         NA         NA         NA
NA
Mileage     -0.6537541          NA  1.0000000 -0.8478541 -0.6931928
-0.6667146
Weight       0.7017999          NA -0.8478541  1.0000000  0.8032804
 0.7629322
Disp         0.4856769          NA -0.6931928  0.8032804  1.0000000
 0.8181881
HP           0.6536433          NA -0.6667146  0.7629322  0.8181881
 1.0000000

It appears that Wt and Price, Wt and Disp, Wt and HP, Disp and HP, HP and
Price are strongly correlated.
To find the statistical significance,
I am trying  sample.correln<-cor.test(newData$Disp, newData$HP,
method="kendall", exact=NULL)
Kendall's rank correlation tau

data:  newx$Disp and newx$HP
z = 7.2192, p-value = 5.229e-13
alternative hypothesis: true tau is not equal to 0
sample estimates:
      tau
0.6563871

If I try the same with
sample.correln<-cor.test(newData$Disp, newData$HP, method="pearson",
exact=NULL)
I get Warning message:
In cor.test.default(newx$Disp, newx$HP, method = "spearman", exact = NULL) :
  Cannot compute exact p-value with ties
> sample.correln

Spearman's rank correlation rho

data:  newx$Disp and newx$HP
S = 5716.8, p-value < 2.2e-16
alternative hypothesis: true rho is not equal to 0
sample estimates:
      rho
0.8411566

I am not sure how to interpret these values.
Basically, I am trying to figure out which combination of factors
influences efficiency.

Thanks
Lalitha
-------------- next part --------------
Price	Country	Reliability	Mileage	Type	Weight	Disp.	HP


8895	USA	4	33	Small	2560	97	113


7402	USA	2	33	Small	2345	114	90


6319	Korea	4	37	Small	1845	81	63


6635	Japan/USA	5	32	Small	2260	91	92


6599	Japan	5	32	Small	2440	113	103


8672	Mexico	4	26	Small	2285	97	82


7399	Japan/USA	5	33	Small	2275	97	90


7254	Korea	1	28	Small	2350	98	74


9599	Japan	5	25	Small	2295	109	90


5866	Japan	NA	34	Small	1900	73	73


8748	Japan/USA	5	29	Small	2390	97	102


6488	Japan	5	35	Small	2075	89	78


9995	Germany	3	26	Small	2330	109	100


11545	USA	1	20	Sporty	3320	305	170


9745	USA	1	27	Sporty	2885	153	100


12164	USA	1	19	Sporty	3310	302	225


11470	USA	3	30	Sporty	2695	133	110


9410	Japan	5	33	Sporty	2170	97	108


13945	Japan	5	27	Sporty	2710	125	140


13249	Japan	3	24	Sporty	2775	146	140


10855	USA	NA	26	Sporty	2840	107	92


13071	Japan	NA	28	Sporty	2485	109	97


18900	Germany	NA	27	Compact	2670	121	108


10565	USA	2	23	Compact	2640	151	110


10320	USA	1	26	Compact	2655	133	95


10945	USA	4	25	Compact	3065	181	141


9483	USA	2	24	Compact	2750	141	98


12145	Japan/USA	5	26	Compact	2920	132	125


12459	Japan/USA	4	24	Compact	2780	133	110


10989	Japan	5	25	Compact	2745	122	102


17879	Japan	4	21	Compact	3110	181	142


11650	Japan	5	21	Compact	2920	146	138


9995	USA	2	23	Compact	2645	151	110


15930	France	NA	24	Compact	2575	116	120


11499	Japan/USA	5	23	Compact	2935	135	130


11588	Japan/USA	5	27	Compact	2920	122	115


18450	Sweden	3	23	Compact	2985	141	114


24760	Japan	5	20	Medium	3265	163	160


13150	USA	3	21	Medium	2880	151	110


12495	USA	2	22	Medium	2975	153	150


16342	USA	3	22	Medium	3450	202	147


15350	USA	2	22	Medium	3145	180	150


13195	USA	3	22	Medium	3190	182	140


14980	USA	1	23	Medium	3610	232	140


9999	Korea	NA	23	Medium	2885	143	110


23300	Japan	5	21	Medium	3480	180	158


17899	Japan	5	22	Medium	3200	180	160


13150	USA	2	21	Medium	2765	151	110


14495	USA	NA	21	Medium	3220	189	135


21498	Japan	3	23	Medium	3480	180	190


16145	USA	3	23	Large	3325	231	165


14525	USA	1	18	Large	3855	305	170


17257	USA	3	20	Large	3850	302	150


13995	USA	NA	18	Van	3195	151	110


15395	USA	3	18	Van	3735	202	150


12267	USA	3	18	Van	3665	182	145


14944	Japan	5	19	Van	3735	181	150


14929	Japan	NA	20	Van	3415	143	107


13949	Japan	NA	20	Van	3185	146	138


14799	Japan	NA	19	Van	3690	146	106



From drjimlemon at gmail.com  Sun May  3 12:53:12 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 3 May 2015 20:53:12 +1000
Subject: [R] Plotting Confidence Intervals
In-Reply-To: <CAHP5r1q=yNbrGRyV4tcgnJKpgS4Fzw1pdTSf=57uJMKU9O-YqQ@mail.gmail.com>
References: <CAHP5r1q2CoxKcGiTUO+bGGsnGpX8wOdQ-yseiE5wVuvDbmApAg@mail.gmail.com>
	<33D76D77E9AC4B438DA38B348ED6890D14407EDF@EMAIL.ktkdom.pte.hu>
	<CAHP5r1q=yNbrGRyV4tcgnJKpgS4Fzw1pdTSf=57uJMKU9O-YqQ@mail.gmail.com>
Message-ID: <CA+8X3fXhEey6yp8hEGdBCLbrxKM0Yaq32j1juDJ3h-VRCeNGAg@mail.gmail.com>

Hi Andre,
Perhaps you want something like this:

plot(c(p_conf[1],p_conf1[1],p_pred2[1],p_pred3[1]),xaxt="n",
 xlab="Model",ylab="Estimate")
axis(1,at=1:4,labels=c("p_conf","p_conf1","p_pred2","p_pred3"))
library(plotrix)
dispersion(1:4,c(p_conf[1],p_conf1[1],p_pred2[1],p_pred3[1]),
 ulim=c(p_conf[3],p_conf1[3],p_pred2[3],p_pred3[3]),
 llim=c(p_conf[2],p_conf1[2],p_pred2[2],p_pred3[2]),interval=FALSE)

Jim


On Sun, May 3, 2015 at 12:16 AM, Andre Roldao
<andre.rafael.roldao at gmail.com> wrote:
> Hi Kehl,
>
> First i would like to thank you for the support.
>
> to respond your question i want rather the 4 intervals with the labels, but
> another one with the 4 bars with the intervals, it was fantastic!
>
> Thank you again!
>
> 2015-05-02 9:24 GMT+01:00 Kehl D?niel <kehld at ktk.pte.hu>:
>
>> Hi Andre,
>>
>> I think you'll have to give some more information about what you want to
>> see on your plot. The 4 intervals with labels? A bar with an interval
>> maybe? Four bars with the intervals? Only two showing differences between
>> conf and pred intervals?
>>
>> Also you do miss a 1 here I guess:
>>
>> p_conf1<- predict(ines,interval="confidence",NJ,level=0.99)
>> p_conf1 #Intervalo de confian?a para o estado NJ e para um nivel de 99%
>> round(p_conf, digits=3)
>>
>> last line should read p_conf1 here?
>>
>> Best,
>> d
>> ________________________________________
>> Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Andre
>> Roldao [andre.rafael.roldao at gmail.com]
>> K?ldve: 2015. m?jus 2. 4:49
>> To: r-help at r-project.org
>> T?rgy: [R] Plotting Confidence Intervals
>>
>> Hi Guys,
>>
>> It's the first time i use R-Help and i hope you can help me.
>>
>> How can i plot conffidence intervals? with the data bellow:
>>
>> #Package Austria
>> library(car)
>> #head(States)
>> States1=data.frame(States)
>>
>> ines=lm(SATM ~ log2(pop) + SATV , data=States1)
>> summary(ines)
>>
>> NJ=as.data.frame(States["NJ",c(4,2,3)]) #Identifica??o do estado NJ
>>
>>
>> p_conf<- predict(ines,interval="confidence",NJ,level=0.95)
>> p_conf #Intervalo de confian?a para o estado NJ e para um nivel de 95%
>> round(p_conf, digits=3)
>>
>> p_conf1<- predict(ines,interval="confidence",NJ,level=0.99)
>> p_conf1 #Intervalo de confian?a para o estado NJ e para um nivel de 99%
>> round(p_conf, digits=3)
>>
>> p_pred2<- predict(ines,interval="prediction",NJ,level=0.95)
>> p_pred2 #Intervalo de perdi??o para o estado NJ e para um nivel de 95%
>> round(p_pred2,digits=3)
>>
>> p_pred3<- predict(ines,interval="prediction",NJ,level=0.99)
>> p_pred3 #Intervalo de perdi??o para o estado NJ e para um nivel de 99%
>> round(p_pred3,digits=3)
>>
>> Thanks
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Sun May  3 13:24:36 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 03 May 2015 12:24:36 +0100
Subject: [R] Request for functions to calculate correlated factors
 influencing an outcome.
In-Reply-To: <CAMeJHHCTWFLFBzVTZ-cooitUMWOf=OLONN=3upCGQiXNArwvfw@mail.gmail.com>
References: <CAMeJHHCTWFLFBzVTZ-cooitUMWOf=OLONN=3upCGQiXNArwvfw@mail.gmail.com>
Message-ID: <55460574.8090505@dewey.myzen.co.uk>

Dear Lalitha, see inline below

On 03/05/2015 10:19, Lalitha Viswanathan wrote:
> Hi
> I have a dataset of the type attached.
> Here's my code thus far.
> dataset <-data.frame(read.delim("data", sep="\t", header=TRUE));
> newData<-subset(dataset, select = c(Price, Reliability, Mileage, Weight,
> Disp, HP));

In fact in the file the variable seems to be called Disp.

> cor(newData, method="pearson");
> Results are
>                   Price Reliability    Mileage     Weight       Disp
> HP
> Price        1.0000000          NA -0.6537541  0.7017999  0.4856769
>   0.6536433
> Reliability         NA           1         NA         NA         NA
> NA
> Mileage     -0.6537541          NA  1.0000000 -0.8478541 -0.6931928
> -0.6667146
> Weight       0.7017999          NA -0.8478541  1.0000000  0.8032804
>   0.7629322
> Disp         0.4856769          NA -0.6931928  0.8032804  1.0000000
>   0.8181881
> HP           0.6536433          NA -0.6667146  0.7629322  0.8181881
>   1.0000000
>
> It appears that Wt and Price, Wt and Disp, Wt and HP, Disp and HP, HP and
> Price are strongly correlated.
> To find the statistical significance,
> I am trying  sample.correln<-cor.test(newData$Disp, newData$HP,
> method="kendall", exact=NULL)
> Kendall's rank correlation tau
>
> data:  newx$Disp and newx$HP
> z = 7.2192, p-value = 5.229e-13
> alternative hypothesis: true tau is not equal to 0
> sample estimates:
>        tau
> 0.6563871
>
> If I try the same with
> sample.correln<-cor.test(newData$Disp, newData$HP, method="pearson",
> exact=NULL)

When I try that it works fine.
The real question is why when you asked it for the Pearson coefficient 
it decided to give you the Spearman as the warning message below points 
out. I suspect you have done something else which you did not tell us about.

> I get Warning message:
> In cor.test.default(newx$Disp, newx$HP, method = "spearman", exact = NULL) :
>    Cannot compute exact p-value with ties
>> sample.correln
>
> Spearman's rank correlation rho
>
> data:  newx$Disp and newx$HP
> S = 5716.8, p-value < 2.2e-16
> alternative hypothesis: true rho is not equal to 0
> sample estimates:
>        rho
> 0.8411566
>
> I am not sure how to interpret these values.
> Basically, I am trying to figure out which combination of factors
> influences efficiency.
>
> Thanks
> Lalitha
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From drjimlemon at gmail.com  Sun May  3 13:43:17 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 3 May 2015 21:43:17 +1000
Subject: [R] Black outlines for errorbar using geom_line
In-Reply-To: <6D5C009FB51EBD41BEE57F4C002350FD01F0FA@SB00112A.adb.intra.admin.ch>
References: <6D5C009FB51EBD41BEE57F4C002350FD01F0FA@SB00112A.adb.intra.admin.ch>
Message-ID: <CA+8X3fUr+p32p+tydo+rrm1cKfc8SrEgyDC8ojk=H8KTBvBNhQ@mail.gmail.com>

Hi Michael,
I don't know about ggplot, but it is fairly easy to create outlined or
even shadowed errorbars:

require(plotrix)
# display thick black errorbars
dispersion(...,lwd=3)
# display thin white errorbars
dispersion(...,col="white")

The above trick produces white errorbars outlined in black. I think it
will work for any routine producing error bars, not just the
"dispersion" function. You may be able to simply add two geom_errorbar
components to the call in the same way as above.

Jim


On Sat, May 2, 2015 at 8:18 AM,  <michael.eisenring at agroscope.admin.ch> wrote:
> Hi there,
>  I would like to create black outlines around my errorbars in order to get especially the white errorbar better visible.
> Is that even possible with ggplot2 and if yes how?
> I would be very grateful if anyone could help me. I added my code and a dput() of my data,
>
> Thank you very much,
> Michael
>
>
> #my code:--------------------------------------------------
>
>
> #load packages
> library(compute.es<http://compute.es/>);library(ggplot2);library(multcomp);library(pastecs);library(WRS)
> library(pastecs);library(Hmisc)
> library (car)
>
>
> # Comput CI manually and produce error plots
>
> #CI manually computed with formula summarySE
> summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
>                       conf.interval=.95, .drop=TRUE) {
>   library(plyr)
>
>   # New version of length which can handle NA's: if na.rm==T, don't count them
>   length2 <- function (x, na.rm=FALSE) {
>     if (na.rm) sum(!is.na<http://is.na/>(x))
>     else       length(x)
>   }
>
>   # This does the summary. For each group's data frame, return a vector with
>   # N, mean, and sd
>   datac <- ddply(data, groupvars, .drop=.drop,
>                  .fun = function(xx, col) {
>                    c(N    = length2(xx[[col]], na.rm=na.rm),
>                      mean = mean   (xx[[col]], na.rm=na.rm),
>                      sd   = sd     (xx[[col]], na.rm=na.rm)
>                    )
>                  },
>                  measurevar
>   )
>
>   # Rename the "mean" column
>   datac <- rename(datac, c("mean" = measurevar))
>
>   datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
>
>   # Confidence interval multiplier for standard error
>   # Calculate t-statistic for confidence interval:
>   # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
>   ciMult <- qt(conf.interval/2 + .5, datac$N-1)
>   datac$ci <- datac$se * ciMult
>
>   return(datac)
> }
>
> #summarySE provides the standard deviation, standard error of the mean, and a (default 95%) confidence interval
> CI <- summarySE(data, measurevar="cor_average", groupvars=c("damage","leaf"))
> CI
>
>
> #plotting in ggplot
> # To prevent that errorbars overlap use position_dodge to move them horizontally
> pd <- position_dodge(0.4) # move them .05 to the left and right
> #Create errorbar using 95% CI
> ggplot(CI, aes(x=leaf, y=cor_average, colour=damage)) +
>   geom_errorbar(aes(ymin=cor_average-ci, ymax=cor_average+ci), width=.3, size=1,position=pd) +
>   geom_line(position=pd) +
>   scale_colour_manual(values=c("white","black","gray65"))+
>   geom_point(position=pd,size=3)
>
>
>
> #my data set: ---------------------------------------------------------------------------------------------------------------
>
>> dput(data<-read.csv("Exp1.csv",sep=",",header=T))
> structure(list(damage = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L), .Label = c("C", "L1", "L4"), class = "factor"), leaf = structure(c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L), .Label = c("Cot", "L1", "L2",
> "L3", "L4", "L5", "L6", "L7", "L8"), class = "factor"), cor_average = c(587.6666667,
> 595.3333333, 858, 516, 542.6666667, 455, 530.3333333, 546.6666667,
> 215.1111111, 666.6666667, 680, 2361.666667, 2880, 2760, 2210,
> 2142, 2508, 1551.666667, 1856, 498.7777778, 2634.666667, 2380,
> 2338.333333, 2006.666667, 3296.666667, 2945.333333, 2720.666667,
> 2436, 2033, 2579.333333, 455.1111111, 2123.333333, 2033.333333,
> 3660.333333, 2765, 3752, 3150, 3747.333333, 3572, 3536, 3593.333333,
> 1178.777778, 3476, 3291.666667, 3927.333333, 3705, 4636.666667,
> 3720, 4080, 4828, 5280, 4495, 711.1111111, 4340, 4173, 4785,
> 5070, 6324, 3360, 5150, 6262.666667, 5624, 5595.333333, 1626.777778,
> 5869.333333, 5080, 6888, 7561.333333, 7280, 3610, 5926.666667,
> 6600, 6375.333333, 7831.666667, 4181.777778, 8023, 6077.333333,
> 14640, 13501.33333, 15383.33333, 6193, 10030, 8756.333333, 10291.66667,
> 16450, 33611.11111, 15138.66667, 10948, 6600, 7785, 10944, 11712,
> 17490, 14370, 10353, 8814.333333, 742.5, 605, 520, 728.5, 418,
> 650, 468.6666667, 506.6666667, 512, 518, 646, 1974, 2408, 2494,
> 1931.666667, 1243.666667, 2024, 1805, 2166.666667, 2408, 1613.333333,
> 2573, 2102.333333, 2470, 2701, 2566.666667, 2960, 2300, 2579.666667,
> 1785, 2223.333333, 2046, 3336.666667, 3737, 4529.666667, 3718,
> 3192, 4110, 3198, 4116, 2645, 3288, 3315, 4850, 4293.333333,
> 4972, 4641, 4370, 4933.333333, 3853.333333, 4658, 3720, 4340,
> 3882.666667, 5577, 7800, 7646.333333, 4200, 5418, 5324.666667,
> 4564, 5085, 5060, 7093.333333, 6923.333333, 7700, 14575, 14725,
> 6650, 12154.66667, 8254.666667, 5800, 7663.333333, 6640, 12661.66667,
> 12982.33333, 14025, 17148, 21960, 10418.33333, 25850, 12636,
> 8470, 17152, 20603.33333, 22078, 20086.66667, 24219, 18544, 13475,
> 23389, 22374, 10246.5, 13695, 12220, 487.5, 645, 623.3333333,
> 493.3333333, 555, 532, 658.6666667, 522, 492, 528, 604.3333333,
> 528, 1998.333333, 2016.666667, 1971.666667, 2376, 1780, 1729,
> 2026.666667, 2186.666667, 1860, 2112, 2300, 2054.666667, 2520,
> 2532.333333, 2181.666667, 2960.333333, 2220, 2472, 2555, 1392,
> 2826.666667, 1457, 2600, 2026.666667, 3720, 4275, 4389, 3014,
> 2875, 3920, 4094, 2712, 3853.333333, 2926, 4766.666667, 3948.333333,
> 5625, 6303.333333, 4783.666667, 4770, 3530.333333, 4840, 3760,
> 4656.666667, 3600, 3923.333333, 5458.333333, 3600, 5115, 5950,
> 5662.666667, 6075, 4307.333333, 5960, 5425, 4978, 6292, 4477.333333,
> 5568, 5364.333333, 8824.666667, 8520, 8000, 11293.33333, 5133.333333,
> 7973.333333, 5786.666667, 6006, 6766.666667, 7000, 7566, 15555,
> 14299.33333, 19716.66667, 24408, 11349, 17400, 13362, 19525,
> 23902, 15364, 16875, 10450, 17605, 22950, 19920, 12412, 21187.33333,
> 20425, 20710, 10280.5, 11063, 21498.66667, 22333.33333)), .Names = c("damage",
> "leaf", "cor_average"), class = "data.frame", row.names = c(NA,
> -297L))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tallylune at gmail.com  Sun May  3 15:01:33 2015
From: tallylune at gmail.com (Citlalli M.J. )
Date: Sun, 3 May 2015 14:01:33 +0100
Subject: [R] OAT Spartan package error
Message-ID: <CAFMUNVNfRkXCNom9L+7Cs6+MfEiH0AXwu3-oQSM0cqeKfzQ1sw@mail.gmail.com>

Hi all,

I am trying to analyse data using the OAT method in the Spartan package.
However I am getting this error when trying to generate the A-Test Scores:
 "Analysing Netlogo Robustness Analysis File, and Generating A-Test Scores"
[1] "No results in the CSV file for simulation at specified baseline
values. No analysis performed"

I checked the csv file and there are results for the baseline values I set.
I also tried with the data and code from the spartan tutorial (available
here:
https://www.york.ac.uk/computational-immunology/software/spartan/#tab-5)
 thinking there was something wrong with my data or code, however I get the
same error all the same. This is strange since I was able to analyse data
using this code a few months back.
Any ideas would be greatly appreciated.

The code:

FILEPATH<- "C:\\Users\\Tali\\R\\Spartan\\OAT"
NETLOGO_BEHAVIOURSPACEFILE<-"patchtrial.csv"
PARAMETERS<-c("logging1","logging2","logging3")
BASELINE<-c(50,50,50)
PMAX<-c(100,100,100)
PMIN<-c(10,10,10)
PINC<-c(10,10,10)
TIMESTEP<-36500
MEASURES<-c("count monkeys")
CSV_FILE_NAME<-"ParamValResponsesLoggingTest2"
ATESTRESULTSFILENAME<-"ATestsLogging2.csv"
ATESTSIGLEVEL<-0.05
MEASURE_SCALE<-c("Number of monkeys","Number of monkeys")
TIMEPOINTS<-NULL; TIMEPOINTSCALE<-NULL

PARAMETERS<-table_header_check(PARAMETERS)
MEASURES<-table_header_check(MEASURES)

oat_process_netlogo_result(FILEPATH,NETLOGO_BEHAVIOURSPACEFILE,
PARAMETERS,BASELINE,PMIN,PMAX,PINC,MEASURES,
CSV_FILE_NAME, ATESTRESULTSFILENAME,TIMESTEP)

oat_graphATestsForSampleSize(FILEPATH,PARAMETERS,MEASURES,
ATESTSIGLEVEL,ATESTRESULTSFILENAME,BASELINE,
PMIN=PMIN,PMAX=PMAX,PINC=PINC,PARAMVALS=NULL)

oat_plotResultDistribution(FILEPATH,PARAMETERS,MEASURES,
MEASURE_SCALE,CSV_FILE_NAME,BASELINE,PMIN=PMIN,PMAX=PMAX,
PINC=PINC,PARAMVALS=NULL,TIMEPOINTS,TIMEPOINTSCALE)?

	[[alternative HTML version deleted]]


From daniela_scida at brown.edu  Sun May  3 17:36:29 2015
From: daniela_scida at brown.edu (Dany)
Date: Sun, 3 May 2015 11:36:29 -0400
Subject: [R]  cycle in a directed graph
Message-ID: <0B1CEF10-1DAD-4239-B625-C27DB53D0CBC@brown.edu>

Hi I saw the answer: 

?If the graph has n nodes and is represented by an adjacency matrix, you can square the matrix (log_2 n)+1 times. Then you can multiply the matrix element-wise by its transpose. ?

I?m a PhD student working on my research and I need to check for cycles in a directed graph to make sure it is a DAG. The answer given is extremely useful but I need the theorem statement, or a reference. Do you have a book where this is stated or a paper?

Thanks!

Daniela.
	[[alternative HTML version deleted]]


From heiko-sorg at gmx.de  Sun May  3 18:22:36 2015
From: heiko-sorg at gmx.de (Reiko)
Date: Sun, 3 May 2015 09:22:36 -0700 (PDT)
Subject: [R] Help with function jtest - inputs other than from lm
Message-ID: <1430670156112-4706738.post@n4.nabble.com>

Hi all,

the function jtest allows to compare two non-nested models. The comparison
is made such that the fitted values of one model are included in the
regressor matrix of the other model. It then looks whether there is any
predictive power of these fitted values.

Unfortunately, the input has to come from a linear regression of class lm. I
think that in the function jtest, both the regressor matrix of model 1 and
the fitted values of model 2 will be estimated. Afterwards, it will perform
the J test. 

However, I don't use lm and wanted therefore to ask if you know whether
there is a way to manually define a regressor matrix (e.g. a matrix) and the
fitted values (vector) as inputs? 

Best,
Reiko



--
View this message in context: http://r.789695.n4.nabble.com/Help-with-function-jtest-inputs-other-than-from-lm-tp4706738.html
Sent from the R help mailing list archive at Nabble.com.


From lalitha.viswanathan79 at gmail.com  Sun May  3 19:46:49 2015
From: lalitha.viswanathan79 at gmail.com (Lalitha Viswanathan)
Date: Sun, 3 May 2015 23:16:49 +0530
Subject: [R] Request for functions to calculate correlated factors
	influencing an outcome.
Message-ID: <CAMeJHHApBUdmm8_meZ=wy=QdvbV_96+7+kgsaS1s=+EDjTufPg@mail.gmail.com>

Hi
I am sorry, I saved the file removing the dot after the Disp (as I was
going wrong on a read.delim which threw an error about !header, etc...The
dot was not the culprit, but I continued to leave it out.
Let me paste the full code here.
x<-read.table("/Users/Documents/StatsTest/fuelEfficiency.txt", header=TRUE,
sep="\t")
x<-data.frame(x)
for (i in unique(x$Country)) { print (i); y <- subset(x, x$Country == i);
print(y); }
newx <- subset (x, select = c(Price, Reliability, Mileage, Weight, Disp,
HP))
cor(newx, method="pearson")
my.cor <-cor.test(newx$Weight, newx$Price, method="spearman")
my.cor <-cor.test(newx$Weight, newx$HP, method="spearman")
my.cor <-cor.test(newx$Disp, newx$HP, method="spearman")
Putting exact=NULL still doesn't remove the warning
my.cor <-cor.test(newx$Disp, newx$HP, method="kendall", exact=NULL)
I tried to find the correlation coeff for a various combination of
variables, but am unable to interpet the results. (Results pasted below in
an earlier post)

Followed it up with a normality test
shapiro.test(newx$Disp)
shapiro.test(newx$HP)

Then decided to do a kruskal.test(newx)
with the result
Kruskal-Wallis chi-squared = 328.94, df = 5, p-value < 2.2e-16

Question is : I am trying to find factors influencing efficiency (in this
case mileage)

What are the range of functions / examples I should be looking at, to find
a factor or combination of factors influencing efficiency?

Any pointers will be helpful

Thanks
Lalitha

On Sun, May 3, 2015 at 2:49 PM, Lalitha Viswanathan <
lalitha.viswanathan79 at gmail.com> wrote:

> Hi
> I have a dataset of the type attached.
> Here's my code thus far.
> dataset <-data.frame(read.delim("data", sep="\t", header=TRUE));
> newData<-subset(dataset, select = c(Price, Reliability, Mileage, Weight,
> Disp, HP));
> cor(newData, method="pearson");
> Results are
>                  Price Reliability    Mileage     Weight       Disp
>   HP
> Price        1.0000000          NA -0.6537541  0.7017999  0.4856769
>  0.6536433
> Reliability         NA           1         NA         NA         NA
>   NA
> Mileage     -0.6537541          NA  1.0000000 -0.8478541 -0.6931928
> -0.6667146
> Weight       0.7017999          NA -0.8478541  1.0000000  0.8032804
>  0.7629322
> Disp         0.4856769          NA -0.6931928  0.8032804  1.0000000
>  0.8181881
> HP           0.6536433          NA -0.6667146  0.7629322  0.8181881
>  1.0000000
>
> It appears that Wt and Price, Wt and Disp, Wt and HP, Disp and HP, HP and
> Price are strongly correlated.
> To find the statistical significance,
> I am trying  sample.correln<-cor.test(newData$Disp, newData$HP,
> method="kendall", exact=NULL)
> Kendall's rank correlation tau
>
> data:  newx$Disp and newx$HP
> z = 7.2192, p-value = 5.229e-13
> alternative hypothesis: true tau is not equal to 0
> sample estimates:
>       tau
> 0.6563871
>
> If I try the same with
> sample.correln<-cor.test(newData$Disp, newData$HP, method="pearson",
> exact=NULL)
> I get Warning message:
> In cor.test.default(newx$Disp, newx$HP, method = "spearman", exact = NULL)
> :
>   Cannot compute exact p-value with ties
> > sample.correln
>
> Spearman's rank correlation rho
>
> data:  newx$Disp and newx$HP
> S = 5716.8, p-value < 2.2e-16
> alternative hypothesis: true rho is not equal to 0
> sample estimates:
>       rho
> 0.8411566
>
> I am not sure how to interpret these values.
> Basically, I am trying to figure out which combination of factors
> influences efficiency.
>
> Thanks
> Lalitha
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun May  3 19:50:26 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 03 May 2015 10:50:26 -0700
Subject: [R] cycle in a directed graph
In-Reply-To: <0B1CEF10-1DAD-4239-B625-C27DB53D0CBC@brown.edu>
References: <0B1CEF10-1DAD-4239-B625-C27DB53D0CBC@brown.edu>
Message-ID: <D0D305E9-41B3-4EDD-A77F-BCEAB76E8F06@dcn.davis.CA.us>

Lacking any reference to R, this message is off-topic on this mailing list. You might try math.stackexchange.com.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 3, 2015 8:36:29 AM PDT, Dany <daniela_scida at brown.edu> wrote:
>Hi I saw the answer: 
>
>?If the graph has n nodes and is represented by an adjacency matrix,
>you can square the matrix (log_2 n)+1 times. Then you can multiply the
>matrix element-wise by its transpose. ?
>
>I?m a PhD student working on my research and I need to check for cycles
>in a directed graph to make sure it is a DAG. The answer given is
>extremely useful but I need the theorem statement, or a reference. Do
>you have a book where this is stated or a paper?
>
>Thanks!
>
>Daniela.
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From theseth.prashant at gmail.com  Sun May  3 20:03:03 2015
From: theseth.prashant at gmail.com (Prashant Sethi)
Date: Sun, 3 May 2015 23:33:03 +0530
Subject: [R] Request for functions to calculate correlated factors
 influencing an outcome.
In-Reply-To: <CAMeJHHApBUdmm8_meZ=wy=QdvbV_96+7+kgsaS1s=+EDjTufPg@mail.gmail.com>
References: <CAMeJHHApBUdmm8_meZ=wy=QdvbV_96+7+kgsaS1s=+EDjTufPg@mail.gmail.com>
Message-ID: <CAM04ykANAbyNifjhu3AKAf88qvqDWjRnASM3Fb_LV6WE3jpX5g@mail.gmail.com>

Hi,

I'm not an expert in data analysis (a beginner still learning tricks of the
trade) but I believe in your case since you're trying to determine the
correlation of a dependent variable with a number of factor variables, you
should try doing the regression analysis of your model. The function you'll
use for that is the lm() function. You can use the forward building or the
backward elimination method to build your model with the most critical
factors included.

Maybe you can give it a try.

Thanks and regards,
Prashant Sethi
On 3 May 2015 23:18, "Lalitha Viswanathan" <lalitha.viswanathan79 at gmail.com>
wrote:

> Hi
> I am sorry, I saved the file removing the dot after the Disp (as I was
> going wrong on a read.delim which threw an error about !header, etc...The
> dot was not the culprit, but I continued to leave it out.
> Let me paste the full code here.
> x<-read.table("/Users/Documents/StatsTest/fuelEfficiency.txt", header=TRUE,
> sep="\t")
> x<-data.frame(x)
> for (i in unique(x$Country)) { print (i); y <- subset(x, x$Country == i);
> print(y); }
> newx <- subset (x, select = c(Price, Reliability, Mileage, Weight, Disp,
> HP))
> cor(newx, method="pearson")
> my.cor <-cor.test(newx$Weight, newx$Price, method="spearman")
> my.cor <-cor.test(newx$Weight, newx$HP, method="spearman")
> my.cor <-cor.test(newx$Disp, newx$HP, method="spearman")
> Putting exact=NULL still doesn't remove the warning
> my.cor <-cor.test(newx$Disp, newx$HP, method="kendall", exact=NULL)
> I tried to find the correlation coeff for a various combination of
> variables, but am unable to interpet the results. (Results pasted below in
> an earlier post)
>
> Followed it up with a normality test
> shapiro.test(newx$Disp)
> shapiro.test(newx$HP)
>
> Then decided to do a kruskal.test(newx)
> with the result
> Kruskal-Wallis chi-squared = 328.94, df = 5, p-value < 2.2e-16
>
> Question is : I am trying to find factors influencing efficiency (in this
> case mileage)
>
> What are the range of functions / examples I should be looking at, to find
> a factor or combination of factors influencing efficiency?
>
> Any pointers will be helpful
>
> Thanks
> Lalitha
>
> On Sun, May 3, 2015 at 2:49 PM, Lalitha Viswanathan <
> lalitha.viswanathan79 at gmail.com> wrote:
>
> > Hi
> > I have a dataset of the type attached.
> > Here's my code thus far.
> > dataset <-data.frame(read.delim("data", sep="\t", header=TRUE));
> > newData<-subset(dataset, select = c(Price, Reliability, Mileage, Weight,
> > Disp, HP));
> > cor(newData, method="pearson");
> > Results are
> >                  Price Reliability    Mileage     Weight       Disp
> >   HP
> > Price        1.0000000          NA -0.6537541  0.7017999  0.4856769
> >  0.6536433
> > Reliability         NA           1         NA         NA         NA
> >   NA
> > Mileage     -0.6537541          NA  1.0000000 -0.8478541 -0.6931928
> > -0.6667146
> > Weight       0.7017999          NA -0.8478541  1.0000000  0.8032804
> >  0.7629322
> > Disp         0.4856769          NA -0.6931928  0.8032804  1.0000000
> >  0.8181881
> > HP           0.6536433          NA -0.6667146  0.7629322  0.8181881
> >  1.0000000
> >
> > It appears that Wt and Price, Wt and Disp, Wt and HP, Disp and HP, HP and
> > Price are strongly correlated.
> > To find the statistical significance,
> > I am trying  sample.correln<-cor.test(newData$Disp, newData$HP,
> > method="kendall", exact=NULL)
> > Kendall's rank correlation tau
> >
> > data:  newx$Disp and newx$HP
> > z = 7.2192, p-value = 5.229e-13
> > alternative hypothesis: true tau is not equal to 0
> > sample estimates:
> >       tau
> > 0.6563871
> >
> > If I try the same with
> > sample.correln<-cor.test(newData$Disp, newData$HP, method="pearson",
> > exact=NULL)
> > I get Warning message:
> > In cor.test.default(newx$Disp, newx$HP, method = "spearman", exact =
> NULL)
> > :
> >   Cannot compute exact p-value with ties
> > > sample.correln
> >
> > Spearman's rank correlation rho
> >
> > data:  newx$Disp and newx$HP
> > S = 5716.8, p-value < 2.2e-16
> > alternative hypothesis: true rho is not equal to 0
> > sample estimates:
> >       rho
> > 0.8411566
> >
> > I am not sure how to interpret these values.
> > Basically, I am trying to figure out which combination of factors
> > influences efficiency.
> >
> > Thanks
> > Lalitha
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From steve.taylor at aut.ac.nz  Sun May  3 22:36:30 2015
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Sun, 3 May 2015 20:36:30 +0000
Subject: [R] Plotting Confidence Intervals
In-Reply-To: <CAHP5r1q2CoxKcGiTUO+bGGsnGpX8wOdQ-yseiE5wVuvDbmApAg@mail.gmail.com>
References: <CAHP5r1q2CoxKcGiTUO+bGGsnGpX8wOdQ-yseiE5wVuvDbmApAg@mail.gmail.com>
Message-ID: <CCE952776B6679469977532BD863C39CAA5ACB8E@Lewis.autuni.aut.ac.nz>

Have you tried:

library(effects)
plot(allEffects(ines),ylim=c(460,550))


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Andre Roldao
Sent: Saturday, 2 May 2015 2:50p
To: r-help at r-project.org
Subject: [R] Plotting Confidence Intervals

Hi Guys,

It's the first time i use R-Help and i hope you can help me.

How can i plot conffidence intervals? with the data bellow:

#Package Austria
library(car)
#head(States)
States1=data.frame(States)

ines=lm(SATM ~ log2(pop) + SATV , data=States1)
summary(ines)

NJ=as.data.frame(States["NJ",c(4,2,3)]) #Identifica??o do estado NJ


p_conf<- predict(ines,interval="confidence",NJ,level=0.95)
p_conf #Intervalo de confian?a para o estado NJ e para um nivel de 95%
round(p_conf, digits=3)

p_conf1<- predict(ines,interval="confidence",NJ,level=0.99)
p_conf1 #Intervalo de confian?a para o estado NJ e para um nivel de 99%
round(p_conf, digits=3)

p_pred2<- predict(ines,interval="prediction",NJ,level=0.95)
p_pred2 #Intervalo de perdi??o para o estado NJ e para um nivel de 95%
round(p_pred2,digits=3)

p_pred3<- predict(ines,interval="prediction",NJ,level=0.99)
p_pred3 #Intervalo de perdi??o para o estado NJ e para um nivel de 99%
round(p_pred3,digits=3)

Thanks

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From jdnewmil at dcn.davis.ca.us  Mon May  4 02:45:09 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 3 May 2015 17:45:09 -0700 (PDT)
Subject: [R] Fwd:  (no subject)
In-Reply-To: <CAMUnHGnfU=C8qMeJdgpkb3=F7oNORx2kW4aEJA2xemJrsL+4FA@mail.gmail.com>
References: <CAMUnHGn-xaNX2sm_CCqDtGoDq-sBv4z_wS6LQf776GiwXXYP6Q@mail.gmail.com>
	<7E3243BB-2116-4E55-858F-4C55DD1072F8@dcn.davis.CA.us>
	<CA+8X3fVRQN96OjtN3SxKka38shVA89XQ5ndRG8Fg=kaxvTuX7g@mail.gmail.com>
	<CAMUnHGnWdY=crZv0+YgVUDNDyzK+TjBfb2WH4+LNXAWhD+0_2Q@mail.gmail.com>
	<CAMUnHGnfU=C8qMeJdgpkb3=F7oNORx2kW4aEJA2xemJrsL+4FA@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1505031717060.92953@pedal.dcn.davis.ca.us>

Please keep the mailing list included. I don't provide help offline.

The Posting Guide (mentioned at the bottom of every message on this list) 
requests that you provide a small reproducible example. Your example is 
not yet reproducible. Reading files off your disk is generally not an 
option in a reproducible example. You may find [1] helpful in clarifying 
the meaning of reproducibility. Pay particular attention to the use of 
"dput" which can let us tell exactly what is in the objects you have read 
in. Just because a column "looks" like a Date doesn't mean it is a Date.

I see you have toyed around with the as.Date function, but I don't see 
that you have applied it to the data you read in. Something like

LPB_PPT_R$Date <- as.Date( as.character( LPB_PPT_R$Date ) )

might help.

I also don't see that you have made a ts object out of the information in 
that data frame, so plot.ts may behave oddly with the information you are 
giving it. I don't use ts myself, but reading ?as.ts it doesn't seem to 
have an option to give specified timestamps. If you know you will need 
timeseries analysis, you might consider the xts package which does accept 
specified timestamps.

Note that once you have converted the Date column to a Date type, you can 
probably plot the data without the ts object that plot.ts wants... just

plot( Rain_cm + Cum_PPT ~ Date, data=LPB_PPT_R )

On Sun, 3 May 2015, Dot Lundberg wrote:

> 
> ---------- Forwarded message ----------
> From: Dot Lundberg <dotlundberg at gmail.com>
> Date: Sun, May 3, 2015 at 7:31 PM
> Subject: Re: [R] (no subject)
> To: Jim Lemon <drjimlemon at gmail.com>
> Cc: r-help at r-project.org
> 
> 
> Hello,
> 
> Here is the example of the dataset and code I am working with.? I have also attached a photo of the
> graphs it produces.? I am trying to get the x axis to read the dates as dates not a count of the dates.
> 
> getwd()
> [1] "C:/Users/Dot/Documents"
> > setwd("c:/users/dot/desktop/r")
> > list.files()
> ?[1] "DEAL4_2_43531.csv"?? "DitchR"????????????? "karen_question.pptx"
> ?[4] "LPB_PPT_R.csv"?????? "LPB_R.csv"?????????? "LPB_R.xlsx"????????
> ?[7] "R codes.docx"??????? "Seasons_D4.csv"????? "test.R"????????????
> [10] "YearData.csv"??????
> > DEAL4_2_43531<-read.csv("DEAL4_2_43531.csv")
> > LPB_PPT_R<-read.csv("LPB_PPT_R.csv")
> > LPB_PPT_R<-read.csv("LPB_PPT_R.csv", header=TRUE)
> > attach(LPB_PPT_R)
> > names(LPB_PPT_R)
> [1] "Date"??? "Rain_cm" "Cum_PPT"
> > class(LPB_PPT_R)
> [1] "data.frame"
> > as.Date(40007, origin = "1900-01-01")
> [1] "2009-07-15"
> ?plot.ts(LPB_PPT_R[,2:3], type="l", col="black", xlab="Date")
> >? head(LPB_PPT_R)
> ??????? Date Rain_cm Cum_PPT
> 1 2009-07-15? 0.0254??? 0.03
> 2 2009-07-16? 0.0000??? 0.03
> 3 2009-07-17? 0.0000??? 0.03
> 4 2009-07-18? 0.0000??? 0.03
> 5 2009-07-19? 0.0000??? 0.03
> 6 2009-07-20? 0.0000??? 0.03
> >
> 
> 
> Any help would be greatly appreciated. Thanks!
> 
> 
> 
> 
> On Wed, Apr 15, 2015 at 5:02 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>       Hi Dot,
>       Jeff's guess is probably correct, but perhaps you could describe the
>       crazy tick marks and the repeating labels a little more. I suspect
>       that if "newdate" was a character variable you wouldn't get a plot at
>       all, and if it is a factor, a few of the labels might identify what
>       went wrong.
>
>       Jim
>
>       > On April 14, 2015 5:04:48 PM PDT, Dot Lundberg <dotlundberg at gmail.com>
>       > wrote:
>       >>New to R. Having trouble with the xaxis in this code. The tick marks
>       >>are
>       >>crazy and the labels repeat. Any suggestions?
>       >>
>       >>par(mar=c(5,5,5,5))
>       >>
>       >>plot(LPB_PPT_R$newdate,LPB_PPT_R$Rain_cm,pch=0,type="l",col="black",yaxt="n",ylim=c(0,8),ylab="")
>       >>axis(side=2, at=c(0,2,4,6,8))
>       >>mtext("Precipitation (cm)", side = 2, line=2.5, at=4)
>       >>mtext("Date", side=1, line=2.5)
>       >>axis.Date(1, at=seq(min(LPB_PPT_R$newdate),
>       >>max(LPB_PPT_R$newdate),las=2,by="1 weeks"),format="%m-%Y")
>       >>
>       >>par(new=TRUE)
>       >>
>       >>plot(LPB_PPT_R$newdate,LPB_PPT_R$Cum_PPT,pch=1,type="l",col="grey",yaxt="n",ylim=c(0,100),
>       >>ylab="")
>       >>axis(side=4, at=c(0,50,100))
>       >>mtext("Cumulative Precipitation (cm)", side=4, line=2.5, at=50,
>       >>col="grey")
>       >>
>       >>? ? ? [[alternative HTML version deleted]]
>       >>
>       >>______________________________________________
>       >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>       >>https://stat.ethz.ch/mailman/listinfo/r-help
>       >>PLEASE do read the posting guide
>       >>http://www.R-project.org/posting-guide.html
>       >>and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From dotlundberg at gmail.com  Mon May  4 01:31:59 2015
From: dotlundberg at gmail.com (Dot Lundberg)
Date: Sun, 3 May 2015 19:31:59 -0400
Subject: [R] (no subject)
In-Reply-To: <CA+8X3fVRQN96OjtN3SxKka38shVA89XQ5ndRG8Fg=kaxvTuX7g@mail.gmail.com>
References: <CAMUnHGn-xaNX2sm_CCqDtGoDq-sBv4z_wS6LQf776GiwXXYP6Q@mail.gmail.com>
	<7E3243BB-2116-4E55-858F-4C55DD1072F8@dcn.davis.CA.us>
	<CA+8X3fVRQN96OjtN3SxKka38shVA89XQ5ndRG8Fg=kaxvTuX7g@mail.gmail.com>
Message-ID: <CAMUnHGnWdY=crZv0+YgVUDNDyzK+TjBfb2WH4+LNXAWhD+0_2Q@mail.gmail.com>

Hello,

Here is the example of the dataset and code I am working with.  I have also
attached a photo of the graphs it produces.  I am trying to get the x axis
to read the dates as dates not a count of the dates.

getwd()
[1] "C:/Users/Dot/Documents"
> setwd("c:/users/dot/desktop/r")
> list.files()
 [1] "DEAL4_2_43531.csv"   "DitchR"              "karen_question.pptx"
 [4] "LPB_PPT_R.csv"       "LPB_R.csv"           "LPB_R.xlsx"
 [7] "R codes.docx"        "Seasons_D4.csv"      "test.R"
[10] "YearData.csv"
> DEAL4_2_43531<-read.csv("DEAL4_2_43531.csv")
> LPB_PPT_R<-read.csv("LPB_PPT_R.csv")
> LPB_PPT_R<-read.csv("LPB_PPT_R.csv", header=TRUE)
> attach(LPB_PPT_R)
> names(LPB_PPT_R)
[1] "Date"    "Rain_cm" "Cum_PPT"
> class(LPB_PPT_R)
[1] "data.frame"
> as.Date(40007, origin = "1900-01-01")
[1] "2009-07-15"
 plot.ts(LPB_PPT_R[,2:3], type="l", col="black", xlab="Date")
>  head(LPB_PPT_R)
        Date Rain_cm Cum_PPT
1 2009-07-15  0.0254    0.03
2 2009-07-16  0.0000    0.03
3 2009-07-17  0.0000    0.03
4 2009-07-18  0.0000    0.03
5 2009-07-19  0.0000    0.03
6 2009-07-20  0.0000    0.03
>


Any help would be greatly appreciated. Thanks!




On Wed, Apr 15, 2015 at 5:02 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Dot,
> Jeff's guess is probably correct, but perhaps you could describe the
> crazy tick marks and the repeating labels a little more. I suspect
> that if "newdate" was a character variable you wouldn't get a plot at
> all, and if it is a factor, a few of the labels might identify what
> went wrong.
>
> Jim
>
> > On April 14, 2015 5:04:48 PM PDT, Dot Lundberg <dotlundberg at gmail.com>
> > wrote:
> >>New to R. Having trouble with the xaxis in this code. The tick marks
> >>are
> >>crazy and the labels repeat. Any suggestions?
> >>
> >>par(mar=c(5,5,5,5))
> >>
>
> >>plot(LPB_PPT_R$newdate,LPB_PPT_R$Rain_cm,pch=0,type="l",col="black",yaxt="n",ylim=c(0,8),ylab="")
> >>axis(side=2, at=c(0,2,4,6,8))
> >>mtext("Precipitation (cm)", side = 2, line=2.5, at=4)
> >>mtext("Date", side=1, line=2.5)
> >>axis.Date(1, at=seq(min(LPB_PPT_R$newdate),
> >>max(LPB_PPT_R$newdate),las=2,by="1 weeks"),format="%m-%Y")
> >>
> >>par(new=TRUE)
> >>
>
> >>plot(LPB_PPT_R$newdate,LPB_PPT_R$Cum_PPT,pch=1,type="l",col="grey",yaxt="n",ylim=c(0,100),
> >>ylab="")
> >>axis(side=4, at=c(0,50,100))
> >>mtext("Cumulative Precipitation (cm)", side=4, line=2.5, at=50,
> >>col="grey")
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >>______________________________________________
> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide
> >>http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
>

From rafaelcarneirocosta.rc at gmail.com  Mon May  4 02:58:34 2015
From: rafaelcarneirocosta.rc at gmail.com (Rafael Costa)
Date: Sun, 3 May 2015 21:58:34 -0300
Subject: [R] Downloading file.Rdata from internet
Message-ID: <CAOy3Z4Ao3Ud=ppkaFgK9W+yV8U8KxMb-=xzGicuReLzCCxKyVg@mail.gmail.com>

Dear R users,

To load the file into "http://www.datafilehost.com/d/c7f0d342", I first
uncheck the "Use our download manager and get recommended downloads" option
and I click the "DOWNLOAD" button. How do I load and save the file directly
from R?

Any help on this is most appreciated.

Thanks in advance,
Rafael Costa.

	[[alternative HTML version deleted]]


From arshad25 at gmail.com  Mon May  4 07:20:01 2015
From: arshad25 at gmail.com (Arshad Mohamed)
Date: Mon, 4 May 2015 08:20:01 +0300
Subject: [R] Seasonal pattern analysis
Message-ID: <CAAGFQQJpyAyzyYXEB3=S1KN=au8ciDMH4mn5YopMxE-u_tF1LA@mail.gmail.com>

Hello everyone,

I want to do a seasonal pattern analysis of a disease incidence. I have the
data on incidence number in each month for 3 years. I saw a good package
called "season" in R. But it looks like it does the analysis for monthly,
weekly or daily fashion. But I need to do the analysis for summer, winter,
spring and autumn. Can anybody give me some help on choosing most suitable
package to do this?

Thanks much
ARshad

-- 
:jak

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Mon May  4 08:37:28 2015
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Mon, 4 May 2015 09:37:28 +0300
Subject: [R] Seasonal pattern analysis
In-Reply-To: <CAAGFQQJpyAyzyYXEB3=S1KN=au8ciDMH4mn5YopMxE-u_tF1LA@mail.gmail.com>
References: <CAAGFQQJpyAyzyYXEB3=S1KN=au8ciDMH4mn5YopMxE-u_tF1LA@mail.gmail.com>
Message-ID: <CAGh51gSex5imG_0ZCkykycwj+0hXNjfGs635Djdy98m8zd=KSg@mail.gmail.com>

Hi,

I suggest you use* ts* function which can create timeseries object of your
data. You can also use* subset* function to subset the data for some
particular months.  I am not sure whether this can help since I don't have
your data to try.

All the best!

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Mon, May 4, 2015 at 8:20 AM, Arshad Mohamed <arshad25 at gmail.com> wrote:

> Hello everyone,
>
> I want to do a seasonal pattern analysis of a disease incidence. I have the
> data on incidence number in each month for 3 years. I saw a good package
> called "season" in R. But it looks like it does the analysis for monthly,
> weekly or daily fashion. But I need to do the analysis for summer, winter,
> spring and autumn. Can anybody give me some help on choosing most suitable
> package to do this?
>
> Thanks much
> ARshad
>
> --
> :jak
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From luysgarcia at gmail.com  Mon May  4 09:52:51 2015
From: luysgarcia at gmail.com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Mon, 4 May 2015 04:52:51 -0300
Subject: [R] Fwd: Question about paired plotting
In-Reply-To: <CANxP2S4MST4k5yDFOpg7JV7f31t7CcEOGZb706gU0WZ71-8Kmw@mail.gmail.com>
References: <CANxP2S4MST4k5yDFOpg7JV7f31t7CcEOGZb706gU0WZ71-8Kmw@mail.gmail.com>
Message-ID: <CANxP2S736TqD0A33V84r2zM7VBwh+HNjawFHY78s=0xdFs7Q=A@mail.gmail.com>

Hello R experts,

I just found a new paper which shows the proper way (according to the
authors) to show data, specially paired. I am very interested in presenting
this kind of data, specially the scatter plott.  I have found a way to
present it using this link:

http://journals.plos.org/plosbiology/article?id=10.1371%2Fjournal.pbio.1002128#pbio.1002128.s007

Nevertheless, I wanted to know if you know some example which allows me to
produce a plot similar to the plots 2B-2D. I could do it by "hand" but it
was quite time consuming and required editing the pictures,

Many thanks for any help you can provide!

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon May  4 10:16:25 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 4 May 2015 01:16:25 -0700
Subject: [R] Downloading file.Rdata from internet
In-Reply-To: <CAOy3Z4Ao3Ud=ppkaFgK9W+yV8U8KxMb-=xzGicuReLzCCxKyVg@mail.gmail.com>
References: <CAOy3Z4Ao3Ud=ppkaFgK9W+yV8U8KxMb-=xzGicuReLzCCxKyVg@mail.gmail.com>
Message-ID: <1F93ECE3-B22A-434E-B32E-F9868106E181@comcast.net>


On May 3, 2015, at 5:58 PM, Rafael Costa wrote:

> Dear R users,
> 
> To load the file into "http://www.datafilehost.com/d/c7f0d342", I first
> uncheck the "Use our download manager and get recommended downloads" option
> and I click the "DOWNLOAD" button. How do I load and save the file directly
> from R?

Its name suggests it is a file that has been saved from R. If you have the same version of R as the person who created it, you should be able to double-click the file from a GUI interface and have it loaded into an R session.

I don't understand the request to save it. It is already in the format that would be created by saving it from an R session.

> 
> Any help on this is most appreciated.
> 
> Thanks in advance,
> Rafael Costa.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Mon May  4 10:30:22 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 4 May 2015 18:30:22 +1000
Subject: [R] Fwd: Question about paired plotting
In-Reply-To: <CANxP2S736TqD0A33V84r2zM7VBwh+HNjawFHY78s=0xdFs7Q=A@mail.gmail.com>
References: <CANxP2S4MST4k5yDFOpg7JV7f31t7CcEOGZb706gU0WZ71-8Kmw@mail.gmail.com>
	<CANxP2S736TqD0A33V84r2zM7VBwh+HNjawFHY78s=0xdFs7Q=A@mail.gmail.com>
Message-ID: <CA+8X3fVoX=+0tVF4cNCGnYO+Lq75EgtbLr0avHYedRqEE-3wdw@mail.gmail.com>

Hi Luis,
Two plotting functions from the plotrix package might be of interest.
One is "ladderplot" that is very similar to the upper plots in the
panels, and the second is "ehplot" that is similar to the lower
panels.

Jim


On Mon, May 4, 2015 at 5:52 PM, Luis Fernando Garc?a
<luysgarcia at gmail.com> wrote:
> Hello R experts,
>
> I just found a new paper which shows the proper way (according to the
> authors) to show data, specially paired. I am very interested in presenting
> this kind of data, specially the scatter plott.  I have found a way to
> present it using this link:
>
> http://journals.plos.org/plosbiology/article?id=10.1371%2Fjournal.pbio.1002128#pbio.1002128.s007
>
> Nevertheless, I wanted to know if you know some example which allows me to
> produce a plot similar to the plots 2B-2D. I could do it by "hand" but it
> was quite time consuming and required editing the pictures,
>
> Many thanks for any help you can provide!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lalitha.viswanathan79 at gmail.com  Mon May  4 10:40:11 2015
From: lalitha.viswanathan79 at gmail.com (Lalitha Viswanathan)
Date: Mon, 4 May 2015 14:10:11 +0530
Subject: [R] Request for functions to calculate correlated factors
 influencing an outcome.
In-Reply-To: <CAM04ykANAbyNifjhu3AKAf88qvqDWjRnASM3Fb_LV6WE3jpX5g@mail.gmail.com>
References: <CAMeJHHApBUdmm8_meZ=wy=QdvbV_96+7+kgsaS1s=+EDjTufPg@mail.gmail.com>
	<CAM04ykANAbyNifjhu3AKAf88qvqDWjRnASM3Fb_LV6WE3jpX5g@mail.gmail.com>
Message-ID: <CAMeJHHDiTbaeMNJZftHaUua-JjLp6JTm6twAH4JyGj4PDbUh0A@mail.gmail.com>

Hi
I used the MASS library
library(MASS)  (by reading about examples at
http://www.statmethods.net/stats/regression.html
<http://s.bl-1.com/h/ofLlK27?url=http://www.statmethods.net/stats/regression.html>
)
fit <- lm(Mileage~Disp+HP+Weight+Reliability,data=newx)
step <- stepAIC(fit, direction="both")
step$anova # display results

It showed the most relevant variables affecting Mileage.
While that is a start, I am looking for a model that fits the entire data
(including Mileage), not factors that influence Mileage.

Multi model inference / selection.

I was reading about glmulti.
Are there any other packages I could look at, for infering models that best
fit the data.

To use nlm / nls, I need a formula, as one of the parameters to best fit
the data and I am looking for functions that will help infer that formula
from the data.

Thanks
lalitha

On Sun, May 3, 2015 at 11:33 PM, Prashant Sethi <theseth.prashant at gmail.com>
wrote:

> Hi,
>
> I'm not an expert in data analysis (a beginner still learning tricks of
> the trade) but I believe in your case since you're trying to determine the
> correlation of a dependent variable with a number of factor variables, you
> should try doing the regression analysis of your model. The function you'll
> use for that is the lm() function. You can use the forward building or the
> backward elimination method to build your model with the most critical
> factors included.
>
> Maybe you can give it a try.
>
> Thanks and regards,
> Prashant Sethi
> On 3 May 2015 23:18, "Lalitha Viswanathan" <
> lalitha.viswanathan79 at gmail.com> wrote:
>
>> Hi
>> I am sorry, I saved the file removing the dot after the Disp (as I was
>> going wrong on a read.delim which threw an error about !header, etc...The
>> dot was not the culprit, but I continued to leave it out.
>> Let me paste the full code here.
>> x<-read.table("/Users/Documents/StatsTest/fuelEfficiency.txt",
>> header=TRUE,
>> sep="\t")
>> x<-data.frame(x)
>> for (i in unique(x$Country)) { print (i); y <- subset(x, x$Country == i);
>> print(y); }
>> newx <- subset (x, select = c(Price, Reliability, Mileage, Weight, Disp,
>> HP))
>> cor(newx, method="pearson")
>> my.cor <-cor.test(newx$Weight, newx$Price, method="spearman")
>> my.cor <-cor.test(newx$Weight, newx$HP, method="spearman")
>> my.cor <-cor.test(newx$Disp, newx$HP, method="spearman")
>> Putting exact=NULL still doesn't remove the warning
>> my.cor <-cor.test(newx$Disp, newx$HP, method="kendall", exact=NULL)
>> I tried to find the correlation coeff for a various combination of
>> variables, but am unable to interpet the results. (Results pasted below in
>> an earlier post)
>>
>> Followed it up with a normality test
>> shapiro.test(newx$Disp)
>> shapiro.test(newx$HP)
>>
>> Then decided to do a kruskal.test(newx)
>> with the result
>> Kruskal-Wallis chi-squared = 328.94, df = 5, p-value < 2.2e-16
>>
>> Question is : I am trying to find factors influencing efficiency (in this
>> case mileage)
>>
>> What are the range of functions / examples I should be looking at, to find
>> a factor or combination of factors influencing efficiency?
>>
>> Any pointers will be helpful
>>
>> Thanks
>> Lalitha
>>
>> On Sun, May 3, 2015 at 2:49 PM, Lalitha Viswanathan <
>> lalitha.viswanathan79 at gmail.com> wrote:
>>
>> > Hi
>> > I have a dataset of the type attached.
>> > Here's my code thus far.
>> > dataset <-data.frame(read.delim("data", sep="\t", header=TRUE));
>> > newData<-subset(dataset, select = c(Price, Reliability, Mileage, Weight,
>> > Disp, HP));
>> > cor(newData, method="pearson");
>> > Results are
>> >                  Price Reliability    Mileage     Weight       Disp
>> >   HP
>> > Price        1.0000000          NA -0.6537541  0.7017999  0.4856769
>> >  0.6536433
>> > Reliability         NA           1         NA         NA         NA
>> >   NA
>> > Mileage     -0.6537541          NA  1.0000000 -0.8478541 -0.6931928
>> > -0.6667146
>> > Weight       0.7017999          NA -0.8478541  1.0000000  0.8032804
>> >  0.7629322
>> > Disp         0.4856769          NA -0.6931928  0.8032804  1.0000000
>> >  0.8181881
>> > HP           0.6536433          NA -0.6667146  0.7629322  0.8181881
>> >  1.0000000
>> >
>> > It appears that Wt and Price, Wt and Disp, Wt and HP, Disp and HP, HP
>> and
>> > Price are strongly correlated.
>> > To find the statistical significance,
>> > I am trying  sample.correln<-cor.test(newData$Disp, newData$HP,
>> > method="kendall", exact=NULL)
>> > Kendall's rank correlation tau
>> >
>> > data:  newx$Disp and newx$HP
>> > z = 7.2192, p-value = 5.229e-13
>> > alternative hypothesis: true tau is not equal to 0
>> > sample estimates:
>> >       tau
>> > 0.6563871
>> >
>> > If I try the same with
>> > sample.correln<-cor.test(newData$Disp, newData$HP, method="pearson",
>> > exact=NULL)
>> > I get Warning message:
>> > In cor.test.default(newx$Disp, newx$HP, method = "spearman", exact =
>> NULL)
>> > :
>> >   Cannot compute exact p-value with ties
>> > > sample.correln
>> >
>> > Spearman's rank correlation rho
>> >
>> > data:  newx$Disp and newx$HP
>> > S = 5716.8, p-value < 2.2e-16
>> > alternative hypothesis: true rho is not equal to 0
>> > sample estimates:
>> >       rho
>> > 0.8411566
>> >
>> > I am not sure how to interpret these values.
>> > Basically, I am trying to figure out which combination of factors
>> > influences efficiency.
>> >
>> > Thanks
>> > Lalitha
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon May  4 11:48:55 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 4 May 2015 09:48:55 +0000
Subject: [R] Problem in r help me
In-Reply-To: <CADG8gktkT7DTzjVr6f957Fcg-=9-4rhv=fFhajvz+pFoi+oFgQ@mail.gmail.com>
References: <CADG8gktu_zJ8Ex0Sx1yo=wYd6dV=f_ZTXrQ8BWcF+OediaYf-g@mail.gmail.com>
	<CADG8gktkT7DTzjVr6f957Fcg-=9-4rhv=fFhajvz+pFoi+oFgQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2C67A@SRVEXCHMBX.precheza.cz>

Hi

Your question is rather cryptic. Data? Code?

You can use internet search to get info about methods

e.g

R hierarchical clustering

gives me many answer regarding clustering in R.

Be more specific to get more specific answer

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ghada
> Almousa
> Sent: Saturday, May 02, 2015 11:03 AM
> To: r-help at r-project.org
> Subject: Re: [R] Problem in r help me
>
> > hello dears
> >
> > I have Search to compare the results between the three types of
> > cluster k-maen ,Em and  Hierarchal clusters How i figured the number
> > of iterations , the time required to build each Cluster ,accuracy
> and
> > sum square error SSE for each cluster in the R programming
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Mon May  4 15:24:40 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 4 May 2015 13:24:40 +0000
Subject: [R] help - hoslem.test
In-Reply-To: <1430743539.21126.YahooMailBasic@web120205.mail.ne1.yahoo.com>
References: <1430743539.21126.YahooMailBasic@web120205.mail.ne1.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2C7C6@SRVEXCHMBX.precheza.cz>

Hi

thanks for data.

na.exclude does not excludes NA values. Actually it computes result without considering NAs but keeps those NA values in propper positions so that the result has the same length as input

Instead of several ifelse you can use

q131 <- as.numeric(cut(id3$q13,c(0,1.5,5)))-1

fitted values start with NA values

> fitted(tp1)
        1241         1242         1243         1244         1245         1246
          NA           NA 2.143345e-11 2.143345e-11 2.143345e-11 2.143345e-11
        1247         1248         1256         1268
2.143345e-11 2.143345e-11 2.143345e-11 2.143345e-11

which obviously hoslem.test is not adapted to.

>
> #Error in quantile.default(yhat, probs = seq(0, 1, 1/g)) :
>  # missing values and NaN's not allowed if 'na.rm' is FALSE

you can use glm without na.action and your fitted values will be without NA.

> tp1 <- glm(q131 ~ q11 + q10+q12+edcat + q08+q06+ q14, family = binomial(link = "logit"), data=id3)
> fitted(tp1)
        1243         1244         1245         1246         1247         1248
2.143345e-11 2.143345e-11 2.143345e-11 2.143345e-11 2.143345e-11 2.143345e-11
        1256         1268
2.143345e-11 2.143345e-11

however
tp1$q131 does not exist

> tp1$q131
NULL
So again, test throws error.

Maybe you wanted

> hoslem.test(na.omit(id3$q131), fitted(tp1), g=10)

        Hosmer and Lemeshow goodness of fit (GOF) test

data:  na.omit(id3$q131), fitted(tp1)
X-squared = NaN, df = 8, p-value = NA

Warning message:
In Ops.factor(1, y) : ?-? not meaningful for factors

However q131 is factor (actually you changed it to factor)

If I change it to numeric

> id3$q131<-q131
> tp1 <- glm(q131 ~ q11 + q10+q12+edcat + q08+q06+ q14, family = binomial(link = "logit"), data=id3)
> hoslem.test(na.omit(id3$q131), fitted(tp1), g=10)

        Hosmer and Lemeshow goodness of fit (GOF) test

data:  na.omit(id3$q131), fitted(tp1)
X-squared = NaN, df = 8, p-value = NA

hoslem test works - at least it does not throw errors.

So best way for you would be to understand basic differences in object types (numeric, factor, ....) by reading R intro and think about what hoslem test needs as an input.

Cheers
Petr

> -----Original Message-----
> From: Luciane Maria Pilotto [mailto:lutipilotto at yahoo.com.br]
> Sent: Monday, May 04, 2015 2:46 PM
> To: r-help at r-project.org; PIKAL Petr
> Subject: RE: [R] help - hoslem.test
>
> Hi
>
> I'm trying to make a reproducible example using the command "dput" as
> fallows.
>
> The problem occurs when running the test of Hosmer and Lemeshow
> (hoslem.test) for residuals gives error. I'm using the command
> "na.action" to exclude the NA values.
>
> Thanks,
> Luciane
>
> ###############################################
>
> load(file.choose())#dataframe:"id3.rda"
> attach(id3)
>

<snip>

>
> #create binary outcome variable (q13) (transformando q13 em bin?ria)
> q131<-ifelse(q13==1,0,ifelse(q13==2,1,ifelse(q13==3,1,
> ifelse(q13==4,1,ifelse(q13==5,1,NA)))))

Instead of several ifelse you can use

q131 <- as.numeric(cut(id3$q13,c(0,1.5,5)))-1

> id3<-cbind(id3,q131)
> id3$q131 <- as.factor(id3$q131)
>
> str(id3)
>
> tp1 <- glm(q131 ~ q11 + q10+q12+edcat + q08+q06+ q14, family =
> binomial(link = "logit"), data=id3, na.action="na.exclude")
> tp1
>
> library(ResourceSelection)
> hoslem.test(tp1$q131, fitted(tp1), g=10)
>
>
>
>
> --------------------------------------------
> Em sex, 1/5/15, PIKAL Petr <petr.pikal at precheza.cz> escreveu:
>
>  Assunto: RE: [R] help - hoslem.test
>  Para: "Luciane Maria Pilotto" <lutipilotto at yahoo.com.br>, "r-help at r-
> project.org" <r-help at r-project.org>
>  Data: Sexta-feira, 1 de Maio de 2015, 3:59
>
>  Hi
>
>  > -----Original Message-----
>  > From: Luciane Maria Pilotto [mailto:lutipilotto at yahoo.com.br]
>  > Sent: Friday, May 01, 2015 12:49 AM
>  > To: PIKAL Petr; r-help at r-project.org;
>  John Kane
>  > Subject: Re: [R] help -
>  hoslem.test
>  >
>  > Ok, in
>  dropbox link below you can download the bank.
>  > (https://www.dropbox.com/s/9qrdf4mhd6tzypi/id3.rda?dl=0)
>
>  No. Not everybody is alowed to
>  use dropbox. Try to post result of
>
>  dput(id3)
>
>  directly to your post.
>
>  Cheers
>  Petr
>
>  >
>  > I change the script
>  following the suggestions, but the error persists.
>  > I used the the na.action command to delete
>  the lost values.
>  >
>  >
>
> #######################################################################
>  >
>  >
>  load("id3.rda")
>  >
>  attach(id3)
>  >
>  >
>  #transformando q13 em bin?ria (o/1)
>  >
>  q131<-ifelse(q13==1,0,ifelse(q13==2,1,ifelse(q13==3,1,
>  > ifelse(q13==4,1,ifelse(q13==5,1,NA)))))
>  > id3<-cbind(id3,q131)
>  > id3$q131 <- as.factor(id3$q131)
>  > str(id3)
>  >
>  > tp1 <- glm(q131 ~ q11 + q10+q12+edcat +
>  q08+q06+ q14, family =
>  > binomial(link =
>  "logit"), data=id3,
>  na.action="na.exclude")
>  >
>  tp1
>  > hoslem.test(tp1$q131, fitted(tp1),
>  g=10)
>  >
>  >
>  >
>  >
>  --------------------------------------------
>  > Em qui, 30/4/15, John Kane <jrkrideau at inbox.com>
>  escreveu:
>  >
>  >
>  Assunto: Re: [R] help - hoslem.test
>  >
>  Para: "PIKAL Petr" <petr.pikal at precheza.cz>,
>  "Luciane Maria Pilotto"
>  >
>  <lutipilotto at yahoo.com.br>,
>  "r-help at r-project.org"
>  <r-help at r-
>  > project.org>
>  >
>  Data: Quinta-feira, 30 de Abril de 2015, 11:51
>  >
>  >  Kevin Thorpe
>  pointed out
>  >  to me that there is a
>  dropbox link at the very bottom of the
>  >  post that I missed. :(
>  >
>  >  I
>  >  just downloaded it, read it in and it
>  looks fine.
>  >
>  >  John
>  Kane
>  >  Kingston ON Canada
>  >
>  >
>  >  > -----Original
>  >  Message-----
>  >  >
>  From: petr.pikal at precheza.cz
>  >  > Sent: Thu, 30 Apr 2015 14:25:23
>  +0000
>  >  > To: lutipilotto at yahoo.com.br,
>  >  r-help at r-project.org
>  >  > Subject: Re: [R] help -
>  hoslem.test
>  >  >
>  >  > Hi
>  >  >
>  >  > I agree with John
>  >  >
>  >  > Just
>  small
>  >  refinements in lines
>  >  >
>  >  >>
>  -----Original Message-----
>  >
>  >>> -----Original Message-----
>  >  >>> From: lutipilotto at yahoo.com.br
>  >  >>> Sent: Thu, 30 Apr 2015
>  04:24:32
>  >  -0700
>  >
>  >>> To: r-help at r-project.org,
>  >  jrkrideau at inbox.com
>  >  >>> Subject: RE: [R] help -
>  >  hoslem.test
>  >
>  >>>
>  >  >>>
>  load("id3.rda")
>  >  >>
>  And what is this?
>  >  >>
>  >  >> We do not
>  >  have access to your office or computer
>  hard disc.
>  >  >>
>  >  >> Please read
>  >  http://stackoverflow.com/questions/5963269/how-to-make-a-
>  >  >> great-r-reproducible-example,
>  see
>  >  ?dput for sending data?
>  >  >>
>  >  >>
>  It is very unlikely anyone here can
>  >
>  help if we have no data.
>  >  >>
>  >  >>
>  >
>  >>>
>  >  attach(id3)
>  >  >
>  >  > Do
>  >  not use attach. It prevents from
>  modifiyng id3.
>  >  >
>  >  >>>
>  >
>  >>> #transformando q13 em bin?ria
>  >  >>>
>  >
>  q131<-ifelse(q13==1,1,ifelse(q13==2,2,ifelse(q13==3,2,
>  >  >>>
>  >
>  ifelse(q13==4,2,ifelse(q13==5,2,NA)))))
>  >  >
>  >
>  >  > q131 <- as.numeric(cut(q13,
>  >  c(0,1.5,5)))
>  >
>  >
>  >  >>
>  >
>  x<-1:7
>  >  >> x
>  >  >
>  >  [1] 1 2 3 4
>  5 6 7
>  >  >> as.numeric(cut(x,
>  >  c(0,1.5,5)))
>  >  >
>  [1]  1  2  2  2  2 NA
>  >  NA
>  >  >
>  >
>  >>>
>  >
>  id3<-cbind(id3,q131)
>  >  >
>  >  > rather dangerous in case id3 is
>  not
>  >  data.frame but matrix
>  >  >
>  >  >>>
>  id3$q131 <-
>  >  as.factor(id3$q131)
>  >  >>>
>  >
>  >>> tp1 <- glm(q131 ~ q11 +
>  >  q10+q12+edcat + q08+q06+ q14, family
>  =
>  >  >>> binomial(link =
>  >  "logit"), data=id3)
>  >  >>>
>  >
>  tp1
>  >  >>>
>  >  >>>
>  library(ResourceSelection)
>  >
>  >>> hoslem.test(tp1$q131, fitted(tp1),
>  >  g=10)
>  >  >
>  >  > hoslem.test
>  >
>  expects x to be a numeric vector of observations, binary
>  >  > (0/1).
>  >  >
>  If I
>  >  understand correctly tp1$q131
>  have values 1, 2 or NA.
>  >  >
>  >  > Cheers
>  >  >
>  Petr
>  >  >
>  >
>  >>>
>  >  >>>
>  >  dataframe: https://www.dropbox.com/s/9qrdf4mhd6tzypi/id3.rda?dl=0
>  >  >>>
>  >
>  >>>
>  >  >>>
>  >
>  __________________________________________________
>  >  >>> Luciane Maria Pilotto
>  >  >>> Mestre e Doutoranda em
>  Sa?de
>  >  Bucal Coletiva - FO/UFRGS
>  >  >>> NDE
>  >
>  Odontologia - UNIVATES
>  >
>  >>>
>  >  Telefone: (51)
>  84512344
>  >  >>>
>  >  >>>
>  >
>  --------------------------------------------
>  >  >>> Em qui, 30/4/15, John Kane
>  <jrkrideau at inbox.com>
>  >  escreveu:
>  >
>  >>>
>  >  >>>  Assunto:
>  RE: [R] help -
>  >  hoslem.test
>  >  >>>  Para:
>  >  "Luciane Maria Pilotto" <lutipilotto at yahoo.com.br>,
>  >  >>> r-help at r-project.org
>  >  >>>  Data: Quinta-feira, 30 de
>  Abril
>  >  de 2015, 7:52
>  >  >>>
>  >
>  >>>  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-
>  >  >> reproducible-example
>  >  >>>
>  >
>  >>>
>  >  John Kane
>  >  >>>  Kingston ON
>  >  Canada
>  >
>  >>>
>  >  >>>
>  >  >>>
>  >  >
>  -----Original Message-----
>  >
>  >>>  > From: lutipilotto at yahoo.com.br
>  >  >>>  > Sent: Wed, 29 Apr
>  2015
>  >  18:45:26 -0700
>  >  >>>  > To: r-help at r-project.org
>  >  >>>  > Subject: [R] help
>  -
>  >  hoslem.test
>  >
>  >>>  >
>  >  >>>
>  > Hello,
>  >  >>>  >
>  >  >>>  > I'm working
>  with
>  >  >>>  ordinal logistic
>  regression
>  >  model (polr) and would
>  like
>  >  >>>
>  >  > to test the proportional odds
>  assumption.
>  >  >>>  For this,
>  I ran the binary
>  >  >>>  >
>  logistic
>  >  >>>  regressions
>  with varying
>  >  cutpoints on the
>  dependent
>  >  >>>
>  >  variable, as
>  >
>  >>>  > described
>  >  in the
>  following
>  >  >>>  commands.
>  >  When running the test of Hosmer and
>  >  >>>  > Lemeshow
>  (hoslem.test) for
>  >  residuals gives
>  >  >>>  error.
>  >  >>>  >
>  >  >>>  > Thanks,
>  >  >>>  > Luciane
>  >  >>>  >
>  >  >>>  >
>  >  >>>
>  >
>  ______________________________________________
>  >  >>>  > R-help at r-project.org
>  >  >>>  mailing list -- To
>  UNSUBSCRIBE
>  >  and more, see
>  >  >>>  > https://stat.ethz.ch/mailman/listinfo/r-help
>  >  >>>  > PLEASE do read the
>  posting
>  >  guide
>  >
>  >>>  > http://www.R-project.org/posting-guide.html
>  >  >>>  > and provide
>  commented,
>  >  minimal,
>  >  >>>  self-contained,
>  >  reproducible code.
>  >  >>>
>  >
>

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From bretschr at xs4all.nl  Mon May  4 15:38:41 2015
From: bretschr at xs4all.nl (Franklin Bretschneider)
Date: Mon, 4 May 2015 15:38:41 +0200
Subject: [R] [R-SIG-Mac] Unsubscribe from the list
In-Reply-To: <55476783.6050206@elremanso.com>
References: <55476783.6050206@elremanso.com>
Message-ID: <F7F34E92-CE0A-4189-9982-493B12787055@xs4all.nl>

Hi Silvia Solis,

Re:

> Hi,
> 
> I wanted to ask you to scratch this email address from the mailing 
> list.  This is a work address and I already receive your emails con my 
> personal account.  My mistake this one time I replied from a different 
> email address.
> 
> Thanks!
> 
> Silvia
> -- 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Mac mailing list
> R-SIG-Mac at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mac


The instructions to unsubscribe are at the end of every message. It is:
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help


Succes,


Frank
---

Franklin Bretschneider
Dept of Biology
Utrecht University
bretschr at xs4all.nl


From gunter.berton at gene.com  Mon May  4 15:55:16 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 4 May 2015 06:55:16 -0700
Subject: [R] Request for functions to calculate correlated factors
 influencing an outcome.
In-Reply-To: <CAMeJHHDiTbaeMNJZftHaUua-JjLp6JTm6twAH4JyGj4PDbUh0A@mail.gmail.com>
References: <CAMeJHHApBUdmm8_meZ=wy=QdvbV_96+7+kgsaS1s=+EDjTufPg@mail.gmail.com>
	<CAM04ykANAbyNifjhu3AKAf88qvqDWjRnASM3Fb_LV6WE3jpX5g@mail.gmail.com>
	<CAMeJHHDiTbaeMNJZftHaUua-JjLp6JTm6twAH4JyGj4PDbUh0A@mail.gmail.com>
Message-ID: <CACk-te0FX=U4kiQqbW2bc2boNHfKo+qXOJpzOTPUn9GJ3fsx+Q@mail.gmail.com>

This would be better posted on a statistical list like
stats.stackexchange.com, as it is largely about statistical
methodology, not R code. Once you have determined what kinds of
methods you want, you might then post back here -- or better yet, just
search! -- for packages that implement those methods in R.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, May 4, 2015 at 1:40 AM, Lalitha Viswanathan
<lalitha.viswanathan79 at gmail.com> wrote:
> Hi
> I used the MASS library
> library(MASS)  (by reading about examples at
> http://www.statmethods.net/stats/regression.html
> <http://s.bl-1.com/h/ofLlK27?url=http://www.statmethods.net/stats/regression.html>
> )
> fit <- lm(Mileage~Disp+HP+Weight+Reliability,data=newx)
> step <- stepAIC(fit, direction="both")
> step$anova # display results
>
> It showed the most relevant variables affecting Mileage.
> While that is a start, I am looking for a model that fits the entire data
> (including Mileage), not factors that influence Mileage.
>
> Multi model inference / selection.
>
> I was reading about glmulti.
> Are there any other packages I could look at, for infering models that best
> fit the data.
>
> To use nlm / nls, I need a formula, as one of the parameters to best fit
> the data and I am looking for functions that will help infer that formula
> from the data.
>
> Thanks
> lalitha
>
> On Sun, May 3, 2015 at 11:33 PM, Prashant Sethi <theseth.prashant at gmail.com>
> wrote:
>
>> Hi,
>>
>> I'm not an expert in data analysis (a beginner still learning tricks of
>> the trade) but I believe in your case since you're trying to determine the
>> correlation of a dependent variable with a number of factor variables, you
>> should try doing the regression analysis of your model. The function you'll
>> use for that is the lm() function. You can use the forward building or the
>> backward elimination method to build your model with the most critical
>> factors included.
>>
>> Maybe you can give it a try.
>>
>> Thanks and regards,
>> Prashant Sethi
>> On 3 May 2015 23:18, "Lalitha Viswanathan" <
>> lalitha.viswanathan79 at gmail.com> wrote:
>>
>>> Hi
>>> I am sorry, I saved the file removing the dot after the Disp (as I was
>>> going wrong on a read.delim which threw an error about !header, etc...The
>>> dot was not the culprit, but I continued to leave it out.
>>> Let me paste the full code here.
>>> x<-read.table("/Users/Documents/StatsTest/fuelEfficiency.txt",
>>> header=TRUE,
>>> sep="\t")
>>> x<-data.frame(x)
>>> for (i in unique(x$Country)) { print (i); y <- subset(x, x$Country == i);
>>> print(y); }
>>> newx <- subset (x, select = c(Price, Reliability, Mileage, Weight, Disp,
>>> HP))
>>> cor(newx, method="pearson")
>>> my.cor <-cor.test(newx$Weight, newx$Price, method="spearman")
>>> my.cor <-cor.test(newx$Weight, newx$HP, method="spearman")
>>> my.cor <-cor.test(newx$Disp, newx$HP, method="spearman")
>>> Putting exact=NULL still doesn't remove the warning
>>> my.cor <-cor.test(newx$Disp, newx$HP, method="kendall", exact=NULL)
>>> I tried to find the correlation coeff for a various combination of
>>> variables, but am unable to interpet the results. (Results pasted below in
>>> an earlier post)
>>>
>>> Followed it up with a normality test
>>> shapiro.test(newx$Disp)
>>> shapiro.test(newx$HP)
>>>
>>> Then decided to do a kruskal.test(newx)
>>> with the result
>>> Kruskal-Wallis chi-squared = 328.94, df = 5, p-value < 2.2e-16
>>>
>>> Question is : I am trying to find factors influencing efficiency (in this
>>> case mileage)
>>>
>>> What are the range of functions / examples I should be looking at, to find
>>> a factor or combination of factors influencing efficiency?
>>>
>>> Any pointers will be helpful
>>>
>>> Thanks
>>> Lalitha
>>>
>>> On Sun, May 3, 2015 at 2:49 PM, Lalitha Viswanathan <
>>> lalitha.viswanathan79 at gmail.com> wrote:
>>>
>>> > Hi
>>> > I have a dataset of the type attached.
>>> > Here's my code thus far.
>>> > dataset <-data.frame(read.delim("data", sep="\t", header=TRUE));
>>> > newData<-subset(dataset, select = c(Price, Reliability, Mileage, Weight,
>>> > Disp, HP));
>>> > cor(newData, method="pearson");
>>> > Results are
>>> >                  Price Reliability    Mileage     Weight       Disp
>>> >   HP
>>> > Price        1.0000000          NA -0.6537541  0.7017999  0.4856769
>>> >  0.6536433
>>> > Reliability         NA           1         NA         NA         NA
>>> >   NA
>>> > Mileage     -0.6537541          NA  1.0000000 -0.8478541 -0.6931928
>>> > -0.6667146
>>> > Weight       0.7017999          NA -0.8478541  1.0000000  0.8032804
>>> >  0.7629322
>>> > Disp         0.4856769          NA -0.6931928  0.8032804  1.0000000
>>> >  0.8181881
>>> > HP           0.6536433          NA -0.6667146  0.7629322  0.8181881
>>> >  1.0000000
>>> >
>>> > It appears that Wt and Price, Wt and Disp, Wt and HP, Disp and HP, HP
>>> and
>>> > Price are strongly correlated.
>>> > To find the statistical significance,
>>> > I am trying  sample.correln<-cor.test(newData$Disp, newData$HP,
>>> > method="kendall", exact=NULL)
>>> > Kendall's rank correlation tau
>>> >
>>> > data:  newx$Disp and newx$HP
>>> > z = 7.2192, p-value = 5.229e-13
>>> > alternative hypothesis: true tau is not equal to 0
>>> > sample estimates:
>>> >       tau
>>> > 0.6563871
>>> >
>>> > If I try the same with
>>> > sample.correln<-cor.test(newData$Disp, newData$HP, method="pearson",
>>> > exact=NULL)
>>> > I get Warning message:
>>> > In cor.test.default(newx$Disp, newx$HP, method = "spearman", exact =
>>> NULL)
>>> > :
>>> >   Cannot compute exact p-value with ties
>>> > > sample.correln
>>> >
>>> > Spearman's rank correlation rho
>>> >
>>> > data:  newx$Disp and newx$HP
>>> > S = 5716.8, p-value < 2.2e-16
>>> > alternative hypothesis: true rho is not equal to 0
>>> > sample estimates:
>>> >       rho
>>> > 0.8411566
>>> >
>>> > I am not sure how to interpret these values.
>>> > Basically, I am trying to figure out which combination of factors
>>> > influences efficiency.
>>> >
>>> > Thanks
>>> > Lalitha
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_grt at yahoo.fr  Mon May  4 16:01:59 2015
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Mon, 04 May 2015 16:01:59 +0200
Subject: [R] gdata library 2.16.1
Message-ID: <55477BD7.3090103@yahoo.fr>

Dear list-members,

Since I update gdata library to 2.16.1 version this morning, I have an 
error on the two macs I use (details on system and R versions at the end).

When I load the package, I have this error:

 > library("gdata", 
lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
gdata: read.xls support for 'XLS' (Excel 97-2004) files ENABLED.

gdata: Unable to load perl libaries needed by read.xls()
gdata: to support 'XLSX' (Excel 2007+) files.

gdata: Run the function 'installXLSXsupport()'
gdata: to automatically download and install the perl
gdata: libaries needed to support Excel XLS and XLSX formats.

Then if I try installXLSXsupport(), I get another error:
 > installXLSXsupport()
Error in installXLSXsupport() :
Unable to install Perl XLSX support libraries.

But my perl system seems to be ok:
 > system("perl -v")

This is perl 5, version 16, subversion 3 (v5.16.3) built for 
darwin-thread-multi-2level

and the perl folder is correctly located in 
/Library/Frameworks/R.framework/Versions/3.2/Resources/library/gdata/perl/

And of course if I try to use read.xls, I get an error (xxx.xlsx is a 
valid file):
 > info <- read.xls("xxx.xlsx"), stringsAsFactors=FALSE)
WARNING: Perl module Spreadsheet::ParseXLSX cannot be loaded.
WARNING: Microsoft Excel 2007 'XLSX' formatted files will not be processed.

Does someone have a solution ? (other than saving file in .csv ! )

Thanks

Marc

####################
R version 3.2.0 Patched (2015-05-01 r68301) -- "Full of Ingredients"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)

OS: MacOSX - Yosemite


From rbaer at atsu.edu  Mon May  4 16:35:20 2015
From: rbaer at atsu.edu (Robert Baer)
Date: Mon, 04 May 2015 09:35:20 -0500
Subject: [R] Downloading file.Rdata from internet
In-Reply-To: <CAOy3Z4Ao3Ud=ppkaFgK9W+yV8U8KxMb-=xzGicuReLzCCxKyVg@mail.gmail.com>
References: <CAOy3Z4Ao3Ud=ppkaFgK9W+yV8U8KxMb-=xzGicuReLzCCxKyVg@mail.gmail.com>
Message-ID: <554783A8.3080701@atsu.edu>



On 5/3/2015 7:58 PM, Rafael Costa wrote:
> Dear R users,
>
> To load the file into "http://www.datafilehost.com/d/c7f0d342", I first
> uncheck the "Use our download manager and get recommended downloads" option
> and I click the "DOWNLOAD" button. How do I load and save the file directly
> from R?
>
> Any help on this is most appreciated.
Use the load command:
?load

On windows it might look something like:

load("C:/Users/Rafael Costa/Downloads/tabela1.1.RData")



> Thanks in advance,
> Rafael Costa.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 


Robert W. Baer, Ph.D.
Professor of Physiology
Kirksville College of Osteopathic Medicine
A T Still University of Health Sciences
800 W. Jefferson St
Kirksville, MO 63501
rbaer(at)atsu.edu


	[[alternative HTML version deleted]]


From rbaer at atsu.edu  Mon May  4 16:54:50 2015
From: rbaer at atsu.edu (Robert Baer)
Date: Mon, 04 May 2015 09:54:50 -0500
Subject: [R] gdata library 2.16.1
In-Reply-To: <55477BD7.3090103@yahoo.fr>
References: <55477BD7.3090103@yahoo.fr>
Message-ID: <5547883A.6070006@atsu.edu>



On 5/4/2015 9:01 AM, Marc Girondot wrote:
> Dear list-members,
>
> Since I update gdata library to 2.16.1 version this morning, I have an 
> error on the two macs I use (details on system and R versions at the 
> end).
>
> When I load the package, I have this error:
>
> > library("gdata", 
> lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
> gdata: read.xls support for 'XLS' (Excel 97-2004) files ENABLED.
>
> gdata: Unable to load perl libaries needed by read.xls()
> gdata: to support 'XLSX' (Excel 2007+) files.
>
> gdata: Run the function 'installXLSXsupport()'
> gdata: to automatically download and install the perl
> gdata: libaries needed to support Excel XLS and XLSX formats.
>
> Then if I try installXLSXsupport(), I get another error:
> > installXLSXsupport()
> Error in installXLSXsupport() :
> Unable to install Perl XLSX support libraries.
>
> But my perl system seems to be ok:
> > system("perl -v")
>
> This is perl 5, version 16, subversion 3 (v5.16.3) built for 
> darwin-thread-multi-2level
>
> and the perl folder is correctly located in 
> /Library/Frameworks/R.framework/Versions/3.2/Resources/library/gdata/perl/
>
> And of course if I try to use read.xls, I get an error (xxx.xlsx is a 
> valid file):
> > info <- read.xls("xxx.xlsx"), stringsAsFactors=FALSE)
> WARNING: Perl module Spreadsheet::ParseXLSX cannot be loaded.
> WARNING: Microsoft Excel 2007 'XLSX' formatted files will not be 
> processed.
>
> Does someone have a solution ? (other than saving file in .csv ! )
>
Don't know about this problem, but much has been written on various 
alternatives (e.g., http://www.milanor.net/blog/?p=779)
One of their suggestions is (cross-platform, java-based solution),

require(XLConnect)
wb=loadWorkbook("myfile.xlsx")
df=readWorksheet(wb,sheet="Sheet1",header=TRUE)






> Thanks
>
> Marc
>
> ####################
> R version 3.2.0 Patched (2015-05-01 r68301) -- "Full of Ingredients"
> Copyright (C) 2015 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>
> OS: MacOSX - Yosemite
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 


Robert W. Baer, Ph.D.
Professor of Physiology
Kirksville College of Osteopathic Medicine
A T Still University of Health Sciences
800 W. Jefferson St
Kirksville, MO 63501
rbaer(at)atsu.edu


From rafaelcarneirocosta.rc at gmail.com  Mon May  4 16:56:05 2015
From: rafaelcarneirocosta.rc at gmail.com (Rafael Costa)
Date: Mon, 4 May 2015 11:56:05 -0300
Subject: [R] Downloading file.Rdata from internet
In-Reply-To: <554783A8.3080701@atsu.edu>
References: <CAOy3Z4Ao3Ud=ppkaFgK9W+yV8U8KxMb-=xzGicuReLzCCxKyVg@mail.gmail.com>
	<554783A8.3080701@atsu.edu>
Message-ID: <CAOy3Z4DNHJkD2vq4ZSReapVdVVvwq=2HMU1ahMft0S0a-CEc6g@mail.gmail.com>

Dear David and Robert,

Thank you for your comments. In fact, I created the file. I would just like
to load the file directly from the internet to R. Is there a command to do
the R uncheck the "Use our download manager and get recommended downloads"
and click the "DOWNLOAD" button?

Thanks for you attention,
Rafael Costa.

2015-05-04 11:35 GMT-03:00 Robert Baer <rbaer at atsu.edu>:

>
>
> On 5/3/2015 7:58 PM, Rafael Costa wrote:
>
> Dear R users,
>
> To load the file into "http://www.datafilehost.com/d/c7f0d342" <http://www.datafilehost.com/d/c7f0d342>, I first
> uncheck the "Use our download manager and get recommended downloads" option
> and I click the "DOWNLOAD" button. How do I load and save the file directly
> from R?
>
> Any help on this is most appreciated.
>
>  Use the load command:
> ?load
>
> On windows it might look something like:
>
> load("C:/Users/Rafael Costa/Downloads/tabela1.1.RData")
>
>
>
>  Thanks in advance,
> Rafael Costa.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, seehttps://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> --
>
>
> Robert W. Baer, Ph.D.
> Professor of Physiology
> Kirksville College of Osteopathic Medicine
> A T Still University of Health Sciences
> 800 W. Jefferson St
> Kirksville, MO 63501
> rbaer(at)atsu.edu
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon May  4 17:44:22 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 04 May 2015 08:44:22 -0700
Subject: [R] Downloading file.Rdata from internet
In-Reply-To: <CAOy3Z4DNHJkD2vq4ZSReapVdVVvwq=2HMU1ahMft0S0a-CEc6g@mail.gmail.com>
References: <CAOy3Z4Ao3Ud=ppkaFgK9W+yV8U8KxMb-=xzGicuReLzCCxKyVg@mail.gmail.com>
	<554783A8.3080701@atsu.edu>
	<CAOy3Z4DNHJkD2vq4ZSReapVdVVvwq=2HMU1ahMft0S0a-CEc6g@mail.gmail.com>
Message-ID: <708E063A-AEEE-4441-857B-7D62954F5143@dcn.davis.CA.us>

The answer to this question does not actually involve R. Directly accessing data files is not allowed by that web service. I suspect the reason is that they need to get paid somehow and they don't want you to bypass their ads. You may have better success if you use a paid web server to share your files.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 4, 2015 7:56:05 AM PDT, Rafael Costa <rafaelcarneirocosta.rc at gmail.com> wrote:
>Dear David and Robert,
>
>Thank you for your comments. In fact, I created the file. I would just
>like
>to load the file directly from the internet to R. Is there a command to
>do
>the R uncheck the "Use our download manager and get recommended
>downloads"
>and click the "DOWNLOAD" button?
>
>Thanks for you attention,
>Rafael Costa.
>
>2015-05-04 11:35 GMT-03:00 Robert Baer <rbaer at atsu.edu>:
>
>>
>>
>> On 5/3/2015 7:58 PM, Rafael Costa wrote:
>>
>> Dear R users,
>>
>> To load the file into "http://www.datafilehost.com/d/c7f0d342"
><http://www.datafilehost.com/d/c7f0d342>, I first
>> uncheck the "Use our download manager and get recommended downloads"
>option
>> and I click the "DOWNLOAD" button. How do I load and save the file
>directly
>> from R?
>>
>> Any help on this is most appreciated.
>>
>>  Use the load command:
>> ?load
>>
>> On windows it might look something like:
>>
>> load("C:/Users/Rafael Costa/Downloads/tabela1.1.RData")
>>
>>
>>
>>  Thanks in advance,
>> Rafael Costa.
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________R-help at r-project.org
>mailing list -- To UNSUBSCRIBE and more,
>seehttps://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> --
>>
>>
>> Robert W. Baer, Ph.D.
>> Professor of Physiology
>> Kirksville College of Osteopathic Medicine
>> A T Still University of Health Sciences
>> 800 W. Jefferson St
>> Kirksville, MO 63501
>> rbaer(at)atsu.edu
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Mon May  4 18:58:18 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 4 May 2015 08:58:18 -0800
Subject: [R] Fwd: Question about paired plotting
In-Reply-To: <CANxP2S736TqD0A33V84r2zM7VBwh+HNjawFHY78s=0xdFs7Q=A@mail.gmail.com>
References: <canxp2s4mst4k5ydfopg7jv7f31t7cceogzb706gu0wz71-8kmw@mail.gmail.com>
Message-ID: <45F9962A36A.000006E0jrkrideau@inbox.com>

Hi Luis,
Ah yes, that paper.  I was rather shocked at what it implied :(  People are still using dynamite plots, for heaven's sake! See http://biostat.mc.vanderbilt.edu/wiki/Main/DynamitePlots  for some comments.
I see Jim has given you one way to do the plots you want. Here is another way using the ggplot2 package. You will probably have to install the package.  The code below covers the 2B:2D plots.
####=======Install ggplot2===================
install.packages("ggplot2")

###======== plot desired graphs==================
library(ggplot2)

dat1  <-  data.frame(x1  = rep("A", 4) , x2  =  rep("B", 4), y1  =  5:8,  y2  = 10:13)

p  <-  ggplot() 
p1  <-   p +  geom_segment( aes(x = x1, y = y1, xend =  x2,  yend = y2)) +
          geom_point(aes(x1, y1, colour = "blue", size = 2)) +
          geom_point(aes(x2, y2, colour = "red", size = 2)) 
p1
      
 p2  <-     p1 +     theme (legend.position = "none") + 
                  xlab("Treatment") + ylab("Change Score")
p2

###======== end==================

We could have all the commands in one statement but it is easier to write the code this way to help in debugging (damn typos1) and so I left it to help you see what is happening.

For the lower plots, in ggplot2, you should have a look at geom_dotplot() . Here is an interesting demo of it in use.  I like the addition of the median line in particular.  

http://rstudio-pubs-static.s3.amazonaws.com/1406_947a49f2d7914dad8b0fd050a9df9858.html




John Kane
Kingston ON Canada


> -----Original Message-----
> From: luysgarcia at gmail.com
> Sent: Mon, 4 May 2015 04:52:51 -0300
> To: r-help at r-project.org
> Subject: [R] Fwd: Question about paired plotting
> 
> Hello R experts,
> 
> I just found a new paper which shows the proper way (according to the
> authors) to show data, specially paired. I am very interested in
> presenting
> this kind of data, specially the scatter plott.  I have found a way to
> present it using this link:
> 
> http://journals.plos.org/plosbiology/article?id=10.1371%2Fjournal.pbio.1002128#pbio.1002128.s007
> 
> Nevertheless, I wanted to know if you know some example which allows me
> to
> produce a plot similar to the plots 2B-2D. I could do it by "hand" but it
> was quite time consuming and required editing the pictures,
> 
> Many thanks for any help you can provide!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From theseth.prashant at gmail.com  Mon May  4 11:28:53 2015
From: theseth.prashant at gmail.com (Prashant Sethi)
Date: Mon, 4 May 2015 14:58:53 +0530
Subject: [R] Request for functions to calculate correlated factors
 influencing an outcome.
In-Reply-To: <CAMeJHHDiTbaeMNJZftHaUua-JjLp6JTm6twAH4JyGj4PDbUh0A@mail.gmail.com>
References: <CAMeJHHApBUdmm8_meZ=wy=QdvbV_96+7+kgsaS1s=+EDjTufPg@mail.gmail.com>
	<CAM04ykANAbyNifjhu3AKAf88qvqDWjRnASM3Fb_LV6WE3jpX5g@mail.gmail.com>
	<CAMeJHHDiTbaeMNJZftHaUua-JjLp6JTm6twAH4JyGj4PDbUh0A@mail.gmail.com>
Message-ID: <CACJ2tAc2_E9oPhcrj4NkaQqkkq85j-na6m0DyLZihS+UXMfKpw@mail.gmail.com>

Hi,

>From my understanding of a model, you need to have one or more dependent
parameter variables which you (y1, y2 etc) and the explanatory parameter
variables (x1, x2 etc) which you fit along with certain coefficients to
determine the dependent parameter with minimum error as possible. I don't
think a factor can be on both sides of the model equation.

In your earlier email you had mentioned this statement: Question is : I am
trying to find factors influencing efficiency (in this
case mileage)

?If this is indeed your question, then I believe the lm() function is what
you need. Otherwise, I think you need to reformulate your query to further
clarify what you are looking for.

?Thanks and regards,
Prashant


On Mon, May 4, 2015 at 2:10 PM, Lalitha Viswanathan <
lalitha.viswanathan79 at gmail.com> wrote:

> Hi
> I used the MASS library
> library(MASS)  (by reading about examples at
> http://www.statmethods.net/stats/regression.html
> <
> http://s.bl-1.com/h/ofLlK27?url=http://www.statmethods.net/stats/regression.html
> >
> )
> fit <- lm(Mileage~Disp+HP+Weight+Reliability,data=newx)
> step <- stepAIC(fit, direction="both")
> step$anova # display results
>
> It showed the most relevant variables affecting Mileage.
> While that is a start, I am looking for a model that fits the entire data
> (including Mileage), not factors that influence Mileage.
>
> Multi model inference / selection.
>
> I was reading about glmulti.
> Are there any other packages I could look at, for infering models that best
> fit the data.
>
> To use nlm / nls, I need a formula, as one of the parameters to best fit
> the data and I am looking for functions that will help infer that formula
> from the data.
>
> Thanks
> lalitha
>
> On Sun, May 3, 2015 at 11:33 PM, Prashant Sethi <
> theseth.prashant at gmail.com>
> wrote:
>
> > Hi,
> >
> > I'm not an expert in data analysis (a beginner still learning tricks of
> > the trade) but I believe in your case since you're trying to determine
> the
> > correlation of a dependent variable with a number of factor variables,
> you
> > should try doing the regression analysis of your model. The function
> you'll
> > use for that is the lm() function. You can use the forward building or
> the
> > backward elimination method to build your model with the most critical
> > factors included.
> >
> > Maybe you can give it a try.
> >
> > Thanks and regards,
> > Prashant Sethi
> > On 3 May 2015 23:18, "Lalitha Viswanathan" <
> > lalitha.viswanathan79 at gmail.com> wrote:
> >
> >> Hi
> >> I am sorry, I saved the file removing the dot after the Disp (as I was
> >> going wrong on a read.delim which threw an error about !header,
> etc...The
> >> dot was not the culprit, but I continued to leave it out.
> >> Let me paste the full code here.
> >> x<-read.table("/Users/Documents/StatsTest/fuelEfficiency.txt",
> >> header=TRUE,
> >> sep="\t")
> >> x<-data.frame(x)
> >> for (i in unique(x$Country)) { print (i); y <- subset(x, x$Country ==
> i);
> >> print(y); }
> >> newx <- subset (x, select = c(Price, Reliability, Mileage, Weight, Disp,
> >> HP))
> >> cor(newx, method="pearson")
> >> my.cor <-cor.test(newx$Weight, newx$Price, method="spearman")
> >> my.cor <-cor.test(newx$Weight, newx$HP, method="spearman")
> >> my.cor <-cor.test(newx$Disp, newx$HP, method="spearman")
> >> Putting exact=NULL still doesn't remove the warning
> >> my.cor <-cor.test(newx$Disp, newx$HP, method="kendall", exact=NULL)
> >> I tried to find the correlation coeff for a various combination of
> >> variables, but am unable to interpet the results. (Results pasted below
> in
> >> an earlier post)
> >>
> >> Followed it up with a normality test
> >> shapiro.test(newx$Disp)
> >> shapiro.test(newx$HP)
> >>
> >> Then decided to do a kruskal.test(newx)
> >> with the result
> >> Kruskal-Wallis chi-squared = 328.94, df = 5, p-value < 2.2e-16
> >>
> >> Question is : I am trying to find factors influencing efficiency (in
> this
> >> case mileage)
> >>
> >> What are the range of functions / examples I should be looking at, to
> find
> >> a factor or combination of factors influencing efficiency?
> >>
> >> Any pointers will be helpful
> >>
> >> Thanks
> >> Lalitha
> >>
> >> On Sun, May 3, 2015 at 2:49 PM, Lalitha Viswanathan <
> >> lalitha.viswanathan79 at gmail.com> wrote:
> >>
> >> > Hi
> >> > I have a dataset of the type attached.
> >> > Here's my code thus far.
> >> > dataset <-data.frame(read.delim("data", sep="\t", header=TRUE));
> >> > newData<-subset(dataset, select = c(Price, Reliability, Mileage,
> Weight,
> >> > Disp, HP));
> >> > cor(newData, method="pearson");
> >> > Results are
> >> >                  Price Reliability    Mileage     Weight       Disp
> >> >   HP
> >> > Price        1.0000000          NA -0.6537541  0.7017999  0.4856769
> >> >  0.6536433
> >> > Reliability         NA           1         NA         NA         NA
> >> >   NA
> >> > Mileage     -0.6537541          NA  1.0000000 -0.8478541 -0.6931928
> >> > -0.6667146
> >> > Weight       0.7017999          NA -0.8478541  1.0000000  0.8032804
> >> >  0.7629322
> >> > Disp         0.4856769          NA -0.6931928  0.8032804  1.0000000
> >> >  0.8181881
> >> > HP           0.6536433          NA -0.6667146  0.7629322  0.8181881
> >> >  1.0000000
> >> >
> >> > It appears that Wt and Price, Wt and Disp, Wt and HP, Disp and HP, HP
> >> and
> >> > Price are strongly correlated.
> >> > To find the statistical significance,
> >> > I am trying  sample.correln<-cor.test(newData$Disp, newData$HP,
> >> > method="kendall", exact=NULL)
> >> > Kendall's rank correlation tau
> >> >
> >> > data:  newx$Disp and newx$HP
> >> > z = 7.2192, p-value = 5.229e-13
> >> > alternative hypothesis: true tau is not equal to 0
> >> > sample estimates:
> >> >       tau
> >> > 0.6563871
> >> >
> >> > If I try the same with
> >> > sample.correln<-cor.test(newData$Disp, newData$HP, method="pearson",
> >> > exact=NULL)
> >> > I get Warning message:
> >> > In cor.test.default(newx$Disp, newx$HP, method = "spearman", exact =
> >> NULL)
> >> > :
> >> >   Cannot compute exact p-value with ties
> >> > > sample.correln
> >> >
> >> > Spearman's rank correlation rho
> >> >
> >> > data:  newx$Disp and newx$HP
> >> > S = 5716.8, p-value < 2.2e-16
> >> > alternative hypothesis: true rho is not equal to 0
> >> > sample estimates:
> >> >       rho
> >> > 0.8411566
> >> >
> >> > I am not sure how to interpret these values.
> >> > Basically, I am trying to figure out which combination of factors
> >> > influences efficiency.
> >> >
> >> > Thanks
> >> > Lalitha
> >> >
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jeremyclarkbio at gmail.com  Mon May  4 12:13:25 2015
From: jeremyclarkbio at gmail.com (Jeremy Clark)
Date: Mon, 4 May 2015 12:13:25 +0200
Subject: [R] Graphs for scientific publication ?
Message-ID: <CACyTWRbKN8vwJPSxpEQxZExBZBqzns8GJ=V4HcXCtbPJxcwWSQ@mail.gmail.com>

Dear All,

Many thanks for your very comprehensive replies. Here I provide some
coding which on my system has the following effects:
1) The italic R is not rendered by CairoX11, but is rendered by quartz.
2) Both geom_smooth and geom_abline here give stepped lines (I've
realised the angle of the line makes quite a difference to this). I
presume that these are not "anti-aliased" - so I was hoping that Cairo
would change this. Unfortunately the command Cairo() does not open any
device, and the CairoX11 device gives similar lines to that from
quartz.
3) As I must turn off general clipping (because I need to add some
text which overlaps the plot edge) it would be useful to be able to
clip particular lines to the plot edge - although this is not a
catastrophe as I can create a new truncated dataframe and plot the
lines from this.

My system is MacBook Air, with all Xcode recently updated including
IOS 8.2, OS X 10.10, Xcode 6.2. I previously, and fairly recently,
installed X11 (and Xquartz), and also updated R and R Cairo, but none
of this has affected the above behaviour.

Any advice gratefully received.

Yours sincerely,

Jeremy Clark

library(ggplot2)
library(grid)
library(Cairo)

theme_jack <- function (base_size = 16, base_family = "") {
    theme_classic(base_size = base_size, base_family = base_family) %+replace%
        theme(
            plot.title = element_text(size=15, vjust=3),
            axis.text = element_text(colour = "black", family="Times",
face=c('bold'), size = 18),
            axis.title.x = element_text(colour = "black",
family="Times", face=c('bold'),   vjust             = -1,    size =
20),
            axis.title.y = element_text(colour = "black",
family="Times", angle=90,      face=c('bold'), vjust= 2, size = 20),
            panel.background = element_rect(fill="white"),
            panel.grid.minor = element_blank(),
            panel.grid.major = element_blank(),
            plot.background = element_rect(fill="white"),
            panel.border = element_blank(),
            panel.background = element_blank(),
            plot.margin=unit(c(1,1.5,1.3,1.3),"cm")
    )
}
theme_set(theme_jack())

DataX <- seq(1, 40, by = 1)
DataY <- seq(1, 40, by = 1)
Datadf <- data.frame(DataX, DataY)

## replace "quartz" with "CairoX11" or "X11" for various effects:

quartz(width = 6 , height = 6) ## quartz renders the italic R correctly
p1 <- ggplot() + ggtitle("Title") + coord_cartesian(xlim = c(1, 40),
ylim = c(0, 40)) + scale_y_continuous(breaks = c(0, 10, 20, 30),
labels = c("0", "10", "20", "30"), expand = c(0, 0)) + ylab("Y-axis")
+ scale_x_continuous(breaks = c(10, 20, 30, 40), expand = c(0, 0)) +
geom_point(data = Datadf, aes(x = DataX, y = DataY)) + xlab("X-axis")

predy <- as.integer(c(38, 25, 20, 14, 8))
predx <- as.integer(c(20, 21, 22, 24, 25))
datapreddf <- as.data.frame(predx, predy)
myplm <- lm(predy ~ predx, data = datapreddf)
lmxrange <- data.frame(predx = seq(from = 20, to = 30, by = 0.01))
lmyrange <- predict.lm(myplm, newdata <- lmxrange)
lmdataframe <- data.frame(lmxrange, lmyrange)
p2 <- p1 + geom_smooth(data = lmdataframe, aes(x = predx, y =
lmyrange), method=lm, se=FALSE, color = "black") +
geom_abline(aes(intercept = as.vector(coefficients(myplm)[1]),
slope=as.vector(coefficients(myplm)[2]+2)), data=lmdataframe) ## both
give stepped lines in both quartz and CairoX11

rsquaredlm = NULL
rsquaredlm[[6]] <- 3 ## false value
listr2 <- list(r2 = rsquaredlm[[6]])
eq1 <- substitute(italic(R)^2 == r2, listr2)
eqstr1 <- as.character(as.expression(eq1))
q3 <- p2 +  annotate(geom = "text", x = 20, y = 30, label = eqstr1,
parse = TRUE, vjust = 1)
gt <- ggplot_gtable(ggplot_build(q3))

gt$layout$clip[gt$layout$name=="panel"] <- "off" ## (necessary to
allow additional text
## overlap - not shown) - clipping of lines can be done with other
coding - although it
##would be nice to be able to do this more efficiently
grid.draw(gt)

## _____________________________________________

Cairo() ## doesn't open any device


From from.d.putto at gmail.com  Mon May  4 13:11:28 2015
From: from.d.putto at gmail.com (Sheila the angel)
Date: Mon, 4 May 2015 13:11:28 +0200
Subject: [R] ggplot, Plot title at the bottom of plot
Message-ID: <CAFinXcRMAc7b7VztHdMCCScq9QxnOrAAVXm6RvVWAs1j4BOGFA@mail.gmail.com>

Hello All,

I am looking for the answer to simple question:

In ggplot, how to put plot title at the bottom of plot ?

This code :

qplot(rnorm(100)) + ggtitle("My Title")

puts the title at middle and top of plot while I want it to be at middle
and *Bottom* of the plot.

Using

+theme(plot.title = element_text(vjust = 10))

is not a good option as it can write on the top of the x-axis labels and
there might not be enough space for title. Moreover one do not want to
adjust "vjust" value all the time.

Thanks

--

Sheila

	[[alternative HTML version deleted]]


From lilskro at hotmail.com  Mon May  4 15:06:48 2015
From: lilskro at hotmail.com (=?iso-8859-1?Q?Lilja_S=F3lveig_Kro?=)
Date: Mon, 4 May 2015 15:06:48 +0200
Subject: [R] Block exogeneity in SVAR
Message-ID: <DUB403-EAS7474F48F35F90512C7AEE0A3D20@phx.gbl>

Good day,

My goal is to use a SVAR model to estimate monetary policy transmission. I
have seven variables, five for a small country and two for a large country.
I?d like to impose block-exogeneity restrictions so that the small county
does not affect the large country (in the short run nor in the long run) but
the large country does affect the small country. I?ll then use impulse
response functions for my analysis.

Is it possible to impose these restrictions using the SVAR function in the
var package in R? 

Best Regards,

Lilja Kro 

 


	[[alternative HTML version deleted]]


From nick.w.jeffery3 at gmail.com  Mon May  4 17:48:40 2015
From: nick.w.jeffery3 at gmail.com (Nick Jeffery)
Date: Mon, 4 May 2015 11:48:40 -0400
Subject: [R] Mantel test
Message-ID: <CADUrEER9U0SUh9BsFGwy=pXpfMjGS8NecRgyiEt3VHD0xLkQkg@mail.gmail.com>

Dear R users,

I'm having trouble getting my data into R in the correct format to run a
Mantel test.

I'm testing genome size differences by genetic distances of the 28S gene
for ~30 species. I'm able to get my genome size data (as a single column of
data) into matrix and dist formats in R but the genetic distances output by
MEGA are already in 'matrix' format so I don't know how to load this CSV
file into R without it calculating new genetic distances when I convert it
to the dist form required by the test.

Thanks in advance,
Nick

-- 
Nick Jeffery, PhD Candidate
Integrative Biology
SCIE 1453
University of Guelph
Guelph, Ontario, Canada

	[[alternative HTML version deleted]]


From toby at huksu.com  Mon May  4 17:48:41 2015
From: toby at huksu.com (thuksu)
Date: Mon, 4 May 2015 08:48:41 -0700 (PDT)
Subject: [R] GLM: What is a good way for dealing with new factor levels
 in the test set?
In-Reply-To: <1430406146519-4706644.post@n4.nabble.com>
References: <1430345103451-4706621.post@n4.nabble.com>
	<CA+8X3fVpesBYY9bXbyHwYQUXrrrTh1qA_7USuAh3hvg0oaGmNg@mail.gmail.com>
	<1430406146519-4706644.post@n4.nabble.com>
Message-ID: <1430754521271-4706772.post@n4.nabble.com>

For anyone who is looking for an answer to this in the future...

I went for "imputation".  It's a way of filling in missing variables based
off of what you see elsewhere in the data.

Myself, I simply took a sample of the categorical from the rest of the test
set.  Some may argue that this is erroneous, as I simply don't know anything
about the new categorical in the test set, and I should throw it away. 
However, my results are going to be aggregated later, and this lets me do
some central limit theorem hand waving.



--
View this message in context: http://r.789695.n4.nabble.com/GLM-What-is-a-good-way-for-dealing-with-new-factor-levels-in-the-test-set-tp4706621p4706772.html
Sent from the R help mailing list archive at Nabble.com.


From dawoodmalik at hotmail.com  Mon May  4 10:29:35 2015
From: dawoodmalik at hotmail.com (dawood ahmad)
Date: Mon, 4 May 2015 08:29:35 +0000
Subject: [R] Need Help!
Message-ID: <COL127-W3452DEC02C549960FC8DBBBD20@phx.gbl>

Dear Sir/Madam,
 
I hope you will be fine. I am new to R language. Recently, I am trying to fit my data with one model.
I am sending you the code and image file on which you can see the error I am receiving instead of executing.
If I give a single value to parameter "ep", it executes well, but if I make a loop/seq for getting a range of data it shows
error.I need you help in solving this problem.
 
Thanking in advance,
 
With Best Regards,
Dawood
 		 	   		  
-------------- next part --------------
A non-text attachment was scrubbed...
Name: CodeImage.png
Type: image/png
Size: 177372 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150504/2cc619b1/attachment.png>

From luysgarcia at gmail.com  Mon May  4 20:35:16 2015
From: luysgarcia at gmail.com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Mon, 4 May 2015 15:35:16 -0300
Subject: [R] Fwd: Question about paired plotting
In-Reply-To: <45F9962A36A.000006E0jrkrideau@inbox.com>
References: <canxp2s4mst4k5ydfopg7jv7f31t7cceogzb706gu0wz71-8kmw@mail.gmail.com>
	<CANxP2S736TqD0A33V84r2zM7VBwh+HNjawFHY78s=0xdFs7Q=A@mail.gmail.com>
	<45F9962A36A.000006E0jrkrideau@inbox.com>
Message-ID: <CANxP2S6WzxgMsnq_0gzje2iJGm04pEmDTqyEDDBay6B3aOR3=g@mail.gmail.com>

Dear John and Tim!

Thanks a lot for your replies. This is just what I needed!!

All the best for you!!

2015-05-04 13:58 GMT-03:00 John Kane <jrkrideau at inbox.com>:

> Hi Luis,
> Ah yes, that paper.  I was rather shocked at what it implied :(  People
> are still using dynamite plots, for heaven's sake! See
> http://biostat.mc.vanderbilt.edu/wiki/Main/DynamitePlots  for some
> comments.
> I see Jim has given you one way to do the plots you want. Here is another
> way using the ggplot2 package. You will probably have to install the
> package.  The code below covers the 2B:2D plots.
> ####=======Install ggplot2===================
> install.packages("ggplot2")
>
> ###======== plot desired graphs==================
> library(ggplot2)
>
> dat1  <-  data.frame(x1  = rep("A", 4) , x2  =  rep("B", 4), y1  =  5:8,
> y2  = 10:13)
>
> p  <-  ggplot()
> p1  <-   p +  geom_segment( aes(x = x1, y = y1, xend =  x2,  yend = y2)) +
>           geom_point(aes(x1, y1, colour = "blue", size = 2)) +
>           geom_point(aes(x2, y2, colour = "red", size = 2))
> p1
>
>  p2  <-     p1 +     theme (legend.position = "none") +
>                   xlab("Treatment") + ylab("Change Score")
> p2
>
> ###======== end==================
>
> We could have all the commands in one statement but it is easier to write
> the code this way to help in debugging (damn typos1) and so I left it to
> help you see what is happening.
>
> For the lower plots, in ggplot2, you should have a look at geom_dotplot()
> . Here is an interesting demo of it in use.  I like the addition of the
> median line in particular.
>
>
> http://rstudio-pubs-static.s3.amazonaws.com/1406_947a49f2d7914dad8b0fd050a9df9858.html
>
>
>
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: luysgarcia at gmail.com
> > Sent: Mon, 4 May 2015 04:52:51 -0300
> > To: r-help at r-project.org
> > Subject: [R] Fwd: Question about paired plotting
> >
> > Hello R experts,
> >
> > I just found a new paper which shows the proper way (according to the
> > authors) to show data, specially paired. I am very interested in
> > presenting
> > this kind of data, specially the scatter plott.  I have found a way to
> > present it using this link:
> >
> >
> http://journals.plos.org/plosbiology/article?id=10.1371%2Fjournal.pbio.1002128#pbio.1002128.s007
> >
> > Nevertheless, I wanted to know if you know some example which allows me
> > to
> > produce a plot similar to the plots 2B-2D. I could do it by "hand" but it
> > was quite time consuming and required editing the pictures,
> >
> > Many thanks for any help you can provide!
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> Check it out at http://www.inbox.com/earth
>
>
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon May  4 21:48:59 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 4 May 2015 19:48:59 +0000
Subject: [R] Mantel test
In-Reply-To: <CADUrEER9U0SUh9BsFGwy=pXpfMjGS8NecRgyiEt3VHD0xLkQkg@mail.gmail.com>
References: <CADUrEER9U0SUh9BsFGwy=pXpfMjGS8NecRgyiEt3VHD0xLkQkg@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D689C1B@mb02.ads.tamu.edu>

Assuming the 'matrix' format is a symmetrical distance 'matrix' stored as a data frame (which read.csv creates) rather a rectangular data 'matrix,' you can convert it to a dist object with as.dist(). 

?dist

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Nick Jeffery
Sent: Monday, May 4, 2015 10:49 AM
To: r-help at r-project.org
Subject: [R] Mantel test

Dear R users,

I'm having trouble getting my data into R in the correct format to run a
Mantel test.

I'm testing genome size differences by genetic distances of the 28S gene
for ~30 species. I'm able to get my genome size data (as a single column of
data) into matrix and dist formats in R but the genetic distances output by
MEGA are already in 'matrix' format so I don't know how to load this CSV
file into R without it calculating new genetic distances when I convert it
to the dist form required by the test.

Thanks in advance,
Nick

-- 
Nick Jeffery, PhD Candidate
Integrative Biology
SCIE 1453
University of Guelph
Guelph, Ontario, Canada

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From g.rudge at bham.ac.uk  Mon May  4 21:59:08 2015
From: g.rudge at bham.ac.uk (gavinr)
Date: Mon, 4 May 2015 12:59:08 -0700 (PDT)
Subject: [R] A problem with string handling to make a time duration
Message-ID: <1430769548728-4706795.post@n4.nabble.com>

I have a character string that represents a time duration. It has an hours
minutes seconds structure(ish) but with letters denoting units (H,M or S) no
leading zeros and no placeholder at all where one or other of the units are
not required.

It looks like this:

t<-c("10H20M33S","1H1M","1M","21M9S","2H55S" ))
df<-data.frame(t)
df

#ideally should look like:
t2<-c("10:20:33","01:00:01","00:01:00","00:21:09","02:00:55") 
df2<-data.frame(t2)
df2

I need to get it into hours minutes and seconds either in time format or as
a string with leading zeros and all three time units represented in each
one, as in df2.  The data, part of a very large dataset, are for onward use
and processing in a GIS application.  I?ve messed about with string handling
statements in SQL to no avail, but wondered if R would be a better bet? 
I?ve had a look at some of the commands in stringr, but am unsure how to
operationalise a solution using this package.  Any advice is welcome.




--
View this message in context: http://r.789695.n4.nabble.com/A-problem-with-string-handling-to-make-a-time-duration-tp4706795.html
Sent from the R help mailing list archive at Nabble.com.


From kehld at ktk.pte.hu  Mon May  4 22:17:48 2015
From: kehld at ktk.pte.hu (=?iso-8859-1?Q?Kehl_D=E1niel?=)
Date: Mon, 4 May 2015 20:17:48 +0000
Subject: [R] Need Help!
In-Reply-To: <COL127-W3452DEC02C549960FC8DBBBD20@phx.gbl>
References: <COL127-W3452DEC02C549960FC8DBBBD20@phx.gbl>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D1441C54A@EMAIL.ktkdom.pte.hu>

Dear Dawood,

it is not a really good idea to open a new email with the same problem you already posted earlier.
I see you accepted some suggestions (HTML, seq) but not others (pi is a defined constant in R, do not change it, type pi ENTER to see this.). I would like to add one more, c is a function, do not use it as a variable name (I used cc instead of c).
I tried to figure out what you want here. The following code might do what you want. It gives you a feeling about how you would create a basic loop. There are nicer ways to do that in R. Note the [i]-s in the for loop!


cc <- 0.5
xc <- 2
s <- 6
Hc2 <- 30
H <- 1
ep<-seq(0.01, 0.49, by=0.001)
res <- numeric(length=length(ep))

for (i in 1:length(ep)){
  f<-function(k) 1.211*10^(-6)*Hc2/H*(trigamma( ((ep[i] + H/Hc2 + (2*xc/s)^2*(1 - cos(k*s))/2)/2*Hc2/H)) -  trigamma(((cc + H/Hc2 + (2*xc/s)^2*(1 - cos(k*s))/2)/2*Hc2/H)))
  res[i] <- integrate(f,-pi/s,pi/s)$value
}

Best,
daniel
________________________________________
Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: dawood ahmad [dawoodmalik at hotmail.com]
K?ldve: 2015. m?jus 4. 10:29
To: r-help at R-project.org
T?rgy: [R] Need Help!

Dear Sir/Madam,

I hope you will be fine. I am new to R language. Recently, I am trying to fit my data with one model.
I am sending you the code and image file on which you can see the error I am receiving instead of executing.
If I give a single value to parameter "ep", it executes well, but if I make a loop/seq for getting a range of data it shows
error.I need you help in solving this problem.

Thanking in advance,

With Best Regards,
Dawood


From f.harrell at vanderbilt.edu  Mon May  4 22:23:27 2015
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Mon, 4 May 2015 15:23:27 -0500
Subject: [R] [R-pkgs] Version 3.16-0 of Hmisc now on CRAN
Message-ID: <5547D53F.30201@vanderbilt.edu>

Several updates have been made to the Hmisc package:

Changes in version 3.16-0 (2015-04-25)
    * html.contents.data.frame: corrected html space character to add 
semicolon
    * ggplot.summaryP: added size of points according to denominators
    * colorFacet: new function
    * labelPlotmath: added chexpr argument (used by rms::ggplot.Predict)
    * rcsplineFunction: added type='integral'
    * summaryP: fixed bug with sort=FALSE using mfreq when shouldn't
    * summaryP: stored levels(val) in original levels order
    * summaryM: removed observations added by addMarginal when computing 
N in left column of tables
    * html.latex: added method for htlatex, added where argument, 
cleaned up code, implemented file='' for knitr when using html/Rmarkdown
    * summaryM, summary.formula: changed calls to translate to gsub()
    * summaryP: corrected but in exclude1 logic, moved exclude1 to 
methods that operate on summaryP objects and out of summaryP itself
    * addMarginal: respect original levels, add argument margloc
    * added latticeExtra:: in front of function calls
    * numeric.string, all.is.numeric: replaced options(warn=-1) with 
suppressWarnings() (thanks: Yihui)
    * arrGrob, print.arrGrob: new functions
    * wtd.var: added maximum likelihood method, fixed unbiased method, 
improved documentation (all provided by Benjamin Tyner)
    * Changed all any(duplicated()) to anyDuplicated(); thanks Benjamin 
Tyler
    * getRs: new function to interact with 
https://github.com/harrelfe/rscripts
    * knitrSet: new function to setup knitr with nice defaults for books 
etc.
      * rcorr: fixed sensing of NAs and diagonal elements of n matrix; 
thanks: Keith Jewell, Campden BRI Group; similar for hoeffd

-- 
------------------------------------------------------------------------
Frank E Harrell Jr 	Professor and Chairman 	School of Medicine

	Department of *Biostatistics* 	*Vanderbilt University*


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From istazahn at gmail.com  Mon May  4 22:59:25 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 4 May 2015 16:59:25 -0400
Subject: [R] Graphs for scientific publication ?
In-Reply-To: <CACyTWRbKN8vwJPSxpEQxZExBZBqzns8GJ=V4HcXCtbPJxcwWSQ@mail.gmail.com>
References: <CACyTWRbKN8vwJPSxpEQxZExBZBqzns8GJ=V4HcXCtbPJxcwWSQ@mail.gmail.com>
Message-ID: <CA+vqiLGcXF64iP7qhe6SOxPkHkhEEZLgN+Oumx19C0+F5pYt+A@mail.gmail.com>

Hi Jeremy,

On Mon, May 4, 2015 at 6:13 AM, Jeremy Clark <jeremyclarkbio at gmail.com>
wrote:
> Dear All,
>
> Many thanks for your very comprehensive replies. Here I provide some
> coding which on my system has the following effects:
> 1) The italic R is not rendered by CairoX11, but is rendered by quartz.

I don't have a Mac available, but it works as expected here on Linux. You
may wish to ask on the r-sig-mac mailing list.

> 2) Both geom_smooth and geom_abline here give stepped lines (I've
> realised the angle of the line makes quite a difference to this). I
> presume that these are not "anti-aliased" - so I was hoping that Cairo
> would change this. Unfortunately the command Cairo() does not open any
> device,

Are you sure about that? It opens a png device by default here. See ?Cairo
especially the type argument.

and the CairoX11 device gives similar lines to that from
> quartz.

Generally graphics that you wish to publish or otherwise disseminate will
be written to a png, pdf, or similar. How does

png("tst.png", width=5, height=5, units = "in", res=300)
q3
dev.off()

look?

> 3) As I must turn off general clipping (because I need to add some
> text which overlaps the plot edge) it would be useful to be able to
> clip particular lines to the plot edge - although this is not a
> catastrophe as I can create a new truncated dataframe and plot the
> lines from this.

It would have been nice to have a reproducible example of what you are
trying to accomplish by turning off clipping. There may be an easier way,
but it's hard to say for sure without knowing what the goal is.

Best,
Ista
>
> My system is MacBook Air, with all Xcode recently updated including
> IOS 8.2, OS X 10.10, Xcode 6.2. I previously, and fairly recently,
> installed X11 (and Xquartz), and also updated R and R Cairo, but none
> of this has affected the above behaviour.
>
> Any advice gratefully received.
>
> Yours sincerely,
>
> Jeremy Clark
>
> library(ggplot2)
> library(grid)
> library(Cairo)
>
> theme_jack <- function (base_size = 16, base_family = "") {
> theme_classic(base_size = base_size, base_family = base_family) %+replace%
> theme(
> plot.title = element_text(size=15, vjust=3),
> axis.text = element_text(colour = "black", family="Times",
> face=c('bold'), size = 18),
> axis.title.x = element_text(colour = "black",
> family="Times", face=c('bold'), vjust = -1, size =
> 20),
> axis.title.y = element_text(colour = "black",
> family="Times", angle=90, face=c('bold'), vjust= 2, size = 20),
> panel.background = element_rect(fill="white"),
> panel.grid.minor = element_blank(),
> panel.grid.major = element_blank(),
> plot.background = element_rect(fill="white"),
> panel.border = element_blank(),
> panel.background = element_blank(),
> plot.margin=unit(c(1,1.5,1.3,1.3),"cm")
> )
> }
> theme_set(theme_jack())
>
> DataX <- seq(1, 40, by = 1)
> DataY <- seq(1, 40, by = 1)
> Datadf <- data.frame(DataX, DataY)
>
> ## replace "quartz" with "CairoX11" or "X11" for various effects:
>
> quartz(width = 6 , height = 6) ## quartz renders the italic R correctly
> p1 <- ggplot() + ggtitle("Title") + coord_cartesian(xlim = c(1, 40),
> ylim = c(0, 40)) + scale_y_continuous(breaks = c(0, 10, 20, 30),
> labels = c("0", "10", "20", "30"), expand = c(0, 0)) + ylab("Y-axis")
> + scale_x_continuous(breaks = c(10, 20, 30, 40), expand = c(0, 0)) +
> geom_point(data = Datadf, aes(x = DataX, y = DataY)) + xlab("X-axis")
>
> predy <- as.integer(c(38, 25, 20, 14, 8))
> predx <- as.integer(c(20, 21, 22, 24, 25))
> datapreddf <- as.data.frame(predx, predy)
> myplm <- lm(predy ~ predx, data = datapreddf)
> lmxrange <- data.frame(predx = seq(from = 20, to = 30, by = 0.01))
> lmyrange <- predict.lm(myplm, newdata <- lmxrange)
> lmdataframe <- data.frame(lmxrange, lmyrange)
> p2 <- p1 + geom_smooth(data = lmdataframe, aes(x = predx, y =
> lmyrange), method=lm, se=FALSE, color = "black") +
> geom_abline(aes(intercept = as.vector(coefficients(myplm)[1]),
> slope=as.vector(coefficients(myplm)[2]+2)), data=lmdataframe) ## both
> give stepped lines in both quartz and CairoX11
>
> rsquaredlm = NULL
> rsquaredlm[[6]] <- 3 ## false value
> listr2 <- list(r2 = rsquaredlm[[6]])
> eq1 <- substitute(italic(R)^2 == r2, listr2)
> eqstr1 <- as.character(as.expression(eq1))
> q3 <- p2 + annotate(geom = "text", x = 20, y = 30, label = eqstr1,
> parse = TRUE, vjust = 1)
> gt <- ggplot_gtable(ggplot_build(q3))
>
> gt$layout$clip[gt$layout$name=="panel"] <- "off" ## (necessary to
> allow additional text
> ## overlap - not shown) - clipping of lines can be done with other
> coding - although it
> ##would be nice to be able to do this more efficiently
> grid.draw(gt)
>
> ## _____________________________________________
>
> Cairo() ## doesn't open any device
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon May  4 23:10:15 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 4 May 2015 14:10:15 -0700
Subject: [R] Graphs for scientific publication ?
In-Reply-To: <CACyTWRbKN8vwJPSxpEQxZExBZBqzns8GJ=V4HcXCtbPJxcwWSQ@mail.gmail.com>
References: <CACyTWRbKN8vwJPSxpEQxZExBZBqzns8GJ=V4HcXCtbPJxcwWSQ@mail.gmail.com>
Message-ID: <87FC873A-CCD0-419D-8583-ADD63CA005E2@comcast.net>


On May 4, 2015, at 3:13 AM, Jeremy Clark wrote:

> Dear All,
> 
> Many thanks for your very comprehensive replies. Here I provide some
> coding which on my system has the following effects:
> 1) The italic R is not rendered by CairoX11, but is rendered by quartz.
> 2) Both geom_smooth and geom_abline here give stepped lines (I've
> realised the angle of the line makes quite a difference to this). I
> presume that these are not "anti-aliased" - so I was hoping that Cairo
> would change this. Unfortunately the command Cairo() does not open any
> device, and the CairoX11 device gives similar lines to that from
> quartz.
> 3) As I must turn off general clipping (because I need to add some
> text which overlaps the plot edge) it would be useful to be able to
> clip particular lines to the plot edge - although this is not a
> catastrophe as I can create a new truncated dataframe and plot the
> lines from this.
> 
> My system is MacBook Air, with all Xcode recently updated including
> IOS 8.2, OS X 10.10, Xcode 6.2. I previously, and fairly recently,
> installed X11 (and Xquartz), and also updated R and R Cairo, but none
> of this has affected the above behaviour.
> 
> Any advice gratefully received.
> 
> Yours sincerely,
> 
> Jeremy Clark
> 
> library(ggplot2)
> library(grid)
> library(Cairo)
> 
> theme_jack <- function (base_size = 16, base_family = "") {
>    theme_classic(base_size = base_size, base_family = base_family) %+replace%
>        theme(
>            plot.title = element_text(size=15, vjust=3),
>            axis.text = element_text(colour = "black", family="Times",
> face=c('bold'), size = 18),
>            axis.title.x = element_text(colour = "black",
> family="Times", face=c('bold'),   vjust             = -1,    size =
> 20),
>            axis.title.y = element_text(colour = "black",
> family="Times", angle=90,      face=c('bold'), vjust= 2, size = 20),
>            panel.background = element_rect(fill="white"),
>            panel.grid.minor = element_blank(),
>            panel.grid.major = element_blank(),
>            plot.background = element_rect(fill="white"),
>            panel.border = element_blank(),
>            panel.background = element_blank(),
>            plot.margin=unit(c(1,1.5,1.3,1.3),"cm")
>    )
> }
> theme_set(theme_jack())
> 
> DataX <- seq(1, 40, by = 1)
> DataY <- seq(1, 40, by = 1)
> Datadf <- data.frame(DataX, DataY)
> 
> ## replace "quartz" with "CairoX11" or "X11" for various effects:
> 
> quartz(width = 6 , height = 6) ## quartz renders the italic R correctly
> p1 <- ggplot() + ggtitle("Title") + coord_cartesian(xlim = c(1, 40),
> ylim = c(0, 40)) + scale_y_continuous(breaks = c(0, 10, 20, 30),
> labels = c("0", "10", "20", "30"), expand = c(0, 0)) + ylab("Y-axis")
> + scale_x_continuous(breaks = c(10, 20, 30, 40), expand = c(0, 0)) +
> geom_point(data = Datadf, aes(x = DataX, y = DataY)) + xlab("X-axis")
> 

> predy <- as.integer(c(38, 25, 20, 14, 8))
> predx <- as.integer(c(20, 21, 22, 24, 25))
> datapreddf <- as.data.frame(predx, predy)
> myplm <- lm(predy ~ predx, data = datapreddf)
> lmxrange <- data.frame(predx = seq(from = 20, to = 30, by = 0.01))
> lmyrange <- predict.lm(myplm, newdata <- lmxrange)
> lmdataframe <- data.frame(lmxrange, lmyrange)
> p2 <- p1 + geom_smooth(data = lmdataframe, aes(x = predx, y =
> lmyrange), method=lm, se=FALSE, color = "black") +
> geom_abline(aes(intercept = as.vector(coefficients(myplm)[1]),
> slope=as.vector(coefficients(myplm)[2]+2)), data=lmdataframe) ## both
> give stepped lines in both quartz and CairoX11
> 
> rsquaredlm = NULL
> rsquaredlm[[6]] <- 3 ## false value
> listr2 <- list(r2 = rsquaredlm[[6]])
> eq1 <- substitute(italic(R)^2 == r2, listr2)
> eqstr1 <- as.character(as.expression(eq1))
> q3 <- p2 +  annotate(geom = "text", x = 20, y = 30, label = eqstr1,
> parse = TRUE, vjust = 1)
> gt <- ggplot_gtable(ggplot_build(q3))
> 
> gt$layout$clip[gt$layout$name=="panel"] <- "off"

> ## (necessary toallow additional text
> ## overlap - not shown) - clipping of lines can be done with other
#   coding - although it
> 
> ## would be nice to be able to do this more efficiently
> grid.draw(gt)
> 
> ## _____________________________________________
> 
> Cairo() ## doesn't open any device

I would not expect it to. The default for the file argument to Cairo() is "". I get an error when I try this on a MacPro running 0sx 10.7.5:

> Cairo(file="test.png")
Fontconfig error: "/Library/Frameworks/R.framework/Resources/fontconfig/fonts/conf.d/10-scale-bitmap-fonts.conf", line 70: non-double matrix element

At any rate one would not generally attempt to smooth out jaggies with the default .png setting for Cairo. One would use CairoPDF or CairoSVG depending on the preferences of ones publisher. (I've never used CairoPDF(), since the ordinary pdf() device "just works".)

This does seem to be way too much code for demonstration of difficulties with getting proper output from a vector graphics device. The onscreen version of quartz has limited resolution but the "Save as..." output should be pdf.

You need to realize that there are several different fonts being used by these devices:

> names( quartzFonts())
[1] "serif" "sans"  "mono" 
> names( CairoFonts())
NULL
>  CairoFonts()
> #  I get nothing ... consistent with the error report that suggests I have not followed the advice in ?CairoFonts: "This function is only available when the cairo graphics library is configured with FreeType and Fontcofig support."

Since I've never needed it, I suggest you try to use pdf() for vector output.

-- 

David Winsemius
Alameda, CA, USA


From john.laing at gmail.com  Mon May  4 23:14:02 2015
From: john.laing at gmail.com (John Laing)
Date: Mon, 4 May 2015 17:14:02 -0400
Subject: [R] A problem with string handling to make a time duration
In-Reply-To: <1430769548728-4706795.post@n4.nabble.com>
References: <1430769548728-4706795.post@n4.nabble.com>
Message-ID: <CAA3Wa=v_nLSb8UMpgrpCsED1263b5qKgsK+1WB4n8xuBuku+tQ@mail.gmail.com>

Regular expressions are the tool for this problem. This pattern
matches your input data:

t <- c("10H20M33S", "1H1M", "1M", "21M9S", "2H55S")
patt <- "^(([0-9]+)H)?(([0-9]+)M)?(([0-9]+)S)?$"
all(grepl(patt, t)) # TRUE

We can use the pattern to extract hour/minute/second components

hms <- lapply(c(h="\\2", m="\\4", s="\\6"), function(r) sub(patt, r, t))

And then just plug those components back into the desired format

formatted <- gsub(" ", "0", sprintf("%2s:%2s:%2s", hms$h, hms$m, hms$s))

In the last line we need the gsub because zero-padding with %02s seems
to be platform-dependent.

JL

On Mon, May 4, 2015 at 3:59 PM, gavinr <g.rudge at bham.ac.uk> wrote:
> I have a character string that represents a time duration. It has an hours
> minutes seconds structure(ish) but with letters denoting units (H,M or S) no
> leading zeros and no placeholder at all where one or other of the units are
> not required.
>
> It looks like this:
>
> t<-c("10H20M33S","1H1M","1M","21M9S","2H55S" ))
> df<-data.frame(t)
> df
>
> #ideally should look like:
> t2<-c("10:20:33","01:00:01","00:01:00","00:21:09","02:00:55")
> df2<-data.frame(t2)
> df2
>
> I need to get it into hours minutes and seconds either in time format or as
> a string with leading zeros and all three time units represented in each
> one, as in df2.  The data, part of a very large dataset, are for onward use
> and processing in a GIS application.  I?ve messed about with string handling
> statements in SQL to no avail, but wondered if R would be a better bet?
> I?ve had a look at some of the commands in stringr, but am unsure how to
> operationalise a solution using this package.  Any advice is welcome.
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/A-problem-with-string-handling-to-make-a-time-duration-tp4706795.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Tue May  5 01:06:07 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 5 May 2015 09:06:07 +1000
Subject: [R] Fwd: Question about paired plotting
In-Reply-To: <CANxP2S6WzxgMsnq_0gzje2iJGm04pEmDTqyEDDBay6B3aOR3=g@mail.gmail.com>
References: <canxp2s4mst4k5ydfopg7jv7f31t7cceogzb706gu0wz71-8kmw@mail.gmail.com>	<CANxP2S736TqD0A33V84r2zM7VBwh+HNjawFHY78s=0xdFs7Q=A@mail.gmail.com>	<45F9962A36A.000006E0jrkrideau@inbox.com>
	<CANxP2S6WzxgMsnq_0gzje2iJGm04pEmDTqyEDDBay6B3aOR3=g@mail.gmail.com>
Message-ID: <000c01d086be$e85bc160$b9134420$@bigpond.com>

Hi 

With R there are usually several ways

Here is another one using lattice (I think it ships with R otherwise
install)

Reshape dat1 to long form and add a column for groups do give d2

d2 = structure(list(y = c(5L, 10L, 6L, 11L, 7L, 12L, 8L, 13L), x = c(1L,
2L, 1L, 2L, 1L, 2L, 1L, 2L), gp = structure(c(1L, 1L, 2L, 2L,
3L, 3L, 4L, 4L), .Label = c("1", "2", "3", "4"), class = "factor")), .Names
= c("y",
"x", "gp"), row.names = c(NA, -8L), class = "data.frame")

library(lattice)


d2

library(lattice)

xyplot(y~x, data = d2,
       groups = gp,
       scales = list(x = list(at = 1:2,
                     labels= LETTERS[1:2])),
       col = 1,
       type = "b")

PS it makes it easier for every one if you send an example; even better
using dput
For windows 
dput(d2, file= "clipboard")
and paste it into your email

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luis
Fernando Garc?a
Sent: Tuesday, 5 May 2015 04:35
To: John Kane
Cc: r-help at r-project.org
Subject: Re: [R] Fwd: Question about paired plotting

Dear John and Tim!

Thanks a lot for your replies. This is just what I needed!!

All the best for you!!

2015-05-04 13:58 GMT-03:00 John Kane <jrkrideau at inbox.com>:

> Hi Luis,
> Ah yes, that paper.  I was rather shocked at what it implied :(  People
> are still using dynamite plots, for heaven's sake! See
> http://biostat.mc.vanderbilt.edu/wiki/Main/DynamitePlots  for some
> comments.
> I see Jim has given you one way to do the plots you want. Here is another
> way using the ggplot2 package. You will probably have to install the
> package.  The code below covers the 2B:2D plots.
> ####=======Install ggplot2===================
> install.packages("ggplot2")
>
> ###======== plot desired graphs==================
> library(ggplot2)
>
> dat1  <-  data.frame(x1  = rep("A", 4) , x2  =  rep("B", 4), y1  =  5:8,
> y2  = 10:13)
>
> p  <-  ggplot()
> p1  <-   p +  geom_segment( aes(x = x1, y = y1, xend =  x2,  yend = y2)) +
>           geom_point(aes(x1, y1, colour = "blue", size = 2)) +
>           geom_point(aes(x2, y2, colour = "red", size = 2))
> p1
>
>  p2  <-     p1 +     theme (legend.position = "none") +
>                   xlab("Treatment") + ylab("Change Score")
> p2
>
> ###======== end==================
>
> We could have all the commands in one statement but it is easier to write
> the code this way to help in debugging (damn typos1) and so I left it to
> help you see what is happening.
>
> For the lower plots, in ggplot2, you should have a look at geom_dotplot()
> . Here is an interesting demo of it in use.  I like the addition of the
> median line in particular.
>
>
>
http://rstudio-pubs-static.s3.amazonaws.com/1406_947a49f2d7914dad8b0fd050a9d
f9858.html
>
>
>
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: luysgarcia at gmail.com
> > Sent: Mon, 4 May 2015 04:52:51 -0300
> > To: r-help at r-project.org
> > Subject: [R] Fwd: Question about paired plotting
> >
> > Hello R experts,
> >
> > I just found a new paper which shows the proper way (according to the
> > authors) to show data, specially paired. I am very interested in
> > presenting
> > this kind of data, specially the scatter plott.  I have found a way to
> > present it using this link:
> >
> >
>
http://journals.plos.org/plosbiology/article?id=10.1371%2Fjournal.pbio.10021
28#pbio.1002128.s007
> >
> > Nevertheless, I wanted to know if you know some example which allows me
> > to
> > produce a plot similar to the plots 2B-2D. I could do it by "hand" but
it
> > was quite time consuming and required editing the pictures,
> >
> > Many thanks for any help you can provide!
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> Check it out at http://www.inbox.com/earth
>
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Tue May  5 05:56:22 2015
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Mon, 4 May 2015 20:56:22 -0700
Subject: [R] GSVD and qr questions
Message-ID: <EB00496A-AD4E-4834-9168-49307223F3C4@noaa.gov>

Hi All:

I posted some of this earlier to the r-sig-mac because at that time I got a Mac specific error, but now I have a more general question.  For a canonical variate analysis (CVA) used in some system identification routines, I need to calculate a generalized svd (GSVD).  On the web there are several scripts that are suppose to work with the LAPACK implementation of GSVD, but when I try them with my matrices I get an index error.  I can save the two arrays using R.matlab and read the matrices into Matlab, and the GSVD function in Matlab works fine for the same arrays.  I get the same error trying to use the GSVD routine in the PEIP package in R.

I have found a Matlab routine that calculates the GSVD using only QR, CHOL and SVD calls, but some of this is outside of what I know and I am trying to translate the routine to R.  I have two questions:

1.  Does anyone know of a working routine for GSVD in R  (and I looked in ?sos? that is how I found the one in PEIP)?

2. In the Matlab function I am trying to translate, they call for the QR decomposition  of the matrix A as qr(A,0).  The second argument (0) according to Matlab does the economy QR decomposition:

> qr(A,0) produces the economy-size decomposition. If m > n, only the first n columns of Q and the first n rows of R are computed. If m<=n, this is the same as [Q,R] = qr(A).

Reading over the help for the?qr?  function in R it is unclear that there is a similar way to do an ?economy? decomposition with one of the optional arguments.  I am probably being brain-dead, but I don?t see how to do that in the R function.

Thanks for any help.

-Roy M.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From kartikmanocha.87 at gmail.com  Mon May  4 21:32:30 2015
From: kartikmanocha.87 at gmail.com (Kartik Manocha)
Date: Tue, 5 May 2015 01:02:30 +0530
Subject: [R] Rhive queries failing
Message-ID: <CAP3=J=O-68wL8v422AnL=bFzC0Ywd9N-ZuNCQzYpvkYf0qkUCw@mail.gmail.com>

Hi folks,

I am facing an error while firing Rhive queries. Its able to connect via
hive server2, list tables do a simple select * operation.

But, a count operation is failing or if I do select "field" from
table_name, that fails too.

Any query that involves processing (like in MR terms) is failing. Mentioned
is the error which its prompting when a query fails

Error: java.sql.SQLException: Error while processing statement: FAILED:
Execution Error, return code 1 from
org.apache.hadoop.hive.ql.exec.mr.MapRedTask

If you have any thoughts or pointers that may help in debugging /
resolving, please let me know.


Thanks in advance,
Kartik

	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Mon May  4 21:38:00 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Mon, 4 May 2015 19:38:00 +0000
Subject: [R] using filter() to sum up
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A12F536F21C@EX10-LIVE-MBN2.ad.kent.ac.uk>

Hi everybody,

I am trying to create a code for the formula in the attachment. I first tried following code:

ltau <- m + theta*sum(psi*X[t-k])

but it does not work and I get for X[t-k] every third element in my vector three times which looks as follows:
X[t-k]
[1] -0.25 -0.25 -0.25 0.50 0.50 0.50 -0.44 -0.44 -0.44 0.15 0.15 0.15

Thus, I tried the filter() function in R which looks as follows:
ltau <- m + theta* filter(f.USA$UTS, phi(K, omega1, omega2), sides=1, method="conv")

Reading the description of this function I am unsure whether this provides the sum of the k lags. The appreviation "conv" provides, as far as I understand, the moving average instead of the sum.

Does anybody have an idea how the R code for the formula attached must look like? Is the filter() function appropriate?

Thanks in advance.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: tau.png
Type: image/png
Size: 8142 bytes
Desc: tau.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150504/7ceb3dd1/attachment.png>

From rmh at temple.edu  Tue May  5 06:10:54 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 5 May 2015 00:10:54 -0400
Subject: [R] GSVD and qr questions
In-Reply-To: <EB00496A-AD4E-4834-9168-49307223F3C4@noaa.gov>
References: <EB00496A-AD4E-4834-9168-49307223F3C4@noaa.gov>
Message-ID: <CAGx1TMDYLZ8yHcdRK8w40QSkJEcnLKwFT9=6Dy1ub0ZjQpLvBg@mail.gmail.com>

Roy,

Look at the qr.R and qr.Q functions.  With the complete=TRUE argument
they bring their matrices up to full size,
by constructing an arbitrary orthogonal completion.
Does this provide what you are looking for?

Rich

On Mon, May 4, 2015 at 11:56 PM, Roy Mendelssohn - NOAA Federal
<roy.mendelssohn at noaa.gov> wrote:
> Hi All:
>
> I posted some of this earlier to the r-sig-mac because at that time I got a Mac specific error, but now I have a more general question.  For a canonical variate analysis (CVA) used in some system identification routines, I need to calculate a generalized svd (GSVD).  On the web there are several scripts that are suppose to work with the LAPACK implementation of GSVD, but when I try them with my matrices I get an index error.  I can save the two arrays using R.matlab and read the matrices into Matlab, and the GSVD function in Matlab works fine for the same arrays.  I get the same error trying to use the GSVD routine in the PEIP package in R.
>
> I have found a Matlab routine that calculates the GSVD using only QR, CHOL and SVD calls, but some of this is outside of what I know and I am trying to translate the routine to R.  I have two questions:
>
> 1.  Does anyone know of a working routine for GSVD in R  (and I looked in ?sos? that is how I found the one in PEIP)?
>
> 2. In the Matlab function I am trying to translate, they call for the QR decomposition  of the matrix A as qr(A,0).  The second argument (0) according to Matlab does the economy QR decomposition:
>
>> qr(A,0) produces the economy-size decomposition. If m > n, only the first n columns of Q and the first n rows of R are computed. If m<=n, this is the same as [Q,R] = qr(A).
>
> Reading over the help for the?qr?  function in R it is unclear that there is a similar way to do an ?economy? decomposition with one of the optional arguments.  I am probably being brain-dead, but I don?t see how to do that in the R function.
>
> Thanks for any help.
>
> -Roy M.
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Tue May  5 06:14:38 2015
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Mon, 4 May 2015 21:14:38 -0700
Subject: [R] GSVD and qr questions
In-Reply-To: <CAGx1TMDYLZ8yHcdRK8w40QSkJEcnLKwFT9=6Dy1ub0ZjQpLvBg@mail.gmail.com>
References: <EB00496A-AD4E-4834-9168-49307223F3C4@noaa.gov>
	<CAGx1TMDYLZ8yHcdRK8w40QSkJEcnLKwFT9=6Dy1ub0ZjQpLvBg@mail.gmail.com>
Message-ID: <5F31DA41-6C09-4E55-81E5-DC7882391ADE@noaa.gov>

Thanks.  But to be honest I am outside of what I really know. so I don?t know if what you describe is what I want  I know what the Matlab function I have calls and what it does, and I am trying to mimic its functionality.  So I am trying to see if there is equivalent to the Matlab qr(A,0) call, that way I know I am getting the same result.

-Roy M.


> On May 4, 2015, at 9:10 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
> 
> Roy,
> 
> Look at the qr.R and qr.Q functions.  With the complete=TRUE argument
> they bring their matrices up to full size,
> by constructing an arbitrary orthogonal completion.
> Does this provide what you are looking for?
> 
> Rich
> 
> On Mon, May 4, 2015 at 11:56 PM, Roy Mendelssohn - NOAA Federal
> <roy.mendelssohn at noaa.gov> wrote:
>> Hi All:
>> 
>> I posted some of this earlier to the r-sig-mac because at that time I got a Mac specific error, but now I have a more general question.  For a canonical variate analysis (CVA) used in some system identification routines, I need to calculate a generalized svd (GSVD).  On the web there are several scripts that are suppose to work with the LAPACK implementation of GSVD, but when I try them with my matrices I get an index error.  I can save the two arrays using R.matlab and read the matrices into Matlab, and the GSVD function in Matlab works fine for the same arrays.  I get the same error trying to use the GSVD routine in the PEIP package in R.
>> 
>> I have found a Matlab routine that calculates the GSVD using only QR, CHOL and SVD calls, but some of this is outside of what I know and I am trying to translate the routine to R.  I have two questions:
>> 
>> 1.  Does anyone know of a working routine for GSVD in R  (and I looked in ?sos? that is how I found the one in PEIP)?
>> 
>> 2. In the Matlab function I am trying to translate, they call for the QR decomposition  of the matrix A as qr(A,0).  The second argument (0) according to Matlab does the economy QR decomposition:
>> 
>>> qr(A,0) produces the economy-size decomposition. If m > n, only the first n columns of Q and the first n rows of R are computed. If m<=n, this is the same as [Q,R] = qr(A).
>> 
>> Reading over the help for the?qr?  function in R it is unclear that there is a similar way to do an ?economy? decomposition with one of the optional arguments.  I am probably being brain-dead, but I don?t see how to do that in the R function.
>> 
>> Thanks for any help.
>> 
>> -Roy M.
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new address and phone***
>> 110 Shaffer Road
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>> 
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From rmh at temple.edu  Tue May  5 06:30:38 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 5 May 2015 00:30:38 -0400
Subject: [R] GSVD and qr questions
In-Reply-To: <5F31DA41-6C09-4E55-81E5-DC7882391ADE@noaa.gov>
References: <EB00496A-AD4E-4834-9168-49307223F3C4@noaa.gov>
	<CAGx1TMDYLZ8yHcdRK8w40QSkJEcnLKwFT9=6Dy1ub0ZjQpLvBg@mail.gmail.com>
	<5F31DA41-6C09-4E55-81E5-DC7882391ADE@noaa.gov>
Message-ID: <CAGx1TMChijTZb2NoLYcitazC6xXOOptzUcdX=1vxWf15NBZ2oA@mail.gmail.com>

off line
I looked at the matlab page and the wikipedia page.
Wikipedia says there are two different things with the gsvd name.

So I guess we need to see a tiny example of your starting matrix
and the decomposition that the matlab function you call returns to you.
I guess you will have to send the "reproducible example" to the list.

Rich

On Tue, May 5, 2015 at 12:14 AM, Roy Mendelssohn - NOAA Federal
<roy.mendelssohn at noaa.gov> wrote:
> Thanks.  But to be honest I am outside of what I really know. so I don?t know if what you describe is what I want  I know what the Matlab function I have calls and what it does, and I am trying to mimic its functionality.  So I am trying to see if there is equivalent to the Matlab qr(A,0) call, that way I know I am getting the same result.
>
> -Roy M.
>
>
>> On May 4, 2015, at 9:10 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
>>
>> Roy,
>>
>> Look at the qr.R and qr.Q functions.  With the complete=TRUE argument
>> they bring their matrices up to full size,
>> by constructing an arbitrary orthogonal completion.
>> Does this provide what you are looking for?
>>
>> Rich
>>
>> On Mon, May 4, 2015 at 11:56 PM, Roy Mendelssohn - NOAA Federal
>> <roy.mendelssohn at noaa.gov> wrote:
>>> Hi All:
>>>
>>> I posted some of this earlier to the r-sig-mac because at that time I got a Mac specific error, but now I have a more general question.  For a canonical variate analysis (CVA) used in some system identification routines, I need to calculate a generalized svd (GSVD).  On the web there are several scripts that are suppose to work with the LAPACK implementation of GSVD, but when I try them with my matrices I get an index error.  I can save the two arrays using R.matlab and read the matrices into Matlab, and the GSVD function in Matlab works fine for the same arrays.  I get the same error trying to use the GSVD routine in the PEIP package in R.
>>>
>>> I have found a Matlab routine that calculates the GSVD using only QR, CHOL and SVD calls, but some of this is outside of what I know and I am trying to translate the routine to R.  I have two questions:
>>>
>>> 1.  Does anyone know of a working routine for GSVD in R  (and I looked in ?sos? that is how I found the one in PEIP)?
>>>
>>> 2. In the Matlab function I am trying to translate, they call for the QR decomposition  of the matrix A as qr(A,0).  The second argument (0) according to Matlab does the economy QR decomposition:
>>>
>>>> qr(A,0) produces the economy-size decomposition. If m > n, only the first n columns of Q and the first n rows of R are computed. If m<=n, this is the same as [Q,R] = qr(A).
>>>
>>> Reading over the help for the?qr?  function in R it is unclear that there is a similar way to do an ?economy? decomposition with one of the optional arguments.  I am probably being brain-dead, but I don?t see how to do that in the R function.
>>>
>>> Thanks for any help.
>>>
>>> -Roy M.
>>>
>>> **********************
>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>> **********************
>>> Roy Mendelssohn
>>> Supervisory Operations Research Analyst
>>> NOAA/NMFS
>>> Environmental Research Division
>>> Southwest Fisheries Science Center
>>> ***Note new address and phone***
>>> 110 Shaffer Road
>>> Santa Cruz, CA 95060
>>> Phone: (831)-420-3666
>>> Fax: (831) 420-3980
>>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>>
>>> "Old age and treachery will overcome youth and skill."
>>> "From those who have been given much, much will be expected"
>>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>


From petr.pikal at precheza.cz  Tue May  5 08:54:21 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 5 May 2015 06:54:21 +0000
Subject: [R] Problem in r help me
In-Reply-To: <CADG8gkuMcvLjnoW5uaNj4mdS30gNbNQf4m6ruzALc-+DPh+Mgg@mail.gmail.com>
References: <CADG8gktu_zJ8Ex0Sx1yo=wYd6dV=f_ZTXrQ8BWcF+OediaYf-g@mail.gmail.com>
	<CADG8gktkT7DTzjVr6f957Fcg-=9-4rhv=fFhajvz+pFoi+oFgQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2C67A@SRVEXCHMBX.precheza.cz>
	<CADG8gkuMcvLjnoW5uaNj4mdS30gNbNQf4m6ruzALc-+DPh+Mgg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2C964@SRVEXCHMBX.precheza.cz>


From: Ghada Almousa [mailto:ghada.f.mm at gmail.com]
Sent: Monday, May 04, 2015 9:20 PM
To: PIKAL Petr
Subject: Re: Problem in r help me

I used internet search to get info about methods but I can't find any info about the comparison between those methods
The comparison in the number of iterations , the time required to build each Cluster  and sum square error SSE for each cluster in the R programming

Pardon me, but does not number of iterations, time and SSE depends also on data used for the analysis?

Cheers
Petr

On Monday, May 4, 2015, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

Your question is rather cryptic. Data? Code?

You can use internet search to get info about methods

e.g

R hierarchical clustering

gives me many answer regarding clustering in R.

Be more specific to get more specific answer

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ghada
> Almousa
> Sent: Saturday, May 02, 2015 11:03 AM
> To: r-help at r-project.org
> Subject: Re: [R] Problem in r help me
>
> > hello dears
> >
> > I have Search to compare the results between the three types of
> > cluster k-maen ,Em and  Hierarchal clusters How i figured the number
> > of iterations , the time required to build each Cluster ,
> and
> > sum square error SSE for each cluster in the R programming
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From luysgarcia at gmail.com  Tue May  5 09:34:10 2015
From: luysgarcia at gmail.com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Tue, 5 May 2015 04:34:10 -0300
Subject: [R] Sort data and symbol change in Jitter plot (ggplot2)
Message-ID: <CANxP2S52MVNNp_GB2=E4q14S24vk9rm1jMyg_-N2hcXWENohNQ@mail.gmail.com>

Dear R experts,

First than all I want to thank your expertise and for sharing your
knowledge with the people who are starting.

Recently I have been working on a new plot style (Jitterplot) but have
still some issues when making two basic functions.

First than all I want to change the symbol according to the prey type
(presa) and not the color, I tried making, geom_dotplot(aes(fill = PRESA)
but it did not work

On a second hand I want to sort the plots from the highest to the lowest
value, I tried by using reorder, but it did not work.

Please find attached the dataset and the script.

Thanks in advance!

####script######

the dataset is attached
library(ggplot2)
p=read.table("paratropis.txt",header=T)
attach(p)
ggplot( data = p, aes(y = Tiempo, x = PRESA, reorder(PRESA, Tiempo, mean)))
+ # Move y and x here so than they can be used in stat_*
  geom_dotplot(aes(shape = PRESA),
               binaxis = "y",         # which axis to bin along
               binwidth = 0.1,        # Minimal difference considered
diffeerent
               stackdir = "center"    # Centered
  ) +
  stat_summary(fun.y = mean, fun.ymin = mean, fun.ymax = mean,
               geom = "crossbar", width = 0.5)
-------------- next part --------------
Ara?a	PRESA	TAMA?O	Tiempo		
Ara1	L.lepi	peque?o	255506		
Ara2	L.passa	grande	439724		
Ara3	L.cicin	peque?o	408377		
Ara3	L.passa	grande	268235		
Ara3	L.passa	peque?o	419578		
Ara3	L.rute	peque?o	427730		
Ara3	L.lepi	grande 	351840		
Ara4	L.cicin	peque?o	548918		
Ara4	L.passa	peque?o	438361		
Ara4	L.rute	grande 	903518		
Ara4	L.rute	peque?o	359928		
Ara4	L.lepi	grande 	332754		
Ara4	L.lepi	peque?o	267759		
Ara6	L.rute	peque?o	227514		
Ara7	L.cicin	peque?o	494398		
Ara7	L.passa	grande	218080		
Ara7	L.rute	grande 	485121		
Ara7	L.rute	peque?o	498692		
Ara7	L.lepi	grande 	248303		
Ara7	L.lepi	peque?o	101027		
Ara8	L.lepi	grande 	320952		
Ara9	L.cicin 	grande	334014		
Ara9	L.cicin	peque?o	232391		
Ara9	L.passa	peque?o	447254		
Ara9	L.rute	grande 	533385		
Ara9	L.rute	peque?o	864524		
Ara9	L.lepi	grande 	282418		
Ara9	L.lepi	peque?o	169500		
Ara10	L.cicin 	grande	476236		
Ara10	L.cicin	peque?o	377899		
Ara10	L.rute	peque?o	426247		
Ara11	L.passa	grande	286441		
Ara11	L.rute	peque?o	544675		
Ara11	L.lepi	grande 	397056		
Ara12	L.passa	grande	217148		
Ara12	L.rute	grande 	438068		
Ara12	L.lepi	grande 	389474		
Ara14	L.cicin 	grande	513290		
Ara14	L.passa	grande	356091		
Ara15	L.cicin	peque?o	511906		
Ara16	L.cicin	peque?o	790962		
Ara16	L.passa	grande	507399		
Ara16	L.rute	peque?o	298853		
Ara17	L.cicin 	grande	468640		
Ara17	L.rute	peque?o	392512		
Ara18	L.rute	peque?o	473115		
Ara19	L.cicin 	grande	578176		
Ara19	L.cicin	peque?o	479934		
Ara19	L.passa	peque?o	319707		
Ara19	L.rute	grande 	347096		
Ara21	L.cicin 	grande	546950		
Ara23	L.cicin 	grande	371814		
Ara23	L.passa	grande	287769		
Ara23	L.passa	peque?o	281093		
Ara23	L.rute	grande 	429621		
Ara23	L.lepi	grande 	208509		
Ara24	L.cicin 	grande	393763		
Ara25	L.cicin 	grande	469052		
Ara25	L.lepi	grande 	410563		
Ara25	L.lepi	peque?o	439584		
Ara26	L.cicin	peque?o	485701		
Ara26	L.rute	grande 	391971		
Ara27	L.cicin 	grande	491197		
Ara28	L.passa	peque?o	308984		
Ara29	L.lepi	peque?o	472830		
Ara30	L.passa	peque?o	249036		
Ara31	L.passa	grande	217148		
Ara31	L.passa	peque?o	212454		
Ara31	L.lepi	peque?o	234619		
Ara32	L.passa	peque?o	230255		
Ara32	L.lepi	peque?o	297512		
Ara34	L.rute	grande 	352213		
Ara34	L.passa	peque?o	191547		
Ara34	L.lepi	peque?o	201616		
Ara36	L.lepi	grande 	411587		
					

From petr.pikal at precheza.cz  Tue May  5 11:21:10 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 5 May 2015 09:21:10 +0000
Subject: [R] Sort data and symbol change in Jitter plot (ggplot2)
In-Reply-To: <CANxP2S52MVNNp_GB2=E4q14S24vk9rm1jMyg_-N2hcXWENohNQ@mail.gmail.com>
References: <CANxP2S52MVNNp_GB2=E4q14S24vk9rm1jMyg_-N2hcXWENohNQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2CA2B@SRVEXCHMBX.precheza.cz>

Hi

answeres in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luis
> Fernando Garc?a
> Sent: Tuesday, May 05, 2015 9:34 AM
> To: r-help at r-project.org
> Subject: [R] Sort data and symbol change in Jitter plot (ggplot2)
>
> Dear R experts,
>
> First than all I want to thank your expertise and for sharing your
> knowledge with the people who are starting.
>
> Recently I have been working on a new plot style (Jitterplot) but have
> still some issues when making two basic functions.
>
> First than all I want to change the symbol according to the prey type
> (presa) and not the color, I tried making, geom_dotplot(aes(fill =
> PRESA)
> but it did not work
>
> On a second hand I want to sort the plots from the highest to the
> lowest
> value, I tried by using reorder, but it did not work.
>
> Please find attached the dataset and the script.
>
> Thanks in advance!
>
> ####script######
>
> the dataset is attached
> library(ggplot2)
> p=read.table("paratropis.txt",header=T)
> attach(p)

Do not use attach, it only confuses things.

firs reorder your factor

p$PRESA <- reorder(p$PRESA, p$Tiempo, mean)

then use geom point to get different shapes.

pl<-ggplot( data = p, aes(y = Tiempo, x = PRESA, shape=PRESA))
pl + geom_point()+ geom_dotplot(binaxis = "y", binwidth = 0.1, stackdir = "center") +
  stat_summary(fun.y = mean, fun.ymin = mean, fun.ymax = mean, geom = "crossbar", width = 0.5)

Is this what you wanted?

Cheers
Petr

> ggplot( data = p, aes(y = Tiempo, x = PRESA, reorder(PRESA, Tiempo,
> mean)))
> + # Move y and x here so than they can be used in stat_*
>   geom_dotplot(aes(shape = PRESA),
>                binaxis = "y",         # which axis to bin along
>                binwidth = 0.1,        # Minimal difference considered
> diffeerent
>                stackdir = "center"    # Centered
>   ) +
>   stat_summary(fun.y = mean, fun.ymin = mean, fun.ymax = mean,
>                geom = "crossbar", width = 0.5)

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pdalgd at gmail.com  Tue May  5 11:40:56 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 5 May 2015 11:40:56 +0200
Subject: [R] using filter() to sum up
In-Reply-To: <AEB16B1613D44C4793A7E6B6986B7A12F536F21C@EX10-LIVE-MBN2.ad.kent.ac.uk>
References: <AEB16B1613D44C4793A7E6B6986B7A12F536F21C@EX10-LIVE-MBN2.ad.kent.ac.uk>
Message-ID: <3B6A60F0-7CB7-4ECF-A675-CEC6FF0962CC@gmail.com>


On 04 May 2015, at 21:38 , T.Riedle <tr206 at kent.ac.uk> wrote:

> Hi everybody,
> 
> I am trying to create a code for the formula in the attachment. I first tried following code:
> 
> ltau <- m + theta*sum(psi*X[t-k])
> 

That's not going to work. It might work with something like

sum(psi*X[(t-1):(t-K)])


> but it does not work and I get for X[t-k] every third element in my vector three times which looks as follows:
> X[t-k]
> [1] -0.25 -0.25 -0.25 0.50 0.50 0.50 -0.44 -0.44 -0.44 0.15 0.15 0.15
> 
> Thus, I tried the filter() function in R which looks as follows:
> ltau <- m + theta* filter(f.USA$UTS, phi(K, omega1, omega2), sides=1, method="conv")
> 
> Reading the description of this function I am unsure whether this provides the sum of the k lags. The appreviation "conv" provides, as far as I understand, the moving average instead of the sum.

I would assume that it means convolution. Which is what you have in the formula.

> Does anybody have an idea how the R code for the formula attached must look like? Is the filter() function appropriate?

It's barking up the right tree, but do your own checks...

-pd


> Thanks in advance.
> <tau.png>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From roryrwilson at yahoo.ca  Tue May  5 10:48:03 2015
From: roryrwilson at yahoo.ca (Rory Wilson)
Date: Tue, 5 May 2015 08:48:03 +0000 (UTC)
Subject: [R] append to all warnings
Message-ID: <829082335.172238.1430815683624.JavaMail.yahoo@mail.yahoo.com>

Hello all,This may be a "newbie" type question but I am rather stuck. I would like to alter my R options such that anytime a warning is generated, the standard warning message is generated, as well as additional details that I would specify (ie, time/date, etc.)
It seems to me something like?
myWarning <- function () {? warnings()? print(Sys.time())}
options(warn=1,warning.expression=quote(myWarning()))
could almost(!) work, but all it does it print the date, rather than the original warning message AND the date.
ie,
log(c(3,-5))

gives
[1] "2015-05-05 04:42:52 EDT"
[1] 1.098612      NaN
I am sure there is a simple solution, but I cannot find it in the help, nor by Googling. ?
Thank you all for your help! Sorry if this is rather elementary.
Rory

	[[alternative HTML version deleted]]


From bretschr at xs4all.nl  Tue May  5 12:26:22 2015
From: bretschr at xs4all.nl (Franklin Bretschneider)
Date: Tue, 5 May 2015 12:26:22 +0200
Subject: [R] A problem with string handling to make a time duration
In-Reply-To: <1430769548728-4706795.post@n4.nabble.com>
References: <1430769548728-4706795.post@n4.nabble.com>
Message-ID: <418D5904-0EF7-4E40-8F30-D1500B10092A@xs4all.nl>

Hello gavinr,

> I have a character string that represents a time duration. It has an hours
> minutes seconds structure(ish) but with letters denoting units (H,M or S) no
> leading zeros and no placeholder at all where one or other of the units are
> not required.
> 
> It looks like this:
> 
> t<-c("10H20M33S","1H1M","1M","21M9S","2H55S" ))
> df<-data.frame(t)
> df
> 
> #ideally should look like:
> t2<-c("10:20:33","01:00:01","00:01:00","00:21:09","02:00:55") 
> df2<-data.frame(t2)
> df2
> 
> I need to get it into hours minutes and seconds either in time format or as
> a string with leading zeros and all three time units represented in each
> one, as in df2.  The data, part of a very large dataset, are for onward use
> and processing in a GIS application.  I?ve messed about with string handling
> statements in SQL to no avail, but wondered if R would be a better bet? 
> I?ve had a look at some of the commands in stringr, but am unsure how to
> operationalise a solution using this package.  Any advice is welcome.
> 


This can be done easily with the substring function, e.g.

# say:

string="12H15M45S"

#then pick:

h=substr(string,1,2)
m=substr(string,4,5)

#  and join again:

newstr = paste(h,m,sep=":")
#  etcetera

Success and
Best regards,

Frank
--


Franklin Bretschneider
Dept of Biology
Utrecht University
bretschr at xs4all.nl


From ldhrf at siswa.ukm.edu.my  Tue May  5 12:59:59 2015
From: ldhrf at siswa.ukm.edu.my (Nasr Al-Dhurafi)
Date: Tue, 5 May 2015 18:59:59 +0800
Subject: [R] Transformation of the circular variable into linear variable
In-Reply-To: <CAFUdcV_DUC3EMG44gcfJ_cdWpmFBw1B+tWjuDuFyHm6uKDZfEQ@mail.gmail.com>
References: <CAFUdcV_DUC3EMG44gcfJ_cdWpmFBw1B+tWjuDuFyHm6uKDZfEQ@mail.gmail.com>
Message-ID: <CAFUdcV8Pddkn+ENu-MfrD+649JXHMLoFcugpBz8PTtan5nBrLw@mail.gmail.com>

Dear All

I am working with a circular data ( wind direction ) and i have problem
in transforming  the circular variable into linear variable. I have found
an equation that can be used to convert the circular variable into linear
variable which is included in this paper *" ARMA based approaches for
forecasting the tuple of wind speed and direction". *The equation is called
as the inverse of a link function and i have attached  the summery of it.T
herefore,Please, if you have an idea of how to conduct it in R programming
or  if you have another method for transformation, let me know it. Your
cooperation is highly appreciated.

My Best Regards &  All The Best

Nasr

On Mon, Mar 30, 2015 at 8:22 PM, Nasr Al-Dhurafi <ldhrf at siswa.ukm.edu.my>
wrote:

> I am working with a circular data ( wind direction ) and i have problem
> in transforming  the circular variable into linear variable. I have found
> an equation that can be used to convert the circular variable into linear
> variable which is included in this paper *" ARMA based approaches for
> forecasting the tuple of wind speed and direction". *The equation is
> called as the inverse of a link function and i have attached  the summery
> of it.Therefore,Please, if you have an idea of how to conduct it in R
> programming or  if you have another method for transformation, let me
> know it. Your cooperation is highly appreciated.
>
> My Best Regards &  All The Best
> Nasr
>

	[[alternative HTML version deleted]]


From g.rudge at bham.ac.uk  Tue May  5 14:00:06 2015
From: g.rudge at bham.ac.uk (gavinr)
Date: Tue, 5 May 2015 05:00:06 -0700 (PDT)
Subject: [R] A problem with string handling to make a time duration
In-Reply-To: <1430769548728-4706795.post@n4.nabble.com>
References: <1430769548728-4706795.post@n4.nabble.com>
Message-ID: <1430827206208-4706822.post@n4.nabble.com>

Thanks guys. The first solution with the gsub / lapply works perfectly. The
solution using substrings would work if the times were in a consistent
format, but without the leading zeros and with some parts of the string
absent completely it would need some extra logic to apply. I need something
to automate over a data set with a million or so time points in it.



--
View this message in context: http://r.789695.n4.nabble.com/A-problem-with-string-handling-to-make-a-time-duration-tp4706795p4706822.html
Sent from the R help mailing list archive at Nabble.com.


From lutipilotto at yahoo.com.br  Tue May  5 14:13:49 2015
From: lutipilotto at yahoo.com.br (Luciane Maria Pilotto)
Date: Tue, 5 May 2015 05:13:49 -0700
Subject: [R] help - hoslem.test
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2C7C6@SRVEXCHMBX.precheza.cz>
Message-ID: <1430828029.46062.YahooMailBasic@web120204.mail.ne1.yahoo.com>

Hi

Thanks for the help!
I used the following commands to run the test hoslem:

rl<-id3[,c("q06", "q08", "q10", "q11", "q12", "q13", "q14", "sexo", "edcat", "rendacat", "cpod", 
          "getario", "bwgr_et")]#select only variables of interest
dim(rl)#[1] 22843    12
attach(rl)

q131 <- as.numeric(cut(rl$q13,c(0,1.5,5)))-1
rl<-cbind(rl,q131)

rlna<-rl[complete.cases(rl),]#exclude NA

tpna <- glm(q131 ~ q11 + q10+rendacat+q12 + q08+q06 + q14, 
            family = binomial(link = "logit"), data=rlna)
hoslem.test(rlna$q131, fitted(tpna), g=10)

Thanks
Luciane

--------------------------------------------
Em seg, 4/5/15, PIKAL Petr <petr.pikal at precheza.cz> escreveu:

 Assunto: RE: [R] help - hoslem.test

t.org" <r-help at r-project.org>
 Data: Segunda-feira, 4 de Maio de 2015, 10:24

 Hi

 thanks for data.

 na.exclude does not excludes NA values. Actually it computes
 result without considering NAs but keeps those NA values in
 propper positions so that the result has the same length as
 input

 Instead of several ifelse you can use

 q131 <- as.numeric(cut(id3$q13,c(0,1.5,5)))-1

 fitted values start with NA values

 > fitted(tp1)
 ? ? ? ? 1241? ? ?
 ???1242? ? ?
 ???1243? ? ?
 ???1244? ? ?
 ???1245? ? ?
 ???1246
 ? ? ? ? ? NA? ? ?
 ? ???NA 2.143345e-11 2.143345e-11
 2.143345e-11 2.143345e-11
 ? ? ? ? 1247? ? ?
 ???1248? ? ?
 ???1256? ? ?
 ???1268
 2.143345e-11 2.143345e-11 2.143345e-11 2.143345e-11

 which obviously hoslem.test is not adapted to.

 >
 > #Error in quantile.default(yhat, probs = seq(0, 1,
 1/g)) :
 >? # missing values and NaN's not allowed if 'na.rm'
 is FALSE

 you can use glm without na.action and your fitted values
 will be without NA.

 > tp1 <- glm(q131 ~ q11 + q10+q12+edcat + q08+q06+
 q14, family = binomial(link = "logit"), data=id3)
 > fitted(tp1)
 ? ? ? ? 1243? ? ?
 ???1244? ? ?
 ???1245? ? ?
 ???1246? ? ?
 ???1247? ? ?
 ???1248
 2.143345e-11 2.143345e-11 2.143345e-11 2.143345e-11
 2.143345e-11 2.143345e-11
 ? ? ? ? 1256? ? ?
 ???1268
 2.143345e-11 2.143345e-11

 however
 tp1$q131 does not exist

 > tp1$q131
 NULL
 So again, test throws error.

 Maybe you wanted

 > hoslem.test(na.omit(id3$q131), fitted(tp1), g=10)

 ? ? ? ? Hosmer and Lemeshow goodness of
 fit (GOF) test

 data:? na.omit(id3$q131), fitted(tp1)
 X-squared = NaN, df = 8, p-value = NA

 Warning message:
 In Ops.factor(1, y) : ?-? not meaningful for factors

 However q131 is factor (actually you changed it to factor)

 If I change it to numeric

 > id3$q131<-q131
 > tp1 <- glm(q131 ~ q11 + q10+q12+edcat + q08+q06+
 q14, family = binomial(link = "logit"), data=id3)
 > hoslem.test(na.omit(id3$q131), fitted(tp1), g=10)

 ? ? ? ? Hosmer and Lemeshow goodness of
 fit (GOF) test

 data:? na.omit(id3$q131), fitted(tp1)
 X-squared = NaN, df = 8, p-value = NA

 hoslem test works - at least it does not throw errors.

 So best way for you would be to understand basic differences
 in object types (numeric, factor, ....) by reading R intro
 and think about what hoslem test needs as an input.

 Cheers
 Petr

 > -----Original Message-----

 > Sent: Monday, May 04, 2015 2:46 PM
 > To: r-help at r-project.org;
 PIKAL Petr
 > Subject: RE: [R] help - hoslem.test
 >
 > Hi
 >
 > I'm trying to make a reproducible example using the
 command "dput" as
 > fallows.
 >
 > The problem occurs when running the test of Hosmer and
 Lemeshow
 > (hoslem.test) for residuals gives error. I'm using the
 command
 > "na.action" to exclude the NA values.
 >
 > Thanks,
 > Luciane
 >
 > ###############################################
 >
 > load(file.choose())#dataframe:"id3.rda"
 > attach(id3)
 >

 <snip>

 >
 > #create binary outcome variable (q13) (transformando
 q13 em bin?ria)
 >
 q131<-ifelse(q13==1,0,ifelse(q13==2,1,ifelse(q13==3,1,
 > ifelse(q13==4,1,ifelse(q13==5,1,NA)))))

 Instead of several ifelse you can use

 q131 <- as.numeric(cut(id3$q13,c(0,1.5,5)))-1

 > id3<-cbind(id3,q131)
 > id3$q131 <- as.factor(id3$q131)
 >
 > str(id3)
 >
 > tp1 <- glm(q131 ~ q11 + q10+q12+edcat + q08+q06+
 q14, family =
 > binomial(link = "logit"), data=id3,
 na.action="na.exclude")
 > tp1
 >
 > library(ResourceSelection)
 > hoslem.test(tp1$q131, fitted(tp1), g=10)
 >
 >
 >
 >
 > --------------------------------------------
 > Em sex, 1/5/15, PIKAL Petr <petr.pikal at precheza.cz>
 escreveu:
 >
 >? Assunto: RE: [R] help - hoslem.test

 "r-help at r-
 > project.org" <r-help at r-project.org>
 >? Data: Sexta-feira, 1 de Maio de 2015, 3:59
 >
 >? Hi
 >
 >? > -----Original Message-----

 >? > Sent: Friday, May 01, 2015 12:49 AM
 >? > To: PIKAL Petr; r-help at r-project.org;
 >? John Kane
 >? > Subject: Re: [R] help -
 >? hoslem.test
 >? >
 >? > Ok, in
 >? dropbox link below you can download the bank.
 >? > (https://www.dropbox.com/s/9qrdf4mhd6tzypi/id3.rda?dl=0)
 >
 >? No. Not everybody is alowed to
 >? use dropbox. Try to post result of
 >
 >? dput(id3)
 >
 >? directly to your post.
 >
 >? Cheers
 >? Petr
 >
 >? >
 >? > I change the script
 >? following the suggestions, but the error
 persists.
 >? > I used the the na.action command to delete
 >? the lost values.
 >? >
 >? >
 >
 >
 #######################################################################
 >? >
 >? >
 >? load("id3.rda")
 >? >
 >? attach(id3)
 >? >
 >? >
 >? #transformando q13 em bin?ria (o/1)
 >? >
 >?
 q131<-ifelse(q13==1,0,ifelse(q13==2,1,ifelse(q13==3,1,
 >? > ifelse(q13==4,1,ifelse(q13==5,1,NA)))))
 >? > id3<-cbind(id3,q131)
 >? > id3$q131 <- as.factor(id3$q131)
 >? > str(id3)
 >? >
 >? > tp1 <- glm(q131 ~ q11 + q10+q12+edcat +
 >? q08+q06+ q14, family =
 >? > binomial(link =
 >? "logit"), data=id3,
 >? na.action="na.exclude")
 >? >
 >? tp1
 >? > hoslem.test(tp1$q131, fitted(tp1),
 >? g=10)
 >? >
 >? >
 >? >
 >? >
 >? --------------------------------------------
 >? > Em qui, 30/4/15, John Kane <jrkrideau at inbox.com>
 >? escreveu:
 >? >
 >? >
 >? Assunto: Re: [R] help - hoslem.test
 >? >
 >? Para: "PIKAL Petr" <petr.pikal at precheza.cz>,
 >? "Luciane Maria Pilotto"
 >? >

 >? "r-help at r-project.org"
 >? <r-help at r-
 >? > project.org>
 >? >
 >? Data: Quinta-feira, 30 de Abril de 2015, 11:51
 >? >
 >? >? Kevin Thorpe
 >? pointed out
 >? >? to me that there is a
 >? dropbox link at the very bottom of the
 >? >? post that I missed. :(
 >? >
 >? >? I
 >? >? just downloaded it, read it in and it
 >? looks fine.
 >? >
 >? >? John
 >? Kane
 >? >? Kingston ON Canada
 >? >
 >? >
 >? >? > -----Original
 >? >? Message-----
 >? >? >
 >? From: petr.pikal at precheza.cz
 >? >? > Sent: Thu, 30 Apr 2015 14:25:23
 >? +0000

 >? >? r-help at r-project.org
 >? >? > Subject: Re: [R] help -
 >? hoslem.test
 >? >? >
 >? >? > Hi
 >? >? >
 >? >? > I agree with John
 >? >? >
 >? >? > Just
 >? small
 >? >? refinements in lines
 >? >? >
 >? >? >>
 >? -----Original Message-----
 >? >
 >? >>> -----Original Message-----

 >? >? >>> Sent: Thu, 30 Apr 2015
 >? 04:24:32
 >? >? -0700
 >? >
 >? >>> To: r-help at r-project.org,
 >? >? jrkrideau at inbox.com
 >? >? >>> Subject: RE: [R] help -
 >? >? hoslem.test
 >? >
 >? >>>
 >? >? >>>
 >? load("id3.rda")
 >? >? >>
 >? And what is this?
 >? >? >>
 >? >? >> We do not
 >? >? have access to your office or
 computer
 >? hard disc.
 >? >? >>
 >? >? >> Please read
 >? >? http://stackoverflow.com/questions/5963269/how-to-make-a-
 >? >? >>
 great-r-reproducible-example,
 >? see
 >? >? ?dput for sending data?
 >? >? >>
 >? >? >>
 >? It is very unlikely anyone here can
 >? >
 >? help if we have no data.
 >? >? >>
 >? >? >>
 >? >
 >? >>>
 >? >? attach(id3)
 >? >? >
 >? >? > Do
 >? >? not use attach. It prevents from
 >? modifiyng id3.
 >? >? >
 >? >? >>>
 >? >
 >? >>> #transformando q13 em bin?ria
 >? >? >>>
 >? >
 >?
 q131<-ifelse(q13==1,1,ifelse(q13==2,2,ifelse(q13==3,2,
 >? >? >>>
 >? >
 >? ifelse(q13==4,2,ifelse(q13==5,2,NA)))))
 >? >? >
 >? >
 >? >? > q131 <- as.numeric(cut(q13,
 >? >? c(0,1.5,5)))
 >? >
 >? >
 >? >? >>
 >? >
 >? x<-1:7
 >? >? >> x
 >? >? >
 >? >? [1] 1 2 3 4
 >? 5 6 7
 >? >? >> as.numeric(cut(x,
 >? >? c(0,1.5,5)))
 >? >? >
 >? [1]? 1? 2? 2? 2? 2 NA
 >? >? NA
 >? >? >
 >? >
 >? >>>
 >? >
 >? id3<-cbind(id3,q131)
 >? >? >
 >? >? > rather dangerous in case id3 is
 >? not
 >? >? data.frame but matrix
 >? >? >
 >? >? >>>
 >? id3$q131 <-
 >? >? as.factor(id3$q131)
 >? >? >>>
 >? >
 >? >>> tp1 <- glm(q131 ~ q11 +
 >? >? q10+q12+edcat + q08+q06+ q14, family
 >? =
 >? >? >>> binomial(link =
 >? >? "logit"), data=id3)
 >? >? >>>
 >? >
 >? tp1
 >? >? >>>
 >? >? >>>
 >? library(ResourceSelection)
 >? >
 >? >>> hoslem.test(tp1$q131, fitted(tp1),
 >? >? g=10)
 >? >? >
 >? >? > hoslem.test
 >? >
 >? expects x to be a numeric vector of observations,
 binary
 >? >? > (0/1).
 >? >? >
 >? If I
 >? >? understand correctly tp1$q131
 >? have values 1, 2 or NA.
 >? >? >
 >? >? > Cheers
 >? >? >
 >? Petr
 >? >? >
 >? >
 >? >>>
 >? >? >>>
 >? >? dataframe: https://www.dropbox.com/s/9qrdf4mhd6tzypi/id3.rda?dl=0
 >? >? >>>
 >? >
 >? >>>
 >? >? >>>
 >? >
 >?
 __________________________________________________
 >? >? >>> Luciane Maria Pilotto
 >? >? >>> Mestre e Doutoranda em
 >? Sa?de
 >? >? Bucal Coletiva - FO/UFRGS
 >? >? >>> NDE
 >? >
 >? Odontologia - UNIVATES
 >? >
 >? >>>
 >? >? Telefone: (51)
 >? 84512344
 >? >? >>>
 >? >? >>>
 >? >
 >? --------------------------------------------
 >? >? >>> Em qui, 30/4/15, John
 Kane
 >? <jrkrideau at inbox.com>
 >? >? escreveu:
 >? >
 >? >>>
 >? >? >>>? Assunto:
 >? RE: [R] help -
 >? >? hoslem.test
 >? >? >>>? Para:

 >? >? >>> r-help at r-project.org
 >? >? >>>? Data: Quinta-feira,
 30 de
 >? Abril
 >? >? de 2015, 7:52
 >? >? >>>
 >? >
 >? >>>? http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-
 >? >? >> reproducible-example
 >? >? >>>
 >? >
 >? >>>
 >? >? John Kane
 >? >? >>>? Kingston ON
 >? >? Canada
 >? >
 >? >>>
 >? >? >>>
 >? >? >>>
 >? >? >
 >? -----Original Message-----
 >? >

 >? >? >>>? > Sent: Wed, 29
 Apr
 >? 2015
 >? >? 18:45:26 -0700
 >? >? >>>? > To: r-help at r-project.org
 >? >? >>>? > Subject: [R]
 help
 >? -
 >? >? hoslem.test
 >? >
 >? >>>? >
 >? >? >>>
 >? > Hello,
 >? >? >>>? >
 >? >? >>>? > I'm working
 >? with
 >? >? >>>? ordinal logistic
 >? regression
 >? >? model (polr) and would
 >? like
 >? >? >>>
 >? >? > to test the proportional odds
 >? assumption.
 >? >? >>>? For this,
 >? I ran the binary
 >? >? >>>? >
 >? logistic
 >? >? >>>? regressions
 >? with varying
 >? >? cutpoints on the
 >? dependent
 >? >? >>>
 >? >? variable, as
 >? >
 >? >>>? > described
 >? >? in the
 >? following
 >? >? >>>? commands.
 >? >? When running the test of Hosmer and
 >? >? >>>? > Lemeshow
 >? (hoslem.test) for
 >? >? residuals gives
 >? >? >>>? error.
 >? >? >>>? >
 >? >? >>>? > Thanks,
 >? >? >>>? > Luciane
 >? >? >>>? >
 >? >? >>>? >
 >? >? >>>
 >? >
 >? ______________________________________________
 >? >? >>>? > R-help at r-project.org
 >? >? >>>? mailing list -- To
 >? UNSUBSCRIBE
 >? >? and more, see
 >? >? >>>? > https://stat.ethz.ch/mailman/listinfo/r-help
 >? >? >>>? > PLEASE do read
 the
 >? posting
 >? >? guide
 >? >
 >? >>>? > http://www.R-project.org/posting-guide.html
 >? >? >>>? > and provide
 >? commented,
 >? >? minimal,
 >? >? >>>? self-contained,
 >? >? reproducible code.
 >? >? >>>
 >? >
 >

 ________________________________
 Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
 d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
 Jestli?e jste obdr?el(a) tento e-mail omylem, informujte
 laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu
 i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
 Nejste-li zam??len?m adres?tem tohoto emailu, nejste
 opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat,
 kop?rovat ?i zve?ej?ovat.
 Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu
 zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

 V p??pad?, ?e je tento e-mail sou??st? obchodn?ho
 jedn?n?:
 - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv
 jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu
 i bez uveden? d?vodu.
 - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku
 bezodkladn? p?ijmout; Odes?latel tohoto e-mailu
 (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce
 s dodatkem ?i odchylkou.
 - trv? odes?latel na tom, ?e p??slu?n? smlouva je
 uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech
 jej?ch n?le?itostech.
 - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n
 uzav?rat za spole?nost ??dn? smlouvy s v?jimkou
 p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn?
 pov??en a takov? pov??en? nebo pln? moc byly
 adres?tovi tohoto emailu p??padn? osob?, kterou
 adres?t zastupuje, p?edlo?eny nebo jejich existence je
 adres?tovi ?i osob? j?m zastoupen? zn?m?.

 This e-mail and any documents attached to it may be
 confidential and are intended only for its intended
 recipients.
 If you received this e-mail by mistake, please immediately
 inform its sender. Delete the contents of this e-mail with
 all attachments and its copies from your system.
 If you are not the intended recipient of this e-mail, you
 are not authorized to use, disseminate, copy or disclose
 this e-mail in any manner.
 The sender of this e-mail shall not be liable for any
 possible damage caused by modifications of the e-mail or by
 delay with transfer of the email.

 In case that this e-mail forms part of business dealings:
 - the sender reserves the right to end negotiations about
 entering into a contract in any time, for any reason, and
 without stating any reasoning.
 - if the e-mail contains an offer, the recipient is entitled
 to immediately accept such offer; The sender of this e-mail
 (offer) excludes any acceptance of the offer on the part of
 the recipient containing any amendment or variation.
 - the sender insists on that the respective contract is
 concluded only upon an express mutual agreement on all its
 aspects.
 - the sender of this e-mail informs that he/she is not
 authorized to enter into any contracts on behalf of the
 company except for cases in which he/she is expressly
 authorized to do so in writing, and such authorization or
 power of attorney is submitted to the recipient or the
 person represented by the recipient, or the existence of
 such authorization is known to the recipient of the person
 represented by the recipient.


From milan.cisty at stuba.sk  Tue May  5 14:25:14 2015
From: milan.cisty at stuba.sk (Milan Cisty)
Date: Tue, 5 May 2015 14:25:14 +0200
Subject: [R] computing AIC when distribution is fitted by lmom or lmomco
Message-ID: <006501d0872e$8a33a470$9e9aed50$@stuba.sk>

Dear list members,
Is it possible to compute in R AIC, when model was fitted by methods of
L-moments (packages lmom or lmomco)?
Or what could be used to compare different candidate distribution models
fitting to data?
Sorry I have no reproducible example, because I do not know how this (AIC)
could be evaluated in this case or even if it has sense, but I appreciate
any suggestion.
Thanks,
Milan


From vito.muggeo at unipa.it  Tue May  5 15:13:42 2015
From: vito.muggeo at unipa.it (Vito M. R. Muggeo)
Date: Tue, 05 May 2015 15:13:42 +0200
Subject: [R] computing AIC when distribution is fitted by lmom or lmomco
In-Reply-To: <006501d0872e$8a33a470$9e9aed50$@stuba.sk>
References: <006501d0872e$8a33a470$9e9aed50$@stuba.sk>
Message-ID: <5548C206.1060700@unipa.it>

dear Milan,
I think you should consult a (local) statistician for your analyses.
R (and packages) are "only" software, and you need theoretical background.
best,
vito



Il 05/05/2015 14.25, Milan Cisty ha scritto:
> Dear list members,
> Is it possible to compute in R AIC, when model was fitted by methods of
> L-moments (packages lmom or lmomco)?
> Or what could be used to compare different candidate distribution models
> fitting to data?
> Sorry I have no reproducible example, because I do not know how this (AIC)
> could be evaluated in this case or even if it has sense, but I appreciate
> any suggestion.
> Thanks,
> Milan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
==============================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 23895240
fax: 091 485726
http://dssm.unipa.it/vmuggeo

28th IWSM
International Workshop on Statistical Modelling
July 8-12, 2013, Palermo
http://iwsm2013.unipa.it


From shouro at gmail.com  Tue May  5 17:00:18 2015
From: shouro at gmail.com (Shouro Dasgupta)
Date: Tue, 5 May 2015 17:00:18 +0200
Subject: [R] Plot by FIPS Code using Shapefiles
Message-ID: <CAMx+UYfi70FAbf6AXEDJXJKH7BNTW=Og7qJ9JCTLqn_wYuocSw@mail.gmail.com>

I am trying to plot data by FIPS code using county shapes files.

library(data.table)
> library(rgdal)
> library(colourschemes)
> library(RColorBrewer)
> library(maptools)
> library(maps)
> library(ggmap)


I have data by FIPS code which looks like this:
>
>
> dput(head(max_change))
> structure(list(FIPS = c("01001", "01003", "01005", "01007", "01009",
> "01011"), pred_hist = c(5.68493780563595e-06, 5.87686839563543e-06,
> 5.68493780563595e-06, 5.84476370329784e-06, 5.89156133294344e-06,
> 5.68493780563595e-06), pred_sim = c(5.60128903156804e-06,
> 5.82369276823497e-06,
> 5.60128903156804e-06, 5.75205304048323e-06, 5.80322399836766e-06,
> 5.60128903156804e-06), change = c(-1.47141054005866, -0.904829303986895,
> -1.47141054005866, -1.58621746782168, -1.49938750670105, -1.47141054005866
> )), .Names = c("FIPS", "pred_hist", "pred_sim", "change"), class =
> c("data.table",
> "data.frame"), row.names = c(NA, -6L), .internal.selfref = <pointer:
> 0x0000000000110788>)


 I add leading zeroes by:

max_change <- as.data.table(max_change)
max_change$FIPS <- sprintf("%05d",as.numeric(max_change$FIPS))

I downloaded shapefiles from here:
ftp://ftp2.census.gov/geo/tiger/TIGER2014/COUNTY/.

I obtain the FIPS codes from the shapefiles and order them using:

shapes_fips <- shapes$GEOID
> shapes_fips <- as.data.table(shapes_fips)
> setnames(shapes_fips, "shapes_fips", "FIPS")
> shapes_fips <- shapes_fips[with(shapes_fips, order(FIPS)), ]
> shapes_fips$FIPS <- as.character(shapes_fips$FIPS)


Then I merge the FIPS codes with my original dataset using:

>
> merged_data <- merge(shapes_fips,max_change,by="FIPS",all.X=T, all.y=T)
> merged_data <- as.data.table(merged_data)


Which looks like this:

structure(list(FIPS = c("01001", "01003", "01005", "01007", "01009",
> "01011"), pred_hist = c(5.68493780563595e-06, 5.87686839563543e-06,
> 5.68493780563595e-06, 5.84476370329784e-06, 5.89156133294344e-06,
> 5.68493780563595e-06), pred_sim = c(5.60128903156804e-06,
> 5.82369276823497e-06,
> 5.60128903156804e-06, 5.75205304048323e-06, 5.80322399836766e-06,
> 5.60128903156804e-06), change = c(-1.47141054005866, -0.904829303986895,
> -1.47141054005866, -1.58621746782168, -1.49938750670105, -1.47141054005866
> )), .Names = c("FIPS", "pred_hist", "pred_sim", "change"), sorted =
> "FIPS", class = c("data.table",
> "data.frame"), row.names = c(NA, -6L), .internal.selfref = <pointer:
> 0x0000000000110788>)


But when I try to merged data back to the SpatialPolygonsDataFrame called
shapes, I get the following error:

shapes$change <- merged_data$change

Error in `[[<-.data.frame`(`*tmp*`, name, value = c(-1.47141054005866,  :
>   replacement has 3109 rows, data has 3233


 Apologies for the messy example, what am I doing wrong? Any help will be
greatly appreciated. Thank you!

Sincerely,

Shouro

	[[alternative HTML version deleted]]


From kyle.hamilton at gmail.com  Fri May  1 03:22:33 2015
From: kyle.hamilton at gmail.com (Kyle Hamilton)
Date: Thu, 30 Apr 2015 18:22:33 -0700
Subject: [R] [R-pkgs] New release of MAVIS (Meta Analysis via Shiny) v1.1
	now on	CRAN
Message-ID: <CAN17LWM+mpR0GvVDzMGCR0iBVm-y-GY2XD8LVLuM6FMi7t50dw@mail.gmail.com>

Dear R users,

I'm pleased to announce that the first major update to the MAVIS
package (Meta Analysis via Shiny) has been released to CRAN.

MAVIS: Meta Analysis via Shiny v1.1 "Smiling Fox" has expanded greatly
over the last couple of months to include the following.

- User interface has been improved with the ?shinyBS? package and icons.
- Support for single case design, dichotomous data sets, and
additional effect size calculators.
- Expanded options for the detection of publication bias.
- Expanded support for both random effects and fixed effects models
with the 'metafor' package.
- Dichotomous data entry now available with input examples.
- Graphical outputs for funnel plots now allow for contour enhancement.
- References to articles covering methods described in MAVIS are now
easy to find.
- Knapp & Hartung Adjustment for random-effects models is now available.
- Regression test options for the detection of publication bias now
include both Weighted Regression with a Multiplicative Dispersion Term
and Meta-analytic Models.
- Users may now have the option for full model output.
- Single Case Design Data Entry now uses the ?shinyAce? package to
allow for easy data entry.

The package is developed using GitHub, and more information as well as
the current development version can be found at
https://github.com/kylehamilton/MAVIS


William Kyle Hamilton  -  Graduate Student
University of California, Merced  -  Psychological Sciences
psychology.ucmerced.edu - kylehamilton.com

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From ajdamico at gmail.com  Tue May  5 17:21:38 2015
From: ajdamico at gmail.com (Anthony Damico)
Date: Tue, 5 May 2015 11:21:38 -0400
Subject: [R] Plot by FIPS Code using Shapefiles
In-Reply-To: <CAMx+UYfi70FAbf6AXEDJXJKH7BNTW=Og7qJ9JCTLqn_wYuocSw@mail.gmail.com>
References: <CAMx+UYfi70FAbf6AXEDJXJKH7BNTW=Og7qJ9JCTLqn_wYuocSw@mail.gmail.com>
Message-ID: <CAOwvMDy2P56hR0hECWJTycpjZAVXJGF2mxMNkrvUV+mzKgRuUg@mail.gmail.com>

hi, after running each individual line of code above, check that the object
still has the expected number of records and unique county fips codes.  it
looks like length( shapes$GEOID ) == 3233 but nrow( merged_data ) == 3109.
the way for you to debug this is for you to go through line by line after
creating each new object  :)

i'm also not sure it's safe to work with gis objects as you're doing, there
are some well-documented examples of working with tiger files here
https://github.com/davidbrae/swmap



On Tue, May 5, 2015 at 11:00 AM, Shouro Dasgupta <shouro at gmail.com> wrote:

> I am trying to plot data by FIPS code using county shapes files.
>
> library(data.table)
> > library(rgdal)
> > library(colourschemes)
> > library(RColorBrewer)
> > library(maptools)
> > library(maps)
> > library(ggmap)
>
>
> I have data by FIPS code which looks like this:
> >
> >
> > dput(head(max_change))
> > structure(list(FIPS = c("01001", "01003", "01005", "01007", "01009",
> > "01011"), pred_hist = c(5.68493780563595e-06, 5.87686839563543e-06,
> > 5.68493780563595e-06, 5.84476370329784e-06, 5.89156133294344e-06,
> > 5.68493780563595e-06), pred_sim = c(5.60128903156804e-06,
> > 5.82369276823497e-06,
> > 5.60128903156804e-06, 5.75205304048323e-06, 5.80322399836766e-06,
> > 5.60128903156804e-06), change = c(-1.47141054005866, -0.904829303986895,
> > -1.47141054005866, -1.58621746782168, -1.49938750670105,
> -1.47141054005866
> > )), .Names = c("FIPS", "pred_hist", "pred_sim", "change"), class =
> > c("data.table",
> > "data.frame"), row.names = c(NA, -6L), .internal.selfref = <pointer:
> > 0x0000000000110788>)
>
>
>  I add leading zeroes by:
>
> max_change <- as.data.table(max_change)
> max_change$FIPS <- sprintf("%05d",as.numeric(max_change$FIPS))
>
> I downloaded shapefiles from here:
> ftp://ftp2.census.gov/geo/tiger/TIGER2014/COUNTY/.
>
> I obtain the FIPS codes from the shapefiles and order them using:
>
> shapes_fips <- shapes$GEOID
> > shapes_fips <- as.data.table(shapes_fips)
> > setnames(shapes_fips, "shapes_fips", "FIPS")
> > shapes_fips <- shapes_fips[with(shapes_fips, order(FIPS)), ]
> > shapes_fips$FIPS <- as.character(shapes_fips$FIPS)
>
>
> Then I merge the FIPS codes with my original dataset using:
>
> >
> > merged_data <- merge(shapes_fips,max_change,by="FIPS",all.X=T, all.y=T)
> > merged_data <- as.data.table(merged_data)
>
>
> Which looks like this:
>
> structure(list(FIPS = c("01001", "01003", "01005", "01007", "01009",
> > "01011"), pred_hist = c(5.68493780563595e-06, 5.87686839563543e-06,
> > 5.68493780563595e-06, 5.84476370329784e-06, 5.89156133294344e-06,
> > 5.68493780563595e-06), pred_sim = c(5.60128903156804e-06,
> > 5.82369276823497e-06,
> > 5.60128903156804e-06, 5.75205304048323e-06, 5.80322399836766e-06,
> > 5.60128903156804e-06), change = c(-1.47141054005866, -0.904829303986895,
> > -1.47141054005866, -1.58621746782168, -1.49938750670105,
> -1.47141054005866
> > )), .Names = c("FIPS", "pred_hist", "pred_sim", "change"), sorted =
> > "FIPS", class = c("data.table",
> > "data.frame"), row.names = c(NA, -6L), .internal.selfref = <pointer:
> > 0x0000000000110788>)
>
>
> But when I try to merged data back to the SpatialPolygonsDataFrame called
> shapes, I get the following error:
>
> shapes$change <- merged_data$change
>
> Error in `[[<-.data.frame`(`*tmp*`, name, value = c(-1.47141054005866,  :
> >   replacement has 3109 rows, data has 3233
>
>
>  Apologies for the messy example, what am I doing wrong? Any help will be
> greatly appreciated. Thank you!
>
> Sincerely,
>
> Shouro
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From shouro at gmail.com  Tue May  5 17:40:08 2015
From: shouro at gmail.com (Shouro Dasgupta)
Date: Tue, 5 May 2015 17:40:08 +0200
Subject: [R] Plot by FIPS Code using Shapefiles
In-Reply-To: <CAOwvMDy2P56hR0hECWJTycpjZAVXJGF2mxMNkrvUV+mzKgRuUg@mail.gmail.com>
References: <CAMx+UYfi70FAbf6AXEDJXJKH7BNTW=Og7qJ9JCTLqn_wYuocSw@mail.gmail.com>
	<CAOwvMDy2P56hR0hECWJTycpjZAVXJGF2mxMNkrvUV+mzKgRuUg@mail.gmail.com>
Message-ID: <CAMx+UYeUK1Spqb3V-GWRoeSpLBT6OZQTASOYGY3FAyNLD1UA3w@mail.gmail.com>

Hello,

Thank you for your reply. My original data has 3109 FIPS codes. Is there a
way to merge only this data into the shapefiles? I hope I am clear.

Thank you also for the link, I am trying to do something like this:
https://gist.github.com/reubano/1281134.

Thanks again!

Sincerely,

Shouro

On Tue, May 5, 2015 at 5:21 PM, Anthony Damico <ajdamico at gmail.com> wrote:

> hi, after running each individual line of code above, check that the
> object still has the expected number of records and unique county fips
> codes.  it looks like length( shapes$GEOID ) == 3233 but nrow( merged_data
> ) == 3109.  the way for you to debug this is for you to go through line by
> line after creating each new object  :)
>
> i'm also not sure it's safe to work with gis objects as you're doing,
> there are some well-documented examples of working with tiger files here
> https://github.com/davidbrae/swmap
>
>
>
> On Tue, May 5, 2015 at 11:00 AM, Shouro Dasgupta <shouro at gmail.com> wrote:
>
>> I am trying to plot data by FIPS code using county shapes files.
>>
>> library(data.table)
>> > library(rgdal)
>> > library(colourschemes)
>> > library(RColorBrewer)
>> > library(maptools)
>> > library(maps)
>> > library(ggmap)
>>
>>
>> I have data by FIPS code which looks like this:
>> >
>> >
>> > dput(head(max_change))
>> > structure(list(FIPS = c("01001", "01003", "01005", "01007", "01009",
>> > "01011"), pred_hist = c(5.68493780563595e-06, 5.87686839563543e-06,
>> > 5.68493780563595e-06, 5.84476370329784e-06, 5.89156133294344e-06,
>> > 5.68493780563595e-06), pred_sim = c(5.60128903156804e-06,
>> > 5.82369276823497e-06,
>> > 5.60128903156804e-06, 5.75205304048323e-06, 5.80322399836766e-06,
>> > 5.60128903156804e-06), change = c(-1.47141054005866, -0.904829303986895,
>> > -1.47141054005866, -1.58621746782168, -1.49938750670105,
>> -1.47141054005866
>> > )), .Names = c("FIPS", "pred_hist", "pred_sim", "change"), class =
>> > c("data.table",
>> > "data.frame"), row.names = c(NA, -6L), .internal.selfref = <pointer:
>> > 0x0000000000110788>)
>>
>>
>>  I add leading zeroes by:
>>
>> max_change <- as.data.table(max_change)
>> max_change$FIPS <- sprintf("%05d",as.numeric(max_change$FIPS))
>>
>> I downloaded shapefiles from here:
>> ftp://ftp2.census.gov/geo/tiger/TIGER2014/COUNTY/.
>>
>> I obtain the FIPS codes from the shapefiles and order them using:
>>
>> shapes_fips <- shapes$GEOID
>> > shapes_fips <- as.data.table(shapes_fips)
>> > setnames(shapes_fips, "shapes_fips", "FIPS")
>> > shapes_fips <- shapes_fips[with(shapes_fips, order(FIPS)), ]
>> > shapes_fips$FIPS <- as.character(shapes_fips$FIPS)
>>
>>
>> Then I merge the FIPS codes with my original dataset using:
>>
>> >
>> > merged_data <- merge(shapes_fips,max_change,by="FIPS",all.X=T, all.y=T)
>> > merged_data <- as.data.table(merged_data)
>>
>>
>> Which looks like this:
>>
>> structure(list(FIPS = c("01001", "01003", "01005", "01007", "01009",
>> > "01011"), pred_hist = c(5.68493780563595e-06, 5.87686839563543e-06,
>> > 5.68493780563595e-06, 5.84476370329784e-06, 5.89156133294344e-06,
>> > 5.68493780563595e-06), pred_sim = c(5.60128903156804e-06,
>> > 5.82369276823497e-06,
>> > 5.60128903156804e-06, 5.75205304048323e-06, 5.80322399836766e-06,
>> > 5.60128903156804e-06), change = c(-1.47141054005866, -0.904829303986895,
>> > -1.47141054005866, -1.58621746782168, -1.49938750670105,
>> -1.47141054005866
>> > )), .Names = c("FIPS", "pred_hist", "pred_sim", "change"), sorted =
>> > "FIPS", class = c("data.table",
>> > "data.frame"), row.names = c(NA, -6L), .internal.selfref = <pointer:
>> > 0x0000000000110788>)
>>
>>
>> But when I try to merged data back to the SpatialPolygonsDataFrame called
>> shapes, I get the following error:
>>
>> shapes$change <- merged_data$change
>>
>> Error in `[[<-.data.frame`(`*tmp*`, name, value = c(-1.47141054005866,  :
>> >   replacement has 3109 rows, data has 3233
>>
>>
>>  Apologies for the messy example, what am I doing wrong? Any help will be
>> greatly appreciated. Thank you!
>>
>> Sincerely,
>>
>> Shouro
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 

Shouro Dasgupta
PhD Candidate | Department of Economics
Ca' Foscari University of Venezia

------------------------------

Junior Researcher | Fondazione Eni Enrico Mattei (FEEM)
Isola di San Giorgio Maggiore, 8 | 30124 Venice, Italy
Tel: +39 041 2700 436

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue May  5 17:41:08 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 5 May 2015 08:41:08 -0700
Subject: [R] Transformation of the circular variable into linear variable
In-Reply-To: <CAFUdcV8Pddkn+ENu-MfrD+649JXHMLoFcugpBz8PTtan5nBrLw@mail.gmail.com>
References: <CAFUdcV_DUC3EMG44gcfJ_cdWpmFBw1B+tWjuDuFyHm6uKDZfEQ@mail.gmail.com>
	<CAFUdcV8Pddkn+ENu-MfrD+649JXHMLoFcugpBz8PTtan5nBrLw@mail.gmail.com>
Message-ID: <1A5E84CF-AB1A-4DD2-A303-5EFEBA55229F@comcast.net>


On May 5, 2015, at 3:59 AM, Nasr Al-Dhurafi wrote:

> Dear All
> 
> I am working with a circular data ( wind direction ) and i have problem
> in transforming  the circular variable into linear variable. I have found
> an equation that can be used to convert the circular variable into linear
> variable which is included in this paper *" ARMA based approaches for
> forecasting the tuple of wind speed and direction". *The equation is called
> as the inverse of a link function and i have attached  the summery of it.T
> herefore,Please, if you have an idea of how to conduct it in R programming
> or  if you have another method for transformation, let me know it. Your
> cooperation is highly appreciated.
> 
> My Best Regards &  All The Best

Here are a couple of plausible explanations for a lack of response to your first message posted 2 months ago:

Neither of your duplicate messages have any attachments. This could be caused by the fact (buried away in one or more of webpages or Posting Guides that define the Rhelp facility)  the information that the mail-server used by the Rhelp list strips any attachments unless they are one of the limited number accepted file formats. (It does not notify posters of htis fact when they submit unacceptable formats.)  The 4 formats I know to be accepted are: MIME-text, .pdf, .ps or .png. Even if you submit formats that you might think would be considered "text", they will not be accepted if they have non-".txt" extensions such as ".csv". As far as I can tell ... only .txt extensions are passed through.

I find an article by that name in Applied Energy Volume 88, Issue 4, April 2011, Pages 1405?1414. The publisher offers a copy at the price of 42 USD. (Expecting us to buy that article seems unreasonable.)

Most of us are not meteorological researchers. In general list members are more likely to respond to requests that include a) sample data, b) code that reflects your efforts, and c) a specification of correct output. It may be helpful to list details of your position.

-- 
David.

> 
> Nasr
> 
> On Mon, Mar 30, 2015 at 8:22 PM, Nasr Al-Dhurafi <ldhrf at siswa.ukm.edu.my>
> wrote:
> 
>> I am working with a circular data ( wind direction ) and i have problem
>> in transforming  the circular variable into linear variable. I have found
>> an equation that can be used to convert the circular variable into linear
>> variable which is included in this paper *" ARMA based approaches for
>> forecasting the tuple of wind speed and direction". *The equation is
>> called as the inverse of a link function and i have attached  the summery
>> of it.Therefore,Please, if you have an idea of how to conduct it in R
>> programming or  if you have another method for transformation, let me
>> know it. Your cooperation is highly appreciated.
>> 
>> My Best Regards &  All The Best
>> Nasr
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dawoodmalik at hotmail.com  Tue May  5 17:05:44 2015
From: dawoodmalik at hotmail.com (dawood ahmad)
Date: Tue, 5 May 2015 15:05:44 +0000
Subject: [R] Need Help!
In-Reply-To: <33D76D77E9AC4B438DA38B348ED6890D1441C54A@EMAIL.ktkdom.pte.hu>
References: <COL127-W3452DEC02C549960FC8DBBBD20@phx.gbl>,
	<33D76D77E9AC4B438DA38B348ED6890D1441C54A@EMAIL.ktkdom.pte.hu>
Message-ID: <COL127-W109CE4EF442CFBB242FAF1BBD10@phx.gbl>

Dear Daniel,
 
Thank you very much for such a kind reply. Actually, I couldn't understand well the criteria of help list, I am 
sorry for that. I tried you method, unfortunately I couldn't get the output. It may be due to my lack of expertise in programming. At this point I need your help which will mean a lot to me. Moreover, if I use single value it gives the output. I am sending you two image files of the outputs. I will be really grateful to you if you guide me.
 
Thanking in advance,
 
With Best Regards,
 
Dawood
 
 
 
> From: kehld at ktk.pte.hu
> To: dawoodmalik at hotmail.com; r-help at r-project.org
> Subject: RE: [R] Need Help!
> Date: Mon, 4 May 2015 20:17:48 +0000
> 
> Dear Dawood,
> 
> it is not a really good idea to open a new email with the same problem you already posted earlier.
> I see you accepted some suggestions (HTML, seq) but not others (pi is a defined constant in R, do not change it, type pi ENTER to see this.). I would like to add one more, c is a function, do not use it as a variable name (I used cc instead of c).
> I tried to figure out what you want here. The following code might do what you want. It gives you a feeling about how you would create a basic loop. There are nicer ways to do that in R. Note the [i]-s in the for loop!
> 
> 
> cc <- 0.5
> xc <- 2
> s <- 6
> Hc2 <- 30
> H <- 1
> ep<-seq(0.01, 0.49, by=0.001)
> res <- numeric(length=length(ep))
> 
> for (i in 1:length(ep)){
>   f<-function(k) 1.211*10^(-6)*Hc2/H*(trigamma( ((ep[i] + H/Hc2 + (2*xc/s)^2*(1 - cos(k*s))/2)/2*Hc2/H)) -  trigamma(((cc + H/Hc2 + (2*xc/s)^2*(1 - cos(k*s))/2)/2*Hc2/H)))
>   res[i] <- integrate(f,-pi/s,pi/s)$value
> }
> 
> Best,
> daniel
> ________________________________________
> Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: dawood ahmad [dawoodmalik at hotmail.com]
> K?ldve: 2015. m?jus 4. 10:29
> To: r-help at R-project.org
> T?rgy: [R] Need Help!
> 
> Dear Sir/Madam,
> 
> I hope you will be fine. I am new to R language. Recently, I am trying to fit my data with one model.
> I am sending you the code and image file on which you can see the error I am receiving instead of executing.
> If I give a single value to parameter "ep", it executes well, but if I make a loop/seq for getting a range of data it shows
> error.I need you help in solving this problem.
> 
> Thanking in advance,
> 
> With Best Regards,
> Dawood
 		 	   		  
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Page1.png
Type: image/png
Size: 493197 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150505/4f6c1882/attachment-0002.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Page2.png
Type: image/png
Size: 451492 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150505/4f6c1882/attachment-0003.png>

From ajdamico at gmail.com  Tue May  5 18:00:56 2015
From: ajdamico at gmail.com (Anthony Damico)
Date: Tue, 5 May 2015 12:00:56 -0400
Subject: [R] Plot by FIPS Code using Shapefiles
In-Reply-To: <CAMx+UYeUK1Spqb3V-GWRoeSpLBT6OZQTASOYGY3FAyNLD1UA3w@mail.gmail.com>
References: <CAMx+UYfi70FAbf6AXEDJXJKH7BNTW=Og7qJ9JCTLqn_wYuocSw@mail.gmail.com>
	<CAOwvMDy2P56hR0hECWJTycpjZAVXJGF2mxMNkrvUV+mzKgRuUg@mail.gmail.com>
	<CAMx+UYeUK1Spqb3V-GWRoeSpLBT6OZQTASOYGY3FAyNLD1UA3w@mail.gmail.com>
Message-ID: <CAOwvMDxjriVOWaqrqWDStwXbjOd4S0gv8fUkTrMhcCwxzJu=ZQ@mail.gmail.com>

so check the unique number of fips codes in the objects before and after

> merged_data <- merge(shapes_fips,max_change,by="FIPS",all.X=T, all.y=T)

also note that all.X should be all.x and you might want to use FALSE for
one or both of those



On Tue, May 5, 2015 at 11:40 AM, Shouro Dasgupta <shouro at gmail.com> wrote:

> Hello,
>
> Thank you for your reply. My original data has 3109 FIPS codes. Is there a
> way to merge only this data into the shapefiles? I hope I am clear.
>
> Thank you also for the link, I am trying to do something like this:
> https://gist.github.com/reubano/1281134.
>
> Thanks again!
>
> Sincerely,
>
> Shouro
>
> On Tue, May 5, 2015 at 5:21 PM, Anthony Damico <ajdamico at gmail.com> wrote:
>
>> hi, after running each individual line of code above, check that the
>> object still has the expected number of records and unique county fips
>> codes.  it looks like length( shapes$GEOID ) == 3233 but nrow( merged_data
>> ) == 3109.  the way for you to debug this is for you to go through line by
>> line after creating each new object  :)
>>
>> i'm also not sure it's safe to work with gis objects as you're doing,
>> there are some well-documented examples of working with tiger files here
>> https://github.com/davidbrae/swmap
>>
>>
>>
>> On Tue, May 5, 2015 at 11:00 AM, Shouro Dasgupta <shouro at gmail.com>
>> wrote:
>>
>>> I am trying to plot data by FIPS code using county shapes files.
>>>
>>> library(data.table)
>>> > library(rgdal)
>>> > library(colourschemes)
>>> > library(RColorBrewer)
>>> > library(maptools)
>>> > library(maps)
>>> > library(ggmap)
>>>
>>>
>>> I have data by FIPS code which looks like this:
>>> >
>>> >
>>> > dput(head(max_change))
>>> > structure(list(FIPS = c("01001", "01003", "01005", "01007", "01009",
>>> > "01011"), pred_hist = c(5.68493780563595e-06, 5.87686839563543e-06,
>>> > 5.68493780563595e-06, 5.84476370329784e-06, 5.89156133294344e-06,
>>> > 5.68493780563595e-06), pred_sim = c(5.60128903156804e-06,
>>> > 5.82369276823497e-06,
>>> > 5.60128903156804e-06, 5.75205304048323e-06, 5.80322399836766e-06,
>>> > 5.60128903156804e-06), change = c(-1.47141054005866,
>>> -0.904829303986895,
>>> > -1.47141054005866, -1.58621746782168, -1.49938750670105,
>>> -1.47141054005866
>>> > )), .Names = c("FIPS", "pred_hist", "pred_sim", "change"), class =
>>> > c("data.table",
>>> > "data.frame"), row.names = c(NA, -6L), .internal.selfref = <pointer:
>>> > 0x0000000000110788>)
>>>
>>>
>>>  I add leading zeroes by:
>>>
>>> max_change <- as.data.table(max_change)
>>> max_change$FIPS <- sprintf("%05d",as.numeric(max_change$FIPS))
>>>
>>> I downloaded shapefiles from here:
>>> ftp://ftp2.census.gov/geo/tiger/TIGER2014/COUNTY/.
>>>
>>> I obtain the FIPS codes from the shapefiles and order them using:
>>>
>>> shapes_fips <- shapes$GEOID
>>> > shapes_fips <- as.data.table(shapes_fips)
>>> > setnames(shapes_fips, "shapes_fips", "FIPS")
>>> > shapes_fips <- shapes_fips[with(shapes_fips, order(FIPS)), ]
>>> > shapes_fips$FIPS <- as.character(shapes_fips$FIPS)
>>>
>>>
>>> Then I merge the FIPS codes with my original dataset using:
>>>
>>> >
>>> > merged_data <- merge(shapes_fips,max_change,by="FIPS",all.X=T, all.y=T)
>>> > merged_data <- as.data.table(merged_data)
>>>
>>>
>>> Which looks like this:
>>>
>>> structure(list(FIPS = c("01001", "01003", "01005", "01007", "01009",
>>> > "01011"), pred_hist = c(5.68493780563595e-06, 5.87686839563543e-06,
>>> > 5.68493780563595e-06, 5.84476370329784e-06, 5.89156133294344e-06,
>>> > 5.68493780563595e-06), pred_sim = c(5.60128903156804e-06,
>>> > 5.82369276823497e-06,
>>> > 5.60128903156804e-06, 5.75205304048323e-06, 5.80322399836766e-06,
>>> > 5.60128903156804e-06), change = c(-1.47141054005866,
>>> -0.904829303986895,
>>> > -1.47141054005866, -1.58621746782168, -1.49938750670105,
>>> -1.47141054005866
>>> > )), .Names = c("FIPS", "pred_hist", "pred_sim", "change"), sorted =
>>> > "FIPS", class = c("data.table",
>>> > "data.frame"), row.names = c(NA, -6L), .internal.selfref = <pointer:
>>> > 0x0000000000110788>)
>>>
>>>
>>> But when I try to merged data back to the SpatialPolygonsDataFrame called
>>> shapes, I get the following error:
>>>
>>> shapes$change <- merged_data$change
>>>
>>> Error in `[[<-.data.frame`(`*tmp*`, name, value = c(-1.47141054005866,  :
>>> >   replacement has 3109 rows, data has 3233
>>>
>>>
>>>  Apologies for the messy example, what am I doing wrong? Any help will be
>>> greatly appreciated. Thank you!
>>>
>>> Sincerely,
>>>
>>> Shouro
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>
> --
>
> Shouro Dasgupta
> PhD Candidate | Department of Economics
> Ca' Foscari University of Venezia
>
> ------------------------------
>
> Junior Researcher | Fondazione Eni Enrico Mattei (FEEM)
> Isola di San Giorgio Maggiore, 8 | 30124 Venice, Italy
> Tel: +39 041 2700 436
>
>

	[[alternative HTML version deleted]]


From NordlDJ at dshs.wa.gov  Tue May  5 18:13:32 2015
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 5 May 2015 16:13:32 +0000
Subject: [R] update.packages() ask for mirror several times
Message-ID: <F7E6D18CC2877149AB5296CE54EA27662ED2B705@WAXMXOLYMB025.WAX.wa.lcl>

I recently installed an R-3.2.0 binary for Win7 64-bit from a CRAN table.  Now when using the menu to update packages, it asks me to select a mirror several times before proceeding to successfully download and install the updated packages.  It is only a minor annoyance, was wondering if anyone else had experienced this, and if so, is there a solution

Here is  my session info

> sessionInfo()
R version 3.2.0 (2015-04-16)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_3.2.0
>

And here is the console dialogue after clicking on update packages

> update.packages(ask='graphics',checkBuilt=TRUE)
--- Please select a CRAN mirror for use in this session ---
--- Please select a CRAN mirror for use in this session ---
also installing the dependency ?stringi?

--- Please select a CRAN mirror for use in this session ---
--- Please select a CRAN mirror for use in this session ---
trying URL 'http://cran.fhcrc.org/bin/windows/contrib/3.2/stringi_0.4-1.zip'
Content type 'application/zip' length 13432789 bytes (12.8 MB)
downloaded 12.8 MB

followed by the rest of the packages which need updating.


Dan

Daniel J. Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services



From hannah.hlx at gmail.com  Tue May  5 18:53:36 2015
From: hannah.hlx at gmail.com (li li)
Date: Tue, 5 May 2015 12:53:36 -0400
Subject: [R] predict function in regression analysis
Message-ID: <CAHLnndYwbbjoLk4LBiXWrbF3Ft8DGOq2N=uMNbL8oGFApFXsOg@mail.gmail.com>

Hi all,
  I have the following data in which there is one factor lot with six
levels and one continuous convariate time.
I want to fit an Ancova model with common slope and different intercept. So
the six lots will have seperate paralell
regression lines.I wanted to find the upper 95% confidence limit for the
mean of the each of
the regression lines. It doesnot seem straightforward to achieve this using
predict function. Can anyone give some suggestions?

  Here is my data. I only show the first 3 lots. Also I show the model I
used in the end. Thanks very much!
     Hanna

      y lot time
 [1,] 4.5   1    0
 [2,] 4.5   1    3
 [3,] 4.7   1    6
 [4,] 6.7   1    9
 [5,] 6.0   1   12
 [6,] 4.4   1   15
 [7,] 4.1   1   18
 [8,] 5.3   1   24
 [9,] 4.0   2    0
[10,] 4.2   2    3
[11,] 4.1   2    6
[12,] 6.4   2    9
[13,] 5.5   2   12
[14,] 3.5   2   15
[15,] 4.6   2   18
[16,] 4.1   2   24
[17,] 4.6   3    0
[18,] 5.0   3    3
[19,] 6.2   3    6
[20,] 5.9   3    9
[21,] 3.9   3   12
[22,] 5.3   3   15
[23,] 6.9   3   18
[24,] 5.7   3   24


> mod <- lm(y ~ lot+time)
> summary(mod)
Call:
lm(formula = y ~ lot + time)
Residuals:
    Min      1Q  Median      3Q     Max
-1.5666 -0.3344 -0.1343  0.4479  1.8985
Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  4.74373    0.36617  12.955 2.84e-14 ***
lot2        -0.47500    0.41129  -1.155   0.2567
lot3         0.41250    0.41129   1.003   0.3234
lot4         0.96109    0.47943   2.005   0.0535 .
lot5         0.98109    0.47943   2.046   0.0490 *
lot6        -0.09891    0.47943  -0.206   0.8379
time         0.02586    0.02046   1.264   0.2153
---

	[[alternative HTML version deleted]]


From lbagua at gmail.com  Tue May  5 19:49:42 2015
From: lbagua at gmail.com (Luis Borda de Agua)
Date: Tue, 5 May 2015 18:49:42 +0100
Subject: [R] order by which the eigenvalues are presented
Message-ID: <4B6C414F-5A12-4BE0-B826-D5A6A4D2EA58@gmail.com>

I?m using R 3.1.3 in OS X 10.10.3 (Yosemite)

I use the function ?eigen? to calculate the eigenvalues of matrix where each element is sampled from a given distribution (normal, beta, etc.). 
According to the information provided: 
"values	
a vector containing the p eigenvalues of x, sorted in decreasing order, according to Mod(values)"


However, for my purposes it would be important to ?fix? the order by which the eigenvalues are presented. To be more specific, I would like to know each time I calculated the eigenvalues from a set of sampled matrix elements which is the eigenvalue that provides the largest (or the smallest) real part.

Is there an easy way to enforce this? (I could not find an option in "eigen".)

Is there another function in R that calculates the eigenvalues and shows their values without sorting them?

Thank you in advance,

Lu?s Borda de ?gua


	[[alternative HTML version deleted]]


From peljasz at yahoo.co.uk  Tue May  5 20:54:19 2015
From: peljasz at yahoo.co.uk (lejeczek)
Date: Tue, 05 May 2015 19:54:19 +0100
Subject: [R] does segfault mean (always) a bug?
Message-ID: <554911DB.8050909@yahoo.co.uk>

hi eveybody

I'm trying something simple (Biocunductor packages), so 
simple I believe it's example from docs but I get segfault.
I don't suppose incorrect scripting can cause segfault, right?

regards


From boris.steipe at utoronto.ca  Tue May  5 21:10:09 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 5 May 2015 15:10:09 -0400
Subject: [R] Need Help!
In-Reply-To: <COL127-W109CE4EF442CFBB242FAF1BBD10@phx.gbl>
References: <COL127-W3452DEC02C549960FC8DBBBD20@phx.gbl>,
	<33D76D77E9AC4B438DA38B348ED6890D1441C54A@EMAIL.ktkdom.pte.hu>
	<COL127-W109CE4EF442CFBB242FAF1BBD10@phx.gbl>
Message-ID: <D638AAFD-0D92-40EC-B9AB-08B99E60A090@utoronto.ca>

For crying out loud Dawood - can you please stop posting screenshots? Do you not know how to copy your output and paste it into the body of a (not HTML formatted!) email? Let us know if you need help with that.

B.

 
On May 5, 2015, at 11:05 AM, dawood ahmad <dawoodmalik at hotmail.com> wrote:

> Dear Daniel,
> 
> Thank you very much for such a kind reply. Actually, I couldn't understand well the criteria of help list, I am 
> sorry for that. I tried you method, unfortunately I couldn't get the output. It may be due to my lack of expertise in programming. At this point I need your help which will mean a lot to me. Moreover, if I use single value it gives the output. I am sending you two image files of the outputs. I will be really grateful to you if you guide me.
> 
> Thanking in advance,
> 
> With Best Regards,
> 
> Dawood
> 
> 
> 
>> From: kehld at ktk.pte.hu
>> To: dawoodmalik at hotmail.com; r-help at r-project.org
>> Subject: RE: [R] Need Help!
>> Date: Mon, 4 May 2015 20:17:48 +0000
>> 
>> Dear Dawood,
>> 
>> it is not a really good idea to open a new email with the same problem you already posted earlier.
>> I see you accepted some suggestions (HTML, seq) but not others (pi is a defined constant in R, do not change it, type pi ENTER to see this.). I would like to add one more, c is a function, do not use it as a variable name (I used cc instead of c).
>> I tried to figure out what you want here. The following code might do what you want. It gives you a feeling about how you would create a basic loop. There are nicer ways to do that in R. Note the [i]-s in the for loop!
>> 
>> 
>> cc <- 0.5
>> xc <- 2
>> s <- 6
>> Hc2 <- 30
>> H <- 1
>> ep<-seq(0.01, 0.49, by=0.001)
>> res <- numeric(length=length(ep))
>> 
>> for (i in 1:length(ep)){
>>  f<-function(k) 1.211*10^(-6)*Hc2/H*(trigamma( ((ep[i] + H/Hc2 + (2*xc/s)^2*(1 - cos(k*s))/2)/2*Hc2/H)) -  trigamma(((cc + H/Hc2 + (2*xc/s)^2*(1 - cos(k*s))/2)/2*Hc2/H)))
>>  res[i] <- integrate(f,-pi/s,pi/s)$value
>> }
>> 
>> Best,
>> daniel
>> ________________________________________
>> Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: dawood ahmad [dawoodmalik at hotmail.com]
>> K?ldve: 2015. m?jus 4. 10:29
>> To: r-help at R-project.org
>> T?rgy: [R] Need Help!
>> 
>> Dear Sir/Madam,
>> 
>> I hope you will be fine. I am new to R language. Recently, I am trying to fit my data with one model.
>> I am sending you the code and image file on which you can see the error I am receiving instead of executing.
>> If I give a single value to parameter "ep", it executes well, but if I make a loop/seq for getting a range of data it shows
>> error.I need you help in solving this problem.
>> 
>> Thanking in advance,
>> 
>> With Best Regards,
>> Dawood
> 		 	   		  <Page1.png><Page2.png>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Tue May  5 21:31:13 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 05 May 2015 15:31:13 -0400
Subject: [R] update.packages() ask for mirror several times
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA27662ED2B705@WAXMXOLYMB025.WAX.wa.lcl>
References: <F7E6D18CC2877149AB5296CE54EA27662ED2B705@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <55491A81.20700@gmail.com>

On 05/05/2015 12:13 PM, Nordlund, Dan (DSHS/RDA) wrote:
> I recently installed an R-3.2.0 binary for Win7 64-bit from a CRAN table.  Now when using the menu to update packages, it asks me to select a mirror several times before proceeding to successfully download and install the updated packages.  It is only a minor annoyance, was wondering if anyone else had experienced this, and if so, is there a solution

You could try R-patched.  This was fixed this week.

Duncan Murdoch

> Here is  my session info
> 
>> sessionInfo()
> R version 3.2.0 (2015-04-16)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> locale:
> [1] LC_COLLATE=English_United States.1252 
> [2] LC_CTYPE=English_United States.1252   
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                          
> [5] LC_TIME=English_United States.1252    
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
> 
> loaded via a namespace (and not attached):
> [1] tools_3.2.0
>>
> 
> And here is the console dialogue after clicking on update packages
> 
>> update.packages(ask='graphics',checkBuilt=TRUE)
> --- Please select a CRAN mirror for use in this session ---
> --- Please select a CRAN mirror for use in this session ---
> also installing the dependency ?stringi?
> 
> --- Please select a CRAN mirror for use in this session ---
> --- Please select a CRAN mirror for use in this session ---
> trying URL 'http://cran.fhcrc.org/bin/windows/contrib/3.2/stringi_0.4-1.zip'
> Content type 'application/zip' length 13432789 bytes (12.8 MB)
> downloaded 12.8 MB
> 
> followed by the rest of the packages which need updating.
> 
> 
> Dan
> 
> Daniel J. Nordlund, PhD
> Research and Data Analysis Division
> Services & Enterprise Support Administration
> Washington State Department of Social and Health Services
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From boris.steipe at utoronto.ca  Tue May  5 21:32:49 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 5 May 2015 15:32:49 -0400
Subject: [R] does segfault mean (always) a bug?
In-Reply-To: <554911DB.8050909@yahoo.co.uk>
References: <554911DB.8050909@yahoo.co.uk>
Message-ID: <7710E05B-B486-4B83-89ED-D6724F708941@utoronto.ca>

Wrong.


B.



On May 5, 2015, at 2:54 PM, lejeczek <peljasz at yahoo.co.uk> wrote:

> hi eveybody
> 
> I'm trying something simple (Biocunductor packages), so simple I believe it's example from docs but I get segfault.
> I don't suppose incorrect scripting can cause segfault, right?
> 
> regards
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From NordlDJ at dshs.wa.gov  Tue May  5 21:34:39 2015
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 5 May 2015 19:34:39 +0000
Subject: [R] update.packages() ask for mirror several times
In-Reply-To: <55491A81.20700@gmail.com>
References: <F7E6D18CC2877149AB5296CE54EA27662ED2B705@WAXMXOLYMB025.WAX.wa.lcl>
	<55491A81.20700@gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27662ED2B790@WAXMXOLYMB025.WAX.wa.lcl>

Thanks,

I will do that.


Dan

Daniel J. Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services

> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Tuesday, May 05, 2015 12:31 PM
> To: Nordlund, Dan (DSHS/RDA); r-help at r-project.org
> Subject: Re: [R] update.packages() ask for mirror several times
> 
> On 05/05/2015 12:13 PM, Nordlund, Dan (DSHS/RDA) wrote:
> > I recently installed an R-3.2.0 binary for Win7 64-bit from a CRAN
> table.  Now when using the menu to update packages, it asks me to
> select a mirror several times before proceeding to successfully
> download and install the updated packages.  It is only a minor
> annoyance, was wondering if anyone else had experienced this, and if
> so, is there a solution
> 
> You could try R-patched.  This was fixed this week.
> 
> Duncan Murdoch
> 
> > Here is  my session info
> >
> >> sessionInfo()
> > R version 3.2.0 (2015-04-16)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows 7 x64 (build 7601) Service Pack 1
> >
> > locale:
> > [1] LC_COLLATE=English_United States.1252
> > [2] LC_CTYPE=English_United States.1252
> > [3] LC_MONETARY=English_United States.1252
> > [4] LC_NUMERIC=C
> > [5] LC_TIME=English_United States.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_3.2.0
> >>
> >
> > And here is the console dialogue after clicking on update packages
> >
> >> update.packages(ask='graphics',checkBuilt=TRUE)
> > --- Please select a CRAN mirror for use in this session ---
> > --- Please select a CRAN mirror for use in this session ---
> > also installing the dependency ?stringi?
> >
> > --- Please select a CRAN mirror for use in this session ---
> > --- Please select a CRAN mirror for use in this session ---
> > trying URL
> 'http://cran.fhcrc.org/bin/windows/contrib/3.2/stringi_0.4-1.zip'
> > Content type 'application/zip' length 13432789 bytes (12.8 MB)
> > downloaded 12.8 MB
> >
> > followed by the rest of the packages which need updating.
> >
> >
> > Dan
> >
> > Daniel J. Nordlund, PhD
> > Research and Data Analysis Division
> > Services & Enterprise Support Administration
> > Washington State Department of Social and Health Services
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From murdoch.duncan at gmail.com  Tue May  5 21:36:59 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 05 May 2015 15:36:59 -0400
Subject: [R] does segfault mean (always) a bug?
In-Reply-To: <554911DB.8050909@yahoo.co.uk>
References: <554911DB.8050909@yahoo.co.uk>
Message-ID: <55491BDB.5070100@gmail.com>

On 05/05/2015 2:54 PM, lejeczek wrote:
> hi eveybody
> 
> I'm trying something simple (Biocunductor packages), so 
> simple I believe it's example from docs but I get segfault.
> I don't suppose incorrect scripting can cause segfault, right?

In R, a segfault always indicates a bug.  What's not so clear is whether
it is a bug in R, a bug in a contributed package, or a bug in some
underlying system library.

If you can only trigger the bug when using a Bioconductor package, then
the first guess is that it is that package, and the maintainer of that
package is in the best position to track it down further.  If you can
simplify the code to trigger it without using any contributed packages,
then it could well be a bug in R, and we'd like to see code to reproduce it.

Duncan Murdoch


From gunter.berton at gene.com  Tue May  5 22:41:50 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 5 May 2015 13:41:50 -0700
Subject: [R] predict function in regression analysis
In-Reply-To: <CAHLnndYwbbjoLk4LBiXWrbF3Ft8DGOq2N=uMNbL8oGFApFXsOg@mail.gmail.com>
References: <CAHLnndYwbbjoLk4LBiXWrbF3Ft8DGOq2N=uMNbL8oGFApFXsOg@mail.gmail.com>
Message-ID: <CACk-te1girrOfGMvCXM=qv5Bbun9qUfUnbVXCK7HeDy-YEqRfA@mail.gmail.com>

 I think you want CI's for intercepts, not "means" (what is a "mean"
for a line??). If so, the ?confint function will give this to you for
the lot effect estimates when applied to a model fitted without an
intercept:

myfit <-lm(y~ lot-1+time)
confint(myfit)


Further discussion should be directed to a statistical site or a local
statistician, as these are not R issues.

Cheers,
Bert


Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, May 5, 2015 at 9:53 AM, li li <hannah.hlx at gmail.com> wrote:
> Hi all,
>   I have the following data in which there is one factor lot with six
> levels and one continuous convariate time.
> I want to fit an Ancova model with common slope and different intercept. So
> the six lots will have seperate paralell
> regression lines.I wanted to find the upper 95% confidence limit for the
> mean of the each of
> the regression lines. It doesnot seem straightforward to achieve this using
> predict function. Can anyone give some suggestions?
>
>   Here is my data. I only show the first 3 lots. Also I show the model I
> used in the end. Thanks very much!
>      Hanna
>
>       y lot time
>  [1,] 4.5   1    0
>  [2,] 4.5   1    3
>  [3,] 4.7   1    6
>  [4,] 6.7   1    9
>  [5,] 6.0   1   12
>  [6,] 4.4   1   15
>  [7,] 4.1   1   18
>  [8,] 5.3   1   24
>  [9,] 4.0   2    0
> [10,] 4.2   2    3
> [11,] 4.1   2    6
> [12,] 6.4   2    9
> [13,] 5.5   2   12
> [14,] 3.5   2   15
> [15,] 4.6   2   18
> [16,] 4.1   2   24
> [17,] 4.6   3    0
> [18,] 5.0   3    3
> [19,] 6.2   3    6
> [20,] 5.9   3    9
> [21,] 3.9   3   12
> [22,] 5.3   3   15
> [23,] 6.9   3   18
> [24,] 5.7   3   24
>
>
>> mod <- lm(y ~ lot+time)
>> summary(mod)
> Call:
> lm(formula = y ~ lot + time)
> Residuals:
>     Min      1Q  Median      3Q     Max
> -1.5666 -0.3344 -0.1343  0.4479  1.8985
> Coefficients:
>             Estimate Std. Error t value Pr(>|t|)
> (Intercept)  4.74373    0.36617  12.955 2.84e-14 ***
> lot2        -0.47500    0.41129  -1.155   0.2567
> lot3         0.41250    0.41129   1.003   0.3234
> lot4         0.96109    0.47943   2.005   0.0535 .
> lot5         0.98109    0.47943   2.046   0.0490 *
> lot6        -0.09891    0.47943  -0.206   0.8379
> time         0.02586    0.02046   1.264   0.2153
> ---
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From varinsacha at yahoo.fr  Wed May  6 00:01:27 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Tue, 5 May 2015 22:01:27 +0000 (UTC)
Subject: [R] Drawing the regression line and the 95% confidence intervals
Message-ID: <231821959.1282783.1430863287892.JavaMail.yahoo@mail.yahoo.com>

Hi, Dear R-helpers,

Here below you will find a reproducible fictitious example working except the "abline" function.

First thing : I try to draw the regression line (multiple linear regression). I try the "abline" function but it does not work. I don't get any error message but the straight line does not appear on the scatterplot.

Second thing : I try to draw the 95% confidence intervals on the regression line. How could I do ?

Using abline(0,1), I can of course add a line 45 degrees angle passing through the origin (intercept=0 and slope=1), but it is not what I am looking for.

GDP.per.head=c(600,560,340,560,580,300,570,900,680,290,590,340)
Quality.score=c(4.5,6.5,6,4.5,7,3,9,10,12.5,6.5,7,9)
Competitivness.score=c(1000,1200,1400,700,680,1010,340,560,690,500,690,460)
LinearModel.1=lm(GDP.per.head ~ Quality.score + Competitivness.score)
plot(GDP.per.head, fitted(LinearModel.1))
abline(GDP.per.head, fitted(LinearModel.1))

Thanks for your help. Looking forward to reading you.

Sacha


From wdunlap at tibco.com  Wed May  6 00:22:45 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 5 May 2015 15:22:45 -0700
Subject: [R] order by which the eigenvalues are presented
In-Reply-To: <4B6C414F-5A12-4BE0-B826-D5A6A4D2EA58@gmail.com>
References: <4B6C414F-5A12-4BE0-B826-D5A6A4D2EA58@gmail.com>
Message-ID: <CAF8bMcY0mYboMS=ncsN97Y3_scnp3keKJFLzQkVHpFRKi=njfw@mail.gmail.com>

You can sort the eigenvalues in the order you want with
    o <- order(Re(e$values), decreasing = TRUE)
or
    o <- order(abs(Re(e$values)), decreasing = TRUE)
followed by
    e$values[o]
where 'e' is the object that eigen returns.

The main argument to order() is what you want to sort by and the subscript
expression e$values[o] does the rearranging.  You can subscript e$vectors
to rearrange them as well.




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, May 5, 2015 at 10:49 AM, Luis Borda de Agua <lbagua at gmail.com>
wrote:

> I?m using R 3.1.3 in OS X 10.10.3 (Yosemite)
>
> I use the function ?eigen? to calculate the eigenvalues of matrix where
> each element is sampled from a given distribution (normal, beta, etc.).
> According to the information provided:
> "values
> a vector containing the p eigenvalues of x, sorted in decreasing order,
> according to Mod(values)"
>
>
> However, for my purposes it would be important to ?fix? the order by which
> the eigenvalues are presented. To be more specific, I would like to know
> each time I calculated the eigenvalues from a set of sampled matrix
> elements which is the eigenvalue that provides the largest (or the
> smallest) real part.
>
> Is there an easy way to enforce this? (I could not find an option in
> "eigen".)
>
> Is there another function in R that calculates the eigenvalues and shows
> their values without sorting them?
>
> Thank you in advance,
>
> Lu?s Borda de ?gua
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed May  6 01:02:49 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 6 May 2015 09:02:49 +1000
Subject: [R] Drawing the regression line and the 95% confidence intervals
In-Reply-To: <231821959.1282783.1430863287892.JavaMail.yahoo@mail.yahoo.com>
References: <231821959.1282783.1430863287892.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fXPXRrOcVZK1=S1Ur9c8YAOogQJtCiWCboXNzCg6zodPw@mail.gmail.com>

Hi Sacha,
The line you have requested is off the plot. The following will
produce what I think you are asking, but I cannot speak for whether it
means anything sensible.

plot(GDP.per.head, fitted(LinearModel.1),ylim=c(200,800))
devlm1<-lm(fitted(LinearModel.1)~GDP.per.head)
abline(devlm1)
conflm1<-confint(devlm1)
abline(coef=conflm1[,1],lty=2)
abline(coef=conflm1[,2],lty=2)

Jim


On Wed, May 6, 2015 at 8:01 AM, varin sacha <varinsacha at yahoo.fr> wrote:
> Hi, Dear R-helpers,
>
> Here below you will find a reproducible fictitious example working except the "abline" function.
>
> First thing : I try to draw the regression line (multiple linear regression). I try the "abline" function but it does not work. I don't get any error message but the straight line does not appear on the scatterplot.
>
> Second thing : I try to draw the 95% confidence intervals on the regression line. How could I do ?
>
> Using abline(0,1), I can of course add a line 45 degrees angle passing through the origin (intercept=0 and slope=1), but it is not what I am looking for.
>
> GDP.per.head=c(600,560,340,560,580,300,570,900,680,290,590,340)
> Quality.score=c(4.5,6.5,6,4.5,7,3,9,10,12.5,6.5,7,9)
> Competitivness.score=c(1000,1200,1400,700,680,1010,340,560,690,500,690,460)
> LinearModel.1=lm(GDP.per.head ~ Quality.score + Competitivness.score)
> plot(GDP.per.head, fitted(LinearModel.1))
> abline(GDP.per.head, fitted(LinearModel.1))
>
> Thanks for your help. Looking forward to reading you.
>
> Sacha
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From peljasz at yahoo.co.uk  Wed May  6 09:20:46 2015
From: peljasz at yahoo.co.uk (lejeczek)
Date: Wed, 06 May 2015 08:20:46 +0100
Subject: [R] does segfault mean (always) a bug?
In-Reply-To: <55491BDB.5070100@gmail.com>
References: <554911DB.8050909@yahoo.co.uk> <55491BDB.5070100@gmail.com>
Message-ID: <5549C0CE.9040303@yahoo.co.uk>

On 05/05/15 20:36, Duncan Murdoch wrote:
> On 05/05/2015 2:54 PM, lejeczek wrote:
>> hi eveybody
>>
>> I'm trying something simple (Biocunductor packages), so
>> simple I believe it's example from docs but I get segfault.
>> I don't suppose incorrect scripting can cause segfault, right?
> In R, a segfault always indicates a bug.  What's not so clear is whether
> it is a bug in R, a bug in a contributed package, or a bug in some
> underlying system library.
>
> If you can only trigger the bug when using a Bioconductor package, then
> the first guess is that it is that package, and the maintainer of that
> package is in the best position to track it down further.  If you can
> simplify the code to trigger it without using any contributed packages,
> then it could well be a bug in R, and we'd like to see code to reproduce it.
>
> Duncan Murdoch
>
hi Duncan
I remember that this was a principle of most of programming 
languages, only a bug in the code and/or compiler could 
cause segfault.
In my case it is a contributed package, specifically GOSim 
package, I'm not R programmer and I realise my scripting is 
far from good and possibly with errors.
I could send that snippet of the code here if people think 
it can be looked into and segfault could be replicated?
I also emailed the author.

many thanks
P.


From corey.sparks at UTSA.EDU  Tue May  5 18:07:35 2015
From: corey.sparks at UTSA.EDU (Corey Sparks)
Date: Tue, 5 May 2015 09:07:35 -0700 (PDT)
Subject: [R] Plot by FIPS Code using Shapefiles
In-Reply-To: <CAMx+UYeUK1Spqb3V-GWRoeSpLBT6OZQTASOYGY3FAyNLD1UA3w@mail.gmail.com>
References: <CAMx+UYfi70FAbf6AXEDJXJKH7BNTW=Og7qJ9JCTLqn_wYuocSw@mail.gmail.com>
	<CAOwvMDy2P56hR0hECWJTycpjZAVXJGF2mxMNkrvUV+mzKgRuUg@mail.gmail.com>
	<CAMx+UYeUK1Spqb3V-GWRoeSpLBT6OZQTASOYGY3FAyNLD1UA3w@mail.gmail.com>
Message-ID: <1430842055487-4706840.post@n4.nabble.com>

Joining data the way you're doing it is dangerous, Roger Bivand and others
describes a standard way to do this process here:
http://r-sig-geo.2731867.n2.nabble.com/Merging-shapefiles-and-csv-td7586839.html

And I do an example using US Census data here, using merge():
http://spatialdemography.org/wp-content/uploads/2013/04/9.-Sparks.pdf
<http://spatialdemography.org/wp-content/uploads/2013/04/9.-Sparks.pdf>  

look at page 134 of that pdf.

Hope this helps



-----
Corey Sparks, PhD
Assistant Professor
Department of Demography
University of Texas at San Antonio
501 West C?sar E. Ch?vez  Blvd 
Monterey Building 2.270C
San Antonio, TX 78207
210-458-3166
corey.sparks 'at' utsa.edu
coreysparks.weebly.com
--
View this message in context: http://r.789695.n4.nabble.com/Plot-by-FIPS-Code-using-Shapefiles-tp4706830p4706840.html
Sent from the R help mailing list archive at Nabble.com.


From maechler at lynne.stat.math.ethz.ch  Wed May  6 10:32:20 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Wed, 6 May 2015 10:32:20 +0200
Subject: [R] does segfault mean (always) a bug?
In-Reply-To: <55491BDB.5070100@gmail.com>
References: <554911DB.8050909@yahoo.co.uk>
	<55491BDB.5070100@gmail.com>
Message-ID: <21833.53652.708440.779967@stat.math.ethz.ch>

>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>     on Tue, 5 May 2015 15:36:59 -0400 writes:

    > On 05/05/2015 2:54 PM, lejeczek wrote:
    >> hi eveybody
    >> 
    >> I'm trying something simple (Biocunductor packages), so 
    >> simple I believe it's example from docs but I get segfault.
    >> I don't suppose incorrect scripting can cause segfault, right?

    > In R, a segfault always indicates a bug.  What's not so clear is whether
    > it is a bug in R, a bug in a contributed package, or a bug in some
    > underlying system library.

    > If you can only trigger the bug when using a Bioconductor package, then
    > the first guess is that it is that package, and the maintainer of that
    > package is in the best position to track it down further.  If you can
    > simplify the code to trigger it without using any contributed packages,
    > then it could well be a bug in R, and we'd like to see code to reproduce it.
    > Duncan Murdoch

The bug Duncan mentions can also be in the user's R code, outside any package:

If a user does what (s)he should never do, namely directly call
.C(), .Fortran(), .Call() or similar (.Internal(), .External(),..)
it is typically easy to trigger segfaults, and then the bug is
in the user's R code.

Variations of the above involve using the inline package, or
other interfaces to C/C++/... code, libraries, etc: The bug may be in
your code rather than the underlying code which is allowed to
make strong assumptions about how it is called.

Martin Maechler


From maechler at lynne.stat.math.ethz.ch  Wed May  6 10:50:10 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Wed, 6 May 2015 10:50:10 +0200
Subject: [R] Transformation of the circular variable into linear variable
In-Reply-To: <1A5E84CF-AB1A-4DD2-A303-5EFEBA55229F@comcast.net>
References: <CAFUdcV_DUC3EMG44gcfJ_cdWpmFBw1B+tWjuDuFyHm6uKDZfEQ@mail.gmail.com>
	<CAFUdcV8Pddkn+ENu-MfrD+649JXHMLoFcugpBz8PTtan5nBrLw@mail.gmail.com>
	<1A5E84CF-AB1A-4DD2-A303-5EFEBA55229F@comcast.net>
Message-ID: <21833.54722.356032.739998@stat.math.ethz.ch>

>>>>> David Winsemius <dwinsemius at comcast.net>
>>>>>     on Tue, 5 May 2015 08:41:08 -0700 writes:

    > On May 5, 2015, at 3:59 AM, Nasr Al-Dhurafi wrote:

    >> Dear All
    >> 
    >> I am working with a circular data ( wind direction ) and i have problem
    >> in transforming  the circular variable into linear variable. I have found
    >> an equation that can be used to convert the circular variable into linear
    >> variable which is included in this paper *" ARMA based approaches for
    >> forecasting the tuple of wind speed and direction". *The equation is called
    >> as the inverse of a link function and i have attached  the summery of it.T
    >> herefore,Please, if you have an idea of how to conduct it in R programming
    >> or  if you have another method for transformation, let me know it. Your
    >> cooperation is highly appreciated.
    >> 
    >> My Best Regards &  All The Best

    > Here are a couple of plausible explanations for a lack of response to your first message posted 2 months ago:

    > Neither of your duplicate messages have any attachments. This could be caused by the fact (buried away in one or more of webpages or Posting Guides that define the Rhelp facility)  the information that the mail-server used by the Rhelp list strips any attachments unless they are one of the limited number accepted file formats. (It does not notify posters of htis fact when they submit unacceptable formats.)  The 4 formats I know to be accepted are: MIME-text, .pdf, .ps or .png. Even if you submit formats that you might think would be considered "text", they will not be accepted if they have non-".txt" extensions such as ".csv". As far as I can tell ... only .txt extensions are passed through.

Thanks a lot, David, for helping Nasr (and many others)!

The above explantion is not quite accurate though and I want to make sure
correct info gets archived here:  The file extension does not
play any role for the mailing list server software, which is "mailman".
Mailman -- rightly -- only looks at the declared MIME type of the attachment.
("MIME": see https://en.wikipedia.org/wiki/MIME).

Now with 99.x% of people using e-mail software which does not
reveal any of these subtle details to you, and many such e-mail
interfaces behaving like Windows programs, that e-mail software may choose
the MIME type (it uses for the attachments it puts into the
e-mail it sends in your behalf) depending on the file extension.
So, from the naive user's point of view with his only e-mail
program he may know, it then seems as if the file extension
determines the acceptance of the attachment by the mailman rules
we have had imposed (for spam and virus protection).

Martin Maechler
ETH Zurich

    >> I find an article by that name in Applied Energy Volume 88, Issue 4, April 2011, Pages 1405?1414. The publisher offers a copy at the price of 42 USD. (Expecting us to buy that article seems unreasonable.)

    > Most of us are not meteorological researchers. In general list members are more likely to respond to requests that include a) sample data, b) code that reflects your efforts, and c) a specification of correct output. It may be helpful to list details of your position.

    > -- 
    > David.

    >> 
    >> Nasr
    >> 
    >> On Mon, Mar 30, 2015 at 8:22 PM, Nasr Al-Dhurafi <ldhrf at siswa.ukm.edu.my>
    >> wrote:
    >> 
    >>> I am working with a circular data ( wind direction ) and i have problem
    >>> in transforming  the circular variable into linear variable. I have found
    >>> an equation that can be used to convert the circular variable into linear
    >>> variable which is included in this paper *" ARMA based approaches for
    >>> forecasting the tuple of wind speed and direction". *The equation is
    >>> called as the inverse of a link function and i have attached  the summery
    >>> of it.Therefore,Please, if you have an idea of how to conduct it in R
    >>> programming or  if you have another method for transformation, let me
    >>> know it. Your cooperation is highly appreciated.
    >>> 
    >>> My Best Regards &  All The Best
    >>> Nasr
    >>> 
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.

    > David Winsemius
    > Alameda, CA, USA

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From peljasz at yahoo.co.uk  Wed May  6 10:56:35 2015
From: peljasz at yahoo.co.uk (lejeczek)
Date: Wed, 06 May 2015 09:56:35 +0100
Subject: [R] does segfault mean (always) a bug?
In-Reply-To: <21833.53652.708440.779967@stat.math.ethz.ch>
References: <554911DB.8050909@yahoo.co.uk>	<55491BDB.5070100@gmail.com>
	<21833.53652.708440.779967@stat.math.ethz.ch>
Message-ID: <5549D743.1070505@yahoo.co.uk>

On 06/05/15 09:32, Martin Maechler wrote:
>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>>      on Tue, 5 May 2015 15:36:59 -0400 writes:
>      > On 05/05/2015 2:54 PM, lejeczek wrote:
>      >> hi eveybody
>      >>
>      >> I'm trying something simple (Biocunductor packages), so
>      >> simple I believe it's example from docs but I get segfault.
>      >> I don't suppose incorrect scripting can cause segfault, right?
>
>      > In R, a segfault always indicates a bug.  What's not so clear is whether
>      > it is a bug in R, a bug in a contributed package, or a bug in some
>      > underlying system library.
>
>      > If you can only trigger the bug when using a Bioconductor package, then
>      > the first guess is that it is that package, and the maintainer of that
>      > package is in the best position to track it down further.  If you can
>      > simplify the code to trigger it without using any contributed packages,
>      > then it could well be a bug in R, and we'd like to see code to reproduce it.
>      > Duncan Murdoch
>
> The bug Duncan mentions can also be in the user's R code, outside any package:
>
> If a user does what (s)he should never do, namely directly call
> .C(), .Fortran(), .Call() or similar (.Internal(), .External(),..)
> it is typically easy to trigger segfaults, and then the bug is
> in the user's R code.
>
> Variations of the above involve using the inline package, or
> other interfaces to C/C++/... code, libraries, etc: The bug may be in
> your code rather than the underlying code which is allowed to
> make strong assumptions about how it is called.
>
> Martin Maechler
>
>
not in my case, no of the above call mentioned calls is 
being used, it really is very simple code (possibly with errors)
I know this is not a place to debug anything but if one 
wants to have a look here it is:

library(org.Hs.eg.db)
#library(org.Mm.eg.db)
#library(org.Sc.sgd.db)
library(GOSim)
#library(GO.db)
#setEvidenceLevel(evidences="all", organism="yeast")
#setEvidenceLevel(evidences="all")
setEvidenceLevel(evidences = "all", 
organism=org.Hs.egORGANISM, gomap=org.Hs.egGO)
calc.diffusion.kernel(method="diffKernelLapl", m=5, 
normalization.method="sqrt", DIR="/__.aLocalStorages/1")
#calc.diffusion.kernel(method="diffKernelLLE", m=5, 
normalization.method="sqrt", DIR="/__.aLocalStorages/1")

and:
...
calculating diffusion kernel 'diffKernelLLE' for ontology BP 
using evidence codes 'all' (Homo sapiens) ...
Note: method with signature ?Matrix#matrix? chosen for 
function ?-?,
  target signature ?ddiMatrix#matrix?.
  "ddiMatrix#ANY" would also be valid

  *** caught segfault ***
address 0x7ffedd69e348, cause 'memory not mapped'

Traceback:
  1: E %*% K %*% E
  2: E %*% K %*% E
  3: calc.diffusion.kernel(method = "diffKernelLLE", m = 5, 
normalization.method = "sqrt",     DIR = "/tmp")
aborting ...

regards


From maechler at lynne.stat.math.ethz.ch  Wed May  6 10:57:16 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Wed, 6 May 2015 10:57:16 +0200
Subject: [R] does segfault mean (always) a bug?
In-Reply-To: <5549C0CE.9040303@yahoo.co.uk>
References: <554911DB.8050909@yahoo.co.uk> <55491BDB.5070100@gmail.com>
	<5549C0CE.9040303@yahoo.co.uk>
Message-ID: <21833.55148.133483.482768@stat.math.ethz.ch>

>>>>> lejeczek  <peljasz at yahoo.co.uk>
>>>>>     on Wed, 6 May 2015 08:20:46 +0100 writes:

    > On 05/05/15 20:36, Duncan Murdoch wrote:
    >> On 05/05/2015 2:54 PM, lejeczek wrote:
    >>> hi eveybody
    >>> 
    >>> I'm trying something simple (Biocunductor packages), so
    >>> simple I believe it's example from docs but I get segfault.
    >>> I don't suppose incorrect scripting can cause segfault, right?
    >> In R, a segfault always indicates a bug.  What's not so clear is whether
    >> it is a bug in R, a bug in a contributed package, or a bug in some
    >> underlying system library.
    >> 
    >> If you can only trigger the bug when using a Bioconductor package, then
    >> the first guess is that it is that package, and the maintainer of that
    >> package is in the best position to track it down further.  If you can
    >> simplify the code to trigger it without using any contributed packages,
    >> then it could well be a bug in R, and we'd like to see code to reproduce it.
    >> 
    >> Duncan Murdoch
    >> 
    > hi Duncan
    > I remember that this was a principle of most of programming 
    > languages, only a bug in the code and/or compiler could 
    > cause segfault.
    > In my case it is a contributed package, specifically GOSim 
    > package, I'm not R programmer and I realise my scripting is 
    > far from good and possibly with errors.
    > I could send that snippet of the code here if people think 
    > it can be looked into and segfault could be replicated?
    > I also emailed the author.

    > many thanks
    > P.

Dear P.,

in the case of segfault from using a contributed package,
you should typically really only email the package maintainer
(which may different than the package authors), and not R-help.
Only if the maintainer does not respond at all (and only if the
package is open source, typically CRAN) should you ask for help here
or another public forum.

(I would also think it to be polite to the maintainer who has
 volunteered her/his code to be used by you if you give him an
 opportunity to see, comment and fix the problem)

Martin Maechler
ETH Zurich


From glennmschultz at me.com  Wed May  6 02:16:53 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Wed, 06 May 2015 00:16:53 +0000 (GMT)
Subject: [R] Package Build Recommendations
Message-ID: <bef9b9ac-03da-41e2-8e07-164802021684@me.com>

Hi All,

I have my R package built and it passes the CRAN tests. ?Now, I have a question. ?The file structure is not standard. ?There are addition data files as follows outlined below. ?Each, if you will, represents separation of concerns with respect to structured securities like MBS and REMICs (CMOs). ?They referenced via connection in the software via a connection string ~/users/BondLab. ?I am looking for recommendations to create the directory and copy the appropriate folders with their data to a user directory on install. ?Any help will be appreciated.

Glenn ?

BondData
Groups
PrepaymentModel
REMIC
RDME
RAID
RatesData
Scenario
Schedules
Tranches
Waterfall


From kehld at ktk.pte.hu  Tue May  5 21:29:14 2015
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?Kehl_D=E1niel?=)
Date: Tue, 5 May 2015 19:29:14 +0000
Subject: [R] Need Help!
In-Reply-To: <COL127-W109CE4EF442CFBB242FAF1BBD10@phx.gbl>
References: <COL127-W3452DEC02C549960FC8DBBBD20@phx.gbl>,
	<33D76D77E9AC4B438DA38B348ED6890D1441C54A@EMAIL.ktkdom.pte.hu>,
	<COL127-W109CE4EF442CFBB242FAF1BBD10@phx.gbl>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D1441D781@EMAIL.ktkdom.pte.hu>

Hi,

type
res #<ENTER> (now it contains your results as a vector)

or

head(res) #so you only see the first couple of values

or

plot(res) #to see a basic plot (you could set axis labels etc, but I suggets you to go ahead and read a tutorial on R!

Best, have a great time with R,
kd
________________________________
Felad?: dawood ahmad [dawoodmalik at hotmail.com]
K?ldve: 2015. m?jus 5. 17:05
To: Kehl D?niel; r-help at R-project.org
T?rgy: RE: [R] Need Help!

Dear Daniel,

Thank you very much for such a kind reply. Actually, I couldn't understand well the criteria of help list, I am
sorry for that. I tried you method, unfortunately I couldn't get the output. It may be due to my lack of expertise in programming. At this point I need your help which will mean a lot to me. Moreover, if I use single value it gives the output. I am sending you two image files of the outputs. I will be really grateful to you if you guide me.

Thanking in advance,

With Best Regards,

Dawood



> From: kehld at ktk.pte.hu
> To: dawoodmalik at hotmail.com; r-help at r-project.org
> Subject: RE: [R] Need Help!
> Date: Mon, 4 May 2015 20:17:48 +0000
>
> Dear Dawood,
>
> it is not a really good idea to open a new email with the same problem you already posted earlier.
> I see you accepted some suggestions (HTML, seq) but not others (pi is a defined constant in R, do not change it, type pi ENTER to see this.). I would like to add one more, c is a function, do not use it as a variable name (I used cc instead of c).
> I tried to figure out what you want here. The following code might do what you want. It gives you a feeling about how you would create a basic loop. There are nicer ways to do that in R. Note the [i]-s in the for loop!
>
>
> cc <- 0.5
> xc <- 2
> s <- 6
> Hc2 <- 30
> H <- 1
> ep<-seq(0.01, 0.49, by=0.001)
> res <- numeric(length=length(ep))
>
> for (i in 1:length(ep)){
> f<-function(k) 1.211*10^(-6)*Hc2/H*(trigamma( ((ep[i] + H/Hc2 + (2*xc/s)^2*(1 - cos(k*s))/2)/2*Hc2/H)) - trigamma(((cc + H/Hc2 + (2*xc/s)^2*(1 - cos(k*s))/2)/2*Hc2/H)))
> res[i] <- integrate(f,-pi/s,pi/s)$value
> }
>
> Best,
> daniel
> ________________________________________
> Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: dawood ahmad [dawoodmalik at hotmail.com]
> K?ldve: 2015. m?jus 4. 10:29
> To: r-help at R-project.org
> T?rgy: [R] Need Help!
>
> Dear Sir/Madam,
>
> I hope you will be fine. I am new to R language. Recently, I am trying to fit my data with one model.
> I am sending you the code and image file on which you can see the error I am receiving instead of executing.
> If I give a single value to parameter "ep", it executes well, but if I make a loop/seq for getting a range of data it shows
> error.I need you help in solving this problem.
>
> Thanking in advance,
>
> With Best Regards,
> Dawood

	[[alternative HTML version deleted]]


From robby0524 at fpc.com.tw  Wed May  6 01:58:53 2015
From: robby0524 at fpc.com.tw (robby0524)
Date: Tue, 5 May 2015 16:58:53 -0700 (PDT)
Subject: [R] R write to JSON format error
Message-ID: <1430870333769-4706860.post@n4.nabble.com>

Dear all 
    There are a stardand  JSON format file from R code. It have a error on
this file. 
    How to modify this source code for a stardand  JSON format file? 
    Test1: 
    Soure code for R studio: 
            Issue_Name<-c("Tag over 30% in minutes") 
            URL_Link<-c("http://61.221.174.234/trendalarm_all.txt") 
            ULink=list(Issue=Issue_Name,URL=URL_Link) 
            #ULink to JSON format 
            sink("ULink.txt") 
            cat(toJSON(ULink)) 
            sink() 
    Result:<This is not a stardand  JSON format file>
            > cat(toJSON(ULink)) 
           {"Issue":"Tag over 30% in
minutes","URL":"http://61.221.174.234/trendalarm_all.txt"} 
            > sink() 
    Test2: 
    Soure code for R studio: 
            Issue_Name<-c("Tag over 30% in minutes") 
            URL_Link<-c("http://61.221.174.234/trendalarm_all.txt") 
            ULink=list(Issue=Issue_Name,URL=URL_Link) 
            
    Run R source code, then run the below command on console windows  
            sink("ULink.txt") 
            cat(toJSON(ULink)) 
            sink() 
    Result:<This is a stardand JSON format file>
           {"Issue":"Tag over 30% in
minutes","URL":"http://61.221.174.234/trendalarm_all.txt"} 
Thanks



--
View this message in context: http://r.789695.n4.nabble.com/R-write-to-JSON-format-error-tp4706860.html
Sent from the R help mailing list archive at Nabble.com.


From lubin.lemarchand at bnpparibas-pf.com  Wed May  6 09:58:35 2015
From: lubin.lemarchand at bnpparibas-pf.com (lubin.lemarchand at bnpparibas-pf.com)
Date: Wed, 6 May 2015 07:58:35 +0000
Subject: [R] Rgraphviz and NA indices error
Message-ID: <4662BD744B63354F81577B73918E04CDB6A935@SPMW0301.mail.shared.fortis>

Hello,


I ran into the same error. From what I understood, if the code :



        plot(dtm, terms=findFreqTerms(dtm, lowfreq=100) [1:30],
        corThreshold=0.75)

gives you this message it's because there aren't 30 terms which happens at least a hundred times in your corpus.
Therefore you might want to lower the frequency threshold.

Ylove.
-------------- next part --------------
 

Ce message et toutes les pi?ces jointes (ci-apr?s le "message") sont 
?tablis ? l'intention exclusive de ses destinataires et sont 
confidentiels. Si vous recevez ce message par erreur, merci de le 
d?truire et d'en avertir imm?diatement l'exp?diteur. Toute utilisation 
de ce message non conforme a sa destination, toute diffusion ou toute 
publication, totale ou partielle, est interdite, sauf autorisation 
expresse. L'internet ne permettant pas d'assurer l'int?grit? de ce 
message, BNP PARIBAS PERSONAL FINANCE (et ses filiales) d?cline(nt) 
toute responsabilit? au titre de ce message, dans l'hypoth?se ou il 
aurait ?t? modifi?. N'imprimez ce message que si n?cessaire, pensez ? 
l'environnement. 

--------------------------------------------- 

This message and any attachments (the "message") is intended solely for 
the addressees and is confidential. If you receive this message in 
error, please delete it and immediately notify the sender. Any use not 
in accord with its purpose, any dissemination or disclosure, either 
whole or partial, is prohibited except formal approval. The internet can 
not guarantee the integrity of this message. BNP PARIBAS PERSONAL 
FINANCE (and its subsidiaries) shall (will) not therefore be liable for 
the message if modified. Do not print this message unless it is 
necessary, consider the environment. 

--------------------------------------------- 


From stephane.adamowicz at avignon.inra.fr  Wed May  6 11:22:19 2015
From: stephane.adamowicz at avignon.inra.fr (=?iso-8859-1?Q?St=E9phane_Adamowicz?=)
Date: Wed, 6 May 2015 11:22:19 +0200
Subject: [R] predict function in regression analysis
In-Reply-To: <CACk-te1girrOfGMvCXM=qv5Bbun9qUfUnbVXCK7HeDy-YEqRfA@mail.gmail.com>
References: <CAHLnndYwbbjoLk4LBiXWrbF3Ft8DGOq2N=uMNbL8oGFApFXsOg@mail.gmail.com>
	<CACk-te1girrOfGMvCXM=qv5Bbun9qUfUnbVXCK7HeDy-YEqRfA@mail.gmail.com>
Message-ID: <D56AAB01-2DC1-4D0A-9849-108A12547AFC@avignon.inra.fr>

Maybe this is what you wanted :

Data <- structure(list(y = c(4.5, 4.5, 4.7, 6.7, 6, 4.4, 4.1, 5.3, 4, 4.2, 4.1, 6.4, 5.5, 3.5, 4.6, 4.1, 4.6, 5, 6.2, 5.9, 3.9, 5.3, 6.9, 5.7), lot = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), duration = c(0L, 3L, 6L, 9L, 12L, 15L, 18L, 24L, 0L, 3L, 6L, 9L, 12L, 15L, 18L, 24L, 0L, 3L, 6L, 9L, 12L, 15L, 18L, 24L)), Names = c("y", "lot","duration"), class = "data.frame", row.names = c(NA, -24L))
Data$lot <- as.factor(Data$lot)
summary(Data)

(ANCOVA <- lm(y ~ lot + duration, data=Data))
summary(ANCOVA)
anova(ANCOVA)


#	diagram
color <- c("black", "red", "blue")
plot(y~duration, data=Data, pch=as.character(lot))

P <- predict(ANCOVA, int="c")
for(lev in levels(Data$lot)) {
index <- which(Data$lot==lev)
matlines(x=Data$duration[index], y=P[index,], col=color[as.integer(lev)])
}

Le 5 mai 2015 ? 22:41, Bert Gunter <gunter.berton at gene.com> a ?crit :

> I think you want CI's for intercepts, not "means" (what is a "mean"
> for a line??). If so, the ?confint function will give this to you for
> the lot effect estimates when applied to a model fitted without an
> intercept:
> 
> myfit <-lm(y~ lot-1+time)
> confint(myfit)
> 
> 
> Further discussion should be directed to a statistical site or a local
> statistician, as these are not R issues.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
> 
> 
> 
> 
> On Tue, May 5, 2015 at 9:53 AM, li li <hannah.hlx at gmail.com> wrote:
>> Hi all,
>>  I have the following data in which there is one factor lot with six
>> levels and one continuous convariate time.
>> I want to fit an Ancova model with common slope and different intercept. So
>> the six lots will have seperate paralell
>> regression lines.I wanted to find the upper 95% confidence limit for the
>> mean of the each of
>> the regression lines. It doesnot seem straightforward to achieve this using
>> predict function. Can anyone give some suggestions?
>> 
>>  Here is my data. I only show the first 3 lots. Also I show the model I
>> used in the end. Thanks very much!
>>     Hanna
>> 
>>      y lot time
>> [1,] 4.5   1    0
>> [2,] 4.5   1    3
>> [3,] 4.7   1    6
>> [4,] 6.7   1    9
>> [5,] 6.0   1   12
>> [6,] 4.4   1   15
>> [7,] 4.1   1   18
>> [8,] 5.3   1   24
>> [9,] 4.0   2    0
>> [10,] 4.2   2    3
>> [11,] 4.1   2    6
>> [12,] 6.4   2    9
>> [13,] 5.5   2   12
>> [14,] 3.5   2   15
>> [15,] 4.6   2   18
>> [16,] 4.1   2   24
>> [17,] 4.6   3    0
>> [18,] 5.0   3    3
>> [19,] 6.2   3    6
>> [20,] 5.9   3    9
>> [21,] 3.9   3   12
>> [22,] 5.3   3   15
>> [23,] 6.9   3   18
>> [24,] 5.7   3   24
>> 
>> 
>>> mod <- lm(y ~ lot+time)
>>> summary(mod)
>> Call:
>> lm(formula = y ~ lot + time)
>> Residuals:
>>    Min      1Q  Median      3Q     Max
>> -1.5666 -0.3344 -0.1343  0.4479  1.8985
>> Coefficients:
>>            Estimate Std. Error t value Pr(>|t|)
>> (Intercept)  4.74373    0.36617  12.955 2.84e-14 ***
>> lot2        -0.47500    0.41129  -1.155   0.2567
>> lot3         0.41250    0.41129   1.003   0.3234
>> lot4         0.96109    0.47943   2.005   0.0535 .
>> lot5         0.98109    0.47943   2.046   0.0490 *
>> lot6        -0.09891    0.47943  -0.206   0.8379
>> time         0.02586    0.02046   1.264   0.2153
>> ---
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



 
St?phane Adamowicz
Chercheur / Scientist
stephane.adamowicz at paca.inra.fr
Centre PACA - UR 1115 PSH
Tel. : +33 1 (0)4 32 72 24 35
Fax : +33 1 (0)4 32 72 24 32
228, route de l'A?rodrome
84 914 Avignon Cedex 9
France
www.inra.fr


From Roger.Bivand at nhh.no  Wed May  6 12:23:58 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 6 May 2015 10:23:58 +0000
Subject: [R] Plot by FIPS Code using Shapefiles
References: <CAMx+UYfi70FAbf6AXEDJXJKH7BNTW=Og7qJ9JCTLqn_wYuocSw@mail.gmail.com>
	<CAOwvMDy2P56hR0hECWJTycpjZAVXJGF2mxMNkrvUV+mzKgRuUg@mail.gmail.com>
	<CAMx+UYeUK1Spqb3V-GWRoeSpLBT6OZQTASOYGY3FAyNLD1UA3w@mail.gmail.com>
	<1430842055487-4706840.post@n4.nabble.com>
Message-ID: <loom.20150506T121605-254@post.gmane.org>

Corey Sparks <corey.sparks <at> utsa.edu> writes:

> 
> Joining data the way you're doing it is dangerous, Roger Bivand and others
> describes a standard way to do this process here:
>
http://r-sig-geo.2731867.n2.nabble.com/Merging-shapefiles-and-csv-td7586839.html


Quite right - the chunks Corey is referring to are:

Please do refer to the vignette in the maptools package, and to previous
threads which have advised that merge() should not be used, and that the
row.names of the data frames be used as ID keys. Typically using match() on
the row.names of the two objects will show which are not correctly aligned.

and

Beware that the data from the objects may be jumbled - never use merge,
always use match() on the row.names vectors of the objects to ensure that
the key-IDs agree. Jumbled data happens, it is important not to think
"shapefile" but to think DBMS with the ID key your way of staying sane. 

The maptools vignette is at:

http://cran.r-project.org/web/packages/maptools/vignettes/combine_maptools.pdf

or:

library(maptools)
vignette("combine_maptools")

Here I also suspect that you'll find that there are non-unique FIPS in the
county polygons file, so may need to go through
maptools::unionSpatialPolygons() first.

Roger

> 
> And I do an example using US Census data here, using merge():
> http://spatialdemography.org/wp-content/uploads/2013/04/9.-Sparks.pdf
> <http://spatialdemography.org/wp-content/uploads/2013/04/9.-Sparks.pdf>  
> 
> look at page 134 of that pdf.
> 
> Hope this helps
> 
> -----
> Corey Sparks, PhD
> Assistant Professor
> Department of Demography
> University of Texas at San Antonio
> 501 West C?sar E. Ch?vez  Blvd 
> Monterey Building 2.270C
> San Antonio, TX 78207
> 210-458-3166
> corey.sparks 'at' utsa.edu
> coreysparks.weebly.com
> --
> View this message in context:
http://r.789695.n4.nabble.com/Plot-by-FIPS-Code-using-Shapefiles-tp4706830p4706840.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help <at> r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From shouro at gmail.com  Wed May  6 12:38:17 2015
From: shouro at gmail.com (Shouro Dasgupta)
Date: Wed, 6 May 2015 12:38:17 +0200
Subject: [R] Plot by FIPS Code using Shapefiles
In-Reply-To: <CAOwvMDxjriVOWaqrqWDStwXbjOd4S0gv8fUkTrMhcCwxzJu=ZQ@mail.gmail.com>
References: <CAMx+UYfi70FAbf6AXEDJXJKH7BNTW=Og7qJ9JCTLqn_wYuocSw@mail.gmail.com>
	<CAOwvMDy2P56hR0hECWJTycpjZAVXJGF2mxMNkrvUV+mzKgRuUg@mail.gmail.com>
	<CAMx+UYeUK1Spqb3V-GWRoeSpLBT6OZQTASOYGY3FAyNLD1UA3w@mail.gmail.com>
	<CAOwvMDxjriVOWaqrqWDStwXbjOd4S0gv8fUkTrMhcCwxzJu=ZQ@mail.gmail.com>
Message-ID: <CAMx+UYdyKBJBiezvQjc7w_Sg3Weu39pM-U4BY6o-V_O+0wfESw@mail.gmail.com>

Dear Anthony,

Thanks again for your reply. The following worked for merge:

merged_data <- merge(shapes_fips,max_change,by="FIPS",all.x=T, all.y=F)


 However, I think I am doing something wrong - as I have 3109 FIPS code in
my original data but when I merge with the shapes
file SpatialPolygonsDataFrame, its not merging properly, many NA.

Is it a good idea to convert the shapefiles into data.frame/data.table for
merging and then transform it back to shapefiles? This is what I have been
doing:

shapes <- readShapePoly("F:/GCM//tl_2014_us_county/tl_2014_us_county.shp")
> shapes <- as.data.frame(shapes)
> setnames(shapes, "GEOID", "FIPS")
>


> shapes_fips <- shapes$GEOID
> shapes_fips <- as.data.table(shapes_fips)
> setnames(shapes_fips, "shapes_fips", "FIPS")
> shapes_fips <- shapes_fips[with(shapes_fips, order(FIPS)), ]
> shapes_fips$FIPS <- as.character(shapes_fips$FIPS)
>


> merged_data <- merge(shapes_fips,max_change,by="FIPS",all.x=F, all.y=T)
> merged_data <- as.data.table(merged_data)
> merged_data <- merged_data[with(merged_data, order(FIPS)), ]
>


> shapes$change <- merged_data$change


Thanks again!

Sincerely,

Shouro

On Tue, May 5, 2015 at 6:00 PM, Anthony Damico <ajdamico at gmail.com> wrote:

> so check the unique number of fips codes in the objects before and after
>
> > merged_data <- merge(shapes_fips,max_change,by="FIPS",all.X=T, all.y=T)
>
> also note that all.X should be all.x and you might want to use FALSE for
> one or both of those
>
>
>
> On Tue, May 5, 2015 at 11:40 AM, Shouro Dasgupta <shouro at gmail.com> wrote:
>
>> Hello,
>>
>> Thank you for your reply. My original data has 3109 FIPS codes. Is there
>> a way to merge only this data into the shapefiles? I hope I am clear.
>>
>> Thank you also for the link, I am trying to do something like this:
>> https://gist.github.com/reubano/1281134.
>>
>> Thanks again!
>>
>> Sincerely,
>>
>> Shouro
>>
>> On Tue, May 5, 2015 at 5:21 PM, Anthony Damico <ajdamico at gmail.com>
>> wrote:
>>
>>> hi, after running each individual line of code above, check that the
>>> object still has the expected number of records and unique county fips
>>> codes.  it looks like length( shapes$GEOID ) == 3233 but nrow( merged_data
>>> ) == 3109.  the way for you to debug this is for you to go through line by
>>> line after creating each new object  :)
>>>
>>> i'm also not sure it's safe to work with gis objects as you're doing,
>>> there are some well-documented examples of working with tiger files here
>>> https://github.com/davidbrae/swmap
>>>
>>>
>>>
>>> On Tue, May 5, 2015 at 11:00 AM, Shouro Dasgupta <shouro at gmail.com>
>>> wrote:
>>>
>>>> I am trying to plot data by FIPS code using county shapes files.
>>>>
>>>> library(data.table)
>>>> > library(rgdal)
>>>> > library(colourschemes)
>>>> > library(RColorBrewer)
>>>> > library(maptools)
>>>> > library(maps)
>>>> > library(ggmap)
>>>>
>>>>
>>>> I have data by FIPS code which looks like this:
>>>> >
>>>> >
>>>> > dput(head(max_change))
>>>> > structure(list(FIPS = c("01001", "01003", "01005", "01007", "01009",
>>>> > "01011"), pred_hist = c(5.68493780563595e-06, 5.87686839563543e-06,
>>>> > 5.68493780563595e-06, 5.84476370329784e-06, 5.89156133294344e-06,
>>>> > 5.68493780563595e-06), pred_sim = c(5.60128903156804e-06,
>>>> > 5.82369276823497e-06,
>>>> > 5.60128903156804e-06, 5.75205304048323e-06, 5.80322399836766e-06,
>>>> > 5.60128903156804e-06), change = c(-1.47141054005866,
>>>> -0.904829303986895,
>>>> > -1.47141054005866, -1.58621746782168, -1.49938750670105,
>>>> -1.47141054005866
>>>> > )), .Names = c("FIPS", "pred_hist", "pred_sim", "change"), class =
>>>> > c("data.table",
>>>> > "data.frame"), row.names = c(NA, -6L), .internal.selfref = <pointer:
>>>> > 0x0000000000110788>)
>>>>
>>>>
>>>>  I add leading zeroes by:
>>>>
>>>> max_change <- as.data.table(max_change)
>>>> max_change$FIPS <- sprintf("%05d",as.numeric(max_change$FIPS))
>>>>
>>>> I downloaded shapefiles from here:
>>>> ftp://ftp2.census.gov/geo/tiger/TIGER2014/COUNTY/.
>>>>
>>>> I obtain the FIPS codes from the shapefiles and order them using:
>>>>
>>>> shapes_fips <- shapes$GEOID
>>>> > shapes_fips <- as.data.table(shapes_fips)
>>>> > setnames(shapes_fips, "shapes_fips", "FIPS")
>>>> > shapes_fips <- shapes_fips[with(shapes_fips, order(FIPS)), ]
>>>> > shapes_fips$FIPS <- as.character(shapes_fips$FIPS)
>>>>
>>>>
>>>> Then I merge the FIPS codes with my original dataset using:
>>>>
>>>> >
>>>> > merged_data <- merge(shapes_fips,max_change,by="FIPS",all.X=T,
>>>> all.y=T)
>>>> > merged_data <- as.data.table(merged_data)
>>>>
>>>>
>>>> Which looks like this:
>>>>
>>>> structure(list(FIPS = c("01001", "01003", "01005", "01007", "01009",
>>>> > "01011"), pred_hist = c(5.68493780563595e-06, 5.87686839563543e-06,
>>>> > 5.68493780563595e-06, 5.84476370329784e-06, 5.89156133294344e-06,
>>>> > 5.68493780563595e-06), pred_sim = c(5.60128903156804e-06,
>>>> > 5.82369276823497e-06,
>>>> > 5.60128903156804e-06, 5.75205304048323e-06, 5.80322399836766e-06,
>>>> > 5.60128903156804e-06), change = c(-1.47141054005866,
>>>> -0.904829303986895,
>>>> > -1.47141054005866, -1.58621746782168, -1.49938750670105,
>>>> -1.47141054005866
>>>> > )), .Names = c("FIPS", "pred_hist", "pred_sim", "change"), sorted =
>>>> > "FIPS", class = c("data.table",
>>>> > "data.frame"), row.names = c(NA, -6L), .internal.selfref = <pointer:
>>>> > 0x0000000000110788>)
>>>>
>>>>
>>>> But when I try to merged data back to the SpatialPolygonsDataFrame
>>>> called
>>>> shapes, I get the following error:
>>>>
>>>> shapes$change <- merged_data$change
>>>>
>>>> Error in `[[<-.data.frame`(`*tmp*`, name, value = c(-1.47141054005866,
>>>> :
>>>> >   replacement has 3109 rows, data has 3233
>>>>
>>>>
>>>>  Apologies for the messy example, what am I doing wrong? Any help will
>>>> be
>>>> greatly appreciated. Thank you!
>>>>
>>>> Sincerely,
>>>>
>>>> Shouro
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>>
>> --
>>
>> Shouro Dasgupta
>> PhD Candidate | Department of Economics
>> Ca' Foscari University of Venezia
>>
>> ------------------------------
>>
>> Junior Researcher | Fondazione Eni Enrico Mattei (FEEM)
>> Isola di San Giorgio Maggiore, 8 | 30124 Venice, Italy
>> Tel: +39 041 2700 436
>>
>>
>


-- 

Shouro Dasgupta
PhD Candidate | Department of Economics
Ca' Foscari University of Venezia

------------------------------

Junior Researcher | Fondazione Eni Enrico Mattei (FEEM)
Isola di San Giorgio Maggiore, 8 | 30124 Venice, Italy
Tel: +39 041 2700 436

	[[alternative HTML version deleted]]


From lvest09 at student.sdu.dk  Wed May  6 11:36:57 2015
From: lvest09 at student.sdu.dk (Livia Maria Vestergaard)
Date: Wed, 6 May 2015 09:36:57 +0000
Subject: [R]  lm model exported from R to excel
Message-ID: <2DFEDD9D3576FB419C7BF7511E983C964AE42FC3@ADM-EXMBX10D.adm.c.sdu.dk>

Hi all
I all. I am wondering whether anybody know how to export an output of an lm model from R to excel in order to have excel recognize the table that comes and divide the numbers in the table into columns and rows? 
I really hope it is possible? :)

Best Livia      

From shivibhatia at ymail.com  Wed May  6 12:21:27 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Wed, 6 May 2015 03:21:27 -0700 (PDT)
Subject: [R] MOnth over Month Variance in %
Message-ID: <1430907687472-4706873.post@n4.nabble.com>

Hi All,
I have data based on truck load for various states.
The data points range from Oct'14 To Mar'15. Now I need to know what was the
difference in load in Nov as compared to Oct in both real numbers as well as
in %. Similarly for all the month in comparison to the previous month. 
I am able to get the desired result in excel and not sure on how to achieve
the same in R.

Kindly suggest. 



--
View this message in context: http://r.789695.n4.nabble.com/MOnth-over-Month-Variance-in-tp4706873.html
Sent from the R help mailing list archive at Nabble.com.


From drjimlemon at gmail.com  Wed May  6 13:26:23 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 6 May 2015 21:26:23 +1000
Subject: [R] lm model exported from R to excel
In-Reply-To: <2DFEDD9D3576FB419C7BF7511E983C964AE42FC3@ADM-EXMBX10D.adm.c.sdu.dk>
References: <2DFEDD9D3576FB419C7BF7511E983C964AE42FC3@ADM-EXMBX10D.adm.c.sdu.dk>
Message-ID: <CA+8X3fWm1-+gP22KNP7SBC=hXk8KqLP5prQU62obdtEpb8R-jA@mail.gmail.com>

Hi Livia,
One way is to use the "delim.table" function in the prettyR package.
See the examples, in particular the final one. The resulting TAB
delimited file will usually import directly into Excel.

Jim


On Wed, May 6, 2015 at 7:36 PM, Livia Maria Vestergaard
<lvest09 at student.sdu.dk> wrote:
> Hi all
> I all. I am wondering whether anybody know how to export an output of an lm model from R to excel in order to have excel recognize the table that comes and divide the numbers in the table into columns and rows?
> I really hope it is possible? :)
>
> Best Livia
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Wed May  6 13:36:47 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 6 May 2015 11:36:47 +0000
Subject: [R] lm model exported from R to excel
In-Reply-To: <2DFEDD9D3576FB419C7BF7511E983C964AE42FC3@ADM-EXMBX10D.adm.c.sdu.dk>
References: <2DFEDD9D3576FB419C7BF7511E983C964AE42FC3@ADM-EXMBX10D.adm.c.sdu.dk>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2CD21@SRVEXCHMBX.precheza.cz>

Hi

AFAIK result of lm model is a list so you cannot expect easy direct output to Excel.

List of 12
 $ coefficients : Named num 61.2
  ..- attr(*, "names")= chr "cas"
 $ residuals    : Named num [1:2] 0 0
  ..- attr(*, "names")= chr [1:2] "1" "2"
 $ effects      : Named num [1:2] -61.2 0
  ..- attr(*, "names")= chr [1:2] "cas" ""
 $ rank         : int 1
 $ fitted.values: Named num [1:2] 0 61.2
  ..- attr(*, "names")= chr [1:2] "1" "2"
 $ assign       : int 1
 $ qr           :List of 5
  ..$ qr   : num [1:2, 1] -1 1
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:2] "1" "2"
  .. .. ..$ : chr "cas"
  .. ..- attr(*, "assign")= int 1
  ..$ qraux: num 1
  ..$ pivot: int 1
  ......


You can output data frame or other matrix like object e.g. by

write.table(tab, "clipboard", sep = "\t", row.names = F)

and in Excel you can use ctrl V.

So first you need to transform list or its part to be suitable for Excel.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Livia
> Maria Vestergaard
> Sent: Wednesday, May 06, 2015 11:37 AM
> To: r-help
> Subject: [R] lm model exported from R to excel
>
> Hi all
> I all. I am wondering whether anybody know how to export an output of
> an lm model from R to excel in order to have excel recognize the table
> that comes and divide the numbers in the table into columns and rows?
> I really hope it is possible? :)
>
> Best Livia
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From dulcalma at bigpond.com  Wed May  6 14:26:34 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 6 May 2015 22:26:34 +1000
Subject: [R] lm model exported from R to excel
In-Reply-To: <2DFEDD9D3576FB419C7BF7511E983C964AE42FC3@ADM-EXMBX10D.adm.c.sdu.dk>
References: <2DFEDD9D3576FB419C7BF7511E983C964AE42FC3@ADM-EXMBX10D.adm.c.sdu.dk>
Message-ID: <001b01d087f7$e471a7b0$ad54f710$@bigpond.com>

Hi Livia

There are several html packages that ?could also do it 

Heres a way with xtable

library(xtable)
y = rnorm(100)
x= rnorm(100)+rnorm(100)
mod <- lm(y ~x)

# latex example easy view
xtable(mod)

# html
file.create("lm.htm")
ff <- file("lm.htm", "a+")
fchars <-  print(xtable(mod),type = "html")
writeLines(paste(fchars, sep = ""), ff)
close(ff)

You can then bring this into Microsoft as an html file

You may need to fill in some of the arguments in xtable to get the right
border format etc

If you are doing many you can make a function to do things

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au 

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Livia Maria
Vestergaard
Sent: Wednesday, 6 May 2015 19:37
To: r-help
Subject: [R] lm model exported from R to excel

Hi all
I all. I am wondering whether anybody know how to export an output of an lm
model from R to excel in order to have excel recognize the table that comes
and divide the numbers in the table into columns and rows? 
I really hope it is possible? :)

Best Livia      
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jl.iccp at gmail.com  Wed May  6 15:04:41 2015
From: jl.iccp at gmail.com (Jue Lin-Ye)
Date: Wed, 6 May 2015 15:04:41 +0200
Subject: [R] Decomposing irregular time series
Message-ID: <CAAMkPW-f9AH8hSChDxGL_X6vAweHE_eXSjG35DtvM3pA_Pnugw@mail.gmail.com>

?Dear fellow members of the r-help list,

?May someone be so kind as to point out? how an irregular time series
should be decomposed into season and trend?

My code, the related error and my data are enclosed herein.

?Best regards and thanks in advance!

?--
Jue?


> x<-read.table(file="Data3.txt",header=T)
> for(i5 in 1:nrow(
?x)){
+ time3<-ISOdatetime(
?x[i5,"AAi"],X_season1[i5,"MMi"],x[i5,"DDi"],x[i5,"HHi"],0,0)
+ }
> zoo(
?x[,"dur_storm"],time3)->ZOO1
> stl(ZOO1)

Error in stl(ZOO1) : series is not periodic or has less than two periods
In addition: Warning message:
In as.ts.zoo(x) : ?x? does not have an underlying regularity

??

?
-------------- next part --------------
"AAi" "MMi" "DDi" "HHi" "dur_storm"
2051 1 14 16 107
2051 1 22 0 167
2051 1 31 12 87
2051 2 16 17 1027
2051 8 17 18 67
2051 11 14 9 977
2051 11 21 15 357
2051 11 24 11 587
2051 12 8 21 107
2051 12 22 18 217
2052 1 20 22 197
2052 2 27 16 127
2052 3 4 21 217
2052 3 26 11 97
2052 7 25 18 97
2052 8 24 14 137
2052 10 14 7 127
2052 10 26 5 157
2052 11 20 23 527
2052 12 9 12 307
2052 12 28 17 107
2053 1 2 7 377
2053 2 6 6 667
2053 2 23 15 457
2053 3 9 5 347
2053 4 15 18 247
2053 4 30 22 127
2053 10 9 8 97
2053 10 31 23 437
2053 11 17 23 447
2053 12 31 2 177
2054 1 26 8 97
2054 1 31 12 147
2054 2 5 23 67
2054 2 13 14 137
2054 2 28 8 67
2054 4 14 21 177
2054 4 16 17 247
2054 10 13 21 207
2054 10 18 21 87
2054 11 1 14 337
2054 11 4 9 157
2054 11 12 20 97
2054 11 23 5 597
2054 12 3 1 147
2055 1 9 0 327
2055 1 27 10 287
2055 2 15 18 127
2055 3 3 17 127
2055 4 1 21 107
2055 4 16 3 117
2055 4 18 16 797
2055 5 16 10 67
2055 7 7 15 97
2055 9 10 13 307
2055 12 23 13 397
2055 12 29 0 127
2056 1 17 0 107
2056 1 20 10 107
2056 3 18 7 577
2056 3 24 7 457
2056 4 5 11 167
2056 4 18 20 477
2056 5 18 16 67
2056 11 25 10 237
2056 12 15 3 197
2056 12 27 3 167
2057 1 2 21 87
2057 1 15 8 1197
2057 2 3 4 107
2057 2 14 7 497
2057 2 23 23 307
2057 2 27 20 787
2057 3 6 17 67
2057 3 20 16 227
2057 5 4 14 147
2057 5 18 1 217
2057 10 21 12 567
2057 11 7 7 487
2057 12 10 1 107
2057 12 26 9 87
2058 1 10 1 817
2058 1 29 6 117
2058 1 31 8 137
2058 2 14 13 97
2058 2 15 18 77
2058 2 19 4 247
2058 3 21 14 67
2058 3 23 12 107
2058 4 7 2 187
2058 6 22 20 67
2058 9 29 5 67
2058 10 4 14 137
2058 11 7 6 567
2058 11 27 8 77
2058 12 29 15 67
2059 2 8 18 397
2059 2 16 2 287
2059 2 19 19 307
2059 4 15 0 447
2059 8 8 8 177
2059 10 21 15 77
2059 10 28 12 487
2059 11 7 10 167
2059 11 14 1 297
2059 11 22 23 67
2059 12 20 3 857
2060 1 17 4 377
2060 2 10 9 187
2060 2 21 8 507
2060 3 1 8 347
2060 3 14 8 327
2060 4 7 5 297
2060 4 17 20 507
2060 4 22 3 127
2060 10 1 16 217
2060 11 22 21 137
2060 12 17 8 117
2060 12 26 13 157
2060 12 31 16 87
2061 1 3 21 577
2061 1 21 10 187
2061 4 8 21 237
2061 4 13 21 327
2061 4 16 19 617
2061 5 24 17 397
2061 11 13 8 357
2061 11 17 8 117
2062 4 6 20 167
2062 4 11 10 377
2062 7 16 4 87
2062 8 29 18 447
2062 10 16 19 107
2062 11 1 18 127
2062 12 20 13 667
2062 12 27 8 267
2063 2 8 23 357
2063 3 13 17 257
2063 3 21 18 227
2063 3 26 16 167
2063 4 2 1 247
2063 4 9 16 277
2063 10 30 17 97
2063 11 11 7 87
2064 1 20 19 77
2064 2 8 14 337
2064 2 21 5 157
2064 3 16 21 227
2064 8 28 5 147
2064 11 3 2 137
2064 12 17 7 167
2065 1 5 19 97
2065 1 21 17 297
2065 1 31 8 397
2065 2 13 20 127
2065 2 24 7 337
2065 3 15 16 197
2065 3 27 21 207
2065 4 9 6 217
2065 4 26 13 97
2065 5 12 17 97
2065 9 7 15 87
2065 11 4 14 237
2065 11 18 1 157
2065 11 19 12 487
2065 12 18 10 77
2066 1 3 17 217
2066 2 22 5 297
2066 3 1 8 407
2066 3 22 17 77
2066 4 3 4 147
2066 5 4 23 397
2066 6 5 10 87
2066 10 9 14 167
2066 10 16 17 67
2066 11 3 18 807
2066 12 16 15 77
2067 1 17 2 107
2067 1 22 2 117
2067 1 28 12 147
2067 2 13 2 67
2067 2 16 2 297
2067 2 25 9 187
2067 3 27 11 97
2067 4 16 14 97
2067 4 26 5 217
2067 4 28 11 237
2067 5 5 7 197
2067 10 2 22 357
2067 10 18 13 327
2067 11 23 17 197
2067 11 30 10 317
2067 12 8 20 287
2067 12 12 10 97
2067 12 14 7 287
2068 1 4 22 217
2068 2 3 14 237
2068 2 13 15 287
2068 2 27 7 117
2068 3 7 4 397
2068 10 16 17 97
2068 10 18 14 207
2068 10 20 19 257
2068 10 29 4 207
2068 11 28 2 167
2068 11 30 5 227
2068 12 10 4 117
2069 1 4 8 257
2069 1 20 20 87
2069 4 6 18 107
2069 4 12 21 207
2069 5 2 8 217
2069 5 30 15 127
2069 6 30 6 77
2069 9 17 3 127
2069 10 4 17 67
2069 11 7 8 197
2069 11 12 5 477
2069 11 26 4 127
2069 11 30 7 257
2070 1 14 18 117
2070 1 29 11 717
2070 3 11 1 317
2070 3 21 2 67
2070 3 31 23 477
2070 4 13 11 297
2070 10 24 2 477
2070 12 15 17 67
2071 1 20 1 417
2071 1 22 12 117
2071 2 20 1 547
2071 2 25 16 357
2071 3 14 14 217
2071 3 24 10 137
2071 3 28 19 377
2071 4 2 3 167
2071 6 6 15 127
2071 10 2 0 127
2072 1 2 8 267
2072 2 12 0 347
2072 2 27 14 137
2072 5 7 9 117
2072 8 5 20 77
2072 10 9 7 97
2072 10 11 13 137
2072 10 17 4 397
2072 10 22 14 127
2072 10 28 1 227
2072 11 21 13 107
2072 11 26 3 147
2072 12 14 23 197
2072 12 19 3 217
2072 12 31 20 87
2073 2 13 15 117
2073 2 18 1 237
2073 3 2 0 277
2073 3 4 7 117
2073 3 5 14 97
2073 3 13 22 87
2073 3 19 8 127
2073 3 20 10 827
2073 3 28 16 77
2073 3 30 5 267
2073 10 7 20 87
2073 10 10 7 177
2073 10 13 3 167
2073 10 20 19 167
2073 12 5 8 97
2073 12 8 16 107
2074 1 8 4 67
2074 1 14 1 207
2074 1 24 21 227
2074 2 2 21 157
2074 3 23 8 317
2074 3 30 18 347
2074 8 22 20 197
2074 9 30 19 207
2074 11 10 0 617
2074 12 2 20 77
2074 12 17 7 197
2074 12 21 11 137
2074 12 24 9 267
2075 1 4 5 137
2075 1 10 15 207
2075 1 20 10 127
2075 1 23 21 97
2075 1 29 18 457
2075 4 12 20 447
2075 5 3 4 187
2075 5 8 1 157
2075 5 23 14 117
2075 9 30 19 127
2075 10 21 18 187
2075 11 5 10 117
2075 11 21 16 97
2075 11 27 16 377
2075 12 28 5 67
2076 1 21 9 347
2076 1 25 6 667
2076 3 5 3 237
2076 3 7 17 337
2076 3 25 1 167
2076 4 2 4 127
2076 9 17 20 67
2076 11 1 16 427
2076 12 31 18 187
2077 1 16 14 137
2077 2 1 20 187
2077 2 25 6 497
2077 3 22 15 267
2077 3 30 1 537
2077 4 24 10 197
2077 4 30 15 167
2077 6 6 16 197
2077 9 2 12 147
2077 9 26 14 367
2077 10 21 14 207
2077 12 9 6 317
2078 1 3 2 357
2078 1 5 12 187
2078 2 10 16 107
2078 2 15 10 307
2078 2 23 4 177
2078 3 22 8 177
2078 4 4 11 97
2078 9 7 18 207
2078 9 14 18 137
2078 11 6 18 257
2078 11 14 7 197
2078 12 20 15 857
2079 1 12 17 177
2079 1 29 3 207
2079 3 15 14 127
2079 3 19 4 247
2079 4 13 14 317
2079 6 17 3 97
2079 10 15 22 77
2079 10 19 20 137
2079 11 25 11 267
2079 12 20 9 97
2080 1 10 14 177
2080 1 20 4 147
2080 2 29 16 177
2080 3 27 16 97
2080 4 5 14 117
2080 4 28 12 67
2080 10 2 9 147
2080 10 27 7 117
2080 10 29 16 257
2080 12 23 13 87
2081 1 7 11 137
2081 3 3 11 197
2081 3 20 5 157
2081 3 25 11 167
2081 3 26 17 607
2081 4 2 0 627
2081 4 29 6 77
2081 9 2 17 377
2081 9 24 12 157
2081 10 4 9 357
2081 10 6 13 117
2081 10 8 17 397
2081 10 12 19 217
2081 10 15 7 77
2081 11 11 13 137
2081 11 13 19 307
2081 12 2 2 137
2081 12 30 10 487
2082 2 13 2 97
2082 2 26 17 67
2082 5 4 17 157
2082 5 12 19 67
2082 10 19 17 67
2082 10 27 16 177
2082 11 7 23 137
2082 12 16 8 67
2082 12 22 14 67
2082 12 23 22 707
2083 1 16 14 457
2083 1 28 12 87
2083 2 16 14 87
2083 3 2 5 477
2083 3 8 22 257
2083 3 11 17 87
2083 4 10 23 227
2083 5 12 2 77
2083 9 18 2 167
2083 10 22 9 317
2083 11 10 4 87
2083 11 18 21 327
2083 12 7 15 267
2084 1 16 11 757
2084 1 21 23 77
2084 1 26 9 127
2084 2 5 8 197
2084 3 10 17 77
2084 3 27 17 207
2084 4 1 17 77
2084 4 15 13 137
2084 5 6 11 257
2084 5 16 2 237
2084 10 20 22 87
2084 10 26 19 407
2084 11 14 9 77
2084 11 23 14 127
2084 12 3 6 137
2084 12 16 19 77
2084 12 31 4 297
2085 1 19 3 337
2085 2 21 22 317
2085 3 14 18 317
2085 4 7 18 97
2085 8 21 10 177
2085 11 23 18 417
2085 12 29 17 267
2086 1 22 2 427
2086 5 8 12 127
2086 10 12 2 417
2086 11 3 7 117
2086 11 8 8 387
2086 12 4 14 767
2086 12 19 20 87
2087 1 8 19 107
2087 1 13 14 657
2087 2 12 1 227
2087 2 14 14 327
2087 3 2 13 407
2087 3 8 17 327
2087 3 14 1 147
2087 3 17 14 207
2087 3 22 3 107
2087 3 24 23 237
2087 4 26 15 317
2087 6 25 16 327
2087 8 29 16 87
2087 10 30 23 267
2087 11 14 4 267
2088 1 6 3 117
2088 2 23 22 567
2088 3 5 5 237
2088 5 7 9 147
2088 5 12 8 77
2088 10 15 15 447
2088 10 19 9 87
2088 12 13 9 67
2088 12 19 2 287
2089 1 2 1 207
2089 1 6 20 127
2089 1 13 13 597
2089 1 19 14 617
2089 1 28 13 447
2089 2 17 23 237
2089 2 25 3 107
2089 3 7 4 67
2089 3 14 8 207
2089 4 9 4 427
2089 9 23 17 67
2089 9 26 8 147
2089 10 1 7 107
2089 10 31 3 367
2089 11 28 0 147
2089 11 30 10 507
2090 1 5 21 217
2090 1 13 22 77
2090 2 15 23 127
2090 2 21 6 97
2090 3 9 19 217
2090 3 11 14 67
2090 3 16 8 127
2090 3 22 12 467
2090 3 28 12 137
2090 3 30 12 147
2090 4 19 22 147
2090 12 3 9 387
2090 12 15 14 87
2090 12 25 1 377
2090 12 28 0 827
2091 1 7 22 467
2091 1 12 2 447
2091 1 25 12 667
2091 2 20 19 147
2091 3 17 20 197
2091 3 22 17 167
2091 4 6 19 197
2091 4 18 19 427
2091 6 14 21 97
2091 6 29 11 177
2091 8 26 7 87
2091 9 3 19 107
2091 9 17 17 377
2091 10 14 6 237
2091 12 10 5 227
2091 12 16 0 247
2092 1 21 22 467
2092 1 29 0 177
2092 2 11 15 177
2092 2 27 13 607
2092 5 5 17 87
2092 8 15 5 207
2092 9 5 11 187
2092 9 19 8 107
2092 9 22 14 407
2092 10 8 18 137
2092 10 10 10 177
2092 10 12 14 107
2092 10 31 7 107
2092 11 7 18 67
2092 11 29 1 187
2092 12 3 5 157
2092 12 10 13 87
2092 12 11 17 307
2093 1 14 13 67
2093 3 4 0 277
2093 3 14 7 697
2093 5 20 13 77
2093 8 19 18 107
2093 10 6 18 187
2093 12 7 16 417
2093 12 14 11 97
2094 1 14 19 257
2094 1 17 17 447
2094 2 27 21 267
2094 3 5 10 167
2094 3 7 22 97
2094 3 10 8 177
2094 3 12 19 117
2094 4 21 1 207
2094 5 13 7 197
2094 9 14 16 107
2094 10 5 11 87
2094 11 17 9 457
2094 12 11 13 487
2094 12 26 3 87
2094 12 27 19 167
2095 2 27 20 297
2095 3 8 11 197
2095 3 13 3 97
2095 4 2 8 287
2095 4 18 11 77
2095 10 11 8 547
2095 10 19 0 247
2095 11 19 9 167
2095 11 20 21 137
2096 1 31 11 247
2096 2 24 14 87
2096 3 6 20 157
2096 3 27 16 127
2096 4 30 0 137
2096 10 5 20 227
2096 10 15 4 1227
2096 11 3 20 457
2096 11 12 7 117
2096 12 6 2 137
2096 12 28 14 77
2097 1 15 4 317
2097 1 25 18 157
2097 2 21 18 117
2097 4 7 11 907
2097 4 14 13 147
2097 4 26 13 187
2097 9 26 7 77
2097 10 20 17 617
2097 10 25 21 207
2097 12 2 20 197
2097 12 14 8 147
2098 1 13 9 107
2098 1 16 7 327
2098 1 19 8 417
2098 2 12 3 107
2098 3 4 9 1157
2098 3 16 13 87
2098 4 15 4 587
2098 5 10 19 67
2098 5 11 16 67
2098 9 9 18 347
2098 9 29 5 347
2098 11 16 16 87
2098 11 20 12 687
2098 12 13 16 137
2099 1 16 16 157
2099 2 28 12 287
2099 3 11 8 267
2099 3 15 17 67
2099 3 29 1 497
2099 5 17 10 107
2099 5 23 2 507
2099 8 1 11 157
2099 8 30 0 107
2099 9 10 9 187
2099 11 12 4 247
2099 11 23 23 277
2099 12 9 12 277
2099 12 22 15 167
2099 12 26 17 747
2100 3 12 14 107
2100 4 4 10 397
2100 4 18 13 1067
2100 10 20 6 157
2100 12 30 3 297

From jdnewmil at dcn.davis.CA.us  Wed May  6 15:09:42 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 06 May 2015 06:09:42 -0700
Subject: [R] MOnth over Month Variance in %
In-Reply-To: <1430907687472-4706873.post@n4.nabble.com>
References: <1430907687472-4706873.post@n4.nabble.com>
Message-ID: <EDED7354-87AC-4925-A6F6-790A6FAE519A@dcn.davis.CA.us>

It seems like the ?diff function might be useful here, but without a reproducible example  (at the very least some data  provided as dput output and results of your Excel calculations for that data) we would have to guess quite a bit and likely be wrong.
Take the recommendations at [1] to heart and give us a better picture of your problem and attempted solution.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 6, 2015 3:21:27 AM PDT, Shivi82 <shivibhatia at ymail.com> wrote:
>Hi All,
>I have data based on truck load for various states.
>The data points range from Oct'14 To Mar'15. Now I need to know what
>was the
>difference in load in Nov as compared to Oct in both real numbers as
>well as
>in %. Similarly for all the month in comparison to the previous month. 
>I am able to get the desired result in excel and not sure on how to
>achieve
>the same in R.
>
>Kindly suggest. 
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/MOnth-over-Month-Variance-in-tp4706873.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Wed May  6 16:19:42 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 6 May 2015 06:19:42 -0800
Subject: [R] MOnth over Month Variance in %
In-Reply-To: <1430907687472-4706873.post@n4.nabble.com>
Message-ID: <5DBC6372B55.0000134Bjrkrideau@inbox.com>

I think we need to know a bit about your level of knowledge of R, what the data currently looks like (In R format preferably) and maybe see what you have tried so far.  Please have a look at the following link, and pay particular attention to the use of dput() as a way to present data on R-help.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: shivibhatia at ymail.com
> Sent: Wed, 6 May 2015 03:21:27 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] MOnth over Month Variance in %
> 
> Hi All,
> I have data based on truck load for various states.
> The data points range from Oct'14 To Mar'15. Now I need to know what was
> the
> difference in load in Nov as compared to Oct in both real numbers as well
> as
> in %. Similarly for all the month in comparison to the previous month.
> I am able to get the desired result in excel and not sure on how to
> achieve
> the same in R.
> 
> Kindly suggest.
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/MOnth-over-Month-Variance-in-tp4706873.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Send your photos by email in seconds...
TRY FREE IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if3
Works in all emails, instant messengers, blogs, forums and social networks.


From dulcalma at bigpond.com  Wed May  6 16:32:48 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 7 May 2015 00:32:48 +1000
Subject: [R] lm model exported from R to excel
In-Reply-To: <2DFEDD9D3576FB419C7BF7511E983C964AE42FF1@ADM-EXMBX10D.adm.c.sdu.dk>
References: <2DFEDD9D3576FB419C7BF7511E983C964AE42FC3@ADM-EXMBX10D.adm.c.sdu.dk>,
	<001b01d087f7$e471a7b0$ad54f710$@bigpond.com>
	<2DFEDD9D3576FB419C7BF7511E983C964AE42FF1@ADM-EXMBX10D.adm.c.sdu.dk>
Message-ID: <000601d08809$871c0cb0$95542610$@bigpond.com>

If you know some basic html language you can jazz up the table headings to
your liking by writing that before the xtable statement.
It save having to muck around in Microsoft to fix it.
If you are going to do a lot of it - a little study of html basics can go
far.

I was changing the headings to what I wanted using html (although not all
the tables were lm summaries) before the major upgrade a year or so ago
Now things are better.

Even a title and comments in html for yourself if not available in xtable
are helpful. I have not used xtable and html since the upgrade as I use
latex

Duncan

-----Original Message-----
From: Livia Maria Vestergaard [mailto:lvest09 at student.sdu.dk] 
Sent: Wednesday, 6 May 2015 22:37
To: Duncan Mackay; R
Subject: SV: [R] lm model exported from R to excel

Hi Duncan
Thank you so much - it worked :)

Best 

Livia
________________________________________
Fra: Duncan Mackay [dulcalma at bigpond.com]
Sendt: 6. maj 2015 14:26
Til: R; Livia Maria Vestergaard
Emne: RE: [R]  lm model exported from R to excel

Hi Livia

There are several html packages that ?could also do it

Heres a way with xtable

library(xtable)
y = rnorm(100)
x= rnorm(100)+rnorm(100)
mod <- lm(y ~x)

# latex example easy view
xtable(mod)

# html
file.create("lm.htm")
ff <- file("lm.htm", "a+")
fchars <-  print(xtable(mod),type = "html")
writeLines(paste(fchars, sep = ""), ff)
close(ff)

You can then bring this into Microsoft as an html file

You may need to fill in some of the arguments in xtable to get the right
border format etc

If you are doing many you can make a function to do things

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Livia Maria
Vestergaard
Sent: Wednesday, 6 May 2015 19:37
To: r-help
Subject: [R] lm model exported from R to excel

Hi all
I all. I am wondering whether anybody know how to export an output of an lm
model from R to excel in order to have excel recognize the table that comes
and divide the numbers in the table into columns and rows?
I really hope it is possible? :)

Best Livia
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Wed May  6 16:48:39 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 6 May 2015 14:48:39 +0000
Subject: [R] Mantel test
In-Reply-To: <CADUrEERHag1XPRr-8CWH-e0en9Li7EenAyfB45-TKSBnBp7jdg@mail.gmail.com>
References: <CADUrEER9U0SUh9BsFGwy=pXpfMjGS8NecRgyiEt3VHD0xLkQkg@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D689C1B@mb02.ads.tamu.edu>
	<CADUrEERHag1XPRr-8CWH-e0en9Li7EenAyfB45-TKSBnBp7jdg@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68A46B@mb02.ads.tamu.edu>

Please keep the discussion on the list. It is hard to answer your question without context. You give us a warning message from a function that is not in base R. Perhaps it is in package ade? You also don?t include anything about the data or the commands that produced the warning message. A dist object does not contain a diagonal so your comment suggests that you did not convert the matrix to a dist object.

David C

From: Nick Jeffery [mailto:nick.w.jeffery3 at gmail.com]
Sent: Wednesday, May 6, 2015 9:34 AM
To: David L Carlson
Subject: Re: [R] Mantel test

Hi,
Thanks for the help. I get these warnings when I run the Mantel test however - is this because the diagonal of the matrix is all 0s? Both are symmetrical matrices about the diagonal line of zeroes.

Warning messages:

1: In is.euclid(m1) : Zero distance(s)

2: In is.euclid(m2) : Zero distance(s)

Thanks for your time,

Nick



On Mon, May 4, 2015 at 3:48 PM, David L Carlson <dcarlson at tamu.edu<mailto:dcarlson at tamu.edu>> wrote:
Assuming the 'matrix' format is a symmetrical distance 'matrix' stored as a data frame (which read.csv creates) rather a rectangular data 'matrix,' you can convert it to a dist object with as.dist().

?dist

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Nick Jeffery
Sent: Monday, May 4, 2015 10:49 AM
To: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: [R] Mantel test

Dear R users,

I'm having trouble getting my data into R in the correct format to run a
Mantel test.

I'm testing genome size differences by genetic distances of the 28S gene
for ~30 species. I'm able to get my genome size data (as a single column of
data) into matrix and dist formats in R but the genetic distances output by
MEGA are already in 'matrix' format so I don't know how to load this CSV
file into R without it calculating new genetic distances when I convert it
to the dist form required by the test.

Thanks in advance,
Nick

--
Nick Jeffery, PhD Candidate
Integrative Biology
SCIE 1453
University of Guelph
Guelph, Ontario, Canada
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--
Nick Jeffery, PhD Candidate
Integrative Biology
SCIE 1453
University of Guelph
Guelph, Ontario, Canada

	[[alternative HTML version deleted]]


From ronald.koelpin at gmail.com  Wed May  6 16:59:45 2015
From: ronald.koelpin at gmail.com (=?UTF-8?B?Um9uYWxkIEvDtmxwaW4=?=)
Date: Wed, 06 May 2015 16:59:45 +0200
Subject: [R] Looking up the code for a function
Message-ID: <554A2C61.1080306@gmail.com>

Hi all,

I am trying to find out how a certain functionality is implemented in R
respectively what a certain found does exactly.

Specifically I am interested in multivariate kernel density estimation.
I found the "ks" package and its "kde" function. Usually, my preferred
way to "look under the hood" of any function is to simply type the
functions name without any brackets or arguments, in this case just:
kde. And this works fine for kde itself. But kde calls other functions,
such as kde.grid.3d or kde.points and typing those function names just
yields "Error: Object '[function name]' not found". These functions
aren't defined within kde either (as far as I can see).

So here is my question: Am I doing something wrong? Is there a way to
look up the code of these functions?

(I already tried google but found only the usual documentation
(vignettes) and articles referencing the function kde or the package ks).

Thanks a lot in advance
and kind regards

RK


From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed May  6 17:11:30 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Wed, 6 May 2015 17:11:30 +0200
Subject: [R] Looking up the code for a function
In-Reply-To: <554A2C61.1080306@gmail.com>
References: <554A2C61.1080306@gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F0C343011@UM-MAIL4112.unimaas.nl>

Probably these are non-exported functions. Try:

getAnywhere(<function name>)

Or if you know which package a function comes from:

<package name>:::<function name>

Best,
Wolfgang

--    
Wolfgang Viechtbauer, Ph.D., Statistician    
Department of Psychiatry and Neuropsychology    
School for Mental Health and Neuroscience    
Faculty of Health, Medicine, and Life Sciences    
Maastricht University, P.O. Box 616 (VIJV1)    
6200 MD Maastricht, The Netherlands    
+31 (43) 388-4170 | http://www.wvbauer.com    

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ronald
> K?lpin
> Sent: Wednesday, May 06, 2015 17:00
> To: r-help at r-project.org
> Subject: [R] Looking up the code for a function
> 
> Hi all,
> 
> I am trying to find out how a certain functionality is implemented in R
> respectively what a certain found does exactly.
> 
> Specifically I am interested in multivariate kernel density estimation.
> I found the "ks" package and its "kde" function. Usually, my preferred
> way to "look under the hood" of any function is to simply type the
> functions name without any brackets or arguments, in this case just:
> kde. And this works fine for kde itself. But kde calls other functions,
> such as kde.grid.3d or kde.points and typing those function names just
> yields "Error: Object '[function name]' not found". These functions
> aren't defined within kde either (as far as I can see).
> 
> So here is my question: Am I doing something wrong? Is there a way to
> look up the code of these functions?
> 
> (I already tried google but found only the usual documentation
> (vignettes) and articles referencing the function kde or the package ks).
> 
> Thanks a lot in advance
> and kind regards
> 
> RK
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Wed May  6 17:19:42 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 6 May 2015 11:19:42 -0400
Subject: [R] Looking up the code for a function
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730F0C343011@UM-MAIL4112.unimaas.nl>
References: <554A2C61.1080306@gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F0C343011@UM-MAIL4112.unimaas.nl>
Message-ID: <624CF65E-850F-46FD-8B9F-1654E17721ED@utoronto.ca>

Here's a discussion on stack overflow with more hints ...
  http://stackoverflow.com/questions/19226816/how-can-i-view-the-source-code-for-a-function

... and a link to an R-News article by Uwe Ligges on the topic
http://cran.r-project.org/doc/Rnews/Rnews_2006-4.pdf (p. 43 f)

Cheers,
Boris

On May 6, 2015, at 11:11 AM, Viechtbauer Wolfgang (STAT) <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> Probably these are non-exported functions. Try:
> 
> getAnywhere(<function name>)
> 
> Or if you know which package a function comes from:
> 
> <package name>:::<function name>
> 
> Best,
> Wolfgang
> 
> --    
> Wolfgang Viechtbauer, Ph.D., Statistician    
> Department of Psychiatry and Neuropsychology    
> School for Mental Health and Neuroscience    
> Faculty of Health, Medicine, and Life Sciences    
> Maastricht University, P.O. Box 616 (VIJV1)    
> 6200 MD Maastricht, The Netherlands    
> +31 (43) 388-4170 | http://www.wvbauer.com    
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ronald
>> K?lpin
>> Sent: Wednesday, May 06, 2015 17:00
>> To: r-help at r-project.org
>> Subject: [R] Looking up the code for a function
>> 
>> Hi all,
>> 
>> I am trying to find out how a certain functionality is implemented in R
>> respectively what a certain found does exactly.
>> 
>> Specifically I am interested in multivariate kernel density estimation.
>> I found the "ks" package and its "kde" function. Usually, my preferred
>> way to "look under the hood" of any function is to simply type the
>> functions name without any brackets or arguments, in this case just:
>> kde. And this works fine for kde itself. But kde calls other functions,
>> such as kde.grid.3d or kde.points and typing those function names just
>> yields "Error: Object '[function name]' not found". These functions
>> aren't defined within kde either (as far as I can see).
>> 
>> So here is my question: Am I doing something wrong? Is there a way to
>> look up the code of these functions?
>> 
>> (I already tried google but found only the usual documentation
>> (vignettes) and articles referencing the function kde or the package ks).
>> 
>> Thanks a lot in advance
>> and kind regards
>> 
>> RK
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Wed May  6 17:33:37 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 6 May 2015 07:33:37 -0800
Subject: [R] lm model exported from R to excel
In-Reply-To: <000601d08809$871c0cb0$95542610$@bigpond.com>
References: <001b01d087f7$e471a7b0$ad54f710$@bigpond.com>
	<2dfedd9d3576fb419c7bf7511e983c964ae42ff1@adm-exmbx10d.adm.c.sdu.dk>
	<2dfedd9d3576fb419c7bf7511e983c964ae42fc3@adm-exmbx10d.adm.c.sdu.dk>
Message-ID: <5E619901A9E.000014A2jrkrideau@inbox.com>

And for those of us who know close to nothing about HTML I found just now that under a basic print.xtable commmand we get those horrible HMTL borders that in Apache OpenOffice seemed impossible to remove safely.  No idea about Word--I have not used it in years.

I did find that adding  html.table.attributes = "border = 0" gets rid of the borders.  So 
So something like 

print.xtable(modtable, type = "html", html.table.attributes = "border = 0", file = "modtable .html") 
seems to give a reasonable  result in AOO.  At least I managed to do some half-decent formatting with it.

Meanwhile, back to LaTeX where the output looks beautiful. I like booktabs :)

John Kane
Kingston ON Canada


> -----Original Message-----
> From: dulcalma at bigpond.com
> Sent: Thu, 7 May 2015 00:32:48 +1000
> To: r-help at r-project.org
> Subject: Re: [R] lm model exported from R to excel
> 
> If you know some basic html language you can jazz up the table headings
> to
> your liking by writing that before the xtable statement.
> It save having to muck around in Microsoft to fix it.
> If you are going to do a lot of it - a little study of html basics can go
> far.
> 
> I was changing the headings to what I wanted using html (although not all
> the tables were lm summaries) before the major upgrade a year or so ago
> Now things are better.
> 
> Even a title and comments in html for yourself if not available in xtable
> are helpful. I have not used xtable and html since the upgrade as I use
> latex
> 
> Duncan
> 
> -----Original Message-----
> From: Livia Maria Vestergaard [mailto:lvest09 at student.sdu.dk]
> Sent: Wednesday, 6 May 2015 22:37
> To: Duncan Mackay; R
> Subject: SV: [R] lm model exported from R to excel
> 
> Hi Duncan
> Thank you so much - it worked :)
> 
> Best
> 
> Livia
> ________________________________________
> Fra: Duncan Mackay [dulcalma at bigpond.com]
> Sendt: 6. maj 2015 14:26
> Til: R; Livia Maria Vestergaard
> Emne: RE: [R]  lm model exported from R to excel
> 
> Hi Livia
> 
> There are several html packages that ?could also do it
> 
> Heres a way with xtable
> 
> library(xtable)
> y = rnorm(100)
> x= rnorm(100)+rnorm(100)
> mod <- lm(y ~x)
> 
> # latex example easy view
> xtable(mod)
> 
> # html
> file.create("lm.htm")
> ff <- file("lm.htm", "a+")
> fchars <-  print(xtable(mod),type = "html")
> writeLines(paste(fchars, sep = ""), ff)
> close(ff)
> 
> You can then bring this into Microsoft as an html file
> 
> You may need to fill in some of the arguments in xtable to get the right
> border format etc
> 
> If you are doing many you can make a function to do things
> 
> Duncan
> 
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Livia
> Maria
> Vestergaard
> Sent: Wednesday, 6 May 2015 19:37
> To: r-help
> Subject: [R] lm model exported from R to excel
> 
> Hi all
> I all. I am wondering whether anybody know how to export an output of an
> lm
> model from R to excel in order to have excel recognize the table that
> comes
> and divide the numbers in the table into columns and rows?
> I really hope it is possible? :)
> 
> Best Livia
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From lvest09 at student.sdu.dk  Wed May  6 14:37:14 2015
From: lvest09 at student.sdu.dk (Livia Maria Vestergaard)
Date: Wed, 6 May 2015 12:37:14 +0000
Subject: [R] lm model exported from R to excel
In-Reply-To: <001b01d087f7$e471a7b0$ad54f710$@bigpond.com>
References: <2DFEDD9D3576FB419C7BF7511E983C964AE42FC3@ADM-EXMBX10D.adm.c.sdu.dk>,
	<001b01d087f7$e471a7b0$ad54f710$@bigpond.com>
Message-ID: <2DFEDD9D3576FB419C7BF7511E983C964AE42FF1@ADM-EXMBX10D.adm.c.sdu.dk>

Hi Duncan
Thank you so much - it worked :)

Best 

Livia
________________________________________
Fra: Duncan Mackay [dulcalma at bigpond.com]
Sendt: 6. maj 2015 14:26
Til: R; Livia Maria Vestergaard
Emne: RE: [R]  lm model exported from R to excel

Hi Livia

There are several html packages that ?could also do it

Heres a way with xtable

library(xtable)
y = rnorm(100)
x= rnorm(100)+rnorm(100)
mod <- lm(y ~x)

# latex example easy view
xtable(mod)

# html
file.create("lm.htm")
ff <- file("lm.htm", "a+")
fchars <-  print(xtable(mod),type = "html")
writeLines(paste(fchars, sep = ""), ff)
close(ff)

You can then bring this into Microsoft as an html file

You may need to fill in some of the arguments in xtable to get the right
border format etc

If you are doing many you can make a function to do things

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Livia Maria
Vestergaard
Sent: Wednesday, 6 May 2015 19:37
To: r-help
Subject: [R] lm model exported from R to excel

Hi all
I all. I am wondering whether anybody know how to export an output of an lm
model from R to excel in order to have excel recognize the table that comes
and divide the numbers in the table into columns and rows?
I really hope it is possible? :)

Best Livia
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From tacsunday at yahoo.fr  Wed May  6 15:09:34 2015
From: tacsunday at yahoo.fr (Robert U)
Date: Wed, 6 May 2015 13:09:34 +0000 (UTC)
Subject: [R] Special character is graph label
Message-ID: <2020667851.1969198.1430917774136.JavaMail.yahoo@mail.yahoo.com>

Dear R users,
I am having issues finding a special character (and how to insert it) in the lab of a graph axis. 

Let us say that the label of my axis is "X", i would like the X to have a "line" over it, indicating that it is the "mean of X values" (i don't even know how to properly state that in english...). Does someone understand, and have any idea about how to do that?
Greetings,
R.H

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed May  6 18:24:53 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 6 May 2015 16:24:53 +0000
Subject: [R] lm model exported from R to excel
In-Reply-To: <2DFEDD9D3576FB419C7BF7511E983C964AE42FF1@ADM-EXMBX10D.adm.c.sdu.dk>
References: <2DFEDD9D3576FB419C7BF7511E983C964AE42FC3@ADM-EXMBX10D.adm.c.sdu.dk>,
	<001b01d087f7$e471a7b0$ad54f710$@bigpond.com>
	<2DFEDD9D3576FB419C7BF7511E983C964AE42FF1@ADM-EXMBX10D.adm.c.sdu.dk>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68A4DD@mb02.ads.tamu.edu>

If you are trying to save the html version of the table, Duncan's example can be simplified to

> print(xtable(mod), type="html", file="lm.html")

Open this file in Excel or Word. Alternatively open it in your browser and paste it into Word or Excel.

If you are using Windows and Excel, you can streamline this a bit more by using the Windows clipboard:

> print(xtable(mod), type="html", file="clipboard")

Open an Excel spreadsheet and then paste the table into it. For some reason, this will not work with Word. You have to paste into Excel, copy the table in Excel, and then paste into Word. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Livia Maria Vestergaard
Sent: Wednesday, May 6, 2015 7:37 AM
To: Duncan Mackay; R
Subject: Re: [R] lm model exported from R to excel

Hi Duncan
Thank you so much - it worked :)

Best 

Livia
________________________________________
Fra: Duncan Mackay [dulcalma at bigpond.com]
Sendt: 6. maj 2015 14:26
Til: R; Livia Maria Vestergaard
Emne: RE: [R]  lm model exported from R to excel

Hi Livia

There are several html packages that ?could also do it

Heres a way with xtable

library(xtable)
y = rnorm(100)
x= rnorm(100)+rnorm(100)
mod <- lm(y ~x)

# latex example easy view
xtable(mod)

# html
file.create("lm.htm")
ff <- file("lm.htm", "a+")
fchars <-  print(xtable(mod),type = "html")
writeLines(paste(fchars, sep = ""), ff)
close(ff)

You can then bring this into Microsoft as an html file

You may need to fill in some of the arguments in xtable to get the right
border format etc

If you are doing many you can make a function to do things

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Livia Maria
Vestergaard
Sent: Wednesday, 6 May 2015 19:37
To: r-help
Subject: [R] lm model exported from R to excel

Hi all
I all. I am wondering whether anybody know how to export an output of an lm
model from R to excel in order to have excel recognize the table that comes
and divide the numbers in the table into columns and rows?
I really hope it is possible? :)

Best Livia
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Wed May  6 18:33:01 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 6 May 2015 16:33:01 +0000
Subject: [R] Special character is graph label
In-Reply-To: <2020667851.1969198.1430917774136.JavaMail.yahoo@mail.yahoo.com>
References: <2020667851.1969198.1430917774136.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68A4FB@mb02.ads.tamu.edu>

You do this with plotmath (see the manual page, ?plotmath):

> plot(rnorm(10), rnorm(10), xlab=expression(bar(X)))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Robert U
Sent: Wednesday, May 6, 2015 8:10 AM
To: R-help at r-project.org
Subject: [R] Special character is graph label

Dear R users,
I am having issues finding a special character (and how to insert it) in the lab of a graph axis. 

Let us say that the label of my axis is "X", i would like the X to have a "line" over it, indicating that it is the "mean of X values" (i don't even know how to properly state that in english...). Does someone understand, and have any idea about how to do that?
Greetings,
R.H

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed May  6 18:53:50 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 6 May 2015 09:53:50 -0700
Subject: [R] does segfault mean (always) a bug?
In-Reply-To: <21833.55148.133483.482768@stat.math.ethz.ch>
References: <554911DB.8050909@yahoo.co.uk> <55491BDB.5070100@gmail.com>
	<5549C0CE.9040303@yahoo.co.uk>
	<21833.55148.133483.482768@stat.math.ethz.ch>
Message-ID: <CAF8bMcZyJ7-Xso_hm4upQUp-aniS0E98EaCKqgGCnEdBbSUwfQ@mail.gmail.com>

It looks like a problem in the Matrix package.  I made the file KE.rda
containing the Matrix objects K and E constructed in calc.diffusion.kernel
by adding a save() call just before where R dies in the original example:

        K = lam$values[1] * I - M
        E = I - matrix(1, ncol = ncol(I), nrow = nrow(I))/ncol(I)
cat("saving K, E, etc. in /tmp/KE.rda\n")
save(K, E, deg, invD, I, W, M, lam, file="/tmp/KE.rda")
cat("    done making the file\n")
        K = E %*% K %*% E

With that file in place I get
> library(Matrix)
> load("KE.rda")
> sessionInfo()
R version 3.2.0 (2015-04-16)
Platform: x86_64-unknown-linux-gnu (64-bit)
Running under: Ubuntu precise (12.04.5 LTS)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] Matrix_1.2-0

loaded via a namespace (and not attached):
[1] grid_3.2.0      lattice_0.20-31
> str(E)
Formal class 'dsyMatrix' [package "Matrix"] with 5 slots
  ..@ x       : num [1:143376676] 1.00 -8.35e-05 -8.35e-05 -8.35e-05
-8.35e-05 ...
  ..@ Dim     : int [1:2] 11974 11974
  ..@ Dimnames:List of 2
  .. ..$ : NULL
  .. ..$ : NULL
  ..@ uplo    : chr "U"
  ..@ factors : list()
> str(K)
Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
  ..@ i       : int [1:487692] 0 69 948 951 1027 1192 1414 1420 1421 1714
...
  ..@ p       : int [1:11975] 0 27 125 147 199 212 221 230 254 274 ...
  ..@ Dim     : int [1:2] 11974 11974
  ..@ Dimnames:List of 2
  .. ..$ : chr [1:11974] "GO:0000002" "GO:0000003" "GO:0000012"
"GO:0000018" ...
  .. ..$ : chr [1:11974] "GO:0000002" "GO:0000003" "GO:0000012"
"GO:0000018" ...
  ..@ x       : num [1:487692] 32.2163 -0.004674 -0.000722 -0.005316
-0.014022 ...
  ..@ factors : list()
> EK <- E %*% K
> EKE <- EK %*% E

 *** caught segfault ***
address 0x7fffa7e1ccf8, cause 'memory not mapped'

Traceback:
 1: EK %*% E
 2: EK %*% E

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection:

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, May 6, 2015 at 1:57 AM, Martin Maechler <
maechler at lynne.stat.math.ethz.ch> wrote:

> >>>>> lejeczek  <peljasz at yahoo.co.uk>
> >>>>>     on Wed, 6 May 2015 08:20:46 +0100 writes:
>
>     > On 05/05/15 20:36, Duncan Murdoch wrote:
>     >> On 05/05/2015 2:54 PM, lejeczek wrote:
>     >>> hi eveybody
>     >>>
>     >>> I'm trying something simple (Biocunductor packages), so
>     >>> simple I believe it's example from docs but I get segfault.
>     >>> I don't suppose incorrect scripting can cause segfault, right?
>     >> In R, a segfault always indicates a bug.  What's not so clear is
> whether
>     >> it is a bug in R, a bug in a contributed package, or a bug in some
>     >> underlying system library.
>     >>
>     >> If you can only trigger the bug when using a Bioconductor package,
> then
>     >> the first guess is that it is that package, and the maintainer of
> that
>     >> package is in the best position to track it down further.  If you
> can
>     >> simplify the code to trigger it without using any contributed
> packages,
>     >> then it could well be a bug in R, and we'd like to see code to
> reproduce it.
>     >>
>     >> Duncan Murdoch
>     >>
>     > hi Duncan
>     > I remember that this was a principle of most of programming
>     > languages, only a bug in the code and/or compiler could
>     > cause segfault.
>     > In my case it is a contributed package, specifically GOSim
>     > package, I'm not R programmer and I realise my scripting is
>     > far from good and possibly with errors.
>     > I could send that snippet of the code here if people think
>     > it can be looked into and segfault could be replicated?
>     > I also emailed the author.
>
>     > many thanks
>     > P.
>
> Dear P.,
>
> in the case of segfault from using a contributed package,
> you should typically really only email the package maintainer
> (which may different than the package authors), and not R-help.
> Only if the maintainer does not respond at all (and only if the
> package is open source, typically CRAN) should you ask for help here
> or another public forum.
>
> (I would also think it to be polite to the maintainer who has
>  volunteered her/his code to be used by you if you give him an
>  opportunity to see, comment and fix the problem)
>
> Martin Maechler
> ETH Zurich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lbagua at gmail.com  Wed May  6 18:58:50 2015
From: lbagua at gmail.com (Luis Borda de Agua)
Date: Wed, 6 May 2015 17:58:50 +0100
Subject: [R] order by which the eigenvalues are presented
Message-ID: <293DC84C-A5C5-4586-80FA-69199B7715E1@gmail.com>

Thank you, Bill, for your reply. However, I'm afraid I didn't explain myself properly.

 

Imagine you have a 2x2 matrix

Then the eigenvalues lambda_1 and lambda_2 are analytically calculated from

 

lambda_1 = (-b+sqrt(delta))/2a

lambda_2 = (-b-sqrt(delta))/2a

 

where delta = b^2-4ac

 

If delta>0 then lambda_1 > lambda_2 always. Otherwise their Real parts are equal.

 

If we have a 3x3 matrix the three eigenvalues will have very complicated expressions:

 

lambda_1 = f_1

lambda_2 = f_2

lambda_3 = f_3

 

where f_1,f_2 and f_3 are functions of the elements of the matrix a11,a12...,a33, which are sampled from a given distribution (e.g. normal(0,1)).

 

What I would like to know is from which expression (f_1,f_2 or f_3) comes the largest Re part of the eigenvalues. For example, does it always come from f_1 independently of the sampled values of a11,a12...,a33?

 

Thank you



____________________________________________________________
Lu?s Borda de ?gua
REFER Biodiversity Chair
CIBIO - Research Center in Biodiversity and Genetic Resources
Campus Agr?rio de Vair?o
R. Padre Armando Quintas
4485-661 Vair?o, Portugal

IICT - Tropical Research Institute
Travessa Conde da Ribeira N. 9 R/C
1300-142 Lisboa, Portugal
Tel: +351 21 361 63 40 ext. 312


	[[alternative HTML version deleted]]


From cdetermanjr at gmail.com  Wed May  6 19:13:17 2015
From: cdetermanjr at gmail.com (Charles Determan)
Date: Wed, 6 May 2015 12:13:17 -0500
Subject: [R] Package Build Recommendations
In-Reply-To: <bef9b9ac-03da-41e2-8e07-164802021684@me.com>
References: <bef9b9ac-03da-41e2-8e07-164802021684@me.com>
Message-ID: <CAKxd1KO=95fLqPZNsaGaMgSW+dROfmg4vCftR_h1LFVrbBd58A@mail.gmail.com>

Hi Glenn,

Generally data files are stored in the 'data' directory.  If you visit
Hadley's R packages site on the data page (http://r-pkgs.had.co.nz/data.html)
this is described quite clearly.  You can use the devtools package
functions like `use_data` to have data files properly stored in your
package.

Cheers,
Charles

On Tue, May 5, 2015 at 7:16 PM, Glenn Schultz <glennmschultz at me.com> wrote:

> Hi All,
>
> I have my R package built and it passes the CRAN tests.  Now, I have a
> question.  The file structure is not standard.  There are addition data
> files as follows outlined below.  Each, if you will, represents separation
> of concerns with respect to structured securities like MBS and REMICs
> (CMOs).  They referenced via connection in the software via a connection
> string ~/users/BondLab.  I am looking for recommendations to create the
> directory and copy the appropriate folders with their data to a user
> directory on install.  Any help will be appreciated.
>
> Glenn
>
> BondData
> Groups
> PrepaymentModel
> REMIC
> RDME
> RAID
> RatesData
> Scenario
> Schedules
> Tranches
> Waterfall
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Wed May  6 19:14:15 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 6 May 2015 09:14:15 -0800
Subject: [R] Special character is graph label
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68A4FB@mb02.ads.tamu.edu>
References: <2020667851.1969198.1430917774136.javamail.yahoo@mail.yahoo.com>
Message-ID: <5F4287281D2.000016C2jrkrideau@inbox.com>

Also have a look at http://astrostatistics.psu.edu/su07/R/html/grDevices/html/plotmath.html for a list of terms.

Oh and it's called  Xbar or X-bar. 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: dcarlson at tamu.edu
> Sent: Wed, 6 May 2015 16:33:01 +0000
> To: tacsunday at yahoo.fr, r-help at r-project.org
> Subject: Re: [R] Special character is graph label
> 
> You do this with plotmath (see the manual page, ?plotmath):
> 
>> plot(rnorm(10), rnorm(10), xlab=expression(bar(X)))
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Robert U
> Sent: Wednesday, May 6, 2015 8:10 AM
> To: R-help at r-project.org
> Subject: [R] Special character is graph label
> 
> Dear R users,
> I am having issues finding a special character (and how to insert it) in
> the lab of a graph axis.
> 
> Let us say that the label of my axis is "X", i would like the X to have a
> "line" over it, indicating that it is the "mean of X values" (i don't
> even know how to properly state that in english...). Does someone
> understand, and have any idea about how to do that?
> Greetings,
> R.H
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From murdoch.duncan at gmail.com  Wed May  6 20:57:51 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 06 May 2015 14:57:51 -0400
Subject: [R] Package Build Recommendations
In-Reply-To: <bef9b9ac-03da-41e2-8e07-164802021684@me.com>
References: <bef9b9ac-03da-41e2-8e07-164802021684@me.com>
Message-ID: <554A642F.4080804@gmail.com>

On 05/05/2015 8:16 PM, Glenn Schultz wrote:
> Hi All,
>
> I have my R package built and it passes the CRAN tests.  Now, I have a question.  The file structure is not standard.  There are addition data files as follows outlined below.  Each, if you will, represents separation of concerns with respect to structured securities like MBS and REMICs (CMOs).  They referenced via connection in the software via a connection string ~/users/BondLab.  I am looking for recommendations to create the directory and copy the appropriate folders with their data to a user directory on install.  Any help will be appreciated.
>

As Charles said, you can put them in the data directory, but there are 
restrictions on the type of files that can be there -- see Writing R 
Extensions.

An alternative is to put them in a directory with a name of your choice 
below the "inst" directory.  (Don't choose a name that conflicts with a 
standard one.)  On installation, it will be copied up a level, and the 
system.file() function will be able to find it.

Duncan Murdoch


From varinsacha at yahoo.fr  Wed May  6 20:59:32 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Wed, 6 May 2015 18:59:32 +0000 (UTC)
Subject: [R] Drawing the regression line and the 95% confidence intervals
In-Reply-To: <CA+8X3fXPXRrOcVZK1=S1Ur9c8YAOogQJtCiWCboXNzCg6zodPw@mail.gmail.com>
References: <CA+8X3fXPXRrOcVZK1=S1Ur9c8YAOogQJtCiWCboXNzCg6zodPw@mail.gmail.com>
Message-ID: <117195626.2417342.1430938772450.JavaMail.yahoo@mail.yahoo.com>

Dear Jim,

I really thank you lots, it perfectly works !
The reproducible example is below.

Last thing : I can easily get the predictions intervals but I don't get to draw them. 
If I want to draw on the same graph (the one I already have the confidence intervals) the prediction intervals. I have tried the abline function without success. How can I do ?

GDP.per.head=c(600,560,340,560,580,300,570,900,680,290,590,340) 
Quality.score=c(4.5,6.5,6,4.5,7,3,9,10,12.5,6.5,7,9) 
Competitivness.score=c(1000,1200,1400,700,680,1010,340,560,690,500,690,460) 
LinearModel.1=lm(GDP.per.head ~ Quality.score + Competitivness.score) 

plot(GDP.per.head, fitted(LinearModel.1),ylim=c(200,800)) 
devlm1<-lm(fitted(LinearModel.1)~GDP.per.head) 
abline(devlm1) 
conflm1<-confint(devlm1) 
abline(coef=conflm1[,1],lty=2) 
abline(coef=conflm1[,2],lty=2) 
predict(LinearModel.1, interval = "prediction") 

Many thanks once more for your help.
Sacha


----- Mail original -----
De : Jim Lemon <drjimlemon at gmail.com>
? : varin sacha <varinsacha at yahoo.fr>
Cc : R-help Mailing List <r-help at r-project.org>
Envoy? le : Mercredi 6 mai 2015 1h02
Objet : Re: [R] Drawing the regression line and the 95% confidence intervals

Hi Sacha,
The line you have requested is off the plot. The following will
produce what I think you are asking, but I cannot speak for whether it
means anything sensible.

plot(GDP.per.head, fitted(LinearModel.1),ylim=c(200,800))
devlm1<-lm(fitted(LinearModel.1)~GDP.per.head)
abline(devlm1)
conflm1<-confint(devlm1)
abline(coef=conflm1[,1],lty=2)
abline(coef=conflm1[,2],lty=2)

Jim



On Wed, May 6, 2015 at 8:01 AM, varin sacha <varinsacha at yahoo.fr> wrote:
> Hi, Dear R-helpers,
>
> Here below you will find a reproducible fictitious example working except the "abline" function.
>
> First thing : I try to draw the regression line (multiple linear regression). I try the "abline" function but it does not work. I don't get any error message but the straight line does not appear on the scatterplot.
>
> Second thing : I try to draw the 95% confidence intervals on the regression line. How could I do ?
>
> Using abline(0,1), I can of course add a line 45 degrees angle passing through the origin (intercept=0 and slope=1), but it is not what I am looking for.
>
> GDP.per.head=c(600,560,340,560,580,300,570,900,680,290,590,340)
> Quality.score=c(4.5,6.5,6,4.5,7,3,9,10,12.5,6.5,7,9)
> Competitivness.score=c(1000,1200,1400,700,680,1010,340,560,690,500,690,460)
> LinearModel.1=lm(GDP.per.head ~ Quality.score + Competitivness.score)
> plot(GDP.per.head, fitted(LinearModel.1))
> abline(GDP.per.head, fitted(LinearModel.1))
>
> Thanks for your help. Looking forward to reading you.
>
> Sacha
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cadeb at usgs.gov  Wed May  6 21:21:43 2015
From: cadeb at usgs.gov (Cade, Brian)
Date: Wed, 6 May 2015 13:21:43 -0600
Subject: [R] Drawing the regression line and the 95% confidence intervals
In-Reply-To: <117195626.2417342.1430938772450.JavaMail.yahoo@mail.yahoo.com>
References: <CA+8X3fXPXRrOcVZK1=S1Ur9c8YAOogQJtCiWCboXNzCg6zodPw@mail.gmail.com>
	<117195626.2417342.1430938772450.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAM5M9BRge7wg7VKrd35AVnTmwYf=wnLkZukjyOcYfWvm8bGLrQ@mail.gmail.com>

The prediction intervals are likely to be much wider than the confidence
intervals so you will need to be sure you scale the yaxis limits large
enough to see them.

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326


On Wed, May 6, 2015 at 12:59 PM, varin sacha <varinsacha at yahoo.fr> wrote:

> Dear Jim,
>
> I really thank you lots, it perfectly works !
> The reproducible example is below.
>
> Last thing : I can easily get the predictions intervals but I don't get to
> draw them.
> If I want to draw on the same graph (the one I already have the confidence
> intervals) the prediction intervals. I have tried the abline function
> without success. How can I do ?
>
> GDP.per.head=c(600,560,340,560,580,300,570,900,680,290,590,340)
> Quality.score=c(4.5,6.5,6,4.5,7,3,9,10,12.5,6.5,7,9)
> Competitivness.score=c(1000,1200,1400,700,680,1010,340,560,690,500,690,460)
> LinearModel.1=lm(GDP.per.head ~ Quality.score + Competitivness.score)
>
> plot(GDP.per.head, fitted(LinearModel.1),ylim=c(200,800))
> devlm1<-lm(fitted(LinearModel.1)~GDP.per.head)
> abline(devlm1)
> conflm1<-confint(devlm1)
> abline(coef=conflm1[,1],lty=2)
> abline(coef=conflm1[,2],lty=2)
> predict(LinearModel.1, interval = "prediction")
>
> Many thanks once more for your help.
> Sacha
>
>
> ----- Mail original -----
> De : Jim Lemon <drjimlemon at gmail.com>
> ? : varin sacha <varinsacha at yahoo.fr>
> Cc : R-help Mailing List <r-help at r-project.org>
> Envoy? le : Mercredi 6 mai 2015 1h02
> Objet : Re: [R] Drawing the regression line and the 95% confidence
> intervals
>
> Hi Sacha,
> The line you have requested is off the plot. The following will
> produce what I think you are asking, but I cannot speak for whether it
> means anything sensible.
>
> plot(GDP.per.head, fitted(LinearModel.1),ylim=c(200,800))
> devlm1<-lm(fitted(LinearModel.1)~GDP.per.head)
> abline(devlm1)
> conflm1<-confint(devlm1)
> abline(coef=conflm1[,1],lty=2)
> abline(coef=conflm1[,2],lty=2)
>
> Jim
>
>
>
> On Wed, May 6, 2015 at 8:01 AM, varin sacha <varinsacha at yahoo.fr> wrote:
> > Hi, Dear R-helpers,
> >
> > Here below you will find a reproducible fictitious example working
> except the "abline" function.
> >
> > First thing : I try to draw the regression line (multiple linear
> regression). I try the "abline" function but it does not work. I don't get
> any error message but the straight line does not appear on the scatterplot.
> >
> > Second thing : I try to draw the 95% confidence intervals on the
> regression line. How could I do ?
> >
> > Using abline(0,1), I can of course add a line 45 degrees angle passing
> through the origin (intercept=0 and slope=1), but it is not what I am
> looking for.
> >
> > GDP.per.head=c(600,560,340,560,580,300,570,900,680,290,590,340)
> > Quality.score=c(4.5,6.5,6,4.5,7,3,9,10,12.5,6.5,7,9)
> >
> Competitivness.score=c(1000,1200,1400,700,680,1010,340,560,690,500,690,460)
> > LinearModel.1=lm(GDP.per.head ~ Quality.score + Competitivness.score)
> > plot(GDP.per.head, fitted(LinearModel.1))
> > abline(GDP.per.head, fitted(LinearModel.1))
> >
> > Thanks for your help. Looking forward to reading you.
> >
> > Sacha
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed May  6 21:52:32 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 6 May 2015 19:52:32 +0000
Subject: [R] Drawing the regression line and the 95% confidence intervals
In-Reply-To: <CAM5M9BRge7wg7VKrd35AVnTmwYf=wnLkZukjyOcYfWvm8bGLrQ@mail.gmail.com>
References: <CA+8X3fXPXRrOcVZK1=S1Ur9c8YAOogQJtCiWCboXNzCg6zodPw@mail.gmail.com>
	<117195626.2417342.1430938772450.JavaMail.yahoo@mail.yahoo.com>
	<CAM5M9BRge7wg7VKrd35AVnTmwYf=wnLkZukjyOcYfWvm8bGLrQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68A5A8@mb02.ads.tamu.edu>

Something like this?

# Compute the prediction limits and get their range to set ylim=
plim <- predict(LinearModel.1, interval = "prediction")
rnge <- c(min(plim[ , 2]), max(plim[ , 3]))
plot(GDP.per.head, fitted(LinearModel.1),ylim=rnge) 

# As before
devlm1<-lm(fitted(LinearModel.1)~GDP.per.head) 
abline(devlm1) 
conflm1<-confint(devlm1) 
abline(coef=conflm1[,1],lty=2) 
abline(coef=conflm1[,2],lty=2) 

# Plot the prediction limits
segments(GDP.per.head, plim[ , 2], GDP.per.head, plim[ , 3], col="gray")

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Cade, Brian
Sent: Wednesday, May 6, 2015 2:22 PM
To: varin sacha
Cc: R-help Mailing List
Subject: Re: [R] Drawing the regression line and the 95% confidence intervals

The prediction intervals are likely to be much wider than the confidence
intervals so you will need to be sure you scale the yaxis limits large
enough to see them.

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326


On Wed, May 6, 2015 at 12:59 PM, varin sacha <varinsacha at yahoo.fr> wrote:

> Dear Jim,
>
> I really thank you lots, it perfectly works !
> The reproducible example is below.
>
> Last thing : I can easily get the predictions intervals but I don't get to
> draw them.
> If I want to draw on the same graph (the one I already have the confidence
> intervals) the prediction intervals. I have tried the abline function
> without success. How can I do ?
>
> GDP.per.head=c(600,560,340,560,580,300,570,900,680,290,590,340)
> Quality.score=c(4.5,6.5,6,4.5,7,3,9,10,12.5,6.5,7,9)
> Competitivness.score=c(1000,1200,1400,700,680,1010,340,560,690,500,690,460)
> LinearModel.1=lm(GDP.per.head ~ Quality.score + Competitivness.score)
>
> plot(GDP.per.head, fitted(LinearModel.1),ylim=c(200,800))
> devlm1<-lm(fitted(LinearModel.1)~GDP.per.head)
> abline(devlm1)
> conflm1<-confint(devlm1)
> abline(coef=conflm1[,1],lty=2)
> abline(coef=conflm1[,2],lty=2)
> predict(LinearModel.1, interval = "prediction")
>
> Many thanks once more for your help.
> Sacha
>
>
> ----- Mail original -----
> De : Jim Lemon <drjimlemon at gmail.com>
> ? : varin sacha <varinsacha at yahoo.fr>
> Cc : R-help Mailing List <r-help at r-project.org>
> Envoy? le : Mercredi 6 mai 2015 1h02
> Objet : Re: [R] Drawing the regression line and the 95% confidence
> intervals
>
> Hi Sacha,
> The line you have requested is off the plot. The following will
> produce what I think you are asking, but I cannot speak for whether it
> means anything sensible.
>
> plot(GDP.per.head, fitted(LinearModel.1),ylim=c(200,800))
> devlm1<-lm(fitted(LinearModel.1)~GDP.per.head)
> abline(devlm1)
> conflm1<-confint(devlm1)
> abline(coef=conflm1[,1],lty=2)
> abline(coef=conflm1[,2],lty=2)
>
> Jim
>
>
>
> On Wed, May 6, 2015 at 8:01 AM, varin sacha <varinsacha at yahoo.fr> wrote:
> > Hi, Dear R-helpers,
> >
> > Here below you will find a reproducible fictitious example working
> except the "abline" function.
> >
> > First thing : I try to draw the regression line (multiple linear
> regression). I try the "abline" function but it does not work. I don't get
> any error message but the straight line does not appear on the scatterplot.
> >
> > Second thing : I try to draw the 95% confidence intervals on the
> regression line. How could I do ?
> >
> > Using abline(0,1), I can of course add a line 45 degrees angle passing
> through the origin (intercept=0 and slope=1), but it is not what I am
> looking for.
> >
> > GDP.per.head=c(600,560,340,560,580,300,570,900,680,290,590,340)
> > Quality.score=c(4.5,6.5,6,4.5,7,3,9,10,12.5,6.5,7,9)
> >
> Competitivness.score=c(1000,1200,1400,700,680,1010,340,560,690,500,690,460)
> > LinearModel.1=lm(GDP.per.head ~ Quality.score + Competitivness.score)
> > plot(GDP.per.head, fitted(LinearModel.1))
> > abline(GDP.per.head, fitted(LinearModel.1))
> >
> > Thanks for your help. Looking forward to reading you.
> >
> > Sacha
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From murdoch.duncan at gmail.com  Wed May  6 23:04:18 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 06 May 2015 17:04:18 -0400
Subject: [R] order by which the eigenvalues are presented
In-Reply-To: <293DC84C-A5C5-4586-80FA-69199B7715E1@gmail.com>
References: <293DC84C-A5C5-4586-80FA-69199B7715E1@gmail.com>
Message-ID: <554A81D2.4090807@gmail.com>

On 06/05/2015 12:58 PM, Luis Borda de Agua wrote:
> Thank you, Bill, for your reply. However, I'm afraid I didn't explain myself properly.
> 
>  
> 
> Imagine you have a 2x2 matrix
> 
> Then the eigenvalues lambda_1 and lambda_2 are analytically calculated from
> 
>  
> 
> lambda_1 = (-b+sqrt(delta))/2a
> 
> lambda_2 = (-b-sqrt(delta))/2a
> 
>  
> 
> where delta = b^2-4ac
> 
>  
> 
> If delta>0 then lambda_1 > lambda_2 always. Otherwise their Real parts are equal.

The first condition is incomplete.  You need a>0 as well.

> 
>  
> 
> If we have a 3x3 matrix the three eigenvalues will have very complicated expressions:
> 
>  
> 
> lambda_1 = f_1
> 
> lambda_2 = f_2
> 
> lambda_3 = f_3
> 
>  
> 
> where f_1,f_2 and f_3 are functions of the elements of the matrix a11,a12...,a33, which are sampled from a given distribution (e.g. normal(0,1)).
> 
>  
> 
> What I would like to know is from which expression (f_1,f_2 or f_3) comes the largest Re part of the eigenvalues. For example, does it always come from f_1 independently of the sampled values of a11,a12...,a33?

I don't know the answer, but I would expect it to depend on the entries
in the matrix in quite a complicated way.

Duncan Murdoch


From varinsacha at yahoo.fr  Wed May  6 23:38:46 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Wed, 6 May 2015 21:38:46 +0000 (UTC)
Subject: [R] Drawing the regression line and the 95% confidence intervals
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68A5A8@mb02.ads.tamu.edu>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68A5A8@mb02.ads.tamu.edu>
Message-ID: <1213459100.2571997.1430948326094.JavaMail.yahoo@mail.yahoo.com>

Brian, thanks for the precisions.
David, many thanks for your code that perfectly works.?
Best,
Sacha
      De?: David L Carlson <dcarlson at tamu.edu>
 ??: "Cade, Brian" <cadeb at usgs.gov>; varin sacha <varinsacha at yahoo.fr> 
Cc?: R-help Mailing List <r-help at r-project.org> 
 Envoy? le : Mercredi 6 mai 2015 21h52
 Objet?: RE: [R] Drawing the regression line and the 95% confidence intervals
   
Something like this?

# Compute the prediction limits and get their range to set ylim=
plim <- predict(LinearModel.1, interval = "prediction")
rnge <- c(min(plim[ , 2]), max(plim[ , 3]))
plot(GDP.per.head, fitted(LinearModel.1),ylim=rnge) 

# As before
devlm1<-lm(fitted(LinearModel.1)~GDP.per.head) 
abline(devlm1) 
conflm1<-confint(devlm1) 
abline(coef=conflm1[,1],lty=2) 
abline(coef=conflm1[,2],lty=2) 

# Plot the prediction limits
segments(GDP.per.head, plim[ , 2], GDP.per.head, plim[ , 3], col="gray")

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Cade, Brian
Sent: Wednesday, May 6, 2015 2:22 PM
To: varin sacha
Cc: R-help Mailing List
Subject: Re: [R] Drawing the regression line and the 95% confidence intervals

The prediction intervals are likely to be much wider than the confidence
intervals so you will need to be sure you scale the yaxis limits large
enough to see them.

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO? 80526-8818

email:? cadeb at usgs.gov <brian_cade at usgs.gov>
tel:? 970 226-9326




> Dear Jim,
>
[[elided Yahoo spam]]
> The reproducible example is below.
>
> Last thing : I can easily get the predictions intervals but I don't get to
> draw them.
> If I want to draw on the same graph (the one I already have the confidence
> intervals) the prediction intervals. I have tried the abline function
> without success. How can I do ?
>
> GDP.per.head=c(600,560,340,560,580,300,570,900,680,290,590,340)
> Quality.score=c(4.5,6.5,6,4.5,7,3,9,10,12.5,6.5,7,9)
> Competitivness.score=c(1000,1200,1400,700,680,1010,340,560,690,500,690,460)
> LinearModel.1=lm(GDP.per.head ~ Quality.score + Competitivness.score)
>
> plot(GDP.per.head, fitted(LinearModel.1),ylim=c(200,800))
> devlm1<-lm(fitted(LinearModel.1)~GDP.per.head)
> abline(devlm1)
> conflm1<-confint(devlm1)
> abline(coef=conflm1[,1],lty=2)
> abline(coef=conflm1[,2],lty=2)
> predict(LinearModel.1, interval = "prediction")
>
> Many thanks once more for your help.
> Sacha
>
>
> ----- Mail original -----
> De : Jim Lemon <drjimlemon at gmail.com>

> Cc : R-help Mailing List <r-help at r-project.org>
> Envoy? le : Mercredi 6 mai 2015 1h02
> Objet : Re: [R] Drawing the regression line and the 95% confidence
> intervals
>
> Hi Sacha,
> The line you have requested is off the plot. The following will
> produce what I think you are asking, but I cannot speak for whether it
> means anything sensible.
>
> plot(GDP.per.head, fitted(LinearModel.1),ylim=c(200,800))
> devlm1<-lm(fitted(LinearModel.1)~GDP.per.head)
> abline(devlm1)
> conflm1<-confint(devlm1)
> abline(coef=conflm1[,1],lty=2)
> abline(coef=conflm1[,2],lty=2)
>
> Jim
>
>
>

> > Hi, Dear R-helpers,
> >
> > Here below you will find a reproducible fictitious example working
> except the "abline" function.
> >
> > First thing : I try to draw the regression line (multiple linear
> regression). I try the "abline" function but it does not work. I don't get
> any error message but the straight line does not appear on the scatterplot.
> >
> > Second thing : I try to draw the 95% confidence intervals on the
> regression line. How could I do ?
> >
> > Using abline(0,1), I can of course add a line 45 degrees angle passing
> through the origin (intercept=0 and slope=1), but it is not what I am
> looking for.
> >
> > GDP.per.head=c(600,560,340,560,580,300,570,900,680,290,590,340)
> > Quality.score=c(4.5,6.5,6,4.5,7,3,9,10,12.5,6.5,7,9)
> >
> Competitivness.score=c(1000,1200,1400,700,680,1010,340,560,690,500,690,460)
> > LinearModel.1=lm(GDP.per.head ~ Quality.score + Competitivness.score)
> > plot(GDP.per.head, fitted(LinearModel.1))
> > abline(GDP.per.head, fitted(LinearModel.1))
> >
> > Thanks for your help. Looking forward to reading you.
> >
> > Sacha
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

??? [[alternative HTML version deleted]]



______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu May  7 00:01:51 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 7 May 2015 08:01:51 +1000
Subject: [R] Drawing the regression line and the 95% confidence intervals
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68A5A8@mb02.ads.tamu.edu>
References: <CA+8X3fXPXRrOcVZK1=S1Ur9c8YAOogQJtCiWCboXNzCg6zodPw@mail.gmail.com>
	<117195626.2417342.1430938772450.JavaMail.yahoo@mail.yahoo.com>
	<CAM5M9BRge7wg7VKrd35AVnTmwYf=wnLkZukjyOcYfWvm8bGLrQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D68A5A8@mb02.ads.tamu.edu>
Message-ID: <CA+8X3fW+zBEBhE+Rh1SM4XR50zB+CrB4CRdSLYyGsDD8r1aMUw@mail.gmail.com>

Hi Sacha,
As Brian noted, you will have to expand the vertical axis. Here is one
way to do it.

plot(GDP.per.head, fitted(LinearModel.1),ylim=c(-60,1200))
devlm1<-lm(fitted(LinearModel.1)~GDP.per.head)
abline(devlm1)
conflm1<-confint(devlm1)
abline(coef=conflm1[,1],lty=2)
abline(coef=conflm1[,2],lty=2)
predict(LinearModel.1, interval = "prediction")
library(plotrix)
predmat<-predict(LinearModel.1, interval = "prediction")
dispersion(GDP.per.head,fitted(LinearModel.1),
 predmat[,3],predmat[,2],interval=FALSE)

You may want to do something about the overlapping points.

Jim


On Thu, May 7, 2015 at 5:52 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> Something like this?
>
> # Compute the prediction limits and get their range to set ylim=
> plim <- predict(LinearModel.1, interval = "prediction")
> rnge <- c(min(plim[ , 2]), max(plim[ , 3]))
> plot(GDP.per.head, fitted(LinearModel.1),ylim=rnge)
>
> # As before
> devlm1<-lm(fitted(LinearModel.1)~GDP.per.head)
> abline(devlm1)
> conflm1<-confint(devlm1)
> abline(coef=conflm1[,1],lty=2)
> abline(coef=conflm1[,2],lty=2)
>
> # Plot the prediction limits
> segments(GDP.per.head, plim[ , 2], GDP.per.head, plim[ , 3], col="gray")
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Cade, Brian
> Sent: Wednesday, May 6, 2015 2:22 PM
> To: varin sacha
> Cc: R-help Mailing List
> Subject: Re: [R] Drawing the regression line and the 95% confidence intervals
>
> The prediction intervals are likely to be much wider than the confidence
> intervals so you will need to be sure you scale the yaxis limits large
> enough to see them.
>
> Brian
>
> Brian S. Cade, PhD
>
> U. S. Geological Survey
> Fort Collins Science Center
> 2150 Centre Ave., Bldg. C
> Fort Collins, CO  80526-8818
>
> email:  cadeb at usgs.gov <brian_cade at usgs.gov>
> tel:  970 226-9326
>
>
> On Wed, May 6, 2015 at 12:59 PM, varin sacha <varinsacha at yahoo.fr> wrote:
>
>> Dear Jim,
>>
>> I really thank you lots, it perfectly works !
>> The reproducible example is below.
>>
>> Last thing : I can easily get the predictions intervals but I don't get to
>> draw them.
>> If I want to draw on the same graph (the one I already have the confidence
>> intervals) the prediction intervals. I have tried the abline function
>> without success. How can I do ?
>>
>> GDP.per.head=c(600,560,340,560,580,300,570,900,680,290,590,340)
>> Quality.score=c(4.5,6.5,6,4.5,7,3,9,10,12.5,6.5,7,9)
>> Competitivness.score=c(1000,1200,1400,700,680,1010,340,560,690,500,690,460)
>> LinearModel.1=lm(GDP.per.head ~ Quality.score + Competitivness.score)
>>
>> plot(GDP.per.head, fitted(LinearModel.1),ylim=c(200,800))
>> devlm1<-lm(fitted(LinearModel.1)~GDP.per.head)
>> abline(devlm1)
>> conflm1<-confint(devlm1)
>> abline(coef=conflm1[,1],lty=2)
>> abline(coef=conflm1[,2],lty=2)
>> predict(LinearModel.1, interval = "prediction")
>>
>> Many thanks once more for your help.
>> Sacha
>>
>>
>> ----- Mail original -----
>> De : Jim Lemon <drjimlemon at gmail.com>
>> ? : varin sacha <varinsacha at yahoo.fr>
>> Cc : R-help Mailing List <r-help at r-project.org>
>> Envoy? le : Mercredi 6 mai 2015 1h02
>> Objet : Re: [R] Drawing the regression line and the 95% confidence
>> intervals
>>
>> Hi Sacha,
>> The line you have requested is off the plot. The following will
>> produce what I think you are asking, but I cannot speak for whether it
>> means anything sensible.
>>
>> plot(GDP.per.head, fitted(LinearModel.1),ylim=c(200,800))
>> devlm1<-lm(fitted(LinearModel.1)~GDP.per.head)
>> abline(devlm1)
>> conflm1<-confint(devlm1)
>> abline(coef=conflm1[,1],lty=2)
>> abline(coef=conflm1[,2],lty=2)
>>
>> Jim
>>
>>
>>
>> On Wed, May 6, 2015 at 8:01 AM, varin sacha <varinsacha at yahoo.fr> wrote:
>> > Hi, Dear R-helpers,
>> >
>> > Here below you will find a reproducible fictitious example working
>> except the "abline" function.
>> >
>> > First thing : I try to draw the regression line (multiple linear
>> regression). I try the "abline" function but it does not work. I don't get
>> any error message but the straight line does not appear on the scatterplot.
>> >
>> > Second thing : I try to draw the 95% confidence intervals on the
>> regression line. How could I do ?
>> >
>> > Using abline(0,1), I can of course add a line 45 degrees angle passing
>> through the origin (intercept=0 and slope=1), but it is not what I am
>> looking for.
>> >
>> > GDP.per.head=c(600,560,340,560,580,300,570,900,680,290,590,340)
>> > Quality.score=c(4.5,6.5,6,4.5,7,3,9,10,12.5,6.5,7,9)
>> >
>> Competitivness.score=c(1000,1200,1400,700,680,1010,340,560,690,500,690,460)
>> > LinearModel.1=lm(GDP.per.head ~ Quality.score + Competitivness.score)
>> > plot(GDP.per.head, fitted(LinearModel.1))
>> > abline(GDP.per.head, fitted(LinearModel.1))
>> >
>> > Thanks for your help. Looking forward to reading you.
>> >
>> > Sacha
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From varinsacha at yahoo.fr  Thu May  7 01:09:41 2015
From: varinsacha at yahoo.fr (varinsacha at yahoo.fr)
Date: Thu, 7 May 2015 01:09:41 +0200
Subject: [R] Drawing the regression line and the 95% confidence intervals
In-Reply-To: <CA+8X3fW+zBEBhE+Rh1SM4XR50zB+CrB4CRdSLYyGsDD8r1aMUw@mail.gmail.com>
References: <CA+8X3fXPXRrOcVZK1=S1Ur9c8YAOogQJtCiWCboXNzCg6zodPw@mail.gmail.com>
	<117195626.2417342.1430938772450.JavaMail.yahoo@mail.yahoo.com>
	<CAM5M9BRge7wg7VKrd35AVnTmwYf=wnLkZukjyOcYfWvm8bGLrQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D68A5A8@mb02.ads.tamu.edu>
	<CA+8X3fW+zBEBhE+Rh1SM4XR50zB+CrB4CRdSLYyGsDD8r1aMUw@mail.gmail.com>
Message-ID: <53476B17-99FE-44DF-A789-AD4F4869E155@yahoo.fr>

Jim,
Perfect
Many thanks once more for your support...
Best regards 
SV

Envoy? de mon iPhone

Le 7 mai 2015 ? 00:01, Jim Lemon <drjimlemon at gmail.com> a ?crit :

> Hi Sacha,
> As Brian noted, you will have to expand the vertical axis. Here is one
> way to do it.
> 
> plot(GDP.per.head, fitted(LinearModel.1),ylim=c(-60,1200))
> devlm1<-lm(fitted(LinearModel.1)~GDP.per.head)
> abline(devlm1)
> conflm1<-confint(devlm1)
> abline(coef=conflm1[,1],lty=2)
> abline(coef=conflm1[,2],lty=2)
> predict(LinearModel.1, interval = "prediction")
> library(plotrix)
> predmat<-predict(LinearModel.1, interval = "prediction")
> dispersion(GDP.per.head,fitted(LinearModel.1),
> predmat[,3],predmat[,2],interval=FALSE)
> 
> You may want to do something about the overlapping points.
> 
> Jim
> 
> 
> On Thu, May 7, 2015 at 5:52 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>> Something like this?
>> 
>> # Compute the prediction limits and get their range to set ylim=
>> plim <- predict(LinearModel.1, interval = "prediction")
>> rnge <- c(min(plim[ , 2]), max(plim[ , 3]))
>> plot(GDP.per.head, fitted(LinearModel.1),ylim=rnge)
>> 
>> # As before
>> devlm1<-lm(fitted(LinearModel.1)~GDP.per.head)
>> abline(devlm1)
>> conflm1<-confint(devlm1)
>> abline(coef=conflm1[,1],lty=2)
>> abline(coef=conflm1[,2],lty=2)
>> 
>> # Plot the prediction limits
>> segments(GDP.per.head, plim[ , 2], GDP.per.head, plim[ , 3], col="gray")
>> 
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>> 
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Cade, Brian
>> Sent: Wednesday, May 6, 2015 2:22 PM
>> To: varin sacha
>> Cc: R-help Mailing List
>> Subject: Re: [R] Drawing the regression line and the 95% confidence intervals
>> 
>> The prediction intervals are likely to be much wider than the confidence
>> intervals so you will need to be sure you scale the yaxis limits large
>> enough to see them.
>> 
>> Brian
>> 
>> Brian S. Cade, PhD
>> 
>> U. S. Geological Survey
>> Fort Collins Science Center
>> 2150 Centre Ave., Bldg. C
>> Fort Collins, CO  80526-8818
>> 
>> email:  cadeb at usgs.gov <brian_cade at usgs.gov>
>> tel:  970 226-9326
>> 
>> 
>> On Wed, May 6, 2015 at 12:59 PM, varin sacha <varinsacha at yahoo.fr> wrote:
>> 
>>> Dear Jim,
>>> 
>>> I really thank you lots, it perfectly works !
>>> The reproducible example is below.
>>> 
>>> Last thing : I can easily get the predictions intervals but I don't get to
>>> draw them.
>>> If I want to draw on the same graph (the one I already have the confidence
>>> intervals) the prediction intervals. I have tried the abline function
>>> without success. How can I do ?
>>> 
>>> GDP.per.head=c(600,560,340,560,580,300,570,900,680,290,590,340)
>>> Quality.score=c(4.5,6.5,6,4.5,7,3,9,10,12.5,6.5,7,9)
>>> Competitivness.score=c(1000,1200,1400,700,680,1010,340,560,690,500,690,460)
>>> LinearModel.1=lm(GDP.per.head ~ Quality.score + Competitivness.score)
>>> 
>>> plot(GDP.per.head, fitted(LinearModel.1),ylim=c(200,800))
>>> devlm1<-lm(fitted(LinearModel.1)~GDP.per.head)
>>> abline(devlm1)
>>> conflm1<-confint(devlm1)
>>> abline(coef=conflm1[,1],lty=2)
>>> abline(coef=conflm1[,2],lty=2)
>>> predict(LinearModel.1, interval = "prediction")
>>> 
>>> Many thanks once more for your help.
>>> Sacha
>>> 
>>> 
>>> ----- Mail original -----
>>> De : Jim Lemon <drjimlemon at gmail.com>
>>> ? : varin sacha <varinsacha at yahoo.fr>
>>> Cc : R-help Mailing List <r-help at r-project.org>
>>> Envoy? le : Mercredi 6 mai 2015 1h02
>>> Objet : Re: [R] Drawing the regression line and the 95% confidence
>>> intervals
>>> 
>>> Hi Sacha,
>>> The line you have requested is off the plot. The following will
>>> produce what I think you are asking, but I cannot speak for whether it
>>> means anything sensible.
>>> 
>>> plot(GDP.per.head, fitted(LinearModel.1),ylim=c(200,800))
>>> devlm1<-lm(fitted(LinearModel.1)~GDP.per.head)
>>> abline(devlm1)
>>> conflm1<-confint(devlm1)
>>> abline(coef=conflm1[,1],lty=2)
>>> abline(coef=conflm1[,2],lty=2)
>>> 
>>> Jim
>>> 
>>> 
>>> 
>>> On Wed, May 6, 2015 at 8:01 AM, varin sacha <varinsacha at yahoo.fr> wrote:
>>>> Hi, Dear R-helpers,
>>>> 
>>>> Here below you will find a reproducible fictitious example working
>>> except the "abline" function.
>>>> 
>>>> First thing : I try to draw the regression line (multiple linear
>>> regression). I try the "abline" function but it does not work. I don't get
>>> any error message but the straight line does not appear on the scatterplot.
>>>> 
>>>> Second thing : I try to draw the 95% confidence intervals on the
>>> regression line. How could I do ?
>>>> 
>>>> Using abline(0,1), I can of course add a line 45 degrees angle passing
>>> through the origin (intercept=0 and slope=1), but it is not what I am
>>> looking for.
>>>> 
>>>> GDP.per.head=c(600,560,340,560,580,300,570,900,680,290,590,340)
>>>> Quality.score=c(4.5,6.5,6,4.5,7,3,9,10,12.5,6.5,7,9)
>>> Competitivness.score=c(1000,1200,1400,700,680,1010,340,560,690,500,690,460)
>>>> LinearModel.1=lm(GDP.per.head ~ Quality.score + Competitivness.score)
>>>> plot(GDP.per.head, fitted(LinearModel.1))
>>>> abline(GDP.per.head, fitted(LinearModel.1))
>>>> 
>>>> Thanks for your help. Looking forward to reading you.
>>>> 
>>>> Sacha
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Thu May  7 02:48:35 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 7 May 2015 10:48:35 +1000
Subject: [R] lm model exported from R to excel
In-Reply-To: <5E619901A9E.000014A2jrkrideau@inbox.com>
References: <001b01d087f7$e471a7b0$ad54f710$@bigpond.com>
	<2dfedd9d3576fb419c7bf7511e983c964ae42ff1@adm-exmbx10d.adm.c.sdu.dk>
	<2dfedd9d3576fb419c7bf7511e983c964ae42fc3@adm-exmbx10d.adm.c.sdu.dk>
	<5E619901A9E.000014A2jrkrideau@inbox.com>
Message-ID: <000c01d0885f$8d691850$a83b48f0$@bigpond.com>

At the expense of extra bandwidth. I also like latex + booktabs; hate word

I format the table header and footer in latex with extra vertical space
between lines and type; output looks more like latex than being cramped from
xtable. 
Thanks anyway to xtable creators -- would be lost without it

Duncan

-----Original Message-----
From: John Kane [mailto:jrkrideau at inbox.com] 
Sent: Thursday, 7 May 2015 01:34
To: Duncan Mackay; R
Subject: Re: [R] lm model exported from R to excel

And for those of us who know close to nothing about HTML I found just now
that under a basic print.xtable commmand we get those horrible HMTL borders
that in Apache OpenOffice seemed impossible to remove safely.  No idea about
Word--I have not used it in years.

I did find that adding  html.table.attributes = "border = 0" gets rid of the
borders.  So 
So something like 

print.xtable(modtable, type = "html", html.table.attributes = "border = 0",
file = "modtable .html") 
seems to give a reasonable  result in AOO.  At least I managed to do some
half-decent formatting with it.

Meanwhile, back to LaTeX where the output looks beautiful. I like booktabs
:)

John Kane
Kingston ON Canada


> -----Original Message-----
> From: dulcalma at bigpond.com
> Sent: Thu, 7 May 2015 00:32:48 +1000
> To: r-help at r-project.org
> Subject: Re: [R] lm model exported from R to excel
> 
> If you know some basic html language you can jazz up the table headings
> to
> your liking by writing that before the xtable statement.
> It save having to muck around in Microsoft to fix it.
> If you are going to do a lot of it - a little study of html basics can go
> far.
> 
> I was changing the headings to what I wanted using html (although not all
> the tables were lm summaries) before the major upgrade a year or so ago
> Now things are better.
> 
> Even a title and comments in html for yourself if not available in xtable
> are helpful. I have not used xtable and html since the upgrade as I use
> latex
> 
> Duncan
> 
> -----Original Message-----
> From: Livia Maria Vestergaard [mailto:lvest09 at student.sdu.dk]
> Sent: Wednesday, 6 May 2015 22:37
> To: Duncan Mackay; R
> Subject: SV: [R] lm model exported from R to excel
> 
> Hi Duncan
> Thank you so much - it worked :)
> 
> Best
> 
> Livia
> ________________________________________
> Fra: Duncan Mackay [dulcalma at bigpond.com]
> Sendt: 6. maj 2015 14:26
> Til: R; Livia Maria Vestergaard
> Emne: RE: [R]  lm model exported from R to excel
> 
> Hi Livia
> 
> There are several html packages that ?could also do it
> 
> Heres a way with xtable
> 
> library(xtable)
> y = rnorm(100)
> x= rnorm(100)+rnorm(100)
> mod <- lm(y ~x)
> 
> # latex example easy view
> xtable(mod)
> 
> # html
> file.create("lm.htm")
> ff <- file("lm.htm", "a+")
> fchars <-  print(xtable(mod),type = "html")
> writeLines(paste(fchars, sep = ""), ff)
> close(ff)
> 
> You can then bring this into Microsoft as an html file
> 
> You may need to fill in some of the arguments in xtable to get the right
> border format etc
> 
> If you are doing many you can make a function to do things
> 
> Duncan
> 
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Livia
> Maria
> Vestergaard
> Sent: Wednesday, 6 May 2015 19:37
> To: r-help
> Subject: [R] lm model exported from R to excel
> 
> Hi all
> I all. I am wondering whether anybody know how to export an output of an
> lm
> model from R to excel in order to have excel recognize the table that
> comes
> and divide the numbers in the table into columns and rows?
> I really hope it is possible? :)
> 
> Best Livia
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From btyner at gmail.com  Thu May  7 04:00:58 2015
From: btyner at gmail.com (Benjamin Tyner)
Date: Wed, 06 May 2015 22:00:58 -0400
Subject: [R] package implementing continuous binomial?
Message-ID: <554AC75A.8070708@gmail.com>

Hi

I'm wondering if anyone is aware of an R package implementing (i.e.,
providing a pdf, cdf, and/or quantile function) for the continuous
binomial distribution? Specifically the one characterized here:

http://www2.math.uni-paderborn.de/fileadmin/Mathematik/AG-Indlekofer/Workshop/Satellite_meeting/ilenko.pdf

Figured I would check here first, before attempting to code it up myself.

Regards
Ben


From santosh2005 at gmail.com  Thu May  7 05:04:21 2015
From: santosh2005 at gmail.com (Santosh)
Date: Wed, 6 May 2015 20:04:21 -0700
Subject: [R] Convert csv to xpt file in R?
Message-ID: <CAN_e6XuoVbqZOFMjGCPG8ZqbD53ZwuLB0e0ZzwGMbUSDq_JtnA@mail.gmail.com>

Dear Rxperts..

Was wondering if there is a way in R to read a csv file and generate an XPT
file?  For some reason the function write.xport() does not seem to work for
me....
i get the following error...
"error in label.data.frame(df,default=""): length of default same as x

A sample dataframe is given below
xg2 <- data.frame(aa=runif(10),bb=sample(runif(100),10))
SASformat(xg2$aa) <- 'Numeric2'
SASformat(xg2$bb) <- 'Numeric2'
label(xg2$aa) <- "test aa"
label(xg2$bb) <- "test bb"
label(xg2) <- "testa"
SAStype(xg2) <- "TestXge"
write.xport(xg2,file="A1.xpt")
Error in label.data.frame(df, default = "") :
  length of default must same as x


Any suggestions/tips are welcome..

Thanks and regards
Santosh

	[[alternative HTML version deleted]]


From s.marin.g5 at gmail.com  Wed May  6 23:27:08 2015
From: s.marin.g5 at gmail.com (Sonia Marin)
Date: Wed, 6 May 2015 16:57:08 -0430
Subject: [R] Not able to submit work assignment4 with submitscript3.R
Message-ID: <CADQ=eETs-F2=3VF+4RKLGXE3d5hk6bBCWncmFJproon6s0HdVg@mail.gmail.com>

Hi, I tried to submit the work assignment4 with submitscript3.R and i got
an error message:
 Error in assign(".CourseraLogin", r, globalenv()) :
  unused arguments (r, globalenv())
I tryied to do it manually, but the files that I got to upload was empty.
Please, let me know, how can i do to send the work assignment4.

Thanks, for your attention.
Best regard
Sonia Marin
rprog-013
TNWpNjGERh

	[[alternative HTML version deleted]]


From james at crosb.ie  Wed May  6 23:55:17 2015
From: james at crosb.ie (jcrosbie)
Date: Wed, 6 May 2015 14:55:17 -0700 (PDT)
Subject: [R] How to finding a given length of runs in a series of data?
Message-ID: <1430949317963-4706915.post@n4.nabble.com>

I'm trying to study times in which flow was operating at a given level or
greater. To do so I have created a way to see how long the series has
operated at a high level. But for some reason the data is calculating the
runs one hour to long. Any ideas on why? 





Code:
Date<-format(seq(as.POSIXct("2014-01-01 01:00"), as.POSIXct("2015-01-01
00:00"),     by="hour"), "%Y-%m-%d %H:%M", usetz = FALSE)
Flow<-runif(8760, 0, 2300)

IsHigh<- function(x ){
    if (x < 1600) return(0) 
    if (1600 <= x) return(1) 
}

isHighFlow = unlist(lapply(Flow, IsHigh))

df = data.frame(Date, Flow, isHighFlow )


temp <- df %>%
  mutate(highFlowInterval = cumsum(isHighFlow==0)) %>%
  group_by(highFlowInterval) %>%
  summarise(hoursHighFlow = n(), minDate = min(as.character(Date)), maxDate
= max(as.character(Date))) 

#Then join the two tables together. 
temp2<-sqldf("SELECT * 
  FROM temp LEFT JOIN df 
  ON df.Date BETWEEN temp.minDate AND temp.maxDate")



--
View this message in context: http://r.789695.n4.nabble.com/How-to-finding-a-given-length-of-runs-in-a-series-of-data-tp4706915.html
Sent from the R help mailing list archive at Nabble.com.


From jean.d.marchal at gmail.com  Thu May  7 02:43:32 2015
From: jean.d.marchal at gmail.com (Jean Marchal)
Date: Wed, 6 May 2015 17:43:32 -0700
Subject: [R] nlminb supplying NaN parameters to objective function
Message-ID: <CACF6B3WqQ4uhPS-_Yk60G8wSPQ80=-PsWa2OQY4HgbyNkJuuww@mail.gmail.com>

Dear list,

I am doing some maximum likelihood estimation using nlminb() with
box-constraints to ensure that all parameters are positive. However,
nlminb() is behaving strangely and seems to supply NaN as parameters
to my objective function (confirmed using browser()) and output the
following:

$par
 [1] NaN NaN NaN   0 NaN   0 NaN NaN NaN NaN NaN NaN NaN

$objective
[1] 0

$convergence
[1] 1

$iterations
[1] 19

$evaluations
function gradient
      87      542

$message
[1] "gr cannot be computed at initial par (65)"


When I use trace = TRUE, I can see the following:

  0:     32495.488: 0.0917404 0.703453  1.89661 1.11022e-16
1.11022e-16 0.107479 1.11022e-16 1.11022e-16 1.11022e-16 0.472377
0.894128  1.86743 1.11022e-16
  1:     4035.3900: 0.0917404 0.703453  1.89661 1.11022e-16
1.11022e-16 0.107479 1.11022e-16 1.11022e-16 1.11022e-16 0.472377
0.894128  1.86743 0.250000
  2:     3955.8801: 0.0948452 0.704168  1.89651 0.000135456 0.0310485
0.107991 0.00138902 0.000427631 1.11022e-16 0.472331 0.894128  1.86743
0.250000
  3:     3951.4141: 0.0948926 0.703906  1.89640 2.99167e-05 0.0315288
0.109692 0.00242572 0.00272185 7.96814e-05 0.472780 0.894130  1.86744
0.249998
....
 17:     3937.3923: 0.0947470 0.703030  1.89605 1.11022e-16 0.0300763
0.115081 0.00562496 0.00989997 0.000323268 0.474247 0.894142  1.86745
0.249737
 18:     3937.3923: 0.0947470 0.703030  1.89605 1.11022e-16 0.0300763
0.115081 0.00562496 0.00989997 0.000323268 0.474247 0.894142  1.86745
0.249737
 19:    -0.0000000:     -nan     -nan     -nan 1.11022e-16     -nan
 -nan     -nan     -nan     -nan     -nan     -nan     -nan      nan


my objective function looks like:

nLL <- function(params){

  mu <- drop(model.matrix(modelTermsObj) %*% params)

  if(any(mu < 0) || anyNA(mu) || any(is.infinite(mu))){
    return(.Machine$double.xmax)
  } else {
    return(-sum(dnbinom(x=args$data[,response], mu = mu, size =
params[length(params)], log = TRUE)))
  }
}

I tried different starting values, different bounds but without
success so far. Is this a bug?

PS after trying to make a reproducible example that I gracefully
failed to do... I change my objective function so instead of using
model.matrix(), I did the maths (e.g. Y ~ A + B * C). Thus, mu is now
a bunch of NaN, and my objective function return .Machine$double.xmax
which is fine. Then nlminb stops and returns (like if nothing
happened):

$par
 [1] 1.11022e-16 1.11022e-16 2.69205e-04 1.11022e-16 1.68161e-03
1.06027e-03 1.16969e-05 1.11022e-16 8.51669e+01 7.31162e+01
5.04748e+00 5.28373e+00 1.23992e-01

$objective
[1] 3823.567

$convergence
[1] 0

$iterations
[1] 1

$evaluations
function gradient
       2       13

$message
[1] "X-convergence (3)"

I can provide the data and model if necessary but cannot make them
publicly available (yet).

Thank you,

Jean


From kehld at ktk.pte.hu  Thu May  7 08:06:37 2015
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?Kehl_D=E1niel?=)
Date: Thu, 7 May 2015 06:06:37 +0000
Subject: [R] Not able to submit work assignment4 with submitscript3.R
In-Reply-To: <CADQ=eETs-F2=3VF+4RKLGXE3d5hk6bBCWncmFJproon6s0HdVg@mail.gmail.com>
References: <CADQ=eETs-F2=3VF+4RKLGXE3d5hk6bBCWncmFJproon6s0HdVg@mail.gmail.com>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D1441DAAC@EMAIL.ktkdom.pte.hu>

Hi there,
this is not a Coursera Forum. Please ask your question there or search the Forums, these are quite regular problems there.

PS: do you really have a user name and a password in your e-mail?
________________________________________
Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Sonia Marin [s.marin.g5 at gmail.com]
K?ldve: 2015. m?jus 6. 23:27
To: r-help at r-project.org
T?rgy: [R] Not able to submit work assignment4 with submitscript3.R

Hi, I tried to submit the work assignment4 with submitscript3.R and i got
an error message:
 Error in assign(".CourseraLogin", r, globalenv()) :
  unused arguments (r, globalenv())
I tryied to do it manually, but the files that I got to upload was empty.
Please, let me know, how can i do to send the work assignment4.

Thanks, for your attention.
Best regard
Sonia Marin
rprog-013
TNWpNjGERh

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From luysgarcia at gmail.com  Thu May  7 08:51:46 2015
From: luysgarcia at gmail.com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Thu, 7 May 2015 03:51:46 -0300
Subject: [R] Sort data and symbol change in Jitter plot (ggplot2)
In-Reply-To: <CANxP2S52MVNNp_GB2=E4q14S24vk9rm1jMyg_-N2hcXWENohNQ@mail.gmail.com>
References: <CANxP2S52MVNNp_GB2=E4q14S24vk9rm1jMyg_-N2hcXWENohNQ@mail.gmail.com>
Message-ID: <CANxP2S6jgfosksorOOEJ_poGSnZX6zWPBnQWMQdxrojo5bYvsg@mail.gmail.com>

Thanks all of you guys!

Your answers were very useful!

Thanks for the answer John, but I will try to keep the dotplot, but it is
very useful to know both techniques anyway :)

Petr, many thanks for your help, it was just what I needed, btw, the
arrangment based on the median was a headache for me! again, thanks!!!

2015-05-05 4:34 GMT-03:00 Luis Fernando Garc?a <luysgarcia at gmail.com>:

> Dear R experts,
>
> First than all I want to thank your expertise and for sharing your
> knowledge with the people who are starting.
>
> Recently I have been working on a new plot style (Jitterplot) but have
> still some issues when making two basic functions.
>
> First than all I want to change the symbol according to the prey type
> (presa) and not the color, I tried making, geom_dotplot(aes(fill = PRESA)
> but it did not work
>
> On a second hand I want to sort the plots from the highest to the lowest
> value, I tried by using reorder, but it did not work.
>
> Please find attached the dataset and the script.
>
> Thanks in advance!
>
> ####script######
>
> the dataset is attached
> library(ggplot2)
> p=read.table("paratropis.txt",header=T)
> attach(p)
> ggplot( data = p, aes(y = Tiempo, x = PRESA, reorder(PRESA, Tiempo,
> mean))) + # Move y and x here so than they can be used in stat_*
>   geom_dotplot(aes(shape = PRESA),
>                binaxis = "y",         # which axis to bin along
>                binwidth = 0.1,        # Minimal difference considered
> diffeerent
>                stackdir = "center"    # Centered
>   ) +
>   stat_summary(fun.y = mean, fun.ymin = mean, fun.ymax = mean,
>                geom = "crossbar", width = 0.5)
>
>
>

	[[alternative HTML version deleted]]


From luysgarcia at gmail.com  Thu May  7 08:59:20 2015
From: luysgarcia at gmail.com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Thu, 7 May 2015 03:59:20 -0300
Subject: [R] Question about cochran test in R
Message-ID: <CANxP2S6EE+x+TqdWR8ULOB+i4w8=SaDiYPtwg=tp0eSPES8S5A@mail.gmail.com>

Dear R Experts,

May be this is a basic question for you, but it is something I need really
urgently. I need to perform a Chi Square analysis for more than two groups
of paired observations. It seems to be ok For Cochran test. Unfortunately I
have not found info about  this test in R, except for dealing with outliers
which is not my aim. I am looking for something like this
https://www.medcalc.org/manual/cochranq.php

I found a video to perform this analysis in R, but was not specially
useful. Does some of you know have some info about how to make this
analysis in R?

Thanks in advance!

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu May  7 09:15:23 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 7 May 2015 17:15:23 +1000
Subject: [R] Question about cochran test in R
In-Reply-To: <CANxP2S6EE+x+TqdWR8ULOB+i4w8=SaDiYPtwg=tp0eSPES8S5A@mail.gmail.com>
References: <CANxP2S6EE+x+TqdWR8ULOB+i4w8=SaDiYPtwg=tp0eSPES8S5A@mail.gmail.com>
Message-ID: <CA+8X3fX1Kn=7__FCERj18V02=XgiB6v3k8HT5gUUFOj=m_KFyg@mail.gmail.com>

Hi Luis,
Try this page:

http://www.r-bloggers.com/cochran-q-test-for-k-related-samples-in-r/

Jim


On Thu, May 7, 2015 at 4:59 PM, Luis Fernando Garc?a
<luysgarcia at gmail.com> wrote:
> Dear R Experts,
>
> May be this is a basic question for you, but it is something I need really
> urgently. I need to perform a Chi Square analysis for more than two groups
> of paired observations. It seems to be ok For Cochran test. Unfortunately I
> have not found info about  this test in R, except for dealing with outliers
> which is not my aim. I am looking for something like this
> https://www.medcalc.org/manual/cochranq.php
>
> I found a video to perform this analysis in R, but was not specially
> useful. Does some of you know have some info about how to make this
> analysis in R?
>
> Thanks in advance!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From holger.steinmetz at web.de  Thu May  7 10:22:57 2015
From: holger.steinmetz at web.de (Holger Steinmetz)
Date: Thu, 7 May 2015 10:22:57 +0200
Subject: [R] Problem with using flexmix for regression mixtures
Message-ID: <E0079AD1-F7BB-44BE-B769-FD1D97E80947@web.de>

Hi there,

I would like to conduct a mixture regression analysis with the flexmix
Package. Was just playing around with the function stepFlexmix() and did not get a foot
into the door.

When I run the stepFlexmix-function, I get the following error (actually a
list of errors that repeats this sentence:

Error in FLXfit(model = model, concomitant = concomitant, control = control, 
: 
   26 Log-likelihood: Inf

The X-Variable is very skewed (percentages of females in top management
teams; many zeros); missing data were omitted. The code was:

M1 <- stepFlexmix(rel_perf ~ prozfem, data = cdata2, k = 1:5, nrep = 5)

I would appreciate any hint what the problem might be.

Thanks in advance,
Holger


From jvadams at usgs.gov  Thu May  7 12:32:36 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 7 May 2015 06:32:36 -0400
Subject: [R] How to finding a given length of runs in a series of data?
In-Reply-To: <1430949317963-4706915.post@n4.nabble.com>
References: <1430949317963-4706915.post@n4.nabble.com>
Message-ID: <CAN5YmCFFvmufNSGM6+yQs_p4CLsOVyT9g_=xD2jDPD=470=bSQ@mail.gmail.com>

Two libraries are needed to run the code you submitted ...

library(dplyr)
library(sqldf)

Your IsHigh() function and its use can be replaced by a single line of code

isHighFlow <- as.numeric(Flow>=1600)

You are getting the additional hour by using cumsum().  One date element
which you seem to characterize as zero hours returns a one in cumsum, two
returns two, etc.
cumsum(c(1, 0, 1, 1, 0, 1, 1, 1, 0))

If everything is off by one hour, just subtract a 1.  Problem solved.

Jean


On Wed, May 6, 2015 at 5:55 PM, jcrosbie <james at crosb.ie> wrote:

> I'm trying to study times in which flow was operating at a given level or
> greater. To do so I have created a way to see how long the series has
> operated at a high level. But for some reason the data is calculating the
> runs one hour to long. Any ideas on why?
>
>
>
>
>
> Code:
> Date<-format(seq(as.POSIXct("2014-01-01 01:00"), as.POSIXct("2015-01-01
> 00:00"),     by="hour"), "%Y-%m-%d %H:%M", usetz = FALSE)
> Flow<-runif(8760, 0, 2300)
>
> IsHigh<- function(x ){
>     if (x < 1600) return(0)
>     if (1600 <= x) return(1)
> }
>
> isHighFlow = unlist(lapply(Flow, IsHigh))
>
> df = data.frame(Date, Flow, isHighFlow )
>
>
> temp <- df %>%
>   mutate(highFlowInterval = cumsum(isHighFlow==0)) %>%
>   group_by(highFlowInterval) %>%
>   summarise(hoursHighFlow = n(), minDate = min(as.character(Date)), maxDate
> = max(as.character(Date)))
>
> #Then join the two tables together.
> temp2<-sqldf("SELECT *
>   FROM temp LEFT JOIN df
>   ON df.Date BETWEEN temp.minDate AND temp.maxDate")
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/How-to-finding-a-given-length-of-runs-in-a-series-of-data-tp4706915.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From nilsson.henric at gmail.com  Thu May  7 13:03:12 2015
From: nilsson.henric at gmail.com (Henric Winell)
Date: Thu, 07 May 2015 13:03:12 +0200
Subject: [R] Question about cochran test in R
In-Reply-To: <CA+8X3fX1Kn=7__FCERj18V02=XgiB6v3k8HT5gUUFOj=m_KFyg@mail.gmail.com>
References: <CANxP2S6EE+x+TqdWR8ULOB+i4w8=SaDiYPtwg=tp0eSPES8S5A@mail.gmail.com>
	<CA+8X3fX1Kn=7__FCERj18V02=XgiB6v3k8HT5gUUFOj=m_KFyg@mail.gmail.com>
Message-ID: <554B4670.6090503@gmail.com>

On 2015-05-07 09:15, Jim Lemon wrote:

> Hi Luis,
> Try this page:
>
> http://www.r-bloggers.com/cochran-q-test-for-k-related-samples-in-r/
>
> Jim

Cochran's Q test is a marginal homogeneity test, and such tests can be 
performed by the 'mh_test' function in the 'coin' package.  The 
following replicates the result in the blog post

 > library("coin")
 >
 > dta <- data.frame(
+     method    = factor(rep(LETTERS[1:4], 6)),
+     repellent = factor(c(1, 1, 0, 0,
+                          1, 1, 0, 1,
+                          1, 0, 0, 0,
+                          1, 1, 1, 0,
+                          1, 1, 0, 1,
+                          1, 1, 0, 1)),
+     fabric    = gl(6, 4, labels = as.roman(1:6))
+ )
 >
 > mh_test(repellent ~ method | fabric, data = dta)

	Asymptotic Marginal-Homogeneity Test

data:  repellent by
	 method (A, B, C, D)
	 stratified by fabric
chi-squared = 9.3158, df = 3, p-value = 0.02537


and uses the asymptotic approximation to compute the p-value.  The 
'coin' package also allows you to approximate the exact null 
distribution using Monte Carlo methods:

 > set.seed(123)
 > mh_test(repellent ~ method | fabric, data = dta,
+         distribution = approximate(B = 10000L))

	Approximative Marginal-Homogeneity Test

data:  repellent by
	 method (A, B, C, D)
	 stratified by fabric
chi-squared = 9.3158, p-value = 0.0202


For future reference, 'mh_test' is fairly general and handles both 
matched pairs or matched sets.  So, the well-known tests due McNemar, 
Cochran, Stuart(-Maxwell) and Madansky are just special cases.

For more general symmetry test problems, the 'coin' package offers the 
'symmetry_test' function and this can be used to perform, e.g., 
multivariate marginal homogeneity tests like the multivariate McNemar 
test (Klingenberg and Agresti, 2006) or the multivariate Friedman test 
(Gerig, 1969).


Henric



>
>
> On Thu, May 7, 2015 at 4:59 PM, Luis Fernando Garc?a
> <luysgarcia at gmail.com> wrote:
>> Dear R Experts,
>>
>> May be this is a basic question for you, but it is something I need really
>> urgently. I need to perform a Chi Square analysis for more than two groups
>> of paired observations. It seems to be ok For Cochran test. Unfortunately I
>> have not found info about  this test in R, except for dealing with outliers
>> which is not my aim. I am looking for something like this
>> https://www.medcalc.org/manual/cochranq.php
>>
>> I found a video to perform this analysis in R, but was not specially
>> useful. Does some of you know have some info about how to make this
>> analysis in R?
>>
>> Thanks in advance!
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ajaouni at gmail.com  Thu May  7 09:52:03 2015
From: ajaouni at gmail.com (Ala' Jaouni)
Date: Thu, 7 May 2015 10:52:03 +0300
Subject: [R] Identifying matched groups based on a rule
Message-ID: <CAHsWkwBdYLx+ceqsKX4iggnR_xanoL07KD8qKt8H0AAeY69UPw@mail.gmail.com>

Hello,

I'm trying to create a table like below for a data set representing one
test and indexed by five categories.

Categories are grouped into a number of buckets (three in this case: A, B,
C) based on the level at which the difference between groups is significant
(0.05).

Category,  Group,  Mean
1,  A,  94.9
2,  A,  94.8
3,  A+B,  93.4
4,  B+C,  91.4
5,  C,  91.1

Is there a way to do this in R?

Thanks.

	[[alternative HTML version deleted]]


From cardio1 at live.ca  Thu May  7 12:58:37 2015
From: cardio1 at live.ca (khal sal)
Date: Thu, 7 May 2015 06:58:37 -0400
Subject: [R] Non UTFB
Message-ID: <BLU171-W535A1AA056CCABA54D6BF3E3DF0@phx.gbl>

I am getting this message after I installed R on MAC
What should I do?
 
 
During startup - Warning messages:
  1: Setting LC_CTYPE failed, using "C"
  2: Setting LC_COLLATE failed, using "C"
  3: Setting LC_TIME failed, using "C"
  4: Setting LC_MESSAGES failed, using "C"
  5: Setting LC_PAPER failed, using "C"
  [R.app GUI 1.50 (6126) x86_64-apple-darwin9.8.0] 
&amp;#114;&amp;#x2d;&amp;#104;&amp;#x65;&amp;#108;&amp;#112;&amp;#32;&amp;#x61;&amp;#116;&amp;#32;&amp;#82;&amp;#x2d;&amp;#112;&amp;#114;&amp;#x6f;&amp;#106;&amp;#x65;&amp;#x63;&amp;#116;&amp;#32;&amp;#100;&amp;#x6f;&amp;#116;&amp;#32;&amp;#x6f;&amp;#114;&amp;#x67
 
 
khal 
 		 	   		  
	[[alternative HTML version deleted]]


From krishnakanth217 at outlook.com  Thu May  7 08:15:29 2015
From: krishnakanth217 at outlook.com (Krishna Kanth)
Date: Thu, 7 May 2015 11:45:29 +0530
Subject: [R] How does ARules in R decide on LHS and RHS??
Message-ID: <BAY176-W29040AED5658D815CD4A69F4DF0@phx.gbl>

I was trying to study arules in R and got stuck on this doubt:

How does arules code decide which column  to be in LHS and which in RHS?? 
 		 	   		  
	[[alternative HTML version deleted]]


From shivibhatia at ymail.com  Thu May  7 07:32:37 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Wed, 6 May 2015 22:32:37 -0700 (PDT)
Subject: [R] MOnth over Month Variance in %
In-Reply-To: <5DBC6372B55.0000134Bjrkrideau@inbox.com>
References: <1430907687472-4706873.post@n4.nabble.com>
	<5DBC6372B55.0000134Bjrkrideau@inbox.com>
Message-ID: <1430976757569-4706923.post@n4.nabble.com>

Thanks John for the tip. I will use it and see what is the output. Also I
will share my analysis on R & then you can advice accordingly. 



--
View this message in context: http://r.789695.n4.nabble.com/MOnth-over-Month-Variance-in-tp4706873p4706923.html
Sent from the R help mailing list archive at Nabble.com.


From pdalgd at gmail.com  Thu May  7 16:45:41 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 7 May 2015 16:45:41 +0200
Subject: [R] Non UTFB
In-Reply-To: <BLU171-W535A1AA056CCABA54D6BF3E3DF0@phx.gbl>
References: <BLU171-W535A1AA056CCABA54D6BF3E3DF0@phx.gbl>
Message-ID: <866D9B18-F68C-40D4-89F6-8795074EFD2A@gmail.com>


On 07 May 2015, at 12:58 , khal sal <cardio1 at live.ca> wrote:

> I am getting this message after I installed R on MAC
> What should I do?

Consult the R for Mac OS X FAQ, I expect. Specifically Section 7, Internationalization.

Notice that we cannot see what your locale settings are, and that your post has been mangled because it was posted in HTML, but there is this specific information in the FAQ: 

"Please note that you must always use `.UTF-8' version of the locale, otherwise R.app will not work properly."

- Peter D.

> 
> 
> During startup - Warning messages:
>  1: Setting LC_CTYPE failed, using "C"
>  2: Setting LC_COLLATE failed, using "C"
>  3: Setting LC_TIME failed, using "C"
>  4: Setting LC_MESSAGES failed, using "C"
>  5: Setting LC_PAPER failed, using "C"
>  [R.app GUI 1.50 (6126) x86_64-apple-darwin9.8.0] 
> &amp;#114;&amp;#x2d;&amp;#104;&amp;#x65;&amp;#108;&amp;#112;&amp;#32;&amp;#x61;&amp;#116;&amp;#32;&amp;#82;&amp;#x2d;&amp;#112;&amp;#114;&amp;#x6f;&amp;#106;&amp;#x65;&amp;#x63;&amp;#116;&amp;#32;&amp;#100;&amp;#x6f;&amp;#116;&amp;#32;&amp;#x6f;&amp;#114;&amp;#x67
> 
> 
> khal 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From NordlDJ at dshs.wa.gov  Thu May  7 17:51:52 2015
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 7 May 2015 15:51:52 +0000
Subject: [R] Convert csv to xpt file in R?
In-Reply-To: <CAN_e6XuoVbqZOFMjGCPG8ZqbD53ZwuLB0e0ZzwGMbUSDq_JtnA@mail.gmail.com>
References: <CAN_e6XuoVbqZOFMjGCPG8ZqbD53ZwuLB0e0ZzwGMbUSDq_JtnA@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27662ED2CFA2@WAXMXOLYMB025.WAX.wa.lcl>

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Santosh
> Sent: Wednesday, May 06, 2015 8:04 PM
> To: r-help
> Subject: [R] Convert csv to xpt file in R?
> 
> Dear Rxperts..
> 
> Was wondering if there is a way in R to read a csv file and generate an
> XPT
> file?  For some reason the function write.xport() does not seem to work
> for
> me....
> i get the following error...
> "error in label.data.frame(df,default=""): length of default same as x
> 
> A sample dataframe is given below
> xg2 <- data.frame(aa=runif(10),bb=sample(runif(100),10))
> SASformat(xg2$aa) <- 'Numeric2'
> SASformat(xg2$bb) <- 'Numeric2'
> label(xg2$aa) <- "test aa"
> label(xg2$bb) <- "test bb"
> label(xg2) <- "testa"
> SAStype(xg2) <- "TestXge"
> write.xport(xg2,file="A1.xpt")
> Error in label.data.frame(df, default = "") :
>   length of default must same as x
> 
> 
> Any suggestions/tips are welcome..
> 
> Thanks and regards
> Santosh
> 

The code above runs without error and produces an xport file on my Win7 64-bit system running R-3.2.0.  You haven't told us anything about your OS, version of R, and packages loaded.  Have you tried running the code from a fresh start of R after only loading the SASxport package?

Dan 

Daniel J. Nordlund
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services



From jrkrideau at inbox.com  Thu May  7 19:40:19 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 7 May 2015 09:40:19 -0800
Subject: [R] MOnth over Month Variance in %
In-Reply-To: <1430976757569-4706923.post@n4.nabble.com>
References: <1430907687472-4706873.post@n4.nabble.com>
	<5dbc6372b55.0000134bjrkrideau@inbox.com>
Message-ID: <6C0F7714F0C.0000056Fjrkrideau@inbox.com>


Sorry, I see that I forgot the link:

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example


John Kane
Kingston ON Canada


> -----Original Message-----
> From: shivibhatia at ymail.com
> Sent: Wed, 6 May 2015 22:32:37 -0700 (PDT)
> To: r-help at r-project.org
> Subject: Re: [R] MOnth over Month Variance in %
> 
> Thanks John for the tip. I will use it and see what is the output. Also I
> will share my analysis on R & then you can advice accordingly.
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/MOnth-over-Month-Variance-in-tp4706873p4706923.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE 5GB EMAIL - Check out spam free email with many cool features!
Visit http://www.inbox.com/email to find out more!


From jrkrideau at inbox.com  Thu May  7 19:50:04 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 7 May 2015 09:50:04 -0800
Subject: [R] How does ARules in R decide on LHS and RHS??
In-Reply-To: <BAY176-W29040AED5658D815CD4A69F4DF0@phx.gbl>
Message-ID: <6C254380042.00000590jrkrideau@inbox.com>

This is pretty sketchy. Perhaps some details might help.
arules is in what package?

Any code ?

Any data?

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: krishnakanth217 at outlook.com
> Sent: Thu, 7 May 2015 11:45:29 +0530
> To: r-help at r-project.org
> Subject: [R] How does ARules in R decide on LHS and RHS??
> 
> I was trying to study arules in R and got stuck on this doubt:
> 
> How does arules code decide which column  to be in LHS and which in RHS??
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From jrkrideau at inbox.com  Thu May  7 19:55:41 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 7 May 2015 09:55:41 -0800
Subject: [R] Identifying matched groups based on a rule
In-Reply-To: <CAHsWkwBdYLx+ceqsKX4iggnR_xanoL07KD8qKt8H0AAeY69UPw@mail.gmail.com>
Message-ID: <6C31C90470A.000005A5jrkrideau@inbox.com>

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

You have not supplied anywhere near enough information. See the link above for some suggestions.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: ajaouni at gmail.com
> Sent: Thu, 7 May 2015 10:52:03 +0300
> To: r-help at r-project.org
> Subject: [R] Identifying matched groups based on a rule
> 
> Hello,
> 
> I'm trying to create a table like below for a data set representing one
> test and indexed by five categories.
> 
> Categories are grouped into a number of buckets (three in this case: A,
> B,
> C) based on the level at which the difference between groups is
> significant
> (0.05).
> 
> Category,  Group,  Mean
> 1,  A,  94.9
> 2,  A,  94.8
> 3,  A+B,  93.4
> 4,  B+C,  91.4
> 5,  C,  91.1
> 
> Is there a way to do this in R?
> 
> Thanks.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From rafaelcarneirocosta.rc at gmail.com  Thu May  7 20:43:22 2015
From: rafaelcarneirocosta.rc at gmail.com (Rafael Costa)
Date: Thu, 7 May 2015 15:43:22 -0300
Subject: [R] About categorical explanatory variables
Message-ID: <CAOy3Z4C4kFDaJ1Yz=5ccYBubHWUdVRqb1APobd4=9jd30sZGVQ@mail.gmail.com>

When you want to get the individual impact of each level of a single
categorical explanatory variable on a variable continuous quantitative
response, simply add the value of the estimated coefficient to the
intercept or, more directly, just consider all levels of the categorical
variable in the regression and omit the intercept, thereby obtaining in
each coefficient estimated the individual effect of that particular
category. But with 2 or more categorical variables, the intercept becomes
the value of a reference group, jointly considering several categories, one
for each qualitative variable. The coefficients in turn will be the
difference between a specific group and the reference group. But I like to
get the individual effects of each category and no effect of group
categories.

My question is: is there any way to get the individual effects in this
case, where there are two or more categorical explanatory variables (these
may be ordered, unordered, or both types)? If so, how to proceed in R?

I have been looked, but I found nothing about it.
Any help will be appreciated. Thanks for listening.

Yours sincerely,
Rafael Costa

	[[alternative HTML version deleted]]


From rafaelcarneirocosta.rc at gmail.com  Thu May  7 20:43:52 2015
From: rafaelcarneirocosta.rc at gmail.com (Rafael Costa)
Date: Thu, 7 May 2015 15:43:52 -0300
Subject: [R] Getting INDIVIDUAL effects of multiple qualitative variables
 (ordered and unordered factors)
Message-ID: <CAOy3Z4C2wu5uMprni1S0eRiCWoitduLvGSHfLg8xH4ucsvy=Aw@mail.gmail.com>

Dear R users,

I have data from a questionnaire and I want to estimate the individual
effect of each explanatory variable (all are qualitative) on the dependent
variable (continuous). However, the default is to consider the estimated
coefficients as the difference between the reference group (estimated value
of the intercept) and the coefficient of the group. Each qualitative
variable relates to a characteristic of a particular activity and the
continuous variable is the time taken to perform this activity. I emphasize
that the reference level of each factor relates to the case where none of
the options for that factor was marked. The data is in "
http://www.datafilehost.com/d/c7f0d342". I did not put them in the script,
because I still do not know how to do this, but I hope this is not a
problem (and I ask my sincere apologies). I do not put just a sample of the
data, since there was singular matrix problems.



First (and main) issue - In order to obtain the individual effect of the
levels of each factor, I considered that the reference group has zero
effect and I did the following steps:



# Since the file was not loaded in the script, it is assumed here that it
was downloaded from the internet and is already loaded in R.

# I will make a quantile regression, so the package follows.

install.packages (quantreg)

library (quantreg)

# Transforming factors into individual objects:

p_1 = table (1: length (tabela1.1 $ p1), as.factor (tabela1.1 $ p1))

p_21 = table (1: length (tabela1.1 $ p21), as.factor (tabela1.1 $ p21))

p_22 = table (1: length (tabela1.1 $ p22), as.factor (tabela1.1 $ p22))

p_23 = table (1: length (tabela1.1 $ p23), as.factor (tabela1.1 $ p23))

p_24 = table (1: length (tabela1.1 $ p24), as.factor (tabela1.1 $ p24))

p_25 = table (1: length (tabela1.1 $ p25), as.factor (tabela1.1 $ p25))

p_34 = table (1: length (tabela1.1 $ p34), as.ordered (tabela1.1 $ p34))

p_5 = table (1: length (tabela1.1 $ p5), as.ordered (tabela1.1 $ p5))

p_6 = table (1: length (tabela1.1 $ p6), as.ordered (tabela1.1 $ p6))

p_7 = table (1: length (tabela1.1 $ p7), as.ordered (tabela1.1 $ p7))

p_8 = table (1: length (tabela1.1 $ p8), as.ordered (tabela1.1 $ p8))

p_9 = table (1: length (tabela1.1 $ p9), as.ordered (tabela1.1 $ p9))

# Regressing the model without intercept, but considering that the
reference group = 0, considering that the reference group means that none
of the factors has been marked (if any was marked, I believe that the time
taken to perform the activity is practically zero).

qrModel=rq(data=tabela1.1, pontoefetivo ~ 0 + p_1[,-1] + p_21[,-1] +
p_22[,-1] + p_23[,-1] + p_24[,-1] + p_25[,-1] + p_34[,-1] + p_5[,-1] +
p_6[,-1] + p_7[,-1] + p_8[,-1] + p_9[,-1], tau=0.5)

summary(qrModel)

My idea was that since the effect of the reference group is zero, the
estimated coefficient of each level is precisely the individual effect of
the chosen variable level. My idea is right? If not, what do I do to get
these individual effects?



Problem 2 - Assuming all is right above, ordered factors not have
increasing effects [See summary (qrModel)]. But should not they have? If
so, what do I do to ensure such an effect?



Problem 3 - Again assuming that everything is correct, I hope that any
estimated coefficients (individual effects on the runtime of the activity)
are not negative values. Am I right about that? If so, what do I do to
ensure that all values ??are not negative?


I am looking forward  any help.

Thanks in advance ,

Rafael Costa.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu May  7 21:10:25 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 7 May 2015 12:10:25 -0700
Subject: [R] package implementing continuous binomial?
In-Reply-To: <554AC75A.8070708@gmail.com>
References: <554AC75A.8070708@gmail.com>
Message-ID: <5425134B-6AA1-4246-BCD4-D4BE4BE2391B@comcast.net>


On May 6, 2015, at 7:00 PM, Benjamin Tyner wrote:

> Hi
> 
> I'm wondering if anyone is aware of an R package implementing (i.e.,
> providing a pdf, cdf, and/or quantile function) for the continuous
> binomial distribution? Specifically the one characterized here:
> 
> http://www2.math.uni-paderborn.de/fileadmin/Mathematik/AG-Indlekofer/Workshop/Satellite_meeting/ilenko.pdf
> 
> Figured I would check here first, before attempting to code it up myself.

I found that reading the ArXiv version of that material was easier to understand:

http://arxiv.org/abs/1303.5990

zipfR package has an implementation of the incomplete beta function that might make some of the coding of the pdf and cdf more simple. 

Searching done with Graves' very useful utility package: 

library('sos')
findFn("incomplete beta function")

(I did't think that doing a search on "continuous Binomial" was likely to be helpful, but I tried it anyway and did not find any functions named "continuous binomial" in their help page titles.)

-- 

David Winsemius
Alameda, CA, USA


From santosh2005 at gmail.com  Thu May  7 22:12:08 2015
From: santosh2005 at gmail.com (Santosh)
Date: Thu, 7 May 2015 13:12:08 -0700
Subject: [R] Convert csv to xpt file in R?
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA27662ED2CFA2@WAXMXOLYMB025.WAX.wa.lcl>
References: <CAN_e6XuoVbqZOFMjGCPG8ZqbD53ZwuLB0e0ZzwGMbUSDq_JtnA@mail.gmail.com>
	<F7E6D18CC2877149AB5296CE54EA27662ED2CFA2@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <CAN_e6XtYHHg9D69gCfAS-tQs07yKjJ1wEwWFBA88=VRx+hmR=g@mail.gmail.com>

Dear Rxperts..
Thanks for your response. Below is the version on Windows 7 Enterprise
(64-bit) OS machine..Yes, I tried SASxport, foreign and Hmisc.. have used
SASxport before (not for writing to xpt though) and continue to have the
same write to sas transport file  issue..

> version
               _
platform       x86_64-w64-mingw32
arch           x86_64
os             mingw32
system         x86_64, mingw32
status
major          3
minor          0.2
year           2013
month          09
day            25
svn rev        63987
language       R
version.string R version 3.0.2 (2013-09-25)

Thanks and regards,
Santosh

On Thu, May 7, 2015 at 8:51 AM, Nordlund, Dan (DSHS/RDA) <
NordlDJ at dshs.wa.gov> wrote:

> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Santosh
> > Sent: Wednesday, May 06, 2015 8:04 PM
> > To: r-help
> > Subject: [R] Convert csv to xpt file in R?
> >
> > Dear Rxperts..
> >
> > Was wondering if there is a way in R to read a csv file and generate an
> > XPT
> > file?  For some reason the function write.xport() does not seem to work
> > for
> > me....
> > i get the following error...
> > "error in label.data.frame(df,default=""): length of default same as x
> >
> > A sample dataframe is given below
> > xg2 <- data.frame(aa=runif(10),bb=sample(runif(100),10))
> > SASformat(xg2$aa) <- 'Numeric2'
> > SASformat(xg2$bb) <- 'Numeric2'
> > label(xg2$aa) <- "test aa"
> > label(xg2$bb) <- "test bb"
> > label(xg2) <- "testa"
> > SAStype(xg2) <- "TestXge"
> > write.xport(xg2,file="A1.xpt")
> > Error in label.data.frame(df, default = "") :
> >   length of default must same as x
> >
> >
> > Any suggestions/tips are welcome..
> >
> > Thanks and regards
> > Santosh
> >
>
> The code above runs without error and produces an xport file on my Win7
> 64-bit system running R-3.2.0.  You haven't told us anything about your OS,
> version of R, and packages loaded.  Have you tried running the code from a
> fresh start of R after only loading the SASxport package?
>
> Dan
>
> Daniel J. Nordlund
> Research and Data Analysis Division
> Services & Enterprise Support Administration
> Washington State Department of Social and Health Services
>
>
>

	[[alternative HTML version deleted]]


From jean.d.marchal at gmail.com  Thu May  7 22:14:05 2015
From: jean.d.marchal at gmail.com (Jean Marchal)
Date: Thu, 7 May 2015 13:14:05 -0700
Subject: [R] nlminb supplying NaN parameters to objective function
In-Reply-To: <CACF6B3WqQ4uhPS-_Yk60G8wSPQ80=-PsWa2OQY4HgbyNkJuuww@mail.gmail.com>
References: <CACF6B3WqQ4uhPS-_Yk60G8wSPQ80=-PsWa2OQY4HgbyNkJuuww@mail.gmail.com>
Message-ID: <CACF6B3V7w1i1d22Mk77fpvTrdz_0f0irQgPR9A5o7Yn1qJR3=g@mail.gmail.com>

A follow-up to my yesterday's email.

I was able to make a reproducible example. All you will have to do is
load the .RData file that you can download here:
https://drive.google.com/file/d/0B0DKwRjF11x4dG1uRWhwb1pfQ2s/view?usp=sharing

and run this line of code:

nlminb(start=sv, objective = nLL, lower = 0, upper = Inf,
control=list(trace=TRUE))

which output the following:

  0:     12523.401: 0.0328502 0.0744493 0.00205298 0.0248628 0.0881807
0.0148887 0.0244485 0.0385922 0.0714495 0.0161784 0.0617551 0.0244901
0.0784038
  1:     12421.888: 0.0282245 0.0697934  0.00000 0.0199076 0.0833634
0.0101135 0.0189494 0.0336236 0.0712130 0.0160687 0.0616015 0.0244689
0.0660129
  2:     12050.535: 0.00371847 0.0451786  0.00000  0.00000 0.0575667
0.00000  0.00000 0.00697067 0.0697205 0.0156250 0.0608550 0.0243431
0.0994355
  3:     12037.682: 0.00303460 0.0445012  0.00000  0.00000 0.0568530
0.00000  0.00000 0.00636016 0.0696959 0.0156250 0.0608550 0.0243419
0.0988824
  4:     12012.684: 0.00164710 0.0431313  0.00000  0.00000 0.0554032
0.00000  0.00000 0.00515500 0.0696451 0.0156250 0.0608550 0.0243395
0.0978328
  5:     12003.017: 0.00107848 0.0425739  0.00000  0.00000 0.0548073
0.00000  0.00000 0.00469592 0.0696233 0.0156250 0.0608550 0.0243386
0.0974616
  6:     11984.372:  0.00000 0.0414397  0.00000  0.00000 0.0535899
0.00000  0.00000 0.00378996 0.0695782 0.0156250 0.0608550 0.0243370
0.0967449
  7:     11978.154:  0.00000 0.0409106  0.00000  0.00000 0.0530158
0.00000  0.00000 0.00340746 0.0695560 0.0156250 0.0608550 0.0243363
0.0964537
  8:    -0.0000000:  0.00000      nan  0.00000  0.00000      nan
0.00000  0.00000      nan      nan      nan      nan      nan      nan

Regards,

Jean

2015-05-06 17:43 GMT-07:00 Jean Marchal <jean.d.marchal at gmail.com>:
> Dear list,
>
> I am doing some maximum likelihood estimation using nlminb() with
> box-constraints to ensure that all parameters are positive. However,
> nlminb() is behaving strangely and seems to supply NaN as parameters
> to my objective function (confirmed using browser()) and output the
> following:
>
> $par
>  [1] NaN NaN NaN   0 NaN   0 NaN NaN NaN NaN NaN NaN NaN
>
> $objective
> [1] 0
>
> $convergence
> [1] 1
>
> $iterations
> [1] 19
>
> $evaluations
> function gradient
>       87      542
>
> $message
> [1] "gr cannot be computed at initial par (65)"
>
>
> When I use trace = TRUE, I can see the following:
>
>   0:     32495.488: 0.0917404 0.703453  1.89661 1.11022e-16
> 1.11022e-16 0.107479 1.11022e-16 1.11022e-16 1.11022e-16 0.472377
> 0.894128  1.86743 1.11022e-16
>   1:     4035.3900: 0.0917404 0.703453  1.89661 1.11022e-16
> 1.11022e-16 0.107479 1.11022e-16 1.11022e-16 1.11022e-16 0.472377
> 0.894128  1.86743 0.250000
>   2:     3955.8801: 0.0948452 0.704168  1.89651 0.000135456 0.0310485
> 0.107991 0.00138902 0.000427631 1.11022e-16 0.472331 0.894128  1.86743
> 0.250000
>   3:     3951.4141: 0.0948926 0.703906  1.89640 2.99167e-05 0.0315288
> 0.109692 0.00242572 0.00272185 7.96814e-05 0.472780 0.894130  1.86744
> 0.249998
> ....
>  17:     3937.3923: 0.0947470 0.703030  1.89605 1.11022e-16 0.0300763
> 0.115081 0.00562496 0.00989997 0.000323268 0.474247 0.894142  1.86745
> 0.249737
>  18:     3937.3923: 0.0947470 0.703030  1.89605 1.11022e-16 0.0300763
> 0.115081 0.00562496 0.00989997 0.000323268 0.474247 0.894142  1.86745
> 0.249737
>  19:    -0.0000000:     -nan     -nan     -nan 1.11022e-16     -nan
>  -nan     -nan     -nan     -nan     -nan     -nan     -nan      nan
>
>
> my objective function looks like:
>
> nLL <- function(params){
>
>   mu <- drop(model.matrix(modelTermsObj) %*% params)
>
>   if(any(mu < 0) || anyNA(mu) || any(is.infinite(mu))){
>     return(.Machine$double.xmax)
>   } else {
>     return(-sum(dnbinom(x=args$data[,response], mu = mu, size =
> params[length(params)], log = TRUE)))
>   }
> }
>
> I tried different starting values, different bounds but without
> success so far. Is this a bug?
>
> PS after trying to make a reproducible example that I gracefully
> failed to do... I change my objective function so instead of using
> model.matrix(), I did the maths (e.g. Y ~ A + B * C). Thus, mu is now
> a bunch of NaN, and my objective function return .Machine$double.xmax
> which is fine. Then nlminb stops and returns (like if nothing
> happened):
>
> $par
>  [1] 1.11022e-16 1.11022e-16 2.69205e-04 1.11022e-16 1.68161e-03
> 1.06027e-03 1.16969e-05 1.11022e-16 8.51669e+01 7.31162e+01
> 5.04748e+00 5.28373e+00 1.23992e-01
>
> $objective
> [1] 3823.567
>
> $convergence
> [1] 0
>
> $iterations
> [1] 1
>
> $evaluations
> function gradient
>        2       13
>
> $message
> [1] "X-convergence (3)"
>
> I can provide the data and model if necessary but cannot make them
> publicly available (yet).
>
> Thank you,
>
> Jean


From rshepard at appl-ecosys.com  Thu May  7 22:50:33 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 7 May 2015 13:50:33 -0700 (PDT)
Subject: [R] Calling Function With Arguments In a Script
Message-ID: <alpine.LNX.2.11.1505071341360.11430@localhost>

   I'm starting to put code in multi-use functions rather than in individual
scripts and have not learned how to invoke the function from the command
line. If this information is in Norman Matloff's 'The Art of R Programming'
or Hadley Wickham's 'Advanced R' please point me to the proper place.

   Here's an example, the script 'pairwise-plots-continuous-vars.R' consists
of this function:

plotpairs <- function(x1,x2,x3,y,plotmain) {
     require(compositions)
     opar <- par(mar=c(4,4,3,1))
     NO3 <- x1
     SO4 <- x2
     pH <- x3
     pairwisePlot(cbind(NO3,SO4,pH),clr(y),add.line=T)
     title(main=plotmain)
     par(opar)
     detach('package:compositions')
     return()
}

   (I suppose the return statement is superfluous since there is no value
returned to a calling function.)

   What I want to do is call plotpairs() with appropriate arguments for each
plot as needed.

TIA,

Rich


From wdunlap at tibco.com  Thu May  7 23:06:10 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 7 May 2015 14:06:10 -0700
Subject: [R] nlminb supplying NaN parameters to objective function
In-Reply-To: <CACF6B3V7w1i1d22Mk77fpvTrdz_0f0irQgPR9A5o7Yn1qJR3=g@mail.gmail.com>
References: <CACF6B3WqQ4uhPS-_Yk60G8wSPQ80=-PsWa2OQY4HgbyNkJuuww@mail.gmail.com>
	<CACF6B3V7w1i1d22Mk77fpvTrdz_0f0irQgPR9A5o7Yn1qJR3=g@mail.gmail.com>
Message-ID: <CAF8bMcbscS2hjAws=4WqxONyc0Ma-zjkToZOTZtRBM2erpC7dg@mail.gmail.com>

Your nLL function returns 1e+308 in near-boundary cases.  Since 1e+308 is so
close to machine infinity, it is easy to get into Inf-Inf (=NaN) or Inf/Inf
(=NaN)
situations when working with it.  Try making that limiting value something
smaller,
like 1e+30, and you may have better luck.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, May 7, 2015 at 1:14 PM, Jean Marchal <jean.d.marchal at gmail.com>
wrote:

> A follow-up to my yesterday's email.
>
> I was able to make a reproducible example. All you will have to do is
> load the .RData file that you can download here:
>
> https://drive.google.com/file/d/0B0DKwRjF11x4dG1uRWhwb1pfQ2s/view?usp=sharing
>
> and run this line of code:
>
> nlminb(start=sv, objective = nLL, lower = 0, upper = Inf,
> control=list(trace=TRUE))
>
> which output the following:
>
>   0:     12523.401: 0.0328502 0.0744493 0.00205298 0.0248628 0.0881807
> 0.0148887 0.0244485 0.0385922 0.0714495 0.0161784 0.0617551 0.0244901
> 0.0784038
>   1:     12421.888: 0.0282245 0.0697934  0.00000 0.0199076 0.0833634
> 0.0101135 0.0189494 0.0336236 0.0712130 0.0160687 0.0616015 0.0244689
> 0.0660129
>   2:     12050.535: 0.00371847 0.0451786  0.00000  0.00000 0.0575667
> 0.00000  0.00000 0.00697067 0.0697205 0.0156250 0.0608550 0.0243431
> 0.0994355
>   3:     12037.682: 0.00303460 0.0445012  0.00000  0.00000 0.0568530
> 0.00000  0.00000 0.00636016 0.0696959 0.0156250 0.0608550 0.0243419
> 0.0988824
>   4:     12012.684: 0.00164710 0.0431313  0.00000  0.00000 0.0554032
> 0.00000  0.00000 0.00515500 0.0696451 0.0156250 0.0608550 0.0243395
> 0.0978328
>   5:     12003.017: 0.00107848 0.0425739  0.00000  0.00000 0.0548073
> 0.00000  0.00000 0.00469592 0.0696233 0.0156250 0.0608550 0.0243386
> 0.0974616
>   6:     11984.372:  0.00000 0.0414397  0.00000  0.00000 0.0535899
> 0.00000  0.00000 0.00378996 0.0695782 0.0156250 0.0608550 0.0243370
> 0.0967449
>   7:     11978.154:  0.00000 0.0409106  0.00000  0.00000 0.0530158
> 0.00000  0.00000 0.00340746 0.0695560 0.0156250 0.0608550 0.0243363
> 0.0964537
>   8:    -0.0000000:  0.00000      nan  0.00000  0.00000      nan
> 0.00000  0.00000      nan      nan      nan      nan      nan      nan
>
> Regards,
>
> Jean
>
> 2015-05-06 17:43 GMT-07:00 Jean Marchal <jean.d.marchal at gmail.com>:
> > Dear list,
> >
> > I am doing some maximum likelihood estimation using nlminb() with
> > box-constraints to ensure that all parameters are positive. However,
> > nlminb() is behaving strangely and seems to supply NaN as parameters
> > to my objective function (confirmed using browser()) and output the
> > following:
> >
> > $par
> >  [1] NaN NaN NaN   0 NaN   0 NaN NaN NaN NaN NaN NaN NaN
> >
> > $objective
> > [1] 0
> >
> > $convergence
> > [1] 1
> >
> > $iterations
> > [1] 19
> >
> > $evaluations
> > function gradient
> >       87      542
> >
> > $message
> > [1] "gr cannot be computed at initial par (65)"
> >
> >
> > When I use trace = TRUE, I can see the following:
> >
> >   0:     32495.488: 0.0917404 0.703453  1.89661 1.11022e-16
> > 1.11022e-16 0.107479 1.11022e-16 1.11022e-16 1.11022e-16 0.472377
> > 0.894128  1.86743 1.11022e-16
> >   1:     4035.3900: 0.0917404 0.703453  1.89661 1.11022e-16
> > 1.11022e-16 0.107479 1.11022e-16 1.11022e-16 1.11022e-16 0.472377
> > 0.894128  1.86743 0.250000
> >   2:     3955.8801: 0.0948452 0.704168  1.89651 0.000135456 0.0310485
> > 0.107991 0.00138902 0.000427631 1.11022e-16 0.472331 0.894128  1.86743
> > 0.250000
> >   3:     3951.4141: 0.0948926 0.703906  1.89640 2.99167e-05 0.0315288
> > 0.109692 0.00242572 0.00272185 7.96814e-05 0.472780 0.894130  1.86744
> > 0.249998
> > ....
> >  17:     3937.3923: 0.0947470 0.703030  1.89605 1.11022e-16 0.0300763
> > 0.115081 0.00562496 0.00989997 0.000323268 0.474247 0.894142  1.86745
> > 0.249737
> >  18:     3937.3923: 0.0947470 0.703030  1.89605 1.11022e-16 0.0300763
> > 0.115081 0.00562496 0.00989997 0.000323268 0.474247 0.894142  1.86745
> > 0.249737
> >  19:    -0.0000000:     -nan     -nan     -nan 1.11022e-16     -nan
> >  -nan     -nan     -nan     -nan     -nan     -nan     -nan      nan
> >
> >
> > my objective function looks like:
> >
> > nLL <- function(params){
> >
> >   mu <- drop(model.matrix(modelTermsObj) %*% params)
> >
> >   if(any(mu < 0) || anyNA(mu) || any(is.infinite(mu))){
> >     return(.Machine$double.xmax)
> >   } else {
> >     return(-sum(dnbinom(x=args$data[,response], mu = mu, size =
> > params[length(params)], log = TRUE)))
> >   }
> > }
> >
> > I tried different starting values, different bounds but without
> > success so far. Is this a bug?
> >
> > PS after trying to make a reproducible example that I gracefully
> > failed to do... I change my objective function so instead of using
> > model.matrix(), I did the maths (e.g. Y ~ A + B * C). Thus, mu is now
> > a bunch of NaN, and my objective function return .Machine$double.xmax
> > which is fine. Then nlminb stops and returns (like if nothing
> > happened):
> >
> > $par
> >  [1] 1.11022e-16 1.11022e-16 2.69205e-04 1.11022e-16 1.68161e-03
> > 1.06027e-03 1.16969e-05 1.11022e-16 8.51669e+01 7.31162e+01
> > 5.04748e+00 5.28373e+00 1.23992e-01
> >
> > $objective
> > [1] 3823.567
> >
> > $convergence
> > [1] 0
> >
> > $iterations
> > [1] 1
> >
> > $evaluations
> > function gradient
> >        2       13
> >
> > $message
> > [1] "X-convergence (3)"
> >
> > I can provide the data and model if necessary but cannot make them
> > publicly available (yet).
> >
> > Thank you,
> >
> > Jean
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From clint at ecy.wa.gov  Thu May  7 23:16:07 2015
From: clint at ecy.wa.gov (Clint Bowman)
Date: Thu, 7 May 2015 14:16:07 -0700 (PDT)
Subject: [R] Calling Function With Arguments In a Script
In-Reply-To: <alpine.LNX.2.11.1505071341360.11430@localhost>
References: <alpine.LNX.2.11.1505071341360.11430@localhost>
Message-ID: <alpine.LRH.2.11.1505071414070.22522@aeolus.ecy.wa.gov>

?source

as in source("pairwise-plots-continuous-vars.R")

then

plotpairs(first,second,third,wise,title)

should get you going

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Thu, 7 May 2015, Rich Shepard wrote:

>  I'm starting to put code in multi-use functions rather than in individual
> scripts and have not learned how to invoke the function from the command
> line. If this information is in Norman Matloff's 'The Art of R Programming'
> or Hadley Wickham's 'Advanced R' please point me to the proper place.
>
>  Here's an example, the script 'pairwise-plots-continuous-vars.R' consists
> of this function:
>
> plotpairs <- function(x1,x2,x3,y,plotmain) {
>     require(compositions)
>     opar <- par(mar=c(4,4,3,1))
>     NO3 <- x1
>     SO4 <- x2
>     pH <- x3
>     pairwisePlot(cbind(NO3,SO4,pH),clr(y),add.line=T)
>     title(main=plotmain)
>     par(opar)
>     detach('package:compositions')
>     return()
> }
>
>  (I suppose the return statement is superfluous since there is no value
> returned to a calling function.)
>
>  What I want to do is call plotpairs() with appropriate arguments for each
> plot as needed.
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From gunter.berton at gene.com  Thu May  7 23:44:30 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 7 May 2015 14:44:30 -0700
Subject: [R] Calling Function With Arguments In a Script
In-Reply-To: <alpine.LNX.2.11.1505071341360.11430@localhost>
References: <alpine.LNX.2.11.1505071341360.11430@localhost>
Message-ID: <CACk-te3_oYJFCxbub43-MxGEqCr5TsMB+tqk=uzoHZHS+uXH2A@mail.gmail.com>

See e.g. Chapter 10.4 in the "Intro to R Tutorial" on the "..." argument.

The general idea is to define your function as:

myfun <- function (named_arguments,...)
{
# Some code
## now call your function as
pairwisePlot(some_named_arguments,...)
}

You would then call myfun with the ...'s replaced by name=value
argument pairs for your pairwisePlot function. e.g.

myfun(named_arguments, arg1= value1, arg2=value2, etc.)

where the arg1, arg2, etc. arguments would be arguments for
pairwisePlot() passed down to it as ... arguments.

Not hard, really, once you see how it works. (I suppose that's a
tautology, though -- probably what physicists say about General
Relativity).

Incidentally, you could even have functions as arbitrary arguments to
myfun and ... contain the argument lists for the function, something
like:

myfunc <- function(fun,...) {fun(...) }

Think of the flexibility this gives! One of the glories of functional
programming -- functions are first class objects that can be used as
arguments just like anything else.

Cheers,
Bert


Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, May 7, 2015 at 1:50 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>   I'm starting to put code in multi-use functions rather than in individual
> scripts and have not learned how to invoke the function from the command
> line. If this information is in Norman Matloff's 'The Art of R Programming'
> or Hadley Wickham's 'Advanced R' please point me to the proper place.
>
>   Here's an example, the script 'pairwise-plots-continuous-vars.R' consists
> of this function:
>
> plotpairs <- function(x1,x2,x3,y,plotmain) {
>     require(compositions)
>     opar <- par(mar=c(4,4,3,1))
>     NO3 <- x1
>     SO4 <- x2
>     pH <- x3
>     pairwisePlot(cbind(NO3,SO4,pH),clr(y),add.line=T)
>     title(main=plotmain)
>     par(opar)
>     detach('package:compositions')
>     return()
> }
>
>   (I suppose the return statement is superfluous since there is no value
> returned to a calling function.)
>
>   What I want to do is call plotpairs() with appropriate arguments for each
> plot as needed.
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Thu May  7 23:50:46 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 7 May 2015 17:50:46 -0400
Subject: [R] Getting INDIVIDUAL effects of multiple qualitative
 variables (ordered and unordered factors)
In-Reply-To: <CAOy3Z4C2wu5uMprni1S0eRiCWoitduLvGSHfLg8xH4ucsvy=Aw@mail.gmail.com>
References: <CAOy3Z4C2wu5uMprni1S0eRiCWoitduLvGSHfLg8xH4ucsvy=Aw@mail.gmail.com>
Message-ID: <CAGx1TMDHuX=jCaD8LjHjeK9B-Of==c81d7cjXbQ4VjW130792Q@mail.gmail.com>

## I think this is what you are looking for.
## Your download host seems to want to give me software, so I am not taking it.

tmp <- data.frame(y=rnorm(20), a=factor(rep(letters[1:4], each=5)))

tmp.aov <- aov(y ~ a, data=tmp)

summary(tmp.aov)

summary(tmp.aov, split=list(a=list(b=1, c=2, d=3)))

summary.lm(tmp.aov)

Rich

On Thu, May 7, 2015 at 2:43 PM, Rafael Costa
<rafaelcarneirocosta.rc at gmail.com> wrote:
> Dear R users,
>
> I have data from a questionnaire and I want to estimate the individual
> effect of each explanatory variable (all are qualitative) on the dependent
> variable (continuous). However, the default is to consider the estimated
> coefficients as the difference between the reference group (estimated value
> of the intercept) and the coefficient of the group. Each qualitative
> variable relates to a characteristic of a particular activity and the
> continuous variable is the time taken to perform this activity. I emphasize
> that the reference level of each factor relates to the case where none of
> the options for that factor was marked. The data is in "
> http://www.datafilehost.com/d/c7f0d342". I did not put them in the script,
> because I still do not know how to do this, but I hope this is not a
> problem (and I ask my sincere apologies). I do not put just a sample of the
> data, since there was singular matrix problems.
>
>
>
> First (and main) issue - In order to obtain the individual effect of the
> levels of each factor, I considered that the reference group has zero
> effect and I did the following steps:
>
>
>
> # Since the file was not loaded in the script, it is assumed here that it
> was downloaded from the internet and is already loaded in R.
>
> # I will make a quantile regression, so the package follows.
>
> install.packages (quantreg)
>
> library (quantreg)
>
> # Transforming factors into individual objects:
>
> p_1 = table (1: length (tabela1.1 $ p1), as.factor (tabela1.1 $ p1))
>
> p_21 = table (1: length (tabela1.1 $ p21), as.factor (tabela1.1 $ p21))
>
> p_22 = table (1: length (tabela1.1 $ p22), as.factor (tabela1.1 $ p22))
>
> p_23 = table (1: length (tabela1.1 $ p23), as.factor (tabela1.1 $ p23))
>
> p_24 = table (1: length (tabela1.1 $ p24), as.factor (tabela1.1 $ p24))
>
> p_25 = table (1: length (tabela1.1 $ p25), as.factor (tabela1.1 $ p25))
>
> p_34 = table (1: length (tabela1.1 $ p34), as.ordered (tabela1.1 $ p34))
>
> p_5 = table (1: length (tabela1.1 $ p5), as.ordered (tabela1.1 $ p5))
>
> p_6 = table (1: length (tabela1.1 $ p6), as.ordered (tabela1.1 $ p6))
>
> p_7 = table (1: length (tabela1.1 $ p7), as.ordered (tabela1.1 $ p7))
>
> p_8 = table (1: length (tabela1.1 $ p8), as.ordered (tabela1.1 $ p8))
>
> p_9 = table (1: length (tabela1.1 $ p9), as.ordered (tabela1.1 $ p9))
>
> # Regressing the model without intercept, but considering that the
> reference group = 0, considering that the reference group means that none
> of the factors has been marked (if any was marked, I believe that the time
> taken to perform the activity is practically zero).
>
> qrModel=rq(data=tabela1.1, pontoefetivo ~ 0 + p_1[,-1] + p_21[,-1] +
> p_22[,-1] + p_23[,-1] + p_24[,-1] + p_25[,-1] + p_34[,-1] + p_5[,-1] +
> p_6[,-1] + p_7[,-1] + p_8[,-1] + p_9[,-1], tau=0.5)
>
> summary(qrModel)
>
> My idea was that since the effect of the reference group is zero, the
> estimated coefficient of each level is precisely the individual effect of
> the chosen variable level. My idea is right? If not, what do I do to get
> these individual effects?
>
>
>
> Problem 2 - Assuming all is right above, ordered factors not have
> increasing effects [See summary (qrModel)]. But should not they have? If
> so, what do I do to ensure such an effect?
>
>
>
> Problem 3 - Again assuming that everything is correct, I hope that any
> estimated coefficients (individual effects on the runtime of the activity)
> are not negative values. Am I right about that? If so, what do I do to
> ensure that all values are not negative?
>
>
> I am looking forward  any help.
>
> Thanks in advance ,
>
> Rafael Costa.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rshepard at appl-ecosys.com  Thu May  7 23:50:46 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 7 May 2015 14:50:46 -0700 (PDT)
Subject: [R] Calling Function With Arguments In a Script
In-Reply-To: <alpine.LRH.2.11.1505071414070.22522@aeolus.ecy.wa.gov>
References: <alpine.LNX.2.11.1505071341360.11430@localhost>
	<alpine.LRH.2.11.1505071414070.22522@aeolus.ecy.wa.gov>
Message-ID: <alpine.LNX.2.11.1505071448550.11430@localhost>

On Thu, 7 May 2015, Clint Bowman wrote:

> as in source("pairwise-plots-continuous-vars.R")

Clint,

   I did this before converting it to a function, when I modified the
variables in the script. Did not try it as a function, should have.

Thanks,

Rich


From rshepard at appl-ecosys.com  Thu May  7 23:52:16 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 7 May 2015 14:52:16 -0700 (PDT)
Subject: [R] Calling Function With Arguments In a Script
In-Reply-To: <CACk-te3_oYJFCxbub43-MxGEqCr5TsMB+tqk=uzoHZHS+uXH2A@mail.gmail.com>
References: <alpine.LNX.2.11.1505071341360.11430@localhost>
	<CACk-te3_oYJFCxbub43-MxGEqCr5TsMB+tqk=uzoHZHS+uXH2A@mail.gmail.com>
Message-ID: <alpine.LNX.2.11.1505071451180.11430@localhost>

On Thu, 7 May 2015, Bert Gunter wrote:

> See e.g. Chapter 10.4 in the "Intro to R Tutorial" on the "..." argument.

Bert,

   Thanks. That was going to be my next step.

Much appreciated,

Rich


From jean.d.marchal at gmail.com  Fri May  8 01:46:50 2015
From: jean.d.marchal at gmail.com (Jean Marchal)
Date: Thu, 7 May 2015 16:46:50 -0700
Subject: [R] nlminb supplying NaN parameters to objective function
In-Reply-To: <CAF8bMcbscS2hjAws=4WqxONyc0Ma-zjkToZOTZtRBM2erpC7dg@mail.gmail.com>
References: <CACF6B3WqQ4uhPS-_Yk60G8wSPQ80=-PsWa2OQY4HgbyNkJuuww@mail.gmail.com>
	<CACF6B3V7w1i1d22Mk77fpvTrdz_0f0irQgPR9A5o7Yn1qJR3=g@mail.gmail.com>
	<CAF8bMcbscS2hjAws=4WqxONyc0Ma-zjkToZOTZtRBM2erpC7dg@mail.gmail.com>
Message-ID: <CACF6B3X3NwUmykUd+jGp4SAzC=qdcSKUNLEPxOVmkjvX_wFh0Q@mail.gmail.com>

Yes, indeed! Problem solved!

Thanks a lot!

Jean

2015-05-07 14:06 GMT-07:00 William Dunlap <wdunlap at tibco.com>:
> Your nLL function returns 1e+308 in near-boundary cases.  Since 1e+308 is so
> close to machine infinity, it is easy to get into Inf-Inf (=NaN) or Inf/Inf
> (=NaN)
> situations when working with it.  Try making that limiting value something
> smaller,
> like 1e+30, and you may have better luck.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, May 7, 2015 at 1:14 PM, Jean Marchal <jean.d.marchal at gmail.com>
> wrote:
>>
>> A follow-up to my yesterday's email.
>>
>> I was able to make a reproducible example. All you will have to do is
>> load the .RData file that you can download here:
>>
>> https://drive.google.com/file/d/0B0DKwRjF11x4dG1uRWhwb1pfQ2s/view?usp=sharing
>>
>> and run this line of code:
>>
>> nlminb(start=sv, objective = nLL, lower = 0, upper = Inf,
>> control=list(trace=TRUE))
>>
>> which output the following:
>>
>>   0:     12523.401: 0.0328502 0.0744493 0.00205298 0.0248628 0.0881807
>> 0.0148887 0.0244485 0.0385922 0.0714495 0.0161784 0.0617551 0.0244901
>> 0.0784038
>>   1:     12421.888: 0.0282245 0.0697934  0.00000 0.0199076 0.0833634
>> 0.0101135 0.0189494 0.0336236 0.0712130 0.0160687 0.0616015 0.0244689
>> 0.0660129
>>   2:     12050.535: 0.00371847 0.0451786  0.00000  0.00000 0.0575667
>> 0.00000  0.00000 0.00697067 0.0697205 0.0156250 0.0608550 0.0243431
>> 0.0994355
>>   3:     12037.682: 0.00303460 0.0445012  0.00000  0.00000 0.0568530
>> 0.00000  0.00000 0.00636016 0.0696959 0.0156250 0.0608550 0.0243419
>> 0.0988824
>>   4:     12012.684: 0.00164710 0.0431313  0.00000  0.00000 0.0554032
>> 0.00000  0.00000 0.00515500 0.0696451 0.0156250 0.0608550 0.0243395
>> 0.0978328
>>   5:     12003.017: 0.00107848 0.0425739  0.00000  0.00000 0.0548073
>> 0.00000  0.00000 0.00469592 0.0696233 0.0156250 0.0608550 0.0243386
>> 0.0974616
>>   6:     11984.372:  0.00000 0.0414397  0.00000  0.00000 0.0535899
>> 0.00000  0.00000 0.00378996 0.0695782 0.0156250 0.0608550 0.0243370
>> 0.0967449
>>   7:     11978.154:  0.00000 0.0409106  0.00000  0.00000 0.0530158
>> 0.00000  0.00000 0.00340746 0.0695560 0.0156250 0.0608550 0.0243363
>> 0.0964537
>>   8:    -0.0000000:  0.00000      nan  0.00000  0.00000      nan
>> 0.00000  0.00000      nan      nan      nan      nan      nan      nan
>>
>> Regards,
>>
>> Jean
>>
>> 2015-05-06 17:43 GMT-07:00 Jean Marchal <jean.d.marchal at gmail.com>:
>> > Dear list,
>> >
>> > I am doing some maximum likelihood estimation using nlminb() with
>> > box-constraints to ensure that all parameters are positive. However,
>> > nlminb() is behaving strangely and seems to supply NaN as parameters
>> > to my objective function (confirmed using browser()) and output the
>> > following:
>> >
>> > $par
>> >  [1] NaN NaN NaN   0 NaN   0 NaN NaN NaN NaN NaN NaN NaN
>> >
>> > $objective
>> > [1] 0
>> >
>> > $convergence
>> > [1] 1
>> >
>> > $iterations
>> > [1] 19
>> >
>> > $evaluations
>> > function gradient
>> >       87      542
>> >
>> > $message
>> > [1] "gr cannot be computed at initial par (65)"
>> >
>> >
>> > When I use trace = TRUE, I can see the following:
>> >
>> >   0:     32495.488: 0.0917404 0.703453  1.89661 1.11022e-16
>> > 1.11022e-16 0.107479 1.11022e-16 1.11022e-16 1.11022e-16 0.472377
>> > 0.894128  1.86743 1.11022e-16
>> >   1:     4035.3900: 0.0917404 0.703453  1.89661 1.11022e-16
>> > 1.11022e-16 0.107479 1.11022e-16 1.11022e-16 1.11022e-16 0.472377
>> > 0.894128  1.86743 0.250000
>> >   2:     3955.8801: 0.0948452 0.704168  1.89651 0.000135456 0.0310485
>> > 0.107991 0.00138902 0.000427631 1.11022e-16 0.472331 0.894128  1.86743
>> > 0.250000
>> >   3:     3951.4141: 0.0948926 0.703906  1.89640 2.99167e-05 0.0315288
>> > 0.109692 0.00242572 0.00272185 7.96814e-05 0.472780 0.894130  1.86744
>> > 0.249998
>> > ....
>> >  17:     3937.3923: 0.0947470 0.703030  1.89605 1.11022e-16 0.0300763
>> > 0.115081 0.00562496 0.00989997 0.000323268 0.474247 0.894142  1.86745
>> > 0.249737
>> >  18:     3937.3923: 0.0947470 0.703030  1.89605 1.11022e-16 0.0300763
>> > 0.115081 0.00562496 0.00989997 0.000323268 0.474247 0.894142  1.86745
>> > 0.249737
>> >  19:    -0.0000000:     -nan     -nan     -nan 1.11022e-16     -nan
>> >  -nan     -nan     -nan     -nan     -nan     -nan     -nan      nan
>> >
>> >
>> > my objective function looks like:
>> >
>> > nLL <- function(params){
>> >
>> >   mu <- drop(model.matrix(modelTermsObj) %*% params)
>> >
>> >   if(any(mu < 0) || anyNA(mu) || any(is.infinite(mu))){
>> >     return(.Machine$double.xmax)
>> >   } else {
>> >     return(-sum(dnbinom(x=args$data[,response], mu = mu, size =
>> > params[length(params)], log = TRUE)))
>> >   }
>> > }
>> >
>> > I tried different starting values, different bounds but without
>> > success so far. Is this a bug?
>> >
>> > PS after trying to make a reproducible example that I gracefully
>> > failed to do... I change my objective function so instead of using
>> > model.matrix(), I did the maths (e.g. Y ~ A + B * C). Thus, mu is now
>> > a bunch of NaN, and my objective function return .Machine$double.xmax
>> > which is fine. Then nlminb stops and returns (like if nothing
>> > happened):
>> >
>> > $par
>> >  [1] 1.11022e-16 1.11022e-16 2.69205e-04 1.11022e-16 1.68161e-03
>> > 1.06027e-03 1.16969e-05 1.11022e-16 8.51669e+01 7.31162e+01
>> > 5.04748e+00 5.28373e+00 1.23992e-01
>> >
>> > $objective
>> > [1] 3823.567
>> >
>> > $convergence
>> > [1] 0
>> >
>> > $iterations
>> > [1] 1
>> >
>> > $evaluations
>> > function gradient
>> >        2       13
>> >
>> > $message
>> > [1] "X-convergence (3)"
>> >
>> > I can provide the data and model if necessary but cannot make them
>> > publicly available (yet).
>> >
>> > Thank you,
>> >
>> > Jean
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From wdunlap at tibco.com  Fri May  8 02:03:53 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 7 May 2015 17:03:53 -0700
Subject: [R] nlminb supplying NaN parameters to objective function
In-Reply-To: <CACF6B3X3NwUmykUd+jGp4SAzC=qdcSKUNLEPxOVmkjvX_wFh0Q@mail.gmail.com>
References: <CACF6B3WqQ4uhPS-_Yk60G8wSPQ80=-PsWa2OQY4HgbyNkJuuww@mail.gmail.com>
	<CACF6B3V7w1i1d22Mk77fpvTrdz_0f0irQgPR9A5o7Yn1qJR3=g@mail.gmail.com>
	<CAF8bMcbscS2hjAws=4WqxONyc0Ma-zjkToZOTZtRBM2erpC7dg@mail.gmail.com>
	<CACF6B3X3NwUmykUd+jGp4SAzC=qdcSKUNLEPxOVmkjvX_wFh0Q@mail.gmail.com>
Message-ID: <CAF8bMca55gtXr_zb4aYerHHkF2SDz+kc5myp7oJbJWfKRK1qiQ@mail.gmail.com>

Your immediate problem may be solved, but the exact value of that limiting
value
affects the parameter estimates a fair bit.  I have not really looked at
your function,
but the ledge around it puts a kink (discontinuous first derivative) into
it, which can
mess up optimizers.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, May 7, 2015 at 4:46 PM, Jean Marchal <jean.d.marchal at gmail.com>
wrote:

> Yes, indeed! Problem solved!
>
> Thanks a lot!
>
> Jean
>
> 2015-05-07 14:06 GMT-07:00 William Dunlap <wdunlap at tibco.com>:
> > Your nLL function returns 1e+308 in near-boundary cases.  Since 1e+308
> is so
> > close to machine infinity, it is easy to get into Inf-Inf (=NaN) or
> Inf/Inf
> > (=NaN)
> > situations when working with it.  Try making that limiting value
> something
> > smaller,
> > like 1e+30, and you may have better luck.
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Thu, May 7, 2015 at 1:14 PM, Jean Marchal <jean.d.marchal at gmail.com>
> > wrote:
> >>
> >> A follow-up to my yesterday's email.
> >>
> >> I was able to make a reproducible example. All you will have to do is
> >> load the .RData file that you can download here:
> >>
> >>
> https://drive.google.com/file/d/0B0DKwRjF11x4dG1uRWhwb1pfQ2s/view?usp=sharing
> >>
> >> and run this line of code:
> >>
> >> nlminb(start=sv, objective = nLL, lower = 0, upper = Inf,
> >> control=list(trace=TRUE))
> >>
> >> which output the following:
> >>
> >>   0:     12523.401: 0.0328502 0.0744493 0.00205298 0.0248628 0.0881807
> >> 0.0148887 0.0244485 0.0385922 0.0714495 0.0161784 0.0617551 0.0244901
> >> 0.0784038
> >>   1:     12421.888: 0.0282245 0.0697934  0.00000 0.0199076 0.0833634
> >> 0.0101135 0.0189494 0.0336236 0.0712130 0.0160687 0.0616015 0.0244689
> >> 0.0660129
> >>   2:     12050.535: 0.00371847 0.0451786  0.00000  0.00000 0.0575667
> >> 0.00000  0.00000 0.00697067 0.0697205 0.0156250 0.0608550 0.0243431
> >> 0.0994355
> >>   3:     12037.682: 0.00303460 0.0445012  0.00000  0.00000 0.0568530
> >> 0.00000  0.00000 0.00636016 0.0696959 0.0156250 0.0608550 0.0243419
> >> 0.0988824
> >>   4:     12012.684: 0.00164710 0.0431313  0.00000  0.00000 0.0554032
> >> 0.00000  0.00000 0.00515500 0.0696451 0.0156250 0.0608550 0.0243395
> >> 0.0978328
> >>   5:     12003.017: 0.00107848 0.0425739  0.00000  0.00000 0.0548073
> >> 0.00000  0.00000 0.00469592 0.0696233 0.0156250 0.0608550 0.0243386
> >> 0.0974616
> >>   6:     11984.372:  0.00000 0.0414397  0.00000  0.00000 0.0535899
> >> 0.00000  0.00000 0.00378996 0.0695782 0.0156250 0.0608550 0.0243370
> >> 0.0967449
> >>   7:     11978.154:  0.00000 0.0409106  0.00000  0.00000 0.0530158
> >> 0.00000  0.00000 0.00340746 0.0695560 0.0156250 0.0608550 0.0243363
> >> 0.0964537
> >>   8:    -0.0000000:  0.00000      nan  0.00000  0.00000      nan
> >> 0.00000  0.00000      nan      nan      nan      nan      nan      nan
> >>
> >> Regards,
> >>
> >> Jean
> >>
> >> 2015-05-06 17:43 GMT-07:00 Jean Marchal <jean.d.marchal at gmail.com>:
> >> > Dear list,
> >> >
> >> > I am doing some maximum likelihood estimation using nlminb() with
> >> > box-constraints to ensure that all parameters are positive. However,
> >> > nlminb() is behaving strangely and seems to supply NaN as parameters
> >> > to my objective function (confirmed using browser()) and output the
> >> > following:
> >> >
> >> > $par
> >> >  [1] NaN NaN NaN   0 NaN   0 NaN NaN NaN NaN NaN NaN NaN
> >> >
> >> > $objective
> >> > [1] 0
> >> >
> >> > $convergence
> >> > [1] 1
> >> >
> >> > $iterations
> >> > [1] 19
> >> >
> >> > $evaluations
> >> > function gradient
> >> >       87      542
> >> >
> >> > $message
> >> > [1] "gr cannot be computed at initial par (65)"
> >> >
> >> >
> >> > When I use trace = TRUE, I can see the following:
> >> >
> >> >   0:     32495.488: 0.0917404 0.703453  1.89661 1.11022e-16
> >> > 1.11022e-16 0.107479 1.11022e-16 1.11022e-16 1.11022e-16 0.472377
> >> > 0.894128  1.86743 1.11022e-16
> >> >   1:     4035.3900: 0.0917404 0.703453  1.89661 1.11022e-16
> >> > 1.11022e-16 0.107479 1.11022e-16 1.11022e-16 1.11022e-16 0.472377
> >> > 0.894128  1.86743 0.250000
> >> >   2:     3955.8801: 0.0948452 0.704168  1.89651 0.000135456 0.0310485
> >> > 0.107991 0.00138902 0.000427631 1.11022e-16 0.472331 0.894128  1.86743
> >> > 0.250000
> >> >   3:     3951.4141: 0.0948926 0.703906  1.89640 2.99167e-05 0.0315288
> >> > 0.109692 0.00242572 0.00272185 7.96814e-05 0.472780 0.894130  1.86744
> >> > 0.249998
> >> > ....
> >> >  17:     3937.3923: 0.0947470 0.703030  1.89605 1.11022e-16 0.0300763
> >> > 0.115081 0.00562496 0.00989997 0.000323268 0.474247 0.894142  1.86745
> >> > 0.249737
> >> >  18:     3937.3923: 0.0947470 0.703030  1.89605 1.11022e-16 0.0300763
> >> > 0.115081 0.00562496 0.00989997 0.000323268 0.474247 0.894142  1.86745
> >> > 0.249737
> >> >  19:    -0.0000000:     -nan     -nan     -nan 1.11022e-16     -nan
> >> >  -nan     -nan     -nan     -nan     -nan     -nan     -nan      nan
> >> >
> >> >
> >> > my objective function looks like:
> >> >
> >> > nLL <- function(params){
> >> >
> >> >   mu <- drop(model.matrix(modelTermsObj) %*% params)
> >> >
> >> >   if(any(mu < 0) || anyNA(mu) || any(is.infinite(mu))){
> >> >     return(.Machine$double.xmax)
> >> >   } else {
> >> >     return(-sum(dnbinom(x=args$data[,response], mu = mu, size =
> >> > params[length(params)], log = TRUE)))
> >> >   }
> >> > }
> >> >
> >> > I tried different starting values, different bounds but without
> >> > success so far. Is this a bug?
> >> >
> >> > PS after trying to make a reproducible example that I gracefully
> >> > failed to do... I change my objective function so instead of using
> >> > model.matrix(), I did the maths (e.g. Y ~ A + B * C). Thus, mu is now
> >> > a bunch of NaN, and my objective function return .Machine$double.xmax
> >> > which is fine. Then nlminb stops and returns (like if nothing
> >> > happened):
> >> >
> >> > $par
> >> >  [1] 1.11022e-16 1.11022e-16 2.69205e-04 1.11022e-16 1.68161e-03
> >> > 1.06027e-03 1.16969e-05 1.11022e-16 8.51669e+01 7.31162e+01
> >> > 5.04748e+00 5.28373e+00 1.23992e-01
> >> >
> >> > $objective
> >> > [1] 3823.567
> >> >
> >> > $convergence
> >> > [1] 0
> >> >
> >> > $iterations
> >> > [1] 1
> >> >
> >> > $evaluations
> >> > function gradient
> >> >        2       13
> >> >
> >> > $message
> >> > [1] "X-convergence (3)"
> >> >
> >> > I can provide the data and model if necessary but cannot make them
> >> > publicly available (yet).
> >> >
> >> > Thank you,
> >> >
> >> > Jean
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri May  8 02:31:10 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 07 May 2015 17:31:10 -0700
Subject: [R] Calling Function With Arguments In a Script
In-Reply-To: <alpine.LNX.2.11.1505071448550.11430@localhost>
References: <alpine.LNX.2.11.1505071341360.11430@localhost>
	<alpine.LRH.2.11.1505071414070.22522@aeolus.ecy.wa.gov>
	<alpine.LNX.2.11.1505071448550.11430@localhost>
Message-ID: <750DBC07-F7CD-42E0-97DD-A3C8D806738C@dcn.davis.CA.us>

I don't know what your work flow looks like, but I certainly do not equate "writing R with functions" to "passing parameters at the command line".  Rather, these seem quite orthogonal to me. I often have one R file of functions, and another R file where I source the first file and keep a record of various invocations of those functions as I identify which parameter values answer questions I have, and I copy those to an interactive R console session for testing. 

I would find the operating system command line an uncomfortable place to experiment with those parameter values because I often want to use R to repeatedly invoke those functions with range of values and then plot those results.

In fact, I can hardly imagine a scenario where I wanted to specify arguments when invoking my R script from the command line, since I can examine the status of the system clock, files and databases from inside R to determine what needed to be done next if I wanted to invoke a script automatically. I would only want to do that if I planned to call R from another scripting language, and I haven't needed to do that yet.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 7, 2015 2:50:46 PM PDT, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>On Thu, 7 May 2015, Clint Bowman wrote:
>
>> as in source("pairwise-plots-continuous-vars.R")
>
>Clint,
>
>   I did this before converting it to a function, when I modified the
>variables in the script. Did not try it as a function, should have.
>
>Thanks,
>
>Rich
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jean.d.marchal at gmail.com  Fri May  8 02:37:59 2015
From: jean.d.marchal at gmail.com (Jean Marchal)
Date: Thu, 7 May 2015 17:37:59 -0700
Subject: [R] nlminb supplying NaN parameters to objective function
In-Reply-To: <CAF8bMca55gtXr_zb4aYerHHkF2SDz+kc5myp7oJbJWfKRK1qiQ@mail.gmail.com>
References: <CACF6B3WqQ4uhPS-_Yk60G8wSPQ80=-PsWa2OQY4HgbyNkJuuww@mail.gmail.com>
	<CACF6B3V7w1i1d22Mk77fpvTrdz_0f0irQgPR9A5o7Yn1qJR3=g@mail.gmail.com>
	<CAF8bMcbscS2hjAws=4WqxONyc0Ma-zjkToZOTZtRBM2erpC7dg@mail.gmail.com>
	<CACF6B3X3NwUmykUd+jGp4SAzC=qdcSKUNLEPxOVmkjvX_wFh0Q@mail.gmail.com>
	<CAF8bMca55gtXr_zb4aYerHHkF2SDz+kc5myp7oJbJWfKRK1qiQ@mail.gmail.com>
Message-ID: <CACF6B3XmB3d6D9phwDTY+7g0NGLkVRVxY1p29wsij4A5PgMUrg@mail.gmail.com>

Thanks for the advice! I will continue to monitor the optimizer behaviour.

Jean

2015-05-07 17:03 GMT-07:00 William Dunlap <wdunlap at tibco.com>:
> Your immediate problem may be solved, but the exact value of that limiting
> value
> affects the parameter estimates a fair bit.  I have not really looked at
> your function,
> but the ledge around it puts a kink (discontinuous first derivative) into
> it, which can
> mess up optimizers.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, May 7, 2015 at 4:46 PM, Jean Marchal <jean.d.marchal at gmail.com>
> wrote:
>>
>> Yes, indeed! Problem solved!
>>
>> Thanks a lot!
>>
>> Jean
>>
>> 2015-05-07 14:06 GMT-07:00 William Dunlap <wdunlap at tibco.com>:
>> > Your nLL function returns 1e+308 in near-boundary cases.  Since 1e+308
>> > is so
>> > close to machine infinity, it is easy to get into Inf-Inf (=NaN) or
>> > Inf/Inf
>> > (=NaN)
>> > situations when working with it.  Try making that limiting value
>> > something
>> > smaller,
>> > like 1e+30, and you may have better luck.
>> >
>> > Bill Dunlap
>> > TIBCO Software
>> > wdunlap tibco.com
>> >
>> > On Thu, May 7, 2015 at 1:14 PM, Jean Marchal <jean.d.marchal at gmail.com>
>> > wrote:
>> >>
>> >> A follow-up to my yesterday's email.
>> >>
>> >> I was able to make a reproducible example. All you will have to do is
>> >> load the .RData file that you can download here:
>> >>
>> >>
>> >> https://drive.google.com/file/d/0B0DKwRjF11x4dG1uRWhwb1pfQ2s/view?usp=sharing
>> >>
>> >> and run this line of code:
>> >>
>> >> nlminb(start=sv, objective = nLL, lower = 0, upper = Inf,
>> >> control=list(trace=TRUE))
>> >>
>> >> which output the following:
>> >>
>> >>   0:     12523.401: 0.0328502 0.0744493 0.00205298 0.0248628 0.0881807
>> >> 0.0148887 0.0244485 0.0385922 0.0714495 0.0161784 0.0617551 0.0244901
>> >> 0.0784038
>> >>   1:     12421.888: 0.0282245 0.0697934  0.00000 0.0199076 0.0833634
>> >> 0.0101135 0.0189494 0.0336236 0.0712130 0.0160687 0.0616015 0.0244689
>> >> 0.0660129
>> >>   2:     12050.535: 0.00371847 0.0451786  0.00000  0.00000 0.0575667
>> >> 0.00000  0.00000 0.00697067 0.0697205 0.0156250 0.0608550 0.0243431
>> >> 0.0994355
>> >>   3:     12037.682: 0.00303460 0.0445012  0.00000  0.00000 0.0568530
>> >> 0.00000  0.00000 0.00636016 0.0696959 0.0156250 0.0608550 0.0243419
>> >> 0.0988824
>> >>   4:     12012.684: 0.00164710 0.0431313  0.00000  0.00000 0.0554032
>> >> 0.00000  0.00000 0.00515500 0.0696451 0.0156250 0.0608550 0.0243395
>> >> 0.0978328
>> >>   5:     12003.017: 0.00107848 0.0425739  0.00000  0.00000 0.0548073
>> >> 0.00000  0.00000 0.00469592 0.0696233 0.0156250 0.0608550 0.0243386
>> >> 0.0974616
>> >>   6:     11984.372:  0.00000 0.0414397  0.00000  0.00000 0.0535899
>> >> 0.00000  0.00000 0.00378996 0.0695782 0.0156250 0.0608550 0.0243370
>> >> 0.0967449
>> >>   7:     11978.154:  0.00000 0.0409106  0.00000  0.00000 0.0530158
>> >> 0.00000  0.00000 0.00340746 0.0695560 0.0156250 0.0608550 0.0243363
>> >> 0.0964537
>> >>   8:    -0.0000000:  0.00000      nan  0.00000  0.00000      nan
>> >> 0.00000  0.00000      nan      nan      nan      nan      nan      nan
>> >>
>> >> Regards,
>> >>
>> >> Jean
>> >>
>> >> 2015-05-06 17:43 GMT-07:00 Jean Marchal <jean.d.marchal at gmail.com>:
>> >> > Dear list,
>> >> >
>> >> > I am doing some maximum likelihood estimation using nlminb() with
>> >> > box-constraints to ensure that all parameters are positive. However,
>> >> > nlminb() is behaving strangely and seems to supply NaN as parameters
>> >> > to my objective function (confirmed using browser()) and output the
>> >> > following:
>> >> >
>> >> > $par
>> >> >  [1] NaN NaN NaN   0 NaN   0 NaN NaN NaN NaN NaN NaN NaN
>> >> >
>> >> > $objective
>> >> > [1] 0
>> >> >
>> >> > $convergence
>> >> > [1] 1
>> >> >
>> >> > $iterations
>> >> > [1] 19
>> >> >
>> >> > $evaluations
>> >> > function gradient
>> >> >       87      542
>> >> >
>> >> > $message
>> >> > [1] "gr cannot be computed at initial par (65)"
>> >> >
>> >> >
>> >> > When I use trace = TRUE, I can see the following:
>> >> >
>> >> >   0:     32495.488: 0.0917404 0.703453  1.89661 1.11022e-16
>> >> > 1.11022e-16 0.107479 1.11022e-16 1.11022e-16 1.11022e-16 0.472377
>> >> > 0.894128  1.86743 1.11022e-16
>> >> >   1:     4035.3900: 0.0917404 0.703453  1.89661 1.11022e-16
>> >> > 1.11022e-16 0.107479 1.11022e-16 1.11022e-16 1.11022e-16 0.472377
>> >> > 0.894128  1.86743 0.250000
>> >> >   2:     3955.8801: 0.0948452 0.704168  1.89651 0.000135456 0.0310485
>> >> > 0.107991 0.00138902 0.000427631 1.11022e-16 0.472331 0.894128
>> >> > 1.86743
>> >> > 0.250000
>> >> >   3:     3951.4141: 0.0948926 0.703906  1.89640 2.99167e-05 0.0315288
>> >> > 0.109692 0.00242572 0.00272185 7.96814e-05 0.472780 0.894130  1.86744
>> >> > 0.249998
>> >> > ....
>> >> >  17:     3937.3923: 0.0947470 0.703030  1.89605 1.11022e-16 0.0300763
>> >> > 0.115081 0.00562496 0.00989997 0.000323268 0.474247 0.894142  1.86745
>> >> > 0.249737
>> >> >  18:     3937.3923: 0.0947470 0.703030  1.89605 1.11022e-16 0.0300763
>> >> > 0.115081 0.00562496 0.00989997 0.000323268 0.474247 0.894142  1.86745
>> >> > 0.249737
>> >> >  19:    -0.0000000:     -nan     -nan     -nan 1.11022e-16     -nan
>> >> >  -nan     -nan     -nan     -nan     -nan     -nan     -nan      nan
>> >> >
>> >> >
>> >> > my objective function looks like:
>> >> >
>> >> > nLL <- function(params){
>> >> >
>> >> >   mu <- drop(model.matrix(modelTermsObj) %*% params)
>> >> >
>> >> >   if(any(mu < 0) || anyNA(mu) || any(is.infinite(mu))){
>> >> >     return(.Machine$double.xmax)
>> >> >   } else {
>> >> >     return(-sum(dnbinom(x=args$data[,response], mu = mu, size =
>> >> > params[length(params)], log = TRUE)))
>> >> >   }
>> >> > }
>> >> >
>> >> > I tried different starting values, different bounds but without
>> >> > success so far. Is this a bug?
>> >> >
>> >> > PS after trying to make a reproducible example that I gracefully
>> >> > failed to do... I change my objective function so instead of using
>> >> > model.matrix(), I did the maths (e.g. Y ~ A + B * C). Thus, mu is now
>> >> > a bunch of NaN, and my objective function return .Machine$double.xmax
>> >> > which is fine. Then nlminb stops and returns (like if nothing
>> >> > happened):
>> >> >
>> >> > $par
>> >> >  [1] 1.11022e-16 1.11022e-16 2.69205e-04 1.11022e-16 1.68161e-03
>> >> > 1.06027e-03 1.16969e-05 1.11022e-16 8.51669e+01 7.31162e+01
>> >> > 5.04748e+00 5.28373e+00 1.23992e-01
>> >> >
>> >> > $objective
>> >> > [1] 3823.567
>> >> >
>> >> > $convergence
>> >> > [1] 0
>> >> >
>> >> > $iterations
>> >> > [1] 1
>> >> >
>> >> > $evaluations
>> >> > function gradient
>> >> >        2       13
>> >> >
>> >> > $message
>> >> > [1] "X-convergence (3)"
>> >> >
>> >> > I can provide the data and model if necessary but cannot make them
>> >> > publicly available (yet).
>> >> >
>> >> > Thank you,
>> >> >
>> >> > Jean
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>
>


From btyner at gmail.com  Fri May  8 04:30:11 2015
From: btyner at gmail.com (Benjamin Tyner)
Date: Thu, 07 May 2015 22:30:11 -0400
Subject: [R] package implementing continuous binomial?
In-Reply-To: <5425134B-6AA1-4246-BCD4-D4BE4BE2391B@comcast.net>
References: <554AC75A.8070708@gmail.com>
	<5425134B-6AA1-4246-BCD4-D4BE4BE2391B@comcast.net>
Message-ID: <554C1FB3.1030700@gmail.com>

Thanks David! I'll take a look at zipfR.

Regards
Ben

On 05/07/2015 03:10 PM, David Winsemius wrote:
> On May 6, 2015, at 7:00 PM, Benjamin Tyner wrote:
>
>> Hi
>>
>> I'm wondering if anyone is aware of an R package implementing (i.e.,
>> providing a pdf, cdf, and/or quantile function) for the continuous
>> binomial distribution? Specifically the one characterized here:
>>
>> http://www2.math.uni-paderborn.de/fileadmin/Mathematik/AG-Indlekofer/Workshop/Satellite_meeting/ilenko.pdf
>>
>> Figured I would check here first, before attempting to code it up myself.
> I found that reading the ArXiv version of that material was easier to understand:
>
> http://arxiv.org/abs/1303.5990
>
> zipfR package has an implementation of the incomplete beta function that might make some of the coding of the pdf and cdf more simple. 
>
> Searching done with Graves' very useful utility package: 
>
> library('sos')
> findFn("incomplete beta function")
>
> (I did't think that doing a search on "continuous Binomial" was likely to be helpful, but I tried it anyway and did not find any functions named "continuous binomial" in their help page titles.)
>



From rashnaikk at gmail.com  Fri May  8 07:22:36 2015
From: rashnaikk at gmail.com (Rashmi Naik k)
Date: Fri, 8 May 2015 10:52:36 +0530
Subject: [R] Requesting information
Message-ID: <CAKKZ-YGOsMNsOMOw48SpHLLEztPjYfwJbRi8xKnPKT2kn==4vg@mail.gmail.com>

Dear Sir/Madam

I'm Working on a research project called "Dynamic price optimization" using
genetic algorithm to optimize product price's in an e-commerce store. I'm
doing this project using R language (package GA). I need help in defining a
Fitness function to optimize the products price. Can any one help me on
this.!!

Regards
Rashmi Naik

	[[alternative HTML version deleted]]


From maechler at lynne.stat.math.ethz.ch  Fri May  8 11:52:00 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Fri, 8 May 2015 11:52:00 +0200
Subject: [R] does segfault mean (always) a bug?
In-Reply-To: <CAF8bMcZyJ7-Xso_hm4upQUp-aniS0E98EaCKqgGCnEdBbSUwfQ@mail.gmail.com>
References: <554911DB.8050909@yahoo.co.uk> <55491BDB.5070100@gmail.com>
	<5549C0CE.9040303@yahoo.co.uk>
	<21833.55148.133483.482768@stat.math.ethz.ch>
	<CAF8bMcZyJ7-Xso_hm4upQUp-aniS0E98EaCKqgGCnEdBbSUwfQ@mail.gmail.com>
Message-ID: <21836.34624.392635.827574@stat.math.ethz.ch>

>>>>> William Dunlap <wdunlap at tibco.com>
>>>>>     on Wed, 6 May 2015 09:53:50 -0700 writes:

    > It looks like a problem in the Matrix package.  
Indeed.

Thanks to Bill Dunlap for the diagnostics below (and other
offline information and) I have been able to fix the bug
yesterday in the R-forge version of Matrix.
The problem was due to using a version of memory allocation
which is known to be quite fast... but is not to be used for
large objects .. which we have here.

I plan to release the amended version of Matrix to CRAN as 

  Matrix_1.2-1  

rather sooner than later.

With thanks to Bill and Pavel,
Martin Maechler
ETH Zurich

    > I made the file KE.rda containing the Matrix objects K and
    > E constructed in calc.diffusion.kernel by adding a save()
    > call just before where R dies in the original example:

    > K = lam$values[1] * I - M
    > E = I - matrix(1, ncol = ncol(I), nrow = nrow(I))/ncol(I)
    > cat("saving K, E, etc. in /tmp/KE.rda\n")
    > save(K, E, deg, invD, I, W, M, lam, file="/tmp/KE.rda")
    > cat("    done making the file\n")
    > K = E %*% K %*% E

    > With that file in place I get
    >> library(Matrix)
    >> load("KE.rda")
    >> sessionInfo()
    > R version 3.2.0 (2015-04-16)
    > Platform: x86_64-unknown-linux-gnu (64-bit)
    > Running under: Ubuntu precise (12.04.5 LTS)

    [ .......... ]

    > other attached packages:
    > [1] Matrix_1.2-0

    > loaded via a namespace (and not attached):
    > [1] grid_3.2.0      lattice_0.20-31
    >> str(E)
    > Formal class 'dsyMatrix' [package "Matrix"] with 5 slots
    > ..@ x       : num [1:143376676] 1.00 -8.35e-05 -8.35e-05 -8.35e-05
    > -8.35e-05 ...
    > ..@ Dim     : int [1:2] 11974 11974
    > ..@ Dimnames:List of 2
    > .. ..$ : NULL
    > .. ..$ : NULL
    > ..@ uplo    : chr "U"
    > ..@ factors : list()
    >> str(K)
    > Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
    > ..@ i       : int [1:487692] 0 69 948 951 1027 1192 1414 1420 1421 1714
    > ...
    > ..@ p       : int [1:11975] 0 27 125 147 199 212 221 230 254 274 ...
    > ..@ Dim     : int [1:2] 11974 11974
    > ..@ Dimnames:List of 2
    > .. ..$ : chr [1:11974] "GO:0000002" "GO:0000003" "GO:0000012"
    > "GO:0000018" ...
    > .. ..$ : chr [1:11974] "GO:0000002" "GO:0000003" "GO:0000012"
    > "GO:0000018" ...
    > ..@ x       : num [1:487692] 32.2163 -0.004674 -0.000722 -0.005316
    > -0.014022 ...
    > ..@ factors : list()
    >> EK <- E %*% K
    >> EKE <- EK %*% E

    > *** caught segfault ***
    > address 0x7fffa7e1ccf8, cause 'memory not mapped'

    [...............]

    > On Wed, May 6, 2015 at 1:57 AM, Martin Maechler <
    > maechler at lynne.stat.math.ethz.ch> wrote:

    >> >>>>> lejeczek  <peljasz at yahoo.co.uk>
    >> >>>>>     on Wed, 6 May 2015 08:20:46 +0100 writes:
    >> 
    >> > On 05/05/15 20:36, Duncan Murdoch wrote:
    >> >> On 05/05/2015 2:54 PM, lejeczek wrote:
    >> >>> hi eveybody
    >> >>>
    >> >>> I'm trying something simple (Biocunductor packages), so
    >> >>> simple I believe it's example from docs but I get segfault.
    >> >>> I don't suppose incorrect scripting can cause segfault, right?
    >> >> In R, a segfault always indicates a bug.  What's not so clear is
    >> whether
    >> >> it is a bug in R, a bug in a contributed package, or a bug in some
    >> >> underlying system library.
    >> >>
    >> >> If you can only trigger the bug when using a Bioconductor package,
    >> then
    >> >> the first guess is that it is that package, and the maintainer of
    >> that
    >> >> package is in the best position to track it down further.  If you
    >> can
    >> >> simplify the code to trigger it without using any contributed
    >> packages,
    >> >> then it could well be a bug in R, and we'd like to see code to
    >> reproduce it.
    >> >>
    >> >> Duncan Murdoch
    >> >>
    >> > hi Duncan
    >> > I remember that this was a principle of most of programming
    >> > languages, only a bug in the code and/or compiler could
    >> > cause segfault.
    >> > In my case it is a contributed package, specifically GOSim
    >> > package, I'm not R programmer and I realise my scripting is
    >> > far from good and possibly with errors.
    >> > I could send that snippet of the code here if people think
    >> > it can be looked into and segfault could be replicated?
    >> > I also emailed the author.
    >> 
    >> > many thanks
    >> > P.
    >> 
    >> Dear P.,
    >> 
    >> in the case of segfault from using a contributed package,
    >> you should typically really only email the package maintainer
    >> (which may different than the package authors), and not R-help.
    >> Only if the maintainer does not respond at all (and only if the
    >> package is open source, typically CRAN) should you ask for help here
    >> or another public forum.
    >> 
    >> (I would also think it to be polite to the maintainer who has
    >> volunteered her/his code to be used by you if you give him an
    >> opportunity to see, comment and fix the problem)
    >> 
    >> Martin Maechler
    >> ETH Zurich


From maechler at lynne.stat.math.ethz.ch  Fri May  8 12:15:34 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Fri, 8 May 2015 12:15:34 +0200
Subject: [R] package implementing continuous binomial?
In-Reply-To: <5425134B-6AA1-4246-BCD4-D4BE4BE2391B@comcast.net>
References: <554AC75A.8070708@gmail.com>
	<5425134B-6AA1-4246-BCD4-D4BE4BE2391B@comcast.net>
Message-ID: <21836.36038.681878.913650@stat.math.ethz.ch>

>>>>> David Winsemius <dwinsemius at comcast.net>
>>>>>     on Thu, 7 May 2015 12:10:25 -0700 writes:

    > On May 6, 2015, at 7:00 PM, Benjamin Tyner wrote:

    >> Hi
    >> 
    >> I'm wondering if anyone is aware of an R package implementing (i.e.,
    >> providing a pdf, cdf, and/or quantile function) for the continuous
    >> binomial distribution? Specifically the one characterized here:
    >> 
    >> http://www2.math.uni-paderborn.de/fileadmin/Mathematik/AG-Indlekofer/Workshop/Satellite_meeting/ilenko.pdf
    >> 
    >> Figured I would check here first, before attempting to code it up myself.

    > I found that reading the ArXiv version of that material was easier to understand:

    > http://arxiv.org/abs/1303.5990

    > zipfR package has an implementation of the incomplete beta function that might make some of the coding of the pdf and cdf more simple. 

Well.

To: David Winsemius <dwinsemius at comcast.net>
Subject: Re: [R] package implementing continuous binomial?
In-Reply-To: <5425134B-6AA1-4246-BCD4-D4BE4BE2391B at comcast.net>
References: <554AC75A.8070708 at gmail.com>
	<5425134B-6AA1-4246-BCD4-D4BE4BE2391B at comcast.net>
X-Mailer: VM 8.2.0b under 24.3.1 (x86_64-redhat-linux-gnu)
Reply-To: Martin Maechler <maechler at stat.math.ethz.ch>
CC: maechler
--text follows this line--
Dear David,

>>>>> David Winsemius <dwinsemius at comcast.net>
>>>>>     on Thu, 7 May 2015 12:10:25 -0700 writes:

    > On May 6, 2015, at 7:00 PM, Benjamin Tyner wrote:

    >> Hi
    >> 
    >> I'm wondering if anyone is aware of an R package implementing (i.e.,
    >> providing a pdf, cdf, and/or quantile function) for the continuous
    >> binomial distribution? Specifically the one characterized here:
    >> 
    >> http://www2.math.uni-paderborn.de/fileadmin/Mathematik/AG-Indlekofer/Workshop/Satellite_meeting/ilenko.pdf
    >> 
    >> Figured I would check here first, before attempting to code it up myself.

    > I found that reading the ArXiv version of that material was easier to understand:

    > http://arxiv.org/abs/1303.5990

    > zipfR package has an implementation of the incomplete beta function that might make some of the coding of the pdf and cdf more simple. 

    > Searching done with Graves' very useful utility package: 

    > library('sos')
    > findFn("incomplete beta function")

Hmm...  R's   pbeta() function is a pretty good implementation
of the  incomplete beta function ... as is tries to say on its
help page.

If you look closely, these functions (for incomplete gamma,
incomplete beta, and their inverses) are simple wrappers to
pgamma() and qgamma() --- sometimes "regularizing" and sometimes
not -- where regularization is simply a multiplication/division
with  gamma() or beta().

I wonder why you did not find R's help page about the beta distribution
{ -> functions  dgamma, pgamma, qgamma, rgamma }
which does mention the "incomplete beta function" prominently.

I don't think Benjamin should use the zipfR package just for
these functions  [and even the zipfR package help page on these
can be read as saying so .. ]

In the end I wonder if the "continuous Binomial" is not just a
version of the good old Beta distribution... as indeed the
Binomial and the Beta are related in the same way 
that the Gamma and the Poisson are.

Martin Maechler
ETH Zurich

    > (I did't think that doing a search on "continuous Binomial" was likely to be helpful, but I tried it anyway and did not find any functions named "continuous binomial" in their help page titles.)

    > -- 

    > David Winsemius
    > Alameda, CA, USA


From stefanML at collocations.de  Fri May  8 12:48:26 2015
From: stefanML at collocations.de (Stefan Evert)
Date: Fri, 8 May 2015 12:48:26 +0200
Subject: [R] package implementing continuous binomial?
In-Reply-To: <21836.36038.681878.913650@stat.math.ethz.ch>
References: <554AC75A.8070708@gmail.com>
	<5425134B-6AA1-4246-BCD4-D4BE4BE2391B@comcast.net>
	<21836.36038.681878.913650@stat.math.ethz.ch>
Message-ID: <6BA441AB-CB42-4A46-8E39-F0C63C92D6AD@collocations.de>


> I don't think Benjamin should use the zipfR package just for
> these functions  [and even the zipfR package help page on these
> can be read as saying so .. ]

Exactly.  They are simply there because it's much easier to write and read code with wrappers that parametrize the incomplete Beta and Gamma functions in the usual way, so the code looks more like the original equations it's based on.

> In the end I wonder if the "continuous Binomial" is not just a
> version of the good old Beta distribution... as indeed the
> Binomial and the Beta are related in the same way 
> that the Gamma and the Poisson are.

I thought so, too, at first and was about to suggest that.  But a closer look at the slides showed that the distribution function of the continuous binomial and Poisson showed that they keep the boundary of the integral fixed (it's one of the parameters of the distribution) and vary one or two of the other parameters of the function with x.  It took me a while to figure this out because the slides use an uncommon notation for incomplete Gamma and Beta functions.

In particular, qgamma() and qbeta() won't give quantiles for the new distributions and one may have to implement some kind of binary search based on the distribution functions of the continuous binomial and Poisson.

In the interest of self-promotion ;-), Evert (2004, Appendix A.4) spells out the connections between the incomplete Beta and Gamma function, the Beta and Gamma distributions, and the binomial and Poisson distributions in what I consider to be an accessible manner.  (PDF, now at last with bookmarks: http://purl.org/stefan.evert/PUB/Evert2004phd.pdf)

Best,
Stefan


From shouro at gmail.com  Thu May  7 16:23:36 2015
From: shouro at gmail.com (Shouro Dasgupta)
Date: Thu, 7 May 2015 16:23:36 +0200
Subject: [R] Plot by FIPS Code using Shapefiles
In-Reply-To: <loom.20150506T121605-254@post.gmane.org>
References: <CAMx+UYfi70FAbf6AXEDJXJKH7BNTW=Og7qJ9JCTLqn_wYuocSw@mail.gmail.com>
	<CAOwvMDy2P56hR0hECWJTycpjZAVXJGF2mxMNkrvUV+mzKgRuUg@mail.gmail.com>
	<CAMx+UYeUK1Spqb3V-GWRoeSpLBT6OZQTASOYGY3FAyNLD1UA3w@mail.gmail.com>
	<1430842055487-4706840.post@n4.nabble.com>
	<loom.20150506T121605-254@post.gmane.org>
Message-ID: <CAMx+UYf7F5_E2UkwRwjhUGVoLGwjaHdB7mWX3RqQRaf5hMsNag@mail.gmail.com>

Excellent suggestions Professors! I really appreciated it. This is what I
am using:

library(data.table)
> library(rgdal)
> library(colourschemes)
> library(RColorBrewer)
> library(maptools)
> library(maps)
> library(ggmap)
> library(classInt)


max_change is my csv file while shapes is my spatial data:

max_change <-read.csv ("F:/GCM/max_change.csv")
> max_change <- as.data.table(max_change)
> max_change$FIPS <- sprintf("%05d",as.numeric(max_change$FIPS))
>


> max_change <- max_change[with(max_change, order(FIPS)), ]
>


> shapes=readOGR(dsn="F:/GCM//tl_2014_us_county", "tl_2014_us_county")
> shapes$FIPS = paste(shapes$STATEFP,shapes$COUNTYFP,sep="")
>


> m = match(shapes$GEOID,max_change$FIPS)
>


> shapes$change = max_change$change[m]


I am plotting the results now. I am getting different plots regarding
county boundaries (most likely because I am doing something wrong). When I
use the *plot *command:

colours = brewer.pal(6,"PuRd")
> sd = data.frame(col=colours,values=c(-2.5,-2,-1.5,-1,-.5,0))
> sc = nearestScheme(sd)
>


> plot(c(-129,-61),c(21,53),type="n",axes=FALSE,xlab="",ylab="")
> title(main = "Mid-Century Projections (GISS-ER-2) using Max GAM")
> plot(shapes,col=sc(shapes$change),add=TRUE,border="white",lwd=0.2,
> colorkey=T)


I get a "beautiful" plot with the county boundaries clearly separated but
for *spplot*;

pal = brewer.pal(6,"Reds")
> brks.eq = classIntervals(shapes$change, style = "jenks")
> spplot(shapes, "change",xlim = c(-129,-61), ylim = c(21,53),
> at=brks.eq$brks,col.regions=pal, col="transparent",
>        main = list(label="Mid-Century Projections (GISS-ER-2) using Max
> GAM"))


 The county boundaries/FIPS are not defined. What am I doing wrong? Thanks
again!

Sincerely,

Shouro

On Wed, May 6, 2015 at 12:23 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> Corey Sparks <corey.sparks <at> utsa.edu> writes:
>
> >
> > Joining data the way you're doing it is dangerous, Roger Bivand and
> others
> > describes a standard way to do this process here:
> >
>
> http://r-sig-geo.2731867.n2.nabble.com/Merging-shapefiles-and-csv-td7586839.html
>
>
> Quite right - the chunks Corey is referring to are:
>
> Please do refer to the vignette in the maptools package, and to previous
> threads which have advised that merge() should not be used, and that the
> row.names of the data frames be used as ID keys. Typically using match() on
> the row.names of the two objects will show which are not correctly aligned.
>
> and
>
> Beware that the data from the objects may be jumbled - never use merge,
> always use match() on the row.names vectors of the objects to ensure that
> the key-IDs agree. Jumbled data happens, it is important not to think
> "shapefile" but to think DBMS with the ID key your way of staying sane.
>
> The maptools vignette is at:
>
>
> http://cran.r-project.org/web/packages/maptools/vignettes/combine_maptools.pdf
>
> or:
>
> library(maptools)
> vignette("combine_maptools")
>
> Here I also suspect that you'll find that there are non-unique FIPS in the
> county polygons file, so may need to go through
> maptools::unionSpatialPolygons() first.
>
> Roger
>
> >
> > And I do an example using US Census data here, using merge():
> > http://spatialdemography.org/wp-content/uploads/2013/04/9.-Sparks.pdf
> > <http://spatialdemography.org/wp-content/uploads/2013/04/9.-Sparks.pdf>
> >
> > look at page 134 of that pdf.
> >
> > Hope this helps
> >
> > -----
> > Corey Sparks, PhD
> > Assistant Professor
> > Department of Demography
> > University of Texas at San Antonio
> > 501 West C?sar E. Ch?vez  Blvd
> > Monterey Building 2.270C
> > San Antonio, TX 78207
> > 210-458-3166
> > corey.sparks 'at' utsa.edu
> > coreysparks.weebly.com
> > --
> > View this message in context:
>
> http://r.789695.n4.nabble.com/Plot-by-FIPS-Code-using-Shapefiles-tp4706830p4706840.html
> > Sent from the R help mailing list archive at Nabble.com.
> >
> > ______________________________________________
> > R-help <at> r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Shouro Dasgupta
PhD Candidate | Department of Economics
Ca' Foscari University of Venezia

------------------------------

Junior Researcher | Fondazione Eni Enrico Mattei (FEEM)
Isola di San Giorgio Maggiore, 8 | 30124 Venice, Italy
Tel: +39 041 2700 436

	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Fri May  8 16:53:22 2015
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 8 May 2015 07:53:22 -0700
Subject: [R] Changing layout in grid.arrange
Message-ID: <5009D022-CFF1-49A2-AAC0-E7FBC79F0139@noaa.gov>

Hi All:

I am doing something very similar to the the example in the grid.arrange package:

require(ggplot2)
plots = lapply(1:10, function(.x) qplot(1:10,rnorm(10), main=paste("plot",.x)))
require(gridExtra)
do.call(grid.arrange,  plots)


If you run this, the layout is 4 rows and 3 columns with graphs 1-3 going across. What I would like instead is for the layout to have 2 columns and 5 rows, with graphs 1-5 going down the first column, graphs 6-10 going down the second column but almost everything I have tried has failed.  Any help appreciated.

-Roy M.


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From lorenzo.isella at gmail.com  Fri May  8 17:51:03 2015
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Fri, 8 May 2015 17:51:03 +0200
Subject: [R] Confusing 2 classes in a multiclass problem
Message-ID: <20150508155103.GB11330@localhost.localdomain>

Dear All,
I hope this is not too off topic.
Apologies for not sending now any code, but the point is really for me
to understand how to proceed.
Let's say that you have a multiclass classification problem and the
outcome you want to predict is given by 9 different classes {A, B...}.
By training several models and checking the confusion matrix, I
noticed that it is particularly hard to tell apart class C and D.
What is the best way forward?
I am thinking about creating two artificial classes: C-and-D and then aggregate
all the other levels into a fictitious class "Other".
Then I can train a model to identify C-and-D vs the Other class.
The next step would be to train a model on telling apart only C and D
which I had merged in the C-and-D class.
Does such an approach sound sensible?
Many thanks

Lorenzo


From nilsson.henric at gmail.com  Fri May  8 15:51:47 2015
From: nilsson.henric at gmail.com (Henric Winell)
Date: Fri, 08 May 2015 15:51:47 +0200
Subject: [R] Question about cochran test in R
In-Reply-To: <CANxP2S4-GFoei_yZPm5bKBtEaqhfUg7raAQ58iOxHuiWvn269w@mail.gmail.com>
References: <CANxP2S6EE+x+TqdWR8ULOB+i4w8=SaDiYPtwg=tp0eSPES8S5A@mail.gmail.com>
	<CA+8X3fX1Kn=7__FCERj18V02=XgiB6v3k8HT5gUUFOj=m_KFyg@mail.gmail.com>
	<554B4670.6090503@gmail.com>
	<CANxP2S4-GFoei_yZPm5bKBtEaqhfUg7raAQ58iOxHuiWvn269w@mail.gmail.com>
Message-ID: <554CBF73.6070402@gmail.com>

Hi Luis,

(Let's keep R-help in the loop for the benefit of others.)

On 2015-05-08 10:25, Luis Fernando Garc?a wrote:

> Thanks a lot for your replies Henry!
>
> Your answer was specially a bless! Many thanks this was an issue which
> was breaking my head.
>
> I have another couple of questions, may be you could help me. For post
> hoc comparison I was planning to run a McNemar test with a bonferroni
> correction, but wanted to be sure my approach is correct.

It's an OK approach, I guess, but you should use the Holm correction 
rather than Bonferroni.  (Holm dominates Bonferroni and is valid under 
the same arbitrary assumptions.)

The "classical" approach, and as suggested in Cochran (1950), would be 
to partition the chi-squared statistic into components of interest.

In a more general approach, a test of all the post-hoc comparisons is 
performed simultaneously.  This is very efficient, in terms of power, 
since it takes account of the correlation between the test statistics. 
Ignoring such dependencies may result in "strange" results, due to loss 
of power, where none of the partial null hypotheses are rejected even 
though the global null hypothesis is rejected.  Unfortunately, I'm not 
aware of any publicly available software that let's you do this.  In 
theory, 'coin' should be able to, and there has even been some work done 
in this direction, but it's currently unfinished.


Henric Winell



>
> Sorry if I annoy you with this remaining question.
>
> Thanks in advance!
>
> 2015-05-07 8:03 GMT-03:00 Henric Winell <nilsson.henric at gmail.com
> <mailto:nilsson.henric at gmail.com>>:
>
>     On 2015-05-07 09:15, Jim Lemon wrote:
>
>         Hi Luis,
>         Try this page:
>
>         http://www.r-bloggers.com/cochran-q-test-for-k-related-samples-in-r/
>
>         Jim
>
>
>     Cochran's Q test is a marginal homogeneity test, and such tests can
>     be performed by the 'mh_test' function in the 'coin' package.  The
>     following replicates the result in the blog post
>
>      > library("coin")
>      >
>      > dta <- data.frame(
>     +     method    = factor(rep(LETTERS[1:4], 6)),
>     +     repellent = factor(c(1, 1, 0, 0,
>     +                          1, 1, 0, 1,
>     +                          1, 0, 0, 0,
>     +                          1, 1, 1, 0,
>     +                          1, 1, 0, 1,
>     +                          1, 1, 0, 1)),
>     +     fabric    = gl(6, 4, labels = as.roman(1:6))
>     + )
>      >
>      > mh_test(repellent ~ method | fabric, data = dta)
>
>              Asymptotic Marginal-Homogeneity Test
>
>     data:  repellent by
>               method (A, B, C, D)
>               stratified by fabric
>     chi-squared = 9.3158, df = 3, p-value = 0.02537
>
>
>     and uses the asymptotic approximation to compute the p-value.  The
>     'coin' package also allows you to approximate the exact null
>     distribution using Monte Carlo methods:
>
>      > set.seed(123)
>      > mh_test(repellent ~ method | fabric, data = dta,
>     +         distribution = approximate(B = 10000L))
>
>              Approximative Marginal-Homogeneity Test
>
>     data:  repellent by
>               method (A, B, C, D)
>               stratified by fabric
>     chi-squared = 9.3158, p-value = 0.0202
>
>
>     For future reference, 'mh_test' is fairly general and handles both
>     matched pairs or matched sets.  So, the well-known tests due
>     McNemar, Cochran, Stuart(-Maxwell) and Madansky are just special cases.
>
>     For more general symmetry test problems, the 'coin' package offers
>     the 'symmetry_test' function and this can be used to perform, e.g.,
>     multivariate marginal homogeneity tests like the multivariate
>     McNemar test (Klingenberg and Agresti, 2006) or the multivariate
>     Friedman test (Gerig, 1969).
>
>
>     Henric
>
>
>
>
>
>
>         On Thu, May 7, 2015 at 4:59 PM, Luis Fernando Garc?a
>         <luysgarcia at gmail.com <mailto:luysgarcia at gmail.com>> wrote:
>
>             Dear R Experts,
>
>             May be this is a basic question for you, but it is something
>             I need really
>             urgently. I need to perform a Chi Square analysis for more
>             than two groups
>             of paired observations. It seems to be ok For Cochran test.
>             Unfortunately I
>             have not found info about  this test in R, except for
>             dealing with outliers
>             which is not my aim. I am looking for something like this
>             https://www.medcalc.org/manual/cochranq.php
>
>             I found a video to perform this analysis in R, but was not
>             specially
>             useful. Does some of you know have some info about how to
>             make this
>             analysis in R?
>
>             Thanks in advance!
>
>                       [[alternative HTML version deleted]]
>
>             ______________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>             list -- To UNSUBSCRIBE and more, see
>             https://stat.ethz.ch/mailman/listinfo/r-help
>             PLEASE do read the posting guide
>             http://www.R-project.org/posting-guide.html
>             and provide commented, minimal, self-contained, reproducible
>             code.
>
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>


From davidsmi at microsoft.com  Fri May  8 19:18:49 2015
From: davidsmi at microsoft.com (David Smith)
Date: Fri, 8 May 2015 17:18:49 +0000
Subject: [R] Revolutions blog roundup: April 2015
Message-ID: <BN3PR0301MB0835B013D7E8E5AAB2743ECCC8DE0@BN3PR0301MB0835.namprd03.prod.outlook.com>

Since 2008, Revolution Analytics staff and guests have written about R every weekday at the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month of particular interest to readers of r-help. 

In case you missed them, here are some articles related to R from the month of April:

Joseph Rickert reviews the inaugural New York City R User Conference, featuring Andrew Gelman: http://blog.revolutionanalytics.com/2015/04/the-ny-r-conference.html

Engineer Vineet Abraham compares performance benchmarks for R and Revolution R Open on OS X and Ubuntu: http://blog.revolutionanalytics.com/2015/04/benchmarks-of-rro-on-osx-and-ubuntu.html

R was featured in the keynotes for the BUILD developer's conference: http://blog.revolutionanalytics.com/2015/04/see-r-in-action-at-the-build-conference.html

Mark Malter created a Shiny application to explore baseball statistics: http://blog.revolutionanalytics.com/2015/04/situational-baseball-analyzing-runs-potential-statistics.html

A curated list of the best packages, add-ons and resources for R according to Qin Wenfeng: 
http://blog.revolutionanalytics.com/2015/04/awesome-r-a-curated-list-of-the-best-add-ons-for-r.html

An analysis of paintings from British museums reveals an increasing use of the colour blue over the last two centuries: http://blog.revolutionanalytics.com/2015/04/paintings-getting-blue.html

Journalists are increasingly referencing source research via DOIs, and packages from rOpenSci allow R users to access that research programmatically: http://blog.revolutionanalytics.com/2015/04/the-new-science-journalism-and-open-science.html

Microsoft is hiring programmers to work on R-related projects: http://blog.revolutionanalytics.com/2015/04/microsoft-hiring-engineers-for-r-projects.html

Some examples of visualizing the results of hierarchical clustering with a heat map: http://blog.revolutionanalytics.com/2015/04/r-for-more-powerful-clustering.html

The Financial Times published an interactive data visualization based on R to explore European unemployment statistics: http://blog.revolutionanalytics.com/2015/04/financial-times-tracks-unemployment-with-r.html

Announcing R 3.2.0: http://blog.revolutionanalytics.com/2015/04/r-320-released.html

Recent R user group meetings have covered Shiny, SparkR, htmlwidgets, and dynamic pricing models: http://blog.revolutionanalytics.com/2015/04/r-user-group-meetings-this-week-in-the-bay-area-and-around-the-world.html

A story about teaching R to archaeologists in Myanmar, and coping with package installation in a low-bandwidth environment with the miniCRAN package: http://blog.revolutionanalytics.com/2015/04/r-in-myanmar.html

RPowerLabs allows electrical engineers to experiment on virtual power distribution systems: http://blog.revolutionanalytics.com/2015/04/rpowerlabs-electric-power-system-virtual-laboratories-online.html

Two high-performance packages from RStudio for reading data into R: readr (for text data) and readxl (for Excel data): http://blog.revolutionanalytics.com/2015/04/new-packages-for-reading-data-into-r-fast.html

A list of the top 25 R user groups in the world by membership: http://blog.revolutionanalytics.com/2015/04/where-are-the-r-users.html

A guide to association rules and market basket analysis in R: http://blog.revolutionanalytics.com/2015/04/association-rules-and-market-basket-analysis-with-r.html

The choroplethrZip package allows R users to create data maps from US zip codes: http://blog.revolutionanalytics.com/2015/04/exploring-san-francisco-with-choropleth.html

Revolution Analytics is now a subsidiary of Microsoft: http://blog.revolutionanalytics.com/2015/04/revolution-analytics-microsoft.html

DeployR 7.4, a web-services framework for integrating R code to other applications, is now available for download: http://blog.revolutionanalytics.com/2015/04/deployr-74-released.html

Coarse-grained parallel computing with R on servers and Hadoop with rxExec in Revolution R Enterprise: http://blog.revolutionanalytics.com/2015/04/coarse-grain-parallelism-with-foreach-and-rxexec.html

Revolution R Open 8.0.2 was released (and 8.0.3 is now available, too): http://blog.revolutionanalytics.com/2015/04/a-minor-update-revolution-r-open-802.html

General interest stories (not related to R) in the past month included: a video travelling at the speed of light (http://blog.revolutionanalytics.com/2015/04/because-its-friday-slow-light.html), a snowy music video (http://blog.revolutionanalytics.com/2015/04/because-its-friday-boy-and-bear-in-the-snow.html), and visualizing the baseline in a Marvin Gaye classic (http://blog.revolutionanalytics.com/2015/04/because-its-friday-all-about-that-bassline.html).

Meeting times for local R user groups (http://blog.revolutionanalytics.com/local-r-groups.html) can be found on the updated R Community Calendar at: http://blog.revolutionanalytics.com/calendar.html

If you're looking for more articles about R, you can find summaries from previous months at http://blog.revolutionanalytics.com/roundups/. You can receive daily blog posts via email using services like blogtrottr.com, or join the Revolution Analytics mailing list at http://revolutionanalytics.com/newsletter to be alerted to new articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions to me at david at revolutionanalytics.com or via Twitter (I'm @revodavid).

Cheers,
# David

--
David M Smith <davidsmi at microsoft.com>
Principal Program Manager, Microsoft? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid
Blog: ?http://blog.revolutionanalytics.com


From rshepard at appl-ecosys.com  Fri May  8 20:34:56 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Fri, 8 May 2015 11:34:56 -0700 (PDT)
Subject: [R] CoDA ANOVA Error
Message-ID: <alpine.LNX.2.11.1505081131470.30315@localhost>

   I'm running linear regressions and ANOVAs on 5 sets of compositional data
following van den Boogaart and Tolosana-Delgado's book, pp. 129 ff. Four of
the five data sets compute without error; one does not. To test results,
load package 'compositions'.

   The input data:
<for Y>
structure(c(0.18968103189681, 0.0619, 0.0875, 0.102910291029103, 
0.1023, 0.482751724827517, 0.5773, 0.7125, 0.5000500050005, 0.5795, 
0.068993100689931, 0.0309, 0.0125, 0.0882088208820882, 0.0341, 
0.206879312068793, 0.2371, 0.1125, 0.235323532353235, 0.2614, 
0.0516948305169483, 0.0928, 0.075, 0.0735073507350735, 0.0227
), .Dim = c(5L, 5L), .Dimnames = list(NULL, c("Fi", "Ga", "Gr", 
"Pr", "Sh")), class = "acomp")
<for X>
c(0.31, 0.31, 0.21, 2, 0.31)

   Regression model:
( model <- lm(ilr(Y) ~ log(X)) )

   Convert back from ILR to original units:
( orig <- ilrInv(coef(model),orig=Y) )

   Then run the ANOVA:
( analvar <- anova(model) )

   The result displayed is:
Error in anova.mlm(model) : residuals have rank 3 < 4

   A Web search found a nabble thread from 2012 but that was related to using
the spephical model, not the Pillai model. I do not see differences between
the number of columns in the Y and X variables in the different data sets
that might throw that error. What might be the cause and is there anything I
can do to test the variable for significance?

Rich


From tmrsg11 at gmail.com  Fri May  8 21:44:45 2015
From: tmrsg11 at gmail.com (C W)
Date: Fri, 8 May 2015 15:44:45 -0400
Subject: [R] trouble installing RcppOctave
Message-ID: <CAE2FW2mBvT1U98jHp2s_f9d3D9Esm6NVgUaQMQFeOhJ9NpZRQA@mail.gmail.com>

Dear R list,

I am trying install the RcppOctave package to run Matlab packages in R.  I
did the following,

> install.packages("RcppOctave")

After some time of installation, I get the following error.  I have
homebrew installed, I also have Octave and Matlab install.

installing the source package ?RcppOctave?

trying URL '
http://watson.nci.nih.gov/cran_mirror/src/contrib/RcppOctave_0.14.5.tar.gz'
Content type 'application/octet-stream' length 767455 bytes (749 KB)
==================================================
downloaded 749 KB

* installing *source* package ?RcppOctave? ...
** package ?RcppOctave? successfully unpacked and MD5 sums checked
checking R CC... clang
checking R CFLAGS... -Wall -mtune=core2 -g -O2
checking R CPPFLAGS... -I/usr/local/include -I/usr/local/include/freetype2
-I/opt/X11/include
checking R CXXFLAGS... -Wall -mtune=core2 -O3
checking for clang... /usr/bin/clang
checking for gcc... clang
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables... checking whether we are cross
compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether clang accepts -g... yes
checking for clang option to accept ISO C89... none needed
checking for g++... g++
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
checking for g++... /usr/bin/g++
Original R_LDFLAGS:   -F/Library/Frameworks/R.framework/.. -framework R
-lpcre -llzma -lbz2 -lz -licucore -lm -liconv
Original R_CPPFLAGS: -I/Library/Frameworks/R.framework/Resources/include
checking whether R is a shared library... yes
checking type of Operating System... Darwin
checking whether OS is Mac OS (Darwin)... yes
Using mkoctfile with R_LDFLAGS: -Wl,"-F/Library/Frameworks/R.framework/..
-framework R -lpcre -llzma -lbz2 -lz -licucore -lm -liconv"
Using mkoctfile with R_CPPFLAGS:
-I/Library/Frameworks/R.framework/Resources/include
checking Octave binary path specification... none
using Octave binary path from $PATH
checking for octave-config... no
checking for mkoctfile... no
configure: error: mkoctfile not found, is Octave installed?

    -> On Mac OS please check that the required packages are installed:

      * octave package from homebrew (works out of the box):
        $ brew install gfortran octave

        # install as usual in R
        > install.packages('RcppOctave')

ERROR: configuration failed for package ?RcppOctave?
* removing
?/Library/Frameworks/R.framework/Versions/3.2/Resources/library/RcppOctave?

The downloaded source packages are in
?/private/var/folders/qf/q83rlh3x2qjcp75c3phtj81c0000gn/T/Rtmpdh718K/downloaded_packages?
Warning message:
In install.packages("RcppOctave") :
  installation of package ?RcppOctave? had non-zero exit status
>


Thanks in advance,

Mike

	[[alternative HTML version deleted]]


From kate.ignatius at gmail.com  Fri May  8 21:50:14 2015
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Fri, 8 May 2015 15:50:14 -0400
Subject: [R] Grep out columns using a list of strings
Message-ID: <CAE6QMsZneyNGxT2Vf6xnRHsSS_Pr7mRJmPZxVDYG_peyuQSYHA@mail.gmail.com>

Hi,

I have a list of 150 strings, say, ap,:

aajkss
dfghjk
sdfghk
...
xxcvvn


And I would l like to grep out these strings from column names in
another file, af,.   I've tried the following but none seem to work:

aps <- af[,grep(ap, colnames(af), value=TRUE)]
aps <- af[,grep(ap, colnames(af), value=FIXED)]
aps <- af[,grep(as.character(list(ap),colnames(af))]

and also aps <- unique (grep(ap, colnames(af))

Is there another way I can do this - maybe without using grep?

Thanks!

Kate.


From rafaelcarneirocosta.rc at gmail.com  Fri May  8 22:07:56 2015
From: rafaelcarneirocosta.rc at gmail.com (Rafael Costa)
Date: Fri, 8 May 2015 17:07:56 -0300
Subject: [R] Getting INDIVIDUAL effects of multiple qualitative
 variables (ordered and unordered factors)
In-Reply-To: <CAGx1TMDHuX=jCaD8LjHjeK9B-Of==c81d7cjXbQ4VjW130792Q@mail.gmail.com>
References: <CAOy3Z4C2wu5uMprni1S0eRiCWoitduLvGSHfLg8xH4ucsvy=Aw@mail.gmail.com>
	<CAGx1TMDHuX=jCaD8LjHjeK9B-Of==c81d7cjXbQ4VjW130792Q@mail.gmail.com>
Message-ID: <CAOy3Z4Dn=F95+C-LAF8NqEM4C=D8+XL7StZH_Fvs-Zz2Yk99Kw@mail.gmail.com>

Dear Richard,

I really appreciate your help.

## Your download host seems to want to give me software, so I am not taking
> it.
>

*To download my file, please uncheck the "Use our download manager and get
recommended downloads" option. *But If you prefer, I might send my file
attached by email.

#In fact, I wish calculate
library (quantreg)
qrModel2=rq(data=tabela1.1, pontoefetivo ~ p1 + p21 + p22 + p23 + p24 + p25
+ p34 + p5 + p6 + p7 + p8 + p9, tau=0.5)
summary(qrModel2)
#But I have to suppress the intercept and consider that the reference group
is also zero.
#When I make
qrModel3=rq(data=tabela1.1, pontoefetivo ~ 0+ p1 + p21 + p22 + p23 + p24 +
p25 + p34 + p5 + p6 + p7 + p8 + p9, tau=0.5)
summary(qrModel3)
#The value of the reference group reappears in the first estimated
coefficient.

Is there any way to do this?

Thanks in advance ,

Rafael Costa.

	[[alternative HTML version deleted]]


From rshepard at appl-ecosys.com  Fri May  8 22:13:39 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Fri, 8 May 2015 13:13:39 -0700 (PDT)
Subject: [R] Specifying Directory to Search When Updating a Package
Message-ID: <alpine.LNX.2.11.1505081306210.30315@localhost>

   R packages here are installed in /usr, not /usr/local/. Most of the time
when I run 'update.packages()' each finds headers in /usr/include. Today,
the package 'rgl' failed to build because it was looking for freetype.h in
/usr/local/include/freetype2/.

   By making a softlink from /usr/include/freetype2 to /usr/local/include/
the package update built without further error.

   For future reference, if an update attempt fails because the code is
looking in a different directory than where the required file (usually a
header) is found, is there a way to specify the correct directory when
issuing the update.packages() command?

Rich


From boris.steipe at utoronto.ca  Fri May  8 22:37:19 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 8 May 2015 16:37:19 -0400
Subject: [R] Grep out columns using a list of strings
In-Reply-To: <CAE6QMsZneyNGxT2Vf6xnRHsSS_Pr7mRJmPZxVDYG_peyuQSYHA@mail.gmail.com>
References: <CAE6QMsZneyNGxT2Vf6xnRHsSS_Pr7mRJmPZxVDYG_peyuQSYHA@mail.gmail.com>
Message-ID: <CC7F7DE0-817C-4EC8-8C25-B57DA6F97F9B@utoronto.ca>

How about %in% ?


# preparing something that looks like I think your data looks like:
ap <- c("aajkss", "dfghjk", "sdfghk", "xxcvvn")
af <- matrix(1:10, nrow=2)
colnames(af) <- c("aajkss", "b", "c", "dfghjk", "e")

# doing what I think you need done:
ap[ap %in% colnames(af)]


Cheers,
B.

(PS. a reproducible example saves us all time and unnecessary effort. :-)





On May 8, 2015, at 3:50 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:

> Hi,
> 
> I have a list of 150 strings, say, ap,:
> 
> aajkss
> dfghjk
> sdfghk
> ...
> xxcvvn
> 
> 
> And I would l like to grep out these strings from column names in
> another file, af,.   I've tried the following but none seem to work:
> 
> aps <- af[,grep(ap, colnames(af), value=TRUE)]
> aps <- af[,grep(ap, colnames(af), value=FIXED)]
> aps <- af[,grep(as.character(list(ap),colnames(af))]
> 
> and also aps <- unique (grep(ap, colnames(af))
> 
> Is there another way I can do this - maybe without using grep?
> 
> Thanks!
> 
> Kate.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nashjc at uottawa.ca  Fri May  8 23:16:42 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Fri, 08 May 2015 17:16:42 -0400
Subject: [R]  nlminb supplying NaN parameters to objective function
Message-ID: <554D27BA.6080302@uottawa.ca>

Your problem is saying (on my machine) that it cannot compute the
gradient. Since it does this numerically, my guess is that the step to
evaluate the gradient violates the bounds and we get log(-something).

I also get

> Warning messages:
> 1: In dnbinom(x = dummyData[, "Y"], mu = mu, size = params[length(params)],  :
>   NaNs produced
> 2: In nlminb(start = sv, objective = nLL, lower = 0, upper = Inf, control = list(trace = TRUE)) :
>   NA/NaN function evaluation
> 3: In dnbinom(x = dummyData[, "Y"], mu = mu, size = params[length(params)],  :
>   NaNs produced
> 4: In nlminb(start = sv, objective = nLL, lower = 0, upper = Inf, control = list(trace = TRUE)) :
>   NA/NaN function evaluation



I put lower=0.01 and got convergence OK, but that may not be suitable,
since all but one of the parameters are at that bound.

> $par
>  [1] 0.01000000 0.01000000 0.01000000 0.01000000 0.01000000 0.01000000
>  [7] 0.01000000 0.01000000 0.01000000 0.01000000 0.01000000 0.01000000
> [13] 0.09168027
> 
> $objective
> [1] 11879.51
> 
> $convergence
> [1] 0
> 
> $iterations
> [1] 8
> 
> $evaluations
> function gradient 
>       13      119 
> 
> $message
> [1] "relative convergence (4)"


As it turns out, Duncan Murdoch, Ben Bolker and I had a meeting
yesterday to discuss improvements in optimization and nonlinear least
squares and derivatives. One suggestion to be implemented is a wrapper
for objective functions to reveal when bounds are violated. It will,
however, take a little time for me to get that organized.

FYI, without the reproducible example, you would not have received this
attempt to explain things. Thanks.

JN



> A follow-up to my yesterday's email.
> 
> I was able to make a reproducible example. All you will have to do is
> load the .RData file that you can download here:
> https://drive.google.com/file/d/0B0DKwRjF11x4dG1uRWhwb1pfQ2s/view?usp=sharing
> 
> and run this line of code:
> 
> nlminb(start=sv, objective = nLL, lower = 0, upper = Inf,
> control=list(trace=TRUE))
> 
> which output the following:
> 
>   0:     12523.401: 0.0328502 0.0744493 0.00205298 0.0248628 0.0881807
> 0.0148887 0.0244485 0.0385922 0.0714495 0.0161784 0.0617551 0.0244901
> 0.0784038
>   1:     12421.888: 0.0282245 0.0697934  0.00000 0.0199076 0.0833634
> 0.0101135 0.0189494 0.0336236 0.0712130 0.0160687 0.0616015 0.0244689
> 0.0660129
>   2:     12050.535: 0.00371847 0.0451786  0.00000  0.00000 0.0575667
> 0.00000  0.00000 0.00697067 0.0697205 0.0156250 0.0608550 0.0243431
> 0.0994355
>   3:     12037.682: 0.00303460 0.0445012  0.00000  0.00000 0.0568530
> 0.00000  0.00000 0.00636016 0.0696959 0.0156250 0.0608550 0.0243419
> 0.0988824
>   4:     12012.684: 0.00164710 0.0431313  0.00000  0.00000 0.0554032
> 0.00000  0.00000 0.00515500 0.0696451 0.0156250 0.0608550 0.0243395
> 0.0978328
>   5:     12003.017: 0.00107848 0.0425739  0.00000  0.00000 0.0548073
> 0.00000  0.00000 0.00469592 0.0696233 0.0156250 0.0608550 0.0243386
> 0.0974616
>   6:     11984.372:  0.00000 0.0414397  0.00000  0.00000 0.0535899
> 0.00000  0.00000 0.00378996 0.0695782 0.0156250 0.0608550 0.0243370
> 0.0967449
>   7:     11978.154:  0.00000 0.0409106  0.00000  0.00000 0.0530158
> 0.00000  0.00000 0.00340746 0.0695560 0.0156250 0.0608550 0.0243363
> 0.0964537
>   8:    -0.0000000:  0.00000      nan  0.00000  0.00000      nan
> 0.00000  0.00000      nan      nan      nan      nan      nan      nan
> 
> Regards,
> 
> Jean
> 
> 2015-05-06 17:43 GMT-07:00 Jean Marchal <jean.d.marchal at gmail.com>:
>> Dear list,
>>
>> I am doing some maximum likelihood estimation using nlminb() with
>> box-constraints to ensure that all parameters are positive. However,
>> nlminb() is behaving strangely and seems to supply NaN as parameters
>> to my objective function (confirmed using browser()) and output the
>> following:
>>
>> $par
>>  [1] NaN NaN NaN   0 NaN   0 NaN NaN NaN NaN NaN NaN NaN
>>
>> $objective
>> [1] 0
>>
>> $convergence
>> [1] 1
>>
>> $iterations
>> [1] 19
>>
>> $evaluations
>> function gradient
>>       87      542
>>
>> $message
>> [1] "gr cannot be computed at initial par (65)"
>>


From jean.d.marchal at gmail.com  Fri May  8 23:29:03 2015
From: jean.d.marchal at gmail.com (Jean Marchal)
Date: Fri, 8 May 2015 14:29:03 -0700
Subject: [R] nlminb supplying NaN parameters to objective function
In-Reply-To: <554D27BA.6080302@uottawa.ca>
References: <554D27BA.6080302@uottawa.ca>
Message-ID: <CACF6B3XTngPpdGXnV2n0gcH6ODZx_knHpLWLTWBAADQ_0NuuSg@mail.gmail.com>

Prof. Nash,

awesome! This sounds promising.

Thank you for the explanation,

Jean

2015-05-08 14:16 GMT-07:00 Prof J C Nash (U30A) <nashjc at uottawa.ca>:

> Your problem is saying (on my machine) that it cannot compute the
> gradient. Since it does this numerically, my guess is that the step to
> evaluate the gradient violates the bounds and we get log(-something).
>
> I also get
>
> > Warning messages:
> > 1: In dnbinom(x = dummyData[, "Y"], mu = mu, size =
> params[length(params)],  :
> >   NaNs produced
> > 2: In nlminb(start = sv, objective = nLL, lower = 0, upper = Inf,
> control = list(trace = TRUE)) :
> >   NA/NaN function evaluation
> > 3: In dnbinom(x = dummyData[, "Y"], mu = mu, size =
> params[length(params)],  :
> >   NaNs produced
> > 4: In nlminb(start = sv, objective = nLL, lower = 0, upper = Inf,
> control = list(trace = TRUE)) :
> >   NA/NaN function evaluation
>
>
>
> I put lower=0.01 and got convergence OK, but that may not be suitable,
> since all but one of the parameters are at that bound.
>
> > $par
> >  [1] 0.01000000 0.01000000 0.01000000 0.01000000 0.01000000 0.01000000
> >  [7] 0.01000000 0.01000000 0.01000000 0.01000000 0.01000000 0.01000000
> > [13] 0.09168027
> >
> > $objective
> > [1] 11879.51
> >
> > $convergence
> > [1] 0
> >
> > $iterations
> > [1] 8
> >
> > $evaluations
> > function gradient
> >       13      119
> >
> > $message
> > [1] "relative convergence (4)"
>
>
> As it turns out, Duncan Murdoch, Ben Bolker and I had a meeting
> yesterday to discuss improvements in optimization and nonlinear least
> squares and derivatives. One suggestion to be implemented is a wrapper
> for objective functions to reveal when bounds are violated. It will,
> however, take a little time for me to get that organized.
>
> FYI, without the reproducible example, you would not have received this
> attempt to explain things. Thanks.
>
> JN
>
>
>
> > A follow-up to my yesterday's email.
> >
> > I was able to make a reproducible example. All you will have to do is
> > load the .RData file that you can download here:
> >
> https://drive.google.com/file/d/0B0DKwRjF11x4dG1uRWhwb1pfQ2s/view?usp=sharing
> >
> > and run this line of code:
> >
> > nlminb(start=sv, objective = nLL, lower = 0, upper = Inf,
> > control=list(trace=TRUE))
> >
> > which output the following:
> >
> >   0:     12523.401: 0.0328502 0.0744493 0.00205298 0.0248628 0.0881807
> > 0.0148887 0.0244485 0.0385922 0.0714495 0.0161784 0.0617551 0.0244901
> > 0.0784038
> >   1:     12421.888: 0.0282245 0.0697934  0.00000 0.0199076 0.0833634
> > 0.0101135 0.0189494 0.0336236 0.0712130 0.0160687 0.0616015 0.0244689
> > 0.0660129
> >   2:     12050.535: 0.00371847 0.0451786  0.00000  0.00000 0.0575667
> > 0.00000  0.00000 0.00697067 0.0697205 0.0156250 0.0608550 0.0243431
> > 0.0994355
> >   3:     12037.682: 0.00303460 0.0445012  0.00000  0.00000 0.0568530
> > 0.00000  0.00000 0.00636016 0.0696959 0.0156250 0.0608550 0.0243419
> > 0.0988824
> >   4:     12012.684: 0.00164710 0.0431313  0.00000  0.00000 0.0554032
> > 0.00000  0.00000 0.00515500 0.0696451 0.0156250 0.0608550 0.0243395
> > 0.0978328
> >   5:     12003.017: 0.00107848 0.0425739  0.00000  0.00000 0.0548073
> > 0.00000  0.00000 0.00469592 0.0696233 0.0156250 0.0608550 0.0243386
> > 0.0974616
> >   6:     11984.372:  0.00000 0.0414397  0.00000  0.00000 0.0535899
> > 0.00000  0.00000 0.00378996 0.0695782 0.0156250 0.0608550 0.0243370
> > 0.0967449
> >   7:     11978.154:  0.00000 0.0409106  0.00000  0.00000 0.0530158
> > 0.00000  0.00000 0.00340746 0.0695560 0.0156250 0.0608550 0.0243363
> > 0.0964537
> >   8:    -0.0000000:  0.00000      nan  0.00000  0.00000      nan
> > 0.00000  0.00000      nan      nan      nan      nan      nan      nan
> >
> > Regards,
> >
> > Jean
> >
> > 2015-05-06 17:43 GMT-07:00 Jean Marchal <jean.d.marchal at gmail.com>:
> >> Dear list,
> >>
> >> I am doing some maximum likelihood estimation using nlminb() with
> >> box-constraints to ensure that all parameters are positive. However,
> >> nlminb() is behaving strangely and seems to supply NaN as parameters
> >> to my objective function (confirmed using browser()) and output the
> >> following:
> >>
> >> $par
> >>  [1] NaN NaN NaN   0 NaN   0 NaN NaN NaN NaN NaN NaN NaN
> >>
> >> $objective
> >> [1] 0
> >>
> >> $convergence
> >> [1] 1
> >>
> >> $iterations
> >> [1] 19
> >>
> >> $evaluations
> >> function gradient
> >>       87      542
> >>
> >> $message
> >> [1] "gr cannot be computed at initial par (65)"
> >>
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat May  9 02:38:01 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 9 May 2015 10:38:01 +1000
Subject: [R] Changing layout in grid.arrange
In-Reply-To: <5009D022-CFF1-49A2-AAC0-E7FBC79F0139@noaa.gov>
References: <5009D022-CFF1-49A2-AAC0-E7FBC79F0139@noaa.gov>
Message-ID: <CA+8X3fVMmpzHYUgTaa8d4A3BjpmKO8TMy0O_-vQF3Y30LgBALw@mail.gmail.com>

Hi Roy,
If this helps, you can get the layout like this:

split.screen(figs=matrix(c(rep(0,5),rep(0.5,10),rep(1,5),
 rep(seq(0.8,0,by=-0.2),2),rep(seq(1,0.2,by=-0.2),2)),ncol=4))
for(scr in 1:10) {
 screen(scr)
 par(mar=c(0,0,0,0))
 plot(0.5,0.5,xlim=c(0,1),ylim=c(0,1),
  axes=FALSE,xlab="",ylab="",type="n")
 box()
 text(0.5,0.5,scr)
}
close.screen(all=TRUE)

Jim


On Sat, May 9, 2015 at 12:53 AM, Roy Mendelssohn - NOAA Federal
<roy.mendelssohn at noaa.gov> wrote:
> Hi All:
>
> I am doing something very similar to the the example in the grid.arrange package:
>
> require(ggplot2)
> plots = lapply(1:10, function(.x) qplot(1:10,rnorm(10), main=paste("plot",.x)))
> require(gridExtra)
> do.call(grid.arrange,  plots)
>
>
> If you run this, the layout is 4 rows and 3 columns with graphs 1-3 going across. What I would like instead is for the layout to have 2 columns and 5 rows, with graphs 1-5 going down the first column, graphs 6-10 going down the second column but almost everything I have tried has failed.  Any help appreciated.
>
> -Roy M.
>
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Sat May  9 03:09:15 2015
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 8 May 2015 18:09:15 -0700
Subject: [R] Changing layout in grid.arrange
In-Reply-To: <CA+8X3fVMmpzHYUgTaa8d4A3BjpmKO8TMy0O_-vQF3Y30LgBALw@mail.gmail.com>
References: <5009D022-CFF1-49A2-AAC0-E7FBC79F0139@noaa.gov>
	<CA+8X3fVMmpzHYUgTaa8d4A3BjpmKO8TMy0O_-vQF3Y30LgBALw@mail.gmail.com>
Message-ID: <A9756791-4615-4176-9491-8A74B0DE1F09@noaa.gov>

Thanks, it took some digging in the internet, but I figured out how to do it.

The first thing is how to pass options to grid.arrange when used in do.call.  It takes a list, which I tried in several different ways,  the list has to be of a certain form, so something like:

> args.list <- c(plots,list(nrow=5,ncol=2))
> do.call(grid.arrange,args.list)


The second thing is to interleave sequences before doing the lapply, as in:

x<- 1:5
y<-6:10
iOrder<-c(rbind(x,y))

I should add that Dennis Murphy sent this solution off-line, I will add it for completeness:

> require(ggplot2)
> plots = lapply(1:10, function(.x) qplot(1:10,rnorm(10), main=paste("plot",.x)))
> require(gridExtra)
> do.call(grid.arrange, c(plots[as.vector(gdata::interleave(1:5, 6:10))],
>                         list(nrow = 5)))


Either of these produces a grid of plots with 5 rows and two columns, which is what I was after.


-Roy





> On May 8, 2015, at 5:38 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi Roy,
> If this helps, you can get the layout like this:
> 
> split.screen(figs=matrix(c(rep(0,5),rep(0.5,10),rep(1,5),
> rep(seq(0.8,0,by=-0.2),2),rep(seq(1,0.2,by=-0.2),2)),ncol=4))
> for(scr in 1:10) {
> screen(scr)
> par(mar=c(0,0,0,0))
> plot(0.5,0.5,xlim=c(0,1),ylim=c(0,1),
>  axes=FALSE,xlab="",ylab="",type="n")
> box()
> text(0.5,0.5,scr)
> }
> close.screen(all=TRUE)
> 
> Jim
> 
> 
> On Sat, May 9, 2015 at 12:53 AM, Roy Mendelssohn - NOAA Federal
> <roy.mendelssohn at noaa.gov> wrote:
>> Hi All:
>> 
>> I am doing something very similar to the the example in the grid.arrange package:
>> 
>> require(ggplot2)
>> plots = lapply(1:10, function(.x) qplot(1:10,rnorm(10), main=paste("plot",.x)))
>> require(gridExtra)
>> do.call(grid.arrange,  plots)
>> 
>> 
>> If you run this, the layout is 4 rows and 3 columns with graphs 1-3 going across. What I would like instead is for the layout to have 2 columns and 5 rows, with graphs 1-5 going down the first column, graphs 6-10 going down the second column but almost everything I have tried has failed.  Any help appreciated.
>> 
>> -Roy M.
>> 
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new address and phone***
>> 110 Shaffer Road
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>> 
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From barry.king at qlx.com  Sat May  9 16:38:46 2015
From: barry.king at qlx.com (Barry King)
Date: Sat, 9 May 2015 10:38:46 -0400
Subject: [R] ERROR: length of 'center' must equal the number of columns of
	'x'
Message-ID: <CAP8WkrxbkgsbwxZO3_0CX=eBC4AKD26e-bwvx6dcBD3bJZdCwA@mail.gmail.com>

I am attempting to predict tomorrow's rainfall, RISK_MM, with LASSO using a
data set that
I have partitioned into a train data set and a test data set.  The
structures of the
two data sets are shown below and appear to be identical except the number
of observations:

str(train)
'data.frame': 262 obs. of  24 variables:
 $ Date         : Factor w/ 366 levels "1/1/2008","1/10/2008",..: 146 312
160 345 58 69 202 52 236 176 ...
 $ Location     : Factor w/ 1 level "Canberra": 1 1 1 1 1 1 1 1 1 1 ...
 $ MinTemp      : num  17.1 4.6 11.3 0.7 10.3 10.1 3.8 7.1 0.5 4.2 ...
 $ MaxTemp      : num  29.6 14.7 32.3 14.1 21.3 31.2 21.7 28.4 17.1 18.9 ...
 $ Rainfall     : num  0 0 0 0 3 0 0.2 0 0 0 ...
 $ Evaporation  : num  5.8 4.4 9.4 5.6 4.2 8.8 2.8 11.6 4 6.4 ...
 $ Sunshine     : num  9.2 8.4 11.4 9 6.7 13.1 6.5 12.7 9.4 10.8 ...
 $ WindGustDir  : Factor w/ 16 levels "E","ENE","ESE",..: 1 15 5 2 7 8 8 4
8 15 ...
 $ WindGustSpeed: int  48 52 28 20 43 41 44 48 31 50 ...
 $ WindDir9am   : Factor w/ 16 levels "E","ENE","ESE",..: 10 15 2 12 2 9 3
7 3 16 ...
 $ WindDir3pm   : Factor w/ 16 levels "E","ENE","ESE",..: 3 8 15 7 4 14 15
7 14 15 ...
 $ WindSpeed9am : int  9 28 4 6 7 6 2 2 6 6 ...
 $ WindSpeed3pm : int  17 33 6 7 19 20 20 19 13 31 ...
 $ Humidity9am  : int  67 54 44 69 79 45 99 45 74 60 ...
 $ Humidity3pm  : int  38 51 17 43 46 16 34 22 42 34 ...
 $ Pressure9am  : num  1017 1015 1024 1027 1018 ...
 $ Pressure3pm  : num  1013 1012 1021 1022 1014 ...
 $ Cloud9am     : int  6 1 5 7 8 0 7 0 1 3 ...
 $ Cloud3pm     : int  7 3 2 1 1 1 7 1 1 2 ...
 $ Temp9am      : num  21.7 9.2 18.2 7.4 11.7 18.7 7.9 17.2 7.4 11.2 ...
 $ Temp3pm      : num  29.1 12 30.5 13.7 19.8 30.4 20.2 28.2 16.2 18.1 ...
 $ RainToday    : Factor w/ 2 levels "No","Yes": 1 1 1 1 2 1 1 1 1 1 ...
 $ RISK_MM      : num  1.8 0 0 0 0 0 0 0 0 0 ...
 $ RainTomorrow : Factor w/ 2 levels "No","Yes": 2 1 1 1 1 1 1 1 1 1 ...
 - attr(*, "na.action")=Class 'omit'  Named int [1:38] 114 119 128 139 141
175 177 181 190 194 ...
  .. ..- attr(*, "names")= chr [1:38] "114" "119" "128" "139" ...

str(test)
'data.frame': 66 obs. of  24 variables:
 $ Date         : Factor w/ 366 levels "1/1/2008","1/10/2008",..: 85 87 88
90 92 64 65 66 70 71 ...
 $ Location     : Factor w/ 1 level "Canberra": 1 1 1 1 1 1 1 1 1 1 ...
 $ MinTemp      : num  13.7 13.3 7.6 6.1 8.8 8.4 9.1 8.5 12.4 13.8 ...
 $ MaxTemp      : num  23.4 15.5 16.1 18.2 19.5 22.8 25.2 27.3 32.1 31.2 ...
 $ Rainfall     : num  3.6 39.8 2.8 0.2 0 16.2 0 0.2 0 0 ...
 $ Evaporation  : num  5.8 7.2 5.6 4.2 4 5.4 4.2 7.2 8.4 7.2 ...
 $ Sunshine     : num  3.3 9.1 10.6 8.4 4.1 7.7 11.9 12.5 11.1 8.4 ...
 $ WindGustDir  : Factor w/ 16 levels "E","ENE","ESE",..: 8 8 11 10 9 1 4 1
1 3 ...
 $ WindGustSpeed: int  85 54 50 43 48 31 30 41 46 44 ...
 $ WindDir9am   : Factor w/ 16 levels "E","ENE","ESE",..: 4 15 11 10 1 9 10
1 10 16 ...
 $ WindDir3pm   : Factor w/ 16 levels "E","ENE","ESE",..: 6 14 3 3 2 3 8 8
16 14 ...
 $ WindSpeed9am : int  6 30 20 19 19 7 6 2 7 6 ...
 $ WindSpeed3pm : int  6 24 28 26 17 6 9 15 9 19 ...
 $ Humidity9am  : int  82 62 68 63 70 82 74 54 70 72 ...
 $ Humidity3pm  : int  69 56 49 47 48 32 34 35 22 23 ...
 $ Pressure9am  : num  1010 1006 1018 1025 1026 ...
 $ Pressure3pm  : num  1007 1007 1018 1022 1023 ...
 $ Cloud9am     : int  8 2 7 4 7 7 1 0 0 7 ...
 $ Cloud3pm     : int  7 7 7 6 7 1 2 3 3 6 ...
 $ Temp9am      : num  15.4 13.5 11.1 12.4 14.1 13.3 14.6 16.8 19.1 20.2 ...
 $ Temp3pm      : num  20.2 14.1 15.4 17.3 18.9 21.7 24 26 30.7 29.8 ...
 $ RainToday    : Factor w/ 2 levels "No","Yes": 2 2 2 1 1 2 1 1 1 1 ...
 $ RISK_MM      : num  39.8 2.8 0 0 16.2 0 0.2 0 0 1.2 ...
 $ RainTomorrow : Factor w/ 2 levels "No","Yes": 2 2 1 1 2 1 1 1 1 2 ...
 - attr(*, "na.action")=Class 'omit'  Named int [1:38] 114 119 128 139 141
175 177 181 190 194 ...
  .. ..- attr(*, "names")= chr [1:38] "114" "119" "128" "139" ...

x <- model.matrix(RISK_MM~MinTemp + MaxTemp + Rainfall + Evaporation
                  + Sunshine  + WindGustSpeed + WindGustDir + WindDir9am
                  + WindDir3pm + WindSpeed9am + WindSpeed3pm
                  + Humidity9am + Humidity3pm + Pressure9am
                  + Pressure3pm + Cloud9am + Cloud3pm + Temp9am + Temp3pm
                  + RainToday, data=train)

x <- x[,-1]
library(lars)

lasso <- lars(x=x,y=train$RISK_MM,trace=TRUE,type="lasso")

fits <- predict.lars(lasso, test, type="fit")

This last statement generates the error:
Error in scale.default(newx, object$meanx, FALSE) :
  length of 'center' must equal the number of columns of 'x'

I do not know how to interpret this error message or how to resolve the
error.
Any guidance you can provide is appreciated.

Thank you,
Barry E. King Ph.D.
Butler University
College of Business
Indianapolis, Indiana

	[[alternative HTML version deleted]]


From kate.ignatius at gmail.com  Sat May  9 16:59:31 2015
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sat, 9 May 2015 10:59:31 -0400
Subject: [R] Error importing data - wrapping?
Message-ID: <CAE6QMsYRo3CzXzxV11QqnsFQ6LfQByPoVgbxaWzDcZzYwuwevw@mail.gmail.com>

I have some data that I've trouble importing...

A B C D E
A 1232 0.565
B 2323 0.5656 0.5656 0.5656
C 2323 0.5656
D 2323 0.5656
E 2323 0.5656
F 2323 0.5656
G 2323 0.5656
G 2323 0.5656 0.5656 0.5656

When I input the data it seems to go like this:

SampleID ItemB ItemC ItemD ItemE
A 1232 0.565
B 2323 0.5656
0.5656 0.5656
C 2323 0.5656
D 2323 0.5656
E 2323 0.5656
F 2323 0.5656
G 2323 0.5656
G 2323 0.5656 0.5656 0.5656

with the last two columns (or the two columns with vast amounts of
missing data which are usually the last two = see SampleB) wrapping
around - is there away to prevent this?

Thanks!


From jdnewmil at dcn.davis.CA.us  Sat May  9 17:11:13 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 09 May 2015 08:11:13 -0700
Subject: [R] Error importing data - wrapping?
In-Reply-To: <CAE6QMsYRo3CzXzxV11QqnsFQ6LfQByPoVgbxaWzDcZzYwuwevw@mail.gmail.com>
References: <CAE6QMsYRo3CzXzxV11QqnsFQ6LfQByPoVgbxaWzDcZzYwuwevw@mail.gmail.com>
Message-ID: <56AF89F8-25F9-4CFD-9956-6DC07C8E0AAE@dcn.davis.CA.us>

There are many ways to import data into R, and I don't know any of them that would do what you are describing. You really need to give us some reproducible code if we are to follow along with your problem.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 9, 2015 7:59:31 AM PDT, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>I have some data that I've trouble importing...
>
>A B C D E
>A 1232 0.565
>B 2323 0.5656 0.5656 0.5656
>C 2323 0.5656
>D 2323 0.5656
>E 2323 0.5656
>F 2323 0.5656
>G 2323 0.5656
>G 2323 0.5656 0.5656 0.5656
>
>When I input the data it seems to go like this:
>
>SampleID ItemB ItemC ItemD ItemE
>A 1232 0.565
>B 2323 0.5656
>0.5656 0.5656
>C 2323 0.5656
>D 2323 0.5656
>E 2323 0.5656
>F 2323 0.5656
>G 2323 0.5656
>G 2323 0.5656 0.5656 0.5656
>
>with the last two columns (or the two columns with vast amounts of
>missing data which are usually the last two = see SampleB) wrapping
>around - is there away to prevent this?
>
>Thanks!
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Sat May  9 17:13:46 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Sat, 9 May 2015 15:13:46 +0000
Subject: [R] Error importing data - wrapping?
In-Reply-To: <CAE6QMsYRo3CzXzxV11QqnsFQ6LfQByPoVgbxaWzDcZzYwuwevw@mail.gmail.com>
References: <CAE6QMsYRo3CzXzxV11QqnsFQ6LfQByPoVgbxaWzDcZzYwuwevw@mail.gmail.com>
Message-ID: <D17371BC.1283EC%macqueen1@llnl.gov>

Some indication of what you have tried would be useful. Assuming you are
using read.table(), then the "fill" argument of read.table() might be what
you need. If you look at the help for read.table you will find:

>From ?read.table:
   fill: logical. If 'TRUE' then in case the rows have unequal length,
          blank fields are implicitly added.  See 'Details'.


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/9/15, 7:59 AM, "Kate Ignatius" <kate.ignatius at gmail.com> wrote:

>I have some data that I've trouble importing...
>
>A B C D E
>A 1232 0.565
>B 2323 0.5656 0.5656 0.5656
>C 2323 0.5656
>D 2323 0.5656
>E 2323 0.5656
>F 2323 0.5656
>G 2323 0.5656
>G 2323 0.5656 0.5656 0.5656
>
>When I input the data it seems to go like this:
>
>SampleID ItemB ItemC ItemD ItemE
>A 1232 0.565
>B 2323 0.5656
>0.5656 0.5656
>C 2323 0.5656
>D 2323 0.5656
>E 2323 0.5656
>F 2323 0.5656
>G 2323 0.5656
>G 2323 0.5656 0.5656 0.5656
>
>with the last two columns (or the two columns with vast amounts of
>missing data which are usually the last two = see SampleB) wrapping
>around - is there away to prevent this?
>
>Thanks!
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kate.ignatius at gmail.com  Sat May  9 17:22:22 2015
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sat, 9 May 2015 11:22:22 -0400
Subject: [R] Error importing data - wrapping?
In-Reply-To: <D17371BC.1283EC%macqueen1@llnl.gov>
References: <CAE6QMsYRo3CzXzxV11QqnsFQ6LfQByPoVgbxaWzDcZzYwuwevw@mail.gmail.com>
	<D17371BC.1283EC%macqueen1@llnl.gov>
Message-ID: <CAE6QMsaDXjri_+i6u5hPWk=ob0T6Mj-qa31eoHYtKwit07S5Sw@mail.gmail.com>

I've tried colClasses="character", fill=T, as.is=T, header=F,
sep="\t", read.csv; read.delim, read.csv2, read.delim2.... don't know
what else to try.

On Sat, May 9, 2015 at 11:13 AM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> Some indication of what you have tried would be useful. Assuming you are
> using read.table(), then the "fill" argument of read.table() might be what
> you need. If you look at the help for read.table you will find:
>
> From ?read.table:
>    fill: logical. If 'TRUE' then in case the rows have unequal length,
>           blank fields are implicitly added.  See 'Details'.
>
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 5/9/15, 7:59 AM, "Kate Ignatius" <kate.ignatius at gmail.com> wrote:
>
>>I have some data that I've trouble importing...
>>
>>A B C D E
>>A 1232 0.565
>>B 2323 0.5656 0.5656 0.5656
>>C 2323 0.5656
>>D 2323 0.5656
>>E 2323 0.5656
>>F 2323 0.5656
>>G 2323 0.5656
>>G 2323 0.5656 0.5656 0.5656
>>
>>When I input the data it seems to go like this:
>>
>>SampleID ItemB ItemC ItemD ItemE
>>A 1232 0.565
>>B 2323 0.5656
>>0.5656 0.5656
>>C 2323 0.5656
>>D 2323 0.5656
>>E 2323 0.5656
>>F 2323 0.5656
>>G 2323 0.5656
>>G 2323 0.5656 0.5656 0.5656
>>
>>with the last two columns (or the two columns with vast amounts of
>>missing data which are usually the last two = see SampleB) wrapping
>>around - is there away to prevent this?
>>
>>Thanks!
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From kate.ignatius at gmail.com  Sat May  9 17:28:03 2015
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sat, 9 May 2015 11:28:03 -0400
Subject: [R] Error importing data - wrapping?
In-Reply-To: <56AF89F8-25F9-4CFD-9956-6DC07C8E0AAE@dcn.davis.CA.us>
References: <CAE6QMsYRo3CzXzxV11QqnsFQ6LfQByPoVgbxaWzDcZzYwuwevw@mail.gmail.com>
	<56AF89F8-25F9-4CFD-9956-6DC07C8E0AAE@dcn.davis.CA.us>
Message-ID: <CAE6QMsa9Z742-d9pCLa_0qGdq=f9f6zD2k8BW96z9P0PCrDGNA@mail.gmail.com>

I've tried many things:

read.csv("data.frame.txt", header=F, fill=T,stringsAsFactors=FALSE,
sep="\t", colClasses="character")
read.csv2("data.frame.txt", fill=T,stringsAsFactors=FALSE, sep="\t",
as.is=T, colClasses="character")

also with read.delim/2

read.table("data.frame.txt", header=F, fill=T,stringsAsFactors=FALSE,
sep="\t", colClasses="character")

And a combination of various different options.

On Sat, May 9, 2015 at 11:11 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> There are many ways to import data into R, and I don't know any of them that would do what you are describing. You really need to give us some reproducible code if we are to follow along with your problem.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On May 9, 2015 7:59:31 AM PDT, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>>I have some data that I've trouble importing...
>>
>>A B C D E
>>A 1232 0.565
>>B 2323 0.5656 0.5656 0.5656
>>C 2323 0.5656
>>D 2323 0.5656
>>E 2323 0.5656
>>F 2323 0.5656
>>G 2323 0.5656
>>G 2323 0.5656 0.5656 0.5656
>>
>>When I input the data it seems to go like this:
>>
>>SampleID ItemB ItemC ItemD ItemE
>>A 1232 0.565
>>B 2323 0.5656
>>0.5656 0.5656
>>C 2323 0.5656
>>D 2323 0.5656
>>E 2323 0.5656
>>F 2323 0.5656
>>G 2323 0.5656
>>G 2323 0.5656 0.5656 0.5656
>>
>>with the last two columns (or the two columns with vast amounts of
>>missing data which are usually the last two = see SampleB) wrapping
>>around - is there away to prevent this?
>>
>>Thanks!
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Sat May  9 18:43:23 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 9 May 2015 09:43:23 -0700
Subject: [R] Error importing data - wrapping?
In-Reply-To: <CAE6QMsaDXjri_+i6u5hPWk=ob0T6Mj-qa31eoHYtKwit07S5Sw@mail.gmail.com>
References: <CAE6QMsYRo3CzXzxV11QqnsFQ6LfQByPoVgbxaWzDcZzYwuwevw@mail.gmail.com>
	<D17371BC.1283EC%macqueen1@llnl.gov>
	<CAE6QMsaDXjri_+i6u5hPWk=ob0T6Mj-qa31eoHYtKwit07S5Sw@mail.gmail.com>
Message-ID: <CAF8bMcauvyM+HrMZfN8Let5q-WsND+1gvP3Pg0_7ouiLAEjN3A@mail.gmail.com>

txt <- c("A B C D E", "A 1232 0.565", "B 2323 0.5656 0.5656 0.5656",
 "C 2323 0.5656", "D 2323 0.5656", "E 2323 0.5656", "F 2323 0.5656",
 "G 2323 0.5656", "G 2323 0.5656 0.5656 0.5656")
z <- read.table(text=txt, fill=TRUE, header=TRUE)
str(z)
#'data.frame':   8 obs. of  5 variables:
# $ A: Factor w/ 7 levels "A","B","C","D",..: 1 2 3 4 5 6 7 7
# $ B: int  1232 2323 2323 2323 2323 2323 2323 2323
# $ C: num  0.565 0.566 0.566 0.566 0.566 ...
# $ D: num  NA 0.566 NA NA NA ...
# $ E: num  NA 0.566 NA NA NA ...

If your file contains extra spaces or tabs at the ends of the lines it
is possible that using sep="\t" may mess things up: using an explicit
'sep' argument means that you have to use it consistently as a separator.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, May 9, 2015 at 8:22 AM, Kate Ignatius <kate.ignatius at gmail.com>
wrote:

> I've tried colClasses="character", fill=T, as.is=T, header=F,
> sep="\t", read.csv; read.delim, read.csv2, read.delim2.... don't know
> what else to try.
>
> On Sat, May 9, 2015 at 11:13 AM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> > Some indication of what you have tried would be useful. Assuming you are
> > using read.table(), then the "fill" argument of read.table() might be
> what
> > you need. If you look at the help for read.table you will find:
> >
> > From ?read.table:
> >    fill: logical. If 'TRUE' then in case the rows have unequal length,
> >           blank fields are implicitly added.  See 'Details'.
> >
> >
> > --
> > Don MacQueen
> >
> > Lawrence Livermore National Laboratory
> > 7000 East Ave., L-627
> > Livermore, CA 94550
> > 925-423-1062
> >
> >
> >
> >
> >
> > On 5/9/15, 7:59 AM, "Kate Ignatius" <kate.ignatius at gmail.com> wrote:
> >
> >>I have some data that I've trouble importing...
> >>
> >>A B C D E
> >>A 1232 0.565
> >>B 2323 0.5656 0.5656 0.5656
> >>C 2323 0.5656
> >>D 2323 0.5656
> >>E 2323 0.5656
> >>F 2323 0.5656
> >>G 2323 0.5656
> >>G 2323 0.5656 0.5656 0.5656
> >>
> >>When I input the data it seems to go like this:
> >>
> >>SampleID ItemB ItemC ItemD ItemE
> >>A 1232 0.565
> >>B 2323 0.5656
> >>0.5656 0.5656
> >>C 2323 0.5656
> >>D 2323 0.5656
> >>E 2323 0.5656
> >>F 2323 0.5656
> >>G 2323 0.5656
> >>G 2323 0.5656 0.5656 0.5656
> >>
> >>with the last two columns (or the two columns with vast amounts of
> >>missing data which are usually the last two = see SampleB) wrapping
> >>around - is there away to prevent this?
> >>
> >>Thanks!
> >>
> >>______________________________________________
> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide
> >>http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rashnaikk at gmail.com  Sat May  9 13:21:26 2015
From: rashnaikk at gmail.com (Rashmi Naik k)
Date: Sat, 9 May 2015 16:51:26 +0530
Subject: [R] How to define fitness function to optimize the products price
Message-ID: <CAKKZ-YG8q1is2Pq60bq1w=00Ss1zADgeuh1ufFLVtiivrob3wQ@mail.gmail.com>

Dear Sir/Madam

I'm Working on a research project called "Dynamic price optimization" using
genetic algorithm to optimize product price's in an e-commerce store. I'm
doing this project using R language (package GA). I need help in defining a
Fitness function to optimize the products price. Can any one help me on
this.!!

Regards
Rashmi Naik

	[[alternative HTML version deleted]]


From mabrouk.abaza.1 at ulaval.ca  Sat May  9 12:48:14 2015
From: mabrouk.abaza.1 at ulaval.ca (maaba)
Date: Sat, 9 May 2015 03:48:14 -0700 (PDT)
Subject: [R] rgamma NaN error message
Message-ID: <1431168494030-4706992.post@n4.nabble.com>

hi,
i need to generate 250 random values with rgamma function. The problem that
i have a negative scale parameter (provided by ensembleBMAgamma0 function).
i received a NaN error message 

any help !

thanks



--
View this message in context: http://r.789695.n4.nabble.com/rgamma-NaN-error-message-tp4706992.html
Sent from the R help mailing list archive at Nabble.com.


From mabrouk.abaza.1 at ulaval.ca  Sat May  9 15:20:53 2015
From: mabrouk.abaza.1 at ulaval.ca (maaba)
Date: Sat, 9 May 2015 06:20:53 -0700 (PDT)
Subject: [R] extract the parameters of the BMA distribution
Message-ID: <1431177653118-4706994.post@n4.nabble.com>

Hi,
i need to extract the parameters of the BMA predictive distribution. when i
use modelParameters( fit, ...) i obtain the parameters of each member. In my
case i would likte to extact the parameters for the global BMA gamma
distribution (global model) and not for each member

any help !

thanks



--
View this message in context: http://r.789695.n4.nabble.com/extract-the-parameters-of-the-BMA-distribution-tp4706994.html
Sent from the R help mailing list archive at Nabble.com.


From glennmschultz at me.com  Sat May  9 20:18:54 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Sat, 09 May 2015 18:18:54 +0000 (GMT)
Subject: [R] Package Build question for Bond Lab
Message-ID: <b94a84d4-adaa-41b3-919a-68ff799d71eb@me.com>

Hello All,

I have set-up the \inst directory and now looking to the .onLoad and .onAttach for side Effects. ?The Bond Lab data directories are all in \inst\BondLab. ?

The connection functions for BondLab are ~\users\BondLab\foo. ?

I would like to be able to create and copy the \inst\BondLab folder at I think attachment. ?Obviously the directory paths are different. ?My question is: ?If I copy and set-up directories with the .onLoad hook will strategy this abstract away the OS? ?Using the .onUnload hook I can remove the directories ~\users\BondLab.

This is the last large technical issue I need to resolve for BondLab. ?I read the writing packages section on 1.5.3 on loan hooks but it really does not address this question.

Best Regards,
Glenn


From gunter.berton at gene.com  Sat May  9 22:54:10 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 9 May 2015 13:54:10 -0700
Subject: [R] How to define fitness function to optimize the products
	price
In-Reply-To: <CAKKZ-YG8q1is2Pq60bq1w=00Ss1zADgeuh1ufFLVtiivrob3wQ@mail.gmail.com>
References: <CAKKZ-YG8q1is2Pq60bq1w=00Ss1zADgeuh1ufFLVtiivrob3wQ@mail.gmail.com>
Message-ID: <CACk-te2Ns1r2fFtHhUz_8kCGRZE2C2-AzQRmD=N=Hout7idpMg@mail.gmail.com>

Way way off topic. Ask your instructor for help or clarification. We
do neither homework nor theses here.

(But you may wish to search the Optimization task view here for
packages that might be relevant:
http://cran.r-project.org/web/views/Optimization.html  0

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, May 9, 2015 at 4:21 AM, Rashmi Naik k <rashnaikk at gmail.com> wrote:
> Dear Sir/Madam
>
> I'm Working on a research project called "Dynamic price optimization" using
> genetic algorithm to optimize product price's in an e-commerce store. I'm
> doing this project using R language (package GA). I need help in defining a
> Fitness function to optimize the products price. Can any one help me on
> this.!!
>
> Regards
> Rashmi Naik
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun May 10 01:08:53 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 10 May 2015 09:08:53 +1000
Subject: [R] Error importing data - wrapping?
In-Reply-To: <CAF8bMcauvyM+HrMZfN8Let5q-WsND+1gvP3Pg0_7ouiLAEjN3A@mail.gmail.com>
References: <CAE6QMsYRo3CzXzxV11QqnsFQ6LfQByPoVgbxaWzDcZzYwuwevw@mail.gmail.com>
	<D17371BC.1283EC%macqueen1@llnl.gov>
	<CAE6QMsaDXjri_+i6u5hPWk=ob0T6Mj-qa31eoHYtKwit07S5Sw@mail.gmail.com>
	<CAF8bMcauvyM+HrMZfN8Let5q-WsND+1gvP3Pg0_7ouiLAEjN3A@mail.gmail.com>
Message-ID: <CA+8X3fWP7wwvjK7+TUn4Kd7rLD5dYCQqZ+r0Kqgf0-LGT1wmig@mail.gmail.com>

Hi Kate,
The following:

x<-read.table(text="A B C D E
A 1232 0.565
B 2323 0.5656 0.5656 0.5656
C 2323 0.5656
D 2323 0.5656
E 2323 0.5656
F 2323 0.5656
G 2323 0.5656
G 2323 0.5656 0.5656 0.5656",header=TRUE,fill=TRUE)

works fine for me:

x
  A    B      C      D      E
1 A 1232 0.5650     NA     NA
2 B 2323 0.5656 0.5656 0.5656
3 C 2323 0.5656     NA     NA
4 D 2323 0.5656     NA     NA
5 E 2323 0.5656     NA     NA
6 F 2323 0.5656     NA     NA
7 G 2323 0.5656     NA     NA
8 G 2323 0.5656 0.5656 0.5656

I just copied your example text into a text editor and added the
"x<-read.table...". Do you really have TAB delimiters in the file you
are trying to import? If so, can you do a global replace of TAB ->
space in the incoming file?

Jim


On Sun, May 10, 2015 at 2:43 AM, William Dunlap <wdunlap at tibco.com> wrote:
> txt <- c("A B C D E", "A 1232 0.565", "B 2323 0.5656 0.5656 0.5656",
>  "C 2323 0.5656", "D 2323 0.5656", "E 2323 0.5656", "F 2323 0.5656",
>  "G 2323 0.5656", "G 2323 0.5656 0.5656 0.5656")
> z <- read.table(text=txt, fill=TRUE, header=TRUE)
> str(z)
> #'data.frame':   8 obs. of  5 variables:
> # $ A: Factor w/ 7 levels "A","B","C","D",..: 1 2 3 4 5 6 7 7
> # $ B: int  1232 2323 2323 2323 2323 2323 2323 2323
> # $ C: num  0.565 0.566 0.566 0.566 0.566 ...
> # $ D: num  NA 0.566 NA NA NA ...
> # $ E: num  NA 0.566 NA NA NA ...
>
> If your file contains extra spaces or tabs at the ends of the lines it
> is possible that using sep="\t" may mess things up: using an explicit
> 'sep' argument means that you have to use it consistently as a separator.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Sat, May 9, 2015 at 8:22 AM, Kate Ignatius <kate.ignatius at gmail.com>
> wrote:
>
>> I've tried colClasses="character", fill=T, as.is=T, header=F,
>> sep="\t", read.csv; read.delim, read.csv2, read.delim2.... don't know
>> what else to try.
>>
>> On Sat, May 9, 2015 at 11:13 AM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>> > Some indication of what you have tried would be useful. Assuming you are
>> > using read.table(), then the "fill" argument of read.table() might be
>> what
>> > you need. If you look at the help for read.table you will find:
>> >
>> > From ?read.table:
>> >    fill: logical. If 'TRUE' then in case the rows have unequal length,
>> >           blank fields are implicitly added.  See 'Details'.
>> >
>> >
>> > --
>> > Don MacQueen
>> >
>> > Lawrence Livermore National Laboratory
>> > 7000 East Ave., L-627
>> > Livermore, CA 94550
>> > 925-423-1062
>> >
>> >
>> >
>> >
>> >
>> > On 5/9/15, 7:59 AM, "Kate Ignatius" <kate.ignatius at gmail.com> wrote:
>> >
>> >>I have some data that I've trouble importing...
>> >>
>> >>A B C D E
>> >>A 1232 0.565
>> >>B 2323 0.5656 0.5656 0.5656
>> >>C 2323 0.5656
>> >>D 2323 0.5656
>> >>E 2323 0.5656
>> >>F 2323 0.5656
>> >>G 2323 0.5656
>> >>G 2323 0.5656 0.5656 0.5656
>> >>
>> >>When I input the data it seems to go like this:
>> >>
>> >>SampleID ItemB ItemC ItemD ItemE
>> >>A 1232 0.565
>> >>B 2323 0.5656
>> >>0.5656 0.5656
>> >>C 2323 0.5656
>> >>D 2323 0.5656
>> >>E 2323 0.5656
>> >>F 2323 0.5656
>> >>G 2323 0.5656
>> >>G 2323 0.5656 0.5656 0.5656
>> >>
>> >>with the last two columns (or the two columns with vast amounts of
>> >>missing data which are usually the last two = see SampleB) wrapping
>> >>around - is there away to prevent this?
>> >>
>> >>Thanks!
>> >>
>> >>______________________________________________
>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>> >>PLEASE do read the posting guide
>> >>http://www.R-project.org/posting-guide.html
>> >>and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From zadig_1 at excite.com  Sun May 10 01:35:13 2015
From: zadig_1 at excite.com (ce)
Date: Sat, 09 May 2015 19:35:13 -0400
Subject: [R] how to update a value in a list with lapply
Message-ID: <20150509193513.15712@web006.roc2.bluetie.com>

Dear All,

I have a list, using lapply I find some elements of the list, and then I want to change the values I find. but it doesn't work:

 foo<-list(A = c(1,3), B =c(1, 2), C = c(3, 1))
 lapply(foo, function(x) if(x[1] == 1 ) x )
$A
[1] 1 3

$B
[1] 1 2

$C
NULL

 lapply(foo, function(x) if(x[1] == 1 ) x[2] <- 0 )
$A
[1] 0

$B
[1] 0

$C
NULL

>  lapply(foo, function(x) if(x[1] == 1 ) x )
$A
[1] 1 3

$B
[1] 1 2

$C
NULL


how to do it correctly ?
thanks


From dwinsemius at comcast.net  Sun May 10 02:00:20 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 9 May 2015 17:00:20 -0700
Subject: [R] how to update a value in a list with lapply
In-Reply-To: <20150509193513.15712@web006.roc2.bluetie.com>
References: <20150509193513.15712@web006.roc2.bluetie.com>
Message-ID: <31AC6099-2D7C-42F4-99BB-F0D6E9D6E218@comcast.net>


On May 9, 2015, at 4:35 PM, ce wrote:

> Dear All,
> 
> I have a list, using lapply I find some elements of the list, and then I want to change the values I find. but it doesn't work:
> 
> foo<-list(A = c(1,3), B =c(1, 2), C = c(3, 1))
> lapply(foo, function(x) if(x[1] == 1 ) x )
> $A
> [1] 1 3
> 
> $B
> [1] 1 2
> 
> $C
> NULL
> 
> lapply(foo, function(x) if(x[1] == 1 ) x[2] <- 0 )
> $A
> [1] 0
> 
> $B
> [1] 0
> 
> $C
> NULL
> 
>> lapply(foo, function(x) if(x[1] == 1 ) x )
> $A
> [1] 1 3
> 
> $B
> [1] 1 2
> 
> $C
> NULL
> 
> 
> how to do it correctly ?

I find it useful to think of the `if` function as `if(cond){cons}else{alt}`

lapply(foo, function(x)  if(x[1] == 1 ) {x[2] <- 0; x }else{x} )
#-----
$A
[1] 1 0

$B
[1] 1 0

$C
[1] 3 1


You were not supply an alternative which was the cause of the NULL (and you were not returning a value which meant that the value returned was the value on the RHS of the assignment).

-- 

David Winsemius
Alameda, CA, USA


From chow.boris at gmail.com  Sun May 10 04:44:31 2015
From: chow.boris at gmail.com (Boris Chow)
Date: Sun, 10 May 2015 10:44:31 +0800
Subject: [R] New to R
Message-ID: <0D0FB2BF-EEEF-4031-B2EA-6486D4A1AA9C@gmail.com>

Dear R users,

I am new to R community and would like to dig into it. Would you advise what are the appropriate steps to do so?

I want to do a pricing of an American option as my first exercise. Can some experienced users give me some pointers to do so?

Thanks a lot,
Boris

From luysgarcia at gmail.com  Sun May 10 08:11:51 2015
From: luysgarcia at gmail.com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Sun, 10 May 2015 03:11:51 -0300
Subject: [R] New to R
In-Reply-To: <0D0FB2BF-EEEF-4031-B2EA-6486D4A1AA9C@gmail.com>
References: <0D0FB2BF-EEEF-4031-B2EA-6486D4A1AA9C@gmail.com>
Message-ID: <CANxP2S5s2d_s60Kh8mN6LH_khsmBwZ51gi+5VonCOH21Q_+MoA@mail.gmail.com>

Dear Boris,

I am new too, but got a lot of help from this webpage. I hope it will work
for you too,

All the best!

http://tryr.codeschool.com/

2015-05-09 23:44 GMT-03:00 Boris Chow <chow.boris at gmail.com>:

> Dear R users,
>
> I am new to R community and would like to dig into it. Would you advise
> what are the appropriate steps to do so?
>
> I want to do a pricing of an American option as my first exercise. Can
> some experienced users give me some pointers to do so?
>
> Thanks a lot,
> Boris
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rex at nosyntax.net  Sun May 10 10:59:02 2015
From: rex at nosyntax.net (rex)
Date: Sun, 10 May 2015 01:59:02 -0700
Subject: [R] New to R
In-Reply-To: <0D0FB2BF-EEEF-4031-B2EA-6486D4A1AA9C@gmail.com>
References: <0D0FB2BF-EEEF-4031-B2EA-6486D4A1AA9C@gmail.com>
Message-ID: <20150510085902.GE11534@nosyntax.net>

Boris Chow <chow.boris at gmail.com> [2015-05-09 20:04]:

>I want to do a pricing of an American option as my first exercise. Can some experienced users give me some pointers to do so?

https://stat.ethz.ch/mailman/listinfo/r-sig-finance

http://cran.r-project.org/web/packages/AmericanCallOpt/AmericanCallOpt.pdf

http://cran.r-project.org/web/packages/fOptions/fOptions.pdf


-rex
-- 
"The market can remain irrational longer than you can remain solvent."
 -- John Maynard Keynes


From ragia11 at hotmail.com  Sun May 10 11:26:09 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Sun, 10 May 2015 12:26:09 +0300
Subject: [R] get the first row ?
In-Reply-To: <DUB125-W28F7F412902742718170DCB3FE0@phx.gbl>
References: <mailman.0.1418986801.25142.r-help@r-project.org>, ,
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>,
	<DUB125-W505E345B0446A1728391D5B3FE0@phx.gbl>,
	<5522CE52.3080407@sapo.pt>,
	<DUB125-W28F7F412902742718170DCB3FE0@phx.gbl>
Message-ID: <DUB125-W22A75C36DF664CC6C21287B3DC0@phx.gbl>

Dear group
kindly

I have a logical data type 
ISINFCluster:
    1     2     3     4     5     6     7     8     9    10    11    12    13    14 
FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 
   15    16    17    18    19    20    21    22    23    24    25    26    27    28 
FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE 
   29    30    31    32    33    34    35    36    37    38    39    40    41    42 
FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 
   43    44    45    46    47    48    49    50 
FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 

and I want to get just number of records from those that has the  value true, thus 

 firstclass<-     all[ISINCluster]  
where  all is numeric object 
1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 
 1  1  2  1  3  1  1  2  5  4  1  6  8  1  2  1  3  3  2 13  1  4  2  4  7  1 14  1  1 
30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 
 1  1  2  2  1  1  2  2  2  9  3  1  1  3  6  1  4  1  3  9  2 

the firstclass containes the following
firstclass
20 27 
13 14 

And I could not get the first row..
head(firstclass)
20 27 
13 14 


how can I got it?
thanks in advance
Ragia



 		 	   		  
	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun May 10 11:46:00 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 10 May 2015 19:46:00 +1000
Subject: [R] get the first row ?
In-Reply-To: <DUB125-W22A75C36DF664CC6C21287B3DC0@phx.gbl>
References: <mailman.0.1418986801.25142.r-help@r-project.org>
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>
	<DUB125-W505E345B0446A1728391D5B3FE0@phx.gbl>
	<5522CE52.3080407@sapo.pt>
	<DUB125-W28F7F412902742718170DCB3FE0@phx.gbl>
	<DUB125-W22A75C36DF664CC6C21287B3DC0@phx.gbl>
Message-ID: <CA+8X3fVypFvysj8OTXr4FgEsLd=svv6vVwLA-4JofDyKc9JghQ@mail.gmail.com>

Hi Ragia,
This is a bit cryptic. "ISINFCluster" looks like a 50 element logical
vector with two TRUE values.
"all" looks like a 50 element numeric vector of counts for each value.
"firstclass" contains the 20th and 27th elements of "all", selected
with "ISINFCluster".
As "firstclass" is a two element named vector, there is only one "row"
and that includes the entire object.

Jim


On Sun, May 10, 2015 at 7:26 PM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
> Dear group
> kindly
>
> I have a logical data type
> ISINFCluster:
>     1     2     3     4     5     6     7     8     9    10    11    12    13    14
> FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>    15    16    17    18    19    20    21    22    23    24    25    26    27    28
> FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE
>    29    30    31    32    33    34    35    36    37    38    39    40    41    42
> FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>    43    44    45    46    47    48    49    50
> FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>
> and I want to get just number of records from those that has the  value true, thus
>
>  firstclass<-     all[ISINCluster]
> where  all is numeric object
> 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
>  1  1  2  1  3  1  1  2  5  4  1  6  8  1  2  1  3  3  2 13  1  4  2  4  7  1 14  1  1
> 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
>  1  1  2  2  1  1  2  2  2  9  3  1  1  3  6  1  4  1  3  9  2
>
> the firstclass containes the following
> firstclass
> 20 27
> 13 14
>
> And I could not get the first row..
> head(firstclass)
> 20 27
> 13 14
>
>
> how can I got it?
> thanks in advance
> Ragia
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ragia11 at hotmail.com  Sun May 10 12:00:38 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Sun, 10 May 2015 13:00:38 +0300
Subject: [R] get sub elements
In-Reply-To: <DUB125-W22A75C36DF664CC6C21287B3DC0@phx.gbl>
References: <mailman.0.1418986801.25142.r-help@r-project.org>, ,
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>,
	<DUB125-W505E345B0446A1728391D5B3FE0@phx.gbl>,
	<5522CE52.3080407@sapo.pt>,
	<DUB125-W28F7F412902742718170DCB3FE0@phx.gbl>,
	<DUB125-W22A75C36DF664CC6C21287B3DC0@phx.gbl>
Message-ID: <DUB125-W31581C48971462021A37DFB3DC0@phx.gbl>

Dear group 
I have this numeric object
allrecords 
1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 
 1  1  2  1  3  1  1  2  5  4  1  6  8  1  2  1  3  3  2 13  1  4  2  4  7  1 14  1  1 
30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 
 1  1  2  2  1  1  2  2  2  9  3  1  1  3  6  1  4  1  3  9  2 


how can I extract only records between 9 and 5 values only  and put the record number n a vector

it should be vector 
thanks in advance
Ragia



 		 	   		   		 	   		  
	[[alternative HTML version deleted]]


From robertsonburns at btinternet.com  Sun May 10 12:54:57 2015
From: robertsonburns at btinternet.com (J Robertson-Burns)
Date: Sun, 10 May 2015 11:54:57 +0100
Subject: [R] get the first row ?
In-Reply-To: <DUB125-W22A75C36DF664CC6C21287B3DC0@phx.gbl>
References: <mailman.0.1418986801.25142.r-help@r-project.org>, ,
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>,
	<DUB125-W505E345B0446A1728391D5B3FE0@phx.gbl>,
	<5522CE52.3080407@sapo.pt>,
	<DUB125-W28F7F412902742718170DCB3FE0@phx.gbl>
	<DUB125-W22A75C36DF664CC6C21287B3DC0@phx.gbl>
Message-ID: <554F3901.4040609@btinternet.com>

It looks to me like you need to understand
subscripting in R.  One place (among many)
to learn subscripting is:

http://www.burns-stat.com/documents/tutorials/impatient-r/

Pat

On 10/05/2015 10:26, Ragia Ibrahim wrote:
> Dear group
> kindly
>
> I have a logical data type
> ISINFCluster:
>      1     2     3     4     5     6     7     8     9    10    11    12    13    14
> FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>     15    16    17    18    19    20    21    22    23    24    25    26    27    28
> FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE
>     29    30    31    32    33    34    35    36    37    38    39    40    41    42
> FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>     43    44    45    46    47    48    49    50
> FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>
> and I want to get just number of records from those that has the  value true, thus
>
>   firstclass<-     all[ISINCluster]
> where  all is numeric object
> 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
>   1  1  2  1  3  1  1  2  5  4  1  6  8  1  2  1  3  3  2 13  1  4  2  4  7  1 14  1  1
> 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
>   1  1  2  2  1  1  2  2  2  9  3  1  1  3  6  1  4  1  3  9  2
>
> the firstclass containes the following
> firstclass
> 20 27
> 13 14
>
> And I could not get the first row..
> head(firstclass)
> 20 27
> 13 14
>
>
> how can I got it?
> thanks in advance
> Ragia
>
>
>
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From giorgio.garziano at ericsson.com  Sun May 10 13:27:45 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Sun, 10 May 2015 11:27:45 +0000
Subject: [R] Variance-covariance matrix
Message-ID: <248E6FA047A8C746BA491485764190F521FBC3BD@ESESSMB207.ericsson.se>

Hi,

I am looking for a R package providing with variance-covariance matrix computation of univariate time series.

Please, any suggestions ?

Regards,

Giorgio


	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sun May 10 13:33:54 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 10 May 2015 12:33:54 +0100
Subject: [R] get sub elements
In-Reply-To: <DUB125-W31581C48971462021A37DFB3DC0@phx.gbl>
References: <mailman.0.1418986801.25142.r-help@r-project.org>, ,
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>,
	<DUB125-W505E345B0446A1728391D5B3FE0@phx.gbl>,
	<5522CE52.3080407@sapo.pt>,
	<DUB125-W28F7F412902742718170DCB3FE0@phx.gbl>,
	<DUB125-W22A75C36DF664CC6C21287B3DC0@phx.gbl>
	<DUB125-W31581C48971462021A37DFB3DC0@phx.gbl>
Message-ID: <554F4222.8030600@sapo.pt>

Hello,

You should learn about indexing in R. Read the pdf R-intro.pdf that 
comes with your installation of R.

allrecords[5 <= allrecords & allrecords <= 9]

should do it.

Hope this helps,

Rui Barradas

Em 10-05-2015 11:00, Ragia Ibrahim escreveu:
> Dear group
> I have this numeric object
> allrecords
> 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
>   1  1  2  1  3  1  1  2  5  4  1  6  8  1  2  1  3  3  2 13  1  4  2  4  7  1 14  1  1
> 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
>   1  1  2  2  1  1  2  2  2  9  3  1  1  3  6  1  4  1  3  9  2
>
>
> how can I extract only records between 9 and 5 values only  and put the record number n a vector
>
> it should be vector
> thanks in advance
> Ragia
>
>
>
>   		 	   		   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r.turner at auckland.ac.nz  Sun May 10 14:15:50 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 11 May 2015 00:15:50 +1200
Subject: [R] Building R-3.2.0 from source.
Message-ID: <554F4BF6.8060508@auckland.ac.nz>



I am just now getting around to upgrading from 3.1.2 to 3.2.0 and am 
getting hammered by a problem which is beyond my limited capabilities of 
handling.

I executed

   ./configure --with-tcltk --with cairo

which seemed to go just fine, and then did:

    make

In fairly short order I started getting  error messages like unto:

> connections.o: In function `gzcon_write':
> /home/rolf/Desktop/Rinst/R-3.2.0/src/main/connections.c:5469: undefined reference to `deflate'

There were also complaints about undefined references to inflate, crc32, 
deflateEnd, inflateEnd, inflateReset, inflateInit2_, deflateInit2_, 
compress, uncompress, and zlibVersion, many of which were issued 
repeatedly.  It finally gave up, saying:

> collect2: error: ld returned 1 exit status

A bit of googling informed me (I think?) that a workaround was to 
configure using --without-system-pcre.  This however achieved nothing in 
my case.

Can anyone point me at what I need to do to fix this?  Install or update 
something?

I am running an (elderly, no-longer-supported) Fedora 17 Linux.

Thanks for any assistance.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From pdalgd at gmail.com  Sun May 10 14:50:37 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 10 May 2015 14:50:37 +0200
Subject: [R] Building R-3.2.0 from source.
In-Reply-To: <554F4BF6.8060508@auckland.ac.nz>
References: <554F4BF6.8060508@auckland.ac.nz>
Message-ID: <425F1A4A-454E-4CF0-A9D5-766DAA301A86@gmail.com>


> On 10 May 2015, at 14:15 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> 
> I am just now getting around to upgrading from 3.1.2 to 3.2.0 and am getting hammered by a problem which is beyond my limited capabilities of handling.
> 
> I executed
> 
>  ./configure --with-tcltk --with cairo
> 
> which seemed to go just fine, and then did:
> 
>   make
> 
> In fairly short order I started getting  error messages like unto:
> 
>> connections.o: In function `gzcon_write':
>> /home/rolf/Desktop/Rinst/R-3.2.0/src/main/connections.c:5469: undefined reference to `deflate'
> 
> There were also complaints about undefined references to inflate, crc32, deflateEnd, inflateEnd, inflateReset, inflateInit2_, deflateInit2_, compress, uncompress, and zlibVersion, many of which were issued repeatedly.  It finally gave up, saying:
> 
>> collect2: error: ld returned 1 exit status
> 
> A bit of googling informed me (I think?) that a workaround was to configure using --without-system-pcre.  This however achieved nothing in my case.
> 
> Can anyone point me at what I need to do to fix this?  Install or update something?
> 
> I am running an (elderly, no-longer-supported) Fedora 17 Linux.
> 
> Thanks for any assistance.

PCRE (regular expressions) won't help you with compression algorithms... If anything, it is  --without-system-xz, -zlib, -bzlib that would come into play, but it would be a better idea to ensure that you do have the libraries and headers installed.

I'm not completely up to speed on Fedora, but the order of the day is that you need to install some variation of lzma/zlib/bzlib and their -dev/-devel header files etc. Check appendix A.1 and A.2 of the R Installation and Administration manual. 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From boris.steipe at utoronto.ca  Sun May 10 15:03:40 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 10 May 2015 09:03:40 -0400
Subject: [R] get sub elements
In-Reply-To: <554F4222.8030600@sapo.pt>
References: <mailman.0.1418986801.25142.r-help@r-project.org>, ,
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>,
	<DUB125-W505E345B0446A1728391D5B3FE0@phx.gbl>,
	<5522CE52.3080407@sapo.pt>,
	<DUB125-W28F7F412902742718170DCB3FE0@phx.gbl>,
	<DUB125-W22A75C36DF664CC6C21287B3DC0@phx.gbl>
	<DUB125-W31581C48971462021A37DFB3DC0@phx.gbl>
	<554F4222.8030600@sapo.pt>
Message-ID: <DF161A39-C75B-4EC9-82F2-7829B4F5124C@utoronto.ca>

I think the "record number" i.e. the indices of the elements were asked for. That would be:

which(5 <= allrecords  & allrecords <= 9)


Cheers,
B.








On May 10, 2015, at 7:33 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
> 
> You should learn about indexing in R. Read the pdf R-intro.pdf that comes with your installation of R.
> 
> allrecords[5 <= allrecords & allrecords <= 9]
> 
> should do it.
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 10-05-2015 11:00, Ragia Ibrahim escreveu:
>> Dear group
>> I have this numeric object
>> allrecords
>> 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
>>  1  1  2  1  3  1  1  2  5  4  1  6  8  1  2  1  3  3  2 13  1  4  2  4  7  1 14  1  1
>> 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
>>  1  1  2  2  1  1  2  2  2  9  3  1  1  3  6  1  4  1  3  9  2
>> 
>> 
>> how can I extract only records between 9 and 5 values only  and put the record number n a vector
>> 
>> it should be vector
>> thanks in advance
>> Ragia
>> 
>> 
>> 
>>  		 	   		   		 	   		
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From zadig_1 at excite.com  Sun May 10 15:11:43 2015
From: zadig_1 at excite.com (ce)
Date: Sun, 10 May 2015 09:11:43 -0400
Subject: [R] how to update a value in a list with lapply
Message-ID: <20150510091143.18474@web007.roc2.bluetie.com>


yes indeed :

 foo <- lapply(foo, function(x) if(x[1] == 1 ) {x[2] <- 0; x }else{x} )

would work. But if the list is too long, would it be time consuming  rather than just updating elements that meet the if condition?

thx
ce


-----Original Message-----
From: "David Winsemius" [dwinsemius at comcast.net]
Date: 05/09/2015 08:00 PM
To: "ce" <zadig_1 at excite.com>
CC: r-help at r-project.org
Subject: Re: [R] how to update a value in a list with lapply


On May 9, 2015, at 4:35 PM, ce wrote:

> Dear All,
> 
> I have a list, using lapply I find some elements of the list, and then I want to change the values I find. but it doesn't work:
> 
> foo<-list(A = c(1,3), B =c(1, 2), C = c(3, 1))
> lapply(foo, function(x) if(x[1] == 1 ) x )
> $A
> [1] 1 3
> 
> $B
> [1] 1 2
> 
> $C
> NULL
> 
> lapply(foo, function(x) if(x[1] == 1 ) x[2] <- 0 )
> $A
> [1] 0
> 
> $B
> [1] 0
> 
> $C
> NULL
> 
>> lapply(foo, function(x) if(x[1] == 1 ) x )
> $A
> [1] 1 3
> 
> $B
> [1] 1 2
> 
> $C
> NULL
> 
> 
> how to do it correctly ?

I find it useful to think of the `if` function as `if(cond){cons}else{alt}`

lapply(foo, function(x)  if(x[1] == 1 ) {x[2] <- 0; x }else{x} )
#-----
$A
[1] 1 0

$B
[1] 1 0

$C
[1] 3 1


You were not supply an alternative which was the cause of the NULL (and you were not returning a value which meant that the value returned was the value on the RHS of the assignment).

-- 

David Winsemius
Alameda, CA, USA


From jrkrideau at inbox.com  Sun May 10 16:26:19 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 10 May 2015 06:26:19 -0800
Subject: [R] New to R
In-Reply-To: <0D0FB2BF-EEEF-4031-B2EA-6486D4A1AA9C@gmail.com>
Message-ID: <9015C8B829E.000006B8jrkrideau@inbox.com>

Welcome to R and the R-help list

Not oriented to finance but just general info
A good source of introductory sources is available at http://www.introductoryr.co.uk/R_Resources_for_Beginners.html. BTW I've never seen the author's book but it does look interesting. :) 

I have had a look at most of the on-line books listed and I'd say any of them is likely to be very helpful. I have read a good bit of the book by Daniel Navarro and it is a excellent intro but possibly a bit tedious if you already are well grounded in stats.

Pat Burn's (of The R Inferno infamy ) has a new tutorial out which looks interesting. It is listed in the above link (Impatient R)

My personal opinion is that An Introduction to R by W.N. Venables and D.M. Smith (2004) is an excellent resource but it is only an introduction if you already are a pretty knowledgeable stats and programming type. However, when you hit a problem it is one of the first places to look for help.

If you have experience with SAS or SPSS then Bob Muenchen's R FOR SAS AND SPSS USERS (www.et.bs.ehu.es/~etptupaf/pub/R/RforSAS&SPSSusers.pdf) also available in expanded hard-copy format, can be extremely useful.

A couple of very useful sites for crafting questions for R-help or Stack

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html. In fact, just following the instructions for preparing a decent example can lead to a solution to the problem.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: chow.boris at gmail.com
> Sent: Sun, 10 May 2015 10:44:31 +0800
> To: r-help at r-project.org
> Subject: [R] New to R
> 
> Dear R users,
> 
> I am new to R community and would like to dig into it. Would you advise
> what are the appropriate steps to do so?
> 
> I want to do a pricing of an American option as my first exercise. Can
> some experienced users give me some pointers to do so?
> 
> Thanks a lot,
> Boris
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE 5GB EMAIL - Check out spam free email with many cool features!
Visit http://www.inbox.com/email to find out more!


From dwinsemius at comcast.net  Sun May 10 21:14:39 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 10 May 2015 12:14:39 -0700
Subject: [R] how to update a value in a list with lapply
In-Reply-To: <20150510091143.18474@web007.roc2.bluetie.com>
References: <20150510091143.18474@web007.roc2.bluetie.com>
Message-ID: <F519900E-BF2A-48EC-93F6-120515D289B4@comcast.net>


On May 10, 2015, at 6:11 AM, ce wrote:

> 
> yes indeed :
> 
> foo <- lapply(foo, function(x) if(x[1] == 1 ) {x[2] <- 0; x }else{x} )
> 
> would work. But if the list is too long, would it be time consuming  rather than just updating elements that meet the if condition?

Any change to an object will require copying the entire object. That is the computing model that R uses. If you had presented a modification strategy that used logical or numeric indexing to effect only targeted nodes of a list, it still would have ended up copying the whole object.

The data.table package was invented in large part to get around that design concern.

-- 
David.

> 
> thx
> ce
> 
> 
> -----Original Message-----
> From: "David Winsemius" [dwinsemius at comcast.net]
> Date: 05/09/2015 08:00 PM
> To: "ce" <zadig_1 at excite.com>
> CC: r-help at r-project.org
> Subject: Re: [R] how to update a value in a list with lapply
> 
> 
> On May 9, 2015, at 4:35 PM, ce wrote:
> 
>> Dear All,
>> 
>> I have a list, using lapply I find some elements of the list, and then I want to change the values I find. but it doesn't work:
>> 
>> foo<-list(A = c(1,3), B =c(1, 2), C = c(3, 1))
>> lapply(foo, function(x) if(x[1] == 1 ) x )
>> $A
>> [1] 1 3
>> 
>> $B
>> [1] 1 2
>> 
>> $C
>> NULL
>> 
>> lapply(foo, function(x) if(x[1] == 1 ) x[2] <- 0 )
>> $A
>> [1] 0
>> 
>> $B
>> [1] 0
>> 
>> $C
>> NULL
>> 
>>> lapply(foo, function(x) if(x[1] == 1 ) x )
>> $A
>> [1] 1 3
>> 
>> $B
>> [1] 1 2
>> 
>> $C
>> NULL
>> 
>> 
>> how to do it correctly ?
> 
> I find it useful to think of the `if` function as `if(cond){cons}else{alt}`
> 
> lapply(foo, function(x)  if(x[1] == 1 ) {x[2] <- 0; x }else{x} )
> #-----
> $A
> [1] 1 0
> 
> $B
> [1] 1 0
> 
> $C
> [1] 3 1
> 
> 
> You were not supply an alternative which was the cause of the NULL (and you were not returning a value which meant that the value returned was the value on the RHS of the assignment).
> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun May 10 21:21:31 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 10 May 2015 12:21:31 -0700
Subject: [R] get the first row ?
In-Reply-To: <DUB125-W22A75C36DF664CC6C21287B3DC0@phx.gbl>
References: <mailman.0.1418986801.25142.r-help@r-project.org>, ,
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>,
	<DUB125-W505E345B0446A1728391D5B3FE0@phx.gbl>,
	<5522CE52.3080407@sapo.pt>,
	<DUB125-W28F7F412902742718170DCB3FE0@phx.gbl>
	<DUB125-W22A75C36DF664CC6C21287B3DC0@phx.gbl>
Message-ID: <41C7BEE6-1776-4C0C-B519-B7CB3EFD060E@comcast.net>


On May 10, 2015, at 2:26 AM, Ragia Ibrahim wrote:

> Dear group
> kindly
> 
> I have a logical data type 
> ISINFCluster:
>    1     2     3     4     5     6     7     8     9    10    11    12    13    14 
> FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 
>   15    16    17    18    19    20    21    22    23    24    25    26    27    28 
> FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE 
>   29    30    31    32    33    34    35    36    37    38    39    40    41    42 
> FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 
>   43    44    45    46    47    48    49    50 
> FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 
> 
> and I want to get just number of records from those that has the  value true, thus 
> 
> firstclass<-     all[ISINCluster]  
> where  all is numeric object 
> 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 
> 1  1  2  1  3  1  1  2  5  4  1  6  8  1  2  1  3  3  2 13  1  4  2  4  7  1 14  1  1 
> 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 
> 1  1  2  2  1  1  2  2  2  9  3  1  1  3  6  1  4  1  3  9  2 
> 
> the firstclass containes the following
> firstclass
> 20 27 
> 13 14 
> 
> And I could not get the first row..
> head(firstclass)
> 20 27 
> 13 14 

The thing you are calling "the first row" is actual the names attrobute for that vector.
> 
> 
> how can I got it?

names(firstclass)

> thanks in advance
> Ragia


--
David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun May 10 21:27:02 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 10 May 2015 12:27:02 -0700
Subject: [R] Variance-covariance matrix
In-Reply-To: <248E6FA047A8C746BA491485764190F521FBC3BD@ESESSMB207.ericsson.se>
References: <248E6FA047A8C746BA491485764190F521FBC3BD@ESESSMB207.ericsson.se>
Message-ID: <15FB78AB-0015-4D2D-BB7B-8DBE6E4B4096@comcast.net>


On May 10, 2015, at 4:27 AM, Giorgio Garziano wrote:

> Hi,
> 
> I am looking for a R package providing with variance-covariance matrix computation of univariate time series.
> 
> Please, any suggestions ?

If you mean the auto-correlation function, then the stats package (loaded by default at startup) has facilities:

?acf
# also same help page describes partial auto-correlation function
#Auto- and Cross- Covariance and -Correlation Function Estimation

-- 

David Winsemius
Alameda, CA, USA


From giorgio.garziano at ericsson.com  Sun May 10 21:54:34 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Sun, 10 May 2015 19:54:34 +0000
Subject: [R] Variance-covariance matrix
In-Reply-To: <15FB78AB-0015-4D2D-BB7B-8DBE6E4B4096@comcast.net>
References: <248E6FA047A8C746BA491485764190F521FBC3BD@ESESSMB207.ericsson.se>
	<15FB78AB-0015-4D2D-BB7B-8DBE6E4B4096@comcast.net>
Message-ID: <248E6FA047A8C746BA491485764190F521FBC47C@ESESSMB207.ericsson.se>

Hi,

Actually as variance-covariance matrix I mean:

	http://stattrek.com/matrix-algebra/covariance-matrix.aspx

that I compute by:

	data <- rnorm(10,2,1)
	n <- length(data)
	data.center <- scale(data, center=TRUE, scale=FALSE)
	var.cov.mat <- (1/(n-1)) * data.center %*% t(data.center)

--
Giorgio Garziano 


-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: domenica 10 maggio 2015 21:27
To: Giorgio Garziano
Cc: r-help at r-project.org
Subject: Re: [R] Variance-covariance matrix


On May 10, 2015, at 4:27 AM, Giorgio Garziano wrote:

> Hi,
> 
> I am looking for a R package providing with variance-covariance matrix computation of univariate time series.
> 
> Please, any suggestions ?

If you mean the auto-correlation function, then the stats package (loaded by default at startup) has facilities:

?acf
# also same help page describes partial auto-correlation function
#Auto- and Cross- Covariance and -Correlation Function Estimation

-- 

David Winsemius
Alameda, CA, USA


From tsjerkw at gmail.com  Sun May 10 22:10:46 2015
From: tsjerkw at gmail.com (Tsjerk Wassenaar)
Date: Sun, 10 May 2015 22:10:46 +0200
Subject: [R] Variance-covariance matrix
In-Reply-To: <248E6FA047A8C746BA491485764190F521FBC47C@ESESSMB207.ericsson.se>
References: <248E6FA047A8C746BA491485764190F521FBC3BD@ESESSMB207.ericsson.se>
	<15FB78AB-0015-4D2D-BB7B-8DBE6E4B4096@comcast.net>
	<248E6FA047A8C746BA491485764190F521FBC47C@ESESSMB207.ericsson.se>
Message-ID: <CABzE1SiF54_Myu4WCp3EmXKKybTDBWa0gtgUrLRPVCSu9XgE9A@mail.gmail.com>

Hi Giorgio,

For a univariate time series? Seriously?

data <- rnorm(10,2,1)
as.matrix(var(data))

Cheers,

Tsjerk


On Sun, May 10, 2015 at 9:54 PM, Giorgio Garziano <
giorgio.garziano at ericsson.com> wrote:

> Hi,
>
> Actually as variance-covariance matrix I mean:
>
>         http://stattrek.com/matrix-algebra/covariance-matrix.aspx
>
> that I compute by:
>
>         data <- rnorm(10,2,1)
>         n <- length(data)
>         data.center <- scale(data, center=TRUE, scale=FALSE)
>         var.cov.mat <- (1/(n-1)) * data.center %*% t(data.center)
>
> --
> Giorgio Garziano
>
>
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: domenica 10 maggio 2015 21:27
> To: Giorgio Garziano
> Cc: r-help at r-project.org
> Subject: Re: [R] Variance-covariance matrix
>
>
> On May 10, 2015, at 4:27 AM, Giorgio Garziano wrote:
>
> > Hi,
> >
> > I am looking for a R package providing with variance-covariance matrix
> computation of univariate time series.
> >
> > Please, any suggestions ?
>
> If you mean the auto-correlation function, then the stats package (loaded
> by default at startup) has facilities:
>
> ?acf
> # also same help page describes partial auto-correlation function
> #Auto- and Cross- Covariance and -Correlation Function Estimation
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Tsjerk A. Wassenaar, Ph.D.

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Sun May 10 22:25:33 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Sun, 10 May 2015 20:25:33 +0000
Subject: [R] Variance-covariance matrix
In-Reply-To: <CABzE1SiF54_Myu4WCp3EmXKKybTDBWa0gtgUrLRPVCSu9XgE9A@mail.gmail.com>
References: <248E6FA047A8C746BA491485764190F521FBC3BD@ESESSMB207.ericsson.se>
	<15FB78AB-0015-4D2D-BB7B-8DBE6E4B4096@comcast.net>
	<248E6FA047A8C746BA491485764190F521FBC47C@ESESSMB207.ericsson.se>
	<CABzE1SiF54_Myu4WCp3EmXKKybTDBWa0gtgUrLRPVCSu9XgE9A@mail.gmail.com>
Message-ID: <248E6FA047A8C746BA491485764190F521FBC4B7@ESESSMB207.ericsson.se>

Hi Tsjerk,

Yes, seriously.

Time series:

X = [x1, x2, x3, ....,xn]

The variance-covariance matrix is V matrix:

            V    =


? x12 / (N-1)

? x1 x2 / (N-1)

. . .

? x1 xn / (N-1)

? x2 x1 / (N-1)

? x22 / (N-1)

. . .

? x2 xn / (N-1)

. . .

. . .

. . .

. . .

? xn x1 / (N-1)

? xn x2 / (N-1)

. . .

? xn2 / (N-1)




Reference: ?Time series and its applications ? with R examples?, Springer,
     $7.8 ?Principal Components? pag. 468, 469

Cheers,

Giorgio


From: Tsjerk Wassenaar [mailto:tsjerkw at gmail.com]
Sent: domenica 10 maggio 2015 22:11
To: Giorgio Garziano
Cc: r-help at r-project.org
Subject: Re: [R] Variance-covariance matrix

Hi Giorgio,

For a univariate time series? Seriously?

data <- rnorm(10,2,1)
as.matrix(var(data))

Cheers,

Tsjerk


On Sun, May 10, 2015 at 9:54 PM, Giorgio Garziano <giorgio.garziano at ericsson.com<mailto:giorgio.garziano at ericsson.com>> wrote:
Hi,

Actually as variance-covariance matrix I mean:

        http://stattrek.com/matrix-algebra/covariance-matrix.aspx

that I compute by:

        data <- rnorm(10,2,1)
        n <- length(data)
        data.center <- scale(data, center=TRUE, scale=FALSE)
        var.cov.mat <- (1/(n-1)) * data.center %*% t(data.center)

--
Giorgio Garziano


-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net<mailto:dwinsemius at comcast.net>]
Sent: domenica 10 maggio 2015 21:27
To: Giorgio Garziano
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Variance-covariance matrix


On May 10, 2015, at 4:27 AM, Giorgio Garziano wrote:

> Hi,
>
> I am looking for a R package providing with variance-covariance matrix computation of univariate time series.
>
> Please, any suggestions ?

If you mean the auto-correlation function, then the stats package (loaded by default at startup) has facilities:

?acf
# also same help page describes partial auto-correlation function
#Auto- and Cross- Covariance and -Correlation Function Estimation

--

David Winsemius
Alameda, CA, USA

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--
Tsjerk A. Wassenaar, Ph.D.

	[[alternative HTML version deleted]]


From tsjerkw at gmail.com  Sun May 10 22:31:14 2015
From: tsjerkw at gmail.com (Tsjerk Wassenaar)
Date: Sun, 10 May 2015 22:31:14 +0200
Subject: [R] Variance-covariance matrix
In-Reply-To: <248E6FA047A8C746BA491485764190F521FBC4B7@ESESSMB207.ericsson.se>
References: <248E6FA047A8C746BA491485764190F521FBC3BD@ESESSMB207.ericsson.se>
	<15FB78AB-0015-4D2D-BB7B-8DBE6E4B4096@comcast.net>
	<248E6FA047A8C746BA491485764190F521FBC47C@ESESSMB207.ericsson.se>
	<CABzE1SiF54_Myu4WCp3EmXKKybTDBWa0gtgUrLRPVCSu9XgE9A@mail.gmail.com>
	<248E6FA047A8C746BA491485764190F521FBC4B7@ESESSMB207.ericsson.se>
Message-ID: <CABzE1Sh3f_5MpWoNiKmdFcoDYbgcTorsc8JibPVAZp-AJkmmrg@mail.gmail.com>

Hi Giorgio,

This is for a multivariate time series. x1 is variable 1 of the observation
vector x, x2, variable 2, etc. If you need x(i) and x(i+1), etc, then
you're looking for the autocovariance/autocorrelation matrix, which is a
quite different thing (and David showed the way). You can easily see that
you don't have N-1 degrees of freedom per entry, because you have fewer
'observations' for larger lag times.

Cheers,

Tsjerk



On Sun, May 10, 2015 at 10:25 PM, Giorgio Garziano <
giorgio.garziano at ericsson.com> wrote:

>  Hi Tsjerk,
>
>
>
> Yes, seriously.
>
>
>
> Time series:
>
>
>
> X = [x1, x2, x3, ....,xn]
>
>
>
> The variance-covariance matrix is V matrix:
>
>
>
> *            V*    =
>
> ? *x*12 / (N-1)
>
> ? *x*1 *x*2 / (N-1)
>
> . . .
>
> ? *x*1 xn / (N-1)
>
> ? *x*2 *x*1 / (N-1)
>
> ? *x*22 / (N-1)
>
> . . .
>
> ? *x*2 *x*n / (N-1)
>
> . . .
>
> . . .
>
> . . .
>
> . . .
>
> ? *x*n *x*1 / (N-1)
>
> ? *x*n *x*2 / (N-1)
>
> . . .
>
> ? *x*n2 / (N-1)
>
>
>
>
>
> Reference: ?Time series and its applications ? with R examples?,
> Springer,
>
>      $7.8 ?Principal Components? pag. 468, 469
>
>
>
> Cheers,
>
>
>
> Giorgio
>
>
>
>
>
> *From:* Tsjerk Wassenaar [mailto:tsjerkw at gmail.com]
> *Sent:* domenica 10 maggio 2015 22:11
>
> *To:* Giorgio Garziano
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] Variance-covariance matrix
>
>
>
> Hi Giorgio,
>
>
>
> For a univariate time series? Seriously?
>
>
>
> data <- rnorm(10,2,1)
>
> as.matrix(var(data))
>
>
>
> Cheers,
>
>
>
> Tsjerk
>
>
>
>
>
> On Sun, May 10, 2015 at 9:54 PM, Giorgio Garziano <
> giorgio.garziano at ericsson.com> wrote:
>
> Hi,
>
> Actually as variance-covariance matrix I mean:
>
>         http://stattrek.com/matrix-algebra/covariance-matrix.aspx
>
> that I compute by:
>
>         data <- rnorm(10,2,1)
>         n <- length(data)
>         data.center <- scale(data, center=TRUE, scale=FALSE)
>         var.cov.mat <- (1/(n-1)) * data.center %*% t(data.center)
>
> --
> Giorgio Garziano
>
>
>
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: domenica 10 maggio 2015 21:27
> To: Giorgio Garziano
> Cc: r-help at r-project.org
> Subject: Re: [R] Variance-covariance matrix
>
>
> On May 10, 2015, at 4:27 AM, Giorgio Garziano wrote:
>
> > Hi,
> >
> > I am looking for a R package providing with variance-covariance matrix
> computation of univariate time series.
> >
> > Please, any suggestions ?
>
> If you mean the auto-correlation function, then the stats package (loaded
> by default at startup) has facilities:
>
> ?acf
> # also same help page describes partial auto-correlation function
> #Auto- and Cross- Covariance and -Correlation Function Estimation
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
> --
>
> Tsjerk A. Wassenaar, Ph.D.
>



-- 
Tsjerk A. Wassenaar, Ph.D.

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun May 10 23:52:54 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 11 May 2015 09:52:54 +1200
Subject: [R] Building R-3.2.0 from source.
In-Reply-To: <425F1A4A-454E-4CF0-A9D5-766DAA301A86@gmail.com>
References: <554F4BF6.8060508@auckland.ac.nz>
	<425F1A4A-454E-4CF0-A9D5-766DAA301A86@gmail.com>
Message-ID: <554FD336.1030604@auckland.ac.nz>


I am cross-posting this to r-sig-fedora (I hope that's not an egregious 
sin) in the hope that doing so might provide some source of insight.

I tried

     sudo yum install zlib

and was told

> Package zlib-1.2.5-7.fc17.x86_64 already installed and latest version


Likewise for "zlib-devel".

I also tried

     sudo yum install bzlib

and was told

> No package bzlib available.

Likewise for "bzlib-devel".

Finally I sort of got some joy with "lzma" and "lzma-devel" --- both of 
those yielded an actual installation.  But it didn't help.

I re-did the configure and then the make and got the same 
errors/complaints about undefined references to deflate, inflate, crc32, 
etc.

Can anyone provide any guidance/suggestions about what else I could try?
I'm getting very frustrated! :-)

cheers,

Rolf Turner

On 11/05/15 00:50, peter dalgaard wrote:
>
>> On 10 May 2015, at 14:15 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>>
>>
>> I am just now getting around to upgrading from 3.1.2 to 3.2.0 and am getting hammered by a problem which is beyond my limited capabilities of handling.
>>
>> I executed
>>
>>   ./configure --with-tcltk --with cairo
>>
>> which seemed to go just fine, and then did:
>>
>>    make
>>
>> In fairly short order I started getting  error messages like unto:
>>
>>> connections.o: In function `gzcon_write':
>>> /home/rolf/Desktop/Rinst/R-3.2.0/src/main/connections.c:5469: undefined reference to `deflate'
>>
>> There were also complaints about undefined references to inflate, crc32, deflateEnd, inflateEnd, inflateReset, inflateInit2_, deflateInit2_, compress, uncompress, and zlibVersion, many of which were issued repeatedly.  It finally gave up, saying:
>>
>>> collect2: error: ld returned 1 exit status
>>
>> A bit of googling informed me (I think?) that a workaround was to configure using --without-system-pcre.  This however achieved nothing in my case.
>>
>> Can anyone point me at what I need to do to fix this?  Install or update something?
>>
>> I am running an (elderly, no-longer-supported) Fedora 17 Linux.
>>
>> Thanks for any assistance.
>
> PCRE (regular expressions) won't help you with compression algorithms... If anything, it is  --without-system-xz, -zlib, -bzlib that would come into play, but it would be a better idea to ensure that you do have the libraries and headers installed.
>
> I'm not completely up to speed on Fedora, but the order of the day is that you need to install some variation of lzma/zlib/bzlib and their -dev/-devel header files etc. Check appendix A.1 and A.2 of the R Installation and Administration manual.
>


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From wdunlap at tibco.com  Mon May 11 00:00:21 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 10 May 2015 15:00:21 -0700
Subject: [R] how to update a value in a list with lapply
In-Reply-To: <20150510091143.18474@web007.roc2.bluetie.com>
References: <20150510091143.18474@web007.roc2.bluetie.com>
Message-ID: <CAF8bMcaSBFTZnCXCm+KWGvTM74jtmQx2e=fCOncHHFfoowoZyA@mail.gmail.com>

You can do the timing yourself on a dataset which you feel is typical of
your usage.
E.g., define a function the implements each algorithm
  > f1 <- function(foo) lapply(foo, function(x) { if (x[1] == 1) x[2] <- 0
; x })
  > f2 <- function(foo) { for(i in seq_along(foo)) if (foo[[i]][1] == 1)
foo[[i]][2] <- 0 ; foo }
and compare the times (and return values) on various datasets.
  > foo1 <- rep(list(c(1,2,1:100)), length=1e5) # every element needs
changing
  > system.time(v1 <- f1(foo1))
     user  system elapsed
     0.28    0.01    0.29
  > system.time(v2 <- f2(foo1))
     user  system elapsed
     0.26    0.03    0.30
  > identical(v1, v2)
  [1] TRUE
  > foo2 <- rep(list(c(0,2,1:100)), length=1e5) # no element needs changing
  > system.time(v1 <- f1(foo2))
     user  system elapsed
     0.09    0.00    0.09
  > system.time(v2 <- f2(foo2))
     user  system elapsed
     0.07    0.00    0.07
  > identical(v1, v2)
  [1] TRUE




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, May 10, 2015 at 6:11 AM, ce <zadig_1 at excite.com> wrote:

>
> yes indeed :
>
>  foo <- lapply(foo, function(x) if(x[1] == 1 ) {x[2] <- 0; x }else{x} )
>
> would work. But if the list is too long, would it be time consuming
> rather than just updating elements that meet the if condition?
>
> thx
> ce
>
>
> -----Original Message-----
> From: "David Winsemius" [dwinsemius at comcast.net]
> Date: 05/09/2015 08:00 PM
> To: "ce" <zadig_1 at excite.com>
> CC: r-help at r-project.org
> Subject: Re: [R] how to update a value in a list with lapply
>
>
> On May 9, 2015, at 4:35 PM, ce wrote:
>
> > Dear All,
> >
> > I have a list, using lapply I find some elements of the list, and then I
> want to change the values I find. but it doesn't work:
> >
> > foo<-list(A = c(1,3), B =c(1, 2), C = c(3, 1))
> > lapply(foo, function(x) if(x[1] == 1 ) x )
> > $A
> > [1] 1 3
> >
> > $B
> > [1] 1 2
> >
> > $C
> > NULL
> >
> > lapply(foo, function(x) if(x[1] == 1 ) x[2] <- 0 )
> > $A
> > [1] 0
> >
> > $B
> > [1] 0
> >
> > $C
> > NULL
> >
> >> lapply(foo, function(x) if(x[1] == 1 ) x )
> > $A
> > [1] 1 3
> >
> > $B
> > [1] 1 2
> >
> > $C
> > NULL
> >
> >
> > how to do it correctly ?
>
> I find it useful to think of the `if` function as `if(cond){cons}else{alt}`
>
> lapply(foo, function(x)  if(x[1] == 1 ) {x[2] <- 0; x }else{x} )
> #-----
> $A
> [1] 1 0
>
> $B
> [1] 1 0
>
> $C
> [1] 3 1
>
>
> You were not supply an alternative which was the cause of the NULL (and
> you were not returning a value which meant that the value returned was the
> value on the RHS of the assignment).
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon May 11 01:46:12 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 11 May 2015 09:46:12 +1000
Subject: [R] fonts in R-3.2.0
Message-ID: <CA+8X3fWzuJ9kFJX_ZSG9b5joQr3TmZvQEMSvfE86_O5OU8ar7g@mail.gmail.com>

Hi all,
I compiled R-3.2.0 from source a few weeks ago and was surprised to
find that the only font that appeared on plots was the System font,
not the most elegant. I had R-3.1.3 previously and all fonts seemed to
be available on my system (Fedora 21). I have the latest version of
urw-fonts (2.4-19) installed and have no problems with fonts that I
can see in any other applications. For example, converting Postscript
files to PDF using ghostcript -sDEVICE=pdfwrite ... gives the correct
fonts when they are not embedded in the Postscript file.

I assume that this is some problem with the location of the font
libraries, but despite poring through the Installation manual,
browsing the configure log and searching "no fonts in R-3.2.0" and
similar search terms, I haven't progressed very far. Any hints?

Jim


From r.turner at auckland.ac.nz  Mon May 11 03:09:57 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 11 May 2015 13:09:57 +1200
Subject: [R] [R-sig-Fedora]  Building R-3.2.0 from source.
In-Reply-To: <CAHkRx6FVxw_nVC9HqRPYh6Ay23frAQ0e5wOHvO15mRRTvOTjcQ@mail.gmail.com>
References: <554F4BF6.8060508@auckland.ac.nz>	<425F1A4A-454E-4CF0-A9D5-766DAA301A86@gmail.com>	<554FD336.1030604@auckland.ac.nz>
	<CAHkRx6FVxw_nVC9HqRPYh6Ay23frAQ0e5wOHvO15mRRTvOTjcQ@mail.gmail.com>
Message-ID: <55500165.2070004@auckland.ac.nz>

On 11/05/15 12:06, M. Edward (Ed) Borasky wrote:
> 1. R 3.2.0 is packaged for Fedora now; it's in Rawhide and Fedora 22.
> I'm running Fedora 22 (late beta) and haven't had any problems with R.
> RStudio Desktop Preview (0.99.435) from the RStudio Fedora RPM is also
> running fine. You might save yourself some hassles by upgrading to
> Fedora 22.

I'm sure I would, but I don't dare.  Everything I see on the Fedora 
mailing list fills me with terror in respect of the disasters that can 
occur.  I don't have the skills to cope with such disasters and I have 
no access to support in respect of Fedora.

> 2. I have a bash script to build R from source that works on Fedora
> 22. It probably also works on Fedora 21 but it's been a while since I
> tried it. Note that it installs 'calibre' and makes the ebooks of the
> manuals. It also does some packaging things at the end you probably
> don't need.

Thanks, but I don't think it's any help in my situation.

I had no problem at all building R 3.1.2 from source.  What changed from
3.1.2 to 3.2.0 that would cause those undefined reference problems?

cheers,

Rolf Turner

>
> On Sun, May 10, 2015 at 2:52 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>> I am cross-posting this to r-sig-fedora (I hope that's not an egregious sin)
>> in the hope that doing so might provide some source of insight.
>>
>> I tried
>>
>>      sudo yum install zlib
>>
>> and was told
>>
>>> Package zlib-1.2.5-7.fc17.x86_64 already installed and latest version
>>
>>
>>
>> Likewise for "zlib-devel".
>>
>> I also tried
>>
>>      sudo yum install bzlib
>>
>> and was told
>>
>>> No package bzlib available.
>>
>>
>> Likewise for "bzlib-devel".
>>
>> Finally I sort of got some joy with "lzma" and "lzma-devel" --- both of
>> those yielded an actual installation.  But it didn't help.
>>
>> I re-did the configure and then the make and got the same errors/complaints
>> about undefined references to deflate, inflate, crc32, etc.
>>
>> Can anyone provide any guidance/suggestions about what else I could try?
>> I'm getting very frustrated! :-)
>>
>> cheers,
>>
>> Rolf Turner
>>
>> On 11/05/15 00:50, peter dalgaard wrote:
>>>
>>>
>>>> On 10 May 2015, at 14:15 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>>
>>>>
>>>>
>>>> I am just now getting around to upgrading from 3.1.2 to 3.2.0 and am
>>>> getting hammered by a problem which is beyond my limited capabilities of
>>>> handling.
>>>>
>>>> I executed
>>>>
>>>>    ./configure --with-tcltk --with cairo
>>>>
>>>> which seemed to go just fine, and then did:
>>>>
>>>>     make
>>>>
>>>> In fairly short order I started getting  error messages like unto:
>>>>
>>>>> connections.o: In function `gzcon_write':
>>>>> /home/rolf/Desktop/Rinst/R-3.2.0/src/main/connections.c:5469: undefined
>>>>> reference to `deflate'
>>>>
>>>>
>>>> There were also complaints about undefined references to inflate, crc32,
>>>> deflateEnd, inflateEnd, inflateReset, inflateInit2_, deflateInit2_,
>>>> compress, uncompress, and zlibVersion, many of which were issued repeatedly.
>>>> It finally gave up, saying:
>>>>
>>>>> collect2: error: ld returned 1 exit status
>>>>
>>>>
>>>> A bit of googling informed me (I think?) that a workaround was to
>>>> configure using --without-system-pcre.  This however achieved nothing in my
>>>> case.
>>>>
>>>> Can anyone point me at what I need to do to fix this?  Install or update
>>>> something?
>>>>
>>>> I am running an (elderly, no-longer-supported) Fedora 17 Linux.
>>>>
>>>> Thanks for any assistance.
>>>
>>>
>>> PCRE (regular expressions) won't help you with compression algorithms...
>>> If anything, it is  --without-system-xz, -zlib, -bzlib that would come into
>>> play, but it would be a better idea to ensure that you do have the libraries
>>> and headers installed.
>>>
>>> I'm not completely up to speed on Fedora, but the order of the day is that
>>> you need to install some variation of lzma/zlib/bzlib and their -dev/-devel
>>> header files etc. Check appendix A.1 and A.2 of the R Installation and
>>> Administration manual.
>>>
>>
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>> Home phone: +64-9-480-4619
>>
>> _______________________________________________
>> R-SIG-Fedora mailing list
>> R-SIG-Fedora at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-fedora
>
>
>


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From glennmschultz at me.com  Mon May 11 03:03:23 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Mon, 11 May 2015 01:03:23 +0000 (GMT)
Subject: [R] Code works on Mac but not Windows
Message-ID: <030b428c-042b-4134-9b4a-5b0e3eae56e2@me.com>

Hello All,

Testing my code on a Windows based machine today. ?There seems to be an offending line of code. ?I have pasted it below. ?Basically, I check to see if the user passed a fit method to TermStructure and if not then default to "ns". ?

The above works fine on my Mac but a windows build errors no method. ?I have to pass a method = "ns" in the function. ?If I pass the value for method to the function it will run with no error. ?Any thoughts are appreciated.

Best Regards,
Glenn

? #Default method for TermStructure
? if(missing(method)) method = "ns"

From tony.n.brown at Vanderbilt.Edu  Mon May 11 06:40:19 2015
From: tony.n.brown at Vanderbilt.Edu (Brown, Tony Nicholas)
Date: Mon, 11 May 2015 04:40:19 +0000
Subject: [R] confidence intervals for differences in proportions from
 complex survey design?
Message-ID: <27E784E40B04E84588E94E6CE0F26EEB2ED19389@ITS-HCWNEM103.ds.vanderbilt.edu>

All:

I need to generate confidence intervals for differences in proportions using data from a complex survey design. An example follows where I attempt to estimate the difference in depression prevalence by sex.

# Data might look something like this:
Dfr<-data.frame(depression=sample(c("yes","no"), size=30, replace=TRUE),
	sex=sample(c("M","F"), size=30, replace=TRUE),
	cluster=rep(1:10, times=3),
	stratum=rep(1:5, each=2, times=3),
	pweight=runif(n=30, min=1, max=3))
Dfr
library(survey)
msdesign<-svydesign(id=~cluster, strata=~stratum, weights=~pweight, nest=TRUE,
	data=Dfr)
# When searching online, one recommendation was to use svyglm() to generate an
# approximation as follows:
confint(with(Dfr, svyglm(I(depression=="yes")~sex, family=gaussian(link=identity), 
	msdesign)), level=0.95, method="Wald")

This question has been asked before on the listserv (circa 2007) and I contacted the original poster, who indicated that they never received a reply.

Here is the question as described by the original poster:

"I'm trying to get confidence intervals of proportions (sometimes for 
subgroups) estimated from complex survey data. Because a function like 
prop.test() does not exist for the "survey" package I tried the following:

1) Define a survey object (PSU of clustered sample, population weights);
2) Use svyglm() of the package "survey" to estimate a binary logistic 
regression (family='binomial'): For the confidence interval of a single 
proportion regress the binary dependent variable on a constant (1), for 
confidence intervals of that variable for subgroups regress this 
variable on the groups (factor) variable;
3) Use predict() to obtain estimated logits and the respective standard 
errors (mod.dat specifying either the constant or the subgroups):

    pred=predict(model,mod.dat,type='link',se.fit=T)

and apply the following to obtain the proportion with its confidence 
intervals (for example, for conf.level=.95):

    lo.e = pred[1:length(pred)]-qnorm((1+conf.level)/2)*SE(pred)
    hi.e = pred[1:length(pred)]+qnorm((1+conf.level)/2)*SE(pred)
    prop = 1/(1+exp(-pred[1:length(pred)]))
    lo = 1/(1+exp(-lo.e))
    hi = 1/(1+exp(-hi.e))

I think that in that way I get CI's based on asymptotic normality - 
either for a single proportion or split up into subgroups.

Question: Is this a correct or a defensible procedure? Or should I use a 
different approach? Note that this approach should also allow to 
estimate CI's for proportions of subgroups taking into account the 
complex survey design."

Thanks in advance for any help that you can provide.

Tony

------------------------------------------------------------------------------
Tony N. Brown, Ph.D.
Associate Chair and Associate Professor of Sociology
Google Scholar Profile: http://tinyurl.com/lozlht8
LinkedIn Profile: https://www.linkedin.com/pub/tony-nicholas-brown/a6/64/31a


From dhultstrand at appliedweatherassociates.com  Mon May 11 06:01:27 2015
From: dhultstrand at appliedweatherassociates.com (Douglas Hultstrand)
Date: Sun, 10 May 2015 22:01:27 -0600
Subject: [R] lmom and lmomRFA Upper and Lower Bounds Simulation Questions
Message-ID: <55502997.7030802@appliedweatherassociates.com>

Hello,

I am using the lmom and lmomRFA to compute the return frequencies using 
the GEV distribution.Iam trying to generate upper and lower bound 
frequency estimates.

I provided a working example of the code that I am using to estimate the 
upper and lower bounds. Specific questions I have are:

1) Is the methodology appropriate and applied correctly?

2) In this example, are the simulated qhat values better than the actual 
fitted data estimates (GEV)?

_*Code Example Below:*_

library(lmom); library(lmomRFA)
set.seed(1234)

# Example data
max_data <- 
c(11.14,10.95,10.21,9.88,9.85,9.74,9.74,9.73,9.62,8.95,8.38,8.20)
moments = samlmu(max_data, sort.data = TRUE)
parGEV <- pelgev(moments)  # GEV

x <- c(10,25,50,100,500,1000)
Fx <- (1-(1/x))
GEV = Fx
PDS <- 1/(log(x)-log(x-1))

for (i in seq_along(Fx)) {
     GEV[i] = round(quagev(Fx[i], parGEV), 3)
}

################
#### BOUNDS ###
################
# A data sample
zz_gev <- quagev(runif(500), parGEV)

# Compute L-moments of the sample, considered as a 1-site region
rdat_gev <- regsamlmu(zz_gev)

# Fit GEV distribution to the regional L-moments
rfit_gev <- regfit(rdat_gev,"gev")

# Generate simulations of an artificial 1-site region with frequency 
distribution fitted to the actual data
sim_gev <- regsimq(rfit_gev$qfunc, nrec = rdat_gev$n, f = 1 - 1 / x )

# Compute error bounds for quantiles of the site's frequency distribution
CI_gev <- sitequantbounds(sim_gev, rfit_gev)

# 90% Error Bounds/CI
Clwr <- round(CI_gev$bound.0.05, 3)
Cupr <- round(CI_gev$bound.0.95, 3)
qhat <- round(CI_gev$Qhat, 3)

# print data
data.frame(Fx, GEV, Clwr, Cupr, qhat)

####################
#### END BOUNDS ##
####################


#Plot and visualize the data
plot(x, GEV, log="x", ylim=c(10.5,12.5), col="blue")
lines(PDS,GEV, col="blue")
lines(PDS,Clwr, lty=3)
lines(PDS,Cupr, lty=3)
lines(PDS,qhat, col="red", lty=5)

Thanks for your help,

Doug

-- 
-----------------------------------------
Douglas M. Hultstrand, MS
Senior Hydrometeorologist
Applied Weather Associates
Monument, Colorado
voice: 970-682-2462
mobile: 720-771-5840
www.appliedweatherassociates.com
dhultstrand at appliedweatherassociates.com
-----------------------------------------


	[[alternative HTML version deleted]]


From tcallawa at redhat.com  Mon May 11 06:19:16 2015
From: tcallawa at redhat.com (Tom Callaway)
Date: Mon, 11 May 2015 00:19:16 -0400 (EDT)
Subject: [R] [R-sig-Fedora]  Building R-3.2.0 from source.
Message-ID: <0d598c13-e2ec-4a01-8d1f-6c4f323302a5@email.android.com>

I just landed in Paris, and haven't read backwards in this thread, but I've done 3.2.0 builds for all current Fedora releases, they're all in updates-testing (I think the Fedora 22 builds are in updates stable now).

The thing that changed is that R doesn't bundle a number of libraries like it used to. This doesn't affect the official Fedora R package, since we never used the bundled libraries. This is documented in the 3.2.0 release notes.

If you really want to build from source, I think you can run:

yum-builddep R

That will install all the necessary Build Requires to build R from source. You need to have the yum-utils package installed for that command to exist.

Hope that helps.

On May 11, 2015 3:10 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> On 11/05/15 12:06, M. Edward (Ed) Borasky wrote: 
> > 1. R 3.2.0 is packaged for Fedora now; it's in Rawhide and Fedora 22. 
> > I'm running Fedora 22 (late beta) and haven't had any problems with R. 
> > RStudio Desktop Preview (0.99.435) from the RStudio Fedora RPM is also 
> > running fine. You might save yourself some hassles by upgrading to 
> > Fedora 22. 
>
> I'm sure I would, but I don't dare.? Everything I see on the Fedora 
> mailing list fills me with terror in respect of the disasters that can 
> occur.? I don't have the skills to cope with such disasters and I have 
> no access to support in respect of Fedora. 
>
> > 2. I have a bash script to build R from source that works on Fedora 
> > 22. It probably also works on Fedora 21 but it's been a while since I 
> > tried it. Note that it installs 'calibre' and makes the ebooks of the 
> > manuals. It also does some packaging things at the end you probably 
> > don't need. 
>
> Thanks, but I don't think it's any help in my situation. 
>
> I had no problem at all building R 3.1.2 from source.? What changed from 
> 3.1.2 to 3.2.0 that would cause those undefined reference problems? 
>
> cheers, 
>
> Rolf Turner 
>
> > 
> > On Sun, May 10, 2015 at 2:52 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote: 
> >> 
> >> I am cross-posting this to r-sig-fedora (I hope that's not an egregious sin) 
> >> in the hope that doing so might provide some source of insight. 
> >> 
> >> I tried 
> >> 
> >>????? sudo yum install zlib 
> >> 
> >> and was told 
> >> 
> >>> Package zlib-1.2.5-7.fc17.x86_64 already installed and latest version 
> >> 
> >> 
> >> 
> >> Likewise for "zlib-devel". 
> >> 
> >> I also tried 
> >> 
> >>????? sudo yum install bzlib 
> >> 
> >> and was told 
> >> 
> >>> No package bzlib available. 
> >> 
> >> 
> >> Likewise for "bzlib-devel". 
> >> 
> >> Finally I sort of got some joy with "lzma" and "lzma-devel" --- both of 
> >> those yielded an actual installation.? But it didn't help. 
> >> 
> >> I re-did the configure and then the make and got the same errors/complaints 
> >> about undefined references to deflate, inflate, crc32, etc. 
> >> 
> >> Can anyone provide any guidance/suggestions about what else I could try? 
> >> I'm getting very frustrated! :-) 
> >> 
> >> cheers, 
> >> 
> >> Rolf Turner 
> >> 
> >> On 11/05/15 00:50, peter dalgaard wrote: 
> >>> 
> >>> 
> >>>> On 10 May 2015, at 14:15 , Rolf Turner <r.turner at auckland.ac.nz> wrote: 
> >>>> 
> >>>> 
> >>>> 
> >>>> I am just now getting around to upgrading from 3.1.2 to 3.2.0 and am 
> >>>> getting hammered by a problem which is beyond my limited capabilities of 
> >>>> handling. 
> >>>> 
> >>>> I executed 
> >>>> 
> >>>>??? ./configure --with-tcltk --with cairo 
> >>>> 
> >>>> which seemed to go just fine, and then did: 
> >>>> 
> >>>>???? make 
> >>>> 
> >>>> In fairly short order I started getting? error messages like unto: 
> >>>> 
> >>>>> connections.o: In function `gzcon_write': 
> >>>>> /home/rolf/Desktop/Rinst/R-3.2.0/src/main/connections.c:5469: undefined 
> >>>>> reference to `deflate' 
> >>>> 
> >>>> 
> >>>> There were also complaints about undefined references to inflate, crc32, 
> >>>> deflateEnd, inflateEnd, inflateReset, inflateInit2_, deflateInit2_, 
> >>>> compress, uncompress, and zlibVersion, many of which were issued repeatedly. 
> >>>> It finally gave up, saying: 
> >>>> 
> >>>>> collect2: error: ld returned 1 exit status 
> >>>> 
> >>>> 
> >>>> A bit of googling informed me (I think?) that a workaround was to 
> >>>> configure using --without-system-pcre.? This however achieved nothing in my 
> >>>> case. 
> >>>> 
> >>>> Can anyone point me at what I need to do to fix this?? Install or update 
> >>>> something? 
> >>>> 
> >>>> I am running an (elderly, no-longer-supported) Fedora 17 Linux. 
> >>>> 
> >>>> Thanks for any assistance. 
> >>> 
> >>> 
> >>> PCRE (regular expressions) won't help you with compression algorithms... 
> >>> If anything, it is? --without-system-xz, -zlib, -bzlib that would come into 
> >>> play, but it would be a better idea to ensure that you do have the libraries 
> >>> and headers installed. 
> >>> 
> >>> I'm not completely up to speed on Fedora, but the order of the day is that 
> >>> you need to install some variation of lzma/zlib/bzlib and their -dev/-devel 
> >>> header files etc. Check appendix A.1 and A.2 of the R Installation and 
> >>> Administration manual. 
> >>> 
> >> 
> >> 
> >> -- 
> >> Technical Editor ANZJS 
> >> Department of Statistics 
> >> University of Auckland 
> >> Phone: +64-9-373-7599 ext. 88276 
> >> Home phone: +64-9-480-4619 
> >> 
> >> _______________________________________________ 
> >> R-SIG-Fedora mailing list 
> >> R-SIG-Fedora at r-project.org 
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-fedora 
> > 
> > 
> > 
>
>
> -- 
> Technical Editor ANZJS 
> Department of Statistics 
> University of Auckland 
> Phone: +64-9-373-7599 ext. 88276 
> Home phone: +64-9-480-4619 
>
> _______________________________________________ 
> R-SIG-Fedora mailing list 
> R-SIG-Fedora at r-project.org 
> https://stat.ethz.ch/mailman/listinfo/r-sig-fedora 

From ajdamico at gmail.com  Mon May 11 07:52:25 2015
From: ajdamico at gmail.com (Anthony Damico)
Date: Mon, 11 May 2015 01:52:25 -0400
Subject: [R] confidence intervals for differences in proportions from
 complex survey design?
In-Reply-To: <27E784E40B04E84588E94E6CE0F26EEB2ED19389@ITS-HCWNEM103.ds.vanderbilt.edu>
References: <27E784E40B04E84588E94E6CE0F26EEB2ED19389@ITS-HCWNEM103.ds.vanderbilt.edu>
Message-ID: <CAOwvMDwSuMo7JxOfR+-Oz5urmXrSKcyBxVqVp+-ocE2y70GXZA@mail.gmail.com>

i don't know the answer to your larger question, but for confidence
intervals around proportions you might look at ?svyciprop.  one of the
method= options might yield the same result as your approximation, not sure

On Mon, May 11, 2015 at 12:40 AM, Brown, Tony Nicholas <
tony.n.brown at vanderbilt.edu> wrote:

> All:
>
> I need to generate confidence intervals for differences in proportions
> using data from a complex survey design. An example follows where I attempt
> to estimate the difference in depression prevalence by sex.
>
> # Data might look something like this:
> Dfr<-data.frame(depression=sample(c("yes","no"), size=30, replace=TRUE),
>         sex=sample(c("M","F"), size=30, replace=TRUE),
>         cluster=rep(1:10, times=3),
>         stratum=rep(1:5, each=2, times=3),
>         pweight=runif(n=30, min=1, max=3))
> Dfr
> library(survey)
> msdesign<-svydesign(id=~cluster, strata=~stratum, weights=~pweight,
> nest=TRUE,
>         data=Dfr)
> # When searching online, one recommendation was to use svyglm() to
> generate an
> # approximation as follows:
> confint(with(Dfr, svyglm(I(depression=="yes")~sex,
> family=gaussian(link=identity),
>         msdesign)), level=0.95, method="Wald")
>
> This question has been asked before on the listserv (circa 2007) and I
> contacted the original poster, who indicated that they never received a
> reply.
>
> Here is the question as described by the original poster:
>
> "I'm trying to get confidence intervals of proportions (sometimes for
> subgroups) estimated from complex survey data. Because a function like
> prop.test() does not exist for the "survey" package I tried the following:
>
> 1) Define a survey object (PSU of clustered sample, population weights);
> 2) Use svyglm() of the package "survey" to estimate a binary logistic
> regression (family='binomial'): For the confidence interval of a single
> proportion regress the binary dependent variable on a constant (1), for
> confidence intervals of that variable for subgroups regress this
> variable on the groups (factor) variable;
> 3) Use predict() to obtain estimated logits and the respective standard
> errors (mod.dat specifying either the constant or the subgroups):
>
>     pred=predict(model,mod.dat,type='link',se.fit=T)
>
> and apply the following to obtain the proportion with its confidence
> intervals (for example, for conf.level=.95):
>
>     lo.e = pred[1:length(pred)]-qnorm((1+conf.level)/2)*SE(pred)
>     hi.e = pred[1:length(pred)]+qnorm((1+conf.level)/2)*SE(pred)
>     prop = 1/(1+exp(-pred[1:length(pred)]))
>     lo = 1/(1+exp(-lo.e))
>     hi = 1/(1+exp(-hi.e))
>
> I think that in that way I get CI's based on asymptotic normality -
> either for a single proportion or split up into subgroups.
>
> Question: Is this a correct or a defensible procedure? Or should I use a
> different approach? Note that this approach should also allow to
> estimate CI's for proportions of subgroups taking into account the
> complex survey design."
>
> Thanks in advance for any help that you can provide.
>
> Tony
>
>
> ------------------------------------------------------------------------------
> Tony N. Brown, Ph.D.
> Associate Chair and Associate Professor of Sociology
> Google Scholar Profile: http://tinyurl.com/lozlht8
> LinkedIn Profile:
> https://www.linkedin.com/pub/tony-nicholas-brown/a6/64/31a
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Mon May 11 08:17:56 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Mon, 11 May 2015 06:17:56 +0000
Subject: [R] Variance-covariance matrix
In-Reply-To: <CABzE1Sh3f_5MpWoNiKmdFcoDYbgcTorsc8JibPVAZp-AJkmmrg@mail.gmail.com>
References: <248E6FA047A8C746BA491485764190F521FBC3BD@ESESSMB207.ericsson.se>
	<15FB78AB-0015-4D2D-BB7B-8DBE6E4B4096@comcast.net>
	<248E6FA047A8C746BA491485764190F521FBC47C@ESESSMB207.ericsson.se>
	<CABzE1SiF54_Myu4WCp3EmXKKybTDBWa0gtgUrLRPVCSu9XgE9A@mail.gmail.com>
	<248E6FA047A8C746BA491485764190F521FBC4B7@ESESSMB207.ericsson.se>
	<CABzE1Sh3f_5MpWoNiKmdFcoDYbgcTorsc8JibPVAZp-AJkmmrg@mail.gmail.com>
Message-ID: <248E6FA047A8C746BA491485764190F521FBC4F5@ESESSMB207.ericsson.se>

Hi Tsjerk,

Yes, I understand your point. Thanks for drawing my attention on that aspect.

Let me then rephrase my question.

I would need some R package function able to compute the variance-covariance matrix
for multivariate series as defined at:

        http://stattrek.com/matrix-algebra/covariance-matrix.aspx


About what outlined in the book reference I mentioned, I shall open a separate thread
in the case.

Thanks.

---

Giorgio

Genoa, Italy

From: Tsjerk Wassenaar [mailto:tsjerkw at gmail.com]
Sent: domenica 10 maggio 2015 22:31
To: Giorgio Garziano
Cc: r-help at r-project.org
Subject: Re: [R] Variance-covariance matrix

Hi Giorgio,

This is for a multivariate time series. x1 is variable 1 of the observation vector x, x2, variable 2, etc. If you need x(i) and x(i+1), etc, then you're looking for the autocovariance/autocorrelation matrix, which is a quite different thing (and David showed the way). You can easily see that you don't have N-1 degrees of freedom per entry, because you have fewer 'observations' for larger lag times.

Cheers,

Tsjerk



On Sun, May 10, 2015 at 10:25 PM, Giorgio Garziano <giorgio.garziano at ericsson.com<mailto:giorgio.garziano at ericsson.com>> wrote:
Hi Tsjerk,

Yes, seriously.

Time series:

X = [x1, x2, x3, ....,xn]

The variance-covariance matrix is V matrix:

            V    =


? x12 / (N-1)

? x1 x2 / (N-1)

. . .

? x1 xn / (N-1)

? x2 x1 / (N-1)

? x22 / (N-1)

. . .

? x2 xn / (N-1)

. . .

. . .

. . .

. . .

? xn x1 / (N-1)

? xn x2 / (N-1)

. . .

? xn2 / (N-1)




Reference: ?Time series and its applications ? with R examples?, Springer,
     $7.8 ?Principal Components? pag. 468, 469

Cheers,

Giorgio


From: Tsjerk Wassenaar [mailto:tsjerkw at gmail.com<mailto:tsjerkw at gmail.com>]
Sent: domenica 10 maggio 2015 22:11

To: Giorgio Garziano
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Variance-covariance matrix

Hi Giorgio,

For a univariate time series? Seriously?

data <- rnorm(10,2,1)
as.matrix(var(data))

Cheers,

Tsjerk


On Sun, May 10, 2015 at 9:54 PM, Giorgio Garziano <giorgio.garziano at ericsson.com<mailto:giorgio.garziano at ericsson.com>> wrote:
Hi,

Actually as variance-covariance matrix I mean:

        http://stattrek.com/matrix-algebra/covariance-matrix.aspx

that I compute by:

        data <- rnorm(10,2,1)
        n <- length(data)
        data.center <- scale(data, center=TRUE, scale=FALSE)
        var.cov.mat <- (1/(n-1)) * data.center %*% t(data.center)

--
Giorgio Garziano


-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net<mailto:dwinsemius at comcast.net>]
Sent: domenica 10 maggio 2015 21:27
To: Giorgio Garziano
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Variance-covariance matrix


On May 10, 2015, at 4:27 AM, Giorgio Garziano wrote:

> Hi,
>
> I am looking for a R package providing with variance-covariance matrix computation of univariate time series.
>
> Please, any suggestions ?

If you mean the auto-correlation function, then the stats package (loaded by default at startup) has facilities:

?acf
# also same help page describes partial auto-correlation function
#Auto- and Cross- Covariance and -Correlation Function Estimation

--

David Winsemius
Alameda, CA, USA

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--
Tsjerk A. Wassenaar, Ph.D.



--
Tsjerk A. Wassenaar, Ph.D.

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon May 11 08:54:51 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 11 May 2015 08:54:51 +0200
Subject: [R] Code works on Mac but not Windows
In-Reply-To: <030b428c-042b-4134-9b4a-5b0e3eae56e2@me.com>
References: <030b428c-042b-4134-9b4a-5b0e3eae56e2@me.com>
Message-ID: <CAJuCY5wBaBgoeT8sE23wEOvS3DZtaDcYjjZBJyofstDdFiTvdA@mail.gmail.com>

Dear Glenn,

We need more details on the function. Please provide a commented, minimal,
self-contained version of the function that reproduces the problem (as the
posting guide asks you to do).

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-11 3:03 GMT+02:00 Glenn Schultz <glennmschultz at me.com>:

> Hello All,
>
> Testing my code on a Windows based machine today.  There seems to be an
> offending line of code.  I have pasted it below.  Basically, I check to see
> if the user passed a fit method to TermStructure and if not then default to
> "ns".
>
> The above works fine on my Mac but a windows build errors no method.  I
> have to pass a method = "ns" in the function.  If I pass the value for
> method to the function it will run with no error.  Any thoughts are
> appreciated.
>
> Best Regards,
> Glenn
>
>   #Default method for TermStructure
>   if(missing(method)) method = "ns"
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kridox at ymail.com  Mon May 11 09:36:26 2015
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 11 May 2015 16:36:26 +0900
Subject: [R] Variance-covariance matrix
In-Reply-To: <248E6FA047A8C746BA491485764190F521FBC4F5@ESESSMB207.ericsson.se>
References: <248E6FA047A8C746BA491485764190F521FBC3BD@ESESSMB207.ericsson.se>
	<15FB78AB-0015-4D2D-BB7B-8DBE6E4B4096@comcast.net>
	<248E6FA047A8C746BA491485764190F521FBC47C@ESESSMB207.ericsson.se>
	<CABzE1SiF54_Myu4WCp3EmXKKybTDBWa0gtgUrLRPVCSu9XgE9A@mail.gmail.com>
	<248E6FA047A8C746BA491485764190F521FBC4B7@ESESSMB207.ericsson.se>
	<CABzE1Sh3f_5MpWoNiKmdFcoDYbgcTorsc8JibPVAZp-AJkmmrg@mail.gmail.com>
	<248E6FA047A8C746BA491485764190F521FBC4F5@ESESSMB207.ericsson.se>
Message-ID: <CAAcyNCzz7Lvx=e+iicVLPxRN5L1uinWXHJTmUzmH-SspJk1z7g@mail.gmail.com>

Hi Giorgio,

No need for a package. Please check function var (?var).

Regards,
Pascal


On Mon, May 11, 2015 at 3:17 PM, Giorgio Garziano
<giorgio.garziano at ericsson.com> wrote:
> Hi Tsjerk,
>
> Yes, I understand your point. Thanks for drawing my attention on that aspect.
>
> Let me then rephrase my question.
>
> I would need some R package function able to compute the variance-covariance matrix
> for multivariate series as defined at:
>
>         http://stattrek.com/matrix-algebra/covariance-matrix.aspx
>
>
> About what outlined in the book reference I mentioned, I shall open a separate thread
> in the case.
>
> Thanks.
>
> ---
>
> Giorgio
>
> Genoa, Italy
>
> From: Tsjerk Wassenaar [mailto:tsjerkw at gmail.com]
> Sent: domenica 10 maggio 2015 22:31
> To: Giorgio Garziano
> Cc: r-help at r-project.org
> Subject: Re: [R] Variance-covariance matrix
>
> Hi Giorgio,
>
> This is for a multivariate time series. x1 is variable 1 of the observation vector x, x2, variable 2, etc. If you need x(i) and x(i+1), etc, then you're looking for the autocovariance/autocorrelation matrix, which is a quite different thing (and David showed the way). You can easily see that you don't have N-1 degrees of freedom per entry, because you have fewer 'observations' for larger lag times.
>
> Cheers,
>
> Tsjerk
>
>
>
> On Sun, May 10, 2015 at 10:25 PM, Giorgio Garziano <giorgio.garziano at ericsson.com<mailto:giorgio.garziano at ericsson.com>> wrote:
> Hi Tsjerk,
>
> Yes, seriously.
>
> Time series:
>
> X = [x1, x2, x3, ....,xn]
>
> The variance-covariance matrix is V matrix:
>
>             V    =
>
>
> ? x12 / (N-1)
>
> ? x1 x2 / (N-1)
>
> . . .
>
> ? x1 xn / (N-1)
>
> ? x2 x1 / (N-1)
>
> ? x22 / (N-1)
>
> . . .
>
> ? x2 xn / (N-1)
>
> . . .
>
> . . .
>
> . . .
>
> . . .
>
> ? xn x1 / (N-1)
>
> ? xn x2 / (N-1)
>
> . . .
>
> ? xn2 / (N-1)
>
>
>
>
> Reference: ?Time series and its applications ? with R examples?, Springer,
>      $7.8 ?Principal Components? pag. 468, 469
>
> Cheers,
>
> Giorgio
>
>
> From: Tsjerk Wassenaar [mailto:tsjerkw at gmail.com<mailto:tsjerkw at gmail.com>]
> Sent: domenica 10 maggio 2015 22:11
>
> To: Giorgio Garziano
> Cc: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: Re: [R] Variance-covariance matrix
>
> Hi Giorgio,
>
> For a univariate time series? Seriously?
>
> data <- rnorm(10,2,1)
> as.matrix(var(data))
>
> Cheers,
>
> Tsjerk
>
>
> On Sun, May 10, 2015 at 9:54 PM, Giorgio Garziano <giorgio.garziano at ericsson.com<mailto:giorgio.garziano at ericsson.com>> wrote:
> Hi,
>
> Actually as variance-covariance matrix I mean:
>
>         http://stattrek.com/matrix-algebra/covariance-matrix.aspx
>
> that I compute by:
>
>         data <- rnorm(10,2,1)
>         n <- length(data)
>         data.center <- scale(data, center=TRUE, scale=FALSE)
>         var.cov.mat <- (1/(n-1)) * data.center %*% t(data.center)
>
> --
> Giorgio Garziano
>
>
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net<mailto:dwinsemius at comcast.net>]
> Sent: domenica 10 maggio 2015 21:27
> To: Giorgio Garziano
> Cc: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: Re: [R] Variance-covariance matrix
>
>
> On May 10, 2015, at 4:27 AM, Giorgio Garziano wrote:
>
>> Hi,
>>
>> I am looking for a R package providing with variance-covariance matrix computation of univariate time series.
>>
>> Please, any suggestions ?
>
> If you mean the auto-correlation function, then the stats package (loaded by default at startup) has facilities:
>
> ?acf
> # also same help page describes partial auto-correlation function
> #Auto- and Cross- Covariance and -Correlation Function Estimation
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Tsjerk A. Wassenaar, Ph.D.
>
>
>
> --
> Tsjerk A. Wassenaar, Ph.D.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From r.turner at auckland.ac.nz  Mon May 11 09:42:53 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 11 May 2015 19:42:53 +1200
Subject: [R] [R-sig-Fedora]  Building R-3.2.0 from source.
In-Reply-To: <0d598c13-e2ec-4a01-8d1f-6c4f323302a5@email.android.com>
References: <0d598c13-e2ec-4a01-8d1f-6c4f323302a5@email.android.com>
Message-ID: <55505D7D.5080005@auckland.ac.nz>

On 11/05/15 16:19, Tom Callaway wrote:
> I just landed in Paris, and haven't read backwards in this thread,
> but I've done 3.2.0 builds for all current Fedora releases, they're
> all in updates-testing (I think the Fedora 22 builds are in updates
> stable now).
>
> The thing that changed is that R doesn't bundle a number of libraries
> like it used to. This doesn't affect the official Fedora R package,
> since we never used the bundled libraries. This is documented in the
> 3.2.0 release notes.
>
> If you really want to build from source, I think you can run:
>
> yum-builddep R
>
> That will install all the necessary Build Requires to build R from
> source. You need to have the yum-utils package installed for that
> command to exist.
>
> Hope that helps.

It certainly did!  Success.  Thank you hugely!

But if I may ask a supplementary question:  You say "If you really want 
to build from source ....".  No, I don't *want* to; I have to.  At least 
in my understanding.  I run the ancient and beyond end-of-life Fedora 
17.  (I haven't the nerve to try to upgrade; my current system may be 
kludgey, but at least it works.  And I *know* that if I try to upgrade 
all hell will break loose.)  It is my understanding that "current Fedora 
releases" *do not* include Fedora 17.  Or do they?
If so, how would I get my hands on an R binary for Fedora 17?

That's really just an academic question at present, since I have now 
managed, thanks to your help, to build R 3.2.0 from source.

Thanks again.

cheers,

Rolf Turner

>
> On May 11, 2015 3:10 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>> On 11/05/15 12:06, M. Edward (Ed) Borasky wrote:
>>> 1. R 3.2.0 is packaged for Fedora now; it's in Rawhide and Fedora 22.
>>> I'm running Fedora 22 (late beta) and haven't had any problems with R.
>>> RStudio Desktop Preview (0.99.435) from the RStudio Fedora RPM is also
>>> running fine. You might save yourself some hassles by upgrading to
>>> Fedora 22.
>>
>> I'm sure I would, but I don't dare.  Everything I see on the Fedora
>> mailing list fills me with terror in respect of the disasters that can
>> occur.  I don't have the skills to cope with such disasters and I have
>> no access to support in respect of Fedora.
>>
>>> 2. I have a bash script to build R from source that works on Fedora
>>> 22. It probably also works on Fedora 21 but it's been a while since I
>>> tried it. Note that it installs 'calibre' and makes the ebooks of the
>>> manuals. It also does some packaging things at the end you probably
>>> don't need.
>>
>> Thanks, but I don't think it's any help in my situation.
>>
>> I had no problem at all building R 3.1.2 from source.  What changed from
>> 3.1.2 to 3.2.0 that would cause those undefined reference problems?
>>
>> cheers,
>>
>> Rolf Turner
>>
>>>
>>> On Sun, May 10, 2015 at 2:52 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>>
>>>> I am cross-posting this to r-sig-fedora (I hope that's not an egregious sin)
>>>> in the hope that doing so might provide some source of insight.
>>>>
>>>> I tried
>>>>
>>>>        sudo yum install zlib
>>>>
>>>> and was told
>>>>
>>>>> Package zlib-1.2.5-7.fc17.x86_64 already installed and latest version
>>>>
>>>>
>>>>
>>>> Likewise for "zlib-devel".
>>>>
>>>> I also tried
>>>>
>>>>        sudo yum install bzlib
>>>>
>>>> and was told
>>>>
>>>>> No package bzlib available.
>>>>
>>>>
>>>> Likewise for "bzlib-devel".
>>>>
>>>> Finally I sort of got some joy with "lzma" and "lzma-devel" --- both of
>>>> those yielded an actual installation.  But it didn't help.
>>>>
>>>> I re-did the configure and then the make and got the same errors/complaints
>>>> about undefined references to deflate, inflate, crc32, etc.
>>>>
>>>> Can anyone provide any guidance/suggestions about what else I could try?
>>>> I'm getting very frustrated! :-)
>>>>
>>>> cheers,
>>>>
>>>> Rolf Turner
>>>>
>>>> On 11/05/15 00:50, peter dalgaard wrote:
>>>>>
>>>>>
>>>>>> On 10 May 2015, at 14:15 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>>>>
>>>>>>
>>>>>>
>>>>>> I am just now getting around to upgrading from 3.1.2 to 3.2.0 and am
>>>>>> getting hammered by a problem which is beyond my limited capabilities of
>>>>>> handling.
>>>>>>
>>>>>> I executed
>>>>>>
>>>>>>      ./configure --with-tcltk --with cairo
>>>>>>
>>>>>> which seemed to go just fine, and then did:
>>>>>>
>>>>>>       make
>>>>>>
>>>>>> In fairly short order I started getting  error messages like unto:
>>>>>>
>>>>>>> connections.o: In function `gzcon_write':
>>>>>>> /home/rolf/Desktop/Rinst/R-3.2.0/src/main/connections.c:5469: undefined
>>>>>>> reference to `deflate'
>>>>>>
>>>>>>
>>>>>> There were also complaints about undefined references to inflate, crc32,
>>>>>> deflateEnd, inflateEnd, inflateReset, inflateInit2_, deflateInit2_,
>>>>>> compress, uncompress, and zlibVersion, many of which were issued repeatedly.
>>>>>> It finally gave up, saying:
>>>>>>
>>>>>>> collect2: error: ld returned 1 exit status
>>>>>>
>>>>>>
>>>>>> A bit of googling informed me (I think?) that a workaround was to
>>>>>> configure using --without-system-pcre.  This however achieved nothing in my
>>>>>> case.
>>>>>>
>>>>>> Can anyone point me at what I need to do to fix this?  Install or update
>>>>>> something?
>>>>>>
>>>>>> I am running an (elderly, no-longer-supported) Fedora 17 Linux.
>>>>>>
>>>>>> Thanks for any assistance.
>>>>>
>>>>>
>>>>> PCRE (regular expressions) won't help you with compression algorithms...
>>>>> If anything, it is  --without-system-xz, -zlib, -bzlib that would come into
>>>>> play, but it would be a better idea to ensure that you do have the libraries
>>>>> and headers installed.
>>>>>
>>>>> I'm not completely up to speed on Fedora, but the order of the day is that
>>>>> you need to install some variation of lzma/zlib/bzlib and their -dev/-devel
>>>>> header files etc. Check appendix A.1 and A.2 of the R Installation and
>>>>> Administration manual.
>>>>>
>>>>
>>>>
>>>> --
>>>> Technical Editor ANZJS
>>>> Department of Statistics
>>>> University of Auckland
>>>> Phone: +64-9-373-7599 ext. 88276
>>>> Home phone: +64-9-480-4619
>>>>
>>>> _______________________________________________
>>>> R-SIG-Fedora mailing list
>>>> R-SIG-Fedora at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-fedora
>>>
>>>
>>>
>>
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>> Home phone: +64-9-480-4619
>>
>> _______________________________________________
>> R-SIG-Fedora mailing list
>> R-SIG-Fedora at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-fedora


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From zadig_1 at excite.com  Mon May 11 15:39:32 2015
From: zadig_1 at excite.com (ce)
Date: Mon, 11 May 2015 09:39:32 -0400
Subject: [R] how to update a value in a list with lapply
Message-ID: <20150511093932.31430@web003.roc2.bluetie.com>


Thanks a lot Bill and David. 
Very few elements will be updated in the list. I think I will go for for loop in this case. As a classic programmer I still feel uncomfortable with lapply anyway. 
ce

-----Original Message-----
From: "William Dunlap" [wdunlap at tibco.com]
Date: 05/10/2015 06:00 PM
To: "ce" <zadig_1 at excite.com>
CC: "David Winsemius" <dwinsemius at comcast.net>, r-help at r-project.org
Subject: Re: [R] how to update a value in a list with lapply

You can do the timing yourself on a dataset which you feel is typical of your usage.E.g., define a function the implements each algorithm? > f1 <- function(foo) lapply(foo, function(x) { if (x[1] == 1) x[2] <- 0 ; x })
? > f2 <- function(foo) { for(i in seq_along(foo)) if (foo[[i]][1] == 1) foo[[i]][2] <- 0 ; foo }
and compare the times (and return values) on various datasets.
? > foo1 <- rep(list(c(1,2,1:100)), length=1e5) # every element needs changing
? > system.time(v1 <- f1(foo1))

? ? ?user ?system elapsed?
? ? ?0.28 ? ?0.01 ? ?0.29?
? > system.time(v2 <- f2(foo1))
? ? ?user ?system elapsed?
? ? ?0.26 ? ?0.03 ? ?0.30?
? > identical(v1, v2)
? [1] TRUE
? > foo2 <- rep(list(c(0,2,1:100)), length=1e5) # no element needs changing
? > system.time(v1 <- f1(foo2))
? ? ?user ?system elapsed?
? ? ?0.09 ? ?0.00 ? ?0.09?
? > system.time(v2 <- f2(foo2))
? ? ?user ?system elapsed?
? ? ?0.07 ? ?0.00 ? ?0.07?
? > identical(v1, v2)
? [1] TRUE










Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, May 10, 2015 at 6:11 AM, ce <zadig_1 at excite.com> wrote:

yes indeed :

?foo <- lapply(foo, function(x) if(x[1] == 1 ) {x[2] <- 0; x }else{x} )

would work. But if the list is too long, would it be time consuming? rather than just updating elements that meet the if condition?

thx
ce


-----Original Message-----
From: "David Winsemius" [dwinsemius at comcast.net]
Date: 05/09/2015 08:00 PM
To: "ce" <zadig_1 at excite.com>
CC: r-help at r-project.org
Subject: Re: [R] how to update a value in a list with lapply


On May 9, 2015, at 4:35 PM, ce wrote:

> Dear All,
>
> I have a list, using lapply I find some elements of the list, and then I want to change the values I find. but it doesn't work:
>
> foo<-list(A = c(1,3), B =c(1, 2), C = c(3, 1))
> lapply(foo, function(x) if(x[1] == 1 ) x )
> $A
> [1] 1 3
>
> $B
> [1] 1 2
>
> $C
> NULL
>
> lapply(foo, function(x) if(x[1] == 1 ) x[2] <- 0 )
> $A
> [1] 0
>
> $B
> [1] 0
>
> $C
> NULL
>
>> lapply(foo, function(x) if(x[1] == 1 ) x )
> $A
> [1] 1 3
>
> $B
> [1] 1 2
>
> $C
> NULL
>
>
> how to do it correctly ?

I find it useful to think of the `if` function as `if(cond){cons}else{alt}`

lapply(foo, function(x)? if(x[1] == 1 ) {x[2] <- 0; x }else{x} )
#-----
$A
[1] 1 0

$B
[1] 1 0

$C
[1] 3 1


You were not supply an alternative which was the cause of the NULL (and you were not returning a value which meant that the value returned was the value on the RHS of the assignment).

--

David Winsemius
Alameda, CA, USA

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From tcallawa at redhat.com  Mon May 11 11:26:39 2015
From: tcallawa at redhat.com (Tom Callaway)
Date: Mon, 11 May 2015 11:26:39 +0200
Subject: [R] [R-sig-Fedora]  Building R-3.2.0 from source.
In-Reply-To: <55505D7D.5080005@auckland.ac.nz>
References: <0d598c13-e2ec-4a01-8d1f-6c4f323302a5@email.android.com>
	<55505D7D.5080005@auckland.ac.nz>
Message-ID: <555075CF.9030902@redhat.com>

On 05/11/2015 09:42 AM, Rolf Turner wrote:
> It certainly did!  Success.  Thank you hugely!
> 
> But if I may ask a supplementary question:  You say "If you really want
> to build from source ....".  No, I don't *want* to; I have to.  At least
> in my understanding.  I run the ancient and beyond end-of-life Fedora
> 17.  (I haven't the nerve to try to upgrade; my current system may be
> kludgey, but at least it works.  And I *know* that if I try to upgrade
> all hell will break loose.)  It is my understanding that "current Fedora
> releases" *do not* include Fedora 17.  Or do they?
> If so, how would I get my hands on an R binary for Fedora 17?
> 
> That's really just an academic question at present, since I have now
> managed, thanks to your help, to build R 3.2.0 from source.

Wow. Well, I can't say that I'm building anything for end-of-lifed
Fedora releases, though I understand your predicament.

That said, I am still building for EL5, which is older than Fedora 17,
so you could try to rebuild the R src.rpm from koji. If it does not work
properly, let me know, and I will try to fix the conditionals so that it
does.

Glad you got it working. :)

~tom

==
Red Hat


From nilsson.henric at gmail.com  Mon May 11 15:41:47 2015
From: nilsson.henric at gmail.com (Henric Winell)
Date: Mon, 11 May 2015 15:41:47 +0200
Subject: [R] how to update a value in a list with lapply
In-Reply-To: <F519900E-BF2A-48EC-93F6-120515D289B4@comcast.net>
References: <20150510091143.18474@web007.roc2.bluetie.com>
	<F519900E-BF2A-48EC-93F6-120515D289B4@comcast.net>
Message-ID: <5550B19B.7070102@gmail.com>

On 2015-05-10 21:14, David Winsemius wrote:

> On May 10, 2015, at 6:11 AM, ce wrote:
>
>>
>> yes indeed :
>>
>> foo <- lapply(foo, function(x) if(x[1] == 1 ) {x[2] <- 0; x
>> }else{x} )
>>
>> would work. But if the list is too long, would it be time consuming
>> rather than just updating elements that meet the if condition?
>
> Any change to an object will require copying the entire object. That
> is the computing model that R uses. If you had presented a
> modification strategy that used logical or numeric indexing to effect
> only targeted nodes of a list, it still would have ended up copying
> the whole object.

This used to be true, but is no longer the case (from R-3.1.0 if my
memory serves me right).  Consider the following example.

> lst <- list(c(1L, 2L), 3.0)
> lst
[[1]]
[1] 1 2

[[2]]
[1] 3

>
> .Internal(inspect(lst))
@1fecce8 19 VECSXP g1c2 [MARK,NAM(1)] (len=2, tl=0)
   @26996a8 13 INTSXP g1c1 [MARK] (len=2, tl=0) 1,2
   @2699648 14 REALSXP g1c1 [MARK,NAM(2)] (len=1, tl=0) 3

Note the memory addresses (the ones starting with @).  Now, let's modify
the first list element:

> lst[[1]][1] <- 4L
> .Internal(inspect(lst))
@1fecce8 19 VECSXP g1c2 [MARK,NAM(1)] (len=2, tl=0)
   @26996a8 13 INTSXP g1c1 [MARK] (len=2, tl=0) 4,2
   @2699648 14 REALSXP g1c1 [MARK,NAM(2)] (len=1, tl=0) 3

As you can see, 'lst' changed but the memory address is still the same. 
  However, if we assign a double instead of an integer in the same 
position, copying must take place since the internal representation is 
changed:

> lst[[1]][1] <- 4.0
> .Internal(inspect(lst))
@1fecce8 19 VECSXP g1c2 [MARK,NAM(1)] (len=2, tl=0)
   @12685a0 14 REALSXP g0c2 [] (len=2, tl=0) 4,2
   @2699648 14 REALSXP g1c1 [MARK,NAM(2)] (len=1, tl=0) 3

But note that *only* the address of the first list element changed. 
This list itself and the second list element remain at the same 
addresses as before.


Henric Winell



>
> The data.table package was invented in large part to get around that
> design concern.
>


From JRMHosking at gmail.com  Mon May 11 16:17:58 2015
From: JRMHosking at gmail.com (J. R. M. Hosking)
Date: Mon, 11 May 2015 10:17:58 -0400
Subject: [R] lmom and lmomRFA Upper and Lower Bounds Simulation Questions
In-Reply-To: <55502997.7030802@appliedweatherassociates.com>
References: <55502997.7030802@appliedweatherassociates.com>
Message-ID: <5550BA16.5070806@gmail.com>

On 2015-05-11 00:01, Douglas Hultstrand wrote:
> Hello,
>
> I am using the lmom and lmomRFA to compute the return frequencies using
> the GEV distribution.Iam trying to generate upper and lower bound
> frequency estimates.
>
> I provided a working example of the code that I am using to estimate the
> upper and lower bounds. Specific questions I have are:
>
> 1) Is the methodology appropriate and applied correctly?
>
> 2) In this example, are the simulated qhat values better than the actual
> fitted data estimates (GEV)?
>
> _*Code Example Below:*_
>
> library(lmom); library(lmomRFA)
> set.seed(1234)
>
> # Example data
> max_data <-
> c(11.14,10.95,10.21,9.88,9.85,9.74,9.74,9.73,9.62,8.95,8.38,8.20)
> moments = samlmu(max_data, sort.data = TRUE)
> parGEV <- pelgev(moments)  # GEV
>
> x <- c(10,25,50,100,500,1000)
> Fx <- (1-(1/x))
> GEV = Fx
> PDS <- 1/(log(x)-log(x-1))
>
> for (i in seq_along(Fx)) {
>       GEV[i] = round(quagev(Fx[i], parGEV), 3)
> }
>
> ################
> #### BOUNDS ###
> ################
> # A data sample
> zz_gev <- quagev(runif(500), parGEV)
>
> # Compute L-moments of the sample, considered as a 1-site region
> rdat_gev <- regsamlmu(zz_gev)
>
> # Fit GEV distribution to the regional L-moments
> rfit_gev <- regfit(rdat_gev,"gev")
>
> # Generate simulations of an artificial 1-site region with frequency
> distribution fitted to the actual data
> sim_gev <- regsimq(rfit_gev$qfunc, nrec = rdat_gev$n, f = 1 - 1 / x )
>
> # Compute error bounds for quantiles of the site's frequency distribution
> CI_gev <- sitequantbounds(sim_gev, rfit_gev)
>
> # 90% Error Bounds/CI
> Clwr <- round(CI_gev$bound.0.05, 3)
> Cupr <- round(CI_gev$bound.0.95, 3)
> qhat <- round(CI_gev$Qhat, 3)
>
> # print data
> data.frame(Fx, GEV, Clwr, Cupr, qhat)
>
> ####################
> #### END BOUNDS ##
> ####################
>
>
> #Plot and visualize the data
> plot(x, GEV, log="x", ylim=c(10.5,12.5), col="blue")
> lines(PDS,GEV, col="blue")
> lines(PDS,Clwr, lty=3)
> lines(PDS,Cupr, lty=3)
> lines(PDS,qhat, col="red", lty=5)
>
> Thanks for your help,
>
> Doug
>


 > 1) Is the methodology appropriate and applied correctly?

Without knowing what you are trying to achieve, it is not possible
to answer that question.  The code that you provide appropriately
and correctly evaluates error bounds for quantile estimates of a
GEV distribution fitted to the data set 'zz_gev'.

The larger point here is that regional frequency analysis for a "region"
containing a single site is equivalent to analysis of a single data set.
In particular, the error bounds returned by sitequantbounds() for a
1-site region are identical to confidence intervals for quantiles
computed for a single data set using a parametric bootstrap.

 > 2) In this example, are the simulated qhat values better than the
 > actual fitted data estimates (GEV)?

See the first sentence of my reply to 1).  'GEV' are the quantiles
of a GEV distribution fitted to 'max_data'.  'CI_gev$Qhat' are the
quantiles of a GEV distribution fitted to 'zz_gev' (you can verify that
'CI_gev$Qhat' is the same as 'quagev(Fx,pelgev(samlmu(zz_gev)))').
For inference about 'max_data', 'GEV' is likely to be better.
For inference about 'zz_gev', 'CI_gev$Qhat' is likely to be better.


J. R. M. Hosking
jrmhosking at gmail.com


From lorenzo.isella at gmail.com  Mon May 11 17:17:32 2015
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Mon, 11 May 2015 17:17:32 +0200
Subject: [R] Caret and custom summary function
Message-ID: <20150511151732.GA15692@localhost.localdomain>

Dear All,
I am trying to implement my own metric (a log loss metric) for a
binary classification problem in Caret.
I must be making some mistake, because I cannot get anything sensible
out of it.
I paste below a numerical example which should run in more or less one
minute on any laptop.
When I run it, I finally have an output of the kind




Aggregating results
Something is wrong; all the LogLoss metric values are missing:
    LogLoss
     Min.   : NA
      1st Qu.: NA
       Median : NA
        Mean   :NaN
	 3rd Qu.: NA
	  Max.   : NA
	   NA's   :40
	   Error in train.default(x, y, weights = w, ...) : Stopping
	   In addition: Warning message:
	   In nominalTrainWorkflow(x = x, y = y, wts = weights, info =
	   trainInfo,  :
	     There were missing values in resampled performance
	     measures.
	     




Any suggestion is appreciated.
Many thanks

Lorenzo





####################################################??

library(caret)
library(C50)


LogLoss <- function (data, lev = NULL, model = NULL)
{
    probs <- pmax(pmin(as.numeric(data$T), 1 - 1e-15), 1e-15)
        logPreds <- log(probs)
	    log1Preds <- log(1 - probs)
	        real <- (as.numeric(data$obs) - 1)
		    out <- c(mean(real * logPreds + (1 - real) *
		    log1Preds)) * -1
		        names(out) <- c("LogLoss")
			    out
			    }






train <- matrix(ncol=5,nrow=200,NA)

train <- as.data.frame(train)
names(train) <- c("donation", "x1","x2","x3","x4")

set.seed(134)

sel <- sample(nrow(train), 0.5*nrow(train))


train$donation[sel] <- "yes"
train$donation[-sel] <- "no"

train$x1 <- seq(nrow(train))
train$x2 <- rnorm(nrow(train))
train$x3 <- 1/train$x1
train$x4 <- sample(nrow(train))

train$donation <- as.factor(train$donation)

c50Grid <- expand.grid(trials = 1:10,
         model = c( "tree" ,"rules"
	                    ),winnow = c(TRUE,
			                             FALSE ))





tc <- trainControl(method = "repeatedCV", summaryFunction=LogLoss,
                   number = 10, repeats = 10, verboseIter=TRUE,
                   classProbs=TRUE)


model <- train(donation~., data=train, method="C5.0", trControl=tc,
               metric="LogLoss", maximize=FALSE, tuneGrid=c50Grid)


From mxkuhn at gmail.com  Mon May 11 17:37:23 2015
From: mxkuhn at gmail.com (Max Kuhn)
Date: Mon, 11 May 2015 11:37:23 -0400
Subject: [R] Caret and custom summary function
In-Reply-To: <20150511151732.GA15692@localhost.localdomain>
References: <20150511151732.GA15692@localhost.localdomain>
Message-ID: <CAJ9CoWmhOpJvDQVgsgKiKPBtAkzCBgcurUxKn2huum0Jsz9sLg@mail.gmail.com>

The version of caret just put on CRAN has a function called mnLogLoss that
does this.

Max

On Mon, May 11, 2015 at 11:17 AM, Lorenzo Isella <lorenzo.isella at gmail.com>
wrote:

> Dear All,
> I am trying to implement my own metric (a log loss metric) for a
> binary classification problem in Caret.
> I must be making some mistake, because I cannot get anything sensible
> out of it.
> I paste below a numerical example which should run in more or less one
> minute on any laptop.
> When I run it, I finally have an output of the kind
>
>
>
>
> Aggregating results
> Something is wrong; all the LogLoss metric values are missing:
>    LogLoss
>     Min.   : NA
>      1st Qu.: NA
>       Median : NA
>        Mean   :NaN
>          3rd Qu.: NA
>           Max.   : NA
>            NA's   :40
>            Error in train.default(x, y, weights = w, ...) : Stopping
>            In addition: Warning message:
>            In nominalTrainWorkflow(x = x, y = y, wts = weights, info =
>            trainInfo,  :
>              There were missing values in resampled performance
>              measures.
>
>
>
>
> Any suggestion is appreciated.
> Many thanks
>
> Lorenzo
>
>
>
>
>
> ####################################################??
>
> library(caret)
> library(C50)
>
>
> LogLoss <- function (data, lev = NULL, model = NULL)
> {
>    probs <- pmax(pmin(as.numeric(data$T), 1 - 1e-15), 1e-15)
>        logPreds <- log(probs)
>             log1Preds <- log(1 - probs)
>                 real <- (as.numeric(data$obs) - 1)
>                     out <- c(mean(real * logPreds + (1 - real) *
>                     log1Preds)) * -1
>                         names(out) <- c("LogLoss")
>                             out
>                             }
>
>
>
>
>
>
> train <- matrix(ncol=5,nrow=200,NA)
>
> train <- as.data.frame(train)
> names(train) <- c("donation", "x1","x2","x3","x4")
>
> set.seed(134)
>
> sel <- sample(nrow(train), 0.5*nrow(train))
>
>
> train$donation[sel] <- "yes"
> train$donation[-sel] <- "no"
>
> train$x1 <- seq(nrow(train))
> train$x2 <- rnorm(nrow(train))
> train$x3 <- 1/train$x1
> train$x4 <- sample(nrow(train))
>
> train$donation <- as.factor(train$donation)
>
> c50Grid <- expand.grid(trials = 1:10,
>         model = c( "tree" ,"rules"
>                             ),winnow = c(TRUE,
>                                                      FALSE ))
>
>
>
>
>
> tc <- trainControl(method = "repeatedCV", summaryFunction=LogLoss,
>                   number = 10, repeats = 10, verboseIter=TRUE,
>                   classProbs=TRUE)
>
>
> model <- train(donation~., data=train, method="C5.0", trControl=tc,
>               metric="LogLoss", maximize=FALSE, tuneGrid=c50Grid)
>
>
>

	[[alternative HTML version deleted]]


From glennmschultz at me.com  Mon May 11 17:36:12 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Mon, 11 May 2015 15:36:12 +0000 (GMT)
Subject: [R] Code works on Mac but not Windows
Message-ID: <eab3ceb9-11e6-42cb-bf6f-6091e5afdc8c@me.com>

Hi Thierry,

Below is the function
setMethod("initialize",
          signature("TermStructure"),
          function(.Object,...,
                   tradedate = "character",
                   period = "numeric",
                   date = "character",
                   spotrate = "numeric",
                   forwardrate = "numeric",
                   TwoYearFwd = "numeric",
                   TenYearFwd = "numeric")
          {
            .Object at tradedate = tradedate
            .Object at period = period
            .Object at date = date
            .Object at spotrate = spotrate
            .Object at forwardrate = forwardrate
            .Object at TwoYearFwd = TwoYearFwd
            .Object at TenYearFwd = TenYearFwd
            
            return(.Object)
            callNextMethod(.Object,...)
          })
#' The TermStructure constructor function it is a wrapper function around the package termstrc
#' 
#' This is a wrapper function around the R package termstrc.  The function passes swap rate data
#' cash flows the to termstrc and creates the TermStructure object used by Bondlab.
#' The function call rates data processes the yield curve and derives cashflow
#' for the daily close swap curve. A Rates object must be called in the local
#' environment for this function to work.
#' @param rates.data A character string representing the data for which the user
#' would like to call the swap curve
#' @param method A character string indicating the fitting method ns = Nelson Siegel, dl = Diebold Lee,
#' sv = Severson, asv = adjusted Severson, cs = cubic spline (not yet implemented in Bond Lab).
#' For addiition details see the termstrc documentation.
#' @examples
#' \dontrun{
#' TermStructure(rates.data = "01-10-2013", method = "ns")}
#' @importFrom lubridate %m+%
#' @importFrom lubridate years
#' @importFrom lubridate day
#' @importFrom lubridate month
#' @importFrom termstrc estim_nss estim_cs spotrates forwardrates
#'@export TermStructure
  TermStructure <- function(rates.data = "character", method = "character"){
  
  #function(trade.date = "character", method = "character")  
  #Error Trap User inputs to the function
  if(missing(rates.data)) stop("missing rates data object")  
  
  # this is the code snippet that works in MAC but not windows
  #Default to Nelson-Siegel
  if(missing(method)) method = "ns"
  
  #Default to parametric
  if(method == "cs") stop("cubic spline not implemented")
  
  #Check that the user input a valid method
  CheckMethod <- c("ns", "dl", "sv", "asv", "cs")
  if(!method %in% CheckMethod) stop ("Invalid 'method' Value")
  
  # pass the yield curve to the function
  rates.data <- rates.data
  
  #set the column counter to make cashflows for termstrucutre
  ColCount <- as.numeric(ncol(rates.data))
  Mat.Years <- as.numeric(rates.data[2,2:ColCount])
  Coupon.Rate <- as.numeric(rates.data[1,2:ColCount])
  Issue.Date <- as.Date(rates.data[1,1])
  
  #initialize coupon bonds S3 class
  #This can be upgraded when bondlab has portfolio function
  ISIN <- vector()
  MATURITYDATE <- vector()
  ISSUEDATE <- vector()
  COUPONRATE <- vector()
  PRICE <- vector()
  ACCRUED <- vector()
  CFISIN <- vector()
  CF <- vector()
  DATE <- vector()
  CASHFLOWS  <- list(CFISIN,CF,DATE)
  names(CASHFLOWS) <- c("ISIN","CF","DATE")
  TODAY <- vector()
  data <- list()
  TSInput <- list()
  
  ### Assign Values to List Items #########
  data = NULL
  data$ISIN <- colnames(rates.data[2:ColCount])
  data$ISSUEDATE <- rep(as.Date(rates.data[1,1]),ColCount - 1)
  
  data$MATURITYDATE <-
    sapply(Mat.Years, function(Mat.Years = Mat.Years, Issue = Issue.Date) 
    {Maturity = if(Mat.Years < 1) {Issue %m+% months(round(Mat.Years * months.in.year))} else 
    {Issue %m+% years(as.numeric(Mat.Years))}
    return(as.character(Maturity))
    }) 
  
  data$COUPONRATE <- ifelse(Mat.Years < 1, 0, Coupon.Rate)                  
  
  data$PRICE <-      ifelse(Mat.Years < 1, (1 + (Coupon.Rate/100))^(Mat.Years * -1) * 100, 100)
  
  data$ACCRUED <- rep(0, ColCount -1)
  
  for(j in 1:(ColCount-1)){
    Vector.Length <- as.numeric(round(difftime(data[[3]][j],
                                               data[[2]][j],
                                               units = c("weeks"))/weeks.in.year,0))
    Vector.Length <- ifelse(Vector.Length < 1, 1, Vector.Length * pmt.frequency)  
    #pmt.frequency should be input 
    
    data$CASHFLOWS$ISIN <- append(data$CASHFLOWS$ISIN, rep(data[[1]][j],Vector.Length))
    
    data$CASHFLOWS$CF <- append(data$CASHFLOWS$CF,
              as.numeric(c(rep((data[[4]][j]/100/pmt.frequency), Vector.Length-1) * min.principal, 
              (min.principal + (data$COUPONRATE[j]/100/pmt.frequency)* min.principal))))
    
    by.months = ifelse(data[[4]][j] == 0, round(difftime(data[[3]][j], rates.data[1,1])/days.in.month), 6) 
    # this sets the month increment so that cashflows can handle discount bills
    
    data$CASHFLOWS$DATE <- append(data$CASHFLOW$DATE,
                          seq(as.Date(rates.data[1,1]) %m+% months(as.numeric(by.months)), 
                          as.Date(data[[3]][j]), by = as.character(paste(by.months, "months", sep = " "))))
    
  } #The Loop Ends here and the list is made
  
  data$TODAY <- as.Date(rates.data[1,1])
  TSInput[[as.character(rates.data[1,1])]] <- c(data)
  
  #set term strucuture input (TSInput) to class couponbonds
  class(TSInput) <- "couponbonds"
  
  #Fit the term structure of interest rates
  
  if(method != "cs") {TSFit <- estim_nss(dataset = TSInput, 
                                         group = as.character(rates.data[1,1]), 
                                         matrange = "all", method = method)} else
  {TSFit <- estim_cs(bonddata = TSInput, 
                     group = as.character(rates.data[1,1]), 
                     matrange = "all", rse = TRUE)}
  
  #Return the coefficient vector to be passed in to the spot and forward rate functions
  #Maybe have the method choosen based on the one that gives the smallest RMSE
  Vector <- switch(method,
                   ns = unname(TSFit$opt_result[[1]]$par[c("beta0", "beta1", "beta2", "tau1")]),
                   dl = unname(TSFit$opt_result[[1]]$par[c("beta0", "beta1", "beta2")]),
                   sv = unname(TSFit$opt_result[[1]]$par[c("beta0", "beta1", "beta2", "tau1", "beta3", "tau2")]),
                   asv = unname(TSFit$opt_result[[1]]$par[c("beta0", "beta1", "beta2", "tau1", "tau2", "tau3")]),
                   #cs = need to figure this out
  )
  
  #Calculate the spot rate curve and determine the forward rates needed to 
  period <- seq(from = 1, to = 492, by = 1)
  #Use the date from the cashflow file
  date <- seq(as.Date(rates.data[1,1]) %m+% months(1), as.Date(data[[3]][j]), by="1 months")
  
  spot.rate.curve <- spotrates(method = method, beta = Vector, m = seq(from = 1/12, to = 492/12, by = 1/12))
  
  forward.rate.curve <- forwardrates(method = method, beta = Vector, m = seq(from = 1/12, to = 492/12, by = 1/12))
  
  Two.Year.Fwd <- (((1 + spot.rate.curve[seq(from = 25, to = 385, by = 1)]) ^ 
                      (period[seq(from = 25, to = 385, by = 1)]/12) /
                      (1 + spot.rate.curve[seq(from = 1, to = 361, by = 1)]) ^ 
                      (period[seq(from = 1, to = 361, by = 1)]/12))^(1/2))-1
  
  Ten.Year.Fwd <- (((1 + spot.rate.curve[seq(from = 121, to = 481, by = 1)]) ^ 
                      (period[seq(from = 121, to = 481, by = 1)]/12) /
                      (1 + spot.rate.curve[seq(from = 1, to = 361, by = 1)]) ^ 
                      (period[seq(from = 1, to = 361, by = 1)]/12))^(1/10))-1
  
  new("TermStructure",
      tradedate = as.character(rates.data[1,1]),
      period = as.numeric(period),
      date = as.character(date),
      spotrate = spot.rate.curve,
      forwardrate = forward.rate.curve,
      TwoYearFwd = Two.Year.Fwd,
      TenYearFwd = Ten.Year.Fwd
  )
} 


setGeneric("TermStructure",
           function(rates.data = "character", method = "character")
           {standardGeneric("TermStructure")})

On May 11, 2015, at 01:54 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:

Dear Glenn,

We need more details on the function. Please provide a commented, minimal, self-contained version of the function that reproduces the problem (as the posting guide asks you to do).?

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner 
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-05-11 3:03 GMT+02:00 Glenn Schultz <glennmschultz at me.com>:
Hello All,

Testing my code on a Windows based machine today.? There seems to be an offending line of code.? I have pasted it below.? Basically, I check to see if the user passed a fit method to TermStructure and if not then default to "ns". ?

The above works fine on my Mac but a windows build errors no method.? I have to pass a method = "ns" in the function.? If I pass the value for method to the function it will run with no error.? Any thoughts are appreciated.

Best Regards,
Glenn

? #Default method for TermStructure
? if(missing(method)) method = "ns"
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From highstat at highstat.com  Mon May 11 22:06:38 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 11 May 2015 22:06:38 +0200
Subject: [R] Course: Introduction to zero inflated models with R
Message-ID: <55510BCE.3090104@highstat.com>

Apologies for cross-posting


We would like to announce the following statistics course in Palm Cove, 
Australia.

Course:  Introduction to zero inflated models with R
Location: Palm Cove, Australia
Date:       17-21 August 2015
Price:       550 GBP
Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://www.highstat.com/Courses/Flyers/Flyer2015_08PalmCoveII.pdf


Keywords:
Zero inflated GLM (ZIP, ZINB, ZAP, ZANB). Zero inflated GLMMs with 
random effects. Bayesian statistics,
MCMC and JAGS. lme4, glmmADMB, JAGS. Overdispersion and solutions. 
Poisson, negative binomial,
gamma, lognormal and binomial distributions. Count data. Continuous data.


Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From henrik.bengtsson at ucsf.edu  Mon May 11 22:19:34 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Mon, 11 May 2015 13:19:34 -0700
Subject: [R] Code works on Mac but not Windows
In-Reply-To: <eab3ceb9-11e6-42cb-bf6f-6091e5afdc8c@me.com>
References: <eab3ceb9-11e6-42cb-bf6f-6091e5afdc8c@me.com>
Message-ID: <CAFDcVCQLh6AS0dopyyU5atQD220kJBmoz=b+awSYC2V9a-10iw@mail.gmail.com>

Before blaming Windows and/or OS X, make sure you verify the behavior
on the exact same versions of R; it might be due to difference in R
versions.  If you're luck it's a bug that has been fixed and your
problems goes away after updating.

This is why folks on this lists are repeatable requesting that
sessionInfo() output is always reported.  Help helpers help you.

My $.02

/Henrik

On Mon, May 11, 2015 at 8:36 AM, Glenn Schultz <glennmschultz at me.com> wrote:
> Hi Thierry,
>
> Below is the function
> setMethod("initialize",
>          signature("TermStructure"),
>          function(.Object,...,
>                   tradedate = "character",
>                   period = "numeric",
>                   date = "character",
>                   spotrate = "numeric",
>                   forwardrate = "numeric",
>                   TwoYearFwd = "numeric",
>                   TenYearFwd = "numeric")
>          {
>            .Object at tradedate = tradedate
>            .Object at period = period
>            .Object at date = date
>            .Object at spotrate = spotrate
>            .Object at forwardrate = forwardrate
>            .Object at TwoYearFwd = TwoYearFwd
>            .Object at TenYearFwd = TenYearFwd
>                       return(.Object)
>            callNextMethod(.Object,...)
>          })
> #' The TermStructure constructor function it is a wrapper function around
> the package termstrc
> #' #' This is a wrapper function around the R package termstrc.  The
> function passes swap rate data
> #' cash flows the to termstrc and creates the TermStructure object used by
> Bondlab.
> #' The function call rates data processes the yield curve and derives
> cashflow
> #' for the daily close swap curve. A Rates object must be called in the
> local
> #' environment for this function to work.
> #' @param rates.data A character string representing the data for which the
> user
> #' would like to call the swap curve
> #' @param method A character string indicating the fitting method ns =
> Nelson Siegel, dl = Diebold Lee,
> #' sv = Severson, asv = adjusted Severson, cs = cubic spline (not yet
> implemented in Bond Lab).
> #' For addiition details see the termstrc documentation.
> #' @examples
> #' \dontrun{
> #' TermStructure(rates.data = "01-10-2013", method = "ns")}
> #' @importFrom lubridate %m+%
> #' @importFrom lubridate years
> #' @importFrom lubridate day
> #' @importFrom lubridate month
> #' @importFrom termstrc estim_nss estim_cs spotrates forwardrates
> #'@export TermStructure
>  TermStructure <- function(rates.data = "character", method = "character"){
>   #function(trade.date = "character", method = "character")   #Error Trap
> User inputs to the function
>  if(missing(rates.data)) stop("missing rates data object")    # this is the
> code snippet that works in MAC but not windows
>  #Default to Nelson-Siegel
>  if(missing(method)) method = "ns"
>   #Default to parametric
>  if(method == "cs") stop("cubic spline not implemented")
>   #Check that the user input a valid method
>  CheckMethod <- c("ns", "dl", "sv", "asv", "cs")
>  if(!method %in% CheckMethod) stop ("Invalid 'method' Value")
>   # pass the yield curve to the function
>  rates.data <- rates.data
>   #set the column counter to make cashflows for termstrucutre
>  ColCount <- as.numeric(ncol(rates.data))
>  Mat.Years <- as.numeric(rates.data[2,2:ColCount])
>  Coupon.Rate <- as.numeric(rates.data[1,2:ColCount])
>  Issue.Date <- as.Date(rates.data[1,1])
>   #initialize coupon bonds S3 class
>  #This can be upgraded when bondlab has portfolio function
>  ISIN <- vector()
>  MATURITYDATE <- vector()
>  ISSUEDATE <- vector()
>  COUPONRATE <- vector()
>  PRICE <- vector()
>  ACCRUED <- vector()
>  CFISIN <- vector()
>  CF <- vector()
>  DATE <- vector()
>  CASHFLOWS  <- list(CFISIN,CF,DATE)
>  names(CASHFLOWS) <- c("ISIN","CF","DATE")
>  TODAY <- vector()
>  data <- list()
>  TSInput <- list()
>   ### Assign Values to List Items #########
>  data = NULL
>  data$ISIN <- colnames(rates.data[2:ColCount])
>  data$ISSUEDATE <- rep(as.Date(rates.data[1,1]),ColCount - 1)
>   data$MATURITYDATE <-
>    sapply(Mat.Years, function(Mat.Years = Mat.Years, Issue = Issue.Date)
> {Maturity = if(Mat.Years < 1) {Issue %m+% months(round(Mat.Years *
> months.in.year))} else    {Issue %m+% years(as.numeric(Mat.Years))}
>    return(as.character(Maturity))
>    })   data$COUPONRATE <- ifelse(Mat.Years < 1, 0, Coupon.Rate)
> data$PRICE <-      ifelse(Mat.Years < 1, (1 + (Coupon.Rate/100))^(Mat.Years
> * -1) * 100, 100)
>   data$ACCRUED <- rep(0, ColCount -1)
>   for(j in 1:(ColCount-1)){
>    Vector.Length <- as.numeric(round(difftime(data[[3]][j],
>                                               data[[2]][j],
>                                               units =
> c("weeks"))/weeks.in.year,0))
>    Vector.Length <- ifelse(Vector.Length < 1, 1, Vector.Length *
> pmt.frequency)     #pmt.frequency should be input       data$CASHFLOWS$ISIN
> <- append(data$CASHFLOWS$ISIN, rep(data[[1]][j],Vector.Length))
>       data$CASHFLOWS$CF <- append(data$CASHFLOWS$CF,
>              as.numeric(c(rep((data[[4]][j]/100/pmt.frequency),
> Vector.Length-1) * min.principal,              (min.principal +
> (data$COUPONRATE[j]/100/pmt.frequency)* min.principal))))
>       by.months = ifelse(data[[4]][j] == 0, round(difftime(data[[3]][j],
> rates.data[1,1])/days.in.month), 6)    # this sets the month increment so
> that cashflows can handle discount bills
>       data$CASHFLOWS$DATE <- append(data$CASHFLOW$DATE,
>                          seq(as.Date(rates.data[1,1]) %m+%
> months(as.numeric(by.months)),
> as.Date(data[[3]][j]), by = as.character(paste(by.months, "months", sep = "
> "))))
>     } #The Loop Ends here and the list is made
>   data$TODAY <- as.Date(rates.data[1,1])
>  TSInput[[as.character(rates.data[1,1])]] <- c(data)
>   #set term strucuture input (TSInput) to class couponbonds
>  class(TSInput) <- "couponbonds"
>   #Fit the term structure of interest rates
>   if(method != "cs") {TSFit <- estim_nss(dataset = TSInput,
> group = as.character(rates.data[1,1]),
> matrange = "all", method = method)} else
>  {TSFit <- estim_cs(bonddata = TSInput,                     group =
> as.character(rates.data[1,1]),                     matrange = "all", rse =
> TRUE)}
>   #Return the coefficient vector to be passed in to the spot and forward
> rate functions
>  #Maybe have the method choosen based on the one that gives the smallest
> RMSE
>  Vector <- switch(method,
>                   ns = unname(TSFit$opt_result[[1]]$par[c("beta0", "beta1",
> "beta2", "tau1")]),
>                   dl = unname(TSFit$opt_result[[1]]$par[c("beta0", "beta1",
> "beta2")]),
>                   sv = unname(TSFit$opt_result[[1]]$par[c("beta0", "beta1",
> "beta2", "tau1", "beta3", "tau2")]),
>                   asv = unname(TSFit$opt_result[[1]]$par[c("beta0", "beta1",
> "beta2", "tau1", "tau2", "tau3")]),
>                   #cs = need to figure this out
>  )
>   #Calculate the spot rate curve and determine the forward rates needed to
> period <- seq(from = 1, to = 492, by = 1)
>  #Use the date from the cashflow file
>  date <- seq(as.Date(rates.data[1,1]) %m+% months(1), as.Date(data[[3]][j]),
> by="1 months")
>   spot.rate.curve <- spotrates(method = method, beta = Vector, m = seq(from
> = 1/12, to = 492/12, by = 1/12))
>   forward.rate.curve <- forwardrates(method = method, beta = Vector, m =
> seq(from = 1/12, to = 492/12, by = 1/12))
>   Two.Year.Fwd <- (((1 + spot.rate.curve[seq(from = 25, to = 385, by = 1)])
> ^                      (period[seq(from = 25, to = 385, by = 1)]/12) /
>                      (1 + spot.rate.curve[seq(from = 1, to = 361, by = 1)])
> ^                      (period[seq(from = 1, to = 361, by =
> 1)]/12))^(1/2))-1
>   Ten.Year.Fwd <- (((1 + spot.rate.curve[seq(from = 121, to = 481, by = 1)])
> ^                      (period[seq(from = 121, to = 481, by = 1)]/12) /
>                      (1 + spot.rate.curve[seq(from = 1, to = 361, by = 1)])
> ^                      (period[seq(from = 1, to = 361, by =
> 1)]/12))^(1/10))-1
>   new("TermStructure",
>      tradedate = as.character(rates.data[1,1]),
>      period = as.numeric(period),
>      date = as.character(date),
>      spotrate = spot.rate.curve,
>      forwardrate = forward.rate.curve,
>      TwoYearFwd = Two.Year.Fwd,
>      TenYearFwd = Ten.Year.Fwd
>  )
> }
>
> setGeneric("TermStructure",
>           function(rates.data = "character", method = "character")
>           {standardGeneric("TermStructure")})
>
>
> On May 11, 2015, at 01:54 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> Dear Glenn,
>
> We need more details on the function. Please provide a commented, minimal,
> self-contained version of the function that reproduces the problem (as the
> posting guide asks you to do).
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more than
> asking him to perform a post-mortem examination: he may be able to say what
> the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner The combination of some
> data and an aching desire for an answer does not ensure that a reasonable
> answer can be extracted from a given body of data. ~ John Tukey
>
> 2015-05-11 3:03 GMT+02:00 Glenn Schultz <glennmschultz at me.com>:
> Hello All,
>
> Testing my code on a Windows based machine today.  There seems to be an
> offending line of code.  I have pasted it below.  Basically, I check to see
> if the user passed a fit method to TermStructure and if not then default to
> "ns".
>
> The above works fine on my Mac but a windows build errors no method.  I have
> to pass a method = "ns" in the function.  If I pass the value for method to
> the function it will run with no error.  Any thoughts are appreciated.
>
> Best Regards,
> Glenn
>
>   #Default method for TermStructure
>   if(missing(method)) method = "ns"
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From newrnewbie at hotmail.com  Mon May 11 22:16:40 2015
From: newrnewbie at hotmail.com (Vin Cheng)
Date: Mon, 11 May 2015 20:16:40 +0000
Subject: [R] binding two lists of lists of dataframes together
Message-ID: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>

 Hi, 
I'm new to R and am stumped.  I'm trying to bind List 1 to List 2 and have the corresponding Output.  
 
I've found the following code - I can't say I understand rbindlist(lapply(list12, "[", i, TRUE)).  Either way - it doesn't give exactly what's needed.
 
library(data.table)
list12 <- list(List1,List2)
nr <- as.vector(nrow(list12[[1]]))
fastbind.ith.rows <- function(i) rbindlist(lapply(list12, "[", i, TRUE))
fastbound <- lapply(1:nr, fastbind.ith.rows)
 
It produces Output 2 - where dataframes are grouped together by rownames, but keeps 2 separate vectors - vs. binding the two into 1 vector.
 
Any help/guidance would be greatly appreciated!!
 
Thanks!
Vince
 
 
List1List2Output (Wanted) V1V2V3 V1V2V3 V1V2V3idc(563,623,581)c(563,623,581)c(563,623,581)idc(217,  120, 372)c(125,  334, 86)c(130,  349, 576)idc(563,623,581,217,  120, 372)c(563,623,581,125,  334, 86)c(563,623,581,130,  349, 576)wgtbandc(0,  0, 0, 0, 0)c(0,  0, 0, 0, 0)c(0,  0, 0, 0, 0)wgtbandc(1,  2, 3)c(1,  2, 3)c(1,  2, 3)wgtbandc(0,  0, 0, 0, 0,1, 2, 3)c(0,  0, 0, 0, 0,1, 2, 3)c(0,  0, 0, 0, 0,1, 2, 3)wgtc(0.007956164,  0.00199414, 0.009970699, 0.00994571, 0.011994826)c(0.007956164,  0.00199414, 0.009970699, 0.00994571, 0.011994826)c(0.007956164,  0.00199414, 0.009970699, 0.00994571, 0.011994826)wgtc(0.003565190625,  0.003565190625, 0.003565190625)c(0.003565190625,  0.00514971979166667, 0.003565190625)c(0.003565190625,  0.003565190625, 0.00514971979166667)wgtc(0.007956164,  0.00199414, 0.009970699, 0.00994571, 0.011994826,0.003565190625,  0.003565190625, 0.003565190625)c(0.007956164,  0.00199414, 0.009970699, 0.00994571, 0.011994826,0.003565190625,  0.00514971979166667, 0.003565190625)c(0.007956164,  0.00199414, 0.009970699, 0.00994571, 0.011994826,0.003565190625,  0.003565190625, 0.00514971979166667)heldc(2,  2, 2, 2, 2)c(2,  2, 2, 2, 2)c(2,  2, 2, 2, 2)heldc(0,  0, 0)c(0,  0, 0)c(0,  0, 0)heldc(2,  2, 2, 2, 2,0, 0, 0)c(2,  2, 2, 2, 2,0, 0, 0)c(2,  2, 2, 2, 2,0, 0, 0)efficiencyc(765,  1660, 1539, 1377, 1452)c(765,  1660, 1539, 1377, 1452)c(765,  1660, 1539, 1377, 1452)efficiencyc(1292,  908, 1283)c(1292,  908, 1283)c(1292,  908, 1283)efficiencyc(765,  1660, 1539, 1377, 1452,1292, 908, 1283)c(765,  1660, 1539, 1377, 1452,1292, 908, 1283)c(765,  1660, 1539, 1377, 1452,1292, 908, 1283)couponc(4,  11, 16, 27, 48)c(4,  11, 16, 27, 48)c(4,  11, 16, 27, 48)couponc(735,  403, 1366)c(414,  1183, 284)c(435,  1222, 127)couponc(4,  11, 16, 27, 48,735, 403, 1366)c(4,  11, 16, 27, 48,414, 1183, 284)c(4,  11, 16, 27, 48,435, 1222, 127) 
Output2 from Sample Code V1V2V3idc(563,623,581)c(563,623,581)c(563,623,581)c(217, 120, 372)c(125,  334, 86)c(130,  349, 576)wgtbandc(0,  0, 0, 0, 0)c(0,  0, 0, 0, 0)c(0,  0, 0, 0, 0)c(1, 2, 3)c(1,  2, 3)c(1,  2, 3)wgtc(0.007956164,  0.00199414, 0.009970699, 0.00994571, 0.011994826)c(0.007956164,  0.00199414, 0.009970699, 0.00994571, 0.011994826)c(0.007956164,  0.00199414, 0.009970699, 0.00994571, 0.011994826)c(0.003565190625, 0.003565190625,  0.003565190625)c(0.003565190625,  0.00514971979166667, 0.003565190625)c(0.003565190625,  0.003565190625, 0.00514971979166667)heldc(2,  2, 2, 2, 2)c(2,  2, 2, 2, 2)c(2,  2, 2, 2, 2)c(0, 0, 0)c(0,  0, 0)c(0,  0, 0)efficiencyc(765,  1660, 1539, 1377, 1452)c(765,  1660, 1539, 1377, 1452)c(765,  1660, 1539, 1377, 1452)c(1292, 908, 1283)c(1292,  908, 1283)c(1292,  908, 1283)couponc(4,  11, 16, 27, 48)c(4,  11, 16, 27, 48)c(4,  11, 16, 27, 48)c(735, 403, 1366)c(414,  1183, 284)c(435,  1222, 127) 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 		 	   		  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue May 12 00:08:54 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 11 May 2015 15:08:54 -0700
Subject: [R] [SPAM?] binding two lists of lists of dataframes together
In-Reply-To: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>
References: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>
Message-ID: <F5D9E087-DB0D-4A3F-9E7E-65C0F3CEFD5D@dcn.davis.CA.us>

HTML email does not work at all well on this mailing list. Sending you your question in plain text will help, as will following the advice in [1] to use the dput function to format the data so that we can easily put it into R and know what you are working with.

My guess at your goal is that you are trying to make one long list out of two short ones. Why not just use the c() function to concatenate the lists? E.g.

List12 <- c( List1, List2 )

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 11, 2015 1:16:40 PM PDT, Vin Cheng <newrnewbie at hotmail.com> wrote:
> Hi, 
>I'm new to R and am stumped.  I'm trying to bind List 1 to List 2 and
>have the corresponding Output.  
> 
>I've found the following code - I can't say I understand
>rbindlist(lapply(list12, "[", i, TRUE)).  Either way - it doesn't give
>exactly what's needed.
> 
>library(data.table)
>list12 <- list(List1,List2)
>nr <- as.vector(nrow(list12[[1]]))
>fastbind.ith.rows <- function(i) rbindlist(lapply(list12, "[", i,
>TRUE))
>fastbound <- lapply(1:nr, fastbind.ith.rows)
> 
>It produces Output 2 - where dataframes are grouped together by
>rownames, but keeps 2 separate vectors - vs. binding the two into 1
>vector.
> 
>Any help/guidance would be greatly appreciated!!
> 
>Thanks!
>Vince
> 
> 
>List1List2Output (Wanted) V1V2V3 V1V2V3
>V1V2V3idc(563,623,581)c(563,623,581)c(563,623,581)idc(217,  120,
>372)c(125,  334, 86)c(130,  349, 576)idc(563,623,581,217,  120,
>372)c(563,623,581,125,  334, 86)c(563,623,581,130,  349,
>576)wgtbandc(0,  0, 0, 0, 0)c(0,  0, 0, 0, 0)c(0,  0, 0, 0,
>0)wgtbandc(1,  2, 3)c(1,  2, 3)c(1,  2, 3)wgtbandc(0,  0, 0, 0, 0,1, 2,
>3)c(0,  0, 0, 0, 0,1, 2, 3)c(0,  0, 0, 0, 0,1, 2, 3)wgtc(0.007956164, 
>0.00199414, 0.009970699, 0.00994571, 0.011994826)c(0.007956164, 
>0.00199414, 0.009970699, 0.00994571, 0.011994826)c(0.007956164, 
>0.00199414, 0.009970699, 0.00994571, 0.011994826)wgtc(0.003565190625, 
>0.003565190625, 0.003565190625)c(0.003565190625,  0.00514971979166667,
>0.003565190625)c(0.003565190625,  0.003565190625,
>0.00514971979166667)wgtc(0.007956164,  0.00199414, 0.009970699,
>0.00994571, 0.011994826,0.003565190625,  0.003565190625,
>0.003565190625)c(0.007956164,  0.00199414, 0.009970699, 0.00994571,
>0.011994826,0.003565190625,  0.00514971979166667,!
> 
> 
>0.003565190625)c(0.007956164,  0.00199414, 0.009970699, 0.00994571,
>0.011994826,0.003565190625,  0.003565190625,
>0.00514971979166667)heldc(2,  2, 2, 2, 2)c(2,  2, 2, 2, 2)c(2,  2, 2,
>2, 2)heldc(0,  0, 0)c(0,  0, 0)c(0,  0, 0)heldc(2,  2, 2, 2, 2,0, 0,
>0)c(2,  2, 2, 2, 2,0, 0, 0)c(2,  2, 2, 2, 2,0, 0, 0)efficiencyc(765, 
>1660, 1539, 1377, 1452)c(765,  1660, 1539, 1377, 1452)c(765,  1660,
>1539, 1377, 1452)efficiencyc(1292,  908, 1283)c(1292,  908,
>1283)c(1292,  908, 1283)efficiencyc(765,  1660, 1539, 1377, 1452,1292,
>908, 1283)c(765,  1660, 1539, 1377, 1452,1292, 908, 1283)c(765,  1660,
>1539, 1377, 1452,1292, 908, 1283)couponc(4,  11, 16, 27, 48)c(4,  11,
>16, 27, 48)c(4,  11, 16, 27, 48)couponc(735,  403, 1366)c(414,  1183,
>284)c(435,  1222, 127)couponc(4,  11, 16, 27, 48,735, 403, 1366)c(4, 
>11, 16, 27, 48,414, 1183, 284)c(4,  11, 16, 27, 48,435, 1222, 127) 
>Output2 from Sample Code
>V1V2V3idc(563,623,581)c(563,623,581)c(563,623,581)c(217, 120,
>372)c(125,  334, 86)c(130,  349, 576)wgtbandc(0,  0, 0, 0, 0)c(0,  0,
>0, 0, 0)c(0,  0, 0, 0, 0)c(1, 2, 3)c(1,  2, 3)c(1,  2,
>3)wgtc(0.007956164,  0.00199414, 0.009970699, 0.00994571,
>0.011994826)c(0.007956164,  0.00199414, 0.009970699, 0.00994571,
>0.011994826)c(0.007956164,  0.00199414, 0.009970699, 0.00994571,
>0.011994826)c(0.003565190625, 0.003565190625, 
>0.003565190625)c(0.003565190625,  0.00514971979166667,
>0.003565190625)c(0.003565190625,  0.003565190625,
>0.00514971979166667)heldc(2,  2, 2, 2, 2)c(2,  2, 2, 2, 2)c(2,  2, 2,
>2, 2)c(0, 0, 0)c(0,  0, 0)c(0,  0, 0)efficiencyc(765,  1660, 1539,
>1377, 1452)c(765,  1660, 1539, 1377, 1452)c(765,  1660, 1539, 1377,
>1452)c(1292, 908, 1283)c(1292,  908, 1283)c(1292,  908, 1283)couponc(4,
>11, 16, 27, 48)c(4,  11, 16, 27, 48)c(4,  11, 16, 27, 48)c(735, 403,
>1366)c(414,  1183, 284)c(435,  1222, 127) 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
>
> 		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rshepard at appl-ecosys.com  Tue May 12 03:34:56 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Mon, 11 May 2015 18:34:56 -0700 (PDT)
Subject: [R] Compositional ANOVA With Several Main Effects: Explanation of
 Results
Message-ID: <alpine.LNX.2.11.1505111831180.20271@localhost>

   The results of compositional ANOVA models with several main effects with
conditional data as the response variable produce 'missing not at random'
(MNAR) results for the same rows in the matrix of output coefficients: the
last, third from last, and fourth from last regardless of the number of
years or which years they are. Why might this happen?

   The model is:
model <- lm(ilr(y) ~ x1 + x2 + x3 + x4)
where x1-x3 are continuous variables and x4 is the discrete varible, year.

   The discrete variable treatment is 'contrasts.' Three data sets are shown
with the *.acomp input matrix and the resulting model coefficients.

set1.acomp:
        Fi         Ga        Gr         Pr        Sh
[1,] 0.06666667 0.6000000 0.06666667 0.2444444 0.02222222
[2,] 0.06122449 0.5714286 0.06122449 0.2653061 0.04081633
[3,] 0.04347826 0.6231884 0.10144928 0.2173913 0.01449275
[4,] 0.04395604 0.5934066 0.06593407 0.2637363 0.03296703
[5,] 0.05000000 0.4333333 0.06666667 0.3666667 0.08333333
[6,] 0.01612903 0.6290323 0.03225806 0.2903226 0.03225806

             Fi           Ga          Gr           Pr          Sh 
(Intercept) 3.115405e-08 0.000279552 2.392303e-11 0.005863277 0.9938571397
x1          6.429247e-02 0.082497400 8.310734e-01 0.021442905 0.0006938677
x2          2.045395e-01 0.197642666 2.021531e-01 0.197459631 0.1982051055
x3          1.736206e-01 0.145594990 5.528400e-01 0.092214496 0.0357298993
x42005      6.161150e-02 0.123183957 2.327678e-02 0.201577707 0.5903500624
x42006              MNAR        MNAR         MNAR        MNAR         MNAR
x42011              MNAR        MNAR         MNAR        MNAR         MNAR
x42012      3.201111e-01 0.071005938 2.128531e-01 0.130202854 0.2658270106
x42013              MNAR        MNAR         MNAR        MNAR         MNAR

set2.acomp:
        Fi         Ga        Gr         Pr        Sh
[1,] 0.05555556 0.5370370 0.16666667 0.1666667 0.07407407
[2,] 0.04347826 0.6739130 0.08695652 0.1521739 0.04347826
[3,] 0.07352941 0.4705882 0.10294118 0.1911765 0.16176471
[4,] 0.04615385 0.5692308 0.07692308 0.2461538 0.06153846
[5,] 0.05479452 0.5205479 0.05479452 0.2465753 0.12328767
[6,] 0.04838710 0.5322581 0.11290323 0.2419355 0.06451613

             Fi          Ga           Gr           Pr           Sh 
(Intercept) 0.002229245 0.0002927936 2.472954e-08 1.361426e-06 0.99747658
x1          0.085750068 0.2770618145 3.810668e-01 2.307283e-01 0.02539301
x2          0.200090962 0.1999211671 2.000300e-01 1.997450e-01 0.20021285
x3          0.090936680 0.1567838336 4.104556e-01 2.970892e-01 0.04473467
x42006      0.200939822 0.2871520918 2.299924e-01 1.429443e-01 0.13897135
x42010             MNAR         MNAR         MNAR         MNAR       MNAR
x42011             MNAR         MNAR         MNAR         MNAR       MNAR
x42012      0.204872911 0.1769349420 8.782860e-02 1.844618e-01 0.34590170
x42013             MNAR         MNAR         MNAR         MNAR       MNAR

set3.acomp:
        Fi         Ga        Gr         Pr        Sh
[1,] 0.05504587 0.5596330 0.07339450 0.2293578 0.082568807
[2,] 0.07339450 0.6146789 0.01834862 0.2293578 0.064220183
[3,] 0.11607143 0.5714286 0.03571429 0.1696429 0.107142857
[4,] 0.10000000 0.4666667 0.15000000 0.1333333 0.150000000
[5,] 0.07777778 0.6111111 0.04444444 0.1888889 0.077777778
[6,] 0.08737623 0.5679455 0.06553218 0.2730507 0.006095338
[7,] 0.10416667 0.5312500 0.06250000 0.2395833 0.062500000
[8,] 0.07228916 0.5542169 0.06024096 0.2650602 0.048192771

             Fi           Ga          Gr         Pr         Sh 
(Intercept) 1.943748e-05 0.058972799 0.89399840 0.04700784 1.524493e-06
x1          4.125158e-02 0.009931625 0.17672213 0.23844959 5.336451e-01
x2          2.000709e-01 0.200086918 0.19954822 0.19948468 2.008093e-01
x3          2.946378e-01 0.146757566 0.07664778 0.13091512 3.510417e-01
x42003      2.347775e-01 0.443477400 0.05214527 0.12408231 1.455175e-01
x42005      2.809541e-01 0.233325976 0.15610948 0.15614758 1.734629e-01
x42006      2.149193e-01 0.031546594 0.07066295 0.03831916 6.445520e-01
x42010              MNAR        MNAR       MNAR       MNAR         MNAR
x42011              MNAR        MNAR       MNAR       MNAR         MNAR
x42012      2.555987e-01 0.170021002 0.18412502 0.16028998 2.299653e-01
x42013              MNAR        MNAR       MNAR       MNAR         MNAR

   I've not found the explanation in my searches and would appreciate
understanding these results.

Rich


From jrkrideau at inbox.com  Tue May 12 04:19:06 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 11 May 2015 18:19:06 -0800
Subject: [R] binding two lists of lists of dataframes together
In-Reply-To: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>
Message-ID: <A2E1A0300F5.00001107jrkrideau@inbox.com>

 http://adv-r.had.co.nz/Reproducibility.html

and please do not post in Html.


John Kane
Kingston ON Canada


> -----Original Message-----
> From: newrnewbie at hotmail.com
> Sent: Mon, 11 May 2015 20:16:40 +0000
> To: r-help at r-project.org
> Subject: [R] binding two lists of lists of dataframes together
> 
>  Hi,
> I'm new to R and am stumped.  I'm trying to bind List 1 to List 2 and
> have the corresponding Output.
> 
> I've found the following code - I can't say I understand
> rbindlist(lapply(list12, "[", i, TRUE)).  Either way - it doesn't give
> exactly what's needed.
> 
> library(data.table)
> list12 <- list(List1,List2)
> nr <- as.vector(nrow(list12[[1]]))
> fastbind.ith.rows <- function(i) rbindlist(lapply(list12, "[", i, TRUE))
> fastbound <- lapply(1:nr, fastbind.ith.rows)
> 
> It produces Output 2 - where dataframes are grouped together by rownames,
> but keeps 2 separate vectors - vs. binding the two into 1 vector.
> 
> Any help/guidance would be greatly appreciated!!
> 
> Thanks!
> Vince
> 
> 
> List1List2Output (Wanted) V1V2V3 V1V2V3
> V1V2V3idc(563,623,581)c(563,623,581)c(563,623,581)idc(217,  120,
> 372)c(125,  334, 86)c(130,  349, 576)idc(563,623,581,217,  120,
> 372)c(563,623,581,125,  334, 86)c(563,623,581,130,  349, 576)wgtbandc(0,
> 0, 0, 0, 0)c(0,  0, 0, 0, 0)c(0,  0, 0, 0, 0)wgtbandc(1,  2, 3)c(1,  2,
> 3)c(1,  2, 3)wgtbandc(0,  0, 0, 0, 0,1, 2, 3)c(0,  0, 0, 0, 0,1, 2,
> 3)c(0,  0, 0, 0, 0,1, 2, 3)wgtc(0.007956164,  0.00199414, 0.009970699,
> 0.00994571, 0.011994826)c(0.007956164,  0.00199414, 0.009970699,
> 0.00994571, 0.011994826)c(0.007956164,  0.00199414, 0.009970699,
> 0.00994571, 0.011994826)wgtc(0.003565190625,  0.003565190625,
> 0.003565190625)c(0.003565190625,  0.00514971979166667,
> 0.003565190625)c(0.003565190625,  0.003565190625,
> 0.00514971979166667)wgtc(0.007956164,  0.00199414, 0.009970699,
> 0.00994571, 0.011994826,0.003565190625,  0.003565190625,
> 0.003565190625)c(0.007956164,  0.00199414, 0.009970699, 0.00994571,
> 0.011994826,0.003565190625,  0.00514971979166667,!
>   0.003565190625)c(0.007956164,  0.00199414, 0.009970699, 0.00994571,
> 0.011994826,0.003565190625,  0.003565190625, 0.00514971979166667)heldc(2,
> 2, 2, 2, 2)c(2,  2, 2, 2, 2)c(2,  2, 2, 2, 2)heldc(0,  0, 0)c(0,  0,
> 0)c(0,  0, 0)heldc(2,  2, 2, 2, 2,0, 0, 0)c(2,  2, 2, 2, 2,0, 0, 0)c(2,
> 2, 2, 2, 2,0, 0, 0)efficiencyc(765,  1660, 1539, 1377, 1452)c(765,  1660,
> 1539, 1377, 1452)c(765,  1660, 1539, 1377, 1452)efficiencyc(1292,  908,
> 1283)c(1292,  908, 1283)c(1292,  908, 1283)efficiencyc(765,  1660, 1539,
> 1377, 1452,1292, 908, 1283)c(765,  1660, 1539, 1377, 1452,1292, 908,
> 1283)c(765,  1660, 1539, 1377, 1452,1292, 908, 1283)couponc(4,  11, 16,
> 27, 48)c(4,  11, 16, 27, 48)c(4,  11, 16, 27, 48)couponc(735,  403,
> 1366)c(414,  1183, 284)c(435,  1222, 127)couponc(4,  11, 16, 27, 48,735,
> 403, 1366)c(4,  11, 16, 27, 48,414, 1183, 284)c(4,  11, 16, 27, 48,435,
> 1222, 127)
> Output2 from Sample Code
> V1V2V3idc(563,623,581)c(563,623,581)c(563,623,581)c(217, 120, 372)c(125,
> 334, 86)c(130,  349, 576)wgtbandc(0,  0, 0, 0, 0)c(0,  0, 0, 0, 0)c(0,
> 0, 0, 0, 0)c(1, 2, 3)c(1,  2, 3)c(1,  2, 3)wgtc(0.007956164,  0.00199414,
> 0.009970699, 0.00994571, 0.011994826)c(0.007956164,  0.00199414,
> 0.009970699, 0.00994571, 0.011994826)c(0.007956164,  0.00199414,
> 0.009970699, 0.00994571, 0.011994826)c(0.003565190625, 0.003565190625,
> 0.003565190625)c(0.003565190625,  0.00514971979166667,
> 0.003565190625)c(0.003565190625,  0.003565190625,
> 0.00514971979166667)heldc(2,  2, 2, 2, 2)c(2,  2, 2, 2, 2)c(2,  2, 2, 2,
> 2)c(0, 0, 0)c(0,  0, 0)c(0,  0, 0)efficiencyc(765,  1660, 1539, 1377,
> 1452)c(765,  1660, 1539, 1377, 1452)c(765,  1660, 1539, 1377,
> 1452)c(1292, 908, 1283)c(1292,  908, 1283)c(1292,  908, 1283)couponc(4,
> 11, 16, 27, 48)c(4,  11, 16, 27, 48)c(4,  11, 16, 27, 48)c(735, 403,
> 1366)c(414,  1183, 284)c(435,  1222, 127)
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From newrnewbie at hotmail.com  Mon May 11 23:07:02 2015
From: newrnewbie at hotmail.com (Vin Cheng)
Date: Mon, 11 May 2015 21:07:02 +0000
Subject: [R] binding two lists of lists of dataframes together
In-Reply-To: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>
References: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>
Message-ID: <BAY179-W90086E8482C153DBB2409FD3DB0@phx.gbl>


 
> From: newrnewbie at hotmail.com
> To: r-help at r-project.org
> Date: Mon, 11 May 2015 20:16:40 +0000
> Subject: [R] binding two lists of lists of dataframes together
> 
>  Hi, 
> I'm new to R and am stumped.  I'm trying to bind List 1 to List 2 and have the corresponding Output.  
>  
> I've found the following code - I can't say I understand rbindlist(lapply(list12, "[", i, TRUE)).  Either way - it doesn't give exactly what's needed.
>  
> library(data.table)
> list12 <- list(List1,List2)
> nr <- as.vector(nrow(list12[[1]]))
> fastbind.ith.rows <- function(i) rbindlist(lapply(list12, "[", i, TRUE))
> fastbound <- lapply(1:nr, fastbind.ith.rows)
>  
> It produces Output 2 - where dataframes are grouped together by rownames, but keeps 2 separate vectors - vs. binding the two into 1 vector.
>  
> Any help/guidance would be greatly appreciated!!
>  
> Thanks!
> Vince
>  
 		 	   		  
-------------- next part --------------
A non-text attachment was scrubbed...
Name: data.pdf
Type: application/pdf
Size: 55729 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150511/20202f33/attachment.pdf>

From drjimlemon at gmail.com  Tue May 12 02:14:08 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 12 May 2015 10:14:08 +1000
Subject: [R] [SPAM?] binding two lists of lists of dataframes together
In-Reply-To: <F5D9E087-DB0D-4A3F-9E7E-65C0F3CEFD5D@dcn.davis.CA.us>
References: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>
	<F5D9E087-DB0D-4A3F-9E7E-65C0F3CEFD5D@dcn.davis.CA.us>
Message-ID: <CA+8X3fVGnaqcU0SD5k22-F1AKh6TBkts9FXuom23Yhc9sL9bRA@mail.gmail.com>

Hi Vin,
If I read your "Output (Wanted)" section correctly, you want a new
list in which each element is the concatenation of the corresponding
elements of the original two. If so, maybe this shorter example will
help:

list1<-list(id=as.data.frame(matrix(rep(c(563,623,581),3),nrow=3,byrow=TRUE)),
 wgtband=as.data.frame(matrix(0,nrow=3,ncol=3,byrow=TRUE)))
list2<-list(id=as.data.frame(matrix(c(217,120,372,125,334,86,130,349,576),nrow=3,byrow=TRUE)),
 wgtband=as.data.frame(matrix(rep(1:3,each=3),nrow=3)))
list3<-list()
for(i in 1:length(list1)) list3[[i]]<-cbind(list1[[i]],list2[[i]])
names(list3)<-names(list1)
list3

Jim


From shidaxia at yahoo.com  Tue May 12 02:18:42 2015
From: shidaxia at yahoo.com (Shi, Tao)
Date: Tue, 12 May 2015 00:18:42 +0000 (UTC)
Subject: [R] Error in title(...) :  X11 font  ....
Message-ID: <510990150.83012.1431389922536.JavaMail.yahoo@mail.yahoo.com>

Hi list,

Could anybody help me to explain the following error message and fix it?  Thank you very much!

Tao


> sessionInfo() 
R version 3.1.2 (2014-10-31) 
Platform: x86_64-unknown-linux-gnu (64-bit) 

locale: 
[1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C 
[3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8 
[5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8 
[7] LC_PAPER=en_US.UTF-8       LC_NAME=C 
[9] LC_ADDRESS=C               LC_TELEPHONE=C 
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C 

attached base packages: 
[1] stats     graphics  grDevices utils     datasets  methods   base 
> 
> 
> plot(1:10, xlab="haha") 
> plot(1:10, ylab="haha") 
> plot(1:10, main="haha") 
Error in title(...) : 
X11 font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 2 at size 14 could not be loaded


From e.robinson at pnc.com  Tue May 12 03:41:10 2015
From: e.robinson at pnc.com (e.robinson at pnc.com)
Date: Mon, 11 May 2015 21:41:10 -0400
Subject: [R] Fw: Downloading R
Message-ID: <OF772A90EC.2DD355A6-ON85257E43.00091F0C-85257E43.00094300@pnc.com>

>         My name is Erick Robinson and I am a SAS administrator at PNC
> Bank.  I have been tasked with installing R on two of our SAS servers,
> but am having trouble downloading the source.  I have little background
> in UNIX (our servers run On Solaris under Unix) and cannot get to the
> site to download.  I clicked on the link in red and it took me to the
> green arrow without any options to download.  I was going to download to
> Windows and then FTP to the server.  What is the best way to download 
the source to our solaris server?  Thanks

Erick Robinson
Software Engineer Lead 
Retail MIS SAS Support 

PNC Technology and Operations
23000 Mill Creek Blv.
Hignland Hills, Oh  44122
440-342-3100
e.robinson at pnc.com



 
----- Forwarded by Erick Robinson/TPS/CLE/PNC on 05/11/2015 09:39 PM -----

From:   Duncan Murdoch <murdoch.duncan at gmail.com>
To:     e.robinson at pnc.com, R-windows at R-project.org, 
Date:   05/11/2015 02:52 PM
Subject:        Re: Downloading R



On 11/05/2015 2:37 PM, e.robinson at pnc.com wrote:
> Hello,
> 
>         My name is Erick Robinson and I am a SAS administrator at PNC
> Bank.  I have been tasked with installing R on two of our SAS servers,
> but am having trouble downloading the source.  I have little background
> in UNIX (our servers run On Solaris under Unix) and cannot get to the
> site to download.  I clicked on the link in red and it took me to the
> green arrow without any options to download.  I was going to download to
> Windows and then FTP to the server

It is much easier to install from a tarball, not from the Subversion
repository.  But more importantly, you're writing to the wrong place.
If my hint is not sufficient, please write to R-help, not to R-windows.
 This is the development list for the Windows version, not a general
support list.

Duncan Murdoch

> 
> 
> 
> 
> 
> 
> 
> Erick Robinson
> Software Engineer Lead
> Retail MIS SAS Support 
> 
> *PNC Technology and Operations*
> 23000 Mill Creek Blv.
> Hignland Hills, Oh  44122
> 440-342-3100
> e.robinson at pnc.com
> 
> 
> 
> 
> 
> The contents of this email are the property of PNC. If it was not
> addressed to you, you have no legal right to read it. If you think you
> received it in error, please notify the sender. Do not forward or copy
> without permission of the sender. This message may be considered a
> commercial electronic message under Canadian law or this message may
> contain an advertisement of a product or service and thus may constitute
> a commercial electronic mail message under US law. You may unsubscribe
> at any time from receiving commercial electronic messages from PNC at
> http://pages.e.pnc.com/globalunsub/
> PNC, 249 Fifth Avenue, Pittsburgh, PA 15222; pnc.com
> 



The contents of this email are the property of PNC. If it was not addressed to you, you have no legal right to read it. If you think you received it in error, please notify the sender. Do not forward or copy without permission of the sender. This message may be considered a commercial electronic message under Canadian law or this message may contain an advertisement of a product or service and thus may constitute a commercial electronic mail message under US law. You may unsubscribe at any time from receiving commercial electronic messages from PNC at http://pages.e.pnc.com/globalunsub/
PNC, 249 Fifth Avenue, Pittsburgh, PA 15222; pnc.com



	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue May 12 09:22:32 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 12 May 2015 09:22:32 +0200
Subject: [R] Downloading R
In-Reply-To: <OF772A90EC.2DD355A6-ON85257E43.00091F0C-85257E43.00094300@pnc.com>
References: <OF772A90EC.2DD355A6-ON85257E43.00091F0C-85257E43.00094300@pnc.com>
Message-ID: <FC8C208F-555F-4D65-80C9-3065B77A3A6D@gmail.com>

Downloading should be the easy bit. Just go to cran.r-project.org (or a mirror) and take the first link under "source code for all platforms".

However, you do need to study the "R Installation and Administration" manual, especially the platform notes. Solaris is a bit outside the mainstream these days, and it may take some elbow grease to get the compilers, libraries, and accessories all lined up properly.

A couple of people on this list and on the r-devel list use Solaris, and may be able to help, but you need to learn how to provide proper context for your questions. It is not informative that you have clicked a red link leading to a green arrow! 

-Peter D.

> On 12 May 2015, at 03:41 , e.robinson at pnc.com wrote:
> 
>>        My name is Erick Robinson and I am a SAS administrator at PNC
>> Bank.  I have been tasked with installing R on two of our SAS servers,
>> but am having trouble downloading the source.  I have little background
>> in UNIX (our servers run On Solaris under Unix) and cannot get to the
>> site to download.  I clicked on the link in red and it took me to the
>> green arrow without any options to download.  I was going to download to
>> Windows and then FTP to the server.  What is the best way to download 
> the source to our solaris server?  Thanks
> 
> Erick Robinson
> Software Engineer Lead 
> Retail MIS SAS Support 
> 
> PNC Technology and Operations
> 23000 Mill Creek Blv.
> Hignland Hills, Oh  44122
> 440-342-3100
> e.robinson at pnc.com
> 
> 
> 
> 
> ----- Forwarded by Erick Robinson/TPS/CLE/PNC on 05/11/2015 09:39 PM -----
> 
> From:   Duncan Murdoch <murdoch.duncan at gmail.com>
> To:     e.robinson at pnc.com, R-windows at R-project.org, 
> Date:   05/11/2015 02:52 PM
> Subject:        Re: Downloading R
> 
> 
> 
> On 11/05/2015 2:37 PM, e.robinson at pnc.com wrote:
>> Hello,
>> 
>>        My name is Erick Robinson and I am a SAS administrator at PNC
>> Bank.  I have been tasked with installing R on two of our SAS servers,
>> but am having trouble downloading the source.  I have little background
>> in UNIX (our servers run On Solaris under Unix) and cannot get to the
>> site to download.  I clicked on the link in red and it took me to the
>> green arrow without any options to download.  I was going to download to
>> Windows and then FTP to the server
> 
> It is much easier to install from a tarball, not from the Subversion
> repository.  But more importantly, you're writing to the wrong place.
> If my hint is not sufficient, please write to R-help, not to R-windows.
> This is the development list for the Windows version, not a general
> support list.
> 
> Duncan Murdoch
> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> Erick Robinson
>> Software Engineer Lead
>> Retail MIS SAS Support 
>> 
>> *PNC Technology and Operations*
>> 23000 Mill Creek Blv.
>> Hignland Hills, Oh  44122
>> 440-342-3100
>> e.robinson at pnc.com
>> 
>> 
>> 
>> 
>> 
>> The contents of this email are the property of PNC. If it was not
>> addressed to you, you have no legal right to read it. If you think you
>> received it in error, please notify the sender. Do not forward or copy
>> without permission of the sender. This message may be considered a
>> commercial electronic message under Canadian law or this message may
>> contain an advertisement of a product or service and thus may constitute
>> a commercial electronic mail message under US law. You may unsubscribe
>> at any time from receiving commercial electronic messages from PNC at
>> http://pages.e.pnc.com/globalunsub/
>> PNC, 249 Fifth Avenue, Pittsburgh, PA 15222; pnc.com
>> 
> 
> 
> 
> The contents of this email are the property of PNC. If it was not addressed to you, you have no legal right to read it. If you think you received it in error, please notify the sender. Do not forward or copy without permission of the sender. This message may be considered a commercial electronic message under Canadian law or this message may contain an advertisement of a product or service and thus may constitute a commercial electronic mail message under US law. You may unsubscribe at any time from receiving commercial electronic messages from PNC at http://pages.e.pnc.com/globalunsub/
> PNC, 249 Fifth Avenue, Pittsburgh, PA 15222; pnc.com
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From thierry.onkelinx at inbo.be  Tue May 12 09:40:00 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 12 May 2015 09:40:00 +0200
Subject: [R] Code works on Mac but not Windows
In-Reply-To: <eab3ceb9-11e6-42cb-bf6f-6091e5afdc8c@me.com>
References: <eab3ceb9-11e6-42cb-bf6f-6091e5afdc8c@me.com>
Message-ID: <CAJuCY5zjtVb+oG8Oez=SLkT=j7xNmqiH_OJ=6FDs4i9cQX3RkA@mail.gmail.com>

Dear Glenn,

I think that you are confusing the signature of a method and the default
values of of function. It looks like you want the signature(rates.data =
"character", method = "character"). But you are setting "character" as
default value of both function arguments. Since you define a default value
for methods, it will not be missing when you omit is from the call.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-11 17:36 GMT+02:00 Glenn Schultz <glennmschultz at me.com>:

> Hi Thierry,
>
> Below is the function
> setMethod("initialize", signature("TermStructure"), function(.Object,...,
> tradedate = "character", period = "numeric", date = "character", spotrate
> = "numeric", forwardrate = "numeric", TwoYearFwd = "numeric", TenYearFwd =
> "numeric") { .Object at tradedate = tradedate .Object at period = period .Object
> @date = date .Object at spotrate = spotrate .Object at forwardrate = forwardrate
> .Object at TwoYearFwd = TwoYearFwd .Object at TenYearFwd = TenYearFwd return(.
> Object) callNextMethod(.Object,...) })#' The TermStructure constructor
> function it is a wrapper function around the package termstrc#' #' This
> is a wrapper function around the R package termstrc. The function passes
> swap rate data#' cash flows the to termstrc and creates the TermStructure
> object used by Bondlab.#' The function call rates data processes the
> yield curve and derives cashflow#' for the daily close swap curve. A
> Rates object must be called in the local#' environment for this function
> to work.#' @param rates.data A character string representing the data for
> which the user#' would like to call the swap curve#' @param method A
> character string indicating the fitting method ns = Nelson Siegel, dl =
> Diebold Lee,#' sv = Severson, asv = adjusted Severson, cs = cubic spline
> (not yet implemented in Bond Lab).#' For addiition details see the
> termstrc documentation.#' @examples#' \dontrun{#'
> TermStructure(rates.data = "01-10-2013", method = "ns")}#' @importFrom
> lubridate %m+%#' @importFrom lubridate years#' @importFrom lubridate day#'
> @importFrom lubridate month#' @importFrom termstrc estim_nss estim_cs
> spotrates forwardrates#'@export TermStructure TermStructure <- function(
> rates.data = "character", method = "character"){ #function(trade.date =
> "character", method = "character") #Error Trap User inputs to the function
> if(missing(rates.data)) stop("missing rates data object") # this is the
> code snippet that works in MAC but not windows *#Default to Nelson-Siegel**
> if(missing(method)) method = "ns"* #Default to parametric if(method == "cs
> ") stop("cubic spline not implemented") #Check that the user input a
> valid method CheckMethod <- c("ns", "dl", "sv", "asv", "cs") if(!method
> %in% CheckMethod) stop ("Invalid 'method' Value") # pass the yield curve
> to the function rates.data <- rates.data #set the column counter to make
> cashflows for termstrucutre ColCount <- as.numeric(ncol(rates.data))
> Mat.Years <- as.numeric(rates.data[2,2:ColCount]) Coupon.Rate <-
> as.numeric(rates.data[1,2:ColCount]) Issue.Date <- as.Date(rates.data[1,1
> ]) #initialize coupon bonds S3 class #This can be upgraded when bondlab
> has portfolio function ISIN <- vector() MATURITYDATE <- vector() ISSUEDATE
> <- vector() COUPONRATE <- vector() PRICE <- vector() ACCRUED <- vector()
> CFISIN <- vector() CF <- vector() DATE <- vector() CASHFLOWS <- list(
> CFISIN,CF,DATE) names(CASHFLOWS) <- c("ISIN","CF","DATE") TODAY <-
> vector() data <- list() TSInput <- list() ### Assign Values to List Items
> ######### data = NULL data$ISIN <- colnames(rates.data[2:ColCount]) data$
> ISSUEDATE <- rep(as.Date(rates.data[1,1]),ColCount - 1) data$MATURITYDATE
> <- sapply(Mat.Years, function(Mat.Years = Mat.Years, Issue = Issue.Date) {
> Maturity = if(Mat.Years < 1) {Issue %m+% months(round(Mat.Years *
> months.in.year))} else {Issue %m+% years(as.numeric(Mat.Years))} return
> (as.character(Maturity)) })  data$COUPONRATE <- ifelse(Mat.Years < 1, 0,
> Coupon.Rate)  data$PRICE <- ifelse(Mat.Years < 1, (1 + (Coupon.Rate/100))^
> (Mat.Years * -1) * 100, 100) data$ACCRUED <- rep(0, ColCount -1) for(j in
> 1:(ColCount-1)){ Vector.Length <- as.numeric(round(difftime(data[[3]][j],
> data[[2]][j], units = c("weeks"))/weeks.in.year,0)) Vector.Length <-
> ifelse(Vector.Length < 1, 1, Vector.Length * pmt.frequency) #pmt.frequency
> should be input  data$CASHFLOWS$ISIN <- append(data$CASHFLOWS$ISIN, rep(
> data[[1]][j],Vector.Length)) data$CASHFLOWS$CF <- append(data$CASHFLOWS$CF
> , as.numeric(c(rep((data[[4]][j]/100/pmt.frequency), Vector.Length-1) *
> min.principal, (min.principal + (data$COUPONRATE[j]/100/pmt.frequency)*
> min.principal)))) by.months = ifelse(data[[4]][j] == 0, round(difftime(
> data[[3]][j], rates.data[1,1])/days.in.month), 6) # this sets the month
> increment so that cashflows can handle discount bills data$CASHFLOWS$DATE
> <- append(data$CASHFLOW$DATE, seq(as.Date(rates.data[1,1]) %m+%
> months(as.numeric(by.months)), as.Date(data[[3]][j]), by =
> as.character(paste(by.months, "months", sep = " ")))) } #The Loop Ends
> here and the list is made data$TODAY <- as.Date(rates.data[1,1]) TSInput
> [[as.character(rates.data[1,1])]] <- c(data) #set term strucuture input
> (TSInput) to class couponbonds class(TSInput) <- "couponbonds" #Fit the
> term structure of interest rates if(method != "cs") {TSFit <- estim_nss(
> dataset = TSInput, group = as.character(rates.data[1,1]), matrange = "all",
> method = method)} else {TSFit <- estim_cs(bonddata = TSInput, group =
> as.character(rates.data[1,1]), matrange = "all", rse = TRUE)} #Return the
> coefficient vector to be passed in to the spot and forward rate functions #Maybe
> have the method choosen based on the one that gives the smallest RMSE
> Vector <- switch(method, ns = unname(TSFit$opt_result[[1]]$par[c("beta0",
> "beta1", "beta2", "tau1")]), dl = unname(TSFit$opt_result[[1]]$par[c("
> beta0", "beta1", "beta2")]), sv = unname(TSFit$opt_result[[1]]$par[c("
> beta0", "beta1", "beta2", "tau1", "beta3", "tau2")]), asv = unname(TSFit$
> opt_result[[1]]$par[c("beta0", "beta1", "beta2", "tau1", "tau2", "tau3"
> )]), #cs = need to figure this out ) #Calculate the spot rate curve and
> determine the forward rates needed to period <- seq(from = 1, to = 492, by
> = 1) #Use the date from the cashflow file date <- seq(as.Date(rates.data[1
> ,1]) %m+% months(1), as.Date(data[[3]][j]), by="1 months") spot.rate.curve
> <- spotrates(method = method, beta = Vector, m = seq(from = 1/12, to = 492
> /12, by = 1/12)) forward.rate.curve <- forwardrates(method = method, beta
> = Vector, m = seq(from = 1/12, to = 492/12, by = 1/12)) Two.Year.Fwd <-
> (((1 + spot.rate.curve[seq(from = 25, to = 385, by = 1)]) ^ (period[seq(
> from = 25, to = 385, by = 1)]/12) / (1 + spot.rate.curve[seq(from = 1, to
> = 361, by = 1)]) ^ (period[seq(from = 1, to = 361, by = 1)]/12))^(1/2))-1
> Ten.Year.Fwd <- (((1 + spot.rate.curve[seq(from = 121, to = 481, by = 1)])
> ^ (period[seq(from = 121, to = 481, by = 1)]/12) / (1 + spot.rate.curve
> [seq(from = 1, to = 361, by = 1)]) ^ (period[seq(from = 1, to = 361, by =
> 1)]/12))^(1/10))-1 new("TermStructure", tradedate = as.character(
> rates.data[1,1]), period = as.numeric(period), date = as.character(date),
> spotrate = spot.rate.curve, forwardrate = forward.rate.curve, TwoYearFwd =
> Two.Year.Fwd, TenYearFwd = Ten.Year.Fwd )}  setGeneric("TermStructure",
> function(rates.data = "character", method = "character") {standardGeneric(
> "TermStructure")})
>
> On May 11, 2015, at 01:54 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> Dear Glenn,
>
> We need more details on the function. Please provide a commented, minimal,
> self-contained version of the function that reproduces the problem (as the
> posting guide asks you to do).
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-05-11 3:03 GMT+02:00 Glenn Schultz <glennmschultz at me.com>:
>
>> Hello All,
>>
>> Testing my code on a Windows based machine today.  There seems to be an
>> offending line of code.  I have pasted it below.  Basically, I check to see
>> if the user passed a fit method to TermStructure and if not then default to
>> "ns".
>>
>> The above works fine on my Mac but a windows build errors no method.  I
>> have to pass a method = "ns" in the function.  If I pass the value for
>> method to the function it will run with no error.  Any thoughts are
>> appreciated.
>>
>> Best Regards,
>> Glenn
>>
>>   #Default method for TermStructure
>>   if(missing(method)) method = "ns"
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jari.oksanen at oulu.fi  Tue May 12 10:10:33 2015
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Tue, 12 May 2015 08:10:33 +0000
Subject: [R] species names on a RDA plot
References: <CAE8g1gOYfpjTE_0WYHbYxK5Nw2Cm85oUTow6O8JAkjVsSFCutA@mail.gmail.com>
	<CAE8g1gPjfGvF42b5j38uE_AWU270NGBFyEV7iPpAd_NGawmVVQ@mail.gmail.com>
	<CA+8X3fUCzdfBZk_-1i5n8GP-YX372hbGG1z5_4bFJ-TK_o98cw@mail.gmail.com>
	<CAE8g1gP0Zy+eowrMWdVik4JCEo1umh4yz80bX_Y7QRhHE-RL4w@mail.gmail.com>
Message-ID: <loom.20150512T100822-693@post.gmane.org>

Antonio Silva <aolinto.lst <at> gmail.com> writes:

> 
> Thanks for your attention Jim
> 
> Following your idea of adding one more step to construct the diagram, I used
> 
> text(spe2.rdaspe, row.names(spe2.rdaspe), pos=3, col="red",cex=0.8)
> 
> and I could add species names.
> 
> It seems that there's nothing we can do in the plot line.
> 
> Have a nice week, best regards
> 

I haven't followed this list, and therefore my answer is a bit 
(a big big) late: the help page of plot function suggests to
use type="t" (that is type is text) in your plot command.

Best wishes, Jari Oksanen


From jorgeivanvelez at gmail.com  Tue May 12 12:59:52 2015
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Tue, 12 May 2015 20:59:52 +1000
Subject: [R] Help with pedigree() function in kinship2
Message-ID: <CAKL8G3HU8Z-F+1mbKRpjqjphVCdBYt1utD7d-iw=NNrHMJ+Gow@mail.gmail.com>

Dear R-help,

I am interested in plotting some pedigrees and came across the kinship2
package. What follows is an example of the pedigrees I am working with.

Now, when running

## check package availability
if(!require(kinship2)) install.packages('kinship2')
require(kinship2)


## data to plot
d <- structure(list(FamilyID = c("1", "1", "1", "1", "1", "1", "1",
"1", "1"), PatientID = structure(c(2L, 3L, 5L, 11L, 12L, 15L,
16L, 17L, 6L), .Label = c(" 1", " 2", " 3", " 4", " 5", " 6",
" 7", " 9", "10", "11", "13", "14", "18", "20", "23", "24", "25",
"27", "28", "29", "30", "31", "33", "34", "35", "37", "38", "39",
"41", "43", "45", "50", "62", "63", "64", "65", "66", "67", "85",
"88"), class = "factor"), FatherID = structure(c(1L, 1L, 6L,
1L, 5L, 6L, 1L, 7L, 6L), .Label = c("0", "1", "10", "11", "13",
"2", "23", "27", "28", "3", "33", "34", "35", "38", "5", "62",
"64", "66", "9"), class = "factor"), MotherID = structure(c(1L,
1L, 7L, 1L, 14L, 7L, 1L, 5L, 7L), .Label = c("0", "10", "18",
"2", "24", "29", "3", "30", "33", "34", "39", "4", "43", "5",
"6", "63", "65", "9"), class = "factor"), Sex = structure(c(2L,
1L, 1L, 2L, 2L, 2L, 1L, 2L, 2L), .Label = c("Female", "Male"), class =
"factor"),
    AffectionStatus = structure(c(1L, 1L, 2L, 1L, 2L, 2L, 1L,
    2L, 2L), .Label = c("1", "2"), class = "factor")), .Names =
c("FamilyID",
"PatientID", "FatherID", "MotherID", "Sex", "AffectionStatus"
), row.names = c(NA, 9L), class = "data.frame")

## plotting
ped <- with(d, pedigree(PatientID, FatherID, MotherID, Sex,  affected =
AffectionStatus, famid = FamilyID))

## Error in pedigree(PatientID, FatherID, MotherID, Sex, affected =
AffectionStatus,  :
##                    Value of 'dadid' not found in the id list 1/0 1/0 1/2
1/0 1/2

I get an error.  My sessionInfo() is at the end.  I was wondering if
someone could help me to dissect what the cause of this error is and how it
can be fixed.

Thank you very much for your help.

Best regards,
Jorge Velez.-


R> sessionInfo()
R version 3.2.0 Patched (2015-05-04 r68320)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.10.3 (Yosemite)

locale:
[1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  parallel  compiler
 methods
[9] base

other attached packages:
[1] kinship2_1.6.0 quadprog_1.5-5 Matrix_1.2-0   readxl_0.1.0

loaded via a namespace (and not attached):
[1] Rcpp_0.11.6     grid_3.2.0      lattice_0.20-31

	[[alternative HTML version deleted]]


From jr297 at exeter.ac.uk  Tue May 12 14:02:41 2015
From: jr297 at exeter.ac.uk (Rapkin, James)
Date: Tue, 12 May 2015 12:02:41 +0000
Subject: [R] MCMCglmm Intersex covariance set to 0
Message-ID: <AMXPR03MB2150FFA6B3B76D26ED35204D9DA0@AMXPR03MB215.eurprd03.prod.outlook.com>

Dear all

I'm trying to examine the effect that the additive genetic covariance (B) between the sexes has on the predicted response to selection on life-history traits in the sexes. 

Using the method of Argrawal and Stinchcombe (2009) this is done by calculating the response to selection following the method of Lande (1980):

(Delta_Z_Male		  = 1/2 		( Gm	B	 (beta m
 Delta_Z_Female)			    B	Gf)	    beta f)	

when B was estimated from my breeding design versus when it was set to zero to reflect the case where genetic covariance between the sexes does not constrain the evolution of shared life-history traits. 

My experiment was a half-sib quantitative breeding design which looked at nutrient intake, specifically protein and carbohydrate, using artificial diets of known nutritional content, in males and females. 

My life history traits are lifespan and reproductive effort. 

I have used an MCMCglmm model to calculate the response to selection when B was predicted from my breeding design using the following as an example:

prior1.1 <- list(G = list(G1 = list(V = diag(4), n = 1.002)), R = list(V = diag(4), n = 1.002))

model1.1 <- MCMCglmm(cbind(Total_P_Eaten_Male_Daily, Total_C_Eaten_Male_Daily, Total_P_Eaten_Female_Daily, Total_C_Eaten_Female_Daily) ~ trait -1, random = ~us(trait):animal, 
                     rcov = ~us(trait):units, family = c("gaussian", "gaussian", "gaussian", "gaussian"), 
                     pedigree = Ped, data = Data, nitt=15000, thin = 50, burnin=100,
                     prior = prior1.1, verbose = T)

modelBM1 <- MCMCglmm(Z_MLS ~ Z_MP + Z_MC-1, data = Male.Data, nitt=15000, thin=50, burnin=100)
modelBF1 <- MCMCglmm(Z_FLS ~ Z_FP + Z_FC-1, data = Female.Data, nitt=15000, thin=50, burnin=100)

# Calculate delta_z
MP_LS_delta_z<-numeric(298)
for(i in 1:298){
  MP_MP <- model1.1$VCV[i, 1]
  MP_MC <- model1.1$VCV[i, 2]
  MP_FP <- model1.1$VCV[i, 3]
  MP_FC <- model1.1$VCV[i, 4]
  MP_LS <- modelBM1$Sol[i, 1]
  MC_LS <- modelBM1$Sol[i, 2]
  FP_LS <- modelBF1$Sol[i, 1]
  FC_LS <- modelBF1$Sol[i, 2]
  
MP_LS_delta_z[i]<- ((MP_MP*MP_LS)+(MP_MC*MC_LS)+(MP_FP*FP_LS)+(MP_FC*FC_LS))
}
#Summary of deltaz including confidence
summary(MP_LS_delta_z)

This has allowed me to calculate the confidence interval of my predicted responses and I would like to be able to do this for when my between sex genetic covariance is set to 0, but I am having trouble doing this. 

Is there a way to set my B to 0? I know how to set all my off diagonal components to 0 but this isn't exactly what I want to do.

Here is an example of my G matrix:

					G1 	G2	G3	G4
				G1	G1,1	G1,2	G1,3	G1,4
				G2	G1,2	G2,2	G2,3	G2,4
				G3	G1,3	G2,3	G3,3	G3,4
				G4	G1,4	G2,4	G3,4	G4,4

I have read the help (?MCMCglmm) and searched through the R help pages but if the answer is there I'm not able to find/understand it. 

Any help would be greatly appreciated. 

Thank you. 

James Rapkin


From talktoneil2008 at ymail.com  Tue May 12 09:39:18 2015
From: talktoneil2008 at ymail.com (talktoneil2008)
Date: Tue, 12 May 2015 00:39:18 -0700 (PDT)
Subject: [R] Urgent - Need help in segmentation using KCluster means
Message-ID: <1431416358076-4707089.post@n4.nabble.com>

Urgent - Need help in segmentation using KCluster means.

Please send me the analysis if someone can - talktoneil2008 at ymail.com

Data link (Droopbox)

https://www.dropbox.com/s/kict2ezfokeyq7h/MAD_ZPR_User-Base_10K_Data_CONSOLIDATED%20_COPY2.xlsx?dl=0





--
View this message in context: http://r.789695.n4.nabble.com/Urgent-Need-help-in-segmentation-using-KCluster-means-tp4707089.html
Sent from the R help mailing list archive at Nabble.com.


From talktoneil2008 at ymail.com  Tue May 12 09:39:47 2015
From: talktoneil2008 at ymail.com (talktoneil2008)
Date: Tue, 12 May 2015 00:39:47 -0700 (PDT)
Subject: [R] Urgent - Need help in segmentation using KCluster means
Message-ID: <1431416387045-4707090.post@n4.nabble.com>

Urgent - Need help in segmentation using KCluster means.

Please send me the analysis if someone can - talktoneil2008 at ymail.com

Data link (Droopbox)

https://www.dropbox.com/s/kict2ezfokeyq7h/MAD_ZPR_User-Base_10K_Data_CONSOLIDATED%20_COPY2.xlsx?dl=0





--
View this message in context: http://r.789695.n4.nabble.com/Urgent-Need-help-in-segmentation-using-KCluster-means-tp4707090.html
Sent from the R help mailing list archive at Nabble.com.


From e.robinson at pnc.com  Tue May 12 13:55:05 2015
From: e.robinson at pnc.com (e.robinson at pnc.com)
Date: Tue, 12 May 2015 07:55:05 -0400
Subject: [R] Downloading R
In-Reply-To: <FC8C208F-555F-4D65-80C9-3065B77A3A6D@gmail.com>
References: <OF772A90EC.2DD355A6-ON85257E43.00091F0C-85257E43.00094300@pnc.com>
	<FC8C208F-555F-4D65-80C9-3065B77A3A6D@gmail.com>
Message-ID: <OF3DF34FBC.5B83E4D0-ON85257E43.004174BC-85257E43.00417851@pnc.com>

Thanks Peter.

Erick Robinson
Software Engineer Lead 
Retail MIS SAS Support 

PNC Technology and Operations
23000 Mill Creek Blv.
Hignland Hills, Oh  44122
440-342-3100
e.robinson at pnc.com



 



From:   peter dalgaard <pdalgd at gmail.com>
To:     e.robinson at pnc.com, 
Cc:     R-help at r-project.org
Date:   05/12/2015 03:22 AM
Subject:        Re: [R] Downloading R



Downloading should be the easy bit. Just go to cran.r-project.org (or a 
mirror) and take the first link under "source code for all platforms".

However, you do need to study the "R Installation and Administration" 
manual, especially the platform notes. Solaris is a bit outside the 
mainstream these days, and it may take some elbow grease to get the 
compilers, libraries, and accessories all lined up properly.

A couple of people on this list and on the r-devel list use Solaris, and 
may be able to help, but you need to learn how to provide proper context 
for your questions. It is not informative that you have clicked a red link 
leading to a green arrow! 

-Peter D.

> On 12 May 2015, at 03:41 , e.robinson at pnc.com wrote:
> 
>>        My name is Erick Robinson and I am a SAS administrator at PNC
>> Bank.  I have been tasked with installing R on two of our SAS servers,
>> but am having trouble downloading the source.  I have little background
>> in UNIX (our servers run On Solaris under Unix) and cannot get to the
>> site to download.  I clicked on the link in red and it took me to the
>> green arrow without any options to download.  I was going to download 
to
>> Windows and then FTP to the server.  What is the best way to download 
> the source to our solaris server?  Thanks
> 
> Erick Robinson
> Software Engineer Lead 
> Retail MIS SAS Support 
> 
> PNC Technology and Operations
> 23000 Mill Creek Blv.
> Hignland Hills, Oh  44122
> 440-342-3100
> e.robinson at pnc.com
> 
> 
> 
> 
> ----- Forwarded by Erick Robinson/TPS/CLE/PNC on 05/11/2015 09:39 PM 
-----
> 
> From:   Duncan Murdoch <murdoch.duncan at gmail.com>
> To:     e.robinson at pnc.com, R-windows at R-project.org, 
> Date:   05/11/2015 02:52 PM
> Subject:        Re: Downloading R
> 
> 
> 
> On 11/05/2015 2:37 PM, e.robinson at pnc.com wrote:
>> Hello,
>> 
>>        My name is Erick Robinson and I am a SAS administrator at PNC
>> Bank.  I have been tasked with installing R on two of our SAS servers,
>> but am having trouble downloading the source.  I have little background
>> in UNIX (our servers run On Solaris under Unix) and cannot get to the
>> site to download.  I clicked on the link in red and it took me to the
>> green arrow without any options to download.  I was going to download 
to
>> Windows and then FTP to the server
> 
> It is much easier to install from a tarball, not from the Subversion
> repository.  But more importantly, you're writing to the wrong place.
> If my hint is not sufficient, please write to R-help, not to R-windows.
> This is the development list for the Windows version, not a general
> support list.
> 
> Duncan Murdoch
> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> Erick Robinson
>> Software Engineer Lead
>> Retail MIS SAS Support 
>> 
>> *PNC Technology and Operations*
>> 23000 Mill Creek Blv.
>> Hignland Hills, Oh  44122
>> 440-342-3100
>> e.robinson at pnc.com
>> 
>> 
>> 
>> 
>> 
>> The contents of this email are the property of PNC. If it was not
>> addressed to you, you have no legal right to read it. If you think you
>> received it in error, please notify the sender. Do not forward or copy
>> without permission of the sender. This message may be considered a
>> commercial electronic message under Canadian law or this message may
>> contain an advertisement of a product or service and thus may 
constitute
>> a commercial electronic mail message under US law. You may unsubscribe
>> at any time from receiving commercial electronic messages from PNC at
>> http://pages.e.pnc.com/globalunsub/
>> PNC, 249 Fifth Avenue, Pittsburgh, PA 15222; pnc.com
>> 
> 
> 
> 
> The contents of this email are the property of PNC. If it was not 
addressed to you, you have no legal right to read it. If you think you 
received it in error, please notify the sender. Do not forward or copy 
without permission of the sender. This message may be considered a 
commercial electronic message under Canadian law or this message may 
contain an advertisement of a product or service and thus may constitute a 
commercial electronic mail message under US law. You may unsubscribe at 
any time from receiving commercial electronic messages from PNC at 
http://pages.e.pnc.com/globalunsub/
> PNC, 249 Fifth Avenue, Pittsburgh, PA 15222; pnc.com
> 
> 
> 
>                [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com











The contents of this email are the property of PNC. If it was not addressed to you, you have no legal right to read it. If you think you received it in error, please notify the sender. Do not forward or copy without permission of the sender. This message may be considered a commercial electronic message under Canadian law or this message may contain an advertisement of a product or service and thus may constitute a commercial electronic mail message under US law. You may unsubscribe at any time from receiving commercial electronic messages from PNC at http://pages.e.pnc.com/globalunsub/
PNC, 249 Fifth Avenue, Pittsburgh, PA 15222; pnc.com



	[[alternative HTML version deleted]]


From rni.boh at gmail.com  Tue May 12 16:34:47 2015
From: rni.boh at gmail.com (Bob O'Hara)
Date: Tue, 12 May 2015 16:34:47 +0200
Subject: [R] Plotting times at night and getting plot limits correct
Message-ID: <CAN-Z0xUj_+EQgGGmFu8393oA28epJ0S+TH2vUcxQqiw2b9n2Xw@mail.gmail.com>

I'm helping colleagues with analysis of frog calls at night, and they
want to plot call statistics against time. This means we hit a
problem: we want the x-axis to start at (say) 18:00 and end at (say)
06:00. I'm reluctant to use the date as well, because we have data
from several dates, but only want to plot against time of day.

Here's some code to illustrate the problem (don't worry about the data
being outside the range of the plot: this is only for illustration).

library(chron)
Times <- chron(times.=paste(c(18:23,0:9),":30:00", sep=""))
Thing <- rnorm(length(Times)) # just something for the y-axis

plot(Times,Thing) # x-axis wrong
plot(Times,Thing, xlim=chron(times.=c("05:00:00", "18:00:00"))) # x-axis right
plot(Times,Thing, xlim=chron(times.=c("18:00:00", "05:00:00"))) #
would like this to work...

Can anyone suggest a solution?

Bob

-- 
Bob O'Hara

Biodiversity and Climate Research Centre
Senckenberganlage 25
D-60325 Frankfurt am Main,
Germany

Tel: +49 69 798 40226
Mobile: +49 1515 888 5440
WWW:   http://www.bik-f.de/root/index.php?page_id=219
Blog: http://occamstypewriter.org/boboh/
Journal of Negative Results - EEB: www.jnr-eeb.org


From thierry.onkelinx at inbo.be  Tue May 12 17:07:49 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 12 May 2015 17:07:49 +0200
Subject: [R] Plotting times at night and getting plot limits correct
In-Reply-To: <CAN-Z0xUj_+EQgGGmFu8393oA28epJ0S+TH2vUcxQqiw2b9n2Xw@mail.gmail.com>
References: <CAN-Z0xUj_+EQgGGmFu8393oA28epJ0S+TH2vUcxQqiw2b9n2Xw@mail.gmail.com>
Message-ID: <CAJuCY5zyhMYQxGuFwb15_QS_f20e4pz3ixat30o3RSZoTKiK6A@mail.gmail.com>

Dear Bob,

Is this useful?

library(lubridate)
library(ggplot2)
n <- 100
h <- sample(c(18:23, 0:9), size = n, replace = TRUE)
m <- sample(0:59, size = n, replace = TRUE)
d <- sample(1:3, size = n, replace = TRUE)
dataset <- data.frame(
  Time = as.POSIXct(paste0("2015-01-", d, " ", h, ":", m, ":0")),
  Thing = rnorm(n)
)
dataset$rTime <- round_date(dataset$Time, unit = "day")
dataset$Time2 <- dataset$Time - dataset$rTime + min(dataset$rTime)
ggplot(dataset, aes(x = Time2, y = Thing, colour = factor(rTime))) +
geom_point()

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-12 16:34 GMT+02:00 Bob O'Hara <rni.boh at gmail.com>:

> I'm helping colleagues with analysis of frog calls at night, and they
> want to plot call statistics against time. This means we hit a
> problem: we want the x-axis to start at (say) 18:00 and end at (say)
> 06:00. I'm reluctant to use the date as well, because we have data
> from several dates, but only want to plot against time of day.
>
> Here's some code to illustrate the problem (don't worry about the data
> being outside the range of the plot: this is only for illustration).
>
> library(chron)
> Times <- chron(times.=paste(c(18:23,0:9),":30:00", sep=""))
> Thing <- rnorm(length(Times)) # just something for the y-axis
>
> plot(Times,Thing) # x-axis wrong
> plot(Times,Thing, xlim=chron(times.=c("05:00:00", "18:00:00"))) # x-axis
> right
> plot(Times,Thing, xlim=chron(times.=c("18:00:00", "05:00:00"))) #
> would like this to work...
>
> Can anyone suggest a solution?
>
> Bob
>
> --
> Bob O'Hara
>
> Biodiversity and Climate Research Centre
> Senckenberganlage 25
> D-60325 Frankfurt am Main,
> Germany
>
> Tel: +49 69 798 40226
> Mobile: +49 1515 888 5440
> WWW:   http://www.bik-f.de/root/index.php?page_id=219
> Blog: http://occamstypewriter.org/boboh/
> Journal of Negative Results - EEB: www.jnr-eeb.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue May 12 17:13:37 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 12 May 2015 17:13:37 +0200
Subject: [R] Plotting times at night and getting plot limits correct
In-Reply-To: <CAN-Z0xUj_+EQgGGmFu8393oA28epJ0S+TH2vUcxQqiw2b9n2Xw@mail.gmail.com>
References: <CAN-Z0xUj_+EQgGGmFu8393oA28epJ0S+TH2vUcxQqiw2b9n2Xw@mail.gmail.com>
Message-ID: <E972D53E-A734-4BA3-AAA9-2F2E5E630474@gmail.com>


On 12 May 2015, at 16:34 , Bob O'Hara <rni.boh at gmail.com> wrote:

> I'm helping colleagues with analysis of frog calls at night,

What do you do during the daytime then? 

> and they
> want to plot call statistics against time. This means we hit a
> problem: we want the x-axis to start at (say) 18:00 and end at (say)
> 06:00. I'm reluctant to use the date as well, because we have data
> from several dates, but only want to plot against time of day.
> 
> Here's some code to illustrate the problem (don't worry about the data
> being outside the range of the plot: this is only for illustration).
> 
> library(chron)
> Times <- chron(times.=paste(c(18:23,0:9),":30:00", sep=""))
> Thing <- rnorm(length(Times)) # just something for the y-axis
> 
> plot(Times,Thing) # x-axis wrong
> plot(Times,Thing, xlim=chron(times.=c("05:00:00", "18:00:00"))) # x-axis right
> plot(Times,Thing, xlim=chron(times.=c("18:00:00", "05:00:00"))) #
> would like this to work...
> 
> Can anyone suggest a solution?

It may be sheer luck, but this seems to work OK:

> Times <- as.POSIXct("1970-01-01 18:00", tz="UTC")+as.difftime(seq(0,12,.5),units="hours")
> Things<-rnorm(25)
> plot(Times,Things) 

I think the chron route is doomed because of the fundamental confusion between going backwards in time and crossing midnight. With a little diligence you should be able to shift dates to a common origin.

-pd

> 
> Bob
> 
> -- 
> Bob O'Hara
> 
> Biodiversity and Climate Research Centre
> Senckenberganlage 25
> D-60325 Frankfurt am Main,
> Germany
> 
> Tel: +49 69 798 40226
> Mobile: +49 1515 888 5440
> WWW:   http://www.bik-f.de/root/index.php?page_id=219
> Blog: http://occamstypewriter.org/boboh/
> Journal of Negative Results - EEB: www.jnr-eeb.org
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From rmh at temple.edu  Tue May 12 17:20:29 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 12 May 2015 11:20:29 -0400
Subject: [R] Plotting times at night and getting plot limits correct
In-Reply-To: <CAN-Z0xUj_+EQgGGmFu8393oA28epJ0S+TH2vUcxQqiw2b9n2Xw@mail.gmail.com>
References: <CAN-Z0xUj_+EQgGGmFu8393oA28epJ0S+TH2vUcxQqiw2b9n2Xw@mail.gmail.com>
Message-ID: <CAGx1TMCAfcRQ00RztRO=Q0-DErRJwwKoEysyJMsfMoEvqmrApA@mail.gmail.com>

Try this.

>From the full data-time value subtract 18:00:00.
This places the times you are interested in into the range 00:00:00 - 12:00:00
Remove the date from these adjusted date-time values and plot y
against the new times.
Take control of the tick-labels and display 18:00 - 0600 instead of
the default 00:00 - 12:00

Rich

On Tue, May 12, 2015 at 10:34 AM, Bob O'Hara <rni.boh at gmail.com> wrote:
> I'm helping colleagues with analysis of frog calls at night, and they
> want to plot call statistics against time. This means we hit a
> problem: we want the x-axis to start at (say) 18:00 and end at (say)
> 06:00. I'm reluctant to use the date as well, because we have data
> from several dates, but only want to plot against time of day.
>
> Here's some code to illustrate the problem (don't worry about the data
> being outside the range of the plot: this is only for illustration).
>
> library(chron)
> Times <- chron(times.=paste(c(18:23,0:9),":30:00", sep=""))
> Thing <- rnorm(length(Times)) # just something for the y-axis
>
> plot(Times,Thing) # x-axis wrong
> plot(Times,Thing, xlim=chron(times.=c("05:00:00", "18:00:00"))) # x-axis right
> plot(Times,Thing, xlim=chron(times.=c("18:00:00", "05:00:00"))) #
> would like this to work...
>
> Can anyone suggest a solution?
>
> Bob
>
> --
> Bob O'Hara
>
> Biodiversity and Climate Research Centre
> Senckenberganlage 25
> D-60325 Frankfurt am Main,
> Germany
>
> Tel: +49 69 798 40226
> Mobile: +49 1515 888 5440
> WWW:   http://www.bik-f.de/root/index.php?page_id=219
> Blog: http://occamstypewriter.org/boboh/
> Journal of Negative Results - EEB: www.jnr-eeb.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From msnewaz at lakeheadu.ca  Tue May 12 16:38:48 2015
From: msnewaz at lakeheadu.ca (Md Newaz)
Date: Tue, 12 May 2015 10:38:48 -0400
Subject: [R] Post-hoc tests on Split-plot design
Message-ID: <CAHP2NVm7J6F5gWpLLK0d8YnAdksaSc5dYjYm1q6Yu3Y=wRT=fg@mail.gmail.com>

Dear R-help,


can you please post the following message to the r-nabble forum.


Thanks!


---------------------------------------------------------------------------------------------------------------------------------

Dear R users,


I have been attempting to carry out post-hoc tests on a split-plot design:


Model:
Yijkl = ? + Ci + ?(i)j + ?(ij) + Tk + CTik + ?T(i)jk + Pl + CPil + ?P(i)jl
+ TPkl + CTPikl + ?TP(i)jkl + ?(ijkl)


I have successfully matched the appropriate degrees of freedom and mean
squares presented in the table below using aov().


*EMS Table:*





2

2

2

3









F

R

F

F









i

j

k

l

EMS

df

F(1,2)

Ci

0

2

2

3

?2 + 6?2? + 6?2? + 12?(C)

1



?(i)j

1

1

2

3

?2 + 6?2? + 6?2?

2



?(ij)

1

1

2

3

?2 + 6?2?

0

F(1,2)

Tk

2

2

0

3

?2 + 3?2?T + 12?(T)

1

F(1,2)

CTik

0

2

0

3

?2 + 3?2?T + 6?(CT)

1



?T(i)jk

1

1

0

3

?2 + 3?2?T

2

F(2,4)

Pl

2

2

2

0

?2 + 2?2?P + 8?(P)

2

F(2,4)

CPil

0

2

2

0

?2 + 2?2?P + 4?(CP)

2



?P(i)jl

1

1

2

0

?2 + 2?2?P

4

F(2,4)

TPkl

2

2

0

0

?2 + ?2?TP + 4?(TP)

2

F(2,4)

CTPikl

0

2

0

0

?2 + ?2?TP + 2?(CTP)

2



?TP(i)jkl

1

1

0

0

?2 + ?2?TP

4



?(ijkl)

1

1

1

1

?2

0



Total











23



mod <- aov(Budburst ~ CO2*SoilTemp*Photoperiod +
Error(Greenhouse/(SoilTemp*Photoperiod)), data = data)

summary(mod)



Error: Greenhouse

                  Df    Sum Sq   Mean Sq   F value   Pr(>F)

CO2           1       1465.2    1465.2      38.81      0.0248

Residuals    2       75.5         37.8



Error: Greenhouse:SoilTemp

                           Df    Sum Sq   Mean Sq   F value   Pr(>F)

SoilTemp             1     238.00    238.00       80.57    0.0122

CO2:SoilTemp      1     145.70    145.70       49.32    0.0197

Residuals              2     5.91        2.95

Error: Greenhouse:Photoperiod

                                Df    Sum Sq  Mean Sq   F value  Pr(>F)

Photoperiod               2    986.9      493.4        6.965     0.0498

CO2:Photoperiod        2    0.2         0.1            0.001     0.9989

Residuals                   4    283.4      70.8



Error: Greenhouse:SoilTemp:Photoperiod

                                                   Df   Sum Sq   Mean Sq
  F value   Pr(>F)

SoilTemp:Photoperiod                   2    14.56       7.28
        0.514     0.6330

CO2:SoilTemp:Photoperiod            2    186.31     93.15         6.576
    0.0544

Residuals                                      4    56.67
      14.17



Error: Within

                    Df     Sum Sq   Mean Sq F value Pr(>F)

Residuals      216   2887        13.37



However, as neither TukeyHSD() nor glht() accept objects of class
?aovlist?, I cannot carry out the post-hoc tests. Is there any way to run a
post-hoc test on an object of class "aovlist"?



Alternatively, I tried modelling the data using lme() and lmer(), but the
problem is that I cannot match the appropriate degrees of freedom and mean
squares obtained from the above included expected mean squares table using
lme() or lmer().



Has anyone else encountered and overcome this issue?



Thanks in advance,


Md. Shah Newaz

Faculty of Natural Resources Management

Lakehead University

Thunder Bay, Ontario, Canada

	[[alternative HTML version deleted]]


From newrnewbie at hotmail.com  Tue May 12 16:56:30 2015
From: newrnewbie at hotmail.com (Vin Cheng)
Date: Tue, 12 May 2015 14:56:30 +0000
Subject: [R] binding two lists of lists of dataframes together
In-Reply-To: <BAY179-W90086E8482C153DBB2409FD3DB0@phx.gbl>
References: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>,
	<BAY179-W90086E8482C153DBB2409FD3DB0@phx.gbl>
Message-ID: <BAY179-W27836A61F3043318CCB1E4D3DA0@phx.gbl>

Hi,
 
Apologies for the newbie error.  Thanks John, Jim, Jeff!
 
Please find the dput output below.  I'm trying to take list1 and list 2 and bind them together at an individual list level by column - all the structures and col names will be the same, but the number of rows could be different for any sublist.  The output should end up looking like list3.  
 
Please let me know if this remains unclear.  Any help/guidance would be greatly appreciated!!
 
Many Thanks,
Vince
 
 
list1<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L), 
                    WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
                    Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
               .Names = c("id", "WgtBand", "Wgt")), 
     structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
                    WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
                    Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
               .Names = c("id", "WgtBand", "Wgt")), 
     structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
                    WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
                    Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
               .Names = c("id", "WgtBand", "Wgt")))


list2<-list(structure(list(id = c(493L, 564L, 147L), 
                           WgtBand = c(1, 2, 3), 
                           Wgt = c(NaN, NaN, NA)), 
                      .Names = c("id", "WgtBand", "Wgt")), 
            structure(list(id = c(276L, 411L, 574L,111L), 
                           WgtBand = c(1, 2, 3,4), 
                           Wgt = c(NaN, NaN, NA,NA)), 
                      .Names = c("id", "WgtBand", "Wgt")), 
            structure(list(id = c(76L, 330L), 
                           WgtBand = c(1, 1), 
                           Wgt = c(NaN, NaN)), 
                      .Names = c("id", "WgtBand", "Wgt")))

list3<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L,493L, 564L, 147L), 
                           WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9,1, 2, 3), 
                           Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA)), 
                      .Names = c("id", "WgtBand", "Wgt")), 
            structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,276L, 411L, 574L,111L), 
                           WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 2, 3,4), 
                           Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA,NA)), 
                      .Names = c("id", "WgtBand", "Wgt")), 
            structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,76L, 330L), 
                           WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 1), 
                           Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN)), 
                      .Names = c("id", "WgtBand", "Wgt")))

 
 

 
From: newrnewbie at hotmail.com
To: r-help at r-project.org
Date: Mon, 11 May 2015 21:07:02 +0000
Subject: Re: [R] binding two lists of lists of dataframes together

 
 
> From: newrnewbie at hotmail.com
> To: r-help at r-project.org
> Date: Mon, 11 May 2015 20:16:40 +0000
> Subject: [R] binding two lists of lists of dataframes together
> 
>  Hi, 
> I'm new to R and am stumped.  I'm trying to bind List 1 to List 2 and have the corresponding Output.  
>  
> I've found the following code - I can't say I understand rbindlist(lapply(list12, "[", i, TRUE)).  Either way - it doesn't give exactly what's needed.
>  
> library(data.table)
> list12 <- list(List1,List2)
> nr <- as.vector(nrow(list12[[1]]))
> fastbind.ith.rows <- function(i) rbindlist(lapply(list12, "[", i, TRUE))
> fastbound <- lapply(1:nr, fastbind.ith.rows)
>  
> It produces Output 2 - where dataframes are grouped together by rownames, but keeps 2 separate vectors - vs. binding the two into 1 vector.
>  
> Any help/guidance would be greatly appreciated!!
>  
> Thanks!
> Vince
>  
 		 	   		  

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code. 		 	   		  
	[[alternative HTML version deleted]]


From weinerm at ccf.org  Tue May 12 17:42:46 2015
From: weinerm at ccf.org (Weiner, Michael)
Date: Tue, 12 May 2015 15:42:46 +0000
Subject: [R] Problems getting Rcmdr running
Message-ID: <DC6306FFE044A644A9BEAE5A43DEA92545CE51@CC-CLEXMB53.cc.ad.cchs.net>

I have been asked by a couple researchers to install Rcmdr on our HPC cluster. The cluster is a CentOS 6.5 64-bit linux OS and I am having issues running Rcmdr on 3.2.0 (and other versions, but I fear the problem I am experiencing is affecting all the versions I have installed).  I have done a fair bit of googling and ran across a thread (https://stat.ethz.ch/pipermail/r-help/2015-April/427338.html) with a number of good responses from John Fox, and looked over the documentation found at http://socserv.socsci.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html but nothing there was helpful to my situation.

> sessionInfo()
R version 3.2.0 (2015-04-16)
Platform: x86_64-unknown-linux-gnu (64-bit)
Running under: CentOS release 6.5 (Final)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] RcmdrMisc_1.0-2 sandwich_2.3-3  car_2.0-25

loaded via a namespace (and not attached):
 [1] Rcpp_0.11.5         tcltk2_1.2-11       nloptr_1.0.4
 [4] RColorBrewer_1.1-2  plyr_1.8.2          tools_3.2.0
 [7] class_7.3-12        rpart_4.1-9         digest_0.6.8
[10] lme4_1.1-7          gtable_0.1.2        nlme_3.1-120
[13] lattice_0.20-31     mgcv_1.8-6          Matrix_1.2-0
[16] parallel_3.2.0      SparseM_1.6         proto_0.3-10
[19] e1071_1.6-4         Rcmdr_2.1-7         stringr_0.6.2
[22] cluster_2.0.1       grid_3.2.0          nnet_7.3-9
[25] tcltk_3.2.0         survival_2.38-1     foreign_0.8-63
[28] latticeExtra_0.6-26 minqa_1.2.4         Formula_1.2-1
[31] ggplot2_1.0.1       reshape2_1.4.1      Hmisc_3.15-0
[34] scales_0.2.4        MASS_7.3-40         abind_1.4-3
[37] pbkrtest_0.4-2      colorspace_1.2-6    quantreg_5.11
[40] acepack_1.3-3.3     munsell_0.4.2       zoo_1.7-12

And here is the somewhat generic error message I get:

> library(Rcmdr)
Loading required package: splines
Loading required package: RcmdrMisc
Loading required package: car
Loading required package: sandwich
Error : .onAttach failed in attachNamespace() for 'Rcmdr', details:
  call: structure(.External(.C_dotTcl, ...), class = "tclObj")
  error: [tcl] Invalid state name hover.

Error: package or namespace load failed for 'Rcmdr'

As a test, I was able to run the tkProgressBar and get the expected widget.  I am at quite a loss here on how to get this running properly. Does anyone have any suggestions on how to proceed?  Can I provide any additional information to assist?

Thank you in advance
Michael Weine Think Pink: October is Breast Cancer Awareness Month


===================================


 Please consider the environment before printing this e-mail

Cleveland Clinic is ranked as one of the top hospitals in America by U.S.News & World Report (2014).  
Visit us online at http://www.clevelandclinic.org for a complete listing of our services, staff and locations.


Confidentiality Note:  This message is intended for use ...{{dropped:18}}


From newrnewbie at hotmail.com  Tue May 12 18:24:14 2015
From: newrnewbie at hotmail.com (Vin Cheng)
Date: Tue, 12 May 2015 16:24:14 +0000
Subject: [R] binding two lists of lists of dataframes together
In-Reply-To: <A2E1A0300F5.00001107jrkrideau@inbox.com>
References: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>,
	<A2E1A0300F5.00001107jrkrideau@inbox.com>
Message-ID: <BAY179-W63A3DF10922679A302B16D3DA0@phx.gbl>

Hi,
  
 Apologies for the newbie error.  Thanks John, Jim, Jeff!
  
 Please find the dput output below.  I'm trying to take list1 and list 2 and bind them together at an individual list level by column - all the structures and col names will be the same, but the number of rows could be different for any sublist.  The output should end up looking like list3.  
  
 Please let me know if this remains unclear.  Any help/guidance would be greatly appreciated!!
  
 Many Thanks,
 Vince
  
  
 list1<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L), 
                     WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
                     Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
                .Names = c("id", "WgtBand", "Wgt")), 
      structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
                     WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
                     Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
                .Names = c("id", "WgtBand", "Wgt")), 
      structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
                     WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
                     Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
                .Names = c("id", "WgtBand", "Wgt")))


 list2<-list(structure(list(id = c(493L, 564L, 147L), 
                            WgtBand = c(1, 2, 3), 
                            Wgt = c(NaN, NaN, NA)), 
                       .Names = c("id", "WgtBand", "Wgt")), 
             structure(list(id = c(276L, 411L, 574L,111L), 
                            WgtBand = c(1, 2, 3,4), 
                            Wgt = c(NaN, NaN, NA,NA)), 
                       .Names = c("id", "WgtBand", "Wgt")), 
             structure(list(id = c(76L, 330L), 
                            WgtBand = c(1, 1), 
                            Wgt = c(NaN, NaN)), 
                       .Names = c("id", "WgtBand", "Wgt")))

 list3<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L,493L, 564L, 147L), 
                            WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9,1, 2, 3), 
                            Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA)), 
                       .Names = c("id", "WgtBand", "Wgt")), 
             structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,276L, 411L, 574L,111L), 
                            WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 2, 3,4), 
                            Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA,NA)), 
                       .Names = c("id", "WgtBand", "Wgt")), 
             structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,76L, 330L), 
                            WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 1), 
                            Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN)), 
                       .Names = c("id", "WgtBand", "Wgt")))
 
> Date: Mon, 11 May 2015 18:19:06 -0800
> From: jrkrideau at inbox.com
> Subject: RE: [R] binding two lists of lists of dataframes together
> To: newrnewbie at hotmail.com; r-help at r-project.org
> 
>  http://adv-r.had.co.nz/Reproducibility.html
> 
> and please do not post in Html.
> 
> 
> John Kane
> Kingston ON Canada
> 
> 
> > -----Original Message-----
> > From: newrnewbie at hotmail.com
> > Sent: Mon, 11 May 2015 20:16:40 +0000
> > To: r-help at r-project.org
> > Subject: [R] binding two lists of lists of dataframes together
> > 
> >  Hi,
> > I'm new to R and am stumped.  I'm trying to bind List 1 to List 2 and
> > have the corresponding Output.
> > 
> > I've found the following code - I can't say I understand
> > rbindlist(lapply(list12, "[", i, TRUE)).  Either way - it doesn't give
> > exactly what's needed.
> > 
> > library(data.table)
> > list12 <- list(List1,List2)
> > nr <- as.vector(nrow(list12[[1]]))
> > fastbind.ith.rows <- function(i) rbindlist(lapply(list12, "[", i, TRUE))
> > fastbound <- lapply(1:nr, fastbind.ith.rows)
> > 
> > It produces Output 2 - where dataframes are grouped together by rownames,
> > but keeps 2 separate vectors - vs. binding the two into 1 vector.
> > 
> > Any help/guidance would be greatly appreciated!!
> > 
> > Thanks!
> > Vince
 		 	   		  
	[[alternative HTML version deleted]]


From nusratthebest at hotmail.com  Tue May 12 18:41:55 2015
From: nusratthebest at hotmail.com (nusrat ullah)
Date: Tue, 12 May 2015 17:41:55 +0100
Subject: [R] ifelse and "&&" vs "&
Message-ID: <SNT407-EAS93FB58DF717BA3119F84AFB9DA0@phx.gbl>

Ip,  g ftehgytreehjjjijiputv

Sent from my iPadgypyrrytutytytfedewaqy?iijj

From aurora.gonzalez2 at um.es  Tue May 12 18:50:48 2015
From: aurora.gonzalez2 at um.es (AURORA GONZALEZ VIDAL)
Date: Tue, 12 May 2015 18:50:48 +0200
Subject: [R] geom_text in ggplot (position)
Message-ID: <20150512185048.Horde.nzIY56yNPzxwjRyuAd3FmQ1@webmail.um.es>

Hello everybody.

I have an "esthetic" question. I have managed to create a stacked and
grouped bar plot but I don't manage with putting the text in the middle of
the bar plots. Do you know how to write the numbers in that position?

Thank you so much.

Example code:

test? <- data.frame(variables =? c("PE_35", "PE_49"),
??????????????????? value1=c(13,3),
??????????????????? value2=c(75,31),
??????????????????? value3=c(7,17),
??????????????????? value4 =c(5,49))

library(reshape2) # for melt

melted <- melt(test, "variables")
melted$cO <- c("A","A","B","B","A","A","B","B")

melted$cat <- ''
melted[melted$variable == 'value1' | melted$variable == 'value2',]$cat <-
"0"
melted[melted$variable == 'value3' | melted$variable == 'value4',]$cat <-
"1"

names(melted)[3] <- "recuento"

library(ggplot2)

ggplot(melted, aes(x = cat, y = recuento,ymax=max(recuento)*1.05, fill =
cO)) +
? geom_bar(stat = 'identity', position = 'stack', col="black") +
facet_grid(~ variables)+
? geom_text(aes(label = recuento), size = 5, hjust = 0.5, vjust = 1,
position ="stack")


------
Aurora Gonz?lez Vidal

Secci?n Apoyo Estad?stico.
Servicio de Apoyo a la Investigaci?n (SAI).
Vicerrectorado de Investigaci?n.
Universidad de Murcia
Edif. SACE . Campus de Espinardo.
30100 Murcia

@. aurora.gonzalez2 at um.es
T. 868 88 7315
F. 868 88 7302
www.um.es/sai
www.um.es/ae

	[[alternative HTML version deleted]]


From rmh at temple.edu  Tue May 12 20:02:56 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 12 May 2015 14:02:56 -0400
Subject: [R] Post-hoc tests on Split-plot design
In-Reply-To: <CAHP2NVm7J6F5gWpLLK0d8YnAdksaSc5dYjYm1q6Yu3Y=wRT=fg@mail.gmail.com>
References: <CAHP2NVm7J6F5gWpLLK0d8YnAdksaSc5dYjYm1q6Yu3Y=wRT=fg@mail.gmail.com>
Message-ID: <CAGx1TMAdN3QLDNC8iJ6oJK0mXHLdspBfC=SFJV+E8L2qZY=iiQ@mail.gmail.com>

Yes, it is possible with the mmc function in the HH package.

install.packages("HH")  ## if you don't have it yet.
library(HH)
?MMC

Look at the maiz example, the long last example in ?MMC.

When you are ready for followup questions, reply to this message to
R-help (not directly to me and
not to nabble).  Please turn off the html mail option.  The html
version of R code is garbled
to illegibility on this plain text email list.

Please read the posting guide linked at the bottom of all R-help mail messages.
Please read also read
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Rich

On Tue, May 12, 2015 at 10:38 AM, Md Newaz <msnewaz at lakeheadu.ca> wrote:
> Dear R-help,
>
>
> can you please post the following message to the r-nabble forum.
>
>
> Thanks!
>
>
> ---------------------------------------------------------------------------------------------------------------------------------
>
> Dear R users,
>
>
> I have been attempting to carry out post-hoc tests on a split-plot design:
>
>
> Model:
> Yijkl = ? + Ci + ?(i)j + ?(ij) + Tk + CTik + ?T(i)jk + Pl + CPil + ?P(i)jl
> + TPkl + CTPikl + ?TP(i)jkl + ?(ijkl)
>
>
> I have successfully matched the appropriate degrees of freedom and mean
> squares presented in the table below using aov().
>
>
> *EMS Table:*
>
>
>
>
>
> 2
>
> 2
>
> 2
>
> 3
>
>
>
>
>
>
>
>
>
> F
>
> R
>
> F
>
> F
>
>
>
>
>
>
>
>
>
> i
>
> j
>
> k
>
> l
>
> EMS
>
> df
>
> F(1,2)
>
> Ci
>
> 0
>
> 2
>
> 2
>
> 3
>
> ?2 + 6?2? + 6?2? + 12?(C)
>
> 1
>
>
>
> ?(i)j
>
> 1
>
> 1
>
> 2
>
> 3
>
> ?2 + 6?2? + 6?2?
>
> 2
>
>
>
> ?(ij)
>
> 1
>
> 1
>
> 2
>
> 3
>
> ?2 + 6?2?
>
> 0
>
> F(1,2)
>
> Tk
>
> 2
>
> 2
>
> 0
>
> 3
>
> ?2 + 3?2?T + 12?(T)
>
> 1
>
> F(1,2)
>
> CTik
>
> 0
>
> 2
>
> 0
>
> 3
>
> ?2 + 3?2?T + 6?(CT)
>
> 1
>
>
>
> ?T(i)jk
>
> 1
>
> 1
>
> 0
>
> 3
>
> ?2 + 3?2?T
>
> 2
>
> F(2,4)
>
> Pl
>
> 2
>
> 2
>
> 2
>
> 0
>
> ?2 + 2?2?P + 8?(P)
>
> 2
>
> F(2,4)
>
> CPil
>
> 0
>
> 2
>
> 2
>
> 0
>
> ?2 + 2?2?P + 4?(CP)
>
> 2
>
>
>
> ?P(i)jl
>
> 1
>
> 1
>
> 2
>
> 0
>
> ?2 + 2?2?P
>
> 4
>
> F(2,4)
>
> TPkl
>
> 2
>
> 2
>
> 0
>
> 0
>
> ?2 + ?2?TP + 4?(TP)
>
> 2
>
> F(2,4)
>
> CTPikl
>
> 0
>
> 2
>
> 0
>
> 0
>
> ?2 + ?2?TP + 2?(CTP)
>
> 2
>
>
>
> ?TP(i)jkl
>
> 1
>
> 1
>
> 0
>
> 0
>
> ?2 + ?2?TP
>
> 4
>
>
>
> ?(ijkl)
>
> 1
>
> 1
>
> 1
>
> 1
>
> ?2
>
> 0
>
>
>
> Total
>
>
>
>
>
>
>
>
>
>
>
> 23
>
>
>
> mod <- aov(Budburst ~ CO2*SoilTemp*Photoperiod +
> Error(Greenhouse/(SoilTemp*Photoperiod)), data = data)
>
> summary(mod)
>
>
>
> Error: Greenhouse
>
>                   Df    Sum Sq   Mean Sq   F value   Pr(>F)
>
> CO2           1       1465.2    1465.2      38.81      0.0248
>
> Residuals    2       75.5         37.8
>
>
>
> Error: Greenhouse:SoilTemp
>
>                            Df    Sum Sq   Mean Sq   F value   Pr(>F)
>
> SoilTemp             1     238.00    238.00       80.57    0.0122
>
> CO2:SoilTemp      1     145.70    145.70       49.32    0.0197
>
> Residuals              2     5.91        2.95
>
> Error: Greenhouse:Photoperiod
>
>                                 Df    Sum Sq  Mean Sq   F value  Pr(>F)
>
> Photoperiod               2    986.9      493.4        6.965     0.0498
>
> CO2:Photoperiod        2    0.2         0.1            0.001     0.9989
>
> Residuals                   4    283.4      70.8
>
>
>
> Error: Greenhouse:SoilTemp:Photoperiod
>
>                                                    Df   Sum Sq   Mean Sq
>   F value   Pr(>F)
>
> SoilTemp:Photoperiod                   2    14.56       7.28
>         0.514     0.6330
>
> CO2:SoilTemp:Photoperiod            2    186.31     93.15         6.576
>     0.0544
>
> Residuals                                      4    56.67
>       14.17
>
>
>
> Error: Within
>
>                     Df     Sum Sq   Mean Sq F value Pr(>F)
>
> Residuals      216   2887        13.37
>
>
>
> However, as neither TukeyHSD() nor glht() accept objects of class
> ?aovlist?, I cannot carry out the post-hoc tests. Is there any way to run a
> post-hoc test on an object of class "aovlist"?
>
>
>
> Alternatively, I tried modelling the data using lme() and lmer(), but the
> problem is that I cannot match the appropriate degrees of freedom and mean
> squares obtained from the above included expected mean squares table using
> lme() or lmer().
>
>
>
> Has anyone else encountered and overcome this issue?
>
>
>
> Thanks in advance,
>
>
> Md. Shah Newaz
>
> Faculty of Natural Resources Management
>
> Lakehead University
>
> Thunder Bay, Ontario, Canada
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue May 12 20:36:50 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 12 May 2015 11:36:50 -0700
Subject: [R] binding two lists of lists of dataframes together
In-Reply-To: <BAY179-W63A3DF10922679A302B16D3DA0@phx.gbl>
References: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>,
	<A2E1A0300F5.00001107jrkrideau@inbox.com>
	<BAY179-W63A3DF10922679A302B16D3DA0@phx.gbl>
Message-ID: <17C25B6B-DDF7-4108-99C9-3DABC178C32F@comcast.net>


On May 12, 2015, at 9:24 AM, Vin Cheng wrote:

> list1<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L), 
>                     WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
>                     Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
>                .Names = c("id", "WgtBand", "Wgt")), 
>      structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
>                     WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
>                     Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
>                .Names = c("id", "WgtBand", "Wgt")), 
>      structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
>                     WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
>                     Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
>                .Names = c("id", "WgtBand", "Wgt")))
> 
> 
> list2<-list(structure(list(id = c(493L, 564L, 147L), 
>                            WgtBand = c(1, 2, 3), 
>                            Wgt = c(NaN, NaN, NA)), 
>                       .Names = c("id", "WgtBand", "Wgt")), 
>             structure(list(id = c(276L, 411L, 574L,111L), 
>                            WgtBand = c(1, 2, 3,4), 
>                            Wgt = c(NaN, NaN, NA,NA)), 
>                       .Names = c("id", "WgtBand", "Wgt")), 
>             structure(list(id = c(76L, 330L), 
>                            WgtBand = c(1, 1), 
>                            Wgt = c(NaN, NaN)), 
>                       .Names = c("id", "WgtBand", "Wgt")))
> 
> list3<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L,493L, 564L, 147L), 
>                            WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9,1, 2, 3), 
>                            Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA)), 
>                       .Names = c("id", "WgtBand", "Wgt")), 
>             structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,276L, 411L, 574L,111L), 
>                            WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 2, 3,4), 
>                            Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA,NA)), 
>                       .Names = c("id", "WgtBand", "Wgt")), 
>             structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,76L, 330L), 
>                            WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 1), 
>                            Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN)), 
>                       .Names = c("id", "WgtBand", "Wgt")))

I get something like the desired structure with:

mapply(function(x,y) mapply(c, x,y), list1,list2)

I can make it closer with:

lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) unclass( as.data.frame(x) ) )


Or even closer with:

lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) as.list( as.data.frame(x) ) )

`identical` does not return TRUE but I cannot see where the difference lies.

-- 

David Winsemius
Alameda, CA, USA


From elanswartz at gmail.com  Tue May 12 20:33:53 2015
From: elanswartz at gmail.com (Elan Swartz)
Date: Tue, 12 May 2015 20:33:53 +0200
Subject: [R] Using Calipers in GenMatch and Match
Message-ID: <CAKq+ZWGAvLk0CFQKgG8-D-L-iL_kKb4fUTSKeHnXTEu7Qqcjig@mail.gmail.com>

Hi

I have been reading the documentation, and it seems there is no difference
in the caliper option in the packages genmatch and match. In both the
simplistic way to use them is to specific a scalar which reflects the
maximum number of standard deviations the control can be away from the
treated. However, when running match(), I can specify relativly small
calipers <.1 without loosing too many observations. On the otherhand, with
GenMatch(), a caliper of 0.5 will drop 98% of my observations.

I was wondering if someone can explain the difference in how a caliper
functions in Genmatch vs. match function?

cheers

	[[alternative HTML version deleted]]


From nilesh.dighe at monsanto.com  Tue May 12 20:03:17 2015
From: nilesh.dighe at monsanto.com (DIGHE, NILESH [AG/2362])
Date: Tue, 12 May 2015 18:03:17 +0000
Subject: [R] help with "by" function
Message-ID: <24156952D190E841BF8E66CB59FAB94A484E6BF7@STLWEXMBXPRD14.na.ds.monsanto.com>

Hi,
I have an anonymous function called function(x) that will run anova, run HSD.test on the model, and then sort the results.  I am passing this anonymous function to the "by" function to get results by "Isopair" factor which is my index variable.  Since I want to run the anova on multiple dependent variables including "Trait1" & "Trait2", I am calling the dependent variable, "trait_names" in the model and then passing the "by" function to another function called "funC" which takes the "trait_names" as an argument to execute.

After I execute the funC(data_set$trait1), I am getting the results by Isopair but the results for the two Isopairs (Isopair-A &Isopair-B) are the same which I know is not correct.  It looks like the data is not getting split by Isopairs and so ALL data is used in anova for both Isopairs.  Any help in modifying function, funC or any other ways to achieve the desired outcome will be highly appreciated.

Thanks.  Nilesh

R code, data set, and session info is pasted below.
R code:
library(agricolae)
funC<- function(trait_names){
  by(data_set, data_set$Isopair,function(x){
  mod<- aov(trait_names~ STGgroup*Field + Rep%in%Field, data=data_set)
  out<-HSD.test(mod,"STGgroup",group=TRUE,console=TRUE)
  dfout<- arrange(data.frame(out$groups),desc(trt))
  })
}
Results:
##execute funC function for Trait1 & Trait2
funC(data_set$Trait1)


data_set$Isopair: Isopair-A

      trt    means M

1 STG     776.9167 a

2 Non-STG 779.0833 a

---------------------------------------------------------------------------

data_set$Isopair: Isopair-B

      trt    means M

1 STG     776.9167 a

2 Non-STG 779.0833 a

Data:
data_set<- structure(list(Field = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L), .Label = c("LML6", "TZL2"), class = "factor"), Isopair = structure(c(1L,
1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
1L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Isopair-A", "Isopair-B"
), class = "factor"), STGgroup = structure(c(1L, 1L, 1L, 2L,
2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
1L, 2L, 2L, 2L), .Label = c("Non-STG", "STG"), class = "factor"),
    Rep = structure(c(1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,
    2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L), .Label = c("Rep1",
    "Rep2", "Rep3"), class = "factor"), Trait1 = c(686L, 641L,
    642L, 727L, 619L, 562L, 808L, 739L, 744L, 873L, 797L, 868L,
    782L, 783L, 675L, 713L, 762L, 641L, 1009L, 995L, 845L, 1186L,
    912L, 663L), Trait2 = c(45L, 65L, 70L, 35L, 20L, 80L, 70L,
    65L, 70L, 20L, 30L, 35L, 40L, 55L, 35L, 40L, 35L, 40L, 40L,
    35L, 25L, 40L, 35L, 25L)), .Names = c("Field", "Isopair",
"STGgroup", "Rep", "Trait1", "Trait2"), class = "data.frame", row.names = c(NA,
-24L))

Session info:

R version 3.1.3 (2015-03-09)

Platform: i386-w64-mingw32/i386 (32-bit)

Running under: Windows 7 x64 (build 7601) Service Pack 1



locale:

[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252

[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C

[5] LC_TIME=English_United States.1252



attached base packages:

[1] grid      stats     graphics  grDevices utils     datasets  methods   base



other attached packages:

 [1] gridExtra_0.9.1 Hmisc_3.16-0    Formula_1.2-1   survival_2.38-1 caret_6.0-41    ggplot2_1.0.1

 [7] lattice_0.20-30 MASS_7.3-39     dplyr_0.4.1     agricolae_1.2-1



loaded via a namespace (and not attached):

 [1] acepack_1.3-3.3     assertthat_0.1      boot_1.3-15         BradleyTerry2_1.0-6

 [5] brglm_0.5-9         car_2.0-25          cluster_2.0.1       coda_0.17-1

 [9] codetools_0.2-10    colorspace_1.2-6    combinat_0.0-8      DBI_0.3.1

[13] deldir_0.1-9        digest_0.6.8        foreach_1.4.2       foreign_0.8-63

[17] gtable_0.1.2        gtools_3.4.1        iterators_1.0.7     klaR_0.6-12

[21] latticeExtra_0.6-26 lazyeval_0.1.10     LearnBayes_2.15     lme4_1.1-7

[25] magrittr_1.5        Matrix_1.1-5        mgcv_1.8-4          minqa_1.2.4

[29] munsell_0.4.2       nlme_3.1-120        nloptr_1.0.4        nnet_7.3-9

[33] parallel_3.1.3      pbkrtest_0.4-2      plyr_1.8.1          proto_0.3-10

[37] quantreg_5.11       RColorBrewer_1.1-2  Rcpp_0.11.6         reshape2_1.4.1

[41] rpart_4.1-9         scales_0.2.4        sp_1.0-17           SparseM_1.6

[45] spdep_0.5-88        splines_3.1.3       stringr_0.6.2       tools_3.1.3





This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled
to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and
all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.

All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its
subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying
this e-mail or any attachment.


The information contained in this email may be subject to the export control laws and regulations of the United States, potentially
including but not limited to the Export Administration Regulations (EAR) and sanctions regulations issued by the U.S. Department of
Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all
applicable U.S. export laws and regulations.

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Tue May 12 20:52:15 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 12 May 2015 14:52:15 -0400
Subject: [R] geom_text in ggplot (position)
In-Reply-To: <20150512185048.Horde.nzIY56yNPzxwjRyuAd3FmQ1@webmail.um.es>
References: <20150512185048.Horde.nzIY56yNPzxwjRyuAd3FmQ1@webmail.um.es>
Message-ID: <CA+vqiLE-+OGamm==bNjVpDBETqO9K4B8icYBRzgzTG2qq+Ke6A@mail.gmail.com>

Well, the stacking makes it tricky. AFAIK you have to calculate the
positions yourself, e.g.,

melted <- melted[order(melted$variables, melted$cat, melted$cO), ]
melted$rec2 <- melted$recuento/2
melted[melted$cO == "B", "rec2"]  <- melted[melted$cO == "B", "rec2"]
+ melted[melted$cO == "A", "recuento"]

library(ggplot2)

ggplot(melted, aes(x = cat, y = recuento,ymax=max(recuento)*1.05, fill = cO)) +
    geom_bar(stat = 'identity', position = 'stack', col="black") +
    facet_grid(~ variables)+
    geom_text(aes(label = recuento, y = rec2), size = 5, hjust = 0.5)


Best,
Ista


On Tue, May 12, 2015 at 12:50 PM, AURORA GONZALEZ VIDAL
<aurora.gonzalez2 at um.es> wrote:
> Hello everybody.
>
> I have an "esthetic" question. I have managed to create a stacked and
> grouped bar plot but I don't manage with putting the text in the middle of
> the bar plots. Do you know how to write the numbers in that position?
>
> Thank you so much.
>
> Example code:
>
> test  <- data.frame(variables =  c("PE_35", "PE_49"),
>                     value1=c(13,3),
>                     value2=c(75,31),
>                     value3=c(7,17),
>                     value4 =c(5,49))
>
> library(reshape2) # for melt
>
> melted <- melt(test, "variables")
> melted$cO <- c("A","A","B","B","A","A","B","B")
>
> melted$cat <- ''
> melted[melted$variable == 'value1' | melted$variable == 'value2',]$cat <-
> "0"
> melted[melted$variable == 'value3' | melted$variable == 'value4',]$cat <-
> "1"
>
> names(melted)[3] <- "recuento"
>
> library(ggplot2)
>
> ggplot(melted, aes(x = cat, y = recuento,ymax=max(recuento)*1.05, fill =
> cO)) +
>   geom_bar(stat = 'identity', position = 'stack', col="black") +
> facet_grid(~ variables)+
>   geom_text(aes(label = recuento), size = 5, hjust = 0.5, vjust = 1,
> position ="stack")
>
>
> ------
> Aurora Gonz?lez Vidal
>
> Secci?n Apoyo Estad?stico.
> Servicio de Apoyo a la Investigaci?n (SAI).
> Vicerrectorado de Investigaci?n.
> Universidad de Murcia
> Edif. SACE . Campus de Espinardo.
> 30100 Murcia
>
> @. aurora.gonzalez2 at um.es
> T. 868 88 7315
> F. 868 88 7302
> www.um.es/sai
> www.um.es/ae
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Tue May 12 21:13:34 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 12 May 2015 14:13:34 -0500
Subject: [R] help with "by" function
In-Reply-To: <24156952D190E841BF8E66CB59FAB94A484E6BF7@STLWEXMBXPRD14.na.ds.monsanto.com>
References: <24156952D190E841BF8E66CB59FAB94A484E6BF7@STLWEXMBXPRD14.na.ds.monsanto.com>
Message-ID: <CAN5YmCE1=2bgEzeVxrkCx+s2qcfhbyCm0PgnMCeD_QpOajsVmw@mail.gmail.com>

Nilesh,

I found a couple errors in your code.  First, in your by() statement you
have a function to operate on the selected subset of data, which you refer
to as
     x
but then, in your aov statement you refer to
     data_set
not
     x

Second, your funC() statement is a function of
     trait_names
but to make sure that the name of the variable is included in the formula,
I changed this to a character variable.

Give the code below a try and see if it works for you.

Jean


library(agricolae)
library(dplyr)

funC <- function(trait_names){
  by(data_set, data_set$Isopair, function(x) {
  mod <- aov(formula(paste(trait_names, "~ STGgroup*Field +
Rep%in%Field")),
    data=x)
  out <- HSD.test(mod, "STGgroup", group=TRUE, console=TRUE)
  dfout <- arrange(data.frame(out$groups), desc(trt))
  })
}

funC("Trait1")


On Tue, May 12, 2015 at 1:03 PM, DIGHE, NILESH [AG/2362] <
nilesh.dighe at monsanto.com> wrote:

> Hi,
> I have an anonymous function called function(x) that will run anova, run
> HSD.test on the model, and then sort the results.  I am passing this
> anonymous function to the "by" function to get results by "Isopair" factor
> which is my index variable.  Since I want to run the anova on multiple
> dependent variables including "Trait1" & "Trait2", I am calling the
> dependent variable, "trait_names" in the model and then passing the "by"
> function to another function called "funC" which takes the "trait_names" as
> an argument to execute.
>
> After I execute the funC(data_set$trait1), I am getting the results by
> Isopair but the results for the two Isopairs (Isopair-A &Isopair-B) are the
> same which I know is not correct.  It looks like the data is not getting
> split by Isopairs and so ALL data is used in anova for both Isopairs.  Any
> help in modifying function, funC or any other ways to achieve the desired
> outcome will be highly appreciated.
>
> Thanks.  Nilesh
>
> R code, data set, and session info is pasted below.
> R code:
> library(agricolae)
> funC<- function(trait_names){
>   by(data_set, data_set$Isopair,function(x){
>   mod<- aov(trait_names~ STGgroup*Field + Rep%in%Field, data=data_set)
>   out<-HSD.test(mod,"STGgroup",group=TRUE,console=TRUE)
>   dfout<- arrange(data.frame(out$groups),desc(trt))
>   })
> }
> Results:
> ##execute funC function for Trait1 & Trait2
> funC(data_set$Trait1)
>
>
> data_set$Isopair: Isopair-A
>
>       trt    means M
>
> 1 STG     776.9167 a
>
> 2 Non-STG 779.0833 a
>
> ---------------------------------------------------------------------------
>
> data_set$Isopair: Isopair-B
>
>       trt    means M
>
> 1 STG     776.9167 a
>
> 2 Non-STG 779.0833 a
>
> Data:
> data_set<- structure(list(Field = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L), .Label = c("LML6", "TZL2"), class = "factor"), Isopair =
> structure(c(1L,
> 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
> 1L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Isopair-A", "Isopair-B"
> ), class = "factor"), STGgroup = structure(c(1L, 1L, 1L, 2L,
> 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
> 1L, 2L, 2L, 2L), .Label = c("Non-STG", "STG"), class = "factor"),
>     Rep = structure(c(1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,
>     2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L), .Label =
> c("Rep1",
>     "Rep2", "Rep3"), class = "factor"), Trait1 = c(686L, 641L,
>     642L, 727L, 619L, 562L, 808L, 739L, 744L, 873L, 797L, 868L,
>     782L, 783L, 675L, 713L, 762L, 641L, 1009L, 995L, 845L, 1186L,
>     912L, 663L), Trait2 = c(45L, 65L, 70L, 35L, 20L, 80L, 70L,
>     65L, 70L, 20L, 30L, 35L, 40L, 55L, 35L, 40L, 35L, 40L, 40L,
>     35L, 25L, 40L, 35L, 25L)), .Names = c("Field", "Isopair",
> "STGgroup", "Rep", "Trait1", "Trait2"), class = "data.frame", row.names =
> c(NA,
> -24L))
>
> Session info:
>
> R version 3.1.3 (2015-03-09)
>
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
>
>
> locale:
>
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252
>
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>
> [5] LC_TIME=English_United States.1252
>
>
>
> attached base packages:
>
> [1] grid      stats     graphics  grDevices utils     datasets  methods
>  base
>
>
>
> other attached packages:
>
>  [1] gridExtra_0.9.1 Hmisc_3.16-0    Formula_1.2-1   survival_2.38-1
> caret_6.0-41    ggplot2_1.0.1
>
>  [7] lattice_0.20-30 MASS_7.3-39     dplyr_0.4.1     agricolae_1.2-1
>
>
>
> loaded via a namespace (and not attached):
>
>  [1] acepack_1.3-3.3     assertthat_0.1      boot_1.3-15
>  BradleyTerry2_1.0-6
>
>  [5] brglm_0.5-9         car_2.0-25          cluster_2.0.1
>  coda_0.17-1
>
>  [9] codetools_0.2-10    colorspace_1.2-6    combinat_0.0-8      DBI_0.3.1
>
> [13] deldir_0.1-9        digest_0.6.8        foreach_1.4.2
>  foreign_0.8-63
>
> [17] gtable_0.1.2        gtools_3.4.1        iterators_1.0.7
>  klaR_0.6-12
>
> [21] latticeExtra_0.6-26 lazyeval_0.1.10     LearnBayes_2.15     lme4_1.1-7
>
> [25] magrittr_1.5        Matrix_1.1-5        mgcv_1.8-4
> minqa_1.2.4
>
> [29] munsell_0.4.2       nlme_3.1-120        nloptr_1.0.4        nnet_7.3-9
>
> [33] parallel_3.1.3      pbkrtest_0.4-2      plyr_1.8.1
> proto_0.3-10
>
> [37] quantreg_5.11       RColorBrewer_1.1-2  Rcpp_0.11.6
>  reshape2_1.4.1
>
> [41] rpart_4.1-9         scales_0.2.4        sp_1.0-17
>  SparseM_1.6
>
> [45] spdep_0.5-88        splines_3.1.3       stringr_0.6.2
>  tools_3.1.3
>
>
>
>
>
> This e-mail message may contain privileged and/or confidential
> information, and is intended to be received only by persons entitled
> to receive such information. If you have received this e-mail in error,
> please notify the sender immediately. Please delete it and
> all attachments from any servers, hard drives or any other media. Other
> use of this e-mail by you is strictly prohibited.
>
> All e-mails and attachments sent and received are subject to monitoring,
> reading and archival by Monsanto, including its
> subsidiaries. The recipient of this e-mail is solely responsible for
> checking for the presence of "Viruses" or other "Malware".
> Monsanto, along with its subsidiaries, accepts no liability for any damage
> caused by any such code transmitted by or accompanying
> this e-mail or any attachment.
>
>
> The information contained in this email may be subject to the export
> control laws and regulations of the United States, potentially
> including but not limited to the Export Administration Regulations (EAR)
> and sanctions regulations issued by the U.S. Department of
> Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this
> information you are obligated to comply with all
> applicable U.S. export laws and regulations.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From nilesh.dighe at monsanto.com  Tue May 12 21:34:32 2015
From: nilesh.dighe at monsanto.com (DIGHE, NILESH [AG/2362])
Date: Tue, 12 May 2015 19:34:32 +0000
Subject: [R] help with "by" function
In-Reply-To: <CAN5YmCE1=2bgEzeVxrkCx+s2qcfhbyCm0PgnMCeD_QpOajsVmw@mail.gmail.com>
References: <24156952D190E841BF8E66CB59FAB94A484E6BF7@STLWEXMBXPRD14.na.ds.monsanto.com>
	<CAN5YmCE1=2bgEzeVxrkCx+s2qcfhbyCm0PgnMCeD_QpOajsVmw@mail.gmail.com>
Message-ID: <24156952D190E841BF8E66CB59FAB94A484E6F42@STLWEXMBXPRD14.na.ds.monsanto.com>

Jean:  Thanks a lot!!  The changes you made to the code gave me what I needed.  I truly appreciate your time in correcting the code.
Nilesh

From: Adams, Jean [mailto:jvadams at usgs.gov]
Sent: Tuesday, May 12, 2015 2:14 PM
To: DIGHE, NILESH [AG/2362]
Cc: r-help at r-project.org
Subject: Re: [R] help with "by" function

Nilesh,

I found a couple errors in your code.  First, in your by() statement you have a function to operate on the selected subset of data, which you refer to as
     x
but then, in your aov statement you refer to
     data_set
not
     x

Second, your funC() statement is a function of
     trait_names
but to make sure that the name of the variable is included in the formula, I changed this to a character variable.

Give the code below a try and see if it works for you.

Jean


library(agricolae)
library(dplyr)

funC <- function(trait_names){
  by(data_set, data_set$Isopair, function(x) {
  mod <- aov(formula(paste(trait_names, "~ STGgroup*Field + Rep%in%Field")),
    data=x)
  out <- HSD.test(mod, "STGgroup", group=TRUE, console=TRUE)
  dfout <- arrange(data.frame(out$groups), desc(trt))
  })
}

funC("Trait1")


On Tue, May 12, 2015 at 1:03 PM, DIGHE, NILESH [AG/2362] <nilesh.dighe at monsanto.com<mailto:nilesh.dighe at monsanto.com>> wrote:
Hi,
I have an anonymous function called function(x) that will run anova, run HSD.test on the model, and then sort the results.  I am passing this anonymous function to the "by" function to get results by "Isopair" factor which is my index variable.  Since I want to run the anova on multiple dependent variables including "Trait1" & "Trait2", I am calling the dependent variable, "trait_names" in the model and then passing the "by" function to another function called "funC" which takes the "trait_names" as an argument to execute.

After I execute the funC(data_set$trait1), I am getting the results by Isopair but the results for the two Isopairs (Isopair-A &Isopair-B) are the same which I know is not correct.  It looks like the data is not getting split by Isopairs and so ALL data is used in anova for both Isopairs.  Any help in modifying function, funC or any other ways to achieve the desired outcome will be highly appreciated.

Thanks.  Nilesh

R code, data set, and session info is pasted below.
R code:
library(agricolae)
funC<- function(trait_names){
  by(data_set, data_set$Isopair,function(x){
  mod<- aov(trait_names~ STGgroup*Field + Rep%in%Field, data=data_set)
  out<-HSD.test(mod,"STGgroup",group=TRUE,console=TRUE)
  dfout<- arrange(data.frame(out$groups),desc(trt))
  })
}
Results:
##execute funC function for Trait1 & Trait2
funC(data_set$Trait1)


data_set$Isopair: Isopair-A

      trt    means M

1 STG     776.9167 a

2 Non-STG 779.0833 a

---------------------------------------------------------------------------

data_set$Isopair: Isopair-B

      trt    means M

1 STG     776.9167 a

2 Non-STG 779.0833 a

Data:
data_set<- structure(list(Field = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L), .Label = c("LML6", "TZL2"), class = "factor"), Isopair = structure(c(1L,
1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
1L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Isopair-A", "Isopair-B"
), class = "factor"), STGgroup = structure(c(1L, 1L, 1L, 2L,
2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
1L, 2L, 2L, 2L), .Label = c("Non-STG", "STG"), class = "factor"),
    Rep = structure(c(1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,
    2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L), .Label = c("Rep1",
    "Rep2", "Rep3"), class = "factor"), Trait1 = c(686L, 641L,
    642L, 727L, 619L, 562L, 808L, 739L, 744L, 873L, 797L, 868L,
    782L, 783L, 675L, 713L, 762L, 641L, 1009L, 995L, 845L, 1186L,
    912L, 663L), Trait2 = c(45L, 65L, 70L, 35L, 20L, 80L, 70L,
    65L, 70L, 20L, 30L, 35L, 40L, 55L, 35L, 40L, 35L, 40L, 40L,
    35L, 25L, 40L, 35L, 25L)), .Names = c("Field", "Isopair",
"STGgroup", "Rep", "Trait1", "Trait2"), class = "data.frame", row.names = c(NA,
-24L))

Session info:

R version 3.1.3 (2015-03-09)

Platform: i386-w64-mingw32/i386 (32-bit)

Running under: Windows 7 x64 (build 7601) Service Pack 1



locale:

[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252

[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C

[5] LC_TIME=English_United States.1252



attached base packages:

[1] grid      stats     graphics  grDevices utils     datasets  methods   base



other attached packages:

 [1] gridExtra_0.9.1 Hmisc_3.16-0    Formula_1.2-1   survival_2.38-1 caret_6.0-41    ggplot2_1.0.1

 [7] lattice_0.20-30 MASS_7.3-39     dplyr_0.4.1     agricolae_1.2-1



loaded via a namespace (and not attached):

 [1] acepack_1.3-3.3     assertthat_0.1      boot_1.3-15         BradleyTerry2_1.0-6

 [5] brglm_0.5-9         car_2.0-25          cluster_2.0.1       coda_0.17-1

 [9] codetools_0.2-10    colorspace_1.2-6    combinat_0.0-8      DBI_0.3.1

[13] deldir_0.1-9        digest_0.6.8        foreach_1.4.2       foreign_0.8-63

[17] gtable_0.1.2        gtools_3.4.1        iterators_1.0.7     klaR_0.6-12

[21] latticeExtra_0.6-26 lazyeval_0.1.10     LearnBayes_2.15     lme4_1.1-7

[25] magrittr_1.5        Matrix_1.1-5        mgcv_1.8-4          minqa_1.2.4

[29] munsell_0.4.2       nlme_3.1-120        nloptr_1.0.4        nnet_7.3-9

[33] parallel_3.1.3      pbkrtest_0.4-2      plyr_1.8.1          proto_0.3-10

[37] quantreg_5.11       RColorBrewer_1.1-2  Rcpp_0.11.6         reshape2_1.4.1

[41] rpart_4.1-9         scales_0.2.4        sp_1.0-17           SparseM_1.6

[45] spdep_0.5-88        splines_3.1.3       stringr_0.6.2       tools_3.1.3





This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled
to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and
all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.

All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its
subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying
this e-mail or any attachment.


The information contained in this email may be subject to the export control laws and regulations of the United States, potentially
including but not limited to the Export Administration Regulations (EAR) and sanctions regulations issued by the U.S. Department of
Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all
applicable U.S. export laws and regulations.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled
to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and
all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.

All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its
subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying
this e-mail or any attachment.


The information contained in this email may be subject to the export control laws and regulations of the United States, potentially
including but not limited to the Export Administration Regulations (EAR) and sanctions regulations issued by the U.S. Department of
Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all
applicable U.S. export laws and regulations.

	[[alternative HTML version deleted]]


From buezas.guido at gmail.com  Tue May 12 21:15:11 2015
From: buezas.guido at gmail.com (Guido Buezas)
Date: Tue, 12 May 2015 16:15:11 -0300
Subject: [R] Help on phylogenetic ANOVA functions
Message-ID: <CAFX2tmOccrE0ZTSk09MajUa9B8o9S+nS4kFMrUFe72r1tahnHA@mail.gmail.com>

Hi everyone:

I'm trying to do a phylogenetic ANOVA analysis, but i'm stuck with both
possibilities: phylANOVA from phytools package, and aov.phylo from geiger
package.

Here is what i have

Input data:
CSV file with columns:
Spp (categorical, for taxonomic species,, 29 species)
Fam (categorical, for taxonomic families)
IF (continuous, length ratio data ranging from 1 to 3 approx, 91 cases)

Phylogenetic tree. (Newick format, with distances, 29 species). I'm sure
that all species are both in phylo tree and in data.

My problems are:

phylANOVA didn't calculate post-hoc tests. All i got was an F and p, but
all results from post-hocs are NA.

aov.phylo won't stop saying:

'formula' must be of the form 'dat~group', where 'group' is a named factor
> vector and 'dat' is a data matrix or named vector"


When were made this way:

dat <- as.vector(data$IF)
names(dat)<-names(data$Spp)
group <- as.vector(data$Spp)
names(group)<-names(data$Spp)

I've googled and tried several ways to name the damned vectors, but it
keeps saying that. Like: names(OBJECT)<-c("name1", "name2",....)

Eventually, i could run it, i don't know how (and that bothers me). BUT,
something bad happened:

The following tips were not found in 'phy' and were dropped from 'data':
>

And viceversa for 'data' and 'phy'. So, analysis is restricted to F and p
values. When i try to make the juicy post-hoc tests (even when i don't know
if it will work), it fails saying that Tukey HSD is not appliable to lm
object.

Hope you understood me and my english, and can help me!

Thank you very much in advance

Guido, from Mar del Plata
-- 
Lic. Guido Buezas
Laboratorio de Morfolog?a Funcional y Comportamiento
IIMyC - UNMdP / CONICET

	[[alternative HTML version deleted]]


From kmwolf at ucdavis.edu  Tue May 12 21:15:37 2015
From: kmwolf at ucdavis.edu (Kristina Wolf)
Date: Tue, 12 May 2015 12:15:37 -0700
Subject: [R] geom_text in ggplot (position)
In-Reply-To: <20150512185048.Horde.nzIY56yNPzxwjRyuAd3FmQ1@webmail.um.es>
References: <20150512185048.Horde.nzIY56yNPzxwjRyuAd3FmQ1@webmail.um.es>
Message-ID: <CAHq6VpdC0Ku78kdDqQKm4r8RwWRVaQvuEamPsvu1a94+B1A55w@mail.gmail.com>

This may or may not be helpful, but you can create a dataframe with the
geom_text exactly where you want it to be (although it will probably be a
lot of extra work and will take time fiddling with it to see if you like
how it looks - and I think it looks fine the way you have it already).

Example for just one of the values, you would have to do this for each:

text75 <- data.frame(cO = factor("B", levels = c("A","B")), cat = "0",
recuento = 50, variables = factor("PE_35", levels = c("PE_35", "PE_49")))

                   ggplot(melted, aes(x = cat, y =
recuento,ymax=max(recuento)*1.05, fill =
                                        cO)) +
                     geom_bar(stat = 'identity', position = 'stack',
col="black") +
                     facet_grid(~ variables)+
                     geom_text(data = text75, label = "75", size = 10, face
= "bold")

*?~ Kristina*

??
Kristina Wolf
?
?
Ph.D. Candidate, Graduate Group in Ecology
M.S. Soil Science
?,
?
B.S. Animal Science?
?
KristinaMWolf.com
Restoration Ecology Lab
?
Department of Plant Sciences
?
University of California, Davis?
?
(530) 750-9771

"We have to remember that what we observe is not nature herself, but nature
exposed to our method of questioning." ~ Werner Heisenberg


On Tue, May 12, 2015 at 9:50 AM, AURORA GONZALEZ VIDAL <
aurora.gonzalez2 at um.es> wrote:

> Hello everybody.
>
> I have an "esthetic" question. I have managed to create a stacked and
> grouped bar plot but I don't manage with putting the text in the middle of
> the bar plots. Do you know how to write the numbers in that position?
>
> Thank you so much.
>
> Example code:
>
> test  <- data.frame(variables =  c("PE_35", "PE_49"),
>                     value1=c(13,3),
>                     value2=c(75,31),
>                     value3=c(7,17),
>                     value4 =c(5,49))
>
> library(reshape2) # for melt
>
> melted <- melt(test, "variables")
> melted$cO <- c("A","A","B","B","A","A","B","B")
>
> melted$cat <- ''
> melted[melted$variable == 'value1' | melted$variable == 'value2',]$cat <-
> "0"
> melted[melted$variable == 'value3' | melted$variable == 'value4',]$cat <-
> "1"
>
> names(melted)[3] <- "recuento"
>
> library(ggplot2)
>
> ggplot(melted, aes(x = cat, y = recuento,ymax=max(recuento)*1.05, fill =
> cO)) +
>   geom_bar(stat = 'identity', position = 'stack', col="black") +
> facet_grid(~ variables)+
>   geom_text(aes(label = recuento), size = 5, hjust = 0.5, vjust = 1,
> position ="stack")
>
>
> ------
> Aurora Gonz?lez Vidal
>
> Secci?n Apoyo Estad?stico.
> Servicio de Apoyo a la Investigaci?n (SAI).
> Vicerrectorado de Investigaci?n.
> Universidad de Murcia
> Edif. SACE . Campus de Espinardo.
> 30100 Murcia
>
> @. aurora.gonzalez2 at um.es
> T. 868 88 7315
> F. 868 88 7302
> www.um.es/sai
> www.um.es/ae
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From newrnewbie at hotmail.com  Tue May 12 21:56:24 2015
From: newrnewbie at hotmail.com (Vin Cheng)
Date: Tue, 12 May 2015 19:56:24 +0000
Subject: [R] binding two lists of lists of dataframes together
In-Reply-To: <17C25B6B-DDF7-4108-99C9-3DABC178C32F@comcast.net>
References: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>,
	<A2E1A0300F5.00001107jrkrideau@inbox.com>
	<BAY179-W63A3DF10922679A302B16D3DA0@phx.gbl>,
	<17C25B6B-DDF7-4108-99C9-3DABC178C32F@comcast.net>
Message-ID: <BAY179-W817CF1BB2EEC863DC596F5D3DA0@phx.gbl>

Hi,
 
Thanks David!  Your solution 3 worked well with the sample data, but when I run solution 2 & 3 on the actual data - it creates a list of 1 for each data point and it doesn't end up looking like the desired output for some reason.
 
I've run a dput on the actual data and pasted below.  There's a lot of data - so I'm only copying list1 - if the solution could bind list1 with itself - it should work just as well.  
 
Sorry for not providing an accurate sample the first time around - I thought the shortened version would be simpler and sufficient.
 
Any help/guidance would be greatly appreciated!
 
Many Thanks,
Vince
 
list1 <- structure(list(V1 = list(c(19L, 94L, 94L, 15L, 90L, 13L, 66L, 
17L, 45L, 69L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, 
NA, NA, NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 
0), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", "ID13", 
"ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", 
"ID21", "ID22", "ID23", "ID24", "ID25", "ID26", "ID27", "ID28", 
"ID29", "ID3", "ID30", "ID31", "ID32", "ID33", "ID34", "ID35", 
"ID36", "ID37", "ID38", "ID39", "ID4", "ID40", "ID41", "ID42", 
"ID43", "ID44", "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", 
"ID50", "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
"ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", "ID64", 
"ID65", "ID66", "ID67", "ID68", "ID69", "ID7", "ID70", "ID71", 
"ID72", "ID73", "ID74", "ID75", "ID76", "ID77", "ID78", "ID79", 
"ID8", "ID80", "ID81", "ID82", "ID83", "ID84", "ID85", "ID86", 
"ID87", "ID88", "ID89", "ID9", "ID90", "ID91", "ID92", "ID93", 
"ID94", "ID95", "ID96", "ID97", "ID98", "ID99"), class = "factor"), 
    structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
    ), .Label = c("Issuer1", "Issuer10", "Issuer100", "Issuer11", 
    "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
    "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", 
    "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", 
    "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", 
    "Issuer30", "Issuer31", "Issuer32", "Issuer33", "Issuer34", 
    "Issuer35", "Issuer36", "Issuer37", "Issuer38", "Issuer39", 
    "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
    "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", 
    "Issuer49", "Issuer5", "Issuer50", "Issuer51", "Issuer52", 
    "Issuer53", "Issuer54", "Issuer55", "Issuer56", "Issuer57", 
    "Issuer58", "Issuer59", "Issuer6", "Issuer60", "Issuer61", 
    "Issuer62", "Issuer63", "Issuer64", "Issuer65", "Issuer66", 
    "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
    "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", 
    "Issuer76", "Issuer77", "Issuer78", "Issuer79", "Issuer8", 
    "Issuer80", "Issuer81", "Issuer82", "Issuer83", "Issuer84", 
    "Issuer85", "Issuer86", "Issuer87", "Issuer88", "Issuer89", 
    "Issuer9", "Issuer90", "Issuer91", "Issuer92", "Issuer93", 
    "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
    "Issuer99"), class = "factor"), c(95.5, 98.5, 98.5, 99.5, 
    103.5, 98.563, 99.75, 98.5, 98.75, 99.125), c(97.5, 99.5, 
    99.5, 100.375, 104.5, 99.188, 100.25, 99.5, 99.75, 100.063
    ), c(2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 4L), c(4L, 5L, 5L, 
    5L, 5L, 2L, 3L, 5L, 3L, 2L), c(TRUE, FALSE, FALSE, TRUE, 
    FALSE, TRUE, TRUE, FALSE, FALSE, TRUE), structure(c(1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
    structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
    structure(c(9L, 2L, 2L, 1L, 2L, 1L, 3L, 3L, 5L, 9L), .Label = c("B", 
    "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
    ), class = "factor"), structure(c(8L, 2L, 2L, 1L, 8L, 2L, 
    2L, 2L, 1L, 7L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
    "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(20L, 
    88L, 88L, 6L, 3L, 35L, 29L, 24L, 53L, 82L), .Label = c("1/11/2019", 
    "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
    "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
    "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
    "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
    "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
    "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
    "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
    "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
    "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
    "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
    "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
    "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
    "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
    "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
    "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
    "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
    "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
    "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
    "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
    c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
    FALSE, FALSE), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 
    10L, 41L, 67L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
    "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
    "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
    "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
    "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
    "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
    "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
    "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
    "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
    "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
    "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
    "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
    "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
    "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
    "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
    "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
    "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
    "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
    "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
    "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
    "Issuer98", "Issuer99"), class = "factor"), structure(c(12L, 
    95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L), .Label = c("BL1", 
    "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
    "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
    "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
    "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
    "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
    "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
    "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
    "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
    "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
    "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
    "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
    "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
    "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(4L, 
    3L, 3L, 5L, 6L, 3L, 2L, 6L, 6L, 5L), .Label = c("Banking, Finance, Insurance & Real Estate", 
    "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
    "Retail", "Services: Business"), class = "factor"), structure(c(3L, 
    5L, 5L, 6L, 4L, 3L, 4L, 2L, 6L, 6L), .Label = c("Financial Intermediaries", 
    "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
    "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
    structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 6L, 8L, 8L), .Label = c("AU", 
    "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
    structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 5L, 6L, 6L), .Label = c("1", 
    "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
    structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L), .Label = c("Canada", 
    "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
    2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
    structure(c(2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
    "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
    c(0.125550168, 1.731733265, 1.731733265, NA, 5.246485518, 
    7.798802147, NA, NA, NA, NA), c(4770L, 3490L, 3490L, 3490L, 
    3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.45, 0.4, 0.4, 
    0.45, 0.55, 0.4, 0.4, 0.45, 0.4, 0.5), c(4770L, 3490L, 3490L, 
    3490L, 3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.55, 
    0.4, 0.4, 0.4, 0.55, 0.4, 0.5, 0.5, 0.45, 0.55), c(18L, 15L, 
    15L, 15L, 18L, 15L, 15L, 15L, 14L, 17L), c(17L, 16L, 16L, 
    15L, 14L, 15L, 15L, 15L, 14L, 15L), c(192500000, 205000000, 
    205000000, 342000000, 120000000, 835000000, 1043700000, 160000000, 
    300000000, 265000000), c(0.02, 0.02, 0.02, 0.4, 0.02, 0.4, 
    0.6, 0.6, 0.6, 0.02), c(850L, 475L, 475L, 500L, 1000L, 350L, 
    400L, 975L, 500L, 700L), c(1, 1.5, 1.5, 1, 1.25, 1, 1, 1, 
    1, 1), c(0.0851, 0.04765, 0.04765, 0.0501, 0.100125, 0.0351, 
    0.0401, 0.0976, 0.0501, 0.0701), c(0.099192999, 0.023321348, 
    0.023321348, 0.06465519, 0.103470278, 0.052237196, 0.051331755, 
    0.112300026, 0.066116739, 0.084107871), c(897.0917677, -1.49365213, 
    -1.49365213, 549.0886934, 975.9481504, 429.1863229, 436.2991366, 
    1062.374805, 567.0741295, 747.1023728), c(0.088186528, 0.048131313, 
    0.048131313, 0.050131332, 0.096274038, 0.035499188, 0.040049938, 
    0.098585859, 0.050478589, 0.070385766), c(0L, 0L, 0L, 0L, 
    0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
    c(0.0178406708595388, 0.0136532951289398, 0.0136532951289398, 
    0.0143553008595989, 0.028689111747851, 0.0100573065902579, 
    0.0180630630630631, 0.043963963963964, 0.0225675675675676, 
    0.0200859598853868), c(0.046805, 0.01906, 0.01906, 0.02004, 
    0.05506875, 0.01404, 0.02005, 0.0488, 0.022545, 0.038555), 
    c(0.001702, 0.000953, 0.000953, 0.02004, 0.0020025, 0.01404, 
    0.02406, 0.05856, 0.03006, 0.001402)), V2 = list(c(93L, 3L, 
85L, 34L, 20L, 89L, 16L, 25L, 83L, 90L), c(1, 1, 2, 3, 4, 5, 
6, 7, 8, 9), c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), c(0, 
0, 0, 0, 0, 0, 0, 0, 0, 0), structure(c(94L, 24L, 85L, 29L, 14L, 
89L, 9L, 19L, 83L, 91L), .Label = c("ID1", "ID10", "ID100", "ID11", 
"ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
"ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
"ID27", "ID28", "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", 
"ID34", "ID35", "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", 
"ID41", "ID42", "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", 
"ID49", "ID5", "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", 
"ID56", "ID57", "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", 
"ID63", "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
"ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", 
"ID78", "ID79", "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", 
"ID85", "ID86", "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", 
"ID92", "ID93", "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"
), class = "factor"), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
"Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
"Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
"Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
"Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", "Issuer32", 
"Issuer33", "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
"Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
"Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", "Issuer49", 
"Issuer5", "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
"Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", "Issuer6", 
"Issuer60", "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
"Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
"Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", "Issuer76", 
"Issuer77", "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
"Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", "Issuer87", 
"Issuer88", "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
"Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
"Issuer99"), class = "factor"), c(99.5, 99.646, 100.402, 100.25, 
98, 99.563, 99.563, 99.388, 99.531, 103.5), c(100.5, 100.271, 
100.903, 100.75, 99, 100.188, 100.063, 99.788, 100.125, 104.5
), c(1L, 6L, 9L, 1L, 1L, 2L, 2L, 10L, 4L, 2L), c(5L, 2L, 1L, 
3L, 3L, 4L, 4L, 1L, 1L, 5L), c(TRUE, TRUE, FALSE, FALSE, TRUE, 
FALSE, FALSE, TRUE, TRUE, FALSE), structure(c(1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
    structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
    structure(c(8L, 1L, 4L, 1L, 3L, 4L, 6L, 1L, 5L, 2L), .Label = c("B", 
    "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
    ), class = "factor"), structure(c(7L, 2L, 5L, 2L, 1L, 2L, 
    6L, 1L, 5L, 8L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
    "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(41L, 
    1L, 13L, 43L, 21L, 87L, 49L, 73L, 46L, 3L), .Label = c("1/11/2019", 
    "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
    "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
    "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
    "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
    "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
    "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
    "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
    "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
    "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
    "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
    "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
    "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
    "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
    "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
    "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
    "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
    "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
    "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
    "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
    c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
    FALSE, FALSE), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
    9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
    "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
    "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
    "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
    "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
    "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
    "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
    "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
    "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
    "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
    "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
    "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
    "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
    "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
    "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
    "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
    "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
    "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
    "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
    "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
    "Issuer98", "Issuer99"), class = "factor"), structure(c(94L, 
    24L, 85L, 29L, 14L, 89L, 9L, 19L, 83L, 91L), .Label = c("BL1", 
    "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
    "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
    "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
    "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
    "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
    "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
    "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
    "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
    "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
    "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
    "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
    "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
    "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(2L, 
    2L, 3L, 6L, 1L, 6L, 6L, 6L, 1L, 6L), .Label = c("Banking, Finance, Insurance & Real Estate", 
    "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
    "Retail", "Services: Business"), class = "factor"), structure(c(6L, 
    6L, 3L, 5L, 1L, 2L, 5L, 3L, 2L, 4L), .Label = c("Financial Intermediaries", 
    "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
    "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
    structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L), .Label = c("AU", 
    "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
    structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label = c("1", 
    "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
    structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("Canada", 
    "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
    structure(c(2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
    "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
    c(2.603554841, 7.27032758, 3.155438813, 5.037267081, 0.125550168, 
    NA, 3.464301168, NA, 4.816376964, 5.246485518), c(2220L, 
    2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 2220L, 3490L
    ), c(0.55, 0.45, 0.5, 0.4, 0.6, 0.45, 0.45, 0.55, 0.2, 0.55
    ), c(2220L, 2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 
    2220L, 3490L), c(0.55, 0.45, 0.5, 0.4, 0.3, 0.45, 0.45, 0.4, 
    0.2, 0.55), c(17L, 15L, 12L, 15L, 14L, 15L, 13L, 14L, 12L, 
    18L), c(16L, 16L, 14L, 16L, 15L, 12L, 13L, 15L, 14L, 14L), 
    c(200000000, 613811406, 750000000, 200000000, 405500000, 
    450000000, 530000000, 2010000000, 775000000, 120000000), 
    c(0.02, 0.5, 0.65, 0.27, 0.5, 0.65, 0.65, 0.3, 0.65, 0.02
    ), c(950L, 350L, 350L, 275L, 450L, 275L, 225L, 325L, 275L, 
    1000L), c(1.25, 1, 0.75, 0.75, 1, 0.75, 0, 1, 0.75, 1.25), 
    c(0.095125, 0.0351, 0.035075, 0.027575, 0.0451, 0.027575, 
    0.02527, 0.0326, 0.027575, 0.100125), c(0.104211455, 0.046414939, 
    0.050338657, 0.027233401, 0.059885473, 0.03459045, 0.028669191, 
    0.048294163, 0.040935438, 0.103470278), c(980.5501911, 400.3544693, 
    385.8629241, 244.6340073, 511.2711809, 294.3073789, 194.2034583, 
    385.9437059, 308.4324006, 975.9481504), c(0.095125, 0.035114573, 
    0.034847619, 0.027437811, 0.045786802, 0.027609374, 0.025317343, 
    0.032734868, 0.027622511, 0.096274038), c(0L, 0L, 0L, 0L, 
    0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
    c(0.0428490990990991, 0.0158108108108108, 0.037313829787234, 
    0.00790114613180516, 0.00945492662473794, 0.0124211711711712, 
    0.0143091732729332, 0.00934097421203438, 0.0124211711711712, 
    0.028689111747851), c(0.05231875, 0.015795, 0.0175375, 0.01103, 
    0.01353, 0.01240875, 0.0113715, 0.01304, 0.005515, 0.05506875
    ), c(0.0019025, 0.01755, 0.02279875, 0.00744525, 0.02255, 
    0.01792375, 0.0164255, 0.00978, 0.01792375, 0.0020025)), 
    V3 = list(c(47L, 95L, 26L, 64L, 16L, 55L, 61L, 39L, 23L, 
    66L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, NA, NA, 
    NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
        structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 
        64L), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", 
        "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
        "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", 
        "ID26", "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", 
        "ID32", "ID33", "ID34", "ID35", "ID36", "ID37", "ID38", 
        "ID39", "ID4", "ID40", "ID41", "ID42", "ID43", "ID44", 
        "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", "ID50", 
        "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
        "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", 
        "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
        "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", 
        "ID77", "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", 
        "ID83", "ID84", "ID85", "ID86", "ID87", "ID88", "ID89", 
        "ID9", "ID90", "ID91", "ID92", "ID93", "ID94", "ID95", 
        "ID96", "ID97", "ID98", "ID99"), class = "factor"), structure(c(43L, 
        96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("Issuer1", 
        "Issuer10", "Issuer100", "Issuer11", "Issuer12", "Issuer13", 
        "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", 
        "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", 
        "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
        "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", 
        "Issuer32", "Issuer33", "Issuer34", "Issuer35", "Issuer36", 
        "Issuer37", "Issuer38", "Issuer39", "Issuer4", "Issuer40", 
        "Issuer41", "Issuer42", "Issuer43", "Issuer44", "Issuer45", 
        "Issuer46", "Issuer47", "Issuer48", "Issuer49", "Issuer5", 
        "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
        "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", 
        "Issuer6", "Issuer60", "Issuer61", "Issuer62", "Issuer63", 
        "Issuer64", "Issuer65", "Issuer66", "Issuer67", "Issuer68", 
        "Issuer69", "Issuer7", "Issuer70", "Issuer71", "Issuer72", 
        "Issuer73", "Issuer74", "Issuer75", "Issuer76", "Issuer77", 
        "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
        "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", 
        "Issuer87", "Issuer88", "Issuer89", "Issuer9", "Issuer90", 
        "Issuer91", "Issuer92", "Issuer93", "Issuer94", "Issuer95", 
        "Issuer96", "Issuer97", "Issuer98", "Issuer99"), class = "factor"), 
        c(99.688, 75.667, 99.229, 99.583, 99.563, 99.188, 98.8, 
        98.5, 99, 99.75), c(100.281, 78.667, 100.104, 100.333, 
        100.063, 99.906, 99.75, 99.5, 99.75, 100.25), c(4L, 3L, 
        6L, 3L, 2L, 4L, 5L, 1L, 1L, 1L), c(4L, 3L, 1L, 3L, 4L, 
        2L, 4L, 5L, 3L, 3L), c(FALSE, TRUE, TRUE, TRUE, FALSE, 
        TRUE, TRUE, FALSE, TRUE, TRUE), structure(c(1L, 1L, 1L, 
        1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
        structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
        structure(c(3L, 8L, 9L, 1L, 6L, 3L, 10L, 10L, 9L, 3L), .Label = c("B", 
        "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", 
        "NR"), class = "factor"), structure(c(6L, 7L, 7L, 2L, 
        6L, 1L, 9L, 9L, 8L, 2L), .Label = c("B1", "B2", "B3", 
        "Ba1", "Ba2", "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), 
        structure(c(66L, 80L, 74L, 30L, 49L, 72L, 70L, 62L, 10L, 
        29L), .Label = c("1/11/2019", "1/2/2019", "1/2/2020", 
        "1/30/2022", "10/15/2016", "10/15/2021", "10/17/2019", 
        "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
        "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", 
        "11/12/2020", "11/20/2019", "11/20/2020", "11/27/2020", 
        "11/5/2021", "11/6/2020", "11/9/2017", "11/9/2018", "12/15/2018", 
        "12/15/2021", "12/15/2022", "12/16/2019", "12/18/2020", 
        "12/20/2019", "12/7/2018", "12/7/2019", "2/12/2021", 
        "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", "2/24/2017", 
        "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", "3/21/2019", 
        "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", "4/30/2018", 
        "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", "5/15/2018", 
        "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", "5/8/2020", 
        "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", "6/2/2019", 
        "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", "6/30/2017", 
        "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", "7/10/2020", 
        "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", "7/29/2022", 
        "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", "8/12/2021", 
        "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", "8/24/2017", 
        "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", "9/18/2016", 
        "9/18/2019", "9/20/2019"), class = "factor"), c(FALSE, 
        FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
        FALSE), structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 
        34L, 17L, 64L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
        "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
        "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
        "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
        "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
        "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
        "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
        "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
        "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
        "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
        "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
        "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
        "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
        "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
        "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
        "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
        "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
        "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
        "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
        "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
        "Issuer98", "Issuer99"), class = "factor"), structure(c(43L, 
        96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("BL1", 
        "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
        "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", 
        "BL22", "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", 
        "BL29", "BL3", "BL30", "BL31", "BL32", "BL33", "BL34", 
        "BL35", "BL36", "BL37", "BL38", "BL39", "BL4", "BL40", 
        "BL41", "BL42", "BL43", "BL44", "BL45", "BL46", "BL47", 
        "BL48", "BL49", "BL5", "BL50", "BL51", "BL52", "BL53", 
        "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", "BL6", 
        "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
        "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", 
        "BL73", "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", 
        "BL8", "BL80", "BL81", "BL82", "BL83", "BL84", "BL85", 
        "BL86", "BL87", "BL88", "BL89", "BL9", "BL90", "BL91", 
        "BL92", "BL93", "BL94", "BL95", "BL96", "BL97", "BL98", 
        "BL99"), class = "factor"), structure(c(1L, 6L, 6L, 4L, 
        6L, 4L, 6L, 2L, 6L, 2L), .Label = c("Banking, Finance, Insurance & Real Estate", 
        "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
        "Retail", "Services: Business"), class = "factor"), structure(c(2L, 
        2L, 1L, 5L, 5L, 3L, 3L, 6L, 2L, 4L), .Label = c("Financial Intermediaries", 
        "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
        "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
        structure(c(8L, 8L, 8L, 8L, 8L, 8L, 5L, 8L, 8L, 8L), .Label = c("AU", 
        "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
        structure(c(6L, 6L, 6L, 6L, 6L, 6L, 3L, 6L, 6L, 6L), .Label = c("1", 
        "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
        structure(c(4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L, 4L), .Label = c("Canada", 
        "Europe", "Other", "U.S."), class = "factor"), structure(c(2L, 
        1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), .Label = c("N", 
        "Y"), class = "factor"), structure(c(1L, 2L, 2L, 1L, 
        1L, 1L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
        structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
        c(8.74248921, NA, NA, 4.338507174, 3.464301168, NA, NA, 
        NA, NA, NA), c(2220L, 2220L, 3490L, 3490L, 1766L, 2220L, 
        8070L, 8070L, 3490L, 2220L), c(0.6, 0.55, 0.4, 0.4, 0.45, 
        0.45, 0.4, 0.45, 0.6, 0.4), c(2220L, 2220L, 3490L, 3490L, 
        1766L, 2220L, 8070L, 8070L, 3490L, 2220L), c(0.3, 0.55, 
        0.55, 0.4, 0.45, 0.4, 0.45, 0.3, 0.55, 0.5), c(13L, 17L, 
        17L, 15L, 13L, 14L, 19L, 19L, 18L, 15L), c(15L, 16L, 
        15L, 15L, 13L, 14L, 19L, 19L, 15L, 15L), c(625000000, 
        450000000, 760000000, 630000000, 530000000, 671500000, 
        240000000, 100000000, 375000000, 1043700000), c(0.5, 
        0.02, 0.02, 0.3, 0.65, 0.3, 0.5, 0.65, 0.02, 0.6), c(275L, 
        750L, 650L, 300L, 225L, 300L, 700L, 925L, 825L, 400L), 
        c(0, 1, 1, 1.25, 0, 1, 1, 1.25, 1.25, 1), c(0.03027, 
        0.0751, 0.0651, 0.030125, 0.02527, 0.0301, 0.0701, 0.092625, 
        0.082625, 0.0401), c(0.031286195, 0.154827358, 0.080695261, 
        0.041683558, 0.028669191, 0.044131997, 0.084009559, 0.108958135, 
        0.090916682, 0.051331755), c(263.290277, 1448.101305, 
        704.3633733, 368.0708419, 194.2034583, 356.3784942, 746.772345, 
        1036.334285, 875.917553, 436.2991366), c(0.030274693, 
        0.097321394, 0.065317835, 0.030137658, 0.025317343, 0.030236973, 
        0.070611937, 0.093560606, 0.083144654, 0.040049938), 
        c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 
        1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), 
        structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
        c(0.0136351351351351, 0.0338288288288288, 0.0186532951289398, 
        0.00863180515759312, 0.0143091732729332, 0.0135585585585586, 
        0.00868649318463445, 0.0114776951672862, 0.0236747851002865, 
        0.0180630630630631), c(0.009081, 0.041305, 0.035805, 
        0.01205, 0.0113715, 0.01204, 0.031545, 0.0277875, 0.04544375, 
        0.02005), c(0.015135, 0.001502, 0.001302, 0.0090375, 
        0.0164255, 0.00903, 0.03505, 0.06020625, 0.0016525, 0.02406
        ))), .Names = c("V1", "V2", "V3"), row.names = c(NA, 
-48L), class = c("data.table", "data.frame"))
 

 
> Subject: Re: [R] binding two lists of lists of dataframes together
> From: dwinsemius at comcast.net
> Date: Tue, 12 May 2015 11:36:50 -0700
> CC: r-help at r-project.org
> To: newrnewbie at hotmail.com
> 
> 
> On May 12, 2015, at 9:24 AM, Vin Cheng wrote:
> 
> > list1<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L), 
> >                     WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> >                     Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> >                .Names = c("id", "WgtBand", "Wgt")), 
> >      structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
> >                     WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
> >                     Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> >                .Names = c("id", "WgtBand", "Wgt")), 
> >      structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
> >                     WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
> >                     Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> >                .Names = c("id", "WgtBand", "Wgt")))
> > 
> > 
> > list2<-list(structure(list(id = c(493L, 564L, 147L), 
> >                            WgtBand = c(1, 2, 3), 
> >                            Wgt = c(NaN, NaN, NA)), 
> >                       .Names = c("id", "WgtBand", "Wgt")), 
> >             structure(list(id = c(276L, 411L, 574L,111L), 
> >                            WgtBand = c(1, 2, 3,4), 
> >                            Wgt = c(NaN, NaN, NA,NA)), 
> >                       .Names = c("id", "WgtBand", "Wgt")), 
> >             structure(list(id = c(76L, 330L), 
> >                            WgtBand = c(1, 1), 
> >                            Wgt = c(NaN, NaN)), 
> >                       .Names = c("id", "WgtBand", "Wgt")))
> > 
> > list3<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L,493L, 564L, 147L), 
> >                            WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9,1, 2, 3), 
> >                            Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA)), 
> >                       .Names = c("id", "WgtBand", "Wgt")), 
> >             structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,276L, 411L, 574L,111L), 
> >                            WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 2, 3,4), 
> >                            Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA,NA)), 
> >                       .Names = c("id", "WgtBand", "Wgt")), 
> >             structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,76L, 330L), 
> >                            WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 1), 
> >                            Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN)), 
> >                       .Names = c("id", "WgtBand", "Wgt")))
> 
> I get something like the desired structure with:
> 
> mapply(function(x,y) mapply(c, x,y), list1,list2)
> 
> I can make it closer with:
> 
> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) unclass( as.data.frame(x) ) )
> 
> 
> Or even closer with:
> 
> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) as.list( as.data.frame(x) ) )
> 
> `identical` does not return TRUE but I cannot see where the difference lies.
> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
 		 	   		  
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue May 12 23:23:54 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 12 May 2015 14:23:54 -0700
Subject: [R] binding two lists of lists of dataframes together
In-Reply-To: <BAY179-W817CF1BB2EEC863DC596F5D3DA0@phx.gbl>
References: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>,
	<A2E1A0300F5.00001107jrkrideau@inbox.com>
	<BAY179-W63A3DF10922679A302B16D3DA0@phx.gbl>,
	<17C25B6B-DDF7-4108-99C9-3DABC178C32F@comcast.net>
	<BAY179-W817CF1BB2EEC863DC596F5D3DA0@phx.gbl>
Message-ID: <1084ED86-44F2-4717-9879-4A8A368FE00A@comcast.net>


On May 12, 2015, at 12:56 PM, Vin Cheng wrote:

> Hi,
> 
> Thanks David!  Your solution 3 worked well with the sample data, but when I run solution 2 & 3 on the actual data - it creates a list of 1 for each data point and it doesn't end up looking like the desired output for some reason.
> 
> I've run a dput on the actual data and pasted below.  There's a lot of data - so I'm only copying list1 - if the solution could bind list1 with itself - it should work just as well.  
> 
> Sorry for not providing an accurate sample the first time around - I thought the shortened version would be simpler and sufficient.
> 
> Any help/guidance would be greatly appreciated!
> 

This appears to be three similarly structured lists of various classes but fortunately for this effort the factor variables in corresponding columns all have the same levels. (Otherwise one would need to convert to character before attempting to stack them.)

I would just use `rbind.data.frame` (after making them dataframes with the same column names.)


dlist <- lapply( list1, function(d) setNames( data.frame(d), paste0("V", 1:48) ))
boundlist <- do.call(rbind, dlist)

# Done.

-- 
David.
> Many Thanks,
> Vince
> 
> list1 <- structure(list(V1 = list(c(19L, 94L, 94L, 15L, 90L, 13L, 66L, 
> 17L, 45L, 69L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, 
> NA, NA, NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 
> 0), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
> ), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", "ID13", 
> "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", 
> "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", "ID27", "ID28", 
> "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", "ID34", "ID35", 
> "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", "ID41", "ID42", 
> "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", 
> "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
> "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", "ID64", 
> "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", "ID70", "ID71", 
> "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", "ID78", "ID79", 
> "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", "ID85", "ID86", 
> "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", "ID92", "ID93", 
> "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"), class = "factor"), 
>    structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
>    ), .Label = c("Issuer1", "Issuer10", "Issuer100", "Issuer11", 
>    "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
>    "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", 
>    "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", 
>    "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", 
>    "Issuer30", "Issuer31", "Issuer32", "Issuer33", "Issuer34", 
>    "Issuer35", "Issuer36", "Issuer37", "Issuer38", "Issuer39", 
>    "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
>    "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", 
>    "Issuer49", "Issuer5", "Issuer50", "Issuer51", "Issuer52", 
>    "Issuer53", "Issuer54", "Issuer55", "Issuer56", "Issuer57", 
>    "Issuer58", "Issuer59", "Issuer6", "Issuer60", "Issuer61", 
>    "Issuer62", "Issuer63", "Issuer64", "Issuer65", "Issuer66", 
>    "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
>    "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", 
>    "Issuer76", "Issuer77", "Issuer78", "Issuer79", "Issuer8", 
>    "Issuer80", "Issuer81", "Issuer82", "Issuer83", "Issuer84", 
>    "Issuer85", "Issuer86", "Issuer87", "Issuer88", "Issuer89", 
>    "Issuer9", "Issuer90", "Issuer91", "Issuer92", "Issuer93", 
>    "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
>    "Issuer99"), class = "factor"), c(95.5, 98.5, 98.5, 99.5, 
>    103.5, 98.563, 99.75, 98.5, 98.75, 99.125), c(97.5, 99.5, 
>    99.5, 100.375, 104.5, 99.188, 100.25, 99.5, 99.75, 100.063
>    ), c(2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 4L), c(4L, 5L, 5L, 
>    5L, 5L, 2L, 3L, 5L, 3L, 2L), c(TRUE, FALSE, FALSE, TRUE, 
>    FALSE, TRUE, TRUE, FALSE, FALSE, TRUE), structure(c(1L, 1L, 
>    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
>    structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
>    structure(c(9L, 2L, 2L, 1L, 2L, 1L, 3L, 3L, 5L, 9L), .Label = c("B", 
>    "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
>    ), class = "factor"), structure(c(8L, 2L, 2L, 1L, 8L, 2L, 
>    2L, 2L, 1L, 7L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
>    "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(20L, 
>    88L, 88L, 6L, 3L, 35L, 29L, 24L, 53L, 82L), .Label = c("1/11/2019", 
>    "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
>    "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
>    "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
>    "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
>    "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
>    "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
>    "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
>    "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
>    "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
>    "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
>    "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
>    "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
>    "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
>    "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
>    "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
>    "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
>    "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
>    "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
>    "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
>    c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
>    FALSE, FALSE), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 
>    10L, 41L, 67L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
>    "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
>    "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
>    "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
>    "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
>    "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
>    "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
>    "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
>    "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
>    "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
>    "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
>    "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
>    "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
>    "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
>    "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
>    "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
>    "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
>    "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
>    "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
>    "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
>    "Issuer98", "Issuer99"), class = "factor"), structure(c(12L, 
>    95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L), .Label = c("BL1", 
>    "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
>    "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
>    "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
>    "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
>    "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
>    "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
>    "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
>    "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
>    "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
>    "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
>    "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
>    "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
>    "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(4L, 
>    3L, 3L, 5L, 6L, 3L, 2L, 6L, 6L, 5L), .Label = c("Banking, Finance, Insurance & Real Estate", 
>    "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
>    "Retail", "Services: Business"), class = "factor"), structure(c(3L, 
>    5L, 5L, 6L, 4L, 3L, 4L, 2L, 6L, 6L), .Label = c("Financial Intermediaries", 
>    "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
>    "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
>    structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 6L, 8L, 8L), .Label = c("AU", 
>    "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
>    structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 5L, 6L, 6L), .Label = c("1", 
>    "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
>    structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L), .Label = c("Canada", 
>    "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
>    2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
>    structure(c(2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
>    "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
>    1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
>    c(0.125550168, 1.731733265, 1.731733265, NA, 5.246485518, 
>    7.798802147, NA, NA, NA, NA), c(4770L, 3490L, 3490L, 3490L, 
>    3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.45, 0.4, 0.4, 
>    0.45, 0.55, 0.4, 0.4, 0.45, 0.4, 0.5), c(4770L, 3490L, 3490L, 
>    3490L, 3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.55, 
>    0.4, 0.4, 0.4, 0.55, 0.4, 0.5, 0.5, 0.45, 0.55), c(18L, 15L, 
>    15L, 15L, 18L, 15L, 15L, 15L, 14L, 17L), c(17L, 16L, 16L, 
>    15L, 14L, 15L, 15L, 15L, 14L, 15L), c(192500000, 205000000, 
>    205000000, 342000000, 120000000, 835000000, 1043700000, 160000000, 
>    300000000, 265000000), c(0.02, 0.02, 0.02, 0.4, 0.02, 0.4, 
>    0.6, 0.6, 0.6, 0.02), c(850L, 475L, 475L, 500L, 1000L, 350L, 
>    400L, 975L, 500L, 700L), c(1, 1.5, 1.5, 1, 1.25, 1, 1, 1, 
>    1, 1), c(0.0851, 0.04765, 0.04765, 0.0501, 0.100125, 0.0351, 
>    0.0401, 0.0976, 0.0501, 0.0701), c(0.099192999, 0.023321348, 
>    0.023321348, 0.06465519, 0.103470278, 0.052237196, 0.051331755, 
>    0.112300026, 0.066116739, 0.084107871), c(897.0917677, -1.49365213, 
>    -1.49365213, 549.0886934, 975.9481504, 429.1863229, 436.2991366, 
>    1062.374805, 567.0741295, 747.1023728), c(0.088186528, 0.048131313, 
>    0.048131313, 0.050131332, 0.096274038, 0.035499188, 0.040049938, 
>    0.098585859, 0.050478589, 0.070385766), c(0L, 0L, 0L, 0L, 
>    0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
>    1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
>    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
>    c(0.0178406708595388, 0.0136532951289398, 0.0136532951289398, 
>    0.0143553008595989, 0.028689111747851, 0.0100573065902579, 
>    0.0180630630630631, 0.043963963963964, 0.0225675675675676, 
>    0.0200859598853868), c(0.046805, 0.01906, 0.01906, 0.02004, 
>    0.05506875, 0.01404, 0.02005, 0.0488, 0.022545, 0.038555), 
>    c(0.001702, 0.000953, 0.000953, 0.02004, 0.0020025, 0.01404, 
>    0.02406, 0.05856, 0.03006, 0.001402)), V2 = list(c(93L, 3L, 
> 85L, 34L, 20L, 89L, 16L, 25L, 83L, 90L), c(1, 1, 2, 3, 4, 5, 
> 6, 7, 8, 9), c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), c(0, 
> 0, 0, 0, 0, 0, 0, 0, 0, 0), structure(c(94L, 24L, 85L, 29L, 14L, 
> 89L, 9L, 19L, 83L, 91L), .Label = c("ID1", "ID10", "ID100", "ID11", 
> "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
> "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", 
> "ID34", "ID35", "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", 
> "ID41", "ID42", "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", 
> "ID49", "ID5", "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", 
> "ID56", "ID57", "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", 
> "ID63", "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
> "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", 
> "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", 
> "ID85", "ID86", "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", 
> "ID92", "ID93", "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"
> ), class = "factor"), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
> 9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
> "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
> "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", "Issuer32", 
> "Issuer33", "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
> "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", "Issuer49", 
> "Issuer5", "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
> "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", "Issuer6", 
> "Issuer60", "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
> "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", "Issuer76", 
> "Issuer77", "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
> "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", "Issuer87", 
> "Issuer88", "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
> "Issuer99"), class = "factor"), c(99.5, 99.646, 100.402, 100.25, 
> 98, 99.563, 99.563, 99.388, 99.531, 103.5), c(100.5, 100.271, 
> 100.903, 100.75, 99, 100.188, 100.063, 99.788, 100.125, 104.5
> ), c(1L, 6L, 9L, 1L, 1L, 2L, 2L, 10L, 4L, 2L), c(5L, 2L, 1L, 
> 3L, 3L, 4L, 4L, 1L, 1L, 5L), c(TRUE, TRUE, FALSE, FALSE, TRUE, 
> FALSE, FALSE, TRUE, TRUE, FALSE), structure(c(1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
>    structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
>    structure(c(8L, 1L, 4L, 1L, 3L, 4L, 6L, 1L, 5L, 2L), .Label = c("B", 
>    "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
>    ), class = "factor"), structure(c(7L, 2L, 5L, 2L, 1L, 2L, 
>    6L, 1L, 5L, 8L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
>    "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(41L, 
>    1L, 13L, 43L, 21L, 87L, 49L, 73L, 46L, 3L), .Label = c("1/11/2019", 
>    "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
>    "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
>    "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
>    "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
>    "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
>    "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
>    "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
>    "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
>    "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
>    "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
>    "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
>    "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
>    "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
>    "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
>    "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
>    "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
>    "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
>    "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
>    "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
>    c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
>    FALSE, FALSE), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
>    9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
>    "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
>    "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
>    "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
>    "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
>    "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
>    "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
>    "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
>    "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
>    "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
>    "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
>    "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
>    "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
>    "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
>    "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
>    "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
>    "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
>    "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
>    "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
>    "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
>    "Issuer98", "Issuer99"), class = "factor"), structure(c(94L, 
>    24L, 85L, 29L, 14L, 89L, 9L, 19L, 83L, 91L), .Label = c("BL1", 
>    "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
>    "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
>    "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
>    "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
>    "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
>    "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
>    "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
>    "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
>    "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
>    "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
>    "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
>    "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
>    "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(2L, 
>    2L, 3L, 6L, 1L, 6L, 6L, 6L, 1L, 6L), .Label = c("Banking, Finance, Insurance & Real Estate", 
>    "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
>    "Retail", "Services: Business"), class = "factor"), structure(c(6L, 
>    6L, 3L, 5L, 1L, 2L, 5L, 3L, 2L, 4L), .Label = c("Financial Intermediaries", 
>    "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
>    "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
>    structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L), .Label = c("AU", 
>    "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
>    structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label = c("1", 
>    "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
>    structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("Canada", 
>    "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
>    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
>    structure(c(2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
>    "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
>    1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
>    c(2.603554841, 7.27032758, 3.155438813, 5.037267081, 0.125550168, 
>    NA, 3.464301168, NA, 4.816376964, 5.246485518), c(2220L, 
>    2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 2220L, 3490L
>    ), c(0.55, 0.45, 0.5, 0.4, 0.6, 0.45, 0.45, 0.55, 0.2, 0.55
>    ), c(2220L, 2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 
>    2220L, 3490L), c(0.55, 0.45, 0.5, 0.4, 0.3, 0.45, 0.45, 0.4, 
>    0.2, 0.55), c(17L, 15L, 12L, 15L, 14L, 15L, 13L, 14L, 12L, 
>    18L), c(16L, 16L, 14L, 16L, 15L, 12L, 13L, 15L, 14L, 14L), 
>    c(200000000, 613811406, 750000000, 200000000, 405500000, 
>    450000000, 530000000, 2010000000, 775000000, 120000000), 
>    c(0.02, 0.5, 0.65, 0.27, 0.5, 0.65, 0.65, 0.3, 0.65, 0.02
>    ), c(950L, 350L, 350L, 275L, 450L, 275L, 225L, 325L, 275L, 
>    1000L), c(1.25, 1, 0.75, 0.75, 1, 0.75, 0, 1, 0.75, 1.25), 
>    c(0.095125, 0.0351, 0.035075, 0.027575, 0.0451, 0.027575, 
>    0.02527, 0.0326, 0.027575, 0.100125), c(0.104211455, 0.046414939, 
>    0.050338657, 0.027233401, 0.059885473, 0.03459045, 0.028669191, 
>    0.048294163, 0.040935438, 0.103470278), c(980.5501911, 400.3544693, 
>    385.8629241, 244.6340073, 511.2711809, 294.3073789, 194.2034583, 
>    385.9437059, 308.4324006, 975.9481504), c(0.095125, 0.035114573, 
>    0.034847619, 0.027437811, 0.045786802, 0.027609374, 0.025317343, 
>    0.032734868, 0.027622511, 0.096274038), c(0L, 0L, 0L, 0L, 
>    0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
>    1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
>    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
>    c(0.0428490990990991, 0.0158108108108108, 0.037313829787234, 
>    0.00790114613180516, 0.00945492662473794, 0.0124211711711712, 
>    0.0143091732729332, 0.00934097421203438, 0.0124211711711712, 
>    0.028689111747851), c(0.05231875, 0.015795, 0.0175375, 0.01103, 
>    0.01353, 0.01240875, 0.0113715, 0.01304, 0.005515, 0.05506875
>    ), c(0.0019025, 0.01755, 0.02279875, 0.00744525, 0.02255, 
>    0.01792375, 0.0164255, 0.00978, 0.01792375, 0.0020025)), 
>    V3 = list(c(47L, 95L, 26L, 64L, 16L, 55L, 61L, 39L, 23L, 
>    66L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, NA, NA, 
>    NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
>        structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 
>        64L), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", 
>        "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
>        "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", 
>        "ID26", "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", 
>        "ID32", "ID33", "ID34", "ID35", "ID36", "ID37", "ID38", 
>        "ID39", "ID4", "ID40", "ID41", "ID42", "ID43", "ID44", 
>        "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", "ID50", 
>        "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
>        "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", 
>        "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
>        "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", 
>        "ID77", "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", 
>        "ID83", "ID84", "ID85", "ID86", "ID87", "ID88", "ID89", 
>        "ID9", "ID90", "ID91", "ID92", "ID93", "ID94", "ID95", 
>        "ID96", "ID97", "ID98", "ID99"), class = "factor"), structure(c(43L, 
>        96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("Issuer1", 
>        "Issuer10", "Issuer100", "Issuer11", "Issuer12", "Issuer13", 
>        "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", 
>        "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", 
>        "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
>        "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", 
>        "Issuer32", "Issuer33", "Issuer34", "Issuer35", "Issuer36", 
>        "Issuer37", "Issuer38", "Issuer39", "Issuer4", "Issuer40", 
>        "Issuer41", "Issuer42", "Issuer43", "Issuer44", "Issuer45", 
>        "Issuer46", "Issuer47", "Issuer48", "Issuer49", "Issuer5", 
>        "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
>        "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", 
>        "Issuer6", "Issuer60", "Issuer61", "Issuer62", "Issuer63", 
>        "Issuer64", "Issuer65", "Issuer66", "Issuer67", "Issuer68", 
>        "Issuer69", "Issuer7", "Issuer70", "Issuer71", "Issuer72", 
>        "Issuer73", "Issuer74", "Issuer75", "Issuer76", "Issuer77", 
>        "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
>        "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", 
>        "Issuer87", "Issuer88", "Issuer89", "Issuer9", "Issuer90", 
>        "Issuer91", "Issuer92", "Issuer93", "Issuer94", "Issuer95", 
>        "Issuer96", "Issuer97", "Issuer98", "Issuer99"), class = "factor"), 
>        c(99.688, 75.667, 99.229, 99.583, 99.563, 99.188, 98.8, 
>        98.5, 99, 99.75), c(100.281, 78.667, 100.104, 100.333, 
>        100.063, 99.906, 99.75, 99.5, 99.75, 100.25), c(4L, 3L, 
>        6L, 3L, 2L, 4L, 5L, 1L, 1L, 1L), c(4L, 3L, 1L, 3L, 4L, 
>        2L, 4L, 5L, 3L, 3L), c(FALSE, TRUE, TRUE, TRUE, FALSE, 
>        TRUE, TRUE, FALSE, TRUE, TRUE), structure(c(1L, 1L, 1L, 
>        1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
>        structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
>        structure(c(3L, 8L, 9L, 1L, 6L, 3L, 10L, 10L, 9L, 3L), .Label = c("B", 
>        "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", 
>        "NR"), class = "factor"), structure(c(6L, 7L, 7L, 2L, 
>        6L, 1L, 9L, 9L, 8L, 2L), .Label = c("B1", "B2", "B3", 
>        "Ba1", "Ba2", "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), 
>        structure(c(66L, 80L, 74L, 30L, 49L, 72L, 70L, 62L, 10L, 
>        29L), .Label = c("1/11/2019", "1/2/2019", "1/2/2020", 
>        "1/30/2022", "10/15/2016", "10/15/2021", "10/17/2019", 
>        "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
>        "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", 
>        "11/12/2020", "11/20/2019", "11/20/2020", "11/27/2020", 
>        "11/5/2021", "11/6/2020", "11/9/2017", "11/9/2018", "12/15/2018", 
>        "12/15/2021", "12/15/2022", "12/16/2019", "12/18/2020", 
>        "12/20/2019", "12/7/2018", "12/7/2019", "2/12/2021", 
>        "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", "2/24/2017", 
>        "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", "3/21/2019", 
>        "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", "4/30/2018", 
>        "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", "5/15/2018", 
>        "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", "5/8/2020", 
>        "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", "6/2/2019", 
>        "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", "6/30/2017", 
>        "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", "7/10/2020", 
>        "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", "7/29/2022", 
>        "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", "8/12/2021", 
>        "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", "8/24/2017", 
>        "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", "9/18/2016", 
>        "9/18/2019", "9/20/2019"), class = "factor"), c(FALSE, 
>        FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
>        FALSE), structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 
>        34L, 17L, 64L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
>        "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
>        "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
>        "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
>        "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
>        "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
>        "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
>        "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
>        "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
>        "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
>        "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
>        "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
>        "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
>        "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
>        "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
>        "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
>        "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
>        "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
>        "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
>        "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
>        "Issuer98", "Issuer99"), class = "factor"), structure(c(43L, 
>        96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("BL1", 
>        "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
>        "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", 
>        "BL22", "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", 
>        "BL29", "BL3", "BL30", "BL31", "BL32", "BL33", "BL34", 
>        "BL35", "BL36", "BL37", "BL38", "BL39", "BL4", "BL40", 
>        "BL41", "BL42", "BL43", "BL44", "BL45", "BL46", "BL47", 
>        "BL48", "BL49", "BL5", "BL50", "BL51", "BL52", "BL53", 
>        "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", "BL6", 
>        "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
>        "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", 
>        "BL73", "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", 
>        "BL8", "BL80", "BL81", "BL82", "BL83", "BL84", "BL85", 
>        "BL86", "BL87", "BL88", "BL89", "BL9", "BL90", "BL91", 
>        "BL92", "BL93", "BL94", "BL95", "BL96", "BL97", "BL98", 
>        "BL99"), class = "factor"), structure(c(1L, 6L, 6L, 4L, 
>        6L, 4L, 6L, 2L, 6L, 2L), .Label = c("Banking, Finance, Insurance & Real Estate", 
>        "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
>        "Retail", "Services: Business"), class = "factor"), structure(c(2L, 
>        2L, 1L, 5L, 5L, 3L, 3L, 6L, 2L, 4L), .Label = c("Financial Intermediaries", 
>        "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
>        "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
>        structure(c(8L, 8L, 8L, 8L, 8L, 8L, 5L, 8L, 8L, 8L), .Label = c("AU", 
>        "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
>        structure(c(6L, 6L, 6L, 6L, 6L, 6L, 3L, 6L, 6L, 6L), .Label = c("1", 
>        "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
>        structure(c(4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L, 4L), .Label = c("Canada", 
>        "Europe", "Other", "U.S."), class = "factor"), structure(c(2L, 
>        1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), .Label = c("N", 
>        "Y"), class = "factor"), structure(c(1L, 2L, 2L, 1L, 
>        1L, 1L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
>        structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
>        c(8.74248921, NA, NA, 4.338507174, 3.464301168, NA, NA, 
>        NA, NA, NA), c(2220L, 2220L, 3490L, 3490L, 1766L, 2220L, 
>        8070L, 8070L, 3490L, 2220L), c(0.6, 0.55, 0.4, 0.4, 0.45, 
>        0.45, 0.4, 0.45, 0.6, 0.4), c(2220L, 2220L, 3490L, 3490L, 
>        1766L, 2220L, 8070L, 8070L, 3490L, 2220L), c(0.3, 0.55, 
>        0.55, 0.4, 0.45, 0.4, 0.45, 0.3, 0.55, 0.5), c(13L, 17L, 
>        17L, 15L, 13L, 14L, 19L, 19L, 18L, 15L), c(15L, 16L, 
>        15L, 15L, 13L, 14L, 19L, 19L, 15L, 15L), c(625000000, 
>        450000000, 760000000, 630000000, 530000000, 671500000, 
>        240000000, 100000000, 375000000, 1043700000), c(0.5, 
>        0.02, 0.02, 0.3, 0.65, 0.3, 0.5, 0.65, 0.02, 0.6), c(275L, 
>        750L, 650L, 300L, 225L, 300L, 700L, 925L, 825L, 400L), 
>        c(0, 1, 1, 1.25, 0, 1, 1, 1.25, 1.25, 1), c(0.03027, 
>        0.0751, 0.0651, 0.030125, 0.02527, 0.0301, 0.0701, 0.092625, 
>        0.082625, 0.0401), c(0.031286195, 0.154827358, 0.080695261, 
>        0.041683558, 0.028669191, 0.044131997, 0.084009559, 0.108958135, 
>        0.090916682, 0.051331755), c(263.290277, 1448.101305, 
>        704.3633733, 368.0708419, 194.2034583, 356.3784942, 746.772345, 
>        1036.334285, 875.917553, 436.2991366), c(0.030274693, 
>        0.097321394, 0.065317835, 0.030137658, 0.025317343, 0.030236973, 
>        0.070611937, 0.093560606, 0.083144654, 0.040049938), 
>        c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 
>        1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), 
>        structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
>        c(0.0136351351351351, 0.0338288288288288, 0.0186532951289398, 
>        0.00863180515759312, 0.0143091732729332, 0.0135585585585586, 
>        0.00868649318463445, 0.0114776951672862, 0.0236747851002865, 
>        0.0180630630630631), c(0.009081, 0.041305, 0.035805, 
>        0.01205, 0.0113715, 0.01204, 0.031545, 0.0277875, 0.04544375, 
>        0.02005), c(0.015135, 0.001502, 0.001302, 0.0090375, 
>        0.0164255, 0.00903, 0.03505, 0.06020625, 0.0016525, 0.02406
>        ))), .Names = c("V1", "V2", "V3"), row.names = c(NA, 
> -48L), class = c("data.table", "data.frame"))
> 
> 
> 
>> Subject: Re: [R] binding two lists of lists of dataframes together
>> From: dwinsemius at comcast.net
>> Date: Tue, 12 May 2015 11:36:50 -0700
>> CC: r-help at r-project.org
>> To: newrnewbie at hotmail.com
>> 
>> 
>> On May 12, 2015, at 9:24 AM, Vin Cheng wrote:
>> 
>>> list1<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L), 
>>>                    WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
>>>                    Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
>>>               .Names = c("id", "WgtBand", "Wgt")), 
>>>     structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
>>>                    WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
>>>                    Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
>>>               .Names = c("id", "WgtBand", "Wgt")), 
>>>     structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
>>>                    WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
>>>                    Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
>>>               .Names = c("id", "WgtBand", "Wgt")))
>>> 
>>> 
>>> list2<-list(structure(list(id = c(493L, 564L, 147L), 
>>>                           WgtBand = c(1, 2, 3), 
>>>                           Wgt = c(NaN, NaN, NA)), 
>>>                      .Names = c("id", "WgtBand", "Wgt")), 
>>>            structure(list(id = c(276L, 411L, 574L,111L), 
>>>                           WgtBand = c(1, 2, 3,4), 
>>>                           Wgt = c(NaN, NaN, NA,NA)), 
>>>                      .Names = c("id", "WgtBand", "Wgt")), 
>>>            structure(list(id = c(76L, 330L), 
>>>                           WgtBand = c(1, 1), 
>>>                           Wgt = c(NaN, NaN)), 
>>>                      .Names = c("id", "WgtBand", "Wgt")))
>>> 
>>> list3<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L,493L, 564L, 147L), 
>>>                           WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9,1, 2, 3), 
>>>                           Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA)), 
>>>                      .Names = c("id", "WgtBand", "Wgt")), 
>>>            structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,276L, 411L, 574L,111L), 
>>>                           WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 2, 3,4), 
>>>                           Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA,NA)), 
>>>                      .Names = c("id", "WgtBand", "Wgt")), 
>>>            structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,76L, 330L), 
>>>                           WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 1), 
>>>                           Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN)), 
>>>                      .Names = c("id", "WgtBand", "Wgt")))
>> 
>> I get something like the desired structure with:
>> 
>> mapply(function(x,y) mapply(c, x,y), list1,list2)
>> 
>> I can make it closer with:
>> 
>> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) unclass( as.data.frame(x) ) )
>> 
>> 
>> Or even closer with:
>> 
>> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) as.list( as.data.frame(x) ) )
>> 
>> `identical` does not return TRUE but I cannot see where the difference lies.
>> 
>> -- 
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From newrnewbie at hotmail.com  Wed May 13 00:12:41 2015
From: newrnewbie at hotmail.com (Vin Cheng)
Date: Tue, 12 May 2015 22:12:41 +0000
Subject: [R] binding two lists of lists of dataframes together
In-Reply-To: <1084ED86-44F2-4717-9879-4A8A368FE00A@comcast.net>
References: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>,
	<A2E1A0300F5.00001107jrkrideau@inbox.com>
	<BAY179-W63A3DF10922679A302B16D3DA0@phx.gbl>,
	<17C25B6B-DDF7-4108-99C9-3DABC178C32F@comcast.net>
	<BAY179-W817CF1BB2EEC863DC596F5D3DA0@phx.gbl>,
	<1084ED86-44F2-4717-9879-4A8A368FE00A@comcast.net>
Message-ID: <BAY179-W41355B8D24DBDB0BEF7978D3DA0@phx.gbl>

Hi David,
 
Would it be possible to modify it a little so that I can keep V1, V2, and V3 intact?
 
I also don't quite know where to put list2 in the solution you provided below? list2 can be an exact copy of list1 for this example.
 
list1 has (48 observations of 3 variables(V1, V2,V3)) each observation has 10 values in a vector 
list2 has (48 observations of 3 variables (V1, V2,V3)) each observation has 10 values in a vector 
 
Output should ideally have (48 observations of 3 variables (V1, V2,V3)) each observation has 20 values in a vector
 list1 V1 stacks with list2 V1, 
 list1 V2 stacks with list2 V2, 
 list1 V3 stacks with list2 V3
 
Boundlist seems to break out the values of each variable(V1,V2,V3) into 10 columns with 1 value in each column.  Is it possible to put the values in the 10 columns(20 values in ideal output) into a vector for each of the 48 observation in each variable(V1,V2,V3).
 
Sorry for all the back and forth - explaining an exact output over email is difficult.
 
I really appreciate the help and the effort!  
 
Thank you again!
Vince
 
> Subject: Re: [R] binding two lists of lists of dataframes together
> From: dwinsemius at comcast.net
> Date: Tue, 12 May 2015 14:23:54 -0700
> CC: r-help at r-project.org
> To: newrnewbie at hotmail.com
> 
> 
> On May 12, 2015, at 12:56 PM, Vin Cheng wrote:
> 
> > Hi,
> > 
> > Thanks David!  Your solution 3 worked well with the sample data, but when I run solution 2 & 3 on the actual data - it creates a list of 1 for each data point and it doesn't end up looking like the desired output for some reason.
> > 
> > I've run a dput on the actual data and pasted below.  There's a lot of data - so I'm only copying list1 - if the solution could bind list1 with itself - it should work just as well.  
> > 
> > Sorry for not providing an accurate sample the first time around - I thought the shortened version would be simpler and sufficient.
> > 
> > Any help/guidance would be greatly appreciated!
> > 
> 
> This appears to be three similarly structured lists of various classes but fortunately for this effort the factor variables in corresponding columns all have the same levels. (Otherwise one would need to convert to character before attempting to stack them.)
> 
> I would just use `rbind.data.frame` (after making them dataframes with the same column names.)
> 
> 
> dlist <- lapply( list1, function(d) setNames( data.frame(d), paste0("V", 1:48) ))
> boundlist <- do.call(rbind, dlist)
> 
> # Done.
> 
> -- 
> David.
> > Many Thanks,
> > Vince
> > 
> > list1 <- structure(list(V1 = list(c(19L, 94L, 94L, 15L, 90L, 13L, 66L, 
> > 17L, 45L, 69L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, 
> > NA, NA, NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 
> > 0), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
> > ), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", "ID13", 
> > "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", 
> > "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", "ID27", "ID28", 
> > "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", "ID34", "ID35", 
> > "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", "ID41", "ID42", 
> > "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", 
> > "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
> > "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", "ID64", 
> > "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", "ID70", "ID71", 
> > "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", "ID78", "ID79", 
> > "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", "ID85", "ID86", 
> > "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", "ID92", "ID93", 
> > "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"), class = "factor"), 
> >    structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
> >    ), .Label = c("Issuer1", "Issuer10", "Issuer100", "Issuer11", 
> >    "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
> >    "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", 
> >    "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", 
> >    "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", 
> >    "Issuer30", "Issuer31", "Issuer32", "Issuer33", "Issuer34", 
> >    "Issuer35", "Issuer36", "Issuer37", "Issuer38", "Issuer39", 
> >    "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
> >    "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", 
> >    "Issuer49", "Issuer5", "Issuer50", "Issuer51", "Issuer52", 
> >    "Issuer53", "Issuer54", "Issuer55", "Issuer56", "Issuer57", 
> >    "Issuer58", "Issuer59", "Issuer6", "Issuer60", "Issuer61", 
> >    "Issuer62", "Issuer63", "Issuer64", "Issuer65", "Issuer66", 
> >    "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
> >    "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", 
> >    "Issuer76", "Issuer77", "Issuer78", "Issuer79", "Issuer8", 
> >    "Issuer80", "Issuer81", "Issuer82", "Issuer83", "Issuer84", 
> >    "Issuer85", "Issuer86", "Issuer87", "Issuer88", "Issuer89", 
> >    "Issuer9", "Issuer90", "Issuer91", "Issuer92", "Issuer93", 
> >    "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
> >    "Issuer99"), class = "factor"), c(95.5, 98.5, 98.5, 99.5, 
> >    103.5, 98.563, 99.75, 98.5, 98.75, 99.125), c(97.5, 99.5, 
> >    99.5, 100.375, 104.5, 99.188, 100.25, 99.5, 99.75, 100.063
> >    ), c(2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 4L), c(4L, 5L, 5L, 
> >    5L, 5L, 2L, 3L, 5L, 3L, 2L), c(TRUE, FALSE, FALSE, TRUE, 
> >    FALSE, TRUE, TRUE, FALSE, FALSE, TRUE), structure(c(1L, 1L, 
> >    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> >    structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> >    structure(c(9L, 2L, 2L, 1L, 2L, 1L, 3L, 3L, 5L, 9L), .Label = c("B", 
> >    "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
> >    ), class = "factor"), structure(c(8L, 2L, 2L, 1L, 8L, 2L, 
> >    2L, 2L, 1L, 7L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
> >    "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(20L, 
> >    88L, 88L, 6L, 3L, 35L, 29L, 24L, 53L, 82L), .Label = c("1/11/2019", 
> >    "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
> >    "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> >    "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
> >    "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
> >    "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
> >    "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
> >    "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
> >    "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
> >    "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
> >    "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
> >    "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
> >    "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
> >    "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
> >    "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
> >    "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
> >    "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
> >    "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
> >    "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
> >    "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
> >    c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> >    FALSE, FALSE), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 
> >    10L, 41L, 67L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> >    "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> >    "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> >    "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> >    "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> >    "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> >    "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> >    "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> >    "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> >    "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> >    "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> >    "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> >    "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> >    "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> >    "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> >    "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> >    "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> >    "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> >    "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> >    "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> >    "Issuer98", "Issuer99"), class = "factor"), structure(c(12L, 
> >    95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L), .Label = c("BL1", 
> >    "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> >    "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
> >    "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
> >    "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
> >    "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
> >    "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
> >    "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
> >    "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> >    "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
> >    "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
> >    "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
> >    "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
> >    "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(4L, 
> >    3L, 3L, 5L, 6L, 3L, 2L, 6L, 6L, 5L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> >    "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> >    "Retail", "Services: Business"), class = "factor"), structure(c(3L, 
> >    5L, 5L, 6L, 4L, 3L, 4L, 2L, 6L, 6L), .Label = c("Financial Intermediaries", 
> >    "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> >    "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> >    structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 6L, 8L, 8L), .Label = c("AU", 
> >    "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> >    structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 5L, 6L, 6L), .Label = c("1", 
> >    "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> >    structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L), .Label = c("Canada", 
> >    "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
> >    2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> >    structure(c(2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
> >    "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
> >    1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> >    c(0.125550168, 1.731733265, 1.731733265, NA, 5.246485518, 
> >    7.798802147, NA, NA, NA, NA), c(4770L, 3490L, 3490L, 3490L, 
> >    3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.45, 0.4, 0.4, 
> >    0.45, 0.55, 0.4, 0.4, 0.45, 0.4, 0.5), c(4770L, 3490L, 3490L, 
> >    3490L, 3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.55, 
> >    0.4, 0.4, 0.4, 0.55, 0.4, 0.5, 0.5, 0.45, 0.55), c(18L, 15L, 
> >    15L, 15L, 18L, 15L, 15L, 15L, 14L, 17L), c(17L, 16L, 16L, 
> >    15L, 14L, 15L, 15L, 15L, 14L, 15L), c(192500000, 205000000, 
> >    205000000, 342000000, 120000000, 835000000, 1043700000, 160000000, 
> >    300000000, 265000000), c(0.02, 0.02, 0.02, 0.4, 0.02, 0.4, 
> >    0.6, 0.6, 0.6, 0.02), c(850L, 475L, 475L, 500L, 1000L, 350L, 
> >    400L, 975L, 500L, 700L), c(1, 1.5, 1.5, 1, 1.25, 1, 1, 1, 
> >    1, 1), c(0.0851, 0.04765, 0.04765, 0.0501, 0.100125, 0.0351, 
> >    0.0401, 0.0976, 0.0501, 0.0701), c(0.099192999, 0.023321348, 
> >    0.023321348, 0.06465519, 0.103470278, 0.052237196, 0.051331755, 
> >    0.112300026, 0.066116739, 0.084107871), c(897.0917677, -1.49365213, 
> >    -1.49365213, 549.0886934, 975.9481504, 429.1863229, 436.2991366, 
> >    1062.374805, 567.0741295, 747.1023728), c(0.088186528, 0.048131313, 
> >    0.048131313, 0.050131332, 0.096274038, 0.035499188, 0.040049938, 
> >    0.098585859, 0.050478589, 0.070385766), c(0L, 0L, 0L, 0L, 
> >    0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
> >    1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
> >    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> >    c(0.0178406708595388, 0.0136532951289398, 0.0136532951289398, 
> >    0.0143553008595989, 0.028689111747851, 0.0100573065902579, 
> >    0.0180630630630631, 0.043963963963964, 0.0225675675675676, 
> >    0.0200859598853868), c(0.046805, 0.01906, 0.01906, 0.02004, 
> >    0.05506875, 0.01404, 0.02005, 0.0488, 0.022545, 0.038555), 
> >    c(0.001702, 0.000953, 0.000953, 0.02004, 0.0020025, 0.01404, 
> >    0.02406, 0.05856, 0.03006, 0.001402)), V2 = list(c(93L, 3L, 
> > 85L, 34L, 20L, 89L, 16L, 25L, 83L, 90L), c(1, 1, 2, 3, 4, 5, 
> > 6, 7, 8, 9), c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), c(0, 
> > 0, 0, 0, 0, 0, 0, 0, 0, 0), structure(c(94L, 24L, 85L, 29L, 14L, 
> > 89L, 9L, 19L, 83L, 91L), .Label = c("ID1", "ID10", "ID100", "ID11", 
> > "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
> > "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> > "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", 
> > "ID34", "ID35", "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", 
> > "ID41", "ID42", "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", 
> > "ID49", "ID5", "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", 
> > "ID56", "ID57", "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", 
> > "ID63", "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
> > "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", 
> > "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", 
> > "ID85", "ID86", "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", 
> > "ID92", "ID93", "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"
> > ), class = "factor"), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
> > 9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
> > "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> > "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
> > "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", "Issuer32", 
> > "Issuer33", "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
> > "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", "Issuer49", 
> > "Issuer5", "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
> > "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", "Issuer6", 
> > "Issuer60", "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
> > "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", "Issuer76", 
> > "Issuer77", "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
> > "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", "Issuer87", 
> > "Issuer88", "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
> > "Issuer99"), class = "factor"), c(99.5, 99.646, 100.402, 100.25, 
> > 98, 99.563, 99.563, 99.388, 99.531, 103.5), c(100.5, 100.271, 
> > 100.903, 100.75, 99, 100.188, 100.063, 99.788, 100.125, 104.5
> > ), c(1L, 6L, 9L, 1L, 1L, 2L, 2L, 10L, 4L, 2L), c(5L, 2L, 1L, 
> > 3L, 3L, 4L, 4L, 1L, 1L, 5L), c(TRUE, TRUE, FALSE, FALSE, TRUE, 
> > FALSE, FALSE, TRUE, TRUE, FALSE), structure(c(1L, 1L, 1L, 1L, 
> > 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> >    structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> >    structure(c(8L, 1L, 4L, 1L, 3L, 4L, 6L, 1L, 5L, 2L), .Label = c("B", 
> >    "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
> >    ), class = "factor"), structure(c(7L, 2L, 5L, 2L, 1L, 2L, 
> >    6L, 1L, 5L, 8L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
> >    "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(41L, 
> >    1L, 13L, 43L, 21L, 87L, 49L, 73L, 46L, 3L), .Label = c("1/11/2019", 
> >    "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
> >    "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> >    "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
> >    "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
> >    "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
> >    "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
> >    "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
> >    "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
> >    "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
> >    "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
> >    "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
> >    "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
> >    "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
> >    "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
> >    "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
> >    "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
> >    "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
> >    "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
> >    "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
> >    c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> >    FALSE, FALSE), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
> >    9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> >    "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> >    "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> >    "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> >    "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> >    "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> >    "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> >    "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> >    "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> >    "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> >    "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> >    "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> >    "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> >    "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> >    "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> >    "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> >    "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> >    "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> >    "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> >    "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> >    "Issuer98", "Issuer99"), class = "factor"), structure(c(94L, 
> >    24L, 85L, 29L, 14L, 89L, 9L, 19L, 83L, 91L), .Label = c("BL1", 
> >    "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> >    "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
> >    "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
> >    "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
> >    "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
> >    "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
> >    "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
> >    "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> >    "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
> >    "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
> >    "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
> >    "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
> >    "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(2L, 
> >    2L, 3L, 6L, 1L, 6L, 6L, 6L, 1L, 6L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> >    "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> >    "Retail", "Services: Business"), class = "factor"), structure(c(6L, 
> >    6L, 3L, 5L, 1L, 2L, 5L, 3L, 2L, 4L), .Label = c("Financial Intermediaries", 
> >    "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> >    "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> >    structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L), .Label = c("AU", 
> >    "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> >    structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label = c("1", 
> >    "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> >    structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("Canada", 
> >    "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
> >    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> >    structure(c(2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
> >    "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
> >    1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> >    c(2.603554841, 7.27032758, 3.155438813, 5.037267081, 0.125550168, 
> >    NA, 3.464301168, NA, 4.816376964, 5.246485518), c(2220L, 
> >    2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 2220L, 3490L
> >    ), c(0.55, 0.45, 0.5, 0.4, 0.6, 0.45, 0.45, 0.55, 0.2, 0.55
> >    ), c(2220L, 2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 
> >    2220L, 3490L), c(0.55, 0.45, 0.5, 0.4, 0.3, 0.45, 0.45, 0.4, 
> >    0.2, 0.55), c(17L, 15L, 12L, 15L, 14L, 15L, 13L, 14L, 12L, 
> >    18L), c(16L, 16L, 14L, 16L, 15L, 12L, 13L, 15L, 14L, 14L), 
> >    c(200000000, 613811406, 750000000, 200000000, 405500000, 
> >    450000000, 530000000, 2010000000, 775000000, 120000000), 
> >    c(0.02, 0.5, 0.65, 0.27, 0.5, 0.65, 0.65, 0.3, 0.65, 0.02
> >    ), c(950L, 350L, 350L, 275L, 450L, 275L, 225L, 325L, 275L, 
> >    1000L), c(1.25, 1, 0.75, 0.75, 1, 0.75, 0, 1, 0.75, 1.25), 
> >    c(0.095125, 0.0351, 0.035075, 0.027575, 0.0451, 0.027575, 
> >    0.02527, 0.0326, 0.027575, 0.100125), c(0.104211455, 0.046414939, 
> >    0.050338657, 0.027233401, 0.059885473, 0.03459045, 0.028669191, 
> >    0.048294163, 0.040935438, 0.103470278), c(980.5501911, 400.3544693, 
> >    385.8629241, 244.6340073, 511.2711809, 294.3073789, 194.2034583, 
> >    385.9437059, 308.4324006, 975.9481504), c(0.095125, 0.035114573, 
> >    0.034847619, 0.027437811, 0.045786802, 0.027609374, 0.025317343, 
> >    0.032734868, 0.027622511, 0.096274038), c(0L, 0L, 0L, 0L, 
> >    0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
> >    1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
> >    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> >    c(0.0428490990990991, 0.0158108108108108, 0.037313829787234, 
> >    0.00790114613180516, 0.00945492662473794, 0.0124211711711712, 
> >    0.0143091732729332, 0.00934097421203438, 0.0124211711711712, 
> >    0.028689111747851), c(0.05231875, 0.015795, 0.0175375, 0.01103, 
> >    0.01353, 0.01240875, 0.0113715, 0.01304, 0.005515, 0.05506875
> >    ), c(0.0019025, 0.01755, 0.02279875, 0.00744525, 0.02255, 
> >    0.01792375, 0.0164255, 0.00978, 0.01792375, 0.0020025)), 
> >    V3 = list(c(47L, 95L, 26L, 64L, 16L, 55L, 61L, 39L, 23L, 
> >    66L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, NA, NA, 
> >    NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> >        structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 
> >        64L), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", 
> >        "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
> >        "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", 
> >        "ID26", "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", 
> >        "ID32", "ID33", "ID34", "ID35", "ID36", "ID37", "ID38", 
> >        "ID39", "ID4", "ID40", "ID41", "ID42", "ID43", "ID44", 
> >        "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", "ID50", 
> >        "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
> >        "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", 
> >        "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
> >        "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", 
> >        "ID77", "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", 
> >        "ID83", "ID84", "ID85", "ID86", "ID87", "ID88", "ID89", 
> >        "ID9", "ID90", "ID91", "ID92", "ID93", "ID94", "ID95", 
> >        "ID96", "ID97", "ID98", "ID99"), class = "factor"), structure(c(43L, 
> >        96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("Issuer1", 
> >        "Issuer10", "Issuer100", "Issuer11", "Issuer12", "Issuer13", 
> >        "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", 
> >        "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", 
> >        "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
> >        "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", 
> >        "Issuer32", "Issuer33", "Issuer34", "Issuer35", "Issuer36", 
> >        "Issuer37", "Issuer38", "Issuer39", "Issuer4", "Issuer40", 
> >        "Issuer41", "Issuer42", "Issuer43", "Issuer44", "Issuer45", 
> >        "Issuer46", "Issuer47", "Issuer48", "Issuer49", "Issuer5", 
> >        "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
> >        "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", 
> >        "Issuer6", "Issuer60", "Issuer61", "Issuer62", "Issuer63", 
> >        "Issuer64", "Issuer65", "Issuer66", "Issuer67", "Issuer68", 
> >        "Issuer69", "Issuer7", "Issuer70", "Issuer71", "Issuer72", 
> >        "Issuer73", "Issuer74", "Issuer75", "Issuer76", "Issuer77", 
> >        "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
> >        "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", 
> >        "Issuer87", "Issuer88", "Issuer89", "Issuer9", "Issuer90", 
> >        "Issuer91", "Issuer92", "Issuer93", "Issuer94", "Issuer95", 
> >        "Issuer96", "Issuer97", "Issuer98", "Issuer99"), class = "factor"), 
> >        c(99.688, 75.667, 99.229, 99.583, 99.563, 99.188, 98.8, 
> >        98.5, 99, 99.75), c(100.281, 78.667, 100.104, 100.333, 
> >        100.063, 99.906, 99.75, 99.5, 99.75, 100.25), c(4L, 3L, 
> >        6L, 3L, 2L, 4L, 5L, 1L, 1L, 1L), c(4L, 3L, 1L, 3L, 4L, 
> >        2L, 4L, 5L, 3L, 3L), c(FALSE, TRUE, TRUE, TRUE, FALSE, 
> >        TRUE, TRUE, FALSE, TRUE, TRUE), structure(c(1L, 1L, 1L, 
> >        1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> >        structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> >        structure(c(3L, 8L, 9L, 1L, 6L, 3L, 10L, 10L, 9L, 3L), .Label = c("B", 
> >        "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", 
> >        "NR"), class = "factor"), structure(c(6L, 7L, 7L, 2L, 
> >        6L, 1L, 9L, 9L, 8L, 2L), .Label = c("B1", "B2", "B3", 
> >        "Ba1", "Ba2", "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), 
> >        structure(c(66L, 80L, 74L, 30L, 49L, 72L, 70L, 62L, 10L, 
> >        29L), .Label = c("1/11/2019", "1/2/2019", "1/2/2020", 
> >        "1/30/2022", "10/15/2016", "10/15/2021", "10/17/2019", 
> >        "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> >        "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", 
> >        "11/12/2020", "11/20/2019", "11/20/2020", "11/27/2020", 
> >        "11/5/2021", "11/6/2020", "11/9/2017", "11/9/2018", "12/15/2018", 
> >        "12/15/2021", "12/15/2022", "12/16/2019", "12/18/2020", 
> >        "12/20/2019", "12/7/2018", "12/7/2019", "2/12/2021", 
> >        "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", "2/24/2017", 
> >        "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", "3/21/2019", 
> >        "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", "4/30/2018", 
> >        "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", "5/15/2018", 
> >        "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", "5/8/2020", 
> >        "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", "6/2/2019", 
> >        "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", "6/30/2017", 
> >        "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", "7/10/2020", 
> >        "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", "7/29/2022", 
> >        "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", "8/12/2021", 
> >        "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", "8/24/2017", 
> >        "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", "9/18/2016", 
> >        "9/18/2019", "9/20/2019"), class = "factor"), c(FALSE, 
> >        FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> >        FALSE), structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 
> >        34L, 17L, 64L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> >        "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> >        "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> >        "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> >        "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> >        "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> >        "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> >        "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> >        "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> >        "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> >        "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> >        "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> >        "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> >        "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> >        "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> >        "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> >        "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> >        "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> >        "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> >        "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> >        "Issuer98", "Issuer99"), class = "factor"), structure(c(43L, 
> >        96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("BL1", 
> >        "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> >        "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", 
> >        "BL22", "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", 
> >        "BL29", "BL3", "BL30", "BL31", "BL32", "BL33", "BL34", 
> >        "BL35", "BL36", "BL37", "BL38", "BL39", "BL4", "BL40", 
> >        "BL41", "BL42", "BL43", "BL44", "BL45", "BL46", "BL47", 
> >        "BL48", "BL49", "BL5", "BL50", "BL51", "BL52", "BL53", 
> >        "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", "BL6", 
> >        "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> >        "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", 
> >        "BL73", "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", 
> >        "BL8", "BL80", "BL81", "BL82", "BL83", "BL84", "BL85", 
> >        "BL86", "BL87", "BL88", "BL89", "BL9", "BL90", "BL91", 
> >        "BL92", "BL93", "BL94", "BL95", "BL96", "BL97", "BL98", 
> >        "BL99"), class = "factor"), structure(c(1L, 6L, 6L, 4L, 
> >        6L, 4L, 6L, 2L, 6L, 2L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> >        "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> >        "Retail", "Services: Business"), class = "factor"), structure(c(2L, 
> >        2L, 1L, 5L, 5L, 3L, 3L, 6L, 2L, 4L), .Label = c("Financial Intermediaries", 
> >        "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> >        "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> >        structure(c(8L, 8L, 8L, 8L, 8L, 8L, 5L, 8L, 8L, 8L), .Label = c("AU", 
> >        "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> >        structure(c(6L, 6L, 6L, 6L, 6L, 6L, 3L, 6L, 6L, 6L), .Label = c("1", 
> >        "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> >        structure(c(4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L, 4L), .Label = c("Canada", 
> >        "Europe", "Other", "U.S."), class = "factor"), structure(c(2L, 
> >        1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), .Label = c("N", 
> >        "Y"), class = "factor"), structure(c(1L, 2L, 2L, 1L, 
> >        1L, 1L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> >        structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> >        c(8.74248921, NA, NA, 4.338507174, 3.464301168, NA, NA, 
> >        NA, NA, NA), c(2220L, 2220L, 3490L, 3490L, 1766L, 2220L, 
> >        8070L, 8070L, 3490L, 2220L), c(0.6, 0.55, 0.4, 0.4, 0.45, 
> >        0.45, 0.4, 0.45, 0.6, 0.4), c(2220L, 2220L, 3490L, 3490L, 
> >        1766L, 2220L, 8070L, 8070L, 3490L, 2220L), c(0.3, 0.55, 
> >        0.55, 0.4, 0.45, 0.4, 0.45, 0.3, 0.55, 0.5), c(13L, 17L, 
> >        17L, 15L, 13L, 14L, 19L, 19L, 18L, 15L), c(15L, 16L, 
> >        15L, 15L, 13L, 14L, 19L, 19L, 15L, 15L), c(625000000, 
> >        450000000, 760000000, 630000000, 530000000, 671500000, 
> >        240000000, 100000000, 375000000, 1043700000), c(0.5, 
> >        0.02, 0.02, 0.3, 0.65, 0.3, 0.5, 0.65, 0.02, 0.6), c(275L, 
> >        750L, 650L, 300L, 225L, 300L, 700L, 925L, 825L, 400L), 
> >        c(0, 1, 1, 1.25, 0, 1, 1, 1.25, 1.25, 1), c(0.03027, 
> >        0.0751, 0.0651, 0.030125, 0.02527, 0.0301, 0.0701, 0.092625, 
> >        0.082625, 0.0401), c(0.031286195, 0.154827358, 0.080695261, 
> >        0.041683558, 0.028669191, 0.044131997, 0.084009559, 0.108958135, 
> >        0.090916682, 0.051331755), c(263.290277, 1448.101305, 
> >        704.3633733, 368.0708419, 194.2034583, 356.3784942, 746.772345, 
> >        1036.334285, 875.917553, 436.2991366), c(0.030274693, 
> >        0.097321394, 0.065317835, 0.030137658, 0.025317343, 0.030236973, 
> >        0.070611937, 0.093560606, 0.083144654, 0.040049938), 
> >        c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 
> >        1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), 
> >        structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> >        c(0.0136351351351351, 0.0338288288288288, 0.0186532951289398, 
> >        0.00863180515759312, 0.0143091732729332, 0.0135585585585586, 
> >        0.00868649318463445, 0.0114776951672862, 0.0236747851002865, 
> >        0.0180630630630631), c(0.009081, 0.041305, 0.035805, 
> >        0.01205, 0.0113715, 0.01204, 0.031545, 0.0277875, 0.04544375, 
> >        0.02005), c(0.015135, 0.001502, 0.001302, 0.0090375, 
> >        0.0164255, 0.00903, 0.03505, 0.06020625, 0.0016525, 0.02406
> >        ))), .Names = c("V1", "V2", "V3"), row.names = c(NA, 
> > -48L), class = c("data.table", "data.frame"))
> > 
> > 
> > 
> >> Subject: Re: [R] binding two lists of lists of dataframes together
> >> From: dwinsemius at comcast.net
> >> Date: Tue, 12 May 2015 11:36:50 -0700
> >> CC: r-help at r-project.org
> >> To: newrnewbie at hotmail.com
> >> 
> >> 
> >> On May 12, 2015, at 9:24 AM, Vin Cheng wrote:
> >> 
> >>> list1<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L), 
> >>>                    WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> >>>                    Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> >>>               .Names = c("id", "WgtBand", "Wgt")), 
> >>>     structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
> >>>                    WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
> >>>                    Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> >>>               .Names = c("id", "WgtBand", "Wgt")), 
> >>>     structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
> >>>                    WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
> >>>                    Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> >>>               .Names = c("id", "WgtBand", "Wgt")))
> >>> 
> >>> 
> >>> list2<-list(structure(list(id = c(493L, 564L, 147L), 
> >>>                           WgtBand = c(1, 2, 3), 
> >>>                           Wgt = c(NaN, NaN, NA)), 
> >>>                      .Names = c("id", "WgtBand", "Wgt")), 
> >>>            structure(list(id = c(276L, 411L, 574L,111L), 
> >>>                           WgtBand = c(1, 2, 3,4), 
> >>>                           Wgt = c(NaN, NaN, NA,NA)), 
> >>>                      .Names = c("id", "WgtBand", "Wgt")), 
> >>>            structure(list(id = c(76L, 330L), 
> >>>                           WgtBand = c(1, 1), 
> >>>                           Wgt = c(NaN, NaN)), 
> >>>                      .Names = c("id", "WgtBand", "Wgt")))
> >>> 
> >>> list3<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L,493L, 564L, 147L), 
> >>>                           WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9,1, 2, 3), 
> >>>                           Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA)), 
> >>>                      .Names = c("id", "WgtBand", "Wgt")), 
> >>>            structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,276L, 411L, 574L,111L), 
> >>>                           WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 2, 3,4), 
> >>>                           Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA,NA)), 
> >>>                      .Names = c("id", "WgtBand", "Wgt")), 
> >>>            structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,76L, 330L), 
> >>>                           WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 1), 
> >>>                           Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN)), 
> >>>                      .Names = c("id", "WgtBand", "Wgt")))
> >> 
> >> I get something like the desired structure with:
> >> 
> >> mapply(function(x,y) mapply(c, x,y), list1,list2)
> >> 
> >> I can make it closer with:
> >> 
> >> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) unclass( as.data.frame(x) ) )
> >> 
> >> 
> >> Or even closer with:
> >> 
> >> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) as.list( as.data.frame(x) ) )
> >> 
> >> `identical` does not return TRUE but I cannot see where the difference lies.
> >> 
> >> -- 
> >> 
> >> David Winsemius
> >> Alameda, CA, USA
> >> 
> > 		 	   		  
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
 		 	   		  
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed May 13 01:00:05 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 12 May 2015 16:00:05 -0700
Subject: [R] binding two lists of lists of dataframes together
In-Reply-To: <BAY179-W41355B8D24DBDB0BEF7978D3DA0@phx.gbl>
References: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>,
	<A2E1A0300F5.00001107jrkrideau@inbox.com>
	<BAY179-W63A3DF10922679A302B16D3DA0@phx.gbl>,
	<17C25B6B-DDF7-4108-99C9-3DABC178C32F@comcast.net>
	<BAY179-W817CF1BB2EEC863DC596F5D3DA0@phx.gbl>,
	<1084ED86-44F2-4717-9879-4A8A368FE00A@comcast.net>
	<BAY179-W41355B8D24DBDB0BEF7978D3DA0@phx.gbl>
Message-ID: <F8CE47F9-1AEE-4514-9779-61DB3AF0F019@comcast.net>


On May 12, 2015, at 3:12 PM, Vin Cheng wrote:

> Hi David,
>  
> Would it be possible to modify it a little so that I can keep V1, V2, and V3 intact?


>  
> I also don't quite know where to put list2 in the solution you provided below? list2 can be an exact copy of list1 for this example.

In which case it would be nearly trivial:

lapply(dlist, function(x) rbind(x,x) ) 

str( lapply(dlist, function(x) rbind(x,x) ) )
List of 3
 $ V1:'data.frame':	20 obs. of  48 variables:
  ..$ V1 : int [1:20] 19 94 94 15 90 13 66 17 45 69 ...
  ..$ V2 : num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
  ..$ V3 : num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
  ..$ V4 : num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
snipped.....

>  
> list1 has (48 observations of 3 variables(V1, V2,V3)) each observation has 10 values in a vector 
> list2 has (48 observations of 3 variables (V1, V2,V3)) each observation has 10 values in a vector 

You basically want a list of the same general structure as list1 where all the elements in list two at the same position and depth have been concatenated?
>  
> Output should ideally have (48 observations of 3 variables (V1, V2,V3)) each observation has 20 values in a vector
>  list1 V1 stacks with list2 V1, 
>  list1 V2 stacks with list2 V2, 
>  list1 V3 stacks with list2 V3

You had a bunch of factor variables in list1. Are we assured that the levels of any factor variables in list2 are the same as the corresponding factor variables in list 1?

>  
> Boundlist seems to break out the values of each variable(V1,V2,V3) into 10 columns with 1 value in each column.

Not the way I use those words after using R for the last 8 years. There were 48 "columns" and 10 positions in each. I think you need to reverse your terminology (columns and rows)  since a "column" in a dataframe is a list and the row numbers are the relative positions along vectors.


>  Is it possible to put the values in the 10 columns(20 values in ideal output) into a vector for each of the 48 observation in each variable(V1,V2,V3).

Having severe trouble reformulating this in R dataframe terminology.

>  
> Sorry for all the back and forth - explaining an exact output over email is difficult.

It shouldn't be difficult if you would post data examples with sufficient complexity to represent the problem. I will build a smaller list of dataframe and name it 'smaller'

Since I had difficulty with mapply I'm switching to the list version named ?Map found in the ?funprog page:

smaller <- lapply(dlist, "[", 1:6)

?Map
 str( Map( rbind, smaller, smaller))

#------I think this is what you might want----------
List of 3
 $ V1:'data.frame':	20 obs. of  6 variables:
  ..$ V1: int [1:20] 19 94 94 15 90 13 66 17 45 69 ...
  ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
  ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
  ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
  ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 12 95 95 8 91 6 64 10 41 67 ...
  ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 12 95 95 8 91 6 64 10 41 67 ...
 $ V2:'data.frame':	20 obs. of  6 variables:
  ..$ V1: int [1:20] 93 3 85 34 20 89 16 25 83 90 ...
  ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
  ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
  ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
  ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 94 24 85 29 14 89 9 19 83 91 ...
  ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 94 24 85 29 14 89 9 19 83 91 ...
 $ V3:'data.frame':	20 obs. of  6 variables:
  ..$ V1: int [1:20] 47 95 26 64 16 55 61 39 23 66 ...
  ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
  ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
  ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
  ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 43 96 20 62 9 52 59 34 17 64 ...
  ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 43 96 20 62 9 52 59 34 17 64 ...

>  
> I really appreciate the help and the effort!  
>  
> Thank you again!
> Vince
>  
> > Subject: Re: [R] binding two lists of lists of dataframes together
> > From: dwinsemius at comcast.net
> > Date: Tue, 12 May 2015 14:23:54 -0700
> > CC: r-help at r-project.org
> > To: newrnewbie at hotmail.com
> > 
> > 
> > On May 12, 2015, at 12:56 PM, Vin Cheng wrote:
> > 
> > > Hi,
> > > 
> > > Thanks David! Your solution 3 worked well with the sample data, but when I run solution 2 & 3 on the actual data - it creates a list of 1 for each data point and it doesn't end up looking like the desired output for some reason.
> > > 
> > > I've run a dput on the actual data and pasted below. There's a lot of data - so I'm only copying list1 - if the solution could bind list1 with itself - it should work just as well. 
> > > 
> > > Sorry for not providing an accurate sample the first time around - I thought the shortened version would be simpler and sufficient.
> > > 
> > > Any help/guidance would be greatly appreciated!
> > > 
> > 
> > This appears to be three similarly structured lists of various classes but fortunately for this effort the factor variables in corresponding columns all have the same levels. (Otherwise one would need to convert to character before attempting to stack them.)
> > 
> > I would just use `rbind.data.frame` (after making them dataframes with the same column names.)
> > 
> > 
> > dlist <- lapply( list1, function(d) setNames( data.frame(d), paste0("V", 1:48) ))
> > boundlist <- do.call(rbind, dlist)
> > 
> > # Done.
> > 
> > -- 
> > David.
> > > Many Thanks,
> > > Vince
> > > 
> > > list1 <- structure(list(V1 = list(c(19L, 94L, 94L, 15L, 90L, 13L, 66L, 
> > > 17L, 45L, 69L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, 
> > > NA, NA, NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 
> > > 0), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
> > > ), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", "ID13", 
> > > "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", 
> > > "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", "ID27", "ID28", 
> > > "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", "ID34", "ID35", 
> > > "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", "ID41", "ID42", 
> > > "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", 
> > > "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
> > > "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", "ID64", 
> > > "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", "ID70", "ID71", 
> > > "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", "ID78", "ID79", 
> > > "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", "ID85", "ID86", 
> > > "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", "ID92", "ID93", 
> > > "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"), class = "factor"), 
> > > structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
> > > ), .Label = c("Issuer1", "Issuer10", "Issuer100", "Issuer11", 
> > > "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
> > > "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", 
> > > "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", 
> > > "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", 
> > > "Issuer30", "Issuer31", "Issuer32", "Issuer33", "Issuer34", 
> > > "Issuer35", "Issuer36", "Issuer37", "Issuer38", "Issuer39", 
> > > "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
> > > "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", 
> > > "Issuer49", "Issuer5", "Issuer50", "Issuer51", "Issuer52", 
> > > "Issuer53", "Issuer54", "Issuer55", "Issuer56", "Issuer57", 
> > > "Issuer58", "Issuer59", "Issuer6", "Issuer60", "Issuer61", 
> > > "Issuer62", "Issuer63", "Issuer64", "Issuer65", "Issuer66", 
> > > "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
> > > "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", 
> > > "Issuer76", "Issuer77", "Issuer78", "Issuer79", "Issuer8", 
> > > "Issuer80", "Issuer81", "Issuer82", "Issuer83", "Issuer84", 
> > > "Issuer85", "Issuer86", "Issuer87", "Issuer88", "Issuer89", 
> > > "Issuer9", "Issuer90", "Issuer91", "Issuer92", "Issuer93", 
> > > "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
> > > "Issuer99"), class = "factor"), c(95.5, 98.5, 98.5, 99.5, 
> > > 103.5, 98.563, 99.75, 98.5, 98.75, 99.125), c(97.5, 99.5, 
> > > 99.5, 100.375, 104.5, 99.188, 100.25, 99.5, 99.75, 100.063
> > > ), c(2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 4L), c(4L, 5L, 5L, 
> > > 5L, 5L, 2L, 3L, 5L, 3L, 2L), c(TRUE, FALSE, FALSE, TRUE, 
> > > FALSE, TRUE, TRUE, FALSE, FALSE, TRUE), structure(c(1L, 1L, 
> > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > structure(c(9L, 2L, 2L, 1L, 2L, 1L, 3L, 3L, 5L, 9L), .Label = c("B", 
> > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
> > > ), class = "factor"), structure(c(8L, 2L, 2L, 1L, 8L, 2L, 
> > > 2L, 2L, 1L, 7L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
> > > "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(20L, 
> > > 88L, 88L, 6L, 3L, 35L, 29L, 24L, 53L, 82L), .Label = c("1/11/2019", 
> > > "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
> > > "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
> > > "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
> > > "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
> > > "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
> > > "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
> > > "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
> > > "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
> > > "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
> > > "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
> > > "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
> > > "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
> > > "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
> > > "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
> > > "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
> > > "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
> > > "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
> > > "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
> > > c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > FALSE, FALSE), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 
> > > 10L, 41L, 67L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > "Issuer98", "Issuer99"), class = "factor"), structure(c(12L, 
> > > 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L), .Label = c("BL1", 
> > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
> > > "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
> > > "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
> > > "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
> > > "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
> > > "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
> > > "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
> > > "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
> > > "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
> > > "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
> > > "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(4L, 
> > > 3L, 3L, 5L, 6L, 3L, 2L, 6L, 6L, 5L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > "Retail", "Services: Business"), class = "factor"), structure(c(3L, 
> > > 5L, 5L, 6L, 4L, 3L, 4L, 2L, 6L, 6L), .Label = c("Financial Intermediaries", 
> > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 6L, 8L, 8L), .Label = c("AU", 
> > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 5L, 6L, 6L), .Label = c("1", 
> > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L), .Label = c("Canada", 
> > > "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
> > > 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > structure(c(2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > c(0.125550168, 1.731733265, 1.731733265, NA, 5.246485518, 
> > > 7.798802147, NA, NA, NA, NA), c(4770L, 3490L, 3490L, 3490L, 
> > > 3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.45, 0.4, 0.4, 
> > > 0.45, 0.55, 0.4, 0.4, 0.45, 0.4, 0.5), c(4770L, 3490L, 3490L, 
> > > 3490L, 3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.55, 
> > > 0.4, 0.4, 0.4, 0.55, 0.4, 0.5, 0.5, 0.45, 0.55), c(18L, 15L, 
> > > 15L, 15L, 18L, 15L, 15L, 15L, 14L, 17L), c(17L, 16L, 16L, 
> > > 15L, 14L, 15L, 15L, 15L, 14L, 15L), c(192500000, 205000000, 
> > > 205000000, 342000000, 120000000, 835000000, 1043700000, 160000000, 
> > > 300000000, 265000000), c(0.02, 0.02, 0.02, 0.4, 0.02, 0.4, 
> > > 0.6, 0.6, 0.6, 0.02), c(850L, 475L, 475L, 500L, 1000L, 350L, 
> > > 400L, 975L, 500L, 700L), c(1, 1.5, 1.5, 1, 1.25, 1, 1, 1, 
> > > 1, 1), c(0.0851, 0.04765, 0.04765, 0.0501, 0.100125, 0.0351, 
> > > 0.0401, 0.0976, 0.0501, 0.0701), c(0.099192999, 0.023321348, 
> > > 0.023321348, 0.06465519, 0.103470278, 0.052237196, 0.051331755, 
> > > 0.112300026, 0.066116739, 0.084107871), c(897.0917677, -1.49365213, 
> > > -1.49365213, 549.0886934, 975.9481504, 429.1863229, 436.2991366, 
> > > 1062.374805, 567.0741295, 747.1023728), c(0.088186528, 0.048131313, 
> > > 0.048131313, 0.050131332, 0.096274038, 0.035499188, 0.040049938, 
> > > 0.098585859, 0.050478589, 0.070385766), c(0L, 0L, 0L, 0L, 
> > > 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
> > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > c(0.0178406708595388, 0.0136532951289398, 0.0136532951289398, 
> > > 0.0143553008595989, 0.028689111747851, 0.0100573065902579, 
> > > 0.0180630630630631, 0.043963963963964, 0.0225675675675676, 
> > > 0.0200859598853868), c(0.046805, 0.01906, 0.01906, 0.02004, 
> > > 0.05506875, 0.01404, 0.02005, 0.0488, 0.022545, 0.038555), 
> > > c(0.001702, 0.000953, 0.000953, 0.02004, 0.0020025, 0.01404, 
> > > 0.02406, 0.05856, 0.03006, 0.001402)), V2 = list(c(93L, 3L, 
> > > 85L, 34L, 20L, 89L, 16L, 25L, 83L, 90L), c(1, 1, 2, 3, 4, 5, 
> > > 6, 7, 8, 9), c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), c(0, 
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0), structure(c(94L, 24L, 85L, 29L, 14L, 
> > > 89L, 9L, 19L, 83L, 91L), .Label = c("ID1", "ID10", "ID100", "ID11", 
> > > "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
> > > "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> > > "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", 
> > > "ID34", "ID35", "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", 
> > > "ID41", "ID42", "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", 
> > > "ID49", "ID5", "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", 
> > > "ID56", "ID57", "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", 
> > > "ID63", "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
> > > "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", 
> > > "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", 
> > > "ID85", "ID86", "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", 
> > > "ID92", "ID93", "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"
> > > ), class = "factor"), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
> > > 9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
> > > "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> > > "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
> > > "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", "Issuer32", 
> > > "Issuer33", "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
> > > "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", "Issuer49", 
> > > "Issuer5", "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
> > > "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", "Issuer6", 
> > > "Issuer60", "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
> > > "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", "Issuer76", 
> > > "Issuer77", "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
> > > "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", "Issuer87", 
> > > "Issuer88", "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
> > > "Issuer99"), class = "factor"), c(99.5, 99.646, 100.402, 100.25, 
> > > 98, 99.563, 99.563, 99.388, 99.531, 103.5), c(100.5, 100.271, 
> > > 100.903, 100.75, 99, 100.188, 100.063, 99.788, 100.125, 104.5
> > > ), c(1L, 6L, 9L, 1L, 1L, 2L, 2L, 10L, 4L, 2L), c(5L, 2L, 1L, 
> > > 3L, 3L, 4L, 4L, 1L, 1L, 5L), c(TRUE, TRUE, FALSE, FALSE, TRUE, 
> > > FALSE, FALSE, TRUE, TRUE, FALSE), structure(c(1L, 1L, 1L, 1L, 
> > > 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > structure(c(8L, 1L, 4L, 1L, 3L, 4L, 6L, 1L, 5L, 2L), .Label = c("B", 
> > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
> > > ), class = "factor"), structure(c(7L, 2L, 5L, 2L, 1L, 2L, 
> > > 6L, 1L, 5L, 8L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
> > > "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(41L, 
> > > 1L, 13L, 43L, 21L, 87L, 49L, 73L, 46L, 3L), .Label = c("1/11/2019", 
> > > "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
> > > "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
> > > "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
> > > "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
> > > "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
> > > "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
> > > "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
> > > "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
> > > "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
> > > "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
> > > "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
> > > "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
> > > "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
> > > "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
> > > "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
> > > "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
> > > "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
> > > "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
> > > c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > FALSE, FALSE), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
> > > 9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > "Issuer98", "Issuer99"), class = "factor"), structure(c(94L, 
> > > 24L, 85L, 29L, 14L, 89L, 9L, 19L, 83L, 91L), .Label = c("BL1", 
> > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
> > > "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
> > > "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
> > > "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
> > > "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
> > > "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
> > > "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
> > > "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
> > > "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
> > > "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
> > > "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(2L, 
> > > 2L, 3L, 6L, 1L, 6L, 6L, 6L, 1L, 6L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > "Retail", "Services: Business"), class = "factor"), structure(c(6L, 
> > > 6L, 3L, 5L, 1L, 2L, 5L, 3L, 2L, 4L), .Label = c("Financial Intermediaries", 
> > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L), .Label = c("AU", 
> > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label = c("1", 
> > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("Canada", 
> > > "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
> > > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > structure(c(2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > c(2.603554841, 7.27032758, 3.155438813, 5.037267081, 0.125550168, 
> > > NA, 3.464301168, NA, 4.816376964, 5.246485518), c(2220L, 
> > > 2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 2220L, 3490L
> > > ), c(0.55, 0.45, 0.5, 0.4, 0.6, 0.45, 0.45, 0.55, 0.2, 0.55
> > > ), c(2220L, 2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 
> > > 2220L, 3490L), c(0.55, 0.45, 0.5, 0.4, 0.3, 0.45, 0.45, 0.4, 
> > > 0.2, 0.55), c(17L, 15L, 12L, 15L, 14L, 15L, 13L, 14L, 12L, 
> > > 18L), c(16L, 16L, 14L, 16L, 15L, 12L, 13L, 15L, 14L, 14L), 
> > > c(200000000, 613811406, 750000000, 200000000, 405500000, 
> > > 450000000, 530000000, 2010000000, 775000000, 120000000), 
> > > c(0.02, 0.5, 0.65, 0.27, 0.5, 0.65, 0.65, 0.3, 0.65, 0.02
> > > ), c(950L, 350L, 350L, 275L, 450L, 275L, 225L, 325L, 275L, 
> > > 1000L), c(1.25, 1, 0.75, 0.75, 1, 0.75, 0, 1, 0.75, 1.25), 
> > > c(0.095125, 0.0351, 0.035075, 0.027575, 0.0451, 0.027575, 
> > > 0.02527, 0.0326, 0.027575, 0.100125), c(0.104211455, 0.046414939, 
> > > 0.050338657, 0.027233401, 0.059885473, 0.03459045, 0.028669191, 
> > > 0.048294163, 0.040935438, 0.103470278), c(980.5501911, 400.3544693, 
> > > 385.8629241, 244.6340073, 511.2711809, 294.3073789, 194.2034583, 
> > > 385.9437059, 308.4324006, 975.9481504), c(0.095125, 0.035114573, 
> > > 0.034847619, 0.027437811, 0.045786802, 0.027609374, 0.025317343, 
> > > 0.032734868, 0.027622511, 0.096274038), c(0L, 0L, 0L, 0L, 
> > > 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
> > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > c(0.0428490990990991, 0.0158108108108108, 0.037313829787234, 
> > > 0.00790114613180516, 0.00945492662473794, 0.0124211711711712, 
> > > 0.0143091732729332, 0.00934097421203438, 0.0124211711711712, 
> > > 0.028689111747851), c(0.05231875, 0.015795, 0.0175375, 0.01103, 
> > > 0.01353, 0.01240875, 0.0113715, 0.01304, 0.005515, 0.05506875
> > > ), c(0.0019025, 0.01755, 0.02279875, 0.00744525, 0.02255, 
> > > 0.01792375, 0.0164255, 0.00978, 0.01792375, 0.0020025)), 
> > > V3 = list(c(47L, 95L, 26L, 64L, 16L, 55L, 61L, 39L, 23L, 
> > > 66L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, NA, NA, 
> > > NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 
> > > 64L), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", 
> > > "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
> > > "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", 
> > > "ID26", "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", 
> > > "ID32", "ID33", "ID34", "ID35", "ID36", "ID37", "ID38", 
> > > "ID39", "ID4", "ID40", "ID41", "ID42", "ID43", "ID44", 
> > > "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", "ID50", 
> > > "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
> > > "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", 
> > > "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
> > > "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", 
> > > "ID77", "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", 
> > > "ID83", "ID84", "ID85", "ID86", "ID87", "ID88", "ID89", 
> > > "ID9", "ID90", "ID91", "ID92", "ID93", "ID94", "ID95", 
> > > "ID96", "ID97", "ID98", "ID99"), class = "factor"), structure(c(43L, 
> > > 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("Issuer1", 
> > > "Issuer10", "Issuer100", "Issuer11", "Issuer12", "Issuer13", 
> > > "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", 
> > > "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", 
> > > "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
> > > "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", 
> > > "Issuer32", "Issuer33", "Issuer34", "Issuer35", "Issuer36", 
> > > "Issuer37", "Issuer38", "Issuer39", "Issuer4", "Issuer40", 
> > > "Issuer41", "Issuer42", "Issuer43", "Issuer44", "Issuer45", 
> > > "Issuer46", "Issuer47", "Issuer48", "Issuer49", "Issuer5", 
> > > "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
> > > "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", 
> > > "Issuer6", "Issuer60", "Issuer61", "Issuer62", "Issuer63", 
> > > "Issuer64", "Issuer65", "Issuer66", "Issuer67", "Issuer68", 
> > > "Issuer69", "Issuer7", "Issuer70", "Issuer71", "Issuer72", 
> > > "Issuer73", "Issuer74", "Issuer75", "Issuer76", "Issuer77", 
> > > "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
> > > "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", 
> > > "Issuer87", "Issuer88", "Issuer89", "Issuer9", "Issuer90", 
> > > "Issuer91", "Issuer92", "Issuer93", "Issuer94", "Issuer95", 
> > > "Issuer96", "Issuer97", "Issuer98", "Issuer99"), class = "factor"), 
> > > c(99.688, 75.667, 99.229, 99.583, 99.563, 99.188, 98.8, 
> > > 98.5, 99, 99.75), c(100.281, 78.667, 100.104, 100.333, 
> > > 100.063, 99.906, 99.75, 99.5, 99.75, 100.25), c(4L, 3L, 
> > > 6L, 3L, 2L, 4L, 5L, 1L, 1L, 1L), c(4L, 3L, 1L, 3L, 4L, 
> > > 2L, 4L, 5L, 3L, 3L), c(FALSE, TRUE, TRUE, TRUE, FALSE, 
> > > TRUE, TRUE, FALSE, TRUE, TRUE), structure(c(1L, 1L, 1L, 
> > > 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > structure(c(3L, 8L, 9L, 1L, 6L, 3L, 10L, 10L, 9L, 3L), .Label = c("B", 
> > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", 
> > > "NR"), class = "factor"), structure(c(6L, 7L, 7L, 2L, 
> > > 6L, 1L, 9L, 9L, 8L, 2L), .Label = c("B1", "B2", "B3", 
> > > "Ba1", "Ba2", "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), 
> > > structure(c(66L, 80L, 74L, 30L, 49L, 72L, 70L, 62L, 10L, 
> > > 29L), .Label = c("1/11/2019", "1/2/2019", "1/2/2020", 
> > > "1/30/2022", "10/15/2016", "10/15/2021", "10/17/2019", 
> > > "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", 
> > > "11/12/2020", "11/20/2019", "11/20/2020", "11/27/2020", 
> > > "11/5/2021", "11/6/2020", "11/9/2017", "11/9/2018", "12/15/2018", 
> > > "12/15/2021", "12/15/2022", "12/16/2019", "12/18/2020", 
> > > "12/20/2019", "12/7/2018", "12/7/2019", "2/12/2021", 
> > > "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", "2/24/2017", 
> > > "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", "3/21/2019", 
> > > "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", "4/30/2018", 
> > > "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", "5/15/2018", 
> > > "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", "5/8/2020", 
> > > "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", "6/2/2019", 
> > > "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", "6/30/2017", 
> > > "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", "7/10/2020", 
> > > "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", "7/29/2022", 
> > > "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", "8/12/2021", 
> > > "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", "8/24/2017", 
> > > "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", "9/18/2016", 
> > > "9/18/2019", "9/20/2019"), class = "factor"), c(FALSE, 
> > > FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > FALSE), structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 
> > > 34L, 17L, 64L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > "Issuer98", "Issuer99"), class = "factor"), structure(c(43L, 
> > > 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("BL1", 
> > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", 
> > > "BL22", "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", 
> > > "BL29", "BL3", "BL30", "BL31", "BL32", "BL33", "BL34", 
> > > "BL35", "BL36", "BL37", "BL38", "BL39", "BL4", "BL40", 
> > > "BL41", "BL42", "BL43", "BL44", "BL45", "BL46", "BL47", 
> > > "BL48", "BL49", "BL5", "BL50", "BL51", "BL52", "BL53", 
> > > "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", "BL6", 
> > > "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", 
> > > "BL73", "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", 
> > > "BL8", "BL80", "BL81", "BL82", "BL83", "BL84", "BL85", 
> > > "BL86", "BL87", "BL88", "BL89", "BL9", "BL90", "BL91", 
> > > "BL92", "BL93", "BL94", "BL95", "BL96", "BL97", "BL98", 
> > > "BL99"), class = "factor"), structure(c(1L, 6L, 6L, 4L, 
> > > 6L, 4L, 6L, 2L, 6L, 2L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > "Retail", "Services: Business"), class = "factor"), structure(c(2L, 
> > > 2L, 1L, 5L, 5L, 3L, 3L, 6L, 2L, 4L), .Label = c("Financial Intermediaries", 
> > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 5L, 8L, 8L, 8L), .Label = c("AU", 
> > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 3L, 6L, 6L, 6L), .Label = c("1", 
> > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L, 4L), .Label = c("Canada", 
> > > "Europe", "Other", "U.S."), class = "factor"), structure(c(2L, 
> > > 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > "Y"), class = "factor"), structure(c(1L, 2L, 2L, 1L, 
> > > 1L, 1L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > c(8.74248921, NA, NA, 4.338507174, 3.464301168, NA, NA, 
> > > NA, NA, NA), c(2220L, 2220L, 3490L, 3490L, 1766L, 2220L, 
> > > 8070L, 8070L, 3490L, 2220L), c(0.6, 0.55, 0.4, 0.4, 0.45, 
> > > 0.45, 0.4, 0.45, 0.6, 0.4), c(2220L, 2220L, 3490L, 3490L, 
> > > 1766L, 2220L, 8070L, 8070L, 3490L, 2220L), c(0.3, 0.55, 
> > > 0.55, 0.4, 0.45, 0.4, 0.45, 0.3, 0.55, 0.5), c(13L, 17L, 
> > > 17L, 15L, 13L, 14L, 19L, 19L, 18L, 15L), c(15L, 16L, 
> > > 15L, 15L, 13L, 14L, 19L, 19L, 15L, 15L), c(625000000, 
> > > 450000000, 760000000, 630000000, 530000000, 671500000, 
> > > 240000000, 100000000, 375000000, 1043700000), c(0.5, 
> > > 0.02, 0.02, 0.3, 0.65, 0.3, 0.5, 0.65, 0.02, 0.6), c(275L, 
> > > 750L, 650L, 300L, 225L, 300L, 700L, 925L, 825L, 400L), 
> > > c(0, 1, 1, 1.25, 0, 1, 1, 1.25, 1.25, 1), c(0.03027, 
> > > 0.0751, 0.0651, 0.030125, 0.02527, 0.0301, 0.0701, 0.092625, 
> > > 0.082625, 0.0401), c(0.031286195, 0.154827358, 0.080695261, 
> > > 0.041683558, 0.028669191, 0.044131997, 0.084009559, 0.108958135, 
> > > 0.090916682, 0.051331755), c(263.290277, 1448.101305, 
> > > 704.3633733, 368.0708419, 194.2034583, 356.3784942, 746.772345, 
> > > 1036.334285, 875.917553, 436.2991366), c(0.030274693, 
> > > 0.097321394, 0.065317835, 0.030137658, 0.025317343, 0.030236973, 
> > > 0.070611937, 0.093560606, 0.083144654, 0.040049938), 
> > > c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 
> > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), 
> > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > c(0.0136351351351351, 0.0338288288288288, 0.0186532951289398, 
> > > 0.00863180515759312, 0.0143091732729332, 0.0135585585585586, 
> > > 0.00868649318463445, 0.0114776951672862, 0.0236747851002865, 
> > > 0.0180630630630631), c(0.009081, 0.041305, 0.035805, 
> > > 0.01205, 0.0113715, 0.01204, 0.031545, 0.0277875, 0.04544375, 
> > > 0.02005), c(0.015135, 0.001502, 0.001302, 0.0090375, 
> > > 0.0164255, 0.00903, 0.03505, 0.06020625, 0.0016525, 0.02406
> > > ))), .Names = c("V1", "V2", "V3"), row.names = c(NA, 
> > > -48L), class = c("data.table", "data.frame"))
> > > 
> > > 
> > > 
> > >> Subject: Re: [R] binding two lists of lists of dataframes together
> > >> From: dwinsemius at comcast.net
> > >> Date: Tue, 12 May 2015 11:36:50 -0700
> > >> CC: r-help at r-project.org
> > >> To: newrnewbie at hotmail.com
> > >> 
> > >> 
> > >> On May 12, 2015, at 9:24 AM, Vin Cheng wrote:
> > >> 
> > >>> list1<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L), 
> > >>> WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > >>> structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
> > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
> > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > >>> structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
> > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
> > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > >>> .Names = c("id", "WgtBand", "Wgt")))
> > >>> 
> > >>> 
> > >>> list2<-list(structure(list(id = c(493L, 564L, 147L), 
> > >>> WgtBand = c(1, 2, 3), 
> > >>> Wgt = c(NaN, NaN, NA)), 
> > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > >>> structure(list(id = c(276L, 411L, 574L,111L), 
> > >>> WgtBand = c(1, 2, 3,4), 
> > >>> Wgt = c(NaN, NaN, NA,NA)), 
> > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > >>> structure(list(id = c(76L, 330L), 
> > >>> WgtBand = c(1, 1), 
> > >>> Wgt = c(NaN, NaN)), 
> > >>> .Names = c("id", "WgtBand", "Wgt")))
> > >>> 
> > >>> list3<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L,493L, 564L, 147L), 
> > >>> WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9,1, 2, 3), 
> > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA)), 
> > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > >>> structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,276L, 411L, 574L,111L), 
> > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 2, 3,4), 
> > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA,NA)), 
> > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > >>> structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,76L, 330L), 
> > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 1), 
> > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN)), 
> > >>> .Names = c("id", "WgtBand", "Wgt")))
> > >> 
> > >> I get something like the desired structure with:
> > >> 
> > >> mapply(function(x,y) mapply(c, x,y), list1,list2)
> > >> 
> > >> I can make it closer with:
> > >> 
> > >> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) unclass( as.data.frame(x) ) )
> > >> 
> > >> 
> > >> Or even closer with:
> > >> 
> > >> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) as.list( as.data.frame(x) ) )
> > >> 
> > >> `identical` does not return TRUE but I cannot see where the difference lies.
> > >> 
> > >> -- 
> > >> 
> > >> David Winsemius
> > >> Alameda, CA, USA
> > >> 
> > > 
> > > [[alternative HTML version deleted]]
> > > 
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > 
> > David Winsemius
> > Alameda, CA, USA
> > 

David Winsemius
Alameda, CA, USA


From arz at berkeley.edu  Wed May 13 06:30:26 2015
From: arz at berkeley.edu (Adam Zeilinger)
Date: Tue, 12 May 2015 21:30:26 -0700
Subject: [R] Questions about permutation tests and error when using
 clusterCall (snow package)
Message-ID: <5552D362.9010302@berkeley.edu>

Hello R help,

I am trying to run a permutation (or randomization) test on a mixed 
effects model.  The randomization is somewhat complex because I want to 
maintain the nested and unbalanced structure of the data.  I am trying 
two different methods.  The first is the PermTest() function in the 
pgirmess package.  The function works fine but the documentation is 
sparse, so I don't know whether it is maintaining the structure of the 
data.  Can anyone help elucidate what is happening in this function?

Second, I wrote my own function for the permutation test.  I would like 
to run it in parallel using clusterCall() from the snow package.  But I 
am having trouble understanding how to specify clusterCall().  The 
attempt described below returns an error:
"Error in checkForRemoteErrors(lapply(cl, recvResult)) : 3 nodes 
produced errors; first error: invalid 'length' argument".

I am working in R 3.2.0 in Windows 8.1 with following versions of the 
required packages: nlme 3.1-120; snow 0.3-13; pgirmess 1.6.0.
Any help would be much appreciated.

#### Permutation test on cluster

require(nlme); require(snow); require(pgirmess)

# Data frame
data <- structure(list(year = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("2009", "2010",
"2011"), class = "factor"), region = structure(c(1L, 1L, 1L,
1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("1",
"2"), class = "factor"), site = structure(c(1L, 1L, 1L, 2L, 2L,
2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 1L, 1L,
1L, 2L, 2L, 2L, 3L, 3L, 3L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L,
2L, 2L, 1L, 2L, 2L, 3L, 3L, 3L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 1L,
1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 3L,
3L, 3L, 1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L), .Label = c("1",
"2", "3"), class = "factor"), crop = structure(c(1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label = c("1",
"2", "3", "4"), class = "factor"), field = structure(c(1L, 2L,
3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L, 1L, 2L,
3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 3L, 1L, 2L, 3L, 1L,
2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 2L, 3L,
1L, 2L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L, 3L, 1L, 2L, 3L,
2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L), .Label = c("1",
"2", "3"), class = "factor"), lnlambda = c(-0.211969959, 0.119059554,
0.248738781, 0.390197821, 0.719815401, -0.643549723, 1.098612289,
0.416209183, 0.208254863, 0.358886297, 0.182792279, 0.981156325,
0.336352229, -1.098745298, 0.693147181, 0.69311718, -0.887324338,
-0.054062388, 0.250599173, -0.693177181, 0.223128351, -0.539010787,
-0.080041541, 0.328540866, 0.048785402, -0.287756742, -0.213609149,
0.470018629, -2.385966702, -0.731888009, -2.137070655, 0.035367144,
-1.027222293, 0.287432041, 0.462475363, 0.347129531, 0.762206716,
0.721248611, -1.789761467, 0, 1.098612289, 0.78845736, -0.336872317,
0.182321557, 0.287432041, 0.470003629, 0, -0.693147181, -0.693147181,
-1.386294361, 0.405465108, -0.095410185, -0.423120043, -0.655851396,
1.148671489, -0.759286983, 0.442760893, 0.783901544, 2.257169229,
0.63180355, -2.253794929, -0.570929548, -1.111697528, 0.251536626,
-1.099612789, 0.693147181, -0.811930717, -0.510825624, -0.287682072,
0.133656385, -0.251028755, -0.693147181, -1.789761467, -1.251763468,
0.336472237, -1.448169765, -1.703748592, 1.386294361, 0.251536626,
-0.916290732)), .Names = c("year", "region", "site", "crop",
"field", "lnlambda"), row.names = c(1L, 2L, 3L, 4L, 5L, 6L, 7L,
8L, 9L, 10L, 11L, 12L, 13L, 14L, 16L, 17L, 19L, 20L, 21L, 22L,
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 49L, 51L, 52L, 53L, 54L,
55L, 56L, 57L, 58L, 59L, 60L, 61L, 65L, 66L, 67L, 68L, 69L, 70L,
71L, 72L, 74L, 75L, 76L, 77L, 97L, 98L, 99L, 100L, 101L, 102L,
103L, 104L, 106L, 107L, 108L, 109L, 110L, 111L, 113L, 114L, 115L,
116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L, 125L, 126L
), class = "data.frame")

# random effects model
mod <- lme(lnlambda ~ year*region*crop, data = data, random = list(site 
= ~1|year:region))

# Randomization test using PermTest()
# Not sure what it's doing
permtest1 <- PermTest(mod, B = 100)

# DIY permutation test with cluster
ti <- proc.time() # Initial time
cl <- makeCluster(3, type = "SOCK") # Make cluster
   require(nlme)
   clusterExport(cl, "data") # Send "data" to each node
   # Set up function to randomize response
   randTest <- function(data){
     # Randomize response variable, thereby preserving nested and 
unbalanced structure
     data$randomLambda <- sample(data$lnlambda)
     # Fit LME model
     lmeResults <- anova(lme(randomLambda ~ year*region*crop, data = 
data, random = list(site = ~1|year:region)))
     return(lmeResults)
   }
   # Call to cluster with replicate() function
   rtoutCluster <- clusterCall(cl, function(n.iter = 100) 
replicate(n.iter, randTest(data),
simplify = FALSE),
                               data)
stopCluster(cl)
tf <- proc.time() # End time
# Time it took
print(tf - ti)

Thanks in advance for your help,
Adam


-- 
Adam Zeilinger
Postdoctoral scholar
Berkeley Initiative for Global Change Biology
University of California Berkeley


From ragia11 at hotmail.com  Wed May 13 08:04:08 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Wed, 13 May 2015 09:04:08 +0300
Subject: [R] matrix inf and zero's value replacement
Message-ID: <DUB125-W15555073A4BB58E0C73C4AB3D90@phx.gbl>

Dear Group,
I have the following matrix
m
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
[1,]    0    2    1  Inf  Inf  Inf  Inf  Inf
[2,]    1    0    2  Inf  Inf  Inf  Inf  Inf
[3,]    2    1    0  Inf  Inf  Inf  Inf  Inf
[4,]    3    2    1    0  Inf  Inf  Inf  Inf
[5,]  Inf  Inf  Inf  Inf    0  Inf  Inf  Inf
[6,]  Inf  Inf  Inf  Inf    1    0  Inf  Inf
[7,]  Inf  Inf  Inf  Inf  Inf  Inf    0  Inf
[8,]    1    3    2  Inf  Inf  Inf    1    0

I want  all values grater than 0 = to 1 and zero other wise?
thanks in advance
so 
this used, 
m <-ifelse(  (m==0)||  is.infinite(m),0, 1   )

but it gave me  zero   result
replacing
|| with | ,make sense and return the matrix I was looking for.

what is the difference betwen boht || an | ? when to use each ?

thanks in advance
 		 	   		  
	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Wed May 13 08:38:23 2015
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Wed, 13 May 2015 09:38:23 +0300
Subject: [R] Mean rain per rain day
Message-ID: <CAGh51gSOe3JnR_xBRxKOjNABNfzVy-Cjdway_MmZ9oFxJHgeXg@mail.gmail.com>

Hi All,

I want to compute Mean rain per rain day from rainfall data but i don't
know how to go about that. Anyone who understand the approach I can use can
help me. In addition, I would like to have RScript which can help me to
compute it. thanks.

Regards,
Frederic.

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Wed May 13 08:47:48 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 13 May 2015 08:47:48 +0200
Subject: [R] matrix inf and zero's value replacement
In-Reply-To: <DUB125-W15555073A4BB58E0C73C4AB3D90@phx.gbl>
References: <DUB125-W15555073A4BB58E0C73C4AB3D90@phx.gbl>
Message-ID: <5552F394.4070101@statistik.tu-dortmund.de>



On 13.05.2015 08:04, Ragia Ibrahim wrote:
> Dear Group,
> I have the following matrix
> m
>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
> [1,]    0    2    1  Inf  Inf  Inf  Inf  Inf
> [2,]    1    0    2  Inf  Inf  Inf  Inf  Inf
> [3,]    2    1    0  Inf  Inf  Inf  Inf  Inf
> [4,]    3    2    1    0  Inf  Inf  Inf  Inf
> [5,]  Inf  Inf  Inf  Inf    0  Inf  Inf  Inf
> [6,]  Inf  Inf  Inf  Inf    1    0  Inf  Inf
> [7,]  Inf  Inf  Inf  Inf  Inf  Inf    0  Inf
> [8,]    1    3    2  Inf  Inf  Inf    1    0
>
> I want  all values grater than 0 = to 1 and zero other wise?
> thanks in advance
> so
> this used,
> m <-ifelse(  (m==0)||  is.infinite(m),0, 1   )
>
> but it gave me  zero   result
> replacing
> || with | ,make sense and return the matrix I was looking for.
>
> what is the difference betwen boht || an | ? when to use each ?

|| only for scalars, see the documentation.

 From your text you want something different:
m[m>0] <- 1

but your code says you want to replace Inf by 0?

Best,
Uwe Ligges



> thanks in advance
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From thierry.onkelinx at inbo.be  Wed May 13 09:53:31 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 13 May 2015 09:53:31 +0200
Subject: [R] Code works on Mac but not Windows
In-Reply-To: <A84F5155-57D0-4127-943D-9DD0E3E17F05@me.com>
References: <eab3ceb9-11e6-42cb-bf6f-6091e5afdc8c@me.com>
	<CAJuCY5zjtVb+oG8Oez=SLkT=j7xNmqiH_OJ=6FDs4i9cQX3RkA@mail.gmail.com>
	<A84F5155-57D0-4127-943D-9DD0E3E17F05@me.com>
Message-ID: <CAJuCY5y3ky5X=XtrymT5Fg1QNSW5BXeed5761=kr=_RRKtNSvw@mail.gmail.com>

Dear Glenn,

Please keep the mailing list in cc.

In this case I would drop the "signature" like values and use correct
defaults.

TermStructure <- function(rates.data, method = "ns")

you can drop if(missing(method)) method = "ns" in that case.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-12 13:43 GMT+02:00 Glenn Schultz <glennmschultz at me.com>:

> Hi Thierry,
> Thanks,  I see what you are saying.  I should alter the code to test for
> values, correct?
>
> Glenn
>
> Sent from my iPhone
>
> On May 12, 2015, at 2:40 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> Dear Glenn,
>
> I think that you are confusing the signature of a method and the default
> values of of function. It looks like you want the signature(rates.data =
> "character", method = "character"). But you are setting "character" as
> default value of both function arguments. Since you define a default value
> for methods, it will not be missing when you omit is from the call.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-05-11 17:36 GMT+02:00 Glenn Schultz <glennmschultz at me.com>:
>
>> Hi Thierry,
>>
>> Below is the function
>> setMethod("initialize", signature("TermStructure"), function(.Object,...,
>> tradedate = "character", period = "numeric", date = "character", spotrate
>> = "numeric", forwardrate = "numeric", TwoYearFwd = "numeric", TenYearFwd
>> = "numeric") { .Object at tradedate = tradedate .Object at period = period .
>> Object at date = date .Object at spotrate = spotrate .Object at forwardrate =
>> forwardrate .Object at TwoYearFwd = TwoYearFwd .Object at TenYearFwd =
>> TenYearFwd return(.Object) callNextMethod(.Object,...) })#' The
>> TermStructure constructor function it is a wrapper function around the
>> package termstrc#' #' This is a wrapper function around the R package
>> termstrc. The function passes swap rate data#' cash flows the to
>> termstrc and creates the TermStructure object used by Bondlab.#' The
>> function call rates data processes the yield curve and derives cashflow#'
>> for the daily close swap curve. A Rates object must be called in the local#'
>> environment for this function to work.#' @param rates.data A character
>> string representing the data for which the user#' would like to call the
>> swap curve#' @param method A character string indicating the fitting
>> method ns = Nelson Siegel, dl = Diebold Lee,#' sv = Severson, asv =
>> adjusted Severson, cs = cubic spline (not yet implemented in Bond Lab).#'
>> For addiition details see the termstrc documentation.#' @examples#'
>> \dontrun{#' TermStructure(rates.data = "01-10-2013", method = "ns")}#'
>> @importFrom lubridate %m+%#' @importFrom lubridate years#' @importFrom
>> lubridate day#' @importFrom lubridate month#' @importFrom termstrc
>> estim_nss estim_cs spotrates forwardrates#'@export TermStructure
>> TermStructure <- function(rates.data = "character", method = "character"
>> ){ #function(trade.date = "character", method = "character") #Error Trap
>> User inputs to the function if(missing(rates.data)) stop("missing rates
>> data object") # this is the code snippet that works in MAC but not
>> windows *#Default to Nelson-Siegel** if(missing(method)) method = "ns"* #Default
>> to parametric if(method == "cs") stop("cubic spline not implemented") #Check
>> that the user input a valid method CheckMethod <- c("ns", "dl", "sv", "
>> asv", "cs") if(!method %in% CheckMethod) stop ("Invalid 'method' Value") #
>> pass the yield curve to the function rates.data <- rates.data #set the
>> column counter to make cashflows for termstrucutre ColCount <-
>> as.numeric(ncol(rates.data)) Mat.Years <- as.numeric(rates.data[2,2:
>> ColCount]) Coupon.Rate <- as.numeric(rates.data[1,2:ColCount]) Issue.Date
>> <- as.Date(rates.data[1,1]) #initialize coupon bonds S3 class #This can
>> be upgraded when bondlab has portfolio function ISIN <- vector()
>> MATURITYDATE <- vector() ISSUEDATE <- vector() COUPONRATE <- vector()
>> PRICE <- vector() ACCRUED <- vector() CFISIN <- vector() CF <- vector()
>> DATE <- vector() CASHFLOWS <- list(CFISIN,CF,DATE) names(CASHFLOWS) <- c(
>> "ISIN","CF","DATE") TODAY <- vector() data <- list() TSInput <- list() ###
>> Assign Values to List Items ######### data = NULL data$ISIN <- colnames(
>> rates.data[2:ColCount]) data$ISSUEDATE <- rep(as.Date(rates.data[1,1]),
>> ColCount - 1) data$MATURITYDATE <- sapply(Mat.Years, function(Mat.Years =
>> Mat.Years, Issue = Issue.Date) {Maturity = if(Mat.Years < 1) {Issue %m+%
>> months(round(Mat.Years * months.in.year))} else {Issue %m+%
>> years(as.numeric(Mat.Years))} return(as.character(Maturity)) })  data$
>> COUPONRATE <- ifelse(Mat.Years < 1, 0, Coupon.Rate)  data$PRICE <-
>> ifelse(Mat.Years < 1, (1 + (Coupon.Rate/100))^(Mat.Years * -1) * 100, 100
>> ) data$ACCRUED <- rep(0, ColCount -1) for(j in 1:(ColCount-1)){
>> Vector.Length <- as.numeric(round(difftime(data[[3]][j], data[[2]][j],
>> units = c("weeks"))/weeks.in.year,0)) Vector.Length <- ifelse(
>> Vector.Length < 1, 1, Vector.Length * pmt.frequency) #pmt.frequency
>> should be input  data$CASHFLOWS$ISIN <- append(data$CASHFLOWS$ISIN, rep(
>> data[[1]][j],Vector.Length)) data$CASHFLOWS$CF <- append(data$CASHFLOWS$
>> CF, as.numeric(c(rep((data[[4]][j]/100/pmt.frequency), Vector.Length-1) *
>> min.principal, (min.principal + (data$COUPONRATE[j]/100/pmt.frequency)*
>> min.principal)))) by.months = ifelse(data[[4]][j] == 0, round(difftime(
>> data[[3]][j], rates.data[1,1])/days.in.month), 6) # this sets the month
>> increment so that cashflows can handle discount bills data$CASHFLOWS$DATE
>> <- append(data$CASHFLOW$DATE, seq(as.Date(rates.data[1,1]) %m+%
>> months(as.numeric(by.months)), as.Date(data[[3]][j]), by =
>> as.character(paste(by.months, "months", sep = " ")))) } #The Loop Ends
>> here and the list is made data$TODAY <- as.Date(rates.data[1,1]) TSInput
>> [[as.character(rates.data[1,1])]] <- c(data) #set term strucuture input
>> (TSInput) to class couponbonds class(TSInput) <- "couponbonds" #Fit the
>> term structure of interest rates if(method != "cs") {TSFit <- estim_nss(
>> dataset = TSInput, group = as.character(rates.data[1,1]), matrange = "all
>> ", method = method)} else {TSFit <- estim_cs(bonddata = TSInput, group =
>> as.character(rates.data[1,1]), matrange = "all", rse = TRUE)} #Return
>> the coefficient vector to be passed in to the spot and forward rate
>> functions #Maybe have the method choosen based on the one that gives the
>> smallest RMSE Vector <- switch(method, ns = unname(TSFit$opt_result[[1]]$
>> par[c("beta0", "beta1", "beta2", "tau1")]), dl = unname(TSFit$opt_result
>> [[1]]$par[c("beta0", "beta1", "beta2")]), sv = unname(TSFit$opt_result[[1
>> ]]$par[c("beta0", "beta1", "beta2", "tau1", "beta3", "tau2")]), asv =
>> unname(TSFit$opt_result[[1]]$par[c("beta0", "beta1", "beta2", "tau1", "
>> tau2", "tau3")]), #cs = need to figure this out ) #Calculate the spot
>> rate curve and determine the forward rates needed to period <- seq(from =
>> 1, to = 492, by = 1) #Use the date from the cashflow file date <-
>> seq(as.Date(rates.data[1,1]) %m+% months(1), as.Date(data[[3]][j]), by="1
>> months") spot.rate.curve <- spotrates(method = method, beta = Vector, m =
>> seq(from = 1/12, to = 492/12, by = 1/12)) forward.rate.curve <-
>> forwardrates(method = method, beta = Vector, m = seq(from = 1/12, to =
>> 492/12, by = 1/12)) Two.Year.Fwd <- (((1 + spot.rate.curve[seq(from = 25,
>> to = 385, by = 1)]) ^ (period[seq(from = 25, to = 385, by = 1)]/12) / (1
>> + spot.rate.curve[seq(from = 1, to = 361, by = 1)]) ^ (period[seq(from =
>> 1, to = 361, by = 1)]/12))^(1/2))-1 Ten.Year.Fwd <- (((1 +
>> spot.rate.curve[seq(from = 121, to = 481, by = 1)]) ^ (period[seq(from =
>> 121, to = 481, by = 1)]/12) / (1 + spot.rate.curve[seq(from = 1, to = 361,
>> by = 1)]) ^ (period[seq(from = 1, to = 361, by = 1)]/12))^(1/10))-1 new("
>> TermStructure", tradedate = as.character(rates.data[1,1]), period =
>> as.numeric(period), date = as.character(date), spotrate = spot.rate.curve
>> , forwardrate = forward.rate.curve, TwoYearFwd = Two.Year.Fwd, TenYearFwd
>> = Ten.Year.Fwd )}  setGeneric("TermStructure", function(rates.data = "
>> character", method = "character") {standardGeneric("TermStructure")})
>>
>> On May 11, 2015, at 01:54 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>> wrote:
>>
>> Dear Glenn,
>>
>> We need more details on the function. Please provide a commented,
>> minimal, self-contained version of the function that reproduces the problem
>> (as the posting guide asks you to do).
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-05-11 3:03 GMT+02:00 Glenn Schultz <glennmschultz at me.com>:
>>
>>> Hello All,
>>>
>>> Testing my code on a Windows based machine today.  There seems to be an
>>> offending line of code.  I have pasted it below.  Basically, I check to see
>>> if the user passed a fit method to TermStructure and if not then default to
>>> "ns".
>>>
>>> The above works fine on my Mac but a windows build errors no method.  I
>>> have to pass a method = "ns" in the function.  If I pass the value for
>>> method to the function it will run with no error.  Any thoughts are
>>> appreciated.
>>>
>>> Best Regards,
>>> Glenn
>>>
>>>   #Default method for TermStructure
>>>   if(missing(method)) method = "ns"
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From shivibhatia at ymail.com  Wed May 13 11:33:20 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Wed, 13 May 2015 02:33:20 -0700 (PDT)
Subject: [R] Residual Plots
Message-ID: <1431509600853-4707138.post@n4.nabble.com>

HI All,
I Am creating a residual plot for my linear model. 
the code I created is : plot(eval$bty_avg,residuals,ylab="residuals",
xlab="Score", main = "Residual Analysis")Here data set is eval. eval$bty_avg
is my  response variable and residual is the var I have created using resid
function to store the residuals. 
syntax used is : residuals<- resid(m_bty)

However when I run the syntax I receive the following error message:-
Error in eval$bty_avg : object of type 'closure' is not subsettable

Please suggest. 



--
View this message in context: http://r.789695.n4.nabble.com/Residual-Plots-tp4707138.html
Sent from the R help mailing list archive at Nabble.com.


From djmuser at gmail.com  Wed May 13 12:08:29 2015
From: djmuser at gmail.com (Dennis Murphy)
Date: Wed, 13 May 2015 03:08:29 -0700
Subject: [R] geom_text in ggplot (position)
In-Reply-To: <20150512185048.Horde.nzIY56yNPzxwjRyuAd3FmQ1@webmail.um.es>
References: <20150512185048.Horde.nzIY56yNPzxwjRyuAd3FmQ1@webmail.um.es>
Message-ID: <CADv2QyFG5YVWZA3=nvYT2asZ0Wz2sd-OUYnV2QKOY=RAtrK0kg@mail.gmail.com>

This problem is discussed in Winston Chang's R Graphics Handbook,
section 3.9. Adapting his code to this example:

test  <- data.frame(variables =  c("PE_35", "PE_49"),
                    value1=c(13,3),
                    value2=c(75,31),
                    value3=c(7,17),
                    value4 =c(5,49))

library(reshape2)
library(ggplot2)
library(plyr)

m <- melt(test, "variables")
m$cO <- gl(2, 2, length = nrow(m), labels = c("A", "B"))
m$cat <- gl(2, 4, labels = c(0, 1))


names(m)[3] <- "recuento"

mm <- ddply(m, .(variables, cat), mutate,
                   pos = cumsum(recuento) - 0.5 * recuento)   ## this
is the key part

ggplot(mm, aes(x = cat, y = recuento, fill = cO)) +
    geom_bar(stat = "identity") +
    geom_text(aes(y = pos, label = recuento)) +
    facet_wrap(~ variables)

Dennis

On Tue, May 12, 2015 at 9:50 AM, AURORA GONZALEZ VIDAL
<aurora.gonzalez2 at um.es> wrote:
> Hello everybody.
>
> I have an "esthetic" question. I have managed to create a stacked and
> grouped bar plot but I don't manage with putting the text in the middle of
> the bar plots. Do you know how to write the numbers in that position?
>
> Thank you so much.
>
> Example code:
>
> test  <- data.frame(variables =  c("PE_35", "PE_49"),
>                     value1=c(13,3),
>                     value2=c(75,31),
>                     value3=c(7,17),
>                     value4 =c(5,49))
>
> library(reshape2) # for melt
>
> melted <- melt(test, "variables")
> melted$cO <- c("A","A","B","B","A","A","B","B")
>
> melted$cat <- ''
> melted[melted$variable == 'value1' | melted$variable == 'value2',]$cat <-
> "0"
> melted[melted$variable == 'value3' | melted$variable == 'value4',]$cat <-
> "1"
>
> names(melted)[3] <- "recuento"
>
> library(ggplot2)
>
> ggplot(melted, aes(x = cat, y = recuento,ymax=max(recuento)*1.05, fill =
> cO)) +
>   geom_bar(stat = 'identity', position = 'stack', col="black") +
> facet_grid(~ variables)+
>   geom_text(aes(label = recuento), size = 5, hjust = 0.5, vjust = 1,
> position ="stack")
>
>
> ------
> Aurora Gonz?lez Vidal
>
> Secci?n Apoyo Estad?stico.
> Servicio de Apoyo a la Investigaci?n (SAI).
> Vicerrectorado de Investigaci?n.
> Universidad de Murcia
> Edif. SACE . Campus de Espinardo.
> 30100 Murcia
>
> @. aurora.gonzalez2 at um.es
> T. 868 88 7315
> F. 868 88 7302
> www.um.es/sai
> www.um.es/ae
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed May 13 14:03:46 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 13 May 2015 22:03:46 +1000
Subject: [R] Residual Plots
In-Reply-To: <1431509600853-4707138.post@n4.nabble.com>
References: <1431509600853-4707138.post@n4.nabble.com>
Message-ID: <CA+8X3fX8BgeuGYWV67kYGs1UiFJ33HNSEEyGC=ep1giD_GqP=A@mail.gmail.com>

Hi Shivi82,
The error message suggests that "eval$bty_avg" is a function. What does:

str(eval)

say about its components?

Jim


On Wed, May 13, 2015 at 7:33 PM, Shivi82 <shivibhatia at ymail.com> wrote:
> HI All,
> I Am creating a residual plot for my linear model.
> the code I created is : plot(eval$bty_avg,residuals,ylab="residuals",
> xlab="Score", main = "Residual Analysis")Here data set is eval. eval$bty_avg
> is my  response variable and residual is the var I have created using resid
> function to store the residuals.
> syntax used is : residuals<- resid(m_bty)
>
> However when I run the syntax I receive the following error message:-
> Error in eval$bty_avg : object of type 'closure' is not subsettable
>
> Please suggest.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Residual-Plots-tp4707138.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed May 13 14:08:30 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 13 May 2015 22:08:30 +1000
Subject: [R] Mean rain per rain day
In-Reply-To: <CAGh51gSOe3JnR_xBRxKOjNABNfzVy-Cjdway_MmZ9oFxJHgeXg@mail.gmail.com>
References: <CAGh51gSOe3JnR_xBRxKOjNABNfzVy-Cjdway_MmZ9oFxJHgeXg@mail.gmail.com>
Message-ID: <CA+8X3fUEFhai07q_wvD+ckZuxAJF_D_z6d0_iqwFi7NNGsf1qw@mail.gmail.com>

Hi Frederic,
It looks like you have a number of daily rainfall values and you want
to get the mean rainfall on days where there was some rain. What you
probably want is:

daily_rainfall<-rpois(50,2)
mean(daily_rainfall[daily_rainfall>0])

You may have to add na.rm=TRUE if there are NAs in your data.

Jim


On Wed, May 13, 2015 at 4:38 PM, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
> Hi All,
>
> I want to compute Mean rain per rain day from rainfall data but i don't
> know how to go about that. Anyone who understand the approach I can use can
> help me. In addition, I would like to have RScript which can help me to
> compute it. thanks.
>
> Regards,
> Frederic.
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed May 13 14:14:24 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 13 May 2015 22:14:24 +1000
Subject: [R] ifelse and "&&" vs "&
In-Reply-To: <SNT407-EAS93FB58DF717BA3119F84AFB9DA0@phx.gbl>
References: <SNT407-EAS93FB58DF717BA3119F84AFB9DA0@phx.gbl>
Message-ID: <CA+8X3fULKpgJQ6MOCdv7QWgOFi2Q=EBTtv42XoOsD6Djqd5CZw@mail.gmail.com>

Hi nusrat,
The ifelse function returns the number of values that result from the
logical expression in the first argument. If you use &&, you get one
logical value. If you use & you get logical values for the number of
conditionals that you specify. For example:

 1:10 > 0 && 1:10 < 11:20
[1] TRUE
 1:10 > 0 & 1:10 < 11:20
 [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE

And for your sake and our's, get a real computer.

Jim



On Wed, May 13, 2015 at 2:41 AM, nusrat ullah <nusratthebest at hotmail.com> wrote:
> Ip,  g ftehgytreehjjjijiputv
>
> Sent from my iPadgypyrrytutytytfedewaqy?iijj
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From therneau at mayo.edu  Wed May 13 15:00:52 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 13 May 2015 08:00:52 -0500
Subject: [R] Help with pedigree() function in kinship2
In-Reply-To: <mailman.7.1431511202.5843.r-help@r-project.org>
References: <mailman.7.1431511202.5843.r-help@r-project.org>
Message-ID: <2f3a88$kmgge@ironport10.mayo.edu>

Your problem is that PatientID, FatherID, MotherID are factors.  The authors of kinship2 
(myself and Jason) simply never thought of someone doing this.  Yes, that is an oversight. 
  We will correct it by adding some more checks and balances.  For now, turn your id 
variables into character or numeric.

Terry Therneau


On 05/13/2015 05:00 AM, r-help-request at r-project.org wrote:
> Dear R-help,
>
> I am interested in plotting some pedigrees and came across the kinship2
> package. What follows is an example of the pedigrees I am working with
> Now, when running
>
> ## check package availability
> if(!require(kinship2)) install.packages('kinship2')
> require(kinship2)
>
>
> ## data to plot
> d <- structure(list(FamilyID = c("1", "1", "1", "1", "1", "1", "1",
> "1", "1"), PatientID = structure(c(2L, 3L, 5L, 11L, 12L, 15L,
> 16L, 17L, 6L), .Label = c(" 1", " 2", " 3", " 4", " 5", " 6",
> " 7", " 9", "10", "11", "13", "14", "18", "20", "23", "24", "25",
> "27", "28", "29", "30", "31", "33", "34", "35", "37", "38", "39",
> "41", "43", "45", "50", "62", "63", "64", "65", "66", "67", "85",
> "88"), class = "factor"), FatherID = structure(c(1L, 1L, 6L,
> 1L, 5L, 6L, 1L, 7L, 6L), .Label = c("0", "1", "10", "11", "13",
> "2", "23", "27", "28", "3", "33", "34", "35", "38", "5", "62",
> "64", "66", "9"), class = "factor"), MotherID = structure(c(1L,
> 1L, 7L, 1L, 14L, 7L, 1L, 5L, 7L), .Label = c("0", "10", "18",
> "2", "24", "29", "3", "30", "33", "34", "39", "4", "43", "5",
> "6", "63", "65", "9"), class = "factor"), Sex = structure(c(2L,
> 1L, 1L, 2L, 2L, 2L, 1L, 2L, 2L), .Label = c("Female", "Male"), class =
> "factor"),
>      AffectionStatus = structure(c(1L, 1L, 2L, 1L, 2L, 2L, 1L,
>      2L, 2L), .Label = c("1", "2"), class = "factor")), .Names =
> c("FamilyID",
> "PatientID", "FatherID", "MotherID", "Sex", "AffectionStatus"
> ), row.names = c(NA, 9L), class = "data.frame")
>
> ## plotting
> ped <- with(d, pedigree(PatientID, FatherID, MotherID, Sex,  affected =
> AffectionStatus, famid = FamilyID))
>
> ## Error in pedigree(PatientID, FatherID, MotherID, Sex, affected =
> AffectionStatus,  :
> ##                    Value of 'dadid' not found in the id list 1/0 1/0 1/2
> 1/0 1/2
>
> I get an error.  My sessionInfo() is at the end.  I was wondering if
> someone could help me to dissect what the cause of this error is and how it
> can be fixed.
>
> Thank you very much for your help.
>
> Best regards,
> Jorge Velez.-


From lorenzolucchi at student.eur.nl  Wed May 13 11:03:07 2015
From: lorenzolucchi at student.eur.nl (Lorenzo Lucchi)
Date: Wed, 13 May 2015 09:03:07 +0000
Subject: [R] lmList Error in !unlist(lapply(coefs, is.null))
Message-ID: <1431507782409.50139@student.eur.nl>

I have a dataframe with the following structure:

 'data.frame':  13095 obs. of  1433 variables:

 $ my   : Factor w/ 624 levels "19631","19632",..: 1 1 1 1 1 1 1 1 1 1 ...

 $ s1   : num  NA NA NA NA NA NA NA NA NA NA ...



Where my is a factor with the number of the month, s1,..,,s1426 vectors that contain my dependent variable, f1,..,f6 vectors that contain my indepent variables.

S1 is a vector with many NA observations.

I want to regress s1 on f1,...,f6. To make the regression, I used the following code:


 try1 <- lmList(s1 ~ f1+f2+f3+f4+f5+f6 |my , data=d1)

 try1

And I received the following output:
Call: lmList(formula = s1 ~ f1 + f2 + f3 + f4 + f5 + f6 | my, data = d1)
Coefficients:
Error in !unlist(lapply(coefs, is.null)) : invalid argument type

I tried to change na.action to na.omit but I have the same output.

I tried to create a new dataframe with:
d2<-data.frame(d1$my,d1$s1,d1$f1,d1$f2,d1$f3,d1$f4,d1$f5,d1$f6)
colnames(d2)<-c("my", "s1", "f1", "f2", "f3", "f4", "f5", "f6")
d2 has the following structure:

'data.frame':  13095 obs. of  8 variables:

 $ my: Factor w/ 624 levels "19631","19632",..: 1 1 1 1 1 1 1 1 1 1 ...

 $ s1: num  NA NA NA NA NA NA NA NA NA NA ...

 $ f1: num  -0.54 1.66 0.68 0.06 0.9 -0.16 0.19 0.25 0.57 -0.1 ...

 $ f2: num  0.94 0.98 0.63 0.32 -0.03 0.11 0.2 -0.03 0.07 0.01 ...

 $ f3: num  0.31 -0.25 0.02 0.29 0.22 0.07 -0.09 -0.17 0.21 0.28 ...

 $ f4: num  1.5 1.7 1.14 -0.02 0.36 0.49 -0.13 0.18 0.14 0.47 ...

 $ f5: num  -0.5 -1.96 -0.66 -0.17 -0.43 0.24 -0.12 -0.01 -0.58 0.52 ...

 $ f6: num  0.38 0.3 0.35 0.3 0.08 0.13 -0.18 -0.05 -0.08 0.03 ...

When I run the regression:

try2<-lmList(s1~f1+f2+f3+f4+f5+f6|my,data=d2)

try2,



It works without any problem.

How can I solve the problem? I need to run a regression for every s, so I can't just create a new dataframe every time. I read the documentation of lmList and also this site but I didn't find anything related at the size of the dataframe, so I don't think that the problem depends from the size of d1, but for all the other things the two dataframe are equivalent.
I also tried to create an example but when I build a new dataframe, also with many NA like my file, I don't have these problems (i.e. lmList works fine).





	[[alternative HTML version deleted]]


From nickdoban at gmail.com  Wed May 13 11:27:34 2015
From: nickdoban at gmail.com (Nicolae Doban)
Date: Wed, 13 May 2015 11:27:34 +0200
Subject: [R] rminer package
Message-ID: <CADPWiKhdOcs9r+fPuJf6RnpKEPjoWjUSG7dcrFD=t12VPsWXXg@mail.gmail.com>

Hello,

I googled and looked on r-bloggers website for how to plot several REC
curves (rminer package) on the same plotting area but couldn't find
anything useful. I want to compare several regression (not logic regression
and not classification) predictive models analyzing the REC curves and the
error rates.

Could you please tell me how it can be done?

Thank you,
Nick

	[[alternative HTML version deleted]]


From venkynov10 at gmail.com  Wed May 13 11:58:20 2015
From: venkynov10 at gmail.com (venkadesan venky)
Date: Wed, 13 May 2015 15:28:20 +0530
Subject: [R] Count
Message-ID: <CAAM-fZ4JVjCH_YkVh=h+ZNueitoj_iwniESSfEJMu=0Ke0vaEg@mail.gmail.com>

Hello Team,

I have data like this

have Small doubts on the following calculation


For example,

Employee size    Camp 1    camp 2     Camp 3

1                            1               0               0

2                            0               0               1

3                            1                1              0

1                            0                0              1

2                             1                0             0

for employee size columns values are repeated and its not uniqe id so i
want to find that how many zero's are there in 1st  id and 2nd id?

for example for employee size(1st row) 1=0+0

                                                 (4th row) 1=0+0

here totally 4 zero,s i want results like this

	[[alternative HTML version deleted]]


From iresearchmobile at gmail.com  Wed May 13 10:51:18 2015
From: iresearchmobile at gmail.com (Android Developer)
Date: Wed, 13 May 2015 13:51:18 +0500
Subject: [R] Help regarding multi-page web application
Message-ID: <CANZttBoa2iYjFTCYnPeJzfbBgNymhA91BASAfL94J0pjamndZg@mail.gmail.com>

Hello,

I am using shiny package to develop web application but got stuck while
creating multi-page web application. I googled my problem but did not get
proper help. I just found R is not supporting multi-page web application
but it was to old question.

*Is R supports multi-page web application development?*
*If yes please guide me how and which package to use?*

Looking forward to hear from you soon.

Thank you.

Regards,

*Rehman Zafar (R programmer)*

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed May 13 16:27:38 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 13 May 2015 10:27:38 -0400
Subject: [R] Count
In-Reply-To: <CAAM-fZ4JVjCH_YkVh=h+ZNueitoj_iwniESSfEJMu=0Ke0vaEg@mail.gmail.com>
References: <CAAM-fZ4JVjCH_YkVh=h+ZNueitoj_iwniESSfEJMu=0Ke0vaEg@mail.gmail.com>
Message-ID: <CAM_vjumHKp5Xu1B_LCUPyewPQ7m3cNjg+KmODox_KmTDWKpCQg@mail.gmail.com>

Hi,

On Wed, May 13, 2015 at 5:58 AM, venkadesan venky <venkynov10 at gmail.com> wrote:
> Hello Team,
>
> I have data like this
>
> have Small doubts on the following calculation
>
>
> For example,
>
> Employee size    Camp 1    camp 2     Camp 3
>
> 1                            1               0               0
>
> 2                            0               0               1
>
> 3                            1                1              0
>
> 1                            0                0              1
>
> 2                             1                0             0

Using dput() is easier for everyone else than just pasting your data in.


> for employee size columns values are repeated and its not uniqe id so i
> want to find that how many zero's are there in 1st  id and 2nd id?
>
> for example for employee size(1st row) 1=0+0
>
>                                                  (4th row) 1=0+0
>
> here totally 4 zero,s i want results like this

I'm not at all sure I understand what you're asking, but what about:

testdata <- data.frame(EmpSize = c(1,2,3,1,2), Camp1 = c(1,0,1,0,1),
Camp2 = c(0,0,1,0,0), Camp3 = c(0,1,0,1,0))

aggregate(rowSums(testdata[, -1] == 0), list(testdata$EmpSize), FUN="sum")

-- 
Sarah Goslee
http://www.functionaldiversity.org


From thierry.onkelinx at inbo.be  Wed May 13 17:49:29 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 13 May 2015 17:49:29 +0200
Subject: [R] Code works on Mac but not Windows
In-Reply-To: <f832b807-4b42-495d-bdff-3d9d04fa7b42@me.com>
References: <CAJuCY5y3ky5X=XtrymT5Fg1QNSW5BXeed5761=kr=_RRKtNSvw@mail.gmail.com>
	<f832b807-4b42-495d-bdff-3d9d04fa7b42@me.com>
Message-ID: <CAJuCY5yZsfZ70GLpmdXcgD+Fr5u5RUr9KitdEafzFxxXRxvZ+A@mail.gmail.com>

Yes

> bar <- function(y = "12345"){
+   message(y)
+ }
> foo <- function(x = "a", y = "b"){
+   bar(y = y)
+ }
> bar()
12345
> bar(y = "abc")
abc
> foo()
b
> foo(y = "xyz")
xyz


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-13 17:43 GMT+02:00 Glenn Schultz <glennmschultz at me.com>:

> Hi Thierry,
>
> Last question I promise.  This function is often embedded in other
> functions which call various analytic functions for mortgage backed
> securities like total return etc.  If I understand you correctly the
> default is set in the TermStructure function. This is the first software
> package I have built so sometimes my understanding is incomplete due to a
> lack of experience.  If I provide "ns" default in the function and the user
> chooses an alternative such as "cs" will that flow to method?
>
> for example:
> PassThroughAnalytic(bond.id = foo, tradedate= foo, method = cs, price){
> bond.id <- MBS(bond.id = bond.id)
> rates.data <- rate(trade.date = foo)
> TermStrucuture <- TermStructure(rate.data = rates.data, method = method)
> *#if I understand correctly the method = "cs" will override the default
> value "ns" in TermStructure *
> MtgCashFlow <- MortgageCashFlow(bond.id = bond.id, tradedate = tradedate,
> price = price)
> KeyRate <- MtgKeyRate(trade.date = trade.date, MtgCashFlow = MtgCashFlow}
>
> Thanks,
> Glenn
>
>
>
> On May 13, 2015, at 02:53 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> Dear Glenn,
>
> Please keep the mailing list in cc.
>
> In this case I would drop the "signature" like values and use correct
> defaults.
>
> TermStructure <- function(rates.data, method = "ns")
>
> you can drop if(missing(method)) method = "ns" in that case.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-05-12 13:43 GMT+02:00 Glenn Schultz <glennmschultz at me.com>:
>
>> Hi Thierry,
>> Thanks,  I see what you are saying.  I should alter the code to test for
>> values, correct?
>>
>> Glenn
>>
>> Sent from my iPhone
>>
>> On May 12, 2015, at 2:40 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>> wrote:
>>
>> Dear Glenn,
>>
>> I think that you are confusing the signature of a method and the default
>> values of of function. It looks like you want the signature(rates.data =
>> "character", method = "character"). But you are setting "character" as
>> default value of both function arguments. Since you define a default value
>> for methods, it will not be missing when you omit is from the call.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-05-11 17:36 GMT+02:00 Glenn Schultz <glennmschultz at me.com>:
>>
>>> Hi Thierry,
>>>
>>> Below is the function
>>>  setMethod("initialize", signature("TermStructure"), function(.Object,
>>> ..., tradedate = "character", period = "numeric", date = "character",
>>> spotrate = "numeric", forwardrate = "numeric", TwoYearFwd = "numeric",
>>> TenYearFwd = "numeric") { .Object at tradedate = tradedate .Object at period =
>>> period .Object at date = date .Object at spotrate = spotrate .Object@
>>> forwardrate = forwardrate .Object at TwoYearFwd = TwoYearFwd .Object@
>>> TenYearFwd = TenYearFwd   return(.Object) callNextMethod(.Object,...) })
>>>  #' The TermStructure constructor function it is a wrapper function
>>> around the package termstrc #'  #' This is a wrapper function around
>>> the R package termstrc. The function passes swap rate data #' cash
>>> flows the to termstrc and creates the TermStructure object used by Bondlab.
>>>  #' The function call rates data processes the yield curve and derives
>>> cashflow #' for the daily close swap curve. A Rates object must be
>>> called in the local #' environment for this function to work. #' @param
>>> rates.data A character string representing the data for which the user #'
>>> would like to call the swap curve #' @param method A character string
>>> indicating the fitting method ns = Nelson Siegel, dl = Diebold Lee, #'
>>> sv = Severson, asv = adjusted Severson, cs = cubic spline (not yet
>>> implemented in Bond Lab). #' For addiition details see the termstrc
>>> documentation. #' @examples #' \dontrun{ #' TermStructure(rates.data =
>>> "01-10-2013", method = "ns")} #' @importFrom lubridate %m+% #'
>>> @importFrom lubridate years #' @importFrom lubridate day #' @importFrom
>>> lubridate month #' @importFrom termstrc estim_nss estim_cs spotrates
>>> forwardrates #'@export TermStructure TermStructure <- function(
>>> rates.data = "character", method = "character"){   #function(trade.date
>>> = "character", method = "character")  #Error Trap User inputs to the
>>> function if(missing(rates.data)) stop("missing rates data object") #
>>> this is the code snippet that works in MAC but not windows *#Default to
>>> Nelson-Siegel* * if(missing(method)) method = "ns"*   #Default to
>>> parametric if(method == "cs") stop("cubic spline not implemented")   #Check
>>> that the user input a valid method CheckMethod <- c("ns", "dl", "sv", "
>>> asv", "cs") if(!method %in% CheckMethod) stop ("Invalid 'method' Value")
>>>    # pass the yield curve to the function rates.data <- rates.data   #set
>>> the column counter to make cashflows for termstrucutre ColCount <-
>>> as.numeric(ncol(rates.data)) Mat.Years <- as.numeric(rates.data[2,2:
>>> ColCount]) Coupon.Rate <- as.numeric(rates.data[1,2:ColCount])
>>> Issue.Date <- as.Date(rates.data[1,1])   #initialize coupon bonds S3
>>> class #This can be upgraded when bondlab has portfolio function ISIN <-
>>> vector() MATURITYDATE <- vector() ISSUEDATE <- vector() COUPONRATE <-
>>> vector() PRICE <- vector() ACCRUED <- vector() CFISIN <- vector() CF <-
>>> vector() DATE <- vector() CASHFLOWS <- list(CFISIN,CF,DATE) names(
>>> CASHFLOWS) <- c("ISIN","CF","DATE") TODAY <- vector() data <- list()
>>> TSInput <- list()   ### Assign Values to List Items ######### data =
>>> NULL data$ISIN <- colnames(rates.data[2:ColCount]) data$ISSUEDATE <-
>>> rep(as.Date(rates.data[1,1]),ColCount - 1)   data$MATURITYDATE <-
>>> sapply(Mat.Years, function(Mat.Years = Mat.Years, Issue = Issue.Date) {
>>> Maturity = if(Mat.Years < 1) {Issue %m+% months(round(Mat.Years *
>>> months.in.year))} else {Issue %m+% years(as.numeric(Mat.Years))} return
>>> (as.character(Maturity)) })   data$COUPONRATE <- ifelse(Mat.Years < 1, 0,
>>> Coupon.Rate)   data$PRICE <- ifelse(Mat.Years < 1, (1 + (Coupon.Rate/100
>>> ))^(Mat.Years * -1) * 100, 100)   data$ACCRUED <- rep(0, ColCount -1)
>>> for(j in 1:(ColCount-1)){ Vector.Length <- as.numeric(round(difftime(
>>> data[[3]][j], data[[2]][j], units = c("weeks"))/weeks.in.year,0))
>>> Vector.Length <- ifelse(Vector.Length < 1, 1, Vector.Length *
>>> pmt.frequency) #pmt.frequency should be input    data$CASHFLOWS$ISIN <-
>>> append(data$CASHFLOWS$ISIN, rep(data[[1]][j],Vector.Length))   data$
>>> CASHFLOWS$CF <- append(data$CASHFLOWS$CF, as.numeric(c(rep((data[[4]][j]
>>> /100/pmt.frequency), Vector.Length-1) * min.principal, (min.principal +
>>> (data$COUPONRATE[j]/100/pmt.frequency)* min.principal))))   by.months =
>>> ifelse(data[[4]][j] == 0, round(difftime(data[[3]][j], rates.data[1,1])/
>>> days.in.month), 6) # this sets the month increment so that cashflows
>>> can handle discount bills   data$CASHFLOWS$DATE <- append(data$CASHFLOW$
>>> DATE, seq(as.Date(rates.data[1,1]) %m+% months(as.numeric(by.months)),
>>> as.Date(data[[3]][j]), by = as.character(paste(by.months, "months", sep
>>> = " "))))   } #The Loop Ends here and the list is made   data$TODAY <-
>>> as.Date(rates.data[1,1]) TSInput[[as.character(rates.data[1,1])]] <- c(
>>> data)   #set term strucuture input (TSInput) to class couponbonds class(
>>> TSInput) <- "couponbonds"   #Fit the term structure of interest rates
>>> if(method != "cs") {TSFit <- estim_nss(dataset = TSInput, group =
>>> as.character(rates.data[1,1]), matrange = "all", method = method)} else
>>> {TSFit <- estim_cs(bonddata = TSInput, group = as.character(rates.data[1
>>> ,1]), matrange = "all", rse = TRUE)}   #Return the coefficient vector
>>> to be passed in to the spot and forward rate functions #Maybe have the
>>> method choosen based on the one that gives the smallest RMSE Vector <-
>>> switch(method, ns = unname(TSFit$opt_result[[1]]$par[c("beta0", "beta1",
>>> "beta2", "tau1")]), dl = unname(TSFit$opt_result[[1]]$par[c("beta0", "
>>> beta1", "beta2")]), sv = unname(TSFit$opt_result[[1]]$par[c("beta0", "
>>> beta1", "beta2", "tau1", "beta3", "tau2")]), asv = unname(TSFit$
>>> opt_result[[1]]$par[c("beta0", "beta1", "beta2", "tau1", "tau2", "tau3"
>>> )]), #cs = need to figure this out )   #Calculate the spot rate curve
>>> and determine the forward rates needed to  period <- seq(from = 1, to =
>>> 492, by = 1) #Use the date from the cashflow file date <- seq(as.Date(
>>> rates.data[1,1]) %m+% months(1), as.Date(data[[3]][j]), by="1 months")
>>>  spot.rate.curve <- spotrates(method = method, beta = Vector, m = seq(
>>> from = 1/12, to = 492/12, by = 1/12))   forward.rate.curve <-
>>> forwardrates(method = method, beta = Vector, m = seq(from = 1/12, to =
>>> 492/12, by = 1/12))   Two.Year.Fwd <- (((1 + spot.rate.curve[seq(from =
>>> 25, to = 385, by = 1)]) ^ (period[seq(from = 25, to = 385, by = 1)]/12)
>>> / (1 + spot.rate.curve[seq(from = 1, to = 361, by = 1)]) ^ (period[seq(
>>> from = 1, to = 361, by = 1)]/12))^(1/2))-1   Ten.Year.Fwd <- (((1 +
>>> spot.rate.curve[seq(from = 121, to = 481, by = 1)]) ^ (period[seq(from =
>>> 121, to = 481, by = 1)]/12) / (1 + spot.rate.curve[seq(from = 1, to =
>>> 361, by = 1)]) ^ (period[seq(from = 1, to = 361, by = 1)]/12))^(1/10))-1
>>>    new("TermStructure", tradedate = as.character(rates.data[1,1]),
>>> period = as.numeric(period), date = as.character(date), spotrate =
>>> spot.rate.curve, forwardrate = forward.rate.curve, TwoYearFwd =
>>> Two.Year.Fwd, TenYearFwd = Ten.Year.Fwd ) }     setGeneric("
>>> TermStructure", function(rates.data = "character", method = "character")
>>>  {standardGeneric("TermStructure")})
>>>
>>> On May 11, 2015, at 01:54 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>>> wrote:
>>>
>>> Dear Glenn,
>>>
>>> We need more details on the function. Please provide a commented,
>>> minimal, self-contained version of the function that reproduces the problem
>>> (as the posting guide asks you to do).
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> 2015-05-11 3:03 GMT+02:00 Glenn Schultz <glennmschultz at me.com>:
>>>
>>>> Hello All,
>>>>
>>>> Testing my code on a Windows based machine today.  There seems to be an
>>>> offending line of code.  I have pasted it below.  Basically, I check to see
>>>> if the user passed a fit method to TermStructure and if not then default to
>>>> "ns".
>>>>
>>>> The above works fine on my Mac but a windows build errors no method.  I
>>>> have to pass a method = "ns" in the function.  If I pass the value for
>>>> method to the function it will run with no error.  Any thoughts are
>>>> appreciated.
>>>>
>>>> Best Regards,
>>>> Glenn
>>>>
>>>>   #Default method for TermStructure
>>>>   if(missing(method)) method = "ns"
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Wed May 13 22:27:27 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 13 May 2015 20:27:27 +0000
Subject: [R] Residual Plots
In-Reply-To: <1431509600853-4707138.post@n4.nabble.com>
References: <1431509600853-4707138.post@n4.nabble.com>
Message-ID: <D179005D.128C94%macqueen1@llnl.gov>

This example might help:

tmp <- data.frame(x=1:10, y=rnorm(10))
foo <- lm(y~x, data=tmp)
plot(tmp$x, residuals(foo))


It appears that eval$bty_avg is not what you think it is.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/13/15, 2:33 AM, "Shivi82" <shivibhatia at ymail.com> wrote:

>HI All,
>I Am creating a residual plot for my linear model.
>the code I created is : plot(eval$bty_avg,residuals,ylab="residuals",
>xlab="Score", main = "Residual Analysis")Here data set is eval.
>eval$bty_avg
>is my  response variable and residual is the var I have created using
>resid
>function to store the residuals.
>syntax used is : residuals<- resid(m_bty)
>
>However when I run the syntax I receive the following error message:-
>Error in eval$bty_avg : object of type 'closure' is not subsettable
>
>Please suggest. 
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Residual-Plots-tp4707138.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Wed May 13 22:35:25 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 13 May 2015 20:35:25 +0000
Subject: [R] Fw: Downloading R
In-Reply-To: <OF772A90EC.2DD355A6-ON85257E43.00091F0C-85257E43.00094300@pnc.com>
References: <OF772A90EC.2DD355A6-ON85257E43.00091F0C-85257E43.00094300@pnc.com>
Message-ID: <D1790275.128CA6%macqueen1@llnl.gov>

Hmmm. Follow the instructions at
   http://www.r-project.org/


After choosing a mirror, you will reach a page that says, in part:

---- partial quote ----
Source Code for all Platforms

Windows and Mac users most likely want to download the precompiled
binaries listed in the upper box, not the source code. The sources have to
be compiled before you can use them. If you do not know what this means,
you probably do not want to do it!

    The latest release (2015-04-16, Full of Ingredients) R-3.2.0.tar.gz,
read what's new in the latest version.
---- end partial quote ----




Then click the link labeled "R-3.2.0.tar.gz"

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/11/15, 6:41 PM, "e.robinson at pnc.com" <e.robinson at pnc.com> wrote:

>>         My name is Erick Robinson and I am a SAS administrator at PNC
>> Bank.  I have been tasked with installing R on two of our SAS servers,
>> but am having trouble downloading the source.  I have little background
>> in UNIX (our servers run On Solaris under Unix) and cannot get to the
>> site to download.  I clicked on the link in red and it took me to the
>> green arrow without any options to download.  I was going to download to
>> Windows and then FTP to the server.  What is the best way to download
>the source to our solaris server?  Thanks
>
>Erick Robinson
>Software Engineer Lead
>Retail MIS SAS Support
>
>PNC Technology and Operations
>23000 Mill Creek Blv.
>Hignland Hills, Oh  44122
>440-342-3100
>e.robinson at pnc.com
>
>
>
> 
>----- Forwarded by Erick Robinson/TPS/CLE/PNC on 05/11/2015 09:39 PM -----
>
>From:   Duncan Murdoch <murdoch.duncan at gmail.com>
>To:     e.robinson at pnc.com, R-windows at R-project.org,
>Date:   05/11/2015 02:52 PM
>Subject:        Re: Downloading R
>
>
>
>On 11/05/2015 2:37 PM, e.robinson at pnc.com wrote:
>> Hello,
>> 
>>         My name is Erick Robinson and I am a SAS administrator at PNC
>> Bank.  I have been tasked with installing R on two of our SAS servers,
>> but am having trouble downloading the source.  I have little background
>> in UNIX (our servers run On Solaris under Unix) and cannot get to the
>> site to download.  I clicked on the link in red and it took me to the
>> green arrow without any options to download.  I was going to download to
>> Windows and then FTP to the server
>
>It is much easier to install from a tarball, not from the Subversion
>repository.  But more importantly, you're writing to the wrong place.
>If my hint is not sufficient, please write to R-help, not to R-windows.
> This is the development list for the Windows version, not a general
>support list.
>
>Duncan Murdoch
>
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> Erick Robinson
>> Software Engineer Lead
>> Retail MIS SAS Support
>> 
>> *PNC Technology and Operations*
>> 23000 Mill Creek Blv.
>> Hignland Hills, Oh  44122
>> 440-342-3100
>> e.robinson at pnc.com
>> 
>> 
>> 
>> 
>> 
>> The contents of this email are the property of PNC. If it was not
>> addressed to you, you have no legal right to read it. If you think you
>> received it in error, please notify the sender. Do not forward or copy
>> without permission of the sender. This message may be considered a
>> commercial electronic message under Canadian law or this message may
>> contain an advertisement of a product or service and thus may constitute
>> a commercial electronic mail message under US law. You may unsubscribe
>> at any time from receiving commercial electronic messages from PNC at
>> http://pages.e.pnc.com/globalunsub/
>> PNC, 249 Fifth Avenue, Pittsburgh, PA 15222; pnc.com
>> 
>
>
>
>The contents of this email are the property of PNC. If it was not
>addressed to you, you have no legal right to read it. If you think you
>received it in error, please notify the sender. Do not forward or copy
>without permission of the sender. This message may be considered a
>commercial electronic message under Canadian law or this message may
>contain an advertisement of a product or service and thus may constitute
>a commercial electronic mail message under US law. You may unsubscribe at
>any time from receiving commercial electronic messages from PNC at
>http://pages.e.pnc.com/globalunsub/
>PNC, 249 Fifth Avenue, Pittsburgh, PA 15222; pnc.com
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From newrnewbie at hotmail.com  Wed May 13 23:01:40 2015
From: newrnewbie at hotmail.com (Vin Cheng)
Date: Wed, 13 May 2015 21:01:40 +0000
Subject: [R] binding two lists of lists of dataframes together
In-Reply-To: <F8CE47F9-1AEE-4514-9779-61DB3AF0F019@comcast.net>
References: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>,
	<A2E1A0300F5.00001107jrkrideau@inbox.com>
	<BAY179-W63A3DF10922679A302B16D3DA0@phx.gbl>,
	<17C25B6B-DDF7-4108-99C9-3DABC178C32F@comcast.net>
	<BAY179-W817CF1BB2EEC863DC596F5D3DA0@phx.gbl>,
	<1084ED86-44F2-4717-9879-4A8A368FE00A@comcast.net>
	<BAY179-W41355B8D24DBDB0BEF7978D3DA0@phx.gbl>,
	<F8CE47F9-1AEE-4514-9779-61DB3AF0F019@comcast.net>
Message-ID: <BAY179-W44BDA61F1D2A044E3AE646D3D90@phx.gbl>

Hi David,
 
I tried both solutions you provided(lapply(dlist, function(x) rbind(x,x) ) & Map( rbind, smaller, smaller))  and they seem to transpose and reshape the data into a different structure.  Whenever I added the str - I only get a NULL.
 
> You basically want a list of the same general structure as list1 where all the elements in list two at the same position and depth have been concatenated?
 
Yes - that sounds exactly right.
 
I've created new input(list1,list2) and desired output(list3) examples below.  I hope this makes the request a lot clearer.
 
Not sure if this helpful, but I found this bit of script and it keeps V1,V2,V3 separate and keeps each set of observations as vectors, but it doesn't concatenate the v1 observations with v2 observations together.
 
sample.list <- list(list1,list2)
library(data.table) 
nr <- nrow(sample.list[[1]])
fastbind.ith.rows <- function(i) rbindlist(lapply(sample.list, "[", i, TRUE))
fastbound <- lapply(1:nr, fastbind.ith.rows)
 
Link:
http://stackoverflow.com/questions/4863341/fast-vectorized-merge-of-list-of-data-frames-by-row
 
Thank you again!
Vince
 
Please find below the structure for list1, list2, and the desired output list3:
 
list1<-structure(list(
V1 = list(c(15L, 19L, 28L, 9L, 17L, 3L, 11L, 21L,7L, 8L, 11L, 13L), 
 c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 
 c(NaN,NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
 c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
 structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
"ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L), .Label = c("Issuer1", "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
"Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), 
class = "factor"), c(99.5, 95.5, 99.5, 100, 98.5, 99.646, 99.833, 98, 99.75, 100, 99.833, 98.563), c(0.4, 0.55, 0.4, 0.4, 0.5, 0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4)), 
V2 = list(c(10L, 29L, 5L, 19L, 28L, 3L, 10L, 12L, 1L, 21L, 23L, 25L), 
c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 
c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
"ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L), .Label = c("Issuer1", 
"Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", 
"Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor")
, c(98.5, 100.25, 99, 95.5, 99.5, 99.646, 98.5, 94.75, 98.75, 98, 99, 99.388), c(0.6, 0.4, 0.45, 0.55, 0.4, 0.45, 0.6, 0.55, 0.5, 0.45, 0.55, 0.4)), 
V3 = list(c(21L, 28L, 3L, 7L, 25L, 25L, 15L, 13L, 3L, 20L, 16L, 18L), 
c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 
c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
"ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L), .Label = c("Issuer1", 
"Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", 
"Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), 
c(98, 99.5, 99.646, 99.75, 99.388, 99.388, 99.5, 98.563, 99.646, 98, 99.563, 100.375), c(0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4, 0.4, 0.45, 0.3, 0.45, 0.5))), .Names = c("V1", 
"V2", "V3"), row.names = c("id", "WgtBand", "Wgt", "Held", "LoanXID", "Issuer", "Bid", "Offer"), class = c("data.table", "data.frame"))
list2<-structure(list(V1 = list(
c(15L, 8L, 2L, 21L, 8L, 2L, 23L, 25L, 20L, 4L), 
c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
structure(c(7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
"ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("Issuer1", 
"Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", 
"Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), c(99.5, 100, 96.969, 98, 100, 96.969, 99, 99.388, 98, 94), 
c(0.4, 0.4, 0.45, 0.45, 0.4, 0.45, 0.55, 0.4, 0.3, 0.45)), 
V2 = list(c(27L, 14L, 11L, 25L, 17L, 15L, 10L, 23L, 16L, 2L), 
c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
structure(c(20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
"ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("Issuer1", 
"Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", 
"Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), 
c(100.296, 88.5, 99.833, 99.388, 98.5, 99.5, 98.5, 99, 99.563, 96.969), c(0.4, 0.4, 0.4, 0.4, 0.5, 0.4, 0.6, 0.55, 0.45, 0.45)), 
V3 = list(c(13L, 26L, 5L, 17L, 5L, 28L, 2L, 16L, 1L, 19L), 
c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
structure(c(5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 11L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", 
"ID24", "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 
11L), .Label = c("Issuer1", "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
"Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"
), class = "factor"), c(98.563, 99.229, 99, 98.5, 99, 99.5, 96.969, 99.563, 98.75, 95.5), c(0.4, 0.55, 0.45, 0.5, 0.45, 0.4, 0.45, 0.45, 0.5, 0.55))), .Names = c("V1", 
"V2", "V3"), row.names = c("id", "WgtBand", "Wgt", "Held", "LoanXID", "Issuer", "Bid", "Offer"), class = c("data.table", "data.frame"))
list3<-structure(list(
V1 = list(c(15L, 19L, 28L, 9L, 17L, 3L, 11L, 21L,7L, 8L, 11L, 13L,15L, 8L, 2L, 21L, 8L, 2L, 23L, 25L, 20L, 4L), 
 c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
 c(NaN,NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
 c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
 structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L,7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
"ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L,7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("Issuer1", "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
"Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), 
class = "factor"), c(99.5, 95.5, 99.5, 100, 98.5, 99.646, 99.833, 98, 99.75, 100, 99.833, 98.563,99.5, 100, 96.969, 98, 100, 96.969, 99, 99.388, 98, 94), c(0.4, 0.55, 0.4, 0.4, 0.5, 0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4,0.4, 0.4, 0.45, 0.45, 0.4, 0.45, 0.55, 0.4, 0.3, 0.45)), 
V2 = list(c(10L, 29L, 5L, 19L, 28L, 3L, 10L, 12L, 1L, 21L, 23L, 25L,27L, 14L, 11L, 25L, 17L, 15L, 10L, 23L, 16L, 2L), 
c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L,20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
"ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L,20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("Issuer1", 
"Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", 
"Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor")
, c(98.5, 100.25, 99, 95.5, 99.5, 99.646, 98.5, 94.75, 98.75, 98, 99, 99.388,100.296, 88.5, 99.833, 99.388, 98.5, 99.5, 98.5, 99, 99.563, 96.969), c(0.6, 0.4, 0.45, 0.55, 0.4, 0.45, 0.6, 0.55, 0.5, 0.45, 0.55, 0.4,0.4, 0.4, 0.4, 0.4, 0.5, 0.4, 0.6, 0.55, 0.45, 0.45)), 
V3 = list(c(21L, 28L, 3L, 7L, 25L, 25L, 15L, 13L, 3L, 20L, 16L, 18L,13L, 26L, 5L, 17L, 5L, 28L, 2L, 16L, 1L, 19L), 
c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L,5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 11L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
"ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L,5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 11L), .Label = c("Issuer1", 
"Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", 
"Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), 
c(98, 99.5, 99.646, 99.75, 99.388, 99.388, 99.5, 98.563, 99.646, 98, 99.563, 100.375,98.563, 99.229, 99, 98.5, 99, 99.5, 96.969, 99.563, 98.75, 95.5), c(0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4, 0.4, 0.45, 0.3, 0.45, 0.5,0.4, 0.55, 0.45, 0.5, 0.45, 0.4, 0.45, 0.45, 0.5, 0.55))), .Names = c("V1", 
"V2", "V3"), row.names = c("id", "WgtBand", "Wgt", "Held", "LoanXID", "Issuer", "Bid", "Offer"), class = c("data.table", "data.frame"))
 
 
 
> Subject: Re: [R] binding two lists of lists of dataframes together
> From: dwinsemius at comcast.net
> Date: Tue, 12 May 2015 16:00:05 -0700
> CC: r-help at r-project.org
> To: newrnewbie at hotmail.com
> 
> 
> On May 12, 2015, at 3:12 PM, Vin Cheng wrote:
> 
> > Hi David,
> >  
> > Would it be possible to modify it a little so that I can keep V1, V2, and V3 intact?
> 
> 
> >  
> > I also don't quite know where to put list2 in the solution you provided below? list2 can be an exact copy of list1 for this example.
> 
> In which case it would be nearly trivial:
> 
> lapply(dlist, function(x) rbind(x,x) ) 
> 
> str( lapply(dlist, function(x) rbind(x,x) ) )
> List of 3
>  $ V1:'data.frame':	20 obs. of  48 variables:
>   ..$ V1 : int [1:20] 19 94 94 15 90 13 66 17 45 69 ...
>   ..$ V2 : num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
>   ..$ V3 : num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
>   ..$ V4 : num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> snipped.....
> 
> >  
> > list1 has (48 observations of 3 variables(V1, V2,V3)) each observation has 10 values in a vector 
> > list2 has (48 observations of 3 variables (V1, V2,V3)) each observation has 10 values in a vector 
> 
> You basically want a list of the same general structure as list1 where all the elements in list two at the same position and depth have been concatenated?
> >  
> > Output should ideally have (48 observations of 3 variables (V1, V2,V3)) each observation has 20 values in a vector
> >  list1 V1 stacks with list2 V1, 
> >  list1 V2 stacks with list2 V2, 
> >  list1 V3 stacks with list2 V3
> 
> You had a bunch of factor variables in list1. Are we assured that the levels of any factor variables in list2 are the same as the corresponding factor variables in list 1?
> 
> >  
> > Boundlist seems to break out the values of each variable(V1,V2,V3) into 10 columns with 1 value in each column.
> 
> Not the way I use those words after using R for the last 8 years. There were 48 "columns" and 10 positions in each. I think you need to reverse your terminology (columns and rows)  since a "column" in a dataframe is a list and the row numbers are the relative positions along vectors.
> 
> 
> >  Is it possible to put the values in the 10 columns(20 values in ideal output) into a vector for each of the 48 observation in each variable(V1,V2,V3).
> 
> Having severe trouble reformulating this in R dataframe terminology.
> 
> >  
> > Sorry for all the back and forth - explaining an exact output over email is difficult.
> 
> It shouldn't be difficult if you would post data examples with sufficient complexity to represent the problem. I will build a smaller list of dataframe and name it 'smaller'
> 
> Since I had difficulty with mapply I'm switching to the list version named ?Map found in the ?funprog page:
> 
> smaller <- lapply(dlist, "[", 1:6)
> 
> ?Map
>  str( Map( rbind, smaller, smaller))
> 
> #------I think this is what you might want----------
> List of 3
>  $ V1:'data.frame':	20 obs. of  6 variables:
>   ..$ V1: int [1:20] 19 94 94 15 90 13 66 17 45 69 ...
>   ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
>   ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
>   ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
>   ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 12 95 95 8 91 6 64 10 41 67 ...
>   ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 12 95 95 8 91 6 64 10 41 67 ...
>  $ V2:'data.frame':	20 obs. of  6 variables:
>   ..$ V1: int [1:20] 93 3 85 34 20 89 16 25 83 90 ...
>   ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
>   ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
>   ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
>   ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 94 24 85 29 14 89 9 19 83 91 ...
>   ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 94 24 85 29 14 89 9 19 83 91 ...
>  $ V3:'data.frame':	20 obs. of  6 variables:
>   ..$ V1: int [1:20] 47 95 26 64 16 55 61 39 23 66 ...
>   ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
>   ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
>   ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
>   ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 43 96 20 62 9 52 59 34 17 64 ...
>   ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 43 96 20 62 9 52 59 34 17 64 ...
> 
> >  
> > I really appreciate the help and the effort!  
> >  
> > Thank you again!
> > Vince
> >  
> > > Subject: Re: [R] binding two lists of lists of dataframes together
> > > From: dwinsemius at comcast.net
> > > Date: Tue, 12 May 2015 14:23:54 -0700
> > > CC: r-help at r-project.org
> > > To: newrnewbie at hotmail.com
> > > 
> > > 
> > > On May 12, 2015, at 12:56 PM, Vin Cheng wrote:
> > > 
> > > > Hi,
> > > > 
> > > > Thanks David! Your solution 3 worked well with the sample data, but when I run solution 2 & 3 on the actual data - it creates a list of 1 for each data point and it doesn't end up looking like the desired output for some reason.
> > > > 
> > > > I've run a dput on the actual data and pasted below. There's a lot of data - so I'm only copying list1 - if the solution could bind list1 with itself - it should work just as well. 
> > > > 
> > > > Sorry for not providing an accurate sample the first time around - I thought the shortened version would be simpler and sufficient.
> > > > 
> > > > Any help/guidance would be greatly appreciated!
> > > > 
> > > 
> > > This appears to be three similarly structured lists of various classes but fortunately for this effort the factor variables in corresponding columns all have the same levels. (Otherwise one would need to convert to character before attempting to stack them.)
> > > 
> > > I would just use `rbind.data.frame` (after making them dataframes with the same column names.)
> > > 
> > > 
> > > dlist <- lapply( list1, function(d) setNames( data.frame(d), paste0("V", 1:48) ))
> > > boundlist <- do.call(rbind, dlist)
> > > 
> > > # Done.
> > > 
> > > -- 
> > > David.
> > > > Many Thanks,
> > > > Vince
> > > > 
> > > > list1 <- structure(list(V1 = list(c(19L, 94L, 94L, 15L, 90L, 13L, 66L, 
> > > > 17L, 45L, 69L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, 
> > > > NA, NA, NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 
> > > > 0), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
> > > > ), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", "ID13", 
> > > > "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", 
> > > > "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", "ID27", "ID28", 
> > > > "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", "ID34", "ID35", 
> > > > "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", "ID41", "ID42", 
> > > > "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", 
> > > > "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
> > > > "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", "ID64", 
> > > > "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", "ID70", "ID71", 
> > > > "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", "ID78", "ID79", 
> > > > "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", "ID85", "ID86", 
> > > > "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", "ID92", "ID93", 
> > > > "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"), class = "factor"), 
> > > > structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
> > > > ), .Label = c("Issuer1", "Issuer10", "Issuer100", "Issuer11", 
> > > > "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
> > > > "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", 
> > > > "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", 
> > > > "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", 
> > > > "Issuer30", "Issuer31", "Issuer32", "Issuer33", "Issuer34", 
> > > > "Issuer35", "Issuer36", "Issuer37", "Issuer38", "Issuer39", 
> > > > "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
> > > > "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", 
> > > > "Issuer49", "Issuer5", "Issuer50", "Issuer51", "Issuer52", 
> > > > "Issuer53", "Issuer54", "Issuer55", "Issuer56", "Issuer57", 
> > > > "Issuer58", "Issuer59", "Issuer6", "Issuer60", "Issuer61", 
> > > > "Issuer62", "Issuer63", "Issuer64", "Issuer65", "Issuer66", 
> > > > "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
> > > > "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", 
> > > > "Issuer76", "Issuer77", "Issuer78", "Issuer79", "Issuer8", 
> > > > "Issuer80", "Issuer81", "Issuer82", "Issuer83", "Issuer84", 
> > > > "Issuer85", "Issuer86", "Issuer87", "Issuer88", "Issuer89", 
> > > > "Issuer9", "Issuer90", "Issuer91", "Issuer92", "Issuer93", 
> > > > "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
> > > > "Issuer99"), class = "factor"), c(95.5, 98.5, 98.5, 99.5, 
> > > > 103.5, 98.563, 99.75, 98.5, 98.75, 99.125), c(97.5, 99.5, 
> > > > 99.5, 100.375, 104.5, 99.188, 100.25, 99.5, 99.75, 100.063
> > > > ), c(2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 4L), c(4L, 5L, 5L, 
> > > > 5L, 5L, 2L, 3L, 5L, 3L, 2L), c(TRUE, FALSE, FALSE, TRUE, 
> > > > FALSE, TRUE, TRUE, FALSE, FALSE, TRUE), structure(c(1L, 1L, 
> > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > structure(c(9L, 2L, 2L, 1L, 2L, 1L, 3L, 3L, 5L, 9L), .Label = c("B", 
> > > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
> > > > ), class = "factor"), structure(c(8L, 2L, 2L, 1L, 8L, 2L, 
> > > > 2L, 2L, 1L, 7L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
> > > > "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(20L, 
> > > > 88L, 88L, 6L, 3L, 35L, 29L, 24L, 53L, 82L), .Label = c("1/11/2019", 
> > > > "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
> > > > "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
> > > > "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
> > > > "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
> > > > "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
> > > > "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
> > > > "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
> > > > "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
> > > > "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
> > > > "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
> > > > "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
> > > > "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
> > > > "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
> > > > "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
> > > > "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
> > > > "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
> > > > "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
> > > > "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
> > > > c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > > FALSE, FALSE), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 
> > > > 10L, 41L, 67L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > > "Issuer98", "Issuer99"), class = "factor"), structure(c(12L, 
> > > > 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L), .Label = c("BL1", 
> > > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
> > > > "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
> > > > "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
> > > > "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
> > > > "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
> > > > "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
> > > > "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
> > > > "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
> > > > "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
> > > > "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
> > > > "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(4L, 
> > > > 3L, 3L, 5L, 6L, 3L, 2L, 6L, 6L, 5L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > > "Retail", "Services: Business"), class = "factor"), structure(c(3L, 
> > > > 5L, 5L, 6L, 4L, 3L, 4L, 2L, 6L, 6L), .Label = c("Financial Intermediaries", 
> > > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 6L, 8L, 8L), .Label = c("AU", 
> > > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 5L, 6L, 6L), .Label = c("1", 
> > > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L), .Label = c("Canada", 
> > > > "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
> > > > 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > > structure(c(2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > > "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > > c(0.125550168, 1.731733265, 1.731733265, NA, 5.246485518, 
> > > > 7.798802147, NA, NA, NA, NA), c(4770L, 3490L, 3490L, 3490L, 
> > > > 3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.45, 0.4, 0.4, 
> > > > 0.45, 0.55, 0.4, 0.4, 0.45, 0.4, 0.5), c(4770L, 3490L, 3490L, 
> > > > 3490L, 3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.55, 
> > > > 0.4, 0.4, 0.4, 0.55, 0.4, 0.5, 0.5, 0.45, 0.55), c(18L, 15L, 
> > > > 15L, 15L, 18L, 15L, 15L, 15L, 14L, 17L), c(17L, 16L, 16L, 
> > > > 15L, 14L, 15L, 15L, 15L, 14L, 15L), c(192500000, 205000000, 
> > > > 205000000, 342000000, 120000000, 835000000, 1043700000, 160000000, 
> > > > 300000000, 265000000), c(0.02, 0.02, 0.02, 0.4, 0.02, 0.4, 
> > > > 0.6, 0.6, 0.6, 0.02), c(850L, 475L, 475L, 500L, 1000L, 350L, 
> > > > 400L, 975L, 500L, 700L), c(1, 1.5, 1.5, 1, 1.25, 1, 1, 1, 
> > > > 1, 1), c(0.0851, 0.04765, 0.04765, 0.0501, 0.100125, 0.0351, 
> > > > 0.0401, 0.0976, 0.0501, 0.0701), c(0.099192999, 0.023321348, 
> > > > 0.023321348, 0.06465519, 0.103470278, 0.052237196, 0.051331755, 
> > > > 0.112300026, 0.066116739, 0.084107871), c(897.0917677, -1.49365213, 
> > > > -1.49365213, 549.0886934, 975.9481504, 429.1863229, 436.2991366, 
> > > > 1062.374805, 567.0741295, 747.1023728), c(0.088186528, 0.048131313, 
> > > > 0.048131313, 0.050131332, 0.096274038, 0.035499188, 0.040049938, 
> > > > 0.098585859, 0.050478589, 0.070385766), c(0L, 0L, 0L, 0L, 
> > > > 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
> > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > > c(0.0178406708595388, 0.0136532951289398, 0.0136532951289398, 
> > > > 0.0143553008595989, 0.028689111747851, 0.0100573065902579, 
> > > > 0.0180630630630631, 0.043963963963964, 0.0225675675675676, 
> > > > 0.0200859598853868), c(0.046805, 0.01906, 0.01906, 0.02004, 
> > > > 0.05506875, 0.01404, 0.02005, 0.0488, 0.022545, 0.038555), 
> > > > c(0.001702, 0.000953, 0.000953, 0.02004, 0.0020025, 0.01404, 
> > > > 0.02406, 0.05856, 0.03006, 0.001402)), V2 = list(c(93L, 3L, 
> > > > 85L, 34L, 20L, 89L, 16L, 25L, 83L, 90L), c(1, 1, 2, 3, 4, 5, 
> > > > 6, 7, 8, 9), c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), c(0, 
> > > > 0, 0, 0, 0, 0, 0, 0, 0, 0), structure(c(94L, 24L, 85L, 29L, 14L, 
> > > > 89L, 9L, 19L, 83L, 91L), .Label = c("ID1", "ID10", "ID100", "ID11", 
> > > > "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
> > > > "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> > > > "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", 
> > > > "ID34", "ID35", "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", 
> > > > "ID41", "ID42", "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", 
> > > > "ID49", "ID5", "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", 
> > > > "ID56", "ID57", "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", 
> > > > "ID63", "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
> > > > "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", 
> > > > "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", 
> > > > "ID85", "ID86", "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", 
> > > > "ID92", "ID93", "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"
> > > > ), class = "factor"), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
> > > > 9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
> > > > "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> > > > "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
> > > > "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", "Issuer32", 
> > > > "Issuer33", "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
> > > > "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", "Issuer49", 
> > > > "Issuer5", "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
> > > > "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", "Issuer6", 
> > > > "Issuer60", "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
> > > > "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", "Issuer76", 
> > > > "Issuer77", "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
> > > > "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", "Issuer87", 
> > > > "Issuer88", "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
> > > > "Issuer99"), class = "factor"), c(99.5, 99.646, 100.402, 100.25, 
> > > > 98, 99.563, 99.563, 99.388, 99.531, 103.5), c(100.5, 100.271, 
> > > > 100.903, 100.75, 99, 100.188, 100.063, 99.788, 100.125, 104.5
> > > > ), c(1L, 6L, 9L, 1L, 1L, 2L, 2L, 10L, 4L, 2L), c(5L, 2L, 1L, 
> > > > 3L, 3L, 4L, 4L, 1L, 1L, 5L), c(TRUE, TRUE, FALSE, FALSE, TRUE, 
> > > > FALSE, FALSE, TRUE, TRUE, FALSE), structure(c(1L, 1L, 1L, 1L, 
> > > > 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > structure(c(8L, 1L, 4L, 1L, 3L, 4L, 6L, 1L, 5L, 2L), .Label = c("B", 
> > > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
> > > > ), class = "factor"), structure(c(7L, 2L, 5L, 2L, 1L, 2L, 
> > > > 6L, 1L, 5L, 8L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
> > > > "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(41L, 
> > > > 1L, 13L, 43L, 21L, 87L, 49L, 73L, 46L, 3L), .Label = c("1/11/2019", 
> > > > "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
> > > > "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
> > > > "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
> > > > "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
> > > > "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
> > > > "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
> > > > "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
> > > > "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
> > > > "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
> > > > "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
> > > > "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
> > > > "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
> > > > "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
> > > > "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
> > > > "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
> > > > "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
> > > > "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
> > > > "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
> > > > c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > > FALSE, FALSE), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
> > > > 9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > > "Issuer98", "Issuer99"), class = "factor"), structure(c(94L, 
> > > > 24L, 85L, 29L, 14L, 89L, 9L, 19L, 83L, 91L), .Label = c("BL1", 
> > > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
> > > > "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
> > > > "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
> > > > "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
> > > > "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
> > > > "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
> > > > "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
> > > > "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
> > > > "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
> > > > "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
> > > > "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(2L, 
> > > > 2L, 3L, 6L, 1L, 6L, 6L, 6L, 1L, 6L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > > "Retail", "Services: Business"), class = "factor"), structure(c(6L, 
> > > > 6L, 3L, 5L, 1L, 2L, 5L, 3L, 2L, 4L), .Label = c("Financial Intermediaries", 
> > > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L), .Label = c("AU", 
> > > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label = c("1", 
> > > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("Canada", 
> > > > "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
> > > > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > > structure(c(2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > > "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > > c(2.603554841, 7.27032758, 3.155438813, 5.037267081, 0.125550168, 
> > > > NA, 3.464301168, NA, 4.816376964, 5.246485518), c(2220L, 
> > > > 2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 2220L, 3490L
> > > > ), c(0.55, 0.45, 0.5, 0.4, 0.6, 0.45, 0.45, 0.55, 0.2, 0.55
> > > > ), c(2220L, 2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 
> > > > 2220L, 3490L), c(0.55, 0.45, 0.5, 0.4, 0.3, 0.45, 0.45, 0.4, 
> > > > 0.2, 0.55), c(17L, 15L, 12L, 15L, 14L, 15L, 13L, 14L, 12L, 
> > > > 18L), c(16L, 16L, 14L, 16L, 15L, 12L, 13L, 15L, 14L, 14L), 
> > > > c(200000000, 613811406, 750000000, 200000000, 405500000, 
> > > > 450000000, 530000000, 2010000000, 775000000, 120000000), 
> > > > c(0.02, 0.5, 0.65, 0.27, 0.5, 0.65, 0.65, 0.3, 0.65, 0.02
> > > > ), c(950L, 350L, 350L, 275L, 450L, 275L, 225L, 325L, 275L, 
> > > > 1000L), c(1.25, 1, 0.75, 0.75, 1, 0.75, 0, 1, 0.75, 1.25), 
> > > > c(0.095125, 0.0351, 0.035075, 0.027575, 0.0451, 0.027575, 
> > > > 0.02527, 0.0326, 0.027575, 0.100125), c(0.104211455, 0.046414939, 
> > > > 0.050338657, 0.027233401, 0.059885473, 0.03459045, 0.028669191, 
> > > > 0.048294163, 0.040935438, 0.103470278), c(980.5501911, 400.3544693, 
> > > > 385.8629241, 244.6340073, 511.2711809, 294.3073789, 194.2034583, 
> > > > 385.9437059, 308.4324006, 975.9481504), c(0.095125, 0.035114573, 
> > > > 0.034847619, 0.027437811, 0.045786802, 0.027609374, 0.025317343, 
> > > > 0.032734868, 0.027622511, 0.096274038), c(0L, 0L, 0L, 0L, 
> > > > 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
> > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > > c(0.0428490990990991, 0.0158108108108108, 0.037313829787234, 
> > > > 0.00790114613180516, 0.00945492662473794, 0.0124211711711712, 
> > > > 0.0143091732729332, 0.00934097421203438, 0.0124211711711712, 
> > > > 0.028689111747851), c(0.05231875, 0.015795, 0.0175375, 0.01103, 
> > > > 0.01353, 0.01240875, 0.0113715, 0.01304, 0.005515, 0.05506875
> > > > ), c(0.0019025, 0.01755, 0.02279875, 0.00744525, 0.02255, 
> > > > 0.01792375, 0.0164255, 0.00978, 0.01792375, 0.0020025)), 
> > > > V3 = list(c(47L, 95L, 26L, 64L, 16L, 55L, 61L, 39L, 23L, 
> > > > 66L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, NA, NA, 
> > > > NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > > structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 
> > > > 64L), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", 
> > > > "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
> > > > "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", 
> > > > "ID26", "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", 
> > > > "ID32", "ID33", "ID34", "ID35", "ID36", "ID37", "ID38", 
> > > > "ID39", "ID4", "ID40", "ID41", "ID42", "ID43", "ID44", 
> > > > "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", "ID50", 
> > > > "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
> > > > "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", 
> > > > "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
> > > > "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", 
> > > > "ID77", "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", 
> > > > "ID83", "ID84", "ID85", "ID86", "ID87", "ID88", "ID89", 
> > > > "ID9", "ID90", "ID91", "ID92", "ID93", "ID94", "ID95", 
> > > > "ID96", "ID97", "ID98", "ID99"), class = "factor"), structure(c(43L, 
> > > > 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("Issuer1", 
> > > > "Issuer10", "Issuer100", "Issuer11", "Issuer12", "Issuer13", 
> > > > "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", 
> > > > "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", 
> > > > "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
> > > > "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", 
> > > > "Issuer32", "Issuer33", "Issuer34", "Issuer35", "Issuer36", 
> > > > "Issuer37", "Issuer38", "Issuer39", "Issuer4", "Issuer40", 
> > > > "Issuer41", "Issuer42", "Issuer43", "Issuer44", "Issuer45", 
> > > > "Issuer46", "Issuer47", "Issuer48", "Issuer49", "Issuer5", 
> > > > "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
> > > > "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", 
> > > > "Issuer6", "Issuer60", "Issuer61", "Issuer62", "Issuer63", 
> > > > "Issuer64", "Issuer65", "Issuer66", "Issuer67", "Issuer68", 
> > > > "Issuer69", "Issuer7", "Issuer70", "Issuer71", "Issuer72", 
> > > > "Issuer73", "Issuer74", "Issuer75", "Issuer76", "Issuer77", 
> > > > "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
> > > > "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", 
> > > > "Issuer87", "Issuer88", "Issuer89", "Issuer9", "Issuer90", 
> > > > "Issuer91", "Issuer92", "Issuer93", "Issuer94", "Issuer95", 
> > > > "Issuer96", "Issuer97", "Issuer98", "Issuer99"), class = "factor"), 
> > > > c(99.688, 75.667, 99.229, 99.583, 99.563, 99.188, 98.8, 
> > > > 98.5, 99, 99.75), c(100.281, 78.667, 100.104, 100.333, 
> > > > 100.063, 99.906, 99.75, 99.5, 99.75, 100.25), c(4L, 3L, 
> > > > 6L, 3L, 2L, 4L, 5L, 1L, 1L, 1L), c(4L, 3L, 1L, 3L, 4L, 
> > > > 2L, 4L, 5L, 3L, 3L), c(FALSE, TRUE, TRUE, TRUE, FALSE, 
> > > > TRUE, TRUE, FALSE, TRUE, TRUE), structure(c(1L, 1L, 1L, 
> > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > structure(c(3L, 8L, 9L, 1L, 6L, 3L, 10L, 10L, 9L, 3L), .Label = c("B", 
> > > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", 
> > > > "NR"), class = "factor"), structure(c(6L, 7L, 7L, 2L, 
> > > > 6L, 1L, 9L, 9L, 8L, 2L), .Label = c("B1", "B2", "B3", 
> > > > "Ba1", "Ba2", "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), 
> > > > structure(c(66L, 80L, 74L, 30L, 49L, 72L, 70L, 62L, 10L, 
> > > > 29L), .Label = c("1/11/2019", "1/2/2019", "1/2/2020", 
> > > > "1/30/2022", "10/15/2016", "10/15/2021", "10/17/2019", 
> > > > "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", 
> > > > "11/12/2020", "11/20/2019", "11/20/2020", "11/27/2020", 
> > > > "11/5/2021", "11/6/2020", "11/9/2017", "11/9/2018", "12/15/2018", 
> > > > "12/15/2021", "12/15/2022", "12/16/2019", "12/18/2020", 
> > > > "12/20/2019", "12/7/2018", "12/7/2019", "2/12/2021", 
> > > > "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", "2/24/2017", 
> > > > "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", "3/21/2019", 
> > > > "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", "4/30/2018", 
> > > > "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", "5/15/2018", 
> > > > "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", "5/8/2020", 
> > > > "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", "6/2/2019", 
> > > > "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", "6/30/2017", 
> > > > "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", "7/10/2020", 
> > > > "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", "7/29/2022", 
> > > > "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", "8/12/2021", 
> > > > "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", "8/24/2017", 
> > > > "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", "9/18/2016", 
> > > > "9/18/2019", "9/20/2019"), class = "factor"), c(FALSE, 
> > > > FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > > FALSE), structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 
> > > > 34L, 17L, 64L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > > "Issuer98", "Issuer99"), class = "factor"), structure(c(43L, 
> > > > 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("BL1", 
> > > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", 
> > > > "BL22", "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", 
> > > > "BL29", "BL3", "BL30", "BL31", "BL32", "BL33", "BL34", 
> > > > "BL35", "BL36", "BL37", "BL38", "BL39", "BL4", "BL40", 
> > > > "BL41", "BL42", "BL43", "BL44", "BL45", "BL46", "BL47", 
> > > > "BL48", "BL49", "BL5", "BL50", "BL51", "BL52", "BL53", 
> > > > "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", "BL6", 
> > > > "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", 
> > > > "BL73", "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", 
> > > > "BL8", "BL80", "BL81", "BL82", "BL83", "BL84", "BL85", 
> > > > "BL86", "BL87", "BL88", "BL89", "BL9", "BL90", "BL91", 
> > > > "BL92", "BL93", "BL94", "BL95", "BL96", "BL97", "BL98", 
> > > > "BL99"), class = "factor"), structure(c(1L, 6L, 6L, 4L, 
> > > > 6L, 4L, 6L, 2L, 6L, 2L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > > "Retail", "Services: Business"), class = "factor"), structure(c(2L, 
> > > > 2L, 1L, 5L, 5L, 3L, 3L, 6L, 2L, 4L), .Label = c("Financial Intermediaries", 
> > > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 5L, 8L, 8L, 8L), .Label = c("AU", 
> > > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 3L, 6L, 6L, 6L), .Label = c("1", 
> > > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L, 4L), .Label = c("Canada", 
> > > > "Europe", "Other", "U.S."), class = "factor"), structure(c(2L, 
> > > > 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > > "Y"), class = "factor"), structure(c(1L, 2L, 2L, 1L, 
> > > > 1L, 1L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > > c(8.74248921, NA, NA, 4.338507174, 3.464301168, NA, NA, 
> > > > NA, NA, NA), c(2220L, 2220L, 3490L, 3490L, 1766L, 2220L, 
> > > > 8070L, 8070L, 3490L, 2220L), c(0.6, 0.55, 0.4, 0.4, 0.45, 
> > > > 0.45, 0.4, 0.45, 0.6, 0.4), c(2220L, 2220L, 3490L, 3490L, 
> > > > 1766L, 2220L, 8070L, 8070L, 3490L, 2220L), c(0.3, 0.55, 
> > > > 0.55, 0.4, 0.45, 0.4, 0.45, 0.3, 0.55, 0.5), c(13L, 17L, 
> > > > 17L, 15L, 13L, 14L, 19L, 19L, 18L, 15L), c(15L, 16L, 
> > > > 15L, 15L, 13L, 14L, 19L, 19L, 15L, 15L), c(625000000, 
> > > > 450000000, 760000000, 630000000, 530000000, 671500000, 
> > > > 240000000, 100000000, 375000000, 1043700000), c(0.5, 
> > > > 0.02, 0.02, 0.3, 0.65, 0.3, 0.5, 0.65, 0.02, 0.6), c(275L, 
> > > > 750L, 650L, 300L, 225L, 300L, 700L, 925L, 825L, 400L), 
> > > > c(0, 1, 1, 1.25, 0, 1, 1, 1.25, 1.25, 1), c(0.03027, 
> > > > 0.0751, 0.0651, 0.030125, 0.02527, 0.0301, 0.0701, 0.092625, 
> > > > 0.082625, 0.0401), c(0.031286195, 0.154827358, 0.080695261, 
> > > > 0.041683558, 0.028669191, 0.044131997, 0.084009559, 0.108958135, 
> > > > 0.090916682, 0.051331755), c(263.290277, 1448.101305, 
> > > > 704.3633733, 368.0708419, 194.2034583, 356.3784942, 746.772345, 
> > > > 1036.334285, 875.917553, 436.2991366), c(0.030274693, 
> > > > 0.097321394, 0.065317835, 0.030137658, 0.025317343, 0.030236973, 
> > > > 0.070611937, 0.093560606, 0.083144654, 0.040049938), 
> > > > c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 
> > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), 
> > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > > c(0.0136351351351351, 0.0338288288288288, 0.0186532951289398, 
> > > > 0.00863180515759312, 0.0143091732729332, 0.0135585585585586, 
> > > > 0.00868649318463445, 0.0114776951672862, 0.0236747851002865, 
> > > > 0.0180630630630631), c(0.009081, 0.041305, 0.035805, 
> > > > 0.01205, 0.0113715, 0.01204, 0.031545, 0.0277875, 0.04544375, 
> > > > 0.02005), c(0.015135, 0.001502, 0.001302, 0.0090375, 
> > > > 0.0164255, 0.00903, 0.03505, 0.06020625, 0.0016525, 0.02406
> > > > ))), .Names = c("V1", "V2", "V3"), row.names = c(NA, 
> > > > -48L), class = c("data.table", "data.frame"))
> > > > 
> > > > 
> > > > 
> > > >> Subject: Re: [R] binding two lists of lists of dataframes together
> > > >> From: dwinsemius at comcast.net
> > > >> Date: Tue, 12 May 2015 11:36:50 -0700
> > > >> CC: r-help at r-project.org
> > > >> To: newrnewbie at hotmail.com
> > > >> 
> > > >> 
> > > >> On May 12, 2015, at 9:24 AM, Vin Cheng wrote:
> > > >> 
> > > >>> list1<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L), 
> > > >>> WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > >>> structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
> > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
> > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > >>> structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
> > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
> > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > > >>> .Names = c("id", "WgtBand", "Wgt")))
> > > >>> 
> > > >>> 
> > > >>> list2<-list(structure(list(id = c(493L, 564L, 147L), 
> > > >>> WgtBand = c(1, 2, 3), 
> > > >>> Wgt = c(NaN, NaN, NA)), 
> > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > >>> structure(list(id = c(276L, 411L, 574L,111L), 
> > > >>> WgtBand = c(1, 2, 3,4), 
> > > >>> Wgt = c(NaN, NaN, NA,NA)), 
> > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > >>> structure(list(id = c(76L, 330L), 
> > > >>> WgtBand = c(1, 1), 
> > > >>> Wgt = c(NaN, NaN)), 
> > > >>> .Names = c("id", "WgtBand", "Wgt")))
> > > >>> 
> > > >>> list3<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L,493L, 564L, 147L), 
> > > >>> WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9,1, 2, 3), 
> > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA)), 
> > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > >>> structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,276L, 411L, 574L,111L), 
> > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 2, 3,4), 
> > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA,NA)), 
> > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > >>> structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,76L, 330L), 
> > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 1), 
> > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN)), 
> > > >>> .Names = c("id", "WgtBand", "Wgt")))
> > > >> 
> > > >> I get something like the desired structure with:
> > > >> 
> > > >> mapply(function(x,y) mapply(c, x,y), list1,list2)
> > > >> 
> > > >> I can make it closer with:
> > > >> 
> > > >> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) unclass( as.data.frame(x) ) )
> > > >> 
> > > >> 
> > > >> Or even closer with:
> > > >> 
> > > >> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) as.list( as.data.frame(x) ) )
> > > >> 
> > > >> `identical` does not return TRUE but I cannot see where the difference lies.
> > > >> 
> > > >> -- 
> > > >> 
> > > >> David Winsemius
> > > >> Alameda, CA, USA
> > > >> 
> > > > 
> > > > [[alternative HTML version deleted]]
> > > > 
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > 
> > > David Winsemius
> > > Alameda, CA, USA
> > > 
> 
> David Winsemius
> Alameda, CA, USA
> 
 		 	   		  
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu May 14 00:51:47 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 13 May 2015 15:51:47 -0700
Subject: [R] binding two lists of lists of dataframes together
In-Reply-To: <BAY179-W44BDA61F1D2A044E3AE646D3D90@phx.gbl>
References: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>,
	<A2E1A0300F5.00001107jrkrideau@inbox.com>
	<BAY179-W63A3DF10922679A302B16D3DA0@phx.gbl>,
	<17C25B6B-DDF7-4108-99C9-3DABC178C32F@comcast.net>
	<BAY179-W817CF1BB2EEC863DC596F5D3DA0@phx.gbl>,
	<1084ED86-44F2-4717-9879-4A8A368FE00A@comcast.net>
	<BAY179-W41355B8D24DBDB0BEF7978D3DA0@phx.gbl>,
	<F8CE47F9-1AEE-4514-9779-61DB3AF0F019@comcast.net>
	<BAY179-W44BDA61F1D2A044E3AE646D3D90@phx.gbl>
Message-ID: <689E9E7A-5D78-4D80-8318-F71A1138C445@comcast.net>


On May 13, 2015, at 2:01 PM, Vin Cheng wrote:

> Hi David,
>  
> I tried both solutions you provided(lapply(dlist, function(x) rbind(x,x) ) & Map( rbind, smaller, smaller))  and they seem to transpose and reshape the data into a different structure.  Whenever I added the str - I only get a NULL.

I believe you are misrepresenting my suggestion. I suggested that you coerce each of the items in those lists to data.frames with appropriate column names before applying rbind.data.frame

Those list1 and list2 examples appear to me as pathologically deformed. They claim to be data.tables but they have no self referential pointers, suggesting to me that they are not data.tables, and they have no column names suggesting not either data.table, nor data.frame.

> class(list1)
[1] "data.table" "data.frame"
> class(list2)
[1] "data.table" "data.frame"

>  
> > You basically want a list of the same general structure as list1 where all the elements in list two at the same position and depth have been concatenated?
>  
> Yes - that sounds exactly right.
>  
Fix up the data.structures, first. Then use Map(rbind, ...)   .... as described previously.

 list1a <- lapply(list1, function(x) setNames( data.frame(x), paste0("V", seq(length(x)) ) ) )
 list2a <- lapply(list2, function(x) setNames( data.frame(x), paste0("V", seq(length(x)) ) ))
 list3a <- Map( rbind.data.frame, list1a, list2a)
 str(list3a)

List of 3
 $ V1:'data.frame':	22 obs. of  8 variables:
  ..$ V1: int [1:22] 15 19 28 9 17 3 11 21 7 8 ...
  ..$ V2: num [1:22] 1 1 2 3 4 5 6 7 8 9 ...
  ..$ V3: num [1:22] NaN NaN NA NA NA NA NA NA NA NA ...
  ..$ V4: num [1:22] 0 0 0 0 0 0 0 0 0 0 ...
  ..$ V5: Factor w/ 29 levels "ID1","ID10","ID11",..: 7 11 21 29 9 23 3 14 27 28 ...
  ..$ V6: Factor w/ 29 levels "Issuer1","Issuer10",..: 7 11 21 29 9 23 3 14 27 28 ...
  ..$ V7: num [1:22] 99.5 95.5 99.5 100 98.5 ...
  ..$ V8: num [1:22] 0.4 0.55 0.4 0.4 0.5 0.45 0.4 0.45 0.6 0.4 ...
 $ V2:'data.frame':	22 obs. of  8 variables:
  ..$ V1: int [1:22] 10 29 5 19 28 3 10 12 1 21 ...
  ..$ V2: num [1:22] 1 1 2 3 4 5 6 7 8 9 ...
  ..$ V3: num [1:22] NaN NaN NA NA NA NA NA NA NA NA ...
  ..$ V4: num [1:22] 0 0 0 0 0 0 0 0 0 0 ...
  ..$ V5: Factor w/ 29 levels "ID1","ID10","ID11",..: 2 22 25 11 21 23 2 4 1 14 ...
  ..$ V6: Factor w/ 29 levels "Issuer1","Issuer10",..: 2 22 25 11 21 23 2 4 1 14 ...
  ..$ V7: num [1:22] 98.5 100.2 99 95.5 99.5 ...
  ..$ V8: num [1:22] 0.6 0.4 0.45 0.55 0.4 0.45 0.6 0.55 0.5 0.45 ...
 $ V3:'data.frame':	22 obs. of  8 variables:
  ..$ V1: int [1:22] 21 28 3 7 25 25 15 13 3 20 ...
  ..$ V2: num [1:22] 1 1 2 3 4 5 6 7 8 9 ...
  ..$ V3: num [1:22] NaN NaN NA NA NA NA NA NA NA NA ...
  ..$ V4: num [1:22] 0 0 0 0 0 0 0 0 0 0 ...
  ..$ V5: Factor w/ 29 levels "ID1","ID10","ID11",..: 14 21 23 27 18 18 7 5 23 13 ...
  ..$ V6: Factor w/ 29 levels "Issuer1","Issuer10",..: 14 21 23 27 18 18 7 5 23 13 ...
  ..$ V7: num [1:22] 98 99.5 99.6 99.8 99.4 ...
  ..$ V8: num [1:22] 0.45 0.4 0.45 0.6 0.4 0.4 0.4 0.4 0.45 0.3 ..

-- 
David


> I've created new input(list1,list2) and desired output(list3) examples below.  I hope this makes the request a lot clearer.
>  
> Not sure if this helpful, but I found this bit of script and it keeps V1,V2,V3 separate and keeps each set of observations as vectors, but it doesn't concatenate the v1 observations with v2 observations together.
>  
> sample.list <- list(list1,list2)
> library(data.table) 
> nr <- nrow(sample.list[[1]])
> fastbind.ith.rows <- function(i) rbindlist(lapply(sample.list, "[", i, TRUE))
> fastbound <- lapply(1:nr, fastbind.ith.rows)
>  
> Link:
> http://stackoverflow.com/questions/4863341/fast-vectorized-merge-of-list-of-data-frames-by-row
>  
> Thank you again!
> Vince
>  
> Please find below the structure for list1, list2, and the desired output list3:
>  
> list1<-structure(list(
> V1 = list(c(15L, 19L, 28L, 9L, 17L, 3L, 11L, 21L,7L, 8L, 11L, 13L), 
>  c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 
>  c(NaN,NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
>  c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
>  structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L), .Label = c("Issuer1", "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), 
> class = "factor"), c(99.5, 95.5, 99.5, 100, 98.5, 99.646, 99.833, 98, 99.75, 100, 99.833, 98.563), c(0.4, 0.55, 0.4, 0.4, 0.5, 0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4)), 
> V2 = list(c(10L, 29L, 5L, 19L, 28L, 3L, 10L, 12L, 1L, 21L, 23L, 25L), 
> c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 
> c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
> c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L), .Label = c("Issuer1", 
> "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", 
> "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor")
> , c(98.5, 100.25, 99, 95.5, 99.5, 99.646, 98.5, 94.75, 98.75, 98, 99, 99.388), c(0.6, 0.4, 0.45, 0.55, 0.4, 0.45, 0.6, 0.55, 0.5, 0.45, 0.55, 0.4)), 
> V3 = list(c(21L, 28L, 3L, 7L, 25L, 25L, 15L, 13L, 3L, 20L, 16L, 18L), 
> c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 
> c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
> c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L), .Label = c("Issuer1", 
> "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", 
> "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), 
> c(98, 99.5, 99.646, 99.75, 99.388, 99.388, 99.5, 98.563, 99.646, 98, 99.563, 100.375), c(0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4, 0.4, 0.45, 0.3, 0.45, 0.5))), .Names = c("V1", 
> "V2", "V3"), row.names = c("id", "WgtBand", "Wgt", "Held", "LoanXID", "Issuer", "Bid", "Offer"), class = c("data.table", "data.frame"))
> list2<-structure(list(V1 = list(
> c(15L, 8L, 2L, 21L, 8L, 2L, 23L, 25L, 20L, 4L), 
> c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> structure(c(7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("Issuer1", 
> "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", 
> "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), c(99.5, 100, 96.969, 98, 100, 96.969, 99, 99.388, 98, 94), 
> c(0.4, 0.4, 0.45, 0.45, 0.4, 0.45, 0.55, 0.4, 0.3, 0.45)), 
> V2 = list(c(27L, 14L, 11L, 25L, 17L, 15L, 10L, 23L, 16L, 2L), 
> c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> structure(c(20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("Issuer1", 
> "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", 
> "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), 
> c(100.296, 88.5, 99.833, 99.388, 98.5, 99.5, 98.5, 99, 99.563, 96.969), c(0.4, 0.4, 0.4, 0.4, 0.5, 0.4, 0.6, 0.55, 0.45, 0.45)), 
> V3 = list(c(13L, 26L, 5L, 17L, 5L, 28L, 2L, 16L, 1L, 19L), 
> c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> structure(c(5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 11L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", 
> "ID24", "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 
> 11L), .Label = c("Issuer1", "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"
> ), class = "factor"), c(98.563, 99.229, 99, 98.5, 99, 99.5, 96.969, 99.563, 98.75, 95.5), c(0.4, 0.55, 0.45, 0.5, 0.45, 0.4, 0.45, 0.45, 0.5, 0.55))), .Names = c("V1", 
> "V2", "V3"), row.names = c("id", "WgtBand", "Wgt", "Held", "LoanXID", "Issuer", "Bid", "Offer"), class = c("data.table", "data.frame"))
> list3<-structure(list(
> V1 = list(c(15L, 19L, 28L, 9L, 17L, 3L, 11L, 21L,7L, 8L, 11L, 13L,15L, 8L, 2L, 21L, 8L, 2L, 23L, 25L, 20L, 4L), 
>  c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
>  c(NaN,NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
>  c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
>  structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L,7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L,7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("Issuer1", "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), 
> class = "factor"), c(99.5, 95.5, 99.5, 100, 98.5, 99.646, 99.833, 98, 99.75, 100, 99.833, 98.563,99.5, 100, 96.969, 98, 100, 96.969, 99, 99.388, 98, 94), c(0.4, 0.55, 0.4, 0.4, 0.5, 0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4,0.4, 0.4, 0.45, 0.45, 0.4, 0.45, 0.55, 0.4, 0.3, 0.45)), 
> V2 = list(c(10L, 29L, 5L, 19L, 28L, 3L, 10L, 12L, 1L, 21L, 23L, 25L,27L, 14L, 11L, 25L, 17L, 15L, 10L, 23L, 16L, 2L), 
> c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L,20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L,20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("Issuer1", 
> "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", 
> "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor")
> , c(98.5, 100.25, 99, 95.5, 99.5, 99.646, 98.5, 94.75, 98.75, 98, 99, 99.388,100.296, 88.5, 99.833, 99.388, 98.5, 99.5, 98.5, 99, 99.563, 96.969), c(0.6, 0.4, 0.45, 0.55, 0.4, 0.45, 0.6, 0.55, 0.5, 0.45, 0.55, 0.4,0.4, 0.4, 0.4, 0.4, 0.5, 0.4, 0.6, 0.55, 0.45, 0.45)), 
> V3 = list(c(21L, 28L, 3L, 7L, 25L, 25L, 15L, 13L, 3L, 20L, 16L, 18L,13L, 26L, 5L, 17L, 5L, 28L, 2L, 16L, 1L, 19L), 
> c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L,5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 11L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L,5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 11L), .Label = c("Issuer1", 
> "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", 
> "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), 
> c(98, 99.5, 99.646, 99.75, 99.388, 99.388, 99.5, 98.563, 99.646, 98, 99.563, 100.375,98.563, 99.229, 99, 98.5, 99, 99.5, 96.969, 99.563, 98.75, 95.5), c(0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4, 0.4, 0.45, 0.3, 0.45, 0.5,0.4, 0.55, 0.45, 0.5, 0.45, 0.4, 0.45, 0.45, 0.5, 0.55))), .Names = c("V1", 
> "V2", "V3"), row.names = c("id", "WgtBand", "Wgt", "Held", "LoanXID", "Issuer", "Bid", "Offer"), class = c("data.table", "data.frame"))
>  
>  
>  
> > Subject: Re: [R] binding two lists of lists of dataframes together
> > From: dwinsemius at comcast.net
> > Date: Tue, 12 May 2015 16:00:05 -0700
> > CC: r-help at r-project.org
> > To: newrnewbie at hotmail.com
> > 
> > 
> > On May 12, 2015, at 3:12 PM, Vin Cheng wrote:
> > 
> > > Hi David,
> > > 
> > > Would it be possible to modify it a little so that I can keep V1, V2, and V3 intact?
> > 
> > 
> > > 
> > > I also don't quite know where to put list2 in the solution you provided below? list2 can be an exact copy of list1 for this example.
> > 
> > In which case it would be nearly trivial:
> > 
> > lapply(dlist, function(x) rbind(x,x) ) 
> > 
> > str( lapply(dlist, function(x) rbind(x,x) ) )
> > List of 3
> > $ V1:'data.frame':	20 obs. of 48 variables:
> > ..$ V1 : int [1:20] 19 94 94 15 90 13 66 17 45 69 ...
> > ..$ V2 : num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
> > ..$ V3 : num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
> > ..$ V4 : num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> > snipped.....
> > 
> > > 
> > > list1 has (48 observations of 3 variables(V1, V2,V3)) each observation has 10 values in a vector 
> > > list2 has (48 observations of 3 variables (V1, V2,V3)) each observation has 10 values in a vector 
> > 
> > You basically want a list of the same general structure as list1 where all the elements in list two at the same position and depth have been concatenated?
> > > 
> > > Output should ideally have (48 observations of 3 variables (V1, V2,V3)) each observation has 20 values in a vector
> > > list1 V1 stacks with list2 V1, 
> > > list1 V2 stacks with list2 V2, 
> > > list1 V3 stacks with list2 V3
> > 
> > You had a bunch of factor variables in list1. Are we assured that the levels of any factor variables in list2 are the same as the corresponding factor variables in list 1?
> > 
> > > 
> > > Boundlist seems to break out the values of each variable(V1,V2,V3) into 10 columns with 1 value in each column.
> > 
> > Not the way I use those words after using R for the last 8 years. There were 48 "columns" and 10 positions in each. I think you need to reverse your terminology (columns and rows) since a "column" in a dataframe is a list and the row numbers are the relative positions along vectors.
> > 
> > 
> > > Is it possible to put the values in the 10 columns(20 values in ideal output) into a vector for each of the 48 observation in each variable(V1,V2,V3).
> > 
> > Having severe trouble reformulating this in R dataframe terminology.
> > 
> > > 
> > > Sorry for all the back and forth - explaining an exact output over email is difficult.
> > 
> > It shouldn't be difficult if you would post data examples with sufficient complexity to represent the problem. I will build a smaller list of dataframe and name it 'smaller'
> > 
> > Since I had difficulty with mapply I'm switching to the list version named ?Map found in the ?funprog page:
> > 
> > smaller <- lapply(dlist, "[", 1:6)
> > 
> > ?Map
> > str( Map( rbind, smaller, smaller))
> > 
> > #------I think this is what you might want----------
> > List of 3
> > $ V1:'data.frame':	20 obs. of 6 variables:
> > ..$ V1: int [1:20] 19 94 94 15 90 13 66 17 45 69 ...
> > ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
> > ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
> > ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> > ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 12 95 95 8 91 6 64 10 41 67 ...
> > ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 12 95 95 8 91 6 64 10 41 67 ...
> > $ V2:'data.frame':	20 obs. of 6 variables:
> > ..$ V1: int [1:20] 93 3 85 34 20 89 16 25 83 90 ...
> > ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
> > ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
> > ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> > ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 94 24 85 29 14 89 9 19 83 91 ...
> > ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 94 24 85 29 14 89 9 19 83 91 ...
> > $ V3:'data.frame':	20 obs. of 6 variables:
> > ..$ V1: int [1:20] 47 95 26 64 16 55 61 39 23 66 ...
> > ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
> > ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
> > ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> > ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 43 96 20 62 9 52 59 34 17 64 ...
> > ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 43 96 20 62 9 52 59 34 17 64 ...
> > 
> > > 
> > > I really appreciate the help and the effort! 
> > > 
> > > Thank you again!
> > > Vince
> > > 
> > > > Subject: Re: [R] binding two lists of lists of dataframes together
> > > > From: dwinsemius at comcast.net
> > > > Date: Tue, 12 May 2015 14:23:54 -0700
> > > > CC: r-help at r-project.org
> > > > To: newrnewbie at hotmail.com
> > > > 
> > > > 
> > > > On May 12, 2015, at 12:56 PM, Vin Cheng wrote:
> > > > 
> > > > > Hi,
> > > > > 
> > > > > Thanks David! Your solution 3 worked well with the sample data, but when I run solution 2 & 3 on the actual data - it creates a list of 1 for each data point and it doesn't end up looking like the desired output for some reason.
> > > > > 
> > > > > I've run a dput on the actual data and pasted below. There's a lot of data - so I'm only copying list1 - if the solution could bind list1 with itself - it should work just as well. 
> > > > > 
> > > > > Sorry for not providing an accurate sample the first time around - I thought the shortened version would be simpler and sufficient.
> > > > > 
> > > > > Any help/guidance would be greatly appreciated!
> > > > > 
> > > > 
> > > > This appears to be three similarly structured lists of various classes but fortunately for this effort the factor variables in corresponding columns all have the same levels. (Otherwise one would need to convert to character before attempting to stack them.)
> > > > 
> > > > I would just use `rbind.data.frame` (after making them dataframes with the same column names.)
> > > > 
> > > > 
> > > > dlist <- lapply( list1, function(d) setNames( data.frame(d), paste0("V", 1:48) ))
> > > > boundlist <- do.call(rbind, dlist)
> > > > 
> > > > # Done.
> > > > 
> > > > -- 
> > > > David.
> > > > > Many Thanks,
> > > > > Vince
> > > > > 
> > > > > list1 <- structure(list(V1 = list(c(19L, 94L, 94L, 15L, 90L, 13L, 66L, 
> > > > > 17L, 45L, 69L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, 
> > > > > NA, NA, NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 
> > > > > 0), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
> > > > > ), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", "ID13", 
> > > > > "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", 
> > > > > "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", "ID27", "ID28", 
> > > > > "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", "ID34", "ID35", 
> > > > > "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", "ID41", "ID42", 
> > > > > "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", 
> > > > > "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
> > > > > "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", "ID64", 
> > > > > "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", "ID70", "ID71", 
> > > > > "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", "ID78", "ID79", 
> > > > > "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", "ID85", "ID86", 
> > > > > "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", "ID92", "ID93", 
> > > > > "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"), class = "factor"), 
> > > > > structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
> > > > > ), .Label = c("Issuer1", "Issuer10", "Issuer100", "Issuer11", 
> > > > > "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
> > > > > "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", 
> > > > > "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", 
> > > > > "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", 
> > > > > "Issuer30", "Issuer31", "Issuer32", "Issuer33", "Issuer34", 
> > > > > "Issuer35", "Issuer36", "Issuer37", "Issuer38", "Issuer39", 
> > > > > "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
> > > > > "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", 
> > > > > "Issuer49", "Issuer5", "Issuer50", "Issuer51", "Issuer52", 
> > > > > "Issuer53", "Issuer54", "Issuer55", "Issuer56", "Issuer57", 
> > > > > "Issuer58", "Issuer59", "Issuer6", "Issuer60", "Issuer61", 
> > > > > "Issuer62", "Issuer63", "Issuer64", "Issuer65", "Issuer66", 
> > > > > "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
> > > > > "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", 
> > > > > "Issuer76", "Issuer77", "Issuer78", "Issuer79", "Issuer8", 
> > > > > "Issuer80", "Issuer81", "Issuer82", "Issuer83", "Issuer84", 
> > > > > "Issuer85", "Issuer86", "Issuer87", "Issuer88", "Issuer89", 
> > > > > "Issuer9", "Issuer90", "Issuer91", "Issuer92", "Issuer93", 
> > > > > "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
> > > > > "Issuer99"), class = "factor"), c(95.5, 98.5, 98.5, 99.5, 
> > > > > 103.5, 98.563, 99.75, 98.5, 98.75, 99.125), c(97.5, 99.5, 
> > > > > 99.5, 100.375, 104.5, 99.188, 100.25, 99.5, 99.75, 100.063
> > > > > ), c(2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 4L), c(4L, 5L, 5L, 
> > > > > 5L, 5L, 2L, 3L, 5L, 3L, 2L), c(TRUE, FALSE, FALSE, TRUE, 
> > > > > FALSE, TRUE, TRUE, FALSE, FALSE, TRUE), structure(c(1L, 1L, 
> > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > structure(c(9L, 2L, 2L, 1L, 2L, 1L, 3L, 3L, 5L, 9L), .Label = c("B", 
> > > > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
> > > > > ), class = "factor"), structure(c(8L, 2L, 2L, 1L, 8L, 2L, 
> > > > > 2L, 2L, 1L, 7L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
> > > > > "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(20L, 
> > > > > 88L, 88L, 6L, 3L, 35L, 29L, 24L, 53L, 82L), .Label = c("1/11/2019", 
> > > > > "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
> > > > > "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
> > > > > "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
> > > > > "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
> > > > > "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
> > > > > "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
> > > > > "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
> > > > > "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
> > > > > "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
> > > > > "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
> > > > > "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
> > > > > "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
> > > > > "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
> > > > > "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
> > > > > "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
> > > > > "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
> > > > > "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
> > > > > "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
> > > > > c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > > > FALSE, FALSE), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 
> > > > > 10L, 41L, 67L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > > > "Issuer98", "Issuer99"), class = "factor"), structure(c(12L, 
> > > > > 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L), .Label = c("BL1", 
> > > > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
> > > > > "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
> > > > > "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
> > > > > "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
> > > > > "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
> > > > > "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
> > > > > "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
> > > > > "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
> > > > > "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
> > > > > "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
> > > > > "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(4L, 
> > > > > 3L, 3L, 5L, 6L, 3L, 2L, 6L, 6L, 5L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > > > "Retail", "Services: Business"), class = "factor"), structure(c(3L, 
> > > > > 5L, 5L, 6L, 4L, 3L, 4L, 2L, 6L, 6L), .Label = c("Financial Intermediaries", 
> > > > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 6L, 8L, 8L), .Label = c("AU", 
> > > > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 5L, 6L, 6L), .Label = c("1", 
> > > > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L), .Label = c("Canada", 
> > > > > "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
> > > > > 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > > > structure(c(2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > > > "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > > 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > > > c(0.125550168, 1.731733265, 1.731733265, NA, 5.246485518, 
> > > > > 7.798802147, NA, NA, NA, NA), c(4770L, 3490L, 3490L, 3490L, 
> > > > > 3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.45, 0.4, 0.4, 
> > > > > 0.45, 0.55, 0.4, 0.4, 0.45, 0.4, 0.5), c(4770L, 3490L, 3490L, 
> > > > > 3490L, 3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.55, 
> > > > > 0.4, 0.4, 0.4, 0.55, 0.4, 0.5, 0.5, 0.45, 0.55), c(18L, 15L, 
> > > > > 15L, 15L, 18L, 15L, 15L, 15L, 14L, 17L), c(17L, 16L, 16L, 
> > > > > 15L, 14L, 15L, 15L, 15L, 14L, 15L), c(192500000, 205000000, 
> > > > > 205000000, 342000000, 120000000, 835000000, 1043700000, 160000000, 
> > > > > 300000000, 265000000), c(0.02, 0.02, 0.02, 0.4, 0.02, 0.4, 
> > > > > 0.6, 0.6, 0.6, 0.02), c(850L, 475L, 475L, 500L, 1000L, 350L, 
> > > > > 400L, 975L, 500L, 700L), c(1, 1.5, 1.5, 1, 1.25, 1, 1, 1, 
> > > > > 1, 1), c(0.0851, 0.04765, 0.04765, 0.0501, 0.100125, 0.0351, 
> > > > > 0.0401, 0.0976, 0.0501, 0.0701), c(0.099192999, 0.023321348, 
> > > > > 0.023321348, 0.06465519, 0.103470278, 0.052237196, 0.051331755, 
> > > > > 0.112300026, 0.066116739, 0.084107871), c(897.0917677, -1.49365213, 
> > > > > -1.49365213, 549.0886934, 975.9481504, 429.1863229, 436.2991366, 
> > > > > 1062.374805, 567.0741295, 747.1023728), c(0.088186528, 0.048131313, 
> > > > > 0.048131313, 0.050131332, 0.096274038, 0.035499188, 0.040049938, 
> > > > > 0.098585859, 0.050478589, 0.070385766), c(0L, 0L, 0L, 0L, 
> > > > > 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > > 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
> > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > > > c(0.0178406708595388, 0.0136532951289398, 0.0136532951289398, 
> > > > > 0.0143553008595989, 0.028689111747851, 0.0100573065902579, 
> > > > > 0.0180630630630631, 0.043963963963964, 0.0225675675675676, 
> > > > > 0.0200859598853868), c(0.046805, 0.01906, 0.01906, 0.02004, 
> > > > > 0.05506875, 0.01404, 0.02005, 0.0488, 0.022545, 0.038555), 
> > > > > c(0.001702, 0.000953, 0.000953, 0.02004, 0.0020025, 0.01404, 
> > > > > 0.02406, 0.05856, 0.03006, 0.001402)), V2 = list(c(93L, 3L, 
> > > > > 85L, 34L, 20L, 89L, 16L, 25L, 83L, 90L), c(1, 1, 2, 3, 4, 5, 
> > > > > 6, 7, 8, 9), c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), c(0, 
> > > > > 0, 0, 0, 0, 0, 0, 0, 0, 0), structure(c(94L, 24L, 85L, 29L, 14L, 
> > > > > 89L, 9L, 19L, 83L, 91L), .Label = c("ID1", "ID10", "ID100", "ID11", 
> > > > > "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
> > > > > "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> > > > > "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", 
> > > > > "ID34", "ID35", "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", 
> > > > > "ID41", "ID42", "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", 
> > > > > "ID49", "ID5", "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", 
> > > > > "ID56", "ID57", "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", 
> > > > > "ID63", "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
> > > > > "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", 
> > > > > "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", 
> > > > > "ID85", "ID86", "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", 
> > > > > "ID92", "ID93", "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"
> > > > > ), class = "factor"), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
> > > > > 9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
> > > > > "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> > > > > "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
> > > > > "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", "Issuer32", 
> > > > > "Issuer33", "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
> > > > > "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", "Issuer49", 
> > > > > "Issuer5", "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
> > > > > "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", "Issuer6", 
> > > > > "Issuer60", "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
> > > > > "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", "Issuer76", 
> > > > > "Issuer77", "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
> > > > > "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", "Issuer87", 
> > > > > "Issuer88", "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
> > > > > "Issuer99"), class = "factor"), c(99.5, 99.646, 100.402, 100.25, 
> > > > > 98, 99.563, 99.563, 99.388, 99.531, 103.5), c(100.5, 100.271, 
> > > > > 100.903, 100.75, 99, 100.188, 100.063, 99.788, 100.125, 104.5
> > > > > ), c(1L, 6L, 9L, 1L, 1L, 2L, 2L, 10L, 4L, 2L), c(5L, 2L, 1L, 
> > > > > 3L, 3L, 4L, 4L, 1L, 1L, 5L), c(TRUE, TRUE, FALSE, FALSE, TRUE, 
> > > > > FALSE, FALSE, TRUE, TRUE, FALSE), structure(c(1L, 1L, 1L, 1L, 
> > > > > 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > structure(c(8L, 1L, 4L, 1L, 3L, 4L, 6L, 1L, 5L, 2L), .Label = c("B", 
> > > > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
> > > > > ), class = "factor"), structure(c(7L, 2L, 5L, 2L, 1L, 2L, 
> > > > > 6L, 1L, 5L, 8L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
> > > > > "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(41L, 
> > > > > 1L, 13L, 43L, 21L, 87L, 49L, 73L, 46L, 3L), .Label = c("1/11/2019", 
> > > > > "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
> > > > > "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
> > > > > "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
> > > > > "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
> > > > > "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
> > > > > "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
> > > > > "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
> > > > > "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
> > > > > "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
> > > > > "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
> > > > > "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
> > > > > "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
> > > > > "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
> > > > > "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
> > > > > "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
> > > > > "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
> > > > > "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
> > > > > "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
> > > > > c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > > > FALSE, FALSE), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
> > > > > 9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > > > "Issuer98", "Issuer99"), class = "factor"), structure(c(94L, 
> > > > > 24L, 85L, 29L, 14L, 89L, 9L, 19L, 83L, 91L), .Label = c("BL1", 
> > > > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
> > > > > "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
> > > > > "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
> > > > > "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
> > > > > "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
> > > > > "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
> > > > > "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
> > > > > "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
> > > > > "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
> > > > > "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
> > > > > "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(2L, 
> > > > > 2L, 3L, 6L, 1L, 6L, 6L, 6L, 1L, 6L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > > > "Retail", "Services: Business"), class = "factor"), structure(c(6L, 
> > > > > 6L, 3L, 5L, 1L, 2L, 5L, 3L, 2L, 4L), .Label = c("Financial Intermediaries", 
> > > > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L), .Label = c("AU", 
> > > > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label = c("1", 
> > > > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("Canada", 
> > > > > "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
> > > > > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > > > structure(c(2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > > > "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > > 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > > > c(2.603554841, 7.27032758, 3.155438813, 5.037267081, 0.125550168, 
> > > > > NA, 3.464301168, NA, 4.816376964, 5.246485518), c(2220L, 
> > > > > 2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 2220L, 3490L
> > > > > ), c(0.55, 0.45, 0.5, 0.4, 0.6, 0.45, 0.45, 0.55, 0.2, 0.55
> > > > > ), c(2220L, 2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 
> > > > > 2220L, 3490L), c(0.55, 0.45, 0.5, 0.4, 0.3, 0.45, 0.45, 0.4, 
> > > > > 0.2, 0.55), c(17L, 15L, 12L, 15L, 14L, 15L, 13L, 14L, 12L, 
> > > > > 18L), c(16L, 16L, 14L, 16L, 15L, 12L, 13L, 15L, 14L, 14L), 
> > > > > c(200000000, 613811406, 750000000, 200000000, 405500000, 
> > > > > 450000000, 530000000, 2010000000, 775000000, 120000000), 
> > > > > c(0.02, 0.5, 0.65, 0.27, 0.5, 0.65, 0.65, 0.3, 0.65, 0.02
> > > > > ), c(950L, 350L, 350L, 275L, 450L, 275L, 225L, 325L, 275L, 
> > > > > 1000L), c(1.25, 1, 0.75, 0.75, 1, 0.75, 0, 1, 0.75, 1.25), 
> > > > > c(0.095125, 0.0351, 0.035075, 0.027575, 0.0451, 0.027575, 
> > > > > 0.02527, 0.0326, 0.027575, 0.100125), c(0.104211455, 0.046414939, 
> > > > > 0.050338657, 0.027233401, 0.059885473, 0.03459045, 0.028669191, 
> > > > > 0.048294163, 0.040935438, 0.103470278), c(980.5501911, 400.3544693, 
> > > > > 385.8629241, 244.6340073, 511.2711809, 294.3073789, 194.2034583, 
> > > > > 385.9437059, 308.4324006, 975.9481504), c(0.095125, 0.035114573, 
> > > > > 0.034847619, 0.027437811, 0.045786802, 0.027609374, 0.025317343, 
> > > > > 0.032734868, 0.027622511, 0.096274038), c(0L, 0L, 0L, 0L, 
> > > > > 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > > 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
> > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > > > c(0.0428490990990991, 0.0158108108108108, 0.037313829787234, 
> > > > > 0.00790114613180516, 0.00945492662473794, 0.0124211711711712, 
> > > > > 0.0143091732729332, 0.00934097421203438, 0.0124211711711712, 
> > > > > 0.028689111747851), c(0.05231875, 0.015795, 0.0175375, 0.01103, 
> > > > > 0.01353, 0.01240875, 0.0113715, 0.01304, 0.005515, 0.05506875
> > > > > ), c(0.0019025, 0.01755, 0.02279875, 0.00744525, 0.02255, 
> > > > > 0.01792375, 0.0164255, 0.00978, 0.01792375, 0.0020025)), 
> > > > > V3 = list(c(47L, 95L, 26L, 64L, 16L, 55L, 61L, 39L, 23L, 
> > > > > 66L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, NA, NA, 
> > > > > NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > > > structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 
> > > > > 64L), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", 
> > > > > "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
> > > > > "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", 
> > > > > "ID26", "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", 
> > > > > "ID32", "ID33", "ID34", "ID35", "ID36", "ID37", "ID38", 
> > > > > "ID39", "ID4", "ID40", "ID41", "ID42", "ID43", "ID44", 
> > > > > "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", "ID50", 
> > > > > "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
> > > > > "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", 
> > > > > "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
> > > > > "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", 
> > > > > "ID77", "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", 
> > > > > "ID83", "ID84", "ID85", "ID86", "ID87", "ID88", "ID89", 
> > > > > "ID9", "ID90", "ID91", "ID92", "ID93", "ID94", "ID95", 
> > > > > "ID96", "ID97", "ID98", "ID99"), class = "factor"), structure(c(43L, 
> > > > > 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("Issuer1", 
> > > > > "Issuer10", "Issuer100", "Issuer11", "Issuer12", "Issuer13", 
> > > > > "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", 
> > > > > "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", 
> > > > > "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
> > > > > "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", 
> > > > > "Issuer32", "Issuer33", "Issuer34", "Issuer35", "Issuer36", 
> > > > > "Issuer37", "Issuer38", "Issuer39", "Issuer4", "Issuer40", 
> > > > > "Issuer41", "Issuer42", "Issuer43", "Issuer44", "Issuer45", 
> > > > > "Issuer46", "Issuer47", "Issuer48", "Issuer49", "Issuer5", 
> > > > > "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
> > > > > "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", 
> > > > > "Issuer6", "Issuer60", "Issuer61", "Issuer62", "Issuer63", 
> > > > > "Issuer64", "Issuer65", "Issuer66", "Issuer67", "Issuer68", 
> > > > > "Issuer69", "Issuer7", "Issuer70", "Issuer71", "Issuer72", 
> > > > > "Issuer73", "Issuer74", "Issuer75", "Issuer76", "Issuer77", 
> > > > > "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
> > > > > "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", 
> > > > > "Issuer87", "Issuer88", "Issuer89", "Issuer9", "Issuer90", 
> > > > > "Issuer91", "Issuer92", "Issuer93", "Issuer94", "Issuer95", 
> > > > > "Issuer96", "Issuer97", "Issuer98", "Issuer99"), class = "factor"), 
> > > > > c(99.688, 75.667, 99.229, 99.583, 99.563, 99.188, 98.8, 
> > > > > 98.5, 99, 99.75), c(100.281, 78.667, 100.104, 100.333, 
> > > > > 100.063, 99.906, 99.75, 99.5, 99.75, 100.25), c(4L, 3L, 
> > > > > 6L, 3L, 2L, 4L, 5L, 1L, 1L, 1L), c(4L, 3L, 1L, 3L, 4L, 
> > > > > 2L, 4L, 5L, 3L, 3L), c(FALSE, TRUE, TRUE, TRUE, FALSE, 
> > > > > TRUE, TRUE, FALSE, TRUE, TRUE), structure(c(1L, 1L, 1L, 
> > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > structure(c(3L, 8L, 9L, 1L, 6L, 3L, 10L, 10L, 9L, 3L), .Label = c("B", 
> > > > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", 
> > > > > "NR"), class = "factor"), structure(c(6L, 7L, 7L, 2L, 
> > > > > 6L, 1L, 9L, 9L, 8L, 2L), .Label = c("B1", "B2", "B3", 
> > > > > "Ba1", "Ba2", "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), 
> > > > > structure(c(66L, 80L, 74L, 30L, 49L, 72L, 70L, 62L, 10L, 
> > > > > 29L), .Label = c("1/11/2019", "1/2/2019", "1/2/2020", 
> > > > > "1/30/2022", "10/15/2016", "10/15/2021", "10/17/2019", 
> > > > > "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", 
> > > > > "11/12/2020", "11/20/2019", "11/20/2020", "11/27/2020", 
> > > > > "11/5/2021", "11/6/2020", "11/9/2017", "11/9/2018", "12/15/2018", 
> > > > > "12/15/2021", "12/15/2022", "12/16/2019", "12/18/2020", 
> > > > > "12/20/2019", "12/7/2018", "12/7/2019", "2/12/2021", 
> > > > > "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", "2/24/2017", 
> > > > > "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", "3/21/2019", 
> > > > > "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", "4/30/2018", 
> > > > > "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", "5/15/2018", 
> > > > > "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", "5/8/2020", 
> > > > > "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", "6/2/2019", 
> > > > > "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", "6/30/2017", 
> > > > > "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", "7/10/2020", 
> > > > > "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", "7/29/2022", 
> > > > > "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", "8/12/2021", 
> > > > > "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", "8/24/2017", 
> > > > > "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", "9/18/2016", 
> > > > > "9/18/2019", "9/20/2019"), class = "factor"), c(FALSE, 
> > > > > FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > > > FALSE), structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 
> > > > > 34L, 17L, 64L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > > > "Issuer98", "Issuer99"), class = "factor"), structure(c(43L, 
> > > > > 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("BL1", 
> > > > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", 
> > > > > "BL22", "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", 
> > > > > "BL29", "BL3", "BL30", "BL31", "BL32", "BL33", "BL34", 
> > > > > "BL35", "BL36", "BL37", "BL38", "BL39", "BL4", "BL40", 
> > > > > "BL41", "BL42", "BL43", "BL44", "BL45", "BL46", "BL47", 
> > > > > "BL48", "BL49", "BL5", "BL50", "BL51", "BL52", "BL53", 
> > > > > "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", "BL6", 
> > > > > "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", 
> > > > > "BL73", "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", 
> > > > > "BL8", "BL80", "BL81", "BL82", "BL83", "BL84", "BL85", 
> > > > > "BL86", "BL87", "BL88", "BL89", "BL9", "BL90", "BL91", 
> > > > > "BL92", "BL93", "BL94", "BL95", "BL96", "BL97", "BL98", 
> > > > > "BL99"), class = "factor"), structure(c(1L, 6L, 6L, 4L, 
> > > > > 6L, 4L, 6L, 2L, 6L, 2L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > > > "Retail", "Services: Business"), class = "factor"), structure(c(2L, 
> > > > > 2L, 1L, 5L, 5L, 3L, 3L, 6L, 2L, 4L), .Label = c("Financial Intermediaries", 
> > > > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 5L, 8L, 8L, 8L), .Label = c("AU", 
> > > > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 3L, 6L, 6L, 6L), .Label = c("1", 
> > > > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L, 4L), .Label = c("Canada", 
> > > > > "Europe", "Other", "U.S."), class = "factor"), structure(c(2L, 
> > > > > 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > > > "Y"), class = "factor"), structure(c(1L, 2L, 2L, 1L, 
> > > > > 1L, 1L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > > > c(8.74248921, NA, NA, 4.338507174, 3.464301168, NA, NA, 
> > > > > NA, NA, NA), c(2220L, 2220L, 3490L, 3490L, 1766L, 2220L, 
> > > > > 8070L, 8070L, 3490L, 2220L), c(0.6, 0.55, 0.4, 0.4, 0.45, 
> > > > > 0.45, 0.4, 0.45, 0.6, 0.4), c(2220L, 2220L, 3490L, 3490L, 
> > > > > 1766L, 2220L, 8070L, 8070L, 3490L, 2220L), c(0.3, 0.55, 
> > > > > 0.55, 0.4, 0.45, 0.4, 0.45, 0.3, 0.55, 0.5), c(13L, 17L, 
> > > > > 17L, 15L, 13L, 14L, 19L, 19L, 18L, 15L), c(15L, 16L, 
> > > > > 15L, 15L, 13L, 14L, 19L, 19L, 15L, 15L), c(625000000, 
> > > > > 450000000, 760000000, 630000000, 530000000, 671500000, 
> > > > > 240000000, 100000000, 375000000, 1043700000), c(0.5, 
> > > > > 0.02, 0.02, 0.3, 0.65, 0.3, 0.5, 0.65, 0.02, 0.6), c(275L, 
> > > > > 750L, 650L, 300L, 225L, 300L, 700L, 925L, 825L, 400L), 
> > > > > c(0, 1, 1, 1.25, 0, 1, 1, 1.25, 1.25, 1), c(0.03027, 
> > > > > 0.0751, 0.0651, 0.030125, 0.02527, 0.0301, 0.0701, 0.092625, 
> > > > > 0.082625, 0.0401), c(0.031286195, 0.154827358, 0.080695261, 
> > > > > 0.041683558, 0.028669191, 0.044131997, 0.084009559, 0.108958135, 
> > > > > 0.090916682, 0.051331755), c(263.290277, 1448.101305, 
> > > > > 704.3633733, 368.0708419, 194.2034583, 356.3784942, 746.772345, 
> > > > > 1036.334285, 875.917553, 436.2991366), c(0.030274693, 
> > > > > 0.097321394, 0.065317835, 0.030137658, 0.025317343, 0.030236973, 
> > > > > 0.070611937, 0.093560606, 0.083144654, 0.040049938), 
> > > > > c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 
> > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), 
> > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > > > c(0.0136351351351351, 0.0338288288288288, 0.0186532951289398, 
> > > > > 0.00863180515759312, 0.0143091732729332, 0.0135585585585586, 
> > > > > 0.00868649318463445, 0.0114776951672862, 0.0236747851002865, 
> > > > > 0.0180630630630631), c(0.009081, 0.041305, 0.035805, 
> > > > > 0.01205, 0.0113715, 0.01204, 0.031545, 0.0277875, 0.04544375, 
> > > > > 0.02005), c(0.015135, 0.001502, 0.001302, 0.0090375, 
> > > > > 0.0164255, 0.00903, 0.03505, 0.06020625, 0.0016525, 0.02406
> > > > > ))), .Names = c("V1", "V2", "V3"), row.names = c(NA, 
> > > > > -48L), class = c("data.table", "data.frame"))
> > > > > 
> > > > > 
> > > > > 
> > > > >> Subject: Re: [R] binding two lists of lists of dataframes together
> > > > >> From: dwinsemius at comcast.net
> > > > >> Date: Tue, 12 May 2015 11:36:50 -0700
> > > > >> CC: r-help at r-project.org
> > > > >> To: newrnewbie at hotmail.com
> > > > >> 
> > > > >> 
> > > > >> On May 12, 2015, at 9:24 AM, Vin Cheng wrote:
> > > > >> 
> > > > >>> list1<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L), 
> > > > >>> WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > >>> structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
> > > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
> > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > >>> structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
> > > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
> > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > > > >>> .Names = c("id", "WgtBand", "Wgt")))
> > > > >>> 
> > > > >>> 
> > > > >>> list2<-list(structure(list(id = c(493L, 564L, 147L), 
> > > > >>> WgtBand = c(1, 2, 3), 
> > > > >>> Wgt = c(NaN, NaN, NA)), 
> > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > >>> structure(list(id = c(276L, 411L, 574L,111L), 
> > > > >>> WgtBand = c(1, 2, 3,4), 
> > > > >>> Wgt = c(NaN, NaN, NA,NA)), 
> > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > >>> structure(list(id = c(76L, 330L), 
> > > > >>> WgtBand = c(1, 1), 
> > > > >>> Wgt = c(NaN, NaN)), 
> > > > >>> .Names = c("id", "WgtBand", "Wgt")))
> > > > >>> 
> > > > >>> list3<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L,493L, 564L, 147L), 
> > > > >>> WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9,1, 2, 3), 
> > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA)), 
> > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > >>> structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,276L, 411L, 574L,111L), 
> > > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 2, 3,4), 
> > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA,NA)), 
> > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > >>> structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,76L, 330L), 
> > > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 1), 
> > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN)), 
> > > > >>> .Names = c("id", "WgtBand", "Wgt")))
> > > > >> 
> > > > >> I get something like the desired structure with:
> > > > >> 
> > > > >> mapply(function(x,y) mapply(c, x,y), list1,list2)
> > > > >> 
> > > > >> I can make it closer with:
> > > > >> 
> > > > >> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) unclass( as.data.frame(x) ) )
> > > > >> 
> > > > >> 
> > > > >> Or even closer with:
> > > > >> 
> > > > >> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) as.list( as.data.frame(x) ) )
> > > > >> 
> > > > >> `identical` does not return TRUE but I cannot see where the difference lies.
> > > > >> 
> > > > >> -- 
> > > > >> 
> > > > >> David Winsemius
> > > > >> Alameda, CA, USA
> > > > >> 
> > > > > 
> > > > > [[alternative HTML version deleted]]
> > > > > 
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > > 
> > > > David Winsemius
> > > > Alameda, CA, USA
> > > > 
> > 
> > David Winsemius
> > Alameda, CA, USA
> >

David Winsemius
Alameda, CA, USA


From msnewaz at lakeheadu.ca  Wed May 13 18:29:37 2015
From: msnewaz at lakeheadu.ca (Md Newaz)
Date: Wed, 13 May 2015 12:29:37 -0400
Subject: [R] Post-hoc test on split-plot design
Message-ID: <CAHP2NVmFpkM6NYHP1xP14gctBJoxnZR1t+hhAtqztui24XtafQ@mail.gmail.com>

Hi Richard,
Thank you very much for your cooperation. I installed the packages "HH" and
run the following model:

Bud.aov<-aov(terms(Budburst~CO2*SoilTemp*Photoperiod+Greenhouse/(SoilTemp*Photoperiod),keep.order=TRUE),data=data)

> summary(Bud.aov)

                                                  Df   Sum Sq   Mean Sq
   F value    Pr(>F)

CO2                                            1    1465.2    1465.2
      109.612   < 2e-16 ***

SoilTemp                                     1    238.0      238.0
       17.805      3.60e-05 ***

CO2:SoilTemp                              1    145.7      145.7
        10.900     0.001125 **

Photoperiod                                  2    986.9      493.4
        36.914     1.62e-14 ***

CO2:Photoperiod                           2     0.2          0.1
 0.006        0.994095

SoilTemp:Photoperiod                    2     14.6        7.3
 0.545        0.580893

CO2:SoilTemp:Photoperiod             2    186.3      93.2           6.969
       0.001167 **

Greenhouse                                   2    75.5        37.8
  2.824        0.061538 .

SoilTemp:Greenhouse                     2     5.9          3.0
  0.221        0.801896

Photoperiod:Greenhouse                  4    283.4      70.8
  5.300       0.000433 ***

SoilTemp:Photoperiod:Greenhouse   4    56.7        14.2          1.060
       0.377363

Residuals                                       216 2887.3    13.4


The results that I got don't look like the results for the split-plot
design which I got using the model below:

mod<-aov(Budburst~CO2*SoilTemp*Photoperiod+Error(Greenhouse/(SoilTemp*Photoperiod)),data=data)

> summary(mod)

Error: Greenhouse

              Df Sum Sq Mean Sq F value Pr(>F)

CO2        1 1465.2  1465.2      38.81    0.0248 *

Residuals  2   75.5    37.8

Error: Greenhouse:SoilTemp

                      Df Sum Sq Mean Sq F value Pr(>F)

SoilTemp         1 238.00  238.00   80.57       0.0122 *

CO2:SoilTemp  1 145.70  145.70   49.32       0.0197 *

Residuals         2   5.91    2.95

Error: Greenhouse:Photoperiod

                          Df Sum Sq Mean Sq F value Pr(>F)

Photoperiod         2  986.9   493.4        6.965    0.0498 *

CO2:Photoperiod  2    0.2     0.1          0.001     0.9989

Residuals            4  283.4    70.8

Error: Greenhouse:SoilTemp:Photoperiod

                                        Df Sum Sq Mean Sq F value Pr(>F)

SoilTemp:Photoperiod         2  14.56    7.28        0.514    0.6330

CO2:SoilTemp:Photoperiod  2 186.31   93.15      6.576    0.0544 .

Residuals                           4  56.67   14.17

Error: Within

                Df   Sum Sq Mean Sq F value Pr(>F)

Residuals 216   2887     13.37

The F and P values are quite different. Moreover, I could not run the
post-hoc tests as well. At this stage I shall highly appreciate your
further cooperation.

Thanks.

Shah

	[[alternative HTML version deleted]]


From msnewaz at lakeheadu.ca  Wed May 13 21:24:27 2015
From: msnewaz at lakeheadu.ca (Shah)
Date: Wed, 13 May 2015 12:24:27 -0700 (PDT)
Subject: [R] Post-hoc tests on Split-plot design
In-Reply-To: <CAHP2NVm7J6F5gWpLLK0d8YnAdksaSc5dYjYm1q6Yu3Y=wRT=fg@mail.gmail.com>
References: <CAHP2NVm7J6F5gWpLLK0d8YnAdksaSc5dYjYm1q6Yu3Y=wRT=fg@mail.gmail.com>
Message-ID: <1431545067326-4707165.post@n4.nabble.com>

Hi Richard,
Thank you very much for your cooperation. I installed the packages "HH" and
run the following model: 

Bud.aov<-aov(terms(Budburst~CO2*SoilTemp*Photoperiod+Greenhouse/(SoilTemp*Photoperiod),keep.order=TRUE),data=data)
> summary(Bud.aov)
                                                  Df   Sum Sq   Mean Sq    F
value    Pr(>F)   

CO2                                            1    1465.2    1465.2      
109.612   < 2e-16 ***

SoilTemp                                     1    238.0      238.0        
17.805      3.60e-05 ***

CO2:SoilTemp                              1    145.7      145.7         
10.900     0.001125 **

Photoperiod                                  2    986.9      493.4         
36.914     1.62e-14 ***

CO2:Photoperiod                           2     0.2          0.1           
0.006        0.994095   

SoilTemp:Photoperiod                    2     14.6        7.3           
0.545        0.580893   

CO2:SoilTemp:Photoperiod             2    186.3      93.2           6.969       
0.001167 **

Greenhouse                                   2    75.5        37.8          
2.824        0.061538 . 

SoilTemp:Greenhouse                     2     5.9          3.0          
0.221        0.801896   

Photoperiod:Greenhouse                  4    283.4      70.8           5.300      
0.000433 ***

SoilTemp:Photoperiod:Greenhouse   4    56.7        14.2          1.060       
0.377363   

Residuals                                       216 2887.3    13.4



The results don't look like the results for the split-plot design which I
got using the model below: 

mod<-aov(Budburst~CO2*SoilTemp*Photoperiod+Error(Greenhouse/(SoilTemp*Photoperiod)),data=data)

> summary(mod)

Error: Greenhouse

              Df Sum Sq Mean Sq F value Pr(>F)  

CO2        1 1465.2  1465.2      38.81    0.0248 *

Residuals  2   75.5    37.8                 

Error: Greenhouse:SoilTemp

                      Df Sum Sq Mean Sq F value Pr(>F)  

SoilTemp         1 238.00  238.00   80.57       0.0122 *

CO2:SoilTemp  1 145.70  145.70   49.32       0.0197 *

Residuals         2   5.91    2.95                 

Error: Greenhouse:Photoperiod

                          Df Sum Sq Mean Sq F value Pr(>F)  

Photoperiod         2  986.9   493.4        6.965    0.0498 *

CO2:Photoperiod  2    0.2     0.1          0.001     0.9989  

Residuals            4  283.4    70.8                 

Error: Greenhouse:SoilTemp:Photoperiod

                                        Df Sum Sq Mean Sq F value Pr(>F)  

SoilTemp:Photoperiod         2  14.56    7.28        0.514    0.6330  

CO2:SoilTemp:Photoperiod  2 186.31   93.15      6.576    0.0544 .

Residuals                           4  56.67   14.17                 

Error: Within

                Df   Sum Sq Mean Sq F value Pr(>F)

Residuals 216   2887     13.37               


The F and P values are quite different. Moreover, I could not run the
post-hoc tests as well. At this stage I shall highly appreciate your further
assistance.

Thanks.

Shah                     



--
View this message in context: http://r.789695.n4.nabble.com/Post-hoc-tests-on-Split-plot-design-tp4707106p4707165.html
Sent from the R help mailing list archive at Nabble.com.


From jfertaj at well.ox.ac.uk  Thu May 14 00:45:03 2015
From: jfertaj at well.ox.ac.uk (Juan Fernandez)
Date: Wed, 13 May 2015 22:45:03 +0000
Subject: [R] error using the huge R package
Message-ID: <6F401FAF-6CE2-4236-B2E1-1AAC31C18136@well.ox.ac.uk>

Dear List

I am trying to do an association network using some expression data I have, the data is really huge: 300 samples and ~30,000 genes. I would like to apply a gaussian graphical model to my data using the huge R package.

Here is the code I am using

> dim(data)
#[1] 317 32200

> huge.out <- huge.npn(data)
> huge.stars <- huge.select(huge.out, criterion=?stars?)

However in this last step I got the following error:

Error in cor(x) : sampling?..in progress:10%
Missing values present in input variable ?x?. Consider using use = ?pairwise.complete.obs?

Any help would be very appreciated

Juan


	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu May 14 00:56:55 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 14 May 2015 08:56:55 +1000
Subject: [R] Plotting times at night and getting plot limits correct
In-Reply-To: <CAGx1TMCAfcRQ00RztRO=Q0-DErRJwwKoEysyJMsfMoEvqmrApA@mail.gmail.com>
References: <CAN-Z0xUj_+EQgGGmFu8393oA28epJ0S+TH2vUcxQqiw2b9n2Xw@mail.gmail.com>
	<CAGx1TMCAfcRQ00RztRO=Q0-DErRJwwKoEysyJMsfMoEvqmrApA@mail.gmail.com>
Message-ID: <CA+8X3fUQVfru4se-H7T7wxFBGiQmAFz12ZEO5T4aF9dhiwLj6w@mail.gmail.com>

Hi Bob,
Given the other answers I may be off target, but perhaps this will help:

# create two "nights" worth of data
Times<-strptime(
 paste(c("2015-05-13","2015-05-14"),paste(rep(c(18:23,0:6),2),":30:00",sep="")),
 "%Y-%m-%d %H:%M:%S")
# telescope the two nights into repeated hours
Hours<-strptime(format(Times,"%H:%M:%S"),"%H:%M:%S")
# get a measure that can be checked for the correct output
calls_per_hour<-sample(10:100,length(Hours))
# plot the repeated values - looks okay
plot(Hours,calls_per_hour)
# now calculate the mean values for each hourly measurement
mean_calls_per_hour<-by(calls_per_hour,as.character(Hours),mean)
# plot the means, making sure that the orders match
plot(sort(unique(Hours)),mean_calls_per_hour)

Jim


On Wed, May 13, 2015 at 1:20 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
> Try this.
>
> >From the full data-time value subtract 18:00:00.
> This places the times you are interested in into the range 00:00:00 - 12:00:00
> Remove the date from these adjusted date-time values and plot y
> against the new times.
> Take control of the tick-labels and display 18:00 - 0600 instead of
> the default 00:00 - 12:00
>
> Rich
>
> On Tue, May 12, 2015 at 10:34 AM, Bob O'Hara <rni.boh at gmail.com> wrote:
>> I'm helping colleagues with analysis of frog calls at night, and they
>> want to plot call statistics against time. This means we hit a
>> problem: we want the x-axis to start at (say) 18:00 and end at (say)
>> 06:00. I'm reluctant to use the date as well, because we have data
>> from several dates, but only want to plot against time of day.
>>
>> Here's some code to illustrate the problem (don't worry about the data
>> being outside the range of the plot: this is only for illustration).
>>
>> library(chron)
>> Times <- chron(times.=paste(c(18:23,0:9),":30:00", sep=""))
>> Thing <- rnorm(length(Times)) # just something for the y-axis
>>
>> plot(Times,Thing) # x-axis wrong
>> plot(Times,Thing, xlim=chron(times.=c("05:00:00", "18:00:00"))) # x-axis right
>> plot(Times,Thing, xlim=chron(times.=c("18:00:00", "05:00:00"))) #
>> would like this to work...
>>
>> Can anyone suggest a solution?
>>
>> Bob
>>
>> --
>> Bob O'Hara
>>
>> Biodiversity and Climate Research Centre
>> Senckenberganlage 25
>> D-60325 Frankfurt am Main,
>> Germany
>>
>> Tel: +49 69 798 40226
>> Mobile: +49 1515 888 5440
>> WWW:   http://www.bik-f.de/root/index.php?page_id=219
>> Blog: http://occamstypewriter.org/boboh/
>> Journal of Negative Results - EEB: www.jnr-eeb.org
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From timlee126 at yahoo.com  Thu May 14 02:11:50 2015
From: timlee126 at yahoo.com (Tim)
Date: Wed, 13 May 2015 17:11:50 -0700
Subject: [R] Cross correlation between two time series over nested time
	periods?
Message-ID: <1431562310.99691.YahooMailBasic@web161406.mail.bf1.yahoo.com>

Dear R users,

I have two time series


Calculate and plot cross correlation between two time series over nested time periods. Each point in either time series is for a week (not exactly a calendar week, but the first week in a calendar year always starts from Jan 1, and the other weeks in the same year follow that, and the last week of the year may contain more than 7 days but no more than 13 days).

The first time series A is stored in a compressed (.gz) text file, which looks like (each week and the corresponding time series value are separated by a comma in a line):
week,value
20060101-20060107,0
20060108-20060114,5
...
20061217-20061223,0
20061224-20061230,0
20070101-20070107,0
20070108-20070114,4
...
20150903-20150909,0
20150910-20150916,1

The second time series B is similarly stored in a compressed (.gz) text file, but over a subset of period of A, which looks like:
week,value
20130122-20130128,509
20130129-20130204,204
...
20131217-20131223,150
20131224-20131231,148.0
20140101-20140107,365.0
20140108-20140114,45.0
...
20150305-20150311,0
20150312-20150318,364

I wonder how to calculate the cross correlation between the two time series A and B (up to a specified maximum lag), and plot A and B in a single plot? 

Thanks and regards,
Tim


From bretschr at xs4all.nl  Thu May 14 12:14:06 2015
From: bretschr at xs4all.nl (Franklin Bretschneider)
Date: Thu, 14 May 2015 12:14:06 +0200
Subject: [R] Cross correlation between two time series over nested time
	periods?
In-Reply-To: <1431562310.99691.YahooMailBasic@web161406.mail.bf1.yahoo.com>
References: <1431562310.99691.YahooMailBasic@web161406.mail.bf1.yahoo.com>
Message-ID: <90A3359D-4E74-4561-AD48-26F739C0FC77@xs4all.nl>


On 2015-05-14 , at 02:11, Tim via R-help <r-help at r-project.org> wrote:


Hello Tim,


Re:


> I have two time series
> 
> 
> Calculate and plot cross correlation between two time series over nested time periods. Each point in either time series is for a week (not exactly a calendar week, but the first week in a calendar year always starts from Jan 1, and the other weeks in the same year follow that, and the last week of the year may contain more than 7 days but no more than 13 days).
> 
> The first time series A is stored in a compressed (.gz) text file, which looks like (each week and the corresponding time series value are separated by a comma in a line):
> week,value
> 20060101-20060107,0
> 20060108-20060114,5
> ...
> 20061217-20061223,0
> 20061224-20061230,0
> 20070101-20070107,0
> 20070108-20070114,4
> ...
> 20150903-20150909,0
> 20150910-20150916,1
> 
> The second time series B is similarly stored in a compressed (.gz) text file, but over a subset of period of A, which looks like:
> week,value
> 20130122-20130128,509
> 20130129-20130204,204
> ...
> 20131217-20131223,150
> 20131224-20131231,148.0
> 20140101-20140107,365.0
> 20140108-20140114,45.0
> ...
> 20150305-20150311,0
> 20150312-20150318,364
> 
> I wonder how to calculate the cross correlation between the two time series A and B (up to a specified maximum lag), and plot A and B in a single plot? 




The auto- and crosscorrelation functions are in the stats package:

acf(x, lag.max = NULL,
    type = c("correlation", "covariance", "partial"),
    plot = TRUE, na.action = na.fail, demean = TRUE, ...)

ccf(x, y, lag.max = NULL, type = c("correlation", "covariance"),
    plot = TRUE, na.action = na.fail, ...)

See further: ?ccf

Succes and
Best wishes,


Frank
---



Franklin Bretschneider
Dept of Biology
Utrecht University
bretschr at xs4all.nl


From shivibhatia at ymail.com  Thu May 14 13:35:27 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Thu, 14 May 2015 04:35:27 -0700 (PDT)
Subject: [R] Dropping predictor variables based on adjusted R square
Message-ID: <1431603327632-4707186.post@n4.nabble.com>

Hello experts,

I have recently (1month) started using R. Earlier I was using SAS to work on
analytic assignments. 
In SAS there is an option - forward selection, backward selection, step wise
selection where in it removes the least impacting predictor variable from
the set  of variables based on adjusted r square and leaves us with the
highest impacting variables to predict.
Is there any similar functionality or function in R studio. Kindly suggest.
Thanks.  



--
View this message in context: http://r.789695.n4.nabble.com/Dropping-predictor-variables-based-on-adjusted-R-square-tp4707186.html
Sent from the R help mailing list archive at Nabble.com.


From drjimlemon at gmail.com  Thu May 14 14:00:22 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 14 May 2015 22:00:22 +1000
Subject: [R] Dropping predictor variables based on adjusted R square
In-Reply-To: <1431603327632-4707186.post@n4.nabble.com>
References: <1431603327632-4707186.post@n4.nabble.com>
Message-ID: <CA+8X3fWKafeQc90-cY6E9NCAnUACvQsOsXh5RBtdL6A-Y6_YQg@mail.gmail.com>

Hi Shiv82,
For a start, look at the "step" function in the stats package. There
are a number of functions in other packages that offer different
variable selection procedures.

Jim


On Thu, May 14, 2015 at 9:35 PM, Shivi82 <shivibhatia at ymail.com> wrote:
> Hello experts,
>
> I have recently (1month) started using R. Earlier I was using SAS to work on
> analytic assignments.
> In SAS there is an option - forward selection, backward selection, step wise
> selection where in it removes the least impacting predictor variable from
> the set  of variables based on adjusted r square and leaves us with the
> highest impacting variables to predict.
> Is there any similar functionality or function in R studio. Kindly suggest.
> Thanks.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Dropping-predictor-variables-based-on-adjusted-R-square-tp4707186.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From samarvir1996 at gmail.com  Thu May 14 14:07:32 2015
From: samarvir1996 at gmail.com (samarvir singh)
Date: Thu, 14 May 2015 17:37:32 +0530
Subject: [R] Need help with lm function on MAC OS X. R version - 3.2.0
Message-ID: <CAOpgo6iks1Xh3BVZKNc8Npb_fVvforg0MA1TV6HqZRt14BsGng@mail.gmail.com>

I Have a data frame named BSE and CP is my independent variable
and here;s the error I get if I try to run an lm function
any idea whats wrong

P.S - all my data is in numeric except company which is a factor. I have
2700 row and 450 variable

P.P.S -  I have no missing data, I have 0 in Empty field.

> BSE_Reg <- lm(CP ~.-company, data = bse)
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
  contrasts can be applied only to factors with 2 or more levels

> BSE_Reg <- lm(CP ~., data = bse)
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
  contrasts can be applied only to factors with 2 or more levels
Error in as.character(tools:::httpdPort) :
  cannot coerce type 'closure' to vector of type 'character'
Error in as.character(tools:::httpdPort) :
  cannot coerce type 'closure' to vector of type 'character'
Error in as.character(tools:::httpdPort) :
  cannot coerce type 'closure' to vector of type 'character'
Error in as.character(tools:::httpdPort) :
  cannot coerce type 'closure' to vector of type 'character'





> R.Version()
$platform
[1] "x86_64-apple-darwin13.4.0"

$arch
[1] "x86_64"

$os
[1] "darwin13.4.0"

$system
[1] "x86_64, darwin13.4.0"

$status
[1] ""

$major
[1] "3"

$minor
[1] "2.0"

$year
[1] "2015"

$month
[1] "04"

$day
[1] "16"

$`svn rev`
[1] "68180"

$language
[1] "R"

$version.string
[1] "R version 3.2.0 (2015-04-16)"

$nickname
[1] "Full of Ingredients"

	[[alternative HTML version deleted]]


From abhinabaroy09 at gmail.com  Thu May 14 14:16:31 2015
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Thu, 14 May 2015 17:46:31 +0530
Subject: [R] Counting consecutive events in R
Message-ID: <CANtKHPWht-hb1eO5O5YCCqMGxC4O5omvmU-MKkNZfhsq9dEBWA@mail.gmail.com>

Hi,

I have the following dataframe

structure(list(Type = c("QRS", "QRS", "QRS", "QRS", "QRS", "QRS",
"QRS", "QRS", "QRS", "QRS", "QRS", "QRS", "RR", "RR", "RR", "PP",
"PP", "PP", "PP", "PP", "PP", "PP", "PP", "PP", "QTc", "QTc",
"QTc", "QTc", "QTc", "QTc", "QTc", "QTc", "QTc", "QTc", "QTc",
"QTc", "QTc", "QTc", "QTc"), Time_Point_Start = c("2015-04-01 14:57:15.0.0312",
"2015-04-01 14:57:15.0.7839", "2015-04-01 14:57:16.0.5343",
"2015-04-01 14:57:17.0.2573",
"2015-04-01 14:57:18.0.0234", "2015-04-01 14:57:18.0.7722",
"2015-04-01 14:57:19.0.5265",
"2015-04-01 14:57:24.0.0195", "2015-04-01 14:57:24.0.7839",
"2015-04-01 14:57:25.0.5343",
"2015-04-01 14:57:26.0.2768", "2015-04-01 14:57:27.0.0273",
"2015-04-01 14:58:03.0.0702",
"2015-04-01 14:58:03.0.8190", "2015-04-01 14:58:04.0.5694",
"2015-04-01 14:57:58.0.4134",
"2015-04-01 14:57:59.0.1637", "2015-04-01 14:57:59.0.9126",
"2015-04-01 14:58:00.0.6630",
"2015-04-01 14:58:01.0.4134", "2015-04-01 14:58:02.0.1637",
"2015-04-01 14:58:02.0.9126",
"2015-04-01 14:58:03.0.6630", "2015-04-01 14:58:04.0.4134",
"2015-04-01 14:57:07.0.4212",
"2015-04-01 14:57:08.0.1715", "2015-04-01 14:57:08.0.9204",
"2015-04-01 14:57:09.0.6864",
"2015-04-01 14:57:10.0.4368", "2015-04-01 14:57:11.0.1871",
"2015-04-01 14:57:11.0.9360",
"2015-04-01 14:57:12.0.6591", "2015-04-01 14:57:13.0.4251",
"2015-04-01 14:57:14.0.1754",
"2015-04-01 14:57:14.0.9243", "2015-04-01 14:57:15.0.6903",
"2015-04-01 14:57:16.0.4407",
"2015-04-01 14:57:17.0.1676", "2015-04-01 14:57:17.0.9321"),
    Time_Point_End = c("2015-04-01 14:57:15.0.0858", "2015-04-01
14:57:15.0.8346",
    "2015-04-01 14:57:16.0.6006", "2015-04-01 14:57:17.0.0351",
    "2015-04-01 14:57:18.0.1403", "2015-04-01 14:57:18.0.8385",
    "2015-04-01 14:57:19.0.5889", "2015-04-01 14:57:24.0.0858",
    "2015-04-01 14:57:24.0.8346", "2015-04-01 14:57:25.0.5772",
    "2015-04-01 14:57:26.0.3939", "2015-04-01 14:57:27.0.0936",
    "2015-04-01 14:58:03.0.8190", "2015-04-01 14:58:04.0.5694",
    "2015-04-01 14:58:05.0.3197", "2015-04-01 14:57:59.0.1637",
    "2015-04-01 14:57:59.0.9126", "2015-04-01 14:58:00.0.6630",
    "2015-04-01 14:58:01.0.4134", "2015-04-01 14:58:02.0.1637",
    "2015-04-01 14:58:02.0.9126", "2015-04-01 14:58:03.0.6630",
    "2015-04-01 14:58:04.0.4134", "2015-04-01 14:58:05.0.1793",
    "2015-04-01 14:57:07.0.8775", "2015-04-01 14:57:08.0.6435",
    "2015-04-01 14:57:09.0.3705", "2015-04-01 14:57:10.0.1209",
    "2015-04-01 14:57:10.0.8697", "2015-04-01 14:57:11.0.6201",
    "2015-04-01 14:57:12.0.3861", "2015-04-01 14:57:13.0.1364",
    "2015-04-01 14:57:13.0.8853", "2015-04-01 14:57:14.0.6513",
    "2015-04-01 14:57:15.0.4017", "2015-04-01 14:57:16.0.1248",
    "2015-04-01 14:57:16.0.9165", "2015-04-01 14:57:17.0.6162",
    "2015-04-01 14:57:18.0.3900"), Value = c(0.0546, 0.0507,
    0.0663, 0.0936, 0.117, 0.0663, 0.0624, 0.0663, 0.0507, 0.0429,
    0.117, 0.0663, 0.7488, 0.7488, 0.7488, 0.7488, 0.7488, 0.7488,
    0.7488, 0.7488, 0.7488, 0.7488, 0.7488, 0.7644, 0.033103481,
    0.034056449, 0.032367699, 0.031000613, 0.031405867, 0.031241866,
    0.032367699, 0.034337907, 0.033125921, 0.034337907, 0.034337907,
    0.031241866, 0.034337907, 0.032367699, 0.032930616), Score = c(0L,
    0L, 0L, 0L, 3L, 0L, 0L, 0L, 0L, 0L, 3L, 0L, 0L, 0L, 0L, 0L,
    0L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), Type_Desc = c(NA, NA, NA,
    NA, 1L, NA, NA, NA, NA, NA, 1L, NA, NA, NA, NA, NA, NA, 1L,
    1L, 1L, 1L, 1L, NA, NA, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L), Pat_id = c(4L, 4L, 4L, 4L, 4L, 4L,
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
    4L, 4L, 4L)), .Names = c("Type", "Time_Point_Start", "Time_Point_End",
"Value", "Score", "Type_Desc", "Pat_id"), class = "data.frame",
row.names = c(NA,
-39L))


For each unique value in column 'Type' , I want to check for
consecutive 5 rows (if any) of 'Score' > 0.

Now, if there are five consecutive rows with Score > 0 and 'Type_Desc'
= 0, then we print "Type_low" , else if

'Type_Desc' = 1, we print "Type_high". The search should end once 5
consecutive rows have been found.

So, for this data frame we will have two statements as follows,


1.PP_high

(reason - consecutive 5 rows of score > 0 and

'Type_Desc' = 1 )

2.QTc_low
(reason - consecutive 5 rows of score > 0 and

'Type_Desc' = 0 )

How can this problem tackled in R?

Thanks,

Abhinaba

	[[alternative HTML version deleted]]


From newrnewbie at hotmail.com  Thu May 14 16:15:51 2015
From: newrnewbie at hotmail.com (Vin Cheng)
Date: Thu, 14 May 2015 14:15:51 +0000
Subject: [R] binding two lists of lists of dataframes together
In-Reply-To: <689E9E7A-5D78-4D80-8318-F71A1138C445@comcast.net>
References: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>,
	<A2E1A0300F5.00001107jrkrideau@inbox.com>
	<BAY179-W63A3DF10922679A302B16D3DA0@phx.gbl>,
	<17C25B6B-DDF7-4108-99C9-3DABC178C32F@comcast.net>
	<BAY179-W817CF1BB2EEC863DC596F5D3DA0@phx.gbl>,
	<1084ED86-44F2-4717-9879-4A8A368FE00A@comcast.net>
	<BAY179-W41355B8D24DBDB0BEF7978D3DA0@phx.gbl>,
	<F8CE47F9-1AEE-4514-9779-61DB3AF0F019@comcast.net>
	<BAY179-W44BDA61F1D2A044E3AE646D3D90@phx.gbl>,
	<689E9E7A-5D78-4D80-8318-F71A1138C445@comcast.net>
Message-ID: <BAY179-W93AB8B2495958B1FDA948AD3D80@phx.gbl>

Hi David,
 
Understood.  I've done a lot of work around this structure, but if there isn't anyway to change it back to the original structure then I'll work around it.
 
Could you possibly show me how to add colnames to list3a?
 
c("id","WgtBand","Wgt","Held","LID","Issuer","Bid","Offer") these would be repeated once for each V1,V2,V3.
 
Thank you again for all the help!  It's much appreciated!
Vince

 
> Subject: Re: [R] binding two lists of lists of dataframes together
> From: dwinsemius at comcast.net
> Date: Wed, 13 May 2015 15:51:47 -0700
> CC: r-help at r-project.org
> To: newrnewbie at hotmail.com
> 
> 
> On May 13, 2015, at 2:01 PM, Vin Cheng wrote:
> 
> > Hi David,
> >  
> > I tried both solutions you provided(lapply(dlist, function(x) rbind(x,x) ) & Map( rbind, smaller, smaller))  and they seem to transpose and reshape the data into a different structure.  Whenever I added the str - I only get a NULL.
> 
> I believe you are misrepresenting my suggestion. I suggested that you coerce each of the items in those lists to data.frames with appropriate column names before applying rbind.data.frame
> 
> Those list1 and list2 examples appear to me as pathologically deformed. They claim to be data.tables but they have no self referential pointers, suggesting to me that they are not data.tables, and they have no column names suggesting not either data.table, nor data.frame.
> 
> > class(list1)
> [1] "data.table" "data.frame"
> > class(list2)
> [1] "data.table" "data.frame"
> 
> >  
> > > You basically want a list of the same general structure as list1 where all the elements in list two at the same position and depth have been concatenated?
> >  
> > Yes - that sounds exactly right.
> >  
> Fix up the data.structures, first. Then use Map(rbind, ...)   .... as described previously.
> 
>  list1a <- lapply(list1, function(x) setNames( data.frame(x), paste0("V", seq(length(x)) ) ) )
>  list2a <- lapply(list2, function(x) setNames( data.frame(x), paste0("V", seq(length(x)) ) ))
>  list3a <- Map( rbind.data.frame, list1a, list2a)
>  str(list3a)
> 
> List of 3
>  $ V1:'data.frame':	22 obs. of  8 variables:
>   ..$ V1: int [1:22] 15 19 28 9 17 3 11 21 7 8 ...
>   ..$ V2: num [1:22] 1 1 2 3 4 5 6 7 8 9 ...
>   ..$ V3: num [1:22] NaN NaN NA NA NA NA NA NA NA NA ...
>   ..$ V4: num [1:22] 0 0 0 0 0 0 0 0 0 0 ...
>   ..$ V5: Factor w/ 29 levels "ID1","ID10","ID11",..: 7 11 21 29 9 23 3 14 27 28 ...
>   ..$ V6: Factor w/ 29 levels "Issuer1","Issuer10",..: 7 11 21 29 9 23 3 14 27 28 ...
>   ..$ V7: num [1:22] 99.5 95.5 99.5 100 98.5 ...
>   ..$ V8: num [1:22] 0.4 0.55 0.4 0.4 0.5 0.45 0.4 0.45 0.6 0.4 ...
>  $ V2:'data.frame':	22 obs. of  8 variables:
>   ..$ V1: int [1:22] 10 29 5 19 28 3 10 12 1 21 ...
>   ..$ V2: num [1:22] 1 1 2 3 4 5 6 7 8 9 ...
>   ..$ V3: num [1:22] NaN NaN NA NA NA NA NA NA NA NA ...
>   ..$ V4: num [1:22] 0 0 0 0 0 0 0 0 0 0 ...
>   ..$ V5: Factor w/ 29 levels "ID1","ID10","ID11",..: 2 22 25 11 21 23 2 4 1 14 ...
>   ..$ V6: Factor w/ 29 levels "Issuer1","Issuer10",..: 2 22 25 11 21 23 2 4 1 14 ...
>   ..$ V7: num [1:22] 98.5 100.2 99 95.5 99.5 ...
>   ..$ V8: num [1:22] 0.6 0.4 0.45 0.55 0.4 0.45 0.6 0.55 0.5 0.45 ...
>  $ V3:'data.frame':	22 obs. of  8 variables:
>   ..$ V1: int [1:22] 21 28 3 7 25 25 15 13 3 20 ...
>   ..$ V2: num [1:22] 1 1 2 3 4 5 6 7 8 9 ...
>   ..$ V3: num [1:22] NaN NaN NA NA NA NA NA NA NA NA ...
>   ..$ V4: num [1:22] 0 0 0 0 0 0 0 0 0 0 ...
>   ..$ V5: Factor w/ 29 levels "ID1","ID10","ID11",..: 14 21 23 27 18 18 7 5 23 13 ...
>   ..$ V6: Factor w/ 29 levels "Issuer1","Issuer10",..: 14 21 23 27 18 18 7 5 23 13 ...
>   ..$ V7: num [1:22] 98 99.5 99.6 99.8 99.4 ...
>   ..$ V8: num [1:22] 0.45 0.4 0.45 0.6 0.4 0.4 0.4 0.4 0.45 0.3 ..
> 
> -- 
> David
> 
> 
> > I've created new input(list1,list2) and desired output(list3) examples below.  I hope this makes the request a lot clearer.
> >  
> > Not sure if this helpful, but I found this bit of script and it keeps V1,V2,V3 separate and keeps each set of observations as vectors, but it doesn't concatenate the v1 observations with v2 observations together.
> >  
> > sample.list <- list(list1,list2)
> > library(data.table) 
> > nr <- nrow(sample.list[[1]])
> > fastbind.ith.rows <- function(i) rbindlist(lapply(sample.list, "[", i, TRUE))
> > fastbound <- lapply(1:nr, fastbind.ith.rows)
> >  
> > Link:
> > http://stackoverflow.com/questions/4863341/fast-vectorized-merge-of-list-of-data-frames-by-row
> >  
> > Thank you again!
> > Vince
> >  
> > Please find below the structure for list1, list2, and the desired output list3:
> >  
> > list1<-structure(list(
> > V1 = list(c(15L, 19L, 28L, 9L, 17L, 3L, 11L, 21L,7L, 8L, 11L, 13L), 
> >  c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 
> >  c(NaN,NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
> >  c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> >  structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> > "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L), .Label = c("Issuer1", "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> > "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), 
> > class = "factor"), c(99.5, 95.5, 99.5, 100, 98.5, 99.646, 99.833, 98, 99.75, 100, 99.833, 98.563), c(0.4, 0.55, 0.4, 0.4, 0.5, 0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4)), 
> > V2 = list(c(10L, 29L, 5L, 19L, 28L, 3L, 10L, 12L, 1L, 21L, 23L, 25L), 
> > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 
> > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
> > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> > "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L), .Label = c("Issuer1", 
> > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", 
> > "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor")
> > , c(98.5, 100.25, 99, 95.5, 99.5, 99.646, 98.5, 94.75, 98.75, 98, 99, 99.388), c(0.6, 0.4, 0.45, 0.55, 0.4, 0.45, 0.6, 0.55, 0.5, 0.45, 0.55, 0.4)), 
> > V3 = list(c(21L, 28L, 3L, 7L, 25L, 25L, 15L, 13L, 3L, 20L, 16L, 18L), 
> > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 
> > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
> > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> > "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L), .Label = c("Issuer1", 
> > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", 
> > "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), 
> > c(98, 99.5, 99.646, 99.75, 99.388, 99.388, 99.5, 98.563, 99.646, 98, 99.563, 100.375), c(0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4, 0.4, 0.45, 0.3, 0.45, 0.5))), .Names = c("V1", 
> > "V2", "V3"), row.names = c("id", "WgtBand", "Wgt", "Held", "LoanXID", "Issuer", "Bid", "Offer"), class = c("data.table", "data.frame"))
> > list2<-structure(list(V1 = list(
> > c(15L, 8L, 2L, 21L, 8L, 2L, 23L, 25L, 20L, 4L), 
> > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > structure(c(7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> > "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("Issuer1", 
> > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", 
> > "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), c(99.5, 100, 96.969, 98, 100, 96.969, 99, 99.388, 98, 94), 
> > c(0.4, 0.4, 0.45, 0.45, 0.4, 0.45, 0.55, 0.4, 0.3, 0.45)), 
> > V2 = list(c(27L, 14L, 11L, 25L, 17L, 15L, 10L, 23L, 16L, 2L), 
> > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > structure(c(20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> > "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("Issuer1", 
> > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", 
> > "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), 
> > c(100.296, 88.5, 99.833, 99.388, 98.5, 99.5, 98.5, 99, 99.563, 96.969), c(0.4, 0.4, 0.4, 0.4, 0.5, 0.4, 0.6, 0.55, 0.45, 0.45)), 
> > V3 = list(c(13L, 26L, 5L, 17L, 5L, 28L, 2L, 16L, 1L, 19L), 
> > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > structure(c(5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 11L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", 
> > "ID24", "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 
> > 11L), .Label = c("Issuer1", "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> > "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"
> > ), class = "factor"), c(98.563, 99.229, 99, 98.5, 99, 99.5, 96.969, 99.563, 98.75, 95.5), c(0.4, 0.55, 0.45, 0.5, 0.45, 0.4, 0.45, 0.45, 0.5, 0.55))), .Names = c("V1", 
> > "V2", "V3"), row.names = c("id", "WgtBand", "Wgt", "Held", "LoanXID", "Issuer", "Bid", "Offer"), class = c("data.table", "data.frame"))
> > list3<-structure(list(
> > V1 = list(c(15L, 19L, 28L, 9L, 17L, 3L, 11L, 21L,7L, 8L, 11L, 13L,15L, 8L, 2L, 21L, 8L, 2L, 23L, 25L, 20L, 4L), 
> >  c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> >  c(NaN,NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> >  c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> >  structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L,7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> > "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L,7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("Issuer1", "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> > "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), 
> > class = "factor"), c(99.5, 95.5, 99.5, 100, 98.5, 99.646, 99.833, 98, 99.75, 100, 99.833, 98.563,99.5, 100, 96.969, 98, 100, 96.969, 99, 99.388, 98, 94), c(0.4, 0.55, 0.4, 0.4, 0.5, 0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4,0.4, 0.4, 0.45, 0.45, 0.4, 0.45, 0.55, 0.4, 0.3, 0.45)), 
> > V2 = list(c(10L, 29L, 5L, 19L, 28L, 3L, 10L, 12L, 1L, 21L, 23L, 25L,27L, 14L, 11L, 25L, 17L, 15L, 10L, 23L, 16L, 2L), 
> > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L,20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> > "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L,20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("Issuer1", 
> > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", 
> > "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor")
> > , c(98.5, 100.25, 99, 95.5, 99.5, 99.646, 98.5, 94.75, 98.75, 98, 99, 99.388,100.296, 88.5, 99.833, 99.388, 98.5, 99.5, 98.5, 99, 99.563, 96.969), c(0.6, 0.4, 0.45, 0.55, 0.4, 0.45, 0.6, 0.55, 0.5, 0.45, 0.55, 0.4,0.4, 0.4, 0.4, 0.4, 0.5, 0.4, 0.6, 0.55, 0.45, 0.45)), 
> > V3 = list(c(21L, 28L, 3L, 7L, 25L, 25L, 15L, 13L, 3L, 20L, 16L, 18L,13L, 26L, 5L, 17L, 5L, 28L, 2L, 16L, 1L, 19L), 
> > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L,5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 11L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> > "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L,5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 11L), .Label = c("Issuer1", 
> > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", 
> > "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), 
> > c(98, 99.5, 99.646, 99.75, 99.388, 99.388, 99.5, 98.563, 99.646, 98, 99.563, 100.375,98.563, 99.229, 99, 98.5, 99, 99.5, 96.969, 99.563, 98.75, 95.5), c(0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4, 0.4, 0.45, 0.3, 0.45, 0.5,0.4, 0.55, 0.45, 0.5, 0.45, 0.4, 0.45, 0.45, 0.5, 0.55))), .Names = c("V1", 
> > "V2", "V3"), row.names = c("id", "WgtBand", "Wgt", "Held", "LoanXID", "Issuer", "Bid", "Offer"), class = c("data.table", "data.frame"))
> >  
> >  
> >  
> > > Subject: Re: [R] binding two lists of lists of dataframes together
> > > From: dwinsemius at comcast.net
> > > Date: Tue, 12 May 2015 16:00:05 -0700
> > > CC: r-help at r-project.org
> > > To: newrnewbie at hotmail.com
> > > 
> > > 
> > > On May 12, 2015, at 3:12 PM, Vin Cheng wrote:
> > > 
> > > > Hi David,
> > > > 
> > > > Would it be possible to modify it a little so that I can keep V1, V2, and V3 intact?
> > > 
> > > 
> > > > 
> > > > I also don't quite know where to put list2 in the solution you provided below? list2 can be an exact copy of list1 for this example.
> > > 
> > > In which case it would be nearly trivial:
> > > 
> > > lapply(dlist, function(x) rbind(x,x) ) 
> > > 
> > > str( lapply(dlist, function(x) rbind(x,x) ) )
> > > List of 3
> > > $ V1:'data.frame':	20 obs. of 48 variables:
> > > ..$ V1 : int [1:20] 19 94 94 15 90 13 66 17 45 69 ...
> > > ..$ V2 : num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
> > > ..$ V3 : num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
> > > ..$ V4 : num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> > > snipped.....
> > > 
> > > > 
> > > > list1 has (48 observations of 3 variables(V1, V2,V3)) each observation has 10 values in a vector 
> > > > list2 has (48 observations of 3 variables (V1, V2,V3)) each observation has 10 values in a vector 
> > > 
> > > You basically want a list of the same general structure as list1 where all the elements in list two at the same position and depth have been concatenated?
> > > > 
> > > > Output should ideally have (48 observations of 3 variables (V1, V2,V3)) each observation has 20 values in a vector
> > > > list1 V1 stacks with list2 V1, 
> > > > list1 V2 stacks with list2 V2, 
> > > > list1 V3 stacks with list2 V3
> > > 
> > > You had a bunch of factor variables in list1. Are we assured that the levels of any factor variables in list2 are the same as the corresponding factor variables in list 1?
> > > 
> > > > 
> > > > Boundlist seems to break out the values of each variable(V1,V2,V3) into 10 columns with 1 value in each column.
> > > 
> > > Not the way I use those words after using R for the last 8 years. There were 48 "columns" and 10 positions in each. I think you need to reverse your terminology (columns and rows) since a "column" in a dataframe is a list and the row numbers are the relative positions along vectors.
> > > 
> > > 
> > > > Is it possible to put the values in the 10 columns(20 values in ideal output) into a vector for each of the 48 observation in each variable(V1,V2,V3).
> > > 
> > > Having severe trouble reformulating this in R dataframe terminology.
> > > 
> > > > 
> > > > Sorry for all the back and forth - explaining an exact output over email is difficult.
> > > 
> > > It shouldn't be difficult if you would post data examples with sufficient complexity to represent the problem. I will build a smaller list of dataframe and name it 'smaller'
> > > 
> > > Since I had difficulty with mapply I'm switching to the list version named ?Map found in the ?funprog page:
> > > 
> > > smaller <- lapply(dlist, "[", 1:6)
> > > 
> > > ?Map
> > > str( Map( rbind, smaller, smaller))
> > > 
> > > #------I think this is what you might want----------
> > > List of 3
> > > $ V1:'data.frame':	20 obs. of 6 variables:
> > > ..$ V1: int [1:20] 19 94 94 15 90 13 66 17 45 69 ...
> > > ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
> > > ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
> > > ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> > > ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 12 95 95 8 91 6 64 10 41 67 ...
> > > ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 12 95 95 8 91 6 64 10 41 67 ...
> > > $ V2:'data.frame':	20 obs. of 6 variables:
> > > ..$ V1: int [1:20] 93 3 85 34 20 89 16 25 83 90 ...
> > > ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
> > > ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
> > > ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> > > ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 94 24 85 29 14 89 9 19 83 91 ...
> > > ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 94 24 85 29 14 89 9 19 83 91 ...
> > > $ V3:'data.frame':	20 obs. of 6 variables:
> > > ..$ V1: int [1:20] 47 95 26 64 16 55 61 39 23 66 ...
> > > ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
> > > ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
> > > ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> > > ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 43 96 20 62 9 52 59 34 17 64 ...
> > > ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 43 96 20 62 9 52 59 34 17 64 ...
> > > 
> > > > 
> > > > I really appreciate the help and the effort! 
> > > > 
> > > > Thank you again!
> > > > Vince
> > > > 
> > > > > Subject: Re: [R] binding two lists of lists of dataframes together
> > > > > From: dwinsemius at comcast.net
> > > > > Date: Tue, 12 May 2015 14:23:54 -0700
> > > > > CC: r-help at r-project.org
> > > > > To: newrnewbie at hotmail.com
> > > > > 
> > > > > 
> > > > > On May 12, 2015, at 12:56 PM, Vin Cheng wrote:
> > > > > 
> > > > > > Hi,
> > > > > > 
> > > > > > Thanks David! Your solution 3 worked well with the sample data, but when I run solution 2 & 3 on the actual data - it creates a list of 1 for each data point and it doesn't end up looking like the desired output for some reason.
> > > > > > 
> > > > > > I've run a dput on the actual data and pasted below. There's a lot of data - so I'm only copying list1 - if the solution could bind list1 with itself - it should work just as well. 
> > > > > > 
> > > > > > Sorry for not providing an accurate sample the first time around - I thought the shortened version would be simpler and sufficient.
> > > > > > 
> > > > > > Any help/guidance would be greatly appreciated!
> > > > > > 
> > > > > 
> > > > > This appears to be three similarly structured lists of various classes but fortunately for this effort the factor variables in corresponding columns all have the same levels. (Otherwise one would need to convert to character before attempting to stack them.)
> > > > > 
> > > > > I would just use `rbind.data.frame` (after making them dataframes with the same column names.)
> > > > > 
> > > > > 
> > > > > dlist <- lapply( list1, function(d) setNames( data.frame(d), paste0("V", 1:48) ))
> > > > > boundlist <- do.call(rbind, dlist)
> > > > > 
> > > > > # Done.
> > > > > 
> > > > > -- 
> > > > > David.
> > > > > > Many Thanks,
> > > > > > Vince
> > > > > > 
> > > > > > list1 <- structure(list(V1 = list(c(19L, 94L, 94L, 15L, 90L, 13L, 66L, 
> > > > > > 17L, 45L, 69L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, 
> > > > > > NA, NA, NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 
> > > > > > 0), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
> > > > > > ), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", "ID13", 
> > > > > > "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", 
> > > > > > "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", "ID27", "ID28", 
> > > > > > "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", "ID34", "ID35", 
> > > > > > "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", "ID41", "ID42", 
> > > > > > "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", 
> > > > > > "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
> > > > > > "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", "ID64", 
> > > > > > "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", "ID70", "ID71", 
> > > > > > "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", "ID78", "ID79", 
> > > > > > "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", "ID85", "ID86", 
> > > > > > "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", "ID92", "ID93", 
> > > > > > "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"), class = "factor"), 
> > > > > > structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
> > > > > > ), .Label = c("Issuer1", "Issuer10", "Issuer100", "Issuer11", 
> > > > > > "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
> > > > > > "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", 
> > > > > > "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", 
> > > > > > "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", 
> > > > > > "Issuer30", "Issuer31", "Issuer32", "Issuer33", "Issuer34", 
> > > > > > "Issuer35", "Issuer36", "Issuer37", "Issuer38", "Issuer39", 
> > > > > > "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
> > > > > > "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", 
> > > > > > "Issuer49", "Issuer5", "Issuer50", "Issuer51", "Issuer52", 
> > > > > > "Issuer53", "Issuer54", "Issuer55", "Issuer56", "Issuer57", 
> > > > > > "Issuer58", "Issuer59", "Issuer6", "Issuer60", "Issuer61", 
> > > > > > "Issuer62", "Issuer63", "Issuer64", "Issuer65", "Issuer66", 
> > > > > > "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
> > > > > > "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", 
> > > > > > "Issuer76", "Issuer77", "Issuer78", "Issuer79", "Issuer8", 
> > > > > > "Issuer80", "Issuer81", "Issuer82", "Issuer83", "Issuer84", 
> > > > > > "Issuer85", "Issuer86", "Issuer87", "Issuer88", "Issuer89", 
> > > > > > "Issuer9", "Issuer90", "Issuer91", "Issuer92", "Issuer93", 
> > > > > > "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
> > > > > > "Issuer99"), class = "factor"), c(95.5, 98.5, 98.5, 99.5, 
> > > > > > 103.5, 98.563, 99.75, 98.5, 98.75, 99.125), c(97.5, 99.5, 
> > > > > > 99.5, 100.375, 104.5, 99.188, 100.25, 99.5, 99.75, 100.063
> > > > > > ), c(2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 4L), c(4L, 5L, 5L, 
> > > > > > 5L, 5L, 2L, 3L, 5L, 3L, 2L), c(TRUE, FALSE, FALSE, TRUE, 
> > > > > > FALSE, TRUE, TRUE, FALSE, FALSE, TRUE), structure(c(1L, 1L, 
> > > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > structure(c(9L, 2L, 2L, 1L, 2L, 1L, 3L, 3L, 5L, 9L), .Label = c("B", 
> > > > > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
> > > > > > ), class = "factor"), structure(c(8L, 2L, 2L, 1L, 8L, 2L, 
> > > > > > 2L, 2L, 1L, 7L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
> > > > > > "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(20L, 
> > > > > > 88L, 88L, 6L, 3L, 35L, 29L, 24L, 53L, 82L), .Label = c("1/11/2019", 
> > > > > > "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
> > > > > > "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > > > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
> > > > > > "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
> > > > > > "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
> > > > > > "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
> > > > > > "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
> > > > > > "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
> > > > > > "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
> > > > > > "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
> > > > > > "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
> > > > > > "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
> > > > > > "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
> > > > > > "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
> > > > > > "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
> > > > > > "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
> > > > > > "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
> > > > > > "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
> > > > > > "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
> > > > > > c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > > > > FALSE, FALSE), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 
> > > > > > 10L, 41L, 67L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > > > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > > > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > > > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > > > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > > > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > > > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > > > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > > > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > > > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > > > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > > > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > > > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > > > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > > > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > > > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > > > > "Issuer98", "Issuer99"), class = "factor"), structure(c(12L, 
> > > > > > 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L), .Label = c("BL1", 
> > > > > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > > > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
> > > > > > "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
> > > > > > "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
> > > > > > "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
> > > > > > "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
> > > > > > "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
> > > > > > "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > > > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
> > > > > > "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
> > > > > > "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
> > > > > > "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
> > > > > > "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(4L, 
> > > > > > 3L, 3L, 5L, 6L, 3L, 2L, 6L, 6L, 5L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > > > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > > > > "Retail", "Services: Business"), class = "factor"), structure(c(3L, 
> > > > > > 5L, 5L, 6L, 4L, 3L, 4L, 2L, 6L, 6L), .Label = c("Financial Intermediaries", 
> > > > > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > > > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > > > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 6L, 8L, 8L), .Label = c("AU", 
> > > > > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > > > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 5L, 6L, 6L), .Label = c("1", 
> > > > > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > > > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L), .Label = c("Canada", 
> > > > > > "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
> > > > > > 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > > > > structure(c(2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > > > > "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > > > 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > > > > c(0.125550168, 1.731733265, 1.731733265, NA, 5.246485518, 
> > > > > > 7.798802147, NA, NA, NA, NA), c(4770L, 3490L, 3490L, 3490L, 
> > > > > > 3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.45, 0.4, 0.4, 
> > > > > > 0.45, 0.55, 0.4, 0.4, 0.45, 0.4, 0.5), c(4770L, 3490L, 3490L, 
> > > > > > 3490L, 3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.55, 
> > > > > > 0.4, 0.4, 0.4, 0.55, 0.4, 0.5, 0.5, 0.45, 0.55), c(18L, 15L, 
> > > > > > 15L, 15L, 18L, 15L, 15L, 15L, 14L, 17L), c(17L, 16L, 16L, 
> > > > > > 15L, 14L, 15L, 15L, 15L, 14L, 15L), c(192500000, 205000000, 
> > > > > > 205000000, 342000000, 120000000, 835000000, 1043700000, 160000000, 
> > > > > > 300000000, 265000000), c(0.02, 0.02, 0.02, 0.4, 0.02, 0.4, 
> > > > > > 0.6, 0.6, 0.6, 0.02), c(850L, 475L, 475L, 500L, 1000L, 350L, 
> > > > > > 400L, 975L, 500L, 700L), c(1, 1.5, 1.5, 1, 1.25, 1, 1, 1, 
> > > > > > 1, 1), c(0.0851, 0.04765, 0.04765, 0.0501, 0.100125, 0.0351, 
> > > > > > 0.0401, 0.0976, 0.0501, 0.0701), c(0.099192999, 0.023321348, 
> > > > > > 0.023321348, 0.06465519, 0.103470278, 0.052237196, 0.051331755, 
> > > > > > 0.112300026, 0.066116739, 0.084107871), c(897.0917677, -1.49365213, 
> > > > > > -1.49365213, 549.0886934, 975.9481504, 429.1863229, 436.2991366, 
> > > > > > 1062.374805, 567.0741295, 747.1023728), c(0.088186528, 0.048131313, 
> > > > > > 0.048131313, 0.050131332, 0.096274038, 0.035499188, 0.040049938, 
> > > > > > 0.098585859, 0.050478589, 0.070385766), c(0L, 0L, 0L, 0L, 
> > > > > > 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > > > 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
> > > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > > > > c(0.0178406708595388, 0.0136532951289398, 0.0136532951289398, 
> > > > > > 0.0143553008595989, 0.028689111747851, 0.0100573065902579, 
> > > > > > 0.0180630630630631, 0.043963963963964, 0.0225675675675676, 
> > > > > > 0.0200859598853868), c(0.046805, 0.01906, 0.01906, 0.02004, 
> > > > > > 0.05506875, 0.01404, 0.02005, 0.0488, 0.022545, 0.038555), 
> > > > > > c(0.001702, 0.000953, 0.000953, 0.02004, 0.0020025, 0.01404, 
> > > > > > 0.02406, 0.05856, 0.03006, 0.001402)), V2 = list(c(93L, 3L, 
> > > > > > 85L, 34L, 20L, 89L, 16L, 25L, 83L, 90L), c(1, 1, 2, 3, 4, 5, 
> > > > > > 6, 7, 8, 9), c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), c(0, 
> > > > > > 0, 0, 0, 0, 0, 0, 0, 0, 0), structure(c(94L, 24L, 85L, 29L, 14L, 
> > > > > > 89L, 9L, 19L, 83L, 91L), .Label = c("ID1", "ID10", "ID100", "ID11", 
> > > > > > "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
> > > > > > "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> > > > > > "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", 
> > > > > > "ID34", "ID35", "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", 
> > > > > > "ID41", "ID42", "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", 
> > > > > > "ID49", "ID5", "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", 
> > > > > > "ID56", "ID57", "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", 
> > > > > > "ID63", "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
> > > > > > "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", 
> > > > > > "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", 
> > > > > > "ID85", "ID86", "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", 
> > > > > > "ID92", "ID93", "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"
> > > > > > ), class = "factor"), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
> > > > > > 9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
> > > > > > "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> > > > > > "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
> > > > > > "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", "Issuer32", 
> > > > > > "Issuer33", "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
> > > > > > "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", "Issuer49", 
> > > > > > "Issuer5", "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
> > > > > > "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", "Issuer6", 
> > > > > > "Issuer60", "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
> > > > > > "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", "Issuer76", 
> > > > > > "Issuer77", "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
> > > > > > "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", "Issuer87", 
> > > > > > "Issuer88", "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
> > > > > > "Issuer99"), class = "factor"), c(99.5, 99.646, 100.402, 100.25, 
> > > > > > 98, 99.563, 99.563, 99.388, 99.531, 103.5), c(100.5, 100.271, 
> > > > > > 100.903, 100.75, 99, 100.188, 100.063, 99.788, 100.125, 104.5
> > > > > > ), c(1L, 6L, 9L, 1L, 1L, 2L, 2L, 10L, 4L, 2L), c(5L, 2L, 1L, 
> > > > > > 3L, 3L, 4L, 4L, 1L, 1L, 5L), c(TRUE, TRUE, FALSE, FALSE, TRUE, 
> > > > > > FALSE, FALSE, TRUE, TRUE, FALSE), structure(c(1L, 1L, 1L, 1L, 
> > > > > > 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > structure(c(8L, 1L, 4L, 1L, 3L, 4L, 6L, 1L, 5L, 2L), .Label = c("B", 
> > > > > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
> > > > > > ), class = "factor"), structure(c(7L, 2L, 5L, 2L, 1L, 2L, 
> > > > > > 6L, 1L, 5L, 8L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
> > > > > > "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(41L, 
> > > > > > 1L, 13L, 43L, 21L, 87L, 49L, 73L, 46L, 3L), .Label = c("1/11/2019", 
> > > > > > "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
> > > > > > "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > > > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
> > > > > > "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
> > > > > > "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
> > > > > > "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
> > > > > > "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
> > > > > > "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
> > > > > > "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
> > > > > > "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
> > > > > > "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
> > > > > > "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
> > > > > > "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
> > > > > > "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
> > > > > > "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
> > > > > > "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
> > > > > > "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
> > > > > > "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
> > > > > > "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
> > > > > > c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > > > > FALSE, FALSE), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
> > > > > > 9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > > > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > > > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > > > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > > > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > > > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > > > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > > > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > > > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > > > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > > > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > > > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > > > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > > > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > > > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > > > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > > > > "Issuer98", "Issuer99"), class = "factor"), structure(c(94L, 
> > > > > > 24L, 85L, 29L, 14L, 89L, 9L, 19L, 83L, 91L), .Label = c("BL1", 
> > > > > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > > > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
> > > > > > "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
> > > > > > "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
> > > > > > "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
> > > > > > "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
> > > > > > "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
> > > > > > "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > > > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
> > > > > > "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
> > > > > > "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
> > > > > > "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
> > > > > > "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(2L, 
> > > > > > 2L, 3L, 6L, 1L, 6L, 6L, 6L, 1L, 6L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > > > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > > > > "Retail", "Services: Business"), class = "factor"), structure(c(6L, 
> > > > > > 6L, 3L, 5L, 1L, 2L, 5L, 3L, 2L, 4L), .Label = c("Financial Intermediaries", 
> > > > > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > > > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > > > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L), .Label = c("AU", 
> > > > > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > > > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label = c("1", 
> > > > > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > > > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("Canada", 
> > > > > > "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
> > > > > > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > > > > structure(c(2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > > > > "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > > > 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > > > > c(2.603554841, 7.27032758, 3.155438813, 5.037267081, 0.125550168, 
> > > > > > NA, 3.464301168, NA, 4.816376964, 5.246485518), c(2220L, 
> > > > > > 2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 2220L, 3490L
> > > > > > ), c(0.55, 0.45, 0.5, 0.4, 0.6, 0.45, 0.45, 0.55, 0.2, 0.55
> > > > > > ), c(2220L, 2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 
> > > > > > 2220L, 3490L), c(0.55, 0.45, 0.5, 0.4, 0.3, 0.45, 0.45, 0.4, 
> > > > > > 0.2, 0.55), c(17L, 15L, 12L, 15L, 14L, 15L, 13L, 14L, 12L, 
> > > > > > 18L), c(16L, 16L, 14L, 16L, 15L, 12L, 13L, 15L, 14L, 14L), 
> > > > > > c(200000000, 613811406, 750000000, 200000000, 405500000, 
> > > > > > 450000000, 530000000, 2010000000, 775000000, 120000000), 
> > > > > > c(0.02, 0.5, 0.65, 0.27, 0.5, 0.65, 0.65, 0.3, 0.65, 0.02
> > > > > > ), c(950L, 350L, 350L, 275L, 450L, 275L, 225L, 325L, 275L, 
> > > > > > 1000L), c(1.25, 1, 0.75, 0.75, 1, 0.75, 0, 1, 0.75, 1.25), 
> > > > > > c(0.095125, 0.0351, 0.035075, 0.027575, 0.0451, 0.027575, 
> > > > > > 0.02527, 0.0326, 0.027575, 0.100125), c(0.104211455, 0.046414939, 
> > > > > > 0.050338657, 0.027233401, 0.059885473, 0.03459045, 0.028669191, 
> > > > > > 0.048294163, 0.040935438, 0.103470278), c(980.5501911, 400.3544693, 
> > > > > > 385.8629241, 244.6340073, 511.2711809, 294.3073789, 194.2034583, 
> > > > > > 385.9437059, 308.4324006, 975.9481504), c(0.095125, 0.035114573, 
> > > > > > 0.034847619, 0.027437811, 0.045786802, 0.027609374, 0.025317343, 
> > > > > > 0.032734868, 0.027622511, 0.096274038), c(0L, 0L, 0L, 0L, 
> > > > > > 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > > > 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
> > > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > > > > c(0.0428490990990991, 0.0158108108108108, 0.037313829787234, 
> > > > > > 0.00790114613180516, 0.00945492662473794, 0.0124211711711712, 
> > > > > > 0.0143091732729332, 0.00934097421203438, 0.0124211711711712, 
> > > > > > 0.028689111747851), c(0.05231875, 0.015795, 0.0175375, 0.01103, 
> > > > > > 0.01353, 0.01240875, 0.0113715, 0.01304, 0.005515, 0.05506875
> > > > > > ), c(0.0019025, 0.01755, 0.02279875, 0.00744525, 0.02255, 
> > > > > > 0.01792375, 0.0164255, 0.00978, 0.01792375, 0.0020025)), 
> > > > > > V3 = list(c(47L, 95L, 26L, 64L, 16L, 55L, 61L, 39L, 23L, 
> > > > > > 66L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, NA, NA, 
> > > > > > NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > > > > structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 
> > > > > > 64L), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", 
> > > > > > "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
> > > > > > "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", 
> > > > > > "ID26", "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", 
> > > > > > "ID32", "ID33", "ID34", "ID35", "ID36", "ID37", "ID38", 
> > > > > > "ID39", "ID4", "ID40", "ID41", "ID42", "ID43", "ID44", 
> > > > > > "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", "ID50", 
> > > > > > "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
> > > > > > "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", 
> > > > > > "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
> > > > > > "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", 
> > > > > > "ID77", "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", 
> > > > > > "ID83", "ID84", "ID85", "ID86", "ID87", "ID88", "ID89", 
> > > > > > "ID9", "ID90", "ID91", "ID92", "ID93", "ID94", "ID95", 
> > > > > > "ID96", "ID97", "ID98", "ID99"), class = "factor"), structure(c(43L, 
> > > > > > 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("Issuer1", 
> > > > > > "Issuer10", "Issuer100", "Issuer11", "Issuer12", "Issuer13", 
> > > > > > "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", 
> > > > > > "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", 
> > > > > > "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
> > > > > > "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", 
> > > > > > "Issuer32", "Issuer33", "Issuer34", "Issuer35", "Issuer36", 
> > > > > > "Issuer37", "Issuer38", "Issuer39", "Issuer4", "Issuer40", 
> > > > > > "Issuer41", "Issuer42", "Issuer43", "Issuer44", "Issuer45", 
> > > > > > "Issuer46", "Issuer47", "Issuer48", "Issuer49", "Issuer5", 
> > > > > > "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
> > > > > > "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", 
> > > > > > "Issuer6", "Issuer60", "Issuer61", "Issuer62", "Issuer63", 
> > > > > > "Issuer64", "Issuer65", "Issuer66", "Issuer67", "Issuer68", 
> > > > > > "Issuer69", "Issuer7", "Issuer70", "Issuer71", "Issuer72", 
> > > > > > "Issuer73", "Issuer74", "Issuer75", "Issuer76", "Issuer77", 
> > > > > > "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
> > > > > > "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", 
> > > > > > "Issuer87", "Issuer88", "Issuer89", "Issuer9", "Issuer90", 
> > > > > > "Issuer91", "Issuer92", "Issuer93", "Issuer94", "Issuer95", 
> > > > > > "Issuer96", "Issuer97", "Issuer98", "Issuer99"), class = "factor"), 
> > > > > > c(99.688, 75.667, 99.229, 99.583, 99.563, 99.188, 98.8, 
> > > > > > 98.5, 99, 99.75), c(100.281, 78.667, 100.104, 100.333, 
> > > > > > 100.063, 99.906, 99.75, 99.5, 99.75, 100.25), c(4L, 3L, 
> > > > > > 6L, 3L, 2L, 4L, 5L, 1L, 1L, 1L), c(4L, 3L, 1L, 3L, 4L, 
> > > > > > 2L, 4L, 5L, 3L, 3L), c(FALSE, TRUE, TRUE, TRUE, FALSE, 
> > > > > > TRUE, TRUE, FALSE, TRUE, TRUE), structure(c(1L, 1L, 1L, 
> > > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > structure(c(3L, 8L, 9L, 1L, 6L, 3L, 10L, 10L, 9L, 3L), .Label = c("B", 
> > > > > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", 
> > > > > > "NR"), class = "factor"), structure(c(6L, 7L, 7L, 2L, 
> > > > > > 6L, 1L, 9L, 9L, 8L, 2L), .Label = c("B1", "B2", "B3", 
> > > > > > "Ba1", "Ba2", "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), 
> > > > > > structure(c(66L, 80L, 74L, 30L, 49L, 72L, 70L, 62L, 10L, 
> > > > > > 29L), .Label = c("1/11/2019", "1/2/2019", "1/2/2020", 
> > > > > > "1/30/2022", "10/15/2016", "10/15/2021", "10/17/2019", 
> > > > > > "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > > > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", 
> > > > > > "11/12/2020", "11/20/2019", "11/20/2020", "11/27/2020", 
> > > > > > "11/5/2021", "11/6/2020", "11/9/2017", "11/9/2018", "12/15/2018", 
> > > > > > "12/15/2021", "12/15/2022", "12/16/2019", "12/18/2020", 
> > > > > > "12/20/2019", "12/7/2018", "12/7/2019", "2/12/2021", 
> > > > > > "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", "2/24/2017", 
> > > > > > "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", "3/21/2019", 
> > > > > > "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", "4/30/2018", 
> > > > > > "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", "5/15/2018", 
> > > > > > "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", "5/8/2020", 
> > > > > > "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", "6/2/2019", 
> > > > > > "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", "6/30/2017", 
> > > > > > "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", "7/10/2020", 
> > > > > > "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", "7/29/2022", 
> > > > > > "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", "8/12/2021", 
> > > > > > "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", "8/24/2017", 
> > > > > > "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", "9/18/2016", 
> > > > > > "9/18/2019", "9/20/2019"), class = "factor"), c(FALSE, 
> > > > > > FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > > > > FALSE), structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 
> > > > > > 34L, 17L, 64L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > > > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > > > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > > > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > > > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > > > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > > > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > > > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > > > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > > > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > > > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > > > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > > > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > > > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > > > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > > > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > > > > "Issuer98", "Issuer99"), class = "factor"), structure(c(43L, 
> > > > > > 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("BL1", 
> > > > > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > > > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", 
> > > > > > "BL22", "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", 
> > > > > > "BL29", "BL3", "BL30", "BL31", "BL32", "BL33", "BL34", 
> > > > > > "BL35", "BL36", "BL37", "BL38", "BL39", "BL4", "BL40", 
> > > > > > "BL41", "BL42", "BL43", "BL44", "BL45", "BL46", "BL47", 
> > > > > > "BL48", "BL49", "BL5", "BL50", "BL51", "BL52", "BL53", 
> > > > > > "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", "BL6", 
> > > > > > "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > > > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", 
> > > > > > "BL73", "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", 
> > > > > > "BL8", "BL80", "BL81", "BL82", "BL83", "BL84", "BL85", 
> > > > > > "BL86", "BL87", "BL88", "BL89", "BL9", "BL90", "BL91", 
> > > > > > "BL92", "BL93", "BL94", "BL95", "BL96", "BL97", "BL98", 
> > > > > > "BL99"), class = "factor"), structure(c(1L, 6L, 6L, 4L, 
> > > > > > 6L, 4L, 6L, 2L, 6L, 2L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > > > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > > > > "Retail", "Services: Business"), class = "factor"), structure(c(2L, 
> > > > > > 2L, 1L, 5L, 5L, 3L, 3L, 6L, 2L, 4L), .Label = c("Financial Intermediaries", 
> > > > > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > > > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > > > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 5L, 8L, 8L, 8L), .Label = c("AU", 
> > > > > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > > > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 3L, 6L, 6L, 6L), .Label = c("1", 
> > > > > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > > > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L, 4L), .Label = c("Canada", 
> > > > > > "Europe", "Other", "U.S."), class = "factor"), structure(c(2L, 
> > > > > > 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > > > > "Y"), class = "factor"), structure(c(1L, 2L, 2L, 1L, 
> > > > > > 1L, 1L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > > > > c(8.74248921, NA, NA, 4.338507174, 3.464301168, NA, NA, 
> > > > > > NA, NA, NA), c(2220L, 2220L, 3490L, 3490L, 1766L, 2220L, 
> > > > > > 8070L, 8070L, 3490L, 2220L), c(0.6, 0.55, 0.4, 0.4, 0.45, 
> > > > > > 0.45, 0.4, 0.45, 0.6, 0.4), c(2220L, 2220L, 3490L, 3490L, 
> > > > > > 1766L, 2220L, 8070L, 8070L, 3490L, 2220L), c(0.3, 0.55, 
> > > > > > 0.55, 0.4, 0.45, 0.4, 0.45, 0.3, 0.55, 0.5), c(13L, 17L, 
> > > > > > 17L, 15L, 13L, 14L, 19L, 19L, 18L, 15L), c(15L, 16L, 
> > > > > > 15L, 15L, 13L, 14L, 19L, 19L, 15L, 15L), c(625000000, 
> > > > > > 450000000, 760000000, 630000000, 530000000, 671500000, 
> > > > > > 240000000, 100000000, 375000000, 1043700000), c(0.5, 
> > > > > > 0.02, 0.02, 0.3, 0.65, 0.3, 0.5, 0.65, 0.02, 0.6), c(275L, 
> > > > > > 750L, 650L, 300L, 225L, 300L, 700L, 925L, 825L, 400L), 
> > > > > > c(0, 1, 1, 1.25, 0, 1, 1, 1.25, 1.25, 1), c(0.03027, 
> > > > > > 0.0751, 0.0651, 0.030125, 0.02527, 0.0301, 0.0701, 0.092625, 
> > > > > > 0.082625, 0.0401), c(0.031286195, 0.154827358, 0.080695261, 
> > > > > > 0.041683558, 0.028669191, 0.044131997, 0.084009559, 0.108958135, 
> > > > > > 0.090916682, 0.051331755), c(263.290277, 1448.101305, 
> > > > > > 704.3633733, 368.0708419, 194.2034583, 356.3784942, 746.772345, 
> > > > > > 1036.334285, 875.917553, 436.2991366), c(0.030274693, 
> > > > > > 0.097321394, 0.065317835, 0.030137658, 0.025317343, 0.030236973, 
> > > > > > 0.070611937, 0.093560606, 0.083144654, 0.040049938), 
> > > > > > c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 
> > > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), 
> > > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > > > > c(0.0136351351351351, 0.0338288288288288, 0.0186532951289398, 
> > > > > > 0.00863180515759312, 0.0143091732729332, 0.0135585585585586, 
> > > > > > 0.00868649318463445, 0.0114776951672862, 0.0236747851002865, 
> > > > > > 0.0180630630630631), c(0.009081, 0.041305, 0.035805, 
> > > > > > 0.01205, 0.0113715, 0.01204, 0.031545, 0.0277875, 0.04544375, 
> > > > > > 0.02005), c(0.015135, 0.001502, 0.001302, 0.0090375, 
> > > > > > 0.0164255, 0.00903, 0.03505, 0.06020625, 0.0016525, 0.02406
> > > > > > ))), .Names = c("V1", "V2", "V3"), row.names = c(NA, 
> > > > > > -48L), class = c("data.table", "data.frame"))
> > > > > > 
> > > > > > 
> > > > > > 
> > > > > >> Subject: Re: [R] binding two lists of lists of dataframes together
> > > > > >> From: dwinsemius at comcast.net
> > > > > >> Date: Tue, 12 May 2015 11:36:50 -0700
> > > > > >> CC: r-help at r-project.org
> > > > > >> To: newrnewbie at hotmail.com
> > > > > >> 
> > > > > >> 
> > > > > >> On May 12, 2015, at 9:24 AM, Vin Cheng wrote:
> > > > > >> 
> > > > > >>> list1<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L), 
> > > > > >>> WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > >>> structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
> > > > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
> > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > >>> structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
> > > > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
> > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > > > > >>> .Names = c("id", "WgtBand", "Wgt")))
> > > > > >>> 
> > > > > >>> 
> > > > > >>> list2<-list(structure(list(id = c(493L, 564L, 147L), 
> > > > > >>> WgtBand = c(1, 2, 3), 
> > > > > >>> Wgt = c(NaN, NaN, NA)), 
> > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > >>> structure(list(id = c(276L, 411L, 574L,111L), 
> > > > > >>> WgtBand = c(1, 2, 3,4), 
> > > > > >>> Wgt = c(NaN, NaN, NA,NA)), 
> > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > >>> structure(list(id = c(76L, 330L), 
> > > > > >>> WgtBand = c(1, 1), 
> > > > > >>> Wgt = c(NaN, NaN)), 
> > > > > >>> .Names = c("id", "WgtBand", "Wgt")))
> > > > > >>> 
> > > > > >>> list3<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L,493L, 564L, 147L), 
> > > > > >>> WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9,1, 2, 3), 
> > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA)), 
> > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > >>> structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,276L, 411L, 574L,111L), 
> > > > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 2, 3,4), 
> > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA,NA)), 
> > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > >>> structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,76L, 330L), 
> > > > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 1), 
> > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN)), 
> > > > > >>> .Names = c("id", "WgtBand", "Wgt")))
> > > > > >> 
> > > > > >> I get something like the desired structure with:
> > > > > >> 
> > > > > >> mapply(function(x,y) mapply(c, x,y), list1,list2)
> > > > > >> 
> > > > > >> I can make it closer with:
> > > > > >> 
> > > > > >> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) unclass( as.data.frame(x) ) )
> > > > > >> 
> > > > > >> 
> > > > > >> Or even closer with:
> > > > > >> 
> > > > > >> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) as.list( as.data.frame(x) ) )
> > > > > >> 
> > > > > >> `identical` does not return TRUE but I cannot see where the difference lies.
> > > > > >> 
> > > > > >> -- 
> > > > > >> 
> > > > > >> David Winsemius
> > > > > >> Alameda, CA, USA
> > > > > >> 
> > > > > > 
> > > > > > [[alternative HTML version deleted]]
> > > > > > 
> > > > > > ______________________________________________
> > > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > > and provide commented, minimal, self-contained, reproducible code.
> > > > > 
> > > > > David Winsemius
> > > > > Alameda, CA, USA
> > > > > 
> > > 
> > > David Winsemius
> > > Alameda, CA, USA
> > >
> 
> David Winsemius
> Alameda, CA, USA
> 
 		 	   		  
	[[alternative HTML version deleted]]


From stefano.sofia at regione.marche.it  Thu May 14 16:22:48 2015
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Thu, 14 May 2015 14:22:48 +0000
Subject: [R] create a vector from several data frames
Message-ID: <8B435C9568170B469AE31E8891E8CC4F2804F785@ESINO.regionemarche.intra>

Dear r-users,
suppose that I have 20 data frames df1, df2, ..., df20 (one for each different location) with the same column names and column types (the first column contains a date, the others are numeric) like

day tmax tmin
2015-05-10 20 10
2015-05-11 21 12
2015-05-12 17 9
2015-05-13 24 13
2015-05-14 25 18

I need to create a vector "tmax_all" of length 20 with the tmax referred to a particular day (let's say 2015-05-14).
I would first build a new data frame

tmax_df <- Reduce(function(x, y) merge(x, y, by="day"), list(df1[ , c("day", "tmax")], df2[ , c("day", "tmax")], ..., df20[ , c("day", "tmax")]))

and then select the row of tmax_df where day is the day I want to.
Is there an easiest way? Is it possible to create straightforward this vector without passing through the merge of all the data frames?

Thank you for your help
Stefano

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

From sarah.goslee at gmail.com  Thu May 14 16:25:23 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 14 May 2015 10:25:23 -0400
Subject: [R] Counting consecutive events in R
In-Reply-To: <CANtKHPWht-hb1eO5O5YCCqMGxC4O5omvmU-MKkNZfhsq9dEBWA@mail.gmail.com>
References: <CANtKHPWht-hb1eO5O5YCCqMGxC4O5omvmU-MKkNZfhsq9dEBWA@mail.gmail.com>
Message-ID: <CAM_vjukXgpA6A0B=QyW5agcv8Ujn4+ZK3Zm97a1mEdFY-UggLQ@mail.gmail.com>

Assuming I understand the problem correctly, you want to check for
runs of at least length five where both Score and Test_desc assume
particular values. You don't care where they are or what other data
are associated, you just want to know if at least one such run exists
in your data frame.

Here's a function that does that:


checkruns <- function(testdata) {

        test1 <- ifelse(testdata$Score > 0 & testdata$Type_Desc == 1 &
!is.na(testdata$Type_Desc), 1, 0)
        test0 <- ifelse(testdata$Score > 0 & testdata$Type_Desc == 0 &
!is.na(testdata$Type_Desc), 1, 0)

        test1.rle <- rle(test1)
        test0.rle <- rle(test0)

        if(any(test1.rle$lengths >= 5 & test1.rle$values == 1))
cat("Type_high\n")
        if(any(test0.rle$lengths >= 5 & test0.rle$values == 1))
cat("Type_low\n")

        invisible()
}

Sarah


On Thu, May 14, 2015 at 8:16 AM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
> Hi,
>
> I have the following dataframe
>
> structure(list(Type = c("QRS", "QRS", "QRS", "QRS", "QRS", "QRS",
> "QRS", "QRS", "QRS", "QRS", "QRS", "QRS", "RR", "RR", "RR", "PP",
> "PP", "PP", "PP", "PP", "PP", "PP", "PP", "PP", "QTc", "QTc",
> "QTc", "QTc", "QTc", "QTc", "QTc", "QTc", "QTc", "QTc", "QTc",
> "QTc", "QTc", "QTc", "QTc"), Time_Point_Start = c("2015-04-01 14:57:15.0.0312",
> "2015-04-01 14:57:15.0.7839", "2015-04-01 14:57:16.0.5343",
> "2015-04-01 14:57:17.0.2573",
> "2015-04-01 14:57:18.0.0234", "2015-04-01 14:57:18.0.7722",
> "2015-04-01 14:57:19.0.5265",
> "2015-04-01 14:57:24.0.0195", "2015-04-01 14:57:24.0.7839",
> "2015-04-01 14:57:25.0.5343",
> "2015-04-01 14:57:26.0.2768", "2015-04-01 14:57:27.0.0273",
> "2015-04-01 14:58:03.0.0702",
> "2015-04-01 14:58:03.0.8190", "2015-04-01 14:58:04.0.5694",
> "2015-04-01 14:57:58.0.4134",
> "2015-04-01 14:57:59.0.1637", "2015-04-01 14:57:59.0.9126",
> "2015-04-01 14:58:00.0.6630",
> "2015-04-01 14:58:01.0.4134", "2015-04-01 14:58:02.0.1637",
> "2015-04-01 14:58:02.0.9126",
> "2015-04-01 14:58:03.0.6630", "2015-04-01 14:58:04.0.4134",
> "2015-04-01 14:57:07.0.4212",
> "2015-04-01 14:57:08.0.1715", "2015-04-01 14:57:08.0.9204",
> "2015-04-01 14:57:09.0.6864",
> "2015-04-01 14:57:10.0.4368", "2015-04-01 14:57:11.0.1871",
> "2015-04-01 14:57:11.0.9360",
> "2015-04-01 14:57:12.0.6591", "2015-04-01 14:57:13.0.4251",
> "2015-04-01 14:57:14.0.1754",
> "2015-04-01 14:57:14.0.9243", "2015-04-01 14:57:15.0.6903",
> "2015-04-01 14:57:16.0.4407",
> "2015-04-01 14:57:17.0.1676", "2015-04-01 14:57:17.0.9321"),
>     Time_Point_End = c("2015-04-01 14:57:15.0.0858", "2015-04-01
> 14:57:15.0.8346",
>     "2015-04-01 14:57:16.0.6006", "2015-04-01 14:57:17.0.0351",
>     "2015-04-01 14:57:18.0.1403", "2015-04-01 14:57:18.0.8385",
>     "2015-04-01 14:57:19.0.5889", "2015-04-01 14:57:24.0.0858",
>     "2015-04-01 14:57:24.0.8346", "2015-04-01 14:57:25.0.5772",
>     "2015-04-01 14:57:26.0.3939", "2015-04-01 14:57:27.0.0936",
>     "2015-04-01 14:58:03.0.8190", "2015-04-01 14:58:04.0.5694",
>     "2015-04-01 14:58:05.0.3197", "2015-04-01 14:57:59.0.1637",
>     "2015-04-01 14:57:59.0.9126", "2015-04-01 14:58:00.0.6630",
>     "2015-04-01 14:58:01.0.4134", "2015-04-01 14:58:02.0.1637",
>     "2015-04-01 14:58:02.0.9126", "2015-04-01 14:58:03.0.6630",
>     "2015-04-01 14:58:04.0.4134", "2015-04-01 14:58:05.0.1793",
>     "2015-04-01 14:57:07.0.8775", "2015-04-01 14:57:08.0.6435",
>     "2015-04-01 14:57:09.0.3705", "2015-04-01 14:57:10.0.1209",
>     "2015-04-01 14:57:10.0.8697", "2015-04-01 14:57:11.0.6201",
>     "2015-04-01 14:57:12.0.3861", "2015-04-01 14:57:13.0.1364",
>     "2015-04-01 14:57:13.0.8853", "2015-04-01 14:57:14.0.6513",
>     "2015-04-01 14:57:15.0.4017", "2015-04-01 14:57:16.0.1248",
>     "2015-04-01 14:57:16.0.9165", "2015-04-01 14:57:17.0.6162",
>     "2015-04-01 14:57:18.0.3900"), Value = c(0.0546, 0.0507,
>     0.0663, 0.0936, 0.117, 0.0663, 0.0624, 0.0663, 0.0507, 0.0429,
>     0.117, 0.0663, 0.7488, 0.7488, 0.7488, 0.7488, 0.7488, 0.7488,
>     0.7488, 0.7488, 0.7488, 0.7488, 0.7488, 0.7644, 0.033103481,
>     0.034056449, 0.032367699, 0.031000613, 0.031405867, 0.031241866,
>     0.032367699, 0.034337907, 0.033125921, 0.034337907, 0.034337907,
>     0.031241866, 0.034337907, 0.032367699, 0.032930616), Score = c(0L,
>     0L, 0L, 0L, 3L, 0L, 0L, 0L, 0L, 0L, 3L, 0L, 0L, 0L, 0L, 0L,
>     0L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), Type_Desc = c(NA, NA, NA,
>     NA, 1L, NA, NA, NA, NA, NA, 1L, NA, NA, NA, NA, NA, NA, 1L,
>     1L, 1L, 1L, 1L, NA, NA, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>     0L, 0L, 0L, 0L, 0L, 0L), Pat_id = c(4L, 4L, 4L, 4L, 4L, 4L,
>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>     4L, 4L, 4L)), .Names = c("Type", "Time_Point_Start", "Time_Point_End",
> "Value", "Score", "Type_Desc", "Pat_id"), class = "data.frame",
> row.names = c(NA,
> -39L))
>
>
> For each unique value in column 'Type' , I want to check for
> consecutive 5 rows (if any) of 'Score' > 0.
>
> Now, if there are five consecutive rows with Score > 0 and 'Type_Desc'
> = 0, then we print "Type_low" , else if
>
> 'Type_Desc' = 1, we print "Type_high". The search should end once 5
> consecutive rows have been found.
>
> So, for this data frame we will have two statements as follows,
>
>
> 1.PP_high
>
> (reason - consecutive 5 rows of score > 0 and
>
> 'Type_Desc' = 1 )
>
> 2.QTc_low
> (reason - consecutive 5 rows of score > 0 and
>
> 'Type_Desc' = 0 )
>
> How can this problem tackled in R?
>
> Thanks,
>
> Abhinaba
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org


From dwinsemius at comcast.net  Thu May 14 16:58:43 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 14 May 2015 07:58:43 -0700
Subject: [R] binding two lists of lists of dataframes together
In-Reply-To: <BAY179-W93AB8B2495958B1FDA948AD3D80@phx.gbl>
References: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>,
	<A2E1A0300F5.00001107jrkrideau@inbox.com>
	<BAY179-W63A3DF10922679A302B16D3DA0@phx.gbl>,
	<17C25B6B-DDF7-4108-99C9-3DABC178C32F@comcast.net>
	<BAY179-W817CF1BB2EEC863DC596F5D3DA0@phx.gbl>,
	<1084ED86-44F2-4717-9879-4A8A368FE00A@comcast.net>
	<BAY179-W41355B8D24DBDB0BEF7978D3DA0@phx.gbl>,
	<F8CE47F9-1AEE-4514-9779-61DB3AF0F019@comcast.net>
	<BAY179-W44BDA61F1D2A044E3AE646D3D90@phx.gbl>,
	<689E9E7A-5D78-4D80-8318-F71A1138C445@comcast.net>
	<BAY179-W93AB8B2495958B1FDA948AD3D80@phx.gbl>
Message-ID: <CCA2CCA9-73C8-4117-9504-F38BA209ADB8@comcast.net>


On May 14, 2015, at 7:15 AM, Vin Cheng wrote:

> Hi David,
>  
> Understood.  I've done a lot of work around this structure, but if there isn't anyway to change it back to the original structure then I'll work around it.

I suppose there might be a way to make it back into a data.table, but it won't be a structure that I would recognize as such. The usual data table column is a vector, whereas your object had a complex list structure stored as a single "column". It was list1 and list 2 that had the class attribute of c('data.table', 'data.frame'), rather than each list component having those attributes which might have made more sense.

If there is some virtue in the origianl structure that I am not appreciating, then just this:

list3a <- data.table(list3a)   # untested

>  
> Could you possibly show me how to add colnames to list3a?
>  
> c("id","WgtBand","Wgt","Held","LID","Issuer","Bid","Offer") these would be repeated once for each V1,V2,V3.
>  

The code I used to build colnames was just:

list1a <- lapply(list1, function(x) setNames( data.frame(x),
                                               paste0("V", seq(length(x)) )
                ) )

So modifying it to put that character vector in the  names attribute on list3a itself could just be:

list3a <- lapply(list3a, function(x) setNames( data.frame(x), 
                                               c("id","WgtBand","Wgt","Held","LID","Issuer","Bid","Offer") ) )

-- 
David



> Thank you again for all the help!  It's much appreciated!
> Vince
> 
>  
> > Subject: Re: [R] binding two lists of lists of dataframes together
> > From: dwinsemius at comcast.net
> > Date: Wed, 13 May 2015 15:51:47 -0700
> > CC: r-help at r-project.org
> > To: newrnewbie at hotmail.com
> > 
> > 
> > On May 13, 2015, at 2:01 PM, Vin Cheng wrote:
> > 
> > > Hi David,
> > > 
> > > I tried both solutions you provided(lapply(dlist, function(x) rbind(x,x) ) & Map( rbind, smaller, smaller)) and they seem to transpose and reshape the data into a different structure. Whenever I added the str - I only get a NULL.
> > 
> > I believe you are misrepresenting my suggestion. I suggested that you coerce each of the items in those lists to data.frames with appropriate column names before applying rbind.data.frame
> > 
> > Those list1 and list2 examples appear to me as pathologically deformed. They claim to be data.tables but they have no self referential pointers, suggesting to me that they are not data.tables, and they have no column names suggesting not either data.table, nor data.frame.
> > 
> > > class(list1)
> > [1] "data.table" "data.frame"
> > > class(list2)
> > [1] "data.table" "data.frame"
> > 
> > > 
> > > > You basically want a list of the same general structure as list1 where all the elements in list two at the same position and depth have been concatenated?
> > > 
> > > Yes - that sounds exactly right.
> > > 
> > Fix up the data.structures, first. Then use Map(rbind, ...) .... as described previously.
> > 
> > list1a <- lapply(list1, function(x) setNames( data.frame(x), paste0("V", seq(length(x)) ) ) )
> > list2a <- lapply(list2, function(x) setNames( data.frame(x), paste0("V", seq(length(x)) ) ))
> > list3a <- Map( rbind.data.frame, list1a, list2a)
> > str(list3a)
> > 
> > List of 3
> > $ V1:'data.frame':	22 obs. of 8 variables:
> > ..$ V1: int [1:22] 15 19 28 9 17 3 11 21 7 8 ...
> > ..$ V2: num [1:22] 1 1 2 3 4 5 6 7 8 9 ...
> > ..$ V3: num [1:22] NaN NaN NA NA NA NA NA NA NA NA ...
> > ..$ V4: num [1:22] 0 0 0 0 0 0 0 0 0 0 ...
> > ..$ V5: Factor w/ 29 levels "ID1","ID10","ID11",..: 7 11 21 29 9 23 3 14 27 28 ...
> > ..$ V6: Factor w/ 29 levels "Issuer1","Issuer10",..: 7 11 21 29 9 23 3 14 27 28 ...
> > ..$ V7: num [1:22] 99.5 95.5 99.5 100 98.5 ...
> > ..$ V8: num [1:22] 0.4 0.55 0.4 0.4 0.5 0.45 0.4 0.45 0.6 0.4 ...
> > $ V2:'data.frame':	22 obs. of 8 variables:
> > ..$ V1: int [1:22] 10 29 5 19 28 3 10 12 1 21 ...
> > ..$ V2: num [1:22] 1 1 2 3 4 5 6 7 8 9 ...
> > ..$ V3: num [1:22] NaN NaN NA NA NA NA NA NA NA NA ...
> > ..$ V4: num [1:22] 0 0 0 0 0 0 0 0 0 0 ...
> > ..$ V5: Factor w/ 29 levels "ID1","ID10","ID11",..: 2 22 25 11 21 23 2 4 1 14 ...
> > ..$ V6: Factor w/ 29 levels "Issuer1","Issuer10",..: 2 22 25 11 21 23 2 4 1 14 ...
> > ..$ V7: num [1:22] 98.5 100.2 99 95.5 99.5 ...
> > ..$ V8: num [1:22] 0.6 0.4 0.45 0.55 0.4 0.45 0.6 0.55 0.5 0.45 ...
> > $ V3:'data.frame':	22 obs. of 8 variables:
> > ..$ V1: int [1:22] 21 28 3 7 25 25 15 13 3 20 ...
> > ..$ V2: num [1:22] 1 1 2 3 4 5 6 7 8 9 ...
> > ..$ V3: num [1:22] NaN NaN NA NA NA NA NA NA NA NA ...
> > ..$ V4: num [1:22] 0 0 0 0 0 0 0 0 0 0 ...
> > ..$ V5: Factor w/ 29 levels "ID1","ID10","ID11",..: 14 21 23 27 18 18 7 5 23 13 ...
> > ..$ V6: Factor w/ 29 levels "Issuer1","Issuer10",..: 14 21 23 27 18 18 7 5 23 13 ...
> > ..$ V7: num [1:22] 98 99.5 99.6 99.8 99.4 ...
> > ..$ V8: num [1:22] 0.45 0.4 0.45 0.6 0.4 0.4 0.4 0.4 0.45 0.3 ..
> > 
> > -- 
> > David
> > 
> > 
> > > I've created new input(list1,list2) and desired output(list3) examples below. I hope this makes the request a lot clearer.
> > > 
> > > Not sure if this helpful, but I found this bit of script and it keeps V1,V2,V3 separate and keeps each set of observations as vectors, but it doesn't concatenate the v1 observations with v2 observations together.
> > > 
> > > sample.list <- list(list1,list2)
> > > library(data.table) 
> > > nr <- nrow(sample.list[[1]])
> > > fastbind.ith.rows <- function(i) rbindlist(lapply(sample.list, "[", i, TRUE))
> > > fastbound <- lapply(1:nr, fastbind.ith.rows)
> > > 
> > > Link:
> > > http://stackoverflow.com/questions/4863341/fast-vectorized-merge-of-list-of-data-frames-by-row
> > > 
> > > Thank you again!
> > > Vince
> > > 
> > > Please find below the structure for list1, list2, and the desired output list3:
> > > 
> > > list1<-structure(list(
> > > V1 = list(c(15L, 19L, 28L, 9L, 17L, 3L, 11L, 21L,7L, 8L, 11L, 13L), 
> > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 
> > > c(NaN,NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> > > "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L), .Label = c("Issuer1", "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> > > "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), 
> > > class = "factor"), c(99.5, 95.5, 99.5, 100, 98.5, 99.646, 99.833, 98, 99.75, 100, 99.833, 98.563), c(0.4, 0.55, 0.4, 0.4, 0.5, 0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4)), 
> > > V2 = list(c(10L, 29L, 5L, 19L, 28L, 3L, 10L, 12L, 1L, 21L, 23L, 25L), 
> > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 
> > > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> > > "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L), .Label = c("Issuer1", 
> > > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", 
> > > "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor")
> > > , c(98.5, 100.25, 99, 95.5, 99.5, 99.646, 98.5, 94.75, 98.75, 98, 99, 99.388), c(0.6, 0.4, 0.45, 0.55, 0.4, 0.45, 0.6, 0.55, 0.5, 0.45, 0.55, 0.4)), 
> > > V3 = list(c(21L, 28L, 3L, 7L, 25L, 25L, 15L, 13L, 3L, 20L, 16L, 18L), 
> > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 
> > > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> > > "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L), .Label = c("Issuer1", 
> > > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", 
> > > "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), 
> > > c(98, 99.5, 99.646, 99.75, 99.388, 99.388, 99.5, 98.563, 99.646, 98, 99.563, 100.375), c(0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4, 0.4, 0.45, 0.3, 0.45, 0.5))), .Names = c("V1", 
> > > "V2", "V3"), row.names = c("id", "WgtBand", "Wgt", "Held", "LoanXID", "Issuer", "Bid", "Offer"), class = c("data.table", "data.frame"))
> > > list2<-structure(list(V1 = list(
> > > c(15L, 8L, 2L, 21L, 8L, 2L, 23L, 25L, 20L, 4L), 
> > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > structure(c(7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> > > "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("Issuer1", 
> > > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", 
> > > "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), c(99.5, 100, 96.969, 98, 100, 96.969, 99, 99.388, 98, 94), 
> > > c(0.4, 0.4, 0.45, 0.45, 0.4, 0.45, 0.55, 0.4, 0.3, 0.45)), 
> > > V2 = list(c(27L, 14L, 11L, 25L, 17L, 15L, 10L, 23L, 16L, 2L), 
> > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > structure(c(20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> > > "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("Issuer1", 
> > > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", 
> > > "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), 
> > > c(100.296, 88.5, 99.833, 99.388, 98.5, 99.5, 98.5, 99, 99.563, 96.969), c(0.4, 0.4, 0.4, 0.4, 0.5, 0.4, 0.6, 0.55, 0.45, 0.45)), 
> > > V3 = list(c(13L, 26L, 5L, 17L, 5L, 28L, 2L, 16L, 1L, 19L), 
> > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > structure(c(5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 11L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", 
> > > "ID24", "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 
> > > 11L), .Label = c("Issuer1", "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> > > "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"
> > > ), class = "factor"), c(98.563, 99.229, 99, 98.5, 99, 99.5, 96.969, 99.563, 98.75, 95.5), c(0.4, 0.55, 0.45, 0.5, 0.45, 0.4, 0.45, 0.45, 0.5, 0.55))), .Names = c("V1", 
> > > "V2", "V3"), row.names = c("id", "WgtBand", "Wgt", "Held", "LoanXID", "Issuer", "Bid", "Offer"), class = c("data.table", "data.frame"))
> > > list3<-structure(list(
> > > V1 = list(c(15L, 19L, 28L, 9L, 17L, 3L, 11L, 21L,7L, 8L, 11L, 13L,15L, 8L, 2L, 21L, 8L, 2L, 23L, 25L, 20L, 4L), 
> > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > c(NaN,NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L,7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> > > "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L,7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("Issuer1", "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> > > "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), 
> > > class = "factor"), c(99.5, 95.5, 99.5, 100, 98.5, 99.646, 99.833, 98, 99.75, 100, 99.833, 98.563,99.5, 100, 96.969, 98, 100, 96.969, 99, 99.388, 98, 94), c(0.4, 0.55, 0.4, 0.4, 0.5, 0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4,0.4, 0.4, 0.45, 0.45, 0.4, 0.45, 0.55, 0.4, 0.3, 0.45)), 
> > > V2 = list(c(10L, 29L, 5L, 19L, 28L, 3L, 10L, 12L, 1L, 21L, 23L, 25L,27L, 14L, 11L, 25L, 17L, 15L, 10L, 23L, 16L, 2L), 
> > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L,20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> > > "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L,20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("Issuer1", 
> > > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", 
> > > "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor")
> > > , c(98.5, 100.25, 99, 95.5, 99.5, 99.646, 98.5, 94.75, 98.75, 98, 99, 99.388,100.296, 88.5, 99.833, 99.388, 98.5, 99.5, 98.5, 99, 99.563, 96.969), c(0.6, 0.4, 0.45, 0.55, 0.4, 0.45, 0.6, 0.55, 0.5, 0.45, 0.55, 0.4,0.4, 0.4, 0.4, 0.4, 0.5, 0.4, 0.6, 0.55, 0.45, 0.45)), 
> > > V3 = list(c(21L, 28L, 3L, 7L, 25L, 25L, 15L, 13L, 3L, 20L, 16L, 18L,13L, 26L, 5L, 17L, 5L, 28L, 2L, 16L, 1L, 19L), 
> > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L,5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 11L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> > > "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L,5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 11L), .Label = c("Issuer1", 
> > > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", 
> > > "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), 
> > > c(98, 99.5, 99.646, 99.75, 99.388, 99.388, 99.5, 98.563, 99.646, 98, 99.563, 100.375,98.563, 99.229, 99, 98.5, 99, 99.5, 96.969, 99.563, 98.75, 95.5), c(0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4, 0.4, 0.45, 0.3, 0.45, 0.5,0.4, 0.55, 0.45, 0.5, 0.45, 0.4, 0.45, 0.45, 0.5, 0.55))), .Names = c("V1", 
> > > "V2", "V3"), row.names = c("id", "WgtBand", "Wgt", "Held", "LoanXID", "Issuer", "Bid", "Offer"), class = c("data.table", "data.frame"))
> > > 
> > > 
> > > 
> > > > Subject: Re: [R] binding two lists of lists of dataframes together
> > > > From: dwinsemius at comcast.net
> > > > Date: Tue, 12 May 2015 16:00:05 -0700
> > > > CC: r-help at r-project.org
> > > > To: newrnewbie at hotmail.com
> > > > 
> > > > 
> > > > On May 12, 2015, at 3:12 PM, Vin Cheng wrote:
> > > > 
> > > > > Hi David,
> > > > > 
> > > > > Would it be possible to modify it a little so that I can keep V1, V2, and V3 intact?
> > > > 
> > > > 
> > > > > 
> > > > > I also don't quite know where to put list2 in the solution you provided below? list2 can be an exact copy of list1 for this example.
> > > > 
> > > > In which case it would be nearly trivial:
> > > > 
> > > > lapply(dlist, function(x) rbind(x,x) ) 
> > > > 
> > > > str( lapply(dlist, function(x) rbind(x,x) ) )
> > > > List of 3
> > > > $ V1:'data.frame':	20 obs. of 48 variables:
> > > > ..$ V1 : int [1:20] 19 94 94 15 90 13 66 17 45 69 ...
> > > > ..$ V2 : num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
> > > > ..$ V3 : num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
> > > > ..$ V4 : num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> > > > snipped.....
> > > > 
> > > > > 
> > > > > list1 has (48 observations of 3 variables(V1, V2,V3)) each observation has 10 values in a vector 
> > > > > list2 has (48 observations of 3 variables (V1, V2,V3)) each observation has 10 values in a vector 
> > > > 
> > > > You basically want a list of the same general structure as list1 where all the elements in list two at the same position and depth have been concatenated?
> > > > > 
> > > > > Output should ideally have (48 observations of 3 variables (V1, V2,V3)) each observation has 20 values in a vector
> > > > > list1 V1 stacks with list2 V1, 
> > > > > list1 V2 stacks with list2 V2, 
> > > > > list1 V3 stacks with list2 V3
> > > > 
> > > > You had a bunch of factor variables in list1. Are we assured that the levels of any factor variables in list2 are the same as the corresponding factor variables in list 1?
> > > > 
> > > > > 
> > > > > Boundlist seems to break out the values of each variable(V1,V2,V3) into 10 columns with 1 value in each column.
> > > > 
> > > > Not the way I use those words after using R for the last 8 years. There were 48 "columns" and 10 positions in each. I think you need to reverse your terminology (columns and rows) since a "column" in a dataframe is a list and the row numbers are the relative positions along vectors.
> > > > 
> > > > 
> > > > > Is it possible to put the values in the 10 columns(20 values in ideal output) into a vector for each of the 48 observation in each variable(V1,V2,V3).
> > > > 
> > > > Having severe trouble reformulating this in R dataframe terminology.
> > > > 
> > > > > 
> > > > > Sorry for all the back and forth - explaining an exact output over email is difficult.
> > > > 
> > > > It shouldn't be difficult if you would post data examples with sufficient complexity to represent the problem. I will build a smaller list of dataframe and name it 'smaller'
> > > > 
> > > > Since I had difficulty with mapply I'm switching to the list version named ?Map found in the ?funprog page:
> > > > 
> > > > smaller <- lapply(dlist, "[", 1:6)
> > > > 
> > > > ?Map
> > > > str( Map( rbind, smaller, smaller))
> > > > 
> > > > #------I think this is what you might want----------
> > > > List of 3
> > > > $ V1:'data.frame':	20 obs. of 6 variables:
> > > > ..$ V1: int [1:20] 19 94 94 15 90 13 66 17 45 69 ...
> > > > ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
> > > > ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
> > > > ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> > > > ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 12 95 95 8 91 6 64 10 41 67 ...
> > > > ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 12 95 95 8 91 6 64 10 41 67 ...
> > > > $ V2:'data.frame':	20 obs. of 6 variables:
> > > > ..$ V1: int [1:20] 93 3 85 34 20 89 16 25 83 90 ...
> > > > ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
> > > > ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
> > > > ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> > > > ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 94 24 85 29 14 89 9 19 83 91 ...
> > > > ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 94 24 85 29 14 89 9 19 83 91 ...
> > > > $ V3:'data.frame':	20 obs. of 6 variables:
> > > > ..$ V1: int [1:20] 47 95 26 64 16 55 61 39 23 66 ...
> > > > ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
> > > > ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
> > > > ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> > > > ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 43 96 20 62 9 52 59 34 17 64 ...
> > > > ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 43 96 20 62 9 52 59 34 17 64 ...
> > > > 
> > > > > 
> > > > > I really appreciate the help and the effort! 
> > > > > 
> > > > > Thank you again!
> > > > > Vince
> > > > > 
> > > > > > Subject: Re: [R] binding two lists of lists of dataframes together
> > > > > > From: dwinsemius at comcast.net
> > > > > > Date: Tue, 12 May 2015 14:23:54 -0700
> > > > > > CC: r-help at r-project.org
> > > > > > To: newrnewbie at hotmail.com
> > > > > > 
> > > > > > 
> > > > > > On May 12, 2015, at 12:56 PM, Vin Cheng wrote:
> > > > > > 
> > > > > > > Hi,
> > > > > > > 
> > > > > > > Thanks David! Your solution 3 worked well with the sample data, but when I run solution 2 & 3 on the actual data - it creates a list of 1 for each data point and it doesn't end up looking like the desired output for some reason.
> > > > > > > 
> > > > > > > I've run a dput on the actual data and pasted below. There's a lot of data - so I'm only copying list1 - if the solution could bind list1 with itself - it should work just as well. 
> > > > > > > 
> > > > > > > Sorry for not providing an accurate sample the first time around - I thought the shortened version would be simpler and sufficient.
> > > > > > > 
> > > > > > > Any help/guidance would be greatly appreciated!
> > > > > > > 
> > > > > > 
> > > > > > This appears to be three similarly structured lists of various classes but fortunately for this effort the factor variables in corresponding columns all have the same levels. (Otherwise one would need to convert to character before attempting to stack them.)
> > > > > > 
> > > > > > I would just use `rbind.data.frame` (after making them dataframes with the same column names.)
> > > > > > 
> > > > > > 
> > > > > > dlist <- lapply( list1, function(d) setNames( data.frame(d), paste0("V", 1:48) ))
> > > > > > boundlist <- do.call(rbind, dlist)
> > > > > > 
> > > > > > # Done.
> > > > > > 
> > > > > > -- 
> > > > > > David.
> > > > > > > Many Thanks,
> > > > > > > Vince
> > > > > > > 
> > > > > > > list1 <- structure(list(V1 = list(c(19L, 94L, 94L, 15L, 90L, 13L, 66L, 
> > > > > > > 17L, 45L, 69L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, 
> > > > > > > NA, NA, NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 
> > > > > > > 0), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
> > > > > > > ), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", "ID13", 
> > > > > > > "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", 
> > > > > > > "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", "ID27", "ID28", 
> > > > > > > "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", "ID34", "ID35", 
> > > > > > > "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", "ID41", "ID42", 
> > > > > > > "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", 
> > > > > > > "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
> > > > > > > "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", "ID64", 
> > > > > > > "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", "ID70", "ID71", 
> > > > > > > "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", "ID78", "ID79", 
> > > > > > > "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", "ID85", "ID86", 
> > > > > > > "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", "ID92", "ID93", 
> > > > > > > "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"), class = "factor"), 
> > > > > > > structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
> > > > > > > ), .Label = c("Issuer1", "Issuer10", "Issuer100", "Issuer11", 
> > > > > > > "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
> > > > > > > "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", 
> > > > > > > "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", 
> > > > > > > "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", 
> > > > > > > "Issuer30", "Issuer31", "Issuer32", "Issuer33", "Issuer34", 
> > > > > > > "Issuer35", "Issuer36", "Issuer37", "Issuer38", "Issuer39", 
> > > > > > > "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
> > > > > > > "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", 
> > > > > > > "Issuer49", "Issuer5", "Issuer50", "Issuer51", "Issuer52", 
> > > > > > > "Issuer53", "Issuer54", "Issuer55", "Issuer56", "Issuer57", 
> > > > > > > "Issuer58", "Issuer59", "Issuer6", "Issuer60", "Issuer61", 
> > > > > > > "Issuer62", "Issuer63", "Issuer64", "Issuer65", "Issuer66", 
> > > > > > > "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
> > > > > > > "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", 
> > > > > > > "Issuer76", "Issuer77", "Issuer78", "Issuer79", "Issuer8", 
> > > > > > > "Issuer80", "Issuer81", "Issuer82", "Issuer83", "Issuer84", 
> > > > > > > "Issuer85", "Issuer86", "Issuer87", "Issuer88", "Issuer89", 
> > > > > > > "Issuer9", "Issuer90", "Issuer91", "Issuer92", "Issuer93", 
> > > > > > > "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
> > > > > > > "Issuer99"), class = "factor"), c(95.5, 98.5, 98.5, 99.5, 
> > > > > > > 103.5, 98.563, 99.75, 98.5, 98.75, 99.125), c(97.5, 99.5, 
> > > > > > > 99.5, 100.375, 104.5, 99.188, 100.25, 99.5, 99.75, 100.063
> > > > > > > ), c(2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 4L), c(4L, 5L, 5L, 
> > > > > > > 5L, 5L, 2L, 3L, 5L, 3L, 2L), c(TRUE, FALSE, FALSE, TRUE, 
> > > > > > > FALSE, TRUE, TRUE, FALSE, FALSE, TRUE), structure(c(1L, 1L, 
> > > > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > > structure(c(9L, 2L, 2L, 1L, 2L, 1L, 3L, 3L, 5L, 9L), .Label = c("B", 
> > > > > > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
> > > > > > > ), class = "factor"), structure(c(8L, 2L, 2L, 1L, 8L, 2L, 
> > > > > > > 2L, 2L, 1L, 7L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
> > > > > > > "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(20L, 
> > > > > > > 88L, 88L, 6L, 3L, 35L, 29L, 24L, 53L, 82L), .Label = c("1/11/2019", 
> > > > > > > "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
> > > > > > > "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > > > > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
> > > > > > > "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
> > > > > > > "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
> > > > > > > "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
> > > > > > > "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
> > > > > > > "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
> > > > > > > "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
> > > > > > > "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
> > > > > > > "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
> > > > > > > "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
> > > > > > > "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
> > > > > > > "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
> > > > > > > "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
> > > > > > > "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
> > > > > > > "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
> > > > > > > "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
> > > > > > > "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
> > > > > > > c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > > > > > FALSE, FALSE), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 
> > > > > > > 10L, 41L, 67L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > > > > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > > > > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > > > > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > > > > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > > > > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > > > > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > > > > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > > > > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > > > > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > > > > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > > > > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > > > > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > > > > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > > > > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > > > > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > > > > > "Issuer98", "Issuer99"), class = "factor"), structure(c(12L, 
> > > > > > > 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L), .Label = c("BL1", 
> > > > > > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > > > > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
> > > > > > > "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
> > > > > > > "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
> > > > > > > "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
> > > > > > > "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
> > > > > > > "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
> > > > > > > "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > > > > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
> > > > > > > "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
> > > > > > > "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
> > > > > > > "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
> > > > > > > "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(4L, 
> > > > > > > 3L, 3L, 5L, 6L, 3L, 2L, 6L, 6L, 5L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > > > > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > > > > > "Retail", "Services: Business"), class = "factor"), structure(c(3L, 
> > > > > > > 5L, 5L, 6L, 4L, 3L, 4L, 2L, 6L, 6L), .Label = c("Financial Intermediaries", 
> > > > > > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > > > > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > > > > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 6L, 8L, 8L), .Label = c("AU", 
> > > > > > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > > > > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 5L, 6L, 6L), .Label = c("1", 
> > > > > > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > > > > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L), .Label = c("Canada", 
> > > > > > > "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
> > > > > > > 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > > > > > structure(c(2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > > > > > "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > > > > 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > > > > > c(0.125550168, 1.731733265, 1.731733265, NA, 5.246485518, 
> > > > > > > 7.798802147, NA, NA, NA, NA), c(4770L, 3490L, 3490L, 3490L, 
> > > > > > > 3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.45, 0.4, 0.4, 
> > > > > > > 0.45, 0.55, 0.4, 0.4, 0.45, 0.4, 0.5), c(4770L, 3490L, 3490L, 
> > > > > > > 3490L, 3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.55, 
> > > > > > > 0.4, 0.4, 0.4, 0.55, 0.4, 0.5, 0.5, 0.45, 0.55), c(18L, 15L, 
> > > > > > > 15L, 15L, 18L, 15L, 15L, 15L, 14L, 17L), c(17L, 16L, 16L, 
> > > > > > > 15L, 14L, 15L, 15L, 15L, 14L, 15L), c(192500000, 205000000, 
> > > > > > > 205000000, 342000000, 120000000, 835000000, 1043700000, 160000000, 
> > > > > > > 300000000, 265000000), c(0.02, 0.02, 0.02, 0.4, 0.02, 0.4, 
> > > > > > > 0.6, 0.6, 0.6, 0.02), c(850L, 475L, 475L, 500L, 1000L, 350L, 
> > > > > > > 400L, 975L, 500L, 700L), c(1, 1.5, 1.5, 1, 1.25, 1, 1, 1, 
> > > > > > > 1, 1), c(0.0851, 0.04765, 0.04765, 0.0501, 0.100125, 0.0351, 
> > > > > > > 0.0401, 0.0976, 0.0501, 0.0701), c(0.099192999, 0.023321348, 
> > > > > > > 0.023321348, 0.06465519, 0.103470278, 0.052237196, 0.051331755, 
> > > > > > > 0.112300026, 0.066116739, 0.084107871), c(897.0917677, -1.49365213, 
> > > > > > > -1.49365213, 549.0886934, 975.9481504, 429.1863229, 436.2991366, 
> > > > > > > 1062.374805, 567.0741295, 747.1023728), c(0.088186528, 0.048131313, 
> > > > > > > 0.048131313, 0.050131332, 0.096274038, 0.035499188, 0.040049938, 
> > > > > > > 0.098585859, 0.050478589, 0.070385766), c(0L, 0L, 0L, 0L, 
> > > > > > > 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > > > > 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
> > > > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > > > > > c(0.0178406708595388, 0.0136532951289398, 0.0136532951289398, 
> > > > > > > 0.0143553008595989, 0.028689111747851, 0.0100573065902579, 
> > > > > > > 0.0180630630630631, 0.043963963963964, 0.0225675675675676, 
> > > > > > > 0.0200859598853868), c(0.046805, 0.01906, 0.01906, 0.02004, 
> > > > > > > 0.05506875, 0.01404, 0.02005, 0.0488, 0.022545, 0.038555), 
> > > > > > > c(0.001702, 0.000953, 0.000953, 0.02004, 0.0020025, 0.01404, 
> > > > > > > 0.02406, 0.05856, 0.03006, 0.001402)), V2 = list(c(93L, 3L, 
> > > > > > > 85L, 34L, 20L, 89L, 16L, 25L, 83L, 90L), c(1, 1, 2, 3, 4, 5, 
> > > > > > > 6, 7, 8, 9), c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), c(0, 
> > > > > > > 0, 0, 0, 0, 0, 0, 0, 0, 0), structure(c(94L, 24L, 85L, 29L, 14L, 
> > > > > > > 89L, 9L, 19L, 83L, 91L), .Label = c("ID1", "ID10", "ID100", "ID11", 
> > > > > > > "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
> > > > > > > "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> > > > > > > "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", 
> > > > > > > "ID34", "ID35", "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", 
> > > > > > > "ID41", "ID42", "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", 
> > > > > > > "ID49", "ID5", "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", 
> > > > > > > "ID56", "ID57", "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", 
> > > > > > > "ID63", "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
> > > > > > > "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", 
> > > > > > > "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", 
> > > > > > > "ID85", "ID86", "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", 
> > > > > > > "ID92", "ID93", "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"
> > > > > > > ), class = "factor"), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
> > > > > > > 9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
> > > > > > > "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> > > > > > > "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
> > > > > > > "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", "Issuer32", 
> > > > > > > "Issuer33", "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
> > > > > > > "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", "Issuer49", 
> > > > > > > "Issuer5", "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
> > > > > > > "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", "Issuer6", 
> > > > > > > "Issuer60", "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
> > > > > > > "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", "Issuer76", 
> > > > > > > "Issuer77", "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
> > > > > > > "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", "Issuer87", 
> > > > > > > "Issuer88", "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
> > > > > > > "Issuer99"), class = "factor"), c(99.5, 99.646, 100.402, 100.25, 
> > > > > > > 98, 99.563, 99.563, 99.388, 99.531, 103.5), c(100.5, 100.271, 
> > > > > > > 100.903, 100.75, 99, 100.188, 100.063, 99.788, 100.125, 104.5
> > > > > > > ), c(1L, 6L, 9L, 1L, 1L, 2L, 2L, 10L, 4L, 2L), c(5L, 2L, 1L, 
> > > > > > > 3L, 3L, 4L, 4L, 1L, 1L, 5L), c(TRUE, TRUE, FALSE, FALSE, TRUE, 
> > > > > > > FALSE, FALSE, TRUE, TRUE, FALSE), structure(c(1L, 1L, 1L, 1L, 
> > > > > > > 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > > structure(c(8L, 1L, 4L, 1L, 3L, 4L, 6L, 1L, 5L, 2L), .Label = c("B", 
> > > > > > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
> > > > > > > ), class = "factor"), structure(c(7L, 2L, 5L, 2L, 1L, 2L, 
> > > > > > > 6L, 1L, 5L, 8L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
> > > > > > > "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(41L, 
> > > > > > > 1L, 13L, 43L, 21L, 87L, 49L, 73L, 46L, 3L), .Label = c("1/11/2019", 
> > > > > > > "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
> > > > > > > "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > > > > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
> > > > > > > "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
> > > > > > > "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
> > > > > > > "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
> > > > > > > "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
> > > > > > > "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
> > > > > > > "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
> > > > > > > "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
> > > > > > > "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
> > > > > > > "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
> > > > > > > "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
> > > > > > > "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
> > > > > > > "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
> > > > > > > "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
> > > > > > > "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
> > > > > > > "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
> > > > > > > "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
> > > > > > > c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > > > > > FALSE, FALSE), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
> > > > > > > 9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > > > > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > > > > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > > > > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > > > > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > > > > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > > > > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > > > > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > > > > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > > > > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > > > > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > > > > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > > > > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > > > > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > > > > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > > > > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > > > > > "Issuer98", "Issuer99"), class = "factor"), structure(c(94L, 
> > > > > > > 24L, 85L, 29L, 14L, 89L, 9L, 19L, 83L, 91L), .Label = c("BL1", 
> > > > > > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > > > > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
> > > > > > > "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
> > > > > > > "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
> > > > > > > "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
> > > > > > > "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
> > > > > > > "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
> > > > > > > "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > > > > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
> > > > > > > "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
> > > > > > > "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
> > > > > > > "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
> > > > > > > "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(2L, 
> > > > > > > 2L, 3L, 6L, 1L, 6L, 6L, 6L, 1L, 6L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > > > > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > > > > > "Retail", "Services: Business"), class = "factor"), structure(c(6L, 
> > > > > > > 6L, 3L, 5L, 1L, 2L, 5L, 3L, 2L, 4L), .Label = c("Financial Intermediaries", 
> > > > > > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > > > > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > > > > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L), .Label = c("AU", 
> > > > > > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > > > > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label = c("1", 
> > > > > > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > > > > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("Canada", 
> > > > > > > "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
> > > > > > > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > > > > > structure(c(2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > > > > > "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > > > > 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > > > > > c(2.603554841, 7.27032758, 3.155438813, 5.037267081, 0.125550168, 
> > > > > > > NA, 3.464301168, NA, 4.816376964, 5.246485518), c(2220L, 
> > > > > > > 2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 2220L, 3490L
> > > > > > > ), c(0.55, 0.45, 0.5, 0.4, 0.6, 0.45, 0.45, 0.55, 0.2, 0.55
> > > > > > > ), c(2220L, 2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 
> > > > > > > 2220L, 3490L), c(0.55, 0.45, 0.5, 0.4, 0.3, 0.45, 0.45, 0.4, 
> > > > > > > 0.2, 0.55), c(17L, 15L, 12L, 15L, 14L, 15L, 13L, 14L, 12L, 
> > > > > > > 18L), c(16L, 16L, 14L, 16L, 15L, 12L, 13L, 15L, 14L, 14L), 
> > > > > > > c(200000000, 613811406, 750000000, 200000000, 405500000, 
> > > > > > > 450000000, 530000000, 2010000000, 775000000, 120000000), 
> > > > > > > c(0.02, 0.5, 0.65, 0.27, 0.5, 0.65, 0.65, 0.3, 0.65, 0.02
> > > > > > > ), c(950L, 350L, 350L, 275L, 450L, 275L, 225L, 325L, 275L, 
> > > > > > > 1000L), c(1.25, 1, 0.75, 0.75, 1, 0.75, 0, 1, 0.75, 1.25), 
> > > > > > > c(0.095125, 0.0351, 0.035075, 0.027575, 0.0451, 0.027575, 
> > > > > > > 0.02527, 0.0326, 0.027575, 0.100125), c(0.104211455, 0.046414939, 
> > > > > > > 0.050338657, 0.027233401, 0.059885473, 0.03459045, 0.028669191, 
> > > > > > > 0.048294163, 0.040935438, 0.103470278), c(980.5501911, 400.3544693, 
> > > > > > > 385.8629241, 244.6340073, 511.2711809, 294.3073789, 194.2034583, 
> > > > > > > 385.9437059, 308.4324006, 975.9481504), c(0.095125, 0.035114573, 
> > > > > > > 0.034847619, 0.027437811, 0.045786802, 0.027609374, 0.025317343, 
> > > > > > > 0.032734868, 0.027622511, 0.096274038), c(0L, 0L, 0L, 0L, 
> > > > > > > 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > > > > 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
> > > > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > > > > > c(0.0428490990990991, 0.0158108108108108, 0.037313829787234, 
> > > > > > > 0.00790114613180516, 0.00945492662473794, 0.0124211711711712, 
> > > > > > > 0.0143091732729332, 0.00934097421203438, 0.0124211711711712, 
> > > > > > > 0.028689111747851), c(0.05231875, 0.015795, 0.0175375, 0.01103, 
> > > > > > > 0.01353, 0.01240875, 0.0113715, 0.01304, 0.005515, 0.05506875
> > > > > > > ), c(0.0019025, 0.01755, 0.02279875, 0.00744525, 0.02255, 
> > > > > > > 0.01792375, 0.0164255, 0.00978, 0.01792375, 0.0020025)), 
> > > > > > > V3 = list(c(47L, 95L, 26L, 64L, 16L, 55L, 61L, 39L, 23L, 
> > > > > > > 66L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, NA, NA, 
> > > > > > > NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > > > > > structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 
> > > > > > > 64L), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", 
> > > > > > > "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
> > > > > > > "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", 
> > > > > > > "ID26", "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", 
> > > > > > > "ID32", "ID33", "ID34", "ID35", "ID36", "ID37", "ID38", 
> > > > > > > "ID39", "ID4", "ID40", "ID41", "ID42", "ID43", "ID44", 
> > > > > > > "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", "ID50", 
> > > > > > > "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
> > > > > > > "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", 
> > > > > > > "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
> > > > > > > "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", 
> > > > > > > "ID77", "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", 
> > > > > > > "ID83", "ID84", "ID85", "ID86", "ID87", "ID88", "ID89", 
> > > > > > > "ID9", "ID90", "ID91", "ID92", "ID93", "ID94", "ID95", 
> > > > > > > "ID96", "ID97", "ID98", "ID99"), class = "factor"), structure(c(43L, 
> > > > > > > 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("Issuer1", 
> > > > > > > "Issuer10", "Issuer100", "Issuer11", "Issuer12", "Issuer13", 
> > > > > > > "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", 
> > > > > > > "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", 
> > > > > > > "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
> > > > > > > "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", 
> > > > > > > "Issuer32", "Issuer33", "Issuer34", "Issuer35", "Issuer36", 
> > > > > > > "Issuer37", "Issuer38", "Issuer39", "Issuer4", "Issuer40", 
> > > > > > > "Issuer41", "Issuer42", "Issuer43", "Issuer44", "Issuer45", 
> > > > > > > "Issuer46", "Issuer47", "Issuer48", "Issuer49", "Issuer5", 
> > > > > > > "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
> > > > > > > "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", 
> > > > > > > "Issuer6", "Issuer60", "Issuer61", "Issuer62", "Issuer63", 
> > > > > > > "Issuer64", "Issuer65", "Issuer66", "Issuer67", "Issuer68", 
> > > > > > > "Issuer69", "Issuer7", "Issuer70", "Issuer71", "Issuer72", 
> > > > > > > "Issuer73", "Issuer74", "Issuer75", "Issuer76", "Issuer77", 
> > > > > > > "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
> > > > > > > "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", 
> > > > > > > "Issuer87", "Issuer88", "Issuer89", "Issuer9", "Issuer90", 
> > > > > > > "Issuer91", "Issuer92", "Issuer93", "Issuer94", "Issuer95", 
> > > > > > > "Issuer96", "Issuer97", "Issuer98", "Issuer99"), class = "factor"), 
> > > > > > > c(99.688, 75.667, 99.229, 99.583, 99.563, 99.188, 98.8, 
> > > > > > > 98.5, 99, 99.75), c(100.281, 78.667, 100.104, 100.333, 
> > > > > > > 100.063, 99.906, 99.75, 99.5, 99.75, 100.25), c(4L, 3L, 
> > > > > > > 6L, 3L, 2L, 4L, 5L, 1L, 1L, 1L), c(4L, 3L, 1L, 3L, 4L, 
> > > > > > > 2L, 4L, 5L, 3L, 3L), c(FALSE, TRUE, TRUE, TRUE, FALSE, 
> > > > > > > TRUE, TRUE, FALSE, TRUE, TRUE), structure(c(1L, 1L, 1L, 
> > > > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > > structure(c(3L, 8L, 9L, 1L, 6L, 3L, 10L, 10L, 9L, 3L), .Label = c("B", 
> > > > > > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", 
> > > > > > > "NR"), class = "factor"), structure(c(6L, 7L, 7L, 2L, 
> > > > > > > 6L, 1L, 9L, 9L, 8L, 2L), .Label = c("B1", "B2", "B3", 
> > > > > > > "Ba1", "Ba2", "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), 
> > > > > > > structure(c(66L, 80L, 74L, 30L, 49L, 72L, 70L, 62L, 10L, 
> > > > > > > 29L), .Label = c("1/11/2019", "1/2/2019", "1/2/2020", 
> > > > > > > "1/30/2022", "10/15/2016", "10/15/2021", "10/17/2019", 
> > > > > > > "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > > > > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", 
> > > > > > > "11/12/2020", "11/20/2019", "11/20/2020", "11/27/2020", 
> > > > > > > "11/5/2021", "11/6/2020", "11/9/2017", "11/9/2018", "12/15/2018", 
> > > > > > > "12/15/2021", "12/15/2022", "12/16/2019", "12/18/2020", 
> > > > > > > "12/20/2019", "12/7/2018", "12/7/2019", "2/12/2021", 
> > > > > > > "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", "2/24/2017", 
> > > > > > > "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", "3/21/2019", 
> > > > > > > "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", "4/30/2018", 
> > > > > > > "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", "5/15/2018", 
> > > > > > > "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", "5/8/2020", 
> > > > > > > "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", "6/2/2019", 
> > > > > > > "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", "6/30/2017", 
> > > > > > > "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", "7/10/2020", 
> > > > > > > "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", "7/29/2022", 
> > > > > > > "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", "8/12/2021", 
> > > > > > > "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", "8/24/2017", 
> > > > > > > "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", "9/18/2016", 
> > > > > > > "9/18/2019", "9/20/2019"), class = "factor"), c(FALSE, 
> > > > > > > FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > > > > > FALSE), structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 
> > > > > > > 34L, 17L, 64L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > > > > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > > > > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > > > > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > > > > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > > > > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > > > > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > > > > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > > > > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > > > > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > > > > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > > > > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > > > > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > > > > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > > > > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > > > > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > > > > > "Issuer98", "Issuer99"), class = "factor"), structure(c(43L, 
> > > > > > > 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("BL1", 
> > > > > > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > > > > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", 
> > > > > > > "BL22", "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", 
> > > > > > > "BL29", "BL3", "BL30", "BL31", "BL32", "BL33", "BL34", 
> > > > > > > "BL35", "BL36", "BL37", "BL38", "BL39", "BL4", "BL40", 
> > > > > > > "BL41", "BL42", "BL43", "BL44", "BL45", "BL46", "BL47", 
> > > > > > > "BL48", "BL49", "BL5", "BL50", "BL51", "BL52", "BL53", 
> > > > > > > "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", "BL6", 
> > > > > > > "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > > > > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", 
> > > > > > > "BL73", "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", 
> > > > > > > "BL8", "BL80", "BL81", "BL82", "BL83", "BL84", "BL85", 
> > > > > > > "BL86", "BL87", "BL88", "BL89", "BL9", "BL90", "BL91", 
> > > > > > > "BL92", "BL93", "BL94", "BL95", "BL96", "BL97", "BL98", 
> > > > > > > "BL99"), class = "factor"), structure(c(1L, 6L, 6L, 4L, 
> > > > > > > 6L, 4L, 6L, 2L, 6L, 2L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > > > > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > > > > > "Retail", "Services: Business"), class = "factor"), structure(c(2L, 
> > > > > > > 2L, 1L, 5L, 5L, 3L, 3L, 6L, 2L, 4L), .Label = c("Financial Intermediaries", 
> > > > > > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > > > > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > > > > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 5L, 8L, 8L, 8L), .Label = c("AU", 
> > > > > > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > > > > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 3L, 6L, 6L, 6L), .Label = c("1", 
> > > > > > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > > > > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L, 4L), .Label = c("Canada", 
> > > > > > > "Europe", "Other", "U.S."), class = "factor"), structure(c(2L, 
> > > > > > > 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > > > > > "Y"), class = "factor"), structure(c(1L, 2L, 2L, 1L, 
> > > > > > > 1L, 1L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > > > > > c(8.74248921, NA, NA, 4.338507174, 3.464301168, NA, NA, 
> > > > > > > NA, NA, NA), c(2220L, 2220L, 3490L, 3490L, 1766L, 2220L, 
> > > > > > > 8070L, 8070L, 3490L, 2220L), c(0.6, 0.55, 0.4, 0.4, 0.45, 
> > > > > > > 0.45, 0.4, 0.45, 0.6, 0.4), c(2220L, 2220L, 3490L, 3490L, 
> > > > > > > 1766L, 2220L, 8070L, 8070L, 3490L, 2220L), c(0.3, 0.55, 
> > > > > > > 0.55, 0.4, 0.45, 0.4, 0.45, 0.3, 0.55, 0.5), c(13L, 17L, 
> > > > > > > 17L, 15L, 13L, 14L, 19L, 19L, 18L, 15L), c(15L, 16L, 
> > > > > > > 15L, 15L, 13L, 14L, 19L, 19L, 15L, 15L), c(625000000, 
> > > > > > > 450000000, 760000000, 630000000, 530000000, 671500000, 
> > > > > > > 240000000, 100000000, 375000000, 1043700000), c(0.5, 
> > > > > > > 0.02, 0.02, 0.3, 0.65, 0.3, 0.5, 0.65, 0.02, 0.6), c(275L, 
> > > > > > > 750L, 650L, 300L, 225L, 300L, 700L, 925L, 825L, 400L), 
> > > > > > > c(0, 1, 1, 1.25, 0, 1, 1, 1.25, 1.25, 1), c(0.03027, 
> > > > > > > 0.0751, 0.0651, 0.030125, 0.02527, 0.0301, 0.0701, 0.092625, 
> > > > > > > 0.082625, 0.0401), c(0.031286195, 0.154827358, 0.080695261, 
> > > > > > > 0.041683558, 0.028669191, 0.044131997, 0.084009559, 0.108958135, 
> > > > > > > 0.090916682, 0.051331755), c(263.290277, 1448.101305, 
> > > > > > > 704.3633733, 368.0708419, 194.2034583, 356.3784942, 746.772345, 
> > > > > > > 1036.334285, 875.917553, 436.2991366), c(0.030274693, 
> > > > > > > 0.097321394, 0.065317835, 0.030137658, 0.025317343, 0.030236973, 
> > > > > > > 0.070611937, 0.093560606, 0.083144654, 0.040049938), 
> > > > > > > c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 
> > > > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), 
> > > > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > > > > > c(0.0136351351351351, 0.0338288288288288, 0.0186532951289398, 
> > > > > > > 0.00863180515759312, 0.0143091732729332, 0.0135585585585586, 
> > > > > > > 0.00868649318463445, 0.0114776951672862, 0.0236747851002865, 
> > > > > > > 0.0180630630630631), c(0.009081, 0.041305, 0.035805, 
> > > > > > > 0.01205, 0.0113715, 0.01204, 0.031545, 0.0277875, 0.04544375, 
> > > > > > > 0.02005), c(0.015135, 0.001502, 0.001302, 0.0090375, 
> > > > > > > 0.0164255, 0.00903, 0.03505, 0.06020625, 0.0016525, 0.02406
> > > > > > > ))), .Names = c("V1", "V2", "V3"), row.names = c(NA, 
> > > > > > > -48L), class = c("data.table", "data.frame"))
> > > > > > > 
> > > > > > > 
> > > > > > > 
> > > > > > >> Subject: Re: [R] binding two lists of lists of dataframes together
> > > > > > >> From: dwinsemius at comcast.net
> > > > > > >> Date: Tue, 12 May 2015 11:36:50 -0700
> > > > > > >> CC: r-help at r-project.org
> > > > > > >> To: newrnewbie at hotmail.com
> > > > > > >> 
> > > > > > >> 
> > > > > > >> On May 12, 2015, at 9:24 AM, Vin Cheng wrote:
> > > > > > >> 
> > > > > > >>> list1<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L), 
> > > > > > >>> WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > > >>> structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
> > > > > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
> > > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > > >>> structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
> > > > > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
> > > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > > > > > >>> .Names = c("id", "WgtBand", "Wgt")))
> > > > > > >>> 
> > > > > > >>> 
> > > > > > >>> list2<-list(structure(list(id = c(493L, 564L, 147L), 
> > > > > > >>> WgtBand = c(1, 2, 3), 
> > > > > > >>> Wgt = c(NaN, NaN, NA)), 
> > > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > > >>> structure(list(id = c(276L, 411L, 574L,111L), 
> > > > > > >>> WgtBand = c(1, 2, 3,4), 
> > > > > > >>> Wgt = c(NaN, NaN, NA,NA)), 
> > > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > > >>> structure(list(id = c(76L, 330L), 
> > > > > > >>> WgtBand = c(1, 1), 
> > > > > > >>> Wgt = c(NaN, NaN)), 
> > > > > > >>> .Names = c("id", "WgtBand", "Wgt")))
> > > > > > >>> 
> > > > > > >>> list3<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L,493L, 564L, 147L), 
> > > > > > >>> WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9,1, 2, 3), 
> > > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA)), 
> > > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > > >>> structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,276L, 411L, 574L,111L), 
> > > > > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 2, 3,4), 
> > > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA,NA)), 
> > > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > > >>> structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,76L, 330L), 
> > > > > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 1), 
> > > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN)), 
> > > > > > >>> .Names = c("id", "WgtBand", "Wgt")))
> > > > > > >> 
> > > > > > >> I get something like the desired structure with:
> > > > > > >> 
> > > > > > >> mapply(function(x,y) mapply(c, x,y), list1,list2)
> > > > > > >> 
> > > > > > >> I can make it closer with:
> > > > > > >> 
> > > > > > >> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) unclass( as.data.frame(x) ) )
> > > > > > >> 
> > > > > > >> 
> > > > > > >> Or even closer with:
> > > > > > >> 
> > > > > > >> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) as.list( as.data.frame(x) ) )
> > > > > > >> 
> > > > > > >> `identical` does not return TRUE but I cannot see where the difference lies.
> > > > > > >> 
> > > > > > >> -- 
> > > > > > >> 
> > > > > > >> David Winsemius
> > > > > > >> Alameda, CA, USA
> > > > > > >> 
> > > > > > > 
> > > > > > > [[alternative HTML version deleted]]
> > > > > > > 
> > > > > > > ______________________________________________
> > > > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > > > and provide commented, minimal, self-contained, reproducible code.
> > > > > > 
> > > > > > David Winsemius
> > > > > > Alameda, CA, USA
> > > > > > 
> > > > 
> > > > David Winsemius
> > > > Alameda, CA, USA
> > > >
> > 
> > David Winsemius
> > Alameda, CA, USA
> > 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu May 14 17:10:09 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 14 May 2015 08:10:09 -0700
Subject: [R] error using the huge R package
In-Reply-To: <6F401FAF-6CE2-4236-B2E1-1AAC31C18136@well.ox.ac.uk>
References: <6F401FAF-6CE2-4236-B2E1-1AAC31C18136@well.ox.ac.uk>
Message-ID: <CC836F34-DB50-47A3-9607-3C1F729539FC@comcast.net>


On May 13, 2015, at 3:45 PM, Juan Fernandez wrote:

> Dear List
> 
> I am trying to do an association network using some expression data I have, the data is really huge: 300 samples and ~30,000 genes. I would like to apply a gaussian graphical model to my data using the huge R package.
> 
> Here is the code I am using
> 
>> dim(data)
> #[1] 317 32200
> 
>> huge.out <- huge.npn(data)
>> huge.stars <- huge.select(huge.out, criterion=?stars?)
> 
> However in this last step I got the following error:
> 
> Error in cor(x) : sampling?..in progress:10%
> Missing values present in input variable ?x?. Consider using use = ?pairwise.complete.obs?

Responded on StackOverflow where this duplicate question was posted yesterday

-- 
David.


> 
> Any help would be very appreciated
> 
> Juan
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From newrnewbie at hotmail.com  Thu May 14 17:11:01 2015
From: newrnewbie at hotmail.com (Vin Cheng)
Date: Thu, 14 May 2015 15:11:01 +0000
Subject: [R] binding two lists of lists of dataframes together
In-Reply-To: <CCA2CCA9-73C8-4117-9504-F38BA209ADB8@comcast.net>
References: <BAY179-W44FA489A2509AFC64284C1D3DB0@phx.gbl>,
	<A2E1A0300F5.00001107jrkrideau@inbox.com>
	<BAY179-W63A3DF10922679A302B16D3DA0@phx.gbl>,
	<17C25B6B-DDF7-4108-99C9-3DABC178C32F@comcast.net>
	<BAY179-W817CF1BB2EEC863DC596F5D3DA0@phx.gbl>,
	<1084ED86-44F2-4717-9879-4A8A368FE00A@comcast.net>
	<BAY179-W41355B8D24DBDB0BEF7978D3DA0@phx.gbl>,
	<F8CE47F9-1AEE-4514-9779-61DB3AF0F019@comcast.net>
	<BAY179-W44BDA61F1D2A044E3AE646D3D90@phx.gbl>,
	<689E9E7A-5D78-4D80-8318-F71A1138C445@comcast.net>
	<BAY179-W93AB8B2495958B1FDA948AD3D80@phx.gbl>,
	<CCA2CCA9-73C8-4117-9504-F38BA209ADB8@comcast.net>
Message-ID: <BAY179-W4054EFB4E607FB4F1AFDD1D3D80@phx.gbl>

Thanks David!
 
Have a good one!
 
> Subject: Re: [R] binding two lists of lists of dataframes together
> From: dwinsemius at comcast.net
> Date: Thu, 14 May 2015 07:58:43 -0700
> CC: r-help at r-project.org
> To: newrnewbie at hotmail.com
> 
> 
> On May 14, 2015, at 7:15 AM, Vin Cheng wrote:
> 
> > Hi David,
> >  
> > Understood.  I've done a lot of work around this structure, but if there isn't anyway to change it back to the original structure then I'll work around it.
> 
> I suppose there might be a way to make it back into a data.table, but it won't be a structure that I would recognize as such. The usual data table column is a vector, whereas your object had a complex list structure stored as a single "column". It was list1 and list 2 that had the class attribute of c('data.table', 'data.frame'), rather than each list component having those attributes which might have made more sense.
> 
> If there is some virtue in the origianl structure that I am not appreciating, then just this:
> 
> list3a <- data.table(list3a)   # untested
> 
> >  
> > Could you possibly show me how to add colnames to list3a?
> >  
> > c("id","WgtBand","Wgt","Held","LID","Issuer","Bid","Offer") these would be repeated once for each V1,V2,V3.
> >  
> 
> The code I used to build colnames was just:
> 
> list1a <- lapply(list1, function(x) setNames( data.frame(x),
>                                                paste0("V", seq(length(x)) )
>                 ) )
> 
> So modifying it to put that character vector in the  names attribute on list3a itself could just be:
> 
> list3a <- lapply(list3a, function(x) setNames( data.frame(x), 
>                                                c("id","WgtBand","Wgt","Held","LID","Issuer","Bid","Offer") ) )
> 
> -- 
> David
> 
> 
> 
> > Thank you again for all the help!  It's much appreciated!
> > Vince
> > 
> >  
> > > Subject: Re: [R] binding two lists of lists of dataframes together
> > > From: dwinsemius at comcast.net
> > > Date: Wed, 13 May 2015 15:51:47 -0700
> > > CC: r-help at r-project.org
> > > To: newrnewbie at hotmail.com
> > > 
> > > 
> > > On May 13, 2015, at 2:01 PM, Vin Cheng wrote:
> > > 
> > > > Hi David,
> > > > 
> > > > I tried both solutions you provided(lapply(dlist, function(x) rbind(x,x) ) & Map( rbind, smaller, smaller)) and they seem to transpose and reshape the data into a different structure. Whenever I added the str - I only get a NULL.
> > > 
> > > I believe you are misrepresenting my suggestion. I suggested that you coerce each of the items in those lists to data.frames with appropriate column names before applying rbind.data.frame
> > > 
> > > Those list1 and list2 examples appear to me as pathologically deformed. They claim to be data.tables but they have no self referential pointers, suggesting to me that they are not data.tables, and they have no column names suggesting not either data.table, nor data.frame.
> > > 
> > > > class(list1)
> > > [1] "data.table" "data.frame"
> > > > class(list2)
> > > [1] "data.table" "data.frame"
> > > 
> > > > 
> > > > > You basically want a list of the same general structure as list1 where all the elements in list two at the same position and depth have been concatenated?
> > > > 
> > > > Yes - that sounds exactly right.
> > > > 
> > > Fix up the data.structures, first. Then use Map(rbind, ...) .... as described previously.
> > > 
> > > list1a <- lapply(list1, function(x) setNames( data.frame(x), paste0("V", seq(length(x)) ) ) )
> > > list2a <- lapply(list2, function(x) setNames( data.frame(x), paste0("V", seq(length(x)) ) ))
> > > list3a <- Map( rbind.data.frame, list1a, list2a)
> > > str(list3a)
> > > 
> > > List of 3
> > > $ V1:'data.frame':	22 obs. of 8 variables:
> > > ..$ V1: int [1:22] 15 19 28 9 17 3 11 21 7 8 ...
> > > ..$ V2: num [1:22] 1 1 2 3 4 5 6 7 8 9 ...
> > > ..$ V3: num [1:22] NaN NaN NA NA NA NA NA NA NA NA ...
> > > ..$ V4: num [1:22] 0 0 0 0 0 0 0 0 0 0 ...
> > > ..$ V5: Factor w/ 29 levels "ID1","ID10","ID11",..: 7 11 21 29 9 23 3 14 27 28 ...
> > > ..$ V6: Factor w/ 29 levels "Issuer1","Issuer10",..: 7 11 21 29 9 23 3 14 27 28 ...
> > > ..$ V7: num [1:22] 99.5 95.5 99.5 100 98.5 ...
> > > ..$ V8: num [1:22] 0.4 0.55 0.4 0.4 0.5 0.45 0.4 0.45 0.6 0.4 ...
> > > $ V2:'data.frame':	22 obs. of 8 variables:
> > > ..$ V1: int [1:22] 10 29 5 19 28 3 10 12 1 21 ...
> > > ..$ V2: num [1:22] 1 1 2 3 4 5 6 7 8 9 ...
> > > ..$ V3: num [1:22] NaN NaN NA NA NA NA NA NA NA NA ...
> > > ..$ V4: num [1:22] 0 0 0 0 0 0 0 0 0 0 ...
> > > ..$ V5: Factor w/ 29 levels "ID1","ID10","ID11",..: 2 22 25 11 21 23 2 4 1 14 ...
> > > ..$ V6: Factor w/ 29 levels "Issuer1","Issuer10",..: 2 22 25 11 21 23 2 4 1 14 ...
> > > ..$ V7: num [1:22] 98.5 100.2 99 95.5 99.5 ...
> > > ..$ V8: num [1:22] 0.6 0.4 0.45 0.55 0.4 0.45 0.6 0.55 0.5 0.45 ...
> > > $ V3:'data.frame':	22 obs. of 8 variables:
> > > ..$ V1: int [1:22] 21 28 3 7 25 25 15 13 3 20 ...
> > > ..$ V2: num [1:22] 1 1 2 3 4 5 6 7 8 9 ...
> > > ..$ V3: num [1:22] NaN NaN NA NA NA NA NA NA NA NA ...
> > > ..$ V4: num [1:22] 0 0 0 0 0 0 0 0 0 0 ...
> > > ..$ V5: Factor w/ 29 levels "ID1","ID10","ID11",..: 14 21 23 27 18 18 7 5 23 13 ...
> > > ..$ V6: Factor w/ 29 levels "Issuer1","Issuer10",..: 14 21 23 27 18 18 7 5 23 13 ...
> > > ..$ V7: num [1:22] 98 99.5 99.6 99.8 99.4 ...
> > > ..$ V8: num [1:22] 0.45 0.4 0.45 0.6 0.4 0.4 0.4 0.4 0.45 0.3 ..
> > > 
> > > -- 
> > > David
> > > 
> > > 
> > > > I've created new input(list1,list2) and desired output(list3) examples below. I hope this makes the request a lot clearer.
> > > > 
> > > > Not sure if this helpful, but I found this bit of script and it keeps V1,V2,V3 separate and keeps each set of observations as vectors, but it doesn't concatenate the v1 observations with v2 observations together.
> > > > 
> > > > sample.list <- list(list1,list2)
> > > > library(data.table) 
> > > > nr <- nrow(sample.list[[1]])
> > > > fastbind.ith.rows <- function(i) rbindlist(lapply(sample.list, "[", i, TRUE))
> > > > fastbound <- lapply(1:nr, fastbind.ith.rows)
> > > > 
> > > > Link:
> > > > http://stackoverflow.com/questions/4863341/fast-vectorized-merge-of-list-of-data-frames-by-row
> > > > 
> > > > Thank you again!
> > > > Vince
> > > > 
> > > > Please find below the structure for list1, list2, and the desired output list3:
> > > > 
> > > > list1<-structure(list(
> > > > V1 = list(c(15L, 19L, 28L, 9L, 17L, 3L, 11L, 21L,7L, 8L, 11L, 13L), 
> > > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 
> > > > c(NaN,NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > > structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> > > > "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L), .Label = c("Issuer1", "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> > > > "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), 
> > > > class = "factor"), c(99.5, 95.5, 99.5, 100, 98.5, 99.646, 99.833, 98, 99.75, 100, 99.833, 98.563), c(0.4, 0.55, 0.4, 0.4, 0.5, 0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4)), 
> > > > V2 = list(c(10L, 29L, 5L, 19L, 28L, 3L, 10L, 12L, 1L, 21L, 23L, 25L), 
> > > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 
> > > > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > > structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> > > > "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L), .Label = c("Issuer1", 
> > > > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", 
> > > > "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor")
> > > > , c(98.5, 100.25, 99, 95.5, 99.5, 99.646, 98.5, 94.75, 98.75, 98, 99, 99.388), c(0.6, 0.4, 0.45, 0.55, 0.4, 0.45, 0.6, 0.55, 0.5, 0.45, 0.55, 0.4)), 
> > > > V3 = list(c(21L, 28L, 3L, 7L, 25L, 25L, 15L, 13L, 3L, 20L, 16L, 18L), 
> > > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), 
> > > > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > > structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> > > > "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L), .Label = c("Issuer1", 
> > > > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", 
> > > > "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), 
> > > > c(98, 99.5, 99.646, 99.75, 99.388, 99.388, 99.5, 98.563, 99.646, 98, 99.563, 100.375), c(0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4, 0.4, 0.45, 0.3, 0.45, 0.5))), .Names = c("V1", 
> > > > "V2", "V3"), row.names = c("id", "WgtBand", "Wgt", "Held", "LoanXID", "Issuer", "Bid", "Offer"), class = c("data.table", "data.frame"))
> > > > list2<-structure(list(V1 = list(
> > > > c(15L, 8L, 2L, 21L, 8L, 2L, 23L, 25L, 20L, 4L), 
> > > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > > structure(c(7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> > > > "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("Issuer1", 
> > > > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", 
> > > > "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), c(99.5, 100, 96.969, 98, 100, 96.969, 99, 99.388, 98, 94), 
> > > > c(0.4, 0.4, 0.45, 0.45, 0.4, 0.45, 0.55, 0.4, 0.3, 0.45)), 
> > > > V2 = list(c(27L, 14L, 11L, 25L, 17L, 15L, 10L, 23L, 16L, 2L), 
> > > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > > structure(c(20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> > > > "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("Issuer1", 
> > > > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", 
> > > > "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), 
> > > > c(100.296, 88.5, 99.833, 99.388, 98.5, 99.5, 98.5, 99, 99.563, 96.969), c(0.4, 0.4, 0.4, 0.4, 0.5, 0.4, 0.6, 0.55, 0.45, 0.45)), 
> > > > V3 = list(c(13L, 26L, 5L, 17L, 5L, 28L, 2L, 16L, 1L, 19L), 
> > > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > > structure(c(5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 11L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", 
> > > > "ID24", "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 
> > > > 11L), .Label = c("Issuer1", "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> > > > "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"
> > > > ), class = "factor"), c(98.563, 99.229, 99, 98.5, 99, 99.5, 96.969, 99.563, 98.75, 95.5), c(0.4, 0.55, 0.45, 0.5, 0.45, 0.4, 0.45, 0.45, 0.5, 0.55))), .Names = c("V1", 
> > > > "V2", "V3"), row.names = c("id", "WgtBand", "Wgt", "Held", "LoanXID", "Issuer", "Bid", "Offer"), class = c("data.table", "data.frame"))
> > > > list3<-structure(list(
> > > > V1 = list(c(15L, 19L, 28L, 9L, 17L, 3L, 11L, 21L,7L, 8L, 11L, 13L,15L, 8L, 2L, 21L, 8L, 2L, 23L, 25L, 20L, 4L), 
> > > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > > c(NaN,NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > > structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L,7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> > > > "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(7L, 11L, 21L, 29L, 9L, 23L, 3L, 14L, 27L, 28L, 3L, 5L,7L, 28L, 12L, 14L, 28L, 12L, 16L, 18L, 13L, 24L), .Label = c("Issuer1", "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> > > > "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), 
> > > > class = "factor"), c(99.5, 95.5, 99.5, 100, 98.5, 99.646, 99.833, 98, 99.75, 100, 99.833, 98.563,99.5, 100, 96.969, 98, 100, 96.969, 99, 99.388, 98, 94), c(0.4, 0.55, 0.4, 0.4, 0.5, 0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4,0.4, 0.4, 0.45, 0.45, 0.4, 0.45, 0.55, 0.4, 0.3, 0.45)), 
> > > > V2 = list(c(10L, 29L, 5L, 19L, 28L, 3L, 10L, 12L, 1L, 21L, 23L, 25L,27L, 14L, 11L, 25L, 17L, 15L, 10L, 23L, 16L, 2L), 
> > > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > > structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L,20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> > > > "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(2L, 22L, 25L, 11L, 21L, 23L, 2L, 4L, 1L, 14L, 16L, 18L,20L, 6L, 3L, 18L, 9L, 7L, 2L, 16L, 8L, 12L), .Label = c("Issuer1", 
> > > > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", 
> > > > "Issuer24", "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor")
> > > > , c(98.5, 100.25, 99, 95.5, 99.5, 99.646, 98.5, 94.75, 98.75, 98, 99, 99.388,100.296, 88.5, 99.833, 99.388, 98.5, 99.5, 98.5, 99, 99.563, 96.969), c(0.6, 0.4, 0.45, 0.55, 0.4, 0.45, 0.6, 0.55, 0.5, 0.45, 0.55, 0.4,0.4, 0.4, 0.4, 0.4, 0.5, 0.4, 0.6, 0.55, 0.45, 0.45)), 
> > > > V3 = list(c(21L, 28L, 3L, 7L, 25L, 25L, 15L, 13L, 3L, 20L, 16L, 18L,13L, 26L, 5L, 17L, 5L, 28L, 2L, 16L, 1L, 19L), 
> > > > c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > > c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), 
> > > > c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > > structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L,5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 11L), .Label = c("ID1", "ID10", "ID11", "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", 
> > > > "ID25", "ID26", "ID27", "ID28", "ID29", "ID3", "ID4", "ID5", "ID6", "ID7", "ID8", "ID9"), class = "factor"), structure(c(14L, 21L, 23L, 27L, 18L, 18L, 7L, 5L, 23L, 13L, 8L, 10L,5L, 19L, 25L, 9L, 25L, 21L, 12L, 8L, 1L, 11L), .Label = c("Issuer1", 
> > > > "Issuer10", "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", 
> > > > "Issuer27", "Issuer28", "Issuer29", "Issuer3", "Issuer4", "Issuer5", "Issuer6", "Issuer7", "Issuer8", "Issuer9"), class = "factor"), 
> > > > c(98, 99.5, 99.646, 99.75, 99.388, 99.388, 99.5, 98.563, 99.646, 98, 99.563, 100.375,98.563, 99.229, 99, 98.5, 99, 99.5, 96.969, 99.563, 98.75, 95.5), c(0.45, 0.4, 0.45, 0.6, 0.4, 0.4, 0.4, 0.4, 0.45, 0.3, 0.45, 0.5,0.4, 0.55, 0.45, 0.5, 0.45, 0.4, 0.45, 0.45, 0.5, 0.55))), .Names = c("V1", 
> > > > "V2", "V3"), row.names = c("id", "WgtBand", "Wgt", "Held", "LoanXID", "Issuer", "Bid", "Offer"), class = c("data.table", "data.frame"))
> > > > 
> > > > 
> > > > 
> > > > > Subject: Re: [R] binding two lists of lists of dataframes together
> > > > > From: dwinsemius at comcast.net
> > > > > Date: Tue, 12 May 2015 16:00:05 -0700
> > > > > CC: r-help at r-project.org
> > > > > To: newrnewbie at hotmail.com
> > > > > 
> > > > > 
> > > > > On May 12, 2015, at 3:12 PM, Vin Cheng wrote:
> > > > > 
> > > > > > Hi David,
> > > > > > 
> > > > > > Would it be possible to modify it a little so that I can keep V1, V2, and V3 intact?
> > > > > 
> > > > > 
> > > > > > 
> > > > > > I also don't quite know where to put list2 in the solution you provided below? list2 can be an exact copy of list1 for this example.
> > > > > 
> > > > > In which case it would be nearly trivial:
> > > > > 
> > > > > lapply(dlist, function(x) rbind(x,x) ) 
> > > > > 
> > > > > str( lapply(dlist, function(x) rbind(x,x) ) )
> > > > > List of 3
> > > > > $ V1:'data.frame':	20 obs. of 48 variables:
> > > > > ..$ V1 : int [1:20] 19 94 94 15 90 13 66 17 45 69 ...
> > > > > ..$ V2 : num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
> > > > > ..$ V3 : num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
> > > > > ..$ V4 : num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> > > > > snipped.....
> > > > > 
> > > > > > 
> > > > > > list1 has (48 observations of 3 variables(V1, V2,V3)) each observation has 10 values in a vector 
> > > > > > list2 has (48 observations of 3 variables (V1, V2,V3)) each observation has 10 values in a vector 
> > > > > 
> > > > > You basically want a list of the same general structure as list1 where all the elements in list two at the same position and depth have been concatenated?
> > > > > > 
> > > > > > Output should ideally have (48 observations of 3 variables (V1, V2,V3)) each observation has 20 values in a vector
> > > > > > list1 V1 stacks with list2 V1, 
> > > > > > list1 V2 stacks with list2 V2, 
> > > > > > list1 V3 stacks with list2 V3
> > > > > 
> > > > > You had a bunch of factor variables in list1. Are we assured that the levels of any factor variables in list2 are the same as the corresponding factor variables in list 1?
> > > > > 
> > > > > > 
> > > > > > Boundlist seems to break out the values of each variable(V1,V2,V3) into 10 columns with 1 value in each column.
> > > > > 
> > > > > Not the way I use those words after using R for the last 8 years. There were 48 "columns" and 10 positions in each. I think you need to reverse your terminology (columns and rows) since a "column" in a dataframe is a list and the row numbers are the relative positions along vectors.
> > > > > 
> > > > > 
> > > > > > Is it possible to put the values in the 10 columns(20 values in ideal output) into a vector for each of the 48 observation in each variable(V1,V2,V3).
> > > > > 
> > > > > Having severe trouble reformulating this in R dataframe terminology.
> > > > > 
> > > > > > 
> > > > > > Sorry for all the back and forth - explaining an exact output over email is difficult.
> > > > > 
> > > > > It shouldn't be difficult if you would post data examples with sufficient complexity to represent the problem. I will build a smaller list of dataframe and name it 'smaller'
> > > > > 
> > > > > Since I had difficulty with mapply I'm switching to the list version named ?Map found in the ?funprog page:
> > > > > 
> > > > > smaller <- lapply(dlist, "[", 1:6)
> > > > > 
> > > > > ?Map
> > > > > str( Map( rbind, smaller, smaller))
> > > > > 
> > > > > #------I think this is what you might want----------
> > > > > List of 3
> > > > > $ V1:'data.frame':	20 obs. of 6 variables:
> > > > > ..$ V1: int [1:20] 19 94 94 15 90 13 66 17 45 69 ...
> > > > > ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
> > > > > ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
> > > > > ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> > > > > ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 12 95 95 8 91 6 64 10 41 67 ...
> > > > > ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 12 95 95 8 91 6 64 10 41 67 ...
> > > > > $ V2:'data.frame':	20 obs. of 6 variables:
> > > > > ..$ V1: int [1:20] 93 3 85 34 20 89 16 25 83 90 ...
> > > > > ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
> > > > > ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
> > > > > ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> > > > > ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 94 24 85 29 14 89 9 19 83 91 ...
> > > > > ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 94 24 85 29 14 89 9 19 83 91 ...
> > > > > $ V3:'data.frame':	20 obs. of 6 variables:
> > > > > ..$ V1: int [1:20] 47 95 26 64 16 55 61 39 23 66 ...
> > > > > ..$ V2: num [1:20] 1 1 2 3 4 5 6 7 8 9 ...
> > > > > ..$ V3: num [1:20] NaN NaN NA NA NA NA NA NA NA NA ...
> > > > > ..$ V4: num [1:20] 0 0 0 0 0 0 0 0 0 0 ...
> > > > > ..$ V5: Factor w/ 100 levels "ID1","ID10","ID100",..: 43 96 20 62 9 52 59 34 17 64 ...
> > > > > ..$ V6: Factor w/ 100 levels "Issuer1","Issuer10",..: 43 96 20 62 9 52 59 34 17 64 ...
> > > > > 
> > > > > > 
> > > > > > I really appreciate the help and the effort! 
> > > > > > 
> > > > > > Thank you again!
> > > > > > Vince
> > > > > > 
> > > > > > > Subject: Re: [R] binding two lists of lists of dataframes together
> > > > > > > From: dwinsemius at comcast.net
> > > > > > > Date: Tue, 12 May 2015 14:23:54 -0700
> > > > > > > CC: r-help at r-project.org
> > > > > > > To: newrnewbie at hotmail.com
> > > > > > > 
> > > > > > > 
> > > > > > > On May 12, 2015, at 12:56 PM, Vin Cheng wrote:
> > > > > > > 
> > > > > > > > Hi,
> > > > > > > > 
> > > > > > > > Thanks David! Your solution 3 worked well with the sample data, but when I run solution 2 & 3 on the actual data - it creates a list of 1 for each data point and it doesn't end up looking like the desired output for some reason.
> > > > > > > > 
> > > > > > > > I've run a dput on the actual data and pasted below. There's a lot of data - so I'm only copying list1 - if the solution could bind list1 with itself - it should work just as well. 
> > > > > > > > 
> > > > > > > > Sorry for not providing an accurate sample the first time around - I thought the shortened version would be simpler and sufficient.
> > > > > > > > 
> > > > > > > > Any help/guidance would be greatly appreciated!
> > > > > > > > 
> > > > > > > 
> > > > > > > This appears to be three similarly structured lists of various classes but fortunately for this effort the factor variables in corresponding columns all have the same levels. (Otherwise one would need to convert to character before attempting to stack them.)
> > > > > > > 
> > > > > > > I would just use `rbind.data.frame` (after making them dataframes with the same column names.)
> > > > > > > 
> > > > > > > 
> > > > > > > dlist <- lapply( list1, function(d) setNames( data.frame(d), paste0("V", 1:48) ))
> > > > > > > boundlist <- do.call(rbind, dlist)
> > > > > > > 
> > > > > > > # Done.
> > > > > > > 
> > > > > > > -- 
> > > > > > > David.
> > > > > > > > Many Thanks,
> > > > > > > > Vince
> > > > > > > > 
> > > > > > > > list1 <- structure(list(V1 = list(c(19L, 94L, 94L, 15L, 90L, 13L, 66L, 
> > > > > > > > 17L, 45L, 69L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, 
> > > > > > > > NA, NA, NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 
> > > > > > > > 0), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
> > > > > > > > ), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", "ID13", 
> > > > > > > > "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", "ID2", "ID20", 
> > > > > > > > "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", "ID27", "ID28", 
> > > > > > > > "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", "ID34", "ID35", 
> > > > > > > > "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", "ID41", "ID42", 
> > > > > > > > "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", 
> > > > > > > > "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
> > > > > > > > "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", "ID64", 
> > > > > > > > "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", "ID70", "ID71", 
> > > > > > > > "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", "ID78", "ID79", 
> > > > > > > > "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", "ID85", "ID86", 
> > > > > > > > "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", "ID92", "ID93", 
> > > > > > > > "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"), class = "factor"), 
> > > > > > > > structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L
> > > > > > > > ), .Label = c("Issuer1", "Issuer10", "Issuer100", "Issuer11", 
> > > > > > > > "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
> > > > > > > > "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", 
> > > > > > > > "Issuer21", "Issuer22", "Issuer23", "Issuer24", "Issuer25", 
> > > > > > > > "Issuer26", "Issuer27", "Issuer28", "Issuer29", "Issuer3", 
> > > > > > > > "Issuer30", "Issuer31", "Issuer32", "Issuer33", "Issuer34", 
> > > > > > > > "Issuer35", "Issuer36", "Issuer37", "Issuer38", "Issuer39", 
> > > > > > > > "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
> > > > > > > > "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", 
> > > > > > > > "Issuer49", "Issuer5", "Issuer50", "Issuer51", "Issuer52", 
> > > > > > > > "Issuer53", "Issuer54", "Issuer55", "Issuer56", "Issuer57", 
> > > > > > > > "Issuer58", "Issuer59", "Issuer6", "Issuer60", "Issuer61", 
> > > > > > > > "Issuer62", "Issuer63", "Issuer64", "Issuer65", "Issuer66", 
> > > > > > > > "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
> > > > > > > > "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", 
> > > > > > > > "Issuer76", "Issuer77", "Issuer78", "Issuer79", "Issuer8", 
> > > > > > > > "Issuer80", "Issuer81", "Issuer82", "Issuer83", "Issuer84", 
> > > > > > > > "Issuer85", "Issuer86", "Issuer87", "Issuer88", "Issuer89", 
> > > > > > > > "Issuer9", "Issuer90", "Issuer91", "Issuer92", "Issuer93", 
> > > > > > > > "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
> > > > > > > > "Issuer99"), class = "factor"), c(95.5, 98.5, 98.5, 99.5, 
> > > > > > > > 103.5, 98.563, 99.75, 98.5, 98.75, 99.125), c(97.5, 99.5, 
> > > > > > > > 99.5, 100.375, 104.5, 99.188, 100.25, 99.5, 99.75, 100.063
> > > > > > > > ), c(2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 4L), c(4L, 5L, 5L, 
> > > > > > > > 5L, 5L, 2L, 3L, 5L, 3L, 2L), c(TRUE, FALSE, FALSE, TRUE, 
> > > > > > > > FALSE, TRUE, TRUE, FALSE, FALSE, TRUE), structure(c(1L, 1L, 
> > > > > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > > > structure(c(9L, 2L, 2L, 1L, 2L, 1L, 3L, 3L, 5L, 9L), .Label = c("B", 
> > > > > > > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
> > > > > > > > ), class = "factor"), structure(c(8L, 2L, 2L, 1L, 8L, 2L, 
> > > > > > > > 2L, 2L, 1L, 7L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
> > > > > > > > "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(20L, 
> > > > > > > > 88L, 88L, 6L, 3L, 35L, 29L, 24L, 53L, 82L), .Label = c("1/11/2019", 
> > > > > > > > "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
> > > > > > > > "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > > > > > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
> > > > > > > > "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
> > > > > > > > "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
> > > > > > > > "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
> > > > > > > > "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
> > > > > > > > "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
> > > > > > > > "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
> > > > > > > > "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
> > > > > > > > "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
> > > > > > > > "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
> > > > > > > > "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
> > > > > > > > "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
> > > > > > > > "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
> > > > > > > > "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
> > > > > > > > "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
> > > > > > > > "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
> > > > > > > > "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
> > > > > > > > c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > > > > > > FALSE, FALSE), structure(c(12L, 95L, 95L, 8L, 91L, 6L, 64L, 
> > > > > > > > 10L, 41L, 67L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > > > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > > > > > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > > > > > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > > > > > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > > > > > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > > > > > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > > > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > > > > > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > > > > > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > > > > > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > > > > > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > > > > > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > > > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > > > > > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > > > > > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > > > > > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > > > > > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > > > > > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > > > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > > > > > > "Issuer98", "Issuer99"), class = "factor"), structure(c(12L, 
> > > > > > > > 95L, 95L, 8L, 91L, 6L, 64L, 10L, 41L, 67L), .Label = c("BL1", 
> > > > > > > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > > > > > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
> > > > > > > > "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
> > > > > > > > "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
> > > > > > > > "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
> > > > > > > > "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
> > > > > > > > "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
> > > > > > > > "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > > > > > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
> > > > > > > > "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
> > > > > > > > "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
> > > > > > > > "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
> > > > > > > > "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(4L, 
> > > > > > > > 3L, 3L, 5L, 6L, 3L, 2L, 6L, 6L, 5L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > > > > > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > > > > > > "Retail", "Services: Business"), class = "factor"), structure(c(3L, 
> > > > > > > > 5L, 5L, 6L, 4L, 3L, 4L, 2L, 6L, 6L), .Label = c("Financial Intermediaries", 
> > > > > > > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > > > > > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > > > > > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 6L, 8L, 8L), .Label = c("AU", 
> > > > > > > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > > > > > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 5L, 6L, 6L), .Label = c("1", 
> > > > > > > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > > > > > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L), .Label = c("Canada", 
> > > > > > > > "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
> > > > > > > > 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > > > > > > structure(c(2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > > > > > > "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > > > > > 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > > > > > > c(0.125550168, 1.731733265, 1.731733265, NA, 5.246485518, 
> > > > > > > > 7.798802147, NA, NA, NA, NA), c(4770L, 3490L, 3490L, 3490L, 
> > > > > > > > 3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.45, 0.4, 0.4, 
> > > > > > > > 0.45, 0.55, 0.4, 0.4, 0.45, 0.4, 0.5), c(4770L, 3490L, 3490L, 
> > > > > > > > 3490L, 3490L, 3490L, 2220L, 2220L, 2220L, 3490L), c(0.55, 
> > > > > > > > 0.4, 0.4, 0.4, 0.55, 0.4, 0.5, 0.5, 0.45, 0.55), c(18L, 15L, 
> > > > > > > > 15L, 15L, 18L, 15L, 15L, 15L, 14L, 17L), c(17L, 16L, 16L, 
> > > > > > > > 15L, 14L, 15L, 15L, 15L, 14L, 15L), c(192500000, 205000000, 
> > > > > > > > 205000000, 342000000, 120000000, 835000000, 1043700000, 160000000, 
> > > > > > > > 300000000, 265000000), c(0.02, 0.02, 0.02, 0.4, 0.02, 0.4, 
> > > > > > > > 0.6, 0.6, 0.6, 0.02), c(850L, 475L, 475L, 500L, 1000L, 350L, 
> > > > > > > > 400L, 975L, 500L, 700L), c(1, 1.5, 1.5, 1, 1.25, 1, 1, 1, 
> > > > > > > > 1, 1), c(0.0851, 0.04765, 0.04765, 0.0501, 0.100125, 0.0351, 
> > > > > > > > 0.0401, 0.0976, 0.0501, 0.0701), c(0.099192999, 0.023321348, 
> > > > > > > > 0.023321348, 0.06465519, 0.103470278, 0.052237196, 0.051331755, 
> > > > > > > > 0.112300026, 0.066116739, 0.084107871), c(897.0917677, -1.49365213, 
> > > > > > > > -1.49365213, 549.0886934, 975.9481504, 429.1863229, 436.2991366, 
> > > > > > > > 1062.374805, 567.0741295, 747.1023728), c(0.088186528, 0.048131313, 
> > > > > > > > 0.048131313, 0.050131332, 0.096274038, 0.035499188, 0.040049938, 
> > > > > > > > 0.098585859, 0.050478589, 0.070385766), c(0L, 0L, 0L, 0L, 
> > > > > > > > 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > > > > > 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
> > > > > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > > > > > > c(0.0178406708595388, 0.0136532951289398, 0.0136532951289398, 
> > > > > > > > 0.0143553008595989, 0.028689111747851, 0.0100573065902579, 
> > > > > > > > 0.0180630630630631, 0.043963963963964, 0.0225675675675676, 
> > > > > > > > 0.0200859598853868), c(0.046805, 0.01906, 0.01906, 0.02004, 
> > > > > > > > 0.05506875, 0.01404, 0.02005, 0.0488, 0.022545, 0.038555), 
> > > > > > > > c(0.001702, 0.000953, 0.000953, 0.02004, 0.0020025, 0.01404, 
> > > > > > > > 0.02406, 0.05856, 0.03006, 0.001402)), V2 = list(c(93L, 3L, 
> > > > > > > > 85L, 34L, 20L, 89L, 16L, 25L, 83L, 90L), c(1, 1, 2, 3, 4, 5, 
> > > > > > > > 6, 7, 8, 9), c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA), c(0, 
> > > > > > > > 0, 0, 0, 0, 0, 0, 0, 0, 0), structure(c(94L, 24L, 85L, 29L, 14L, 
> > > > > > > > 89L, 9L, 19L, 83L, 91L), .Label = c("ID1", "ID10", "ID100", "ID11", 
> > > > > > > > "ID12", "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
> > > > > > > > "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", "ID26", 
> > > > > > > > "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", "ID32", "ID33", 
> > > > > > > > "ID34", "ID35", "ID36", "ID37", "ID38", "ID39", "ID4", "ID40", 
> > > > > > > > "ID41", "ID42", "ID43", "ID44", "ID45", "ID46", "ID47", "ID48", 
> > > > > > > > "ID49", "ID5", "ID50", "ID51", "ID52", "ID53", "ID54", "ID55", 
> > > > > > > > "ID56", "ID57", "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", 
> > > > > > > > "ID63", "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
> > > > > > > > "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", "ID77", 
> > > > > > > > "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", "ID83", "ID84", 
> > > > > > > > "ID85", "ID86", "ID87", "ID88", "ID89", "ID9", "ID90", "ID91", 
> > > > > > > > "ID92", "ID93", "ID94", "ID95", "ID96", "ID97", "ID98", "ID99"
> > > > > > > > ), class = "factor"), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
> > > > > > > > 9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > > > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", "Issuer16", 
> > > > > > > > "Issuer17", "Issuer18", "Issuer19", "Issuer2", "Issuer20", "Issuer21", 
> > > > > > > > "Issuer22", "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
> > > > > > > > "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", "Issuer32", 
> > > > > > > > "Issuer33", "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > > > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", "Issuer43", 
> > > > > > > > "Issuer44", "Issuer45", "Issuer46", "Issuer47", "Issuer48", "Issuer49", 
> > > > > > > > "Issuer5", "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
> > > > > > > > "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", "Issuer6", 
> > > > > > > > "Issuer60", "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > > > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", "Issuer70", 
> > > > > > > > "Issuer71", "Issuer72", "Issuer73", "Issuer74", "Issuer75", "Issuer76", 
> > > > > > > > "Issuer77", "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
> > > > > > > > "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", "Issuer87", 
> > > > > > > > "Issuer88", "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > > > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", "Issuer98", 
> > > > > > > > "Issuer99"), class = "factor"), c(99.5, 99.646, 100.402, 100.25, 
> > > > > > > > 98, 99.563, 99.563, 99.388, 99.531, 103.5), c(100.5, 100.271, 
> > > > > > > > 100.903, 100.75, 99, 100.188, 100.063, 99.788, 100.125, 104.5
> > > > > > > > ), c(1L, 6L, 9L, 1L, 1L, 2L, 2L, 10L, 4L, 2L), c(5L, 2L, 1L, 
> > > > > > > > 3L, 3L, 4L, 4L, 1L, 1L, 5L), c(TRUE, TRUE, FALSE, FALSE, TRUE, 
> > > > > > > > FALSE, FALSE, TRUE, TRUE, FALSE), structure(c(1L, 1L, 1L, 1L, 
> > > > > > > > 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > > > structure(c(8L, 1L, 4L, 1L, 3L, 4L, 6L, 1L, 5L, 2L), .Label = c("B", 
> > > > > > > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", "NR"
> > > > > > > > ), class = "factor"), structure(c(7L, 2L, 5L, 2L, 1L, 2L, 
> > > > > > > > 6L, 1L, 5L, 8L), .Label = c("B1", "B2", "B3", "Ba1", "Ba2", 
> > > > > > > > "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), structure(c(41L, 
> > > > > > > > 1L, 13L, 43L, 21L, 87L, 49L, 73L, 46L, 3L), .Label = c("1/11/2019", 
> > > > > > > > "1/2/2019", "1/2/2020", "1/30/2022", "10/15/2016", "10/15/2021", 
> > > > > > > > "10/17/2019", "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > > > > > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", "11/12/2020", 
> > > > > > > > "11/20/2019", "11/20/2020", "11/27/2020", "11/5/2021", "11/6/2020", 
> > > > > > > > "11/9/2017", "11/9/2018", "12/15/2018", "12/15/2021", "12/15/2022", 
> > > > > > > > "12/16/2019", "12/18/2020", "12/20/2019", "12/7/2018", "12/7/2019", 
> > > > > > > > "2/12/2021", "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", 
> > > > > > > > "2/24/2017", "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", 
> > > > > > > > "3/21/2019", "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", 
> > > > > > > > "4/30/2018", "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", 
> > > > > > > > "5/15/2018", "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", 
> > > > > > > > "5/8/2020", "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", 
> > > > > > > > "6/2/2019", "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", 
> > > > > > > > "6/30/2017", "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", 
> > > > > > > > "7/10/2020", "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", 
> > > > > > > > "7/29/2022", "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", 
> > > > > > > > "8/12/2021", "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", 
> > > > > > > > "8/24/2017", "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", 
> > > > > > > > "9/18/2016", "9/18/2019", "9/20/2019"), class = "factor"), 
> > > > > > > > c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > > > > > > FALSE, FALSE), structure(c(94L, 24L, 85L, 29L, 14L, 89L, 
> > > > > > > > 9L, 19L, 83L, 91L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > > > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > > > > > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > > > > > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > > > > > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > > > > > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > > > > > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > > > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > > > > > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > > > > > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > > > > > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > > > > > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > > > > > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > > > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > > > > > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > > > > > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > > > > > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > > > > > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > > > > > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > > > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > > > > > > "Issuer98", "Issuer99"), class = "factor"), structure(c(94L, 
> > > > > > > > 24L, 85L, 29L, 14L, 89L, 9L, 19L, 83L, 91L), .Label = c("BL1", 
> > > > > > > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > > > > > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", "BL22", 
> > > > > > > > "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", "BL29", "BL3", 
> > > > > > > > "BL30", "BL31", "BL32", "BL33", "BL34", "BL35", "BL36", "BL37", 
> > > > > > > > "BL38", "BL39", "BL4", "BL40", "BL41", "BL42", "BL43", "BL44", 
> > > > > > > > "BL45", "BL46", "BL47", "BL48", "BL49", "BL5", "BL50", "BL51", 
> > > > > > > > "BL52", "BL53", "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", 
> > > > > > > > "BL6", "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > > > > > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", "BL73", 
> > > > > > > > "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", "BL8", "BL80", 
> > > > > > > > "BL81", "BL82", "BL83", "BL84", "BL85", "BL86", "BL87", "BL88", 
> > > > > > > > "BL89", "BL9", "BL90", "BL91", "BL92", "BL93", "BL94", "BL95", 
> > > > > > > > "BL96", "BL97", "BL98", "BL99"), class = "factor"), structure(c(2L, 
> > > > > > > > 2L, 3L, 6L, 1L, 6L, 6L, 6L, 1L, 6L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > > > > > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > > > > > > "Retail", "Services: Business"), class = "factor"), structure(c(6L, 
> > > > > > > > 6L, 3L, 5L, 1L, 2L, 5L, 3L, 2L, 4L), .Label = c("Financial Intermediaries", 
> > > > > > > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > > > > > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > > > > > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L), .Label = c("AU", 
> > > > > > > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > > > > > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label = c("1", 
> > > > > > > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > > > > > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("Canada", 
> > > > > > > > "Europe", "Other", "U.S."), class = "factor"), structure(c(1L, 
> > > > > > > > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > > > > > > structure(c(2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > > > > > > "Y"), class = "factor"), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > > > > > 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > > > > > > c(2.603554841, 7.27032758, 3.155438813, 5.037267081, 0.125550168, 
> > > > > > > > NA, 3.464301168, NA, 4.816376964, 5.246485518), c(2220L, 
> > > > > > > > 2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 2220L, 3490L
> > > > > > > > ), c(0.55, 0.45, 0.5, 0.4, 0.6, 0.45, 0.45, 0.55, 0.2, 0.55
> > > > > > > > ), c(2220L, 2220L, 940L, 3490L, 4770L, 2220L, 1766L, 3490L, 
> > > > > > > > 2220L, 3490L), c(0.55, 0.45, 0.5, 0.4, 0.3, 0.45, 0.45, 0.4, 
> > > > > > > > 0.2, 0.55), c(17L, 15L, 12L, 15L, 14L, 15L, 13L, 14L, 12L, 
> > > > > > > > 18L), c(16L, 16L, 14L, 16L, 15L, 12L, 13L, 15L, 14L, 14L), 
> > > > > > > > c(200000000, 613811406, 750000000, 200000000, 405500000, 
> > > > > > > > 450000000, 530000000, 2010000000, 775000000, 120000000), 
> > > > > > > > c(0.02, 0.5, 0.65, 0.27, 0.5, 0.65, 0.65, 0.3, 0.65, 0.02
> > > > > > > > ), c(950L, 350L, 350L, 275L, 450L, 275L, 225L, 325L, 275L, 
> > > > > > > > 1000L), c(1.25, 1, 0.75, 0.75, 1, 0.75, 0, 1, 0.75, 1.25), 
> > > > > > > > c(0.095125, 0.0351, 0.035075, 0.027575, 0.0451, 0.027575, 
> > > > > > > > 0.02527, 0.0326, 0.027575, 0.100125), c(0.104211455, 0.046414939, 
> > > > > > > > 0.050338657, 0.027233401, 0.059885473, 0.03459045, 0.028669191, 
> > > > > > > > 0.048294163, 0.040935438, 0.103470278), c(980.5501911, 400.3544693, 
> > > > > > > > 385.8629241, 244.6340073, 511.2711809, 294.3073789, 194.2034583, 
> > > > > > > > 385.9437059, 308.4324006, 975.9481504), c(0.095125, 0.035114573, 
> > > > > > > > 0.034847619, 0.027437811, 0.045786802, 0.027609374, 0.025317343, 
> > > > > > > > 0.032734868, 0.027622511, 0.096274038), c(0L, 0L, 0L, 0L, 
> > > > > > > > 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 1L, 1L, 1L, 1L, 
> > > > > > > > 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), structure(c(1L, 
> > > > > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > > > > > > c(0.0428490990990991, 0.0158108108108108, 0.037313829787234, 
> > > > > > > > 0.00790114613180516, 0.00945492662473794, 0.0124211711711712, 
> > > > > > > > 0.0143091732729332, 0.00934097421203438, 0.0124211711711712, 
> > > > > > > > 0.028689111747851), c(0.05231875, 0.015795, 0.0175375, 0.01103, 
> > > > > > > > 0.01353, 0.01240875, 0.0113715, 0.01304, 0.005515, 0.05506875
> > > > > > > > ), c(0.0019025, 0.01755, 0.02279875, 0.00744525, 0.02255, 
> > > > > > > > 0.01792375, 0.0164255, 0.00978, 0.01792375, 0.0020025)), 
> > > > > > > > V3 = list(c(47L, 95L, 26L, 64L, 16L, 55L, 61L, 39L, 23L, 
> > > > > > > > 66L), c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), c(NaN, NaN, NA, NA, 
> > > > > > > > NA, NA, NA, NA, NA, NA), c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
> > > > > > > > structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 
> > > > > > > > 64L), .Label = c("ID1", "ID10", "ID100", "ID11", "ID12", 
> > > > > > > > "ID13", "ID14", "ID15", "ID16", "ID17", "ID18", "ID19", 
> > > > > > > > "ID2", "ID20", "ID21", "ID22", "ID23", "ID24", "ID25", 
> > > > > > > > "ID26", "ID27", "ID28", "ID29", "ID3", "ID30", "ID31", 
> > > > > > > > "ID32", "ID33", "ID34", "ID35", "ID36", "ID37", "ID38", 
> > > > > > > > "ID39", "ID4", "ID40", "ID41", "ID42", "ID43", "ID44", 
> > > > > > > > "ID45", "ID46", "ID47", "ID48", "ID49", "ID5", "ID50", 
> > > > > > > > "ID51", "ID52", "ID53", "ID54", "ID55", "ID56", "ID57", 
> > > > > > > > "ID58", "ID59", "ID6", "ID60", "ID61", "ID62", "ID63", 
> > > > > > > > "ID64", "ID65", "ID66", "ID67", "ID68", "ID69", "ID7", 
> > > > > > > > "ID70", "ID71", "ID72", "ID73", "ID74", "ID75", "ID76", 
> > > > > > > > "ID77", "ID78", "ID79", "ID8", "ID80", "ID81", "ID82", 
> > > > > > > > "ID83", "ID84", "ID85", "ID86", "ID87", "ID88", "ID89", 
> > > > > > > > "ID9", "ID90", "ID91", "ID92", "ID93", "ID94", "ID95", 
> > > > > > > > "ID96", "ID97", "ID98", "ID99"), class = "factor"), structure(c(43L, 
> > > > > > > > 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("Issuer1", 
> > > > > > > > "Issuer10", "Issuer100", "Issuer11", "Issuer12", "Issuer13", 
> > > > > > > > "Issuer14", "Issuer15", "Issuer16", "Issuer17", "Issuer18", 
> > > > > > > > "Issuer19", "Issuer2", "Issuer20", "Issuer21", "Issuer22", 
> > > > > > > > "Issuer23", "Issuer24", "Issuer25", "Issuer26", "Issuer27", 
> > > > > > > > "Issuer28", "Issuer29", "Issuer3", "Issuer30", "Issuer31", 
> > > > > > > > "Issuer32", "Issuer33", "Issuer34", "Issuer35", "Issuer36", 
> > > > > > > > "Issuer37", "Issuer38", "Issuer39", "Issuer4", "Issuer40", 
> > > > > > > > "Issuer41", "Issuer42", "Issuer43", "Issuer44", "Issuer45", 
> > > > > > > > "Issuer46", "Issuer47", "Issuer48", "Issuer49", "Issuer5", 
> > > > > > > > "Issuer50", "Issuer51", "Issuer52", "Issuer53", "Issuer54", 
> > > > > > > > "Issuer55", "Issuer56", "Issuer57", "Issuer58", "Issuer59", 
> > > > > > > > "Issuer6", "Issuer60", "Issuer61", "Issuer62", "Issuer63", 
> > > > > > > > "Issuer64", "Issuer65", "Issuer66", "Issuer67", "Issuer68", 
> > > > > > > > "Issuer69", "Issuer7", "Issuer70", "Issuer71", "Issuer72", 
> > > > > > > > "Issuer73", "Issuer74", "Issuer75", "Issuer76", "Issuer77", 
> > > > > > > > "Issuer78", "Issuer79", "Issuer8", "Issuer80", "Issuer81", 
> > > > > > > > "Issuer82", "Issuer83", "Issuer84", "Issuer85", "Issuer86", 
> > > > > > > > "Issuer87", "Issuer88", "Issuer89", "Issuer9", "Issuer90", 
> > > > > > > > "Issuer91", "Issuer92", "Issuer93", "Issuer94", "Issuer95", 
> > > > > > > > "Issuer96", "Issuer97", "Issuer98", "Issuer99"), class = "factor"), 
> > > > > > > > c(99.688, 75.667, 99.229, 99.583, 99.563, 99.188, 98.8, 
> > > > > > > > 98.5, 99, 99.75), c(100.281, 78.667, 100.104, 100.333, 
> > > > > > > > 100.063, 99.906, 99.75, 99.5, 99.75, 100.25), c(4L, 3L, 
> > > > > > > > 6L, 3L, 2L, 4L, 5L, 1L, 1L, 1L), c(4L, 3L, 1L, 3L, 4L, 
> > > > > > > > 2L, 4L, 5L, 3L, 3L), c(FALSE, TRUE, TRUE, TRUE, FALSE, 
> > > > > > > > TRUE, TRUE, FALSE, TRUE, TRUE), structure(c(1L, 1L, 1L, 
> > > > > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "First", class = "factor"), 
> > > > > > > > structure(c(3L, 8L, 9L, 1L, 6L, 3L, 10L, 10L, 9L, 3L), .Label = c("B", 
> > > > > > > > "B-", "B+", "BB", "BB-", "BB+", "BBB-", "CCC", "CCC+", 
> > > > > > > > "NR"), class = "factor"), structure(c(6L, 7L, 7L, 2L, 
> > > > > > > > 6L, 1L, 9L, 9L, 8L, 2L), .Label = c("B1", "B2", "B3", 
> > > > > > > > "Ba1", "Ba2", "Ba3", "Caa1", "Caa2", "NR"), class = "factor"), 
> > > > > > > > structure(c(66L, 80L, 74L, 30L, 49L, 72L, 70L, 62L, 10L, 
> > > > > > > > 29L), .Label = c("1/11/2019", "1/2/2019", "1/2/2020", 
> > > > > > > > "1/30/2022", "10/15/2016", "10/15/2021", "10/17/2019", 
> > > > > > > > "10/17/2021", "10/19/2019", "10/2/2017", "10/22/2020", 
> > > > > > > > "10/31/2018", "10/8/2021", "10/9/2018", "10/9/2019", 
> > > > > > > > "11/12/2020", "11/20/2019", "11/20/2020", "11/27/2020", 
> > > > > > > > "11/5/2021", "11/6/2020", "11/9/2017", "11/9/2018", "12/15/2018", 
> > > > > > > > "12/15/2021", "12/15/2022", "12/16/2019", "12/18/2020", 
> > > > > > > > "12/20/2019", "12/7/2018", "12/7/2019", "2/12/2021", 
> > > > > > > > "2/14/2020", "2/20/2021", "2/21/2021", "2/21/2022", "2/24/2017", 
> > > > > > > > "2/26/2019", "2/6/2019", "3/20/2018", "3/20/2020", "3/21/2019", 
> > > > > > > > "4/11/2016", "4/11/2020", "4/17/2021", "4/23/2020", "4/30/2018", 
> > > > > > > > "4/5/2020", "5/11/2018", "5/14/2021", "5/14/2022", "5/15/2018", 
> > > > > > > > "5/20/2021", "5/22/2021", "5/22/2022", "5/31/2020", "5/8/2020", 
> > > > > > > > "6/13/2018", "6/17/2021", "6/19/2021", "6/19/2022", "6/2/2019", 
> > > > > > > > "6/20/2017", "6/27/2019", "6/3/2019", "6/30/2016", "6/30/2017", 
> > > > > > > > "6/30/2019", "6/5/2020", "6/7/2021", "7/10/2018", "7/10/2020", 
> > > > > > > > "7/11/2021", "7/11/2022", "7/2/2021", "7/29/2021", "7/29/2022", 
> > > > > > > > "7/3/2019", "7/9/2020", "7/9/2021", "8/1/2021", "8/12/2021", 
> > > > > > > > "8/14/2019", "8/15/2021", "8/20/2021", "8/23/2019", "8/24/2017", 
> > > > > > > > "8/29/2021", "8/3/2018", "8/7/2017", "8/7/2019", "9/18/2016", 
> > > > > > > > "9/18/2019", "9/20/2019"), class = "factor"), c(FALSE, 
> > > > > > > > FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
> > > > > > > > FALSE), structure(c(43L, 96L, 20L, 62L, 9L, 52L, 59L, 
> > > > > > > > 34L, 17L, 64L), .Label = c("Issuer1", "Issuer10", "Issuer100", 
> > > > > > > > "Issuer11", "Issuer12", "Issuer13", "Issuer14", "Issuer15", 
> > > > > > > > "Issuer16", "Issuer17", "Issuer18", "Issuer19", "Issuer2", 
> > > > > > > > "Issuer20", "Issuer21", "Issuer22", "Issuer23", "Issuer24", 
> > > > > > > > "Issuer25", "Issuer26", "Issuer27", "Issuer28", "Issuer29", 
> > > > > > > > "Issuer3", "Issuer30", "Issuer31", "Issuer32", "Issuer33", 
> > > > > > > > "Issuer34", "Issuer35", "Issuer36", "Issuer37", "Issuer38", 
> > > > > > > > "Issuer39", "Issuer4", "Issuer40", "Issuer41", "Issuer42", 
> > > > > > > > "Issuer43", "Issuer44", "Issuer45", "Issuer46", "Issuer47", 
> > > > > > > > "Issuer48", "Issuer49", "Issuer5", "Issuer50", "Issuer51", 
> > > > > > > > "Issuer52", "Issuer53", "Issuer54", "Issuer55", "Issuer56", 
> > > > > > > > "Issuer57", "Issuer58", "Issuer59", "Issuer6", "Issuer60", 
> > > > > > > > "Issuer61", "Issuer62", "Issuer63", "Issuer64", "Issuer65", 
> > > > > > > > "Issuer66", "Issuer67", "Issuer68", "Issuer69", "Issuer7", 
> > > > > > > > "Issuer70", "Issuer71", "Issuer72", "Issuer73", "Issuer74", 
> > > > > > > > "Issuer75", "Issuer76", "Issuer77", "Issuer78", "Issuer79", 
> > > > > > > > "Issuer8", "Issuer80", "Issuer81", "Issuer82", "Issuer83", 
> > > > > > > > "Issuer84", "Issuer85", "Issuer86", "Issuer87", "Issuer88", 
> > > > > > > > "Issuer89", "Issuer9", "Issuer90", "Issuer91", "Issuer92", 
> > > > > > > > "Issuer93", "Issuer94", "Issuer95", "Issuer96", "Issuer97", 
> > > > > > > > "Issuer98", "Issuer99"), class = "factor"), structure(c(43L, 
> > > > > > > > 96L, 20L, 62L, 9L, 52L, 59L, 34L, 17L, 64L), .Label = c("BL1", 
> > > > > > > > "BL10", "BL100", "BL11", "BL12", "BL13", "BL14", "BL15", 
> > > > > > > > "BL16", "BL17", "BL18", "BL19", "BL2", "BL20", "BL21", 
> > > > > > > > "BL22", "BL23", "BL24", "BL25", "BL26", "BL27", "BL28", 
> > > > > > > > "BL29", "BL3", "BL30", "BL31", "BL32", "BL33", "BL34", 
> > > > > > > > "BL35", "BL36", "BL37", "BL38", "BL39", "BL4", "BL40", 
> > > > > > > > "BL41", "BL42", "BL43", "BL44", "BL45", "BL46", "BL47", 
> > > > > > > > "BL48", "BL49", "BL5", "BL50", "BL51", "BL52", "BL53", 
> > > > > > > > "BL54", "BL55", "BL56", "BL57", "BL58", "BL59", "BL6", 
> > > > > > > > "BL60", "BL61", "BL62", "BL63", "BL64", "BL65", "BL66", 
> > > > > > > > "BL67", "BL68", "BL69", "BL7", "BL70", "BL71", "BL72", 
> > > > > > > > "BL73", "BL74", "BL75", "BL76", "BL77", "BL78", "BL79", 
> > > > > > > > "BL8", "BL80", "BL81", "BL82", "BL83", "BL84", "BL85", 
> > > > > > > > "BL86", "BL87", "BL88", "BL89", "BL9", "BL90", "BL91", 
> > > > > > > > "BL92", "BL93", "BL94", "BL95", "BL96", "BL97", "BL98", 
> > > > > > > > "BL99"), class = "factor"), structure(c(1L, 6L, 6L, 4L, 
> > > > > > > > 6L, 4L, 6L, 2L, 6L, 2L), .Label = c("Banking, Finance, Insurance & Real Estate", 
> > > > > > > > "Consumer goods: Non-durable", "Energy: Oil & Gas", "Hotel, Gaming, & Leisure", 
> > > > > > > > "Retail", "Services: Business"), class = "factor"), structure(c(2L, 
> > > > > > > > 2L, 1L, 5L, 5L, 3L, 3L, 6L, 2L, 4L), .Label = c("Financial Intermediaries", 
> > > > > > > > "Health care", "Leisure goods/activities/movies", "Multiline Retail", 
> > > > > > > > "Oil & gas", "Retailers (except food & drug)"), class = "factor"), 
> > > > > > > > structure(c(8L, 8L, 8L, 8L, 8L, 8L, 5L, 8L, 8L, 8L), .Label = c("AU", 
> > > > > > > > "BE", "CA", "DE", "FR", "GB", "LU", "US"), class = "factor"), 
> > > > > > > > structure(c(6L, 6L, 6L, 6L, 6L, 6L, 3L, 6L, 6L, 6L), .Label = c("1", 
> > > > > > > > "2", "3", "Tax Jurisdiction", "UK", "US"), class = "factor"), 
> > > > > > > > structure(c(4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L, 4L), .Label = c("Canada", 
> > > > > > > > "Europe", "Other", "U.S."), class = "factor"), structure(c(2L, 
> > > > > > > > 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), .Label = c("N", 
> > > > > > > > "Y"), class = "factor"), structure(c(1L, 2L, 2L, 1L, 
> > > > > > > > 1L, 1L, 2L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
> > > > > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "FLOATING", class = "factor"), 
> > > > > > > > c(8.74248921, NA, NA, 4.338507174, 3.464301168, NA, NA, 
> > > > > > > > NA, NA, NA), c(2220L, 2220L, 3490L, 3490L, 1766L, 2220L, 
> > > > > > > > 8070L, 8070L, 3490L, 2220L), c(0.6, 0.55, 0.4, 0.4, 0.45, 
> > > > > > > > 0.45, 0.4, 0.45, 0.6, 0.4), c(2220L, 2220L, 3490L, 3490L, 
> > > > > > > > 1766L, 2220L, 8070L, 8070L, 3490L, 2220L), c(0.3, 0.55, 
> > > > > > > > 0.55, 0.4, 0.45, 0.4, 0.45, 0.3, 0.55, 0.5), c(13L, 17L, 
> > > > > > > > 17L, 15L, 13L, 14L, 19L, 19L, 18L, 15L), c(15L, 16L, 
> > > > > > > > 15L, 15L, 13L, 14L, 19L, 19L, 15L, 15L), c(625000000, 
> > > > > > > > 450000000, 760000000, 630000000, 530000000, 671500000, 
> > > > > > > > 240000000, 100000000, 375000000, 1043700000), c(0.5, 
> > > > > > > > 0.02, 0.02, 0.3, 0.65, 0.3, 0.5, 0.65, 0.02, 0.6), c(275L, 
> > > > > > > > 750L, 650L, 300L, 225L, 300L, 700L, 925L, 825L, 400L), 
> > > > > > > > c(0, 1, 1, 1.25, 0, 1, 1, 1.25, 1.25, 1), c(0.03027, 
> > > > > > > > 0.0751, 0.0651, 0.030125, 0.02527, 0.0301, 0.0701, 0.092625, 
> > > > > > > > 0.082625, 0.0401), c(0.031286195, 0.154827358, 0.080695261, 
> > > > > > > > 0.041683558, 0.028669191, 0.044131997, 0.084009559, 0.108958135, 
> > > > > > > > 0.090916682, 0.051331755), c(263.290277, 1448.101305, 
> > > > > > > > 704.3633733, 368.0708419, 194.2034583, 356.3784942, 746.772345, 
> > > > > > > > 1036.334285, 875.917553, 436.2991366), c(0.030274693, 
> > > > > > > > 0.097321394, 0.065317835, 0.030137658, 0.025317343, 0.030236973, 
> > > > > > > > 0.070611937, 0.093560606, 0.083144654, 0.040049938), 
> > > > > > > > c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), structure(c(1L, 
> > > > > > > > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "NO", class = "factor"), 
> > > > > > > > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "CS", class = "factor"), 
> > > > > > > > c(0.0136351351351351, 0.0338288288288288, 0.0186532951289398, 
> > > > > > > > 0.00863180515759312, 0.0143091732729332, 0.0135585585585586, 
> > > > > > > > 0.00868649318463445, 0.0114776951672862, 0.0236747851002865, 
> > > > > > > > 0.0180630630630631), c(0.009081, 0.041305, 0.035805, 
> > > > > > > > 0.01205, 0.0113715, 0.01204, 0.031545, 0.0277875, 0.04544375, 
> > > > > > > > 0.02005), c(0.015135, 0.001502, 0.001302, 0.0090375, 
> > > > > > > > 0.0164255, 0.00903, 0.03505, 0.06020625, 0.0016525, 0.02406
> > > > > > > > ))), .Names = c("V1", "V2", "V3"), row.names = c(NA, 
> > > > > > > > -48L), class = c("data.table", "data.frame"))
> > > > > > > > 
> > > > > > > > 
> > > > > > > > 
> > > > > > > >> Subject: Re: [R] binding two lists of lists of dataframes together
> > > > > > > >> From: dwinsemius at comcast.net
> > > > > > > >> Date: Tue, 12 May 2015 11:36:50 -0700
> > > > > > > >> CC: r-help at r-project.org
> > > > > > > >> To: newrnewbie at hotmail.com
> > > > > > > >> 
> > > > > > > >> 
> > > > > > > >> On May 12, 2015, at 9:24 AM, Vin Cheng wrote:
> > > > > > > >> 
> > > > > > > >>> list1<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L), 
> > > > > > > >>> WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9), 
> > > > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > > > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > > > >>> structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
> > > > > > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
> > > > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > > > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > > > >>> structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L), 
> > > > > > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9), 
> > > > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA)), 
> > > > > > > >>> .Names = c("id", "WgtBand", "Wgt")))
> > > > > > > >>> 
> > > > > > > >>> 
> > > > > > > >>> list2<-list(structure(list(id = c(493L, 564L, 147L), 
> > > > > > > >>> WgtBand = c(1, 2, 3), 
> > > > > > > >>> Wgt = c(NaN, NaN, NA)), 
> > > > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > > > >>> structure(list(id = c(276L, 411L, 574L,111L), 
> > > > > > > >>> WgtBand = c(1, 2, 3,4), 
> > > > > > > >>> Wgt = c(NaN, NaN, NA,NA)), 
> > > > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > > > >>> structure(list(id = c(76L, 330L), 
> > > > > > > >>> WgtBand = c(1, 1), 
> > > > > > > >>> Wgt = c(NaN, NaN)), 
> > > > > > > >>> .Names = c("id", "WgtBand", "Wgt")))
> > > > > > > >>> 
> > > > > > > >>> list3<-list(structure(list(id = c(493L, 564L, 147L, 83L, 33L, 276L, 402L, 285L, 30L, 555L,493L, 564L, 147L), 
> > > > > > > >>> WgtBand = c(1, 1, 2, 3, 4, 5, 6, 7, 8, 9,1, 2, 3), 
> > > > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA)), 
> > > > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > > > >>> structure(list(id = c(376L, 130L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,276L, 411L, 574L,111L), 
> > > > > > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 2, 3,4), 
> > > > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN, NA,NA)), 
> > > > > > > >>> .Names = c("id", "WgtBand", "Wgt")), 
> > > > > > > >>> structure(list(id = c(76L, 330L, 574L, 47L, 131L, 581L, 133L, 69L, 35L, 487L,76L, 330L), 
> > > > > > > >>> WgtBand = c(1, 1, 2, 3, 4,5, 6, 7, 8, 9, 1, 1), 
> > > > > > > >>> Wgt = c(NaN, NaN, NA, NA, NA, NA, NA, NA, NA, NA,NaN, NaN)), 
> > > > > > > >>> .Names = c("id", "WgtBand", "Wgt")))
> > > > > > > >> 
> > > > > > > >> I get something like the desired structure with:
> > > > > > > >> 
> > > > > > > >> mapply(function(x,y) mapply(c, x,y), list1,list2)
> > > > > > > >> 
> > > > > > > >> I can make it closer with:
> > > > > > > >> 
> > > > > > > >> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) unclass( as.data.frame(x) ) )
> > > > > > > >> 
> > > > > > > >> 
> > > > > > > >> Or even closer with:
> > > > > > > >> 
> > > > > > > >> lapply( mapply(function(x,y) mapply(c, x,y), list1,list2) , function(x) as.list( as.data.frame(x) ) )
> > > > > > > >> 
> > > > > > > >> `identical` does not return TRUE but I cannot see where the difference lies.
> > > > > > > >> 
> > > > > > > >> -- 
> > > > > > > >> 
> > > > > > > >> David Winsemius
> > > > > > > >> Alameda, CA, USA
> > > > > > > >> 
> > > > > > > > 
> > > > > > > > [[alternative HTML version deleted]]
> > > > > > > > 
> > > > > > > > ______________________________________________
> > > > > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > > > > and provide commented, minimal, self-contained, reproducible code.
> > > > > > > 
> > > > > > > David Winsemius
> > > > > > > Alameda, CA, USA
> > > > > > > 
> > > > > 
> > > > > David Winsemius
> > > > > Alameda, CA, USA
> > > > >
> > > 
> > > David Winsemius
> > > Alameda, CA, USA
> > > 
> 
> David Winsemius
> Alameda, CA, USA
> 
 		 	   		  
	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Thu May 14 17:18:57 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 14 May 2015 15:18:57 +0000
Subject: [R] create a vector from several data frames
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F2804F785@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F2804F785@ESINO.regionemarche.intra>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68BFBB@mb02.ads.tamu.edu>

If you combine all of the df's into a list, e.g.

dfn <- paste0("df", 1:20)
df <- lapply(dfn, get)
names(df) <- dfn

and if "target" is the day you want in the same date/time format as the day variable in the data frames:

sapply(df, function(x) x[x$day==target, "tmax"])

will return a named vector of the tmax values.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Stefano Sofia
Sent: Thursday, May 14, 2015 9:23 AM
To: r-help at r-project.org
Subject: [R] create a vector from several data frames

Dear r-users,
suppose that I have 20 data frames df1, df2, ..., df20 (one for each different location) with the same column names and column types (the first column contains a date, the others are numeric) like

day tmax tmin
2015-05-10 20 10
2015-05-11 21 12
2015-05-12 17 9
2015-05-13 24 13
2015-05-14 25 18

I need to create a vector "tmax_all" of length 20 with the tmax referred to a particular day (let's say 2015-05-14).
I would first build a new data frame

tmax_df <- Reduce(function(x, y) merge(x, y, by="day"), list(df1[ , c("day", "tmax")], df2[ , c("day", "tmax")], ..., df20[ , c("day", "tmax")]))

and then select the row of tmax_df where day is the day I want to.
Is there an easiest way? Is it possible to create straightforward this vector without passing through the merge of all the data frames?

Thank you for your help
Stefano

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From jdnewmil at dcn.davis.ca.us  Thu May 14 17:56:24 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 14 May 2015 08:56:24 -0700 (PDT)
Subject: [R] Plotting times at night and getting plot limits correct
In-Reply-To: <CA+8X3fUQVfru4se-H7T7wxFBGiQmAFz12ZEO5T4aF9dhiwLj6w@mail.gmail.com>
References: <CAN-Z0xUj_+EQgGGmFu8393oA28epJ0S+TH2vUcxQqiw2b9n2Xw@mail.gmail.com>
	<CAGx1TMCAfcRQ00RztRO=Q0-DErRJwwKoEysyJMsfMoEvqmrApA@mail.gmail.com>
	<CA+8X3fUQVfru4se-H7T7wxFBGiQmAFz12ZEO5T4aF9dhiwLj6w@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1505140832030.41415@pedal.dcn.davis.ca.us>

I might do it this way using Jim's sample data:

epoch <- as.POSIXct( "1970-01-01" ) # any date you like
dta <- data.frame( Timestamps = epoch
                               + as.difftime( ifelse( Times >= 5/24
                                                    , Times
                                                    , Times + 1 )
                                            , units="days" )
                  , Thing=Thing
                  )
brks <- epoch + as.difftime( seq( 5, 29, 1 ), units="hours" )
plot( Thing ~ Timestamps, dta, xaxt="n", xlim=c( min(brks), max(brks) ) )
axis.POSIXct( 1, at=brks, format="%H:%M" )

or, using ggplot2 instead of base graphics:

library(ggplot2)
library(scales)
ggplot( dta, aes( x=Timestamps, y=Thing ) ) +
     geom_point() +
     scale_x_datetime( breaks=brks
                     , limits=c( min(brks), max(brks) )
                     , labels=date_format("%H:%M") ) +
     theme( axis.text.x = element_text( angle = 90, hjust = 1 ) )

On Thu, 14 May 2015, Jim Lemon wrote:

> Hi Bob,
> Given the other answers I may be off target, but perhaps this will help:
>
> # create two "nights" worth of data
> Times<-strptime(
> paste(c("2015-05-13","2015-05-14"),paste(rep(c(18:23,0:6),2),":30:00",sep="")),
> "%Y-%m-%d %H:%M:%S")
> # telescope the two nights into repeated hours
> Hours<-strptime(format(Times,"%H:%M:%S"),"%H:%M:%S")
> # get a measure that can be checked for the correct output
> calls_per_hour<-sample(10:100,length(Hours))
> # plot the repeated values - looks okay
> plot(Hours,calls_per_hour)
> # now calculate the mean values for each hourly measurement
> mean_calls_per_hour<-by(calls_per_hour,as.character(Hours),mean)
> # plot the means, making sure that the orders match
> plot(sort(unique(Hours)),mean_calls_per_hour)
>
> Jim
>
>
> On Wed, May 13, 2015 at 1:20 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
>> Try this.
>>
>>> From the full data-time value subtract 18:00:00.
>> This places the times you are interested in into the range 00:00:00 - 12:00:00
>> Remove the date from these adjusted date-time values and plot y
>> against the new times.
>> Take control of the tick-labels and display 18:00 - 0600 instead of
>> the default 00:00 - 12:00
>>
>> Rich
>>
>> On Tue, May 12, 2015 at 10:34 AM, Bob O'Hara <rni.boh at gmail.com> wrote:
>>> I'm helping colleagues with analysis of frog calls at night, and they
>>> want to plot call statistics against time. This means we hit a
>>> problem: we want the x-axis to start at (say) 18:00 and end at (say)
>>> 06:00. I'm reluctant to use the date as well, because we have data
>>> from several dates, but only want to plot against time of day.
>>>
>>> Here's some code to illustrate the problem (don't worry about the data
>>> being outside the range of the plot: this is only for illustration).
>>>
>>> library(chron)
>>> Times <- chron(times.=paste(c(18:23,0:9),":30:00", sep=""))
>>> Thing <- rnorm(length(Times)) # just something for the y-axis
>>>
>>> plot(Times,Thing) # x-axis wrong
>>> plot(Times,Thing, xlim=chron(times.=c("05:00:00", "18:00:00"))) # x-axis right
>>> plot(Times,Thing, xlim=chron(times.=c("18:00:00", "05:00:00"))) #
>>> would like this to work...
>>>
>>> Can anyone suggest a solution?
>>>
>>> Bob
>>>
>>> --
>>> Bob O'Hara
>>>
>>> Biodiversity and Climate Research Centre
>>> Senckenberganlage 25
>>> D-60325 Frankfurt am Main,
>>> Germany
>>>
>>> Tel: +49 69 798 40226
>>> Mobile: +49 1515 888 5440
>>> WWW:   http://www.bik-f.de/root/index.php?page_id=219
>>> Blog: http://occamstypewriter.org/boboh/
>>> Journal of Negative Results - EEB: www.jnr-eeb.org
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From chasiotisv at math.auth.gr  Thu May 14 10:44:10 2015
From: chasiotisv at math.auth.gr (chasiotisv at math.auth.gr)
Date: Thu, 14 May 2015 11:44:10 +0300
Subject: [R] Determinant
Message-ID: <20150514114410.Horde.vpVUyrOEBCBgDy3GxYJnZx4@webmail.auth.gr>

Hello,

I am Vasilis Chasiotis and I am a candidate Ph.D. student in Aristotle  
University of Thessaloniki in Greece.

I have the following problem.

I want to check if the square of a number ( for example the square of  
1.677722e+29 ) is an integer.

The problem is that this number is the calculation of the determinant  
(so the number should be an integer) of a matrix 22x22, which means it  
has an approximation ( the "real" number is 1.6777216e+29 but R gives  
to me  1.6777215999999849e+29 ), because R use LU-decomposition to  
calculate the determinant.

That means that the radical of the number 1.6777215999999849e+29 is  
not an integer, but it should be.

How can we overcome this problem?

Thank you in advance.

I look forward to hearing from you soon.


Vasilis Chasiotis


From jana.zelva at seznam.cz  Thu May 14 13:33:04 2015
From: jana.zelva at seznam.cz (=?utf-8?q?Jana_=C5=98=C3=ADhov=C3=A1?=)
Date: Thu, 14 May 2015 13:33:04 +0200 (CEST)
Subject: [R] mixed-and weights
Message-ID: <1rR7.KQ6c.44KCvz6juFX.1LL8Vm@seznam.cz>


Hi,

?
 
I?m beginner with R and I hope that someone can help me.

?
 
I need to know how make command weights in mixed-effect model wit random 
intercept. Command weights=xxx is not function in nlme package. But I think 
that this command is commonly used for linear models. 

?
 
Should I use a different package or special command. 

?
 
Thank you for your advice

?
 
Jana ?.
=
	[[alternative HTML version deleted]]


From johannes at huesing.name  Thu May 14 16:14:15 2015
From: johannes at huesing.name (Johannes Huesing)
Date: Thu, 14 May 2015 16:14:15 +0200
Subject: [R] Counting consecutive events in R
In-Reply-To: <CANtKHPWht-hb1eO5O5YCCqMGxC4O5omvmU-MKkNZfhsq9dEBWA@mail.gmail.com>
References: <CANtKHPWht-hb1eO5O5YCCqMGxC4O5omvmU-MKkNZfhsq9dEBWA@mail.gmail.com>
Message-ID: <20150514141414.GA5485@huesing.name>

I normally use rle() for these problems, see ?rle.

for instance,

k <- rbinom(999, 1, .5)                                                                                                               
series <- function(run) {                                                                                                                 r <- rle(run)                                                                                                                        ser <- which(r$lengths > 5 & r$values)                                                                                          }                                                                                                                                     
series(k)    


returns the indices of consecutive runs that have length 5 or longer.
      

Abhinaba Roy <abhinabaroy09 at gmail.com> [Thu, May 14, 2015 at 02:16:31PM CEST]:
>Hi,
>
>I have the following dataframe
>
>structure(list(Type = c("QRS", "QRS", "QRS", "QRS", "QRS", "QRS",
>"QRS", "QRS", "QRS", "QRS", "QRS", "QRS", "RR", "RR", "RR", "PP",
>"PP", "PP", "PP", "PP", "PP", "PP", "PP", "PP", "QTc", "QTc",
>"QTc", "QTc", "QTc", "QTc", "QTc", "QTc", "QTc", "QTc", "QTc",
>"QTc", "QTc", "QTc", "QTc"), Time_Point_Start = c("2015-04-01 14:57:15.0.0312",
>"2015-04-01 14:57:15.0.7839", "2015-04-01 14:57:16.0.5343",
>"2015-04-01 14:57:17.0.2573",
>"2015-04-01 14:57:18.0.0234", "2015-04-01 14:57:18.0.7722",
>"2015-04-01 14:57:19.0.5265",
>"2015-04-01 14:57:24.0.0195", "2015-04-01 14:57:24.0.7839",
>"2015-04-01 14:57:25.0.5343",
>"2015-04-01 14:57:26.0.2768", "2015-04-01 14:57:27.0.0273",
>"2015-04-01 14:58:03.0.0702",
>"2015-04-01 14:58:03.0.8190", "2015-04-01 14:58:04.0.5694",
>"2015-04-01 14:57:58.0.4134",
>"2015-04-01 14:57:59.0.1637", "2015-04-01 14:57:59.0.9126",
>"2015-04-01 14:58:00.0.6630",
>"2015-04-01 14:58:01.0.4134", "2015-04-01 14:58:02.0.1637",
>"2015-04-01 14:58:02.0.9126",
>"2015-04-01 14:58:03.0.6630", "2015-04-01 14:58:04.0.4134",
>"2015-04-01 14:57:07.0.4212",
>"2015-04-01 14:57:08.0.1715", "2015-04-01 14:57:08.0.9204",
>"2015-04-01 14:57:09.0.6864",
>"2015-04-01 14:57:10.0.4368", "2015-04-01 14:57:11.0.1871",
>"2015-04-01 14:57:11.0.9360",
>"2015-04-01 14:57:12.0.6591", "2015-04-01 14:57:13.0.4251",
>"2015-04-01 14:57:14.0.1754",
>"2015-04-01 14:57:14.0.9243", "2015-04-01 14:57:15.0.6903",
>"2015-04-01 14:57:16.0.4407",
>"2015-04-01 14:57:17.0.1676", "2015-04-01 14:57:17.0.9321"),
>    Time_Point_End = c("2015-04-01 14:57:15.0.0858", "2015-04-01
>14:57:15.0.8346",
>    "2015-04-01 14:57:16.0.6006", "2015-04-01 14:57:17.0.0351",
>    "2015-04-01 14:57:18.0.1403", "2015-04-01 14:57:18.0.8385",
>    "2015-04-01 14:57:19.0.5889", "2015-04-01 14:57:24.0.0858",
>    "2015-04-01 14:57:24.0.8346", "2015-04-01 14:57:25.0.5772",
>    "2015-04-01 14:57:26.0.3939", "2015-04-01 14:57:27.0.0936",
>    "2015-04-01 14:58:03.0.8190", "2015-04-01 14:58:04.0.5694",
>    "2015-04-01 14:58:05.0.3197", "2015-04-01 14:57:59.0.1637",
>    "2015-04-01 14:57:59.0.9126", "2015-04-01 14:58:00.0.6630",
>    "2015-04-01 14:58:01.0.4134", "2015-04-01 14:58:02.0.1637",
>    "2015-04-01 14:58:02.0.9126", "2015-04-01 14:58:03.0.6630",
>    "2015-04-01 14:58:04.0.4134", "2015-04-01 14:58:05.0.1793",
>    "2015-04-01 14:57:07.0.8775", "2015-04-01 14:57:08.0.6435",
>    "2015-04-01 14:57:09.0.3705", "2015-04-01 14:57:10.0.1209",
>    "2015-04-01 14:57:10.0.8697", "2015-04-01 14:57:11.0.6201",
>    "2015-04-01 14:57:12.0.3861", "2015-04-01 14:57:13.0.1364",
>    "2015-04-01 14:57:13.0.8853", "2015-04-01 14:57:14.0.6513",
>    "2015-04-01 14:57:15.0.4017", "2015-04-01 14:57:16.0.1248",
>    "2015-04-01 14:57:16.0.9165", "2015-04-01 14:57:17.0.6162",
>    "2015-04-01 14:57:18.0.3900"), Value = c(0.0546, 0.0507,
>    0.0663, 0.0936, 0.117, 0.0663, 0.0624, 0.0663, 0.0507, 0.0429,
>    0.117, 0.0663, 0.7488, 0.7488, 0.7488, 0.7488, 0.7488, 0.7488,
>    0.7488, 0.7488, 0.7488, 0.7488, 0.7488, 0.7644, 0.033103481,
>    0.034056449, 0.032367699, 0.031000613, 0.031405867, 0.031241866,
>    0.032367699, 0.034337907, 0.033125921, 0.034337907, 0.034337907,
>    0.031241866, 0.034337907, 0.032367699, 0.032930616), Score = c(0L,
>    0L, 0L, 0L, 3L, 0L, 0L, 0L, 0L, 0L, 3L, 0L, 0L, 0L, 0L, 0L,
>    0L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), Type_Desc = c(NA, NA, NA,
>    NA, 1L, NA, NA, NA, NA, NA, 1L, NA, NA, NA, NA, NA, NA, 1L,
>    1L, 1L, 1L, 1L, NA, NA, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>    0L, 0L, 0L, 0L, 0L, 0L), Pat_id = c(4L, 4L, 4L, 4L, 4L, 4L,
>    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>    4L, 4L, 4L)), .Names = c("Type", "Time_Point_Start", "Time_Point_End",
>"Value", "Score", "Type_Desc", "Pat_id"), class = "data.frame",
>row.names = c(NA,
>-39L))
>
>
>For each unique value in column 'Type' , I want to check for
>consecutive 5 rows (if any) of 'Score' > 0.
>
>Now, if there are five consecutive rows with Score > 0 and 'Type_Desc'
>= 0, then we print "Type_low" , else if
>
>'Type_Desc' = 1, we print "Type_high". The search should end once 5
>consecutive rows have been found.
>
>So, for this data frame we will have two statements as follows,
>
>
>1.PP_high
>
>(reason - consecutive 5 rows of score > 0 and
>
>'Type_Desc' = 1 )
>
>2.QTc_low
>(reason - consecutive 5 rows of score > 0 and
>
>'Type_Desc' = 0 )
>
>How can this problem tackled in R?
>
>Thanks,
>
>Abhinaba
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Johannes H?sing               There is something fascinating about science. 
                               One gets such wholesale returns of conjecture 
mailto:johannes at huesing.name  from such a trifling investment of fact.                
http://derwisch.wikidot.com         (Mark Twain, "Life on the Mississippi")


From hess.bn at gmail.com  Thu May 14 20:01:50 2015
From: hess.bn at gmail.com (Benjamin)
Date: Thu, 14 May 2015 14:01:50 -0400
Subject: [R]  specific package to laply
Message-ID: <CAKdEGU9E+PhgJPO6GFtbWC0Hs+gs6BF7Ru0Xu9OZzXko6bAArg@mail.gmail.com>

Hi,

I have a batch jobs problem for parallel code without sudo.  When I try to
send a package to the different nodes, as follows:

.libPaths( c(.libPaths(),
             "/my/first/library",
             "/my/second/library")
          )
library(foreach)
library(iterators)
library(parallel)
library(doParallel)
library(rvest)
cl <- makeCluster(detectCores())
registerDoParallel(cl)
sites <- paste0("https://www.site",1:2,".com")

html0 <- foreach(i=sites,.packages='rvest') %dopar% html(i)


I get the following output:

Error in e$fun(obj, substitute(ex), parent.frame(), e$data) :
  worker initialization failed: there is no package called ?rvest?
Calls: %dopar% -> <Anonymous>

Presumably, I need a way to export my .libPaths() to the nodes.  Any
suggestions?

Thanks,
Benjamin

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu May 14 20:21:25 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 14 May 2015 11:21:25 -0700
Subject: [R] specific package to laply
In-Reply-To: <CAKdEGU9E+PhgJPO6GFtbWC0Hs+gs6BF7Ru0Xu9OZzXko6bAArg@mail.gmail.com>
References: <CAKdEGU9E+PhgJPO6GFtbWC0Hs+gs6BF7Ru0Xu9OZzXko6bAArg@mail.gmail.com>
Message-ID: <756D3026-A098-4DFA-AD67-E999DE3668FF@dcn.davis.CA.us>

I suggest you post using plain text to minimize communication problems on this list.

I use the clusterEvalQ and cluster export functions to setup the slave processes before I start processing.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 14, 2015 11:01:50 AM PDT, Benjamin <hess.bn at gmail.com> wrote:
>Hi,
>
>I have a batch jobs problem for parallel code without sudo.  When I try
>to
>send a package to the different nodes, as follows:
>
>.libPaths( c(.libPaths(),
>             "/my/first/library",
>             "/my/second/library")
>          )
>library(foreach)
>library(iterators)
>library(parallel)
>library(doParallel)
>library(rvest)
>cl <- makeCluster(detectCores())
>registerDoParallel(cl)
>sites <- paste0("https://www.site",1:2,".com")
>
>html0 <- foreach(i=sites,.packages='rvest') %dopar% html(i)
>
>
>I get the following output:
>
>Error in e$fun(obj, substitute(ex), parent.frame(), e$data) :
>  worker initialization failed: there is no package called ?rvest?
>Calls: %dopar% -> <Anonymous>
>
>Presumably, I need a way to export my .libPaths() to the nodes.  Any
>suggestions?
>
>Thanks,
>Benjamin
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Thu May 14 21:17:23 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 14 May 2015 15:17:23 -0400
Subject: [R] Determinant
In-Reply-To: <20150514114410.Horde.vpVUyrOEBCBgDy3GxYJnZx4@webmail.auth.gr>
References: <20150514114410.Horde.vpVUyrOEBCBgDy3GxYJnZx4@webmail.auth.gr>
Message-ID: <BBB4E574-EEE0-4B4C-9986-4339D8B3B7CC@utoronto.ca>

Of course the number _is_ an integer. It seems you are asking whether that integer can be exactly _represented_ on a computer? That depends on your processor (eg. 32/64 bit) and the size of the number; alternatively you could calculate with arbitrary precision with the Rmpfr package.

For more insights, have a look at Pat Burs' summary of number representation in R (http://www.burns-stat.com/documents/tutorials/impatient-r/more-r-key-objects/more-r-numbers/) and/or read chapter one of his R inferno.

Or, maybe you can state more clearly what you are trying to achieve in the end, there might be other options.

Cheers,
B.



On May 14, 2015, at 4:44 AM, chasiotisv at math.auth.gr wrote:

> Hello,
> 
> I am Vasilis Chasiotis and I am a candidate Ph.D. student in Aristotle University of Thessaloniki in Greece.
> 
> I have the following problem.
> 
> I want to check if the square of a number ( for example the square of 1.677722e+29 ) is an integer.
> 
> The problem is that this number is the calculation of the determinant (so the number should be an integer) of a matrix 22x22, which means it has an approximation ( the "real" number is 1.6777216e+29 but R gives to me  1.6777215999999849e+29 ), because R use LU-decomposition to calculate the determinant.
> 
> That means that the radical of the number 1.6777215999999849e+29 is not an integer, but it should be.
> 
> How can we overcome this problem?
> 
> Thank you in advance.
> 
> I look forward to hearing from you soon.
> 
> 
> Vasilis Chasiotis
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dafemlions at yahoo.co.uk  Thu May 14 21:45:01 2015
From: dafemlions at yahoo.co.uk (Olufemi Bolarinwa)
Date: Thu, 14 May 2015 19:45:01 +0000 (UTC)
Subject: [R] Error: Gradient function might be wrong - check it! for system
 of equations using Optimx
Message-ID: <58141111.3432532.1431632701432.JavaMail.yahoo@mail.yahoo.com>

Hello,I am estimating a system of 3 equations using a nonlinear GMM.The first and second equations consists of a linear part and a nonlinear part. The nonlinear parts is specified as a logit and the logit as a whole has a coefficient attached to it. For the first two equations, it is specified as follows:The whole equation: (a1*x1 + a2*x2 +a3*x3 + a4*x4 + a5*x5 + a22*(exp(a6*x6 + a7*x7 + a8*x9 + a9*x10 + a10*x11 + a11*x12 + a14*x16)/(1+exp(a6*x6 + a7*x7 + a8*x9 + a9*x10 + a10*x11 + a11*x12 + a14*x16))))
The linear portion of the equation:?a1*x1 + a2*x2 +a3*x3 + a4*x4 + a5*x5The nonlinear portion of the equation: a22*(exp(a6*x6 + a7*x7 + a8*x9 + a9*x10 + a10*x11 + a11*x12 + a14*x16)/(1+exp(a6*x6 + a7*x7 + a8*x9 + a9*x10 + a10*x11 + a11*x12 + a14*x16)))The third equation is a logit with seven independent variables.The first and the second equation have 12 variables while the third equation have 7 variables.?I did calculate my gradient from the moment conditions which led to a 12 by 12 matrix for the first equation, a 12 by 12 matrix for the second equation and a 7 by 7 matrix for the third equation because I have 12, 12, and 7 instruments for the three equations respectively.Since it is estimated as a system of equations, I made it into a block diagonal matrix which is a 31 by 31 matrix.
This is the matrix that I used in my optimx routine which gave me the error message
Maximizing -- use negfn and neggrError: Gradient function might be wrong - check it!?In addition: Warning message:In gn - ga :? longer object length is not a multiple of shorter object length
When I used optim routine, I got a similar error messageError in optim(parm, fn = obj, gr = gradient, method = "BFGS", hessian = TRUE) :?? gradient in optim evaluated to length 1023 not 35
?I used the numDeriv to compare my gradient with the numerical gradient and I have the following error> require(numDeriv)> mygrad = gradient(parm)> numgrad = jacobian(obj, parm)> cbind(mygrad,numgrad)Error in cbind(mygrad, numgrad) :?? number of rows of matrices must match (see arg 2)> all.equal(mygrad,numgrad)[1] "Attributes: < Length mismatch: comparison on first 1 components >" "Attributes: < Component ?dim?: Mean relative difference: 0.5625 >"[3] "Numeric: lengths (1023, 35) differ"
A way forward will be appreciated.

?

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu May 14 21:50:26 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 14 May 2015 12:50:26 -0700
Subject: [R] Determinant
In-Reply-To: <20150514114410.Horde.vpVUyrOEBCBgDy3GxYJnZx4@webmail.auth.gr>
References: <20150514114410.Horde.vpVUyrOEBCBgDy3GxYJnZx4@webmail.auth.gr>
Message-ID: <C8833E55-7BC7-4836-AC70-9D785D1074D7@comcast.net>


On May 14, 2015, at 1:44 AM, chasiotisv at math.auth.gr wrote:

> Hello,
> 
> I am Vasilis Chasiotis and I am a candidate Ph.D. student in Aristotle University of Thessaloniki in Greece.
> 
> I have the following problem.
> 
> I want to check if the square of a number ( for example the square of 1.677722e+29 ) is an integer.
> 

The square of 1.677722e+29 is almost certainly an integer since the power of 10  (+29)  exceeds the number of digits. That implies that the number in non-scientific notation has many 0's on the righthand side.

I'm guessing that you may be asking whether the square-root is an integer.

> The problem is that this number is the calculation of the determinant (so the number should be an integer) of a matrix 22x22, which means it has an approximation ( the "real" number is 1.6777216e+29 but R gives to me  1.6777215999999849e+29 ), because R use LU-decomposition to calculate the determinant.
> 
> That means that the radical of the number 1.6777215999999849e+29 is not an integer, but it should be.

Again guessing that by 'radical' you mean the square-root. I am also confused about  what test you were applying to that result to determine that it was not an integer. 

At any rate, I'm guessing that the limitation of R's numerical accuracy may get in the way of determining whether the square-root is an integer. If it were integer then it should equal floor(n) :

 (1.6777215999999849e+29)^(1/2) - floor((1.6777215999999849e+29)^(1/2)) 
#[1] 0.125

 (1.6777216e+29)^(1/2) - floor( (1.6777216e+29)^(1/2) )
#[1] 0

That's because that number was the product of two perfect squares:

> 16777216^(1/2) - floor( 1.6777216^(1/2) )
[1] 4095

And 10^22 = 10^11*10^11


If you know how big the  original was you could round it to the correct precision but that seems too much to hope for.

 print( round(1.6777215999999849e+29, digits=10) , digits=10)
#[1] 1.6777216e+29

identical( (1.6777216e+29)^(1/2) , floor( (1.6777216e+29)^(1/2) ) )
#[1] TRUE

> 
> How can we overcome this problem? 

There are a couple of packages that support exact math on really large numbers. You need to clarify what is being requested. You definitely need to review R-FAQ 7.31 and make sure you understand it and also review ?double and ?integer

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu May 14 22:26:59 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 14 May 2015 13:26:59 -0700
Subject: [R] Determinant
In-Reply-To: <C8833E55-7BC7-4836-AC70-9D785D1074D7@comcast.net>
References: <20150514114410.Horde.vpVUyrOEBCBgDy3GxYJnZx4@webmail.auth.gr>
	<C8833E55-7BC7-4836-AC70-9D785D1074D7@comcast.net>
Message-ID: <F876D70F-1DD0-4E99-A089-473E72AF32F3@comcast.net>


On May 14, 2015, at 12:50 PM, David Winsemius wrote:

> 
> On May 14, 2015, at 1:44 AM, chasiotisv at math.auth.gr wrote:
> 
>> Hello,
>> 
>> I am Vasilis Chasiotis and I am a candidate Ph.D. student in Aristotle University of Thessaloniki in Greece.
>> 
>> I have the following problem.
>> 
>> I want to check if the square of a number ( for example the square of 1.677722e+29 ) is an integer.
>> 
> 
> The square of 1.677722e+29 is almost certainly an integer since the power of 10  (+29)  exceeds the number of digits. That implies that the number in non-scientific notation has many 0's on the righthand side.
> 
> I'm guessing that you may be asking whether the square-root is an integer.
> 
>> The problem is that this number is the calculation of the determinant (so the number should be an integer) of a matrix 22x22, which means it has an approximation ( the "real" number is 1.6777216e+29 but R gives to me  1.6777215999999849e+29 ), because R use LU-decomposition to calculate the determinant.
>> 
>> That means that the radical of the number 1.6777215999999849e+29 is not an integer, but it should be.
> 
> Again guessing that by 'radical' you mean the square-root. I am also confused about  what test you were applying to that result to determine that it was not an integer. 
> 
> At any rate, I'm guessing that the limitation of R's numerical accuracy may get in the way of determining whether the square-root is an integer. If it were integer then it should equal floor(n) :
> 
> (1.6777215999999849e+29)^(1/2) - floor((1.6777215999999849e+29)^(1/2)) 
> #[1] 0.125
> 
> (1.6777216e+29)^(1/2) - floor( (1.6777216e+29)^(1/2) )
> #[1] 0
> 
> That's because that number was the product of two perfect squares:
> 
>> 16777216^(1/2) - floor( 1.6777216^(1/2) )
> [1] 4095


Sorry: Meant to copy this to the response:

> 16777216^(1/2) - floor( 16777216^(1/2) )
[1] 0
> 16777216^(1/2) 
[1] 4096


> 
> And 10^22 = 10^11*10^11
> 
> 
> If you know how big the  original was you could round it to the correct precision but that seems too much to hope for.
> 
> print( round(1.6777215999999849e+29, digits=10) , digits=10)
> #[1] 1.6777216e+29
> 
> identical( (1.6777216e+29)^(1/2) , floor( (1.6777216e+29)^(1/2) ) )
> #[1] TRUE
> 
>> 
>> How can we overcome this problem? 
> 
> There are a couple of packages that support exact math on really large numbers. You need to clarify what is being requested. You definitely need to review R-FAQ 7.31 and make sure you understand it and also review ?double and ?integer
> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From timlee126 at yahoo.com  Thu May 14 16:17:27 2015
From: timlee126 at yahoo.com (Tim)
Date: Thu, 14 May 2015 07:17:27 -0700
Subject: [R] Cross correlation between two time series over nested time
	periods?
In-Reply-To: <90A3359D-4E74-4561-AD48-26F739C0FC77@xs4all.nl>
Message-ID: <1431613047.48971.YahooMailBasic@web161403.mail.bf1.yahoo.com>

Thanks!

Here the period of my time series B is a proper subinterval of the period of A.

Does ccf(A,B) requires A and B span the same period?

If A and B don't span the same period, what does ccf do?
When moving B along the period of A by a lag, does ccf(A,B) calculate the cross correlation between B and the part of A overlapping with B?
Or does ccf(A,B) calculate the cross correlation between A and the extension of B to the period of A by zero padding?

--------------------------------------------
On Thu, 5/14/15, Franklin Bretschneider <bretschr at xs4all.nl> wrote:

 Subject: Re: [R] Cross correlation between two time series over nested time periods?

 Date: Thursday, May 14, 2015, 6:14 AM


 On
 2015-05-14 , at 02:11, Tim via R-help <r-help at r-project.org>
 wrote:


 Hello Tim,


 Re:


 > I have two time series
 > 
 > 
 > Calculate and plot cross correlation
 between two time series over nested time periods. Each point
 in either time series is for a week (not exactly a calendar
 week, but the first week in a calendar year always starts
 from Jan 1, and the other weeks in the same year follow
 that, and the last week of the year may contain more than 7
 days but no more than 13 days).
 > 
 > The first time series A is stored in a
 compressed (.gz) text file, which looks like (each week and
 the corresponding time series value are separated by a comma
 in a line):
 > week,value
 > 20060101-20060107,0
 >
 20060108-20060114,5
 > ...
 > 20061217-20061223,0
 >
 20061224-20061230,0
 >
 20070101-20070107,0
 >
 20070108-20070114,4
 > ...
 > 20150903-20150909,0
 >
 20150910-20150916,1
 > 
 > The second time series B is similarly
 stored in a compressed (.gz) text file, but over a subset of
 period of A, which looks like:
 >
 week,value
 > 20130122-20130128,509
 > 20130129-20130204,204
 >
 ...
 > 20131217-20131223,150
 > 20131224-20131231,148.0
 > 20140101-20140107,365.0
 > 20140108-20140114,45.0
 > ...
 >
 20150305-20150311,0
 >
 20150312-20150318,364
 > 
 > I wonder how to calculate the cross
 correlation between the two time series A and B (up to a
 specified maximum lag), and plot A and B in a single plot?





 The auto- and crosscorrelation
 functions are in the stats package:

 acf(x, lag.max = NULL,
 ? ?
 type = c("correlation", "covariance",
 "partial"),
 ? ? plot = TRUE,
 na.action = na.fail, demean = TRUE, ...)

 ccf(x, y, lag.max = NULL, type =
 c("correlation", "covariance"),
 ? ? plot = TRUE, na.action = na.fail, ...)

 See further: ?ccf

 Succes and
 Best wishes,


 Frank
 ---



 Franklin Bretschneider
 Dept of
 Biology
 Utrecht University
 bretschr at xs4all.nl


From preet.balaji20 at gmail.com  Thu May 14 12:50:43 2015
From: preet.balaji20 at gmail.com (Preethi Balaji)
Date: Thu, 14 May 2015 11:50:43 +0100
Subject: [R]  Reading a tiff image
Message-ID: <CABPcpMxj70M=_kdcdnVBk_k7kdROOwok-ZRgwRDBMJd_dOFBHg@mail.gmail.com>

Dear R users,

I am new to R and trying to learn raster image processing in R.

I have a tiff image with pixel values and I am trying to read this image in
R so that I can make some calculations and process the image.

Could you please tell me how to read a tiff image in R?

Thanks!
-- 

Regards,
*Preethi Malur Balaji* | PhD Student
University College Cork | Cork, Ireland.

	[[alternative HTML version deleted]]


From silvano at uel.br  Thu May 14 13:31:46 2015
From: silvano at uel.br (silvano)
Date: Thu, 14 May 2015 08:31:46 -0300
Subject: [R] Reading access file
Message-ID: <3D174B511E4C4C148D686459F46E6B61@uelHP>

Hello everybody.

I have a access file to read in R but I can?t to do this. 

I used Hmisc package, but it doesn?t work. 

Someone has the commands to read this kind of file?

I attached the access file.

Thanks.

Silvano.

From soeren.vogel at posteo.ch  Thu May 14 20:28:27 2015
From: soeren.vogel at posteo.ch (soeren.vogel at posteo.ch)
Date: Thu, 14 May 2015 20:28:27 +0200
Subject: [R] Deparse substitute assign with list elements
Message-ID: <CDF73919-52A4-442D-8104-1E5F7E195081@posteo.ch>

Hello,

When I use function `foo` with list elements (example 2), it defines a new object named `b[[1]]`, which is not what I want.  How can I change the function code to show the desired behaviour for all data structures passed to the function?  Or is there a more appropriate way to sort of "pass by references" in a function?

Thanks
S?ren

<src>
bar <- function(x) {
	return( x + 3 )
}

foo <- function(x, value) {
	nm <- deparse(substitute(x))
	tmp <- bar( value )
	assign(nm, tmp, parent.frame())
}

# 1)
a <- NA
foo(a, 4)
a # 7, fine :-)

# 2)
b <- list(NA, NA)
foo(b[[1]], 4) # the first list item should be 7
b # wanted 7 but still list with two NAs :-(
</src>


From kehld at ktk.pte.hu  Thu May 14 22:46:38 2015
From: kehld at ktk.pte.hu (=?windows-1250?Q?Kehl_D=E1niel?=)
Date: Thu, 14 May 2015 20:46:38 +0000
Subject: [R] Reading access file
In-Reply-To: <3D174B511E4C4C148D686459F46E6B61@uelHP>
References: <3D174B511E4C4C148D686459F46E6B61@uelHP>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D14420C83@EMAIL.ktkdom.pte.hu>

Hi Silvano,

your attachment did not go through (only a couple of formats are supported). Please try to give your code next time and what error you get but first read this, it might help:

http://www.statmethods.net/input/dbinterface.html

best,
daniel
________________________________________
Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: silvano [silvano at uel.br]
K?ldve: 2015. m?jus 14. 13:31
To: R
T?rgy: [R] Reading access file

Hello everybody.

I have a access file to read in R but I can?t to do this.

I used Hmisc package, but it doesn?t work.

Someone has the commands to read this kind of file?

I attached the access file.

Thanks.

Silvano.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From kehld at ktk.pte.hu  Thu May 14 22:51:26 2015
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?Kehl_D=E1niel?=)
Date: Thu, 14 May 2015 20:51:26 +0000
Subject: [R] Reading a tiff image
In-Reply-To: <CABPcpMxj70M=_kdcdnVBk_k7kdROOwok-ZRgwRDBMJd_dOFBHg@mail.gmail.com>
References: <CABPcpMxj70M=_kdcdnVBk_k7kdROOwok-ZRgwRDBMJd_dOFBHg@mail.gmail.com>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D14420C94@EMAIL.ktkdom.pte.hu>

Hello,

please set your mailing program to plain text instead of HTML if you post to this list.
If you google read tiff in R you end up with the package called 'tiff'. (http://cran.r-project.org/web/packages/tiff/tiff.pdf)
In case you do not know how to install and load a package, please consult the intro to R pdf which comes with your installation.

Good luck with R,
daniel
________________________________________
Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Preethi Balaji [preet.balaji20 at gmail.com]
K?ldve: 2015. m?jus 14. 12:50
To: r-help at r-project.org
T?rgy: [R]  Reading a tiff image

Dear R users,

I am new to R and trying to learn raster image processing in R.

I have a tiff image with pixel values and I am trying to read this image in
R so that I can make some calculations and process the image.

Could you please tell me how to read a tiff image in R?

Thanks!
--

Regards,
*Preethi Malur Balaji* | PhD Student
University College Cork | Cork, Ireland.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Thu May 14 22:52:41 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 14 May 2015 16:52:41 -0400
Subject: [R] Reading a tiff image
In-Reply-To: <CABPcpMxj70M=_kdcdnVBk_k7kdROOwok-ZRgwRDBMJd_dOFBHg@mail.gmail.com>
References: <CABPcpMxj70M=_kdcdnVBk_k7kdROOwok-ZRgwRDBMJd_dOFBHg@mail.gmail.com>
Message-ID: <CAM_vjukAzjgxdae4bU0Y0=tSgzXvpfos-EmSbZowW3X+aySH+A@mail.gmail.com>

There are many easy ways to answer this kind of question yourself.

One possibility: go to www.rseek.org and search for "read tiff file".

That will quickly suggest the tiff package, which you can install from
CRAN, and also the rtiff package, ditto. It will also link to previous
discussions of that very topic on this mailing list, and other useful
information.

Sarah


On Thu, May 14, 2015 at 6:50 AM, Preethi Balaji
<preet.balaji20 at gmail.com> wrote:
> Dear R users,
>
> I am new to R and trying to learn raster image processing in R.
>
> I have a tiff image with pixel values and I am trying to read this image in
> R so that I can make some calculations and process the image.
>
> Could you please tell me how to read a tiff image in R?
>
> Thanks!
> --
>
> Regards,
> *Preethi Malur Balaji* | PhD Student
> University College Cork | Cork, Ireland.

-- 
Sarah Goslee
http://www.functionaldiversity.org


From liuwensui at gmail.com  Thu May 14 22:58:38 2015
From: liuwensui at gmail.com (Wensui Liu)
Date: Thu, 14 May 2015 15:58:38 -0500
Subject: [R] Reading access file
In-Reply-To: <3D174B511E4C4C148D686459F46E6B61@uelHP>
References: <3D174B511E4C4C148D686459F46E6B61@uelHP>
Message-ID: <CAKyN3iCZriJ-7mEAYmx_EX=BXzGe70yhJW=yd2wHq7eTixCHuQ@mail.gmail.com>

mdbConnect<-odbcConnectAccess("C:\\temp\\demo.mdb");
sqlTables(mdbConnect);
demo<-sqlFetch(mdbConnect, "tblDemo");
odbcClose(mdbConnect);
rm(demo);

On Thu, May 14, 2015 at 6:31 AM, silvano <silvano at uel.br> wrote:

> Hello everybody.
>
> I have a access file to read in R but I can?t to do this.
>
> I used Hmisc package, but it doesn?t work.
>
> Someone has the commands to read this kind of file?
>
> I attached the access file.
>
> Thanks.
>
> Silvano.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
==============================
WenSui Liu
Credit Risk Manager, 53 Bancorp
wensui.liu at 53.com
513-295-4370
==============================

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri May 15 00:02:16 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 14 May 2015 15:02:16 -0700
Subject: [R] Deparse substitute assign with list elements
In-Reply-To: <CDF73919-52A4-442D-8104-1E5F7E195081@posteo.ch>
References: <CDF73919-52A4-442D-8104-1E5F7E195081@posteo.ch>
Message-ID: <CAF8bMcZrX4LnXE7VFGVB0XZi3kT22N_AQtzY9xyStrvVhX8_kQ@mail.gmail.com>

You could use a 'replacement function' named 'bar<-', whose last argument
is called 'value', and use bar(variable) <- newValue where you currently
use foo(variable, newValue).

bar <- function(x) {
    x + 3
}
`bar<-` <- function(x, value) {
    bar(value)
}

a <- NA
bar(a) <- 4
a
# [1] 7
b <- list(NA, NA)
bar(b[[1]]) <- 4
b
#[[1]]
#[1] 7
#
#[[2]]
#[1] NA


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, May 14, 2015 at 11:28 AM, <soeren.vogel at posteo.ch> wrote:

> Hello,
>
> When I use function `foo` with list elements (example 2), it defines a new
> object named `b[[1]]`, which is not what I want.  How can I change the
> function code to show the desired behaviour for all data structures passed
> to the function?  Or is there a more appropriate way to sort of "pass by
> references" in a function?
>
> Thanks
> S?ren
>
> <src>
> bar <- function(x) {
>         return( x + 3 )
> }
>
> foo <- function(x, value) {
>         nm <- deparse(substitute(x))
>         tmp <- bar( value )
>         assign(nm, tmp, parent.frame())
> }
>
> # 1)
> a <- NA
> foo(a, 4)
> a # 7, fine :-)
>
> # 2)
> b <- list(NA, NA)
> foo(b[[1]], 4) # the first list item should be 7
> b # wanted 7 but still list with two NAs :-(
> </src>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri May 15 00:12:41 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 14 May 2015 15:12:41 -0700
Subject: [R] Determinant
In-Reply-To: <BBB4E574-EEE0-4B4C-9986-4339D8B3B7CC@utoronto.ca>
References: <20150514114410.Horde.vpVUyrOEBCBgDy3GxYJnZx4@webmail.auth.gr>
	<BBB4E574-EEE0-4B4C-9986-4339D8B3B7CC@utoronto.ca>
Message-ID: <CAF8bMcYbNjSEzjQi=KJLwZ72KU5QEU3GSGVQNgWvWrOWWViEPA@mail.gmail.com>

Note that when using double precision arithmetic you cannot tell
if that number is different from other numbers within 10 billion of
it -- they all have the same representation.

> 1.6777215999999849e+29 == 1.6777215999999849e+29 + 1e10
[1] TRUE

You need to use other, time consuming, methods (e.g., arbitrary
precision arithmetic such as in the Rmpfr package, or some
analysis)


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, May 14, 2015 at 12:17 PM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> Of course the number _is_ an integer. It seems you are asking whether that
> integer can be exactly _represented_ on a computer? That depends on your
> processor (eg. 32/64 bit) and the size of the number; alternatively you
> could calculate with arbitrary precision with the Rmpfr package.
>
> For more insights, have a look at Pat Burs' summary of number
> representation in R (
> http://www.burns-stat.com/documents/tutorials/impatient-r/more-r-key-objects/more-r-numbers/)
> and/or read chapter one of his R inferno.
>
> Or, maybe you can state more clearly what you are trying to achieve in the
> end, there might be other options.
>
> Cheers,
> B.
>
>
>
> On May 14, 2015, at 4:44 AM, chasiotisv at math.auth.gr wrote:
>
> > Hello,
> >
> > I am Vasilis Chasiotis and I am a candidate Ph.D. student in Aristotle
> University of Thessaloniki in Greece.
> >
> > I have the following problem.
> >
> > I want to check if the square of a number ( for example the square of
> 1.677722e+29 ) is an integer.
> >
> > The problem is that this number is the calculation of the determinant
> (so the number should be an integer) of a matrix 22x22, which means it has
> an approximation ( the "real" number is 1.6777216e+29 but R gives to me
> 1.6777215999999849e+29 ), because R use LU-decomposition to calculate the
> determinant.
> >
> > That means that the radical of the number 1.6777215999999849e+29 is not
> an integer, but it should be.
> >
> > How can we overcome this problem?
> >
> > Thank you in advance.
> >
> > I look forward to hearing from you soon.
> >
> >
> > Vasilis Chasiotis
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri May 15 01:08:59 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 14 May 2015 16:08:59 -0700
Subject: [R] Reading access file
In-Reply-To: <CAKyN3iCZriJ-7mEAYmx_EX=BXzGe70yhJW=yd2wHq7eTixCHuQ@mail.gmail.com>
References: <3D174B511E4C4C148D686459F46E6B61@uelHP>
	<CAKyN3iCZriJ-7mEAYmx_EX=BXzGe70yhJW=yd2wHq7eTixCHuQ@mail.gmail.com>
Message-ID: <9A0E0710-26EB-4E6C-ACB9-1D6D2B35A751@dcn.davis.CA.us>

Be sure to use the 32bit version of R with the code below. This is a limitation of the ODBC driver for "mdb" files. If you use the odbcConnectAccess2007() function to connect to "accdb" files then you can use 64bit R.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 14, 2015 1:58:38 PM PDT, Wensui Liu <liuwensui at gmail.com> wrote:
>mdbConnect<-odbcConnectAccess("C:\\temp\\demo.mdb");
>sqlTables(mdbConnect);
>demo<-sqlFetch(mdbConnect, "tblDemo");
>odbcClose(mdbConnect);
>rm(demo);
>
>On Thu, May 14, 2015 at 6:31 AM, silvano <silvano at uel.br> wrote:
>
>> Hello everybody.
>>
>> I have a access file to read in R but I can?t to do this.
>>
>> I used Hmisc package, but it doesn?t work.
>>
>> Someone has the commands to read this kind of file?
>>
>> I attached the access file.
>>
>> Thanks.
>>
>> Silvano.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>-- 
>==============================
>WenSui Liu
>Credit Risk Manager, 53 Bancorp
>wensui.liu at 53.com
>513-295-4370
>==============================
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From drobichaud at lgl.com  Fri May 15 00:53:29 2015
From: drobichaud at lgl.com (David Robichaud)
Date: Thu, 14 May 2015 15:53:29 -0700
Subject: [R] Interpreting GLM Interaction Contrasts in R (using glht)
Message-ID: <55552769.2080206@lgl.com>

Hello,

I am trying to do a BACI analysis on count data, and I am having trouble 
interpreting the output from  multcomp::glht.   I don't understand how 
the contrast's coefficients are related to effect size (if at all??).

I have 5 treatment conditions (one is a control), and I have counts from 
before the treatments were applied and after. Let's say that my model 
form is this ("Period" is the 'before' vs 'after' factor):

     m.pois <- glm(Y_count ~ Treatment + Period + Treatment:Period,
                        data = df.temp,
                        family = "poisson")

As in all BACI designs, I am interested in the interaction term, i.e., 
the differences of the differences.  For example, I'd like to test 
whether TreatmentVR30 changed more than the Control did:
    (TreatmentVR30Later - TreatmentVR30Before) - (ControlLater - 
ControlBefore).

I have done the math, and I created all my planned contrasts, run them 
through the multcomp::glht, and I am struggling to interpret the 
output.  As an example of my confusion, I ran the same contrast in two 
directions (A-B and B-A), which should give the same result (one 
positive, one negative):

     contr <- rbind(
       "VR30 vs Control" =     c(0, 0, 0, 0, 0, 0, -1, 0, 0, 1),
       "Control vs VR30" =     c(0, 0, 0, 0, 0, 0, 1, 0, 0, -1)  )
     m.pois.contr <- summary(glht(m.pois, contr))

which works perfectly, returning one positive and one negative estimate, 
as expected:

     Linear Hypotheses:
                          Estimate Std. Error z value Pr(>|z|)
     VR30 vs Control == 0   0.7354     0.5621   1.308    0.191
     Control vs VR30 == 0  -0.7354     0.5621  -1.308    0.191
     (Adjusted p values reported -- single-step method)

Understanding that the estimates are in log space (due to the link 
function of the poisson family in the glm), I back transformed using 
exp(coef(m.pois.contr) to get:

     VR30 vs Control Control vs VR30
           2.0862414       0.4793309

So, which is it?  Did Control change more than VR30, or did VR30 change 
more than Control, and for both questions, by how much?

Clearly I am missing something here.  I expect that this will be a 
simple fix, but surprisingly, I cannot find it anywhere online.

Thanks in advance to anyone who can help,

David Robichaud, Victoria, BC, Canada


From Virgil.Smith at flir.com  Fri May 15 01:13:28 2015
From: Virgil.Smith at flir.com (Smith, Virgil)
Date: Thu, 14 May 2015 23:13:28 +0000
Subject: [R] Using iconv from glibc
Message-ID: <F14AEF751653024287138321000C846AF4822229@BOS-DAG1.zone1.flir.net>

The R Installation and Administration manual section A.1 states that glibc should provide a suitable iconv function, but I can't get R's configure script to accept/validate iconv on a platform I need to support using glibc 2.20.

Is glibc is actually compatible (or if gnu libiconv is essentially the only path)?

If glibc should work, what should I check to troubleshoot my environment?

The configure error I get is
    checking iconv.h usability... yes
    checking iconv.h presence... yes
    checking for iconv.h... yes
    checking for iconv... yes
    checking whether iconv accepts "UTF-8", "latin1", "ASCII" and "UCS-*"... no
    configure: error: a suitable iconv is essential

My full list of installed glibc / libc packages is
    glibc-binary-localedata-en-gb - 2.20-r0
    glibc-binary-localedata-en-us - 2.20-r0
    glibc-gconv - 2.20-r0
    glibc-gconv-utf-16 - 2.20-r0
    glibc-locale-en-gb - 2.20-r0
    libc6 - 2.20-r0
    libc6-dev - 2.20-r0
    libc6-extra-nss - 2.20-r0
    libc6-thread-db - 2.20-r0



________________________________

Notice to recipient: This email is meant for only the intended recipient of the transmission, and may be a communication privileged by law, subject to export control restrictions or that otherwise contains proprietary information. If you receive this email by mistake, please notify us immediately by replying to this message and then destroy it and do not review, disclose, copy or distribute it. Thank you in advance for your cooperation.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri May 15 01:48:49 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 14 May 2015 16:48:49 -0700
Subject: [R] Using iconv from glibc
In-Reply-To: <F14AEF751653024287138321000C846AF4822229@BOS-DAG1.zone1.flir.net>
References: <F14AEF751653024287138321000C846AF4822229@BOS-DAG1.zone1.flir.net>
Message-ID: <F09F0BA1-1FD8-4A49-91D1-FDAB1BDE1166@dcn.davis.CA.us>

This belongs on R-devel. Read the Posting Guide, which also warns you to post in plain text (for less confusion and a better reception).
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 14, 2015 4:13:28 PM PDT, "Smith, Virgil" <Virgil.Smith at flir.com> wrote:
>The R Installation and Administration manual section A.1 states that
>glibc should provide a suitable iconv function, but I can't get R's
>configure script to accept/validate iconv on a platform I need to
>support using glibc 2.20.
>
>Is glibc is actually compatible (or if gnu libiconv is essentially the
>only path)?
>
>If glibc should work, what should I check to troubleshoot my
>environment?
>
>The configure error I get is
>    checking iconv.h usability... yes
>    checking iconv.h presence... yes
>    checking for iconv.h... yes
>    checking for iconv... yes
>checking whether iconv accepts "UTF-8", "latin1", "ASCII" and
>"UCS-*"... no
>    configure: error: a suitable iconv is essential
>
>My full list of installed glibc / libc packages is
>    glibc-binary-localedata-en-gb - 2.20-r0
>    glibc-binary-localedata-en-us - 2.20-r0
>    glibc-gconv - 2.20-r0
>    glibc-gconv-utf-16 - 2.20-r0
>    glibc-locale-en-gb - 2.20-r0
>    libc6 - 2.20-r0
>    libc6-dev - 2.20-r0
>    libc6-extra-nss - 2.20-r0
>    libc6-thread-db - 2.20-r0
>
>
>
>________________________________
>
>Notice to recipient: This email is meant for only the intended
>recipient of the transmission, and may be a communication privileged by
>law, subject to export control restrictions or that otherwise contains
>proprietary information. If you receive this email by mistake, please
>notify us immediately by replying to this message and then destroy it
>and do not review, disclose, copy or distribute it. Thank you in
>advance for your cooperation.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Fri May 15 10:12:41 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 15 May 2015 10:12:41 +0200
Subject: [R] Interpreting GLM Interaction Contrasts in R (using glht)
In-Reply-To: <55552769.2080206@lgl.com>
References: <55552769.2080206@lgl.com>
Message-ID: <CAJuCY5wqzsLjGxuauME5sstM5n_tjwuQBakvp3h5coCVMUFM5A@mail.gmail.com>

Dear David,

You have missed the fact that exp(-a) = 1/exp(a). Additive effects on the
log scale are multiplicative effects on the original scale.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-15 0:53 GMT+02:00 David Robichaud <drobichaud at lgl.com>:

> Hello,
>
> I am trying to do a BACI analysis on count data, and I am having trouble
> interpreting the output from  multcomp::glht.   I don't understand how the
> contrast's coefficients are related to effect size (if at all??).
>
> I have 5 treatment conditions (one is a control), and I have counts from
> before the treatments were applied and after. Let's say that my model form
> is this ("Period" is the 'before' vs 'after' factor):
>
>     m.pois <- glm(Y_count ~ Treatment + Period + Treatment:Period,
>                        data = df.temp,
>                        family = "poisson")
>
> As in all BACI designs, I am interested in the interaction term, i.e., the
> differences of the differences.  For example, I'd like to test whether
> TreatmentVR30 changed more than the Control did:
>    (TreatmentVR30Later - TreatmentVR30Before) - (ControlLater -
> ControlBefore).
>
> I have done the math, and I created all my planned contrasts, run them
> through the multcomp::glht, and I am struggling to interpret the output.
> As an example of my confusion, I ran the same contrast in two directions
> (A-B and B-A), which should give the same result (one positive, one
> negative):
>
>     contr <- rbind(
>       "VR30 vs Control" =     c(0, 0, 0, 0, 0, 0, -1, 0, 0, 1),
>       "Control vs VR30" =     c(0, 0, 0, 0, 0, 0, 1, 0, 0, -1)  )
>     m.pois.contr <- summary(glht(m.pois, contr))
>
> which works perfectly, returning one positive and one negative estimate,
> as expected:
>
>     Linear Hypotheses:
>                          Estimate Std. Error z value Pr(>|z|)
>     VR30 vs Control == 0   0.7354     0.5621   1.308    0.191
>     Control vs VR30 == 0  -0.7354     0.5621  -1.308    0.191
>     (Adjusted p values reported -- single-step method)
>
> Understanding that the estimates are in log space (due to the link
> function of the poisson family in the glm), I back transformed using
> exp(coef(m.pois.contr) to get:
>
>     VR30 vs Control Control vs VR30
>           2.0862414       0.4793309
>
> So, which is it?  Did Control change more than VR30, or did VR30 change
> more than Control, and for both questions, by how much?
>
> Clearly I am missing something here.  I expect that this will be a simple
> fix, but surprisingly, I cannot find it anywhere online.
>
> Thanks in advance to anyone who can help,
>
> David Robichaud, Victoria, BC, Canada
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rni.boh at gmail.com  Fri May 15 12:31:04 2015
From: rni.boh at gmail.com (Bob O'Hara)
Date: Fri, 15 May 2015 12:31:04 +0200
Subject: [R] Plotting times at night and getting plot limits correct
In-Reply-To: <alpine.BSF.2.00.1505140832030.41415@pedal.dcn.davis.ca.us>
References: <CAN-Z0xUj_+EQgGGmFu8393oA28epJ0S+TH2vUcxQqiw2b9n2Xw@mail.gmail.com>
	<CAGx1TMCAfcRQ00RztRO=Q0-DErRJwwKoEysyJMsfMoEvqmrApA@mail.gmail.com>
	<CA+8X3fUQVfru4se-H7T7wxFBGiQmAFz12ZEO5T4aF9dhiwLj6w@mail.gmail.com>
	<alpine.BSF.2.00.1505140832030.41415@pedal.dcn.davis.ca.us>
Message-ID: <CAN-Z0xVXzKG5qptFNqx-zKJ-vTmeTX4CgHNigPW8zZq4ipVoVg@mail.gmail.com>

Thanks Thierry, Peter, Richard, Jim and Jeff for your help! In the end
I used Thierry's suggetion, in essence to add a day onto the sequences
that start after midnight, and this seems to work fine.

Bob
P.S. What I do during the day is my business, even if it mainly sems
to involve feeding frozen fruit & yoghurt to parrots...

On 14 May 2015 at 17:56, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> I might do it this way using Jim's sample data:
>
> epoch <- as.POSIXct( "1970-01-01" ) # any date you like
> dta <- data.frame( Timestamps = epoch
>                               + as.difftime( ifelse( Times >= 5/24
>                                                    , Times
>                                                    , Times + 1 )
>                                            , units="days" )
>                  , Thing=Thing
>                  )
> brks <- epoch + as.difftime( seq( 5, 29, 1 ), units="hours" )
> plot( Thing ~ Timestamps, dta, xaxt="n", xlim=c( min(brks), max(brks) ) )
> axis.POSIXct( 1, at=brks, format="%H:%M" )
>
> or, using ggplot2 instead of base graphics:
>
> library(ggplot2)
> library(scales)
> ggplot( dta, aes( x=Timestamps, y=Thing ) ) +
>     geom_point() +
>     scale_x_datetime( breaks=brks
>                     , limits=c( min(brks), max(brks) )
>                     , labels=date_format("%H:%M") ) +
>     theme( axis.text.x = element_text( angle = 90, hjust = 1 ) )
>
>
> On Thu, 14 May 2015, Jim Lemon wrote:
>
>> Hi Bob,
>> Given the other answers I may be off target, but perhaps this will help:
>>
>> # create two "nights" worth of data
>> Times<-strptime(
>>
>> paste(c("2015-05-13","2015-05-14"),paste(rep(c(18:23,0:6),2),":30:00",sep="")),
>> "%Y-%m-%d %H:%M:%S")
>> # telescope the two nights into repeated hours
>> Hours<-strptime(format(Times,"%H:%M:%S"),"%H:%M:%S")
>> # get a measure that can be checked for the correct output
>> calls_per_hour<-sample(10:100,length(Hours))
>> # plot the repeated values - looks okay
>> plot(Hours,calls_per_hour)
>> # now calculate the mean values for each hourly measurement
>> mean_calls_per_hour<-by(calls_per_hour,as.character(Hours),mean)
>> # plot the means, making sure that the orders match
>> plot(sort(unique(Hours)),mean_calls_per_hour)
>>
>> Jim
>>
>>
>> On Wed, May 13, 2015 at 1:20 AM, Richard M. Heiberger <rmh at temple.edu>
>> wrote:
>>>
>>> Try this.
>>>
>>>> From the full data-time value subtract 18:00:00.
>>>
>>> This places the times you are interested in into the range 00:00:00 -
>>> 12:00:00
>>> Remove the date from these adjusted date-time values and plot y
>>> against the new times.
>>> Take control of the tick-labels and display 18:00 - 0600 instead of
>>> the default 00:00 - 12:00
>>>
>>> Rich
>>>
>>> On Tue, May 12, 2015 at 10:34 AM, Bob O'Hara <rni.boh at gmail.com> wrote:
>>>>
>>>> I'm helping colleagues with analysis of frog calls at night, and they
>>>> want to plot call statistics against time. This means we hit a
>>>> problem: we want the x-axis to start at (say) 18:00 and end at (say)
>>>> 06:00. I'm reluctant to use the date as well, because we have data
>>>> from several dates, but only want to plot against time of day.
>>>>
>>>> Here's some code to illustrate the problem (don't worry about the data
>>>> being outside the range of the plot: this is only for illustration).
>>>>
>>>> library(chron)
>>>> Times <- chron(times.=paste(c(18:23,0:9),":30:00", sep=""))
>>>> Thing <- rnorm(length(Times)) # just something for the y-axis
>>>>
>>>> plot(Times,Thing) # x-axis wrong
>>>> plot(Times,Thing, xlim=chron(times.=c("05:00:00", "18:00:00"))) # x-axis
>>>> right
>>>> plot(Times,Thing, xlim=chron(times.=c("18:00:00", "05:00:00"))) #
>>>> would like this to work...
>>>>
>>>> Can anyone suggest a solution?
>>>>
>>>> Bob
>>>>
>>>> --
>>>> Bob O'Hara
>>>>
>>>> Biodiversity and Climate Research Centre
>>>> Senckenberganlage 25
>>>> D-60325 Frankfurt am Main,
>>>> Germany
>>>>
>>>> Tel: +49 69 798 40226
>>>> Mobile: +49 1515 888 5440
>>>> WWW:   http://www.bik-f.de/root/index.php?page_id=219
>>>> Blog: http://occamstypewriter.org/boboh/
>>>> Journal of Negative Results - EEB: www.jnr-eeb.org
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bob O'Hara

Biodiversity and Climate Research Centre
Senckenberganlage 25
D-60325 Frankfurt am Main,
Germany

Tel: +49 69 798 40226
Mobile: +49 1515 888 5440
WWW:   http://www.bik-f.de/root/index.php?page_id=219
Blog: http://occamstypewriter.org/boboh/
Journal of Negative Results - EEB: www.jnr-eeb.org


From govokai at gmail.com  Fri May 15 14:05:58 2015
From: govokai at gmail.com (Kai Mx)
Date: Fri, 15 May 2015 14:05:58 +0200
Subject: [R] print dataframe names in loop
Message-ID: <CAHOWgNXcQXq32+gkUcZ14UDMsungZoFSLj2Hv0QP+L_mFyA4Jg@mail.gmail.com>

Hi everybody,

I just can't  figure this out:

I have a loop trough several dataframes such as

for (df in list(df1, df2, df3, ...)) {
..some functions with df..
}

now I want to print out the current dataframes name (ie the list items
name) with the cat command before the actual functions to have better
orientation in the output.
However, I haven't been successful with different variations of deparse(),
substitute(), (cat(substitute(df)) gives me 'df' for the whole loop).

Could somebody please enlighten me?

Thanks so much!

Best,

Kai

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri May 15 14:20:15 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 15 May 2015 22:20:15 +1000
Subject: [R] print dataframe names in loop
In-Reply-To: <CAHOWgNXcQXq32+gkUcZ14UDMsungZoFSLj2Hv0QP+L_mFyA4Jg@mail.gmail.com>
References: <CAHOWgNXcQXq32+gkUcZ14UDMsungZoFSLj2Hv0QP+L_mFyA4Jg@mail.gmail.com>
Message-ID: <CA+8X3fXUwjVTAJ3fUOHB_5VA1gsv2XZJBrugHbwa6bViiP5C2A@mail.gmail.com>

Hi Kai,
One way is to name the components of your list with the names of the
data frames:

df1<-data.frame(a=1:3)
df2<-data.frame(a=4:6)
df3<-data.frame(a=7:9)
dflist<-list(df1,df2,df3)
names(dflist)<-c("df1","df2","df3")
for(i in 1:length(dflist)) cat(names(dflist)[i],"\n")
df1
df2
df3

Jim


On Fri, May 15, 2015 at 10:05 PM, Kai Mx <govokai at gmail.com> wrote:
> Hi everybody,
>
> I just can't  figure this out:
>
> I have a loop trough several dataframes such as
>
> for (df in list(df1, df2, df3, ...)) {
> ..some functions with df..
> }
>
> now I want to print out the current dataframes name (ie the list items
> name) with the cat command before the actual functions to have better
> orientation in the output.
> However, I haven't been successful with different variations of deparse(),
> substitute(), (cat(substitute(df)) gives me 'df' for the whole loop).
>
> Could somebody please enlighten me?
>
> Thanks so much!
>
> Best,
>
> Kai
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Fri May 15 14:46:47 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 15 May 2015 08:46:47 -0400
Subject: [R] Determinant
In-Reply-To: <20150515121937.Horde.uqJuilmRbmU-eC6qhO5b-TM@webmail.auth.gr>
References: <20150514114410.Horde.vpVUyrOEBCBgDy3GxYJnZx4@webmail.auth.gr>
	<BBB4E574-EEE0-4B4C-9986-4339D8B3B7CC@utoronto.ca>
	<20150515121937.Horde.uqJuilmRbmU-eC6qhO5b-TM@webmail.auth.gr>
Message-ID: <607841B0-6DBD-4A24-9121-D0D11EF763A0@utoronto.ca>

Please keep discussion son the list.

On May 15, 2015, at 5:19 AM, chasiotisv at math.auth.gr wrote:

> Yes, I am asking whether that integer can be exactly represented on a computer.
Yes, but it requires significant effort to do so because you need arbitrary-precision algorithms.


> I use 64 bit.
> 
> I have changed 64 up to 1024 but nothing changed.
I don't think we are talking about the same thing here.


> I have tried also to use Rmpfr package, but I haven't solved my problem?
You have not clearly stated what the problem is you are trying to solve. Clearly you don't need to know whether the number is an integer - you already know it is. You also know that a number of that size cannot be exactly represented natively in your computer. So asking whether it turns out to be a whole number or not is asking a question about the machine precision and the algorithm, not about the number. 


> How do you think I can use the Rmpfr package?
> 2^63-1
[1] 9.223372e+18

> print(2^63 - 1, digits=19)
[1] 9223372036854775808       # wrong!

library(Rmpfr)
a <- mpfr(2, 64)
print(a^63 - 1, digits=19)
1 'mpfr' number of precision  64   bits 
[1] 9223372036854775807       # correct!

... but you will need to change the code that does the calculation so that it uses mpfr-class number with enough precision to safely avoid rounding errors for the size of all intermediate values in your calculation. Probably this means you will write your own determinant algorithm - and if this is just for one matrix it doesn't need to be fast so why not. Google tells me there are division-free algorithms for calculating determinants that are O(n^4). But as I wrote above, I can't imagine why this makes sense.


B.



> 
> 
> Vasilis
> 


From HLiao at odu.edu  Fri May 15 15:55:17 2015
From: HLiao at odu.edu (Liao, Hongsheng)
Date: Fri, 15 May 2015 13:55:17 +0000
Subject: [R] How to make sub-headers in R
Message-ID: <44F908E52BA1744BB88DEB8E10103AAD82F58CA8@KIRK.ts.odu.edu>

I know how to make one-row header for a data frame using "colnames".  Is there any function to insert sub-header between the first row of the data and the header?  Thanks

Hongsheng (Hank) Liao, PhD.
Lab Manager
Center for Quantitative  Fisheries Ecology
Old Dominion University
757-683-4571




	[[alternative HTML version deleted]]


From patriciocuaron at gmail.com  Fri May 15 16:38:04 2015
From: patriciocuaron at gmail.com (=?UTF-8?Q?Patricio_Cuar=C3=B3n?=)
Date: Fri, 15 May 2015 11:38:04 -0300
Subject: [R] tables package: localization of "All" subtotals label
Message-ID: <CAJJcQDPqCvXM4i=5P3_a6WFaoRbAMxAHGgqimkzsvijP4W1BEQ@mail.gmail.com>

Hello. I'd like to know how could I localize (or otherwise change the
string) of the "All" subtotal that appears when using something like
library(tables)
data(iris)

tabular((Species + 1) ~ (n=1) + Format(digits=2)* + (Sepal.Length +
Sepal.Width)*(mean + sd), data=iris)

(that's the first example of the documentation, which btw doesn't seem to work):

Error in e[[3]] : subscript out of bounds



Thanks!

	[[alternative HTML version deleted]]


From soeren.vogel at posteo.ch  Fri May 15 10:50:18 2015
From: soeren.vogel at posteo.ch (soeren.vogel at posteo.ch)
Date: Fri, 15 May 2015 10:50:18 +0200
Subject: [R] Deparse substitute assign with list elements
In-Reply-To: <CAF8bMcZrX4LnXE7VFGVB0XZi3kT22N_AQtzY9xyStrvVhX8_kQ@mail.gmail.com>
References: <CDF73919-52A4-442D-8104-1E5F7E195081@posteo.ch>
	<CAF8bMcZrX4LnXE7VFGVB0XZi3kT22N_AQtzY9xyStrvVhX8_kQ@mail.gmail.com>
Message-ID: <CD5C0F59-C13F-48C6-834D-4D414C5F73AC@posteo.ch>

Thanks, Bill, I should have googled more carefully:

http://stackoverflow.com/questions/9561053/assign-values-to-a-list-element-in-r

So, remove

	assign(nm, tmp, parent.frame())

and add

	txt <- paste( nm, '<-', tmp, sep='' )
	eval( parse(text=txt), parent.frame() )

in `foo()` will do the trick.

Bests
S?ren

> On 15.05.2015, at 00:02, William Dunlap <wdunlap at tibco.com> wrote:
> 
> You could use a 'replacement function' named 'bar<-', whose last argument
> is called 'value', and use bar(variable) <- newValue where you currently
> use foo(variable, newValue).
> 
> bar <- function(x) {
>     x + 3
> }
> `bar<-` <- function(x, value) {
>     bar(value)
> }
> 
> a <- NA
> bar(a) <- 4
> a
> # [1] 7
> b <- list(NA, NA)
> bar(b[[1]]) <- 4
> b
> #[[1]]
> #[1] 7
> #
> #[[2]]
> #[1] NA
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Thu, May 14, 2015 at 11:28 AM, <soeren.vogel at posteo.ch> wrote:
> Hello,
> 
> When I use function `foo` with list elements (example 2), it defines a new object named `b[[1]]`, which is not what I want.  How can I change the function code to show the desired behaviour for all data structures passed to the function?  Or is there a more appropriate way to sort of "pass by references" in a function?
> 
> Thanks
> S?ren
> 
> <src>
> bar <- function(x) {
>         return( x + 3 )
> }
> 
> foo <- function(x, value) {
>         nm <- deparse(substitute(x))
>         tmp <- bar( value )
>         assign(nm, tmp, parent.frame())
> }
> 
> # 1)
> a <- NA
> foo(a, 4)
> a # 7, fine :-)
> 
> # 2)
> b <- list(NA, NA)
> foo(b[[1]], 4) # the first list item should be 7
> b # wanted 7 but still list with two NAs :-(
> </src>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From jdnewmil at dcn.davis.CA.us  Fri May 15 16:42:52 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 15 May 2015 07:42:52 -0700
Subject: [R] How to make sub-headers in R
In-Reply-To: <44F908E52BA1744BB88DEB8E10103AAD82F58CA8@KIRK.ts.odu.edu>
References: <44F908E52BA1744BB88DEB8E10103AAD82F58CA8@KIRK.ts.odu.edu>
Message-ID: <C189D215-DA73-46DB-9E1A-DD2D4E2E1EDA@dcn.davis.CA.us>

I think you are not interpreting what is happening correctly. Column names are labels used for purposes of referring to the data in your R code. That they might also be useful in presenting data in output is coincidental. The fact that many data input functions replace spaces in those labels with periods should convince you of this fact.

On the other hand, the options available when you output that table usually depend on where you want to display the result, which you have not mentioned. For example the tables package has many options for labeling columns if you are generating HTML or LaTeX output. Or, you could write your own function to generate any output format you want.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 15, 2015 6:55:17 AM PDT, "Liao, Hongsheng" <HLiao at odu.edu> wrote:
>I know how to make one-row header for a data frame using "colnames". 
>Is there any function to insert sub-header between the first row of the
>data and the header?  Thanks
>
>Hongsheng (Hank) Liao, PhD.
>Lab Manager
>Center for Quantitative  Fisheries Ecology
>Old Dominion University
>757-683-4571
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Fri May 15 16:48:51 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 15 May 2015 07:48:51 -0700
Subject: [R] How to make sub-headers in R
In-Reply-To: <44F908E52BA1744BB88DEB8E10103AAD82F58CA8@KIRK.ts.odu.edu>
References: <44F908E52BA1744BB88DEB8E10103AAD82F58CA8@KIRK.ts.odu.edu>
Message-ID: <CACk-te1LcSnbao8q9VTUKYpOXyun=fvyWWoH1QHn2Cm_mwd0yA@mail.gmail.com>

Hank:

1. No.

2. You would do well to go through an R tutorial -- the "Introduction
to R" ships with R, but there are many more on the Web --  as you
appear to be applying spreadsheet type concepts to R's data.frame data
structure. While there certainly is a resemblance, conflating the two
is a grave error that will get you into a lot of trouble. If you wish
to use R, learn R; don't intuit or presume.

3. One way to simulate what you want to do is to attach a "subhead"
attribute to your data frame, class this structure( e.g.
c("frame_with_subhead","data.frame") ) and write a (S3)
print.frame_with_subhead method to print objects of the class in some
suitable way. See ?attributes, ?attr, and ?UseMethod. However, all
these man pages will be terse and assume that you have done the
aforementioned homework of learning R. You could, of course, use S4
classes or any other OO system available for R instead of S3.

HTH.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, May 15, 2015 at 6:55 AM, Liao, Hongsheng <HLiao at odu.edu> wrote:
> I know how to make one-row header for a data frame using "colnames".  Is there any function to insert sub-header between the first row of the data and the header?  Thanks
>
> Hongsheng (Hank) Liao, PhD.
> Lab Manager
> Center for Quantitative  Fisheries Ecology
> Old Dominion University
> 757-683-4571
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri May 15 16:49:27 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 15 May 2015 07:49:27 -0700
Subject: [R] Deparse substitute assign with list elements
In-Reply-To: <CD5C0F59-C13F-48C6-834D-4D414C5F73AC@posteo.ch>
References: <CDF73919-52A4-442D-8104-1E5F7E195081@posteo.ch>
	<CAF8bMcZrX4LnXE7VFGVB0XZi3kT22N_AQtzY9xyStrvVhX8_kQ@mail.gmail.com>
	<CD5C0F59-C13F-48C6-834D-4D414C5F73AC@posteo.ch>
Message-ID: <CAF8bMcbzW+EecJVLJ0FtG_039Bwo_yZZd2RM7uwx3uvjUKwx4g@mail.gmail.com>

        txt <- paste( nm, '<-', tmp, sep='' )
        eval( parse(text=txt), parent.frame() )

        in `foo()` will do the trick.

Yuck.

If you use that sort of syntax your code becomes hard to understand and
you risk changing variables that users do not want changed.  When the
use uses something like bar(x)<-newValue she knows that 'bar' is going to
change.

Your new code will also fail if you try something like foo(b+10).


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, May 15, 2015 at 1:50 AM, <soeren.vogel at posteo.ch> wrote:

> Thanks, Bill, I should have googled more carefully:
>
>
> http://stackoverflow.com/questions/9561053/assign-values-to-a-list-element-in-r
>
> So, remove
>
>         assign(nm, tmp, parent.frame())
>
> and add
>
>         txt <- paste( nm, '<-', tmp, sep='' )
>         eval( parse(text=txt), parent.frame() )
>
> in `foo()` will do the trick.
>
> Bests
> S?ren
>
> > On 15.05.2015, at 00:02, William Dunlap <wdunlap at tibco.com> wrote:
> >
> > You could use a 'replacement function' named 'bar<-', whose last argument
> > is called 'value', and use bar(variable) <- newValue where you currently
> > use foo(variable, newValue).
> >
> > bar <- function(x) {
> >     x + 3
> > }
> > `bar<-` <- function(x, value) {
> >     bar(value)
> > }
> >
> > a <- NA
> > bar(a) <- 4
> > a
> > # [1] 7
> > b <- list(NA, NA)
> > bar(b[[1]]) <- 4
> > b
> > #[[1]]
> > #[1] 7
> > #
> > #[[2]]
> > #[1] NA
> >
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Thu, May 14, 2015 at 11:28 AM, <soeren.vogel at posteo.ch> wrote:
> > Hello,
> >
> > When I use function `foo` with list elements (example 2), it defines a
> new object named `b[[1]]`, which is not what I want.  How can I change the
> function code to show the desired behaviour for all data structures passed
> to the function?  Or is there a more appropriate way to sort of "pass by
> references" in a function?
> >
> > Thanks
> > S?ren
> >
> > <src>
> > bar <- function(x) {
> >         return( x + 3 )
> > }
> >
> > foo <- function(x, value) {
> >         nm <- deparse(substitute(x))
> >         tmp <- bar( value )
> >         assign(nm, tmp, parent.frame())
> > }
> >
> > # 1)
> > a <- NA
> > foo(a, 4)
> > a # 7, fine :-)
> >
> > # 2)
> > b <- list(NA, NA)
> > foo(b[[1]], 4) # the first list item should be 7
> > b # wanted 7 but still list with two NAs :-(
> > </src>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Fri May 15 16:53:57 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 15 May 2015 10:53:57 -0400
Subject: [R] How to make sub-headers in R
In-Reply-To: <44F908E52BA1744BB88DEB8E10103AAD82F58CA8@KIRK.ts.odu.edu>
References: <44F908E52BA1744BB88DEB8E10103AAD82F58CA8@KIRK.ts.odu.edu>
Message-ID: <AFBC1366-E8FD-4458-BD6A-934FFC97E25B@utoronto.ca>


On May 15, 2015, at 9:55 AM, Liao, Hongsheng <HLiao at odu.edu> wrote:

> I know how to make one-row header for a data frame using "colnames".  Is there any function to insert sub-header between the first row of the data and the header?  Thanks

The elements of a data frame's columns are all of the same type. Inserting an extra row with character values would coerce the entire column to be of type character:

myDf <- data.frame(a=c(1:3),b=letters[1:3], C=LETTERS[1:3], stringsAsFactors=FALSE)
sapply(myDf, class)
          a           b           C 
  "integer" "character" "character" 
myDf <- rbind(c("text1", "text2", "text3"), myDf)
myDf
      a     b     C
1 text1 text2 text3
2     1     a     A
3     2     b     B
4     3     c     C

sapply(myDf, class)
          a           b           C 
"character" "character" "character" 

In addition, you shouldn't be thinking about the "header" as being a textual description anyway: the colname is actually much like a variable name, a label to identify a column. If you think of an Excel file (I think this is where your question is coming from), the names are the A, B ... Z, AA, AB ... names. It just so happens that R can construct column names from data it finds in a "header row". But they are _attributes_ of the data frame, not part of the contents. However you can look at the attributes ...
attributes(myDf)
$names
[1] "a" "b" "C"

$row.names
[1] 1 2 3 4

$class
[1] "data.frame"

attributes(myDf)$names
[1] "a" "b" "C"


... and you can add additional attributes:

attributes(myDf)$subheaders <- c("text1", "text2", "text3")

attributes(myDf)
$names
[1] "a" "b" "C"

$row.names
[1] 1 2 3 4

$class
[1] "data.frame"

$subheaders
[1] "text1" "text2" "text3"


Hope this helps.
Boris







> 
> Hongsheng (Hank) Liao, PhD.
> Lab Manager
> Center for Quantitative  Fisheries Ecology
> Old Dominion University
> 757-683-4571
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri May 15 17:17:07 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 15 May 2015 11:17:07 -0400
Subject: [R] tables package: localization of "All" subtotals label
In-Reply-To: <CAJJcQDPqCvXM4i=5P3_a6WFaoRbAMxAHGgqimkzsvijP4W1BEQ@mail.gmail.com>
References: <CAJJcQDPqCvXM4i=5P3_a6WFaoRbAMxAHGgqimkzsvijP4W1BEQ@mail.gmail.com>
Message-ID: <55560DF3.1040200@gmail.com>

On 15/05/2015 10:38 AM, Patricio Cuar?n wrote:
> Hello. I'd like to know how could I localize (or otherwise change the
> string) of the "All" subtotal that appears when using something like
> library(tables)
> data(iris)
> 
> tabular((Species + 1) ~ (n=1) + Format(digits=2)* + (Sepal.Length +
> Sepal.Width)*(mean + sd), data=iris)
> 
> (that's the first example of the documentation, which btw doesn't seem to work):

You have an extra "+" in there.  The tables vignette is written in
Sweave, which displays prompts like those in the R console.  You don't
want to include them in cut-and-paste versions of the code.

To change "All" to some other string, you could use Heading():


tabular( (Species + Heading("Todos")*1) ~ (n=1) + Format(digits=2)*
         (Sepal.Length + Sepal.Width)*(mean + sd), data=iris )

                Sepal.Length      Sepal.Width
 Species    n   mean         sd   mean        sd
 setosa      50 1.00         0.35 1.00        0.38
 versicolor  50 1.00         0.52 1.00        0.31
 virginica   50 1.00         0.64 1.00        0.32
 Todos      150 1.00         0.83 1.00        0.44

If you want to change the labels used for each level of the Species
variable, you would use the "levelnames" argument to Factor() or one of
the related functions.

Duncan Murdoch

> 
> Error in e[[3]] : subscript out of bounds
> 
> 
> 
> Thanks!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From HLiao at odu.edu  Fri May 15 17:18:15 2015
From: HLiao at odu.edu (Liao, Hongsheng)
Date: Fri, 15 May 2015 15:18:15 +0000
Subject: [R] How to make sub-headers in R
In-Reply-To: <C189D215-DA73-46DB-9E1A-DD2D4E2E1EDA@dcn.davis.CA.us>
References: <44F908E52BA1744BB88DEB8E10103AAD82F58CA8@KIRK.ts.odu.edu>
	<C189D215-DA73-46DB-9E1A-DD2D4E2E1EDA@dcn.davis.CA.us>
Message-ID: <44F908E52BA1744BB88DEB8E10103AAD82F58D38@KIRK.ts.odu.edu>

Thanks for your response.  I want to make a LaTeX table with a title and subtitles.  Attached is an example made using Word. I can use "xtable()" and "print()" to generate a LaTeX table of it with "Age" as title.   However, I would like to make the second row "Interval (Inch) ........." as sub-title so that both the title and sub-title can be repeated on every page in my long table split among multiple pages.  In LaTeX, "\endhead" can repeat title but not the row of "Interval ..." because it is not title or sub-title.  I can copy and paste "Interval..." above "\endhead" to get the repetition of "Interval...".  However, I am trying to learn how to avoid "copy and paste", instead, let LaTeX do the job automatically.  I know that I am making the question more complicated than my original one and hope it is clear enough this time.

Hongsheng (Hank) Liao, PhD.
Lab Manager
Center for Quantitative  Fisheries Ecology
Old Dominion University
757-683-4571







-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us] 
Sent: Friday, May 15, 2015 10:43 AM
To: Liao, Hongsheng; r-help at r-project.org
Subject: Re: [R] How to make sub-headers in R

I think you are not interpreting what is happening correctly. Column names are labels used for purposes of referring to the data in your R code. That they might also be useful in presenting data in output is coincidental. The fact that many data input functions replace spaces in those labels with periods should convince you of this fact.

On the other hand, the options available when you output that table usually depend on where you want to display the result, which you have not mentioned. For example the tables package has many options for labeling columns if you are generating HTML or LaTeX output. Or, you could write your own function to generate any output format you want.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

On May 15, 2015 6:55:17 AM PDT, "Liao, Hongsheng" <HLiao at odu.edu> wrote:
>I know how to make one-row header for a data frame using "colnames". 
>Is there any function to insert sub-header between the first row of the 
>data and the header?  Thanks
>
>Hongsheng (Hank) Liao, PhD.
>Lab Manager
>Center for Quantitative  Fisheries Ecology Old Dominion University
>757-683-4571
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



--
BEGIN-ANTISPAM-VOTING-LINKS
------------------------------------------------------

Teach CanIt if this mail (ID 03OseHrzs) is spam:
Spam:        https://www.spamtrap.odu.edu/canit/b.php?i=03OseHrzs&m=a356b01b838f&t=20150515&c=s
Not spam:    https://www.spamtrap.odu.edu/canit/b.php?i=03OseHrzs&m=a356b01b838f&t=20150515&c=n
Forget vote: https://www.spamtrap.odu.edu/canit/b.php?i=03OseHrzs&m=a356b01b838f&t=20150515&c=f
------------------------------------------------------
END-ANTISPAM-VOTING-LINKS


From boris.steipe at utoronto.ca  Fri May 15 17:42:07 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 15 May 2015 11:42:07 -0400
Subject: [R] How to make sub-headers in R
In-Reply-To: <44F908E52BA1744BB88DEB8E10103AAD82F58D38@KIRK.ts.odu.edu>
References: <44F908E52BA1744BB88DEB8E10103AAD82F58CA8@KIRK.ts.odu.edu>
	<C189D215-DA73-46DB-9E1A-DD2D4E2E1EDA@dcn.davis.CA.us>
	<44F908E52BA1744BB88DEB8E10103AAD82F58D38@KIRK.ts.odu.edu>
Message-ID: <B4FE1B3A-CEC6-479B-9EAE-D030216AD3ED@utoronto.ca>

I don't see that being an option in xtable ... but looking at this:
   http://tex.stackexchange.com/questions/33510/how-do-i-create-the-headings-for-this-multirow-multicolum-table
... it seems to be pretty straightforward to write a function that writes LaTeX output from your dataframe for the Tex multirow package.


B.

On May 15, 2015, at 11:18 AM, Liao, Hongsheng <HLiao at odu.edu> wrote:

> Thanks for your response.  I want to make a LaTeX table with a title and subtitles.  Attached is an example made using Word. I can use "xtable()" and "print()" to generate a LaTeX table of it with "Age" as title.   However, I would like to make the second row "Interval (Inch) ........." as sub-title so that both the title and sub-title can be repeated on every page in my long table split among multiple pages.  In LaTeX, "\endhead" can repeat title but not the row of "Interval ..." because it is not title or sub-title.  I can copy and paste "Interval..." above "\endhead" to get the repetition of "Interval...".  However, I am trying to learn how to avoid "copy and paste", instead, let LaTeX do the job automatically. I know that I am making the question more complicated than my original one and hope it is clear enough this time.
> 
> Hongsheng (Hank) Liao, PhD.
> Lab Manager
> Center for Quantitative  Fisheries Ecology
> Old Dominion University
> 757-683-4571
> 
> 
> 
> 
> 
> 
> 
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us] 
> Sent: Friday, May 15, 2015 10:43 AM
> To: Liao, Hongsheng; r-help at r-project.org
> Subject: Re: [R] How to make sub-headers in R
> 
> I think you are not interpreting what is happening correctly. Column names are labels used for purposes of referring to the data in your R code. That they might also be useful in presenting data in output is coincidental. The fact that many data input functions replace spaces in those labels with periods should convince you of this fact.
> 
> On the other hand, the options available when you output that table usually depend on where you want to display the result, which you have not mentioned. For example the tables package has many options for labeling columns if you are generating HTML or LaTeX output. Or, you could write your own function to generate any output format you want.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
> 
> On May 15, 2015 6:55:17 AM PDT, "Liao, Hongsheng" <HLiao at odu.edu> wrote:
>> I know how to make one-row header for a data frame using "colnames". 
>> Is there any function to insert sub-header between the first row of the 
>> data and the header?  Thanks
>> 
>> Hongsheng (Hank) Liao, PhD.
>> Lab Manager
>> Center for Quantitative  Fisheries Ecology Old Dominion University
>> 757-683-4571
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --
> BEGIN-ANTISPAM-VOTING-LINKS
> ------------------------------------------------------
> 
> Teach CanIt if this mail (ID 03OseHrzs) is spam:
> Spam:        https://www.spamtrap.odu.edu/canit/b.php?i=03OseHrzs&m=a356b01b838f&t=20150515&c=s
> Not spam:    https://www.spamtrap.odu.edu/canit/b.php?i=03OseHrzs&m=a356b01b838f&t=20150515&c=n
> Forget vote: https://www.spamtrap.odu.edu/canit/b.php?i=03OseHrzs&m=a356b01b838f&t=20150515&c=f
> ------------------------------------------------------
> END-ANTISPAM-VOTING-LINKS
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri May 15 19:02:43 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 15 May 2015 10:02:43 -0700
Subject: [R] print dataframe names in loop
In-Reply-To: <CAHOWgNXcQXq32+gkUcZ14UDMsungZoFSLj2Hv0QP+L_mFyA4Jg@mail.gmail.com>
References: <CAHOWgNXcQXq32+gkUcZ14UDMsungZoFSLj2Hv0QP+L_mFyA4Jg@mail.gmail.com>
Message-ID: <200457B1-9A21-4BBA-87F6-B4F83E03395D@comcast.net>


On May 15, 2015, at 5:05 AM, Kai Mx wrote:

> Hi everybody,
> 
> I just can't  figure this out:
> 
> I have a loop trough several dataframes such as
> 
> for (df in list(df1, df2, df3, ...)) {
> ..some functions with df..
> }
> 
> now I want to print out the current dataframes name (ie the list items
> name) with the cat command before the actual functions to have better
> orientation in the output.
> However, I haven't been successful with different variations of deparse(),
> substitute(), (cat(substitute(df)) gives me 'df' for the whole loop).

You were close. Try:

 deparse(substitute(df))

> 
> Could somebody please enlighten me?
> 
> Thanks so much!
> 
> Best,
> 
> Kai
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From govokai at gmail.com  Fri May 15 19:05:53 2015
From: govokai at gmail.com (Kai Mx)
Date: Fri, 15 May 2015 19:05:53 +0200
Subject: [R] print dataframe names in loop
In-Reply-To: <CA+8X3fXUwjVTAJ3fUOHB_5VA1gsv2XZJBrugHbwa6bViiP5C2A@mail.gmail.com>
References: <CAHOWgNXcQXq32+gkUcZ14UDMsungZoFSLj2Hv0QP+L_mFyA4Jg@mail.gmail.com>
	<CA+8X3fXUwjVTAJ3fUOHB_5VA1gsv2XZJBrugHbwa6bViiP5C2A@mail.gmail.com>
Message-ID: <CAHOWgNXo+Tz_0KfGqY9R95NBDEuk_PTCGvW-S4n00xVJmG+DFQ@mail.gmail.com>

thanks, that would work, but isn't there a maybe more elegant way to
"extract" the name from the df variable within the current for (df in
list()) loop?

Best,

Kai


On Fri, May 15, 2015 at 2:20 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Kai,
> One way is to name the components of your list with the names of the
> data frames:
>
> df1<-data.frame(a=1:3)
> df2<-data.frame(a=4:6)
> df3<-data.frame(a=7:9)
> dflist<-list(df1,df2,df3)
> names(dflist)<-c("df1","df2","df3")
> for(i in 1:length(dflist)) cat(names(dflist)[i],"\n")
> df1
> df2
> df3
>
> Jim
>
>
> On Fri, May 15, 2015 at 10:05 PM, Kai Mx <govokai at gmail.com> wrote:
> > Hi everybody,
> >
> > I just can't  figure this out:
> >
> > I have a loop trough several dataframes such as
> >
> > for (df in list(df1, df2, df3, ...)) {
> > ..some functions with df..
> > }
> >
> > now I want to print out the current dataframes name (ie the list items
> > name) with the cat command before the actual functions to have better
> > orientation in the output.
> > However, I haven't been successful with different variations of
> deparse(),
> > substitute(), (cat(substitute(df)) gives me 'df' for the whole loop).
> >
> > Could somebody please enlighten me?
> >
> > Thanks so much!
> >
> > Best,
> >
> > Kai
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From oma.gonzales at gmail.com  Fri May 15 19:09:14 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Fri, 15 May 2015 12:09:14 -0500
Subject: [R] print dataframe names in loop
In-Reply-To: <CA+8X3fXUwjVTAJ3fUOHB_5VA1gsv2XZJBrugHbwa6bViiP5C2A@mail.gmail.com>
References: <CAHOWgNXcQXq32+gkUcZ14UDMsungZoFSLj2Hv0QP+L_mFyA4Jg@mail.gmail.com>
	<CA+8X3fXUwjVTAJ3fUOHB_5VA1gsv2XZJBrugHbwa6bViiP5C2A@mail.gmail.com>
Message-ID: <CAM-xyZjdWNoLJq4XFVbc8y-wv568ACsuKvxBGPcRhGoqUxY6eg@mail.gmail.com>

Two seconds using google:

http://stackoverflow.com/questions/9002227/how-to-get-the-name-of-a-data-frame-within-a-list

2015-05-15 7:20 GMT-05:00 Jim Lemon <drjimlemon at gmail.com>:

> Hi Kai,
> One way is to name the components of your list with the names of the
> data frames:
>
> df1<-data.frame(a=1:3)
> df2<-data.frame(a=4:6)
> df3<-data.frame(a=7:9)
> dflist<-list(df1,df2,df3)
> names(dflist)<-c("df1","df2","df3")
> for(i in 1:length(dflist)) cat(names(dflist)[i],"\n")
> df1
> df2
> df3
>
> Jim
>
>
> On Fri, May 15, 2015 at 10:05 PM, Kai Mx <govokai at gmail.com> wrote:
> > Hi everybody,
> >
> > I just can't  figure this out:
> >
> > I have a loop trough several dataframes such as
> >
> > for (df in list(df1, df2, df3, ...)) {
> > ..some functions with df..
> > }
> >
> > now I want to print out the current dataframes name (ie the list items
> > name) with the cat command before the actual functions to have better
> > orientation in the output.
> > However, I haven't been successful with different variations of
> deparse(),
> > substitute(), (cat(substitute(df)) gives me 'df' for the whole loop).
> >
> > Could somebody please enlighten me?
> >
> > Thanks so much!
> >
> > Best,
> >
> > Kai
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jszhao at yeah.net  Fri May 15 17:20:22 2015
From: jszhao at yeah.net (Jinsong Zhao)
Date: Fri, 15 May 2015 23:20:22 +0800
Subject: [R] ANOVA for nested design
Message-ID: <55560EB6.10206@yeah.net>

Hi there,

The following is a simple design. A and B are factors with their levels 
randomly selected. In other words, A and B are random.

The data is recorded in "abc", as:
 > dput(abc)
structure(list(water = c(12.1, 12.1, 12.8, 12.8, 14.4, 14.4,
14.7, 14.5, 23.1, 23.4, 28.1, 28.8), A = structure(c(1L, 1L,
1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L), .Label = c("1", "2",
"3"), class = "factor"), B = structure(c(1L, 1L, 2L, 2L, 3L,
3L, 4L, 4L, 5L, 5L, 6L, 6L), .Label = c("1", "2", "3", "4", "5",
"6"), class = "factor")), .Names = c("water", "A", "B"), row.names = c(NA,
-12L), class = "data.frame")

I run ems from afex package:

 > ems(n ~ A*B, nested="A/B", random="AB")
       VarianceComponent
Effect e B A
      A 1 n nb
      B 1 n
      e 1
attr(,"terms")
[1] n a b

So, the ANOVA for this design is something like:

 > summary(aov(water ~ A + Error(B), abc))

Error: B
           Df Sum Sq Mean Sq F value Pr(>F)
A          2  416.8  208.39   22.68 0.0155 *
Residuals  3   27.6    9.19
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Error: Within
           Df Sum Sq Mean Sq F value Pr(>F)
Residuals  6   0.31 0.05167
 > summary(aov(water ~ B + Error(A), abc))

Error: A
   Df Sum Sq Mean Sq
B  2  416.8   208.4

Error: Within
           Df Sum Sq Mean Sq F value   Pr(>F)
B          3  27.57   9.190   177.9 2.99e-06 ***
Residuals  6   0.31   0.052
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
 >

Is it possible to write the above two aov(...) into one aov(...)?

Any suggestions will be really appreciated. Thanks in advance.

Best regards,
Jinsong


From limingwei19890622 at gmail.com  Fri May 15 19:00:08 2015
From: limingwei19890622 at gmail.com (Mingwei Li)
Date: Fri, 15 May 2015 12:00:08 -0500
Subject: [R] =?utf-8?q?Is_anyone_learned_Coursera_course_named_=E2=80=9CR_?=
 =?utf-8?q?Programming=E2=80=9D_of_Johns_Hopkins_Roger_D=2E_Peng=3F?=
Message-ID: <B9209687-B034-480A-B5FB-F1A52CB1D3C8@gmail.com>

Hi all,
Is anyone learned Coursera course named ?R Programming? of Johns Hopkins Roger D. Peng? 
I have one question of how to submit my homework.
Following is the request of the question:
pollutantmean <- function(directory, pollutant, id = 1:332) {
        ## 'directory' is a character vector of length 1 indicating
        ## the location of the CSV files

        ## 'pollutant' is a character vector of length 1 indicating
        ## the name of the pollutant for which we will calculate the
        ## mean; either "sulfate" or "nitrate".

        ## 'id' is an integer vector indicating the monitor ID numbers
        ## to be used

        ## Return the mean of the pollutant across all monitors list
        ## in the 'id' vector (ignoring NA values)
        ## NOTE: Do not round the result!
}
I have successfully come out the correct results. However, I do not know how to submit my homework step by step. 
I have attached one picture in this email, is anyone can help me out?
Thank you so much!

From oma.gonzales at gmail.com  Fri May 15 19:17:37 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Fri, 15 May 2015 12:17:37 -0500
Subject: [R]
	=?utf-8?q?Is_anyone_learned_Coursera_course_named_=E2=80=9CR_?=
	=?utf-8?q?Programming=E2=80=9D_of_Johns_Hopkins_Roger_D=2E_Peng=3F?=
In-Reply-To: <B9209687-B034-480A-B5FB-F1A52CB1D3C8@gmail.com>
References: <B9209687-B034-480A-B5FB-F1A52CB1D3C8@gmail.com>
Message-ID: <CAM-xyZhJ8dz2Z2phsKQ-rx9_ehLfAQi00mdpHBfc0m1ro5eYxQ@mail.gmail.com>

You need to save your pollutantmean in your wroking directory.

Then use the submit function they give in the homeworks page. Download it,
or use the source() function.

Then in the console, use "submit()"... thes functions needs your
identification as student... then it prints notes to continue with the
process.

Good luck.

2015-05-15 12:00 GMT-05:00 Mingwei Li <limingwei19890622 at gmail.com>:

> Hi all,
> Is anyone learned Coursera course named ?R Programming? of Johns Hopkins
> Roger D. Peng?
> I have one question of how to submit my homework.
> Following is the request of the question:
> pollutantmean <- function(directory, pollutant, id = 1:332) {
>         ## 'directory' is a character vector of length 1 indicating
>         ## the location of the CSV files
>
>         ## 'pollutant' is a character vector of length 1 indicating
>         ## the name of the pollutant for which we will calculate the
>         ## mean; either "sulfate" or "nitrate".
>
>         ## 'id' is an integer vector indicating the monitor ID numbers
>         ## to be used
>
>         ## Return the mean of the pollutant across all monitors list
>         ## in the 'id' vector (ignoring NA values)
>         ## NOTE: Do not round the result!
> }
> I have successfully come out the correct results. However, I do not know
> how to submit my homework step by step.
> I have attached one picture in this email, is anyone can help me out?
> Thank you so much!
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dotlundberg at gmail.com  Fri May 15 19:16:50 2015
From: dotlundberg at gmail.com (Dot Lundberg)
Date: Fri, 15 May 2015 13:16:50 -0400
Subject: [R] R free courses-Recommendations
Message-ID: <CAMUnHGmR=kra-TMk2j01iohgeu5Quuj28yUQcbZ_NQvkFryGWA@mail.gmail.com>

Hi all,

I am looking for suggestions on R free courses. Any suggestions?

Thanks!

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Fri May 15 19:51:10 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 15 May 2015 17:51:10 +0000
Subject: [R] Need help with lm function on MAC OS X. R version - 3.2.0
In-Reply-To: <CAOpgo6iks1Xh3BVZKNc8Npb_fVvforg0MA1TV6HqZRt14BsGng@mail.gmail.com>
References: <CAOpgo6iks1Xh3BVZKNc8Npb_fVvforg0MA1TV6HqZRt14BsGng@mail.gmail.com>
Message-ID: <D17B7EBD.129BD7%macqueen1@llnl.gov>

For sure this is not a Mac OS X related problem.

If the data frame is named BSE then your lm() calls need to say data =
BSE, not data = bse.

How many factpr levels does company have?

Besides all that, I would suggest you start with simpler uses of lm, and
find out if they work. For example, try

  lm( CP ~ company, data=BSE)

If that works, then start adding variables on the right hand side until
you get one that causes errors.

The message about a 'closure' suggests that you are somehow asking lm() to
perform analyses on an R function instead of data in a data frame. That
would be very strange, and I have trouble imagining how that could be.

Are you sure all your data is numeric? Try
  lapply( BSE, class)
  str(BSE)


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/14/15, 5:07 AM, "samarvir singh" <samarvir1996 at gmail.com> wrote:

>I Have a data frame named BSE and CP is my independent variable
>and here;s the error I get if I try to run an lm function
>any idea whats wrong
>
>P.S - all my data is in numeric except company which is a factor. I have
>2700 row and 450 variable
>
>P.P.S -  I have no missing data, I have 0 in Empty field.
>
>> BSE_Reg <- lm(CP ~.-company, data = bse)
>Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>  contrasts can be applied only to factors with 2 or more levels
>
>> BSE_Reg <- lm(CP ~., data = bse)
>Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>  contrasts can be applied only to factors with 2 or more levels
>Error in as.character(tools:::httpdPort) :
>  cannot coerce type 'closure' to vector of type 'character'
>Error in as.character(tools:::httpdPort) :
>  cannot coerce type 'closure' to vector of type 'character'
>Error in as.character(tools:::httpdPort) :
>  cannot coerce type 'closure' to vector of type 'character'
>Error in as.character(tools:::httpdPort) :
>  cannot coerce type 'closure' to vector of type 'character'
>
>
>
>
>
>> R.Version()
>$platform
>[1] "x86_64-apple-darwin13.4.0"
>
>$arch
>[1] "x86_64"
>
>$os
>[1] "darwin13.4.0"
>
>$system
>[1] "x86_64, darwin13.4.0"
>
>$status
>[1] ""
>
>$major
>[1] "3"
>
>$minor
>[1] "2.0"
>
>$year
>[1] "2015"
>
>$month
>[1] "04"
>
>$day
>[1] "16"
>
>$`svn rev`
>[1] "68180"
>
>$language
>[1] "R"
>
>$version.string
>[1] "R version 3.2.0 (2015-04-16)"
>
>$nickname
>[1] "Full of Ingredients"
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From drobichaud at lgl.com  Fri May 15 19:52:50 2015
From: drobichaud at lgl.com (David Robichaud)
Date: Fri, 15 May 2015 10:52:50 -0700
Subject: [R] Interpreting GLM Interaction Contrasts in R (using glht)
In-Reply-To: <CAJuCY5wqzsLjGxuauME5sstM5n_tjwuQBakvp3h5coCVMUFM5A@mail.gmail.com>
References: <55552769.2080206@lgl.com>
	<CAJuCY5wqzsLjGxuauME5sstM5n_tjwuQBakvp3h5coCVMUFM5A@mail.gmail.com>
Message-ID: <55563272.6080408@lgl.com>

Hi Thierry and everyone else,
This makes sense!  I knew it would be something totally straightforward.
Thanks for taking the time to let me know,
Dave


From HLiao at odu.edu  Fri May 15 20:15:03 2015
From: HLiao at odu.edu (Liao, Hongsheng)
Date: Fri, 15 May 2015 18:15:03 +0000
Subject: [R] How to make sub-headers in R
In-Reply-To: <B4FE1B3A-CEC6-479B-9EAE-D030216AD3ED@utoronto.ca>
References: <44F908E52BA1744BB88DEB8E10103AAD82F58CA8@KIRK.ts.odu.edu>
	<C189D215-DA73-46DB-9E1A-DD2D4E2E1EDA@dcn.davis.CA.us>
	<44F908E52BA1744BB88DEB8E10103AAD82F58D38@KIRK.ts.odu.edu>
	<B4FE1B3A-CEC6-479B-9EAE-D030216AD3ED@utoronto.ca>
Message-ID: <44F908E52BA1744BB88DEB8E10103AAD82F58DFA@KIRK.ts.odu.edu>

Thank you very much for trying to help me.  Using following R codes, I can generate a LaTeX long table which can repeat "Age" and "Interval & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & Totals" as title and subtitle across multiple pages.  However, the part of "0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11" is for fish ages (I am working on fish) which vary between species and years within each species, and R can't update this part according to different species and years.  As a result, I have to manually update it in either my R or LaTeX codes, which I am trying to avoid in order to save time and to minimize errors.  It looks like there is no solution to my problem so far.  Anyway, thank you again and have a good weekend.

age.addtorow          <- list()
age.addtorow$pos      <- list()
age.addtorow$pos[[1]] <- c(0)
age.addtorow$command  <- c(paste("\\hline \n",
				     "\\endfirsthead \n",
				     "\\multicolumn{4}{l}{{", paste("Table", "\\thetable\\ Continued}}", paste("\\", "\\", sep="")), paste("\n"),
       			     "\\hline \n",
				     "\\multicolumn{7}{r}{{Age}}", paste("\\", "\\", sep=""), paste("\n"),
				     "\\hline \n",
				     "Interval & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & Totals", paste("\\", "\\", sep=""), paste("\n"),
				     "\\hline \n",
				     "\\endhead \n",
                             "\\hline \n",
                             "{\\footnotesize To continue} \n",
                             "\\endfoot \n",
                             "\\endlastfoot \n",sep=""))

print(x.age.composition, file=output.age.composition.location.file, include.rownames = FALSE, 
      				include.colnames = TRUE, hline.after = c(-1, -1, 0, 1, nrow(x.age.composition), nrow(x.age.composition)), type="latex",
					append=FALSE, floating=FALSE, tabular.environment = "longtable", na.print = "", caption.placement = "top", 
					sanitize.colnames.function = force, add.to.row = age.addtorow))  


-----Original Message-----
From: Boris Steipe [mailto:boris.steipe at utoronto.ca] 
Sent: Friday, May 15, 2015 11:42 AM
To: Liao, Hongsheng
Cc: r-help at r-project.org
Subject: Re: [R] How to make sub-headers in R

I don't see that being an option in xtable ... but looking at this:
   http://tex.stackexchange.com/questions/33510/how-do-i-create-the-headings-for-this-multirow-multicolum-table
... it seems to be pretty straightforward to write a function that writes LaTeX output from your dataframe for the Tex multirow package.


B.

On May 15, 2015, at 11:18 AM, Liao, Hongsheng <HLiao at odu.edu> wrote:

> Thanks for your response.  I want to make a LaTeX table with a title and subtitles.  Attached is an example made using Word. I can use "xtable()" and "print()" to generate a LaTeX table of it with "Age" as title.   However, I would like to make the second row "Interval (Inch) ........." as sub-title so that both the title and sub-title can be repeated on every page in my long table split among multiple pages.  In LaTeX, "\endhead" can repeat title but not the row of "Interval ..." because it is not title or sub-title.  I can copy and paste "Interval..." above "\endhead" to get the repetition of "Interval...".  However, I am trying to learn how to avoid "copy and paste", instead, let LaTeX do the job automatically. I know that I am making the question more complicated than my original one and hope it is clear enough this time.
> 
> Hongsheng (Hank) Liao, PhD.
> Lab Manager
> Center for Quantitative  Fisheries Ecology Old Dominion University
> 757-683-4571
> 
> 
> 
> 
> 
> 
> 
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us]
> Sent: Friday, May 15, 2015 10:43 AM
> To: Liao, Hongsheng; r-help at r-project.org
> Subject: Re: [R] How to make sub-headers in R
> 
> I think you are not interpreting what is happening correctly. Column names are labels used for purposes of referring to the data in your R code. That they might also be useful in presenting data in output is coincidental. The fact that many data input functions replace spaces in those labels with periods should convince you of this fact.
> 
> On the other hand, the options available when you output that table usually depend on where you want to display the result, which you have not mentioned. For example the tables package has many options for labeling columns if you are generating HTML or LaTeX output. Or, you could write your own function to generate any output format you want.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ----------------------------------------------------------------------
> ----- Sent from my phone. Please excuse my brevity.
> 
> On May 15, 2015 6:55:17 AM PDT, "Liao, Hongsheng" <HLiao at odu.edu> wrote:
>> I know how to make one-row header for a data frame using "colnames". 
>> Is there any function to insert sub-header between the first row of 
>> the data and the header?  Thanks
>> 
>> Hongsheng (Hank) Liao, PhD.
>> Lab Manager
>> Center for Quantitative  Fisheries Ecology Old Dominion University
>> 757-683-4571
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
BEGIN-ANTISPAM-VOTING-LINKS
------------------------------------------------------
Teach CanIt if this mail (ID 01OsfJgXE) is spam:Spam:        https://www.spamtrap.odu.edu/canit/b.php?i=01OsfJgXE&m=d0e228a83e81&t=20150515&c=sNot spam:    https://www.spamtrap.odu.edu/canit/b.php?i=01OsfJgXE&m=d0e228a83e81&t=20150515&c=nForget vote: https://www.spamtrap.odu.edu/canit/b.php?i=01OsfJgXE&m=d0e228a83e81&t=20150515&c=f
------------------------------------------------------
END-ANTISPAM-VOTING-LINKS


From murdoch.duncan at gmail.com  Fri May 15 20:16:14 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 15 May 2015 14:16:14 -0400
Subject: [R] tables package: localization of "All" subtotals label
In-Reply-To: <CAJJcQDPqCvXM4i=5P3_a6WFaoRbAMxAHGgqimkzsvijP4W1BEQ@mail.gmail.com>
References: <CAJJcQDPqCvXM4i=5P3_a6WFaoRbAMxAHGgqimkzsvijP4W1BEQ@mail.gmail.com>
Message-ID: <555637EE.8000006@gmail.com>

On 15/05/2015 10:38 AM, Patricio Cuar?n wrote:
> Hello. I'd like to know how could I localize (or otherwise change the
> string) of the "All" subtotal that appears when using something like

I just took a look at the source of the package.  Currently there is no
way to use the R internationalization facilities to change the default
display of "All", but that's easy to add.  The only other fixed word
displayed by the package is "Percent".

I'll commit changes to allow these to be set automatically.  If you are
really interested in this, you can read the online description at

http://developer.r-project.org/Translations30.html

for how to put together a translation file for your language; I'd be
happy to include it in future versions of tables.  (The translation
shouldn't be hard for only two words, the hard part is likely getting
the tools to install a translation.  Error message translations could
also be included.)

Duncan Murdoch


From boris.steipe at utoronto.ca  Fri May 15 20:34:37 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 15 May 2015 14:34:37 -0400
Subject: [R] How to make sub-headers in R
In-Reply-To: <44F908E52BA1744BB88DEB8E10103AAD82F58DFA@KIRK.ts.odu.edu>
References: <44F908E52BA1744BB88DEB8E10103AAD82F58CA8@KIRK.ts.odu.edu>
	<C189D215-DA73-46DB-9E1A-DD2D4E2E1EDA@dcn.davis.CA.us>
	<44F908E52BA1744BB88DEB8E10103AAD82F58D38@KIRK.ts.odu.edu>
	<B4FE1B3A-CEC6-479B-9EAE-D030216AD3ED@utoronto.ca>
	<44F908E52BA1744BB88DEB8E10103AAD82F58DFA@KIRK.ts.odu.edu>
Message-ID: <DDF46500-4704-47F9-A621-790F2D2BDB53@utoronto.ca>

Hongsheng -
If you can define the fish ages programmatically, you can also get the values into your output. I had understood your "sub-header" to be constant per column. Does it need to be updated for different rows? Or are you just missing the fact that paste() can take variables, and even functions like so:

R > myAge <- function(x) { x*x }
R > ages <- c(1, 1, 2, 3, 5, 8)
R > paste("Interval ",
       " & 1",            # in string
       " & ", 2,          # constant
       " & ", ages[4],    # from vector
       " & ", ages[5], 
       " & ", myAge(5),   # from function
       "\n", sep="")
[1] "Interval  & 1 & 2 & 3 & 5 & 25\n"


Cheers,
Boris




On May 15, 2015, at 2:15 PM, Liao, Hongsheng <HLiao at odu.edu> wrote:

> Thank you very much for trying to help me.  Using following R codes, I can generate a LaTeX long table which can repeat "Age" and "Interval & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & Totals" as title and subtitle across multiple pages.  However, the part of "0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11" is for fish ages (I am working on fish) which vary between species and years within each species, and R can't update this part according to different species and years.  As a result, I have to manually update it in either my R or LaTeX codes, which I am trying to avoid in order to save time and to minimize errors.  It looks like there is no solution to my problem so far.  Anyway, thank you again and have a good weekend.
> 
> age.addtorow          <- list()
> age.addtorow$pos      <- list()
> age.addtorow$pos[[1]] <- c(0)
> age.addtorow$command  <- c(paste("\\hline \n",
> 				     "\\endfirsthead \n",
> 				     "\\multicolumn{4}{l}{{", paste("Table", "\\thetable\\ Continued}}", paste("\\", "\\", sep="")), paste("\n"),
>       			     "\\hline \n",
> 				     "\\multicolumn{7}{r}{{Age}}", paste("\\", "\\", sep=""), paste("\n"),
> 				     "\\hline \n",
> 				     "Interval & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & Totals", paste("\\", "\\", sep=""), paste("\n"),
> 				     "\\hline \n",
> 				     "\\endhead \n",
>                             "\\hline \n",
>                             "{\\footnotesize To continue} \n",
>                             "\\endfoot \n",
>                             "\\endlastfoot \n",sep=""))
> 
> print(x.age.composition, file=output.age.composition.location.file, include.rownames = FALSE, 
>      				include.colnames = TRUE, hline.after = c(-1, -1, 0, 1, nrow(x.age.composition), nrow(x.age.composition)), type="latex",
> 					append=FALSE, floating=FALSE, tabular.environment = "longtable", na.print = "", caption.placement = "top", 
> 					sanitize.colnames.function = force, add.to.row = age.addtorow))  
> 
> 
> -----Original Message-----
> From: Boris Steipe [mailto:boris.steipe at utoronto.ca] 
> Sent: Friday, May 15, 2015 11:42 AM
> To: Liao, Hongsheng
> Cc: r-help at r-project.org
> Subject: Re: [R] How to make sub-headers in R
> 
> I don't see that being an option in xtable ... but looking at this:
>   http://tex.stackexchange.com/questions/33510/how-do-i-create-the-headings-for-this-multirow-multicolum-table
> ... it seems to be pretty straightforward to write a function that writes LaTeX output from your dataframe for the Tex multirow package.
> 
> 
> B.
> 
> On May 15, 2015, at 11:18 AM, Liao, Hongsheng <HLiao at odu.edu> wrote:
> 
>> Thanks for your response.  I want to make a LaTeX table with a title and subtitles.  Attached is an example made using Word. I can use "xtable()" and "print()" to generate a LaTeX table of it with "Age" as title.   However, I would like to make the second row "Interval (Inch) ........." as sub-title so that both the title and sub-title can be repeated on every page in my long table split among multiple pages.  In LaTeX, "\endhead" can repeat title but not the row of "Interval ..." because it is not title or sub-title.  I can copy and paste "Interval..." above "\endhead" to get the repetition of "Interval...".  However, I am trying to learn how to avoid "copy and paste", instead, let LaTeX do the job automatically. I know that I am making the question more complicated than my original one and hope it is clear enough this time.
>> 
>> Hongsheng (Hank) Liao, PhD.
>> Lab Manager
>> Center for Quantitative  Fisheries Ecology Old Dominion University
>> 757-683-4571
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us]
>> Sent: Friday, May 15, 2015 10:43 AM
>> To: Liao, Hongsheng; r-help at r-project.org
>> Subject: Re: [R] How to make sub-headers in R
>> 
>> I think you are not interpreting what is happening correctly. Column names are labels used for purposes of referring to the data in your R code. That they might also be useful in presenting data in output is coincidental. The fact that many data input functions replace spaces in those labels with periods should convince you of this fact.
>> 
>> On the other hand, the options available when you output that table usually depend on where you want to display the result, which you have not mentioned. For example the tables package has many options for labeling columns if you are generating HTML or LaTeX output. Or, you could write your own function to generate any output format you want.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                     Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ----------------------------------------------------------------------
>> ----- Sent from my phone. Please excuse my brevity.
>> 
>> On May 15, 2015 6:55:17 AM PDT, "Liao, Hongsheng" <HLiao at odu.edu> wrote:
>>> I know how to make one-row header for a data frame using "colnames". 
>>> Is there any function to insert sub-header between the first row of 
>>> the data and the header?  Thanks
>>> 
>>> Hongsheng (Hank) Liao, PhD.
>>> Lab Manager
>>> Center for Quantitative  Fisheries Ecology Old Dominion University
>>> 757-683-4571
>>> 
>>> 
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> --
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --
> BEGIN-ANTISPAM-VOTING-LINKS
> ------------------------------------------------------
> Teach CanIt if this mail (ID 01OsfJgXE) is spam:Spam:        https://www.spamtrap.odu.edu/canit/b.php?i=01OsfJgXE&m=d0e228a83e81&t=20150515&c=sNot spam:    https://www.spamtrap.odu.edu/canit/b.php?i=01OsfJgXE&m=d0e228a83e81&t=20150515&c=nForget vote: https://www.spamtrap.odu.edu/canit/b.php?i=01OsfJgXE&m=d0e228a83e81&t=20150515&c=f
> ------------------------------------------------------
> END-ANTISPAM-VOTING-LINKS


From dwinsemius at comcast.net  Fri May 15 22:11:54 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 15 May 2015 13:11:54 -0700
Subject: [R] print dataframe names in loop
In-Reply-To: <CAHOWgNXo+Tz_0KfGqY9R95NBDEuk_PTCGvW-S4n00xVJmG+DFQ@mail.gmail.com>
References: <CAHOWgNXcQXq32+gkUcZ14UDMsungZoFSLj2Hv0QP+L_mFyA4Jg@mail.gmail.com>
	<CA+8X3fXUwjVTAJ3fUOHB_5VA1gsv2XZJBrugHbwa6bViiP5C2A@mail.gmail.com>
	<CAHOWgNXo+Tz_0KfGqY9R95NBDEuk_PTCGvW-S4n00xVJmG+DFQ@mail.gmail.com>
Message-ID: <03614043-DBDD-4215-8A78-D565F622BCAD@comcast.net>


On May 15, 2015, at 10:05 AM, Kai Mx wrote:

> thanks, that would work, but isn't there a maybe more elegant way to
> "extract" the name from the df variable within the current for (df in
> list()) loop?
> 

You do realize that the `for` function returns NULL, I hope? I was surprised when I learned this, although it is clearly stated in the help page.

Neither `lapply` nor `for` passes the names into the environment for evaluation:

for( d in dflist ) { z <- deparse(substitute(d)); print(z)}
[1] "d"
[1] "d"
[1] "d"

People would generally use this approach:

for (n in names(dflist) { ...do something with nm or dflist[[nm]]... }

-- 
David.



> Best,
> 
> Kai
> 
> 
> On Fri, May 15, 2015 at 2:20 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
>> Hi Kai,
>> One way is to name the components of your list with the names of the
>> data frames:
>> 
>> df1<-data.frame(a=1:3)
>> df2<-data.frame(a=4:6)
>> df3<-data.frame(a=7:9)
>> dflist<-list(df1,df2,df3)
>> names(dflist)<-c("df1","df2","df3")
>> for(i in 1:length(dflist)) cat(names(dflist)[i],"\n")
>> df1
>> df2
>> df3
>> 
>> Jim
>> 
>> 
>> On Fri, May 15, 2015 at 10:05 PM, Kai Mx <govokai at gmail.com> wrote:
>>> Hi everybody,
>>> 
>>> I just can't  figure this out:
>>> 
>>> I have a loop trough several dataframes such as
>>> 
>>> for (df in list(df1, df2, df3, ...)) {
>>> ..some functions with df..
>>> }
>>> 
>>> now I want to print out the current dataframes name (ie the list items
>>> name) with the cat command before the actual functions to have better
>>> orientation in the output.
>>> However, I haven't been successful with different variations of
>> deparse(),
>>> substitute(), (cat(substitute(df)) gives me 'df' for the whole loop).
>>> 
>>> Could somebody please enlighten me?
>>> 
>>> Thanks so much!
>>> 
>>> Best,
>>> 
>>> Kai

-- 

David Winsemius
Alameda, CA, USA


From crawford.winnie at ensco.com  Fri May 15 20:38:41 2015
From: crawford.winnie at ensco.com (Crawford.Winnie)
Date: Fri, 15 May 2015 14:38:41 -0400
Subject: [R] R free courses-Recommendations
In-Reply-To: <CAMUnHGmR=kra-TMk2j01iohgeu5Quuj28yUQcbZ_NQvkFryGWA@mail.gmail.com>
References: <CAMUnHGmR=kra-TMk2j01iohgeu5Quuj28yUQcbZ_NQvkFryGWA@mail.gmail.com>
Message-ID: <A28DB6AE7BD4A24486F559EA5E1D731B6AA59D3354@mb-ex07.ensco.win>

www.coursera.org, excellent MOOC.

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dot Lundberg
Sent: Friday, May 15, 2015 1:17 PM
To: r-help at r-project.org
Subject: [R] R free courses-Recommendations

Hi all,

I am looking for suggestions on R free courses. Any suggestions?

Thanks!

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

The information contained in this email message is intended only for the use of the individual(s) to whom it is addressed and may contain information that is privileged and sensitive. If you are not the intended recipient, or otherwise have received this communication in error, please notify the sender immediately by email at the above referenced address and note that any further dissemination, distribution or copying of this communication is strictly prohibited.

The U.S. Export Control Laws regulate the export and re-export of technology originating in the United States. This includes the electronic transmission of information and software to foreign countries and to certain foreign nationals. Recipient agrees to abide by these laws and their regulations -- including the U.S. Department of Commerce Export Administration Regulations and the U.S. Department of State International Traffic in Arms Regulations -- and not to transfer, by electronic transmission or otherwise, any content derived from this email to either a foreign national or a foreign destination in violation of such laws.


From HLiao at odu.edu  Fri May 15 22:36:23 2015
From: HLiao at odu.edu (Liao, Hongsheng)
Date: Fri, 15 May 2015 20:36:23 +0000
Subject: [R] How to make sub-headers in R
In-Reply-To: <DDF46500-4704-47F9-A621-790F2D2BDB53@utoronto.ca>
References: <44F908E52BA1744BB88DEB8E10103AAD82F58CA8@KIRK.ts.odu.edu>
	<C189D215-DA73-46DB-9E1A-DD2D4E2E1EDA@dcn.davis.CA.us>
	<44F908E52BA1744BB88DEB8E10103AAD82F58D38@KIRK.ts.odu.edu>
	<B4FE1B3A-CEC6-479B-9EAE-D030216AD3ED@utoronto.ca>
	<44F908E52BA1744BB88DEB8E10103AAD82F58DFA@KIRK.ts.odu.edu>
	<DDF46500-4704-47F9-A621-790F2D2BDB53@utoronto.ca>
Message-ID: <44F908E52BA1744BB88DEB8E10103AAD82F58E80@KIRK.ts.odu.edu>

Hi Boris,
First of all, thank you for persisting to help me on the issue.  Second, I didn't know paste() could take a function, and thanks for teaching me about it even I didn't use it this time. Finally, I have found the solution based on your code.    Following are what I have done:

1. Using your age vector  ages <- c(1, 1, 2, 3, 5, 8) as data, I typed them in following code to generate the output I want

age.addtorow          <- list()
age.addtorow$pos      <- list()
age.addtorow$pos[[1]] <- c(0)
age.addtorow$command  <- c(paste("\\hline \n",
				     "\\endfirsthead \n",
 				     "\\multicolumn{4}{l}{{", paste("Table", "\\thetable\\ Continued}}", paste("\\", "\\", sep="")), paste("\n"),
       			     "\\hline \n",
 				     "\\multicolumn{7}{r}{{Age}}", paste("\\", "\\", sep=""), paste("\n"),
 				     "\\hline \n",
 				     "Interval & 1 & 1 & 2 & 3 & 5 & 8", paste("\\", "\\", sep=""), paste("\n"),
 				     "\\hline \n",
 				     "\\endhead \n",
                             "\\hline \n",
                             "{\\footnotesize To continue} \n",
                             "\\endfoot \n",
					"\\endlastfoot \n",sep=""))


2. Then, I wrote a loop as follows:  
ages <- c(1, 1, 2, 3, 5, 8)
subtitle <- "Interval"
for(i in 1:length(ages)){
subtitle <- paste(subtitle, "&", ages[i])
}

3. Put the object "subtitle" in the following code:

age.addtorow          <- list()
age.addtorow$pos      <- list()
age.addtorow$pos[[1]] <- c(0)
age.addtorow$command  <- c(paste("\\hline \n",
				     "\\endfirsthead \n",
 				     "\\multicolumn{4}{l}{{", paste("Table", "\\thetable\\ Continued}}", paste("\\", "\\", sep="")), paste("\n"),
       			     "\\hline \n",
 				     "\\multicolumn{7}{r}{{Age}}", paste("\\", "\\", sep=""), paste("\n"),
 				     "\\hline \n",
 				     subtitle, paste("\\", "\\", sep=""), paste("\n"),
 				     "\\hline \n",
 				     "\\endhead \n",
                             "\\hline \n",
                             "{\\footnotesize To continue} \n",
                             "\\endfoot \n",
					"\\endlastfoot \n",sep=""))

4. Both codes generate the exact same result as follows:
> age.addtorow
$pos
$pos[[1]]
[1] 0


$command
[1] "\\hline \n\\endfirsthead \n\\multicolumn{4}{l}{{Table \\thetable\\ Continued}} \\\\\n\\hline \n\\multicolumn{7}{r}{{Age}}\\\\\n\\hline \nInterval & 1 & 1 & 2 & 3 & 5 & 8\\\\\n\\hline \n\\endhead \n\\hline \n{\\footnotesize To continue} \n\\endfoot \n\\endlastfoot \n"

5. Since the vector "ages" can be updated from the database of different species and years, my problem is solved.

Thank you very much again.  Now I can go home happily and have a good weekend.  You have a wonderful weekend, too.

Hank

Hongsheng (Hank) Liao, PhD.
Lab Manager
Center for Quantitative  Fisheries Ecology
Old Dominion University
757-683-4571






-----Original Message-----
From: Boris Steipe [mailto:boris.steipe at utoronto.ca] 
Sent: Friday, May 15, 2015 2:35 PM
To: Liao, Hongsheng
Cc: r-help at r-project.org
Subject: Re: [R] How to make sub-headers in R

Hongsheng -
If you can define the fish ages programmatically, you can also get the values into your output. I had understood your "sub-header" to be constant per column. Does it need to be updated for different rows? Or are you just missing the fact that paste() can take variables, and even functions like so:

R > myAge <- function(x) { x*x }
R > ages <- c(1, 1, 2, 3, 5, 8)
R > paste("Interval ",
       " & 1",            # in string
       " & ", 2,          # constant
       " & ", ages[4],    # from vector
       " & ", ages[5], 
       " & ", myAge(5),   # from function
       "\n", sep="")
[1] "Interval  & 1 & 2 & 3 & 5 & 25\n"


Cheers,
Boris




On May 15, 2015, at 2:15 PM, Liao, Hongsheng <HLiao at odu.edu> wrote:

> Thank you very much for trying to help me.  Using following R codes, I can generate a LaTeX long table which can repeat "Age" and "Interval & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & Totals" as title and subtitle across multiple pages.  However, the part of "0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11" is for fish ages (I am working on fish) which vary between species and years within each species, and R can't update this part according to different species and years.  As a result, I have to manually update it in either my R or LaTeX codes, which I am trying to avoid in order to save time and to minimize errors.  It looks like there is no solution to my problem so far.  Anyway, thank you again and have a good weekend.
> 
> age.addtorow          <- list()
> age.addtorow$pos      <- list()
> age.addtorow$pos[[1]] <- c(0)
> age.addtorow$command  <- c(paste("\\hline \n",
> 				     "\\endfirsthead \n",
> 				     "\\multicolumn{4}{l}{{", paste("Table", "\\thetable\\ Continued}}", paste("\\", "\\", sep="")), paste("\n"),
>       			     "\\hline \n",
> 				     "\\multicolumn{7}{r}{{Age}}", paste("\\", "\\", sep=""), paste("\n"),
> 				     "\\hline \n",
> 				     "Interval & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & Totals", paste("\\", "\\", sep=""), paste("\n"),
> 				     "\\hline \n",
> 				     "\\endhead \n",
>                             "\\hline \n",
>                             "{\\footnotesize To continue} \n",
>                             "\\endfoot \n",
>                             "\\endlastfoot \n",sep=""))
> 
> print(x.age.composition, file=output.age.composition.location.file, include.rownames = FALSE, 
>      				include.colnames = TRUE, hline.after = c(-1, -1, 0, 1, nrow(x.age.composition), nrow(x.age.composition)), type="latex",
> 					append=FALSE, floating=FALSE, tabular.environment = "longtable", na.print = "", caption.placement = "top", 
> 					sanitize.colnames.function = force, add.to.row = age.addtorow))
> 
> 
> -----Original Message-----
> From: Boris Steipe [mailto:boris.steipe at utoronto.ca]
> Sent: Friday, May 15, 2015 11:42 AM
> To: Liao, Hongsheng
> Cc: r-help at r-project.org
> Subject: Re: [R] How to make sub-headers in R
> 
> I don't see that being an option in xtable ... but looking at this:
>   
> http://tex.stackexchange.com/questions/33510/how-do-i-create-the-headi
> ngs-for-this-multirow-multicolum-table
> ... it seems to be pretty straightforward to write a function that writes LaTeX output from your dataframe for the Tex multirow package.
> 
> 
> B.
> 
> On May 15, 2015, at 11:18 AM, Liao, Hongsheng <HLiao at odu.edu> wrote:
> 
>> Thanks for your response.  I want to make a LaTeX table with a title and subtitles.  Attached is an example made using Word. I can use "xtable()" and "print()" to generate a LaTeX table of it with "Age" as title.   However, I would like to make the second row "Interval (Inch) ........." as sub-title so that both the title and sub-title can be repeated on every page in my long table split among multiple pages.  In LaTeX, "\endhead" can repeat title but not the row of "Interval ..." because it is not title or sub-title.  I can copy and paste "Interval..." above "\endhead" to get the repetition of "Interval...".  However, I am trying to learn how to avoid "copy and paste", instead, let LaTeX do the job automatically. I know that I am making the question more complicated than my original one and hope it is clear enough this time.
>> 
>> Hongsheng (Hank) Liao, PhD.
>> Lab Manager
>> Center for Quantitative  Fisheries Ecology Old Dominion University
>> 757-683-4571
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us]
>> Sent: Friday, May 15, 2015 10:43 AM
>> To: Liao, Hongsheng; r-help at r-project.org
>> Subject: Re: [R] How to make sub-headers in R
>> 
>> I think you are not interpreting what is happening correctly. Column names are labels used for purposes of referring to the data in your R code. That they might also be useful in presenting data in output is coincidental. The fact that many data input functions replace spaces in those labels with periods should convince you of this fact.
>> 
>> On the other hand, the options available when you output that table usually depend on where you want to display the result, which you have not mentioned. For example the tables package has many options for labeling columns if you are generating HTML or LaTeX output. Or, you could write your own function to generate any output format you want.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                     Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------
>> -
>> ----- Sent from my phone. Please excuse my brevity.
>> 
>> On May 15, 2015 6:55:17 AM PDT, "Liao, Hongsheng" <HLiao at odu.edu> wrote:
>>> I know how to make one-row header for a data frame using "colnames". 
>>> Is there any function to insert sub-header between the first row of 
>>> the data and the header?  Thanks
>>> 
>>> Hongsheng (Hank) Liao, PhD.
>>> Lab Manager
>>> Center for Quantitative  Fisheries Ecology Old Dominion University
>>> 757-683-4571
>>> 
>>> 
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> --
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --



--
BEGIN-ANTISPAM-VOTING-LINKS
------------------------------------------------------
Teach CanIt if this mail (ID 03OsiBGtq) is spam:Spam:        https://www.spamtrap.odu.edu/canit/b.php?i=03OsiBGtq&m=c21d21b85f81&t=20150515&c=sNot spam:    https://www.spamtrap.odu.edu/canit/b.php?i=03OsiBGtq&m=c21d21b85f81&t=20150515&c=nForget vote: https://www.spamtrap.odu.edu/canit/b.php?i=03OsiBGtq&m=c21d21b85f81&t=20150515&c=f
------------------------------------------------------
END-ANTISPAM-VOTING-LINKS


From wdunlap at tibco.com  Fri May 15 22:51:26 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 15 May 2015 13:51:26 -0700
Subject: [R] print dataframe names in loop
In-Reply-To: <CA+8X3fXUwjVTAJ3fUOHB_5VA1gsv2XZJBrugHbwa6bViiP5C2A@mail.gmail.com>
References: <CAHOWgNXcQXq32+gkUcZ14UDMsungZoFSLj2Hv0QP+L_mFyA4Jg@mail.gmail.com>
	<CA+8X3fXUwjVTAJ3fUOHB_5VA1gsv2XZJBrugHbwa6bViiP5C2A@mail.gmail.com>
Message-ID: <CAF8bMcZZAY_8ugentR+fAMrtd6d=wWO13oS6z9Yj43Yfi7=8eg@mail.gmail.com>

You can automate the adding of the names to the list with the following
function, so you
can replace the
  dflist<-list(df1,df2,df3)
  names(dflist)<-c("df1","df2","df3")
with
  dflist <- namedList(df1, df2, df3)
If you supply names, such in
  dflist <- namedList(df1, Second=df2, log(df3))
it will use your names and create names for the unnamed ones.

(Once you make a named list of data.frames, you can remove the the
originals from your global environment so you will have a single version
of truth.)

namedList <- function (...)
{
    L <- list(...)
    nms <- names(L)
    if (is.null(nms)) {
        nms <- rep("", length(L))
    }
    if (any(needsName <- is.na(nms) | !nzchar(nms))) {
        nms[needsName] <- vapply(substitute(...())[needsName],
            function(x) deparse(x, nlines = 1L), FUN.VALUE = "")
        names(L) <- nms
    }
    L
}


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, May 15, 2015 at 5:20 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Kai,
> One way is to name the components of your list with the names of the
> data frames:
>
> df1<-data.frame(a=1:3)
> df2<-data.frame(a=4:6)
> df3<-data.frame(a=7:9)
> dflist<-list(df1,df2,df3)
> names(dflist)<-c("df1","df2","df3")
> for(i in 1:length(dflist)) cat(names(dflist)[i],"\n")
> df1
> df2
> df3
>
> Jim
>
>
> On Fri, May 15, 2015 at 10:05 PM, Kai Mx <govokai at gmail.com> wrote:
> > Hi everybody,
> >
> > I just can't  figure this out:
> >
> > I have a loop trough several dataframes such as
> >
> > for (df in list(df1, df2, df3, ...)) {
> > ..some functions with df..
> > }
> >
> > now I want to print out the current dataframes name (ie the list items
> > name) with the cat command before the actual functions to have better
> > orientation in the output.
> > However, I haven't been successful with different variations of
> deparse(),
> > substitute(), (cat(substitute(df)) gives me 'df' for the whole loop).
> >
> > Could somebody please enlighten me?
> >
> > Thanks so much!
> >
> > Best,
> >
> > Kai
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From samarvir1996 at gmail.com  Sat May 16 04:20:01 2015
From: samarvir1996 at gmail.com (samarvir singh)
Date: Sat, 16 May 2015 02:20:01 +0000
Subject: [R] Need help with lm function on MAC OS X. R version - 3.2.0
In-Reply-To: <D17B7EBD.129BD7%macqueen1@llnl.gov>
References: <CAOpgo6iks1Xh3BVZKNc8Npb_fVvforg0MA1TV6HqZRt14BsGng@mail.gmail.com>
	<D17B7EBD.129BD7%macqueen1@llnl.gov>
Message-ID: <CAOpgo6iE5ks4eAdsimpY=boN6KR+Q4YvFMfmwfa1KY56rmzJ6g@mail.gmail.com>

Thanks a lot Don, I did the above mentioned. And yes one of my variable
field had some non numeric data. Because of large set of variables , when I
used str(BSE) , some result was omitted, so that's why it went un noticed.
Thank you

On Fri 15 May, 2015 11:21 pm MacQueen, Don <macqueen1 at llnl.gov> wrote:

> For sure this is not a Mac OS X related problem.
>
> If the data frame is named BSE then your lm() calls need to say data =
> BSE, not data = bse.
>
> How many factpr levels does company have?
>
> Besides all that, I would suggest you start with simpler uses of lm, and
> find out if they work. For example, try
>
>   lm( CP ~ company, data=BSE)
>
> If that works, then start adding variables on the right hand side until
> you get one that causes errors.
>
> The message about a 'closure' suggests that you are somehow asking lm() to
> perform analyses on an R function instead of data in a data frame. That
> would be very strange, and I have trouble imagining how that could be.
>
> Are you sure all your data is numeric? Try
>   lapply( BSE, class)
>   str(BSE)
>
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 5/14/15, 5:07 AM, "samarvir singh" <samarvir1996 at gmail.com> wrote:
>
> >I Have a data frame named BSE and CP is my independent variable
> >and here;s the error I get if I try to run an lm function
> >any idea whats wrong
> >
> >P.S - all my data is in numeric except company which is a factor. I have
> >2700 row and 450 variable
> >
> >P.P.S -  I have no missing data, I have 0 in Empty field.
> >
> >> BSE_Reg <- lm(CP ~.-company, data = bse)
> >Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
> >  contrasts can be applied only to factors with 2 or more levels
> >
> >> BSE_Reg <- lm(CP ~., data = bse)
> >Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
> >  contrasts can be applied only to factors with 2 or more levels
> >Error in as.character(tools:::httpdPort) :
> >  cannot coerce type 'closure' to vector of type 'character'
> >Error in as.character(tools:::httpdPort) :
> >  cannot coerce type 'closure' to vector of type 'character'
> >Error in as.character(tools:::httpdPort) :
> >  cannot coerce type 'closure' to vector of type 'character'
> >Error in as.character(tools:::httpdPort) :
> >  cannot coerce type 'closure' to vector of type 'character'
> >
> >
> >
> >
> >
> >> R.Version()
> >$platform
> >[1] "x86_64-apple-darwin13.4.0"
> >
> >$arch
> >[1] "x86_64"
> >
> >$os
> >[1] "darwin13.4.0"
> >
> >$system
> >[1] "x86_64, darwin13.4.0"
> >
> >$status
> >[1] ""
> >
> >$major
> >[1] "3"
> >
> >$minor
> >[1] "2.0"
> >
> >$year
> >[1] "2015"
> >
> >$month
> >[1] "04"
> >
> >$day
> >[1] "16"
> >
> >$`svn rev`
> >[1] "68180"
> >
> >$language
> >[1] "R"
> >
> >$version.string
> >[1] "R version 3.2.0 (2015-04-16)"
> >
> >$nickname
> >[1] "Full of Ingredients"
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From luca.cerone at gmail.com  Sat May 16 08:34:44 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Sat, 16 May 2015 08:34:44 +0200
Subject: [R] Template Engine for R
Message-ID: <CAFnz2-8Rr-6DyAdgA2_KmZG7WoQ5G6cQiMztV-uC_CGbuy2R-g@mail.gmail.com>

Dear all,
I am looking for a template engine for R.

I have already come across {{mustache}} and its R implementation whisker,
however I am looking for something with a few more features like "if blocks",
"for loop", "block inheritance" and so on (for those of you who
are familiar with Python I am looking for something like Jinja2 or Mako).

I searched in google, but the only option for R seems whisker.

Can any of you recommend me some alternatives?

Thanks a lot in advance for the help!

Cheers,
Luca


From jdnewmil at dcn.davis.CA.us  Sat May 16 09:11:16 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 16 May 2015 00:11:16 -0700
Subject: [R] Template Engine for R
In-Reply-To: <CAFnz2-8Rr-6DyAdgA2_KmZG7WoQ5G6cQiMztV-uC_CGbuy2R-g@mail.gmail.com>
References: <CAFnz2-8Rr-6DyAdgA2_KmZG7WoQ5G6cQiMztV-uC_CGbuy2R-g@mail.gmail.com>
Message-ID: <7B740FBC-D38E-40D0-8871-E59583051A67@dcn.davis.CA.us>

Not familiar with your examples, but knitr relies on R for control flow and whisker for template substitution, so it kind of seems unnecessary to have yet another syntax for control flow.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 15, 2015 11:34:44 PM PDT, Luca Cerone <luca.cerone at gmail.com> wrote:
>Dear all,
>I am looking for a template engine for R.
>
>I have already come across {{mustache}} and its R implementation
>whisker,
>however I am looking for something with a few more features like "if
>blocks",
>"for loop", "block inheritance" and so on (for those of you who
>are familiar with Python I am looking for something like Jinja2 or
>Mako).
>
>I searched in google, but the only option for R seems whisker.
>
>Can any of you recommend me some alternatives?
>
>Thanks a lot in advance for the help!
>
>Cheers,
>Luca
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From luca.cerone at gmail.com  Sat May 16 09:33:17 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Sat, 16 May 2015 09:33:17 +0200
Subject: [R] Template Engine for R
In-Reply-To: <7B740FBC-D38E-40D0-8871-E59583051A67@dcn.davis.CA.us>
References: <CAFnz2-8Rr-6DyAdgA2_KmZG7WoQ5G6cQiMztV-uC_CGbuy2R-g@mail.gmail.com>
	<7B740FBC-D38E-40D0-8871-E59583051A67@dcn.davis.CA.us>
Message-ID: <CAFnz2-_YCRNfo5vV++AzgFJWAK8=dfiX94Hc9nS753ZhH50+vQ@mail.gmail.com>

Hi Jeff,
thanks for your reply.

Can you elaborate a bit more what you mean? I know very lillte knitr,
mostly because I use it in Rstudio to render Rmarkdown documents.
However I do not need a template engine for reporting, and I can't see
how I should use it.

Can you provide me with  just a minimal example?

Cheers,
Luca

On Sat, May 16, 2015 at 9:11 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Not familiar with your examples, but knitr relies on R for control flow and whisker for template substitution, so it kind of seems unnecessary to have yet another syntax for control flow.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On May 15, 2015 11:34:44 PM PDT, Luca Cerone <luca.cerone at gmail.com> wrote:
>>Dear all,
>>I am looking for a template engine for R.
>>
>>I have already come across {{mustache}} and its R implementation
>>whisker,
>>however I am looking for something with a few more features like "if
>>blocks",
>>"for loop", "block inheritance" and so on (for those of you who
>>are familiar with Python I am looking for something like Jinja2 or
>>Mako).
>>
>>I searched in google, but the only option for R seems whisker.
>>
>>Can any of you recommend me some alternatives?
>>
>>Thanks a lot in advance for the help!
>>
>>Cheers,
>>Luca
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From henrik.bengtsson at ucsf.edu  Sat May 16 09:41:00 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Sat, 16 May 2015 00:41:00 -0700
Subject: [R] Template Engine for R
In-Reply-To: <CAFnz2-8Rr-6DyAdgA2_KmZG7WoQ5G6cQiMztV-uC_CGbuy2R-g@mail.gmail.com>
References: <CAFnz2-8Rr-6DyAdgA2_KmZG7WoQ5G6cQiMztV-uC_CGbuy2R-g@mail.gmail.com>
Message-ID: <CAFDcVCTeK3vPbk14sMWC7azgU07Xgyk3gywP-n1tOgyJVfGGEg@mail.gmail.com>

See http://cran.r-project.org/package=R.rsp

Henrik
(author)

On Fri, May 15, 2015 at 11:34 PM, Luca Cerone <luca.cerone at gmail.com> wrote:
> Dear all,
> I am looking for a template engine for R.
>
> I have already come across {{mustache}} and its R implementation whisker,
> however I am looking for something with a few more features like "if blocks",
> "for loop", "block inheritance" and so on (for those of you who
> are familiar with Python I am looking for something like Jinja2 or Mako).
>
> I searched in google, but the only option for R seems whisker.
>
> Can any of you recommend me some alternatives?
>
> Thanks a lot in advance for the help!
>
> Cheers,
> Luca
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From govokai at gmail.com  Sat May 16 11:33:24 2015
From: govokai at gmail.com (Kai Mx)
Date: Sat, 16 May 2015 11:33:24 +0200
Subject: [R] print dataframe names in loop
In-Reply-To: <CAF8bMcZZAY_8ugentR+fAMrtd6d=wWO13oS6z9Yj43Yfi7=8eg@mail.gmail.com>
References: <CAHOWgNXcQXq32+gkUcZ14UDMsungZoFSLj2Hv0QP+L_mFyA4Jg@mail.gmail.com>
	<CA+8X3fXUwjVTAJ3fUOHB_5VA1gsv2XZJBrugHbwa6bViiP5C2A@mail.gmail.com>
	<CAF8bMcZZAY_8ugentR+fAMrtd6d=wWO13oS6z9Yj43Yfi7=8eg@mail.gmail.com>
Message-ID: <CAHOWgNU94u67qdV+rUMaqtW27xbsY4TdbfQdZfi8cvXmvQGO+w@mail.gmail.com>

Thanks for all the input.
It seems like there is no way around introducing names for the list items,
but the namedList-function is really neat.
Function returns are not at issue for me, I rather want to use it on plots
or outputs in the console.

Best,

Kai


On Fri, May 15, 2015 at 10:51 PM, William Dunlap <wdunlap at tibco.com> wrote:

> You can automate the adding of the names to the list with the following
> function, so you
> can replace the
>   dflist<-list(df1,df2,df3)
>   names(dflist)<-c("df1","df2","df3")
> with
>   dflist <- namedList(df1, df2, df3)
> If you supply names, such in
>   dflist <- namedList(df1, Second=df2, log(df3))
> it will use your names and create names for the unnamed ones.
>
> (Once you make a named list of data.frames, you can remove the the
> originals from your global environment so you will have a single version
> of truth.)
>
> namedList <- function (...)
> {
>     L <- list(...)
>     nms <- names(L)
>     if (is.null(nms)) {
>         nms <- rep("", length(L))
>     }
>     if (any(needsName <- is.na(nms) | !nzchar(nms))) {
>         nms[needsName] <- vapply(substitute(...())[needsName],
>             function(x) deparse(x, nlines = 1L), FUN.VALUE = "")
>         names(L) <- nms
>     }
>     L
> }
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, May 15, 2015 at 5:20 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Kai,
>> One way is to name the components of your list with the names of the
>> data frames:
>>
>> df1<-data.frame(a=1:3)
>> df2<-data.frame(a=4:6)
>> df3<-data.frame(a=7:9)
>> dflist<-list(df1,df2,df3)
>> names(dflist)<-c("df1","df2","df3")
>> for(i in 1:length(dflist)) cat(names(dflist)[i],"\n")
>> df1
>> df2
>> df3
>>
>> Jim
>>
>>
>> On Fri, May 15, 2015 at 10:05 PM, Kai Mx <govokai at gmail.com> wrote:
>> > Hi everybody,
>> >
>> > I just can't  figure this out:
>> >
>> > I have a loop trough several dataframes such as
>> >
>> > for (df in list(df1, df2, df3, ...)) {
>> > ..some functions with df..
>> > }
>> >
>> > now I want to print out the current dataframes name (ie the list items
>> > name) with the cat command before the actual functions to have better
>> > orientation in the output.
>> > However, I haven't been successful with different variations of
>> deparse(),
>> > substitute(), (cat(substitute(df)) gives me 'df' for the whole loop).
>> >
>> > Could somebody please enlighten me?
>> >
>> > Thanks so much!
>> >
>> > Best,
>> >
>> > Kai
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From luca.cerone at gmail.com  Sat May 16 12:57:22 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Sat, 16 May 2015 12:57:22 +0200
Subject: [R] Template Engine for R
In-Reply-To: <CAFDcVCTeK3vPbk14sMWC7azgU07Xgyk3gywP-n1tOgyJVfGGEg@mail.gmail.com>
References: <CAFnz2-8Rr-6DyAdgA2_KmZG7WoQ5G6cQiMztV-uC_CGbuy2R-g@mail.gmail.com>
	<CAFDcVCTeK3vPbk14sMWC7azgU07Xgyk3gywP-n1tOgyJVfGGEg@mail.gmail.com>
Message-ID: <CAFnz2--tFC_6ps_4QQot9ytGvro6G0zpeJa-1P=yLp-jDjEYNQ@mail.gmail.com>

Thanks Henrik!

That's seem more like what I am looking for, though I do not have to
use a template engine for reporting purposes.
I do not need to create html, nor markdown but I'll see if I can use
it for what I need :)

Cheers,
luca

On Sat, May 16, 2015 at 9:41 AM, Henrik Bengtsson
<henrik.bengtsson at ucsf.edu> wrote:
> See http://cran.r-project.org/package=R.rsp
>
> Henrik
> (author)
>
> On Fri, May 15, 2015 at 11:34 PM, Luca Cerone <luca.cerone at gmail.com> wrote:
>> Dear all,
>> I am looking for a template engine for R.
>>
>> I have already come across {{mustache}} and its R implementation whisker,
>> however I am looking for something with a few more features like "if blocks",
>> "for loop", "block inheritance" and so on (for those of you who
>> are familiar with Python I am looking for something like Jinja2 or Mako).
>>
>> I searched in google, but the only option for R seems whisker.
>>
>> Can any of you recommend me some alternatives?
>>
>> Thanks a lot in advance for the help!
>>
>> Cheers,
>> Luca
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From nicholas.wray at ntlworld.com  Fri May 15 22:40:33 2015
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Fri, 15 May 2015 21:40:33 +0100
Subject: [R] Variable number of loops
Message-ID: <CALcakBaPjYfqzjqE8a5VhRF5NG4tvbsyOcn-6TiTH-dUvNZT1A@mail.gmail.com>

I am trying to build a programme which will work out the permutations of a
number of variables, eg a=0 to 1, b=0 to 1, and c=0 to 2, so permutations
would be (0,0,0), (1,0,0), (0,1,0)... etc In this case there would be 2 x
2x 3 = 12 permutations.  If the number of variables are fixed it's easy to
loop round with nesting

However I don't have a fixed number of variables, so I have a variable
number of loops.  I am trying to use a recursive function to do this and
have been building it up step-wise

I want to return a list of all the permutations at the end, but the
programme I have so ar doesn't return a full list, but just the first
element

2 things -- 1 I don't see why this is happening, and 2 is this the right
way to approach this problem?  I cannot find find anything about this in R
on the net

recursfunc1<-function(xf,shiftvecf,vlistf){
  if(xf<4){
    xf<-xf+1
    vlistf[[length(vlistf)+1]]<-shiftvec[xf]
    #print(paste(xf,"and",shiftvec[xf]))
    print(vlistf)
    #print(shiftvec[xf])
    xf<-recursfunc1(xf,shiftvecf,vlistf)}
  return(vlistf)}

shiftvec<-c(2,1,1,0)
vlist<-list()
perm<-recursfunc1(xf=0,shiftvecf=shiftvec,vlistf=vlist)
perm

I want perm to return the elements of shiftvec as a list so that I can then
do all the permutations as the next stage, but it only returns the first
element of shiftvec

Thanks, Nick Wray

	[[alternative HTML version deleted]]


From glennmschultz at me.com  Sat May 16 03:04:27 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Sat, 16 May 2015 01:04:27 +0000 (GMT)
Subject: [R] Illustrating use of R package
Message-ID: <dca7fd64-2e0f-445d-bfee-8b31c87169ba@me.com>

I have an R package Bond Lab which actually supports a book Investing in MBS using R and Open Source Computing. ?The Bond Lab beta is stable. ?I have also created a package companion to investing in MBS. ?Both are on my Github site

https://github.com/glennmschultz/

I wrote the companion as functions for each chapter calling source code. ?I really don't like the way it works presentation wise but the user could see the code used. ?Further, the user must create a directory and copy the source into the directory. ?Further the source runs all examples at once which seems a little confusion. ?However, to illustrate a function for chapter example I think I have to make a function to call a function which does not make sense.

My first question, any suggestions on illustrating function call aside from the strategy I am using. ?I am not a fan of what I am doing.

My second question regards on.load() vs. on.attach() Bond Lab needs to create the BondLab directory which installs in the BondLab library to the ~/users directory, the same for the companion. ?

I think I should use on.load(), correct?
I am not sure how to do this and will the same function work for both Windows and MAC? ?
Do I need different copy from path for Windows and MAC or can it be generic since the copy happens at load.
I?would like to get Bond Lab on?CRAN. ?I read CRAN rules require a yes/no from the user to write a directory. ?So, I need to write an on.load() function for both Bond Lab and the Companion. ?Also, CRAN requires that a package works on at least two systems so I need to figure out the Windows build. ?This leads to another question.

Can I somehow make a windows binary on a MAC?
If not, can I emulate Windows on a MAC and make a binary? ?Seems like this may not be 100%.
Will I actually?have?to buy a windows machine to build the windows binary for CRAN?

Glenn ?

From gunter.berton at gene.com  Sat May 16 15:28:53 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 16 May 2015 06:28:53 -0700
Subject: [R] Variable number of loops
In-Reply-To: <CALcakBaPjYfqzjqE8a5VhRF5NG4tvbsyOcn-6TiTH-dUvNZT1A@mail.gmail.com>
References: <CALcakBaPjYfqzjqE8a5VhRF5NG4tvbsyOcn-6TiTH-dUvNZT1A@mail.gmail.com>
Message-ID: <CACk-te1FO5rhrVrbkU8JF2ONOfBOAEGsB9JMAvShjG0cfBEGVQ@mail.gmail.com>

Are you trying to reinvent ?expand.grid   ?

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, May 15, 2015 at 1:40 PM, WRAY NICHOLAS
<nicholas.wray at ntlworld.com> wrote:
> I am trying to build a programme which will work out the permutations of a
> number of variables, eg a=0 to 1, b=0 to 1, and c=0 to 2, so permutations
> would be (0,0,0), (1,0,0), (0,1,0)... etc In this case there would be 2 x
> 2x 3 = 12 permutations.  If the number of variables are fixed it's easy to
> loop round with nesting
>
> However I don't have a fixed number of variables, so I have a variable
> number of loops.  I am trying to use a recursive function to do this and
> have been building it up step-wise
>
> I want to return a list of all the permutations at the end, but the
> programme I have so ar doesn't return a full list, but just the first
> element
>
> 2 things -- 1 I don't see why this is happening, and 2 is this the right
> way to approach this problem?  I cannot find find anything about this in R
> on the net
>
> recursfunc1<-function(xf,shiftvecf,vlistf){
>   if(xf<4){
>     xf<-xf+1
>     vlistf[[length(vlistf)+1]]<-shiftvec[xf]
>     #print(paste(xf,"and",shiftvec[xf]))
>     print(vlistf)
>     #print(shiftvec[xf])
>     xf<-recursfunc1(xf,shiftvecf,vlistf)}
>   return(vlistf)}
>
> shiftvec<-c(2,1,1,0)
> vlist<-list()
> perm<-recursfunc1(xf=0,shiftvecf=shiftvec,vlistf=vlist)
> perm
>
> I want perm to return the elements of shiftvec as a list so that I can then
> do all the permutations as the next stage, but it only returns the first
> element of shiftvec
>
> Thanks, Nick Wray
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From henrik.bengtsson at ucsf.edu  Sat May 16 17:17:47 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Sat, 16 May 2015 08:17:47 -0700
Subject: [R] Template Engine for R
In-Reply-To: <CAFnz2--tFC_6ps_4QQot9ytGvro6G0zpeJa-1P=yLp-jDjEYNQ@mail.gmail.com>
References: <CAFnz2-8Rr-6DyAdgA2_KmZG7WoQ5G6cQiMztV-uC_CGbuy2R-g@mail.gmail.com>
	<CAFDcVCTeK3vPbk14sMWC7azgU07Xgyk3gywP-n1tOgyJVfGGEg@mail.gmail.com>
	<CAFnz2--tFC_6ps_4QQot9ytGvro6G0zpeJa-1P=yLp-jDjEYNQ@mail.gmail.com>
Message-ID: <CAFDcVCQOyjy80ALG-itCFoOC-2G4Dxw=FUkhZR1BL3AJ8MqaRw@mail.gmail.com>

Hi Luca,

I must admit I've not used template engines like the ones you refer
to, but I can guess the idea and I believe RSP (the name of the markup
language defined in R.rsp) is powerful enough to achieve something similar.

RSP, has two main sets of constructors: (a) RSP pre-processing
directives and (b) RSP code expressions.

The pre-processing directives are independent of the R language, e.g.
<@%include file="<pathname>|<url>"%> and <@%ifeq a="42"%> ...
<@%else%> ... <@%endif%>.  They would look/work the same if, say,
Python implemented an RSP engine.

The code expressions contain R code, e.g. <% x <- runif(10) %> and <%=
x %>.  These are specific to R.  If implemented in Python, these would
contain Python code.  (There's a concept/framework for
mix-and-matching languages too).

There is no direct way of using the language-independent
pre-processing directives to setup templates.  However, you can do it
use the the RSP code expressions.  The following example is from the
http://cran.r-project.org/web/packages/R.rsp/vignettes/Dynamic_document_creation_using_RSP.pdf
vignette:

<% myTemplate <- function(n, ...) { %>
The sum of $x=<%=hpaste(1:n, abbreviate="\\ldots")%>$ is <%=sum(1:n)-%>.<%-%>
<% } # myTemplate() %>

\begin{itemize}
<% for (ii in c(3,5,10,100)) { %>
\item <% myTemplate(n=ii) %>
<% } # for (ii ...) %>
\end{itemize}

You can of course define the myTemplate() function in a separate file
and reuse it by <@%include file="templates.rsp"%>.  It can also
contain pre-processing directives.  It can in turn include other RSP
files.


Finally, I'm not sure what your target output format is, but RSP is
designed to work with _any text-based formats_, so you can use it to
generate code ('script.bash.rsp'), tab-delimited text files
('genes.tsv.rsp') and so on.  For example:

# A data frame save from R
# created_by: <%= author %>
# created_on: <%= Sys.date() %>
# nbr_of_rows: <%= nrow(data) %>
# column_names: <%= paste(sQuote(colnames(data)), collapse=", ") #>
# column_classes: <%= paste(sQuote(sapply(data, typeof)), collapse=", ") #>
<% write.table(data, sep="\t", quote=FALSE) %>

will output a tab-delimited table with header comments.  Running it through as

 data <- ...
 tsv <- rfile("genes.tsv.rsp")

will generate file 'genes.tsv'.  If you want the output to be sent to
stdout, you can do rcat(file="genes.tsv.rsp").

/Henrik

On Sat, May 16, 2015 at 3:57 AM, Luca Cerone <luca.cerone at gmail.com> wrote:
> Thanks Henrik!
>
> That's seem more like what I am looking for, though I do not have to
> use a template engine for reporting purposes.
> I do not need to create html, nor markdown but I'll see if I can use
> it for what I need :)
>
> Cheers,
> luca
>
> On Sat, May 16, 2015 at 9:41 AM, Henrik Bengtsson
> <henrik.bengtsson at ucsf.edu> wrote:
>> See http://cran.r-project.org/package=R.rsp
>>
>> Henrik
>> (author)
>>
>> On Fri, May 15, 2015 at 11:34 PM, Luca Cerone <luca.cerone at gmail.com> wrote:
>>> Dear all,
>>> I am looking for a template engine for R.
>>>
>>> I have already come across {{mustache}} and its R implementation whisker,
>>> however I am looking for something with a few more features like "if blocks",
>>> "for loop", "block inheritance" and so on (for those of you who
>>> are familiar with Python I am looking for something like Jinja2 or Mako).
>>>
>>> I searched in google, but the only option for R seems whisker.
>>>
>>> Can any of you recommend me some alternatives?
>>>
>>> Thanks a lot in advance for the help!
>>>
>>> Cheers,
>>> Luca
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From luca.cerone at gmail.com  Sat May 16 17:38:16 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Sat, 16 May 2015 17:38:16 +0200
Subject: [R] Template Engine for R
In-Reply-To: <CAFDcVCQOyjy80ALG-itCFoOC-2G4Dxw=FUkhZR1BL3AJ8MqaRw@mail.gmail.com>
References: <CAFnz2-8Rr-6DyAdgA2_KmZG7WoQ5G6cQiMztV-uC_CGbuy2R-g@mail.gmail.com>
	<CAFDcVCTeK3vPbk14sMWC7azgU07Xgyk3gywP-n1tOgyJVfGGEg@mail.gmail.com>
	<CAFnz2--tFC_6ps_4QQot9ytGvro6G0zpeJa-1P=yLp-jDjEYNQ@mail.gmail.com>
	<CAFDcVCQOyjy80ALG-itCFoOC-2G4Dxw=FUkhZR1BL3AJ8MqaRw@mail.gmail.com>
Message-ID: <CAFnz2-8qYOCfBvhB94w_6vqz4QkkaV92V5nZZoEeyikSC-mTFA@mail.gmail.com>

On Sat, May 16, 2015 at 5:17 PM, Henrik Bengtsson
<henrik.bengtsson at ucsf.edu> wrote:
> _any text-based formats_,

That's exactly what I am looking for then :)

I have to create a set of .txt templates. 90% of the time I just will
have to do simple "tags" substitutions,
but there are some times where I'll need some control flow.

Thanks again for linking me this!

Cheers,
Luca


From dileepkunjaai at gmail.com  Sat May 16 19:12:25 2015
From: dileepkunjaai at gmail.com (=?UTF-8?B?4LSV4LWB4LSe4LWN4LSe4LS+4LSv4LS/IGt1bmphYWk=?=)
Date: Sat, 16 May 2015 22:42:25 +0530
Subject: [R] Convert to a vector to read.table output format
Message-ID: <CALTF6skSDUvp8U2yFVbbVwG9M3Y8LReiEf0jKbVkVYU8G7dh+Q@mail.gmail.com>

Dear all,

 I want to convert a variable (that variable obtained from an 'nc ' file) I
want to convert  it into a* read.table* output format

Example:

> index_data<-get.var.ncdf(f_hist ,"meant_iitm_ALLIN_YEAR")
> index_data
 [1] 24.06333 24.07208 24.20208 24.12625 24.27333 24.42458 24.26583
 [8] 24.30042 24.49750


I want to convert it in to


>   V1           V2         V3          V4              V5
V6          V7          V8
24.06333  24.07208  24.20208 24.12625  24.27333 24.42458 24.26583 24.30042
    V9
24.49750


Thank you all in advance......
--
DILEEPKUMAR. R
J R F, IIT DELHI

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sat May 16 20:33:57 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 16 May 2015 19:33:57 +0100
Subject: [R] Convert to a vector to read.table output format
In-Reply-To: <CALTF6skSDUvp8U2yFVbbVwG9M3Y8LReiEf0jKbVkVYU8G7dh+Q@mail.gmail.com>
References: <CALTF6skSDUvp8U2yFVbbVwG9M3Y8LReiEf0jKbVkVYU8G7dh+Q@mail.gmail.com>
Message-ID: <55578D95.4010209@sapo.pt>

Hello,

I'm not exactly sure of what you want.
1) If you just want that output, just set the names attribute  of 
index_data.

names(index_data) <- paste0("V", 1:length(index_data))

2) If you want to create a data.frame from index_data try the following.

dat <- data.frame(index_data[1])
for(i in 2:length(index_data))
	dat <-cbind(dat, index_data[i])
names(dat) <- paste0("V", 1:length(index_data))
dat


Hope this helps,

Rui Barradas

Em 16-05-2015 18:12, ???????? kunjaai escreveu:
> Dear all,
>
>   I want to convert a variable (that variable obtained from an 'nc ' file) I
> want to convert  it into a* read.table* output format
>
> Example:
>
>> index_data<-get.var.ncdf(f_hist ,"meant_iitm_ALLIN_YEAR")
>> index_data
>   [1] 24.06333 24.07208 24.20208 24.12625 24.27333 24.42458 24.26583
>   [8] 24.30042 24.49750
>
>
> I want to convert it in to
>
>
>>    V1           V2         V3          V4              V5
> V6          V7          V8
> 24.06333  24.07208  24.20208 24.12625  24.27333 24.42458 24.26583 24.30042
>      V9
> 24.49750
>
>
> Thank you all in advance......
> --
> DILEEPKUMAR. R
> J R F, IIT DELHI
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hannah.hlx at gmail.com  Sat May 16 21:32:39 2015
From: hannah.hlx at gmail.com (li li)
Date: Sat, 16 May 2015 15:32:39 -0400
Subject: [R] dotplot
Message-ID: <CAHLnnda-2Vx8mOHMu-iG0yLsNKe_sJG80gCks17=2p5FG4vfhw@mail.gmail.com>

Hi all,
  I wrote the following code and have two questions:
  (1) As you can see, I would like different colors for different
types. It does not come out that way in the graph from this code.
Anyone know how to fix this?
   (2) How do I made the lots number on x axis eligible to read?
   (3) How do I remove the verticle line in the graph.
    Thanks for your help.
      Hanna


lot <- as.character(c("D1300000" ,"D1300005" ,"D1300010", "D1300015",
"D1300020",
         "D1300025" ,"D1300030" ,"D1300035", "D1300040",  "D1300045",
         "D1300000" ,"D1300005" ,"D1300010", "D1300015",  "D1300020",
         "D1300025" ,"D1300030" ,"D1300035", "D1300040",  "D1300045",
         "D1300000" ,"D1300005" ,"D1300010", "D1300015",  "D1300020",
         "D1300025" ,"D1300030" ,"D1300035", "D1300040",  "D1300045"))

val <- rnorm(30)
type <- rep(1:3,each=10)
tmp <- as.data.frame(cbind(val, type, lot))
tmp$sybm <- rep(c(1, 12, 16), each=10)
tmp$color <- rep(c("blue", "red", "green"), each=10)
tmp$val <- as.numeric(tmp$val)
dotplot(val ~ lot, tmp,
        ylab = "values", xlab="lot", aspect=1,
        pch=tmp$sybm, color=tmp$color)


From gunter.berton at gene.com  Sat May 16 21:54:41 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 16 May 2015 12:54:41 -0700
Subject: [R] Variable number of loops
In-Reply-To: <CALcakBbQpNzSHJCixYfn=2nPzS2mSX4u4jayBOq6tJ6wLx4BXg@mail.gmail.com>
References: <CALcakBaPjYfqzjqE8a5VhRF5NG4tvbsyOcn-6TiTH-dUvNZT1A@mail.gmail.com>
	<CACk-te1FO5rhrVrbkU8JF2ONOfBOAEGsB9JMAvShjG0cfBEGVQ@mail.gmail.com>
	<CALcakBbQpNzSHJCixYfn=2nPzS2mSX4u4jayBOq6tJ6wLx4BXg@mail.gmail.com>
Message-ID: <CACk-te3y7CHniVYJLUnxNiK-Mg=3gXC8ZwG0NBd_Ganiawz2Ag@mail.gmail.com>

1. Please always reply to the list unless there is a compelling reason
to keep the discussion private. You will have a better chance of
getting something useful that way.

2. I don't know what you mean by "I don't have a fixed number of
variables." You have to specify at least the number of variables and
how many levels each has in order to work out what you requested,
which is **NOT** the number of permutations but the number of
combinations AFAICS, which is exactly what expand.grid will give you.

3. Maybe what you're looking for is the ... arguments in function
calls, which would be used along the lines of:

myfun <- function( x,y,...)
{
## some code
combs <- expand.grid(...)
## some more code
}

Any good R tutorial will tell you about this if this is unfamiliar.

4. Another possibility might be to deliver a list of named variables
as an argument and then use do.call, e.g.

myfun <- (x,y, alist)
{
## some code
combs <- do.call(expand.grid, alist)
## some more code
}

?do.call and/or a tutorial for details.

5. Otherwise, maybe someone else can figure out what you're looking for.

Cheers,
Bert



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, May 16, 2015 at 11:16 AM, WRAY NICHOLAS
<nicholas.wray at ntlworld.com> wrote:
> I might be but doesn't expand.grid need a defined and listed number of
> inputs?  The problem I'm having is that the number of variables is not
> fixed, so I'm not sure whether I can reference the variable number of
> variables by using a vector -- haven't had time to try yet   But thanks
> anyway Nick Wray
>
> On 16 May 2015 at 14:28, Bert Gunter <gunter.berton at gene.com> wrote:
>>
>> Are you trying to reinvent ?expand.grid   ?
>>
>> -- Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Fri, May 15, 2015 at 1:40 PM, WRAY NICHOLAS
>> <nicholas.wray at ntlworld.com> wrote:
>> > I am trying to build a programme which will work out the permutations of
>> > a
>> > number of variables, eg a=0 to 1, b=0 to 1, and c=0 to 2, so
>> > permutations
>> > would be (0,0,0), (1,0,0), (0,1,0)... etc In this case there would be 2
>> > x
>> > 2x 3 = 12 permutations.  If the number of variables are fixed it's easy
>> > to
>> > loop round with nesting
>> >
>> > However I don't have a fixed number of variables, so I have a variable
>> > number of loops.  I am trying to use a recursive function to do this and
>> > have been building it up step-wise
>> >
>> > I want to return a list of all the permutations at the end, but the
>> > programme I have so ar doesn't return a full list, but just the first
>> > element
>> >
>> > 2 things -- 1 I don't see why this is happening, and 2 is this the right
>> > way to approach this problem?  I cannot find find anything about this in
>> > R
>> > on the net
>> >
>> > recursfunc1<-function(xf,shiftvecf,vlistf){
>> >   if(xf<4){
>> >     xf<-xf+1
>> >     vlistf[[length(vlistf)+1]]<-shiftvec[xf]
>> >     #print(paste(xf,"and",shiftvec[xf]))
>> >     print(vlistf)
>> >     #print(shiftvec[xf])
>> >     xf<-recursfunc1(xf,shiftvecf,vlistf)}
>> >   return(vlistf)}
>> >
>> > shiftvec<-c(2,1,1,0)
>> > vlist<-list()
>> > perm<-recursfunc1(xf=0,shiftvecf=shiftvec,vlistf=vlist)
>> > perm
>> >
>> > I want perm to return the elements of shiftvec as a list so that I can
>> > then
>> > do all the permutations as the next stage, but it only returns the first
>> > element of shiftvec
>> >
>> > Thanks, Nick Wray
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From djnordlund at frontier.com  Sat May 16 22:19:49 2015
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Sat, 16 May 2015 13:19:49 -0700
Subject: [R] dotplot
In-Reply-To: <CAHLnnda-2Vx8mOHMu-iG0yLsNKe_sJG80gCks17=2p5FG4vfhw@mail.gmail.com>
References: <CAHLnnda-2Vx8mOHMu-iG0yLsNKe_sJG80gCks17=2p5FG4vfhw@mail.gmail.com>
Message-ID: <5557A665.1060605@frontier.com>

On 5/16/2015 12:32 PM, li li wrote:
> Hi all,
>    I wrote the following code and have two questions:
>    (1) As you can see, I would like different colors for different
> types. It does not come out that way in the graph from this code.
> Anyone know how to fix this?
>     (2) How do I made the lots number on x axis eligible to read?
>     (3) How do I remove the verticle line in the graph.
>      Thanks for your help.
>        Hanna
>
>
> lot <- as.character(c("D1300000" ,"D1300005" ,"D1300010", "D1300015",
> "D1300020",
>           "D1300025" ,"D1300030" ,"D1300035", "D1300040",  "D1300045",
>           "D1300000" ,"D1300005" ,"D1300010", "D1300015",  "D1300020",
>           "D1300025" ,"D1300030" ,"D1300035", "D1300040",  "D1300045",
>           "D1300000" ,"D1300005" ,"D1300010", "D1300015",  "D1300020",
>           "D1300025" ,"D1300030" ,"D1300035", "D1300040",  "D1300045"))
>
> val <- rnorm(30)
> type <- rep(1:3,each=10)
> tmp <- as.data.frame(cbind(val, type, lot))
> tmp$sybm <- rep(c(1, 12, 16), each=10)
> tmp$color <- rep(c("blue", "red", "green"), each=10)
> tmp$val <- as.numeric(tmp$val)
> dotplot(val ~ lot, tmp,
>          ylab = "values", xlab="lot", aspect=1,
>          pch=tmp$sybm, color=tmp$color)
>

Li Li,

1. if the dotplot function you are referring to is from the lattice 
package, then the correct name for the "color" parameter is col.  You 
could just use col=type to get different colors but you won't have 
control over the colors chosen.  I created a vector, color, specifying 
the colors and the order they will be applied.

2.  the scales parameter is what you are looking for.  The parameter is 
looking for a list which consists of name=value pairs. You can rotate 
the labels by a specified number of degrees.  In my example, I chose 30 
degrees, rot=30.

3. I don't know how to eliminate the vertical lines, but if you read the 
lattice documentation, you will find it (if it is possible).

color=c("blue", "red", "green")
dotplot(val ~ lot, tmp,
         ylab = "values", xlab="lot", scales=list(rot=30), aspect=1,
         pch=tmp$sybm, col=color)


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Bothell, WA USA


From djnordlund at frontier.com  Sat May 16 22:45:16 2015
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Sat, 16 May 2015 13:45:16 -0700
Subject: [R] dotplot
In-Reply-To: <5557A665.1060605@frontier.com>
References: <CAHLnnda-2Vx8mOHMu-iG0yLsNKe_sJG80gCks17=2p5FG4vfhw@mail.gmail.com>
	<5557A665.1060605@frontier.com>
Message-ID: <5557AC5C.4090509@frontier.com>

On 5/16/2015 1:19 PM, Daniel Nordlund wrote:
> On 5/16/2015 12:32 PM, li li wrote:
>> Hi all,
>>    I wrote the following code and have two questions:
>>    (1) As you can see, I would like different colors for different
>> types. It does not come out that way in the graph from this code.
>> Anyone know how to fix this?
>>     (2) How do I made the lots number on x axis eligible to read?
>>     (3) How do I remove the verticle line in the graph.
>>      Thanks for your help.
>>        Hanna
>>
>>
>> lot <- as.character(c("D1300000" ,"D1300005" ,"D1300010", "D1300015",
>> "D1300020",
>>           "D1300025" ,"D1300030" ,"D1300035", "D1300040",  "D1300045",
>>           "D1300000" ,"D1300005" ,"D1300010", "D1300015",  "D1300020",
>>           "D1300025" ,"D1300030" ,"D1300035", "D1300040",  "D1300045",
>>           "D1300000" ,"D1300005" ,"D1300010", "D1300015",  "D1300020",
>>           "D1300025" ,"D1300030" ,"D1300035", "D1300040",  "D1300045"))
>>
>> val <- rnorm(30)
>> type <- rep(1:3,each=10)
>> tmp <- as.data.frame(cbind(val, type, lot))
>> tmp$sybm <- rep(c(1, 12, 16), each=10)
>> tmp$color <- rep(c("blue", "red", "green"), each=10)
>> tmp$val <- as.numeric(tmp$val)
>> dotplot(val ~ lot, tmp,
>>          ylab = "values", xlab="lot", aspect=1,
>>          pch=tmp$sybm, color=tmp$color)
>>
>
> Li Li,
>
> 1. if the dotplot function you are referring to is from the lattice
> package, then the correct name for the "color" parameter is col.  You
> could just use col=type to get different colors but you won't have
> control over the colors chosen.  I created a vector, color, specifying
> the colors and the order they will be applied.
>
> 2.  the scales parameter is what you are looking for.  The parameter is
> looking for a list which consists of name=value pairs. You can rotate
> the labels by a specified number of degrees.  In my example, I chose 30
> degrees, rot=30.
>
> 3. I don't know how to eliminate the vertical lines, but if you read the
> lattice documentation, you will find it (if it is possible).
>
> color=c("blue", "red", "green")
> dotplot(val ~ lot, tmp,
>          ylab = "values", xlab="lot", scales=list(rot=30), aspect=1,
>          pch=tmp$sybm, col=color)
>
>
> Hope this is helpful,
>
> Dan
>

I apologize; my use of the color vector was incorrect.  You could just 
use the tmp$color values with the correct color parameter name.  Like

dotplot(val ~ lot, tmp,
         ylab = "values", xlab="lot", scales=list(rot=30), aspect=1,
         pch=tmp$sybm, col=tmp$color)


Dan



-- 
Daniel Nordlund
Bothell, WA USA


From drjimlemon at gmail.com  Sun May 17 01:19:06 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 17 May 2015 09:19:06 +1000
Subject: [R] Variable number of loops
In-Reply-To: <CACk-te3y7CHniVYJLUnxNiK-Mg=3gXC8ZwG0NBd_Ganiawz2Ag@mail.gmail.com>
References: <CALcakBaPjYfqzjqE8a5VhRF5NG4tvbsyOcn-6TiTH-dUvNZT1A@mail.gmail.com>
	<CACk-te1FO5rhrVrbkU8JF2ONOfBOAEGsB9JMAvShjG0cfBEGVQ@mail.gmail.com>
	<CALcakBbQpNzSHJCixYfn=2nPzS2mSX4u4jayBOq6tJ6wLx4BXg@mail.gmail.com>
	<CACk-te3y7CHniVYJLUnxNiK-Mg=3gXC8ZwG0NBd_Ganiawz2Ag@mail.gmail.com>
Message-ID: <CA+8X3fVXnyP4kJNV+D7fscap+ceL7WFw49=tFpC0-YcVDjAquw@mail.gmail.com>

Hi all,
Given the number of help requests that involve
permutations/combinations, and the less than obvious naming of the
expand.grid function, perhaps adding an alias such as
"permute.elements" or "combine.elements" might ease the tasks of both
searchers and those offering help. Neither of the above names appear
to be used at present.

Jim


On Sun, May 17, 2015 at 5:54 AM, Bert Gunter <gunter.berton at gene.com> wrote:
> 1. Please always reply to the list unless there is a compelling reason
> to keep the discussion private. You will have a better chance of
> getting something useful that way.
>
> 2. I don't know what you mean by "I don't have a fixed number of
> variables." You have to specify at least the number of variables and
> how many levels each has in order to work out what you requested,
> which is **NOT** the number of permutations but the number of
> combinations AFAICS, which is exactly what expand.grid will give you.
>
> 3. Maybe what you're looking for is the ... arguments in function
> calls, which would be used along the lines of:
>
> myfun <- function( x,y,...)
> {
> ## some code
> combs <- expand.grid(...)
> ## some more code
> }
>
> Any good R tutorial will tell you about this if this is unfamiliar.
>
> 4. Another possibility might be to deliver a list of named variables
> as an argument and then use do.call, e.g.
>
> myfun <- (x,y, alist)
> {
> ## some code
> combs <- do.call(expand.grid, alist)
> ## some more code
> }
>
> ?do.call and/or a tutorial for details.
>
> 5. Otherwise, maybe someone else can figure out what you're looking for.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Sat, May 16, 2015 at 11:16 AM, WRAY NICHOLAS
> <nicholas.wray at ntlworld.com> wrote:
>> I might be but doesn't expand.grid need a defined and listed number of
>> inputs?  The problem I'm having is that the number of variables is not
>> fixed, so I'm not sure whether I can reference the variable number of
>> variables by using a vector -- haven't had time to try yet   But thanks
>> anyway Nick Wray
>>
>> On 16 May 2015 at 14:28, Bert Gunter <gunter.berton at gene.com> wrote:
>>>
>>> Are you trying to reinvent ?expand.grid   ?
>>>
>>> -- Bert
>>>
>>> Bert Gunter
>>> Genentech Nonclinical Biostatistics
>>> (650) 467-7374
>>>
>>> "Data is not information. Information is not knowledge. And knowledge
>>> is certainly not wisdom."
>>> Clifford Stoll
>>>
>>>
>>>
>>>
>>> On Fri, May 15, 2015 at 1:40 PM, WRAY NICHOLAS
>>> <nicholas.wray at ntlworld.com> wrote:
>>> > I am trying to build a programme which will work out the permutations of
>>> > a
>>> > number of variables, eg a=0 to 1, b=0 to 1, and c=0 to 2, so
>>> > permutations
>>> > would be (0,0,0), (1,0,0), (0,1,0)... etc In this case there would be 2
>>> > x
>>> > 2x 3 = 12 permutations.  If the number of variables are fixed it's easy
>>> > to
>>> > loop round with nesting
>>> >
>>> > However I don't have a fixed number of variables, so I have a variable
>>> > number of loops.  I am trying to use a recursive function to do this and
>>> > have been building it up step-wise
>>> >
>>> > I want to return a list of all the permutations at the end, but the
>>> > programme I have so ar doesn't return a full list, but just the first
>>> > element
>>> >
>>> > 2 things -- 1 I don't see why this is happening, and 2 is this the right
>>> > way to approach this problem?  I cannot find find anything about this in
>>> > R
>>> > on the net
>>> >
>>> > recursfunc1<-function(xf,shiftvecf,vlistf){
>>> >   if(xf<4){
>>> >     xf<-xf+1
>>> >     vlistf[[length(vlistf)+1]]<-shiftvec[xf]
>>> >     #print(paste(xf,"and",shiftvec[xf]))
>>> >     print(vlistf)
>>> >     #print(shiftvec[xf])
>>> >     xf<-recursfunc1(xf,shiftvecf,vlistf)}
>>> >   return(vlistf)}
>>> >
>>> > shiftvec<-c(2,1,1,0)
>>> > vlist<-list()
>>> > perm<-recursfunc1(xf=0,shiftvecf=shiftvec,vlistf=vlist)
>>> > perm
>>> >
>>> > I want perm to return the elements of shiftvec as a list so that I can
>>> > then
>>> > do all the permutations as the next stage, but it only returns the first
>>> > element of shiftvec
>>> >
>>> > Thanks, Nick Wray
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Sun May 17 02:48:40 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sun, 17 May 2015 10:48:40 +1000
Subject: [R] dotplot
In-Reply-To: <5557AC5C.4090509@frontier.com>
References: <CAHLnnda-2Vx8mOHMu-iG0yLsNKe_sJG80gCks17=2p5FG4vfhw@mail.gmail.com>	<5557A665.1060605@frontier.com>
	<5557AC5C.4090509@frontier.com>
Message-ID: <000001d0903b$38d07480$aa715d80$@bigpond.com>

if this is using lattice panel.dotplot gives the clues
The vertical lines are inserted by panel abline.

You can make your own panel.dotplot function by removing panel.abline which
uses col.line for the vertical line colour
 
A quick fix is by making col.line = "transparent". If you want to add lines
this may cause trouble for you

dotplot(val ~ lot, tmp,
        col.line = "transparent",
        ylab = "values", xlab="lot", scales=list(rot=30), aspect=1,
        pch=tmp$sybm, col=tmp$color)

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Daniel
Nordlund
Sent: Sunday, 17 May 2015 06:45
To: r-help at r-project.org
Cc: SAS-L at LISTSERV.UGA.EDU
Subject: Re: [R] dotplot

On 5/16/2015 1:19 PM, Daniel Nordlund wrote:
> On 5/16/2015 12:32 PM, li li wrote:
>> Hi all,
>>    I wrote the following code and have two questions:
>>    (1) As you can see, I would like different colors for different
>> types. It does not come out that way in the graph from this code.
>> Anyone know how to fix this?
>>     (2) How do I made the lots number on x axis eligible to read?
>>     (3) How do I remove the verticle line in the graph.
>>      Thanks for your help.
>>        Hanna
>>
>>
>> lot <- as.character(c("D1300000" ,"D1300005" ,"D1300010", "D1300015",
>> "D1300020",
>>           "D1300025" ,"D1300030" ,"D1300035", "D1300040",  "D1300045",
>>           "D1300000" ,"D1300005" ,"D1300010", "D1300015",  "D1300020",
>>           "D1300025" ,"D1300030" ,"D1300035", "D1300040",  "D1300045",
>>           "D1300000" ,"D1300005" ,"D1300010", "D1300015",  "D1300020",
>>           "D1300025" ,"D1300030" ,"D1300035", "D1300040",  "D1300045"))
>>
>> val <- rnorm(30)
>> type <- rep(1:3,each=10)
>> tmp <- as.data.frame(cbind(val, type, lot))
>> tmp$sybm <- rep(c(1, 12, 16), each=10)
>> tmp$color <- rep(c("blue", "red", "green"), each=10)
>> tmp$val <- as.numeric(tmp$val)
>> dotplot(val ~ lot, tmp,
>>          ylab = "values", xlab="lot", aspect=1,
>>          pch=tmp$sybm, color=tmp$color)
>>
>
> Li Li,
>
> 1. if the dotplot function you are referring to is from the lattice
> package, then the correct name for the "color" parameter is col.  You
> could just use col=type to get different colors but you won't have
> control over the colors chosen.  I created a vector, color, specifying
> the colors and the order they will be applied.
>
> 2.  the scales parameter is what you are looking for.  The parameter is
> looking for a list which consists of name=value pairs. You can rotate
> the labels by a specified number of degrees.  In my example, I chose 30
> degrees, rot=30.
>
> 3. I don't know how to eliminate the vertical lines, but if you read the
> lattice documentation, you will find it (if it is possible).
>
> color=c("blue", "red", "green")
> dotplot(val ~ lot, tmp,
>          ylab = "values", xlab="lot", scales=list(rot=30), aspect=1,
>          pch=tmp$sybm, col=color)
>
>
> Hope this is helpful,
>
> Dan
>

I apologize; my use of the color vector was incorrect.  You could just 
use the tmp$color values with the correct color parameter name.  Like

dotplot(val ~ lot, tmp,
         ylab = "values", xlab="lot", scales=list(rot=30), aspect=1,
         pch=tmp$sybm, col=tmp$color)


Dan



-- 
Daniel Nordlund
Bothell, WA USA

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun May 17 01:04:03 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 17 May 2015 09:04:03 +1000
Subject: [R] Convert to a vector to read.table output format
In-Reply-To: <55578D95.4010209@sapo.pt>
References: <CALTF6skSDUvp8U2yFVbbVwG9M3Y8LReiEf0jKbVkVYU8G7dh+Q@mail.gmail.com>
	<55578D95.4010209@sapo.pt>
Message-ID: <CA+8X3fW0bPqBMw9H4_hnQm7DoWz2LbycJ+UkvHyH=CUUBgAbhQ@mail.gmail.com>

Hi ????????,
It looks like you want write.table.

# as Rui Suggested
names(index_data) <- paste0("V", 1:length(index_data))
write.table(index.table,"index_table_file.txt",row.names=FALSE)

Jim


On Sun, May 17, 2015 at 4:33 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> I'm not exactly sure of what you want.
> 1) If you just want that output, just set the names attribute  of
> index_data.
>
> names(index_data) <- paste0("V", 1:length(index_data))
>
> 2) If you want to create a data.frame from index_data try the following.
>
> dat <- data.frame(index_data[1])
> for(i in 2:length(index_data))
>         dat <-cbind(dat, index_data[i])
> names(dat) <- paste0("V", 1:length(index_data))
> dat
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> Em 16-05-2015 18:12, ???????? kunjaai escreveu:
>>
>> Dear all,
>>
>>   I want to convert a variable (that variable obtained from an 'nc ' file)
>> I
>> want to convert  it into a* read.table* output format
>>
>> Example:
>>
>>> index_data<-get.var.ncdf(f_hist ,"meant_iitm_ALLIN_YEAR")
>>> index_data
>>
>>   [1] 24.06333 24.07208 24.20208 24.12625 24.27333 24.42458 24.26583
>>   [8] 24.30042 24.49750
>>
>>
>> I want to convert it in to
>>
>>
>>>    V1           V2         V3          V4              V5
>>
>> V6          V7          V8
>> 24.06333  24.07208  24.20208 24.12625  24.27333 24.42458 24.26583 24.30042
>>      V9
>> 24.49750
>>
>>
>> Thank you all in advance......
>> --
>> DILEEPKUMAR. R
>> J R F, IIT DELHI
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gjkruse at gmail.com  Sun May 17 00:39:12 2015
From: gjkruse at gmail.com (Greg K)
Date: Sat, 16 May 2015 15:39:12 -0700 (PDT)
Subject: [R] R Commander qcc
Message-ID: <CANtv0EWvSj9cu5Yu5SMNageavUrfT8BPjez+_go=wUYCD5VBpA@mail.gmail.com>

I am completely new to R and am trying to utilize its capabilities as an
alternative to Minitab.  I don't have any development ability at all, but
the R Commander GUI is able to give me the functionality I need with the
exception of control charts.  I have installed the qcc package but when I
load the package nothing happens (it does not give me any more functionality
or selection choices in Rcmdr).

I am sure there is something relatively simple that I am missing, but I
can't figure it out.  Any help would be greatly appreciated!

-Greg




--
View this message in context: http://r.789695.n4.nabble.com/R-Commander-qcc-tp4707327.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From alex at glasshat.com  Sun May 17 02:03:40 2015
From: alex at glasshat.com (Alex Fun)
Date: Sun, 17 May 2015 10:03:40 +1000
Subject: [R] List of Rserve integrations
Message-ID: <CAFK0YYaJc_FHt4tymkNfxLpjmHcWGDC=+LUq_oaTDDL6tRhAQg@mail.gmail.com>

Hi R users,

I am looking for examples of software that comes with an inbuilt connector
to Rserve. The only thing I have found so far is Tableau:
http://www.simafore.com/blog/bid/120209/Integrating-Tableau-and-R-for-data-analytics-in-four-simple-steps

Please let me know if anyone knows of more visualisation/data
analysis/reporting software that uses Rserve to connect to R.

Best regards,

Alex

-- 
 * Alex Fun *   Resident Scientist
  * Email: * alex at glasshat.com
* Website: * www.glasshat.com
* Address: * Level 9, 70 Pitt Street Sydney NSW 2000   * Office: * 02 9114
9515
 * Personal: * 02 9114 9515
* Fax: * None

<http://www.linkedin.com/company/glasshat?utm_source=WiseStamp&utm_medium=email&utm_term=&utm_content=&utm_campaign=signature>
<https://www.facebook.com/glasshattech?utm_source=WiseStamp&utm_medium=email&utm_term=&utm_content=&utm_campaign=signature>
<https://twitter.com/glasshattech?utm_source=WiseStamp&utm_medium=email&utm_term=&utm_content=&utm_campaign=signature>
<https://plus.google.com/u/0/b/106522326351402007579/106522326351402007579/posts?utm_source=WiseStamp&utm_medium=email&utm_term=&utm_content=&utm_campaign=signature>
<https://au.linkedin.com/pub/alex-fun/52/666/677?utm_source=WiseStamp&utm_medium=email&utm_term=&utm_content=&utm_campaign=signature>
  Latest from our blog:  How to optimise you brand's Twitter account
<http://www.glasshat.com/blog/2015/5/6/how-to-optimise-twitter?utm_source=WiseStamp&utm_medium=email&utm_term=&utm_content=&utm_campaign=signature>
  IMPORTANT: The contents of this email and any attachments are
confidential. They are intended for the named recipient(s) only. If you
have received this email by mistake, please notify the sender immediately
and do not disclose the contents to anyone or make copies thereof.

	[[alternative HTML version deleted]]


From lyle00 at gmail.com  Sat May 16 15:53:46 2015
From: lyle00 at gmail.com (Lyle Warren)
Date: Sat, 16 May 2015 23:53:46 +1000
Subject: [R] Help manipulating 23andme data in R - reproducing relationship
	results
Message-ID: <CAA3AKSfNk2aNmaue6vRhVj_ox+0eF6yD6op8s1GVT-41T5hY8w@mail.gmail.com>

Hi,

I'm trying to replicate 23andMe's parentage test results within R, using
the 23andme raw data. Does anyone know a simple way to do this? I have read
the data with gwascat and it seems to be in there fine.

Thanks for any help you can give!

Cheers,

Lyle

	[[alternative HTML version deleted]]


From lyle00 at gmail.com  Sun May 17 00:32:45 2015
From: lyle00 at gmail.com (Lyle Warren)
Date: Sun, 17 May 2015 08:32:45 +1000
Subject: [R] Comparing 2 different files in R
Message-ID: <CAA3AKSdx3cHFoqBn5Pxf3Af=DW82vZE-VCFuR9++_dnz9gxVdA@mail.gmail.com>

Hi,

I have multiple files that I want to compare in R. They contain SNP data
with genotype in the 4th column, which is what I want to compare.

Is there any easy way to do this?

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun May 17 10:07:31 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 17 May 2015 20:07:31 +1200
Subject: [R] Comparing 2 different files in R
In-Reply-To: <CAA3AKSdx3cHFoqBn5Pxf3Af=DW82vZE-VCFuR9++_dnz9gxVdA@mail.gmail.com>
References: <CAA3AKSdx3cHFoqBn5Pxf3Af=DW82vZE-VCFuR9++_dnz9gxVdA@mail.gmail.com>
Message-ID: <55584C43.2000101@auckland.ac.nz>

On 17/05/15 10:32, Lyle Warren wrote:
> Hi,
>
> I have multiple files that I want to compare in R. They contain SNP data
> with genotype in the 4th column, which is what I want to compare.
>
> Is there any easy way to do this?

Yes.  Learn to use R.

cheers,

Rolf Turner


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From jrkrideau at inbox.com  Sun May 17 12:51:30 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 17 May 2015 02:51:30 -0800
Subject: [R] R Commander qcc
In-Reply-To: <CANtv0EWvSj9cu5Yu5SMNageavUrfT8BPjez+_go=wUYCD5VBpA@mail.gmail.com>
Message-ID: <E6383219D12.00000530jrkrideau@inbox.com>

Welcome to R and the R-help list.   

If I am not misunderstanding you, you expect use the qcc package from within the Rcmdr GUI.

I have never really used RCommander, though I played around with it a few years ago,   but I don't believe it can call qcc directly.  I 'think' you have the choice of using qcc from a command line interface or possibly installing a plug-in for Rcmder.  Have a look at this link http://decisionstats.com/2011/01/27/r-commander-plugins-20-and-growing/

BTW you might also be interested in this link http://blog.yhathq.com/posts/quality-control-in-r.html for other approaches to control charts.

While a good Gui like Rcmdr is useful you really will not get the full power of R with a Gui.  It can be a bit intimidating to use a command interface if you are not used to one but it is by far the best way.  It may not seem it but it is much more efficient in the longer term to go to a command-line interface. 

There is also the issue of whether there is an integration for the package and your Gui.  Luckily, it looks like there is a Rcmdr plugin for qcc but there are probably 100's, or more likely, 1000's of packages with such a plug-in and you cannot capitalize on them other than with a command-line approach.

You can use R by typing commands into the R-GUI (assuming you are using Windows) or by typing in the terminal under Linux but this does not work well. Most/all R users do all their writing in a text editor or Integrated Development Environment (IDE). There are some fierce wars over which editor or IDE is best. Here are a couple of links about the issue. Text Editors and IDEs http://r.789695.n4.nabble.com/Best-R-text-editors-td903450.html and http://en.wikipedia.org/wiki/R_%28programming_language%29#Editors_and_IDEs .

It's worth shopping around to see what best suits you. I have found Tinn-R very good when working in Windows though, recently, I have moved to Linux and to the IDE, RStudio and the gedit text editor with its R plug-in. A major advantage of Tinn-R and gedit , particularly if you are just getting started, is that they both have extensive code highlighting which makes it easier to find and fix minor syntax errors and typos. RStudio has several advantages, among other things, it shows what data objects you have loaded and makes saving and handling graphs easier .

BW one  of the obvious things I missed when first using R was  that you can just copy and paste code into R if you are working through an example to see what is happening

John Kane
Kingston ON Canada


> -----Original Message-----
> From: gjkruse at gmail.com
> Sent: Sat, 16 May 2015 15:39:12 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] R Commander qcc
> 
> I am completely new to R and am trying to utilize its capabilities as an
> alternative to Minitab.  I don't have any development ability at all, but
> the R Commander GUI is able to give me the functionality I need with the
> exception of control charts.  I have installed the qcc package but when I
> load the package nothing happens (it does not give me any more
> functionality
> or selection choices in Rcmdr).
> 
> I am sure there is something relatively simple that I am missing, but I
> can't figure it out.  Any help would be greatly appreciated!
> 
> -Greg
>

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From jrkrideau at inbox.com  Sun May 17 12:53:59 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 17 May 2015 02:53:59 -0800
Subject: [R] Comparing 2 different files in R
In-Reply-To: <CAA3AKSdx3cHFoqBn5Pxf3Af=DW82vZE-VCFuR9++_dnz9gxVdA@mail.gmail.com>
Message-ID: <E63DBF94A52.00000534jrkrideau@inbox.com>

Probably but since you  have not told us anything about what you are doing it is difficult to say.  

You might find these links helpful http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html


John Kane
Kingston ON Canada


> -----Original Message-----
> From: lyle00 at gmail.com
> Sent: Sun, 17 May 2015 08:32:45 +1000
> To: r-help at r-project.org
> Subject: [R] Comparing 2 different files in R
> 
> Hi,
> 
> I have multiple files that I want to compare in R. They contain SNP data
> with genotype in the 4th column, which is what I want to compare.
> 
> Is there any easy way to do this?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From lyle00 at gmail.com  Sun May 17 12:56:24 2015
From: lyle00 at gmail.com (Lyle Warren)
Date: Sun, 17 May 2015 20:56:24 +1000
Subject: [R] Comparing 2 different files in R
In-Reply-To: <E63DBF94A52.00000534jrkrideau@inbox.com>
References: <CAA3AKSdx3cHFoqBn5Pxf3Af=DW82vZE-VCFuR9++_dnz9gxVdA@mail.gmail.com>
	<E63DBF94A52.00000534jrkrideau@inbox.com>
Message-ID: <CAA3AKSfTWBT6iEVvv6cpw661jgREHi2TZUdmbzdUhkzUXJwsGA@mail.gmail.com>

Thanks and sorry for being light on detail.

I have multiple files of raw human genome SNP data. Very large - the
compressed zip files are about 8mb large.

On 17 May 2015 at 20:53, John Kane <jrkrideau at inbox.com> wrote:

> Probably but since you  have not told us anything about what you are doing
> it is difficult to say.
>
> You might find these links helpful
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> and http://adv-r.had.co.nz/Reproducibility.html
>
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: lyle00 at gmail.com
> > Sent: Sun, 17 May 2015 08:32:45 +1000
> > To: r-help at r-project.org
> > Subject: [R] Comparing 2 different files in R
> >
> > Hi,
> >
> > I have multiple files that I want to compare in R. They contain SNP data
> > with genotype in the 4th column, which is what I want to compare.
> >
> > Is there any easy way to do this?
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
> your desktop!
> Check it out at http://www.inbox.com/marineaquarium
>
>
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Sun May 17 13:14:28 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 17 May 2015 03:14:28 -0800
Subject: [R] Comparing 2 different files in R
In-Reply-To: <CAA3AKSfTWBT6iEVvv6cpw661jgREHi2TZUdmbzdUhkzUXJwsGA@mail.gmail.com>
References: <e63dbf94a52.00000534jrkrideau@inbox.com>
	<caa3aksdx3chfoqbn5pxf3af=dw82vze-vcfur9++_dnz9gxvda@mail.gmail.com>
Message-ID: <E66B861E873.0000054Cjrkrideau@inbox.com>

John Kane
Kingston ON Canada

-----Original Message-----
From: lyle00 at gmail.com
Sent: Sun, 17 May 2015 20:56:24 +1000
To: jrkrideau at inbox.com
Subject: Re: [R] Comparing 2 different files in R
This is not an area I am going to be able to help with but we still need a lot more information I think.

At the moment we know nothing about the structure of the data, what you are trying to accomplish, in substantive terms, and what you may have tried.  As I say. I know nothing about the area but perhaps we need to know if all you want is to see if the SNP's are the same in different files, do you need summary stats or graphics. Come to think of it, something like a journal abstract might do nicely.

It may be that more knowlegeable people can recommend useful approaches or suggest that your type of analysis is more suitable in the Bioconductor lists.

Ideally we should see any 'minimal' code you may have written in R if any, &  some sample data is possible. See ?dput for a handy way to provide data but we,  hopefully, don't need to see 8mg of data. Probably just the first few lines of data would do.  A command like dput(head(50)) should be enough. See ?dput and?head for what these are doing or have a look at the links provided earlier.  For various reasons dput() is about the best method available for passing data to a help list or forum.  

Oh and one more thing. You seem to have sent this last post in HTML. The R-help list is plain-text so we would ask that you send everything in plain. HTML is stripped away and the resulting plain text can be so close to unintelligible that many readers will just ignore it.
==============================================
Thanks and sorry for being light on detail.?

I have multiple files of raw human genome SNP data. Very large - the compressed zip files are about 8mb large.?

On 17 May 2015 at 20:53, John Kane <jrkrideau at inbox.com> wrote:

	Probably but since you? have not told us anything about what you are doing it is difficult to say.

 You might find these links helpful http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example] and http://adv-r.had.co.nz/Reproducibility.html [http://adv-r.had.co.nz/Reproducibility.html]

 John Kane
 Kingston ON Canada

 > -----Original Message-----
 > From: lyle00 at gmail.com
 > Sent: Sun, 17 May 2015 08:32:45 +1000
 > To: r-help at r-project.org
 > Subject: [R] Comparing 2 different files in R
 >
 > Hi,
 >
 > I have multiple files that I want to compare in R. They contain SNP data
 > with genotype in the 4th column, which is what I want to compare.
 >
 > Is there any easy way to do this?
 >

>? ? ? ?[[alternative HTML version deleted]]
 >
 > ______________________________________________
 > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 > PLEASE do read the posting guide
 > http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 > and provide commented, minimal, self-contained, reproducible code.

 ____________________________________________________________
 FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
 Check it out at http://www.inbox.com/marineaquarium [http://www.inbox.com/marineaquarium]

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From dileepkunjaai at gmail.com  Sun May 17 13:28:13 2015
From: dileepkunjaai at gmail.com (=?UTF-8?B?4LSV4LWB4LSe4LWN4LSe4LS+4LSv4LS/IGt1bmphYWk=?=)
Date: Sun, 17 May 2015 16:58:13 +0530
Subject: [R] Convert to a vector to read.table output format
In-Reply-To: <CA+8X3fW0bPqBMw9H4_hnQm7DoWz2LbycJ+UkvHyH=CUUBgAbhQ@mail.gmail.com>
References: <CALTF6skSDUvp8U2yFVbbVwG9M3Y8LReiEf0jKbVkVYU8G7dh+Q@mail.gmail.com>
	<55578D95.4010209@sapo.pt>
	<CA+8X3fW0bPqBMw9H4_hnQm7DoWz2LbycJ+UkvHyH=CUUBgAbhQ@mail.gmail.com>
Message-ID: <CALTF6s=8AfhVCPjOuu6B9VhsiWPH2VdcfPD4e_5bk+171X=w+A@mail.gmail.com>

Thank you all for your time......


Thank you.... Now its working.... :))


Cheers .....



On Sun, May 17, 2015 at 4:34 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi ????????,
> It looks like you want write.table.
>
> # as Rui Suggested
> names(index_data) <- paste0("V", 1:length(index_data))
> write.table(index.table,"index_table_file.txt",row.names=FALSE)
>
> Jim
>
>
> On Sun, May 17, 2015 at 4:33 AM, Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> > Hello,
> >
> > I'm not exactly sure of what you want.
> > 1) If you just want that output, just set the names attribute  of
> > index_data.
> >
> > names(index_data) <- paste0("V", 1:length(index_data))
> >
> > 2) If you want to create a data.frame from index_data try the following.
> >
> > dat <- data.frame(index_data[1])
> > for(i in 2:length(index_data))
> >         dat <-cbind(dat, index_data[i])
> > names(dat) <- paste0("V", 1:length(index_data))
> > dat
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> > Em 16-05-2015 18:12, ???????? kunjaai escreveu:
> >>
> >> Dear all,
> >>
> >>   I want to convert a variable (that variable obtained from an 'nc '
> file)
> >> I
> >> want to convert  it into a* read.table* output format
> >>
> >> Example:
> >>
> >>> index_data<-get.var.ncdf(f_hist ,"meant_iitm_ALLIN_YEAR")
> >>> index_data
> >>
> >>   [1] 24.06333 24.07208 24.20208 24.12625 24.27333 24.42458 24.26583
> >>   [8] 24.30042 24.49750
> >>
> >>
> >> I want to convert it in to
> >>
> >>
> >>>    V1           V2         V3          V4              V5
> >>
> >> V6          V7          V8
> >> 24.06333  24.07208  24.20208 24.12625  24.27333 24.42458 24.26583
> 24.30042
> >>      V9
> >> 24.49750
> >>
> >>
> >> Thank you all in advance......
> >> --
> >> DILEEPKUMAR. R
> >> J R F, IIT DELHI
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
DILEEPKUMAR. R
J R F, IIT DELHI

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Sun May 17 14:15:14 2015
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 17 May 2015 08:15:14 -0400
Subject: [R] R Commander qcc
In-Reply-To: <E6383219D12.00000530jrkrideau@inbox.com>
References: <E6383219D12.00000530jrkrideau@inbox.com>
Message-ID: <web-560162819@cgpsrv2.cis.mcmaster.ca>

Dear John and Greg,

As John says, even with the about 40 plugin packages that are on CRAN (the R package archive network), the Rcmdr covers only a small fraction of what's available in base R and the thousands of CRAN packages.

As it turns out, however, there's an Rcmdr quality-control plugin that may meet Greg's needs, RcmdrPlugin.qual <http://cran.r-project.org/web/packages/RcmdrPlugin.qual/index.html>. You might check that out. Install it via the command install.packages("RcmdrPlugin.qual") at the R > command prompt, and then either load it via the Rcmdr Tools menu or directly via library(RcmdrPlugin.qual).

More generally, the names of most Rcmdr plugins begin with "RcmdrPlugin.". If you go to the alphbetical CRAN packages list at <http://cran.r-project.org/web/packages/available_packages_by_name.html> and search for "RcmdrPlugin.", you'll see them. Searching for "Rcmdr" will turn up a few more.

I hope this helps,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	
	
	

On Sun, 17 May 2015 02:51:30 -0800
 John Kane <jrkrideau at inbox.com> wrote:
> Welcome to R and the R-help list.   
> 
> If I am not misunderstanding you, you expect use the qcc package from within the Rcmdr GUI.
> 
> I have never really used RCommander, though I played around with it a few years ago,   but I don't believe it can call qcc directly.  I 'think' you have the choice of using qcc from a command line interface or possibly installing a plug-in for Rcmder.  Have a look at this link http://decisionstats.com/2011/01/27/r-commander-plugins-20-and-growing/
> 
> BTW you might also be interested in this link http://blog.yhathq.com/posts/quality-control-in-r.html for other approaches to control charts.
> 
> While a good Gui like Rcmdr is useful you really will not get the full power of R with a Gui.  It can be a bit intimidating to use a command interface if you are not used to one but it is by far the best way.  It may not seem it but it is much more efficient in the longer term to go to a command-line interface. 
> 
> There is also the issue of whether there is an integration for the package and your Gui.  Luckily, it looks like there is a Rcmdr plugin for qcc but there are probably 100's, or more likely, 1000's of packages with such a plug-in and you cannot capitalize on them other than with a command-line approach.
> 
> You can use R by typing commands into the R-GUI (assuming you are using Windows) or by typing in the terminal under Linux but this does not work well. Most/all R users do all their writing in a text editor or Integrated Development Environment (IDE). There are some fierce wars over which editor or IDE is best. Here are a couple of links about the issue. Text Editors and IDEs http://r.789695.n4.nabble.com/Best-R-text-editors-td903450.html and http://en.wikipedia.org/wiki/R_%28programming_language%29#Editors_and_IDEs .
> 
> It's worth shopping around to see what best suits you. I have found Tinn-R very good when working in Windows though, recently, I have moved to Linux and to the IDE, RStudio and the gedit text editor with its R plug-in. A major advantage of Tinn-R and gedit , particularly if you are just getting started, is that they both have extensive code highlighting which makes it easier to find and fix minor syntax errors and typos. RStudio has several advantages, among other things, it shows what data objects you have loaded and makes saving and handling graphs easier .
> 
> BW one  of the obvious things I missed when first using R was  that you can just copy and paste code into R if you are working through an example to see what is happening
> 
> John Kane
> Kingston ON Canada
> 
> 
> > -----Original Message-----
> > From: gjkruse at gmail.com
> > Sent: Sat, 16 May 2015 15:39:12 -0700 (PDT)
> > To: r-help at r-project.org
> > Subject: [R] R Commander qcc
> > 
> > I am completely new to R and am trying to utilize its capabilities as an
> > alternative to Minitab.  I don't have any development ability at all, but
> > the R Commander GUI is able to give me the functionality I need with the
> > exception of control charts.  I have installed the qcc package but when I
> > load the package nothing happens (it does not give me any more
> > functionality
> > or selection choices in Rcmdr).
> > 
> > I am sure there is something relatively simple that I am missing, but I
> > can't figure it out.  Any help would be greatly appreciated!
> > 
> > -Greg
> >
> 
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sun May 17 14:23:40 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 17 May 2015 04:23:40 -0800
Subject: [R] R Commander qcc
In-Reply-To: <web-560162819@cgpsrv2.cis.mcmaster.ca>
References: <e6383219d12.00000530jrkrideau@inbox.com>
Message-ID: <E706332962D.000005C0jrkrideau@inbox.com>

Thanks John,

I had not realised they were on CRAN.  Definately a great help.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jfox at mcmaster.ca
> Sent: Sun, 17 May 2015 08:15:14 -0400
> To: jrkrideau at inbox.com, gjkruse at gmail.com
> Subject: Re: [R] R Commander qcc
> 
> Dear John and Greg,
> 
> As John says, even with the about 40 plugin packages that are on CRAN
> (the R package archive network), the Rcmdr covers only a small fraction
> of what's available in base R and the thousands of CRAN packages.
> 
> As it turns out, however, there's an Rcmdr quality-control plugin that
> may meet Greg's needs, RcmdrPlugin.qual
> <http://cran.r-project.org/web/packages/RcmdrPlugin.qual/index.html>. You
> might check that out. Install it via the command
> install.packages("RcmdrPlugin.qual") at the R > command prompt, and then
> either load it via the Rcmdr Tools menu or directly via
> library(RcmdrPlugin.qual).
> 
> More generally, the names of most Rcmdr plugins begin with
> "RcmdrPlugin.". If you go to the alphbetical CRAN packages list at
> <http://cran.r-project.org/web/packages/available_packages_by_name.html>
> and search for "RcmdrPlugin.", you'll see them. Searching for "Rcmdr"
> will turn up a few more.
> 
> I hope this helps,
>  John
> 
> ------------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
> 
> 
> 
> 
> On Sun, 17 May 2015 02:51:30 -0800
>  John Kane <jrkrideau at inbox.com> wrote:
>> Welcome to R and the R-help list.
>> 
>> If I am not misunderstanding you, you expect use the qcc package from
>> within the Rcmdr GUI.
>> 
>> I have never really used RCommander, though I played around with it a
>> few years ago,   but I don't believe it can call qcc directly.  I
>> 'think' you have the choice of using qcc from a command line interface
>> or possibly installing a plug-in for Rcmder.  Have a look at this link
>> http://decisionstats.com/2011/01/27/r-commander-plugins-20-and-growing/
>> 
>> BTW you might also be interested in this link
>> http://blog.yhathq.com/posts/quality-control-in-r.html for other
>> approaches to control charts.
>> 
>> While a good Gui like Rcmdr is useful you really will not get the full
>> power of R with a Gui.  It can be a bit intimidating to use a command
>> interface if you are not used to one but it is by far the best way.  It
>> may not seem it but it is much more efficient in the longer term to go
>> to a command-line interface.
>> 
>> There is also the issue of whether there is an integration for the
>> package and your Gui.  Luckily, it looks like there is a Rcmdr plugin
>> for qcc but there are probably 100's, or more likely, 1000's of packages
>> with such a plug-in and you cannot capitalize on them other than with a
>> command-line approach.
>> 
>> You can use R by typing commands into the R-GUI (assuming you are using
>> Windows) or by typing in the terminal under Linux but this does not work
>> well. Most/all R users do all their writing in a text editor or
>> Integrated Development Environment (IDE). There are some fierce wars
>> over which editor or IDE is best. Here are a couple of links about the
>> issue. Text Editors and IDEs
>> http://r.789695.n4.nabble.com/Best-R-text-editors-td903450.html and
http://en.wikipedia.org/wiki/R_%28programming_language%29#Editors_and_IDEs
>> .
>> 
>> It's worth shopping around to see what best suits you. I have found
>> Tinn-R very good when working in Windows though, recently, I have moved
>> to Linux and to the IDE, RStudio and the gedit text editor with its R
>> plug-in. A major advantage of Tinn-R and gedit , particularly if you are
>> just getting started, is that they both have extensive code highlighting
>> which makes it easier to find and fix minor syntax errors and typos.
>> RStudio has several advantages, among other things, it shows what data
>> objects you have loaded and makes saving and handling graphs easier .
>> 
>> BW one  of the obvious things I missed when first using R was  that you
>> can just copy and paste code into R if you are working through an
>> example to see what is happening
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: gjkruse at gmail.com
>>> Sent: Sat, 16 May 2015 15:39:12 -0700 (PDT)
>>> To: r-help at r-project.org
>>> Subject: [R] R Commander qcc
>>> 
>>> I am completely new to R and am trying to utilize its capabilities as
>>> an
>>> alternative to Minitab.  I don't have any development ability at all,
>>> but
>>> the R Commander GUI is able to give me the functionality I need with
>>> the
>>> exception of control charts.  I have installed the qcc package but when
>>> I
>>> load the package nothing happens (it does not give me any more
>>> functionality
>>> or selection choices in Rcmdr).
>>> 
>>> I am sure there is something relatively simple that I am missing, but I
>>> can't figure it out.  Any help would be greatly appreciated!
>>> 
>>> -Greg
>>> 
>> 
>> ____________________________________________________________
>> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From lyle00 at gmail.com  Sun May 17 15:15:19 2015
From: lyle00 at gmail.com (Lyle Warren)
Date: Sun, 17 May 2015 23:15:19 +1000
Subject: [R] Comparing 2 different files in R
In-Reply-To: <752C3AED-083B-4080-BC3C-03537C2EAC97@gmail.com>
References: <CAA3AKSdx3cHFoqBn5Pxf3Af=DW82vZE-VCFuR9++_dnz9gxVdA@mail.gmail.com>
	<E63DBF94A52.00000534jrkrideau@inbox.com>
	<CAA3AKSfTWBT6iEVvv6cpw661jgREHi2TZUdmbzdUhkzUXJwsGA@mail.gmail.com>
	<752C3AED-083B-4080-BC3C-03537C2EAC97@gmail.com>
Message-ID: <CAA3AKSfFDo=tO77rQnydj+++Co2Zd8StZJO3+fvhjzamfCobkg@mail.gmail.com>

Thanks Ben!

On 17 May 2015 at 23:14, Ben Tupper <ben.bighair at gmail.com> wrote:

> Hi,
>
> On May 17, 2015, at 6:56 AM, Lyle Warren <lyle00 at gmail.com> wrote:
>
> > Thanks and sorry for being light on detail.
> >
> > I have multiple files of raw human genome SNP data. Very large - the
> > compressed zip files are about 8mb large.
> >
>
> You'll have better luck asking on the Bioconductor help list (
> http://www.bioconductor.org/ ) You may want to start here...
>
> http://www.bioconductor.org/help/support/posting-guide/
>
> and here...
>
> http://www.bioconductor.org/help/search/index.html?q=SNP
>
>
> Cheers,
> Ben
>
>
>
>
> > On 17 May 2015 at 20:53, John Kane <jrkrideau at inbox.com> wrote:
> >
> >> Probably but since you  have not told us anything about what you are
> doing
> >> it is difficult to say.
> >>
> >> You might find these links helpful
> >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >> and http://adv-r.had.co.nz/Reproducibility.html
> >>
> >>
> >> John Kane
> >> Kingston ON Canada
> >>
> >>
> >>> -----Original Message-----
> >>> From: lyle00 at gmail.com
> >>> Sent: Sun, 17 May 2015 08:32:45 +1000
> >>> To: r-help at r-project.org
> >>> Subject: [R] Comparing 2 different files in R
> >>>
> >>> Hi,
> >>>
> >>> I have multiple files that I want to compare in R. They contain SNP
> data
> >>> with genotype in the 4th column, which is what I want to compare.
> >>>
> >>> Is there any easy way to do this?
> >>>
> >>>      [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ____________________________________________________________
> >> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
> >> your desktop!
> >> Check it out at http://www.inbox.com/marineaquarium
> >>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun May 17 15:27:21 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 17 May 2015 09:27:21 -0400
Subject: [R] Illustrating use of R package
In-Reply-To: <dca7fd64-2e0f-445d-bfee-8b31c87169ba@me.com>
References: <dca7fd64-2e0f-445d-bfee-8b31c87169ba@me.com>
Message-ID: <55589739.1000000@gmail.com>

Lots of questions.  I'm only answering some of them, inline.

On 15/05/2015 9:04 PM, Glenn Schultz wrote:
> I have an R package Bond Lab which actually supports a book Investing in MBS using R and Open Source Computing.  The Bond Lab beta is stable.  I have also created a package companion to investing in MBS.  Both are on my Github site
> 
> https://github.com/glennmschultz/
> 
> I wrote the companion as functions for each chapter calling source code.  I really don't like the way it works presentation wise but the user could see the code used.  Further, the user must create a directory and copy the source into the directory.  Further the source runs all examples at once which seems a little confusion.  However, to illustrate a function for chapter example I think I have to make a function to call a function which does not make sense.
> 
> My first question, any suggestions on illustrating function call aside from the strategy I am using.  I am not a fan of what I am doing.
> 
> My second question regards on.load() vs. on.attach() Bond Lab needs to create the BondLab directory which installs in the BondLab library to the ~/users directory, the same for the companion.  
> 
> I think I should use on.load(), correct?

Almost certainly.  Only use on.attach() if the action depends on whether
the package functions are visible to the user (as opposed to being only
visible to some other package that is using it).  If you want the same
actions regardless of visibility, use on.load().

> I am not sure how to do this and will the same function work for both Windows and MAC?  

dir.create() will, but you need to be careful how you specify paths.  If
you use system.file() to construct the path you should be okay.

> Do I need different copy from path for Windows and MAC or can it be generic since the copy happens at load.
> I would like to get Bond Lab on CRAN.  I read CRAN rules require a yes/no from the user to write a directory.  So, I need to write an on.load() function for both Bond Lab and the Companion.  Also, CRAN requires that a package works on at least two systems so I need to figure out the Windows build.  This leads to another question.
> 
> Can I somehow make a windows binary on a MAC?

Yes, you can use VirtualBox or some other VM or emulator to run Windows
on a Mac.  (Theoretically there are other ways that stay purely within
Mac OS, but they are not supported.)

> If not, can I emulate Windows on a MAC and make a binary?  Seems like this may not be 100%.
> Will I actually have to buy a windows machine to build the windows binary for CRAN?

You don't need to make a Windows binary at all, except for local
testing.  You only need to make the tarball, and CRAN will build the binary.

However, testing is important.  You should use
win-builder.r-project.org to build and test for Windows if you're doing
OS-specific things.

Duncan Murdoch

> 
> Glenn  
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ben.bighair at gmail.com  Sun May 17 15:14:35 2015
From: ben.bighair at gmail.com (Ben Tupper)
Date: Sun, 17 May 2015 09:14:35 -0400
Subject: [R] Comparing 2 different files in R
In-Reply-To: <CAA3AKSfTWBT6iEVvv6cpw661jgREHi2TZUdmbzdUhkzUXJwsGA@mail.gmail.com>
References: <CAA3AKSdx3cHFoqBn5Pxf3Af=DW82vZE-VCFuR9++_dnz9gxVdA@mail.gmail.com>
	<E63DBF94A52.00000534jrkrideau@inbox.com>
	<CAA3AKSfTWBT6iEVvv6cpw661jgREHi2TZUdmbzdUhkzUXJwsGA@mail.gmail.com>
Message-ID: <752C3AED-083B-4080-BC3C-03537C2EAC97@gmail.com>

Hi,

On May 17, 2015, at 6:56 AM, Lyle Warren <lyle00 at gmail.com> wrote:

> Thanks and sorry for being light on detail.
> 
> I have multiple files of raw human genome SNP data. Very large - the
> compressed zip files are about 8mb large.
> 

You'll have better luck asking on the Bioconductor help list ( http://www.bioconductor.org/ ) You may want to start here...

http://www.bioconductor.org/help/support/posting-guide/

and here...

http://www.bioconductor.org/help/search/index.html?q=SNP


Cheers,
Ben




> On 17 May 2015 at 20:53, John Kane <jrkrideau at inbox.com> wrote:
> 
>> Probably but since you  have not told us anything about what you are doing
>> it is difficult to say.
>> 
>> You might find these links helpful
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> and http://adv-r.had.co.nz/Reproducibility.html
>> 
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: lyle00 at gmail.com
>>> Sent: Sun, 17 May 2015 08:32:45 +1000
>>> To: r-help at r-project.org
>>> Subject: [R] Comparing 2 different files in R
>>> 
>>> Hi,
>>> 
>>> I have multiple files that I want to compare in R. They contain SNP data
>>> with genotype in the 4th column, which is what I want to compare.
>>> 
>>> Is there any easy way to do this?
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ____________________________________________________________
>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
>> your desktop!
>> Check it out at http://www.inbox.com/marineaquarium
>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Eli.Ateljevich at water.ca.gov  Sun May 17 10:18:29 2015
From: Eli.Ateljevich at water.ca.gov (Ateljevich, Eli@DWR)
Date: Sun, 17 May 2015 08:18:29 +0000
Subject: [R] Multichannel reconstruction in Rssa
Message-ID: <73F8F665C0FCF549AF963069AB8CB27F700D91@057-SN2MPN1-041.057d.mgd.msft.net>

Hi. I have been trying to use the Rssa singular spectrum analysis library on a dataset of 15 minute data at four (cohesive) water temperature stations in an estuary. The stations have different missing data patterns, though I can find a period of 2 years where all four are mostly present. There are two major periodicities (annual and diurnal), and I am using L=N/2. The only calls I am making are to ssa, plot() to examine wcor and create the groups (total of 6) and then reconstruct().

The ssa() command with kind="mssa" seems to function to completion. However each component (e.g. F1, F2) in the reconstruction has the expected dimension but only one column with non-missing values. The others are NA for every time point in the column.

The EuStockMarkets mssa example in the documentation works fine for me. When I pepper it with missing data I get missing data in the reconstruction in those elements in the data array that were missing in the original data, not entire columns or any expansion. It seems like my data is causing a big expansion of missing data. Is there something else I should be doing? For instance should I be interpolating very small gaps? Why is the first column seemingly always healthy or is that just a coincidence?

Thanks.



	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun May 17 18:52:52 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 17 May 2015 09:52:52 -0700
Subject: [R] Help manipulating 23andme data in R - reproducing
	relationship	results
In-Reply-To: <CAA3AKSfNk2aNmaue6vRhVj_ox+0eF6yD6op8s1GVT-41T5hY8w@mail.gmail.com>
References: <CAA3AKSfNk2aNmaue6vRhVj_ox+0eF6yD6op8s1GVT-41T5hY8w@mail.gmail.com>
Message-ID: <1BA10E19-9E11-4825-A709-4C494CB0D148@dcn.davis.CA.us>

This is a very domain-specific question (genetic data analysis), not so much a question about how to use R, so does not seem on topic here. I also suspect that the company 23andme may use some proprietary algorithms, so "replicating their results" could be a tall order. 

You might start with the CRAN "Statistical Genetics" task view, and a textbook on the subject. The Bioconductor project may also be a useful resource. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 16, 2015 6:53:46 AM PDT, Lyle Warren <lyle00 at gmail.com> wrote:
>Hi,
>
>I'm trying to replicate 23andMe's parentage test results within R,
>using
>the 23andme raw data. Does anyone know a simple way to do this? I have
>read
>the data with gwascat and it seems to be in there fine.
>
>Thanks for any help you can give!
>
>Cheers,
>
>Lyle
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From yonas at wku.edu.et  Sun May 17 16:31:08 2015
From: yonas at wku.edu.et (Yonas Yohannes)
Date: Sun, 17 May 2015 17:31:08 +0300
Subject: [R] Error in dimnames(phi) <- list(rn,
 dims) : length of 'dimnames' [2] not equal to array extent
Message-ID: <CANL1GdJG9tYj+mOP7sHaK-9R5vRXCjJ=1vwXz9VrdgF=Bk_Yqg@mail.gmail.com>

Dears,
I have presence and absence data set (8 rows and 33 columns) and when I
want to get out of the default two dimensions command using summary(ca(mydata,
nd=3)) the following error message displyed:

Error in dimnames(phi) <- list(rn, dims) :
  length of 'dimnames' [2] not equal to array extent

Please help! So many thanks in advance!
Kindly,
* <mail%3Ayonas at wku.edu.et>*

	[[alternative HTML version deleted]]


From angela.radulescu at gmail.com  Sun May 17 18:05:27 2015
From: angela.radulescu at gmail.com (Angela Radulescu)
Date: Sun, 17 May 2015 12:05:27 -0400
Subject: [R] Two Different Interaction Terms for Mixed Factorial ANOVA in R?
Message-ID: <CA+1mWgLYizXG4Z+CZjKCJz7fThZnQ3-r=4=J-7uBLy5UNjHoFA@mail.gmail.com>

I have the following R output from a mixed factorial ANOVA:

Error: subj
                 Df Sum Sq Mean Sq F value  Pr(>F)   group
1   11.3   11.26   0.449 0.50811
singleType        1    0.7    0.66   0.026 0.87220   group:singleType
1  237.5  237.53   9.484 0.00461 **Residuals        28  701.3   25.04
                 ---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
?.? 0.1 ? ? 1
Error: subj:singleType
                 Df Sum Sq Mean Sq F value Pr(>F)
singleType        1 1566.4  1566.4 411.445 <2e-16 ***group:singleType
1    3.4     3.4   0.893  0.352    Residuals        30  114.2     3.8
                 ---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
?.? 0.1 ? ? 1
Error: Within
            Df Sum Sq Mean Sq F value Pr(>F)Residuals 3286   5747   1.749

Here "group" is the between factor (2 levels) and "singleType" the within
factor (2 levels). I'm not sure why there are two group:singleType
interaction terms. Any help would be much appreciated!

For reference, here is the original aov call:

anova.p = aov(data = dat.colSingle, rt ~ (group*singleType) +
Error(subj/singleType))
summary(anova.p)

Thank you!

-- 
Angela Radulescu

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sun May 17 19:04:33 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 17 May 2015 10:04:33 -0700
Subject: [R] Help manipulating 23andme data in R - reproducing
 relationship results
In-Reply-To: <1BA10E19-9E11-4825-A709-4C494CB0D148@dcn.davis.CA.us>
References: <CAA3AKSfNk2aNmaue6vRhVj_ox+0eF6yD6op8s1GVT-41T5hY8w@mail.gmail.com>
	<1BA10E19-9E11-4825-A709-4C494CB0D148@dcn.davis.CA.us>
Message-ID: <CACk-te36n2WWQxAkZ0K+7Zc6hz-1T-Pirw_=tG2VC+dHrFLrhg@mail.gmail.com>

(No response necessary)

What struck me about this post was the apparent mismatch: the OP
seemed not to have a clue where to begin. Maybe he somehow has been
assigned or chose a task for which his skills and background are
inadequate. This is not really a criticism: if someone told me to make
a dining room set, my reply would be: "Either find someone else or see
you in about a year after which I may have learned enough to attempt
the task. "

So maybe the OP should give up looking for internet advice altogether
and find someone local to work with?

And, of course, apologies if I have misinterpreted.

Cheers,
Bert



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, May 17, 2015 at 9:52 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> This is a very domain-specific question (genetic data analysis), not so much a question about how to use R, so does not seem on topic here. I also suspect that the company 23andme may use some proprietary algorithms, so "replicating their results" could be a tall order.
>
> You might start with the CRAN "Statistical Genetics" task view, and a textbook on the subject. The Bioconductor project may also be a useful resource.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On May 16, 2015 6:53:46 AM PDT, Lyle Warren <lyle00 at gmail.com> wrote:
>>Hi,
>>
>>I'm trying to replicate 23andMe's parentage test results within R,
>>using
>>the 23andme raw data. Does anyone know a simple way to do this? I have
>>read
>>the data with gwascat and it seems to be in there fine.
>>
>>Thanks for any help you can give!
>>
>>Cheers,
>>
>>Lyle
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Sun May 17 19:17:32 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sun, 17 May 2015 13:17:32 -0400
Subject: [R] Two Different Interaction Terms for Mixed Factorial ANOVA
	in R?
In-Reply-To: <CA+1mWgLYizXG4Z+CZjKCJz7fThZnQ3-r=4=J-7uBLy5UNjHoFA@mail.gmail.com>
References: <CA+1mWgLYizXG4Z+CZjKCJz7fThZnQ3-r=4=J-7uBLy5UNjHoFA@mail.gmail.com>
Message-ID: <CAGx1TMBsPm5=wZF9czYYR_niTDjE6czy57SFZVaDmedB7NAm4Q@mail.gmail.com>

Angela,

My guess is that your data are not balanced.
That could be due to a typo in one of the factors, or it could be that
you actually have different numbers of observations at some of the
factor levels.

Rich

On Sun, May 17, 2015 at 12:05 PM, Angela Radulescu
<angela.radulescu at gmail.com> wrote:
> I have the following R output from a mixed factorial ANOVA:
>
> Error: subj
>                  Df Sum Sq Mean Sq F value  Pr(>F)   group
> 1   11.3   11.26   0.449 0.50811
> singleType        1    0.7    0.66   0.026 0.87220   group:singleType
> 1  237.5  237.53   9.484 0.00461 **Residuals        28  701.3   25.04
>                  ---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
> ?.? 0.1 ? ? 1
> Error: subj:singleType
>                  Df Sum Sq Mean Sq F value Pr(>F)
> singleType        1 1566.4  1566.4 411.445 <2e-16 ***group:singleType
> 1    3.4     3.4   0.893  0.352    Residuals        30  114.2     3.8
>                  ---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05
> ?.? 0.1 ? ? 1
> Error: Within
>             Df Sum Sq Mean Sq F value Pr(>F)Residuals 3286   5747   1.749
>
> Here "group" is the between factor (2 levels) and "singleType" the within
> factor (2 levels). I'm not sure why there are two group:singleType
> interaction terms. Any help would be much appreciated!
>
> For reference, here is the original aov call:
>
> anova.p = aov(data = dat.colSingle, rt ~ (group*singleType) +
> Error(subj/singleType))
> summary(anova.p)
>
> Thank you!
>
> --
> Angela Radulescu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sun May 17 19:22:24 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 17 May 2015 10:22:24 -0700
Subject: [R] Error in dimnames(phi) <- list(rn,
	dims) : length of 'dimnames' [2] not equal to array extent
In-Reply-To: <CANL1GdJG9tYj+mOP7sHaK-9R5vRXCjJ=1vwXz9VrdgF=Bk_Yqg@mail.gmail.com>
References: <CANL1GdJG9tYj+mOP7sHaK-9R5vRXCjJ=1vwXz9VrdgF=Bk_Yqg@mail.gmail.com>
Message-ID: <1D06E853-648E-475A-B122-2DEF4EE0BD2E@dcn.davis.CA.us>

You desperately need to study [1] and the Posting Guide mentioned at the bottom of this and every other message on this list.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 17, 2015 7:31:08 AM PDT, Yonas Yohannes <yonas at wku.edu.et> wrote:
>Dears,
>I have presence and absence data set (8 rows and 33 columns) and when I
>want to get out of the default two dimensions command using
>summary(ca(mydata,
>nd=3)) the following error message displyed:
>
>Error in dimnames(phi) <- list(rn, dims) :
>  length of 'dimnames' [2] not equal to array extent
>
>Please help! So many thanks in advance!
>Kindly,
>* <mail%3Ayonas at wku.edu.et>*
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jefdaj at berkeley.edu  Sun May 17 19:42:58 2015
From: jefdaj at berkeley.edu (Jeffrey David Johnson)
Date: Sun, 17 May 2015 10:42:58 -0700
Subject: [R] smooth.spline error while fitting bacterial growth curves with
 grofit
Message-ID: <20150517104258.d3426223f798909fd2b173b8@berkeley.edu>

I'm trying to use the grofit package to compare growth rates between
bacterial cultures, but I've come across a couple glitches/things I
don't understand. I'm not sure if they're related to the package or to a
problem with my growth data, which is messy. Some strains don't follow
a proper logarithmic growth curve because they died or didn't grow over
the course of the experiment. I could remove those but it will get more
time consuming once I have more cultures going.

I've attached the 'time' matrix and 'data' data frame. This code should
fit the growth curves, but when I run it I get an error related to
`smooth.spline`:

require(grofit)
mytime <- as.matrix(read.table('time.txt'))
mydata <- read.csv('data.csv')
dimnames(mytime) <- NULL
fits <- gcFit(mytime, mydata, grofit.control(
  interactive=FALSE, # don't ask if the graphs look OK
  nboot.gc=1000,     # number of bootstraps
  fit.opt="s"        # just do splines, no models
))

= 1. growth curve =================================
----------------------------------------------------
= 2. growth curve =================================
----------------------------------------------------
= 3. growth curve =================================
----------------------------------------------------
Error in smooth.spline(time, data, spar = control$smooth.gc) : 
  'tol' must be strictly positive and finite
Error in gcFitSpline(time.cur, data.cur, gcID, control.change) : 
  object 'y.spl' not found

That error usually occurs at some point, though I've run through all 17
successfully a couple times. The documentation says:

> smooth.gc: Parameter describing the smoothness of the spline fit;
> usually (not necessary) in (0;1]. Set ?smooth.gc=NULL? causes the
> program to query an optimal value via cross validation techniques.
> Note: This is partly experimental. In future improved implementations
> of the ?smooth.spline? function may lead to different results. See
> documentation of the R function ?smooth.spline? for further details.
> Especially for datasets with few data points the option ?NULL? might
> result in a too small smoothing parameter, which produces an error in
> ?smooth.spline?. In that case the usage of a fixed value is
> recommended. Default: ?NULL?.

I tried setting different values (0.1, 0.5, 0.9, 1, 10) and they all
cause the same error. If instead I use the `gcBootSpline` function
directly, it gives a different error about the number of bootstraps
being 0, when they clearly aren't:

fits <- gcBootSpline(mytime, mydata, grofit.control(nboot.gc=1000))

Error in gcBootSpline(mytime, mydata, grofit.control(nboot.gc =
1000)) : Number of bootstrap samples is zero! See grofit.control()

Am I using these right? Is there something about the data that would
make it un-fittable?
Jeff

From gunter.berton at gene.com  Sun May 17 20:42:27 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 17 May 2015 11:42:27 -0700
Subject: [R] smooth.spline error while fitting bacterial growth curves
 with grofit
In-Reply-To: <20150517104258.d3426223f798909fd2b173b8@berkeley.edu>
References: <20150517104258.d3426223f798909fd2b173b8@berkeley.edu>
Message-ID: <CACk-te23_=vbGq-tv9x=2Kkp0HUSfebuR=FL6Cuqa7C7xGktMw@mail.gmail.com>

1. Very likely, you have insufficient data in some of your growth
curves to do the fits using gcv. If  you remove the curves where the
bacteria didn't grow, things should work. Alternatively, there may
well be ways of expressing the model that would allow pooling across
cultures that didn't grow. (Sounds like a mixtures problem, actually:
you are mixing cultures that grow  with those that don't and need to
determine the mixing proportion and the growth parameters of those
that grew).

2. HOWEVER, IF you remove the curves, you may very well be getting the
wrong (biased) results -- i.e. your results will be irreproducible
garbage, as you will only be taking data from cultures that grew well.
I would **strongly** suggest you work with a local statistical expert
to help you deal with these issues. I do not think you should trust
remote advice from the internet on such complex data (including mine!)

Cheers,
Bert


Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, May 17, 2015 at 10:42 AM, Jeffrey David Johnson
<jefdaj at berkeley.edu> wrote:
> I'm trying to use the grofit package to compare growth rates between
> bacterial cultures, but I've come across a couple glitches/things I
> don't understand. I'm not sure if they're related to the package or to a
> problem with my growth data, which is messy. Some strains don't follow
> a proper logarithmic growth curve because they died or didn't grow over
> the course of the experiment. I could remove those but it will get more
> time consuming once I have more cultures going.
>
> I've attached the 'time' matrix and 'data' data frame. This code should
> fit the growth curves, but when I run it I get an error related to
> `smooth.spline`:
>
> require(grofit)
> mytime <- as.matrix(read.table('time.txt'))
> mydata <- read.csv('data.csv')
> dimnames(mytime) <- NULL
> fits <- gcFit(mytime, mydata, grofit.control(
>   interactive=FALSE, # don't ask if the graphs look OK
>   nboot.gc=1000,     # number of bootstraps
>   fit.opt="s"        # just do splines, no models
> ))
>
> = 1. growth curve =================================
> ----------------------------------------------------
> = 2. growth curve =================================
> ----------------------------------------------------
> = 3. growth curve =================================
> ----------------------------------------------------
> Error in smooth.spline(time, data, spar = control$smooth.gc) :
>   'tol' must be strictly positive and finite
> Error in gcFitSpline(time.cur, data.cur, gcID, control.change) :
>   object 'y.spl' not found
>
> That error usually occurs at some point, though I've run through all 17
> successfully a couple times. The documentation says:
>
>> smooth.gc: Parameter describing the smoothness of the spline fit;
>> usually (not necessary) in (0;1]. Set ?smooth.gc=NULL? causes the
>> program to query an optimal value via cross validation techniques.
>> Note: This is partly experimental. In future improved implementations
>> of the ?smooth.spline? function may lead to different results. See
>> documentation of the R function ?smooth.spline? for further details.
>> Especially for datasets with few data points the option ?NULL? might
>> result in a too small smoothing parameter, which produces an error in
>> ?smooth.spline?. In that case the usage of a fixed value is
>> recommended. Default: ?NULL?.
>
> I tried setting different values (0.1, 0.5, 0.9, 1, 10) and they all
> cause the same error. If instead I use the `gcBootSpline` function
> directly, it gives a different error about the number of bootstraps
> being 0, when they clearly aren't:
>
> fits <- gcBootSpline(mytime, mydata, grofit.control(nboot.gc=1000))
>
> Error in gcBootSpline(mytime, mydata, grofit.control(nboot.gc =
> 1000)) : Number of bootstrap samples is zero! See grofit.control()
>
> Am I using these right? Is there something about the data that would
> make it un-fittable?
> Jeff
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kristi.glover at hotmail.com  Sun May 17 22:06:25 2015
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Sun, 17 May 2015 14:06:25 -0600
Subject: [R] variable selections to avoid multicollinearity
Message-ID: <COL130-W812690160EA2796CFFCCA7FAC50@phx.gbl>

HI R user, 
I was trying to reduce my independent variables before I run models. I have a dependent variable as a present or TRUE only (no Absence or False) whereas I have more than 20 independent variables but they are highly correlated. I was trying to reduce the independent variables . I found  PCA for feature  selection are used. 
but for the PCA feature selection, I realized that it used dependent variable (as a linear model) with independent variables to select the variables based on variation explained. But, for me , the dependent data are only "1". Therefore, I could not run it. 

would you give me some suggestions on how I reduce the variables into a certain numbers ? I have attached a sample data. In this data set, the dependent variable is "sp" and other 20 variables are the independent variables

dat<-structure(list(sp = c(1L, 1L, 1L, 1L, 1L), var1 = c(32L, 222L, 
134L, 114L, 121L), var2 = c(188L, 175L, 167L, 166L, 167L), var3 = c(123L, 
129L, 136L, 138L, 137L), var4 = c(40L, 35L, 37L, 38L, 37L), var5 = c(6756L, 
8080L, 7856L, 7899L, 7891L), var6 = c(334L, 352L, 341L, 340L, 
341L), var7 = c(29L, -9L, -18L, -22L, -20L), var8 = c(305L, 361L, 
359L, 362L, 361L), var9 = c(108L, 217L, 167L, 166L, 166L), var10 = c(237L, 
67L, 61L, 59L, 60L), var11 = c(270L, 276L, 265L, 264L, 264L), 
    var12 = c(97L, 67L, 61L, 59L, 60L), var13 = c(1491L, 916L, 
    1245L, 1282L, 1250L), var14 = c(168L, 127L, 154L, 155L, 154L
    ), var15 = c(99L, 43L, 67L, 70L, 68L), var16 = c(15L, 32L, 
    22L, 21L, 21L), var17 = c(432L, 313L, 390L, 400L, 392L), 
    var18 = c(308L, 148L, 254L, 269L, 257L), var19 = c(332L, 
    213L, 269L, 277L, 271L), var20 = c(430L, 148L, 254L, 269L, 
    257L)), .Names = c("sp", "var1", "var2", "var3", "var4", 
"var5", "var6", "var7", "var8", "var9", "var10", "var11", "var12", 
"var13", "var14", "var15", "var16", "var17", "var18", "var19", 
"var20"), class = "data.frame", row.names = c(NA, -5L))

thanks 

 		 	   		  
	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Sun May 17 20:51:38 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Sun, 17 May 2015 18:51:38 +0000
Subject: [R] using filter() to sum up
In-Reply-To: <3B6A60F0-7CB7-4ECF-A675-CEC6FF0962CC@gmail.com>
References: <AEB16B1613D44C4793A7E6B6986B7A12F536F21C@EX10-LIVE-MBN2.ad.kent.ac.uk>
	<3B6A60F0-7CB7-4ECF-A675-CEC6FF0962CC@gmail.com>
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A12F5378473@EX10-LIVE-MBN1.ad.kent.ac.uk>

Hi,
I tried the formula

sum(psi*X[(t-1):(t-K)])

but it provides the vector of all observations. Thus, I changed K to k where 

K<-3 and k<-1:K

This yields better results but not what I want since I should get 3 values as K=3.

> X[(t-1):(t-k)]
[1] 0.1
Warning message:
In (t - 1):(t - k) :
  numerical expression has 3 elements: only the first used

Why do I get this error message and how can I avoid it??

Thanks in advance


-----Original Message-----
From: peter dalgaard [mailto:pdalgd at gmail.com] 
Sent: 05 May 2015 11:41
To: T.Riedle
Cc: r-help at r-project.org
Subject: Re: [R] using filter() to sum up


On 04 May 2015, at 21:38 , T.Riedle <tr206 at kent.ac.uk> wrote:

> Hi everybody,
> 
> I am trying to create a code for the formula in the attachment. I first tried following code:
> 
> ltau <- m + theta*sum(psi*X[t-k])
> 

That's not going to work. It might work with something like

sum(psi*X[(t-1):(t-K)])


> but it does not work and I get for X[t-k] every third element in my vector three times which looks as follows:
> X[t-k]
> [1] -0.25 -0.25 -0.25 0.50 0.50 0.50 -0.44 -0.44 -0.44 0.15 0.15 0.15
> 
> Thus, I tried the filter() function in R which looks as follows:
> ltau <- m + theta* filter(f.USA$UTS, phi(K, omega1, omega2), sides=1, 
> method="conv")
> 
> Reading the description of this function I am unsure whether this provides the sum of the k lags. The appreviation "conv" provides, as far as I understand, the moving average instead of the sum.

I would assume that it means convolution. Which is what you have in the formula.

> Does anybody have an idea how the R code for the formula attached must look like? Is the filter() function appropriate?

It's barking up the right tree, but do your own checks...

-pd


> Thanks in advance.
> <tau.png>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com









-------------- next part --------------
A non-text attachment was scrubbed...
Name: tau.png
Type: image/png
Size: 8142 bytes
Desc: tau.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150517/d2ecc266/attachment.png>

From lyle00 at gmail.com  Sun May 17 22:52:32 2015
From: lyle00 at gmail.com (Lyle Warren)
Date: Mon, 18 May 2015 06:52:32 +1000
Subject: [R] Help manipulating 23andme data in R - reproducing
 relationship results
In-Reply-To: <CACk-te36n2WWQxAkZ0K+7Zc6hz-1T-Pirw_=tG2VC+dHrFLrhg@mail.gmail.com>
References: <CAA3AKSfNk2aNmaue6vRhVj_ox+0eF6yD6op8s1GVT-41T5hY8w@mail.gmail.com>
	<1BA10E19-9E11-4825-A709-4C494CB0D148@dcn.davis.CA.us>
	<CACk-te36n2WWQxAkZ0K+7Zc6hz-1T-Pirw_=tG2VC+dHrFLrhg@mail.gmail.com>
Message-ID: <CAA3AKSe6u1WMKkaT3JS3UYfx-7T3q1b06ZM7imnDconRppqc3Q@mail.gmail.com>

Thanks Jeff, Bert!

You are right - definitely out of my skill area.. I've no found some help
on the bioconductor mailing list.

On 18 May 2015 at 03:04, Bert Gunter <gunter.berton at gene.com> wrote:

> (No response necessary)
>
> What struck me about this post was the apparent mismatch: the OP
> seemed not to have a clue where to begin. Maybe he somehow has been
> assigned or chose a task for which his skills and background are
> inadequate. This is not really a criticism: if someone told me to make
> a dining room set, my reply would be: "Either find someone else or see
> you in about a year after which I may have learned enough to attempt
> the task. "
>
> So maybe the OP should give up looking for internet advice altogether
> and find someone local to work with?
>
> And, of course, apologies if I have misinterpreted.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Sun, May 17, 2015 at 9:52 AM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
> > This is a very domain-specific question (genetic data analysis), not so
> much a question about how to use R, so does not seem on topic here. I also
> suspect that the company 23andme may use some proprietary algorithms, so
> "replicating their results" could be a tall order.
> >
> > You might start with the CRAN "Statistical Genetics" task view, and a
> textbook on the subject. The Bioconductor project may also be a useful
> resource.
> >
> ---------------------------------------------------------------------------
> > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
> >                                       Live:   OO#.. Dead: OO#..  Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> >
> ---------------------------------------------------------------------------
> > Sent from my phone. Please excuse my brevity.
> >
> > On May 16, 2015 6:53:46 AM PDT, Lyle Warren <lyle00 at gmail.com> wrote:
> >>Hi,
> >>
> >>I'm trying to replicate 23andMe's parentage test results within R,
> >>using
> >>the 23andme raw data. Does anyone know a simple way to do this? I have
> >>read
> >>the data with gwascat and it seems to be in there fine.
> >>
> >>Thanks for any help you can give!
> >>
> >>Cheers,
> >>
> >>Lyle
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >>______________________________________________
> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide
> >>http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mtmorgan at fredhutch.org  Sun May 17 23:04:45 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Sun, 17 May 2015 14:04:45 -0700
Subject: [R] Help manipulating 23andme data in R - reproducing
 relationship results
In-Reply-To: <CAA3AKSe6u1WMKkaT3JS3UYfx-7T3q1b06ZM7imnDconRppqc3Q@mail.gmail.com>
References: <CAA3AKSfNk2aNmaue6vRhVj_ox+0eF6yD6op8s1GVT-41T5hY8w@mail.gmail.com>	<1BA10E19-9E11-4825-A709-4C494CB0D148@dcn.davis.CA.us>	<CACk-te36n2WWQxAkZ0K+7Zc6hz-1T-Pirw_=tG2VC+dHrFLrhg@mail.gmail.com>
	<CAA3AKSe6u1WMKkaT3JS3UYfx-7T3q1b06ZM7imnDconRppqc3Q@mail.gmail.com>
Message-ID: <5559026D.7000303@fredhutch.org>

On 05/17/2015 01:52 PM, Lyle Warren wrote:
> Thanks Jeff, Bert!
>
> You are right - definitely out of my skill area.. I've no found some help
> on the bioconductor mailing list.

I'm not sure that you've asked in the right place

   https://support.bioconductor.org

see also http://www.vincebuffalo.com/2012/03/12/23andme-gwascat.html which is a 
little dated and maybe not relevant to your question.

A little tangentially, see also https://support.bioconductor.org/p/67444/

Martin Morgan

>
> On 18 May 2015 at 03:04, Bert Gunter <gunter.berton at gene.com> wrote:
>
>> (No response necessary)
>>
>> What struck me about this post was the apparent mismatch: the OP
>> seemed not to have a clue where to begin. Maybe he somehow has been
>> assigned or chose a task for which his skills and background are
>> inadequate. This is not really a criticism: if someone told me to make
>> a dining room set, my reply would be: "Either find someone else or see
>> you in about a year after which I may have learned enough to attempt
>> the task. "
>>
>> So maybe the OP should give up looking for internet advice altogether
>> and find someone local to work with?
>>
>> And, of course, apologies if I have misinterpreted.
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Sun, May 17, 2015 at 9:52 AM, Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us> wrote:
>>> This is a very domain-specific question (genetic data analysis), not so
>> much a question about how to use R, so does not seem on topic here. I also
>> suspect that the company 23andme may use some proprietary algorithms, so
>> "replicating their results" could be a tall order.
>>>
>>> You might start with the CRAN "Statistical Genetics" task view, and a
>> textbook on the subject. The Bioconductor project may also be a useful
>> resource.
>>>
>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>>                                        Live:   OO#.. Dead: OO#..  Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>>
>> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On May 16, 2015 6:53:46 AM PDT, Lyle Warren <lyle00 at gmail.com> wrote:
>>>> Hi,
>>>>
>>>> I'm trying to replicate 23andMe's parentage test results within R,
>>>> using
>>>> the 23andme raw data. Does anyone know a simple way to do this? I have
>>>> read
>>>> the data with gwascat and it seems to be in there fine.
>>>>
>>>> Thanks for any help you can give!
>>>>
>>>> Cheers,
>>>>
>>>> Lyle
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From gunter.berton at gene.com  Mon May 18 01:16:02 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 17 May 2015 16:16:02 -0700
Subject: [R] variable selections to avoid multicollinearity
In-Reply-To: <COL130-W812690160EA2796CFFCCA7FAC50@phx.gbl>
References: <COL130-W812690160EA2796CFFCCA7FAC50@phx.gbl>
Message-ID: <CACk-te3s8a8YbB6-JAx02KGO6U-1wUKfgAh2HBEYjvWogn2x1w@mail.gmail.com>

OFFTOPIC! This is a statistical question, not an R question. Post on a
statistics site like stats.stackexchange.com  .

However, your post suggests that you are completely out of your depth
here (0/1 responses suggest that glm modeling via logistic regression
is called for). Remote internet advice is unlikely to fill the gap
between what you seem to need and what you seem to know. I strongly
suggest you find a local statistical expert to help if you wish to
avoid producing nonsense.

(Once you have figured out what you need to do, questions about how to
use R tools to do it are of course appropriate).

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, May 17, 2015 at 1:06 PM, Kristi Glover
<kristi.glover at hotmail.com> wrote:
> HI R user,
> I was trying to reduce my independent variables before I run models. I have a dependent variable as a present or TRUE only (no Absence or False) whereas I have more than 20 independent variables but they are highly correlated. I was trying to reduce the independent variables . I found  PCA for feature  selection are used.
> but for the PCA feature selection, I realized that it used dependent variable (as a linear model) with independent variables to select the variables based on variation explained. But, for me , the dependent data are only "1". Therefore, I could not run it.
>
> would you give me some suggestions on how I reduce the variables into a certain numbers ? I have attached a sample data. In this data set, the dependent variable is "sp" and other 20 variables are the independent variables
>
> dat<-structure(list(sp = c(1L, 1L, 1L, 1L, 1L), var1 = c(32L, 222L,
> 134L, 114L, 121L), var2 = c(188L, 175L, 167L, 166L, 167L), var3 = c(123L,
> 129L, 136L, 138L, 137L), var4 = c(40L, 35L, 37L, 38L, 37L), var5 = c(6756L,
> 8080L, 7856L, 7899L, 7891L), var6 = c(334L, 352L, 341L, 340L,
> 341L), var7 = c(29L, -9L, -18L, -22L, -20L), var8 = c(305L, 361L,
> 359L, 362L, 361L), var9 = c(108L, 217L, 167L, 166L, 166L), var10 = c(237L,
> 67L, 61L, 59L, 60L), var11 = c(270L, 276L, 265L, 264L, 264L),
>     var12 = c(97L, 67L, 61L, 59L, 60L), var13 = c(1491L, 916L,
>     1245L, 1282L, 1250L), var14 = c(168L, 127L, 154L, 155L, 154L
>     ), var15 = c(99L, 43L, 67L, 70L, 68L), var16 = c(15L, 32L,
>     22L, 21L, 21L), var17 = c(432L, 313L, 390L, 400L, 392L),
>     var18 = c(308L, 148L, 254L, 269L, 257L), var19 = c(332L,
>     213L, 269L, 277L, 271L), var20 = c(430L, 148L, 254L, 269L,
>     257L)), .Names = c("sp", "var1", "var2", "var3", "var4",
> "var5", "var6", "var7", "var8", "var9", "var10", "var11", "var12",
> "var13", "var14", "var15", "var16", "var17", "var18", "var19",
> "var20"), class = "data.frame", row.names = c(NA, -5L))
>
> thanks
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon May 18 02:30:41 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 18 May 2015 10:30:41 +1000
Subject: [R] Error in dimnames(phi) <- list(rn,
 dims) : length of 'dimnames' [2] not equal to array extent
In-Reply-To: <1D06E853-648E-475A-B122-2DEF4EE0BD2E@dcn.davis.CA.us>
References: <CANL1GdJG9tYj+mOP7sHaK-9R5vRXCjJ=1vwXz9VrdgF=Bk_Yqg@mail.gmail.com>
	<1D06E853-648E-475A-B122-2DEF4EE0BD2E@dcn.davis.CA.us>
Message-ID: <CA+8X3fU1DnRgzmX9PMhfDdPJc5BFwHNRnznoNQY54JFj9qrLCQ@mail.gmail.com>

Hi Yonas,
If this is the "ca" function from the package of the same name, it
looks to me as though your data set is only two dimensions and you are
requesting 3 dimensions in the output. Have you tried calling ca with
the default nd=NA?

Jim


On Mon, May 18, 2015 at 3:22 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> You desperately need to study [1] and the Posting Guide mentioned at the bottom of this and every other message on this list.
>
> [1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On May 17, 2015 7:31:08 AM PDT, Yonas Yohannes <yonas at wku.edu.et> wrote:
>>Dears,
>>I have presence and absence data set (8 rows and 33 columns) and when I
>>want to get out of the default two dimensions command using
>>summary(ca(mydata,
>>nd=3)) the following error message displyed:
>>
>>Error in dimnames(phi) <- list(rn, dims) :
>>  length of 'dimnames' [2] not equal to array extent
>>
>>Please help! So many thanks in advance!
>>Kindly,
>>* <mail%3Ayonas at wku.edu.et>*
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jefdaj at berkeley.edu  Mon May 18 04:08:23 2015
From: jefdaj at berkeley.edu (Jeffrey David Johnson)
Date: Sun, 17 May 2015 19:08:23 -0700
Subject: [R] smooth.spline error while fitting bacterial growth curves
 with grofit
In-Reply-To: <CACk-te23_=vbGq-tv9x=2Kkp0HUSfebuR=FL6Cuqa7C7xGktMw@mail.gmail.com>
References: <20150517104258.d3426223f798909fd2b173b8@berkeley.edu>
	<CACk-te23_=vbGq-tv9x=2Kkp0HUSfebuR=FL6Cuqa7C7xGktMw@mail.gmail.com>
Message-ID: <20150517190823.14e3b46dda16183be2641fd9@berkeley.edu>

Thanks, I think you're right. I removed the strains whose final OD was
below 0.2 since all the ones that clearly grew are above that, and
grofit produces fewer errors on the remaining 6. The error still happens
occasionally, but if I stick to 1000 bootstraps instead of 10000 it's
not often. Of course I won't rely on these numbers! I'll try again once
my current timecourse is done with 6 replicates per strain, and if
everything is still messy rethink the experimental design.

... Which brings up another question. Would it be better to estimate
growth parameters (mu, lambda, etc.) for each replicate and then take
the mean and standard deviation of those, or to average the growth data
first and calculate one set of parameters per strain? (Sorry if that's
very basic statistics)
Jeff

On Sun, 17 May 2015 11:42:27 -0700
Bert Gunter <gunter.berton at gene.com> wrote:

> 1. Very likely, you have insufficient data in some of your growth
> curves to do the fits using gcv. If  you remove the curves where the
> bacteria didn't grow, things should work. Alternatively, there may
> well be ways of expressing the model that would allow pooling across
> cultures that didn't grow. (Sounds like a mixtures problem, actually:
> you are mixing cultures that grow  with those that don't and need to
> determine the mixing proportion and the growth parameters of those
> that grew).
> 
> 2. HOWEVER, IF you remove the curves, you may very well be getting the
> wrong (biased) results -- i.e. your results will be irreproducible
> garbage, as you will only be taking data from cultures that grew well.
> I would **strongly** suggest you work with a local statistical expert
> to help you deal with these issues. I do not think you should trust
> remote advice from the internet on such complex data (including mine!)
> 
> Cheers,
> Bert
> 
> 
> Cheers,
> Bert
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
> 
> 
> 
> 
> On Sun, May 17, 2015 at 10:42 AM, Jeffrey David Johnson
> <jefdaj at berkeley.edu> wrote:
> > I'm trying to use the grofit package to compare growth rates between
> > bacterial cultures, but I've come across a couple glitches/things I
> > don't understand. I'm not sure if they're related to the package or to a
> > problem with my growth data, which is messy. Some strains don't follow
> > a proper logarithmic growth curve because they died or didn't grow over
> > the course of the experiment. I could remove those but it will get more
> > time consuming once I have more cultures going.
> >
> > I've attached the 'time' matrix and 'data' data frame. This code should
> > fit the growth curves, but when I run it I get an error related to
> > `smooth.spline`:
> >
> > require(grofit)
> > mytime <- as.matrix(read.table('time.txt'))
> > mydata <- read.csv('data.csv')
> > dimnames(mytime) <- NULL
> > fits <- gcFit(mytime, mydata, grofit.control(
> >   interactive=FALSE, # don't ask if the graphs look OK
> >   nboot.gc=1000,     # number of bootstraps
> >   fit.opt="s"        # just do splines, no models
> > ))
> >
> > = 1. growth curve =================================
> > ----------------------------------------------------
> > = 2. growth curve =================================
> > ----------------------------------------------------
> > = 3. growth curve =================================
> > ----------------------------------------------------
> > Error in smooth.spline(time, data, spar = control$smooth.gc) :
> >   'tol' must be strictly positive and finite
> > Error in gcFitSpline(time.cur, data.cur, gcID, control.change) :
> >   object 'y.spl' not found
> >
> > That error usually occurs at some point, though I've run through all 17
> > successfully a couple times. The documentation says:
> >
> >> smooth.gc: Parameter describing the smoothness of the spline fit;
> >> usually (not necessary) in (0;1]. Set ?smooth.gc=NULL? causes the
> >> program to query an optimal value via cross validation techniques.
> >> Note: This is partly experimental. In future improved implementations
> >> of the ?smooth.spline? function may lead to different results. See
> >> documentation of the R function ?smooth.spline? for further details.
> >> Especially for datasets with few data points the option ?NULL? might
> >> result in a too small smoothing parameter, which produces an error in
> >> ?smooth.spline?. In that case the usage of a fixed value is
> >> recommended. Default: ?NULL?.
> >
> > I tried setting different values (0.1, 0.5, 0.9, 1, 10) and they all
> > cause the same error. If instead I use the `gcBootSpline` function
> > directly, it gives a different error about the number of bootstraps
> > being 0, when they clearly aren't:
> >
> > fits <- gcBootSpline(mytime, mydata, grofit.control(nboot.gc=1000))
> >
> > Error in gcBootSpline(mytime, mydata, grofit.control(nboot.gc =
> > 1000)) : Number of bootstrap samples is zero! See grofit.control()
> >
> > Am I using these right? Is there something about the data that would
> > make it un-fittable?
> > Jeff
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From pnsinha68 at gmail.com  Mon May 18 09:14:37 2015
From: pnsinha68 at gmail.com (Partha Sinha)
Date: Mon, 18 May 2015 12:44:37 +0530
Subject: [R] Selective package installation
Message-ID: <CADcgpJey-r8adNBcH0ACDDZg64YXJ6oRfg7CTkS5uHeKpYoAYw@mail.gmail.com>

I am using Win 7, 32 bit and R 3.2.0

I want to install few packages via script.
The script should first check if the package is already installed (I
dont want update).If the package is already there , then it would go
to the next package in my list.
How can I do this ?
Parth


From pd.mes at cbs.dk  Mon May 18 09:30:11 2015
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Mon, 18 May 2015 09:30:11 +0200
Subject: [R] Release of R 3.2.1 scheduled for June 18
Message-ID: <127E408C-FBBE-41D1-B6D6-2D53B8D8B208@cbs.dk>

We intend to have a patch release on June 18, nickname will be "World-Famous Astronaut". The detailed schedule will be made available via developer.r-project.org as usual.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From ripley at stats.ox.ac.uk  Mon May 18 10:33:37 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 18 May 2015 09:33:37 +0100
Subject: [R] Selective package installation
In-Reply-To: <CADcgpJey-r8adNBcH0ACDDZg64YXJ6oRfg7CTkS5uHeKpYoAYw@mail.gmail.com>
References: <CADcgpJey-r8adNBcH0ACDDZg64YXJ6oRfg7CTkS5uHeKpYoAYw@mail.gmail.com>
Message-ID: <5559A3E1.2050803@stats.ox.ac.uk>

On 18/05/2015 08:14, Partha Sinha wrote:
> I am using Win 7, 32 bit and R 3.2.0
>
> I want to install few packages via script.
> The script should first check if the package is already installed (I
> dont want update).If the package is already there , then it would go
> to the next package in my list.
> How can I do this ?

Take a look at the code of the built-in function new.packages(): what 
you ask for is a variant on what it does.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From stefano.sofia at regione.marche.it  Mon May 18 12:49:16 2015
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Mon, 18 May 2015 10:49:16 +0000
Subject: [R] create a vector from several data frames
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68BFBB@mb02.ads.tamu.edu>
References: <8B435C9568170B469AE31E8891E8CC4F2804F785@ESINO.regionemarche.intra>,
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D68BFBB@mb02.ads.tamu.edu>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F2804FBD2@ESINO.regionemarche.intra>

Thank you David.
It is exactly what I was looking for and it works pefectly.

Stefano
________________________________________
Da: David L Carlson [dcarlson at tamu.edu]
Inviato: gioved? 14 maggio 2015 17.18
A: Stefano Sofia; r-help at r-project.org
Oggetto: RE: create a vector from several data frames

If you combine all of the df's into a list, e.g.

dfn <- paste0("df", 1:20)
df <- lapply(dfn, get)
names(df) <- dfn

and if "target" is the day you want in the same date/time format as the day variable in the data frames:

sapply(df, function(x) x[x$day==target, "tmax"])

will return a named vector of the tmax values.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Stefano Sofia
Sent: Thursday, May 14, 2015 9:23 AM
To: r-help at r-project.org
Subject: [R] create a vector from several data frames

Dear r-users,
suppose that I have 20 data frames df1, df2, ..., df20 (one for each different location) with the same column names and column types (the first column contains a date, the others are numeric) like

day tmax tmin
2015-05-10 20 10
2015-05-11 21 12
2015-05-12 17 9
2015-05-13 24 13
2015-05-14 25 18

I need to create a vector "tmax_all" of length 20 with the tmax referred to a particular day (let's say 2015-05-14).
I would first build a new data frame

tmax_df <- Reduce(function(x, y) merge(x, y, by="day"), list(df1[ , c("day", "tmax")], df2[ , c("day", "tmax")], ..., df20[ , c("day", "tmax")]))

and then select the row of tmax_df where day is the day I want to.
Is there an easiest way? Is it possible to create straightforward this vector without passing through the merge of all the data frames?

Thank you for your help
Stefano

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.


From dcarlson at tamu.edu  Mon May 18 16:27:49 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 18 May 2015 14:27:49 +0000
Subject: [R] Error in dimnames(phi) <- list(rn,
 dims) : length of 'dimnames' [2] not equal to array extent
In-Reply-To: <CA+8X3fU1DnRgzmX9PMhfDdPJc5BFwHNRnznoNQY54JFj9qrLCQ@mail.gmail.com>
References: <CANL1GdJG9tYj+mOP7sHaK-9R5vRXCjJ=1vwXz9VrdgF=Bk_Yqg@mail.gmail.com>
	<1D06E853-648E-475A-B122-2DEF4EE0BD2E@dcn.davis.CA.us>
	<CA+8X3fU1DnRgzmX9PMhfDdPJc5BFwHNRnznoNQY54JFj9qrLCQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68CBDC@mb02.ads.tamu.edu>

I think this is a bug in the current version of ca() in package ca. I am copying the package maintainer with this example:

# Reproducible example from manual page for ca():

> library(ca)
> data("author")
> author.ca <- ca(author) # No problem
> author.ca <- ca(author, nd=3)
Error in dimnames(phi) <- list(rn, dims) : 
  length of 'dimnames' [2] not equal to array extent
> library(MASS)
> author.ca <- corresp(author, nf=3) # No problem

So the MASS version of correspondence analysis, corresp(), is able to extract three dimensions (actually up to 11) from "author". I am certain I have used ca() in the past and extracted more than two dimensions from similar tables. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Sunday, May 17, 2015 7:31 PM
Cc: r-help mailing list
Subject: Re: [R] Error in dimnames(phi) <- list(rn, dims) : length of 'dimnames' [2] not equal to array extent

Hi Yonas,
If this is the "ca" function from the package of the same name, it
looks to me as though your data set is only two dimensions and you are
requesting 3 dimensions in the output. Have you tried calling ca with
the default nd=NA?

Jim


On Mon, May 18, 2015 at 3:22 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> You desperately need to study [1] and the Posting Guide mentioned at the bottom of this and every other message on this list.
>
> [1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On May 17, 2015 7:31:08 AM PDT, Yonas Yohannes <yonas at wku.edu.et> wrote:
>>Dears,
>>I have presence and absence data set (8 rows and 33 columns) and when I
>>want to get out of the default two dimensions command using
>>summary(ca(mydata,
>>nd=3)) the following error message displyed:
>>
>>Error in dimnames(phi) <- list(rn, dims) :
>>  length of 'dimnames' [2] not equal to array extent
>>
>>Please help! So many thanks in advance!
>>Kindly,
>>* <mail%3Ayonas at wku.edu.et>*
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Mon May 18 16:44:17 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 18 May 2015 07:44:17 -0700
Subject: [R] smooth.spline error while fitting bacterial growth curves
 with grofit
In-Reply-To: <20150517190823.14e3b46dda16183be2641fd9@berkeley.edu>
References: <20150517104258.d3426223f798909fd2b173b8@berkeley.edu>
	<CACk-te23_=vbGq-tv9x=2Kkp0HUSfebuR=FL6Cuqa7C7xGktMw@mail.gmail.com>
	<20150517190823.14e3b46dda16183be2641fd9@berkeley.edu>
Message-ID: <CACk-te0RiEcuK4d+ujrSzrnAzsTi8WZR5vtCFEV1omk_eKixgQ@mail.gmail.com>

Your question is OFFTOPIC for this list. Post on a statistics list
like stats.stackexchange.com .

But both your proposals are wrong, though depending on your data and
purpose, they may be adequate. I suggest you consult wit a local
statistician on the use of mixed effects models for repeated
measures/growth curves or post it on the same topics.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, May 17, 2015 at 7:08 PM, Jeffrey David Johnson
<jefdaj at berkeley.edu> wrote:
> Thanks, I think you're right. I removed the strains whose final OD was
> below 0.2 since all the ones that clearly grew are above that, and
> grofit produces fewer errors on the remaining 6. The error still happens
> occasionally, but if I stick to 1000 bootstraps instead of 10000 it's
> not often. Of course I won't rely on these numbers! I'll try again once
> my current timecourse is done with 6 replicates per strain, and if
> everything is still messy rethink the experimental design.
>
> ... Which brings up another question. Would it be better to estimate
> growth parameters (mu, lambda, etc.) for each replicate and then take
> the mean and standard deviation of those, or to average the growth data
> first and calculate one set of parameters per strain? (Sorry if that's
> very basic statistics)
> Jeff
>
> On Sun, 17 May 2015 11:42:27 -0700
> Bert Gunter <gunter.berton at gene.com> wrote:
>
>> 1. Very likely, you have insufficient data in some of your growth
>> curves to do the fits using gcv. If  you remove the curves where the
>> bacteria didn't grow, things should work. Alternatively, there may
>> well be ways of expressing the model that would allow pooling across
>> cultures that didn't grow. (Sounds like a mixtures problem, actually:
>> you are mixing cultures that grow  with those that don't and need to
>> determine the mixing proportion and the growth parameters of those
>> that grew).
>>
>> 2. HOWEVER, IF you remove the curves, you may very well be getting the
>> wrong (biased) results -- i.e. your results will be irreproducible
>> garbage, as you will only be taking data from cultures that grew well.
>> I would **strongly** suggest you work with a local statistical expert
>> to help you deal with these issues. I do not think you should trust
>> remote advice from the internet on such complex data (including mine!)
>>
>> Cheers,
>> Bert
>>
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Sun, May 17, 2015 at 10:42 AM, Jeffrey David Johnson
>> <jefdaj at berkeley.edu> wrote:
>> > I'm trying to use the grofit package to compare growth rates between
>> > bacterial cultures, but I've come across a couple glitches/things I
>> > don't understand. I'm not sure if they're related to the package or to a
>> > problem with my growth data, which is messy. Some strains don't follow
>> > a proper logarithmic growth curve because they died or didn't grow over
>> > the course of the experiment. I could remove those but it will get more
>> > time consuming once I have more cultures going.
>> >
>> > I've attached the 'time' matrix and 'data' data frame. This code should
>> > fit the growth curves, but when I run it I get an error related to
>> > `smooth.spline`:
>> >
>> > require(grofit)
>> > mytime <- as.matrix(read.table('time.txt'))
>> > mydata <- read.csv('data.csv')
>> > dimnames(mytime) <- NULL
>> > fits <- gcFit(mytime, mydata, grofit.control(
>> >   interactive=FALSE, # don't ask if the graphs look OK
>> >   nboot.gc=1000,     # number of bootstraps
>> >   fit.opt="s"        # just do splines, no models
>> > ))
>> >
>> > = 1. growth curve =================================
>> > ----------------------------------------------------
>> > = 2. growth curve =================================
>> > ----------------------------------------------------
>> > = 3. growth curve =================================
>> > ----------------------------------------------------
>> > Error in smooth.spline(time, data, spar = control$smooth.gc) :
>> >   'tol' must be strictly positive and finite
>> > Error in gcFitSpline(time.cur, data.cur, gcID, control.change) :
>> >   object 'y.spl' not found
>> >
>> > That error usually occurs at some point, though I've run through all 17
>> > successfully a couple times. The documentation says:
>> >
>> >> smooth.gc: Parameter describing the smoothness of the spline fit;
>> >> usually (not necessary) in (0;1]. Set ?smooth.gc=NULL? causes the
>> >> program to query an optimal value via cross validation techniques.
>> >> Note: This is partly experimental. In future improved implementations
>> >> of the ?smooth.spline? function may lead to different results. See
>> >> documentation of the R function ?smooth.spline? for further details.
>> >> Especially for datasets with few data points the option ?NULL? might
>> >> result in a too small smoothing parameter, which produces an error in
>> >> ?smooth.spline?. In that case the usage of a fixed value is
>> >> recommended. Default: ?NULL?.
>> >
>> > I tried setting different values (0.1, 0.5, 0.9, 1, 10) and they all
>> > cause the same error. If instead I use the `gcBootSpline` function
>> > directly, it gives a different error about the number of bootstraps
>> > being 0, when they clearly aren't:
>> >
>> > fits <- gcBootSpline(mytime, mydata, grofit.control(nboot.gc=1000))
>> >
>> > Error in gcBootSpline(mytime, mydata, grofit.control(nboot.gc =
>> > 1000)) : Number of bootstrap samples is zero! See grofit.control()
>> >
>> > Am I using these right? Is there something about the data that would
>> > make it un-fittable?
>> > Jeff
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From quiro3 at msn.com  Mon May 18 13:32:20 2015
From: quiro3 at msn.com (=?iso-8859-1?B?QXJpYWRuYSBHYXJj7WEgU+Flbno=?=)
Date: Mon, 18 May 2015 11:32:20 +0000
Subject: [R] R-help
Message-ID: <DUB128-W724D1EA554691EAEE0892A86C40@phx.gbl>

Good afternoon,
I'm working in a disease spread model, and I have to use a function to put information on a table.
My question is that I don't know how to get the output of this function in a table. Thanks in advance!
Here I paste my script:
tbmodel <- function(time,S,E,I,De,Di,beta,alpha,phi,rho){  ts <- data.frame(time=sim.time,S=susceptibles,E=exposed,I=infectious,De=De,Di=Di)  next.time <- ts  while(next.time$time<limit.time&next.time$S>0&next.time$E>=0&next.time$I>=0) # Conditions under which within-herd spread continues  {    next.time <-gillespie(next.time$time,next.time$S,next.time$E, next.time$I,next.time$De,next.time$Di,beta,alpha,phi,rho)    ts <- rbind(ts,next.time)    if(ts$time[nrow(ts)]>limit.time|ts$E[nrow(ts)]<0)ts <- ts[-nrow(ts),]  # Elimination of last column (time> limit.time)  }

 		 	   		  
	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Mon May 18 17:24:45 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 18 May 2015 11:24:45 -0400
Subject: [R] R-help
In-Reply-To: <DUB128-W724D1EA554691EAEE0892A86C40@phx.gbl>
References: <DUB128-W724D1EA554691EAEE0892A86C40@phx.gbl>
Message-ID: <88728175-E1CC-4C01-9FF8-063CE5933DB0@utoronto.ca>

(Don't post in HTML. Your code is illegible that way.)

Something as simple as ...
   return(ts)
... to conclude your function perhaps?


B.

On May 18, 2015, at 7:32 AM, Ariadna Garc?a S?enz <quiro3 at msn.com> wrote:

> Good afternoon,
> I'm working in a disease spread model, and I have to use a function to put information on a table.
> My question is that I don't know how to get the output of this function in a table. Thanks in advance!
> Here I paste my script:
> tbmodel <- function(time,S,E,I,De,Di,beta,alpha,phi,rho){  ts <- data.frame(time=sim.time,S=susceptibles,E=exposed,I=infectious,De=De,Di=Di)  next.time <- ts  while(next.time$time<limit.time&next.time$S>0&next.time$E>=0&next.time$I>=0) # Conditions under which within-herd spread continues  {    next.time <-gillespie(next.time$time,next.time$S,next.time$E, next.time$I,next.time$De,next.time$Di,beta,alpha,phi,rho)    ts <- rbind(ts,next.time)    if(ts$time[nrow(ts)]>limit.time|ts$E[nrow(ts)]<0)ts <- ts[-nrow(ts),]  # Elimination of last column (time> limit.time)  }
> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon May 18 17:51:33 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 18 May 2015 08:51:33 -0700
Subject: [R] R-help
In-Reply-To: <DUB128-W724D1EA554691EAEE0892A86C40@phx.gbl>
References: <DUB128-W724D1EA554691EAEE0892A86C40@phx.gbl>
Message-ID: <D86DDA2B-646C-44B0-9FA4-7ED40FB88D64@dcn.davis.CA.us>

It is quite clear that you are confused, because your function is full of variables that are not defined in your email. Unfortunately, that also makes helping you quite difficult. Also, your (accidental?) use of HTML format means that your code is garbled on our end (see below). You have to learn how to make your email program send plain text to avoid this problem. (This point and others are in the Posting Guide mentioned at the bottom if this and every email on the list.

Usually your functions will be easier to understand and run faster if they return a vector, and at the point where you call the function you assign that return value to a new column in your data table. Normally we just put an expression (often as simple as a variable name) alone on the last line of the function in order to return it.

plusXY <- function( x, y ) {
  result <- x + y
  result
}
DF <- data.frame( a=1:5, b=5:9 )
str( DF )
DF$c <- plusXY( DF$a, DF$b )
str( DF )

The above steps are a reproducible example. Without you giving us a reproducible example of the kind of code AND data you have it is very difficult to understand your problem at the receiving end of an email. The link [1] below gives advice on making such examples.

I also recommend that you (more carefully) read the Introduction to R document that came with the software. In particular, study indexing or the various members of the lapply family of functions, since rbind is quite an inefficient way to add data to a data frame. Patrick Burns' "The R Inferno" [2] may provide some useful guidance as well.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://www.burns-stat.com/
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 18, 2015 4:32:20 AM PDT, "Ariadna Garc?a S?enz" <quiro3 at msn.com> wrote:
>Good afternoon,
>I'm working in a disease spread model, and I have to use a function to
>put information on a table.
>My question is that I don't know how to get the output of this function
>in a table. Thanks in advance!
>Here I paste my script:
>tbmodel <- function(time,S,E,I,De,Di,beta,alpha,phi,rho){  ts <-
>data.frame(time=sim.time,S=susceptibles,E=exposed,I=infectious,De=De,Di=Di)
>next.time <- ts 
>while(next.time$time<limit.time&next.time$S>0&next.time$E>=0&next.time$I>=0)
># Conditions under which within-herd spread continues  {    next.time
><-gillespie(next.time$time,next.time$S,next.time$E,
>next.time$I,next.time$De,next.time$Di,beta,alpha,phi,rho)    ts <-
>rbind(ts,next.time)   
>if(ts$time[nrow(ts)]>limit.time|ts$E[nrow(ts)]<0)ts <- ts[-nrow(ts),] 
># Elimination of last column (time> limit.time)  }
>
> 		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From onenadi at uni-goettingen.de  Mon May 18 17:52:44 2015
From: onenadi at uni-goettingen.de (=?UTF-8?B?T2xlZyBOZW5hZGnEhw==?=)
Date: Mon, 18 May 2015 17:52:44 +0200
Subject: [R] Error in dimnames(phi) <- list(rn,
 dims) : length of 'dimnames' [2] not equal to array extent
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68CBDC@mb02.ads.tamu.edu>
References: <CANL1GdJG9tYj+mOP7sHaK-9R5vRXCjJ=1vwXz9VrdgF=Bk_Yqg@mail.gmail.com>	<1D06E853-648E-475A-B122-2DEF4EE0BD2E@dcn.davis.CA.us>
	<CA+8X3fU1DnRgzmX9PMhfDdPJc5BFwHNRnznoNQY54JFj9qrLCQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D68CBDC@mb02.ads.tamu.edu>
Message-ID: <555A0ACC.5000109@uni-goettingen.de>

David, Thanks for forwarding this to me.

Yonas, Please try updating your ca package to version 0.61 which fixes 
this issue. This is not the latest official CRAN version, so get it from 
R-forge via
 > update.packages("ca", repos = "http://r-forge.r-project.org")

All the best,
Oleg.


On 18/05/2015 16:27, David L Carlson wrote:> I think this is a bug in 
the current version of ca() in package ca. I am copying the package 
maintainer with this example:
 >
 > # Reproducible example from manual page for ca():
 >
 >> library(ca)
 >> data("author")
 >> author.ca <- ca(author) # No problem
 >> author.ca <- ca(author, nd=3)
 > Error in dimnames(phi) <- list(rn, dims) :
 >    length of 'dimnames' [2] not equal to array extent
 >> library(MASS)
 >> author.ca <- corresp(author, nf=3) # No problem
 >
 > So the MASS version of correspondence analysis, corresp(), is able to 
extract three dimensions (actually up to 11) from "author". I am certain 
I have used ca() in the past and extracted more than two dimensions from 
similar tables.
 >
 > -------------------------------------
 > David L Carlson
 > Department of Anthropology
 > Texas A&M University
 > College Station, TX 77840-4352
 >
 >
 >
 > -----Original Message-----
 > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
 > Sent: Sunday, May 17, 2015 7:31 PM
 > Cc: r-help mailing list
 > Subject: Re: [R] Error in dimnames(phi) <- list(rn, dims) : length of 
'dimnames' [2] not equal to array extent
 >
 > Hi Yonas,
 > If this is the "ca" function from the package of the same name, it
 > looks to me as though your data set is only two dimensions and you are
 > requesting 3 dimensions in the output. Have you tried calling ca with
 > the default nd=NA?
 >
 > Jim
 >
 >
 > On Mon, May 18, 2015 at 3:22 AM, Jeff Newmiller
 > <jdnewmil at dcn.davis.ca.us> wrote:
 >> You desperately need to study [1] and the Posting Guide mentioned at 
the bottom of this and every other message on this list.
 >>
 >> [1] 
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
 >> 
---------------------------------------------------------------------------
 >> Jeff Newmiller                        The     .....       .....  Go 
Live...
 >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. 
Live Go...
 >>                                        Live:   OO#.. Dead: OO#.. 
Playing
 >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
 >> /Software/Embedded Controllers)               .OO#.       .OO#. 
rocks...1k
 >> 
---------------------------------------------------------------------------
 >> Sent from my phone. Please excuse my brevity.
 >>
 >> On May 17, 2015 7:31:08 AM PDT, Yonas Yohannes <yonas at wku.edu.et> wrote:
 >>> Dears,
 >>> I have presence and absence data set (8 rows and 33 columns) and when I
 >>> want to get out of the default two dimensions command using
 >>> summary(ca(mydata,
 >>> nd=3)) the following error message displyed:
 >>>
 >>> Error in dimnames(phi) <- list(rn, dims) :
 >>>   length of 'dimnames' [2] not equal to array extent
 >>>
 >>> Please help! So many thanks in advance!
 >>> Kindly,
 >>> * <mail%3Ayonas at wku.edu.et>*
 >>>
 >>>        [[alternative HTML version deleted]]
 >>>
 >>> ______________________________________________
 >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 >>> https://stat.ethz.ch/mailman/listinfo/r-help
 >>> PLEASE do read the posting guide
 >>> http://www.R-project.org/posting-guide.html
 >>> and provide commented, minimal, self-contained, reproducible code.
 >>
 >> ______________________________________________
 >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 >> https://stat.ethz.ch/mailman/listinfo/r-help
 >> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
 >> and provide commented, minimal, self-contained, reproducible code.
 >
 > ______________________________________________
 > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
 > and provide commented, minimal, self-contained, reproducible code.
 >


From enryu_crema at yahoo.it  Mon May 18 19:00:14 2015
From: enryu_crema at yahoo.it (Yahoo)
Date: Mon, 18 May 2015 19:00:14 +0200
Subject: [R] p-values and temporal uncertainty in variables
Message-ID: <9E5AD89E-7DEA-4FF9-8F89-FA95E0D8DF93@yahoo.it>

Dear List,

This is one of those questions that are easier to be explained with an example. I also apologise as strictly speaking this is not an R question, but more general methodological question that I would like to solve in R.  

Suppose we have the following data

#Generate artificial data#
DateMeans<-c(900,1000,1250,1300,1380,1400,1400,1500,1550)
DateSDs<-c(300,400,100,100,60,60,120,100,50)
index=sample(1:9,size=400,prob=c(0.238,0.119,0.238,0.048,0.095,0.048,0.048,0.024,0.143),replace=TRUE)
A1=rnorm(100,mean=5,sd=1)
A2=rnorm(100,mean=5,sd=1)
B1=rnorm(100,mean=5,sd=2)
B2=rnorm(100,mean=5,sd=1.5)

data=data.frame(type=c(rep("a",200),rep("b",200)),size=c(A1,A2,B1,B2),dateAvg=DateMeans[index]+round(runif(400,min=0,max=100)),dateSd=DateSDs[index]+round(runif(400,min=0,max=20)))
head(data)

Let?s say we are measuring the size of two objects labelled ?a? and ?b? (the column ?type?), and we are interested whether one is bigger than the other. They are normally distributed so a standard t-test will suffice. However, suppose also that these object have a time-stamp (column dateAvg), each with some degree of uncertainty (column dateSd) described as a Gaussian error. If I want to now the average size of type ?a? for a given interval (let?s say between 1300 and 1400), I could simply resample as follow:

nsim<-1000 #number of simulations
MeanOfA<-numeric(length=nsim)

for (s in 1:nsim)
{
simdates<-rnorm(nrow(data),mean=data$dateAvg,sd=data$dateSd)
i=which(simdates>=interestBlock[1]&simdates<=interestBlock[2])
MeanOfA[s]=mean(subset(data[i,],type=="a")$size)
}

This will give me a distribution of means that will include the uncertainty of our summary statistics. I think there is nothing wrong with this.

But suppose I want to test whether objects of type ?a? are different in size in comparison with objects of type ?b?. I don?t think comparing the means obtained from the simulation is fair, as the significance will change as a function of the number of simulations. All I can think of is to compute a t-test for each iteration, something like the following:


nsim=1000
interestBlock=c(1400,1500)
statistic<-numeric(length=nsim)
pvals<-numeric(length=nsim)
diffs<-numeric(length=nsim)
for (s in 1:nsim)
{
simdates<-rnorm(nrow(data),mean=data$dateAvg,sd=data$dateSd)
i=which(simdates>=interestBlock[1]&simdates<=interestBlock[2])
tmpdata=data[i,]
diffs[s]=mean(subset(tmpdata,type=="a")$size)-mean(subset(tmpdata,type=="b")$size)
res=t.test(x=subset(tmpdata,type=="a")$size,y=subset(tmpdata,type=="b")$size)
statistic[s]=res$statistic
pvals[s]=res$p.value  
}

And then get a distribution of p-values (that I frankly find useless). Is there a way to get a single p-value? The only alternative I can think of is to get a 95% confidence interval of the difference in mean, and see if this includes no difference in mean or not?. 

Many thanks in advance,
Enrico


From Douglas.Federman at utoledo.edu  Mon May 18 20:45:23 2015
From: Douglas.Federman at utoledo.edu (Federman, Douglas)
Date: Mon, 18 May 2015 18:45:23 +0000
Subject: [R] Template Engine for R
In-Reply-To: <CAFnz2-8Rr-6DyAdgA2_KmZG7WoQ5G6cQiMztV-uC_CGbuy2R-g@mail.gmail.com>
References: <CAFnz2-8Rr-6DyAdgA2_KmZG7WoQ5G6cQiMztV-uC_CGbuy2R-g@mail.gmail.com>
Message-ID: <F1065E5D886F4D429259CDEAE3F83CB61AF13262@msgdb20.utad.utoledo.edu>

There is a new one on CRAN called infuser that may meet your needs


--
One who is in a dying condition is regarded as a living person in all respects.
    -- Maimonides


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luca Cerone
Sent: Saturday, May 16, 2015 2:35 AM
To: R-help
Subject: [R] Template Engine for R

Dear all,
I am looking for a template engine for R.

I have already come across {{mustache}} and its R implementation whisker, however I am looking for something with a few more features like "if blocks", "for loop", "block inheritance" and so on (for those of you who are familiar with Python I am looking for something like Jinja2 or Mako).

I searched in google, but the only option for R seems whisker.

Can any of you recommend me some alternatives?

Thanks a lot in advance for the help!

Cheers,
Luca

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From luca.cerone at gmail.com  Mon May 18 21:00:13 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Mon, 18 May 2015 21:00:13 +0200
Subject: [R] Template Engine for R
In-Reply-To: <F1065E5D886F4D429259CDEAE3F83CB61AF13262@msgdb20.utad.utoledo.edu>
References: <CAFnz2-8Rr-6DyAdgA2_KmZG7WoQ5G6cQiMztV-uC_CGbuy2R-g@mail.gmail.com>
	<F1065E5D886F4D429259CDEAE3F83CB61AF13262@msgdb20.utad.utoledo.edu>
Message-ID: <CAFnz2-_hNspxEdFN0Mh=wRbaDLyvRH87xZ1AydB6_SL9xt9RwA@mail.gmail.com>

Hi Douglas,
I read about it just this morning!
It seems interesting, but I don't think it handles if and for, yet.

I'll look at it in more details, though.

Thanks a lot for hint :)

Cheers,
Luca


On Mon, May 18, 2015 at 8:45 PM, Federman, Douglas
<Douglas.Federman at utoledo.edu> wrote:
> There is a new one on CRAN called infuser that may meet your needs
>
>
> --
> One who is in a dying condition is regarded as a living person in all respects.
>     -- Maimonides
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luca Cerone
> Sent: Saturday, May 16, 2015 2:35 AM
> To: R-help
> Subject: [R] Template Engine for R
>
> Dear all,
> I am looking for a template engine for R.
>
> I have already come across {{mustache}} and its R implementation whisker, however I am looking for something with a few more features like "if blocks", "for loop", "block inheritance" and so on (for those of you who are familiar with Python I am looking for something like Jinja2 or Mako).
>
> I searched in google, but the only option for R seems whisker.
>
> Can any of you recommend me some alternatives?
>
> Thanks a lot in advance for the help!
>
> Cheers,
> Luca
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ivo.welch at anderson.ucla.edu  Mon May 18 23:47:49 2015
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Mon, 18 May 2015 14:47:49 -0700
Subject: [R] Finding Optimum of Stochastic Function
Message-ID: <CAPr7RtV99V3=3QUMKAmLridyECOr2MAq6cqXRV3929MadCU7XQ@mail.gmail.com>

Could someone please point me to an optimizer for stochastic functions?
   (In http://cran.r-project.org/web/views/Optimization.html, I saw methods
that use random directions for deterministic functions, which is not the
kind of stochastic I need.)

For clarification, say I have an outcome function f(x), where x is a vector
of, say, 3 choices.  f(x) yields a simulated result that depends on random
draws.  That is, if I run it twice, it will give me different answers.  I
want to find the value of x that has the highest average f(x).

There are apparently well-defined algorithms, such as Robbins-Monro,
Kiefer-Wolfowitz, and Spall, although I don't know how they work nor do I
need to know much.  Presumably, a good algorithm knows not to draw too many
points at a given x too early (when far away from the optimum), but to
start more scattershot; and not to try to climb too aggressively.
Intuitively, I probably want to start from a point, draw in a cloud around
this point, and slowly sample-crawl into the direction where values tend to
be higher.  Ideally, the algorithm would try to solve an updatable
least-squares problem to determine its next sample.

Pointers appreciated.

regards, /iaw
----
Ivo Welch (ivo.welch at gmail.com)

	[[alternative HTML version deleted]]


From aziz4 at illinois.edu  Tue May 19 07:50:09 2015
From: aziz4 at illinois.edu (Aziz, Muhammad Fayez)
Date: Tue, 19 May 2015 05:50:09 +0000
Subject: [R] Understanding mod.matrix for directed networks
Message-ID: <8BB99D4AA51D4A4397817F165A7BD8DD6F0A7988@CHIMBX5.ad.uillinois.edu>

Dear Gabor,



Please find attached an Excel file with detailed information on a four node directed network to calculate its pairwise modularity matrix using igraph: mod.matrix(). I have tried multiple combinations to figure out how the formula works or is applied but failed to find consistency, specially for the pairs of arcs in opposing directions where the pairwise modularity is different (highlighted and color-coded). I gave membership(wtc) as input to mod.matrix() but not even sure if its used in the formula provided in the following R manual page:



http://igraph.org/r/doc/modularity.html



Advice with a solved example in the Excel sheet would be deeply appreciated.



Thanks and regards,

Fayez

University of Illinois at Urbana Champaign, USA

From lvest09 at student.sdu.dk  Tue May 19 10:16:34 2015
From: lvest09 at student.sdu.dk (Livia Maria Vestergaard)
Date: Tue, 19 May 2015 08:16:34 +0000
Subject: [R]  Output interpretation: standard error of lm dummy variable
Message-ID: <2DFEDD9D3576FB419C7BF7511E983C964AE43973@ADM-EXMBX10D.adm.c.sdu.dk>

Hi guys

I have a statistical question to an analyse I ran in R. It is a dummy variable  model with the 5 regions of Denmark as 4 independent dummy variables and price as the dependent variable:

price = 10.325 - 0.176*Sjaeland - 0.368 * NJylland - 0.230*MJylland - 0.120* Syddanmark

I understand the R^2 = 0.7348  - that it shows the explanatory force of the model (between 0 and 1)
My question is simply how to interpret the standard error = 0.7348 on 342199 degrees of freedom? How is it calculated when the model is a dummy variable model. And what does  it mean that the F-statistic says that there are 1894 on 4 and 342199 DF (degrees if freedom?) with a p-value < 0?

I have been searching for hours - and can't quite figure out how R reached the numbers and how to interpret the output of standard error and the p-value of the dummy model.

I really hope you can help :)

Best Livia 
-------------- n?ste del --------------
En vedh?ftet fil der ikke var tekst, er blevet fjernet...
Navn: Regioner.png
Type: image/png
St?rrelse: 67604 bytes
Beskrivelse: Regioner.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150519/40b90040/attachment.png>

From drjimlemon at gmail.com  Tue May 19 12:44:54 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 19 May 2015 20:44:54 +1000
Subject: [R] Output interpretation: standard error of lm dummy variable
In-Reply-To: <2DFEDD9D3576FB419C7BF7511E983C964AE43973@ADM-EXMBX10D.adm.c.sdu.dk>
References: <2DFEDD9D3576FB419C7BF7511E983C964AE43973@ADM-EXMBX10D.adm.c.sdu.dk>
Message-ID: <CA+8X3fUgkc_JdFTogVF_47oo9oO0r9mVJ=ri5=MnSDxtFHyNFA@mail.gmail.com>

Hi Livia,
You seem to have mixed up the residual error with the R^2, which is
just over 0.02. The bottom line on your summary table says that the
obtained F statistic was equal to 1894 (this has been truncated to
four significant places). The probability of obtaining that value with
your data given the F distribution for 4 numerator and 342199
denominator degrees of freedom is very small, but not less than 0. The
notation <2.2e-16 can be roughly translated in English as "about as
close to zero as this function can calculate". You should note that
with that many observations, a significant result is almost
guaranteed, but the linear model explains almost none of the variance
in prices.

Jim


On Tue, May 19, 2015 at 6:16 PM, Livia Maria Vestergaard
<lvest09 at student.sdu.dk> wrote:
> Hi guys
>
> I have a statistical question to an analyse I ran in R. It is a dummy variable  model with the 5 regions of Denmark as 4 independent dummy variables and price as the dependent variable:
>
> price = 10.325 - 0.176*Sjaeland - 0.368 * NJylland - 0.230*MJylland - 0.120* Syddanmark
>
> I understand the R^2 = 0.7348  - that it shows the explanatory force of the model (between 0 and 1)
> My question is simply how to interpret the standard error = 0.7348 on 342199 degrees of freedom? How is it calculated when the model is a dummy variable model. And what does  it mean that the F-statistic says that there are 1894 on 4 and 342199 DF (degrees if freedom?) with a p-value < 0?
>
> I have been searching for hours - and can't quite figure out how R reached the numbers and how to interpret the output of standard error and the p-value of the dummy model.
>
> I really hope you can help :)
>
> Best Livia
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nashjc at uottawa.ca  Tue May 19 13:57:25 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Tue, 19 May 2015 07:57:25 -0400
Subject: [R]  Finding Optimum of Stochastic Function
In-Reply-To: <mailman.9.1432029602.23939.r-help@r-project.org>
References: <mailman.9.1432029602.23939.r-help@r-project.org>
Message-ID: <555B2525.7040200@uottawa.ca>

Most of the stochastic optimization methods are directed at multiple
optima. You appear to have an imprecisely determined function e.g., time
taken for racing driver to get round the track, and indeed this is a
different form of stochastic optimization.

With Harry Joe of UBC I did quite a bit of work about 20 years ago on
response surface minimization, but none of this is (to my knowledge)
translated to R. David Wagstaff at Penn State just sent me a msg that
he's making some progress translating our Fortran 77 to Fortran 95 (I
think to R might actually be easier). I believe Harry had at least a
partial C version.

reference is Statistics and Computing 13: 277?286, 2003 "Numerical
optimization and surface estimation with imprecise function evaluations"

Our approach was to generate some points and model them as a paraboloid
and then search near the minimum of that model. All the "smarts" are in
choosing which points to add to or remove from the set of points for
modelling the surface. Clearly there are no guarantees, but for some
applications we found this worked not too badly.

JN

On 15-05-19 06:00 AM, r-help-request at r-project.org wrote:
> Message: 11
> Date: Mon, 18 May 2015 14:47:49 -0700
> From: ivo welch <ivo.welch at anderson.ucla.edu>
> To: r-help at r-project.org
> Subject: [R] Finding Optimum of Stochastic Function
> Message-ID:
> 	<CAPr7RtV99V3=3QUMKAmLridyECOr2MAq6cqXRV3929MadCU7XQ at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
> 
> Could someone please point me to an optimizer for stochastic functions?
>    (In http://cran.r-project.org/web/views/Optimization.html, I saw methods
> that use random directions for deterministic functions, which is not the
> kind of stochastic I need.)
> 
> For clarification, say I have an outcome function f(x), where x is a vector
> of, say, 3 choices.  f(x) yields a simulated result that depends on random
> draws.  That is, if I run it twice, it will give me different answers.  I
> want to find the value of x that has the highest average f(x).
> 
> There are apparently well-defined algorithms, such as Robbins-Monro,
> Kiefer-Wolfowitz, and Spall, although I don't know how they work nor do I
> need to know much.  Presumably, a good algorithm knows not to draw too many
> points at a given x too early (when far away from the optimum), but to
> start more scattershot; and not to try to climb too aggressively.
> Intuitively, I probably want to start from a point, draw in a cloud around
> this point, and slowly sample-crawl into the direction where values tend to
> be higher.  Ideally, the algorithm would try to solve an updatable
> least-squares problem to determine its next sample.
> 
> Pointers appreciated.
> 
> regards, /iaw
> ----
> Ivo Welch (ivo.welch at gmail.com)
> 
> 	[[alternative HTML version deleted]]


From yonas at wku.edu.et  Tue May 19 08:23:07 2015
From: yonas at wku.edu.et (Yonas Yohannes)
Date: Tue, 19 May 2015 09:23:07 +0300
Subject: [R] Error in dimnames(phi) <- list(rn,
 dims) : length of 'dimnames' [2] not equal to array extent
In-Reply-To: <555A0ACC.5000109@uni-goettingen.de>
References: <CANL1GdJG9tYj+mOP7sHaK-9R5vRXCjJ=1vwXz9VrdgF=Bk_Yqg@mail.gmail.com>
	<1D06E853-648E-475A-B122-2DEF4EE0BD2E@dcn.davis.CA.us>
	<CA+8X3fU1DnRgzmX9PMhfDdPJc5BFwHNRnznoNQY54JFj9qrLCQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D68CBDC@mb02.ads.tamu.edu>
	<555A0ACC.5000109@uni-goettingen.de>
Message-ID: <CANL1GdJYQqeG40s=Uqy8ONk1+yKdb5Vj-MYbxGOe0cQzgN2yvQ@mail.gmail.com>

Dear Oleg,
Thank you so much for your advice! But I tried to update the packages and
check whether the problem is fixed. But I end up with the same error.
Error in dimnames(phi) <- list(rn, dims) :
  length of 'dimnames' [2] not equal to array extent

It seems to me that, what I got to update from R-forge is version 0.60 not
version 0.61. Please see below the script I got while updating the package:

trying URL 'http://R-Forge.R-project.org/bin/windows/contrib/3.1/ca_0.60.zip
'

Content type 'application/zip' length 98081 bytes (95 KB)

opened URL

downloaded 95 KB


Do you think version 0.60 is not fixing the problem?

Kindly,

Yonas


On Mon, May 18, 2015 at 6:52 PM, Oleg Nenadi? <onenadi at uni-goettingen.de>
wrote:

> David, Thanks for forwarding this to me.
>
> Yonas, Please try updating your ca package to version 0.61 which fixes
> this issue. This is not the latest official CRAN version, so get it from
> R-forge via
> > update.packages("ca", repos = "http://r-forge.r-project.org")
>
> All the best,
> Oleg.
>
>
>
> On 18/05/2015 16:27, David L Carlson wrote:> I think this is a bug in the
> current version of ca() in package ca. I am copying the package maintainer
> with this example:
> >
> > # Reproducible example from manual page for ca():
> >
> >> library(ca)
> >> data("author")
> >> author.ca <- ca(author) # No problem
> >> author.ca <- ca(author, nd=3)
> > Error in dimnames(phi) <- list(rn, dims) :
> >    length of 'dimnames' [2] not equal to array extent
> >> library(MASS)
> >> author.ca <- corresp(author, nf=3) # No problem
> >
> > So the MASS version of correspondence analysis, corresp(), is able to
> extract three dimensions (actually up to 11) from "author". I am certain I
> have used ca() in the past and extracted more than two dimensions from
> similar tables.
> >
> > -------------------------------------
> > David L Carlson
> > Department of Anthropology
> > Texas A&M University
> > College Station, TX 77840-4352
> >
> >
> >
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim
> Lemon
> > Sent: Sunday, May 17, 2015 7:31 PM
> > Cc: r-help mailing list
> > Subject: Re: [R] Error in dimnames(phi) <- list(rn, dims) : length of
> 'dimnames' [2] not equal to array extent
> >
> > Hi Yonas,
> > If this is the "ca" function from the package of the same name, it
> > looks to me as though your data set is only two dimensions and you are
> > requesting 3 dimensions in the output. Have you tried calling ca with
> > the default nd=NA?
> >
> > Jim
> >
> >
> > On Mon, May 18, 2015 at 3:22 AM, Jeff Newmiller
> > <jdnewmil at dcn.davis.ca.us> wrote:
> >> You desperately need to study [1] and the Posting Guide mentioned at
> the bottom of this and every other message on this list.
> >>
> >> [1]
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >>
> ---------------------------------------------------------------------------
> >> Jeff Newmiller                        The     .....       .....  Go
> Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. Live
> Go...
> >>                                        Live:   OO#.. Dead: OO#.. Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> >>
> ---------------------------------------------------------------------------
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On May 17, 2015 7:31:08 AM PDT, Yonas Yohannes <yonas at wku.edu.et>
> wrote:
> >>> Dears,
> >>> I have presence and absence data set (8 rows and 33 columns) and when I
> >>> want to get out of the default two dimensions command using
> >>> summary(ca(mydata,
> >>> nd=3)) the following error message displyed:
> >>>
> >>> Error in dimnames(phi) <- list(rn, dims) :
> >>>   length of 'dimnames' [2] not equal to array extent
> >>>
> >>> Please help! So many thanks in advance!
> >>> Kindly,
> >>> * <mail%3Ayonas at wku.edu.et>*
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From ogi.nic at googlemail.com  Tue May 19 09:04:23 2015
From: ogi.nic at googlemail.com (=?UTF-8?B?T2xlZyBOZW5hZGnEhw==?=)
Date: Tue, 19 May 2015 09:04:23 +0200
Subject: [R] Error in dimnames(phi) <- list(rn,
 dims) : length of 'dimnames' [2] not equal to array extent
In-Reply-To: <CANL1GdJYQqeG40s=Uqy8ONk1+yKdb5Vj-MYbxGOe0cQzgN2yvQ@mail.gmail.com>
References: <CANL1GdJG9tYj+mOP7sHaK-9R5vRXCjJ=1vwXz9VrdgF=Bk_Yqg@mail.gmail.com>	<1D06E853-648E-475A-B122-2DEF4EE0BD2E@dcn.davis.CA.us>	<CA+8X3fU1DnRgzmX9PMhfDdPJc5BFwHNRnznoNQY54JFj9qrLCQ@mail.gmail.com>	<53BF8FB63FAF2E4A9455EF1EE94DA7262D68CBDC@mb02.ads.tamu.edu>	<555A0ACC.5000109@uni-goettingen.de>
	<CANL1GdJYQqeG40s=Uqy8ONk1+yKdb5Vj-MYbxGOe0cQzgN2yvQ@mail.gmail.com>
Message-ID: <555AE077.7010605@gmail.com>

Dear Yonas,
It usually takes some time until a Windows binary version is available 
on R-Forge. It is version 0.61 you want here.

So, you can either install the source version using
 > install.packages("ca", repos="http://R-Forge.R-project.org", 
type="source")
or manually download and install the binary package from
https://r-forge.r-project.org/R/?group_id=1859

Kind regards,
Oleg.


On 19.05.2015 08:23, Yonas Yohannes wrote:
 > Dear Oleg,
 > Thank you so much for your advice! But I tried to update the packages
 > and check whether the problem is fixed. But I end up with the same error.
 > Error in dimnames(phi) <- list(rn, dims) :
 > length of 'dimnames' [2] not equal to array extent
 >
 > It seems to me that, what I got to update from R-forge is version 0.60
 > not version 0.61. Please see below the script I got while updating the
 > package:
 >
 > trying URL
 > 'http://R-Forge.R-project.org/bin/windows/contrib/3.1/ca_0.60.zip'
 >
 > Content type 'application/zip' length 98081 bytes (95 KB)
 >
 > opened URL
 >
 > downloaded 95 KB
 >
 >
 > Do you think version 0.60 is not fixing the problem?
 >
 > Kindly,
 >
 > Yonas
 >
 >
 >
 > On Mon, May 18, 2015 at 6:52 PM, Oleg Nenadi? <onenadi at uni-goettingen.de
 > <mailto:onenadi at uni-goettingen.de>> wrote:
 >
 >     David, Thanks for forwarding this to me.
 >
 >     Yonas, Please try updating your ca package to version 0.61 which
 >     fixes this issue. This is not the latest official CRAN version, so
 >     get it from R-forge via
 >      > update.packages("ca", repos = "http://r-forge.r-project.org")
 >
 >     All the best,
 >     Oleg.
 >
 >
 >
 >     On 18/05/2015 16:27, David L Carlson wrote:> I think this is a bug
 >     in the current version of ca() in package ca. I am copying the
 >     package maintainer with this example:
 >      >
 >      > # Reproducible example from manual page for ca():
 >      >
 >      >> library(ca)
 >      >> data("author")
 >      >> author.ca <http://author.ca> <- ca(author) # No problem
 >      >> author.ca <http://author.ca> <- ca(author, nd=3)
 >      > Error in dimnames(phi) <- list(rn, dims) :
 >      > length of 'dimnames' [2] not equal to array extent
 >      >> library(MASS)
 >      >> author.ca <http://author.ca> <- corresp(author, nf=3) # No 
problem
 >      >
 >      > So the MASS version of correspondence analysis, corresp(), is
 >     able to extract three dimensions (actually up to 11) from "author".
 >     I am certain I have used ca() in the past and extracted more than
 >     two dimensions from similar tables.
 >      >
 >      > -------------------------------------
 >      > David L Carlson
 >      > Department of Anthropology
 >      > Texas A&M University
 >      > College Station, TX 77840-4352
 >      >
 >      >
 >      >
 >      > -----Original Message-----
 >      > From: R-help [mailto:r-help-bounces at r-project.org
 >     <mailto:r-help-bounces at r-project.org>] On Behalf Of Jim Lemon
 >      > Sent: Sunday, May 17, 2015 7:31 PM
 >      > Cc: r-help mailing list
 >      > Subject: Re: [R] Error in dimnames(phi) <- list(rn, dims) :
 >     length of 'dimnames' [2] not equal to array extent
 >      >
 >      > Hi Yonas,
 >      > If this is the "ca" function from the package of the same name, it
 >      > looks to me as though your data set is only two dimensions and
 >     you are
 >      > requesting 3 dimensions in the output. Have you tried calling 
ca with
 >      > the default nd=NA?
 >      >
 >      > Jim
 >      >
 >      >
 >      > On Mon, May 18, 2015 at 3:22 AM, Jeff Newmiller
 >      > <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>> 
wrote:
 >      >> You desperately need to study [1] and the Posting Guide
 >     mentioned at the bottom of this and every other message on this list.
 >      >>
 >      >> [1]
 > 
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
 >      >>
 > 
---------------------------------------------------------------------------
 >      >> Jeff Newmiller The ..... ..... Go Live...
 >      >> DCN:<jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>>
 >     Basics: ##.#. ##.#. Live Go...
 >      >> Live: OO#.. Dead: OO#.. Playing
 >      >> Research Engineer (Solar/Batteries O.O#. #.O#. with
 >      >> /Software/Embedded Controllers) .OO#. .OO#. rocks...1k
 >      >>
 > 
---------------------------------------------------------------------------
 >      >> Sent from my phone. Please excuse my brevity.
 >      >>
 >      >> On May 17, 2015 7:31:08 AM PDT, Yonas Yohannes <yonas at wku.edu.et
 >     <mailto:yonas at wku.edu.et>> wrote:
 >      >>> Dears,
 >      >>> I have presence and absence data set (8 rows and 33 columns)
 >     and when I
 >      >>> want to get out of the default two dimensions command using
 >      >>> summary(ca(mydata,
 >      >>> nd=3)) the following error message displyed:
 >      >>>
 >      >>> Error in dimnames(phi) <- list(rn, dims) :
 >      >>> length of 'dimnames' [2] not equal to array extent
 >      >>>
 >      >>> Please help! So many thanks in advance!
 >      >>> Kindly,
 >      >>> * <mail%3Ayonas at wku.edu.et <mailto:mail%253Ayonas at wku.edu.et>>*
 >      >>>
 >      >>> [[alternative HTML version deleted]]
 >      >>>
 >      >>> ______________________________________________
 >      >>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
 >     -- To UNSUBSCRIBE and more, see
 >      >>> https://stat.ethz.ch/mailman/listinfo/r-help
 >      >>> PLEASE do read the posting guide
 >      >>> http://www.R-project.org/posting-guide.html
 >      >>> and provide commented, minimal, self-contained, reproducible 
code.
 >      >>
 >      >> ______________________________________________
 >      >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
 >     -- To UNSUBSCRIBE and more, see
 >      >> https://stat.ethz.ch/mailman/listinfo/r-help
 >      >> PLEASE do read the posting guide
 >     http://www.R-project.org/posting-guide.html
 >      >> and provide commented, minimal, self-contained, reproducible 
code.
 >      >
 >      > ______________________________________________
 >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
 >     -- To UNSUBSCRIBE and more, see
 >      > https://stat.ethz.ch/mailman/listinfo/r-help
 >      > PLEASE do read the posting guide
 >     http://www.R-project.org/posting-guide.html
 >      > and provide commented, minimal, self-contained, reproducible code.
 >      >
 >
 >


From hafizuddinarshad21 at gmail.com  Tue May 19 12:10:32 2015
From: hafizuddinarshad21 at gmail.com (Hafizuddin Arshad)
Date: Tue, 19 May 2015 03:10:32 -0700
Subject: [R] Count number in r
Message-ID: <CAAPm8Oo4=CNrijMyh75g6CR4X7-OJQJNpO0Kv0uG_24-CYoz+g@mail.gmail.com>

Dear R users,

Could someone help me on this? I have this kind of data set:

structure(list(Year = c(1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L), Month = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L), Rain = c(58.9, 74.6, 17.7, 7.8, 1.2, 1, 5.3, 0.7,
1.2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 10.4, 17.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)), .Names = c("Year",
"Month", "Rain"), class = "data.frame", row.names = c(NA, -44L
))

I want to count data in "Rain" that is greater and equal to 0.1 mm
according to their "Month" and "Year". I have used this code, but it seems
so wrong.

raindat <- read.csv('my data set',header=TRUE)
yearcorr<-min(raindat$Year)-1
years<-unique(raindat$Year)
rainmonth<-as.data.frame(matrix(0,nrow=2,ncol=12))
for(year in years) {
  for(month in 1:12) {
    if(any(raindat$Year==year&raindat$Month==month))
      rainmonth[year-yearcorr,month]<-
      length((which(raindat$Rain >=
0.1))[raindat$Year==year&raindat$Month==month])
  }
}
rownames(rainmonth)<-years
names(rainmonth)<-month.abb
rainmonth

Thank you so much.


Arshad

	[[alternative HTML version deleted]]


From jorgeivanvelez at gmail.com  Tue May 19 15:20:53 2015
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Tue, 19 May 2015 23:20:53 +1000
Subject: [R] Count number in r
In-Reply-To: <CAAPm8Oo4=CNrijMyh75g6CR4X7-OJQJNpO0Kv0uG_24-CYoz+g@mail.gmail.com>
References: <CAAPm8Oo4=CNrijMyh75g6CR4X7-OJQJNpO0Kv0uG_24-CYoz+g@mail.gmail.com>
Message-ID: <CAKL8G3FAFc47mvTpRX8V+HXTMiQoZpgFv0GPbZwNTHW7fm_yQw@mail.gmail.com>

Dear Arshad,

Here is a possibility using tapply():

with(d, tapply(Rain, list(Month, Year), function(x) sum(x > .1)))
##1971
#1   12
#2    0


where "d" is your data.frame().   See also ?aggregate and ?ave.

Best,
Jorge.-


On Tue, May 19, 2015 at 8:10 PM, Hafizuddin Arshad <
hafizuddinarshad21 at gmail.com> wrote:

> Dear R users,
>
> Could someone help me on this? I have this kind of data set:
>
> structure(list(Year = c(1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L), Month = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L), Rain = c(58.9, 74.6, 17.7, 7.8, 1.2, 1, 5.3, 0.7,
> 1.2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 10.4, 17.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)), .Names = c("Year",
> "Month", "Rain"), class = "data.frame", row.names = c(NA, -44L
> ))
>
> I want to count data in "Rain" that is greater and equal to 0.1 mm
> according to their "Month" and "Year". I have used this code, but it seems
> so wrong.
>
> raindat <- read.csv('my data set',header=TRUE)
> yearcorr<-min(raindat$Year)-1
> years<-unique(raindat$Year)
> rainmonth<-as.data.frame(matrix(0,nrow=2,ncol=12))
> for(year in years) {
>   for(month in 1:12) {
>     if(any(raindat$Year==year&raindat$Month==month))
>       rainmonth[year-yearcorr,month]<-
>       length((which(raindat$Rain >=
> 0.1))[raindat$Year==year&raindat$Month==month])
>   }
> }
> rownames(rainmonth)<-years
> names(rainmonth)<-month.abb
> rainmonth
>
> Thank you so much.
>
>
> Arshad
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue May 19 17:18:53 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 19 May 2015 15:18:53 +0000
Subject: [R] Count number in r
In-Reply-To: <CAKL8G3FAFc47mvTpRX8V+HXTMiQoZpgFv0GPbZwNTHW7fm_yQw@mail.gmail.com>
References: <CAAPm8Oo4=CNrijMyh75g6CR4X7-OJQJNpO0Kv0uG_24-CYoz+g@mail.gmail.com>
	<CAKL8G3FAFc47mvTpRX8V+HXTMiQoZpgFv0GPbZwNTHW7fm_yQw@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68CF2F@mb02.ads.tamu.edu>

Here's an approach using xtabs() if you want the output as a table:

> flag <- as.integer(d$Rain>=.1)
> xtabs(flag~Year+Month, d)
      Month
Year    1  2
  1971 12  0

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jorge I Velez
Sent: Tuesday, May 19, 2015 8:21 AM
To: Hafizuddin Arshad
Cc: R Help
Subject: Re: [R] Count number in r

Dear Arshad,

Here is a possibility using tapply():

with(d, tapply(Rain, list(Month, Year), function(x) sum(x > .1)))
##1971
#1   12
#2    0


where "d" is your data.frame().   See also ?aggregate and ?ave.

Best,
Jorge.-


On Tue, May 19, 2015 at 8:10 PM, Hafizuddin Arshad <
hafizuddinarshad21 at gmail.com> wrote:

> Dear R users,
>
> Could someone help me on this? I have this kind of data set:
>
> structure(list(Year = c(1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L), Month = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L), Rain = c(58.9, 74.6, 17.7, 7.8, 1.2, 1, 5.3, 0.7,
> 1.2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 10.4, 17.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)), .Names = c("Year",
> "Month", "Rain"), class = "data.frame", row.names = c(NA, -44L
> ))
>
> I want to count data in "Rain" that is greater and equal to 0.1 mm
> according to their "Month" and "Year". I have used this code, but it seems
> so wrong.
>
> raindat <- read.csv('my data set',header=TRUE)
> yearcorr<-min(raindat$Year)-1
> years<-unique(raindat$Year)
> rainmonth<-as.data.frame(matrix(0,nrow=2,ncol=12))
> for(year in years) {
>   for(month in 1:12) {
>     if(any(raindat$Year==year&raindat$Month==month))
>       rainmonth[year-yearcorr,month]<-
>       length((which(raindat$Rain >=
> 0.1))[raindat$Year==year&raindat$Month==month])
>   }
> }
> rownames(rainmonth)<-years
> names(rainmonth)<-month.abb
> rainmonth
>
> Thank you so much.
>
>
> Arshad
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Tue May 19 17:57:19 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 19 May 2015 07:57:19 -0800
Subject: [R] Count number in r
In-Reply-To: <CAAPm8Oo4=CNrijMyh75g6CR4X7-OJQJNpO0Kv0uG_24-CYoz+g@mail.gmail.com>
Message-ID: <02090DC0A96.0000037Djrkrideau@inbox.com>

And another approach just for the heck of it.

library(plyr)

# where dat1 is your data 
dd1  <-  subset(dat1, Rain >= .01)

dd1$Year  <-  as.factor(dd1$Year)
dd1$Month  <-  as.factor(dd1$Month)

count (dd1, .(Year, Month))

John Kane

Kingston ON Canada


> -----Original Message-----
> From: hafizuddinarshad21 at gmail.com
> Sent: Tue, 19 May 2015 03:10:32 -0700
> To: r-help at r-project.org
> Subject: [R] Count number in r
> 
> Dear R users,
> 
> Could someone help me on this? I have this kind of data set:
> 
> structure(list(Year = c(1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L), Month = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L), Rain = c(58.9, 74.6, 17.7, 7.8, 1.2, 1, 5.3, 0.7,
> 1.2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 10.4, 17.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)), .Names =
> c("Year",
> "Month", "Rain"), class = "data.frame", row.names = c(NA, -44L
> ))
> 
> I want to count data in "Rain" that is greater and equal to 0.1 mm
> according to their "Month" and "Year". I have used this code, but it
> seems
> so wrong.
> 
> raindat <- read.csv('my data set',header=TRUE)
> yearcorr<-min(raindat$Year)-1
> years<-unique(raindat$Year)
> rainmonth<-as.data.frame(matrix(0,nrow=2,ncol=12))
> for(year in years) {
>   for(month in 1:12) {
>     if(any(raindat$Year==year&raindat$Month==month))
>       rainmonth[year-yearcorr,month]<-
>       length((which(raindat$Rain >=
> 0.1))[raindat$Year==year&raindat$Month==month])
>   }
> }
> rownames(rainmonth)<-years
> names(rainmonth)<-month.abb
> rainmonth
> 
> Thank you so much.
> 
> 
> Arshad
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From johnwasige at gmail.com  Tue May 19 18:26:35 2015
From: johnwasige at gmail.com (John Wasige)
Date: Tue, 19 May 2015 18:26:35 +0200
Subject: [R] Count number in r
In-Reply-To: <02090DC0A96.0000037Djrkrideau@inbox.com>
References: <CAAPm8Oo4=CNrijMyh75g6CR4X7-OJQJNpO0Kv0uG_24-CYoz+g@mail.gmail.com>
	<02090DC0A96.0000037Djrkrideau@inbox.com>
Message-ID: <CAJgdCD6O9FmL8QNWN6O3jgi5hyO7f82we7rU9Pprq+k5na5L8Q@mail.gmail.com>

Dear all,

I am kindly requesting for help on how I can count pixels with value less
and equal to -0.08 for a raster stack.

Thanks for your help

John

On Tue, May 19, 2015 at 5:57 PM, John Kane <jrkrideau at inbox.com> wrote:

> And another approach just for the heck of it.
>
> library(plyr)
>
> # where dat1 is your data
> dd1  <-  subset(dat1, Rain >= .01)
>
> dd1$Year  <-  as.factor(dd1$Year)
> dd1$Month  <-  as.factor(dd1$Month)
>
> count (dd1, .(Year, Month))
>
> John Kane
>
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: hafizuddinarshad21 at gmail.com
> > Sent: Tue, 19 May 2015 03:10:32 -0700
> > To: r-help at r-project.org
> > Subject: [R] Count number in r
> >
> > Dear R users,
> >
> > Could someone help me on this? I have this kind of data set:
> >
> > structure(list(Year = c(1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> > 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> > 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> > 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> > 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> > 1971L, 1971L), Month = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > 2L, 2L, 2L), Rain = c(58.9, 74.6, 17.7, 7.8, 1.2, 1, 5.3, 0.7,
> > 1.2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 10.4, 17.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)), .Names =
> > c("Year",
> > "Month", "Rain"), class = "data.frame", row.names = c(NA, -44L
> > ))
> >
> > I want to count data in "Rain" that is greater and equal to 0.1 mm
> > according to their "Month" and "Year". I have used this code, but it
> > seems
> > so wrong.
> >
> > raindat <- read.csv('my data set',header=TRUE)
> > yearcorr<-min(raindat$Year)-1
> > years<-unique(raindat$Year)
> > rainmonth<-as.data.frame(matrix(0,nrow=2,ncol=12))
> > for(year in years) {
> >   for(month in 1:12) {
> >     if(any(raindat$Year==year&raindat$Month==month))
> >       rainmonth[year-yearcorr,month]<-
> >       length((which(raindat$Rain >=
> > 0.1))[raindat$Year==year&raindat$Month==month])
> >   }
> > }
> > rownames(rainmonth)<-years
> > names(rainmonth)<-month.abb
> > rainmonth
> >
> > Thank you so much.
> >
> >
> > Arshad
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
John Wasige
"Birds born in a Cage think Flying is an illness."

	[[alternative HTML version deleted]]


From soe.xiyan at gmail.com  Tue May 19 18:37:13 2015
From: soe.xiyan at gmail.com (Soe Xiyan)
Date: Tue, 19 May 2015 23:37:13 +0700
Subject: [R] Count unchanged class attribute
Message-ID: <CAMvMaMZNkTo=WtwzQ13o9O+6G8e6eBX3mL9p8G5kfaEea=feSw@mail.gmail.com>

Maybe someone can help me.
Suppose I have data-set like this:

  Netto   Bruto  class
1 10      1000    yes
2 100     20      yes


  Netto   Bruto  class
1 101     1000    yes
2 100     210     no


  Netto   Bruto  class
1 10      10      yes
2 12      28      yes
3 100     20      yes

  Netto   Bruto  class
1 120     200     no
2 400     20      yes


  Netto   Bruto  class
1 110     12000   yes
2 1100    120     yes
3 120     100     yes
4 1140    125     yes

How to calculate the number of classes has changed.
The expected result is
- class changed    2
- class unchanged  3


Thank you so much.
Soe Xiyan

	[[alternative HTML version deleted]]


From jainsley at gmail.com  Tue May 19 18:38:39 2015
From: jainsley at gmail.com (Joshua Ainsley)
Date: Tue, 19 May 2015 12:38:39 -0400
Subject: [R] RJDBC and Unicode characters on Windows
Message-ID: <CAE_ZCEnUypE_ukBvXfw6iRyLBP_wd0a-=qan8G4Z7-y6PUqYfQ@mail.gmail.com>

Hello,

I am using the RJDBC library to connect to a SQL database and pull out text
that includes Hebrew characters. If I do this on a Mac, the data frames I
construct display the characters properly. If I do it on a Windows PC, then
the characters are converted to strings like this:

<U+05DE><U+05E2><U+05D5><U+05EA> <U+05D7><U+05D8><U+05D9><U+05DD>

I have tried "UTF-8", "UCS-2LE", "UTF-8-BOM", and "UTF-16LE" encodings with
no luck. Any suggestions on getting the data to display properly?

Thanks,
Josh

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Tue May 19 22:14:56 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 19 May 2015 12:14:56 -0800
Subject: [R] Count number in r
In-Reply-To: <CAJgdCD6O9FmL8QNWN6O3jgi5hyO7f82we7rU9Pprq+k5na5L8Q@mail.gmail.com>
References: <02090dc0a96.0000037djrkrideau@inbox.com>
	<caapm8oo4=cnrijmyh75g6cr4x7-ojqjnpo0kv0ug_24-cyoz+g@mail.gmail.com>
Message-ID: <0448DE27832.0000084Fjrkrideau@inbox.com>


If nothing suggested in this thread help I'd suggest asking in R-sig-Geo where they will be more familiar with the issues.

Please do not post in HTML. It can serious mangle code to the point it is indecipherable.  

John Kane
Kingston ON Canada

-----Original Message-----
From: johnwasige at gmail.com
Sent: Tue, 19 May 2015 18:26:35 +0200
To: jrkrideau at inbox.com
Subject: Re: [R] Count number in r

Dear all,

I am kindly requesting for help on how I can count pixels with value less and equal to -0.08 for a raster stack.

Thanks for your help

John

On Tue, May 19, 2015 at 5:57 PM, John Kane <jrkrideau at inbox.com> wrote:

	And another approach just for the heck of it.

 library(plyr)

 # where dat1 is your data
 dd1? <-? subset(dat1, Rain >= .01)

 dd1$Year? <-? as.factor(dd1$Year)
 dd1$Month? <-? as.factor(dd1$Month)

 count (dd1, .(Year, Month))

 John Kane

 Kingston ON Canada

 > -----Original Message-----
 > From: hafizuddinarshad21 at gmail.com
 > Sent: Tue, 19 May 2015 03:10:32 -0700
 > To: r-help at r-project.org
 > Subject: [R] Count number in r
 >
 > Dear R users,
 >
 > Could someone help me on this? I have this kind of data set:
 >
 > structure(list(Year = c(1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
 > 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
 > 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
 > 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
 > 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
 > 1971L, 1971L), Month = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
 > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
 > 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
 > 2L, 2L, 2L), Rain = c(58.9, 74.6, 17.7, 7.8, 1.2, 1, 5.3, 0.7,
 > 1.2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
 > 0, 10.4, 17.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)), .Names =
 > c("Year",
 > "Month", "Rain"), class = "data.frame", row.names = c(NA, -44L
 > ))
 >
 > I want to count data in "Rain" that is greater and equal to 0.1 mm
 > according to their "Month" and "Year". I have used this code, but it
 > seems
 > so wrong.
 >
 > raindat <- read.csv('my data set',header=TRUE)
 > yearcorr<-min(raindat$Year)-1
 > years<-unique(raindat$Year)
 > rainmonth<-as.data.frame(matrix(0,nrow=2,ncol=12))
 > for(year in years) {
 >? ?for(month in 1:12) {
 >? ? ?if(any(raindat$Year==year&raindat$Month==month))
 >? ? ? ?rainmonth[year-yearcorr,month]<-
 >? ? ? ?length((which(raindat$Rain >=
 > 0.1))[raindat$Year==year&raindat$Month==month])
 >? ?}
 > }
 > rownames(rainmonth)<-years
 > names(rainmonth)<-month.abb
 > rainmonth
 >
 > Thank you so much.
 >
 >
 > Arshad
 >
 >? ? ? ?[[alternative HTML version deleted]]
 >
 > ______________________________________________
 > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 > PLEASE do read the posting guide
 > http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 > and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
 Can't remember your password? Do you need a strong and secure password?
 Use Password manager! It stores your passwords & protects your account.

 ______________________________________________
 R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 PLEASE do read the posting guide http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 and provide commented, minimal, self-contained, reproducible code.

-- 

John Wasige
"Birds born in a Cage think Flying is an illness."

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From lvest09 at student.sdu.dk  Tue May 19 22:37:13 2015
From: lvest09 at student.sdu.dk (Livia Maria Vestergaard)
Date: Tue, 19 May 2015 20:37:13 +0000
Subject: [R] Urgent :) Output interpretation: standard error of lm dummy
 variable
Message-ID: <2DFEDD9D3576FB419C7BF7511E983C964AE439FB@ADM-EXMBX10D.adm.c.sdu.dk>

Hi :)

I have an an examination tomorrow, and don't quite understand how R calculated the values. 

Yes. You are right R^2=0.02166 :)
As mentioned It is a dummy variable  model with the 5 regions of Denmark as 4 independent dummy variables and price as the dependent variable. 

 price = 10.325 - 0.176*Sjaeland - 0.368 * NJylland - 0.230*MJylland - 0.120* Syddanmark

I will probably be asked how to interpret the standard error = 0.7348 on 342199 degrees of freedom (= 342 204 observations - 5 categories); about the 5 standard errors for the beta values, the F-statistic = 1894 on 4 categories and the p-value ? 0. But I don't quite understand how R reached the outputs and what parameter are F-distributed, what the standard errors says something about and the standard errors and the F-statistic = 1894  when it is a dummy variable model. 

Hopefully the answer is out there somewhere  and you can help :)

Best  Livia
________________________________________
Fra: Livia Maria Vestergaard
Sendt: 19. maj 2015 10:16
Til: r-help at r-project.org
Emne: [R] Output interpretation: standard error of lm dummy variable

Hi guys

I have a statistical question to an analyse I ran in R. It is a dummy variable  model with the 5 regions of Denmark as 4 independent dummy variables and price as the dependent variable:

price = 10.325 - 0.176*Sjaeland - 0.368 * NJylland - 0.230*MJylland - 0.120* Syddanmark

I understand the R^2 = 0.7348  - that it shows the explanatory force of the model (between 0 and 1)
My question is simply how to interpret the standard error = 0.7348 on 342199 degrees of freedom? How is it calculated when the model is a dummy variable model. And what does  it mean that the F-statistic says that there are 1894 on 4 and 342199 DF (degrees if freedom?) with a p-value < 0?

I have been searching for hours - and can't quite figure out how R reached the numbers and how to interpret the output of standard error and the p-value of the dummy model.

I really hope you can help :)

Best Livia
-------------- n?ste del --------------
En vedh?ftet fil der ikke var tekst, er blevet fjernet...
Navn: Regioner.png
Type: image/png
St?rrelse: 67604 bytes
Beskrivelse: Regioner.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150519/60e64c21/attachment.png>

From mi_westphal at yahoo.com  Tue May 19 22:23:13 2015
From: mi_westphal at yahoo.com (michael westphal)
Date: Tue, 19 May 2015 20:23:13 +0000 (UTC)
Subject: [R] Fixed effects regression and robust regression
Message-ID: <647852567.2141686.1432066993630.JavaMail.yahoo@mail.yahoo.com>

Hello:
I am using R 3.0.2. ?
I have panel data on countries' renewable energy net generation (and installed capacity) over time. ?I am regressing these dependent variables on various socioeconomic variables, as well as binary policy variables. ?I have have done basic OLS, but I wanted to explore both fixed effects models, as there are likely significant country effects (using plm) and robust regression (using rlm), as Q-Q plots indicate that there are some strong outliers. ?This might be a question of apples and oranges, but how do I compare the goodness of fit of the fixed effects models with the robust regression models? ?One can use F-tests to compare OLS and the fixed effects, and since the OLS and robust regressions have the same number of DFs, looking at the residual standard error is insightful. ?Any help would be appreciated.
Cheers,
Michael

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue May 19 22:58:39 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 19 May 2015 13:58:39 -0700
Subject: [R] Fixed effects regression and robust regression
In-Reply-To: <647852567.2141686.1432066993630.JavaMail.yahoo@mail.yahoo.com>
References: <647852567.2141686.1432066993630.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CACk-te2yK_WvV0GqBsqFeJhGD6exNkaVaaS1oVZTVe2h+95R4w@mail.gmail.com>

On Tue, May 19, 2015 at 1:23 PM, michael westphal via R-help
<r-help at r-project.org> wrote:

You can't compare them (statistically -- you can of course draw
pictures). Note, from ?rlm:

" Note that the df.residual component is deliberately set to NA to
avoid inappropriate estimation of the residual scale from the residual
mean square by "lm" methods. "

Further questions should probably go to a statistics list like
stats.stackexchange.com, as statistical questions are generally
offtopic here.

Cheers,
Bert



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll


From jdnewmil at dcn.davis.CA.us  Wed May 20 00:11:41 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 19 May 2015 15:11:41 -0700
Subject: [R] Urgent :) Output interpretation: standard error of lm dummy
	variable
In-Reply-To: <2DFEDD9D3576FB419C7BF7511E983C964AE439FB@ADM-EXMBX10D.adm.c.sdu.dk>
References: <2DFEDD9D3576FB419C7BF7511E983C964AE439FB@ADM-EXMBX10D.adm.c.sdu.dk>
Message-ID: <D84AA58B-F81E-4F75-B309-2F58E743972C@dcn.davis.CA.us>

Technically it is not on topic to discuss the statistics behind R calculations here, and certainly not our job to do so within the context of your educational institution's schedule. However, you have the power to read the source code of any function in R or contributed packages, so go for it. Just enter the name of most functions without parentheses at the R command line. Page 43 of [1] should help for more deeply hidden code.

[1] http://cran.r-project.org/doc/Rnews/Rnews_2006-4.pdf
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 19, 2015 1:37:13 PM PDT, Livia Maria Vestergaard <lvest09 at student.sdu.dk> wrote:
>Hi :)
>
>I have an an examination tomorrow, and don't quite understand how R
>calculated the values. 
>
>Yes. You are right R^2=0.02166 :)
>As mentioned It is a dummy variable  model with the 5 regions of
>Denmark as 4 independent dummy variables and price as the dependent
>variable. 
>
>price = 10.325 - 0.176*Sjaeland - 0.368 * NJylland - 0.230*MJylland -
>0.120* Syddanmark
>
>I will probably be asked how to interpret the standard error = 0.7348
>on 342199 degrees of freedom (= 342 204 observations - 5 categories);
>about the 5 standard errors for the beta values, the F-statistic = 1894
>on 4 categories and the p-value ? 0. But I don't quite understand how R
>reached the outputs and what parameter are F-distributed, what the
>standard errors says something about and the standard errors and the
>F-statistic = 1894  when it is a dummy variable model. 
>
>Hopefully the answer is out there somewhere  and you can help :)
>
>Best  Livia
>________________________________________
>Fra: Livia Maria Vestergaard
>Sendt: 19. maj 2015 10:16
>Til: r-help at r-project.org
>Emne: [R] Output interpretation: standard error of lm dummy variable
>
>Hi guys
>
>I have a statistical question to an analyse I ran in R. It is a dummy
>variable  model with the 5 regions of Denmark as 4 independent dummy
>variables and price as the dependent variable:
>
>price = 10.325 - 0.176*Sjaeland - 0.368 * NJylland - 0.230*MJylland -
>0.120* Syddanmark
>
>I understand the R^2 = 0.7348  - that it shows the explanatory force of
>the model (between 0 and 1)
>My question is simply how to interpret the standard error = 0.7348 on
>342199 degrees of freedom? How is it calculated when the model is a
>dummy variable model. And what does  it mean that the F-statistic says
>that there are 1894 on 4 and 342199 DF (degrees if freedom?) with a
>p-value < 0?
>
>I have been searching for hours - and can't quite figure out how R
>reached the numbers and how to interpret the output of standard error
>and the p-value of the dummy model.
>
>I really hope you can help :)
>
>Best Livia
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Wed May 20 03:00:58 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 20 May 2015 13:00:58 +1200
Subject: [R] Count unchanged class attribute
In-Reply-To: <CAMvMaMZNkTo=WtwzQ13o9O+6G8e6eBX3mL9p8G5kfaEea=feSw@mail.gmail.com>
References: <CAMvMaMZNkTo=WtwzQ13o9O+6G8e6eBX3mL9p8G5kfaEea=feSw@mail.gmail.com>
Message-ID: <555BDCCA.7030404@auckland.ac.nz>

On 20/05/15 04:37, Soe Xiyan wrote:
> Maybe someone can help me.
> Suppose I have data-set like this:
>
>    Netto   Bruto  class
> 1 10      1000    yes
> 2 100     20      yes
>
>
>    Netto   Bruto  class
> 1 101     1000    yes
> 2 100     210     no
>
>
>    Netto   Bruto  class
> 1 10      10      yes
> 2 12      28      yes
> 3 100     20      yes
>
>    Netto   Bruto  class
> 1 120     200     no
> 2 400     20      yes
>
>
>    Netto   Bruto  class
> 1 110     12000   yes
> 2 1100    120     yes
> 3 120     100     yes
> 4 1140    125     yes
>
> How to calculate the number of classes has changed.
> The expected result is
> - class changed    2
> - class unchanged  3

The actual structure of your "data set" is unclear.  You appear to have 
your data stored in a number of separate data frames, but this is not 
made explicit.  The details must be specified in order for anyone to be
able to help you.

Moreover it is not at all clear what you want to achieve.

Why is "class changed" equal to 2 and "class unchanged" equal to 3?

I count 2 "no"-s and 11 "yes"-s (not 3 "yes"-s).

There are many clever people who subscribe to the R-help list, but few 
if any of them are mind-readers.

cheers,

Rolf Turner


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From jrkrideau at inbox.com  Wed May 20 04:02:21 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 19 May 2015 18:02:21 -0800
Subject: [R] Count unchanged class attribute
In-Reply-To: <CAMvMaMZNkTo=WtwzQ13o9O+6G8e6eBX3mL9p8G5kfaEea=feSw@mail.gmail.com>
Message-ID: <075163F297C.00000C78jrkrideau@inbox.com>

Is this a list of data.frames or what?

Please have a look at one or both of these for some ideas of how to ask a question and provide information on the problem.  The better you can describe what you have and what you need the better people can help.
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html


John Kane
Kingston ON Canada


> -----Original Message-----
> From: soe.xiyan at gmail.com
> Sent: Tue, 19 May 2015 23:37:13 +0700
> To: r-help at r-project.org
> Subject: [R] Count unchanged class attribute
> 
> Maybe someone can help me.
> Suppose I have data-set like this:
> 
>   Netto   Bruto  class
> 1 10      1000    yes
> 2 100     20      yes
> 
> 
>   Netto   Bruto  class
> 1 101     1000    yes
> 2 100     210     no
> 
> 
>   Netto   Bruto  class
> 1 10      10      yes
> 2 12      28      yes
> 3 100     20      yes
> 
>   Netto   Bruto  class
> 1 120     200     no
> 2 400     20      yes
> 
> 
>   Netto   Bruto  class
> 1 110     12000   yes
> 2 1100    120     yes
> 3 120     100     yes
> 4 1140    125     yes
> 
> How to calculate the number of classes has changed.
> The expected result is
> - class changed    2
> - class unchanged  3
> 
> 
> Thank you so much.
> Soe Xiyan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From gunter.berton at gene.com  Wed May 20 05:04:58 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 19 May 2015 20:04:58 -0700
Subject: [R] Count unchanged class attribute
In-Reply-To: <075163F297C.00000C78jrkrideau@inbox.com>
References: <CAMvMaMZNkTo=WtwzQ13o9O+6G8e6eBX3mL9p8G5kfaEea=feSw@mail.gmail.com>
	<075163F297C.00000C78jrkrideau@inbox.com>
Message-ID: <CACk-te0+bO2jc9Uafwx_5B5CeuwFJxAZWRqcTvrrrewCUNC_Dw@mail.gmail.com>

Probably "or what."

This demonstrates a fundamental conundrum: many users or prospective users
of R have had little exposure to data structures in their formal education
and therefore can be flummoxed by R's fussiness -- as any programming
language must necessarily be. Consider: data frames, matrices, lists,
"classes", objects with attributes (e.g. factors),...

Excel, which is basically structureless, of course, exacerbates the
problem. Those accustomed to its tolerance (and the confusion that results)
expect R to behave the same way. Education is the only recourse, either in
formal courses or through R tutorials that strongly emphasize this aspect
of interacting with R and especially writing effective code. But that
demands effort and, to some extent, aptitude... both of which seem to be in
increasingly short supply amidst the worldwide explosion in R's usage.

Of course, feel free to disagree... Just my $.02

Cheers,
Bert


Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
Clifford Stoll



On Tue, May 19, 2015 at 7:02 PM, John Kane <jrkrideau at inbox.com> wrote:

> Is this a list of data.frames or what?
>
> Please have a look at one or both of these for some ideas of how to ask a
> question and provide information on the problem.  The better you can
> describe what you have and what you need the better people can help.
>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> and http://adv-r.had.co.nz/Reproducibility.html
>
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: soe.xiyan at gmail.com
> > Sent: Tue, 19 May 2015 23:37:13 +0700
> > To: r-help at r-project.org
> > Subject: [R] Count unchanged class attribute
> >
> > Maybe someone can help me.
> > Suppose I have data-set like this:
> >
> >   Netto   Bruto  class
> > 1 10      1000    yes
> > 2 100     20      yes
> >
> >
> >   Netto   Bruto  class
> > 1 101     1000    yes
> > 2 100     210     no
> >
> >
> >   Netto   Bruto  class
> > 1 10      10      yes
> > 2 12      28      yes
> > 3 100     20      yes
> >
> >   Netto   Bruto  class
> > 1 120     200     no
> > 2 400     20      yes
> >
> >
> >   Netto   Bruto  class
> > 1 110     12000   yes
> > 2 1100    120     yes
> > 3 120     100     yes
> > 4 1140    125     yes
> >
> > How to calculate the number of classes has changed.
> > The expected result is
> > - class changed    2
> > - class unchanged  3
> >
> >
> > Thank you so much.
> > Soe Xiyan
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Wed May 20 07:54:29 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 19 May 2015 21:54:29 -0800
Subject: [R] Count unchanged class attribute
In-Reply-To: <CACk-te0+bO2jc9Uafwx_5B5CeuwFJxAZWRqcTvrrrewCUNC_Dw@mail.gmail.com>
References: <075163f297c.00000c78jrkrideau@inbox.com>
	<camvmamznkto=wtwzq13o9o+6g8e6ebx3ml9p8g5kfaeea=fesw@mail.gmail.com>
Message-ID: <09583DE8A20.00000E3Ajrkrideau@inbox.com>

John Kane
Kingston ON Canada

-----Original Message-----
From: gunter.berton at gene.com
Sent: Tue, 19 May 2015 20:04:58 -0700
To: jrkrideau at inbox.com
Subject: Re: [R] Count unchanged class attribute

Probably "or what."

This demonstrates a fundamental conundrum: many users or prospective users of R have had little exposure to data structures in their formal education and therefore can be flummoxed by R's fussiness -- as any programming language must necessarily be. Consider: data frames, matrices, lists, "classes", objects with attributes (e.g. factors),...
==========================
Nonsense, I am sure that weird feeling that my brain was being wrung out like a dishcloth, that I felt for the first 3-5 weeks was due to something I ate and had nothing to due with SPSS or SAS.



===========================


Excel, which is basically structureless, of course, exacerbates the problem. Those accustomed to its tolerance (and the confusion that results) expect R to behave the same way. Education is the only recourse, either in formal courses or through R tutorials that strongly emphasize this aspect of interacting with R and especially writing effective code. But that demands effort and, to some extent, aptitude... both of which seem to be in increasingly short supply amidst the worldwide explosion in R's usage.
================================
I don't think it's lack of aptitude but  I seldom see much in the various tutorials and books that really emphasis data structures or typing so people can spend a lot of time figuring out what a list is. Who, me?

I agree that Excel is scary. I believe I mentioned before that I live in fear that some medical spreadsheet will calculate a medical dose on my telephone number rather than my weight.  Of course, Excel being Excel, it would probably obligingly translate a character-formatted telephone number into a real number. I must try this the next time I get close to a machine with Excel.  
===============================
Of course, feel free to disagree... Just my $.02

Cheers,

Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge is certainly not wisdom."
Clifford Stoll

On Tue, May 19, 2015 at 7:02 PM, John Kane <jrkrideau at inbox.com> wrote:

	Is this a list of data.frames or what?

 Please have a look at one or both of these for some ideas of how to ask a question and provide information on the problem.? The better you can describe what you have and what you need the better people can help.
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example] and http://adv-r.had.co.nz/Reproducibility.html [http://adv-r.had.co.nz/Reproducibility.html]

 John Kane
 Kingston ON Canada

 > -----Original Message-----
 > From: soe.xiyan at gmail.com
 > Sent: Tue, 19 May 2015 23:37:13 +0700
 > To: r-help at r-project.org
 > Subject: [R] Count unchanged class attribute
 >
 > Maybe someone can help me.
 > Suppose I have data-set like this:
 >
 >? ?Netto? ?Bruto? class
 > 1 10? ? ? 1000? ? yes
 > 2 100? ? ?20? ? ? yes
 >
 >
 >? ?Netto? ?Bruto? class
 > 1 101? ? ?1000? ? yes
 > 2 100? ? ?210? ? ?no
 >
 >
 >? ?Netto? ?Bruto? class
 > 1 10? ? ? 10? ? ? yes
 > 2 12? ? ? 28? ? ? yes
 > 3 100? ? ?20? ? ? yes
 >
 >? ?Netto? ?Bruto? class
 > 1 120? ? ?200? ? ?no
 > 2 400? ? ?20? ? ? yes
 >
 >
 >? ?Netto? ?Bruto? class
 > 1 110? ? ?12000? ?yes
 > 2 1100? ? 120? ? ?yes
 > 3 120? ? ?100? ? ?yes
 > 4 1140? ? 125? ? ?yes
 >
 > How to calculate the number of classes has changed.
 > The expected result is
 > - class changed? ? 2
 > - class unchanged? 3
 >
 >
 > Thank you so much.
 > Soe Xiyan
 >
 >? ? ? ?[[alternative HTML version deleted]]
 >
 > ______________________________________________
 > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 > PLEASE do read the posting guide
 > http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 > and provide commented, minimal, self-contained, reproducible code.

 ____________________________________________________________
 Can't remember your password? Do you need a strong and secure password?
 Use Password manager! It stores your passwords & protects your account.

 ______________________________________________
 R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 PLEASE do read the posting guide http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From kdwang at google.com  Wed May 20 07:21:16 2015
From: kdwang at google.com (Kevin Wang)
Date: Tue, 19 May 2015 22:21:16 -0700
Subject: [R] Sequentially serializing large objects
Message-ID: <CAKSOrHKu3YTHPJ1Fdu1QhksVKR++Ye4nzxqSFN0wVtLSumsrQg@mail.gmail.com>

Hi r-help, I've been having some issues serializing large objects over a
socket. I can reproduce the issue with the following two instances:

Instance 1:
> conn <- socketConnection("localhost", 34533, server = TRUE, open = "w+b")
> for (i in 1:10) { serialize(1:2e9, conn) }

Instance 2:
> conn <- socketConnection("localhost", 34533, open = "r+b")
> for (i in 1:10) { unserialize(conn) }

This gives me

Error in unserialize(conn) : error reading from connection

on the second process , and if I ignore the error, future unserialize calls
result in

Error in unserialize(conn) : unknown input format.

I'm running R 3.1.1. How can I unserialize the objects properly? Both of
these error messages aren't particularly helpful. I've tried serializing to
a raw vector then serializing chunks at a time, but for some reason doing
the subsetting makes R's memory usage balloon way above a copy of the large
object. writeBin() also seems to ignore the size parameter, so that doesn't
work either.

Thanks!

Kevin Wang | Software Engineer | kdwang at google.com | 248.327.3647

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed May 20 08:36:54 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 20 May 2015 16:36:54 +1000
Subject: [R] Count unchanged class attribute
In-Reply-To: <CACk-te0+bO2jc9Uafwx_5B5CeuwFJxAZWRqcTvrrrewCUNC_Dw@mail.gmail.com>
References: <CAMvMaMZNkTo=WtwzQ13o9O+6G8e6eBX3mL9p8G5kfaEea=feSw@mail.gmail.com>
	<075163F297C.00000C78jrkrideau@inbox.com>
	<CACk-te0+bO2jc9Uafwx_5B5CeuwFJxAZWRqcTvrrrewCUNC_Dw@mail.gmail.com>
Message-ID: <CA+8X3fXzCtqKTyXcXO-XbjC_FC6gvWwcO-kBdwM+Kk3r7mSbPg@mail.gmail.com>

Hi Xiyan,
I have to admit that your puzzle very nearly stumped me. At first I
thought the question was:

"What are the numbers of rows with changed and unchanged class values?"

That doesn't work as there are at most four rows and your answer sums
to five. I then tried:

"How many times does at least one value of class change between
successive data frames?"

Nope, four have at least one change. Could it have been:

"Using unique combinations of the values of Netto and Bruto, how many
changes have occurred?"

Wrong again, there are 12 combinations, not five. Surely you don't mean:

"In how many data frames does ta least one value of class equal 'no'?"

df1<-data.frame(Netto=c(10,100),Bruto=c(1000,20),class=c("yes","yes"))
df2<-data.frame(Netto=c(101,100),Bruto=c(1000,210),class=c("yes","no"))
df3<-data.frame(Netto=c(10,12,100),Bruto=c(10,28,20),class=c("yes","yes","yes"))
df4<-data.frame(Netto=c(120,400),Bruto=c(200,20),class=c("no","yes"))
df5<-data.frame(Netto=c(110,1100,120,1140),Bruto=c(12000,120,100,125),
 class=c("yes","yes","yes","yes"))
sxdat<-list(df1,df2,df3,df4,df5)
table(ifelse(unlist(lapply(sxdat,function(x)
return(any(x$class=="no")))),"changed","unchanged"))

Jim

On Wed, May 20, 2015 at 1:04 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> Probably "or what."
>
> This demonstrates a fundamental conundrum: many users or prospective users
> of R have had little exposure to data structures in their formal education
> and therefore can be flummoxed by R's fussiness -- as any programming
> language must necessarily be. Consider: data frames, matrices, lists,
> "classes", objects with attributes (e.g. factors),...
>
> Excel, which is basically structureless, of course, exacerbates the
> problem. Those accustomed to its tolerance (and the confusion that results)
> expect R to behave the same way. Education is the only recourse, either in
> formal courses or through R tutorials that strongly emphasize this aspect
> of interacting with R and especially writing effective code. But that
> demands effort and, to some extent, aptitude... both of which seem to be in
> increasingly short supply amidst the worldwide explosion in R's usage.
>
> Of course, feel free to disagree... Just my $.02
>
> Cheers,
> Bert
>
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge is
> certainly not wisdom."
> Clifford Stoll
>
>
>
> On Tue, May 19, 2015 at 7:02 PM, John Kane <jrkrideau at inbox.com> wrote:
>
>> Is this a list of data.frames or what?
>>
>> Please have a look at one or both of these for some ideas of how to ask a
>> question and provide information on the problem.  The better you can
>> describe what you have and what you need the better people can help.
>>
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> and http://adv-r.had.co.nz/Reproducibility.html
>>
>>
>> John Kane
>> Kingston ON Canada
>>
>>
>> > -----Original Message-----
>> > From: soe.xiyan at gmail.com
>> > Sent: Tue, 19 May 2015 23:37:13 +0700
>> > To: r-help at r-project.org
>> > Subject: [R] Count unchanged class attribute
>> >
>> > Maybe someone can help me.
>> > Suppose I have data-set like this:
>> >
>> >   Netto   Bruto  class
>> > 1 10      1000    yes
>> > 2 100     20      yes
>> >
>> >
>> >   Netto   Bruto  class
>> > 1 101     1000    yes
>> > 2 100     210     no
>> >
>> >
>> >   Netto   Bruto  class
>> > 1 10      10      yes
>> > 2 12      28      yes
>> > 3 100     20      yes
>> >
>> >   Netto   Bruto  class
>> > 1 120     200     no
>> > 2 400     20      yes
>> >
>> >
>> >   Netto   Bruto  class
>> > 1 110     12000   yes
>> > 2 1100    120     yes
>> > 3 120     100     yes
>> > 4 1140    125     yes
>> >
>> > How to calculate the number of classes has changed.
>> > The expected result is
>> > - class changed    2
>> > - class unchanged  3
>> >
>> >
>> > Thank you so much.
>> > Soe Xiyan
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ____________________________________________________________
>> Can't remember your password? Do you need a strong and secure password?
>> Use Password manager! It stores your passwords & protects your account.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Wed May 20 10:18:53 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 20 May 2015 09:18:53 +0100
Subject: [R] Fixed effects regression and robust regression
In-Reply-To: <647852567.2141686.1432066993630.JavaMail.yahoo@mail.yahoo.com>
References: <647852567.2141686.1432066993630.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1A8C1289955EF649A09086A153E267240220C1AF@GBTEDVPEXCMB04.corp.lgc-group.com>

> since the OLS and robust regressions have the same number of DFs, looking
>  at the residual standard error is insightful.  

Sadly not. The residual scale in a robust model is only partly indicative of goodness of fit; robust models intentionally downweight outliers. Much of the difference in scale can be due to downweighting, rather than change in model, especially where outliers are roughly symmetricaly distributed. And the degrees of freedom are not, strictly, the same. You have the same numbers of observations, but once you throw in different weights, it's debatable whether the effective df are really equal to the classical df. In any case degrees of freedom mostly matters as a distribution parameter - if you could trust the distribution to be normal, chi-squared etc you would not need robust statistics.

What you can do, to an extent, is use something like lmRob in the robustbase package to test your fixed effects; comparing the different inferences will tell you something about which effects in OLS are simply artefacts caused by outliers. lmRob uses comparatively recent developments in wald-type inference tests to put the tests on a firmer footing.

S Ellison

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From walke554 at umn.edu  Wed May 20 15:45:01 2015
From: walke554 at umn.edu (walke554)
Date: Wed, 20 May 2015 06:45:01 -0700 (PDT)
Subject: [R] deSolve ODE Output Question
Message-ID: <1432129501132-4707448.post@n4.nabble.com>

Hello,

I am working on a simple ODE problem with the deSolve package, and I was
hoping that someone could answer a question about how the deSolve package
does integration.  

Here is my program:

#The function
STDMod<-function(t,y,p){
	IH = y[1];
	IL = y[2];
	with(as.list(p), {
		dIH.dt = Beta[1,1]*(nH-IH)*IH + Beta[1,2]*(nH-IH)*IL - gamma*IH;
		dIL.dt = Beta[2,1]*(nL-IL)*IH + Beta[2,2]*(nL-IL)*IL - gamma*IL;
		return(list(c(dIH.dt,dIL.dt)));
	})
}

#giving the parameters

Beta = matrix(data=c(10, 0.1, 0.1, 1.0), ncol=2, nrow=2)
nH = 0.2
nL = 0.8
IH0 = 1e-5
IL0 = 0

gamma = 1

p = list(Beta=Beta, gamma=gamma, nH=nH, nL=nL)

y0 = c(IH0, IL0)

#Running the ode integrator

steps= 10;
t = seq(from=0, to=30, by=.01);
out = ode(y=y0, times=t, func=STDMod, parms=p);

My understanding is that the 'out' matrix would be the values of the STDmod
function at each time step, given the initial values of the state parameters
IH and IL.  However, for the very first time step, I am getting a value
different than what the derivative and the initial values add up to.

My output:
<http://r.789695.n4.nabble.com/file/n4707448/ROutput.png> 

but 'IH0' + 'the value of dIH.dt = Beta[1,1]*(nH-IH)*IH +
Beta[1,2]*(nH-IH)*IL - gamma*IH for timestep one' = 1.999e-5.  Is there
something that I am missing?  I am hoping to use this for more complicated
derivatives, but I want to make sure I am using the package correctly first.

Thanks!



--
View this message in context: http://r.789695.n4.nabble.com/deSolve-ODE-Output-Question-tp4707448.html
Sent from the R help mailing list archive at Nabble.com.


From kbrenzinger at gmx.de  Wed May 20 10:58:53 2015
From: kbrenzinger at gmx.de (Brenzo)
Date: Wed, 20 May 2015 01:58:53 -0700 (PDT)
Subject: [R] Error after performing anosim function with vegan
Message-ID: <1432112333501-4707444.post@n4.nabble.com>

Hello,

so I'm relatively new in R, but normally i don't have big problems by using
R. 

But today i struggle a lot with an error message that occurred the first
time.

Error in sort.int(x, na.last = na.last, decreasing = decreasing, ...) : 
  'x' must be atomic

I'm using just a normal anosim function and 2 weeks ago it was working fine
with the same files and the same script. So maybe some of you can help me.

Here is the total script:

> data <-read.csv("H:\\PhD\\Ergebnisse Versuch Norwegen\\T-RFLP\\nirK
> Adonis2.csv")
> fix (data)
> data1 <- (data [,-1])
> fix (data1)
> cca.env<- read.csv ("H:\\PhD\\Ergebnisse Versuch
> Norwegen\\T-RFLP\\env2.csv",
+ header= TRUE, )
> fix(cca.env)
> du<- vegdist(data)
> fix(du)
> attach(cca.env)
> dune.ano <- anosim(du, Sample)
> summary(dune.ano)

Call:
anosim(dat = du, grouping = Sample) 
Dissimilarity: bray 

ANOSIM statistic R:  
      Significance: 0.001 

Permutation: free
Number of permutations: 999

Error in sort.int(x, na.last = na.last, decreasing = decreasing, ...) : 
  'x' must be atomic

it is more or less exactly the same matrix than in the example from R:

> data(dune)
> fix(dune)
> data(dune.env)
> fix(dune.env)
> dune.dist <- vegdist(dune)
> attach(dune.env)
> dune.ano <- anosim(dune.dist, Management)
> summary(dune.ano)

Call:
anosim(dat = dune.dist, grouping = Management) 
Dissimilarity: bray 

ANOSIM statistic R: 0.2579 
      Significance: 0.008 

Permutation: free
Number of permutations: 999

Upper quantiles of permutations (null model):
  90%   95% 97.5%   99% 
0.115 0.151 0.192 0.250 

Dissimilarity ranks between and within classes:
        0%   25%    50%     75%  100%   N
Between  4 58.50 104.00 145.500 188.0 147
BF       5 15.25  25.50  41.250  57.0   3
HF       1  7.25  46.25  68.125  89.5  10
NM       6 64.75 124.50 156.250 181.0  15
SF       3 32.75  53.50  99.250 184.0  15

Greetings Kristof




--
View this message in context: http://r.789695.n4.nabble.com/Error-after-performing-anosim-function-with-vegan-tp4707444.html
Sent from the R help mailing list archive at Nabble.com.


From dieter.anseeuw at inagro.be  Wed May 20 12:03:28 2015
From: dieter.anseeuw at inagro.be (Dieter Anseeuw)
Date: Wed, 20 May 2015 10:03:28 +0000
Subject: [R] subsetting question
Message-ID: <72E5B92E710560479A262E2C2C644391208B1566@BEXCPS01.inagrp.local>

Dear all,
I would like to do multiple actions on a subset of my data. Therefore, I want to create a for loop on the variable "Date" (actually a double for loop on yet another variable, but let's omit that for a moment).
I want to run down every level of "Date" and perform multiple actions on the data from a certain date. Here is my code:

for (i in 1:length(datums)){
meanweight<-mean(dataset1[dataset1$Date==datums[i],]$Weight)
...

However, this subsetting obviously doesn't work. How can I adjust my code so that R runs down all levels of Data in a for loop?
(I need the for loop, not tapply(), sapply(), ...)

Thanks in advance,
Dieter Anseeuw

	[[alternative HTML version deleted]]


From gabriel.weindel at gmail.com  Wed May 20 12:13:17 2015
From: gabriel.weindel at gmail.com (Gabriel WEINDEL)
Date: Wed, 20 May 2015 12:13:17 +0200
Subject: [R] Vincentizing Reaction Time data in R
Message-ID: <555C5E3D.6090103@gmail.com>

Dear all,

For my master thesis, I'm currently working in cognitive neuroscience on 
executive control through measurement of reaction time and I need to get 
my data 'vincentized' with an exclusive use of R set by my statistic 
teacher for a test purpose, for this reason I can't use the python code 
the lab team usually uses.
Despite a dozen hours of research I couldn't find any package or R-code 
which would allow the use of vincentization, that's why I'm querying 
help on the R forum.

So has anyone ever used vincentization in R ?

Best regards,

-- 
Gabriel Weindel
Master student in Neuropsychology - Aix-Marseille University (France)


From pizgy.st288 at gmail.com  Wed May 20 13:49:17 2015
From: pizgy.st288 at gmail.com (=?UTF-8?B?VGhhbmggSHV54buBbiBUcuG6p24=?=)
Date: Wed, 20 May 2015 13:49:17 +0200
Subject: [R] About manipulating NetCDF files in ncdf package.
Message-ID: <CAAKZ4EtGdQ=m-2rN2COPhs5hrw18x13ogcGCjaCK24dRqssXqA@mail.gmail.com>

Dear R-project staffs,

I'm now dealing with some NetCDF files for my scientific work and I'm
reading it and manipulating it with R.
So far I would like to ask some questions:
1. I have a NetCDF file for time-series data (*daily* time step) in a
domain (with longitudes and latitudes) with two variables are two component
of wind speeds (u-wind and v-wind). I would like  to creat a new NetCDF
file with the synthesized wind speed from the two components from the
existing file in the same spatial resolution but with *monthly* time steps.
Which syntax can I use to compile the code for this?
(please find the enclosed picture for variables information)

2. I have another NetCDF file for time-series data *(hourly)*  in a domain
(with longitudes and latitudes) for downward solar radiation which I want
to transfer to *monthly* data.Which syntax can I use to compile the code
for this?

Thanks and looking forward to your guidance.

Best regards,
Thanh Huyen Tran

-- 
Thanh Huyen Tran

*Master student of Hydrosciences and Engineering Programme,*

*Faculty of Environmental Sciences*
*University of Technology Dresden, Germany*
-------------- next part --------------
A non-text attachment was scrubbed...
Name: wind components variables.png
Type: image/png
Size: 10726 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150520/0e7c9e8e/attachment.png>

From ivan.calandra at univ-reims.fr  Wed May 20 16:31:35 2015
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Wed, 20 May 2015 16:31:35 +0200
Subject: [R] subsetting question
In-Reply-To: <72E5B92E710560479A262E2C2C644391208B1566@BEXCPS01.inagrp.local>
References: <72E5B92E710560479A262E2C2C644391208B1566@BEXCPS01.inagrp.local>
Message-ID: <555C9AC7.6040403@univ-reims.fr>

Hi,

What about using functions like aggregate()?
Something like:
aggregate(Weight~datums, data=dataset1, FUN=mean)

If you need to do more things, you can create your own function for 'FUN'

HTH,
Ivan

--
Ivan Calandra, ATER
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 20/05/15 12:03, Dieter Anseeuw a ?crit :
> Dear all,
> I would like to do multiple actions on a subset of my data. Therefore, I want to create a for loop on the variable "Date" (actually a double for loop on yet another variable, but let's omit that for a moment).
> I want to run down every level of "Date" and perform multiple actions on the data from a certain date. Here is my code:
>
> for (i in 1:length(datums)){
> meanweight<-mean(dataset1[dataset1$Date==datums[i],]$Weight)
> ...
>
> However, this subsetting obviously doesn't work. How can I adjust my code so that R runs down all levels of Data in a for loop?
> (I need the for loop, not tapply(), sapply(), ...)
>
> Thanks in advance,
> Dieter Anseeuw
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From john.archie.mckown at gmail.com  Wed May 20 16:38:47 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 20 May 2015 09:38:47 -0500
Subject: [R] Vincentizing Reaction Time data in R
In-Reply-To: <555C5E3D.6090103@gmail.com>
References: <555C5E3D.6090103@gmail.com>
Message-ID: <CAAJSdjhhJwV40YNHyLyqBGh8jrDDcEo0LXD=HTVs+LvPTeabiQ@mail.gmail.com>

On Wed, May 20, 2015 at 5:13 AM, Gabriel WEINDEL <gabriel.weindel at gmail.com>
wrote:

> Dear all,
>
> For my master thesis, I'm currently working in cognitive neuroscience on
> executive control through measurement of reaction time and I need to get my
> data 'vincentized' with an exclusive use of R set by my statistic teacher
> for a test purpose, for this reason I can't use the python code the lab
> team usually uses.
> Despite a dozen hours of research I couldn't find any package or R-code
> which would allow the use of vincentization, that's why I'm querying help
> on the R forum.
>
> So has anyone ever used vincentization in R ?
>

I haven't. And I failed statistics in school. But a Google search got me to
this page, which I hope might be of some help to you. If not, my apologies.

https://stat.ethz.ch/pipermail/r-help/2003-May/034272.html



>
> Best regards,
>
> --
> Gabriel Weindel
> Master student in Neuropsychology - Aix-Marseille University (France)
>


-- 
If someone tell you that nothing is impossible:
Ask him to dribble a football.He's about as useful as a wax frying pan.10
to the 12th power microphones = 1 MegaphoneMaranatha! <><John McKown

	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Wed May 20 16:52:12 2015
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Wed, 20 May 2015 07:52:12 -0700
Subject: [R] About manipulating NetCDF files in ncdf package.
In-Reply-To: <CAAKZ4EtGdQ=m-2rN2COPhs5hrw18x13ogcGCjaCK24dRqssXqA@mail.gmail.com>
References: <CAAKZ4EtGdQ=m-2rN2COPhs5hrw18x13ogcGCjaCK24dRqssXqA@mail.gmail.com>
Message-ID: <4B184193-EA51-429A-97DF-DB64561E8E6D@noaa.gov>

Hi Thanh:

You are confounding  several issues here, and are providing only incomplete information about your data.  The confounded issues are:

1.  How to write a netcdf with a given coordinate system.

2.  How to calculate a monthly average or monthly subsample from a larger sample.

I would guess that you data are really dimensioned something like (time,lat, lon) and what would help is showing the results of say:

str(u_w)

Also, in your original netcdf file there were probably coordinate variables for time, latitude and longitude, you need to read those in and be aware of their dimensions, and the latitude and longitude data will form the basis of your new netcdf file.

To create and write a new netcdf file you will need to understand somewhat the structure of a netcdf file.  As the help for the ncdf4-package says:

> If you want to WRITE data to a new netCDF file, the procedure is to first define the dimensions your data array has, then define the variable, then create the file. So, first call ncdim_def to define the dimensions that your data exists along (for example, latitude, longitude, and time). Then call ncvar_def to define a variable that uses those dimensions, and will hold your data. Then call nc_create to create the netCDF file. Finally, call ncvar_put to write your data to the newly created netCDF file, and nc_close when you are done.
> 

Also look at the following web site:

https://www.image.ucar.edu/GSP/Software/Netcdf/

As for issue two, your data are just 3-D arrays, and it is just a question of normal array averaging or other operations to get you monthly data.

HTH,

-Roy



> On May 20, 2015, at 4:49 AM, Thanh Huy?n Tr?n <pizgy.st288 at gmail.com> wrote:
> 
> Dear R-project staffs,
> 
> I'm now dealing with some NetCDF files for my scientific work and I'm
> reading it and manipulating it with R.
> So far I would like to ask some questions:
> 1. I have a NetCDF file for time-series data (*daily* time step) in a
> domain (with longitudes and latitudes) with two variables are two component
> of wind speeds (u-wind and v-wind). I would like  to creat a new NetCDF
> file with the synthesized wind speed from the two components from the
> existing file in the same spatial resolution but with *monthly* time steps.
> Which syntax can I use to compile the code for this?
> (please find the enclosed picture for variables information)
> 
> 2. I have another NetCDF file for time-series data *(hourly)*  in a domain
> (with longitudes and latitudes) for downward solar radiation which I want
> to transfer to *monthly* data.Which syntax can I use to compile the code
> for this?
> 
> Thanks and looking forward to your guidance.
> 
> Best regards,
> Thanh Huyen Tran
> 
> -- 
> Thanh Huyen Tran
> 
> *Master student of Hydrosciences and Engineering Programme,*
> 
> *Faculty of Environmental Sciences*
> *University of Technology Dresden, Germany*
> <wind components variables.png>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From dcarlson at tamu.edu  Wed May 20 16:54:08 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 20 May 2015 14:54:08 +0000
Subject: [R] Error after performing anosim function with vegan
In-Reply-To: <1432112333501-4707444.post@n4.nabble.com>
References: <1432112333501-4707444.post@n4.nabble.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68D26D@mb02.ads.tamu.edu>

We are not going to be able to help much without the data. You say it is "more or less" the same as the example data so maybe it is "less" similar than you think. 

Another possibility is that you keep using fix() for some reason that you have not explained. That function calls edit() which can strip attributes and that can create problems with some data.frames and matrices as the manual page warns:

"Editing an R object may change it in ways other than are obvious: see the comment under edit. See edit.data.frame for changes that can occur when editing a data frame or matrix."

If you just want to look at the data use, View() not fix().

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Brenzo
Sent: Wednesday, May 20, 2015 3:59 AM
To: r-help at r-project.org
Subject: [R] Error after performing anosim function with vegan

Hello,

so I'm relatively new in R, but normally i don't have big problems by using
R. 

But today i struggle a lot with an error message that occurred the first
time.

Error in sort.int(x, na.last = na.last, decreasing = decreasing, ...) :
  'x' must be atomic

I'm using just a normal anosim function and 2 weeks ago it was working fine
with the same files and the same script. So maybe some of you can help me.

Here is the total script:

> data <-read.csv("H:\\PhD\\Ergebnisse Versuch Norwegen\\T-RFLP\\nirK
> Adonis2.csv")
> fix (data)
> data1 <- (data [,-1])
> fix (data1)
> cca.env<- read.csv ("H:\\PhD\\Ergebnisse Versuch
> Norwegen\\T-RFLP\\env2.csv",
+ header= TRUE, )
> fix(cca.env)
> du<- vegdist(data)
> fix(du)
> attach(cca.env)
> dune.ano <- anosim(du, Sample)
> summary(dune.ano)

Call:
anosim(dat = du, grouping = Sample) 
Dissimilarity: bray 

ANOSIM statistic R:  
      Significance: 0.001 

Permutation: free
Number of permutations: 999

Error in sort.int(x, na.last = na.last, decreasing = decreasing, ...) :
  'x' must be atomic

it is more or less exactly the same matrix than in the example from R:

> data(dune)
> fix(dune)
> data(dune.env)
> fix(dune.env)
> dune.dist <- vegdist(dune)
> attach(dune.env)
> dune.ano <- anosim(dune.dist, Management)
> summary(dune.ano)

Call:
anosim(dat = dune.dist, grouping = Management) 
Dissimilarity: bray 

ANOSIM statistic R: 0.2579 
      Significance: 0.008 

Permutation: free
Number of permutations: 999

Upper quantiles of permutations (null model):
  90%   95% 97.5%   99% 
0.115 0.151 0.192 0.250 

Dissimilarity ranks between and within classes:
        0%   25%    50%     75%  100%   N
Between  4 58.50 104.00 145.500 188.0 147
BF       5 15.25  25.50  41.250  57.0   3
HF       1  7.25  46.25  68.125  89.5  10
NM       6 64.75 124.50 156.250 181.0  15
SF       3 32.75  53.50  99.250 184.0  15

Greetings Kristof




--
View this message in context: http://r.789695.n4.nabble.com/Error-after-performing-anosim-function-with-vegan-tp4707444.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed May 20 17:41:52 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 20 May 2015 08:41:52 -0700
Subject: [R] subsetting question
In-Reply-To: <72E5B92E710560479A262E2C2C644391208B1566@BEXCPS01.inagrp.local>
References: <72E5B92E710560479A262E2C2C644391208B1566@BEXCPS01.inagrp.local>
Message-ID: <CAF8bMcZNAK_Yz0WOmk_k_6hC-RHQGnaig_+poL-Y=3JqruF++g@mail.gmail.com>

Here is a self-contained example of what you might be trying to do.
You would get better answers if you supplied this yourself.

dataset1 <-
data.frame(Date=as.POSIXct(c("2015-04-01","2015-04-01","2015-04-07",
"2015-04-19")), Weight=11:14)
datums <- as.POSIXct(c("2015-04-01", "2015-04-08", "2015-04-19"))
# note that neither dataset1$Date nor datums is a subset of the other

for (i in 1:length(datums)){
    meanweight <- mean(dataset1[dataset1$Date==datums[i],]$Weight)
}

You said is 'obviously' doesn't work, but didn't say in what was wrong with
what it did.  One obvious (to me) thing is that in each iteration you
overwrote the
meanweight assigned in the previous iteration so you end up with only the
last one calculated.  You can fix that by using making meanweight a vector
and assigning elements of it in the loop.

meanWeight <- numeric(length(datums))
for (i in 1:length(datums)){
    meanWeight[i] <- mean(dataset1[dataset1$Date==datums[i],]$Weight)
}
data.frame(datums, meanWeight)
#      datums meanWeight
#1 2015-04-01       11.5
#2 2015-04-08        NaN
#3 2015-04-19       14.0

This looks to me like the appropriate result, but your self-contained
example
would make me more convinced of that.

By the way, why is is important to you to use a for loop and not a function
like
tapply() or aggregate()?  They can cause hassles with the data I gave above
because datums does not partition dataset1$Date, but I don't know what your
problem with them is.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, May 20, 2015 at 3:03 AM, Dieter Anseeuw <dieter.anseeuw at inagro.be>
wrote:

> Dear all,
> I would like to do multiple actions on a subset of my data. Therefore, I
> want to create a for loop on the variable "Date" (actually a double for
> loop on yet another variable, but let's omit that for a moment).
> I want to run down every level of "Date" and perform multiple actions on
> the data from a certain date. Here is my code:
>
> for (i in 1:length(datums)){
> meanweight<-mean(dataset1[dataset1$Date==datums[i],]$Weight)
> ...
>
> However, this subsetting obviously doesn't work. How can I adjust my code
> so that R runs down all levels of Data in a for loop?
> (I need the for loop, not tapply(), sapply(), ...)
>
> Thanks in advance,
> Dieter Anseeuw
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From nidhi.rai at igate.com  Wed May 20 14:19:15 2015
From: nidhi.rai at igate.com (NidhiRai)
Date: Wed, 20 May 2015 05:19:15 -0700 (PDT)
Subject: [R] java.lang.OutOfMemoryError: Java heap space
In-Reply-To: <1385122716933-4680963.post@n4.nabble.com>
References: <1385122716933-4680963.post@n4.nabble.com>
Message-ID: <1432124355905-4707446.post@n4.nabble.com>

Hello Bharat,

I am also getting the same error in same situation.
Just want to know that did you resolved your problem, if yes then can you
please help me out.

Thanks !!





--
View this message in context: http://r.789695.n4.nabble.com/java-lang-OutOfMemoryError-Java-heap-space-tp4680963p4707446.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Wed May 20 18:34:19 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 20 May 2015 09:34:19 -0700
Subject: [R] deSolve ODE Output Question
In-Reply-To: <1432129501132-4707448.post@n4.nabble.com>
References: <1432129501132-4707448.post@n4.nabble.com>
Message-ID: <20782D44-0924-4B7A-B494-AC0176FA2FE5@comcast.net>


On May 20, 2015, at 6:45 AM, walke554 wrote:

> Hello,
> 
> I am working on a simple ODE problem with the deSolve package, and I was
> hoping that someone could answer a question about how the deSolve package
> does integration.  
> 
> Here is my program:
> 
> #The function
> STDMod<-function(t,y,p){
> 	IH = y[1];
> 	IL = y[2];
> 	with(as.list(p), {
> 		dIH.dt = Beta[1,1]*(nH-IH)*IH + Beta[1,2]*(nH-IH)*IL - gamma*IH;
> 		dIL.dt = Beta[2,1]*(nL-IL)*IH + Beta[2,2]*(nL-IL)*IL - gamma*IL;
> 		return(list(c(dIH.dt,dIL.dt)));
> 	})
> }
> 
> #giving the parameters
> 
> Beta = matrix(data=c(10, 0.1, 0.1, 1.0), ncol=2, nrow=2)
> nH = 0.2
> nL = 0.8
> IH0 = 1e-5
> IL0 = 0
> 
> gamma = 1
> 
> p = list(Beta=Beta, gamma=gamma, nH=nH, nL=nL)
> 
> y0 = c(IH0, IL0)
> 
> #Running the ode integrator
> 
> steps= 10;
> t = seq(from=0, to=30, by=.01);
> out = ode(y=y0, times=t, func=STDMod, parms=p);
> 
> My understanding is that the 'out' matrix would be the values of the STDmod
> function at each time step, given the initial values of the state parameters
> IH and IL.  However, for the very first time step, I am getting a value
> different than what the derivative and the initial values add up to.

My reading of the returned value from a call to ode is that it is not the values returned by the 'func'-function which only contain the derivative vectors, but rather the integrated values. That is what you are seeing in any case. You need to remember that integrators calculate the derivative and then further multiply by the "dt" increment which in your case will make the incremental values one-hundredth of the value you calculated by hand below.  (Basic calculus.)

> 
> My output:
> <http://r.789695.n4.nabble.com/file/n4707448/ROutput.png> 
> 
> but 'IH0' + 'the value of dIH.dt = Beta[1,1]*(nH-IH)*IH +
> Beta[1,2]*(nH-IH)*IL - gamma*IH for timestep one' = 1.999e-5.  Is there
> something that I am missing?  I am hoping to use this for more complicated
> derivatives, but I want to make sure I am using the package correctly first.
> 
> Thanks!
> 
> 
> 
> View this message in context: http://r.789695.n4.nabble.com/deSolve-ODE-Output-Question-tp4707448.html
> Sent from the R help mailing list archive at Nabble.com.

I normally also respond to the list and the questioner but have gotten an annoying number of bounces from Nabble users so am not responding directly.

-- 
David Winsemius
Alameda, CA, USA


From macqueen1 at llnl.gov  Wed May 20 18:35:18 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 20 May 2015 16:35:18 +0000
Subject: [R] subsetting question
Message-ID: <D182046B.12AA3B%macqueen1@llnl.gov>

Assuming datums is a vector of the unique dates in Date... perhaps
  datums <- sort(unique(dataset1$Date))

I usually set it up like this

for (i in 1:length(datums) ) {

  crnt.date <- datums[i]
  tmpdat <- subset(dataset1, Date==crnt.date)
  cat(i, format(crnt.date), 'dim(tmpdat)',dim(tmpdat),'\n\n')

 ## use tmpdat for the multiple actions

}

The extra step of creating a subset helps one check that everything is
working as expected. It has no noticeable effect on performance with
datasets of the size I normally work with.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/20/15, 3:03 AM, "Dieter Anseeuw" <dieter.anseeuw at inagro.be> wrote:

>Dear all,
>I would like to do multiple actions on a subset of my data. Therefore, I
>want to create a for loop on the variable "Date" (actually a double for
>loop on yet another variable, but let's omit that for a moment).
>I want to run down every level of "Date" and perform multiple actions on
>the data from a certain date. Here is my code:
>
>for (i in 1:length(datums)){
>meanweight<-mean(dataset1[dataset1$Date==datums[i],]$Weight)
>...
>
>However, this subsetting obviously doesn't work. How can I adjust my code
>so that R runs down all levels of Data in a for loop?
>(I need the for loop, not tapply(), sapply(), ...)
>
>Thanks in advance,
>Dieter Anseeuw
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Wed May 20 18:41:32 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 20 May 2015 08:41:32 -0800
Subject: [R] Vincentizing Reaction Time data in R
In-Reply-To: <CAAJSdjhhJwV40YNHyLyqBGh8jrDDcEo0LXD=HTVs+LvPTeabiQ@mail.gmail.com>
References: <555c5e3d.6090103@gmail.com>
Message-ID: <0EFE87454A4.000016C2jrkrideau@inbox.com>

John Kane
Kingston ON Canada

> -----Original Message-----
> From: john.archie.mckown at gmail.com
> Sent: Wed, 20 May 2015 09:38:47 -0500
> To: gabriel.weindel at gmail.com
> Subject: Re: [R] Vincentizing Reaction Time data in R
> 
> On Wed, May 20, 2015 at 5:13 AM, Gabriel WEINDEL
> <gabriel.weindel at gmail.com>
> wrote:
> 
>> Dear all,
>> 
>> For my master thesis, I'm currently working in cognitive neuroscience on
>> executive control through measurement of reaction time and I need to get
>> my
>> data 'vincentized' with an exclusive use of R set by my statistic
>> teacher
>> for a test purpose, for this reason I can't use the python code the lab
>> team usually uses.
>> Despite a dozen hours of research I couldn't find any package or R-code
>> which would allow the use of vincentization, that's why I'm querying
>> help
>> on the R forum.
>> 
>> So has anyone ever used vincentization in R ?
>> 
> 
> I haven't. And I failed statistics in school. But a Google search got me
> to
> this page, which I hope might be of some help to you. If not, my
> apologies.
> 
> https://stat.ethz.ch/pipermail/r-help/2003-May/034272.html [https://stat.ethz.ch/pipermail/r-help/2003-May/034272.html]
I never heard of it either and I passed a couple out of some number > 2 but we always thought the perception and cognition people strange.
I think this paper may be a lead. An email to the authors might help
http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4017132/ [http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4017132/]
>

>> Gabriel Weindel
>> Master student in Neuropsychology - Aix-Marseille University (France)

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From jvadams at usgs.gov  Wed May 20 22:46:01 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 20 May 2015 15:46:01 -0500
Subject: [R] ASA Conference on Statistical Practice
Message-ID: <CAN5YmCE9rjtb_u37E=EofRLeSUe2fL2uhVNGFJ8KG-d9A-B0tg@mail.gmail.com>

R users,

Abstracts are now being accepted for the
     2016 ASA Conference on Statistical Practice,
     February 18-20,
     San Diego, CA, USA.

Past conference attendees have shown particular interest in R,
reproducibility, and data visualization.

The deadline for submission is June 25.  Presentations will be 35 minutes
long and fall into four broad themes:
     Communication, Impact, and Career Development
     Data Modeling and Analysis
     Big Data Prediction and Analytics
     Software, Programming, and Graphics

Abstracts may be submitted at
http://www.amstat.org/meetings/csp/2016/abstracts.cfm

Thank you.

Jean V. Adams
on behalf of the ASA-CSP 2016 Steering Committee



`?.,,  ><(((?>   `?.,,  ><(((?>   `?.,,  ><(((?>

Jean V. Adams
Statistician
U.S. Geological Survey
Great Lakes Science Center
223 East Steinfest Road
Antigo, WI 54409  USA
http://www.glsc.usgs.gov
http://profile.usgs.gov/jvadams

	[[alternative HTML version deleted]]


From newrnewbie at hotmail.com  Thu May 21 01:13:56 2015
From: newrnewbie at hotmail.com (Vin Cheng)
Date: Wed, 20 May 2015 23:13:56 +0000
Subject: [R] Subset and 0 replace?
In-Reply-To: <D182046B.12AA3B%macqueen1@llnl.gov>
References: <D182046B.12AA3B%macqueen1@llnl.gov>
Message-ID: <BAY179-W6500E86D2E20BB0B9FC7CD3C20@phx.gbl>

Hi,
 
I'm trying to group rows in a dataframe with SPCLORatingValue factor >16 and summing the Wgt's that correspond to this condition.  There are 100 dataframes in a list.  
 
Some of the dataframes won't have any rows that have this condition SPCLORatingValue>16 and therefore no corresponding weight.  
 
My problem is that I need to have a corresponding value for each dataframe in the list - so 100 values. 
 
If dataframe 44 doesn't have any SPCLORatingValue>16, then I end up getting a vector that's 99 long vs. 100.  putting value 45 into 44's slot and so on.
 
Is there either an if/else statement or argument I can place into subset to put a 0 for the data frames that don't have SPCLORatingValue>16?
 
GenEval[18,1:100] <- t(summaryBy(Wgt.sum~as.numeric(.id),data=subset(ldply(Generation,function(x) summaryBy(Wgt ~ SPCLORatingValue, data=x, FUN=c(sum))),SPCLORatingValue>16),FUN=c(sum),order=FALSE))
 
Any help or guidance would be greatly appreciated!
Many Thanks,
Vince
 
 
 		 	   		  
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu May 21 01:30:04 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 20 May 2015 19:30:04 -0400
Subject: [R] Subset and 0 replace?
In-Reply-To: <BAY179-W6500E86D2E20BB0B9FC7CD3C20@phx.gbl>
References: <D182046B.12AA3B%macqueen1@llnl.gov>
	<BAY179-W6500E86D2E20BB0B9FC7CD3C20@phx.gbl>
Message-ID: <555D18FC.9060101@gmail.com>

On 20/05/2015 7:13 PM, Vin Cheng wrote:
> Hi,
>  
> I'm trying to group rows in a dataframe with SPCLORatingValue factor >16 and summing the Wgt's that correspond to this condition.  There are 100 dataframes in a list.  
>  
> Some of the dataframes won't have any rows that have this condition SPCLORatingValue>16 and therefore no corresponding weight.  
>  
> My problem is that I need to have a corresponding value for each dataframe in the list - so 100 values. 
>  
> If dataframe 44 doesn't have any SPCLORatingValue>16, then I end up getting a vector that's 99 long vs. 100.  putting value 45 into 44's slot and so on.
>  
> Is there either an if/else statement or argument I can place into subset to put a 0 for the data frames that don't have SPCLORatingValue>16?
>  
> GenEval[18,1:100] <- t(summaryBy(Wgt.sum~as.numeric(.id),data=subset(ldply(Generation,function(x) summaryBy(Wgt ~ SPCLORatingValue, data=x, FUN=c(sum))),SPCLORatingValue>16),FUN=c(sum),order=FALSE))
>  

The summaryBy function is not in base R.  There's a function with that
name in the doBy package; is that the one you're using?

You doing say how to do the grouping, and I can't read your code to
figure it out, but this code will do what you want with suitable inputs:

by(df, group, function(subset) with(subset, sum(Wgt[SPCLORatingValue >
16])))

where df is your dataframe, and group is a variable that defines the groups.

Duncan Murdoch


From jrkrideau at inbox.com  Thu May 21 03:22:50 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 20 May 2015 17:22:50 -0800
Subject: [R] Vincentizing Reaction Time data in R
In-Reply-To: <555CEF34.2060701@gmail.com>
References: <0efe87454a4.000016c2jrkrideau@inbox.com>
	<555c5e3d.6090103@gmail.com>
Message-ID: <138BB855187.00000675jrkrideau@inbox.com>



> -----Original Message-----
> From: gabriel.weindel at gmail.com
> Sent: Wed, 20 May 2015 22:31:48 +0200
> To: jrkrideau at inbox.com, john.archie.mckown at gmail.com
> Subject: Re: [R] Vincentizing Reaction Time data in R
> 
> John Kane : I already read the paper and wrote an e-mail to the author,
> he used matlab and suggested me to ask this same question on this forum.
> But thank you for your answer.

The paper said that they had used R !  They must have forgotten to add what may have been a minor bit of use of mintabl

I had a look at the equation in the Wiki article and I have long ago forgotten how to read such a thing but I wonder how complicated it is as an algorithm?  R is very flexible and it might be fairly easy to just write a function to do it. 

Actually I just had a very quick look at the Ratcliff paper in Psychological Bulletin 1979, Vol. 86, No. 3, 446-461 (http://star.psy.ohio-state.edu/coglab/People/roger/pdf/Papers/psychbull79.pdf)

I am tired and it is not my area of expertise but it does not look too difficult to write a function in R to do this. But I have been wrong before. :)

> 
> John McKown : thanks a lot, this could be a great help to me but I have
> to take a closer look.
> 
> Again thank you for your replies.
> 
> Regards,
> 
> --
> Gabriel Weindel
> Master student in Neuropsychology - Aix-Marseille University (France)
> 
> 
> 
> Le 20/05/2015 18:41, John Kane a ?crit :
>> John Kane
>> Kingston ON Canada
>> 
>>> -----Original Message-----
>>> From: john.archie.mckown at gmail.com
>>> Sent: Wed, 20 May 2015 09:38:47 -0500
>>> To: gabriel.weindel at gmail.com
>>> Subject: Re: [R] Vincentizing Reaction Time data in R
>>> 
>>> On Wed, May 20, 2015 at 5:13 AM, Gabriel WEINDEL
>>> <gabriel.weindel at gmail.com>
>>> wrote:
>>> 
>>>> Dear all,
>>>> 
>>>> For my master thesis, I'm currently working in cognitive neuroscience
>>>> on
>>>> executive control through measurement of reaction time and I need to
>>>> get
>>>> my
>>>> data 'vincentized' with an exclusive use of R set by my statistic
>>>> teacher
>>>> for a test purpose, for this reason I can't use the python code the
>>>> lab
>>>> team usually uses.
>>>> Despite a dozen hours of research I couldn't find any package or
>>>> R-code
>>>> which would allow the use of vincentization, that's why I'm querying
>>>> help
>>>> on the R forum.
>>>> 
>>>> So has anyone ever used vincentization in R ?
>>>> 
>>> 
>>> I haven't. And I failed statistics in school. But a Google search got
>>> me
>>> to
>>> this page, which I hope might be of some help to you. If not, my
>>> apologies.
>>> 
>>> https://stat.ethz.ch/pipermail/r-help/2003-May/034272.html
>>> [https://stat.ethz.ch/pipermail/r-help/2003-May/034272.html]
>> I never heard of it either and I passed a couple out of some number > 2
>> but we always thought the perception and cognition people strange.
>> I think this paper may be a lead. An email to the authors might help
>> http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4017132/
>> [http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4017132/]
>>> 
>> 
>>>> Gabriel Weindel
>>>> Master student in Neuropsychology - Aix-Marseille University (France)
>> 
>> ____________________________________________________________
>> FREE ONLINE PHOTOSHARING - Share your photos online with your friends
>> and family!
>> Visit http://www.inbox.com/photosharing to find out more!
>> 
>>

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From djnordlund at frontier.com  Thu May 21 04:07:11 2015
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Wed, 20 May 2015 19:07:11 -0700
Subject: [R] Vincentizing Reaction Time data in R
In-Reply-To: <138BB855187.00000675jrkrideau@inbox.com>
References: <0efe87454a4.000016c2jrkrideau@inbox.com>	<555c5e3d.6090103@gmail.com>
	<138BB855187.00000675jrkrideau@inbox.com>
Message-ID: <555D3DCF.70209@frontier.com>

On 5/20/2015 6:22 PM, John Kane wrote:
>
>
>> -----Original Message-----
>> From: gabriel.weindel at gmail.com
>> Sent: Wed, 20 May 2015 22:31:48 +0200
>> To: jrkrideau at inbox.com, john.archie.mckown at gmail.com
>> Subject: Re: [R] Vincentizing Reaction Time data in R
>>
>> John Kane : I already read the paper and wrote an e-mail to the author,
>> he used matlab and suggested me to ask this same question on this forum.
>> But thank you for your answer.
>
> The paper said that they had used R !  They must have forgotten to add what may have been a minor bit of use of mintabl
>
> I had a look at the equation in the Wiki article and I have long ago forgotten how to read such a thing but I wonder how complicated it is as an algorithm?  R is very flexible and it might be fairly easy to just write a function to do it.
>
> Actually I just had a very quick look at the Ratcliff paper in Psychological Bulletin 1979, Vol. 86, No. 3, 446-461 (http://star.psy.ohio-state.edu/coglab/People/roger/pdf/Papers/psychbull79.pdf)
>
> I am tired and it is not my area of expertise but it does not look too difficult to write a function in R to do this. But I have been wrong before. :)
>
>>
>> John McKown : thanks a lot, this could be a great help to me but I have
>> to take a closer look.
>>
>> Again thank you for your replies.
>>
>> Regards,
>>
>> --
>> Gabriel Weindel
>> Master student in Neuropsychology - Aix-Marseille University (France)
>>
>>
>>
>> Le 20/05/2015 18:41, John Kane a ?crit :
>>> John Kane
>>> Kingston ON Canada
>>>
>>>> -----Original Message-----
>>>> From: john.archie.mckown at gmail.com
>>>> Sent: Wed, 20 May 2015 09:38:47 -0500
>>>> To: gabriel.weindel at gmail.com
>>>> Subject: Re: [R] Vincentizing Reaction Time data in R
>>>>
>>>> On Wed, May 20, 2015 at 5:13 AM, Gabriel WEINDEL
>>>> <gabriel.weindel at gmail.com>
>>>> wrote:
>>>>
>>>>> Dear all,
>>>>>
>>>>> For my master thesis, I'm currently working in cognitive neuroscience
>>>>> on
>>>>> executive control through measurement of reaction time and I need to
>>>>> get
>>>>> my
>>>>> data 'vincentized' with an exclusive use of R set by my statistic
>>>>> teacher
>>>>> for a test purpose, for this reason I can't use the python code the
>>>>> lab
>>>>> team usually uses.
>>>>> Despite a dozen hours of research I couldn't find any package or
>>>>> R-code
>>>>> which would allow the use of vincentization, that's why I'm querying
>>>>> help
>>>>> on the R forum.
>>>>>
>>>>> So has anyone ever used vincentization in R ?
>>>>>
>>>>
>>>> I haven't. And I failed statistics in school. But a Google search got
>>>> me
>>>> to
>>>> this page, which I hope might be of some help to you. If not, my
>>>> apologies.
>>>>
>>>> https://stat.ethz.ch/pipermail/r-help/2003-May/034272.html
>>>> [https://stat.ethz.ch/pipermail/r-help/2003-May/034272.html]
>>> I never heard of it either and I passed a couple out of some number > 2
>>> but we always thought the perception and cognition people strange.
>>> I think this paper may be a lead. An email to the authors might help
>>> http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4017132/
>>> [http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4017132/]
>>>>
>>>
>>>>> Gabriel Weindel
>>>>> Master student in Neuropsychology - Aix-Marseille University (France)
>>>


A (very) brief search regarding 'vincentizing' reaction time (RT) 
suggests that it just involves binning the RTs and computing the means 
within bins (typically deciles), then analyzing how the distribution of 
means differs across experimental conditions.  This may help you get 
started.

# create some data
rt <- rnorm(100,200,50)
# create deciles for binning
decile <- as.numeric(cut(rt, quantile(rt,0:10)/10),include.lowest=TRUE))
# collect into a dataframe (not really necessary)
df <- data.frame(rt=rt, decile=decile)
#compute the bin means
aggregate(rt,list(decile),mean,data=df)


This should give you a start,

Dan

-- 
Daniel Nordlund
Bothell, WA USA


From ralphfehrer at gmail.com  Wed May 20 20:41:02 2015
From: ralphfehrer at gmail.com (Ralph Fehrer)
Date: Wed, 20 May 2015 20:41:02 +0200
Subject: [R] Interfacing Python from R
Message-ID: <008101d0932c$86513f20$92f3bd60$@gmail.com>

Hi,

 

I need  to call python code from within R. So far, I have found 

 

http://rpython.r-forge.r-project.org/        (which is not supported for
windows) 

 

and

 

http://www.omegahat.org/RSPython/   (which  has not been maintained since
2005) .

 

 

Is there any R-package for python interfacing, that  works on windows and is
regularly maintained?

 

 

Kind regards,

 

Finn

 

 

 

 

 


	[[alternative HTML version deleted]]


From gabriel.weindel at gmail.com  Wed May 20 22:31:48 2015
From: gabriel.weindel at gmail.com (Gabriel WEINDEL)
Date: Wed, 20 May 2015 22:31:48 +0200
Subject: [R] Vincentizing Reaction Time data in R
In-Reply-To: <0EFE87454A4.000016C2jrkrideau@inbox.com>
References: <555c5e3d.6090103@gmail.com>
	<0EFE87454A4.000016C2jrkrideau@inbox.com>
Message-ID: <555CEF34.2060701@gmail.com>

John Kane : I already read the paper and wrote an e-mail to the author, 
he used matlab and suggested me to ask this same question on this forum. 
But thank you for your answer.

John McKown : thanks a lot, this could be a great help to me but I have 
to take a closer look.

Again thank you for your replies.

Regards,

--
Gabriel Weindel
Master student in Neuropsychology - Aix-Marseille University (France)



Le 20/05/2015 18:41, John Kane a ?crit :
> John Kane
> Kingston ON Canada
>
>> -----Original Message-----
>> From: john.archie.mckown at gmail.com
>> Sent: Wed, 20 May 2015 09:38:47 -0500
>> To: gabriel.weindel at gmail.com
>> Subject: Re: [R] Vincentizing Reaction Time data in R
>>
>> On Wed, May 20, 2015 at 5:13 AM, Gabriel WEINDEL
>> <gabriel.weindel at gmail.com>
>> wrote:
>>
>>> Dear all,
>>>
>>> For my master thesis, I'm currently working in cognitive neuroscience on
>>> executive control through measurement of reaction time and I need to get
>>> my
>>> data 'vincentized' with an exclusive use of R set by my statistic
>>> teacher
>>> for a test purpose, for this reason I can't use the python code the lab
>>> team usually uses.
>>> Despite a dozen hours of research I couldn't find any package or R-code
>>> which would allow the use of vincentization, that's why I'm querying
>>> help
>>> on the R forum.
>>>
>>> So has anyone ever used vincentization in R ?
>>>
>>
>> I haven't. And I failed statistics in school. But a Google search got me
>> to
>> this page, which I hope might be of some help to you. If not, my
>> apologies.
>>
>> https://stat.ethz.ch/pipermail/r-help/2003-May/034272.html [https://stat.ethz.ch/pipermail/r-help/2003-May/034272.html]
> I never heard of it either and I passed a couple out of some number > 2 but we always thought the perception and cognition people strange.
> I think this paper may be a lead. An email to the authors might help
> http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4017132/ [http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4017132/]
>>
>
>>> Gabriel Weindel
>>> Master student in Neuropsychology - Aix-Marseille University (France)
>
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
> Visit http://www.inbox.com/photosharing to find out more!
>
>


From yishinlin001 at gmail.com  Thu May 21 04:13:54 2015
From: yishinlin001 at gmail.com (Yisihn)
Date: Thu, 21 May 2015 10:13:54 +0800
Subject: [R] Vincentizing Reaction Time data in R
In-Reply-To: <555C5E3D.6090103@gmail.com>
References: <555C5E3D.6090103@gmail.com>
Message-ID: <87k2w2smn1.wl-yishinlin001@gmail.com>

On Wed, 20 May 2015 18:13:17 +0800,
Hi Gabriel,

As far as I could recall, there isn't an R package that has explicitly implemented "vincentization". You definitively can find some code segments/functions that have implemented "vincentize" on the web. But you should verify if they do exactly what you wish to do.  If you could look at the question from percentile/quantle perspective, it would not take you too much time to realise that they are similar.  I would suggest you to read, as John Kane suggested, Prof. Ratcliff's 1979 paper.  Another paper that may be very helpful is Prof van Zandt's 2000 RT paper.

However, you should be aware that there are some different implementation of "vincentization", and it is debatable, if not problematic, to use it, rather than other more general quantile methods. It would help you to understand not only how to do vincentization, but also why/why not if you could read papers from Jeff Rouder's as well as from Heathcote's and Brown's lab.

Sorry that I hesitate to give you the code, because this looks like part of your course works.  It would be more rewarding for you, if you could figure out by yourself.

Yishin


Gabriel WEINDEL wrote:
> 
> Dear all,
> 
> For my master thesis, I'm currently working in cognitive neuroscience
> on executive control through measurement of reaction time and I need
> to get my data 'vincentized' with an exclusive use of R set by my
> statistic teacher for a test purpose, for this reason I can't use the
> python code the lab team usually uses.
> Despite a dozen hours of research I couldn't find any package or
> R-code which would allow the use of vincentization, that's why I'm
> querying help on the R forum.
> 
> So has anyone ever used vincentization in R ?
> 
> Best regards,
> 
> -- 
> Gabriel Weindel
> Master student in Neuropsychology - Aix-Marseille University (France)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Thu May 21 06:05:00 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 20 May 2015 21:05:00 -0700
Subject: [R] Interfacing Python from R
In-Reply-To: <008101d0932c$86513f20$92f3bd60$@gmail.com>
References: <008101d0932c$86513f20$92f3bd60$@gmail.com>
Message-ID: <CACk-te05GkxfWRK3gCD_TNx-toZ_pwNxEe8QO2_Vs=9DLLr9ww@mail.gmail.com>

Search. (Not a new idea!)

(I googled on "Call python from R" and found at least one more package).

-- Bert



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, May 20, 2015 at 11:41 AM, Ralph Fehrer <ralphfehrer at gmail.com> wrote:
> Hi,
>
>
>
> I need  to call python code from within R. So far, I have found
>
>
>
> http://rpython.r-forge.r-project.org/        (which is not supported for
> windows)
>
>
>
> and
>
>
>
> http://www.omegahat.org/RSPython/   (which  has not been maintained since
> 2005) .
>
>
>
>
>
> Is there any R-package for python interfacing, that  works on windows and is
> regularly maintained?
>
>
>
>
>
> Kind regards,
>
>
>
> Finn
>
>
>
>
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Thu May 21 06:13:59 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 20 May 2015 21:13:59 -0700
Subject: [R] Vincentizing Reaction Time data in R
In-Reply-To: <555CEF34.2060701@gmail.com>
References: <555c5e3d.6090103@gmail.com>
	<0EFE87454A4.000016C2jrkrideau@inbox.com>
	<555CEF34.2060701@gmail.com>
Message-ID: <CACk-te1oRTA3Znuj31FKd0g4n50PjVNYbVUT3wcKLj=5Xgs36w@mail.gmail.com>

I have one more suggestion:
Consult a local statistician. Psychology, neuroscience (and a host of
other professions that I have encountered) are full of bad statistical
practice and reinvention of wheels. "Vincentizing" sounds suspiciously
like such an example. A statistician could help you sort it out and
either validate the methodology or point you to equivalent more
standard versions (and R packages or functions that might implement
them) or other better alternatives.

Psychology and neuroscience are in particular undergoing public soul
searching regarding their research methodology and the
irreproducibility of many of their published results. Don't add to the
problem: get help from someone local with the necessary statistical
expertise.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, May 20, 2015 at 1:31 PM, Gabriel WEINDEL
<gabriel.weindel at gmail.com> wrote:
> John Kane : I already read the paper and wrote an e-mail to the author, he
> used matlab and suggested me to ask this same question on this forum. But
> thank you for your answer.
>
> John McKown : thanks a lot, this could be a great help to me but I have to
> take a closer look.
>
> Again thank you for your replies.
>
> Regards,
>
> --
> Gabriel Weindel
> Master student in Neuropsychology - Aix-Marseille University (France)
>
>
>
> Le 20/05/2015 18:41, John Kane a ?crit :
>>
>> John Kane
>> Kingston ON Canada
>>
>>> -----Original Message-----
>>> From: john.archie.mckown at gmail.com
>>> Sent: Wed, 20 May 2015 09:38:47 -0500
>>> To: gabriel.weindel at gmail.com
>>> Subject: Re: [R] Vincentizing Reaction Time data in R
>>>
>>> On Wed, May 20, 2015 at 5:13 AM, Gabriel WEINDEL
>>> <gabriel.weindel at gmail.com>
>>> wrote:
>>>
>>>> Dear all,
>>>>
>>>> For my master thesis, I'm currently working in cognitive neuroscience on
>>>> executive control through measurement of reaction time and I need to get
>>>> my
>>>> data 'vincentized' with an exclusive use of R set by my statistic
>>>> teacher
>>>> for a test purpose, for this reason I can't use the python code the lab
>>>> team usually uses.
>>>> Despite a dozen hours of research I couldn't find any package or R-code
>>>> which would allow the use of vincentization, that's why I'm querying
>>>> help
>>>> on the R forum.
>>>>
>>>> So has anyone ever used vincentization in R ?
>>>>
>>>
>>> I haven't. And I failed statistics in school. But a Google search got me
>>> to
>>> this page, which I hope might be of some help to you. If not, my
>>> apologies.
>>>
>>> https://stat.ethz.ch/pipermail/r-help/2003-May/034272.html
>>> [https://stat.ethz.ch/pipermail/r-help/2003-May/034272.html]
>>
>> I never heard of it either and I passed a couple out of some number > 2
>> but we always thought the perception and cognition people strange.
>> I think this paper may be a lead. An email to the authors might help
>> http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4017132/
>> [http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4017132/]
>>>
>>>
>>
>>>> Gabriel Weindel
>>>> Master student in Neuropsychology - Aix-Marseille University (France)
>>
>>
>> ____________________________________________________________
>> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and
>> family!
>> Visit http://www.inbox.com/photosharing to find out more!
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu May 21 07:12:01 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 20 May 2015 22:12:01 -0700
Subject: [R] Subset and 0 replace?
In-Reply-To: <BAY179-W6500E86D2E20BB0B9FC7CD3C20@phx.gbl>
References: <D182046B.12AA3B%macqueen1@llnl.gov>
	<BAY179-W6500E86D2E20BB0B9FC7CD3C20@phx.gbl>
Message-ID: <CAF8bMcbkOp2ktNxA00ho8DVHfBWYD3BpV4_Py9yE33if8YHROQ@mail.gmail.com>

Can you show a small self-contained example of you data and expected
results?
I tried to make one and your expression returned a single number in a 1 by
1 matrix.

library(doBy)
Generation<-list(
   data.frame(Wgt=c(1,2,4), SPCLORatingValue=c(10,11,12)),
   data.frame(Wgt=c(8,16), SPCLORatingValue=c(15,17)),
   data.frame(Wgt=c(32,64), SPCLORatingValue=c(19,20)))
 t(summaryBy(Wgt.sum~as.numeric(.id),data=subset(ldply(Generation,function(x)
summaryBy(Wgt ~ SPCLORatingValue, data=x,
FUN=c(sum))),SPCLORatingValue>16),FUN=c(sum),order=FALSE))
#              1
#Wgt.sum.sum 112
str(.Last.value)
# num [1, 1] 112
# - attr(*, "dimnames")=List of 2
#  ..$ : chr "Wgt.sum.sum"
#  ..$ : chr "1"

Two ways of dealing with the problem you verbally described are
(a) determine which elements of the input you can process (e.g., which
have some values>16) and use subscripting on both the left and right
side of the assignment operator to put the results in the right place.
E.g.,
    x <- c(-1, 1, 2)
    ok <- x>0
    x[ok] <- log(x[ok])
(b) make your function handle any case so you don't have to do any
subsetting on either side.  In your case it may be easy since
sum(zeroLongNumericVector) is 0. In other cases you may want to use ifelse,
as in
   x <- c(-1, 1, 2)
   x <- ifelse(x>0, log(x), x)



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, May 20, 2015 at 4:13 PM, Vin Cheng <newrnewbie at hotmail.com> wrote:

> Hi,
>
> I'm trying to group rows in a dataframe with SPCLORatingValue factor >16
> and summing the Wgt's that correspond to this condition.  There are 100
> dataframes in a list.
>
> Some of the dataframes won't have any rows that have this condition
> SPCLORatingValue>16 and therefore no corresponding weight.
>
> My problem is that I need to have a corresponding value for each dataframe
> in the list - so 100 values.
>
> If dataframe 44 doesn't have any SPCLORatingValue>16, then I end up
> getting a vector that's 99 long vs. 100.  putting value 45 into 44's slot
> and so on.
>
> Is there either an if/else statement or argument I can place into subset
> to put a 0 for the data frames that don't have SPCLORatingValue>16?
>
> GenEval[18,1:100] <-
> t(summaryBy(Wgt.sum~as.numeric(.id),data=subset(ldply(Generation,function(x)
> summaryBy(Wgt ~ SPCLORatingValue, data=x,
> FUN=c(sum))),SPCLORatingValue>16),FUN=c(sum),order=FALSE))
>
> Any help or guidance would be greatly appreciated!
> Many Thanks,
> Vince
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From soe.xiyan at gmail.com  Thu May 21 07:57:27 2015
From: soe.xiyan at gmail.com (Soe Xiyan)
Date: Thu, 21 May 2015 12:57:27 +0700
Subject: [R] Count unchanged class attribute
In-Reply-To: <CA+8X3fXzCtqKTyXcXO-XbjC_FC6gvWwcO-kBdwM+Kk3r7mSbPg@mail.gmail.com>
References: <CAMvMaMZNkTo=WtwzQ13o9O+6G8e6eBX3mL9p8G5kfaEea=feSw@mail.gmail.com>
	<075163F297C.00000C78jrkrideau@inbox.com>
	<CACk-te0+bO2jc9Uafwx_5B5CeuwFJxAZWRqcTvrrrewCUNC_Dw@mail.gmail.com>
	<CA+8X3fXzCtqKTyXcXO-XbjC_FC6gvWwcO-kBdwM+Kk3r7mSbPg@mail.gmail.com>
Message-ID: <CAMvMaMbCFfpAJ7YhQKcfEwZqg=R06dRvUG=PX+dsxNE1ZY=x=g@mail.gmail.com>

My apologize if the question is confusing. This is due to my English
language.
Thanks to Jim Lemon who has helped me.
I must to learn R harder, like how to use  "unlist" and "list".

On Wed, May 20, 2015 at 1:36 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Xiyan,
> I have to admit that your puzzle very nearly stumped me. At first I
> thought the question was:
>
> "What are the numbers of rows with changed and unchanged class values?"
>
> That doesn't work as there are at most four rows and your answer sums
> to five. I then tried:
>
> "How many times does at least one value of class change between
> successive data frames?"
>
> Nope, four have at least one change. Could it have been:
>
> "Using unique combinations of the values of Netto and Bruto, how many
> changes have occurred?"
>
> Wrong again, there are 12 combinations, not five. Surely you don't mean:
>
> "In how many data frames does ta least one value of class equal 'no'?"
>
> df1<-data.frame(Netto=c(10,100),Bruto=c(1000,20),class=c("yes","yes"))
> df2<-data.frame(Netto=c(101,100),Bruto=c(1000,210),class=c("yes","no"))
>
> df3<-data.frame(Netto=c(10,12,100),Bruto=c(10,28,20),class=c("yes","yes","yes"))
> df4<-data.frame(Netto=c(120,400),Bruto=c(200,20),class=c("no","yes"))
> df5<-data.frame(Netto=c(110,1100,120,1140),Bruto=c(12000,120,100,125),
>  class=c("yes","yes","yes","yes"))
> sxdat<-list(df1,df2,df3,df4,df5)
> table(ifelse(unlist(lapply(sxdat,function(x)
> return(any(x$class=="no")))),"changed","unchanged"))
>
> Jim
>
> On Wed, May 20, 2015 at 1:04 PM, Bert Gunter <gunter.berton at gene.com>
> wrote:
> > Probably "or what."
> >
> > This demonstrates a fundamental conundrum: many users or prospective
> users
> > of R have had little exposure to data structures in their formal
> education
> > and therefore can be flummoxed by R's fussiness -- as any programming
> > language must necessarily be. Consider: data frames, matrices, lists,
> > "classes", objects with attributes (e.g. factors),...
> >
> > Excel, which is basically structureless, of course, exacerbates the
> > problem. Those accustomed to its tolerance (and the confusion that
> results)
> > expect R to behave the same way. Education is the only recourse, either
> in
> > formal courses or through R tutorials that strongly emphasize this aspect
> > of interacting with R and especially writing effective code. But that
> > demands effort and, to some extent, aptitude... both of which seem to be
> in
> > increasingly short supply amidst the worldwide explosion in R's usage.
> >
> > Of course, feel free to disagree... Just my $.02
> >
> > Cheers,
> > Bert
> >
> >
> > Bert Gunter
> > Genentech Nonclinical Biostatistics
> > (650) 467-7374
> >
> > "Data is not information. Information is not knowledge. And knowledge is
> > certainly not wisdom."
> > Clifford Stoll
> >
> >
> >
> > On Tue, May 19, 2015 at 7:02 PM, John Kane <jrkrideau at inbox.com> wrote:
> >
> >> Is this a list of data.frames or what?
> >>
> >> Please have a look at one or both of these for some ideas of how to ask
> a
> >> question and provide information on the problem.  The better you can
> >> describe what you have and what you need the better people can help.
> >>
> >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >> and http://adv-r.had.co.nz/Reproducibility.html
> >>
> >>
> >> John Kane
> >> Kingston ON Canada
> >>
> >>
> >> > -----Original Message-----
> >> > From: soe.xiyan at gmail.com
> >> > Sent: Tue, 19 May 2015 23:37:13 +0700
> >> > To: r-help at r-project.org
> >> > Subject: [R] Count unchanged class attribute
> >> >
> >> > Maybe someone can help me.
> >> > Suppose I have data-set like this:
> >> >
> >> >   Netto   Bruto  class
> >> > 1 10      1000    yes
> >> > 2 100     20      yes
> >> >
> >> >
> >> >   Netto   Bruto  class
> >> > 1 101     1000    yes
> >> > 2 100     210     no
> >> >
> >> >
> >> >   Netto   Bruto  class
> >> > 1 10      10      yes
> >> > 2 12      28      yes
> >> > 3 100     20      yes
> >> >
> >> >   Netto   Bruto  class
> >> > 1 120     200     no
> >> > 2 400     20      yes
> >> >
> >> >
> >> >   Netto   Bruto  class
> >> > 1 110     12000   yes
> >> > 2 1100    120     yes
> >> > 3 120     100     yes
> >> > 4 1140    125     yes
> >> >
> >> > How to calculate the number of classes has changed.
> >> > The expected result is
> >> > - class changed    2
> >> > - class unchanged  3
> >> >
> >> >
> >> > Thank you so much.
> >> > Soe Xiyan
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ____________________________________________________________
> >> Can't remember your password? Do you need a strong and secure password?
> >> Use Password manager! It stores your passwords & protects your account.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sigbert at wiwi.hu-berlin.de  Thu May 21 11:45:26 2015
From: sigbert at wiwi.hu-berlin.de (Sigbert Klinke)
Date: Thu, 21 May 2015 11:45:26 +0200
Subject: [R] Feature or bug?
Message-ID: <555DA936.6000807@wiwi.hu-berlin.de>

Hi,

if I run

update <- function (newtime) { ginput <<- list(time=newtime)}

server <- function (input) {
  print(paste("Before", input$time))
  update(1)
  print(paste("After:", input$time))
}

ginput <- list(time=0)
server(ginput)

then I get as result

[1] "Before 0"
[1] "After: 0"

If I uncomment the first print

update <- function (newtime) { ginput <<- list(time=newtime) }

server <- function (input) {
  #print(paste("Before", input$time))
  update(1)
  print(paste("After:", input$time))
}

ginput <- list(time=0)
server(ginput)

then I get

[1] "After: 1"

Even when I use a side effect (by assign some new value to a global
variable) I would have expected the same behaviour in both cases.

Sigbert

-- 
http://u.hu-berlin.de/sk

From maechler at lynne.stat.math.ethz.ch  Thu May 21 11:01:46 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Thu, 21 May 2015 11:01:46 +0200
Subject: [R] The R Foundation announces new mailing list 'R-package-devel'
Message-ID: <21853.40698.326587.61371@stat.math.ethz.ch>

New Mailing list:  R-package-devel -- User R Packages Development

At last week's monthly meeting, the R foundation has decided to
create a new mailing list in order to help R package authors in
their package development and testing.

The idea is that some experienced R programmers (often those
currently helping on R-devel or also R-help) will help package
authors and thus unload some of the burden of the CRAN team
members.

Please read the detailed description of the mailing list here,
       https://stat.ethz.ch/mailman/listinfo/r-package-devel
or also the more extended announcement of the list on R-devel,
archived at
	 https://stat.ethz.ch/pipermail/r-devel/2015-May/071208.html


For the R foundation,
Martin Maechler, Secretary General

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From Berwin.Turlach at gmail.com  Thu May 21 12:50:23 2015
From: Berwin.Turlach at gmail.com (Berwin A Turlach)
Date: Thu, 21 May 2015 18:50:23 +0800
Subject: [R] Feature or bug?
In-Reply-To: <555DA936.6000807@wiwi.hu-berlin.de>
References: <555DA936.6000807@wiwi.hu-berlin.de>
Message-ID: <20150521185023.1a1d4fb5@bossiaea>

G'day Sigbert,

long time no see :)
How is Berlin these days?

On Thu, 21 May 2015 11:45:26 +0200
Sigbert Klinke <sigbert at wiwi.hu-berlin.de> wrote:

It is a feature.

> if I run
> 
> update <- function (newtime) { ginput <<- list(time=newtime)}
> 
> server <- function (input) {
>   print(paste("Before", input$time))
>   update(1)
>   print(paste("After:", input$time))
> }
> 
> ginput <- list(time=0)
> server(ginput)
> 
> then I get as result
> 
> [1] "Before 0"
> [1] "After: 0"

The first print command evaluates input and after this the function
server has an object named "input" in its local environment.  The
second print command reuses this object and extracts the component time
from it (which has not changed).  The change of the global variable has
no effect.

> If I uncomment the first print
> 
> update <- function (newtime) { ginput <<- list(time=newtime) }
> 
> server <- function (input) {
>   #print(paste("Before", input$time))
>   update(1)
>   print(paste("After:", input$time))
> }
> 
> ginput <- list(time=0)
> server(ginput)
> 
> then I get
> 
> [1] "After: 1"

Because the global variable is changed before input is evaluated.  R
has lazy argument evaluation, arguments are only evaluated once they
are needed.  You are essentially getting bitten by R's lazy evaluation
plus "pass by value" syntax.

> Even when I use a side effect (by assign some new value to a global
> variable) I would have expected the same behaviour in both cases.

To get the behaviour that you expect, you would have to write your code
along the following lines:

R> update <- function (newtime) { ginput <<- list(time=newtime)}
R> server <- function(input){
+     inp <- as.name(deparse(substitute(input)))
+     print(paste("Before", eval(substitute(XXX$time, list(XXX=inp)))))
+     update(1)
+     print(paste("After:", eval(substitute(XXX$time, list(XXX=inp)))))
+ }
R> ginput <- list(time=0)
R> server(ginput)
[1] "Before 0"
[1] "After: 1"


A cleaner way is perhaps to use environments, as these are passed by
reference:

R> update <- function(env, newtime) env$time <- newtime
R> server <- function(input){
+     print(paste("Before", input$time))
+     update(input, 1)
+     print(paste("After:", input$time))
+ }
R> ginput <- new.env()
R> ginput$time <- 0
R> server(ginput)
[1] "Before 0"
[1] "After: 1"

HTH.

Cheers,

	Berwin

========================== Full address ============================
A/Prof Berwin A Turlach               Tel.: +61 (8) 6488 3338 (secr)
School of Maths and Stats (M019)            +61 (8) 6488 3383 (self)
The University of Western Australia   FAX : +61 (8) 6488 1028
35 Stirling Highway                   
Crawley WA 6009                     e-mail: Berwin.Turlach at gmail.com
Australia                http://www.maths.uwa.edu.au/~berwin
                         http://www.researcherid.com/rid/A-4995-2008


From jrkrideau at inbox.com  Thu May 21 15:52:30 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 21 May 2015 05:52:30 -0800
Subject: [R] Vincentizing Reaction Time data in R
In-Reply-To: <87k2w2smn1.wl-yishinlin001@gmail.com>
References: <555c5e3d.6090103@gmail.com>
Message-ID: <1A175F8EE5E.00000C3Ajrkrideau@inbox.com>

In line

John Kane
Kingston ON Canada


> -----Original Message-----
> From: yishinlin001 at gmail.com
> Sent: Thu, 21 May 2015 10:13:54 +0800
> To: gabriel.weindel at gmail.com
> Subject: Re: [R] Vincentizing Reaction Time data in R
> 
> On Wed, 20 May 2015 18:13:17 +0800,
> Hi Gabriel,
> 
> As far as I could recall, there isn't an R package that has explicitly
> implemented "vincentization". You definitively can find some code
> segments/functions that have implemented "vincentize" on the web. But you
> should verify if they do exactly what you wish to do.  If you could look
> at the question from percentile/quantle perspective, it would not take
> you too much time to realise that they are similar.  I would suggest you
> to read, as John Kane suggested, Prof. Ratcliff's 1979 paper.  Another
> paper that may be very helpful is Prof van Zandt's 2000 RT paper.
> 
> However, you should be aware that there are some different implementation
> of "vincentization", and it is debatable, if not problematic, to use it,
> rather than other more general quantile methods. It would help you to
> understand not only how to do vincentization, but also why/why not if you
> could read papers from Jeff Rouder's as well as from Heathcote's and
> Brown's lab.
> 
> Sorry that I hesitate to give you the code, because this looks like part
> of your course works.  It would be more rewarding for you, if you could
> figure out by yourself.
> 
> Yishin
> 
While I agree the exercise is likely to be a good learning experience I don't see this as the equivalent of course work. 

If Gabriel (the OP) was tasked with implementing  "vincentization" in R then, strictly speaking it is course work but if I understand him the requirement is to do his work in R rather than Minitab.  If such a function existed in an existing R package than he could have simply plugged in the numbers et voil?, done.

The tenor of the question did not suggest this and it would require the stats instructor to know that there was no  "vincentization" function anywhere among the, what, a thousand or so packages? And if the OP was working on his own data as part of the course then the instructor might have little or no idea of exactly what functions are needed

The course  strikes me more as an effort to get psychologists away from SPSS which often seems to be the only software package anyone knows.


> Gabriel WEINDEL wrote:
>> 
>> Dear all,
>> 
>> For my master thesis, I'm currently working in cognitive neuroscience
>> on executive control through measurement of reaction time and I need
>> to get my data 'vincentized' with an exclusive use of R set by my
>> statistic teacher for a test purpose, for this reason I can't use the
>> python code the lab team usually uses.
>> Despite a dozen hours of research I couldn't find any package or
>> R-code which would allow the use of vincentization, that's why I'm
>> querying help on the R forum.
>> 
>> So has anyone ever used vincentization in R ?
>> 
>> Best regards,
>> 
>> --
>> Gabriel Weindel
>> Master student in Neuropsychology - Aix-Marseille University (France)
>>

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From gunter.berton at gene.com  Thu May 21 16:26:28 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 21 May 2015 07:26:28 -0700
Subject: [R] Feature or bug?
In-Reply-To: <20150521185023.1a1d4fb5@bossiaea>
References: <555DA936.6000807@wiwi.hu-berlin.de>
	<20150521185023.1a1d4fb5@bossiaea>
Message-ID: <CACk-te1rbVkw5jDJ4HJQVpkUyR3a1sSrX4iUwK3_yh6f174urQ@mail.gmail.com>

Well..

"Because the global variable is changed before input is evaluated.  R
has lazy argument evaluation, arguments are only evaluated once they
are needed.  You are essentially getting bitten by R's lazy evaluation
plus "pass by value" syntax."

While I may be either wrong or just picking on semantics, I don't
think so. It is merely what you stated previously: input was assigned
a value in the local server function environment, and that assignment
was not affected by the subsequent assignment to the global
environment. So it is a matter of R's semantics -- where it looks for
the values bound to symbols -- rather than lazy evaluation.

Obviously then, a simple way to do what the OP seemed to want would be
to simply assign the updated value in the local function environment,
rather than the global. I get nervous whenever I see constructs with
eval(substitute...)) or global assignments from within a function.
Both have their place, of course, but (the latter especially) can be
dangerous, and my experience both on the list and with my own code, is
that if you think you need them, you probably should rethink what you
need to do.

Corrections and/or criticism of these comments are welcome.

Best,
Bert



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, May 21, 2015 at 3:50 AM, Berwin A Turlach
<Berwin.Turlach at gmail.com> wrote:
> G'day Sigbert,
>
> long time no see :)
> How is Berlin these days?
>
> On Thu, 21 May 2015 11:45:26 +0200
> Sigbert Klinke <sigbert at wiwi.hu-berlin.de> wrote:
>
> It is a feature.
>
>> if I run
>>
>> update <- function (newtime) { ginput <<- list(time=newtime)}
>>
>> server <- function (input) {
>>   print(paste("Before", input$time))
>>   update(1)
>>   print(paste("After:", input$time))
>> }
>>
>> ginput <- list(time=0)
>> server(ginput)
>>
>> then I get as result
>>
>> [1] "Before 0"
>> [1] "After: 0"
>
> The first print command evaluates input and after this the function
> server has an object named "input" in its local environment.  The
> second print command reuses this object and extracts the component time
> from it (which has not changed).  The change of the global variable has
> no effect.
>
>> If I uncomment the first print
>>
>> update <- function (newtime) { ginput <<- list(time=newtime) }
>>
>> server <- function (input) {
>>   #print(paste("Before", input$time))
>>   update(1)
>>   print(paste("After:", input$time))
>> }
>>
>> ginput <- list(time=0)
>> server(ginput)
>>
>> then I get
>>
>> [1] "After: 1"
>
> Because the global variable is changed before input is evaluated.  R
> has lazy argument evaluation, arguments are only evaluated once they
> are needed.  You are essentially getting bitten by R's lazy evaluation
> plus "pass by value" syntax.
>
>> Even when I use a side effect (by assign some new value to a global
>> variable) I would have expected the same behaviour in both cases.
>
> To get the behaviour that you expect, you would have to write your code
> along the following lines:
>
> R> update <- function (newtime) { ginput <<- list(time=newtime)}
> R> server <- function(input){
> +     inp <- as.name(deparse(substitute(input)))
> +     print(paste("Before", eval(substitute(XXX$time, list(XXX=inp)))))
> +     update(1)
> +     print(paste("After:", eval(substitute(XXX$time, list(XXX=inp)))))
> + }
> R> ginput <- list(time=0)
> R> server(ginput)
> [1] "Before 0"
> [1] "After: 1"
>
>
> A cleaner way is perhaps to use environments, as these are passed by
> reference:
>
> R> update <- function(env, newtime) env$time <- newtime
> R> server <- function(input){
> +     print(paste("Before", input$time))
> +     update(input, 1)
> +     print(paste("After:", input$time))
> + }
> R> ginput <- new.env()
> R> ginput$time <- 0
> R> server(ginput)
> [1] "Before 0"
> [1] "After: 1"
>
> HTH.
>
> Cheers,
>
>         Berwin
>
> ========================== Full address ============================
> A/Prof Berwin A Turlach               Tel.: +61 (8) 6488 3338 (secr)
> School of Maths and Stats (M019)            +61 (8) 6488 3383 (self)
> The University of Western Australia   FAX : +61 (8) 6488 1028
> 35 Stirling Highway
> Crawley WA 6009                     e-mail: Berwin.Turlach at gmail.com
> Australia                http://www.maths.uwa.edu.au/~berwin
>                          http://www.researcherid.com/rid/A-4995-2008
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Thu May 21 16:48:31 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 21 May 2015 16:48:31 +0200
Subject: [R] Feature or bug?
In-Reply-To: <CACk-te1rbVkw5jDJ4HJQVpkUyR3a1sSrX4iUwK3_yh6f174urQ@mail.gmail.com>
References: <555DA936.6000807@wiwi.hu-berlin.de>
	<20150521185023.1a1d4fb5@bossiaea>
	<CACk-te1rbVkw5jDJ4HJQVpkUyR3a1sSrX4iUwK3_yh6f174urQ@mail.gmail.com>
Message-ID: <635DDE6D-AB44-457C-8EFB-FEAF2EF0B698@gmail.com>


On 21 May 2015, at 16:26 , Bert Gunter <gunter.berton at gene.com> wrote:

> Well..
> 
> "Because the global variable is changed before input is evaluated.  R
> has lazy argument evaluation, arguments are only evaluated once they
> are needed.  You are essentially getting bitten by R's lazy evaluation
> plus "pass by value" syntax."
> 
> While I may be either wrong or just picking on semantics, I don't
> think so. It is merely what you stated previously: input was assigned
> a value in the local server function environment, and that assignment
> was not affected by the subsequent assignment to the global
> environment. So it is a matter of R's semantics -- where it looks for
> the values bound to symbols -- rather than lazy evaluation.
> 
> Obviously then, a simple way to do what the OP seemed to want would be
> to simply assign the updated value in the local function environment,
> rather than the global. I get nervous whenever I see constructs with
> eval(substitute...)) or global assignments from within a function.
> Both have their place, of course, but (the latter especially) can be
> dangerous, and my experience both on the list and with my own code, is
> that if you think you need them, you probably should rethink what you
> need to do.
> 
> Corrections and/or criticism of these comments are welcome.
> 

Berwin is right, or rather: There are two issues. The "input" argument to server() is evaluated when first used. The difference between the two examples is whether this happens before or after update(), and that is the effect of lazy evaluation. The fact that it in the first case the value is unchanged by the update is due to scoping: Once evaluate "input" becomes a local variable  an is unchanged by assignment to the global variable.

-pd


> Best,
> Bert
> 
> 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
> 
> 
> 
> 
> On Thu, May 21, 2015 at 3:50 AM, Berwin A Turlach
> <Berwin.Turlach at gmail.com> wrote:
>> G'day Sigbert,
>> 
>> long time no see :)
>> How is Berlin these days?
>> 
>> On Thu, 21 May 2015 11:45:26 +0200
>> Sigbert Klinke <sigbert at wiwi.hu-berlin.de> wrote:
>> 
>> It is a feature.
>> 
>>> if I run
>>> 
>>> update <- function (newtime) { ginput <<- list(time=newtime)}
>>> 
>>> server <- function (input) {
>>>  print(paste("Before", input$time))
>>>  update(1)
>>>  print(paste("After:", input$time))
>>> }
>>> 
>>> ginput <- list(time=0)
>>> server(ginput)
>>> 
>>> then I get as result
>>> 
>>> [1] "Before 0"
>>> [1] "After: 0"
>> 
>> The first print command evaluates input and after this the function
>> server has an object named "input" in its local environment.  The
>> second print command reuses this object and extracts the component time
>> from it (which has not changed).  The change of the global variable has
>> no effect.
>> 
>>> If I uncomment the first print
>>> 
>>> update <- function (newtime) { ginput <<- list(time=newtime) }
>>> 
>>> server <- function (input) {
>>>  #print(paste("Before", input$time))
>>>  update(1)
>>>  print(paste("After:", input$time))
>>> }
>>> 
>>> ginput <- list(time=0)
>>> server(ginput)
>>> 
>>> then I get
>>> 
>>> [1] "After: 1"
>> 
>> Because the global variable is changed before input is evaluated.  R
>> has lazy argument evaluation, arguments are only evaluated once they
>> are needed.  You are essentially getting bitten by R's lazy evaluation
>> plus "pass by value" syntax.
>> 
>>> Even when I use a side effect (by assign some new value to a global
>>> variable) I would have expected the same behaviour in both cases.
>> 
>> To get the behaviour that you expect, you would have to write your code
>> along the following lines:
>> 
>> R> update <- function (newtime) { ginput <<- list(time=newtime)}
>> R> server <- function(input){
>> +     inp <- as.name(deparse(substitute(input)))
>> +     print(paste("Before", eval(substitute(XXX$time, list(XXX=inp)))))
>> +     update(1)
>> +     print(paste("After:", eval(substitute(XXX$time, list(XXX=inp)))))
>> + }
>> R> ginput <- list(time=0)
>> R> server(ginput)
>> [1] "Before 0"
>> [1] "After: 1"
>> 
>> 
>> A cleaner way is perhaps to use environments, as these are passed by
>> reference:
>> 
>> R> update <- function(env, newtime) env$time <- newtime
>> R> server <- function(input){
>> +     print(paste("Before", input$time))
>> +     update(input, 1)
>> +     print(paste("After:", input$time))
>> + }
>> R> ginput <- new.env()
>> R> ginput$time <- 0
>> R> server(ginput)
>> [1] "Before 0"
>> [1] "After: 1"
>> 
>> HTH.
>> 
>> Cheers,
>> 
>>        Berwin
>> 
>> ========================== Full address ============================
>> A/Prof Berwin A Turlach               Tel.: +61 (8) 6488 3338 (secr)
>> School of Maths and Stats (M019)            +61 (8) 6488 3383 (self)
>> The University of Western Australia   FAX : +61 (8) 6488 1028
>> 35 Stirling Highway
>> Crawley WA 6009                     e-mail: Berwin.Turlach at gmail.com
>> Australia                http://www.maths.uwa.edu.au/~berwin
>>                         http://www.researcherid.com/rid/A-4995-2008
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From wdunlap at tibco.com  Thu May 21 17:03:01 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 21 May 2015 08:03:01 -0700
Subject: [R] Feature or bug?
In-Reply-To: <635DDE6D-AB44-457C-8EFB-FEAF2EF0B698@gmail.com>
References: <555DA936.6000807@wiwi.hu-berlin.de>
	<20150521185023.1a1d4fb5@bossiaea>
	<CACk-te1rbVkw5jDJ4HJQVpkUyR3a1sSrX4iUwK3_yh6f174urQ@mail.gmail.com>
	<635DDE6D-AB44-457C-8EFB-FEAF2EF0B698@gmail.com>
Message-ID: <CAF8bMcatVEoF3=NT0sdPh8M-8TxdgajaFS7JOyGawtWsF8EYmg@mail.gmail.com>

If you add a print statement to trace the evaluation of the input argument
you can see how the lazy evaluation works:

> update <- function (newtime) {
    cat("# update() is changing global ginput's time from", ginput$time,
"to", newtime, "\n")
    ginput <<- list(time = newtime)
    }
> server <- function(input, doFirstPrint) {
    if (doFirstPrint) {
        cat("# Before calling update(1): input$time=", input$time,
"ginput$time=", ginput$time, "\n")
    }
    update(1)
    cat("# After calling update(1): input$time=", input$time,
"ginput$time=", ginput$time, "\n")
    }
> ginput <- list(time=0)
> server({cat("# Evaluating server's 'input' argument\n"); ginput},
doFirstPrint=TRUE)
# Evaluating server's 'input' argument
# Before calling update(1): input$time= 0 ginput$time= 0
# update() is changing global ginput's time from 0 to 1
# After calling update(1): input$time= 0 ginput$time= 1
> ginput <- list(time=0)
> server({cat("# Evaluating server's 'input' argument\n"); ginput},
doFirstPrint=FALSE)
# update() is changing global ginput's time from 0 to 1
# Evaluating server's 'input' argument
# After calling update(1): input$time= 1 ginput$time= 1


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, May 21, 2015 at 7:48 AM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> On 21 May 2015, at 16:26 , Bert Gunter <gunter.berton at gene.com> wrote:
>
> > Well..
> >
> > "Because the global variable is changed before input is evaluated.  R
> > has lazy argument evaluation, arguments are only evaluated once they
> > are needed.  You are essentially getting bitten by R's lazy evaluation
> > plus "pass by value" syntax."
> >
> > While I may be either wrong or just picking on semantics, I don't
> > think so. It is merely what you stated previously: input was assigned
> > a value in the local server function environment, and that assignment
> > was not affected by the subsequent assignment to the global
> > environment. So it is a matter of R's semantics -- where it looks for
> > the values bound to symbols -- rather than lazy evaluation.
> >
> > Obviously then, a simple way to do what the OP seemed to want would be
> > to simply assign the updated value in the local function environment,
> > rather than the global. I get nervous whenever I see constructs with
> > eval(substitute...)) or global assignments from within a function.
> > Both have their place, of course, but (the latter especially) can be
> > dangerous, and my experience both on the list and with my own code, is
> > that if you think you need them, you probably should rethink what you
> > need to do.
> >
> > Corrections and/or criticism of these comments are welcome.
> >
>
> Berwin is right, or rather: There are two issues. The "input" argument to
> server() is evaluated when first used. The difference between the two
> examples is whether this happens before or after update(), and that is the
> effect of lazy evaluation. The fact that it in the first case the value is
> unchanged by the update is due to scoping: Once evaluate "input" becomes a
> local variable  an is unchanged by assignment to the global variable.
>
> -pd
>
>
> > Best,
> > Bert
> >
> >
> >
> > Bert Gunter
> > Genentech Nonclinical Biostatistics
> > (650) 467-7374
> >
> > "Data is not information. Information is not knowledge. And knowledge
> > is certainly not wisdom."
> > Clifford Stoll
> >
> >
> >
> >
> > On Thu, May 21, 2015 at 3:50 AM, Berwin A Turlach
> > <Berwin.Turlach at gmail.com> wrote:
> >> G'day Sigbert,
> >>
> >> long time no see :)
> >> How is Berlin these days?
> >>
> >> On Thu, 21 May 2015 11:45:26 +0200
> >> Sigbert Klinke <sigbert at wiwi.hu-berlin.de> wrote:
> >>
> >> It is a feature.
> >>
> >>> if I run
> >>>
> >>> update <- function (newtime) { ginput <<- list(time=newtime)}
> >>>
> >>> server <- function (input) {
> >>>  print(paste("Before", input$time))
> >>>  update(1)
> >>>  print(paste("After:", input$time))
> >>> }
> >>>
> >>> ginput <- list(time=0)
> >>> server(ginput)
> >>>
> >>> then I get as result
> >>>
> >>> [1] "Before 0"
> >>> [1] "After: 0"
> >>
> >> The first print command evaluates input and after this the function
> >> server has an object named "input" in its local environment.  The
> >> second print command reuses this object and extracts the component time
> >> from it (which has not changed).  The change of the global variable has
> >> no effect.
> >>
> >>> If I uncomment the first print
> >>>
> >>> update <- function (newtime) { ginput <<- list(time=newtime) }
> >>>
> >>> server <- function (input) {
> >>>  #print(paste("Before", input$time))
> >>>  update(1)
> >>>  print(paste("After:", input$time))
> >>> }
> >>>
> >>> ginput <- list(time=0)
> >>> server(ginput)
> >>>
> >>> then I get
> >>>
> >>> [1] "After: 1"
> >>
> >> Because the global variable is changed before input is evaluated.  R
> >> has lazy argument evaluation, arguments are only evaluated once they
> >> are needed.  You are essentially getting bitten by R's lazy evaluation
> >> plus "pass by value" syntax.
> >>
> >>> Even when I use a side effect (by assign some new value to a global
> >>> variable) I would have expected the same behaviour in both cases.
> >>
> >> To get the behaviour that you expect, you would have to write your code
> >> along the following lines:
> >>
> >> R> update <- function (newtime) { ginput <<- list(time=newtime)}
> >> R> server <- function(input){
> >> +     inp <- as.name(deparse(substitute(input)))
> >> +     print(paste("Before", eval(substitute(XXX$time, list(XXX=inp)))))
> >> +     update(1)
> >> +     print(paste("After:", eval(substitute(XXX$time, list(XXX=inp)))))
> >> + }
> >> R> ginput <- list(time=0)
> >> R> server(ginput)
> >> [1] "Before 0"
> >> [1] "After: 1"
> >>
> >>
> >> A cleaner way is perhaps to use environments, as these are passed by
> >> reference:
> >>
> >> R> update <- function(env, newtime) env$time <- newtime
> >> R> server <- function(input){
> >> +     print(paste("Before", input$time))
> >> +     update(input, 1)
> >> +     print(paste("After:", input$time))
> >> + }
> >> R> ginput <- new.env()
> >> R> ginput$time <- 0
> >> R> server(ginput)
> >> [1] "Before 0"
> >> [1] "After: 1"
> >>
> >> HTH.
> >>
> >> Cheers,
> >>
> >>        Berwin
> >>
> >> ========================== Full address ============================
> >> A/Prof Berwin A Turlach               Tel.: +61 (8) 6488 3338 (secr)
> >> School of Maths and Stats (M019)            +61 (8) 6488 3383 (self)
> >> The University of Western Australia   FAX : +61 (8) 6488 1028
> >> 35 Stirling Highway
> >> Crawley WA 6009                     e-mail: Berwin.Turlach at gmail.com
> >> Australia                http://www.maths.uwa.edu.au/~berwin
> >>                         http://www.researcherid.com/rid/A-4995-2008
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From assaf at uw.edu  Thu May 21 18:21:28 2015
From: assaf at uw.edu (Assaf P. Oron)
Date: Thu, 21 May 2015 09:21:28 -0700
Subject: [R] Question regarding different R versions on an enterprise
	network server
Message-ID: <CAEGxr5APBGsLdsN1Fdego6icEghJ=Kt1deLgwSrfXSPsCNVD8A@mail.gmail.com>

Hi all,

I represent R users vs. IT dept. at my workplace (yes, an enviable task :)

We've managed to get a workable network-based R application, for people who
work remotely, or don't have a machine (i.e., they use a VDI terminal).
Everything in this organization is staunchly Windows and Microsoft.

We've agreed to upgrade only once yearly, to save IT resources. Now we're
upgrading, and I would like users to be able to keep their old R 3.1.0
directory trees like it's available on a single Windows machine. At least
for a few months, so that people can evaluate back-compatibility if they
need. In fact, we have an even older server-based 3.0.1, which happens to
be  the only R version for which the Tableaux-R connection works (at least
according to my colleagues, I don't use Tableaux).

Anyway, long story short. That was just the motivating example. The problem
I'm dealing with is whether a network application that has several versions
of R (3.1.z, 3.2.z), etc., all available, and each reading and installing
libraries to a different folder tree.

The libraries right now are installed into each user's "personal" share
drive. It's pretty stable. However, obviously the 3.2.z libraries will now
overwrite the 3.1.z.

My IT contact says it's impossible, because the Windows app name is always
just Rgui.exe, and they can only have one set of instructions associated
with the same app name (i.e., what folders to go to, etc.)

I wonder whether anyone has had experience with this, or I should just give
up and alert people that if they want to explore various historical layers
of R and the associated packages, they will have to work around and/or
install and uninstall lots of packages each time.

Thanks!

Assaf

-- 
Assaf P. Oron, Ph.D.
Senior Statistician, Children's Core for Biomedical Statistics
(206)884-1236, assaf.oron at seattlechildrens.org
------------
Consulting statistician, Seattle DEEDS Project
http://www.duwamishdiesel.org/
Instructor, UW Certificate for Statistical Analysis with R
assaf at uw.edu

	[[alternative HTML version deleted]]


From gabriel.weindel at gmail.com  Thu May 21 17:50:02 2015
From: gabriel.weindel at gmail.com (Weindel Gabriel)
Date: Thu, 21 May 2015 17:50:02 +0200
Subject: [R] Vincentizing Reaction Time data in R
In-Reply-To: <1A175F8EE5E.00000C3Ajrkrideau@inbox.com>
References: <555c5e3d.6090103@gmail.com>
	<1A175F8EE5E.00000C3Ajrkrideau@inbox.com>
Message-ID: <555DFEAA.4000507@gmail.com>

Bert : Thank you for your advice, it would be a little bit difficult to 
do it for my master thesis but, if I want to go further with a PhD 
thesis (and I do want), I would probably follow your advice and get in 
touch with a statistician.

Yishin : Thank you very much for the references, I will definitively
read the papers you quote. I'm already a little bit aware of the misuses
possible with the vincentization in particular thanks to the paper of
Rouder and Speckman (2004) and it seems to fit with my design. No 
problem if you want to keep the code but I have to tell you that it's 
our first semester using R and the teacher surely didn't thought that we 
will run out of available code with our experiment. Like John guessed 
the purpose of the course was to give a first view of R to get over the 
temptation of SPSS, my bad if I want to avoid biased statistics like 
sample mean ANOVA's on RT.

Dan : Thank you for your tip, this sure will help but I'm quiet at the
beginning of my R skills so I hardly trust myself to do it on my own,
but I can sure give it a try.

John : I had the same assumption but my research director warned me that 
I might run out of time for my first presentation by doing so but fairly 
enough for my master thesis. But again like I said to Dan I'm quiet 
concerned by my actual R skill.

Anyway I have to say that I'm really glad to see how much help you can 
get by using the r-help mailing-list.

Regards,
Gabriel

Le 21/05/2015 15:52, John Kane a ?crit :
> In line
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: yishinlin001 at gmail.com
>> Sent: Thu, 21 May 2015 10:13:54 +0800
>> To: gabriel.weindel at gmail.com
>> Subject: Re: [R] Vincentizing Reaction Time data in R
>>
>> On Wed, 20 May 2015 18:13:17 +0800,
>> Hi Gabriel,
>>
>> As far as I could recall, there isn't an R package that has explicitly
>> implemented "vincentization". You definitively can find some code
>> segments/functions that have implemented "vincentize" on the web. But you
>> should verify if they do exactly what you wish to do.  If you could look
>> at the question from percentile/quantle perspective, it would not take
>> you too much time to realise that they are similar.  I would suggest you
>> to read, as John Kane suggested, Prof. Ratcliff's 1979 paper.  Another
>> paper that may be very helpful is Prof van Zandt's 2000 RT paper.
>>
>> However, you should be aware that there are some different implementation
>> of "vincentization", and it is debatable, if not problematic, to use it,
>> rather than other more general quantile methods. It would help you to
>> understand not only how to do vincentization, but also why/why not if you
>> could read papers from Jeff Rouder's as well as from Heathcote's and
>> Brown's lab.
>>
>> Sorry that I hesitate to give you the code, because this looks like part
>> of your course works.  It would be more rewarding for you, if you could
>> figure out by yourself.
>>
>> Yishin
>>
> While I agree the exercise is likely to be a good learning experience I don't see this as the equivalent of course work.
>
> If Gabriel (the OP) was tasked with implementing  "vincentization" in R then, strictly speaking it is course work but if I understand him the requirement is to do his work in R rather than Minitab.  If such a function existed in an existing R package than he could have simply plugged in the numbers et voil?, done.
>
> The tenor of the question did not suggest this and it would require the stats instructor to know that there was no  "vincentization" function anywhere among the, what, a thousand or so packages? And if the OP was working on his own data as part of the course then the instructor might have little or no idea of exactly what functions are needed
>
> The course  strikes me more as an effort to get psychologists away from SPSS which often seems to be the only software package anyone knows.
>
>
>> Gabriel WEINDEL wrote:
>>>
>>> Dear all,
>>>
>>> For my master thesis, I'm currently working in cognitive neuroscience
>>> on executive control through measurement of reaction time and I need
>>> to get my data 'vincentized' with an exclusive use of R set by my
>>> statistic teacher for a test purpose, for this reason I can't use the
>>> python code the lab team usually uses.
>>> Despite a dozen hours of research I couldn't find any package or
>>> R-code which would allow the use of vincentization, that's why I'm
>>> querying help on the R forum.
>>>
>>> So has anyone ever used vincentization in R ?
>>>
>>> Best regards,
>>>
>>> --
>>> Gabriel Weindel
>>> Master student in Neuropsychology - Aix-Marseille University (France)
>>>
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/manager
>
>


From newrnewbie at hotmail.com  Thu May 21 18:50:20 2015
From: newrnewbie at hotmail.com (Vin Cheng)
Date: Thu, 21 May 2015 16:50:20 +0000
Subject: [R] Subset and 0 replace?
In-Reply-To: <CAF8bMcbkOp2ktNxA00ho8DVHfBWYD3BpV4_Py9yE33if8YHROQ@mail.gmail.com>
References: <D182046B.12AA3B%macqueen1@llnl.gov>
	<BAY179-W6500E86D2E20BB0B9FC7CD3C20@phx.gbl>,
	<CAF8bMcbkOp2ktNxA00ho8DVHfBWYD3BpV4_Py9yE33if8YHROQ@mail.gmail.com>
Message-ID: <BAY179-W285B48D51AB90CCF885BB9D3C10@phx.gbl>

Thanks William/Duncan!
 
Duncan - Yes - I am using the doBy package.
 
running this line on the sample data below gives weights for V5,V44, & V2.  Ideally I would like 0's for V8 and V10 in the output.
 
So it would look like:
e<-structure(matrix(c("V5", "0.008714910", "V8", "0", "V10", "0", "V44", "0.004357455", "V2", "0.008714910"),nrow = 2))
 
 
This is far as I've gotten by subsetting and  summing:
a<-t(summaryBy(Wgt.sum~as.numeric(.id),data=subset(ldply(c,function(x) summaryBy(Wgt ~ SPCLORatingValue, data=x, FUN=c(sum))),SPCLORatingValue>16),FUN=c(sum),order=FALSE))
 
All help/guidance is much appreciated!  Thanks Vince!
 
Sample data example:
c<-structure(list(V5 = structure(list(WgtBand = c(2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2), Wgt = c(0.00435745520833333, 0.00435745520833333, 
0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
0.00435745520833333, 0.00435745520833333, 0.00435745520833333
), SPCLORatingValue = c(11L, 15L, 14L, 15L, 14L, 14L, 16L, 19L, 
13L, 17L, 11L)), .Names = c("WgtBand", "Wgt", "SPCLORatingValue"
), row.names = 12:22, class = "data.frame"), V8 = structure(list(
    WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), Wgt = c(0.00435745520833333, 
    0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
    0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
    0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
    0.00435745520833333), SPCLORatingValue = c(14L, 15L, 15L, 
    12L, 15L, 12L, 13L, 15L, 14L, 15L, 14L)), .Names = c("WgtBand", 
"Wgt", "SPCLORatingValue"), row.names = 12:22, class = "data.frame"), 
    V10 = structure(list(WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2, 
    2, 2, 2), Wgt = c(0.00435745520833333, 0.00435745520833333, 
    0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
    0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
    0.00435745520833333, 0.00435745520833333, 0.00435745520833333
    ), SPCLORatingValue = c(15L, 13L, 14L, 14L, 13L, 13L, 13L, 
    15L, 15L, 13L, 14L)), .Names = c("WgtBand", "Wgt", "SPCLORatingValue"
    ), row.names = 12:22, class = "data.frame"), V44 = structure(list(
        WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), Wgt = c(0.00435745520833333, 
        0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
        0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
        0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
        0.00435745520833333), SPCLORatingValue = c(13L, 14L, 
        16L, 15L, 14L, 14L, 18L, 13L, 16L, 15L, 11L)), .Names = c("WgtBand", 
    "Wgt", "SPCLORatingValue"), row.names = 12:22, class = "data.frame"), 
    V2 = structure(list(WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 
    2, 2), Wgt = c(0.00435745520833333, 0.00435745520833333, 
    0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
    0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
    0.00435745520833333, 0.00435745520833333, 0.00435745520833333
    ), SPCLORatingValue = c(13L, 14L, 15L, 15L, 15L, 14L, 12L, 
    16L, 17L, 15L, 19L)), .Names = c("WgtBand", "Wgt", "SPCLORatingValue"
    ), row.names = 12:22, class = "data.frame")), .Names = c("V5", 
"V8", "V10", "V44", "V2"))
structure(list(V5 = structure(list(WgtBand = c(2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2), Wgt = c(0.00435745520833333, 0.00435745520833333, 
0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
0.00435745520833333, 0.00435745520833333, 0.00435745520833333
), SPCLORatingValue = c(11L, 15L, 14L, 15L, 14L, 14L, 16L, 19L, 
13L, 17L, 11L)), .Names = c("WgtBand", "Wgt", "SPCLORatingValue"
), row.names = 12:22, class = "data.frame"), V8 = structure(list(
    WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), Wgt = c(0.00435745520833333, 
    0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
    0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
    0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
    0.00435745520833333), SPCLORatingValue = c(14L, 15L, 15L, 
    12L, 15L, 12L, 13L, 15L, 14L, 15L, 14L)), .Names = c("WgtBand", 
"Wgt", "SPCLORatingValue"), row.names = 12:22, class = "data.frame"), 
    V10 = structure(list(WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2, 
    2, 2, 2), Wgt = c(0.00435745520833333, 0.00435745520833333, 
    0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
    0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
    0.00435745520833333, 0.00435745520833333, 0.00435745520833333
    ), SPCLORatingValue = c(15L, 13L, 14L, 14L, 13L, 13L, 13L, 
    15L, 15L, 13L, 14L)), .Names = c("WgtBand", "Wgt", "SPCLORatingValue"))))
 
 
 
 
 
 
 
 
 
 
 
 

 
From: wdunlap at tibco.com
Date: Wed, 20 May 2015 22:12:01 -0700
Subject: Re: [R] Subset and 0 replace?
To: newrnewbie at hotmail.com
CC: r-help at r-project.org

Can you show a small self-contained example of you data and expected results?I tried to make one and your expression returned a single number in a 1 by 1 matrix.
library(doBy)Generation<-list(   data.frame(Wgt=c(1,2,4), SPCLORatingValue=c(10,11,12)),   data.frame(Wgt=c(8,16), SPCLORatingValue=c(15,17)),   data.frame(Wgt=c(32,64), SPCLORatingValue=c(19,20))) t(summaryBy(Wgt.sum~as.numeric(.id),data=subset(ldply(Generation,function(x) summaryBy(Wgt ~ SPCLORatingValue, data=x, FUN=c(sum))),SPCLORatingValue>16),FUN=c(sum),order=FALSE))#              1#Wgt.sum.sum 112str(.Last.value)# num [1, 1] 112# - attr(*, "dimnames")=List of 2#  ..$ : chr "Wgt.sum.sum"#  ..$ : chr "1"
Two ways of dealing with the problem you verbally described are(a) determine which elements of the input you can process (e.g., whichhave some values>16) and use subscripting on both the left and rightside of the assignment operator to put the results in the right place.  E.g.,    x <- c(-1, 1, 2)    ok <- x>0    x[ok] <- log(x[ok])(b) make your function handle any case so you don't have to do anysubsetting on either side.  In your case it may be easy since sum(zeroLongNumericVector) is 0. In other cases you may want to use ifelse,as in   x <- c(-1, 1, 2)   x <- ifelse(x>0, log(x), x)

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, May 20, 2015 at 4:13 PM, Vin Cheng <newrnewbie at hotmail.com> wrote:
Hi,



I'm trying to group rows in a dataframe with SPCLORatingValue factor >16 and summing the Wgt's that correspond to this condition.  There are 100 dataframes in a list.



Some of the dataframes won't have any rows that have this condition SPCLORatingValue>16 and therefore no corresponding weight.



My problem is that I need to have a corresponding value for each dataframe in the list - so 100 values.



If dataframe 44 doesn't have any SPCLORatingValue>16, then I end up getting a vector that's 99 long vs. 100.  putting value 45 into 44's slot and so on.



Is there either an if/else statement or argument I can place into subset to put a 0 for the data frames that don't have SPCLORatingValue>16?



GenEval[18,1:100] <- t(summaryBy(Wgt.sum~as.numeric(.id),data=subset(ldply(Generation,function(x) summaryBy(Wgt ~ SPCLORatingValue, data=x, FUN=c(sum))),SPCLORatingValue>16),FUN=c(sum),order=FALSE))



Any help or guidance would be greatly appreciated!

Many Thanks,

Vince







        [[alternative HTML version deleted]]



______________________________________________

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.


 		 	   		  
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu May 21 18:54:42 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 21 May 2015 12:54:42 -0400
Subject: [R] Question regarding different R versions on an enterprise
 network server
In-Reply-To: <CAEGxr5APBGsLdsN1Fdego6icEghJ=Kt1deLgwSrfXSPsCNVD8A@mail.gmail.com>
References: <CAEGxr5APBGsLdsN1Fdego6icEghJ=Kt1deLgwSrfXSPsCNVD8A@mail.gmail.com>
Message-ID: <555E0DD2.1080505@gmail.com>

On 21/05/2015 12:21 PM, Assaf P. Oron wrote:
> Hi all,
>
> I represent R users vs. IT dept. at my workplace (yes, an enviable task :)
>
> We've managed to get a workable network-based R application, for people who
> work remotely, or don't have a machine (i.e., they use a VDI terminal).
> Everything in this organization is staunchly Windows and Microsoft.
>
> We've agreed to upgrade only once yearly, to save IT resources. Now we're
> upgrading, and I would like users to be able to keep their old R 3.1.0
> directory trees like it's available on a single Windows machine. At least
> for a few months, so that people can evaluate back-compatibility if they
> need. In fact, we have an even older server-based 3.0.1, which happens to
> be  the only R version for which the Tableaux-R connection works (at least
> according to my colleagues, I don't use Tableaux).
>
> Anyway, long story short. That was just the motivating example. The problem
> I'm dealing with is whether a network application that has several versions
> of R (3.1.z, 3.2.z), etc., all available, and each reading and installing
> libraries to a different folder tree.
>
> The libraries right now are installed into each user's "personal" share
> drive. It's pretty stable. However, obviously the 3.2.z libraries will now
> overwrite the 3.1.z.
>
> My IT contact says it's impossible, because the Windows app name is always
> just Rgui.exe, and they can only have one set of instructions associated
> with the same app name (i.e., what folders to go to, etc.)

If you are doing the install, you can rename Rgui.exe to something else, 
e.g. rename the old one to Rgui31.exe.

The default setup already installs user packages into a local directory 
with a versioned name, so that shouldn't be a problem.
See ?R_LIBS for details on that.

Duncan Murdoch
>
> I wonder whether anyone has had experience with this, or I should just give
> up and alert people that if they want to explore various historical layers
> of R and the associated packages, they will have to work around and/or
> install and uninstall lots of packages each time.
>
> Thanks!
>
> Assaf
>


From jdnewmil at dcn.davis.CA.us  Thu May 21 19:03:48 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 21 May 2015 10:03:48 -0700
Subject: [R] Question regarding different R versions on an
	enterprise	network server
In-Reply-To: <CAEGxr5APBGsLdsN1Fdego6icEghJ=Kt1deLgwSrfXSPsCNVD8A@mail.gmail.com>
References: <CAEGxr5APBGsLdsN1Fdego6icEghJ=Kt1deLgwSrfXSPsCNVD8A@mail.gmail.com>
Message-ID: <F183B793-84EA-4AC2-AB05-4F199D2A36F3@dcn.davis.CA.us>

3.2 library is in a different directory than 3.1 library.

You might benefit from reading the discussion about packages in the installation manual for R.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 21, 2015 9:21:28 AM PDT, "Assaf P. Oron" <assaf at uw.edu> wrote:
>Hi all,
>
>I represent R users vs. IT dept. at my workplace (yes, an enviable task
>:)
>
>We've managed to get a workable network-based R application, for people
>who
>work remotely, or don't have a machine (i.e., they use a VDI terminal).
>Everything in this organization is staunchly Windows and Microsoft.
>
>We've agreed to upgrade only once yearly, to save IT resources. Now
>we're
>upgrading, and I would like users to be able to keep their old R 3.1.0
>directory trees like it's available on a single Windows machine. At
>least
>for a few months, so that people can evaluate back-compatibility if
>they
>need. In fact, we have an even older server-based 3.0.1, which happens
>to
>be  the only R version for which the Tableaux-R connection works (at
>least
>according to my colleagues, I don't use Tableaux).
>
>Anyway, long story short. That was just the motivating example. The
>problem
>I'm dealing with is whether a network application that has several
>versions
>of R (3.1.z, 3.2.z), etc., all available, and each reading and
>installing
>libraries to a different folder tree.
>
>The libraries right now are installed into each user's "personal" share
>drive. It's pretty stable. However, obviously the 3.2.z libraries will
>now
>overwrite the 3.1.z.
>
>My IT contact says it's impossible, because the Windows app name is
>always
>just Rgui.exe, and they can only have one set of instructions
>associated
>with the same app name (i.e., what folders to go to, etc.)
>
>I wonder whether anyone has had experience with this, or I should just
>give
>up and alert people that if they want to explore various historical
>layers
>of R and the associated packages, they will have to work around and/or
>install and uninstall lots of packages each time.
>
>Thanks!
>
>Assaf


From assaf at uw.edu  Thu May 21 20:09:25 2015
From: assaf at uw.edu (Assaf P. Oron)
Date: Thu, 21 May 2015 11:09:25 -0700
Subject: [R] Question regarding different R versions on an enterprise
 network server
In-Reply-To: <555E0DD2.1080505@gmail.com>
References: <CAEGxr5APBGsLdsN1Fdego6icEghJ=Kt1deLgwSrfXSPsCNVD8A@mail.gmail.com>
	<555E0DD2.1080505@gmail.com>
Message-ID: <CAEGxr5Cam_Yy1SVb-5_rE9SRMULUqBkQ=Q0RQHGp6dEJUgow0A@mail.gmail.com>

Thanks for the quick response.

@Duncan: The IT person says he cannot rename the binary. Naturally that's
the first suggestion I made to him. I found it odd but he's the IT person
not me.
OTOH if I have authoritative word from the R team that it's perfectly
doable, I can get back to him :)

@Jeff: Since it's a network app, on their side it doesn't sit in a 'folder'
so there's no way for the different Rgui.exe's to reference different
folders. If they are called the same, they will all read off of the same
initialization files.

Assaf



On Thu, May 21, 2015 at 9:54 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 21/05/2015 12:21 PM, Assaf P. Oron wrote:
>
>> Hi all,
>>
>> I represent R users vs. IT dept. at my workplace (yes, an enviable task :)
>>
>> We've managed to get a workable network-based R application, for people
>> who
>> work remotely, or don't have a machine (i.e., they use a VDI terminal).
>> Everything in this organization is staunchly Windows and Microsoft.
>>
>> We've agreed to upgrade only once yearly, to save IT resources. Now we're
>> upgrading, and I would like users to be able to keep their old R 3.1.0
>> directory trees like it's available on a single Windows machine. At least
>> for a few months, so that people can evaluate back-compatibility if they
>> need. In fact, we have an even older server-based 3.0.1, which happens to
>> be  the only R version for which the Tableaux-R connection works (at least
>> according to my colleagues, I don't use Tableaux).
>>
>> Anyway, long story short. That was just the motivating example. The
>> problem
>> I'm dealing with is whether a network application that has several
>> versions
>> of R (3.1.z, 3.2.z), etc., all available, and each reading and installing
>> libraries to a different folder tree.
>>
>> The libraries right now are installed into each user's "personal" share
>> drive. It's pretty stable. However, obviously the 3.2.z libraries will now
>> overwrite the 3.1.z.
>>
>> My IT contact says it's impossible, because the Windows app name is always
>> just Rgui.exe, and they can only have one set of instructions associated
>> with the same app name (i.e., what folders to go to, etc.)
>>
>
> If you are doing the install, you can rename Rgui.exe to something else,
> e.g. rename the old one to Rgui31.exe.
>
> The default setup already installs user packages into a local directory
> with a versioned name, so that shouldn't be a problem.
> See ?R_LIBS for details on that.
>
> Duncan Murdoch
>
>
>> I wonder whether anyone has had experience with this, or I should just
>> give
>> up and alert people that if they want to explore various historical layers
>> of R and the associated packages, they will have to work around and/or
>> install and uninstall lots of packages each time.
>>
>> Thanks!
>>
>> Assaf
>>
>>
>


-- 
Assaf P. Oron, Ph.D.
Senior Statistician, Children's Core for Biomedical Statistics
(206)884-1236, assaf.oron at seattlechildrens.org
------------
Consulting statistician, Seattle DEEDS Project
http://www.duwamishdiesel.org/
Instructor, UW Certificate for Statistical Analysis with R
assaf at uw.edu

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu May 21 22:42:58 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 21 May 2015 13:42:58 -0700
Subject: [R] Question regarding different R versions on an enterprise
	network server
In-Reply-To: <CAEGxr5Cam_Yy1SVb-5_rE9SRMULUqBkQ=Q0RQHGp6dEJUgow0A@mail.gmail.com>
References: <CAEGxr5APBGsLdsN1Fdego6icEghJ=Kt1deLgwSrfXSPsCNVD8A@mail.gmail.com>
	<555E0DD2.1080505@gmail.com>
	<CAEGxr5Cam_Yy1SVb-5_rE9SRMULUqBkQ=Q0RQHGp6dEJUgow0A@mail.gmail.com>
Message-ID: <DE94D9ED-2D7A-42C7-B2FE-ED2A17673499@dcn.davis.CA.us>

Assaf: they are named differently when you run different versions. 3.1 and 3.2 are different, but 3.1.1 and 3.1.2 are both in the 3.1 directory.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 21, 2015 11:09:25 AM PDT, "Assaf P. Oron" <assaf at uw.edu> wrote:
>Thanks for the quick response.
>
>@Duncan: The IT person says he cannot rename the binary. Naturally
>that's
>the first suggestion I made to him. I found it odd but he's the IT
>person
>not me.
>OTOH if I have authoritative word from the R team that it's perfectly
>doable, I can get back to him :)
>
>@Jeff: Since it's a network app, on their side it doesn't sit in a
>'folder'
>so there's no way for the different Rgui.exe's to reference different
>folders. If they are called the same, they will all read off of the
>same
>initialization files.
>
>Assaf
>
>
>
>On Thu, May 21, 2015 at 9:54 AM, Duncan Murdoch
><murdoch.duncan at gmail.com>
>wrote:
>
>> On 21/05/2015 12:21 PM, Assaf P. Oron wrote:
>>
>>> Hi all,
>>>
>>> I represent R users vs. IT dept. at my workplace (yes, an enviable
>task :)
>>>
>>> We've managed to get a workable network-based R application, for
>people
>>> who
>>> work remotely, or don't have a machine (i.e., they use a VDI
>terminal).
>>> Everything in this organization is staunchly Windows and Microsoft.
>>>
>>> We've agreed to upgrade only once yearly, to save IT resources. Now
>we're
>>> upgrading, and I would like users to be able to keep their old R
>3.1.0
>>> directory trees like it's available on a single Windows machine. At
>least
>>> for a few months, so that people can evaluate back-compatibility if
>they
>>> need. In fact, we have an even older server-based 3.0.1, which
>happens to
>>> be  the only R version for which the Tableaux-R connection works (at
>least
>>> according to my colleagues, I don't use Tableaux).
>>>
>>> Anyway, long story short. That was just the motivating example. The
>>> problem
>>> I'm dealing with is whether a network application that has several
>>> versions
>>> of R (3.1.z, 3.2.z), etc., all available, and each reading and
>installing
>>> libraries to a different folder tree.
>>>
>>> The libraries right now are installed into each user's "personal"
>share
>>> drive. It's pretty stable. However, obviously the 3.2.z libraries
>will now
>>> overwrite the 3.1.z.
>>>
>>> My IT contact says it's impossible, because the Windows app name is
>always
>>> just Rgui.exe, and they can only have one set of instructions
>associated
>>> with the same app name (i.e., what folders to go to, etc.)
>>>
>>
>> If you are doing the install, you can rename Rgui.exe to something
>else,
>> e.g. rename the old one to Rgui31.exe.
>>
>> The default setup already installs user packages into a local
>directory
>> with a versioned name, so that shouldn't be a problem.
>> See ?R_LIBS for details on that.
>>
>> Duncan Murdoch
>>
>>
>>> I wonder whether anyone has had experience with this, or I should
>just
>>> give
>>> up and alert people that if they want to explore various historical
>layers
>>> of R and the associated packages, they will have to work around
>and/or
>>> install and uninstall lots of packages each time.
>>>
>>> Thanks!
>>>
>>> Assaf
>>>
>>>
>>


From goochmi at gmail.com  Thu May 21 21:19:52 2015
From: goochmi at gmail.com (Michael Gooch)
Date: Thu, 21 May 2015 15:19:52 -0400
Subject: [R] compiling R with tuned BLAS
Message-ID: <555E2FD8.80504@gmail.com>

I am looking at the instructions on 
http://cran.r-project.org/doc/manuals/r-patched/R-admin.html#ATLAS

I have noticed that ATLAS produces two shared libs in addition to the 
*.a files:
http://math-atlas.sourceforge.net/atlas_install/node22.html

contents of the ATLAS lib directory:
libatlas.a  libcblas.a  libf77blas.a  liblapack.a  libptcblas.a 
libptf77blas.a  libsatlas.so  libtatlas.so

The instructions do not appear to match up with the *.a files & *.so 
files as described. (it appears to want me to use shared libs, but the 
names defined are static libs, not shared libs).

should I simply be having it link against libtatlas.so (and pthreads) 
for shared threaded atlas and libsatlas.so for shared sequential atlas?
do I need shared versions of the other static libraries?

I think the help is a bit out of date, or at least unclear as to what it 
intends of me.

M. Gooch


From goochmi at gmail.com  Thu May 21 22:03:21 2015
From: goochmi at gmail.com (Michael Gooch)
Date: Thu, 21 May 2015 16:03:21 -0400
Subject: [R] configure script claims that pkg-config doesn't know about cairo
In-Reply-To: <555E2FD8.80504@gmail.com>
References: <555E2FD8.80504@gmail.com>
Message-ID: <555E3A09.8030600@gmail.com>

and yet I checked manually :

pkg-config --print-variables cairo
exec_prefix
prefix
libdir
includedir

something weird is going on with this


From wdunlap at tibco.com  Fri May 22 00:36:05 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 21 May 2015 15:36:05 -0700
Subject: [R] Subset and 0 replace?
In-Reply-To: <BAY179-W285B48D51AB90CCF885BB9D3C10@phx.gbl>
References: <D182046B.12AA3B%macqueen1@llnl.gov>
	<BAY179-W6500E86D2E20BB0B9FC7CD3C20@phx.gbl>
	<CAF8bMcbkOp2ktNxA00ho8DVHfBWYD3BpV4_Py9yE33if8YHROQ@mail.gmail.com>
	<BAY179-W285B48D51AB90CCF885BB9D3C10@phx.gbl>
Message-ID: <CAF8bMcY71gsatiVYDv5-S7JhQP-XaagaXHnXREzX3GFA3ntdXQ@mail.gmail.com>

I renamed your 'c' to be 'toyData' and your 'e' to be 'desiredResult'.  Do
you
want the following, which uses only base R code?

> vapply(toyData,
              FUN=function(V)with(V, sum(Wgt[SPCLORatingValue>16])),
              FUN.VALUE=0)
         V5          V8         V10         V44          V2
0.008714910 0.000000000 0.000000000 0.004357455 0.008714910

It what is in your desired result but in a more useful format (e.g., numbers
instead of character strings for sum).

> desiredResult
     [,1]          [,2] [,3]  [,4]          [,5]
[1,] "V5"          "V8" "V10" "V44"         "V2"
[2,] "0.008714910" "0"  "0"   "0.004357455" "0.008714910"


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, May 21, 2015 at 9:50 AM, Vin Cheng <newrnewbie at hotmail.com> wrote:

> Thanks William/Duncan!
>
> Duncan - Yes - I am using the doBy package.
>
> running this line on the sample data below gives weights for V5,V44, &
> V2.  Ideally I would like 0's for V8 and V10 in the output.
>
> So it would look like:
> e<-structure(matrix(c("V5", "0.008714910", "V8", "0", "V10", "0", "V44",
> "0.004357455", "V2", "0.008714910"),nrow = 2))
>
>
> This is far as I've gotten by subsetting and  summing:
> a<-t(summaryBy(Wgt.sum~as.numeric(.id),data=subset(ldply(c,function(x)
> summaryBy(Wgt ~ SPCLORatingValue, data=x,
> FUN=c(sum))),SPCLORatingValue>16),FUN=c(sum),order=FALSE))
>
> All help/guidance is much appreciated!  Thanks Vince!
>
> Sample data example:
> c<-structure(list(V5 = structure(list(WgtBand = c(2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2), Wgt = c(0.00435745520833333, 0.00435745520833333,
> 0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
> 0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
> 0.00435745520833333, 0.00435745520833333, 0.00435745520833333
> ), SPCLORatingValue = c(11L, 15L, 14L, 15L, 14L, 14L, 16L, 19L,
> 13L, 17L, 11L)), .Names = c("WgtBand", "Wgt", "SPCLORatingValue"
> ), row.names = 12:22, class = "data.frame"), V8 = structure(list(
>     WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), Wgt =
> c(0.00435745520833333,
>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
>     0.00435745520833333), SPCLORatingValue = c(14L, 15L, 15L,
>     12L, 15L, 12L, 13L, 15L, 14L, 15L, 14L)), .Names = c("WgtBand",
> "Wgt", "SPCLORatingValue"), row.names = 12:22, class = "data.frame"),
>     V10 = structure(list(WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2,
>     2, 2, 2), Wgt = c(0.00435745520833333, 0.00435745520833333,
>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333
>     ), SPCLORatingValue = c(15L, 13L, 14L, 14L, 13L, 13L, 13L,
>     15L, 15L, 13L, 14L)), .Names = c("WgtBand", "Wgt", "SPCLORatingValue"
>     ), row.names = 12:22, class = "data.frame"), V44 = structure(list(
>         WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), Wgt =
> c(0.00435745520833333,
>         0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
>         0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
>         0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
>         0.00435745520833333), SPCLORatingValue = c(13L, 14L,
>         16L, 15L, 14L, 14L, 18L, 13L, 16L, 15L, 11L)), .Names =
> c("WgtBand",
>     "Wgt", "SPCLORatingValue"), row.names = 12:22, class = "data.frame"),
>     V2 = structure(list(WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2, 2,
>     2, 2), Wgt = c(0.00435745520833333, 0.00435745520833333,
>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333
>     ), SPCLORatingValue = c(13L, 14L, 15L, 15L, 15L, 14L, 12L,
>     16L, 17L, 15L, 19L)), .Names = c("WgtBand", "Wgt", "SPCLORatingValue"
>     ), row.names = 12:22, class = "data.frame")), .Names = c("V5",
> "V8", "V10", "V44", "V2"))
> structure(list(V5 = structure(list(WgtBand = c(2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2), Wgt = c(0.00435745520833333, 0.00435745520833333,
> 0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
> 0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
> 0.00435745520833333, 0.00435745520833333, 0.00435745520833333
> ), SPCLORatingValue = c(11L, 15L, 14L, 15L, 14L, 14L, 16L, 19L,
> 13L, 17L, 11L)), .Names = c("WgtBand", "Wgt", "SPCLORatingValue"
> ), row.names = 12:22, class = "data.frame"), V8 = structure(list(
>     WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), Wgt =
> c(0.00435745520833333,
>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
>     0.00435745520833333), SPCLORatingValue = c(14L, 15L, 15L,
>     12L, 15L, 12L, 13L, 15L, 14L, 15L, 14L)), .Names = c("WgtBand",
> "Wgt", "SPCLORatingValue"), row.names = 12:22, class = "data.frame"),
>     V10 = structure(list(WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2,
>     2, 2, 2), Wgt = c(0.00435745520833333, 0.00435745520833333,
>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333,
>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333
>     ), SPCLORatingValue = c(15L, 13L, 14L, 14L, 13L, 13L, 13L,
>     15L, 15L, 13L, 14L)), .Names = c("WgtBand", "Wgt",
> "SPCLORatingValue"))))
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> ------------------------------
> From: wdunlap at tibco.com
> Date: Wed, 20 May 2015 22:12:01 -0700
> Subject: Re: [R] Subset and 0 replace?
> To: newrnewbie at hotmail.com
> CC: r-help at r-project.org
>
>
> Can you show a small self-contained example of you data and expected
> results?
> I tried to make one and your expression returned a single number in a 1 by
> 1 matrix.
>
> library(doBy)
> Generation<-list(
>    data.frame(Wgt=c(1,2,4), SPCLORatingValue=c(10,11,12)),
>    data.frame(Wgt=c(8,16), SPCLORatingValue=c(15,17)),
>    data.frame(Wgt=c(32,64), SPCLORatingValue=c(19,20)))
>  t(summaryBy(Wgt.sum~as.numeric(.id),data=subset(ldply(Generation,function(x)
> summaryBy(Wgt ~ SPCLORatingValue, data=x,
> FUN=c(sum))),SPCLORatingValue>16),FUN=c(sum),order=FALSE))
> #              1
> #Wgt.sum.sum 112
> str(.Last.value)
> # num [1, 1] 112
> # - attr(*, "dimnames")=List of 2
> #  ..$ : chr "Wgt.sum.sum"
> #  ..$ : chr "1"
>
> Two ways of dealing with the problem you verbally described are
> (a) determine which elements of the input you can process (e.g., which
> have some values>16) and use subscripting on both the left and right
> side of the assignment operator to put the results in the right place.
> E.g.,
>     x <- c(-1, 1, 2)
>     ok <- x>0
>     x[ok] <- log(x[ok])
> (b) make your function handle any case so you don't have to do any
> subsetting on either side.  In your case it may be easy since
> sum(zeroLongNumericVector) is 0. In other cases you may want to use ifelse,
> as in
>    x <- c(-1, 1, 2)
>    x <- ifelse(x>0, log(x), x)
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Wed, May 20, 2015 at 4:13 PM, Vin Cheng <newrnewbie at hotmail.com> wrote:
>
> Hi,
>
> I'm trying to group rows in a dataframe with SPCLORatingValue factor >16
> and summing the Wgt's that correspond to this condition.  There are 100
> dataframes in a list.
>
> Some of the dataframes won't have any rows that have this condition
> SPCLORatingValue>16 and therefore no corresponding weight.
>
> My problem is that I need to have a corresponding value for each dataframe
> in the list - so 100 values.
>
> If dataframe 44 doesn't have any SPCLORatingValue>16, then I end up
> getting a vector that's 99 long vs. 100.  putting value 45 into 44's slot
> and so on.
>
> Is there either an if/else statement or argument I can place into subset
> to put a 0 for the data frames that don't have SPCLORatingValue>16?
>
> GenEval[18,1:100] <-
> t(summaryBy(Wgt.sum~as.numeric(.id),data=subset(ldply(Generation,function(x)
> summaryBy(Wgt ~ SPCLORatingValue, data=x,
> FUN=c(sum))),SPCLORatingValue>16),FUN=c(sum),order=FALSE))
>
> Any help or guidance would be greatly appreciated!
> Many Thanks,
> Vince
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From newrnewbie at hotmail.com  Fri May 22 01:26:57 2015
From: newrnewbie at hotmail.com (Vin Cheng)
Date: Thu, 21 May 2015 16:26:57 -0700
Subject: [R] Subset and 0 replace?
In-Reply-To: <CAF8bMcY71gsatiVYDv5-S7JhQP-XaagaXHnXREzX3GFA3ntdXQ@mail.gmail.com>
References: <D182046B.12AA3B%macqueen1@llnl.gov>
	<BAY179-W6500E86D2E20BB0B9FC7CD3C20@phx.gbl>
	<CAF8bMcbkOp2ktNxA00ho8DVHfBWYD3BpV4_Py9yE33if8YHROQ@mail.gmail.com>
	<BAY179-W285B48D51AB90CCF885BB9D3C10@phx.gbl>
	<CAF8bMcY71gsatiVYDv5-S7JhQP-XaagaXHnXREzX3GFA3ntdXQ@mail.gmail.com>
Message-ID: <BAY403-EAS1809EE649936642E7FE366DD3C10@phx.gbl>

This is perfect!  Thanks William!!!

Vince

> On May 21, 2015, at 3:36 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> I renamed your 'c' to be 'toyData' and your 'e' to be 'desiredResult'.  Do you
> want the following, which uses only base R code?
> 
> > vapply(toyData,
>               FUN=function(V)with(V, sum(Wgt[SPCLORatingValue>16])),
>               FUN.VALUE=0)
>          V5          V8         V10         V44          V2
> 0.008714910 0.000000000 0.000000000 0.004357455 0.008714910
> 
> It what is in your desired result but in a more useful format (e.g., numbers
> instead of character strings for sum).
> 
> > desiredResult
>      [,1]          [,2] [,3]  [,4]          [,5]
> [1,] "V5"          "V8" "V10" "V44"         "V2"
> [2,] "0.008714910" "0"  "0"   "0.004357455" "0.008714910"
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
>> On Thu, May 21, 2015 at 9:50 AM, Vin Cheng <newrnewbie at hotmail.com> wrote:
>> Thanks William/Duncan!
>>  
>> Duncan - Yes - I am using the doBy package.
>>  
>> running this line on the sample data below gives weights for V5,V44, & V2.  Ideally I would like 0's for V8 and V10 in the output.
>>  
>> So it would look like:
>> e<-structure(matrix(c("V5", "0.008714910", "V8", "0", "V10", "0", "V44", "0.004357455", "V2", "0.008714910"),nrow = 2))
>>  
>>  
>> This is far as I've gotten by subsetting and  summing:
>> a<-t(summaryBy(Wgt.sum~as.numeric(.id),data=subset(ldply(c,function(x) summaryBy(Wgt ~ SPCLORatingValue, data=x, FUN=c(sum))),SPCLORatingValue>16),FUN=c(sum),order=FALSE))
>>  
>> All help/guidance is much appreciated!  Thanks Vince!
>>  
>> Sample data example:
>> c<-structure(list(V5 = structure(list(WgtBand = c(2, 2, 2, 2, 2, 
>> 2, 2, 2, 2, 2, 2), Wgt = c(0.00435745520833333, 0.00435745520833333, 
>> 0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>> 0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>> 0.00435745520833333, 0.00435745520833333, 0.00435745520833333
>> ), SPCLORatingValue = c(11L, 15L, 14L, 15L, 14L, 14L, 16L, 19L, 
>> 13L, 17L, 11L)), .Names = c("WgtBand", "Wgt", "SPCLORatingValue"
>> ), row.names = 12:22, class = "data.frame"), V8 = structure(list(
>>     WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), Wgt = c(0.00435745520833333, 
>>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>>     0.00435745520833333), SPCLORatingValue = c(14L, 15L, 15L, 
>>     12L, 15L, 12L, 13L, 15L, 14L, 15L, 14L)), .Names = c("WgtBand", 
>> "Wgt", "SPCLORatingValue"), row.names = 12:22, class = "data.frame"), 
>>     V10 = structure(list(WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2, 
>>     2, 2, 2), Wgt = c(0.00435745520833333, 0.00435745520833333, 
>>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333
>>     ), SPCLORatingValue = c(15L, 13L, 14L, 14L, 13L, 13L, 13L, 
>>     15L, 15L, 13L, 14L)), .Names = c("WgtBand", "Wgt", "SPCLORatingValue"
>>     ), row.names = 12:22, class = "data.frame"), V44 = structure(list(
>>         WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), Wgt = c(0.00435745520833333, 
>>         0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>>         0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>>         0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>>         0.00435745520833333), SPCLORatingValue = c(13L, 14L, 
>>         16L, 15L, 14L, 14L, 18L, 13L, 16L, 15L, 11L)), .Names = c("WgtBand", 
>>     "Wgt", "SPCLORatingValue"), row.names = 12:22, class = "data.frame"), 
>>     V2 = structure(list(WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 
>>     2, 2), Wgt = c(0.00435745520833333, 0.00435745520833333, 
>>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333
>>     ), SPCLORatingValue = c(13L, 14L, 15L, 15L, 15L, 14L, 12L, 
>>     16L, 17L, 15L, 19L)), .Names = c("WgtBand", "Wgt", "SPCLORatingValue"
>>     ), row.names = 12:22, class = "data.frame")), .Names = c("V5", 
>> "V8", "V10", "V44", "V2"))
>> structure(list(V5 = structure(list(WgtBand = c(2, 2, 2, 2, 2, 
>> 2, 2, 2, 2, 2, 2), Wgt = c(0.00435745520833333, 0.00435745520833333, 
>> 0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>> 0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>> 0.00435745520833333, 0.00435745520833333, 0.00435745520833333
>> ), SPCLORatingValue = c(11L, 15L, 14L, 15L, 14L, 14L, 16L, 19L, 
>> 13L, 17L, 11L)), .Names = c("WgtBand", "Wgt", "SPCLORatingValue"
>> ), row.names = 12:22, class = "data.frame"), V8 = structure(list(
>>     WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), Wgt = c(0.00435745520833333, 
>>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>>     0.00435745520833333), SPCLORatingValue = c(14L, 15L, 15L, 
>>     12L, 15L, 12L, 13L, 15L, 14L, 15L, 14L)), .Names = c("WgtBand", 
>> "Wgt", "SPCLORatingValue"), row.names = 12:22, class = "data.frame"), 
>>     V10 = structure(list(WgtBand = c(2, 2, 2, 2, 2, 2, 2, 2, 
>>     2, 2, 2), Wgt = c(0.00435745520833333, 0.00435745520833333, 
>>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333, 
>>     0.00435745520833333, 0.00435745520833333, 0.00435745520833333
>>     ), SPCLORatingValue = c(15L, 13L, 14L, 14L, 13L, 13L, 13L, 
>>     15L, 15L, 13L, 14L)), .Names = c("WgtBand", "Wgt", "SPCLORatingValue"))))
>>  
>>  
>>  
>>  
>>  
>>  
>>  
>>  
>>  
>>  
>>  
>>  
>> 
>>  
>> From: wdunlap at tibco.com
>> Date: Wed, 20 May 2015 22:12:01 -0700
>> Subject: Re: [R] Subset and 0 replace?
>> To: newrnewbie at hotmail.com
>> CC: r-help at r-project.org
>> 
>> 
>> Can you show a small self-contained example of you data and expected results?
>> I tried to make one and your expression returned a single number in a 1 by 1 matrix.
>> 
>> library(doBy)
>> Generation<-list(
>>    data.frame(Wgt=c(1,2,4), SPCLORatingValue=c(10,11,12)),
>>    data.frame(Wgt=c(8,16), SPCLORatingValue=c(15,17)),
>>    data.frame(Wgt=c(32,64), SPCLORatingValue=c(19,20)))
>>  t(summaryBy(Wgt.sum~as.numeric(.id),data=subset(ldply(Generation,function(x) summaryBy(Wgt ~ SPCLORatingValue, data=x, FUN=c(sum))),SPCLORatingValue>16),FUN=c(sum),order=FALSE))
>> #              1
>> #Wgt.sum.sum 112
>> str(.Last.value)
>> # num [1, 1] 112
>> # - attr(*, "dimnames")=List of 2
>> #  ..$ : chr "Wgt.sum.sum"
>> #  ..$ : chr "1"
>> 
>> Two ways of dealing with the problem you verbally described are
>> (a) determine which elements of the input you can process (e.g., which
>> have some values>16) and use subscripting on both the left and right
>> side of the assignment operator to put the results in the right place.  E.g.,
>>     x <- c(-1, 1, 2)
>>     ok <- x>0
>>     x[ok] <- log(x[ok])
>> (b) make your function handle any case so you don't have to do any
>> subsetting on either side.  In your case it may be easy since sum(zeroLongNumericVector) is 0. In other cases you may want to use ifelse,
>> as in
>>    x <- c(-1, 1, 2)
>>    x <- ifelse(x>0, log(x), x)
>> 
>> 
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>> On Wed, May 20, 2015 at 4:13 PM, Vin Cheng <newrnewbie at hotmail.com> wrote:
>> Hi,
>> 
>> I'm trying to group rows in a dataframe with SPCLORatingValue factor >16 and summing the Wgt's that correspond to this condition.  There are 100 dataframes in a list.
>> 
>> Some of the dataframes won't have any rows that have this condition SPCLORatingValue>16 and therefore no corresponding weight.
>> 
>> My problem is that I need to have a corresponding value for each dataframe in the list - so 100 values.
>> 
>> If dataframe 44 doesn't have any SPCLORatingValue>16, then I end up getting a vector that's 99 long vs. 100.  putting value 45 into 44's slot and so on.
>> 
>> Is there either an if/else statement or argument I can place into subset to put a 0 for the data frames that don't have SPCLORatingValue>16?
>> 
>> GenEval[18,1:100] <- t(summaryBy(Wgt.sum~as.numeric(.id),data=subset(ldply(Generation,function(x) summaryBy(Wgt ~ SPCLORatingValue, data=x, FUN=c(sum))),SPCLORatingValue>16),FUN=c(sum),order=FALSE))
>> 
>> Any help or guidance would be greatly appreciated!
>> Many Thanks,
>> Vince
>> 
>> 
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 

	[[alternative HTML version deleted]]


From rashnaikk at gmail.com  Fri May 22 09:09:05 2015
From: rashnaikk at gmail.com (Rashmi Naik k)
Date: Fri, 22 May 2015 12:39:05 +0530
Subject: [R] Genetic algorithm workflow Problem..!! Is it right or wrong ??
Message-ID: <CAKKZ-YE-MJpWHDoNG4t-4XNkwdQmA8M4Y0wscEFO04pw_Mb82A@mail.gmail.com>

I'm actually looking for a way to use a genetic algorithm to optimize
product price's in an e-commerce store. and im doing it in R language.

I'm using GA package in r and below is my data set.

library(GA)
dataset-------input1

    Production.Cost Product.Price Product.Quality Delivery.Time
After.Sales.Service Sellers.Reputation Selling.Price

[1,]        871.1901        879.99         1139.99
895.13             1029.98                  986.2725          1066

[2,]        296.9901        299.99          329.95
329.73              334.99                    323.6650           321


---------------------------------------------------------
and this is my fitness function

f <-function(x) x * runif(1)
 fitness <-function(x) f(x)
--------------------------------------------------
and i have generated a random population

pop<-gareal_Population(rp,input1)
-----------------------------------------------------
i have used roulette wheel selection

sel<-gareal_rwSelection(rp,pop$population)
---------------------------------------------------------------

I have Used Single point Crossover

cross<-gareal_spCrossover(rp,sel$population)
----------------------------------------------------------------------------------

I Don't know whether i'm doing it right or not..!! But i don't know how to
optimize a products price using Genetic algorithm.
Can any body suggest me on this.. and take me to a right direction.

Any Suggestions accepted..!! Please do help me on this

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Fri May 22 12:03:17 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 22 May 2015 12:03:17 +0200
Subject: [R] Selective package installation
In-Reply-To: <CADcgpJey-r8adNBcH0ACDDZg64YXJ6oRfg7CTkS5uHeKpYoAYw@mail.gmail.com>
References: <CADcgpJey-r8adNBcH0ACDDZg64YXJ6oRfg7CTkS5uHeKpYoAYw@mail.gmail.com>
Message-ID: <555EFEE5.3070406@statistik.tu-dortmund.de>



On 18.05.2015 09:14, Partha Sinha wrote:
> I am using Win 7, 32 bit and R 3.2.0
>
> I want to install few packages via script.
> The script should first check if the package is already installed (I
> dont want update).

assume the packages are given in a character vector pkg.

pkg <- c("MASS", "A")

Then:

inst <- installed.packages()[,1]
install.packages(setdiff(pkg, inst))

Best,
Uwe Ligges





> If the package is already there , then it would go
> to the next package in my list.


> How can I do this ?
> Parth
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkrideau at inbox.com  Fri May 22 13:17:58 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 22 May 2015 03:17:58 -0800
Subject: [R] Vincentizing Reaction Time data in R
In-Reply-To: <555DFEAA.4000507@gmail.com>
References: <1a175f8ee5e.00000c3ajrkrideau@inbox.com>
	<555c5e3d.6090103@gmail.com>
Message-ID: <255099FE2FC.00000513jrkrideau@inbox.com>

Hi, Gabriel,

Do I  understand the idea behind 'vincentizing' reaction times? 
I don't want to work through the Ratcliff, (1979)  paper unless I must.

Let's say we have a subject , s1, with 50 rt scores.
We sort the scores from high to low (or low to high , it makes no difference) then we split the 50 scores into quantiles (let's say deciles) and calculate the mean/decile?   

Repeat for each subject.  We now have the 'vincentized' means. 

That's it? 

Example, of what I understand for just for one subject (s1)

# install plyr package if not already installed
install.packages("plyr")
#=======================================

library(plyr)

# create some sciency looking sample data
rtmatter   <- c (seq(0.50 , 1.50, 0.01), seq(0.55, 1.55,  0.01) )
str(rtmatter)  # verify it looks sciencey 

# create one subject
s1  <-  sample(rtmatter, 50, replace = TRUE)

# calculate 'vincentized' means for s1
s1  <-  sort(s1)
c1  <-  cut(s1, 10, right = TRUE)
ss1  <-  data.frame(c1,  s1)
vince1   <-   ddply(ss1, .(c1), summarize, decile.mean = mean(s1) )
vince1


John Kane
Kingston ON Canada


> -----Original Message-----
> From: gabriel.weindel at gmail.com
> Sent: Thu, 21 May 2015 17:50:02 +0200
> To: jrkrideau at inbox.com, yishinlin001 at gmail.com, gunter.berton at gene.com,
> djnordlund at frontier.com
> Subject: Re: [R] Vincentizing Reaction Time data in R
> 
> Bert : Thank you for your advice, it would be a little bit difficult to
> do it for my master thesis but, if I want to go further with a PhD
> thesis (and I do want), I would probably follow your advice and get in
> touch with a statistician.
> 
> Yishin : Thank you very much for the references, I will definitively
> read the papers you quote. I'm already a little bit aware of the misuses
> possible with the vincentization in particular thanks to the paper of
> Rouder and Speckman (2004) and it seems to fit with my design. No
> problem if you want to keep the code but I have to tell you that it's
> our first semester using R and the teacher surely didn't thought that we
> will run out of available code with our experiment. Like John guessed
> the purpose of the course was to give a first view of R to get over the
> temptation of SPSS, my bad if I want to avoid biased statistics like
> sample mean ANOVA's on RT.
> 
> Dan : Thank you for your tip, this sure will help but I'm quiet at the
> beginning of my R skills so I hardly trust myself to do it on my own,
> but I can sure give it a try.
> 
> John : I had the same assumption but my research director warned me that
> I might run out of time for my first presentation by doing so but fairly
> enough for my master thesis. But again like I said to Dan I'm quiet
> concerned by my actual R skill.
> 
> Anyway I have to say that I'm really glad to see how much help you can
> get by using the r-help mailing-list.
> 
> Regards,
> Gabriel
> 
> Le 21/05/2015 15:52, John Kane a ?crit :
>> In line
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: yishinlin001 at gmail.com
>>> Sent: Thu, 21 May 2015 10:13:54 +0800
>>> To: gabriel.weindel at gmail.com
>>> Subject: Re: [R] Vincentizing Reaction Time data in R
>>> 
>>> On Wed, 20 May 2015 18:13:17 +0800,
>>> Hi Gabriel,
>>> 
>>> As far as I could recall, there isn't an R package that has explicitly
>>> implemented "vincentization". You definitively can find some code
>>> segments/functions that have implemented "vincentize" on the web. But
>>> you
>>> should verify if they do exactly what you wish to do.  If you could
>>> look
>>> at the question from percentile/quantle perspective, it would not take
>>> you too much time to realise that they are similar.  I would suggest
>>> you
>>> to read, as John Kane suggested, Prof. Ratcliff's 1979 paper.  Another
>>> paper that may be very helpful is Prof van Zandt's 2000 RT paper.
>>> 
>>> However, you should be aware that there are some different
>>> implementation
>>> of "vincentization", and it is debatable, if not problematic, to use
>>> it,
>>> rather than other more general quantile methods. It would help you to
>>> understand not only how to do vincentization, but also why/why not if
>>> you
>>> could read papers from Jeff Rouder's as well as from Heathcote's and
>>> Brown's lab.
>>> 
>>> Sorry that I hesitate to give you the code, because this looks like
>>> part
>>> of your course works.  It would be more rewarding for you, if you could
>>> figure out by yourself.
>>> 
>>> Yishin
>>> 
>> While I agree the exercise is likely to be a good learning experience I
>> don't see this as the equivalent of course work.
>> 
>> If Gabriel (the OP) was tasked with implementing  "vincentization" in R
>> then, strictly speaking it is course work but if I understand him the
>> requirement is to do his work in R rather than Minitab.  If such a
>> function existed in an existing R package than he could have simply
>> plugged in the numbers et voil?, done.
>> 
>> The tenor of the question did not suggest this and it would require the
>> stats instructor to know that there was no  "vincentization" function
>> anywhere among the, what, a thousand or so packages? And if the OP was
>> working on his own data as part of the course then the instructor might
>> have little or no idea of exactly what functions are needed
>> 
>> The course  strikes me more as an effort to get psychologists away from
>> SPSS which often seems to be the only software package anyone knows.
>> 
>> 
>>> Gabriel WEINDEL wrote:
>>>> 
>>>> Dear all,
>>>> 
>>>> For my master thesis, I'm currently working in cognitive neuroscience
>>>> on executive control through measurement of reaction time and I need
>>>> to get my data 'vincentized' with an exclusive use of R set by my
>>>> statistic teacher for a test purpose, for this reason I can't use the
>>>> python code the lab team usually uses.
>>>> Despite a dozen hours of research I couldn't find any package or
>>>> R-code which would allow the use of vincentization, that's why I'm
>>>> querying help on the R forum.
>>>> 
>>>> So has anyone ever used vincentization in R ?
>>>> 
>>>> Best regards,
>>>> 
>>>> --
>>>> Gabriel Weindel
>>>> Master student in Neuropsychology - Aix-Marseille University (France)
>>>> 
>> 
>> ____________________________________________________________
>> Can't remember your password? Do you need a strong and secure password?
>> Use Password manager! It stores your passwords & protects your account.
>> Check it out at http://mysecurelogon.com/manager
>> 
>>

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From cdetermanjr at gmail.com  Fri May 22 14:16:11 2015
From: cdetermanjr at gmail.com (Charles Determan)
Date: Fri, 22 May 2015 07:16:11 -0500
Subject: [R] compiling R with tuned BLAS
In-Reply-To: <555E2FD8.80504@gmail.com>
References: <555E2FD8.80504@gmail.com>
Message-ID: <CAKxd1KOwQe9zKoVfv9yByeC8H=AzHD9YzRm8LkdvF7EevoyWqg@mail.gmail.com>

Which OS are you using (Windows, Linux (distro), Mac)?  When you mention
.so files I tend to assume you are using a Linux system.  If you are using
ubuntu, changing the BLAS used by R is relatively trivial by using
'update-alternatives'.  More detail is provided at the following link:
http://www.stat.cmu.edu/~nmv/2013/07/09/for-faster-r-use-openblas-instead-better-than-atlas-trivial-to-switch-to-on-ubuntu/

Charles

On Thu, May 21, 2015 at 2:19 PM, Michael Gooch <goochmi at gmail.com> wrote:

> I am looking at the instructions on
> http://cran.r-project.org/doc/manuals/r-patched/R-admin.html#ATLAS
>
> I have noticed that ATLAS produces two shared libs in addition to the *.a
> files:
> http://math-atlas.sourceforge.net/atlas_install/node22.html
>
> contents of the ATLAS lib directory:
> libatlas.a  libcblas.a  libf77blas.a  liblapack.a  libptcblas.a
> libptf77blas.a  libsatlas.so  libtatlas.so
>
> The instructions do not appear to match up with the *.a files & *.so files
> as described. (it appears to want me to use shared libs, but the names
> defined are static libs, not shared libs).
>
> should I simply be having it link against libtatlas.so (and pthreads) for
> shared threaded atlas and libsatlas.so for shared sequential atlas?
> do I need shared versions of the other static libraries?
>
> I think the help is a bit out of date, or at least unclear as to what it
> intends of me.
>
> M. Gooch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From cflynch at ncsu.edu  Fri May 22 16:20:00 2015
From: cflynch at ncsu.edu (Collin Lynch)
Date: Fri, 22 May 2015 10:20:00 -0400
Subject: [R] Genetic algorithm workflow Problem..!! Is it right or wrong
	??
In-Reply-To: <CAKKZ-YE-MJpWHDoNG4t-4XNkwdQmA8M4Y0wscEFO04pw_Mb82A@mail.gmail.com>
References: <CAKKZ-YE-MJpWHDoNG4t-4XNkwdQmA8M4Y0wscEFO04pw_Mb82A@mail.gmail.com>
Message-ID: <CAE=6FXb9vJuwJk1SO4JZTfZ1Mes6tDV1_uyxncVzb2mNmQDOiQ@mail.gmail.com>

Rashmi, I think that this might be beyond the scope of this list as it
is focused on issues with the R language specifically.  It does not
look like you have any R errors although we would need to see some
output to be sure.

With respect to the general GA workflow it appears that you are doing
it right although the exact function of your fitness operator is not
clear to me.  I recommend looking at "An Introduction to Genetic
Algorithms" by Melanie Mitchell.  That is a good resource for more
general GA advice.

    Sincerely,
    Collin Lynch.



On Fri, May 22, 2015 at 3:09 AM, Rashmi Naik k <rashnaikk at gmail.com> wrote:
> I'm actually looking for a way to use a genetic algorithm to optimize
> product price's in an e-commerce store. and im doing it in R language.
>
> I'm using GA package in r and below is my data set.
>
> library(GA)
> dataset-------input1
>
>     Production.Cost Product.Price Product.Quality Delivery.Time
> After.Sales.Service Sellers.Reputation Selling.Price
>
> [1,]        871.1901        879.99         1139.99
> 895.13             1029.98                  986.2725          1066
>
> [2,]        296.9901        299.99          329.95
> 329.73              334.99                    323.6650           321
>
>
> ---------------------------------------------------------
> and this is my fitness function
>
> f <-function(x) x * runif(1)
>  fitness <-function(x) f(x)
> --------------------------------------------------
> and i have generated a random population
>
> pop<-gareal_Population(rp,input1)
> -----------------------------------------------------
> i have used roulette wheel selection
>
> sel<-gareal_rwSelection(rp,pop$population)
> ---------------------------------------------------------------
>
> I have Used Single point Crossover
>
> cross<-gareal_spCrossover(rp,sel$population)
> ----------------------------------------------------------------------------------
>
> I Don't know whether i'm doing it right or not..!! But i don't know how to
> optimize a products price using Genetic algorithm.
> Can any body suggest me on this.. and take me to a right direction.
>
> Any Suggestions accepted..!! Please do help me on this
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From peter_van_summeren at hotmail.com  Fri May 22 16:00:41 2015
From: peter_van_summeren at hotmail.com (Peter van Summeren)
Date: Fri, 22 May 2015 16:00:41 +0200
Subject: [R] Debian Rcmdr misses sem leaps etc
Message-ID: <DUB122-W49175573C34BFC0AEC09D3DAC00@phx.gbl>

Hello,when I start up Rcmdr under Jessie Debian I get the message that there are packages missing:sem, markdown, leaps, knitr, aplpackIt then wants to get these from cran. But first I have to tell where to put them: I HAVE NO IDEA.I downloaded Rcmdr via a package program.Can anyone help me to get a good Rcmdr?with friendly greetings,Peter 		 	   		  
	[[alternative HTML version deleted]]


From catarinaramosmaia at gmail.com  Fri May 22 19:08:13 2015
From: catarinaramosmaia at gmail.com (Catarina Maia)
Date: Fri, 22 May 2015 18:08:13 +0100
Subject: [R] error message
Message-ID: <CAGR7OBNNwJVmhV5iMLHTPdV7b2KrjcgwNs2EOmMYq5yUhYOFFA@mail.gmail.com>

Hi
Can you please help me :(

I am trying to fit a multilevel model but I have received the following
message

skate.3 <- bugs (skate.data, inits=NULL, skate.parameters,
"skates.bug",+                  n.chains=2, n.iter=500, +
bugs.directory="c:/ProgramFiles(x86)/OpenBUGS/OpenBUGS323",+
  program=c("OpenBUGS"))model is syntactically correctexpected
variable name error pos 5 (error on line 1)variable n is not
definedmodel must be compiled before generating initial valuesSampling
has been started ...model must be initialized before updatingmodel
must be initialized before DIC can be monitoredError in
BRugs::samplesSet(parametersToSave) :
  model must be initialized before monitors used

	[[alternative HTML version deleted]]


From ifigueiredo at ipma.pt  Fri May 22 18:57:08 2015
From: ifigueiredo at ipma.pt (Ivone Figueiredo)
Date: Fri, 22 May 2015 17:57:08 +0100
Subject: [R] ERROR Message
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAHoPlyHqlMtJunuDgZb1NhbCgAAAEAAAAFrePFU5YnxArSLRPlWCMccBAAAAAA==@ipma.pt>

Hi 

Could you please help me 

I am trying to fit a Multilevel Poisson regression with the following code 

## BUGS CODE

## Multilevel Poisson regression 

model {

  for (i in 1:n){

    y[i] ~ dpois (lambda[i])

    log(lambda[i]) <- mu + 

      b.species[Species[i]] + b.quarter[Quarter[i]] + epsilon[i]

    epsilon[i] ~ dnorm (0, tau.epsilon)

  }

  mu ~ dnorm (0, .0001)

  mu.adj <- mu +  mean(b.species[]) + mean(b.quarter[])

  tau.epsilon <- pow(sigma.epsilon, -2)

  sigma.epsilon ~ dunif (0, 100)

  

  for (j in 1:n.species){

    b.species[j] ~ dnorm (0, tau.species)

    b.species.adj[j] <-  b.species[j] - mean( b.species[])

  }

  tau.species <- pow(sigma.species, -2)

  sigma.species ~ dunif (0, 100)

  

  for (j in 1:n.quarters){

    b.quarter[j] ~ dnorm (0, tau.quarter)

    b.quarter.adj[j] <- b.quarter[j] - mean(b.quarter[])

  }

  tau.quarter <- pow(sigma.quarter, -2)

  sigma.quarter ~ dunif (0, 100)

}

 

##

 

skate.data <- list ("Species", "n.species", "Quarter", "n.quarters", "y")

                    

#radon.inits <- function (){

#  list (a=rnorm(J), b=rnorm(1), g.0=rnorm(1), g.1=rnorm(1),

#        sigma.y=runif(1), sigma.a=runif(1))

#}

 

skate.parameters <- c ("mu", "b.quarter", "b.species", "sigma.species",
"sigma.quarter", "sigma.epsilon")

 

skate.3 <- bugs (skate.data, inits=NULL, skate.parameters, "skates.bug",

                 n.chains=3, n.iter=500, 

            bugs.directory="c:/ProgramFiles(x86)/OpenBUGS/OpenBUGS323",

            program=c("OpenBUGS"))

 

 

But I always receive this message error 

 

Loading required package: BRugs

Welcome to BRugs connected to OpenBUGS version 3.2.3

model is syntactically correct

Error in aperm.default(datalist[[i]]) : 

  invalid first argument, must be an array

In addition: Warning messages:

1: package 'BRugs' was built under R version 3.0.3 

2: In FUN(X[[5L]], ...) : class of 'x' was discarded

 

 

 


	[[alternative HTML version deleted]]


From knussear at mac.com  Fri May 22 19:26:03 2015
From: knussear at mac.com (Ken Nussear)
Date: Fri, 22 May 2015 10:26:03 -0700
Subject: [R] data.table cant find function melt?
Message-ID: <555F66AB.7080001@mac.com>

Hi all, trying to use the melt function in data.table and I'm getting an
error....

Anyone seen this before or know how to fix it?

Thanks

str(Distdata)

Classes ?data.table? and 'data.frame':	828451 obs. of  3 variables:
 $ Poly1   : int  50088 50088 50088 50088 50088 50088 50088 50088 50088
50088 ...
 $ Poly2   : int  44884 11542 11543 11540 11541 11546 11547 11544 11545
11548 ...
 $ Distance: int  788641 3794345 3652511 3915074 3895469 3639175 3644151
3648356 3646023 3615863 ...
 - attr(*, ".internal.selfref")=<externalptr> 



melt.data.table(Distdata, id.vars=Poly1, measure.vars=Poly2)

Error: could not find function "melt.data.table"

melt(Distdata, id.vars=Poly1, measure.vars=Poly2)

Error: could not find function "melt"]


From jrkrideau at inbox.com  Fri May 22 19:25:56 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 22 May 2015 09:25:56 -0800
Subject: [R] error message
In-Reply-To: <CAGR7OBNNwJVmhV5iMLHTPdV7b2KrjcgwNs2EOmMYq5yUhYOFFA@mail.gmail.com>
Message-ID: <2887144D07B.00000AAFjrkrideau@inbox.com>

I think we need a couple of things. First we need your post in text not hmtl.  R-help removes the html as a security feature and it turns your post into a complete mess. See below.

Second we probably need more information and some data.  Please read one or both of these http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html

Welcome to the R-help list

John Kane
Kingston ON Canada


> -----Original Message-----
> From: catarinaramosmaia at gmail.com
> Sent: Fri, 22 May 2015 18:08:13 +0100
> To: r-help at r-project.org
> Subject: [R] error message
> 
> Hi
> Can you please help me :(
> 
> I am trying to fit a multilevel model but I have received the following
> message
> 
> skate.3 <- bugs (skate.data, inits=NULL, skate.parameters,
> "skates.bug",+                  n.chains=2, n.iter=500, +
> bugs.directory="c:/ProgramFiles(x86)/OpenBUGS/OpenBUGS323",+
>   program=c("OpenBUGS"))model is syntactically correctexpected
> variable name error pos 5 (error on line 1)variable n is not
> definedmodel must be compiled before generating initial valuesSampling
> has been started ...model must be initialized before updatingmodel
> must be initialized before DIC can be monitoredError in
> BRugs::samplesSet(parametersToSave) :
>   model must be initialized before monitors used
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From jrkrideau at inbox.com  Fri May 22 19:28:23 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 22 May 2015 09:28:23 -0800
Subject: [R] Debian Rcmdr misses sem leaps etc
In-Reply-To: <DUB122-W49175573C34BFC0AEC09D3DAC00@phx.gbl>
Message-ID: <288C89DF4A5.00000ABCjrkrideau@inbox.com>

On Ubuntu I just let R install new packages  wherever it wants.  

Is R on Jesse suggesting a spot?  If so, go with it.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: peter_van_summeren at hotmail.com
> Sent: Fri, 22 May 2015 16:00:41 +0200
> To: r-help at r-project.org
> Subject: [R] Debian Rcmdr misses sem leaps etc
> 
> Hello,when I start up Rcmdr under Jessie Debian I get the message that
> there are packages missing:sem, markdown, leaps, knitr, aplpackIt then
> wants to get these from cran. But first I have to tell where to put them:
> I HAVE NO IDEA.I downloaded Rcmdr via a package program.Can anyone help
> me to get a good Rcmdr?with friendly greetings,Peter
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From cjrinconr at unal.edu.co  Fri May 22 19:32:40 2015
From: cjrinconr at unal.edu.co (Carlos Javier Rincon Rodriguez)
Date: Fri, 22 May 2015 12:32:40 -0500
Subject: [R] Heatmap
In-Reply-To: <CABeLv6g=88qDfYaKNZzG4=NxKaD+NBc9Fg0uaVvSyq445SpHKg@mail.gmail.com>
References: <CAJgdCD7eTRMAJA5oJZPNeNU-fU1tnYwd4ujfy2fboQ+-iUYEUg@mail.gmail.com>
	<553F180F020000CB0012ADCA@smtp.medicine.umaryland.edu>
	<CABeLv6g=88qDfYaKNZzG4=NxKaD+NBc9Fg0uaVvSyq445SpHKg@mail.gmail.com>
Message-ID: <CABeLv6if8XB7AV-Y8LHV_gA8SUgDhjn3EG7x_A-ph5EyoGCQ5g@mail.gmail.com>

Hi. Good morning.

I am trying to load a shapefile to do a heatmap of Colombia. I using all
this package:

library(ctv)

library(spatial)

library(ggplot2)

library(sp)

library(rgdal)

library(rgeos)

library(maptools)

library(ggmap)


and a using this two commands to load the file:


depto<-readShapePoly("depto.shp")

depto <- readOGR(dsn = ".", "depto")


but the result is:


     depto<-readShapePoly("depto.shp")

     Error in getinfo.shape(filen) : Error opening SHP file


     depto <- readOGR(dsn = ".", "depto")

     Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding,
use_iconv = use_iconv,  : Cannot open file


Also I am working in a MAC computer and when I open R, I have this warning
message:


    WARNING: You're using a non-UTF8 locale, therefore only ASCII
characters will work.

    Please read R for Mac OS X FAQ (see Help) section 9 and adjust your
system preferences accordingly.


I looking the R for Mac document but there is not section 9.!!!


Thanks for any help.



Carlos.



2015-05-05 18:01 GMT-05:00 Carlos Javier Rincon Rodriguez <
cjrinconr at unal.edu.co>:

> Hi.
>
> This is my problem. I try to load a shapefile to do a heatmap of Colombia.
> I using all this package:
>
> library(ctv)
>
> library(spatial)
>
> library(ggplot2)
>
> library(sp)
>
> library(rgdal)
>
> library(rgeos)
>
> library(maptools)
>
> library(ggmap)
>
>
> and a using this two commands to load the file:
>
>
> depto<-readShapePoly("depto.shp")
>
> depto <- readOGR(dsn = ".", "depto")
>
>
> but the result is:
>
>
> depto<-readShapePoly("depto.shp")
>
> Error in getinfo.shape(filen) : Error opening SHP file
>
>
> depto <- readOGR(dsn = ".", "depto")
>
> Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding, use_iconv
> = use_iconv,  :
>
>   Cannot open file
>
> I attach the shapefile that i using.
>
> also i am working in mac computer i don know if that could be the reason.
>
> if somebody knows thanks.
>
>
>
> 2015-04-28 4:18 GMT-05:00 John Sorkin <jsorkin at grecc.umaryland.edu>:
>
> Look at the heatmap function
>>
>> > John David Sorkin M.D., Ph.D.
>> > Professor of Medicine
>> > Chief, Biostatistics and Informatics
>> > University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> > Baltimore VA Medical Center
>> > 10 North Greene Street
>> > GRECC (BT/18/GR)
>> > Baltimore, MD 21201-1524
>> > (Phone) 410-605-7119
>> > (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>>
>> > On Apr 28, 2015, at 3:41 AM, John Wasige <johnwasige at gmail.com> wrote:
>> >
>> > Dear all,
>> >
>> > I need to make a heapmap of SPI results for a monthly timeseies of 30
>> > years. Does anybody know to do it?
>> >
>> > Thanks for your help
>> >
>> > John
>> >
>> >    [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> Confidentiality Statement:
>> This email message, including any attachments, is for the sole use of the
>> intended recipient(s) and may contain confidential and privileged
>> information. Any unauthorized use, disclosure or distribution is
>> prohibited. If you are not the intended recipient, please contact the
>> sender by reply email and destroy all copies of the original message.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Fri May 22 19:39:13 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 22 May 2015 09:39:13 -0800
Subject: [R] data.table cant find function melt?
In-Reply-To: <555F66AB.7080001@mac.com>
Message-ID: <28A4C16BC5D.00000ADFjrkrideau@inbox.com>

Hi Ken,

This is strange but look at the example at ?melt , pick the data.table example not the reshape2 example.

It looks to me like data.table is using the reshape2 melt() 

Perhaps data.table used to load reshape2 but now you need to do it explicitly, or at least that's my guess.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: knussear at mac.com
> Sent: Fri, 22 May 2015 10:26:03 -0700
> To: r-help at r-project.org
> Subject: [R] data.table cant find function melt?
> 
> Hi all, trying to use the melt function in data.table and I'm getting an
> error....
> 
> Anyone seen this before or know how to fix it?
> 
> Thanks
> 
> str(Distdata)
> 
> Classes ?data.table? and 'data.frame':	828451 obs. of  3 variables:
>  $ Poly1   : int  50088 50088 50088 50088 50088 50088 50088 50088 50088
> 50088 ...
>  $ Poly2   : int  44884 11542 11543 11540 11541 11546 11547 11544 11545
> 11548 ...
>  $ Distance: int  788641 3794345 3652511 3915074 3895469 3639175 3644151
> 3648356 3646023 3615863 ...
>  - attr(*, ".internal.selfref")=<externalptr>
> 
> 
> 
> melt.data.table(Distdata, id.vars=Poly1, measure.vars=Poly2)
> 
> Error: could not find function "melt.data.table"
> 
> melt(Distdata, id.vars=Poly1, measure.vars=Poly2)
> 
> Error: could not find function "melt"]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From stefano.sofia at regione.marche.it  Fri May 22 20:02:26 2015
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Fri, 22 May 2015 18:02:26 +0000
Subject: [R] apply a function to a list of data frames
Message-ID: <8B435C9568170B469AE31E8891E8CC4F280584CF@CHIENTI.regionemarche.intra>

Dear R-users,
given a list of dataframes (like below reported), for each month I need to apply a function (called calc).
The result should be written in a new list of data frames, one row for each month.

I have been trying to use sapply, with no success.
Could somebody help me in this?


$df1
day dmo_12 Eonestep_12 tmax dmo_27 Eonestep_27 tmin
2012-12-01 11 13 13 9 8 8
2012-12-02 11 13 13 5 6 8
2012-12-03 6 10 8 6 6 7
2012-12-04 11 13 9 6 6 3
2012-12-05 8 10 12 5 6 7
2012-12-06 8 10 8 4 5 4
2012-12-07 7 9 8 6 6 5
...


calc <- function(dmo_12, Eonestep_12, dmo_27, Eonestep_27)
{
bias_dmo_max <- round(mean((dmo_12-Eonestep_12), na.rm=TRUE), digits=2)
rmse_dmo_max <- round(sqrt(mean((dmo_12-Eonestep_12)^2, na.rm=TRUE)), digits=2)
bias_dmo_min <- round(mean((dmo_27-Eonestep_27), na.rm=TRUE), digits=2)
rmse_dmo_min <- round(sqrt(mean((dmo_27-Eonestep_27)^2, na.rm=TRUE)), digits=2)
result <- list(bias_dmo_max, rmse_dmo_max, bias_dmo_min, rmse_dmo_min)
result
}


Thank you for your help
Stefano


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Fri May 22 20:09:00 2015
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 22 May 2015 14:09:00 -0400
Subject: [R] Debian Rcmdr misses sem leaps etc
In-Reply-To: <DUB122-W49175573C34BFC0AEC09D3DAC00@phx.gbl>
References: <DUB122-W49175573C34BFC0AEC09D3DAC00@phx.gbl>
Message-ID: <002701d094ba$619420f0$24bc62d0$@mcmaster.ca>

Dear Peter,

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Peter
> van Summeren
> Sent: May-22-15 10:01 AM
> To: .
> Subject: [R] Debian Rcmdr misses sem leaps etc
> 
> Hello,when I start up Rcmdr under Jessie Debian I get the message that
> there are packages missing:sem, markdown, leaps, knitr, aplpackIt then
> wants to get these from cran. But first I have to tell where to put
> them: I HAVE NO IDEA.I downloaded Rcmdr via a package program.Can anyone
> help me to get a good Rcmdr?with friendly greetings,Peter

I don't use Debian myself, but have you tried simply clicking the OK button
in the dialog box for installing the missing packages? Perhaps you've done
that and are then asked where to install the packages, but if so that's
unclear from your message. More generally, it would help to have more detail
about what you did.

A bit of background: There are two package systems, one for Debian, which
includes R, the Rcmdr package, and some other R packages (such as the car
package) used by the R Commander, and the CRAN R package archive. Most of
the R packages that the Rcmdr uses reside in the latter archive. If these
are missing, the R Commander detects that and asks your permission to
install them. As I said, simply clicking OK should work (as far as I know).

I'm cc'ing Dirk Eddelbuettel, who takes care of the R Debian packages.

I hope this helps,
 John

-----------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/



> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


---
This email has been checked for viruses by Avast antivirus software.
http://www.avast.com


From gunter.berton at gene.com  Fri May 22 20:14:12 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 22 May 2015 11:14:12 -0700
Subject: [R] apply a function to a list of data frames
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F280584CF@CHIENTI.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F280584CF@CHIENTI.regionemarche.intra>
Message-ID: <CACk-te2mJFg24ULdEWVGbDerLpEvzRQwBavNOLfxHew_OqDABQ@mail.gmail.com>

Where is your code? I see no invocation of sapply.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, May 22, 2015 at 11:02 AM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Dear R-users,
> given a list of dataframes (like below reported), for each month I need to apply a function (called calc).
> The result should be written in a new list of data frames, one row for each month.
>
> I have been trying to use sapply, with no success.
> Could somebody help me in this?
>
>
> $df1
> day dmo_12 Eonestep_12 tmax dmo_27 Eonestep_27 tmin
> 2012-12-01 11 13 13 9 8 8
> 2012-12-02 11 13 13 5 6 8
> 2012-12-03 6 10 8 6 6 7
> 2012-12-04 11 13 9 6 6 3
> 2012-12-05 8 10 12 5 6 7
> 2012-12-06 8 10 8 4 5 4
> 2012-12-07 7 9 8 6 6 5
> ...
>
>
> calc <- function(dmo_12, Eonestep_12, dmo_27, Eonestep_27)
> {
> bias_dmo_max <- round(mean((dmo_12-Eonestep_12), na.rm=TRUE), digits=2)
> rmse_dmo_max <- round(sqrt(mean((dmo_12-Eonestep_12)^2, na.rm=TRUE)), digits=2)
> bias_dmo_min <- round(mean((dmo_27-Eonestep_27), na.rm=TRUE), digits=2)
> rmse_dmo_min <- round(sqrt(mean((dmo_27-Eonestep_27)^2, na.rm=TRUE)), digits=2)
> result <- list(bias_dmo_max, rmse_dmo_max, bias_dmo_min, rmse_dmo_min)
> result
> }
>
>
> Thank you for your help
> Stefano
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Fri May 22 20:26:33 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 22 May 2015 19:26:33 +0100
Subject: [R] apply a function to a list of data frames
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F280584CF@CHIENTI.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F280584CF@CHIENTI.regionemarche.intra>
Message-ID: <555F74D9.8090706@sapo.pt>

Hello,

You should change your function to accept only one argument, the 
data.frames, and then use lapply (not sapply).
Something like the following.

calc <- function(dat)
{
	bias_dmo_max <- round(mean((dat$dmo_12-dat$Eonestep_12), na.rm=TRUE), 
digits=2)
	rmse_dmo_max <- round(sqrt(mean((dat$dmo_12-dat$Eonestep_12)^2, 
na.rm=TRUE)), digits=2)
	bias_dmo_min <- round(mean((dat$dmo_27-dat$Eonestep_27), na.rm=TRUE), 
digits=2)
	rmse_dmo_min <- round(sqrt(mean((dat$dmo_27-dat$Eonestep_27)^2, 
na.rm=TRUE)), digits=2)
	result <- list(bias_dmo_max, rmse_dmo_max, bias_dmo_min, rmse_dmo_min)
	result
}

result_lst <- lapply(lst, calc)


Hope this helps,

Rui Barradas


Em 22-05-2015 19:02, Stefano Sofia escreveu:
> Dear R-users,
> given a list of dataframes (like below reported), for each month I need to apply a function (called calc).
> The result should be written in a new list of data frames, one row for each month.
>
> I have been trying to use sapply, with no success.
> Could somebody help me in this?
>
>
> $df1
> day dmo_12 Eonestep_12 tmax dmo_27 Eonestep_27 tmin
> 2012-12-01 11 13 13 9 8 8
> 2012-12-02 11 13 13 5 6 8
> 2012-12-03 6 10 8 6 6 7
> 2012-12-04 11 13 9 6 6 3
> 2012-12-05 8 10 12 5 6 7
> 2012-12-06 8 10 8 4 5 4
> 2012-12-07 7 9 8 6 6 5
> ...
>
>
> calc <- function(dmo_12, Eonestep_12, dmo_27, Eonestep_27)
> {
> bias_dmo_max <- round(mean((dmo_12-Eonestep_12), na.rm=TRUE), digits=2)
> rmse_dmo_max <- round(sqrt(mean((dmo_12-Eonestep_12)^2, na.rm=TRUE)), digits=2)
> bias_dmo_min <- round(mean((dmo_27-Eonestep_27), na.rm=TRUE), digits=2)
> rmse_dmo_min <- round(sqrt(mean((dmo_27-Eonestep_27)^2, na.rm=TRUE)), digits=2)
> result <- list(bias_dmo_max, rmse_dmo_max, bias_dmo_min, rmse_dmo_min)
> result
> }
>
>
> Thank you for your help
> Stefano
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.CA.us  Fri May 22 20:32:00 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 22 May 2015 11:32:00 -0700
Subject: [R] Debian Rcmdr misses sem leaps etc
In-Reply-To: <002701d094ba$619420f0$24bc62d0$@mcmaster.ca>
References: <DUB122-W49175573C34BFC0AEC09D3DAC00@phx.gbl>
	<002701d094ba$619420f0$24bc62d0$@mcmaster.ca>
Message-ID: <9AD38871-E679-4CD6-BEED-F6F3CA9386C4@dcn.davis.CA.us>

For those R packages, as a normal user (rather than sysadmin of a shared computer) the OP should accept the default R/3.1 subdirectory in their home directory.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 22, 2015 11:09:00 AM PDT, John Fox <jfox at mcmaster.ca> wrote:
>Dear Peter,
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Peter
>> van Summeren
>> Sent: May-22-15 10:01 AM
>> To: .
>> Subject: [R] Debian Rcmdr misses sem leaps etc
>> 
>> Hello,when I start up Rcmdr under Jessie Debian I get the message
>that
>> there are packages missing:sem, markdown, leaps, knitr, aplpackIt
>then
>> wants to get these from cran. But first I have to tell where to put
>> them: I HAVE NO IDEA.I downloaded Rcmdr via a package program.Can
>anyone
>> help me to get a good Rcmdr?with friendly greetings,Peter
>
>I don't use Debian myself, but have you tried simply clicking the OK
>button
>in the dialog box for installing the missing packages? Perhaps you've
>done
>that and are then asked where to install the packages, but if so that's
>unclear from your message. More generally, it would help to have more
>detail
>about what you did.
>
>A bit of background: There are two package systems, one for Debian,
>which
>includes R, the Rcmdr package, and some other R packages (such as the
>car
>package) used by the R Commander, and the CRAN R package archive. Most
>of
>the R packages that the Rcmdr uses reside in the latter archive. If
>these
>are missing, the R Commander detects that and asks your permission to
>install them. As I said, simply clicking OK should work (as far as I
>know).
>
>I'm cc'ing Dirk Eddelbuettel, who takes care of the R Debian packages.
>
>I hope this helps,
> John
>
>-----------------------------------------------
>John Fox, Professor
>McMaster University
>Hamilton, Ontario, Canada
>http://socserv.socsci.mcmaster.ca/jfox/
>
>
>
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>---
>This email has been checked for viruses by Avast antivirus software.
>http://www.avast.com
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri May 22 23:07:13 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 22 May 2015 14:07:13 -0700
Subject: [R] Heatmap
In-Reply-To: <CABeLv6if8XB7AV-Y8LHV_gA8SUgDhjn3EG7x_A-ph5EyoGCQ5g@mail.gmail.com>
References: <CAJgdCD7eTRMAJA5oJZPNeNU-fU1tnYwd4ujfy2fboQ+-iUYEUg@mail.gmail.com>
	<553F180F020000CB0012ADCA@smtp.medicine.umaryland.edu>
	<CABeLv6g=88qDfYaKNZzG4=NxKaD+NBc9Fg0uaVvSyq445SpHKg@mail.gmail.com>
	<CABeLv6if8XB7AV-Y8LHV_gA8SUgDhjn3EG7x_A-ph5EyoGCQ5g@mail.gmail.com>
Message-ID: <8460114B-1899-46B0-83C6-D176C65FFB95@comcast.net>


On May 22, 2015, at 10:32 AM, Carlos Javier Rincon Rodriguez wrote:

> Hi. Good morning.
> 
> I am trying to load a shapefile to do a heatmap of Colombia. I using all
> this package:
> 
> library(ctv)
> 
> library(spatial)
> 
> library(ggplot2)
> 
> library(sp)
> 
> library(rgdal)
> 
> library(rgeos)
> 
> library(maptools)
> 
> library(ggmap)
> 
> 
> and a using this two commands to load the file:
> 
> 
> depto<-readShapePoly("depto.shp")

Was going to suggest following up on the SIG-geo mailing list since the shape-shifters don't all hang out in these parts, but I see that you crossposted. (That's not considered good form on R mailing lists.)

> 
> depto <- readOGR(dsn = ".", "depto")
> 
> 
> but the result is:
> 
> 
>     depto<-readShapePoly("depto.shp")
> 
>     Error in getinfo.shape(filen) : Error opening SHP file
> 
> 
>     depto <- readOGR(dsn = ".", "depto")
> 
>     Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding,
> use_iconv = use_iconv,  : Cannot open file
> 
> 
> Also I am working in a MAC computer and when I open R, I have this warning
> message:
> 
> 
>    WARNING: You're using a non-UTF8 locale, therefore only ASCII
> characters will work.
> 
>    Please read R for Mac OS X FAQ (see Help) section 9 and adjust your
> system preferences accordingly.
> 
> 
> I looking the R for Mac document but there is not section 9.!!!

This FAQ:

http://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html

(I see 10 numbered major headings, although admittedly the 9th is the acknowledgements section. I'm wondering if it were the 7th section that was meant, since it has information about setting the locale.)

-- 
David.
> 
> 
> Thanks for any help.
> 
> 
> 
> Carlos.
> 
> 
> 
> 2015-05-05 18:01 GMT-05:00 Carlos Javier Rincon Rodriguez <
> cjrinconr at unal.edu.co>:
> 
>> Hi.
>> 
>> This is my problem. I try to load a shapefile to do a heatmap of Colombia.
>> I using all this package:
>> 
>> library(ctv)
>> 
>> library(spatial)
>> 
>> library(ggplot2)
>> 
>> library(sp)
>> 
>> library(rgdal)
>> 
>> library(rgeos)
>> 
>> library(maptools)
>> 
>> library(ggmap)
>> 
>> 
>> and a using this two commands to load the file:
>> 
>> 
>> depto<-readShapePoly("depto.shp")
>> 
>> depto <- readOGR(dsn = ".", "depto")
>> 
>> 
>> but the result is:
>> 
>> 
>> depto<-readShapePoly("depto.shp")
>> 
>> Error in getinfo.shape(filen) : Error opening SHP file
>> 
>> 
>> depto <- readOGR(dsn = ".", "depto")
>> 
>> Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding, use_iconv
>> = use_iconv,  :
>> 
>>  Cannot open file
>> 
>> I attach the shapefile that i using.
>> 
>> also i am working in mac computer i don know if that could be the reason.
>> 
>> if somebody knows thanks.
>> 
>> 
>> 
>> 2015-04-28 4:18 GMT-05:00 John Sorkin <jsorkin at grecc.umaryland.edu>:
>> 
>> Look at the heatmap function
>>> 
>>>> John David Sorkin M.D., Ph.D.
>>>> Professor of Medicine
>>>> Chief, Biostatistics and Informatics
>>>> University of Maryland School of Medicine Division of Gerontology and
>>> Geriatric Medicine
>>>> Baltimore VA Medical Center
>>>> 10 North Greene Street
>>>> GRECC (BT/18/GR)
>>>> Baltimore, MD 21201-1524
>>>> (Phone) 410-605-7119
>>>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>> 
>>> 
>>>> On Apr 28, 2015, at 3:41 AM, John Wasige <johnwasige at gmail.com> wrote:
>>>> 
>>>> Dear all,
>>>> 
>>>> I need to make a heapmap of SPI results for a monthly timeseies of 30
>>>> years. Does anybody know to do it?
>>>> 
>>>> Thanks for your help
>>>> 
>>>> John
>>>> 
>>>>   [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
> 


David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Sat May 23 01:03:57 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 23 May 2015 09:03:57 +1000
Subject: [R] ERROR Message
In-Reply-To: <!&!AAAAAAAAAAAYAAAAAAAAAHoPlyHqlMtJunuDgZb1NhbCgAAAEAAAAFrePFU5YnxArSLRPlWCMccBAAAAAA==@ipma.pt>
References: <!&!AAAAAAAAAAAYAAAAAAAAAHoPlyHqlMtJunuDgZb1NhbCgAAAEAAAAFrePFU5YnxArSLRPlWCMccBAAAAAA==@ipma.pt>
Message-ID: <CA+8X3fUE4vypogPM5391YHyWVHe6JcoOPui6_zy9wYc-u=E5VA@mail.gmail.com>

Hi Ivone,
This does look a bit like homework as someone else sent a help request
with a strikingly similar problem. However, I would first do something
like this:

is.array(datalist[[1]])

as this is what the error message is saying.

Jim


On Sat, May 23, 2015 at 2:57 AM, Ivone Figueiredo <ifigueiredo at ipma.pt> wrote:
> Hi
>
> Could you please help me
>
> I am trying to fit a Multilevel Poisson regression with the following code
>
> ## BUGS CODE
>
> ## Multilevel Poisson regression
>
> model {
>
>   for (i in 1:n){
>
>     y[i] ~ dpois (lambda[i])
>
>     log(lambda[i]) <- mu +
>
>       b.species[Species[i]] + b.quarter[Quarter[i]] + epsilon[i]
>
>     epsilon[i] ~ dnorm (0, tau.epsilon)
>
>   }
>
>   mu ~ dnorm (0, .0001)
>
>   mu.adj <- mu +  mean(b.species[]) + mean(b.quarter[])
>
>   tau.epsilon <- pow(sigma.epsilon, -2)
>
>   sigma.epsilon ~ dunif (0, 100)
>
>
>
>   for (j in 1:n.species){
>
>     b.species[j] ~ dnorm (0, tau.species)
>
>     b.species.adj[j] <-  b.species[j] - mean( b.species[])
>
>   }
>
>   tau.species <- pow(sigma.species, -2)
>
>   sigma.species ~ dunif (0, 100)
>
>
>
>   for (j in 1:n.quarters){
>
>     b.quarter[j] ~ dnorm (0, tau.quarter)
>
>     b.quarter.adj[j] <- b.quarter[j] - mean(b.quarter[])
>
>   }
>
>   tau.quarter <- pow(sigma.quarter, -2)
>
>   sigma.quarter ~ dunif (0, 100)
>
> }
>
>
>
> ##
>
>
>
> skate.data <- list ("Species", "n.species", "Quarter", "n.quarters", "y")
>
>
>
> #radon.inits <- function (){
>
> #  list (a=rnorm(J), b=rnorm(1), g.0=rnorm(1), g.1=rnorm(1),
>
> #        sigma.y=runif(1), sigma.a=runif(1))
>
> #}
>
>
>
> skate.parameters <- c ("mu", "b.quarter", "b.species", "sigma.species",
> "sigma.quarter", "sigma.epsilon")
>
>
>
> skate.3 <- bugs (skate.data, inits=NULL, skate.parameters, "skates.bug",
>
>                  n.chains=3, n.iter=500,
>
>             bugs.directory="c:/ProgramFiles(x86)/OpenBUGS/OpenBUGS323",
>
>             program=c("OpenBUGS"))
>
>
>
>
>
> But I always receive this message error
>
>
>
> Loading required package: BRugs
>
> Welcome to BRugs connected to OpenBUGS version 3.2.3
>
> model is syntactically correct
>
> Error in aperm.default(datalist[[i]]) :
>
>   invalid first argument, must be an array
>
> In addition: Warning messages:
>
> 1: package 'BRugs' was built under R version 3.0.3
>
> 2: In FUN(X[[5L]], ...) : class of 'x' was discarded
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mxalimohamma at ualr.edu  Fri May 22 19:37:50 2015
From: mxalimohamma at ualr.edu (Mohammad Alimohammadi)
Date: Fri, 22 May 2015 12:37:50 -0500
Subject: [R] Problem with comparing multiple data sets
Message-ID: <CAJVfk9nM_a2Gr86OXimHbc8HZoN45RMWLL_VmXak4RPoj1=OQw@mail.gmail.com>

Hi everyone,

I am very new to R and I have a task to do. I appreciate any help. I have 3
data sets. Each data set has 4 columns. For example:

Class  Comment   Term   Text
0           com1        aac    text1
2           com2        aax    text2
1           com3        vvx    text3

Now I need t compare the class section between 3 data sets and assign the
most available class to that text. For example if text1 is assigned to
class 0 in data set 1&2 but assigned as 2 in data set 3 then it should be
assigned to class 0. If they are all the same so the class will be the
same. The ideal thing would be to keep the same format and just update the
class. Is there any easy way to do this?

Thanks a lot.

	[[alternative HTML version deleted]]


From varun1220 at gmail.com  Sat May 23 01:01:12 2015
From: varun1220 at gmail.com (varun joshi)
Date: Fri, 22 May 2015 19:01:12 -0400
Subject: [R] R programming
Message-ID: <CAF1MNLH8dU6mf0GSp=R6ZbGXU1ibrS2WDFWjY+Ctrrbx9XmvuQ@mail.gmail.com>

Hello there,

I wanted to learn R programming over this summer hence I registered for the
R programming course on Coursera. I understood most part of the lecture but
I'm having a hard time with the assignments.

Till now I can write small functions such as calculating mean of a vector
or an array. I can also use arguments such as lapply, sapply, rbind etc.

I am not very handy with coding in R. I get completely stuck.

What should I do to learn gradually?

Can anyone tell me what to do step by step. I'm an average student pursuing
my masters in Engineering Management at UNC Charlotte.

	[[alternative HTML version deleted]]


From claire.oquin at uky.edu  Sat May 23 01:07:06 2015
From: claire.oquin at uky.edu (Claire O'Quin)
Date: Fri, 22 May 2015 19:07:06 -0400
Subject: [R] Stepwise rQTL-unknown warning message and odd QTL curve
Message-ID: <CAAVUFsnR4=hhx5wGcgqLbKwV88FGGD6mP92Vk-FvCTr=KjfAAw@mail.gmail.com>

Hi There,

I am running a stepwise QTL for a backcross and got the following warning
message:

Warning message:
In lastout[[i]] - (max(lastout[[i]]) - dropresult[rn == qn[i], 3]) :
  longer object length is not a multiple of shorter object length

I can not discern what this means. When I created my plot, the QTL curve on
chromosome 3 is very odd (tried attaching it), so I suspect that the
warning is connected to that odd curve plot.

I tried running the fitqtl just to see what would happen and got an error
(Error in solve.default(t(Z) %*% Z, t(Z) %*% X) : system is computationally
singular: reciprocal condition number = 1.49755e-24).

Any thoughts about what is going on?

Thank you,
Claire



-----------------------------------
Claire O'Quin, PhD
Postdoctoral Research Scholar
University of Kentucky
http://www.linnenlab.com/home.html
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Phenotype2_Oddplot.pdf
Type: application/pdf
Size: 115737 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150522/3e929603/attachment.pdf>

From drjimlemon at gmail.com  Sat May 23 01:45:30 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 23 May 2015 09:45:30 +1000
Subject: [R] Heatmap
In-Reply-To: <8460114B-1899-46B0-83C6-D176C65FFB95@comcast.net>
References: <CAJgdCD7eTRMAJA5oJZPNeNU-fU1tnYwd4ujfy2fboQ+-iUYEUg@mail.gmail.com>
	<553F180F020000CB0012ADCA@smtp.medicine.umaryland.edu>
	<CABeLv6g=88qDfYaKNZzG4=NxKaD+NBc9Fg0uaVvSyq445SpHKg@mail.gmail.com>
	<CABeLv6if8XB7AV-Y8LHV_gA8SUgDhjn3EG7x_A-ph5EyoGCQ5g@mail.gmail.com>
	<8460114B-1899-46B0-83C6-D176C65FFB95@comcast.net>
Message-ID: <CA+8X3fVGgPNjnwg1rGockoq6o1byUop=oqE4MCUdXqgDUB=MKw@mail.gmail.com>

Hi Carlos,
The error from:

readShapePoly("depto.shp")

may well be that the function cannot find the file. Assuming that
there is a file "depto.shp", is it in the working directory of R when
you issue this command? Find out by:

getwd()

I suppose that macintosh computers try to hide the actual location of
files, so you may have to hunt around to find where the file resides
and whether you will have to add a path to your call. The second error
probably stems from the first, as if the file hasn't been read, the
information in it cannot be extracted.

Jim


On Sat, May 23, 2015 at 7:07 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On May 22, 2015, at 10:32 AM, Carlos Javier Rincon Rodriguez wrote:
>
>> Hi. Good morning.
>>
>> I am trying to load a shapefile to do a heatmap of Colombia. I using all
>> this package:
>>
>> library(ctv)
>>
>> library(spatial)
>>
>> library(ggplot2)
>>
>> library(sp)
>>
>> library(rgdal)
>>
>> library(rgeos)
>>
>> library(maptools)
>>
>> library(ggmap)
>>
>>
>> and a using this two commands to load the file:
>>
>>
>> depto<-readShapePoly("depto.shp")
>
> Was going to suggest following up on the SIG-geo mailing list since the shape-shifters don't all hang out in these parts, but I see that you crossposted. (That's not considered good form on R mailing lists.)
>
>>
>> depto <- readOGR(dsn = ".", "depto")
>>
>>
>> but the result is:
>>
>>
>>     depto<-readShapePoly("depto.shp")
>>
>>     Error in getinfo.shape(filen) : Error opening SHP file
>>
>>
>>     depto <- readOGR(dsn = ".", "depto")
>>
>>     Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding,
>> use_iconv = use_iconv,  : Cannot open file
>>
>>
>> Also I am working in a MAC computer and when I open R, I have this warning
>> message:
>>
>>
>>    WARNING: You're using a non-UTF8 locale, therefore only ASCII
>> characters will work.
>>
>>    Please read R for Mac OS X FAQ (see Help) section 9 and adjust your
>> system preferences accordingly.
>>
>>
>> I looking the R for Mac document but there is not section 9.!!!
>
> This FAQ:
>
> http://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html
>
> (I see 10 numbered major headings, although admittedly the 9th is the acknowledgements section. I'm wondering if it were the 7th section that was meant, since it has information about setting the locale.)
>
> --
> David.
>>
>>
>> Thanks for any help.
>>
>>
>>
>> Carlos.
>>
>>
>>
>> 2015-05-05 18:01 GMT-05:00 Carlos Javier Rincon Rodriguez <
>> cjrinconr at unal.edu.co>:
>>
>>> Hi.
>>>
>>> This is my problem. I try to load a shapefile to do a heatmap of Colombia.
>>> I using all this package:
>>>
>>> library(ctv)
>>>
>>> library(spatial)
>>>
>>> library(ggplot2)
>>>
>>> library(sp)
>>>
>>> library(rgdal)
>>>
>>> library(rgeos)
>>>
>>> library(maptools)
>>>
>>> library(ggmap)
>>>
>>>
>>> and a using this two commands to load the file:
>>>
>>>
>>> depto<-readShapePoly("depto.shp")
>>>
>>> depto <- readOGR(dsn = ".", "depto")
>>>
>>>
>>> but the result is:
>>>
>>>
>>> depto<-readShapePoly("depto.shp")
>>>
>>> Error in getinfo.shape(filen) : Error opening SHP file
>>>
>>>
>>> depto <- readOGR(dsn = ".", "depto")
>>>
>>> Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding, use_iconv
>>> = use_iconv,  :
>>>
>>>  Cannot open file
>>>
>>> I attach the shapefile that i using.
>>>
>>> also i am working in mac computer i don know if that could be the reason.
>>>
>>> if somebody knows thanks.
>>>
>>>
>>>
>>> 2015-04-28 4:18 GMT-05:00 John Sorkin <jsorkin at grecc.umaryland.edu>:
>>>
>>> Look at the heatmap function
>>>>
>>>>> John David Sorkin M.D., Ph.D.
>>>>> Professor of Medicine
>>>>> Chief, Biostatistics and Informatics
>>>>> University of Maryland School of Medicine Division of Gerontology and
>>>> Geriatric Medicine
>>>>> Baltimore VA Medical Center
>>>>> 10 North Greene Street
>>>>> GRECC (BT/18/GR)
>>>>> Baltimore, MD 21201-1524
>>>>> (Phone) 410-605-7119
>>>>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>>
>>>>
>>>>> On Apr 28, 2015, at 3:41 AM, John Wasige <johnwasige at gmail.com> wrote:
>>>>>
>>>>> Dear all,
>>>>>
>>>>> I need to make a heapmap of SPI results for a monthly timeseies of 30
>>>>> years. Does anybody know to do it?
>>>>>
>>>>> Thanks for your help
>>>>>
>>>>> John
>>>>>
>>>>>   [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>
>
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From glennmschultz at me.com  Sat May 23 03:03:21 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Sat, 23 May 2015 01:03:21 +0000 (GMT)
Subject: [R] Roxygen Documentation
Message-ID: <9740bf98-2ca8-41fc-9099-34b805794ab0@me.com>

Hello R help,
I am in the process of creating the companion to my book which illustrates how to call Bond Lab (my R package for MBS and fixed income). ?

I started with the idea of scripts and then functions calling functions. ?Neither seemed very good to me. ?I checked a couple of packages (Max Kuhn, etc.). ?The companions were mostly scripts that the user can copy paste. ?So, I thought I would try that with Roxygen2. ? I have tried a few iterations. ?The code I have tried is variation of below and?does?not?work.? Does anyone know if I can use Roxygen2 in this way or do I need to seek an alternative.

Thanks,
Glenn

#' Chapter 1 Present Value Function Example
#'?
#' The script example calls the presesnt value function
#' from the package BondLab
#' @examples
#' \dontrun{
require(BondLab)
PV = TimeValue(interest.rate = .05,
? ? ? ? ? ? ? ?number.periods = 3,
? ? ? ? ? ? ? ?frequency = 1,
? ? ? ? ? ? ? ?type = "PV")}

From jdnewmil at dcn.davis.CA.us  Sat May 23 07:09:27 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 22 May 2015 22:09:27 -0700
Subject: [R] Roxygen Documentation
In-Reply-To: <9740bf98-2ca8-41fc-9099-34b805794ab0@me.com>
References: <9740bf98-2ca8-41fc-9099-34b805794ab0@me.com>
Message-ID: <216E58A4-CF3F-47FE-8257-D4A671FCBE2B@dcn.davis.CA.us>

I think you are looking for a way to make a vignette. Consider using the Sweave variant of knitr.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 22, 2015 6:03:21 PM PDT, Glenn Schultz <glennmschultz at me.com> wrote:
>Hello R help,
>I am in the process of creating the companion to my book which
>illustrates how to call Bond Lab (my R package for MBS and fixed
>income). ?
>
>I started with the idea of scripts and then functions calling
>functions. ?Neither seemed very good to me. ?I checked a couple of
>packages (Max Kuhn, etc.). ?The companions were mostly scripts that the
>user can copy paste. ?So, I thought I would try that with Roxygen2. ? I
>have tried a few iterations. ?The code I have tried is variation of
>below and?does?not?work.? Does anyone know if I can use Roxygen2 in
>this way or do I need to seek an alternative.
>
>Thanks,
>Glenn
>
>#' Chapter 1 Present Value Function Example
>#'?
>#' The script example calls the presesnt value function
>#' from the package BondLab
>#' @examples
>#' \dontrun{
>require(BondLab)
>PV = TimeValue(interest.rate = .05,
>? ? ? ? ? ? ? ?number.periods = 3,
>? ? ? ? ? ? ? ?frequency = 1,
>? ? ? ? ? ? ? ?type = "PV")}
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From shivibhatia at ymail.com  Sat May 23 06:53:55 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Fri, 22 May 2015 21:53:55 -0700 (PDT)
Subject: [R] R programming
In-Reply-To: <CAF1MNLH8dU6mf0GSp=R6ZbGXU1ibrS2WDFWjY+Ctrrbx9XmvuQ@mail.gmail.com>
References: <CAF1MNLH8dU6mf0GSp=R6ZbGXU1ibrS2WDFWjY+Ctrrbx9XmvuQ@mail.gmail.com>
Message-ID: <1432356835790-4707548.post@n4.nabble.com>

Hi Varun,

Courses offered from Coursera & EDX are very informative and carry details
in depth. 
However I agree with your point that these courses are very fast paced &
sometimes very technical in nature. (I found the same when I went for Linear
regression course)
I have also recently started learning R and enrolled for free courses at
DataCamp.

DataCamp is fabulous and it really helped me to build a very sound base in
R. There are various courses available ranging from Statistical analysis to
regression, Data analysis, graphical presentation and what not. 
Hence I would highly recommend enrolling for DataCamp without any hiccup.
Once you find you are pretty comfortable with the basics of R you might want
to get enrolled for the paid courses as well as I have done and these course
will only add value to your profile and as an individual.

Happy Learning.
Cheers!!!!
Shivi 



--
View this message in context: http://r.789695.n4.nabble.com/R-programming-tp4707545p4707548.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Sat May 23 07:34:11 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 22 May 2015 22:34:11 -0700
Subject: [R] R programming
In-Reply-To: <CAF1MNLH8dU6mf0GSp=R6ZbGXU1ibrS2WDFWjY+Ctrrbx9XmvuQ@mail.gmail.com>
References: <CAF1MNLH8dU6mf0GSp=R6ZbGXU1ibrS2WDFWjY+Ctrrbx9XmvuQ@mail.gmail.com>
Message-ID: <0C529428-0274-41B4-81CF-45AC9027639F@dcn.davis.CA.us>

Practice (use the str function frequently, print small pieces of complex expressions to understand how they are constructed).

Read the Introduction to R document. Especially the part about indexing.

Read Pat Burns' The R Inferno.

Also remember to post in plain text on this list next time 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 22, 2015 4:01:12 PM PDT, varun joshi <varun1220 at gmail.com> wrote:
>Hello there,
>
>I wanted to learn R programming over this summer hence I registered for
>the
>R programming course on Coursera. I understood most part of the lecture
>but
>I'm having a hard time with the assignments.
>
>Till now I can write small functions such as calculating mean of a
>vector
>or an array. I can also use arguments such as lapply, sapply, rbind
>etc.
>
>I am not very handy with coding in R. I get completely stuck.
>
>What should I do to learn gradually?
>
>Can anyone tell me what to do step by step. I'm an average student
>pursuing
>my masters in Engineering Management at UNC Charlotte.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sat May 23 08:28:26 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 23 May 2015 16:28:26 +1000
Subject: [R] R programming
In-Reply-To: <CAF1MNLH8dU6mf0GSp=R6ZbGXU1ibrS2WDFWjY+Ctrrbx9XmvuQ@mail.gmail.com>
References: <CAF1MNLH8dU6mf0GSp=R6ZbGXU1ibrS2WDFWjY+Ctrrbx9XmvuQ@mail.gmail.com>
Message-ID: <CA+8X3fWFywA_BNKGb_hEDM_t_AA56UhpO88wVmgN83GWUQz7Og@mail.gmail.com>

Hi varun,
A few suggestions.
Learn to use the built in help system, whichever version (text, HTML,
PDF) you prefer.
Learn to use one of the search programs (see
http://cran.r-project.org/search.html)
Try to do every task that you can in R.

Jim


On Sat, May 23, 2015 at 9:01 AM, varun joshi <varun1220 at gmail.com> wrote:
> Hello there,
>
> I wanted to learn R programming over this summer hence I registered for the
> R programming course on Coursera. I understood most part of the lecture but
> I'm having a hard time with the assignments.
>
> Till now I can write small functions such as calculating mean of a vector
> or an array. I can also use arguments such as lapply, sapply, rbind etc.
>
> I am not very handy with coding in R. I get completely stuck.
>
> What should I do to learn gradually?
>
> Can anyone tell me what to do step by step. I'm an average student pursuing
> my masters in Engineering Management at UNC Charlotte.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Sat May 23 09:36:15 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 23 May 2015 09:36:15 +0200
Subject: [R] Stepwise rQTL-unknown warning message and odd QTL curve
In-Reply-To: <CAAVUFsnR4=hhx5wGcgqLbKwV88FGGD6mP92Vk-FvCTr=KjfAAw@mail.gmail.com>
References: <CAAVUFsnR4=hhx5wGcgqLbKwV88FGGD6mP92Vk-FvCTr=KjfAAw@mail.gmail.com>
Message-ID: <55602DEF.1020002@statistik.tu-dortmund.de>



On 23.05.2015 01:07, Claire O'Quin wrote:
> Hi There,
>
> I am running a stepwise QTL for a backcross and got the following warning
> message:
>
> Warning message:
> In lastout[[i]] - (max(lastout[[i]]) - dropresult[rn == qn[i], 3]) :
>    longer object length is not a multiple of shorter object length

So dimensions of the arguments may not match?
>
> I can not discern what this means. When I created my plot, the QTL curve on
> chromosome 3 is very odd (tried attaching it), so I suspect that the
> warning is connected to that odd curve plot.
>
> I tried running the fitqtl just to see what would happen and got an error
> (Error in solve.default(t(Z) %*% Z, t(Z) %*% X) : system is computationally
> singular: reciprocal condition number = 1.49755e-24).
>
> Any thoughts about what is going on?

No, without knoing what the arguments and the actual code was.

Best,
Uwe Ligges

>
> Thank you,
> Claire
>
>
>
> -----------------------------------
> Claire O'Quin, PhD
> Postdoctoral Research Scholar
> University of Kentucky
> http://www.linnenlab.com/home.html
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ragia11 at hotmail.com  Sat May 23 11:10:51 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Sat, 23 May 2015 12:10:51 +0300
Subject: [R] order matrix regarding its content.
Message-ID: <DUB125-W6672412794352F79871638B3CF0@phx.gbl>

Dear group,
I have the following matrix

  1 2 3 4 5 6 7 8 9 10
1  0 1 1 1 1 1 1 1 1  1
2  0 0 0 1 1 0 0 0 0  0
3  0 0 0 1 1 1 1 1 1  1
4  0 0 0 0 1 0 0 0 0  0
5  0 0 0 0 0 0 0 0 0  0
6  0 0 0 0 0 0 1 1 1  1
7  0 0 0 0 0 0 0 1 1  0
8  0 0 0 0 0 0 0 0 1  0
9  1 1 1 1 1 1 1 1 1  1
10 0 0 0 0 0 0 0 0 0  0

how to order it according to ones and zeros to be ordered as if it all ones orpartially finally all zeros, like  the following or similar


9  1 1 1 1 1 1 1 1 1  1
1  0 1 1 1 1 1 1 1 1  1
3  0 0 0 1 1 1 1 1 1  1
6  0 0 0 0 0 0 1 1 1  1
2  0 0 0 1 1 0 0 0 0  0
7  0 0 0 0 0 0 0 1 1  0
4  0 0 0 0 1 0 0 0 0  0
8  0 0 0 0 0 0 0 0 1  0
5  0 0 0 0 0 0 0 0 0  0
10 0 0 0 0 0 0 0 0 0  0


thanks in advance
Ragia





 		 	   		  
	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sat May 23 11:54:22 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 23 May 2015 10:54:22 +0100
Subject: [R] order matrix regarding its content.
In-Reply-To: <DUB125-W6672412794352F79871638B3CF0@phx.gbl>
References: <DUB125-W6672412794352F79871638B3CF0@phx.gbl>
Message-ID: <55604E4E.2010807@sapo.pt>

Hello,

Maybe something like the following. (Assuming your matrix is named 'mat')


mat[order(rowSums(mat)), ]


Hope this helps,

Rui Barradas


Em 23-05-2015 10:10, Ragia Ibrahim escreveu:
> Dear group,
> I have the following matrix
>
>    1 2 3 4 5 6 7 8 9 10
> 1  0 1 1 1 1 1 1 1 1  1
> 2  0 0 0 1 1 0 0 0 0  0
> 3  0 0 0 1 1 1 1 1 1  1
> 4  0 0 0 0 1 0 0 0 0  0
> 5  0 0 0 0 0 0 0 0 0  0
> 6  0 0 0 0 0 0 1 1 1  1
> 7  0 0 0 0 0 0 0 1 1  0
> 8  0 0 0 0 0 0 0 0 1  0
> 9  1 1 1 1 1 1 1 1 1  1
> 10 0 0 0 0 0 0 0 0 0  0
>
> how to order it according to ones and zeros to be ordered as if it all ones orpartially finally all zeros, like  the following or similar
>
>
> 9  1 1 1 1 1 1 1 1 1  1
> 1  0 1 1 1 1 1 1 1 1  1
> 3  0 0 0 1 1 1 1 1 1  1
> 6  0 0 0 0 0 0 1 1 1  1
> 2  0 0 0 1 1 0 0 0 0  0
> 7  0 0 0 0 0 0 0 1 1  0
> 4  0 0 0 0 1 0 0 0 0  0
> 8  0 0 0 0 0 0 0 0 1  0
> 5  0 0 0 0 0 0 0 0 0  0
> 10 0 0 0 0 0 0 0 0 0  0
>
>
> thanks in advance
> Ragia
>
>
>
>
>
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sat May 23 11:55:07 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 23 May 2015 11:55:07 +0200
Subject: [R] order matrix regarding its content.
In-Reply-To: <DUB125-W6672412794352F79871638B3CF0@phx.gbl>
References: <DUB125-W6672412794352F79871638B3CF0@phx.gbl>
Message-ID: <55604E7B.5020508@statistik.tu-dortmund.de>



On 23.05.2015 11:10, Ragia Ibrahim wrote:
> Dear group,
> I have the following matrix
>
>    1 2 3 4 5 6 7 8 9 10
> 1  0 1 1 1 1 1 1 1 1  1
> 2  0 0 0 1 1 0 0 0 0  0
> 3  0 0 0 1 1 1 1 1 1  1
> 4  0 0 0 0 1 0 0 0 0  0
> 5  0 0 0 0 0 0 0 0 0  0
> 6  0 0 0 0 0 0 1 1 1  1
> 7  0 0 0 0 0 0 0 1 1  0
> 8  0 0 0 0 0 0 0 0 1  0
> 9  1 1 1 1 1 1 1 1 1  1
> 10 0 0 0 0 0 0 0 0 0  0
>
> how to order it according to ones and zeros to be ordered as if it all ones orpartially finally all zeros, like  the following or similar


  X[order(-rowSums(X)),]

Best,
Uwe Ligges



>
> 9  1 1 1 1 1 1 1 1 1  1
> 1  0 1 1 1 1 1 1 1 1  1
> 3  0 0 0 1 1 1 1 1 1  1
> 6  0 0 0 0 0 0 1 1 1  1
> 2  0 0 0 1 1 0 0 0 0  0
> 7  0 0 0 0 0 0 0 1 1  0
> 4  0 0 0 0 1 0 0 0 0  0
> 8  0 0 0 0 0 0 0 0 1  0
> 5  0 0 0 0 0 0 0 0 0  0
> 10 0 0 0 0 0 0 0 0 0  0
>
>
> thanks in advance
> Ragia
>
>
>
>
>
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From peter_van_summeren at hotmail.com  Sat May 23 08:40:52 2015
From: peter_van_summeren at hotmail.com (Peter van Summeren)
Date: Sat, 23 May 2015 08:40:52 +0200
Subject: [R] =?windows-1256?q?Debian_Rcmdr_misses_sem_leaps_etc=FE?=
Message-ID: <DUB122-W14F13B82D2AD9A8099F544DACF0@phx.gbl>

Thanks to all who answered me,
After reading all the mails I got, I did the following:- I logged in as root in Debian Jessie- I started Rcmdr.   it told me that some files are missing,   it offered me to get them,    I did not fill in anything, just said ok,   I had to choose a website from where to download, ok,   it  downloaded and it  worked quite  a lot,   in the end it said: the downloaded packages are in /temp/Rtmp25kiWx/downloaded_packages,-  Rcmdr came up neatly,-  I changed to normal user mode, Rcmdr came up neatly.
The reason I choose to log in as root, was that I was unsure what would happen in the process.As root I can maintain "rights".All my R-packages I downloaded as normal user with a package commander. When some Debian developer reads the above: why was the usual package commander not enough?But I am glad I could reach this mailing list. 
with friendly greetings,Peter 		 	   		  
	[[alternative HTML version deleted]]


From ragia11 at hotmail.com  Sat May 23 14:34:54 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Sat, 23 May 2015 15:34:54 +0300
Subject: [R] order matrix regarding its content.
In-Reply-To: <55604E7B.5020508@statistik.tu-dortmund.de>
References: <DUB125-W6672412794352F79871638B3CF0@phx.gbl>,
	<55604E7B.5020508@statistik.tu-dortmund.de>
Message-ID: <DUB125-W24A2C52A6EF870AEE886E0B3CF0@phx.gbl>

Many thanks

> Date: Sat, 23 May 2015 11:55:07 +0200
> From: ligges at statistik.tu-dortmund.de
> To: ragia11 at hotmail.com; r-help at r-project.org
> Subject: Re: [R] order matrix regarding its content.
> 
> 
> 
> On 23.05.2015 11:10, Ragia Ibrahim wrote:
> > Dear group,
> > I have the following matrix
> >
> >    1 2 3 4 5 6 7 8 9 10
> > 1  0 1 1 1 1 1 1 1 1  1
> > 2  0 0 0 1 1 0 0 0 0  0
> > 3  0 0 0 1 1 1 1 1 1  1
> > 4  0 0 0 0 1 0 0 0 0  0
> > 5  0 0 0 0 0 0 0 0 0  0
> > 6  0 0 0 0 0 0 1 1 1  1
> > 7  0 0 0 0 0 0 0 1 1  0
> > 8  0 0 0 0 0 0 0 0 1  0
> > 9  1 1 1 1 1 1 1 1 1  1
> > 10 0 0 0 0 0 0 0 0 0  0
> >
> > how to order it according to ones and zeros to be ordered as if it all ones orpartially finally all zeros, like  the following or similar
> 
> 
>   X[order(-rowSums(X)),]
> 
> Best,
> Uwe Ligges
> 
> 
> 
> >
> > 9  1 1 1 1 1 1 1 1 1  1
> > 1  0 1 1 1 1 1 1 1 1  1
> > 3  0 0 0 1 1 1 1 1 1  1
> > 6  0 0 0 0 0 0 1 1 1  1
> > 2  0 0 0 1 1 0 0 0 0  0
> > 7  0 0 0 0 0 0 0 1 1  0
> > 4  0 0 0 0 1 0 0 0 0  0
> > 8  0 0 0 0 0 0 0 0 1  0
> > 5  0 0 0 0 0 0 0 0 0  0
> > 10 0 0 0 0 0 0 0 0 0  0
> >
> >
> > thanks in advance
> > Ragia
> >
> >
> >
> >
> >
> >   		 	   		
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
 		 	   		  
	[[alternative HTML version deleted]]


From rshepard at appl-ecosys.com  Sat May 23 14:51:25 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Sat, 23 May 2015 05:51:25 -0700 (PDT)
Subject: [R] R programming
In-Reply-To: <CAF1MNLH8dU6mf0GSp=R6ZbGXU1ibrS2WDFWjY+Ctrrbx9XmvuQ@mail.gmail.com>
References: <CAF1MNLH8dU6mf0GSp=R6ZbGXU1ibrS2WDFWjY+Ctrrbx9XmvuQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.11.1505230546390.10656@localhost>

On Fri, 22 May 2015, varun joshi wrote:

> What should I do to learn gradually?

   Not sure how one gradually learns; I suppose it depends on what sort of
applications one wants to develop and the most effective means by which one
learns. Regardless, a good place to start is by buying and reading Norman
Matloff's "The Art of R Programming" and following that with Haley Wickham's
"Advanced R".

HTH,

Rich


From jrkrideau at inbox.com  Sat May 23 15:23:59 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 23 May 2015 05:23:59 -0800
Subject: [R] Problem with comparing multiple data sets
In-Reply-To: <CAJVfk9nM_a2Gr86OXimHbc8HZoN45RMWLL_VmXak4RPoj1=OQw@mail.gmail.com>
Message-ID: <32FCEB5D574.0000035Fjrkrideau@inbox.com>

Hi Mohammad 

Welcome to the R-help list.

There probably is a fairly easy way to what you want but I think we probably need a bit more background information on what you are trying to achieve.  I know I'm not exactly clear on your decision rule(s). 

It would also be very useful to see some actual sample data in useable R format.Have a look at these links http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html for some hints on what you might want to include in your question.

In particular, read up about dput()  in those links and/or see ?dput.  This is the generally preferred way to supply sample or illustrative data to the R-help list.  It basically creates a perfect copy of the data as it exists on 'your' machine so that R-help readers see exactly what you do.  







John Kane
Kingston ON Canada


> -----Original Message-----
> From: mxalimohamma at ualr.edu
> Sent: Fri, 22 May 2015 12:37:50 -0500
> To: r-help at r-project.org
> Subject: [R] Problem with comparing multiple data sets
> 
> Hi everyone,
> 
> I am very new to R and I have a task to do. I appreciate any help. I have
> 3
> data sets. Each data set has 4 columns. For example:
> 
> Class  Comment   Term   Text
> 0           com1        aac    text1
> 2           com2        aax    text2
> 1           com3        vvx    text3
> 
> Now I need t compare the class section between 3 data sets and assign the
> most available class to that text. For example if text1 is assigned to
> class 0 in data set 1&2 but assigned as 2 in data set 3 then it should be
> assigned to class 0. If they are all the same so the class will be the
> same. The ideal thing would be to keep the same format and just update
> the
> class. Is there any easy way to do this?
> 
> Thanks a lot.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From jfox at mcmaster.ca  Sat May 23 16:02:00 2015
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 23 May 2015 10:02:00 -0400
Subject: [R] Debian Rcmdr misses sem leaps etc?
In-Reply-To: <DUB122-W14F13B82D2AD9A8099F544DACF0@phx.gbl>
References: <DUB122-W14F13B82D2AD9A8099F544DACF0@phx.gbl>
Message-ID: <web-560822677@cgpsrv2.cis.mcmaster.ca>

Dear Peter,

On Sat, 23 May 2015 08:40:52 +0200
 Peter van Summeren <peter_van_summeren at hotmail.com> wrote:
> Thanks to all who answered me,
> After reading all the mails I got, I did the following:- I logged in as root in Debian Jessie- I started Rcmdr.   it told me that some files are missing,   it offered me to get them,    I did not fill in anything, just said ok,   I had to choose a website from where to download, ok,   it  downloaded and it  worked quite  a lot,   in the end it said: the downloaded packages are in /temp/Rtmp25kiWx/downloaded_packages,-  Rcmdr came up neatly,-  I changed to normal user mode, Rcmdr came up neatly.
> The reason I choose to log in as root, was that I was unsure what would happen in the process.

As I said, I'm not a Debian user, but I don't believe that it was necessary for you to log in as root to install R packages. It's also unclear to me whether you *tried* doing this as an ordinary user -- that is, simply clicking OK in the dialog box that offered to install missing R packages and then selecting a CRAN mirror from which those packages would be downloaded.


> As root I can maintain "rights".All my R-packages I downloaded as normal user with a package commander. When some Debian developer reads the above: why was the usual package commander not enough?

That would require that Dirk package for Debian *all* the R packages used by the Rcmdr and their dependencies, which would be a lot of work -- unnecessary work since R packages can be installed directly from CRAN without being repackaged for Debian.

Best,
 John 

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	
> But I am glad I could reach this mailing list. 
> with friendly greetings,Peter 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sat May 23 16:15:06 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 23 May 2015 06:15:06 -0800
Subject: [R] R programming
In-Reply-To: <CAF1MNLH8dU6mf0GSp=R6ZbGXU1ibrS2WDFWjY+Ctrrbx9XmvuQ@mail.gmail.com>
Message-ID: <336F2CA74C8.000003D4jrkrideau@inbox.com>

Read R-help. :) Seriously, you will see all kinds of problems and questions. Some of the simpler ones you can try yourself and see how your approach matches other peoples. 

Google around for some R blogs and see if you find any that are useful. https://learnr.wordpress.com/ might be useful. IIRC there is a mixture of real intro and very sophisticated material there.

Think of something simple exercise or analysis that you would normally do in Matlab or even in a spreadsheet and see how easily you can translate this to R. If needed think more of what you would expect students in first year to be doing if you are a TA and duplicate it in R. 

A great intro to R, in my opinion is Dan Navarro's book (available as a pdf at my last look) but I suspect from your point of view not so good as he is a psychologist and is writing for them. http://health.adelaide.edu.au/psychology/ccs/docs/lsr/lsr-0.3.pdf

With your educational background An Introduction to R may be a good read but, as a non-techie, my normal advise is not to read it right away. It is a fantastic reference and repays reading after a few weeks into R but it is IMHO emphatically NOT an introduction in the same way that the Navarro book is. (I am now changing my name and entering a witness protection program).

Learn as much as possible about the various basic data structures in R.  As someone said use str() a lot.  Here is an example why. Just copy and paste:
dat1  <- structure(list(aa = structure(1:10, .Label = c("1", "2", "3", 
"4", "5", "6", "7", "8", "9", "10"), class = "factor"), bb = c(10L, 
9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L, 1L)), .Names = c("aa", "bb"), row.names = c(NA, 
-10L), class = "data.frame")

dat2  <-  structure(list(aa = 1:10, bb = c(10L, 9L, 8L, 7L, 6L, 5L, 4L, 
3L, 2L, 1L)), .Names = c("aa", "bb"), row.names = c(NA, -10L), class = "data.frame")

dat1
dat2  # looks a lot like dat1 :)


with(dat1, aa*bb)
with(dat2 , aa*bb)

str(dat1)
str(dat2)


BTW dat1 and dat2 are in dput() format which is the preferred way to supply data to the R-help list.  It provides a perfect copy of the data as it sits on your machine and avoids little problems like we see in dat1 vs dat2 if other readers are loading data on their machines.

If the course has not already recommended this, get a good dedicatd R text editor or IDE.  Everyone has their own, but some popular ones seem to be Tinn-R, EMACS, RStudio, and there are many others.

John Kane
Kingston ON Canada

PS: Don't post in HTML. it mangles code.


> -----Original Message-----
> From: varun1220 at gmail.com
> Sent: Fri, 22 May 2015 19:01:12 -0400
> To: r-help at r-project.org
> Subject: [R] R programming
> 
> Hello there,
> 
> I wanted to learn R programming over this summer hence I registered for
> the
> R programming course on Coursera. I understood most part of the lecture
> but
> I'm having a hard time with the assignments.
> 
> Till now I can write small functions such as calculating mean of a vector
> or an array. I can also use arguments such as lapply, sapply, rbind etc.
> 
> I am not very handy with coding in R. I get completely stuck.
> 
> What should I do to learn gradually?
> 
> Can anyone tell me what to do step by step. I'm an average student
> pursuing
> my masters in Engineering Management at UNC Charlotte.
> 
> 	[[alternative HTML version deleted]]
>

____________________________________________________________
Publish your photos in seconds for FREE
TRY IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if4


From jrkrideau at inbox.com  Sat May 23 16:16:34 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 23 May 2015 06:16:34 -0800
Subject: [R] Stepwise rQTL-unknown warning message and odd QTL curve
In-Reply-To: <55602DEF.1020002@statistik.tu-dortmund.de>
References: <caavufsnr4=hhx5wgcgqlbkwv88fggd6mp92vk-fvctr=kjfaaw@mail.gmail.com>
Message-ID: <337271CCFDC.000003DAjrkrideau@inbox.com>


http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html

John Kane
Kingston ON Canada


> -----Original Message-----
> From: ligges at statistik.tu-dortmund.de
> Sent: Sat, 23 May 2015 09:36:15 +0200
> To: claire.oquin at uky.edu, r-help at r-project.org
> Subject: Re: [R] Stepwise rQTL-unknown warning message and odd QTL curve
> 
> 
> 
> On 23.05.2015 01:07, Claire O'Quin wrote:
>> Hi There,
>> 
>> I am running a stepwise QTL for a backcross and got the following
>> warning
>> message:
>> 
>> Warning message:
>> In lastout[[i]] - (max(lastout[[i]]) - dropresult[rn == qn[i], 3]) :
>>    longer object length is not a multiple of shorter object length
> 
> So dimensions of the arguments may not match?
>> 
>> I can not discern what this means. When I created my plot, the QTL curve
>> on
>> chromosome 3 is very odd (tried attaching it), so I suspect that the
>> warning is connected to that odd curve plot.
>> 
>> I tried running the fitqtl just to see what would happen and got an
>> error
>> (Error in solve.default(t(Z) %*% Z, t(Z) %*% X) : system is
>> computationally
>> singular: reciprocal condition number = 1.49755e-24).
>> 
>> Any thoughts about what is going on?
> 
> No, without knoing what the arguments and the actual code was.
> 
> Best,
> Uwe Ligges
> 
>> 
>> Thank you,
>> Claire
>> 
>> 
>> 
>> -----------------------------------
>> Claire O'Quin, PhD
>> Postdoctoral Research Scholar
>> University of Kentucky
>> http://www.linnenlab.com/home.html
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From kathryn.lord2000 at gmail.com  Sat May 23 16:55:59 2015
From: kathryn.lord2000 at gmail.com (Kathryn Lord)
Date: Sat, 23 May 2015 23:55:59 +0900
Subject: [R] elegant way to create a sequence with the 'rep' bulit-in
	function
Message-ID: <CAMFx86wtOghh+cimVCKOPpX977a2+tu7iyrthMncHXLgDy=41w@mail.gmail.com>

Dear R users,

I'd like to create a sequence/vector, for example,

1 1 2 2 3 3 1 1 2 2 3 3 1 1 2 2 3 3 1 1 2 2 3 3       4 4 4 4 5 5 5 5 4 4 4
4 5 5 5 5 4 4 4 4 5 5 5 5       6 6 6 7 7 7 8 8 8 9 9 9 6 6 6 7 7 7 8 8 8 9
9 9

So I did like this below.

a <- 4
b <- 3
c <- 2

grp <- c( rep(1:b, each=c, times=a), rep(1:c, each=a, times=b)+b, rep(1:a,
each=b, times=c)+b+c )

I wonder if there is a more elegant way to do this?

Any suggestions? Thank you!

Best wishes

Kathie

	[[alternative HTML version deleted]]


From michelle.galla at gmx.de  Sat May 23 12:59:26 2015
From: michelle.galla at gmx.de (MGalla)
Date: Sat, 23 May 2015 03:59:26 -0700 (PDT)
Subject: [R] Help with urnsamples and all possible combination
Message-ID: <1432378766194-4707560.post@n4.nabble.com>

Hello, 

i need some help to use urnsamples from the package "prob".

At the moment i use it in this way

A<-as.matrix(urnsamples(1:25, size = 7,ordered=FALSE,replace=TRUE))

So I get the numbers 1 to 25 and choose 7 of them, but it is possible to get
one number more than one time. 
But I want additionally that I get a number not more than three times. So
for example "1111222" is no 
combination, but "1112223" is allowed. 

I know that it should be possible to create A in my way and than delete all
"wrong" combinations, 
but i will work also with bigger size than 7, so the Matrix A will get to
large. 

So my question is, if there is a option to give urnsamples the limit to
choose every object not more than three times? Or is there another way to
get the combinations I want. 

Thanks, 
Michelle Galla



--
View this message in context: http://r.789695.n4.nabble.com/Help-with-urnsamples-and-all-possible-combination-tp4707560.html
Sent from the R help mailing list archive at Nabble.com.


From claire.oquin at uky.edu  Sat May 23 13:40:03 2015
From: claire.oquin at uky.edu (Claire O'Quin)
Date: Sat, 23 May 2015 07:40:03 -0400
Subject: [R] Stepwise rQTL-unknown warning message and odd QTL curve
In-Reply-To: <ba50202500704591bf6682f3fbcdaea4@EX10HB02.ad.uky.edu>
References: <CAAVUFsnR4=hhx5wGcgqLbKwV88FGGD6mP92Vk-FvCTr=KjfAAw@mail.gmail.com>
	<ba50202500704591bf6682f3fbcdaea4@EX10HB02.ad.uky.edu>
Message-ID: <CAAVUFsn5Lzino33XogJ82jpTS3HdWGn=1y18DE8NoqWAB8PTBQ@mail.gmail.com>

Sorry, I'll try to provide more detail about what I have done so far with
code and any relevant output results.

>library(qtl)
>sawfly.cross <- read.cross(format="csv",
file="~/Desktop/Sawfly_data/QTL/Sawfly_QTL.csv", na.strings="NA",
genotypes=c("A", "B"), alleles=c("A", "B"), estimate.map=F)
--Read the following data:
 430  individuals
 506  markers
 19  phenotypes
 --Cross type: bc

>print(sawfly.cross)
--This is an object of class "cross".
  It is too complex to print, so we provide just this summary.
    Backcross

    No. individuals:    430

    No. phenotypes:     19
    Percent phenotyped: 99.8 99.8 99.3 99.1 99.1 99.1 99.1 99.1 99.5 99.8
99.8 99.5 98.8 99.8 99.8 99.8 99.8 98.4 99.5

    No. chromosomes:    7
        Autosomes:      1 2 3 4 5 6 7

    Total markers:      506
    No. markers:        103 89 75 74 65 51 49
    Percent genotyped:  96.2
    Genotypes (%):      AA:49.7  AB:50.3
    Backcross

    No. individuals:    430

    No. phenotypes:     19
    Percent phenotyped: 99.8 99.8 99.3 99.1 99.1 99.1 99.1 99.1 99.5 99.8
99.8 99.5 98.8 99.8 99.8 99.8 99.8 98.4 99.5

    No. chromosomes:    7
        Autosomes:      1 2 3 4 5 6 7

    Total markers:      506
    No. markers:        103 89 75 74 65 51 49
    Percent genotyped:  96.2
    Genotypes (%):      AA:49.7  AB:50.3

>sawfly.cross <- calc.genoprob(sawfly.cross, step=2.5, error.prob=0.1,
map.function="kosambi", stepwidth="fixed")

**I am using head size as a covariant.**

>head.covar <- pull.pheno(sawfly.cross, pheno.col=19)
>sawfly.cross.stepwise.peryellow <- scantwo(sawfly.cross, pheno.col=2,
model="normal", method="hk", addcovar=head.covar, use="all.obs",
clean.output=F, verbose=T, n.perm=1000, batchsize=100);
save.image("~/Desktop/Sawfly_data/QTL/SawflyQTL.RData")
--Warning messages:
1: In checkcovar(cross, pheno.col, addcovar, intcovar, perm.strata,  :
  Dropping 1 individuals with missing phenotypes.

2: In checkcovar(cross, pheno.col, addcovar, intcovar, perm.strata,  :
  Dropping 1 individuals with missing covariates.

> sawfly.cross.stepwise.peryellow.pen <- calc.penalties(alpha=0.05,
perms=sawfly.cross.stepwise.peryellow)

>> sawfly.cross.stepwise.peryellow.stepqtl <- stepwiseqtl(sawfly.cross,
pheno.col=2, method="hk", max.qtl=10,
penalties=sawfly.cross.stepwise.peryellow.pen , verbose=T,
keeplodprofile=T, covar=head.covar, scan.pairs=F, keeptrace=T)
--Error in covar[!hasmissing, , drop = FALSE] : incorrect number of
dimensions

**I corrected this with the next piece of code

>sawfly.cross.stepwise.peryellow.stepqtl <- stepwiseqtl(sawfly.cross,
pheno.col=2, method="hk", max.qtl=10,
penalties=sawfly.cross.stepwise.peryellow.pen , verbose=T,
keeplodprofile=T, covar=as.data.frame(sawfly.cross$pheno$Head.Area),
scan.pairs=F, keeptrace=T)

The stepwise than ran and I got to the point where I got the warning
message I posted

about:Warning message:
In lastout[[i]] - (max(lastout[[i]]) - dropresult[rn == qn[i], 3]) :
  longer object length is not a multiple of shorter object length

I proceeded to examine the output

>sawfly.cross.stepwise.peryellow.stepqtl
  QTL object containing genotype probabilities.

      name chr    pos n.gen
Q1 1 at 106.1   1 106.11     2
Q2 2 at 180.0   2 179.97     2
Q3 3 at 181.9   3 181.91     2
Q4 3 at 181.9   3 181.91     2
Q5 5 at 142.5   5 142.50     2

  Formula: y ~ sawfly.cross$pheno$Head.Area + Q1 + Q2 + Q3 + Q4 + Q5 +
Q4:Q5

  pLOD:  166.23


In my late night of googling, I did see that the warning can indicate that
dimensions of the arguments do not match, but I do not know how to
translate that to my data or output.

Thank you.

On Sat, May 23, 2015 at 3:36 AM, Uwe Ligges <ligges at statistik.tu-dortmund.de
> wrote:

>
>
> On 23.05.2015 01:07, Claire O'Quin wrote:
> > Hi There,
> >
> > I am running a stepwise QTL for a backcross and got the following warning
> > message:
> >
> > Warning message:
> > In lastout[[i]] - (max(lastout[[i]]) - dropresult[rn == qn[i], 3]) :
> >    longer object length is not a multiple of shorter object length
>
> So dimensions of the arguments may not match?
> >
> > I can not discern what this means. When I created my plot, the QTL curve
> on
> > chromosome 3 is very odd (tried attaching it), so I suspect that the
> > warning is connected to that odd curve plot.
> >
> > I tried running the fitqtl just to see what would happen and got an error
> > (Error in solve.default(t(Z) %*% Z, t(Z) %*% X) : system is
> computationally
> > singular: reciprocal condition number = 1.49755e-24).
> >
> > Any thoughts about what is going on?
>
> No, without knoing what the arguments and the actual code was.
>
> Best,
> Uwe Ligges
>
> >
> > Thank you,
> > Claire
> >
> >
> >
> > -----------------------------------
> > Claire O'Quin, PhD
> > Postdoctoral Research Scholar
> > University of Kentucky
> > http://www.linnenlab.com/home.html
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>



-- 
-----------------------------------
Claire O'Quin, PhD
Postdoctoral Research Scholar
University of Kentucky
http://www.linnenlab.com/home.html

	[[alternative HTML version deleted]]


From claire.oquin at uky.edu  Sat May 23 16:30:04 2015
From: claire.oquin at uky.edu (Claire O'Quin)
Date: Sat, 23 May 2015 10:30:04 -0400
Subject: [R] Stepwise rQTL-unknown warning message and odd QTL curve
In-Reply-To: <6f28182adfdf42328f028a19c8f9b03b@EX10HB01.ad.uky.edu>
References: <caavufsnr4=hhx5wgcgqlbkwv88fggd6mp92vk-fvctr=kjfaaw@mail.gmail.com>
	<55602DEF.1020002@statistik.tu-dortmund.de>
	<6f28182adfdf42328f028a19c8f9b03b@EX10HB01.ad.uky.edu>
Message-ID: <CAAVUFskqtXRbrGzidzzr2Jj7=cev9OWDmU2tOhW1Nd28JqJyTw@mail.gmail.com>

Thank you for that information. I have found an rQTL help group and will
try to see if folks over there can help. I apologize for not doing a very
good job of communicating my issues over here.  I will try my best to
produce a reproducible example and post it here if I don't make any
progress on resolving my issues. Thank you everyone for your time.

On Sat, May 23, 2015 at 10:16 AM, John Kane <jrkrideau at inbox.com> wrote:

>
>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> and http://adv-r.had.co.nz/Reproducibility.html
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: ligges at statistik.tu-dortmund.de
> > Sent: Sat, 23 May 2015 09:36:15 +0200
> > To: claire.oquin at uky.edu, r-help at r-project.org
> > Subject: Re: [R] Stepwise rQTL-unknown warning message and odd QTL curve
> >
> >
> >
> > On 23.05.2015 01:07, Claire O'Quin wrote:
> >> Hi There,
> >>
> >> I am running a stepwise QTL for a backcross and got the following
> >> warning
> >> message:
> >>
> >> Warning message:
> >> In lastout[[i]] - (max(lastout[[i]]) - dropresult[rn == qn[i], 3]) :
> >>    longer object length is not a multiple of shorter object length
> >
> > So dimensions of the arguments may not match?
> >>
> >> I can not discern what this means. When I created my plot, the QTL curve
> >> on
> >> chromosome 3 is very odd (tried attaching it), so I suspect that the
> >> warning is connected to that odd curve plot.
> >>
> >> I tried running the fitqtl just to see what would happen and got an
> >> error
> >> (Error in solve.default(t(Z) %*% Z, t(Z) %*% X) : system is
> >> computationally
> >> singular: reciprocal condition number = 1.49755e-24).
> >>
> >> Any thoughts about what is going on?
> >
> > No, without knoing what the arguments and the actual code was.
> >
> > Best,
> > Uwe Ligges
> >
> >>
> >> Thank you,
> >> Claire
> >>
> >>
> >>
> >> -----------------------------------
> >> Claire O'Quin, PhD
> >> Postdoctoral Research Scholar
> >> University of Kentucky
> >> http://www.linnenlab.com/home.html
> >>
> >>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> Check it out at http://www.inbox.com/earth
>
>
>


-- 
-----------------------------------
Claire O'Quin, PhD
Postdoctoral Research Scholar
University of Kentucky
http://www.linnenlab.com/home.html

	[[alternative HTML version deleted]]


From c_c_ribeiro at hotmail.com  Sat May 23 17:13:15 2015
From: c_c_ribeiro at hotmail.com (Claudio Ribeiro)
Date: Sat, 23 May 2015 17:13:15 +0200
Subject: [R] Looking for help finding a wrapper/package to use TA-Lib in R
Message-ID: <DUB404-EAS2563B051B1B8BAEC57C55DEA7CF0@phx.gbl>

Dear members,

We all know the power and usefulness of TA-Lib. There is a python wrapper for it but, despite all my searching, I am unable to find it for R. Does anyone know why? I am starting learning and using RStudio and would really like to be able to call the TA-Lib functions from RStudio. Does anyone know where I can find an R wrapper or any other alternative?

Many thanks.
Claudio

From jrkrideau at inbox.com  Sat May 23 17:56:59 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 23 May 2015 07:56:59 -0800
Subject: [R] Looking for help finding a wrapper/package to use TA-Lib in
 R
In-Reply-To: <DUB404-EAS2563B051B1B8BAEC57C55DEA7CF0@phx.gbl>
Message-ID: <3452E72CA3A.00000493jrkrideau@inbox.com>

"We all know the power and usefulness of TA-Lib. "

Well no, I've never even heard of it before. Can you give us a link or something?  
John Kane
Kingston ON Canada


> -----Original Message-----
> From: c_c_ribeiro at hotmail.com
> Sent: Sat, 23 May 2015 17:13:15 +0200
> To: r-help at r-project.org
> Subject: [R] Looking for help finding a wrapper/package to use TA-Lib in
> R
> 
> Dear members,
> 
> We all know the power and usefulness of TA-Lib. There is a python wrapper
> for it but, despite all my searching, I am unable to find it for R. Does
> anyone know why? I am starting learning and using RStudio and would
> really like to be able to call the TA-Lib functions from RStudio. Does
> anyone know where I can find an R wrapper or any other alternative?
> 
> Many thanks.
> Claudio
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From jrkrideau at inbox.com  Sat May 23 19:40:36 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 23 May 2015 09:40:36 -0800
Subject: [R] Stepwise rQTL-unknown warning message and odd QTL curve
In-Reply-To: <CAAVUFsn5Lzino33XogJ82jpTS3HdWGn=1y18DE8NoqWAB8PTBQ@mail.gmail.com>
References: <ba50202500704591bf6682f3fbcdaea4@ex10hb02.ad.uky.edu>
	<caavufsnr4=hhx5wgcgqlbkwv88fggd6mp92vk-fvctr=kjfaaw@mail.gmail.com>
Message-ID: <353A7C8C0F2.0000058Ajrkrideau@inbox.com>

Hi Clare,
I suspect that we need to see some data in dput() format.  See the links I sent earlier or have a look at ?dput for more information.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: claire.oquin at uky.edu
> Sent: Sat, 23 May 2015 07:40:03 -0400
> To: ligges at statistik.tu-dortmund.de
> Subject: Re: [R] Stepwise rQTL-unknown warning message and odd QTL curve
> 
> Sorry, I'll try to provide more detail about what I have done so far with
> code and any relevant output results.
> 
> >library(qtl)
> >sawfly.cross <- read.cross(format="csv",
> file="~/Desktop/Sawfly_data/QTL/Sawfly_QTL.csv", na.strings="NA",
> genotypes=c("A", "B"), alleles=c("A", "B"), estimate.map=F)
> --Read the following data:
>  430  individuals
>  506  markers
>  19  phenotypes
>  --Cross type: bc
> 
> >print(sawfly.cross)
> --This is an object of class "cross".
>   It is too complex to print, so we provide just this summary.
>     Backcross
> 
>     No. individuals:    430
> 
>     No. phenotypes:     19
>     Percent phenotyped: 99.8 99.8 99.3 99.1 99.1 99.1 99.1 99.1 99.5 99.8
> 99.8 99.5 98.8 99.8 99.8 99.8 99.8 98.4 99.5
> 
>     No. chromosomes:    7
>         Autosomes:      1 2 3 4 5 6 7
> 
>     Total markers:      506
>     No. markers:        103 89 75 74 65 51 49
>     Percent genotyped:  96.2
>     Genotypes (%):      AA:49.7  AB:50.3
>     Backcross
> 
>     No. individuals:    430
> 
>     No. phenotypes:     19
>     Percent phenotyped: 99.8 99.8 99.3 99.1 99.1 99.1 99.1 99.1 99.5 99.8
> 99.8 99.5 98.8 99.8 99.8 99.8 99.8 98.4 99.5
> 
>     No. chromosomes:    7
>         Autosomes:      1 2 3 4 5 6 7
> 
>     Total markers:      506
>     No. markers:        103 89 75 74 65 51 49
>     Percent genotyped:  96.2
>     Genotypes (%):      AA:49.7  AB:50.3
> 
> >sawfly.cross <- calc.genoprob(sawfly.cross, step=2.5, error.prob=0.1,
> map.function="kosambi", stepwidth="fixed")
> 
> **I am using head size as a covariant.**
> 
> >head.covar <- pull.pheno(sawfly.cross, pheno.col=19)
> >sawfly.cross.stepwise.peryellow <- scantwo(sawfly.cross, pheno.col=2,
> model="normal", method="hk", addcovar=head.covar, use="all.obs",
> clean.output=F, verbose=T, n.perm=1000, batchsize=100);
> save.image("~/Desktop/Sawfly_data/QTL/SawflyQTL.RData")
> --Warning messages:
> 1: In checkcovar(cross, pheno.col, addcovar, intcovar, perm.strata,  :
>   Dropping 1 individuals with missing phenotypes.
> 
> 2: In checkcovar(cross, pheno.col, addcovar, intcovar, perm.strata,  :
>   Dropping 1 individuals with missing covariates.
> 
>> sawfly.cross.stepwise.peryellow.pen <- calc.penalties(alpha=0.05,
> perms=sawfly.cross.stepwise.peryellow)
> 
>>> sawfly.cross.stepwise.peryellow.stepqtl <- stepwiseqtl(sawfly.cross,
> pheno.col=2, method="hk", max.qtl=10,
> penalties=sawfly.cross.stepwise.peryellow.pen , verbose=T,
> keeplodprofile=T, covar=head.covar, scan.pairs=F, keeptrace=T)
> --Error in covar[!hasmissing, , drop = FALSE] : incorrect number of
> dimensions
> 
> **I corrected this with the next piece of code
> 
> >sawfly.cross.stepwise.peryellow.stepqtl <- stepwiseqtl(sawfly.cross,
> pheno.col=2, method="hk", max.qtl=10,
> penalties=sawfly.cross.stepwise.peryellow.pen , verbose=T,
> keeplodprofile=T, covar=as.data.frame(sawfly.cross$pheno$Head.Area),
> scan.pairs=F, keeptrace=T)
> 
> The stepwise than ran and I got to the point where I got the warning
> message I posted
> 
> about:Warning message:
> In lastout[[i]] - (max(lastout[[i]]) - dropresult[rn == qn[i], 3]) :
>   longer object length is not a multiple of shorter object length
> 
> I proceeded to examine the output
> 
> >sawfly.cross.stepwise.peryellow.stepqtl
>   QTL object containing genotype probabilities.
> 
>       name chr    pos n.gen
> Q1 1 at 106.1   1 106.11     2
> Q2 2 at 180.0   2 179.97     2
> Q3 3 at 181.9   3 181.91     2
> Q4 3 at 181.9   3 181.91     2
> Q5 5 at 142.5   5 142.50     2
> 
>   Formula: y ~ sawfly.cross$pheno$Head.Area + Q1 + Q2 + Q3 + Q4 + Q5 +
> Q4:Q5
> 
>   pLOD:  166.23
> 
> 
> In my late night of googling, I did see that the warning can indicate
> that
> dimensions of the arguments do not match, but I do not know how to
> translate that to my data or output.
> 
> Thank you.
> 
> On Sat, May 23, 2015 at 3:36 AM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de
>> wrote:
> 
>> 
>> 
>> On 23.05.2015 01:07, Claire O'Quin wrote:
>>> Hi There,
>>> 
>>> I am running a stepwise QTL for a backcross and got the following
>>> warning
>>> message:
>>> 
>>> Warning message:
>>> In lastout[[i]] - (max(lastout[[i]]) - dropresult[rn == qn[i], 3]) :
>>>    longer object length is not a multiple of shorter object length
>> 
>> So dimensions of the arguments may not match?
>>> 
>>> I can not discern what this means. When I created my plot, the QTL
>>> curve
>> on
>>> chromosome 3 is very odd (tried attaching it), so I suspect that the
>>> warning is connected to that odd curve plot.
>>> 
>>> I tried running the fitqtl just to see what would happen and got an
>>> error
>>> (Error in solve.default(t(Z) %*% Z, t(Z) %*% X) : system is
>> computationally
>>> singular: reciprocal condition number = 1.49755e-24).
>>> 
>>> Any thoughts about what is going on?
>> 
>> No, without knoing what the arguments and the actual code was.
>> 
>> Best,
>> Uwe Ligges
>> 
>>> 
>>> Thank you,
>>> Claire
>>> 
>>> 
>>> 
>>> -----------------------------------
>>> Claire O'Quin, PhD
>>> Postdoctoral Research Scholar
>>> University of Kentucky
>>> http://www.linnenlab.com/home.html
>>> 
>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
> 
> 
> 
> --
> -----------------------------------
> Claire O'Quin, PhD
> Postdoctoral Research Scholar
> University of Kentucky
> http://www.linnenlab.com/home.html
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Send your photos by email in seconds...
TRY FREE IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if3
Works in all emails, instant messengers, blogs, forums and social networks.


From goochmi at gmail.com  Sat May 23 19:58:25 2015
From: goochmi at gmail.com (Michael J Gooch)
Date: Sat, 23 May 2015 13:58:25 -0400
Subject: [R] Fwd:  compiling R with tuned BLAS
In-Reply-To: <555F3FCD.3080900@gmail.com>
References: <555F3FCD.3080900@gmail.com>
Message-ID: <5560BFC1.8050109@gmail.com>

forgot to include the list on cc


-------- Forwarded Message --------
Subject: 	Re: [R] compiling R with tuned BLAS
Date: 	Fri, 22 May 2015 10:40:13 -0400
From: 	Michael Gooch <goochmi at gmail.com>
To: 	Charles Determan <cdetermanjr at gmail.com>



I am not an administrative user. I'm using a university cluster and have 
to build everything and its dependencies manually.

I cannot use update alternatives, as it is a centos machine and as 
mentioned, I am not a sudoer. I have been setting up the various tools 
with http://modules.sourceforge.net/.

M. Gooch

On 05/22/2015 08:16 AM, Charles Determan wrote:
> Which OS are you using (Windows, Linux (distro), Mac)? When you 
> mention .so files I tend to assume you are using a Linux system.  If 
> you are using ubuntu, changing the BLAS used by R is relatively 
> trivial by using 'update-alternatives'.  More detail is provided at 
> the following link: 
> http://www.stat.cmu.edu/~nmv/2013/07/09/for-faster-r-use-openblas-instead-better-than-atlas-trivial-to-switch-to-on-ubuntu/ 
> <http://www.stat.cmu.edu/%7Enmv/2013/07/09/for-faster-r-use-openblas-instead-better-than-atlas-trivial-to-switch-to-on-ubuntu/>
>
> Charles
>
> On Thu, May 21, 2015 at 2:19 PM, Michael Gooch <goochmi at gmail.com 
> <mailto:goochmi at gmail.com>> wrote:
>
>     I am looking at the instructions on
>     http://cran.r-project.org/doc/manuals/r-patched/R-admin.html#ATLAS
>
>     I have noticed that ATLAS produces two shared libs in addition to
>     the *.a files:
>     http://math-atlas.sourceforge.net/atlas_install/node22.html
>
>     contents of the ATLAS lib directory:
>     libatlas.a  libcblas.a  libf77blas.a  liblapack.a libptcblas.a
>     libptf77blas.a  libsatlas.so  libtatlas.so
>
>     The instructions do not appear to match up with the *.a files &
>     *.so files as described. (it appears to want me to use shared
>     libs, but the names defined are static libs, not shared libs).
>
>     should I simply be having it link against libtatlas.so (and
>     pthreads) for shared threaded atlas and libsatlas.so for shared
>     sequential atlas?
>     do I need shared versions of the other static libraries?
>
>     I think the help is a bit out of date, or at least unclear as to
>     what it intends of me.
>
>     M. Gooch
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>





---
This email has been checked for viruses by Avast antivirus software.


	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Sat May 23 20:01:37 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 23 May 2015 10:01:37 -0800
Subject: [R] Looking for help finding a wrapper/package to use TA-Lib in
 R
In-Reply-To: <DUB404-EAS34177B48AFB15D29C796512A7CF0@phx.gbl>
References: <3452e72ca3a.00000493jrkrideau@inbox.com>
Message-ID: <3569789552C.000005D4jrkrideau@inbox.com>

Terribly uninformative web-site but it does give us some idea. Thanks

John Kane
Kingston ON Canada


> -----Original Message-----
> From: c_c_ribeiro at hotmail.com
> Sent: Sat, 23 May 2015 19:50:26 +0200
> To: jrkrideau at inbox.com
> Subject: Re: [R] Looking for help finding a wrapper/package to use TA-Lib
> in R
> 
> Apologies. I assumed it was widely known. My mistake. The link is
> www.ta-lib.org
> 
> 
> 
> 
>> On May 23, 2015, at 5:57 PM, John Kane <jrkrideau at inbox.com> wrote:
>> 
>> "We all know the power and usefulness of TA-Lib. "
>> 
>> Well no, I've never even heard of it before. Can you give us a link or
>> something?
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: c_c_ribeiro at hotmail.com
>>> Sent: Sat, 23 May 2015 17:13:15 +0200
>>> To: r-help at r-project.org
>>> Subject: [R] Looking for help finding a wrapper/package to use TA-Lib
>>> in
>>> R
>>> 
>>> Dear members,
>>> 
>>> We all know the power and usefulness of TA-Lib. There is a python
>>> wrapper
>>> for it but, despite all my searching, I am unable to find it for R.
>>> Does
>>> anyone know why? I am starting learning and using RStudio and would
>>> really like to be able to call the TA-Lib functions from RStudio. Does
>>> anyone know where I can find an R wrapper or any other alternative?
>>> 
>>> Many thanks.
>>> Claudio
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ____________________________________________________________
>> Can't remember your password? Do you need a strong and secure password?
>> Use Password manager! It stores your passwords & protects your account.
>> Check it out at http://mysecurelogon.com/manager
>> 
>>

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From boris.steipe at utoronto.ca  Sat May 23 20:36:06 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 23 May 2015 14:36:06 -0400
Subject: [R] Help with urnsamples and all possible combination
In-Reply-To: <1432378766194-4707560.post@n4.nabble.com>
References: <1432378766194-4707560.post@n4.nabble.com>
Message-ID: <3411D57F-039C-443C-A76C-1888A57C3198@utoronto.ca>

Actually your approach doesn't get around making a matrix of that size. If you look at the code of urnsamples, (in prob:::urnsamples.default), you'll find that it creates an intermediate object using expand.grid(). So you might as well create the matrix yourself, extract all rows for which max(table(<your row>)) < 4, and sample() from those (or use them all).

Or, if you are willing to accept the slight shift in probabilities of selected elements, and number of combinations you need is limited, and you can accept the small possibility that a combination will be repeated, you could just replicate your vector three times and sample without replacement:

s <- 7
x <- 1:25
limit <- 20
A <- matrix(0, nrow=limit, ncol=s)
for (i in 1:limit) {
    A[i, ] <- sort(sample(rep(x,3), size = s, replace = FALSE))
}
A


Cheers,
B.



On May 23, 2015, at 6:59 AM, MGalla <michelle.galla at gmx.de> wrote:

> Hello, 
> 
> i need some help to use urnsamples from the package "prob".
> 
> At the moment i use it in this way
> 
> A<-as.matrix(urnsamples(1:25, size = 7,ordered=FALSE,replace=TRUE))
> 
> So I get the numbers 1 to 25 and choose 7 of them, but it is possible to get
> one number more than one time. 
> But I want additionally that I get a number not more than three times. So
> for example "1111222" is no 
> combination, but "1112223" is allowed. 
> 
> I know that it should be possible to create A in my way and than delete all
> "wrong" combinations, 
> but i will work also with bigger size than 7, so the Matrix A will get to
> large. 
> 
> So my question is, if there is a option to give urnsamples the limit to
> choose every object not more than three times? Or is there another way to
> get the combinations I want. 
> 
> Thanks, 
> Michelle Galla
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Help-with-urnsamples-and-all-possible-combination-tp4707560.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From c_c_ribeiro at hotmail.com  Sat May 23 19:50:26 2015
From: c_c_ribeiro at hotmail.com (Claudio Ribeiro)
Date: Sat, 23 May 2015 19:50:26 +0200
Subject: [R] Looking for help finding a wrapper/package to use TA-Lib in
	R
In-Reply-To: <3452E72CA3A.00000493jrkrideau@inbox.com>
References: <3452E72CA3A.00000493jrkrideau@inbox.com>
Message-ID: <DUB404-EAS34177B48AFB15D29C796512A7CF0@phx.gbl>

Apologies. I assumed it was widely known. My mistake. The link is www.ta-lib.org




> On May 23, 2015, at 5:57 PM, John Kane <jrkrideau at inbox.com> wrote:
> 
> "We all know the power and usefulness of TA-Lib. "
> 
> Well no, I've never even heard of it before. Can you give us a link or something?  
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: c_c_ribeiro at hotmail.com
>> Sent: Sat, 23 May 2015 17:13:15 +0200
>> To: r-help at r-project.org
>> Subject: [R] Looking for help finding a wrapper/package to use TA-Lib in
>> R
>> 
>> Dear members,
>> 
>> We all know the power and usefulness of TA-Lib. There is a python wrapper
>> for it but, despite all my searching, I am unable to find it for R. Does
>> anyone know why? I am starting learning and using RStudio and would
>> really like to be able to call the TA-Lib functions from RStudio. Does
>> anyone know where I can find an R wrapper or any other alternative?
>> 
>> Many thanks.
>> Claudio
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/manager
> 
> 


From gunter.berton at gene.com  Sat May 23 21:52:01 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 23 May 2015 12:52:01 -0700
Subject: [R] elegant way to create a sequence with the 'rep' bulit-in
	function
In-Reply-To: <CAMFx86wtOghh+cimVCKOPpX977a2+tu7iyrthMncHXLgDy=41w@mail.gmail.com>
References: <CAMFx86wtOghh+cimVCKOPpX977a2+tu7iyrthMncHXLgDy=41w@mail.gmail.com>
Message-ID: <CACk-te3MEfd7gAVruhGis6W4_Bg9L-M=cRXjZ-Y-SCx=irR4nw@mail.gmail.com>

Elegance is in the eye of the beholder.

But I would have thought that anything you do would be some variation of:

c(rep(1:3,e=2,time=4),
rep(4:5,e=4,time=3),
rep(6:9,e=3,time=2) )

## yielding

 [1] 1 1 2 2 3 3 1 1 2 2 3 3 1 1 2 2 3 3 1 1 2 2 3 3 4 4 4 4 5 5 5 5 4
4 4 4 5 5 5 5 4
[42] 4 4 4 5 5 5 5 6 6 6 7 7 7 8 8 8 9 9 9 6 6 6 7 7 7 8 8 8 9 9 9

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, May 23, 2015 at 7:55 AM, Kathryn Lord
<kathryn.lord2000 at gmail.com> wrote:
> Dear R users,
>
> I'd like to create a sequence/vector, for example,
>
> 1 1 2 2 3 3 1 1 2 2 3 3 1 1 2 2 3 3 1 1 2 2 3 3       4 4 4 4 5 5 5 5 4 4 4
> 4 5 5 5 5 4 4 4 4 5 5 5 5       6 6 6 7 7 7 8 8 8 9 9 9 6 6 6 7 7 7 8 8 8 9
> 9 9
>
> So I did like this below.
>
> a <- 4
> b <- 3
> c <- 2
>
> grp <- c( rep(1:b, each=c, times=a), rep(1:c, each=a, times=b)+b, rep(1:a,
> each=b, times=c)+b+c )
>
> I wonder if there is a more elegant way to do this?
>
> Any suggestions? Thank you!
>
> Best wishes
>
> Kathie
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sat May 23 23:46:30 2015
From: jdnewmil at dcn.davis.ca.us (jdnewmil)
Date: Sat, 23 May 2015 14:46:30 -0700
Subject: [R] elegant way to create a sequence with the 'rep' bulit-in
 function
In-Reply-To: <CACk-te3MEfd7gAVruhGis6W4_Bg9L-M=cRXjZ-Y-SCx=irR4nw@mail.gmail.com>
References: <CAMFx86wtOghh+cimVCKOPpX977a2+tu7iyrthMncHXLgDy=41w@mail.gmail.com>
	<CACk-te3MEfd7gAVruhGis6W4_Bg9L-M=cRXjZ-Y-SCx=irR4nw@mail.gmail.com>
Message-ID: <e515cd3d979b34f19ca02d698a5a4756@omsoft.com>

I agree with Bert. It is not clear what is generating a need for this 
sequence, so it
is difficult to see what aspects need to be adjustable. If this specific
sequence is the only one you need, then Bert's code looks "elegant" to 
me.

One note: "c" is a base function in R. Functions in R are first-class 
objects.
It is really confusing and just a bad idea to create a vector named "c" 
and then
call "c" as well. I have used uppercase variable names to alleviate this 
problem.

A <- 4
B <- 3
C <- 2

# Minutely more efficient version of OP code:
c( rep( seq.int( B )        , each=C, times=A )
  , rep( seq.int( C ) + B    , each=A, times=B )
  , rep( seq.int( A ) + B + C, each=B, times=C )
  )

# Excessively flexible version of OP code (can make V longer):
V <- c( A, B, C )
M <- cbind( embed( c( V[ -1 ], V ), length( V ) ), cumsum( V ) - V[ 1 ] 
)
do.call( c
        , lapply( seq.int( nrow( M ) )
                , function( i ) { rep( seq.int( M[ i, 3 ] ) + M[ i, 4 ],  
each=M[ i, 2 ], times=M[ i, 1 ] ) }
                )
        )

Please post using plain text format to insure that we see what you see, 
since the mailing list WILL remove HTML.

On 2015-05-23 12:52, Bert Gunter wrote:
> Elegance is in the eye of the beholder.
> 
> But I would have thought that anything you do would be some variation 
> of:
> 
> c(rep(1:3,e=2,time=4),
> rep(4:5,e=4,time=3),
> rep(6:9,e=3,time=2) )
> 
> ## yielding
> 
>  [1] 1 1 2 2 3 3 1 1 2 2 3 3 1 1 2 2 3 3 1 1 2 2 3 3 4 4 4 4 5 5 5 5 4
> 4 4 4 5 5 5 5 4
> [42] 4 4 4 5 5 5 5 6 6 6 7 7 7 8 8 8 9 9 9 6 6 6 7 7 7 8 8 8 9 9 9
> 
> Cheers,
> Bert
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
> 
> 
> 
> 
> On Sat, May 23, 2015 at 7:55 AM, Kathryn Lord
> <kathryn.lord2000 at gmail.com> wrote:
>> Dear R users,
>> 
>> I'd like to create a sequence/vector, for example,
>> 
>> 1 1 2 2 3 3 1 1 2 2 3 3 1 1 2 2 3 3 1 1 2 2 3 3       4 4 4 4 5 5 5 5 
>> 4 4 4
>> 4 5 5 5 5 4 4 4 4 5 5 5 5       6 6 6 7 7 7 8 8 8 9 9 9 6 6 6 7 7 7 8 
>> 8 8 9
>> 9 9
>> 
>> So I did like this below.
>> 
>> a <- 4
>> b <- 3
>> c <- 2
>> 
>> grp <- c( rep(1:b, each=c, times=a), rep(1:c, each=a, times=b)+b, 
>> rep(1:a,
>> each=b, times=c)+b+c )
>> 
>> I wonder if there is a more elegant way to do this?
>> 
>> Any suggestions? Thank you!
>> 
>> Best wishes
>> 
>> Kathie
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From oma.gonzales at gmail.com  Sun May 24 01:08:52 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Sat, 23 May 2015 18:08:52 -0500
Subject: [R] how to loop or lapply over a "XMLNodeSet" object with condition
	(if else)
Message-ID: <CAM-xyZgnqnm_oXiGyNDOi0HxWHuiAxdexeLuLkUVQzNr_g5+3Q@mail.gmail.com>

Hi, R-Help members,

I'm doing some webscraping. This time i need the image (url) of the
products of an ecommerce.
I can get the nodes where the urls are, but when trying to extract the URL,
i need to take 1
additional step:

"src" vs "data-original": in the source code, some urls are in the "src"
attribute, while others in the "data-original" attribute.

How to make a loop of an apply function to: if node element contains
"data-original" do:

...     %>%
        html_attr("data-original")

else do:

...     %>%
         html_attr("src")


The result should be a vector with the urls.


My code:

1.- I can get the nodes for the images:


##########################################################
#This result in a "XMLNodeSet" object

library(rvest)

PCs <- html("http://www.linio.cl/computacion/pc-escritorio/") %>%
        html_nodes(".product-item-img") %>%
        html_nodes("img")

###########################################################


#for the attr "data-original"

PCs2 <- html("http://www.linio.cl/computacion/pc-escritorio/") %>%
        html_nodes(".product-item-img") %>%
        html_nodes("img") %>%
        html_attr("data-original")

Gives the urls for the attr "data-original", and NAs where there isn't this
attr.


#for the attr "src"


PCs3 <- html("http://www.linio.cl/computacion/pc-escritorio/") %>%
        html_nodes(".product-item-img") %>%
        html_nodes("img") %>%
        html_attr("src")


Gives the content for the "src" attr. How ever, in some products the url
needed is in the "data-original" attr, and not here.

#### combination throwing NAs as result #####


PCs4 <- html("http://www.linio.cl/computacion/pc-escritorio/") %>%
        html_nodes(".product-item-img") %>%
        html_nodes("img") %>%
        html_attr("data-original|src")



################################################

I've also tried something like this:

lapply(PCs, function(e) {
        if ("data-original" %in% i) {
                print("ok")
        }
})

but get this:


 Error in match(x, table, nomatch = 0L) :
  'match' requires vector arguments



Thanks.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun May 24 05:59:27 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 24 May 2015 13:59:27 +1000
Subject: [R] elegant way to create a sequence with the 'rep' bulit-in
	function
In-Reply-To: <e515cd3d979b34f19ca02d698a5a4756@omsoft.com>
References: <CAMFx86wtOghh+cimVCKOPpX977a2+tu7iyrthMncHXLgDy=41w@mail.gmail.com>
	<CACk-te3MEfd7gAVruhGis6W4_Bg9L-M=cRXjZ-Y-SCx=irR4nw@mail.gmail.com>
	<e515cd3d979b34f19ca02d698a5a4756@omsoft.com>
Message-ID: <CA+8X3fW5K+ZkRKfFxU+MJg+KjAX0ZyHND7P24m8Ld6RROgkGHQ@mail.gmail.com>

Hi Kathryn,
Well, there's always:

make_num_seq<-function(x=list(c(from=1,to=1,by=1,each=1,times=1))) {
 return(c(unlist(lapply(x,
  function(x) return(rep(seq(x[1],x[2],by=x[3]),each=x[4],times=x[5]))))))
}
make_num_seq(list(c(1,3,1,2,4),c(4,5,1,4,3),c(6,9,1,3,2)))

Jim


On Sun, May 24, 2015 at 7:46 AM, jdnewmil <jdnewmil at dcn.davis.ca.us> wrote:
> I agree with Bert. It is not clear what is generating a need for this
> sequence, so it
> is difficult to see what aspects need to be adjustable. If this specific
> sequence is the only one you need, then Bert's code looks "elegant" to me.
>
> One note: "c" is a base function in R. Functions in R are first-class
> objects.
> It is really confusing and just a bad idea to create a vector named "c" and
> then
> call "c" as well. I have used uppercase variable names to alleviate this
> problem.
>
> A <- 4
> B <- 3
> C <- 2
>
> # Minutely more efficient version of OP code:
> c( rep( seq.int( B )        , each=C, times=A )
>  , rep( seq.int( C ) + B    , each=A, times=B )
>  , rep( seq.int( A ) + B + C, each=B, times=C )
>  )
>
> # Excessively flexible version of OP code (can make V longer):
> V <- c( A, B, C )
> M <- cbind( embed( c( V[ -1 ], V ), length( V ) ), cumsum( V ) - V[ 1 ] )
> do.call( c
>        , lapply( seq.int( nrow( M ) )
>                , function( i ) { rep( seq.int( M[ i, 3 ] ) + M[ i, 4 ],
> each=M[ i, 2 ], times=M[ i, 1 ] ) }
>                )
>        )
>
> Please post using plain text format to insure that we see what you see,
> since the mailing list WILL remove HTML.
>
>
> On 2015-05-23 12:52, Bert Gunter wrote:
>>
>> Elegance is in the eye of the beholder.
>>
>> But I would have thought that anything you do would be some variation of:
>>
>> c(rep(1:3,e=2,time=4),
>> rep(4:5,e=4,time=3),
>> rep(6:9,e=3,time=2) )
>>
>> ## yielding
>>
>>  [1] 1 1 2 2 3 3 1 1 2 2 3 3 1 1 2 2 3 3 1 1 2 2 3 3 4 4 4 4 5 5 5 5 4
>> 4 4 4 5 5 5 5 4
>> [42] 4 4 4 5 5 5 5 6 6 6 7 7 7 8 8 8 9 9 9 6 6 6 7 7 7 8 8 8 9 9 9
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Sat, May 23, 2015 at 7:55 AM, Kathryn Lord
>> <kathryn.lord2000 at gmail.com> wrote:
>>>
>>> Dear R users,
>>>
>>> I'd like to create a sequence/vector, for example,
>>>
>>> 1 1 2 2 3 3 1 1 2 2 3 3 1 1 2 2 3 3 1 1 2 2 3 3       4 4 4 4 5 5 5 5 4 4
>>> 4
>>> 4 5 5 5 5 4 4 4 4 5 5 5 5       6 6 6 7 7 7 8 8 8 9 9 9 6 6 6 7 7 7 8 8 8
>>> 9
>>> 9 9
>>>
>>> So I did like this below.
>>>
>>> a <- 4
>>> b <- 3
>>> c <- 2
>>>
>>> grp <- c( rep(1:b, each=c, times=a), rep(1:c, each=a, times=b)+b,
>>> rep(1:a,
>>> each=b, times=c)+b+c )
>>>
>>> I wonder if there is a more elegant way to do this?
>>>
>>> Any suggestions? Thank you!
>>>
>>> Best wishes
>>>
>>> Kathie
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From vijaya.mulakalapalli at gmail.com  Sat May 23 22:16:26 2015
From: vijaya.mulakalapalli at gmail.com (Vijaya mulakalapalli)
Date: Sun, 24 May 2015 04:16:26 +0800
Subject: [R] Entropy Optimization to fit distribution parameters through
	Alabama package
Message-ID: <CA+yLEZCKFFQv6kYSLizkVJgg_C_PzxEJ+EQbwGoyoa=a=XaSpg@mail.gmail.com>

Hi,

I am trying to fit the parameters of a distribution to my data using
entropy optimization. For this I am using the first 4 moments of my data
and trying to calibrate them to the most suitable distribution by
maximizing entropy. Since the moment constraints are nonlinear, I am trying
to use package alabama to achieve this. Since negative Entropy is a convex
function, I was hopeful of achieving a global minima through this exercise.
However, my entropy function converges to different values with different
starting points. Am I doing something wrong here? I could provide the code
based on your inputs

Thanks!

	[[alternative HTML version deleted]]


From maria.mi8 at gmx.de  Sun May 24 00:21:12 2015
From: maria.mi8 at gmx.de (Narua)
Date: Sat, 23 May 2015 15:21:12 -0700 (PDT)
Subject: [R] Problem with apply list to function: numerical expression has 4
 elements: only the first used
Message-ID: <1432419672494-4707588.post@n4.nabble.com>

Hello ,

I want to try R for statistics. 

Therefore, I defined a function f with parameters m and k, which calculates
a to sqrt(x) proportional density function: 
f <- function(m,k)((1/(sum(sqrt(1:m))))*sqrt(k))

A function F sums the results in order to get a distribution function:
F <- function(m,i)(sum(f(m,1:i)))
It works e.g. for m=4:
> F(4,1)
[1] 0.1627005
> F(4,4)
[1] 1

If I want to see all results for m=4, I write
> F(4,1:4)
[1] 0.1627005
Warning message:
In 1:i : numerical expression has 4 elements: only the first used

what does the error message mean? 
and how can I solve it?

I've already tried rapply but I get the same error and googled for a while
but there is nowhere a satisfying answer

Can someone help me here?

many thanks in advance, 
Narua




--
View this message in context: http://r.789695.n4.nabble.com/Problem-with-apply-list-to-function-numerical-expression-has-4-elements-only-the-first-used-tp4707588.html
Sent from the R help mailing list archive at Nabble.com.


From kehld at ktk.pte.hu  Sun May 24 09:22:03 2015
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?Kehl_D=E1niel?=)
Date: Sun, 24 May 2015 07:22:03 +0000
Subject: [R] Problem with apply list to function: numerical expression
 has 4 elements: only the first used
In-Reply-To: <1432419672494-4707588.post@n4.nabble.com>
References: <1432419672494-4707588.post@n4.nabble.com>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D14442668@EMAIL.ktkdom.pte.hu>

Dear Narua,

Others might suggest other things but here are some of my points.
In general it is not a good idea to call a function F as it is an abbreviation for FALSE.
Also it might be a good idea to write your functions in a way that they check the length of the arguments and behave accordingly  (if nothing else, with loops). It is really nice to take a look at the family of apply functions (although I also have problems with them sometimes).

I did not check, but you can try something like this

ff <- function(m,k)((1/(sum(sqrt(1:m))))*sqrt(k))
FF <- function(m,i)(sum(ff(m,1:i)))
x <- 1:4

sapply(x, ff, m=4)
sapply(x, FF, m=4)


Keep up with using R! :)

Best,
kd
________________________________________
Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Narua [maria.mi8 at gmx.de]
K?ldve: 2015. m?jus 24. 0:21
To: r-help at r-project.org
T?rgy: [R] Problem with apply list to function: numerical expression has 4 elements: only the first used

Hello ,

I want to try R for statistics.

Therefore, I defined a function f with parameters m and k, which calculates
a to sqrt(x) proportional density function:
f <- function(m,k)((1/(sum(sqrt(1:m))))*sqrt(k))

A function F sums the results in order to get a distribution function:
F <- function(m,i)(sum(f(m,1:i)))
It works e.g. for m=4:
> F(4,1)
[1] 0.1627005
> F(4,4)
[1] 1

If I want to see all results for m=4, I write
> F(4,1:4)
[1] 0.1627005
Warning message:
In 1:i : numerical expression has 4 elements: only the first used

what does the error message mean?
and how can I solve it?

I've already tried rapply but I get the same error and googled for a while
but there is nowhere a satisfying answer

Can someone help me here?

many thanks in advance,
Narua




--
View this message in context: http://r.789695.n4.nabble.com/Problem-with-apply-list-to-function-numerical-expression-has-4-elements-only-the-first-used-tp4707588.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bsmith030465 at gmail.com  Sun May 24 13:47:51 2015
From: bsmith030465 at gmail.com (Brian Smith)
Date: Sun, 24 May 2015 07:47:51 -0400
Subject: [R] plot: rug colors
Message-ID: <CAEQKoCHBKkFC3SEh4PNizWwuTDqs9XwCqCLerfcSXCFtVADjvw@mail.gmail.com>

Hi,

I wanted the rug (in plot) to have different colors. For example:

vals1 <- sample(1:100,5)
vals2 <- sample(1:100,5)

rugcols <- c("red","blue","brown","red","yellow")

plot(vals1,vals2)
rug(vals1,col=rugcols,lwd=2)


However, with this code I only get 'red' for all the ticks. Is there a way
I can get the different colors for rug?

thanks!

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun May 24 14:09:19 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 24 May 2015 08:09:19 -0400
Subject: [R] plot: rug colors
In-Reply-To: <CAEQKoCHBKkFC3SEh4PNizWwuTDqs9XwCqCLerfcSXCFtVADjvw@mail.gmail.com>
References: <CAEQKoCHBKkFC3SEh4PNizWwuTDqs9XwCqCLerfcSXCFtVADjvw@mail.gmail.com>
Message-ID: <5561BF6F.5060206@gmail.com>

On 24/05/2015 7:47 AM, Brian Smith wrote:
> Hi,
> 
> I wanted the rug (in plot) to have different colors. For example:
> 
> vals1 <- sample(1:100,5)
> vals2 <- sample(1:100,5)
> 
> rugcols <- c("red","blue","brown","red","yellow")
> 
> plot(vals1,vals2)
> rug(vals1,col=rugcols,lwd=2)
> 
> 
> However, with this code I only get 'red' for all the ticks. Is there a way
> I can get the different colors for rug?

The rug() function is basically a wrapper for axis(), and it doesn't
support multiple colours of tick marks.  So what you could do is call
rug() once for each colour:

# This line is not needed in your example, but might be in general...
rugcols <- rep(rugcols, length.out=length(vals1))

for (col in unique(rugcols)) {
  show <- rugcols == col
  rug(vals1[show], col=col, lwd=2)
}

Duncan Murdoch


From bsmith030465 at gmail.com  Sun May 24 14:51:33 2015
From: bsmith030465 at gmail.com (Brian Smith)
Date: Sun, 24 May 2015 08:51:33 -0400
Subject: [R] plot: rug colors
In-Reply-To: <5561BF6F.5060206@gmail.com>
References: <CAEQKoCHBKkFC3SEh4PNizWwuTDqs9XwCqCLerfcSXCFtVADjvw@mail.gmail.com>
	<5561BF6F.5060206@gmail.com>
Message-ID: <CAEQKoCHc+51r6T1aBQw8o57Mh9fqcww_uHf04PpHjLtB6Wf8Yg@mail.gmail.com>

Thanks Duncan! That works!

On Sun, May 24, 2015 at 8:09 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 24/05/2015 7:47 AM, Brian Smith wrote:
> > Hi,
> >
> > I wanted the rug (in plot) to have different colors. For example:
> >
> > vals1 <- sample(1:100,5)
> > vals2 <- sample(1:100,5)
> >
> > rugcols <- c("red","blue","brown","red","yellow")
> >
> > plot(vals1,vals2)
> > rug(vals1,col=rugcols,lwd=2)
> >
> >
> > However, with this code I only get 'red' for all the ticks. Is there a
> way
> > I can get the different colors for rug?
>
> The rug() function is basically a wrapper for axis(), and it doesn't
> support multiple colours of tick marks.  So what you could do is call
> rug() once for each colour:
>
> # This line is not needed in your example, but might be in general...
> rugcols <- rep(rugcols, length.out=length(vals1))
>
> for (col in unique(rugcols)) {
>   show <- rugcols == col
>   rug(vals1[show], col=col, lwd=2)
> }
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun May 24 08:15:57 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 24 May 2015 16:15:57 +1000
Subject: [R] Problem with comparing multiple data sets
In-Reply-To: <32FCEB5D574.0000035Fjrkrideau@inbox.com>
References: <CAJVfk9nM_a2Gr86OXimHbc8HZoN45RMWLL_VmXak4RPoj1=OQw@mail.gmail.com>
	<32FCEB5D574.0000035Fjrkrideau@inbox.com>
Message-ID: <CA+8X3fW4BwSQ2U-EpUmzQzsfL-4sYJZaKFR56qS8i-FMk7HPfA@mail.gmail.com>

Hi Mohammad,
You know, I thought this would be fairly easy, but it wasn't really.

df1<-data.frame(Class=c(0,2,1),Comment=c("com1","com2","com3"),
 Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
df2<-data.frame(Class=c(0,2,1),Comment=c("com1","com2","com3"),
 Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
df3<-data.frame(Class=c(2,1,0),Comment=c("com1","com2","com3"),
 Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
dflist<-list(df1,df2,df3)
dflist

# define a function that extracts the value from one field
# selected by a value in another field
extract_by_value<-function(x,field1,value1,field2) {
 return(x[x[,field1]==value1,field2])
}

# define another function that equates all of the values
sub_value<-function(x,field1,value1,field2,value2) {
 x[x[,field1]==value1,field2]<-value2
 return(x)
}

conformity<-function(x,fieldname1,value1,fieldname2) {
 # get the most frequent value in fieldname2
 # for the desired value in fieldname1
 most_freq<-as.numeric(names(which.max(table(unlist(lapply(x,
  extract_by_value,fieldname1,value1,fieldname2))))))
 # now set all the values to the most frequent
 for(i in 1:length(x))
  x[[i]]<-sub_value(x[[i]],fieldname1,value1,fieldname2,most_freq)
 return(x)
}

conformity(dflist,"Text","text1","Class")

Jim

On Sat, May 23, 2015 at 11:23 PM, John Kane <jrkrideau at inbox.com> wrote:
> Hi Mohammad
>
> Welcome to the R-help list.
>
> There probably is a fairly easy way to what you want but I think we probably need a bit more background information on what you are trying to achieve.  I know I'm not exactly clear on your decision rule(s).
>
> It would also be very useful to see some actual sample data in useable R format.Have a look at these links http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html for some hints on what you might want to include in your question.
>
> In particular, read up about dput()  in those links and/or see ?dput.  This is the generally preferred way to supply sample or illustrative data to the R-help list.  It basically creates a perfect copy of the data as it exists on 'your' machine so that R-help readers see exactly what you do.
>
>
>
>
>
>
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: mxalimohamma at ualr.edu
>> Sent: Fri, 22 May 2015 12:37:50 -0500
>> To: r-help at r-project.org
>> Subject: [R] Problem with comparing multiple data sets
>>
>> Hi everyone,
>>
>> I am very new to R and I have a task to do. I appreciate any help. I have
>> 3
>> data sets. Each data set has 4 columns. For example:
>>
>> Class  Comment   Term   Text
>> 0           com1        aac    text1
>> 2           com2        aax    text2
>> 1           com3        vvx    text3
>>
>> Now I need t compare the class section between 3 data sets and assign the
>> most available class to that text. For example if text1 is assigned to
>> class 0 in data set 1&2 but assigned as 2 in data set 3 then it should be
>> assigned to class 0. If they are all the same so the class will be the
>> same. The ideal thing would be to keep the same format and just update
>> the
>> class. Is there any easy way to do this?
>>
>> Thanks a lot.
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maria.mi8 at gmx.de  Sun May 24 15:30:13 2015
From: maria.mi8 at gmx.de (Narua)
Date: Sun, 24 May 2015 06:30:13 -0700 (PDT)
Subject: [R] Problem with apply list to function: numerical expression
 has 4 elements: only the first used
In-Reply-To: <33D76D77E9AC4B438DA38B348ED6890D14442668@EMAIL.ktkdom.pte.hu>
References: <1432419672494-4707588.post@n4.nabble.com>
	<33D76D77E9AC4B438DA38B348ED6890D14442668@EMAIL.ktkdom.pte.hu>
Message-ID: <1432474213014-4707611.post@n4.nabble.com>

Dear kd,
thanks for your fast reply :-D
hm, I thougth, F is normally the abbrevation, but in R FALSE represents
"false"?
Anyway, your function works.

I had actually a little more complicate functions (put I posted in the forum
first an easier example):
f<-function(a,b)((1/(sum(sqrt(1:a))))*sqrt(b))
F<-function(a,b)(sum(f(a,1:b)))
> F(5,3)
[1] 0.4946433
> F(5,5)
[1] 1
therefore, 0.4946433 is the distribution of b=3 with a=5 Elements.

FInv<-function(s,a,b) if(isTRUE(all.equal(F(a,b),s, tolerance=0.00001)))
cat("F(",s,",",a,",",b,") equals s; ") else cat("F(",a,",",b,") does not
equal to s; ")
FInv is the reverse function. you put a probability in the function and
recieve the distribution b of a special a.
I wanted to have a function FInv' to pass on s for all a and all b to
FInv(s,a,b) in order to find out, which probability fits to which a and b.

And I couln't pass on a and b so easily, I got the error: "In 1:i :
numerical expression has 4 elements: only the first used "
I think, the reason is, that R expects a number, but receives a list, and
that produces the error.

I tried 
>x<-c(1:10)
> FooInv<-function(s) foreach(i=1:10)%do%sapply(x,FInv,s=s,k=i) and that
> works:
> FooInv(0.4946433)
F(s = 0.4946433 ,m = 5 ,k = 3 ) equals s; [[1]]

Foreach is a for-loop, and sapply matches FInv for every element of the list
x.

But now another problem occured:
Obviously R gets anywhere a NULL-pointer, because the full output is:
F(s = 0.4946433 ,m = 5 ,k = 3 ) equals s; [[1]]
[[1]][[1]]
NULL

[[1]][[2]]
NULL

[[1]][[3]]
NULL

[[1]][[4]]
NULL

[[1]][[5]]
NULL
...
in every loop.

Do you know how I can get rid of the NULL-outputs?

if this problem is solved, I have all I need in order to calculate the
distribution and its inverse function :-)

Thanks in advance,
Narua 




--
View this message in context: http://r.789695.n4.nabble.com/Problem-with-apply-list-to-function-numerical-expression-has-4-elements-only-the-first-used-tp4707588p4707611.html
Sent from the R help mailing list archive at Nabble.com.


From maria.mi8 at gmx.de  Sun May 24 15:35:09 2015
From: maria.mi8 at gmx.de (Narua)
Date: Sun, 24 May 2015 06:35:09 -0700 (PDT)
Subject: [R] Problem with apply list to function: numerical expression
 has 4 elements: only the first used
In-Reply-To: <33D76D77E9AC4B438DA38B348ED6890D14442668@EMAIL.ktkdom.pte.hu>
References: <1432419672494-4707588.post@n4.nabble.com>
	<33D76D77E9AC4B438DA38B348ED6890D14442668@EMAIL.ktkdom.pte.hu>
Message-ID: <1432474509383-4707612.post@n4.nabble.com>

Dear kd,
thanks for your fast reply 
hm, I thougth, F is normally the abbrevation, but in R FALSE represents
"false"?
Anyway, your function works and I got the idea to work with "apply" 

I had actually a little more complicate functions (put I posted in the forum
first an easier example):
f<-function(a,b)((1/(sum(sqrt(1:a))))*sqrt(b))
F<-function(a,b)(sum(f(a,1:b)))
> F(5,3)
[1] 0.4946433
> F(5,5)
[1] 1
therefore, 0.4946433 is the distribution of b=3 with a=5 Elements.

FInv<-function(s,a,b) if(isTRUE(all.equal(F(a,b),s, tolerance=0.00001)))
cat("F(",s,",",a,",",b,") equals s; ") else cat("F(",a,",",b,") does not
equal to s; ")
FInv is the reverse function. you put a probability in the function and
recieve the distribution b of a special a.
I wanted to have a function FInv' to pass on s for all a and all b to
FInv(s,a,b) in order to find out, which probability fits to which a and b.

And I couln't pass on a and b so easily, I got the error: "In 1:i :
numerical expression has 4 elements: only the first used "
I think, the reason is, that R expects a number, but receives a list, and
that produces the error.

I tried 
>x<-c(1:10)
> FooInv<-function(s) foreach(i=1:10)%do%sapply(x,FInv,s=s,k=i) and that
> works:
> FooInv(0.4946433)
F(s = 0.4946433 ,m = 5 ,k = 3 ) equals s; [[1]]

Foreach is a for-loop, and sapply matches FInv for every element of the list
x.

But now another problem occured:
Obviously R gets anywhere a NULL-pointer, because the full output is:
F(s = 0.4946433 ,m = 5 ,k = 3 ) equals s; [[1]]
[[1]][[1]]
NULL

[[1]][[2]]
NULL

[[1]][[3]]
NULL

[[1]][[4]]
NULL

[[1]][[5]]
NULL
...
in every loop.

Do you or someone else know how  I can get rid of the NULL-outputs?

if this problem is solved, I have all I need in order to calculate the
distribution and its inverse function :-)

Thanks in advance,
Narua 



--
View this message in context: http://r.789695.n4.nabble.com/Problem-with-apply-list-to-function-numerical-expression-has-4-elements-only-the-first-used-tp4707588p4707612.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Sun May 24 19:45:51 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 24 May 2015 10:45:51 -0700
Subject: [R] Problem with apply list to function: numerical expression
	has 4 elements: only the first used
In-Reply-To: <1432474509383-4707612.post@n4.nabble.com>
References: <1432419672494-4707588.post@n4.nabble.com>
	<33D76D77E9AC4B438DA38B348ED6890D14442668@EMAIL.ktkdom.pte.hu>
	<1432474509383-4707612.post@n4.nabble.com>
Message-ID: <D753637A-BD4E-497C-B26C-153837AF2E0C@comcast.net>


> On May 24, 2015, at 6:35 AM, Narua <maria.mi8 at gmx.de> wrote:
> 
> Dear kd,
> thanks for your fast reply 
> hm, I thougth, F is normally the abbrevation, but in R FALSE represents
> "false"?
> Anyway, your function works and I got the idea to work with "apply" 
> 
> I had actually a little more complicate functions (put I posted in the forum
> first an easier example):
> f<-function(a,b)((1/(sum(sqrt(1:a))))*sqrt(b))
> F<-function(a,b)(sum(f(a,1:b)))
>> F(5,3)
> [1] 0.4946433
>> F(5,5)
> [1] 1
> therefore, 0.4946433 is the distribution of b=3 with a=5 Elements.
> 
> FInv<-function(s,a,b) if(isTRUE(all.equal(F(a,b),s, tolerance=0.00001)))
> cat("F(",s,",",a,",",b,") equals s; ") else cat("F(",a,",",b,") does not
> equal to s; ")
> FInv is the reverse function. you put a probability in the function and
> recieve the distribution b of a special a.
> I wanted to have a function FInv' to pass on s for all a and all b to
> FInv(s,a,b) in order to find out, which probability fits to which a and b.
> 
> And I couln't pass on a and b so easily, I got the error: "In 1:i :
> numerical expression has 4 elements: only the first used "
> I think, the reason is, that R expects a number, but receives a list, and
> that produces the error.

No. First off, it?s not an error but rather a warning. Here?s the easiest way of seeng what produces it>

> m=1:4
> 1:m
[1] 1
Warning message:
In 1:m : numerical expression has 4 elements: only the first used

? David.
> 

> 
> I tried 
>> x<-c(1:10)
>> FooInv<-function(s) foreach(i=1:10)%do%sapply(x,FInv,s=s,k=i) and that
>> works:
>> FooInv(0.4946433)
> F(s = 0.4946433 ,m = 5 ,k = 3 ) equals s; [[1]]
> 
> Foreach is a for-loop, and sapply matches FInv for every element of the list
> x.
> 
> But now another problem occured:
> Obviously R gets anywhere a NULL-pointer, because the full output is:
> F(s = 0.4946433 ,m = 5 ,k = 3 ) equals s; [[1]]
> [[1]][[1]]
> NULL
> 
> [[1]][[2]]
> NULL
> 
> [[1]][[3]]
> NULL
> 
> [[1]][[4]]
> NULL
> 
> [[1]][[5]]
> NULL
> ...
> in every loop.
> 
> Do you or someone else know how  I can get rid of the NULL-outputs?
> 
> if this problem is solved, I have all I need in order to calculate the
> distribution and its inverse function :-)
> 
> Thanks in advance,
> Narua 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Problem-with-apply-list-to-function-numerical-expression-has-4-elements-only-the-first-used-tp4707588p4707612.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From faradj.g at gmail.com  Sun May 24 20:28:49 2015
From: faradj.g at gmail.com (Faradj Koliev)
Date: Sun, 24 May 2015 20:28:49 +0200
Subject: [R] Online courses in Event History / Survival analysis with R
Message-ID: <20C9D4DA-1ADB-469D-9E27-A7377E2A6271@gmail.com>

Dear all, 

I am looking for some online courses ? paid or free ? in survival analysis with R. Perhaps you can recommend some interesting online courses? 

Best, 
Faradj Koliev

From curtisburkhalter at gmail.com  Sun May 24 23:34:13 2015
From: curtisburkhalter at gmail.com (Curtis Burkhalter)
Date: Sun, 24 May 2015 15:34:13 -0600
Subject: [R] problem with duplicated function
Message-ID: <CAJmwvUaKJaNQMHLwkRKJK2nAkmfgO121NRn3yB3BAkuuyaw6mQ@mail.gmail.com>

Hello everyone,

I have two very large dataframes (~1 million rows x 5 columns), of which
two of the columns are lat/long coordinates. The names of the dataframes
are 'data07' and 'data 08'. Data08 has a few more sampling points than data
07 so I want to subset data08 so that it has the same number of data points
as data07 using the unique lat/long coordinates.

Here are the associated data structures:

*str(data07)*
'data.frame':   969109 obs. of  5 variables:
 $ cell    : int  710228 715545 720690 720824 695611 700490 700626 705371
705507 710363 ...
 $ prN     : int  288 276 286 304 258 257 264 272 286 316 ...
 $ Location: Factor w/ 32 levels " ","Blacks_Fork",..: 24 24 24 24 24 24 24
24 24 24 ...
 $ Xcor    : num  -111 -111 -111 -111 -111 ...
 $ Ycor    : num  41.7 41.7 41.7 41.7 41.8 ...

*str(data08)*
'data.frame':   969810 obs. of  5 variables:
 $ cell    : int  705528 710321 710456 715677 720762 720896 699953 700635
700771 705664 ...
 $ prN     : int  293 281 299 278 276 266 282 255 287 280 ...
 $ Location: Factor w/ 31 levels "Blacks_Fork",..: 23 23 23 23 23 23 23 23
23 23 ...
 $ Xcor    : num  -111 -111 -111 -111 -111 ...
 $ Ycor    : num  41.8 41.7 41.7 41.7 41.7 ...

I've tried using the following code to accomplish my problem:

tt <- rbind(data07, data08)

tt.dup <- duplicated(tt[,4:5]) # marks all duplicate rows in data08 from
last 2 cols                                            #that correspond to
the lat/long

tt.dup <- tt.dup[-seq_len(nrow(data07))] # remove all data07 entries (first
n)

test=ddata08[tt.dup, ] # index only TRUE/duplicated elements from data08

When I run the code 'tt.dup' is FALSE for all entries, which I know isn't
true.

Here's a small subset of the data so that you can see exactly where there
are duplicates

data07[1:10,]
                 cell prN Location     Xcor    Ycor
710229 *710228 288     Sage -111.044 41.7403*
715546 *715545 276     Sage -111.044 41.7245*
720691 *720690 286     Sage -111.044 41.7131*
720825 *720824 304     Sage -111.044 41.7109*
695612 695611 258     Sage -111.043 41.7766
700491 700490 257     Sage -111.043 41.7653
700627 700626 264     Sage -111.043 41.7630
705372 705371 272     Sage -111.043 41.7517
705508 705507 286     Sage -111.043 41.7495
710364 710363 316     Sage -111.043 41.7381

 data08[1:10,]
                 cell prN Location     Xcor    Ycor
705529 705528 293     Sage -111.044 41.7517
710322 *710321 281     Sage -111.044 41.7403*
710457 710456 299     Sage -111.044 41.7381
715678 *715677 278     Sage -111.044 41.7245*
720763 *720762 276     Sage -111.044 41.7131*
720897 *720896 266     Sage -111.044 41.7109*
699954 699953 282     Sage -111.043 41.7767
700636 700635 255     Sage -111.043 41.7653
700772 700771 287     Sage -111.043 41.7631
705665 705664 280     Sage -111.043 41.7495


If anyone has any suggestions as to where I might be going wrong I'd
greatly appreciate it.

Thank you




-- 
Curtis Burkhalter
Postdoctoral Research Associate, Audubon Rockies

https://sites.google.com/site/curtisburkhalter/

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sun May 24 23:55:43 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 24 May 2015 14:55:43 -0700
Subject: [R] problem with duplicated function
In-Reply-To: <CAJmwvUaKJaNQMHLwkRKJK2nAkmfgO121NRn3yB3BAkuuyaw6mQ@mail.gmail.com>
References: <CAJmwvUaKJaNQMHLwkRKJK2nAkmfgO121NRn3yB3BAkuuyaw6mQ@mail.gmail.com>
Message-ID: <CACk-te3_yBRaZuLQ3bpOCrQ5Qim0_uC5xwCUVE+Ng6126Ta7CA@mail.gmail.com>

I have NOT looked at your code in detail -- I might have if you had
used dput() to make available small subsets of your data frames that
exhibited the problems. However, the following, from ?duplicated,
sounds like it may be relevant:

"When used on a data frame with more than one column, or an array or
matrix when comparing dimensions of length greater than one, this
tests for identity of character representations. This will catch
people who unwisely rely on exact equality of floating-point numbers!
"

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, May 24, 2015 at 2:34 PM, Curtis Burkhalter
<curtisburkhalter at gmail.com> wrote:
> Hello everyone,
>
> I have two very large dataframes (~1 million rows x 5 columns), of which
> two of the columns are lat/long coordinates. The names of the dataframes
> are 'data07' and 'data 08'. Data08 has a few more sampling points than data
> 07 so I want to subset data08 so that it has the same number of data points
> as data07 using the unique lat/long coordinates.
>
> Here are the associated data structures:
>
> *str(data07)*
> 'data.frame':   969109 obs. of  5 variables:
>  $ cell    : int  710228 715545 720690 720824 695611 700490 700626 705371
> 705507 710363 ...
>  $ prN     : int  288 276 286 304 258 257 264 272 286 316 ...
>  $ Location: Factor w/ 32 levels " ","Blacks_Fork",..: 24 24 24 24 24 24 24
> 24 24 24 ...
>  $ Xcor    : num  -111 -111 -111 -111 -111 ...
>  $ Ycor    : num  41.7 41.7 41.7 41.7 41.8 ...
>
> *str(data08)*
> 'data.frame':   969810 obs. of  5 variables:
>  $ cell    : int  705528 710321 710456 715677 720762 720896 699953 700635
> 700771 705664 ...
>  $ prN     : int  293 281 299 278 276 266 282 255 287 280 ...
>  $ Location: Factor w/ 31 levels "Blacks_Fork",..: 23 23 23 23 23 23 23 23
> 23 23 ...
>  $ Xcor    : num  -111 -111 -111 -111 -111 ...
>  $ Ycor    : num  41.8 41.7 41.7 41.7 41.7 ...
>
> I've tried using the following code to accomplish my problem:
>
> tt <- rbind(data07, data08)
>
> tt.dup <- duplicated(tt[,4:5]) # marks all duplicate rows in data08 from
> last 2 cols                                            #that correspond to
> the lat/long
>
> tt.dup <- tt.dup[-seq_len(nrow(data07))] # remove all data07 entries (first
> n)
>
> test=ddata08[tt.dup, ] # index only TRUE/duplicated elements from data08
>
> When I run the code 'tt.dup' is FALSE for all entries, which I know isn't
> true.
>
> Here's a small subset of the data so that you can see exactly where there
> are duplicates
>
> data07[1:10,]
>                  cell prN Location     Xcor    Ycor
> 710229 *710228 288     Sage -111.044 41.7403*
> 715546 *715545 276     Sage -111.044 41.7245*
> 720691 *720690 286     Sage -111.044 41.7131*
> 720825 *720824 304     Sage -111.044 41.7109*
> 695612 695611 258     Sage -111.043 41.7766
> 700491 700490 257     Sage -111.043 41.7653
> 700627 700626 264     Sage -111.043 41.7630
> 705372 705371 272     Sage -111.043 41.7517
> 705508 705507 286     Sage -111.043 41.7495
> 710364 710363 316     Sage -111.043 41.7381
>
>  data08[1:10,]
>                  cell prN Location     Xcor    Ycor
> 705529 705528 293     Sage -111.044 41.7517
> 710322 *710321 281     Sage -111.044 41.7403*
> 710457 710456 299     Sage -111.044 41.7381
> 715678 *715677 278     Sage -111.044 41.7245*
> 720763 *720762 276     Sage -111.044 41.7131*
> 720897 *720896 266     Sage -111.044 41.7109*
> 699954 699953 282     Sage -111.043 41.7767
> 700636 700635 255     Sage -111.043 41.7653
> 700772 700771 287     Sage -111.043 41.7631
> 705665 705664 280     Sage -111.043 41.7495
>
>
> If anyone has any suggestions as to where I might be going wrong I'd
> greatly appreciate it.
>
> Thank you
>
>
>
>
> --
> Curtis Burkhalter
> Postdoctoral Research Associate, Audubon Rockies
>
> https://sites.google.com/site/curtisburkhalter/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon May 25 00:12:14 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 24 May 2015 15:12:14 -0700
Subject: [R] problem with duplicated function
In-Reply-To: <CAJmwvUaKJaNQMHLwkRKJK2nAkmfgO121NRn3yB3BAkuuyaw6mQ@mail.gmail.com>
References: <CAJmwvUaKJaNQMHLwkRKJK2nAkmfgO121NRn3yB3BAkuuyaw6mQ@mail.gmail.com>
Message-ID: <B77B3CB3-BC2F-4A41-8E18-E195E6404F07@dcn.davis.CA.us>

You are going wrong in a few places: posting using HTML format, not using dput to share your data sample, and comparing floating point numbers for equality.

HTML email is stripped to plain text on this list so we don't see what you see. In addition, HTML formatting corrupts code, so we cannot even run it.

The dput function is highly recommended for making reproducible examples. [1]

FAQ 7.31 warns against expecting floating point numbers that appear the same when printed to actually be equal. This advice actually applies to all programming languages.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 24, 2015 2:34:13 PM PDT, Curtis Burkhalter <curtisburkhalter at gmail.com> wrote:
>Hello everyone,
>
>I have two very large dataframes (~1 million rows x 5 columns), of
>which
>two of the columns are lat/long coordinates. The names of the
>dataframes
>are 'data07' and 'data 08'. Data08 has a few more sampling points than
>data
>07 so I want to subset data08 so that it has the same number of data
>points
>as data07 using the unique lat/long coordinates.
>
>Here are the associated data structures:
>
>*str(data07)*
>'data.frame':   969109 obs. of  5 variables:
>$ cell    : int  710228 715545 720690 720824 695611 700490 700626
>705371
>705507 710363 ...
> $ prN     : int  288 276 286 304 258 257 264 272 286 316 ...
>$ Location: Factor w/ 32 levels " ","Blacks_Fork",..: 24 24 24 24 24 24
>24
>24 24 24 ...
> $ Xcor    : num  -111 -111 -111 -111 -111 ...
> $ Ycor    : num  41.7 41.7 41.7 41.7 41.8 ...
>
>*str(data08)*
>'data.frame':   969810 obs. of  5 variables:
>$ cell    : int  705528 710321 710456 715677 720762 720896 699953
>700635
>700771 705664 ...
> $ prN     : int  293 281 299 278 276 266 282 255 287 280 ...
>$ Location: Factor w/ 31 levels "Blacks_Fork",..: 23 23 23 23 23 23 23
>23
>23 23 ...
> $ Xcor    : num  -111 -111 -111 -111 -111 ...
> $ Ycor    : num  41.8 41.7 41.7 41.7 41.7 ...
>
>I've tried using the following code to accomplish my problem:
>
>tt <- rbind(data07, data08)
>
>tt.dup <- duplicated(tt[,4:5]) # marks all duplicate rows in data08
>from
>last 2 cols                                            #that correspond
>to
>the lat/long
>
>tt.dup <- tt.dup[-seq_len(nrow(data07))] # remove all data07 entries
>(first
>n)
>
>test=ddata08[tt.dup, ] # index only TRUE/duplicated elements from
>data08
>
>When I run the code 'tt.dup' is FALSE for all entries, which I know
>isn't
>true.
>
>Here's a small subset of the data so that you can see exactly where
>there
>are duplicates
>
>data07[1:10,]
>                 cell prN Location     Xcor    Ycor
>710229 *710228 288     Sage -111.044 41.7403*
>715546 *715545 276     Sage -111.044 41.7245*
>720691 *720690 286     Sage -111.044 41.7131*
>720825 *720824 304     Sage -111.044 41.7109*
>695612 695611 258     Sage -111.043 41.7766
>700491 700490 257     Sage -111.043 41.7653
>700627 700626 264     Sage -111.043 41.7630
>705372 705371 272     Sage -111.043 41.7517
>705508 705507 286     Sage -111.043 41.7495
>710364 710363 316     Sage -111.043 41.7381
>
> data08[1:10,]
>                 cell prN Location     Xcor    Ycor
>705529 705528 293     Sage -111.044 41.7517
>710322 *710321 281     Sage -111.044 41.7403*
>710457 710456 299     Sage -111.044 41.7381
>715678 *715677 278     Sage -111.044 41.7245*
>720763 *720762 276     Sage -111.044 41.7131*
>720897 *720896 266     Sage -111.044 41.7109*
>699954 699953 282     Sage -111.043 41.7767
>700636 700635 255     Sage -111.043 41.7653
>700772 700771 287     Sage -111.043 41.7631
>705665 705664 280     Sage -111.043 41.7495
>
>
>If anyone has any suggestions as to where I might be going wrong I'd
>greatly appreciate it.
>
>Thank you


From r.turner at auckland.ac.nz  Mon May 25 00:35:56 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 25 May 2015 10:35:56 +1200
Subject: [R] problem with duplicated function
In-Reply-To: <CAJmwvUaKJaNQMHLwkRKJK2nAkmfgO121NRn3yB3BAkuuyaw6mQ@mail.gmail.com>
References: <CAJmwvUaKJaNQMHLwkRKJK2nAkmfgO121NRn3yB3BAkuuyaw6mQ@mail.gmail.com>
Message-ID: <5562524C.9050808@auckland.ac.nz>

On 25/05/15 09:34, Curtis Burkhalter wrote:
> Hello everyone,
>
> I have two very large dataframes (~1 million rows x 5 columns), of which
> two of the columns are lat/long coordinates. The names of the dataframes
> are 'data07' and 'data 08'. Data08 has a few more sampling points than data
> 07 so I want to subset data08 so that it has the same number of data points
> as data07 using the unique lat/long coordinates.
>
> Here are the associated data structures:
>
> *str(data07)*
> 'data.frame':   969109 obs. of  5 variables:
>   $ cell    : int  710228 715545 720690 720824 695611 700490 700626 705371
> 705507 710363 ...
>   $ prN     : int  288 276 286 304 258 257 264 272 286 316 ...
>   $ Location: Factor w/ 32 levels " ","Blacks_Fork",..: 24 24 24 24 24 24 24
> 24 24 24 ...
>   $ Xcor    : num  -111 -111 -111 -111 -111 ...
>   $ Ycor    : num  41.7 41.7 41.7 41.7 41.8 ...
>
> *str(data08)*
> 'data.frame':   969810 obs. of  5 variables:
>   $ cell    : int  705528 710321 710456 715677 720762 720896 699953 700635
> 700771 705664 ...
>   $ prN     : int  293 281 299 278 276 266 282 255 287 280 ...
>   $ Location: Factor w/ 31 levels "Blacks_Fork",..: 23 23 23 23 23 23 23 23
> 23 23 ...
>   $ Xcor    : num  -111 -111 -111 -111 -111 ...
>   $ Ycor    : num  41.8 41.7 41.7 41.7 41.7 ...
>
> I've tried using the following code to accomplish my problem:
>
> tt <- rbind(data07, data08)
>
> tt.dup <- duplicated(tt[,4:5]) # marks all duplicate rows in data08 from
> last 2 cols                                            #that correspond to
> the lat/long


I get tt.dup to be:

>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE
> [13] FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE

>
> tt.dup <- tt.dup[-seq_len(nrow(data07))] # remove all data07 entries (first
> n)

This just throws away the first 10 entries of tt.dup, leaving

>  [1] FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE

>
> test=ddata08[tt.dup, ] # index only TRUE/duplicated elements from data08
        ^

This leaves the c(2,4,5,6,8,10) entries of data08.
>
> When I run the code 'tt.dup' is FALSE for all entries, which I know isn't
> true.

Only 4 of the entries of tt.dup are FALSE; 6 are TRUE.  I don't 
understand why you think that they are all FALSE.

Perhaps your subsets do not accurately reflect the actual nature of your 
data.

cheers,

Rolf Turner

>
> Here's a small subset of the data so that you can see exactly where there
> are duplicates
>
> data07[1:10,]
>                   cell prN Location     Xcor    Ycor
> 710229 *710228 288     Sage -111.044 41.7403*
> 715546 *715545 276     Sage -111.044 41.7245*
> 720691 *720690 286     Sage -111.044 41.7131*
> 720825 *720824 304     Sage -111.044 41.7109*
> 695612 695611 258     Sage -111.043 41.7766
> 700491 700490 257     Sage -111.043 41.7653
> 700627 700626 264     Sage -111.043 41.7630
> 705372 705371 272     Sage -111.043 41.7517
> 705508 705507 286     Sage -111.043 41.7495
> 710364 710363 316     Sage -111.043 41.7381
>
>   data08[1:10,]
>                   cell prN Location     Xcor    Ycor
> 705529 705528 293     Sage -111.044 41.7517
> 710322 *710321 281     Sage -111.044 41.7403*
> 710457 710456 299     Sage -111.044 41.7381
> 715678 *715677 278     Sage -111.044 41.7245*
> 720763 *720762 276     Sage -111.044 41.7131*
> 720897 *720896 266     Sage -111.044 41.7109*
> 699954 699953 282     Sage -111.043 41.7767
> 700636 700635 255     Sage -111.043 41.7653
> 700772 700771 287     Sage -111.043 41.7631
> 705665 705664 280     Sage -111.043 41.7495
>
>
> If anyone has any suggestions as to where I might be going wrong I'd
> greatly appreciate it.
>
> Thank you
>
>
>
>


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From glennmschultz at me.com  Mon May 25 03:27:53 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Mon, 25 May 2015 01:27:53 +0000 (GMT)
Subject: [R] Viewport help
Message-ID: <d2474c43-b628-4f1d-a043-6fe7bcca6150@me.com>

Hello All,

I have a function which outputs graphically the results of a pass-through OAS analysis. ?The viewport is 2x2. ?The idea is to leave a small margin at the top and enter a title with something like the following.?

Bond Lab Pass Through OAS?
Bond Id: foo at bond.id
OAS : foo at OAS

I am a little lost on the viewport and can't quite get to the last step. ?The function is below and the code I have question about is in red.

Glenn

The function is below - The code I have a question about is in red
#' OAS Analaysis of Pass Though MBS
#'?
#' Function calls BondLab PassThroughOAS and plots the results
#' copyright Bond Lab Technologies, Inc 2015
#' @importFrom BondLab PassThroughOAS
#' @param bond.id a character string the bond id
#' @param trade.date a character string the trade date
#' @param settlement.date a character string the settlement date
#' @param original.balance a numeric value the original balance
#' @param price a numeric value the price
#' @param sigma a numeric the **annualized** volatility. ?The volatilty assumption assumes
#' a trading year of 252 days
#' @export
PassThrough.OAS <- function(bond.id = character,
? ? ? ? ? ? ? ? ? ? ? ? ? ? trade.date = character,
? ? ? ? ? ? ? ? ? ? ? ? ? ? settlement.date = character,
? ? ? ? ? ? ? ? ? ? ? ? ? ? original.balance = numeric(),
? ? ? ? ? ? ? ? ? ? ? ? ? ? price = numeric(),
? ? ? ? ? ? ? ? ? ? ? ? ? ? sigma = numeric(),
? ? ? ? ? ? ? ? ? ? ? ? ? ? paths = numeric()){
? set.seed = 100
? sigma = sigma/sqrt(trading.days)
? OAS.Analysis <- PassThroughOAS(bond.id = bond.id,?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?trade.date = trade.date,?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?settlement.date = settlement.date,?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?original.bal = original.balance,
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?price = price, ?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?sigma = sigma,?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?paths = paths,?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?PrepaymentAssumption = "MODEL")
??
? # price distribution
? OAS.Price <- data.frame(OAS.Analysis at PriceDist)
? OAS.Price <- data.frame(cbind(OAS.Price, seq(1: length(OAS.Price))))
? colnames(OAS.Price) <- c("value", "count")

??
? price.dist <- ggplot(OAS.Price, aes(x = value )) +
? ? geom_density(fill = "#56B4E9", colour = "#56B4E9", alpha = .6) +
? ? geom_histogram(aes(y =..density..), color = "lightgrey", fill = "#0072B2", bindwidth = .01) +
? ? theme_minimal() +
? ? #scale_x_continuous(breaks = seq(80,120, 5)) +
? ? labs(title = "Price Distribution") +
? ? ylab("Density")+
? ? xlab("Path Price") +
? ? theme(panel.grid.major = element_line(size = .25, color = "grey")) +
? ? theme(axis.text = element_text(size = 15)) +
? ? theme(axis.title = element_text(size = 20)) +?
? ? theme(legend.position = "none")
??
? # modified duration distribution
? OAS.Mdur <- data.frame(OAS.Analysis at PathModDur)
? OAS.Mdur <- data.frame(cbind(OAS.Mdur, seq(1:length(OAS.Mdur))))
? colnames(OAS.Mdur) <- c("value", "count")

??
? Mdur.dist <- ggplot(OAS.Mdur, aes(x = value )) +
? ? geom_density(fill = "#56B4E9", colour = "#56B4E9", alpha = .6) +
? ? geom_histogram(aes(y =..density..), color = "lightgrey", fill = "#0072B2", bindwidth = .01) +
? ? theme_minimal() +
? ? #scale_x_continuous(breaks = seq(80,120, 5)) +
? ? labs(title = "Mod. Duration Distribution") +
? ? ylab("Density")+
? ? xlab("Path Mod. Duration") +
? ? theme(panel.grid.major = element_line(size = .25, color = "grey")) +
? ? theme(axis.text = element_text(size = 15)) +
? ? theme(axis.title = element_text(size = 20)) +?
? ? theme(legend.position = "none")
??
? ? layout <- grid.layout(nrow = 2, ncol = 2,
? ? ? ? ? ? ? ? ? ? ? ? ? widths = unit(c(2,2), c("null", "null")),
? ? ? ? ? ? ? ? ? ? ? ? ? heights = unit(c(.3, 2), c("null", "null")))
??
? ? vplayout <- function(...){
? ? grid.newpage()
? ? pushViewport(viewport(layout = layout))}
??
? ? subplot <- function(x, y) {viewport(layout.pos.row = x,
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? layout.pos.col = y)}
? ? mmplot <- function(a, b) {
? ? vplayout()
? ? print(a, vp = subplot(2, 1))
? ? print(b, vp = subplot(2, 2))
? }
??
? OAS <- mmplot(price.dist, Mdur.dist)
? plot(OAS)
??
}?

From ivonemfigueiredo at gmail.com  Mon May 25 09:02:52 2015
From: ivonemfigueiredo at gmail.com (Ivone Figueiredo)
Date: Mon, 25 May 2015 08:02:52 +0100
Subject: [R] Problem on estimating fish species
Message-ID: <CAGPy+s8TtXibKBFOn7gkEUGnOwhA_WTGmZz1JQ3K=PzzsFWr=w@mail.gmail.com>

Hi
I am trying to estimate the proportion of species landed by species. But I
always get error messages.

Can you please help me? Thanks Ivone

 I am trying to use R2Winbugs to

skate.4 <- bugs (skateA.data, inits=skatesA.inits, skateA.parameters,
model1.file,   n.chains=1, n.iter=50,          bugs.directory="C:/Program
Files (x86)/OpenBUGS/OpenBUGS323/", program=c("OpenBUGS"), debug=TRUE)

skateA.data <- list(n=length(y_A), y_A =y_A, Species_A= Species_A,
n.species_A=n.species_A)

skateA.parameters <- c ("mu","b.species", "sigma.species",  "sigma.epsilon")

skatesA.inits <- function (){
  list (mu=rnorm(0.5),  b.species=rnorm(0.2), sigma.species=runif(1),
        sigma.epsilon=runif(1))}


The model is

model {
  for (i in 1:n){
    y[i] ~ dpois (lambda[i])
    lambda[i] <- exp(mu+b.species[Species_A[i]] + epsilon[i])
    epsilon[i]  ~ dnorm (0, tau.epsilon)
  }
  mu ~ dnorm (0, .0001)
  mu.adj <- mu +  mean(b.species[])
  tau.epsilon <- pow(sigma.epsilon, -2)
  sigma.epsilon ~ dunif (0, 100)
  b.species[1] <-0

  for (j in 2:n.species_A){
    b.species[j] ~ dnorm (0, tau.species)
  }
  tau.species <- pow(sigma.species, -2)
  sigma.species ~ dunif (0, 100)
}

 the data are:

n  <-  54

n.species_A <- 3





y <- c(6.80,10.20 124.20, 6.350, 0.00,63.20, 0.00, 0.00,86.850, 3.60,
2.550,60.950,0.00, 0.00,87.20, 2.60, 0.00,58.10, 3.360,34.990,62.140, 0.00,
0.00,63.90,0.00, 0.00 112.660, 0.00, 0.00 121.630, 0.00, 3.580 101.770,
0.00, 0.00 158.00,0.00, 0.00 123.279, 0.00, 0.00 124.255, 3.170,
0.00,27.840, 5.930, 0.00 174.435,0.00, 0.00,53.525, 0.00, 4.858,68.945)



Species <- c("RJC?, ?RJE?, ?RJH?, ?RJC?, ?RJE?, ?RJH?, ?RJC?, ?RJE?, ?RJH?,
?RJC?, ?RJE?, ?RJH?, ?RJC?, ?RJE?, ?RJH?, ?RJC", "RJE?, ?RJH?, ?RJC?,
?RJE?, ?RJH?, ?RJC?, ?RJE?, ?RJH?, ?RJC?, ?RJE?, ?RJH?, ?RJC?, ?RJE?,
?RJH?, ?RJC?, ?RJE", "RJH?, ?RJC?, ?RJE?, ?RJH?, ?RJC?, ?RJE?, ?RJH?,
?RJC?, ?RJE?, ?RJH?, ?RJC?, ?RJE?, ?RJH?, ?RJC?, ?RJE?, ?RJH", "RJC?,
?RJE?, ?RJH?, ?RJC?, ?RJE?, ?RJH")

	[[alternative HTML version deleted]]


From wsq at szu.edu.cn  Mon May 25 04:25:32 2015
From: wsq at szu.edu.cn (wsq at szu.edu.cn)
Date: Mon, 25 May 2015 10:25:32 +0800
Subject: [R] How to extract the standardized residuals tests from the
	summary report of fGarch
Message-ID: <2015052510253245706712@szu.edu.cn>

I am using the Rmarkdown to produce a  html slides automatically, and I want to known
How to extract the standardized residuals tests section from the summary report?


Here are the R-code:


>library("fGarch") 
>N = 200
>x.vec = as.vector(garchSim(garchSpec(rseed = 1985), n = N)[,1])
>fit=garchFit(~ garch(1,1), data = x.vec, trace = FALSE)


> summary(fit)


Title:
 GARCH Modelling 


Call:
 garchFit(formula = ~garch(1, 1), data = x.vec, trace = FALSE) 


Mean and Variance Equation:
 data ~ garch(1, 1)
<environment: 0x000000002df6b330>
 [data = x.vec]


Conditional Distribution:
 norm 


Coefficient(s):
        mu       omega      alpha1       beta1  
3.5418e-05  1.0819e-06  8.8855e-02  8.1200e-01  


Std. Errors:
 based on Hessian 


Error Analysis:
        Estimate  Std. Error  t value Pr(>|t|)    
mu     3.542e-05   2.183e-04    0.162    0.871    
omega  1.082e-06   1.051e-06    1.030    0.303    
alpha1 8.885e-02   5.450e-02    1.630    0.103    
beta1  8.120e-01   1.242e-01    6.538 6.25e-11 ***
---
Signif. codes:  0 ??***?? 0.001 ??**?? 0.01 ??*?? 0.05 ??.?? 0.1 ?? ?? 1


Log Likelihood:
 861.9494    normalized:  4.309747 


Description:
 Mon May 25 09:10:52 2015 by user: WENSQ 




Standardised Residuals Tests:
                                Statistic p-Value  
 Jarque-Bera Test   R    Chi^2  1.114092  0.5728988
 Shapiro-Wilk Test  R    W      0.9932317 0.4911085
 Ljung-Box Test     R    Q(10)  7.303961  0.6964713
 Ljung-Box Test     R    Q(15)  8.712829  0.8920477
 Ljung-Box Test     R    Q(20)  9.766984  0.972203 
 Ljung-Box Test     R^2  Q(10)  11.88455  0.2928573
 Ljung-Box Test     R^2  Q(15)  14.93927  0.4558006
 Ljung-Box Test     R^2  Q(20)  20.08937  0.4523516
 LM Arch Test       R    TR^2   11.57234  0.480607 


Information Criterion Statistics:
      AIC       BIC       SIC      HQIC 
-8.579494 -8.513527 -8.580273 -8.552798 




Dr.  WEN SONG-QIAO
SHENZHEN UNIVERSITY
SHENZHEN,CHINA
Email??wsq at szu.edu.cn
	[[alternative HTML version deleted]]


From gabriel.weindel at gmail.com  Mon May 25 11:55:04 2015
From: gabriel.weindel at gmail.com (Gabriel WEINDEL)
Date: Mon, 25 May 2015 11:55:04 +0200
Subject: [R] Vincentizing Reaction Time data in R
In-Reply-To: <255099FE2FC.00000513jrkrideau@inbox.com>
References: <1a175f8ee5e.00000c3ajrkrideau@inbox.com>
	<555c5e3d.6090103@gmail.com>
	<255099FE2FC.00000513jrkrideau@inbox.com>
Message-ID: <5562F178.1080702@gmail.com>

Hi John,

Sorry for the response delay.

I found a way to do it in a slight different way : 
http://www.nicebread.de/comparing-all-quantiles-of-two-distributions-simultaneously/

You're right with the application. I just put some comments in your post.

Thank you for your time. I will now use the quantile comparison for my 
statistic test, and perform vincentization later for my thesis result. 
If I create something useful I will share it on this topic.

Gabriel

> Do I  understand the idea behind 'vincentizing' reaction times?
> I don't want to work through the Ratcliff, (1979)  paper unless I must.
>
> Let's say we have a subject , s1, with 50 rt scores.
> We sort the scores from high to low (or low to high , it makes no difference) then we split the 50 scores into quantiles (let's say deciles) and calculate the mean/decile?
>
> Repeat for each subject.  We now have the 'vincentized' means.
>
> That's it?

Yes, the point is to get rid of the shape blindness of, for example 
ANOVA sample mean, by using quantiles to also reduce influence of outliers.
>
> Example, of what I understand for just for one subject (s1)
>
> # install plyr package if not already installed
> install.packages("plyr")
> #=======================================
>
> library(plyr)
>
> # create some sciency looking sample data
> rtmatter   <- c (seq(0.50 , 1.50, 0.01), seq(0.55, 1.55,  0.01) )
> str(rtmatter)  # verify it looks sciencey
>
> # create one subject
> s1  <-  sample(rtmatter, 50, replace = TRUE)
>
> # calculate 'vincentized' means for s1
> s1  <-  sort(s1)
> c1  <-  cut(s1, 10, right = TRUE)

You cut the distribution in 10, the use of vincentization fix the cut to 
n ? bins. So a formula should be used to compute it for each set of data

> ss1  <-  data.frame(c1,  s1)
> vince1   <-   ddply(ss1, .(c1), summarize, decile.mean = mean(s1) )
> vince1
>
That's right too.
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: gabriel.weindel at gmail.com
>> Sent: Thu, 21 May 2015 17:50:02 +0200
>> To: jrkrideau at inbox.com, yishinlin001 at gmail.com, gunter.berton at gene.com,
>> djnordlund at frontier.com
>> Subject: Re: [R] Vincentizing Reaction Time data in R
>>
>> Bert : Thank you for your advice, it would be a little bit difficult to
>> do it for my master thesis but, if I want to go further with a PhD
>> thesis (and I do want), I would probably follow your advice and get in
>> touch with a statistician.
>>
>> Yishin : Thank you very much for the references, I will definitively
>> read the papers you quote. I'm already a little bit aware of the misuses
>> possible with the vincentization in particular thanks to the paper of
>> Rouder and Speckman (2004) and it seems to fit with my design. No
>> problem if you want to keep the code but I have to tell you that it's
>> our first semester using R and the teacher surely didn't thought that we
>> will run out of available code with our experiment. Like John guessed
>> the purpose of the course was to give a first view of R to get over the
>> temptation of SPSS, my bad if I want to avoid biased statistics like
>> sample mean ANOVA's on RT.
>>
>> Dan : Thank you for your tip, this sure will help but I'm quiet at the
>> beginning of my R skills so I hardly trust myself to do it on my own,
>> but I can sure give it a try.
>>
>> John : I had the same assumption but my research director warned me that
>> I might run out of time for my first presentation by doing so but fairly
>> enough for my master thesis. But again like I said to Dan I'm quiet
>> concerned by my actual R skill.
>>
>> Anyway I have to say that I'm really glad to see how much help you can
>> get by using the r-help mailing-list.
>>
>> Regards,
>> Gabriel
>>
>> Le 21/05/2015 15:52, John Kane a ?crit :
>>> In line
>>>
>>> John Kane
>>> Kingston ON Canada
>>>
>>>
>>>> -----Original Message-----
>>>> From: yishinlin001 at gmail.com
>>>> Sent: Thu, 21 May 2015 10:13:54 +0800
>>>> To: gabriel.weindel at gmail.com
>>>> Subject: Re: [R] Vincentizing Reaction Time data in R
>>>>
>>>> On Wed, 20 May 2015 18:13:17 +0800,
>>>> Hi Gabriel,
>>>>
>>>> As far as I could recall, there isn't an R package that has explicitly
>>>> implemented "vincentization". You definitively can find some code
>>>> segments/functions that have implemented "vincentize" on the web. But
>>>> you
>>>> should verify if they do exactly what you wish to do.  If you could
>>>> look
>>>> at the question from percentile/quantle perspective, it would not take
>>>> you too much time to realise that they are similar.  I would suggest
>>>> you
>>>> to read, as John Kane suggested, Prof. Ratcliff's 1979 paper.  Another
>>>> paper that may be very helpful is Prof van Zandt's 2000 RT paper.
>>>>
>>>> However, you should be aware that there are some different
>>>> implementation
>>>> of "vincentization", and it is debatable, if not problematic, to use
>>>> it,
>>>> rather than other more general quantile methods. It would help you to
>>>> understand not only how to do vincentization, but also why/why not if
>>>> you
>>>> could read papers from Jeff Rouder's as well as from Heathcote's and
>>>> Brown's lab.
>>>>
>>>> Sorry that I hesitate to give you the code, because this looks like
>>>> part
>>>> of your course works.  It would be more rewarding for you, if you could
>>>> figure out by yourself.
>>>>
>>>> Yishin
>>>>
>>> While I agree the exercise is likely to be a good learning experience I
>>> don't see this as the equivalent of course work.
>>>
>>> If Gabriel (the OP) was tasked with implementing  "vincentization" in R
>>> then, strictly speaking it is course work but if I understand him the
>>> requirement is to do his work in R rather than Minitab.  If such a
>>> function existed in an existing R package than he could have simply
>>> plugged in the numbers et voil?, done.
>>>
>>> The tenor of the question did not suggest this and it would require the
>>> stats instructor to know that there was no  "vincentization" function
>>> anywhere among the, what, a thousand or so packages? And if the OP was
>>> working on his own data as part of the course then the instructor might
>>> have little or no idea of exactly what functions are needed
>>>
>>> The course  strikes me more as an effort to get psychologists away from
>>> SPSS which often seems to be the only software package anyone knows.
>>>
>>>
>>>> Gabriel WEINDEL wrote:
>>>>>
>>>>> Dear all,
>>>>>
>>>>> For my master thesis, I'm currently working in cognitive neuroscience
>>>>> on executive control through measurement of reaction time and I need
>>>>> to get my data 'vincentized' with an exclusive use of R set by my
>>>>> statistic teacher for a test purpose, for this reason I can't use the
>>>>> python code the lab team usually uses.
>>>>> Despite a dozen hours of research I couldn't find any package or
>>>>> R-code which would allow the use of vincentization, that's why I'm
>>>>> querying help on the R forum.
>>>>>
>>>>> So has anyone ever used vincentization in R ?
>>>>>
>>>>> Best regards,
>>>>>
>>>>> --
>>>>> Gabriel Weindel
>>>>> Master student in Neuropsychology - Aix-Marseille University (France)
>>>>>
>>>
>>> ____________________________________________________________
>>> Can't remember your password? Do you need a strong and secure password?
>>> Use Password manager! It stores your passwords & protects your account.
>>> Check it out at http://mysecurelogon.com/manager
>>>
>>>
>
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
> Visit http://www.inbox.com/photosharing to find out more!
>
>


From shivibhatia at ymail.com  Mon May 25 14:19:46 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Mon, 25 May 2015 05:19:46 -0700 (PDT)
Subject: [R] Issues with loading csv file
Message-ID: <1432556386134-4707637.post@n4.nabble.com>

HI All,

I am trying to load an CSV file into the R project. the code for the same
is:
mydata<- read.csv("Jan-May Data.csv", header=TRUE)

however with this I am getting the below error message:
/*Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'Jan-May Data.csv': No such file or directory*/

I am under the impression that R automatically pulls the data from the
working directory and we do not have to add the location where the file is
saved. Please let me know if my understanding is correct and help on the
error as well.

Please note the csv file is already saved in the WD.
Thank you, Shivi



--
View this message in context: http://r.789695.n4.nabble.com/Issues-with-loading-csv-file-tp4707637.html
Sent from the R help mailing list archive at Nabble.com.


From kevin.thorpe at utoronto.ca  Mon May 25 14:45:26 2015
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Mon, 25 May 2015 08:45:26 -0400
Subject: [R] Issues with loading csv file
In-Reply-To: <1432556386134-4707637.post@n4.nabble.com>
References: <1432556386134-4707637.post@n4.nabble.com>
Message-ID: <55631966.5000006@utoronto.ca>

On 05/25/2015 08:19 AM, Shivi82 wrote:
> HI All,
>
> I am trying to load an CSV file into the R project. the code for the same
> is:
> mydata<- read.csv("Jan-May Data.csv", header=TRUE)
>
> however with this I am getting the below error message:
> /*Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") :
>    cannot open file 'Jan-May Data.csv': No such file or directory*/
>
> I am under the impression that R automatically pulls the data from the
> working directory and we do not have to add the location where the file is
> saved. Please let me know if my understanding is correct and help on the
> error as well.
>
> Please note the csv file is already saved in the WD.
> Thank you, Shivi
>

The error message suggests that R is not finding the file. Are you sure 
it is in R's working directory? Try explicitly setting the working 
directory to the directory (folder) where your CSV file is. There is a 
menu option for this.

Kevin

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From glennmschultz at me.com  Mon May 25 15:04:53 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Mon, 25 May 2015 13:04:53 +0000 (GMT)
Subject: [R] data for pass though OAS viewport question
Message-ID: <d50dd6c5-6129-4f2b-8214-6adc561a91e4@me.com>

Attached is dput of the pass through OAS?

From gunter.berton at gene.com  Mon May 25 16:12:49 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 25 May 2015 07:12:49 -0700
Subject: [R] data for pass though OAS viewport question
In-Reply-To: <d50dd6c5-6129-4f2b-8214-6adc561a91e4@me.com>
References: <d50dd6c5-6129-4f2b-8214-6adc561a91e4@me.com>
Message-ID: <CACk-te1oJdiZQYh+Hjrp-E_REM1c=ZW4eF3kwmgmB9Q8cPmpWQ@mail.gmail.com>

No it ain't. Most attachments don't make it through. dput() it
directly into the email body -- that's the point: it's plain text.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, May 25, 2015 at 6:04 AM, Glenn Schultz <glennmschultz at me.com> wrote:
> Attached is dput of the pass through OAS
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From robertsonburns at btinternet.com  Mon May 25 17:23:36 2015
From: robertsonburns at btinternet.com (J Robertson-Burns)
Date: Mon, 25 May 2015 16:23:36 +0100
Subject: [R] Issues with loading csv file
In-Reply-To: <1432556386134-4707637.post@n4.nabble.com>
References: <1432556386134-4707637.post@n4.nabble.com>
Message-ID: <55633E78.5090105@btinternet.com>

I suggest two commands to diagnose
the problem:

getwd()  # show the working directory of R

This is navigation tool #17.
http://www.burns-stat.com/r-navigation-tools/

list.files()  # show the files in the working directory

You can copy and paste file names to avoid
typing mistakes.  (Not that I've ever made any.)

Pat

On 25/05/2015 13:19, Shivi82 wrote:
> HI All,
>
> I am trying to load an CSV file into the R project. the code for the same
> is:
> mydata<- read.csv("Jan-May Data.csv", header=TRUE)
>
> however with this I am getting the below error message:
> /*Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") :
>    cannot open file 'Jan-May Data.csv': No such file or directory*/
>
> I am under the impression that R automatically pulls the data from the
> working directory and we do not have to add the location where the file is
> saved. Please let me know if my understanding is correct and help on the
> error as well.
>
> Please note the csv file is already saved in the WD.
> Thank you, Shivi
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Issues-with-loading-csv-file-tp4707637.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkrideau at inbox.com  Mon May 25 17:31:19 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 25 May 2015 07:31:19 -0800
Subject: [R] Vincentizing Reaction Time data in R
In-Reply-To: <5562F178.1080702@gmail.com>
References: <255099fe2fc.00000513jrkrideau@inbox.com>
	<1a175f8ee5e.00000c3ajrkrideau@inbox.com> <555c5e3d.6090103@gmail.com>
Message-ID: <4D3ED455915.00000513jrkrideau@inbox.com>


Thanks Gabriel, 
That new method you found looks interesting even if it is a long way from anything I am likely to be doing.

Re my code below.  It looks like  vincentization is actually straight-forward.  I used bins = 10 since it was a convenient number.  I imagine if one was to actually turn this into a function it would not be that hard to come up with some formula to calculate bin size although statisticians may be wincing when they read that last remark.

I played a little more with the idea and it really looks pretty easy to  vincentizatise a data.frame.  

John Kane
Kingston ON Canada


> -----Original Message-----
> From: gabriel.weindel at gmail.com
> Sent: Mon, 25 May 2015 11:55:04 +0200
> To: jrkrideau at inbox.com
> Subject: Re: [R] Vincentizing Reaction Time data in R
> 
> Hi John,
> 
> Sorry for the response delay.
> 
> I found a way to do it in a slight different way :
> http://www.nicebread.de/comparing-all-quantiles-of-two-distributions-simultaneously/
> 
> You're right with the application. I just put some comments in your post.
> 
> Thank you for your time. I will now use the quantile comparison for my
> statistic test, and perform vincentization later for my thesis result.
> If I create something useful I will share it on this topic.
> 
> Gabriel
> 
>> Do I  understand the idea behind 'vincentizing' reaction times?
>> I don't want to work through the Ratcliff, (1979)  paper unless I must.
>> 
>> Let's say we have a subject , s1, with 50 rt scores.
>> We sort the scores from high to low (or low to high , it makes no
>> difference) then we split the 50 scores into quantiles (let's say
>> deciles) and calculate the mean/decile?
>> 
>> Repeat for each subject.  We now have the 'vincentized' means.
>> 
>> That's it?
> 
> Yes, the point is to get rid of the shape blindness of, for example
> ANOVA sample mean, by using quantiles to also reduce influence of
> outliers.
>> 
>> Example, of what I understand for just for one subject (s1)
>> 
>> # install plyr package if not already installed
>> install.packages("plyr")
>> #=======================================
>> 
>> library(plyr)
>> 
>> # create some sciency looking sample data
>> rtmatter   <- c (seq(0.50 , 1.50, 0.01), seq(0.55, 1.55,  0.01) )
>> str(rtmatter)  # verify it looks sciencey
>> 
>> # create one subject
>> s1  <-  sample(rtmatter, 50, replace = TRUE)
>> 
>> # calculate 'vincentized' means for s1
>> s1  <-  sort(s1)
>> c1  <-  cut(s1, 10, right = TRUE)
> 
> You cut the distribution in 10, the use of vincentization fix the cut to
> n ? bins. So a formula should be used to compute it for each set of data
> 
>> ss1  <-  data.frame(c1,  s1)
>> vince1   <-   ddply(ss1, .(c1), summarize, decile.mean = mean(s1) )
>> vince1
>> 
> That's right too.
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: gabriel.weindel at gmail.com
>>> Sent: Thu, 21 May 2015 17:50:02 +0200
>>> To: jrkrideau at inbox.com, yishinlin001 at gmail.com,
>>> gunter.berton at gene.com,
>>> djnordlund at frontier.com
>>> Subject: Re: [R] Vincentizing Reaction Time data in R
>>> 
>>> Bert : Thank you for your advice, it would be a little bit difficult to
>>> do it for my master thesis but, if I want to go further with a PhD
>>> thesis (and I do want), I would probably follow your advice and get in
>>> touch with a statistician.
>>> 
>>> Yishin : Thank you very much for the references, I will definitively
>>> read the papers you quote. I'm already a little bit aware of the
>>> misuses
>>> possible with the vincentization in particular thanks to the paper of
>>> Rouder and Speckman (2004) and it seems to fit with my design. No
>>> problem if you want to keep the code but I have to tell you that it's
>>> our first semester using R and the teacher surely didn't thought that
>>> we
>>> will run out of available code with our experiment. Like John guessed
>>> the purpose of the course was to give a first view of R to get over the
>>> temptation of SPSS, my bad if I want to avoid biased statistics like
>>> sample mean ANOVA's on RT.
>>> 
>>> Dan : Thank you for your tip, this sure will help but I'm quiet at the
>>> beginning of my R skills so I hardly trust myself to do it on my own,
>>> but I can sure give it a try.
>>> 
>>> John : I had the same assumption but my research director warned me
>>> that
>>> I might run out of time for my first presentation by doing so but
>>> fairly
>>> enough for my master thesis. But again like I said to Dan I'm quiet
>>> concerned by my actual R skill.
>>> 
>>> Anyway I have to say that I'm really glad to see how much help you can
>>> get by using the r-help mailing-list.
>>> 
>>> Regards,
>>> Gabriel
>>> 
>>> Le 21/05/2015 15:52, John Kane a ?crit :
>>>> In line
>>>> 
>>>> John Kane
>>>> Kingston ON Canada
>>>> 
>>>> 
>>>>> -----Original Message-----
>>>>> From: yishinlin001 at gmail.com
>>>>> Sent: Thu, 21 May 2015 10:13:54 +0800
>>>>> To: gabriel.weindel at gmail.com
>>>>> Subject: Re: [R] Vincentizing Reaction Time data in R
>>>>> 
>>>>> On Wed, 20 May 2015 18:13:17 +0800,
>>>>> Hi Gabriel,
>>>>> 
>>>>> As far as I could recall, there isn't an R package that has
>>>>> explicitly
>>>>> implemented "vincentization". You definitively can find some code
>>>>> segments/functions that have implemented "vincentize" on the web. But
>>>>> you
>>>>> should verify if they do exactly what you wish to do.  If you could
>>>>> look
>>>>> at the question from percentile/quantle perspective, it would not
>>>>> take
>>>>> you too much time to realise that they are similar.  I would suggest
>>>>> you
>>>>> to read, as John Kane suggested, Prof. Ratcliff's 1979 paper.
>>>>> Another
>>>>> paper that may be very helpful is Prof van Zandt's 2000 RT paper.
>>>>> 
>>>>> However, you should be aware that there are some different
>>>>> implementation
>>>>> of "vincentization", and it is debatable, if not problematic, to use
>>>>> it,
>>>>> rather than other more general quantile methods. It would help you to
>>>>> understand not only how to do vincentization, but also why/why not if
>>>>> you
>>>>> could read papers from Jeff Rouder's as well as from Heathcote's and
>>>>> Brown's lab.
>>>>> 
>>>>> Sorry that I hesitate to give you the code, because this looks like
>>>>> part
>>>>> of your course works.  It would be more rewarding for you, if you
>>>>> could
>>>>> figure out by yourself.
>>>>> 
>>>>> Yishin
>>>>> 
>>>> While I agree the exercise is likely to be a good learning experience
>>>> I
>>>> don't see this as the equivalent of course work.
>>>> 
>>>> If Gabriel (the OP) was tasked with implementing  "vincentization" in
>>>> R
>>>> then, strictly speaking it is course work but if I understand him the
>>>> requirement is to do his work in R rather than Minitab.  If such a
>>>> function existed in an existing R package than he could have simply
>>>> plugged in the numbers et voil?, done.
>>>> 
>>>> The tenor of the question did not suggest this and it would require
>>>> the
>>>> stats instructor to know that there was no  "vincentization" function
>>>> anywhere among the, what, a thousand or so packages? And if the OP was
>>>> working on his own data as part of the course then the instructor
>>>> might
>>>> have little or no idea of exactly what functions are needed
>>>> 
>>>> The course  strikes me more as an effort to get psychologists away
>>>> from
>>>> SPSS which often seems to be the only software package anyone knows.
>>>> 
>>>> 
>>>>> Gabriel WEINDEL wrote:
>>>>>> 
>>>>>> Dear all,
>>>>>> 
>>>>>> For my master thesis, I'm currently working in cognitive
>>>>>> neuroscience
>>>>>> on executive control through measurement of reaction time and I need
>>>>>> to get my data 'vincentized' with an exclusive use of R set by my
>>>>>> statistic teacher for a test purpose, for this reason I can't use
>>>>>> the
>>>>>> python code the lab team usually uses.
>>>>>> Despite a dozen hours of research I couldn't find any package or
>>>>>> R-code which would allow the use of vincentization, that's why I'm
>>>>>> querying help on the R forum.
>>>>>> 
>>>>>> So has anyone ever used vincentization in R ?
>>>>>> 
>>>>>> Best regards,
>>>>>> 
>>>>>> --
>>>>>> Gabriel Weindel
>>>>>> Master student in Neuropsychology - Aix-Marseille University
>>>>>> (France)
>>>>>> 
>>>> 
>>>> ____________________________________________________________
>>>> Can't remember your password? Do you need a strong and secure
>>>> password?
>>>> Use Password manager! It stores your passwords & protects your
>>>> account.
>>>> Check it out at http://mysecurelogon.com/manager
>>>> 
>>>> 
>> 
>> ____________________________________________________________
>> FREE ONLINE PHOTOSHARING - Share your photos online with your friends
>> and family!
>> Visit http://www.inbox.com/photosharing to find out more!
>> 
>> 
>

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From lists at dewey.myzen.co.uk  Mon May 25 17:39:09 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 25 May 2015 16:39:09 +0100
Subject: [R] Issues with loading csv file
In-Reply-To: <1432556386134-4707637.post@n4.nabble.com>
References: <1432556386134-4707637.post@n4.nabble.com>
Message-ID: <5563421D.1040701@dewey.myzen.co.uk>

You could try list.files() which will tell you which files R thinks are 
in your working directory.

On 25/05/2015 13:19, Shivi82 wrote:
> HI All,
>
> I am trying to load an CSV file into the R project. the code for the same
> is:
> mydata<- read.csv("Jan-May Data.csv", header=TRUE)
>
> however with this I am getting the below error message:
> /*Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") :
>    cannot open file 'Jan-May Data.csv': No such file or directory*/
>
> I am under the impression that R automatically pulls the data from the
> working directory and we do not have to add the location where the file is
> saved. Please let me know if my understanding is correct and help on the
> error as well.
>
> Please note the csv file is already saved in the WD.
> Thank you, Shivi
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Issues-with-loading-csv-file-tp4707637.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From mruiz at cenipalma.org  Mon May 25 17:56:32 2015
From: mruiz at cenipalma.org (Miller Andres Ruiz Sanchez)
Date: Mon, 25 May 2015 10:56:32 -0500
Subject: [R] Trouble with SPI package
Message-ID: <CAPd+fAsQ7g6vr_gn4WOHWa5r8_fc4FEvdOo--qKotQPkxd-h0w@mail.gmail.com>

Hello,

I write to ask you about an error that I have when I use the script below.
I'm working with monthly  precipitation  data for the period between 1990
and 1998.

I really thanks your help.

_______________________________________________________________

> require(SPEI)
> require(spi)
> require(sm)

> dir()
[1] "IndexScript.R"  "PradoCorre.txt" "spi.txt"

> Prado=read.table("PradoCorre.txt", head=TRUE, dec=".")

> write.table(Prado,file="PradoCorre.txt",quote=FALSE,row.names=TRUE)

> spi(3,"PradoCorre.txt",1990,1998)
Error en data[i, ] : sub?ndice fuera de  los l?mites


> Prado
   Months X1990  X1991 X1992 X1993 X1994 X1995 X1996 X1997 X1998
1     Jan   0.0   0.00   0.0  22.3   0.0   0.0  15.4   0.0   0.0
2     Feb   0.0  11.00   0.0   0.0   0.0   0.0   0.0   2.5   0.0
3     Mar   0.0   8.70   0.0  13.1   0.3   0.4  34.3   0.0   3.8
4     Apr  52.0  32.20  96.8  70.0  61.4 251.0  21.0  31.0  18.0
5     May 130.0  34.11 249.1 348.4 211.0 141.5 144.8  36.3 314.3
6     Jun 102.0 142.20 188.5  70.6  24.1 116.9  90.6 159.4 126.9
7     Jul  86.0  98.00  80.6  89.0  39.9 228.0 234.0  26.2  27.8
8     Aug 135.0  82.78  76.3 173.5 245.9 370.9  44.2  51.8 162.4
9     Sep 132.0 103.30 216.4 214.3 120.0 177.7  84.3 132.3 403.9
10    Oct 432.0 245.60 180.6 253.2 101.2 356.1 241.9  92.8 117.8
11    Nov  42.6  24.03  48.3  64.3 155.1  15.0 120.0  14.2   0.0
12    Dec 109.3   1.60   0.0  26.0   0.0   9.3   0.0   0.0   0.0
>


________________________________________________________________




Cordialmente

*Miller Ruiz*
Ingeniero Agr?nomo
Auxiliar de Investigaci?n
?rea de Geom?tica
Cenipalma - Zona Norte
Cel: 3164807973
Fundaci?n - Magdalena

-- 
[image: Fedepalma] 
<http://www.google.com/url?q=http%3A%2F%2Fwww.fedepalma.org&sa=D&sntz=1&usg=AFrqEzcV3Ok1p8dfn_mAY_mbeKqx9TcBUA>
  
<http://www.google.com/url?q=http%3A%2F%2Fwww.cenipalma.org%2F&sa=D&sntz=1&usg=AFrqEzfg7qal8zogbo9Aq6drmj-iPne9eQ>
El presente mensaje de datos como sus archivos adjuntos se consideran 
informaci?n confidencial y de valor estrat?gico para la Federaci?n; motivo 
por el cual s?lo podr?  ser empleada por su exclusivo destinatario, seg?n 
las indicaciones impartidas por el remitente y dada la naturaleza de la 
misma. En consecuencia, cualquier uso, explotaci?n, reproducci?n,
modificaci?n, distribuci?n, puesta a disposici?n entre otras posibilidades 
diferentes a las autorizadas, se entender?n expresamente prohibidas. Si 
Usted No es el destinatario, deber  eliminar completamente el mensaje y, en
lo posible, notificar al remitente del mismo. Es responsabilidad del 
destinatario de este mensaje comprobar que el mensaje de datos y sus 
adjuntos no representan un riesgo inform?tico para su propio sistema.

La Federaci?n ha tomado las medidas adecuadas para tratar de prevenir la 
transmisi?n de virus y programas malignos, no obstante, no se hace 
responsable por su eventual transmisi?n por este conducto. La Federaci?n 
 no acepta responsabilidad alguna por eventuales da?os o alteraciones
derivadas de la recepci?n o uso del presente mensaje.

-- 

<http://www.google.com/url?q=http%3A%2F%2Fwww.cenipalma.org%2F&sa=D&sntz=1&usg=AFrqEzfg7qal8zogbo9Aq6drmj-iPne9eQ>
El presente mensaje de datos como sus archivos adjuntos se consideran 
informaci?n confidencial y de valor estrat?gico para la Federaci?n; motivo 
por el cual s?lo podr?  ser empleada por su exclusivo destinatario, seg?n 
las indicaciones impartidas por el remitente y dada la naturaleza de la 
misma. En consecuencia, cualquier uso, explotaci?n, reproducci?n,
modificaci?n, distribuci?n, puesta a disposici?n entre otras posibilidades 
diferentes a las autorizadas, se entender?n expresamente prohibidas. Si 
Usted No es el destinatario, deber  eliminar completamente el mensaje y, en
lo posible, notificar al remitente del mismo. Es responsabilidad del 
destinatario de este mensaje comprobar que el mensaje de datos y sus 
adjuntos no representan un riesgo inform?tico para su propio sistema.

La Federaci?n ha tomado las medidas adecuadas para tratar de prevenir la 
transmisi?n de virus y programas malignos, no obstante, no se hace 
responsable por su eventual transmisi?n por este conducto. La Federaci?n 
 no acepta responsabilidad alguna por eventuales da?os o alteraciones
derivadas de la recepci?n o uso del presente mensaje.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon May 25 19:56:04 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 25 May 2015 10:56:04 -0700
Subject: [R] Trouble with SPI package
In-Reply-To: <CAPd+fAsQ7g6vr_gn4WOHWa5r8_fc4FEvdOo--qKotQPkxd-h0w@mail.gmail.com>
References: <CAPd+fAsQ7g6vr_gn4WOHWa5r8_fc4FEvdOo--qKotQPkxd-h0w@mail.gmail.com>
Message-ID: <8BBB8A32-ABF5-4053-8029-21BC4B95D072@dcn.davis.CA.us>

Why are you overwriting your input file after you read it in? This seems likely to end up corrupting your input data if you make a mistake.

For instance, when you read a file into a data frame that has pure numeric values in the header line, the default behaviour is to convert those numeric values to valid labels, which means that they must start with a letter (in this case X). 

I have never used the spi function, but its help file example for the filename argument suggests that the year numbers should not have letters in them. 

You should be able to use a text editor to repair your input file, and remove the line that overwrites it from your code.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 25, 2015 8:56:32 AM PDT, Miller Andres Ruiz Sanchez <mruiz at cenipalma.org> wrote:
>Hello,
>
>I write to ask you about an error that I have when I use the script
>below.
>I'm working with monthly  precipitation  data for the period between
>1990
>and 1998.
>
>I really thanks your help.
>
>_______________________________________________________________
>
>> require(SPEI)
>> require(spi)
>> require(sm)
>
>> dir()
>[1] "IndexScript.R"  "PradoCorre.txt" "spi.txt"
>
>> Prado=read.table("PradoCorre.txt", head=TRUE, dec=".")
>
>> write.table(Prado,file="PradoCorre.txt",quote=FALSE,row.names=TRUE)
>
>> spi(3,"PradoCorre.txt",1990,1998)
>Error en data[i, ] : sub?ndice fuera de  los l?mites
>
>
>> Prado
>   Months X1990  X1991 X1992 X1993 X1994 X1995 X1996 X1997 X1998
>1     Jan   0.0   0.00   0.0  22.3   0.0   0.0  15.4   0.0   0.0
>2     Feb   0.0  11.00   0.0   0.0   0.0   0.0   0.0   2.5   0.0
>3     Mar   0.0   8.70   0.0  13.1   0.3   0.4  34.3   0.0   3.8
>4     Apr  52.0  32.20  96.8  70.0  61.4 251.0  21.0  31.0  18.0
>5     May 130.0  34.11 249.1 348.4 211.0 141.5 144.8  36.3 314.3
>6     Jun 102.0 142.20 188.5  70.6  24.1 116.9  90.6 159.4 126.9
>7     Jul  86.0  98.00  80.6  89.0  39.9 228.0 234.0  26.2  27.8
>8     Aug 135.0  82.78  76.3 173.5 245.9 370.9  44.2  51.8 162.4
>9     Sep 132.0 103.30 216.4 214.3 120.0 177.7  84.3 132.3 403.9
>10    Oct 432.0 245.60 180.6 253.2 101.2 356.1 241.9  92.8 117.8
>11    Nov  42.6  24.03  48.3  64.3 155.1  15.0 120.0  14.2   0.0
>12    Dec 109.3   1.60   0.0  26.0   0.0   9.3   0.0   0.0   0.0
>>
>
>
>________________________________________________________________
>
>
>
>
>Cordialmente
>
>*Miller Ruiz*
>Ingeniero Agr?nomo
>Auxiliar de Investigaci?n
>?rea de Geom?tica
>Cenipalma - Zona Norte
>Cel: 3164807973
>Fundaci?n - Magdalena
>
>-- 
>[image: Fedepalma] 
><http://www.google.com/url?q=http%3A%2F%2Fwww.fedepalma.org&sa=D&sntz=1&usg=AFrqEzcV3Ok1p8dfn_mAY_mbeKqx9TcBUA>
>  
><http://www.google.com/url?q=http%3A%2F%2Fwww.cenipalma.org%2F&sa=D&sntz=1&usg=AFrqEzfg7qal8zogbo9Aq6drmj-iPne9eQ>
>El presente mensaje de datos como sus archivos adjuntos se consideran 
>informaci?n confidencial y de valor estrat?gico para la Federaci?n;
>motivo 
>por el cual s?lo podr?  ser empleada por su exclusivo destinatario,
>seg?n 
>las indicaciones impartidas por el remitente y dada la naturaleza de la
>
>misma. En consecuencia, cualquier uso, explotaci?n, reproducci?n,
>modificaci?n, distribuci?n, puesta a disposici?n entre otras
>posibilidades 
>diferentes a las autorizadas, se entender?n expresamente prohibidas. Si
>
>Usted No es el destinatario, deber  eliminar completamente el mensaje
>y, en
>lo posible, notificar al remitente del mismo. Es responsabilidad del 
>destinatario de este mensaje comprobar que el mensaje de datos y sus 
>adjuntos no representan un riesgo inform?tico para su propio sistema.
>
>La Federaci?n ha tomado las medidas adecuadas para tratar de prevenir
>la 
>transmisi?n de virus y programas malignos, no obstante, no se hace 
>responsable por su eventual transmisi?n por este conducto. La
>Federaci?n 
> no acepta responsabilidad alguna por eventuales da?os o alteraciones
>derivadas de la recepci?n o uso del presente mensaje.
>
>-- 
>
><http://www.google.com/url?q=http%3A%2F%2Fwww.cenipalma.org%2F&sa=D&sntz=1&usg=AFrqEzfg7qal8zogbo9Aq6drmj-iPne9eQ>
>El presente mensaje de datos como sus archivos adjuntos se consideran 
>informaci?n confidencial y de valor estrat?gico para la Federaci?n;
>motivo 
>por el cual s?lo podr?  ser empleada por su exclusivo destinatario,
>seg?n 
>las indicaciones impartidas por el remitente y dada la naturaleza de la
>
>misma. En consecuencia, cualquier uso, explotaci?n, reproducci?n,
>modificaci?n, distribuci?n, puesta a disposici?n entre otras
>posibilidades 
>diferentes a las autorizadas, se entender?n expresamente prohibidas. Si
>
>Usted No es el destinatario, deber  eliminar completamente el mensaje
>y, en
>lo posible, notificar al remitente del mismo. Es responsabilidad del 
>destinatario de este mensaje comprobar que el mensaje de datos y sus 
>adjuntos no representan un riesgo inform?tico para su propio sistema.
>
>La Federaci?n ha tomado las medidas adecuadas para tratar de prevenir
>la 
>transmisi?n de virus y programas malignos, no obstante, no se hace 
>responsable por su eventual transmisi?n por este conducto. La
>Federaci?n 
> no acepta responsabilidad alguna por eventuales da?os o alteraciones
>derivadas de la recepci?n o uso del presente mensaje.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon May 25 19:58:39 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 25 May 2015 10:58:39 -0700
Subject: [R] How to extract the standardized residuals tests from the
	summary report of fGarch
In-Reply-To: <2015052510253245706712@szu.edu.cn>
References: <2015052510253245706712@szu.edu.cn>
Message-ID: <21A36B80-0D67-4C72-A93E-60BAFA0941F6@comcast.net>


> On May 24, 2015, at 7:25 PM, wsq at szu.edu.cn wrote:
> 
> I am using the Rmarkdown to produce a  html slides automatically, and I want to known
> How to extract the standardized residuals tests section from the summary report?
> 

Probbly the easiest way is with capture.output. I looked at the returned value from the summary method for that S4 object and it was NULL, so the function appears to simply be acting via side-effects of cat to the console. You could look at the code with:

showMethods(class="fGARCH", f="summary", includeDefs=TRUE)

? 
David.
> 
> Here are the R-code:
> 
> 
>> library("fGarch") 
>> N = 200
>> x.vec = as.vector(garchSim(garchSpec(rseed = 1985), n = N)[,1])
>> fit=garchFit(~ garch(1,1), data = x.vec, trace = FALSE)
> 
> 
>> summary(fit)
> 
> 
> Title:
> GARCH Modelling 
> 
> 
> Call:
> garchFit(formula = ~garch(1, 1), data = x.vec, trace = FALSE) 
> 
> 
> Mean and Variance Equation:
> data ~ garch(1, 1)
> <environment: 0x000000002df6b330>
> [data = x.vec]
> 
> 
> Conditional Distribution:
> norm 
> 
> 
> Coefficient(s):
>        mu       omega      alpha1       beta1  
> 3.5418e-05  1.0819e-06  8.8855e-02  8.1200e-01  
> 
> 
> Std. Errors:
> based on Hessian 
> 
> 
> Error Analysis:
>        Estimate  Std. Error  t value Pr(>|t|)    
> mu     3.542e-05   2.183e-04    0.162    0.871    
> omega  1.082e-06   1.051e-06    1.030    0.303    
> alpha1 8.885e-02   5.450e-02    1.630    0.103    
> beta1  8.120e-01   1.242e-01    6.538 6.25e-11 ***
> ---
> Signif. codes:  0 ??***?? 0.001 ??**?? 0.01 ??*?? 0.05 ??.?? 0.1 ?? ?? 1
> 
> 
> Log Likelihood:
> 861.9494    normalized:  4.309747 
> 
> 
> Description:
> Mon May 25 09:10:52 2015 by user: WENSQ 
> 
> 
> 
> 
> Standardised Residuals Tests:
>                                Statistic p-Value  
> Jarque-Bera Test   R    Chi^2  1.114092  0.5728988
> Shapiro-Wilk Test  R    W      0.9932317 0.4911085
> Ljung-Box Test     R    Q(10)  7.303961  0.6964713
> Ljung-Box Test     R    Q(15)  8.712829  0.8920477
> Ljung-Box Test     R    Q(20)  9.766984  0.972203 
> Ljung-Box Test     R^2  Q(10)  11.88455  0.2928573
> Ljung-Box Test     R^2  Q(15)  14.93927  0.4558006
> Ljung-Box Test     R^2  Q(20)  20.08937  0.4523516
> LM Arch Test       R    TR^2   11.57234  0.480607 
> 
> 
> Information Criterion Statistics:
>      AIC       BIC       SIC      HQIC 
> -8.579494 -8.513527 -8.580273 -8.552798 
> 
> 
> 
> 
> Dr.  WEN SONG-QIAO
> SHENZHEN UNIVERSITY
> SHENZHEN,CHINA
> Email??wsq at szu.edu.cn
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From nicholas.wray at ntlworld.com  Mon May 25 19:50:53 2015
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Mon, 25 May 2015 18:50:53 +0100
Subject: [R] Issues with loading csv file
In-Reply-To: <1432556386134-4707637.post@n4.nabble.com>
References: <1432556386134-4707637.post@n4.nabble.com>
Message-ID: <CALcakBYF4iCjSR3K8bY25g-jXds0ps_sVTWuQbWQqCNdyu6u=g@mail.gmail.com>

Something you could try is to put a small csv file into a location and set
the word to that and see whether it's finding it
eg
setwd("C:/Users/Shivi/Documents/")
open this file, stick a csv doc and see whether R will read it

Nick

On 25 May 2015 at 13:19, Shivi82 <shivibhatia at ymail.com> wrote:

> HI All,
>
> I am trying to load an CSV file into the R project. the code for the same
> is:
> mydata<- read.csv("Jan-May Data.csv", header=TRUE)
>
> however with this I am getting the below error message:
> /*Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") :
>   cannot open file 'Jan-May Data.csv': No such file or directory*/
>
> I am under the impression that R automatically pulls the data from the
> working directory and we do not have to add the location where the file is
> saved. Please let me know if my understanding is correct and help on the
> error as well.
>
> Please note the csv file is already saved in the WD.
> Thank you, Shivi
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Issues-with-loading-csv-file-tp4707637.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From g.rudge at bham.ac.uk  Mon May 25 21:28:55 2015
From: g.rudge at bham.ac.uk (gavinr)
Date: Mon, 25 May 2015 12:28:55 -0700 (PDT)
Subject: [R] run a calculation function over time fields,
 ordered and grouped by variables
Message-ID: <1432582135039-4707655.post@n4.nabble.com>

I?ve got some transit data relating to bus stops for a GIS data set.  Each
row represents one stop on a route.  For each record I have the start time
of the route, a sequence in which a bus stops, the time the bus arrives at
the first stop and the time taken to get to each of the stops from the last
one in the sequence.  Not all sequences of stops starts with the number 1,
some may start with a higher number.
I need to make a new variable which has the time the bus arrives at each
stop by using the start time from the stop with the lowest sequence number,
to populate all of the arrival times for each stop in each route. 

I have a very simple example below with just three routes and a few stops in
each.  My actual data set has a few million rows.  I've also created a
version of the data set I'm aiming to get.

There are two problems here.  Firstly getting the data into the correct
format to do the calculations with 
durations, and secondly running a function over the data set to obtain the
times.
It is the durations that are critical not the date, so using the POSIX
methods doesn?t really seem appropriate here.  Ultimately the times are
going to be used in a route solver in an ArcSDE geodatabase.  I tried to use
strptime to format my times, but could not get them into a data.frame as
presumably they are a list.  In this example I?ve left them as strings. 

Any help is much appreciated.

#create four columns with route id, stop sequence interval time and route
start time
ssq<-c(3,4,5,6,7,8,9,1,2,3,4,2,3,4,5,6,7,8)
tint<-c("00:00","00:12","00:03","00:06","00:09","00:02","00:04","00:00","00:08","00:10","00:10","00:00","00:02","00:04","00:08","00:02","00:01","00:01")
tst<-c(rep("18:20",7),rep("10:50",4),rep("16:15",7))
rtid<-c(rep("a",7),rep("b",4),rep("c",7))
df<-data.frame(cbind(ssq,tint,tst,rtid))
df      

#correct data set should look like this
tarr<-c("18:20","18:32","18:35","18:41","18:50","18:52","18:56","10:50","10:58","11:08","11:18","16:15","16:17","16:21","16:29","16:31","16:32","16:33")
df2<-cbind(df,tarr)
df2





--
View this message in context: http://r.789695.n4.nabble.com/run-a-calculation-function-over-time-fields-ordered-and-grouped-by-variables-tp4707655.html
Sent from the R help mailing list archive at Nabble.com.


From andrejfavia at ml1.net  Mon May 25 22:39:32 2015
From: andrejfavia at ml1.net (andrejfavia at ml1.net)
Date: Mon, 25 May 2015 16:39:32 -0400
Subject: [R] How do I move the horizontal axis in a plot so that it starts
 at the zero of the vertical axis?
Message-ID: <1432586372.2864381.277751097.35790984@webmail.messagingengine.com>

Greetings.

[1] How do I move the horizontal axis in a plot so that it starts at the
zero of the vertical axis? I tried using ylim=c(0, 2) but it doesn't
work. I'd also like to keep the "0.0" along the vertical axis and not
have it vanish.

[2] Also, how do I change the data points to five-pointed stars?

[3] Also, how do I know where threads posted to this email address
appear on the Nabble forum, so that I can post to it and have my posts
approved?


Example:

x <- c(-2.5, -1.3, 0.6, 0.8, 2.1)
y <- c(0.3, 1.9, 1.4, 0.7, 1.1)

plot(x, y, ylim=c(0, 2))


From drjimlemon at gmail.com  Mon May 25 23:42:16 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 26 May 2015 07:42:16 +1000
Subject: [R] How do I move the horizontal axis in a plot so that it
 starts at the zero of the vertical axis?
In-Reply-To: <1432586372.2864381.277751097.35790984@webmail.messagingengine.com>
References: <1432586372.2864381.277751097.35790984@webmail.messagingengine.com>
Message-ID: <CA+8X3fUrNU7KxtAiQvvNwebgDA+UsfGRW+nQzY0+vc+cYkfZNA@mail.gmail.com>

Hi andrejfavia,
You probably want:

plot(x,y,ylim=c(0,2),yaxs="i")

for question [1], Have a look at the ms.polygram and my.symbols help
pages in the TeachingDemos package for question [2] and I haven't got
a clue about question [3].

Jim


On Tue, May 26, 2015 at 6:39 AM,  <andrejfavia at ml1.net> wrote:
> Greetings.
>
> [1] How do I move the horizontal axis in a plot so that it starts at the
> zero of the vertical axis? I tried using ylim=c(0, 2) but it doesn't
> work. I'd also like to keep the "0.0" along the vertical axis and not
> have it vanish.
>
> [2] Also, how do I change the data points to five-pointed stars?
>
> [3] Also, how do I know where threads posted to this email address
> appear on the Nabble forum, so that I can post to it and have my posts
> approved?
>
>
> Example:
>
> x <- c(-2.5, -1.3, 0.6, 0.8, 2.1)
> y <- c(0.3, 1.9, 1.4, 0.7, 1.1)
>
> plot(x, y, ylim=c(0, 2))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue May 26 00:43:36 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 26 May 2015 08:43:36 +1000
Subject: [R] run a calculation function over time fields,
 ordered and grouped by variables
In-Reply-To: <1432582135039-4707655.post@n4.nabble.com>
References: <1432582135039-4707655.post@n4.nabble.com>
Message-ID: <CA+8X3fWCn-phaV9PPWv6shEHsSn9us3TnYdFGdJ1RVEaJ_e7Mg@mail.gmail.com>

Hi gavinr,
Perhaps this will do what you want.

add_HH_MM<-function(x) {
 t1bits<-strsplit(as.character(x$tst),":")
 t2bits<-strsplit(as.character(x$tint),":")
 hours<-as.numeric(lapply(t1bits,"[",1))+cumsum(as.numeric(lapply(t2bits,"[",1)))
 minutes<-as.numeric(lapply(t1bits,"[",2))+cumsum(as.numeric(lapply(t2bits,"[",2)))
 next_hour<-minutes > 59
 # adjust for running into the next hour
 minutes[next_hour]<-minutes[next_hour]-60
 hours[next_hour]<-hours[next_hour]+1
 # adjust for running into the next day
 hours[hours > 23]<-hours[hours > 23]-24
 return(paste(formatC(hours,width=2,flag=0),formatC(minutes,width=2,flag=0),sep=":"))
}

df$tarr<-unlist(by(df,df$rtid,add_HH_MM))

Jim


On Tue, May 26, 2015 at 5:28 AM, gavinr <g.rudge at bham.ac.uk> wrote:
> I?ve got some transit data relating to bus stops for a GIS data set.  Each
> row represents one stop on a route.  For each record I have the start time
> of the route, a sequence in which a bus stops, the time the bus arrives at
> the first stop and the time taken to get to each of the stops from the last
> one in the sequence.  Not all sequences of stops starts with the number 1,
> some may start with a higher number.
> I need to make a new variable which has the time the bus arrives at each
> stop by using the start time from the stop with the lowest sequence number,
> to populate all of the arrival times for each stop in each route.
>
> I have a very simple example below with just three routes and a few stops in
> each.  My actual data set has a few million rows.  I've also created a
> version of the data set I'm aiming to get.
>
> There are two problems here.  Firstly getting the data into the correct
> format to do the calculations with
> durations, and secondly running a function over the data set to obtain the
> times.
> It is the durations that are critical not the date, so using the POSIX
> methods doesn?t really seem appropriate here.  Ultimately the times are
> going to be used in a route solver in an ArcSDE geodatabase.  I tried to use
> strptime to format my times, but could not get them into a data.frame as
> presumably they are a list.  In this example I?ve left them as strings.
>
> Any help is much appreciated.
>
> #create four columns with route id, stop sequence interval time and route
> start time
> ssq<-c(3,4,5,6,7,8,9,1,2,3,4,2,3,4,5,6,7,8)
> tint<-c("00:00","00:12","00:03","00:06","00:09","00:02","00:04","00:00","00:08","00:10","00:10","00:00","00:02","00:04","00:08","00:02","00:01","00:01")
> tst<-c(rep("18:20",7),rep("10:50",4),rep("16:15",7))
> rtid<-c(rep("a",7),rep("b",4),rep("c",7))
> df<-data.frame(cbind(ssq,tint,tst,rtid))
> df
>
> #correct data set should look like this
> tarr<-c("18:20","18:32","18:35","18:41","18:50","18:52","18:56","10:50","10:58","11:08","11:18","16:15","16:17","16:21","16:29","16:31","16:32","16:33")
> df2<-cbind(df,tarr)
> df2
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/run-a-calculation-function-over-time-fields-ordered-and-grouped-by-variables-tp4707655.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From highstat at highstat.com  Tue May 26 00:52:50 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 25 May 2015 23:52:50 +0100
Subject: [R] Stats course Phillip Island Nature Parks, Australia
Message-ID: <5563A7C2.3050301@highstat.com>

Apologies for cross-posting


We would like to announce the following statistics course:

Course: Data exploration, regression, GLM & GAM with introduction to R
When: 14 - 18 September 2015
Where: Phillip Island Nature Parks, Australia
Course flyer: 
http://www.highstat.com/Courses/Flyers/Flyer2015_09PhillipIsland_regression_GLM_GAM.pdf
URL: http://www.highstat.com/statscourse.htm


Kind regards,

Alain Zuur



-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com


From jdnewmil at dcn.davis.ca.us  Tue May 26 02:04:17 2015
From: jdnewmil at dcn.davis.ca.us (jdnewmil)
Date: Mon, 25 May 2015 17:04:17 -0700
Subject: [R] run a calculation function over time fields,
 ordered and grouped by variables
In-Reply-To: <CA+8X3fWCn-phaV9PPWv6shEHsSn9us3TnYdFGdJ1RVEaJ_e7Mg@mail.gmail.com>
References: <1432582135039-4707655.post@n4.nabble.com>
	<CA+8X3fWCn-phaV9PPWv6shEHsSn9us3TnYdFGdJ1RVEaJ_e7Mg@mail.gmail.com>
Message-ID: <b2780bef82d491b1bc7de7b71688548a@omsoft.com>

Another way:

#create four columns with route id, stop sequence interval time and 
route start time
ssq <- c( 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 2, 3, 4, 5, 6, 7, 8 )
tint <- c( "00:00", "00:12", "00:03", "00:06", "00:09", "00:02", "00:04"
          , "00:00", "00:08", "00:10", "00:10"
          , "00:00", "00:02", "00:04", "00:08", "00:02", "00:01", "00:01" 
)
tst <- c( rep( "18:20", 7 )
         , rep( "10:50", 4 )
         , rep( "16:15", 7 ) )
rtid <- c( rep( "a", 7 )
          , rep( "b", 4 )
          , rep( "c", 7 ) )
# Don't use cbind to make data frames... it usually ends up
# forcing all columns to be character or factors
# Also, avoid using "df" as a variable name... it is the name of
# a function in base R, so that gets confusing fast
DF <- data.frame( ssq, tint, tst, rtid, stringsAsFactors=FALSE )
DF

#correct data set should look like this
tarr <- c( "18:20", "18:32", "18:35", "18:41", "18:50", "18:52", "18:56"
          , "10:50", "10:58", "11:08", "11:18"
          , "16:15", "16:17", "16:21", "16:29", "16:31", "16:32", "16:33" 
)
DF2  <- data.frame( DF, tarr, stringsAsFactors=FALSE )
DF2

library(dplyr)
DFs <- (   DF
        %>% group_by( rtid )
        %>% mutate( tarr
             = as.character(   as.POSIXct( tst, format="%H:%M", tz="GMT" 
)
                             + as.difftime(
                                 cumsum(
                                   as.numeric(
                                       as.difftime( tint, format="%H:%M" 
)
                                     , units="mins"
                                     )
                                   )
                                 , units="mins"
                                 )
                           , format="%H:%M" )
                  )
        %>% as.data.frame # removes grouping behavior from result
        )
identical( DFs, DF2 )

On 2015-05-25 15:43, Jim Lemon wrote:
> Hi gavinr,
> Perhaps this will do what you want.
> 
> add_HH_MM<-function(x) {
>  t1bits<-strsplit(as.character(x$tst),":")
>  t2bits<-strsplit(as.character(x$tint),":")
> 
> hours<-as.numeric(lapply(t1bits,"[",1))+cumsum(as.numeric(lapply(t2bits,"[",1)))
> 
> minutes<-as.numeric(lapply(t1bits,"[",2))+cumsum(as.numeric(lapply(t2bits,"[",2)))
>  next_hour<-minutes > 59
>  # adjust for running into the next hour
>  minutes[next_hour]<-minutes[next_hour]-60
>  hours[next_hour]<-hours[next_hour]+1
>  # adjust for running into the next day
>  hours[hours > 23]<-hours[hours > 23]-24
> 
> return(paste(formatC(hours,width=2,flag=0),formatC(minutes,width=2,flag=0),sep=":"))
> }
> 
> df$tarr<-unlist(by(df,df$rtid,add_HH_MM))
> 
> Jim
> 
> 
> On Tue, May 26, 2015 at 5:28 AM, gavinr <g.rudge at bham.ac.uk> wrote:
>> I?ve got some transit data relating to bus stops for a GIS data set.  
>> Each
>> row represents one stop on a route.  For each record I have the start 
>> time
>> of the route, a sequence in which a bus stops, the time the bus 
>> arrives at
>> the first stop and the time taken to get to each of the stops from the 
>> last
>> one in the sequence.  Not all sequences of stops starts with the 
>> number 1,
>> some may start with a higher number.
>> I need to make a new variable which has the time the bus arrives at 
>> each
>> stop by using the start time from the stop with the lowest sequence 
>> number,
>> to populate all of the arrival times for each stop in each route.
>> 
>> I have a very simple example below with just three routes and a few 
>> stops in
>> each.  My actual data set has a few million rows.  I've also created a
>> version of the data set I'm aiming to get.
>> 
>> There are two problems here.  Firstly getting the data into the 
>> correct
>> format to do the calculations with
>> durations, and secondly running a function over the data set to obtain 
>> the
>> times.
>> It is the durations that are critical not the date, so using the POSIX
>> methods doesn?t really seem appropriate here.  Ultimately the times 
>> are
>> going to be used in a route solver in an ArcSDE geodatabase.  I tried 
>> to use
>> strptime to format my times, but could not get them into a data.frame 
>> as
>> presumably they are a list.  In this example I?ve left them as 
>> strings.
>> 
>> Any help is much appreciated.
>> 
>> #create four columns with route id, stop sequence interval time and 
>> route
>> start time
>> ssq<-c(3,4,5,6,7,8,9,1,2,3,4,2,3,4,5,6,7,8)
>> tint<-c("00:00","00:12","00:03","00:06","00:09","00:02","00:04","00:00","00:08","00:10","00:10","00:00","00:02","00:04","00:08","00:02","00:01","00:01")
>> tst<-c(rep("18:20",7),rep("10:50",4),rep("16:15",7))
>> rtid<-c(rep("a",7),rep("b",4),rep("c",7))
>> df<-data.frame(cbind(ssq,tint,tst,rtid))
>> df
>> 
>> #correct data set should look like this
>> tarr<-c("18:20","18:32","18:35","18:41","18:50","18:52","18:56","10:50","10:58","11:08","11:18","16:15","16:17","16:21","16:29","16:31","16:32","16:33")
>> df2<-cbind(df,tarr)
>> df2
>> 
>> 
>> 
>> 
>> 
>> --
>> View this message in context: 
>> http://r.789695.n4.nabble.com/run-a-calculation-function-over-time-fields-ordered-and-grouped-by-variables-tp4707655.html
>> Sent from the R help mailing list archive at Nabble.com.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue May 26 02:18:31 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 25 May 2015 17:18:31 -0700
Subject: [R] How do I move the horizontal axis in a plot so that it
	starts at the zero of the vertical axis?
In-Reply-To: <1432586372.2864381.277751097.35790984@webmail.messagingengine.com>
References: <1432586372.2864381.277751097.35790984@webmail.messagingengine.com>
Message-ID: <4319DFD1-531D-41D2-BFAE-B93D7B6A67D0@dcn.davis.CA.us>

Regarding [3], you are better off not using Nabble for this EMAIL list at all... at best it does not encourage following the Posting Guide, and at worst it discourages people on the mailing list from answering your questions.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 25, 2015 1:39:32 PM PDT, andrejfavia at ml1.net wrote:
>Greetings.
>
>[1] How do I move the horizontal axis in a plot so that it starts at
>the
>zero of the vertical axis? I tried using ylim=c(0, 2) but it doesn't
>work. I'd also like to keep the "0.0" along the vertical axis and not
>have it vanish.
>
>[2] Also, how do I change the data points to five-pointed stars?
>
>[3] Also, how do I know where threads posted to this email address
>appear on the Nabble forum, so that I can post to it and have my posts
>approved?
>
>
>Example:
>
>x <- c(-2.5, -1.3, 0.6, 0.8, 2.1)
>y <- c(0.3, 1.9, 1.4, 0.7, 1.1)
>
>plot(x, y, ylim=c(0, 2))
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From glennmschultz at me.com  Tue May 26 02:24:01 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Tue, 26 May 2015 00:24:01 +0000 (GMT)
Subject: [R] R CMD methods and ggplot2 advice
Message-ID: <9057ac48-7cff-44b9-88a4-0c2fb24683b3@me.com>

Hello All,

I have two packages Bond Lab and the Companion to Investing in MBS. ?Bond Lab clears the check and I am working on the on.load() to copy a needed directory per Duncan Murdoch's advise to make Bond Lab CRAN-able. ?The companion passes with two notes. ?The output is below:

I get two notes (highlighted in red)

Not sure on this one as I tried to declare methods but I get another note methods declared but not used. ?The second note is related to ggplot2 they are variable passed to ggplot2 within a function. ?I am not sure why they appear in the R CMD check. ?If someone could point in the right direction to resolve these I would appreciate the advice. ?These are my last remaining two issues to make the packages pass CRAN aside from the on.load()

Best Regards,
Glenn

* checking dependencies in R code ... NOTE
package ?methods? is used but not declared


* checking R code for possible problems ... NOTE
CreditEnhancement: no visible binding for global variable ?Period?
CreditEnhancement: no visible binding for global variable ?Value?
CreditEnhancement: no visible binding for global variable ?Variable?
CreditEnhancement: no visible binding for global variable ?..density..?
PassThrough.OAS: no visible binding for global variable ?value?
PassThrough.OAS: no visible binding for global variable ?..density..?
PassThroughCashFlow: no visible binding for global variable ?Period?
PassThroughCashFlow: no visible binding for global variable ?value?
PassThroughCashFlow: no visible binding for global variable ?variable?
PlotMtgKeyRates: no visible binding for global variable ?Tenor?
PlotMtgKeyRates: no visible binding for global variable ?Duration?
PlotTermStructure: no visible binding for global variable ?value?
PlotTermStructure: no visible binding for global variable ?variable?
REMICOAS: no visible binding for global variable ?value?
REMICOAS: no visible binding for global variable ?..density..?
TotalReturn: no visible binding for global variable ?Scenario?
TotalReturn: no visible binding for global variable ?value?
TotalReturn: no visible binding for global variable ?variable?
TwistScenario: no visible binding for global variable ?Scenario?
TwistScenario: no visible binding for global variable ?Return?
ValuationFramework: no visible binding for global variable ?value?
ValuationFramework: no visible binding for global variable ?variable?

==> devtools::check()

Updating Companion2IMBS documentation
Loading Companion2IMBS
'/Library/Frameworks/R.framework/Resources/bin/R' --vanilla CMD build ?\
? '/Users/glennschultz/Companion to Investing in MBS' --no-resave-data ?\
? --no-manual?

* checking for file ?/Users/glennschultz/Companion to Investing in MBS/DESCRIPTION? ... OK
* preparing ?Companion2IMBS?:
* checking DESCRIPTION meta-information ... OK
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
Removed empty directory ?Companion2IMBS/inst?
Removed empty directory ?Companion2IMBS/test/testthat?
Removed empty directory ?Companion2IMBS/test?
* building ?Companion2IMBS_1.0.tar.gz?

'/Library/Frameworks/R.framework/Resources/bin/R' --vanilla CMD check ?\
? '/var/folders/tv/sq6gmnvs13j8jrhkt87f_zmc0000gn/T//RtmpOabREs/Companion2IMBS_1.0.tar.gz' ?\
? --timings?

* using log directory ?/Users/glennschultz/Companion2IMBS.Rcheck?
* using R version 3.0.3 (2014-03-06)
* using platform: x86_64-apple-darwin10.8.0 (64-bit)
* using session charset: UTF-8
* checking for file ?Companion2IMBS/DESCRIPTION? ... OK
* checking extension type ... Package
* this is package ?Companion2IMBS? version ?1.0?
* checking package namespace information ... OK
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking if there is a namespace ... OK
* checking for executable files ... OK
* checking for hidden files and directories ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking whether package ?Companion2IMBS? can be installed ... OK
* checking installed package size ... OK
* checking package directory ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... OK
* checking for left-over files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for non-ASCII characters ... OK
* checking R files for syntax errors ... OK
* checking whether the package can be loaded ... OK
* checking whether the package can be loaded with stated dependencies ... OK
* checking whether the package can be unloaded cleanly ... OK
* checking whether the namespace can be loaded with stated dependencies ... OK
* checking whether the namespace can be unloaded cleanly ... OK
* checking dependencies in R code ... NOTE
package ?methods? is used but not declared
See the information on DESCRIPTION files in the chapter ?Creating R
packages? of the ?Writing R Extensions? manual.
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... OK
* checking R code for possible problems ... NOTE
CreditEnhancement: no visible binding for global variable ?Period?
CreditEnhancement: no visible binding for global variable ?Value?
CreditEnhancement: no visible binding for global variable ?Variable?
CreditEnhancement: no visible binding for global variable ?..density..?
PassThrough.OAS: no visible binding for global variable ?value?
PassThrough.OAS: no visible binding for global variable ?..density..?
PassThroughCashFlow: no visible binding for global variable ?Period?
PassThroughCashFlow: no visible binding for global variable ?value?
PassThroughCashFlow: no visible binding for global variable ?variable?
PlotMtgKeyRates: no visible binding for global variable ?Tenor?
PlotMtgKeyRates: no visible binding for global variable ?Duration?
PlotTermStructure: no visible binding for global variable ?value?
PlotTermStructure: no visible binding for global variable ?variable?
REMICOAS: no visible binding for global variable ?value?
REMICOAS: no visible binding for global variable ?..density..?
TotalReturn: no visible binding for global variable ?Scenario?
TotalReturn: no visible binding for global variable ?value?
TotalReturn: no visible binding for global variable ?variable?
TwistScenario: no visible binding for global variable ?Scenario?
TwistScenario: no visible binding for global variable ?Return?
ValuationFramework: no visible binding for global variable ?value?
ValuationFramework: no visible binding for global variable ?variable?
* checking Rd files ... OK
* checking Rd metadata ... OK
* checking Rd line widths ... OK
* checking Rd cross-references ... OK
* checking for missing documentation entries ... OK
* checking for code/documentation mismatches ... OK
* checking Rd \usage sections ... OK
* checking Rd contents ... OK
* checking for unstated dependencies in examples ... OK
* checking examples ... [60s/60s] OK
Examples with CPU or elapsed time > 5s
? ? ? ? ? ? ? ? ? ? user system elapsed
TwistScenario ? ? 18.827 ?1.037 ?19.872
PassThrough.OAS ? 17.485 ?0.068 ?17.567
CreditEnhancement 10.959 ?0.128 ?11.106
PlotMtgKeyRates ? 10.081 ?0.421 ?10.506
* checking PDF version of manual ... OK
NOTE: There were 2 notes.
See
? ?/Users/glennschultz/Companion2IMBS.Rcheck/00check.log?
for details.



R CMD check succeeded


From alberto.canarini at sydney.edu.au  Tue May 26 07:43:47 2015
From: alberto.canarini at sydney.edu.au (Alberto Canarini)
Date: Tue, 26 May 2015 05:43:47 +0000
Subject: [R] Path analysis
Message-ID: <1729CEFBC82756438ED46013CCF57756469CC6D8@ex-mbx-pro-06>

Hi there,

As I'm approaching path analysis I was wondering which packages may suite a path analysis for my data. My data are on interaction of soil biotic and abiotic factor, like microbial biomass carbon, soil carbon, water content, temperature etc.

Thanks in advance,

Best regards.

Alberto

Alberto Canarini
PhD Student l Faculty of Agriculture and Environment
THE UNIVERSITY OF SYDNEY
Shared room l CCWF l Camden Campus l NSW 2570
P 02 935 11892


	[[alternative HTML version deleted]]


From jane.wong083 at gmail.com  Tue May 26 12:14:02 2015
From: jane.wong083 at gmail.com (wong jane)
Date: Tue, 26 May 2015 18:14:02 +0800
Subject: [R] How to pass a variable to a function which use variable name as
	a parameter
Message-ID: <CACnBwQu7aqGceHMVR1vZd2g-NXv_4ETNFSfoCTYEw+Rq0K6OnQ@mail.gmail.com>

There are functions which use variable names as parameters in some R
packages. However, if the variable name is stored in another variable, how
can I pass this variable to the function. Taking the "rms" package as an
example:

library(rms)
n <- 1000
age <- rnorm(n, 50, 10)
sex <- factor(sample(c('female','male'), n,TRUE))

y <- rnorm(n, 200, 25)
ddist <- datadist(age, sex)
options(datadist='ddist')
fit <- lrm(y ~ age)
Predict(fit, age, np=4)
options(datadist=NULL)

Here "age" was a variable name passed to Predict() function, but if "age"
was stored in variable "var", that is, var <- "age", how can I pass "var"
to Predict() function? The purpose is that I want to change the parameter
of Predict()  in a loop.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue May 26 13:20:22 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 26 May 2015 07:20:22 -0400
Subject: [R] R CMD methods and ggplot2 advice
In-Reply-To: <9057ac48-7cff-44b9-88a4-0c2fb24683b3@me.com>
References: <9057ac48-7cff-44b9-88a4-0c2fb24683b3@me.com>
Message-ID: <556456F6.1030901@gmail.com>

This posting should probably go to the new R-package-devel mailing list
instead of R-help.  If you do re-post there, you should give more
information to let people help you.  We can see the errors, but we can't
see the source to your package, so it's hard to diagnose them.  If your
source is online somewhere, a link to it would really help.  If not,
then please include a copy of the DESCRIPTION file (so we can see how
you declared dependence on methods), and extracts from the source of
CreditEnhancement() where you use Period, etc.

Duncan Murdoch

On 25/05/2015 8:24 PM, Glenn Schultz wrote:
> Hello All,
> 
> I have two packages Bond Lab and the Companion to Investing in MBS.  Bond Lab clears the check and I am working on the on.load() to copy a needed directory per Duncan Murdoch's advise to make Bond Lab CRAN-able.  The companion passes with two notes.  The output is below:
> 
> I get two notes (highlighted in red)
> 
> Not sure on this one as I tried to declare methods but I get another note methods declared but not used.  The second note is related to ggplot2 they are variable passed to ggplot2 within a function.  I am not sure why they appear in the R CMD check.  If someone could point in the right direction to resolve these I would appreciate the advice.  These are my last remaining two issues to make the packages pass CRAN aside from the on.load()
> 
> Best Regards,
> Glenn
> 
> * checking dependencies in R code ... NOTE
> package ?methods? is used but not declared
> 
> 
> * checking R code for possible problems ... NOTE
> CreditEnhancement: no visible binding for global variable ?Period?
> CreditEnhancement: no visible binding for global variable ?Value?
> CreditEnhancement: no visible binding for global variable ?Variable?
> CreditEnhancement: no visible binding for global variable ?..density..?
> PassThrough.OAS: no visible binding for global variable ?value?
> PassThrough.OAS: no visible binding for global variable ?..density..?
> PassThroughCashFlow: no visible binding for global variable ?Period?
> PassThroughCashFlow: no visible binding for global variable ?value?
> PassThroughCashFlow: no visible binding for global variable ?variable?
> PlotMtgKeyRates: no visible binding for global variable ?Tenor?
> PlotMtgKeyRates: no visible binding for global variable ?Duration?
> PlotTermStructure: no visible binding for global variable ?value?
> PlotTermStructure: no visible binding for global variable ?variable?
> REMICOAS: no visible binding for global variable ?value?
> REMICOAS: no visible binding for global variable ?..density..?
> TotalReturn: no visible binding for global variable ?Scenario?
> TotalReturn: no visible binding for global variable ?value?
> TotalReturn: no visible binding for global variable ?variable?
> TwistScenario: no visible binding for global variable ?Scenario?
> TwistScenario: no visible binding for global variable ?Return?
> ValuationFramework: no visible binding for global variable ?value?
> ValuationFramework: no visible binding for global variable ?variable?
> 
> ==> devtools::check()
> 
> Updating Companion2IMBS documentation
> Loading Companion2IMBS
> '/Library/Frameworks/R.framework/Resources/bin/R' --vanilla CMD build  \
>   '/Users/glennschultz/Companion to Investing in MBS' --no-resave-data  \
>   --no-manual 
> 
> * checking for file ?/Users/glennschultz/Companion to Investing in MBS/DESCRIPTION? ... OK
> * preparing ?Companion2IMBS?:
> * checking DESCRIPTION meta-information ... OK
> * checking for LF line-endings in source and make files
> * checking for empty or unneeded directories
> Removed empty directory ?Companion2IMBS/inst?
> Removed empty directory ?Companion2IMBS/test/testthat?
> Removed empty directory ?Companion2IMBS/test?
> * building ?Companion2IMBS_1.0.tar.gz?
> 
> '/Library/Frameworks/R.framework/Resources/bin/R' --vanilla CMD check  \
>   '/var/folders/tv/sq6gmnvs13j8jrhkt87f_zmc0000gn/T//RtmpOabREs/Companion2IMBS_1.0.tar.gz'  \
>   --timings 
> 
> * using log directory ?/Users/glennschultz/Companion2IMBS.Rcheck?
> * using R version 3.0.3 (2014-03-06)
> * using platform: x86_64-apple-darwin10.8.0 (64-bit)
> * using session charset: UTF-8
> * checking for file ?Companion2IMBS/DESCRIPTION? ... OK
> * checking extension type ... Package
> * this is package ?Companion2IMBS? version ?1.0?
> * checking package namespace information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking if there is a namespace ... OK
> * checking for executable files ... OK
> * checking for hidden files and directories ... OK
> * checking for portable file names ... OK
> * checking for sufficient/correct file permissions ... OK
> * checking whether package ?Companion2IMBS? can be installed ... OK
> * checking installed package size ... OK
> * checking package directory ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking for left-over files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for non-ASCII characters ... OK
> * checking R files for syntax errors ... OK
> * checking whether the package can be loaded ... OK
> * checking whether the package can be loaded with stated dependencies ... OK
> * checking whether the package can be unloaded cleanly ... OK
> * checking whether the namespace can be loaded with stated dependencies ... OK
> * checking whether the namespace can be unloaded cleanly ... OK
> * checking dependencies in R code ... NOTE
> package ?methods? is used but not declared
> See the information on DESCRIPTION files in the chapter ?Creating R
> packages? of the ?Writing R Extensions? manual.
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... OK
> * checking R code for possible problems ... NOTE
> CreditEnhancement: no visible binding for global variable ?Period?
> CreditEnhancement: no visible binding for global variable ?Value?
> CreditEnhancement: no visible binding for global variable ?Variable?
> CreditEnhancement: no visible binding for global variable ?..density..?
> PassThrough.OAS: no visible binding for global variable ?value?
> PassThrough.OAS: no visible binding for global variable ?..density..?
> PassThroughCashFlow: no visible binding for global variable ?Period?
> PassThroughCashFlow: no visible binding for global variable ?value?
> PassThroughCashFlow: no visible binding for global variable ?variable?
> PlotMtgKeyRates: no visible binding for global variable ?Tenor?
> PlotMtgKeyRates: no visible binding for global variable ?Duration?
> PlotTermStructure: no visible binding for global variable ?value?
> PlotTermStructure: no visible binding for global variable ?variable?
> REMICOAS: no visible binding for global variable ?value?
> REMICOAS: no visible binding for global variable ?..density..?
> TotalReturn: no visible binding for global variable ?Scenario?
> TotalReturn: no visible binding for global variable ?value?
> TotalReturn: no visible binding for global variable ?variable?
> TwistScenario: no visible binding for global variable ?Scenario?
> TwistScenario: no visible binding for global variable ?Return?
> ValuationFramework: no visible binding for global variable ?value?
> ValuationFramework: no visible binding for global variable ?variable?
> * checking Rd files ... OK
> * checking Rd metadata ... OK
> * checking Rd line widths ... OK
> * checking Rd cross-references ... OK
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... OK
> * checking Rd \usage sections ... OK
> * checking Rd contents ... OK
> * checking for unstated dependencies in examples ... OK
> * checking examples ... [60s/60s] OK
> Examples with CPU or elapsed time > 5s
>                     user system elapsed
> TwistScenario     18.827  1.037  19.872
> PassThrough.OAS   17.485  0.068  17.567
> CreditEnhancement 10.959  0.128  11.106
> PlotMtgKeyRates   10.081  0.421  10.506
> * checking PDF version of manual ... OK
> NOTE: There were 2 notes.
> See
>   ?/Users/glennschultz/Companion2IMBS.Rcheck/00check.log?
> for details.
> 
> 
> 
> R CMD check succeeded
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From shivibhatia at ymail.com  Tue May 26 13:14:00 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Tue, 26 May 2015 04:14:00 -0700 (PDT)
Subject: [R] Issues with loading csv file
In-Reply-To: <55633E78.5090105@btinternet.com>
References: <1432556386134-4707637.post@n4.nabble.com>
	<55633E78.5090105@btinternet.com>
Message-ID: <1432638840794-4707675.post@n4.nabble.com>

Hi Pat,

Thanks for the suggestion. It worked for me. 
Actually I had not saved the file in the WD accidentally and with the help
of get files syntax I got to know what was the issue.

Thanks a ton.
Shivi



--
View this message in context: http://r.789695.n4.nabble.com/Issues-with-loading-csv-file-tp4707637p4707675.html
Sent from the R help mailing list archive at Nabble.com.


From cdetermanjr at gmail.com  Tue May 26 14:05:31 2015
From: cdetermanjr at gmail.com (Charles Determan)
Date: Tue, 26 May 2015 07:05:31 -0500
Subject: [R] Path analysis
In-Reply-To: <1729CEFBC82756438ED46013CCF57756469CC6D8@ex-mbx-pro-06>
References: <1729CEFBC82756438ED46013CCF57756469CC6D8@ex-mbx-pro-06>
Message-ID: <CAKxd1KOGdo339MbjThtXHfktky+Cyg2c7SgNZhR+pmu=8GZsYg@mail.gmail.com>

Given that your problem primarily focuses on a biological context you
probably would have better luck with bioconductor (www.bioconductor.org).

Regards,
Charles

On Tue, May 26, 2015 at 12:43 AM, Alberto Canarini <
alberto.canarini at sydney.edu.au> wrote:

> Hi there,
>
> As I'm approaching path analysis I was wondering which packages may suite
> a path analysis for my data. My data are on interaction of soil biotic and
> abiotic factor, like microbial biomass carbon, soil carbon, water content,
> temperature etc.
>
> Thanks in advance,
>
> Best regards.
>
> Alberto
>
> Alberto Canarini
> PhD Student l Faculty of Agriculture and Environment
> THE UNIVERSITY OF SYDNEY
> Shared room l CCWF l Camden Campus l NSW 2570
> P 02 935 11892
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gudrun.gygli at wur.nl  Tue May 26 09:10:35 2015
From: gudrun.gygli at wur.nl (Gygli, Gudrun)
Date: Tue, 26 May 2015 07:10:35 +0000
Subject: [R] png package in Ubuntu 12.04 with R 3.1.0
Message-ID: <1432624256289.86220@wur.nl>


Dear All,


I am using R to analyse computer simulations of ligand docking in a protein.

I am plotting the results as scatterplots and bopxplots, using the code below.

This works perfectly fine.


I would like now to add a png file to that plot, meaning I want sth like:


png(file="analysis.png")
par(mfrow=c(1,3), oma=c(0,0,2,0))

plot

boxplot

PNG figure I read in


I am running Ubuntu 12.04 and R 3.1.0.


readPNG and the png packge do NOT work for me at this point.


when I try to install the png package I get the error below.


Any ideas what's wrong or other options to import png files?


Thank you in advance for the help.


Best regards


Gudrun



png(file="analysis.png")
par(mfrow=c(1,2), oma=c(0,0,2,0))
plot(data, main="all", xlab="simulations run", ylab="steps")
boxplot(data, main="steps", horizontal = FALSE, axes = FALSE, staplewex = 1)
text(y = boxplot.stats(data)$stats, labels = boxplot.stats(data)$stats, x = 1.35)
title("analysis", outer=TRUE)



install.packages("png")


downloaded 24 Kb


* installing *source* package 'png' ...
** package 'png' successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      `libpng-config --cflags` -fpic  -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c read.c -o read.o
/bin/bash: libpng-config: command not found
read.c:3:17: fatal error: png.h: No such file or directory
compilation terminated.
make: *** [read.o] Error 1
ERROR: compilation failed for package 'png'
* removing '/home/g1/R/x86_64-pc-linux-gnu-library/3.1/png'

The downloaded source packages are in
    '/tmp/Rtmpvo3r8J/downloaded_packages'
Warning message:
In install.packages("png") :
  installation of package 'png' had non-zero exit status




Gudrun Gygli, MSc

PhD candidate

Wageningen University
Laboratory of Biochemistry
Dreijenlaan 3
6703 HA Wageningen
The Netherlands

Phone  31 317483387
e-mail: gudrun.gygli at wur.nl

- - - - - - - - - - - - - - - - - -

Project information: http://www.wageningenur.nl/en/show/Bioinformatics-structural-biology-and-molecular-modeling-of-Vanillyl-Alcohol-Oxidases-VAOs.htm


From venkynov10 at gmail.com  Tue May 26 13:41:50 2015
From: venkynov10 at gmail.com (venkadesan venky)
Date: Tue, 26 May 2015 17:11:50 +0530
Subject: [R] (no subject)
Message-ID: <CAAM-fZ4nyZUbC+HoybHNN-Sr-06rNfDa1f8pt-y6z8U3Ahc=Zg@mail.gmail.com>

Hello guys,

I have data set like this

Name   A         B         C        D
Venky  12       157       168     209
Kalai    65       8899     889     998
balaji    98       877       8787   9888
.
.
.

i want to change Name column as a Charcter and A column as a percentage and
B and C column as a thousand seperators

	[[alternative HTML version deleted]]


From michelle.galla at gmx.de  Tue May 26 13:31:17 2015
From: michelle.galla at gmx.de (MGalla)
Date: Tue, 26 May 2015 04:31:17 -0700 (PDT)
Subject: [R] Help with urnsamples and all possible combination
In-Reply-To: <3411D57F-039C-443C-A76C-1888A57C3198@utoronto.ca>
References: <1432378766194-4707560.post@n4.nabble.com>
	<3411D57F-039C-443C-A76C-1888A57C3198@utoronto.ca>
Message-ID: <1432639877145-4707676.post@n4.nabble.com>

Thanks for your help. So I have to try it on the long way, because I need
exactly all combinations, but thanks for the idea.

Best wishes
Michelle Galla



--
View this message in context: http://r.789695.n4.nabble.com/Help-with-urnsamples-and-all-possible-combination-tp4707560p4707676.html
Sent from the R help mailing list archive at Nabble.com.


From bruno.lambert at uantwerpen.be  Tue May 26 11:33:56 2015
From: bruno.lambert at uantwerpen.be (Lambert Bruno)
Date: Tue, 26 May 2015 09:33:56 +0000
Subject: [R] =?windows-1252?q?logistic_regression_R_and_Stata_=96_grouping?=
	=?windows-1252?q?_variable?=
Message-ID: <DF1DD3F5916A274694302741224613ED013C28A097@xmail31.ad.ua.ac.be>

Hello,

I mostly use Stata 13 for my regression analysis. I want to conduct a logistic regression on a proportion/number of success. Because I receive errors in Stata I did not expect nor understand (if there are Stata experts who want to know more about the problems I face and can potentially help me solve them, I would be glad to give more details), I want to repeat the analysis in R. In Stata I would use the command: xtlogit DEP_PROP INDEP_A INDEP_B INDEP_C, i(ID). ID is the identifier for each subject. There are eight lines with data for each subject because there are three within factors (INDEP_A, B, C) with two levels each (0 and 1). I can repeat this analysis in R by using the command: glm(DEP_SUC ~ INDEP_A + INDEP_B + INDEP_C, family = ?binomial?). DEP_SUC is here a table with the successes and misses per row. Again, there are eight rows for each subject. But while I know how to group these lines in Stata by using the option i(ID ), I do not know what to do in R. I have search for more information about the i() command, but did not find any usefull information.

So, to summarize: I want to find out how three variables (binary) influence a proportion and use logistic regression. In Stata I can group multiple lines per subject using the i( ) command in logistic regression. What is the equivalent in R?

Thank you in advance!

	[[alternative HTML version deleted]]


From Lalitha.Kristipati at techmahindra.com  Tue May 26 12:51:14 2015
From: Lalitha.Kristipati at techmahindra.com (Lalitha Kristipati)
Date: Tue, 26 May 2015 10:51:14 +0000
Subject: [R] Hadoop R integration
Message-ID: <cc1a5da59407444a977662d83b3aa2a4@BLREXCHMBX001.TechMahindra.com>


Hi,

I need to showcase how R and Hadoop can work together using ORCH. I have found a sample code from the ORACLE website as follows
dfs <- hdfs.attach("ontime_DB")

res <- hadoop.run(
        dfs,
        mapper = function(key, value) {
          if (key == 'SFO' & !is.na(x$ARRDELAY)) {
            keyval(key, value)
          }
          else {
            NULL
          }
            },
         reducer = function(key, values) {
            for (x in values) {
                sumAD <- sumAD + x$ARRDELAY
                count <- count + 1
                  }
                  res <- sumAD / count
                  keyval(key, res)
            })

OUTPUT:

> hdfs.get(res)
   key     val1
1  SFO   17.44828

I could not understand in this code where is ORCH acting as a connector. Even if you can explain how ORCH acts as a connector to Hadoop with another example it would also be helpful.


Regards,
Lalitha Kristipati
Associate Software Engineer



============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Tue May 26 14:25:24 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 26 May 2015 07:25:24 -0500
Subject: [R] How to pass a variable to a function which use variable
 name as a parameter
In-Reply-To: <CACnBwQu7aqGceHMVR1vZd2g-NXv_4ETNFSfoCTYEw+Rq0K6OnQ@mail.gmail.com>
References: <CACnBwQu7aqGceHMVR1vZd2g-NXv_4ETNFSfoCTYEw+Rq0K6OnQ@mail.gmail.com>
Message-ID: <CAAJSdji5gWgODaRM4K6E2tAWq83wz_gES7qYMeR=xpNS3S76Sw@mail.gmail.com>

On Tue, May 26, 2015 at 5:14 AM, wong jane <jane.wong083 at gmail.com> wrote:

> There are functions which use variable names as parameters in some R
> packages. However, if the variable name is stored in another variable, how
> can I pass this variable to the function. Taking the "rms" package as an
> example:
>
> ??
> library(rms)
> n <- 1000
> age <- rnorm(n, 50, 10)
> sex <- factor(sample(c('female','male'), n,TRUE))
>
> y <- rnorm(n, 200, 25)
> ddist <- datadist(age, sex)
> options(datadist='ddist')
> fit <- lrm(y ~ age)
> Predict(fit, age, np=4)
> options(datadist=NULL)
>
> Here "age" was a variable name passed to Predict() function, but if "age"
> was stored in variable "var", that is, var <- "age", how can I pass "var"
> to Predict() function? The purpose is that I want to change the parameter
> of Predict()  in a loop.
>
>
?Please turn off HMTL email. The forum software doesn't really like it.

What you want is the "get()" function.


var<-"age"

?
?
library(rms)
n <- 1000
age <- rnorm(n, 50, 10)
sex <- factor(sample(c('female','male'), n,TRUE))

y <- rnorm(n, 200, 25)
?#?
ddist <- datadist(age, sex)
?ddist <- datadist(get(var),sex)?
options(datadist='ddist')
fit <- lrm(y ~ age)
?#?
Predict(fit, age, np=4)
?Predict(fit,get(var),np=4)?
options(datadist=NULL)

-- 
My sister opened a computer store in Hawaii. She sells C shells down by the
seashore.

If someone tell you that nothing is impossible:
Ask him to dribble a football.

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue May 26 14:26:16 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 26 May 2015 22:26:16 +1000
Subject: [R] (no subject)
In-Reply-To: <CAAM-fZ4nyZUbC+HoybHNN-Sr-06rNfDa1f8pt-y6z8U3Ahc=Zg@mail.gmail.com>
References: <CAAM-fZ4nyZUbC+HoybHNN-Sr-06rNfDa1f8pt-y6z8U3Ahc=Zg@mail.gmail.com>
Message-ID: <CA+8X3fWvY+T6OpvjJXG-gz5kC-xgMvX5sMZUypvPOE0dScTnmQ@mail.gmail.com>

Hi venkadesan,
Assuming that the Name column is now a factor (and the data set is a
data frame named "mydata"), try:

mydata$Name<-as.character(mydata$Name)

If you mean that you want to display column A with percentage signs:

paste(mydata$A,"%",sep="")

You can use the "format" function to display the final three columns
with thousand separators:

format(mydata$B,big.mark=",")

Note that the result will be a character variable, not a number.

Jim


On Tue, May 26, 2015 at 9:41 PM, venkadesan venky <venkynov10 at gmail.com> wrote:
> Hello guys,
>
> I have data set like this
>
> Name   A         B         C        D
> Venky  12       157       168     209
> Kalai    65       8899     889     998
> balaji    98       877       8787   9888
> .
> .
> .
>
> i want to change Name column as a Charcter and A column as a percentage and
> B and C column as a thousand seperators
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From stefano.sofia at regione.marche.it  Tue May 26 14:47:23 2015
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Tue, 26 May 2015 12:47:23 +0000
Subject: [R] apply a function to a list of data frames
In-Reply-To: <555F74D9.8090706@sapo.pt>
References: <8B435C9568170B469AE31E8891E8CC4F280584CF@CHIENTI.regionemarche.intra>,
	<555F74D9.8090706@sapo.pt>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F28061A52@CHIENTI.regionemarche.intra>

Thank you for your help.
Your explanations have been very useful.

Stefano

________________________________________
Da: Rui Barradas [ruipbarradas at sapo.pt]
Inviato: venerd? 22 maggio 2015 20.26
A: Stefano Sofia; r-help at r-project.org
Oggetto: Re: [R] apply a function to a list of data frames

Hello,

You should change your function to accept only one argument, the
data.frames, and then use lapply (not sapply).
Something like the following.

calc <- function(dat)
{
        bias_dmo_max <- round(mean((dat$dmo_12-dat$Eonestep_12), na.rm=TRUE),
digits=2)
        rmse_dmo_max <- round(sqrt(mean((dat$dmo_12-dat$Eonestep_12)^2,
na.rm=TRUE)), digits=2)
        bias_dmo_min <- round(mean((dat$dmo_27-dat$Eonestep_27), na.rm=TRUE),
digits=2)
        rmse_dmo_min <- round(sqrt(mean((dat$dmo_27-dat$Eonestep_27)^2,
na.rm=TRUE)), digits=2)
        result <- list(bias_dmo_max, rmse_dmo_max, bias_dmo_min, rmse_dmo_min)
        result
}

result_lst <- lapply(lst, calc)


Hope this helps,

Rui Barradas


Em 22-05-2015 19:02, Stefano Sofia escreveu:
> Dear R-users,
> given a list of dataframes (like below reported), for each month I need to apply a function (called calc).
> The result should be written in a new list of data frames, one row for each month.
>
> I have been trying to use sapply, with no success.
> Could somebody help me in this?
>
>
> $df1
> day dmo_12 Eonestep_12 tmax dmo_27 Eonestep_27 tmin
> 2012-12-01 11 13 13 9 8 8
> 2012-12-02 11 13 13 5 6 8
> 2012-12-03 6 10 8 6 6 7
> 2012-12-04 11 13 9 6 6 3
> 2012-12-05 8 10 12 5 6 7
> 2012-12-06 8 10 8 4 5 4
> 2012-12-07 7 9 8 6 6 5
> ...
>
>
> calc <- function(dmo_12, Eonestep_12, dmo_27, Eonestep_27)
> {
> bias_dmo_max <- round(mean((dmo_12-Eonestep_12), na.rm=TRUE), digits=2)
> rmse_dmo_max <- round(sqrt(mean((dmo_12-Eonestep_12)^2, na.rm=TRUE)), digits=2)
> bias_dmo_min <- round(mean((dmo_27-Eonestep_27), na.rm=TRUE), digits=2)
> rmse_dmo_min <- round(sqrt(mean((dmo_27-Eonestep_27)^2, na.rm=TRUE)), digits=2)
> result <- list(bias_dmo_max, rmse_dmo_max, bias_dmo_min, rmse_dmo_min)
> result
> }
>
>
> Thank you for your help
> Stefano
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.


From jrkrideau at inbox.com  Tue May 26 14:52:57 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 26 May 2015 04:52:57 -0800
Subject: [R] png package in Ubuntu 12.04 with R 3.1.0
In-Reply-To: <1432624256289.86220@wur.nl>
Message-ID: <586F827F445.00001233jrkrideau@inbox.com>

Have you loaded the png package?

library(png)

John Kane
Kingston ON Canada


> -----Original Message-----
> From: gudrun.gygli at wur.nl
> Sent: Tue, 26 May 2015 07:10:35 +0000
> To: r-help at r-project.org
> Subject: [R] png package in Ubuntu 12.04 with R 3.1.0
> 
> 
> Dear All,
> 
> 
> I am using R to analyse computer simulations of ligand docking in a
> protein.
> 
> I am plotting the results as scatterplots and bopxplots, using the code
> below.
> 
> This works perfectly fine.
> 
> 
> I would like now to add a png file to that plot, meaning I want sth like:
> 
> 
> png(file="analysis.png")
> par(mfrow=c(1,3), oma=c(0,0,2,0))
> 
> plot
> 
> boxplot
> 
> PNG figure I read in
> 
> 
> I am running Ubuntu 12.04 and R 3.1.0.
> 
> 
> readPNG and the png packge do NOT work for me at this point.
> 
> 
> when I try to install the png package I get the error below.
> 
> 
> Any ideas what's wrong or other options to import png files?
> 
> 
> Thank you in advance for the help.
> 
> 
> Best regards
> 
> 
> Gudrun
> 
> 
> 
> png(file="analysis.png")
> par(mfrow=c(1,2), oma=c(0,0,2,0))
> plot(data, main="all", xlab="simulations run", ylab="steps")
> boxplot(data, main="steps", horizontal = FALSE, axes = FALSE, staplewex =
> 1)
> text(y = boxplot.stats(data)$stats, labels = boxplot.stats(data)$stats, x
> = 1.35)
> title("analysis", outer=TRUE)
> 
> 
> 
> install.packages("png")
> 
> 
> downloaded 24 Kb
> 
> 
> * installing *source* package 'png' ...
> ** package 'png' successfully unpacked and MD5 sums checked
> ** libs
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      `libpng-config
> --cflags` -fpic  -g -O2 -fstack-protector --param=ssp-buffer-size=4
> -Wformat -Wformat-security -Werror=format-security -D_FORTIFY_SOURCE=2 -g
> -c read.c -o read.o
> /bin/bash: libpng-config: command not found
> read.c:3:17: fatal error: png.h: No such file or directory
> compilation terminated.
> make: *** [read.o] Error 1
> ERROR: compilation failed for package 'png'
> * removing '/home/g1/R/x86_64-pc-linux-gnu-library/3.1/png'
> 
> The downloaded source packages are in
>     '/tmp/Rtmpvo3r8J/downloaded_packages'
> Warning message:
> In install.packages("png") :
>   installation of package 'png' had non-zero exit status
> 
> 
> 
> 
> Gudrun Gygli, MSc
> 
> PhD candidate
> 
> Wageningen University
> Laboratory of Biochemistry
> Dreijenlaan 3
> 6703 HA Wageningen
> The Netherlands
> 
> Phone  31 317483387
> e-mail: gudrun.gygli at wur.nl
> 
> - - - - - - - - - - - - - - - - - -
> 
> Project information:
> http://www.wageningenur.nl/en/show/Bioinformatics-structural-biology-and-molecular-modeling-of-Vanillyl-Alcohol-Oxidases-VAOs.htm
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From jfox at mcmaster.ca  Tue May 26 14:57:43 2015
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 26 May 2015 08:57:43 -0400
Subject: [R] Path analysis
In-Reply-To: <1729CEFBC82756438ED46013CCF57756469CC6D8@ex-mbx-pro-06>
References: <1729CEFBC82756438ED46013CCF57756469CC6D8@ex-mbx-pro-06>
Message-ID: <web-561027026@cgpsrv2.cis.mcmaster.ca>

Dear Alberto,

There are several R packages available on CRAN for structural equation modeling: sem, lavaan, and OpenMx come immediately to mind. If your model is recursive with only observed variables, then you could just use lm(). If your model is nonrecursive with only observed variables, then you could also use the systemfit package.

I hope this helps,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	


On Tue, 26 May 2015 05:43:47 +0000
 Alberto Canarini <alberto.canarini at sydney.edu.au> wrote:
> Hi there,
> 
> As I'm approaching path analysis I was wondering which packages may suite a path analysis for my data. My data are on interaction of soil biotic and abiotic factor, like microbial biomass carbon, soil carbon, water content, temperature etc.
> 
> Thanks in advance,
> 
> Best regards.
> 
> Alberto
> 
> Alberto Canarini
> PhD Student l Faculty of Agriculture and Environment
> THE UNIVERSITY OF SYDNEY
> Shared room l CCWF l Camden Campus l NSW 2570
> P 02 935 11892
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tom at nmrql.com  Tue May 26 15:29:08 2015
From: tom at nmrql.com (nmrql)
Date: Tue, 26 May 2015 06:29:08 -0700 (PDT)
Subject: [R] Installing "Blotter"and "Rtools"in R
Message-ID: <1432646948252-4707688.post@n4.nabble.com>

HI, Im trying to install the "blotter" package in R however I get the
following message:
 
Warning in install.packages :
  package ?blotter? is not available (for R version 3.2.0)

I have been told to first install the "Rtools" package, which gives me the
same message.
I also believe that there is a way to install Rtools directly from the
website: "http://cran.r-project.org/bin/windows/Rtools/" However  do not
know how to do this.

Any help would be much aprreciated?
Thanks



--
View this message in context: http://r.789695.n4.nabble.com/Installing-Blotter-and-Rtools-in-R-tp4707688.html
Sent from the R help mailing list archive at Nabble.com.


From wdunlap at tibco.com  Tue May 26 17:30:35 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 26 May 2015 08:30:35 -0700
Subject: [R] How to pass a variable to a function which use variable
 name as a parameter
In-Reply-To: <CACnBwQu7aqGceHMVR1vZd2g-NXv_4ETNFSfoCTYEw+Rq0K6OnQ@mail.gmail.com>
References: <CACnBwQu7aqGceHMVR1vZd2g-NXv_4ETNFSfoCTYEw+Rq0K6OnQ@mail.gmail.com>
Message-ID: <CAF8bMcb-3yTCeEO93BbnsJyR9ASUD4yE8Mik_5VkiY5x32nnRg@mail.gmail.com>

One way to use variable names in functions like Predict() that
do not evaluate their arguments in the standard way is to use
do.call() along with as.name().  E.g.,
  varName<-"age"
  do.call("Predict", list(fit, as.name(varName), np=4))})
gives the same result as
  Predict(fit, age, np=4)



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, May 26, 2015 at 3:14 AM, wong jane <jane.wong083 at gmail.com> wrote:

> There are functions which use variable names as parameters in some R
> packages. However, if the variable name is stored in another variable, how
> can I pass this variable to the function. Taking the "rms" package as an
> example:
>
> library(rms)
> n <- 1000
> age <- rnorm(n, 50, 10)
> sex <- factor(sample(c('female','male'), n,TRUE))
>
> y <- rnorm(n, 200, 25)
> ddist <- datadist(age, sex)
> options(datadist='ddist')
> fit <- lrm(y ~ age)
> Predict(fit, age, np=4)
> options(datadist=NULL)
>
> Here "age" was a variable name passed to Predict() function, but if "age"
> was stored in variable "var", that is, var <- "age", how can I pass "var"
> to Predict() function? The purpose is that I want to change the parameter
> of Predict()  in a loop.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From xie at yihui.name  Tue May 26 18:31:14 2015
From: xie at yihui.name (Yihui Xie)
Date: Tue, 26 May 2015 11:31:14 -0500
Subject: [R] png package in Ubuntu 12.04 with R 3.1.0
In-Reply-To: <1432624256289.86220@wur.nl>
References: <1432624256289.86220@wur.nl>
Message-ID: <CANROs4dJ297UL0mSXLpLejsYaFn_pPd0qQZkvdFy_bcZ40Kazw@mail.gmail.com>

sudo apt-get install libpng12-dev

I'm not sure about Ubuntu 12.04. You may need a different libpng??-dev.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Tue, May 26, 2015 at 2:10 AM, Gygli, Gudrun <gudrun.gygli at wur.nl> wrote:
>
> Dear All,
>
>
> I am using R to analyse computer simulations of ligand docking in a protein.
>
> I am plotting the results as scatterplots and bopxplots, using the code below.
>
> This works perfectly fine.
>
>
> I would like now to add a png file to that plot, meaning I want sth like:
>
>
> png(file="analysis.png")
> par(mfrow=c(1,3), oma=c(0,0,2,0))
>
> plot
>
> boxplot
>
> PNG figure I read in
>
>
> I am running Ubuntu 12.04 and R 3.1.0.
>
>
> readPNG and the png packge do NOT work for me at this point.
>
>
> when I try to install the png package I get the error below.
>
>
> Any ideas what's wrong or other options to import png files?
>
>
> Thank you in advance for the help.
>
>
> Best regards
>
>
> Gudrun
>
>
>
> png(file="analysis.png")
> par(mfrow=c(1,2), oma=c(0,0,2,0))
> plot(data, main="all", xlab="simulations run", ylab="steps")
> boxplot(data, main="steps", horizontal = FALSE, axes = FALSE, staplewex = 1)
> text(y = boxplot.stats(data)$stats, labels = boxplot.stats(data)$stats, x = 1.35)
> title("analysis", outer=TRUE)
>
>
>
> install.packages("png")
>
>
> downloaded 24 Kb
>
>
> * installing *source* package 'png' ...
> ** package 'png' successfully unpacked and MD5 sums checked
> ** libs
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      `libpng-config --cflags` -fpic  -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c read.c -o read.o
> /bin/bash: libpng-config: command not found
> read.c:3:17: fatal error: png.h: No such file or directory
> compilation terminated.
> make: *** [read.o] Error 1
> ERROR: compilation failed for package 'png'
> * removing '/home/g1/R/x86_64-pc-linux-gnu-library/3.1/png'
>
> The downloaded source packages are in
>     '/tmp/Rtmpvo3r8J/downloaded_packages'
> Warning message:
> In install.packages("png") :
>   installation of package 'png' had non-zero exit status
>
>
>
>
> Gudrun Gygli, MSc
>
> PhD candidate
>
> Wageningen University
> Laboratory of Biochemistry
> Dreijenlaan 3
> 6703 HA Wageningen
> The Netherlands
>
> Phone  31 317483387
> e-mail: gudrun.gygli at wur.nl
>
> - - - - - - - - - - - - - - - - - -
>
> Project information: http://www.wageningenur.nl/en/show/Bioinformatics-structural-biology-and-molecular-modeling-of-Vanillyl-Alcohol-Oxidases-VAOs.htm
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue May 26 19:22:10 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 26 May 2015 10:22:10 -0700
Subject: [R] How to pass a variable to a function which use variable
	name as a parameter
In-Reply-To: <CAF8bMcb-3yTCeEO93BbnsJyR9ASUD4yE8Mik_5VkiY5x32nnRg@mail.gmail.com>
References: <CACnBwQu7aqGceHMVR1vZd2g-NXv_4ETNFSfoCTYEw+Rq0K6OnQ@mail.gmail.com>
	<CAF8bMcb-3yTCeEO93BbnsJyR9ASUD4yE8Mik_5VkiY5x32nnRg@mail.gmail.com>
Message-ID: <FCC646A8-B377-465E-A8FB-1C8A413EB585@comcast.net>


On May 26, 2015, at 8:30 AM, William Dunlap wrote:

> One way to use variable names in functions like Predict() that
> do not evaluate their arguments in the standard way is to use
> do.call() along with as.name().  E.g.,
>  varName<-"age"
>  do.call("Predict", list(fit, as.name(varName), np=4))})
> gives the same result as
>  Predict(fit, age, np=4)
> 

Here's another approach, developed after looking at the code and the help page, where I noticed that the factors argument was given an an alternate route for specifying the variables for evaluation. The requirements for the 'factors' argument are that it be provided as a named list and have either specific values or NA.

 var="age"
 vlist <- list(dum=NA)
 names(vlist)=var
 
 Predict(fit, factors=vlist, np=4)
#----- same result -------
       age     yhat    lower    upper
1 25.04901 6.834836 4.856497 8.813174
2 41.14259 6.882369 4.919433 8.845306
3 57.23618 6.929903 4.967118 8.892688
4 73.32977 6.977437 4.999548 8.955325

Response variable (y): log odds 

Limits are 0.95 confidence limits

-- 
David.

> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Tue, May 26, 2015 at 3:14 AM, wong jane <jane.wong083 at gmail.com> wrote:
> 
>> There are functions which use variable names as parameters in some R
>> packages. However, if the variable name is stored in another variable, how
>> can I pass this variable to the function. Taking the "rms" package as an
>> example:
>> 
>> library(rms)
>> n <- 1000
>> age <- rnorm(n, 50, 10)
>> sex <- factor(sample(c('female','male'), n,TRUE))
>> 
>> y <- rnorm(n, 200, 25)
>> ddist <- datadist(age, sex)
>> options(datadist='ddist')
>> fit <- lrm(y ~ age)
>> Predict(fit, age, np=4)
>> options(datadist=NULL)
>> 
>> Here "age" was a variable name passed to Predict() function, but if "age"
>> was stored in variable "var", that is, var <- "age", how can I pass "var"
>> to Predict() function? The purpose is that I want to change the parameter
>> of Predict()  in a loop.
>> 
>>        [[alternative HTML version deleted]]
-- 
> 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Tue May 26 19:28:34 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 26 May 2015 10:28:34 -0700
Subject: [R] Installing "Blotter"and "Rtools"in R
In-Reply-To: <1432646948252-4707688.post@n4.nabble.com>
References: <1432646948252-4707688.post@n4.nabble.com>
Message-ID: <350B9BF7-B165-4041-9BDF-0EEFF416A693@comcast.net>


On May 26, 2015, at 6:29 AM, nmrql wrote:

> HI, Im trying to install the "blotter" package in R however I get the
> following message:

How?

> 
> Warning in install.packages :
>  package ?blotter? is not available (for R version 3.2.0)

I do not see it in the list of packages available from CRAN.
> 
> I have been told to first install the "Rtools" package, which gives me the
> same message.

Rtools is a set of Windows utilities. I don't think it's possible to be installed from an R console session.


> I also believe that there is a way to install Rtools directly from the
> website: "http://cran.r-project.org/bin/windows/Rtools/" However  do not
> know how to do this.

http://cran.r-project.org/bin/windows/Rtools/index.html

http://cran.r-project.org/bin/windows/Rtools/installer.html


> 
> Any help would be much aprreciated?
> Thanks
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Installing-Blotter-and-Rtools-in-R-tp4707688.html
> Sent from the R help mailing list archive at Nabble.com.

Posting from Nabble is somewhat discouraged. If it is at all feasible you should use a regular mail client and post directly to the list.

-- 

David Winsemius
Alameda, CA, USA


From hannah.hlx at gmail.com  Tue May 26 20:13:54 2015
From: hannah.hlx at gmail.com (li li)
Date: Tue, 26 May 2015 14:13:54 -0400
Subject: [R] lme function to obtain pvalue for fixed effect
Message-ID: <CAHLnndbj=DV3+Krw8gaEH8rBCzh9+Q2b+t0AwAUu9V7BfGwkVA@mail.gmail.com>

Hi all,
  I am using the lme function to run a random coefficient model. Please see
output (mod1) as below.
  I need to obtain the pvalue for the fixed effect. As you can see,
the pvalues given using the summary function is different from the
resutls given in anova function.
Why should they be different and which one is the correct one to use?
   Thanks!
      Hanna


> summary(mod1)
Linear mixed-effects model fit by REML
 Data: minus20C1
        AIC       BIC   logLik
  -82.60042 -70.15763 49.30021

Random effects:
 Formula: ~1 + months | lot
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 8.907584e-03 (Intr)
months      6.039781e-05 -0.096
Residual    4.471243e-02

Fixed effects: ti ~ type * months
                     Value   Std.Error DF   t-value p-value
(Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
type             0.13502089 0.026676101  4  5.061493  0.0072
months          0.00804790 0.001218941 31  6.602368  0.0000
type:months -0.00693679 0.002981859 31 -2.326329  0.0267
 Correlation:
               (Intr) typ months
type        -0.633
months         -0.785  0.497
type:months  0.321 -0.762 -0.409

Standardized Within-Group Residuals:
          Min            Q1           Med            Q3           Max
-2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00

Number of Observations: 39
Number of Groups: 6
> anova(mod1)
            numDF denDF   F-value p-value
(Intercept)     1    31 2084.0265  <.0001
type            1     4   10.8957  0.0299
months          1    31   38.3462  <.0001
type:months     1    31    5.4118  0.0267


From byronvinu_8 at hotmail.com  Tue May 26 21:19:08 2015
From: byronvinu_8 at hotmail.com (byron vinueza)
Date: Tue, 26 May 2015 14:19:08 -0500
Subject: [R] [R-sig-ME] lme function to obtain pvalue for fixed effect
In-Reply-To: <CAHLnndbj=DV3+Krw8gaEH8rBCzh9+Q2b+t0AwAUu9V7BfGwkVA@mail.gmail.com>
References: <CAHLnndbj=DV3+Krw8gaEH8rBCzh9+Q2b+t0AwAUu9V7BfGwkVA@mail.gmail.com>
Message-ID: <BLU406-EAS16766F94C10A98D0545848AC4CC0@phx.gbl>

You can use the lmerTest package .





Enviado desde mi iPhone

> El 26/5/2015, a las 13:18, li li <hannah.hlx at gmail.com> escribi?:
> 
> Hi all,
>  I am using the lme function to run a random coefficient model. Please see
> output (mod1) as below.
>  I need to obtain the pvalue for the fixed effect. As you can see,
> the pvalues given using the summary function is different from the
> resutls given in anova function.
> Why should they be different and which one is the correct one to use?
>   Thanks!
>      Hanna
> 
> 
>> summary(mod1)
> Linear mixed-effects model fit by REML
> Data: minus20C1
>        AIC       BIC   logLik
>  -82.60042 -70.15763 49.30021
> 
> Random effects:
> Formula: ~1 + months | lot
> Structure: General positive-definite, Log-Cholesky parametrization
>            StdDev       Corr
> (Intercept) 8.907584e-03 (Intr)
> months      6.039781e-05 -0.096
> Residual    4.471243e-02
> 
> Fixed effects: ti ~ type * months
>                     Value   Std.Error DF   t-value p-value
> (Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
> type             0.13502089 0.026676101  4  5.061493  0.0072
> months          0.00804790 0.001218941 31  6.602368  0.0000
> type:months -0.00693679 0.002981859 31 -2.326329  0.0267
> Correlation:
>               (Intr) typ months
> type        -0.633
> months         -0.785  0.497
> type:months  0.321 -0.762 -0.409
> 
> Standardized Within-Group Residuals:
>          Min            Q1           Med            Q3           Max
> -2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00
> 
> Number of Observations: 39
> Number of Groups: 6
>> anova(mod1)
>            numDF denDF   F-value p-value
> (Intercept)     1    31 2084.0265  <.0001
> type            1     4   10.8957  0.0299
> months          1    31   38.3462  <.0001
> type:months     1    31    5.4118  0.0267
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From hannah.hlx at gmail.com  Tue May 26 21:46:11 2015
From: hannah.hlx at gmail.com (li li)
Date: Tue, 26 May 2015 15:46:11 -0400
Subject: [R] [R-sig-ME] lme function to obtain pvalue for fixed effect
In-Reply-To: <BLU406-EAS16766F94C10A98D0545848AC4CC0@phx.gbl>
References: <CAHLnndbj=DV3+Krw8gaEH8rBCzh9+Q2b+t0AwAUu9V7BfGwkVA@mail.gmail.com>
	<BLU406-EAS16766F94C10A98D0545848AC4CC0@phx.gbl>
Message-ID: <CAHLnndY1hay+2sU-K+LSJrrzMJAZCtb4ef25BT_HYufxd07drw@mail.gmail.com>

Thanks so much for replying.
Yes LimerTest package could be used to get pvalues when using lmer
function. But still the summary and anova function give different
pvalues.
   Hanna

2015-05-26 15:19 GMT-04:00, byron vinueza <byronvinu_8 at hotmail.com>:
> You can use the lmerTest package .
>
>
>
>
>
> Enviado desde mi iPhone
>
>> El 26/5/2015, a las 13:18, li li <hannah.hlx at gmail.com> escribi?:
>>
>> Hi all,
>>  I am using the lme function to run a random coefficient model. Please
>> see
>> output (mod1) as below.
>>  I need to obtain the pvalue for the fixed effect. As you can see,
>> the pvalues given using the summary function is different from the
>> resutls given in anova function.
>> Why should they be different and which one is the correct one to use?
>>   Thanks!
>>      Hanna
>>
>>
>>> summary(mod1)
>> Linear mixed-effects model fit by REML
>> Data: minus20C1
>>        AIC       BIC   logLik
>>  -82.60042 -70.15763 49.30021
>>
>> Random effects:
>> Formula: ~1 + months | lot
>> Structure: General positive-definite, Log-Cholesky parametrization
>>            StdDev       Corr
>> (Intercept) 8.907584e-03 (Intr)
>> months      6.039781e-05 -0.096
>> Residual    4.471243e-02
>>
>> Fixed effects: ti ~ type * months
>>                     Value   Std.Error DF   t-value p-value
>> (Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
>> type             0.13502089 0.026676101  4  5.061493  0.0072
>> months          0.00804790 0.001218941 31  6.602368  0.0000
>> type:months -0.00693679 0.002981859 31 -2.326329  0.0267
>> Correlation:
>>               (Intr) typ months
>> type        -0.633
>> months         -0.785  0.497
>> type:months  0.321 -0.762 -0.409
>>
>> Standardized Within-Group Residuals:
>>          Min            Q1           Med            Q3           Max
>> -2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00
>>
>> Number of Observations: 39
>> Number of Groups: 6
>>> anova(mod1)
>>            numDF denDF   F-value p-value
>> (Intercept)     1    31 2084.0265  <.0001
>> type            1     4   10.8957  0.0299
>> months          1    31   38.3462  <.0001
>> type:months     1    31    5.4118  0.0267
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From thierry.onkelinx at inbo.be  Tue May 26 22:09:49 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 26 May 2015 22:09:49 +0200
Subject: [R] [R-sig-ME] lme function to obtain pvalue for fixed effect
In-Reply-To: <CAHLnndY1hay+2sU-K+LSJrrzMJAZCtb4ef25BT_HYufxd07drw@mail.gmail.com>
References: <CAHLnndbj=DV3+Krw8gaEH8rBCzh9+Q2b+t0AwAUu9V7BfGwkVA@mail.gmail.com>
	<BLU406-EAS16766F94C10A98D0545848AC4CC0@phx.gbl>
	<CAHLnndY1hay+2sU-K+LSJrrzMJAZCtb4ef25BT_HYufxd07drw@mail.gmail.com>
Message-ID: <CAJuCY5ykuSex7iqwm-+V7fCAZrhD8h6U3B3Gb513qAYJs8G=Sg@mail.gmail.com>

Because they test different hypothesis.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-26 21:46 GMT+02:00 li li <hannah.hlx at gmail.com>:

> Thanks so much for replying.
> Yes LimerTest package could be used to get pvalues when using lmer
> function. But still the summary and anova function give different
> pvalues.
>    Hanna
>
> 2015-05-26 15:19 GMT-04:00, byron vinueza <byronvinu_8 at hotmail.com>:
> > You can use the lmerTest package .
> >
> >
> >
> >
> >
> > Enviado desde mi iPhone
> >
> >> El 26/5/2015, a las 13:18, li li <hannah.hlx at gmail.com> escribi?:
> >>
> >> Hi all,
> >>  I am using the lme function to run a random coefficient model. Please
> >> see
> >> output (mod1) as below.
> >>  I need to obtain the pvalue for the fixed effect. As you can see,
> >> the pvalues given using the summary function is different from the
> >> resutls given in anova function.
> >> Why should they be different and which one is the correct one to use?
> >>   Thanks!
> >>      Hanna
> >>
> >>
> >>> summary(mod1)
> >> Linear mixed-effects model fit by REML
> >> Data: minus20C1
> >>        AIC       BIC   logLik
> >>  -82.60042 -70.15763 49.30021
> >>
> >> Random effects:
> >> Formula: ~1 + months | lot
> >> Structure: General positive-definite, Log-Cholesky parametrization
> >>            StdDev       Corr
> >> (Intercept) 8.907584e-03 (Intr)
> >> months      6.039781e-05 -0.096
> >> Residual    4.471243e-02
> >>
> >> Fixed effects: ti ~ type * months
> >>                     Value   Std.Error DF   t-value p-value
> >> (Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
> >> type             0.13502089 0.026676101  4  5.061493  0.0072
> >> months          0.00804790 0.001218941 31  6.602368  0.0000
> >> type:months -0.00693679 0.002981859 31 -2.326329  0.0267
> >> Correlation:
> >>               (Intr) typ months
> >> type        -0.633
> >> months         -0.785  0.497
> >> type:months  0.321 -0.762 -0.409
> >>
> >> Standardized Within-Group Residuals:
> >>          Min            Q1           Med            Q3           Max
> >> -2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00
> >>
> >> Number of Observations: 39
> >> Number of Groups: 6
> >>> anova(mod1)
> >>            numDF denDF   F-value p-value
> >> (Intercept)     1    31 2084.0265  <.0001
> >> type            1     4   10.8957  0.0299
> >> months          1    31   38.3462  <.0001
> >> type:months     1    31    5.4118  0.0267
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Wed May 27 01:09:39 2015
From: hannah.hlx at gmail.com (li li)
Date: Tue, 26 May 2015 19:09:39 -0400
Subject: [R] different results from lme and lmer function
Message-ID: <CAHLnndawxUjg=rec6Y1eFMopk2GAqhPC3cDG2wr62+4cwiyTRg@mail.gmail.com>

Hi all,
  I am fitting a random slope and random intercept model using R. I
used both lme and lmer funciton for the same model. However I got
different results as shown below (different variance component
estimates and so on). I think that is really confusing. They should
produce close results. Anyone has any thoughts or suggestions. Also,
which one should be comparable to sas results?
 Thanks!
  Hanna

## using lme function
> mod_lme <- lme(ti  ~ type*months, random=~ 1+months|lot, na.action=na.omit,
+ data=one, control = lmeControl(opt = "optim"))
> summary(mod_lme)
Linear mixed-effects model fit by REML
 Data: one
        AIC       BIC   logLik
  -82.60042 -70.15763 49.30021

Random effects:
 Formula: ~1 + months | lot
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 8.907584e-03 (Intr)
months      6.039781e-05 -0.096
Residual    4.471243e-02

Fixed effects: ti ~ type * months
                     Value   Std.Error DF   t-value p-value
(Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
type            0.13502089 0.026676101  4  5.061493  0.0072
months          0.00804790 0.001218941 31  6.602368  0.0000
type:months -0.00693679 0.002981859 31 -2.326329  0.0267
 Correlation:
               (Intr) typPPQ months
type           -0.633
months         -0.785  0.497
type:months  0.321 -0.762 -0.409

Standardized Within-Group Residuals:
          Min            Q1           Med            Q3           Max
-2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00

Number of Observations: 39
Number of Groups: 6




###Using lmer function
> mod_lmer <-lmer(ti  ~ type*months+(1+months|lot), na.action=na.omit, data=one)
> summary(mod_lmer)
Linear mixed model fit by REML t-tests use Satterthwaite approximations to
  degrees of freedom [merModLmerTest]
Formula: ti ~ type * months + (1 + months | lot)
   Data: one

REML criterion at convergence: -98.8

Scaled residuals:
    Min      1Q  Median      3Q     Max
-2.1347 -0.2156 -0.0067  0.3615  2.0840

Random effects:
 Groups   Name        Variance  Std.Dev.  Corr
 lot      (Intercept) 2.870e-04 0.0169424
          months      4.135e-07 0.0006431 -1.00
 Residual             1.950e-03 0.0441644
Number of obs: 39, groups:  lot, 6

Fixed effects:
                Estimate Std. Error        df t value Pr(>|t|)
(Intercept)     0.258312   0.018661  4.820000  13.842 4.59e-05 ***
type         0.135021   0.028880  6.802000   4.675  0.00245 **
months          0.008048   0.001259 11.943000   6.390 3.53e-05 ***
type:months -0.006937   0.002991 28.910000  -2.319  0.02767 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) typPPQ months
type     -0.646
months      -0.825  0.533
type:month  0.347 -0.768 -0.421


From bbolker at gmail.com  Wed May 27 02:03:10 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 May 2015 20:03:10 -0400
Subject: [R] [R-sig-ME] different results from lme and lmer function
In-Reply-To: <CAHLnndawxUjg=rec6Y1eFMopk2GAqhPC3cDG2wr62+4cwiyTRg@mail.gmail.com>
References: <CAHLnndawxUjg=rec6Y1eFMopk2GAqhPC3cDG2wr62+4cwiyTRg@mail.gmail.com>
Message-ID: <CABghstTbase8N810vRNumX=kh-W-Cia0+rs9dMSw1REeojJPow@mail.gmail.com>

  These actually aren't terribly different from each other.  I suspect
that lmer is slightly closer to the correct answer, because lme
reports a "log-likelihood" (really -1/2 times the REML criterion) of
49.30021, while lmer reports a REML criterion of  -98.8 -> slightly
better fit at -R/2 = 49.4.  The residual sds are 0.0447 (lme) vs.
0.0442 (lmer); the intercept sd estimate is 0.016 vs 0.0089,
admittedly a bit low, and both month sds are very small.  lmer
indicates a singular fit (correlation of -1).    If you look at the
confidence intervals on these estimates (confint(fitted_model) in
lme4; intervals(fitted_model) in lme) I think you'll find that the
confidence intervals are much wider than these differences (you may
even find that lme reports that it can't give you the intervals
because the Hessian [curvature] matrix is not positive definite).

  Both should be comparable to SAS PROC MIXED results, I think, if
you get the syntax right ...

On Tue, May 26, 2015 at 7:09 PM, li li <hannah.hlx at gmail.com> wrote:
> Hi all,
>   I am fitting a random slope and random intercept model using R. I
> used both lme and lmer funciton for the same model. However I got
> different results as shown below (different variance component
> estimates and so on). I think that is really confusing. They should
> produce close results. Anyone has any thoughts or suggestions. Also,
> which one should be comparable to sas results?
>  Thanks!
>   Hanna
>
> ## using lme function
>> mod_lme <- lme(ti  ~ type*months, random=~ 1+months|lot, na.action=na.omit,
> + data=one, control = lmeControl(opt = "optim"))
>> summary(mod_lme)
> Linear mixed-effects model fit by REML
>  Data: one
>         AIC       BIC   logLik
>   -82.60042 -70.15763 49.30021
>
> Random effects:
>  Formula: ~1 + months | lot
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 8.907584e-03 (Intr)
> months      6.039781e-05 -0.096
> Residual    4.471243e-02
>
> Fixed effects: ti ~ type * months
>                      Value   Std.Error DF   t-value p-value
> (Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
> type            0.13502089 0.026676101  4  5.061493  0.0072
> months          0.00804790 0.001218941 31  6.602368  0.0000
> type:months -0.00693679 0.002981859 31 -2.326329  0.0267
>  Correlation:
>                (Intr) typPPQ months
> type           -0.633
> months         -0.785  0.497
> type:months  0.321 -0.762 -0.409
>
> Standardized Within-Group Residuals:
>           Min            Q1           Med            Q3           Max
> -2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00
>
> Number of Observations: 39
> Number of Groups: 6
>
>
>
>
> ###Using lmer function
>> mod_lmer <-lmer(ti  ~ type*months+(1+months|lot), na.action=na.omit, data=one)
>> summary(mod_lmer)
> Linear mixed model fit by REML t-tests use Satterthwaite approximations to
>   degrees of freedom [merModLmerTest]
> Formula: ti ~ type * months + (1 + months | lot)
>    Data: one
>
> REML criterion at convergence: -98.8
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -2.1347 -0.2156 -0.0067  0.3615  2.0840
>
> Random effects:
>  Groups   Name        Variance  Std.Dev.  Corr
>  lot      (Intercept) 2.870e-04 0.0169424
>           months      4.135e-07 0.0006431 -1.00
>  Residual             1.950e-03 0.0441644
> Number of obs: 39, groups:  lot, 6
>
> Fixed effects:
>                 Estimate Std. Error        df t value Pr(>|t|)
> (Intercept)     0.258312   0.018661  4.820000  13.842 4.59e-05 ***
> type         0.135021   0.028880  6.802000   4.675  0.00245 **
> months          0.008048   0.001259 11.943000   6.390 3.53e-05 ***
> type:months -0.006937   0.002991 28.910000  -2.319  0.02767 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) typPPQ months
> type     -0.646
> months      -0.825  0.533
> type:month  0.347 -0.768 -0.421
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Wed May 27 02:09:48 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 27 May 2015 00:09:48 +0000
Subject: [R] lme function to obtain pvalue for fixed effect
References: <CAHLnndbj=DV3+Krw8gaEH8rBCzh9+Q2b+t0AwAUu9V7BfGwkVA@mail.gmail.com>
Message-ID: <loom.20150527T020802-79@post.gmane.org>

li li <hannah.hlx <at> gmail.com> writes:

> 
> Hi all,
>   I am using the lme function to run a random coefficient model.
> Please see
> output (mod1) as below.

  Please don't cross-post to different R lists (this is explicitly
deprecated by the list policy: <http://www.r-project.org/mail.html>, 
"cross-posting is considered to be impolite").  r-sig-mixed-models
seems to be more appropriate for these questions.

  sincerely
    Ben Bolker


From jsorkin at grecc.umaryland.edu  Wed May 27 02:47:12 2015
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Tue, 26 May 2015 20:47:12 -0400
Subject: [R] [R-sig-ME] different results from lme and lmer function
In-Reply-To: <CABghstTbase8N810vRNumX=kh-W-Cia0+rs9dMSw1REeojJPow@mail.gmail.com>
References: <CAHLnndawxUjg=rec6Y1eFMopk2GAqhPC3cDG2wr62+4cwiyTRg@mail.gmail.com>
	<CABghstTbase8N810vRNumX=kh-W-Cia0+rs9dMSw1REeojJPow@mail.gmail.com>
Message-ID: <5564DBD6020000CB0012DD15@smtp.medicine.umaryland.edu>

Ben,
I doubt the very small difference in log likelihood gives much, if any
information about which model is a better fit. Even if we overlook the
limited precision of the estimate of the REML criterion, the difference
is so small as to me of minimal importance.
John

> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)


> On May 26, 2015, at 8:03 PM, Ben Bolker <bbolker at gmail.com> wrote:
> 
>  These actually aren't terribly different from each other.  I suspect
> that lmer is slightly closer to the correct answer, because lme
> reports a "log-likelihood" (really -1/2 times the REML criterion) of
> 49.30021, while lmer reports a REML criterion of  -98.8 -> slightly
> better fit at -R/2 = 49.4.  The residual sds are 0.0447 (lme) vs.
> 0.0442 (lmer); the intercept sd estimate is 0.016 vs 0.0089,
> admittedly a bit low, and both month sds are very small.  lmer
> indicates a singular fit (correlation of -1).    If you look at the
> confidence intervals on these estimates (confint(fitted_model) in
> lme4; intervals(fitted_model) in lme) I think you'll find that the
> confidence intervals are much wider than these differences (you may
> even find that lme reports that it can't give you the intervals
> because the Hessian [curvature] matrix is not positive definite).
> 
>  Both should be comparable to SAS PROC MIXED results, I think, if
> you get the syntax right ...
> 
>> On Tue, May 26, 2015 at 7:09 PM, li li <hannah.hlx at gmail.com> wrote:
>> Hi all,
>>  I am fitting a random slope and random intercept model using R. I
>> used both lme and lmer funciton for the same model. However I got
>> different results as shown below (different variance component
>> estimates and so on). I think that is really confusing. They should
>> produce close results. Anyone has any thoughts or suggestions. Also,
>> which one should be comparable to sas results?
>> Thanks!
>>  Hanna
>> 
>> ## using lme function
>>> mod_lme <- lme(ti  ~ type*months, random=~ 1+months|lot,
na.action=na.omit,
>> + data=one, control = lmeControl(opt = "optim"))
>>> summary(mod_lme)
>> Linear mixed-effects model fit by REML
>> Data: one
>>        AIC       BIC   logLik
>>  -82.60042 -70.15763 49.30021
>> 
>> Random effects:
>> Formula: ~1 + months | lot
>> Structure: General positive-definite, Log-Cholesky parametrization
>>            StdDev       Corr
>> (Intercept) 8.907584e-03 (Intr)
>> months      6.039781e-05 -0.096
>> Residual    4.471243e-02
>> 
>> Fixed effects: ti ~ type * months
>>                     Value   Std.Error DF   t-value p-value
>> (Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
>> type            0.13502089 0.026676101  4  5.061493  0.0072
>> months          0.00804790 0.001218941 31  6.602368  0.0000
>> type:months -0.00693679 0.002981859 31 -2.326329  0.0267
>> Correlation:
>>               (Intr) typPPQ months
>> type           -0.633
>> months         -0.785  0.497
>> type:months  0.321 -0.762 -0.409
>> 
>> Standardized Within-Group Residuals:
>>          Min            Q1           Med            Q3           Max
>> -2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00
>> 
>> Number of Observations: 39
>> Number of Groups: 6
>> 
>> 
>> 
>> 
>> ###Using lmer function
>>> mod_lmer <-lmer(ti  ~ type*months+(1+months|lot), na.action=na.omit,
data=one)
>>> summary(mod_lmer)
>> Linear mixed model fit by REML t-tests use Satterthwaite
approximations to
>>  degrees of freedom [merModLmerTest]
>> Formula: ti ~ type * months + (1 + months | lot)
>>   Data: one
>> 
>> REML criterion at convergence: -98.8
>> 
>> Scaled residuals:
>>    Min      1Q  Median      3Q     Max
>> -2.1347 -0.2156 -0.0067  0.>> lot      (Intercept) 2.870e-04 0.0169424
>>          months      4.135e-07 0.0006431 -1.00
>> Residual             1.950e-03 0.0441644
>> Number of obs: 39, groups:  lot, 6
>> 
>> Fixed effects:
>>                Estimate Std. Error        df t value Pr(>|t|)
>> (Intercept)     0.258312   0.018661  4.820000  13.842 4.59e-05 ***
>> type         0.135021   0.028880  6.802000   4.675  0.00245 **
>> months          0.008048   0.001259 11.943000   6.390 3.53e-05 ***
>> type:months -0.006937   0.002991 28.910000  -2.319  0.02767 *
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> 
>> Correlation of Fixed Effects:
>>            (Intr) typPPQ months
>> type     -0.646
>> months      -0.825  0.533
>> type:month  0.347 -0.768 -0.421
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Confidentiality Statement:
This email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is
prohibited. If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 

From dan.abner99 at gmail.com  Wed May 27 03:30:49 2015
From: dan.abner99 at gmail.com (Dan Abner)
Date: Tue, 26 May 2015 21:30:49 -0400
Subject: [R] Find and replace backslashes XXXX
Message-ID: <CAPRGo-nWEegO2OStRUQfeJNcC_88gy1qx-DQOkdaLe6LZq9iPw@mail.gmail.com>

Hi all,

I realize that the backslash is an escape character in R, therefore, I
am trying to replace it with a forward slash. Can someone please
suggest how to get this code to work?

> lib<-gsub("\","/","X:\Classes\TT\Automation")
Error: unexpected symbol in "lib<-gsub("\","/","X"


Thanks,

Dan


From istazahn at gmail.com  Wed May 27 03:56:58 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 26 May 2015 21:56:58 -0400
Subject: [R] Find and replace backslashes XXXX
In-Reply-To: <CAPRGo-nWEegO2OStRUQfeJNcC_88gy1qx-DQOkdaLe6LZq9iPw@mail.gmail.com>
References: <CAPRGo-nWEegO2OStRUQfeJNcC_88gy1qx-DQOkdaLe6LZq9iPw@mail.gmail.com>
Message-ID: <CA+vqiLG0NDkcfQQCGMd_5E-CkUr9PuAbbAanXL2cOSrzWhi2PQ@mail.gmail.com>

Escape the backslash with another backslash, i.e.,

gsub("\\","/","X:\\Classes\\TT\\Automation", fixed = TRUE)

best,
Ista

On Tue, May 26, 2015 at 9:30 PM, Dan Abner <dan.abner99 at gmail.com> wrote:
> Hi all,
>
> I realize that the backslash is an escape character in R, therefore, I
> am trying to replace it with a forward slash. Can someone please
> suggest how to get this code to work?
>
>> lib<-gsub("\","/","X:\Classes\TT\Automation")
> Error: unexpected symbol in "lib<-gsub("\","/","X"
>
>
> Thanks,
>
> Dan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bluehonour at yahoo.com  Wed May 27 00:59:34 2015
From: bluehonour at yahoo.com (blue honour)
Date: Tue, 26 May 2015 22:59:34 +0000 (UTC)
Subject: [R] Retrieving data from nested lists
Message-ID: <114097949.2723666.1432681174171.JavaMail.yahoo@mail.yahoo.com>

Dear R users,
I have a question regarding retrieving data from nested lists. To illustrate, here is an example input:
d1<-data.table(v1=c(3,4),v2=c(2,5))
d2<-data.table(v1=c(1,2),v2=c(1,1))l1<-list(d1,name="test")l2<-list(d2,name="test2")motherlist<-list()motherlist$l1<-l1motherlist$l2<-l2
Let's say we are given motherlist as above. We would like to get the union of the contents of v1 vector from d1 data.table and the v1 vector from d2 data.table. How can we achieve this in a compact one line command using motherlist as input please??
Thank you.?



	[[alternative HTML version deleted]]


From burbrink666 at gmail.com  Wed May 27 02:12:55 2015
From: burbrink666 at gmail.com (Frank Burbrink)
Date: Tue, 26 May 2015 20:12:55 -0400
Subject: [R] Problem merging data frames and duplicates
Message-ID: <CAAbnQ5gJ_B-pqz2+z15+yCXGqBobje0aOVMkSOgQVxVuacMnNg@mail.gmail.com>

Hello All,

I am attempting to merge two data frames that naturally contain duplicate
entries, however when using either merge or dMerge I get even more
duplicates.

For example:

data.frame(state=c("IL", "IL", "LA","LA", "MS","MS", "AR", "AR"),
locus=c(1,1,2,2,3,4,5,6))->x

data.frame(state=c("IL", "IL", "AR", "AR", "TN","TN"),
locus=c(1,1,2,3,3,4,4))->y

These yield:

 x
  state locus
1    IL     1
2    IL     1
3    LA     2
4    LA     2
5    MS     3
6    MS     4
7    AR     5
8    AR     6

y
  state locus
1    IL     1
2    IL     1
3    AR     2
4    AR     3
5    TN     3
6    TN     4

However, when merged by "state: they produce another second set of AR and
IL:
merge(x,y,by=1,all=T)->z

   state locus.x locus.y
1     AR       5       2
2     AR       5       3
3     AR       6       2
4     AR       6       3
5     IL       1       1
6     IL       1       1
7     IL       1       1
8     IL       1       1
9     LA       2      NA
10    LA       2      NA
11    MS       3      NA
12    MS       4      NA
13    TN      NA       3
14    TN      NA       4

While, the NAs are desired when states are missing, I don't want the extra
duplicated states and values but rather:

   state locus.x locus.y
1     AR       5       2
4     AR       6       3
7     IL       1       1
8     IL       1       1
9     LA       2      NA
10    LA       2      NA
11    MS       3      NA
12    MS       4      NA
13    TN      NA       3
14    TN      NA       4

Any help would be much appreciated.

Thanks!

Frank

-- 

*************************************
*Frank T. Burbrink, Ph.D.*
*Professor*
*Biology Department*
*6S-143*
*2800 Victory Blvd.*
*College of Staten Island/CUNY*
*Staten Island, New York 10314*
*E-Mail:Frank.Burbrink at csi.cuny.edu <E-Mail%3AFrank.Burbrink at csi.cuny.edu>*
*Phone:718-982-3961*
*Web Page: http://scholar.library.csi.cuny.edu/~fburbrink/
<http://scholar.library.csi.cuny.edu/%7Efburbrink/>*
*************************************
*Chair *
*Ecology, Evolutionary Biology, and Behavior*
*Doctoral Subprogram*
*Biology Program*
*City University of New York *
*Graduate Center*
*365 Fifth Avenue*
*New York, NY 10016-4309*
************************************

	[[alternative HTML version deleted]]


From mxalimohamma at ualr.edu  Wed May 27 03:11:08 2015
From: mxalimohamma at ualr.edu (Mohammad Alimohammadi)
Date: Tue, 26 May 2015 20:11:08 -0500
Subject: [R] Problem with comparing multiple data sets
Message-ID: <CAJVfk9nuZDJdadGobNHDTP2cY_a06XrLZYj8x8393+LeB0OWfg@mail.gmail.com>

Thank you John. Yes. as you mentioned this is not really what I am looking
for.

It's interesting because I was really thinking that it should be pretty
easy. All I need to do is just compare class1, class2 and class3 for each
text and put the most frequent number next to it in each row. Repeat it for
all the rows. Apparently it's not that simple.

Sorry I didn't notice that I sent it only to you! Thanks for letting me
know.

I appreciate if anybody can help on this.

Thank you.




On Tue, May 26, 2015 at 7:27 PM, John Kane <jrkrideau at inbox.com> wrote:

> Hi Mohammad,
>
> The data came through beautifully despite the fact that you posted in
> HTML.  Please, post in plain text.
>
> Oh, just as I was ready to push Send, I  noticed you only replied to me.
> You really should reply to the R-help list since there are a lot more and
> better people to help there. Besides it's a world-wide list. Others can
> play with the problem while we sleep :) .
>
> I will just reply to you but I really suggest sending all of this to the
> list.
>
> Now I am wondering what to do with the data. As a first swipe I just added
> up all the values in each class by each text value. Results are below. Not
> what you want by any means but perhaps a small step.
>
> Then I started to think are we really interested in the sum or should we
> be looking at incidence, that is should we be looking at the frequency
> rather than the sum?
>
> Is
> class.1 class.2   class  #dac
>   0           2              0
>
> a value of 2 (sum) or a hit of 1 (count or freq) ?
>
> Anyway below is what I have tried so far -- it may not be anywhere near
> what you want but if it makes any sense then I think we just need to pick
> off the highest values for each combination of terms and class to give you
> what you want.
>
> I suspect our real data-munging gurus can do  all this faster and better
> than I can but hopefully it is a start.
>
> Where your data set is dat1
> #=====================================
> # If reshape2 is not installed.
> install.packages("reshape2")
> #=====================================
>
> library(reshape2)
>  mdat  <-  melt(dat1, id.vars= c("terms"),
>        variable.name = "class",
>        value.name = "value",
>        na.rm = FALSE)
>
> mdat1  <-  aggregate(value ~ terms + class, data = mdat, sum)
>
> mdat1[order(mdat1$terms, mdat1$class), ]
>
> #=====================================
>
>
> John Kane
> Kingston ON Canada
>
> -----Original Message-----
> From: mxalimohamma at ualr.edu
> Sent: Tue, 26 May 2015 09:50:43 -0500
> To: jrkrideau at inbox.com
> Subject: Re: [R] Problem with comparing multiple data sets
>
> Thank you John for being patient with me.
>
> My original post was to compare 3 sets of data which had difference in
> their class value for the same text. However, I thought it might be easier
> to combine those 3 data sets into one that shows the 3 different classes
> and then find the most frequent class value for the text. So that's what I
> did. Now I only want to add the most frequent class value in a new column.
>
> I tried to create a dput version of the data set (Only a small part of it)
> so you can see. I hope it works.
>
> > Tweet1<- read.csv(file="part1_complete.csv",head=TRUE,sep= ",")
>
> > dput(head(Tweet1, 100))
>
> structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
>
> 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 0L, 1L, 2L, 2L, 2L, 1L, 1L, 1L,
>
> 1L, 2L, 1L, 1L, 1L, 0L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L), class.2 = c(2L,
>
> 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>
> 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L,
>
> 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L,
>
> 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 1L), class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
>
> 1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L, 0L, 2L, 2L, 0L, 2L, 1L, 1L, 1L,
>
> 1L, 0L, 0L, 0L, 2L, 1L, 0L, 0L, 1L, 0L, 0L, 2L, 2L, 2L, 2L, 2L,
>
> 0L, 2L, 2L, 1L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L), terms = structure(c(9L,
>
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
>
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
>
> 9L, 9L, 9L, 9L, 69L, 69L, 69L, 69L, 69L, 40L, 40L, 40L, 40L,
>
> 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 98L, 98L, 98L, 98L, 98L,
>
> 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 23L, 87L, 87L, 87L,
>
> 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L,
>
> 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L,
>
> 87L, 87L), .Label = c("#accountability",
> "#accountability,#anonymity,anonymity",
>
> "#accountability,recovery", "#anonymity,anonymity",
> "#anonymous,anonymous",
>
> "#attacker,security", "#authentication,access control", "#confidential",
>
> "#dac", "#encryption,#privacy,#security", "#identifier",
> "#identifier,identifier",
>
> "#intrusion,#security,security", "#mac", "#mac,#security",
> "#mac,password",
>
> "#mac,security", "#password,privacy", "#password,security",
> "#prevention,prevention",
>
> "#privacy,#security,password", "#privacy,identifiable",
> "#privacy,information privacy,privacy",
>
> "#privacy,intrusion", "#privacy,location privacy,privacy",
> "#privacy,password,security",
>
> "#privacy,personal data", "#privacy,personal information,privacy",
>
> "#privacy,security", "#pseudonym", "#pseudonymity",
> "#security,authentication,identity management",
>
> "#security,identity management,security", "#security,mac,security",
>
> "#security,malicious,security", "#security,personal information",
>
> "#security,retention", "#token", "#token,token",
> "accountability,anonymous",
>
> "accountability,audit trail", "accountability,confidential",
>
> "accountability,security", "accountability,token", "adversary,pin",
>
> "anonymity,authentication", "anonymity,security", "anonymous,disclosure",
>
> "anonymous,password", "authentication,password,security",
> "authorization,mac",
>
> "authorization,permission", "confidential,disclosure",
> "confidential,disclosure,security",
>
> "confidential,mac", "confidential,personal information",
> "confidential,pin",
>
> "confidential,privilege", "confidentiality,security", "consent",
>
> "dac", "dac,pcm", "data aggregation,privacy", "data controller",
>
> "data protection,encryption", "data protection,recovery", "data
> protection,security",
>
> "data quality,security", "data security,encryption,security",
>
> "data security,mac,security", "data security,personal data,security",
>
> "data security,prevention,security", "detection", "detection,mac",
>
> "detection,password", "deterrence,prevention", "digital signature",
>
> "disclosure,password", "disclosure,private information",
> "disclosure,security",
>
> "encryption,password,recovery", "encryption,private data", "id
> management,privacy",
>
> "id management,security", "identifier", "identifier,token", "location
> privacy,privacy",
>
> "mac,password,security", "mac,permission", "mac,prevention",
>
> "mac,privacy", "mac,pseudonym", "malicious,prevention", "non-repudiation",
>
> "password,prevention,security", "password,private information",
>
> "password,recovery", "password,user id", "permission,personal data",
>
> "permission,privacy,privacy policy", "personal data", "personal
> identification number,pin",
>
> "personal information", "personal information,security", "prevention",
>
> "prevention,privilege", "privacy,privacy policy", "privacy,privacy
> preferences",
>
> "private information,security", "recovery,retention", "recovery,token",
>
> "retention,token", "sensitive data", "token"), class = "factor")), .Names
> = c("class.1",
>
> "class.2", "class.3", "terms"), row.names = c(NA, 100L), class =
> "data.frame")
>
> On Mon, May 25, 2015 at 2:04 PM, John Kane <jrkrideau at inbox.com> wrote:
>
>         Hi Mohammad,
>
>  If you are just starting with R a sense of total confusion is often the
> first feeling.  Welcome :).
>
>  If you are a SAS or SPSS user this may help
> https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf
> [
> https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf
> ]
>
>  If anything,  I am even more lost than before.
>
>  Did Jim Lemon's approach help? Confuse ?
>
>  Perhaps one of the problems is that the data did not come through
> cleanly.  You posted in HTML and the R-help list strips out all HTML so the
> result often is mangled beyond any real use.
>
>  I may have imagined that your data are more complicated than they really
> are if all you really want is some kind of frequency count possibly by some
> conditioning variable. Is this it?
>
>   It seems too simple but that is what I read that Excel is doing (as
> incompetently as usual---I had not realised it was possible to be even less
> impressed with Excel than I already  was.)
>
>  Can you send us some more data in dput() format. See the links I provided
> earlier or have a look at ?dput for more information.
>
>  If you have lot of data, a representative sample is fine.  It is often
> enough to do something like :
>  dput(head(mydata, 100))
>  which supplies 100 rows of data.
>
>  Just output the dput() data, copy and paste into your email,  et voil?
> we have the exact same data.
>
>  The reason for dput() is that it provides a snapshot of exactly how the
> data exists on your machine. Given all sorts of differences between OS's,
> personal settings, human languages and so on. what I or another R-help
> reader see  or read in may not correspond to what you have. Using dput()
> avoids all of this.
>
>  Here is a simple example of what I mean. If you look at dat1 and dat2
> they 'look' the same but ... I could read in data either way depending on
> all sorts of variable and have no idea which, if either is how you see the
> data.
>
>   Data are supplied in dput() format, just copy and paste into R.
>  =====
>  dat1  <- structure(list(aa = structure(1:10, .Label = c("1", "2", "3",
>  "4", "5", "6", "7", "8", "9", "10"), class = "factor"), bb = c(10L,
>  9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L, 1L)), .Names = c("aa", "bb"), row.names =
> c(NA,
>  -10L), class = "data.frame")
>
>  dat2  <-  structure(list(aa = 1:10, bb = c(10L, 9L, 8L, 7L, 6L, 5L, 4L,
>  3L, 2L, 1L)), .Names = c("aa", "bb"), row.names = c(NA, -10L), class =
> "data.frame")
>
>  dat1
>  dat2  # looks a lot like dat1
>
>  with(dat1, aa*bb)
>  with(dat2 , aa*bb)
>
>  str(dat1)
>  str(dat2)
>
>  =======
>
>  John Kane
>  Kingston ON Canada
>
>  -----Original Message-----
>  From: mxalimohamma at ualr.edu
>  Sent: Mon, 25 May 2015 12:14:46 -0500
>  To: jrkrideau at inbox.com
>  Subject: Re: [R] Problem with comparing multiple data sets
>
>  Hi John.
>
>  Thank you for your response.
>
>  Here is a small portion of my actual data set. What I am supposed to do
> is to use a function similar to mode function in excel to find the most
> frequent value (class) for each term.
>
>    V1 V2 V3 V4
>
>  1 class 1 class 2 class 3 terms
>
>  2 0 2 0 #dac
>
>  3 0 2          0 #dac
>
>  4 0 2 0 #dac
>
>  5 0 2 0 #dac
>
>  6 1 0 1 #dac
>
>  7 0 0 0 #dac
>
>  ....
>
>  Since I just started using R. I don't know where I am going with this. I
> appreciate any help.
>
>  On Sat, May 23, 2015 at 8:23 AM, John Kane <jrkrideau at inbox.com> wrote:
>
>          Hi Mohammad
>
>   Welcome to the R-help list.
>
>   There probably is a fairly easy way to what you want but I think we
> probably need a bit more background information on what you are trying to
> achieve.  I know I'm not exactly clear on your decision rule(s).
>
>   It would also be very useful to see some actual sample data in useable R
> format.Have a look at these links
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> [
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]
> [
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> [
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]]
> and http://adv-r.had.co.nz/Reproducibility.html [
> http://adv-r.had.co.nz/Reproducibility.html] [
> http://adv-r.had.co.nz/Reproducibility.html [
> http://adv-r.had.co.nz/Reproducibility.html]] for some hints on what you
> might want to include in your question.
>
>   In particular, read up about dput()  in those links and/or see ?dput.
> This is the generally preferred way to supply sample or illustrative data
> to the R-help list.  It basically creates a perfect copy of the data as it
> exists on 'your' machine so that R-help readers see exactly what you do.
>
>   John Kane
>   Kingston ON Canada
>
>   > -----Original Message-----
>   > From: mxalimohamma at ualr.edu
>   > Sent: Fri, 22 May 2015 12:37:50 -0500
>   > To: r-help at r-project.org
>   > Subject: [R] Problem with comparing multiple data sets
>   >
>   > Hi everyone,
>   >
>   > I am very new to R and I have a task to do. I appreciate any help. I
> have
>   > 3
>   > data sets. Each data set has 4 columns. For example:
>   >
>   > Class  Comment   Term   Text
>   > 0           com1        aac    text1
>   > 2           com2        aax    text2
>   > 1           com3        vvx    text3
>   >
>   > Now I need t compare the class section between 3 data sets and assign
> the
>   > most available class to that text. For example if text1 is assigned to
>   > class 0 in data set 1&2 but assigned as 2 in data set 3 then it should
> be
>   > assigned to class 0. If they are all the same so the class will be the
>   > same. The ideal thing would be to keep the same format and just update
>   > the
>   > class. Is there any easy way to do this?
>   >
>   > Thanks a lot.
>   >
>
>  >       [[alternative HTML version deleted]]
>   >
>   > ______________________________________________
>   > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
>  > https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help] [
> https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help]]
>   > PLEASE do read the posting guide
>   > http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html] [
> http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html]]
>   > and provide commented, minimal, self-contained, reproducible code.
>
>   ____________________________________________________________
>   FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>   Check it out at http://www.inbox.com/earth [http://www.inbox.com/earth]
> [http://www.inbox.com/earth [http://www.inbox.com/earth]]
>
>  --
>
>  Mohammad Alimohammadi | Graduate Assistant
>  University of Arkansas at Little Rock | College of Science
> and Mathematics (CSAM)
>
>  501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu] [
> http://ualr.edu/ [http://ualr.edu/]]
>
>  Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
> http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [
> http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
> http://scholar.google.com/citations?user=MsfN_i8AAAAJ]]
>
>  ____________________________________________________________
>  FREE ONLINE PHOTOSHARING - Share your photos online with your friends and
> family!
>  Visit http://www.inbox.com/photosharing [
> http://www.inbox.com/photosharing] to find out more!
>
> --
>
> Mohammad Alimohammadi | Graduate Assistant
> University of Arkansas at Little Rock | College of Science and Mathematics
> (CSAM)
>
> 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu/]
>
> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
> http://scholar.google.com/citations?user=MsfN_i8AAAAJ]
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> Check it out at http://www.inbox.com/earth
>
>
>


-- 
Mohammad Alimohammadi | Graduate Assistant
University of Arkansas at Little Rock | College of Science and Mathematics
(CSAM)
501.346.8007 | mxalimohamma at ualr.edu | ualr.edu

Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ

	[[alternative HTML version deleted]]


From lestat_90 at hotmail.com  Wed May 27 03:12:23 2015
From: lestat_90 at hotmail.com (Renato Rivera)
Date: Tue, 26 May 2015 20:12:23 -0500
Subject: [R] X11 font problem
Message-ID: <BLU179-W18EA0AE019F3BA11F1FC3182CB0@phx.gbl>

Hi I have this problem and do not know how to solve it, I'm new to R

R version 2.15.0 (2012-03-30)
Copyright (C) 2012 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

x11 font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 1 at size 16 could not be loaded 		 	   		  
	[[alternative HTML version deleted]]


From oussa.belm at hotmail.com  Wed May 27 03:23:35 2015
From: oussa.belm at hotmail.com (oussama belmejdoub)
Date: Wed, 27 May 2015 01:23:35 +0000
Subject: [R] nls model singular gradient matrix at initial parameter
	estimates
Message-ID: <DUB109-W3681A8069B5CE24D6E75A79CCB0@phx.gbl>

Greetings,
I'm trying to use the nls function in my statistics project but I'm really finding lot of difficulties.
I have a function called apinene_modele_prediction that calculates the estimations:
library(expm); #exp of a matrixapinene_modele_prediction <- function(t,theta) {	x0=c(100,0,0,0,0)	A=matrix(c(-(theta[1]+theta[2]),theta[1],theta[2],0,0,0,0,0,0,0,0,0,-(theta[3]+theta[4]),theta[3],theta[4],0,0,0,0,0,0,0,theta[5],0,-theta[5]),5,5)	X=x0	for (i in t[2:length(t)]){		X=c(X,x0%*%expm(A*i))		}return(X)}

My "t" vector is given by: 
t=seq(0,100,by=2) 
And the real observations "y" ara given to us  in a txt file called "data.txt" that I have joined to this message.
So when I try to fit the "theta" in my model starting with: theta=c(0.2,0.2,0.2,0.2,0.2) 
And doing:
theta_appr <-nls(y~apinene_modele_prediction(t,theta),start=list(theta=c(0.2,0.2,0.2,0.2,0.2)))
I always got the ERROR : singular gradient matrix at initial parameter estimates
And, when I try: nls(y~apinene_modele_prediction(t,c(theta,theta,theta,theta,theta)),start=list(theta=0.2))
I got the result: Nonlinear regression model  model: y ~ apinene_modele_prediction(t, c(theta, theta, theta, theta,     theta))   data: parent.frame()  theta0.04403 residual sum-of-squares: 219002
But I need to have the elements of the theta to be different and not equal.
Thanks in advance for your help. 		 	   		  
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: data.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150527/37052351/attachment.txt>

From luca.cerone at gmail.com  Wed May 27 09:29:37 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Wed, 27 May 2015 09:29:37 +0200
Subject: [R] Remove entry with sensitive information from history
Message-ID: <CAFnz2-9_tQLzea4u_jHuedr0_KTKY9NVCD+4=_WTxrH4bvv4AQ@mail.gmail.com>

Hi everybody,

in one of my packages I store encrypted password.

If the user has to change the password in use she can run:

update_password(old_password, new_password)

The problem is that the commands ends up in the .Rhistory file.

Is there any way I can avoid this? Any suggestion about it?

Cheers,
Luca


From dwinsemius at comcast.net  Wed May 27 09:31:06 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 27 May 2015 00:31:06 -0700
Subject: [R] Retrieving data from nested lists
In-Reply-To: <114097949.2723666.1432681174171.JavaMail.yahoo@mail.yahoo.com>
References: <114097949.2723666.1432681174171.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <70DC3060-0EE8-452A-8C5C-28FDD0BE894F@comcast.net>


On May 26, 2015, at 3:59 PM, blue honour via R-help wrote:

> Dear R users,
> I have a question regarding retrieving data from nested lists. To illustrate, here is an example input:
> d1<-data.table(v1=c(3,4),v2=c(2,5))
> d2<-data.table(v1=c(1,2),v2=c(1,1))l1<-list(d1,name="test")l2<-list(d2,name="test2")motherlist<-list()motherlist$l1<-l1motherlist$l2<-l2
> Let's say we are given motherlist as above. We would like to get the union of the contents of v1 vector from d1 data.table and the v1 vector from d2 data.table. How can we achieve this in a compact one line command using motherlist as input please? 
> Thank you. 
> 
> 
> 
> 	[[alternative HTML version deleted]]

Your posting is a good example of the reason we ask people _not_ to post in HTNL. Linefeeds (among many other useful bits of information) get lost:

d1<-data.table(v1=c(3,4),v2=c(2,5))
d2<-data.table(v1=c(1,2),v2=c(1,1))
l1<-list(d1,name="test")
l2<-list(d2,name="test2")
motherlist<-list()
motherlist$l1<-l1
motherlist$l2<-l2



> with( motherlist, c( l1[1][[1]]$v1, l2[1][[1]]$v1) )
[1] 3 4 1 2

OR:
> with( motherlist, c( l1[[1]]$v1, l2[[1]]$v1) )
[1] 3 4 1 2

That used the inheritance of data.tables from data.frames. This is data.table extraction syntax:

> with( motherlist, c( l1[[1]][ ,v1], l2[[1]][ ,v1]) )
[1] 3 4 1 2

Another approach with the display of intermediate values:

> sapply(motherlist, "[", 1)
$l1
   v1 v2
1:  3  2
2:  4  5

$l2
   v1 v2
1:  1  1
2:  2  1

> sapply( sapply(motherlist, "[", 1) , "[[", 1)
     l1 l2
[1,]  3  1
[2,]  4  2

> c( sapply( sapply(motherlist, "[", 1) , "[[", 1) )
[1] 3 4 1 2

Please read the posting guide.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ripley at stats.ox.ac.uk  Wed May 27 09:40:14 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 27 May 2015 08:40:14 +0100
Subject: [R] X11 font problem
In-Reply-To: <BLU179-W18EA0AE019F3BA11F1FC3182CB0@phx.gbl>
References: <BLU179-W18EA0AE019F3BA11F1FC3182CB0@phx.gbl>
Message-ID: <556574DE.1030004@stats.ox.ac.uk>

On 27/05/2015 02:12, Renato Rivera wrote:
> Hi I have this problem and do not know how to solve it, I'm new to R
>
> R version 2.15.0 (2012-03-30)

That is a very old version of R: the posting guide asked you to update 
before posting.

> Copyright (C) 2012 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-unknown-linux-gnu (64-bit)

Which is not very specific.  The posting guide asks for sesssionInfo(): 
on a current version of R that would tell which Linux distro.

>
> x11 font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 1 at size 16 could not be loaded 		 	   		

You read the manual, the current version of which is at 
http://cran.r-project.org/doc/manuals/r-release/R-admin.html#Useful-libraries-and-programs 
, starting 'For the best font experience with these devices you need 
suitable fonts installed '.

You should also check

capabilities('cairo')

if that is false (as I suspect), read the parts about cairo support and 
reinstall R with cairo support.


> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
PLEASE do.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From dwinsemius at comcast.net  Wed May 27 09:45:14 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 27 May 2015 00:45:14 -0700
Subject: [R] Remove entry with sensitive information from history
In-Reply-To: <CAFnz2-9_tQLzea4u_jHuedr0_KTKY9NVCD+4=_WTxrH4bvv4AQ@mail.gmail.com>
References: <CAFnz2-9_tQLzea4u_jHuedr0_KTKY9NVCD+4=_WTxrH4bvv4AQ@mail.gmail.com>
Message-ID: <7A139850-417B-48C7-A487-7B6D8F6D64F2@comcast.net>


On May 27, 2015, at 12:29 AM, Luca Cerone wrote:

> Hi everybody,
> 
> in one of my packages I store encrypted password.
> 
> If the user has to change the password in use she can run:
> 
> update_password(old_password, new_password)
> 
> The problem is that the commands ends up in the .Rhistory file.
> 
> Is there any way I can avoid this? Any suggestion about it?
> 

Write a small password verification program in Rcpp or tcl and then call it to handle the dialog. In the past Greg Snow has suggested: "The tkexamp function in the TeachingDemos package can help with creating tcltk dialog boxes. "

-- 

David Winsemius
Alameda, CA, USA


From wjm1 at caa.columbia.edu  Wed May 27 09:53:38 2015
From: wjm1 at caa.columbia.edu (William Michels)
Date: Wed, 27 May 2015 00:53:38 -0700
Subject: [R] Problem merging data frames and duplicates
In-Reply-To: <CAAbnQ5gJ_B-pqz2+z15+yCXGqBobje0aOVMkSOgQVxVuacMnNg@mail.gmail.com>
References: <CAAbnQ5gJ_B-pqz2+z15+yCXGqBobje0aOVMkSOgQVxVuacMnNg@mail.gmail.com>
Message-ID: <CAA99HCyqULLzW2aodnwZ2epPWP+MSX+Q6-TGM6tRk5Ro=D-EaQ@mail.gmail.com>

Hi Frank,

It looks like you're very close. I think you want:

unique(merge(x, y, by = 1, all=T))

Gabor Grothendieck's sqldf package is very useful if you're more
comfortable with SQL-type syntax, see:

https://github.com/ggrothendieck/sqldf

Best Regards,

William (Bill) Michels, Ph.D.



On Tue, May 26, 2015 at 5:12 PM, Frank Burbrink
<burbrink666 at gmail.com> wrote: <SNIP>


From daisy.duursma at gmail.com  Wed May 27 08:35:12 2015
From: daisy.duursma at gmail.com (Daisy Englert Duursma)
Date: Wed, 27 May 2015 16:35:12 +1000
Subject: [R] Identifying peak periods of observations in circular yearly data
Message-ID: <CAFf2dDGACuVMUurKT9TsPv=xWJNcCgx=tgBSdWFJp4TO2himTg@mail.gmail.com>

Greetings,

I am trying to identify at which point during the year 80% of bird breeding
observations are. typically I would answer a question like this by finding
the median or quartiles but how do I deal with situations where the 80% of
the is from day 285 through day 366 (leap year) and extends to day 30?

The data is circular and and day 365 is as close to day 366 as day 1.

I am reading the manual for CircStats and circular but I could really use
some help on this.


Here is some dummy data:


obsDay<-c(rep(1:30,10),rep(45:65,2),65:180,rep(181:265,2),rep(266:330,4),rep(331:366,6))

plot(density(obsDay))



-- 
Daisy Englert Duursma
Department of Biological Sciences
Room W19F 135
Macquarie University, North Ryde, NSW 2109
Australia

Tel +61 2 9850 1302

	[[alternative HTML version deleted]]


From luca.cerone at gmail.com  Wed May 27 10:17:44 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Wed, 27 May 2015 10:17:44 +0200
Subject: [R] Remove entry with sensitive information from history
In-Reply-To: <7A139850-417B-48C7-A487-7B6D8F6D64F2@comcast.net>
References: <CAFnz2-9_tQLzea4u_jHuedr0_KTKY9NVCD+4=_WTxrH4bvv4AQ@mail.gmail.com>
	<7A139850-417B-48C7-A487-7B6D8F6D64F2@comcast.net>
Message-ID: <CAFnz2-83_zPeK99SUNuB-h1a_3DZiv_gwRB3-+nYsQVx4wDbjg@mail.gmail.com>

Hi David, thanks, but the function has to work from an R shell, I have
no graphical server in my remote machines.

On Wed, May 27, 2015 at 9:45 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On May 27, 2015, at 12:29 AM, Luca Cerone wrote:
>
>> Hi everybody,
>>
>> in one of my packages I store encrypted password.
>>
>> If the user has to change the password in use she can run:
>>
>> update_password(old_password, new_password)
>>
>> The problem is that the commands ends up in the .Rhistory file.
>>
>> Is there any way I can avoid this? Any suggestion about it?
>>
>
> Write a small password verification program in Rcpp or tcl and then call it to handle the dialog. In the past Greg Snow has suggested: "The tkexamp function in the TeachingDemos package can help with creating tcltk dialog boxes. "
>
> --
>
> David Winsemius
> Alameda, CA, USA
>


From ripley at stats.ox.ac.uk  Wed May 27 11:06:44 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 27 May 2015 10:06:44 +0100
Subject: [R] Remove entry with sensitive information from history
In-Reply-To: <CAFnz2-83_zPeK99SUNuB-h1a_3DZiv_gwRB3-+nYsQVx4wDbjg@mail.gmail.com>
References: <CAFnz2-9_tQLzea4u_jHuedr0_KTKY9NVCD+4=_WTxrH4bvv4AQ@mail.gmail.com>	<7A139850-417B-48C7-A487-7B6D8F6D64F2@comcast.net>
	<CAFnz2-83_zPeK99SUNuB-h1a_3DZiv_gwRB3-+nYsQVx4wDbjg@mail.gmail.com>
Message-ID: <55658924.8010007@stats.ox.ac.uk>

On 27/05/2015 09:17, Luca Cerone wrote:
> Hi David, thanks, but the function has to work from an R shell, I have
> no graphical server in my remote machines.

My suggestion was going to be to use readline() to read the passwords. 
Ideally one would use a custom reader from stdin which did not echo, but 
that is not possible without knowledge of the terminal/console in use 
(which is hard to do portably), nor in general.  One could do what some 
password readers (e.g. that on iOS) do, and after each character is 
entered backspace and overwrite by x or dot.

>
> On Wed, May 27, 2015 at 9:45 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>> On May 27, 2015, at 12:29 AM, Luca Cerone wrote:
>>
>>> Hi everybody,
>>>
>>> in one of my packages I store encrypted password.
>>>
>>> If the user has to change the password in use she can run:
>>>
>>> update_password(old_password, new_password)
>>>
>>> The problem is that the commands ends up in the .Rhistory file.
>>>
>>> Is there any way I can avoid this? Any suggestion about it?
>>>
>>
>> Write a small password verification program in Rcpp or tcl and then call it to handle the dialog. In the past Greg Snow has suggested: "The tkexamp function in the TeachingDemos package can help with creating tcltk dialog boxes. "
>>
>> --
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From drjimlemon at gmail.com  Wed May 27 11:34:04 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 27 May 2015 19:34:04 +1000
Subject: [R] Identifying peak periods of observations in circular yearly
	data
In-Reply-To: <CAFf2dDGACuVMUurKT9TsPv=xWJNcCgx=tgBSdWFJp4TO2himTg@mail.gmail.com>
References: <CAFf2dDGACuVMUurKT9TsPv=xWJNcCgx=tgBSdWFJp4TO2himTg@mail.gmail.com>
Message-ID: <CA+8X3fU=gQLh1d5hAmD0aZZ9t=1Qys6OuLt2H3HcJ3r0XzpSzA@mail.gmail.com>

Hi Daisy,
You face a problem similar to one with which I have grappled in
different fields. The year is designed for the northern hemisphere,
beginning and ending in less productive biologic states in those
regions. I have previously argued that since the calendar year is an
arbitrary progression, it makes more sense to redraw the annual
boundary when examining things like this in the southern hemisphere.
That is to say, a "year" is conventionally marked at about the
northern winter solstice. Down here, this becomes the summer solstice
and breaks up a lot of things that happen around that time. Have you
thought of defining a southern bird-watching year as beginning and
ending at the southern winter solstice? As I am currently writing in
an entirely different context, it shouldn't really make much
difference.

Jim


On Wed, May 27, 2015 at 4:35 PM, Daisy Englert Duursma
<daisy.duursma at gmail.com> wrote:
> Greetings,
>
> I am trying to identify at which point during the year 80% of bird breeding
> observations are. typically I would answer a question like this by finding
> the median or quartiles but how do I deal with situations where the 80% of
> the is from day 285 through day 366 (leap year) and extends to day 30?
>
> The data is circular and and day 365 is as close to day 366 as day 1.
>
> I am reading the manual for CircStats and circular but I could really use
> some help on this.
>
>
> Here is some dummy data:
>
>
> obsDay<-c(rep(1:30,10),rep(45:65,2),65:180,rep(181:265,2),rep(266:330,4),rep(331:366,6))
>
> plot(density(obsDay))
>
>
>
> --
> Daisy Englert Duursma
> Department of Biological Sciences
> Room W19F 135
> Macquarie University, North Ryde, NSW 2109
> Australia
>
> Tel +61 2 9850 1302
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From shivibhatia at ymail.com  Wed May 27 11:28:56 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Wed, 27 May 2015 02:28:56 -0700 (PDT)
Subject: [R] Help on Histogram ~ Barplot
Message-ID: <1432718936755-4707739.post@n4.nabble.com>

Hello All,
I need help on creating a histogram for one of my data. The data is as below
(sample):
MFST_WT	Hours	PROCESS	Month	Weekday	Day of the Month
6,828	13	       INBOUND	Mar	             Fri	13
2,504	16	       INBOUND	Mar	             Fri	27
20	        16	       INBOUND	Mar	             Fri	27
10,262	16	       INBOUND	Mar	             Fri	27
2,500	17	       INBOUND	Mar	             Fri	13
3,938	16	       INBOUND	Feb	            Thu	26
798	        10	       INBOUND	Feb	            Sat	14
5,439	15	       INBOUND	Feb	            Mon	16

This data has these columns and total rows are 45000. 
Now I need to group the data and create a bar plot based on total weight on
a monthly basis. The code I have used is:
barplot(mwlc$MFST_WT, names.arg = mwlc$Month, las=2, ylim=c(0,10000), col
="red",
        border="orange", main="Monthly Weight")
but this is showing an error. Please suggest. 




--
View this message in context: http://r.789695.n4.nabble.com/Help-on-Histogram-Barplot-tp4707739.html
Sent from the R help mailing list archive at Nabble.com.


From henrik.bengtsson at ucsf.edu  Wed May 27 12:13:13 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Wed, 27 May 2015 03:13:13 -0700
Subject: [R] Remove entry with sensitive information from history
In-Reply-To: <55658924.8010007@stats.ox.ac.uk>
References: <CAFnz2-9_tQLzea4u_jHuedr0_KTKY9NVCD+4=_WTxrH4bvv4AQ@mail.gmail.com>
	<7A139850-417B-48C7-A487-7B6D8F6D64F2@comcast.net>
	<CAFnz2-83_zPeK99SUNuB-h1a_3DZiv_gwRB3-+nYsQVx4wDbjg@mail.gmail.com>
	<55658924.8010007@stats.ox.ac.uk>
Message-ID: <CAFDcVCRqzgOzy4cG2eLy0ZBSkzfQWKYXkLEosQ5njsnbApP04A@mail.gmail.com>

To answer your question on filtering the command-line history: You can
use savehistory()/loadhistory() to rewrite the history, but like all
other solutions/suggestions, it's not guaranteed to work everywhere.
Example:

filterhistory <- function(filter) {
  stopifnot(is.function(filter))
  hf <- tempfile()
  on.exit(file.remove(hf))
  savehistory(hf)
  history <- readLines(hf)
  historyF <- filter(history)
  ## Always write the same number of history lines as
  ## read to make sure everything is overwritten,
  ## cf. 'R_HISTSIZE' in help('savehistory').
  ndropped <- length(history)-length(historyF)
  clear <- rep("'<command-line history erased>'", times=ndropped)
  historyF <- c(clear, historyF)

  writeLines(historyF, con=hf)
  loadhistory(hf)
}

update_password <- function(...) {
  filterhistory(filter=function(x) {
    str(x)
    start <- grep("update_password", x, fixed=TRUE)[1]
    x[seq_len(start-1L)]
  })
  ## ...
  cat("Hello world!\n")
}

This won't work if someone does:

foo <- update_password

and calls foo().  Then you need to use a more clever filter function,
e.g. one that drops the last call, which may be spread out on multiple
lines so not just the last line.

/Henrik

On Wed, May 27, 2015 at 2:06 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On 27/05/2015 09:17, Luca Cerone wrote:
>>
>> Hi David, thanks, but the function has to work from an R shell, I have
>> no graphical server in my remote machines.
>
>
> My suggestion was going to be to use readline() to read the passwords.
> Ideally one would use a custom reader from stdin which did not echo, but
> that is not possible without knowledge of the terminal/console in use (which
> is hard to do portably), nor in general.  One could do what some password
> readers (e.g. that on iOS) do, and after each character is entered backspace
> and overwrite by x or dot.
>
>
>>
>> On Wed, May 27, 2015 at 9:45 AM, David Winsemius <dwinsemius at comcast.net>
>> wrote:
>>>
>>>
>>> On May 27, 2015, at 12:29 AM, Luca Cerone wrote:
>>>
>>>> Hi everybody,
>>>>
>>>> in one of my packages I store encrypted password.
>>>>
>>>> If the user has to change the password in use she can run:
>>>>
>>>> update_password(old_password, new_password)
>>>>
>>>> The problem is that the commands ends up in the .Rhistory file.
>>>>
>>>> Is there any way I can avoid this? Any suggestion about it?
>>>>
>>>
>>> Write a small password verification program in Rcpp or tcl and then call
>>> it to handle the dialog. In the past Greg Snow has suggested: "The tkexamp
>>> function in the TeachingDemos package can help with creating tcltk dialog
>>> boxes. "
>>>
>>> --
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed May 27 12:49:39 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 27 May 2015 20:49:39 +1000
Subject: [R] Help on Histogram ~ Barplot
In-Reply-To: <1432718936755-4707739.post@n4.nabble.com>
References: <1432718936755-4707739.post@n4.nabble.com>
Message-ID: <CA+8X3fUtZaEbU2Aq_zdHA13vehCq5xFi4ZCmzn_emfXUimY5vg@mail.gmail.com>

Hi Shivi82,
My suggestion is that the error concerned a mismatch between the
number of labels and the number of bars.

More seriously, you seem to want to sum the values of weight (MFST_WT)
within each month. So:

tot_mon_wt<-by(mwlc$MFST_WT,mwlc$Month,sum)
barplot(tot_mon_wt, names.arg = sort(unique(mwlc$Month)), las=2,
  ylim=c(0,25000),col="red",border="orange", main="Monthly Weight")

Jim


On Wed, May 27, 2015 at 7:28 PM, Shivi82 <shivibhatia at ymail.com> wrote:
> Hello All,
> I need help on creating a histogram for one of my data. The data is as below
> (sample):
> MFST_WT Hours   PROCESS Month   Weekday Day of the Month
> 6,828   13             INBOUND  Mar                  Fri        13
> 2,504   16             INBOUND  Mar                  Fri        27
> 20              16             INBOUND  Mar                  Fri        27
> 10,262  16             INBOUND  Mar                  Fri        27
> 2,500   17             INBOUND  Mar                  Fri        13
> 3,938   16             INBOUND  Feb                 Thu 26
> 798             10             INBOUND  Feb                 Sat 14
> 5,439   15             INBOUND  Feb                 Mon 16
>
> This data has these columns and total rows are 45000.
> Now I need to group the data and create a bar plot based on total weight on
> a monthly basis. The code I have used is:
> barplot(mwlc$MFST_WT, names.arg = mwlc$Month, las=2, ylim=c(0,10000), col
> ="red",
>         border="orange", main="Monthly Weight")
> but this is showing an error. Please suggest.
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Help-on-Histogram-Barplot-tp4707739.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed May 27 13:10:22 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 27 May 2015 07:10:22 -0400
Subject: [R] Find and replace backslashes XXXX
In-Reply-To: <CA+vqiLG0NDkcfQQCGMd_5E-CkUr9PuAbbAanXL2cOSrzWhi2PQ@mail.gmail.com>
References: <CAPRGo-nWEegO2OStRUQfeJNcC_88gy1qx-DQOkdaLe6LZq9iPw@mail.gmail.com>
	<CA+vqiLG0NDkcfQQCGMd_5E-CkUr9PuAbbAanXL2cOSrzWhi2PQ@mail.gmail.com>
Message-ID: <5565A61E.9020106@gmail.com>

On 26/05/2015 9:56 PM, Ista Zahn wrote:
> Escape the backslash with another backslash, i.e.,
> 
> gsub("\\","/","X:\\Classes\\TT\\Automation", fixed = TRUE)

... and note that if you want to use a regular expression (i.e. fixed =
FALSE), you would need another level of escaping, i.e.

gsub("\\\\","/","X:\\Classes\\TT\\Automation")

The second level of escaping is for the regexpr processor.  It would
need to be done in the first or second strings, but not in the third,
which is the data.

Duncan Murdoch


> 
> best,
> Ista
> 
> On Tue, May 26, 2015 at 9:30 PM, Dan Abner <dan.abner99 at gmail.com> wrote:
>> Hi all,
>>
>> I realize that the backslash is an escape character in R, therefore, I
>> am trying to replace it with a forward slash. Can someone please
>> suggest how to get this code to work?
>>
>>> lib<-gsub("\","/","X:\Classes\TT\Automation")
>> Error: unexpected symbol in "lib<-gsub("\","/","X"
>>
>>
>> Thanks,
>>
>> Dan
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From shivibhatia at ymail.com  Wed May 27 12:56:04 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Wed, 27 May 2015 03:56:04 -0700 (PDT)
Subject: [R] Help on Histogram ~ Barplot
In-Reply-To: <CA+8X3fUtZaEbU2Aq_zdHA13vehCq5xFi4ZCmzn_emfXUimY5vg@mail.gmail.com>
References: <1432718936755-4707739.post@n4.nabble.com>
	<CA+8X3fUtZaEbU2Aq_zdHA13vehCq5xFi4ZCmzn_emfXUimY5vg@mail.gmail.com>
Message-ID: <1432724164295-4707744.post@n4.nabble.com>

HI Jim,

Thanks for the help however R throws an error when i create a var
tot_mon_wt- 
tot_mon_wt<-by(mwlc$MFST_WT,mwlc$Month,sum). It gives me an error = 
Error in Summary.factor(c(1L, 1L), na.rm = FALSE) : 
  ?sum? not meaningful for factors

Not sure what this error refers to. Thank you, Shivi



--
View this message in context: http://r.789695.n4.nabble.com/Help-on-Histogram-Barplot-tp4707739p4707744.html
Sent from the R help mailing list archive at Nabble.com.


From thierry.onkelinx at inbo.be  Wed May 27 13:25:10 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 27 May 2015 13:25:10 +0200
Subject: [R] Find and replace backslashes XXXX
In-Reply-To: <5565A61E.9020106@gmail.com>
References: <CAPRGo-nWEegO2OStRUQfeJNcC_88gy1qx-DQOkdaLe6LZq9iPw@mail.gmail.com>
	<CA+vqiLG0NDkcfQQCGMd_5E-CkUr9PuAbbAanXL2cOSrzWhi2PQ@mail.gmail.com>
	<5565A61E.9020106@gmail.com>
Message-ID: <CAJuCY5z7sB8ELjSiiqoyCh36RV1xrdmrk5qBSNkTQWqs8xDVHQ@mail.gmail.com>

Since the character looks like a Windows file path, you could use
normalizePath() instead of gsub().

normalizePath("X:\\Classes\\TT\\Automation", winslash = "/", mustWork =
FALSE)

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-27 13:10 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 26/05/2015 9:56 PM, Ista Zahn wrote:
> > Escape the backslash with another backslash, i.e.,
> >
> > gsub("\\","/","X:\\Classes\\TT\\Automation", fixed = TRUE)
>
> ... and note that if you want to use a regular expression (i.e. fixed =
> FALSE), you would need another level of escaping, i.e.
>
> gsub("\\\\","/","X:\\Classes\\TT\\Automation")
>
> The second level of escaping is for the regexpr processor.  It would
> need to be done in the first or second strings, but not in the third,
> which is the data.
>
> Duncan Murdoch
>
>
> >
> > best,
> > Ista
> >
> > On Tue, May 26, 2015 at 9:30 PM, Dan Abner <dan.abner99 at gmail.com>
> wrote:
> >> Hi all,
> >>
> >> I realize that the backslash is an escape character in R, therefore, I
> >> am trying to replace it with a forward slash. Can someone please
> >> suggest how to get this code to work?
> >>
> >>> lib<-gsub("\","/","X:\Classes\TT\Automation")
> >> Error: unexpected symbol in "lib<-gsub("\","/","X"
> >>
> >>
> >> Thanks,
> >>
> >> Dan
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed May 27 13:37:21 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 27 May 2015 13:37:21 +0200
Subject: [R] R CMD methods and ggplot2 advice
In-Reply-To: <9057ac48-7cff-44b9-88a4-0c2fb24683b3@me.com>
References: <9057ac48-7cff-44b9-88a4-0c2fb24683b3@me.com>
Message-ID: <CAJuCY5ybP4mnC7sUtnwL_=9+XCeGAMAoO26ZiqRB=Sgo-aZnvQ@mail.gmail.com>

Dear Glenn,

Suppose this function

test <- function(df){
  ggplot(df, aes(x = gp, y = y)) + geom_point()
}

Then R CMD check will consider gp and y as global variables since they are
undefined. Because R CMD check cannot detect that gp and y will be
extracted from df by ggplot2.

Possible workarounds

# now gp and y are defined within the function. ggplot2 still looks for gp
and y in df.
test <- function(df){
  gp <- NULL
  y <- NULL
  ggplot(df, aes(x = gp, y = y)) + geom_point()
}

# now "gp" and "y" are strings and hence defined
test <- function(df){
  ggplot(df, aes_string(x = "gp", y = "y")) + geom_point()
}

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-26 2:24 GMT+02:00 Glenn Schultz <glennmschultz at me.com>:

> Hello All,
>
> I have two packages Bond Lab and the Companion to Investing in MBS.  Bond
> Lab clears the check and I am working on the on.load() to copy a needed
> directory per Duncan Murdoch's advise to make Bond Lab CRAN-able.  The
> companion passes with two notes.  The output is below:
>
> I get two notes (highlighted in red)
>
> Not sure on this one as I tried to declare methods but I get another note
> methods declared but not used.  The second note is related to ggplot2 they
> are variable passed to ggplot2 within a function.  I am not sure why they
> appear in the R CMD check.  If someone could point in the right direction
> to resolve these I would appreciate the advice.  These are my last
> remaining two issues to make the packages pass CRAN aside from the on.load()
>
> Best Regards,
> Glenn
>
> * checking dependencies in R code ... NOTE
> package ?methods? is used but not declared
>
>
> * checking R code for possible problems ... NOTE
> CreditEnhancement: no visible binding for global variable ?Period?
> CreditEnhancement: no visible binding for global variable ?Value?
> CreditEnhancement: no visible binding for global variable ?Variable?
> CreditEnhancement: no visible binding for global variable ?..density..?
> PassThrough.OAS: no visible binding for global variable ?value?
> PassThrough.OAS: no visible binding for global variable ?..density..?
> PassThroughCashFlow: no visible binding for global variable ?Period?
> PassThroughCashFlow: no visible binding for global variable ?value?
> PassThroughCashFlow: no visible binding for global variable ?variable?
> PlotMtgKeyRates: no visible binding for global variable ?Tenor?
> PlotMtgKeyRates: no visible binding for global variable ?Duration?
> PlotTermStructure: no visible binding for global variable ?value?
> PlotTermStructure: no visible binding for global variable ?variable?
> REMICOAS: no visible binding for global variable ?value?
> REMICOAS: no visible binding for global variable ?..density..?
> TotalReturn: no visible binding for global variable ?Scenario?
> TotalReturn: no visible binding for global variable ?value?
> TotalReturn: no visible binding for global variable ?variable?
> TwistScenario: no visible binding for global variable ?Scenario?
> TwistScenario: no visible binding for global variable ?Return?
> ValuationFramework: no visible binding for global variable ?value?
> ValuationFramework: no visible binding for global variable ?variable?
>
> ==> devtools::check()
>
> Updating Companion2IMBS documentation
> Loading Companion2IMBS
> '/Library/Frameworks/R.framework/Resources/bin/R' --vanilla CMD build  \
>   '/Users/glennschultz/Companion to Investing in MBS' --no-resave-data  \
>   --no-manual
>
> * checking for file ?/Users/glennschultz/Companion to Investing in
> MBS/DESCRIPTION? ... OK
> * preparing ?Companion2IMBS?:
> * checking DESCRIPTION meta-information ... OK
> * checking for LF line-endings in source and make files
> * checking for empty or unneeded directories
> Removed empty directory ?Companion2IMBS/inst?
> Removed empty directory ?Companion2IMBS/test/testthat?
> Removed empty directory ?Companion2IMBS/test?
> * building ?Companion2IMBS_1.0.tar.gz?
>
> '/Library/Frameworks/R.framework/Resources/bin/R' --vanilla CMD check  \
>
> '/var/folders/tv/sq6gmnvs13j8jrhkt87f_zmc0000gn/T//RtmpOabREs/Companion2IMBS_1.0.tar.gz'
>  \
>   --timings
>
> * using log directory ?/Users/glennschultz/Companion2IMBS.Rcheck?
> * using R version 3.0.3 (2014-03-06)
> * using platform: x86_64-apple-darwin10.8.0 (64-bit)
> * using session charset: UTF-8
> * checking for file ?Companion2IMBS/DESCRIPTION? ... OK
> * checking extension type ... Package
> * this is package ?Companion2IMBS? version ?1.0?
> * checking package namespace information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking if there is a namespace ... OK
> * checking for executable files ... OK
> * checking for hidden files and directories ... OK
> * checking for portable file names ... OK
> * checking for sufficient/correct file permissions ... OK
> * checking whether package ?Companion2IMBS? can be installed ... OK
> * checking installed package size ... OK
> * checking package directory ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking for left-over files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for non-ASCII characters ... OK
> * checking R files for syntax errors ... OK
> * checking whether the package can be loaded ... OK
> * checking whether the package can be loaded with stated dependencies ...
> OK
> * checking whether the package can be unloaded cleanly ... OK
> * checking whether the namespace can be loaded with stated dependencies
> ... OK
> * checking whether the namespace can be unloaded cleanly ... OK
> * checking dependencies in R code ... NOTE
> package ?methods? is used but not declared
> See the information on DESCRIPTION files in the chapter ?Creating R
> packages? of the ?Writing R Extensions? manual.
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... OK
> * checking R code for possible problems ... NOTE
> CreditEnhancement: no visible binding for global variable ?Period?
> CreditEnhancement: no visible binding for global variable ?Value?
> CreditEnhancement: no visible binding for global variable ?Variable?
> CreditEnhancement: no visible binding for global variable ?..density..?
> PassThrough.OAS: no visible binding for global variable ?value?
> PassThrough.OAS: no visible binding for global variable ?..density..?
> PassThroughCashFlow: no visible binding for global variable ?Period?
> PassThroughCashFlow: no visible binding for global variable ?value?
> PassThroughCashFlow: no visible binding for global variable ?variable?
> PlotMtgKeyRates: no visible binding for global variable ?Tenor?
> PlotMtgKeyRates: no visible binding for global variable ?Duration?
> PlotTermStructure: no visible binding for global variable ?value?
> PlotTermStructure: no visible binding for global variable ?variable?
> REMICOAS: no visible binding for global variable ?value?
> REMICOAS: no visible binding for global variable ?..density..?
> TotalReturn: no visible binding for global variable ?Scenario?
> TotalReturn: no visible binding for global variable ?value?
> TotalReturn: no visible binding for global variable ?variable?
> TwistScenario: no visible binding for global variable ?Scenario?
> TwistScenario: no visible binding for global variable ?Return?
> ValuationFramework: no visible binding for global variable ?value?
> ValuationFramework: no visible binding for global variable ?variable?
> * checking Rd files ... OK
> * checking Rd metadata ... OK
> * checking Rd line widths ... OK
> * checking Rd cross-references ... OK
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... OK
> * checking Rd \usage sections ... OK
> * checking Rd contents ... OK
> * checking for unstated dependencies in examples ... OK
> * checking examples ... [60s/60s] OK
> Examples with CPU or elapsed time > 5s
>                     user system elapsed
> TwistScenario     18.827  1.037  19.872
> PassThrough.OAS   17.485  0.068  17.567
> CreditEnhancement 10.959  0.128  11.106
> PlotMtgKeyRates   10.081  0.421  10.506
> * checking PDF version of manual ... OK
> NOTE: There were 2 notes.
> See
>   ?/Users/glennschultz/Companion2IMBS.Rcheck/00check.log?
> for details.
>
>
>
> R CMD check succeeded
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From shivibhatia at ymail.com  Wed May 27 13:32:30 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Wed, 27 May 2015 04:32:30 -0700 (PDT)
Subject: [R] Printing with Header & no of observations
Message-ID: <1432726350155-4707747.post@n4.nabble.com>

HI Team,
A quick question.

When I used the print option in R to see the output of my syntax I do not
see the headers or column names. Is there a way to see the headers in the
print.
Also as most of the datasets we work today have huge number of observations
but when I print it only shows a portion of the output. Is there a
limitation to the number of rows that can be printed.

Kindly suggest. Thanks, Shivi



--
View this message in context: http://r.789695.n4.nabble.com/Printing-with-Header-no-of-observations-tp4707747.html
Sent from the R help mailing list archive at Nabble.com.


From lists at dewey.myzen.co.uk  Wed May 27 14:46:02 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 27 May 2015 13:46:02 +0100
Subject: [R] Help on Histogram ~ Barplot
In-Reply-To: <1432724164295-4707744.post@n4.nabble.com>
References: <1432718936755-4707739.post@n4.nabble.com>	<CA+8X3fUtZaEbU2Aq_zdHA13vehCq5xFi4ZCmzn_emfXUimY5vg@mail.gmail.com>
	<1432724164295-4707744.post@n4.nabble.com>
Message-ID: <5565BC8A.4090906@dewey.myzen.co.uk>



On 27/05/2015 11:56, Shivi82 wrote:
> HI Jim,
>
> Thanks for the help however R throws an error when i create a var
> tot_mon_wt-
> tot_mon_wt<-by(mwlc$MFST_WT,mwlc$Month,sum). It gives me an error =
> Error in Summary.factor(c(1L, 1L), na.rm = FALSE) :
>    ?sum? not meaningful for factors
>
> Not sure what this error refers to.

Dear Shivi
It means that you have tried to use sum on a variable which is a factor. 
You can easily convert it to numeric but if it were me I would want to 
find out how it got turned into a factor before I transformed it.

  Thank you, Shivi
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Help-on-Histogram-Barplot-tp4707739p4707744.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jrkrideau at inbox.com  Wed May 27 14:50:55 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 27 May 2015 04:50:55 -0800
Subject: [R] Problem merging data frames and duplicates
In-Reply-To: <CAAbnQ5gJ_B-pqz2+z15+yCXGqBobje0aOVMkSOgQVxVuacMnNg@mail.gmail.com>
Message-ID: <64FD9CDB2BB.00001391jrkrideau@inbox.com>

y has unequal n's . There are 6 states and 7 loci.  

It is safer to submit data in the dput() form. See ?dput for information.



John Kane
Kingston ON Canada


> -----Original Message-----
> From: burbrink666 at gmail.com
> Sent: Tue, 26 May 2015 20:12:55 -0400
> To: r-help at r-project.org
> Subject: [R] Problem merging data frames and duplicates
> 
> Hello All,
> 
> I am attempting to merge two data frames that naturally contain duplicate
> entries, however when using either merge or dMerge I get even more
> duplicates.
> 
> For example:
> 
> data.frame(state=c("IL", "IL", "LA","LA", "MS","MS", "AR", "AR"),
> locus=c(1,1,2,2,3,4,5,6))->x
> 
> data.frame(state=c("IL", "IL", "AR", "AR", "TN","TN"),
> locus=c(1,1,2,3,3,4,4))->y
> 
> These yield:
> 
>  x
>   state locus
> 1    IL     1
> 2    IL     1
> 3    LA     2
> 4    LA     2
> 5    MS     3
> 6    MS     4
> 7    AR     5
> 8    AR     6
> 
> y
>   state locus
> 1    IL     1
> 2    IL     1
> 3    AR     2
> 4    AR     3
> 5    TN     3
> 6    TN     4
> 
> However, when merged by "state: they produce another second set of AR and
> IL:
> merge(x,y,by=1,all=T)->z
> 
>    state locus.x locus.y
> 1     AR       5       2
> 2     AR       5       3
> 3     AR       6       2
> 4     AR       6       3
> 5     IL       1       1
> 6     IL       1       1
> 7     IL       1       1
> 8     IL       1       1
> 9     LA       2      NA
> 10    LA       2      NA
> 11    MS       3      NA
> 12    MS       4      NA
> 13    TN      NA       3
> 14    TN      NA       4
> 
> While, the NAs are desired when states are missing, I don't want the
> extra
> duplicated states and values but rather:
> 
>    state locus.x locus.y
> 1     AR       5       2
> 4     AR       6       3
> 7     IL       1       1
> 8     IL       1       1
> 9     LA       2      NA
> 10    LA       2      NA
> 11    MS       3      NA
> 12    MS       4      NA
> 13    TN      NA       3
> 14    TN      NA       4
> 
> Any help would be much appreciated.
> 
> Thanks!
> 
> Frank
> 
> --
> 
> *************************************
> *Frank T. Burbrink, Ph.D.*
> *Professor*
> *Biology Department*
> *6S-143*
> *2800 Victory Blvd.*
> *College of Staten Island/CUNY*
> *Staten Island, New York 10314*
> *E-Mail:Frank.Burbrink at csi.cuny.edu
> <E-Mail%3AFrank.Burbrink at csi.cuny.edu>*
> *Phone:718-982-3961*
> *Web Page: http://scholar.library.csi.cuny.edu/~fburbrink/
> <http://scholar.library.csi.cuny.edu/%7Efburbrink/>*
> *************************************
> *Chair *
> *Ecology, Evolutionary Biology, and Behavior*
> *Doctoral Subprogram*
> *Biology Program*
> *City University of New York *
> *Graduate Center*
> *365 Fifth Avenue*
> *New York, NY 10016-4309*
> ************************************
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From dan.abner99 at gmail.com  Wed May 27 14:55:29 2015
From: dan.abner99 at gmail.com (Dan Abner)
Date: Wed, 27 May 2015 08:55:29 -0400
Subject: [R] Find and replace backslashes XXXX
In-Reply-To: <CA+vqiLG0NDkcfQQCGMd_5E-CkUr9PuAbbAanXL2cOSrzWhi2PQ@mail.gmail.com>
References: <CAPRGo-nWEegO2OStRUQfeJNcC_88gy1qx-DQOkdaLe6LZq9iPw@mail.gmail.com>
	<CA+vqiLG0NDkcfQQCGMd_5E-CkUr9PuAbbAanXL2cOSrzWhi2PQ@mail.gmail.com>
Message-ID: <CAPRGo-=JpSOXEx1bdMXOU83HgcSo8UD3Ud85s0j-0Q5Yp64aeg@mail.gmail.com>

Hi Ista,

Is there no way to not escape the backslash in the pathway? The
pathway is going to change and will become very long and I need to do
this programmatically. Beside, escaping the backslash defeats the
purpose of using gsub. If I could do this manually each and every
time, I would change simply change the backslash to a forward slash
and therefore not need gsub at all...

Thanks,

Dan

On Tue, May 26, 2015 at 9:56 PM, Ista Zahn <istazahn at gmail.com> wrote:
> Escape the backslash with another backslash, i.e.,
>
> gsub("\\","/","X:\\Classes\\TT\\Automation", fixed = TRUE)
>
> best,
> Ista
>
> On Tue, May 26, 2015 at 9:30 PM, Dan Abner <dan.abner99 at gmail.com> wrote:
>> Hi all,
>>
>> I realize that the backslash is an escape character in R, therefore, I
>> am trying to replace it with a forward slash. Can someone please
>> suggest how to get this code to work?
>>
>>> lib<-gsub("\","/","X:\Classes\TT\Automation")
>> Error: unexpected symbol in "lib<-gsub("\","/","X"
>>
>>
>> Thanks,
>>
>> Dan
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From therneau at mayo.edu  Wed May 27 15:02:26 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 27 May 2015 08:02:26 -0500
Subject: [R] Logistic regression R and Stata grouping variable
In-Reply-To: <mailman.3.1432720802.12331.r-help@r-project.org>
References: <mailman.3.1432720802.12331.r-help@r-project.org>
Message-ID: <2f3a88$ncujq@ironport10.mayo.edu>

You were not completely clear, but it appears that you have data where each subject has 
results from 8 "trials", as a pair of variables is changed.  If that is correct, then you 
want to have a variance that corrects for the repeated measures.  In R the glm command 
handles the simple case but not the repeated measures one.  Statisticially you can use a 
generalized estimating equations approach (package "gee") or a random effect per subject 
approach (lme or lmer package).

Terry T.


On 05/27/2015 05:00 AM, r-help-request at r-project.org wrote:
> I mostly use Stata 13 for my regression analysis. I want to conduct a logistic regression on a proportion/number of success. Because I receive errors in Stata I did not expect nor understand (if there are Stata experts who want to know more about the problems I face and can potentially help me solve them, I would be glad to give more details), I want to repeat the analysis in R. In Stata I would use the command: xtlogit DEP_PROP INDEP_A INDEP_B INDEP_C, i(ID). ID is the identifier for each subject. There are eight lines with data for each subject because there are three within factors (INDEP_A, B, C) with two levels each (0 and 1). I can repeat this analysis in R by using the command: glm(DEP_SUC ~ INDEP_A + INDEP_B + INDEP_C, family = ?binomial?). DEP_SUC is here a table with the successes and misses per row. Again, there are eight rows for each subject. But while I know how to group these lines in Stata by using the option i(ID ), I do not know what to do in R. I have sear!
>   ch for more information about the i() command, but did not find any usefull information.
>
> So, to summarize: I want to find out how three variables (binary) influence a proportion and use logistic regression. In Stata I can group multiple lines per subject using the i( ) command in logistic regression. What is the equivalent in R?
>
> Thank you in advance!


From barry.king at qlx.com  Wed May 27 15:03:27 2015
From: barry.king at qlx.com (Barry King)
Date: Wed, 27 May 2015 09:03:27 -0400
Subject: [R] pls - No variable selection
Message-ID: <CAP8Wkrza77_T8kco64V7BcRJdByDcT6+E+H0RD8yWqXFo33cZw@mail.gmail.com>

I am attempting to use mixOmics' pls() on a problem with 16 rows
and 27 columns.  When I run pls I get the message "No variable selection."
I have included a small problem below that produces this message.
What am I doing wrong?  Any help is appreciated.


#===== Begin small reproducible sample program =====
library(mixOmics)

X <- matrix(c(2766, 2610, 3306, 3630,
              1492, 1419, 1369, 1158,
              2450, 2379, 2400, 2055,
              2751, 2883, 3492, 3570,
              2652, 2691, 3225, 3285,
              3993, 4722, 6147, 6720,
              4032, 4350, 5430, 5763,
              4530, 5190, 6910, 7580,
              4077, 4410, 5460, 5857,
              3450, 3432, 3969, 4020,
              4989, 5301, 6807, 7425,
              5340, 5790, 7590, 8390,
              3162, 3477, 4365, 4650,
              4380, 4695, 6018, 6510,
              4587, 4200, 5040, 5289,
              4017, 4725, 6090, 6570),
            ncol=4)
colnames(X) <- c("v1","v2","v3","v4")

Y <- matrix(c( 3.0110,
               0.0000,
               0.0000,
               1.4820,
               1.1160,
               3.3970,
               2.4280,
               4.0240,
               2.2750,
               0.9588,
               3.1900,
               4.1320,
               2.1600,
               3.0940,
               1.6040,
               3.1620),
            ncol=1)
colnames(Y) <- c("y")

mpls <- pls(X, Y,  mode="regression", ncomp=2)
mpls

#===== End small reproducible sample program, begin console output =====

Call:
 pls(X = X, Y = Y, mode = "regression")

 PLS with a 'regression' mode with 2 PLS components.
 You entered data X of dimensions: 16 4
 You entered data Y of dimensions: 16 1

 No variable selection.

 Available components:
 --------------------
 loading vectors: see object$loadings
 variates: see object$variates
 variable names: see object$names

#===== End console output =====

Barry King
Associate Professor of Information Technology
Butler University

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Wed May 27 15:05:38 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 27 May 2015 05:05:38 -0800
Subject: [R] Problem with comparing multiple data sets
In-Reply-To: <CAJVfk9nuZDJdadGobNHDTP2cY_a06XrLZYj8x8393+LeB0OWfg@mail.gmail.com>
Message-ID: <651E81B86BB.000013CBjrkrideau@inbox.com>

Hi Mohammad, 

I went back and reread your original statement of the problem about and I think I kinda grasp it. It is actually quite clear and I misunderstood it completely.

At the moment I have no idea how to approach it.  As Jim Lemon said, it looks easy but may not be.  I'll go back and re-examine Jim's approach.

You might want to create three sample data sets of the original data layouts and upload them, in dput() format, to the list.  It may be easier to tackle from that approach.

In any case, in the existing data set is a 2 a numeric value 2 or just an on/off indicator?  

John Kane
Kingston ON Canada


> -----Original Message-----
> From: mxalimohamma at ualr.edu
> Sent: Tue, 26 May 2015 20:11:08 -0500
> To: r-help at r-project.org
> Subject: Re: [R] Problem with comparing multiple data sets
> 
> Thank you John. Yes. as you mentioned this is not really what I am
> looking
> for.
> 
> It's interesting because I was really thinking that it should be pretty
> easy. All I need to do is just compare class1, class2 and class3 for each
> text and put the most frequent number next to it in each row. Repeat it
> for
> all the rows. Apparently it's not that simple.
> 
> Sorry I didn't notice that I sent it only to you! Thanks for letting me
> know.
> 
> I appreciate if anybody can help on this.
> 
> Thank you.
> 
> 
> 
> 
> On Tue, May 26, 2015 at 7:27 PM, John Kane <jrkrideau at inbox.com> wrote:
> 
>> Hi Mohammad,
>> 
>> The data came through beautifully despite the fact that you posted in
>> HTML.  Please, post in plain text.
>> 
>> Oh, just as I was ready to push Send, I  noticed you only replied to me.
>> You really should reply to the R-help list since there are a lot more
>> and
>> better people to help there. Besides it's a world-wide list. Others can
>> play with the problem while we sleep :) .
>> 
>> I will just reply to you but I really suggest sending all of this to the
>> list.
>> 
>> Now I am wondering what to do with the data. As a first swipe I just
>> added
>> up all the values in each class by each text value. Results are below.
>> Not
>> what you want by any means but perhaps a small step.
>> 
>> Then I started to think are we really interested in the sum or should we
>> be looking at incidence, that is should we be looking at the frequency
>> rather than the sum?
>> 
>> Is
>> class.1 class.2   class  #dac
>>   0           2              0
>> 
>> a value of 2 (sum) or a hit of 1 (count or freq) ?
>> 
>> Anyway below is what I have tried so far -- it may not be anywhere near
>> what you want but if it makes any sense then I think we just need to
>> pick
>> off the highest values for each combination of terms and class to give
>> you
>> what you want.
>> 
>> I suspect our real data-munging gurus can do  all this faster and better
>> than I can but hopefully it is a start.
>> 
>> Where your data set is dat1
>> #=====================================
>> # If reshape2 is not installed.
>> install.packages("reshape2")
>> #=====================================
>> 
>> library(reshape2)
>>  mdat  <-  melt(dat1, id.vars= c("terms"),
>>        variable.name = "class",
>>        value.name = "value",
>>        na.rm = FALSE)
>> 
>> mdat1  <-  aggregate(value ~ terms + class, data = mdat, sum)
>> 
>> mdat1[order(mdat1$terms, mdat1$class), ]
>> 
>> #=====================================
>> 
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> -----Original Message-----
>> From: mxalimohamma at ualr.edu
>> Sent: Tue, 26 May 2015 09:50:43 -0500
>> To: jrkrideau at inbox.com
>> Subject: Re: [R] Problem with comparing multiple data sets
>> 
>> Thank you John for being patient with me.
>> 
>> My original post was to compare 3 sets of data which had difference in
>> their class value for the same text. However, I thought it might be
>> easier
>> to combine those 3 data sets into one that shows the 3 different classes
>> and then find the most frequent class value for the text. So that's what
>> I
>> did. Now I only want to add the most frequent class value in a new
>> column.
>> 
>> I tried to create a dput version of the data set (Only a small part of
>> it)
>> so you can see. I hope it works.
>> 
>>> Tweet1<- read.csv(file="part1_complete.csv",head=TRUE,sep= ",")
>> 
>>> dput(head(Tweet1, 100))
>> 
>> structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
>> 
>> 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 0L, 1L, 2L, 2L, 2L, 1L, 1L, 1L,
>> 
>> 1L, 2L, 1L, 1L, 1L, 0L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L), class.2 = c(2L,
>> 
>> 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 
>> 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L,
>> 
>> 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L,
>> 
>> 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
>> 
>> 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 
>> 1L, 1L, 1L), class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
>> 
>> 1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L, 0L, 2L, 2L, 0L, 2L, 1L, 1L, 1L,
>> 
>> 1L, 0L, 0L, 0L, 2L, 1L, 0L, 0L, 1L, 0L, 0L, 2L, 2L, 2L, 2L, 2L,
>> 
>> 0L, 2L, 2L, 1L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
>> 
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L), terms = structure(c(9L,
>> 
>> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
>> 
>> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
>> 
>> 9L, 9L, 9L, 9L, 69L, 69L, 69L, 69L, 69L, 40L, 40L, 40L, 40L,
>> 
>> 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 98L, 98L, 98L, 98L, 98L,
>> 
>> 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 23L, 87L, 87L, 87L,
>> 
>> 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L,
>> 
>> 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L,
>> 
>> 87L, 87L), .Label = c("#accountability",
>> "#accountability,#anonymity,anonymity",
>> 
>> "#accountability,recovery", "#anonymity,anonymity",
>> "#anonymous,anonymous",
>> 
>> "#attacker,security", "#authentication,access control", "#confidential",
>> 
>> "#dac", "#encryption,#privacy,#security", "#identifier",
>> "#identifier,identifier",
>> 
>> "#intrusion,#security,security", "#mac", "#mac,#security",
>> "#mac,password",
>> 
>> "#mac,security", "#password,privacy", "#password,security",
>> "#prevention,prevention",
>> 
>> "#privacy,#security,password", "#privacy,identifiable",
>> "#privacy,information privacy,privacy",
>> 
>> "#privacy,intrusion", "#privacy,location privacy,privacy",
>> "#privacy,password,security",
>> 
>> "#privacy,personal data", "#privacy,personal information,privacy",
>> 
>> "#privacy,security", "#pseudonym", "#pseudonymity",
>> "#security,authentication,identity management",
>> 
>> "#security,identity management,security", "#security,mac,security",
>> 
>> "#security,malicious,security", "#security,personal information",
>> 
>> "#security,retention", "#token", "#token,token",
>> "accountability,anonymous",
>> 
>> "accountability,audit trail", "accountability,confidential",
>> 
>> "accountability,security", "accountability,token", "adversary,pin",
>> 
>> "anonymity,authentication", "anonymity,security",
>> "anonymous,disclosure",
>> 
>> "anonymous,password", "authentication,password,security",
>> "authorization,mac",
>> 
>> "authorization,permission", "confidential,disclosure",
>> "confidential,disclosure,security",
>> 
>> "confidential,mac", "confidential,personal information",
>> "confidential,pin",
>> 
>> "confidential,privilege", "confidentiality,security", "consent",
>> 
>> "dac", "dac,pcm", "data aggregation,privacy", "data controller",
>> 
>> "data protection,encryption", "data protection,recovery", "data
>> protection,security",
>> 
>> "data quality,security", "data security,encryption,security",
>> 
>> "data security,mac,security", "data security,personal data,security",
>> 
>> "data security,prevention,security", "detection", "detection,mac",
>> 
>> "detection,password", "deterrence,prevention", "digital signature",
>> 
>> "disclosure,password", "disclosure,private information",
>> "disclosure,security",
>> 
>> "encryption,password,recovery", "encryption,private data", "id
>> management,privacy",
>> 
>> "id management,security", "identifier", "identifier,token", "location
>> privacy,privacy",
>> 
>> "mac,password,security", "mac,permission", "mac,prevention",
>> 
>> "mac,privacy", "mac,pseudonym", "malicious,prevention",
>> "non-repudiation",
>> 
>> "password,prevention,security", "password,private information",
>> 
>> "password,recovery", "password,user id", "permission,personal data",
>> 
>> "permission,privacy,privacy policy", "personal data", "personal
>> identification number,pin",
>> 
>> "personal information", "personal information,security", "prevention",
>> 
>> "prevention,privilege", "privacy,privacy policy", "privacy,privacy
>> preferences",
>> 
>> "private information,security", "recovery,retention", "recovery,token",
>> 
>> "retention,token", "sensitive data", "token"), class = "factor")),
>> .Names
>> = c("class.1",
>> 
>> "class.2", "class.3", "terms"), row.names = c(NA, 100L), class =
>> "data.frame")
>> 
>> On Mon, May 25, 2015 at 2:04 PM, John Kane <jrkrideau at inbox.com> wrote:
>> 
>>         Hi Mohammad,
>> 
>>  If you are just starting with R a sense of total confusion is often the
>> first feeling.  Welcome :).
>> 
>>  If you are a SAS or SPSS user this may help
>> https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf
>> [
>> https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf
>> ]
>> 
>>  If anything,  I am even more lost than before.
>> 
>>  Did Jim Lemon's approach help? Confuse ?
>> 
>>  Perhaps one of the problems is that the data did not come through
>> cleanly.  You posted in HTML and the R-help list strips out all HTML so
>> the
>> result often is mangled beyond any real use.
>> 
>>  I may have imagined that your data are more complicated than they
>> really
>> are if all you really want is some kind of frequency count possibly by
>> some
>> conditioning variable. Is this it?
>> 
>>   It seems too simple but that is what I read that Excel is doing (as
>> incompetently as usual---I had not realised it was possible to be even
>> less
>> impressed with Excel than I already  was.)
>> 
>>  Can you send us some more data in dput() format. See the links I
>> provided
>> earlier or have a look at ?dput for more information.
>> 
>>  If you have lot of data, a representative sample is fine.  It is often
>> enough to do something like :
>>  dput(head(mydata, 100))
>>  which supplies 100 rows of data.
>> 
>>  Just output the dput() data, copy and paste into your email,  et voil?
>> we have the exact same data.
>> 
>>  The reason for dput() is that it provides a snapshot of exactly how the
>> data exists on your machine. Given all sorts of differences between
>> OS's,
>> personal settings, human languages and so on. what I or another R-help
>> reader see  or read in may not correspond to what you have. Using dput()
>> avoids all of this.
>> 
>>  Here is a simple example of what I mean. If you look at dat1 and dat2
>> they 'look' the same but ... I could read in data either way depending
>> on
>> all sorts of variable and have no idea which, if either is how you see
>> the
>> data.
>> 
>>   Data are supplied in dput() format, just copy and paste into R.
>>  =====
>>  dat1  <- structure(list(aa = structure(1:10, .Label = c("1", "2", "3",
>>  "4", "5", "6", "7", "8", "9", "10"), class = "factor"), bb = c(10L,
>>  9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L, 1L)), .Names = c("aa", "bb"), row.names
>> =
>> c(NA,
>>  -10L), class = "data.frame")
>> 
>>  dat2  <-  structure(list(aa = 1:10, bb = c(10L, 9L, 8L, 7L, 6L, 5L, 4L,
>>  3L, 2L, 1L)), .Names = c("aa", "bb"), row.names = c(NA, -10L), class =
>> "data.frame")
>> 
>>  dat1
>>  dat2  # looks a lot like dat1
>> 
>>  with(dat1, aa*bb)
>>  with(dat2 , aa*bb)
>> 
>>  str(dat1)
>>  str(dat2)
>> 
>>  =======
>> 
>>  John Kane
>>  Kingston ON Canada
>> 
>>  -----Original Message-----
>>  From: mxalimohamma at ualr.edu
>>  Sent: Mon, 25 May 2015 12:14:46 -0500
>>  To: jrkrideau at inbox.com
>>  Subject: Re: [R] Problem with comparing multiple data sets
>> 
>>  Hi John.
>> 
>>  Thank you for your response.
>> 
>>  Here is a small portion of my actual data set. What I am supposed to do
>> is to use a function similar to mode function in excel to find the most
>> frequent value (class) for each term.
>> 
>>    V1 V2 V3 V4
>> 
>>  1 class 1 class 2 class 3 terms
>> 
>>  2 0 2 0 #dac
>> 
>>  3 0 2          0 #dac
>> 
>>  4 0 2 0 #dac
>> 
>>  5 0 2 0 #dac
>> 
>>  6 1 0 1 #dac
>> 
>>  7 0 0 0 #dac
>> 
>>  ....
>> 
>>  Since I just started using R. I don't know where I am going with this.
>> I
>> appreciate any help.
>> 
>>  On Sat, May 23, 2015 at 8:23 AM, John Kane <jrkrideau at inbox.com> wrote:
>> 
>>          Hi Mohammad
>> 
>>   Welcome to the R-help list.
>> 
>>   There probably is a fairly easy way to what you want but I think we
>> probably need a bit more background information on what you are trying
>> to
>> achieve.  I know I'm not exactly clear on your decision rule(s).
>> 
>>   It would also be very useful to see some actual sample data in useable
>> R
>> format.Have a look at these links
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> [
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]
>> [
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> [
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]]
>> and http://adv-r.had.co.nz/Reproducibility.html [
>> http://adv-r.had.co.nz/Reproducibility.html] [
>> http://adv-r.had.co.nz/Reproducibility.html [
>> http://adv-r.had.co.nz/Reproducibility.html]] for some hints on what you
>> might want to include in your question.
>> 
>>   In particular, read up about dput()  in those links and/or see ?dput.
>> This is the generally preferred way to supply sample or illustrative
>> data
>> to the R-help list.  It basically creates a perfect copy of the data as
>> it
>> exists on 'your' machine so that R-help readers see exactly what you do.
>> 
>>   John Kane
>>   Kingston ON Canada
>> 
>>   > -----Original Message-----
>>   > From: mxalimohamma at ualr.edu
>>   > Sent: Fri, 22 May 2015 12:37:50 -0500
>>   > To: r-help at r-project.org
>>   > Subject: [R] Problem with comparing multiple data sets
>>   >
>>   > Hi everyone,
>>   >
>>   > I am very new to R and I have a task to do. I appreciate any help. I
>> have
>>   > 3
>>   > data sets. Each data set has 4 columns. For example:
>>   >
>>   > Class  Comment   Term   Text
>>   > 0           com1        aac    text1
>>   > 2           com2        aax    text2
>>   > 1           com3        vvx    text3
>>   >
>>   > Now I need t compare the class section between 3 data sets and
>> assign
>> the
>>   > most available class to that text. For example if text1 is assigned
>> to
>>   > class 0 in data set 1&2 but assigned as 2 in data set 3 then it
>> should
>> be
>>   > assigned to class 0. If they are all the same so the class will be
>> the
>>   > same. The ideal thing would be to keep the same format and just
>> update
>>   > the
>>   > class. Is there any easy way to do this?
>>   >
>>   > Thanks a lot.
>>   >
>> 
>>  >       [[alternative HTML version deleted]]
>>   >
>>   > ______________________________________________
>>   > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> 
>>  > https://stat.ethz.ch/mailman/listinfo/r-help [
>> https://stat.ethz.ch/mailman/listinfo/r-help] [
>> https://stat.ethz.ch/mailman/listinfo/r-help [
>> https://stat.ethz.ch/mailman/listinfo/r-help]]
>>   > PLEASE do read the posting guide
>>   > http://www.R-project.org/posting-guide.html [
>> http://www.R-project.org/posting-guide.html] [
>> http://www.R-project.org/posting-guide.html [
>> http://www.R-project.org/posting-guide.html]]
>>   > and provide commented, minimal, self-contained, reproducible code.
>> 
>>   ____________________________________________________________
>>   FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>>   Check it out at http://www.inbox.com/earth
>> [http://www.inbox.com/earth]
>> [http://www.inbox.com/earth [http://www.inbox.com/earth]]
>> 
>>  --
>> 
>>  Mohammad Alimohammadi | Graduate Assistant
>>  University of Arkansas at Little Rock | College of Science
>> and Mathematics (CSAM)
>> 
>>  501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu] [
>> http://ualr.edu/ [http://ualr.edu/]]
>> 
>>  Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
>> http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [
>> http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
>> http://scholar.google.com/citations?user=MsfN_i8AAAAJ]]
>> 
>>  ____________________________________________________________
>>  FREE ONLINE PHOTOSHARING - Share your photos online with your friends
>> and
>> family!
>>  Visit http://www.inbox.com/photosharing [
>> http://www.inbox.com/photosharing] to find out more!
>> 
>> --
>> 
>> Mohammad Alimohammadi | Graduate Assistant
>> University of Arkansas at Little Rock | College of Science and
>> Mathematics
>> (CSAM)
>> 
>> 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu/]
>> 
>> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
>> http://scholar.google.com/citations?user=MsfN_i8AAAAJ]
>> 
>> ____________________________________________________________
>> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>> Check it out at http://www.inbox.com/earth
>> 
>> 
>> 
> 
> 
> --
> Mohammad Alimohammadi | Graduate Assistant
> University of Arkansas at Little Rock | College of Science and
> Mathematics
> (CSAM)
> 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu
> 
> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From venkynov10 at gmail.com  Wed May 27 15:07:36 2015
From: venkynov10 at gmail.com (venkadesan venky)
Date: Wed, 27 May 2015 18:37:36 +0530
Subject: [R] Doubts on Forecasting
Message-ID: <CAAM-fZ4f+U639vUG--fcy+C0PAe-J7hXYUUhxxZKKhUCW3+n-Q@mail.gmail.com>

Hello Team.

I have one doubts on Forecasting
I have the 2 years of data by month wise i need to find 3rd year Value
based on the past 2 years value if we using forecasting trend value coming
i want to find the exact value please help



Thanks and Regards
Venkatesan

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed May 27 15:19:28 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 27 May 2015 09:19:28 -0400
Subject: [R] Find and replace backslashes XXXX
In-Reply-To: <CAPRGo-=JpSOXEx1bdMXOU83HgcSo8UD3Ud85s0j-0Q5Yp64aeg@mail.gmail.com>
References: <CAPRGo-nWEegO2OStRUQfeJNcC_88gy1qx-DQOkdaLe6LZq9iPw@mail.gmail.com>	<CA+vqiLG0NDkcfQQCGMd_5E-CkUr9PuAbbAanXL2cOSrzWhi2PQ@mail.gmail.com>
	<CAPRGo-=JpSOXEx1bdMXOU83HgcSo8UD3Ud85s0j-0Q5Yp64aeg@mail.gmail.com>
Message-ID: <5565C460.8010403@gmail.com>

On 27/05/2015 8:55 AM, Dan Abner wrote:
> Hi Ista,
> 
> Is there no way to not escape the backslash in the pathway? 

You don't need to escape it if you read it from a file, get it from
list.files(), etc.  You only need to escape it if you are writing a
literal string in R code.

Duncan Murdoch

The
> pathway is going to change and will become very long and I need to do
> this programmatically. Beside, escaping the backslash defeats the
> purpose of using gsub. If I could do this manually each and every
> time, I would change simply change the backslash to a forward slash
> and therefore not need gsub at all...
> 
> Thanks,
> 
> Dan
> 
> On Tue, May 26, 2015 at 9:56 PM, Ista Zahn <istazahn at gmail.com> wrote:
>> Escape the backslash with another backslash, i.e.,
>>
>> gsub("\\","/","X:\\Classes\\TT\\Automation", fixed = TRUE)
>>
>> best,
>> Ista
>>
>> On Tue, May 26, 2015 at 9:30 PM, Dan Abner <dan.abner99 at gmail.com> wrote:
>>> Hi all,
>>>
>>> I realize that the backslash is an escape character in R, therefore, I
>>> am trying to replace it with a forward slash. Can someone please
>>> suggest how to get this code to work?
>>>
>>>> lib<-gsub("\","/","X:\Classes\TT\Automation")
>>> Error: unexpected symbol in "lib<-gsub("\","/","X"
>>>
>>>
>>> Thanks,
>>>
>>> Dan
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ssefick at gmail.com  Wed May 27 15:23:15 2015
From: ssefick at gmail.com (stephen sefick)
Date: Wed, 27 May 2015 08:23:15 -0500
Subject: [R] pls - No variable selection
In-Reply-To: <CAP8Wkrza77_T8kco64V7BcRJdByDcT6+E+H0RD8yWqXFo33cZw@mail.gmail.com>
References: <CAP8Wkrza77_T8kco64V7BcRJdByDcT6+E+H0RD8yWqXFo33cZw@mail.gmail.com>
Message-ID: <CADKEMqiDHcnTVs30mJU4kXErMZdB1Zj3O8UtQ_Hj+z9Mx1LCfA@mail.gmail.com>

Hi Barry,

I looked at the source code for pls quickly and couldn't find where/why
this message is being printed. Maybe an undocumented behavior? I would ask
the package maintainer. It doesn't look like a warning - just that there
was no variable selection.
HTH,

Stephen

On Wed, May 27, 2015 at 8:03 AM, Barry King <barry.king at qlx.com> wrote:

> I am attempting to use mixOmics' pls() on a problem with 16 rows
> and 27 columns.  When I run pls I get the message "No variable selection."
> I have included a small problem below that produces this message.
> What am I doing wrong?  Any help is appreciated.
>
>
> #===== Begin small reproducible sample program =====
> library(mixOmics)
>
> X <- matrix(c(2766, 2610, 3306, 3630,
>               1492, 1419, 1369, 1158,
>               2450, 2379, 2400, 2055,
>               2751, 2883, 3492, 3570,
>               2652, 2691, 3225, 3285,
>               3993, 4722, 6147, 6720,
>               4032, 4350, 5430, 5763,
>               4530, 5190, 6910, 7580,
>               4077, 4410, 5460, 5857,
>               3450, 3432, 3969, 4020,
>               4989, 5301, 6807, 7425,
>               5340, 5790, 7590, 8390,
>               3162, 3477, 4365, 4650,
>               4380, 4695, 6018, 6510,
>               4587, 4200, 5040, 5289,
>               4017, 4725, 6090, 6570),
>             ncol=4)
> colnames(X) <- c("v1","v2","v3","v4")
>
> Y <- matrix(c( 3.0110,
>                0.0000,
>                0.0000,
>                1.4820,
>                1.1160,
>                3.3970,
>                2.4280,
>                4.0240,
>                2.2750,
>                0.9588,
>                3.1900,
>                4.1320,
>                2.1600,
>                3.0940,
>                1.6040,
>                3.1620),
>             ncol=1)
> colnames(Y) <- c("y")
>
> mpls <- pls(X, Y,  mode="regression", ncomp=2)
> mpls
>
> #===== End small reproducible sample program, begin console output =====
>
> Call:
>  pls(X = X, Y = Y, mode = "regression")
>
>  PLS with a 'regression' mode with 2 PLS components.
>  You entered data X of dimensions: 16 4
>  You entered data Y of dimensions: 16 1
>
>  No variable selection.
>
>  Available components:
>  --------------------
>  loading vectors: see object$loadings
>  variates: see object$variates
>  variable names: see object$names
>
> #===== End console output =====
>
> Barry King
> Associate Professor of Information Technology
> Butler University
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Wed May 27 15:27:00 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 27 May 2015 05:27:00 -0800
Subject: [R] Doubts on Forecasting
In-Reply-To: <CAAM-fZ4f+U639vUG--fcy+C0PAe-J7hXYUUhxxZKKhUCW3+n-Q@mail.gmail.com>
Message-ID: <654E43E012E.00001412jrkrideau@inbox.com>

I doubt if there is enough information in your email to let anyone really comment. 

Have a look at Reproducibility :
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html
for some suggestions on how to frame a question for R-help.


John Kane
Kingston ON Canada


> -----Original Message-----
> From: venkynov10 at gmail.com
> Sent: Wed, 27 May 2015 18:37:36 +0530
> To: r-help at r-project.org
> Subject: [R] Doubts on Forecasting
> 
> Hello Team.
> 
> I have one doubts on Forecasting
> I have the 2 years of data by month wise i need to find 3rd year Value
> based on the past 2 years value if we using forecasting trend value
> coming
> i want to find the exact value please help
> 
> 
> 
> Thanks and Regards
> Venkatesan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From jrkrideau at inbox.com  Wed May 27 15:35:13 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 27 May 2015 05:35:13 -0800
Subject: [R] Printing with Header & no of observations
In-Reply-To: <1432726350155-4707747.post@n4.nabble.com>
Message-ID: <65609DBB145.00001438jrkrideau@inbox.com>

I am not totally clear on the header question but would something like ?head help here?  It will show a certain number of rows of data with headers included .  I think the default is 6 rows but if all you want to do is check names and a bit of data something like head(xx, 2) works nicely.

RE output -- yes there is a limit, http://stackoverflow.com/questions/6758727/how-to-increase-the-limit-for-max-print-in-r.
If you want to examine 'really' huge outputs you might want to use ?sink or perphaps write the file to disc (?write.file) and examine it in a text editor.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: shivibhatia at ymail.com
> Sent: Wed, 27 May 2015 04:32:30 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] Printing with Header & no of observations
> 
> HI Team,
> A quick question.
> 
> When I used the print option in R to see the output of my syntax I do not
> see the headers or column names. Is there a way to see the headers in the
> print.
> Also as most of the datasets we work today have huge number of
> observations
> but when I print it only shows a portion of the output. Is there a
> limitation to the number of rows that can be printed.
> 
> Kindly suggest. Thanks, Shivi
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Printing-with-Header-no-of-observations-tp4707747.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From jrkrideau at inbox.com  Wed May 27 16:19:46 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 27 May 2015 06:19:46 -0800
Subject: [R] Problem with comparing multiple data sets
In-Reply-To: <CAJVfk9nuZDJdadGobNHDTP2cY_a06XrLZYj8x8393+LeB0OWfg@mail.gmail.com>
Message-ID: <65C435966BD.0000150Djrkrideau@inbox.com>

I was wondering about the layout of each of your data sets. I cobbled together what I think is the most likely scenarios.  My bet is the data sets most closely resemble my data set 4 in structure. Am I correct?  I dropped the other two columns in your data layout as likely to be immaterial to the problem.

data set 1 (unique text and class)
class text
0     text1
2     text2
1     text3
2     text4

data set 2 (unique class, multiple text)
class text
0     text1
0     text1
0     text1
2     text2
1     text3
2     text4

data set 3 (multiple classes, multiple text)
class text
0     text1
0     text1
1     text1
2     text2
1     text3
2     text4

data set 4 (mutltiple classes , multiple text, text not found in other data sets)
0     text1
0     text1
1     text1
2     text2
1     text3
2     text4
2     text6
0     text6

John Kane
Kingston ON Canada


> -----Original Message-----
> From: mxalimohamma at ualr.edu
> Sent: Tue, 26 May 2015 20:11:08 -0500
> To: r-help at r-project.org
> Subject: Re: [R] Problem with comparing multiple data sets
> 
> Thank you John. Yes. as you mentioned this is not really what I am
> looking
> for.
> 
> It's interesting because I was really thinking that it should be pretty
> easy. All I need to do is just compare class1, class2 and class3 for each
> text and put the most frequent number next to it in each row. Repeat it
> for
> all the rows. Apparently it's not that simple.
> 
> Sorry I didn't notice that I sent it only to you! Thanks for letting me
> know.
> 
> I appreciate if anybody can help on this.
> 
> Thank you.
> 
> 
> 
> 
> On Tue, May 26, 2015 at 7:27 PM, John Kane <jrkrideau at inbox.com> wrote:
> 
>> Hi Mohammad,
>> 
>> The data came through beautifully despite the fact that you posted in
>> HTML.  Please, post in plain text.
>> 
>> Oh, just as I was ready to push Send, I  noticed you only replied to me.
>> You really should reply to the R-help list since there are a lot more
>> and
>> better people to help there. Besides it's a world-wide list. Others can
>> play with the problem while we sleep :) .
>> 
>> I will just reply to you but I really suggest sending all of this to the
>> list.
>> 
>> Now I am wondering what to do with the data. As a first swipe I just
>> added
>> up all the values in each class by each text value. Results are below.
>> Not
>> what you want by any means but perhaps a small step.
>> 
>> Then I started to think are we really interested in the sum or should we
>> be looking at incidence, that is should we be looking at the frequency
>> rather than the sum?
>> 
>> Is
>> class.1 class.2   class  #dac
>>   0           2              0
>> 
>> a value of 2 (sum) or a hit of 1 (count or freq) ?
>> 
>> Anyway below is what I have tried so far -- it may not be anywhere near
>> what you want but if it makes any sense then I think we just need to
>> pick
>> off the highest values for each combination of terms and class to give
>> you
>> what you want.
>> 
>> I suspect our real data-munging gurus can do  all this faster and better
>> than I can but hopefully it is a start.
>> 
>> Where your data set is dat1
>> #=====================================
>> # If reshape2 is not installed.
>> install.packages("reshape2")
>> #=====================================
>> 
>> library(reshape2)
>>  mdat  <-  melt(dat1, id.vars= c("terms"),
>>        variable.name = "class",
>>        value.name = "value",
>>        na.rm = FALSE)
>> 
>> mdat1  <-  aggregate(value ~ terms + class, data = mdat, sum)
>> 
>> mdat1[order(mdat1$terms, mdat1$class), ]
>> 
>> #=====================================
>> 
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> -----Original Message-----
>> From: mxalimohamma at ualr.edu
>> Sent: Tue, 26 May 2015 09:50:43 -0500
>> To: jrkrideau at inbox.com
>> Subject: Re: [R] Problem with comparing multiple data sets
>> 
>> Thank you John for being patient with me.
>> 
>> My original post was to compare 3 sets of data which had difference in
>> their class value for the same text. However, I thought it might be
>> easier
>> to combine those 3 data sets into one that shows the 3 different classes
>> and then find the most frequent class value for the text. So that's what
>> I
>> did. Now I only want to add the most frequent class value in a new
>> column.
>> 
>> I tried to create a dput version of the data set (Only a small part of
>> it)
>> so you can see. I hope it works.
>> 
>>> Tweet1<- read.csv(file="part1_complete.csv",head=TRUE,sep= ",")
>> 
>>> dput(head(Tweet1, 100))
>> 
>> structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
>> 
>> 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 0L, 1L, 2L, 2L, 2L, 1L, 1L, 1L,
>> 
>> 1L, 2L, 1L, 1L, 1L, 0L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L), class.2 = c(2L,
>> 
>> 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 
>> 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L,
>> 
>> 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L,
>> 
>> 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
>> 
>> 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 
>> 1L, 1L, 1L), class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
>> 
>> 1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L, 0L, 2L, 2L, 0L, 2L, 1L, 1L, 1L,
>> 
>> 1L, 0L, 0L, 0L, 2L, 1L, 0L, 0L, 1L, 0L, 0L, 2L, 2L, 2L, 2L, 2L,
>> 
>> 0L, 2L, 2L, 1L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
>> 
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L), terms = structure(c(9L,
>> 
>> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
>> 
>> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
>> 
>> 9L, 9L, 9L, 9L, 69L, 69L, 69L, 69L, 69L, 40L, 40L, 40L, 40L,
>> 
>> 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 98L, 98L, 98L, 98L, 98L,
>> 
>> 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 23L, 87L, 87L, 87L,
>> 
>> 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L,
>> 
>> 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L,
>> 
>> 87L, 87L), .Label = c("#accountability",
>> "#accountability,#anonymity,anonymity",
>> 
>> "#accountability,recovery", "#anonymity,anonymity",
>> "#anonymous,anonymous",
>> 
>> "#attacker,security", "#authentication,access control", "#confidential",
>> 
>> "#dac", "#encryption,#privacy,#security", "#identifier",
>> "#identifier,identifier",
>> 
>> "#intrusion,#security,security", "#mac", "#mac,#security",
>> "#mac,password",
>> 
>> "#mac,security", "#password,privacy", "#password,security",
>> "#prevention,prevention",
>> 
>> "#privacy,#security,password", "#privacy,identifiable",
>> "#privacy,information privacy,privacy",
>> 
>> "#privacy,intrusion", "#privacy,location privacy,privacy",
>> "#privacy,password,security",
>> 
>> "#privacy,personal data", "#privacy,personal information,privacy",
>> 
>> "#privacy,security", "#pseudonym", "#pseudonymity",
>> "#security,authentication,identity management",
>> 
>> "#security,identity management,security", "#security,mac,security",
>> 
>> "#security,malicious,security", "#security,personal information",
>> 
>> "#security,retention", "#token", "#token,token",
>> "accountability,anonymous",
>> 
>> "accountability,audit trail", "accountability,confidential",
>> 
>> "accountability,security", "accountability,token", "adversary,pin",
>> 
>> "anonymity,authentication", "anonymity,security",
>> "anonymous,disclosure",
>> 
>> "anonymous,password", "authentication,password,security",
>> "authorization,mac",
>> 
>> "authorization,permission", "confidential,disclosure",
>> "confidential,disclosure,security",
>> 
>> "confidential,mac", "confidential,personal information",
>> "confidential,pin",
>> 
>> "confidential,privilege", "confidentiality,security", "consent",
>> 
>> "dac", "dac,pcm", "data aggregation,privacy", "data controller",
>> 
>> "data protection,encryption", "data protection,recovery", "data
>> protection,security",
>> 
>> "data quality,security", "data security,encryption,security",
>> 
>> "data security,mac,security", "data security,personal data,security",
>> 
>> "data security,prevention,security", "detection", "detection,mac",
>> 
>> "detection,password", "deterrence,prevention", "digital signature",
>> 
>> "disclosure,password", "disclosure,private information",
>> "disclosure,security",
>> 
>> "encryption,password,recovery", "encryption,private data", "id
>> management,privacy",
>> 
>> "id management,security", "identifier", "identifier,token", "location
>> privacy,privacy",
>> 
>> "mac,password,security", "mac,permission", "mac,prevention",
>> 
>> "mac,privacy", "mac,pseudonym", "malicious,prevention",
>> "non-repudiation",
>> 
>> "password,prevention,security", "password,private information",
>> 
>> "password,recovery", "password,user id", "permission,personal data",
>> 
>> "permission,privacy,privacy policy", "personal data", "personal
>> identification number,pin",
>> 
>> "personal information", "personal information,security", "prevention",
>> 
>> "prevention,privilege", "privacy,privacy policy", "privacy,privacy
>> preferences",
>> 
>> "private information,security", "recovery,retention", "recovery,token",
>> 
>> "retention,token", "sensitive data", "token"), class = "factor")),
>> .Names
>> = c("class.1",
>> 
>> "class.2", "class.3", "terms"), row.names = c(NA, 100L), class =
>> "data.frame")
>> 
>> On Mon, May 25, 2015 at 2:04 PM, John Kane <jrkrideau at inbox.com> wrote:
>> 
>>         Hi Mohammad,
>> 
>>  If you are just starting with R a sense of total confusion is often the
>> first feeling.  Welcome :).
>> 
>>  If you are a SAS or SPSS user this may help
>> https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf
>> [
>> https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf
>> ]
>> 
>>  If anything,  I am even more lost than before.
>> 
>>  Did Jim Lemon's approach help? Confuse ?
>> 
>>  Perhaps one of the problems is that the data did not come through
>> cleanly.  You posted in HTML and the R-help list strips out all HTML so
>> the
>> result often is mangled beyond any real use.
>> 
>>  I may have imagined that your data are more complicated than they
>> really
>> are if all you really want is some kind of frequency count possibly by
>> some
>> conditioning variable. Is this it?
>> 
>>   It seems too simple but that is what I read that Excel is doing (as
>> incompetently as usual---I had not realised it was possible to be even
>> less
>> impressed with Excel than I already  was.)
>> 
>>  Can you send us some more data in dput() format. See the links I
>> provided
>> earlier or have a look at ?dput for more information.
>> 
>>  If you have lot of data, a representative sample is fine.  It is often
>> enough to do something like :
>>  dput(head(mydata, 100))
>>  which supplies 100 rows of data.
>> 
>>  Just output the dput() data, copy and paste into your email,  et voil?
>> we have the exact same data.
>> 
>>  The reason for dput() is that it provides a snapshot of exactly how the
>> data exists on your machine. Given all sorts of differences between
>> OS's,
>> personal settings, human languages and so on. what I or another R-help
>> reader see  or read in may not correspond to what you have. Using dput()
>> avoids all of this.
>> 
>>  Here is a simple example of what I mean. If you look at dat1 and dat2
>> they 'look' the same but ... I could read in data either way depending
>> on
>> all sorts of variable and have no idea which, if either is how you see
>> the
>> data.
>> 
>>   Data are supplied in dput() format, just copy and paste into R.
>>  =====
>>  dat1  <- structure(list(aa = structure(1:10, .Label = c("1", "2", "3",
>>  "4", "5", "6", "7", "8", "9", "10"), class = "factor"), bb = c(10L,
>>  9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L, 1L)), .Names = c("aa", "bb"), row.names
>> =
>> c(NA,
>>  -10L), class = "data.frame")
>> 
>>  dat2  <-  structure(list(aa = 1:10, bb = c(10L, 9L, 8L, 7L, 6L, 5L, 4L,
>>  3L, 2L, 1L)), .Names = c("aa", "bb"), row.names = c(NA, -10L), class =
>> "data.frame")
>> 
>>  dat1
>>  dat2  # looks a lot like dat1
>> 
>>  with(dat1, aa*bb)
>>  with(dat2 , aa*bb)
>> 
>>  str(dat1)
>>  str(dat2)
>> 
>>  =======
>> 
>>  John Kane
>>  Kingston ON Canada
>> 
>>  -----Original Message-----
>>  From: mxalimohamma at ualr.edu
>>  Sent: Mon, 25 May 2015 12:14:46 -0500
>>  To: jrkrideau at inbox.com
>>  Subject: Re: [R] Problem with comparing multiple data sets
>> 
>>  Hi John.
>> 
>>  Thank you for your response.
>> 
>>  Here is a small portion of my actual data set. What I am supposed to do
>> is to use a function similar to mode function in excel to find the most
>> frequent value (class) for each term.
>> 
>>    V1 V2 V3 V4
>> 
>>  1 class 1 class 2 class 3 terms
>> 
>>  2 0 2 0 #dac
>> 
>>  3 0 2          0 #dac
>> 
>>  4 0 2 0 #dac
>> 
>>  5 0 2 0 #dac
>> 
>>  6 1 0 1 #dac
>> 
>>  7 0 0 0 #dac
>> 
>>  ....
>> 
>>  Since I just started using R. I don't know where I am going with this.
>> I
>> appreciate any help.
>> 
>>  On Sat, May 23, 2015 at 8:23 AM, John Kane <jrkrideau at inbox.com> wrote:
>> 
>>          Hi Mohammad
>> 
>>   Welcome to the R-help list.
>> 
>>   There probably is a fairly easy way to what you want but I think we
>> probably need a bit more background information on what you are trying
>> to
>> achieve.  I know I'm not exactly clear on your decision rule(s).
>> 
>>   It would also be very useful to see some actual sample data in useable
>> R
>> format.Have a look at these links
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> [
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]
>> [
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> [
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]]
>> and http://adv-r.had.co.nz/Reproducibility.html [
>> http://adv-r.had.co.nz/Reproducibility.html] [
>> http://adv-r.had.co.nz/Reproducibility.html [
>> http://adv-r.had.co.nz/Reproducibility.html]] for some hints on what you
>> might want to include in your question.
>> 
>>   In particular, read up about dput()  in those links and/or see ?dput.
>> This is the generally preferred way to supply sample or illustrative
>> data
>> to the R-help list.  It basically creates a perfect copy of the data as
>> it
>> exists on 'your' machine so that R-help readers see exactly what you do.
>> 
>>   John Kane
>>   Kingston ON Canada
>> 
>>   > -----Original Message-----
>>   > From: mxalimohamma at ualr.edu
>>   > Sent: Fri, 22 May 2015 12:37:50 -0500
>>   > To: r-help at r-project.org
>>   > Subject: [R] Problem with comparing multiple data sets
>>   >
>>   > Hi everyone,
>>   >
>>   > I am very new to R and I have a task to do. I appreciate any help. I
>> have
>>   > 3
>>   > data sets. Each data set has 4 columns. For example:
>>   >
>>   > Class  Comment   Term   Text
>>   > 0           com1        aac    text1
>>   > 2           com2        aax    text2
>>   > 1           com3        vvx    text3
>>   >
>>   > Now I need t compare the class section between 3 data sets and
>> assign
>> the
>>   > most available class to that text. For example if text1 is assigned
>> to
>>   > class 0 in data set 1&2 but assigned as 2 in data set 3 then it
>> should
>> be
>>   > assigned to class 0. If they are all the same so the class will be
>> the
>>   > same. The ideal thing would be to keep the same format and just
>> update
>>   > the
>>   > class. Is there any easy way to do this?
>>   >
>>   > Thanks a lot.
>>   >
>> 
>>  >       [[alternative HTML version deleted]]
>>   >
>>   > ______________________________________________
>>   > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> 
>>  > https://stat.ethz.ch/mailman/listinfo/r-help [
>> https://stat.ethz.ch/mailman/listinfo/r-help] [
>> https://stat.ethz.ch/mailman/listinfo/r-help [
>> https://stat.ethz.ch/mailman/listinfo/r-help]]
>>   > PLEASE do read the posting guide
>>   > http://www.R-project.org/posting-guide.html [
>> http://www.R-project.org/posting-guide.html] [
>> http://www.R-project.org/posting-guide.html [
>> http://www.R-project.org/posting-guide.html]]
>>   > and provide commented, minimal, self-contained, reproducible code.
>> 
>>   ____________________________________________________________
>>   FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>>   Check it out at http://www.inbox.com/earth
>> [http://www.inbox.com/earth]
>> [http://www.inbox.com/earth [http://www.inbox.com/earth]]
>> 
>>  --
>> 
>>  Mohammad Alimohammadi | Graduate Assistant
>>  University of Arkansas at Little Rock | College of Science
>> and Mathematics (CSAM)
>> 
>>  501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu] [
>> http://ualr.edu/ [http://ualr.edu/]]
>> 
>>  Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
>> http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [
>> http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
>> http://scholar.google.com/citations?user=MsfN_i8AAAAJ]]
>> 
>>  ____________________________________________________________
>>  FREE ONLINE PHOTOSHARING - Share your photos online with your friends
>> and
>> family!
>>  Visit http://www.inbox.com/photosharing [
>> http://www.inbox.com/photosharing] to find out more!
>> 
>> --
>> 
>> Mohammad Alimohammadi | Graduate Assistant
>> University of Arkansas at Little Rock | College of Science and
>> Mathematics
>> (CSAM)
>> 
>> 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu/]
>> 
>> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
>> http://scholar.google.com/citations?user=MsfN_i8AAAAJ]
>> 
>> ____________________________________________________________
>> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>> Check it out at http://www.inbox.com/earth
>> 
>> 
>> 
> 
> 
> --
> Mohammad Alimohammadi | Graduate Assistant
> University of Arkansas at Little Rock | College of Science and
> Mathematics
> (CSAM)
> 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu
> 
> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Share photos & screenshots in seconds...
TRY FREE IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if1
Works in all emails, instant messengers, blogs, forums and social networks.


From jrkrideau at inbox.com  Wed May 27 16:32:29 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 27 May 2015 06:32:29 -0800
Subject: [R] Problem with comparing multiple data sets
In-Reply-To: <CAJVfk9=4KdEh01gOHFN279y5ESOcNzUzbVHqUmgMPC1Z_HbLWg@mail.gmail.com>
References: <cajvfk9nuzdjdadgobnhdtp2cy_a06xrlzyj8x8393+leb0owfg@mail.gmail.com>
	<651e81b86bb.000013cbjrkrideau@inbox.com>
Message-ID: <65E09D319F0.00001550jrkrideau@inbox.com>

Thanks Mohammad. 
The data appear to have come through just fine. This probably means you can ignore some of the questions I just sent you -- our emails are crossing. 

I probably will not get a chance  to look at this til this afternoon (10:25 here now). We can hope someone with more skill than I have will have solved the problem by then.

This is starting to sound a bit like a psychometric inter-rater reliability study.  Does each data set contain the same set of items ?


John Kane
Kingston ON Canada

-----Original Message-----
From: mxalimohamma at ualr.edu
Sent: Wed, 27 May 2015 09:18:12 -0500
To: jrkrideau at inbox.com, r-help at r-project.org
Subject: Re: [R] Problem with comparing multiple data sets

Hi John,

I created the original data set with dput . This time I only loaded 50 values for each data set (dat1, dat2, dat3).

About your question, all 0,1 and 2 are indicator of a specific class. The task is to compare 3 independent classification of a certain term and and determine the actual class of the term by finding the most frequent assigned number for that term.

I thought it might be easier to combine them into 1 data frame but either way is fine.

Let me know if it shows up clean. I saved the dput in txt file and copied here from that file. I assume this is the right way to do it. I might be wrong.

==============================================

dat1

structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,?

0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,?

0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,?

1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), terms = structure(c(1L, 1L,?

1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label = c("#dac",?

"#mac,#security", "accountability,anonymous", "data security,encryption,security"

), class = "factor")), .Names = c("class.1", "terms"), class = "data.frame", row.names = c(NA,?

-49L))

dat2

structure(list(class.2 = c(2L, 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L,?

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,?

0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L,?

2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L), terms = structure(c(1L, 1L,?

1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label = c("#dac",?

"#mac,#security", "accountability,anonymous", "data security,encryption,security"

), class = "factor")), .Names = c("class.2", "terms"), class = "data.frame", row.names = c(NA,?

-49L))

dat3

structure(list(class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,?

0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,?

0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,?

1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L), terms = structure(c(1L, 1L,?

1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label = c("#dac",?

"#mac,#security", "accountability,anonymous", "data security,encryption,security"

), class = "factor")), .Names = c("class.3", "terms"), class = "data.frame", row.names = c(NA,?

-49L))

=============================================

On Wed, May 27, 2015 at 8:05 AM, John Kane <jrkrideau at inbox.com> wrote:

	Hi Mohammad,

 I went back and reread your original statement of the problem about and I think I kinda grasp it. It is actually quite clear and I misunderstood it completely.

 At the moment I have no idea how to approach it.? As Jim Lemon said, it looks easy but may not be.? I'll go back and re-examine Jim's approach.

 You might want to create three sample data sets of the original data layouts and upload them, in dput() format, to the list.? It may be easier to tackle from that approach.

 In any case, in the existing data set is a 2 a numeric value 2 or just an on/off indicator?

 John Kane
 Kingston ON Canada

 > -----Original Message-----
 > From: mxalimohamma at ualr.edu

> Sent: Tue, 26 May 2015 20:11:08 -0500
 > To: r-help at r-project.org
 > Subject: Re: [R] Problem with comparing multiple data sets
 >
 > Thank you John. Yes. as you mentioned this is not really what I am
 > looking
 > for.
 >
 > It's interesting because I was really thinking that it should be pretty
 > easy. All I need to do is just compare class1, class2 and class3 for each
 > text and put the most frequent number next to it in each row. Repeat it
 > for
 > all the rows. Apparently it's not that simple.
 >
 > Sorry I didn't notice that I sent it only to you! Thanks for letting me
 > know.
 >
 > I appreciate if anybody can help on this.
 >
 > Thank you.
 >
 >
 >
 >
 > On Tue, May 26, 2015 at 7:27 PM, John Kane <jrkrideau at inbox.com> wrote:
 >
 >> Hi Mohammad,
 >>
 >> The data came through beautifully despite the fact that you posted in
 >> HTML.? Please, post in plain text.
 >>
 >> Oh, just as I was ready to push Send, I? noticed you only replied to me.
 >> You really should reply to the R-help list since there are a lot more
 >> and
 >> better people to help there. Besides it's a world-wide list. Others can
 >> play with the problem while we sleep :) .
 >>
 >> I will just reply to you but I really suggest sending all of this to the
 >> list.
 >>
 >> Now I am wondering what to do with the data. As a first swipe I just
 >> added
 >> up all the values in each class by each text value. Results are below.
 >> Not
 >> what you want by any means but perhaps a small step.
 >>
 >> Then I started to think are we really interested in the sum or should we
 >> be looking at incidence, that is should we be looking at the frequency
 >> rather than the sum?
 >>
 >> Is
 >> class.1 class.2? ?class? #dac
 >>? ?0? ? ? ? ? ?2? ? ? ? ? ? ? 0
 >>
 >> a value of 2 (sum) or a hit of 1 (count or freq) ?
 >>
 >> Anyway below is what I have tried so far -- it may not be anywhere near
 >> what you want but if it makes any sense then I think we just need to
 >> pick
 >> off the highest values for each combination of terms and class to give
 >> you
 >> what you want.
 >>
 >> I suspect our real data-munging gurus can do? all this faster and better
 >> than I can but hopefully it is a start.
 >>
 >> Where your data set is dat1
 >> #=====================================
 >> # If reshape2 is not installed.
 >> install.packages("reshape2")
 >> #=====================================
 >>
 >> library(reshape2)
 >>? mdat? <-? melt(dat1, id.vars= c("terms"),
 >>? ? ? ? variable.name [http://variable.name] = "class",
 >>? ? ? ? value.name [http://value.name] = "value",
 >>? ? ? ? na.rm = FALSE)
 >>
 >> mdat1? <-? aggregate(value ~ terms + class, data = mdat, sum)
 >>
 >> mdat1[order(mdat1$terms, mdat1$class), ]
 >>
 >> #=====================================
 >>
 >>
 >> John Kane
 >> Kingston ON Canada
 >>
 >> -----Original Message-----
 >> From: mxalimohamma at ualr.edu
 >> Sent: Tue, 26 May 2015 09:50:43 -0500
 >> To: jrkrideau at inbox.com
 >> Subject: Re: [R] Problem with comparing multiple data sets
 >>
 >> Thank you John for being patient with me.
 >>
 >> My original post was to compare 3 sets of data which had difference in
 >> their class value for the same text. However, I thought it might be
 >> easier
 >> to combine those 3 data sets into one that shows the 3 different classes
 >> and then find the most frequent class value for the text. So that's what
 >> I
 >> did. Now I only want to add the most frequent class value in a new
 >> column.
 >>
 >> I tried to create a dput version of the data set (Only a small part of
 >> it)
 >> so you can see. I hope it works.
 >>
 >>> Tweet1<- read.csv(file="part1_complete.csv",head=TRUE,sep= ",")
 >>
 >>> dput(head(Tweet1, 100))
 >>
 >> structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 >>
 >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 >>
 >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
 >>
 >> 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 0L, 1L, 2L, 2L, 2L, 1L, 1L, 1L,
 >>
 >> 1L, 2L, 1L, 1L, 1L, 0L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
 >>
 >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
 >>
 >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L), class.2 = c(2L,
 >>
 >> 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
 >>
 >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 >>
 >> 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L,
 >>
 >> 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L,
 >>
 >> 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
 >>
 >> 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
 >>
 >> 1L, 1L, 1L), class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 >>
 >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 >>
 >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
 >>
 >> 1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L, 0L, 2L, 2L, 0L, 2L, 1L, 1L, 1L,
 >>
 >> 1L, 0L, 0L, 0L, 2L, 1L, 0L, 0L, 1L, 0L, 0L, 2L, 2L, 2L, 2L, 2L,
 >>
 >> 0L, 2L, 2L, 1L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
 >>
 >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L), terms = structure(c(9L,
 >>
 >> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
 >>
 >> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
 >>
 >> 9L, 9L, 9L, 9L, 69L, 69L, 69L, 69L, 69L, 40L, 40L, 40L, 40L,
 >>
 >> 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 98L, 98L, 98L, 98L, 98L,
 >>
 >> 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 23L, 87L, 87L, 87L,
 >>
 >> 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L,
 >>
 >> 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L,
 >>
 >> 87L, 87L), .Label = c("#accountability",
 >> "#accountability,#anonymity,anonymity",
 >>
 >> "#accountability,recovery", "#anonymity,anonymity",
 >> "#anonymous,anonymous",
 >>
 >> "#attacker,security", "#authentication,access control", "#confidential",
 >>
 >> "#dac", "#encryption,#privacy,#security", "#identifier",
 >> "#identifier,identifier",
 >>
 >> "#intrusion,#security,security", "#mac", "#mac,#security",
 >> "#mac,password",
 >>
 >> "#mac,security", "#password,privacy", "#password,security",
 >> "#prevention,prevention",
 >>
 >> "#privacy,#security,password", "#privacy,identifiable",
 >> "#privacy,information privacy,privacy",
 >>
 >> "#privacy,intrusion", "#privacy,location privacy,privacy",
 >> "#privacy,password,security",
 >>
 >> "#privacy,personal data", "#privacy,personal information,privacy",
 >>
 >> "#privacy,security", "#pseudonym", "#pseudonymity",
 >> "#security,authentication,identity management",
 >>
 >> "#security,identity management,security", "#security,mac,security",
 >>
 >> "#security,malicious,security", "#security,personal information",
 >>
 >> "#security,retention", "#token", "#token,token",
 >> "accountability,anonymous",
 >>
 >> "accountability,audit trail", "accountability,confidential",
 >>
 >> "accountability,security", "accountability,token", "adversary,pin",
 >>
 >> "anonymity,authentication", "anonymity,security",
 >> "anonymous,disclosure",
 >>
 >> "anonymous,password", "authentication,password,security",
 >> "authorization,mac",
 >>
 >> "authorization,permission", "confidential,disclosure",
 >> "confidential,disclosure,security",
 >>
 >> "confidential,mac", "confidential,personal information",
 >> "confidential,pin",
 >>
 >> "confidential,privilege", "confidentiality,security", "consent",
 >>
 >> "dac", "dac,pcm", "data aggregation,privacy", "data controller",
 >>
 >> "data protection,encryption", "data protection,recovery", "data
 >> protection,security",
 >>
 >> "data quality,security", "data security,encryption,security",
 >>
 >> "data security,mac,security", "data security,personal data,security",
 >>
 >> "data security,prevention,security", "detection", "detection,mac",
 >>
 >> "detection,password", "deterrence,prevention", "digital signature",
 >>
 >> "disclosure,password", "disclosure,private information",
 >> "disclosure,security",
 >>
 >> "encryption,password,recovery", "encryption,private data", "id
 >> management,privacy",
 >>
 >> "id management,security", "identifier", "identifier,token", "location
 >> privacy,privacy",
 >>
 >> "mac,password,security", "mac,permission", "mac,prevention",
 >>
 >> "mac,privacy", "mac,pseudonym", "malicious,prevention",
 >> "non-repudiation",
 >>
 >> "password,prevention,security", "password,private information",
 >>
 >> "password,recovery", "password,user id", "permission,personal data",
 >>
 >> "permission,privacy,privacy policy", "personal data", "personal
 >> identification number,pin",
 >>
 >> "personal information", "personal information,security", "prevention",
 >>
 >> "prevention,privilege", "privacy,privacy policy", "privacy,privacy
 >> preferences",
 >>
 >> "private information,security", "recovery,retention", "recovery,token",
 >>
 >> "retention,token", "sensitive data", "token"), class = "factor")),
 >> .Names
 >> = c("class.1",
 >>
 >> "class.2", "class.3", "terms"), row.names = c(NA, 100L), class =
 >> "data.frame")
 >>
 >> On Mon, May 25, 2015 at 2:04 PM, John Kane <jrkrideau at inbox.com> wrote:
 >>
 >>? ? ? ? ?Hi Mohammad,
 >>
 >>? If you are just starting with R a sense of total confusion is often the
 >> first feeling.? Welcome :).
 >>
 >>? If you are a SAS or SPSS user this may help
 >> https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf [https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf]
 >> [
 >> https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf [https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf]
 >> ]
 >>
 >>? If anything,? I am even more lost than before.
 >>
 >>? Did Jim Lemon's approach help? Confuse ?
 >>
 >>? Perhaps one of the problems is that the data did not come through
 >> cleanly.? You posted in HTML and the R-help list strips out all HTML so
 >> the
 >> result often is mangled beyond any real use.
 >>
 >>? I may have imagined that your data are more complicated than they
 >> really
 >> are if all you really want is some kind of frequency count possibly by
 >> some
 >> conditioning variable. Is this it?
 >>
 >>? ?It seems too simple but that is what I read that Excel is doing (as
 >> incompetently as usual---I had not realised it was possible to be even
 >> less
 >> impressed with Excel than I already? was.)
 >>
 >>? Can you send us some more data in dput() format. See the links I
 >> provided
 >> earlier or have a look at ?dput for more information.
 >>
 >>? If you have lot of data, a representative sample is fine.? It is often
 >> enough to do something like :
 >>? dput(head(mydata, 100))
 >>? which supplies 100 rows of data.
 >>
 >>? Just output the dput() data, copy and paste into your email,? et voil?
 >> we have the exact same data.
 >>
 >>? The reason for dput() is that it provides a snapshot of exactly how the
 >> data exists on your machine. Given all sorts of differences between
 >> OS's,
 >> personal settings, human languages and so on. what I or another R-help
 >> reader see? or read in may not correspond to what you have. Using dput()
 >> avoids all of this.
 >>
 >>? Here is a simple example of what I mean. If you look at dat1 and dat2
 >> they 'look' the same but ... I could read in data either way depending
 >> on
 >> all sorts of variable and have no idea which, if either is how you see
 >> the
 >> data.
 >>
 >>? ?Data are supplied in dput() format, just copy and paste into R.
 >>? =====
 >>? dat1? <- structure(list(aa = structure(1:10, .Label = c("1", "2", "3",
 >>? "4", "5", "6", "7", "8", "9", "10"), class = "factor"), bb = c(10L,
 >>? 9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L, 1L)), .Names = c("aa", "bb"), row.names
 >> =
 >> c(NA,
 >>? -10L), class = "data.frame")
 >>
 >>? dat2? <-? structure(list(aa = 1:10, bb = c(10L, 9L, 8L, 7L, 6L, 5L, 4L,
 >>? 3L, 2L, 1L)), .Names = c("aa", "bb"), row.names = c(NA, -10L), class =
 >> "data.frame")
 >>
 >>? dat1
 >>? dat2? # looks a lot like dat1
 >>
 >>? with(dat1, aa*bb)
 >>? with(dat2 , aa*bb)
 >>
 >>? str(dat1)
 >>? str(dat2)
 >>
 >>? =======
 >>
 >>? John Kane
 >>? Kingston ON Canada
 >>
 >>? -----Original Message-----
 >>? From: mxalimohamma at ualr.edu
 >>? Sent: Mon, 25 May 2015 12:14:46 -0500
 >>? To: jrkrideau at inbox.com
 >>? Subject: Re: [R] Problem with comparing multiple data sets
 >>
 >>? Hi John.
 >>
 >>? Thank you for your response.
 >>
 >>? Here is a small portion of my actual data set. What I am supposed to do
 >> is to use a function similar to mode function in excel to find the most
 >> frequent value (class) for each term.
 >>
 >>? ? V1 V2 V3 V4
 >>
 >>? 1 class 1 class 2 class 3 terms
 >>
 >>? 2 0 2 0 #dac
 >>
 >>? 3 0 2? ? ? ? ? 0 #dac
 >>
 >>? 4 0 2 0 #dac
 >>
 >>? 5 0 2 0 #dac
 >>
 >>? 6 1 0 1 #dac
 >>
 >>? 7 0 0 0 #dac
 >>
 >>? ....
 >>
 >>? Since I just started using R. I don't know where I am going with this.
 >> I
 >> appreciate any help.
 >>
 >>? On Sat, May 23, 2015 at 8:23 AM, John Kane <jrkrideau at inbox.com> wrote:
 >>
 >>? ? ? ? ? Hi Mohammad
 >>
 >>? ?Welcome to the R-help list.
 >>
 >>? ?There probably is a fairly easy way to what you want but I think we
 >> probably need a bit more background information on what you are trying
 >> to
 >> achieve.? I know I'm not exactly clear on your decision rule(s).
 >>
 >>? ?It would also be very useful to see some actual sample data in useable
 >> R
 >> format.Have a look at these links
 >> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]
 >> [
 >> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]]
 >> [
 >> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]
 >> [
 >> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]]]
 >> and http://adv-r.had.co.nz/Reproducibility.html [http://adv-r.had.co.nz/Reproducibility.html] [
 >> http://adv-r.had.co.nz/Reproducibility.html [http://adv-r.had.co.nz/Reproducibility.html]] [
 >> http://adv-r.had.co.nz/Reproducibility.html [http://adv-r.had.co.nz/Reproducibility.html] [
 >> http://adv-r.had.co.nz/Reproducibility.html [http://adv-r.had.co.nz/Reproducibility.html]]] for some hints on what you
 >> might want to include in your question.
 >>
 >>? ?In particular, read up about dput()? in those links and/or see ?dput.
 >> This is the generally preferred way to supply sample or illustrative
 >> data
 >> to the R-help list.? It basically creates a perfect copy of the data as
 >> it
 >> exists on 'your' machine so that R-help readers see exactly what you do.
 >>
 >>? ?John Kane
 >>? ?Kingston ON Canada
 >>
 >>? ?> -----Original Message-----
 >>? ?> From: mxalimohamma at ualr.edu
 >>? ?> Sent: Fri, 22 May 2015 12:37:50 -0500
 >>? ?> To: r-help at r-project.org
 >>? ?> Subject: [R] Problem with comparing multiple data sets
 >>? ?>
 >>? ?> Hi everyone,
 >>? ?>
 >>? ?> I am very new to R and I have a task to do. I appreciate any help. I
 >> have
 >>? ?> 3
 >>? ?> data sets. Each data set has 4 columns. For example:
 >>? ?>
 >>? ?> Class? Comment? ?Term? ?Text
 >>? ?> 0? ? ? ? ? ?com1? ? ? ? aac? ? text1
 >>? ?> 2? ? ? ? ? ?com2? ? ? ? aax? ? text2
 >>? ?> 1? ? ? ? ? ?com3? ? ? ? vvx? ? text3
 >>? ?>
 >>? ?> Now I need t compare the class section between 3 data sets and
 >> assign
 >> the
 >>? ?> most available class to that text. For example if text1 is assigned
 >> to
 >>? ?> class 0 in data set 1&2 but assigned as 2 in data set 3 then it
 >> should
 >> be
 >>? ?> assigned to class 0. If they are all the same so the class will be
 >> the
 >>? ?> same. The ideal thing would be to keep the same format and just
 >> update
 >>? ?> the
 >>? ?> class. Is there any easy way to do this?
 >>? ?>
 >>? ?> Thanks a lot.
 >>? ?>
 >>
 >>? >? ? ? ?[[alternative HTML version deleted]]
 >>? ?>
 >>? ?> ______________________________________________
 >>? ?> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 >>
 >>? > https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [
 >> https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]] [
 >> https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [
 >> https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]]]
 >>? ?> PLEASE do read the posting guide
 >>? ?> http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [
 >> http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]] [
 >> http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [
 >> http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]]]
 >>? ?> and provide commented, minimal, self-contained, reproducible code.
 >>
 >>? ?____________________________________________________________
 >>? ?FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
 >>? ?Check it out at http://www.inbox.com/earth [http://www.inbox.com/earth]
 >> [http://www.inbox.com/earth [http://www.inbox.com/earth]]
 >> [http://www.inbox.com/earth [http://www.inbox.com/earth] [http://www.inbox.com/earth [http://www.inbox.com/earth]]]
 >>
 >>? --
 >>
 >>? Mohammad Alimohammadi | Graduate Assistant
 >>? University of Arkansas at Little Rock | College of Science
 >> and Mathematics (CSAM)
 >>
 >>? 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu] [http://ualr.edu [http://ualr.edu]] [
 >> http://ualr.edu/ [http://ualr.edu/] [http://ualr.edu/ [http://ualr.edu/]]]
 >>
 >>? Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [
 >> http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]] [
 >> http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [
 >> http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]]]
 >>
 >>? ____________________________________________________________
 >>? FREE ONLINE PHOTOSHARING - Share your photos online with your friends
 >> and
 >> family!
 >>? Visit http://www.inbox.com/photosharing [http://www.inbox.com/photosharing] [
 >> http://www.inbox.com/photosharing [http://www.inbox.com/photosharing]] to find out more!
 >>
 >> --
 >>
 >> Mohammad Alimohammadi | Graduate Assistant
 >> University of Arkansas at Little Rock | College of Science and
 >> Mathematics
 >> (CSAM)
 >>
 >> 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu] [http://ualr.edu/ [http://ualr.edu/]]
 >>
 >> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [
 >> http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]]
 >>
 >> ____________________________________________________________
 >> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
 >> Check it out at http://www.inbox.com/earth [http://www.inbox.com/earth]
 >>
 >>
 >>
 >
 >
 > --
 > Mohammad Alimohammadi | Graduate Assistant
 > University of Arkansas at Little Rock | College of Science and
 > Mathematics
 > (CSAM)
 > 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu]
 >
 > Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]
 >
 >? ? ? ?[[alternative HTML version deleted]]
 >
 > ______________________________________________
 > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 > PLEASE do read the posting guide
 > http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 > and provide commented, minimal, self-contained, reproducible code.

 ____________________________________________________________

Can't remember your password? Do you need a strong and secure password?
 Use Password manager! It stores your passwords & protects your account.
 Check it out at http://mysecurelogon.com/password-manager [http://mysecurelogon.com/password-manager]

-- 

Mohammad Alimohammadi | Graduate Assistant
University of Arkansas at Little Rock | College of Science and?Mathematics (CSAM)?

501.346.8007 | mxalimohamma at ualr.edu?| ualr.edu [http://ualr.edu/]

Public URL:?http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jrkrideau at inbox.com  Wed May 27 16:57:31 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 27 May 2015 06:57:31 -0800
Subject: [R] Problem with comparing multiple data sets
In-Reply-To: <CAJVfk9mtzPpyG=_vFmvX2YXjP_RXsda5bV+VYMrp_m0KvN03KQ@mail.gmail.com>
References: <cajvfk9nuzdjdadgobnhdtp2cy_a06xrlzyj8x8393+leb0owfg@mail.gmail.com>
	<651e81b86bb.000013cbjrkrideau@inbox.com>
	<65e09d319f0.00001550jrkrideau@inbox.com>
	<cajvfk9=4kdeh01gohfn279y5esocnzuzbvhqumgmpc1z_hblwg@mail.gmail.com>
Message-ID: <661892D16A5.000015D4jrkrideau@inbox.com>

Hi Mohammad,

My mantra for the day is "Plain Text", Plain Text". A bas HTML.
And I really need to get out of here.  

I have not found a solution but is this a bit more like what you want?

#===============================================

dat1  <-  structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
c("#dac",
"#mac,#security", "accountability,anonymous", "data
security,encryption,security"
), class = "factor")), .Names = c("class.1", "terms"), class =
"data.frame", row.names = c(NA,
-49L))

dat2  <-  structure(list(class.2 = c(2L, 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L,
2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L), terms = structure(c(1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
c("#dac",
"#mac,#security", "accountability,anonymous", "data
security,encryption,security"
), class = "factor")), .Names = c("class.2", "terms"), class =
"data.frame", row.names = c(NA,
-49L))

dat3  <-  structure(list(class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
c("#dac",
"#mac,#security", "accountability,anonymous", "data
security,encryption,security"
), class = "factor")), .Names = c("class.3", "terms"), class =
"data.frame", row.names = c(NA,
-49L))

names(dat1) <-  names(dat2)  <-  names(dat3)  <-  c("class", "term")

bbind  <-  rbind(dat1, dat1, dat3)

with(bbind, table( term, class))

#=========================================

John Kane
Kingston ON Canada

-----Original Message-----
From: mxalimohamma at ualr.edu
Sent: Wed, 27 May 2015 09:37:24 -0500
To: jrkrideau at inbox.com, r-help at r-project.org
Subject: Re: [R] Problem with comparing multiple data sets

Thanks John,

I really hope it can be answered. Yes all 3 data sets have the same items.

On Wed, May 27, 2015 at 9:32 AM, John Kane <jrkrideau at inbox.com> wrote:

	Thanks Mohammad.
 The data appear to have come through just fine. This probably means you can ignore some of the questions I just sent you -- our emails are crossing.

 I probably will not get a chance? to look at this til this afternoon (10:25 here now). We can hope someone with more skill than I have will have solved the problem by then.

 This is starting to sound a bit like a psychometric inter-rater reliability study.? Does each data set contain the same set of items ?

 John Kane
 Kingston ON Canada

 -----Original Message-----
 From: mxalimohamma at ualr.edu

Sent: Wed, 27 May 2015 09:18:12 -0500
 To: jrkrideau at inbox.com, r-help at r-project.org
 Subject: Re: [R] Problem with comparing multiple data sets

 Hi John,

 I created the original data set with dput . This time I only loaded 50 values for each data set (dat1, dat2, dat3).

 About your question, all 0,1 and 2 are indicator of a specific class. The task is to compare 3 independent classification of a certain term and and determine the actual class of the term by finding the most frequent assigned number for that term.

 I thought it might be easier to combine them into 1 data frame but either way is fine.

 Let me know if it shows up clean. I saved the dput in txt file and copied here from that file. I assume this is the right way to do it. I might be wrong.

 ==============================================

 dat1

 structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,?

 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,?

 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,?

 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), terms = structure(c(1L, 1L,?

 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label = c("#dac",?

 "#mac,#security", "accountability,anonymous", "data security,encryption,security"

 ), class = "factor")), .Names = c("class.1", "terms"), class = "data.frame", row.names = c(NA,?

 -49L))

 dat2

 structure(list(class.2 = c(2L, 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L,?

 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,?

 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L,?

 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L), terms = structure(c(1L, 1L,?

 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label = c("#dac",?

 "#mac,#security", "accountability,anonymous", "data security,encryption,security"

 ), class = "factor")), .Names = c("class.2", "terms"), class = "data.frame", row.names = c(NA,?

 -49L))

 dat3

 structure(list(class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,?

 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,?

 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,?

 1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L), terms = structure(c(1L, 1L,?

 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,?

 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label = c("#dac",?

 "#mac,#security", "accountability,anonymous", "data security,encryption,security"

 ), class = "factor")), .Names = c("class.3", "terms"), class = "data.frame", row.names = c(NA,?

 -49L))

 =============================================

 On Wed, May 27, 2015 at 8:05 AM, John Kane <jrkrideau at inbox.com> wrote:

 ? ? ? ? Hi Mohammad,

 ?I went back and reread your original statement of the problem about and I think I kinda grasp it. It is actually quite clear and I misunderstood it completely.

 ?At the moment I have no idea how to approach it.? As Jim Lemon said, it looks easy but may not be.? I'll go back and re-examine Jim's approach.

 ?You might want to create three sample data sets of the original data layouts and upload them, in dput() format, to the list.? It may be easier to tackle from that approach.

 ?In any case, in the existing data set is a 2 a numeric value 2 or just an on/off indicator?

 ?John Kane
 ?Kingston ON Canada

 ?> -----Original Message-----
 ?> From: mxalimohamma at ualr.edu

 > Sent: Tue, 26 May 2015 20:11:08 -0500
 ?> To: r-help at r-project.org
 ?> Subject: Re: [R] Problem with comparing multiple data sets
 ?>
 ?> Thank you John. Yes. as you mentioned this is not really what I am
 ?> looking
 ?> for.
 ?>
 ?> It's interesting because I was really thinking that it should be pretty
 ?> easy. All I need to do is just compare class1, class2 and class3 for each
 ?> text and put the most frequent number next to it in each row. Repeat it
 ?> for
 ?> all the rows. Apparently it's not that simple.
 ?>
 ?> Sorry I didn't notice that I sent it only to you! Thanks for letting me
 ?> know.
 ?>
 ?> I appreciate if anybody can help on this.
 ?>
 ?> Thank you.
 ?>
 ?>
 ?>
 ?>
 ?> On Tue, May 26, 2015 at 7:27 PM, John Kane <jrkrideau at inbox.com> wrote:
 ?>
 ?>> Hi Mohammad,
 ?>>
 ?>> The data came through beautifully despite the fact that you posted in
 ?>> HTML.? Please, post in plain text.
 ?>>
 ?>> Oh, just as I was ready to push Send, I? noticed you only replied to me.
 ?>> You really should reply to the R-help list since there are a lot more
 ?>> and
 ?>> better people to help there. Besides it's a world-wide list. Others can
 ?>> play with the problem while we sleep :) .
 ?>>
 ?>> I will just reply to you but I really suggest sending all of this to the
 ?>> list.
 ?>>
 ?>> Now I am wondering what to do with the data. As a first swipe I just
 ?>> added
 ?>> up all the values in each class by each text value. Results are below.
 ?>> Not
 ?>> what you want by any means but perhaps a small step.
 ?>>
 ?>> Then I started to think are we really interested in the sum or should we
 ?>> be looking at incidence, that is should we be looking at the frequency
 ?>> rather than the sum?
 ?>>
 ?>> Is
 ?>> class.1 class.2? ?class? #dac
 ?>>? ?0? ? ? ? ? ?2? ? ? ? ? ? ? 0
 ?>>
 ?>> a value of 2 (sum) or a hit of 1 (count or freq) ?
 ?>>
 ?>> Anyway below is what I have tried so far -- it may not be anywhere near
 ?>> what you want but if it makes any sense then I think we just need to
 ?>> pick
 ?>> off the highest values for each combination of terms and class to give
 ?>> you
 ?>> what you want.
 ?>>
 ?>> I suspect our real data-munging gurus can do? all this faster and better
 ?>> than I can but hopefully it is a start.
 ?>>
 ?>> Where your data set is dat1
 ?>> #=====================================
 ?>> # If reshape2 is not installed.
 ?>> install.packages("reshape2")
 ?>> #=====================================
 ?>>
 ?>> library(reshape2)
 ?>>? mdat? <-? melt(dat1, id.vars= c("terms"),

?>>? ? ? ? variable.name [http://variable.name] [http://variable.name [http://variable.name]] = "class",
 ?>>? ? ? ? value.name [http://value.name] [http://value.name [http://value.name]] = "value",

?>>? ? ? ? na.rm = FALSE)
 ?>>
 ?>> mdat1? <-? aggregate(value ~ terms + class, data = mdat, sum)
 ?>>
 ?>> mdat1[order(mdat1$terms, mdat1$class), ]
 ?>>
 ?>> #=====================================
 ?>>
 ?>>
 ?>> John Kane
 ?>> Kingston ON Canada
 ?>>
 ?>> -----Original Message-----
 ?>> From: mxalimohamma at ualr.edu
 ?>> Sent: Tue, 26 May 2015 09:50:43 -0500
 ?>> To: jrkrideau at inbox.com
 ?>> Subject: Re: [R] Problem with comparing multiple data sets
 ?>>
 ?>> Thank you John for being patient with me.
 ?>>
 ?>> My original post was to compare 3 sets of data which had difference in
 ?>> their class value for the same text. However, I thought it might be
 ?>> easier
 ?>> to combine those 3 data sets into one that shows the 3 different classes
 ?>> and then find the most frequent class value for the text. So that's what
 ?>> I
 ?>> did. Now I only want to add the most frequent class value in a new
 ?>> column.
 ?>>
 ?>> I tried to create a dput version of the data set (Only a small part of
 ?>> it)
 ?>> so you can see. I hope it works.
 ?>>
 ?>>> Tweet1<- read.csv(file="part1_complete.csv",head=TRUE,sep= ",")
 ?>>
 ?>>> dput(head(Tweet1, 100))
 ?>>
 ?>> structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 ?>>
 ?>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 ?>>
 ?>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
 ?>>
 ?>> 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 0L, 1L, 2L, 2L, 2L, 1L, 1L, 1L,
 ?>>
 ?>> 1L, 2L, 1L, 1L, 1L, 0L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
 ?>>
 ?>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
 ?>>
 ?>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L), class.2 = c(2L,
 ?>>
 ?>> 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
 ?>>
 ?>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 ?>>
 ?>> 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L,
 ?>>
 ?>> 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L,
 ?>>
 ?>> 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
 ?>>
 ?>> 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
 ?>>
 ?>> 1L, 1L, 1L), class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 ?>>
 ?>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 ?>>
 ?>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
 ?>>
 ?>> 1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L, 0L, 2L, 2L, 0L, 2L, 1L, 1L, 1L,
 ?>>
 ?>> 1L, 0L, 0L, 0L, 2L, 1L, 0L, 0L, 1L, 0L, 0L, 2L, 2L, 2L, 2L, 2L,
 ?>>
 ?>> 0L, 2L, 2L, 1L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
 ?>>
 ?>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L), terms = structure(c(9L,
 ?>>
 ?>> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
 ?>>
 ?>> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
 ?>>
 ?>> 9L, 9L, 9L, 9L, 69L, 69L, 69L, 69L, 69L, 40L, 40L, 40L, 40L,
 ?>>
 ?>> 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 98L, 98L, 98L, 98L, 98L,
 ?>>
 ?>> 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 23L, 87L, 87L, 87L,
 ?>>
 ?>> 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L,
 ?>>
 ?>> 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L,
 ?>>
 ?>> 87L, 87L), .Label = c("#accountability",
 ?>> "#accountability,#anonymity,anonymity",
 ?>>
 ?>> "#accountability,recovery", "#anonymity,anonymity",
 ?>> "#anonymous,anonymous",
 ?>>
 ?>> "#attacker,security", "#authentication,access control", "#confidential",
 ?>>
 ?>> "#dac", "#encryption,#privacy,#security", "#identifier",
 ?>> "#identifier,identifier",
 ?>>
 ?>> "#intrusion,#security,security", "#mac", "#mac,#security",
 ?>> "#mac,password",
 ?>>
 ?>> "#mac,security", "#password,privacy", "#password,security",
 ?>> "#prevention,prevention",
 ?>>
 ?>> "#privacy,#security,password", "#privacy,identifiable",
 ?>> "#privacy,information privacy,privacy",
 ?>>
 ?>> "#privacy,intrusion", "#privacy,location privacy,privacy",
 ?>> "#privacy,password,security",
 ?>>
 ?>> "#privacy,personal data", "#privacy,personal information,privacy",
 ?>>
 ?>> "#privacy,security", "#pseudonym", "#pseudonymity",
 ?>> "#security,authentication,identity management",
 ?>>
 ?>> "#security,identity management,security", "#security,mac,security",
 ?>>
 ?>> "#security,malicious,security", "#security,personal information",
 ?>>
 ?>> "#security,retention", "#token", "#token,token",
 ?>> "accountability,anonymous",
 ?>>
 ?>> "accountability,audit trail", "accountability,confidential",
 ?>>
 ?>> "accountability,security", "accountability,token", "adversary,pin",
 ?>>
 ?>> "anonymity,authentication", "anonymity,security",
 ?>> "anonymous,disclosure",
 ?>>
 ?>> "anonymous,password", "authentication,password,security",
 ?>> "authorization,mac",
 ?>>
 ?>> "authorization,permission", "confidential,disclosure",
 ?>> "confidential,disclosure,security",
 ?>>
 ?>> "confidential,mac", "confidential,personal information",
 ?>> "confidential,pin",
 ?>>
 ?>> "confidential,privilege", "confidentiality,security", "consent",
 ?>>
 ?>> "dac", "dac,pcm", "data aggregation,privacy", "data controller",
 ?>>
 ?>> "data protection,encryption", "data protection,recovery", "data
 ?>> protection,security",
 ?>>
 ?>> "data quality,security", "data security,encryption,security",
 ?>>
 ?>> "data security,mac,security", "data security,personal data,security",
 ?>>
 ?>> "data security,prevention,security", "detection", "detection,mac",
 ?>>
 ?>> "detection,password", "deterrence,prevention", "digital signature",
 ?>>
 ?>> "disclosure,password", "disclosure,private information",
 ?>> "disclosure,security",
 ?>>
 ?>> "encryption,password,recovery", "encryption,private data", "id
 ?>> management,privacy",
 ?>>
 ?>> "id management,security", "identifier", "identifier,token", "location
 ?>> privacy,privacy",
 ?>>
 ?>> "mac,password,security", "mac,permission", "mac,prevention",
 ?>>
 ?>> "mac,privacy", "mac,pseudonym", "malicious,prevention",
 ?>> "non-repudiation",
 ?>>
 ?>> "password,prevention,security", "password,private information",
 ?>>
 ?>> "password,recovery", "password,user id", "permission,personal data",
 ?>>
 ?>> "permission,privacy,privacy policy", "personal data", "personal
 ?>> identification number,pin",
 ?>>
 ?>> "personal information", "personal information,security", "prevention",
 ?>>
 ?>> "prevention,privilege", "privacy,privacy policy", "privacy,privacy
 ?>> preferences",
 ?>>
 ?>> "private information,security", "recovery,retention", "recovery,token",
 ?>>
 ?>> "retention,token", "sensitive data", "token"), class = "factor")),
 ?>> .Names
 ?>> = c("class.1",
 ?>>
 ?>> "class.2", "class.3", "terms"), row.names = c(NA, 100L), class =
 ?>> "data.frame")
 ?>>
 ?>> On Mon, May 25, 2015 at 2:04 PM, John Kane <jrkrideau at inbox.com> wrote:
 ?>>
 ?>>? ? ? ? ?Hi Mohammad,
 ?>>
 ?>>? If you are just starting with R a sense of total confusion is often the
 ?>> first feeling.? Welcome :).
 ?>>
 ?>>? If you are a SAS or SPSS user this may help
 ?>> https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf [https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf] [https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf [https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf]]
 ?>> [
 ?>> https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf [https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf] [https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf [https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf]]
 ?>> ]
 ?>>
 ?>>? If anything,? I am even more lost than before.
 ?>>
 ?>>? Did Jim Lemon's approach help? Confuse ?
 ?>>
 ?>>? Perhaps one of the problems is that the data did not come through
 ?>> cleanly.? You posted in HTML and the R-help list strips out all HTML so
 ?>> the
 ?>> result often is mangled beyond any real use.
 ?>>
 ?>>? I may have imagined that your data are more complicated than they
 ?>> really
 ?>> are if all you really want is some kind of frequency count possibly by
 ?>> some
 ?>> conditioning variable. Is this it?
 ?>>
 ?>>? ?It seems too simple but that is what I read that Excel is doing (as
 ?>> incompetently as usual---I had not realised it was possible to be even
 ?>> less
 ?>> impressed with Excel than I already? was.)
 ?>>
 ?>>? Can you send us some more data in dput() format. See the links I
 ?>> provided
 ?>> earlier or have a look at ?dput for more information.
 ?>>
 ?>>? If you have lot of data, a representative sample is fine.? It is often
 ?>> enough to do something like :
 ?>>? dput(head(mydata, 100))
 ?>>? which supplies 100 rows of data.
 ?>>
 ?>>? Just output the dput() data, copy and paste into your email,? et voil?
 ?>> we have the exact same data.
 ?>>
 ?>>? The reason for dput() is that it provides a snapshot of exactly how the
 ?>> data exists on your machine. Given all sorts of differences between
 ?>> OS's,
 ?>> personal settings, human languages and so on. what I or another R-help
 ?>> reader see? or read in may not correspond to what you have. Using dput()
 ?>> avoids all of this.
 ?>>
 ?>>? Here is a simple example of what I mean. If you look at dat1 and dat2
 ?>> they 'look' the same but ... I could read in data either way depending
 ?>> on
 ?>> all sorts of variable and have no idea which, if either is how you see
 ?>> the
 ?>> data.
 ?>>
 ?>>? ?Data are supplied in dput() format, just copy and paste into R.
 ?>>? =====
 ?>>? dat1? <- structure(list(aa = structure(1:10, .Label = c("1", "2", "3",
 ?>>? "4", "5", "6", "7", "8", "9", "10"), class = "factor"), bb = c(10L,
 ?>>? 9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L, 1L)), .Names = c("aa", "bb"), row.names
 ?>> =
 ?>> c(NA,
 ?>>? -10L), class = "data.frame")
 ?>>
 ?>>? dat2? <-? structure(list(aa = 1:10, bb = c(10L, 9L, 8L, 7L, 6L, 5L, 4L,
 ?>>? 3L, 2L, 1L)), .Names = c("aa", "bb"), row.names = c(NA, -10L), class =
 ?>> "data.frame")
 ?>>
 ?>>? dat1
 ?>>? dat2? # looks a lot like dat1
 ?>>
 ?>>? with(dat1, aa*bb)
 ?>>? with(dat2 , aa*bb)
 ?>>
 ?>>? str(dat1)
 ?>>? str(dat2)
 ?>>
 ?>>? =======
 ?>>
 ?>>? John Kane
 ?>>? Kingston ON Canada
 ?>>
 ?>>? -----Original Message-----
 ?>>? From: mxalimohamma at ualr.edu
 ?>>? Sent: Mon, 25 May 2015 12:14:46 -0500
 ?>>? To: jrkrideau at inbox.com
 ?>>? Subject: Re: [R] Problem with comparing multiple data sets
 ?>>
 ?>>? Hi John.
 ?>>
 ?>>? Thank you for your response.
 ?>>
 ?>>? Here is a small portion of my actual data set. What I am supposed to do
 ?>> is to use a function similar to mode function in excel to find the most
 ?>> frequent value (class) for each term.
 ?>>
 ?>>? ? V1 V2 V3 V4
 ?>>
 ?>>? 1 class 1 class 2 class 3 terms
 ?>>
 ?>>? 2 0 2 0 #dac
 ?>>
 ?>>? 3 0 2? ? ? ? ? 0 #dac
 ?>>
 ?>>? 4 0 2 0 #dac
 ?>>
 ?>>? 5 0 2 0 #dac
 ?>>
 ?>>? 6 1 0 1 #dac
 ?>>
 ?>>? 7 0 0 0 #dac
 ?>>
 ?>>? ....
 ?>>
 ?>>? Since I just started using R. I don't know where I am going with this.
 ?>> I
 ?>> appreciate any help.
 ?>>
 ?>>? On Sat, May 23, 2015 at 8:23 AM, John Kane <jrkrideau at inbox.com> wrote:
 ?>>
 ?>>? ? ? ? ? Hi Mohammad
 ?>>
 ?>>? ?Welcome to the R-help list.
 ?>>
 ?>>? ?There probably is a fairly easy way to what you want but I think we
 ?>> probably need a bit more background information on what you are trying
 ?>> to
 ?>> achieve.? I know I'm not exactly clear on your decision rule(s).
 ?>>
 ?>>? ?It would also be very useful to see some actual sample data in useable
 ?>> R
 ?>> format.Have a look at these links
 ?>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example] [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]]
 ?>> [
 ?>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example] [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]]]
 ?>> [
 ?>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example] [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]]
 ?>> [
 ?>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example] [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example] [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]]]]
 ?>> and http://adv-r.had.co.nz/Reproducibility.html [http://adv-r.had.co.nz/Reproducibility.html] [http://adv-r.had.co.nz/Reproducibility.html [http://adv-r.had.co.nz/Reproducibility.html]] [

?>> http://adv-r.had.co.nz/Reproducibility.html [http://adv-r.had.co.nz/Reproducibility.html] [http://adv-r.had.co.nz/Reproducibility.html [http://adv-r.had.co.nz/Reproducibility.html]]] [

?>> http://adv-r.had.co.nz/Reproducibility.html [http://adv-r.had.co.nz/Reproducibility.html] [http://adv-r.had.co.nz/Reproducibility.html [http://adv-r.had.co.nz/Reproducibility.html]] [
 ?>> http://adv-r.had.co.nz/Reproducibility.html [http://adv-r.had.co.nz/Reproducibility.html] [http://adv-r.had.co.nz/Reproducibility.html] [http://adv-r.had.co.nz/Reproducibility.html]]]] for some hints on what you
 ?>> might want to include in your question.
 ?>>
 ?>>? ?In particular, read up about dput()? in those links and/or see ?dput.
 ?>> This is the generally preferred way to supply sample or illustrative
 ?>> data
 ?>> to the R-help list.? It basically creates a perfect copy of the data as
 ?>> it
 ?>> exists on 'your' machine so that R-help readers see exactly what you do.
 ?>>
 ?>>? ?John Kane
 ?>>? ?Kingston ON Canada
 ?>>
 ?>>? ?> -----Original Message-----
 ?>>? ?> From: mxalimohamma at ualr.edu
 ?>>? ?> Sent: Fri, 22 May 2015 12:37:50 -0500
 ?>>? ?> To: r-help at r-project.org
 ?>>? ?> Subject: [R] Problem with comparing multiple data sets
 ?>>? ?>
 ?>>? ?> Hi everyone,
 ?>>? ?>
 ?>>? ?> I am very new to R and I have a task to do. I appreciate any help. I
 ?>> have
 ?>>? ?> 3
 ?>>? ?> data sets. Each data set has 4 columns. For example:
 ?>>? ?>
 ?>>? ?> Class? Comment? ?Term? ?Text
 ?>>? ?> 0? ? ? ? ? ?com1? ? ? ? aac? ? text1
 ?>>? ?> 2? ? ? ? ? ?com2? ? ? ? aax? ? text2
 ?>>? ?> 1? ? ? ? ? ?com3? ? ? ? vvx? ? text3
 ?>>? ?>
 ?>>? ?> Now I need t compare the class section between 3 data sets and
 ?>> assign
 ?>> the
 ?>>? ?> most available class to that text. For example if text1 is assigned
 ?>> to
 ?>>? ?> class 0 in data set 1&2 but assigned as 2 in data set 3 then it
 ?>> should
 ?>> be
 ?>>? ?> assigned to class 0. If they are all the same so the class will be
 ?>> the
 ?>>? ?> same. The ideal thing would be to keep the same format and just
 ?>> update
 ?>>? ?> the
 ?>>? ?> class. Is there any easy way to do this?
 ?>>? ?>
 ?>>? ?> Thanks a lot.
 ?>>? ?>
 ?>>
 ?>>? >? ? ? ?[[alternative HTML version deleted]]
 ?>>? ?>
 ?>>? ?> ______________________________________________
 ?>>? ?> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 ?>>
 ?>>? > https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]] [

?>> https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]]] [
 ?>> https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]] [
 ?>> https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help]]]]
 ?>>? ?> PLEASE do read the posting guide
 ?>>? ?> http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]] [
 ?>> http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]]] [
 ?>> http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]] [
 ?>> http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html]]]]
 ?>>? ?> and provide commented, minimal, self-contained, reproducible code.
 ?>>
 ?>>? ?____________________________________________________________
 ?>>? ?FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
 ?>>? ?Check it out at http://www.inbox.com/earth [http://www.inbox.com/earth] [http://www.inbox.com/earth [http://www.inbox.com/earth]]
 ?>> [http://www.inbox.com/earth [http://www.inbox.com/earth] [http://www.inbox.com/earth [http://www.inbox.com/earth]]]
 ?>> [http://www.inbox.com/earth [http://www.inbox.com/earth] [http://www.inbox.com/earth [http://www.inbox.com/earth]] [http://www.inbox.com/earth [http://www.inbox.com/earth] [http://www.inbox.com/earth] [http://www.inbox.com/earth]]]]
 ?>>
 ?>>? --
 ?>>
 ?>>? Mohammad Alimohammadi | Graduate Assistant
 ?>>? University of Arkansas at Little Rock | College of Science
 ?>> and Mathematics (CSAM)
 ?>>
 ?>>? 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu] [http://ualr.edu [http://ualr.edu]] [http://ualr.edu [http://ualr.edu] [http://ualr.edu [http://ualr.edu]]] [
 ?>> http://ualr.edu/ [http://ualr.edu/] [http://ualr.edu/ [http://ualr.edu/]] [http://ualr.edu/ [http://ualr.edu/] [http://ualr.edu/] [http://ualr.edu/]]]]
 ?>>
 ?>>? Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]] [
 ?>> http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]]] [
 ?>> http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]] [
 ?>> http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]]]]
 ?>>
 ?>>? ____________________________________________________________
 ?>>? FREE ONLINE PHOTOSHARING - Share your photos online with your friends
 ?>> and
 ?>> family!
 ?>>? Visit http://www.inbox.com/photosharing [http://www.inbox.com/photosharing] [http://www.inbox.com/photosharing [http://www.inbox.com/photosharing]] [
 ?>> http://www.inbox.com/photosharing [http://www.inbox.com/photosharing] [http://www.inbox.com/photosharing [http://www.inbox.com/photosharing]]] to find out more!
 ?>>
 ?>> --
 ?>>
 ?>> Mohammad Alimohammadi | Graduate Assistant
 ?>> University of Arkansas at Little Rock | College of Science and
 ?>> Mathematics
 ?>> (CSAM)
 ?>>
 ?>> 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu] [http://ualr.edu [http://ualr.edu]] [http://ualr.edu/ [http://ualr.edu/] [http://ualr.edu/ [http://ualr.edu/]]]
 ?>>
 ?>> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]] [
 ?>> http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]]]
 ?>>
 ?>> ____________________________________________________________
 ?>> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
 ?>> Check it out at http://www.inbox.com/earth [http://www.inbox.com/earth] [http://www.inbox.com/earth [http://www.inbox.com/earth]]
 ?>>
 ?>>
 ?>>
 ?>
 ?>
 ?> --
 ?> Mohammad Alimohammadi | Graduate Assistant
 ?> University of Arkansas at Little Rock | College of Science and
 ?> Mathematics
 ?> (CSAM)
 ?> 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu] [http://ualr.edu [http://ualr.edu]]
 ?>
 ?> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]]
 ?>
 ?>? ? ? ?[[alternative HTML version deleted]]
 ?>
 ?> ______________________________________________
 ?> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 ?> https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]]
 ?> PLEASE do read the posting guide
 ?> http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]]
 ?> and provide commented, minimal, self-contained, reproducible code.

 ?____________________________________________________________

 Can't remember your password? Do you need a strong and secure password?
 ?Use Password manager! It stores your passwords & protects your account.
 ?Check it out at http://mysecurelogon.com/password-manager [http://mysecurelogon.com/password-manager] [http://mysecurelogon.com/password-manager [http://mysecurelogon.com/password-manager]]

 --

 Mohammad Alimohammadi | Graduate Assistant
 University of Arkansas at Little Rock | College of Science and?Mathematics (CSAM)?

 501.346.8007?| mxalimohamma at ualr.edu?| ualr.edu [http://ualr.edu] [http://ualr.edu/ [http://ualr.edu/]]

 Public URL:?http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]]

 ____________________________________________________________
 FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
 Check it out at http://www.inbox.com/marineaquarium [http://www.inbox.com/marineaquarium]

-- 

Mohammad Alimohammadi | Graduate Assistant
University of Arkansas at Little Rock | College of Science and?Mathematics (CSAM)?

501.346.8007 | mxalimohamma at ualr.edu?| ualr.edu [http://ualr.edu/]

Public URL:?http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]

____________________________________________________________
Receive Notifications of Incoming Messages
Easily monitor multiple email accounts & access them with a click.
Visit http://www.inbox.com/notifier and check it out!


From Onoriode.Coast at csiro.au  Wed May 27 11:06:34 2015
From: Onoriode.Coast at csiro.au (Onoriode.Coast at csiro.au)
Date: Wed, 27 May 2015 09:06:34 +0000
Subject: [R] Estimating Four Parameters with nls in R
Message-ID: <D736F454355006429DA41754A53FFDBB43CD1107@exmbx06-cdc.nexus.csiro.au>

Hello all!

I am trying to estimate four parameters of a model (mu, sigma, theta and lambda) for a subset of data (snapshot given below). I have tried to do this using the nls package in R but I kept getting error messages (Error in numericDeriv(form[[3L]], names(ind), env) :  --AND-- Missing value or an infinity produced when evaluating the model). Please have a look at my code and tell, if you can, how I might get it to work. The data has five levels of "WP" (0, -0.4, -0.8, -1.2 and -1.6).

Mod1<-nls(1-germ~exp(-1*((WP-(theta/time)-mu)/sigma)^lambda),start=c(mu=-3,theta=3,sigma=3,lambda=-1),data=ht)

WP

time

germ

0

1.333333

0

0

1.416667

0

0

1.5

0.04

0

1.583333

0.04

0

2.083333

0.08

0

2.166667

0.16

0

2.25

0.24

0

2.333333

0.36

0

2.416667

0.6

0

2.5

0.64

0

2.583333

0.64

0

2.666667

0.72

0

2.916667

1

.
.
.
-1.6

2.916667

0

-1.6

3.166667

0

-1.6

3.666667

0

-1.6

4.166667

0

-1.6

4.666667

0

-1.6

5.166667

0

-1.6

5.666667

0

-1.6

7.666667

0

-1.6

9.666667

0

-1.6

12.66667

0

-1.6

19.66667

0



Dr Onoriode Coast
Postdoctoral Fellow
Agriculture Flagship
CSIRO
E onoriode.coast at csiro.au


	[[alternative HTML version deleted]]


From daisy.duursma at gmail.com  Wed May 27 11:42:03 2015
From: daisy.duursma at gmail.com (Daisy Englert Duursma)
Date: Wed, 27 May 2015 19:42:03 +1000
Subject: [R] Identifying peak periods of observations in circular yearly
	data
In-Reply-To: <CA+8X3fU=gQLh1d5hAmD0aZZ9t=1Qys6OuLt2H3HcJ3r0XzpSzA@mail.gmail.com>
References: <CAFf2dDGACuVMUurKT9TsPv=xWJNcCgx=tgBSdWFJp4TO2himTg@mail.gmail.com>
	<CA+8X3fU=gQLh1d5hAmD0aZZ9t=1Qys6OuLt2H3HcJ3r0XzpSzA@mail.gmail.com>
Message-ID: <CAFf2dDHoWdur=8hPdFXhaui0cJ9P=-byUTqK8Xp8+iJTxeQHXg@mail.gmail.com>

Thanks for the advice Jim. I did actually play around with this idea, but
for some bird species (emu) the beginning of the breeding season is
actually January while for others it is in July or at other times. Breeding
seasons can be driven by dry season or temperatures, so although there are
generalizations each species need to be assessed.

On Wed, May 27, 2015 at 7:34 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Daisy,
> You face a problem similar to one with which I have grappled in
> different fields. The year is designed for the northern hemisphere,
> beginning and ending in less productive biologic states in those
> regions. I have previously argued that since the calendar year is an
> arbitrary progression, it makes more sense to redraw the annual
> boundary when examining things like this in the southern hemisphere.
> That is to say, a "year" is conventionally marked at about the
> northern winter solstice. Down here, this becomes the summer solstice
> and breaks up a lot of things that happen around that time. Have you
> thought of defining a southern bird-watching year as beginning and
> ending at the southern winter solstice? As I am currently writing in
> an entirely different context, it shouldn't really make much
> difference.
>
> Jim
>
>
> On Wed, May 27, 2015 at 4:35 PM, Daisy Englert Duursma
> <daisy.duursma at gmail.com> wrote:
> > Greetings,
> >
> > I am trying to identify at which point during the year 80% of bird
> breeding
> > observations are. typically I would answer a question like this by
> finding
> > the median or quartiles but how do I deal with situations where the 80%
> of
> > the is from day 285 through day 366 (leap year) and extends to day 30?
> >
> > The data is circular and and day 365 is as close to day 366 as day 1.
> >
> > I am reading the manual for CircStats and circular but I could really use
> > some help on this.
> >
> >
> > Here is some dummy data:
> >
> >
> >
> obsDay<-c(rep(1:30,10),rep(45:65,2),65:180,rep(181:265,2),rep(266:330,4),rep(331:366,6))
> >
> > plot(density(obsDay))
> >
> >
> >
> > --
> > Daisy Englert Duursma
> > Department of Biological Sciences
> > Room W19F 135
> > Macquarie University, North Ryde, NSW 2109
> > Australia
> >
> > Tel +61 2 9850 1302
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Daisy Englert Duursma
Department of Biological Sciences
Room W19F 135
Macquarie University, North Ryde, NSW 2109
Australia

Tel +61 2 9850 1302

	[[alternative HTML version deleted]]


From lioneldelm at gmail.com  Wed May 27 11:43:26 2015
From: lioneldelm at gmail.com (Lionel Delmas)
Date: Wed, 27 May 2015 11:43:26 +0200
Subject: [R] Getting a cdf equal to 1 from a variable kernel density
	estimation
Message-ID: <CABX4axPKoq+SFbLDjMyLVHXBDB0HAdox1UK0jj7ZFP1TS008=g@mail.gmail.com>

When I integrate the variable kernel density estimation of a sample from
-inf to inf, I should get 1. But it is not what I get with my code below. I
find a value higher than 2. How can I fix this?

n<-1000
df <- data.frame(x=unlist(lapply(1, function(i) rnorm(n, 0,sd=1))))
df<-as.data.frame(df[order(df$x),])
names(df)[1]<-"x"

library(functional)

gaussianKernel <- function(u, h) exp(-sum(u^2)/(2*h^2))

densityFunction <- function(x, df, ker, h){
    difference = t(t(df) - x)
    W = sum(apply(difference, 1, ker, h=h))
    W/(nrow(df)*(h^(length(df))))}

myDensityFunction <- Curry(densityFunction, df=df, ker=gaussianKernel , h=2)

vect<-vector()for (i in 1:length(df$x)){
f<-myDensityFunction(df$x[i])
vect<-c(vect,f)}

plot(df$x,vect,ylim=c(0,1),xlim=c(-5,5),type="l")

f <- approxfun(df$x, vect, yleft = 0, yright = 0)
integrate(f, -Inf, Inf)

Thanks

	[[alternative HTML version deleted]]


From burbrink666 at gmail.com  Wed May 27 12:20:40 2015
From: burbrink666 at gmail.com (Frank Burbrink)
Date: Wed, 27 May 2015 06:20:40 -0400
Subject: [R] Problem merging data frames and duplicates
In-Reply-To: <CAA99HCyqULLzW2aodnwZ2epPWP+MSX+Q6-TGM6tRk5Ro=D-EaQ@mail.gmail.com>
References: <CAAbnQ5gJ_B-pqz2+z15+yCXGqBobje0aOVMkSOgQVxVuacMnNg@mail.gmail.com>
	<CAA99HCyqULLzW2aodnwZ2epPWP+MSX+Q6-TGM6tRk5Ro=D-EaQ@mail.gmail.com>
Message-ID: <CAAbnQ5iYF-Ajr0xNjowMJrXPbc+P+6KBN9w6OJVW+C0=_toF_A@mail.gmail.com>

Thanks Bill,

However, unique(merge(x, y, by = 1, all=T)) is giving me:

   state locus.x locus.y
1     AR       5       2
2     AR       5       3
3     AR       6       2
4     AR       6       3
5     IL       1       1
9     LA       2      NA
11    MS       3      NA
12    MS       4      NA
13    TN      NA       3
14    TN      NA       4

This has AR repeated twice and the normal double IL and LA now only listed
singly.

What I am hoping for is something like this:

   state locus.x locus.y
1     AR       5       2
4     AR       6       3
7     IL       1       1
8     IL       1       1
9     LA       2      NA
10    LA       2      NA
11    MS       3      NA
12    MS       4      NA
13    TN      NA       3
14    TN      NA       4

On Wed, May 27, 2015 at 3:53 AM, William Michels <wjm1 at caa.columbia.edu>
wrote:

> Hi Frank,
>
> It looks like you're very close. I think you want:
>
> unique(merge(x, y, by = 1, all=T))
>
> Gabor Grothendieck's sqldf package is very useful if you're more
> comfortable with SQL-type syntax, see:
>
> https://github.com/ggrothendieck/sqldf
>
> Best Regards,
>
> William (Bill) Michels, Ph.D.
>
>
>
> On Tue, May 26, 2015 at 5:12 PM, Frank Burbrink
> <burbrink666 at gmail.com> wrote: <SNIP>
>



-- 

*************************************
*Frank T. Burbrink, Ph.D.*
*Professor*
*Biology Department*
*6S-143*
*2800 Victory Blvd.*
*College of Staten Island/CUNY*
*Staten Island, New York 10314*
*E-Mail:Frank.Burbrink at csi.cuny.edu <E-Mail%3AFrank.Burbrink at csi.cuny.edu>*
*Phone:718-982-3961*
*Web Page: http://scholar.library.csi.cuny.edu/~fburbrink/
<http://scholar.library.csi.cuny.edu/%7Efburbrink/>*
*************************************
*Chair *
*Ecology, Evolutionary Biology, and Behavior*
*Doctoral Subprogram*
*Biology Program*
*City University of New York *
*Graduate Center*
*365 Fifth Avenue*
*New York, NY 10016-4309*
************************************

	[[alternative HTML version deleted]]


From burbrink666 at gmail.com  Wed May 27 13:01:50 2015
From: burbrink666 at gmail.com (Frank Burbrink)
Date: Wed, 27 May 2015 07:01:50 -0400
Subject: [R] Problem merging data frames and duplicates
In-Reply-To: <CAAbnQ5iYF-Ajr0xNjowMJrXPbc+P+6KBN9w6OJVW+C0=_toF_A@mail.gmail.com>
References: <CAAbnQ5gJ_B-pqz2+z15+yCXGqBobje0aOVMkSOgQVxVuacMnNg@mail.gmail.com>
	<CAA99HCyqULLzW2aodnwZ2epPWP+MSX+Q6-TGM6tRk5Ro=D-EaQ@mail.gmail.com>
	<CAAbnQ5iYF-Ajr0xNjowMJrXPbc+P+6KBN9w6OJVW+C0=_toF_A@mail.gmail.com>
Message-ID: <CAAbnQ5ipi5MGtYri3CXoguNAp4Tq21DSN-+yaKP6QtuR-ESmVw@mail.gmail.com>

I have figured out a cheesy work around since these problems have to do
with not having unique identifiers for the States:

1) Append a unique identifier to each state such that both AR becomes ARa
and ARb
2) run the normal merge(x,y,by=1, all=T)
3) Use subst to cut the appended identifiers.

While this is clunky I can just write a function to do it all at once.

On Wed, May 27, 2015 at 6:20 AM, Frank Burbrink <burbrink666 at gmail.com>
wrote:

> Thanks Bill,
>
> However, unique(merge(x, y, by = 1, all=T)) is giving me:
>
>    state locus.x locus.y
> 1     AR       5       2
> 2     AR       5       3
> 3     AR       6       2
> 4     AR       6       3
> 5     IL       1       1
> 9     LA       2      NA
> 11    MS       3      NA
> 12    MS       4      NA
> 13    TN      NA       3
> 14    TN      NA       4
>
> This has AR repeated twice and the normal double IL and LA now only listed
> singly.
>
> What I am hoping for is something like this:
>
>    state locus.x locus.y
> 1     AR       5       2
> 4     AR       6       3
> 7     IL       1       1
> 8     IL       1       1
> 9     LA       2      NA
> 10    LA       2      NA
> 11    MS       3      NA
> 12    MS       4      NA
> 13    TN      NA       3
> 14    TN      NA       4
>
> On Wed, May 27, 2015 at 3:53 AM, William Michels <wjm1 at caa.columbia.edu>
> wrote:
>
>> Hi Frank,
>>
>> It looks like you're very close. I think you want:
>>
>> unique(merge(x, y, by = 1, all=T))
>>
>> Gabor Grothendieck's sqldf package is very useful if you're more
>> comfortable with SQL-type syntax, see:
>>
>> https://github.com/ggrothendieck/sqldf
>>
>> Best Regards,
>>
>> William (Bill) Michels, Ph.D.
>>
>>
>>
>> On Tue, May 26, 2015 at 5:12 PM, Frank Burbrink
>> <burbrink666 at gmail.com> wrote: <SNIP>
>>
>
>
>
> --
>
> *************************************
> *Frank T. Burbrink, Ph.D.*
> *Professor*
> *Biology Department*
> *6S-143*
> *2800 Victory Blvd.*
> *College of Staten Island/CUNY*
> *Staten Island, New York 10314*
> *E-Mail:Frank.Burbrink at csi.cuny.edu <E-Mail%3AFrank.Burbrink at csi.cuny.edu>*
> *Phone:718-982-3961 <718-982-3961>*
> *Web Page: http://scholar.library.csi.cuny.edu/~fburbrink/
> <http://scholar.library.csi.cuny.edu/%7Efburbrink/>*
> *************************************
> *Chair *
> *Ecology, Evolutionary Biology, and Behavior*
> *Doctoral Subprogram*
> *Biology Program*
> *City University of New York *
> *Graduate Center*
> *365 Fifth Avenue*
> *New York, NY 10016-4309*
> ************************************
>



-- 

*************************************
*Frank T. Burbrink, Ph.D.*
*Professor*
*Biology Department*
*6S-143*
*2800 Victory Blvd.*
*College of Staten Island/CUNY*
*Staten Island, New York 10314*
*E-Mail:Frank.Burbrink at csi.cuny.edu <E-Mail%3AFrank.Burbrink at csi.cuny.edu>*
*Phone:718-982-3961*
*Web Page: http://scholar.library.csi.cuny.edu/~fburbrink/
<http://scholar.library.csi.cuny.edu/%7Efburbrink/>*
*************************************
*Chair *
*Ecology, Evolutionary Biology, and Behavior*
*Doctoral Subprogram*
*Biology Program*
*City University of New York *
*Graduate Center*
*365 Fifth Avenue*
*New York, NY 10016-4309*
************************************

	[[alternative HTML version deleted]]


From wjm1 at caa.columbia.edu  Wed May 27 15:27:08 2015
From: wjm1 at caa.columbia.edu (William Michels)
Date: Wed, 27 May 2015 06:27:08 -0700
Subject: [R] Problem merging data frames and duplicates
In-Reply-To: <CAAbnQ5ipi5MGtYri3CXoguNAp4Tq21DSN-+yaKP6QtuR-ESmVw@mail.gmail.com>
References: <CAAbnQ5gJ_B-pqz2+z15+yCXGqBobje0aOVMkSOgQVxVuacMnNg@mail.gmail.com>
	<CAA99HCyqULLzW2aodnwZ2epPWP+MSX+Q6-TGM6tRk5Ro=D-EaQ@mail.gmail.com>
	<CAAbnQ5iYF-Ajr0xNjowMJrXPbc+P+6KBN9w6OJVW+C0=_toF_A@mail.gmail.com>
	<CAAbnQ5ipi5MGtYri3CXoguNAp4Tq21DSN-+yaKP6QtuR-ESmVw@mail.gmail.com>
Message-ID: <CAA99HCxgV+arv7oxLop_8Jnhz=DGfRPrKC+1gy2bckKaQ6zphQ@mail.gmail.com>

Hi Frank!

Ok, bind columns together in a state-wise fashion, allowing for state
duplicates. Below (maybe cheesy) uses the state abbreviations
"state.abb" in the datasets package. Also uses two functions
"rbind.na" and "cbind.na", available from Andrej-Nikolai Spiess'
website at:  http://www.dr-spiess.de . These functions are pretty
helpful in that they bind without recycling, inserting NAs instead.

by.state1 <- function(df1, df2) {
  df_out <- data.frame( state1=character(), locus1=numeric(),
state2=character(), locus2=numeric() )
  for(i in 1:50) {
    df_out_per <- cbind.na(df1[df1$state == state.abb[i], ],
df2[df2$state == state.abb[i], ])
    df_out <- rbind.na(df_out, df_out_per)
  }
  df_out
}

data.frame(state=c("IL", "IL", "LA","LA", "MS","MS", "AR", "AR"),
           locus=c(1,1,2,2,3,4,5,6)) -> x

##edit y to correct number of loci (6 not 7)
data.frame(state=c("IL", "IL", "AR", "AR", "TN","TN"),
           locus=c(1,1,2,3,3,4)) -> y

> by.state1(x,y)
   state locus state locus
7     AR     5    AR     2
8     AR     6    AR     3
3     IL     1    IL     1
4     IL     1    IL     1
31    LA     2  <NA>    NA
41    LA     2  <NA>    NA
5     MS     3  <NA>    NA
6     MS     4  <NA>    NA
9   <NA>    NA    TN     3
10  <NA>    NA    TN     4

The rows will be in state alphabetical order. If you need the row
numbers cleaned up as well (numeric order) you can pre-merge your data
to states.abb:

> a <- merge(state.abb, x, by= 1, all=F)
> b <- merge(state.abb, y, by= 1, all=F)
> colnames(a) <- c("state", "locus")
> colnames(b) <- c("state", "locus")
> by.state1(a,b)

   state locus state locus
1     AR     5    AR     2
2     AR     6    AR     3
3     IL     1    IL     1
4     IL     1    IL     1
5     LA     2  <NA>    NA
6     LA     2  <NA>    NA
7     MS     3  <NA>    NA
8     MS     4  <NA>    NA
9   <NA>    NA    TN     3
10  <NA>    NA    TN     4
>

Hope this helps,

Bill

William Michels, Ph.D.


On Wed, May 27, 2015 at 4:01 AM, Frank Burbrink <burbrink666 at gmail.com> wrote:
> I have figured out a cheesy work around since these problems have to do with
> not having unique identifiers for the States:
>
> 1) Append a unique identifier to each state such that both AR becomes ARa
> and ARb
> 2) run the normal merge(x,y,by=1, all=T)
> 3) Use subst to cut the appended identifiers.
>
> While this is clunky I can just write a function to do it all at once.
>
> On Wed, May 27, 2015 at 6:20 AM, Frank Burbrink <burbrink666 at gmail.com>
> wrote:
>>
>> Thanks Bill,
>>
>> However, unique(merge(x, y, by = 1, all=T)) is giving me:
>>
>>    state locus.x locus.y
>> 1     AR       5       2
>> 2     AR       5       3
>> 3     AR       6       2
>> 4     AR       6       3
>> 5     IL       1       1
>> 9     LA       2      NA
>> 11    MS       3      NA
>> 12    MS       4      NA
>> 13    TN      NA       3
>> 14    TN      NA       4
>>
>> This has AR repeated twice and the normal double IL and LA now only listed
>> singly.
>>
>> What I am hoping for is something like this:
>>
>>    state locus.x locus.y
>> 1     AR       5       2
>> 4     AR       6       3
>> 7     IL       1       1
>> 8     IL       1       1
>> 9     LA       2      NA
>> 10    LA       2      NA
>> 11    MS       3      NA
>> 12    MS       4      NA
>> 13    TN      NA       3
>> 14    TN      NA       4
>>
>> On Wed, May 27, 2015 at 3:53 AM, William Michels <wjm1 at caa.columbia.edu>
>> wrote:
>>>
>>> Hi Frank,
>>>
>>> It looks like you're very close. I think you want:
>>>
>>> unique(merge(x, y, by = 1, all=T))
>>>
>>> Gabor Grothendieck's sqldf package is very useful if you're more
>>> comfortable with SQL-type syntax, see:
>>>
>>> https://github.com/ggrothendieck/sqldf
>>>
>>> Best Regards,
>>>
>>> William (Bill) Michels, Ph.D.
>>>
>>>
>>>
>>> On Tue, May 26, 2015 at 5:12 PM, Frank Burbrink
>>> <burbrink666 at gmail.com> wrote: <SNIP>
>>
>>
>>
>>
>> --
>>
>> ***********************************
>> Frank T. Burbrink, Ph.D.
>> Professor
>> Biology Department
>> 6S-143
>> 2800 Victory Blvd.
>> College of Staten Island/CUNY
>> Staten Island, New York 10314
>> E-Mail:Frank.Burbrink at csi.cuny.edu
>> Phone:718-982-3961
>> Web Page: http://scholar.library.csi.cuny.edu/~fburbrink/
>> ***********************************
>> Chair
>> Ecology, Evolutionary Biology, and Behavior
>> Doctoral Subprogram
>> Biology Program
>> City University of New York
>> Graduate Center
>> 365 Fifth Avenue
>> New York, NY 10016-4309
>> **********************************
>
>
>
>
> --
>
> ***********************************
> Frank T. Burbrink, Ph.D.
> Professor
> Biology Department
> 6S-143
> 2800 Victory Blvd.
> College of Staten Island/CUNY
> Staten Island, New York 10314
> E-Mail:Frank.Burbrink at csi.cuny.edu
> Phone:718-982-3961
> Web Page: http://scholar.library.csi.cuny.edu/~fburbrink/
> ***********************************
> Chair
> Ecology, Evolutionary Biology, and Behavior
> Doctoral Subprogram
> Biology Program
> City University of New York
> Graduate Center
> 365 Fifth Avenue
> New York, NY 10016-4309
> **********************************


From burbrink666 at gmail.com  Wed May 27 15:42:59 2015
From: burbrink666 at gmail.com (Frank Burbrink)
Date: Wed, 27 May 2015 09:42:59 -0400
Subject: [R] Problem merging data frames and duplicates
In-Reply-To: <CAA99HCxgV+arv7oxLop_8Jnhz=DGfRPrKC+1gy2bckKaQ6zphQ@mail.gmail.com>
References: <CAAbnQ5gJ_B-pqz2+z15+yCXGqBobje0aOVMkSOgQVxVuacMnNg@mail.gmail.com>
	<CAA99HCyqULLzW2aodnwZ2epPWP+MSX+Q6-TGM6tRk5Ro=D-EaQ@mail.gmail.com>
	<CAAbnQ5iYF-Ajr0xNjowMJrXPbc+P+6KBN9w6OJVW+C0=_toF_A@mail.gmail.com>
	<CAAbnQ5ipi5MGtYri3CXoguNAp4Tq21DSN-+yaKP6QtuR-ESmVw@mail.gmail.com>
	<CAA99HCxgV+arv7oxLop_8Jnhz=DGfRPrKC+1gy2bckKaQ6zphQ@mail.gmail.com>
Message-ID: <CAAbnQ5gAizocfv3dTr4mCTbS4FpvrA83WBaNtBdXRhuVaSHmtQ@mail.gmail.com>

Interesting solutions. Thanks guys!

On Wed, May 27, 2015 at 9:27 AM, William Michels <wjm1 at caa.columbia.edu>
wrote:

> Hi Frank!
>
> Ok, bind columns together in a state-wise fashion, allowing for state
> duplicates. Below (maybe cheesy) uses the state abbreviations
> "state.abb" in the datasets package. Also uses two functions
> "rbind.na" and "cbind.na", available from Andrej-Nikolai Spiess'
> website at:  http://www.dr-spiess.de . These functions are pretty
> helpful in that they bind without recycling, inserting NAs instead.
>
> by.state1 <- function(df1, df2) {
>   df_out <- data.frame( state1=character(), locus1=numeric(),
> state2=character(), locus2=numeric() )
>   for(i in 1:50) {
>     df_out_per <- cbind.na(df1[df1$state == state.abb[i], ],
> df2[df2$state == state.abb[i], ])
>     df_out <- rbind.na(df_out, df_out_per)
>   }
>   df_out
> }
>
> data.frame(state=c("IL", "IL", "LA","LA", "MS","MS", "AR", "AR"),
>            locus=c(1,1,2,2,3,4,5,6)) -> x
>
> ##edit y to correct number of loci (6 not 7)
> data.frame(state=c("IL", "IL", "AR", "AR", "TN","TN"),
>            locus=c(1,1,2,3,3,4)) -> y
>
> > by.state1(x,y)
>    state locus state locus
> 7     AR     5    AR     2
> 8     AR     6    AR     3
> 3     IL     1    IL     1
> 4     IL     1    IL     1
> 31    LA     2  <NA>    NA
> 41    LA     2  <NA>    NA
> 5     MS     3  <NA>    NA
> 6     MS     4  <NA>    NA
> 9   <NA>    NA    TN     3
> 10  <NA>    NA    TN     4
>
> The rows will be in state alphabetical order. If you need the row
> numbers cleaned up as well (numeric order) you can pre-merge your data
> to states.abb:
>
> > a <- merge(state.abb, x, by= 1, all=F)
> > b <- merge(state.abb, y, by= 1, all=F)
> > colnames(a) <- c("state", "locus")
> > colnames(b) <- c("state", "locus")
> > by.state1(a,b)
>
>    state locus state locus
> 1     AR     5    AR     2
> 2     AR     6    AR     3
> 3     IL     1    IL     1
> 4     IL     1    IL     1
> 5     LA     2  <NA>    NA
> 6     LA     2  <NA>    NA
> 7     MS     3  <NA>    NA
> 8     MS     4  <NA>    NA
> 9   <NA>    NA    TN     3
> 10  <NA>    NA    TN     4
> >
>
> Hope this helps,
>
> Bill
>
> William Michels, Ph.D.
>
>
> On Wed, May 27, 2015 at 4:01 AM, Frank Burbrink <burbrink666 at gmail.com>
> wrote:
> > I have figured out a cheesy work around since these problems have to do
> with
> > not having unique identifiers for the States:
> >
> > 1) Append a unique identifier to each state such that both AR becomes ARa
> > and ARb
> > 2) run the normal merge(x,y,by=1, all=T)
> > 3) Use subst to cut the appended identifiers.
> >
> > While this is clunky I can just write a function to do it all at once.
> >
> > On Wed, May 27, 2015 at 6:20 AM, Frank Burbrink <burbrink666 at gmail.com>
> > wrote:
> >>
> >> Thanks Bill,
> >>
> >> However, unique(merge(x, y, by = 1, all=T)) is giving me:
> >>
> >>    state locus.x locus.y
> >> 1     AR       5       2
> >> 2     AR       5       3
> >> 3     AR       6       2
> >> 4     AR       6       3
> >> 5     IL       1       1
> >> 9     LA       2      NA
> >> 11    MS       3      NA
> >> 12    MS       4      NA
> >> 13    TN      NA       3
> >> 14    TN      NA       4
> >>
> >> This has AR repeated twice and the normal double IL and LA now only
> listed
> >> singly.
> >>
> >> What I am hoping for is something like this:
> >>
> >>    state locus.x locus.y
> >> 1     AR       5       2
> >> 4     AR       6       3
> >> 7     IL       1       1
> >> 8     IL       1       1
> >> 9     LA       2      NA
> >> 10    LA       2      NA
> >> 11    MS       3      NA
> >> 12    MS       4      NA
> >> 13    TN      NA       3
> >> 14    TN      NA       4
> >>
> >> On Wed, May 27, 2015 at 3:53 AM, William Michels <wjm1 at caa.columbia.edu
> >
> >> wrote:
> >>>
> >>> Hi Frank,
> >>>
> >>> It looks like you're very close. I think you want:
> >>>
> >>> unique(merge(x, y, by = 1, all=T))
> >>>
> >>> Gabor Grothendieck's sqldf package is very useful if you're more
> >>> comfortable with SQL-type syntax, see:
> >>>
> >>> https://github.com/ggrothendieck/sqldf
> >>>
> >>> Best Regards,
> >>>
> >>> William (Bill) Michels, Ph.D.
> >>>
> >>>
> >>>
> >>> On Tue, May 26, 2015 at 5:12 PM, Frank Burbrink
> >>> <burbrink666 at gmail.com> wrote: <SNIP>
> >>
> >>
> >>
> >>
> >> --
> >>
> >> ***********************************
> >> Frank T. Burbrink, Ph.D.
> >> Professor
> >> Biology Department
> >> 6S-143
> >> 2800 Victory Blvd.
> >> College of Staten Island/CUNY
> >> Staten Island, New York 10314
> >> E-Mail:Frank.Burbrink at csi.cuny.edu
> >> Phone:718-982-3961
> >> Web Page: http://scholar.library.csi.cuny.edu/~fburbrink/
> >> ***********************************
> >> Chair
> >> Ecology, Evolutionary Biology, and Behavior
> >> Doctoral Subprogram
> >> Biology Program
> >> City University of New York
> >> Graduate Center
> >> 365 Fifth Avenue
> >> New York, NY 10016-4309
> >> **********************************
> >
> >
> >
> >
> > --
> >
> > ***********************************
> > Frank T. Burbrink, Ph.D.
> > Professor
> > Biology Department
> > 6S-143
> > 2800 Victory Blvd.
> > College of Staten Island/CUNY
> > Staten Island, New York 10314
> > E-Mail:Frank.Burbrink at csi.cuny.edu
> > Phone:718-982-3961
> > Web Page: http://scholar.library.csi.cuny.edu/~fburbrink/
> > ***********************************
> > Chair
> > Ecology, Evolutionary Biology, and Behavior
> > Doctoral Subprogram
> > Biology Program
> > City University of New York
> > Graduate Center
> > 365 Fifth Avenue
> > New York, NY 10016-4309
> > **********************************
>



-- 

*************************************
*Frank T. Burbrink, Ph.D.*
*Professor*
*Biology Department*
*6S-143*
*2800 Victory Blvd.*
*College of Staten Island/CUNY*
*Staten Island, New York 10314*
*E-Mail:Frank.Burbrink at csi.cuny.edu <E-Mail%3AFrank.Burbrink at csi.cuny.edu>*
*Phone:718-982-3961*
*Web Page: http://scholar.library.csi.cuny.edu/~fburbrink/
<http://scholar.library.csi.cuny.edu/%7Efburbrink/>*
*************************************
*Chair *
*Ecology, Evolutionary Biology, and Behavior*
*Doctoral Subprogram*
*Biology Program*
*City University of New York *
*Graduate Center*
*365 Fifth Avenue*
*New York, NY 10016-4309*
************************************

	[[alternative HTML version deleted]]


From mxalimohamma at ualr.edu  Wed May 27 16:18:12 2015
From: mxalimohamma at ualr.edu (Mohammad Alimohammadi)
Date: Wed, 27 May 2015 09:18:12 -0500
Subject: [R] Problem with comparing multiple data sets
In-Reply-To: <651E81B86BB.000013CBjrkrideau@inbox.com>
References: <CAJVfk9nuZDJdadGobNHDTP2cY_a06XrLZYj8x8393+LeB0OWfg@mail.gmail.com>
	<651E81B86BB.000013CBjrkrideau@inbox.com>
Message-ID: <CAJVfk9=4KdEh01gOHFN279y5ESOcNzUzbVHqUmgMPC1Z_HbLWg@mail.gmail.com>

Hi John,

I created the original data set with dput . This time I only loaded 50
values for each data set (dat1, dat2, dat3).

About your question, all 0,1 and 2 are indicator of a specific class. The
task is to compare 3 independent classification of a certain term and and
determine the actual class of the term by finding the most frequent
assigned number for that term.

I thought it might be easier to combine them into 1 data frame but either
way is fine.

Let me know if it shows up clean. I saved the dput in txt file and copied
here from that file. I assume this is the right way to do it. I might be
wrong.


==============================================

*dat1*

structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
c("#dac",
"#mac,#security", "accountability,anonymous", "data
security,encryption,security"
), class = "factor")), .Names = c("class.1", "terms"), class =
"data.frame", row.names = c(NA,
-49L))


*dat2*

structure(list(class.2 = c(2L, 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L,
2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L), terms = structure(c(1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
c("#dac",
"#mac,#security", "accountability,anonymous", "data
security,encryption,security"
), class = "factor")), .Names = c("class.2", "terms"), class =
"data.frame", row.names = c(NA,
-49L))

*dat3*

structure(list(class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
c("#dac",
"#mac,#security", "accountability,anonymous", "data
security,encryption,security"
), class = "factor")), .Names = c("class.3", "terms"), class =
"data.frame", row.names = c(NA,
-49L))

=============================================









On Wed, May 27, 2015 at 8:05 AM, John Kane <jrkrideau at inbox.com> wrote:

> Hi Mohammad,
>
> I went back and reread your original statement of the problem about and I
> think I kinda grasp it. It is actually quite clear and I misunderstood it
> completely.
>
> At the moment I have no idea how to approach it.  As Jim Lemon said, it
> looks easy but may not be.  I'll go back and re-examine Jim's approach.
>
> You might want to create three sample data sets of the original data
> layouts and upload them, in dput() format, to the list.  It may be easier
> to tackle from that approach.
>
> In any case, in the existing data set is a 2 a numeric value 2 or just an
> on/off indicator?
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: mxalimohamma at ualr.edu
> > Sent: Tue, 26 May 2015 20:11:08 -0500
> > To: r-help at r-project.org
> > Subject: Re: [R] Problem with comparing multiple data sets
> >
> > Thank you John. Yes. as you mentioned this is not really what I am
> > looking
> > for.
> >
> > It's interesting because I was really thinking that it should be pretty
> > easy. All I need to do is just compare class1, class2 and class3 for each
> > text and put the most frequent number next to it in each row. Repeat it
> > for
> > all the rows. Apparently it's not that simple.
> >
> > Sorry I didn't notice that I sent it only to you! Thanks for letting me
> > know.
> >
> > I appreciate if anybody can help on this.
> >
> > Thank you.
> >
> >
> >
> >
> > On Tue, May 26, 2015 at 7:27 PM, John Kane <jrkrideau at inbox.com> wrote:
> >
> >> Hi Mohammad,
> >>
> >> The data came through beautifully despite the fact that you posted in
> >> HTML.  Please, post in plain text.
> >>
> >> Oh, just as I was ready to push Send, I  noticed you only replied to me.
> >> You really should reply to the R-help list since there are a lot more
> >> and
> >> better people to help there. Besides it's a world-wide list. Others can
> >> play with the problem while we sleep :) .
> >>
> >> I will just reply to you but I really suggest sending all of this to the
> >> list.
> >>
> >> Now I am wondering what to do with the data. As a first swipe I just
> >> added
> >> up all the values in each class by each text value. Results are below.
> >> Not
> >> what you want by any means but perhaps a small step.
> >>
> >> Then I started to think are we really interested in the sum or should we
> >> be looking at incidence, that is should we be looking at the frequency
> >> rather than the sum?
> >>
> >> Is
> >> class.1 class.2   class  #dac
> >>   0           2              0
> >>
> >> a value of 2 (sum) or a hit of 1 (count or freq) ?
> >>
> >> Anyway below is what I have tried so far -- it may not be anywhere near
> >> what you want but if it makes any sense then I think we just need to
> >> pick
> >> off the highest values for each combination of terms and class to give
> >> you
> >> what you want.
> >>
> >> I suspect our real data-munging gurus can do  all this faster and better
> >> than I can but hopefully it is a start.
> >>
> >> Where your data set is dat1
> >> #=====================================
> >> # If reshape2 is not installed.
> >> install.packages("reshape2")
> >> #=====================================
> >>
> >> library(reshape2)
> >>  mdat  <-  melt(dat1, id.vars= c("terms"),
> >>        variable.name = "class",
> >>        value.name = "value",
> >>        na.rm = FALSE)
> >>
> >> mdat1  <-  aggregate(value ~ terms + class, data = mdat, sum)
> >>
> >> mdat1[order(mdat1$terms, mdat1$class), ]
> >>
> >> #=====================================
> >>
> >>
> >> John Kane
> >> Kingston ON Canada
> >>
> >> -----Original Message-----
> >> From: mxalimohamma at ualr.edu
> >> Sent: Tue, 26 May 2015 09:50:43 -0500
> >> To: jrkrideau at inbox.com
> >> Subject: Re: [R] Problem with comparing multiple data sets
> >>
> >> Thank you John for being patient with me.
> >>
> >> My original post was to compare 3 sets of data which had difference in
> >> their class value for the same text. However, I thought it might be
> >> easier
> >> to combine those 3 data sets into one that shows the 3 different classes
> >> and then find the most frequent class value for the text. So that's what
> >> I
> >> did. Now I only want to add the most frequent class value in a new
> >> column.
> >>
> >> I tried to create a dput version of the data set (Only a small part of
> >> it)
> >> so you can see. I hope it works.
> >>
> >>> Tweet1<- read.csv(file="part1_complete.csv",head=TRUE,sep= ",")
> >>
> >>> dput(head(Tweet1, 100))
> >>
> >> structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >>
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >>
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
> >>
> >> 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 0L, 1L, 2L, 2L, 2L, 1L, 1L, 1L,
> >>
> >> 1L, 2L, 1L, 1L, 1L, 0L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> >>
> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >>
> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L), class.2 = c(2L,
> >>
> >> 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >>
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >>
> >> 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L,
> >>
> >> 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L,
> >>
> >> 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
> >>
> >> 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >>
> >> 1L, 1L, 1L), class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >>
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >>
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
> >>
> >> 1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L, 0L, 2L, 2L, 0L, 2L, 1L, 1L, 1L,
> >>
> >> 1L, 0L, 0L, 0L, 2L, 1L, 0L, 0L, 1L, 0L, 0L, 2L, 2L, 2L, 2L, 2L,
> >>
> >> 0L, 2L, 2L, 1L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
> >>
> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L), terms = structure(c(9L,
> >>
> >> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> >>
> >> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> >>
> >> 9L, 9L, 9L, 9L, 69L, 69L, 69L, 69L, 69L, 40L, 40L, 40L, 40L,
> >>
> >> 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 98L, 98L, 98L, 98L, 98L,
> >>
> >> 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 23L, 87L, 87L, 87L,
> >>
> >> 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L,
> >>
> >> 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L,
> >>
> >> 87L, 87L), .Label = c("#accountability",
> >> "#accountability,#anonymity,anonymity",
> >>
> >> "#accountability,recovery", "#anonymity,anonymity",
> >> "#anonymous,anonymous",
> >>
> >> "#attacker,security", "#authentication,access control", "#confidential",
> >>
> >> "#dac", "#encryption,#privacy,#security", "#identifier",
> >> "#identifier,identifier",
> >>
> >> "#intrusion,#security,security", "#mac", "#mac,#security",
> >> "#mac,password",
> >>
> >> "#mac,security", "#password,privacy", "#password,security",
> >> "#prevention,prevention",
> >>
> >> "#privacy,#security,password", "#privacy,identifiable",
> >> "#privacy,information privacy,privacy",
> >>
> >> "#privacy,intrusion", "#privacy,location privacy,privacy",
> >> "#privacy,password,security",
> >>
> >> "#privacy,personal data", "#privacy,personal information,privacy",
> >>
> >> "#privacy,security", "#pseudonym", "#pseudonymity",
> >> "#security,authentication,identity management",
> >>
> >> "#security,identity management,security", "#security,mac,security",
> >>
> >> "#security,malicious,security", "#security,personal information",
> >>
> >> "#security,retention", "#token", "#token,token",
> >> "accountability,anonymous",
> >>
> >> "accountability,audit trail", "accountability,confidential",
> >>
> >> "accountability,security", "accountability,token", "adversary,pin",
> >>
> >> "anonymity,authentication", "anonymity,security",
> >> "anonymous,disclosure",
> >>
> >> "anonymous,password", "authentication,password,security",
> >> "authorization,mac",
> >>
> >> "authorization,permission", "confidential,disclosure",
> >> "confidential,disclosure,security",
> >>
> >> "confidential,mac", "confidential,personal information",
> >> "confidential,pin",
> >>
> >> "confidential,privilege", "confidentiality,security", "consent",
> >>
> >> "dac", "dac,pcm", "data aggregation,privacy", "data controller",
> >>
> >> "data protection,encryption", "data protection,recovery", "data
> >> protection,security",
> >>
> >> "data quality,security", "data security,encryption,security",
> >>
> >> "data security,mac,security", "data security,personal data,security",
> >>
> >> "data security,prevention,security", "detection", "detection,mac",
> >>
> >> "detection,password", "deterrence,prevention", "digital signature",
> >>
> >> "disclosure,password", "disclosure,private information",
> >> "disclosure,security",
> >>
> >> "encryption,password,recovery", "encryption,private data", "id
> >> management,privacy",
> >>
> >> "id management,security", "identifier", "identifier,token", "location
> >> privacy,privacy",
> >>
> >> "mac,password,security", "mac,permission", "mac,prevention",
> >>
> >> "mac,privacy", "mac,pseudonym", "malicious,prevention",
> >> "non-repudiation",
> >>
> >> "password,prevention,security", "password,private information",
> >>
> >> "password,recovery", "password,user id", "permission,personal data",
> >>
> >> "permission,privacy,privacy policy", "personal data", "personal
> >> identification number,pin",
> >>
> >> "personal information", "personal information,security", "prevention",
> >>
> >> "prevention,privilege", "privacy,privacy policy", "privacy,privacy
> >> preferences",
> >>
> >> "private information,security", "recovery,retention", "recovery,token",
> >>
> >> "retention,token", "sensitive data", "token"), class = "factor")),
> >> .Names
> >> = c("class.1",
> >>
> >> "class.2", "class.3", "terms"), row.names = c(NA, 100L), class =
> >> "data.frame")
> >>
> >> On Mon, May 25, 2015 at 2:04 PM, John Kane <jrkrideau at inbox.com> wrote:
> >>
> >>         Hi Mohammad,
> >>
> >>  If you are just starting with R a sense of total confusion is often the
> >> first feeling.  Welcome :).
> >>
> >>  If you are a SAS or SPSS user this may help
> >>
> https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf
> >> [
> >>
> https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf
> >> ]
> >>
> >>  If anything,  I am even more lost than before.
> >>
> >>  Did Jim Lemon's approach help? Confuse ?
> >>
> >>  Perhaps one of the problems is that the data did not come through
> >> cleanly.  You posted in HTML and the R-help list strips out all HTML so
> >> the
> >> result often is mangled beyond any real use.
> >>
> >>  I may have imagined that your data are more complicated than they
> >> really
> >> are if all you really want is some kind of frequency count possibly by
> >> some
> >> conditioning variable. Is this it?
> >>
> >>   It seems too simple but that is what I read that Excel is doing (as
> >> incompetently as usual---I had not realised it was possible to be even
> >> less
> >> impressed with Excel than I already  was.)
> >>
> >>  Can you send us some more data in dput() format. See the links I
> >> provided
> >> earlier or have a look at ?dput for more information.
> >>
> >>  If you have lot of data, a representative sample is fine.  It is often
> >> enough to do something like :
> >>  dput(head(mydata, 100))
> >>  which supplies 100 rows of data.
> >>
> >>  Just output the dput() data, copy and paste into your email,  et voil?
> >> we have the exact same data.
> >>
> >>  The reason for dput() is that it provides a snapshot of exactly how the
> >> data exists on your machine. Given all sorts of differences between
> >> OS's,
> >> personal settings, human languages and so on. what I or another R-help
> >> reader see  or read in may not correspond to what you have. Using dput()
> >> avoids all of this.
> >>
> >>  Here is a simple example of what I mean. If you look at dat1 and dat2
> >> they 'look' the same but ... I could read in data either way depending
> >> on
> >> all sorts of variable and have no idea which, if either is how you see
> >> the
> >> data.
> >>
> >>   Data are supplied in dput() format, just copy and paste into R.
> >>  =====
> >>  dat1  <- structure(list(aa = structure(1:10, .Label = c("1", "2", "3",
> >>  "4", "5", "6", "7", "8", "9", "10"), class = "factor"), bb = c(10L,
> >>  9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L, 1L)), .Names = c("aa", "bb"), row.names
> >> =
> >> c(NA,
> >>  -10L), class = "data.frame")
> >>
> >>  dat2  <-  structure(list(aa = 1:10, bb = c(10L, 9L, 8L, 7L, 6L, 5L, 4L,
> >>  3L, 2L, 1L)), .Names = c("aa", "bb"), row.names = c(NA, -10L), class =
> >> "data.frame")
> >>
> >>  dat1
> >>  dat2  # looks a lot like dat1
> >>
> >>  with(dat1, aa*bb)
> >>  with(dat2 , aa*bb)
> >>
> >>  str(dat1)
> >>  str(dat2)
> >>
> >>  =======
> >>
> >>  John Kane
> >>  Kingston ON Canada
> >>
> >>  -----Original Message-----
> >>  From: mxalimohamma at ualr.edu
> >>  Sent: Mon, 25 May 2015 12:14:46 -0500
> >>  To: jrkrideau at inbox.com
> >>  Subject: Re: [R] Problem with comparing multiple data sets
> >>
> >>  Hi John.
> >>
> >>  Thank you for your response.
> >>
> >>  Here is a small portion of my actual data set. What I am supposed to do
> >> is to use a function similar to mode function in excel to find the most
> >> frequent value (class) for each term.
> >>
> >>    V1 V2 V3 V4
> >>
> >>  1 class 1 class 2 class 3 terms
> >>
> >>  2 0 2 0 #dac
> >>
> >>  3 0 2          0 #dac
> >>
> >>  4 0 2 0 #dac
> >>
> >>  5 0 2 0 #dac
> >>
> >>  6 1 0 1 #dac
> >>
> >>  7 0 0 0 #dac
> >>
> >>  ....
> >>
> >>  Since I just started using R. I don't know where I am going with this.
> >> I
> >> appreciate any help.
> >>
> >>  On Sat, May 23, 2015 at 8:23 AM, John Kane <jrkrideau at inbox.com>
> wrote:
> >>
> >>          Hi Mohammad
> >>
> >>   Welcome to the R-help list.
> >>
> >>   There probably is a fairly easy way to what you want but I think we
> >> probably need a bit more background information on what you are trying
> >> to
> >> achieve.  I know I'm not exactly clear on your decision rule(s).
> >>
> >>   It would also be very useful to see some actual sample data in useable
> >> R
> >> format.Have a look at these links
> >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >> [
> >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> ]
> >> [
> >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >> [
> >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> ]]
> >> and http://adv-r.had.co.nz/Reproducibility.html [
> >> http://adv-r.had.co.nz/Reproducibility.html] [
> >> http://adv-r.had.co.nz/Reproducibility.html [
> >> http://adv-r.had.co.nz/Reproducibility.html]] for some hints on what
> you
> >> might want to include in your question.
> >>
> >>   In particular, read up about dput()  in those links and/or see ?dput.
> >> This is the generally preferred way to supply sample or illustrative
> >> data
> >> to the R-help list.  It basically creates a perfect copy of the data as
> >> it
> >> exists on 'your' machine so that R-help readers see exactly what you do.
> >>
> >>   John Kane
> >>   Kingston ON Canada
> >>
> >>   > -----Original Message-----
> >>   > From: mxalimohamma at ualr.edu
> >>   > Sent: Fri, 22 May 2015 12:37:50 -0500
> >>   > To: r-help at r-project.org
> >>   > Subject: [R] Problem with comparing multiple data sets
> >>   >
> >>   > Hi everyone,
> >>   >
> >>   > I am very new to R and I have a task to do. I appreciate any help. I
> >> have
> >>   > 3
> >>   > data sets. Each data set has 4 columns. For example:
> >>   >
> >>   > Class  Comment   Term   Text
> >>   > 0           com1        aac    text1
> >>   > 2           com2        aax    text2
> >>   > 1           com3        vvx    text3
> >>   >
> >>   > Now I need t compare the class section between 3 data sets and
> >> assign
> >> the
> >>   > most available class to that text. For example if text1 is assigned
> >> to
> >>   > class 0 in data set 1&2 but assigned as 2 in data set 3 then it
> >> should
> >> be
> >>   > assigned to class 0. If they are all the same so the class will be
> >> the
> >>   > same. The ideal thing would be to keep the same format and just
> >> update
> >>   > the
> >>   > class. Is there any easy way to do this?
> >>   >
> >>   > Thanks a lot.
> >>   >
> >>
> >>  >       [[alternative HTML version deleted]]
> >>   >
> >>   > ______________________________________________
> >>   > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>
> >>  > https://stat.ethz.ch/mailman/listinfo/r-help [
> >> https://stat.ethz.ch/mailman/listinfo/r-help] [
> >> https://stat.ethz.ch/mailman/listinfo/r-help [
> >> https://stat.ethz.ch/mailman/listinfo/r-help]]
> >>   > PLEASE do read the posting guide
> >>   > http://www.R-project.org/posting-guide.html [
> >> http://www.R-project.org/posting-guide.html] [
> >> http://www.R-project.org/posting-guide.html [
> >> http://www.R-project.org/posting-guide.html]]
> >>   > and provide commented, minimal, self-contained, reproducible code.
> >>
> >>   ____________________________________________________________
> >>   FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> >>   Check it out at http://www.inbox.com/earth
> >> [http://www.inbox.com/earth]
> >> [http://www.inbox.com/earth [http://www.inbox.com/earth]]
> >>
> >>  --
> >>
> >>  Mohammad Alimohammadi | Graduate Assistant
> >>  University of Arkansas at Little Rock | College of Science
> >> and Mathematics (CSAM)
> >>
> >>  501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu] [
> >> http://ualr.edu/ [http://ualr.edu/]]
> >>
> >>  Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
> >> http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [
> >> http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
> >> http://scholar.google.com/citations?user=MsfN_i8AAAAJ]]
> >>
> >>  ____________________________________________________________
> >>  FREE ONLINE PHOTOSHARING - Share your photos online with your friends
> >> and
> >> family!
> >>  Visit http://www.inbox.com/photosharing [
> >> http://www.inbox.com/photosharing] to find out more!
> >>
> >> --
> >>
> >> Mohammad Alimohammadi | Graduate Assistant
> >> University of Arkansas at Little Rock | College of Science and
> >> Mathematics
> >> (CSAM)
> >>
> >> 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu/]
> >>
> >> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
> >> http://scholar.google.com/citations?user=MsfN_i8AAAAJ]
> >>
> >> ____________________________________________________________
> >> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> >> Check it out at http://www.inbox.com/earth
> >>
> >>
> >>
> >
> >
> > --
> > Mohammad Alimohammadi | Graduate Assistant
> > University of Arkansas at Little Rock | College of Science and
> > Mathematics
> > (CSAM)
> > 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu
> >
> > Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/password-manager
>
>
>


-- 
Mohammad Alimohammadi | Graduate Assistant
University of Arkansas at Little Rock | College of Science and Mathematics
(CSAM)
501.346.8007 | mxalimohamma at ualr.edu | ualr.edu

Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ

	[[alternative HTML version deleted]]


From mxalimohamma at ualr.edu  Wed May 27 16:37:24 2015
From: mxalimohamma at ualr.edu (Mohammad Alimohammadi)
Date: Wed, 27 May 2015 09:37:24 -0500
Subject: [R] Problem with comparing multiple data sets
In-Reply-To: <65E09D319F0.00001550jrkrideau@inbox.com>
References: <cajvfk9nuzdjdadgobnhdtp2cy_a06xrlzyj8x8393+leb0owfg@mail.gmail.com>
	<651e81b86bb.000013cbjrkrideau@inbox.com>
	<CAJVfk9=4KdEh01gOHFN279y5ESOcNzUzbVHqUmgMPC1Z_HbLWg@mail.gmail.com>
	<65E09D319F0.00001550jrkrideau@inbox.com>
Message-ID: <CAJVfk9mtzPpyG=_vFmvX2YXjP_RXsda5bV+VYMrp_m0KvN03KQ@mail.gmail.com>

Thanks John,

I really hope it can be answered. Yes all 3 data sets have the same items.

On Wed, May 27, 2015 at 9:32 AM, John Kane <jrkrideau at inbox.com> wrote:

> Thanks Mohammad.
> The data appear to have come through just fine. This probably means you
> can ignore some of the questions I just sent you -- our emails are crossing.
>
> I probably will not get a chance  to look at this til this afternoon
> (10:25 here now). We can hope someone with more skill than I have will have
> solved the problem by then.
>
> This is starting to sound a bit like a psychometric inter-rater
> reliability study.  Does each data set contain the same set of items ?
>
>
> John Kane
> Kingston ON Canada
>
> -----Original Message-----
> From: mxalimohamma at ualr.edu
> Sent: Wed, 27 May 2015 09:18:12 -0500
> To: jrkrideau at inbox.com, r-help at r-project.org
> Subject: Re: [R] Problem with comparing multiple data sets
>
> Hi John,
>
> I created the original data set with dput . This time I only loaded 50
> values for each data set (dat1, dat2, dat3).
>
> About your question, all 0,1 and 2 are indicator of a specific class. The
> task is to compare 3 independent classification of a certain term and and
> determine the actual class of the term by finding the most frequent
> assigned number for that term.
>
> I thought it might be easier to combine them into 1 data frame but either
> way is fine.
>
> Let me know if it shows up clean. I saved the dput in txt file and copied
> here from that file. I assume this is the right way to do it. I might be
> wrong.
>
> ==============================================
>
> dat1
>
> structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
>
> 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
>
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
> c("#dac",
>
> "#mac,#security", "accountability,anonymous", "data
> security,encryption,security"
>
> ), class = "factor")), .Names = c("class.1", "terms"), class =
> "data.frame", row.names = c(NA,
>
> -49L))
>
> dat2
>
> structure(list(class.2 = c(2L, 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L,
>
> 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L), terms = structure(c(1L, 1L,
>
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
> c("#dac",
>
> "#mac,#security", "accountability,anonymous", "data
> security,encryption,security"
>
> ), class = "factor")), .Names = c("class.2", "terms"), class =
> "data.frame", row.names = c(NA,
>
> -49L))
>
> dat3
>
> structure(list(class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
>
> 1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
>
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
> c("#dac",
>
> "#mac,#security", "accountability,anonymous", "data
> security,encryption,security"
>
> ), class = "factor")), .Names = c("class.3", "terms"), class =
> "data.frame", row.names = c(NA,
>
> -49L))
>
> =============================================
>
> On Wed, May 27, 2015 at 8:05 AM, John Kane <jrkrideau at inbox.com> wrote:
>
>         Hi Mohammad,
>
>  I went back and reread your original statement of the problem about and I
> think I kinda grasp it. It is actually quite clear and I misunderstood it
> completely.
>
>  At the moment I have no idea how to approach it.  As Jim Lemon said, it
> looks easy but may not be.  I'll go back and re-examine Jim's approach.
>
>  You might want to create three sample data sets of the original data
> layouts and upload them, in dput() format, to the list.  It may be easier
> to tackle from that approach.
>
>  In any case, in the existing data set is a 2 a numeric value 2 or just an
> on/off indicator?
>
>  John Kane
>  Kingston ON Canada
>
>  > -----Original Message-----
>  > From: mxalimohamma at ualr.edu
>
> > Sent: Tue, 26 May 2015 20:11:08 -0500
>  > To: r-help at r-project.org
>  > Subject: Re: [R] Problem with comparing multiple data sets
>  >
>  > Thank you John. Yes. as you mentioned this is not really what I am
>  > looking
>  > for.
>  >
>  > It's interesting because I was really thinking that it should be pretty
>  > easy. All I need to do is just compare class1, class2 and class3 for
> each
>  > text and put the most frequent number next to it in each row. Repeat it
>  > for
>  > all the rows. Apparently it's not that simple.
>  >
>  > Sorry I didn't notice that I sent it only to you! Thanks for letting me
>  > know.
>  >
>  > I appreciate if anybody can help on this.
>  >
>  > Thank you.
>  >
>  >
>  >
>  >
>  > On Tue, May 26, 2015 at 7:27 PM, John Kane <jrkrideau at inbox.com> wrote:
>  >
>  >> Hi Mohammad,
>  >>
>  >> The data came through beautifully despite the fact that you posted in
>  >> HTML.  Please, post in plain text.
>  >>
>  >> Oh, just as I was ready to push Send, I  noticed you only replied to
> me.
>  >> You really should reply to the R-help list since there are a lot more
>  >> and
>  >> better people to help there. Besides it's a world-wide list. Others can
>  >> play with the problem while we sleep :) .
>  >>
>  >> I will just reply to you but I really suggest sending all of this to
> the
>  >> list.
>  >>
>  >> Now I am wondering what to do with the data. As a first swipe I just
>  >> added
>  >> up all the values in each class by each text value. Results are below.
>  >> Not
>  >> what you want by any means but perhaps a small step.
>  >>
>  >> Then I started to think are we really interested in the sum or should
> we
>  >> be looking at incidence, that is should we be looking at the frequency
>  >> rather than the sum?
>  >>
>  >> Is
>  >> class.1 class.2   class  #dac
>  >>   0           2              0
>  >>
>  >> a value of 2 (sum) or a hit of 1 (count or freq) ?
>  >>
>  >> Anyway below is what I have tried so far -- it may not be anywhere near
>  >> what you want but if it makes any sense then I think we just need to
>  >> pick
>  >> off the highest values for each combination of terms and class to give
>  >> you
>  >> what you want.
>  >>
>  >> I suspect our real data-munging gurus can do  all this faster and
> better
>  >> than I can but hopefully it is a start.
>  >>
>  >> Where your data set is dat1
>  >> #=====================================
>  >> # If reshape2 is not installed.
>  >> install.packages("reshape2")
>  >> #=====================================
>  >>
>  >> library(reshape2)
>  >>  mdat  <-  melt(dat1, id.vars= c("terms"),
>  >>        variable.name [http://variable.name] = "class",
>  >>        value.name [http://value.name] = "value",
>  >>        na.rm = FALSE)
>  >>
>  >> mdat1  <-  aggregate(value ~ terms + class, data = mdat, sum)
>  >>
>  >> mdat1[order(mdat1$terms, mdat1$class), ]
>  >>
>  >> #=====================================
>  >>
>  >>
>  >> John Kane
>  >> Kingston ON Canada
>  >>
>  >> -----Original Message-----
>  >> From: mxalimohamma at ualr.edu
>  >> Sent: Tue, 26 May 2015 09:50:43 -0500
>  >> To: jrkrideau at inbox.com
>  >> Subject: Re: [R] Problem with comparing multiple data sets
>  >>
>  >> Thank you John for being patient with me.
>  >>
>  >> My original post was to compare 3 sets of data which had difference in
>  >> their class value for the same text. However, I thought it might be
>  >> easier
>  >> to combine those 3 data sets into one that shows the 3 different
> classes
>  >> and then find the most frequent class value for the text. So that's
> what
>  >> I
>  >> did. Now I only want to add the most frequent class value in a new
>  >> column.
>  >>
>  >> I tried to create a dput version of the data set (Only a small part of
>  >> it)
>  >> so you can see. I hope it works.
>  >>
>  >>> Tweet1<- read.csv(file="part1_complete.csv",head=TRUE,sep= ",")
>  >>
>  >>> dput(head(Tweet1, 100))
>  >>
>  >> structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>  >>
>  >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>  >>
>  >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
>  >>
>  >> 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 0L, 1L, 2L, 2L, 2L, 1L, 1L, 1L,
>  >>
>  >> 1L, 2L, 1L, 1L, 1L, 0L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>  >>
>  >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>  >>
>  >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L), class.2 = c(2L,
>  >>
>  >> 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>  >>
>  >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>  >>
>  >> 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L,
>  >>
>  >> 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L,
>  >>
>  >> 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
>  >>
>  >> 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>  >>
>  >> 1L, 1L, 1L), class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>  >>
>  >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>  >>
>  >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
>  >>
>  >> 1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L, 0L, 2L, 2L, 0L, 2L, 1L, 1L, 1L,
>  >>
>  >> 1L, 0L, 0L, 0L, 2L, 1L, 0L, 0L, 1L, 0L, 0L, 2L, 2L, 2L, 2L, 2L,
>  >>
>  >> 0L, 2L, 2L, 1L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
>  >>
>  >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L), terms = structure(c(9L,
>  >>
>  >> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
>  >>
>  >> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
>  >>
>  >> 9L, 9L, 9L, 9L, 69L, 69L, 69L, 69L, 69L, 40L, 40L, 40L, 40L,
>  >>
>  >> 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 98L, 98L, 98L, 98L, 98L,
>  >>
>  >> 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 98L, 23L, 87L, 87L, 87L,
>  >>
>  >> 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L,
>  >>
>  >> 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L,
>  >>
>  >> 87L, 87L), .Label = c("#accountability",
>  >> "#accountability,#anonymity,anonymity",
>  >>
>  >> "#accountability,recovery", "#anonymity,anonymity",
>  >> "#anonymous,anonymous",
>  >>
>  >> "#attacker,security", "#authentication,access control",
> "#confidential",
>  >>
>  >> "#dac", "#encryption,#privacy,#security", "#identifier",
>  >> "#identifier,identifier",
>  >>
>  >> "#intrusion,#security,security", "#mac", "#mac,#security",
>  >> "#mac,password",
>  >>
>  >> "#mac,security", "#password,privacy", "#password,security",
>  >> "#prevention,prevention",
>  >>
>  >> "#privacy,#security,password", "#privacy,identifiable",
>  >> "#privacy,information privacy,privacy",
>  >>
>  >> "#privacy,intrusion", "#privacy,location privacy,privacy",
>  >> "#privacy,password,security",
>  >>
>  >> "#privacy,personal data", "#privacy,personal information,privacy",
>  >>
>  >> "#privacy,security", "#pseudonym", "#pseudonymity",
>  >> "#security,authentication,identity management",
>  >>
>  >> "#security,identity management,security", "#security,mac,security",
>  >>
>  >> "#security,malicious,security", "#security,personal information",
>  >>
>  >> "#security,retention", "#token", "#token,token",
>  >> "accountability,anonymous",
>  >>
>  >> "accountability,audit trail", "accountability,confidential",
>  >>
>  >> "accountability,security", "accountability,token", "adversary,pin",
>  >>
>  >> "anonymity,authentication", "anonymity,security",
>  >> "anonymous,disclosure",
>  >>
>  >> "anonymous,password", "authentication,password,security",
>  >> "authorization,mac",
>  >>
>  >> "authorization,permission", "confidential,disclosure",
>  >> "confidential,disclosure,security",
>  >>
>  >> "confidential,mac", "confidential,personal information",
>  >> "confidential,pin",
>  >>
>  >> "confidential,privilege", "confidentiality,security", "consent",
>  >>
>  >> "dac", "dac,pcm", "data aggregation,privacy", "data controller",
>  >>
>  >> "data protection,encryption", "data protection,recovery", "data
>  >> protection,security",
>  >>
>  >> "data quality,security", "data security,encryption,security",
>  >>
>  >> "data security,mac,security", "data security,personal data,security",
>  >>
>  >> "data security,prevention,security", "detection", "detection,mac",
>  >>
>  >> "detection,password", "deterrence,prevention", "digital signature",
>  >>
>  >> "disclosure,password", "disclosure,private information",
>  >> "disclosure,security",
>  >>
>  >> "encryption,password,recovery", "encryption,private data", "id
>  >> management,privacy",
>  >>
>  >> "id management,security", "identifier", "identifier,token", "location
>  >> privacy,privacy",
>  >>
>  >> "mac,password,security", "mac,permission", "mac,prevention",
>  >>
>  >> "mac,privacy", "mac,pseudonym", "malicious,prevention",
>  >> "non-repudiation",
>  >>
>  >> "password,prevention,security", "password,private information",
>  >>
>  >> "password,recovery", "password,user id", "permission,personal data",
>  >>
>  >> "permission,privacy,privacy policy", "personal data", "personal
>  >> identification number,pin",
>  >>
>  >> "personal information", "personal information,security", "prevention",
>  >>
>  >> "prevention,privilege", "privacy,privacy policy", "privacy,privacy
>  >> preferences",
>  >>
>  >> "private information,security", "recovery,retention", "recovery,token",
>  >>
>  >> "retention,token", "sensitive data", "token"), class = "factor")),
>  >> .Names
>  >> = c("class.1",
>  >>
>  >> "class.2", "class.3", "terms"), row.names = c(NA, 100L), class =
>  >> "data.frame")
>  >>
>  >> On Mon, May 25, 2015 at 2:04 PM, John Kane <jrkrideau at inbox.com>
> wrote:
>  >>
>  >>         Hi Mohammad,
>  >>
>  >>  If you are just starting with R a sense of total confusion is often
> the
>  >> first feeling.  Welcome :).
>  >>
>  >>  If you are a SAS or SPSS user this may help
>  >>
> https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf
> [
> https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf
> ]
>  >> [
>  >>
> https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf
> [
> https://science.nature.nps.gov/im/datamgmt/statistics/r/documents/r_for_sas_spss_users.pdf
> ]
>  >> ]
>  >>
>  >>  If anything,  I am even more lost than before.
>  >>
>  >>  Did Jim Lemon's approach help? Confuse ?
>  >>
>  >>  Perhaps one of the problems is that the data did not come through
>  >> cleanly.  You posted in HTML and the R-help list strips out all HTML so
>  >> the
>  >> result often is mangled beyond any real use.
>  >>
>  >>  I may have imagined that your data are more complicated than they
>  >> really
>  >> are if all you really want is some kind of frequency count possibly by
>  >> some
>  >> conditioning variable. Is this it?
>  >>
>  >>   It seems too simple but that is what I read that Excel is doing (as
>  >> incompetently as usual---I had not realised it was possible to be even
>  >> less
>  >> impressed with Excel than I already  was.)
>  >>
>  >>  Can you send us some more data in dput() format. See the links I
>  >> provided
>  >> earlier or have a look at ?dput for more information.
>  >>
>  >>  If you have lot of data, a representative sample is fine.  It is often
>  >> enough to do something like :
>  >>  dput(head(mydata, 100))
>  >>  which supplies 100 rows of data.
>  >>
>  >>  Just output the dput() data, copy and paste into your email,  et voil?
>  >> we have the exact same data.
>  >>
>  >>  The reason for dput() is that it provides a snapshot of exactly how
> the
>  >> data exists on your machine. Given all sorts of differences between
>  >> OS's,
>  >> personal settings, human languages and so on. what I or another R-help
>  >> reader see  or read in may not correspond to what you have. Using
> dput()
>  >> avoids all of this.
>  >>
>  >>  Here is a simple example of what I mean. If you look at dat1 and dat2
>  >> they 'look' the same but ... I could read in data either way depending
>  >> on
>  >> all sorts of variable and have no idea which, if either is how you see
>  >> the
>  >> data.
>  >>
>  >>   Data are supplied in dput() format, just copy and paste into R.
>  >>  =====
>  >>  dat1  <- structure(list(aa = structure(1:10, .Label = c("1", "2", "3",
>  >>  "4", "5", "6", "7", "8", "9", "10"), class = "factor"), bb = c(10L,
>  >>  9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L, 1L)), .Names = c("aa", "bb"),
> row.names
>  >> =
>  >> c(NA,
>  >>  -10L), class = "data.frame")
>  >>
>  >>  dat2  <-  structure(list(aa = 1:10, bb = c(10L, 9L, 8L, 7L, 6L, 5L,
> 4L,
>  >>  3L, 2L, 1L)), .Names = c("aa", "bb"), row.names = c(NA, -10L), class =
>  >> "data.frame")
>  >>
>  >>  dat1
>  >>  dat2  # looks a lot like dat1
>  >>
>  >>  with(dat1, aa*bb)
>  >>  with(dat2 , aa*bb)
>  >>
>  >>  str(dat1)
>  >>  str(dat2)
>  >>
>  >>  =======
>  >>
>  >>  John Kane
>  >>  Kingston ON Canada
>  >>
>  >>  -----Original Message-----
>  >>  From: mxalimohamma at ualr.edu
>  >>  Sent: Mon, 25 May 2015 12:14:46 -0500
>  >>  To: jrkrideau at inbox.com
>  >>  Subject: Re: [R] Problem with comparing multiple data sets
>  >>
>  >>  Hi John.
>  >>
>  >>  Thank you for your response.
>  >>
>  >>  Here is a small portion of my actual data set. What I am supposed to
> do
>  >> is to use a function similar to mode function in excel to find the most
>  >> frequent value (class) for each term.
>  >>
>  >>    V1 V2 V3 V4
>  >>
>  >>  1 class 1 class 2 class 3 terms
>  >>
>  >>  2 0 2 0 #dac
>  >>
>  >>  3 0 2          0 #dac
>  >>
>  >>  4 0 2 0 #dac
>  >>
>  >>  5 0 2 0 #dac
>  >>
>  >>  6 1 0 1 #dac
>  >>
>  >>  7 0 0 0 #dac
>  >>
>  >>  ....
>  >>
>  >>  Since I just started using R. I don't know where I am going with this.
>  >> I
>  >> appreciate any help.
>  >>
>  >>  On Sat, May 23, 2015 at 8:23 AM, John Kane <jrkrideau at inbox.com>
> wrote:
>  >>
>  >>          Hi Mohammad
>  >>
>  >>   Welcome to the R-help list.
>  >>
>  >>   There probably is a fairly easy way to what you want but I think we
>  >> probably need a bit more background information on what you are trying
>  >> to
>  >> achieve.  I know I'm not exactly clear on your decision rule(s).
>  >>
>  >>   It would also be very useful to see some actual sample data in
> useable
>  >> R
>  >> format.Have a look at these links
>  >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> [
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> ]
>  >> [
>  >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> [
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> ]]
>  >> [
>  >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> [
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> ]
>  >> [
>  >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> [
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]
> ]]
>  >> and http://adv-r.had.co.nz/Reproducibility.html [
> http://adv-r.had.co.nz/Reproducibility.html] [
>  >> http://adv-r.had.co.nz/Reproducibility.html [
> http://adv-r.had.co.nz/Reproducibility.html]] [
>  >> http://adv-r.had.co.nz/Reproducibility.html [
> http://adv-r.had.co.nz/Reproducibility.html] [
>  >> http://adv-r.had.co.nz/Reproducibility.html [
> http://adv-r.had.co.nz/Reproducibility.html]]] for some hints on what you
>  >> might want to include in your question.
>  >>
>  >>   In particular, read up about dput()  in those links and/or see ?dput.
>  >> This is the generally preferred way to supply sample or illustrative
>  >> data
>  >> to the R-help list.  It basically creates a perfect copy of the data as
>  >> it
>  >> exists on 'your' machine so that R-help readers see exactly what you
> do.
>  >>
>  >>   John Kane
>  >>   Kingston ON Canada
>  >>
>  >>   > -----Original Message-----
>  >>   > From: mxalimohamma at ualr.edu
>  >>   > Sent: Fri, 22 May 2015 12:37:50 -0500
>  >>   > To: r-help at r-project.org
>  >>   > Subject: [R] Problem with comparing multiple data sets
>  >>   >
>  >>   > Hi everyone,
>  >>   >
>  >>   > I am very new to R and I have a task to do. I appreciate any help.
> I
>  >> have
>  >>   > 3
>  >>   > data sets. Each data set has 4 columns. For example:
>  >>   >
>  >>   > Class  Comment   Term   Text
>  >>   > 0           com1        aac    text1
>  >>   > 2           com2        aax    text2
>  >>   > 1           com3        vvx    text3
>  >>   >
>  >>   > Now I need t compare the class section between 3 data sets and
>  >> assign
>  >> the
>  >>   > most available class to that text. For example if text1 is assigned
>  >> to
>  >>   > class 0 in data set 1&2 but assigned as 2 in data set 3 then it
>  >> should
>  >> be
>  >>   > assigned to class 0. If they are all the same so the class will be
>  >> the
>  >>   > same. The ideal thing would be to keep the same format and just
>  >> update
>  >>   > the
>  >>   > class. Is there any easy way to do this?
>  >>   >
>  >>   > Thanks a lot.
>  >>   >
>  >>
>  >>  >       [[alternative HTML version deleted]]
>  >>   >
>  >>   > ______________________________________________
>  >>   > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  >>
>  >>  > https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help] [
>  >> https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help]] [
>  >> https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help] [
>  >> https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help]]]
>  >>   > PLEASE do read the posting guide
>  >>   > http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html] [
>  >> http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html]] [
>  >> http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html] [
>  >> http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html]]]
>  >>   > and provide commented, minimal, self-contained, reproducible code.
>  >>
>  >>   ____________________________________________________________
>  >>   FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>  >>   Check it out at http://www.inbox.com/earth [
> http://www.inbox.com/earth]
>  >> [http://www.inbox.com/earth [http://www.inbox.com/earth]]
>  >> [http://www.inbox.com/earth [http://www.inbox.com/earth] [
> http://www.inbox.com/earth [http://www.inbox.com/earth]]]
>  >>
>  >>  --
>  >>
>  >>  Mohammad Alimohammadi | Graduate Assistant
>  >>  University of Arkansas at Little Rock | College of Science
>  >> and Mathematics (CSAM)
>  >>
>  >>  501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu] [
> http://ualr.edu [http://ualr.edu]] [
>  >> http://ualr.edu/ [http://ualr.edu/] [http://ualr.edu/ [
> http://ualr.edu/]]]
>  >>
>  >>  Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
> http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [
>  >> http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
> http://scholar.google.com/citations?user=MsfN_i8AAAAJ]] [
>  >> http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
> http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [
>  >> http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
> http://scholar.google.com/citations?user=MsfN_i8AAAAJ]]]
>  >>
>  >>  ____________________________________________________________
>  >>  FREE ONLINE PHOTOSHARING - Share your photos online with your friends
>  >> and
>  >> family!
>  >>  Visit http://www.inbox.com/photosharing [
> http://www.inbox.com/photosharing] [
>  >> http://www.inbox.com/photosharing [http://www.inbox.com/photosharing]]
> to find out more!
>  >>
>  >> --
>  >>
>  >> Mohammad Alimohammadi | Graduate Assistant
>  >> University of Arkansas at Little Rock | College of Science and
>  >> Mathematics
>  >> (CSAM)
>  >>
>  >> 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu] [
> http://ualr.edu/ [http://ualr.edu/]]
>  >>
>  >> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
> http://scholar.google.com/citations?user=MsfN_i8AAAAJ] [
>  >> http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
> http://scholar.google.com/citations?user=MsfN_i8AAAAJ]]
>  >>
>  >> ____________________________________________________________
>  >> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>  >> Check it out at http://www.inbox.com/earth [http://www.inbox.com/earth
> ]
>  >>
>  >>
>  >>
>  >
>  >
>  > --
>  > Mohammad Alimohammadi | Graduate Assistant
>  > University of Arkansas at Little Rock | College of Science and
>  > Mathematics
>  > (CSAM)
>  > 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu]
>  >
>  > Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
> http://scholar.google.com/citations?user=MsfN_i8AAAAJ]
>  >
>  >       [[alternative HTML version deleted]]
>  >
>  > ______________________________________________
>  > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  > https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help]
>  > PLEASE do read the posting guide
>  > http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html]
>  > and provide commented, minimal, self-contained, reproducible code.
>
>  ____________________________________________________________
>
> Can't remember your password? Do you need a strong and secure password?
>  Use Password manager! It stores your passwords & protects your account.
>  Check it out at http://mysecurelogon.com/password-manager [
> http://mysecurelogon.com/password-manager]
>
> --
>
> Mohammad Alimohammadi | Graduate Assistant
> University of Arkansas at Little Rock | College of Science and Mathematics
> (CSAM)
>
> 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu/]
>
> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [
> http://scholar.google.com/citations?user=MsfN_i8AAAAJ]
>
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
> your desktop!
> Check it out at http://www.inbox.com/marineaquarium
>
>
>


-- 
Mohammad Alimohammadi | Graduate Assistant
University of Arkansas at Little Rock | College of Science and Mathematics
(CSAM)
501.346.8007 | mxalimohamma at ualr.edu | ualr.edu

Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ

	[[alternative HTML version deleted]]


From suman12029 at yahoo.co.uk  Wed May 27 17:00:03 2015
From: suman12029 at yahoo.co.uk (Suman)
Date: Wed, 27 May 2015 20:45:03 +0545
Subject: [R] About performance of R
Message-ID: <1993D826-7BE9-4F96-8D8A-2F3DD02177AF@yahoo.co.uk>

Hi there,

Now that R has grown up with a vibrant community. It's no 1 statistical package used by scientists. It's graphics capabilities are amazing.
Now it's time to provide native support in "R core" for distributed and parallel computing for high performance in massive datasets.
And may be base R functions should be replaced with best R packages like data.table, dplyr, reader for fast and efficient operations.


Thanks

Sent from my iPad

From gudrun.gygli at wur.nl  Wed May 27 17:31:34 2015
From: gudrun.gygli at wur.nl (Gygli, Gudrun)
Date: Wed, 27 May 2015 15:31:34 +0000
Subject: [R] use of writePNG() in a multiplot OR rasterImage() size control
 in a multiplot
Message-ID: <1432740718559.62200@wur.nl>

Dear All,


I am trying to plot several things in a multiplot using par(mfrow...) AND add a pre-existing png file to that plot.

I have found 2 options of doing this in the web:


writePNG() and another fix using rasterImage().


writePNG(): the option using writePNG() does not add the  " pre-existing png" to my mutliplot.


    I use a code similar to this:

    img<-read("myotherpng.png")


    png(file="mydata.png")

    par(mfrow=c(1,3))

    plot(mydata)

    boxplot(mydata)

    writePNG(img, target="mydata.png")


    Any ideas why this does notwork?



rasterImage(): this is a bit more tricky, but works partly:


the code comes from the rforge (https://www.rforge.net/doc/packages/png/readPNG.html)

and writes the png (see detailed code at the end of email), but is basically:


    img<-read("myotherpng.png")


    png(file="mydata.png")

    par(mfrow=c(1,3))

    plot(mydata)

    boxplot(mydata)
    rforgecode using rasterImage() to print img



If I use this code like below, I do get the" pre-existing png" plotted in my multiplot, but with very wrong dimensions.

rasterImage(image, xleft, ybottom, xright, ytop)

I have no idea how to get the xleft, ybottom,xright and ytop values that match the file I import and allow plotting it fitting into the space allocated by mfrow (meaning that the plot, boxplot and image do not overlap.)


Any ideas?


Thanks for any help about the topic.


Best regards


Gudrun



    img<-read("myotherpng.png")


    png(file="mydata.png")

    par(mfrow=c(1,3))

    plot(mydata)

    boxplot(mydata)

if (exists("rasterImage")) { # can plot only in R 2.11.0 and higher
  plot(1:2, type='n')
  if (names(dev.cur()) == "windows") {
    # windows device doesn't support semi-transparency so we'll need
    # to flatten the image
    transparent <- img[,,4] == 0
    img <- as.raster(img[,,1:3])
    img[transparent] <- NA
    # interpolate must be FALSE on Windows, otherwise R will
    # try to interpolate transparency and fail
    rasterImage(img, 1.2, 1.27, 1.8, 1.73, interpolate=FALSE)
  } else {
    # any reasonable device will be fine using alpha
    rasterImage(img, 1.2, 1.27, 1.8, 1.73)
  }
}



Gudrun Gygli, MSc

PhD candidate

Wageningen University
Laboratory of Biochemistry
Dreijenlaan 3
6703 HA Wageningen
The Netherlands

Phone  31 317483387
e-mail: gudrun.gygli at wur.nl

- - - - - - - - - - - - - - - - - -

Project information: http://www.wageningenur.nl/en/show/Bioinformatics-structural-biology-and-molecular-modeling-of-Vanillyl-Alcohol-Oxidases-VAOs.htm


From gunter.berton at gene.com  Wed May 27 17:35:31 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 27 May 2015 08:35:31 -0700
Subject: [R] About performance of R
In-Reply-To: <1993D826-7BE9-4F96-8D8A-2F3DD02177AF@yahoo.co.uk>
References: <1993D826-7BE9-4F96-8D8A-2F3DD02177AF@yahoo.co.uk>
Message-ID: <CACk-te0uc4st9VTOT2Okt0RsQYZZe58B2jeSVW_iAE=BZS8bOg@mail.gmail.com>

Did you consider the amount of code your "suggestions" would break?

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, May 27, 2015 at 8:00 AM, Suman <suman12029 at yahoo.co.uk> wrote:
> Hi there,
>
> Now that R has grown up with a vibrant community. It's no 1 statistical package used by scientists. It's graphics capabilities are amazing.
> Now it's time to provide native support in "R core" for distributed and parallel computing for high performance in massive datasets.
> And may be base R functions should be replaced with best R packages like data.table, dplyr, reader for fast and efficient operations.
>
>
> Thanks
>
> Sent from my iPad
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Wed May 27 17:54:08 2015
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Wed, 27 May 2015 08:54:08 -0700
Subject: [R] Simulating a time series with a given spectrum
Message-ID: <272DD1F0-B876-4125-810E-7B37138AF012@noaa.gov>

Hi All:

Is there a routine in R that allows me to simulate a time series that has a given spectrum?  I have looked at the R Time Series Task view, and have done a web search also, including an article to appear in the handbook of statistics on time series in R, but I don?t see anything offhand.  There are some that will simulate state-space models or for given covariances matrices, but for a variety of reasons I would prefer simulating series with a given spectrum.

Thanks for any help.

-Roy


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From dcarlson at tamu.edu  Wed May 27 18:02:02 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 27 May 2015 16:02:02 +0000
Subject: [R] Identifying peak periods of observations in circular
	yearly	data
In-Reply-To: <CAFf2dDHoWdur=8hPdFXhaui0cJ9P=-byUTqK8Xp8+iJTxeQHXg@mail.gmail.com>
References: <CAFf2dDGACuVMUurKT9TsPv=xWJNcCgx=tgBSdWFJp4TO2himTg@mail.gmail.com>
	<CA+8X3fU=gQLh1d5hAmD0aZZ9t=1Qys6OuLt2H3HcJ3r0XzpSzA@mail.gmail.com>
	<CAFf2dDHoWdur=8hPdFXhaui0cJ9P=-byUTqK8Xp8+iJTxeQHXg@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68E7EE@mb02.ads.tamu.edu>

You can use package circular for this. You have to convert 1-366 to 1-360 by dividing the days by 366 and multiplying by 360 and converting the results back to days by adding 360 if the value is <0 and dividing by 360 and multiplying by 366:

> library(circular)
> degrees <- obsDay/366*360 # convert year to 360 degrees
> # Create a circular object
> circ <- circular(degrees, units="degrees", template="geographics")
> # Get descriptive stats
> mean(circ)
Circular Data: 
Type = angles 
Units = degrees 
Template = geographics 
Modulo = asis 
Zero = 1.570796 
Rotation = clock 
[1] -23.5503
> median(circ)
Circular Data: 
Type = angles 
Units = degrees 
Template = geographics 
Modulo = asis 
Zero = 1.570796 
Rotation = clock 
[1] -17.70492
attr(,"medians")
[1] 342.2951
> sd(circ)
[1] 1.28903
> pct80 <- quantile(circ, prob=c(.1, .9))
> pct80
Circular Data: 
Type = angles 
Units = degrees 
Template = geographics 
Modulo = asis 
Zero = 1.570796 
Rotation = clock 
       10%        90% 
  59.01639 -135.73770 
> # Convert result back to days
> days <- ifelse(pct80<0, pct80+360, pct80)/360*366
> days
10% 90% 
 60 228 
> # Plot the results
> plot(circ, stack=TRUE, axes=FALSE)
> axis <- circular(c(0, 90, 180, 270), units="degrees", template="geographics")
> axis.circular(at=axis, labels=c("Jan", "April", "July", "October"), 
+     template="geographics", zero=0, tcl.text=.15)
> arrows.circular(quantile(circ, prob=c(.10, .90)), lwd=2)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Daisy Englert Duursma
Sent: Wednesday, May 27, 2015 4:42 AM
To: Jim Lemon
Cc: r-help at R-project.org
Subject: Re: [R] Identifying peak periods of observations in circular yearly data

Thanks for the advice Jim. I did actually play around with this idea, but
for some bird species (emu) the beginning of the breeding season is
actually January while for others it is in July or at other times. Breeding
seasons can be driven by dry season or temperatures, so although there are
generalizations each species need to be assessed.

On Wed, May 27, 2015 at 7:34 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Daisy,
> You face a problem similar to one with which I have grappled in
> different fields. The year is designed for the northern hemisphere,
> beginning and ending in less productive biologic states in those
> regions. I have previously argued that since the calendar year is an
> arbitrary progression, it makes more sense to redraw the annual
> boundary when examining things like this in the southern hemisphere.
> That is to say, a "year" is conventionally marked at about the
> northern winter solstice. Down here, this becomes the summer solstice
> and breaks up a lot of things that happen around that time. Have you
> thought of defining a southern bird-watching year as beginning and
> ending at the southern winter solstice? As I am currently writing in
> an entirely different context, it shouldn't really make much
> difference.
>
> Jim
>
>
> On Wed, May 27, 2015 at 4:35 PM, Daisy Englert Duursma
> <daisy.duursma at gmail.com> wrote:
> > Greetings,
> >
> > I am trying to identify at which point during the year 80% of bird
> breeding
> > observations are. typically I would answer a question like this by
> finding
> > the median or quartiles but how do I deal with situations where the 80%
> of
> > the is from day 285 through day 366 (leap year) and extends to day 30?
> >
> > The data is circular and and day 365 is as close to day 366 as day 1.
> >
> > I am reading the manual for CircStats and circular but I could really use
> > some help on this.
> >
> >
> > Here is some dummy data:
> >
> >
> >
> obsDay<-c(rep(1:30,10),rep(45:65,2),65:180,rep(181:265,2),rep(266:330,4),rep(331:366,6))
> >
> > plot(density(obsDay))
> >
> >
> >
> > --
> > Daisy Englert Duursma
> > Department of Biological Sciences
> > Room W19F 135
> > Macquarie University, North Ryde, NSW 2109
> > Australia
> >
> > Tel +61 2 9850 1302
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Daisy Englert Duursma
Department of Biological Sciences
Room W19F 135
Macquarie University, North Ryde, NSW 2109
Australia

Tel +61 2 9850 1302

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Wed May 27 18:15:14 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 27 May 2015 17:15:14 +0100
Subject: [R] Simulating a time series with a given spectrum
In-Reply-To: <272DD1F0-B876-4125-810E-7B37138AF012@noaa.gov>
References: <272DD1F0-B876-4125-810E-7B37138AF012@noaa.gov>
Message-ID: <5565ED92.5060504@stats.ox.ac.uk>

On 27/05/2015 16:54, Roy Mendelssohn - NOAA Federal wrote:
> Hi All:
>
> Is there a routine in R that allows me to simulate a time series that has a given spectrum?  I have looked at the R Time Series Task view, and have done a web search also, including an article to appear in the handbook of statistics on time series in R, but I don?t see anything offhand.  There are some that will simulate state-space models or for given covariances matrices, but for a variety of reasons I would prefer simulating series with a given spectrum.

It is relatively simple to do for series of lengths a power of two (and 
you can simulate a longer series to achieve this).  Use the spectrum 
values to simulate independent complex normals with uniform phase and 
variance proportional to the spectral density at the Fourier frequencies 
then use the inverse fft() to get the series.

You should be able to copy some code from boot::tsboot()'s 'scramble' 
method.

> Thanks for any help.
>
> -Roy
>
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From roy.mendelssohn at noaa.gov  Wed May 27 18:30:47 2015
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Wed, 27 May 2015 09:30:47 -0700
Subject: [R] Simulating a time series with a given spectrum
In-Reply-To: <5565ED92.5060504@stats.ox.ac.uk>
References: <272DD1F0-B876-4125-810E-7B37138AF012@noaa.gov>
	<5565ED92.5060504@stats.ox.ac.uk>
Message-ID: <4983EC49-FBFA-4B45-89AD-8EAF61F2D182@noaa.gov>

Thanks,  I will look at that.

-Roy

> On May 27, 2015, at 9:15 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> 
> On 27/05/2015 16:54, Roy Mendelssohn - NOAA Federal wrote:
>> Hi All:
>> 
>> Is there a routine in R that allows me to simulate a time series that has a given spectrum?  I have looked at the R Time Series Task view, and have done a web search also, including an article to appear in the handbook of statistics on time series in R, but I don?t see anything offhand.  There are some that will simulate state-space models or for given covariances matrices, but for a variety of reasons I would prefer simulating series with a given spectrum.
> 
> It is relatively simple to do for series of lengths a power of two (and you can simulate a longer series to achieve this).  Use the spectrum values to simulate independent complex normals with uniform phase and variance proportional to the spectral density at the Fourier frequencies then use the inverse fft() to get the series.
> 
> You should be able to copy some code from boot::tsboot()'s 'scramble' method.
> 
>> Thanks for any help.
>> 
>> -Roy
>> 
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new address and phone***
>> 110 Shaffer Road
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From dwinsemius at comcast.net  Wed May 27 19:14:06 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 27 May 2015 10:14:06 -0700
Subject: [R] Help on Histogram ~ Barplot
In-Reply-To: <1432718936755-4707739.post@n4.nabble.com>
References: <1432718936755-4707739.post@n4.nabble.com>
Message-ID: <20CC31C4-3534-4CB6-AE07-303BC23135C9@comcast.net>


On May 27, 2015, at 2:28 AM, Shivi82 wrote:

> Hello All,
> I need help on creating a histogram for one of my data. The data is as below
> (sample):
> MFST_WT	Hours	PROCESS	Month	Weekday	Day of the Month
> 6,828	13	       INBOUND	Mar	             Fri	13
> 2,504	16	       INBOUND	Mar	             Fri	27
> 20	        16	       INBOUND	Mar	             Fri	27
> 10,262	16	       INBOUND	Mar	             Fri	27
> 2,500	17	       INBOUND	Mar	             Fri	13
> 3,938	16	       INBOUND	Feb	            Thu	26
> 798	        10	       INBOUND	Feb	            Sat	14
> 5,439	15	       INBOUND	Feb	            Mon	16
> 

What I'm seeing here is the likelihood that the data object has been input incorrectly (or is a mess in the original file?) There appear to be commas in what would presumably be a numeric column and a column name with spaces in it. There is also misregistration of some lines of data possible with tab-characters that were eaten by Nabble's interface.  If you want help under these circumstances you should either respond with the first 20 lines of the original data file posted through a mail-client bypassing Nabble or post dput( head(objname, 20))


> This data has these columns and total rows are 45000. 
> Now I need to group the data and create a bar plot based on total weight on
> a monthly basis. The code I have used is:
> barplot(mwlc$MFST_WT, names.arg = mwlc$Month, las=2, ylim=c(0,10000), col
> ="red",
>        border="orange", main="Monthly Weight")
> but this is showing an error. Please suggest. 
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Help-on-Histogram-Barplot-tp4707739.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Wed May 27 19:33:29 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 27 May 2015 10:33:29 -0700
Subject: [R] About performance of R
In-Reply-To: <1993D826-7BE9-4F96-8D8A-2F3DD02177AF@yahoo.co.uk>
References: <1993D826-7BE9-4F96-8D8A-2F3DD02177AF@yahoo.co.uk>
Message-ID: <3D61F74C-715A-4536-B480-240DB68C33C9@dcn.davis.CA.us>

a) Base R already includes the "parallel" package. Deciding to use more than one processor for a particular computation is a very high level decision that can require knowledge of computing time cost, importance of other tasks on the system, and interdependence of computation results. It is not a decision that R should automatically make.

b) Most performance issues with R arise due to users choosing inefficient algorithms. Inserting parallelism inside existing algorithms will not fix that.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 27, 2015 8:00:03 AM PDT, Suman <suman12029 at yahoo.co.uk> wrote:
>Hi there,
>
>Now that R has grown up with a vibrant community. It's no 1 statistical
>package used by scientists. It's graphics capabilities are amazing.
>Now it's time to provide native support in "R core" for distributed and
>parallel computing for high performance in massive datasets.
>And may be base R functions should be replaced with best R packages
>like data.table, dplyr, reader for fast and efficient operations.
>
>
>Thanks
>
>Sent from my iPad
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed May 27 19:50:15 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 27 May 2015 10:50:15 -0700
Subject: [R] About performance of R
In-Reply-To: <1993D826-7BE9-4F96-8D8A-2F3DD02177AF@yahoo.co.uk>
References: <1993D826-7BE9-4F96-8D8A-2F3DD02177AF@yahoo.co.uk>
Message-ID: <12798F67-3677-420E-998B-6D1F46A1463A@comcast.net>


On May 27, 2015, at 8:00 AM, Suman wrote:

> Hi there,
> 
> Now that R has grown up with a vibrant community. It's no 1 statistical package used by scientists. It's graphics capabilities are amazing.
> Now it's time to provide native support in "R core" for distributed and parallel computing for high performance in massive datasets.
> And may be base R functions should be replaced with best R packages like data.table, dplyr, reader for fast and efficient operations.
> 
> 
> Thanks
> 
> Sent from my iPad

Generally email exhortations from iPads are quite ineffective in promoting fundamental advances. 

In the US, efforts at cheerleading of sports events are often attempted by small groups of scantily clad women of various ages, usually young, using coordinated dance movements. I wonder if something similar should be attempted those desirous of more rapid advancement of computer software. On the other hand, I suppose the world has been historically effective in this domain by waving large bundles of cash and stock options, rather than waving unclad female body parts. 

Got any cash to wave?

-- 

David Winsemius
Alameda, CA, USA


From kengoing.gj at gmail.com  Wed May 27 19:10:29 2015
From: kengoing.gj at gmail.com (Kengo Inagaki)
Date: Wed, 27 May 2015 12:10:29 -0500
Subject: [R] Collinearity? Cannot get logisticRidge{ridge} to work
Message-ID: <CAC7aZ4mjgNh1ZtvYw6boDxdCxOLyGAMqaeHdzW1148U_Lk1ZCw@mail.gmail.com>

I am currently working on a health care related project using R. I am
learning R while working on data analysis.

Below is the part of the data in which i am encountering a problem.



Case#    Sex         Therapy1             Therapy2             Outcome

1              male      no
no                           Alive

2              female  no
no                           Death

3              male      no
no                           Alive

4              female  no
no                           Death

5              male      no
no                           Death

6              male      no
no                           Alive

7              male      yes
no                           Alive

8              female  no
no                           Death

9              male      no
yes                         Alive

10           female  no
no                           Death

11           female  yes
yes                         Death

12           female  yes
no                           Death

13           female  yes
no                           Death

14           female  yes
no                           Alive

15           male      yes
no                           Alive

16           male      yes
no                           Alive

17           male      no
yes                         Death

18           male      no
yes                         Death

19           male      yes
no                           Alive

20           female  no
yes                         Death

21           female  yes
no                           Alive

22           female  no
yes                         Death

23           male      yes
no                           Alive

24           female  yes
no                           Alive

25           female  yes
no                           Alive



"Outcome" is the response variable and "Sex", "Therapy1", "Therapy2" are
predictor variables.

All of the predictors are significantly associated with the outcome by
univariate analysis.

Logistic regression runs fine with most of the predictors when "Sex" and
"Therapy1" are not included at the same time (This is a part of table that
I cut out from a larger table for ease of

presentation and there are more predictors that i tested).

However, when "Sex" and "Therapy1" are included in logistic regression
model at the same time, standard error inflates and p value gets close to 1.

The formula used is,



>Model<-glm(Outcome~Sex+Therapy1,data=a,family=binomial) #I assigned a
vector "a" to represent above table.



After doing some reading, I suspect this might be collinearity, as vif
values (using "vif()" function in car package) were sky high (8,875,841 for
both "Sex" and "Therapy1").

Learning that ridge regression may be a solution, I attempted using
logisticRidge {ridge} using the following formula, but i get the
accomapnying error message.



>logisticRidge(a$Outcome~a$Sex+a$Therapy1)



Error in ifelse(y, log(p), log(1 - p)) :

  invalid to change the storage mode of a factor



At this point I do not have an idea how to solve this and would like to
seek help.

I really really appreciate your input!!!

	[[alternative HTML version deleted]]


From carmineapice at gmail.com  Wed May 27 18:23:49 2015
From: carmineapice at gmail.com (Carmine Apice)
Date: Wed, 27 May 2015 18:23:49 +0200
Subject: [R] information_request
Message-ID: <CAJBLP2U5dAsQ1R8Az7m4WXPkPPvCJm8=ih6wiwqHfb6bsptiVA@mail.gmail.com>

Good Morning,
I'm an italian student of Statistics.
I'd like to know how to obtain the source code
of "summary()" function, because I'm building a new
model in R, and I would like to implement a summary function
similar to that used for linear models.
How can I obtain the source code?

Thank you in advance for your help.

Best regards
*Carmine Apice*

-- 
*Carmine Apice*
Tel:  +39 081.8811398
Fax: +39.081.8811398
Mobile: 3288248606
E-Mail: carmineapice at gmail.com
Twitter: http://twitter.com/apicecarmine
Skype: *carmine.apice1*

Se riceve questa mail per errore la prego di avvertire il mittente e di
cancellarla.
If you received this email in error, please notify the sender and delete
this email from your system.

	[[alternative HTML version deleted]]


From marianavelasque at gmail.com  Wed May 27 19:00:18 2015
From: marianavelasque at gmail.com (Mariana Velasque)
Date: Wed, 27 May 2015 18:00:18 +0100
Subject: [R] Double Hierarchical Generalized Linear Models
Message-ID: <03FB0833-DACE-4DBA-ADFE-7F69605F5BB9@gmail.com>

I am new modeling and I am trying to analyse my data using the package Double Hierarchical Generalized Linear Models. However, I always get the same sort of error:

Error in z %*% v_h : non-conformable arguments. 
I think that this error indicates that the matrices are created with non-calculable dimensions, but I don't know how to solve it.

I am creating my model with two fixed and two random effects. with this format:

rm(list=ls(all=TRUE))
library("dhglm")

data=read.csv("log_data.csv", header=TRUE)
phi<-matrix(1,n<-nrow(data),1)
lambda<-matrix(1,n<-nrow(data),1)
data<-cbind(data,phi,lambda)

sr <- as.numeric(data$SR)   ##Dependent variable

id <- as.numeric(data$ID)    ##individual number
    obs <- as.numeric(data$Obs)    ##Observation number

o2r <- as.numeric(data$O2R)    ##Fixed factor 1 (oxygen consumption 1)
    o2a <-as.numeric(data$O2A)    ##Fixed factor 2 (oxygen consumption 2)

lambda <-as.numeric(data$lambda)

phi<-as.numeric(data$phi)


model_mu<-DHGLMMODELING(Model="mean",
Link="log",
LinPred= sr~o2a+ o2r + (1|id) + (1|obs),
RandDist= c("inverse-gamma", "gamma"),
 LinPredRandVariance=lambda~ 1 +(1|id) + (1|obs) ,
RandDistRandVariance=c("gaussian", "gaussian"))

model_phi<-DHGLMMODELING(Model="dispersion", 
Link="log", 
LinPred = phi~o2a+ o2r + (1|id) + (1|obs), 
 RandDist= c("gaussian", "gaussian"))   

res_glm<-dhglmfit(RespDist="gaussian",    
                  DataMain=data,
                  MeanModel=model_mu,
                  DispersionModel=model_phi,
                PhiFix=NULL, LamFix=NULL,mord=1,dord=1,Maxiter=200,convergence=1e-06)

Mariana Velasque 

PhD Student 
Marine Biology & Ecology Research Centre | School of Marine Science and Engineering | Plymouth University | 616 Davy | Drakes Circus | Plymouth | PL4 8AA | UK | +44 1752 5 84598 (Shared phone) | mariana.velasqueborges at plymouth.ac.uk <https://webmail.plymouth.ac.uk/owa/redir.aspx?C=0UUp9Pz8dkK1n_4m1deYkaEPZLevftEIjV4BgdiwFBa9Smiq3Nzoxl6fFxk5PwzRXWIRYoEPm8k.&URL=mailto%3amariana.velasqueborges%40plymouth.ac.uk> | marianavelasque at gmail.com <https://webmail.plymouth.ac.uk/owa/redir.aspx?C=0UUp9Pz8dkK1n_4m1deYkaEPZLevftEIjV4BgdiwFBa9Smiq3Nzoxl6fFxk5PwzRXWIRYoEPm8k.&URL=mailto%3amarianavelasque%40gmail.com>
Doutoranda
Centro de Pesquisa em Biologia Marinha & Ecologia | Faculdade de Ci?ncias e Engenharia Marinha | Universidade de Plymouth | 616 Davy | Drakes Circus | Plymouth | PL4 8AA | UK | +44 1752 5 84598 (Telefone compartilhado) |mariana.velasqueborges at plymouth.ac.uk <https://webmail.plymouth.ac.uk/owa/redir.aspx?C=0UUp9Pz8dkK1n_4m1deYkaEPZLevftEIjV4BgdiwFBa9Smiq3Nzoxl6fFxk5PwzRXWIRYoEPm8k.&URL=mailto%3a%7cmariana.velasqueborges%40plymouth.ac.uk> |marianavelasque at gmail.com <https://webmail.plymouth.ac.uk/owa/redir.aspx?C=0UUp9Pz8dkK1n_4m1deYkaEPZLevftEIjV4BgdiwFBa9Smiq3Nzoxl6fFxk5PwzRXWIRYoEPm8k.&URL=mailto%3amarianavelasque%40gmail.com>

	[[alternative HTML version deleted]]


From mxalimohamma at ualr.edu  Wed May 27 20:47:11 2015
From: mxalimohamma at ualr.edu (Mohammad Alimohammadi)
Date: Wed, 27 May 2015 13:47:11 -0500
Subject: [R] Problem with comparing multiple data sets
In-Reply-To: <CAJVfk9kx-hJyeUd5q=Y6KGxY8oYzW3J4sHhXDUv39JJ1F43mtA@mail.gmail.com>
References: <CAJVfk9nM_a2Gr86OXimHbc8HZoN45RMWLL_VmXak4RPoj1=OQw@mail.gmail.com>
	<32FCEB5D574.0000035Fjrkrideau@inbox.com>
	<CA+8X3fW4BwSQ2U-EpUmzQzsfL-4sYJZaKFR56qS8i-FMk7HPfA@mail.gmail.com>
	<CAJVfk9kx-hJyeUd5q=Y6KGxY8oYzW3J4sHhXDUv39JJ1F43mtA@mail.gmail.com>
Message-ID: <CAJVfk9k+Qk9CUqrbTLmAjyVdu5ErZHtd1VErHnABPkHiikDOaQ@mail.gmail.com>

Ok. so I read about the ("modeest") package that gives the results that I
am looking for (most repeated value).

I modified the data frame a little and moved the text to the first column.
This is the data frame with all 3 possible classes for each term.

=================================
structure(list(terms = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 4L, 4L,
4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label = c("#dac",
"#mac,#security",
"accountability,anonymous", "data security,encryption,security"
), class = "factor"), class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L,
1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), class.2 = c(2L, 2L,
2L, 2L, 0L, 0L, 2L, 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L,
0L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L),
    class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L, 1L,
    0L, 0L, 0L, 0L, 2L, 1L, 2L)), .Names = c("terms", "class.1",
"class.2", "class.3"), class = "data.frame", row.names = c(NA,
-49L))
=============================================
#Then I applied the function below:

======================
library(modeest)
df<- read.csv(file="short.csv", head= TRUE, sep=",")
apply(df[ ,2:length(df)], 1, mfv)

============================
# It gives the most frequent value for each row which is what I need. The
only problem is that all the values are displayed in one single row.

 [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 2 1 1 1 1 0 0 0 0 2 1 2

It would be much better to show them in separate rows.
For example:

 [1] 0

 [2] 0

 [3] 1
....

Any idea how to do this?




On Wed, May 27, 2015 at 10:11 AM, Mohammad Alimohammadi <
mxalimohamma at ualr.edu> wrote:

> Hi Jim,
>
> Thank you for your advice.
>
> I'm not sure how to exactly incorporate this function though. I added a
> portion of the actual data sets. all 3 data sets have the same items (text)
> with different class values. So I need to assign the most repeated class
> (0,1,2) for each text.
>
> For example: if line1 has text "aaa". It may be assigned to class 0 in
> dat1, 2 in dat 2 and 0 in dat3. in this case the "aaa" will be assigned to
> 0 (most repeated value). So it goes for each text.
>
> I really appreciate your help.
>
> =========================================
>
> *dat1*
>
> structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
> 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
> c("#dac",
> "#mac,#security", "accountability,anonymous", "data
> security,encryption,security"
> ), class = "factor")), .Names = c("class.1", "terms"), class =
> "data.frame", row.names = c(NA,
> -49L))
>
>
> *dat2*
>
> structure(list(class.2 = c(2L, 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L,
> 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L), terms = structure(c(1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
> c("#dac",
> "#mac,#security", "accountability,anonymous", "data
> security,encryption,security"
> ), class = "factor")), .Names = c("class.2", "terms"), class =
> "data.frame", row.names = c(NA,
> -49L))
>
>
> *dat3*
>
> structure(list(class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
> 1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
> c("#dac",
> "#mac,#security", "accountability,anonymous", "data
> security,encryption,security"
> ), class = "factor")), .Names = c("class.3", "terms"), class =
> "data.frame", row.names = c(NA,
> -49L))
>
> ===========================================================
>
>
> On Sun, May 24, 2015 at 1:15 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Mohammad,
>> You know, I thought this would be fairly easy, but it wasn't really.
>>
>> df1<-data.frame(Class=c(0,2,1),Comment=c("com1","com2","com3"),
>>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
>> df2<-data.frame(Class=c(0,2,1),Comment=c("com1","com2","com3"),
>>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
>> df3<-data.frame(Class=c(2,1,0),Comment=c("com1","com2","com3"),
>>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
>> dflist<-list(df1,df2,df3)
>> dflist
>>
>> # define a function that extracts the value from one field
>> # selected by a value in another field
>> extract_by_value<-function(x,field1,value1,field2) {
>>  return(x[x[,field1]==value1,field2])
>> }
>>
>> # define another function that equates all of the values
>> sub_value<-function(x,field1,value1,field2,value2) {
>>  x[x[,field1]==value1,field2]<-value2
>>  return(x)
>> }
>>
>> conformity<-function(x,fieldname1,value1,fieldname2) {
>>  # get the most frequent value in fieldname2
>>  # for the desired value in fieldname1
>>  most_freq<-as.numeric(names(which.max(table(unlist(lapply(x,
>>   extract_by_value,fieldname1,value1,fieldname2))))))
>>  # now set all the values to the most frequent
>>  for(i in 1:length(x))
>>   x[[i]]<-sub_value(x[[i]],fieldname1,value1,fieldname2,most_freq)
>>  return(x)
>> }
>>
>> conformity(dflist,"Text","text1","Class")
>>
>> Jim
>>
>> On Sat, May 23, 2015 at 11:23 PM, John Kane <jrkrideau at inbox.com> wrote:
>> > Hi Mohammad
>> >
>> > Welcome to the R-help list.
>> >
>> > There probably is a fairly easy way to what you want but I think we
>> probably need a bit more background information on what you are trying to
>> achieve.  I know I'm not exactly clear on your decision rule(s).
>> >
>> > It would also be very useful to see some actual sample data in useable
>> R format.Have a look at these links
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> and http://adv-r.had.co.nz/Reproducibility.html for some hints on what
>> you might want to include in your question.
>> >
>> > In particular, read up about dput()  in those links and/or see ?dput.
>> This is the generally preferred way to supply sample or illustrative data
>> to the R-help list.  It basically creates a perfect copy of the data as it
>> exists on 'your' machine so that R-help readers see exactly what you do.
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > John Kane
>> > Kingston ON Canada
>> >
>> >
>> >> -----Original Message-----
>> >> From: mxalimohamma at ualr.edu
>> >> Sent: Fri, 22 May 2015 12:37:50 -0500
>> >> To: r-help at r-project.org
>> >> Subject: [R] Problem with comparing multiple data sets
>> >>
>> >> Hi everyone,
>> >>
>> >> I am very new to R and I have a task to do. I appreciate any help. I
>> have
>> >> 3
>> >> data sets. Each data set has 4 columns. For example:
>> >>
>> >> Class  Comment   Term   Text
>> >> 0           com1        aac    text1
>> >> 2           com2        aax    text2
>> >> 1           com3        vvx    text3
>> >>
>> >> Now I need t compare the class section between 3 data sets and assign
>> the
>> >> most available class to that text. For example if text1 is assigned to
>> >> class 0 in data set 1&2 but assigned as 2 in data set 3 then it should
>> be
>> >> assigned to class 0. If they are all the same so the class will be the
>> >> same. The ideal thing would be to keep the same format and just update
>> >> the
>> >> class. Is there any easy way to do this?
>> >>
>> >> Thanks a lot.
>> >>
>> >>       [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ____________________________________________________________
>> > FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Mohammad Alimohammadi | Graduate Assistant
> University of Arkansas at Little Rock | College of Science and Mathematics
> (CSAM)
> | mxalimohamma at ualr.edu | ualr.edu
>
> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
>



-- 
Mohammad Alimohammadi | Graduate Assistant
University of Arkansas at Little Rock | College of Science and Mathematics
(CSAM)
501.346.8007 | mxalimohamma at ualr.edu | ualr.edu

Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed May 27 20:52:19 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 27 May 2015 14:52:19 -0400
Subject: [R] About performance of R
In-Reply-To: <1993D826-7BE9-4F96-8D8A-2F3DD02177AF@yahoo.co.uk>
References: <1993D826-7BE9-4F96-8D8A-2F3DD02177AF@yahoo.co.uk>
Message-ID: <55661263.9040007@gmail.com>

On 27/05/2015 11:00 AM, Suman wrote:
> Hi there,
>
> Now that R has grown up with a vibrant community. It's no 1 statistical package used by scientists. It's graphics capabilities are amazing.
> Now it's time to provide native support in "R core" for distributed and parallel computing for high performance in massive datasets.
> And may be base R functions should be replaced with best R packages like data.table, dplyr, reader for fast and efficient operations.

Given your first three sentences, I would say the current development 
strategy for R is successful.  As Bert mentioned, one thing we have 
always tried to do is to make improvements without large disruptions to 
the existing code base.  I think we will continue to do that.

This means we are unlikely to make big, incompatible replacements. But 
there's nothing stopping people from using data.table, dplyr, etc. even 
if they aren't in the core.  In fact, having them outside of core R is 
better:  there are only so many core R developers, and if they are 
working on data.table, etc., they wouldn't be working on other things.

Compatible replacements are another question.  There is ongoing work on 
making R faster, and making it easier to take advantage of multiple 
processors.  I believe R 3.2.0 is faster than the R 3.1.x series in many 
things, and changes like that are likely to continue.  Plus, there is 
base support for explicit parallel programming in the parallel package, 
as Jeff mentioned.

As to David and his large bundles; those would definitely be appreciated.

Duncan Murdoch


From dcarlson at tamu.edu  Wed May 27 20:53:47 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 27 May 2015 18:53:47 +0000
Subject: [R] information_request
In-Reply-To: <CAJBLP2U5dAsQ1R8Az7m4WXPkPPvCJm8=ih6wiwqHfb6bsptiVA@mail.gmail.com>
References: <CAJBLP2U5dAsQ1R8Az7m4WXPkPPvCJm8=ih6wiwqHfb6bsptiVA@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68E9F9@mb02.ads.tamu.edu>

Start R and then type:

> summary.lm


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Carmine Apice
Sent: Wednesday, May 27, 2015 11:24 AM
To: r-help at r-project.org
Subject: [R] information_request

Good Morning,
I'm an italian student of Statistics.
I'd like to know how to obtain the source code
of "summary()" function, because I'm building a new
model in R, and I would like to implement a summary function
similar to that used for linear models.
How can I obtain the source code?

Thank you in advance for your help.

Best regards
*Carmine Apice*

-- 
*Carmine Apice*
Tel:  +39 081.8811398
Fax: +39.081.8811398
Mobile: 3288248606
E-Mail: carmineapice at gmail.com
Twitter: http://twitter.com/apicecarmine
Skype: *carmine.apice1*

Se riceve questa mail per errore la prego di avvertire il mittente e di
cancellarla.
If you received this email in error, please notify the sender and delete
this email from your system.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed May 27 20:57:37 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 27 May 2015 11:57:37 -0700
Subject: [R] Collinearity? Cannot get logisticRidge{ridge} to work
In-Reply-To: <CAC7aZ4mjgNh1ZtvYw6boDxdCxOLyGAMqaeHdzW1148U_Lk1ZCw@mail.gmail.com>
References: <CAC7aZ4mjgNh1ZtvYw6boDxdCxOLyGAMqaeHdzW1148U_Lk1ZCw@mail.gmail.com>
Message-ID: <D34A739F-63C5-48FA-BD1D-56B676416B43@comcast.net>


On May 27, 2015, at 10:10 AM, Kengo Inagaki wrote:

> I am currently working on a health care related project using R. I am
> learning R while working on data analysis.
> 
> Below is the part of the data in which i am encountering a problem.
> 
> 
> Case#    Sex         Therapy1             Therapy2             Outcome
> 
> 1              male      no
> no                           Alive
> 

snipped mangled data sent in HTML

> 
> 
> "Outcome" is the response variable and "Sex", "Therapy1", "Therapy2" are
> predictor variables.
> 
> All of the predictors are significantly associated with the outcome by
> univariate analysis.
> 
> Logistic regression runs fine with most of the predictors when "Sex" and
> "Therapy1" are not included at the same time (This is a part of table that
> I cut out from a larger table for ease of
> 
> presentation and there are more predictors that i tested).

Please examine the data before reaching for ridge regression:

What does this show: ...

    with(a,  table(Sex, Therapy1) )

I predict you will see a zero cell entry. The read about "complete separation" and the so-called "Hauck-Donner effect".

-- 
David.
> 
> However, when "Sex" and "Therapy1" are included in logistic regression
> model at the same time, standard error inflates and p value gets close to 1.
> 
> The formula used is,
> 
> 
> 
>> Model<-glm(Outcome~Sex+Therapy1,data=a,family=binomial) #I assigned a
> vector "a" to represent above table.
> 
> 
> 
> After doing some reading, I suspect this might be collinearity, as vif
> values (using "vif()" function in car package) were sky high (8,875,841 for
> both "Sex" and "Therapy1").
> 
> Learning that ridge regression may be a solution, I attempted using
> logisticRidge {ridge} using the following formula, but i get the
> accomapnying error message.
> 
> 
> 
>> logisticRidge(a$Outcome~a$Sex+a$Therapy1)
> 
> 
> 
> Error in ifelse(y, log(p), log(1 - p)) :
> 
>  invalid to change the storage mode of a factor
> 
> 
> 
> At this point I do not have an idea how to solve this and would like to
> seek help.
> 
> I really really appreciate your input!!!
> 
> 	[[alternative HTML version deleted]]
> 


David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Wed May 27 21:18:47 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 27 May 2015 19:18:47 +0000
Subject: [R] Problem with comparing multiple data sets
In-Reply-To: <CAJVfk9k+Qk9CUqrbTLmAjyVdu5ErZHtd1VErHnABPkHiikDOaQ@mail.gmail.com>
References: <CAJVfk9nM_a2Gr86OXimHbc8HZoN45RMWLL_VmXak4RPoj1=OQw@mail.gmail.com>
	<32FCEB5D574.0000035Fjrkrideau@inbox.com>
	<CA+8X3fW4BwSQ2U-EpUmzQzsfL-4sYJZaKFR56qS8i-FMk7HPfA@mail.gmail.com>
	<CAJVfk9kx-hJyeUd5q=Y6KGxY8oYzW3J4sHhXDUv39JJ1F43mtA@mail.gmail.com>
	<CAJVfk9k+Qk9CUqrbTLmAjyVdu5ErZHtd1VErHnABPkHiikDOaQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68EA9D@mb02.ads.tamu.edu>

Save the result of the apply() function:

Out <- apply(df[ ,2:length(df)], 1, mfv)

Then there are several options:

Approximately what you asked for
data.frame(Out)
t(t(Out))

More typing but exactly what you asked for
cat(paste0("[", 1:length(Out), "] ", Out), sep="\n")


David L. Carlson
Department of Anthropology
Texas A&M University


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Mohammad Alimohammadi
Sent: Wednesday, May 27, 2015 1:47 PM
To: John Kane; r-help at r-project.org
Subject: Re: [R] Problem with comparing multiple data sets

Ok. so I read about the ("modeest") package that gives the results that I
am looking for (most repeated value).

I modified the data frame a little and moved the text to the first column.
This is the data frame with all 3 possible classes for each term.

=================================
structure(list(terms = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 4L, 4L,
4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label = c("#dac",
"#mac,#security",
"accountability,anonymous", "data security,encryption,security"
), class = "factor"), class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L,
1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), class.2 = c(2L, 2L,
2L, 2L, 0L, 0L, 2L, 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L,
0L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L),
    class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L, 1L,
    0L, 0L, 0L, 0L, 2L, 1L, 2L)), .Names = c("terms", "class.1",
"class.2", "class.3"), class = "data.frame", row.names = c(NA,
-49L))
=============================================
#Then I applied the function below:

======================
library(modeest)
df<- read.csv(file="short.csv", head= TRUE, sep=",")
apply(df[ ,2:length(df)], 1, mfv)

============================
# It gives the most frequent value for each row which is what I need. The
only problem is that all the values are displayed in one single row.

 [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 2 1 1 1 1 0 0 0 0 2 1 2

It would be much better to show them in separate rows.
For example:

 [1] 0

 [2] 0

 [3] 1
....

Any idea how to do this?




On Wed, May 27, 2015 at 10:11 AM, Mohammad Alimohammadi <
mxalimohamma at ualr.edu> wrote:

> Hi Jim,
>
> Thank you for your advice.
>
> I'm not sure how to exactly incorporate this function though. I added a
> portion of the actual data sets. all 3 data sets have the same items (text)
> with different class values. So I need to assign the most repeated class
> (0,1,2) for each text.
>
> For example: if line1 has text "aaa". It may be assigned to class 0 in
> dat1, 2 in dat 2 and 0 in dat3. in this case the "aaa" will be assigned to
> 0 (most repeated value). So it goes for each text.
>
> I really appreciate your help.
>
> =========================================
>
> *dat1*
>
> structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
> 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
> c("#dac",
> "#mac,#security", "accountability,anonymous", "data
> security,encryption,security"
> ), class = "factor")), .Names = c("class.1", "terms"), class =
> "data.frame", row.names = c(NA,
> -49L))
>
>
> *dat2*
>
> structure(list(class.2 = c(2L, 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L,
> 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L), terms = structure(c(1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
> c("#dac",
> "#mac,#security", "accountability,anonymous", "data
> security,encryption,security"
> ), class = "factor")), .Names = c("class.2", "terms"), class =
> "data.frame", row.names = c(NA,
> -49L))
>
>
> *dat3*
>
> structure(list(class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
> 1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
> c("#dac",
> "#mac,#security", "accountability,anonymous", "data
> security,encryption,security"
> ), class = "factor")), .Names = c("class.3", "terms"), class =
> "data.frame", row.names = c(NA,
> -49L))
>
> ===========================================================
>
>
> On Sun, May 24, 2015 at 1:15 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Mohammad,
>> You know, I thought this would be fairly easy, but it wasn't really.
>>
>> df1<-data.frame(Class=c(0,2,1),Comment=c("com1","com2","com3"),
>>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
>> df2<-data.frame(Class=c(0,2,1),Comment=c("com1","com2","com3"),
>>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
>> df3<-data.frame(Class=c(2,1,0),Comment=c("com1","com2","com3"),
>>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
>> dflist<-list(df1,df2,df3)
>> dflist
>>
>> # define a function that extracts the value from one field
>> # selected by a value in another field
>> extract_by_value<-function(x,field1,value1,field2) {
>>  return(x[x[,field1]==value1,field2])
>> }
>>
>> # define another function that equates all of the values
>> sub_value<-function(x,field1,value1,field2,value2) {
>>  x[x[,field1]==value1,field2]<-value2
>>  return(x)
>> }
>>
>> conformity<-function(x,fieldname1,value1,fieldname2) {
>>  # get the most frequent value in fieldname2
>>  # for the desired value in fieldname1
>>  most_freq<-as.numeric(names(which.max(table(unlist(lapply(x,
>>   extract_by_value,fieldname1,value1,fieldname2))))))
>>  # now set all the values to the most frequent
>>  for(i in 1:length(x))
>>   x[[i]]<-sub_value(x[[i]],fieldname1,value1,fieldname2,most_freq)
>>  return(x)
>> }
>>
>> conformity(dflist,"Text","text1","Class")
>>
>> Jim
>>
>> On Sat, May 23, 2015 at 11:23 PM, John Kane <jrkrideau at inbox.com> wrote:
>> > Hi Mohammad
>> >
>> > Welcome to the R-help list.
>> >
>> > There probably is a fairly easy way to what you want but I think we
>> probably need a bit more background information on what you are trying to
>> achieve.  I know I'm not exactly clear on your decision rule(s).
>> >
>> > It would also be very useful to see some actual sample data in useable
>> R format.Have a look at these links
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> and http://adv-r.had.co.nz/Reproducibility.html for some hints on what
>> you might want to include in your question.
>> >
>> > In particular, read up about dput()  in those links and/or see ?dput.
>> This is the generally preferred way to supply sample or illustrative data
>> to the R-help list.  It basically creates a perfect copy of the data as it
>> exists on 'your' machine so that R-help readers see exactly what you do.
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > John Kane
>> > Kingston ON Canada
>> >
>> >
>> >> -----Original Message-----
>> >> From: mxalimohamma at ualr.edu
>> >> Sent: Fri, 22 May 2015 12:37:50 -0500
>> >> To: r-help at r-project.org
>> >> Subject: [R] Problem with comparing multiple data sets
>> >>
>> >> Hi everyone,
>> >>
>> >> I am very new to R and I have a task to do. I appreciate any help. I
>> have
>> >> 3
>> >> data sets. Each data set has 4 columns. For example:
>> >>
>> >> Class  Comment   Term   Text
>> >> 0           com1        aac    text1
>> >> 2           com2        aax    text2
>> >> 1           com3        vvx    text3
>> >>
>> >> Now I need t compare the class section between 3 data sets and assign
>> the
>> >> most available class to that text. For example if text1 is assigned to
>> >> class 0 in data set 1&2 but assigned as 2 in data set 3 then it should
>> be
>> >> assigned to class 0. If they are all the same so the class will be the
>> >> same. The ideal thing would be to keep the same format and just update
>> >> the
>> >> class. Is there any easy way to do this?
>> >>
>> >> Thanks a lot.
>> >>
>> >>       [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ____________________________________________________________
>> > FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Mohammad Alimohammadi | Graduate Assistant
> University of Arkansas at Little Rock | College of Science and Mathematics
> (CSAM)
> | mxalimohamma at ualr.edu | ualr.edu
>
> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
>



-- 
Mohammad Alimohammadi | Graduate Assistant
University of Arkansas at Little Rock | College of Science and Mathematics
(CSAM)
501.346.8007 | mxalimohamma at ualr.edu | ualr.edu

Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mxalimohamma at ualr.edu  Wed May 27 21:28:48 2015
From: mxalimohamma at ualr.edu (Mohammad Alimohammadi)
Date: Wed, 27 May 2015 14:28:48 -0500
Subject: [R] Problem with comparing multiple data sets
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68EA9D@mb02.ads.tamu.edu>
References: <CAJVfk9nM_a2Gr86OXimHbc8HZoN45RMWLL_VmXak4RPoj1=OQw@mail.gmail.com>
	<32FCEB5D574.0000035Fjrkrideau@inbox.com>
	<CA+8X3fW4BwSQ2U-EpUmzQzsfL-4sYJZaKFR56qS8i-FMk7HPfA@mail.gmail.com>
	<CAJVfk9kx-hJyeUd5q=Y6KGxY8oYzW3J4sHhXDUv39JJ1F43mtA@mail.gmail.com>
	<CAJVfk9k+Qk9CUqrbTLmAjyVdu5ErZHtd1VErHnABPkHiikDOaQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D68EA9D@mb02.ads.tamu.edu>
Message-ID: <CAJVfk9m1LCja8DXU9w4CYMGKpGnYHNNseeY7cbLN4QfWUKoMMg@mail.gmail.com>

Thanks David it worked !

One more thing. I hope it's not complicated. Is it also possible to display
the terms for each row next to it?

for example:

[1] #dac    2
[2] #dac    0
[3] #dac    1
...




On Wed, May 27, 2015 at 2:18 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> Save the result of the apply() function:
>
> Out <- apply(df[ ,2:length(df)], 1, mfv)
>
> Then there are several options:
>
> Approximately what you asked for
> data.frame(Out)
> t(t(Out))
>
> More typing but exactly what you asked for
> cat(paste0("[", 1:length(Out), "] ", Out), sep="\n")
>
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Mohammad
> Alimohammadi
> Sent: Wednesday, May 27, 2015 1:47 PM
> To: John Kane; r-help at r-project.org
> Subject: Re: [R] Problem with comparing multiple data sets
>
> Ok. so I read about the ("modeest") package that gives the results that I
> am looking for (most repeated value).
>
> I modified the data frame a little and moved the text to the first column.
> This is the data frame with all 3 possible classes for each term.
>
> =================================
> structure(list(terms = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 4L, 4L,
> 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label = c("#dac",
> "#mac,#security",
> "accountability,anonymous", "data security,encryption,security"
> ), class = "factor"), class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L,
> 1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), class.2 = c(2L, 2L,
> 2L, 2L, 0L, 0L, 2L, 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L,
> 0L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L),
>     class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>     0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>     0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L, 1L,
>     0L, 0L, 0L, 0L, 2L, 1L, 2L)), .Names = c("terms", "class.1",
> "class.2", "class.3"), class = "data.frame", row.names = c(NA,
> -49L))
> =============================================
> #Then I applied the function below:
>
> ======================
> library(modeest)
> df<- read.csv(file="short.csv", head= TRUE, sep=",")
> apply(df[ ,2:length(df)], 1, mfv)
>
> ============================
> # It gives the most frequent value for each row which is what I need. The
> only problem is that all the values are displayed in one single row.
>
>  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> 0 0 2 1 1 1 1 0 0 0 0 2 1 2
>
> It would be much better to show them in separate rows.
> For example:
>
>  [1] 0
>
>  [2] 0
>
>  [3] 1
> ....
>
> Any idea how to do this?
>
>
>
>
> On Wed, May 27, 2015 at 10:11 AM, Mohammad Alimohammadi <
> mxalimohamma at ualr.edu> wrote:
>
> > Hi Jim,
> >
> > Thank you for your advice.
> >
> > I'm not sure how to exactly incorporate this function though. I added a
> > portion of the actual data sets. all 3 data sets have the same items
> (text)
> > with different class values. So I need to assign the most repeated class
> > (0,1,2) for each text.
> >
> > For example: if line1 has text "aaa". It may be assigned to class 0 in
> > dat1, 2 in dat 2 and 0 in dat3. in this case the "aaa" will be assigned
> to
> > 0 (most repeated value). So it goes for each text.
> >
> > I really appreciate your help.
> >
> > =========================================
> >
> > *dat1*
> >
> > structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
> > 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
> > c("#dac",
> > "#mac,#security", "accountability,anonymous", "data
> > security,encryption,security"
> > ), class = "factor")), .Names = c("class.1", "terms"), class =
> > "data.frame", row.names = c(NA,
> > -49L))
> >
> >
> > *dat2*
> >
> > structure(list(class.2 = c(2L, 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L,
> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L,
> > 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L), terms = structure(c(1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
> > c("#dac",
> > "#mac,#security", "accountability,anonymous", "data
> > security,encryption,security"
> > ), class = "factor")), .Names = c("class.2", "terms"), class =
> > "data.frame", row.names = c(NA,
> > -49L))
> >
> >
> > *dat3*
> >
> > structure(list(class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
> > 1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
> > c("#dac",
> > "#mac,#security", "accountability,anonymous", "data
> > security,encryption,security"
> > ), class = "factor")), .Names = c("class.3", "terms"), class =
> > "data.frame", row.names = c(NA,
> > -49L))
> >
> > ===========================================================
> >
> >
> > On Sun, May 24, 2015 at 1:15 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >> Hi Mohammad,
> >> You know, I thought this would be fairly easy, but it wasn't really.
> >>
> >> df1<-data.frame(Class=c(0,2,1),Comment=c("com1","com2","com3"),
> >>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
> >> df2<-data.frame(Class=c(0,2,1),Comment=c("com1","com2","com3"),
> >>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
> >> df3<-data.frame(Class=c(2,1,0),Comment=c("com1","com2","com3"),
> >>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
> >> dflist<-list(df1,df2,df3)
> >> dflist
> >>
> >> # define a function that extracts the value from one field
> >> # selected by a value in another field
> >> extract_by_value<-function(x,field1,value1,field2) {
> >>  return(x[x[,field1]==value1,field2])
> >> }
> >>
> >> # define another function that equates all of the values
> >> sub_value<-function(x,field1,value1,field2,value2) {
> >>  x[x[,field1]==value1,field2]<-value2
> >>  return(x)
> >> }
> >>
> >> conformity<-function(x,fieldname1,value1,fieldname2) {
> >>  # get the most frequent value in fieldname2
> >>  # for the desired value in fieldname1
> >>  most_freq<-as.numeric(names(which.max(table(unlist(lapply(x,
> >>   extract_by_value,fieldname1,value1,fieldname2))))))
> >>  # now set all the values to the most frequent
> >>  for(i in 1:length(x))
> >>   x[[i]]<-sub_value(x[[i]],fieldname1,value1,fieldname2,most_freq)
> >>  return(x)
> >> }
> >>
> >> conformity(dflist,"Text","text1","Class")
> >>
> >> Jim
> >>
> >> On Sat, May 23, 2015 at 11:23 PM, John Kane <jrkrideau at inbox.com>
> wrote:
> >> > Hi Mohammad
> >> >
> >> > Welcome to the R-help list.
> >> >
> >> > There probably is a fairly easy way to what you want but I think we
> >> probably need a bit more background information on what you are trying
> to
> >> achieve.  I know I'm not exactly clear on your decision rule(s).
> >> >
> >> > It would also be very useful to see some actual sample data in useable
> >> R format.Have a look at these links
> >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >> and http://adv-r.had.co.nz/Reproducibility.html for some hints on what
> >> you might want to include in your question.
> >> >
> >> > In particular, read up about dput()  in those links and/or see ?dput.
> >> This is the generally preferred way to supply sample or illustrative
> data
> >> to the R-help list.  It basically creates a perfect copy of the data as
> it
> >> exists on 'your' machine so that R-help readers see exactly what you do.
> >> >
> >> >
> >> >
> >> >
> >> >
> >> >
> >> >
> >> > John Kane
> >> > Kingston ON Canada
> >> >
> >> >
> >> >> -----Original Message-----
> >> >> From: mxalimohamma at ualr.edu
> >> >> Sent: Fri, 22 May 2015 12:37:50 -0500
> >> >> To: r-help at r-project.org
> >> >> Subject: [R] Problem with comparing multiple data sets
> >> >>
> >> >> Hi everyone,
> >> >>
> >> >> I am very new to R and I have a task to do. I appreciate any help. I
> >> have
> >> >> 3
> >> >> data sets. Each data set has 4 columns. For example:
> >> >>
> >> >> Class  Comment   Term   Text
> >> >> 0           com1        aac    text1
> >> >> 2           com2        aax    text2
> >> >> 1           com3        vvx    text3
> >> >>
> >> >> Now I need t compare the class section between 3 data sets and assign
> >> the
> >> >> most available class to that text. For example if text1 is assigned
> to
> >> >> class 0 in data set 1&2 but assigned as 2 in data set 3 then it
> should
> >> be
> >> >> assigned to class 0. If they are all the same so the class will be
> the
> >> >> same. The ideal thing would be to keep the same format and just
> update
> >> >> the
> >> >> class. Is there any easy way to do this?
> >> >>
> >> >> Thanks a lot.
> >> >>
> >> >>       [[alternative HTML version deleted]]
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> > ____________________________________________________________
> >> > FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> >
> > --
> > Mohammad Alimohammadi | Graduate Assistant
> > University of Arkansas at Little Rock | College of Science and
> Mathematics
> > (CSAM)
> > | mxalimohamma at ualr.edu | ualr.edu
> >
> > Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
> >
>
>
>
> --
> Mohammad Alimohammadi | Graduate Assistant
> University of Arkansas at Little Rock | College of Science and Mathematics
> (CSAM)
> 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu
>
> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Mohammad Alimohammadi | Graduate Assistant
University of Arkansas at Little Rock | College of Science and Mathematics
(CSAM)
501.346.8007 | mxalimohamma at ualr.edu | ualr.edu

Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ

	[[alternative HTML version deleted]]


From jenn.sweatman21 at gmail.com  Wed May 27 22:08:58 2015
From: jenn.sweatman21 at gmail.com (Jennifer Sweatman)
Date: Wed, 27 May 2015 16:08:58 -0400
Subject: [R] Issue with 95% CI using MASS{confint}
Message-ID: <CACBvRXSAAVsMYEOmqR7q4yKY3mctZKR=z7TeRQQ8suxrYd9KBA@mail.gmail.com>

I am trying to run a nonlinear model looking at seasonal abundance of
plants with the following limitations:



fit.nls.s<-nls(S_a~beta+m*time+alpha*sin(w*time+phi),

             data= xy,

             start=list(beta=2.1, m=0, alpha=2, phi = 1, w = 1),

             upper=list(beta="inf", m="inf", alpha="inf", phi = 2*pi, w =
"inf"),

             lower=list(beta="-inf", m="-inf", alpha=0, phi = 0, w =
0.0000001),

             algorithm="port")



I want to know the 95% confidence intervals for all of my model
parameters.  I have been using confint from the MASS package but I?m
getting some NA values.  See output below:

confint(fit.nls.s)

            2.5%     97.5%

beta  1.68170858 2.5635734

m     0.02810172 0.0710163

alpha         NA 0.6755750

phi           NA        NA

w             NA 1.0275199

The parameters I most need 95% CIs for are alpha and w (when alpha is
significant), but I consistently get NA for the lower limit of both.  I
have changed my Upper/Lower limits for alpha, phi, and w to +/- infinity,
but my CIs still don?t include complete intervals. Any suggestions as to
what is going on here?



Thank you for your time

	[[alternative HTML version deleted]]


From wjm1 at caa.columbia.edu  Wed May 27 22:00:29 2015
From: wjm1 at caa.columbia.edu (William Michels)
Date: Wed, 27 May 2015 13:00:29 -0700
Subject: [R] Problem merging data frames and duplicates
In-Reply-To: <CAAbnQ5gAizocfv3dTr4mCTbS4FpvrA83WBaNtBdXRhuVaSHmtQ@mail.gmail.com>
References: <CAAbnQ5gJ_B-pqz2+z15+yCXGqBobje0aOVMkSOgQVxVuacMnNg@mail.gmail.com>
	<CAA99HCyqULLzW2aodnwZ2epPWP+MSX+Q6-TGM6tRk5Ro=D-EaQ@mail.gmail.com>
	<CAAbnQ5iYF-Ajr0xNjowMJrXPbc+P+6KBN9w6OJVW+C0=_toF_A@mail.gmail.com>
	<CAAbnQ5ipi5MGtYri3CXoguNAp4Tq21DSN-+yaKP6QtuR-ESmVw@mail.gmail.com>
	<CAA99HCxgV+arv7oxLop_8Jnhz=DGfRPrKC+1gy2bckKaQ6zphQ@mail.gmail.com>
	<CAAbnQ5gAizocfv3dTr4mCTbS4FpvrA83WBaNtBdXRhuVaSHmtQ@mail.gmail.com>
Message-ID: <CAA99HCwtyhW44gGcUkfcag-ZAAnmMHW29Y3ZSBnYQ=oqOzfd9Q@mail.gmail.com>

Notes:

1. You can get output for all states (alphabetically) by pre-merging
data with states.abb:

a1 <- merge(state.abb, x, by= 1, all.x=T)
b1 <- merge(state.abb, y, by= 1, all.x=T)
colnames(a1) <- c("state", "locus")
colnames(b1) <- c("state", "locus")
by.states1(a1,b1)

2. In my previous post (based on the very small test data given), it
seemed output could be arranged sequentially by row numbers, while
keeping states alphabetically arranged. This doesn't appear to be
possible in general. The larger example above is in state-alphabetical
order, but row numbers are not sequential.

Best, Bill

William Michels, Ph.D.


On Wed, May 27, 2015 at 6:42 AM, Frank Burbrink <burbrink666 at gmail.com> wrote:
> Interesting solutions. Thanks guys!
>
> On Wed, May 27, 2015 at 9:27 AM, William Michels <wjm1 at caa.columbia.edu>
> wrote:


From murdoch.duncan at gmail.com  Wed May 27 22:28:48 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 27 May 2015 16:28:48 -0400
Subject: [R] Issue with 95% CI using MASS{confint}
In-Reply-To: <CACBvRXSAAVsMYEOmqR7q4yKY3mctZKR=z7TeRQQ8suxrYd9KBA@mail.gmail.com>
References: <CACBvRXSAAVsMYEOmqR7q4yKY3mctZKR=z7TeRQQ8suxrYd9KBA@mail.gmail.com>
Message-ID: <55662900.4000600@gmail.com>

On 27/05/2015 4:08 PM, Jennifer Sweatman wrote:
> I am trying to run a nonlinear model looking at seasonal abundance of
> plants with the following limitations:
> 
> 
> 
> fit.nls.s<-nls(S_a~beta+m*time+alpha*sin(w*time+phi),
> 
>              data= xy,
> 
>              start=list(beta=2.1, m=0, alpha=2, phi = 1, w = 1),
> 
>              upper=list(beta="inf", m="inf", alpha="inf", phi = 2*pi, w =
> "inf"),
> 
>              lower=list(beta="-inf", m="-inf", alpha=0, phi = 0, w =
> 0.0000001),
> 
>              algorithm="port")
> 
> 
> 
> I want to know the 95% confidence intervals for all of my model
> parameters.  I have been using confint from the MASS package but I?m
> getting some NA values.  See output below:
> 
> confint(fit.nls.s)
> 
>             2.5%     97.5%
> 
> beta  1.68170858 2.5635734
> 
> m     0.02810172 0.0710163
> 
> alpha         NA 0.6755750
> 
> phi           NA        NA
> 
> w             NA 1.0275199
> 
> The parameters I most need 95% CIs for are alpha and w (when alpha is
> significant), but I consistently get NA for the lower limit of both.  I
> have changed my Upper/Lower limits for alpha, phi, and w to +/- infinity,
> but my CIs still don?t include complete intervals. Any suggestions as to
> what is going on here?

Probably the profiling failed.  You could look at
plot(profile(fit.nls.s)) to see an indication of what's going on.  If
your tau values don't exceed 2 on one side of the estimate, you can't
get a confidence limit on that side.  Your data may not rule out any phi
values, or may not rule out a lower limit on alpha or w.

Duncan Murdoch


From lordpreetam at gmail.com  Wed May 27 22:43:32 2015
From: lordpreetam at gmail.com (Preetam Pal)
Date: Thu, 28 May 2015 02:13:32 +0530
Subject: [R] Multivariate Kernel Regression : Nadaraya-Watson or
	Gasser-Muller methods
Message-ID: <CAHVFrXHSvwoNm9thdDVR0B5H1k2-C0v_W5F8aJM2sdBp4VinPA@mail.gmail.com>

Hi R-users,

Can anybody kindly inform me which package I need to install in RStudio to
run *Multivariate Kernel Regressions* (preferably,Gasser-Muller or
Nadaraya-Watson) ?
I am getting only univariate set-ups in the online resources, I need
multivariate (i.e. multiple regressors).

Thanks and regards,
Preetam

-- 
Preetam Pal
(+91)-9432212774
M-Stat 2nd Year,                                             Room No. N-114
Statistics Division,                                           C.V.Raman
Hall
Indian Statistical Institute,                                 B.H.O.S.
Kolkata.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed May 27 23:57:13 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 27 May 2015 14:57:13 -0700
Subject: [R] Collinearity? Cannot get logisticRidge{ridge} to work
In-Reply-To: <CAC7aZ4nmOwjKx9dZ9yA553bqG_4yg+uKJxNThZn1-dAZPRyOOA@mail.gmail.com>
References: <CAC7aZ4mjgNh1ZtvYw6boDxdCxOLyGAMqaeHdzW1148U_Lk1ZCw@mail.gmail.com>
	<D34A739F-63C5-48FA-BD1D-56B676416B43@comcast.net>
	<CAC7aZ4nmOwjKx9dZ9yA553bqG_4yg+uKJxNThZn1-dAZPRyOOA@mail.gmail.com>
Message-ID: <11F65DBA-E64E-44C4-8F41-99A69844F2F0@comcast.net>


On May 27, 2015, at 2:49 PM, Kengo Inagaki wrote:

> Thank you very much for your rapid response. I sincerely appreciate your input.
> I am sorry for sending the previous email in HTML format.
> 
> with(a,  table(Sex, Therapy1) )   shows the following.
>          Therapy1
> Sex      no yes
>  female  6   7
>  male    7   5
> 
>  and with(a,  table(Therapy1, Outcome) )
> elicit the following
> 
>        Outcome
> Sex      Alive Death
>  female     4     9
>  male       9     3
> 
>        Outcome
> Therapy1 Alive Death
>     no      4     9
>     yes     9     3

Then what about:

with(a,  table(Sex, Therapy1,  Outcome) )

-- 
David


> 
> As there is no zero cells, it does not seem to be complete separation.
> I really appreciate comments.
> 
> Kengo Inagaki
> Memphis, TN
> 
> 
> 2015-05-27 13:57 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>> 
>> On May 27, 2015, at 10:10 AM, Kengo Inagaki wrote:
>> 
>>> I am currently working on a health care related project using R. I am
>>> learning R while working on data analysis.
>>> 
>>> Below is the part of the data in which i am encountering a problem.
>>> 
>>> 
>>> Case#    Sex         Therapy1             Therapy2             Outcome
>>> 
>>> 1              male      no
>>> no                           Alive
>>> 
>> 
>> snipped mangled data sent in HTML
>> 
>>> 
>>> 
>>> "Outcome" is the response variable and "Sex", "Therapy1", "Therapy2" are
>>> predictor variables.
>>> 
>>> All of the predictors are significantly associated with the outcome by
>>> univariate analysis.
>>> 
>>> Logistic regression runs fine with most of the predictors when "Sex" and
>>> "Therapy1" are not included at the same time (This is a part of table that
>>> I cut out from a larger table for ease of
>>> 
>>> presentation and there are more predictors that i tested).
>> 
>> Please examine the data before reaching for ridge regression:
>> 
>> What does this show: ...
>> 
>>    with(a,  table(Sex, Therapy1) )
>> 
>> I predict you will see a zero cell entry. The read about "complete separation" and the so-called "Hauck-Donner effect".
>> 
>> --
>> David.
>>> 
>>> However, when "Sex" and "Therapy1" are included in logistic regression
>>> model at the same time, standard error inflates and p value gets close to 1.
>>> 
>>> The formula used is,
>>> 
>>> 
>>> 
>>>> Model<-glm(Outcome~Sex+Therapy1,data=a,family=binomial) #I assigned a
>>> vector "a" to represent above table.
>>> 
>>> 
>>> 
>>> After doing some reading, I suspect this might be collinearity, as vif
>>> values (using "vif()" function in car package) were sky high (8,875,841 for
>>> both "Sex" and "Therapy1").
>>> 
>>> Learning that ridge regression may be a solution, I attempted using
>>> logisticRidge {ridge} using the following formula, but i get the
>>> accomapnying error message.
>>> 
>>> 
>>> 
>>>> logisticRidge(a$Outcome~a$Sex+a$Therapy1)
>>> 
>>> 
>>> 
>>> Error in ifelse(y, log(p), log(1 - p)) :
>>> 
>>> invalid to change the storage mode of a factor
>>> 
>>> 
>>> 
>>> At this point I do not have an idea how to solve this and would like to
>>> seek help.
>>> 
>>> I really really appreciate your input!!!
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>> 
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu May 28 00:03:28 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 27 May 2015 15:03:28 -0700
Subject: [R] Collinearity? Cannot get logisticRidge{ridge} to work
In-Reply-To: <CAC7aZ4kH4d6JDNYpjxe8fttAovDiZ3=sBrJisKO7CiUcyFr1Ew@mail.gmail.com>
References: <CAC7aZ4mjgNh1ZtvYw6boDxdCxOLyGAMqaeHdzW1148U_Lk1ZCw@mail.gmail.com>
	<D34A739F-63C5-48FA-BD1D-56B676416B43@comcast.net>
	<CAC7aZ4nmOwjKx9dZ9yA553bqG_4yg+uKJxNThZn1-dAZPRyOOA@mail.gmail.com>
	<11F65DBA-E64E-44C4-8F41-99A69844F2F0@comcast.net>
	<CAC7aZ4kH4d6JDNYpjxe8fttAovDiZ3=sBrJisKO7CiUcyFr1Ew@mail.gmail.com>
Message-ID: <DD6A8E58-F75D-4D09-840C-65A4065A7583@comcast.net>


On May 27, 2015, at 3:00 PM, Kengo Inagaki wrote:

> Here is the result-
> 
>> with(a,  table(Sex, Therapy1,  Outcome) )
> , , Outcome = Alive
> 
>        Therapy1
> Sex      no yes
>  female  0   4
>  male    4   5
> 
> , , Outcome = Death
> 
>        Therapy1
> Sex      no yes
>  female  6   3
>  male    3   0

So no deaths when Female had no-Therapy1 and no survivors with the opposite for those variables. Complete separation.

-- 
David.

> 
> 
> 2015-05-27 16:57 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>> 
>> On May 27, 2015, at 2:49 PM, Kengo Inagaki wrote:
>> 
>>> Thank you very much for your rapid response. I sincerely appreciate your input.
>>> I am sorry for sending the previous email in HTML format.
>>> 
>>> with(a,  table(Sex, Therapy1) )   shows the following.
>>>         Therapy1
>>> Sex      no yes
>>> female  6   7
>>> male    7   5
>>> 
>>> and with(a,  table(Therapy1, Outcome) )
>>> elicit the following
>>> 
>>>       Outcome
>>> Sex      Alive Death
>>> female     4     9
>>> male       9     3
>>> 
>>>       Outcome
>>> Therapy1 Alive Death
>>>    no      4     9
>>>    yes     9     3
>> 
>> Then what about:
>> 
>> with(a,  table(Sex, Therapy1,  Outcome) )
>> 
>> --
>> David
>> 
>> 
>>> 
>>> As there is no zero cells, it does not seem to be complete separation.
>>> I really appreciate comments.
>>> 
>>> Kengo Inagaki
>>> Memphis, TN
>>> 
>>> 
>>> 2015-05-27 13:57 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>>>> 
>>>> On May 27, 2015, at 10:10 AM, Kengo Inagaki wrote:
>>>> 
>>>>> I am currently working on a health care related project using R. I am
>>>>> learning R while working on data analysis.
>>>>> 
>>>>> Below is the part of the data in which i am encountering a problem.
>>>>> 
>>>>> 
>>>>> Case#    Sex         Therapy1             Therapy2             Outcome
>>>>> 
>>>>> 1              male      no
>>>>> no                           Alive
>>>>> 
>>>> 
>>>> snipped mangled data sent in HTML
>>>> 
>>>>> 
>>>>> 
>>>>> "Outcome" is the response variable and "Sex", "Therapy1", "Therapy2" are
>>>>> predictor variables.
>>>>> 
>>>>> All of the predictors are significantly associated with the outcome by
>>>>> univariate analysis.
>>>>> 
>>>>> Logistic regression runs fine with most of the predictors when "Sex" and
>>>>> "Therapy1" are not included at the same time (This is a part of table that
>>>>> I cut out from a larger table for ease of
>>>>> 
>>>>> presentation and there are more predictors that i tested).
>>>> 
>>>> Please examine the data before reaching for ridge regression:
>>>> 
>>>> What does this show: ...
>>>> 
>>>>   with(a,  table(Sex, Therapy1) )
>>>> 
>>>> I predict you will see a zero cell entry. The read about "complete separation" and the so-called "Hauck-Donner effect".
>>>> 
>>>> --
>>>> David.
>>>>> 
>>>>> However, when "Sex" and "Therapy1" are included in logistic regression
>>>>> model at the same time, standard error inflates and p value gets close to 1.
>>>>> 
>>>>> The formula used is,
>>>>> 
>>>>> 
>>>>> 
>>>>>> Model<-glm(Outcome~Sex+Therapy1,data=a,family=binomial) #I assigned a
>>>>> vector "a" to represent above table.
>>>>> 
>>>>> 
>>>>> 
>>>>> After doing some reading, I suspect this might be collinearity, as vif
>>>>> values (using "vif()" function in car package) were sky high (8,875,841 for
>>>>> both "Sex" and "Therapy1").
>>>>> 
>>>>> Learning that ridge regression may be a solution, I attempted using
>>>>> logisticRidge {ridge} using the following formula, but i get the
>>>>> accomapnying error message.
>>>>> 
>>>>> 
>>>>> 
>>>>>> logisticRidge(a$Outcome~a$Sex+a$Therapy1)
>>>>> 
>>>>> 
>>>>> 
>>>>> Error in ifelse(y, log(p), log(1 - p)) :
>>>>> 
>>>>> invalid to change the storage mode of a factor
>>>>> 
>>>>> 
>>>>> 
>>>>> At this point I do not have an idea how to solve this and would like to
>>>>> seek help.
>>>>> 
>>>>> I really really appreciate your input!!!
>>>>> 
>>>>>     [[alternative HTML version deleted]]
>>>>> 
>>>> 
>>>> 
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>> 
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From djnordlund at frontier.com  Thu May 28 01:10:18 2015
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Wed, 27 May 2015 16:10:18 -0700
Subject: [R] Getting a cdf equal to 1 from a variable kernel density
	estimation
In-Reply-To: <CABX4axPKoq+SFbLDjMyLVHXBDB0HAdox1UK0jj7ZFP1TS008=g@mail.gmail.com>
References: <CABX4axPKoq+SFbLDjMyLVHXBDB0HAdox1UK0jj7ZFP1TS008=g@mail.gmail.com>
Message-ID: <55664EDA.4030606@frontier.com>

On 5/27/2015 2:43 AM, Lionel Delmas wrote:
> When I integrate the variable kernel density estimation of a sample from
> -inf to inf, I should get 1. But it is not what I get with my code below. I
> find a value higher than 2. How can I fix this?
>
> n<-1000
> df <- data.frame(x=unlist(lapply(1, function(i) rnorm(n, 0,sd=1))))
> df<-as.data.frame(df[order(df$x),])
> names(df)[1]<-"x"
>
> library(functional)
>
> gaussianKernel <- function(u, h) exp(-sum(u^2)/(2*h^2))
>
> densityFunction <- function(x, df, ker, h){
>      difference = t(t(df) - x)
>      W = sum(apply(difference, 1, ker, h=h))
>      W/(nrow(df)*(h^(length(df))))}
>
> myDensityFunction <- Curry(densityFunction, df=df, ker=gaussianKernel , h=2)
>
> vect<-vector()for (i in 1:length(df$x)){
> f<-myDensityFunction(df$x[i])
> vect<-c(vect,f)}
>
> plot(df$x,vect,ylim=c(0,1),xlim=c(-5,5),type="l")
>
> f <- approxfun(df$x, vect, yleft = 0, yright = 0)
> integrate(f, -Inf, Inf)
>
> Thanks
>


I ran your code.  Looking at the plot output, it is obvious that there 
is something wrong with you density estimates.  Since you are estimating 
density for standard normal random variates, the density for values near 
0 should be approximately 0.4, and for values in the tails the density 
should be "close" to 0.

You mention "variable kernel density estimation", but I don't see where 
you are varying your smoothing parameter, h, or any distance measure.  R 
provides a density function that could be used here, unless you are just 
wanting an excerise in how density estimation works (or this is a 
homework problem).

This is not my area of expertise, but the main problem(s) appears to be 
how gaussianKernel() and densityFunction() are written.  I think you 
want something like the following:

gaussianKernel <- function(u) exp(-u^2/2)/(2*pi)^.5

densityFunction <- function(x, df, ker, h){
     difference = t(t(df) - x)/h
     W = sum(apply(difference, 1, ker)) / (nrow(df)*h)
     }


If you are wanting to do density estimation for real world work, I would 
get help from someone in your local area.


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Bothell, WA USA


From dwinsemius at comcast.net  Thu May 28 02:26:14 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 27 May 2015 17:26:14 -0700
Subject: [R] Double Hierarchical Generalized Linear Models
In-Reply-To: <03FB0833-DACE-4DBA-ADFE-7F69605F5BB9@gmail.com>
References: <03FB0833-DACE-4DBA-ADFE-7F69605F5BB9@gmail.com>
Message-ID: <7DC4EEAD-ED37-47AB-AF35-3CA88371E3DF@comcast.net>


On May 27, 2015, at 10:00 AM, Mariana Velasque wrote:

> I am new modeling and I am trying to analyse my data using the package Double Hierarchical Generalized Linear Models.

> However, I always get the same sort of error:
> 
> Error in z %*% v_h : non-conformable arguments. 

It means the either one or more of those are not matrices or that dim(z)[2] is not equal to dim(v_h)[1]

Cannot multiply matrix and array
> matrix(1:4, 2) %*% array(1:8, c(2,2,2))
Error in matrix(1:4, 2) %*% array(1:8, c(2, 2, 2)) : 
  non-conformable arguments


> matrix(1:4, 2) %*% matrix(1:8, 2)
     [,1] [,2] [,3] [,4]
[1,]    7   15   23   31
[2,]   10   22   34   46

> dim(matrix(1:4, 2))[2] == dim( matrix(1:8, 2))[1]
[1] TRUE

> matrix(1:4, 2) %*% matrix(1:8, 4)
Error in matrix(1:4, 2) %*% matrix(1:8, 4) : non-conformable arguments

Suggests to me that you are sending the function a data layout that it was not designed to handle.


> I think that this error indicates that the matrices are created with non-calculable dimensions, but I don't know how to solve it.
> 
> I am creating my model with two fixed and two random effects. with this format:
> 
> # rm(list=ls(all=TRUE))

Many people think it is rather discourteous to leave this code in without a comment symbol in front of it as a warning.

> library("dhglm")
> 
> data=read.csv("log_data.csv", header=TRUE)

Since we cannot see these 'data', none of the rest of the code will be meaningful other than letting us see that none of your objects had those names. (But perhaps one of your columns was named "z" or "v_h"? The error is apparently not being trapped in the setup process for matrix algebra, so the maintainer is the only person who has a good chance of debugging.  You are advised in the posting guide to first send questions about rarely used packages ... along with the data ... to the package maintainer.


> phi<-matrix(1,n<-nrow(data),1)
> lambda<-matrix(1,n<-nrow(data),1)
> data<-cbind(data,phi,lambda)
> 
> sr <- as.numeric(data$SR)   ##Dependent variable
> 
> id <- as.numeric(data$ID)    ##individual number
>    obs <- as.numeric(data$Obs)    ##Observation number
> 
> o2r <- as.numeric(data$O2R)    ##Fixed factor 1 (oxygen consumption 1)
>    o2a <-as.numeric(data$O2A)    ##Fixed factor 2 (oxygen consumption 2)
> 
> lambda <-as.numeric(data$lambda)
> 
> phi<-as.numeric(data$phi)
> 
> 
> model_mu<-DHGLMMODELING(Model="mean",
> Link="log",
> LinPred= sr~o2a+ o2r + (1|id) + (1|obs),
> RandDist= c("inverse-gamma", "gamma"),
> LinPredRandVariance=lambda~ 1 +(1|id) + (1|obs) ,
> RandDistRandVariance=c("gaussian", "gaussian"))
> 
> model_phi<-DHGLMMODELING(Model="dispersion", 
> Link="log", 
> LinPred = phi~o2a+ o2r + (1|id) + (1|obs), 
> RandDist= c("gaussian", "gaussian"))   
> 
> res_glm<-dhglmfit(RespDist="gaussian",    
>                  DataMain=data,
>                  MeanModel=model_mu,
>                  DispersionModel=model_phi,
>                PhiFix=NULL, LamFix=NULL,mord=1,dord=1,Maxiter=200,convergence=1e-06)
> 
> Mariana Velasque 
> 
> PhD Student 
> Marine Biology & Ecology Research Centre | School of Marine Science and Engineering | 


snipped

> 
> 	[[alternative HTML version deleted]]

Please learn to use your mail client to send plain text. (It's not hard to do this with gmail.)

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Thu May 28 02:31:45 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 28 May 2015 00:31:45 +0000
Subject: [R] Problem with comparing multiple data sets
In-Reply-To: <CAJVfk9m1LCja8DXU9w4CYMGKpGnYHNNseeY7cbLN4QfWUKoMMg@mail.gmail.com>
References: <CAJVfk9nM_a2Gr86OXimHbc8HZoN45RMWLL_VmXak4RPoj1=OQw@mail.gmail.com>
	<32FCEB5D574.0000035Fjrkrideau@inbox.com>
	<CA+8X3fW4BwSQ2U-EpUmzQzsfL-4sYJZaKFR56qS8i-FMk7HPfA@mail.gmail.com>
	<CAJVfk9kx-hJyeUd5q=Y6KGxY8oYzW3J4sHhXDUv39JJ1F43mtA@mail.gmail.com>
	<CAJVfk9k+Qk9CUqrbTLmAjyVdu5ErZHtd1VErHnABPkHiikDOaQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D68EA9D@mb02.ads.tamu.edu>
	<CAJVfk9m1LCja8DXU9w4CYMGKpGnYHNNseeY7cbLN4QfWUKoMMg@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68EBFF@mb02.ads.tamu.edu>

cat(paste0("[", 1:length(Out), "] #dac     ", Out), sep="\n")

David
From: Mohammad Alimohammadi [mailto:mxalimohamma at ualr.edu]
Sent: Wednesday, May 27, 2015 2:29 PM
To: David L Carlson; r-help at r-project.org
Subject: Re: [R] Problem with comparing multiple data sets

Thanks David it worked !

One more thing. I hope it's not complicated. Is it also possible to display the terms for each row next to it?

for example:

[1] #dac    2
[2] #dac    0
[3] #dac    1
...




On Wed, May 27, 2015 at 2:18 PM, David L Carlson <dcarlson at tamu.edu<mailto:dcarlson at tamu.edu>> wrote:
Save the result of the apply() function:

Out <- apply(df[ ,2:length(df)], 1, mfv)

Then there are several options:

Approximately what you asked for
data.frame(Out)
t(t(Out))

More typing but exactly what you asked for
cat(paste0("[", 1:length(Out), "] ", Out), sep="\n")


David L. Carlson
Department of Anthropology
Texas A&M University


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Mohammad Alimohammadi
Sent: Wednesday, May 27, 2015 1:47 PM
To: John Kane; r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Problem with comparing multiple data sets

Ok. so I read about the ("modeest") package that gives the results that I
am looking for (most repeated value).

I modified the data frame a little and moved the text to the first column.
This is the data frame with all 3 possible classes for each term.

=================================
structure(list(terms = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 4L, 4L,
4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label = c("#dac",
"#mac,#security",
"accountability,anonymous", "data security,encryption,security"
), class = "factor"), class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L,
1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), class.2 = c(2L, 2L,
2L, 2L, 0L, 0L, 2L, 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L,
0L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L),
    class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L, 1L,
    0L, 0L, 0L, 0L, 2L, 1L, 2L)), .Names = c("terms", "class.1",
"class.2", "class.3"), class = "data.frame", row.names = c(NA,
-49L))
=============================================
#Then I applied the function below:

======================
library(modeest)
df<- read.csv(file="short.csv", head= TRUE, sep=",")
apply(df[ ,2:length(df)], 1, mfv)

============================
# It gives the most frequent value for each row which is what I need. The
only problem is that all the values are displayed in one single row.

 [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 2 1 1 1 1 0 0 0 0 2 1 2

It would be much better to show them in separate rows.
For example:

 [1] 0

 [2] 0

 [3] 1
....

Any idea how to do this?



On Wed, May 27, 2015 at 10:11 AM, Mohammad Alimohammadi <
mxalimohamma at ualr.edu<mailto:mxalimohamma at ualr.edu>> wrote:

> Hi Jim,
>
> Thank you for your advice.
>
> I'm not sure how to exactly incorporate this function though. I added a
> portion of the actual data sets. all 3 data sets have the same items (text)
> with different class values. So I need to assign the most repeated class
> (0,1,2) for each text.
>
> For example: if line1 has text "aaa". It may be assigned to class 0 in
> dat1, 2 in dat 2 and 0 in dat3. in this case the "aaa" will be assigned to
> 0 (most repeated value). So it goes for each text.
>
> I really appreciate your help.
>
> =========================================
>
> *dat1*
>
> structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
> 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
> c("#dac",
> "#mac,#security", "accountability,anonymous", "data
> security,encryption,security"
> ), class = "factor")), .Names = c("class.1", "terms"), class =
> "data.frame", row.names = c(NA,
> -49L))
>
>
> *dat2*
>
> structure(list(class.2 = c(2L, 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L,
> 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L), terms = structure(c(1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
> c("#dac",
> "#mac,#security", "accountability,anonymous", "data
> security,encryption,security"
> ), class = "factor")), .Names = c("class.2", "terms"), class =
> "data.frame", row.names = c(NA,
> -49L))
>
>
> *dat3*
>
> structure(list(class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
> 1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
> c("#dac",
> "#mac,#security", "accountability,anonymous", "data
> security,encryption,security"
> ), class = "factor")), .Names = c("class.3", "terms"), class =
> "data.frame", row.names = c(NA,
> -49L))
>
> ===========================================================
>
>
> On Sun, May 24, 2015 at 1:15 AM, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:
>
>> Hi Mohammad,
>> You know, I thought this would be fairly easy, but it wasn't really.
>>
>> df1<-data.frame(Class=c(0,2,1),Comment=c("com1","com2","com3"),
>>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
>> df2<-data.frame(Class=c(0,2,1),Comment=c("com1","com2","com3"),
>>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
>> df3<-data.frame(Class=c(2,1,0),Comment=c("com1","com2","com3"),
>>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
>> dflist<-list(df1,df2,df3)
>> dflist
>>
>> # define a function that extracts the value from one field
>> # selected by a value in another field
>> extract_by_value<-function(x,field1,value1,field2) {
>>  return(x[x[,field1]==value1,field2])
>> }
>>
>> # define another function that equates all of the values
>> sub_value<-function(x,field1,value1,field2,value2) {
>>  x[x[,field1]==value1,field2]<-value2
>>  return(x)
>> }
>>
>> conformity<-function(x,fieldname1,value1,fieldname2) {
>>  # get the most frequent value in fieldname2
>>  # for the desired value in fieldname1
>>  most_freq<-as.numeric(names(which.max(table(unlist(lapply(x,
>>   extract_by_value,fieldname1,value1,fieldname2))))))
>>  # now set all the values to the most frequent
>>  for(i in 1:length(x))
>>   x[[i]]<-sub_value(x[[i]],fieldname1,value1,fieldname2,most_freq)
>>  return(x)
>> }
>>
>> conformity(dflist,"Text","text1","Class")
>>
>> Jim
>>
>> On Sat, May 23, 2015 at 11:23 PM, John Kane <jrkrideau at inbox.com<mailto:jrkrideau at inbox.com>> wrote:
>> > Hi Mohammad
>> >
>> > Welcome to the R-help list.
>> >
>> > There probably is a fairly easy way to what you want but I think we
>> probably need a bit more background information on what you are trying to
>> achieve.  I know I'm not exactly clear on your decision rule(s).
>> >
>> > It would also be very useful to see some actual sample data in useable
>> R format.Have a look at these links
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> and http://adv-r.had.co.nz/Reproducibility.html for some hints on what
>> you might want to include in your question.
>> >
>> > In particular, read up about dput()  in those links and/or see ?dput.
>> This is the generally preferred way to supply sample or illustrative data
>> to the R-help list.  It basically creates a perfect copy of the data as it
>> exists on 'your' machine so that R-help readers see exactly what you do.
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > John Kane
>> > Kingston ON Canada
>> >
>> >
>> >> -----Original Message-----
>> >> From: mxalimohamma at ualr.edu<mailto:mxalimohamma at ualr.edu>
>> >> Sent: Fri, 22 May 2015 12:37:50 -0500
>> >> To: r-help at r-project.org<mailto:r-help at r-project.org>
>> >> Subject: [R] Problem with comparing multiple data sets
>> >>
>> >> Hi everyone,
>> >>
>> >> I am very new to R and I have a task to do. I appreciate any help. I
>> have
>> >> 3
>> >> data sets. Each data set has 4 columns. For example:
>> >>
>> >> Class  Comment   Term   Text
>> >> 0           com1        aac    text1
>> >> 2           com2        aax    text2
>> >> 1           com3        vvx    text3
>> >>
>> >> Now I need t compare the class section between 3 data sets and assign
>> the
>> >> most available class to that text. For example if text1 is assigned to
>> >> class 0 in data set 1&2 but assigned as 2 in data set 3 then it should
>> be
>> >> assigned to class 0. If they are all the same so the class will be the
>> >> same. The ideal thing would be to keep the same format and just update
>> >> the
>> >> class. Is there any easy way to do this?
>> >>
>> >> Thanks a lot.
>> >>
>> >>       [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ____________________________________________________________
>> > FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>> >
>> > ______________________________________________
>> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Mohammad Alimohammadi | Graduate Assistant
> University of Arkansas at Little Rock | College of Science and Mathematics
> (CSAM)
> | mxalimohamma at ualr.edu<mailto:mxalimohamma at ualr.edu> | ualr.edu<http://ualr.edu>
>
> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
>


--
Mohammad Alimohammadi | Graduate Assistant
University of Arkansas at Little Rock | College of Science and Mathematics
(CSAM)
501.346.8007<tel:501.346.8007> | mxalimohamma at ualr.edu<mailto:mxalimohamma at ualr.edu> | ualr.edu<http://ualr.edu>

Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--
Mohammad Alimohammadi | Graduate Assistant
University of Arkansas at Little Rock | College of Science and Mathematics (CSAM)
501.346.8007 | mxalimohamma at ualr.edu<mailto:mxalimohamma at ualr.edu> | ualr.edu<http://ualr.edu/>

Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
[https://mailtrack.io/trace/mail/d062b2c3f56ab0e306570c96c3e24fb7c7b80685.png]

	[[alternative HTML version deleted]]


From kridox at ymail.com  Thu May 28 04:28:45 2015
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 28 May 2015 11:28:45 +0900
Subject: [R] Simulating a time series with a given spectrum
In-Reply-To: <272DD1F0-B876-4125-810E-7B37138AF012@noaa.gov>
References: <272DD1F0-B876-4125-810E-7B37138AF012@noaa.gov>
Message-ID: <CAAcyNCz8+f1692809_-RmH5ZGRSTDwbQeQ8R6WT_HWkNFwGUVQ@mail.gmail.com>

On Thu, May 28, 2015 at 12:54 AM, Roy Mendelssohn - NOAA Federal
<roy.mendelssohn at noaa.gov> wrote:
> Hi All:
>
> Is there a routine in R that allows me to simulate a time series that has a given spectrum?  I have looked at the R Time Series Task view, and have done a web search also, including an article to appear in the handbook of statistics on time series in R, but I don?t see anything offhand.  There are some that will simulate state-space models or for given covariances matrices, but for a variety of reasons I would prefer simulating series with a given spectrum.
>

Not sure it will totally answer your question, but if you are
interested in simulating random time series having the same power
spectrum but random phases as an input time series, you can visit this
website (http://iri.columbia.edu/~vincent/matlab_function_version1/function_matlab.htm).
There is a Matlab function called "ebisuzaki"
(http://iri.columbia.edu/~vincent/matlab_function_version1/ebisuzaki.htm),
which performs this. Of course, this implies you already have a time
series of known spectrum. This function can easily be rewritten in R.


> Thanks for any help.
>
> -Roy
>
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From kengoing.gj at gmail.com  Wed May 27 23:49:03 2015
From: kengoing.gj at gmail.com (Kengo Inagaki)
Date: Wed, 27 May 2015 16:49:03 -0500
Subject: [R] Collinearity? Cannot get logisticRidge{ridge} to work
In-Reply-To: <D34A739F-63C5-48FA-BD1D-56B676416B43@comcast.net>
References: <CAC7aZ4mjgNh1ZtvYw6boDxdCxOLyGAMqaeHdzW1148U_Lk1ZCw@mail.gmail.com>
	<D34A739F-63C5-48FA-BD1D-56B676416B43@comcast.net>
Message-ID: <CAC7aZ4nmOwjKx9dZ9yA553bqG_4yg+uKJxNThZn1-dAZPRyOOA@mail.gmail.com>

Thank you very much for your rapid response. I sincerely appreciate your input.
I am sorry for sending the previous email in HTML format.

with(a,  table(Sex, Therapy1) )   shows the following.
          Therapy1
Sex      no yes
  female  6   7
  male    7   5

with(a,  table(Sex, Outcome) ) and with(a,  table(Therapy1, Outcome) )
elicit the following

        Outcome
Sex      Alive Death
  female     4     9
  male       9     3

        Outcome
Therapy1 Alive Death
     no      4     9
     yes     9     3

As there is no zero cells, it does not seem to be complete separation.
I really appreciate comments.

Kengo Inagaki
Memphis, TN


2015-05-27 13:57 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>
> On May 27, 2015, at 10:10 AM, Kengo Inagaki wrote:
>
>> I am currently working on a health care related project using R. I am
>> learning R while working on data analysis.
>>
>> Below is the part of the data in which i am encountering a problem.
>>
>>
>> Case#    Sex         Therapy1             Therapy2             Outcome
>>
>> 1              male      no
>> no                           Alive
>>
>
> snipped mangled data sent in HTML
>
>>
>>
>> "Outcome" is the response variable and "Sex", "Therapy1", "Therapy2" are
>> predictor variables.
>>
>> All of the predictors are significantly associated with the outcome by
>> univariate analysis.
>>
>> Logistic regression runs fine with most of the predictors when "Sex" and
>> "Therapy1" are not included at the same time (This is a part of table that
>> I cut out from a larger table for ease of
>>
>> presentation and there are more predictors that i tested).
>
> Please examine the data before reaching for ridge regression:
>
> What does this show: ...
>
>     with(a,  table(Sex, Therapy1) )
>
> I predict you will see a zero cell entry. The read about "complete separation" and the so-called "Hauck-Donner effect".
>
> --
> David.
>>
>> However, when "Sex" and "Therapy1" are included in logistic regression
>> model at the same time, standard error inflates and p value gets close to 1.
>>
>> The formula used is,
>>
>>
>>
>>> Model<-glm(Outcome~Sex+Therapy1,data=a,family=binomial) #I assigned a
>> vector "a" to represent above table.
>>
>>
>>
>> After doing some reading, I suspect this might be collinearity, as vif
>> values (using "vif()" function in car package) were sky high (8,875,841 for
>> both "Sex" and "Therapy1").
>>
>> Learning that ridge regression may be a solution, I attempted using
>> logisticRidge {ridge} using the following formula, but i get the
>> accomapnying error message.
>>
>>
>>
>>> logisticRidge(a$Outcome~a$Sex+a$Therapy1)
>>
>>
>>
>> Error in ifelse(y, log(p), log(1 - p)) :
>>
>>  invalid to change the storage mode of a factor
>>
>>
>>
>> At this point I do not have an idea how to solve this and would like to
>> seek help.
>>
>> I really really appreciate your input!!!
>>
>>       [[alternative HTML version deleted]]
>>
>
>
> David Winsemius
> Alameda, CA, USA
>


From kengoing.gj at gmail.com  Thu May 28 00:00:22 2015
From: kengoing.gj at gmail.com (Kengo Inagaki)
Date: Wed, 27 May 2015 17:00:22 -0500
Subject: [R] Collinearity? Cannot get logisticRidge{ridge} to work
In-Reply-To: <11F65DBA-E64E-44C4-8F41-99A69844F2F0@comcast.net>
References: <CAC7aZ4mjgNh1ZtvYw6boDxdCxOLyGAMqaeHdzW1148U_Lk1ZCw@mail.gmail.com>
	<D34A739F-63C5-48FA-BD1D-56B676416B43@comcast.net>
	<CAC7aZ4nmOwjKx9dZ9yA553bqG_4yg+uKJxNThZn1-dAZPRyOOA@mail.gmail.com>
	<11F65DBA-E64E-44C4-8F41-99A69844F2F0@comcast.net>
Message-ID: <CAC7aZ4kH4d6JDNYpjxe8fttAovDiZ3=sBrJisKO7CiUcyFr1Ew@mail.gmail.com>

Here is the result-

> with(a,  table(Sex, Therapy1,  Outcome) )
, , Outcome = Alive

        Therapy1
Sex      no yes
  female  0   4
  male    4   5

, , Outcome = Death

        Therapy1
Sex      no yes
  female  6   3
  male    3   0


2015-05-27 16:57 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>
> On May 27, 2015, at 2:49 PM, Kengo Inagaki wrote:
>
>> Thank you very much for your rapid response. I sincerely appreciate your input.
>> I am sorry for sending the previous email in HTML format.
>>
>> with(a,  table(Sex, Therapy1) )   shows the following.
>>          Therapy1
>> Sex      no yes
>>  female  6   7
>>  male    7   5
>>
>>  and with(a,  table(Therapy1, Outcome) )
>> elicit the following
>>
>>        Outcome
>> Sex      Alive Death
>>  female     4     9
>>  male       9     3
>>
>>        Outcome
>> Therapy1 Alive Death
>>     no      4     9
>>     yes     9     3
>
> Then what about:
>
> with(a,  table(Sex, Therapy1,  Outcome) )
>
> --
> David
>
>
>>
>> As there is no zero cells, it does not seem to be complete separation.
>> I really appreciate comments.
>>
>> Kengo Inagaki
>> Memphis, TN
>>
>>
>> 2015-05-27 13:57 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>>>
>>> On May 27, 2015, at 10:10 AM, Kengo Inagaki wrote:
>>>
>>>> I am currently working on a health care related project using R. I am
>>>> learning R while working on data analysis.
>>>>
>>>> Below is the part of the data in which i am encountering a problem.
>>>>
>>>>
>>>> Case#    Sex         Therapy1             Therapy2             Outcome
>>>>
>>>> 1              male      no
>>>> no                           Alive
>>>>
>>>
>>> snipped mangled data sent in HTML
>>>
>>>>
>>>>
>>>> "Outcome" is the response variable and "Sex", "Therapy1", "Therapy2" are
>>>> predictor variables.
>>>>
>>>> All of the predictors are significantly associated with the outcome by
>>>> univariate analysis.
>>>>
>>>> Logistic regression runs fine with most of the predictors when "Sex" and
>>>> "Therapy1" are not included at the same time (This is a part of table that
>>>> I cut out from a larger table for ease of
>>>>
>>>> presentation and there are more predictors that i tested).
>>>
>>> Please examine the data before reaching for ridge regression:
>>>
>>> What does this show: ...
>>>
>>>    with(a,  table(Sex, Therapy1) )
>>>
>>> I predict you will see a zero cell entry. The read about "complete separation" and the so-called "Hauck-Donner effect".
>>>
>>> --
>>> David.
>>>>
>>>> However, when "Sex" and "Therapy1" are included in logistic regression
>>>> model at the same time, standard error inflates and p value gets close to 1.
>>>>
>>>> The formula used is,
>>>>
>>>>
>>>>
>>>>> Model<-glm(Outcome~Sex+Therapy1,data=a,family=binomial) #I assigned a
>>>> vector "a" to represent above table.
>>>>
>>>>
>>>>
>>>> After doing some reading, I suspect this might be collinearity, as vif
>>>> values (using "vif()" function in car package) were sky high (8,875,841 for
>>>> both "Sex" and "Therapy1").
>>>>
>>>> Learning that ridge regression may be a solution, I attempted using
>>>> logisticRidge {ridge} using the following formula, but i get the
>>>> accomapnying error message.
>>>>
>>>>
>>>>
>>>>> logisticRidge(a$Outcome~a$Sex+a$Therapy1)
>>>>
>>>>
>>>>
>>>> Error in ifelse(y, log(p), log(1 - p)) :
>>>>
>>>> invalid to change the storage mode of a factor
>>>>
>>>>
>>>>
>>>> At this point I do not have an idea how to solve this and would like to
>>>> seek help.
>>>>
>>>> I really really appreciate your input!!!
>>>>
>>>>      [[alternative HTML version deleted]]
>>>>
>>>
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>
> David Winsemius
> Alameda, CA, USA
>


From kengoing.gj at gmail.com  Thu May 28 00:06:01 2015
From: kengoing.gj at gmail.com (Kengo Inagaki)
Date: Wed, 27 May 2015 17:06:01 -0500
Subject: [R] Collinearity? Cannot get logisticRidge{ridge} to work
In-Reply-To: <DD6A8E58-F75D-4D09-840C-65A4065A7583@comcast.net>
References: <CAC7aZ4mjgNh1ZtvYw6boDxdCxOLyGAMqaeHdzW1148U_Lk1ZCw@mail.gmail.com>
	<D34A739F-63C5-48FA-BD1D-56B676416B43@comcast.net>
	<CAC7aZ4nmOwjKx9dZ9yA553bqG_4yg+uKJxNThZn1-dAZPRyOOA@mail.gmail.com>
	<11F65DBA-E64E-44C4-8F41-99A69844F2F0@comcast.net>
	<CAC7aZ4kH4d6JDNYpjxe8fttAovDiZ3=sBrJisKO7CiUcyFr1Ew@mail.gmail.com>
	<DD6A8E58-F75D-4D09-840C-65A4065A7583@comcast.net>
Message-ID: <CAC7aZ4=fPipAojE7S8hkVgaM6vuz-8eJ3M1w94RL=UT--kMCFg@mail.gmail.com>

I did not understand complete separation quite well..
Thank you very much for clarification.

Kengo

2015-05-27 17:03 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>
> On May 27, 2015, at 3:00 PM, Kengo Inagaki wrote:
>
>> Here is the result-
>>
>>> with(a,  table(Sex, Therapy1,  Outcome) )
>> , , Outcome = Alive
>>
>>        Therapy1
>> Sex      no yes
>>  female  0   4
>>  male    4   5
>>
>> , , Outcome = Death
>>
>>        Therapy1
>> Sex      no yes
>>  female  6   3
>>  male    3   0
>
> So no deaths when Female had no-Therapy1 and no survivors with the opposite for those variables. Complete separation.
>
> --
> David.
>
>>
>>
>> 2015-05-27 16:57 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>>>
>>> On May 27, 2015, at 2:49 PM, Kengo Inagaki wrote:
>>>
>>>> Thank you very much for your rapid response. I sincerely appreciate your input.
>>>> I am sorry for sending the previous email in HTML format.
>>>>
>>>> with(a,  table(Sex, Therapy1) )   shows the following.
>>>>         Therapy1
>>>> Sex      no yes
>>>> female  6   7
>>>> male    7   5
>>>>
>>>> and with(a,  table(Therapy1, Outcome) )
>>>> elicit the following
>>>>
>>>>       Outcome
>>>> Sex      Alive Death
>>>> female     4     9
>>>> male       9     3
>>>>
>>>>       Outcome
>>>> Therapy1 Alive Death
>>>>    no      4     9
>>>>    yes     9     3
>>>
>>> Then what about:
>>>
>>> with(a,  table(Sex, Therapy1,  Outcome) )
>>>
>>> --
>>> David
>>>
>>>
>>>>
>>>> As there is no zero cells, it does not seem to be complete separation.
>>>> I really appreciate comments.
>>>>
>>>> Kengo Inagaki
>>>> Memphis, TN
>>>>
>>>>
>>>> 2015-05-27 13:57 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>>>>>
>>>>> On May 27, 2015, at 10:10 AM, Kengo Inagaki wrote:
>>>>>
>>>>>> I am currently working on a health care related project using R. I am
>>>>>> learning R while working on data analysis.
>>>>>>
>>>>>> Below is the part of the data in which i am encountering a problem.
>>>>>>
>>>>>>
>>>>>> Case#    Sex         Therapy1             Therapy2             Outcome
>>>>>>
>>>>>> 1              male      no
>>>>>> no                           Alive
>>>>>>
>>>>>
>>>>> snipped mangled data sent in HTML
>>>>>
>>>>>>
>>>>>>
>>>>>> "Outcome" is the response variable and "Sex", "Therapy1", "Therapy2" are
>>>>>> predictor variables.
>>>>>>
>>>>>> All of the predictors are significantly associated with the outcome by
>>>>>> univariate analysis.
>>>>>>
>>>>>> Logistic regression runs fine with most of the predictors when "Sex" and
>>>>>> "Therapy1" are not included at the same time (This is a part of table that
>>>>>> I cut out from a larger table for ease of
>>>>>>
>>>>>> presentation and there are more predictors that i tested).
>>>>>
>>>>> Please examine the data before reaching for ridge regression:
>>>>>
>>>>> What does this show: ...
>>>>>
>>>>>   with(a,  table(Sex, Therapy1) )
>>>>>
>>>>> I predict you will see a zero cell entry. The read about "complete separation" and the so-called "Hauck-Donner effect".
>>>>>
>>>>> --
>>>>> David.
>>>>>>
>>>>>> However, when "Sex" and "Therapy1" are included in logistic regression
>>>>>> model at the same time, standard error inflates and p value gets close to 1.
>>>>>>
>>>>>> The formula used is,
>>>>>>
>>>>>>
>>>>>>
>>>>>>> Model<-glm(Outcome~Sex+Therapy1,data=a,family=binomial) #I assigned a
>>>>>> vector "a" to represent above table.
>>>>>>
>>>>>>
>>>>>>
>>>>>> After doing some reading, I suspect this might be collinearity, as vif
>>>>>> values (using "vif()" function in car package) were sky high (8,875,841 for
>>>>>> both "Sex" and "Therapy1").
>>>>>>
>>>>>> Learning that ridge regression may be a solution, I attempted using
>>>>>> logisticRidge {ridge} using the following formula, but i get the
>>>>>> accomapnying error message.
>>>>>>
>>>>>>
>>>>>>
>>>>>>> logisticRidge(a$Outcome~a$Sex+a$Therapy1)
>>>>>>
>>>>>>
>>>>>>
>>>>>> Error in ifelse(y, log(p), log(1 - p)) :
>>>>>>
>>>>>> invalid to change the storage mode of a factor
>>>>>>
>>>>>>
>>>>>>
>>>>>> At this point I do not have an idea how to solve this and would like to
>>>>>> seek help.
>>>>>>
>>>>>> I really really appreciate your input!!!
>>>>>>
>>>>>>     [[alternative HTML version deleted]]
>>>>>>
>>>>>
>>>>>
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>>
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>
> David Winsemius
> Alameda, CA, USA
>


From oussa.belm at hotmail.com  Thu May 28 01:18:52 2015
From: oussa.belm at hotmail.com (oussama belmejdoub)
Date: Wed, 27 May 2015 23:18:52 +0000
Subject: [R] Really stuck with the nls function!! It's Urgent !!
In-Reply-To: <DUB109-W3681A8069B5CE24D6E75A79CCB0@phx.gbl>
References: <DUB109-W3681A8069B5CE24D6E75A79CCB0@phx.gbl>
Message-ID: <DUB109-W775FD92671EF8A8904968B9CCB0@phx.gbl>

Greetings,

I'm trying to use the nls function in my statistics project but I'm really finding lot of difficulties.

I have a function called apinene_modele_prediction that calculates the estimations:
library(expm); #exp of a matrixapinene_modele_prediction <- function(t,theta) {x0=c(100,0,0,0,0);A=matrix(c(-(theta[1]+theta[2]),theta[1],theta[2],0,0,0,0,0,0,0,0,0,-(theta[3]+theta[4]),theta[3],theta[4],0,0,0,0,0,0,0,theta[5],0,-theta[5]),5,5);X=x0;for (i in t[2:length(t)]){X=c(X,x0%*%expm(A*i));}return(X);}
 
My "t" vector is given by: 
t=seq(0,100,by=2)
And the real observations "y" ara given to us  in a txt file called "data.txt" that I have joined to this message.

So when I try to fit the "theta" in my model starting with: theta=c(0.2,0.2,0.2,0.2,0.2) 
And doing:
theta_appr <-nls(y~apinene_modele_prediction(t,theta),start=list(theta=c(0.2,0.2,0.2,0.2,0.2)))
I always get the ERROR : singular gradient matrix at initial parameter estimates

And, when I try: nls(y~apinene_modele_prediction(t,c(theta,theta,theta,theta,theta)),start=list(theta=0.2))
I get the result:Nonlinear regression model  model: y ~ apinene_modele_prediction(t, c(theta,theta,theta,theta,theta))data: parent.frame()theta 0.04403residual sum-of-squares: 219002


But I need to have the elements of the theta to be different and not equal.
Thanks in advance for your help. 		 	   		  
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: data.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150527/527a3c21/attachment.txt>

From bluehonour at yahoo.com  Thu May 28 01:34:01 2015
From: bluehonour at yahoo.com (blue honour)
Date: Wed, 27 May 2015 16:34:01 -0700
Subject: [R] Using lapply when there are dependencies
Message-ID: <1432769641.61204.YahooMailBasic@web121703.mail.ne1.yahoo.com>

Hi all,

Let's say I have a vector:

vv<-c(1,2,3)


And suppose I have a function f(a,b), which is a function of 2 scalar inputs. I would like to evaluate this function separately for each element of the vv vector while the second input to f( ) will be the previous output from f( ). So, the valuation of f() has a dependency on the previous f( ) valuation (recursive). This type of calculation is easy to set up with a for loop but that will run slow. How can I achieve this with apply family of functions please?

I have the same question for the case when vv is a data.table instead of a vector.

Thank you for any help.


From alamesa2012 at gmail.com  Thu May 28 04:56:10 2015
From: alamesa2012 at gmail.com (Gen)
Date: Wed, 27 May 2015 22:56:10 -0400
Subject: [R] Problem with particular file in XML package?
Message-ID: <CALRDpwUedO3x62qRcvn9sPXFmUv6mWfr6LpqL4QkD=GpxAh4NA@mail.gmail.com>

I have been attempting to install the R devtools package at work.  The
version of R is 3.1.2 (Pumpkin Helmet).  However, the installation of
devtools fails because devtools depends on rversions which in turn depends
upon the XML package (XML_3.98-1.1.tar.gz), and the XML package is not
importing correctly for us.

One of our system administrators tried scanning through the files in the
XML package, and he said that the particular file:
/src/contrib/XML_3.98-1.1.tar.gz/XML/inst/exampleData/dtd.zip looks
corrupted.  The actual error message he received was: "Archive parsing
failed!  (Data is corrupted)."  For the record, I tried downloading an
older version of the XML package (XML_3.95-0.1.tar.gz) but that was also
without success -- this time there was a separate error message about not
being able to locate xml2-config.  (Perhaps XML_3.95-0.1.tar.gz is just not
compatible with R version 3.1.2?)

I tried browsing over to the "CRAN checks" link for the XML package and
noticed several red warning messages under the "Status" column -- not sure
if that is typical?  Has anyone else had trouble with the XML package
lately and if so, how did you resolve it?  Would it be possible to remove
the potentially corrupted file and then re-upload the package source
XML_3.98-1.1.tar.gz to the CRAN webpage?  Thanks for your help/suggestions!

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu May 28 08:02:11 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 27 May 2015 23:02:11 -0700
Subject: [R] Using lapply when there are dependencies
In-Reply-To: <1432769641.61204.YahooMailBasic@web121703.mail.ne1.yahoo.com>
References: <1432769641.61204.YahooMailBasic@web121703.mail.ne1.yahoo.com>
Message-ID: <A616A46D-FFA5-4CF2-AE9F-9F258550962A@comcast.net>


On May 27, 2015, at 4:34 PM, blue honour via R-help wrote:

> Hi all,
> 
> Let's say I have a vector:
> 
> vv<-c(1,2,3)
> 
> 
> And suppose I have a function f(a,b), which is a function of 2 scalar inputs. I would like to evaluate this function separately for each element of the vv vector while the second input to f( ) will be the previous output from f( ). So, the valuation of f() has a dependency on the previous f( ) valuation (recursive). This type of calculation is easy to set up with a for loop but that will run slow. How can I achieve this with apply family of functions please?

The speed of loops is determined by the speed of their inner functions. The Reduce() function does what you request but for the application described it will need an init value.

Reduce(f, vv, init=<something>)

> I have the same question for the case when vv is a data.table instead of a vector.

I could be wrong but that doesn't sound like an effective use of the data.table facilities.

-- 

David Winsemius
Alameda, CA, USA


From petr.pikal at precheza.cz  Thu May 28 06:48:52 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 28 May 2015 04:48:52 +0000
Subject: [R] Using lapply when there are dependencies
In-Reply-To: <1432769641.61204.YahooMailBasic@web121703.mail.ne1.yahoo.com>
References: <1432769641.61204.YahooMailBasic@web121703.mail.ne1.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2DB0A@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of blue
> honour via R-help
> Sent: Thursday, May 28, 2015 1:34 AM
> To: r-help at r-project.org
> Subject: [R] Using lapply when there are dependencies
>
> Hi all,
>
> Let's say I have a vector:
>
> vv<-c(1,2,3)
>
>
> And suppose I have a function f(a,b), which is a function of 2 scalar
> inputs. I would like to evaluate this function separately for each
> element of the vv vector while the second input to f( ) will be the
> previous output from f( ). So, the valuation of f() has a dependency on
> the previous f( ) valuation (recursive). This type of calculation is
> easy to set up with a for loop but that will run slow. How can I

*apply is a hidden loop so there shall not be substantial speed improvement. Usually slow for loop means there is some coding issue which is unnecessary and shall be changed to vectorized. But without actual code it is hard to say.

Cheers
Petr


> achieve this with apply family of functions please?
>
> I have the same question for the case when vv is a data.table instead
> of a vector.
>
> Thank you for any help.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ripley at stats.ox.ac.uk  Thu May 28 08:38:02 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 28 May 2015 07:38:02 +0100
Subject: [R] Problem with particular file in XML package?
In-Reply-To: <CALRDpwUedO3x62qRcvn9sPXFmUv6mWfr6LpqL4QkD=GpxAh4NA@mail.gmail.com>
References: <CALRDpwUedO3x62qRcvn9sPXFmUv6mWfr6LpqL4QkD=GpxAh4NA@mail.gmail.com>
Message-ID: <5566B7CA.90804@stats.ox.ac.uk>

This really should have been sent to the package maintainer.  But that 
the zip file is corrupt has been reported several times, and does not 
block installation for anyone else, so your (plural) diagnosis is wrong.

On 28/05/2015 03:56, Gen wrote:
> I have been attempting to install the R devtools package at work.  The
> version of R is 3.1.2 (Pumpkin Helmet).  However, the installation of
> devtools fails because devtools depends on rversions which in turn depends
> upon the XML package (XML_3.98-1.1.tar.gz), and the XML package is not
> importing correctly for us.
>
> One of our system administrators tried scanning through the files in the
> XML package, and he said that the particular file:
> /src/contrib/XML_3.98-1.1.tar.gz/XML/inst/exampleData/dtd.zip looks
> corrupted.  The actual error message he received was: "Archive parsing
> failed!  (Data is corrupted)."  For the record, I tried downloading an
> older version of the XML package (XML_3.95-0.1.tar.gz) but that was also
> without success -- this time there was a separate error message about not
> being able to locate xml2-config.  (Perhaps XML_3.95-0.1.tar.gz is just not
> compatible with R version 3.1.2?)
>
> I tried browsing over to the "CRAN checks" link for the XML package and
> noticed several red warning messages under the "Status" column -- not sure
> if that is typical?  Has anyone else had trouble with the XML package
> lately and if so, how did you resolve it?  Would it be possible to remove
> the potentially corrupted file and then re-upload the package source
> XML_3.98-1.1.tar.gz to the CRAN webpage?  Thanks for your help/suggestions!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

PLEASE do, including what it says about HTML mail, 'at a minimum' 
information required and upgrading before posting: R 3.1.2 is already 2 
versions obsolete.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From jdnewmil at dcn.davis.CA.us  Thu May 28 08:44:07 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 27 May 2015 23:44:07 -0700
Subject: [R] Using lapply when there are dependencies
In-Reply-To: <1432769641.61204.YahooMailBasic@web121703.mail.ne1.yahoo.com>
References: <1432769641.61204.YahooMailBasic@web121703.mail.ne1.yahoo.com>
Message-ID: <3BD313F8-22F9-4B68-8776-1BF78F9CDAC0@dcn.davis.CA.us>

For loops are not slow. Inefficient memory management in for loops is slow.  Feel free to preallocate your output vectors and write for loops to your heart's content. If you really want speed you can write this in C++ using Rcpp [1]. If your f() is a standard digital filter algorithm this has already been done for you (see ?filter).

[1] https://stat.ethz.ch/pipermail/r-help//2014-December/424027.html
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 27, 2015 4:34:01 PM PDT, blue honour via R-help <r-help at r-project.org> wrote:
>Hi all,
>
>Let's say I have a vector:
>
>vv<-c(1,2,3)
>
>
>And suppose I have a function f(a,b), which is a function of 2 scalar
>inputs. I would like to evaluate this function separately for each
>element of the vv vector while the second input to f( ) will be the
>previous output from f( ). So, the valuation of f() has a dependency on
>the previous f( ) valuation (recursive). This type of calculation is
>easy to set up with a for loop but that will run slow. How can I
>achieve this with apply family of functions please?
>
>I have the same question for the case when vv is a data.table instead
>of a vector.
>
>Thank you for any help.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lenz99 at gmail.com  Thu May 28 09:50:31 2015
From: lenz99 at gmail.com (Matthias Kuhn)
Date: Thu, 28 May 2015 09:50:31 +0200
Subject: [R] ..lsmeans and coxme..
Message-ID: <CAFOoap+cz++MEp41pejN8sqUo6yokN0Mnaseit5pbos00xH9UA@mail.gmail.com>

Dear list-eners,

I run into the following problem when I want to get contrasts from a coxme
model using the lsmeans package: A call to lsmeans on the coxme model
throws the following error:

Error in if (adjustSigma && object$method == "ML") V = V *
object$dims$N/(object$dims$N -  :
  missing value where TRUE/FALSE needed


I give an example:


library(coxme)
library(lsmeans)

fm <- coxme(Surv(y, uncens) ~ trt + (trt | center) + strata(center),
data=eortc)
summary(fm)

lsmeans(fm, ~ trt)



traceback points to the internal function lsmeans:::lsm.basis.lme()

Any ideas?

Thanks in advance.

-m

	[[alternative HTML version deleted]]


From Keith.Jewell at campdenbri.co.uk  Thu May 28 10:25:11 2015
From: Keith.Jewell at campdenbri.co.uk (Keith Jewell)
Date: Thu, 28 May 2015 09:25:11 +0100
Subject: [R] Problem with particular file in XML package?
In-Reply-To: <5566B7CA.90804@stats.ox.ac.uk>
References: <CALRDpwUedO3x62qRcvn9sPXFmUv6mWfr6LpqL4QkD=GpxAh4NA@mail.gmail.com>
	<5566B7CA.90804@stats.ox.ac.uk>
Message-ID: <mk6jd8$d1i$1@ger.gmane.org>

The OP asked "Has anyone else had trouble with the XML package lately 
and if so, how did you resolve it?"

For what it's worth...

I failed to install XML using install() with the defaults; I can't 
remember the exact error message, something about access denied.

Downloading XML_3.98-1.1.zip with Internet Explorer 
<http://cran.r-project.org/bin/windows/contrib/3.2/XML_3.98-1.1.zip> 
gave a more informative error:
========================
Threat Source: http://cran.r-project.or...trib/3.2/XML_3.98-1.1.zip

The file requested could not be scanned by Sophos Anti-Virus. This means 
it could be encrypted or may contain errors that prevent full scanning. 
As a result, the file was blocked from downloading.
=====================
... so my access was blocked by our systems anti-virus.

Our IT people bypassed the anti-virus to download the zip from which I 
successfully installed.

I note that in the library as installed there is a file
    ...\XML\exampleData\dtd.zip
Double-clicking in Windows Explorer gives an error:
=========
Windows cannot open the folder. The Compressed (zipped) Folder ... is 
invalid.
=========

I speculate that Sophos Anti-Virus could not scan dtd.zip because it 
tried to open it as a zipped folder and failed. I don't know if it 
really is a zipped folder or if that's just its name :-O

This 2013 thread seems relevant 
https://stat.ethz.ch/pipermail/r-sig-mac/2013-November/010494.html


On 28/05/2015 07:38, Prof Brian Ripley wrote:
> This really should have been sent to the package maintainer.  But that
> the zip file is corrupt has been reported several times, and does not
> block installation for anyone else, so your (plural) diagnosis is wrong.
>
> On 28/05/2015 03:56, Gen wrote:
>> I have been attempting to install the R devtools package at work.  The
>> version of R is 3.1.2 (Pumpkin Helmet).  However, the installation of
>> devtools fails because devtools depends on rversions which in turn
>> depends
>> upon the XML package (XML_3.98-1.1.tar.gz), and the XML package is not
>> importing correctly for us.
>>
>> One of our system administrators tried scanning through the files in the
>> XML package, and he said that the particular file:
>> /src/contrib/XML_3.98-1.1.tar.gz/XML/inst/exampleData/dtd.zip looks
>> corrupted.  The actual error message he received was: "Archive parsing
>> failed!  (Data is corrupted)."  For the record, I tried downloading an
>> older version of the XML package (XML_3.95-0.1.tar.gz) but that was also
>> without success -- this time there was a separate error message about not
>> being able to locate xml2-config.  (Perhaps XML_3.95-0.1.tar.gz is
>> just not
>> compatible with R version 3.1.2?)
>>
>> I tried browsing over to the "CRAN checks" link for the XML package and
>> noticed several red warning messages under the "Status" column -- not
>> sure
>> if that is typical?  Has anyone else had trouble with the XML package
>> lately and if so, how did you resolve it?  Would it be possible to remove
>> the potentially corrupted file and then re-upload the package source
>> XML_3.98-1.1.tar.gz to the CRAN webpage?  Thanks for your
>> help/suggestions!
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>
> PLEASE do, including what it says about HTML mail, 'at a minimum'
> information required and upgrading before posting: R 3.1.2 is already 2
> versions obsolete.
>


From Rainer at krugs.de  Thu May 28 10:52:01 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 28 May 2015 10:52:01 +0200
Subject: [R] Reset running R session to --vanilla state?
Message-ID: <m2h9qxxexa.fsf@krugs.de>

Hi

Is there a way of resetting R to the --vanilla state *without closing
and restarting* R, i.e. all packages un-loaded (except the ones loaded
automatically in --vanilla), all options reset, dev() closed,
environments detached and deleted, ...?

,----
| > Version
|                _                           
| platform       x86_64-apple-darwin14.3.0   
| arch           x86_64                      
| os             darwin14.3.0                
| system         x86_64, darwin14.3.0        
| status                                     
| major          3                           
| minor          2.0                         
| year           2015                        
| month          04                          
| day            16                          
| svn rev        68180                       
| language       R                           
| version.string R version 3.2.0 (2015-04-16)
| nickname       Full of Ingredients         
`----

Thanks,

Rainer

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150528/82b2eef7/attachment.bin>

From pdalgd at gmail.com  Thu May 28 11:26:52 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 28 May 2015 11:26:52 +0200
Subject: [R] Collinearity? Cannot get logisticRidge{ridge} to work
In-Reply-To: <CAC7aZ4=fPipAojE7S8hkVgaM6vuz-8eJ3M1w94RL=UT--kMCFg@mail.gmail.com>
References: <CAC7aZ4mjgNh1ZtvYw6boDxdCxOLyGAMqaeHdzW1148U_Lk1ZCw@mail.gmail.com>
	<D34A739F-63C5-48FA-BD1D-56B676416B43@comcast.net>
	<CAC7aZ4nmOwjKx9dZ9yA553bqG_4yg+uKJxNThZn1-dAZPRyOOA@mail.gmail.com>
	<11F65DBA-E64E-44C4-8F41-99A69844F2F0@comcast.net>
	<CAC7aZ4kH4d6JDNYpjxe8fttAovDiZ3=sBrJisKO7CiUcyFr1Ew@mail.gmail.com>
	<DD6A8E58-F75D-4D09-840C-65A4065A7583@comcast.net>
	<CAC7aZ4=fPipAojE7S8hkVgaM6vuz-8eJ3M1w94RL=UT--kMCFg@mail.gmail.com>
Message-ID: <5A636270-C450-469F-B7FD-A678CD6AB5FF@gmail.com>


On 28 May 2015, at 00:06 , Kengo Inagaki <kengoing.gj at gmail.com> wrote:

> I did not understand complete separation quite well..
> Thank you very much for clarification.
> 
> Kengo
> 
> 2015-05-27 17:03 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>> 
>> On May 27, 2015, at 3:00 PM, Kengo Inagaki wrote:
>> 
>>> Here is the result-
>>> 
>>>> with(a,  table(Sex, Therapy1,  Outcome) )
>>> , , Outcome = Alive
>>> 
>>>       Therapy1
>>> Sex      no yes
>>> female  0   4
>>> male    4   5
>>> 
>>> , , Outcome = Death
>>> 
>>>       Therapy1
>>> Sex      no yes
>>> female  6   3
>>> male    3   0
>> 
>> So no deaths when Female had no-Therapy1 and no survivors with the opposite for those variables. Complete separation.


Actually not quite complete separation, but just as bad.  If you look at the linear combination Sex + Therapy, you get

0 (female, no therapy)
1 (female, therapy OR male, no therapy
2 (male, therapy)


0: 6 dead, 0 survive
1: 6 dead, 8 survive
2: 0 dead, 5 survive

and any logistic curve through (1, log(6/8)) fits the middle point and the other two will be fitted better and better as the curve gets steeper, so the fit diverges. 

That's a general pattern: you can have complete separation except at one point and still get divergence. Similarly (and really just the same), if you have multiple regression with k parameters and there's a k-1 dimensional hyperplane in predictor space with all responses 0  on one side and 1 on the other, but possibly both 0 and 1 _on_ the hyperplane. Google tells me that this is called quasicomplete separation.

-pd

>> 
>> --
>> David.
>> 
>>> 
>>> 
>>> 2015-05-27 16:57 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>>>> 
>>>> On May 27, 2015, at 2:49 PM, Kengo Inagaki wrote:
>>>> 
>>>>> Thank you very much for your rapid response. I sincerely appreciate your input.
>>>>> I am sorry for sending the previous email in HTML format.
>>>>> 
>>>>> with(a,  table(Sex, Therapy1) )   shows the following.
>>>>>        Therapy1
>>>>> Sex      no yes
>>>>> female  6   7
>>>>> male    7   5
>>>>> 
>>>>> and with(a,  table(Therapy1, Outcome) )
>>>>> elicit the following
>>>>> 
>>>>>      Outcome
>>>>> Sex      Alive Death
>>>>> female     4     9
>>>>> male       9     3
>>>>> 
>>>>>      Outcome
>>>>> Therapy1 Alive Death
>>>>>   no      4     9
>>>>>   yes     9     3
>>>> 
>>>> Then what about:
>>>> 
>>>> with(a,  table(Sex, Therapy1,  Outcome) )
>>>> 
>>>> --
>>>> David
>>>> 
>>>> 
>>>>> 
>>>>> As there is no zero cells, it does not seem to be complete separation.
>>>>> I really appreciate comments.
>>>>> 
>>>>> Kengo Inagaki
>>>>> Memphis, TN
>>>>> 
>>>>> 
>>>>> 2015-05-27 13:57 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>>>>>> 
>>>>>> On May 27, 2015, at 10:10 AM, Kengo Inagaki wrote:
>>>>>> 
>>>>>>> I am currently working on a health care related project using R. I am
>>>>>>> learning R while working on data analysis.
>>>>>>> 
>>>>>>> Below is the part of the data in which i am encountering a problem.
>>>>>>> 
>>>>>>> 
>>>>>>> Case#    Sex         Therapy1             Therapy2             Outcome
>>>>>>> 
>>>>>>> 1              male      no
>>>>>>> no                           Alive
>>>>>>> 
>>>>>> 
>>>>>> snipped mangled data sent in HTML
>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> "Outcome" is the response variable and "Sex", "Therapy1", "Therapy2" are
>>>>>>> predictor variables.
>>>>>>> 
>>>>>>> All of the predictors are significantly associated with the outcome by
>>>>>>> univariate analysis.
>>>>>>> 
>>>>>>> Logistic regression runs fine with most of the predictors when "Sex" and
>>>>>>> "Therapy1" are not included at the same time (This is a part of table that
>>>>>>> I cut out from a larger table for ease of
>>>>>>> 
>>>>>>> presentation and there are more predictors that i tested).
>>>>>> 
>>>>>> Please examine the data before reaching for ridge regression:
>>>>>> 
>>>>>> What does this show: ...
>>>>>> 
>>>>>>  with(a,  table(Sex, Therapy1) )
>>>>>> 
>>>>>> I predict you will see a zero cell entry. The read about "complete separation" and the so-called "Hauck-Donner effect".
>>>>>> 
>>>>>> --
>>>>>> David.
>>>>>>> 
>>>>>>> However, when "Sex" and "Therapy1" are included in logistic regression
>>>>>>> model at the same time, standard error inflates and p value gets close to 1.
>>>>>>> 
>>>>>>> The formula used is,
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>>> Model<-glm(Outcome~Sex+Therapy1,data=a,family=binomial) #I assigned a
>>>>>>> vector "a" to represent above table.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> After doing some reading, I suspect this might be collinearity, as vif
>>>>>>> values (using "vif()" function in car package) were sky high (8,875,841 for
>>>>>>> both "Sex" and "Therapy1").
>>>>>>> 
>>>>>>> Learning that ridge regression may be a solution, I attempted using
>>>>>>> logisticRidge {ridge} using the following formula, but i get the
>>>>>>> accomapnying error message.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>>> logisticRidge(a$Outcome~a$Sex+a$Therapy1)
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> Error in ifelse(y, log(p), log(1 - p)) :
>>>>>>> 
>>>>>>> invalid to change the storage mode of a factor
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> At this point I do not have an idea how to solve this and would like to
>>>>>>> seek help.
>>>>>>> 
>>>>>>> I really really appreciate your input!!!
>>>>>>> 
>>>>>>>    [[alternative HTML version deleted]]
>>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> David Winsemius
>>>>>> Alameda, CA, USA
>>>>>> 
>>>> 
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>> 
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From r.turner at auckland.ac.nz  Thu May 28 11:28:15 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 28 May 2015 21:28:15 +1200
Subject: [R] R CMD methods and ggplot2 advice
In-Reply-To: <CAJuCY5ybP4mnC7sUtnwL_=9+XCeGAMAoO26ZiqRB=Sgo-aZnvQ@mail.gmail.com>
References: <9057ac48-7cff-44b9-88a4-0c2fb24683b3@me.com>
	<CAJuCY5ybP4mnC7sUtnwL_=9+XCeGAMAoO26ZiqRB=Sgo-aZnvQ@mail.gmail.com>
Message-ID: <5566DFAF.70409@auckland.ac.nz>

On 27/05/15 23:37, Thierry Onkelinx wrote:
> Dear Glenn,
>
> Suppose this function
>
> test <- function(df){
>    ggplot(df, aes(x = gp, y = y)) + geom_point()
> }
>
> Then R CMD check will consider gp and y as global variables since they are
> undefined. Because R CMD check cannot detect that gp and y will be
> extracted from df by ggplot2.
>
> Possible workarounds
>
> # now gp and y are defined within the function. ggplot2 still looks for gp
> and y in df.
> test <- function(df){
>    gp <- NULL
>    y <- NULL
>    ggplot(df, aes(x = gp, y = y)) + geom_point()
> }
>
> # now "gp" and "y" are strings and hence defined
> test <- function(df){
>    ggplot(df, aes_string(x = "gp", y = "y")) + geom_point()
> }

<SNIP>

Why not use utils::globalVariables?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From murdoch.duncan at gmail.com  Thu May 28 12:41:40 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 28 May 2015 06:41:40 -0400
Subject: [R] Reset running R session to --vanilla state?
In-Reply-To: <m2h9qxxexa.fsf@krugs.de>
References: <m2h9qxxexa.fsf@krugs.de>
Message-ID: <5566F0E4.2050300@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

On 28/05/2015 4:52 AM, Rainer M Krug wrote:
> Hi
> 
> Is there a way of resetting R to the --vanilla state *without
> closing and restarting* R, i.e. all packages un-loaded (except the
> ones loaded automatically in --vanilla), all options reset, dev()
> closed, environments detached and deleted, ...?
> 

Not with the standard front-ends.  I would guess you could write your
own front end that did that, but it would probably be easier to just
run R in a separate process, and close and restart it.  I think that's
what RStudio does.

Duncan Murdoch

-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: GPGTools - https://gpgtools.org

iQEcBAEBCgAGBQJVZvDjAAoJEHE2Kz23YMZyb90IAJnJSNKSCLL4ANaUOMkYcwcV
5Lxoxqxq9lzn+wTtPgTlT9TqbxlO8sxRf/DJB5ewF3+KJPQ61Ln9SGkwgxKFtK5Q
U5Ap1ZCox5RRIVZPDi0JAjpU+2T0MhdsbjQnCfpz6zHflFRe1pRXi+X5DWs7fX+L
a2K3TRxtlNBgOZUpW2n931TxvkFWL0FaFIGKoMnEFabVlEbkYoBHAI4dAJEVlkDl
SWPCZYvi5UlJY5dpgbOGhLrkM3lWcHqwgfbe80h8i8eIfo13pQTRz4P+PjvITcSM
xJCv55mifueiznpNjY7OW/HMOpb9T4a1PQZmTcRswI3uZVUB1YwBBtVcy74VetQ=
=ehx9
-----END PGP SIGNATURE-----


From Rainer at krugs.de  Thu May 28 13:28:51 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 28 May 2015 13:28:51 +0200
Subject: [R] Reset running R session to --vanilla state?
In-Reply-To: <5566F0E4.2050300@gmail.com> (Duncan Murdoch's message of "Thu,
	28 May 2015 06:41:40 -0400")
References: <m2h9qxxexa.fsf@krugs.de> <5566F0E4.2050300@gmail.com>
Message-ID: <m21ti1x7nw.fsf@krugs.de>

Duncan Murdoch <murdoch.duncan at gmail.com> writes:

> On 28/05/2015 4:52 AM, Rainer M Krug wrote:
>> Hi
>>
>> Is there a way of resetting R to the --vanilla state *without
>> closing and restarting* R, i.e. all packages un-loaded (except the
>> ones loaded automatically in --vanilla), all options reset, dev()
>> closed, environments detached and deleted, ...?
>>
>
> Not with the standard front-ends.  I would guess you could write your
> own front end that did that, but it would probably be easier to just
> run R in a separate process, and close and restart it.  I think that's
> what RStudio does.

That's what I guessed. I wanted to do this in emacs / ess but then I
have to think about a restart solution in ESS, which should be possible.

Thanks,

Rainer


>
> Duncan Murdoch
>

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150528/b56db27e/attachment.bin>

From thierry.onkelinx at inbo.be  Thu May 28 14:08:49 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 28 May 2015 14:08:49 +0200
Subject: [R] R CMD methods and ggplot2 advice
In-Reply-To: <5566DFAF.70409@auckland.ac.nz>
References: <9057ac48-7cff-44b9-88a4-0c2fb24683b3@me.com>
	<CAJuCY5ybP4mnC7sUtnwL_=9+XCeGAMAoO26ZiqRB=Sgo-aZnvQ@mail.gmail.com>
	<5566DFAF.70409@auckland.ac.nz>
Message-ID: <CAJuCY5yydEjMK6575vyL3G93ARiQiOhM6+dxNtjQScPdmPPBTA@mail.gmail.com>

Dear Rolf,

utils::globalVariables() seems to work package wide. I prefer to ignore
these variable only within the function in which I explicitly define them.
If I use one of those variables in another function in which I haven't
declared them as global, then I want R CMD check to give me a NOTE.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-28 11:28 GMT+02:00 Rolf Turner <r.turner at auckland.ac.nz>:

> On 27/05/15 23:37, Thierry Onkelinx wrote:
>
>> Dear Glenn,
>>
>> Suppose this function
>>
>> test <- function(df){
>>    ggplot(df, aes(x = gp, y = y)) + geom_point()
>> }
>>
>> Then R CMD check will consider gp and y as global variables since they are
>> undefined. Because R CMD check cannot detect that gp and y will be
>> extracted from df by ggplot2.
>>
>> Possible workarounds
>>
>> # now gp and y are defined within the function. ggplot2 still looks for gp
>> and y in df.
>> test <- function(df){
>>    gp <- NULL
>>    y <- NULL
>>    ggplot(df, aes(x = gp, y = y)) + geom_point()
>> }
>>
>> # now "gp" and "y" are strings and hence defined
>> test <- function(df){
>>    ggplot(df, aes_string(x = "gp", y = "y")) + geom_point()
>> }
>>
>
> <SNIP>
>
> Why not use utils::globalVariables?
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Thu May 28 14:12:46 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 28 May 2015 07:12:46 -0500
Subject: [R] Problem with particular file in XML package?
In-Reply-To: <5566B7CA.90804@stats.ox.ac.uk>
References: <CALRDpwUedO3x62qRcvn9sPXFmUv6mWfr6LpqL4QkD=GpxAh4NA@mail.gmail.com>
	<5566B7CA.90804@stats.ox.ac.uk>
Message-ID: <CABdHhvGYT=pTkT3css=5p=xkY88bvn8e_w=7iM6WOXw+KcUR2A@mail.gmail.com>

I have also seen this problem on a student's windows machine (with R
3.2.0 and on multiple mirrors). It appeared that the package zip
itself was being corrupted (with an error to the tune of downloaded
file size does not agree with actual file size). The most likely
explanation that I could come up with was that a virus checker was
hitting a false positive and mangling the zip file.

Hadley

On Thu, May 28, 2015 at 1:38 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> This really should have been sent to the package maintainer.  But that the
> zip file is corrupt has been reported several times, and does not block
> installation for anyone else, so your (plural) diagnosis is wrong.
>
>
> On 28/05/2015 03:56, Gen wrote:
>>
>> I have been attempting to install the R devtools package at work.  The
>> version of R is 3.1.2 (Pumpkin Helmet).  However, the installation of
>> devtools fails because devtools depends on rversions which in turn depends
>> upon the XML package (XML_3.98-1.1.tar.gz), and the XML package is not
>> importing correctly for us.
>>
>> One of our system administrators tried scanning through the files in the
>> XML package, and he said that the particular file:
>> /src/contrib/XML_3.98-1.1.tar.gz/XML/inst/exampleData/dtd.zip looks
>> corrupted.  The actual error message he received was: "Archive parsing
>> failed!  (Data is corrupted)."  For the record, I tried downloading an
>> older version of the XML package (XML_3.95-0.1.tar.gz) but that was also
>> without success -- this time there was a separate error message about not
>> being able to locate xml2-config.  (Perhaps XML_3.95-0.1.tar.gz is just
>> not
>> compatible with R version 3.1.2?)
>>
>> I tried browsing over to the "CRAN checks" link for the XML package and
>> noticed several red warning messages under the "Status" column -- not sure
>> if that is typical?  Has anyone else had trouble with the XML package
>> lately and if so, how did you resolve it?  Would it be possible to remove
>> the potentially corrupted file and then re-upload the package source
>> XML_3.98-1.1.tar.gz to the CRAN webpage?  Thanks for your
>> help/suggestions!
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>
>
> PLEASE do, including what it says about HTML mail, 'at a minimum'
> information required and upgrading before posting: R 3.1.2 is already 2
> versions obsolete.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From jvadams at usgs.gov  Thu May 28 14:36:07 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 28 May 2015 07:36:07 -0500
Subject: [R] Really stuck with the nls function!! It's Urgent !!
In-Reply-To: <DUB109-W775FD92671EF8A8904968B9CCB0@phx.gbl>
References: <DUB109-W3681A8069B5CE24D6E75A79CCB0@phx.gbl>
	<DUB109-W775FD92671EF8A8904968B9CCB0@phx.gbl>
Message-ID: <CAN5YmCGLLX9o6-TjLvA_7ZfQEH0p1+xiiRXDC-TsRGRWP0uRSQ@mail.gmail.com>

I can't answer your question, but I can help you get help by re-writing
your code so it's easy for others to see what you're talking about ...

Jean


library(expm)
apinene_modele_prediction <- function(t, theta) {
  x0 = c(100, 0, 0, 0, 0)
  A = matrix(c(
    -(theta[1]+theta[2]), theta[1], theta[2], 0, 0,
    0, 0, 0, 0, 0,
    0, 0, -(theta[3]+theta[4]), theta[3], theta[4],
    0, 0, 0, 0, 0,
    0, 0, theta[5], 0, -theta[5]
    ), 5, 5)
  X = x0
  for (i in t[2:length(t)]) {
    X = c(X, x0 %*% expm(A*i))
  }
  return(X)
}

t = seq(0, 100, by = 2)
theta = c(0.2, 0.2, 0.2, 0.2, 0.2)
nls(y ~ apinene_modele_prediction(t, theta),
  start = list(theta = c(0.2, 0.2, 0.2, 0.2, 0.2)))
nls(y ~ apinene_modele_prediction(t, c(theta, theta, theta, theta, theta)),
  start = list(theta = 0.2))


On Wed, May 27, 2015 at 6:18 PM, oussama belmejdoub <oussa.belm at hotmail.com>
wrote:

> Greetings,
>
> I'm trying to use the nls function in my statistics project but I'm really
> finding lot of difficulties.
>
> I have a function called apinene_modele_prediction that calculates the
> estimations:
> library(expm); #exp of a matrixapinene_modele_prediction <-
> function(t,theta)
> {x0=c(100,0,0,0,0);A=matrix(c(-(theta[1]+theta[2]),theta[1],theta[2],0,0,0,0,0,0,0,0,0,-(theta[3]+theta[4]),theta[3],theta[4],0,0,0,0,0,0,0,theta[5],0,-theta[5]),5,5);X=x0;for
> (i in t[2:length(t)]){X=c(X,x0%*%expm(A*i));}return(X);}
>
> My "t" vector is given by:
> t=seq(0,100,by=2)
> And the real observations "y" ara given to us  in a txt file called
> "data.txt" that I have joined to this message.
>
> So when I try to fit the "theta" in my model starting with:
> theta=c(0.2,0.2,0.2,0.2,0.2)
> And doing:
> theta_appr
> <-nls(y~apinene_modele_prediction(t,theta),start=list(theta=c(0.2,0.2,0.2,0.2,0.2)))
> I always get the ERROR : singular gradient matrix at initial parameter
> estimates
>
> And, when I try:
> nls(y~apinene_modele_prediction(t,c(theta,theta,theta,theta,theta)),start=list(theta=0.2))
> I get the result:Nonlinear regression model  model: y ~
> apinene_modele_prediction(t, c(theta,theta,theta,theta,theta))data:
> parent.frame()theta 0.04403residual sum-of-squares: 219002
>
>
> But I need to have the elements of the theta to be different and not equal.
> Thanks in advance for your help.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Thu May 28 14:59:02 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 28 May 2015 04:59:02 -0800
Subject: [R] Problem with comparing multiple data sets
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68EBFF@mb02.ads.tamu.edu>
References: <ca+8x3fw4bwsq2u-epumzqzsfl-4syjzakfr56qs8i-fmk7hpfa@mail.gmail.com>
	<53bf8fb63faf2e4a9455ef1ee94da7262d68ea9d@mb02.ads.tamu.edu>
	<cajvfk9k+qk9cuqrbtlmajyvdu5erzhtd1verhnabpkhiikdoaq@mail.gmail.com>
	<cajvfk9nm_a2gr86oximhbc8hzon45rmwll_vmxak4rpoj1=oqw@mail.gmail.com>
	<cajvfk9m1lcja8dxu9w4cymgkpgnyhnnseey7cbln4qfwukommg@mail.gmail.com>
	<cajvfk9kx-hjyeud5q=y6kgxy8oyzw3j4shhxduv39jj1f43mta@mail.gmail.com>
	<32fceb5d574.0000035fjrkrideau@inbox.com>
Message-ID: <71A266E0C5D.000000CFjrkrideau@inbox.com>

Lovely solution Mohammed. I had not even heard of the modeest package.   

For names, I'd just create another data.frame

mode.names  <-  data.frame(df[,1], Out)

John Kane
Kingston ON Canada


> -----Original Message-----
> From: dcarlson at tamu.edu
> Sent: Thu, 28 May 2015 00:31:45 +0000
> To: mxalimohamma at ualr.edu, r-help at r-project.org
> Subject: Re: [R] Problem with comparing multiple data sets
> 
> cat(paste0("[", 1:length(Out), "] #dac     ", Out), sep="\n")
> 
> David
> From: Mohammad Alimohammadi [mailto:mxalimohamma at ualr.edu]
> Sent: Wednesday, May 27, 2015 2:29 PM
> To: David L Carlson; r-help at r-project.org
> Subject: Re: [R] Problem with comparing multiple data sets
> 
> Thanks David it worked !
> 
> One more thing. I hope it's not complicated. Is it also possible to
> display the terms for each row next to it?
> 
> for example:
> 
> [1] #dac    2
> [2] #dac    0
> [3] #dac    1
> ...
> 
> 
> 
> 
> On Wed, May 27, 2015 at 2:18 PM, David L Carlson
> <dcarlson at tamu.edu<mailto:dcarlson at tamu.edu>> wrote:
> Save the result of the apply() function:
> 
> Out <- apply(df[ ,2:length(df)], 1, mfv)
> 
> Then there are several options:
> 
> Approximately what you asked for
> data.frame(Out)
> t(t(Out))
> 
> More typing but exactly what you asked for
> cat(paste0("[", 1:length(Out), "] ", Out), sep="\n")
> 
> 
> David L. Carlson
> Department of Anthropology
> Texas A&M University
> 
> 
> -----Original Message-----
> From: R-help
[mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>]
> On Behalf Of Mohammad Alimohammadi
> Sent: Wednesday, May 27, 2015 1:47 PM
> To: John Kane; r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: Re: [R] Problem with comparing multiple data sets
> 
> Ok. so I read about the ("modeest") package that gives the results that I
> am looking for (most repeated value).
> 
> I modified the data frame a little and moved the text to the first
> column.
> This is the data frame with all 3 possible classes for each term.
> 
> =================================
> structure(list(terms = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 4L, 4L,
> 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label = c("#dac",
> "#mac,#security",
> "accountability,anonymous", "data security,encryption,security"
> ), class = "factor"), class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L,
> 1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), class.2 = c(2L, 2L,
> 2L, 2L, 0L, 0L, 2L, 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L,
> 0L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L),
>     class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>     0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>     0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L, 1L,
>     0L, 0L, 0L, 0L, 2L, 1L, 2L)), .Names = c("terms", "class.1",
> "class.2", "class.3"), class = "data.frame", row.names = c(NA,
> -49L))
> =============================================
> #Then I applied the function below:
> 
> ======================
> library(modeest)
> df<- read.csv(file="short.csv", head= TRUE, sep=",")
> apply(df[ ,2:length(df)], 1, mfv)
> 
> ============================
> # It gives the most frequent value for each row which is what I need. The
> only problem is that all the values are displayed in one single row.
> 
>  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> 0
> 0 0 2 1 1 1 1 0 0 0 0 2 1 2
> 
> It would be much better to show them in separate rows.
> For example:
> 
>  [1] 0
> 
>  [2] 0
> 
>  [3] 1
> ....
> 
> Any idea how to do this?
> 
> 
> 
> On Wed, May 27, 2015 at 10:11 AM, Mohammad Alimohammadi <
> mxalimohamma at ualr.edu<mailto:mxalimohamma at ualr.edu>> wrote:
> 
>> Hi Jim,
>> 
>> Thank you for your advice.
>> 
>> I'm not sure how to exactly incorporate this function though. I added a
>> portion of the actual data sets. all 3 data sets have the same items
>> (text)
>> with different class values. So I need to assign the most repeated class
>> (0,1,2) for each text.
>> 
>> For example: if line1 has text "aaa". It may be assigned to class 0 in
>> dat1, 2 in dat 2 and 0 in dat3. in this case the "aaa" will be assigned
>> to
>> 0 (most repeated value). So it goes for each text.
>> 
>> I really appreciate your help.
>> 
>> =========================================
>> 
>> *dat1*
>> 
>> structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
>> 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
>> c("#dac",
>> "#mac,#security", "accountability,anonymous", "data
>> security,encryption,security"
>> ), class = "factor")), .Names = c("class.1", "terms"), class =
>> "data.frame", row.names = c(NA,
>> -49L))
>> 
>> 
>> *dat2*
>> 
>> structure(list(class.2 = c(2L, 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L,
>> 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L), terms = structure(c(1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
>> c("#dac",
>> "#mac,#security", "accountability,anonymous", "data
>> security,encryption,security"
>> ), class = "factor")), .Names = c("class.2", "terms"), class =
>> "data.frame", row.names = c(NA,
>> -49L))
>> 
>> 
>> *dat3*
>> 
>> structure(list(class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
>> 1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
>> c("#dac",
>> "#mac,#security", "accountability,anonymous", "data
>> security,encryption,security"
>> ), class = "factor")), .Names = c("class.3", "terms"), class =
>> "data.frame", row.names = c(NA,
>> -49L))
>> 
>> ===========================================================
>> 
>> 
>> On Sun, May 24, 2015 at 1:15 AM, Jim Lemon
>> <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:
>> 
>>> Hi Mohammad,
>>> You know, I thought this would be fairly easy, but it wasn't really.
>>> 
>>> df1<-data.frame(Class=c(0,2,1),Comment=c("com1","com2","com3"),
>>>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
>>> df2<-data.frame(Class=c(0,2,1),Comment=c("com1","com2","com3"),
>>>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
>>> df3<-data.frame(Class=c(2,1,0),Comment=c("com1","com2","com3"),
>>>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
>>> dflist<-list(df1,df2,df3)
>>> dflist
>>> 
>>> # define a function that extracts the value from one field
>>> # selected by a value in another field
>>> extract_by_value<-function(x,field1,value1,field2) {
>>>  return(x[x[,field1]==value1,field2])
>>> }
>>> 
>>> # define another function that equates all of the values
>>> sub_value<-function(x,field1,value1,field2,value2) {
>>>  x[x[,field1]==value1,field2]<-value2
>>>  return(x)
>>> }
>>> 
>>> conformity<-function(x,fieldname1,value1,fieldname2) {
>>>  # get the most frequent value in fieldname2
>>>  # for the desired value in fieldname1
>>>  most_freq<-as.numeric(names(which.max(table(unlist(lapply(x,
>>>   extract_by_value,fieldname1,value1,fieldname2))))))
>>>  # now set all the values to the most frequent
>>>  for(i in 1:length(x))
>>>   x[[i]]<-sub_value(x[[i]],fieldname1,value1,fieldname2,most_freq)
>>>  return(x)
>>> }
>>> 
>>> conformity(dflist,"Text","text1","Class")
>>> 
>>> Jim
>>> 
>>> On Sat, May 23, 2015 at 11:23 PM, John Kane
>>> <jrkrideau at inbox.com<mailto:jrkrideau at inbox.com>> wrote:
>>>> Hi Mohammad
>>>> 
>>>> Welcome to the R-help list.
>>>> 
>>>> There probably is a fairly easy way to what you want but I think we
>>> probably need a bit more background information on what you are trying
>>> to
>>> achieve.  I know I'm not exactly clear on your decision rule(s).
>>>> 
>>>> It would also be very useful to see some actual sample data in useable
>>> R format.Have a look at these links
>>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>> and http://adv-r.had.co.nz/Reproducibility.html for some hints on what
>>> you might want to include in your question.
>>>> 
>>>> In particular, read up about dput()  in those links and/or see ?dput.
>>> This is the generally preferred way to supply sample or illustrative
>>> data
>>> to the R-help list.  It basically creates a perfect copy of the data as
>>> it
>>> exists on 'your' machine so that R-help readers see exactly what you
>>> do.
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> John Kane
>>>> Kingston ON Canada
>>>> 
>>>> 
>>>>> -----Original Message-----
>>>>> From: mxalimohamma at ualr.edu<mailto:mxalimohamma at ualr.edu>
>>>>> Sent: Fri, 22 May 2015 12:37:50 -0500
>>>>> To: r-help at r-project.org<mailto:r-help at r-project.org>
>>>>> Subject: [R] Problem with comparing multiple data sets
>>>>> 
>>>>> Hi everyone,
>>>>> 
>>>>> I am very new to R and I have a task to do. I appreciate any help. I
>>> have
>>>>> 3
>>>>> data sets. Each data set has 4 columns. For example:
>>>>> 
>>>>> Class  Comment   Term   Text
>>>>> 0           com1        aac    text1
>>>>> 2           com2        aax    text2
>>>>> 1           com3        vvx    text3
>>>>> 
>>>>> Now I need t compare the class section between 3 data sets and assign
>>> the
>>>>> most available class to that text. For example if text1 is assigned
>>>>> to
>>>>> class 0 in data set 1&2 but assigned as 2 in data set 3 then it
>>>>> should
>>> be
>>>>> assigned to class 0. If they are all the same so the class will be
>>>>> the
>>>>> same. The ideal thing would be to keep the same format and just
>>>>> update
>>>>> the
>>>>> class. Is there any easy way to do this?
>>>>> 
>>>>> Thanks a lot.
>>>>> 
>>>>>       [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>>>>> UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ____________________________________________________________
>>>> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>>>> UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> 
>> --
>> Mohammad Alimohammadi | Graduate Assistant
>> University of Arkansas at Little Rock | College of Science and
>> Mathematics
>> (CSAM)
>> | mxalimohamma at ualr.edu<mailto:mxalimohamma at ualr.edu> |
>> ualr.edu<http://ualr.edu>
>> 
>> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
>> 
> 
> 
> --
> Mohammad Alimohammadi | Graduate Assistant
> University of Arkansas at Little Rock | College of Science and
> Mathematics
> (CSAM)
> 501.346.8007<tel:501.346.8007> |
> mxalimohamma at ualr.edu<mailto:mxalimohamma at ualr.edu> |
> ualr.edu<http://ualr.edu>
> 
> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --
> Mohammad Alimohammadi | Graduate Assistant
> University of Arkansas at Little Rock | College of Science and
> Mathematics (CSAM)
> 501.346.8007 | mxalimohamma at ualr.edu<mailto:mxalimohamma at ualr.edu> |
> ualr.edu<http://ualr.edu/>
> 
> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
> [https://mailtrack.io/trace/mail/d062b2c3f56ab0e306570c96c3e24fb7c7b80685.png]
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From nashjc at uottawa.ca  Thu May 28 15:12:44 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Thu, 28 May 2015 09:12:44 -0400
Subject: [R] R] nls model singular gradient matrix at initial parameter,
	> 	estimates
In-Reply-To: <mailman.3.1432720802.12331.r-help@r-project.org>
References: <mailman.3.1432720802.12331.r-help@r-project.org>
Message-ID: <5567144C.1070509@uottawa.ca>

I have a section (6.4.2) about "singular gradient" (actually singular
Jacobian to numerical analysts) in my recent book "Nonlinear parameter
optimization using R tools". nls() is prone to this, though having all
the starting values the same in many functions can be asking for trouble
of this sort, as is any function involving expm(). (If you search on
R-help archives, you'll find where there is discussion of how this can
result in huge timing differences in two similar methods of calculation.
But that is about timing rather than computational failure.)

To avoid some of the "singular gradient" issues, try package nlmrt. Note
that it's nlxb() has a slightly different call in that more arguments
need to be explicitly specified.

JN


On 15-05-27 06:00 AM, r-help-request at r-project.org wrote:
> Message: 34
> Date: Wed, 27 May 2015 01:23:35 +0000
> From: oussama belmejdoub <oussa.belm at hotmail.com>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Subject: [R] nls model singular gradient matrix at initial parameter
> 	estimates
> Message-ID: <DUB109-W3681A8069B5CE24D6E75A79CCB0 at phx.gbl>
> Content-Type: text/plain; charset="iso-8859-1"
> 
> Greetings,
> I'm trying to use the nls function in my statistics project but I'm really finding lot of difficulties.
> I have a function called apinene_modele_prediction that calculates the estimations:
> library(expm); #exp of a matrixapinene_modele_prediction <- function(t,theta) {	x0=c(100,0,0,0,0)	A=matrix(c(-(theta[1]+theta[2]),theta[1],theta[2],0,0,0,0,0,0,0,0,0,-(theta[3]+theta[4]),theta[3],theta[4],0,0,0,0,0,0,0,theta[5],0,-theta[5]),5,5)	X=x0	for (i in t[2:length(t)]){		X=c(X,x0%*%expm(A*i))		}return(X)}
> 
> My "t" vector is given by: 
> t=seq(0,100,by=2) 
> And the real observations "y" ara given to us  in a txt file called "data.txt" that I have joined to this message.
> So when I try to fit the "theta" in my model starting with: theta=c(0.2,0.2,0.2,0.2,0.2) 
> And doing:
> theta_appr <-nls(y~apinene_modele_prediction(t,theta),start=list(theta=c(0.2,0.2,0.2,0.2,0.2)))
> I always got the ERROR : singular gradient matrix at initial parameter estimates
> And, when I try: nls(y~apinene_modele_prediction(t,c(theta,theta,theta,theta,theta)),start=list(theta=0.2))
> I got the result: Nonlinear regression model  model: y ~ apinene_modele_prediction(t, c(theta, theta, theta, theta,     theta))   data: parent.frame()  theta0.04403 residual sum-of-squares: 219002
> But I need to have the elements of the theta to be different and not equal.
> Thanks in advance for your help. 		 	   		  
> -------------- next part --------------
> An embedded and charset-unspecified text was scrubbed...
> Name: data.txt
> URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150527/37052351/attachment-0001.txt>


From shivibhatia at ymail.com  Thu May 28 15:13:04 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Thu, 28 May 2015 06:13:04 -0700 (PDT)
Subject: [R] Help on Histogram ~ Barplot
In-Reply-To: <20CC31C4-3534-4CB6-AE07-303BC23135C9@comcast.net>
References: <1432718936755-4707739.post@n4.nabble.com>
	<20CC31C4-3534-4CB6-AE07-303BC23135C9@comcast.net>
Message-ID: <1432818784215-4707839.post@n4.nabble.com>

HI David,

So if I understand from your post below, when we import a file in R- we need
to make sure that the variable names do not have any space nor they should
be in special characters or not in comma format.
Please correct me I am wrong.

Now I have changed the file to a new file as RData.csv file and now when I
use the below code it gives me an error 
graph<- read.csv("RData.csv", header = TRUE)
MonthlyWeight<-by(RData$Weight,names.arg = RData$Month,sum)

The error is : Error in by(RData$Weight, names.arg = RData$Month, sum) : 
  object 'RData' not found. Whereas I checked using "getwd()" this file is
saved in the working directory. 
Please suggest. 



--
View this message in context: http://r.789695.n4.nabble.com/Help-on-Histogram-Barplot-tp4707739p4707839.html
Sent from the R help mailing list archive at Nabble.com.


From sarah.goslee at gmail.com  Thu May 28 16:00:02 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 28 May 2015 10:00:02 -0400
Subject: [R] Help on Histogram ~ Barplot
In-Reply-To: <1432818784215-4707839.post@n4.nabble.com>
References: <1432718936755-4707739.post@n4.nabble.com>
	<20CC31C4-3534-4CB6-AE07-303BC23135C9@comcast.net>
	<1432818784215-4707839.post@n4.nabble.com>
Message-ID: <CAM_vjum=wYpFyJJRAj9Cc=pg2Dv0eUw0W6N54Di=BnOJcUjLCQ@mail.gmail.com>

Hello,


> Now I have changed the file to a new file as RData.csv file and now when I
> use the below code it gives me an error
> graph<- read.csv("RData.csv", header = TRUE)

Here you read RData.csv into R as a data frame named graph.

> MonthlyWeight<-by(RData$Weight,names.arg = RData$Month,sum)

So here you need to refer to that data frame using the name you gave it.

Your problem looks like a lack of basic understanding of how R works.
Here are a couple of sources that might help you get started:
http://www.burns-stat.com/documents/tutorials/impatient-r/
http://cyclismo.org/tutorial/R/

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From kmwolf at ucdavis.edu  Thu May 28 16:08:52 2015
From: kmwolf at ucdavis.edu (Kristina Wolf)
Date: Thu, 28 May 2015 07:08:52 -0700
Subject: [R] Help on Histogram ~ Barplot
In-Reply-To: <1432818784215-4707839.post@n4.nabble.com>
References: <1432718936755-4707739.post@n4.nabble.com>
	<20CC31C4-3534-4CB6-AE07-303BC23135C9@comcast.net>
	<1432818784215-4707839.post@n4.nabble.com>
Message-ID: <8BA68DE8-C899-447D-8C49-2ACBA49C9293@ucdavis.edu>

I don't know why that doesn't work, but try adding in 
sep=","
In your read.csv()

That shouldn't matter as to whether or not it recognizes your object though, but it will matter in how your object is read. 

Other simple things might be to make sure the file is saved and then close it out to make sure there is no open dialog box preventing the save from occurring. Then run the read.csv again and see if the object shows up in R.



~ Kristina 

Kristina Wolf
PhD Candidate, Graduate Group in Ecology 
M.S. Soil Science, B.S. Animal Science 
KristinaMWolf.com
Restoration Ecology Lab
Department of Plant Sciences
University of California, Davis
(530) 750-9771

> On May 28, 2015, at 6:13 AM, Shivi82 <shivibhatia at ymail.com> wrote:
> 
> HI David,
> 
> So if I understand from your post below, when we import a file in R- we need
> to make sure that the variable names do not have any space nor they should
> be in special characters or not in comma format.
> Please correct me I am wrong.
> 
> Now I have changed the file to a new file as RData.csv file and now when I
> use the below code it gives me an error 
> graph<- read.csv("RData.csv", header = TRUE)
> MonthlyWeight<-by(RData$Weight,names.arg = RData$Month,sum)
> 
> The error is : Error in by(RData$Weight, names.arg = RData$Month, sum) : 
>  object 'RData' not found. Whereas I checked using "getwd()" this file is
> saved in the working directory. 
> Please suggest. 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Help-on-Histogram-Barplot-tp4707739p4707839.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu May 28 17:00:18 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 28 May 2015 08:00:18 -0700
Subject: [R] Help on Histogram ~ Barplot
In-Reply-To: <1432818784215-4707839.post@n4.nabble.com>
References: <1432718936755-4707739.post@n4.nabble.com>
	<20CC31C4-3534-4CB6-AE07-303BC23135C9@comcast.net>
	<1432818784215-4707839.post@n4.nabble.com>
Message-ID: <1AD014CF-5AAE-46F3-A593-75A10DEB692A@comcast.net>

Adding back context which was omitted by this Nabble user who still does not understand the mailing list conventions:

> On May 27, 2015, at 2:28 AM, Shivi82 wrote:
> 
>> Hello All,
>> I need help on creating a histogram for one of my data. The data is as below
>> (sample):
>> MFST_WT	Hours	PROCESS	Month	Weekday	Day of the Month
>> 6,828	13	       INBOUND	Mar	             Fri	13
>> 2,504	16	       INBOUND	Mar	             Fri	27
>> 20	        16	       INBOUND	Mar	             Fri	27
>> 10,262	16	       INBOUND	Mar	             Fri	27
>> 2,500	17	       INBOUND	Mar	             Fri	13
>> 3,938	16	       INBOUND	Feb	            Thu	26
>> 798	        10	       INBOUND	Feb	            Sat	14
>> 5,439	15	       INBOUND	Feb	            Mon	16
>> 
> D.Winsemius wrote:
> What I'm seeing here is the likelihood that the data object has been input incorrectly (or is a mess in the original file?) There appear to be commas in what would presumably be a numeric column and a column name with spaces in it. There is also misregistration of some lines of data possible with tab-characters that were eaten by Nabble's interface.  If you want help under these circumstances you should either respond with the first 20 lines of the original data file posted through a mail-client bypassing Nabble or post dput( head(objname, 20))

On May 28, 2015, at 6:13 AM, Shivi82 wrote:

> HI David,
> 
> So if I understand from your post below, when we import a file in R- we need
> to make sure that the variable names do not have any space nor they should
> be in special characters or not in comma format.

Well .... perhaps. I asked to see the first several lines of the data. If it really were a csv file, then there should not have been any commas in the first column when the R data-object was printed. Any spaces in the header row should have been converted to periods. That's what the `make.names` function does when it encounters spaces or special characters.

-- 
David.


> Please correct me I am wrong.
> 
> Now I have changed the file to a new file as RData.csv file and now when I
> use the below code it gives me an error 
> graph<- read.csv("RData.csv", header = TRUE)
> MonthlyWeight<-by(RData$Weight,names.arg = RData$Month,sum)
> 
> The error is : Error in by(RData$Weight, names.arg = RData$Month, sum) : 
>  object 'RData' not found. Whereas I checked using "getwd()" this file is
> saved in the working directory. 
> Please suggest. 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Help-on-Histogram-Barplot-tp4707739p4707839.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bluehonour at yahoo.com  Thu May 28 08:42:50 2015
From: bluehonour at yahoo.com (blue honour)
Date: Wed, 27 May 2015 23:42:50 -0700
Subject: [R] Using lapply when there are dependencies
In-Reply-To: <A616A46D-FFA5-4CF2-AE9F-9F258550962A@comcast.net>
Message-ID: <1432795370.56910.YahooMailBasic@web121703.mail.ne1.yahoo.com>

Thank you. May I ask, what would you recommend reading in order to learn how to vectorise loops with dependencies using data.table facilities? I have been searching online on this topic since last night but no luck yet. 


--------------------------------------------
On Thu, 5/28/15, David Winsemius <dwinsemius at comcast.net> wrote:

 Subject: Re: [R] Using lapply when there are dependencies

 Cc: r-help at r-project.org
 Date: Thursday, May 28, 2015, 7:02 AM
 
 
 On May
 27, 2015, at 4:34 PM, blue honour via R-help wrote:
 
 > Hi all,
 > 
 > Let's say I have
 a vector:
 > 
 >
 vv<-c(1,2,3)
 > 
 >
 
 > And suppose I have a function f(a,b),
 which is a function of 2 scalar inputs. I would like to
 evaluate this function separately for each element of the vv
 vector while the second input to f( ) will be the previous
 output from f( ). So, the valuation of f() has a dependency
 on the previous f( ) valuation (recursive). This type of
 calculation is easy to set up with a for loop but that will
 run slow. How can I achieve this with apply family of
 functions please?
 
 The speed
 of loops is determined by the speed of their inner
 functions. The Reduce() function does what you request but
 for the application described it will need an init value.
 
 Reduce(f, vv,
 init=<something>)
 
 > I
 have the same question for the case when vv is a data.table
 instead of a vector.
 
 I could be wrong but that doesn't sound
 like an effective use of the data.table facilities.
 
 -- 
 
 David Winsemius
 Alameda, CA,
 USA


From drjimlemon at gmail.com  Thu May 28 11:31:47 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 28 May 2015 19:31:47 +1000
Subject: [R] Identifying peak periods of observations in circular yearly
	data
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68E7EE@mb02.ads.tamu.edu>
References: <CAFf2dDGACuVMUurKT9TsPv=xWJNcCgx=tgBSdWFJp4TO2himTg@mail.gmail.com>
	<CA+8X3fU=gQLh1d5hAmD0aZZ9t=1Qys6OuLt2H3HcJ3r0XzpSzA@mail.gmail.com>
	<CAFf2dDHoWdur=8hPdFXhaui0cJ9P=-byUTqK8Xp8+iJTxeQHXg@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D68E7EE@mb02.ads.tamu.edu>
Message-ID: <CA+8X3fXTALo8H913H7QcPwU5GP4W28E1U_9FJ+=P7xDWSXQFSw@mail.gmail.com>

Hi Daisy,
Let me rephrase what I said. Are you looking for 80% of bird breeding
observations for a given species in a calendar year (I think not), or
in the breeding season for that species, which may not be strongly
linked to a calendar year? Your example data, when plotted like this:

hist(obsDay,breaks=seq(0,380,by=20))

look like breeding begins at about the middle of the year, increases
in intensity until the first month or two in the next year and then
declines sharply until the middle of that year. Getting the 80% in a
calendar year is easy, but I don't think it means anything in terms of
breeding behavior. My comment, which probably was pretty obscure, was
that I think you are looking for the beginning of the breeding season
in order to calculate the quantile or if you want to predict when that
quantile will occur, then go looking for the kernel density of the
observed historical distribution.

Jim


On Thu, May 28, 2015 at 2:02 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> You can use package circular for this. You have to convert 1-366 to 1-360 by dividing the days by 366 and multiplying by 360 and converting the results back to days by adding 360 if the value is <0 and dividing by 360 and multiplying by 366:
>
>> library(circular)
>> degrees <- obsDay/366*360 # convert year to 360 degrees
>> # Create a circular object
>> circ <- circular(degrees, units="degrees", template="geographics")
>> # Get descriptive stats
>> mean(circ)
> Circular Data:
> Type = angles
> Units = degrees
> Template = geographics
> Modulo = asis
> Zero = 1.570796
> Rotation = clock
> [1] -23.5503
>> median(circ)
> Circular Data:
> Type = angles
> Units = degrees
> Template = geographics
> Modulo = asis
> Zero = 1.570796
> Rotation = clock
> [1] -17.70492
> attr(,"medians")
> [1] 342.2951
>> sd(circ)
> [1] 1.28903
>> pct80 <- quantile(circ, prob=c(.1, .9))
>> pct80
> Circular Data:
> Type = angles
> Units = degrees
> Template = geographics
> Modulo = asis
> Zero = 1.570796
> Rotation = clock
>        10%        90%
>   59.01639 -135.73770
>> # Convert result back to days
>> days <- ifelse(pct80<0, pct80+360, pct80)/360*366
>> days
> 10% 90%
>  60 228
>> # Plot the results
>> plot(circ, stack=TRUE, axes=FALSE)
>> axis <- circular(c(0, 90, 180, 270), units="degrees", template="geographics")
>> axis.circular(at=axis, labels=c("Jan", "April", "July", "October"),
> +     template="geographics", zero=0, tcl.text=.15)
>> arrows.circular(quantile(circ, prob=c(.10, .90)), lwd=2)
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Daisy Englert Duursma
> Sent: Wednesday, May 27, 2015 4:42 AM
> To: Jim Lemon
> Cc: r-help at R-project.org
> Subject: Re: [R] Identifying peak periods of observations in circular yearly data
>
> Thanks for the advice Jim. I did actually play around with this idea, but
> for some bird species (emu) the beginning of the breeding season is
> actually January while for others it is in July or at other times. Breeding
> seasons can be driven by dry season or temperatures, so although there are
> generalizations each species need to be assessed.
>
> On Wed, May 27, 2015 at 7:34 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Daisy,
>> You face a problem similar to one with which I have grappled in
>> different fields. The year is designed for the northern hemisphere,
>> beginning and ending in less productive biologic states in those
>> regions. I have previously argued that since the calendar year is an
>> arbitrary progression, it makes more sense to redraw the annual
>> boundary when examining things like this in the southern hemisphere.
>> That is to say, a "year" is conventionally marked at about the
>> northern winter solstice. Down here, this becomes the summer solstice
>> and breaks up a lot of things that happen around that time. Have you
>> thought of defining a southern bird-watching year as beginning and
>> ending at the southern winter solstice? As I am currently writing in
>> an entirely different context, it shouldn't really make much
>> difference.
>>
>> Jim
>>
>>
>> On Wed, May 27, 2015 at 4:35 PM, Daisy Englert Duursma
>> <daisy.duursma at gmail.com> wrote:
>> > Greetings,
>> >
>> > I am trying to identify at which point during the year 80% of bird
>> breeding
>> > observations are. typically I would answer a question like this by
>> finding
>> > the median or quartiles but how do I deal with situations where the 80%
>> of
>> > the is from day 285 through day 366 (leap year) and extends to day 30?
>> >
>> > The data is circular and and day 365 is as close to day 366 as day 1.
>> >
>> > I am reading the manual for CircStats and circular but I could really use
>> > some help on this.
>> >
>> >
>> > Here is some dummy data:
>> >
>> >
>> >
>> obsDay<-c(rep(1:30,10),rep(45:65,2),65:180,rep(181:265,2),rep(266:330,4),rep(331:366,6))
>> >
>> > plot(density(obsDay))
>> >
>> >
>> >
>> > --
>> > Daisy Englert Duursma
>> > Department of Biological Sciences
>> > Room W19F 135
>> > Macquarie University, North Ryde, NSW 2109
>> > Australia
>> >
>> > Tel +61 2 9850 1302
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Daisy Englert Duursma
> Department of Biological Sciences
> Room W19F 135
> Macquarie University, North Ryde, NSW 2109
> Australia
>
> Tel +61 2 9850 1302
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From claire.rioualen at inserm.fr  Thu May 28 12:10:15 2015
From: claire.rioualen at inserm.fr (Claire Rioualen)
Date: Thu, 28 May 2015 12:10:15 +0200
Subject: [R] Can't seem to install packages
Message-ID: <CAHJq8T-+u3P1U1nNgnzr8KKev+neFpuUJWayttmg6fqQ0G3CUg@mail.gmail.com>

Hello,

I can't seem to install R packages, since it seemed there were some
permission problems I "chmoded" /usr/share/R/ and /usr/lib/R/. However,
there are still errors in the process. Here's my config:

> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] ggplot2_1.0.1        BiocInstaller_1.16.5

loaded via a namespace (and not attached):
 [1] colorspace_1.2-6 digest_0.6.8     grid_3.1.1       gtable_0.1.2
 [5] magrittr_1.5     MASS_7.3-40      munsell_0.4.2    plyr_1.8.2
 [9] proto_0.3-10     Rcpp_0.11.6      reshape2_1.4.1   scales_0.2.4
[13] stringi_0.4-1    stringr_1.0.0    tcltk_3.1.1      tools_3.1.1

And here are some packages I tried to install:

*> install.packages("XML")*
Installing package into ???/packages/rsat/R-scripts/Rpackages???
(as ???lib??? is unspecified)
trying URL 'http://ftp.igh.cnrs.fr/pub/CRAN/src/contrib/XML_3.98-1.1.tar.gz'
Content type 'text/html' length 1582216 bytes (1.5 Mb)
opened URL
==================================================
downloaded 1.5 Mb

* installing *source* package ???XML??? ...
** package ???XML??? successfully unpacked and MD5 sums checked
checking for gcc... gcc
checking for C compiler default output file name... rm: cannot remove
'a.out.dSYM': Is a directory
a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking how to run the C preprocessor... gcc -E
checking for sed... /bin/sed
checking for pkg-config... /usr/bin/pkg-config
checking for xml2-config... no
Cannot find xml2-config
ERROR: configuration failed for package ???XML???
* removing ???/packages/rsat/R-scripts/Rpackages/XML???

The downloaded source packages are in
    ???/tmp/RtmphODjkn/downloaded_packages???
Warning message:
In install.packages("XML") :
  installation of package ???XML??? had non-zero exit status


*> install.packages("Biostrings")*
Installing package into ???/packages/rsat/R-scripts/Rpackages???
(as ???lib??? is unspecified)
Warning message:
package ???Biostrings??? is not available (for R version 3.1.1)

*> biocLite("Biostrings")*
[...]
io_utils.c:16:18: fatal error: zlib.h: No such file or directory
 #include <zlib.h>
                  ^
compilation terminated.
/usr/lib/R/etc/Makeconf:128: recipe for target 'io_utils.o' failed
make: *** [io_utils.o] Error 1
ERROR: compilation failed for package ???Biostrings???
* removing ???/packages/rsat/R-scripts/Rpackages/Biostrings???

The downloaded source packages are in
    ???/tmp/RtmphODjkn/downloaded_packages???
Warning message:
In install.packages(pkgs = pkgs, lib = lib, repos = repos, ...) :
  installation of package ???Biostrings??? had non-zero exit status


I've used R on several machines before and never had such problems.
Thanks for any clue!

-- 
Claire Rioualen
--
Lab. Technological Advances for Genomics and Clinics (TAGC)
INSERM Unit U1090, Aix-Marseille Universit? (AMU).
163, Avenue de Luminy,
13288 MARSEILLE cedex 09.
France

	[[alternative HTML version deleted]]


From sami.toppinen at kolumbus.fi  Thu May 28 15:08:47 2015
From: sami.toppinen at kolumbus.fi (sami.toppinen at kolumbus.fi)
Date: Thu, 28 May 2015 16:08:47 +0300
Subject: [R] Issue with 95% CI using MASS{confint}
Message-ID: <2e763bdc6032dd7e7094321ce96e1474@be56.mail.saunalahti.fi>

I encountered the same problem today. It seems to occur only when you 
use exactly 95 % as the confidence level. For example:

> confint(g1)
Waiting for profiling to be done...
        2.5%      97.5%
a0 1.257512   1.330881
KP       NA 163.862932
> confint(g1, level = 0.95)
Waiting for profiling to be done...
        2.5%      97.5%
a0 1.257512   1.330881
KP       NA 163.862932
> confint(g1, level = 0.950001)
Waiting for profiling to be done...
          2.5%      97.5%
a0   1.257512   1.330881
KP 125.814534 163.862996
> confint(g1, level = 0.949999)
Waiting for profiling to be done...
          2.5%      97.5%
a0   1.257512   1.330881
KP 125.814709 163.862802

--
Sami Toppinen


From murdoch.duncan at gmail.com  Thu May 28 17:21:02 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 28 May 2015 11:21:02 -0400
Subject: [R] Can't seem to install packages
In-Reply-To: <CAHJq8T-+u3P1U1nNgnzr8KKev+neFpuUJWayttmg6fqQ0G3CUg@mail.gmail.com>
References: <CAHJq8T-+u3P1U1nNgnzr8KKev+neFpuUJWayttmg6fqQ0G3CUg@mail.gmail.com>
Message-ID: <5567325E.9030208@gmail.com>

On 28/05/2015 6:10 AM, Claire Rioualen wrote:
> Hello,
>
> I can't seem to install R packages, since it seemed there were some
> permission problems I "chmoded" /usr/share/R/ and /usr/lib/R/. However,
> there are still errors in the process. Here's my config:
>
> > sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] ggplot2_1.0.1        BiocInstaller_1.16.5
>
> loaded via a namespace (and not attached):
>   [1] colorspace_1.2-6 digest_0.6.8     grid_3.1.1       gtable_0.1.2
>   [5] magrittr_1.5     MASS_7.3-40      munsell_0.4.2    plyr_1.8.2
>   [9] proto_0.3-10     Rcpp_0.11.6      reshape2_1.4.1   scales_0.2.4
> [13] stringi_0.4-1    stringr_1.0.0    tcltk_3.1.1      tools_3.1.1
>
> And here are some packages I tried to install:
>
> *> install.packages("XML")*
> Installing package into ???/packages/rsat/R-scripts/Rpackages???
> (as ???lib??? is unspecified)
> trying URL 'http://ftp.igh.cnrs.fr/pub/CRAN/src/contrib/XML_3.98-1.1.tar.gz'
> Content type 'text/html' length 1582216 bytes (1.5 Mb)
> opened URL
> ==================================================
> downloaded 1.5 Mb
>
> * installing *source* package ???XML??? ...
> ** package ???XML??? successfully unpacked and MD5 sums checked
> checking for gcc... gcc
> checking for C compiler default output file name... rm: cannot remove
> 'a.out.dSYM': Is a directory
> a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> checking how to run the C preprocessor... gcc -E
> checking for sed... /bin/sed
> checking for pkg-config... /usr/bin/pkg-config
> checking for xml2-config... no
> Cannot find xml2-config
> ERROR: configuration failed for package ???XML???
> * removing ???/packages/rsat/R-scripts/Rpackages/XML???
>
> The downloaded source packages are in
>      ???/tmp/RtmphODjkn/downloaded_packages???
> Warning message:
> In install.packages("XML") :
>    installation of package ???XML??? had non-zero exit status
>
>
> *> install.packages("Biostrings")*
> Installing package into ???/packages/rsat/R-scripts/Rpackages???
> (as ???lib??? is unspecified)
> Warning message:
> package ???Biostrings??? is not available (for R version 3.1.1)
>
> *> biocLite("Biostrings")*
> [...]
> io_utils.c:16:18: fatal error: zlib.h: No such file or directory
>   #include <zlib.h>
>                    ^
> compilation terminated.
> /usr/lib/R/etc/Makeconf:128: recipe for target 'io_utils.o' failed
> make: *** [io_utils.o] Error 1
> ERROR: compilation failed for package ???Biostrings???
> * removing ???/packages/rsat/R-scripts/Rpackages/Biostrings???
>
> The downloaded source packages are in
>      ???/tmp/RtmphODjkn/downloaded_packages???
> Warning message:
> In install.packages(pkgs = pkgs, lib = lib, repos = repos, ...) :
>    installation of package ???Biostrings??? had non-zero exit status
>
>
> I've used R on several machines before and never had such problems.
> Thanks for any clue!
>
It's hard to read your message (I think it was posted in HTML), but I 
think those are all valid errors in building those packages.  You appear 
to be missing some of their dependencies.  This is not likely related to 
permissions.

Duncan Murdoch


From murdoch.duncan at gmail.com  Thu May 28 17:22:15 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 28 May 2015 11:22:15 -0400
Subject: [R] Issue with 95% CI using MASS{confint}
In-Reply-To: <2e763bdc6032dd7e7094321ce96e1474@be56.mail.saunalahti.fi>
References: <2e763bdc6032dd7e7094321ce96e1474@be56.mail.saunalahti.fi>
Message-ID: <556732A7.2030403@gmail.com>

On 28/05/2015 9:08 AM, sami.toppinen at kolumbus.fi wrote:
> I encountered the same problem today. It seems to occur only when you
> use exactly 95 % as the confidence level. For example:
>
> > confint(g1)
> Waiting for profiling to be done...
>          2.5%      97.5%
> a0 1.257512   1.330881
> KP       NA 163.862932
> > confint(g1, level = 0.95)
> Waiting for profiling to be done...
>          2.5%      97.5%
> a0 1.257512   1.330881
> KP       NA 163.862932
> > confint(g1, level = 0.950001)
> Waiting for profiling to be done...
>            2.5%      97.5%
> a0   1.257512   1.330881
> KP 125.814534 163.862996
> > confint(g1, level = 0.949999)
> Waiting for profiling to be done...
>            2.5%      97.5%
> a0   1.257512   1.330881
> KP 125.814709 163.862802

That's very strange.  It would be nice to see a reproducible example.

Duncan Murdoch


From mtmorgan at fredhutch.org  Thu May 28 17:33:17 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Thu, 28 May 2015 08:33:17 -0700
Subject: [R] Can't seem to install packages
In-Reply-To: <5567325E.9030208@gmail.com>
References: <CAHJq8T-+u3P1U1nNgnzr8KKev+neFpuUJWayttmg6fqQ0G3CUg@mail.gmail.com>
	<5567325E.9030208@gmail.com>
Message-ID: <5567353D.5030202@fredhutch.org>

On 05/28/2015 08:21 AM, Duncan Murdoch wrote:
> On 28/05/2015 6:10 AM, Claire Rioualen wrote:
>> Hello,
>>
>> I can't seem to install R packages, since it seemed there were some
>> permission problems I "chmoded" /usr/share/R/ and /usr/lib/R/. However,
>> there are still errors in the process. Here's my config:
>>
>> > sessionInfo()
>> R version 3.1.1 (2014-07-10)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> locale:
>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] ggplot2_1.0.1        BiocInstaller_1.16.5
>>
>> loaded via a namespace (and not attached):
>>   [1] colorspace_1.2-6 digest_0.6.8     grid_3.1.1       gtable_0.1.2
>>   [5] magrittr_1.5     MASS_7.3-40      munsell_0.4.2    plyr_1.8.2
>>   [9] proto_0.3-10     Rcpp_0.11.6      reshape2_1.4.1   scales_0.2.4
>> [13] stringi_0.4-1    stringr_1.0.0    tcltk_3.1.1      tools_3.1.1
>>
>> And here are some packages I tried to install:
>>
>> *> install.packages("XML")*
>> Installing package into ???/packages/rsat/R-scripts/Rpackages???
>> (as ???lib??? is unspecified)
>> trying URL 'http://ftp.igh.cnrs.fr/pub/CRAN/src/contrib/XML_3.98-1.1.tar.gz'
>> Content type 'text/html' length 1582216 bytes (1.5 Mb)
>> opened URL
>> ==================================================
>> downloaded 1.5 Mb
>>
>> * installing *source* package ???XML??? ...
>> ** package ???XML??? successfully unpacked and MD5 sums checked
>> checking for gcc... gcc
>> checking for C compiler default output file name... rm: cannot remove
>> 'a.out.dSYM': Is a directory
>> a.out
>> checking whether the C compiler works... yes
>> checking whether we are cross compiling... no
>> checking for suffix of executables...
>> checking for suffix of object files... o
>> checking whether we are using the GNU C compiler... yes
>> checking whether gcc accepts -g... yes
>> checking for gcc option to accept ISO C89... none needed
>> checking how to run the C preprocessor... gcc -E
>> checking for sed... /bin/sed
>> checking for pkg-config... /usr/bin/pkg-config
>> checking for xml2-config... no
>> Cannot find xml2-config
>> ERROR: configuration failed for package ???XML???
>> * removing ???/packages/rsat/R-scripts/Rpackages/XML???

this is a missing system dependency, requiring the libxml2 'dev' headers. On my 
linux this is

   sudo apt-get installl libxml2-dev

likely you'll also end up needing curl via libcurl4-openssl-dev or similar

>>
>> The downloaded source packages are in
>>      ???/tmp/RtmphODjkn/downloaded_packages???
>> Warning message:
>> In install.packages("XML") :
>>    installation of package ???XML??? had non-zero exit status
>>
>>
>> *> install.packages("Biostrings")*
>> Installing package into ???/packages/rsat/R-scripts/Rpackages???
>> (as ???lib??? is unspecified)
>> Warning message:
>> package ???Biostrings??? is not available (for R version 3.1.1)

>>
>> *> biocLite("Biostrings")*


Yes,Bioconductor versions packages differently from CRAN (we have twice-yearly 
releases and stable 'release' and 'devel' branches). Following the instructions 
for package installation at

     http://bioconductor.org/packages/Biostrings

but...


>> [...]
>> io_utils.c:16:18: fatal error: zlib.h: No such file or directory
>>   #include <zlib.h>
>>                    ^

this seems like a relatively basic header to be missing, installable from 
zlib1g-dev, but I wonder if you're taking a mis-step earlier, e.g., trying to 
install on a cluster node that is configured for software use but not installation?

Also the instructions here to install R

   http://cran.r-project.org/bin/linux/

would likely include these basic dependencies 'out of the box'.

Martin

>> compilation terminated.
>> /usr/lib/R/etc/Makeconf:128: recipe for target 'io_utils.o' failed
>> make: *** [io_utils.o] Error 1
>> ERROR: compilation failed for package ???Biostrings???
>> * removing ???/packages/rsat/R-scripts/Rpackages/Biostrings???
>>
>> The downloaded source packages are in
>>      ???/tmp/RtmphODjkn/downloaded_packages???
>> Warning message:
>> In install.packages(pkgs = pkgs, lib = lib, repos = repos, ...) :
>>    installation of package ???Biostrings??? had non-zero exit status
>>
>>
>> I've used R on several machines before and never had such problems.
>> Thanks for any clue!
>>
> It's hard to read your message (I think it was posted in HTML), but I think
> those are all valid errors in building those packages.  You appear to be missing
> some of their dependencies.  This is not likely related to permissions.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From bgunter.4567 at gmail.com  Thu May 28 17:09:15 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 28 May 2015 08:09:15 -0700
Subject: [R] Help on Histogram ~ Barplot
In-Reply-To: <8BA68DE8-C899-447D-8C49-2ACBA49C9293@ucdavis.edu>
References: <1432718936755-4707739.post@n4.nabble.com>
	<20CC31C4-3534-4CB6-AE07-303BC23135C9@comcast.net>
	<1432818784215-4707839.post@n4.nabble.com>
	<8BA68DE8-C899-447D-8C49-2ACBA49C9293@ucdavis.edu>
Message-ID: <CAGxFJbRon6BR4MuCN3t5gdEUgxbUWFB4wjBth8yPbVxCTDvyaA@mail.gmail.com>

Unless I have missed something somewhere, the object is named "graph" not
"RData" . Further, the call to by() is complete nonsense, with arguments
misspecified -- there is no "names.arg" argument to by() (the 2nd argument
is named "INDICES")

It appears that some people need to spend some time with R tutorials before
further posting (or replying) on this list.

Cheers,
Bert

graph<- read.csv("RData.csv", header = TRUE)

On Thu, May 28, 2015 at 7:08 AM, Kristina Wolf <kmwolf at ucdavis.edu> wrote:

> I don't know why that doesn't work, but try adding in
> sep=","
> In your read.csv()
>
> That shouldn't matter as to whether or not it recognizes your object
> though, but it will matter in how your object is read.
>
> Other simple things might be to make sure the file is saved and then close
> it out to make sure there is no open dialog box preventing the save from
> occurring. Then run the read.csv again and see if the object shows up in R.
>
>
>
> ~ Kristina
>
> Kristina Wolf
> PhD Candidate, Graduate Group in Ecology
> M.S. Soil Science, B.S. Animal Science
> KristinaMWolf.com
> Restoration Ecology Lab
> Department of Plant Sciences
> University of California, Davis
> (530) 750-9771
>
> > On May 28, 2015, at 6:13 AM, Shivi82 <shivibhatia at ymail.com> wrote:
> >
> > HI David,
> >
> > So if I understand from your post below, when we import a file in R- we
> need
> > to make sure that the variable names do not have any space nor they
> should
> > be in special characters or not in comma format.
> > Please correct me I am wrong.
> >
> > Now I have changed the file to a new file as RData.csv file and now when
> I
> > use the below code it gives me an error
> > graph<- read.csv("RData.csv", header = TRUE)
> > MonthlyWeight<-by(RData$Weight,names.arg = RData$Month,sum)
> >
> > The error is : Error in by(RData$Weight, names.arg = RData$Month, sum) :
> >  object 'RData' not found. Whereas I checked using "getwd()" this file is
> > saved in the working directory.
> > Please suggest.
> >
> >
> >
> > --
> > View this message in context:
> http://r.789695.n4.nabble.com/Help-on-Histogram-Barplot-tp4707739p4707839.html
> > Sent from the R help mailing list archive at Nabble.com.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From claire.rioualen at inserm.fr  Thu May 28 17:41:10 2015
From: claire.rioualen at inserm.fr (Claire Rioualen)
Date: Thu, 28 May 2015 17:41:10 +0200
Subject: [R] Can't seem to install packages
In-Reply-To: <5567353D.5030202@fredhutch.org>
References: <CAHJq8T-+u3P1U1nNgnzr8KKev+neFpuUJWayttmg6fqQ0G3CUg@mail.gmail.com>
	<5567325E.9030208@gmail.com> <5567353D.5030202@fredhutch.org>
Message-ID: <CAHJq8T-VzhdOZwvqPCEr27_T17aF7JmF=w1GBDf=Jb0jGXmA6A@mail.gmail.com>

Hello,
Indeed I've had a lot of dependencies issues, but I'm solving them one
after the other.
Thanks for your time!

CR

On Thu, May 28, 2015 at 5:33 PM, Martin Morgan <mtmorgan at fredhutch.org>
wrote:

> On 05/28/2015 08:21 AM, Duncan Murdoch wrote:
>
>> On 28/05/2015 6:10 AM, Claire Rioualen wrote:
>>
>>> Hello,
>>>
>>> I can't seem to install R packages, since it seemed there were some
>>> permission problems I "chmoded" /usr/share/R/ and /usr/lib/R/. However,
>>> there are still errors in the process. Here's my config:
>>>
>>> > sessionInfo()
>>> R version 3.1.1 (2014-07-10)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>
>>> locale:
>>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] ggplot2_1.0.1        BiocInstaller_1.16.5
>>>
>>> loaded via a namespace (and not attached):
>>>   [1] colorspace_1.2-6 digest_0.6.8     grid_3.1.1       gtable_0.1.2
>>>   [5] magrittr_1.5     MASS_7.3-40      munsell_0.4.2    plyr_1.8.2
>>>   [9] proto_0.3-10     Rcpp_0.11.6      reshape2_1.4.1   scales_0.2.4
>>> [13] stringi_0.4-1    stringr_1.0.0    tcltk_3.1.1      tools_3.1.1
>>>
>>> And here are some packages I tried to install:
>>>
>>> *> install.packages("XML")*
>>> Installing package into ???/packages/rsat/R-scripts/Rpackages???
>>> (as ???lib??? is unspecified)
>>> trying URL '
>>> http://ftp.igh.cnrs.fr/pub/CRAN/src/contrib/XML_3.98-1.1.tar.gz'
>>> Content type 'text/html' length 1582216 bytes (1.5 Mb)
>>> opened URL
>>> ==================================================
>>> downloaded 1.5 Mb
>>>
>>> * installing *source* package ???XML??? ...
>>> ** package ???XML??? successfully unpacked and MD5 sums checked
>>> checking for gcc... gcc
>>> checking for C compiler default output file name... rm: cannot remove
>>> 'a.out.dSYM': Is a directory
>>> a.out
>>> checking whether the C compiler works... yes
>>> checking whether we are cross compiling... no
>>> checking for suffix of executables...
>>> checking for suffix of object files... o
>>> checking whether we are using the GNU C compiler... yes
>>> checking whether gcc accepts -g... yes
>>> checking for gcc option to accept ISO C89... none needed
>>> checking how to run the C preprocessor... gcc -E
>>> checking for sed... /bin/sed
>>> checking for pkg-config... /usr/bin/pkg-config
>>> checking for xml2-config... no
>>> Cannot find xml2-config
>>> ERROR: configuration failed for package ???XML???
>>> * removing ???/packages/rsat/R-scripts/Rpackages/XML???
>>>
>>
> this is a missing system dependency, requiring the libxml2 'dev' headers.
> On my linux this is
>
>   sudo apt-get installl libxml2-dev
>
> likely you'll also end up needing curl via libcurl4-openssl-dev or similar
>
>
>>> The downloaded source packages are in
>>>      ???/tmp/RtmphODjkn/downloaded_packages???
>>> Warning message:
>>> In install.packages("XML") :
>>>    installation of package ???XML??? had non-zero exit status
>>>
>>>
>>> *> install.packages("Biostrings")*
>>> Installing package into ???/packages/rsat/R-scripts/Rpackages???
>>> (as ???lib??? is unspecified)
>>> Warning message:
>>> package ???Biostrings??? is not available (for R version 3.1.1)
>>>
>>
>
>>> *> biocLite("Biostrings")*
>>>
>>
>
> Yes,Bioconductor versions packages differently from CRAN (we have
> twice-yearly releases and stable 'release' and 'devel' branches). Following
> the instructions for package installation at
>
>     http://bioconductor.org/packages/Biostrings
>
> but...
>
>
>  [...]
>>> io_utils.c:16:18: fatal error: zlib.h: No such file or directory
>>>   #include <zlib.h>
>>>                    ^
>>>
>>
> this seems like a relatively basic header to be missing, installable from
> zlib1g-dev, but I wonder if you're taking a mis-step earlier, e.g., trying
> to install on a cluster node that is configured for software use but not
> installation?
>
> Also the instructions here to install R
>
>   http://cran.r-project.org/bin/linux/
>
> would likely include these basic dependencies 'out of the box'.
>
> Martin
>
>  compilation terminated.
>>> /usr/lib/R/etc/Makeconf:128: recipe for target 'io_utils.o' failed
>>> make: *** [io_utils.o] Error 1
>>> ERROR: compilation failed for package ???Biostrings???
>>> * removing ???/packages/rsat/R-scripts/Rpackages/Biostrings???
>>>
>>> The downloaded source packages are in
>>>      ???/tmp/RtmphODjkn/downloaded_packages???
>>> Warning message:
>>> In install.packages(pkgs = pkgs, lib = lib, repos = repos, ...) :
>>>    installation of package ???Biostrings??? had non-zero exit status
>>>
>>>
>>> I've used R on several machines before and never had such problems.
>>> Thanks for any clue!
>>>
>>>  It's hard to read your message (I think it was posted in HTML), but I
>> think
>> those are all valid errors in building those packages.  You appear to be
>> missing
>> some of their dependencies.  This is not likely related to permissions.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793
>



-- 
Claire Rioualen
--
Lab. Technological Advances for Genomics and Clinics (TAGC)
INSERM Unit U1090, Aix-Marseille Universit? (AMU).
163, Avenue de Luminy,
13288 MARSEILLE cedex 09.
France

	[[alternative HTML version deleted]]


From luca.cerone at gmail.com  Thu May 28 19:18:08 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Thu, 28 May 2015 19:18:08 +0200
Subject: [R] best way to handle database connections from within a package
Message-ID: <CAFnz2-9PMa-jBo-7EoDCr1iYoKV83jwSJfPTz+MkTz9Pp=qYnQ@mail.gmail.com>

Dear all,
I am writing a package that is a collection of queries to be run
against a postgresql database,
so that the users do not have to worry about the structure of the database.

In my package I import dbDriver, dbUnloadDriver, dbConnect,
dbDisconnect from the package DBI
and dbGetQuery from the package RPostgreSQL.

All the function in a function in my package have the same structure:

getFancyData <- function( from, to) {
    on.exit( dbDisconnect(con), add=TRUE)
    on.exit( dbUnloadDriver(drv), add=TRUE)
    drv <- dbDriver("PostgreSQL")
    con <- dbConnect(drv,
                     user=pkguser,
                     host=pkghost,
                     password=pkgpassword,
                     port = pkgport)

    query <- sprintf("select * from fancyTable where dt between '%s'
and '%s'", from, to)
    res <- dbGetQuery(con,query)
    return(res)
}

The various access details are read from an encrypted profile that the
user has to
create when she installs the package.

Such functions work perfectly fine, but I have to replicate a lot of
times loading and unloading the driver and connecting and
disconnecting from the database.

I am wondering if there is a better way to do this job, like loading
the driver and opening the connection only once when the package is
loaded. However I have to make sure that
if R crashes or the code where the function is called contains an
error then the connection
with the database is closed. How would you implement this?


Also how would you write a functional that would at least allow me to
avoid replicating
the boilerplate code to load and unload the drivers?

I am thinking something on the lines of:

querybuild <- function(query, ....)
    on.exit( dbDisconnect(con), add=TRUE)
    on.exit( dbUnloadDriver(drv), add=TRUE)
    query <- sprintf(query, ... )
    res <- dbSendQuery(query)
    return(res)
}

and then define

getFancyData <- function(from, to) querybuild("select * from
fancyTable where dt between '%s' and '%s'", from, to)

Do you see a better way?

Thanks a lot in advance for your help and advice on this!

Cheers,
Luca


From murdoch.duncan at gmail.com  Thu May 28 19:36:40 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 28 May 2015 13:36:40 -0400
Subject: [R] Issue with 95% CI using MASS{confint}
In-Reply-To: <CACBvRXTxZV3mnTPW1hT=F581Q-vNZ2CWcpGCJcNqu8F1nmXBEQ@mail.gmail.com>
References: <2e763bdc6032dd7e7094321ce96e1474@be56.mail.saunalahti.fi>	<556732A7.2030403@gmail.com>
	<CACBvRXTxZV3mnTPW1hT=F581Q-vNZ2CWcpGCJcNqu8F1nmXBEQ@mail.gmail.com>
Message-ID: <55675228.2060206@gmail.com>

On 28/05/2015 1:11 PM, Jennifer Sweatman wrote:
> Hi all,
>
> Thank you for your responses. Unfortunately, setting level=0.9500001 or
> 0.949999 did not work for me. I followed your code, Duncan, and some of my
> tau values are less than 2.  I don't know how to interpret this
> information, however. Can you point me in the direction to a reference?

This is probably discussed in the MASS book, but I don't have a copy at 
hand.  I learned it from Bates
and Watts' Nonlinear Regression, Ch 6, Graphical Summaries of Nonlinear 
Inference Regions.  The
idea is that the tau parameter should have roughly a N(0,1) distribution 
if the parameter is
correct, so the confidence region corresponds to the set of parameters 
where tau is in the
central 95% of that distribution, i.e. +/- 1.96.  If tau never goes 
outside that range, then you can't limit the parameter.

Duncan Murdoch
>
> Thanks,
>
> Jenn
>
> On Thu, May 28, 2015 at 11:22 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
> > On 28/05/2015 9:08 AM, sami.toppinen at kolumbus.fi wrote:
> >
> >> I encountered the same problem today. It seems to occur only when you
> >> use exactly 95 % as the confidence level. For example:
> >>
> >> > confint(g1)
> >> Waiting for profiling to be done...
> >>          2.5%      97.5%
> >> a0 1.257512   1.330881
> >> KP       NA 163.862932
> >> > confint(g1, level = 0.95)
> >> Waiting for profiling to be done...
> >>          2.5%      97.5%
> >> a0 1.257512   1.330881
> >> KP       NA 163.862932
> >> > confint(g1, level = 0.950001)
> >> Waiting for profiling to be done...
> >>            2.5%      97.5%
> >> a0   1.257512   1.330881
> >> KP 125.814534 163.862996
> >> > confint(g1, level = 0.949999)
> >> Waiting for profiling to be done...
> >>            2.5%      97.5%
> >> a0   1.257512   1.330881
> >> KP 125.814709 163.862802
> >>
> >
> > That's very strange.  It would be nice to see a reproducible example.
> >
> > Duncan Murdoch
> >
>
>
>


From luca.cerone at gmail.com  Thu May 28 19:40:39 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Thu, 28 May 2015 19:40:39 +0200
Subject: [R] Using names in function with ellipsis (non standard evaluation?)
Message-ID: <CAFnz2-9_ioEM5P+zuYqLmF-pYNTeNJY8ZeZP-HftoGm-AKORTw@mail.gmail.com>

Hi everybody,

this is probably a silly question, but I can't find a way to recognize
the names that are passed
to variables in ellipsis.

For example, say I have a "core" function that receives some extra
parameters through ...
e.g.

f <- function(...) {
   params <- c(...)
   #dothehardworkhere using "names(params)"
}

and then I want to create a function g where some of the parameters
are set like:

g <- function(x,y) f(x,y)

I figure I probably have to use to substitute in f, but it is not
clear to me how.

Definitely what I need to achieve is that when I call:

g(1,2) then in f params is the vector c(x=1,y=2);
similarly I want to be able to call g(y=2, x=1)
and have params = c(x=1,y=2) in f.

Can you please help me understanding how to do this?

Thanks a lot for your help!

Cheers,
Luca


From luca.cerone at gmail.com  Thu May 28 19:44:38 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Thu, 28 May 2015 19:44:38 +0200
Subject: [R] Remove entry with sensitive information from history
In-Reply-To: <CAFDcVCRqzgOzy4cG2eLy0ZBSkzfQWKYXkLEosQ5njsnbApP04A@mail.gmail.com>
References: <CAFnz2-9_tQLzea4u_jHuedr0_KTKY9NVCD+4=_WTxrH4bvv4AQ@mail.gmail.com>
	<7A139850-417B-48C7-A487-7B6D8F6D64F2@comcast.net>
	<CAFnz2-83_zPeK99SUNuB-h1a_3DZiv_gwRB3-+nYsQVx4wDbjg@mail.gmail.com>
	<55658924.8010007@stats.ox.ac.uk>
	<CAFDcVCRqzgOzy4cG2eLy0ZBSkzfQWKYXkLEosQ5njsnbApP04A@mail.gmail.com>
Message-ID: <CAFnz2-8NBs0HwLKt7Kzr8vuO1bAa6507RTnkm1go+eunFxTyQA@mail.gmail.com>

Thanks to you all for your help!

I see Brian's answer as good when I want to prompt the user for a
password (when they set the profile for example) and I would like to
know how to mask the input there.

Henrik's answer seems the closest to what I would like to achieve, but
you are right if they assign the function to a different name, than it
can be problematic.. unleass I don't do a search in the namespace
everytime
and see which names reference to update_password, which seems quite
complicated, but it is a good starting point!

Thanks a lot again for the help!

Cheers,
Luca

On Wed, May 27, 2015 at 12:13 PM, Henrik Bengtsson
<henrik.bengtsson at ucsf.edu> wrote:
> To answer your question on filtering the command-line history: You can
> use savehistory()/loadhistory() to rewrite the history, but like all
> other solutions/suggestions, it's not guaranteed to work everywhere.
> Example:
>
> filterhistory <- function(filter) {
>   stopifnot(is.function(filter))
>   hf <- tempfile()
>   on.exit(file.remove(hf))
>   savehistory(hf)
>   history <- readLines(hf)
>   historyF <- filter(history)
>   ## Always write the same number of history lines as
>   ## read to make sure everything is overwritten,
>   ## cf. 'R_HISTSIZE' in help('savehistory').
>   ndropped <- length(history)-length(historyF)
>   clear <- rep("'<command-line history erased>'", times=ndropped)
>   historyF <- c(clear, historyF)
>
>   writeLines(historyF, con=hf)
>   loadhistory(hf)
> }
>
> update_password <- function(...) {
>   filterhistory(filter=function(x) {
>     str(x)
>     start <- grep("update_password", x, fixed=TRUE)[1]
>     x[seq_len(start-1L)]
>   })
>   ## ...
>   cat("Hello world!\n")
> }
>
> This won't work if someone does:
>
> foo <- update_password
>
> and calls foo().  Then you need to use a more clever filter function,
> e.g. one that drops the last call, which may be spread out on multiple
> lines so not just the last line.
>
> /Henrik
>
> On Wed, May 27, 2015 at 2:06 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote:
>> On 27/05/2015 09:17, Luca Cerone wrote:
>>>
>>> Hi David, thanks, but the function has to work from an R shell, I have
>>> no graphical server in my remote machines.
>>
>>
>> My suggestion was going to be to use readline() to read the passwords.
>> Ideally one would use a custom reader from stdin which did not echo, but
>> that is not possible without knowledge of the terminal/console in use (which
>> is hard to do portably), nor in general.  One could do what some password
>> readers (e.g. that on iOS) do, and after each character is entered backspace
>> and overwrite by x or dot.
>>
>>
>>>
>>> On Wed, May 27, 2015 at 9:45 AM, David Winsemius <dwinsemius at comcast.net>
>>> wrote:
>>>>
>>>>
>>>> On May 27, 2015, at 12:29 AM, Luca Cerone wrote:
>>>>
>>>>> Hi everybody,
>>>>>
>>>>> in one of my packages I store encrypted password.
>>>>>
>>>>> If the user has to change the password in use she can run:
>>>>>
>>>>> update_password(old_password, new_password)
>>>>>
>>>>> The problem is that the commands ends up in the .Rhistory file.
>>>>>
>>>>> Is there any way I can avoid this? Any suggestion about it?
>>>>>
>>>>
>>>> Write a small password verification program in Rcpp or tcl and then call
>>>> it to handle the dialog. In the past Greg Snow has suggested: "The tkexamp
>>>> function in the TeachingDemos package can help with creating tcltk dialog
>>>> boxes. "
>>>>
>>>> --
>>>>
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Emeritus Professor of Applied Statistics, University of Oxford
>> 1 South Parks Road, Oxford OX1 3TG, UK
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu May 28 20:03:57 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 28 May 2015 14:03:57 -0400
Subject: [R] Using names in function with ellipsis (non standard
	evaluation?)
In-Reply-To: <CAFnz2-9_ioEM5P+zuYqLmF-pYNTeNJY8ZeZP-HftoGm-AKORTw@mail.gmail.com>
References: <CAFnz2-9_ioEM5P+zuYqLmF-pYNTeNJY8ZeZP-HftoGm-AKORTw@mail.gmail.com>
Message-ID: <5567588D.5050706@gmail.com>

On 28/05/2015 1:40 PM, Luca Cerone wrote:
> Hi everybody,
>
> this is probably a silly question, but I can't find a way to recognize
> the names that are passed
> to variables in ellipsis.
>
> For example, say I have a "core" function that receives some extra
> parameters through ...
> e.g.
>
> f <- function(...) {
>     params <- c(...)
>     #dothehardworkhere using "names(params)"
> }

The usual method is to use list(...) which retains the names, not c(...).
>
> and then I want to create a function g where some of the parameters
> are set like:
>
> g <- function(x,y) f(x,y)
>
> I figure I probably have to use to substitute in f, but it is not
> clear to me how.
>
> Definitely what I need to achieve is that when I call:
>
> g(1,2) then in f params is the vector c(x=1,y=2);
> similarly I want to be able to call g(y=2, x=1)
> and have params = c(x=1,y=2) in f.
>
> Can you please help me understanding how to do this?

Can't you just call g(...)?  I don't understand what the problem is.

Duncan Murdoch
>
> Thanks a lot for your help!
>
> Cheers,
> Luca
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Thu May 28 20:47:25 2015
From: tmrsg11 at gmail.com (C W)
Date: Thu, 28 May 2015 14:47:25 -0400
Subject: [R] Why I am not able to load library(R.matlab)? Other packages are
	fine.
Message-ID: <CAE2FW2mSRPr5hGGGGKM1P4Pp4Ka4vHQsWKx86oFAQ+5rDoJimA@mail.gmail.com>

Dear R list,

I am trying to do use the R.matlab library, I did the following, but it
does not work.

> library(R.matlab)
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
= vI[[j]]) :
  there is no package called ?R.methodsS3?
Error: package or namespace load failed for ?R.matlab?

This is my session info.

> sessionInfo()
R version 3.2.0 (2015-04-16)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.10.3 (Yosemite)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

My R is up-to-date, R 3.2.0.  Why is this happening?  Is it because I
installed the new R version, instead of updating it?  Maybe things are in a
different directory?

Thanks so much,

Mike

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu May 28 21:17:45 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 28 May 2015 15:17:45 -0400
Subject: [R] Using names in function with ellipsis (non standard
	evaluation?)
In-Reply-To: <CAFnz2-9_ioEM5P+zuYqLmF-pYNTeNJY8ZeZP-HftoGm-AKORTw@mail.gmail.com>
References: <CAFnz2-9_ioEM5P+zuYqLmF-pYNTeNJY8ZeZP-HftoGm-AKORTw@mail.gmail.com>
Message-ID: <556769D9.4050003@gmail.com>

On 28/05/2015 1:40 PM, Luca Cerone wrote:
> Hi everybody,
> 
> this is probably a silly question, but I can't find a way to recognize
> the names that are passed
> to variables in ellipsis.
> 
> For example, say I have a "core" function that receives some extra
> parameters through ...
> e.g.
> 
> f <- function(...) {
>    params <- c(...)
>    #dothehardworkhere using "names(params)"
> }
> 
> and then I want to create a function g where some of the parameters
> are set like:
> 
> g <- function(x,y) f(x,y)
> 
> I figure I probably have to use to substitute in f, but it is not
> clear to me how.
> 
> Definitely what I need to achieve is that when I call:
> 
> g(1,2) then in f params is the vector c(x=1,y=2);
> similarly I want to be able to call g(y=2, x=1)
> and have params = c(x=1,y=2) in f.
> 
> Can you please help me understanding how to do this?

Sorry, I misunderstood your question.  I didn't notice that g calls f.
You should write g to call f with names on the parameters, i.e.

g <- function(x,y) f(x=x, y=y)

then f will receive the parameters with names on them.  I'd still advise
against using c(...), but it will give you the output you want with that
input; the problem is if your users do something like
g(1:2, 3:4) (which would give c(x1=1, x2=2, y1=3, y2=4)).

Duncan Murdoch


From henrik.bengtsson at ucsf.edu  Thu May 28 21:30:35 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Thu, 28 May 2015 12:30:35 -0700
Subject: [R] Why I am not able to load library(R.matlab)? Other packages
 are fine.
In-Reply-To: <CAE2FW2mSRPr5hGGGGKM1P4Pp4Ka4vHQsWKx86oFAQ+5rDoJimA@mail.gmail.com>
References: <CAE2FW2mSRPr5hGGGGKM1P4Pp4Ka4vHQsWKx86oFAQ+5rDoJimA@mail.gmail.com>
Message-ID: <CAFDcVCRF3dChpgAoonZ+RtB1zywdYDD7x9LYAVKCJ7f82ZFbgw@mail.gmail.com>

For some unknown reason, you've managed to install R.matlab without
the dependency R.methodsS3 (cf.
http://cran.r-project.org/web/packages/R.matlab/) or it happened due
to some other glitch somewhere.

Try to reinstall R.matlab.  If that doesn't help, explicitly install
R.methodsS3 and retry.  If you get the same error with the other
dependencies (R.oo and R.utils), do the same.

/Henrik



On Thu, May 28, 2015 at 11:47 AM, C W <tmrsg11 at gmail.com> wrote:
> Dear R list,
>
> I am trying to do use the R.matlab library, I did the following, but it
> does not work.
>
>> library(R.matlab)
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
> = vI[[j]]) :
>   there is no package called ?R.methodsS3?
> Error: package or namespace load failed for ?R.matlab?
>
> This is my session info.
>
>> sessionInfo()
> R version 3.2.0 (2015-04-16)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.10.3 (Yosemite)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> My R is up-to-date, R 3.2.0.  Why is this happening?  Is it because I
> installed the new R version, instead of updating it?  Maybe things are in a
> different directory?
>
> Thanks so much,
>
> Mike
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu May 28 21:55:44 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 28 May 2015 12:55:44 -0700
Subject: [R] Using names in function with ellipsis (non standard
	evaluation?)
In-Reply-To: <5567588D.5050706@gmail.com>
References: <CAFnz2-9_ioEM5P+zuYqLmF-pYNTeNJY8ZeZP-HftoGm-AKORTw@mail.gmail.com>
	<5567588D.5050706@gmail.com>
Message-ID: <C98BE373-8E93-4A93-8FCF-5F295AAF7472@comcast.net>


On May 28, 2015, at 11:03 AM, Duncan Murdoch wrote:

> On 28/05/2015 1:40 PM, Luca Cerone wrote:
>> Hi everybody,
>> 
>> this is probably a silly question, but I can't find a way to recognize
>> the names that are passed
>> to variables in ellipsis.
>> 
>> For example, say I have a "core" function that receives some extra
>> parameters through ...
>> e.g.
>> 
>> f <- function(...) {
>>    params <- c(...)
>>    #dothehardworkhere using "names(params)"
>> }
> 
> The usual method is to use list(...) which retains the names, not c(...).
>> 
>> and then I want to create a function g where some of the parameters
>> are set like:
>> 
>> g <- function(x,y) f(x,y)
>> 
>> I figure I probably have to use to substitute in f, but it is not
>> clear to me how.
>> 
>> Definitely what I need to achieve is that when I call:
>> 
>> g(1,2) then in f params is the vector c(x=1,y=2);
>> similarly I want to be able to call g(y=2, x=1)
>> and have params = c(x=1,y=2) in f.
>> 
>> Can you please help me understanding how to do this?
> 
> Can't you just call g(...)?  I don't understand what the problem is.

I certainly agree that the problem statement is unclear. Using list(...) returns a value that is predictably a list whereas using c(...) may return an atomic vector or a list depending on the mode of the arguments. But in both instances names are available.

> f <- function(...) {
+   params <- c(...)
+   print( names(params))
+ }
> f(x=2,y=3)
[1] "x" "y"
> f <- function(...) {
+   params <- list(...)
+   print( names(params))
+ }
> f(x=2,y=3)
[1] "x" "y"
> f <- function(...) {
+   params <- list(...)
+   str(params)
+ }
> f(x=2,y=3)
List of 2
 $ x: num 2
 $ y: num 3
> f <- function(...) {
+   params <- c(...)
+   str(params)
+ }
> f(x=2,y=3)
 Named num [1:2] 2 3
 - attr(*, "names")= chr [1:2] "x" "y"
> f(x=2,y=list(3))
List of 2
 $ x: num 2
 $ y: num 3

Passing to the next function requires some extra effort:

> g <- function(...) {lis <- list(...); x<-lis[['x']]; y=lis[['y']]; f(x,y) }
> f <- function(x,y) x^y

> g(y=2, x=10)
[1] 100


Explicitly extracting named values into the local function environment seemed a bit convoluted but successful. This lets the lis object be the first place to look but evaluation will pull in tokens that are not found in that list

> g <- function(...) {lis <- list(...); eval(expression( f(x,y)), envir=lis) }
> g(y=2, x=10)
[1] 100

> g <- function(...) {lis <- list(...); eval(expression( f(x,y)), envir=lis) }
> g(y=2)
[1] 64
> x
[1] 8


The naive attempt fails because the names are not on the search list:
> rm(x); rm(y)
> g <- function(...) {lis <- list(...); f(x,y) }
> g(y=2, x=10)
Error in f(x, y) : object 'x' not found


If those symbols existed outside the g()  function, they would be found and used:

> y=3 ; x=8  # outside the function body

> g(y=2, x=10)
[1] 512  Not expected


-- 

David Winsemius
Alameda, CA, USA


From jenn.sweatman21 at gmail.com  Thu May 28 19:11:50 2015
From: jenn.sweatman21 at gmail.com (Jennifer Sweatman)
Date: Thu, 28 May 2015 13:11:50 -0400
Subject: [R] Issue with 95% CI using MASS{confint}
In-Reply-To: <556732A7.2030403@gmail.com>
References: <2e763bdc6032dd7e7094321ce96e1474@be56.mail.saunalahti.fi>
	<556732A7.2030403@gmail.com>
Message-ID: <CACBvRXTxZV3mnTPW1hT=F581Q-vNZ2CWcpGCJcNqu8F1nmXBEQ@mail.gmail.com>

Hi all,

Thank you for your responses. Unfortunately, setting level=0.9500001 or
0.949999 did not work for me. I followed your code, Duncan, and some of my
tau values are less than 2.  I don't know how to interpret this
information, however. Can you point me in the direction to a reference?

Thanks,

Jenn

On Thu, May 28, 2015 at 11:22 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 28/05/2015 9:08 AM, sami.toppinen at kolumbus.fi wrote:
>
>> I encountered the same problem today. It seems to occur only when you
>> use exactly 95 % as the confidence level. For example:
>>
>> > confint(g1)
>> Waiting for profiling to be done...
>>          2.5%      97.5%
>> a0 1.257512   1.330881
>> KP       NA 163.862932
>> > confint(g1, level = 0.95)
>> Waiting for profiling to be done...
>>          2.5%      97.5%
>> a0 1.257512   1.330881
>> KP       NA 163.862932
>> > confint(g1, level = 0.950001)
>> Waiting for profiling to be done...
>>            2.5%      97.5%
>> a0   1.257512   1.330881
>> KP 125.814534 163.862996
>> > confint(g1, level = 0.949999)
>> Waiting for profiling to be done...
>>            2.5%      97.5%
>> a0   1.257512   1.330881
>> KP 125.814709 163.862802
>>
>
> That's very strange.  It would be nice to see a reproducible example.
>
> Duncan Murdoch
>



-- 
Jennifer Sweatman
PhD Candidate
Seagrass Ecosystems Lab
Florida International University

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu May 28 22:49:57 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 28 May 2015 13:49:57 -0700
Subject: [R] Using names in function with ellipsis (non standard
	evaluation?)
In-Reply-To: <556769D9.4050003@gmail.com>
References: <CAFnz2-9_ioEM5P+zuYqLmF-pYNTeNJY8ZeZP-HftoGm-AKORTw@mail.gmail.com>
	<556769D9.4050003@gmail.com>
Message-ID: <CAGxFJbSO1n==eQ_gbFFjvY4GhK-mvZNhpDc-u-3pnhh-r0Eg_A@mail.gmail.com>

I also am not sure exactly what the OP wants and even less sure of what he
needs...

But a possible answer is that a canonical way to do this is just to pass
down the ... list in the definition and specifying a named list of
arguments in the call (as has already been mentioned).

e.g. consider:

> g <- function(f,...)f(...)
## so g can accept arbitrary functions with arbitrary arguments

> fru <- function(x,y=3)x+y

> g(fru,x=2) ## default y used
[1] 5

> g(fru,x=2,y=7) ## y argument given explicitly
[1] 9


Please pardon the noise if this is irrelevant.

Cheers,
Bert

On Thu, May 28, 2015 at 12:17 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 28/05/2015 1:40 PM, Luca Cerone wrote:
> > Hi everybody,
> >
> > this is probably a silly question, but I can't find a way to recognize
> > the names that are passed
> > to variables in ellipsis.
> >
> > For example, say I have a "core" function that receives some extra
> > parameters through ...
> > e.g.
> >
> > f <- function(...) {
> >    params <- c(...)
> >    #dothehardworkhere using "names(params)"
> > }
> >
> > and then I want to create a function g where some of the parameters
> > are set like:
> >
> > g <- function(x,y) f(x,y)
> >
> > I figure I probably have to use to substitute in f, but it is not
> > clear to me how.
> >
> > Definitely what I need to achieve is that when I call:
> >
> > g(1,2) then in f params is the vector c(x=1,y=2);
> > similarly I want to be able to call g(y=2, x=1)
> > and have params = c(x=1,y=2) in f.
> >
> > Can you please help me understanding how to do this?
>
> Sorry, I misunderstood your question.  I didn't notice that g calls f.
> You should write g to call f with names on the parameters, i.e.
>
> g <- function(x,y) f(x=x, y=y)
>
> then f will receive the parameters with names on them.  I'd still advise
> against using c(...), but it will give you the output you want with that
> input; the problem is if your users do something like
> g(1:2, 3:4) (which would give c(x1=1, x2=2, y1=3, y2=4)).
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From nezahathunter at yahoo.co.uk  Thu May 28 23:16:27 2015
From: nezahathunter at yahoo.co.uk (Nezahat HUnter)
Date: Thu, 28 May 2015 21:16:27 +0000 (UTC)
Subject: [R] analysis of variance test
Message-ID: <1302405070.1151306.1432847787354.JavaMail.yahoo@mail.yahoo.com>


Let's say I have 12 observation of 5 variables and my first variable is categorical (with 4 different levels). I am trying to find out statistical significance difference between these categorical levels for each variable, but my? function is not working! Please note that my data "x" are in data.frame format.
Any suggestion would be helpful.Many thanks.

function(x)
{
??? x1 <- numeric
??? x2 <- numeric
??? for(i in 2:length(x)) {
??? ??? x1[i] <- summary(aov(x[, i] ~ factor(x[, 1])))
??? ??? x2[i] <- x1[i]$Pr[1]? #Pr is the probability values
??? ??? if(x2[i] < 0.06)
??? ??? ??? x2[i] <- 1
??? ??? else x2[i] <- 0??? 
??? }
??? x2
}




	[[alternative HTML version deleted]]


From kengoing.gj at gmail.com  Thu May 28 22:19:08 2015
From: kengoing.gj at gmail.com (Kengo Inagaki)
Date: Thu, 28 May 2015 15:19:08 -0500
Subject: [R] Collinearity? Cannot get logisticRidge{ridge} to work
In-Reply-To: <5A636270-C450-469F-B7FD-A678CD6AB5FF@gmail.com>
References: <CAC7aZ4mjgNh1ZtvYw6boDxdCxOLyGAMqaeHdzW1148U_Lk1ZCw@mail.gmail.com>
	<D34A739F-63C5-48FA-BD1D-56B676416B43@comcast.net>
	<CAC7aZ4nmOwjKx9dZ9yA553bqG_4yg+uKJxNThZn1-dAZPRyOOA@mail.gmail.com>
	<11F65DBA-E64E-44C4-8F41-99A69844F2F0@comcast.net>
	<CAC7aZ4kH4d6JDNYpjxe8fttAovDiZ3=sBrJisKO7CiUcyFr1Ew@mail.gmail.com>
	<DD6A8E58-F75D-4D09-840C-65A4065A7583@comcast.net>
	<CAC7aZ4=fPipAojE7S8hkVgaM6vuz-8eJ3M1w94RL=UT--kMCFg@mail.gmail.com>
	<5A636270-C450-469F-B7FD-A678CD6AB5FF@gmail.com>
Message-ID: <CAC7aZ4mi4S1UTPrxc8eJ31Yum-qVS6kmeNo31nqyCP+QAXaWkw@mail.gmail.com>

Dr. Dalgaard,

Thank you for further clarifying the problem.
I found a few possible solutions on internet, and will try to find the solution.

This was my first time to post questions on this mailing list, and I
learned quite a bit though working on this problem.
I apologize for any impoliteness you may have noticed.

Best regards,

Kengo


2015-05-28 4:26 GMT-05:00 peter dalgaard <pdalgd at gmail.com>:
>
> On 28 May 2015, at 00:06 , Kengo Inagaki <kengoing.gj at gmail.com> wrote:
>
>> I did not understand complete separation quite well..
>> Thank you very much for clarification.
>>
>> Kengo
>>
>> 2015-05-27 17:03 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>>>
>>> On May 27, 2015, at 3:00 PM, Kengo Inagaki wrote:
>>>
>>>> Here is the result-
>>>>
>>>>> with(a,  table(Sex, Therapy1,  Outcome) )
>>>> , , Outcome = Alive
>>>>
>>>>       Therapy1
>>>> Sex      no yes
>>>> female  0   4
>>>> male    4   5
>>>>
>>>> , , Outcome = Death
>>>>
>>>>       Therapy1
>>>> Sex      no yes
>>>> female  6   3
>>>> male    3   0
>>>
>>> So no deaths when Female had no-Therapy1 and no survivors with the opposite for those variables. Complete separation.
>
>
> Actually not quite complete separation, but just as bad.  If you look at the linear combination Sex + Therapy, you get
>
> 0 (female, no therapy)
> 1 (female, therapy OR male, no therapy
> 2 (male, therapy)
>
>
> 0: 6 dead, 0 survive
> 1: 6 dead, 8 survive
> 2: 0 dead, 5 survive
>
> and any logistic curve through (1, log(6/8)) fits the middle point and the other two will be fitted better and better as the curve gets steeper, so the fit diverges.
>
> That's a general pattern: you can have complete separation except at one point and still get divergence. Similarly (and really just the same), if you have multiple regression with k parameters and there's a k-1 dimensional hyperplane in predictor space with all responses 0  on one side and 1 on the other, but possibly both 0 and 1 _on_ the hyperplane. Google tells me that this is called quasicomplete separation.
>
> -pd
>
>>>
>>> --
>>> David.
>>>
>>>>
>>>>
>>>> 2015-05-27 16:57 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>>>>>
>>>>> On May 27, 2015, at 2:49 PM, Kengo Inagaki wrote:
>>>>>
>>>>>> Thank you very much for your rapid response. I sincerely appreciate your input.
>>>>>> I am sorry for sending the previous email in HTML format.
>>>>>>
>>>>>> with(a,  table(Sex, Therapy1) )   shows the following.
>>>>>>        Therapy1
>>>>>> Sex      no yes
>>>>>> female  6   7
>>>>>> male    7   5
>>>>>>
>>>>>> and with(a,  table(Therapy1, Outcome) )
>>>>>> elicit the following
>>>>>>
>>>>>>      Outcome
>>>>>> Sex      Alive Death
>>>>>> female     4     9
>>>>>> male       9     3
>>>>>>
>>>>>>      Outcome
>>>>>> Therapy1 Alive Death
>>>>>>   no      4     9
>>>>>>   yes     9     3
>>>>>
>>>>> Then what about:
>>>>>
>>>>> with(a,  table(Sex, Therapy1,  Outcome) )
>>>>>
>>>>> --
>>>>> David
>>>>>
>>>>>
>>>>>>
>>>>>> As there is no zero cells, it does not seem to be complete separation.
>>>>>> I really appreciate comments.
>>>>>>
>>>>>> Kengo Inagaki
>>>>>> Memphis, TN
>>>>>>
>>>>>>
>>>>>> 2015-05-27 13:57 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>>>>>>>
>>>>>>> On May 27, 2015, at 10:10 AM, Kengo Inagaki wrote:
>>>>>>>
>>>>>>>> I am currently working on a health care related project using R. I am
>>>>>>>> learning R while working on data analysis.
>>>>>>>>
>>>>>>>> Below is the part of the data in which i am encountering a problem.
>>>>>>>>
>>>>>>>>
>>>>>>>> Case#    Sex         Therapy1             Therapy2             Outcome
>>>>>>>>
>>>>>>>> 1              male      no
>>>>>>>> no                           Alive
>>>>>>>>
>>>>>>>
>>>>>>> snipped mangled data sent in HTML
>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> "Outcome" is the response variable and "Sex", "Therapy1", "Therapy2" are
>>>>>>>> predictor variables.
>>>>>>>>
>>>>>>>> All of the predictors are significantly associated with the outcome by
>>>>>>>> univariate analysis.
>>>>>>>>
>>>>>>>> Logistic regression runs fine with most of the predictors when "Sex" and
>>>>>>>> "Therapy1" are not included at the same time (This is a part of table that
>>>>>>>> I cut out from a larger table for ease of
>>>>>>>>
>>>>>>>> presentation and there are more predictors that i tested).
>>>>>>>
>>>>>>> Please examine the data before reaching for ridge regression:
>>>>>>>
>>>>>>> What does this show: ...
>>>>>>>
>>>>>>>  with(a,  table(Sex, Therapy1) )
>>>>>>>
>>>>>>> I predict you will see a zero cell entry. The read about "complete separation" and the so-called "Hauck-Donner effect".
>>>>>>>
>>>>>>> --
>>>>>>> David.
>>>>>>>>
>>>>>>>> However, when "Sex" and "Therapy1" are included in logistic regression
>>>>>>>> model at the same time, standard error inflates and p value gets close to 1.
>>>>>>>>
>>>>>>>> The formula used is,
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>> Model<-glm(Outcome~Sex+Therapy1,data=a,family=binomial) #I assigned a
>>>>>>>> vector "a" to represent above table.
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> After doing some reading, I suspect this might be collinearity, as vif
>>>>>>>> values (using "vif()" function in car package) were sky high (8,875,841 for
>>>>>>>> both "Sex" and "Therapy1").
>>>>>>>>
>>>>>>>> Learning that ridge regression may be a solution, I attempted using
>>>>>>>> logisticRidge {ridge} using the following formula, but i get the
>>>>>>>> accomapnying error message.
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>> logisticRidge(a$Outcome~a$Sex+a$Therapy1)
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> Error in ifelse(y, log(p), log(1 - p)) :
>>>>>>>>
>>>>>>>> invalid to change the storage mode of a factor
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> At this point I do not have an idea how to solve this and would like to
>>>>>>>> seek help.
>>>>>>>>
>>>>>>>> I really really appreciate your input!!!
>>>>>>>>
>>>>>>>>    [[alternative HTML version deleted]]
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> David Winsemius
>>>>>>> Alameda, CA, USA
>>>>>>>
>>>>>
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>>
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>


From luca.cerone at gmail.com  Fri May 29 05:35:16 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Fri, 29 May 2015 05:35:16 +0200
Subject: [R] Using names in function with ellipsis (non standard
	evaluation?)
In-Reply-To: <CAGxFJbSO1n==eQ_gbFFjvY4GhK-mvZNhpDc-u-3pnhh-r0Eg_A@mail.gmail.com>
References: <CAFnz2-9_ioEM5P+zuYqLmF-pYNTeNJY8ZeZP-HftoGm-AKORTw@mail.gmail.com>
	<556769D9.4050003@gmail.com>
	<CAGxFJbSO1n==eQ_gbFFjvY4GhK-mvZNhpDc-u-3pnhh-r0Eg_A@mail.gmail.com>
Message-ID: <CAFnz2-9JXFaGbkMAUzOmoyokX5Dm1P2qcto107Hft5OSJW6vHQ@mail.gmail.com>

Thanks a lot to all of you for the help!

Duncan's solution is what I was looking for!

In my examples I assumed that if f(...) is called by g then the names
I use in g were transferred to f, which is not true.

But calling f as Duncan explained ( g <- function(x,y) f(x=x,y=y) )
solves the issue!

Thanks a lot again for helping me with this!

Cheers,
Luca

On Thu, May 28, 2015 at 10:49 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> I also am not sure exactly what the OP wants and even less sure of what he
> needs...
>
> But a possible answer is that a canonical way to do this is just to pass
> down the ... list in the definition and specifying a named list of arguments
> in the call (as has already been mentioned).
>
> e.g. consider:
>
>> g <- function(f,...)f(...)
> ## so g can accept arbitrary functions with arbitrary arguments
>
>> fru <- function(x,y=3)x+y
>
>> g(fru,x=2) ## default y used
> [1] 5
>
>> g(fru,x=2,y=7) ## y argument given explicitly
> [1] 9
>
>
> Please pardon the noise if this is irrelevant.
>
> Cheers,
> Bert
>
> On Thu, May 28, 2015 at 12:17 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>>
>> On 28/05/2015 1:40 PM, Luca Cerone wrote:
>> > Hi everybody,
>> >
>> > this is probably a silly question, but I can't find a way to recognize
>> > the names that are passed
>> > to variables in ellipsis.
>> >
>> > For example, say I have a "core" function that receives some extra
>> > parameters through ...
>> > e.g.
>> >
>> > f <- function(...) {
>> >    params <- c(...)
>> >    #dothehardworkhere using "names(params)"
>> > }
>> >
>> > and then I want to create a function g where some of the parameters
>> > are set like:
>> >
>> > g <- function(x,y) f(x,y)
>> >
>> > I figure I probably have to use to substitute in f, but it is not
>> > clear to me how.
>> >
>> > Definitely what I need to achieve is that when I call:
>> >
>> > g(1,2) then in f params is the vector c(x=1,y=2);
>> > similarly I want to be able to call g(y=2, x=1)
>> > and have params = c(x=1,y=2) in f.
>> >
>> > Can you please help me understanding how to do this?
>>
>> Sorry, I misunderstood your question.  I didn't notice that g calls f.
>> You should write g to call f with names on the parameters, i.e.
>>
>> g <- function(x,y) f(x=x, y=y)
>>
>> then f will receive the parameters with names on them.  I'd still advise
>> against using c(...), but it will give you the output you want with that
>> input; the problem is if your users do something like
>> g(1:2, 3:4) (which would give c(x1=1, x2=2, y1=3, y2=4)).
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From alamesa2012 at gmail.com  Fri May 29 04:42:16 2015
From: alamesa2012 at gmail.com (Gen)
Date: Thu, 28 May 2015 22:42:16 -0400
Subject: [R] Problem with particular file in XML package?
In-Reply-To: <CABdHhvGYT=pTkT3css=5p=xkY88bvn8e_w=7iM6WOXw+KcUR2A@mail.gmail.com>
References: <CALRDpwUedO3x62qRcvn9sPXFmUv6mWfr6LpqL4QkD=GpxAh4NA@mail.gmail.com>
	<5566B7CA.90804@stats.ox.ac.uk>
	<CABdHhvGYT=pTkT3css=5p=xkY88bvn8e_w=7iM6WOXw+KcUR2A@mail.gmail.com>
Message-ID: <CALRDpwVQwA+HUmF8dOHp+vNdmPW-1ZTn5rAn8PjkBCbHh6B8jg@mail.gmail.com>

Keith Jewell-2 wrote
> The OP asked "Has anyone else had trouble with the XML package lately
> and if so, how did you resolve it?"
>
> For what it's worth...
>
> I failed to install XML using install() with the defaults; I can't
> remember the exact error message, something about access denied.
>
> Downloading XML_3.98-1.1.zip with Internet Explorer
> &lt;http://cran.r-project.org/bin/windows/contrib/3.2/XML_3.98-1.1.zip&gt;
> gave a more informative error:
> ========================
> Threat Source: http://cran.r-project.or...trib/3.2/XML_3.98-1.1.zip
>
> The file requested could not be scanned by Sophos Anti-Virus. This means
> it could be encrypted or may contain errors that prevent full scanning.
> As a result, the file was blocked from downloading.
> =====================
> ... so my access was blocked by our systems anti-virus.
>
> Our IT people bypassed the anti-virus to download the zip from which I
> successfully installed.
>
> I note that in the library as installed there is a file
>     ...\XML\exampleData\dtd.zip
> Double-clicking in Windows Explorer gives an error:
> =========
> Windows cannot open the folder. The Compressed (zipped) Folder ... is
> invalid.
> =========
>
> I speculate that Sophos Anti-Virus could not scan dtd.zip because it
> tried to open it as a zipped folder and failed. I don't know if it
> really is a zipped folder or if that's just its name :-O

Thanks a bunch; I suspect something similar to the Sophos Anti-Virus
detection is happening at my workplace that results in the XML package being
blocked.  I am one step removed from the installation process there (also
the reason why I am working with R version 3.1.2) -- the frustrating thing
is that I am able to download and get everything working correctly at home.
Knowing that your IT folks had to bypass the anti-virus software to get it
installed gives me some additional info. to try to resolve this issue.  I am
wondering if the package maintainer or others might be able to modify
dtd.zip?


> On 28/05/2015 07:38, Prof Brian Ripley wrote:
>> This really should have been sent to the package maintainer.

Yes, I actually sent an email to the package maintainer on May 21 but
figured I would try the R help forum as well.

On Thu, May 28, 2015 at 8:12 AM, Hadley Wickham <h.wickham at gmail.com> wrote:

> I have also seen this problem on a student's windows machine (with R
> 3.2.0 and on multiple mirrors). It appeared that the package zip
> itself was being corrupted (with an error to the tune of downloaded
> file size does not agree with actual file size). The most likely
> explanation that I could come up with was that a virus checker was
> hitting a false positive and mangling the zip file.
>
> Hadley
>
> On Thu, May 28, 2015 at 1:38 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote:
> > This really should have been sent to the package maintainer.  But that
> the
> > zip file is corrupt has been reported several times, and does not block
> > installation for anyone else, so your (plural) diagnosis is wrong.
> >
> >
> > On 28/05/2015 03:56, Gen wrote:
> >>
> >> I have been attempting to install the R devtools package at work.  The
> >> version of R is 3.1.2 (Pumpkin Helmet).  However, the installation of
> >> devtools fails because devtools depends on rversions which in turn
> depends
> >> upon the XML package (XML_3.98-1.1.tar.gz), and the XML package is not
> >> importing correctly for us.
> >>
> >> One of our system administrators tried scanning through the files in the
> >> XML package, and he said that the particular file:
> >> /src/contrib/XML_3.98-1.1.tar.gz/XML/inst/exampleData/dtd.zip looks
> >> corrupted.  The actual error message he received was: "Archive parsing
> >> failed!  (Data is corrupted)."  For the record, I tried downloading an
> >> older version of the XML package (XML_3.95-0.1.tar.gz) but that was also
> >> without success -- this time there was a separate error message about
> not
> >> being able to locate xml2-config.  (Perhaps XML_3.95-0.1.tar.gz is just
> >> not
> >> compatible with R version 3.1.2?)
> >>
> >> I tried browsing over to the "CRAN checks" link for the XML package and
> >> noticed several red warning messages under the "Status" column -- not
> sure
> >> if that is typical?  Has anyone else had trouble with the XML package
> >> lately and if so, how did you resolve it?  Would it be possible to
> remove
> >> the potentially corrupted file and then re-upload the package source
> >> XML_3.98-1.1.tar.gz to the CRAN webpage?  Thanks for your
> >> help/suggestions!
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >
> >
> > PLEASE do, including what it says about HTML mail, 'at a minimum'
> > information required and upgrading before posting: R 3.1.2 is already 2
> > versions obsolete.
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Emeritus Professor of Applied Statistics, University of Oxford
> > 1 South Parks Road, Oxford OX1 3TG, UK
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> http://had.co.nz/
>

	[[alternative HTML version deleted]]


From shivibhatia at ymail.com  Fri May 29 10:41:29 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Fri, 29 May 2015 01:41:29 -0700 (PDT)
Subject: [R] Error in CSV file
Message-ID: <1432888889610-4707879.post@n4.nabble.com>

Hello All,
This is an easy fix but I am not able to find the root cause of the error. I
am trying to upload a csv file but it is throwing an error.
Have done a lot of research on google and some tutorial but cant find a
solution hence please advice:-
Syntax is :-   aaa<-read.csv(file ="VehicleData.csv",Header=TRUE)

Error:- Error in read.table(file = file, header = header, sep = sep, quote =
quote,  : 
  unused argument (Header = TRUE)

Snapshot of the file:-
Weight	Hours	PROCESS	Month	Weekday	Day
6828	         13	        INBOUND	Mar	              Fri	13
2504	         16	        INBOUND	Mar	              Fri	27
20	         16	        INBOUND	Mar	              Fri	27
10262	 16	        INBOUND	Mar	              Fri	27
2500	         17	        INBOUND	Mar	              Fri	13

Kindly help. 




--
View this message in context: http://r.789695.n4.nabble.com/Error-in-CSV-file-tp4707879.html
Sent from the R help mailing list archive at Nabble.com.


From ivan.calandra at univ-reims.fr  Fri May 29 11:14:02 2015
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Fri, 29 May 2015 11:14:02 +0200
Subject: [R] Error in CSV file
In-Reply-To: <1432888889610-4707879.post@n4.nabble.com>
References: <1432888889610-4707879.post@n4.nabble.com>
Message-ID: <55682DDA.5050008@univ-reims.fr>

Hi Shivi,

R is case sensitive and the error message that the argument "Header" is 
unused (because unrecognized). Try with "header" (lower case "h") and it 
should work.

HTH,
Ivan

--
Ivan Calandra, ATER
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 29/05/15 10:41, Shivi82 a ?crit :
> Hello All,
> This is an easy fix but I am not able to find the root cause of the error. I
> am trying to upload a csv file but it is throwing an error.
> Have done a lot of research on google and some tutorial but cant find a
> solution hence please advice:-
> Syntax is :-   aaa<-read.csv(file ="VehicleData.csv",Header=TRUE)
>
> Error:- Error in read.table(file = file, header = header, sep = sep, quote =
> quote,  :
>    unused argument (Header = TRUE)
>
> Snapshot of the file:-
> Weight	Hours	PROCESS	Month	Weekday	Day
> 6828	         13	        INBOUND	Mar	              Fri	13
> 2504	         16	        INBOUND	Mar	              Fri	27
> 20	         16	        INBOUND	Mar	              Fri	27
> 10262	 16	        INBOUND	Mar	              Fri	27
> 2500	         17	        INBOUND	Mar	              Fri	13
>
> Kindly help.
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Error-in-CSV-file-tp4707879.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Rainer at krugs.de  Fri May 29 11:14:02 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 29 May 2015 11:14:02 +0200
Subject: [R] Error in CSV file
In-Reply-To: <1432888889610-4707879.post@n4.nabble.com> (Shivi's message of
	"Fri, 29 May 2015 01:41:29 -0700 (PDT)")
References: <1432888889610-4707879.post@n4.nabble.com>
Message-ID: <m2mw0nvj8l.fsf@krugs.de>

Shivi82 <shivibhatia at ymail.com> writes:

> Hello All,
> This is an easy fix but I am not able to find the root cause of the error. I
> am trying to upload a csv file but it is throwing an error.
> Have done a lot of research on google and some tutorial but cant find a
> solution hence please advice:-
> Syntax is :-   aaa<-read.csv(file ="VehicleData.csv",Header=TRUE)
>
> Error:- Error in read.table(file = file, header = header, sep = sep, quote =
> quote,  : 
>   unused argument (Header = TRUE)
                     ^^^^^^^^^^^^^^

use "header = TRUE" instead of "Header = TRUE". R is case sensitive.

Cheers,

Rainer

>
> Snapshot of the file:-
> Weight	Hours	PROCESS	Month	Weekday	Day
> 6828	         13	        INBOUND	Mar	              Fri	13
> 2504	         16	        INBOUND	Mar	              Fri	27
> 20	         16	        INBOUND	Mar	              Fri	27
> 10262	 16	        INBOUND	Mar	              Fri	27
> 2500	         17	        INBOUND	Mar	              Fri	13
>
> Kindly help. 
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Error-in-CSV-file-tp4707879.html
> Sent from the R help mailing list archive at Nabble.com.
>

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150529/028bff49/attachment.bin>

From shivibhatia at ymail.com  Fri May 29 11:04:23 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Fri, 29 May 2015 02:04:23 -0700 (PDT)
Subject: [R] Error in CSV file
In-Reply-To: <55682DDA.5050008@univ-reims.fr>
References: <1432888889610-4707879.post@n4.nabble.com>
	<55682DDA.5050008@univ-reims.fr>
Message-ID: <1432890263640-4707882.post@n4.nabble.com>

This ate my head like for 2 hours. God thanks for the help. 



--
View this message in context: http://r.789695.n4.nabble.com/Error-in-CSV-file-tp4707879p4707882.html
Sent from the R help mailing list archive at Nabble.com.


From lists at dewey.myzen.co.uk  Fri May 29 13:31:23 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 29 May 2015 12:31:23 +0100
Subject: [R] analysis of variance test
In-Reply-To: <1302405070.1151306.1432847787354.JavaMail.yahoo@mail.yahoo.com>
References: <1302405070.1151306.1432847787354.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <55684E0B.9030803@dewey.myzen.co.uk>

Dear Nezahat
In future it would be helpful if you

1 - gave us the data so we can reproduce what you are doing
2 - told us what the error was in case we cannot replicate ti
3 - did not post in HTML as it messes up everything in your post

What did you think x1 <- numeric was going to do?
Try
x1 <- numeric
str(x1)


On 28/05/2015 22:16, Nezahat HUnter wrote:
>
> Let's say I have 12 observation of 5 variables and my first variable is categorical (with 4 different levels). I am trying to find out statistical significance difference between these categorical levels for each variable, but my  function is not working! Please note that my data "x" are in data.frame format.
> Any suggestion would be helpful.Many thanks.
>
> function(x)
> {
>      x1 <- numeric
>      x2 <- numeric
>      for(i in 2:length(x)) {
>          x1[i] <- summary(aov(x[, i] ~ factor(x[, 1])))
>          x2[i] <- x1[i]$Pr[1]  #Pr is the probability values
>          if(x2[i] < 0.06)
>              x2[i] <- 1
>          else x2[i] <- 0
>      }
>      x2
> }
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From drjimlemon at gmail.com  Fri May 29 13:35:27 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 29 May 2015 21:35:27 +1000
Subject: [R] analysis of variance test
In-Reply-To: <1302405070.1151306.1432847787354.JavaMail.yahoo@mail.yahoo.com>
References: <1302405070.1151306.1432847787354.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fXm+NmdshQm0F+QdHM+2p_H0O6K6Z=AsDDWaoTogx865Q@mail.gmail.com>

Hi Nezahat,
First, you are storing the code of the function "numeric" in x1 and
x2. You probably want to use:

x1<-numeric()
x2<-numeric()

Second, you are then storing the output of your aov summary (a list)
in x1, which requires a bit of analysis to get the information you
want (i.e. p value). The following will work for your example, but is
not a general solution.

nh_fun<-function(x) {
    pvals <-numeric()
    for(i in 2:length(x))
        pvals[i-1]<-unlist(summary(aov(x[,i] ~
factor(x[,1])))[[1]][5])[1] <= 0.05
    return(pvals)
}

nh_fun(x)

As you probably want to get the conventional <=0.05, I have changed
the criterion. If you want to understand why the mess of extractors
appears after the "summary" call, use the "str" function successively
on the return value from "summary"

Jim


On Fri, May 29, 2015 at 7:16 AM, Nezahat HUnter
<nezahathunter at yahoo.co.uk> wrote:
>
> Let's say I have 12 observation of 5 variables and my first variable is categorical (with 4 different levels). I am trying to find out statistical significance difference between these categorical levels for each variable, but my  function is not working! Please note that my data "x" are in data.frame format.
> Any suggestion would be helpful.Many thanks.
>
> function(x)
> {
>     x1 <- numeric
>     x2 <- numeric
>     for(i in 2:length(x)) {
>         x1[i] <- summary(aov(x[, i] ~ factor(x[, 1])))
>         x2[i] <- x1[i]$Pr[1]  #Pr is the probability values
>         if(x2[i] < 0.06)
>             x2[i] <- 1
>         else x2[i] <- 0
>     }
>     x2
> }
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From shivibhatia at ymail.com  Fri May 29 13:53:17 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Fri, 29 May 2015 04:53:17 -0700 (PDT)
Subject: [R] Help on R Functionality & Histogram
Message-ID: <1432900397222-4707886.post@n4.nabble.com>

Hello Experts, 
I have couple of questions on the analysis I am creating.
1) How does R adopt to changes. The case I have here is that the excel I
have started initially had to be modified because the data I had was on
hourly basis ranging from 0 to 23 hours. After Changes 0 was modified to 24
in hours. Now do I need to recall this excel again in R using read.csv
syntax or is there another way to do so i.e. a kind of reload option
2) I am creating a histogram. I need on x axis 24 hours to be displayed
separately as 0,1,2, and thereon. However it only shows till 20 which makes
the look awkward. Also all l need to resize the labels and if possible
inside the bars. It used the below code, axis fonts have changed but labels
give an error with this code

Code:- hist(aaa$Hours,main="Hourly Weight",xlab = "Time",breaks = 25,col =
"yellow",ylim = c(0,9000),
     labels=TRUE, cex.axis=0.6,cex.label=0.6)

Kindly advice on the both the questions. Thanks. 

Histogram.png <http://r.789695.n4.nabble.com/file/n4707886/Histogram.png>  



--
View this message in context: http://r.789695.n4.nabble.com/Help-on-R-Functionality-Histogram-tp4707886.html
Sent from the R help mailing list archive at Nabble.com.


From gavan.mcgrath at uwa.edu.au  Fri May 29 14:12:30 2015
From: gavan.mcgrath at uwa.edu.au (Gavan McGrath)
Date: Fri, 29 May 2015 20:12:30 +0800
Subject: [R] How to make new predictions from a GAM with a spline forced
 through the origin
Message-ID: <117DA204-7981-41C8-AE12-B36FDB9C3FDF@uwa.edu.au>

Hi,

I?m followed an example to fit a GAM with a spline forced through a point, i.e. (0,0). This works fine from one of Simon?s examples however when it comes to making a prediction from a new set of x values I?m a bit stumped.

In the example below a smooth term is constructed and the basis and penalties at x=0 are removed then the gam is fitted to a spline basis matrix X using spline penalties.

Can someone suggest a way that I can make predictions at new  x  values based on the gam b below.


Here is Simon Wood's example:

library(mgcv)
set.seed(0)
n <- 100
x <- runif(n)*4-1;x <- sort(x);
f <- exp(4*x)/(1+exp(4*x));y <- f+rnorm(100)*0.1;plot(x,y)
dat <- data.frame(x=x,y=y)

## Create a spline basis and penalty, making sure there is a knot
## at the constraint point, (0 here, but could be anywhere)
knots <- data.frame(x=seq(-1,3,length=9)) ## create knots
## set up smoother...
sm <- smoothCon(s(x,k=9,bs="cr"),dat,knots=knots)[[1]]

## 3rd parameter is value of spline at knot location 0,
## set it to 0 by dropping...
X <- sm$X[,-3]        ## spline basis
S <- sm$S[[1]][-3,-3] ## spline penalty
off <- y*0 + .6       ## offset term to force curve through (0, .6)

## fit spline constrained through (0, .6)...
b <- gam(y ~ X - 1 + offset(off),paraPen=list(X=list(S)))
lines(x,predict(b))



	[[alternative HTML version deleted]]


From shivibhatia at ymail.com  Fri May 29 13:54:59 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Fri, 29 May 2015 04:54:59 -0700 (PDT)
Subject: [R] Help on R Functionality & Histogram
Message-ID: <1432900499664-4707887.post@n4.nabble.com>

Hello Experts, 
I have couple of questions on the analysis I am creating.
1) How does R adopt to changes. The case I have here is that the excel I
have started initially had to be modified because the data I had was on
hourly basis ranging from 0 to 23 hours. After Changes 0 was modified to 24
in hours. Now do I need to recall this excel again in R using read.csv
syntax or is there another way to do so i.e. a kind of reload option
2) I am creating a histogram. I need on x axis 24 hours to be displayed
separately as 0,1,2, and thereon. However it only shows till 20 which makes
the look awkward. Also all l need to resize the labels and if possible
inside the bars. It used the below code, axis fonts have changed but labels
give an error with this code

Code:- hist(aaa$Hours,main="Hourly Weight",xlab = "Time",breaks = 25,col =
"yellow",ylim = c(0,9000),
     labels=TRUE, cex.axis=0.6,cex.label=0.6)

Kindly advice on the both the questions. Thanks. 






--
View this message in context: http://r.789695.n4.nabble.com/Help-on-R-Functionality-Histogram-tp4707887.html
Sent from the R help mailing list archive at Nabble.com.


From sarah.goslee at gmail.com  Fri May 29 14:50:48 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 29 May 2015 08:50:48 -0400
Subject: [R] Help on R Functionality & Histogram
In-Reply-To: <1432900397222-4707886.post@n4.nabble.com>
References: <1432900397222-4707886.post@n4.nabble.com>
Message-ID: <CAM_vjumQyDS2dwg=gYF_6SRGCbp7xpZ1k6KU1FRVfGQxDr8XLg@mail.gmail.com>

On Fri, May 29, 2015 at 7:53 AM, Shivi82 <shivibhatia at ymail.com> wrote:
> Hello Experts,
> I have couple of questions on the analysis I am creating.
> 1) How does R adopt to changes. The case I have here is that the excel I
> have started initially had to be modified because the data I had was on
> hourly basis ranging from 0 to 23 hours. After Changes 0 was modified to 24
> in hours. Now do I need to recall this excel again in R using read.csv
> syntax or is there another way to do so i.e. a kind of reload option

Using read.csv() is the reload option. R has no automatic interface to
external files.


> 2) I am creating a histogram. I need on x axis 24 hours to be displayed
> separately as 0,1,2, and thereon. However it only shows till 20 which makes
> the look awkward. Also all l need to resize the labels and if possible
> inside the bars. It used the below code, axis fonts have changed but labels
> give an error with this code
>
> Code:- hist(aaa$Hours,main="Hourly Weight",xlab = "Time",breaks = 25,col =
> "yellow",ylim = c(0,9000),
>      labels=TRUE, cex.axis=0.6,cex.label=0.6)

The most understandable approach is to break it down into chunks:
Create the histogram.
Add a custom axis.
Add custom labels.

# using fake data
aaa <- data.frame(Hours = sample(1:24, 10000, replace=TRUE))

aaa.hist <- hist(aaa$Hours, main="Hourly Weight", xlab = "Time",
breaks = seq(0, 24), col = "yellow", ylim = c(0,9000), cex.axis=0.6,
xaxt="n")
axis(1, (0:23)+.5, 1:24, cex.axis=.6)
text((0:23)+.5, aaa.hist$counts-150, aaa.hist$counts, cex=.6)

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From shivibhatia at ymail.com  Fri May 29 15:00:44 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Fri, 29 May 2015 06:00:44 -0700 (PDT)
Subject: [R] Help on R Functionality & Histogram
In-Reply-To: <CAM_vjumQyDS2dwg=gYF_6SRGCbp7xpZ1k6KU1FRVfGQxDr8XLg@mail.gmail.com>
References: <1432900397222-4707886.post@n4.nabble.com>
	<CAM_vjumQyDS2dwg=gYF_6SRGCbp7xpZ1k6KU1FRVfGQxDr8XLg@mail.gmail.com>
Message-ID: <1432904444917-4707891.post@n4.nabble.com>

Thanks Sarah. This is magical. 
Thanks for explaining in such a length. 



--
View this message in context: http://r.789695.n4.nabble.com/Help-on-R-Functionality-Histogram-tp4707886p4707891.html
Sent from the R help mailing list archive at Nabble.com.


From myencephalon at gmail.com  Fri May 29 14:48:18 2015
From: myencephalon at gmail.com (Josh Grant)
Date: Fri, 29 May 2015 14:48:18 +0200
Subject: [R] An Odd Request
Message-ID: <CAFFw4tpGo2uu+vYhVsFWFpHR_QKA59QtN2WbM_uv2_bMui4whQ@mail.gmail.com>

Hello R-Users

I apologize in advance if my post is inappropriate. I read the entire
posting guide and found nothing to say so, but you never know. I am seeking
a knowledgable R-user that might be interested (for whatever reason) in
helping out on what I hope would be considered a worthy project.

I am a research scientist, albeit one with little programming ability. I
recently started a website which allows patients of different sorts to
suggest research studies. Everything is completely free and anonymous. When
several members express interest in a particular idea I attempt to build it
so they can actually run through the study. Clearly there are limits but we
currently we have 4 communities, chronic fatigue syndrome, fibromyalgia,
multiple sclerosis and pernicious anaemia and there are several active
studies in which people are submitting data every day. It's quite exciting
and I think it has great potential to help people, particularly with
disorders that have defied explanation.

I'm currently using google spreadsheets/forms to create symptom trackers
and interactive dashboards of the results which (most of the time) show
group results by default but which can show individual results if an ID is
entered. Unfortunately google spreadsheets is a little limited and I now
require the use of more complicated stats such as linear mixed models.

I know that I need to move to R, I understand the basics of running
statistical tests with packages such as LMER, but I have no clue how to go
about integrating such analyses into a website. I could certainly learn
how, would love to, and ultimately will, but if someone was interested in
joining me in this endeavour much more could be accomplished.

If you're interested in knowing more let me know.

Josh

	[[alternative HTML version deleted]]


From cdetermanjr at gmail.com  Fri May 29 15:54:46 2015
From: cdetermanjr at gmail.com (Charles Determan)
Date: Fri, 29 May 2015 08:54:46 -0500
Subject: [R] An Odd Request
In-Reply-To: <CAFFw4tpGo2uu+vYhVsFWFpHR_QKA59QtN2WbM_uv2_bMui4whQ@mail.gmail.com>
References: <CAFFw4tpGo2uu+vYhVsFWFpHR_QKA59QtN2WbM_uv2_bMui4whQ@mail.gmail.com>
Message-ID: <CAKxd1KPpua2CeG8JApTLYuNfa8eh_zs4kxLQS2+Rvnxu9wtKuQ@mail.gmail.com>

If you are primarily interested in making your R analyses in to a website
you should look in to the 'Shiny' package.  It makes generating web pages
very easy.  Here is a link to the Shiny Gallery providing some examples (
http://shiny.rstudio.com/gallery/).

Regards,
Charles

On Fri, May 29, 2015 at 7:48 AM, Josh Grant <myencephalon at gmail.com> wrote:

> Hello R-Users
>
> I apologize in advance if my post is inappropriate. I read the entire
> posting guide and found nothing to say so, but you never know. I am seeking
> a knowledgable R-user that might be interested (for whatever reason) in
> helping out on what I hope would be considered a worthy project.
>
> I am a research scientist, albeit one with little programming ability. I
> recently started a website which allows patients of different sorts to
> suggest research studies. Everything is completely free and anonymous. When
> several members express interest in a particular idea I attempt to build it
> so they can actually run through the study. Clearly there are limits but we
> currently we have 4 communities, chronic fatigue syndrome, fibromyalgia,
> multiple sclerosis and pernicious anaemia and there are several active
> studies in which people are submitting data every day. It's quite exciting
> and I think it has great potential to help people, particularly with
> disorders that have defied explanation.
>
> I'm currently using google spreadsheets/forms to create symptom trackers
> and interactive dashboards of the results which (most of the time) show
> group results by default but which can show individual results if an ID is
> entered. Unfortunately google spreadsheets is a little limited and I now
> require the use of more complicated stats such as linear mixed models.
>
> I know that I need to move to R, I understand the basics of running
> statistical tests with packages such as LMER, but I have no clue how to go
> about integrating such analyses into a website. I could certainly learn
> how, would love to, and ultimately will, but if someone was interested in
> joining me in this endeavour much more could be accomplished.
>
> If you're interested in knowing more let me know.
>
> Josh
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From abolfazl.saghafi at gmail.com  Fri May 29 15:44:54 2015
From: abolfazl.saghafi at gmail.com (Abolfazl Saghafi)
Date: Fri, 29 May 2015 09:44:54 -0400
Subject: [R]  Problems with nls
Message-ID: <CADFFKVxcV0fu0ZgGpaz37dH4-FEw2_WVx2L65NWMz_qzGpSYyQ@mail.gmail.com>

Can some help me with a question on this bass model, please

As I read some articles on this topic, I understand that
1. the bass formula is
N(t) = pm + (q-p) N(t-1) - (q/m) (N(t-1))^2
2. which is a difference equation with the solution
N(t) = m (1 ? exp(?(p+q)t)) / (1 + (q/p)exp(?(p+q)t))
3. So, using a linear regression would give us some some initial
estimations for the parameters m, p, q
4. we then can put the initial estimations into a NLS to get the better
estimations

Am I right?

Now the question is,
why is that I see people use cumulative data and try to fit it into a pdf as
M * ( ((P+Q)^2 / P) * exp(-(P+Q) * T79) ) / (1+(Q/P)*exp(-(P+Q)*T79))^2,

why not using the cumulative data and fit directly the N(t)

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri May 29 16:22:49 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 29 May 2015 07:22:49 -0700
Subject: [R] Problems with nls
In-Reply-To: <CADFFKVxcV0fu0ZgGpaz37dH4-FEw2_WVx2L65NWMz_qzGpSYyQ@mail.gmail.com>
References: <CADFFKVxcV0fu0ZgGpaz37dH4-FEw2_WVx2L65NWMz_qzGpSYyQ@mail.gmail.com>
Message-ID: <CAGxFJbSz8v+0ckGgzHSTLftH7seXm0q6F_=+xhkqx=BFBYWFPg@mail.gmail.com>

AFAICS this has essentially nothing to do with R. Please post elsewhere,
e.g. on a statistics list like stats.stackexchange.com.

Cheers,
Bert



On Fri, May 29, 2015 at 6:44 AM, Abolfazl Saghafi <
abolfazl.saghafi at gmail.com> wrote:

> Can some help me with a question on this bass model, please
>
> As I read some articles on this topic, I understand that
> 1. the bass formula is
> N(t) = pm + (q-p) N(t-1) - (q/m) (N(t-1))^2
> 2. which is a difference equation with the solution
> N(t) = m (1 ? exp(?(p+q)t)) / (1 + (q/p)exp(?(p+q)t))
> 3. So, using a linear regression would give us some some initial
> estimations for the parameters m, p, q
> 4. we then can put the initial estimations into a NLS to get the better
> estimations
>
> Am I right?
>
> Now the question is,
> why is that I see people use cumulative data and try to fit it into a pdf
> as
> M * ( ((P+Q)^2 / P) * exp(-(P+Q) * T79) ) / (1+(Q/P)*exp(-(P+Q)*T79))^2,
>
> why not using the cumulative data and fit directly the N(t)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From msharp at txbiomed.org  Fri May 29 17:32:26 2015
From: msharp at txbiomed.org (Mark Sharp)
Date: Fri, 29 May 2015 15:32:26 +0000
Subject: [R] best way to handle database connections from within a
	package
In-Reply-To: <CAFnz2-9PMa-jBo-7EoDCr1iYoKV83jwSJfPTz+MkTz9Pp=qYnQ@mail.gmail.com>
References: <CAFnz2-9PMa-jBo-7EoDCr1iYoKV83jwSJfPTz+MkTz9Pp=qYnQ@mail.gmail.com>
Message-ID: <EB941D84-9905-467C-A780-3006E1AB5EC1@txbiomed.org>

I would simply separate the database connect and disconnect functions from the query functions. 

Mark
R. Mark Sharp, Ph.D.
msharp at TxBiomed.org





> On May 28, 2015, at 12:18 PM, Luca Cerone <luca.cerone at gmail.com> wrote:
> 
> Dear all,
> I am writing a package that is a collection of queries to be run
> against a postgresql database,
> so that the users do not have to worry about the structure of the database.
> 
> In my package I import dbDriver, dbUnloadDriver, dbConnect,
> dbDisconnect from the package DBI
> and dbGetQuery from the package RPostgreSQL.
> 
> All the function in a function in my package have the same structure:
> 
> getFancyData <- function( from, to) {
>    on.exit( dbDisconnect(con), add=TRUE)
>    on.exit( dbUnloadDriver(drv), add=TRUE)
>    drv <- dbDriver("PostgreSQL")
>    con <- dbConnect(drv,
>                     user=pkguser,
>                     host=pkghost,
>                     password=pkgpassword,
>                     port = pkgport)
> 
>    query <- sprintf("select * from fancyTable where dt between '%s'
> and '%s'", from, to)
>    res <- dbGetQuery(con,query)
>    return(res)
> }
> 
> The various access details are read from an encrypted profile that the
> user has to
> create when she installs the package.
> 
> Such functions work perfectly fine, but I have to replicate a lot of
> times loading and unloading the driver and connecting and
> disconnecting from the database.
> 
> I am wondering if there is a better way to do this job, like loading
> the driver and opening the connection only once when the package is
> loaded. However I have to make sure that
> if R crashes or the code where the function is called contains an
> error then the connection
> with the database is closed. How would you implement this?
> 
> 
> Also how would you write a functional that would at least allow me to
> avoid replicating
> the boilerplate code to load and unload the drivers?
> 
> I am thinking something on the lines of:
> 
> querybuild <- function(query, ....)
>    on.exit( dbDisconnect(con), add=TRUE)
>    on.exit( dbUnloadDriver(drv), add=TRUE)
>    query <- sprintf(query, ... )
>    res <- dbSendQuery(query)
>    return(res)
> }
> 
> and then define
> 
> getFancyData <- function(from, to) querybuild("select * from
> fancyTable where dt between '%s' and '%s'", from, to)
> 
> Do you see a better way?
> 
> Thanks a lot in advance for your help and advice on this!
> 
> Cheers,
> Luca
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Fri May 29 17:53:39 2015
From: tmrsg11 at gmail.com (C W)
Date: Fri, 29 May 2015 11:53:39 -0400
Subject: [R] Why I am not able to load library(R.matlab)? Other packages
 are fine.
In-Reply-To: <CAFDcVCRF3dChpgAoonZ+RtB1zywdYDD7x9LYAVKCJ7f82ZFbgw@mail.gmail.com>
References: <CAE2FW2mSRPr5hGGGGKM1P4Pp4Ka4vHQsWKx86oFAQ+5rDoJimA@mail.gmail.com>
	<CAFDcVCRF3dChpgAoonZ+RtB1zywdYDD7x9LYAVKCJ7f82ZFbgw@mail.gmail.com>
Message-ID: <CAE2FW2n2MyzFDDBV=MnP4jJYPR_AP4dTunHo+PA3J9udqufNfg@mail.gmail.com>

Hi Henrik,

I don't quite get what I should do here.  I am not familiar with
R.methodS3.  Can you tell me what command exactly do I need to do?

Thanks,

Mike

On Thu, May 28, 2015 at 3:30 PM, Henrik Bengtsson <henrik.bengtsson at ucsf.edu
> wrote:

> For some unknown reason, you've managed to install R.matlab without
> the dependency R.methodsS3 (cf.
> http://cran.r-project.org/web/packages/R.matlab/) or it happened due
> to some other glitch somewhere.
>
> Try to reinstall R.matlab.  If that doesn't help, explicitly install
> R.methodsS3 and retry.  If you get the same error with the other
> dependencies (R.oo and R.utils), do the same.
>
> /Henrik
>
>
>
> On Thu, May 28, 2015 at 11:47 AM, C W <tmrsg11 at gmail.com> wrote:
> > Dear R list,
> >
> > I am trying to do use the R.matlab library, I did the following, but it
> > does not work.
> >
> >> library(R.matlab)
> > Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
> versionCheck
> > = vI[[j]]) :
> >   there is no package called ?R.methodsS3?
> > Error: package or namespace load failed for ?R.matlab?
> >
> > This is my session info.
> >
> >> sessionInfo()
> > R version 3.2.0 (2015-04-16)
> > Platform: x86_64-apple-darwin13.4.0 (64-bit)
> > Running under: OS X 10.10.3 (Yosemite)
> >
> > locale:
> > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > My R is up-to-date, R 3.2.0.  Why is this happening?  Is it because I
> > installed the new R version, instead of updating it?  Maybe things are
> in a
> > different directory?
> >
> > Thanks so much,
> >
> > Mike
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From liuwensui at gmail.com  Fri May 29 18:31:43 2015
From: liuwensui at gmail.com (Wensui Liu)
Date: Fri, 29 May 2015 12:31:43 -0400
Subject: [R] alternatives to KS test applicable to K-samples
Message-ID: <CAKyN3iBv73_FUsmH2S0nqsann4E-CqMPCt5+0XVwEX2PD50jzQ@mail.gmail.com>

Good morning, All
I have a stat question not specifically related to the the programming language.
To compare distributional consistency / discrepancy between two
samples, we usually use kolmogorov-smirnov test, which is implemented
in R with ks.test() or in SAS with "pro npar1way edf".
I am wondering if there is any alternative to KS test that could be
generalized to K-samples.

Thanks and have a nice weekend.

wensui


From mxalimohamma at ualr.edu  Fri May 29 18:40:41 2015
From: mxalimohamma at ualr.edu (Mohammad Alimohammadi)
Date: Fri, 29 May 2015 11:40:41 -0500
Subject: [R] Problem with comparing multiple data sets
In-Reply-To: <CAJVfk9k7ZJLg8iP+SL_EAMyZfr_=en40Q3OB5fE2ZwQca0suOA@mail.gmail.com>
References: <CAJVfk9nM_a2Gr86OXimHbc8HZoN45RMWLL_VmXak4RPoj1=OQw@mail.gmail.com>
	<32FCEB5D574.0000035Fjrkrideau@inbox.com>
	<CA+8X3fW4BwSQ2U-EpUmzQzsfL-4sYJZaKFR56qS8i-FMk7HPfA@mail.gmail.com>
	<CAJVfk9kx-hJyeUd5q=Y6KGxY8oYzW3J4sHhXDUv39JJ1F43mtA@mail.gmail.com>
	<CAJVfk9k+Qk9CUqrbTLmAjyVdu5ErZHtd1VErHnABPkHiikDOaQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D68EA9D@mb02.ads.tamu.edu>
	<CAJVfk9m1LCja8DXU9w4CYMGKpGnYHNNseeY7cbLN4QfWUKoMMg@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D68EBFF@mb02.ads.tamu.edu>
	<CAJVfk9k7ZJLg8iP+SL_EAMyZfr_=en40Q3OB5fE2ZwQca0suOA@mail.gmail.com>
Message-ID: <CAJVfk9nf-w1aEtpzL7VkhcAOkNYeoY1cv5WL3CakJ-MWE6B16Q@mail.gmail.com>

Hi everyone.

I tried the (modeest) package on my initial test data and it worked.
However, it doesn't work on the entire data set. I saved one of the
protions that gives error. (Not for all of the values but for some of
them). For example: lines 36 and 37 and 39 correctly show the mode value
but 38 and 40 are not correct. Such error is repeated for many of the
values.

[36,] 2
[37,] 2
[38,] Numeric,3
[39,] 1
[40,] Numeric,3

============================================

#This is what I did:
> df<- read.csv(file="Part1-modif.csv", head=TRUE, sep=",")
> Out<- apply(df[,2:length(df)],1, mfv)
> t(t(Out))


#This is the data set

structure(list(terms = structure(c(2L, 4L, 4L, 4L, 3L, 1L, 5L,
5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label =
c("#authentication,access control",
"#privacy,personal data", "#security,malicious,security", "data
controller",
"id management,security", "password,recovery"), class = "factor"),
    class.1 = c(2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L,
    2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L,
    1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 1L,
    2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L), class.2 = c(2L, 2L, 2L,
    0L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 2L,
    2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L,
    2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L,
    2L, 2L), class.3 = c(2L, 0L, 2L, 2L, 1L, 1L, 0L, 0L, 0L,
    2L, 2L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L)), .Names = c("terms",
"class.1", "class.2", "class.3"), class = "data.frame", row.names = c(NA,
-50L))

========================================================

also when I try to include the terms to the result it gives me an error:

> mode.names<- data.frame (df[,1],Out)
Error in data.frame(df[, 1], Out) :
arguments imply differing number of rows: 50, 3







On Thu, May 28, 2015 at 9:24 AM, Mohammad Alimohammadi <
mxalimohamma at ualr.edu> wrote:

> Thank you David for your help !
>
> On Wed, May 27, 2015 at 7:31 PM, David L Carlson <dcarlson at tamu.edu>
> wrote:
>
>>  cat(paste0("[", 1:length(Out), "] #dac     ", Out), sep="\n")
>>
>>  David
>>
>> *From:* Mohammad Alimohammadi [mailto:mxalimohamma at ualr.edu]
>> *Sent:* Wednesday, May 27, 2015 2:29 PM
>> *To:* David L Carlson; r-help at r-project.org
>>
>> *Subject:* Re: [R] Problem with comparing multiple data sets
>>
>>
>>
>> Thanks David it worked !
>>
>>
>>
>> One more thing. I hope it's not complicated. Is it also possible to
>> display the terms for each row next to it?
>>
>>
>>
>> for example:
>>
>>
>>
>> [1] #dac    2
>>
>> [2] #dac    0
>>
>> [3] #dac    1
>>
>> ...
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> On Wed, May 27, 2015 at 2:18 PM, David L Carlson <dcarlson at tamu.edu>
>> wrote:
>>
>> Save the result of the apply() function:
>>
>> Out <- apply(df[ ,2:length(df)], 1, mfv)
>>
>> Then there are several options:
>>
>> Approximately what you asked for
>> data.frame(Out)
>> t(t(Out))
>>
>> More typing but exactly what you asked for
>> cat(paste0("[", 1:length(Out), "] ", Out), sep="\n")
>>
>>
>> David L. Carlson
>> Department of Anthropology
>> Texas A&M University
>>
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Mohammad
>> Alimohammadi
>> Sent: Wednesday, May 27, 2015 1:47 PM
>> To: John Kane; r-help at r-project.org
>> Subject: Re: [R] Problem with comparing multiple data sets
>>
>> Ok. so I read about the ("modeest") package that gives the results that I
>> am looking for (most repeated value).
>>
>> I modified the data frame a little and moved the text to the first column.
>> This is the data frame with all 3 possible classes for each term.
>>
>> =================================
>> structure(list(terms = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 4L, 4L,
>> 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label = c("#dac",
>> "#mac,#security",
>> "accountability,anonymous", "data security,encryption,security"
>> ), class = "factor"), class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L,
>> 1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), class.2 = c(2L, 2L,
>> 2L, 2L, 0L, 0L, 2L, 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L,
>> 0L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L),
>>     class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>>     0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>>     0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L, 1L,
>>     0L, 0L, 0L, 0L, 2L, 1L, 2L)), .Names = c("terms", "class.1",
>> "class.2", "class.3"), class = "data.frame", row.names = c(NA,
>> -49L))
>> =============================================
>> #Then I applied the function below:
>>
>> ======================
>> library(modeest)
>> df<- read.csv(file="short.csv", head= TRUE, sep=",")
>> apply(df[ ,2:length(df)], 1, mfv)
>>
>> ============================
>> # It gives the most frequent value for each row which is what I need. The
>> only problem is that all the values are displayed in one single row.
>>
>>  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
>> 0 0 2 1 1 1 1 0 0 0 0 2 1 2
>>
>> It would be much better to show them in separate rows.
>> For example:
>>
>>  [1] 0
>>
>>  [2] 0
>>
>>  [3] 1
>> ....
>>
>> Any idea how to do this?
>>
>>
>>
>>   On Wed, May 27, 2015 at 10:11 AM, Mohammad Alimohammadi <
>> mxalimohamma at ualr.edu> wrote:
>>
>> > Hi Jim,
>> >
>> > Thank you for your advice.
>> >
>> > I'm not sure how to exactly incorporate this function though. I added a
>> > portion of the actual data sets. all 3 data sets have the same items
>> (text)
>> > with different class values. So I need to assign the most repeated class
>> > (0,1,2) for each text.
>> >
>> > For example: if line1 has text "aaa". It may be assigned to class 0 in
>> > dat1, 2 in dat 2 and 0 in dat3. in this case the "aaa" will be assigned
>> to
>> > 0 (most repeated value). So it goes for each text.
>> >
>> > I really appreciate your help.
>> >
>> > =========================================
>> >
>> > *dat1*
>> >
>> > structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
>> > 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
>> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> > 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
>> > c("#dac",
>> > "#mac,#security", "accountability,anonymous", "data
>> > security,encryption,security"
>> > ), class = "factor")), .Names = c("class.1", "terms"), class =
>> > "data.frame", row.names = c(NA,
>> > -49L))
>> >
>> >
>> > *dat2*
>> >
>> > structure(list(class.2 = c(2L, 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L,
>> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L,
>> > 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L), terms = structure(c(1L, 1L,
>> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> > 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
>> > c("#dac",
>> > "#mac,#security", "accountability,anonymous", "data
>> > security,encryption,security"
>> > ), class = "factor")), .Names = c("class.2", "terms"), class =
>> > "data.frame", row.names = c(NA,
>> > -49L))
>> >
>> >
>> > *dat3*
>>
>> >
>> > structure(list(class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
>> > 1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
>> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> > 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
>> > c("#dac",
>> > "#mac,#security", "accountability,anonymous", "data
>> > security,encryption,security"
>> > ), class = "factor")), .Names = c("class.3", "terms"), class =
>> > "data.frame", row.names = c(NA,
>> > -49L))
>> >
>> > ===========================================================
>> >
>> >
>> > On Sun, May 24, 2015 at 1:15 AM, Jim Lemon <drjimlemon at gmail.com>
>> wrote:
>> >
>> >> Hi Mohammad,
>> >> You know, I thought this would be fairly easy, but it wasn't really.
>> >>
>> >> df1<-data.frame(Class=c(0,2,1),Comment=c("com1","com2","com3"),
>> >>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
>> >> df2<-data.frame(Class=c(0,2,1),Comment=c("com1","com2","com3"),
>> >>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
>> >> df3<-data.frame(Class=c(2,1,0),Comment=c("com1","com2","com3"),
>> >>  Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
>> >> dflist<-list(df1,df2,df3)
>> >> dflist
>> >>
>> >> # define a function that extracts the value from one field
>> >> # selected by a value in another field
>> >> extract_by_value<-function(x,field1,value1,field2) {
>> >>  return(x[x[,field1]==value1,field2])
>> >> }
>> >>
>> >> # define another function that equates all of the values
>> >> sub_value<-function(x,field1,value1,field2,value2) {
>> >>  x[x[,field1]==value1,field2]<-value2
>> >>  return(x)
>> >> }
>> >>
>> >> conformity<-function(x,fieldname1,value1,fieldname2) {
>> >>  # get the most frequent value in fieldname2
>> >>  # for the desired value in fieldname1
>> >>  most_freq<-as.numeric(names(which.max(table(unlist(lapply(x,
>> >>   extract_by_value,fieldname1,value1,fieldname2))))))
>> >>  # now set all the values to the most frequent
>> >>  for(i in 1:length(x))
>> >>   x[[i]]<-sub_value(x[[i]],fieldname1,value1,fieldname2,most_freq)
>> >>  return(x)
>> >> }
>> >>
>> >> conformity(dflist,"Text","text1","Class")
>> >>
>> >> Jim
>> >>
>> >> On Sat, May 23, 2015 at 11:23 PM, John Kane <jrkrideau at inbox.com>
>> wrote:
>> >> > Hi Mohammad
>> >> >
>> >> > Welcome to the R-help list.
>> >> >
>> >> > There probably is a fairly easy way to what you want but I think we
>> >> probably need a bit more background information on what you are trying
>> to
>> >> achieve.  I know I'm not exactly clear on your decision rule(s).
>> >> >
>> >> > It would also be very useful to see some actual sample data in
>> useable
>> >> R format.Have a look at these links
>> >>
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> >> and http://adv-r.had.co.nz/Reproducibility.html for some hints on what
>> >> you might want to include in your question.
>> >> >
>> >> > In particular, read up about dput()  in those links and/or see ?dput.
>> >> This is the generally preferred way to supply sample or illustrative
>> data
>> >> to the R-help list.  It basically creates a perfect copy of the data
>> as it
>> >> exists on 'your' machine so that R-help readers see exactly what you
>> do.
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > John Kane
>> >> > Kingston ON Canada
>> >> >
>> >> >
>> >> >> -----Original Message-----
>> >> >> From: mxalimohamma at ualr.edu
>> >> >> Sent: Fri, 22 May 2015 12:37:50 -0500
>> >> >> To: r-help at r-project.org
>> >> >> Subject: [R] Problem with comparing multiple data sets
>> >> >>
>> >> >> Hi everyone,
>> >> >>
>> >> >> I am very new to R and I have a task to do. I appreciate any help. I
>> >> have
>> >> >> 3
>> >> >> data sets. Each data set has 4 columns. For example:
>> >> >>
>> >> >> Class  Comment   Term   Text
>> >> >> 0           com1        aac    text1
>> >> >> 2           com2        aax    text2
>> >> >> 1           com3        vvx    text3
>> >> >>
>> >> >> Now I need t compare the class section between 3 data sets and
>> assign
>> >> the
>> >> >> most available class to that text. For example if text1 is assigned
>> to
>> >> >> class 0 in data set 1&2 but assigned as 2 in data set 3 then it
>> should
>> >> be
>> >> >> assigned to class 0. If they are all the same so the class will be
>> the
>> >> >> same. The ideal thing would be to keep the same format and just
>> update
>> >> >> the
>> >> >> class. Is there any easy way to do this?
>> >> >>
>> >> >> Thanks a lot.
>> >> >>
>> >> >>       [[alternative HTML version deleted]]
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> PLEASE do read the posting guide
>> >> >> http://www.R-project.org/posting-guide.html
>> >> >> and provide commented, minimal, self-contained, reproducible code.
>> >> >
>> >> > ____________________________________________________________
>> >> > FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >
>> >
>> > --
>> > Mohammad Alimohammadi | Graduate Assistant
>> > University of Arkansas at Little Rock | College of Science and
>> Mathematics
>> > (CSAM)
>> > | mxalimohamma at ualr.edu | ualr.edu
>> >
>> > Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
>> >
>>
>>
>>   --
>> Mohammad Alimohammadi | Graduate Assistant
>> University of Arkansas at Little Rock | College of Science and Mathematics
>> (CSAM)
>> 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu
>>
>> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>
>>
>> --
>>
>> Mohammad Alimohammadi | Graduate Assistant
>>
>> University of Arkansas at Little Rock | College of Science
>> and Mathematics (CSAM)
>>
>> 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu
>>
>>
>>
>> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
>>
>>
>
>
> --
> Mohammad Alimohammadi | Graduate Assistant
> University of Arkansas at Little Rock | College of Science and Mathematics
> (CSAM)
> 501.346.8007 | mxalimohamma at ualr.edu | ualr.edu
>
> Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ
>



-- 
Mohammad Alimohammadi | Graduate Assistant
University of Arkansas at Little Rock | College of Science and Mathematics
(CSAM)
501.346.8007 | mxalimohamma at ualr.edu | ualr.edu

Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ

	[[alternative HTML version deleted]]


From kate.ignatius at gmail.com  Fri May 29 18:58:22 2015
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Fri, 29 May 2015 12:58:22 -0400
Subject: [R] Converting unique strings to unique numbers
Message-ID: <CAE6QMsbz8P2T4PuXEzThewAhRbBiLeg+ifGQ5cd1RxKbZAAyFQ@mail.gmail.com>

I have a pedigree file as so:

X0001 BYX859      0      0  2  1 BYX859
X0001 BYX894      0      0  1  1 BYX894
X0001 BYX862 BYX894 BYX859  2  2 BYX862
X0001 BYX863 BYX894 BYX859  2  2 BYX863
X0001 BYX864 BYX894 BYX859  2  2 BYX864
X0001 BYX865 BYX894 BYX859  2  2 BYX865

And I was hoping to change all unique string values to numbers.

That is:

BYX859 = 1
BYX894 = 2
BYX862 = 3
BYX863 = 4
BYX864 = 5
BYX865 = 6

But only in columns 2 - 4.  Essentially I would like the data to look like this:

X0001 1 0 0  2  1 BYX859
X0001 2 0 0  1  1 BYX894
X0001 3 2 1  2  2 BYX862
X0001 4 2 1  2  2 BYX863
X0001 5 2 1  2  2 BYX864
X0001 6 2 1  2  2 BYX865

Is this possible with factors?

Thanks!

K.


From cadeb at usgs.gov  Fri May 29 19:02:08 2015
From: cadeb at usgs.gov (Cade, Brian)
Date: Fri, 29 May 2015 11:02:08 -0600
Subject: [R] alternatives to KS test applicable to K-samples
In-Reply-To: <CAKyN3iBv73_FUsmH2S0nqsann4E-CqMPCt5+0XVwEX2PD50jzQ@mail.gmail.com>
References: <CAKyN3iBv73_FUsmH2S0nqsann4E-CqMPCt5+0XVwEX2PD50jzQ@mail.gmail.com>
Message-ID: <CAM5M9BQzfdP9JKtKDvbd4uwHgjrNNwQDEOhi-q+cPhPHn26Jsg@mail.gmail.com>

Wensui:  There are the multi-response permutation procedures (MRPP) that
readily test the omnibus hypothesis of no distributional differences among
multiple samples for univariate or multivariate responses.  There also are
empirical coverage tests that test a similar hypothesis among multiple
samples but only for univariate responses.  Both are included in the USGS
Blossom package for R linked here:
https://www.fort.usgs.gov/products/23735 (not
yet distributed via CRAN).  The MRPP may also be available in other R
packages on CRAN (vegan ?).

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326


On Fri, May 29, 2015 at 10:31 AM, Wensui Liu <liuwensui at gmail.com> wrote:

> Good morning, All
> I have a stat question not specifically related to the the programming
> language.
> To compare distributional consistency / discrepancy between two
> samples, we usually use kolmogorov-smirnov test, which is implemented
> in R with ks.test() or in SAS with "pro npar1way edf".
> I am wondering if there is any alternative to KS test that could be
> generalized to K-samples.
>
> Thanks and have a nice weekend.
>
> wensui
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Fri May 29 19:27:23 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 29 May 2015 17:27:23 +0000
Subject: [R] Converting unique strings to unique numbers
In-Reply-To: <CAE6QMsbz8P2T4PuXEzThewAhRbBiLeg+ifGQ5cd1RxKbZAAyFQ@mail.gmail.com>
References: <CAE6QMsbz8P2T4PuXEzThewAhRbBiLeg+ifGQ5cd1RxKbZAAyFQ@mail.gmail.com>
Message-ID: <D18DEF2D.12C4A3%macqueen1@llnl.gov>

Here is an example to get you started:

mycol <- c('b','a','d','d','b','c')
as.numeric(factor(mycol))

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/29/15, 9:58 AM, "Kate Ignatius" <kate.ignatius at gmail.com> wrote:

>I have a pedigree file as so:
>
>X0001 BYX859      0      0  2  1 BYX859
>X0001 BYX894      0      0  1  1 BYX894
>X0001 BYX862 BYX894 BYX859  2  2 BYX862
>X0001 BYX863 BYX894 BYX859  2  2 BYX863
>X0001 BYX864 BYX894 BYX859  2  2 BYX864
>X0001 BYX865 BYX894 BYX859  2  2 BYX865
>
>And I was hoping to change all unique string values to numbers.
>
>That is:
>
>BYX859 = 1
>BYX894 = 2
>BYX862 = 3
>BYX863 = 4
>BYX864 = 5
>BYX865 = 6
>
>But only in columns 2 - 4.  Essentially I would like the data to look
>like this:
>
>X0001 1 0 0  2  1 BYX859
>X0001 2 0 0  1  1 BYX894
>X0001 3 2 1  2  2 BYX862
>X0001 4 2 1  2  2 BYX863
>X0001 5 2 1  2  2 BYX864
>X0001 6 2 1  2  2 BYX865
>
>Is this possible with factors?
>
>Thanks!
>
>K.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Fri May 29 19:27:21 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 29 May 2015 10:27:21 -0700
Subject: [R] Converting unique strings to unique numbers
In-Reply-To: <CAE6QMsbz8P2T4PuXEzThewAhRbBiLeg+ifGQ5cd1RxKbZAAyFQ@mail.gmail.com>
References: <CAE6QMsbz8P2T4PuXEzThewAhRbBiLeg+ifGQ5cd1RxKbZAAyFQ@mail.gmail.com>
Message-ID: <614A9399-BB2C-4BEB-ACB1-DEFBB88DCD4E@dcn.davis.CA.us>

Of course, but I would not recommend it. A factor is a vector of integers with an attribute containing the labels that those integers correspond to. You seem to be asking for a factor that has lost the definitions part. But hey, newvector <- as.integer(factor(oldvector)) should get you what you asked for one column at a time.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 29, 2015 9:58:22 AM PDT, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>I have a pedigree file as so:
>
>X0001 BYX859      0      0  2  1 BYX859
>X0001 BYX894      0      0  1  1 BYX894
>X0001 BYX862 BYX894 BYX859  2  2 BYX862
>X0001 BYX863 BYX894 BYX859  2  2 BYX863
>X0001 BYX864 BYX894 BYX859  2  2 BYX864
>X0001 BYX865 BYX894 BYX859  2  2 BYX865
>
>And I was hoping to change all unique string values to numbers.
>
>That is:
>
>BYX859 = 1
>BYX894 = 2
>BYX862 = 3
>BYX863 = 4
>BYX864 = 5
>BYX865 = 6
>
>But only in columns 2 - 4.  Essentially I would like the data to look
>like this:
>
>X0001 1 0 0  2  1 BYX859
>X0001 2 0 0  1  1 BYX894
>X0001 3 2 1  2  2 BYX862
>X0001 4 2 1  2  2 BYX863
>X0001 5 2 1  2  2 BYX864
>X0001 6 2 1  2  2 BYX865
>
>Is this possible with factors?
>
>Thanks!
>
>K.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri May 29 19:31:09 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 29 May 2015 10:31:09 -0700
Subject: [R] Converting unique strings to unique numbers
In-Reply-To: <CAE6QMsbz8P2T4PuXEzThewAhRbBiLeg+ifGQ5cd1RxKbZAAyFQ@mail.gmail.com>
References: <CAE6QMsbz8P2T4PuXEzThewAhRbBiLeg+ifGQ5cd1RxKbZAAyFQ@mail.gmail.com>
Message-ID: <CAF8bMca-zbrhtEmA0dpN24byPueDXsvbNot0WF1ZK0yM_vRt0w@mail.gmail.com>

match() will do what you want.  E.g., run your data through
the following function.

f <- function (data)
{
    uniqStrings <- unique(c(data[, 2], data[, 3], data[, 4]))
    uniqStrings <- setdiff(uniqStrings, "0")
    for (j in 2:4) {
        data[[j]] <- match(data[[j]], uniqStrings, nomatch = 0L)
    }
    data
}



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, May 29, 2015 at 9:58 AM, Kate Ignatius <kate.ignatius at gmail.com>
wrote:

> I have a pedigree file as so:
>
> X0001 BYX859      0      0  2  1 BYX859
> X0001 BYX894      0      0  1  1 BYX894
> X0001 BYX862 BYX894 BYX859  2  2 BYX862
> X0001 BYX863 BYX894 BYX859  2  2 BYX863
> X0001 BYX864 BYX894 BYX859  2  2 BYX864
> X0001 BYX865 BYX894 BYX859  2  2 BYX865
>
> And I was hoping to change all unique string values to numbers.
>
> That is:
>
> BYX859 = 1
> BYX894 = 2
> BYX862 = 3
> BYX863 = 4
> BYX864 = 5
> BYX865 = 6
>
> But only in columns 2 - 4.  Essentially I would like the data to look like
> this:
>
> X0001 1 0 0  2  1 BYX859
> X0001 2 0 0  1  1 BYX894
> X0001 3 2 1  2  2 BYX862
> X0001 4 2 1  2  2 BYX863
> X0001 5 2 1  2  2 BYX864
> X0001 6 2 1  2  2 BYX865
>
> Is this possible with factors?
>
> Thanks!
>
> K.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri May 29 19:55:33 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 29 May 2015 17:55:33 +0000
Subject: [R] Why I am not able to load library(R.matlab)? Other packages
	are fine.
References: <CAE2FW2mSRPr5hGGGGKM1P4Pp4Ka4vHQsWKx86oFAQ+5rDoJimA@mail.gmail.com>
	<CAFDcVCRF3dChpgAoonZ+RtB1zywdYDD7x9LYAVKCJ7f82ZFbgw@mail.gmail.com>
	<CAE2FW2n2MyzFDDBV=MnP4jJYPR_AP4dTunHo+PA3J9udqufNfg@mail.gmail.com>
Message-ID: <loom.20150529T195442-623@post.gmane.org>

C W <tmrsg11 <at> gmail.com> writes:

> 
> Hi Henrik,
> 
> I don't quite get what I should do here.  I am not familiar with
> R.methodS3.  Can you tell me what command exactly do I need to do?
> 
> Thanks,
> 
> Mike

install.packages("R.methodsS3")
install.packages("R.matlab")
library("R.matlab")



  [snip snip snip]


From liuwensui at gmail.com  Fri May 29 19:58:29 2015
From: liuwensui at gmail.com (Wensui Liu)
Date: Fri, 29 May 2015 13:58:29 -0400
Subject: [R] alternatives to KS test applicable to K-samples
In-Reply-To: <CAM5M9BQzfdP9JKtKDvbd4uwHgjrNNwQDEOhi-q+cPhPHn26Jsg@mail.gmail.com>
References: <CAKyN3iBv73_FUsmH2S0nqsann4E-CqMPCt5+0XVwEX2PD50jzQ@mail.gmail.com>
	<CAM5M9BQzfdP9JKtKDvbd4uwHgjrNNwQDEOhi-q+cPhPHn26Jsg@mail.gmail.com>
Message-ID: <CAKyN3iC=8Y2HGsrs79mdPcudk1JQrcwgrk5nf_Vg=iKLscyzAg@mail.gmail.com>

Very nice, Brian

Sincerely appreciate your assistance!

On Friday, May 29, 2015, Cade, Brian <cadeb at usgs.gov> wrote:

> Wensui:  There are the multi-response permutation procedures (MRPP) that
> readily test the omnibus hypothesis of no distributional differences among
> multiple samples for univariate or multivariate responses.  There also are
> empirical coverage tests that test a similar hypothesis among multiple
> samples but only for univariate responses.  Both are included in the USGS
> Blossom package for R linked here:
> https://www.fort.usgs.gov/products/23735 (not yet distributed via CRAN).
> The MRPP may also be available in other R packages on CRAN (vegan ?).
>
> Brian
>
> Brian S. Cade, PhD
>
> U. S. Geological Survey
> Fort Collins Science Center
> 2150 Centre Ave., Bldg. C
> Fort Collins, CO  80526-8818
>
> email:  cadeb at usgs.gov
> <javascript:_e(%7B%7D,'cvml','brian_cade at usgs.gov');>
> tel:  970 226-9326
>
>
> On Fri, May 29, 2015 at 10:31 AM, Wensui Liu <liuwensui at gmail.com
> <javascript:_e(%7B%7D,'cvml','liuwensui at gmail.com');>> wrote:
>
>> Good morning, All
>> I have a stat question not specifically related to the the programming
>> language.
>> To compare distributional consistency / discrepancy between two
>> samples, we usually use kolmogorov-smirnov test, which is implemented
>> in R with ks.test() or in SAS with "pro npar1way edf".
>> I am wondering if there is any alternative to KS test that could be
>> generalized to K-samples.
>>
>> Thanks and have a nice weekend.
>>
>> wensui
>>
>> ______________________________________________
>> R-help at r-project.org
>> <javascript:_e(%7B%7D,'cvml','R-help at r-project.org');> mailing list --
>> To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

-- 
==============================
WenSui Liu
Credit Risk Manager, 53 Bancorp
wensui.liu at 53.com
513-295-4370
==============================

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Fri May 29 20:16:57 2015
From: hpages at fredhutch.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 29 May 2015 11:16:57 -0700
Subject: [R] Converting unique strings to unique numbers
In-Reply-To: <CAE6QMsbz8P2T4PuXEzThewAhRbBiLeg+ifGQ5cd1RxKbZAAyFQ@mail.gmail.com>
References: <CAE6QMsbz8P2T4PuXEzThewAhRbBiLeg+ifGQ5cd1RxKbZAAyFQ@mail.gmail.com>
Message-ID: <5568AD19.7020606@fredhutch.org>

Hi Kate,

I found that matching the character vector to itself is a very
effective way to do this:

   x <- c("a", "bunch", "of", "strings", "whose", "exact", "content",
          "is", "of", "little", "interest")
   ids <- match(x, x)
   ids
   # [1]  1  2  3  4  5  6  7  8  3 10 11

By using this trick, many manipulations on character vectors can
be replaced by manipulations on integer vectors, which are sometimes
way more efficient.

Cheers,
H.


On 05/29/2015 09:58 AM, Kate Ignatius wrote:
> I have a pedigree file as so:
>
> X0001 BYX859      0      0  2  1 BYX859
> X0001 BYX894      0      0  1  1 BYX894
> X0001 BYX862 BYX894 BYX859  2  2 BYX862
> X0001 BYX863 BYX894 BYX859  2  2 BYX863
> X0001 BYX864 BYX894 BYX859  2  2 BYX864
> X0001 BYX865 BYX894 BYX859  2  2 BYX865
>
> And I was hoping to change all unique string values to numbers.
>
> That is:
>
> BYX859 = 1
> BYX894 = 2
> BYX862 = 3
> BYX863 = 4
> BYX864 = 5
> BYX865 = 6
>
> But only in columns 2 - 4.  Essentially I would like the data to look like this:
>
> X0001 1 0 0  2  1 BYX859
> X0001 2 0 0  1  1 BYX894
> X0001 3 2 1  2  2 BYX862
> X0001 4 2 1  2  2 BYX863
> X0001 5 2 1  2  2 BYX864
> X0001 6 2 1  2  2 BYX865
>
> Is this possible with factors?
>
> Thanks!
>
> K.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From kate.ignatius at gmail.com  Fri May 29 20:30:26 2015
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Fri, 29 May 2015 14:30:26 -0400
Subject: [R] Converting unique strings to unique numbers
In-Reply-To: <CAF8bMca-zbrhtEmA0dpN24byPueDXsvbNot0WF1ZK0yM_vRt0w@mail.gmail.com>
References: <CAE6QMsbz8P2T4PuXEzThewAhRbBiLeg+ifGQ5cd1RxKbZAAyFQ@mail.gmail.com>
	<CAF8bMca-zbrhtEmA0dpN24byPueDXsvbNot0WF1ZK0yM_vRt0w@mail.gmail.com>
Message-ID: <CAE6QMsZPnU-gj8LAeHhSj2VAFwHan1Z-uG+wMen6GLY7vG5yew@mail.gmail.com>

I found this helpful.  However - the second to forth columns come out
all zero - was this the intention?

That is:

X0001 0 0 0  2  1 BYX859
X0001 0 0 0  1  1 BYX894
X0001 0 0 0  2  2 BYX862
X0001 0 0 0  2  2 BYX863
X0001 0 0 0  2  2 BYX864
X0001 0 0 0  2  2 BYX865

On Fri, May 29, 2015 at 1:31 PM, William Dunlap <wdunlap at tibco.com> wrote:
> match() will do what you want.  E.g., run your data through
> the following function.
>
> f <- function (data)
> {
>     uniqStrings <- unique(c(data[, 2], data[, 3], data[, 4]))
>     uniqStrings <- setdiff(uniqStrings, "0")
>     for (j in 2:4) {
>         data[[j]] <- match(data[[j]], uniqStrings, nomatch = 0L)
>     }
>     data
> }
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, May 29, 2015 at 9:58 AM, Kate Ignatius <kate.ignatius at gmail.com>
> wrote:
>>
>> I have a pedigree file as so:
>>
>> X0001 BYX859      0      0  2  1 BYX859
>> X0001 BYX894      0      0  1  1 BYX894
>> X0001 BYX862 BYX894 BYX859  2  2 BYX862
>> X0001 BYX863 BYX894 BYX859  2  2 BYX863
>> X0001 BYX864 BYX894 BYX859  2  2 BYX864
>> X0001 BYX865 BYX894 BYX859  2  2 BYX865
>>
>> And I was hoping to change all unique string values to numbers.
>>
>> That is:
>>
>> BYX859 = 1
>> BYX894 = 2
>> BYX862 = 3
>> BYX863 = 4
>> BYX864 = 5
>> BYX865 = 6
>>
>> But only in columns 2 - 4.  Essentially I would like the data to look like
>> this:
>>
>> X0001 1 0 0  2  1 BYX859
>> X0001 2 0 0  1  1 BYX894
>> X0001 3 2 1  2  2 BYX862
>> X0001 4 2 1  2  2 BYX863
>> X0001 5 2 1  2  2 BYX864
>> X0001 6 2 1  2  2 BYX865
>>
>> Is this possible with factors?
>>
>> Thanks!
>>
>> K.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From dwinsemius at comcast.net  Fri May 29 20:32:23 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 29 May 2015 11:32:23 -0700
Subject: [R] alternatives to KS test applicable to K-samples
In-Reply-To: <CAKyN3iBv73_FUsmH2S0nqsann4E-CqMPCt5+0XVwEX2PD50jzQ@mail.gmail.com>
References: <CAKyN3iBv73_FUsmH2S0nqsann4E-CqMPCt5+0XVwEX2PD50jzQ@mail.gmail.com>
Message-ID: <F58B52FA-FC39-4C4B-87C1-3D2F388F424F@comcast.net>


On May 29, 2015, at 9:31 AM, Wensui Liu wrote:

> Good morning, All
> I have a stat question not specifically related to the the programming language.
> To compare distributional consistency / discrepancy between two
> samples, we usually use kolmogorov-smirnov test, which is implemented
> in R with ks.test() or in SAS with "pro npar1way edf".
> I am wondering if there is any alternative to KS test that could be
> generalized to K-samples.

The 'coin' package (Hothorn, Hornick, van de Weil, and Zeileis) presents a variety of permutation and rank-based tests that would probably be more powerful than any multi-group variant of the KS test. The multi-group variant of the Wilcoxon Rank Sum Test presented in the examples for the help page: ?wilcox_test is the Nemenyi-Damico-Wolfe-Dunn test.

-- 

David Winsemius
Alameda, CA, USA


From SYLensing at uams.edu  Fri May 29 20:36:19 2015
From: SYLensing at uams.edu (Lensing, Shelly Y)
Date: Fri, 29 May 2015 18:36:19 +0000
Subject: [R] Result differences in 32-bit vs. 64-bit point.in.polygon?
Message-ID: <71a860b9eb4f44e494dce127b1db35e7@MAIL13M3N2.ad.uams.edu>

Is anyone aware of point.in.polygon giving different results for 32-bit vs. 64-bit R? Our OS is 64-bit Windows 7 Enterprise. I'm working with someone else's extensive R program and the final results are close but not exactly matching. We're thinking it might be something with the point.in.polygon function (one of many possibilities, including leaps).

Thanks much,

Shelly Lensing
Biostatistics / University of Arkansas for Medical Sciences
4301 W. Markham St. #781 / Little Rock, AR  72205
V: 501.686.8203 / F: 501-526-6729 / COPH 3236

----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including a...{{dropped:10}}


From sarah.goslee at gmail.com  Fri May 29 21:04:25 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 29 May 2015 15:04:25 -0400
Subject: [R] Converting unique strings to unique numbers
In-Reply-To: <5568AD19.7020606@fredhutch.org>
References: <CAE6QMsbz8P2T4PuXEzThewAhRbBiLeg+ifGQ5cd1RxKbZAAyFQ@mail.gmail.com>
	<5568AD19.7020606@fredhutch.org>
Message-ID: <CAM_vjum9u394LkEwikvqz78FHzifSjAH7jVti+GxN3riDxMDtw@mail.gmail.com>

On Fri, May 29, 2015 at 2:16 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
> Hi Kate,
>
> I found that matching the character vector to itself is a very
> effective way to do this:
>
>   x <- c("a", "bunch", "of", "strings", "whose", "exact", "content",
>          "is", "of", "little", "interest")
>   ids <- match(x, x)
>   ids
>   # [1]  1  2  3  4  5  6  7  8  3 10 11
>
> By using this trick, many manipulations on character vectors can
> be replaced by manipulations on integer vectors, which are sometimes
> way more efficient.

Hm. I hadn't thought of that approach - I use the
as.numeric(factor(...)) approach.

So I was curious, and compared the two:


set.seed(43)
x <- sample(letters, 10000, replace=TRUE)

system.time({
  for(i in seq_len(20000)) {
  ids1 <- match(x, x)
}})

#   user  system elapsed
#  9.657   0.000   9.657

system.time({
  for(i in seq_len(20000)) {
  ids2 <- as.numeric(factor(x, levels=letters))
}})

#   user  system elapsed
#   6.16    0.00    6.16

Using factor() is faster. More importantly, using factor() lets you
set the order of the indices in an expected fashion, where match()
assigns them in the order of occurrence.

head(data.frame(x, ids1, ids2))

  x ids1 ids2
1 m    1   13
2 x    2   24
3 b    3    2
4 s    4   19
5 i    5    9
6 o    6   15

In a problem like Kate's where there are several columns for which the
same ordering of indices is desired, that becomes really important.

If you take Bill Dunlap's modification of the match() approach, it
resolves both problems: matching against the pooled unique values is
both faster than the factor() version and gives the same result:


On Fri, May 29, 2015 at 1:31 PM, William Dunlap <wdunlap at tibco.com> wrote:
> match() will do what you want.  E.g., run your data through
> the following function.
>
f <- function (data)
{
    uniqStrings <- unique(c(data[, 2], data[, 3], data[, 4]))
    uniqStrings <- setdiff(uniqStrings, "0")
    for (j in 2:4) {
        data[[j]] <- match(data[[j]], uniqStrings, nomatch = 0L)
    }
    data
}

##

y <- data.frame(id = 1:5000, v1 = sample(letters, 5000, replace=TRUE),
v2 = sample(letters, 5000, replace=TRUE), v3 = sample(letters, 5000,
replace=TRUE), stringsAsFactors=FALSE)


system.time({
  for(i in seq_len(20000)) {
    ids3 <- f(data.frame(y))
}})

#   user  system elapsed
# 22.515   0.000  22.518



ff <- function(data)
{
    uniqStrings <- unique(c(data[, 2], data[, 3], data[, 4]))
    uniqStrings <- setdiff(uniqStrings, "0")
    for (j in 2:4) {
        data[[j]] <- as.numeric(factor(data[[j]], levels=uniqStrings))
    }
    data
}

system.time({
  for(i in seq_len(20000)) {
    ids4 <- ff(data.frame(y))
}})

#    user  system elapsed
#  26.083   0.002  26.090

head(ids3)

  id v1 v2 v3
1  1  1  2  8
2  2  2 19 22
3  3  3 21 16
4  4  4 10 17
5  5  1  8 18
6  6  1 12 26

head(ids4)

  id v1 v2 v3
1  1  1  2  8
2  2  2 19 22
3  3  3 21 16
4  4  4 10 17
5  5  1  8 18
6  6  1 12 26

Kate, if you're getting all zeros, check str(yourdataframe) - it's
likely that when you imported your data into R the strings were
already converted to factors, which is not what you want (ask me how I
know this!).

Sarah



> On 05/29/2015 09:58 AM, Kate Ignatius wrote:
>>
>> I have a pedigree file as so:
>>
>> X0001 BYX859      0      0  2  1 BYX859
>> X0001 BYX894      0      0  1  1 BYX894
>> X0001 BYX862 BYX894 BYX859  2  2 BYX862
>> X0001 BYX863 BYX894 BYX859  2  2 BYX863
>> X0001 BYX864 BYX894 BYX859  2  2 BYX864
>> X0001 BYX865 BYX894 BYX859  2  2 BYX865
>>
>> And I was hoping to change all unique string values to numbers.
>>
>> That is:
>>
>> BYX859 = 1
>> BYX894 = 2
>> BYX862 = 3
>> BYX863 = 4
>> BYX864 = 5
>> BYX865 = 6
>>
>> But only in columns 2 - 4.  Essentially I would like the data to look like
>> this:
>>
>> X0001 1 0 0  2  1 BYX859
>> X0001 2 0 0  1  1 BYX894
>> X0001 3 2 1  2  2 BYX862
>> X0001 4 2 1  2  2 BYX863
>> X0001 5 2 1  2  2 BYX864
>> X0001 6 2 1  2  2 BYX865
>>
>> Is this possible with factors?
>>
>> Thanks!
>>
>> K.
>>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From tonightsthenight at gmail.com  Fri May 29 21:51:40 2015
From: tonightsthenight at gmail.com (Sam Albers)
Date: Fri, 29 May 2015 12:51:40 -0700
Subject: [R] Automatically updating a plot from a regularly updated data file
Message-ID: <CADkXsV2G1-0Cz4qcdTD9XhapO6T6NQQJ+5npAgBAMTMkzGUWPQ@mail.gmail.com>

Hi all,

I have a question about using R in a way that may not be correct but I
thought I would ask anyway.

I have an instrument that outputs a text file with comma separated data. A
new line is added to the file each time the instrument takes a new reading.
Is there any way to configure R such that a script to generate a plot from
said text file is re-run each time the file is modified (i.e. a new line is
added). So basically update an exported plot each time a new line of data
is collected.

Is this type of thing possible in R? If not can anyone recommend some
Windows (or Linux if need be) tools that could help me accomplish this
preferably still utilizing R's plotting capabilites? I know that there are
other tools that can do this all but nothing makes figures as nicely as R.

I suppose more generally this is a question about way to automate processes
with R to take advantage of R's functionality.

Thanks in advance.

Sam

	[[alternative HTML version deleted]]


From tanasa at gmail.com  Fri May 29 22:19:25 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Fri, 29 May 2015 13:19:25 -0700
Subject: [R] about transforming a data.frame
Message-ID: <CA+JEM03i23EwH+n4vBM44_9=osoimk6P=KS8B8sLB6CzodO4oQ@mail.gmail.com>

Dear all,

I would appreciate a suggestion on the following : I am working with a
data.frame (below) :

  EXP    CT   row_names   col_names
1   test -5    B4:B5:B6    B1:B2:B3
2   test -2    B7:B8:B9    B1:B2:B3
3   test -2    D4:D5:D6    H4:H5:H6
4   test -2    D10:D11:D12 F10:F11:F12
5   test -2    D10:D11:D12    H1:H2:H3
6   test -2    E10:E11:E12    G7:G8:G9
7   test -4     A1:A2:A3    D1:D2:D3
8   test -4   B10:B11:B12    B1:B2:B3

what would be the easiest way to consider UNIQUE elements in the ROW_NAMES
or the UNIQUE elements in the COL_NAMES and :

print how many times these UNIQUE ELEMENTS associate with the numbers -5,
-2, or -4 (these numbers are on the column names CT) ..

thanks,

bogdan

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Fri May 29 22:29:49 2015
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 29 May 2015 13:29:49 -0700
Subject: [R] Converting unique strings to unique numbers
In-Reply-To: <CAM_vjum9u394LkEwikvqz78FHzifSjAH7jVti+GxN3riDxMDtw@mail.gmail.com>
References: <CAE6QMsbz8P2T4PuXEzThewAhRbBiLeg+ifGQ5cd1RxKbZAAyFQ@mail.gmail.com>	<5568AD19.7020606@fredhutch.org>
	<CAM_vjum9u394LkEwikvqz78FHzifSjAH7jVti+GxN3riDxMDtw@mail.gmail.com>
Message-ID: <5568CC3D.5050709@fredhutch.org>

Hi Sarah,

On 05/29/2015 12:04 PM, Sarah Goslee wrote:
> On Fri, May 29, 2015 at 2:16 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
>> Hi Kate,
>>
>> I found that matching the character vector to itself is a very
>> effective way to do this:
>>
>>    x <- c("a", "bunch", "of", "strings", "whose", "exact", "content",
>>           "is", "of", "little", "interest")
>>    ids <- match(x, x)
>>    ids
>>    # [1]  1  2  3  4  5  6  7  8  3 10 11
>>
>> By using this trick, many manipulations on character vectors can
>> be replaced by manipulations on integer vectors, which are sometimes
>> way more efficient.
>
> Hm. I hadn't thought of that approach - I use the
> as.numeric(factor(...)) approach.
>
> So I was curious, and compared the two:
>
>
> set.seed(43)
> x <- sample(letters, 10000, replace=TRUE)
>
> system.time({
>    for(i in seq_len(20000)) {
>    ids1 <- match(x, x)
> }})
>
> #   user  system elapsed
> #  9.657   0.000   9.657
>
> system.time({
>    for(i in seq_len(20000)) {
>    ids2 <- as.numeric(factor(x, levels=letters))
> }})
>
> #   user  system elapsed
> #   6.16    0.00    6.16
>
> Using factor() is faster.

That's an unfair comparison, because you already know what the levels
are so you can supply them to your call to factor(). Most of the time
you don't know what the levels are so either you just do factor(x) and
let the factor() constructor compute the levels for you, or you compute
them yourself upfront with something like factor(x, levels=unique(x)).

   library(microbenchmark)

   microbenchmark(
     {ids1 <- match(x, x)},
     {ids2 <- as.integer(factor(x, levels=letters))},
     {ids3 <- as.integer(factor(x))},
     {ids4 <- as.integer(factor(x, levels=unique(x)))}
   )
   Unit: microseconds
                                                       expr     min       lq
                                {     ids1 <- match(x, x) } 245.979 262.2390
    {     ids2 <- as.integer(factor(x, levels = letters)) } 214.115 219.2320
                      {     ids3 <- as.integer(factor(x)) } 380.782 388.7295
  {     ids4 <- as.integer(factor(x, levels = unique(x))) } 332.250 342.6630
        mean   median      uq     max neval
    267.3210 264.4845 268.348 293.894   100
    226.9913 220.9870 226.147 314.875   100
    402.2242 394.7165 412.075 481.410   100
    349.7405 345.3090 353.162 383.002   100

> More importantly, using factor() lets you
> set the order of the indices in an expected fashion, where match()
> assigns them in the order of occurrence.
>
> head(data.frame(x, ids1, ids2))
>
>    x ids1 ids2
> 1 m    1   13
> 2 x    2   24
> 3 b    3    2
> 4 s    4   19
> 5 i    5    9
> 6 o    6   15
>
> In a problem like Kate's where there are several columns for which the
> same ordering of indices is desired, that becomes really important.

I'm not sure why which particular ID gets assigned to each string would
matter but maybe I'm missing something. What really matters is that each
string receives a unique ID. match(x, x) does that.

In Kate's problem, where the strings are in more than one column,
and you want the ID to be unique across the columns, you need to do
match(x, x) where 'x' contains the strings from all the columns
that you want to replace:

   m <- matrix(c(
     "X0001", "BYX859",        0,        0,  2,  1, "BYX859",
     "X0001", "BYX894",        0,        0,  1,  1, "BYX894",
     "X0001", "BYX862", "BYX894", "BYX859",  2,  2, "BYX862",
     "X0001", "BYX863", "BYX894", "BYX859",  2,  2, "BYX863",
     "X0001", "BYX864", "BYX894", "BYX859",  2,  2, "BYX864",
     "X0001", "BYX865", "BYX894", "BYX859",  2,  2, "BYX865"
   ), ncol=7, byrow=TRUE)

   x <- m[ , 2:4]
   id <- match(x, x, nomatch=0, incomparables="0")
   m[ , 2:4] <- id

No factor needed. No loop needed. ;-)

Cheers,
H.

>
> If you take Bill Dunlap's modification of the match() approach, it
> resolves both problems: matching against the pooled unique values is
> both faster than the factor() version and gives the same result:
>
>
> On Fri, May 29, 2015 at 1:31 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> match() will do what you want.  E.g., run your data through
>> the following function.
>>
> f <- function (data)
> {
>      uniqStrings <- unique(c(data[, 2], data[, 3], data[, 4]))
>      uniqStrings <- setdiff(uniqStrings, "0")
>      for (j in 2:4) {
>          data[[j]] <- match(data[[j]], uniqStrings, nomatch = 0L)
>      }
>      data
> }
>
> ##
>
> y <- data.frame(id = 1:5000, v1 = sample(letters, 5000, replace=TRUE),
> v2 = sample(letters, 5000, replace=TRUE), v3 = sample(letters, 5000,
> replace=TRUE), stringsAsFactors=FALSE)
>
>
> system.time({
>    for(i in seq_len(20000)) {
>      ids3 <- f(data.frame(y))
> }})
>
> #   user  system elapsed
> # 22.515   0.000  22.518
>
>
>
> ff <- function(data)
> {
>      uniqStrings <- unique(c(data[, 2], data[, 3], data[, 4]))
>      uniqStrings <- setdiff(uniqStrings, "0")
>      for (j in 2:4) {
>          data[[j]] <- as.numeric(factor(data[[j]], levels=uniqStrings))
>      }
>      data
> }
>
> system.time({
>    for(i in seq_len(20000)) {
>      ids4 <- ff(data.frame(y))
> }})
>
> #    user  system elapsed
> #  26.083   0.002  26.090
>
> head(ids3)
>
>    id v1 v2 v3
> 1  1  1  2  8
> 2  2  2 19 22
> 3  3  3 21 16
> 4  4  4 10 17
> 5  5  1  8 18
> 6  6  1 12 26
>
> head(ids4)
>
>    id v1 v2 v3
> 1  1  1  2  8
> 2  2  2 19 22
> 3  3  3 21 16
> 4  4  4 10 17
> 5  5  1  8 18
> 6  6  1 12 26
>
> Kate, if you're getting all zeros, check str(yourdataframe) - it's
> likely that when you imported your data into R the strings were
> already converted to factors, which is not what you want (ask me how I
> know this!).
>
> Sarah
>
>
>
>> On 05/29/2015 09:58 AM, Kate Ignatius wrote:
>>>
>>> I have a pedigree file as so:
>>>
>>> X0001 BYX859      0      0  2  1 BYX859
>>> X0001 BYX894      0      0  1  1 BYX894
>>> X0001 BYX862 BYX894 BYX859  2  2 BYX862
>>> X0001 BYX863 BYX894 BYX859  2  2 BYX863
>>> X0001 BYX864 BYX894 BYX859  2  2 BYX864
>>> X0001 BYX865 BYX894 BYX859  2  2 BYX865
>>>
>>> And I was hoping to change all unique string values to numbers.
>>>
>>> That is:
>>>
>>> BYX859 = 1
>>> BYX894 = 2
>>> BYX862 = 3
>>> BYX863 = 4
>>> BYX864 = 5
>>> BYX865 = 6
>>>
>>> But only in columns 2 - 4.  Essentially I would like the data to look like
>>> this:
>>>
>>> X0001 1 0 0  2  1 BYX859
>>> X0001 2 0 0  1  1 BYX894
>>> X0001 3 2 1  2  2 BYX862
>>> X0001 4 2 1  2  2 BYX863
>>> X0001 5 2 1  2  2 BYX864
>>> X0001 6 2 1  2  2 BYX865
>>>
>>> Is this possible with factors?
>>>
>>> Thanks!
>>>
>>> K.
>>>
>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From sarah.goslee at gmail.com  Fri May 29 22:32:45 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 29 May 2015 16:32:45 -0400
Subject: [R] about transforming a data.frame
In-Reply-To: <CA+JEM03i23EwH+n4vBM44_9=osoimk6P=KS8B8sLB6CzodO4oQ@mail.gmail.com>
References: <CA+JEM03i23EwH+n4vBM44_9=osoimk6P=KS8B8sLB6CzodO4oQ@mail.gmail.com>
Message-ID: <CAM_vju=x8yOj5o9gRPx=nnaTQitDb9ueexf65F+Eg8DNJp0z2g@mail.gmail.com>

Hi,

Please use dput() to provide your data, as it can get somewhat mangled
by copy and pasting, especially if you post in HTML (as you are asked
not to do in the posting guide).

What is a unique element? is "B4:B5:B6" an element, or are "B4" and
"B5" each elements? That is, what is the result you expect to obtain
for the sample data you provided?

What code have you tried? I would think table() might be involved, and
possibly strsplit(), but will refrain from putting more time into this
until you provide a reproducible dataset with dput() and some clearer
idea of your intent.

Sarah

On Fri, May 29, 2015 at 4:19 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> Dear all,
>
> I would appreciate a suggestion on the following : I am working with a
> data.frame (below) :
>
>   EXP    CT   row_names   col_names
> 1   test -5    B4:B5:B6    B1:B2:B3
> 2   test -2    B7:B8:B9    B1:B2:B3
> 3   test -2    D4:D5:D6    H4:H5:H6
> 4   test -2    D10:D11:D12 F10:F11:F12
> 5   test -2    D10:D11:D12    H1:H2:H3
> 6   test -2    E10:E11:E12    G7:G8:G9
> 7   test -4     A1:A2:A3    D1:D2:D3
> 8   test -4   B10:B11:B12    B1:B2:B3
>
> what would be the easiest way to consider UNIQUE elements in the ROW_NAMES
> or the UNIQUE elements in the COL_NAMES and :
>
> print how many times these UNIQUE ELEMENTS associate with the numbers -5,
> -2, or -4 (these numbers are on the column names CT) ..
>
> thanks,
>
> bogdan
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From wdunlap at tibco.com  Fri May 29 22:48:46 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 29 May 2015 13:48:46 -0700
Subject: [R] Converting unique strings to unique numbers
In-Reply-To: <5568CC3D.5050709@fredhutch.org>
References: <CAE6QMsbz8P2T4PuXEzThewAhRbBiLeg+ifGQ5cd1RxKbZAAyFQ@mail.gmail.com>
	<5568AD19.7020606@fredhutch.org>
	<CAM_vjum9u394LkEwikvqz78FHzifSjAH7jVti+GxN3riDxMDtw@mail.gmail.com>
	<5568CC3D.5050709@fredhutch.org>
Message-ID: <CAF8bMca=bunKEDBj37ibpHXGQ97bxO-7ke=PnE0O9kk0Wh7xhw@mail.gmail.com>

>I'm not sure why which particular ID gets assigned to each string would
>matter but maybe I'm missing something. What really matters is that each
>string receives a unique ID. match(x, x) does that.

I think each row of the OP's dataset represented an individual (column 2)
followed by its mother and father (columns 3 and 4).  I assume that the
marker "0" means that a parent is not in the dataset.  If you match against
the strings in column 2 only, in their original order, then the resulting
numbers
give the row number of an individual, making it straightforward to look up
information regarding the ancestors of an individual.  Hence the choice of
numeric ID's may be important.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, May 29, 2015 at 1:29 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:

> Hi Sarah,
>
> On 05/29/2015 12:04 PM, Sarah Goslee wrote:
>
>> On Fri, May 29, 2015 at 2:16 PM, Herv? Pag?s <hpages at fredhutch.org>
>> wrote:
>>
>>> Hi Kate,
>>>
>>> I found that matching the character vector to itself is a very
>>> effective way to do this:
>>>
>>>    x <- c("a", "bunch", "of", "strings", "whose", "exact", "content",
>>>           "is", "of", "little", "interest")
>>>    ids <- match(x, x)
>>>    ids
>>>    # [1]  1  2  3  4  5  6  7  8  3 10 11
>>>
>>> By using this trick, many manipulations on character vectors can
>>> be replaced by manipulations on integer vectors, which are sometimes
>>> way more efficient.
>>>
>>
>> Hm. I hadn't thought of that approach - I use the
>> as.numeric(factor(...)) approach.
>>
>> So I was curious, and compared the two:
>>
>>
>> set.seed(43)
>> x <- sample(letters, 10000, replace=TRUE)
>>
>> system.time({
>>    for(i in seq_len(20000)) {
>>    ids1 <- match(x, x)
>> }})
>>
>> #   user  system elapsed
>> #  9.657   0.000   9.657
>>
>> system.time({
>>    for(i in seq_len(20000)) {
>>    ids2 <- as.numeric(factor(x, levels=letters))
>> }})
>>
>> #   user  system elapsed
>> #   6.16    0.00    6.16
>>
>> Using factor() is faster.
>>
>
> That's an unfair comparison, because you already know what the levels
> are so you can supply them to your call to factor(). Most of the time
> you don't know what the levels are so either you just do factor(x) and
> let the factor() constructor compute the levels for you, or you compute
> them yourself upfront with something like factor(x, levels=unique(x)).
>
>   library(microbenchmark)
>
>   microbenchmark(
>     {ids1 <- match(x, x)},
>     {ids2 <- as.integer(factor(x, levels=letters))},
>     {ids3 <- as.integer(factor(x))},
>     {ids4 <- as.integer(factor(x, levels=unique(x)))}
>   )
>   Unit: microseconds
>                                                       expr     min       lq
>                                {     ids1 <- match(x, x) } 245.979 262.2390
>    {     ids2 <- as.integer(factor(x, levels = letters)) } 214.115 219.2320
>                      {     ids3 <- as.integer(factor(x)) } 380.782 388.7295
>  {     ids4 <- as.integer(factor(x, levels = unique(x))) } 332.250 342.6630
>        mean   median      uq     max neval
>    267.3210 264.4845 268.348 293.894   100
>    226.9913 220.9870 226.147 314.875   100
>    402.2242 394.7165 412.075 481.410   100
>    349.7405 345.3090 353.162 383.002   100
>
>  More importantly, using factor() lets you
>> set the order of the indices in an expected fashion, where match()
>> assigns them in the order of occurrence.
>>
>> head(data.frame(x, ids1, ids2))
>>
>>    x ids1 ids2
>> 1 m    1   13
>> 2 x    2   24
>> 3 b    3    2
>> 4 s    4   19
>> 5 i    5    9
>> 6 o    6   15
>>
>> In a problem like Kate's where there are several columns for which the
>> same ordering of indices is desired, that becomes really important.
>>
>
> I'm not sure why which particular ID gets assigned to each string would
> matter but maybe I'm missing something. What really matters is that each
> string receives a unique ID. match(x, x) does that.
>
> In Kate's problem, where the strings are in more than one column,
> and you want the ID to be unique across the columns, you need to do
> match(x, x) where 'x' contains the strings from all the columns
> that you want to replace:
>
>   m <- matrix(c(
>     "X0001", "BYX859",        0,        0,  2,  1, "BYX859",
>     "X0001", "BYX894",        0,        0,  1,  1, "BYX894",
>     "X0001", "BYX862", "BYX894", "BYX859",  2,  2, "BYX862",
>     "X0001", "BYX863", "BYX894", "BYX859",  2,  2, "BYX863",
>     "X0001", "BYX864", "BYX894", "BYX859",  2,  2, "BYX864",
>     "X0001", "BYX865", "BYX894", "BYX859",  2,  2, "BYX865"
>   ), ncol=7, byrow=TRUE)
>
>   x <- m[ , 2:4]
>   id <- match(x, x, nomatch=0, incomparables="0")
>   m[ , 2:4] <- id
>
> No factor needed. No loop needed. ;-)
>
> Cheers,
> H.
>
>
>> If you take Bill Dunlap's modification of the match() approach, it
>> resolves both problems: matching against the pooled unique values is
>> both faster than the factor() version and gives the same result:
>>
>>
>> On Fri, May 29, 2015 at 1:31 PM, William Dunlap <wdunlap at tibco.com>
>> wrote:
>>
>>> match() will do what you want.  E.g., run your data through
>>> the following function.
>>>
>>>  f <- function (data)
>> {
>>      uniqStrings <- unique(c(data[, 2], data[, 3], data[, 4]))
>>      uniqStrings <- setdiff(uniqStrings, "0")
>>      for (j in 2:4) {
>>          data[[j]] <- match(data[[j]], uniqStrings, nomatch = 0L)
>>      }
>>      data
>> }
>>
>> ##
>>
>> y <- data.frame(id = 1:5000, v1 = sample(letters, 5000, replace=TRUE),
>> v2 = sample(letters, 5000, replace=TRUE), v3 = sample(letters, 5000,
>> replace=TRUE), stringsAsFactors=FALSE)
>>
>>
>> system.time({
>>    for(i in seq_len(20000)) {
>>      ids3 <- f(data.frame(y))
>> }})
>>
>> #   user  system elapsed
>> # 22.515   0.000  22.518
>>
>>
>>
>> ff <- function(data)
>> {
>>      uniqStrings <- unique(c(data[, 2], data[, 3], data[, 4]))
>>      uniqStrings <- setdiff(uniqStrings, "0")
>>      for (j in 2:4) {
>>          data[[j]] <- as.numeric(factor(data[[j]], levels=uniqStrings))
>>      }
>>      data
>> }
>>
>> system.time({
>>    for(i in seq_len(20000)) {
>>      ids4 <- ff(data.frame(y))
>> }})
>>
>> #    user  system elapsed
>> #  26.083   0.002  26.090
>>
>> head(ids3)
>>
>>    id v1 v2 v3
>> 1  1  1  2  8
>> 2  2  2 19 22
>> 3  3  3 21 16
>> 4  4  4 10 17
>> 5  5  1  8 18
>> 6  6  1 12 26
>>
>> head(ids4)
>>
>>    id v1 v2 v3
>> 1  1  1  2  8
>> 2  2  2 19 22
>> 3  3  3 21 16
>> 4  4  4 10 17
>> 5  5  1  8 18
>> 6  6  1 12 26
>>
>> Kate, if you're getting all zeros, check str(yourdataframe) - it's
>> likely that when you imported your data into R the strings were
>> already converted to factors, which is not what you want (ask me how I
>> know this!).
>>
>> Sarah
>>
>>
>>
>>  On 05/29/2015 09:58 AM, Kate Ignatius wrote:
>>>
>>>>
>>>> I have a pedigree file as so:
>>>>
>>>> X0001 BYX859      0      0  2  1 BYX859
>>>> X0001 BYX894      0      0  1  1 BYX894
>>>> X0001 BYX862 BYX894 BYX859  2  2 BYX862
>>>> X0001 BYX863 BYX894 BYX859  2  2 BYX863
>>>> X0001 BYX864 BYX894 BYX859  2  2 BYX864
>>>> X0001 BYX865 BYX894 BYX859  2  2 BYX865
>>>>
>>>> And I was hoping to change all unique string values to numbers.
>>>>
>>>> That is:
>>>>
>>>> BYX859 = 1
>>>> BYX894 = 2
>>>> BYX862 = 3
>>>> BYX863 = 4
>>>> BYX864 = 5
>>>> BYX865 = 6
>>>>
>>>> But only in columns 2 - 4.  Essentially I would like the data to look
>>>> like
>>>> this:
>>>>
>>>> X0001 1 0 0  2  1 BYX859
>>>> X0001 2 0 0  1  1 BYX894
>>>> X0001 3 2 1  2  2 BYX862
>>>> X0001 4 2 1  2  2 BYX863
>>>> X0001 5 2 1  2  2 BYX864
>>>> X0001 6 2 1  2  2 BYX865
>>>>
>>>> Is this possible with factors?
>>>>
>>>> Thanks!
>>>>
>>>> K.
>>>>
>>>>
>>
>>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From tanasa at gmail.com  Fri May 29 22:58:20 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Fri, 29 May 2015 13:58:20 -0700
Subject: [R] about transforming a data.frame
In-Reply-To: <CAM_vju=x8yOj5o9gRPx=nnaTQitDb9ueexf65F+Eg8DNJp0z2g@mail.gmail.com>
References: <CA+JEM03i23EwH+n4vBM44_9=osoimk6P=KS8B8sLB6CzodO4oQ@mail.gmail.com>
	<CAM_vju=x8yOj5o9gRPx=nnaTQitDb9ueexf65F+Eg8DNJp0z2g@mail.gmail.com>
Message-ID: <CA+JEM02ptDsO3gq_1-a4_F2feSdxKzker5mM914rmAbvodXc3Q@mail.gmail.com>

Hi Sarah,

thank you for your help. I have simplified the example, by reading the
elements in a data frame, eg :

df <- data.frame (row_names = c("B4:B5:B6", "B7:B8:B9", "D4:D5:D6",
"D10:D11:D12", "D10:D11:D12", "E10:E11:E12", "A1:A2:A3", "B10:B11:B12"),
col_names = c
("B1:B2:B3","B1:B2:B3","H4:H5:H6","F10:F11:F12","H1:H2:H3","G7:G8:G9","D1:D2:D3","B1:B2:B3"),
CT = c(5,2,2,2,2,2,4,4) )

I have used the the count() in the plyr package :

count_row_names <- count(df$row_names)
count_col_names <- count(df$col_names)

however, I would need to correlate these UNIQUE ELEMENTS in the columns
"row_names" or "col_names" with the numbers they associate in the  CT
columns, eg :

""B1:B2:B3" associate with "5, 2, 4" (in CT column), or "D10:D11:D12"
associate with "2" (in the CT column).

thank you very much,

bogdan




On Fri, May 29, 2015 at 1:32 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Hi,
>
> Please use dput() to provide your data, as it can get somewhat mangled
> by copy and pasting, especially if you post in HTML (as you are asked
> not to do in the posting guide).
>
> What is a unique element? is "B4:B5:B6" an element, or are "B4" and
> "B5" each elements? That is, what is the result you expect to obtain
> for the sample data you provided?
>
> What code have you tried? I would think table() might be involved, and
> possibly strsplit(), but will refrain from putting more time into this
> until you provide a reproducible dataset with dput() and some clearer
> idea of your intent.
>
> Sarah
>
> On Fri, May 29, 2015 at 4:19 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> > Dear all,
> >
> > I would appreciate a suggestion on the following : I am working with a
> > data.frame (below) :
> >
> >   EXP    CT   row_names   col_names
> > 1   test -5    B4:B5:B6    B1:B2:B3
> > 2   test -2    B7:B8:B9    B1:B2:B3
> > 3   test -2    D4:D5:D6    H4:H5:H6
> > 4   test -2    D10:D11:D12 F10:F11:F12
> > 5   test -2    D10:D11:D12    H1:H2:H3
> > 6   test -2    E10:E11:E12    G7:G8:G9
> > 7   test -4     A1:A2:A3    D1:D2:D3
> > 8   test -4   B10:B11:B12    B1:B2:B3
> >
> > what would be the easiest way to consider UNIQUE elements in the
> ROW_NAMES
> > or the UNIQUE elements in the COL_NAMES and :
> >
> > print how many times these UNIQUE ELEMENTS associate with the numbers -5,
> > -2, or -4 (these numbers are on the column names CT) ..
> >
> > thanks,
> >
> > bogdan
> >
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Fri May 29 23:11:43 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 29 May 2015 13:11:43 -0800
Subject: [R] about transforming a data.frame
In-Reply-To: <CA+JEM02ptDsO3gq_1-a4_F2feSdxKzker5mM914rmAbvodXc3Q@mail.gmail.com>
References: <cam_vju=x8yoj5o9grpx=nnatqitdb9ueexf65f+eg8dnjp0z2g@mail.gmail.com>
	<ca+jem03i23ewh+n4vbm44_9=osoimk6p=ks8b8slb6czodo4oq@mail.gmail.com>
Message-ID: <82824615D6C.00000F5Djrkrideau@inbox.com>

Bogdan, the request was for data in dput() format. 

Type ?dput for more information.

Do dput(myfile) copy the ouput and paste into the email

You should get something like: 
structure(list(c1 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 
2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 
5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 
8L, 8L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L), .Label = c("(0.509,0.614]", 
"(0.614,0.718]", "(0.718,0.822]", "(0.822,0.926]", "(0.926,1.03]", 
"(1.03,1.13]", "(1.13,1.24]", "(1.24,1.34]", "(1.34,1.45]", "(1.45,1.55]"
), class = "factor"), s1 = c(0.51, 0.52, 0.58, 0.58, 0.59, 0.6, 
0.63, 0.65, 0.68, 0.74, 0.74, 0.75, 0.77, 0.77, 0.77, 0.78, 0.79, 
0.84, 0.84, 0.85, 0.87, 0.93, 0.93, 0.95, 0.99, 1.04, 1.09, 1.11, 
1.13, 1.14, 1.14, 1.14, 1.17, 1.18, 1.19, 1.22, 1.22, 1.23, 1.28, 
1.29, 1.3, 1.32, 1.37, 1.38, 1.38, 1.4, 1.43, 1.47, 1.52, 1.55
)), .Names = c("c1", "s1"), row.names = c(NA, -50L), class = "data.frame")

Data in duput() format is the preferred way to get data in R-help since it provides a perfect copy of what you have on your machine.  Any other way of providing data risks the recipients reading it into R differently than it is on your machine.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: tanasa at gmail.com
> Sent: Fri, 29 May 2015 13:58:20 -0700
> To: sarah.goslee at gmail.com
> Subject: Re: [R] about transforming a data.frame
> 
> Hi Sarah,
> 
> thank you for your help. I have simplified the example, by reading the
> elements in a data frame, eg :
> 
> df <- data.frame (row_names = c("B4:B5:B6", "B7:B8:B9", "D4:D5:D6",
> "D10:D11:D12", "D10:D11:D12", "E10:E11:E12", "A1:A2:A3", "B10:B11:B12"),
> col_names = c
> ("B1:B2:B3","B1:B2:B3","H4:H5:H6","F10:F11:F12","H1:H2:H3","G7:G8:G9","D1:D2:D3","B1:B2:B3"),
> CT = c(5,2,2,2,2,2,4,4) )
> 
> I have used the the count() in the plyr package :
> 
> count_row_names <- count(df$row_names)
> count_col_names <- count(df$col_names)
> 
> however, I would need to correlate these UNIQUE ELEMENTS in the columns
> "row_names" or "col_names" with the numbers they associate in the  CT
> columns, eg :
> 
> ""B1:B2:B3" associate with "5, 2, 4" (in CT column), or "D10:D11:D12"
> associate with "2" (in the CT column).
> 
> thank you very much,
> 
> bogdan
> 
> 
> 
> 
> On Fri, May 29, 2015 at 1:32 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
> 
>> Hi,
>> 
>> Please use dput() to provide your data, as it can get somewhat mangled
>> by copy and pasting, especially if you post in HTML (as you are asked
>> not to do in the posting guide).
>> 
>> What is a unique element? is "B4:B5:B6" an element, or are "B4" and
>> "B5" each elements? That is, what is the result you expect to obtain
>> for the sample data you provided?
>> 
>> What code have you tried? I would think table() might be involved, and
>> possibly strsplit(), but will refrain from putting more time into this
>> until you provide a reproducible dataset with dput() and some clearer
>> idea of your intent.
>> 
>> Sarah
>> 
>> On Fri, May 29, 2015 at 4:19 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
>>> Dear all,
>>> 
>>> I would appreciate a suggestion on the following : I am working with a
>>> data.frame (below) :
>>> 
>>>   EXP    CT   row_names   col_names
>>> 1   test -5    B4:B5:B6    B1:B2:B3
>>> 2   test -2    B7:B8:B9    B1:B2:B3
>>> 3   test -2    D4:D5:D6    H4:H5:H6
>>> 4   test -2    D10:D11:D12 F10:F11:F12
>>> 5   test -2    D10:D11:D12    H1:H2:H3
>>> 6   test -2    E10:E11:E12    G7:G8:G9
>>> 7   test -4     A1:A2:A3    D1:D2:D3
>>> 8   test -4   B10:B11:B12    B1:B2:B3
>>> 
>>> what would be the easiest way to consider UNIQUE elements in the
>> ROW_NAMES
>>> or the UNIQUE elements in the COL_NAMES and :
>>> 
>>> print how many times these UNIQUE ELEMENTS associate with the numbers
>>> -5,
>>> -2, or -4 (these numbers are on the column names CT) ..
>>> 
>>> thanks,
>>> 
>>> bogdan
>>> 
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From tmrsg11 at gmail.com  Fri May 29 23:11:46 2015
From: tmrsg11 at gmail.com (C W)
Date: Fri, 29 May 2015 17:11:46 -0400
Subject: [R] Why I am not able to load library(R.matlab)? Other packages
 are fine.
In-Reply-To: <loom.20150529T195442-623@post.gmane.org>
References: <CAE2FW2mSRPr5hGGGGKM1P4Pp4Ka4vHQsWKx86oFAQ+5rDoJimA@mail.gmail.com>
	<CAFDcVCRF3dChpgAoonZ+RtB1zywdYDD7x9LYAVKCJ7f82ZFbgw@mail.gmail.com>
	<CAE2FW2n2MyzFDDBV=MnP4jJYPR_AP4dTunHo+PA3J9udqufNfg@mail.gmail.com>
	<loom.20150529T195442-623@post.gmane.org>
Message-ID: <CAE2FW2nCr4_AW-MSkQqWzs02TbFsathZpm0vT65SWWDT4dc7oQ@mail.gmail.com>

Wow, thanks Ben.  That worked very well.

I guess I didn't have R.methodS3?  But that doesn't make sense, because I
was using R.matlab few weeks ago.  I believe I was on R 3.1.

Maybe it's in R 3.1 folder?  I am using a Mac, btw.

Cheers,

-M

On Fri, May 29, 2015 at 1:55 PM, Ben Bolker <bbolker at gmail.com> wrote:

> C W <tmrsg11 <at> gmail.com> writes:
>
> >
> > Hi Henrik,
> >
> > I don't quite get what I should do here.  I am not familiar with
> > R.methodS3.  Can you tell me what command exactly do I need to do?
> >
> > Thanks,
> >
> > Mike
>
> install.packages("R.methodsS3")
> install.packages("R.matlab")
> library("R.matlab")
>
>
>
>   [snip snip snip]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri May 29 23:10:36 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 29 May 2015 17:10:36 -0400
Subject: [R] Why I am not able to load library(R.matlab)? Other packages
 are fine.
In-Reply-To: <CAE2FW2nCr4_AW-MSkQqWzs02TbFsathZpm0vT65SWWDT4dc7oQ@mail.gmail.com>
References: <CAE2FW2mSRPr5hGGGGKM1P4Pp4Ka4vHQsWKx86oFAQ+5rDoJimA@mail.gmail.com>
	<CAFDcVCRF3dChpgAoonZ+RtB1zywdYDD7x9LYAVKCJ7f82ZFbgw@mail.gmail.com>
	<CAE2FW2n2MyzFDDBV=MnP4jJYPR_AP4dTunHo+PA3J9udqufNfg@mail.gmail.com>
	<loom.20150529T195442-623@post.gmane.org>
	<CAE2FW2nCr4_AW-MSkQqWzs02TbFsathZpm0vT65SWWDT4dc7oQ@mail.gmail.com>
Message-ID: <5568D5CC.3050505@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

 I think Henrik's point (which I merely clarified) was that something
funky (we'll probably never know what, and it's not worth figuring out
unless it happens again/to other people) had gone wrong and that the
easiest thing to do was just to reinstall.

References:
* https://www.youtube.com/watch?v=t2F1rFmyQmY
*
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.208.9970&rep=rep1&type=pdf


On 15-05-29 05:11 PM, C W wrote:
> Wow, thanks Ben.  That worked very well.
> 
> I guess I didn't have R.methodS3?  But that doesn't make sense,
> because I was using R.matlab few weeks ago.  I believe I was on R
> 3.1.
> 
> Maybe it's in R 3.1 folder?  I am using a Mac, btw.
> 
> Cheers,
> 
> -M
> 
> On Fri, May 29, 2015 at 1:55 PM, Ben Bolker <bbolker at gmail.com>
> wrote:
> 
>> C W <tmrsg11 <at> gmail.com> writes:
>> 
>>> 
>>> Hi Henrik,
>>> 
>>> I don't quite get what I should do here.  I am not familiar
>>> with R.methodS3.  Can you tell me what command exactly do I
>>> need to do?
>>> 
>>> Thanks,
>>> 
>>> Mike
>> 
>> install.packages("R.methodsS3") install.packages("R.matlab") 
>> library("R.matlab")
>> 
>> 
>> 
>> [snip snip snip]
>> 
>> ______________________________________________ 
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read
>> the posting guide http://www.R-project.org/posting-guide.html and
>> provide commented, minimal, self-contained, reproducible code.
>> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVaNXMAAoJEOCV5YRblxUHj6kH/3W3etyn+HlT0X1PEj7DQf2c
Qo0q9ed2csPRLbLLrpX2FPKbxLg/g6MSxmIQ118tbWhkzKfRoyxCZHLcT+U2xLuR
V7QAS3Yns2ENSSSH1GvdSeFZTQWW3XFZN/kT+/zQYjaZewZOlo4Cgqc16c6mGBRS
eSIRIyA3iJWnMEc878nbMJztvsEqnpZSNSIXiI91UX/l8sDrBNYCNtfzY86JqJhp
8O0q7zkaRIrb6UuViY3qTC5+qpGruUYIUbeqyNei7MNErrG3AufsODfs5d/CjSCa
5jlbS512JRrQFV2JKHU+AH+4Q9CJQBVS+F6JZdjhHB2fUmAx0XIR6IJEBfSvBSk=
=nO+b
-----END PGP SIGNATURE-----


From macqueen1 at llnl.gov  Fri May 29 23:16:34 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 29 May 2015 21:16:34 +0000
Subject: [R] Automatically updating a plot from a regularly updated data
 file
In-Reply-To: <CADkXsV2G1-0Cz4qcdTD9XhapO6T6NQQJ+5npAgBAMTMkzGUWPQ@mail.gmail.com>
References: <CADkXsV2G1-0Cz4qcdTD9XhapO6T6NQQJ+5npAgBAMTMkzGUWPQ@mail.gmail.com>
Message-ID: <D18E1F64.12C50C%macqueen1@llnl.gov>

A lot will depend on how frequently data is added to the file, how big the
file gets, and how important it is to see updated plots quickly.

I have R doing exactly what you describe, and have found logic like this
(which might be described as crude) to be sufficient

while( {some condition} ) {
  {read the data file}
  {make the plot}
  Sys.sleep( {some number of seconds} )
}

Of course this is not actually noticing that the file has changed and
responding, it is just updating at regular intervals. But that might be
good enough.


A slightly more sophisticated approach would be to set up a loop like the
above, and have the sleep time short, but within the loop use

  file.info({the csv file})

and when the modification time is later than the previous modification
time, read the data and update the plot.


If the file gets really big, you might not want to reload the entire file
each time. That might lead you into things like keeping track of how many
lines the file has, and only reading the new lines -- if you need your
plots to be cumulative. In that situation you might end up using the
pipe() function to create your connection to the file, and pass the OS's
'tail' command (Linux or Mac, not sure about Win) to pipe.

If you only need to plot the last, say, X hours of data, then you may not
need to keep track of the number of lines, just read the last N lines
(hopefully not too hard to figure out what N should be).

If you don't want an R process running indefinitely, as is the case for
the above, you can, on Linux and Mac, set up a cron job to run an R script
as often as once per minute. I have at least one such task where it
happens every 2 minutes, and makes plots of the current data. In this
case, we have 16 measurement devices each sending data to a MySQL database
once per minute; the R script pulls the data from the database every 2
minutes and plots, and the system works well for our needs. Windows will
have some equivalent to cron, I just don't know what it is.

FWIW, all of the above write png files which are viewed via a webserver.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/29/15, 12:51 PM, "Sam Albers" <tonightsthenight at gmail.com> wrote:

>Hi all,
>
>I have a question about using R in a way that may not be correct but I
>thought I would ask anyway.
>
>I have an instrument that outputs a text file with comma separated data. A
>new line is added to the file each time the instrument takes a new
>reading.
>Is there any way to configure R such that a script to generate a plot from
>said text file is re-run each time the file is modified (i.e. a new line
>is
>added). So basically update an exported plot each time a new line of data
>is collected.
>
>Is this type of thing possible in R? If not can anyone recommend some
>Windows (or Linux if need be) tools that could help me accomplish this
>preferably still utilizing R's plotting capabilites? I know that there are
>other tools that can do this all but nothing makes figures as nicely as R.
>
>I suppose more generally this is a question about way to automate
>processes
>with R to take advantage of R's functionality.
>
>Thanks in advance.
>
>Sam
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tanasa at gmail.com  Fri May 29 23:16:47 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Fri, 29 May 2015 14:16:47 -0700
Subject: [R] about transforming a data.frame
In-Reply-To: <82824615D6C.00000F5Djrkrideau@inbox.com>
References: <cam_vju=x8yoj5o9grpx=nnatqitdb9ueexf65f+eg8dnjp0z2g@mail.gmail.com>
	<ca+jem03i23ewh+n4vbm44_9=osoimk6p=ks8b8slb6czodo4oq@mail.gmail.com>
	<CA+JEM02ptDsO3gq_1-a4_F2feSdxKzker5mM914rmAbvodXc3Q@mail.gmail.com>
	<82824615D6C.00000F5Djrkrideau@inbox.com>
Message-ID: <CA+JEM03ZaUWcDnj9RrXt56wjbwA2m+nDd8-deJ67scM1Sxz8Aw@mail.gmail.com>

Hi John,

thanks for clarifications, yes, of course, the dput() output is the
following :

dput(dataframe_matches_ddCT)

structure(list(FIGURE = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label
= "test", class = "factor"), ddCT = c(-5.4595, -2.7467,
-2.7467, -2.7467, -2.7467, -2.7467, -4.5927, -4.5927), row_names =
structure(c(1L, 2L, 3L, 4L, 4L, 5L, 6L, 7L), .Label = c("B4:B5:B6",
"B7:B8:B9", "D4:D5:D6", "D10:D11:D12", "E10:E11:E12", "A1:A2:A3",
"B10:B11:B12"
), class = "factor"), col_names = structure(c(1L, 1L, 2L, 3L, 4L, 5L, 6L,
1L), .Label = c("B1:B2:B3", "H4:H5:H6", "F10:F11:F12",
"H1:H2:H3", "G7:G8:G9", "D1:D2:D3"), class = "factor"),
CTaverage_MATRIX_SUBSTRACTIONS = c(-5.4595413208,
-2.74678293866667, -2.74099286393334, -2.74331347146666, -2.74805959066667,
-2.755259196, -4.59402211506667, -4.5927206675)), .Names = c("FIGURE",
"ddCT", "row_names", "col_names", "CTaverage_MATRIX_SUBSTRACTIONS"
), row.names = c(NA, 8L), class = "data.frame")

thanks again for your input,

-- bogdan

On Fri, May 29, 2015 at 2:11 PM, John Kane <jrkrideau at inbox.com> wrote:

> Bogdan, the request was for data in dput() format.
>
> Type ?dput for more information.
>
> Do dput(myfile) copy the ouput and paste into the email
>
> You should get something like:
> structure(list(c1 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
> 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
> 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L,
> 8L, 8L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L), .Label = c("(0.509,0.614]",
> "(0.614,0.718]", "(0.718,0.822]", "(0.822,0.926]", "(0.926,1.03]",
> "(1.03,1.13]", "(1.13,1.24]", "(1.24,1.34]", "(1.34,1.45]", "(1.45,1.55]"
> ), class = "factor"), s1 = c(0.51, 0.52, 0.58, 0.58, 0.59, 0.6,
> 0.63, 0.65, 0.68, 0.74, 0.74, 0.75, 0.77, 0.77, 0.77, 0.78, 0.79,
> 0.84, 0.84, 0.85, 0.87, 0.93, 0.93, 0.95, 0.99, 1.04, 1.09, 1.11,
> 1.13, 1.14, 1.14, 1.14, 1.17, 1.18, 1.19, 1.22, 1.22, 1.23, 1.28,
> 1.29, 1.3, 1.32, 1.37, 1.38, 1.38, 1.4, 1.43, 1.47, 1.52, 1.55
> )), .Names = c("c1", "s1"), row.names = c(NA, -50L), class = "data.frame")
>
> Data in duput() format is the preferred way to get data in R-help since it
> provides a perfect copy of what you have on your machine.  Any other way of
> providing data risks the recipients reading it into R differently than it
> is on your machine.
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: tanasa at gmail.com
> > Sent: Fri, 29 May 2015 13:58:20 -0700
> > To: sarah.goslee at gmail.com
> > Subject: Re: [R] about transforming a data.frame
> >
> > Hi Sarah,
> >
> > thank you for your help. I have simplified the example, by reading the
> > elements in a data frame, eg :
> >
> > df <- data.frame (row_names = c("B4:B5:B6", "B7:B8:B9", "D4:D5:D6",
> > "D10:D11:D12", "D10:D11:D12", "E10:E11:E12", "A1:A2:A3", "B10:B11:B12"),
> > col_names = c
> >
> ("B1:B2:B3","B1:B2:B3","H4:H5:H6","F10:F11:F12","H1:H2:H3","G7:G8:G9","D1:D2:D3","B1:B2:B3"),
> > CT = c(5,2,2,2,2,2,4,4) )
> >
> > I have used the the count() in the plyr package :
> >
> > count_row_names <- count(df$row_names)
> > count_col_names <- count(df$col_names)
> >
> > however, I would need to correlate these UNIQUE ELEMENTS in the columns
> > "row_names" or "col_names" with the numbers they associate in the  CT
> > columns, eg :
> >
> > ""B1:B2:B3" associate with "5, 2, 4" (in CT column), or "D10:D11:D12"
> > associate with "2" (in the CT column).
> >
> > thank you very much,
> >
> > bogdan
> >
> >
> >
> >
> > On Fri, May 29, 2015 at 1:32 PM, Sarah Goslee <sarah.goslee at gmail.com>
> > wrote:
> >
> >> Hi,
> >>
> >> Please use dput() to provide your data, as it can get somewhat mangled
> >> by copy and pasting, especially if you post in HTML (as you are asked
> >> not to do in the posting guide).
> >>
> >> What is a unique element? is "B4:B5:B6" an element, or are "B4" and
> >> "B5" each elements? That is, what is the result you expect to obtain
> >> for the sample data you provided?
> >>
> >> What code have you tried? I would think table() might be involved, and
> >> possibly strsplit(), but will refrain from putting more time into this
> >> until you provide a reproducible dataset with dput() and some clearer
> >> idea of your intent.
> >>
> >> Sarah
> >>
> >> On Fri, May 29, 2015 at 4:19 PM, Bogdan Tanasa <tanasa at gmail.com>
> wrote:
> >>> Dear all,
> >>>
> >>> I would appreciate a suggestion on the following : I am working with a
> >>> data.frame (below) :
> >>>
> >>>   EXP    CT   row_names   col_names
> >>> 1   test -5    B4:B5:B6    B1:B2:B3
> >>> 2   test -2    B7:B8:B9    B1:B2:B3
> >>> 3   test -2    D4:D5:D6    H4:H5:H6
> >>> 4   test -2    D10:D11:D12 F10:F11:F12
> >>> 5   test -2    D10:D11:D12    H1:H2:H3
> >>> 6   test -2    E10:E11:E12    G7:G8:G9
> >>> 7   test -4     A1:A2:A3    D1:D2:D3
> >>> 8   test -4   B10:B11:B12    B1:B2:B3
> >>>
> >>> what would be the easiest way to consider UNIQUE elements in the
> >> ROW_NAMES
> >>> or the UNIQUE elements in the COL_NAMES and :
> >>>
> >>> print how many times these UNIQUE ELEMENTS associate with the numbers
> >>> -5,
> >>> -2, or -4 (these numbers are on the column names CT) ..
> >>>
> >>> thanks,
> >>>
> >>> bogdan
> >>>
> >> --
> >> Sarah Goslee
> >> http://www.functionaldiversity.org
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and
> family!
> Visit http://www.inbox.com/photosharing to find out more!
>
>
>

	[[alternative HTML version deleted]]


From tanasa at gmail.com  Fri May 29 23:54:25 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Fri, 29 May 2015 14:54:25 -0700
Subject: [R] about transforming a data.frame
In-Reply-To: <CA+8X3fWZPQ+BkOcb_h9fZ7rNVpWDnj52cs-z4XqV9O41H5+khw@mail.gmail.com>
References: <cam_vju=x8yoj5o9grpx=nnatqitdb9ueexf65f+eg8dnjp0z2g@mail.gmail.com>
	<ca+jem03i23ewh+n4vbm44_9=osoimk6p=ks8b8slb6czodo4oq@mail.gmail.com>
	<CA+JEM02ptDsO3gq_1-a4_F2feSdxKzker5mM914rmAbvodXc3Q@mail.gmail.com>
	<82824615D6C.00000F5Djrkrideau@inbox.com>
	<CA+8X3fWZPQ+BkOcb_h9fZ7rNVpWDnj52cs-z4XqV9O41H5+khw@mail.gmail.com>
Message-ID: <CA+JEM03L6yZTxogs1qOqZrYVJJj8TZSq7189BmeohJKZonRByA@mail.gmail.com>

Hi Jim,

yes, thank you, that is the desired output. one more question please :
after using the dataframe :

df <- data.frame (row_names = c("B4:B5:B6", "B7:B8:B9", "D4:D5:D6",
"D10:D11:D12", "D10:D11:D12", "E10:E11:E12", "A1:A2:A3", "B10:B11:B12"),
col_names = c
("B1:B2:B3","B1:B2:B3","H4:H5:H6","F10:F11:F12","H1:H2:H3","G7:G8:G9","D1:D2:D3","B1:B2:B3"),
CT = c(5,2,2,2,2,2,4,4) )

and :

table(df$row_names,df$CT)
table(df$col_names,df$CT)

how could I quickly verify that "B1:B2:B3" (for example) hits the CT values
of 2,4,5  at least one time ? an example is in

table(df$col_names,df$CT) ?

thank you very much,

-- bogdan



On Fri, May 29, 2015 at 2:40 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Bogdan,
> Sarah has already suggested this, but doesn't:
>
> table(df$row_names,df$CT)
> table(df$col_names,df$CT)
>
> give you what you want?
>
> Jim
>
>
> On Sat, May 30, 2015 at 7:11 AM, John Kane <jrkrideau at inbox.com> wrote:
> > Bogdan, the request was for data in dput() format.
> >
> > Type ?dput for more information.
> >
> > Do dput(myfile) copy the ouput and paste into the email
> >
> > You should get something like:
> > structure(list(c1 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
> > 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
> > 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L,
> > 8L, 8L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L), .Label = c("(0.509,0.614]",
> > "(0.614,0.718]", "(0.718,0.822]", "(0.822,0.926]", "(0.926,1.03]",
> > "(1.03,1.13]", "(1.13,1.24]", "(1.24,1.34]", "(1.34,1.45]", "(1.45,1.55]"
> > ), class = "factor"), s1 = c(0.51, 0.52, 0.58, 0.58, 0.59, 0.6,
> > 0.63, 0.65, 0.68, 0.74, 0.74, 0.75, 0.77, 0.77, 0.77, 0.78, 0.79,
> > 0.84, 0.84, 0.85, 0.87, 0.93, 0.93, 0.95, 0.99, 1.04, 1.09, 1.11,
> > 1.13, 1.14, 1.14, 1.14, 1.17, 1.18, 1.19, 1.22, 1.22, 1.23, 1.28,
> > 1.29, 1.3, 1.32, 1.37, 1.38, 1.38, 1.4, 1.43, 1.47, 1.52, 1.55
> > )), .Names = c("c1", "s1"), row.names = c(NA, -50L), class =
> "data.frame")
> >
> > Data in duput() format is the preferred way to get data in R-help since
> it provides a perfect copy of what you have on your machine.  Any other way
> of providing data risks the recipients reading it into R differently than
> it is on your machine.
> >
> > John Kane
> > Kingston ON Canada
> >
> >
> >> -----Original Message-----
> >> From: tanasa at gmail.com
> >> Sent: Fri, 29 May 2015 13:58:20 -0700
> >> To: sarah.goslee at gmail.com
> >> Subject: Re: [R] about transforming a data.frame
> >>
> >> Hi Sarah,
> >>
> >> thank you for your help. I have simplified the example, by reading the
> >> elements in a data frame, eg :
> >>
> >> df <- data.frame (row_names = c("B4:B5:B6", "B7:B8:B9", "D4:D5:D6",
> >> "D10:D11:D12", "D10:D11:D12", "E10:E11:E12", "A1:A2:A3", "B10:B11:B12"),
> >> col_names = c
> >>
> ("B1:B2:B3","B1:B2:B3","H4:H5:H6","F10:F11:F12","H1:H2:H3","G7:G8:G9","D1:D2:D3","B1:B2:B3"),
> >> CT = c(5,2,2,2,2,2,4,4) )
> >>
> >> I have used the the count() in the plyr package :
> >>
> >> count_row_names <- count(df$row_names)
> >> count_col_names <- count(df$col_names)
> >>
> >> however, I would need to correlate these UNIQUE ELEMENTS in the columns
> >> "row_names" or "col_names" with the numbers they associate in the  CT
> >> columns, eg :
> >>
> >> ""B1:B2:B3" associate with "5, 2, 4" (in CT column), or "D10:D11:D12"
> >> associate with "2" (in the CT column).
> >>
> >> thank you very much,
> >>
> >> bogdan
> >>
> >>
> >>
> >>
> >> On Fri, May 29, 2015 at 1:32 PM, Sarah Goslee <sarah.goslee at gmail.com>
> >> wrote:
> >>
> >>> Hi,
> >>>
> >>> Please use dput() to provide your data, as it can get somewhat mangled
> >>> by copy and pasting, especially if you post in HTML (as you are asked
> >>> not to do in the posting guide).
> >>>
> >>> What is a unique element? is "B4:B5:B6" an element, or are "B4" and
> >>> "B5" each elements? That is, what is the result you expect to obtain
> >>> for the sample data you provided?
> >>>
> >>> What code have you tried? I would think table() might be involved, and
> >>> possibly strsplit(), but will refrain from putting more time into this
> >>> until you provide a reproducible dataset with dput() and some clearer
> >>> idea of your intent.
> >>>
> >>> Sarah
> >>>
> >>> On Fri, May 29, 2015 at 4:19 PM, Bogdan Tanasa <tanasa at gmail.com>
> wrote:
> >>>> Dear all,
> >>>>
> >>>> I would appreciate a suggestion on the following : I am working with a
> >>>> data.frame (below) :
> >>>>
> >>>>   EXP    CT   row_names   col_names
> >>>> 1   test -5    B4:B5:B6    B1:B2:B3
> >>>> 2   test -2    B7:B8:B9    B1:B2:B3
> >>>> 3   test -2    D4:D5:D6    H4:H5:H6
> >>>> 4   test -2    D10:D11:D12 F10:F11:F12
> >>>> 5   test -2    D10:D11:D12    H1:H2:H3
> >>>> 6   test -2    E10:E11:E12    G7:G8:G9
> >>>> 7   test -4     A1:A2:A3    D1:D2:D3
> >>>> 8   test -4   B10:B11:B12    B1:B2:B3
> >>>>
> >>>> what would be the easiest way to consider UNIQUE elements in the
> >>> ROW_NAMES
> >>>> or the UNIQUE elements in the COL_NAMES and :
> >>>>
> >>>> print how many times these UNIQUE ELEMENTS associate with the numbers
> >>>> -5,
> >>>> -2, or -4 (these numbers are on the column names CT) ..
> >>>>
> >>>> thanks,
> >>>>
> >>>> bogdan
> >>>>
> >>> --
> >>> Sarah Goslee
> >>> http://www.functionaldiversity.org
> >>>
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ____________________________________________________________
> > FREE ONLINE PHOTOSHARING - Share your photos online with your friends
> and family!
> > Visit http://www.inbox.com/photosharing to find out more!
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri May 29 23:55:27 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 29 May 2015 17:55:27 -0400
Subject: [R] about transforming a data.frame
In-Reply-To: <CA+JEM02ptDsO3gq_1-a4_F2feSdxKzker5mM914rmAbvodXc3Q@mail.gmail.com>
References: <CA+JEM03i23EwH+n4vBM44_9=osoimk6P=KS8B8sLB6CzodO4oQ@mail.gmail.com>
	<CAM_vju=x8yOj5o9gRPx=nnaTQitDb9ueexf65F+Eg8DNJp0z2g@mail.gmail.com>
	<CA+JEM02ptDsO3gq_1-a4_F2feSdxKzker5mM914rmAbvodXc3Q@mail.gmail.com>
Message-ID: <CAM_vju=oH1d78KYMvHGP1kdS7+UNgpTkkweSXp65g58Xema3iQ@mail.gmail.com>

I'm still not really clear on what you need (format, etc), but this
may help you get started:

> with(df, table(CT, row_names))
   row_names
CT  A1:A2:A3 B10:B11:B12 B4:B5:B6 B7:B8:B9 D10:D11:D12 D4:D5:D6 E10:E11:E12
  2        0           0        0        1           2        1           1
  4        1           1        0        0           0        0           0
  5        0           0        1        0           0        0           0
> with(df, table(CT, col_names))
   col_names
CT  B1:B2:B3 D1:D2:D3 F10:F11:F12 G7:G8:G9 H1:H2:H3 H4:H5:H6
  2        1        0           1        1        1        1
  4        1        1           0        0        0        0
  5        1        0           0        0        0        0
>

On Fri, May 29, 2015 at 4:58 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> Hi Sarah,
>
> thank you for your help. I have simplified the example, by reading the
> elements in a data frame, eg :
>
> df <- data.frame (row_names = c("B4:B5:B6", "B7:B8:B9", "D4:D5:D6",
> "D10:D11:D12", "D10:D11:D12", "E10:E11:E12", "A1:A2:A3", "B10:B11:B12"),
> col_names = c
> ("B1:B2:B3","B1:B2:B3","H4:H5:H6","F10:F11:F12","H1:H2:H3","G7:G8:G9","D1:D2:D3","B1:B2:B3"),
> CT = c(5,2,2,2,2,2,4,4) )
>
> I have used the the count() in the plyr package :
>
> count_row_names <- count(df$row_names)
> count_col_names <- count(df$col_names)
>
> however, I would need to correlate these UNIQUE ELEMENTS in the columns
> "row_names" or "col_names" with the numbers they associate in the  CT
> columns, eg :
>
> ""B1:B2:B3" associate with "5, 2, 4" (in CT column), or "D10:D11:D12"
> associate with "2" (in the CT column).
>
> thank you very much,
>
> bogdan
>
>
>
>
> On Fri, May 29, 2015 at 1:32 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>>
>> Hi,
>>
>> Please use dput() to provide your data, as it can get somewhat mangled
>> by copy and pasting, especially if you post in HTML (as you are asked
>> not to do in the posting guide).
>>
>> What is a unique element? is "B4:B5:B6" an element, or are "B4" and
>> "B5" each elements? That is, what is the result you expect to obtain
>> for the sample data you provided?
>>
>> What code have you tried? I would think table() might be involved, and
>> possibly strsplit(), but will refrain from putting more time into this
>> until you provide a reproducible dataset with dput() and some clearer
>> idea of your intent.
>>
>> Sarah
>>
>> On Fri, May 29, 2015 at 4:19 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
>> > Dear all,
>> >
>> > I would appreciate a suggestion on the following : I am working with a
>> > data.frame (below) :
>> >
>> >   EXP    CT   row_names   col_names
>> > 1   test -5    B4:B5:B6    B1:B2:B3
>> > 2   test -2    B7:B8:B9    B1:B2:B3
>> > 3   test -2    D4:D5:D6    H4:H5:H6
>> > 4   test -2    D10:D11:D12 F10:F11:F12
>> > 5   test -2    D10:D11:D12    H1:H2:H3
>> > 6   test -2    E10:E11:E12    G7:G8:G9
>> > 7   test -4     A1:A2:A3    D1:D2:D3
>> > 8   test -4   B10:B11:B12    B1:B2:B3
>> >
>> > what would be the easiest way to consider UNIQUE elements in the
>> > ROW_NAMES
>> > or the UNIQUE elements in the COL_NAMES and :
>> >
>> > print how many times these UNIQUE ELEMENTS associate with the numbers
>> > -5,
>> > -2, or -4 (these numbers are on the column names CT) ..
>> >
>> > thanks,
>> >
>> > bogdan
>> >


From tanasa at gmail.com  Fri May 29 23:58:47 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Fri, 29 May 2015 14:58:47 -0700
Subject: [R] about transforming a data.frame
In-Reply-To: <CAM_vju=oH1d78KYMvHGP1kdS7+UNgpTkkweSXp65g58Xema3iQ@mail.gmail.com>
References: <CA+JEM03i23EwH+n4vBM44_9=osoimk6P=KS8B8sLB6CzodO4oQ@mail.gmail.com>
	<CAM_vju=x8yOj5o9gRPx=nnaTQitDb9ueexf65F+Eg8DNJp0z2g@mail.gmail.com>
	<CA+JEM02ptDsO3gq_1-a4_F2feSdxKzker5mM914rmAbvodXc3Q@mail.gmail.com>
	<CAM_vju=oH1d78KYMvHGP1kdS7+UNgpTkkweSXp65g58Xema3iQ@mail.gmail.com>
Message-ID: <CA+JEM02kH+nePE9C4zotxq0unSj2LgZhhgGAuddWf2yR0-voOg@mail.gmail.com>

Dear Sarah,

thank you very much, it is very helpful. please may I ask one more question
about a quick and easy tutorial about the loading multiple files (from a
folder) in R, and processing one file at a time ?  thanks very much again,

bogdan

On Fri, May 29, 2015 at 2:55 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> I'm still not really clear on what you need (format, etc), but this
> may help you get started:
>
> > with(df, table(CT, row_names))
>    row_names
> CT  A1:A2:A3 B10:B11:B12 B4:B5:B6 B7:B8:B9 D10:D11:D12 D4:D5:D6 E10:E11:E12
>   2        0           0        0        1           2        1           1
>   4        1           1        0        0           0        0           0
>   5        0           0        1        0           0        0           0
> > with(df, table(CT, col_names))
>    col_names
> CT  B1:B2:B3 D1:D2:D3 F10:F11:F12 G7:G8:G9 H1:H2:H3 H4:H5:H6
>   2        1        0           1        1        1        1
>   4        1        1           0        0        0        0
>   5        1        0           0        0        0        0
> >
>
> On Fri, May 29, 2015 at 4:58 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> > Hi Sarah,
> >
> > thank you for your help. I have simplified the example, by reading the
> > elements in a data frame, eg :
> >
> > df <- data.frame (row_names = c("B4:B5:B6", "B7:B8:B9", "D4:D5:D6",
> > "D10:D11:D12", "D10:D11:D12", "E10:E11:E12", "A1:A2:A3", "B10:B11:B12"),
> > col_names = c
> >
> ("B1:B2:B3","B1:B2:B3","H4:H5:H6","F10:F11:F12","H1:H2:H3","G7:G8:G9","D1:D2:D3","B1:B2:B3"),
> > CT = c(5,2,2,2,2,2,4,4) )
> >
> > I have used the the count() in the plyr package :
> >
> > count_row_names <- count(df$row_names)
> > count_col_names <- count(df$col_names)
> >
> > however, I would need to correlate these UNIQUE ELEMENTS in the columns
> > "row_names" or "col_names" with the numbers they associate in the  CT
> > columns, eg :
> >
> > ""B1:B2:B3" associate with "5, 2, 4" (in CT column), or "D10:D11:D12"
> > associate with "2" (in the CT column).
> >
> > thank you very much,
> >
> > bogdan
> >
> >
> >
> >
> > On Fri, May 29, 2015 at 1:32 PM, Sarah Goslee <sarah.goslee at gmail.com>
> > wrote:
> >>
> >> Hi,
> >>
> >> Please use dput() to provide your data, as it can get somewhat mangled
> >> by copy and pasting, especially if you post in HTML (as you are asked
> >> not to do in the posting guide).
> >>
> >> What is a unique element? is "B4:B5:B6" an element, or are "B4" and
> >> "B5" each elements? That is, what is the result you expect to obtain
> >> for the sample data you provided?
> >>
> >> What code have you tried? I would think table() might be involved, and
> >> possibly strsplit(), but will refrain from putting more time into this
> >> until you provide a reproducible dataset with dput() and some clearer
> >> idea of your intent.
> >>
> >> Sarah
> >>
> >> On Fri, May 29, 2015 at 4:19 PM, Bogdan Tanasa <tanasa at gmail.com>
> wrote:
> >> > Dear all,
> >> >
> >> > I would appreciate a suggestion on the following : I am working with a
> >> > data.frame (below) :
> >> >
> >> >   EXP    CT   row_names   col_names
> >> > 1   test -5    B4:B5:B6    B1:B2:B3
> >> > 2   test -2    B7:B8:B9    B1:B2:B3
> >> > 3   test -2    D4:D5:D6    H4:H5:H6
> >> > 4   test -2    D10:D11:D12 F10:F11:F12
> >> > 5   test -2    D10:D11:D12    H1:H2:H3
> >> > 6   test -2    E10:E11:E12    G7:G8:G9
> >> > 7   test -4     A1:A2:A3    D1:D2:D3
> >> > 8   test -4   B10:B11:B12    B1:B2:B3
> >> >
> >> > what would be the easiest way to consider UNIQUE elements in the
> >> > ROW_NAMES
> >> > or the UNIQUE elements in the COL_NAMES and :
> >> >
> >> > print how many times these UNIQUE ELEMENTS associate with the numbers
> >> > -5,
> >> > -2, or -4 (these numbers are on the column names CT) ..
> >> >
> >> > thanks,
> >> >
> >> > bogdan
> >> >
>

	[[alternative HTML version deleted]]


From tmrsg11 at gmail.com  Sat May 30 00:13:22 2015
From: tmrsg11 at gmail.com (C W)
Date: Fri, 29 May 2015 18:13:22 -0400
Subject: [R] Why I am not able to load library(R.matlab)? Other packages
 are fine.
In-Reply-To: <5568D5CC.3050505@gmail.com>
References: <CAE2FW2mSRPr5hGGGGKM1P4Pp4Ka4vHQsWKx86oFAQ+5rDoJimA@mail.gmail.com>
	<CAFDcVCRF3dChpgAoonZ+RtB1zywdYDD7x9LYAVKCJ7f82ZFbgw@mail.gmail.com>
	<CAE2FW2n2MyzFDDBV=MnP4jJYPR_AP4dTunHo+PA3J9udqufNfg@mail.gmail.com>
	<loom.20150529T195442-623@post.gmane.org>
	<CAE2FW2nCr4_AW-MSkQqWzs02TbFsathZpm0vT65SWWDT4dc7oQ@mail.gmail.com>
	<5568D5CC.3050505@gmail.com>
Message-ID: <CAE2FW2mtuzQnWxA3T6bs1yxC87BefB1H1ogsmQPnK3EBrdL02g@mail.gmail.com>

Hi Ben,

Thanks for the fun clip.  I love it.  Have a wonderful day!

-M

On Fri, May 29, 2015 at 5:10 PM, Ben Bolker <bbolker at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>  I think Henrik's point (which I merely clarified) was that something
> funky (we'll probably never know what, and it's not worth figuring out
> unless it happens again/to other people) had gone wrong and that the
> easiest thing to do was just to reinstall.
>
> References:
> * https://www.youtube.com/watch?v=t2F1rFmyQmY
> *
>
> http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.208.9970&rep=rep1&type=pdf
>
>
> On 15-05-29 05:11 PM, C W wrote:
> > Wow, thanks Ben.  That worked very well.
> >
> > I guess I didn't have R.methodS3?  But that doesn't make sense,
> > because I was using R.matlab few weeks ago.  I believe I was on R
> > 3.1.
> >
> > Maybe it's in R 3.1 folder?  I am using a Mac, btw.
> >
> > Cheers,
> >
> > -M
> >
> > On Fri, May 29, 2015 at 1:55 PM, Ben Bolker <bbolker at gmail.com>
> > wrote:
> >
> >> C W <tmrsg11 <at> gmail.com> writes:
> >>
> >>>
> >>> Hi Henrik,
> >>>
> >>> I don't quite get what I should do here.  I am not familiar
> >>> with R.methodS3.  Can you tell me what command exactly do I
> >>> need to do?
> >>>
> >>> Thanks,
> >>>
> >>> Mike
> >>
> >> install.packages("R.methodsS3") install.packages("R.matlab")
> >> library("R.matlab")
> >>
> >>
> >>
> >> [snip snip snip]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read
> >> the posting guide http://www.R-project.org/posting-guide.html and
> >> provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJVaNXMAAoJEOCV5YRblxUHj6kH/3W3etyn+HlT0X1PEj7DQf2c
> Qo0q9ed2csPRLbLLrpX2FPKbxLg/g6MSxmIQ118tbWhkzKfRoyxCZHLcT+U2xLuR
> V7QAS3Yns2ENSSSH1GvdSeFZTQWW3XFZN/kT+/zQYjaZewZOlo4Cgqc16c6mGBRS
> eSIRIyA3iJWnMEc878nbMJztvsEqnpZSNSIXiI91UX/l8sDrBNYCNtfzY86JqJhp
> 8O0q7zkaRIrb6UuViY3qTC5+qpGruUYIUbeqyNei7MNErrG3AufsODfs5d/CjSCa
> 5jlbS512JRrQFV2JKHU+AH+4Q9CJQBVS+F6JZdjhHB2fUmAx0XIR6IJEBfSvBSk=
> =nO+b
> -----END PGP SIGNATURE-----
>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sat May 30 00:15:04 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 29 May 2015 18:15:04 -0400
Subject: [R] Help on R Functionality & Histogram
In-Reply-To: <1432900499664-4707887.post@n4.nabble.com>
References: <1432900499664-4707887.post@n4.nabble.com>
Message-ID: <F0D7DACD-A99A-4341-933A-3B8ADB9182BE@utoronto.ca>

Don't use Nabble when posting to the R-Help forum.

Responses inline.

On May 29, 2015, at 7:54 AM, Shivi82 <shivibhatia at ymail.com> wrote:

> Hello Experts, 
> I have couple of questions on the analysis I am creating.
> 1) How does R adopt to changes. The case I have here is that the excel I
> have started initially had to be modified because the data I had was on
> hourly basis ranging from 0 to 23 hours. After Changes 0 was modified to 24
> in hours. Now do I need to recall this excel again in R using read.csv
> syntax or is there another way to do so i.e. a kind of reload option

No. Reload the data by rerunning your script.


> 2) I am creating a histogram. I need on x axis 24 hours to be displayed
> separately as 0,1,2, and thereon. However it only shows till 20 which makes
> the look awkward. Also all l need to resize the labels and if possible
> inside the bars. It used the below code, axis fonts have changed but labels
> give an error with this code
> 
> Code:- hist(aaa$Hours,main="Hourly Weight",xlab = "Time",breaks = 25,col =
> "yellow",ylim = c(0,9000),
>     labels=TRUE, cex.axis=0.6,cex.label=0.6)

The very understandable warning message you must have got with that call tells you that there is no such argument "cex.label".

hist() calls plot.histogram() which internally calls text() to write the labels. text() has an argument "cex", but even if you supply it to hist(), it is not passed to text() via the function body of plot.histogram(). You could modify plot.histogram but the more immediate solution is to set labels = FALSE, and explicitly use text() to write your labels. Try something like

x <- hist(aaa$Hours,
     main="Hourly Weight",
     xlab = "Time",
     breaks = 25,
     col = "yellow",
     ylim = c(0,9000),
     labels=FALSE,
     cex.axis=0.6)
     
text(x$mids, x$counts * 1.05, labels = x$counts, cex=0.5)



B.


> 
> Kindly advice on the both the questions. Thanks. 
> 
> 
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Help-on-R-Functionality-Histogram-tp4707887.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Sat May 30 00:18:08 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 29 May 2015 18:18:08 -0400
Subject: [R] about transforming a data.frame
In-Reply-To: <CA+JEM02kH+nePE9C4zotxq0unSj2LgZhhgGAuddWf2yR0-voOg@mail.gmail.com>
References: <CA+JEM03i23EwH+n4vBM44_9=osoimk6P=KS8B8sLB6CzodO4oQ@mail.gmail.com>
	<CAM_vju=x8yOj5o9gRPx=nnaTQitDb9ueexf65F+Eg8DNJp0z2g@mail.gmail.com>
	<CA+JEM02ptDsO3gq_1-a4_F2feSdxKzker5mM914rmAbvodXc3Q@mail.gmail.com>
	<CAM_vju=oH1d78KYMvHGP1kdS7+UNgpTkkweSXp65g58Xema3iQ@mail.gmail.com>
	<CA+JEM02kH+nePE9C4zotxq0unSj2LgZhhgGAuddWf2yR0-voOg@mail.gmail.com>
Message-ID: <CAM_vjun=LHGBcnGNfY29HBuTJNghE9ht0oeW6PO9JRCZzgUp-g@mail.gmail.com>

LMGTFY: http://stackoverflow.com/questions/11433432/importing-multiple-csv-files-into-r

On Fri, May 29, 2015 at 5:58 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> Dear Sarah,
>
> thank you very much, it is very helpful. please may I ask one more question
> about a quick and easy tutorial about the loading multiple files (from a
> folder) in R, and processing one file at a time ?  thanks very much again,
>
> bogdan
>
> On Fri, May 29, 2015 at 2:55 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>>
>> I'm still not really clear on what you need (format, etc), but this
>> may help you get started:
>>
>> > with(df, table(CT, row_names))
>>    row_names
>> CT  A1:A2:A3 B10:B11:B12 B4:B5:B6 B7:B8:B9 D10:D11:D12 D4:D5:D6
>> E10:E11:E12
>>   2        0           0        0        1           2        1
>> 1
>>   4        1           1        0        0           0        0
>> 0
>>   5        0           0        1        0           0        0
>> 0
>> > with(df, table(CT, col_names))
>>    col_names
>> CT  B1:B2:B3 D1:D2:D3 F10:F11:F12 G7:G8:G9 H1:H2:H3 H4:H5:H6
>>   2        1        0           1        1        1        1
>>   4        1        1           0        0        0        0
>>   5        1        0           0        0        0        0
>> >
>>
>> On Fri, May 29, 2015 at 4:58 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
>> > Hi Sarah,
>> >
>> > thank you for your help. I have simplified the example, by reading the
>> > elements in a data frame, eg :
>> >
>> > df <- data.frame (row_names = c("B4:B5:B6", "B7:B8:B9", "D4:D5:D6",
>> > "D10:D11:D12", "D10:D11:D12", "E10:E11:E12", "A1:A2:A3", "B10:B11:B12"),
>> > col_names = c
>> >
>> > ("B1:B2:B3","B1:B2:B3","H4:H5:H6","F10:F11:F12","H1:H2:H3","G7:G8:G9","D1:D2:D3","B1:B2:B3"),
>> > CT = c(5,2,2,2,2,2,4,4) )
>> >
>> > I have used the the count() in the plyr package :
>> >
>> > count_row_names <- count(df$row_names)
>> > count_col_names <- count(df$col_names)
>> >
>> > however, I would need to correlate these UNIQUE ELEMENTS in the columns
>> > "row_names" or "col_names" with the numbers they associate in the  CT
>> > columns, eg :
>> >
>> > ""B1:B2:B3" associate with "5, 2, 4" (in CT column), or "D10:D11:D12"
>> > associate with "2" (in the CT column).
>> >
>> > thank you very much,
>> >
>> > bogdan
>> >
>> >
>> >
>> >
>> > On Fri, May 29, 2015 at 1:32 PM, Sarah Goslee <sarah.goslee at gmail.com>
>> > wrote:
>> >>
>> >> Hi,
>> >>
>> >> Please use dput() to provide your data, as it can get somewhat mangled
>> >> by copy and pasting, especially if you post in HTML (as you are asked
>> >> not to do in the posting guide).
>> >>
>> >> What is a unique element? is "B4:B5:B6" an element, or are "B4" and
>> >> "B5" each elements? That is, what is the result you expect to obtain
>> >> for the sample data you provided?
>> >>
>> >> What code have you tried? I would think table() might be involved, and
>> >> possibly strsplit(), but will refrain from putting more time into this
>> >> until you provide a reproducible dataset with dput() and some clearer
>> >> idea of your intent.
>> >>
>> >> Sarah
>> >>
>> >> On Fri, May 29, 2015 at 4:19 PM, Bogdan Tanasa <tanasa at gmail.com>
>> >> wrote:
>> >> > Dear all,
>> >> >
>> >> > I would appreciate a suggestion on the following : I am working with
>> >> > a
>> >> > data.frame (below) :
>> >> >
>> >> >   EXP    CT   row_names   col_names
>> >> > 1   test -5    B4:B5:B6    B1:B2:B3
>> >> > 2   test -2    B7:B8:B9    B1:B2:B3
>> >> > 3   test -2    D4:D5:D6    H4:H5:H6
>> >> > 4   test -2    D10:D11:D12 F10:F11:F12
>> >> > 5   test -2    D10:D11:D12    H1:H2:H3
>> >> > 6   test -2    E10:E11:E12    G7:G8:G9
>> >> > 7   test -4     A1:A2:A3    D1:D2:D3
>> >> > 8   test -4   B10:B11:B12    B1:B2:B3
>> >> >
>> >> > what would be the easiest way to consider UNIQUE elements in the
>> >> > ROW_NAMES
>> >> > or the UNIQUE elements in the COL_NAMES and :
>> >> >
>> >> > print how many times these UNIQUE ELEMENTS associate with the numbers
>> >> > -5,
>> >> > -2, or -4 (these numbers are on the column names CT) ..
>> >> >
>> >> > thanks,
>> >> >
>> >> > bogdan
>> >> >
>
>


From murdoch.duncan at gmail.com  Sat May 30 00:35:04 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 29 May 2015 18:35:04 -0400
Subject: [R] Result differences in 32-bit vs. 64-bit point.in.polygon?
In-Reply-To: <71a860b9eb4f44e494dce127b1db35e7@MAIL13M3N2.ad.uams.edu>
References: <71a860b9eb4f44e494dce127b1db35e7@MAIL13M3N2.ad.uams.edu>
Message-ID: <5568E998.2060901@gmail.com>

On 29/05/2015 2:36 PM, Lensing, Shelly Y wrote:
> Is anyone aware of point.in.polygon giving different results for 32-bit vs. 64-bit R? Our OS is 64-bit Windows 7 Enterprise. I'm working with someone else's extensive R program and the final results are close but not exactly matching. We're thinking it might be something with the point.in.polygon function (one of many possibilities, including leaps).

Often 32 bit R does calculations slightly more accurately than 64 bit R
does.  This is because the 64 bit compiler is more likely to do
calculations in 64 bit precision when the 32 bit compiler does them in
80 bit precision.  Of course, individual calculations being more
accurate doesn't mean the final answer is, but small numeric differences
in floating point calculations are to be expected.

Duncan Murdoch


From jrkrideau at inbox.com  Sat May 30 00:38:21 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 29 May 2015 14:38:21 -0800
Subject: [R] Problem with comparing multiple data sets
In-Reply-To: <CAJVfk9nf-w1aEtpzL7VkhcAOkNYeoY1cv5WL3CakJ-MWE6B16Q@mail.gmail.com>
References: <ca+8x3fw4bwsq2u-epumzqzsfl-4syjzakfr56qs8i-fmk7hpfa@mail.gmail.com>
	<53bf8fb63faf2e4a9455ef1ee94da7262d68ea9d@mb02.ads.tamu.edu>
	<cajvfk9k+qk9cuqrbtlmajyvdu5erzhtd1verhnabpkhiikdoaq@mail.gmail.com>
	<cajvfk9nm_a2gr86oximhbc8hzon45rmwll_vmxak4rpoj1=oqw@mail.gmail.com>
	<cajvfk9m1lcja8dxu9w4cymgkpgnyhnnseey7cbln4qfwukommg@mail.gmail.com>
	<cajvfk9kx-hjyeud5q=y6kgxy8oyzw3j4shhxduv39jj1f43mta@mail.gmail.com>
	<cajvfk9k7zjlg8ip+sl_eamyzfr_=en40q3ob5fe2zwqca0suoa@mail.gmail.com>
	<32fceb5d574.0000035fjrkrideau@inbox.com>
	<53bf8fb63faf2e4a9455ef1ee94da7262d68ebff@mb02.ads.tamu.edu>
Message-ID: <8343EF0F57B.000010A1jrkrideau@inbox.com>

Hi Mohammad,
I have no idea what is happening but for some reason your new data (renamed df1 since df is a reserved word in R) is outputting a list whereas dff1 (your original test data) is giving a vector as you wanted.

It may be obvious but I don't see why df1 is giving us a list.  As far as I can tell the two data sets are structually the same.

The two data sets are below the program.  
## =============================
library(modeest)

# Original test data 
str(dff2)
head(dff2)

# sample of new data
str(d1)
head(df1)

Out.dff2  <- apply(dff2[ ,2:length(dff2)], 1, mfv)
str(Out.dff2)

Out.df1  <-  apply(df1[ , 2:length(df1)], 1, mfv)
str(Out.df1)


## =============================
## New data set 
df1  <- structure(list(terms = structure(c(2L, 4L, 4L, 4L, 3L, 1L, 5L,
5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label =
c("#authentication,access control",
"#privacy,personal data", "#security,malicious,security", "data controller",
"id management,security", "password,recovery"), class = "factor"),
    class.1 = c(2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L,
    2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L,
    1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 1L,
    2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L), class.2 = c(2L, 2L, 2L,
    0L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 2L,
    2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L,
    2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L,
    2L, 2L), class.3 = c(2L, 0L, 2L, 2L, 1L, 1L, 0L, 0L, 0L,
    2L, 2L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L)), .Names = c("terms",
"class.1", "class.2", "class.3"), class = "data.frame", row.names = c(NA,
-50L))

## Original test data set

dff2  <-   structure(list(terms = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 4L, 4L,
 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label = c("#dac",
 "#mac,#security",
 "accountability,anonymous", "data security,encryption,security"
 ), class = "factor"), class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L,
 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L,
 1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), class.2 = c(2L, 2L,
 2L, 2L, 0L, 0L, 2L, 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L,
 0L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L),
     class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
     0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
     0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L, 1L,
     0L, 0L, 0L, 0L, 2L, 1L, 2L)), .Names = c("terms", "class.1",
 "class.2", "class.3"), class = "data.frame", row.names = c(NA,
 -49L))

##=========================================



John Kane
Kingston ON Canada

-----Original Message-----
From: mxalimohamma at ualr.edu
Sent: Fri, 29 May 2015 11:40:41 -0500
To: dcarlson at tamu.edu, drjimlemon at gmail.com, jrkrideau at inbox.com, r-help at r-project.org
Subject: Re: [R] Problem with comparing multiple data sets

Hi everyone.

I tried the (modeest) package on my initial test data and it worked. However, it doesn't work on the entire data set. I saved one of the protions that gives error. (Not for all of the values but for some of them). For example: lines 36 and 37 and 39 correctly show the mode value but 38 and 40 are not correct. Such error is repeated for many of the values.

[36,] 2 ? ? ? ?

[37,] 2 ? ? ? ?

[38,] Numeric,3

[39,] 1 ? ? ? ?

[40,] Numeric,3

============================================

#This is what I did:

> df<- read.csv(file="Part1-modif.csv", head=TRUE, sep=",")

> Out<- apply(df[,2:length(df)],1, mfv)

> t(t(Out))

#This is the data set?

structure(list(terms = structure(c(2L, 4L, 4L, 4L, 3L, 1L, 5L,?

5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,?

6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,?

6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label = c("#authentication,access control",?

"#privacy,personal data", "#security,malicious,security", "data controller",?

"id management,security", "password,recovery"), class = "factor"),?

? ? class.1 = c(2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L,?

? ? 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L,?

? ? 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 1L,?

? ? 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L), class.2 = c(2L, 2L, 2L,?

? ? 0L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 2L,?

? ? 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L,?

? ? 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L,?

? ? 2L, 2L), class.3 = c(2L, 0L, 2L, 2L, 1L, 1L, 0L, 0L, 0L,?

? ? 2L, 2L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,?

? ? 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,?

? ? 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L)), .Names = c("terms",?

"class.1", "class.2", "class.3"), class = "data.frame", row.names = c(NA,?

-50L))

========================================================

also when I try to include the terms to the result it gives me an error:

> mode.names<- data.frame (df[,1],Out)

Error in data.frame(df[, 1], Out) :?

arguments imply differing number of rows: 50, 3

On Thu, May 28, 2015 at 9:24 AM, Mohammad Alimohammadi <mxalimohamma at ualr.edu> wrote:

Thank you David for your help !

On Wed, May 27, 2015 at 7:31 PM, David L Carlson <dcarlson at tamu.edu> wrote:

	cat(paste0("[", 1:length(Out), "] #dac ? ? ", Out), sep="\n")

	David

	From: Mohammad Alimohammadi [mailto:mxalimohamma at ualr.edu] 
 Sent: Wednesday, May 27, 2015 2:29 PM
 To: David L Carlson; r-help at r-project.org

 Subject: Re: [R] Problem with comparing multiple data sets

	Thanks David it worked !

	One more thing. I hope it's not complicated. Is it also possible to display the terms for each row next to it?

	for example:

	[1] #dac ? ?2

	[2] #dac ? ?0

	[3] #dac ? ?1

	...

	On Wed, May 27, 2015 at 2:18 PM, David L Carlson <dcarlson at tamu.edu> wrote:

	Save the result of the apply() function:

 Out <- apply(df[ ,2:length(df)], 1, mfv)

 Then there are several options:

 Approximately what you asked for
 data.frame(Out)
 t(t(Out))

 More typing but exactly what you asked for
 cat(paste0("[", 1:length(Out), "] ", Out), sep="\n")

 David L. Carlson
 Department of Anthropology
 Texas A&M University

 -----Original Message-----
 From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Mohammad Alimohammadi
 Sent: Wednesday, May 27, 2015 1:47 PM
 To: John Kane; r-help at r-project.org
 Subject: Re: [R] Problem with comparing multiple data sets

 Ok. so I read about the ("modeest") package that gives the results that I
 am looking for (most repeated value).

 I modified the data frame a little and moved the text to the first column.
 This is the data frame with all 3 possible classes for each term.

 =================================
 structure(list(terms = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 4L, 4L,
 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label = c("#dac",
 "#mac,#security",
 "accountability,anonymous", "data security,encryption,security"
 ), class = "factor"), class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L,
 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L,
 1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), class.2 = c(2L, 2L,
 2L, 2L, 0L, 0L, 2L, 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L,
 0L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L),
 ? ? class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 ? ? 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 ? ? 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L, 1L,
 ? ? 0L, 0L, 0L, 0L, 2L, 1L, 2L)), .Names = c("terms", "class.1",
 "class.2", "class.3"), class = "data.frame", row.names = c(NA,
 -49L))
 =============================================
 #Then I applied the function below:

 ======================
 library(modeest)
 df<- read.csv(file="short.csv", head= TRUE, sep=",")
 apply(df[ ,2:length(df)], 1, mfv)

 ============================
 # It gives the most frequent value for each row which is what I need. The
 only problem is that all the values are displayed in one single row.

 ?[1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 2 1 1 1 1 0 0 0 0 2 1 2

 It would be much better to show them in separate rows.
 For example:

 ?[1] 0

 ?[2] 0

 ?[3] 1
 ....

 Any idea how to do this?

	On Wed, May 27, 2015 at 10:11 AM, Mohammad Alimohammadi <
 mxalimohamma at ualr.edu> wrote:

 > Hi Jim,
 >
 > Thank you for your advice.
 >
 > I'm not sure how to exactly incorporate this function though. I added a
 > portion of the actual data sets. all 3 data sets have the same items (text)
 > with different class values. So I need to assign the most repeated class
 > (0,1,2) for each text.
 >
 > For example: if line1 has text "aaa". It may be assigned to class 0 in
 > dat1, 2 in dat 2 and 0 in dat3. in this case the "aaa" will be assigned to
 > 0 (most repeated value). So it goes for each text.
 >
 > I really appreciate your help.
 >
 > =========================================
 >
 > *dat1*
 >
 > structure(list(class.1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
 > 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
 > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
 > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
 > 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
 > c("#dac",
 > "#mac,#security", "accountability,anonymous", "data
 > security,encryption,security"
 > ), class = "factor")), .Names = c("class.1", "terms"), class =
 > "data.frame", row.names = c(NA,
 > -49L))
 >
 >
 > *dat2*
 >
 > structure(list(class.2 = c(2L, 2L, 2L, 2L, 0L, 0L, 2L, 0L, 0L,
 > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 2L, 2L, 2L, 1L, 1L, 2L,
 > 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L), terms = structure(c(1L, 1L,
 > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
 > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
 > 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
 > c("#dac",
 > "#mac,#security", "accountability,anonymous", "data
 > security,encryption,security"
 > ), class = "factor")), .Names = c("class.2", "terms"), class =
 > "data.frame", row.names = c(NA,
 > -49L))
 >
 >
 > *dat3*

	>
 > structure(list(class.3 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
 > 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 2L, 1L, 1L, 1L,
 > 1L, 0L, 0L, 0L, 0L, 2L, 1L, 2L), terms = structure(c(1L, 1L,
 > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
 > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
 > 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L), .Label =
 > c("#dac",
 > "#mac,#security", "accountability,anonymous", "data
 > security,encryption,security"
 > ), class = "factor")), .Names = c("class.3", "terms"), class =
 > "data.frame", row.names = c(NA,
 > -49L))
 >
 > ===========================================================
 >
 >
 > On Sun, May 24, 2015 at 1:15 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
 >
 >> Hi Mohammad,
 >> You know, I thought this would be fairly easy, but it wasn't really.
 >>
 >> df1<-data.frame(Class=c(0,2,1),Comment=c("com1","com2","com3"),
 >>? Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
 >> df2<-data.frame(Class=c(0,2,1),Comment=c("com1","com2","com3"),
 >>? Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
 >> df3<-data.frame(Class=c(2,1,0),Comment=c("com1","com2","com3"),
 >>? Term=c("aac","aax","vvx"),Text=c("text1","text2","text3"))
 >> dflist<-list(df1,df2,df3)
 >> dflist
 >>
 >> # define a function that extracts the value from one field
 >> # selected by a value in another field
 >> extract_by_value<-function(x,field1,value1,field2) {
 >>? return(x[x[,field1]==value1,field2])
 >> }
 >>
 >> # define another function that equates all of the values
 >> sub_value<-function(x,field1,value1,field2,value2) {
 >>? x[x[,field1]==value1,field2]<-value2
 >>? return(x)
 >> }
 >>
 >> conformity<-function(x,fieldname1,value1,fieldname2) {
 >>? # get the most frequent value in fieldname2
 >>? # for the desired value in fieldname1
 >>? most_freq<-as.numeric(names(which.max(table(unlist(lapply(x,
 >>? ?extract_by_value,fieldname1,value1,fieldname2))))))
 >>? # now set all the values to the most frequent
 >>? for(i in 1:length(x))
 >>? ?x[[i]]<-sub_value(x[[i]],fieldname1,value1,fieldname2,most_freq)
 >>? return(x)
 >> }
 >>
 >> conformity(dflist,"Text","text1","Class")
 >>
 >> Jim
 >>
 >> On Sat, May 23, 2015 at 11:23 PM, John Kane <jrkrideau at inbox.com> wrote:
 >> > Hi Mohammad
 >> >
 >> > Welcome to the R-help list.
 >> >
 >> > There probably is a fairly easy way to what you want but I think we
 >> probably need a bit more background information on what you are trying to
 >> achieve.? I know I'm not exactly clear on your decision rule(s).
 >> >
 >> > It would also be very useful to see some actual sample data in useable
 >> R format.Have a look at these links
 >> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]
 >> and http://adv-r.had.co.nz/Reproducibility.html [http://adv-r.had.co.nz/Reproducibility.html] for some hints on what
 >> you might want to include in your question.
 >> >
 >> > In particular, read up about dput()? in those links and/or see ?dput.
 >> This is the generally preferred way to supply sample or illustrative data
 >> to the R-help list.? It basically creates a perfect copy of the data as it
 >> exists on 'your' machine so that R-help readers see exactly what you do.
 >> >
 >> >
 >> >
 >> >
 >> >
 >> >
 >> >
 >> > John Kane
 >> > Kingston ON Canada
 >> >
 >> >
 >> >> -----Original Message-----
 >> >> From: mxalimohamma at ualr.edu
 >> >> Sent: Fri, 22 May 2015 12:37:50 -0500
 >> >> To: r-help at r-project.org
 >> >> Subject: [R] Problem with comparing multiple data sets
 >> >>
 >> >> Hi everyone,
 >> >>
 >> >> I am very new to R and I have a task to do. I appreciate any help. I
 >> have
 >> >> 3
 >> >> data sets. Each data set has 4 columns. For example:
 >> >>
 >> >> Class? Comment? ?Term? ?Text
 >> >> 0? ? ? ? ? ?com1? ? ? ? aac? ? text1
 >> >> 2? ? ? ? ? ?com2? ? ? ? aax? ? text2
 >> >> 1? ? ? ? ? ?com3? ? ? ? vvx? ? text3
 >> >>
 >> >> Now I need t compare the class section between 3 data sets and assign
 >> the
 >> >> most available class to that text. For example if text1 is assigned to
 >> >> class 0 in data set 1&2 but assigned as 2 in data set 3 then it should
 >> be
 >> >> assigned to class 0. If they are all the same so the class will be the
 >> >> same. The ideal thing would be to keep the same format and just update
 >> >> the
 >> >> class. Is there any easy way to do this?
 >> >>
 >> >> Thanks a lot.
 >> >>
 >> >>? ? ? ?[[alternative HTML version deleted]]
 >> >>
 >> >> ______________________________________________
 >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 >> >> https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 >> >> PLEASE do read the posting guide
 >> >> http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 >> >> and provide commented, minimal, self-contained, reproducible code.
 >> >
 >> > ____________________________________________________________
 >> > FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
 >> >
 >> > ______________________________________________
 >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 >> > https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 >> > PLEASE do read the posting guide
 >> http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 >> > and provide commented, minimal, self-contained, reproducible code.
 >>
 >
 >
 >
 > --
 > Mohammad Alimohammadi | Graduate Assistant
 > University of Arkansas at Little Rock | College of Science and Mathematics
 > (CSAM)
 > | mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu]
 >
 > Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]
 >

	--
 Mohammad Alimohammadi | Graduate Assistant
 University of Arkansas at Little Rock | College of Science and Mathematics
 (CSAM)
 501.346.8007?|  mxalimohamma at ualr.edu | ualr.edu [http://ualr.edu]

 Public URL: http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]

	? ? ? ? [[alternative HTML version deleted]]

 ______________________________________________
 R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 PLEASE do read the posting guide http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 and provide commented, minimal, self-contained, reproducible code.

	-- 

	Mohammad Alimohammadi | Graduate Assistant

	University of Arkansas at Little Rock | College of Science and?Mathematics (CSAM)?

	501.346.8007 | mxalimohamma at ualr.edu?| ualr.edu [http://ualr.edu/]

	Public URL:?http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]

-- 

Mohammad Alimohammadi | Graduate Assistant
University of Arkansas at Little Rock | College of Science and?Mathematics (CSAM)?

501.346.8007 | mxalimohamma at ualr.edu?| ualr.edu [http://ualr.edu/]

Public URL:?http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]

-- 

Mohammad Alimohammadi | Graduate Assistant
University of Arkansas at Little Rock | College of Science and?Mathematics (CSAM)?

501.346.8007 | mxalimohamma at ualr.edu?| ualr.edu [http://ualr.edu/]

Public URL:?http://scholar.google.com/citations?user=MsfN_i8AAAAJ [http://scholar.google.com/citations?user=MsfN_i8AAAAJ]

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From tanasa at gmail.com  Sat May 30 00:47:17 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Fri, 29 May 2015 15:47:17 -0700
Subject: [R] about transforming a data.frame
In-Reply-To: <CAM_vjun=LHGBcnGNfY29HBuTJNghE9ht0oeW6PO9JRCZzgUp-g@mail.gmail.com>
References: <CA+JEM03i23EwH+n4vBM44_9=osoimk6P=KS8B8sLB6CzodO4oQ@mail.gmail.com>
	<CAM_vju=x8yOj5o9gRPx=nnaTQitDb9ueexf65F+Eg8DNJp0z2g@mail.gmail.com>
	<CA+JEM02ptDsO3gq_1-a4_F2feSdxKzker5mM914rmAbvodXc3Q@mail.gmail.com>
	<CAM_vju=oH1d78KYMvHGP1kdS7+UNgpTkkweSXp65g58Xema3iQ@mail.gmail.com>
	<CA+JEM02kH+nePE9C4zotxq0unSj2LgZhhgGAuddWf2yR0-voOg@mail.gmail.com>
	<CAM_vjun=LHGBcnGNfY29HBuTJNghE9ht0oeW6PO9JRCZzgUp-g@mail.gmail.com>
Message-ID: <CA+JEM02=GJE3znYUNzdYxXN=_C24i=Qb_q1R-bEJgtbayQ1OnA@mail.gmail.com>

thanks a lot Sarah, very much appreciate it !

On Fri, May 29, 2015 at 3:18 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> LMGTFY:
> http://stackoverflow.com/questions/11433432/importing-multiple-csv-files-into-r
>
> On Fri, May 29, 2015 at 5:58 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> > Dear Sarah,
> >
> > thank you very much, it is very helpful. please may I ask one more
> question
> > about a quick and easy tutorial about the loading multiple files (from a
> > folder) in R, and processing one file at a time ?  thanks very much
> again,
> >
> > bogdan
> >
> > On Fri, May 29, 2015 at 2:55 PM, Sarah Goslee <sarah.goslee at gmail.com>
> > wrote:
> >>
> >> I'm still not really clear on what you need (format, etc), but this
> >> may help you get started:
> >>
> >> > with(df, table(CT, row_names))
> >>    row_names
> >> CT  A1:A2:A3 B10:B11:B12 B4:B5:B6 B7:B8:B9 D10:D11:D12 D4:D5:D6
> >> E10:E11:E12
> >>   2        0           0        0        1           2        1
> >> 1
> >>   4        1           1        0        0           0        0
> >> 0
> >>   5        0           0        1        0           0        0
> >> 0
> >> > with(df, table(CT, col_names))
> >>    col_names
> >> CT  B1:B2:B3 D1:D2:D3 F10:F11:F12 G7:G8:G9 H1:H2:H3 H4:H5:H6
> >>   2        1        0           1        1        1        1
> >>   4        1        1           0        0        0        0
> >>   5        1        0           0        0        0        0
> >> >
> >>
> >> On Fri, May 29, 2015 at 4:58 PM, Bogdan Tanasa <tanasa at gmail.com>
> wrote:
> >> > Hi Sarah,
> >> >
> >> > thank you for your help. I have simplified the example, by reading the
> >> > elements in a data frame, eg :
> >> >
> >> > df <- data.frame (row_names = c("B4:B5:B6", "B7:B8:B9", "D4:D5:D6",
> >> > "D10:D11:D12", "D10:D11:D12", "E10:E11:E12", "A1:A2:A3",
> "B10:B11:B12"),
> >> > col_names = c
> >> >
> >> >
> ("B1:B2:B3","B1:B2:B3","H4:H5:H6","F10:F11:F12","H1:H2:H3","G7:G8:G9","D1:D2:D3","B1:B2:B3"),
> >> > CT = c(5,2,2,2,2,2,4,4) )
> >> >
> >> > I have used the the count() in the plyr package :
> >> >
> >> > count_row_names <- count(df$row_names)
> >> > count_col_names <- count(df$col_names)
> >> >
> >> > however, I would need to correlate these UNIQUE ELEMENTS in the
> columns
> >> > "row_names" or "col_names" with the numbers they associate in the  CT
> >> > columns, eg :
> >> >
> >> > ""B1:B2:B3" associate with "5, 2, 4" (in CT column), or "D10:D11:D12"
> >> > associate with "2" (in the CT column).
> >> >
> >> > thank you very much,
> >> >
> >> > bogdan
> >> >
> >> >
> >> >
> >> >
> >> > On Fri, May 29, 2015 at 1:32 PM, Sarah Goslee <sarah.goslee at gmail.com
> >
> >> > wrote:
> >> >>
> >> >> Hi,
> >> >>
> >> >> Please use dput() to provide your data, as it can get somewhat
> mangled
> >> >> by copy and pasting, especially if you post in HTML (as you are asked
> >> >> not to do in the posting guide).
> >> >>
> >> >> What is a unique element? is "B4:B5:B6" an element, or are "B4" and
> >> >> "B5" each elements? That is, what is the result you expect to obtain
> >> >> for the sample data you provided?
> >> >>
> >> >> What code have you tried? I would think table() might be involved,
> and
> >> >> possibly strsplit(), but will refrain from putting more time into
> this
> >> >> until you provide a reproducible dataset with dput() and some clearer
> >> >> idea of your intent.
> >> >>
> >> >> Sarah
> >> >>
> >> >> On Fri, May 29, 2015 at 4:19 PM, Bogdan Tanasa <tanasa at gmail.com>
> >> >> wrote:
> >> >> > Dear all,
> >> >> >
> >> >> > I would appreciate a suggestion on the following : I am working
> with
> >> >> > a
> >> >> > data.frame (below) :
> >> >> >
> >> >> >   EXP    CT   row_names   col_names
> >> >> > 1   test -5    B4:B5:B6    B1:B2:B3
> >> >> > 2   test -2    B7:B8:B9    B1:B2:B3
> >> >> > 3   test -2    D4:D5:D6    H4:H5:H6
> >> >> > 4   test -2    D10:D11:D12 F10:F11:F12
> >> >> > 5   test -2    D10:D11:D12    H1:H2:H3
> >> >> > 6   test -2    E10:E11:E12    G7:G8:G9
> >> >> > 7   test -4     A1:A2:A3    D1:D2:D3
> >> >> > 8   test -4   B10:B11:B12    B1:B2:B3
> >> >> >
> >> >> > what would be the easiest way to consider UNIQUE elements in the
> >> >> > ROW_NAMES
> >> >> > or the UNIQUE elements in the COL_NAMES and :
> >> >> >
> >> >> > print how many times these UNIQUE ELEMENTS associate with the
> numbers
> >> >> > -5,
> >> >> > -2, or -4 (these numbers are on the column names CT) ..
> >> >> >
> >> >> > thanks,
> >> >> >
> >> >> > bogdan
> >> >> >
> >
> >
>

	[[alternative HTML version deleted]]


From adtrombley at gmail.com  Sat May 30 00:31:56 2015
From: adtrombley at gmail.com (Austin Trombley)
Date: Fri, 29 May 2015 15:31:56 -0700 (PDT)
Subject: [R] TWS and R
In-Reply-To: <1353047748288-4649699.post@n4.nabble.com>
References: <1353047748288-4649699.post@n4.nabble.com>
Message-ID: <6464ed03-efc8-4d8a-b528-a71665f27e9c@googlegroups.com>

Has anyone found a solution to this?  I am having the same issue?  thanks! 

On Thursday, November 15, 2012 at 10:35:48 PM UTC-8, abcd1234 wrote:
>
> Hi all, 
>
>  The TWS on my system is unable to connect to my R session. Here is the 
> error that I'm getting: 
>
> /> tws<-twsConnect() 
> Error in socketConnection(host = host, port = port, open = "ab", blocking 
> = 
> blocking) : 
> cannot open the connection 
> In addition: Warning message: 
> In socketConnection(host = host, port = port, open = "ab", blocking = 
> blocking) : 
> localhost:7496 cannot be opened/ 
>
> Here is the session info for the R session: 
> / 
> R version 2.15.1 (2012-06-22) 
>  Platform: x86_64-pc-linux-gnu (64-bit) 
> locale: 
>  [1] LC_CTYPE=en_IN.UTF-8LC_NUMERIC=C 
>
>  [3] LC_TIME=en_IN.UTF-8LC_COLLATE=en_IN.UTF-8 
>   
> [5] LC_MONETARY=en_IN.UTF-8LC_MESSAGES=en_IN.UTF-8 
>   
> [7] LC_PAPER=CLC_NAME=C 
>
>  [9] LC_ADDRESS=CLC_TELEPHONE=C 
>
>  [11] LC_MEASUREMENT=en_IN.UTF-8 LC_IDENTIFICATION=C 
>
>  attached base packages: 
> [1] statsgraphicsgrDevices utilsdatasets 
> [6] methodsbase 
>   
> other attached packages: 
>  [1] IBrokers_0.9-10 xts_0.8-6zoo_1.7-8 
>
>  loaded via a namespace (and not attached): 
>  [1] grid_2.15.1lattice_0.20-0 tools_2.15.1/ 
>
> I have checked the "Enable Activex and Socket clients"  but it hasn't 
> helped. Since I'm running on an Ubuntu machine, I even tried changing the 
> parameter blocking in the command twsConnect() to 
>
> 1. blocking = FALSE 
>
> 2. According to the one mentioned here 
>
> http://code.google.com/p/ibrokers/source/detail?r=84&path=/trunk/R/twsConnect.R 
>   
> but nothing has helped. 
>
> I have also added 127.0.0.1 to the "Trusted IP" option. 
>
>  Please let me know what I should do. 
>
> Thanks. 
>
>
>
>
> -- 
> View this message in context: 
> http://r.789695.n4.nabble.com/TWS-and-R-tp4649699.html 
> Sent from the R help mailing list archive at Nabble.com. 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From zeyn2307 at gmail.com  Fri May 29 16:49:28 2015
From: zeyn2307 at gmail.com (zeynab jibril)
Date: Fri, 29 May 2015 15:49:28 +0100
Subject: [R] vectorized code
Message-ID: <CAH8tL_h7AZ5EjE6q4m2W=3w0=hnEBemzCTuDmjgqNcEJ4R+Tww@mail.gmail.com>

HI

I was working on online example, where virus is spread through a graph. The
example is sufficient for small graph i.e. small number of edges and nodes.
But I tried it on very large graph i.e. 10000 nodes and 20000 edges, but
the below function is not sufficient for large graph because its slow.

My question is how can the below function be converted to Vectorized code
can be optimized for large graphs?

spreadVirus <- function(G,Vinitial,Activation_probability){



# Precompute all outgoing graph adjacencies



G$AdjList = get.adjlist(G,mode="out")



# Initialize various graph attributes

V(G)$color    = "blue"

E(G)$color    = "black"

V(G)[Vinitial]$color    <- "yellow"



# List to store the incremental graphs (for plotting later)

Glist <- list(G)

count <- 1



# Spread the infection

active <- Vinitial



while(length(active)>0){

new_infected <- NULL

E(G)$color = "black"



for(v in active){

# spread through the daily contacts of vertex v



daily_contacts <- G$AdjList[[v]]



E(G)[v %->% daily_contacts]$color <- "red"



for(v1 in daily_contacts){



if(V(G)[v1]$color == "blue" & new_color=="red") {



V(G)[v1]$color <- "red"



new_infected <- c(new_infected,v1)



 }

}

}

# the next active set

#this needed for updating



active <- new_infected



# Add graph to list

# optional dependening on if i want to graph

count <- count + 1

Glist[[count]] <- G

}

return(Glist)

}

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri May 29 23:40:35 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 30 May 2015 07:40:35 +1000
Subject: [R] about transforming a data.frame
In-Reply-To: <82824615D6C.00000F5Djrkrideau@inbox.com>
References: <cam_vju=x8yoj5o9grpx=nnatqitdb9ueexf65f+eg8dnjp0z2g@mail.gmail.com>
	<ca+jem03i23ewh+n4vbm44_9=osoimk6p=ks8b8slb6czodo4oq@mail.gmail.com>
	<CA+JEM02ptDsO3gq_1-a4_F2feSdxKzker5mM914rmAbvodXc3Q@mail.gmail.com>
	<82824615D6C.00000F5Djrkrideau@inbox.com>
Message-ID: <CA+8X3fWZPQ+BkOcb_h9fZ7rNVpWDnj52cs-z4XqV9O41H5+khw@mail.gmail.com>

Hi Bogdan,
Sarah has already suggested this, but doesn't:

table(df$row_names,df$CT)
table(df$col_names,df$CT)

give you what you want?

Jim


On Sat, May 30, 2015 at 7:11 AM, John Kane <jrkrideau at inbox.com> wrote:
> Bogdan, the request was for data in dput() format.
>
> Type ?dput for more information.
>
> Do dput(myfile) copy the ouput and paste into the email
>
> You should get something like:
> structure(list(c1 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
> 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
> 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L,
> 8L, 8L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L), .Label = c("(0.509,0.614]",
> "(0.614,0.718]", "(0.718,0.822]", "(0.822,0.926]", "(0.926,1.03]",
> "(1.03,1.13]", "(1.13,1.24]", "(1.24,1.34]", "(1.34,1.45]", "(1.45,1.55]"
> ), class = "factor"), s1 = c(0.51, 0.52, 0.58, 0.58, 0.59, 0.6,
> 0.63, 0.65, 0.68, 0.74, 0.74, 0.75, 0.77, 0.77, 0.77, 0.78, 0.79,
> 0.84, 0.84, 0.85, 0.87, 0.93, 0.93, 0.95, 0.99, 1.04, 1.09, 1.11,
> 1.13, 1.14, 1.14, 1.14, 1.17, 1.18, 1.19, 1.22, 1.22, 1.23, 1.28,
> 1.29, 1.3, 1.32, 1.37, 1.38, 1.38, 1.4, 1.43, 1.47, 1.52, 1.55
> )), .Names = c("c1", "s1"), row.names = c(NA, -50L), class = "data.frame")
>
> Data in duput() format is the preferred way to get data in R-help since it provides a perfect copy of what you have on your machine.  Any other way of providing data risks the recipients reading it into R differently than it is on your machine.
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: tanasa at gmail.com
>> Sent: Fri, 29 May 2015 13:58:20 -0700
>> To: sarah.goslee at gmail.com
>> Subject: Re: [R] about transforming a data.frame
>>
>> Hi Sarah,
>>
>> thank you for your help. I have simplified the example, by reading the
>> elements in a data frame, eg :
>>
>> df <- data.frame (row_names = c("B4:B5:B6", "B7:B8:B9", "D4:D5:D6",
>> "D10:D11:D12", "D10:D11:D12", "E10:E11:E12", "A1:A2:A3", "B10:B11:B12"),
>> col_names = c
>> ("B1:B2:B3","B1:B2:B3","H4:H5:H6","F10:F11:F12","H1:H2:H3","G7:G8:G9","D1:D2:D3","B1:B2:B3"),
>> CT = c(5,2,2,2,2,2,4,4) )
>>
>> I have used the the count() in the plyr package :
>>
>> count_row_names <- count(df$row_names)
>> count_col_names <- count(df$col_names)
>>
>> however, I would need to correlate these UNIQUE ELEMENTS in the columns
>> "row_names" or "col_names" with the numbers they associate in the  CT
>> columns, eg :
>>
>> ""B1:B2:B3" associate with "5, 2, 4" (in CT column), or "D10:D11:D12"
>> associate with "2" (in the CT column).
>>
>> thank you very much,
>>
>> bogdan
>>
>>
>>
>>
>> On Fri, May 29, 2015 at 1:32 PM, Sarah Goslee <sarah.goslee at gmail.com>
>> wrote:
>>
>>> Hi,
>>>
>>> Please use dput() to provide your data, as it can get somewhat mangled
>>> by copy and pasting, especially if you post in HTML (as you are asked
>>> not to do in the posting guide).
>>>
>>> What is a unique element? is "B4:B5:B6" an element, or are "B4" and
>>> "B5" each elements? That is, what is the result you expect to obtain
>>> for the sample data you provided?
>>>
>>> What code have you tried? I would think table() might be involved, and
>>> possibly strsplit(), but will refrain from putting more time into this
>>> until you provide a reproducible dataset with dput() and some clearer
>>> idea of your intent.
>>>
>>> Sarah
>>>
>>> On Fri, May 29, 2015 at 4:19 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
>>>> Dear all,
>>>>
>>>> I would appreciate a suggestion on the following : I am working with a
>>>> data.frame (below) :
>>>>
>>>>   EXP    CT   row_names   col_names
>>>> 1   test -5    B4:B5:B6    B1:B2:B3
>>>> 2   test -2    B7:B8:B9    B1:B2:B3
>>>> 3   test -2    D4:D5:D6    H4:H5:H6
>>>> 4   test -2    D10:D11:D12 F10:F11:F12
>>>> 5   test -2    D10:D11:D12    H1:H2:H3
>>>> 6   test -2    E10:E11:E12    G7:G8:G9
>>>> 7   test -4     A1:A2:A3    D1:D2:D3
>>>> 8   test -4   B10:B11:B12    B1:B2:B3
>>>>
>>>> what would be the easiest way to consider UNIQUE elements in the
>>> ROW_NAMES
>>>> or the UNIQUE elements in the COL_NAMES and :
>>>>
>>>> print how many times these UNIQUE ELEMENTS associate with the numbers
>>>> -5,
>>>> -2, or -4 (these numbers are on the column names CT) ..
>>>>
>>>> thanks,
>>>>
>>>> bogdan
>>>>
>>> --
>>> Sarah Goslee
>>> http://www.functionaldiversity.org
>>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
> Visit http://www.inbox.com/photosharing to find out more!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hpages at fredhutch.org  Sat May 30 01:12:48 2015
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 29 May 2015 16:12:48 -0700
Subject: [R] Converting unique strings to unique numbers
In-Reply-To: <CAF8bMca=bunKEDBj37ibpHXGQ97bxO-7ke=PnE0O9kk0Wh7xhw@mail.gmail.com>
References: <CAE6QMsbz8P2T4PuXEzThewAhRbBiLeg+ifGQ5cd1RxKbZAAyFQ@mail.gmail.com>
	<5568AD19.7020606@fredhutch.org>
	<CAM_vjum9u394LkEwikvqz78FHzifSjAH7jVti+GxN3riDxMDtw@mail.gmail.com>
	<5568CC3D.5050709@fredhutch.org>
	<CAF8bMca=bunKEDBj37ibpHXGQ97bxO-7ke=PnE0O9kk0Wh7xhw@mail.gmail.com>
Message-ID: <5568F270.60605@fredhutch.org>

Hi Bill,

On 05/29/2015 01:48 PM, William Dunlap wrote:
>>I'm not sure why which particular ID gets assigned to each string would
>>matter but maybe I'm missing something. What really matters is that each
>>string receives a unique ID. match(x, x) does that.
>
> I think each row of the OP's dataset represented an individual (column 2)
> followed by its mother and father (columns 3 and 4).  I assume that the
> marker "0" means that a parent is not in the dataset.  If you match against
> the strings in column 2 only, in their original order, then the
> resulting numbers
> give the row number of an individual,

Note that the code I gave happens to do exactly that (assuming that
column 2 contains no duplicates, but your code is also relying on that
assumption in order to have the ids match the row numbers).

We're discussing the merit of match(x, x) versus match(x, unique(x)).
All I'm trying to say is that the unique(x) step (which doubles the cost
of the whole operation, because it also uses hashing, like match() does)
is generally not needed. It doesn't seem to be needed in Kate's use
case.

H.

> making it straightforward to look up
> information regarding the ancestors of an individual.  Hence the choice of
> numeric ID's may be important.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
>
> On Fri, May 29, 2015 at 1:29 PM, Herv? Pag?s <hpages at fredhutch.org
> <mailto:hpages at fredhutch.org>> wrote:
>
>     Hi Sarah,
>
>     On 05/29/2015 12:04 PM, Sarah Goslee wrote:
>
>         On Fri, May 29, 2015 at 2:16 PM, Herv? Pag?s
>         <hpages at fredhutch.org <mailto:hpages at fredhutch.org>> wrote:
>
>             Hi Kate,
>
>             I found that matching the character vector to itself is a very
>             effective way to do this:
>
>                 x <- c("a", "bunch", "of", "strings", "whose", "exact",
>             "content",
>                        "is", "of", "little", "interest")
>                 ids <- match(x, x)
>                 ids
>                 # [1]  1  2  3  4  5  6  7  8  3 10 11
>
>             By using this trick, many manipulations on character vectors can
>             be replaced by manipulations on integer vectors, which are
>             sometimes
>             way more efficient.
>
>
>         Hm. I hadn't thought of that approach - I use the
>         as.numeric(factor(...)) approach.
>
>         So I was curious, and compared the two:
>
>
>         set.seed(43)
>         x <- sample(letters, 10000, replace=TRUE)
>
>         system.time({
>             for(i in seq_len(20000)) {
>             ids1 <- match(x, x)
>         }})
>
>         #   user  system elapsed
>         #  9.657   0.000   9.657
>
>         system.time({
>             for(i in seq_len(20000)) {
>             ids2 <- as.numeric(factor(x, levels=letters))
>         }})
>
>         #   user  system elapsed
>         #   6.16    0.00    6.16
>
>         Using factor() is faster.
>
>
>     That's an unfair comparison, because you already know what the levels
>     are so you can supply them to your call to factor(). Most of the time
>     you don't know what the levels are so either you just do factor(x) and
>     let the factor() constructor compute the levels for you, or you compute
>     them yourself upfront with something like factor(x, levels=unique(x)).
>
>        library(microbenchmark)
>
>        microbenchmark(
>          {ids1 <- match(x, x)},
>          {ids2 <- as.integer(factor(x, levels=letters))},
>          {ids3 <- as.integer(factor(x))},
>          {ids4 <- as.integer(factor(x, levels=unique(x)))}
>        )
>        Unit: microseconds
>                                                            expr     min
>           lq
>                                     {     ids1 <- match(x, x) } 245.979
>     262.2390
>         {     ids2 <- as.integer(factor(x, levels = letters)) } 214.115
>     219.2320
>                           {     ids3 <- as.integer(factor(x)) } 380.782
>     388.7295
>       {     ids4 <- as.integer(factor(x, levels = unique(x))) } 332.250
>     342.6630
>             mean   median      uq     max neval
>         267.3210 264.4845 268.348 293.894   100
>         226.9913 220.9870 226.147 314.875   100
>         402.2242 394.7165 412.075 481.410   100
>         349.7405 345.3090 353.162 383.002   100
>
>         More importantly, using factor() lets you
>         set the order of the indices in an expected fashion, where match()
>         assigns them in the order of occurrence.
>
>         head(data.frame(x, ids1, ids2))
>
>             x ids1 ids2
>         1 m    1   13
>         2 x    2   24
>         3 b    3    2
>         4 s    4   19
>         5 i    5    9
>         6 o    6   15
>
>         In a problem like Kate's where there are several columns for
>         which the
>         same ordering of indices is desired, that becomes really important.
>
>
>     I'm not sure why which particular ID gets assigned to each string would
>     matter but maybe I'm missing something. What really matters is that each
>     string receives a unique ID. match(x, x) does that.
>
>     In Kate's problem, where the strings are in more than one column,
>     and you want the ID to be unique across the columns, you need to do
>     match(x, x) where 'x' contains the strings from all the columns
>     that you want to replace:
>
>        m <- matrix(c(
>          "X0001", "BYX859",        0,        0,  2,  1, "BYX859",
>          "X0001", "BYX894",        0,        0,  1,  1, "BYX894",
>          "X0001", "BYX862", "BYX894", "BYX859",  2,  2, "BYX862",
>          "X0001", "BYX863", "BYX894", "BYX859",  2,  2, "BYX863",
>          "X0001", "BYX864", "BYX894", "BYX859",  2,  2, "BYX864",
>          "X0001", "BYX865", "BYX894", "BYX859",  2,  2, "BYX865"
>        ), ncol=7, byrow=TRUE)
>
>        x <- m[ , 2:4]
>        id <- match(x, x, nomatch=0, incomparables="0")
>        m[ , 2:4] <- id
>
>     No factor needed. No loop needed. ;-)
>
>     Cheers,
>     H.
>
>
>         If you take Bill Dunlap's modification of the match() approach, it
>         resolves both problems: matching against the pooled unique values is
>         both faster than the factor() version and gives the same result:
>
>
>         On Fri, May 29, 2015 at 1:31 PM, William Dunlap
>         <wdunlap at tibco.com <mailto:wdunlap at tibco.com>> wrote:
>
>             match() will do what you want.  E.g., run your data through
>             the following function.
>
>         f <- function (data)
>         {
>               uniqStrings <- unique(c(data[, 2], data[, 3], data[, 4]))
>               uniqStrings <- setdiff(uniqStrings, "0")
>               for (j in 2:4) {
>                   data[[j]] <- match(data[[j]], uniqStrings, nomatch = 0L)
>               }
>               data
>         }
>
>         ##
>
>         y <- data.frame(id = 1:5000, v1 = sample(letters, 5000,
>         replace=TRUE),
>         v2 = sample(letters, 5000, replace=TRUE), v3 = sample(letters, 5000,
>         replace=TRUE), stringsAsFactors=FALSE)
>
>
>         system.time({
>             for(i in seq_len(20000)) {
>               ids3 <- f(data.frame(y))
>         }})
>
>         #   user  system elapsed
>         # 22.515   0.000  22.518
>
>
>
>         ff <- function(data)
>         {
>               uniqStrings <- unique(c(data[, 2], data[, 3], data[, 4]))
>               uniqStrings <- setdiff(uniqStrings, "0")
>               for (j in 2:4) {
>                   data[[j]] <- as.numeric(factor(data[[j]],
>         levels=uniqStrings))
>               }
>               data
>         }
>
>         system.time({
>             for(i in seq_len(20000)) {
>               ids4 <- ff(data.frame(y))
>         }})
>
>         #    user  system elapsed
>         #  26.083   0.002  26.090
>
>         head(ids3)
>
>             id v1 v2 v3
>         1  1  1  2  8
>         2  2  2 19 22
>         3  3  3 21 16
>         4  4  4 10 17
>         5  5  1  8 18
>         6  6  1 12 26
>
>         head(ids4)
>
>             id v1 v2 v3
>         1  1  1  2  8
>         2  2  2 19 22
>         3  3  3 21 16
>         4  4  4 10 17
>         5  5  1  8 18
>         6  6  1 12 26
>
>         Kate, if you're getting all zeros, check str(yourdataframe) - it's
>         likely that when you imported your data into R the strings were
>         already converted to factors, which is not what you want (ask me
>         how I
>         know this!).
>
>         Sarah
>
>
>
>             On 05/29/2015 09:58 AM, Kate Ignatius wrote:
>
>
>                 I have a pedigree file as so:
>
>                 X0001 BYX859      0      0  2  1 BYX859
>                 X0001 BYX894      0      0  1  1 BYX894
>                 X0001 BYX862 BYX894 BYX859  2  2 BYX862
>                 X0001 BYX863 BYX894 BYX859  2  2 BYX863
>                 X0001 BYX864 BYX894 BYX859  2  2 BYX864
>                 X0001 BYX865 BYX894 BYX859  2  2 BYX865
>
>                 And I was hoping to change all unique string values to
>                 numbers.
>
>                 That is:
>
>                 BYX859 = 1
>                 BYX894 = 2
>                 BYX862 = 3
>                 BYX863 = 4
>                 BYX864 = 5
>                 BYX865 = 6
>
>                 But only in columns 2 - 4.  Essentially I would like the
>                 data to look like
>                 this:
>
>                 X0001 1 0 0  2  1 BYX859
>                 X0001 2 0 0  1  1 BYX894
>                 X0001 3 2 1  2  2 BYX862
>                 X0001 4 2 1  2  2 BYX863
>                 X0001 5 2 1  2  2 BYX864
>                 X0001 6 2 1  2  2 BYX865
>
>                 Is this possible with factors?
>
>                 Thanks!
>
>                 K.
>
>
>
>
>     --
>     Herv? Pag?s
>
>     Program in Computational Biology
>     Division of Public Health Sciences
>     Fred Hutchinson Cancer Research Center
>     1100 Fairview Ave. N, M1-B514
>     P.O. Box 19024
>     Seattle, WA 98109-1024
>
>     E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>     Phone: (206) 667-5791 <tel:%28206%29%20667-5791>
>     Fax: (206) 667-1319 <tel:%28206%29%20667-1319>
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From drjimlemon at gmail.com  Sat May 30 01:21:32 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 30 May 2015 09:21:32 +1000
Subject: [R] about transforming a data.frame
In-Reply-To: <CA+JEM02=GJE3znYUNzdYxXN=_C24i=Qb_q1R-bEJgtbayQ1OnA@mail.gmail.com>
References: <CA+JEM03i23EwH+n4vBM44_9=osoimk6P=KS8B8sLB6CzodO4oQ@mail.gmail.com>
	<CAM_vju=x8yOj5o9gRPx=nnaTQitDb9ueexf65F+Eg8DNJp0z2g@mail.gmail.com>
	<CA+JEM02ptDsO3gq_1-a4_F2feSdxKzker5mM914rmAbvodXc3Q@mail.gmail.com>
	<CAM_vju=oH1d78KYMvHGP1kdS7+UNgpTkkweSXp65g58Xema3iQ@mail.gmail.com>
	<CA+JEM02kH+nePE9C4zotxq0unSj2LgZhhgGAuddWf2yR0-voOg@mail.gmail.com>
	<CAM_vjun=LHGBcnGNfY29HBuTJNghE9ht0oeW6PO9JRCZzgUp-g@mail.gmail.com>
	<CA+JEM02=GJE3znYUNzdYxXN=_C24i=Qb_q1R-bEJgtbayQ1OnA@mail.gmail.com>
Message-ID: <CA+8X3fWgMyXfAVsaSV8EUiBGBL84tPZSLAOcKM91GY0_tQuCCw@mail.gmail.com>

Hi Bogdan,
If you mean "How can I verify that "B1:B2:B3" is paired with all of
the values 2, 4 and 5"

apply(table(df$col_names,df$CT),1,all)

and if you mean "How can I verify that "B1:B2:B3" is paired with at
least one of the values 2, 4 and 5"

apply(table(df$col_names,df$CT),1,any)

Jim


Hi Jim,

yes, thank you, that is the desired output. one more question please :
after using the dataframe :

df <- data.frame (row_names = c("B4:B5:B6", "B7:B8:B9", "D4:D5:D6",
"D10:D11:D12", "D10:D11:D12", "E10:E11:E12", "A1:A2:A3",
"B10:B11:B12"),  col_names = c
("B1:B2:B3","B1:B2:B3","H4:H5:H6","F10:F11:F12","H1:H2:H3","G7:G8:G9","D1:D2:D3","B1:B2:B3"),
CT = c(5,2,2,2,2,2,4,4) )

and :

table(df$row_names,df$CT)
table(df$col_names,df$CT)

how could I quickly verify that "B1:B2:B3" (for example) hits the CT
values of 2,4,5  at least one time ? an example is in

table(df$col_names,df$CT) ?

thank you very much,

-- bogdan


From tanasa at gmail.com  Sat May 30 01:29:28 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Fri, 29 May 2015 16:29:28 -0700
Subject: [R] about transforming a data.frame
In-Reply-To: <CA+8X3fWgMyXfAVsaSV8EUiBGBL84tPZSLAOcKM91GY0_tQuCCw@mail.gmail.com>
References: <CA+JEM03i23EwH+n4vBM44_9=osoimk6P=KS8B8sLB6CzodO4oQ@mail.gmail.com>
	<CAM_vju=x8yOj5o9gRPx=nnaTQitDb9ueexf65F+Eg8DNJp0z2g@mail.gmail.com>
	<CA+JEM02ptDsO3gq_1-a4_F2feSdxKzker5mM914rmAbvodXc3Q@mail.gmail.com>
	<CAM_vju=oH1d78KYMvHGP1kdS7+UNgpTkkweSXp65g58Xema3iQ@mail.gmail.com>
	<CA+JEM02kH+nePE9C4zotxq0unSj2LgZhhgGAuddWf2yR0-voOg@mail.gmail.com>
	<CAM_vjun=LHGBcnGNfY29HBuTJNghE9ht0oeW6PO9JRCZzgUp-g@mail.gmail.com>
	<CA+JEM02=GJE3znYUNzdYxXN=_C24i=Qb_q1R-bEJgtbayQ1OnA@mail.gmail.com>
	<CA+8X3fWgMyXfAVsaSV8EUiBGBL84tPZSLAOcKM91GY0_tQuCCw@mail.gmail.com>
Message-ID: <CA+JEM00Ny1rHEFSNqc-HPNSNhXLb8QMhtqjVU-COVxdVz1XB7A@mail.gmail.com>

Thanks a lot Jim. If I may ask one more little question please,

shall I ask the question ""How can I verify that "B1:B2:B3" is paired with
ALL of the values 2, 4 and 5 ",

regardless of the pairing value (in our case, for the code below, the
"pairing value" for "B1:B2:B3" is 1, but it can be 2,3,4, etc BUT NOT
zero),

how could I test for that ? or this is the way that "apply" works for "all"
argument ?

a good documentation for "apply" function will help too . thanks, and happy
weekend !

-- bogdan


On Fri, May 29, 2015 at 4:21 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Bogdan,
> If you mean "How can I verify that "B1:B2:B3" is paired with all of
> the values 2, 4 and 5"
>
> apply(table(df$col_names,df$CT),1,all)
>
> and if you mean "How can I verify that "B1:B2:B3" is paired with at
> least one of the values 2, 4 and 5"
>
> apply(table(df$col_names,df$CT),1,any)
>
> Jim
>
>
> Hi Jim,
>
> yes, thank you, that is the desired output. one more question please :
> after using the dataframe :
>
> df <- data.frame (row_names = c("B4:B5:B6", "B7:B8:B9", "D4:D5:D6",
> "D10:D11:D12", "D10:D11:D12", "E10:E11:E12", "A1:A2:A3",
> "B10:B11:B12"),  col_names = c
>
> ("B1:B2:B3","B1:B2:B3","H4:H5:H6","F10:F11:F12","H1:H2:H3","G7:G8:G9","D1:D2:D3","B1:B2:B3"),
> CT = c(5,2,2,2,2,2,4,4) )
>
> and :
>
> table(df$row_names,df$CT)
> table(df$col_names,df$CT)
>
> how could I quickly verify that "B1:B2:B3" (for example) hits the CT
> values of 2,4,5  at least one time ? an example is in
>
> table(df$col_names,df$CT) ?
>
> thank you very much,
>
> -- bogdan
>

	[[alternative HTML version deleted]]


From tanasa at gmail.com  Sat May 30 01:41:29 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Fri, 29 May 2015 16:41:29 -0700
Subject: [R] about transforming a data.frame
In-Reply-To: <CA+JEM00Ny1rHEFSNqc-HPNSNhXLb8QMhtqjVU-COVxdVz1XB7A@mail.gmail.com>
References: <CA+JEM03i23EwH+n4vBM44_9=osoimk6P=KS8B8sLB6CzodO4oQ@mail.gmail.com>
	<CAM_vju=x8yOj5o9gRPx=nnaTQitDb9ueexf65F+Eg8DNJp0z2g@mail.gmail.com>
	<CA+JEM02ptDsO3gq_1-a4_F2feSdxKzker5mM914rmAbvodXc3Q@mail.gmail.com>
	<CAM_vju=oH1d78KYMvHGP1kdS7+UNgpTkkweSXp65g58Xema3iQ@mail.gmail.com>
	<CA+JEM02kH+nePE9C4zotxq0unSj2LgZhhgGAuddWf2yR0-voOg@mail.gmail.com>
	<CAM_vjun=LHGBcnGNfY29HBuTJNghE9ht0oeW6PO9JRCZzgUp-g@mail.gmail.com>
	<CA+JEM02=GJE3znYUNzdYxXN=_C24i=Qb_q1R-bEJgtbayQ1OnA@mail.gmail.com>
	<CA+8X3fWgMyXfAVsaSV8EUiBGBL84tPZSLAOcKM91GY0_tQuCCw@mail.gmail.com>
	<CA+JEM00Ny1rHEFSNqc-HPNSNhXLb8QMhtqjVU-COVxdVz1XB7A@mail.gmail.com>
Message-ID: <CA+JEM00jdW31STkQ7XP3eQqQFq6SiWLoQLWRkAz9Ez8eFEpiXg@mail.gmail.com>

Hi Jim,

thanks again. now I see : the answer to my previous question seems to be
yes, as "all" functions works on logical vectors ... best wishes,

-- bogdan

On Fri, May 29, 2015 at 4:29 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:

> Thanks a lot Jim. If I may ask one more little question please,
>
> shall I ask the question ""How can I verify that "B1:B2:B3" is paired with
> ALL of the values 2, 4 and 5 ",
>
> regardless of the pairing value (in our case, for the code below, the
> "pairing value" for "B1:B2:B3" is 1, but it can be 2,3,4, etc BUT NOT
> zero),
>
> how could I test for that ? or this is the way that "apply" works for
> "all" argument ?
>
> a good documentation for "apply" function will help too . thanks, and
> happy weekend !
>
> -- bogdan
>
>
> On Fri, May 29, 2015 at 4:21 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Bogdan,
>> If you mean "How can I verify that "B1:B2:B3" is paired with all of
>> the values 2, 4 and 5"
>>
>> apply(table(df$col_names,df$CT),1,all)
>>
>> and if you mean "How can I verify that "B1:B2:B3" is paired with at
>> least one of the values 2, 4 and 5"
>>
>> apply(table(df$col_names,df$CT),1,any)
>>
>> Jim
>>
>>
>> Hi Jim,
>>
>> yes, thank you, that is the desired output. one more question please :
>> after using the dataframe :
>>
>> df <- data.frame (row_names = c("B4:B5:B6", "B7:B8:B9", "D4:D5:D6",
>> "D10:D11:D12", "D10:D11:D12", "E10:E11:E12", "A1:A2:A3",
>> "B10:B11:B12"),  col_names = c
>>
>> ("B1:B2:B3","B1:B2:B3","H4:H5:H6","F10:F11:F12","H1:H2:H3","G7:G8:G9","D1:D2:D3","B1:B2:B3"),
>> CT = c(5,2,2,2,2,2,4,4) )
>>
>> and :
>>
>> table(df$row_names,df$CT)
>> table(df$col_names,df$CT)
>>
>> how could I quickly verify that "B1:B2:B3" (for example) hits the CT
>> values of 2,4,5  at least one time ? an example is in
>>
>> table(df$col_names,df$CT) ?
>>
>> thank you very much,
>>
>> -- bogdan
>>
>
>

	[[alternative HTML version deleted]]


From mark at markdrummond.ca  Sat May 30 04:12:56 2015
From: mark at markdrummond.ca (Mark Drummond)
Date: Fri, 29 May 2015 22:12:56 -0400
Subject: [R] Toronto CRAN mirror 403 error?
Message-ID: <CAAb4XW2TwA+=Kz4bQu2S7q9u=WqdgeJq5YB-o0T=1hSnLZ52WQ@mail.gmail.com>

I've been getting a 403 when I try pulling from the Toronto CRAN mirror
today.

http://cran.utstat.utoronto.ca/

Is there a contact list for mirror managers?

-- 
Cheers, Mark

*Mark Drummond*
mark at markdrummond.ca

When I get sad, I stop being sad and be Awesome instead. TRUE STORY.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat May 30 01:14:14 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 30 May 2015 09:14:14 +1000
Subject: [R] Problem with comparing multiple data sets
In-Reply-To: <8343EF0F57B.000010A1jrkrideau@inbox.com>
References: <ca+8x3fw4bwsq2u-epumzqzsfl-4syjzakfr56qs8i-fmk7hpfa@mail.gmail.com>
	<53bf8fb63faf2e4a9455ef1ee94da7262d68ea9d@mb02.ads.tamu.edu>
	<cajvfk9k+qk9cuqrbtlmajyvdu5erzhtd1verhnabpkhiikdoaq@mail.gmail.com>
	<cajvfk9nm_a2gr86oximhbc8hzon45rmwll_vmxak4rpoj1=oqw@mail.gmail.com>
	<cajvfk9m1lcja8dxu9w4cymgkpgnyhnnseey7cbln4qfwukommg@mail.gmail.com>
	<cajvfk9kx-hjyeud5q=y6kgxy8oyzw3j4shhxduv39jj1f43mta@mail.gmail.com>
	<cajvfk9k7zjlg8ip+sl_eamyzfr_=en40q3ob5fe2zwqca0suoa@mail.gmail.com>
	<32fceb5d574.0000035fjrkrideau@inbox.com>
	<53bf8fb63faf2e4a9455ef1ee94da7262d68ebff@mb02.ads.tamu.edu>
	<CAJVfk9nf-w1aEtpzL7VkhcAOkNYeoY1cv5WL3CakJ-MWE6B16Q@mail.gmail.com>
	<8343EF0F57B.000010A1jrkrideau@inbox.com>
Message-ID: <CA+8X3fW=_OyWSHPH55yd-zQKng3_M8OrE6zR0m80OVreX+RVOw@mail.gmail.com>

Hi Mohammad,
It looks like you are still having problems with this. Given your
latest data set, as below, here is something that might do what you
want. From David's message, I'm not sure whether you are operating on
a single data frame or a list.

# this is the data set as taken from your message below
madf<-structure(list(terms = structure(c(2L, 4L, 4L, 4L, 3L, 1L, 5L,
5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label =
c("#authentication,access control",
"#privacy,personal data", "#security,malicious,security", "data controller",
"id management,security", "password,recovery"), class = "factor"),
    class.1 = c(2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L,
    2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L,
    1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 1L,
    2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L), class.2 = c(2L, 2L, 2L,
    0L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 2L,
    2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L,
    2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L,
    2L, 2L), class.3 = c(2L, 0L, 2L, 2L, 1L, 1L, 0L, 0L, 0L,
    2L, 2L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L)), .Names = c("terms",
"class.1", "class.2", "class.3"), class = "data.frame", row.names = c(NA,
-50L))

# define a function that extracts the value from one field
# selected by a value in another field
extract_by_value<-function(x,field1,value1,field2) {
 return(x[x[,field1]==value1,field2])
}

# define another function that equates all of the values
sub_value<-function(x,field1,value1,field2,value2) {
 x[x[,field1]==value1,field2]<-value2
 return(x)
}

# this now steps through every value in "key_field"
# and operates on every field listed in "change_fields"
conformity<-function(x,key_field,change_fields) {
 keys<-unique(x[,key_field])
 for(key in keys) {
  for(change_field in change_fields) {
   # get the most frequent value in change_field
   # for the desired value in key_field
   most_freq<-as.numeric(names(which.max(table(
    extract_by_value(x,key_field,key,change_field)))))
   # now set all the values to the most frequent
   x<-sub_value(x,key_field,key,change_field,most_freq)
  }
 }
 return(x)
}

conformity(madf,"terms",c("class.1","class.2","class.3"))

Obviously you will want to save the return value of "conformity" into
your original data frame or create a new one.

Jim

> Hi everyone.
>
> I tried the (modeest) package on my initial test data and it worked. However, it doesn't work on the entire data set. I saved one of the protions that gives error. (Not for all of the values but for some of them). For example: lines 36 and 37 and 39 correctly show the mode value but 38 and 40 are not correct. Such error is repeated for many of the values.
>
> [36,] 2
>
> [37,] 2
>
> [38,] Numeric,3
>
> [39,] 1
>
> [40,] Numeric,3
>
> ============================================
>
> #This is what I did:
>
>> df<- read.csv(file="Part1-modif.csv", head=TRUE, sep=",")
>
>> Out<- apply(df[,2:length(df)],1, mfv)
>
>> t(t(Out))
>
> #This is the data set
>
> structure(list(terms = structure(c(2L, 4L, 4L, 4L, 3L, 1L, 5L,
>
> 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
>
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
>
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label = c("#authentication,access control",
>
> "#privacy,personal data", "#security,malicious,security", "data controller",
>
> "id management,security", "password,recovery"), class = "factor"),
>
>     class.1 = c(2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L,
>
>     2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L,
>
>     1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 1L,
>
>     2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L), class.2 = c(2L, 2L, 2L,
>
>     0L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 2L,
>
>     2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L,
>
>     2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 2L,
>
>     2L, 2L), class.3 = c(2L, 0L, 2L, 2L, 1L, 1L, 0L, 0L, 0L,
>
>     2L, 2L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>
>     0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>
>     0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L)), .Names = c("terms",
>
> "class.1", "class.2", "class.3"), class = "data.frame", row.names = c(NA,
>
> -50L))
>
> ========================================================
>
> also when I try to include the terms to the result it gives me an error:
>
>> mode.names<- data.frame (df[,1],Out)
>
> Error in data.frame(df[, 1], Out) :
>
> arguments imply differing number of rows: 50, 3
>


From jdnewmil at dcn.davis.CA.us  Sat May 30 05:03:11 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 29 May 2015 20:03:11 -0700
Subject: [R] Toronto CRAN mirror 403 error?
In-Reply-To: <CAAb4XW2TwA+=Kz4bQu2S7q9u=WqdgeJq5YB-o0T=1hSnLZ52WQ@mail.gmail.com>
References: <CAAb4XW2TwA+=Kz4bQu2S7q9u=WqdgeJq5YB-o0T=1hSnLZ52WQ@mail.gmail.com>
Message-ID: <7132AD04-A9A2-4832-B83D-CB8C94FCBEE3@dcn.davis.CA.us>

This is why there are mirrors. You don't have to wait for them or tell them to do their jobs.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 29, 2015 7:12:56 PM PDT, Mark Drummond <mark at markdrummond.ca> wrote:
>I've been getting a 403 when I try pulling from the Toronto CRAN mirror
>today.
>
>http://cran.utstat.utoronto.ca/
>
>Is there a contact list for mirror managers?


From dwinsemius at comcast.net  Sat May 30 05:27:52 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 29 May 2015 20:27:52 -0700
Subject: [R] Toronto CRAN mirror 403 error?
In-Reply-To: <CAAb4XW2TwA+=Kz4bQu2S7q9u=WqdgeJq5YB-o0T=1hSnLZ52WQ@mail.gmail.com>
References: <CAAb4XW2TwA+=Kz4bQu2S7q9u=WqdgeJq5YB-o0T=1hSnLZ52WQ@mail.gmail.com>
Message-ID: <91C32F86-EE1D-47A5-B9C0-CC475FEDE028@comcast.net>


On May 29, 2015, at 7:12 PM, Mark Drummond wrote:

> I've been getting a 403 when I try pulling from the Toronto CRAN mirror
> today.
> 
> http://cran.utstat.utoronto.ca/

Right. It's been out for the last 2.7 days:

http://cran.r-project.org/mirmon_report.html#ca

> 
> Is there a contact list for mirror managers?

Why do you care? Why not use another mirror? The http://lib.stat.cmu.edu/R/CRAN/ mirror should be fairly close if you are on that side of the continent.

-- 
David.

> 
> -- 
> Cheers, Mark
> 
> *Mark Drummond*
> mark at markdrummond.ca
> 
> When I get sad, I stop being sad and be Awesome instead. TRUE STORY.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ggrothendieck at gmail.com  Sat May 30 06:02:32 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 30 May 2015 00:02:32 -0400
Subject: [R] Toronto CRAN mirror 403 error?
In-Reply-To: <CAAb4XW2TwA+=Kz4bQu2S7q9u=WqdgeJq5YB-o0T=1hSnLZ52WQ@mail.gmail.com>
References: <CAAb4XW2TwA+=Kz4bQu2S7q9u=WqdgeJq5YB-o0T=1hSnLZ52WQ@mail.gmail.com>
Message-ID: <CAP01uRk5vxAm9tzRJTMEd_awjVRfCxocs0b8sXSEs6v7qCFumg@mail.gmail.com>

On Fri, May 29, 2015 at 10:12 PM, Mark Drummond <mark at markdrummond.ca> wrote:
> I've been getting a 403 when I try pulling from the Toronto CRAN mirror
> today.
>
> http://cran.utstat.utoronto.ca/
>
> Is there a contact list for mirror managers?
>

See the cran_mirrors.csv file in
  R.home("doc")
of your R distribution.


From shivibhatia at ymail.com  Sat May 30 06:55:25 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Fri, 29 May 2015 21:55:25 -0700 (PDT)
Subject: [R] Help on R Functionality & Histogram
In-Reply-To: <CAM_vjumQyDS2dwg=gYF_6SRGCbp7xpZ1k6KU1FRVfGQxDr8XLg@mail.gmail.com>
References: <1432900397222-4707886.post@n4.nabble.com>
	<CAM_vjumQyDS2dwg=gYF_6SRGCbp7xpZ1k6KU1FRVfGQxDr8XLg@mail.gmail.com>
Message-ID: <1432961725207-4707949.post@n4.nabble.com>

Thanks you Sarah. This was very impressive and really helped me out.




--
View this message in context: http://r.789695.n4.nabble.com/Help-on-R-Functionality-Histogram-tp4707886p4707949.html
Sent from the R help mailing list archive at Nabble.com.


From nicholas.wray at ntlworld.com  Sat May 30 12:29:09 2015
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Sat, 30 May 2015 11:29:09 +0100
Subject: [R] Arrays of variable dimensionality
Message-ID: <CALcakBaD0cwMZU+kH6gO7uLgFRr_NyFpn85cJmbtYNqwH6pK_Q@mail.gmail.com>

Hello folks

Supposing I have a multidimensional array in an R prog, say a 4D array.

I want the coordinate quantities to be read off from a vector.  The values
in the vector (vec) are generated by a function.

This is easy if the number of dimensions is fixed for both the array and
the number of elements in the  vector (say 4):

X<-array[vec[1],vec[2],vec[3],vec[4]]

But if the number of dimensions of the array is not fixed and can change
during the course of the prog I am stuck as to how to do this, as I don?t
know a way of feeding a vector or list of unspecified beforehand length
into the coordinates for an array

I can?t find anything useful about this on the net

Does anyone have any ideas?
Thanks, Nick

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat May 30 13:18:56 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 30 May 2015 21:18:56 +1000
Subject: [R] Arrays of variable dimensionality
In-Reply-To: <CALcakBaD0cwMZU+kH6gO7uLgFRr_NyFpn85cJmbtYNqwH6pK_Q@mail.gmail.com>
References: <CALcakBaD0cwMZU+kH6gO7uLgFRr_NyFpn85cJmbtYNqwH6pK_Q@mail.gmail.com>
Message-ID: <CA+8X3fWUHJ4tMdz4b8L3UQXMBx6JxY7b6dLKtq9k4CTzc6rPFw@mail.gmail.com>

Hi Nick,
Does length(dim(X)) help by getting the current dimensions of the
array before you pass the vectors of indices?

Jim


On Sat, May 30, 2015 at 8:29 PM, WRAY NICHOLAS
<nicholas.wray at ntlworld.com> wrote:
> Hello folks
>
> Supposing I have a multidimensional array in an R prog, say a 4D array.
>
> I want the coordinate quantities to be read off from a vector.  The values
> in the vector (vec) are generated by a function.
>
> This is easy if the number of dimensions is fixed for both the array and
> the number of elements in the  vector (say 4):
>
> X<-array[vec[1],vec[2],vec[3],vec[4]]
>
> But if the number of dimensions of the array is not fixed and can change
> during the course of the prog I am stuck as to how to do this, as I don?t
> know a way of feeding a vector or list of unspecified beforehand length
> into the coordinates for an array
>
> I can?t find anything useful about this on the net
>
> Does anyone have any ideas?
> Thanks, Nick
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat May 30 13:23:53 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 30 May 2015 07:23:53 -0400
Subject: [R] Toronto CRAN mirror 403 error?
In-Reply-To: <91C32F86-EE1D-47A5-B9C0-CC475FEDE028@comcast.net>
References: <CAAb4XW2TwA+=Kz4bQu2S7q9u=WqdgeJq5YB-o0T=1hSnLZ52WQ@mail.gmail.com>
	<91C32F86-EE1D-47A5-B9C0-CC475FEDE028@comcast.net>
Message-ID: <55699DC9.1010303@gmail.com>

On 29/05/2015 11:27 PM, David Winsemius wrote:
> 
> On May 29, 2015, at 7:12 PM, Mark Drummond wrote:
> 
>> I've been getting a 403 when I try pulling from the Toronto CRAN mirror
>> today.
>>
>> http://cran.utstat.utoronto.ca/
> 
> Right. It's been out for the last 2.7 days:
> 
> http://cran.r-project.org/mirmon_report.html#ca
> 
>>
>> Is there a contact list for mirror managers?
> 
> Why do you care? Why not use another mirror? The http://lib.stat.cmu.edu/R/CRAN/ mirror should be fairly close if you are on that side of the continent.
> 

It's possible that the mirror manager is unaware of this, and might like
to be informed.  I know him, and will send an email.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Sat May 30 13:30:27 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 30 May 2015 12:30:27 +0100
Subject: [R] Arrays of variable dimensionality
In-Reply-To: <CALcakBaD0cwMZU+kH6gO7uLgFRr_NyFpn85cJmbtYNqwH6pK_Q@mail.gmail.com>
References: <CALcakBaD0cwMZU+kH6gO7uLgFRr_NyFpn85cJmbtYNqwH6pK_Q@mail.gmail.com>
Message-ID: <55699F53.10009@stats.ox.ac.uk>

On 30/05/2015 11:29, WRAY NICHOLAS wrote:
> Hello folks
>
> Supposing I have a multidimensional array in an R prog, say a 4D array.
>
> I want the coordinate quantities to be read off from a vector.  The values
> in the vector (vec) are generated by a function.

It is not clear what you want to do.
>
> This is easy if the number of dimensions is fixed for both the array and
> the number of elements in the  vector (say 4):
>
> X<-array[vec[1],vec[2],vec[3],vec[4]]

Is 'array' an array and not the function of that name?

I am guess you are missing do.call, the way to generate calls with 
variable-length argument lists.  My guess of your intention could be written

arr <- array(1:256, rep(4,4))
vec <- 1:4
arr[1, 2, 3, 4] # same as
do.call(`[`, c(list(arr), as.list(vec)))

>
> But if the number of dimensions of the array is not fixed and can change
> during the course of the prog I am stuck as to how to do this, as I don?t
> know a way of feeding a vector or list of unspecified beforehand length
> into the coordinates for an array
>
> I can?t find anything useful about this on the net
>
> Does anyone have any ideas?
> Thanks, Nick
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
PLEASE do.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From sohail13 at gmail.com  Sat May 30 13:40:07 2015
From: sohail13 at gmail.com (Sohail Khan)
Date: Sat, 30 May 2015 07:40:07 -0400
Subject: [R] lapply function
Message-ID: <CABUTPBm-UVm7wdz+u0Cv_-bd=uJP0D7ueC9T_cLKJTxHGHu9cQ@mail.gmail.com>

Hi R Gurus,

I am writing a simple function that take a numeric vector column from a
data frame and scales the vector column with certain criteria.  I would
then pass this function to a list of dataframes by lappy.

Question is how do I write a function that works on a numeric vector.  My
function as is, seems to work on the first element of the vector.

I.E.
scale
function(x,mn,max){
if (x==min(x)) 0

if (x==max(x)) 10
else x=max-min/10
}

where x is the numeric column of the dataframe.

Thank you.

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Sat May 30 13:51:53 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 30 May 2015 07:51:53 -0400
Subject: [R] lapply function
In-Reply-To: <CABUTPBm-UVm7wdz+u0Cv_-bd=uJP0D7ueC9T_cLKJTxHGHu9cQ@mail.gmail.com>
References: <CABUTPBm-UVm7wdz+u0Cv_-bd=uJP0D7ueC9T_cLKJTxHGHu9cQ@mail.gmail.com>
Message-ID: <CAM_vjumEo+MGgkVas7KYCoN3CEfswGrsrE1rG=4tD+HS5SnGGw@mail.gmail.com>

You need the vectorizes ifelse() instead of if().

Also watch out for order of operations in the last line, and there is
already a base R function named scale(). And spelling of arguments, of
course.

On Saturday, May 30, 2015, Sohail Khan <sohail13 at gmail.com> wrote:

> Hi R Gurus,
>
> I am writing a simple function that take a numeric vector column from a
> data frame and scales the vector column with certain criteria.  I would
> then pass this function to a list of dataframes by lappy.
>
> Question is how do I write a function that works on a numeric vector.  My
> function as is, seems to work on the first element of the vector.
>
> I.E.
> scale
> function(x,mn,max){
> if (x==min(x)) 0
>
> if (x==max(x)) 10
> else x=max-min/10
> }
>
> where x is the numeric column of the dataframe.
>
> Thank you.
>
>
>

-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From antoviral at gmail.com  Sat May 30 14:01:28 2015
From: antoviral at gmail.com (Antonello Preti)
Date: Sat, 30 May 2015 14:01:28 +0200
Subject: [R] metagen - plotStudySizes: order by year and not alphabetical
Message-ID: <CAPmpGDshuYcRL4E=uUzHk1xvY8yiAMtxpZr-ziYHZrt-F8iy-w@mail.gmail.com>

HI everybody.
I'm using the package 'metagen' to plot sample size in meta-analysis.
The plot function of the package reorders the studies by alphabetcial order.
However, I would like to have the studies listed by year.
How can I force the plotting function to order the study by the variable
'year' rather than by the first initial of the variable 'reference'?

Thank you in advance,
Antonello

Here my sample code:


### the data

df <- structure(list(reference = structure(c(3L, 6L, 9L, 2L, 8L, 5L,
7L, 10L, 4L, 1L), .Label = c("Bellani et al. 2012             ",
"Bocco et al. 2004              ", "Costa 1998          ",
"Dalla Volta et al. 2011           ", "Manzanere et al. 2006             ",
"McEnty et al. 2001             ", "Ossian et al. 2006                ",
"Simone et al. 2004               ", "Tanter et al. 2002         ",
"Zimmian et al. 2006              "), class = "factor"), size = c(20,
288, 70, 138, 475, 191, 918, 80, 508, 205), year = c(1998, 2001,
2002, 2004, 2004, 2006, 2006, 2006, 2011, 2012)), .Names = c("reference",
"size", "year"), class = "data.frame", row.names = c(NA, -10L
))

### a quick look at the data

head(df)
str(df)

### the library

library(metagen); library(ggplot2)

### the plot

p1 <- plotStudySizes(df)
p1 <- p1 + ggtitle("Studies with Cross-sectional estimates")
p1

	[[alternative HTML version deleted]]


From mark at markdrummond.ca  Sat May 30 14:56:32 2015
From: mark at markdrummond.ca (Mark Drummond)
Date: Sat, 30 May 2015 08:56:32 -0400
Subject: [R] Toronto CRAN mirror 403 error?
In-Reply-To: <7132AD04-A9A2-4832-B83D-CB8C94FCBEE3@dcn.davis.CA.us>
References: <CAAb4XW2TwA+=Kz4bQu2S7q9u=WqdgeJq5YB-o0T=1hSnLZ52WQ@mail.gmail.com>
	<7132AD04-A9A2-4832-B83D-CB8C94FCBEE3@dcn.davis.CA.us>
Message-ID: <CAAb4XW0RRoPBXiewn2GsBvYB_NuDVnptJ2pc4JzHrg-zN6-y0g@mail.gmail.com>

I am using another mirror. Just being a good net.citizen.

On Fri, May 29, 2015 at 11:03 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> This is why there are mirrors. You don't have to wait for them or tell
> them to do their jobs.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On May 29, 2015 7:12:56 PM PDT, Mark Drummond <mark at markdrummond.ca>
> wrote:
> >I've been getting a 403 when I try pulling from the Toronto CRAN mirror
> >today.
> >
> >http://cran.utstat.utoronto.ca/
> >
> >Is there a contact list for mirror managers?
>
>


-- 
Cheers, Mark

*Mark Drummond*
mark at markdrummond.ca

When I get sad, I stop being sad and be Awesome instead. TRUE STORY.

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Sat May 30 14:57:09 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 30 May 2015 04:57:09 -0800
Subject: [R] metagen - plotStudySizes: order by year and not alphabetical
In-Reply-To: <CAPmpGDshuYcRL4E=uUzHk1xvY8yiAMtxpZr-ziYHZrt-F8iy-w@mail.gmail.com>
Message-ID: <8AC37AFF4CF.000002AFjrkrideau@inbox.com>

Yes you can do it fairly easily in 'basic' ggplot2.  You need to change the references from factors to ordered factors and then plot.

Note your data is now called dat1 as df is an R function. Do ?df to see what it is.

dat1$reference  <- factor(dat1$reference, levels = dat1$reference[order(dat1$year)])
p1  <-  ggplot(dat1, aes( reference, size)) + geom_bar( stat = "identity") + coord_flip()
 p2   <- p1 + ggtitle("Studies with Cross-sectional estimates")
p2


I hope this helps
John Kane
Kingston ON Canada


> -----Original Message-----
> From: antoviral at gmail.com
> Sent: Sat, 30 May 2015 14:01:28 +0200
> To: r-help at r-project.org
> Subject: [R] metagen - plotStudySizes: order by year and not alphabetical
> 
> HI everybody.
> I'm using the package 'metagen' to plot sample size in meta-analysis.
> The plot function of the package reorders the studies by alphabetcial
> order.
> However, I would like to have the studies listed by year.
> How can I force the plotting function to order the study by the variable
> 'year' rather than by the first initial of the variable 'reference'?
> 
> Thank you in advance,
> Antonello
> 
> Here my sample code:
> 
> 
> ### the data
> 
> df <- structure(list(reference = structure(c(3L, 6L, 9L, 2L, 8L, 5L,
> 7L, 10L, 4L, 1L), .Label = c("Bellani et al. 2012             ",
> "Bocco et al. 2004              ", "Costa 1998          ",
> "Dalla Volta et al. 2011           ", "Manzanere et al. 2006
> ",
> "McEnty et al. 2001             ", "Ossian et al. 2006                ",
> "Simone et al. 2004               ", "Tanter et al. 2002         ",
> "Zimmian et al. 2006              "), class = "factor"), size = c(20,
> 288, 70, 138, 475, 191, 918, 80, 508, 205), year = c(1998, 2001,
> 2002, 2004, 2004, 2006, 2006, 2006, 2011, 2012)), .Names = c("reference",
> "size", "year"), class = "data.frame", row.names = c(NA, -10L
> ))
> 
> ### a quick look at the data
> 
> head(df)
> str(df)
> 
> ### the library
> 
> library(metagen); library(ggplot2)
> 
> ### the plot
> 
> p1 <- plotStudySizes(df)
> p1 <- p1 + ggtitle("Studies with Cross-sectional estimates")
> p1
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From mark at markdrummond.ca  Sat May 30 14:57:17 2015
From: mark at markdrummond.ca (Mark Drummond)
Date: Sat, 30 May 2015 08:57:17 -0400
Subject: [R] Toronto CRAN mirror 403 error?
In-Reply-To: <55699DC9.1010303@gmail.com>
References: <CAAb4XW2TwA+=Kz4bQu2S7q9u=WqdgeJq5YB-o0T=1hSnLZ52WQ@mail.gmail.com>
	<91C32F86-EE1D-47A5-B9C0-CC475FEDE028@comcast.net>
	<55699DC9.1010303@gmail.com>
Message-ID: <CAAb4XW0fgYdM9rKRtZtcu+m70McmMUjiLWx=gsFc5F7ta0=QoA@mail.gmail.com>

> It's possible that the mirror manager is unaware of this, and might like
> to be informed.  I know him, and will send an email.
>
> Duncan Murdoch

Thanks Duncan.


-- 
Cheers, Mark


From jrkrideau at inbox.com  Sat May 30 15:44:03 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 30 May 2015 05:44:03 -0800
Subject: [R] metagen - plotStudySizes: order by year and not alphabetical
In-Reply-To: <CAPmpGDshuYcRL4E=uUzHk1xvY8yiAMtxpZr-ziYHZrt-F8iy-w@mail.gmail.com>
Message-ID: <8B2C5312815.00000322jrkrideau@inbox.com>

Adding a bit of formatting
Where your data is dat1


dat1$reference  <- factor(dat1$reference, levels = dat1$reference[order(dat1$year)])
pp2 <-  ggplot(dat1, aes( reference, size)) + geom_bar( stat = "identity") + coord_flip()
 pp2   <- pp2 + ggtitle("Studies with Cross-sectional estimates") + 
         xlab("") + ylab("Total Number of Subjects")
pp2

John Kane
Kingston ON Canada


> -----Original Message-----
> From: antoviral at gmail.com
> Sent: Sat, 30 May 2015 14:01:28 +0200
> To: r-help at r-project.org
> Subject: [R] metagen - plotStudySizes: order by year and not alphabetical
> 
> HI everybody.
> I'm using the package 'metagen' to plot sample size in meta-analysis.
> The plot function of the package reorders the studies by alphabetcial
> order.
> However, I would like to have the studies listed by year.
> How can I force the plotting function to order the study by the variable
> 'year' rather than by the first initial of the variable 'reference'?
> 
> Thank you in advance,
> Antonello
> 
> Here my sample code:
> 
> 
> ### the data
> 
> df <- structure(list(reference = structure(c(3L, 6L, 9L, 2L, 8L, 5L,
> 7L, 10L, 4L, 1L), .Label = c("Bellani et al. 2012             ",
> "Bocco et al. 2004              ", "Costa 1998          ",
> "Dalla Volta et al. 2011           ", "Manzanere et al. 2006
> ",
> "McEnty et al. 2001             ", "Ossian et al. 2006                ",
> "Simone et al. 2004               ", "Tanter et al. 2002         ",
> "Zimmian et al. 2006              "), class = "factor"), size = c(20,
> 288, 70, 138, 475, 191, 918, 80, 508, 205), year = c(1998, 2001,
> 2002, 2004, 2004, 2006, 2006, 2006, 2011, 2012)), .Names = c("reference",
> "size", "year"), class = "data.frame", row.names = c(NA, -10L
> ))
> 
> ### a quick look at the data
> 
> head(df)
> str(df)
> 
> ### the library
> 
> library(metagen); library(ggplot2)
> 
> ### the plot
> 
> p1 <- plotStudySizes(df)
> p1 <- p1 + ggtitle("Studies with Cross-sectional estimates")
> p1
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From liuwensui at gmail.com  Sat May 30 16:09:01 2015
From: liuwensui at gmail.com (Wensui Liu)
Date: Sat, 30 May 2015 09:09:01 -0500
Subject: [R] alternatives to KS test applicable to K-samples
In-Reply-To: <F58B52FA-FC39-4C4B-87C1-3D2F388F424F@comcast.net>
References: <CAKyN3iBv73_FUsmH2S0nqsann4E-CqMPCt5+0XVwEX2PD50jzQ@mail.gmail.com>
	<F58B52FA-FC39-4C4B-87C1-3D2F388F424F@comcast.net>
Message-ID: <CAKyN3iDDZmMU=QsNhMJ6HEoWqL67JOqsUJPmz0n5dBUwspMVAg@mail.gmail.com>

Thanks for your insight, David
But I am not interested in comparing means among multiple groups.
Instead, I want to compare empirical distributions. In this case, I am
not sure if wilcoxon should be still applicable.

still appreciate it.

On Fri, May 29, 2015 at 1:32 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On May 29, 2015, at 9:31 AM, Wensui Liu wrote:
>
>> Good morning, All
>> I have a stat question not specifically related to the the programming language.
>> To compare distributional consistency / discrepancy between two
>> samples, we usually use kolmogorov-smirnov test, which is implemented
>> in R with ks.test() or in SAS with "pro npar1way edf".
>> I am wondering if there is any alternative to KS test that could be
>> generalized to K-samples.
>
> The 'coin' package (Hothorn, Hornick, van de Weil, and Zeileis) presents a variety of permutation and rank-based tests that would probably be more powerful than any multi-group variant of the KS test. The multi-group variant of the Wilcoxon Rank Sum Test presented in the examples for the help page: ?wilcox_test is the Nemenyi-Damico-Wolfe-Dunn test.
>
> --
>
> David Winsemius
> Alameda, CA, USA
>



-- 
==============================
WenSui Liu
Credit Risk Manager, 53 Bancorp
wensui.liu at 53.com
513-295-4370
==============================


From wdunlap at tibco.com  Sat May 30 18:36:39 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 30 May 2015 09:36:39 -0700
Subject: [R] Arrays of variable dimensionality
In-Reply-To: <CALcakBaD0cwMZU+kH6gO7uLgFRr_NyFpn85cJmbtYNqwH6pK_Q@mail.gmail.com>
References: <CALcakBaD0cwMZU+kH6gO7uLgFRr_NyFpn85cJmbtYNqwH6pK_Q@mail.gmail.com>
Message-ID: <CAF8bMcaJDmRWTzxAiPMmdzC7NCkjH7bHHrqhvc-soqsuNxxbBw@mail.gmail.com>

I don't know for sure what result you want, but it may be that
using a length(dim(array))-column matrix as your subscript will
do what you want.  E.g.,
  > a <- array(101:124, dim=4:2)
  > subscriptMatrix <- cbind(c(1,3), c(2,2), c(2,1))
  > subscriptMatrix
       [,1] [,2] [,3]
  [1,]    1    2    2
  [2,]    3    2    1
  > a[subscriptMatrix]
  [1] 117 107
  > a[1, 2, 2]
  [1] 117
  > a[3, 2, 1]
  [1] 107


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, May 30, 2015 at 3:29 AM, WRAY NICHOLAS <nicholas.wray at ntlworld.com>
wrote:

> Hello folks
>
> Supposing I have a multidimensional array in an R prog, say a 4D array.
>
> I want the coordinate quantities to be read off from a vector.  The values
> in the vector (vec) are generated by a function.
>
> This is easy if the number of dimensions is fixed for both the array and
> the number of elements in the  vector (say 4):
>
> X<-array[vec[1],vec[2],vec[3],vec[4]]
>
> But if the number of dimensions of the array is not fixed and can change
> during the course of the prog I am stuck as to how to do this, as I don?t
> know a way of feeding a vector or list of unspecified beforehand length
> into the coordinates for an array
>
> I can?t find anything useful about this on the net
>
> Does anyone have any ideas?
> Thanks, Nick
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sat May 30 19:34:25 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 30 May 2015 10:34:25 -0700
Subject: [R] Arrays of variable dimensionality
In-Reply-To: <CALcakBaD0cwMZU+kH6gO7uLgFRr_NyFpn85cJmbtYNqwH6pK_Q@mail.gmail.com>
References: <CALcakBaD0cwMZU+kH6gO7uLgFRr_NyFpn85cJmbtYNqwH6pK_Q@mail.gmail.com>
Message-ID: <76DE51A4-2D85-4B02-99B4-AE9DEDCF414B@dcn.davis.CA.us>

Don't.

Arrays in R don't have variable dimensions [1]. To the extent that you pretend otherwise, you will degrade performance and complicate your program. I would argue that similar effects arise in languages that do let you pretend that arrays have variable dimensions.

The main reason variable-sized arrays seem useful is that some algorithms or data sources yield variable amounts of data. There are various ways to handle these cases, and the use of lists to hold intermediate units of data followed by transfer of that data into an array (strategically handled after you know how big the array has to be) is one of the more common ones.

Another technique is to use one of the ragged array or sparse matrix data structures, but they generally work best when the data actually are sparse.

Being more specific about your immediate problem can elicit more specific help.

BTW please post plain text on this list... HTML is not supported by the list reflector and leads to misunderstandings.

[1] More precisely, the total number of elements in the underlying vector is fixed, though you can redefine how the dimensions use the elements in that vector. For example, study the "aperm" function.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On May 30, 2015 3:29:09 AM PDT, WRAY NICHOLAS <nicholas.wray at ntlworld.com> wrote:
>Hello folks
>
>Supposing I have a multidimensional array in an R prog, say a 4D array.
>
>I want the coordinate quantities to be read off from a vector.  The
>values
>in the vector (vec) are generated by a function.
>
>This is easy if the number of dimensions is fixed for both the array
>and
>the number of elements in the  vector (say 4):
>
>X<-array[vec[1],vec[2],vec[3],vec[4]]
>
>But if the number of dimensions of the array is not fixed and can
>change
>during the course of the prog I am stuck as to how to do this, as I
>don?t
>know a way of feeding a vector or list of unspecified beforehand length
>into the coordinates for an array
>
>I can?t find anything useful about this on the net
>
>Does anyone have any ideas?
>Thanks, Nick
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat May 30 19:42:35 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 30 May 2015 10:42:35 -0700
Subject: [R] alternatives to KS test applicable to K-samples
In-Reply-To: <CAKyN3iDDZmMU=QsNhMJ6HEoWqL67JOqsUJPmz0n5dBUwspMVAg@mail.gmail.com>
References: <CAKyN3iBv73_FUsmH2S0nqsann4E-CqMPCt5+0XVwEX2PD50jzQ@mail.gmail.com>
	<F58B52FA-FC39-4C4B-87C1-3D2F388F424F@comcast.net>
	<CAKyN3iDDZmMU=QsNhMJ6HEoWqL67JOqsUJPmz0n5dBUwspMVAg@mail.gmail.com>
Message-ID: <9C7A6EAE-9656-4E86-A4D9-2B2511FE514D@comcast.net>


On May 30, 2015, at 7:09 AM, Wensui Liu wrote:

> Thanks for your insight, David
> But I am not interested in comparing means among multiple groups.
> Instead, I want to compare empirical distributions. In this case, I am
> not sure if wilcoxon should be still applicable.
> 
> still appreciate it.

The Wilcoxon Rank Sum is not comparing means (or medians as I mistakenly thought in the past) but is a more general test of location. You are correct in thinking that the KS test is implicitly testing a wider range of hypotheses, although it remains fairly weak against specific tests. I wasn't suggesting the coin package simply because of its capacity to generalize the WRS test but because of its capacity to support permutation tests of many sorts. 

If you are testing at all, then there would seem to be a likelihood (in the vague sense of consideration of possible goals of your testing proces) that you really would be interested in departures from "equality of distribution" that might have a more specific description, and might therefore be interested in testing strategies with more power, perhaps a compound test for differences in location and spread.

-- 
David.

 
> 
> On Fri, May 29, 2015 at 1:32 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> On May 29, 2015, at 9:31 AM, Wensui Liu wrote:
>> 
>>> Good morning, All
>>> I have a stat question not specifically related to the the programming language.
>>> To compare distributional consistency / discrepancy between two
>>> samples, we usually use kolmogorov-smirnov test, which is implemented
>>> in R with ks.test() or in SAS with "pro npar1way edf".
>>> I am wondering if there is any alternative to KS test that could be
>>> generalized to K-samples.
>> 
>> The 'coin' package (Hothorn, Hornick, van de Weil, and Zeileis) presents a variety of permutation and rank-based tests that would probably be more powerful than any multi-group variant of the KS test. The multi-group variant of the Wilcoxon Rank Sum Test presented in the examples for the help page: ?wilcox_test is the Nemenyi-Damico-Wolfe-Dunn test.
>> 
>> --
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
> 
> 
> 
> -- 
> ==============================
> WenSui Liu
> Credit Risk Manager, 53 Bancorp
> wensui.liu at 53.com
> 513-295-4370
> ==============================

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Sat May 30 20:02:38 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 30 May 2015 11:02:38 -0700
Subject: [R] alternatives to KS test applicable to K-samples
In-Reply-To: <9C7A6EAE-9656-4E86-A4D9-2B2511FE514D@comcast.net>
References: <CAKyN3iBv73_FUsmH2S0nqsann4E-CqMPCt5+0XVwEX2PD50jzQ@mail.gmail.com>
	<F58B52FA-FC39-4C4B-87C1-3D2F388F424F@comcast.net>
	<CAKyN3iDDZmMU=QsNhMJ6HEoWqL67JOqsUJPmz0n5dBUwspMVAg@mail.gmail.com>
	<9C7A6EAE-9656-4E86-A4D9-2B2511FE514D@comcast.net>
Message-ID: <CAGxFJbS3ikq-xbeV4v8aQSJ73S8GE1TLR4mAeykCFqUs8FEVkg@mail.gmail.com>

... or in not testing at all. The distributions are not the same, period.
So what. Testing for equality is useless -- the real question is: what
issues are you trying to address/ what questions are you trying to answer/
can they be answered with the data you have or plan to get?

In any case, this does not seem the proper venue for such matters, as it
has nothing to do with R -- for now, anyways (mea culpa). I would suggest
you post to a statistics list like stats.stackexchange.com to figure out
what you want to do and then maybe come back here as necessary (after
searching) to get any help you might need with R tools to do it.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Sat, May 30, 2015 at 10:42 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On May 30, 2015, at 7:09 AM, Wensui Liu wrote:
>
> > Thanks for your insight, David
> > But I am not interested in comparing means among multiple groups.
> > Instead, I want to compare empirical distributions. In this case, I am
> > not sure if wilcoxon should be still applicable.
> >
> > still appreciate it.
>
> The Wilcoxon Rank Sum is not comparing means (or medians as I mistakenly
> thought in the past) but is a more general test of location. You are
> correct in thinking that the KS test is implicitly testing a wider range of
> hypotheses, although it remains fairly weak against specific tests. I
> wasn't suggesting the coin package simply because of its capacity to
> generalize the WRS test but because of its capacity to support permutation
> tests of many sorts.
>
> If you are testing at all, then there would seem to be a likelihood (in
> the vague sense of consideration of possible goals of your testing proces)
> that you really would be interested in departures from "equality of
> distribution" that might have a more specific description, and might
> therefore be interested in testing strategies with more power, perhaps a
> compound test for differences in location and spread.
>
> --
> David.
>
>
> >
> > On Fri, May 29, 2015 at 1:32 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >>
> >> On May 29, 2015, at 9:31 AM, Wensui Liu wrote:
> >>
> >>> Good morning, All
> >>> I have a stat question not specifically related to the the programming
> language.
> >>> To compare distributional consistency / discrepancy between two
> >>> samples, we usually use kolmogorov-smirnov test, which is implemented
> >>> in R with ks.test() or in SAS with "pro npar1way edf".
> >>> I am wondering if there is any alternative to KS test that could be
> >>> generalized to K-samples.
> >>
> >> The 'coin' package (Hothorn, Hornick, van de Weil, and Zeileis)
> presents a variety of permutation and rank-based tests that would probably
> be more powerful than any multi-group variant of the KS test. The
> multi-group variant of the Wilcoxon Rank Sum Test presented in the examples
> for the help page: ?wilcox_test is the Nemenyi-Damico-Wolfe-Dunn test.
> >>
> >> --
> >>
> >> David Winsemius
> >> Alameda, CA, USA
> >>
> >
> >
> >
> > --
> > ==============================
> > WenSui Liu
> > Credit Risk Manager, 53 Bancorp
> > wensui.liu at 53.com
> > 513-295-4370
> > ==============================
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From munawar.a.cheema at gmail.com  Sat May 30 16:35:50 2015
From: munawar.a.cheema at gmail.com (Munawar Cheema)
Date: Sat, 30 May 2015 15:35:50 +0100
Subject: [R] puzzling behaviour of identical function
Message-ID: <CADwNEa6JzhKN2maS-mUd+OiJkijuz_ZpHEWwm3o7VWEBf3wjvw@mail.gmail.com>

I am puzzled by the following seemingly contradictory calls to the function
identical. Below is a minimal example, that reproduces them:

> sessionInfo()
R version 3.2.0 (2015-04-16)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.9.5 (Mavericks)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  grid      methods
[8] base

loaded via a namespace (and not attached):
[1] compiler_3.2.0 tools_3.2.0    memoise_0.2.1  digest_0.6.8
> readLines("tmp.R")
[1] "if (identical(function(x)1,function(x)1)) cat(\"Identical!\\n\")
else cat(\"Not Identical!\\n\")"
> sys.source("tmp.R", envir=new.env(parent=baseenv()))
Identical!
> if (identical(function(x)1,function(x)1)) cat("Identical!\n") else cat("Not Identical!\n")
Not Identical!



Can anyone explain why I get a false value from the command line but true if I
use sys.source?

-- 
Kind Regards
Munawar Cheema


From mm675 at hermes.cam.ac.uk  Sat May 30 17:56:17 2015
From: mm675 at hermes.cam.ac.uk (Michelle Morters)
Date: Sat, 30 May 2015 16:56:17 +0100
Subject: [R] zero in alternate elements in alternate rows in matrix
In-Reply-To: <5569D6B2.90207@hermes.cam.ac.uk>
References: <5569D6B2.90207@hermes.cam.ac.uk>
Message-ID: <5569DDA1.2060702@hermes.cam.ac.uk>

Hi - I'm trying to generate the (toy) matrix below in R. I get the error 
message shown below (and no matrix!) and I'm unclear as to why - if 
someone could advise as to why, that would be ace. Thank you! Michelle


0.7 	0 	0.1 	0 	0.1 	0 	0 	0 	0 	0 	0 	0
0.1 	0.7 	0.1 	0.1 	0.1 	0.1 	0 	0 	0 	0 	0 	0
0.1 	0.1 	0.7 	0 	0.1 	0 	0.1 	0 	0 	0 	0 	0
0.1 	0.1 	0.1 	0.7 	0.1 	0.1 	0.1 	0.1 	0 	0 	0 	0
0.1 	0.1 	0.1 	0.1 	0.7 	0 	0.1 	0 	0.1 	0 	0 	0
0 	0.1 	0.1 	0.1 	0.1 	0.7 	0.1 	0.1 	0.1 	0.1 	0 	0
0 	0 	0.1 	0.1 	0.1 	0.1 	0.7 	0 	0.1 	0 	0.1 	0
0 	0 	0 	0.1 	0.1 	0.1 	0.1 	0.7 	0.1 	0.1 	0.1 	0.1
0 	0 	0 	0 	0.1 	0.1 	0.1 	0.1 	0.7 	0 	0.1 	0
0 	0 	0 	0 	0 	0.1 	0.1 	0.1 	0.1 	0.7 	0.1 	0.1
0 	0 	0 	0 	0 	0 	0.1 	0.1 	0.1 	0.1 	0.7 	0
0 	0 	0 	0 	0 	0 	0 	0.1 	0.1 	0.1 	0.1 	0.7



cross = 0.1
diag = 0.7
n=12  # to be changed to n=1:100 once the code below is correct
nbe=4
R0=sapply(n,function(x){
m = matrix(0, nrow=x, ncol=x)
for (i in 1:x)
{
for(j in 1:x)
{
if (i==j)
{
m[i,j] = diag
}
else if(j<=i+nbe & j>=i-nbe)
{
m[i,j]=cross
}
}
}
for (i in seq(1,x,2))
{
for (j in seq(i+1,i+nbe,2))
{
m[i,j]=0
}
}
print(m)
max(Mod(eigen(m)$value))
}
)
R0

error message: Error in `[<-`(`*tmp*`, i, j, value = 0) : subscript out 
of bounds










	[[alternative HTML version deleted]]


From mm675 at hermes.cam.ac.uk  Sat May 30 21:07:52 2015
From: mm675 at hermes.cam.ac.uk (Michelle Morters)
Date: Sat, 30 May 2015 20:07:52 +0100
Subject: [R] please ignore previous e-mail re zeros in alternate rows &
 alternate elements in matrix
Message-ID: <556A0A88.8090608@hermes.cam.ac.uk>

Sorry - I have solved my problem already - please don't post the request 
for advice on how to generate a matrix with zeros in alternate rows & 
alternate elements in the supra-diagonal

Cheers
Michelle


From wdunlap at tibco.com  Sat May 30 21:49:51 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 30 May 2015 12:49:51 -0700
Subject: [R] puzzling behaviour of identical function
In-Reply-To: <CADwNEa6JzhKN2maS-mUd+OiJkijuz_ZpHEWwm3o7VWEBf3wjvw@mail.gmail.com>
References: <CADwNEa6JzhKN2maS-mUd+OiJkijuz_ZpHEWwm3o7VWEBf3wjvw@mail.gmail.com>
Message-ID: <CAF8bMcYyxP5HhV5HCFDwd063=ZN1a3NCgaE95-R4dJtU9GoGZQ@mail.gmail.com>

Their 'srcref' attributes differ.  srcref describes the text that
the parser was given when creating the function.

> identical(f1 <- function(x)1, f2 <- function(x)1)
[1] FALSE
> str(f1)
function (x)
 - attr(*, "srcref")=Class 'srcref'  atomic [1:8] 1 17 1 28 17 28 1 1
  .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile' <environment:
0x00000000166c02a0>
> str(f2)
function (x)
 - attr(*, "srcref")=Class 'srcref'  atomic [1:8] 1 37 1 48 37 48 1 1
  .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile' <environment:
0x00000000166c02a0>

You can remore the the srcref attribute with attr(f1, "srcref")<-NULL and
you can
avoid having it attached to functions when they are created by setting
options(keep.source=FALSE).



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, May 30, 2015 at 7:35 AM, Munawar Cheema <munawar.a.cheema at gmail.com>
wrote:

> I am puzzled by the following seemingly contradictory calls to the function
> identical. Below is a minimal example, that reproduces them:
>
> > sessionInfo()
> R version 3.2.0 (2015-04-16)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.9.5 (Mavericks)
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  grid      methods
> [8] base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.2.0 tools_3.2.0    memoise_0.2.1  digest_0.6.8
> > readLines("tmp.R")
> [1] "if (identical(function(x)1,function(x)1)) cat(\"Identical!\\n\")
> else cat(\"Not Identical!\\n\")"
> > sys.source("tmp.R", envir=new.env(parent=baseenv()))
> Identical!
> > if (identical(function(x)1,function(x)1)) cat("Identical!\n") else
> cat("Not Identical!\n")
> Not Identical!
>
>
>
> Can anyone explain why I get a false value from the command line but true
> if I
> use sys.source?
>
> --
> Kind Regards
> Munawar Cheema
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat May 30 21:56:30 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 30 May 2015 15:56:30 -0400
Subject: [R] puzzling behaviour of identical function
In-Reply-To: <CADwNEa6JzhKN2maS-mUd+OiJkijuz_ZpHEWwm3o7VWEBf3wjvw@mail.gmail.com>
References: <CADwNEa6JzhKN2maS-mUd+OiJkijuz_ZpHEWwm3o7VWEBf3wjvw@mail.gmail.com>
Message-ID: <556A15EE.7000508@gmail.com>

On 30/05/2015 10:35 AM, Munawar Cheema wrote:
> I am puzzled by the following seemingly contradictory calls to the function
> identical. Below is a minimal example, that reproduces them:
> 
>> sessionInfo()
> R version 3.2.0 (2015-04-16)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.9.5 (Mavericks)
> 
> locale:
> [1] C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  grid      methods
> [8] base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.2.0 tools_3.2.0    memoise_0.2.1  digest_0.6.8
>> readLines("tmp.R")
> [1] "if (identical(function(x)1,function(x)1)) cat(\"Identical!\\n\")
> else cat(\"Not Identical!\\n\")"
>> sys.source("tmp.R", envir=new.env(parent=baseenv()))
> Identical!
>> if (identical(function(x)1,function(x)1)) cat("Identical!\n") else cat("Not Identical!\n")
> Not Identical!
> 
> 
> 
> Can anyone explain why I get a false value from the command line but true if I
> use sys.source?
> 

sys.source has keep.source = getOption("keep.source.pkgs"), which
defaults to FALSE.  Normal evaluation uses getOption("keep.source"),
which defaults to TRUE.

You can see the difference if you save the functions, and use str(), e.g.

f <- function(x)1
g <- function(x)1

str(f)
str(g)

Duncan Murdoch


From liuwensui at gmail.com  Sat May 30 22:30:21 2015
From: liuwensui at gmail.com (Wensui Liu)
Date: Sat, 30 May 2015 16:30:21 -0400
Subject: [R] alternatives to KS test applicable to K-samples
In-Reply-To: <CAGxFJbS3ikq-xbeV4v8aQSJ73S8GE1TLR4mAeykCFqUs8FEVkg@mail.gmail.com>
References: <CAKyN3iBv73_FUsmH2S0nqsann4E-CqMPCt5+0XVwEX2PD50jzQ@mail.gmail.com>
	<F58B52FA-FC39-4C4B-87C1-3D2F388F424F@comcast.net>
	<CAKyN3iDDZmMU=QsNhMJ6HEoWqL67JOqsUJPmz0n5dBUwspMVAg@mail.gmail.com>
	<9C7A6EAE-9656-4E86-A4D9-2B2511FE514D@comcast.net>
	<CAGxFJbS3ikq-xbeV4v8aQSJ73S8GE1TLR4mAeykCFqUs8FEVkg@mail.gmail.com>
Message-ID: <CAKyN3iCgX3NvVD07d=kBLBZO-PzwTzVGzdhzuHZR8ufdfJr1oA@mail.gmail.com>

thanks for your comment, Bert
as pointed out by Brian, mrpp suits my need.

On Sat, May 30, 2015 at 2:02 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> ... or in not testing at all. The distributions are not the same, period. So
> what. Testing for equality is useless -- the real question is: what issues
> are you trying to address/ what questions are you trying to answer/ can they
> be answered with the data you have or plan to get?
>
> In any case, this does not seem the proper venue for such matters, as it has
> nothing to do with R -- for now, anyways (mea culpa). I would suggest you
> post to a statistics list like stats.stackexchange.com to figure out what
> you want to do and then maybe come back here as necessary (after searching)
> to get any help you might need with R tools to do it.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge is
> certainly not wisdom."
>    -- Clifford Stoll
>
> On Sat, May 30, 2015 at 10:42 AM, David Winsemius <dwinsemius at comcast.net>
> wrote:
>>
>>
>> On May 30, 2015, at 7:09 AM, Wensui Liu wrote:
>>
>> > Thanks for your insight, David
>> > But I am not interested in comparing means among multiple groups.
>> > Instead, I want to compare empirical distributions. In this case, I am
>> > not sure if wilcoxon should be still applicable.
>> >
>> > still appreciate it.
>>
>> The Wilcoxon Rank Sum is not comparing means (or medians as I mistakenly
>> thought in the past) but is a more general test of location. You are correct
>> in thinking that the KS test is implicitly testing a wider range of
>> hypotheses, although it remains fairly weak against specific tests. I wasn't
>> suggesting the coin package simply because of its capacity to generalize the
>> WRS test but because of its capacity to support permutation tests of many
>> sorts.
>>
>> If you are testing at all, then there would seem to be a likelihood (in
>> the vague sense of consideration of possible goals of your testing proces)
>> that you really would be interested in departures from "equality of
>> distribution" that might have a more specific description, and might
>> therefore be interested in testing strategies with more power, perhaps a
>> compound test for differences in location and spread.
>>
>> --
>> David.
>>
>>
>> >
>> > On Fri, May 29, 2015 at 1:32 PM, David Winsemius
>> > <dwinsemius at comcast.net> wrote:
>> >>
>> >> On May 29, 2015, at 9:31 AM, Wensui Liu wrote:
>> >>
>> >>> Good morning, All
>> >>> I have a stat question not specifically related to the the programming
>> >>> language.
>> >>> To compare distributional consistency / discrepancy between two
>> >>> samples, we usually use kolmogorov-smirnov test, which is implemented
>> >>> in R with ks.test() or in SAS with "pro npar1way edf".
>> >>> I am wondering if there is any alternative to KS test that could be
>> >>> generalized to K-samples.
>> >>
>> >> The 'coin' package (Hothorn, Hornick, van de Weil, and Zeileis)
>> >> presents a variety of permutation and rank-based tests that would probably
>> >> be more powerful than any multi-group variant of the KS test. The
>> >> multi-group variant of the Wilcoxon Rank Sum Test presented in the examples
>> >> for the help page: ?wilcox_test is the Nemenyi-Damico-Wolfe-Dunn test.
>> >>
>> >> --
>> >>
>> >> David Winsemius
>> >> Alameda, CA, USA
>> >>
>> >
>> >
>> >
>> > --
>> > ==============================
>> > WenSui Liu
>> > Credit Risk Manager, 53 Bancorp
>> > wensui.liu at 53.com
>> > 513-295-4370
>> > ==============================
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
==============================
WenSui Liu
Credit Risk Manager, 53 Bancorp
wensui.liu at 53.com
513-295-4370


From dwinsemius at comcast.net  Sat May 30 23:11:06 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 30 May 2015 14:11:06 -0700
Subject: [R] alternatives to KS test applicable to K-samples
In-Reply-To: <CAM5M9BQzfdP9JKtKDvbd4uwHgjrNNwQDEOhi-q+cPhPHn26Jsg@mail.gmail.com>
References: <CAKyN3iBv73_FUsmH2S0nqsann4E-CqMPCt5+0XVwEX2PD50jzQ@mail.gmail.com>
	<CAM5M9BQzfdP9JKtKDvbd4uwHgjrNNwQDEOhi-q+cPhPHn26Jsg@mail.gmail.com>
Message-ID: <F5122165-BEB9-4EA9-8AB0-712520E3036C@comcast.net>


On May 29, 2015, at 10:02 AM, Cade, Brian wrote:

> Wensui:  There are the multi-response permutation procedures (MRPP) that
> readily test the omnibus hypothesis of no distributional differences among
> multiple samples for univariate or multivariate responses.  There also are
> empirical coverage tests that test a similar hypothesis among multiple
> samples but only for univariate responses.  Both are included in the USGS
> Blossom package for R linked here:
> https://www.fort.usgs.gov/products/23735 (not yet distributed via CRAN).

I did not find a link to an actual package at that page nor on any of the others to which it linked.

> The MRPP may also be available in other R packages on CRAN (vegan ?).

There is an mrpp function in pkg:vegan although its help page description made me think it depended (at least in its default mode) on the squared-deviations from means. I'd suggest using CRAN Task View: Robust Statistical Methods  (Maintainer: Martin Maechler) for searching for alternative methods.

-- 
David.


> 
> Brian
> 
> Brian S. Cade, PhD
> 
> U. S. Geological Survey
> Fort Collins Science Center
> 2150 Centre Ave., Bldg. C
> Fort Collins, CO  80526-8818
> 
> email:  cadeb at usgs.gov <brian_cade at usgs.gov>
> tel:  970 226-9326
> 
> 
> On Fri, May 29, 2015 at 10:31 AM, Wensui Liu <liuwensui at gmail.com> wrote:
> 
>> Good morning, All
>> I have a stat question not specifically related to the the programming
>> language.
>> To compare distributional consistency / discrepancy between two
>> samples, we usually use kolmogorov-smirnov test, which is implemented
>> in R with ks.test() or in SAS with "pro npar1way edf".
>> I am wondering if there is any alternative to KS test that could be
>> generalized to K-samples.
>> 
>> Thanks and have a nice weekend.
>> 
>> wensui
> 


David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun May 31 04:15:36 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 30 May 2015 19:15:36 -0700
Subject: [R] zero in alternate elements in alternate rows in matrix
In-Reply-To: <5569DDA1.2060702@hermes.cam.ac.uk>
References: <5569D6B2.90207@hermes.cam.ac.uk>
	<5569DDA1.2060702@hermes.cam.ac.uk>
Message-ID: <55407D54-D753-4939-A4A2-CC36D1B7DBC3@comcast.net>


On May 30, 2015, at 8:56 AM, Michelle Morters wrote:

> Hi - I'm trying to generate the (toy) matrix below in R. I get the error 
> message shown below (and no matrix!) and I'm unclear as to why - if 
> someone could advise as to why, that would be ace. Thank you! Michelle
> 
> 
> 0.7 	0 	0.1 	0 	0.1 	0 	0 	0 	0 	0 	0 	0
> 0.1 	0.7 	0.1 	0.1 	0.1 	0.1 	0 	0 	0 	0 	0 	0
> 0.1 	0.1 	0.7 	0 	0.1 	0 	0.1 	0 	0 	0 	0 	0
> 0.1 	0.1 	0.1 	0.7 	0.1 	0.1 	0.1 	0.1 	0 	0 	0 	0
> 0.1 	0.1 	0.1 	0.1 	0.7 	0 	0.1 	0 	0.1 	0 	0 	0
> 0 	0.1 	0.1 	0.1 	0.1 	0.7 	0.1 	0.1 	0.1 	0.1 	0 	0
> 0 	0 	0.1 	0.1 	0.1 	0.1 	0.7 	0 	0.1 	0 	0.1 	0
> 0 	0 	0 	0.1 	0.1 	0.1 	0.1 	0.7 	0.1 	0.1 	0.1 	0.1
> 0 	0 	0 	0 	0.1 	0.1 	0.1 	0.1 	0.7 	0 	0.1 	0
> 0 	0 	0 	0 	0 	0.1 	0.1 	0.1 	0.1 	0.7 	0.1 	0.1
> 0 	0 	0 	0 	0 	0 	0.1 	0.1 	0.1 	0.1 	0.7 	0
> 0 	0 	0 	0 	0 	0 	0 	0.1 	0.1 	0.1 	0.1 	0.7
> 
> 

One can use loopless methods:

 cross = 0.1
 diag_val = 0.7
 n=12  
 nbe=4
 m = matrix(0, nrow=n, ncol=n)
 diag(m)=diag_val      # probably better not to use 'diag' as name of value.
 rm <- row(m); cm <- col(m)  # creates indicator matrices of same size
 m[abs(rm - cm) < 4 & rm != cm] <- cross  # Fill supra- and sub-diagonals.
 m[ cm %% 2 == 0 & rm %% 2 == 1 & rm < cm ] = 0 
   # Zero supra diags in odd rows and in even cols.
#-------------
> m
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
 [1,]  0.7  0.0  0.1  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0
 [2,]  0.1  0.7  0.1  0.1  0.1  0.0  0.0  0.0  0.0   0.0   0.0   0.0
 [3,]  0.1  0.1  0.7  0.0  0.1  0.0  0.0  0.0  0.0   0.0   0.0   0.0
 [4,]  0.1  0.1  0.1  0.7  0.1  0.1  0.1  0.0  0.0   0.0   0.0   0.0
 [5,]  0.0  0.1  0.1  0.1  0.7  0.0  0.1  0.0  0.0   0.0   0.0   0.0
 [6,]  0.0  0.0  0.1  0.1  0.1  0.7  0.1  0.1  0.1   0.0   0.0   0.0
 [7,]  0.0  0.0  0.0  0.1  0.1  0.1  0.7  0.0  0.1   0.0   0.0   0.0
 [8,]  0.0  0.0  0.0  0.0  0.1  0.1  0.1  0.7  0.1   0.1   0.1   0.0
 [9,]  0.0  0.0  0.0  0.0  0.0  0.1  0.1  0.1  0.7   0.0   0.1   0.0
[10,]  0.0  0.0  0.0  0.0  0.0  0.0  0.1  0.1  0.1   0.7   0.1   0.1
[11,]  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.1  0.1   0.1   0.7   0.0
[12,]  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.1   0.1   0.1   0.7

-- 
David

> 
> cross = 0.1
> diag = 0.7
> n=12  # to be changed to n=1:100 once the code below is correct
> nbe=4
> R0=sapply(n,function(x){
> m = matrix(0, nrow=x, ncol=x)  

# this would be creating a series of "m" objects at various values of n x n dimensions and then over-writing them.

> for (i in 1:x)
> {
> for(j in 1:x)
> {
> if (i==j)
> {
> m[i,j] = diag
> }
> else if(j<=i+nbe & j>=i-nbe)
> {
> m[i,j]=cross
> }
> }
> }
> for (i in seq(1,x,2))
> {
> for (j in seq(i+1,i+nbe,2))
> {
> m[i,j]=0
> }
> }
> print(m)
> max(Mod(eigen(m)$value))
> }
> )
> R0
> 
> error message: Error in `[<-`(`*tmp*`, i, j, value = 0) : subscript out 
> of bounds
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From henrik.bengtsson at ucsf.edu  Sun May 31 05:20:52 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Sat, 30 May 2015 20:20:52 -0700
Subject: [R] Arrays of variable dimensionality
In-Reply-To: <76DE51A4-2D85-4B02-99B4-AE9DEDCF414B@dcn.davis.CA.us>
References: <CALcakBaD0cwMZU+kH6gO7uLgFRr_NyFpn85cJmbtYNqwH6pK_Q@mail.gmail.com>
	<76DE51A4-2D85-4B02-99B4-AE9DEDCF414B@dcn.davis.CA.us>
Message-ID: <CAFDcVCQipL8WUzWYVkXJS8Heo-mcnhvE=c4LBZT=Goxg2qvcTA@mail.gmail.com>

Basically dropping by saying what's already been said, but also that
you probably want to do whatever you're trying to achieve using
vectorized operations.  A small summary with some tweaks:

## Generate an array with a "random" number of dimensions
dim <- c(4, 5, 6, 7)
dimnames <- lapply(1:4, FUN=function(i) sprintf("%s%d", letters[i], 1:dim[i])
)
x <- array(seq_len(prod(dim)), dim=dim, dimnames=dimnames)

# A single cell
> y0 <-x[1,2,3,4]
> y <- do.call(`[`, c(list(x), alist(1,2,3,4)))
> y
[1] 405
> stopifnot(identical(y, y0))

# A "block" subset of the array
> y0 <- x[1:2,2,3:4,4]
> y <- do.call(`[`, c(list(x), alist(1:2,2,3:4,4)))
> y
    c3  c4
a1 405 425
a2 406 426
> stopifnot(identical(y, y0))

# A "block" subset of the array (preserving all 4 dimensions)
> y0 <- x[1:2,2,3:4,4, drop=FALSE]
> y <- do.call(`[`, c(list(x), alist(1:2,2,3:4,4), drop=FALSE))
> str(y)
 int [1:2, 1, 1:2, 1] 405 406 425 426
 - attr(*, "dimnames")=List of 4
  ..$ : chr [1:2] "a1" "a2"
  ..$ : chr "b2"
  ..$ : chr [1:2] "c3" "c4"
  ..$ : chr "d4"
> stopifnot(identical(y, y0))

# Why alist() and not list()?  Because if you also need to do ...
> y0 <- x[1:2,,1:2,, drop=FALSE]
> y <- do.call(`[`, c(list(x), alist(1:2,,1:2,), drop=FALSE))
> str(y)
 int [1:2, 1:5, 1:2, 1:7] 1 2 5 6 9 10 13 14 17 18 ...
 - attr(*, "dimnames")=List of 4
  ..$ : chr [1:2] "a1" "a2"
  ..$ : chr [1:5] "b1" "b2" "b3" "b4" ...
  ..$ : chr [1:2] "c1" "c2"
  ..$ : chr [1:7] "d1" "d2" "d3" "d4" ...
> stopifnot(identical(y, y0))

# Any subset of cells - not a "block" (using what is called "matrix
indexing" in R)
> y0 <- c(x[1,2,2,4], x[3,2,1,3])
> idxs <- cbind(c(1,3), c(2,2), c(2,1), c(4,3))
> y <- x[idxs]
[1] 385 247
> stopifnot(identical(y, y0))


For a (possibly) more readable subsetting by "blocks" than using
do.call(), there's also:

> library(R.utils)
> y <- extract(x, indices=list(1:2,2,3:4,4), drop=TRUE)
> y <- extract(x, indices=list(1:2,2,3:4,4), drop=FALSE)

It also has some other bells and whistles, but it cannot do more than
what already shown above.

/Henrik
(author of R.utils)

On Sat, May 30, 2015 at 10:34 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Don't.
>
> Arrays in R don't have variable dimensions [1]. To the extent that you pretend otherwise, you will degrade performance and complicate your program. I would argue that similar effects arise in languages that do let you pretend that arrays have variable dimensions.
>
> The main reason variable-sized arrays seem useful is that some algorithms or data sources yield variable amounts of data. There are various ways to handle these cases, and the use of lists to hold intermediate units of data followed by transfer of that data into an array (strategically handled after you know how big the array has to be) is one of the more common ones.
>
> Another technique is to use one of the ragged array or sparse matrix data structures, but they generally work best when the data actually are sparse.
>
> Being more specific about your immediate problem can elicit more specific help.
>
> BTW please post plain text on this list... HTML is not supported by the list reflector and leads to misunderstandings.
>
> [1] More precisely, the total number of elements in the underlying vector is fixed, though you can redefine how the dimensions use the elements in that vector. For example, study the "aperm" function.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On May 30, 2015 3:29:09 AM PDT, WRAY NICHOLAS <nicholas.wray at ntlworld.com> wrote:
>>Hello folks
>>
>>Supposing I have a multidimensional array in an R prog, say a 4D array.
>>
>>I want the coordinate quantities to be read off from a vector.  The
>>values
>>in the vector (vec) are generated by a function.
>>
>>This is easy if the number of dimensions is fixed for both the array
>>and
>>the number of elements in the  vector (say 4):
>>
>>X<-array[vec[1],vec[2],vec[3],vec[4]]
>>
>>But if the number of dimensions of the array is not fixed and can
>>change
>>during the course of the prog I am stuck as to how to do this, as I
>>don?t
>>know a way of feeding a vector or list of unspecified beforehand length
>>into the coordinates for an array
>>
>>I can?t find anything useful about this on the net
>>
>>Does anyone have any ideas?
>>Thanks, Nick
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nicholas.wray at ntlworld.com  Sun May 31 16:01:00 2015
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Sun, 31 May 2015 15:01:00 +0100
Subject: [R] Fwd: Arrays of variable dimensionality
In-Reply-To: <CALcakBaD0cwMZU+kH6gO7uLgFRr_NyFpn85cJmbtYNqwH6pK_Q@mail.gmail.com>
References: <CALcakBaD0cwMZU+kH6gO7uLgFRr_NyFpn85cJmbtYNqwH6pK_Q@mail.gmail.com>
Message-ID: <CALcakBaVgny6PaTpun8z_F=9kLL9+i5w4xwktzA8063Y7XKkgQ@mail.gmail.com>

Thanks for all the ideas   I will run through them next week when I'm back
at work... Nick
---------- Forwarded message ----------
From: WRAY NICHOLAS <nicholas.wray at ntlworld.com>
Date: 30 May 2015 at 11:29
Subject: Arrays of variable dimensionality
To: r-help <r-help at r-project.org>


Hello folks

Supposing I have a multidimensional array in an R prog, say a 4D array.

I want the coordinate quantities to be read off from a vector.  The values
in the vector (vec) are generated by a function.

This is easy if the number of dimensions is fixed for both the array and
the number of elements in the  vector (say 4):

X<-array[vec[1],vec[2],vec[3],vec[4]]

But if the number of dimensions of the array is not fixed and can change
during the course of the prog I am stuck as to how to do this, as I don?t
know a way of feeding a vector or list of unspecified beforehand length
into the coordinates for an array

I can?t find anything useful about this on the net

Does anyone have any ideas?
Thanks, Nick

	[[alternative HTML version deleted]]


From geert.simkens at catharinaziekenhuis.nl  Sun May 31 23:10:06 2015
From: geert.simkens at catharinaziekenhuis.nl (GeertSim)
Date: Sun, 31 May 2015 14:10:06 -0700 (PDT)
Subject: [R] censboot function for bootstrapping Cox proportional Hazard
	Model
Message-ID: <1433106606456-4707989.post@n4.nabble.com>

Dear all,

I developed a cox regression model with three independent factors to predict
overall survival in a specific group of patients. I would like to adjust
this model for overoptimism with the censboot function of the boot package.
I would like to use bootstrapping to adjust the regression coefficients of
this model. However, I am unable to complete all the arguments of the
censboot function after searching for several hours. The error I am not able
to fix in the formula is:

> censboot(coxpredictors, mod.coxregr.hub, R=10, sim="ordinary")
Error in censboot(coxpredictors, mod.coxregr.hub, R = 10, sim = "ordinary")
: 
  incorrect number of subscripts on matrix

I assume it has something to do with the strata argument, but I am not sure
how to fix that. Furthermore, is "ordinary" simulation the correct type for
this kind of analysis? I hope someone can help me to complete the formula so
I can perform my bootstrap analysis. You can find my entire script below. 

Many thanks in advance.

Best regards,

Geert Simkens

> library(Hmisc)
> library(survival)
> library(foreign)
> library(boot)
> library(car)
> library(pROC)
> load("~/coxmodel.Rda")
> attach(coxpredictors)
> 
> summary(coxpredictors)
 FollowUpMonths        Event            PCI10              N2          
Symptoms     
 Min.   : 0.1314   Min.   :0.0000   Min.   :0.0000   Min.   :0.000   Min.  
:0.0000  
 1st Qu.:11.3676   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.000   1st
Qu.:1.0000  
 Median :19.6797   Median :0.0000   Median :0.0000   Median :0.000   Median
:1.0000  
 Mean   :23.4967   Mean   :0.4472   Mean   :0.3668   Mean   :0.402   Mean  
:0.8241  
 3rd Qu.:32.2135   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.000   3rd
Qu.:1.0000  
 Max.   :87.1622   Max.   :1.0000   Max.   :1.0000   Max.   :1.000   Max.  
:1.0000  
> 
> time <- FollowUpMonths
> event <- Event
> X <- cbind(PCI10, N2, Symptoms)
> summary(time)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.1314 11.3700 19.6800 23.5000 32.2100 87.1600 
> 
> # cox regression model with dataname first
> mod.coxregr.hub = function(coxpredictors)
+ {
+     coxph(Surv(time,event == 1) ~ X, method="breslow", model=TRUE)
+ }
> 
> # cox regression model
> coxmodel = coxph(Surv(time,event == 1) ~ X, method="breslow", model=TRUE)
> 
> summary(coxmodel)
Call:
coxph(formula = Surv(time, event == 1) ~ X, model = TRUE, method =
"breslow")

  n= 199, number of events= 89 

            coef exp(coef) se(coef)     z Pr(>|z|)    
XPCI10    1.3179    3.7356   0.2198 5.996 2.02e-09 ***
XN2       0.5587    1.7485   0.2165 2.580  0.00987 ** 
XSymptoms 0.8102    2.2483   0.3787 2.139  0.03241 *  
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

          exp(coef) exp(-coef) lower .95 upper .95
XPCI10        3.736     0.2677     2.428     5.747
XN2           1.748     0.5719     1.144     2.673
XSymptoms     2.248     0.4448     1.070     4.723

Concordance= 0.703  (se = 0.033 )
Rsquare= 0.216   (max possible= 0.982 )
Likelihood ratio test= 48.42  on 3 df,   p=1.73e-10
Wald test            = 48.11  on 3 df,   p=2.02e-10
Score (logrank) test = 52.96  on 3 df,   p=1.867e-11
> 
> # bootstrapping formula
> censboot(coxpredictors, mod.coxregr.hub, R=10, sim="ordinary")
Error in censboot(coxpredictors, mod.coxregr.hub, R = 10, sim = "ordinary")
: 
  incorrect number of subscripts on matrix
> 
> 



--
View this message in context: http://r.789695.n4.nabble.com/censboot-function-for-bootstrapping-Cox-proportional-Hazard-Model-tp4707989.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Sun May 31 23:47:10 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 31 May 2015 14:47:10 -0700
Subject: [R] censboot function for bootstrapping Cox proportional Hazard
	Model
In-Reply-To: <1433106606456-4707989.post@n4.nabble.com>
References: <1433106606456-4707989.post@n4.nabble.com>
Message-ID: <BC79A196-1F3F-4160-9C22-67E1CFE96A4D@comcast.net>


On May 31, 2015, at 2:10 PM, GeertSim wrote:

> Dear all,
> 
> I developed a cox regression model with three independent factors to predict
> overall survival in a specific group of patients. I would like to adjust
> this model for overoptimism with the censboot function of the boot package.
> I would like to use bootstrapping to adjust the regression coefficients of
> this model. However, I am unable to complete all the arguments of the
> censboot function after searching for several hours. The error I am not able
> to fix in the formula is:
> 
>> censboot(coxpredictors, mod.coxregr.hub, R=10, sim="ordinary")
> Error in censboot(coxpredictors, mod.coxregr.hub, R = 10, sim = "ordinary")
> : 
>  incorrect number of subscripts on matrix
> 
> I assume it has something to do with the strata argument, but I am not sure
> how to fix that. Furthermore, is "ordinary" simulation the correct type for
> this kind of analysis? I hope someone can help me to complete the formula so
> I can perform my bootstrap analysis. You can find my entire script below. 
> 
> Many thanks in advance.
> 
> Best regards,
> 
> Geert Simkens
> 
>> library(Hmisc)
>> library(survival)
>> library(foreign)
>> library(boot)
>> library(car)
>> library(pROC)
>> load("~/coxmodel.Rda")
>> attach(coxpredictors)

My guess (and one can only guess since there is no way to see the data) is that it has to do with attaching that dataframe and supplying arguments to the function (for instance 'event' and 'time` that are outside the evaluation environment that is expected inside the boot function. Using `attach` is generally unsafe and not appropriate for arguments passed into regression functions, especially so for boot-functions. More guesswork: I suspect that most of R-Core would rather that it did not exist.


-- 
David.

>> 
>> summary(coxpredictors)
> FollowUpMonths        Event            PCI10              N2          
> Symptoms     
> Min.   : 0.1314   Min.   :0.0000   Min.   :0.0000   Min.   :0.000   Min.  
> :0.0000  
> 1st Qu.:11.3676   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.000   1st
> Qu.:1.0000  
> Median :19.6797   Median :0.0000   Median :0.0000   Median :0.000   Median
> :1.0000  
> Mean   :23.4967   Mean   :0.4472   Mean   :0.3668   Mean   :0.402   Mean  
> :0.8241  
> 3rd Qu.:32.2135   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.000   3rd
> Qu.:1.0000  
> Max.   :87.1622   Max.   :1.0000   Max.   :1.0000   Max.   :1.000   Max.  
> :1.0000  
>> 
>> time <- FollowUpMonths
>> event <- Event
>> X <- cbind(PCI10, N2, Symptoms)
>> summary(time)
>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
> 0.1314 11.3700 19.6800 23.5000 32.2100 87.1600 
>> 
>> # cox regression model with dataname first
>> mod.coxregr.hub = function(coxpredictors)
> + {
> +     coxph(Surv(time,event == 1) ~ X, method="breslow", model=TRUE)
> + }
>> 
>> # cox regression model
>> coxmodel = coxph(Surv(time,event == 1) ~ X, method="breslow", model=TRUE)
>> 
>> summary(coxmodel)
> Call:
> coxph(formula = Surv(time, event == 1) ~ X, model = TRUE, method =
> "breslow")
> 
>  n= 199, number of events= 89 
> 
>            coef exp(coef) se(coef)     z Pr(>|z|)    
> XPCI10    1.3179    3.7356   0.2198 5.996 2.02e-09 ***
> XN2       0.5587    1.7485   0.2165 2.580  0.00987 ** 
> XSymptoms 0.8102    2.2483   0.3787 2.139  0.03241 *  
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
>          exp(coef) exp(-coef) lower .95 upper .95
> XPCI10        3.736     0.2677     2.428     5.747
> XN2           1.748     0.5719     1.144     2.673
> XSymptoms     2.248     0.4448     1.070     4.723
> 
> Concordance= 0.703  (se = 0.033 )
> Rsquare= 0.216   (max possible= 0.982 )
> Likelihood ratio test= 48.42  on 3 df,   p=1.73e-10
> Wald test            = 48.11  on 3 df,   p=2.02e-10
> Score (logrank) test = 52.96  on 3 df,   p=1.867e-11
>> 
>> # bootstrapping formula
>> censboot(coxpredictors, mod.coxregr.hub, R=10, sim="ordinary")
> Error in censboot(coxpredictors, mod.coxregr.hub, R = 10, sim = "ordinary")
> : 
>  incorrect number of subscripts on matrix
>> 
>> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/censboot-function-for-bootstrapping-Cox-proportional-Hazard-Model-tp4707989.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


