From fjbuch at gmail.com  Fri Dec  1 00:03:30 2006
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Thu, 30 Nov 2006 18:03:30 -0500
Subject: [R] reshape command is (stats) dropping instances
In-Reply-To: <f8e6ff050611291650o4aad976bn6f32d3f11d330cb7@mail.gmail.com>
References: <bd93cdad0611291010r56ea989dj3b9c955b9697a431@mail.gmail.com>
	<f8e6ff050611291650o4aad976bn6f32d3f11d330cb7@mail.gmail.com>
Message-ID: <bd93cdad0611301503g630cd42ds7b66c4937f9134a9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061130/dce74def/attachment-0003.ksh 

From cberry at tajo.ucsd.edu  Fri Dec  1 01:32:44 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Thu, 30 Nov 2006 16:32:44 -0800
Subject: [R] analog to the matlab buffer function?
In-Reply-To: <1989899931.93201164925846099.JavaMail.nobody@mail08.abv.bg>
References: <1989899931.93201164925846099.JavaMail.nobody@mail08.abv.bg>
Message-ID: <Pine.LNX.4.64.0611301629190.24545@tajo.ucsd.edu>


See

 	?embed

It is not quite the same, but this seems to be what you want - at least 
for the example you give:

> t( embed(1:5,3) )[3:1,]
      [,1] [,2] [,3]
[1,]    1    2    3
[2,]    2    3    4
[3,]    3    4    5
>

On Fri, 1 Dec 2006, Martin Ivanov wrote:

> Hello! I am new to R. I could not find a function analogous to matlab's 
> function buffer, which is used in signal processing. Is there such a 
> function in R? What I need to do is as follows. If I apply the function 
> to the vector c(1:5) for example with a window length 3 and overlapping 
> 2, I need to get a matrix like this:
> 1 2 3
> 2 3 4
> 3 4 5
> In matlab this is achieved with the function buffer. Is there ananalogous R function?
>
> Thank you very much in advance.
> Regards,
> Martin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717



From amit_605 at yahoo.co.in  Fri Dec  1 02:00:40 2006
From: amit_605 at yahoo.co.in (amit soni)
Date: Fri, 1 Dec 2006 06:30:40 +0530 (IST)
Subject: [R] query on nlm() function
Message-ID: <20061201010040.64198.qmail@web8407.mail.in.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061201/a94319f9/attachment-0003.ksh 

From marc_schwartz at comcast.net  Fri Dec  1 02:56:58 2006
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 30 Nov 2006 19:56:58 -0600
Subject: [R] analog to the matlab buffer function?
In-Reply-To: <Pine.LNX.4.64.0611301629190.24545@tajo.ucsd.edu>
References: <1989899931.93201164925846099.JavaMail.nobody@mail08.abv.bg>
	<Pine.LNX.4.64.0611301629190.24545@tajo.ucsd.edu>
Message-ID: <1164938218.4738.15.camel@localhost.localdomain>

Here is another possibility, though I may be missing how the Matlab
function handles incomplete rows generated at the end of the source
vector. I have not fully tested this, so it may yet require some
tweaking and certainly appropriate error checking.

I am presuming that the basic premise is that each row is of length
'window' and that it overlaps with the END of prior row by 'overlap'. 


Buffer <- function(x, window, overlap)
{
  Res <- NULL

  while (length(x) >= window)
  {
    Res <- c(Res, x[1:window])
    x <- x[(1 + window - overlap):length(x)]
  }

  matrix(Res, ncol = window, byrow = TRUE)
}


> Buffer(1:5, 3, 2)
     [,1] [,2] [,3]
[1,]    1    2    3
[2,]    2    3    4
[3,]    3    4    5

> Buffer(1:10, 4, 2)
     [,1] [,2] [,3] [,4]
[1,]    1    2    3    4
[2,]    3    4    5    6
[3,]    5    6    7    8
[4,]    7    8    9   10

HTH,

Marc Schwartz


On Thu, 2006-11-30 at 16:32 -0800, Charles C. Berry wrote: 
> See
> 
>  	?embed
> 
> It is not quite the same, but this seems to be what you want - at least 
> for the example you give:
> 
> > t( embed(1:5,3) )[3:1,]
>       [,1] [,2] [,3]
> [1,]    1    2    3
> [2,]    2    3    4
> [3,]    3    4    5
> >
> 
> On Fri, 1 Dec 2006, Martin Ivanov wrote:
> 
> > Hello! I am new to R. I could not find a function analogous to matlab's 
> > function buffer, which is used in signal processing. Is there such a 
> > function in R? What I need to do is as follows. If I apply the function 
> > to the vector c(1:5) for example with a window length 3 and overlapping 
> > 2, I need to get a matrix like this:
> > 1 2 3
> > 2 3 4
> > 3 4 5
> > In matlab this is achieved with the function buffer. Is there ananalogous R function?



From spencer.graves at pdf.com  Fri Dec  1 05:36:17 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 30 Nov 2006 20:36:17 -0800
Subject: [R] help
In-Reply-To: <6.1.2.0.2.20061122121246.01b705f0@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061122121246.01b705f0@aiminy.mail.iastate.edu>
Message-ID: <456FB141.7090508@pdf.com>

      In case you haven't already received an adequate reply (which I 
haven't seen) or figured this out on your own, I will comment.  Consider 
the following modifications of an example in the 'lmer' documentation: 

(fm0.0 <- lmer(Reaction~(1|Subject), sleepstudy))
(fm0.1 <- lmer(Reaction~1+(1|Subject), sleepstudy))
(fm0.s <- lmer(Reaction~Subject+(1|Subject), sleepstudy))

      The first two models are equivalent, as can be seen from looking 
at the output.  In the "formula" language, something like "Reaction~X" 
means to estimate an intercept plus an X effect.  If you want a 
no-constant model, you must specify "Reaction ~ -1+X".  When X is a 
factor, "Reaction ~ -1+X" effectively fits the same model as 
"Reaction~X" using an alternative parameterization.  If X is numeric, 
"Reaction~X" means estimate b0 and b1 in Reaction = b0 + b1*X + error.  
Meanwhile, "Reaction ~ -1+X" means estimate only b1 in Reaction = b1*X + 
error.  In this latter case, the introduction of "-1" actually changes 
the model. 

      The third model "Reaction~Subject+(1+Subject) is a confusion:  The 
"~Subject" part asks lmer to estimate a separate parameter for each 
Subject.  The (1|Subject) term asks lmer to estimate the standard 
deviation for between-Subject random variability after the fixed effects 
are removed.  Since Subject is also listed as a fixed effect in this 
model, the model is overparameterized:  I'm not certain, but it appears 
to me that the software doesn't know whether to allocate 
subject-specific deviations from the overall mean to the fixed effects 
coefficients or the random effect, and it appears to do a little of both.

      It might be nice if 'lmer' included a check for factors appearing 
as both fixed and random effects.  However, I believe that 'lme4' and (R 
more generally) is primarily a research platform for new statistical 
algorithm development.  Most of the R Core Team work to maintain R under 
the GNU license primarily because it supports their research (and 
educational) objectives.  The product therefore may not strive to be as 
supportive for naive users as commercial software. 

      Hope this helps. 
      Spencer Graves

Aimin Yan wrote:
> consider p as random effect with 5 levels, what is difference between these 
> two models?
>
>  > p5.random.p <- lmer(Y 
> ~p+(1|p),data=p5,family=binomial,control=list(usePQL=FALSE,msV=1))
>  > p5.random.p1 <- lmer(Y 
> ~1+(1|p),data=p5,family=binomial,control=list(usePQL=FALSE,msV=1))
>
> thanks,
>
> Aimin Yan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From gustaf.rydevik at gmail.com  Fri Dec  1 07:45:12 2006
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Fri, 1 Dec 2006 09:45:12 +0300
Subject: [R] Vertical line in densityplot?
Message-ID: <45f568c70611302245w1df82444qb48cc2f1d15568e5@mail.gmail.com>

Hi all,

I'm trying to get a vertical line at a specific point in a
densityplot. abline seems to be what's required, but it doesn't align
itself to the scale used in the plot.

example:

library(lattice)
x<-rnorm(100)
plot.new()
densityplot(x)
abline(v=0)
-----
The line seems to use some other coordinate system. What kind of call
do I use to make abline use the graph's coordinates?

Additionally, it would be nice to have standard xy-axis, and to have
the line stop at the x-axis, so if anyone could tell me how to do
that, I'd be grateful.

Thanks in advance,

Gustaf


PS: a minor question: Why do I have to call plot.new() for abline to work?

-- 
email:gustaf.rydevik at gmail.com
tel: +46(0)703051451
address: Kantorsgatan 50:190 75424 Uppsala Sweden



From kknoblauch at free.fr  Fri Dec  1 08:38:16 2006
From: kknoblauch at free.fr (Ken Knoblauch)
Date: Fri, 1 Dec 2006 08:38:16 +0100
Subject: [R]  Vertical line in densityplot?
Message-ID: <A0658EDA-C702-4B31-8630-B4D9201176CB@free.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061201/d2efde11/attachment-0003.ksh 

From petzoldt at rcs.urz.tu-dresden.de  Fri Dec  1 08:44:38 2006
From: petzoldt at rcs.urz.tu-dresden.de (Thomas Petzoldt)
Date: Fri, 01 Dec 2006 08:44:38 +0100
Subject: [R] Vertical line in densityplot?
In-Reply-To: <45f568c70611302245w1df82444qb48cc2f1d15568e5@mail.gmail.com>
References: <45f568c70611302245w1df82444qb48cc2f1d15568e5@mail.gmail.com>
Message-ID: <456FDD66.8090106@rcs.urz.tu-dresden.de>

Hi,

lattice graphics work by utilizing so called panel functions. Here is a 
working version of your example:

library(lattice)
x<-rnorm(100)
plot.new()
densityplot(x,
   panel=function(x, ...){
     panel.densityplot(x, ...)
     panel.abline(v=0)
   }
)


For mor information, please look into the examples of densityplot and 
the help file of panel.abline


Hope it helps

Thomas


Gustaf Rydevik wrote:
> Hi all,
> 
> I'm trying to get a vertical line at a specific point in a
> densityplot. abline seems to be what's required, but it doesn't align
> itself to the scale used in the plot.
> 
> example:
> 
> library(lattice)
> x<-rnorm(100)
> plot.new()
> densityplot(x)
> abline(v=0)
> -----
> The line seems to use some other coordinate system. What kind of call
> do I use to make abline use the graph's coordinates?
> 
> Additionally, it would be nice to have standard xy-axis, and to have
> the line stop at the x-axis, so if anyone could tell me how to do
> that, I'd be grateful.

What is a "standard x achsis?".

> Thanks in advance,
> 
> Gustaf
> 
> 
> PS: a minor question: Why do I have to call plot.new() for abline to work?
>



From christian.hoffmann at wsl.ch  Fri Dec  1 09:03:33 2006
From: christian.hoffmann at wsl.ch (Christian Hoffmann)
Date: Fri, 01 Dec 2006 09:03:33 +0100
Subject: [R] Question on sub(stitute)  X_1 -> X\_1
In-Reply-To: <mailman.7.1164020402.6146.r-help@stat.math.ethz.ch>
References: <mailman.7.1164020402.6146.r-help@stat.math.ethz.ch>
Message-ID: <456FE1D5.8020103@wsl.ch>

Hi,

Searching the archives has brought no clue:

For a tex chunk in an Sweave text

"Oracle query results: differences \Sexpr{varname},..."

I need to change the string varname from "X_1" to "X\_1",

sub("_",??,"X_+")  -> "X\_1"

so that subsequent Latex will generate "X_1" (i.e. show the underscore) 
instead of "X subscript 1" (subscripting the "1")

Various trials with sub("_","\\_",varname) and the like have not helped.

sub("_","\\_","X_1")             -> "X_1"
sub("_","\\_","X_1",fixed=TRUE)  -> "X\\_1"
sub("_","\_","X_1",fixed=TRUE)   -> "X_1"

Latex will translate  "X\\_1" to X  (linefeed) 1  !!

Thanks for help

Christian
-- 
Dr. Christian W. Hoffmann,
Swiss Federal Research Institute WSL
Zuercherstrasse 111, CH-8903 Birmensdorf, Switzerland
Tel +41-44-7392-277 (office), -111(exchange), -215  (fax)
christian.hoffmann at wsl.ch,  www.wsl.ch/staff/christian.hoffmann



From gustaf.rydevik at gmail.com  Fri Dec  1 09:06:15 2006
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Fri, 1 Dec 2006 11:06:15 +0300
Subject: [R] Vertical line in densityplot?
In-Reply-To: <456FDD66.8090106@rcs.urz.tu-dresden.de>
References: <45f568c70611302245w1df82444qb48cc2f1d15568e5@mail.gmail.com>
	<456FDD66.8090106@rcs.urz.tu-dresden.de>
Message-ID: <45f568c70612010006j16167ce8v922a492c4ef5105b@mail.gmail.com>

On 12/1/06, Thomas Petzoldt <petzoldt at rcs.urz.tu-dresden.de> wrote:
> Hi,
>
> lattice graphics work by utilizing so called panel functions. Here is a
> working version of your example:
>
> library(lattice)
> x<-rnorm(100)
> plot.new()
> densityplot(x,
>   panel=function(x, ...){
>     panel.densityplot(x, ...)
>     panel.abline(v=0)
>   }
> )
>
>
> For mor information, please look into the examples of densityplot and
> the help file of panel.abline
>
>
> Hope it helps
>
> Thomas
>

Thank you very much! Lattice works somewhat different from "regular"
graphics step-by-step addition then.

With standard axis, I just meant a set of axis where the x and y axis
are represented by lines going through origo, or (0,0). Right now some
sort of box is used instead.

Thanks again!

/Gustaf

-- 
email:gustaf.rydevik at gmail.com
tel: +46(0)703051451
address: Kantorsgatan 50:190 75424 Uppsala Sweden



From r.hankin at noc.soton.ac.uk  Fri Dec  1 09:16:49 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Fri, 1 Dec 2006 08:16:49 +0000
Subject: [R] analog to the matlab buffer function?
In-Reply-To: <Pine.LNX.4.64.0611301629190.24545@tajo.ucsd.edu>
References: <1989899931.93201164925846099.JavaMail.nobody@mail08.abv.bg>
	<Pine.LNX.4.64.0611301629190.24545@tajo.ucsd.edu>
Message-ID: <8E0D0403-47E4-4451-A9EC-378BB2AB7CF6@soc.soton.ac.uk>

 > do.call("rbind",lapply(0:4,function(i){i+(1:5)}))
      [,1] [,2] [,3] [,4] [,5]
[1,]    1    2    3    4    5
[2,]    2    3    4    5    6
[3,]    3    4    5    6    7
[4,]    4    5    6    7    8
[5,]    5    6    7    8    9
 >



On 1 Dec 2006, at 00:32, Charles C. Berry wrote:

>
> See
>
>  	?embed
>
> It is not quite the same, but this seems to be what you want - at  
> least
> for the example you give:
>
>> t( embed(1:5,3) )[3:1,]
>       [,1] [,2] [,3]
> [1,]    1    2    3
> [2,]    2    3    4
> [3,]    3    4    5
>>
>
> On Fri, 1 Dec 2006, Martin Ivanov wrote:
>
>> Hello! I am new to R. I could not find a function analogous to  
>> matlab's
>> function buffer, which is used in signal processing. Is there such a
>> function in R? What I need to do is as follows. If I apply the  
>> function
>> to the vector c(1:5) for example with a window length 3 and  
>> overlapping
>> 2, I need to get a matrix like this:
>> 1 2 3
>> 2 3 4
>> 3 4 5
>> In matlab this is achieved with the function buffer. Is there  
>> ananalogous R function?
>>
>> Thank you very much in advance.
>> Regards,
>> Martin
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> Charles C. Berry                        (858) 534-2098
>                                           Dept of Family/Preventive  
> Medicine
> E mailto:cberry at tajo.ucsd.edu	         UC San Diego
> http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego  
> 92093-0717
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From ibrahimmutlay at gmail.com  Fri Dec  1 09:28:17 2006
From: ibrahimmutlay at gmail.com (=?ISO-8859-9?Q?=DDbrahim_Mutlay?=)
Date: Fri, 1 Dec 2006 03:28:17 -0500
Subject: [R] RKward installation problem
Message-ID: <eb21cbcd0612010028i6425eacetb234e82d595ee604@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061201/232bcabc/attachment-0004.pl 

From simon.kempf at web.de  Fri Dec  1 09:30:27 2006
From: simon.kempf at web.de (Simon P. Kempf)
Date: Fri, 1 Dec 2006 09:30:27 +0100
Subject: [R] Box Tidwell / Error Message
Message-ID: <E1Gq3n4-0002sy-00@smtp05.web.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061201/8c0aa1fc/attachment-0004.pl 

From ripley at stats.ox.ac.uk  Fri Dec  1 10:29:53 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 1 Dec 2006 09:29:53 +0000 (GMT)
Subject: [R] Question on sub(stitute)  X_1 -> X\_1
In-Reply-To: <456FE1D5.8020103@wsl.ch>
References: <mailman.7.1164020402.6146.r-help@stat.math.ethz.ch>
	<456FE1D5.8020103@wsl.ch>
Message-ID: <Pine.LNX.4.64.0612010925280.27283@gannet.stats.ox.ac.uk>

You are confusing the printed representation with the string (a clue which 
is all over the archives, and in ?regex).

X1 <- sub("_","\\_","X_1",fixed=TRUE)
print(X1)
cat(X1, "\n")
X2 <- sub("_","\\\\_","X_1")
cat(X1, "\n")

both do as you ask.

On Fri, 1 Dec 2006, Christian Hoffmann wrote:

> Hi,
>
> Searching the archives has brought no clue:
>
> For a tex chunk in an Sweave text
>
> "Oracle query results: differences \Sexpr{varname},..."
>
> I need to change the string varname from "X_1" to "X\_1",
>
> sub("_",??,"X_+")  -> "X\_1"
>
> so that subsequent Latex will generate "X_1" (i.e. show the underscore)
> instead of "X subscript 1" (subscripting the "1")
>
> Various trials with sub("_","\\_",varname) and the like have not helped.
>
> sub("_","\\_","X_1")             -> "X_1"
> sub("_","\\_","X_1",fixed=TRUE)  -> "X\\_1"
> sub("_","\_","X_1",fixed=TRUE)   -> "X_1"
>
> Latex will translate  "X\\_1" to X  (linefeed) 1  !!
>
> Thanks for help
>
> Christian
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From RKrug at sun.ac.za  Fri Dec  1 10:46:11 2006
From: RKrug at sun.ac.za (Rainer M Krug)
Date: Fri, 01 Dec 2006 11:46:11 +0200
Subject: [R] specify point shape for ggplot (equivalent to pch)?
Message-ID: <456FF9E3.5080808@sun.ac.za>

Hi

is it possible to specify the shape of the point to be used in ggplot 
(as with pch in plot)? I couldn't find anything in the help.

Thanks

Rainer

-- 
Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology and Entomology
University of Stellenbosch
Matieland 7602
South Africa

Tel:		+27 - (0)72 808 2975 (w)
Fax:		+27 - (0)86 516 2782
Fax:		+27 - (0)21 808 3304 (w)
Cell:		+27 - (0)83 9479 042

email:	RKrug at sun.ac.za
       	Rainer at krugs.de



From petr.pikal at precheza.cz  Fri Dec  1 11:34:26 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 01 Dec 2006 11:34:26 +0100
Subject: [R] Aggregating data
In-Reply-To: <456DB4B8.6000706@education.wisc.edu>
References: <456D5C12.7631.8587E6@localhost>
Message-ID: <45701342.30746.CDF69F@localhost>

Hi

On 29 Nov 2006 at 10:26, David Kaplan wrote:

Date sent:      	Wed, 29 Nov 2006 10:26:32 -0600
From:           	David Kaplan <dkaplan at education.wisc.edu>
To:             	Petr Pikal <petr.pikal at precheza.cz>
Copies to:      	r-help at stat.math.ethz.ch
Subject:        	Re: [R] Aggregating data

> The problem is that this doesn't seem to give what I want.  I did look
> at this.  Perhaps doBy will work - haven't tried it yet.  But, any

the only thing we know what you want to do is aggregating data. 
That's why I directed you to the mentioned possibilities for data 
aggregating.

Below each post you will find this 

> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

and doing what is recommended can help others to understand your 
problem. Without telling us anything we also can do almost nothing.

HTH
Petr


> other suggestions are much appreciated.
> 
> 
> ======================================================================
> ===== David Kaplan, Ph.D. Professor Department of Educational
> Psychology University of Wisconsin - Madison Educational Sciences,
> Room, 1061 1025 W. Johnson Street Madison, WI 53706
> 
> email: dkaplan at education.wisc.edu
> homepage:
> http://www.education.wisc.edu/edpsych/facstaff/kaplan/kaplan.htm
> Phone: 608-262-0836
> ======================================================================
> =====
> 
> Petr Pikal wrote:
> > Similar answer as last time
> > 
> > aggregate, tapply, by or ppackage doBy
> > 
> > HTH
> > 
> > PS. If you want to add some other text then subject in your post do
> > not use HTML posting as recommended in posting guide.
> > 
> > Petr
> > 
> > 
> > On 28 Nov 2006 at 22:04, David Kaplan wrote:
> > 
> > Date sent:      	Tue, 28 Nov 2006 22:04:09 -0600
> > From:           	David Kaplan <dkaplan at education.wisc.edu>
> > To:             	r-help at stat.math.ethz.ch
> > Subject:        	[R] Aggregating data
> > 
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html and provide commented,
> >> minimal, self-contained, reproducible code.
> > 
> > Petr Pikal
> > petr.pikal at precheza.cz
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

Petr Pikal
petr.pikal at precheza.cz



From gavin.simpson at ucl.ac.uk  Fri Dec  1 11:44:05 2006
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 01 Dec 2006 10:44:05 +0000
Subject: [R] Quicker way of combining vectors into a data.frame
In-Reply-To: <1164908096.4584.14.camel@localhost.localdomain>
References: <1164906008.15235.13.camel@gsimpson.geog.ucl.ac.uk>
	<1164907551.4584.8.camel@localhost.localdomain>
	<1164908096.4584.14.camel@localhost.localdomain>
Message-ID: <1164969845.23223.6.camel@gsimpson.geog.ucl.ac.uk>

[ Resending to the list as I fell foul of the too many recipients rule ]

On Thu, 2006-11-30 at 11:34 -0600, Marc Schwartz wrote:

Thanks to Marc, Prof. Ripley, Sebastian and Sebastian (Luque - offline)
for your comments and suggestions.

I noticed that two of the vectors were named and so I removed the names
(names(vec) <- NULL) and that pushed the execution time for the function
from c. 40 seconds to c. 115 seconds and all the time was taken within
the data.frame(...) call. So having names *on* some of the vectors
seemed to help things along, which was the opposite of what i had
expected.

If I use the cbind method of Marc, then the execution time for the
function drops to c. 1 second (most of which is in the calculation of
one of the vectors). So I guess I can work round this now.

What I find interesting is that:

test.dat <- rnorm(4471)
> system.time(z <- data.frame(col1 = test.dat, col2 = test.dat, col3 =
test.dat,
+ col4 = test.dat, col5 = test.dat, col6 = test.dat, col7 = test.dat,
+ col8 = test.dat, col9 = test.dat, col10 = test.dat))
[1] 0.008 0.000 0.007 0.000 0.000

Whereas doing exactly the same thing with different data in the function
gives the following timings:

system.time(fab <- data.frame(lc.ratio, Q,
+                      fNupt,
+                      rho.n, rho.s,
+                      net.Nimm,
+                      net.Nden,
+                      CLminN,
+                      CLmaxN,
+                      CLmaxS))
[1] 173.415   0.260 192.192   0.000   0.000

Most of that was without a change in memory, but towards the end for c.
5 seconds memory use by R increased by 200-300 MB.

and...

> system.time(fab <- data.frame(lc.ratio = lc.ratio, Q = Q,
+                      fNupt = fNupt,
+                      rho.n = rho.n, rho.s = rho.s,
+                      net.Nimm = net.Nimm,
+                      net.Nden = net.Nden,
+                      CLminN = CLminN,
+                      CLmaxN = CLmaxN,
+                      CLmaxS = CLmaxS))
[1]  99.966   0.140 114.091   0.000   0.000

Again with a slight increase in memory usage in last 5 seconds. So now,
having stripped the names of two of the vectors (so now all are
un-named), the un-named version of the data.frame call is almost twice
as slow as the named data.frame call.

If I leave the names on the two vectors that had them, I get the
following timings for those same calls

> system.time(fab <- data.frame(lc.ratio, Q,
+                      fNupt,
+                      rho.n, rho.s,
+                      net.Nimm,
+                      net.Nden,
+                      CLminN,
+                      CLmaxN,
+                      CLmaxS))
[1]  96.234   0.244 101.706   0.000   0.000

> system.time(fab <- data.frame(lc.ratio = lc.ratio, Q = Q,
+                      fNupt = fNupt,
+                      rho.n = rho.n, rho.s = rho.s,
+                      net.Nimm = net.Nimm,
+                      net.Nden = net.Nden,
+                      CLminN = CLminN,
+                      CLmaxN = CLmaxN,
+                      CLmaxS = CLmaxS))
[1] 13.597  0.088 15.868  0.000  0.000

So having the 2 named vectors and using the named version of the
data.frame call is the fastest combination.

This is all done within the debugger at the time when I would be
generating fab, and if I do,

system.time(z <- data.frame(col1 = test.dat, col2 = test.dat, col3 =
test.dat,
+ col4 = test.dat, col5 = test.dat, col6 = test.dat, col7 = test.dat,
+ col8 = test.dat, col9 = test.dat, col10 = test.dat))
[1] 0.008 0.000 0.007 0.000 0.000

(as above) at this point in the debugger it is exceedingly quick.

I just don't understand what is going on with data.frame.

I have yet to try Prof. Ripley's suggestion of being a bit naughty with
R - I'll see if that is any quicker.

Once again, thanks to you all for your suggestions.

All the best,

G

> Gavin,
> 
> One more note, which is that even timing the direct data frame creation
> on my system with colnames, again using the same 10 numeric columns, I
> get:
> 
> > system.time(DF1 <- data.frame(lc.ratio = Col1, Q = Col2, fNupt = Col3,
>                                 rho.n = Col4, rho.s = Col5, 
>                                 net.Nimm = Col6, net.Nden = Col7, 
>                                 CLminN = Col8, CLmaxN = Col9, 
>                                 CLmaxS = Col10))
> [1] 0.012 0.000 0.028 0.000 0.000
> 
> 
> > str(DF1)
> 'data.frame':   4471 obs. of  10 variables:
>  $ lc.ratio: num   0.1423  0.1873 -1.8129  0.0255 -1.7650 ...
>  $ Q       : num   0.8340 -0.2387 -0.0864 -1.1184 -0.3368 ...
>  $ fNupt   : num  -0.1718 -0.0549  1.5194 -1.6127 -1.2019 ...
>  $ rho.n   : num  -0.740  0.240  0.522 -1.492  1.003 ...
>  $ rho.s   : num  -0.2363 -1.6248 -0.3045  0.0294  0.1240 ...
>  $ net.Nimm: num  -0.774  0.947 -1.098  0.809  1.216 ...
>  $ net.Nden: num  -0.198 -0.135 -0.300 -0.618 -0.784 ...
>  $ CLminN  : num   0.924 -3.265  0.211  0.813  0.262 ...
>  $ CLmaxN  : num   0.3212 -0.0502 -0.9978  0.9005 -1.6535 ...
>  $ CLmaxS  : num  -0.520  0.278 -0.546 -0.925  1.507 ...
> 
> 
> 
> 
> So there is something else going on, either with your code or some other
> conflict, unless my assumptions about your data are incorrect.
> 
> HTH,
> 
> Marc
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC & ENSIS, UCL Geography,  [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From carmei3 at web.de  Fri Dec  1 11:51:47 2006
From: carmei3 at web.de (Carmen Meier)
Date: Fri, 01 Dec 2006 11:51:47 +0100
Subject: [R] writing function with ,... )
In-Reply-To: <Pine.LNX.4.64.0611301224020.25165@springer.berkeley.edu>
References: <456F3AB4.3010703@web.de>
	<Pine.LNX.4.64.0611301224020.25165@springer.berkeley.edu>
Message-ID: <45700943.1000100@web.de>

Thanks, a lot
I was not able to find it the hole day ...
Carmen

Phil Spector schrieb:
> Carmen -
>    You certainly can write functions that use ..., but you need
> to extract the arguments that the dots represent with list().
> Here's a modified version of your function that may help explain
> how this feature works.
>
> test <- function(x,...){
>     print(x)
>     args = list(...)
>     if('y' %in% names(args))print(args$y)
>     if('z' %in% names(args))print(args$z)
> }
>
>                                        - Phil Spector
>                      Statistical Computing Facility
>                      Department of Statistics
>                      UC Berkeley
>                      spector at stat.berkeley.edu
>
>



From P.Dalgaard at biostat.ku.dk  Fri Dec  1 12:13:11 2006
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 01 Dec 2006 12:13:11 +0100
Subject: [R] Quicker way of combining vectors into a data.frame
In-Reply-To: <1164969845.23223.6.camel@gsimpson.geog.ucl.ac.uk>
References: <1164906008.15235.13.camel@gsimpson.geog.ucl.ac.uk>	<1164907551.4584.8.camel@localhost.localdomain>	<1164908096.4584.14.camel@localhost.localdomain>
	<1164969845.23223.6.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <45700E47.5070506@biostat.ku.dk>

Gavin Simpson wrote:
> [ Resending to the list as I fell foul of the too many recipients rule ]
>
> On Thu, 2006-11-30 at 11:34 -0600, Marc Schwartz wrote:
>
> Thanks to Marc, Prof. Ripley, Sebastian and Sebastian (Luque - offline)
> for your comments and suggestions.
>
> I noticed that two of the vectors were named and so I removed the names
> (names(vec) <- NULL) and that pushed the execution time for the function
> from c. 40 seconds to c. 115 seconds and all the time was taken within
> the data.frame(...) call. So having names *on* some of the vectors
> seemed to help things along, which was the opposite of what i had
> expected.
>
> If I use the cbind method of Marc, then the execution time for the
> function drops to c. 1 second (most of which is in the calculation of
> one of the vectors). So I guess I can work round this now.
>
> What I find interesting is that:
>
> test.dat <- rnorm(4471)
>   
>> system.time(z <- data.frame(col1 = test.dat, col2 = test.dat, col3 =
>>     
> test.dat,
> + col4 = test.dat, col5 = test.dat, col6 = test.dat, col7 = test.dat,
> + col8 = test.dat, col9 = test.dat, col10 = test.dat))
> [1] 0.008 0.000 0.007 0.000 0.000
>
> Whereas doing exactly the same thing with different data in the function
> gives the following timings:
>
> system.time(fab <- data.frame(lc.ratio, Q,
> +                      fNupt,
> +                      rho.n, rho.s,
> +                      net.Nimm,
> +                      net.Nden,
> +                      CLminN,
> +                      CLmaxN,
> +                      CLmaxS))
> [1] 173.415   0.260 192.192   0.000   0.000
>
> Most of that was without a change in memory, but towards the end for c.
> 5 seconds memory use by R increased by 200-300 MB.
>
> and...
>
>   
>> system.time(fab <- data.frame(lc.ratio = lc.ratio, Q = Q,
>>     
> +                      fNupt = fNupt,
> +                      rho.n = rho.n, rho.s = rho.s,
> +                      net.Nimm = net.Nimm,
> +                      net.Nden = net.Nden,
> +                      CLminN = CLminN,
> +                      CLmaxN = CLmaxN,
> +                      CLmaxS = CLmaxS))
> [1]  99.966   0.140 114.091   0.000   0.000
>
> Again with a slight increase in memory usage in last 5 seconds. So now,
> having stripped the names of two of the vectors (so now all are
> un-named), the un-named version of the data.frame call is almost twice
> as slow as the named data.frame call.
>
> If I leave the names on the two vectors that had them, I get the
> following timings for those same calls
>
>   
>> system.time(fab <- data.frame(lc.ratio, Q,
>>     
> +                      fNupt,
> +                      rho.n, rho.s,
> +                      net.Nimm,
> +                      net.Nden,
> +                      CLminN,
> +                      CLmaxN,
> +                      CLmaxS))
> [1]  96.234   0.244 101.706   0.000   0.000
>
>   
>> system.time(fab <- data.frame(lc.ratio = lc.ratio, Q = Q,
>>     
> +                      fNupt = fNupt,
> +                      rho.n = rho.n, rho.s = rho.s,
> +                      net.Nimm = net.Nimm,
> +                      net.Nden = net.Nden,
> +                      CLminN = CLminN,
> +                      CLmaxN = CLmaxN,
> +                      CLmaxS = CLmaxS))
> [1] 13.597  0.088 15.868  0.000  0.000
>
> So having the 2 named vectors and using the named version of the
> data.frame call is the fastest combination.
>
> This is all done within the debugger at the time when I would be
> generating fab, and if I do,
>
> system.time(z <- data.frame(col1 = test.dat, col2 = test.dat, col3 =
> test.dat,
> + col4 = test.dat, col5 = test.dat, col6 = test.dat, col7 = test.dat,
> + col8 = test.dat, col9 = test.dat, col10 = test.dat))
> [1] 0.008 0.000 0.007 0.000 0.000
>
> (as above) at this point in the debugger it is exceedingly quick.
>
> I just don't understand what is going on with data.frame.
>
>   
I think there is something about the data you're not telling us...

Could you e.g. do something like

str(data.frame(lc.ratio, Q,
                      fNupt,
                      rho.n, rho.s,
                      net.Nimm,
                      net.Nden,
                      CLminN,
                      CLmaxN,
                      CLmaxS))


and

str(list(lc.ratio, Q,
                      fNupt,
                      rho.n, rho.s,
                      net.Nimm,
                      net.Nden,
                      CLminN,
                      CLmaxN,
                      CLmaxS))





-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From kaniovsk at wsr.ac.at  Fri Dec  1 12:25:42 2006
From: kaniovsk at wsr.ac.at (Serguei Kaniovski)
Date: Fri, 1 Dec 2006 12:25:42 +0100 (CET)
Subject: [R] A different contingency table of counts by case
Message-ID: <7822395.1164972342692.SLOX.WebMail.wwwrun@billa.wsr.ac.at>

Dear All,

the following code, by courtesy of Jacques VESLOT, collates the
following contingency table from DATA (read in as "df", sample listed
below)

"led" represents (court) cases,
"jid" the (justices) persons, and
"vote" is the binary state.

The command:

smat<-t(apply(combinations(nlevels(df$jid), 2), 1, function(x)
with(df[df$jid %in% levels(df$jid)[x],],
table(factor(unlist(sapply(split(vote, led), function(y)
ifelse(length(y) == 2, paste(y, collapse=""), NA))),
levels=c("00","01","10","11"))))))

collates a contingency table of number of cases any two persons

a. both have "1",
b. the first has "0" - the second has "1",
c. the first has "1" - the second has "0",
d. both have "0".

QUESTION: I would like to collate a table counting all possible
combinations of binary states, ie voting outcomes. Each "led" contains 9
"jid", so there will be 2^9=512 different possibilities. These are, in
the order of the decimals the vectors represent,
(1,1,1,1,1,1,1,1,1)
(1,1,1,1,1,1,1,1,0)
(1,1,1,1,1,1,1,0,1)
etc. until
(0,0,0,0,0,0,0,0,1)
(0,0,0,0,0,0,0,0,0)
What I need to know is how often each of the 512 outcomes occurs.

Thanks,
Serguei

DATA:
jid,led,vote
breyer;143/0154;0
ginsberg;143/0154;0
kennedy;143/0154;1
oconnor;143/0154;0
rehnquist;143/0154;0
scalia;143/0154;0
souter;143/0154;0
stevens;143/0154;0
thomas;143/0154;1
breyer;143/0171;1
ginsberg;143/0171;1
kennedy;143/0171;1
oconnor;143/0171;0
rehnquist;143/0171;0
scalia;143/0171;0
souter;143/0171;1
stevens;143/0171;1
thomas;143/0171;0
breyer;143/0238;1
ginsberg;143/0238;1
kennedy;143/0238;1
oconnor;143/0238;1
rehnquist;143/0238;1
scalia;143/0238;1
souter;143/0238;1
stevens;143/0238;1
thomas;143/0238;1
breyer;143/0258;1
ginsberg;143/0258;1
kennedy;143/0258;1
oconnor;143/0258;1
rehnquist;143/0258;1
scalia;143/0258;1
souter;143/0258;1
stevens;143/0258;1
thomas;143/0258;1
breyer;143/0270;0
ginsberg;143/0270;0
kennedy;143/0270;1
oconnor;143/0270;0
rehnquist;143/0270;1
scalia;143/0270;1
souter;143/0270;0
stevens;143/0270;0
thomas;143/0270;1
breyer;143/0311;0
ginsberg;143/0311;1
kennedy;143/0311;0
oconnor;143/0311;0
rehnquist;143/0311;0
scalia;143/0311;1
souter;143/0311;1
stevens;143/0311;1
thomas;143/0311;1
breyer;143/0388;1
ginsberg;143/0388;1
kennedy;143/0388;1
oconnor;143/0388;1
rehnquist;143/0388;1
scalia;143/0388;0
souter;143/0388;1
stevens;143/0388;0
thomas;143/0388;1
breyer;143/0399;1
ginsberg;143/0399;1
kennedy;143/0399;1
oconnor;143/0399;1
rehnquist;143/0399;1
scalia;143/0399;1
souter;143/0399;1
stevens;143/0399;1
thomas;143/0399;1
breyer;143/0408;1
ginsberg;143/0408;0
kennedy;143/0408;1
oconnor;143/0408;1
rehnquist;143/0408;1
scalia;143/0408;1
souter;143/0408;0
stevens;143/0408;0
thomas;143/0408;1



From gavin.simpson at ucl.ac.uk  Fri Dec  1 13:06:37 2006
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 01 Dec 2006 12:06:37 +0000
Subject: [R] Quicker way of combining vectors into a data.frame
In-Reply-To: <45700E47.5070506@biostat.ku.dk>
References: <1164906008.15235.13.camel@gsimpson.geog.ucl.ac.uk>
	<1164907551.4584.8.camel@localhost.localdomain>
	<1164908096.4584.14.camel@localhost.localdomain>
	<1164969845.23223.6.camel@gsimpson.geog.ucl.ac.uk>
	<45700E47.5070506@biostat.ku.dk>
Message-ID: <1164974797.23223.16.camel@gsimpson.geog.ucl.ac.uk>

On Fri, 2006-12-01 at 12:13 +0100, Peter Dalgaard wrote:
> Gavin Simpson wrote:
<snip />
> >
> > I just don't understand what is going on with data.frame.
> >
> >   
> I think there is something about the data you're not telling us...

Yes, that I was doing something very, very silly that I thought would
work (produce a vector CLmaxN of the required length), but was in fact
blowing out to a huge named list. It was this that was causing the
massive increase in computation time in data.frame over cbind.

After correcting my mistake, timings for data.frame are:

system.time(fab <- data.frame(lc.ratio, Q,
+                      fNupt,
+                      rho.n, rho.s,
+                      net.Nimm,
+                      net.Nden,
+                      CLminN,
+                      CLmaxN,
+                      CLmaxS))
[1] 0.012 0.000 0.011 0.000 0.000
Browse[1]> system.time(fab <- data.frame(lc.ratio = lc.ratio, Q = Q,
+                      fNupt = fNupt,
+                      rho.n = rho.n, rho.s = rho.s,
+                      net.Nimm = net.Nimm,
+                      net.Nden = net.Nden,
+                      CLminN = CLminN,
+                      CLmaxN = CLmaxN,
+                      CLmaxS = CLmaxS))
[1] 0.008 0.000 0.018 0.000 0.000

One vector has names for some reason, removing them brings the un-named
data.frame version down to the named version timing and makes no
difference to the named version

Browse[1]> names(CLmaxS) <- NULL
Browse[1]> system.time(fab <- data.frame(lc.ratio, Q,
+                      fNupt,
+                      rho.n, rho.s,
+                      net.Nimm,
+                      net.Nden,
+                      CLminN,
+                      CLmaxN,
+                      CLmaxS))
[1] 0.008 0.000 0.016 0.000 0.000
Browse[1]> system.time(fab <- data.frame(lc.ratio = lc.ratio, Q = Q,
+                      fNupt = fNupt,
+                      rho.n = rho.n, rho.s = rho.s,
+                      net.Nimm = net.Nimm,
+                      net.Nden = net.Nden,
+                      CLminN = CLminN,
+                      CLmaxN = CLmaxN,
+                      CLmaxS = CLmaxS))
[1] 0.008 0.000 0.009 0.000 0.000

Apologies to the list for bothering you all with my stupidity and thank
you again to everyone who replied - I knew it was I who was doing
something wrong, but couldn't see it and thanks to your comments,
suggestions and queries I was able to work out what that was.

All the best,

G

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC & ENSIS, UCL Geography,  [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From Goesele at hfph.mwn.de  Fri Dec  1 13:18:49 2006
From: Goesele at hfph.mwn.de (Andreas Goesele)
Date: Fri, 01 Dec 2006 13:18:49 +0100
Subject: [R] Dummies multiplied with other variable (solved)
In-Reply-To: <815b70590611301102u47a67048uf6aff53a9c24c063@mail.gmail.com>
	(David Barron's message of "Thu, 30 Nov 2006 19:02:49 +0000")
References: <87hcwi6kxf.fsf@debian.IGP>
	<815b70590611291332l132f0d29pc24198ea31e7e5cc@mail.gmail.com>
	<87bqmp7tqi.fsf@debian.IGP>
	<815b70590611300051p44583d8m35c747c3912313fb@mail.gmail.com>
	<873b807umn.fsf@debian.IGP>
	<815b70590611301102u47a67048uf6aff53a9c24c063@mail.gmail.com>
Message-ID: <87d573erme.fsf_-_@debian.IGP>

"David Barron" <mothsailor at googlemail.com> writes:

> I'm not sure if this will help, but it's worth a try.  Do the
> regression as I suggested before, extract the model matrix and remove
> the "offending" column.  I'm assuming you don't know in advance how
> many levels there are in the factor.  Then use this to perform the
> regression.  Something like this:
>
> m1 <- lm(x ~ fd:y + fd)
> mm <- model.matrix(m1)
> nl <- length(levels(fd))
> newdat <- mm[,-c(1,nl)]
> lm(x ~ newdat)

Thanks a lot! With a small change that solved my problem!

-- 
Andreas G?sele                   Omnis enim res, quae dando non deficit,
Inst. f. Gesellschaftspolitik    dum habetur et non datur,
Kaulbachstr. 31a, 80539 M?nchen  nondum habetur, quomodo habenda est.
E-mail: goesele at hfph.mwn.de      (Augustinus)



From Giovanni_Millo at Generali.com  Fri Dec  1 13:23:56 2006
From: Giovanni_Millo at Generali.com (Millo Giovanni)
Date: Fri, 1 Dec 2006 13:23:56 +0100
Subject: [R] simple parallel computing on single multicore machine
Message-ID: <7C95FD2FC68FBB45B9E9FDC1ECD49AF5F6E1DB@BEMAILEXTV03.corp.generali.net>

Dear List,

the advent of multicore machines in the consumer segment makes me wonder
whether it would, at least in principle, be possible to divide a
computational task into more slave R processes running on the different
cores of the same processor, more or less in the way package SNOW would
do on a cluster. I am thinking of simple 'embarassingly parallel'
problems, just like inverting 1000 matrices, estimating 1000 models or
the like.

I have seen some talk here on making R multi-threaded and the like, but
this is much simpler. I am just a curious useR, so don't bother if you
don't have time, but maybe you can point me at some resource, or just
say "this is nonsense"...

Cheers 
Giovanni

Giovanni Millo
Research Dept.,
Assicurazioni Generali SpA
Via Machiavelli 4, 
34131 Trieste (Italy)
tel. +39 040 671184 
fax  +39 040 671160
 
Ai sensi del D.Lgs. 196/2003 si precisa che le informazioni ...{{dropped}}



From B.Rowlingson at lancaster.ac.uk  Fri Dec  1 13:37:33 2006
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 01 Dec 2006 12:37:33 +0000
Subject: [R] C structures in R
Message-ID: <4570220D.10806@lancaster.ac.uk>

Is it safe to call C code from R that mallocs memory for a structure, 
returning a pointer to that structure via some 'raw()' parameter. Then, 
pass that pointer to another C routine, and finally free the malloced 
memory by passing the raw() data to another C routine?

I've written some code that does this, I'm just not sure if anything 
could go wrong. The worst I can come up with is a memory leak if the 
structure's memory isn't freed - possibly because the R is interrupted.

R isn't going to stomp on memory that's been malloced by an included C 
routine between .C calls though, is it?

Barry

[[
gory details:

   R code calls a C routine with .C passing a 4-byte (because 4 is 
sizeof(char*) in my architecture) 'raw' object, the C code then mallocs 
the structure and copies the address of the structure into the 4 bytes 
that the raw object (which appears as a char* in the C routine argument 
list) points to. This gets returned back to R. Another option would be 
to create a raw object of the right size to store my structure, pass 
that to C and not malloc anything in C. But that would mean altering the 
C code which I want to do as little as possible.

gory code available on request.

]]



From ligges at statistik.uni-dortmund.de  Fri Dec  1 13:38:53 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 01 Dec 2006 13:38:53 +0100
Subject: [R] simple parallel computing on single multicore machine
In-Reply-To: <7C95FD2FC68FBB45B9E9FDC1ECD49AF5F6E1DB@BEMAILEXTV03.corp.generali.net>
References: <7C95FD2FC68FBB45B9E9FDC1ECD49AF5F6E1DB@BEMAILEXTV03.corp.generali.net>
Message-ID: <4570225D.1090501@statistik.uni-dortmund.de>



Millo Giovanni wrote:
> Dear List,
> 
> the advent of multicore machines in the consumer segment makes me wonder
> whether it would, at least in principle, be possible to divide a
> computational task into more slave R processes running on the different
> cores of the same processor, more or less in the way package SNOW would
> do on a cluster. I am thinking of simple 'embarassingly parallel'
> problems, just like inverting 1000 matrices, estimating 1000 models or
> the like.
> 
> I have seen some talk here on making R multi-threaded and the like, but
> this is much simpler. I am just a curious useR, so don't bother if you
> don't have time, but maybe you can point me at some resource, or just
> say "this is nonsense"...


Just use snow itself, for example.
Or on a completely other level a tuned BLAS for perallel computations 
such as ATLAS.

Uwe Ligges


> Cheers 
> Giovanni
> 
> Giovanni Millo
> Research Dept.,
> Assicurazioni Generali SpA
> Via Machiavelli 4, 
> 34131 Trieste (Italy)
> tel. +39 040 671184 
> fax  +39 040 671160
>  
> Ai sensi del D.Lgs. 196/2003 si precisa che le informazioni ...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From P.Dalgaard at biostat.ku.dk  Fri Dec  1 13:47:28 2006
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 01 Dec 2006 13:47:28 +0100
Subject: [R] simple parallel computing on single multicore machine
In-Reply-To: <7C95FD2FC68FBB45B9E9FDC1ECD49AF5F6E1DB@BEMAILEXTV03.corp.generali.net>
References: <7C95FD2FC68FBB45B9E9FDC1ECD49AF5F6E1DB@BEMAILEXTV03.corp.generali.net>
Message-ID: <45702460.2040909@biostat.ku.dk>

Millo Giovanni wrote:
> Dear List,
>
> the advent of multicore machines in the consumer segment makes me wonder
> whether it would, at least in principle, be possible to divide a
> computational task into more slave R processes running on the different
> cores of the same processor, more or less in the way package SNOW would
> do on a cluster. I am thinking of simple 'embarassingly parallel'
> problems, just like inverting 1000 matrices, estimating 1000 models or
> the like.
>
> I have seen some talk here on making R multi-threaded and the like, but
> this is much simpler. I am just a curious useR, so don't bother if you
> don't have time, but maybe you can point me at some resource, or just
> say "this is nonsense"...
>
>
>   
I don't think snow (or rather its underlying message-passing interface)
cares whether its processes are on different physical machines. So this
is easily doable. Of course you need to be aware that the processes are
competing for resources like RAM and disc.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From rdiaz at cnio.es  Fri Dec  1 13:53:00 2006
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Fri, 1 Dec 2006 13:53:00 +0100
Subject: [R] simple parallel computing on single multicore machine
In-Reply-To: <7C95FD2FC68FBB45B9E9FDC1ECD49AF5F6E1DB@BEMAILEXTV03.corp.generali.net>
References: <7C95FD2FC68FBB45B9E9FDC1ECD49AF5F6E1DB@BEMAILEXTV03.corp.generali.net>
Message-ID: <200612011353.00665.rdiaz@cnio.es>

On Friday 01 December 2006 13:23, Millo Giovanni wrote:
> Dear List,
>
> the advent of multicore machines in the consumer segment makes me wonder
> whether it would, at least in principle, be possible to divide a
> computational task into more slave R processes running on the different
> cores of the same processor, more or less in the way package SNOW would
> do on a cluster. I am thinking of simple 'embarassingly parallel'
> problems, just like inverting 1000 matrices, estimating 1000 models or
> the like.
>
> I have seen some talk here on making R multi-threaded and the like, but
> this is much simpler. I am just a curious useR, so don't bother if you
> don't have time, but maybe you can point me at some resource, or just
> say "this is nonsense"...



Dear Millo,

I find the usage of papply (from the library with the same name), which itself 
uses Rmpi to be easy and ideal for those cases. The papply documentation 
shows clearly what you need to do to pass the required arguments to papply. 
And once you have your MPI universe up and running (with whichever number of 
slaves you specify) it just works. As well, I find debugging very simple: 
just start an MPI universe with only one node, which forces papply to run 
serially (non-parallel) so wrong arguments, missing libraries, etc, are easy 
to spot.

Best,

R.





>
> Cheers
> Giovanni
>
> Giovanni Millo
> Research Dept.,
> Assicurazioni Generali SpA
> Via Machiavelli 4,
> 34131 Trieste (Italy)
> tel. +39 040 671184
> fax  +39 040 671160
>
> Ai sensi del D.Lgs. 196/2003 si precisa che le informazioni ...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented, minimal,
> self-contained, reproducible code.

-- 
Ram?n D?az-Uriarte
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://ligarto.org/rdiaz
PGP KeyID: 0xE89B3462
(http://ligarto.org/rdiaz/0xE89B3462.asc)



**NOTA DE CONFIDENCIALIDAD** Este correo electr?nico, y en s...{{dropped}}



From ripley at stats.ox.ac.uk  Fri Dec  1 14:21:36 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 1 Dec 2006 13:21:36 +0000 (GMT)
Subject: [R] C structures in R
In-Reply-To: <4570220D.10806@lancaster.ac.uk>
References: <4570220D.10806@lancaster.ac.uk>
Message-ID: <Pine.LNX.4.64.0612011316001.13593@gannet.stats.ox.ac.uk>

Isn't this a question clearly in R-devel's domain?

  R-devel is intended for questions and discussion about code development
  in R. Questions likely to prompt discussion unintelligible to
  non-programmers should go to to R-devel.

The short answer is that quite a bit of code, e.g pwilcox and RODBC, does 
things like this.  You don't need to pass the pointer back to R, but if 
you do external pointers are designed for this job.  Nevertheless, 
graphics recording on Windows makes use of integers AFAIR to store C-level 
structures (but it predates raw and external pointers).

On Fri, 1 Dec 2006, Barry Rowlingson wrote:

> Is it safe to call C code from R that mallocs memory for a structure,
> returning a pointer to that structure via some 'raw()' parameter. Then,
> pass that pointer to another C routine, and finally free the malloced
> memory by passing the raw() data to another C routine?
>
> I've written some code that does this, I'm just not sure if anything
> could go wrong. The worst I can come up with is a memory leak if the
> structure's memory isn't freed - possibly because the R is interrupted.
>
> R isn't going to stomp on memory that's been malloced by an included C
> routine between .C calls though, is it?
>
> Barry
>
> [[
> gory details:
>
>   R code calls a C routine with .C passing a 4-byte (because 4 is
> sizeof(char*) in my architecture) 'raw' object, the C code then mallocs
> the structure and copies the address of the structure into the 4 bytes
> that the raw object (which appears as a char* in the C routine argument
> list) points to. This gets returned back to R. Another option would be
> to create a raw object of the right size to store my structure, pass
> that to C and not malloc anything in C. But that would mean altering the
> C code which I want to do as little as possible.
>
> gory code available on request.
>
> ]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From j.abellan at imperial.ac.uk  Fri Dec  1 14:23:30 2006
From: j.abellan at imperial.ac.uk (Juanjo Abellan)
Date: Fri, 1 Dec 2006 14:23:30 +0100
Subject: [R] *** caught segfault *** error
In-Reply-To: <Pine.LNX.4.64.0611301038010.8011@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.44.0611301124100.11410-100000@reclus.nhh.no>
	<Pine.LNX.4.64.0611301038010.8011@gannet.stats.ox.ac.uk>
Message-ID: <EBA6A03A-6088-4383-8C0E-5F5AE6C2B0FC@imperial.ac.uk>

Dear all,

The shapefile was generated with ArcGIS 9.0 running on Windows XP. It  
can be can be found in www.uv.es/~abellan/districts_ok.zip.

Re running sessionInfo() before the error occurres as suggested by  
Prof. Ripley:

 > library(spdep)
Loading required package: tripack
Loading required package: maptools
Loading required package: foreign
Loading required package: sp
Loading required package: SparseM
Package SparseM (0.71) loaded.  To cite, see citation("SparseM")
Loading required package: boot
 > library(maptools)
 > sessionInfo()
R version 2.4.0 (2006-10-03)
i386-apple-darwin8.8.1

locale:
es_ES.UTF-8/es_ES.UTF-8/es_ES.UTF-8/C/es_ES.UTF-8/es_ES.UTF-8

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"      
"datasets"  "base"

other attached packages:
    spdep     boot  SparseM maptools       sp  foreign  tripack
"0.3-32" "1.2-26"   "0.71"  "0.6-3"  "0.9-4" "0.8-17" "1.2-10"
 > district.shp <- read.shape("~/Documents/SAHSU/MD/data/Carthography/ 
districts_ok.shp")
Shapefile type: Polygon, (5), # of Shapes: 354
 > plot(district.shp)

*** caught segfault ***
address 0xc00006d5, cause 'memory not mapped'

Traceback:
1: polygon(theMap$Shapes[[ii]]$verts, col = fg[i], border = ol,     ...)
2: plot.Map(district.shp)
3: plot(district.shp)
4: plot(district.shp)

Possible actions:
1: abort (with core dump)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection:



Re trying maptools "example(read.shape)" as suggested by Dr Bivand:

 > example(read.shape)

rd.shp> x <- read.shape(system.file("shapes/sids.shp", package =  
"maptools")[1])
Shapefile type: Polygon, (5), # of Shapes: 100

rd.shp> length(x$Shapes)
[1] 100

rd.shp> unlist(lapply(x$att.data, class))
      AREA PERIMETER     CNTY_   CNTY_ID      NAME      FIPS     
FIPSNO  CRESS_ID     BIR74     SID74
"numeric" "numeric" "numeric" "numeric"  "factor"  "factor" "numeric"  
"numeric" "numeric" "numeric"
   NWBIR74     BIR79     SID79   NWBIR79
"numeric" "numeric" "numeric" "numeric"

rd.shp> str(getinfo.shape(system.file("shapes/fylk-val.shp",
     package = "maptools")[1]))
List of 5
$ : chr "/Library/Frameworks/R.framework/Versions/2.4/Resources/ 
library/maptools/shapes/fylk-val.shp"
$ : int 3
$ : int 97
$ : num [1:4]   -4868 6456207       0       0
$ : num [1:4] 1084722 7841997       0       0
- attr(*, "class")= chr "shapehead"
 > plot(x)
Warning message:
'plot.Map' is deprecated.
Use 'plot.Spatial' instead.
See help("Deprecated") and help("maptools-deprecated").

The maps is plotted.

Sorry, I didn't understand the issue about the locale and the C  
locale that Prof Ripley mentioned. Where could I learn about that?

Thanks,

Juanjo



El 30/11/2006, a las 11:41, Prof Brian Ripley escribi?:

> On Thu, 30 Nov 2006, Roger Bivand wrote:
>
>> On Thu, 30 Nov 2006, Juanjo Abellan wrote:
>>
>>> Dear R users,
>>>
>>> I use R 2.4.0 on an iMac running Mac OS X 10.4.8, with a 2.16GHz
>>> Intel Core 2 Duo and 2GB 667 MHz DDR2 SDRAM.
>>>
>>
>> Please make a copy of the offending shapefile available either on a
>> website or attach it to me off-list. It would be useful to know  
>> its origin
>> (which software wrote it) and whether the copy on the iMac is  
>> identical to
>> the copy on the Windows PC (perhaps attach both?). Can other  
>> shapefiles be
>> read on the iMac?
>>
>> (This may be an R-sig-Mac issue as well as an R-sig-geo issue, so  
>> if other
>> iMac users could check whether example(read.shape) in the maptools  
>> package
>> works for them on similar hardware, I'd be grateful)
>
> And also please run sessionInfo() *after* attaching the packages,  
> since all the version information on those packages is missing in  
> the log you sent.
>
> It is possibly a locale issue (non-UTF-8 strings in the  
> shapefile?), so you might like to try this in the C locale.
>
>
>>> > sessionInfo()
>>> R version 2.4.0 (2006-10-03)
>>> i386-apple-darwin8.8.1
>>>
>>> locale:
>>> es_ES.UTF-8/es_ES.UTF-8/es_ES.UTF-8/C/es_ES.UTF-8/es_ES.UTF-8
>>>
>>> attached base packages:
>>> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"
>>> "datasets"  "base"
>>>
>>>
>>> I get an error below whenever I try to plot a map from a shapefile
>>> imported into R; I've tried packages shapefiles and spdep, and two
>>> different shapefiles, and get the error in all 4 combinations.
>>>
>>> The shapefile is imported correctly, and I get the error only when I
>>> try to plot the map. I specifically use commands
>>>
>>> > library(spdep)
>>> Loading required package: tripack
>>> Loading required package: maptools
>>> Loading required package: foreign
>>> Loading required package: sp
>>> Loading required package: SparseM
>>> Package SparseM (0.71) loaded.  To cite, see citation("SparseM")
>>> Loading required package: boot
>>> > library(maptools)
>>> > district.shp <- read.shape("~/Documents/SAHSU/MD/data/ 
>>> Carthography/
>>> districts_ok.shp")
>>> Shapefile type: Polygon, (5), # of Shapes: 354
>>> > plot(district.shp)
>>>
>>> *** caught segfault ***
>>> address 0xc00006d5, cause 'memory not mapped'
>>>
>>> Traceback:
>>> 1: polygon(theMap$Shapes[[ii]]$verts, col = fg[i], border =  
>>> ol,     ...)
>>> 2: plot.Map(district.shp)
>>> 3: plot(district.shp)
>>> 4: plot(district.shp)
>>>
>>> Possible actions:
>>> 1: abort (with core dump)
>>> 2: normal R exit
>>> 3: exit R without saving workspace
>>> 4: exit R saving workspace
>>> Selection:
>>>
>>> I saw that plot.Map is deprecated, so I converted the shapefile into
>>> a polygon list, and then tried to plot it, but still got the error:
>>>
>>> > library(spdep)
>>> Loading required package: tripack
>>> Loading required package: maptools
>>> Loading required package: foreign
>>> Loading required package: sp
>>> Loading required package: SparseM
>>> Package SparseM (0.71) loaded.  To cite, see citation("SparseM")
>>> Loading required package: boot
>>> > library(maptools)
>>> > district.shp <- read.shape("~/Documents/SAHSU/MD/data/ 
>>> Carthography/
>>> districts_ok.shp")
>>> Shapefile type: Polygon, (5), # of Shapes: 354
>>> > district.pl <- Map2poly(district.shp, as.character(district.shp 
>>> $att
>>> $DISTRICT_2))
>>> > plot(district.pl)
>>>
>>> *** caught segfault ***
>>> address 0xc0000165, cause 'memory not mapped'
>>>
>>> Traceback:
>>> 1: polygon(coords[pFrom[i]:pTo[i], ], border = border, xpd = xpd,
>>> density = density, angle = angle)
>>> 2: polygonholes(x[[j]], border = border, xpd = xpd, density =  
>>> density
>>> [j],     angle = angle[j], pbg = pbg, forcefill = forcefill)
>>> 3: plot.polylist(district.pl)
>>> 4: plot(district.pl)
>>> 5: plot(district.pl)
>>>
>>> Possible actions:
>>> 1: abort (with core dump)
>>> 2: normal R exit
>>> 3: exit R without saving workspace
>>> 4: exit R saving workspace
>>> Selection:
>>>
>>>
>>> I also get the same error when I use library shapefiles to import  
>>> the
>>> shp file and then try to plot the polygons myself; these are the
>>> commands I run:
>>>
>>> > library(shapefiles)
>>> > districts.shp <- read.shapefile("~/Documents/SAHSU/MD/data/
>>> carthography/districts_ok")
>>>
>>> Attaching package: 'foreign'
>>>
>>>
>>> 	The following object(s) are masked from package:shapefiles :
>>>
>>> 	 read.dbf
>>>
>>> 	The following object(s) are masked from package:shapefiles :
>>>
>>> 	 write.dbf
>>>
>>> > ndistricts <- length(districts.shp$shp$shp)
>>> > keys <- districts.shp$dbf$dbf$DISTRICT_2
>>> > vertices <- list()
>>> > for(i in 1:ndistricts){
>>> + vertices[[i]] <- districts.shp$shp$shp[[i]]$points
>>> + }
>>> >
>>> > districts.map <- list(codigo=keys, vertices=vertices)#,
>>> nombre=wardnames)
>>> >
>>> > xymin <- apply(t(sapply(districts.map$vertices, apply, 2, min)),
>>> 2, min)
>>> > xymax <- apply(t(sapply(districts.map$vertices, apply, 2, max)),
>>> 2, max)
>>> > corners <- expand.grid(xymin, xymax)
>>> >
>>> > # Plotting the corners and then adding polygons one by one.
>>> > par(pty="s")
>>> > plot(rbind(xymin, xymax), type="n")
>>> > for (i in 1:ndistricts){
>>> +     polygon(x=districts.map$vertices[[i]][,1], y=districts.map
>>> $vertices[[i]][,2])
>>> + }
>>>
>>> *** caught segfault ***
>>> address 0xc00009d8, cause 'memory not mapped'
>>>
>>> Traceback:
>>> 1: polygon(x = districts.map$vertices[[i]][, 1], y = districts.map
>>> $vertices[[i]][,     2])
>>>
>>> Possible actions:
>>> 1: abort (with core dump)
>>> 2: normal R exit
>>> 3: exit R without saving workspace
>>> 4: exit R saving workspace
>>> Selection:
>>>
>>>
>>> The same commands work fine in my laptop (Intel Pentium 4 CPU 2.00
>>> GHz, with 512 MB RAM), where I use R v2.2.1 on Windows XP Home
>>> Edition v2002.
>>>
>>> Any ideas of what may cause the error?
>>>
>>> Many thanks,
>>>
>>> Juanjo Abellan
>>> Research Associate in Statistics
>>> Department of Epidemiology and Public Health
>>> Imperial College London
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jayemerson at gmail.com  Fri Dec  1 14:25:05 2006
From: jayemerson at gmail.com (Jay Emerson)
Date: Fri, 1 Dec 2006 08:25:05 -0500
Subject: [R] AIC for heckit
Message-ID: <d4588dec0612010525s6d788716of30a1066eb50f4c2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061201/050e655c/attachment-0004.pl 

From ripley at stats.ox.ac.uk  Fri Dec  1 14:38:06 2006
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Fri, 1 Dec 2006 13:38:06 +0000 (GMT Standard Time)
Subject: [R] *** caught segfault *** error
In-Reply-To: <EBA6A03A-6088-4383-8C0E-5F5AE6C2B0FC@imperial.ac.uk>
References: <Pine.LNX.4.44.0611301124100.11410-100000@reclus.nhh.no>
	<Pine.LNX.4.64.0611301038010.8011@gannet.stats.ox.ac.uk>
	<EBA6A03A-6088-4383-8C0E-5F5AE6C2B0FC@imperial.ac.uk>
Message-ID: <Pine.WNT.4.64.0612011336480.3808@Petrel>

On Fri, 1 Dec 2006, Juanjo Abellan wrote:

[...]

> Sorry, I didn't understand the issue about the locale and the C locale that 
> Prof Ripley mentioned. Where could I learn about that?

In the R-admin manual (but Roger will understand).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Fri Dec  1 15:06:09 2006
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 1 Dec 2006 09:06:09 -0500
Subject: [R] Box Tidwell / Error Message
In-Reply-To: <E1Gq3n4-0002sy-00@smtp05.web.de>
Message-ID: <20061201140607.MOKU1750.tomts40-srv.bellnexxia.net@JohnDesktop8300>

Dear Simon,

It's hard to tell without the data and more information about the nature of
the variables, but I suspect that the program is running into numerical
difficulties because of a flat likelihood at the maximum. Is age2 by any
chance age^2? How is year (in either form) related to age?

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Simon P. Kempf
> Sent: Friday, December 01, 2006 3:30 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Box Tidwell / Error Message
> 
> Dear R-Users,
> 
>  
> 
> I used the box.tidwell () function of the car Package. 
> 
>  
> 
> When I used the following formula:
> 
>  
> 
> semi.sub.in.mi1.boxtidwell_h<-box.tidwell(RENT_LG ~ 
> I(age+1)+I(age2+1)+X06A
> + I(X08B+1) + I(X22+1) + I(X24+1) + X31A, ~B_YEAR + C_X01 + C_X14 + 
> + C_X19 +
> C_X29A +C_X21 + C_X23 + D_X12 + D_X17 + D_X18 + D_X25 + D_X27 
> + D_X30 +
> D_X32 + D_X35, data = semi.sub.in.mi1)
> 
>  
> 
> everything is fine.
> 
>  
> 
> However, when I replaced the time dummy variable:
> 
>  
> 
> semi.sub.in.mi1.boxtidwell_h<-box.tidwell(RENT_LG ~ 
> I(age+1)+I(age2+1)+X06A
> + I(X08B+1) + I(X22+1) + I(X24+1) + X31A, ~B_HALF + C_X01 + C_X14 + 
> + C_X19 +
> C_X29A +C_X21 + C_X23 + D_X12 + D_X17 + D_X18 + D_X25 + D_X27 
> + D_X30 +
> D_X32 + D_X35, data = semi.sub.in.mi1)
> 
>  
> 
> I get the following error message:
> 
>  
> 
> Error in lm.fit(x, y, offset = offset, singular.ok = 
> singular.ok, ...) : 
> 
>         NA/NaN/Inf in foreign function call (arg 1)
> 
>  
> 
> When I use the following formula (I deleted the I(age2+1) term):
> 
>  
> 
> semi.sub.in.mi1.boxtidwell_h<-box.tidwell(RENT_LG ~ I(age+1)+X06A +
> I(X08B+1) + I(X22+1) + I(X24+1) + X31A, ~B_HALF + C_X01 + 
> C_X14 + C_X19 + C_X29A +C_X21 + C_X23 + D_X12 + D_X17 + D_X18 
> + D_X25 + D_X27 + D_X30 +
> D_X32 + D_X35, data = semi.sub.in.mi1)
> 
>  
> 
> It works.
> 
>  
> 
> Some background information:
> 
>  
> 
> -          The formula with the predictors to be transformed 
> contains only
> variables which are >0.
> 
> -          The data set does not have any missing values
> 
> -          B_YEAR is a factor with 10 levels
> 
> -          B_HALF is a factor with 20 levels
> 
> -          The data set contains more than 19000 observations.
> 
>  
> 
> Now, I am bit confused. Why does the function works when I 
> use B_YEAR respecitvely why does it work with B_HALF when I 
> delete I(age2+1)
> 
>  
> 
> Thanks in advance,
> 
>  
> 
> Simon
> 
>  
> 
>  
> 
>  
> 
>  
> 
> Simon P. Kempf 
> 
> Dipl.-Kfm. MScRE Immobilienvkonom (ebs)
> 
> Wissenschaftlicher Assistent
> 
>  
> 
> B|ro:
> 
> IREBS Immobilienakademie
> 
> c/o ebs Immobilienakademie GmbH
> 
> Berliner Str. 26a
> 
> 13507 Berlin
> 
>  
> 
> Privat:
> 
> Dunckerstra_e 60
> 
> 10439 Berlin
> 
>  
> 
> Mobil: 0176 7002 6687
> 
> Email:  <mailto:simon.kempf at web.de> simon.kempf at web.de
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
>



From B.Rowlingson at lancaster.ac.uk  Fri Dec  1 15:09:13 2006
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 01 Dec 2006 14:09:13 +0000
Subject: [R] C structures in R
In-Reply-To: <Pine.LNX.4.64.0612011316001.13593@gannet.stats.ox.ac.uk>
References: <4570220D.10806@lancaster.ac.uk>
	<Pine.LNX.4.64.0612011316001.13593@gannet.stats.ox.ac.uk>
Message-ID: <45703789.3090205@lancaster.ac.uk>

Prof Brian Ripley wrote:

> The short answer is that quite a bit of code, e.g pwilcox and RODBC, 
> does things like this.  You don't need to pass the pointer back to R, 
> but if you do external pointers are designed for this job.  

  [reads a bit more of 'Writing R Extensions'...]

  Right yes, this does look like the tool for the job. I'll try and come 
up with a minimal example that duplicates what I'm doing with raw and 
pointers, it might be a useful illustration in the documentation.

Barry



From massimodisasha at yahoo.it  Fri Dec  1 16:05:05 2006
From: massimodisasha at yahoo.it (massimodisasha)
Date: Fri, 1 Dec 2006 16:05:05 +0100
Subject: [R] memeory problem?!
Message-ID: <270A8B45-F201-4C87-8EE3-79C4615EA9CD@yahoo.it>


hi,
i'm trying to perform a clustering on a big dataframe the code is this:


print("load required R packages")

require(spgrass6)

require(cluster)

gmeta6 <- gmeta6()

print("read in our 7 raster files from GRASS")

x <- readFLOAT6sp(c 
("er","crosc","longc","slope","profc","minic","maxic"))

print("assemble a matrix of our terrain variables")

morph <- data.frame(cbind(x$er, x$crosc, x$longc, x$slope, x$profc, x 
$minic, x$maxic))

print("normailize slope by dividing my max(slope)")

morph <- data.frame(cbind(x$er, x$crosc, x$longc, x$slope/max(x 
$slope), x$profc, x$minic, x$maxic))

names(morph) <- c 
("er","crosc","longc","slope_n","profc","minic","maxic")

print("perform the clustering")

morph.clara <- clara(morph, k=5, stand=F)

x$morph_class <- morph.clara$clustering

print("send result back to GRASS")

rast.put6(x,"morph", zcol="morph_class")



during the step : ....perform the clustering
after a lot of time,
i've this error:




Errore in sprintf(fmt, ...) : La lunghezza della stringa eccede la  
dimensione del buffer di 8192
Inoltre: Warning messages:
1: perl = TRUE ?? implementato solo nei locale UTF-8
2: perl = TRUE ?? implementato solo nei locale UTF-8
3: perl = TRUE ?? implementato solo nei locale UTF-8
4: perl = TRUE ?? implementato solo nei locale UTF-8
5: perl = TRUE ?? implementato solo nei locale UTF-8
6: perl = TRUE ?? implementato solo nei locale UTF-8
7: perl = TRUE ?? implementato solo nei locale UTF-8
8: La stringa di caratteri verr?  probabilmente troncata
Esecuzione interrotta



if i try the same code on a subregion of my data, it works very fine!
but for a large region i've this error :-(

obviously i think that is a memory problem, right ?
(i'm working with a notebook PPC-1.33-512ram)
my data are  : 7 raster-map on a region of about 50X40 km at a  
resolution of 20m.
is there some wolkaround about the memory problems?

an other question is:
what is this :
Warning messages:
1: perl = TRUE ?? implementato solo nei locale UTF-8
2: perl = TRUE ?? implementato solo nei locale UTF-8
3: perl = TRUE ?? implementato solo nei locale UTF-8
4: perl = TRUE ?? implementato solo nei locale UTF-8
5: perl = TRUE ?? implementato solo nei locale UTF-8
6: perl = TRUE ?? implementato solo nei locale UTF-8
7: perl = TRUE ?? implementato solo nei locale UTF-8

is it about this line of the code :

morph.clara <- clara(morph, k=5, stand=F)
i have an F > false


thanks for any suggestion about,

Massimo



From EICKELMA at de.ibm.com  Fri Dec  1 16:22:00 2006
From: EICKELMA at de.ibm.com (Hans-Juergen Eickelmann)
Date: Fri, 1 Dec 2006 16:22:00 +0100
Subject: [R] group by
Message-ID: <OF1E1281AE.0FEBC093-ONC1257237.0045791E-C1257237.005468E6@de.ibm.com>


Dear R-community,


I started using R  to control yield and output from different factories by
production week. A typical example is below.

Location    Week  ShippedWafer      SortedWafer UnsortedWafer
WaferYield  GoodDie
A           47    9           4           5           0.476       -12
B           40    5           5           0           -0.3262           -9
B           48    2           1           1           5.092       18


This output was generated from the following sample data. The complete list
can have more than 5K rows

TransactionWeek   Shipdate    Partnumber  Testside    Lot         Wafer1
      Wafer2            Yieldnorm   Chipnorm
47                11/20/2006  SWN3        A           12WAC00
3LU105SOG6  3LU105SOG6  17.231            60
47                11/20/2006  SWN3        A           12WAC00
3LU108SOE6  NA          NA          NA
40                10/3/2006   WN30        B           0ZQNC00
3XM063SOA1  3XM063SOA1  3.146       -12
40                10/3/2006   WN30        B           0ZQNC00
3XM072SOA3  3XM072SOA3  9.536       29

I'm a newbee so I'm doing this step by step. 1st Site A,  than siteB and
combine this with rbind to C<-rbind(A,B);
This code works however finally I would like to break up the data even more
and split it to Site, Week, Partnumber and Lot and here I'm lost.

Is there a 'grouping by' function in R which allows this operation much
easier without 'hardwiring' the parameter like I did it?


Code siteA
Weekmin <- min(ship$TransactionWeek);
Weekmax <- max(ship$TransactionWeek);
Week <-Weekmin -1;

repeat{
Week <- Week +1;
ship1  <- subset(ship, ship$TransactionWeek == Week &ship$Testside %in%
c("A"));
ship2 <- subset(ship1,ship1$Yield != 0 );
ship3 <- subset(ship1,is.na(ship1$Yield));

Location <- "A";
ShippedWafer <- nrow(ship1);
SortedWafer <- nrow(ship1)-nrow(ship3);
UnsortedWafer <- nrow(ship3);
WaferYield <- mean(ship2$Yieldnorm, na.rm=TRUE);
GoodDie <- sum(ship1$Chipnorm, na.rm=TRUE);
assign(paste("week", Week, sep="."), data.frame(Location, Week,
ShippedWafer,
      SortedWafer, UnsortedWafer, WaferYield,GoodDie))
if (Week == Weekmin) next
line <- rbind(get(paste("week", Week-1, sep=".")),get(paste("week", Week,
sep=".")))
assign(paste("week", Week, sep="."), data.frame(line))

if (Week < Weekmax)next
if (Week == Weekmax) break
}
A <- data.frame(get(paste("week", Week, sep=".")));

Hans

Hans-J Eickelmann
ISC Technology Procurement Center Mainz, Germany
email : Eickelma at de.ibm.com
phone : +49-(0)6131-84-2516
mobile: +49-(0)170-632-5596



From spencer.graves at pdf.com  Fri Dec  1 17:00:30 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 01 Dec 2006 08:00:30 -0800
Subject: [R] lme function
In-Reply-To: <7513794.post@talk.nabble.com>
References: <7513794.post@talk.nabble.com>
Message-ID: <4570519E.60001@pdf.com>

      RSiteSearch("lme spatial correlation", "functions") produced 10 
hits for me just now.  The sixth title on that list was "spatial 
correlation structure" 
(http://finzi.psych.upenn.edu/R/library/nlme/html/corSpher.html).  This 
is the help page for the "corSpher" function.  The Examples section 
there includes references to selected pages in Pinheiro and Bates (2000) 
Mixed-Effects Models in S and S-Plus (Springer), which  for me is 
essential documentation for 'lme' and is the best book I know on 
mixed-effects models generally.  The value of that book is greatly 
enhanced by the availability of script files "ch01.R", "ch02.R", ..., 
"ch06.R", "ch08.R" (in the "~R\library\nlme\scripts" subdirectory of 
your R installation directory).  These contain R code to reproduce all 
the data analyses in the book.  There are a very few cases where the 
syntax is different between R and that documented in the book [e.g., x^2 
must be I(x^2)].  Before I found the script files, I couldn't understand 
why I got substantially different results from the book when just typing 
the commands into R. 

       Hope this helps. 
      Spencer Graves

Mark Wilson wrote:
> Hello.
>
> As advised by Mick Crawley in his book on S+, I'm trying to use the lme
> function to examine a linear relationship between two variables measured at
> 60 locations in 12 sites, while taking account of any spatial
> autocorrelation (i.e. similarity in variation between the two variables that
> is due to site). I am using the function as follows:
>
> model<-lme(yvariable~xvariable,random=~xvariable|site)
>
> If you know your way around this function, I would be very grateful if you
> could confirm that this approach is a valid one, or point out why it isn't.
> I'd also be very keen to hear any suggestions regarding alternative ways to
> address the spatial autocorrelation in my data (I'm hoping to arrive at a
> slightly more elegant solution than simply taking site averages for each of
> the two variables and running a correlation using these mean values).
>
> Thanks,
>
> Mark
>



From msubianto at gmail.com  Fri Dec  1 18:02:02 2006
From: msubianto at gmail.com (Muhammad Subianto)
Date: Fri, 01 Dec 2006 18:02:02 +0100
Subject: [R] Make many barplot into one plot
Message-ID: <4570600A.3040506@gmail.com>

Dear all,
## I have 4 tables like this:

satu  <- array(c(5,15,20,68,29,54,84,119), dim=c(2,4),
               dimnames=list(c("Negative", "Positive"), c("Black", 
"Brown", "Red", "Blond")))
dua   <- array(c(50,105,30,8,29,25,84,9), dim=c(2,4),
               dimnames=list(c("Negative", "Positive"), c("Black", 
"Brown", "Red", "Blond")))
tiga  <- array(c(9,16,26,68,12,4,84,12), dim=c(2,4),
               dimnames=list(c("Negative", "Positive"), c("Black", 
"Brown", "Red", "Blond")))
empat <- array(c(25,13,50,78,19,34,84,101), dim=c(2,4),
               dimnames=list(c("Negative", "Positive"), c("Black", 
"Brown", "Red", "Blond")))

## with barplot I can make a plot for each table:

barplot(satu, beside=TRUE, legend.text=rownames(satu),
        ylim = c(0, max(colSums(satu)) * 1.2))
x11()
barplot(dua, beside=TRUE, legend.text=rownames(dua),
        ylim = c(0, max(colSums(dua)) * 1.2))
x11()
barplot(tiga, beside=TRUE, legend.text=rownames(tiga),
        ylim = c(0, max(colSums(tiga)) * 1.2))
x11()
barplot(empat, beside=TRUE, legend.text=rownames(empat),
        ylim = c(0, max(colSums(empat)) * 1.2))

## I can make all barplot above into one plot with

x11(width=11,height=8)
## Make a plot with 2 rows and 2 columns
oldpar <- par(mfrow=c(2,2),
   barplot(above)
par(oldpar)

## Are there any functions to make all barplot above into one plot?
## I would like to produce barplot like:

|   |                               |   |
|   |   |   |   |   |   |   |   |   |   |   |   |   |
|pos|neg|pos|neg|pos|neg|pos|neg|   |pos|neg|pos|neg| ...
|   |   |   |   |   |   |   |   |   |   |   |   |   |
---------------------------------   --------------------
  satu     dua     tiga   empat        satu    dua ...
              black                         blond

I would be grateful if anybody could help me.
Thank you very much.

Muhammad Subianto



From Greg.Snow at intermountainmail.org  Fri Dec  1 18:44:20 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 1 Dec 2006 10:44:20 -0700
Subject: [R] simple parallel computing on single multicore machine
Message-ID: <07E228A5BE53C24CAD490193A7381BBB6F26C2@LP-EXCHVS07.CO.IHC.COM>

Look at the nws package, I have had success using it to parallelize
simulations using a couple of computers that were not being used at the
time.  I don't have a multicore machine, but the examples in the package
make it look like using it for multicore would be even easier.

This is on windows 2000 machines with cygwin installed.

Hope this helps, 


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Millo Giovanni
Sent: Friday, December 01, 2006 5:24 AM
To: r-help at stat.math.ethz.ch
Subject: [R] simple parallel computing on single multicore machine

Dear List,

the advent of multicore machines in the consumer segment makes me wonder
whether it would, at least in principle, be possible to divide a
computational task into more slave R processes running on the different
cores of the same processor, more or less in the way package SNOW would
do on a cluster. I am thinking of simple 'embarassingly parallel'
problems, just like inverting 1000 matrices, estimating 1000 models or
the like.

I have seen some talk here on making R multi-threaded and the like, but
this is much simpler. I am just a curious useR, so don't bother if you
don't have time, but maybe you can point me at some resource, or just
say "this is nonsense"...

Cheers
Giovanni

Giovanni Millo
Research Dept.,
Assicurazioni Generali SpA
Via Machiavelli 4,
34131 Trieste (Italy)
tel. +39 040 671184
fax  +39 040 671160
 
Ai sensi del D.Lgs. 196/2003 si precisa che le informazioni
...{{dropped}}

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From marc_schwartz at comcast.net  Fri Dec  1 19:00:27 2006
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 01 Dec 2006 12:00:27 -0600
Subject: [R] Make many barplot into one plot
In-Reply-To: <4570600A.3040506@gmail.com>
References: <4570600A.3040506@gmail.com>
Message-ID: <1164996027.4552.10.camel@localhost.localdomain>

On Fri, 2006-12-01 at 18:02 +0100, Muhammad Subianto wrote:
> Dear all,
> ## I have 4 tables like this:
> 
> satu  <- array(c(5,15,20,68,29,54,84,119), dim=c(2,4),
>                dimnames=list(c("Negative", "Positive"), c("Black", 
> "Brown", "Red", "Blond")))
> dua   <- array(c(50,105,30,8,29,25,84,9), dim=c(2,4),
>                dimnames=list(c("Negative", "Positive"), c("Black", 
> "Brown", "Red", "Blond")))
> tiga  <- array(c(9,16,26,68,12,4,84,12), dim=c(2,4),
>                dimnames=list(c("Negative", "Positive"), c("Black", 
> "Brown", "Red", "Blond")))
> empat <- array(c(25,13,50,78,19,34,84,101), dim=c(2,4),
>                dimnames=list(c("Negative", "Positive"), c("Black", 
> "Brown", "Red", "Blond")))
> 
> ## with barplot I can make a plot for each table:
> 
> barplot(satu, beside=TRUE, legend.text=rownames(satu),
>         ylim = c(0, max(colSums(satu)) * 1.2))
> x11()
> barplot(dua, beside=TRUE, legend.text=rownames(dua),
>         ylim = c(0, max(colSums(dua)) * 1.2))
> x11()
> barplot(tiga, beside=TRUE, legend.text=rownames(tiga),
>         ylim = c(0, max(colSums(tiga)) * 1.2))
> x11()
> barplot(empat, beside=TRUE, legend.text=rownames(empat),
>         ylim = c(0, max(colSums(empat)) * 1.2))
> 
> ## I can make all barplot above into one plot with
> 
> x11(width=11,height=8)
> ## Make a plot with 2 rows and 2 columns
> oldpar <- par(mfrow=c(2,2),
>    barplot(above)
> par(oldpar)
> 
> ## Are there any functions to make all barplot above into one plot?
> ## I would like to produce barplot like:
> 
> |   |                               |   |
> |   |   |   |   |   |   |   |   |   |   |   |   |   |
> |pos|neg|pos|neg|pos|neg|pos|neg|   |pos|neg|pos|neg| ...
> |   |   |   |   |   |   |   |   |   |   |   |   |   |
> ---------------------------------   --------------------
>   satu     dua     tiga   empat        satu    dua ...
>               black                         blond
> 
> I would be grateful if anybody could help me.
> Thank you very much.

I would encourage you to look at the barchart() function in the lattice
package, which in many ways is better suited to doing multi-dimensional
plots.

That being said:

# rbind() the tables together
TAB <- rbind(satu, dua, tiga, empat)

# Do the barplot and save the bar midpoints
mp <- barplot(TAB, beside = TRUE,
              axisnames = FALSE)

# Add the individual bar labels
mtext(1, at = mp, text = c("N", "P"),
      line = 0, cex = 0.5)

# Get the midpoints of each sequential pair of bars
# within each of the four groups
at <- t(sapply(seq(1, nrow(TAB), by = 2),
               function(x) colMeans(mp[c(x, x+1), ])))

# Add the group labels for each pair
mtext(1, at = at,
      text = rep(c("satu", "dua", "tiga", "empat"), 4),
      line = 1, cex = 0.75)

# Add the color labels for each group
mtext(1, at = colMeans(mp),
      text = c("Black", "Brown", "Red", "Blond"),
      line = 2)


Take a look at ?barplot and note that the function returns the bar
midpoints, which in this case is a matrix:

> mp
     [,1] [,2] [,3] [,4]
[1,]  1.5 10.5 19.5 28.5
[2,]  2.5 11.5 20.5 29.5
[3,]  3.5 12.5 21.5 30.5
[4,]  4.5 13.5 22.5 31.5
[5,]  5.5 14.5 23.5 32.5
[6,]  6.5 15.5 24.5 33.5
[7,]  7.5 16.5 25.5 34.5
[8,]  8.5 17.5 26.5 35.5


Then look at ?mtext for the labelling.

HTH,

Marc Schwartz



From alex at transitive.com  Fri Dec  1 19:06:40 2006
From: alex at transitive.com (Alex Brown)
Date: Fri, 1 Dec 2006 18:06:40 +0000
Subject: [R] group by
In-Reply-To: <OF1E1281AE.0FEBC093-ONC1257237.0045791E-C1257237.005468E6@de.ibm.com>
References: <OF1E1281AE.0FEBC093-ONC1257237.0045791E-C1257237.005468E6@de.ibm.com>
Message-ID: <161B5AC8-FCDF-4876-89FA-69562012F119@transitive.com>

Hi Hans,

The short answer is yes.  I suspect you need to look at the 'by',  
'tapply' or 'aggregate' functions, depending upon what your data type  
is, exactly.

In general, it's best to come up with a really simple example which  
illustrates the part you don't know how to do.  If you can do that,  
someone will be able to come up with a simple solution.

-Alex Brown

On 1 Dec 2006, at 15:22, Hans-Juergen Eickelmann wrote:

>
> Dear R-community,
>
>
> I started using R  to control yield and output from different  
> factories by
> production week. A typical example is below.
>
> Location    Week  ShippedWafer      SortedWafer UnsortedWafer
> WaferYield  GoodDie
> A           47    9           4           5           0.476       -12
> B           40    5           5           0            
> -0.3262           -9
> B           48    2           1           1           5.092       18
>
>
> This output was generated from the following sample data. The  
> complete list
> can have more than 5K rows
>
> TransactionWeek   Shipdate    Partnumber  Testside    Lot          
> Wafer1
>       Wafer2            Yieldnorm   Chipnorm
> 47                11/20/2006  SWN3        A           12WAC00
> 3LU105SOG6  3LU105SOG6  17.231            60
> 47                11/20/2006  SWN3        A           12WAC00
> 3LU108SOE6  NA          NA          NA
> 40                10/3/2006   WN30        B           0ZQNC00
> 3XM063SOA1  3XM063SOA1  3.146       -12
> 40                10/3/2006   WN30        B           0ZQNC00
> 3XM072SOA3  3XM072SOA3  9.536       29
>
> I'm a newbee so I'm doing this step by step. 1st Site A,  than  
> siteB and
> combine this with rbind to C<-rbind(A,B);
> This code works however finally I would like to break up the data  
> even more
> and split it to Site, Week, Partnumber and Lot and here I'm lost.
>
> Is there a 'grouping by' function in R which allows this operation  
> much
> easier without 'hardwiring' the parameter like I did it?
>
>
> Code siteA
> Weekmin <- min(ship$TransactionWeek);
> Weekmax <- max(ship$TransactionWeek);
> Week <-Weekmin -1;
>
> repeat{
> Week <- Week +1;
> ship1  <- subset(ship, ship$TransactionWeek == Week &ship$Testside % 
> in%
> c("A"));
> ship2 <- subset(ship1,ship1$Yield != 0 );
> ship3 <- subset(ship1,is.na(ship1$Yield));
>
> Location <- "A";
> ShippedWafer <- nrow(ship1);
> SortedWafer <- nrow(ship1)-nrow(ship3);
> UnsortedWafer <- nrow(ship3);
> WaferYield <- mean(ship2$Yieldnorm, na.rm=TRUE);
> GoodDie <- sum(ship1$Chipnorm, na.rm=TRUE);
> assign(paste("week", Week, sep="."), data.frame(Location, Week,
> ShippedWafer,
>       SortedWafer, UnsortedWafer, WaferYield,GoodDie))
> if (Week == Weekmin) next
> line <- rbind(get(paste("week", Week-1, sep=".")),get(paste("week",  
> Week,
> sep=".")))
> assign(paste("week", Week, sep="."), data.frame(line))
>
> if (Week < Weekmax)next
> if (Week == Weekmax) break
> }
> A <- data.frame(get(paste("week", Week, sep=".")));
>
> Hans
>
> Hans-J Eickelmann
> ISC Technology Procurement Center Mainz, Germany
> email : Eickelma at de.ibm.com
> phone : +49-(0)6131-84-2516
> mobile: +49-(0)170-632-5596
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From gregory_warnes at URMC.Rochester.edu  Fri Dec  1 19:26:26 2006
From: gregory_warnes at URMC.Rochester.edu (Gregory R. Warnes)
Date: Fri, 01 Dec 2006 13:26:26 -0500
Subject: [R] analog to the matlab buffer function?
In-Reply-To: <1164938218.4738.15.camel@localhost.localdomain>
Message-ID: <C195DE02.C713%gregory_warnes@urmc.rochester.edu>

The gtools package also includes a function, 'running', which accomplishes
the desired task:

> library(gtools)
> t(running(1:5, width=3, fun=c))
    [,1] [,2] [,3]
1:3    1    2    3
2:4    2    3    4
3:5    3    4    5
>  


On 11/30/06 8:56 PM, "Marc Schwartz" <marc_schwartz at comcast.net> wrote:

> Here is another possibility, though I may be missing how the Matlab
> function handles incomplete rows generated at the end of the source
> vector. I have not fully tested this, so it may yet require some
> tweaking and certainly appropriate error checking.
> 
> I am presuming that the basic premise is that each row is of length
> 'window' and that it overlaps with the END of prior row by 'overlap'.
> 
> 
> Buffer <- function(x, window, overlap)
> {
>   Res <- NULL
> 
>   while (length(x) >= window)
>   {
>     Res <- c(Res, x[1:window])
>     x <- x[(1 + window - overlap):length(x)]
>   }
> 
>   matrix(Res, ncol = window, byrow = TRUE)
> }
> 
> 
>> Buffer(1:5, 3, 2)
>      [,1] [,2] [,3]
> [1,]    1    2    3
> [2,]    2    3    4
> [3,]    3    4    5
> 
>> Buffer(1:10, 4, 2)
>      [,1] [,2] [,3] [,4]
> [1,]    1    2    3    4
> [2,]    3    4    5    6
> [3,]    5    6    7    8
> [4,]    7    8    9   10
> 
> HTH,
> 
> Marc Schwartz
> 
> 
> On Thu, 2006-11-30 at 16:32 -0800, Charles C. Berry wrote:
>> See
>> 
>> ?embed
>> 
>> It is not quite the same, but this seems to be what you want - at least
>> for the example you give:
>> 
>>> t( embed(1:5,3) )[3:1,]
>>       [,1] [,2] [,3]
>> [1,]    1    2    3
>> [2,]    2    3    4
>> [3,]    3    4    5
>>> 
>> 
>> On Fri, 1 Dec 2006, Martin Ivanov wrote:
>> 
>>> Hello! I am new to R. I could not find a function analogous to matlab's
>>> function buffer, which is used in signal processing. Is there such a
>>> function in R? What I need to do is as follows. If I apply the function
>>> to the vector c(1:5) for example with a window length 3 and overlapping
>>> 2, I need to get a matrix like this:
>>> 1 2 3
>>> 2 3 4
>>> 3 4 5
>>> In matlab this is achieved with the function buffer. Is there ananalogous R
>>> function?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bklick1 at jhmi.edu  Fri Dec  1 19:41:56 2006
From: bklick1 at jhmi.edu (BRENDAN KLICK)
Date: Fri, 01 Dec 2006 13:41:56 -0500
Subject: [R] error in hetcor function (polycor package)?
Message-ID: <45703124020000F50000749C@cis27.hosts.jhmi.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061201/9c19386e/attachment-0004.pl 

From bklick at jhsph.edu  Fri Dec  1 19:49:00 2006
From: bklick at jhsph.edu (Klick, Brendan A.)
Date: Fri, 1 Dec 2006 13:49:00 -0500
Subject: [R] error in hetcor function (polycor package)?
Message-ID: <E619BDBD99B4F74D9DCA32F43BE92671031CDF49@XCH-VN02.sph.ad.jhsph.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061201/06b12375/attachment-0004.pl 

From bklick1 at jhmi.edu  Fri Dec  1 19:48:47 2006
From: bklick1 at jhmi.edu (BRENDAN KLICK)
Date: Fri, 01 Dec 2006 13:48:47 -0500
Subject: [R] error in hetcor function (polycor package)?
Message-ID: <457032BF020000F5000074A0@cis27.hosts.jhmi.edu>

I have been using the hetcor function in the polycor package.  When I
don't specify the use option everything runs smoothly.  However, when I
specify use either as "pairwise.complete.obs" or "complete.obs" I get
this error
 
Error in optim(rho, f, control = control, hessian = TRUE, method =
"BFGS") : 
        non-finite value supplied by optim

Is this an error in the hetcor function or am I missing something. 
Thanks for your help.
 
Brendan Klick
Johns Hopkins University School of Medicine



From maechler at stat.math.ethz.ch  Fri Dec  1 19:51:58 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 1 Dec 2006 19:51:58 +0100
Subject: [R] C structures in R
In-Reply-To: <45703789.3090205@lancaster.ac.uk>
References: <4570220D.10806@lancaster.ac.uk>
	<Pine.LNX.4.64.0612011316001.13593@gannet.stats.ox.ac.uk>
	<45703789.3090205@lancaster.ac.uk>
Message-ID: <17776.31182.338482.509477@stat.math.ethz.ch>

>>>>> "BaRow" == Barry Rowlingson <B.Rowlingson at lancaster.ac.uk>
>>>>>     on Fri, 01 Dec 2006 14:09:13 +0000 writes:

    BaRow> Prof Brian Ripley wrote:
    >> The short answer is that quite a bit of code, e.g pwilcox
    >> and RODBC, does things like this.  You don't need to pass
    >> the pointer back to R, but if you do external pointers
    >> are designed for this job.

    BaRow>   [reads a bit more of 'Writing R Extensions'...]

    BaRow>   Right yes, this does look like the tool for the
    BaRow> job. I'll try and come up with a minimal example that
    BaRow> duplicates what I'm doing with raw and pointers, it
    BaRow> might be a useful illustration in the documentation.

Yes, indeed.  I've wanted to have a small well documented
example on using external pointers more than once.

And if it would end up to be too large for "Writing R Ext..", 
you could put it at least on the R-Wiki.

Thanks in advance!
Martin



From bolker at zoo.ufl.edu  Fri Dec  1 20:10:00 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Fri, 1 Dec 2006 19:10:00 +0000 (UTC)
Subject: [R] 3D histogramm
References: <BAY19-F205425944715D1D87306E7E5DB0@phx.gbl>
Message-ID: <loom.20061201T191528-781@post.gmane.org>

C?line Henzelin <celine_appui <at> hotmail.com> writes:

> 
> thank you for your answer i checked my code and it now works
> 
> One more question... do you know how to have an 3D histogramm from a known 
> matrix of probabilities
> 
> Cline
> 

  An RSiteSearch on 3d histogram will get you some answers,
as well as a variety of strong opinions about why you shouldn't
plot your data as 3d histograms in the first place.

  Hints:

   demo(hist3d) in the rgl package
   example(scatterplot3d) in the scatterplot3d package
   
  Ben Bolker



From valderama at gmail.com  Fri Dec  1 20:48:11 2006
From: valderama at gmail.com (Laurent Valdes)
Date: Fri, 1 Dec 2006 20:48:11 +0100
Subject: [R] combining bclust and kkmeans
Message-ID: <3ef00e160612011148l54394727j5ac949c1f1875c4b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061201/1737e016/attachment-0004.pl 

From deepayan.sarkar at gmail.com  Fri Dec  1 21:09:14 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 1 Dec 2006 12:09:14 -0800
Subject: [R] Make many barplot into one plot
In-Reply-To: <1164996027.4552.10.camel@localhost.localdomain>
References: <4570600A.3040506@gmail.com>
	<1164996027.4552.10.camel@localhost.localdomain>
Message-ID: <eb555e660612011209v2dd050a8pd1f873a76fb97017@mail.gmail.com>

On 12/1/06, Marc Schwartz <marc_schwartz at comcast.net> wrote:
> On Fri, 2006-12-01 at 18:02 +0100, Muhammad Subianto wrote:
> > Dear all,
> > ## I have 4 tables like this:
> >
> > satu  <- array(c(5,15,20,68,29,54,84,119), dim=c(2,4),
> >                dimnames=list(c("Negative", "Positive"), c("Black",
> > "Brown", "Red", "Blond")))
> > dua   <- array(c(50,105,30,8,29,25,84,9), dim=c(2,4),
> >                dimnames=list(c("Negative", "Positive"), c("Black",
> > "Brown", "Red", "Blond")))
> > tiga  <- array(c(9,16,26,68,12,4,84,12), dim=c(2,4),
> >                dimnames=list(c("Negative", "Positive"), c("Black",
> > "Brown", "Red", "Blond")))
> > empat <- array(c(25,13,50,78,19,34,84,101), dim=c(2,4),
> >                dimnames=list(c("Negative", "Positive"), c("Black",
> > "Brown", "Red", "Blond")))
> >
> > ## with barplot I can make a plot for each table:
> >
> > barplot(satu, beside=TRUE, legend.text=rownames(satu),
> >         ylim = c(0, max(colSums(satu)) * 1.2))
> > x11()
> > barplot(dua, beside=TRUE, legend.text=rownames(dua),
> >         ylim = c(0, max(colSums(dua)) * 1.2))
> > x11()
> > barplot(tiga, beside=TRUE, legend.text=rownames(tiga),
> >         ylim = c(0, max(colSums(tiga)) * 1.2))
> > x11()
> > barplot(empat, beside=TRUE, legend.text=rownames(empat),
> >         ylim = c(0, max(colSums(empat)) * 1.2))
> >
> > ## I can make all barplot above into one plot with
> >
> > x11(width=11,height=8)
> > ## Make a plot with 2 rows and 2 columns
> > oldpar <- par(mfrow=c(2,2),
> >    barplot(above)
> > par(oldpar)
> >
> > ## Are there any functions to make all barplot above into one plot?
> > ## I would like to produce barplot like:
> >
> > |   |                               |   |
> > |   |   |   |   |   |   |   |   |   |   |   |   |   |
> > |pos|neg|pos|neg|pos|neg|pos|neg|   |pos|neg|pos|neg| ...
> > |   |   |   |   |   |   |   |   |   |   |   |   |   |
> > ---------------------------------   --------------------
> >   satu     dua     tiga   empat        satu    dua ...
> >               black                         blond
> >
> > I would be grateful if anybody could help me.
> > Thank you very much.
>
> I would encourage you to look at the barchart() function in the lattice
> package, which in many ways is better suited to doing multi-dimensional
> plots.
>
> That being said:
>
> [snipped]

And here is a lattice alternative:


dflist <- list()
for (nm in c("satu", "dua", "tiga", "empat"))
{
    dflist[[nm]] <- as.data.frame.table(get(nm))
}

cdf <- do.call(make.groups, dflist)

barchart(Freq ~ which | Var2, data = cdf,
         groups = Var1, stack = FALSE, origin = 0,
         layout = c(4, 1), auto.key = TRUE)

barchart(which ~ Freq | Var2, data = cdf,
         groups = Var1, stack = TRUE,
         auto.key = TRUE)


-Deepayan



From hassen62 at voila.fr  Fri Dec  1 22:07:13 2006
From: hassen62 at voila.fr (hassen62 at voila.fr)
Date: Fri,  1 Dec 2006 22:07:13 +0100 (CET)
Subject: [R] Demand of help
Message-ID: <6594602.1165007233342.JavaMail.www@wwinf4106>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061201/b37e9918/attachment-0004.pl 

From Roger.Bivand at nhh.no  Fri Dec  1 22:30:38 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 1 Dec 2006 22:30:38 +0100 (CET)
Subject: [R] Demand of help
In-Reply-To: <6594602.1165007233342.JavaMail.www@wwinf4106>
Message-ID: <Pine.LNX.4.44.0612012230180.13581-100000@reclus.nhh.no>

On Fri, 1 Dec 2006 hassen62 at voila.fr wrote:

> Hi, I'm a phd student of economics in Tunisia who is intersted now with
> the seasonal unit roots test of Canova and Hansen. So I've installed the
> package "uroot" in RGUI. I use R 2.4.0. The problem when I apply the
> function to my data, I've always a message from RConsole that it is
> impossible to find the function CH.test. Are there problems as for the
> use of this package? Please help me. Thank you in advance.

library(uroot) ?

> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From massimodisasha at yahoo.it  Fri Dec  1 23:04:16 2006
From: massimodisasha at yahoo.it (Massimo Di Stefano)
Date: Fri, 1 Dec 2006 23:04:16 +0100 (CET)
Subject: [R] memory problem
Message-ID: <323604.34642.qm@web55003.mail.re4.yahoo.com>

hi to all,
frustated for this error, to day i buy a 1 GB memory
slot for my laptop
now it have 1,28GB instead the old 512, but i've the
same error :-(
damn!damn!....how can i do?
repeat for a little area (about 20X20 km and res=20m)
it work fine!
have you any suggestion?
is ther a method for look if this error depend from my
ram or other....?
thanks foe any suggestion!
i need your help.
thanks.
Massimo


Il giorno 01/dic/06, alle ore 16:05, massimodisasha ha
scritto:
hi,
i'm trying to perform a clustering on a big dataframe
the code is this:


print("load required R packages")

require(spgrass6)

require(cluster)

gmeta6 <- gmeta6()

print("read in our 7 raster files from GRASS")

x <-
readFLOAT6sp(c("er","crosc","longc","slope","profc","minic","maxic"))

print("assemble a matrix of our terrain variables")

morph <- data.frame(cbind(x$er, x$crosc, x$longc,
x$slope, x$profc, x$minic, x$maxic))

print("normailize slope by dividing my max(slope)")

morph <- data.frame(cbind(x$er, x$crosc, x$longc,
x$slope/max(x$slope), x$profc, x$minic, x$maxic))

names(morph) <-
c("er","crosc","longc","slope_n","profc","minic","maxic")

print("perform the clustering")

morph.clara <- clara(morph, k=5, stand=F)

x$morph_class <- morph.clara$clustering

print("send result back to GRASS")

rast.put6(x,"morph", zcol="morph_class")



during the step : ....perform the clustering
after a lot of time,
i've this error:




Errore in sprintf(fmt, ...) : La lunghezza della
stringa eccede la dimensione del buffer di 8192
Inoltre: Warning messages:
1: perl = TRUE ?? implementato solo nei locale UTF-8
2: perl = TRUE ?? implementato solo nei locale UTF-8
3: perl = TRUE ?? implementato solo nei locale UTF-8
4: perl = TRUE ?? implementato solo nei locale UTF-8
5: perl = TRUE ?? implementato solo nei locale UTF-8
6: perl = TRUE ?? implementato solo nei locale UTF-8
7: perl = TRUE ?? implementato solo nei locale UTF-8
8: La stringa di caratteri verr?  probabilmente
troncata
Esecuzione interrotta



if i try the same code on a subregion of my data, it
works very fine!
but for a large region i've this error :-(

obviously i think that is a memory problem, right ?
(i'm working with a notebook PPC-1.33-512ram)
my data are  : 7 raster-map on a region of about 50X40
km at a resolution of 20m.
is there some wolkaround about the memory problems?

an other question is:
what is this :
Warning messages:
1: perl = TRUE ?? implementato solo nei locale UTF-8
2: perl = TRUE ?? implementato solo nei locale UTF-8
3: perl = TRUE ?? implementato solo nei locale UTF-8
4: perl = TRUE ?? implementato solo nei locale UTF-8
5: perl = TRUE ?? implementato solo nei locale UTF-8
6: perl = TRUE ?? implementato solo nei locale UTF-8
7: perl = TRUE ?? implementato solo nei locale UTF-8

is it about this line of the code :

morph.clara <- clara(morph, k=5, stand=F)
i have an F > false


thanks for any suggestion about,

Massimo



From p.murrell at auckland.ac.nz  Fri Dec  1 23:15:05 2006
From: p.murrell at auckland.ac.nz (p.murrell at auckland.ac.nz)
Date: Sat, 2 Dec 2006 11:15:05 +1300 (NZDT)
Subject: [R] R News, volume 6, issue 5 is now available
Message-ID: <50369.219.88.201.195.1165011305.squirrel@www.stat.auckland.ac.nz>

Hi

The December 2006 issue of R News is now available on CRAN under the
Documentation/Newsletter link.

Paul
(on behalf of the R News Editorial Board)
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/

_______________________________________________
R-announce at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce



From ripley at stats.ox.ac.uk  Fri Dec  1 23:29:05 2006
From: ripley at stats.ox.ac.uk (Brian Ripley)
Date: Fri, 1 Dec 2006 22:29:05 +0000 (GMT)
Subject: [R] AIC for heckit
In-Reply-To: <d4588dec0612010525s6d788716of30a1066eb50f4c2@mail.gmail.com>
References: <d4588dec0612010525s6d788716of30a1066eb50f4c2@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0612012225140.3353@auk.stats>

As I read it hectik() in micEcon does not fit by maximum likelihood, so 
AIC is undefined.  (People seem to have a magic faith in AIC as a 
universal panacea, but it does come with a long list of conditions for 
applicability.)

heckit's $probit is apparently only part of the fitting, but for any model 
fit we would always recommend the extractor functions (e.g. AIC()) over 
messing with components of the fit.

On Fri, 1 Dec 2006, Jay Emerson wrote:

>> I have used the heckit function in micEcon.
>> ...
>> How can I then get the AIC for this model?
>
> It appears that the heckit $probit object is of class 'glm' and so, for
> example:
>
> main.result <- heckit(whateveryouaredoing)        # Do your heckit()...
> probit.result <- main.result$probit         # The glm object produced by
> heckit()
> probit.aic <- probit.result$aic                 # The AIC, see ?glm
>
> should have what you need, ready to go.  I used these tedious names and
> three lines of code just to be clear about what is what (I wouldn't really
> do it this way).  !)
>
> Jay
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From c.n.lawrence at gmail.com  Fri Dec  1 23:34:24 2006
From: c.n.lawrence at gmail.com (Christopher N. Lawrence)
Date: Fri, 1 Dec 2006 16:34:24 -0600
Subject: [R] Confusing difference in S4 summary method dispatch within an S3
	summary
Message-ID: <e2e0e3d30612011434v19eaf644mb77db255ab5c672b@mail.gmail.com>

I'm trying to track down a problem I'm having in the Zelig package and
have stumbled across a very odd difference in the method dispatch for
a derived S4 class.

Specifically, I have an object of class ZeligS4vglm, which is a
subclass of vglm and vlm respectively (these are from the VGAM
package).

summary() at the command line prompt of this object calls
summary.vglm, which is what I expect to happen.

However, when summary() is called on this object from within another
summary() (summary.MI in Zelig... MI is an S3 class wrapping a number
of ZeligS4vglm objects in this case), it appears to be using the
generic summary() method and ignoring the summary methods defined for
the object:

Browse[1]> summary(object[[1]])
     Length Class       Mode
[1,] 1      ZeligS4vglm S4

I assume this has something to do with protecting the programmer from
infinite recursion into summary() - i.e. so summary.object <-
function(x) { summary(x) } doesn't blow up the stack - but is there a
workaround?


Chris
-- 
Christopher N. Lawrence <clawren6 at slu.edu>
Assistant Professor of Political Science (non-tenure-track)
Saint Louis University
109 Fitzgerald Hall
3500 Lindell Boulevard
St. Louis, Missouri 63103-1021

Website: http://www.cnlawrence.com/



From darked90 at yahoo.com  Fri Dec  1 23:52:25 2006
From: darked90 at yahoo.com (Darek Kedra)
Date: Fri, 1 Dec 2006 14:52:25 -0800 (PST)
Subject: [R] newbie: new_data_frame <- selected set of rows
Message-ID: <26270.41152.qm@web90413.mail.mud.yahoo.com>

Two missing things:

>distances
 [1] 13 14 10 11  2  4  6  1  3  9  8 12  7  5

#numbers correspond to rows in my_dataframe

> my_dataframe
                      V2         V3         V4        
V5         V6
ENSP00000354687 35660.45 0.04794521 0.05479452
0.06849315 0.07534247
ENSP00000355046 38942.77 0.02967359 0.04451039
0.04451039 0.06824926
ENSP00000354499 57041.21 0.04700855 0.08760684
0.11965812 0.06196581

ENSP00000354687 etc are rownames. 

I am trying to get top five row names with smallest
distances from a given vector as calculated by
distancevector from hopach.



Darek Kedra





 
____________________________________________________________________________________
Cheap talk?



From jfox at mcmaster.ca  Sat Dec  2 00:19:56 2006
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 1 Dec 2006 18:19:56 -0500
Subject: [R] error in hetcor function (polycor package)?
In-Reply-To: <45703124020000F50000749C@cis27.hosts.jhmi.edu>
Message-ID: <20061201231953.RTZB17401.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Brendan,

That's curious, because the use argument to hetcor() works fine for me (see
below). Is it possible that you tried to use this argument without
specifying a data frame as the first argument to hetcor? If so, please see
?hetcor. If not, it would help to have an example.

I hope this helps,
 John

------------ snip -------------

> set.seed(12345) # adapting the example in ?hetcor
> R <- matrix(0, 4, 4)
> R[upper.tri(R)] <- runif(6)
> diag(R) <- 1
> R <- cov2cor(t(R) %*% R)
> round(R, 4)  # population correlations
       [,1]   [,2]   [,3]   [,4]
[1,] 1.0000 0.5848 0.5718 0.6233
[2,] 0.5848 1.0000 0.7374 0.6249
[3,] 0.5718 0.7374 1.0000 0.5923
[4,] 0.6233 0.6249 0.5923 1.0000
> data <- rmvnorm(1000, rep(0, 4), R)
> round(cor(data), 4)   # sample correlations
       [,1]   [,2]   [,3]   [,4]
[1,] 1.0000 0.5933 0.5659 0.6088
[2,] 0.5933 1.0000 0.7334 0.6230
[3,] 0.5659 0.7334 1.0000 0.5802
[4,] 0.6088 0.6230 0.5802 1.0000
> x1 <- data[,1]
> x2 <- data[,2]
> y1 <- cut(data[,3], c(-Inf, .75, Inf))
> y2 <- cut(data[,4], c(-Inf, -1, .5, 1.5, Inf))
> data <- data.frame(x1, x2, y1, y2)
> data[1,1] <- NA
> hetcor(data) 

Two-Step Estimates

Correlations/Type of Correlation:
       x1      x2         y1         y2
x1      1 Pearson Polyserial Polyserial
x2 0.5932       1 Polyserial Polyserial
y1 0.5952  0.7409          1 Polychoric
y2  0.624  0.6316     0.5708          1

Standard Errors:
        x1      x2     y1
x1                       
x2 0.02053               
y1 0.03092 0.02296       
y2 0.02027 0.01995 0.0374

n = 999 

P-values for Tests of Bivariate Normality:
       x1     x2      y1
x1                      
x2 0.4782               
y1 0.4023 0.8871        
y2 0.1166 0.5077 0.05526

> hetcor(data, use = "complete.obs")

Two-Step Estimates

Correlations/Type of Correlation:
       x1      x2         y1         y2
x1      1 Pearson Polyserial Polyserial
x2 0.5932       1 Polyserial Polyserial
y1 0.5952  0.7409          1 Polychoric
y2  0.624  0.6316     0.5708          1

Standard Errors:
        x1      x2     y1
x1                       
x2 0.02053               
y1 0.03092 0.02296       
y2 0.02027 0.01995 0.0374

n = 999 

P-values for Tests of Bivariate Normality:
       x1     x2      y1
x1                      
x2 0.4782               
y1 0.4023 0.8871        
y2 0.1166 0.5077 0.05526

> hetcor(data, use = "pairwise.complete.obs")

Two-Step Estimates

Correlations/Type of Correlation:
       x1      x2         y1         y2
x1      1 Pearson Polyserial Polyserial
x2 0.5932       1 Polyserial Polyserial
y1 0.5952  0.7409          1 Polychoric
y2  0.624  0.6317     0.5711          1

Standard Errors/Numbers of Observations:
        x1      x2      y1   y2
x1     999     999     999  999
x2 0.02053    1000    1000 1000
y1 0.03092 0.02295    1000 1000
y2 0.02027 0.01994 0.03738 1000

P-values for Tests of Bivariate Normality:
       x1     x2      y1
x1                      
x2 0.4952               
y1 0.4023  0.878        
y2 0.1166 0.5255 0.05615

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of BRENDAN KLICK
> Sent: Friday, December 01, 2006 1:42 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] error in hetcor function (polycor package)?
> 
> I have been using the hetcor function in the polycor package. 
>  When I don't specify the use option everything runs 
> smoothly.  However, when I specify use either as 
> "pairwise.complete.obs" or "complete.obs" I get this error
>  
> Error in optim(rho, f, control = control, hessian = TRUE, method =
> "BFGS") : 
>         non-finite value supplied by optim
> 
> Is this an error in the hetcor function or am I missing something. 
> Thanks for your help.
>  
> Brendan Klick
> Johns Hopkins University School of Medicine bklick1 at jhmi.edu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From dmck at u.washington.edu  Sat Dec  2 00:34:22 2006
From: dmck at u.washington.edu (Don McKenzie)
Date: Fri, 01 Dec 2006 15:34:22 -0800
Subject: [R]  package installation fails only for "sp"
Message-ID: <4570BBFE.1050303@u.washington.edu>

I have escaped Splus for Windows (mostly) and have started using
R (v 2.3.1 on i686 redhat).  Installing packages has been routine except
for "sp" (classes and methods for spatial data).  I get the following error
message

 > install.packages("sp")
Warning in download.packages(unique(pkgs),destdir=tmpd,available=available,:
            no package 'sp'  at the repositories
 
Clearly I am missing something (probably obvious), but can someone 
enlighten me
as to why the behavior of this package installation is different from 
others?  sp is
listed under "Contributed packages" at the R-project URL.  Thank you
for your time.

-- 
___________________________________

Don McKenzie, Research Ecologist
Pacific Wildland Fire Sciences Lab
USDA Forest Service
400 N 34th St. #201
Seattle, WA 98103, USA
(206) 732-7824
donaldmckenzie at fs.fed.us

Affiliate Assistant Professor
College of Forest Resources 
CSES Climate Impacts Group
University of Washington
dmck at u.washington.edu



From bklick1 at jhmi.edu  Sat Dec  2 00:37:09 2006
From: bklick1 at jhmi.edu (BRENDAN KLICK)
Date: Fri, 01 Dec 2006 18:37:09 -0500
Subject: [R] error in hetcor function (polycor package)?
In-Reply-To: <20061201231953.RTZB17401.tomts10-srv.bellnexxia.net@JohnDesktop8300>
References: <45703124020000F50000749C@cis27.hosts.jhmi.edu>
	<20061201231953.RTZB17401.tomts10-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <45707655020000F5000074E7@cis27.hosts.jhmi.edu>

Yes, that's it.

 hetcor(x1, x2, y1, y2) 
 hetcor(data, use="pairwise.complete.obs")

works but

 hetcor(x1, x2, y1, y2, use="complete.obs") 
 hetcor(x1, x2, y1, y2, use="pairwise.complete.obs") 

do not.  Thanks very much!

Brendan

>>> John Fox <jfox at mcmaster.ca> 12/01/06 6:19 PM >>>
Dear Brendan,

That's curious, because the use argument to hetcor() works fine for me
(see
below). Is it possible that you tried to use this argument without
specifying a data frame as the first argument to hetcor? If so, please
see
?hetcor. If not, it would help to have an example.

I hope this helps,
 John

------------ snip -------------

> set.seed(12345) # adapting the example in ?hetcor
> R <- matrix(0, 4, 4)
> R[upper.tri(R)] <- runif(6)
> diag(R) <- 1
> R <- cov2cor(t(R) %*% R)
> round(R, 4)  # population correlations
       [,1]   [,2]   [,3]   [,4]
[1,] 1.0000 0.5848 0.5718 0.6233
[2,] 0.5848 1.0000 0.7374 0.6249
[3,] 0.5718 0.7374 1.0000 0.5923
[4,] 0.6233 0.6249 0.5923 1.0000
> data <- rmvnorm(1000, rep(0, 4), R)
> round(cor(data), 4)   # sample correlations
       [,1]   [,2]   [,3]   [,4]
[1,] 1.0000 0.5933 0.5659 0.6088
[2,] 0.5933 1.0000 0.7334 0.6230
[3,] 0.5659 0.7334 1.0000 0.5802
[4,] 0.6088 0.6230 0.5802 1.0000
> x1 <- data[,1]
> x2 <- data[,2]
> y1 <- cut(data[,3], c(-Inf, .75, Inf))
> y2 <- cut(data[,4], c(-Inf, -1, .5, 1.5, Inf))
> data <- data.frame(x1, x2, y1, y2)
> data[1,1] <- NA
> hetcor(data) 

Two-Step Estimates

Correlations/Type of Correlation:
       x1      x2         y1         y2
x1      1 Pearson Polyserial Polyserial
x2 0.5932       1 Polyserial Polyserial
y1 0.5952  0.7409          1 Polychoric
y2  0.624  0.6316     0.5708          1

Standard Errors:
        x1      x2     y1
x1                       
x2 0.02053               
y1 0.03092 0.02296       
y2 0.02027 0.01995 0.0374

n = 999 

P-values for Tests of Bivariate Normality:
       x1     x2      y1
x1                      
x2 0.4782               
y1 0.4023 0.8871        
y2 0.1166 0.5077 0.05526

> hetcor(data, use = "complete.obs")

Two-Step Estimates

Correlations/Type of Correlation:
       x1      x2         y1         y2
x1      1 Pearson Polyserial Polyserial
x2 0.5932       1 Polyserial Polyserial
y1 0.5952  0.7409          1 Polychoric
y2  0.624  0.6316     0.5708          1

Standard Errors:
        x1      x2     y1
x1                       
x2 0.02053               
y1 0.03092 0.02296       
y2 0.02027 0.01995 0.0374

n = 999 

P-values for Tests of Bivariate Normality:
       x1     x2      y1
x1                      
x2 0.4782               
y1 0.4023 0.8871        
y2 0.1166 0.5077 0.05526

> hetcor(data, use = "pairwise.complete.obs")

Two-Step Estimates

Correlations/Type of Correlation:
       x1      x2         y1         y2
x1      1 Pearson Polyserial Polyserial
x2 0.5932       1 Polyserial Polyserial
y1 0.5952  0.7409          1 Polychoric
y2  0.624  0.6317     0.5711          1

Standard Errors/Numbers of Observations:
        x1      x2      y1   y2
x1     999     999     999  999
x2 0.02053    1000    1000 1000
y1 0.03092 0.02295    1000 1000
y2 0.02027 0.01994 0.03738 1000

P-values for Tests of Bivariate Normality:
       x1     x2      y1
x1                      
x2 0.4952               
y1 0.4023  0.878        
y2 0.1166 0.5255 0.05615

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of BRENDAN KLICK
> Sent: Friday, December 01, 2006 1:42 PM
> To: r-help at stat.math.ethz.ch 
> Subject: [R] error in hetcor function (polycor package)?
> 
> I have been using the hetcor function in the polycor package. 
>  When I don't specify the use option everything runs 
> smoothly.  However, when I specify use either as 
> "pairwise.complete.obs" or "complete.obs" I get this error
>  
> Error in optim(rho, f, control = control, hessian = TRUE, method =
> "BFGS") : 
>         non-finite value supplied by optim
> 
> Is this an error in the hetcor function or am I missing something. 
> Thanks for your help.
>  
> Brendan Klick
> Johns Hopkins University School of Medicine bklick1 at jhmi.edu 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.



From DePrengM at botanicgardens.org  Sat Dec  2 00:56:24 2006
From: DePrengM at botanicgardens.org (Michelle DePrenger-Levin)
Date: Fri, 01 Dec 2006 16:56:24 -0700
Subject: [R] cloud() question
Message-ID: <s5705ec6.059@DBG>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061201/6c7e50a8/attachment-0004.pl 

From deepayan.sarkar at gmail.com  Sat Dec  2 00:57:10 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 1 Dec 2006 15:57:10 -0800
Subject: [R] cloud() question
In-Reply-To: <s5705ec6.059@DBG>
References: <s5705ec6.059@DBG>
Message-ID: <eb555e660612011557u589738e2ne9a1a42aa02f98ea@mail.gmail.com>

On 12/1/06, Michelle DePrenger-Levin <DePrengM at botanicgardens.org> wrote:
> Hello,
>
> I am trying to plot lines in 3 dimensions from a multiple linear model
> to illustrate the interaction of two of the explanatory variables. I'm
> trying to use the cloud function (though I'm open to a different
> function if an easier one exists). I keep getting the error message:
>
> Error in cloud(lmPeHa061201, data = PeHa061201, cex = 0.8, main =
> "Table 99: PeHa",  :
>         no applicable method for "cloud"
>
> I have tried to make my command look just like the examples but am at a
> loss as to why I don't have an "applicable method". I enter:
>
> lmPeHa061201=lm(sqrtplants~sqrtPlantsPrev+Site+NumFruitedPrev+HerbPrevious+RainfallJulyJuneprev+RainfallJulyJune+
> (Site*HerbPrevious)+(HerbPrevious*NumFruitedPrev)+(RainfallJulyJune*RainfallJulyJuneprev),
> data=PeHa061201)
>
> par.set <-
>     list(axis.line = list(col = "transparent"), clip = list(panel =
> FALSE))
>
> print(cloud(lmPeHa061201, data=PeHa061201, cex = .8,
>  screen = list(z=20, x=-70, y=0),
>  par.settings = par.set,
>  distance = .4, zoom = .6))

What example does this look like exactly? Normally, the first argument
of cloud has to be a formula that looks like 'z ~ x * y'. In your
call, it is the result of a call to lm, which among other things, is
not a formula.

It's difficult to suggest alternatives without a reproducible example.

> If I could get past this error, I'd like to add a line (with abline()
> ??) to show just one (and then potentially others on the same plot) of
> the interaction factors but I'm not sure if this will work either.

Probably not. Adding stuff to 3-d plots are harder than for 2-d plots.

-Deepayan



From p.dalgaard at biostat.ku.dk  Sat Dec  2 00:57:06 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 02 Dec 2006 00:57:06 +0100
Subject: [R] package installation fails only for "sp"
In-Reply-To: <4570BBFE.1050303@u.washington.edu>
References: <4570BBFE.1050303@u.washington.edu>
Message-ID: <4570C152.9060701@biostat.ku.dk>

Don McKenzie wrote:
> I have escaped Splus for Windows (mostly) and have started using
> R (v 2.3.1 on i686 redhat).  Installing packages has been routine except
> for "sp" (classes and methods for spatial data).  I get the following error
> message
>
>  > install.packages("sp")
> Warning in download.packages(unique(pkgs),destdir=tmpd,available=available,:
>             no package 'sp'  at the repositories
>  
> Clearly I am missing something (probably obvious), but can someone 
> enlighten me
> as to why the behavior of this package installation is different from 
> others?  sp is
> listed under "Contributed packages" at the R-project URL.  Thank you
> for your time.
>
>   
Try looking at the Depends: field....



From Mark.Bravington at csiro.au  Sat Dec  2 02:10:46 2006
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Sat, 2 Dec 2006 12:10:46 +1100
Subject: [R] fixup for debug package and R2.4.0
Message-ID: <D79013E40FEF254AAF0D72DFC94F27482307A0@extas4-hba.tas.csiro.au>

A number of users have spotted a terminal problem with the 'debug' package under R2.4.0, along the lines of 

> mtrace(x)
> x()
Error in attr(value, "row.names") <- rlabs :
 row names must be 'character' or 'integer', not 'double' 

This arose from a bug in 'rbind.data.frame' in R2.4.0 itself. The bug is fixed in R2.4.0 patched, so the best solution is to install the patched version. This is painless, at least for Windows, since a binary version of R-patched is available on CRAN (I hadn't realized this).

If for reason you desperately don't want to install R-patched, the following *ugly* bit of code can be run after loading the 'debug' library [so you could put this in your '.First' function]:

Thanks to all who reported the problem

Mark Bravington
mark.bravington at csiro.au

mvbutils:::assign.to.base( 'rbind.data.frame', function (..., deparse.level = 1) 
{
    match.names <- function(clabs, nmi) {
        if (all(clabs == nmi)) 
            NULL
        else if (length(nmi) == length(clabs) && all(nii <- match(nmi, 
            clabs, 0))) {
            m <- pmatch(nmi, clabs, 0)
            if (any(m == 0)) 
                stop("names do not match previous names")
            m
        }
        else stop("names do not match previous names:\n\t", paste(nmi[nii == 
            0], collapse = ", "))
    }
    Make.row.names <- function(nmi, ri, ni, nrow) {
        if (nchar(nmi) > 0) {
            if (ni == 0) 
                character(0)
            else if (ni > 1) 
                paste(nmi, ri, sep = ".")
            else nmi
        }
        else if (nrow > 0 && identical(ri, 1:ni)) 
            as.integer(seq.int(from = nrow + 1, length = ni))
        else ri
    }
    allargs <- list(...)
    allargs <- allargs[sapply(allargs, length) > 0]
    n <- length(allargs)
    if (n == 0) 
        return(structure(list(), class = "data.frame", row.names = integer()))
    nms <- names(allargs)
    if (is.null(nms)) 
        nms <- character(length(allargs))
    cl <- NULL
    perm <- rows <- rlabs <- vector("list", n)
    nrow <- 0
    value <- clabs <- NULL
    all.levs <- list()
    for (i in 1:n) {
        xi <- allargs[[i]]
        nmi <- nms[i]
        if (is.matrix(xi)) 
            allargs[[i]] <- xi <- as.data.frame(xi)
        if (inherits(xi, "data.frame")) {
            if (is.null(cl)) 
                cl <- oldClass(xi)
            ri <- attr(xi, "row.names")
            ni <- length(ri)
            if (is.null(clabs)) 
                clabs <- names(xi)
            else {
                pi <- match.names(clabs, names(xi))
                if (!is.null(pi)) 
                  perm[[i]] <- pi
            }
            rows[[i]] <- seq.int(from = nrow + 1, length = ni)
            rlabs[[i]] <- Make.row.names(nmi, ri, ni, nrow)
            nrow <- nrow + ni
            if (is.null(value)) {
                value <- unclass(xi)
                nvar <- length(value)
                all.levs <- vector("list", nvar)
                has.dim <- logical(nvar)
                facCol <- logical(nvar)
                ordCol <- logical(nvar)
                for (j in 1:nvar) {
                  xj <- value[[j]]
                  if (!is.null(levels(xj))) {
                    all.levs[[j]] <- levels(xj)
                    facCol[j] <- TRUE
                  }
                  else facCol[j] <- is.factor(xj)
                  ordCol[j] <- is.ordered(xj)
                  has.dim[j] <- length(dim(xj)) == 2
                }
            }
            else for (j in 1:nvar) {
                xij <- xi[[j]]
                if (is.null(pi) || is.na(jj <- pi[[j]])) 
                  jj <- j
                if (facCol[jj]) {
                  if (length(lij <- levels(xij)) > 0) {
                    all.levs[[jj]] <- unique(c(all.levs[[jj]], 
                      lij))
                    ordCol[jj] <- ordCol[jj] & is.ordered(xij)
                  }
                  else if (is.character(xij)) 
                    all.levs[[jj]] <- unique(c(all.levs[[jj]], 
                      xij))
                }
            }
        }
        else if (is.list(xi)) {
            ni <- range(sapply(xi, length))
            if (ni[1] == ni[2]) 
                ni <- ni[1]
            else stop("invalid list argument: all variables should have the same length")
            rows[[i]] <- ri <- as.integer(seq.int(from = nrow + 
                1, length = ni))
            nrow <- nrow + ni
            rlabs[[i]] <- Make.row.names(nmi, ri, ni, nrow)
            if (length(nmi <- names(xi)) > 0) {
                if (is.null(clabs)) 
                  clabs <- nmi
                else {
                  tmp <- match.names(clabs, nmi)
                  if (!is.null(tmp)) 
                    perm[[i]] <- tmp
                }
            }
        }
        else if (length(xi) > 0) {
            rows[[i]] <- nrow <- nrow + 1
            rlabs[[i]] <- if (nchar(nmi) > 0) 
                nmi
            else as.integer(nrow)
        }
    }
    nvar <- length(clabs)
    if (nvar == 0) 
        nvar <- max(sapply(allargs, length))
    if (nvar == 0) 
        return(structure(list(), class = "data.frame", row.names = integer()))
    pseq <- 1:nvar
    if (is.null(value)) {
        value <- list()
        value[pseq] <- list(logical(nrow))
    }
    names(value) <- clabs
    for (j in 1:nvar) if (length(lij <- all.levs[[j]]) > 0) 
        value[[j]] <- factor(as.vector(value[[j]]), lij, ordered = ordCol[j])
    if (any(has.dim)) {
        rmax <- max(unlist(rows))
        for (i in (1:nvar)[has.dim]) if (!inherits(xi <- value[[i]], 
            "data.frame")) {
            dn <- dimnames(xi)
            rn <- dn[[1]]
            if (length(rn) > 0) 
                length(rn) <- rmax
            pi <- dim(xi)[2]
            length(xi) <- rmax * pi
            value[[i]] <- array(xi, c(rmax, pi), list(rn, dn[[2]]))
        }
    }
    for (i in 1:n) {
        xi <- unclass(allargs[[i]])
        if (!is.list(xi)) 
            if (length(xi) != nvar) 
                xi <- rep(xi, length.out = nvar)
        ri <- rows[[i]]
        pi <- perm[[i]]
        if (is.null(pi)) 
            pi <- pseq
        for (j in 1:nvar) {
            jj <- pi[j]
            xij <- xi[[j]]
            if (has.dim[jj]) {
                value[[jj]][ri, ] <- xij
                rownames(value[[jj]])[ri] <- rownames(xij)
            }
            else {
                value[[jj]][ri] <- if (is.factor(xij)) 
                  as.vector(xij)
                else xij
                if (!is.null(nm <- names(xij))) 
                  names(value[[jj]])[ri] <- nm
            }
        }
    }
    rlabs <- unlist(rlabs)
    if (any(duplicated(rlabs))) 
        rlabs <- make.unique(as.character(unlist(rlabs)), sep = "")
    if (is.null(cl)) {
        as.data.frame(value, row.names = rlabs)
    }
    else {
        class(value) <- cl
        attr(value, "row.names") <- rlabs
        value
    }
})



From spencer.graves at pdf.com  Sat Dec  2 02:29:56 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 01 Dec 2006 17:29:56 -0800
Subject: [R] Quadratic Optimization
In-Reply-To: <20061126223207.15485.qmail@web8414.mail.in.yahoo.com>
References: <20061126223207.15485.qmail@web8414.mail.in.yahoo.com>
Message-ID: <4570D714.4040708@pdf.com>

      Unless I'm missing something, optimizing a linear function with 
quadratic constraints is almost trivial with Langrange multipliers. 

      Maximize a'x subject to x'Ax=c. 

      S = Lagrange objective = a'x+lam*(x'Ax-c). 
      dS/dx = a + 2*lam*Ax. 
     
      Given lam, x1 = solve(A, a)/(2*lam) 
        
      Then x = c*x1/(x'Ax) 

      In R, you need to know that "t" = transpose of a matrix. 

      I thought I had seen mention of a contributed package for 
optimization with nonlinear constraints.  However, you don't need that 
here. 

      In case this does not solve your problem, my crude engineer's 
approach to constrained optimization includes the following: 

      (1) Find transformation to send the constraints to +/-Inf. 

      (2) If that fails, add the constraints as a penalty.  Start with a 
low penalty and gradually increase it if necessary until you solve the 
problem.  Of course, to do this, you have to make sure your objective 
function returns valid numbers outside the constrained region. 

      How's this? 
      Spencer Graves

amit soni wrote:
> Hi,
>
> I need to solve an optimization problem in R having linear objective function and quadratic constraints(number of variables is around 80).  What are the possible choices to do this in R.
> optim() function only allows box constrained problems. Is it possible in nlm()? Or please tell me if there is any other routine.
>
> Thanks
>
> Amit
>
>
>
>
>  
> ____________________________________________________________________________________
> Cheap talk?
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From wwguo at gmail.com  Sat Dec  2 05:00:25 2006
From: wwguo at gmail.com (Wei-Wei Guo)
Date: Sat, 02 Dec 2006 12:00:25 +0800
Subject: [R]  Is there a better way for inputing data manually?
Message-ID: <365031447.30585@eyou.net>


Dear All,

I have worked with R for some time. It's a great tool for data analysis. But it's too hard to inputing raw data manually with R (I don't mean importing data. R is good at importing data). Maybe it's not a focused topic in this list, but I don't know other place where I can ask the question. How do you do when inputing data from a paper material, such as questionnaire, or what do you use ?

Best wishes,
Wei-Wei



From murdoch at stats.uwo.ca  Sat Dec  2 05:40:17 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 01 Dec 2006 23:40:17 -0500
Subject: [R] Is there a better way for inputing data manually?
In-Reply-To: <365031447.30585@eyou.net>
References: <365031447.30585@eyou.net>
Message-ID: <457103B1.7010308@stats.uwo.ca>

On 12/1/2006 11:00 PM, Wei-Wei Guo wrote:
> Dear All,
> 
> I have worked with R for some time. It's a great tool for data analysis. But it's too hard to inputing raw data manually with R (I don't mean importing data. R is good at importing data). Maybe it's not a focused topic in this list, but I don't know other place where I can ask the question. How do you do when inputing data from a paper material, such as questionnaire, or what do you use ?

I would not use R for this.  Depending on how many questionnaires I had, 
from small number to large, I would use:

1.  A text file.
2.  A spreadsheet, like Excel, or the OpenOffice one, or the R data editor.
3.  A custom program written specifically to handle the particular 
questionnaire.

You can do 1 and 2 in R, but you can't do them as well as programs 
dedicated to those tasks, and you can't do 3 at all well.  It depends a 
lot on the specific conventions of the platform you're working on.  R is 
aimed at writing cross-platform programs, and isn't particularly good at 
writing GUI programs, which is what you want here.  I would personally 
use Delphi for this, but there are lots of alternatives.

Duncan Murdoch



From ripley at stats.ox.ac.uk  Sat Dec  2 08:28:26 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 2 Dec 2006 07:28:26 +0000 (GMT)
Subject: [R] package installation fails only for "sp"
In-Reply-To: <4570BBFE.1050303@u.washington.edu>
References: <4570BBFE.1050303@u.washington.edu>
Message-ID: <Pine.LNX.4.64.0612020724520.14260@gannet.stats.ox.ac.uk>

One thing you did miss was the request in the posting guide to update to 
the latest version of R before posting.

Note that it is the download that fails, not the installation.  There is a 
binary versioon of 'sp' for R 2.3.x on the CRAN master, so it looks like a 
problem with the CRAN mirror you are using -- but of course I don't have 
an outdated version of R installed to cross-check.

On Fri, 1 Dec 2006, Don McKenzie wrote:

> I have escaped Splus for Windows (mostly) and have started using
> R (v 2.3.1 on i686 redhat).  Installing packages has been routine except
> for "sp" (classes and methods for spatial data).  I get the following error
> message
>
> > install.packages("sp")
> Warning in download.packages(unique(pkgs),destdir=tmpd,available=available,:
>            no package 'sp'  at the repositories
>
> Clearly I am missing something (probably obvious), but can someone
> enlighten me
> as to why the behavior of this package installation is different from
> others?  sp is
> listed under "Contributed packages" at the R-project URL.  Thank you
> for your time.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sat Dec  2 08:37:15 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 2 Dec 2006 07:37:15 +0000 (GMT)
Subject: [R] package installation fails only for "sp"
In-Reply-To: <Pine.LNX.4.64.0612020724520.14260@gannet.stats.ox.ac.uk>
References: <4570BBFE.1050303@u.washington.edu>
	<Pine.LNX.4.64.0612020724520.14260@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0612020730570.14260@gannet.stats.ox.ac.uk>

Sorry, I missed that 'i686 redhat' might mean Red Hat, that is a form of 
Linux.  The advice in the first para applies: the current version of 'sp' 
in the source area on CRAN is for R>=2.4.0: see

http://cran.r-project.org/src/contrib/Descriptions/sp.html

If you cannot update your R, there are versions of 'sp' available in the 
Archive area on CRAN that willl work with R 2.3.1.

On Sat, 2 Dec 2006, Prof Brian Ripley wrote:

> One thing you did miss was the request in the posting guide to update to the 
> latest version of R before posting.
>
> Note that it is the download that fails, not the installation.  There is a 
> binary version of 'sp' for R 2.3.x on the CRAN master, so it looks like a 
> problem with the CRAN mirror you are using -- but of course I don't have an 
> outdated version of R installed to cross-check.
>
> On Fri, 1 Dec 2006, Don McKenzie wrote:
>
>> I have escaped Splus for Windows (mostly) and have started using
>> R (v 2.3.1 on i686 redhat).  Installing packages has been routine except
>> for "sp" (classes and methods for spatial data).  I get the following error
>> message
>> 
>> > install.packages("sp")
>> Warning in 
>> download.packages(unique(pkgs),destdir=tmpd,available=available,:
>>            no package 'sp'  at the repositories
>> 
>> Clearly I am missing something (probably obvious), but can someone
>> enlighten me
>> as to why the behavior of this package installation is different from
>> others?  sp is
>> listed under "Contributed packages" at the R-project URL.  Thank you
>> for your time.
>> 
>> 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wjgoh at brookes.ac.uk  Sat Dec  2 10:04:51 2006
From: wjgoh at brookes.ac.uk (Wee-Jin Goh)
Date: Sat, 2 Dec 2006 09:04:51 +0000
Subject: [R] symbol.C is now deprecated?
Message-ID: <EB99BE79-31AB-433B-B37E-58A1E38FCBEA@brookes.ac.uk>

Hello list,

I have a function that I wrote in C to be called in R. I've done that  
using symbol.C, which is the method I came across on the internet.

Now that it's supposed to be deprecated and can be removed in the  
next version of R (!!), what up-to-date method that replaces symbol.C?

cheers,
Wee-Jin



From maechler at stat.math.ethz.ch  Sat Dec  2 11:19:58 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 2 Dec 2006 11:19:58 +0100
Subject: [R] Quadratic Optimization
In-Reply-To: <4570D714.4040708@pdf.com>
References: <20061126223207.15485.qmail@web8414.mail.in.yahoo.com>
	<4570D714.4040708@pdf.com>
Message-ID: <17777.21326.6043.444139@stat.math.ethz.ch>

>>>>> "SpG" == Spencer Graves <spencer.graves at pdf.com>
>>>>>     on Fri, 01 Dec 2006 17:29:56 -0800 writes:

    SpG>       Unless I'm missing something, optimizing a linear
    SpG> function with quadratic constraints is almost trivial
    SpG> with Langrange multipliers.

yes. Good point, let's hope we're not solving someone's homework
here :-)

    SpG>       Maximize a'x subject to x'Ax=c.

    SpG>       S = Lagrange objective = a'x+lam*(x'Ax-c).
    SpG>         dS/dx = a + 2*lam*Ax.

    SpG>       Given lam, x1 = solve(A, a)/(2*lam)

  [you forgot a "-" , but it's irrelevant, since 'lam' arbitrarily varies;
   and we can use  x1 = solve(A,a) in the following ]

    SpG>       Then x = c*x1/(x'Ax)

but the last equation above is not useful ("x" on the RHS).
Rather, we know that  x = s * x1 (for some scalar 's') and from
the constraint x'Ax = c (or equivalently, from dS/d{lam} = 0),
we find that

   s = +/- sqrt(c / (x1' A x1))

and can even see that  x1' A x1 = x1' A A^{-1} a =  x1' a

Note the "+/-" : we get the minimizing and the maximizing values

    SpG>       In R, you need to know that "t" = transpose of a
    SpG> matrix.

In other words, as an "algorithm" in R



solveLinQuad <- function(a,A,c)
{
    ## Purpose: maximize a'x  under constraint  x'Ax = c
    ##       we return x = arg.max{...}, but note that  arg.min{..} = -x
    ## -------------------------------------------------------------------
    ## Author: Martin Maechler, Date:  2 Dec 2006

    ## argument checking ...
    stopifnot(is.matrix(A), nrow(A) == ncol(A), length(a) == nrow(A),
              is.numeric(A), is.numeric(a), is.numeric(c))
    x1 <- solve(A,a)
    ## note that  x1' A x1 = x1' A A^{-1} a = x1' a { == sum(x1 * a) }
    x <- sqrt(c / sum(x1 * a)) * x1
    ## we return the arg.max :
    if(sum(x * a) >= 0) x else -x
}

## Test:
set.seed(1)
A <- crossprod(matrix(round(rnorm(24),2), 6,4))
a <- c(-1, 1, -2, 6)
c <- 3
(x <- solveLinQuad(a,A,c))
##    -------------
sum(a * x) # 4.677
## constraint
sum(x * (A %*% x)) ## -> 3

    SpG>       I thought I had seen mention of a contributed
    SpG> package for optimization with nonlinear constraints.
    SpG> However, you don't need that here.

    SpG>       In case this does not solve your problem, my
    SpG> crude engineer's approach to constrained optimization
    SpG> includes the following:

    SpG>       (1) Find transformation to send the constraints
    SpG> to +/-Inf.

    SpG>       (2) If that fails, add the constraints as a
    SpG> penalty.  Start with a low penalty and gradually
    SpG> increase it if necessary until you solve the problem.
    SpG> Of course, to do this, you have to make sure your
    SpG> objective function returns valid numbers outside the
    SpG> constrained region.

    SpG>       How's this?  Spencer Graves

    SpG> amit soni wrote:
    >> Hi,
    >>
    >> I need to solve an optimization problem in R having
    >> linear objective function and quadratic
    >> constraints(number of variables is around 80).  What are
    >> the possible choices to do this in R.  optim() function
    >> only allows box constrained problems. Is it possible in
    >> nlm()? Or please tell me if there is any other routine.
    >>
    >> Thanks
    >>
    >> Amit



From carmei3 at web.de  Sat Dec  2 11:32:29 2006
From: carmei3 at web.de (Carmen Meier)
Date: Sat, 02 Dec 2006 11:32:29 +0100
Subject: [R] error using environment(f) <- NULL
Message-ID: <4571563D.7050602@web.de>

Hi To all,
I found in the tread
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/46740.html

the reply for

/> y <- 3 /
/> f <- function(x) y /
/> environment(f) <- NULL /
/> f(1)

/but this example (R 2.4.0) will cause an error:

The use of the NULL environment is not longer possible (translated)
The ?environment reports the NULL as possible.
is there any other way now ,to get the same result

Regards Carmen



From ggrothendieck at gmail.com  Sat Dec  2 12:11:17 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 2 Dec 2006 06:11:17 -0500
Subject: [R] error using environment(f) <- NULL
In-Reply-To: <4571563D.7050602@web.de>
References: <4571563D.7050602@web.de>
Message-ID: <971536df0612020311n2b4a416fvdd3df1517bc1d619@mail.gmail.com>

Try :

environment(f) <- baseenv()

There is also emptyenv() depending on what you want.

See ?baseenv



On 12/2/06, Carmen Meier <carmei3 at web.de> wrote:
> Hi To all,
> I found in the tread
> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/46740.html
>
> the reply for
>
> /> y <- 3 /
> /> f <- function(x) y /
> /> environment(f) <- NULL /
> /> f(1)
>
> /but this example (R 2.4.0) will cause an error:
>
> The use of the NULL environment is not longer possible (translated)
> The ?environment reports the NULL as possible.
> is there any other way now ,to get the same result
>
> Regards Carmen
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From shubhakaranth at gmail.com  Sat Dec  2 12:22:34 2006
From: shubhakaranth at gmail.com (Shubha Karanth)
Date: Sat, 2 Dec 2006 16:52:34 +0530
Subject: [R] Fwd: Urgent Help in Paste Command
In-Reply-To: <A36876D3F8A5734FA84A4338135E7CC39A59ED@BAN-MAILSRV03.Amba.com>
References: <A36876D3F8A5734FA84A4338135E7CC39A59ED@BAN-MAILSRV03.Amba.com>
Message-ID: <67e4ea330612020322o1b3c2958o7032877b57019aa7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061202/f33793e5/attachment-0004.pl 

From info at aghmed.fsnet.co.uk  Sat Dec  2 12:38:26 2006
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Sat, 02 Dec 2006 11:38:26 +0000
Subject: [R] Is there a better way for inputing data manually?
In-Reply-To: <457103B1.7010308@stats.uwo.ca>
References: <365031447.30585@eyou.net>
 <457103B1.7010308@stats.uwo.ca>
Message-ID: <7.0.0.16.0.20061202113406.0194bdb0@aghmed.fsnet.co.uk>

At 04:40 02/12/2006, Duncan Murdoch wrote:
>On 12/1/2006 11:00 PM, Wei-Wei Guo wrote:
>>Dear All,
>>I have worked with R for some time. It's a great tool for data 
>>analysis. But it's too hard to inputing raw data manually with R (I 
>>don't mean importing data. R is good at importing data). Maybe it's 
>>not a focused topic in this list, but I don't know other place 
>>where I can ask the question. How do you do when inputing data from 
>>a paper material, such as questionnaire, or what do you use ?
>
>I would not use R for this.  Depending on how many questionnaires I 
>had, from small number to large, I would use:
>
>1.  A text file.
>2.  A spreadsheet, like Excel, or the OpenOffice one, or the R data editor.
>3.  A custom program written specifically to handle the particular 
>questionnaire.
>
>You can do 1 and 2 in R, but you can't do them as well as programs 
>dedicated to those tasks, and you can't do 3 at all well.  It 
>depends a lot on the specific conventions of the platform you're 
>working on.  R is aimed at writing cross-platform programs, and 
>isn't particularly good at writing GUI programs, which is what you 
>want here.  I would personally use Delphi for this, but there are 
>lots of alternatives.

I usually use Epidata, available from http://www.epidata.dk/, which 
is free and enables you to write your own questionnaire file and then 
input your data. It also enables you to implement checks during data 
entry which in my view is an important feature. It enables export in 
a number of formats but its native output format, the .rec file, can 
be read into R using the foreign package.

>Duncan Murdoch
>
>

Michael Dewey
http://www.aghmed.fsnet.co.uk



From ggrothendieck at gmail.com  Sat Dec  2 12:50:47 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 2 Dec 2006 06:50:47 -0500
Subject: [R] Fwd: Urgent Help in Paste Command
In-Reply-To: <67e4ea330612020322o1b3c2958o7032877b57019aa7@mail.gmail.com>
References: <A36876D3F8A5734FA84A4338135E7CC39A59ED@BAN-MAILSRV03.Amba.com>
	<67e4ea330612020322o1b3c2958o7032877b57019aa7@mail.gmail.com>
Message-ID: <971536df0612020350q37580999k10eb1ac3565ad4c8@mail.gmail.com>

Try this:

> x <- readline()
C:\Program Files\R\R-2.4.0\bin\Rgui.exe
> x
[1] "C:\\Program Files\\R\\R-2.4.0\\bin\\Rgui.exe"



You can also use

   readLines("clipboard")

if you are trying to read in something from the clipboard.


On 12/2/06, Shubha Karanth <shubhakaranth at gmail.com> wrote:
> Hi Experts,
>
> I want to see my object as below:
>     'C:\Program Files\R\R-2.4.0\bin\Rgui.exe'
> So I use the paste command. None of the below is working. Could anyone help
> me on this?
>
> > paste("'C:\Program Files\R\R-2.4.0\bin\Rgui.exe'")
> [1] "'C:Program FilesRR-2.4.0\binRgui.exe'"
>
> > paste("'C:","\","Program Files","\","R","\","R-2.4.0","\","bin","\","
> Rgui.exe'",sep="")
> Error: syntax error in "paste("'C:","\","Program"
>
> >paste("'C:","Program Files","R","R-2.4.0","bin","Rgui.exe'",sep="\")
> +
>
> I need to only use the \ symbol and not / or \\. Please help me?
>
> Thank you,
> Shubha.
>
>        [[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>



From shubhak at ambaresearch.com  Sat Dec  2 13:08:57 2006
From: shubhak at ambaresearch.com (Shubha Vishwanath Karanth)
Date: Sat, 2 Dec 2006 17:38:57 +0530
Subject: [R] Fwd: Urgent Help in Paste Command
Message-ID: <A36876D3F8A5734FA84A4338135E7CC39A59F7@BAN-MAILSRV03.Amba.com>

But when I do this I need x value to be " C:\Program
Files\R\R-2.4.0\bin\Rgui.exe" and not C:\\Program
Files\\R\\R-2.4.0\\bin\\Rgui.exe"

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Gabor
Grothendieck
Sent: Saturday, December 02, 2006 5:21 PM
To: Shubha Karanth
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Fwd: Urgent Help in Paste Command

Try this:

> x <- readline()
C:\Program Files\R\R-2.4.0\bin\Rgui.exe
> x
[1] "C:\\Program Files\\R\\R-2.4.0\\bin\\Rgui.exe"



You can also use

   readLines("clipboard")

if you are trying to read in something from the clipboard.


On 12/2/06, Shubha Karanth <shubhakaranth at gmail.com> wrote:
> Hi Experts,
>
> I want to see my object as below:
>     'C:\Program Files\R\R-2.4.0\bin\Rgui.exe'
> So I use the paste command. None of the below is working. Could anyone
help
> me on this?
>
> > paste("'C:\Program Files\R\R-2.4.0\bin\Rgui.exe'")
> [1] "'C:Program FilesRR-2.4.0\binRgui.exe'"
>
> > paste("'C:","\","Program
Files","\","R","\","R-2.4.0","\","bin","\","
> Rgui.exe'",sep="")
> Error: syntax error in "paste("'C:","\","Program"
>
> >paste("'C:","Program Files","R","R-2.4.0","bin","Rgui.exe'",sep="\")
> +
>
> I need to only use the \ symbol and not / or \\. Please help me...
>
> Thank you,
> Shubha.
>
>        [[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ggrothendieck at gmail.com  Sat Dec  2 13:26:04 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 2 Dec 2006 07:26:04 -0500
Subject: [R] Fwd: Urgent Help in Paste Command
In-Reply-To: <A36876D3F8A5734FA84A4338135E7CC39A59F7@BAN-MAILSRV03.Amba.com>
References: <A36876D3F8A5734FA84A4338135E7CC39A59F7@BAN-MAILSRV03.Amba.com>
Message-ID: <971536df0612020426p4077ca8dg61d90ddf53a48e6@mail.gmail.com>

x is the value you asked for.  I think you are confusing its printed
representation
with its value.  Try cat(x) and strsplit(x, "")

On 12/2/06, Shubha Vishwanath Karanth <shubhak at ambaresearch.com> wrote:
> But when I do this I need x value to be " C:\Program
> Files\R\R-2.4.0\bin\Rgui.exe" and not C:\\Program
> Files\\R\\R-2.4.0\\bin\\Rgui.exe"
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Gabor
> Grothendieck
> Sent: Saturday, December 02, 2006 5:21 PM
> To: Shubha Karanth
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Fwd: Urgent Help in Paste Command
>
> Try this:
>
> > x <- readline()
> C:\Program Files\R\R-2.4.0\bin\Rgui.exe
> > x
> [1] "C:\\Program Files\\R\\R-2.4.0\\bin\\Rgui.exe"
>
>
>
> You can also use
>
>   readLines("clipboard")
>
> if you are trying to read in something from the clipboard.
>
>
> On 12/2/06, Shubha Karanth <shubhakaranth at gmail.com> wrote:
> > Hi Experts,
> >
> > I want to see my object as below:
> >     'C:\Program Files\R\R-2.4.0\bin\Rgui.exe'
> > So I use the paste command. None of the below is working. Could anyone
> help
> > me on this?
> >
> > > paste("'C:\Program Files\R\R-2.4.0\bin\Rgui.exe'")
> > [1] "'C:Program FilesRR-2.4.0\binRgui.exe'"
> >
> > > paste("'C:","\","Program
> Files","\","R","\","R-2.4.0","\","bin","\","
> > Rgui.exe'",sep="")
> > Error: syntax error in "paste("'C:","\","Program"
> >
> > >paste("'C:","Program Files","R","R-2.4.0","bin","Rgui.exe'",sep="\")
> > +
> >
> > I need to only use the \ symbol and not / or \\. Please help me...
> >
> > Thank you,
> > Shubha.
> >
> >        [[alternative HTML version deleted]]
> >
> >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From shubhak at ambaresearch.com  Sat Dec  2 14:04:03 2006
From: shubhak at ambaresearch.com (Shubha Vishwanath Karanth)
Date: Sat, 2 Dec 2006 18:34:03 +0530
Subject: [R] Fwd: Urgent Help in Paste Command
Message-ID: <A36876D3F8A5734FA84A4338135E7CC39A59F9@BAN-MAILSRV03.Amba.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061202/06def568/attachment-0004.pl 

From shubhak at ambaresearch.com  Sat Dec  2 14:04:22 2006
From: shubhak at ambaresearch.com (Shubha Vishwanath Karanth)
Date: Sat, 2 Dec 2006 18:34:22 +0530
Subject: [R] Fwd: Urgent Help in Paste Command
Message-ID: <A36876D3F8A5734FA84A4338135E7CC39A59FA@BAN-MAILSRV03.Amba.com>


O yaa... Thank you so much...
-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Sent: Saturday, December 02, 2006 5:56 PM
To: Shubha Vishwanath Karanth
Cc: Shubha Karanth; r-help at stat.math.ethz.ch
Subject: Re: [R] Fwd: Urgent Help in Paste Command

x is the value you asked for.  I think you are confusing its printed
representation
with its value.  Try cat(x) and strsplit(x, "")

On 12/2/06, Shubha Vishwanath Karanth <shubhak at ambaresearch.com> wrote:
> But when I do this I need x value to be " C:\Program
> Files\R\R-2.4.0\bin\Rgui.exe" and not C:\\Program
> Files\\R\\R-2.4.0\\bin\\Rgui.exe"
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Gabor
> Grothendieck
> Sent: Saturday, December 02, 2006 5:21 PM
> To: Shubha Karanth
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Fwd: Urgent Help in Paste Command
>
> Try this:
>
> > x <- readline()
> C:\Program Files\R\R-2.4.0\bin\Rgui.exe
> > x
> [1] "C:\\Program Files\\R\\R-2.4.0\\bin\\Rgui.exe"
>
>
>
> You can also use
>
>   readLines("clipboard")
>
> if you are trying to read in something from the clipboard.
>
>
> On 12/2/06, Shubha Karanth <shubhakaranth at gmail.com> wrote:
> > Hi Experts,
> >
> > I want to see my object as below:
> >     'C:\Program Files\R\R-2.4.0\bin\Rgui.exe'
> > So I use the paste command. None of the below is working. Could
anyone
> help
> > me on this?
> >
> > > paste("'C:\Program Files\R\R-2.4.0\bin\Rgui.exe'")
> > [1] "'C:Program FilesRR-2.4.0\binRgui.exe'"
> >
> > > paste("'C:","\","Program
> Files","\","R","\","R-2.4.0","\","bin","\","
> > Rgui.exe'",sep="")
> > Error: syntax error in "paste("'C:","\","Program"
> >
> > >paste("'C:","Program
Files","R","R-2.4.0","bin","Rgui.exe'",sep="\")
> > +
> >
> > I need to only use the \ symbol and not / or \\. Please help me...
> >
> > Thank you,
> > Shubha.
> >
> >        [[alternative HTML version deleted]]
> >
> >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From ripley at stats.ox.ac.uk  Sat Dec  2 14:09:18 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 2 Dec 2006 13:09:18 +0000 (GMT)
Subject: [R] Quadratic Optimization
In-Reply-To: <17777.21326.6043.444139@stat.math.ethz.ch>
References: <20061126223207.15485.qmail@web8414.mail.in.yahoo.com>
	<4570D714.4040708@pdf.com> <17777.21326.6043.444139@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.64.0612021303270.8562@gannet.stats.ox.ac.uk>

On Sat, 2 Dec 2006, Martin Maechler wrote:

>>>>>> "SpG" == Spencer Graves <spencer.graves at pdf.com>
>>>>>>     on Fri, 01 Dec 2006 17:29:56 -0800 writes:
>
>    SpG>       Unless I'm missing something, optimizing a linear
>    SpG> function with quadratic constraints is almost trivial
>    SpG> with Langrange multipliers.
>
> yes. Good point, let's hope we're not solving someone's homework
> here :-)

But that is a single equality quadratic constraint, and I believe 
'quadratic constraints' (note, plural) conventionally means multiple 
inequality constraints.  That meaning is a hard problem that needs 
specialized software (most likely using interior-point methods).

>    SpG>       Maximize a'x subject to x'Ax=c.

Not I believe the usual meaning (nor what Googling 'quadratic constraints' 
came up with for me).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From murdoch at stats.uwo.ca  Sat Dec  2 14:14:02 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 02 Dec 2006 08:14:02 -0500
Subject: [R] symbol.C is now deprecated?
In-Reply-To: <EB99BE79-31AB-433B-B37E-58A1E38FCBEA@brookes.ac.uk>
References: <EB99BE79-31AB-433B-B37E-58A1E38FCBEA@brookes.ac.uk>
Message-ID: <45717C1A.2020904@stats.uwo.ca>

On 12/2/2006 4:04 AM, Wee-Jin Goh wrote:
> Hello list,
> 
> I have a function that I wrote in C to be called in R. I've done that  
> using symbol.C, which is the method I came across on the internet.
> 
> Now that it's supposed to be deprecated and can be removed in the  
> next version of R (!!), what up-to-date method that replaces symbol.C?

You don't need it at all.  Just give the entry point name directly in 
you .C() calls.  This is documented in the Writing R Extensions manual, 
with examples.

Duncan Murdoch



From philipp.pagel.lists at t-online.de  Sat Dec  2 14:16:06 2006
From: philipp.pagel.lists at t-online.de (Philipp Pagel)
Date: Sat, 2 Dec 2006 14:16:06 +0100
Subject: [R] newbie: new_data_frame <- selected set of rows
In-Reply-To: <928715.70626.qm@web90407.mail.mud.yahoo.com>
References: <928715.70626.qm@web90407.mail.mud.yahoo.com>
Message-ID: <20061202131606.GA15341@gsf.de>


	Hi!

> distances <- order(distancevector(scaled_DB, scaled_DB['query',],
> d="euclid"))

Just compute the distances WITHOUT ordering, here. And then

> 1) create a small top_five frame

top = scaled_DB[rank(distances)<=5, ]

rank() is better for this than order() in case there are ties.

> 2) after I got top_five I woul like to get the index
> of my query entry, something along Pythons 
> top_five.index('query_string')

You mean by row name?

which(row.names(scaled_DB)=='query_string')

But why would you need the index? If you want to get the respective row
use logical indexing:

my_dataframe['query_string', ]

> 3) possibly combine values in distances with row names
> from my_dataframe:
> row_1 distance_from_query1
> row_2 distance_from_query2

The easiest way to store the distances along with the original names and
data would be to simply make distances a column in your data frame,
which is what I would have done to begin with. The entire procedure
would then look like this:

my_dataframe = read.table( ... )
scaled_DB <- scale(my_dataframe, center=FALSE)
scaled_DB$dist1 = distancevector(scaled_DB, scaled_DB['query1',], ...)
scaled_DB$dist2 = distancevector(scaled_DB, scaled_DB['query2',], ...)
scaled_DB$dist3 = distancevector(scaled_DB, scaled_DB['query3',], ...)
...
top1 = scaled_DB[rank(scaled_DB$dist1)<=5, ]
...

cu
	Philipp

-- 
Dr. Philipp Pagel                            Tel.  +49-8161-71 2131
Dept. of Genome Oriented Bioinformatics      Fax.  +49-8161-71 2186
Technical University of Munich
Science Center Weihenstephan
85350 Freising, Germany

 and

Institute for Bioinformatics / MIPS          Tel.  +49-89-3187 3675
GSF - National Research Center               Fax.  +49-89-3187 3585
      for Environment and Health
Ingolst?dter Landstrasse 1
85764 Neuherberg, Germany
http://mips.gsf.de/staff/pagel



From wjgoh at brookes.ac.uk  Sat Dec  2 14:44:58 2006
From: wjgoh at brookes.ac.uk (Wee-Jin Goh)
Date: Sat, 2 Dec 2006 13:44:58 +0000
Subject: [R] Trouble passing arrays to C code
Message-ID: <08C1A7C9-F750-4C58-8324-576A40F05141@brookes.ac.uk>

Hello,

I'm having more trouble with interfacing with C code. I have a  
function in C that will return the result of its computation as 3  
arrays. The signature of the function is as follows:

void lorenz_run(double x0, double y0, double z0, double h, int steps,
					double *res_x, double *res_y, double *res_z)

The function works, as I've tested it from within C itself and the  
results it gives are accurate. In order to integrate it with R, I've  
written the following C wrapper function:

void lorenz_run_R_wrapper(double *x0, double *y0, double *z0, double  
*h, double *steps,
			double *res_x, double *res_y, double *res_z) {
	lorenz_run(*x0, *y0, *z0, *h, *steps, res_x, res_y, res_z);	
}

The corresponding R wrapper function is:

lorenz_run <- function(x0,y0,z0,h,steps) {
	returned_data = .C("lorenz_run_R_wrapper",
                        x0=as.double(x0),
                        y0=as.double(y0),
                        z0=as.double(z0),
                        h=as.double(h),
                        steps=as.integer(steps),
                        res_x=double(steps),
                        res_y=double(steps),
                        res_z=double(steps))
      # Return the value of the result parameter
      return( rbind(returned_data$res_x, returned_data$res_y,  
returned_data$res_z))

}

My problem is, that the first elements of res_x, res_y, and res_z are  
correctly set. But the rest of the cells in those 3 arrays remain 0.  
This leads me to think that I am passing these arrays to the C code  
wrongly. Can anyone help me out?

Thanks in advance,
Wee-Jin



From antonio.fabio at gmail.com  Sat Dec  2 16:17:21 2006
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Sat, 2 Dec 2006 16:17:21 +0100
Subject: [R]  Trouble passing arrays to C code
In-Reply-To: <b0808fdc0612020716g71c3ddf7j4bcb861379a29d7a@mail.gmail.com>
References: <08C1A7C9-F750-4C58-8324-576A40F05141@brookes.ac.uk>
	<b0808fdc0612020716g71c3ddf7j4bcb861379a29d7a@mail.gmail.com>
Message-ID: <b0808fdc0612020717j63a253b8o88a4b6a8e952bd55@mail.gmail.com>

2006/12/2, Wee-Jin Goh <wjgoh at brookes.ac.uk>:
> Hello,
>
> I'm having more trouble with interfacing with C code. I have a
> function in C that will return the result of its computation as 3
> arrays. The signature of the function is as follows:
>
> void lorenz_run(double x0, double y0, double z0, double h, int steps,
>                                         double *res_x, double *res_y, double *res_z)
>
> The function works, as I've tested it from within C itself and the
> results it gives are accurate. In order to integrate it with R, I've
> written the following C wrapper function:
>
> void lorenz_run_R_wrapper(double *x0, double *y0, double *z0, double
> *h, double *steps,

here 'steps' is double, was integer in 'lorenz_run'.

>                         double *res_x, double *res_y, double *res_z) {
>         lorenz_run(*x0, *y0, *z0, *h, *steps, res_x, res_y, res_z);
> }
>
> The corresponding R wrapper function is:
>
> lorenz_run <- function(x0,y0,z0,h,steps) {
>         returned_data = .C("lorenz_run_R_wrapper",
>                         x0=as.double(x0),
>                         y0=as.double(y0),
>                         z0=as.double(z0),
>                         h=as.double(h),
>                         steps=as.integer(steps),
>                         res_x=double(steps),
>                         res_y=double(steps),
>                         res_z=double(steps))
>       # Return the value of the result parameter
>       return( rbind(returned_data$res_x, returned_data$res_y,
> returned_data$res_z))
>
> }
>
> My problem is, that the first elements of res_x, res_y, and res_z are
> correctly set. But the rest of the cells in those 3 arrays remain 0.
> This leads me to think that I am passing these arrays to the C code
> wrongly.  Can anyone help me out?
>
> Thanks in advance,
> Wee-Jin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


--
Antonio, Fabio Di Narzo
Ph.D. student at
Department of Statistical Sciences
University of Bologna, Italy



From ethan.johnsons at gmail.com  Sat Dec  2 16:56:42 2006
From: ethan.johnsons at gmail.com (Ethan Johnsons)
Date: Sat, 2 Dec 2006 10:56:42 -0500
Subject: [R] Chi-squared approximation may be incorrect in: chisq.test(x)
Message-ID: <5cd96f050612020756l1460aa8an66f0b083c79350ef@mail.gmail.com>

I am getting "Chi-squared approximation may be incorrect in:
chisq.test(x)"  with the data bleow.

Frequency distribution of number of male offspring in families of size 5.
Number of Male Offspring 	N
0 		                          518
1 		                         2245
2 		                          4621
3 		                          4753
4 		                          2476
5 		                            549
Total 		                      15,162


> x=matrix(c(0,1,2,3,4,5,518,2245,4621,4753,2476,549), ncol=2)
> x
     [,1] [,2]
[1,]    0  518
[2,]    1 2245
[3,]    2 4621
[4,]    3 4753
[5,]    4 2476
[6,]    5  549
> chisq.test(x)

        Pearson's Chi-squared test

data:  x
X-squared = 40.4672, df = 5, p-value = 1.202e-07

Warning message:
Chi-squared approximation may be incorrect in: chisq.test(x)

Does the warning mean that chisq.test(x) can't be used for this data.

If chisq.test(x) can't be used for this data, which test is to be used?

Pls advise.

thx

ej



From jrkrideau at yahoo.ca  Sat Dec  2 17:17:38 2006
From: jrkrideau at yahoo.ca (John Kane)
Date: Sat, 2 Dec 2006 11:17:38 -0500 (EST)
Subject: [R] specify point shape for ggplot (equivalent to pch)?
In-Reply-To: <456FF9E3.5080808@sun.ac.za>
Message-ID: <269261.93476.qm@web32811.mail.mud.yahoo.com>


--- Rainer M Krug <RKrug at sun.ac.za> wrote:

> Hi
> 
> is it possible to specify the shape of the point to
> be used in ggplot 
> (as with pch in plot)? I couldn't find anything in
> the help.
> 
> Thanks
> 
> Rainer

I was looking for that the other day while just poking
around with ggplot and did not see it but I a very new
to R and to ggplot. 

However have a look at the function map_shape.  It
looks to me like this decides what points are used but
this is just a guess.



From ggrothendieck at gmail.com  Sat Dec  2 17:29:30 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 2 Dec 2006 11:29:30 -0500
Subject: [R] specify point shape for ggplot (equivalent to pch)?
In-Reply-To: <456FF9E3.5080808@sun.ac.za>
References: <456FF9E3.5080808@sun.ac.za>
Message-ID: <971536df0612020829o2c571aa8i6cc6d4070c0b0c12@mail.gmail.com>

See the last example in ?qplot

On 12/1/06, Rainer M Krug <RKrug at sun.ac.za> wrote:
> Hi
>
> is it possible to specify the shape of the point to be used in ggplot
> (as with pch in plot)? I couldn't find anything in the help.
>
> Thanks
>
> Rainer
>
> --
> Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
> Biology (UCT)
>
> Department of Conservation Ecology and Entomology
> University of Stellenbosch
> Matieland 7602
> South Africa
>
> Tel:            +27 - (0)72 808 2975 (w)
> Fax:            +27 - (0)86 516 2782
> Fax:            +27 - (0)21 808 3304 (w)
> Cell:           +27 - (0)83 9479 042
>
> email:  RKrug at sun.ac.za
>        Rainer at krugs.de
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From dylan.beaudette at gmail.com  Sat Dec  2 19:07:47 2006
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Sat, 2 Dec 2006 10:07:47 -0800
Subject: [R] memory problem [cluster]
In-Reply-To: <323604.34642.qm@web55003.mail.re4.yahoo.com>
References: <323604.34642.qm@web55003.mail.re4.yahoo.com>
Message-ID: <200612021007.47511.dylan.beaudette@gmail.com>

Hi Stephano,

Looks like you used my example verbatim 
(http://casoilresource.lawr.ucdavis.edu/drupal/node/221)

:)

While my approach has not *yet* been published, the original source [4] by 
Roger Bivand certainly has. Just a reminder.

That said, I would highly recommend reading up on the background literature 
assocated with both the cluster package [1] and terrain classificartion i.e.
[2] and [3]. Note that although the clara() function was created to work on 
massive datasets, it is still possible to overwhelm the available memory with 
multiple gridded objects- recall that all R objects are held in memory.

I have asked the maintainer of the cluster package, Martin Maechler, about 
integrating a known medoid option into the clara() function- which would be 
extremely useful in adding some 'supervision' to landscape classification 
with clara(). Hopefully there will be enough requests for the feature, that 
Martin will kindly add it :) .

1. Kaufman, L. & Rousseeuw, P.J. Finding Groups in Data An Introduction to 
Cluster Analysis Wiley-Interscience, 2005

2. Blaszczynski, J. Landform characterization with geographical information 
systems Photogrammetric Engineering and Remote Sensing, 1997, 63, 183-191

3. Wood, W.F. & Snell, J.B. A Quatitative system for classifying landforms 
U.S. Quatermaster Research & Engineering Center, 1960

4. Bivand, R. Integrating GRASS 5.0 and R: GIS and modern statistics Computers 
& Geosciences, 2000, 26, 1043?1052


On Friday 01 December 2006 14:04, Massimo Di Stefano wrote:
> hi to all,
> frustated for this error, to day i buy a 1 GB memory
> slot for my laptop
> now it have 1,28GB instead the old 512, but i've the
> same error :-(
> damn!damn!....how can i do?
> repeat for a little area (about 20X20 km and res=20m)
> it work fine!
> have you any suggestion?
> is ther a method for look if this error depend from my
> ram or other....?
> thanks foe any suggestion!
> i need your help.
> thanks.
> Massimo
>
>
> Il giorno 01/dic/06, alle ore 16:05, massimodisasha ha
> scritto:
> hi,
> i'm trying to perform a clustering on a big dataframe
> the code is this:
>
>
> print("load required R packages")
>
> require(spgrass6)
>
> require(cluster)
>
> gmeta6 <- gmeta6()
>
> print("read in our 7 raster files from GRASS")
>
> x <-
> readFLOAT6sp(c("er","crosc","longc","slope","profc","minic","maxic"))
>
> print("assemble a matrix of our terrain variables")
>
> morph <- data.frame(cbind(x$er, x$crosc, x$longc,
> x$slope, x$profc, x$minic, x$maxic))
>
> print("normailize slope by dividing my max(slope)")
>
> morph <- data.frame(cbind(x$er, x$crosc, x$longc,
> x$slope/max(x$slope), x$profc, x$minic, x$maxic))
>
> names(morph) <-
> c("er","crosc","longc","slope_n","profc","minic","maxic")
>
> print("perform the clustering")
>
> morph.clara <- clara(morph, k=5, stand=F)
>
> x$morph_class <- morph.clara$clustering
>
> print("send result back to GRASS")
>
> rast.put6(x,"morph", zcol="morph_class")
>
>
>
> during the step : ....perform the clustering
> after a lot of time,
> i've this error:
>
>
>
>
> Errore in sprintf(fmt, ...) : La lunghezza della
> stringa eccede la dimensione del buffer di 8192
> Inoltre: Warning messages:
> 1: perl = TRUE ?? implementato solo nei locale UTF-8
> 2: perl = TRUE ?? implementato solo nei locale UTF-8
> 3: perl = TRUE ?? implementato solo nei locale UTF-8
> 4: perl = TRUE ?? implementato solo nei locale UTF-8
> 5: perl = TRUE ?? implementato solo nei locale UTF-8
> 6: perl = TRUE ?? implementato solo nei locale UTF-8
> 7: perl = TRUE ?? implementato solo nei locale UTF-8
> 8: La stringa di caratteri verr?  probabilmente
> troncata
> Esecuzione interrotta
>
>
>
> if i try the same code on a subregion of my data, it
> works very fine!
> but for a large region i've this error :-(
>
> obviously i think that is a memory problem, right ?
> (i'm working with a notebook PPC-1.33-512ram)
> my data are  : 7 raster-map on a region of about 50X40
> km at a resolution of 20m.
> is there some wolkaround about the memory problems?
>
> an other question is:
> what is this :
> Warning messages:
> 1: perl = TRUE ?? implementato solo nei locale UTF-8
> 2: perl = TRUE ?? implementato solo nei locale UTF-8
> 3: perl = TRUE ?? implementato solo nei locale UTF-8
> 4: perl = TRUE ?? implementato solo nei locale UTF-8
> 5: perl = TRUE ?? implementato solo nei locale UTF-8
> 6: perl = TRUE ?? implementato solo nei locale UTF-8
> 7: perl = TRUE ?? implementato solo nei locale UTF-8
>
> is it about this line of the code :
>
> morph.clara <- clara(morph, k=5, stand=F)
> i have an F > false
>
>
> thanks for any suggestion about,
>
> Massimo
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented, minimal,
> self-contained, reproducible code.

-- 
Dylan Beaudette
Soils and Biogeochemistry Graduate Group
University of California at Davis
530.754.7341



From Ted.Harding at nessie.mcc.ac.uk  Sat Dec  2 18:42:20 2006
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 02 Dec 2006 17:42:20 -0000 (GMT)
Subject: [R] Chi-squared approximation may be incorrect in: chisq.tes
In-Reply-To: <5cd96f050612020756l1460aa8an66f0b083c79350ef@mail.gmail.com>
Message-ID: <XFMail.061202174220.Ted.Harding@nessie.mcc.ac.uk>

On 02-Dec-06 Ethan Johnsons wrote:
> I am getting "Chi-squared approximation may be incorrect in:
> chisq.test(x)"  with the data bleow.
> 
> Frequency distribution of number of male offspring in families of size
> 5.
> Number of Male Offspring      N
>         0                           518
>         1                          2245
>         2                          4621
>         3                          4753
>         4                          2476
>         5                           549
> Total                             15162
> 
> 
>> x=matrix(c(0,1,2,3,4,5,518,2245,4621,4753,2476,549), ncol=2)
>> x
>      [,1] [,2]
> [1,]    0  518
> [2,]    1 2245
> [3,]    2 4621
> [4,]    3 4753
> [5,]    4 2476
> [6,]    5  549
>> chisq.test(x)
> 
>         Pearson's Chi-squared test
> 
> data:  x
> X-squared = 40.4672, df = 5, p-value = 1.202e-07
> 
> Warning message:
> Chi-squared approximation may be incorrect in: chisq.test(x)
> 
> Does the warning mean that chisq.test(x) can't be used for this data.
> 
> If chisq.test(x) can't be used for this data, which test is to be used?

You are feeding a matrix with 6 rows and *2 columns* to chisq.test()

See "?chisq.test":

  If 'x' is a matrix with at least two rows and columns, it is taken
  as a two-dimensional contingency table, and hence its entries
  should be nonnegative integers.

In other words, the first column -- giving the numbers (0-5)
of male offspring -- is also being used as count data, so what
you're getting is a test of association between the two sets
of "counts" {0,1,2,3,4,5} and {518,2245,4621,4753,2476,549}!

So, if (which seems likely) you want to test the counts in
the second column against (say) a binomial distribution,
you could use the following code (assuming P[boy]=0.5)

  chisq.test(x[,2],p=dbinom(x[,1],5,0.5))
  ##    Chi-squared test for given probabilities
  ##    data:  x[, 2] 
  ##    X-squared = 30.3181, df = 5, p-value = 1.277e-05

so it seems a binomial with P=0.5 won't do. Hence next try
the best estimate of P assuming binomial:

  P<-sum((0:5)*x[,2])/(5*sum(x[,2]))
  P
  ##  [1] 0.5064635

So does this improve things?:

  chisq.test(x[,2],p=dbinom(x[,1],5,P))
  ##    Chi-squared test for given probabilities
  ##    data:  x[, 2] 
  ##    X-squared = 17.744, df = 5, p-value = 0.003285

well, quite a bit -- but of course chisq.test() uses the wrong
degrees of freedom (should be 4, since we've estimated P this
time), so actually it's worse than that:

  ## 1-pchisq(17.744,4)
  ## [1] 0.001384664

though at 1.4e-3 it's still better than 1.3e-5!

Nevertheless, now that we've got the best-fitting binomial model,
the hypothesis that the numbers of male children in families of
size 5 is binomially distributed is clearly implausible.

Sufficient conditions for binomial distribution are
a) The genders of different births in the same family are
   independent of each other
b) The probability of "boy" is the same for all families.
Hence either (a) or (b) [or both] fails for these data.

I don't know of any way to force chisq.test() itself to take
account of degrees of freedom used up in estimation. chisq.test()
is a test for contingency tables (including a 1-row table tested
against a fixed given probability distribution).

Anyway, an indication of how the data fail to follow the best fitting
binomial distribution can be obtained by looking at

  X2T<-chisq.test(x[,2],p=dbinom(x[,1],5,P))
  cbind((0:5),X2T$expected,X2T$observed)
  ##       [,1]      [,2] [,3]
  ##  [1,]    0  443.9691  518
  ##  [2,]    1 2277.9893 2245
  ##  [3,]    2 4675.3120 4621
  ##  [4,]    3 4797.7711 4753
  ##  [5,]    4 2461.7188 2476
  ##  [6,]    5  505.2396  549


showing (at least) that there seem to be excess counts in
the "0" and "5" classes. This can be further clarified with

  n.E<-X2T$expected; n.O<-X2T$observed; Dev<-(n.O-n.E)/sqrt(n.E)
  cbind((0:5),X2T$expected,X2T$observed,Dev)
  ##                               Dev
  ##  [1,] 0  443.9691  518  3.5134726
  ##  [2,] 1 2277.9893 2245 -0.6911901
  ##  [3,] 2 4675.3120 4621 -0.7943114
  ##  [4,] 3 4797.7711 4753 -0.6463652
  ##  [5,] 4 2461.7188 2476  0.2878353
  ##  [6,] 5  505.2396  549  1.9468512

  sum(Dev^2)
  ##  [1] 17.74403
[agreeing with the 17.744 from chisq.test()]

Hence there seems to be a clear excess of all-girl families,
and some excess of all-boy families, but nothing obviously
remarkable about the others (which does not of course exclude
that there is a dependency between the genders of successive
births in these too).

Quite how you proceed further depends on how you wish to model
this dependency. See VGAM package for betabin.ab(), which fits
a beta-binomial (binomial where the probability P varies from
case [family] to case according to a beta-distribution), for
instance.

Hoping this helps,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 02-Dec-06                                       Time: 17:42:16
------------------------------ XFMail ------------------------------



From wjgoh at brookes.ac.uk  Sat Dec  2 18:53:40 2006
From: wjgoh at brookes.ac.uk (Wee-Jin Goh)
Date: Sat, 2 Dec 2006 17:53:40 +0000
Subject: [R] Trouble passing arrays to C code
In-Reply-To: <b0808fdc0612020717j63a253b8o88a4b6a8e952bd55@mail.gmail.com>
References: <08C1A7C9-F750-4C58-8324-576A40F05141@brookes.ac.uk>
	<b0808fdc0612020716g71c3ddf7j4bcb861379a29d7a@mail.gmail.com>
	<b0808fdc0612020717j63a253b8o88a4b6a8e952bd55@mail.gmail.com>
Message-ID: <00554B9D-3D5F-440D-932F-AD591A5F1416@brookes.ac.uk>

Thank you!!! That was the problem and now it's solved. Thanks for  
providing a fresh pair of eyes.

Regards,
Wee-Jin


On 2 Dec 2006, at 15:17, Antonio, Fabio Di Narzo wrote:


>
> here 'steps' is double, was integer in 'lorenz_run'.
>
> --
> Antonio, Fabio Di Narzo
> Ph.D. student at
> Department of Statistical Sciences
> University of Bologna, Italy
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From spencer.graves at pdf.com  Sat Dec  2 19:19:06 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 02 Dec 2006 10:19:06 -0800
Subject: [R] Quadratic Optimization
In-Reply-To: <Pine.LNX.4.64.0612021303270.8562@gannet.stats.ox.ac.uk>
References: <20061126223207.15485.qmail@web8414.mail.in.yahoo.com>
	<4570D714.4040708@pdf.com>
	<17777.21326.6043.444139@stat.math.ethz.ch>
	<Pine.LNX.4.64.0612021303270.8562@gannet.stats.ox.ac.uk>
Message-ID: <4571C39A.2030906@pdf.com>

Hi, Prof. Ripley: 

<snip>

>
> But that is a single equality quadratic constraint, and I believe 
> 'quadratic constraints' (note, plural) conventionally means multiple 
> inequality constraints.  That meaning is a hard problem that needs 
> specialized software (most likely using interior-point methods).
>
>>    SpG>       Maximize a'x subject to x'Ax=c.
>
> Not I believe the usual meaning (nor what Googling 'quadratic 
> constraints' came up with for me).
>
Thanks for the clarification.  Spencer Graves



From dmck at u.washington.edu  Sat Dec  2 20:28:45 2006
From: dmck at u.washington.edu (Don McKenzie)
Date: Sat, 2 Dec 2006 11:28:45 -0800
Subject: [R] package installation fails only for "sp"
In-Reply-To: <Pine.LNX.4.64.0612020730570.14260@gannet.stats.ox.ac.uk>
References: <4570BBFE.1050303@u.washington.edu>
	<Pine.LNX.4.64.0612020724520.14260@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0612020730570.14260@gannet.stats.ox.ac.uk>
Message-ID: <4AB83E51-4FEB-4676-A33D-15BAE5EB0EB2@u.washington.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061202/8ca357b6/attachment-0004.pl 

From bessa_ricardo at hotmail.com  Sat Dec  2 20:47:25 2006
From: bessa_ricardo at hotmail.com (Ricardo Bessa)
Date: Sat, 02 Dec 2006 19:47:25 +0000
Subject: [R] nonlinear quantile regression
Message-ID: <BAY23-F4ED86B198E914B50CDED196D90@phx.gbl>

Hello, I?m with a problem in using nonlinear quantile regression, the 
function nlrq.
I want to do a quantile regression o nonlinear function in the form 
a*log(x)-b, the coefficients ?a? and ?b? is my objective. I try to use the 
command:

funx <- function(x,a,b){
res <- a*log(x)-b
res
}

Dat.nlrq <- nlrq(y ~ funx(x, a, b), data=Dat, tau=0.25, trace=TRUE)

But a can?t solve de problem, How I put the formula ?y ~ funx(x,a,b)??

_________________________________________________________________
MSN Busca: f?cil, r?pido, direto ao ponto.  http://search.msn.com.br



From roger at ysidro.econ.uiuc.edu  Sat Dec  2 21:28:36 2006
From: roger at ysidro.econ.uiuc.edu (roger koenker)
Date: Sat, 2 Dec 2006 14:28:36 -0600
Subject: [R] nonlinear quantile regression
In-Reply-To: <BAY23-F4ED86B198E914B50CDED196D90@phx.gbl>
References: <BAY23-F4ED86B198E914B50CDED196D90@phx.gbl>
Message-ID: <DBA1F85B-CA54-496A-95D1-B9A94FF668AB@ysidro.econ.uiuc.edu>

This isn't a nonlinear QR problem.  You can write:

	f <- rq(y ~ log(x),  data=Dat, tau=0.25)

which corresponds to the model

	Q_y (.25|x)  =  a log(x) + b

note the sign convention on b.

url:    www.econ.uiuc.edu/~roger                Roger Koenker
email   rkoenker at uiuc.edu                       Department of Economics
vox:    217-333-4558                            University of Illinois
fax:    217-244-6678                            Champaign, IL 61820


On Dec 2, 2006, at 1:47 PM, Ricardo Bessa wrote:

> Hello, I?m with a problem in using nonlinear quantile regression, the
> function nlrq.
> I want to do a quantile regression o nonlinear function in the form
> a*log(x)-b, the coefficients ?a? and ?b? is my objective. I try to  
> use the
> command:
>
> funx <- function(x,a,b){
> res <- a*log(x)-b
> res
> }
>
> Dat.nlrq <- nlrq(y ~ funx(x, a, b), data=Dat, tau=0.25, trace=TRUE)
>
> But a can?t solve de problem, How I put the formula ?y ~ funx(x,a,b)??
>
> _________________________________________________________________
> MSN Busca: f?cil, r?pido, direto ao ponto.  http://search.msn.com.br
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From massimodisasha at yahoo.it  Fri Dec  1 23:04:16 2006
From: massimodisasha at yahoo.it (massimodisasha)
Date: Fri, 1 Dec 2006 23:04:16 +0100
Subject: [R] memeory problem?!
In-Reply-To: <270A8B45-F201-4C87-8EE3-79C4615EA9CD@yahoo.it>
References: <270A8B45-F201-4C87-8EE3-79C4615EA9CD@yahoo.it>
Message-ID: <31ED42ED-01BB-40C1-AA24-19EADA27DA25@yahoo.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061201/aad46e79/attachment-0004.pl 

From hassen62 at voila.fr  Sat Dec  2 21:32:13 2006
From: hassen62 at voila.fr (hassen62 at voila.fr)
Date: Sat,  2 Dec 2006 21:32:13 +0100 (CET)
Subject: [R] Problem with CH.test in uroot package
Message-ID: <8747042.1165091533967.JavaMail.www@wwinf4104>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061202/f47f3f4a/attachment-0004.pl 

From amit_605 at yahoo.co.in  Sat Dec  2 21:52:23 2006
From: amit_605 at yahoo.co.in (amit soni)
Date: Sun, 3 Dec 2006 02:22:23 +0530 (IST)
Subject: [R] Quadratic Optimization
Message-ID: <20061202205224.7305.qmail@web8414.mail.in.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061203/5e6dd24d/attachment-0004.pl 

From Roger.Bivand at nhh.no  Sat Dec  2 22:11:12 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 2 Dec 2006 22:11:12 +0100 (CET)
Subject: [R] memory problem [cluster]
In-Reply-To: <200612021007.47511.dylan.beaudette@gmail.com>
Message-ID: <Pine.LNX.4.44.0612022200140.14338-100000@reclus.nhh.no>

On Sat, 2 Dec 2006, Dylan Beaudette wrote:

> Hi Stephano,

Looks like you used my example verbatim 
(http://casoilresource.lawr.ucdavis.edu/drupal/node/221)

:)

>From exchanges on R-sig-geo, I believe the original questioner is feeding
NAs to clara, and the error message in clara() is overrunning the buffer
in sprintf(), so the memory problem isn't correctly identified. Using
scripts out of context without checking whether the input data frame 
satifies the conditions of the functions being used is asking for trouble. 
The error message:

 > traceback()
2: stop(ngettext(length(i), sprintf("Observation %d has", i[1]),
        sprintf("Observations %s have", paste(i, collapse = ","))),
        " *only* NAs --> omit for clustering")
1: clara(morph, k = 5, stand = F)

is coming from lines:

                i[1]), sprintf("Observations %s have", paste(i, 
                collapse = ","))), " *only* NAs --> omit for clustering")

in clara(). I have suggested dropping those rows from the data frame in a 
reply on R-sig-geo, but maybe clara() could be patched to count the # of 
completely missing rows, and if # is more than a modest number, not print 
the obs. numbers, just the total?

Roger


While my approach has not *yet* been published, the original source [4] by 
Roger Bivand certainly has. Just a reminder.

That said, I would highly recommend reading up on the background literature 
assocated with both the cluster package [1] and terrain classificartion i.e.
[2] and [3]. Note that although the clara() function was created to work on 
massive datasets, it is still possible to overwhelm the available memory with 
multiple gridded objects- recall that all R objects are held in memory.

I have asked the maintainer of the cluster package, Martin Maechler, about 
integrating a known medoid option into the clara() function- which would be 
extremely useful in adding some 'supervision' to landscape classification 
with clara(). Hopefully there will be enough requests for the feature, that 
Martin will kindly add it :) .

1. Kaufman, L. & Rousseeuw, P.J. Finding Groups in Data An Introduction to 
Cluster Analysis Wiley-Interscience, 2005

2. Blaszczynski, J. Landform characterization with geographical information 
systems Photogrammetric Engineering and Remote Sensing, 1997, 63, 183-191

3. Wood, W.F. & Snell, J.B. A Quatitative system for classifying landforms 
U.S. Quatermaster Research & Engineering Center, 1960

4. Bivand, R. Integrating GRASS 5.0 and R: GIS and modern statistics Computers 
& Geosciences, 2000, 26, 1043???1052


On Friday 01 December 2006 14:04, Massimo Di Stefano wrote:
> hi to all,
> frustated for this error, to day i buy a 1 GB memory
> slot for my laptop
> now it have 1,28GB instead the old 512, but i've the
> same error :-(
> damn!damn!....how can i do?
> repeat for a little area (about 20X20 km and res=20m)
> it work fine!
> have you any suggestion?
> is ther a method for look if this error depend from my
> ram or other....?
> thanks foe any suggestion!
> i need your help.
> thanks.
> Massimo
>
>
> Il giorno 01/dic/06, alle ore 16:05, massimodisasha ha
> scritto:
> hi,
> i'm trying to perform a clustering on a big dataframe
> the code is this:
>
>
> print("load required R packages")
>
> require(spgrass6)
>
> require(cluster)
>
> gmeta6 <- gmeta6()
>
> print("read in our 7 raster files from GRASS")
>
> x <-
> readFLOAT6sp(c("er","crosc","longc","slope","profc","minic","maxic"))
>
> print("assemble a matrix of our terrain variables")
>
> morph <- data.frame(cbind(x$er, x$crosc, x$longc,
> x$slope, x$profc, x$minic, x$maxic))
>
> print("normailize slope by dividing my max(slope)")
>
> morph <- data.frame(cbind(x$er, x$crosc, x$longc,
> x$slope/max(x$slope), x$profc, x$minic, x$maxic))
>
> names(morph) <-
> c("er","crosc","longc","slope_n","profc","minic","maxic")
>
> print("perform the clustering")
>
> morph.clara <- clara(morph, k=5, stand=F)
>
> x$morph_class <- morph.clara$clustering
>
> print("send result back to GRASS")
>
> rast.put6(x,"morph", zcol="morph_class")
>
>
>
> during the step : ....perform the clustering
> after a lot of time,
> i've this error:
>
>
>
>
> Errore in sprintf(fmt, ...) : La lunghezza della
> stringa eccede la dimensione del buffer di 8192
> Inoltre: Warning messages:
> 1: perl = TRUE ???? implementato solo nei locale UTF-8
> 2: perl = TRUE ???? implementato solo nei locale UTF-8
> 3: perl = TRUE ???? implementato solo nei locale UTF-8
> 4: perl = TRUE ???? implementato solo nei locale UTF-8
> 5: perl = TRUE ???? implementato solo nei locale UTF-8
> 6: perl = TRUE ???? implementato solo nei locale UTF-8
> 7: perl = TRUE ???? implementato solo nei locale UTF-8
> 8: La stringa di caratteri verr??  probabilmente
> troncata
> Esecuzione interrotta
>
>
>
> if i try the same code on a subregion of my data, it
> works very fine!
> but for a large region i've this error :-(
>
> obviously i think that is a memory problem, right ?
> (i'm working with a notebook PPC-1.33-512ram)
> my data are  : 7 raster-map on a region of about 50X40
> km at a resolution of 20m.
> is there some wolkaround about the memory problems?
>
> an other question is:
> what is this :
> Warning messages:
> 1: perl = TRUE ???? implementato solo nei locale UTF-8
> 2: perl = TRUE ???? implementato solo nei locale UTF-8
> 3: perl = TRUE ???? implementato solo nei locale UTF-8
> 4: perl = TRUE ???? implementato solo nei locale UTF-8
> 5: perl = TRUE ???? implementato solo nei locale UTF-8
> 6: perl = TRUE ???? implementato solo nei locale UTF-8
> 7: perl = TRUE ???? implementato solo nei locale UTF-8
>
> is it about this line of the code :
>
> morph.clara <- clara(morph, k=5, stand=F)
> i have an F > false
>
>
> thanks for any suggestion about,
>
> Massimo
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented, minimal,
> self-contained, reproducible code.

-- 
Dylan Beaudette
Soils and Biogeochemistry Graduate Group
University of California at Davis
530.754.7341

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Manuel.A.Morales at williams.edu  Sun Dec  3 02:26:59 2006
From: Manuel.A.Morales at williams.edu (Manuel Morales)
Date: Sat, 02 Dec 2006 20:26:59 -0500
Subject: [R] Force "square" crosstabulation
Message-ID: <1165109222.4713.5.camel@solidago.localdomain>

Hello list members,

I'm looking for a way to force the results of a crosstabulation to be
square - that is, to include 0 values.

For example:

table(letters[1:4],letters[c(1:3,3)])

yields:
    a b c
  a 1 0 0
  b 0 1 0
  c 0 0 1
  d 0 0 1

I would like to return:
    a b c d
  a 1 0 0 0
  b 0 1 0 0
  c 0 0 1 0
  d 0 0 1 0

Any suggestions?

Thanks!
-- 
Manuel A. Morales
http://mutualism.williams.edu
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: This is a digitally signed message part
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20061202/cbcc2f06/attachment-0005.bin 

From murdoch at stats.uwo.ca  Sun Dec  3 02:33:48 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 02 Dec 2006 20:33:48 -0500
Subject: [R] Force "square" crosstabulation
In-Reply-To: <1165109222.4713.5.camel@solidago.localdomain>
References: <1165109222.4713.5.camel@solidago.localdomain>
Message-ID: <4572297C.2050201@stats.uwo.ca>

On 12/2/2006 8:26 PM, Manuel Morales wrote:
> Hello list members,
> 
> I'm looking for a way to force the results of a crosstabulation to be
> square - that is, to include 0 values.
> 
> For example:
> 
> table(letters[1:4],letters[c(1:3,3)])
> 
> yields:
>     a b c
>   a 1 0 0
>   b 0 1 0
>   c 0 0 1
>   d 0 0 1
> 
> I would like to return:
>     a b c d
>   a 1 0 0 0
>   b 0 1 0 0
>   c 0 0 1 0
>   d 0 0 1 0
> 
> Any suggestions?

Force the categories to be factors.

 > fletters <- factor(letters[1:4])
 > table(fletters[1:4],fletters[c(1:3,3)])

     a b c d
   a 1 0 0 0
   b 0 1 0 0
   c 0 0 1 0
   d 0 0 1 0

The idea is that when you take subsets of factors, the levels stay the 
same, and table uses those levels for its categories.

Duncan Murdoch



From Bill.Venables at csiro.au  Sun Dec  3 04:57:56 2006
From: Bill.Venables at csiro.au (Bill.Venables at csiro.au)
Date: Sun, 3 Dec 2006 13:57:56 +1000
Subject: [R] Force "square" crosstabulation
Message-ID: <B998A44C8986644EA8029CFE6396A9248408D5@exqld2-bne.qld.csiro.au>

Use factors with specified levels.

> lev <- letters[1:4]
> table(factor(letters[1:4], levels = lev),
	   factor(letters[c(1:3,3)], levels = lev)) 
   
    a b c d
  a 1 0 0 0
  b 0 1 0 0
  c 0 0 1 0
  d 0 0 1 0

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Manuel Morales
Sent: Sunday, 3 December 2006 11:27 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Force "square" crosstabulation

Hello list members,

I'm looking for a way to force the results of a crosstabulation to be
square - that is, to include 0 values.

For example:

table(letters[1:4],letters[c(1:3,3)])

yields:
    a b c
  a 1 0 0
  b 0 1 0
  c 0 0 1
  d 0 0 1

I would like to return:
    a b c d
  a 1 0 0 0
  b 0 1 0 0
  c 0 0 1 0
  d 0 0 1 0

Any suggestions?

Thanks!
-- 
Manuel A. Morales
http://mutualism.williams.edu



From ethan.johnsons at gmail.com  Sun Dec  3 06:55:25 2006
From: ethan.johnsons at gmail.com (Ethan Johnsons)
Date: Sun, 3 Dec 2006 00:55:25 -0500
Subject: [R] prop.trend.test issue
Message-ID: <5cd96f050612022155l5dfc8e3en5b077a0600b87598@mail.gmail.com>

I have the clinical study data.

		                           Year 0 	Year 3
Retinol (nmol/L) 	N 	Mean +-sd 	Mean +-sd
Vitamin A group 	73 	1.89+-0.36 	2.06+-0.53
Trace group 	           57 	   1.83+-0.31 	  1.78+-0.30

where N is the number of male for the clinical study.

I want to test if the mean serum retinol has increased over 3 years
among subjects in the vitamin A group.

>  1.89+0.36
[1] 2.25
> 1.89-0.36
[1] 1.53
> 2.06+0.53
[1] 2.59
> 2.06-0.53
[1] 1.53


> prop.trend.test(c(2.25, 1.53),c( 2.59, 1.53))

        Chi-squared Test for Trend in Proportions

data:  c(2.25, 1.53) out of c(2.59, 1.53) ,
 using scores: 1 2
X-squared = 0.2189, df = 1, p-value = 0.6399

The issue I am seeing that N of Vitamin A group = 73 seems not reflected.
This leads me to think that I can't implement the test based on the
data just presented.
Nor a two-tailed test is possible.

        2-sample test for equality of proportions with continuity correction

data:  c(2.25, 1.53) out of c(2.59, 1.53)
X-squared = 0, df = 1, p-value = 1
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.6738203  0.4112720
sample estimates:
   prop 1    prop 2
0.8687259 1.0000000

Warning message:
Chi-squared approximation may be incorrect in: prop.test(c(2.25,
1.53), c(2.59, 1.53))

Any ideas, please?

thx

ej



From phgrosjean at sciviews.org  Sun Dec  3 12:25:36 2006
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Sun, 03 Dec 2006 12:25:36 +0100
Subject: [R] nonlinear quantile regression
In-Reply-To: <BAY23-F4ED86B198E914B50CDED196D90@phx.gbl>
References: <BAY23-F4ED86B198E914B50CDED196D90@phx.gbl>
Message-ID: <4572B430.2020909@sciviews.org>

You must specify starting conditions.

PhG

Ricardo Bessa wrote:
> Hello, I?m with a problem in using nonlinear quantile regression, the 
> function nlrq.
> I want to do a quantile regression o nonlinear function in the form 
> a*log(x)-b, the coefficients ?a? and ?b? is my objective. I try to use the 
> command:
> 
> funx <- function(x,a,b){
> res <- a*log(x)-b
> res
> }
> 
> Dat.nlrq <- nlrq(y ~ funx(x, a, b), data=Dat, tau=0.25, trace=TRUE)
> 
> But a can?t solve de problem, How I put the formula ?y ~ funx(x,a,b)??
> 
> _________________________________________________________________
> MSN Busca: f?cil, r?pido, direto ao ponto.  http://search.msn.com.br
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From info at aghmed.fsnet.co.uk  Sun Dec  3 13:26:52 2006
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Sun, 03 Dec 2006 12:26:52 +0000
Subject: [R] prop.trend.test issue
In-Reply-To: <5cd96f050612022155l5dfc8e3en5b077a0600b87598@mail.gmail.co
 m>
References: <5cd96f050612022155l5dfc8e3en5b077a0600b87598@mail.gmail.com>
Message-ID: <7.0.0.16.0.20061203122539.019a4eb8@aghmed.fsnet.co.uk>

At 05:55 03/12/2006, Ethan Johnsons wrote:
>I have the clinical study data.
>
>                                            Year 0       Year 3
>Retinol (nmol/L)        N       Mean +-sd       Mean +-sd
>Vitamin A group         73      1.89+-0.36      2.06+-0.53
>Trace group                57      1.83+-0.31     1.78+-0.30
>
>where N is the number of male for the clinical study.
>
>I want to test if the mean serum retinol has increased over 3 years
>among subjects in the vitamin A group.

If you want to test means why did you think a test for proportions 
was a good idea?


>>  1.89+0.36
>[1] 2.25
>>1.89-0.36
>[1] 1.53
>>2.06+0.53
>[1] 2.59
>>2.06-0.53
>[1] 1.53
>
>
>>prop.trend.test(c(2.25, 1.53),c( 2.59, 1.53))
>
>        Chi-squared Test for Trend in Proportions
>
>data:  c(2.25, 1.53) out of c(2.59, 1.53) ,
>using scores: 1 2
>X-squared = 0.2189, df = 1, p-value = 0.6399
>
>The issue I am seeing that N of Vitamin A group = 73 seems not reflected.
>This leads me to think that I can't implement the test based on the
>data just presented.
>Nor a two-tailed test is possible.
>
>        2-sample test for equality of proportions with continuity correction
>
>data:  c(2.25, 1.53) out of c(2.59, 1.53)
>X-squared = 0, df = 1, p-value = 1
>alternative hypothesis: two.sided
>95 percent confidence interval:
>-0.6738203  0.4112720
>sample estimates:
>   prop 1    prop 2
>0.8687259 1.0000000
>
>Warning message:
>Chi-squared approximation may be incorrect in: prop.test(c(2.25,
>1.53), c(2.59, 1.53))
>
>Any ideas, please?
>
>thx
>
>ej
>
>

Michael Dewey
http://www.aghmed.fsnet.co.uk



From ethan.johnsons at gmail.com  Sun Dec  3 14:46:33 2006
From: ethan.johnsons at gmail.com (Ethan Johnsons)
Date: Sun, 3 Dec 2006 08:46:33 -0500
Subject: [R] prop.trend.test issue
In-Reply-To: <7.0.0.16.0.20061203122539.019a4eb8@aghmed.fsnet.co.uk>
References: <5cd96f050612022155l5dfc8e3en5b077a0600b87598@mail.gmail.com>
	<7.0.0.16.0.20061203122539.019a4eb8@aghmed.fsnet.co.uk>
Message-ID: <5cd96f050612030546q23db3748w27d5500d56e30333@mail.gmail.com>

I don't find any other test avail for this?
Am I missing something?

thx

ej

On 12/3/06, Michael Dewey <info at aghmed.fsnet.co.uk> wrote:
> At 05:55 03/12/2006, Ethan Johnsons wrote:
> >I have the clinical study data.
> >
> >                                            Year 0       Year 3
> >Retinol (nmol/L)        N       Mean +-sd       Mean +-sd
> >Vitamin A group         73      1.89+-0.36      2.06+-0.53
> >Trace group                57      1.83+-0.31     1.78+-0.30
> >
> >where N is the number of male for the clinical study.
> >
> >I want to test if the mean serum retinol has increased over 3 years
> >among subjects in the vitamin A group.
>
> If you want to test means why did you think a test for proportions
> was a good idea?
>
>
> >>  1.89+0.36
> >[1] 2.25
> >>1.89-0.36
> >[1] 1.53
> >>2.06+0.53
> >[1] 2.59
> >>2.06-0.53
> >[1] 1.53
> >
> >
> >>prop.trend.test(c(2.25, 1.53),c( 2.59, 1.53))
> >
> >        Chi-squared Test for Trend in Proportions
> >
> >data:  c(2.25, 1.53) out of c(2.59, 1.53) ,
> >using scores: 1 2
> >X-squared = 0.2189, df = 1, p-value = 0.6399
> >
> >The issue I am seeing that N of Vitamin A group = 73 seems not reflected.
> >This leads me to think that I can't implement the test based on the
> >data just presented.
> >Nor a two-tailed test is possible.
> >
> >        2-sample test for equality of proportions with continuity correction
> >
> >data:  c(2.25, 1.53) out of c(2.59, 1.53)
> >X-squared = 0, df = 1, p-value = 1
> >alternative hypothesis: two.sided
> >95 percent confidence interval:
> >-0.6738203  0.4112720
> >sample estimates:
> >   prop 1    prop 2
> >0.8687259 1.0000000
> >
> >Warning message:
> >Chi-squared approximation may be incorrect in: prop.test(c(2.25,
> >1.53), c(2.59, 1.53))
> >
> >Any ideas, please?
> >
> >thx
> >
> >ej
> >
> >
>
> Michael Dewey
> http://www.aghmed.fsnet.co.uk
>
>



From m4lawren at artsmail.uwaterloo.ca  Sun Dec  3 15:33:05 2006
From: m4lawren at artsmail.uwaterloo.ca (Mike Lawrence)
Date: Sun, 03 Dec 2006 09:33:05 -0500
Subject: [R] nnet() fit criteria
Message-ID: <4572E021.5070302@artsmail.uwaterloo.ca>

Hi all,

I'm using nnet() for non-linear regression as in Ch8.10 of MASS. I 
understand that nnet() by default optimizes least squares. I'm looking 
to have it instead optimize such that the mean error is zero (so that it 
is unbiased). Any suggestions on how this might be achieved?

Cheers,

Mike

-- 
Mike Lawrence
http://artsweb.uwaterloo.ca/~m4lawren

"The road to wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
- Piet Hein



From ligges at statistik.uni-dortmund.de  Sun Dec  3 16:23:40 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 03 Dec 2006 16:23:40 +0100
Subject: [R] Problem with CH.test in uroot package
In-Reply-To: <8747042.1165091533967.JavaMail.www@wwinf4104>
References: <8747042.1165091533967.JavaMail.www@wwinf4104>
Message-ID: <4572EBFC.4060408@statistik.uni-dortmund.de>

This seems to be a bug, hence send the bug report to the package 
maintainer (CCing) - or even better fix it yourself and send the patch 
to the package maintainer.

Uwe Ligges

hassen62 at voila.fr wrote:
> Dear friends, I installed the package ???uroot??? then I wrote library (uroot) and I entered a series entitled extp, in spite of that the problem persite. In short,here are what I wrote and the message that I obtained: 
>> library(uroot)
>> extp=c(1,3,10,14,12,5,8,12,13,15,9,8,7,10,9,7,3,10,3,11,12,7,4,9,8,10,20,17)
>> CH.test (wts=extp, frec=c(1,1), f0=1, DetTr=FALSE, ltrunc=NULL)
> Erreur dans seq.default(2, qq * 2, 2) : signe incorrect de l'argument 'by'
> 
> The last line wants to say that there is incorrect sign of the argument ???by???
> Which will be your suggestions, thank you.
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From neuro3000 at hotmail.com  Sun Dec  3 17:16:18 2006
From: neuro3000 at hotmail.com (=?iso-8859-1?B?TmV1cm8gTGVTdXBlckjpcm9z?=)
Date: Sun, 03 Dec 2006 11:16:18 -0500
Subject: [R] newbie: new_data_frame <- selected set of rows
In-Reply-To: <26270.41152.qm@web90413.mail.mud.yahoo.com>
Message-ID: <BAY131-F9478B83257A5137471CC0AFD80@phx.gbl>



#Mock df creation
my_dataframe <-data.frame(matrix(runif(14*5),14,5))
row.names(my_dataframe) <-paste("ENSP",1:14,sep="")
distances <-c(13,14,10 ,11,  2,  4,  6,  1,  3,  9,  8, 12,  7,  5)

head(my_dataframe[order(distances),],5)


>From: Darek Kedra <darked90 at yahoo.com>
>To: r-help at stat.math.ethz.ch
>Subject: Re: [R] newbie: new_data_frame <- selected set of rows
>Date: Fri, 1 Dec 2006 14:52:25 -0800 (PST)
>
>Two missing things:
>
> >distances
>  [1] 13 14 10 11  2  4  6  1  3  9  8 12  7  5
>
>#numbers correspond to rows in my_dataframe
>
> > my_dataframe
>                       V2         V3         V4
>V5         V6
>ENSP00000354687 35660.45 0.04794521 0.05479452
>0.06849315 0.07534247
>ENSP00000355046 38942.77 0.02967359 0.04451039
>0.04451039 0.06824926
>ENSP00000354499 57041.21 0.04700855 0.08760684
>0.11965812 0.06196581
>
>ENSP00000354687 etc are rownames.
>
>I am trying to get top five row names with smallest
>distances from a given vector as calculated by
>distancevector from hopach.
>
>
>
>Darek Kedra
>
>
>
>
>
>
>____________________________________________________________________________________
>Cheap talk?
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide 
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From ripley at stats.ox.ac.uk  Sun Dec  3 18:41:10 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 3 Dec 2006 17:41:10 +0000 (GMT)
Subject: [R] nnet() fit criteria
In-Reply-To: <4572E021.5070302@artsmail.uwaterloo.ca>
References: <4572E021.5070302@artsmail.uwaterloo.ca>
Message-ID: <Pine.LNX.4.64.0612031650300.8752@gannet.stats.ox.ac.uk>

On Sun, 3 Dec 2006, Mike Lawrence wrote:

> I'm using nnet() for non-linear regression as in Ch8.10 of MASS. I
> understand that nnet() by default optimizes least squares. I'm looking
> to have it instead optimize such that the mean error is zero (so that it
> is unbiased). Any suggestions on how this might be achieved?

What makes you think least-squares does not achieve that?  At a guess you 
mean the average prediction error over the training data in a regression 
problem, and any non-linear regression with an intercept term achieves 
that.  But 'it is unbiased' needs futher statements including what the 
model is that what 'it' is supposed to be estimating unbiasedly in that 
model.

Now for a non-linear regression you should be using linout = TRUE (as in 
the reference you give), and then you do have a 'non-linear regression 
with an intercept term'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From info at aghmed.fsnet.co.uk  Sun Dec  3 19:36:20 2006
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Sun, 03 Dec 2006 18:36:20 +0000
Subject: [R] prop.trend.test issue
In-Reply-To: <5cd96f050612030546q23db3748w27d5500d56e30333@mail.gmail.co
 m>
References: <5cd96f050612022155l5dfc8e3en5b077a0600b87598@mail.gmail.com>
	<7.0.0.16.0.20061203122539.019a4eb8@aghmed.fsnet.co.uk>
	<5cd96f050612030546q23db3748w27d5500d56e30333@mail.gmail.com>
Message-ID: <7.0.0.16.0.20061203183417.019977c0@aghmed.fsnet.co.uk>

At 13:46 03/12/2006, Ethan Johnsons wrote:
>I don't find any other test avail for this?
>Am I missing something?

I do not want to seem unhelpful but the only response that springs to 
mind is a knowledge of statistics.

I hope people's lives are not at stake with the results of your analysis

>thx
>
>ej
>
>On 12/3/06, Michael Dewey <info at aghmed.fsnet.co.uk> wrote:
>>At 05:55 03/12/2006, Ethan Johnsons wrote:
>> >I have the clinical study data.
>> >
>> >                                            Year 0       Year 3
>> >Retinol (nmol/L)        N       Mean +-sd       Mean +-sd
>> >Vitamin A group         73      1.89+-0.36      2.06+-0.53
>> >Trace group                57      1.83+-0.31     1.78+-0.30
>> >
>> >where N is the number of male for the clinical study.
>> >
>> >I want to test if the mean serum retinol has increased over 3 years
>> >among subjects in the vitamin A group.
>>
>>If you want to test means why did you think a test for proportions
>>was a good idea?
>>
>>
>> >>  1.89+0.36
>> >[1] 2.25
>> >>1.89-0.36
>> >[1] 1.53
>> >>2.06+0.53
>> >[1] 2.59
>> >>2.06-0.53
>> >[1] 1.53
>> >
>> >
>> >>prop.trend.test(c(2.25, 1.53),c( 2.59, 1.53))
>> >
>> >        Chi-squared Test for Trend in Proportions
>> >
>> >data:  c(2.25, 1.53) out of c(2.59, 1.53) ,
>> >using scores: 1 2
>> >X-squared = 0.2189, df = 1, p-value = 0.6399
>> >
>> >The issue I am seeing that N of Vitamin A group = 73 seems not reflected.
>> >This leads me to think that I can't implement the test based on the
>> >data just presented.
>> >Nor a two-tailed test is possible.
>> >
>> >        2-sample test for equality of proportions with continuity 
>> correction
>> >
>> >data:  c(2.25, 1.53) out of c(2.59, 1.53)
>> >X-squared = 0, df = 1, p-value = 1
>> >alternative hypothesis: two.sided
>> >95 percent confidence interval:
>> >-0.6738203  0.4112720
>> >sample estimates:
>> >   prop 1    prop 2
>> >0.8687259 1.0000000
>> >
>> >Warning message:
>> >Chi-squared approximation may be incorrect in: prop.test(c(2.25,
>> >1.53), c(2.59, 1.53))
>> >
>> >Any ideas, please?
>> >
>> >thx
>> >
>> >ej
>> >
>> >
>>
>>Michael Dewey
>>http://www.aghmed.fsnet.co.uk
>>
>
>
>
>--
>No virus found in this incoming message.
>Checked by AVG Free Edition.
>Version: 7.5.431 / Virus Database: 268.15.3/562 - Release Date: 
>01/12/2006 13:12

Michael Dewey
http://www.aghmed.fsnet.co.uk



From cgillies at ualberta.ca  Sun Dec  3 19:58:18 2006
From: cgillies at ualberta.ca (Cameron Gillies)
Date: Sun, 03 Dec 2006 11:58:18 -0700
Subject: [R] lmer and a response that is a proportion
Message-ID: <C1986C5A.1372%cgillies@ualberta.ca>

Greetings all,

I am using lmer (lme4 package) to analyze data where the response is a
proportion (0 to 1).  It appears to work, but I am wondering if the analysis
is treating the response appropriately - i.e. can lmer do this?

I have used both family=binomial and quasibinomial - is one more appropriate
when the response is a proportion?  The coefficient estimates are identical,
but the standard errors are larger with family=binomial.

Thanks very much for any insight you may have!
Cam


Cam Gillies
PhD Candidate
Biological Sciences
University of Alberta



From aiminy at iastate.edu  Sun Dec  3 20:36:45 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Sun, 03 Dec 2006 13:36:45 -0600
Subject: [R] R_WinEdt question
Message-ID: <6.1.2.0.2.20061203133326.01ce9888@aiminy.mail.iastate.edu>

Hello,
I am new to R-WinEdt. Here is my code. If I don't want see output for 
summary(mp) in my final document, just want to run it.
How to modify these code?

Thanks,

Aimin Yan

<<R code,echo=FALSE>>=
library(MASS)
options(contrasts=c("contr.treatment","contr.poly"))
p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")

p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
attach(p5)
mp<-glm(Y~P-1,data=p5)
summary(mp)
@



From rolf at math.unb.ca  Sun Dec  3 21:10:21 2006
From: rolf at math.unb.ca (rolf at math.unb.ca)
Date: Sun, 3 Dec 2006 16:10:21 -0400 (AST)
Subject: [R] prop.trend.test issue
Message-ID: <200612032010.kB3KALoo005671@weisner.math.unb.ca>

Michael Dewey wrote:

> At 13:46 03/12/2006, Ethan Johnsons wrote:
> 
> >I don't find any other test avail for this?
> >Am I missing something?
> 
> I do not want to seem unhelpful but the only response that springs to 
> mind is a knowledge of statistics.
> 
> I hope people's lives are not at stake with the results of your analysis

	Amen, brother.  Well said.

	Another response springs to *my* mind but it is just as well
	to suppress it.

				cheers,

					Rolf Turner



From nbvale at gmail.com  Sun Dec  3 21:51:05 2006
From: nbvale at gmail.com (Nuno Vale)
Date: Sun, 3 Dec 2006 20:51:05 +0000
Subject: [R] Modify package AMORE
Message-ID: <84ef61090612031251r48fcadb5n5d2f6de2bdd58cd6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061203/0838a274/attachment-0004.pl 

From jeffmiller at adsam.com  Sun Dec  3 21:57:46 2006
From: jeffmiller at adsam.com (Jeff Miller)
Date: Sun, 3 Dec 2006 15:57:46 -0500
Subject: [R] creating column based on another variable
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAEuLs8ZPMuFInPbB+1JmPy7CgAAAEAAAAFlGOuVXOglMl9dsiAiWt/kBAAAAAA==@adsam.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061203/c8359e46/attachment-0004.pl 

From jfox at mcmaster.ca  Sun Dec  3 23:10:17 2006
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 3 Dec 2006 17:10:17 -0500
Subject: [R] lmer and a response that is a proportion
In-Reply-To: <C1986C5A.1372%cgillies@ualberta.ca>
Message-ID: <20061203221015.BDNX6280.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear Cameron,

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Cameron Gillies
> Sent: Sunday, December 03, 2006 1:58 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] lmer and a response that is a proportion
> 
> Greetings all,
> 
> I am using lmer (lme4 package) to analyze data where the 
> response is a proportion (0 to 1).  It appears to work, but I 
> am wondering if the analysis is treating the response 
> appropriately - i.e. can lmer do this?
>

As far as I know, you can specify the response as a proportion, in which
case the binomial counts would be given via the weights argument -- at least
that's how it's done in glm(). An alternative that should be equivalent is
to specify a two-column matrix with counts of "successes" and "failures" as
the response. Simply giving the proportion of successes without the counts
wouldn't be appropriate.
 
> I have used both family=binomial and quasibinomial - is one 
> more appropriate when the response is a proportion?  The 
> coefficient estimates are identical, but the standard errors 
> are larger with family=binomial.
>

The difference is that in the binomial family the dispersion is fixed to 1,
while in the quasibinomial family it is estimated as a free parameter. If
the standard errors are larger with family=binomial, then that suggests that
the data are underdispersed (relative to the binomial); if the difference is
substantial -- the factor is just the square root of the estimated
dispersion -- then the binomial model is probably not appropriate for the
data.

I hope this helps,
 John
 
> Thanks very much for any insight you may have!
> Cam
> 
> 
> Cam Gillies
> PhD Candidate
> Biological Sciences
> University of Alberta
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From collins.gs at gmail.com  Sun Dec  3 23:28:46 2006
From: collins.gs at gmail.com (Gary Collins)
Date: Sun, 3 Dec 2006 22:28:46 +0000
Subject: [R] passing an argument to a function which is also to be a
	dataframe column name
Message-ID: <dd6040c90612031428g6a1472cv332bd7ebbf1e32c2@mail.gmail.com>

any suggestions on the following gratefully welcome,

I have a dataframe, which I am subsetting via labels

atpi[, creativity]

where (for example)

atpi = as.data.frame(matrix(1:50, ncol = 5, nrow = 10))
names(atpi) = c("Q1", "Q2", "Q3", "Q4", "Q5")

and

creativity = c("Q1", "Q3", "Q4")

I want to add an extra column to the dataframe atpi labelled "creativity",
which is the rowsum of these 3 columns.  My problem is not the rowsum but
but the passing of an argument to a function, which is being used for subsetting
but also for labelling the rowsum column. I can do a one-off hack for
creativity,
but I want to generalise this, as I have numerous subsets
like creativity) to calculate and some pre-processiing (imputing
missing data etc)...
so I'm looking for something simple along the lines of

scoring = function(x, A){
	x[, A] = rowSums(x[, A])
	x
}

where a call such as

scoring(atpi, creativity)

would produce something along the lines of

> atpi
   Q1 Q2 Q3 Q4 Q5 creativity
1   1 11 21 31 41         53
2   2 12 22 32 42         56
3   3 13 23 33 43         59
4   4 14 24 34 44         62
5   5 15 25 35 45         65
6   6 16 26 36 46         68
7   7 17 27 37 47         71
8   8 18 28 38 48         74
9   9 19 29 39 49         77
10 10 20 30 40 50         80

Thanks in advance

Gary



From ripley at stats.ox.ac.uk  Sun Dec  3 23:46:03 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 3 Dec 2006 22:46:03 +0000 (GMT)
Subject: [R] passing an argument to a function which is also to be a
 dataframe column name
In-Reply-To: <dd6040c90612031428g6a1472cv332bd7ebbf1e32c2@mail.gmail.com>
References: <dd6040c90612031428g6a1472cv332bd7ebbf1e32c2@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0612032242500.12560@gannet.stats.ox.ac.uk>

I think you want

scoring <- function(x, A){
    nm <- deparse(substitute(A))
    x[, nm] <- rowSums(x[, A])
    x
}


On Sun, 3 Dec 2006, Gary Collins wrote:

> any suggestions on the following gratefully welcome,
>
> I have a dataframe, which I am subsetting via labels
>
> atpi[, creativity]
>
> where (for example)
>
> atpi = as.data.frame(matrix(1:50, ncol = 5, nrow = 10))
> names(atpi) = c("Q1", "Q2", "Q3", "Q4", "Q5")
>
> and
>
> creativity = c("Q1", "Q3", "Q4")
>
> I want to add an extra column to the dataframe atpi labelled "creativity",
> which is the rowsum of these 3 columns.  My problem is not the rowsum but
> but the passing of an argument to a function, which is being used for subsetting
> but also for labelling the rowsum column. I can do a one-off hack for
> creativity,
> but I want to generalise this, as I have numerous subsets
> like creativity) to calculate and some pre-processiing (imputing
> missing data etc)...
> so I'm looking for something simple along the lines of
>
> scoring = function(x, A){
> 	x[, A] = rowSums(x[, A])
> 	x
> }
>
> where a call such as
>
> scoring(atpi, creativity)
>
> would produce something along the lines of
>
>> atpi
>   Q1 Q2 Q3 Q4 Q5 creativity
> 1   1 11 21 31 41         53
> 2   2 12 22 32 42         56
> 3   3 13 23 33 43         59
> 4   4 14 24 34 44         62
> 5   5 15 25 35 45         65
> 6   6 16 26 36 46         68
> 7   7 17 27 37 47         71
> 8   8 18 28 38 48         74
> 9   9 19 29 39 49         77
> 10 10 20 30 40 50         80
>
> Thanks in advance
>
> Gary
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Dec  3 23:47:43 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 3 Dec 2006 22:47:43 +0000 (GMT)
Subject: [R] lmer and a response that is a proportion
In-Reply-To: <20061203221015.BDNX6280.tomts25-srv.bellnexxia.net@JohnDesktop8300>
References: <20061203221015.BDNX6280.tomts25-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <Pine.LNX.4.64.0612032228510.12560@gannet.stats.ox.ac.uk>

On Sun, 3 Dec 2006, John Fox wrote:

> Dear Cameron,
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Cameron Gillies
>> Sent: Sunday, December 03, 2006 1:58 PM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] lmer and a response that is a proportion
>>
>> Greetings all,
>>
>> I am using lmer (lme4 package) to analyze data where the
>> response is a proportion (0 to 1).  It appears to work, but I
>> am wondering if the analysis is treating the response
>> appropriately - i.e. can lmer do this?
>>
>
> As far as I know, you can specify the response as a proportion, in which
> case the binomial counts would be given via the weights argument -- at least
> that's how it's done in glm(). An alternative that should be equivalent is
> to specify a two-column matrix with counts of "successes" and "failures" as
> the response. Simply giving the proportion of successes without the counts
> wouldn't be appropriate.
>
>> I have used both family=binomial and quasibinomial - is one
>> more appropriate when the response is a proportion?  The
>> coefficient estimates are identical, but the standard errors
>> are larger with family=binomial.
>>
>
> The difference is that in the binomial family the dispersion is fixed to 1,
> while in the quasibinomial family it is estimated as a free parameter. If
> the standard errors are larger with family=binomial, then that suggests that
> the data are underdispersed (relative to the binomial); if the difference is
> substantial -- the factor is just the square root of the estimated
> dispersion -- then the binomial model is probably not appropriate for the
> data.

John's last deduction is appropriate to a GLM, but not necessarily to a 
GLMM. I don't have detailed experience with lmer for binomial, but I do 
for various other fitting routines for GLMM.  Remember there are at least 
two sources of randomness in a GLMM, and let us keep it simple and have 
just a subject effect and a measurement error.  Then if over-dispersion is 
happening within subjects, forcing the binomial dispersion (at the 
measurement level) to 1 tends to increase the estimate of the 
subject-level variance component to compensate, and in turn increase some
of the standard errors.

(Please note the 'tends' in that para, as the details of the design do 
matter.  For cognescenti, think about plot and sub-plot treatments in a 
split-plot design.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kubovy at virginia.edu  Mon Dec  4 00:10:40 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Sun, 3 Dec 2006 18:10:40 -0500
Subject: [R] overplot() examples fail (package:gplots)
Message-ID: <343C0A06-CF4A-4050-9663-9322F5508C86@virginia.edu>

require(gplots)
data(rtPCR)

overplot( RQ ~ Conc..ug.ml. | Test.Substance,
	data=rtPCR,
	subset=Detector=="ProbeType 7" & Conc..ug.ml. > 0,
	same.scale=TRUE, log="xy", f=3/4,
	main="Detector=ProbeType 7",
	xlab="Concentration (ug/ml)",
	ylab="Relative Gene Quantification"
)

# Error in lowess.default(mf[[-response]], mf[[response]], f = f,  
iter = iter,  :
# 	'x' is empty
# In addition: Warning messages:
# 1: no non-missing arguments to min; returning Inf
# 2: no non-missing arguments to max; returning -Inf

**************************************
# The second example fails as well, but with:
# Error in plot.window(xlim, ylim, log, asp, ...) :
# 	need finite 'ylim' values
# In addition: Warning messages:
# 1: no non-missing arguments to min; returning Inf
# 2: no non-missing arguments to max; returning -Inf

**************************************
R version 2.4.0 (2006-10-03)
powerpc-apple-darwin8.7.0

locale:
C

attached base packages:
[1] "splines"   "grid"      "methods"   "utils"     "stats"      
"graphics"  "grDevices" "datasets"
[9] "base"

other attached packages:
     gplots      gdata     gtools       lme4        gam     
effects      Hmisc       coda    gmodels
    "2.3.2"    "2.3.1"    "2.3.0" "0.9975-9"     "0.97"    "1.0-9"     
"3.1-2"   "0.10-7"   "2.13.1"
     Matrix    reshape        JGR     iplots     JavaGD       
rJava       MASS    lattice
"0.9975-6"    "0.7.1"   "1.4-13"    "1.0-5"    "0.3-5"   "0.4-12"    
"7.2-30"  "0.14-15"

_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/



From cgillies at ualberta.ca  Mon Dec  4 00:30:46 2006
From: cgillies at ualberta.ca (Cameron Gillies)
Date: Sun, 03 Dec 2006 16:30:46 -0700
Subject: [R] lmer and a response that is a proportion
In-Reply-To: <Pine.LNX.4.64.0612032228510.12560@gannet.stats.ox.ac.uk>
Message-ID: <C198AC36.137C%cgillies@ualberta.ca>

Dear Brian and John,

Thanks for your insight.  I'll clarify a couple of things incase it changes
your advice.

My response is a ratio of two measures taken during a bird's path, which
varies from 0  to 1, so I cannot convert it columns of the number of
successes.  It has to be reported as the proportion.  I could logit
transform it to make it normal, but I am trying to avoid that so I can
analyze it directly.

The subjects are individual birds and I have a range of sample sizes from
each bird (from 8 to >200, average of about 75 measurements/bird).

Thanks!
Cam


On 12/3/06 3:47 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:

> On Sun, 3 Dec 2006, John Fox wrote:
> 
>> Dear Cameron,
>> 
>>> -----Original Message-----
>>> From: r-help-bounces at stat.math.ethz.ch
>>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Cameron Gillies
>>> Sent: Sunday, December 03, 2006 1:58 PM
>>> To: r-help at stat.math.ethz.ch
>>> Subject: [R] lmer and a response that is a proportion
>>> 
>>> Greetings all,
>>> 
>>> I am using lmer (lme4 package) to analyze data where the
>>> response is a proportion (0 to 1).  It appears to work, but I
>>> am wondering if the analysis is treating the response
>>> appropriately - i.e. can lmer do this?
>>> 
>> 
>> As far as I know, you can specify the response as a proportion, in which
>> case the binomial counts would be given via the weights argument -- at least
>> that's how it's done in glm(). An alternative that should be equivalent is
>> to specify a two-column matrix with counts of "successes" and "failures" as
>> the response. Simply giving the proportion of successes without the counts
>> wouldn't be appropriate.
>> 
>>> I have used both family=binomial and quasibinomial - is one
>>> more appropriate when the response is a proportion?  The
>>> coefficient estimates are identical, but the standard errors
>>> are larger with family=binomial.
>>> 
>> 
>> The difference is that in the binomial family the dispersion is fixed to 1,
>> while in the quasibinomial family it is estimated as a free parameter. If
>> the standard errors are larger with family=binomial, then that suggests that
>> the data are underdispersed (relative to the binomial); if the difference is
>> substantial -- the factor is just the square root of the estimated
>> dispersion -- then the binomial model is probably not appropriate for the
>> data.
> 
> John's last deduction is appropriate to a GLM, but not necessarily to a
> GLMM. I don't have detailed experience with lmer for binomial, but I do
> for various other fitting routines for GLMM.  Remember there are at least
> two sources of randomness in a GLMM, and let us keep it simple and have
> just a subject effect and a measurement error.  Then if over-dispersion is
> happening within subjects, forcing the binomial dispersion (at the
> measurement level) to 1 tends to increase the estimate of the
> subject-level variance component to compensate, and in turn increase some
> of the standard errors.
> 
> (Please note the 'tends' in that para, as the details of the design do
> matter.  For cognescenti, think about plot and sub-plot treatments in a
> split-plot design.)



From jfox at mcmaster.ca  Mon Dec  4 03:24:19 2006
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 3 Dec 2006 21:24:19 -0500
Subject: [R] lmer and a response that is a proportion
In-Reply-To: <C198AC36.137C%cgillies@ualberta.ca>
Message-ID: <20061204022416.GXIN17401.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Cameron,

Given your description, I thought that this might be the case. 

I'd first examine the distribution of the response variable to see what it
looks like. If the values don't push the boundaries of 0 and 1, and their
distribution is unimodal and reasonably symmetric, I'd consider analyzing
them directly using normally distributed errors. If the values do stack up
near 0, 1, or both, I'd consider a transformation, or perhaps a different
family (depending on the pattern); in particular, if they stack up near both
0 and 1, a logit or similar transformation could help. Finally, if you have
many values of 0, 1, or both, then a transformation isn't promising (and,
indeed, the logit wouldn't be defined for these values). In any event, I'd
check diagnostics after a preliminary fit.

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: Cameron Gillies [mailto:cgillies at ualberta.ca] 
> Sent: Sunday, December 03, 2006 6:31 PM
> To: Prof Brian Ripley; John Fox
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] lmer and a response that is a proportion
> 
> Dear Brian and John,
> 
> Thanks for your insight.  I'll clarify a couple of things 
> incase it changes your advice.
> 
> My response is a ratio of two measures taken during a bird's 
> path, which varies from 0  to 1, so I cannot convert it 
> columns of the number of successes.  It has to be reported as 
> the proportion.  I could logit transform it to make it 
> normal, but I am trying to avoid that so I can analyze it directly.
> 
> The subjects are individual birds and I have a range of 
> sample sizes from each bird (from 8 to >200, average of about 
> 75 measurements/bird).
> 
> Thanks!
> Cam
> 
> 
> On 12/3/06 3:47 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:
> 
> > On Sun, 3 Dec 2006, John Fox wrote:
> > 
> >> Dear Cameron,
> >> 
> >>> -----Original Message-----
> >>> From: r-help-bounces at stat.math.ethz.ch 
> >>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Cameron 
> >>> Gillies
> >>> Sent: Sunday, December 03, 2006 1:58 PM
> >>> To: r-help at stat.math.ethz.ch
> >>> Subject: [R] lmer and a response that is a proportion
> >>> 
> >>> Greetings all,
> >>> 
> >>> I am using lmer (lme4 package) to analyze data where the 
> response is 
> >>> a proportion (0 to 1).  It appears to work, but I am wondering if 
> >>> the analysis is treating the response appropriately - 
> i.e. can lmer 
> >>> do this?
> >>> 
> >> 
> >> As far as I know, you can specify the response as a proportion, in 
> >> which case the binomial counts would be given via the weights 
> >> argument -- at least that's how it's done in glm(). An alternative 
> >> that should be equivalent is to specify a two-column matrix with 
> >> counts of "successes" and "failures" as the response. 
> Simply giving 
> >> the proportion of successes without the counts wouldn't be 
> appropriate.
> >> 
> >>> I have used both family=binomial and quasibinomial - is one more 
> >>> appropriate when the response is a proportion?  The coefficient 
> >>> estimates are identical, but the standard errors are larger with 
> >>> family=binomial.
> >>> 
> >> 
> >> The difference is that in the binomial family the 
> dispersion is fixed 
> >> to 1, while in the quasibinomial family it is estimated as a free 
> >> parameter. If the standard errors are larger with family=binomial, 
> >> then that suggests that the data are underdispersed 
> (relative to the 
> >> binomial); if the difference is substantial -- the factor 
> is just the 
> >> square root of the estimated dispersion -- then the 
> binomial model is 
> >> probably not appropriate for the data.
> > 
> > John's last deduction is appropriate to a GLM, but not 
> necessarily to 
> > a GLMM. I don't have detailed experience with lmer for 
> binomial, but I 
> > do for various other fitting routines for GLMM.  Remember 
> there are at 
> > least two sources of randomness in a GLMM, and let us keep 
> it simple 
> > and have just a subject effect and a measurement error.  Then if 
> > over-dispersion is happening within subjects, forcing the binomial 
> > dispersion (at the measurement level) to 1 tends to increase the 
> > estimate of the subject-level variance component to 
> compensate, and in 
> > turn increase some of the standard errors.
> > 
> > (Please note the 'tends' in that para, as the details of 
> the design do 
> > matter.  For cognescenti, think about plot and sub-plot 
> treatments in 
> > a split-plot design.)
>



From blomsp at ozemail.com.au  Mon Dec  4 03:46:26 2006
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Mon, 04 Dec 2006 13:46:26 +1100
Subject: [R] lmer and a response that is a proportion
In-Reply-To: <20061204022416.GXIN17401.tomts10-srv.bellnexxia.net@JohnDesktop8300>
References: <20061204022416.GXIN17401.tomts10-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <45738C02.1070906@ozemail.com.au>

Would beta regression solve your problem? (package betareg)

Simon.

John Fox wrote:
> Dear Cameron,
>
> Given your description, I thought that this might be the case. 
>
> I'd first examine the distribution of the response variable to see what it
> looks like. If the values don't push the boundaries of 0 and 1, and their
> distribution is unimodal and reasonably symmetric, I'd consider analyzing
> them directly using normally distributed errors. If the values do stack up
> near 0, 1, or both, I'd consider a transformation, or perhaps a different
> family (depending on the pattern); in particular, if they stack up near both
> 0 and 1, a logit or similar transformation could help. Finally, if you have
> many values of 0, 1, or both, then a transformation isn't promising (and,
> indeed, the logit wouldn't be defined for these values). In any event, I'd
> check diagnostics after a preliminary fit.
>
> I hope this helps,
>  John
>
> --------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox 
> -------------------------------- 
>
>   
>> -----Original Message-----
>> From: Cameron Gillies [mailto:cgillies at ualberta.ca] 
>> Sent: Sunday, December 03, 2006 6:31 PM
>> To: Prof Brian Ripley; John Fox
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] lmer and a response that is a proportion
>>
>> Dear Brian and John,
>>
>> Thanks for your insight.  I'll clarify a couple of things 
>> incase it changes your advice.
>>
>> My response is a ratio of two measures taken during a bird's 
>> path, which varies from 0  to 1, so I cannot convert it 
>> columns of the number of successes.  It has to be reported as 
>> the proportion.  I could logit transform it to make it 
>> normal, but I am trying to avoid that so I can analyze it directly.
>>
>> The subjects are individual birds and I have a range of 
>> sample sizes from each bird (from 8 to >200, average of about 
>> 75 measurements/bird).
>>
>> Thanks!
>> Cam
>>
>>
>> On 12/3/06 3:47 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:
>>
>>     
>>> On Sun, 3 Dec 2006, John Fox wrote:
>>>
>>>       
>>>> Dear Cameron,
>>>>
>>>>         
>>>>> -----Original Message-----
>>>>> From: r-help-bounces at stat.math.ethz.ch 
>>>>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Cameron 
>>>>> Gillies
>>>>> Sent: Sunday, December 03, 2006 1:58 PM
>>>>> To: r-help at stat.math.ethz.ch
>>>>> Subject: [R] lmer and a response that is a proportion
>>>>>
>>>>> Greetings all,
>>>>>
>>>>> I am using lmer (lme4 package) to analyze data where the 
>>>>>           
>> response is 
>>     
>>>>> a proportion (0 to 1).  It appears to work, but I am wondering if 
>>>>> the analysis is treating the response appropriately - 
>>>>>           
>> i.e. can lmer 
>>     
>>>>> do this?
>>>>>
>>>>>           
>>>> As far as I know, you can specify the response as a proportion, in 
>>>> which case the binomial counts would be given via the weights 
>>>> argument -- at least that's how it's done in glm(). An alternative 
>>>> that should be equivalent is to specify a two-column matrix with 
>>>> counts of "successes" and "failures" as the response. 
>>>>         
>> Simply giving 
>>     
>>>> the proportion of successes without the counts wouldn't be 
>>>>         
>> appropriate.
>>     
>>>>> I have used both family=binomial and quasibinomial - is one more 
>>>>> appropriate when the response is a proportion?  The coefficient 
>>>>> estimates are identical, but the standard errors are larger with 
>>>>> family=binomial.
>>>>>
>>>>>           
>>>> The difference is that in the binomial family the 
>>>>         
>> dispersion is fixed 
>>     
>>>> to 1, while in the quasibinomial family it is estimated as a free 
>>>> parameter. If the standard errors are larger with family=binomial, 
>>>> then that suggests that the data are underdispersed 
>>>>         
>> (relative to the 
>>     
>>>> binomial); if the difference is substantial -- the factor 
>>>>         
>> is just the 
>>     
>>>> square root of the estimated dispersion -- then the 
>>>>         
>> binomial model is 
>>     
>>>> probably not appropriate for the data.
>>>>         
>>> John's last deduction is appropriate to a GLM, but not 
>>>       
>> necessarily to 
>>     
>>> a GLMM. I don't have detailed experience with lmer for 
>>>       
>> binomial, but I 
>>     
>>> do for various other fitting routines for GLMM.  Remember 
>>>       
>> there are at 
>>     
>>> least two sources of randomness in a GLMM, and let us keep 
>>>       
>> it simple 
>>     
>>> and have just a subject effect and a measurement error.  Then if 
>>> over-dispersion is happening within subjects, forcing the binomial 
>>> dispersion (at the measurement level) to 1 tends to increase the 
>>> estimate of the subject-level variance component to 
>>>       
>> compensate, and in 
>>     
>>> turn increase some of the standard errors.
>>>
>>> (Please note the 'tends' in that para, as the details of 
>>>       
>> the design do 
>>     
>>> matter.  For cognescenti, think about plot and sub-plot 
>>>       
>> treatments in 
>>     
>>> a split-plot design.)
>>>       
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>   


-- 
Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat. 
Centre for Resource and Environmental Studies
The Australian National University              
Canberra ACT 0200                               
Australia                                       
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer 
can be extracted from a given body of data.
- John Tukey.



From cgillies at ualberta.ca  Mon Dec  4 05:38:31 2006
From: cgillies at ualberta.ca (Cameron Gillies)
Date: Sun, 03 Dec 2006 21:38:31 -0700
Subject: [R] lmer and a response that is a proportion
In-Reply-To: <45738C02.1070906@ozemail.com.au>
Message-ID: <C198F457.1385%cgillies@ualberta.ca>

Hello Simon and John,

I'm afraid I need to include random effects, both a random intercept and
possibly random coefficients and it doesn't look like betareg can do that.

John, the data is spread along the range of 0 to 1 with most values closer
to 1, so it does transform well using the logit transformation.  I was
trying to avoid that though because I was not sure what impact the
transformation would have on the random effects or interpretation of the
coefficients.  

Thanks again!
Cam

On 12/3/06 7:46 PM, "Simon Blomberg" <blomsp at ozemail.com.au> wrote:

> Would beta regression solve your problem? (package betareg)
> 
> Simon.
> 
> John Fox wrote:
>> Dear Cameron,
>> 
>> Given your description, I thought that this might be the case.
>> 
>> I'd first examine the distribution of the response variable to see what it
>> looks like. If the values don't push the boundaries of 0 and 1, and their
>> distribution is unimodal and reasonably symmetric, I'd consider analyzing
>> them directly using normally distributed errors. If the values do stack up
>> near 0, 1, or both, I'd consider a transformation, or perhaps a different
>> family (depending on the pattern); in particular, if they stack up near both
>> 0 and 1, a logit or similar transformation could help. Finally, if you have
>> many values of 0, 1, or both, then a transformation isn't promising (and,
>> indeed, the logit wouldn't be defined for these values). In any event, I'd
>> check diagnostics after a preliminary fit.
>> 
>> I hope this helps,
>>  John
>> 
>> --------------------------------
>> John Fox
>> Department of Sociology
>> McMaster University
>> Hamilton, Ontario
>> Canada L8S 4M4
>> 905-525-9140x23604
>> http://socserv.mcmaster.ca/jfox
>> --------------------------------
>> 
>>   
>>> -----Original Message-----
>>> From: Cameron Gillies [mailto:cgillies at ualberta.ca]
>>> Sent: Sunday, December 03, 2006 6:31 PM
>>> To: Prof Brian Ripley; John Fox
>>> Cc: r-help at stat.math.ethz.ch
>>> Subject: Re: [R] lmer and a response that is a proportion
>>> 
>>> Dear Brian and John,
>>> 
>>> Thanks for your insight.  I'll clarify a couple of things
>>> incase it changes your advice.
>>> 
>>> My response is a ratio of two measures taken during a bird's
>>> path, which varies from 0  to 1, so I cannot convert it
>>> columns of the number of successes.  It has to be reported as
>>> the proportion.  I could logit transform it to make it
>>> normal, but I am trying to avoid that so I can analyze it directly.
>>> 
>>> The subjects are individual birds and I have a range of
>>> sample sizes from each bird (from 8 to >200, average of about
>>> 75 measurements/bird).
>>> 
>>> Thanks!
>>> Cam
>>> 
>>> 
>>> On 12/3/06 3:47 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:
>>> 
>>>     
>>>> On Sun, 3 Dec 2006, John Fox wrote:
>>>> 
>>>>       
>>>>> Dear Cameron,
>>>>> 
>>>>>         
>>>>>> -----Original Message-----
>>>>>> From: r-help-bounces at stat.math.ethz.ch
>>>>>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Cameron
>>>>>> Gillies
>>>>>> Sent: Sunday, December 03, 2006 1:58 PM
>>>>>> To: r-help at stat.math.ethz.ch
>>>>>> Subject: [R] lmer and a response that is a proportion
>>>>>> 
>>>>>> Greetings all,
>>>>>> 
>>>>>> I am using lmer (lme4 package) to analyze data where the
>>>>>>           
>>> response is 
>>>     
>>>>>> a proportion (0 to 1).  It appears to work, but I am wondering if
>>>>>> the analysis is treating the response appropriately -
>>>>>>           
>>> i.e. can lmer 
>>>     
>>>>>> do this?
>>>>>> 
>>>>>>           
>>>>> As far as I know, you can specify the response as a proportion, in
>>>>> which case the binomial counts would be given via the weights
>>>>> argument -- at least that's how it's done in glm(). An alternative
>>>>> that should be equivalent is to specify a two-column matrix with
>>>>> counts of "successes" and "failures" as the response.
>>>>>         
>>> Simply giving 
>>>     
>>>>> the proportion of successes without the counts wouldn't be
>>>>>         
>>> appropriate.
>>>     
>>>>>> I have used both family=binomial and quasibinomial - is one more
>>>>>> appropriate when the response is a proportion?  The coefficient
>>>>>> estimates are identical, but the standard errors are larger with
>>>>>> family=binomial.
>>>>>> 
>>>>>>           
>>>>> The difference is that in the binomial family the
>>>>>         
>>> dispersion is fixed
>>>     
>>>>> to 1, while in the quasibinomial family it is estimated as a free
>>>>> parameter. If the standard errors are larger with family=binomial,
>>>>> then that suggests that the data are underdispersed
>>>>>         
>>> (relative to the
>>>     
>>>>> binomial); if the difference is substantial -- the factor
>>>>>         
>>> is just the 
>>>     
>>>>> square root of the estimated dispersion -- then the
>>>>>         
>>> binomial model is
>>>     
>>>>> probably not appropriate for the data.
>>>>>         
>>>> John's last deduction is appropriate to a GLM, but not
>>>>       
>>> necessarily to 
>>>     
>>>> a GLMM. I don't have detailed experience with lmer for
>>>>       
>>> binomial, but I
>>>     
>>>> do for various other fitting routines for GLMM.  Remember
>>>>       
>>> there are at 
>>>     
>>>> least two sources of randomness in a GLMM, and let us keep
>>>>       
>>> it simple 
>>>     
>>>> and have just a subject effect and a measurement error.  Then if
>>>> over-dispersion is happening within subjects, forcing the binomial
>>>> dispersion (at the measurement level) to 1 tends to increase the
>>>> estimate of the subject-level variance component to
>>>>       
>>> compensate, and in
>>>     
>>>> turn increase some of the standard errors.
>>>> 
>>>> (Please note the 'tends' in that para, as the details of
>>>>       
>>> the design do 
>>>     
>>>> matter.  For cognescenti, think about plot and sub-plot
>>>>       
>>> treatments in 
>>>     
>>>> a split-plot design.)
>>>>       
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>>   
>



From gregor.gorjanc at bfro.uni-lj.si  Mon Dec  4 07:23:53 2006
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Mon, 4 Dec 2006 06:23:53 +0000 (UTC)
Subject: [R] lmer and a response that is a proportion
References: <45738C02.1070906@ozemail.com.au>
	<C198F457.1385%cgillies@ualberta.ca>
Message-ID: <loom.20061204T072225-791@post.gmane.org>

Cameron Gillies <cgillies <at> ualberta.ca> writes:
> Hello Simon and John,
> 
> I'm afraid I need to include random effects, both a random intercept and
> possibly random coefficients and it doesn't look like betareg can do that.

Kevin Wright has posted wish on R-wiki for beta mixed effects model. There is no
package for this, but there was a nice article describing such a model. Well, it
is a start.

Gregor



From A.Robinson at ms.unimelb.edu.au  Mon Dec  4 07:46:08 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 4 Dec 2006 17:46:08 +1100 (EST)
Subject: [R] lmer and a response that is a proportion
In-Reply-To: <C198F457.1385%cgillies@ualberta.ca>
References: <C198F457.1385%cgillies@ualberta.ca>
Message-ID: <45572.220.237.183.166.1165214768.squirrel@webmail.ms.unimelb.edu.au>

Hi Cam,

I like John's suggestion too.  The only thing that I would add to it is
that you might find it worthwhile to use lme() instead of lmer(). The
former permits flexible modeling of the variance, whereas to my knowledge
the latter doesn't, yet.  You might find that with judicious modeling of
the variance, the model assumptions could reasonably be met.

Good luck,

Andrew

On Mon, December 4, 2006 3:38 pm, Cameron Gillies wrote:
> Hello Simon and John,
>
> I'm afraid I need to include random effects, both a random intercept and
> possibly random coefficients and it doesn't look like betareg can do that.
>
> John, the data is spread along the range of 0 to 1 with most values closer
> to 1, so it does transform well using the logit transformation.  I was
> trying to avoid that though because I was not sure what impact the
> transformation would have on the random effects or interpretation of the
> coefficients.
>
> Thanks again!
> Cam
>
> On 12/3/06 7:46 PM, "Simon Blomberg" <blomsp at ozemail.com.au> wrote:
>
>> Would beta regression solve your problem? (package betareg)
>>
>> Simon.
>>
>> John Fox wrote:
>>> Dear Cameron,
>>>
>>> Given your description, I thought that this might be the case.
>>>
>>> I'd first examine the distribution of the response variable to see what
>>> it
>>> looks like. If the values don't push the boundaries of 0 and 1, and
>>> their
>>> distribution is unimodal and reasonably symmetric, I'd consider
>>> analyzing
>>> them directly using normally distributed errors. If the values do stack
>>> up
>>> near 0, 1, or both, I'd consider a transformation, or perhaps a
>>> different
>>> family (depending on the pattern); in particular, if they stack up near
>>> both
>>> 0 and 1, a logit or similar transformation could help. Finally, if you
>>> have
>>> many values of 0, 1, or both, then a transformation isn't promising
>>> (and,
>>> indeed, the logit wouldn't be defined for these values). In any event,
>>> I'd
>>> check diagnostics after a preliminary fit.
>>>
>>> I hope this helps,
>>>  John
>>>
>>> --------------------------------
>>> John Fox
>>> Department of Sociology
>>> McMaster University
>>> Hamilton, Ontario
>>> Canada L8S 4M4
>>> 905-525-9140x23604
>>> http://socserv.mcmaster.ca/jfox
>>> --------------------------------
>>>
>>>
>>>> -----Original Message-----
>>>> From: Cameron Gillies [mailto:cgillies at ualberta.ca]
>>>> Sent: Sunday, December 03, 2006 6:31 PM
>>>> To: Prof Brian Ripley; John Fox
>>>> Cc: r-help at stat.math.ethz.ch
>>>> Subject: Re: [R] lmer and a response that is a proportion
>>>>
>>>> Dear Brian and John,
>>>>
>>>> Thanks for your insight.  I'll clarify a couple of things
>>>> incase it changes your advice.
>>>>
>>>> My response is a ratio of two measures taken during a bird's
>>>> path, which varies from 0  to 1, so I cannot convert it
>>>> columns of the number of successes.  It has to be reported as
>>>> the proportion.  I could logit transform it to make it
>>>> normal, but I am trying to avoid that so I can analyze it directly.
>>>>
>>>> The subjects are individual birds and I have a range of
>>>> sample sizes from each bird (from 8 to >200, average of about
>>>> 75 measurements/bird).
>>>>
>>>> Thanks!
>>>> Cam
>>>>
>>>>
>>>> On 12/3/06 3:47 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:
>>>>
>>>>
>>>>> On Sun, 3 Dec 2006, John Fox wrote:
>>>>>
>>>>>
>>>>>> Dear Cameron,
>>>>>>
>>>>>>
>>>>>>> -----Original Message-----
>>>>>>> From: r-help-bounces at stat.math.ethz.ch
>>>>>>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Cameron
>>>>>>> Gillies
>>>>>>> Sent: Sunday, December 03, 2006 1:58 PM
>>>>>>> To: r-help at stat.math.ethz.ch
>>>>>>> Subject: [R] lmer and a response that is a proportion
>>>>>>>
>>>>>>> Greetings all,
>>>>>>>
>>>>>>> I am using lmer (lme4 package) to analyze data where the
>>>>>>>
>>>> response is
>>>>
>>>>>>> a proportion (0 to 1).  It appears to work, but I am wondering if
>>>>>>> the analysis is treating the response appropriately -
>>>>>>>
>>>> i.e. can lmer
>>>>
>>>>>>> do this?
>>>>>>>
>>>>>>>
>>>>>> As far as I know, you can specify the response as a proportion, in
>>>>>> which case the binomial counts would be given via the weights
>>>>>> argument -- at least that's how it's done in glm(). An alternative
>>>>>> that should be equivalent is to specify a two-column matrix with
>>>>>> counts of "successes" and "failures" as the response.
>>>>>>
>>>> Simply giving
>>>>
>>>>>> the proportion of successes without the counts wouldn't be
>>>>>>
>>>> appropriate.
>>>>
>>>>>>> I have used both family=binomial and quasibinomial - is one more
>>>>>>> appropriate when the response is a proportion?  The coefficient
>>>>>>> estimates are identical, but the standard errors are larger with
>>>>>>> family=binomial.
>>>>>>>
>>>>>>>
>>>>>> The difference is that in the binomial family the
>>>>>>
>>>> dispersion is fixed
>>>>
>>>>>> to 1, while in the quasibinomial family it is estimated as a free
>>>>>> parameter. If the standard errors are larger with family=binomial,
>>>>>> then that suggests that the data are underdispersed
>>>>>>
>>>> (relative to the
>>>>
>>>>>> binomial); if the difference is substantial -- the factor
>>>>>>
>>>> is just the
>>>>
>>>>>> square root of the estimated dispersion -- then the
>>>>>>
>>>> binomial model is
>>>>
>>>>>> probably not appropriate for the data.
>>>>>>
>>>>> John's last deduction is appropriate to a GLM, but not
>>>>>
>>>> necessarily to
>>>>
>>>>> a GLMM. I don't have detailed experience with lmer for
>>>>>
>>>> binomial, but I
>>>>
>>>>> do for various other fitting routines for GLMM.  Remember
>>>>>
>>>> there are at
>>>>
>>>>> least two sources of randomness in a GLMM, and let us keep
>>>>>
>>>> it simple
>>>>
>>>>> and have just a subject effect and a measurement error.  Then if
>>>>> over-dispersion is happening within subjects, forcing the binomial
>>>>> dispersion (at the measurement level) to 1 tends to increase the
>>>>> estimate of the subject-level variance component to
>>>>>
>>>> compensate, and in
>>>>
>>>>> turn increase some of the standard errors.
>>>>>
>>>>> (Please note the 'tends' in that para, as the details of
>>>>>
>>>> the design do
>>>>
>>>>> matter.  For cognescenti, think about plot and sub-plot
>>>>>
>>>> treatments in
>>>>
>>>>> a split-plot design.)
>>>>>
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
Department of Mathematics and Statistics            Fax: +61-3-8344 4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au



From ligges at statistik.uni-dortmund.de  Mon Dec  4 08:29:33 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 04 Dec 2006 08:29:33 +0100
Subject: [R] hide output in SWeave documents; was: R_WinEdt question
In-Reply-To: <6.1.2.0.2.20061203133326.01ce9888@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061203133326.01ce9888@aiminy.mail.iastate.edu>
Message-ID: <4573CE5D.1050805@statistik.uni-dortmund.de>

Why is the question below related to RWinEdt? It looks to me like an 
SWeave question. Please read its manual.
The answer is to add the option results=hide to the code chunk's header:

<<R code,echo=FALSE,results=hide>>=

BTW: I do not understand why you want to call summary() but not print 
its results.

Uwe Ligges


Aimin Yan wrote:
> Hello,
> I am new to R-WinEdt. Here is my code. If I don't want see output for 
> summary(mp) in my final document, just want to run it.
> How to modify these code?
> 
> Thanks,
> 
> Aimin Yan
> 
> <<R code,echo=FALSE>>=
> library(MASS)
> options(contrasts=c("contr.treatment","contr.poly"))
> p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
> 
> p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
> attach(p5)
> mp<-glm(Y~P-1,data=p5)
> summary(mp)
> @
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From simon.kempf at web.de  Mon Dec  4 08:53:02 2006
From: simon.kempf at web.de (Simon P. Kempf)
Date: Mon, 4 Dec 2006 08:53:02 +0100
Subject: [R] Box Tidwell / Error Message / Error in parse(file, n, text,
	prompt) : syntax error in
Message-ID: <E1Gr8da-00064q-00@smtp06.web.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061204/53732eb6/attachment-0004.pl 

From ligges at statistik.uni-dortmund.de  Mon Dec  4 09:06:21 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 04 Dec 2006 09:06:21 +0100
Subject: [R] creating column based on another variable
In-Reply-To: <!&!AAAAAAAAAAAYAAAAAAAAAEuLs8ZPMuFInPbB+1JmPy7CgAAAEAAAAFlGOuVXOglMl9dsiAiWt/kBAAAAAA==@adsam.com>
References: <!&!AAAAAAAAAAAYAAAAAAAAAEuLs8ZPMuFInPbB+1JmPy7CgAAAEAAAAFlGOuVXOglMl9dsiAiWt/kBAAAAAA==@adsam.com>
Message-ID: <4573D6FD.4050303@statistik.uni-dortmund.de>



Jeff Miller wrote:
> Hi all,
> 
>  
> 
> I hope someone can help me with this.
> 
>  
> 
> Suppose I import a text file and one of the columns looks like this:
> 
>  
> 
> New York
> 
> New York
> 
> England
> 
> Spain
> 
> Spain
> 
> Orlando
> 
> New York
> 
> England
> 
> France


I don't understand the semantics here. You are mixing cities and countries.


> I want to add a variable that is based on the previous one
> 
>  
> 
> US
> 
> US
> 
> Europe
> 
> Europe
> 
> Europe
> 
> US
> 
> US
> 
> Europe
> 
> Europe


Now you are mixing a single country and a whole continent.

Is this some homework?

You should consider to tell R which cities are in the US and which 
countries are in Europe and than try to match appropriately ...
As the footer of this message says:
"PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html"
which tells you to read introductory material and to specify some code 
examples and details that you already have got. Then it's much easier 
for us to help.

Uwe Ligges



>  
> 
> How do that?
> 
>  
> 
> Also, I would like to be able to export the data as a text file that retains
> this new variable.
> 
>  
> 
> Any suggestions are greatly appreciated,
> 
>  
> 
> Jeff Miller
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From tura at centroin.com.br  Mon Dec  4 10:05:27 2006
From: tura at centroin.com.br (Bernardo Rangel tura)
Date: Mon, 04 Dec 2006 07:05:27 -0200
Subject: [R] prop.trend.test issue
In-Reply-To: <5cd96f050612022155l5dfc8e3en5b077a0600b87598@mail.gmail.co
 m>
References: <5cd96f050612022155l5dfc8e3en5b077a0600b87598@mail.gmail.com>
Message-ID: <7.0.0.16.2.20061204070447.025f07b8@centroin.com.br>

At 03:55 AM 12/3/2006, Ethan Johnsons wrote:
>I have the clinical study data.
>
>                                            Year 0       Year 3
>Retinol (nmol/L)        N       Mean +-sd       Mean +-sd
>Vitamin A group         73      1.89+-0.36      2.06+-0.53
>Trace group                57      1.83+-0.31     1.78+-0.30
>
>where N is the number of male for the clinical study.
>
>I want to test if the mean serum retinol has increased over 3 years
>among subjects in the vitamin A group.


If  You desire check mean serum retinol has increased over 3 years in 
vitamin A group.
You may use t.test
Look this example:

#Generate random Data

set.seed(123)
VitA1<-rnorm(73,1.89,.36)
Trace1<-rnorm(57,1.83,0.31)
VitA2<-rnorm(73,2.06,.53)
Trace2<-rnorm(57,1.78,0.30)

# Calculate diference Year 3 - Year 0

dVitA<-VitA2-VitA1
dTrace<-Trace2-Trace1

# Testing diference
t.test(dVitA,dTrace)


         Welch Two Sample t-test

data:  dVitA and dTrace
t = 2.2762, df = 117.746, p-value = 0.02464
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
  0.02756874 0.39659494
sample estimates:
   mean of x   mean of y
  0.15905162 -0.05303022





Bernardo Rangel Tura, MD, Phd
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil



From kaniovsk at wifo.ac.at  Mon Dec  4 10:14:54 2006
From: kaniovsk at wifo.ac.at (Serguei Kaniovski)
Date: Mon, 04 Dec 2006 10:14:54 +0100
Subject: [R] Count cases by indicator
Message-ID: <4573E70E.1020908@wifo.ac.at>

Hi,

In the data below, "case" represents cases, "x" binary states. Each 
"case" has exactly 9 "x", ie is a binary vector of length 9.

There are 2^9=512 possible combinations of binary states in a given 
"case", ie 512 possible vectors. I generate these in the order of the 
decimals the vectors represent, as:

cmat<-as.matrix(expand.grid(rep(list(0:1),9)))
cmat<-cmat[nrow(cmat):1,ncol(cmat):1]

"cmat" contains the binary vectors as rows.

QUESTION: I would like to know how often each of the 512 vectors occurs 
in "case".

With these data, the output should be a vector with 2^9=512 coordinates, 
having 2,2,1,3, as, respectively, the coordinate number 129, 193, 449, 
512, and zeros in all other coordinates.

Thank you for your help,
Serguei

df<-read.delim("clipboard",sep=";")

DATA:
case;x
093/0188;0
093/0188;0
093/0188;1
093/0188;0
093/0188;1
093/0188;1
093/0188;1
093/0188;1
093/0188;1
093/0206;0
093/0206;0
093/0206;0
093/0206;0
093/0206;0
093/0206;0
093/0206;0
093/0206;0
093/0206;0
093/0216;0
093/0216;1
093/0216;1
093/0216;1
093/0216;1
093/0216;1
093/0216;0
093/0216;1
093/0216;1
093/0305;0
093/0305;1
093/0305;1
093/0305;1
093/0305;1
093/0305;1
093/0305;1
093/0305;1
093/0305;1
093/0325;0
093/0325;0
093/0325;0
093/0325;0
093/0325;0
093/0325;0
093/0325;0
093/0325;0
093/0325;0
093/0449;0
093/0449;0
093/0449;0
093/0449;0
093/0449;0
093/0449;0
093/0449;0
093/0449;0
093/0449;0
093/0473;0
093/0473;0
093/0473;1
093/0473;1
093/0473;1
093/0473;1
093/0473;1
093/0473;1
093/0473;1
093/0499;0
093/0499;0
093/0499;1
093/0499;1
093/0499;1
093/0499;1
093/0499;1
093/0499;1
093/0499;1
-- 
___________________________________________________________________

Austrian Institute of Economic Research (WIFO)

Name: Serguei Kaniovski			P.O.Box 91
Tel.: +43-1-7982601-231			Arsenal Objekt 20
Fax:  +43-1-7989386			1103 Vienna, Austria
Mail: Serguei.Kaniovski at wifo.ac.at

http://www.wifo.ac.at/Serguei.Kaniovski



From msubianto at gmail.com  Mon Dec  4 10:42:30 2006
From: msubianto at gmail.com (Muhammad Subianto)
Date: Mon, 04 Dec 2006 10:42:30 +0100
Subject: [R] Make many barplot into one plot
In-Reply-To: <eb555e660612011209v2dd050a8pd1f873a76fb97017@mail.gmail.com>
References: <4570600A.3040506@gmail.com>	
	<1164996027.4552.10.camel@localhost.localdomain>
	<eb555e660612011209v2dd050a8pd1f873a76fb97017@mail.gmail.com>
Message-ID: <4573ED86.80605@gmail.com>

Dear; Marc Schwartz and Deepayan Sarkar,
Thank you both very much for the suggestions!  These are exactly what I 
was looking for.

Best wishes, Muhammad Subianto


On this day 12/01/2006 09:09 PM, Deepayan Sarkar wrote:
> On 12/1/06, Marc Schwartz <marc_schwartz at comcast.net> wrote:
>> On Fri, 2006-12-01 at 18:02 +0100, Muhammad Subianto wrote:
>> > Dear all,
>> > ## I have 4 tables like this:
>> >
>> > satu  <- array(c(5,15,20,68,29,54,84,119), dim=c(2,4),
>> >                dimnames=list(c("Negative", "Positive"), c("Black",
>> > "Brown", "Red", "Blond")))
>> > dua   <- array(c(50,105,30,8,29,25,84,9), dim=c(2,4),
>> >                dimnames=list(c("Negative", "Positive"), c("Black",
>> > "Brown", "Red", "Blond")))
>> > tiga  <- array(c(9,16,26,68,12,4,84,12), dim=c(2,4),
>> >                dimnames=list(c("Negative", "Positive"), c("Black",
>> > "Brown", "Red", "Blond")))
>> > empat <- array(c(25,13,50,78,19,34,84,101), dim=c(2,4),
>> >                dimnames=list(c("Negative", "Positive"), c("Black",
>> > "Brown", "Red", "Blond")))
>> >
>> > ## with barplot I can make a plot for each table:
>> >
>> > barplot(satu, beside=TRUE, legend.text=rownames(satu),
>> >         ylim = c(0, max(colSums(satu)) * 1.2))
>> > x11()
>> > barplot(dua, beside=TRUE, legend.text=rownames(dua),
>> >         ylim = c(0, max(colSums(dua)) * 1.2))
>> > x11()
>> > barplot(tiga, beside=TRUE, legend.text=rownames(tiga),
>> >         ylim = c(0, max(colSums(tiga)) * 1.2))
>> > x11()
>> > barplot(empat, beside=TRUE, legend.text=rownames(empat),
>> >         ylim = c(0, max(colSums(empat)) * 1.2))
>> >
>> > ## I can make all barplot above into one plot with
>> >
>> > x11(width=11,height=8)
>> > ## Make a plot with 2 rows and 2 columns
>> > oldpar <- par(mfrow=c(2,2),
>> >    barplot(above)
>> > par(oldpar)
>> >
>> > ## Are there any functions to make all barplot above into one plot?
>> > ## I would like to produce barplot like:
>> >
>> > |   |                               |   |
>> > |   |   |   |   |   |   |   |   |   |   |   |   |   |
>> > |pos|neg|pos|neg|pos|neg|pos|neg|   |pos|neg|pos|neg| ...
>> > |   |   |   |   |   |   |   |   |   |   |   |   |   |
>> > ---------------------------------   --------------------
>> >   satu     dua     tiga   empat        satu    dua ...
>> >               black                         blond
>> >
>> > I would be grateful if anybody could help me.
>> > Thank you very much.
>>
>> I would encourage you to look at the barchart() function in the lattice
>> package, which in many ways is better suited to doing multi-dimensional
>> plots.
>>
>> That being said:
>>
>> [snipped]
>
> And here is a lattice alternative:
>
>
> dflist <- list()
> for (nm in c("satu", "dua", "tiga", "empat"))
> {
>    dflist[[nm]] <- as.data.frame.table(get(nm))
> }
>
> cdf <- do.call(make.groups, dflist)
>
> barchart(Freq ~ which | Var2, data = cdf,
>         groups = Var1, stack = FALSE, origin = 0,
>         layout = c(4, 1), auto.key = TRUE)
>
> barchart(which ~ Freq | Var2, data = cdf,
>         groups = Var1, stack = TRUE,
>         auto.key = TRUE)
>
>
> -Deepayan
>



From Sven.Garbade at med.uni-heidelberg.de  Mon Dec  4 11:01:26 2006
From: Sven.Garbade at med.uni-heidelberg.de (Sven Garbade)
Date: Mon, 04 Dec 2006 11:01:26 +0100
Subject: [R] background color in strip.custom()
Message-ID: <1165226486.3280.6.camel@localhost.localdomain>

Hi all,
how can I change the background color in lattice strips according to a
factor level, eg:

library(lattice)
x <- rnorm(100)
y <- sqrt(x)
f <- gl(2, 50, c("A", "B"))
xyplot(y ~ x | f)

I like to change the background color of the strips according to the
levels in f and tried several things like this with no success:

xyplot(y ~ x | f, strip=strip.custom(bg=c("red", "green")))

Is this possible?

Thanks, Sven



From sspaeth at ethz.ch  Mon Dec  4 12:04:52 2006
From: sspaeth at ethz.ch (Sebastian Spaeth)
Date: Mon, 04 Dec 2006 12:04:52 +0100
Subject: [R] Summary shows wrong maximum
Message-ID: <op.tj07qenxmp0376@mtec-hg-docking-1-dhcp-25.ethz.ch>

Hi all,
I have a list with a numerical column "cum_hardreuses". By coincidence I  
discovered this:

> max(libs[,"cum_hardreuses"])
[1] 1793

> summary(libs[,"cum_hardreuses"])
    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
       1       2       4      36      14    1790

(note the max value of 1790) Ouch this is bad! Anything I can do to remedy  
this? Known bug?

This is a Version 1.16 (3198) of the MacOSX R.

Regards,
Sebastian Spaeth



From bernarduse1 at yahoo.fr  Mon Dec  4 12:55:52 2006
From: bernarduse1 at yahoo.fr (Marc Bernard)
Date: Mon, 4 Dec 2006 12:55:52 +0100 (CET)
Subject: [R] stepAIC for lmer
Message-ID: <20061204115552.36606.qmail@web23402.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061204/be9eff24/attachment-0004.pl 

From ligges at statistik.uni-dortmund.de  Mon Dec  4 12:57:01 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 04 Dec 2006 12:57:01 +0100
Subject: [R] Summary shows wrong maximum
In-Reply-To: <op.tj07qenxmp0376@mtec-hg-docking-1-dhcp-25.ethz.ch>
References: <op.tj07qenxmp0376@mtec-hg-docking-1-dhcp-25.ethz.ch>
Message-ID: <45740D0D.8090003@statistik.uni-dortmund.de>



Sebastian Spaeth wrote:
> Hi all,
> I have a list with a numerical column "cum_hardreuses". By coincidence I  
> discovered this:
> 
>> max(libs[,"cum_hardreuses"])
> [1] 1793
> 
>> summary(libs[,"cum_hardreuses"])
>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>        1       2       4      36      14    1790
> 
> (note the max value of 1790) Ouch this is bad! Anything I can do to remedy  
> this? Known bug?

No, it's a feature! See ?summary: printing is done up to 3 significant 
digits by default. If you want it more precise, for example use:

summary(libs[,"cum_hardreuses"], digits=10)

Uwe Ligges


> This is a Version 1.16 (3198) of the MacOSX R.
> 
> Regards,
> Sebastian Spaeth
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From gavin.simpson at ucl.ac.uk  Mon Dec  4 13:06:19 2006
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Mon, 04 Dec 2006 12:06:19 +0000
Subject: [R] Summary shows wrong maximum
In-Reply-To: <op.tj07qenxmp0376@mtec-hg-docking-1-dhcp-25.ethz.ch>
References: <op.tj07qenxmp0376@mtec-hg-docking-1-dhcp-25.ethz.ch>
Message-ID: <1165233979.15139.9.camel@gsimpson.geog.ucl.ac.uk>

On Mon, 2006-12-04 at 12:04 +0100, Sebastian Spaeth wrote:
> Hi all,
> I have a list with a numerical column "cum_hardreuses". By coincidence I  
> discovered this:
> 
> > max(libs[,"cum_hardreuses"])
> [1] 1793
> 
> > summary(libs[,"cum_hardreuses"])
>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>        1       2       4      36      14    1790
> 
> (note the max value of 1790) Ouch this is bad! Anything I can do to remedy  
> this? Known bug?

Did you read ?summary, which has:

 ## Default S3 method:
     summary(object, ..., digits = max(3, getOption("digits")-3))

so this is a rounding issue of the *printed* representation of the
summary. Just change digits to be a larger number:

> dat <- rnorm(100)
> max(dat)
[1] 2.434443
> summary(dat)
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
-2.21100 -0.65450  0.03793  0.06919  0.84650  2.43400
> summary(dat, digits = 10)
       Min.     1st Qu.      Median        Mean     3rd Qu.        Max.
-2.21106232 -0.65451716  0.03793040  0.06919486  0.84652269  2.43444263
> # same with integer as in your example
> dat <- floor(dat * 1000000)
> max(dat)
[1] 2434442
> summary(dat)
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
-2211000  -654500    37930    69190   846500  2434000
> summary(dat, digits = 10)
       Min.     1st Qu.      Median        Mean     3rd Qu.        Max.
-2211063.00  -654517.50    37930.00    69194.38   846522.00  2434442.00

HTH

G

> 
> This is a Version 1.16 (3198) of the MacOSX R.
> 
> Regards,
> Sebastian Spaeth
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC & ENSIS, UCL Geography,  [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From sspaeth at ethz.ch  Mon Dec  4 13:08:25 2006
From: sspaeth at ethz.ch (Sebastian Spaeth)
Date: Mon, 04 Dec 2006 13:08:25 +0100
Subject: [R] Summary shows wrong maximum
In-Reply-To: <45740D0D.8090003@statistik.uni-dortmund.de>
References: <op.tj07qenxmp0376@mtec-hg-docking-1-dhcp-25.ethz.ch>
	<45740D0D.8090003@statistik.uni-dortmund.de>
Message-ID: <45740FB9.20800@ethz.ch>

Uwe Ligges wrote:
>>> max(libs[,"cum_hardreuses"])
>> [1] 1793
>>> summary(libs[,"cum_hardreuses"])
>>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>        1       2       4      36      14    1790
>> (note the max value of 1790) Ouch this is bad! Anything I can do to 
>> remedy  this? Known bug?

> No, it's a feature! See ?summary: printing is done up to 3 significant 
> digits by default. If you want it more precise, for example use:

Thanks for the info. Good to know. I didn't think that it would round 
pre-comma digits though.

Grateful,
Sebastian



From bernarduse1 at yahoo.fr  Mon Dec  4 13:17:18 2006
From: bernarduse1 at yahoo.fr (Marc Bernard)
Date: Mon, 4 Dec 2006 13:17:18 +0100 (CET)
Subject: [R] stepAIC
Message-ID: <373202.93419.qm@web23404.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061204/bbb0f63b/attachment-0004.pl 

From wwguocn at gmail.com  Mon Dec  4 13:25:40 2006
From: wwguocn at gmail.com (Guo Wei-Wei)
Date: Mon, 4 Dec 2006 20:25:40 +0800
Subject: [R] Is there a better way for inputing data manually?
In-Reply-To: <7.0.0.16.0.20061202113406.0194bdb0@aghmed.fsnet.co.uk>
References: <365031447.30585@eyou.net> <457103B1.7010308@stats.uwo.ca>
	<7.0.0.16.0.20061202113406.0194bdb0@aghmed.fsnet.co.uk>
Message-ID: <d3677d7d0612040425k57fdff33u6263cab1bcde1940@mail.gmail.com>

Thank you, Duncan and Michael. Your information are all very helpful for me.

Wei-Wei



From audig84 at yahoo.com  Mon Dec  4 13:30:33 2006
From: audig84 at yahoo.com (aditya gangadharan)
Date: Mon, 4 Dec 2006 04:30:33 -0800 (PST)
Subject: [R] GAM model selection and dropping terms based on GCV
Message-ID: <20061204123033.3420.qmail@web51106.mail.yahoo.com>

Hello,
I have a question regarding model selection and dropping of terms for GAMs fitted with package mgcv. I am following the approach suggested in Wood (2001), Wood and Augustin (2002).
 
I fitted a saturated model, and I find from the plots that for two of the covariates,
1. The confidence interval includes 0 almost everywhere
2. The degrees of freedom are NOT close to 1
3. The partial residuals from plot.gam don?t show much pattern visually (to me)
4. When I drop either or both of the terms, the GCV score increases;

This is my main problem: how much of an increase in GCV is ?acceptable? when terms are dropped? In the above case, the delta GCV scores are .03, .06 and .11 when I drop covariate A, covariate B and both respectively from the full model.  
I would be very grateful for any advice on this.

Thank you
Best Wishes
Aditya



From andy_liaw at merck.com  Mon Dec  4 14:24:01 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 4 Dec 2006 08:24:01 -0500
Subject: [R] Count cases by indicator
In-Reply-To: <4573E70E.1020908@wifo.ac.at>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA035369B3@usctmx1106.merck.com>

I might be missing something, but the data you showed don't seem to
match your expectation.  Firstly, 111111111 in binary is 511 in decimal,
so your "coordinates" are off by 1.  Secondly, for the data you've
shown, the matrix equivalent look like:

m <- matrix(df$x, ncol=9, byrow=TRUE)
rownames(m) <- levels(df$cases)
print(m)

         [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
093/0188    0    0    1    0    1    1    1    1    1
093/0206    0    0    0    0    0    0    0    0    0
093/0216    0    1    1    1    1    1    0    1    1
093/0305    0    1    1    1    1    1    1    1    1
093/0325    0    0    0    0    0    0    0    0    0
093/0449    0    0    0    0    0    0    0    0    0
093/0473    0    0    1    1    1    1    1    1    1
093/0499    0    0    1    1    1    1    1    1    1

The counts of unique occurances are:

table(do.call(paste, c(as.data.frame(m), sep="")

000000000 001011111 001111111 011111011 011111111 
        3         1         2         1         1 

which do not agree with yours.

If I understood what you wanted, I would do:

R> table(rowSums(matrix(2^(0:8) * df$x, ncol=9, byrow=TRUE)))

  0 446 500 508 510 
  3   1   1   2   1 

Andy


From: Serguei Kaniovski
 
> Hi,
> 
> In the data below, "case" represents cases, "x" binary 
> states. Each "case" has exactly 9 "x", ie is a binary vector 
> of length 9.
> 
> There are 2^9=512 possible combinations of binary states in a 
> given "case", ie 512 possible vectors. I generate these in 
> the order of the decimals the vectors represent, as:
> 
> cmat<-as.matrix(expand.grid(rep(list(0:1),9)))
> cmat<-cmat[nrow(cmat):1,ncol(cmat):1]
> 
> "cmat" contains the binary vectors as rows.
> 
> QUESTION: I would like to know how often each of the 512 
> vectors occurs in "case".
> 
> With these data, the output should be a vector with 2^9=512 
> coordinates, having 2,2,1,3, as, respectively, the coordinate 
> number 129, 193, 449, 512, and zeros in all other coordinates.
> 
> Thank you for your help,
> Serguei
> 
> df<-read.delim("clipboard",sep=";")
> 
> DATA:
> case;x
> 093/0188;0
> 093/0188;0
> 093/0188;1
> 093/0188;0
> 093/0188;1
> 093/0188;1
> 093/0188;1
> 093/0188;1
> 093/0188;1
> 093/0206;0
> 093/0206;0
> 093/0206;0
> 093/0206;0
> 093/0206;0
> 093/0206;0
> 093/0206;0
> 093/0206;0
> 093/0206;0
> 093/0216;0
> 093/0216;1
> 093/0216;1
> 093/0216;1
> 093/0216;1
> 093/0216;1
> 093/0216;0
> 093/0216;1
> 093/0216;1
> 093/0305;0
> 093/0305;1
> 093/0305;1
> 093/0305;1
> 093/0305;1
> 093/0305;1
> 093/0305;1
> 093/0305;1
> 093/0305;1
> 093/0325;0
> 093/0325;0
> 093/0325;0
> 093/0325;0
> 093/0325;0
> 093/0325;0
> 093/0325;0
> 093/0325;0
> 093/0325;0
> 093/0449;0
> 093/0449;0
> 093/0449;0
> 093/0449;0
> 093/0449;0
> 093/0449;0
> 093/0449;0
> 093/0449;0
> 093/0449;0
> 093/0473;0
> 093/0473;0
> 093/0473;1
> 093/0473;1
> 093/0473;1
> 093/0473;1
> 093/0473;1
> 093/0473;1
> 093/0473;1
> 093/0499;0
> 093/0499;0
> 093/0499;1
> 093/0499;1
> 093/0499;1
> 093/0499;1
> 093/0499;1
> 093/0499;1
> 093/0499;1
> --
> ___________________________________________________________________
> 
> Austrian Institute of Economic Research (WIFO)
> 
> Name: Serguei Kaniovski			P.O.Box 91
> Tel.: +43-1-7982601-231			Arsenal Objekt 20
> Fax:  +43-1-7989386			1103 Vienna, Austria
> Mail: Serguei.Kaniovski at wifo.ac.at
> 
> http://www.wifo.ac.at/Serguei.Kaniovski
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From ripley at stats.ox.ac.uk  Mon Dec  4 14:27:14 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 4 Dec 2006 13:27:14 +0000 (GMT)
Subject: [R] stepAIC for lmer
In-Reply-To: <20061204115552.36606.qmail@web23402.mail.ird.yahoo.com>
References: <20061204115552.36606.qmail@web23402.mail.ird.yahoo.com>
Message-ID: <Pine.LNX.4.64.0612041236520.21914@gannet.stats.ox.ac.uk>

On Mon, 4 Dec 2006, Marc Bernard wrote:

> Dear All,
>
>  I am trying to use stepAIC for an lmer object but it doesn't work. Here is an example:

No, and it is not documented to work with lmer objects.  stepAIC is 
support software for a book, and lmer is not discussed in that book (and 
postdates the book considerably).  lmer does not return an object of the 
type considered by stepAIC (it has an S4 class and it not at all similar 
to e.g. glm).

>
>  x1 <- gl(4,100)
> x2 <- gl(2,200)
> time <- rep(1:4,100)
>  ID <- rep(1:100, each=4)
>  Y <- runif(400) <=.5
>  levels(Y) <- c(1,0)
>  dfr <- as.data.frame(cbind(ID,Y,time,x1,x2))
>
>
>  fm0.lmer <- lmer(Y ~ time+x1+x2 + (1|ID), data = dfr, family = binomial)
>
>  fm.lmer <- stepAIC(fm0.lmer,scope = list(upper = ~I(time-6)*SF_0_N4*SEX, lower = ~1,trace = FALSE))
>
>  I obtain the following error:
>
>  Error in terms.default(object) : no terms component
>
>  I would be very grateful for any suggestion,
>
>  Bernard,
>
>
>
>
>
>
> ---------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Dec  4 14:46:42 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 4 Dec 2006 13:46:42 +0000 (GMT)
Subject: [R] building R 2.4.0 on aix
In-Reply-To: <d05d0f500611290705j12f21af6l6609d9ed9813216f@mail.gmail.com>
References: <Pine.LNX.4.62.0611172137580.7747@trucha11.hpc.unm.edu>
	<d05d0f500611290705j12f21af6l6609d9ed9813216f@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0611291618090.9716@gannet.stats.ox.ac.uk>

I've not seen any response to either of these messages, and so am replying 
in an attempt to provide some explanation.  No core R developer has access 
to AIX, nor have we had for some time.  (Most of the recent workarounds 
for AIX have come from the kind efforts of Ei-ji Nakama.)  It does seem 
AIX rivals Darwin (the underlying OS of MacOS X) for being the least alike 
of the Unix-alikes (but fortunately we have Simon Urbanek to explain 
Darwin to us).

We don't know if R 2.4.0 has been built successfully on AIX: we do know 
that no one reported any problems in the alpha/beta/RC test period.  If no 
one tested it, this indicates a lack of support for the R developers from 
the AIX community.  I believe I have seen a report which indicated that R 
2.3.1 was built successfully.

Some more specific comments to Eric Harley:

> configure:26491: checking how to get verbose linking output from f95
> configure:26502: f95 -c  conftest.f >&5
> f95: 1501-218 file conftest.f contains an incorrect file suffix

It seems your 'f95' is not a conventional Fortran compiler.  But you have 
not told us what compiler it is: only if we know the full story can we 
advise against it.

> but make exits early with errors.

Without telling us what they are, the experts here cannot help.


On Wed, 29 Nov 2006, Eric Harley wrote:

> Roy and others,
>
> I'm also trying to build R 2.4.0 on aix 5 (5.3 in my case, on an
> Intellistation Power 285) and I have not had luck yet.  I notice that
> the only mentions of AIX on this list in the past two months are
> people not having luck building it.  So far there don't seem to be any
> responses, and I don't know if it's from lack of information in the
> questions, or because this isn't the right place to ask the questions.

There have been replies, but no responses to those replies.  We often do 
not find out if problems do get resolved.

> Does anyone know a good place to ask such questions?  If this is the
> right place, please let me know what information you need.
>
> I am unfortunately very new to this business of compiling and linking
> on Unix, so I have trouble knowing what information to provide.
>
> Here's my stab at troubleshooting, which is basically trial-and-error:
>
> ===
> tried just to type ./configure (I can always dream, right?  :-) )
> Failed with the following problem in config.log
>
> configure:26491: checking how to get verbose linking output from f95
> configure:26502: f95 -c  conftest.f >&5
> f95: 1501-218 file conftest.f contains an incorrect file suffix
> configure:26508: $? = 1
> configure: failed program was:
> |       program main
> |
> |       end
> configure:26587: WARNING: compilation failed
> configure:26593: result:
> config.log (93%)
>
> ===
> A little playing around shows me that f95 doesn't like to compile
> files ending in .f, so I try doing
> ./configure F77=f77
>
> In this case, the configure script completes successfully.
> Now I try
> make
>
> but make exits early with errors.
> make check
> gives
>
> make: 1254-002 Cannot find a rule to create target
> ../../src/library/base/all.R from dependencies.
> Stop.
>
> and a few other 1254-004 errors.
>
> ===
> There are some examples in
> http://cran.r-project.org/doc/manuals/R-admin.html , particularly in
> the AIX platform notes (C.9 AIX).  However, the second paragraph says
> "The rest of this section is historical, as the default *_LDFLAGS were
> changed in R 2.4.0." so evidently the examples don't apply to the
> current version of R.  I tried some frankenstein combinations of the
> options given in the examples, using the xl*_* compilers since I don't
> have gfortran on my system, but this kind of thing is time-consuming
> when I'm essentially making random changes.
>
> I'm hoping that someone with more experience than I can at least help
> me sort through the "Cannot find a rule to create target" error, and
> that maybe I can proceed somehow one error at a time and finally end
> up with something that works.
>
> BTW, I did try to google the "Cannot find a rule to create target"
> "from dependencies", but I don't get much that I can understand.  One
> message said something about this means make can't find the source
> code.  If this is the problem, how can I figure out what source code
> make is looking for, where it's looking for it, and how to tell it the
> right place to look?  Or perhaps there's something else I'm missing?
>
> Thanks,
> Eric Harley
>
>
> On 11/20/06, Roy Heimbach <royh at hpc.unm.edu> wrote:
>> I'm trying to build R 2.4.0 on aix 5 and not having much luck.  If
>> anyone on the list has built 2.3 or 2.4 on AIX and would be willing
>> pass along some hints, I would be grateful.  So would the research
>> group that's waiting to use R.
>>
>> Thanks,
>> Roy Heimbach
>> --
>> Roy Heimbach <royh at hpc.unm.edu> / 505-277-8348
>> User Services / Center for High Performance Computing
>> University of New Mexico
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Mon Dec  4 14:47:41 2006
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 4 Dec 2006 08:47:41 -0500
Subject: [R] Box Tidwell / Error Message / Error in parse(file, n, text,
	prompt) : syntax error in
In-Reply-To: <E1Gr8da-00064q-00@smtp06.web.de>
Message-ID: <20061204134739.KMSF5067.tomts5-srv.bellnexxia.net@JohnDesktop8300>

Dear Simon,

I think that the most likely answer is that there's an error in the command
that you wrote (which is being sourced from a file?), but it's hard to tell
from the information that you supply. It might help to do a traceback()
after the error. I doubt that the error depends on the data.

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Simon P. Kempf
> Sent: Monday, December 04, 2006 2:53 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Box Tidwell / Error Message / Error in 
> parse(file, n, text,prompt) : syntax error in
> 
> Dear R-Users,
> 
>  
> 
> I used the box.tidwell () function of the car Package. 
> 
>  
> 
> So far everything is fine. However, if the number of dummy 
> variables in the part not to be transformed (other.x formula) 
> exceeds a certain level (around 70), I receive the following 
> error message:
> 
>  
> 
> Error in parse(file, n, text, prompt) : syntax error in 
> 
>  
> 
> What did I miss? And how can I solve this problem?
> 
>  
> 
> I read some of the messages in the mail archives about this 
> error message, but to be honest I am rather a novice in R, I 
> did not understand them.
> 
>  
> 
> Some background information:
> 
>  
> 
> -          The data set does not have any missing values
> 
> -          The data set contains more than 19000 observations.
> 
>  
> 
> Thanks in advance and if you need more information about the 
> data, please let me know,
> 
>  
> 
> Simon
> 
>  
> 
>  
> 
>  
> 
>  
> 
> Simon P. Kempf 
> 
> Dipl.-Kfm. MScRE Immobilienvkonom (ebs)
> 
> Wissenschaftlicher Assistent
> 
>  
> 
> B|ro:
> 
> IREBS Immobilienakademie
> 
> c/o ebs Immobilienakademie GmbH
> 
> Berliner Str. 26a
> 
> 13507 Berlin
> 
>  
> 
> Privat:
> 
> Dunckerstra_e 60
> 
> 10439 Berlin
> 
>  
> 
> Mobil: 0176 7002 6687
> 
> Email:  <mailto:simon.kempf at web.de> simon.kempf at web.de
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
>



From ghoneimmf at yahoo.com  Mon Dec  4 11:28:20 2006
From: ghoneimmf at yahoo.com (mohamed ghoneim)
Date: Mon, 4 Dec 2006 02:28:20 -0800 (PST)
Subject: [R] ask for help
Message-ID: <153111.79503.qm@web56613.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061204/1c8f43e8/attachment-0004.pl 

From r.hankin at noc.soton.ac.uk  Mon Dec  4 15:08:38 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Mon, 4 Dec 2006 14:08:38 +0000
Subject: [R] backticks
Message-ID: <398217B3-5BB4-48AB-B594-9A559E4488E7@soc.soton.ac.uk>

I noticed just now that
package.skeleton() produces R files in which
the function names are escaped with backticks.

?Quotes says that "The preferred quote is the backtick (`)",
but I don't understand _why_  this is preferred.

?formula gives some clues but points out that there
are no guarantees that formulae using non-syntactic names such as
`like this` will be accepted.

What exactly do backticks do that single or double quotes don't?
Where do I look for documentation on this?




--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From timb at metrumrg.com  Mon Dec  4 15:15:34 2006
From: timb at metrumrg.com (Tim Bergsma)
Date: Mon, 04 Dec 2006 09:15:34 -0500
Subject: [R] S4 newbie - extending S3 classes
Message-ID: <45742D86.8060407@metrumrg.com>

I tried recently to extend data.frame using S4, with depressing results. 
  Someone asked about this back in January, and was referred to the 
"Register or Convert" advice.  Putting the pieces together, I'm guessing 
  that to extend data.frame usefully in S4, one would actually have to 
write it from scratch, creating all the usual attributes, methods, etc. 
  One certainly wouldn't want to do this if unnecessary or if already 
done by someone more competent.  I've ordered John Chamber's book 
"Programming with Data".  In the meantime, can someone confirm/deny my 
suspicions that data.frame would need an S4 rewrite and that no standard 
rewrite exists?

Thanks,

Tim.



From s.wood at bath.ac.uk  Mon Dec  4 15:14:45 2006
From: s.wood at bath.ac.uk (Simon Wood)
Date: Mon, 4 Dec 2006 14:14:45 +0000
Subject: [R] GAM model selection and dropping terms based on GCV
In-Reply-To: <20061204123033.3420.qmail@web51106.mail.yahoo.com>
References: <20061204123033.3420.qmail@web51106.mail.yahoo.com>
Message-ID: <200612041414.45265.s.wood@bath.ac.uk>

On Monday 04 December 2006 12:30, aditya gangadharan wrote:
> Hello,
> I have a question regarding model selection and dropping of terms for GAMs
> fitted with package mgcv. I am following the approach suggested in Wood
> (2001), Wood and Augustin (2002).
>
> I fitted a saturated model, and I find from the plots that for two of the
> covariates, 1. The confidence interval includes 0 almost everywhere
> 2. The degrees of freedom are NOT close to 1
> 3. The partial residuals from plot.gam don?t show much pattern visually (to
> me) 4. When I drop either or both of the terms, the GCV score increases;
>
> This is my main problem: how much of an increase in GCV is ?acceptable?
> when terms are dropped? In the above case, the delta GCV scores are .03,
> .06 and .11 when I drop covariate A, covariate B and both respectively from
> the full model. I would be very grateful for any advice on this.
- I'm not sure that there is really an answer to this. GCV  is based on 
minimizing some approximation to the expected prediction error of the model. 
So to answer the question you'd need to do something like decide how much 
increase from `optimal' prediction error you would be prepared to tolerate. 
I think that it's not all that easy to come up with a nice way of blending  
prediction error based approaches to model selection, with approaches based 
on finding a model that is somehow the simplest model consistent with the 
data (but perhaps other people will comment on this). 

- That said, there is certainly an issue relating to the fact that the GCV 
score (or AIC, in fact) is rather asymmetric, so that random variability in 
the score tends to lead more readily to overfitting than to underfitting. 
This suggests that in fact prediction error performance at finite sample 
sizes may be improved by shrinking the smoothing parameters themselves. With 
`mgcv::gam' you can do this by increasing the `gamma' parameter above it's 
default value, which favours smoother models by making each model degree of 
freedom count as gamma degrees of freedom in the GCV score (or AIC/UBRE). It 
is possible to choose `gamma' by e.g. 10-fold cross-validation, but that 
requires some coding.

- There are more discussions of GAM model selection in various mgcv help files 
and my book. See help("mgcv-package") for details of which pages, and the 
reference. 

My bottom line on model seelction is to use things like GCV, AIC, confidence 
interval coverage and approximate p-values for guidance, but not as the basis 
for rules... modelling context has to play a part as well. 

Sorry if that's all a bit vague.

Simon


-- 
> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283



From justin_bem at yahoo.fr  Mon Dec  4 15:31:52 2006
From: justin_bem at yahoo.fr (justin bem)
Date: Mon, 4 Dec 2006 14:31:52 +0000 (GMT)
Subject: [R] Regression question ...
Message-ID: <20061204143152.15504.qmail@web23011.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061204/2ffd1323/attachment-0004.pl 

From P.Dalgaard at biostat.ku.dk  Mon Dec  4 15:33:00 2006
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 04 Dec 2006 15:33:00 +0100
Subject: [R] backticks
In-Reply-To: <398217B3-5BB4-48AB-B594-9A559E4488E7@soc.soton.ac.uk>
References: <398217B3-5BB4-48AB-B594-9A559E4488E7@soc.soton.ac.uk>
Message-ID: <4574319C.7050806@biostat.ku.dk>

Robin Hankin wrote:
> I noticed just now that
> package.skeleton() produces R files in which
> the function names are escaped with backticks.
>
> ?Quotes says that "The preferred quote is the backtick (`)",
> but I don't understand _why_  this is preferred.
>
> ?formula gives some clues but points out that there
> are no guarantees that formulae using non-syntactic names such as
> `like this` will be accepted.
>
> What exactly do backticks do that single or double quotes don't?
>   
I don't know whether we really want to be that dogmatic about it, but in
a nutshell

`like this` <- 2
"like that" <- 3
print(`like this`)
print("like that")

I.e. backtick'ed names work whereever ordinary names do, but quoted
names work only on the LHS of assignments.

The note in ?formula should probably be understood defensively: We
intend backtick'ed names to work in all contexts, but  there may be
programming practices where the backticks are not preserved (notably if
there is a deparse-reparse step involved).

> Where do I look for documentation on this?
>
>
>
>
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>   tel  023-8059-7743
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ethan.johnsons at gmail.com  Mon Dec  4 15:37:55 2006
From: ethan.johnsons at gmail.com (Ethan Johnsons)
Date: Mon, 4 Dec 2006 09:37:55 -0500
Subject: [R] prop.trend.test issue
In-Reply-To: <7.0.0.16.2.20061204070447.025f07b8@centroin.com.br>
References: <5cd96f050612022155l5dfc8e3en5b077a0600b87598@mail.gmail.com>
	<7.0.0.16.2.20061204070447.025f07b8@centroin.com.br>
Message-ID: <5cd96f050612040637r54f698adrc37192cd71b8d052@mail.gmail.com>

On 12/4/06, Bernardo Rangel tura <tura at centroin.com.br> wrote:
> At 03:55 AM 12/3/2006, Ethan Johnsons wrote:
> >I have the clinical study data.
> >
> >                                            Year 0       Year 3
> >Retinol (nmol/L)        N       Mean +-sd       Mean +-sd
> >Vitamin A group         73      1.89+-0.36      2.06+-0.53
> >Trace group                57      1.83+-0.31     1.78+-0.30
> >
> >where N is the number of male for the clinical study.
> >
> >I want to test if the mean serum retinol has increased over 3 years
> >among subjects in the vitamin A group.
>
>
> If  You desire check mean serum retinol has increased over 3 years in
> vitamin A group.
> You may use t.test
> Look this example:
>
> #Generate random Data
>
> set.seed(123)
> VitA1<-rnorm(73,1.89,.36)
> Trace1<-rnorm(57,1.83,0.31)
> VitA2<-rnorm(73,2.06,.53)
> Trace2<-rnorm(57,1.78,0.30)
>
> # Calculate diference Year 3 - Year 0
>
> dVitA<-VitA2-VitA1
> dTrace<-Trace2-Trace1
>
> # Testing diference
> t.test(dVitA,dTrace)
>
>
>          Welch Two Sample t-test
>
> data:  dVitA and dTrace
> t = 2.2762, df = 117.746, p-value = 0.02464
> alternative hypothesis: true difference in means is not equal to 0
> 95 percent confidence interval:
>   0.02756874 0.39659494
> sample estimates:
>    mean of x   mean of y
>   0.15905162 -0.05303022
>
>
>
>
>
> Bernardo Rangel Tura, MD, Phd
> National Institute of Cardiology Laranjeiras
> Rio de Janeiro Brazil
>
>

Thank you so much.  It is clear now.

ej



From r.hankin at noc.soton.ac.uk  Mon Dec  4 15:42:41 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Mon, 4 Dec 2006 14:42:41 +0000
Subject: [R] backticks
In-Reply-To: <4574319C.7050806@biostat.ku.dk>
References: <398217B3-5BB4-48AB-B594-9A559E4488E7@soc.soton.ac.uk>
	<4574319C.7050806@biostat.ku.dk>
Message-ID: <C453AB21-CFB6-4EA4-ADBD-33ECF3F617C6@soc.soton.ac.uk>

Peter

Aha!  so R backticks work just like bash backticks  (duh!)
unless they are on the LHS of an assignment.

[We bash people now use $(...) instead]

Could we add something to this effect to Quotes.Rd?


rksh


On 4 Dec 2006, at 14:33, Peter Dalgaard wrote:

> Robin Hankin wrote:
>>
[snip]
>> What exactly do backticks do that single or double quotes don't?
>>
> I don't know whether we really want to be that dogmatic about it,  
> but in
> a nutshell
>
> `like this` <- 2
> "like that" <- 3
> print(`like this`)
> print("like that")
>
> I.e. backtick'ed names work whereever ordinary names do, but quoted
> names work only on the LHS of assignments.
>
> The note in ?formula should probably be understood defensively: We
> intend backtick'ed names to work in all contexts, but  there may be
> programming practices where the backticks are not preserved  
> (notably if
> there is a deparse-reparse step involved).
>
>> Where do I look for documentation on this?
>>
>>
>>
>>
>> --
>> Robin Hankin
>> Uncertainty Analyst
>> National Oceanography Centre, Southampton
>> European Way, Southampton SO14 3ZH, UK
>>   tel  023-8059-7743
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> -- 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)  
> 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)  
> 35327907

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From zia.wadud at imperial.ac.uk  Mon Dec  4 16:04:17 2006
From: zia.wadud at imperial.ac.uk (Wadud, Zia)
Date: Mon, 4 Dec 2006 15:04:17 -0000
Subject: [R] package mgcv, command gamm
Message-ID: <735C1873E656C24699818814048F8FB004C7CAB7@icex1.ic.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061204/383ad5ba/attachment-0004.pl 

From jrkrideau at yahoo.ca  Mon Dec  4 16:08:55 2006
From: jrkrideau at yahoo.ca (John Kane)
Date: Mon, 4 Dec 2006 10:08:55 -0500 (EST)
Subject: [R] creating column based on another variable
In-Reply-To: <!&!AAAAAAAAAAAYAAAAAAAAAEuLs8ZPMuFInPbB+1JmPy7CgAAAEAAAAFlGOuVXOglMl9dsiAiWt/kBAAAAAA==@adsam.com>
Message-ID: <161812.28076.qm@web32807.mail.mud.yahoo.com>


--- Jeff Miller <jeffmiller at adsam.com> wrote:

> Hi all,
> 
> I hope someone can help me with this.

> Suppose I import a text file and one of the columns
> looks like this:
> 
> New York
> 
> New York
> 
> England
> 
> Spain
> 
> Spain
> 
> Orlando
> 
> New York
> 
> England
> 
> France
> 

> I want to add a variable that is based on the
> previous one
> 
>  
> 
> US
> 
> US
> 
> Europe
> 
> Europe
> 
> Europe
> 
> US
> 
> US
> 
> Europe
> 
> Europe
> 
> How do that?

?cbind

> Also, I would like to be able to export the data as
> a text file that retains
> this new variable.

> Any suggestions are greatly appreciated,
 
> Jeff Miller

?write.table
?write.csv

It might be a good idea to read a bit about how R
works.  A handy tutorial is 
http://www.math.ilstu.edu/dhkim/Rstuff/Rtutor.html

and you should have a look at the FAQ and the Intro to
R   both available the main R site
http://www.r-project.org/



From P.Dalgaard at biostat.ku.dk  Mon Dec  4 16:17:00 2006
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 04 Dec 2006 16:17:00 +0100
Subject: [R] backticks
In-Reply-To: <C453AB21-CFB6-4EA4-ADBD-33ECF3F617C6@soc.soton.ac.uk>
References: <398217B3-5BB4-48AB-B594-9A559E4488E7@soc.soton.ac.uk>	<4574319C.7050806@biostat.ku.dk>
	<C453AB21-CFB6-4EA4-ADBD-33ECF3F617C6@soc.soton.ac.uk>
Message-ID: <45743BEC.3040802@biostat.ku.dk>

Robin Hankin wrote:
> Peter
>
> Aha!  so R backticks work just like bash backticks  (duh!)
>   

Er, no. Backticks in shells have a command inside that will be evaluated
and replaced by its output. (This is a bit confusing, but single and
double quotes were already taken at the time...)

> unless they are on the LHS of an assignment.
>
> [We bash people now use $(...) instead]
>
> Could we add something to this effect to Quotes.Rd?
>
>
> rksh
>
>
> On 4 Dec 2006, at 14:33, Peter Dalgaard wrote:
>
>   
>> Robin Hankin wrote:
>>     
> [snip]
>   
>>> What exactly do backticks do that single or double quotes don't?
>>>
>>>       
>> I don't know whether we really want to be that dogmatic about it,  
>> but in
>> a nutshell
>>
>> `like this` <- 2
>> "like that" <- 3
>> print(`like this`)
>> print("like that")
>>
>> I.e. backtick'ed names work whereever ordinary names do, but quoted
>> names work only on the LHS of assignments.
>>
>> The note in ?formula should probably be understood defensively: We
>> intend backtick'ed names to work in all contexts, but  there may be
>> programming practices where the backticks are not preserved  
>> (notably if
>> there is a deparse-reparse step involved).
>>
>>     
>>> Where do I look for documentation on this?
>>>
>>>
>>>
>>>
>>> --
>>> Robin Hankin
>>> Uncertainty Analyst
>>> National Oceanography Centre, Southampton
>>> European Way, Southampton SO14 3ZH, UK
>>>   tel  023-8059-7743
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>       
>> -- 
>>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)  
>> 35327918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)  
>> 35327907
>>     
>
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>   tel  023-8059-7743
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ggrothendieck at gmail.com  Mon Dec  4 16:46:38 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 4 Dec 2006 10:46:38 -0500
Subject: [R] backticks
In-Reply-To: <45743BEC.3040802@biostat.ku.dk>
References: <398217B3-5BB4-48AB-B594-9A559E4488E7@soc.soton.ac.uk>
	<4574319C.7050806@biostat.ku.dk>
	<C453AB21-CFB6-4EA4-ADBD-33ECF3F617C6@soc.soton.ac.uk>
	<45743BEC.3040802@biostat.ku.dk>
Message-ID: <971536df0612040746r3f95537dqd9ae2df3bdb0eca4@mail.gmail.com>

On 12/4/06, Peter Dalgaard <P.Dalgaard at biostat.ku.dk> wrote:
> Robin Hankin wrote:
> > Peter
> >
> > Aha!  so R backticks work just like bash backticks  (duh!)
> >
>
> Er, no. Backticks in shells have a command inside that will be evaluated
> and replaced by its output. (This is a bit confusing, but single and
> double quotes were already taken at the time...)

This shell-like behavior is also available in the gsubfn package
which allows one to process string arguments in arbitrary functions
using backticks by prefacing the function in question with fn$.
For example, by prefacing cat with fn$ we have:

   > library(gsubfn)
   > fn$cat("pi = $pi, pi/2 = `pi/2`\n")
   pi = 3.14159265358979, pi/2 = 1.57079632679490

>
> > unless they are on the LHS of an assignment.
> >
> > [We bash people now use $(...) instead]
> >
> > Could we add something to this effect to Quotes.Rd?
> >
> >
> > rksh
> >
> >
> > On 4 Dec 2006, at 14:33, Peter Dalgaard wrote:
> >
> >
> >> Robin Hankin wrote:
> >>
> > [snip]
> >
> >>> What exactly do backticks do that single or double quotes don't?
> >>>
> >>>
> >> I don't know whether we really want to be that dogmatic about it,
> >> but in
> >> a nutshell
> >>
> >> `like this` <- 2
> >> "like that" <- 3
> >> print(`like this`)
> >> print("like that")
> >>
> >> I.e. backtick'ed names work whereever ordinary names do, but quoted
> >> names work only on the LHS of assignments.
> >>
> >> The note in ?formula should probably be understood defensively: We
> >> intend backtick'ed names to work in all contexts, but  there may be
> >> programming practices where the backticks are not preserved
> >> (notably if
> >> there is a deparse-reparse step involved).
> >>
> >>
> >>> Where do I look for documentation on this?
> >>>
> >>>
> >>>
> >>>
> >>> --
> >>> Robin Hankin
> >>> Uncertainty Analyst
> >>> National Oceanography Centre, Southampton
> >>> European Way, Southampton SO14 3ZH, UK
> >>>   tel  023-8059-7743
> >>>
> >>> ______________________________________________
> >>> R-help at stat.math.ethz.ch mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-
> >>> guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >> --
> >>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
> >>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> >>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)
> >> 35327918
> >> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)
> >> 35327907
> >>
> >
> > --
> > Robin Hankin
> > Uncertainty Analyst
> > National Oceanography Centre, Southampton
> > European Way, Southampton SO14 3ZH, UK
> >   tel  023-8059-7743
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From s.wood at bath.ac.uk  Mon Dec  4 17:32:55 2006
From: s.wood at bath.ac.uk (Simon Wood)
Date: Mon, 4 Dec 2006 16:32:55 +0000
Subject: [R] package mgcv, command gamm
In-Reply-To: <735C1873E656C24699818814048F8FB004C7CAB7@icex1.ic.ac.uk>
References: <735C1873E656C24699818814048F8FB004C7CAB7@icex1.ic.ac.uk>
Message-ID: <200612041632.55125.s.wood@bath.ac.uk>




On Monday 04 December 2006 15:04, Wadud, Zia wrote:
> Hi
> I am an engineer and am running the package mgcv and specifically the
> command gamm (generalized additive mixed modelling), with random
> effects. i have a few queries:
> 1. When I run the command with 1000/2000 observations, it runs ok.
> However, I would like to see the results as in vis.gam command in the
> same package, with the 3-d visuals. It appears no such option is
> available for gamm in the manual. I was wondering if someone has used
> this before and obtained the plots similar to vis.gam, which I believe
> plots the predictions automatically. I have used 'te' command for two
> way interaction of the smooth terms, plus some paramteric terms.
here's a working example....
 library(mgcv)
      ## simple examples using gamm as alternative to gam
      set.seed(0)
      n <- 400
      sig <- 2
      x0 <- runif(n, 0, 1)
      x1 <- runif(n, 0, 1)
      x2 <- runif(n, 0, 1)
      x3 <- runif(n, 0, 1)
      f <- 2 * sin(pi * x0)
      f <- f + exp(2 * x1) - 3.75887
      f <- f+0.2*x2^11*(10*(1-x2))^6+10*(10*x2)^3*(1-x2)^10-1.396
      e <- rnorm(n, 0, sig)
      y <- f + e
      b <- gamm(y~s(x0)+s(x1)+s(x2)+s(x3))
   vis.gam(b$gam)



> 2. I am not sure how the gamm results are saved, and if prediction is at
> all possible. The documentations talks about gam in detail, but not
> gamm.
- There are 2 parts to a gamm fitted model object, an `lme' fitted model 
object, and a `gam' fitted model object. They refer to the same model, of 
course, but simply refer to it in different ways. You can do prediction with 
either part, but it's easiest with the `gam' part, e.g. following the 
previous example...

predict(b$gam)

> 3. When I use my entire dataset (approx 58000 obs, and, well even with
> 10000 observations) I am running against memory all the time (it says
> cannot allocate a  vector of size 'some number). I used it on a 3GB RAM
> machine and I am suspicious if it is something else.
- This will run out of memory if you are using the default "tp" basis for any 
terms --- if that is the case then either change basis to "cr" or use the 
`knots' argument as detailed at the end of the ?gam examples.

- I would need to know more about the model structure to make any further 
suggestions here.... 

best,
Simon


> Many thanks in advance,
> Zia
>
>
> **********************************************************
> Zia Wadud
> PhD Student
> Centre for Transport Studies
> Department of Civil and Environmental Engineering
> Imperial College London
> London SW7 2AZ
> Tel +44 (0) 207 594 6055
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented, minimal,
> self-contained, reproducible code.

-- 
> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283



From amnakhan493 at gmail.com  Mon Dec  4 17:42:56 2006
From: amnakhan493 at gmail.com (amna khan)
Date: Mon, 4 Dec 2006 08:42:56 -0800
Subject: [R] Help for L-moment Ratio Diagram
Message-ID: <3ffd3bb60612040842w93c7e64v6a2b312ee0115f97@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061204/c529334c/attachment-0004.pl 

From jbcombes at gmail.com  Mon Dec  4 18:06:29 2006
From: jbcombes at gmail.com (Jean-Baptiste Combes)
Date: Mon, 4 Dec 2006 18:06:29 +0100
Subject: [R] Weight and see
Message-ID: <959b0bd80612040906v643aba9y127e74e2dc520684@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061204/34b932b4/attachment-0004.pl 

From tlumley at u.washington.edu  Mon Dec  4 18:16:15 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 4 Dec 2006 09:16:15 -0800 (PST)
Subject: [R] Weight and see
In-Reply-To: <959b0bd80612040906v643aba9y127e74e2dc520684@mail.gmail.com>
References: <959b0bd80612040906v643aba9y127e74e2dc520684@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0612040915420.21245@homer22.u.washington.edu>

On Mon, 4 Dec 2006, Jean-Baptiste Combes wrote:

> Hello,
>
> I am new on this list so please forgive me if I ask thnigs that were already
> solved.
> I am a french statistician and i would like to use R in my job, but I would
> like to know (I haven't found yet) if R can take into account weights. I am
> working on a study which had to get a weight variable, in order to make the
> sample close to the population in terms of sex and universities (I am
> working on students).
>

The 'survey' package can use weights and other sampling information to get 
correct population estimates.

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From m.bridgman at sbcglobal.net  Mon Dec  4 18:44:14 2006
From: m.bridgman at sbcglobal.net (Matthew Bridgman)
Date: Mon, 4 Dec 2006 09:44:14 -0800
Subject: [R] Multilevel Modeling in R
Message-ID: <82E7FED9-447F-4608-A194-6AE7708E2264@sbcglobal.net>

Can anyone recommend a good text or resource for learning how to do  
Multilevel modeling in R?

Thanks,
   Matt



From gerifalte28 at hotmail.com  Mon Dec  4 18:48:53 2006
From: gerifalte28 at hotmail.com (Francisco Zagmutt)
Date: Mon, 04 Dec 2006 10:48:53 -0700
Subject: [R] Multilevel Modeling in R
In-Reply-To: <82E7FED9-447F-4608-A194-6AE7708E2264@sbcglobal.net>
References: <82E7FED9-447F-4608-A194-6AE7708E2264@sbcglobal.net>
Message-ID: <45745F85.7080408@hotmail.com>

An excellent resource with many examples and R code is:
Mixed Effects Models in S and S-Plus by Jose C. Pinheiro, Douglas M. Bates


Dr. Francisco J. Zagmutt
College of Veterinary Medicine and Biomedical Sciences
Colorado State University


Matthew Bridgman wrote:
> Can anyone recommend a good text or resource for learning how to do  
> Multilevel modeling in R?
> 
> Thanks,
>    Matt
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From ccleland at optonline.net  Mon Dec  4 19:00:45 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Mon, 04 Dec 2006 13:00:45 -0500
Subject: [R] Multilevel Modeling in R
In-Reply-To: <82E7FED9-447F-4608-A194-6AE7708E2264@sbcglobal.net>
References: <82E7FED9-447F-4608-A194-6AE7708E2264@sbcglobal.net>
Message-ID: <4574624D.5060402@optonline.net>

Matthew Bridgman wrote:
> Can anyone recommend a good text or resource for learning how to do  
> Multilevel modeling in R?

  Here are a few other resources in addition to Pinheiro & Bates (2000):

http://finzi.psych.upenn.edu/R/library/mlmRev/doc/MlmSoftRev.pdf

http://cran.r-project.org/doc/packages/multilevel.pdf

http://stat.ethz.ch/CRAN/doc/Rnews/Rnews_2003-3.pdf [Lockwood, Doran &
McCaffrey]

http://cran.r-project.org/doc/contrib/Fox-Companion/appendix-mixed-models.pdf

> Thanks,
>    Matt
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894



From ericthompso at gmail.com  Mon Dec  4 19:05:03 2006
From: ericthompso at gmail.com (Eric Thompson)
Date: Mon, 4 Dec 2006 13:05:03 -0500
Subject: [R] Help for L-moment Ratio Diagram
In-Reply-To: <3ffd3bb60612040842w93c7e64v6a2b312ee0115f97@mail.gmail.com>
References: <3ffd3bb60612040842w93c7e64v6a2b312ee0115f97@mail.gmail.com>
Message-ID: <e603d4040612041005w41722a3by5f23faf242732987@mail.gmail.com>

I think there are a few packages for doing this. I have used "lmomco":
the function lmom.ub() will calculate the sample lmoments, and
lmrdia() gives theoretical lmoments for different distributions.

Hope this is helpful.

Eric


On 12/4/06, amna khan <amnakhan493 at gmail.com> wrote:
> Respected Sir
>
> I have to select a probability distribution using L-moment Ratio Diagram. I
> am not understanding how to plot sample TAU3 and TUA4 on L-moment Ratio
> Diagram.
> Please Guide me
> Best Regards
>
> --
> AMINA SHAHZADI
> Department of Statistics
> GC University Lahore, Pakistan.
> Email:
> amnakhan493 at gmail.com
> amna_989 at hotmail.com
> amna_989 at yahoo.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From m4lawren at artsmail.uwaterloo.ca  Mon Dec  4 19:09:01 2006
From: m4lawren at artsmail.uwaterloo.ca (Mike Lawrence)
Date: Mon, 04 Dec 2006 14:09:01 -0400
Subject: [R] How to calculate area between ECDF and CDF?
Message-ID: <4574643D.7090006@artsmail.uwaterloo.ca>

Hi all,

I'm working with data to which I'm fitting three-parameter weibull 
distributions (shape, scale & shift). The data are of low sample sizes 
(between 10 and 80 observations), so I'm reluctant to check my fits 
using chi-square (also, I'd like to avoid bin choice issues). I'd use 
the Kolmogorov-Smirnov test, but of course this is invalid when the 
distribution parameters are estimated from the data.

So I'm tinkering with an alternative method (excuse my naivet? if this 
is a bad idea, I'm a relative statistical novice) that calculates the 
area of the difference between the ECDF of the data and the CDF of the 
estimated function (somewhat like KS, which looks at the greatest 
distance between these). My thought is to compare this observed area to 
a distribution of simulated areas derived by monte carlo simulation 
(draw N random samples from the estimated function, calculating area, 
and repeat 1e5 times). If the observed area is greater than say 95% of 
the simulated areas, then I'd reject the fit.

My problem is that I can't figure out how to efficiently calculate the 
area between the ECDF and CDF functions. I can of course calculate the 
integral of each easily, and if one were consistently larger than the 
other simple subtraction of the integrals would yield the area between. 
However, when the functions cross, as frequently occurs, the solution 
seems much more complex. Any suggestions? Since as noted above I'll be 
doing the area calculation 1e5 times or so per test, a computationally 
frugal solution would be much appreciated!

Here's some code that I've been toying with:

#set up some true parameters
shape=2
scale=.5
shift=.3
n=10

#generate some observed data
obs=obs=rweibull(10,shape,scale)+shift

#lets say that the following are the estimated parameters from whatever 
estimation process I'm using
est.shape=1.9
est.scale=.6
est.shift=.35

#Calculate area between ECDF and CDF of the function defined by the
#estimated parameters
# ???
#The following would work if the ECDF were consistently higher or lower
#than the CDF

#Get the CDF area between 0 and some large number (here, 10 is pretty
#large)
cdf.area=integrate(pweibull,0,10,shape=est.shape,scale=est.scale)

#Get the ECDF area.
#first get rid of the shift in obs
obs=obs-est.shift
#calculate area by multiplying cumulative proportions by distance
#between knots, then summing
#add knot at 10 to match cdf
k=c(knots(ecdf(obs)),10)
ecdf.area=vector("numeric",(n-1))
for(i in 1:n){
	ecdf.area[i]=(k[i+1]-k[i])*(sum(obs<=k[i])/n)
}
ecdf.area=sum(ecdf.area)

#again, subtraction of the areas works if the ecdf is consistently lower
#than the cdf
diff=cdf.area-ecdf.area
#or consistently higher than the cdf
diff=ecdf.area-cdf.area
#but how to calculate when the functions cross?
	

Cheers,

Mike

-- 
Mike Lawrence
http://artsweb.uwaterloo.ca/~m4lawren

"The road to wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
- Piet Hein



From jeffmiller at alphapoint05.net  Mon Dec  4 19:11:32 2006
From: jeffmiller at alphapoint05.net (Jeff Miller)
Date: Mon, 4 Dec 2006 13:11:32 -0500
Subject: [R] Multilevel Modeling in R
In-Reply-To: <4574624D.5060402@optonline.net>
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAEuLs8ZPMuFInPbB+1JmPy7CgAAAEAAAANlAyaWrFjhPtnYyvF/kdW0BAAAAAA==@alphapoint05.net>

Wow, would someone please send pdf links like that for SEM?

Thanks,
Jeff

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Chuck Cleland
Sent: Monday, December 04, 2006 1:01 PM
To: Matthew Bridgman
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Multilevel Modeling in R

Matthew Bridgman wrote:
> Can anyone recommend a good text or resource for learning how to do  
> Multilevel modeling in R?

  Here are a few other resources in addition to Pinheiro & Bates (2000):

http://finzi.psych.upenn.edu/R/library/mlmRev/doc/MlmSoftRev.pdf

http://cran.r-project.org/doc/packages/multilevel.pdf

http://stat.ethz.ch/CRAN/doc/Rnews/Rnews_2003-3.pdf [Lockwood, Doran &
McCaffrey]

http://cran.r-project.org/doc/contrib/Fox-Companion/appendix-mixed-models.pd
f

> Thanks,
>    Matt
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From royh at hpc.unm.edu  Mon Dec  4 19:26:27 2006
From: royh at hpc.unm.edu (Roy Heimbach)
Date: Mon, 4 Dec 2006 11:26:27 -0700 (MST)
Subject: [R] building R 2.4.0 on aix
In-Reply-To: <Pine.LNX.4.64.0611291618090.9716@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.62.0611172137580.7747@trucha11.hpc.unm.edu>
	<d05d0f500611290705j12f21af6l6609d9ed9813216f@mail.gmail.com>
	<Pine.LNX.4.64.0611291618090.9716@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.62.0612041120590.22323@trucha11.hpc.unm.edu>

Prof. Ripley:

Thanks for a clear statement of the situation.  Lack of response to
my post, coupled with the many prompt and knowledgeable responses
to other posts, led me to believe something like this must be true.

I have access to an AIX machine, and probably enough help to sort out
the 2.4.0 build issues under AIX.  I'm hoping to post something useful
to other AIX users in January or February.

Cheers,
Roy Heimbach

On Mon, 4 Dec 2006, Prof Brian Ripley wrote:
> I've not seen any response to either of these messages, and so am replying in 
> an attempt to provide some explanation.  No core R developer has access to 
> AIX, nor have we had for some time.  (Most of the recent workarounds for AIX 
> have come from the kind efforts of Ei-ji Nakama.)  It does seem AIX rivals 
> Darwin (the underlying OS of MacOS X) for being the least alike of the 
> Unix-alikes (but fortunately we have Simon Urbanek to explain Darwin to us).
>
> We don't know if R 2.4.0 has been built successfully on AIX: we do know that 
> no one reported any problems in the alpha/beta/RC test period.  If no one 
> tested it, this indicates a lack of support for the R developers from the AIX 
> community.  I believe I have seen a report which indicated that R 2.3.1 was 
> built successfully.
>
> Some more specific comments to Eric Harley:
>
>> configure:26491: checking how to get verbose linking output from f95
>> configure:26502: f95 -c  conftest.f >&5
>> f95: 1501-218 file conftest.f contains an incorrect file suffix
>
> It seems your 'f95' is not a conventional Fortran compiler.  But you have not 
> told us what compiler it is: only if we know the full story can we advise 
> against it.
>
>> but make exits early with errors.
>
> Without telling us what they are, the experts here cannot help.
>
>
> On Wed, 29 Nov 2006, Eric Harley wrote:
>
>> Roy and others,
>> 
>> I'm also trying to build R 2.4.0 on aix 5 (5.3 in my case, on an
>> Intellistation Power 285) and I have not had luck yet.  I notice that
>> the only mentions of AIX on this list in the past two months are
>> people not having luck building it.  So far there don't seem to be any
>> responses, and I don't know if it's from lack of information in the
>> questions, or because this isn't the right place to ask the questions.
>
> There have been replies, but no responses to those replies.  We often do not 
> find out if problems do get resolved.
>
>> Does anyone know a good place to ask such questions?  If this is the
>> right place, please let me know what information you need.
>> 
>> I am unfortunately very new to this business of compiling and linking
>> on Unix, so I have trouble knowing what information to provide.
>> 
>> Here's my stab at troubleshooting, which is basically trial-and-error:
>> 
>> ===
>> tried just to type ./configure (I can always dream, right?  :-) )
>> Failed with the following problem in config.log
>> 
>> configure:26491: checking how to get verbose linking output from f95
>> configure:26502: f95 -c  conftest.f >&5
>> f95: 1501-218 file conftest.f contains an incorrect file suffix
>> configure:26508: $? = 1
>> configure: failed program was:
>> |       program main
>> |
>> |       end
>> configure:26587: WARNING: compilation failed
>> configure:26593: result:
>> config.log (93%)
>> 
>> ===
>> A little playing around shows me that f95 doesn't like to compile
>> files ending in .f, so I try doing
>> ./configure F77=f77
>> 
>> In this case, the configure script completes successfully.
>> Now I try
>> make
>> 
>> but make exits early with errors.
>> make check
>> gives
>> 
>> make: 1254-002 Cannot find a rule to create target
>> ../../src/library/base/all.R from dependencies.
>> Stop.
>> 
>> and a few other 1254-004 errors.
>> 
>> ===
>> There are some examples in
>> http://cran.r-project.org/doc/manuals/R-admin.html , particularly in
>> the AIX platform notes (C.9 AIX).  However, the second paragraph says
>> "The rest of this section is historical, as the default *_LDFLAGS were
>> changed in R 2.4.0." so evidently the examples don't apply to the
>> current version of R.  I tried some frankenstein combinations of the
>> options given in the examples, using the xl*_* compilers since I don't
>> have gfortran on my system, but this kind of thing is time-consuming
>> when I'm essentially making random changes.
>> 
>> I'm hoping that someone with more experience than I can at least help
>> me sort through the "Cannot find a rule to create target" error, and
>> that maybe I can proceed somehow one error at a time and finally end
>> up with something that works.
>> 
>> BTW, I did try to google the "Cannot find a rule to create target"
>> "from dependencies", but I don't get much that I can understand.  One
>> message said something about this means make can't find the source
>> code.  If this is the problem, how can I figure out what source code
>> make is looking for, where it's looking for it, and how to tell it the
>> right place to look?  Or perhaps there's something else I'm missing?
>> 
>> Thanks,
>> Eric Harley
>> 
>> 
>> On 11/20/06, Roy Heimbach <royh at hpc.unm.edu> wrote:
>>> I'm trying to build R 2.4.0 on aix 5 and not having much luck.  If
>>> anyone on the list has built 2.3 or 2.4 on AIX and would be willing
>>> pass along some hints, I would be grateful.  So would the research
>>> group that's waiting to use R.
>>> 
>>> Thanks,
>>> Roy Heimbach
>>> --
>>> Roy Heimbach <royh at hpc.unm.edu> / 505-277-8348
>>> User Services / Center for High Performance Computing
>>> University of New Mexico
>>> 
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
>

-- 
Roy Heimbach <royh at hpc.unm.edu> / 505-277-8348
User Services / Center for High Performance Computing
University of New Mexico



From scorrea at soton.ac.uk  Mon Dec  4 19:50:26 2006
From: scorrea at soton.ac.uk (Correa S.T.)
Date: Mon, 4 Dec 2006 18:50:26 -0000
Subject: [R] FW: Initial values used by function lme
Message-ID: <A91F084EA64F33478ADFF6F2713B05D3050FF57E@ISS-CL-EX-V2.soton.ac.uk>

 

-----Original Message-----
From: Correa S.T. 
Sent: 04 December 2006 18:47
To: Trujillo L.
Subject: Initial values used by function lme

Hi R users,

I am trying to obtain the "good" initial values used by function lme
when fitting a two-level random effect model, since it seems there is an
internal function in lme that calculates those values apropriately.

Does anybody know how to get that information?

Many thanks,

Solange Correa.
PhD student
Southampton University.



From jfox at mcmaster.ca  Mon Dec  4 20:11:03 2006
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 04 Dec 2006 14:11:03 -0500
Subject: [R] Multilevel Modeling in R
In-Reply-To: <!&!AAAAAAAAAAAYAAAAAAAAAEuLs8ZPMuFInPbB+1JmPy7CgAAAEAAAANlAyaWrFjhPtnYyvF/kdW0BAAAAAA==@alphapoint05.net>
Message-ID: <web-152075238@cgpsrv2.cis.mcmaster.ca>

Dear Jeff,

On Mon, 4 Dec 2006 13:11:32 -0500
 "Jeff Miller" <jeffmiller at alphapoint05.net> wrote:
> Wow, would someone please send pdf links like that for SEM?
>

R's SEM capabilities aren't as strong as its mixed-model capabilities,
but here are some links:

<http://socserv.socsci.mcmaster.ca/jfox/Misc/sem/SEM-paper.pdf> 

<http://socserv.socsci.mcmaster.ca/jfox/Books/Companion/appendix-sems.pdf>

<http://socserv.socsci.mcmaster.ca/jfox/Courses/Oxford-2006/index.html>

I hope this helps,
 John

> Thanks,
> Jeff
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Chuck Cleland
> Sent: Monday, December 04, 2006 1:01 PM
> To: Matthew Bridgman
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Multilevel Modeling in R
> 
> Matthew Bridgman wrote:
> > Can anyone recommend a good text or resource for learning how to do
>  
> > Multilevel modeling in R?
> 
>   Here are a few other resources in addition to Pinheiro & Bates
> (2000):
> 
> http://finzi.psych.upenn.edu/R/library/mlmRev/doc/MlmSoftRev.pdf
> 
> http://cran.r-project.org/doc/packages/multilevel.pdf
> 
> http://stat.ethz.ch/CRAN/doc/Rnews/Rnews_2003-3.pdf [Lockwood, Doran
> &
> McCaffrey]
> 
>
http://cran.r-project.org/doc/contrib/Fox-Companion/appendix-mixed-models.pd
> f
> 
> > Thanks,
> >    Matt
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Chuck Cleland, Ph.D.
> NDRI, Inc.
> 71 West 23rd Street, 8th floor
> New York, NY 10010
> tel: (212) 845-4495 (Tu, Th)
> tel: (732) 512-0171 (M, W, F)
> fax: (917) 438-0894
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



From Anna_Belova at abtassoc.com  Mon Dec  4 20:27:20 2006
From: Anna_Belova at abtassoc.com (Anna Belova)
Date: Mon, 4 Dec 2006 14:27:20 -0500
Subject: [R] Calling R functions in Delphi
Message-ID: <OF3A5C81C3.5AEE7555-ON8525723A.0069E1BB-8525723A.006ADF77@abtassoc.com>


Hello All,

We would like to call quantile() function from the R-package STATS in a
Delphi program. If this is possible, could anyone provide us with an
example?

Thanks in advance.

--Anna
-----------------------------------------
Anna Belova
Abt Associates Inc.
4800 Montgomery Ln, St 600
Bethesda, MD-20814
phone: 301-347-5304
fax: 301-652-7530
http://www.abtassociates.com/environment

-----------------------------------------
This message may contain privileged and confidential informa...{{dropped}}



From aiminy at iastate.edu  Mon Dec  4 20:33:02 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Mon, 04 Dec 2006 13:33:02 -0600
Subject: [R] residuals problem for lmer
Message-ID: <6.1.2.0.2.20061204132857.01bbebb0@aiminy.mail.iastate.edu>

p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
attach(p5)
m.random<-lmer(formula = Y ~ Aa + As + Cur + Aa:As + Aa:Cur + 
As:Cur+(1|P),family = binomial(logit),method="REML",data = p5)
stdresid(m.random)

doesn't work , why?

Can I do use nlme

if so, How to write code for nlme?



From murdoch at stats.uwo.ca  Mon Dec  4 20:52:20 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 04 Dec 2006 14:52:20 -0500
Subject: [R] Calling R functions in Delphi
In-Reply-To: <OF3A5C81C3.5AEE7555-ON8525723A.0069E1BB-8525723A.006ADF77@abtassoc.com>
References: <OF3A5C81C3.5AEE7555-ON8525723A.0069E1BB-8525723A.006ADF77@abtassoc.com>
Message-ID: <45747C74.9040608@stats.uwo.ca>

On 12/4/2006 2:27 PM, Anna Belova wrote:
> Hello All,
> 
> We would like to call quantile() function from the R-package STATS in a
> Delphi program. If this is possible, could anyone provide us with an
> example?

You probably want to be talking to the Rcom-l list, see 
<http://mailman.csd.univie.ac.at/mailman/listinfo/rcom-l>.

Duncan Murdoch



From gerifalte28 at hotmail.com  Mon Dec  4 21:09:29 2006
From: gerifalte28 at hotmail.com (Francisco Zagmutt)
Date: Mon, 04 Dec 2006 13:09:29 -0700
Subject: [R] Calling R functions in Delphi
In-Reply-To: <OF3A5C81C3.5AEE7555-ON8525723A.0069E1BB-8525723A.006ADF77@abtassoc.com>
References: <OF3A5C81C3.5AEE7555-ON8525723A.0069E1BB-8525723A.006ADF77@abtassoc.com>
Message-ID: <45748079.70800@hotmail.com>

If your only interest is the quantile function, you may consider 
implementing your own version in Pascal.  Since R is open source you can 
look at the source code here: 
https://svn.r-project.org/R/trunk/src/library/stats/R/quantile.R

And use the code as a guideline (I recommend reading the GNU license 
before you use R for your own applications)

You can alway use the COM capabilities in R, available at 
http://sunsite.univie.ac.at/rcom/

Try RSiteSearch("Delphi") for a few interesting threads on the subject.

Regards,

Francisco

Dr. Francisco J. Zagmutt
College of Veterinary Medicine and Biomedical Sciences
Colorado State University


Anna Belova wrote:
> Hello All,
> 
> We would like to call quantile() function from the R-package STATS in a
> Delphi program. If this is possible, could anyone provide us with an
> example?
> 
> Thanks in advance.
> 
> --Anna
> -----------------------------------------
> Anna Belova
> Abt Associates Inc.
> 4800 Montgomery Ln, St 600
> Bethesda, MD-20814
> phone: 301-347-5304
> fax: 301-652-7530
> http://www.abtassociates.com/environment
> 
> -----------------------------------------
> This message may contain privileged and confidential informa...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From nbvale at gmail.com  Mon Dec  4 21:11:44 2006
From: nbvale at gmail.com (Nuno Vale)
Date: Mon, 4 Dec 2006 20:11:44 +0000
Subject: [R] Package AMORE
Message-ID: <84ef61090612041211g30ee0220md179dfa3d73397a9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061204/e805a721/attachment-0004.pl 

From falimadhi at iq.harvard.edu  Mon Dec  4 21:12:47 2006
From: falimadhi at iq.harvard.edu (Ferdinand Alimadhi)
Date: Mon, 04 Dec 2006 15:12:47 -0500
Subject: [R] unlock package environment ?
Message-ID: <4574813F.8040901@iq.harvard.edu>

Hello,

Somewhere in my S3 package "foo" I want to create, on the fly, a  new S4 
class which extends another S4 class "bar".

setClass("fooS4bar", representation("bar", bar.data = "data.frame"), 
where = parent.env(environment()))

where "where" is the environment of my "foo" package.


But I get:

Error in assign(classMetaName(Class), def, where) :
        cannot add bindings to a locked environment

Is there any way to unlock the package environment, add a binding and 
lock it back?  How the environment of my own package got locked on the 
first place?

Thanks for your help,

Ferdinand



From falimadhi at iq.harvard.edu  Mon Dec  4 21:31:15 2006
From: falimadhi at iq.harvard.edu (Ferdinand Alimadhi)
Date: Mon, 04 Dec 2006 15:31:15 -0500
Subject: [R] unlock package environment ?
Message-ID: <45748593.3090102@iq.harvard.edu>

Hello,

Inside my S3 packages "foo" Im trying to create an S4 class which 
extends another S4 class "bar".

setClass("fooS4bar", representation("bar", foo.data = "data.frame"), 
where = parent.env(environment()))

But I get:

Error in assign(classMetaName(Class), def, where) :
        cannot add bindings to a locked environment

 (Note: it works fine if  where = .GlobalEnv  but I want it to be 
created in my package environment !!)

Is there any way to unlock the environment add some bindings and then 
lock it back. How the environment of my own package got locked in the 
first place?

Thanks for your help
-Ferdi



From pocernic at rap.ucar.edu  Mon Dec  4 21:32:05 2006
From: pocernic at rap.ucar.edu (Matt Pocernich)
Date: Mon, 4 Dec 2006 13:32:05 -0700
Subject: [R] lattice plots - variables in columns
Message-ID: <20061204203205.GL27031@albedo>

I an using xyplot in lattice.  I have data in a dataframe.  Some columns
contains data, each from a different group.  Is there a direct way to 
specify a range of column names as a grouping variables?  Currently, I 
am stacking the data and creating a column with names.

Thanks,

Matt

-- 
Matt Pocernich
National Center for Atmospheric Research
Research Applications Laboratory
(303) 497-8312



From sundar.dorai-raj at pdf.com  Mon Dec  4 21:39:04 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 04 Dec 2006 12:39:04 -0800
Subject: [R] lattice plots - variables in columns
In-Reply-To: <20061204203205.GL27031@albedo>
References: <20061204203205.GL27031@albedo>
Message-ID: <45748768.7080001@pdf.com>


Matt Pocernich said the following on 12/4/2006 12:32 PM:
> I an using xyplot in lattice.  I have data in a dataframe.  Some columns
> contains data, each from a different group.  Is there a direct way to 
> specify a range of column names as a grouping variables?  Currently, I 
> am stacking the data and creating a column with names.
> 
> Thanks,
> 
> Matt
> 

Hi, Matt,

Yes. Try this:

my.data <- data.frame(x = 1:10, y1 = 1:10, y2 = 11:20)
xyplot(y1 + y2 ~ x, my.data)
## or if you want y1,y2 in panels
xyplot(y1 + y2 ~ x, my.data, outer = TRUE)

HTH,

--sundar



From friendly at yorku.ca  Mon Dec  4 21:40:54 2006
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 04 Dec 2006 15:40:54 -0500
Subject: [R] example() and example(package=) like data() and data(package=) ?
Message-ID: <457487D6.9090804@yorku.ca>

data() and data(package="foo") present screens
describing available data sets in all or specified packages,
and
dd <- data()
returns a structure where dd$results contains columns for
"Package" "LibPath" "Item" "Title", all of which make it easy
to 'do things' with package data.

Is there any reason why there should not be parallel uses,
example() and example(package="foo") not requiring a topic
to be specified?  That would be very handy, especially for
exploring a new package or developing tools for documenting
them, with output.

-Michael
-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From wasquith at austin.rr.com  Mon Dec  4 23:20:45 2006
From: wasquith at austin.rr.com (William Asquith)
Date: Mon, 4 Dec 2006 16:20:45 -0600
Subject: [R] Help for L-moment Ratio Diagram
In-Reply-To: <e603d4040612041005w41722a3by5f23faf242732987@mail.gmail.com>
References: <3ffd3bb60612040842w93c7e64v6a2b312ee0115f97@mail.gmail.com>
	<e603d4040612041005w41722a3by5f23faf242732987@mail.gmail.com>
Message-ID: <0AB7F469-5DBB-42CC-949D-F85CE655E7E2@austin.rr.com>

Amina,
If you can follow this code, you will see that the black dots scatter  
around an L-skew of zero and L-kurtosis of 0.122602, which are the  
theoretical L-moments of the standard normal distribution.

library(lmomco)
lmrdia <- lmrdia()
plotlmrdia(lmrdia,ylim=c(-.2,.2),xlim=c(-.2,.2))
lms <- lmoms(rnorm(500))
points(lms$ratios[3],lms$ratios[4],pch=16)
lms <- lmoms(rnorm(500))
points(lms$ratios[3],lms$ratios[4],pch=16)
lms <- lmoms(rnorm(500))
points(lms$ratios[3],lms$ratios[4],pch=16)
lms <- lmoms(rnorm(500))
points(lms$ratios[3],lms$ratios[4],pch=16)

Further interpretion of the diagram is well documented in Hosking's  
1990  paper and the references shown on the help page.

William

On Dec 4, 2006, at 12:05 PM, Eric Thompson wrote:

> I think there are a few packages for doing this. I have used "lmomco":
> the function lmom.ub() will calculate the sample lmoments, and
> lmrdia() gives theoretical lmoments for different distributions.
>
> Hope this is helpful.
>
> Eric
>
>
> On 12/4/06, amna khan <amnakhan493 at gmail.com> wrote:
>> Respected Sir
>>
>> I have to select a probability distribution using L-moment Ratio  
>> Diagram. I
>> am not understanding how to plot sample TAU3 and TUA4 on L-moment  
>> Ratio
>> Diagram.
>> Please Guide me
>> Best Regards
>>
>> --
>> AMINA SHAHZADI
>> Department of Statistics
>> GC University Lahore, Pakistan.
>> Email:
>> amnakhan493 at gmail.com
>> amna_989 at hotmail.com
>> amna_989 at yahoo.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From mackay at northnet.com.au  Mon Dec  4 23:54:02 2006
From: mackay at northnet.com.au (Duncan Mackay)
Date: Tue, 05 Dec 2006 08:54:02 +1000
Subject: [R] background color in strip.custom()
In-Reply-To: <1165226486.3280.6.camel@localhost.localdomain>
References: <1165226486.3280.6.camel@localhost.localdomain>
Message-ID: <6.0.1.1.1.20061205084417.027f8dd0@mail.northnet.com.au>

One way is to use the argument par.settings

get the right name

names(trellis.par.get())

or

str(trellis.par.get())

to find the list names to change

then

xyplot(y ~ x | f,
           par.settings = list(strip.background = list(col = c(your colours)) )


Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
ARMIDALE NSW 2351
Email: dmackay9 at pobox.une.edu.au
   home: mackay at northnet.com.au
Phone: 02 6772 9794

At 20:01 04/12/06, you wrote:
>Hi all,
>how can I change the background color in lattice strips according to a
>factor level, eg:
>
>library(lattice)
>x <- rnorm(100)
>y <- sqrt(x)
>f <- gl(2, 50, c("A", "B"))
>xyplot(y ~ x | f)
>
>I like to change the background color of the strips according to the
>levels in f and tried several things like this with no success:
>
>xyplot(y ~ x | f, strip=strip.custom(bg=c("red", "green")))
>
>Is this possible?
>
>Thanks, Sven
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From natalie.zayats at gmail.com  Tue Dec  5 00:16:55 2006
From: natalie.zayats at gmail.com (Natalie Zayats)
Date: Tue, 5 Dec 2006 01:16:55 +0200
Subject: [R] Nested for loop
Message-ID: <4d359a50612041516j501cf3an671ce9fd7b30121f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061205/c9c01155/attachment-0004.pl 

From blomsp at ozemail.com.au  Tue Dec  5 00:26:20 2006
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Tue, 05 Dec 2006 10:26:20 +1100
Subject: [R] Nested for loop
In-Reply-To: <4d359a50612041516j501cf3an671ce9fd7b30121f@mail.gmail.com>
References: <4d359a50612041516j501cf3an671ce9fd7b30121f@mail.gmail.com>
Message-ID: <4574AE9C.6090005@ozemail.com.au>

Please supply some code that reproduces the problem!

cheers,

Simon.

Natalie Zayats wrote:
> Hi all,
>
> Does anybody know whether one can nest IF statement in multiple FOR loops ?
> According to results of my code, only the first iteration of each loop is
> performed...
>
> Thanks,
>
> Regards,
>
> Natalie
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>   


-- 
Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat. 
Centre for Resource and Environmental Studies
The Australian National University              
Canberra ACT 0200                               
Australia                                       
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer 
can be extracted from a given body of data.
- John Tukey.



From p.dalgaard at biostat.ku.dk  Tue Dec  5 00:27:59 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 05 Dec 2006 00:27:59 +0100
Subject: [R] Nested for loop
In-Reply-To: <4d359a50612041516j501cf3an671ce9fd7b30121f@mail.gmail.com>
References: <4d359a50612041516j501cf3an671ce9fd7b30121f@mail.gmail.com>
Message-ID: <4574AEFF.5060803@biostat.ku.dk>

Natalie Zayats wrote:
> Hi all,
>
> Does anybody know whether one can nest IF statement in multiple FOR loops ?
> According to results of my code, only the first iteration of each loop is
> performed...
>
>   
Well, yes, that should be possible. Proving your claim with actual 
sample code would give the readers a better chance to diagnose what went 
wrong!



From deepayan.sarkar at gmail.com  Tue Dec  5 00:40:43 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Mon, 4 Dec 2006 15:40:43 -0800
Subject: [R] background color in strip.custom()
In-Reply-To: <1165226486.3280.6.camel@localhost.localdomain>
References: <1165226486.3280.6.camel@localhost.localdomain>
Message-ID: <eb555e660612041540h57932335u797ae5cb6d613081@mail.gmail.com>

On 12/4/06, Sven Garbade <Sven.Garbade at med.uni-heidelberg.de> wrote:
> Hi all,
> how can I change the background color in lattice strips according to a
> factor level, eg:
>
> library(lattice)
> x <- rnorm(100)
> y <- sqrt(x)
> f <- gl(2, 50, c("A", "B"))
> xyplot(y ~ x | f)
>
> I like to change the background color of the strips according to the
> levels in f and tried several things like this with no success:
>
> xyplot(y ~ x | f, strip=strip.custom(bg=c("red", "green")))
>
> Is this possible?

Yes, you just have to write a custom strip function (slightly beyond
what strip.custom is capable of):

xyplot(y ~ x | f,
       strip = function(..., which.panel, bg) {
           bg.col = trellis.par.get("strip.background")$col;
           ## or bg.col = c("red", "green") if you prefer
           strip.default(..., which.panel = which.panel,
                        bg = rep(bg.col, length = which.panel)[which.panel])
       })

This will only work when you have one conditioning variable (otherwise
'which.panel' won't be a scalar), but you haven't told us what you
want to happen otherwise.

-Deepayan



From deepayan.sarkar at gmail.com  Tue Dec  5 00:42:27 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Mon, 4 Dec 2006 15:42:27 -0800
Subject: [R] background color in strip.custom()
In-Reply-To: <6.0.1.1.1.20061205084417.027f8dd0@mail.northnet.com.au>
References: <1165226486.3280.6.camel@localhost.localdomain>
	<6.0.1.1.1.20061205084417.027f8dd0@mail.northnet.com.au>
Message-ID: <eb555e660612041542w7b6ef343nfd0eeed533d05b5c@mail.gmail.com>

On 12/4/06, Duncan Mackay <mackay at northnet.com.au> wrote:
> One way is to use the argument par.settings
>
> get the right name
>
> names(trellis.par.get())
>
> or
>
> str(trellis.par.get())
>
> to find the list names to change
>
> then
>
> xyplot(y ~ x | f,
>            par.settings = list(strip.background = list(col = c(your colours)) )

That's answering a slightly different question, I think.

-Deepayan

>
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> ARMIDALE NSW 2351
> Email: dmackay9 at pobox.une.edu.au
>    home: mackay at northnet.com.au
> Phone: 02 6772 9794
>
> At 20:01 04/12/06, you wrote:
> >Hi all,
> >how can I change the background color in lattice strips according to a
> >factor level, eg:
> >
> >library(lattice)
> >x <- rnorm(100)
> >y <- sqrt(x)
> >f <- gl(2, 50, c("A", "B"))
> >xyplot(y ~ x | f)
> >
> >I like to change the background color of the strips according to the
> >levels in f and tried several things like this with no success:
> >
> >xyplot(y ~ x | f, strip=strip.custom(bg=c("red", "green")))
> >
> >Is this possible?
> >
> >Thanks, Sven



From pensterfuzzer at yahoo.de  Tue Dec  5 01:30:50 2006
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Tue, 5 Dec 2006 01:30:50 +0100 (CET)
Subject: [R] summaryBy(): Is it the best option?
Message-ID: <682431.28939.qm@web23007.mail.ird.yahoo.com>

Hi,

since I have quite large tables and the processing
takes quite a while I am
curious if I can improve the performance of this
aggregation somehow: At the 
moment I am using summaryBy from the doBy package
under R 2.4.0, Win2K.

summaryBy(soc_s6aq5 + soc_s6aq7 + soc_s6aq9 +
soc_s6aq11 ~ hh + 
comgroup,soc6a,postfix=c("","","",""),FUN=sum,
na.rm=T)

The data.frame has 124100 rows and 13 cols.

Thanks for any hints!

Werner



From sapsi at pobox.com  Tue Dec  5 03:20:09 2006
From: sapsi at pobox.com (Saptarshi Guha)
Date: Mon, 4 Dec 2006 21:20:09 -0500
Subject: [R] A question on grid - grid.points not spaced properly
Message-ID: <B5D33109-7452-4115-B779-6A74ED3374BD@pobox.com>

Hello,
	How can i 'fix' the following output.

	v=viewport(x=216/2, y=216/2,w=216, h=216,default.units = "bigpts")
	pushViewport(v)
	x=c(119,130,140,151)
	y=c(124,124,124,124)
	grid.points(x,y,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
	grid.points(x-2,y,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
	grid.points(x+2,y,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
	grid.points(x,y-2,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
	grid.points(x,y+2,size=unit(1,"bigpts"),default.units="bigpts",pch=".")


	One would expect to get a 4 figures composed of 5 dots each  - 2  
vertically spaced and 2 horizontally spaced symmetrically around the  
center dot.
	However i seem to get odd results - e.g on Quartz(OS X) output, the  
last command, places the dot bang next to the center dot.
	On 'jpeg' output with higest quality, this oddity happens with the 'x 
+2' command.

	This doesn't happen to all of the points, only some - and not necc.  
the edge figures.

	Is there anyway i can control this?
	Thanks
	Saptarshi

Saptarshi Guha | sapsi at pobox.com | http://www.stat.purdue.edu/~sguha



From ethan.johnsons at gmail.com  Tue Dec  5 03:35:24 2006
From: ethan.johnsons at gmail.com (Ethan Johnsons)
Date: Mon, 4 Dec 2006 21:35:24 -0500
Subject: [R] Chi-Square Goodness-of-Fit test
Message-ID: <5cd96f050612041835w58408121id58bac82b03e34b6@mail.gmail.com>

Do you know/have a function that takes a vector x and provides a
returned p-value that uses the Chi-Square Goodness-of-Fit test to test
the goodness of fit of a standard normal distribution.

Awaiting your positive reply.

Thx

ej



From blomsp at ozemail.com.au  Tue Dec  5 04:02:50 2006
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Tue, 05 Dec 2006 14:02:50 +1100
Subject: [R] Chi-Square Goodness-of-Fit test
In-Reply-To: <5cd96f050612041835w58408121id58bac82b03e34b6@mail.gmail.com>
References: <5cd96f050612041835w58408121id58bac82b03e34b6@mail.gmail.com>
Message-ID: <4574E15A.7050607@ozemail.com.au>

See pearson.test in the nortest package. Also, read the notes section in 
?pearson.test. You may not really want to do this test.

HTH,

Simon.

Ethan Johnsons wrote:
> Do you know/have a function that takes a vector x and provides a
> returned p-value that uses the Chi-Square Goodness-of-Fit test to test
> the goodness of fit of a standard normal distribution.
>
> Awaiting your positive reply.
>
> Thx
>
> ej
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>   


-- 
Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat. 
Centre for Resource and Environmental Studies
The Australian National University              
Canberra ACT 0200                               
Australia                                       
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer 
can be extracted from a given body of data.
- John Tukey.



From acostaguill at gmail.com  Tue Dec  5 05:49:18 2006
From: acostaguill at gmail.com (Guillermo Acosta)
Date: Mon, 4 Dec 2006 21:49:18 -0700
Subject: [R] error: too many open devices
Message-ID: <d737f9590612042049p1eda7545k5b7da9381fefdc8f@mail.gmail.com>

Hello all--

I've been using 1.13 (v1915) on my Mac pretty intensly for about a
month, but today when I tried to generate a plot I recieved this
message:

Error in quartz(width=9)   :  too many open devices

I was caught by surprise, because I only had the R console open at the
time. I checked to be sure, by clicking "Window" at the top bar, and R
console was the only window open. I thought I had a problem in the
workspace, so I switched to a different one that worked earlier today,
but the error was there too. I tried clearing the workspace entirely,
and creating a single vector and plotting that, but again I got this
error about "too many open devices". I even quit R, closed everything
I had, and restarted... but this error is still there.

Has anybody seen this before? I'm sure it's a pretty simple fix,
except I've run out of the places that I can think to look.

Many thanks in advance,
Sincerely,
Guillermo Acosta
Graduate Student
Department of Physics and Astronomy
Brigham Young University



From ethan.johnsons at gmail.com  Tue Dec  5 06:24:44 2006
From: ethan.johnsons at gmail.com (Ethan Johnsons)
Date: Tue, 5 Dec 2006 00:24:44 -0500
Subject: [R] Chi-Square Goodness-of-Fit test
In-Reply-To: <91BD8318-8A1F-4D1B-99D4-BB324D9D53C5@u.washington.edu>
References: <5cd96f050612041835w58408121id58bac82b03e34b6@mail.gmail.com>
	<4574E15A.7050607@ozemail.com.au>
	<91BD8318-8A1F-4D1B-99D4-BB324D9D53C5@u.washington.edu>
Message-ID: <5cd96f050612042124t58ab54ecje6f00184a92ebe3a@mail.gmail.com>

If we use this data as an example, does ks.test still valid?

E.Coli Group	Observed	Expected
A	57	77.9
B	330	547.1
C	2132	2126.7
D	4584	4283.3
E	4604	4478.5
F	2119	2431.1
G	659	684.1
H	251	107.2

thx

ej

On 12/4/06, Don McKenzie <dmck at u.washington.edu> wrote:
>
> in R v 2.4
>
> > x <- rnorm(50)
> > y <- rnorm(50)
> > ks.test(x,y,"rnorm")
>
>  Two-sample Kolmogorov-Smirnov test
>
> data:  x and y
> D = 0.08, p-value = 0.9977
> alternative hypothesis: two.sided
>
> **********
>
> > x <- rnorm(50)
> > y <- runif(50)
> > ks.test(x,y,"rnorm")
>
>  Two-sample Kolmogorov-Smirnov test
>
> data:  x and y
> D = 0.46, p-value = 3.801e-05
> alternative hypothesis: two.sided
> ******************
>
>
>
> On Dec 4, 2006, at 7:02 PM, Simon Blomberg wrote:
>
> See pearson.test in the nortest package. Also, read the notes section in
> ?pearson.test. You may not really want to do this test.
>
> HTH,
>
> Simon.
>
> Ethan Johnsons wrote:
> Do you know/have a function that takes a vector x and provides a
> returned p-value that uses the Chi-Square Goodness-of-Fit test to test
> the goodness of fit of a standard normal distribution.
>
> Awaiting your positive reply.
>
> Thx
>
> ej
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
> --
> Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
> Centre for Resource and Environmental Studies
> The Australian National University
> Canberra ACT 0200
> Australia
> T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
> F: +61 2 6125 0757
> CRICOS Provider # 00120C
>
> The combination of some data and an aching desire for
> an answer does not ensure that a reasonable answer
> can be extracted from a given body of data.
> - John Tukey.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> Don McKenzie, Research Ecologist
> Pacific WIldland Fire Sciences Lab
> US Forest Service
>
> Affiliate Assistant Professor
> College of Forest Resources
> CSES Climate Impacts Group
> University of Washington
>
> 206.732.7824
> dmck at u.washington.edu
> donaldmckenzie at fs.fed.us
>
>
>
>



From spencer.graves at pdf.com  Tue Dec  5 07:48:51 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 04 Dec 2006 22:48:51 -0800
Subject: [R] Help with response CIs for lme
In-Reply-To: <DBB3E82B-75EE-447C-8BC0-6425D8B5E8FD@virginia.edu>
References: <DBB3E82B-75EE-447C-8BC0-6425D8B5E8FD@virginia.edu>
Message-ID: <45751653.5020107@pdf.com>

      No, your example computation does NOT produce the desired "lme 
prediction intervals".  I ran your script and got exactly the same 
numbers for upper and lower limits.  Even without any consideration of 
statistical theory, this suggests either shockingly precise statistical 
estimation or a problem with your algorithm. 

      The theory behind such intervals is sufficiently complicated that 
the 'nlme' developers have not found a need sufficient to justify the 
effort required to develop the required capability.  A reply by James 
Rogers to a similar question a couple of years ago concluded, "It is not 
easy to write such a function for the general case, but it may be 
relatively easy to write your own for special cases of lme models." 
(http://finzi.psych.upenn.edu/R/Rhelp02a/archive/42781.html)

      To briefly outline some of the difficulties, we first should ask 
if you want confidence intervals for the MEAN of future values or for 
the future values themselves?  And how do you want to handle the random 
effects?  If you want the mean of the fixed effects, averaging over 
random effects, that should be fairly easy.  Consider, for example, the 
following modification of the example on the 'lme' help page: 

fm1 <- lme(distance ~ age, data = Orthodont) # random is ~ age
summary(fm1)
<snip>

Fixed effects: distance ~ age
                Value Std.Error DF   t-value p-value
(Intercept) 16.761111 0.7752461 80 21.620375       0
age          0.660185 0.0712533 80  9.265334       0
 Correlation:
    (Intr)
age -0.848

      From the "Std.Error" and "Correlation", we could reconstruct the 
covariance matrix of the parameter estimates, b.hat.  Call this S.b.  
Then the estimate for Ey for some new set of covariates coded in a row 
vector x' is var(Ey.hat) = x' S.b x.  The square root of this number is 
a standard deviation, and you could add and subtract some multiple like 
2 of this number from x' b.hat to get the desired confidence interval. 

      If I wanted to do that myself, I might read the code for 
"summary.lme", after using getAnywhere("summary.lme") to get it. 

      I know this doesn't solve your problem, but I hope it helps.      
      Spencer Graves

Michael Kubovy wrote:
> Hi,
>
> Can someone please offer a procedure for going from CIs produced by  
> intervals.lme() to fixed-effects response CIs.
>
> Here's a simple example:
>
> library(mlmRev)
> library(nlme)
> hsb.lme <- lme(mAch ~ minrty * sector, random = ~ 1 | cses, Hsb82)
> (intervals(hsb.lme))
> (hsb.new <- data.frame
>      minrty = rep(c('No', 'Yes'), 2),
>      sector = rep(c('Public', 'Catholic'), each = 2)))
> cbind(hsb.new, predict(hsb.lme, hsb.new, level = 0))
>
> Is the following correct (I know from the previous command that the  
> estimate is correct)?
> cbind(hsb.new, rbind(hsb.int[[1]][1,], hsb.int[[1]][1,]+hsb.int[[1]] 
> [2,], hsb.int[[1]][1,]+hsb.int[[1]][3,], hsb.int[[1]][1,]+hsb.int[[1]] 
> [2,] + hsb.int[[1]][3,] + hsb.int[[1]][4,]))
>
> If so, is there an easier way to write it?
> _____________________________
> Professor Michael Kubovy
> University of Virginia
> Department of Psychology
> USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
> Parcels:    Room 102        Gilmer Hall
>          McCormick Road    Charlottesville, VA 22903
> Office:    B011    +1-434-982-4729
> Lab:        B019    +1-434-982-4751
> Fax:        +1-434-982-4766
> WWW:    http://www.people.virginia.edu/~mk9y/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From RKrug at sun.ac.za  Tue Dec  5 08:23:11 2006
From: RKrug at sun.ac.za (Rainer M Krug)
Date: Tue, 05 Dec 2006 09:23:11 +0200
Subject: [R] Calling R functions in Delphi
In-Reply-To: <OF3A5C81C3.5AEE7555-ON8525723A.0069E1BB-8525723A.006ADF77@abtassoc.com>
References: <OF3A5C81C3.5AEE7555-ON8525723A.0069E1BB-8525723A.006ADF77@abtassoc.com>
Message-ID: <45751E5F.3090105@sun.ac.za>

Anna Belova wrote:
> Hello All,
> 
> We would like to call quantile() function from the R-package STATS in a
> Delphi program. If this is possible, could anyone provide us with an
> example?

Hi Anna

There was a translation of the header files from C to Delphi, so that 
you could used R directly without using DCom - Hans-Peter Suter 
translated / made them.

I'll mail you the version which he send me off list.

Rainer

> 
> Thanks in advance.
> 
> --Anna
> -----------------------------------------
> Anna Belova
> Abt Associates Inc.
> 4800 Montgomery Ln, St 600
> Bethesda, MD-20814
> phone: 301-347-5304
> fax: 301-652-7530
> http://www.abtassociates.com/environment
> 
> -----------------------------------------
> This message may contain privileged and confidential informa...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology and Entomology
University of Stellenbosch
Matieland 7602
South Africa

Tel:		+27 - (0)72 808 2975 (w)
Fax:		+27 - (0)86 516 2782
Fax:		+27 - (0)21 808 3304 (w)
Cell:		+27 - (0)83 9479 042

email:	RKrug at sun.ac.za
       	Rainer at krugs.de



From maechler at stat.math.ethz.ch  Tue Dec  5 10:04:42 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 5 Dec 2006 10:04:42 +0100
Subject: [R] memory problem [cluster]
In-Reply-To: <Pine.LNX.4.44.0612022200140.14338-100000@reclus.nhh.no>
References: <200612021007.47511.dylan.beaudette@gmail.com>
	<Pine.LNX.4.44.0612022200140.14338-100000@reclus.nhh.no>
Message-ID: <17781.13866.345784.757321@stat.math.ethz.ch>

>>>>> "Roger" == Roger Bivand <Roger.Bivand at nhh.no>
>>>>>     on Sat, 2 Dec 2006 22:11:12 +0100 (CET) writes:

    Roger> On Sat, 2 Dec 2006, Dylan Beaudette wrote:
    >> Hi Stephano,

    Roger> Looks like you used my example verbatim 
    Roger> (http://casoilresource.lawr.ucdavis.edu/drupal/node/221)

    Roger> :)

    >> From exchanges on R-sig-geo, I believe the original questioner is feeding
    Roger> NAs to clara, and the error message in clara() is overrunning the buffer
    Roger> in sprintf(), so the memory problem isn't correctly identified. Using
    Roger> scripts out of context without checking whether the input data frame 
    Roger> satifies the conditions of the functions being used is asking for trouble. 
    Roger> The error message:

    >> traceback()
    Roger> 2: stop(ngettext(length(i), sprintf("Observation %d has", i[1]),
    Roger> sprintf("Observations %s have", paste(i, collapse = ","))),
    Roger> " *only* NAs --> omit for clustering")
    Roger> 1: clara(morph, k = 5, stand = F)

    Roger> is coming from lines:

    Roger> i[1]), sprintf("Observations %s have", paste(i, 
    Roger> collapse = ","))), " *only* NAs --> omit for clustering")

    Roger> in clara(). I have suggested dropping those rows from the data frame in a 
    Roger> reply on R-sig-geo, but maybe clara() could be patched to count the # of 
    Roger> completely missing rows, and if # is more than a modest number, not print 
    Roger> the obs. numbers, just the total?

Yes, thanks Roger, for the hint; I have now done that
(will be in cluster_1.11.4):

  > data(xclara)
  > xclara[sample(nrow(xclara), 50),] <- NA
  > clara(xclara, k = 3)
  Error in clara(xclara, k = 3) : 50 observations (6,95,106,191,258,294,295,321,432,601,662,702 ...)
	  have *only* NAs --> na.omit() them for clustering!


Lessons to be learned (I have learned it earlier; but not
scrutinized all my code to see if it's obeyed :-):  

- Inside stop(..) be careful not produce another error;
  particularly not a memory-related one, since this will give
  user-error messages that are not at all helpful.

- All non-beginner R users should be trained to routinely say
  'traceback()' after they've seen an error.

Regards,
Martin Maechler, ETH Zurich



From jsandblom at gmail.com  Tue Dec  5 10:12:48 2006
From: jsandblom at gmail.com (Johan Sandblom)
Date: Tue, 5 Dec 2006 10:12:48 +0100
Subject: [R] Horizontal stripplot
Message-ID: <97a06f070612050112y305666aclbf7c7f3795a92f24@mail.gmail.com>

I have a plot similar to the following

library(lattice)
stripplot(1:15, rep(1:3, each=5))

In order to save space for a presentation, I would like to have
horizontal strips instead of vertical. The argument 'horiz' turns the
arguments around, but not the plot. The documentation for 'stripplot'
('xyplot'), 'panel.stripplot' and the FAQ do not seem to provide
insight. Any help appreciated.

Regards, Johan

I am using R-2.4.0 on Debian Linux (details below)

version

> version
               _
platform       i486-pc-linux-gnu
arch           i486
os             linux-gnu
system         i486, linux-gnu
status         Patched
major          2
minor          4.0
year           2006
month          11
day            03
svn rev        39777
language       R
version.string R version 2.4.0 Patched (2006-11-03 r39777)
> sessionInfo()
R version 2.4.0 Patched (2006-11-03 r39777)
i486-pc-linux-gnu

locale:
LC_CTYPE=sv_SE.ISO-8859-15;LC_NUMERIC=C;LC_TIME=sv_SE.ISO-8859-15;LC_COLLATE=sv_SE.ISO-8859-15;LC_MONETARY=sv_SE.ISO-8859-15;LC_MESSAGES=sv_SE.ISO-8859-15;LC_PAPER=sv_SE.ISO-8859-15;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=sv_SE.ISO-8859-15;LC_IDENTIFICATION=C

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"

other attached packages:
  lattice
"0.14-13"

-- 
Johan Sandblom  N8, MRC, Karolinska sjh
t +46851776108  17176 Stockholm
m +46735521477  Sweden
"What is wanted is not the will to believe, but the
will to find out, which is the exact opposite"
- Bertrand Russell



From Thierry.ONKELINX at inbo.be  Tue Dec  5 10:44:16 2006
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 5 Dec 2006 10:44:16 +0100
Subject: [R] error: too many open devices
In-Reply-To: <d737f9590612042049p1eda7545k5b7da9381fefdc8f@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A1040258FF77@inboexch.inbo.be>

dev.list() will give a list with all open devices. dev.off() will close
the current device.

Cheers,

Thierry


------------------------------------------------------------------------
----

ir. Thierry Onkelinx

Instituut voor natuur- en bosonderzoek / Reseach Institute for Nature
and Forest

Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance

Gaverstraat 4

9500 Geraardsbergen

Belgium

tel. + 32 54/436 185

Thierry.Onkelinx at inbo.be

www.inbo.be 

 

Do not put your faith in what statistics say until you have carefully
considered what they do not say.  ~William W. Watt

A statistical analysis, properly conducted, is a delicate dissection of
uncertainties, a surgery of suppositions. ~M.J.Moroney

-----Oorspronkelijk bericht-----
Van: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] Namens Guillermo Acosta
Verzonden: dinsdag 5 december 2006 5:49
Aan: r-help at stat.math.ethz.ch
Onderwerp: [R] error: too many open devices

Hello all--

I've been using 1.13 (v1915) on my Mac pretty intensly for about a
month, but today when I tried to generate a plot I recieved this
message:

Error in quartz(width=9)   :  too many open devices

I was caught by surprise, because I only had the R console open at the
time. I checked to be sure, by clicking "Window" at the top bar, and R
console was the only window open. I thought I had a problem in the
workspace, so I switched to a different one that worked earlier today,
but the error was there too. I tried clearing the workspace entirely,
and creating a single vector and plotting that, but again I got this
error about "too many open devices". I even quit R, closed everything
I had, and restarted... but this error is still there.

Has anybody seen this before? I'm sure it's a pretty simple fix,
except I've run out of the places that I can think to look.

Many thanks in advance,
Sincerely,
Guillermo Acosta
Graduate Student
Department of Physics and Astronomy
Brigham Young University

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From deepayan.sarkar at gmail.com  Tue Dec  5 10:56:18 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 5 Dec 2006 01:56:18 -0800
Subject: [R] Horizontal stripplot
In-Reply-To: <97a06f070612050112y305666aclbf7c7f3795a92f24@mail.gmail.com>
References: <97a06f070612050112y305666aclbf7c7f3795a92f24@mail.gmail.com>
Message-ID: <eb555e660612050156t32c0632bna5c08f7622764d36@mail.gmail.com>

On 12/5/06, Johan Sandblom <jsandblom at gmail.com> wrote:
> I have a plot similar to the following
>
> library(lattice)
> stripplot(1:15, rep(1:3, each=5))

That doesn't look like a meaningful call. Did you mean something like

stripplot(1:15 ~ rep(1:3, each=5))

?

In any case, the 'horiz(ontal)' argument is meant for unusual
situations, you shouldn't need to use it. One of the variables in a
strip plot is supposed to be a categorical variable, and categorical
variables are represented by factors in R. Instead of using numeric
variables as in your example, use factors, and you should be fine. For
example, this gives me horizontal strip plots:

stripplot(factor(rep(1:3, each=5)) ~ 1:15)

and this vertical:

stripplot(1:15 ~ factor(rep(1:3, each=5)))

> In order to save space for a presentation, I would like to have
> horizontal strips instead of vertical. The argument 'horiz' turns the
> arguments around, but not the plot. The documentation for 'stripplot'
> ('xyplot'), 'panel.stripplot' and the FAQ do not seem to provide
> insight. Any help appreciated.

The documentation for 'stripplot' says:

          ... In the other four functions documented here,
          exactly one of 'x' and 'y' should be numeric, and the other a
          factor or shingle. Which of these will happen is determined
          by the 'horizontal' argument - if 'horizontal=TRUE', then 'y'
          will be coerced to be a factor or shingle, otherwise 'x'. The
          default value of 'horizontal' is 'FALSE' if 'x' is a factor
          or shingle, 'TRUE' otherwise.

which part is unclear?

-Deepayan



From gchappi at gmail.com  Tue Dec  5 11:39:34 2006
From: gchappi at gmail.com (Hans-Peter)
Date: Tue, 5 Dec 2006 11:39:34 +0100
Subject: [R] Calling R functions in Delphi
In-Reply-To: <45751E5F.3090105@sun.ac.za>
References: <OF3A5C81C3.5AEE7555-ON8525723A.0069E1BB-8525723A.006ADF77@abtassoc.com>
	<45751E5F.3090105@sun.ac.za>
Message-ID: <47fce0650612050239h5fe24046ne07a13e7acf04bef@mail.gmail.com>

2006/12/5, Rainer M Krug <RKrug at sun.ac.za>:
> There was a translation of the header files from C to Delphi, so that
> you could used R directly without using DCom - Hans-Peter Suter
> translated / made them.

Thanks for mentioning. You can download these files any time from:
  - http://treetron.googlepages.com/  (select delphi interface units)

BUT notice, that they will only enable you to write *packages* which
contain Delphi code and not to link/embed R directly from Delphi. IMO
you should use RCom as mentioned above.

-- 
Regards,
Hans-Peter



From a.ebrahimi at ieee.org  Tue Dec  5 12:48:28 2006
From: a.ebrahimi at ieee.org (A.R. Ebrahimi)
Date: Tue, 05 Dec 2006 15:18:28 +0330
Subject: [R] problem with lists...
Message-ID: <45755C8C.7060602@ieee.org>

Hi guys,
I am new to R, so sorry if my problem seems trivial.

Sometimes I encounter some lists, which I cannot index their components 
with [ . ]
For instance the prcomp() function returns a 'prcomp' object whose 
components are some 'lists'. the second component is a list that 
comtains the following:

 > mylist <- churn[2]

 > class(mylist)
[1] "list"

 > mylist

                            PC1                    PC2                
PC3                    PC4                    PC5                    PC6
Account_Length    -8.930570e-03    2.383719e-03    -2.414908e-02    
-1.004704e-01    9.941468e-01    2.867606e-02
Area_Code            1.543767e-02    -1.710566e-02    -6.258129e-03    
9.945271e-01    1.008478e-01    -8.890155e-03
Intl_Plan                -2.627796e-04    -1.809011e-04    
-9.542965e-05    3.230055e-04    2.148520e-04    -1.622996e-05
VMail_Plan            4.879640e-06    -1.339026e-04    1.639344e-04    
-1.367628e-05    2.897648e-05    5.548126e-04
VMail_Message    -4.174810e-04    -2.969518e-03    4.791422e-03    
-5.643246e-04    -1.752559e-03    1.433728e-02
Day_Mins            -9.845791e-01    2.049519e-02    -4.038624e-02    
1.619195e-02    -8.308484e-03    4.217712e-04
Day_Calls            -2.810874e-03    1.428161e-02    2.837638e-03    
-7.647877e-03    2.532260e-02    -9.431350e-01
Day_Charge        -1.673781e-01    3.483165e-03    -6.864827e-03    
2.752626e-03    -1.412836e-03    7.042886e-05
Eve_Mins            -4.029002e-02    -8.265860e-01    5.544912e-01    
-1.166711e-02    1.426697e-02    -1.087738e-02

It look more like a matrix!
but I cannot access individual items in this list.

 > mylist[1]
'returns the whole think'

 > mylist[1,1]
Error in mylist[1, 1] : incorrect number of dimensions

 > mylist[2]
$<NA>
NULL


Would you please help me on this
Regards



From m_osm at gmx.net  Tue Dec  5 13:06:26 2006
From: m_osm at gmx.net (Mahdi Osman)
Date: Tue, 05 Dec 2006 13:06:26 +0100
Subject: [R] cluster package
Message-ID: <20061205120626.315000@gmx.net>

Hi list,

I am doing cluster analysis using the cluster package. I created a dendrogram using the function plot(agnes(myData)). When I try to change the sise of labels, it does not work. I tried cex = 1.5, etc. Nothing worked. Can anyone give me a hint on how to change the sise of the labels, as well as the sise of axes labels.

Thanks

Mahdi
-- 
-----------------------------------
Mahdi Osman (PhD)
E-mail: m_osm at gmx.net



From ccleland at optonline.net  Tue Dec  5 13:16:45 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Tue, 05 Dec 2006 07:16:45 -0500
Subject: [R] problem with lists...
In-Reply-To: <45755C8C.7060602@ieee.org>
References: <45755C8C.7060602@ieee.org>
Message-ID: <4575632D.6010403@optonline.net>

A.R. Ebrahimi wrote:
> Hi guys,
> I am new to R, so sorry if my problem seems trivial.
> 
> Sometimes I encounter some lists, which I cannot index their components 
> with [ . ]
> For instance the prcomp() function returns a 'prcomp' object whose 
> components are some 'lists'. the second component is a list that 
> comtains the following:
> 
>  > mylist <- churn[2]
> 
>  > class(mylist)
> [1] "list"
> 
>  > mylist
> 
>                             PC1                    PC2                
> PC3                    PC4                    PC5                    PC6
> Account_Length    -8.930570e-03    2.383719e-03    -2.414908e-02    
> -1.004704e-01    9.941468e-01    2.867606e-02
> Area_Code            1.543767e-02    -1.710566e-02    -6.258129e-03    
> 9.945271e-01    1.008478e-01    -8.890155e-03
> Intl_Plan                -2.627796e-04    -1.809011e-04    
> -9.542965e-05    3.230055e-04    2.148520e-04    -1.622996e-05
> VMail_Plan            4.879640e-06    -1.339026e-04    1.639344e-04    
> -1.367628e-05    2.897648e-05    5.548126e-04
> VMail_Message    -4.174810e-04    -2.969518e-03    4.791422e-03    
> -5.643246e-04    -1.752559e-03    1.433728e-02
> Day_Mins            -9.845791e-01    2.049519e-02    -4.038624e-02    
> 1.619195e-02    -8.308484e-03    4.217712e-04
> Day_Calls            -2.810874e-03    1.428161e-02    2.837638e-03    
> -7.647877e-03    2.532260e-02    -9.431350e-01
> Day_Charge        -1.673781e-01    3.483165e-03    -6.864827e-03    
> 2.752626e-03    -1.412836e-03    7.042886e-05
> Eve_Mins            -4.029002e-02    -8.265860e-01    5.544912e-01    
> -1.166711e-02    1.426697e-02    -1.087738e-02
> 
> It look more like a matrix!
> but I cannot access individual items in this list.
> 
>  > mylist[1]
> 'returns the whole think'
> 
>  > mylist[1,1]
> Error in mylist[1, 1] : incorrect number of dimensions
> 
>  > mylist[2]
> $<NA>
> NULL
> 
> 
> Would you please help me on this

  Below are some possibilities.  What exactly are you trying to extract
for the prcomp results?

> pc <- prcomp(USArrests, scale = TRUE)

> str(pc)
List of 5
 $ sdev    : num [1:4] 1.575 0.995 0.597 0.416
 $ rotation: num [1:4, 1:4] -0.536 -0.583 -0.278 -0.543  0.418 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:4] "Murder" "Assault" "UrbanPop" "Rape"
  .. ..$ : chr [1:4] "PC1" "PC2" "PC3" "PC4"
 $ center  : Named num [1:4]   7.79 170.76  65.54  21.23
  ..- attr(*, "names")= chr [1:4] "Murder" "Assault" "UrbanPop" "Rape"
 $ scale   : Named num [1:4]  4.36 83.34 14.47  9.37
  ..- attr(*, "names")= chr [1:4] "Murder" "Assault" "UrbanPop" "Rape"
 $ x       : num [1:50, 1:4] -0.976 -1.931 -1.745  0.140 -2.499 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:50] "Alabama" "Alaska" "Arizona" "Arkansas" ...
  .. ..$ : chr [1:4] "PC1" "PC2" "PC3" "PC4"
 - attr(*, "class")= chr "prcomp"

> pc[[2]]
                PC1        PC2        PC3         PC4
Murder   -0.5358995  0.4181809 -0.3412327  0.64922780
Assault  -0.5831836  0.1879856 -0.2681484 -0.74340748
UrbanPop -0.2781909 -0.8728062 -0.3780158  0.13387773
Rape     -0.5434321 -0.1673186  0.8177779  0.08902432

> pc[[2]][,1:2]
                PC1        PC2
Murder   -0.5358995  0.4181809
Assault  -0.5831836  0.1879856
UrbanPop -0.2781909 -0.8728062
Rape     -0.5434321 -0.1673186

> pc$rotation[,1:2]
                PC1        PC2
Murder   -0.5358995  0.4181809
Assault  -0.5831836  0.1879856
UrbanPop -0.2781909 -0.8728062
Rape     -0.5434321 -0.1673186

> Regards
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894



From mm at pinest.org  Mon Dec  4 23:16:20 2006
From: mm at pinest.org (Michael McCulloch)
Date: Mon, 04 Dec 2006 14:16:20 -0800
Subject: [R] beginning my R-learning
Message-ID: <6.0.3.0.0.20061204141530.01e1a960@pop.sbcglobal.yahoo.com>

Hello,
I'm just beginning to learn R. What books/online learning modules with 
datasets would you suggest?
Thank you!



Best wishes,
Michael


____________________________________

Michael McCulloch
Pine Street Clinic
Pine Street Foundation
124 Pine Street, San Anselmo, CA 94960-2674
tel     415.407.1357
fax     415.485.1065
email:  mm at pinest.org
web:    www.pinest.org
         www.pinestreetfoundation.org
         www.medepi.net/meta



From murdoch at stats.uwo.ca  Tue Dec  5 14:42:21 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 05 Dec 2006 08:42:21 -0500
Subject: [R] beginning my R-learning
In-Reply-To: <6.0.3.0.0.20061204141530.01e1a960@pop.sbcglobal.yahoo.com>
References: <6.0.3.0.0.20061204141530.01e1a960@pop.sbcglobal.yahoo.com>
Message-ID: <4575773D.8090408@stats.uwo.ca>

On 12/4/2006 5:16 PM, Michael McCulloch wrote:
> Hello,
> I'm just beginning to learn R. What books/online learning modules with 
> datasets would you suggest?

I think this depends on your background, and what you intend to do with 
R.  The manuals that come with R will probably answer your questions, 
but there may be easier ways to get what you need.

Duncan Murdoch



From czoske at astro.rug.nl  Tue Dec  5 15:07:32 2006
From: czoske at astro.rug.nl (Oliver Czoske)
Date: Tue, 5 Dec 2006 15:07:32 +0100 (MET)
Subject: [R] Summary shows wrong maximum
In-Reply-To: <45740D0D.8090003@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0612051459100.9703-100000@shoemaker.intra.astro.rug.nl>

On Mon, 4 Dec 2006, Uwe Ligges wrote:
> Sebastian Spaeth wrote:
> > Hi all,
> > I have a list with a numerical column "cum_hardreuses". By coincidence I  
> > discovered this:
> > 
> >> max(libs[,"cum_hardreuses"])
> > [1] 1793
> > 
> >> summary(libs[,"cum_hardreuses"])
> >     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> >        1       2       4      36      14    1790
> > 
> > (note the max value of 1790) Ouch this is bad! Anything I can do to remedy  
> > this? Known bug?
> 
> No, it's a feature! See ?summary: printing is done up to 3 significant 
> digits by default. 

Unfortunately, '1790' is printed with *four* significant digits, not 
three. The correct representation with three significant digits would have 
to employ scientific notation, 1.79e3. 

-- 
--------------------------------------------------------------
Oliver Czoske                              czoske at astro.rug.nl
Kapteyn Astronomical Institute           Tel.: +31-50-363 4036
P.O.Box 800
9700 AV Groningen
Netherlands



From cerbrinags at hotmail.com  Tue Dec  5 15:09:39 2006
From: cerbrinags at hotmail.com (guanshen)
Date: Tue, 5 Dec 2006 14:09:39 +0000
Subject: [R] question about installation of R 2.4
Message-ID: <BAY124-W951046983E6739FD00620D9DE0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061205/73bb32a6/attachment-0004.pl 

From maechler at stat.math.ethz.ch  Tue Dec  5 15:12:39 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 5 Dec 2006 15:12:39 +0100
Subject: [R] How to customize dendrogram plots {"cluster package"}
In-Reply-To: <20061205120626.315000@gmx.net>
References: <20061205120626.315000@gmx.net>
Message-ID: <17781.32343.619025.308819@stat.math.ethz.ch>

>>>>> "Mahdi" == Mahdi Osman <m_osm at gmx.net>
>>>>>     on Tue, 05 Dec 2006 13:06:26 +0100 writes:


    Mahdi> I am doing cluster analysis using the cluster package. I created a dendrogram using the function plot(agnes(myData)). When I try to change the sise of labels, it does not work. I tried cex = 1.5, etc. Nothing worked. Can anyone give me a hint on how to change the sise of the labels, as well as the sise of axes labels.

You need to learn 
  (1) finding out what you are doing, and
  (2) telling others more precisely about it ...

- As you see, plot() is "smart" about agnes() results;
  so you should read the help page for agnes.
  --> In it's "See also" section, there's several links,
  notably to 'plot.agnes' :
- Since agnes() has S3 class "agnes" (and 'plot()' is a (S3)
  generic function, it's the plot.agnes() method that is used.
  It's help page explains things about the two plots it draws,
  and then

  >>  For more customization of the plots, rather call 'bannerplot' and
  >>  'pltree' directly with corresponding arguments, e.g., 'xlab' or 'ylab'.

- From ?pltree, you are quickly lead on to  '?pltree.twins'
  and there, I hope you see the light:

  ---> use as.hclust() , as.dendrogram() and work with the very
  flexible plot() methods for "dendrogram"s.

  As always: "Learn from the examples"; in this case, already
       example(pltree.twins)
  shows you how to change the 'cex' (i.e. size) for the labels.

--- --- ---


 Morale Of The Story  
 ~ ~ ~ ~ ~ ~ ~ ~ ~ ~

 o short version:  RTFM

 o longer version: 

       1. Do read the help pages
       2. Do read the help pages carefully, and 
       3. Obey the "See also"
	  --> goto 1


Regards,
Martin Maechler ETH Zurich



From milton_ruser at yahoo.com.br  Tue Dec  5 15:24:06 2006
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Tue, 5 Dec 2006 14:24:06 +0000 (GMT)
Subject: [R] from "table" to "df"
Message-ID: <20061205142406.90632.qmail@web56611.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061205/e2970757/attachment-0004.pl 

From milton_ruser at yahoo.com.br  Tue Dec  5 16:33:13 2006
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Tue, 5 Dec 2006 15:33:13 +0000 (GMT)
Subject: [R] from "table" to "dataframe"
Message-ID: <590852.28764.qm@web56611.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061205/8180debc/attachment-0004.pl 

From EICKELMA at de.ibm.com  Tue Dec  5 16:33:15 2006
From: EICKELMA at de.ibm.com (Hans-Juergen Eickelmann)
Date: Tue, 5 Dec 2006 16:33:15 +0100
Subject: [R] if(){} else{}
Message-ID: <OFB59BA846.2882DD87-ONC125723B.00530366-C125723B.00557106@de.ibm.com>


Dear R-community,

my data set looks like 'mat' below.

Plant<-c(NA,1,1,1,NA,NA,NA,NA,NA,1);
Value1<-rnorm(1:10);
Value2<-rnorm(1:10);
mat<-cbind(Plant,Value1,Value2);
I receive data from two different sites.
One site is identified by an interger number, the other site has no data in
column Plant=NA.

My pb:

I'm trying to assign labels "A" or "B" to these 2 sites into a new column,
but my if(){} else{} statement fails with the following statement:
Error in if (is.na(mat$Plant == TRUE)) { :
        argument is of length zero

if(is.na(mat$Plant==TRUE)){mat$Plant1="A"} else{mat$Plant1="B"};

I looked through the avail doc and R-help for some time but wasn't able to
fix the pb.

Thx Hans



From antonio.punzon at st.ieo.es  Tue Dec  5 16:35:31 2006
From: antonio.punzon at st.ieo.es (Antonio Punzon)
Date: Tue, 5 Dec 2006 16:35:31 +0100 
Subject: [R] Cummulative Variance in Correspondence Analysis (ADE4)
Message-ID: <BF1DECA51E1F22428D68DD2686054CF4585365@servidor_2000.st.ieo.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061205/5819fd48/attachment-0004.pl 

From pierrelap at gmail.com  Tue Dec  5 16:43:56 2006
From: pierrelap at gmail.com (Pierre Lapointe)
Date: Tue, 5 Dec 2006 10:43:56 -0500
Subject: [R] Quintile by month vector
Message-ID: <676b0d530612050743v5c90c90fye78ecd963674efcd@mail.gmail.com>

Hello,

Question: How do I create a QUINTILE BY MONTH vector

#Here's my dataset
set.seed(1)
dates <- c(rep("2006-01-01",6),rep("2007-02-01",6))
value <-runif(12)
DF <-data.frame(cbind(dates,value),stringsAsFactors=FALSE)
DF$dates <-as.Date(DF$dates,format="%Y-%m-%d")
DF$value <-as.numeric(DF$value)

#Here's how I calculate quintiles for whole dataset
library(Hmisc)
as.numeric(cut2(DF$value, g=5))
# [1] 2 3 3 5 1 4 5 4 3 1 2 1

Now, I need to calculate quintiles by month and year

For example the quintiles for observations in January 2006 would be

as.numeric(cut2(
subset(DF,as.numeric(format(DF$dates, "%m"))==1&
as.numeric(format(DF$dates, "%Y"))==2006,select="value",drop=TRUE)
, g=5))
#[1] 1 2 3 5 1 4

In other words, I'm looking for a vector that would give the January
2006 quintile if the observation is in January and February 2007
quintile if in February 2007.



From andy_liaw at merck.com  Tue Dec  5 17:03:36 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 5 Dec 2006 11:03:36 -0500
Subject: [R] from "table" to "dataframe"
In-Reply-To: <590852.28764.qm@web56611.mail.re3.yahoo.com>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA03536E20@usctmx1106.merck.com>

Like this?

R> data.frame(unclass(df2))
   a b c d
s1 8 4 4 4
s2 8 4 4 4
s3 8 4 4 4

Andy
 

From: Milton Cezar Ribeiro
> 
> Hi there, 
>    
>   I have a two-entrance dataframe, and I would like generate 
> a new dataframe with its frequency. I tryed this
>    
>   site<-rep(c("s1","s2","s3"),20)
> species<-rep(c("a","b","a","c","d"),12)
>   df<-data.frame(cbind(site,species))
>   df2<-table(df)
> 
>   But when I convert df2 to data.frame I miss the square 
> format. I would like have my data.frame like this:
>    
>   site a b c d
>   s1 8 4 4 4
>   s2 8 4 4 4
>   s3 8 4 4 4
>    
>   Any help?
>    
>   Miltinho
> 
>  		
> ---------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From tuechler at gmx.at  Tue Dec  5 17:04:36 2006
From: tuechler at gmx.at (Heinz Tuechler)
Date: Tue, 05 Dec 2006 17:04:36 +0100
Subject: [R] How to join data.frames containing Surv objects?
Message-ID: <3.0.6.32.20061205170436.00b089f0@pop.gmx.net>

Dear All,

Trying to combine two data frames with identical structure by rbind() or
merge() I cannot find a way to preserve the class of a Surv object (see
example).
Reading the help page for rbind, I an uncertain if I could expect that a
Surf oject retains it's class, but I would wish it did.

Thanks

Heinz T?chler

R version 2.4.0 Patched (2006-11-03 r39792)
Windows XP

library(survival)
## create example data
starttime <- rep(0,5)
stoptime  <- 1:5
event     <- c(1,0,1,1,1)
group     <- c(1,1,1,2,2)

## build Surv object
survobj <- Surv(starttime, stoptime, event)

## build data.frame with Surv object
df.test <- data.frame(survobj, group); df.test; str(df.test)
## split in two data frames
dft1 <- df.test[1:3,]; dft1; str(dft1); class(dft1$survobj)  # class is Surv
dft2 <- df.test[4:5,]; dft2; str(dft2); class(dft2$survobj)  # class is Surv
## rbind in one data.frame
dft12 <- rbind(dft1, dft2); dft12; str(dft12); class(dft12$survobj)  #
class is matrix

## merge in one data.frame
dft12merge <- merge(dft1, dft2, all=TRUE, sort=FALSE)
dft12merge; str(dft12merge); class(dft12merge$survobj)  # class is matrix



From neuro3000 at hotmail.com  Tue Dec  5 17:09:40 2006
From: neuro3000 at hotmail.com (=?iso-8859-1?B?TmV1cm8gTGVTdXBlckjpcm9z?=)
Date: Tue, 05 Dec 2006 11:09:40 -0500
Subject: [R] beginning my R-learning
In-Reply-To: <6.0.3.0.0.20061204141530.01e1a960@pop.sbcglobal.yahoo.com>
Message-ID: <BAY131-F301AD80533E9C0542F79DFAFDE0@phx.gbl>

R for begginers is a good start:
cran.r-project.org/doc/contrib/Paradis-rdebuts_en.pdf


>From: Michael McCulloch <mm at pinest.org>
>To: r-help at stat.math.ethz.ch
>Subject: [R] beginning my R-learning
>Date: Mon, 04 Dec 2006 14:16:20 -0800
>
>Hello,
>I'm just beginning to learn R. What books/online learning modules with
>datasets would you suggest?
>Thank you!
>
>
>
>Best wishes,
>Michael
>
>
>____________________________________
>
>Michael McCulloch
>Pine Street Clinic
>Pine Street Foundation
>124 Pine Street, San Anselmo, CA 94960-2674
>tel     415.407.1357
>fax     415.485.1065
>email:  mm at pinest.org
>web:    www.pinest.org
>          www.pinestreetfoundation.org
>          www.medepi.net/meta
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide 
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

_________________________________________________________________
Achetez ce que vous voulez, quand vous voulez sur Sympatico / MSN Magasiner



From jbcombes at gmail.com  Tue Dec  5 17:19:50 2006
From: jbcombes at gmail.com (Jean-Baptiste Combes)
Date: Tue, 5 Dec 2006 17:19:50 +0100
Subject: [R] Surveys ans missing values
Message-ID: <959b0bd80612050819u28e04b50r33536af462fb6548@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061205/329e0d74/attachment-0004.pl 

From dray at biomserv.univ-lyon1.fr  Tue Dec  5 17:22:37 2006
From: dray at biomserv.univ-lyon1.fr (=?ISO-8859-1?Q?St=E9phane_Dray?=)
Date: Tue, 05 Dec 2006 17:22:37 +0100
Subject: [R] Cummulative Variance in Correspondence Analysis (ADE4)
In-Reply-To: <BF1DECA51E1F22428D68DD2686054CF4585365@servidor_2000.st.ieo.es>
References: <BF1DECA51E1F22428D68DD2686054CF4585365@servidor_2000.st.ieo.es>
Message-ID: <45759CCD.8030304@biomserv.univ-lyon1.fr>

Dear Antonio,
if you have questions on the ade4 package, please  send email to adelist 
(http://listes.univ-lyon1.fr/wws/info/adelist).
The total inertia (variance) of CA is equal to the sum of all eigenvalues :

 > data(rpjdl)
 > rpjdl.coa <- dudi.coa(rpjdl$fau, scannf = FALSE, nf = 4)
 > sum(rpjdl.coa$eig)
[1] 4.468333

This is equal to the chi2 stat divided by the number of individuals:

 > chisq.test(rpjdl$fau)$statistic/sum(rpjdl$fau)
X-squared
 4.468333

One can obtain the inertia associated to i-th axis by dividing the i-th 
eigenvalue by the total inertia. Here are percentages:

 > round(rpjdl.coa$eig/sum(rpjdl.coa$eig)*100,2)
 [1] 16.86  6.56  5.13  4.58  3.52  3.39  3.37  3.12  2.87  2.72  2.63  2.56
[13]  2.49  2.43  2.34  2.21  2.09  2.00  1.86  1.76  1.61  1.48  1.45  1.43
[25]  1.38  1.26  1.23  1.15  1.14  1.08  1.07  1.01  0.94  0.92  0.89  0.83
[37]  0.77  0.71  0.65  0.61  0.59  0.49  0.47  0.46  0.38  0.36  0.35  0.32
[49]  0.29  0.19

The cumulative inertia is obtained by :

 > round(cumsum(rpjdl.coa$eig)/sum(rpjdl.coa$eig)*100,2)
 [1]  16.86  23.41  28.55  33.13  36.65  40.03  43.41  46.53  49.39  52.11
[11]  54.75  57.31  59.79  62.23  64.57  66.78  68.87  70.87  72.73  74.49
[21]  76.10  77.58  79.02  80.45  81.83  83.09  84.32  85.47  86.61  87.69
[31]  88.76  89.77  90.71  91.63  92.53  93.36  94.13  94.84  95.49  96.10
[41]  96.69  97.19  97.66  98.12  98.49  98.85  99.20  99.52  99.81 100.00

Antonio Punzon wrote:
> Hi all:
> How can I calculate the cumulative variance (or variance for each component)
> in correspondence analysis?
> If were possible in ADE4 package
> Thank you
>
>
>
>  -- Antonio Punz?n Merino
>  O__---- Instituto Espa?ol de Oceanograf?a
> c/ /'_ --- Centro Oceanogr?fico de Santander
>  (*) \(*) -- Promontorio de San Mart?n S/N
> ~~~~~~~~~~ 39004-Santander; Spain
>  PO BOX: 240
>  Tlf: +34 942 29 10 60
> Fax: +34 942 27 50 72
> e-mail: antonio.punzon at st.ieo.es
> web: www.ieo.es <www.ieo.es> 
> web: www.sap-ieo.wikispaces.com <www.sap-ieo.wikispaces.com>
> ________________________________________
>
>
>
> La informaci?n contenida en este e-mail y sus ficheros adjuntos es totalmente confidencial y no deber?a ser usado si no fuera usted alguno de los destinatarios. Si ha recibido este e-mail por error, por favor avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de almacenamiento.   This email is confidential and should not be used by anyone who is not the original intended  recipient. If you have received this e-mail in  error please inform the sender and delete it from  your mailbox or any other storage mechanism.
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
St?phane DRAY (dray at biomserv.univ-lyon1.fr )
Laboratoire BBE-CNRS-UMR-5558, Univ. C. Bernard - Lyon I
43, Bd du 11 Novembre 1918, 69622 Villeurbanne Cedex, France
Tel: 33 4 72 43 27 57       Fax: 33 4 72 43 13 88
http://biomserv.univ-lyon1.fr/~dray/



From Greg.Snow at intermountainmail.org  Tue Dec  5 17:25:53 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Tue, 5 Dec 2006 09:25:53 -0700
Subject: [R] if(){} else{}
Message-ID: <07E228A5BE53C24CAD490193A7381BBB6F2941@LP-EXCHVS07.CO.IHC.COM>

Try this version:

Plant<-c(NA,1,1,1,NA,NA,NA,NA,NA,1);
Value1<-rnorm(10);
Value2<-rnorm(10);
mat<-data.frame(Plant,Value1,Value2);

mat <- transform(mat, Plant1=ifelse(is.na(Plant), "A","B"))


A couple of comments on your original code:

The 1:10 in the rnorm calls is unnecessary since rnorm just takes the
length of the vector, just tell rnorm how many numbers you want (or you
could do rnorm(Plant) to have R count for you).

The cbind function creates a matrix, the notation mat$Plant assumes that
mat is a list or data frame and that is why you received the error.

The  if (){} else {} syntax is usually for program flow and looks for a
scalar value, the function ifelse is vectorized and usefull for vectors
(which is what it looks like you wanted).

The transform function is nice in that it allows you to skip some of the
indexing.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Hans-Juergen
Eickelmann
Sent: Tuesday, December 05, 2006 8:33 AM
To: r-help at stat.math.ethz.ch
Subject: [R] if(){} else{}


Dear R-community,

my data set looks like 'mat' below.

Plant<-c(NA,1,1,1,NA,NA,NA,NA,NA,1);
Value1<-rnorm(1:10);
Value2<-rnorm(1:10);
mat<-cbind(Plant,Value1,Value2);
I receive data from two different sites.
One site is identified by an interger number, the other site has no data
in column Plant=NA.

My pb:

I'm trying to assign labels "A" or "B" to these 2 sites into a new
column, but my if(){} else{} statement fails with the following
statement:
Error in if (is.na(mat$Plant == TRUE)) { :
        argument is of length zero

if(is.na(mat$Plant==TRUE)){mat$Plant1="A"} else{mat$Plant1="B"};

I looked through the avail doc and R-help for some time but wasn't able
to fix the pb.

Thx Hans

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From d.scott at auckland.ac.nz  Tue Dec  5 17:26:55 2006
From: d.scott at auckland.ac.nz (David Scott)
Date: Wed, 6 Dec 2006 05:26:55 +1300 (NZDT)
Subject: [R] if(){} else{}
In-Reply-To: <OFB59BA846.2882DD87-ONC125723B.00530366-C125723B.00557106@de.ibm.com>
References: <OFB59BA846.2882DD87-ONC125723B.00530366-C125723B.00557106@de.ibm.com>
Message-ID: <Pine.LNX.4.64.0612060525440.19095@stat12.stat.auckland.ac.nz>


Test should be

if(is.na(mat$Plant)){ ...



On Tue, 5 Dec 2006, Hans-Juergen Eickelmann wrote:

>
> Dear R-community,
>
> my data set looks like 'mat' below.
>
> Plant<-c(NA,1,1,1,NA,NA,NA,NA,NA,1);
> Value1<-rnorm(1:10);
> Value2<-rnorm(1:10);
> mat<-cbind(Plant,Value1,Value2);
> I receive data from two different sites.
> One site is identified by an interger number, the other site has no data in
> column Plant=NA.
>
> My pb:
>
> I'm trying to assign labels "A" or "B" to these 2 sites into a new column,
> but my if(){} else{} statement fails with the following statement:
> Error in if (is.na(mat$Plant == TRUE)) { :
>        argument is of length zero
>
> if(is.na(mat$Plant==TRUE)){mat$Plant1="A"} else{mat$Plant1="B"};
>
> I looked through the avail doc and R-help for some time but wasn't able to
> fix the pb.
>
> Thx Hans
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

_________________________________________________________________
David Scott	Visiting (Until January 07)
 		Department of Probability and Statistics
 		The University of Sheffield
 		The Hicks Building
 		Hounsfield Road
 		Sheffield S3 7RH
 		United Kingdom
Phone:	+44 114 222 3908
Email:	d.scott at auckland.ac.nz



From Greg.Snow at intermountainmail.org  Tue Dec  5 17:38:21 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Tue, 5 Dec 2006 09:38:21 -0700
Subject: [R] Surveys ans missing values
Message-ID: <07E228A5BE53C24CAD490193A7381BBB6F2947@LP-EXCHVS07.CO.IHC.COM>

Have you tried:

> svymean(~q135, survey, na.rm=TRUE)

 


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jean-Baptiste
Combes
Sent: Tuesday, December 05, 2006 9:20 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Surveys ans missing values

Hello,

I still apologise if the question i ask is naive. I would like to use R
instead of usual softs (SAS, Stata) or at list to do things that the
others do not. As a consequence I am trying to get familiar with R, and
i am astonished because it does not seem to do things that are easy to
do on other softs.

I have got data with missing values (I am working on a questionnaire
filled by students) and with weights and stratification. I learned how
to use the survey package, and I would like to do an average (by using
svymean) of a variable that has some NA.
I first tried :
svymean(~q135,survey) #q135 is the name of the variable and survey is
the name of the survey design but as there is missing values, i get that
:

     mean SE
q135   NA NA

as a consequence I put the observations without missing values in a
vector x
:
x<-na.omit(data$q135)

and I tried to make my average on that vector
svymean(~x,survey)
but I get an error because my weights are constructed on all the sample
and the vector of the weights has 1773 rows (that is the size of the
population) and the variable I want to make an average on has only 1754
rows.

I expect that my explanations are clear enough.

Thanks very much

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From mm at pinest.org  Tue Dec  5 17:45:52 2006
From: mm at pinest.org (Michael McCulloch)
Date: Tue, 05 Dec 2006 08:45:52 -0800
Subject: [R] using R for survival analysis
Message-ID: <6.0.3.0.0.20061205083736.01e1b2d0@pop.sbcglobal.yahoo.com>

Thank you to all who made very helpful suggestions to get started with R. 
Duncan Murdoch raised an excellent question, asking about my background and 
reason for using R. I'm an epidemiologist, applying the marginal structural 
models approach (inverse probability of treatment weights) in a Cox 
proportional hazards analysis.

The statistical program which I had been using does not have functions for 
doing a weighted Cox analysis.  Any advice pointing me in the direction of 
resources to help probability-of-treatment-weighted Cox proportional 
hazards would be most appreciated.



Best wishes,
Michael


____________________________________

Michael McCulloch
Pine Street Clinic
Pine Street Foundation
124 Pine Street, San Anselmo, CA 94960-2674
tel     415.407.1357
fax     415.485.1065
email:  mm at pinest.org
web:    www.pinest.org
         www.pinestreetfoundation.org
         www.medepi.net/meta



From gavin.simpson at ucl.ac.uk  Tue Dec  5 17:46:37 2006
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 05 Dec 2006 16:46:37 +0000
Subject: [R] if(){} else{}
In-Reply-To: <OFB59BA846.2882DD87-ONC125723B.00530366-C125723B.00557106@de.ibm.com>
References: <OFB59BA846.2882DD87-ONC125723B.00530366-C125723B.00557106@de.ibm.com>
Message-ID: <1165337197.30209.63.camel@gsimpson.geog.ucl.ac.uk>

On Tue, 2006-12-05 at 16:33 +0100, Hans-Juergen Eickelmann wrote:
> Dear R-community,
> 
> my data set looks like 'mat' below.
> 
> Plant<-c(NA,1,1,1,NA,NA,NA,NA,NA,1);
> Value1<-rnorm(1:10);

You only really need rnorm(10), as in ?rnorm, rnorm is defined as
rnorm(n, mean=0, sd=1) and n is the number of observations.

> Value2<-rnorm(1:10);
> mat<-cbind(Plant,Value1,Value2);

You don't need the ";" at the ends of the lines, and cbind() returns a
matrix, for which you cannot use "$" to access the columns:

> class(mat)
[1] "matrix"
> mat$Plant
NULL

What you are looking for is ifelse(), see ?ifelse, but here is your
example, suitable spaced out and minus the other infelicities.

Plant <- c(NA, 1, 1, 1, NA, NA, NA, NA, NA, 1)
Value1 <- rnorm(10)
Value2 <- rnorm(10)
mat <- data.frame(Plant, Value1, Value2)
mat$Plant1 <- ifelse(is.na(mat$Plant), "A", "B")

> mat$Plant1
 [1] "A" "B" "B" "B" "A" "A" "A" "A" "A" "B"
> mat
   Plant      Value1      Value2 Plant1
1     NA  2.76603270 -0.20435729      A
2      1 -0.54688170 -0.81943566      B
3      1  0.30480812 -0.05404563      B
4      1  1.64959026 -0.10762260      B
5     NA  1.13528236 -0.04670294      A
6     NA  1.55636761  0.87617575      A
7     NA  0.40651924  1.90516887      A
8     NA  1.49827147  0.05080935      A
9     NA -0.04396752  0.53267040      A
10     1  0.42714137 -0.55944595      B

HTH

G

> I receive data from two different sites.
> One site is identified by an interger number, the other site has no data in
> column Plant=NA.
> 
> My pb:
> 
> I'm trying to assign labels "A" or "B" to these 2 sites into a new column,
> but my if(){} else{} statement fails with the following statement:
> Error in if (is.na(mat$Plant == TRUE)) { :
>         argument is of length zero
> 
> if(is.na(mat$Plant==TRUE)){mat$Plant1="A"} else{mat$Plant1="B"};

That's not how you use is.na(), see ?is.na, as is.na(x) returns
TRUE/FLASE depending on wither x is NA or not

> I looked through the avail doc and R-help for some time but wasn't able to
> fix the pb.
> 
> Thx Hans
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC & ENSIS, UCL Geography,  [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From gavin.simpson at ucl.ac.uk  Tue Dec  5 17:48:47 2006
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 05 Dec 2006 16:48:47 +0000
Subject: [R] if(){} else{}
In-Reply-To: <Pine.LNX.4.64.0612060525440.19095@stat12.stat.auckland.ac.nz>
References: <OFB59BA846.2882DD87-ONC125723B.00530366-C125723B.00557106@de.ibm.com>
	<Pine.LNX.4.64.0612060525440.19095@stat12.stat.auckland.ac.nz>
Message-ID: <1165337327.30209.66.camel@gsimpson.geog.ucl.ac.uk>

On Wed, 2006-12-06 at 05:26 +1300, David Scott wrote:
> Test should be
> 
> if(is.na(mat$Plant)){ ...

No, that won't work because if() is not vectorized:

> if(is.na(mat$Plant)){mat$Plant1 <- "A"} else{mat$Plant1 <- "B"}
Warning message:
the condition has length > 1 and only the first element will be used in:
if (is.na(mat$Plant)) {
> mat$Plant1
 [1] "A" "A" "A" "A" "A" "A" "A" "A" "A" "A"

G

> 
> 
> 
> On Tue, 5 Dec 2006, Hans-Juergen Eickelmann wrote:
> 
> >
> > Dear R-community,
> >
> > my data set looks like 'mat' below.
> >
> > Plant<-c(NA,1,1,1,NA,NA,NA,NA,NA,1);
> > Value1<-rnorm(1:10);
> > Value2<-rnorm(1:10);
> > mat<-cbind(Plant,Value1,Value2);
> > I receive data from two different sites.
> > One site is identified by an interger number, the other site has no data in
> > column Plant=NA.
> >
> > My pb:
> >
> > I'm trying to assign labels "A" or "B" to these 2 sites into a new column,
> > but my if(){} else{} statement fails with the following statement:
> > Error in if (is.na(mat$Plant == TRUE)) { :
> >        argument is of length zero
> >
> > if(is.na(mat$Plant==TRUE)){mat$Plant1="A"} else{mat$Plant1="B"};
> >
> > I looked through the avail doc and R-help for some time but wasn't able to
> > fix the pb.
> >
> > Thx Hans
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> _________________________________________________________________
> David Scott	Visiting (Until January 07)
>  		Department of Probability and Statistics
>  		The University of Sheffield
>  		The Hicks Building
>  		Hounsfield Road
>  		Sheffield S3 7RH
>  		United Kingdom
> Phone:	+44 114 222 3908
> Email:	d.scott at auckland.ac.nz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC & ENSIS, UCL Geography,  [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From tlumley at u.washington.edu  Tue Dec  5 17:57:06 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 5 Dec 2006 08:57:06 -0800 (PST)
Subject: [R] using R for survival analysis
In-Reply-To: <6.0.3.0.0.20061205083736.01e1b2d0@pop.sbcglobal.yahoo.com>
References: <6.0.3.0.0.20061205083736.01e1b2d0@pop.sbcglobal.yahoo.com>
Message-ID: <Pine.LNX.4.64.0612050851190.31848@homer22.u.washington.edu>

On Tue, 5 Dec 2006, Michael McCulloch wrote:

> Thank you to all who made very helpful suggestions to get started with R.
> Duncan Murdoch raised an excellent question, asking about my background and
> reason for using R. I'm an epidemiologist, applying the marginal structural
> models approach (inverse probability of treatment weights) in a Cox
> proportional hazards analysis.
>
> The statistical program which I had been using does not have functions for
> doing a weighted Cox analysis.  Any advice pointing me in the direction of
> resources to help probability-of-treatment-weighted Cox proportional
> hazards would be most appreciated.

You can do IPW estimation with the coxph() function in the 'survival' 
package as long as you use the `robust=TRUE' option for standard errors.

The weights can be supplied as weights to coxph().

  You need to fit logistic regression models for treatment, with glm(), 
then use predict() to get probabilities of treatment (yes/no) then convert 
these into probability of observed treatment, then take the reciprocal to 
get the weights.

How messy this all is depends on the data structure -- how regular the 
observations of 'treatment' are, for example -- since this determines how 
many different logistic models for treatment you will need.

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From rmh at temple.edu  Tue Dec  5 18:06:41 2006
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue,  5 Dec 2006 12:06:41 -0500 (EST)
Subject: [R] Fwd:  from "table" to "dataframe"
Message-ID: <20061205120641.BOW04066@po-d.temple.edu>

It is easy to force a table into a data.frame and still keep the
tabular structure, but I am not sure why you would want to do that.

data.frame(df2[])

The columns of a data.frame are independent variables.
The columns of df2 don't stand on their own.


---- Original message ----
>Date: Tue, 5 Dec 2006 15:33:13 +0000 (GMT)
>From: Milton Cezar Ribeiro <milton_ruser at yahoo.com.br>  
>Subject: [R] from "table" to "dataframe"  
>To: R-help <r-help at stat.math.ethz.ch>
>
>Hi there, 
>   
>  I have a two-entrance dataframe, and I would like generate a new dataframe with its frequency. 
I tryed this
>   
>  site<-rep(c("s1","s2","s3"),20)
>species<-rep(c("a","b","a","c","d"),12)
>  df<-data.frame(cbind(site,species))
>  df2<-table(df)
>
>  But when I convert df2 to data.frame I miss the square format. I would like have my data.frame 
like this:
>   
>  site a b c d
>  s1 8 4 4 4
>  s2 8 4 4 4
>  s3 8 4 4 4
>   
>  Any help?
>   
>  Miltinho
>
> 		
>---------------------------------
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From mike.prager at noaa.gov  Tue Dec  5 18:13:36 2006
From: mike.prager at noaa.gov (Mike Prager)
Date: Tue, 05 Dec 2006 12:13:36 -0500
Subject: [R] beginning my R-learning
References: <6.0.3.0.0.20061204141530.01e1a960@pop.sbcglobal.yahoo.com>
Message-ID: <1m9bn2hm4t13gqs3ub9hnhir3tcber1ctr@4ax.com>

Michael McCulloch <mm at pinest.org> wrote:

> Hello,
> I'm just beginning to learn R. What books/online learning modules with 
> datasets would you suggest?
> Thank you!

Thomas Lumley has a nice introduction here:

http://faculty.washington.edu/tlumley/b514/R-fundamentals.pdf


-- 
Mike Prager, NOAA, Beaufort, NC
* Opinions expressed are personal and not represented otherwise.
* Any use of tradenames does not constitute a NOAA endorsement.



From backer at psych.uib.no  Tue Dec  5 18:36:08 2006
From: backer at psych.uib.no (Tom Backer Johnsen)
Date: Tue, 05 Dec 2006 18:36:08 +0100
Subject: [R] Calling R functions in Delphi
In-Reply-To: <OF3A5C81C3.5AEE7555-ON8525723A.0069E1BB-8525723A.006ADF77@abtassoc.com>
References: <OF3A5C81C3.5AEE7555-ON8525723A.0069E1BB-8525723A.006ADF77@abtassoc.com>
Message-ID: <4575AE08.8010304@psych.uib.no>

Anna Belova wrote:
> Hello All,
> 
> We would like to call quantile() function from the R-package STATS in a
> Delphi program. If this is possible, could anyone provide us with an
> example?

It is possible, and in principle simple.  The essentials:  (1) Write a 
file containing the something like a script in R with whatever 
commands. (2) Start a process involving the execution of R with a 
command line containing two arguments, the name of the command file 
and the file where you want the output (results) to be. (3) wait for 
the process to stop.  So, here is a function (returns true if 
everyhing worked OK) that does that:

function StartRAndWait (CommandLine : string) : Boolean;
var
    Proc_info: TProcessInformation;
    Startinfo: TStartupInfo;
    ExitCode: longword;
    CreateOK : Boolean;
begin
    Result := False;

    { Initialize the structures }

    FillChar(proc_info, sizeof (TProcessInformation), #0);
    FillChar(startinfo, sizeof (TStartupInfo), #0);
    Startinfo.cb := sizeof (TStartupInfo);
    Startinfo.dwFlags := STARTF_USESHOWWINDOW or STARTF_USESTDHANDLES;
    Startinfo.wShowWindow := SW_HIDE;

    { Attempt to create the process. If successful wait for it to end}

    CreateOK := CreateProcess(Nil, PChar('R.exe ' + CommandLine), nil,
       nil,False, CREATE_NEW_PROCESS_GROUP+NORMAL_PRIORITY_CLASS, nil,
       nil, StartInfo, proc_info);
    if (CreateOK) then begin
       WaitForSingleObject (proc_info.hProcess, INFINITE);
       GetExitCodeProcess(proc_info.hProcess, ExitCode);
       Result := True
       end;
    CloseHandle(proc_info.hThread);
    CloseHandle(proc_info.hProcess);
    end;

The argument for the procedure (CommandLine) is a string, created by a 
statement like:

Command := 'CMD BATCH ' + CommandFileName + ' ' + TempFileName;

where CommandFileName is the name of the file with the script, and 
TempFileName is the name of the text file containing the output. The 
procedure is fairly lowlevel, but it worked for me using Delphi 7.  I 
do not remember how I managed to put this together (probably a mix of 
help from the R and Delphi lists), so please do not ask questions 
about the finer details.

Tom


+----------------------------------------------------------------+
| Tom Backer Johnsen, Psychometrics Unit,  Faculty of Psychology |
| University of Bergen, Christies gt. 12, N-5015 Bergen,  NORWAY |
| Tel : +47-5558-9185                        Fax : +47-5558-9879 |
| Email : backer at psych.uib.no    URL : http://www.galton.uib.no/ |
+----------------------------------------------------------------+



From malfonso at telecom.com.co  Tue Dec  5 20:25:21 2006
From: malfonso at telecom.com.co (Mario Alfonso Morales Rivera)
Date: Tue, 05 Dec 2006 14:25:21 -0500
Subject: [R] publicar tutorial en CRAN
Message-ID: <4575C7A1.9010707@telecom.com.co>

Hola, a todos los usuarios de R. Me gustar?a saber que pasos hay que
seguir para que un manual o tutorial acerca de R escrito por un
usuario quede disponible en CRAN.

Escrib? un tutorial de Sweave en espa?ol y quiero colocarlo a
disposici?n de los usuarios de R pero no se cuales son los pasos a
seguir, a quien hay que dirigirlo y que requisitos se requieren para
eso.



From A.Robinson at ms.unimelb.edu.au  Tue Dec  5 20:39:32 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 6 Dec 2006 06:39:32 +1100
Subject: [R] if(){} else{}
In-Reply-To: <OFB59BA846.2882DD87-ONC125723B.00530366-C125723B.00557106@de.ibm.com>
References: <OFB59BA846.2882DD87-ONC125723B.00530366-C125723B.00557106@de.ibm.com>
Message-ID: <20061205193932.GK70252@ms.unimelb.edu.au>

Hi Hans,

try this ...

mat <- as.data.frame(cbind(Plant,Value1,Value2))

mat$Plant1 <- ifelse(is.na(mat$Plant), "A", "B")

Cheers

Andrew


On Tue, Dec 05, 2006 at 04:33:15PM +0100, Hans-Juergen Eickelmann wrote:
> 
> Dear R-community,
> 
> my data set looks like 'mat' below.
> 
> Plant<-c(NA,1,1,1,NA,NA,NA,NA,NA,1);
> Value1<-rnorm(1:10);
> Value2<-rnorm(1:10);
> mat<-cbind(Plant,Value1,Value2);
> I receive data from two different sites.
> One site is identified by an interger number, the other site has no data in
> column Plant=NA.
> 
> My pb:
> 
> I'm trying to assign labels "A" or "B" to these 2 sites into a new column,
> but my if(){} else{} statement fails with the following statement:
> Error in if (is.na(mat$Plant == TRUE)) { :
>         argument is of length zero
> 
> if(is.na(mat$Plant==TRUE)){mat$Plant1="A"} else{mat$Plant1="B"};
> 
> I looked through the avail doc and R-help for some time but wasn't able to
> fix the pb.
> 
> Thx Hans
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From dlr32 at cornell.edu  Tue Dec  5 20:41:40 2006
From: dlr32 at cornell.edu (Daniel Lee Rabosky)
Date: Tue, 5 Dec 2006 14:41:40 -0500 (EST)
Subject: [R] dynamic variable creation in lists and data frames
Message-ID: <1898.74.71.46.2.1165347700.squirrel@webmail.cornell.edu>

Hi

I have a question about the creation of variables within lists in R.  I am
running simulations and am interested in two parameters, ESM and ESMM (the
similarity of these names is important for my question).  I do simulations
to generate ESMM, then plug these values into a second simulation function
to get ESM:

x <- list()

for (i in 1:nsimulations)
{
	x$ESMM[i] <- do_simulation1()
	x$ESM[i] <- do_simulation2(x$ESMM[i])
}

and I return everything as a dataframe, x <- as.data.frame(x)

When I do this, I find that x$ESMM is overwritten by x$ESM for the first
simulation.  However, x$ESM is nonetheless correctly generated using
x$ESMM.

Thus, x$ESM[1] =  x$ESMM[1], but for the other n-thousand simulations,
ESMM is not overwritten; the error only occurs on the first instance of
ESM.

I think I know why this is occurring: I am creating a new variable in a
list and assigning it a value, but when R can?t find the variable, it
overwrites the next most similar variable (ESMM).  But it still proceeds
to create the new variable ESM, having overwritten x$ESMM[1].  And it
doesn?t happen for subsequent simulations, because both variables then
exist in the list.

My questions are:
1) how different do variable names have to be to avoid this problem?  What
exactly is R using to decide that ESMM is the same as ESM?

or

2) is there something fundamentally flawed with the manner in which I
dynamically create variables in lists, without initializing them in some
fashion?  This approach worked fine until I noticed this issue with
variables having similar names.

Thanks very much in advance for your help.

Dan Rabosky


Dan Rabosky
Department of Ecology and Evolutionary Biology
Corson Hall
Cornell University
Ithaca, NY 14853



From malfonso at telecom.com.co  Tue Dec  5 21:04:37 2006
From: malfonso at telecom.com.co (Mario Alfonso Morales Rivera)
Date: Tue, 05 Dec 2006 15:04:37 -0500
Subject: [R] put tutorials in CRAN
Message-ID: <4575D0D5.8090701@telecom.com.co>

Hi everyone.
I made an R tutorial in Spanish and would like to know how to put it in CRAN so
everyone can have access to it, does anyone know how to do this? Are there any
steps, rules, etc. to follow to make this tutorial available through CRAN?
Thanks



From p.murrell at auckland.ac.nz  Tue Dec  5 21:11:55 2006
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 06 Dec 2006 09:11:55 +1300
Subject: [R] A question on grid - grid.points not spaced properly
In-Reply-To: <B5D33109-7452-4115-B779-6A74ED3374BD@pobox.com>
References: <B5D33109-7452-4115-B779-6A74ED3374BD@pobox.com>
Message-ID: <4575D28B.7030804@stat.auckland.ac.nz>

Hi


Saptarshi Guha wrote:
> Hello,
> 	How can i 'fix' the following output.
> 
> 	v=viewport(x=216/2, y=216/2,w=216, h=216,default.units = "bigpts")
> 	pushViewport(v)
> 	x=c(119,130,140,151)
> 	y=c(124,124,124,124)
> 	grid.points(x,y,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
> 	grid.points(x-2,y,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
> 	grid.points(x+2,y,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
> 	grid.points(x,y-2,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
> 	grid.points(x,y+2,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
> 
> 
> 	One would expect to get a 4 figures composed of 5 dots each  - 2  
> vertically spaced and 2 horizontally spaced symmetrically around the  
> center dot.
> 	However i seem to get odd results - e.g on Quartz(OS X) output, the  
> last command, places the dot bang next to the center dot.
> 	On 'jpeg' output with higest quality, this oddity happens with the 'x 
> +2' command.
> 
> 	This doesn't happen to all of the points, only some - and not necc.  
> the edge figures.
> 
> 	Is there anyway i can control this?


I think you are seeing a rasterization effect.  Both on screen and in a
bitmap format you are essentially turning on a single pixel at a time.
The locations you are giving do not necessarily correspond to an exact
pixel location (bigpoints are in 1/72 inches, but your screen might have
a resolution of 96 ppi) so you just get the nearest pixel to that
location.  So the gap you specify of two bigpoints sometimes comes out
as 2 pixels, sometimes as 1 pixel (for example).

For comparison, try running your code on a PDF (or other vector format)
device;  the result is much more what you are expecting I think.

Paul


> 	Thanks
> 	Saptarshi
> 
> Saptarshi Guha | sapsi at pobox.com | http://www.stat.purdue.edu/~sguha
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From marc_schwartz at comcast.net  Tue Dec  5 21:21:48 2006
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Tue, 05 Dec 2006 14:21:48 -0600
Subject: [R] dynamic variable creation in lists and data frames
In-Reply-To: <1898.74.71.46.2.1165347700.squirrel@webmail.cornell.edu>
References: <1898.74.71.46.2.1165347700.squirrel@webmail.cornell.edu>
Message-ID: <1165350108.11445.30.camel@localhost.localdomain>

On Tue, 2006-12-05 at 14:41 -0500, Daniel Lee Rabosky wrote:
> Hi
> 
> I have a question about the creation of variables within lists in R.  I am
> running simulations and am interested in two parameters, ESM and ESMM (the
> similarity of these names is important for my question).  I do simulations
> to generate ESMM, then plug these values into a second simulation function
> to get ESM:
> 
> x <- list()
> 
> for (i in 1:nsimulations)
> {
> 	x$ESMM[i] <- do_simulation1()
> 	x$ESM[i] <- do_simulation2(x$ESMM[i])
> }
> 
> and I return everything as a dataframe, x <- as.data.frame(x)
> 
> When I do this, I find that x$ESMM is overwritten by x$ESM for the first
> simulation.  However, x$ESM is nonetheless correctly generated using
> x$ESMM.
> 
> Thus, x$ESM[1] =  x$ESMM[1], but for the other n-thousand simulations,
> ESMM is not overwritten; the error only occurs on the first instance of
> ESM.
> 
> I think I know why this is occurring: I am creating a new variable in a
> list and assigning it a value, but when R can?t find the variable, it
> overwrites the next most similar variable (ESMM).  But it still proceeds
> to create the new variable ESM, having overwritten x$ESMM[1].  And it
> doesn?t happen for subsequent simulations, because both variables then
> exist in the list.
> 
> My questions are:
> 1) how different do variable names have to be to avoid this problem?  What
> exactly is R using to decide that ESMM is the same as ESM?
> 
> or
> 
> 2) is there something fundamentally flawed with the manner in which I
> dynamically create variables in lists, without initializing them in some
> fashion?  This approach worked fine until I noticed this issue with
> variables having similar names.
> 
> Thanks very much in advance for your help.
> 
> Dan Rabosky

This has to do with partial matching to index data frame columns and
list elements. It is the default behavior in R and if you search the
archives using:

  RSiteSearch("partial matching")

you will note prior discussions on this.

A simple example:

> x <- list()
> x
list()

> x$ESMM[1] <- 1
> x
$ESMM
[1] 1

> x$ESM[1] <- 2
> x
$ESMM
[1] 2

$ESM
[1] 2


Both values are changed, since x$ESM does not yet exist and the
assignment partially matches x$ESMM. Then x$ESM is created.

I think that in this particular situation, you might want to try:

# Create a simple function that returns pairs of random samples from 
# 'letters', which is a:z
Sim <- function()
{
   list(ESMM = letters[sample(26, 1)], 
        ESM = letters[sample(26, 1)])
}

# Run it once
> Sim()
$ESMM
[1] "l"

$ESM
[1] "z"


Now use replicate() to do this 10 times. Note the default behavior is to
simplify the returned values into a matrix. 

> x <- replicate(10, Sim())
> x
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
ESMM "x"  "q"  "c"  "f"  "e"  "f"  "y"  "d"  "z"  "h"  
ESM  "u"  "c"  "j"  "v"  "u"  "j"  "o"  "p"  "g"  "g"  


So, in your case create a function Sim() like this:

Sim <- function()
{
  ESMM <- do_simulation1()
  ESM <- do_simulation2(ESMM)
  
  list(ESMM = ESMM, ESM = ESM)
}


and then use replicate() as above.  See ?replicate for more information.

HTH,

Marc Schwartz



From sapsi at pobox.com  Tue Dec  5 21:27:06 2006
From: sapsi at pobox.com (Saptarshi Guha)
Date: Tue, 05 Dec 2006 15:27:06 -0500
Subject: [R] A question on grid - grid.points not spaced properly
In-Reply-To: <4575D28B.7030804@stat.auckland.ac.nz>
References: <B5D33109-7452-4115-B779-6A74ED3374BD@pobox.com>
	<4575D28B.7030804@stat.auckland.ac.nz>
Message-ID: <4575D61A.6060408@pobox.com>

Hi,
    Thank you for the explanation. I have one further question - should 
i wish to plot to the screen, which units (apart from bigpts) for exact 
plotting.
Essentially i wish to create my own plotting character - hence the 
pch="." and the surrounding dots - so it would be nice if i could place 
the surrounding dots exactly.
    Thank you
    Saptarshi Guha


Paul Murrell wrote:
> Hi
>
>
> Saptarshi Guha wrote:
>   
>> Hello,
>> 	How can i 'fix' the following output.
>>
>> 	v=viewport(x=216/2, y=216/2,w=216, h=216,default.units = "bigpts")
>> 	pushViewport(v)
>> 	x=c(119,130,140,151)
>> 	y=c(124,124,124,124)
>> 	grid.points(x,y,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
>> 	grid.points(x-2,y,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
>> 	grid.points(x+2,y,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
>> 	grid.points(x,y-2,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
>> 	grid.points(x,y+2,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
>>
>>
>> 	One would expect to get a 4 figures composed of 5 dots each  - 2  
>> vertically spaced and 2 horizontally spaced symmetrically around the  
>> center dot.
>> 	However i seem to get odd results - e.g on Quartz(OS X) output, the  
>> last command, places the dot bang next to the center dot.
>> 	On 'jpeg' output with higest quality, this oddity happens with the 'x 
>> +2' command.
>>
>> 	This doesn't happen to all of the points, only some - and not necc.  
>> the edge figures.
>>
>> 	Is there anyway i can control this?
>>     
>
>
> I think you are seeing a rasterization effect.  Both on screen and in a
> bitmap format you are essentially turning on a single pixel at a time.
> The locations you are giving do not necessarily correspond to an exact
> pixel location (bigpoints are in 1/72 inches, but your screen might have
> a resolution of 96 ppi) so you just get the nearest pixel to that
> location.  So the gap you specify of two bigpoints sometimes comes out
> as 2 pixels, sometimes as 1 pixel (for example).
>
> For comparison, try running your code on a PDF (or other vector format)
> device;  the result is much more what you are expecting I think.
>
> Paul
>
>
>   
>> 	Thanks
>> 	Saptarshi
>>
>> Saptarshi Guha | sapsi at pobox.com | http://www.stat.purdue.edu/~sguha
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>     
>
>



From Mark.Leeds at morganstanley.com  Tue Dec  5 21:42:21 2006
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Tue, 5 Dec 2006 15:42:21 -0500
Subject: [R] stat question - not R question so ignore if not interested
Message-ID: <D3AEEDA31E57474B840BEBC25A8A8344B643E1@NYWEXMB23.msad.ms.com>

If do a scattrplot of data ( x and y ) and there are two clouds of
points. One cloud is in the left
bottom corner of the plot and the other cloud is in the upper right.

If I fit a regression line to this data ( or equivalently , calculate a
correlation ), then obviously, it is going to seem like
x and y are related because a line has to be connected between the 2
clouds. But, there must be a regression assumption that
is violated here because if the regressions are done separately on each
cloud, then there really isn't
a relationship between x and y. I was just wondering 1) what assumption
in regression is being violated in
the first case or 2) possibly if the regression is valid and the results
just have some different interpreation ? 
Thanks.

 
Mark
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}



From carmei3 at web.de  Tue Dec  5 21:48:20 2006
From: carmei3 at web.de (Carmen Meier)
Date: Tue, 05 Dec 2006 21:48:20 +0100
Subject: [R] bind  data.frames seperately
Message-ID: <4575DB14.5050705@web.de>

Hi to all,

I would like to bind data1 and data2 (both are coming from an Excel 
sheet) but only the data rows
using rbind will cause double names and value.
but I need only add the data.rows and the rest of the names and values 
should be NA

value.1=c("a","b","c","d",5:54)          # building similar data frame 
like from excel
for (i in 5:54) value.1[i] <- NA            #only to simulate the NAs 
for the example
value.2=c(1:54)
for (i in 5:54) value.2[i] <- NA

data1<-data.frame(names=value.1, value=value.2, 
data.row.1=c(1:54),data.row.2=c(1:54))

value.1=c("a","b","c","d",5:69)
for (i in 5:69) value.1[i] <- NA
value.2=c(1:69)
for (i in 5:69) value.2[i] <- NA

data2<-data.frame(names=value.1, value.2, 
data.row.1=c(1:69),data.row.2=c(1:69))

By the way: Why are the NAs from name are changing from NA to <NA> after 
the data.frame command?

Thank you for your help

Carmen



From lourdes.pena at gmail.com  Tue Dec  5 21:54:44 2006
From: lourdes.pena at gmail.com (=?ISO-8859-1?Q?Lourdes_Pe=F1a_Castillo?=)
Date: Tue, 5 Dec 2006 15:54:44 -0500
Subject: [R] Font size x-axis in plotMeans not affected by cex...
Message-ID: <1c759b150612051254o1275982ercccc959114279f59@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061205/be822242/attachment-0004.pl 

From p.murrell at auckland.ac.nz  Tue Dec  5 21:58:40 2006
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 06 Dec 2006 09:58:40 +1300
Subject: [R] A question on grid - grid.points not spaced properly
In-Reply-To: <4575D61A.6060408@pobox.com>
References: <B5D33109-7452-4115-B779-6A74ED3374BD@pobox.com>
	<4575D28B.7030804@stat.auckland.ac.nz> <4575D61A.6060408@pobox.com>
Message-ID: <4575DD80.3070600@stat.auckland.ac.nz>

Hi


Saptarshi Guha wrote:
> Hi,
>     Thank you for the explanation. I have one further question - should 
> i wish to plot to the screen, which units (apart from bigpts) for exact 
> plotting.
> Essentially i wish to create my own plotting character - hence the 
> pch="." and the surrounding dots - so it would be nice if i could place 
> the surrounding dots exactly.


R graphics is a vector system rather than a raster system, which means
that all locations and dimensions are effectively on an infinite
resolution device.  There are no "pixels" to refer to.  So you are
already placing the dots exactly.

When graphics are rendered by a specific device, there will be rounding
if the device is raster (e.g., screen).  So not all devices can render
your dots exactly.

If you know that your plotting character will only be rendered on a
raster device, "native" coordinates in the top-level grid viewport refer
(approximately) to pixels, e.g.,

> grid.newpage()
> grid.rect(x=0, y=0, width=10, height=10, default.units="native",
            just=c("left", "bottom"))
> grid.rect(x=10, y=10, width=10, height=10, default.units="native",
            just=c("left", "bottom"))
> grid.rect(x=20, y=20, width=10, height=10, default.units="native",
            just=c("left", "bottom"))

but you can still get rounding problems and these coordinates are not
available in any other grid viewport.

In other words, you cannot predict exactly which pixels will get turned
on when you draw something on screen with R graphics.

If it's any consolation, this is true of the predefined plotting symbols
too!  (do all the plusses look the same on screen?)

plot(1:10, 1:10, pch=3)

Paul

p.s.  An exercise for the reader:  why do all of these plusses look the
same on screen?

plot(1:10, 1:10, pch="+")


>     Thank you
>     Saptarshi Guha
> 
> 
> Paul Murrell wrote:
>> Hi
>>
>>
>> Saptarshi Guha wrote:
>>   
>>> Hello,
>>> 	How can i 'fix' the following output.
>>>
>>> 	v=viewport(x=216/2, y=216/2,w=216, h=216,default.units = "bigpts")
>>> 	pushViewport(v)
>>> 	x=c(119,130,140,151)
>>> 	y=c(124,124,124,124)
>>> 	grid.points(x,y,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
>>> 	grid.points(x-2,y,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
>>> 	grid.points(x+2,y,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
>>> 	grid.points(x,y-2,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
>>> 	grid.points(x,y+2,size=unit(1,"bigpts"),default.units="bigpts",pch=".")
>>>
>>>
>>> 	One would expect to get a 4 figures composed of 5 dots each  - 2  
>>> vertically spaced and 2 horizontally spaced symmetrically around the  
>>> center dot.
>>> 	However i seem to get odd results - e.g on Quartz(OS X) output, the  
>>> last command, places the dot bang next to the center dot.
>>> 	On 'jpeg' output with higest quality, this oddity happens with the 'x 
>>> +2' command.
>>>
>>> 	This doesn't happen to all of the points, only some - and not necc.  
>>> the edge figures.
>>>
>>> 	Is there anyway i can control this?
>>>     
>>
>> I think you are seeing a rasterization effect.  Both on screen and in a
>> bitmap format you are essentially turning on a single pixel at a time.
>> The locations you are giving do not necessarily correspond to an exact
>> pixel location (bigpoints are in 1/72 inches, but your screen might have
>> a resolution of 96 ppi) so you just get the nearest pixel to that
>> location.  So the gap you specify of two bigpoints sometimes comes out
>> as 2 pixels, sometimes as 1 pixel (for example).
>>
>> For comparison, try running your code on a PDF (or other vector format)
>> device;  the result is much more what you are expecting I think.
>>
>> Paul
>>
>>
>>   
>>> 	Thanks
>>> 	Saptarshi
>>>
>>> Saptarshi Guha | sapsi at pobox.com | http://www.stat.purdue.edu/~sguha
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>     
>>   

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From yoni.schamroth at compile-inc.com  Tue Dec  5 22:03:37 2006
From: yoni.schamroth at compile-inc.com (Yoni Schamroth)
Date: Tue, 05 Dec 2006 23:03:37 +0200
Subject: [R] double precision
Message-ID: <03ae01c718b0$d57b3240$2b00a8c0@yonixp>

Hi,

I am attempting to query a data frame from a mysql database.
One of the variables is a unique identification number ("numeric") 18 digits
long.
I am struggling to retrieve this variable exactly without any rounding.

The function I am using is sqlQuery(), with an ODBC connection.
Querying directly results in the double being rounded towards the end (eg
6527600583317876352 instead of 6527600583317876380)

Is there anyway of preserving the "numeric" class of the variable and it
precision without converting it to a factor? Is the double stored as a
64-bit integer?

I have attempted to use the 'dec' as well as 'as.is = TRUE', both
automatically convert it to a factor which I am trying to avoid. 

Any advice or assistance would be greatly appreciated.

Thanks

Yoni Schamroth
Director of Research
MediaBoost LTD
Tel. +972-3-5333033 (ext. 105)
Fax.?+972-3-5480617
Mob.?+972-52-3422204
yoni.schamroth at compile-inc.com



From Philip.Leifeld at uni-konstanz.de  Tue Dec  5 22:30:02 2006
From: Philip.Leifeld at uni-konstanz.de (Philip Leifeld)
Date: Tue, 05 Dec 2006 22:30:02 +0100
Subject: [R] incidence and adjacency matrix conversion
Message-ID: <4575E4DA.6040808@uni-konstanz.de>

Dear all,

how can I convert an m x n incidence matrix into an m x m adjacency 
matrix or an n x n adjacency matrix? The current matrix contains binary 
data, hence the new matrix would contain counts of common occurrences.

Thank you for your help.

Phil



From Roger.Bivand at nhh.no  Tue Dec  5 22:31:54 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 5 Dec 2006 22:31:54 +0100 (CET)
Subject: [R] double precision
In-Reply-To: <03ae01c718b0$d57b3240$2b00a8c0@yonixp>
Message-ID: <Pine.LNX.4.44.0612052226540.11260-100000@reclus.nhh.no>

On Tue, 5 Dec 2006, Yoni Schamroth wrote:

> Hi,
> 
> I am attempting to query a data frame from a mysql database.
> One of the variables is a unique identification number ("numeric") 18 digits
> long.
> I am struggling to retrieve this variable exactly without any rounding.

Read it as a character - a double is a double:

> x <- 6527600583317876352
> y <- 6527600583317876380
> all.equal(x,y)
[1] TRUE
> storage.mode(x)
[1] "double"

and why they are equal is a FAQ (only ~16 digits in a double). Integer is
4-byte. Since they are IDs, not to be used for math, leave them as
character strings - which they are, like telephone numbers.


> 
> The function I am using is sqlQuery(), with an ODBC connection.
> Querying directly results in the double being rounded towards the end (eg
> 6527600583317876352 instead of 6527600583317876380)
> 
> Is there anyway of preserving the "numeric" class of the variable and it
> precision without converting it to a factor? Is the double stored as a
> 64-bit integer?
> 
> I have attempted to use the 'dec' as well as 'as.is = TRUE', both
> automatically convert it to a factor which I am trying to avoid. 
> 
> Any advice or assistance would be greatly appreciated.
> 
> Thanks
> 
> Yoni Schamroth
> Director of Research
> MediaBoost LTD
> Tel. +972-3-5333033 (ext. 105)
> Fax.?+972-3-5480617
> Mob.?+972-52-3422204
> yoni.schamroth at compile-inc.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From greenboy21 at gmail.com  Tue Dec  5 22:34:00 2006
From: greenboy21 at gmail.com (Xu Yuan)
Date: Tue, 5 Dec 2006 16:34:00 -0500
Subject: [R] test of spatial dependence??
Message-ID: <e00347d90612051334m75926168k7bfc427948564e68@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061205/82356f79/attachment-0004.pl 

From rmh at temple.edu  Tue Dec  5 22:34:31 2006
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue,  5 Dec 2006 16:34:31 -0500 (EST)
Subject: [R] stat question - not R question so ignore if not interested
Message-ID: <20061205163431.BOW67668@po-d.temple.edu>

The missing piece is why there are two clusters.  There is
most likely a two-level factor distinguishing the groups
that was not included in the model.  It might not even have
been measured and now you need to find it.

Rich



From baron at psych.upenn.edu  Tue Dec  5 22:44:54 2006
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Tue, 5 Dec 2006 16:44:54 -0500
Subject: [R] stat question - not R question so ignore if not interested
In-Reply-To: <20061205163431.BOW67668@po-d.temple.edu>
References: <20061205163431.BOW67668@po-d.temple.edu>
Message-ID: <20061205214454.GA23329@psych.upenn.edu>

A classic example used by my colleague Paul Rozin (when he
teaches Psych 1) is to compute the correlation between height
and number of shoes owned, in the class.  Shorter students own
more shoes.  But ...

On 12/05/06 16:34, Richard M. Heiberger wrote:
> The missing piece is why there are two clusters.  There is
> most likely a two-level factor distinguishing the groups
> that was not included in the model.  It might not even have
> been measured and now you need to find it.
> 
> Rich

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)



From backer at psych.uib.no  Tue Dec  5 22:55:20 2006
From: backer at psych.uib.no (Tom Backer Johnsen)
Date: Tue, 05 Dec 2006 22:55:20 +0100
Subject: [R] Calling R functions in Delphi
In-Reply-To: <OF8297EA9F.BF3D2E95-ON8525723B.006CF166-8525723B.006F38D0@abtassoc.com>
References: <OF8297EA9F.BF3D2E95-ON8525723B.006CF166-8525723B.006F38D0@abtassoc.com>
Message-ID: <4575EAC8.8040903@psych.uib.no>

Anna Belova wrote:
> Hellp Tom,
> 
> Thank you so much!
> 
> Several people have helped by pointing us to using R as a COM server.  This
> is an exciting functionality, but unfortunately we are afraid we can't use
> it in this project.
> 
> I really appreciate your thought and your time.

The solution I suggested was not using R as a COM server, but calling 
R directly in a thread.  If you are using Delphi at all it should 
work.  So, I consider the suggestion to be good.

Besides, considering where your mail originates (a corporation), you 
might consider that I deserve a fee.  Do you want a bank account 
number?  Now, that might be difficult, considering that US bank 
systems are quite primitive by European standards, but nevertheless ...

Tom
> 
> Regards,
> Anna
> -----------------------------------------
> Anna Belova
> Abt Associates Inc.
> 4800 Montgomery Ln, St 600
> Bethesda, MD-20814
> phone: 301-347-5304
> fax: 301-652-7530
> http://www.abtassociates.com/environment
> 
> 
> 
>                                                                            
>              Tom Backer                                                    
>              Johnsen                                                       
>              <backer at psych.uib                                          To 
>              .no>                      Anna Belova                         
>                                        <Anna_Belova at abtassoc.com>          
>              12/05/2006 12:36                                           cc 
>              PM                        r-help at stat.math.ethz.ch            
>                                                                    Subject 
>                                        Re: [R] Calling R functions in      
>                                        Delphi                              
>                                                                            
>                                                                            
>                                                                            
>                                                                            
>                                                                            
>                                                                            
> 
> 
> 
> 
> Anna Belova wrote:
>> Hello All,
>>
>> We would like to call quantile() function from the R-package STATS in a
>> Delphi program. If this is possible, could anyone provide us with an
>> example?
> 
> It is possible, and in principle simple.  The essentials:  (1) Write a
> file containing the something like a script in R with whatever
> commands. (2) Start a process involving the execution of R with a
> command line containing two arguments, the name of the command file
> and the file where you want the output (results) to be. (3) wait for
> the process to stop.  So, here is a function (returns true if
> everyhing worked OK) that does that:
> 
> function StartRAndWait (CommandLine : string) : Boolean;
> var
>     Proc_info: TProcessInformation;
>     Startinfo: TStartupInfo;
>     ExitCode: longword;
>     CreateOK : Boolean;
> begin
>     Result := False;
> 
>     { Initialize the structures }
> 
>     FillChar(proc_info, sizeof (TProcessInformation), #0);
>     FillChar(startinfo, sizeof (TStartupInfo), #0);
>     Startinfo.cb := sizeof (TStartupInfo);
>     Startinfo.dwFlags := STARTF_USESHOWWINDOW or STARTF_USESTDHANDLES;
>     Startinfo.wShowWindow := SW_HIDE;
> 
>     { Attempt to create the process. If successful wait for it to end}
> 
>     CreateOK := CreateProcess(Nil, PChar('R.exe ' + CommandLine), nil,
>        nil,False, CREATE_NEW_PROCESS_GROUP+NORMAL_PRIORITY_CLASS, nil,
>        nil, StartInfo, proc_info);
>     if (CreateOK) then begin
>        WaitForSingleObject (proc_info.hProcess, INFINITE);
>        GetExitCodeProcess(proc_info.hProcess, ExitCode);
>        Result := True
>        end;
>     CloseHandle(proc_info.hThread);
>     CloseHandle(proc_info.hProcess);
>     end;
> 
> The argument for the procedure (CommandLine) is a string, created by a
> statement like:
> 
> Command := 'CMD BATCH ' + CommandFileName + ' ' + TempFileName;
> 
> where CommandFileName is the name of the file with the script, and
> TempFileName is the name of the text file containing the output. The
> procedure is fairly lowlevel, but it worked for me using Delphi 7.  I
> do not remember how I managed to put this together (probably a mix of
> help from the R and Delphi lists), so please do not ask questions
> about the finer details.
> 
> Tom
> 
> 
> +----------------------------------------------------------------+
> | Tom Backer Johnsen, Psychometrics Unit,  Faculty of Psychology |
> | University of Bergen, Christies gt. 12, N-5015 Bergen,  NORWAY |
> | Tel : +47-5558-9185                        Fax : +47-5558-9879 |
> | Email : backer at psych.uib.no    URL : http://www.galton.uib.no/ |
> +----------------------------------------------------------------+
> 
> 
> -----------------------------------------
> This message may contain privileged and confidential infor...{{dropped}}



From dfarrar at newrvana.com  Tue Dec  5 23:05:38 2006
From: dfarrar at newrvana.com (David Farrar)
Date: Tue, 5 Dec 2006 14:05:38 -0800 (PST)
Subject: [R] test of spatial dependence?? - ask an ecologist?
In-Reply-To: <e00347d90612051334m75926168k7bfc427948564e68@mail.gmail.com>
Message-ID: <493883.80128.qm@web802.biz.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061205/2c2f23ca/attachment-0004.pl 

From HDoran at air.org  Tue Dec  5 23:08:27 2006
From: HDoran at air.org (Doran, Harold)
Date: Tue, 5 Dec 2006 17:08:27 -0500
Subject: [R] Comparing posterior and likelihood estimates for proportions
	(off topic)
Message-ID: <2323A6D37908A847A7C32F1E3662C80E6B0830@dc1ex01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061205/f3511aa8/attachment-0004.pl 

From mothsailor at googlemail.com  Tue Dec  5 23:17:54 2006
From: mothsailor at googlemail.com (David Barron)
Date: Tue, 5 Dec 2006 22:17:54 +0000
Subject: [R] incidence and adjacency matrix conversion
In-Reply-To: <4575E4DA.6040808@uni-konstanz.de>
References: <4575E4DA.6040808@uni-konstanz.de>
Message-ID: <815b70590612051417ga74d036g12822d94e7ec8189@mail.gmail.com>

I think you can do this using the network package.  Look at the
as.network.matrix and as.matrix.network functions, for example.

On 05/12/06, Philip Leifeld <Philip.Leifeld at uni-konstanz.de> wrote:
> Dear all,
>
> how can I convert an m x n incidence matrix into an m x m adjacency
> matrix or an n x n adjacency matrix? The current matrix contains binary
> data, hence the new matrix would contain counts of common occurrences.
>
> Thank you for your help.
>
> Phil
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP



From kubovy at virginia.edu  Tue Dec  5 23:21:00 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Tue, 5 Dec 2006 17:21:00 -0500
Subject: [R] stat question - not R question so ignore if not interested
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A8344B643E1@NYWEXMB23.msad.ms.com>
References: <D3AEEDA31E57474B840BEBC25A8A8344B643E1@NYWEXMB23.msad.ms.com>
Message-ID: <55001AFD-B540-4539-AC68-B367F29223DF@virginia.edu>

On Dec 5, 2006, at 3:42 PM, Leeds, Mark ((IED)) wrote:

> If do a scattrplot of data ( x and y ) and there are two clouds of
> points. One cloud is in the left
> bottom corner of the plot and the other cloud is in the upper right.
>
> If I fit a regression line to this data ( or equivalently ,  
> calculate a
> correlation ), then obviously, it is going to seem like
> x and y are related because a line has to be connected between the 2
> clouds. But, there must be a regression assumption that
> is violated here because if the regressions are done separately on  
> each
> cloud, then there really isn't
> a relationship between x and y. I was just wondering 1) what  
> assumption
> in regression is being violated in
> the first case or 2) possibly if the regression is valid and the  
> results
> just have some different interpreation ?

One needs only to look at diagnostic plots:

Suppose
set.seed(2)
xy <- data.frame(y = c(rnorm(300), rnorm(300, 5)), x = c(rnorm(300),  
rnorm(300, 5)))
op <- par(mfrow = c(2,2))
plot(lm(y ~ x, xy))
par(op)

The model does not fit well because the residuals aren't flat as a  
function of fit and because homoscedasticity is violated.

When this happens we might try a different approach:
require(sm)
xy.sm <- sm.regression(xy$x, xy$y)

Whenever there's a big discrepancy between an OLS fit and a robust  
one, we should not pursue the OLS one w/o reinterpretation, which  
others have discussed in their replies.
_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/



From sapsi at pobox.com  Tue Dec  5 23:33:49 2006
From: sapsi at pobox.com (Saptarshi Guha)
Date: Tue, 5 Dec 2006 17:33:49 -0500
Subject: [R] A question on grid - grid.points not spaced properly
In-Reply-To: <4575DD80.3070600@stat.auckland.ac.nz>
References: <B5D33109-7452-4115-B779-6A74ED3374BD@pobox.com>
	<4575D28B.7030804@stat.auckland.ac.nz> <4575D61A.6060408@pobox.com>
	<4575DD80.3070600@stat.auckland.ac.nz>
Message-ID: <1F833E81-6B62-4204-AF40-0AB806195DC3@pobox.com>

Hi,
	Thank you for the detailed explanation.
> If it's any consolation, this is true of the predefined plotting  
> symbols

True. Its good to be aware of the structure of R graphics. Have been  
planning to pick up the Grid book.

> p.s.  An exercise for the reader:  why do all of these plusses look  
> the
> same on screen?
>
> plot(1:10, 1:10, pch="+")

Is this because we are getting the system/device font renderer(e.g  
the postscript renderer, OS X font renderer)
to draw the character "+" so the widths/height will be exactly  
measure, but R is drawing itself when doing pch=3 ?

Thanks
Saptarshi

Saptarshi Guha | sapsi at pobox.com | http://www.stat.purdue.edu/~sguha


On Dec 5, 2006, at 3:58 PM, Paul Murrell wrote:

> Hi
>
>
> Saptarshi Guha wrote:
>> Hi,
>>     Thank you for the explanation. I have one further question -  
>> should
>> i wish to plot to the screen, which units (apart from bigpts) for  
>> exact
>> plotting.
>> Essentially i wish to create my own plotting character - hence the
>> pch="." and the surrounding dots - so it would be nice if i could  
>> place
>> the surrounding dots exactly.
>
>
> R graphics is a vector system rather than a raster system, which means
> that all locations and dimensions are effectively on an infinite
> resolution device.  There are no "pixels" to refer to.  So you are
> already placing the dots exactly.
>
> When graphics are rendered by a specific device, there will be  
> rounding
> if the device is raster (e.g., screen).  So not all devices can render
> your dots exactly.
>
> If you know that your plotting character will only be rendered on a
> raster device, "native" coordinates in the top-level grid viewport  
> refer
> (approximately) to pixels, e.g.,
>
>> grid.newpage()
>> grid.rect(x=0, y=0, width=10, height=10, default.units="native",
>             just=c("left", "bottom"))
>> grid.rect(x=10, y=10, width=10, height=10, default.units="native",
>             just=c("left", "bottom"))
>> grid.rect(x=20, y=20, width=10, height=10, default.units="native",
>             just=c("left", "bottom"))
>
> but you can still get rounding problems and these coordinates are not
> available in any other grid viewport.
>
> In other words, you cannot predict exactly which pixels will get  
> turned
> on when you draw something on screen with R graphics.
>
> If it's any consolation, this is true of the predefined plotting  
> symbols
> too!  (do all the plusses look the same on screen?)
>
> plot(1:10, 1:10, pch=3)
>
> Paul
>
> p.s.  An exercise for the reader:  why do all of these plusses look  
> the
> same on screen?
>
> plot(1:10, 1:10, pch="+")
>
>
>>     Thank you
>>     Saptarshi Guha
>>
>>
>> Paul Murrell wrote:
>>> Hi
>>>
>>>
>>> Saptarshi Guha wrote:
>>>
>>>> Hello,
>>>> 	How can i 'fix' the following output.
>>>>
>>>> 	v=viewport(x=216/2, y=216/2,w=216, h=216,default.units = "bigpts")
>>>> 	pushViewport(v)
>>>> 	x=c(119,130,140,151)
>>>> 	y=c(124,124,124,124)
>>>> 	grid.points(x,y,size=unit 
>>>> (1,"bigpts"),default.units="bigpts",pch=".")
>>>> 	grid.points(x-2,y,size=unit 
>>>> (1,"bigpts"),default.units="bigpts",pch=".")
>>>> 	grid.points(x+2,y,size=unit 
>>>> (1,"bigpts"),default.units="bigpts",pch=".")
>>>> 	grid.points(x,y-2,size=unit 
>>>> (1,"bigpts"),default.units="bigpts",pch=".")
>>>> 	grid.points(x,y+2,size=unit 
>>>> (1,"bigpts"),default.units="bigpts",pch=".")
>>>>
>>>>
>>>> 	One would expect to get a 4 figures composed of 5 dots each  - 2
>>>> vertically spaced and 2 horizontally spaced symmetrically around  
>>>> the
>>>> center dot.
>>>> 	However i seem to get odd results - e.g on Quartz(OS X) output,  
>>>> the
>>>> last command, places the dot bang next to the center dot.
>>>> 	On 'jpeg' output with higest quality, this oddity happens with  
>>>> the 'x
>>>> +2' command.
>>>>
>>>> 	This doesn't happen to all of the points, only some - and not  
>>>> necc.
>>>> the edge figures.
>>>>
>>>> 	Is there anyway i can control this?
>>>>
>>>
>>> I think you are seeing a rasterization effect.  Both on screen  
>>> and in a
>>> bitmap format you are essentially turning on a single pixel at a  
>>> time.
>>> The locations you are giving do not necessarily correspond to an  
>>> exact
>>> pixel location (bigpoints are in 1/72 inches, but your screen  
>>> might have
>>> a resolution of 96 ppi) so you just get the nearest pixel to that
>>> location.  So the gap you specify of two bigpoints sometimes  
>>> comes out
>>> as 2 pixels, sometimes as 1 pixel (for example).
>>>
>>> For comparison, try running your code on a PDF (or other vector  
>>> format)
>>> device;  the result is much more what you are expecting I think.
>>>
>>> Paul
>>>
>>>
>>>
>>>> 	Thanks
>>>> 	Saptarshi
>>>>
>>>> Saptarshi Guha | sapsi at pobox.com | http://www.stat.purdue.edu/ 
>>>> ~sguha
>>>>
>>>> ______________________________________________
>>>> R-help at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/ 
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/



From p.murrell at auckland.ac.nz  Tue Dec  5 23:41:41 2006
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 06 Dec 2006 11:41:41 +1300
Subject: [R] A question on grid - grid.points not spaced properly
In-Reply-To: <1F833E81-6B62-4204-AF40-0AB806195DC3@pobox.com>
References: <B5D33109-7452-4115-B779-6A74ED3374BD@pobox.com>
	<4575D28B.7030804@stat.auckland.ac.nz> <4575D61A.6060408@pobox.com>
	<4575DD80.3070600@stat.auckland.ac.nz>
	<1F833E81-6B62-4204-AF40-0AB806195DC3@pobox.com>
Message-ID: <4575F5A5.8090804@stat.auckland.ac.nz>

Hi


Saptarshi Guha wrote:
> Hi,
> 	Thank you for the detailed explanation.
>> If it's any consolation, this is true of the predefined plotting  
>> symbols
> 
> True. Its good to be aware of the structure of R graphics. Have been  
> planning to pick up the Grid book.
> 
>> p.s.  An exercise for the reader:  why do all of these plusses look  
>> the
>> same on screen?
>>
>> plot(1:10, 1:10, pch="+")
> 
> Is this because we are getting the system/device font renderer(e.g  
> the postscript renderer, OS X font renderer)
> to draw the character "+" so the widths/height will be exactly  
> measure, but R is drawing itself when doing pch=3 ?


Yep.  (Slightly more accurately, it's the difference between getting the
system to draw a couple of lines and getting the system to draw a
character from a font.)  Which suggests that if you want to design a new
plotting symbol that looks good everywhere, all you have to do is design
a new font! :)

Paul


> Thanks
> Saptarshi
> 
> Saptarshi Guha | sapsi at pobox.com | http://www.stat.purdue.edu/~sguha
> 
> 
> On Dec 5, 2006, at 3:58 PM, Paul Murrell wrote:
> 
>> Hi
>>
>>
>> Saptarshi Guha wrote:
>>> Hi,
>>>     Thank you for the explanation. I have one further question -  
>>> should
>>> i wish to plot to the screen, which units (apart from bigpts) for  
>>> exact
>>> plotting.
>>> Essentially i wish to create my own plotting character - hence the
>>> pch="." and the surrounding dots - so it would be nice if i could  
>>> place
>>> the surrounding dots exactly.
>>
>> R graphics is a vector system rather than a raster system, which means
>> that all locations and dimensions are effectively on an infinite
>> resolution device.  There are no "pixels" to refer to.  So you are
>> already placing the dots exactly.
>>
>> When graphics are rendered by a specific device, there will be  
>> rounding
>> if the device is raster (e.g., screen).  So not all devices can render
>> your dots exactly.
>>
>> If you know that your plotting character will only be rendered on a
>> raster device, "native" coordinates in the top-level grid viewport  
>> refer
>> (approximately) to pixels, e.g.,
>>
>>> grid.newpage()
>>> grid.rect(x=0, y=0, width=10, height=10, default.units="native",
>>             just=c("left", "bottom"))
>>> grid.rect(x=10, y=10, width=10, height=10, default.units="native",
>>             just=c("left", "bottom"))
>>> grid.rect(x=20, y=20, width=10, height=10, default.units="native",
>>             just=c("left", "bottom"))
>>
>> but you can still get rounding problems and these coordinates are not
>> available in any other grid viewport.
>>
>> In other words, you cannot predict exactly which pixels will get  
>> turned
>> on when you draw something on screen with R graphics.
>>
>> If it's any consolation, this is true of the predefined plotting  
>> symbols
>> too!  (do all the plusses look the same on screen?)
>>
>> plot(1:10, 1:10, pch=3)
>>
>> Paul
>>
>> p.s.  An exercise for the reader:  why do all of these plusses look  
>> the
>> same on screen?
>>
>> plot(1:10, 1:10, pch="+")
>>
>>
>>>     Thank you
>>>     Saptarshi Guha
>>>
>>>
>>> Paul Murrell wrote:
>>>> Hi
>>>>
>>>>
>>>> Saptarshi Guha wrote:
>>>>
>>>>> Hello,
>>>>> 	How can i 'fix' the following output.
>>>>>
>>>>> 	v=viewport(x=216/2, y=216/2,w=216, h=216,default.units = "bigpts")
>>>>> 	pushViewport(v)
>>>>> 	x=c(119,130,140,151)
>>>>> 	y=c(124,124,124,124)
>>>>> 	grid.points(x,y,size=unit 
>>>>> (1,"bigpts"),default.units="bigpts",pch=".")
>>>>> 	grid.points(x-2,y,size=unit 
>>>>> (1,"bigpts"),default.units="bigpts",pch=".")
>>>>> 	grid.points(x+2,y,size=unit 
>>>>> (1,"bigpts"),default.units="bigpts",pch=".")
>>>>> 	grid.points(x,y-2,size=unit 
>>>>> (1,"bigpts"),default.units="bigpts",pch=".")
>>>>> 	grid.points(x,y+2,size=unit 
>>>>> (1,"bigpts"),default.units="bigpts",pch=".")
>>>>>
>>>>>
>>>>> 	One would expect to get a 4 figures composed of 5 dots each  - 2
>>>>> vertically spaced and 2 horizontally spaced symmetrically around  
>>>>> the
>>>>> center dot.
>>>>> 	However i seem to get odd results - e.g on Quartz(OS X) output,  
>>>>> the
>>>>> last command, places the dot bang next to the center dot.
>>>>> 	On 'jpeg' output with higest quality, this oddity happens with  
>>>>> the 'x
>>>>> +2' command.
>>>>>
>>>>> 	This doesn't happen to all of the points, only some - and not  
>>>>> necc.
>>>>> the edge figures.
>>>>>
>>>>> 	Is there anyway i can control this?
>>>>>
>>>> I think you are seeing a rasterization effect.  Both on screen  
>>>> and in a
>>>> bitmap format you are essentially turning on a single pixel at a  
>>>> time.
>>>> The locations you are giving do not necessarily correspond to an  
>>>> exact
>>>> pixel location (bigpoints are in 1/72 inches, but your screen  
>>>> might have
>>>> a resolution of 96 ppi) so you just get the nearest pixel to that
>>>> location.  So the gap you specify of two bigpoints sometimes  
>>>> comes out
>>>> as 2 pixels, sometimes as 1 pixel (for example).
>>>>
>>>> For comparison, try running your code on a PDF (or other vector  
>>>> format)
>>>> device;  the result is much more what you are expecting I think.
>>>>
>>>> Paul
>>>>
>>>>
>>>>
>>>>> 	Thanks
>>>>> 	Saptarshi
>>>>>
>>>>> Saptarshi Guha | sapsi at pobox.com | http://www.stat.purdue.edu/ 
>>>>> ~sguha
>>>>>
>>>>> ______________________________________________
>>>>> R-help at stat.math.ethz.ch mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/ 
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>> -- 
>> Dr Paul Murrell
>> Department of Statistics
>> The University of Auckland
>> Private Bag 92019
>> Auckland
>> New Zealand
>> 64 9 3737599 x85392
>> paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From jm.blanco at ualberta.ca  Tue Dec  5 23:42:12 2006
From: jm.blanco at ualberta.ca (=?ISO-8859-1?Q?Jos=E9-Manuel_Blanco-Moreno?=)
Date: Tue, 05 Dec 2006 15:42:12 -0700
Subject: [R] Wombling
Message-ID: <4575F5C4.9040009@ualberta.ca>

Hello,
    Does anyone know if there is any package in R to perform wombling 
(sensu Barbujani et al. 1990) or a related method? RSiteSearch only 
gives 2 results with "wombling" and I am not aware of any other name for 
the method. Some weeks ago there was a related question on the list but 
there was no response... I acknowledge that programming it wouldn't be 
so difficult (only needs to apply solve() over a grid), but I am not a 
good programmer and I am a little bit concerned with efficiency.

Thank you for any information,

-- 
Jos?-Manuel Blanco-Moreno

-----------------------------------
Department of Biological Sciences
University of Alberta

CW-405 Biological Sciences Bldg.
Edmonton, Alberta, Canada
T6G 2E9
-----------------------------------

Phone: (1) 780 492 3289
Fax: (1) 780 492 9457



From elichten at biomail.ucsd.edu  Tue Dec  5 23:49:03 2006
From: elichten at biomail.ucsd.edu (Elinor Lichtenberg)
Date: Tue, 5 Dec 2006 14:49:03 -0800 (PST)
Subject: [R] Spearman correlation ties and discrepancies
Message-ID: <Pine.GSO.4.64.0612051421230.5859@biomail>

Hi.  I am currently trying to run some Spearman correlations, and have 
encountered two issues.

1) When using cor.test() with a variable that includes ties, I get the 
"Cannot compute exact p-values with ties" error.  I have read that this 
function now uses an asymptotic formula that allows for ties, so do not 
understand why I am getting this error.  (I am running version 2.4.0.)

I read the following data in from a CSV file:
species,ecoldom,ecolrank,abundance,persistence,behavdom,behavrank,aggrlevel
Fv,0.108333333,6,2.5,0,0.351351351,5,0.12195122
Mq,0.114583333,5,2,0,0.167539267,5,0.287878788
N,0.125,3,0.5,0,0.285714286,5,0.333333333
S,0.116792929,4,11,0.125,0.684027778,2,0.723214286
Th,0.164737654,1,22.5,0.875,0.717948718,2,1.614285714
Ts,0.131944444,2,3,0,0.712328767,2,1.068965517

I then use:
cor.test(ecoldom, persistence, method="spearman")


2) I have tried using spearman.test() as an alternative to cor.test() and 
get different p-values (although the rho values are the same).  Here is an 
example:

> spearman(ecoldom, abundance)
       rho
0.4857143
> spearman.test(ecoldom, abundance)
   Rsquare         F       df1       df2    pvalue         n
0.2359184 1.2350427 1.0000000 4.0000000 0.3287230 6.0000000
> cor.test(ecoldom, abundance, method="spearman")

 	Spearman's rank correlation rho

data:  ecoldom and abundance
S = 18, p-value = 0.3556
alternative hypothesis: true rho is not equal to 0
sample estimates:
       rho
0.4857143

Is this difference due to the two functions using different algorithms?

Thanks
Elinor Lichtenberg



From gunter.berton at gene.com  Tue Dec  5 23:06:00 2006
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 5 Dec 2006 14:06:00 -0800
Subject: [R] stat question - not R question so ignore if not interested
In-Reply-To: <20061205214454.GA23329@psych.upenn.edu>
Message-ID: <004e01c718b9$8d001e00$4d908980@gne.windows.gene.com>

... But of course this is always the question underlying all empirical -- or
maybe even scientific -- analysis: is there some other perhaps more
fundamental variable out there that I'm missing that would explain what's
"really" going on?

I clearly remember George Box commenting on this in his Monday night beer
and statistics sessions: after you're done and perhaps have written up and
presented your (intricate!) analysis, you're always worried that someone
might come along and say, "Well, did you consider...?"

Cheers,
Bert 

Bert Gunter
Genentech Nonclinical Statistics
South San Francisco, CA 94404


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jonathan Baron
Sent: Tuesday, December 05, 2006 1:45 PM
To: Richard M. Heiberger
Cc: r-help at stat.math.ethz.ch; C. Park; Leeds,Mark (IED)
Subject: Re: [R] stat question - not R question so ignore if not interested

A classic example used by my colleague Paul Rozin (when he
teaches Psych 1) is to compute the correlation between height
and number of shoes owned, in the class.  Shorter students own
more shoes.  But ...

On 12/05/06 16:34, Richard M. Heiberger wrote:
> The missing piece is why there are two clusters.  There is
> most likely a two-level factor distinguishing the groups
> that was not included in the model.  It might not even have
> been measured and now you need to find it.
> 
> Rich

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ohitsabid at yahoo.com  Tue Dec  5 23:12:14 2006
From: ohitsabid at yahoo.com (Syed Abid Hussaini)
Date: Tue, 5 Dec 2006 14:12:14 -0800 (PST)
Subject: [R] Show date on graph
In-Reply-To: <mailman.12.1165316406.12259.r-help@stat.math.ethz.ch>
Message-ID: <102478.1832.qm@web35614.mail.mud.yahoo.com>

I have a character "2006-11-06" which was originally scanned from a csv file. This character is
named date. I now use mtext (date) on a plot and i see strange cluttered characters instead of
2006-11-06. I tried many ways but i dont know whats going on. Then for testing i made an
artificial character d <- ("2006-11-06") and now when i do mtext (d) it shows up on the plot.
While both date and d return "2006-11-06" only d shows up on the plots. Any help would be appreciated.


 
____________________________________________________________________________________
Have a burning question?  
Go to www.Answers.yahoo.com and get answers from real people who know.



From Sinnwell.Jason at mayo.edu  Tue Dec  5 22:34:10 2006
From: Sinnwell.Jason at mayo.edu (Sinnwell, Jason P.)
Date: Tue, 5 Dec 2006 15:34:10 -0600
Subject: [R] [R-pkgs] New package: ibdreg
Message-ID: <EDFDBF4E8E9AE049A9BB81801F493041494374@msgebe21.mfad.mfroot.org>

Dear useRs,

Please find the new package ibdreg version 0.1.0 on CRAN.

The package contains a method for analysis of genetic linkage 
with covariates by regression methods that use identity by descent 
(IBD) sharing probabilities for relative pairs.  The methods 
account for correlations of IBD statistics for 
relative pairs within the same pedigree.

The reference is:

Schaid DJ, Sinnwell JP, Thibodeau SN.  Testing Genetic
Linkage with Relative Pairs and Covariates by
Quasi-Likelihood Score Statistics. Submitted.

Cheers, 
Jason Sinnwell

============================             
 Mayo Clinic, Rochester     
 Division of Biostatistics  
 ph:  507.284.3270          
 fax: 507.284.9542          
 sinnwell[at]mayo.edu

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From p.dalgaard at biostat.ku.dk  Wed Dec  6 01:56:14 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 06 Dec 2006 01:56:14 +0100
Subject: [R] Spearman correlation ties and discrepancies
In-Reply-To: <Pine.GSO.4.64.0612051421230.5859@biomail>
References: <Pine.GSO.4.64.0612051421230.5859@biomail>
Message-ID: <4576152E.7000002@biostat.ku.dk>

Elinor Lichtenberg wrote:
> Hi.  I am currently trying to run some Spearman correlations, and have 
> encountered two issues.
>
> 1) When using cor.test() with a variable that includes ties, I get the 
> "Cannot compute exact p-values with ties" error.  I have read that this 
> function now uses an asymptotic formula that allows for ties, so do not 
> understand why I am getting this error.  (I am running version 2.4.0.)
>
>   
Because asymptotic formulas are not exact!

> I read the following data in from a CSV file:
> species,ecoldom,ecolrank,abundance,persistence,behavdom,behavrank,aggrlevel
> Fv,0.108333333,6,2.5,0,0.351351351,5,0.12195122
> Mq,0.114583333,5,2,0,0.167539267,5,0.287878788
> N,0.125,3,0.5,0,0.285714286,5,0.333333333
> S,0.116792929,4,11,0.125,0.684027778,2,0.723214286
> Th,0.164737654,1,22.5,0.875,0.717948718,2,1.614285714
> Ts,0.131944444,2,3,0,0.712328767,2,1.068965517
>
> I then use:
> cor.test(ecoldom, persistence, method="spearman")
>
>
> 2) I have tried using spearman.test() as an alternative to cor.test() and 
> get different p-values (although the rho values are the same).  Here is an 
> example:
>
>   
>> spearman(ecoldom, abundance)
>>     
>        rho
> 0.4857143
>   
>> spearman.test(ecoldom, abundance)
>>     
>    Rsquare         F       df1       df2    pvalue         n
> 0.2359184 1.2350427 1.0000000 4.0000000 0.3287230 6.0000000
>   
>> cor.test(ecoldom, abundance, method="spearman")
>>     
>
>  	Spearman's rank correlation rho
>
> data:  ecoldom and abundance
> S = 18, p-value = 0.3556
> alternative hypothesis: true rho is not equal to 0
> sample estimates:
>        rho
> 0.4857143
>
> Is this difference due to the two functions using different algorithms?
>
>   

What spearman.test? It is not standard, and you're not telling us which 
package it came from. Offhand I would guess that cor.test is using the 
exact formula and spearman.test an asymptotic one. You can force 
cor.test to use the asymptotic formula by setting exact=FALSE (oops, 
there's a documentation buglet there).



From kubovy at virginia.edu  Wed Dec  6 02:59:51 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Tue, 5 Dec 2006 20:59:51 -0500
Subject: [R] Help with response CIs for lme
In-Reply-To: <45751653.5020107@pdf.com>
References: <DBB3E82B-75EE-447C-8BC0-6425D8B5E8FD@virginia.edu>
	<45751653.5020107@pdf.com>
Message-ID: <C182F346-8D14-4C5A-BE18-FA5E7A8D64A2@virginia.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061205/bdc75791/attachment-0004.pl 

From nicolas.mazziotta at swing.be  Wed Dec  6 08:16:21 2006
From: nicolas.mazziotta at swing.be (Nicolas Mazziotta)
Date: Wed, 6 Dec 2006 08:16:21 +0100
Subject: [R] vcd package, assoc()
Message-ID: <200612060816.22207.nicolas.mazziotta@swing.be>

Hello,

I am trying to use the extended assocplot() function: assoc(), from vcd 
package. Trouble is that it cannot even run its own examples on my 
installation. I get this output:

$> example(assoc)

assoc> data("HairEyeColor")

assoc> (x <- margin.table(HairEyeColor, c(1, 2)))
       Eye
Hair    Brown Blue Hazel Green
  Black    68   20    15     5
  Brown   119   84    54    29
  Red      26   17    14    14
  Blond     7   94    10    16

assoc> assoc(x)
Error in unit.c(mar[4], unit(1, "null"), mar[2], legend_width) :
        It is invalid to combine unit objects with other types


Version info output by citation("vcd") is 1.0-1.

Any idea about what's going wrong? 

Thanks for any help.

-- 
Nicolas Mazziotta

The contents of this e-mail, including any attachments, are confidential and 
are intended for the sole use of the individual or entity to which it is 
addressed. Any distribution, copying or dissemination of this message is 
expected to conform to all legal stipulations governing the use of 
information.



From ligges at statistik.uni-dortmund.de  Wed Dec  6 08:23:33 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 06 Dec 2006 08:23:33 +0100
Subject: [R] put tutorials in CRAN
In-Reply-To: <4575D0D5.8090701@telecom.com.co>
References: <4575D0D5.8090701@telecom.com.co>
Message-ID: <45766FF5.3000605@statistik.uni-dortmund.de>



Mario Alfonso Morales Rivera wrote:
> Hi everyone.
> I made an R tutorial in Spanish and would like to know how to put it in CRAN so
> everyone can have access to it, does anyone know how to do this? Are there any
> steps, rules, etc. to follow to make this tutorial available through CRAN?

Please go to http://cran.r-project.org/ and read the section "Submitting 
to CRAN" at the bottom of that page.
Many thanks in advance for your contribution!

Best,
Uwe Ligges

> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ligges at statistik.uni-dortmund.de  Wed Dec  6 08:26:56 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 06 Dec 2006 08:26:56 +0100
Subject: [R] vcd package, assoc()
In-Reply-To: <200612060816.22207.nicolas.mazziotta@swing.be>
References: <200612060816.22207.nicolas.mazziotta@swing.be>
Message-ID: <457670C0.9010500@statistik.uni-dortmund.de>



Nicolas Mazziotta wrote:
> Hello,
> 
> I am trying to use the extended assocplot() function: assoc(), from vcd 
> package. Trouble is that it cannot even run its own examples on my 
> installation. I get this output:
> 
> $> example(assoc)
> 
> assoc> data("HairEyeColor")
> 
> assoc> (x <- margin.table(HairEyeColor, c(1, 2)))
>        Eye
> Hair    Brown Blue Hazel Green
>   Black    68   20    15     5
>   Brown   119   84    54    29
>   Red      26   17    14    14
>   Blond     7   94    10    16
> 
> assoc> assoc(x)
> Error in unit.c(mar[4], unit(1, "null"), mar[2], legend_width) :
>         It is invalid to combine unit objects with other types
> 
> 
> Version info output by citation("vcd") is 1.0-1.
> 
> Any idea about what's going wrong? 

Works for me. Which version of R is this? R-2.4.0, R-patched or R-devel?

Uwe Ligges

> Thanks for any help.
>



From nicolas.mazziotta at swing.be  Wed Dec  6 08:34:04 2006
From: nicolas.mazziotta at swing.be (Nicolas Mazziotta)
Date: Wed, 6 Dec 2006 08:34:04 +0100
Subject: [R] vcd package, assoc()
In-Reply-To: <457670C0.9010500@statistik.uni-dortmund.de>
References: <200612060816.22207.nicolas.mazziotta@swing.be>
	<457670C0.9010500@statistik.uni-dortmund.de>
Message-ID: <200612060834.04925.nicolas.mazziotta@swing.be>

R version is R 2.2.1 (kubuntu dapper package)

Le mercredi 06 d?cembre 2006 08:26, Uwe Ligges a ?crit?:
> > Error in unit.c(mar[4], unit(1, "null"), mar[2], legend_width) :
> >         It is invalid to combine unit objects with other types
> Works for me. Which version of R is this? R-2.4.0, R-patched or R-devel?
>

-- 
Nicolas Mazziotta

The contents of this e-mail, including any attachments, are confidential and 
are intended for the sole use of the individual or entity to which it is 
addressed. Any distribution, copying or dissemination of this message is 
expected to conform to all legal stipulations governing the use of 
information.



From ligges at statistik.uni-dortmund.de  Wed Dec  6 08:34:41 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 06 Dec 2006 08:34:41 +0100
Subject: [R] Show date on graph
In-Reply-To: <102478.1832.qm@web35614.mail.mud.yahoo.com>
References: <102478.1832.qm@web35614.mail.mud.yahoo.com>
Message-ID: <45767291.1000306@statistik.uni-dortmund.de>

Syed Abid Hussaini wrote:
> I have a character "2006-11-06" which was originally scanned from a csv file. This character is
> named date. I now use mtext (date) on a plot and i see strange cluttered characters instead of

Then it is not a character but some date/time object such as a POSIXlt 
class. mtext() does not have an appropriate method for it. If this date 
is x, just plot as.character(x) instead.

Uwe Ligges


> 2006-11-06. I tried many ways but i dont know whats going on. Then for testing i made an
> artificial character d <- ("2006-11-06") and now when i do mtext (d) it shows up on the plot.
> While both date and d return "2006-11-06" only d shows up on the plots. Any help would be appreciated.
> 
> 
>  
> ____________________________________________________________________________________
> Have a burning question?  
> Go to www.Answers.yahoo.com and get answers from real people who know.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ligges at statistik.uni-dortmund.de  Wed Dec  6 08:42:49 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 06 Dec 2006 08:42:49 +0100
Subject: [R] vcd package, assoc()
In-Reply-To: <200612060834.04925.nicolas.mazziotta@swing.be>
References: <200612060816.22207.nicolas.mazziotta@swing.be>	<457670C0.9010500@statistik.uni-dortmund.de>
	<200612060834.04925.nicolas.mazziotta@swing.be>
Message-ID: <45767479.9020100@statistik.uni-dortmund.de>



Nicolas Mazziotta wrote:
> R version is R 2.2.1 (kubuntu dapper package)

So update your outdated version of R at first!
At least to R-2.4.0, even better to R-2.4.0 patched which will soon 
become R-2.4.1.

Anyway, David, the vcd maintainer, is certainly going to fix the 
DESCRIPTION's "Depends" entry.

Best,
Uwe Ligges


> Le mercredi 06 d?cembre 2006 08:26, Uwe Ligges a ?crit :
>>> Error in unit.c(mar[4], unit(1, "null"), mar[2], legend_width) :
>>>         It is invalid to combine unit objects with other types
>> Works for me. Which version of R is this? R-2.4.0, R-patched or R-devel?
>>
>



From jim at bitwrit.com.au  Wed Dec  6 08:49:51 2006
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 06 Dec 2006 18:49:51 +1100
Subject: [R] Show date on graph
In-Reply-To: <102478.1832.qm@web35614.mail.mud.yahoo.com>
References: <102478.1832.qm@web35614.mail.mud.yahoo.com>
Message-ID: <4576761F.4010504@bitwrit.com.au>

Syed Abid Hussaini wrote:
> I have a character "2006-11-06" which was originally scanned from a csv file. This character is
> named date. I now use mtext (date) on a plot and i see strange cluttered characters instead of
> 2006-11-06. I tried many ways but i dont know whats going on. Then for testing i made an
> artificial character d <- ("2006-11-06") and now when i do mtext (d) it shows up on the plot.
> While both date and d return "2006-11-06" only d shows up on the plots. Any help would be appreciated.
> 
> 
>  
Hi Syed,
If you try to display something with mtext, it expects the object to be 
a character string. When you just print the object, the print method 
works out that it is a date object and silently converts it to a 
character string to be printed. Try this:

mtext(format(date,"%Y-%m-%d"),...)

Also note that it isn't a great idea to use "date" to name a variable. 
Even though you can now get away with it, using the same name for two 
things (a function and a variable) often comes back to haunt one.

Jim



From nicolas.mazziotta at swing.be  Wed Dec  6 09:14:10 2006
From: nicolas.mazziotta at swing.be (Nicolas Mazziotta)
Date: Wed, 6 Dec 2006 09:14:10 +0100
Subject: [R] SOLVED kubuntu repository (was vcd package, assoc())
In-Reply-To: <45767479.9020100@statistik.uni-dortmund.de>
References: <200612060816.22207.nicolas.mazziotta@swing.be>
	<200612060834.04925.nicolas.mazziotta@swing.be>
	<45767479.9020100@statistik.uni-dortmund.de>
Message-ID: <200612060914.10497.nicolas.mazziotta@swing.be>

Thanks for your help. And sorry for not having noticed that kubuntu dapper 
packages were very outdated.

This might help other kubuntu dapper users:

- add this line to /etc/apt/sources.list

deb http://cran.R-project.org/bin/linux/ubuntu dapper/

- uninstall all previously installed r packages added via apt (don't 
just "update" them);

- update your installation by reinstalling the packages.

vcd package now works.

Le mercredi 06 d?cembre 2006 08:42, vous avez ?crit?:
> Nicolas Mazziotta wrote:
> > R version is R 2.2.1 (kubuntu dapper package)
>
> So update your outdated version of R at first!
> At least to R-2.4.0, even better to R-2.4.0 patched which will soon
> become R-2.4.1.
>
> Anyway, David, the vcd maintainer, is certainly going to fix the
> DESCRIPTION's "Depends" entry.
>
> Best,
> Uwe Ligges
>
> > Le mercredi 06 d?cembre 2006 08:26, Uwe Ligges a ?crit :
> >>> Error in unit.c(mar[4], unit(1, "null"), mar[2], legend_width) :
> >>>         It is invalid to combine unit objects with other types
> >>
> >> Works for me. Which version of R is this? R-2.4.0, R-patched or R-devel?

-- 
Nicolas Mazziotta

The contents of this e-mail, including any attachments, are confidential and 
are intended for the sole use of the individual or entity to which it is 
addressed. Any distribution, copying or dissemination of this message is 
expected to conform to all legal stipulations governing the use of 
information.



From ohitsabid at yahoo.com  Wed Dec  6 09:15:12 2006
From: ohitsabid at yahoo.com (Syed Abid Hussaini)
Date: Wed, 6 Dec 2006 00:15:12 -0800 (PST)
Subject: [R] Show date on graph
In-Reply-To: <45767291.1000306@statistik.uni-dortmund.de>
Message-ID: <632648.82612.qm@web35611.mail.mud.yahoo.com>

Thanks Jim and Uwe!!

  Both methods work for me. 

Methods:

1. plot as.character(x) 

2. mtext(format(date,"%Y-%m-%d"),...)



From justin_bem at yahoo.fr  Wed Dec  6 09:30:08 2006
From: justin_bem at yahoo.fr (justin bem)
Date: Wed, 6 Dec 2006 08:30:08 +0000 (GMT)
Subject: [R] Re : stat question - not R question so ignore if not interested
Message-ID: <20061206083008.42178.qmail@web23006.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061206/6678f4af/attachment-0004.pl 

From vicctorr at gmail.com  Wed Dec  6 09:33:31 2006
From: vicctorr at gmail.com (victor)
Date: Wed, 06 Dec 2006 09:33:31 +0100
Subject: [R] intercept value in lme
Message-ID: <4576805B.6060403@gmail.com>

Dear all,

I've got a problem in fitting multilevel model in lme. I don't know to 
much about that but suspect that something is wrong with my model.

I'm trying to fit:

m1<-lme(X~Y,~1|group,data=data,na.action=na.exclude,method="ML")
m2<-lme(X~Y+Z,~1|group,data=data,na.action=na.exclude,method="ML")

where:
X - dependent var. measured on a scale ranging from -25 to 0
Y - level 1 variable
Z - level 1 variable

In m1 the intercept value is equal -3, in m2 (that is after adding Lev 2 
var.) is equal +16.

What can be wrong with my variables? Is this possible that intercept 
value exceeds scale?

Best regards,

victor



From petr.pikal at precheza.cz  Wed Dec  6 09:49:20 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 06 Dec 2006 09:49:20 +0100
Subject: [R] if(){} else{}
In-Reply-To: <20061205193932.GK70252@ms.unimelb.edu.au>
References: <OFB59BA846.2882DD87-ONC125723B.00530366-C125723B.00557106@de.ibm.com>
Message-ID: <45769220.29222.280C32@localhost>

Hi

a little bit quicker solution is based on subsetting and a fact that 
logical vector can be treated as numeric with FALSE=0 and TRUE = 1

Plant<-sample(c(NA,1), 100000, replace=T);
Value1<-rnorm(Plant);
Value2<-rnorm(Plant);
mat<-data.frame(Plant=Plant,Value1=Value1,Value2=Value2)

> system.time(mat$Plant1<-c("B","A")[is.na(mat$Plant)+1])
[1] 0.03 0.02 0.05   NA   NA
> system.time(mat$Plant2 <- ifelse(is.na(mat$Plant), "A", "B"))
[1] 0.28 0.01 0.30   NA   NA
> with(mat, all.equal(Plant1, Plant2))
[1] TRUE

HTH
Petr



On 6 Dec 2006 at 6:39, Andrew Robinson wrote:

Date sent:      	Wed, 6 Dec 2006 06:39:32 +1100
From:           	Andrew Robinson <A.Robinson at ms.unimelb.edu.au>
To:             	Hans-Juergen Eickelmann <EICKELMA at de.ibm.com>
Copies to:      	r-help at stat.math.ethz.ch
Subject:        	Re: [R] if(){} else{}

> Hi Hans,
> 
> try this ...
> 
> mat <- as.data.frame(cbind(Plant,Value1,Value2))
> 
> mat$Plant1 <- ifelse(is.na(mat$Plant), "A", "B")
> 
> Cheers
> 
> Andrew
> 
> 
> On Tue, Dec 05, 2006 at 04:33:15PM +0100, Hans-Juergen Eickelmann
> wrote: > > Dear R-community, > > my data set looks like 'mat' below. >
> > Plant<-c(NA,1,1,1,NA,NA,NA,NA,NA,1); > Value1<-rnorm(1:10); >
> Value2<-rnorm(1:10); > mat<-cbind(Plant,Value1,Value2); > I receive
> data from two different sites. > One site is identified by an interger
> number, the other site has no data in > column Plant=NA. > > My pb: >
> > I'm trying to assign labels "A" or "B" to these 2 sites into a new
> column, > but my if(){} else{} statement fails with the following
> statement: > Error in if (is.na(mat$Plant == TRUE)) { : >        
> argument is of length zero > >
> if(is.na(mat$Plant==TRUE)){mat$Plant1="A"} else{mat$Plant1="B"}; > > I
> looked through the avail doc and R-help for some time but wasn't able
> to > fix the pb. > > Thx Hans > >
> ______________________________________________ >
> R-help at stat.math.ethz.ch mailing list >
> https://stat.ethz.ch/mailman/listinfo/r-help > PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html > and
> provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Andrew Robinson  
> Department of Mathematics and Statistics            Tel:
> +61-3-8344-9763 University of Melbourne, VIC 3010 Australia        
> Fax: +61-3-8344-4599 http://www.ms.unimelb.edu.au/~andrewpr
> http://blogs.mbs.edu/fishing-in-the-bay/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

Petr Pikal
petr.pikal at precheza.cz



From dfarrar at newrvana.com  Wed Dec  6 01:29:05 2006
From: dfarrar at newrvana.com (David Farrar)
Date: Tue, 5 Dec 2006 16:29:05 -0800 (PST)
Subject: [R] stat question - not R question so ignore if not interested
In-Reply-To: <004e01c718b9$8d001e00$4d908980@gne.windows.gene.com>
Message-ID: <610524.62624.qm@web808.biz.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061205/a01dda1e/attachment-0004.pl 

From petr.pikal at precheza.cz  Wed Dec  6 10:27:57 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 06 Dec 2006 10:27:57 +0100
Subject: [R] summaryBy(): Is it the best option?
In-Reply-To: <682431.28939.qm@web23007.mail.ird.yahoo.com>
Message-ID: <45769B2D.14339.4B6573@localhost>

Hi

I did not see any answer yet so I try. You can use aggregate, by or 
sapply.

Something like
aggregate(soc6a[, your columns], list(hh=hh), sum, na.rm=T)
by(soc6a[, your columns], hh, sum, na.rm=T)
sapply(split(soc6a[, your columns], hh), sum, na.rm=T)

But you have to check speed gain by yourself.

HTH
Petr



On 5 Dec 2006 at 1:30, Werner Wernersen wrote:

Date sent:      	Tue, 5 Dec 2006 01:30:50 +0100 (CET)
From:           	Werner Wernersen <pensterfuzzer at yahoo.de>
To:             	r-help at stat.math.ethz.ch
Subject:        	[R] summaryBy(): Is it the best option?

> Hi,
> 
> since I have quite large tables and the processing
> takes quite a while I am
> curious if I can improve the performance of this
> aggregation somehow: At the 
> moment I am using summaryBy from the doBy package
> under R 2.4.0, Win2K.
> 
> summaryBy(soc_s6aq5 + soc_s6aq7 + soc_s6aq9 +
> soc_s6aq11 ~ hh + 
> comgroup,soc6a,postfix=c("","","",""),FUN=sum,
> na.rm=T)
> 
> The data.frame has 124100 rows and 13 cols.
> 
> Thanks for any hints!
> 
> Werner
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

Petr Pikal
petr.pikal at precheza.cz



From scionforbai at gmail.com  Wed Dec  6 10:56:27 2006
From: scionforbai at gmail.com (Scionforbai)
Date: Wed, 6 Dec 2006 10:56:27 +0100
Subject: [R] test of spatial dependence??
In-Reply-To: <e00347d90612051334m75926168k7bfc427948564e68@mail.gmail.com>
References: <e00347d90612051334m75926168k7bfc427948564e68@mail.gmail.com>
Message-ID: <e9ee1f0a0612060156l4b4ec645q9a142f5bc3c29144@mail.gmail.com>

> How to test the spatial dependence of a column of data? for example
[...]
> All I have is 25 numbers.

If you don't have coordinates of your data, as I understand here,
there's nothing you can do, of course ...
If you have coordinates, you should compute the variogram -and/or the
spatial covariance- of your data and look if they are meaningful.
Hint: read a book about geostatistics.

> PS, could someone confirm that "spatial dependence" is equivalent to
> "spatial correlation" or "spatial autocorrelation" or not.

So, to me there is a light difference, but it's really "for advanced
users", and maybe questionable.

Bye.



From torleif at stryn.net  Wed Dec  6 11:02:31 2006
From: torleif at stryn.net (Torleif Markussen Lunde)
Date: Wed, 06 Dec 2006 11:02:31 +0100
Subject: [R] Prediction and plottiong of several effects against response
 with GAM (mgcv)
In-Reply-To: <mailman.13.1165316406.12259.r-help@stat.math.ethz.ch>
References: <mailman.13.1165316406.12259.r-help@stat.math.ethz.ch>
Message-ID: <45769537.8040105@stryn.net>

Hi

Using GAM (mgcv) I want plots of x against y. Using predict.gam when 
there is only one effect x works fine. However, when i want to make 
plots of several x agains y. Can this be done? I have tried using 
model.gam$model$x2 in pred.2.resp whitout making it work.

Thanks
Torleif


Below is how I have done it:


ss <- alder==1&CPUE>0
x1 <- altitude[ss]
x2 <- start[ss]
x3 <- bunndyp[ss]
x4 <- longitude[ss]
y <- CPUE[ss]
mean.y <- mean(y)

model.gam <- gam(y~ s(x2, bs="cc") + s(x1, bs="ts") + 
s(I(x3^.5),bs="ts"), poisson, gamma=1.4)

# to plot on the response scale
val.for.pred <- data.frame(x2=seq(min(x2), max(x2), length.out=222), 
x1=seq(min(x1), max(x1), length.out=222), x3=seq(min(x3), max(x3), 
length.out=222))
pred.2.resp <- predict.gam(model.gam, val.for.pred ,type="response",
se.fit=TRUE)
lower.band <- pred.2.resp$fit - 2*pred.2.resp$se.fit
upper.band <- pred.2.resp$fit + 2*pred.2.resp$se.fit
pred.2.resp <- data.frame(val.for.pred, pred.2.resp, lower.band,
upper.band)

# same thing on term scale
pred.2.term <- predict.gam(model.gam, val.for.pred ,type="terms",
se.fit=TRUE)
lower.band <- pred.2.term$fit - 2*pred.2.term$se.fit
upper.band <- pred.2.term$fit + 2*pred.2.term$se.fit
pred.2.term <- data.frame(val.for.pred, pred.2.term, lower.band,
upper.band)

# it is easier to compare two plots instead of looking at these two 
data.frames
plot(model.gam, residuals=T, pch=1, cex=0.7)
abline(h=0)

#To plot x2 against y
plot(y~x2, col=grey(0.8), pch=19, cex=0.2)
lines(fit~x2, col="blue", data=pred.2.resp)
lines(lower.band~x2, col="red", lty=2, data=pred.2.resp)
lines(upper.band~x2, col="red", lty=2, data=pred.2.resp)
abline(h=coef(model.gam)[1],lty=5,col=grey(0.35))



From david.meyer at wu-wien.ac.at  Wed Dec  6 11:17:40 2006
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Wed, 06 Dec 2006 11:17:40 +0100
Subject: [R] vcd package, assoc()
In-Reply-To: <45767479.9020100@statistik.uni-dortmund.de>
References: <200612060816.22207.nicolas.mazziotta@swing.be>	<457670C0.9010500@statistik.uni-dortmund.de>
	<200612060834.04925.nicolas.mazziotta@swing.be>
	<45767479.9020100@statistik.uni-dortmund.de>
Message-ID: <457698C4.6030506@wu-wien.ac.at>

Yes, he will :)

Thanks, Uwe!

David

Uwe Ligges schrieb:
>
>
> Nicolas Mazziotta wrote:
>> R version is R 2.2.1 (kubuntu dapper package)
>
> So update your outdated version of R at first!
> At least to R-2.4.0, even better to R-2.4.0 patched which will soon 
> become R-2.4.1.
>
> Anyway, David, the vcd maintainer, is certainly going to fix the 
> DESCRIPTION's "Depends" entry.
>
> Best,
> Uwe Ligges
>
>
>> Le mercredi 06 d?cembre 2006 08:26, Uwe Ligges a ?crit :
>>>> Error in unit.c(mar[4], unit(1, "null"), mar[2], legend_width) :
>>>>         It is invalid to combine unit objects with other types
>>> Works for me. Which version of R is this? R-2.4.0, R-patched or 
>>> R-devel?
>>>
>>
>
>
>

-- 
Dr. David Meyer
Department of Information Systems and Operations

Vienna University of Economics and Business Administration
Augasse 2-6, A-1090 Wien, Austria, Europe
Tel: +43-1-313 36 4393
Fax: +43-1-313 36 90 4393 
HP:  http://wi.wu-wien.ac.at/~meyer/



From lopatows at pasteur.fr  Wed Dec  6 12:06:46 2006
From: lopatows at pasteur.fr (Lulla OPATOWSKI)
Date: Wed, 6 Dec 2006 12:06:46 +0100
Subject: [R] Questions about regression with time-series
Message-ID: <98b6643e7354766bfa1c9869428ac3c1@pasteur.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061206/0c5da2b5/attachment-0004.pl 

From A.Robinson at ms.unimelb.edu.au  Wed Dec  6 12:17:01 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 6 Dec 2006 22:17:01 +1100
Subject: [R] intercept value in lme
In-Reply-To: <4576805B.6060403@gmail.com>
References: <4576805B.6060403@gmail.com>
Message-ID: <20061206111701.GC70252@ms.unimelb.edu.au>

Dear Victor,

this is a really difficult problem to intepret, let alone diagnose.
Please provide commented, minimal, self-contained, reproducible code
that will allow us to see what the problem is.

Cheers

Andrew

On Wed, Dec 06, 2006 at 09:33:31AM +0100, victor wrote:
> Dear all,
> 
> I've got a problem in fitting multilevel model in lme. I don't know to 
> much about that but suspect that something is wrong with my model.
> 
> I'm trying to fit:
> 
> m1<-lme(X~Y,~1|group,data=data,na.action=na.exclude,method="ML")
> m2<-lme(X~Y+Z,~1|group,data=data,na.action=na.exclude,method="ML")
> 
> where:
> X - dependent var. measured on a scale ranging from -25 to 0
> Y - level 1 variable
> Z - level 1 variable
> 
> In m1 the intercept value is equal -3, in m2 (that is after adding Lev 2 
> var.) is equal +16.
> 
> What can be wrong with my variables? Is this possible that intercept 
> value exceeds scale?
> 
> Best regards,
> 
> victor
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From john_d_mchenry at yahoo.com  Wed Dec  6 13:51:03 2006
From: john_d_mchenry at yahoo.com (John McHenry)
Date: Wed, 6 Dec 2006 04:51:03 -0800 (PST)
Subject: [R] Can anyone read a S-PLUS .dmp file for me?
Message-ID: <261185.50358.qm@web35404.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061206/37205358/attachment-0004.pl 

From HDoran at air.org  Wed Dec  6 13:57:24 2006
From: HDoran at air.org (Doran, Harold)
Date: Wed, 6 Dec 2006 07:57:24 -0500
Subject: [R] intercept value in lme
Message-ID: <2323A6D37908A847A7C32F1E3662C80E6B0839@dc1ex01.air.org>

As Andrew noted, you need to provide more information. But, what I see
is that your model assumes X is continuous but you say it is bounded,
-25 < X < 0 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of victor
> Sent: Wednesday, December 06, 2006 3:34 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] intercept value in lme
> 
> Dear all,
> 
> I've got a problem in fitting multilevel model in lme. I 
> don't know to much about that but suspect that something is 
> wrong with my model.
> 
> I'm trying to fit:
> 
> m1<-lme(X~Y,~1|group,data=data,na.action=na.exclude,method="ML")
> m2<-lme(X~Y+Z,~1|group,data=data,na.action=na.exclude,method="ML")
> 
> where:
> X - dependent var. measured on a scale ranging from -25 to 0 
> Y - level 1 variable Z - level 1 variable
> 
> In m1 the intercept value is equal -3, in m2 (that is after 
> adding Lev 2
> var.) is equal +16.
> 
> What can be wrong with my variables? Is this possible that 
> intercept value exceeds scale?
> 
> Best regards,
> 
> victor
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From milton_ruser at yahoo.com.br  Wed Dec  6 14:25:35 2006
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Wed, 6 Dec 2006 13:25:35 +0000 (GMT)
Subject: [R] test of spatial dependence?? - ask an ecologist?
In-Reply-To: <493883.80128.qm@web802.biz.mail.mud.yahoo.com>
Message-ID: <669380.66037.qm@web56609.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061206/1d02c456/attachment-0004.pl 

From ripley at stats.ox.ac.uk  Wed Dec  6 14:31:25 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 6 Dec 2006 13:31:25 +0000 (GMT)
Subject: [R] Can anyone read a S-PLUS .dmp file for me?
In-Reply-To: <261185.50358.qm@web35404.mail.mud.yahoo.com>
References: <261185.50358.qm@web35404.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0612061320010.13969@gannet.stats.ox.ac.uk>

On Wed, 6 Dec 2006, John McHenry wrote:

> Anyone?

Yes, I can read it, but what use is that to you?  Given that it is someone 
else's copyright work, I am not at liberty to redistribute a different 
version:

   hblm and associated programs Copyright 1995 by William DuMouchel.
   Permission is given for not-for-profit redistribution of the hblm
   programs so long as this About.hblm variable is included unmodified.
   Please report problems, failures and successes of this program to
   dumouchel at research.att.com

The reason for the error is that it appears to contain invalid S data 
frames.  (They are in invalid in R and in current S-PLUS, but they seems 
also to have been invalid in S3.  Restoring dumps used to be one way to 
create invalid objects, but many of the loopholes have been plugged in R.)

>
> John McHenry <john_d_mchenry at yahoo.com> wrote:    Hi WizaRds,
>
>  I tried reading the S-PLUS file
>
>  ftp://ftp.research.att.com/dist/bayes-meta/hblm.dmp
>
>  into R using
>
>  data.restore("hblm.dmp")
>
>  but I got an error:
>
>  Error in attributes(value) <- thelist[-match(c(".Data", ".Dim", ".Dimnames",  :
> row names must be 'character' or 'integer', not 'double'
> In addition: Warning message:
> NAs introduced by coercion
>
>  Does anyone know how to read this type of S-PLUS file into R? I am not familiar with it.
>  On http://cran.r-project.org/doc/manuals/R-data.html it is suggested that
>  "it is usually more reliable to dump the object(s) in S-PLUS and source the dumpfile in R"
>  See also, http://tolstoy.newcastle.edu.au/R/help/05/12/18209.html
>
>  I don't know how this file was created. Could someone with S-PLUS access please see if they can read it?
>
>  Thanks!
>
>  Jack.
>
> ---------------------------------
>
>
>
> ---------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Dec  6 14:34:02 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 6 Dec 2006 13:34:02 +0000 (GMT)
Subject: [R] Summary shows wrong maximum
In-Reply-To: <Pine.LNX.4.44.0612051459100.9703-100000@shoemaker.intra.astro.rug.nl>
References: <Pine.LNX.4.44.0612051459100.9703-100000@shoemaker.intra.astro.rug.nl>
Message-ID: <Pine.LNX.4.64.0612061216120.6922@gannet.stats.ox.ac.uk>

'Unfortunately' you give no credentials for your ex cathedra 
pronouncement.  E.g.

http://en.wikipedia.org/wiki/Significant_digits

says

The situation regarding trailing zero digits that fall to the left of the 
decimal place in a number with no digits provided that fall to the right 
of the decimal place is less clear, but these are typically not considered 
significant unless the decimal point is placed at the end of the number to 
indicate otherwise (e.g., "2000." versus "2000"). To make things more 
clear, trailing zeros are only recognized as significant figures if the 
number they are a part of has a decimal point. For example, 450 only has 
two sig figs, but 450. has three.

which directly contradicts you.  So this is at best a matter of opinion, 
and credentials do matter for opinions.


On Tue, 5 Dec 2006, Oliver Czoske wrote:

> On Mon, 4 Dec 2006, Uwe Ligges wrote:
>> Sebastian Spaeth wrote:
>>> Hi all,
>>> I have a list with a numerical column "cum_hardreuses". By coincidence I
>>> discovered this:
>>>
>>>> max(libs[,"cum_hardreuses"])
>>> [1] 1793
>>>
>>>> summary(libs[,"cum_hardreuses"])
>>>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>>        1       2       4      36      14    1790
>>>
>>> (note the max value of 1790) Ouch this is bad! Anything I can do to remedy
>>> this? Known bug?
>>
>> No, it's a feature! See ?summary: printing is done up to 3 significant
>> digits by default.
>
> Unfortunately, '1790' is printed with *four* significant digits, not
> three. The correct representation with three significant digits would have
> to employ scientific notation, 1.79e3.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From milton_ruser at yahoo.com.br  Wed Dec  6 14:38:35 2006
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Wed, 6 Dec 2006 13:38:35 +0000 (GMT)
Subject: [R] publicar tutorial en CRAN (translation)
In-Reply-To: <4575C7A1.9010707@telecom.com.co>
Message-ID: <456386.71709.qm@web56603.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061206/e5cca1bf/attachment-0004.pl 

From rolf at math.unb.ca  Wed Dec  6 15:09:05 2006
From: rolf at math.unb.ca (rolf at math.unb.ca)
Date: Wed, 6 Dec 2006 10:09:05 -0400 (AST)
Subject: [R] Summary shows wrong maximum
Message-ID: <200612061409.kB6E95V7020331@weisner.math.unb.ca>

Brian Ripley wrote:

> 'Unfortunately' you give no credentials for your ex cathedra
> pronouncement.  E.g.
> 
> http://en.wikipedia.org/wiki/Significant_digits
> 
> says
> 
> The situation regarding trailing zero digits that fall to the left of
> the decimal place in a number with no digits provided that fall to
> the right of the decimal place is less clear, but these are typically
> not considered significant unless the decimal point is placed at the
> end of the number to indicate otherwise (e.g., "2000." versus
> "2000"). To make things more clear, trailing zeros are only
> recognized as significant figures if the number they are a part of
> has a decimal point. For example, 450 only has two sig figs, but 450.
> has three.
> 
> which directly contradicts you.  So this is at best a matter of
> opinion, and credentials do matter for opinions.

	In the elementary statistics text ``Statistics for the Life
	Sciences'' (Samuels and Witmer, Prentice-Hall, 3rd ed.;
	fairly respectable credentials)  there is an appendix on
	Significant Digits which says, amongst other things:

	``How many significant digits are in the number 23000?
	When the number is expressed in this way --- in ordinary
	rather than scientific notation --- it is not really
	possible to tell how many significant digits it has.''

	....

	``Scientific notation removes the ambiguity.''

	Determining the significance of digits from the presence
	of a decimal point is perhaps a ``reasonable'' convention,
	but it is certainly not one that is widely practiced or
	understood.  Relying on an obscure convention is fraught
	with risk.

					cheers,

						Rolf Turner
						rolf at math.unb.ca



From shusong.jin at gmail.com  Wed Dec  6 15:25:28 2006
From: shusong.jin at gmail.com (Jin Shusong)
Date: Wed, 6 Dec 2006 22:25:28 +0800
Subject: [R] Usage of apply
Message-ID: <20061206142528.GA3339@smtp.gmail.com>

Dear R Users,
  
  Are there any documents on the usage of apply, tapply,
sapply so that I avoid explicit loops.  I found that these
three functions were quite hard to be understood.  Thank you
in advance.
-- 
               Jin



From ccleland at optonline.net  Wed Dec  6 15:53:55 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 06 Dec 2006 09:53:55 -0500
Subject: [R] Usage of apply
In-Reply-To: <20061206142528.GA3339@smtp.gmail.com>
References: <20061206142528.GA3339@smtp.gmail.com>
Message-ID: <4576D983.9080500@optonline.net>

Jin Shusong wrote:
> Dear R Users,
>   
>   Are there any documents on the usage of apply, tapply,
> sapply so that I avoid explicit loops.  I found that these
> three functions were quite hard to be understood.  Thank you
> in advance.

  If you have read the help pages for each and possibly even consulted
the reference on those help pages, you may need to elaborate on what
parts of these functions you don't understand.  You might also describe
a loop you are contemplating and ask how it might be replaced by one of
these functions.
  Here is a very simple example of a loop that could be avoided with one
of these functions:

> for(i in 1:4){print(mean(iris[,i]))}
[1] 5.843333
[1] 3.057333
[1] 3.758
[1] 1.199333

  Here is how you would do that with apply():

> apply(iris[,1:4], 2, mean)
Sepal.Length  Sepal.Width Petal.Length  Petal.Width
    5.843333     3.057333     3.758000     1.199333

  Even better in this particular case would be:

> colMeans(iris[,1:4])
Sepal.Length  Sepal.Width Petal.Length  Petal.Width
    5.843333     3.057333     3.758000     1.199333

  but you don't always want mean() or sum() as the function, so the
functions you mention above are more general than colMeans() and similar
functions.

> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894



From ggrothendieck at gmail.com  Wed Dec  6 16:19:23 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 6 Dec 2006 10:19:23 -0500
Subject: [R] Usage of apply
In-Reply-To: <20061206142528.GA3339@smtp.gmail.com>
References: <20061206142528.GA3339@smtp.gmail.com>
Message-ID: <971536df0612060719s7d2e95d1h73854bb11dacadd0@mail.gmail.com>

Google for
   contributed documentation CRAN
and in the first hit look through the several dozen tutorials there until you
find one that describes the apply functions in a way meaningful to you.
There is also some tutorial information on the relevant portion of this page:
   http://zoonek2.free.fr/UNIX/48_R/02.html


On 12/6/06, Jin Shusong <shusong.jin at gmail.com> wrote:
> Dear R Users,
>
>  Are there any documents on the usage of apply, tapply,
> sapply so that I avoid explicit loops.  I found that these
> three functions were quite hard to be understood.  Thank you
> in advance.
> --
>               Jin
>
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>



From erich.neuwirth at univie.ac.at  Wed Dec  6 16:34:50 2006
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Wed, 06 Dec 2006 16:34:50 +0100
Subject: [R] Calling R functions in Delphi
In-Reply-To: <4575AE08.8010304@psych.uib.no>
References: <OF3A5C81C3.5AEE7555-ON8525723A.0069E1BB-8525723A.006ADF77@abtassoc.com>
	<4575AE08.8010304@psych.uib.no>
Message-ID: <4576E31A.3020700@univie.ac.at>

R(D)COM available from CRAN (section Other) gives you R as a COM server.
If Delphi can act as a COM client (which I think is true), you can
access R directly from within your program without the need to write files.



> Anna Belova wrote:
>> Hello All,
>>
>> We would like to call quantile() function from the R-package STATS in a
>> Delphi program. If this is possible, could anyone provide us with an
>> example?


-- 
Erich Neuwirth, University of Vienna
Faculty of Computer Science
Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-39464 Fax: +43-1-4277-39459



From durduran at yahoo.com  Wed Dec  6 16:44:03 2006
From: durduran at yahoo.com (Turgut Durduran)
Date: Wed, 6 Dec 2006 07:44:03 -0800 (PST)
Subject: [R] Trellis Plot Labels
Message-ID: <20061206154403.74602.qmail@web31015.mail.mud.yahoo.com>



----- Original Message ----
From: Deepayan Sarkar <deepayan.sarkar at gmail.com>
To: Turgut Durduran <durduran at yahoo.com>
Cc: r-help at stat.math.ethz.ch
Sent: Saturday, November 18, 2006 4:28:03 PM
Subject: Re: Re: [R] Trellis Plot Labels

On 11/17/06, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
> On 11/17/06, Turgut Durduran <durduran at yahoo.com> wrote:
> > On 11/17/06, Turgut Durduran <durduran at yahoo.com> wrote:
> > >> Hello everyone,
> > >>
> > >> I am ploting a groupeddata object with formula:
> > >>
> > >> formula(mydatausegroup)
> > >> BF ~ HO | ID/Infar/Day
> > >>
> > >> Using this command:
> > >> plot(na.omit(mydatausegroup), displayLevel=2,layout=c(10,2),aspect=2)
> > >>
> > >>
> > >> This trellis plot does almost what I want and produces a 10x2 trellis plot, each panel is labeled
> > >> as ID/Infar where infarct is either 1 or 0. And in each panel, it plots BF vs HO for each Day. However, the "days" are labeled simply as "1,2,3,4" i>>nstead of their actual values (ranging from 1 to 8). This just mapped for each ID the "1 st measurement, 2nd measurement, 3rd measurement, 4th >>measurement".
> > >>
>
> This seems to be intended behaviour, and the responsible function is
> collapse.groupedData (which is not very transparent to me).
>
> > >> How can I get this trellis plot to use 8 different colors and label them correct?
>
> I don't see a documented way, so you'll probably need to modify
> collapse.groupedData

>>I should have added: it's of course fairly easy if you use xyplot directly.


Thank you very much for your detailed help. However, in xyplot, I am ending up a whole bunch of empty panels corresponding to missing days. For example if I did:
 xyplot(CBF~OB|Day*Inf*ID,data=na.omit(mydatausegroup))

I must be misunderstanding the xyplot again.

Turgut



From GPetris at uark.edu  Wed Dec  6 17:48:29 2006
From: GPetris at uark.edu (Giovanni Petris)
Date: Wed, 6 Dec 2006 10:48:29 -0600 (CST)
Subject: [R] Questions about regression with time-series
In-Reply-To: <98b6643e7354766bfa1c9869428ac3c1@pasteur.fr> (message from Lulla
	OPATOWSKI on Wed, 06 Dec 2006 12:06:46 +0100)
References: <98b6643e7354766bfa1c9869428ac3c1@pasteur.fr>
Message-ID: <200612061648.kB6GmTFC028326@definetti.ddns.uark.edu>


I think the function 'arima' can handle this, except for
the automatic evaluation of the ARMA orders.

Giovanni

> Date: Wed, 06 Dec 2006 12:06:46 +0100
> From: Lulla OPATOWSKI <lopatows at pasteur.fr>
> Sender: r-help-bounces at stat.math.ethz.ch
> Precedence: list
> 
> --===============0156932283==
> Content-Disposition: inline
> Content-Type: text/plain
> Content-Transfer-Encoding: quoted-printable
> Content-length: 954
> 
> Hi,
> 
> I am using 2 times series and I want to carry out a regression of Seri1=20
> by Serie2 using structured (autocorrelated) errors.
> (Equivalent to the autoreg function in SAS)
> 
> I found the function gls (package nlme) and I made:
> 
> gls_mens<-gls(mening_s_des~dataATB, correlation =3D corAR1())
> 
> My problem is that I don=92t want a AR(1) structure but ARMA(n,p) but the=
> =20
> execution fails :
> 
> gls_mens<-gls(mening_s_des~dataATB, correlation =3D corARMA(p=3D52))
> Error in "coef<-.corARMA"(`*tmp*`, value =3D c(11.2591629857661,=20
> 9.1821585359071,  :
> 	Coefficient matrix not invertible
> 
> This should be because most of the coefficients <52 are near to 0.
> 
> I am looking for a way to be able :
> - To evaluate automatically my ARMA structure (if it exists)
> - To specify manually the not null lags for my ARMA structure (as a=20
> vector for example)
> 
> Does anyone know about such functions?
> 
> Thank you for your help
> 
> 
> 	[[alternative text/enriched version deleted]]
> 
> 
> --===============0156932283==
> Content-Type: text/plain; charset="us-ascii"
> MIME-Version: 1.0
> Content-Transfer-Encoding: 7bit
> Content-Disposition: inline
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> --===============0156932283==--
> 
>



From GPetris at uark.edu  Wed Dec  6 17:50:48 2006
From: GPetris at uark.edu (Giovanni Petris)
Date: Wed, 6 Dec 2006 10:50:48 -0600 (CST)
Subject: [R] Comparing posterior and likelihood estimates for
 proportions	(off topic)
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E6B0830@dc1ex01.air.org>
	(HDoran@air.org)
References: <2323A6D37908A847A7C32F1E3662C80E6B0830@dc1ex01.air.org>
Message-ID: <200612061650.kB6GomOH028332@definetti.ddns.uark.edu>


You are not comparing estimates of the population proportion. 

Giovanni

> Date: Tue, 05 Dec 2006 17:08:27 -0500
> From: "Doran, Harold" <HDoran at air.org>
> Sender: r-help-bounces at stat.math.ethz.ch
> Precedence: list
> Thread-topic: Comparing posterior and likelihood estimates for proportions	(off
>  topic)
> Thread-index: AccYuQPSLwIrLya5T4ivem8lVU99aQ==
> 
> This question is slightly off topic, but I'll use R to try and make it
> as relevant as possible. I'm working on a problem where I want to
> compare estimates from a posterior distribution with a uniform prior
> with those obtained from a frequentist approach. Under these conditions
> the estimates should agree.
> 
> Specifically, I am asking the question, "What is the probability that
> the true proportion of students passing a test is 50% when the observed
> proportion for that school is only 38%?"
> 
> For my example, there are 100 students in the school and 38 of them
> passed an exam. For conjugacy, if we choose a beta prior, then posterior
> in this case is also a beta distribution. Now, I believe the a and b
> parameters for a beta with a uniform prior is a=1 and b=1, or 1/(1+1)
> 
> Here is my R code for the posterior with a flat prior
> 
> n <- 100 # Total number of individuals
> y <- 38  # Number of successes
> a <- 1   # Parameter 1 for Beta prior
> b <- 1   # Parameter 2 for Beta prior
> theta <- .38 # Proportion passing
> 
> pbeta(.50, a + y, b+n-y, lower.tail=FALSE)
> [1] 0.008253
> 
> Now, the binomial distribution gives
> 
> > dbinom(50, 100, .38)
> [1] 0.0040984
> 
> Obviously, the results don't agree. So, I'm wondering if I have 
> 
> A) made a computational error
> B) have an error in my assumption that the results should agree in this
> case
> 
> Thanks for any reactions
> Harold
> 
> Windows XP
> > version
>                _                           
> platform       i386-pc-mingw32             
> arch           i386                        
> os             mingw32                     
> system         i386, mingw32               
> status                                     
> major          2                           
> minor          4.0                         
> year           2006                        
> month          10                          
> day            03                          
> svn rev        39566                       
> language       R                           
> version.string R version 2.4.0 (2006-10-03)
> 
>  
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 

Giovanni Petris  <GPetris at uark.edu>
Associate Professor
Department of Mathematical Sciences
University of Arkansas - Fayetteville, AR 72701
Ph: (479) 575-6324, 575-8630 (fax)
http://definetti.uark.edu/~gpetris/



From efg at stowers-institute.org  Wed Dec  6 18:00:17 2006
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Wed, 6 Dec 2006 11:00:17 -0600
Subject: [R] Calling R functions in Delphi
References: <OF3A5C81C3.5AEE7555-ON8525723A.0069E1BB-8525723A.006ADF77@abtassoc.com>
	<4575AE08.8010304@psych.uib.no>
Message-ID: <el6sv8$tlp$1@sea.gmane.org>

Thanks for the great example, Tom.

"Tom Backer Johnsen" <backer at psych.uib.no> wrote in message 
news:4575AE08.8010304 at psych.uib.no...
> Anna Belova wrote:

>> We would like to call quantile() function from the R-package STATS in a
>> Delphi program. If this is possible, could anyone provide us with an
>> example?
>
> It is possible, and in principle simple.  The essentials:  (1) Write a
> file containing the something like a script in R with whatever
> commands. (2) Start a process involving the execution of R with a
> command line containing two arguments, the name of the command file
> and the file where you want the output (results) to be. (3) wait for
> the process to stop.  So, here is a function (returns true if
> everyhing worked OK) that does that:

. . .

>    CreateOK := CreateProcess(Nil, PChar('R.exe ' + CommandLine), nil,
>       nil,False, CREATE_NEW_PROCESS_GROUP+NORMAL_PRIORITY_CLASS, nil,
>       nil, StartInfo, proc_info);

I had to give the full path to the R executable to get this to work:

   CreateOK := CreateProcess(Nil, PChar('C:\Program 
Files\R\R-2.4.0\bin\R.exe ' + CommandLine), nil,
       nil,False, CREATE_NEW_PROCESS_GROUP+NORMAL_PRIORITY_CLASS, nil,
       nil, StartInfo, proc_info);

I used Delphi 7 to test StartRAndWait with this button press event:

procedure TForm1.Button1Click(Sender: TObject);
  VAR
    Command: STRING;
begin
  Screen.Cursor := crHourGlass;
  TRY
    Command := 'CMD  BATCH  Sample.R  SampleOutput.txt';
    StartRAndWait(Command);
  FINALLY
    Screen.Cursor := crDefault
  END
end;


Sample.R file
=====================
sink('quantile.txt')
quantile(0:100)
sink()
=====================

I used sink in the R script to isolate the output of the R quantile command 
to help any parsing of the output:

SampleOutput.txt
=====================
R version 2.4.0 (2006-10-03)
Copyright (C) 2006 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> sink('quantile.txt')
> quantile(0:100)
> sink()

=====================


quantile.txt
=====================
  0%  25%  50%  75% 100%
   0   25   50   75  100
=====================


Tinn-R is written in Delphi, so its source code should be a great example of 
a Delphi/R interface.  I've never studied the source code -- that's been on 
my "to do" list for months --, but I'm guessing it uses RCOm, like 
Hans-Peter suggested.  Nevertheless, Tom's example above may also be quite 
useful.

efg

Earl F. Glynn
Scientific Programmer
Stowers Institute for Medical Research



From dfarrar at newrvana.com  Wed Dec  6 18:06:27 2006
From: dfarrar at newrvana.com (David Farrar)
Date: Wed, 6 Dec 2006 09:06:27 -0800 (PST)
Subject: [R] test of spatial dependence?? - ask an ecologist?
In-Reply-To: <669380.66037.qm@web56609.mail.re3.yahoo.com>
Message-ID: <214844.99686.qm@web802.biz.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061206/da74c996/attachment-0004.pl 

From vicctorr at gmail.com  Wed Dec  6 18:06:55 2006
From: vicctorr at gmail.com (victor)
Date: Wed, 06 Dec 2006 18:06:55 +0100
Subject: [R] intercept value in lme
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E6B0839@dc1ex01.air.org>
References: <2323A6D37908A847A7C32F1E3662C80E6B0839@dc1ex01.air.org>
Message-ID: <4576F8AF.1060804@gmail.com>

It is boundend, you're right. In fact it is -25<=X<=0

These are cross-national survey data (I was investigated 7 countries in 
each country there was 900-1700 cases).
In fact, there was two level 2 variables, so:

m1<-lme(X~Y,~1|group,data=data,na.action=na.exclude,method="ML")
m2<-lme(X~Y+Z1+Z2,~1|group,data=data,na.action=na.exclude,method="ML")

X is a life satisfaction factor combined from 2 other variables for each 
case separately, of course.
Y  - income per capita in household
Z1 - unemployment rate in a country.
Z2 - life expectancy in a country
group - country

I attach a similar model where after adding Lev2 predictors intercept 
value is even 22!

I'm sure there is my mistake somwhere but... what is wrong?



Linear mixed-effects model fit by maximum likelihood
  Data: data
        AIC      BIC    logLik
   31140.77 31167.54 -15566.39

Random effects:
  Formula: ~1 | country
         (Intercept) Residual
StdDev:   0.8698037 3.300206

Fixed effects: X ~ Y
                 Value Std.Error   DF    t-value p-value
(Intercept) -4.397051 0.3345368 5944 -13.143698       0
Y           -0.000438 0.0000521 5944  -8.399448       0
  Correlation:
         (Intr)
Y       -0.13

Standardized Within-Group Residuals:
        Min         Q1        Med         Q3        Max
-6.3855881 -0.5223116  0.2948941  0.6250717  2.6020180

Number of Observations: 5952
Number of Groups: 7


and for the second model:

Linear mixed-effects model fit by maximum likelihood
  Data: data
        AIC      BIC    logLik
   31133.08 31173.23 -15560.54

Random effects:
  Formula: ~1 | country
         (Intercept) Residual
StdDev:   0.3631184 3.300201

Fixed effects: X ~ Y + Z1 + Z2
                 Value Std.Error   DF   t-value p-value
(Intercept) 22.188828  4.912214 5944  4.517073  0.0000
Y           -0.000440  0.000052 5944 -8.456196  0.0000
Z1          -0.095532  0.037520    4 -2.546161  0.0636
Z2          -0.333549  0.062031    4 -5.377127  0.0058
  Correlation:
         (Intr) FAMPEC UNEMP
Y        0.168
Z1      -0.429  0.080
Z2      -0.997 -0.188  0.366

Standardized Within-Group Residuals:
        Min         Q1        Med         Q3        Max
-6.3778888 -0.5291287  0.2963226  0.6260023  2.6226880

Number of Observations: 5952
Number of Groups: 7

Doran, Harold wrote:
> As Andrew noted, you need to provide more information. But, what I see
> is that your model assumes X is continuous but you say it is bounded,
> -25 < X < 0 
> 
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch 
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of victor
>> Sent: Wednesday, December 06, 2006 3:34 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] intercept value in lme
>>
>> Dear all,
>>
>> I've got a problem in fitting multilevel model in lme. I 
>> don't know to much about that but suspect that something is 
>> wrong with my model.
>>
>> I'm trying to fit:
>>
>> m1<-lme(X~Y,~1|group,data=data,na.action=na.exclude,method="ML")
>> m2<-lme(X~Y+Z,~1|group,data=data,na.action=na.exclude,method="ML")
>>
>> where:
>> X - dependent var. measured on a scale ranging from -25 to 0 
>> Y - level 1 variable Z - level 1 variable
>>
>> In m1 the intercept value is equal -3, in m2 (that is after 
>> adding Lev 2
>> var.) is equal +16.
>>
>> What can be wrong with my variables? Is this possible that 
>> intercept value exceeds scale?
>>
>> Best regards,
>>
>> victor
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>



From gunter.berton at gene.com  Wed Dec  6 18:20:30 2006
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 6 Dec 2006 09:20:30 -0800
Subject: [R] Summary shows wrong maximum
In-Reply-To: <Pine.LNX.4.64.0612061216120.6922@gannet.stats.ox.ac.uk>
Message-ID: <003401c7195a$d4bb8a80$4d908980@gne.windows.gene.com>

 
Folks:

Is 

"So this is at best a matter of opinion, 
and credentials do matter for opinions."

-- Brian Ripley

an R fortunes candidate?

-- Bert Gunter


On Tue, 5 Dec 2006, Oliver Czoske wrote:

> On Mon, 4 Dec 2006, Uwe Ligges wrote:
>> Sebastian Spaeth wrote:
>>> Hi all,
>>> I have a list with a numerical column "cum_hardreuses". By coincidence I
>>> discovered this:
>>>
>>>> max(libs[,"cum_hardreuses"])
>>> [1] 1793
>>>
>>>> summary(libs[,"cum_hardreuses"])
>>>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>>        1       2       4      36      14    1790
>>>
>>> (note the max value of 1790) Ouch this is bad! Anything I can do to
remedy
>>> this? Known bug?
>>
>> No, it's a feature! See ?summary: printing is done up to 3 significant
>> digits by default.
>
> Unfortunately, '1790' is printed with *four* significant digits, not
> three. The correct representation with three significant digits would have
> to employ scientific notation, 1.79e3.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From deepayan.sarkar at gmail.com  Wed Dec  6 18:25:51 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 6 Dec 2006 09:25:51 -0800
Subject: [R] Trellis Plot Labels
In-Reply-To: <20061206154403.74602.qmail@web31015.mail.mud.yahoo.com>
References: <20061206154403.74602.qmail@web31015.mail.mud.yahoo.com>
Message-ID: <eb555e660612060925t4435c6bdv90f8da079be8dfb3@mail.gmail.com>

On 12/6/06, Turgut Durduran <durduran at yahoo.com> wrote:
>
>
> ----- Original Message ----
> From: Deepayan Sarkar <deepayan.sarkar at gmail.com>
> To: Turgut Durduran <durduran at yahoo.com>
> Cc: r-help at stat.math.ethz.ch
> Sent: Saturday, November 18, 2006 4:28:03 PM
> Subject: Re: Re: [R] Trellis Plot Labels
>
> On 11/17/06, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
> > On 11/17/06, Turgut Durduran <durduran at yahoo.com> wrote:
> > > On 11/17/06, Turgut Durduran <durduran at yahoo.com> wrote:
> > > >> Hello everyone,
> > > >>
> > > >> I am ploting a groupeddata object with formula:
> > > >>
> > > >> formula(mydatausegroup)
> > > >> BF ~ HO | ID/Infar/Day
> > > >>
> > > >> Using this command:
> > > >> plot(na.omit(mydatausegroup), displayLevel=2,layout=c(10,2),aspect=2)
> > > >>
> > > >>
> > > >> This trellis plot does almost what I want and produces a 10x2 trellis plot, each panel is labeled
> > > >> as ID/Infar where infarct is either 1 or 0. And in each panel, it plots BF vs HO for each Day. However, the "days" are labeled simply as "1,2,3,4" i>>nstead of their actual values (ranging from 1 to 8). This just mapped for each ID the "1 st measurement, 2nd measurement, 3rd measurement, 4th >>measurement".
> > > >>
> >
> > This seems to be intended behaviour, and the responsible function is
> > collapse.groupedData (which is not very transparent to me).
> >
> > > >> How can I get this trellis plot to use 8 different colors and label them correct?
> >
> > I don't see a documented way, so you'll probably need to modify
> > collapse.groupedData
>
> >>I should have added: it's of course fairly easy if you use xyplot directly.
>
>
> Thank you very much for your detailed help. However, in xyplot, I am ending up a whole bunch of empty panels corresponding to missing days. For example if I did:
>  xyplot(CBF~OB|Day*Inf*ID,data=na.omit(mydatausegroup))

In this case, the plot will have one panel for every combination of
non-empty levels of Day, Inf and ID (not every non-empty combination
of levels). In your case, if you have a nested structure where the
levels of Inf and ID don't mean anything individually. You should be
using an interaction, e.g.

xyplot(CBF~OB|Day:Inf:ID,data=na.omit(mydatausegroup))

To xyplot, the difference is that there is now one conditioning
variable rather than 3, and it will omit any empty levels.

-Deepayan



From amnakhan493 at gmail.com  Wed Dec  6 18:28:43 2006
From: amnakhan493 at gmail.com (amna khan)
Date: Wed, 6 Dec 2006 09:28:43 -0800
Subject: [R] R-Help
Message-ID: <3ffd3bb60612060928t389f91f5t2f271b8fc38f5842@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061206/188056c3/attachment-0004.pl 

From gunter.berton at gene.com  Wed Dec  6 18:30:50 2006
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 6 Dec 2006 09:30:50 -0800
Subject: [R] Usage of apply
In-Reply-To: <4576D983.9080500@optonline.net>
Message-ID: <003e01c7195c$468a1a90$4d908980@gne.windows.gene.com>


But do note -- again! -- that the apply family of functions do their magic
**internally through looping**, so that they are generally not much faster
-- and sometimes a bit slower -- then explicit loops. Their chief advantage
(IMO, of course) is in code clarity and correctness, which is why I prefer
them. (They are also written to do their looping as efficiently as possible,
which explicit looping in user code may not.)

Of course, vectorized calculations (colMeans() in the example below) **are**
much faster and usually clearer than explicit loops.
 
Bert Gunter
Genentech Nonclinical Statistics
South San Francisco, CA 94404

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Chuck Cleland
Sent: Wednesday, December 06, 2006 6:54 AM
To: R Help
Subject: Re: [R] Usage of apply

Jin Shusong wrote:
> Dear R Users,
>   
>   Are there any documents on the usage of apply, tapply,
> sapply so that I avoid explicit loops.  I found that these
> three functions were quite hard to be understood.  Thank you
> in advance.

  If you have read the help pages for each and possibly even consulted
the reference on those help pages, you may need to elaborate on what
parts of these functions you don't understand.  You might also describe
a loop you are contemplating and ask how it might be replaced by one of
these functions.
  Here is a very simple example of a loop that could be avoided with one
of these functions:

> for(i in 1:4){print(mean(iris[,i]))}
[1] 5.843333
[1] 3.057333
[1] 3.758
[1] 1.199333

  Here is how you would do that with apply():

> apply(iris[,1:4], 2, mean)
Sepal.Length  Sepal.Width Petal.Length  Petal.Width
    5.843333     3.057333     3.758000     1.199333

  Even better in this particular case would be:

> colMeans(iris[,1:4])
Sepal.Length  Sepal.Width Petal.Length  Petal.Width
    5.843333     3.057333     3.758000     1.199333

  but you don't always want mean() or sum() as the function, so the
functions you mention above are more general than colMeans() and similar
functions.

> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ccleland at optonline.net  Wed Dec  6 18:31:12 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 06 Dec 2006 12:31:12 -0500
Subject: [R] intercept value in lme
In-Reply-To: <4576F8AF.1060804@gmail.com>
References: <2323A6D37908A847A7C32F1E3662C80E6B0839@dc1ex01.air.org>
	<4576F8AF.1060804@gmail.com>
Message-ID: <4576FE60.6070402@optonline.net>

victor wrote:
> It is boundend, you're right. In fact it is -25<=X<=0
> 
> These are cross-national survey data (I was investigated 7 countries in 
> each country there was 900-1700 cases).
> In fact, there was two level 2 variables, so:
> 
> m1<-lme(X~Y,~1|group,data=data,na.action=na.exclude,method="ML")
> m2<-lme(X~Y+Z1+Z2,~1|group,data=data,na.action=na.exclude,method="ML")
> 
> X is a life satisfaction factor combined from 2 other variables for each 
> case separately, of course.
> Y  - income per capita in household
> Z1 - unemployment rate in a country.
> Z2 - life expectancy in a country
> group - country

Victor:
  What happens if you center Y, Z1, and Z2 so that 0 corresponds to the
mean for each?  As it is, zero is a very unusual value for each of these
variables.  Do you really want to estimate the value of X when income =
0, unemployment = 0, and life expectancy = 0?  If I understand
correctly, I think that's why the intercept value looks unusual to you.

> I attach a similar model where after adding Lev2 predictors intercept 
> value is even 22!
> 
> I'm sure there is my mistake somwhere but... what is wrong?
> 
> 
> 
> Linear mixed-effects model fit by maximum likelihood
>   Data: data
>         AIC      BIC    logLik
>    31140.77 31167.54 -15566.39
> 
> Random effects:
>   Formula: ~1 | country
>          (Intercept) Residual
> StdDev:   0.8698037 3.300206
> 
> Fixed effects: X ~ Y
>                  Value Std.Error   DF    t-value p-value
> (Intercept) -4.397051 0.3345368 5944 -13.143698       0
> Y           -0.000438 0.0000521 5944  -8.399448       0
>   Correlation:
>          (Intr)
> Y       -0.13
> 
> Standardized Within-Group Residuals:
>         Min         Q1        Med         Q3        Max
> -6.3855881 -0.5223116  0.2948941  0.6250717  2.6020180
> 
> Number of Observations: 5952
> Number of Groups: 7
> 
> 
> and for the second model:
> 
> Linear mixed-effects model fit by maximum likelihood
>   Data: data
>         AIC      BIC    logLik
>    31133.08 31173.23 -15560.54
> 
> Random effects:
>   Formula: ~1 | country
>          (Intercept) Residual
> StdDev:   0.3631184 3.300201
> 
> Fixed effects: X ~ Y + Z1 + Z2
>                  Value Std.Error   DF   t-value p-value
> (Intercept) 22.188828  4.912214 5944  4.517073  0.0000
> Y           -0.000440  0.000052 5944 -8.456196  0.0000
> Z1          -0.095532  0.037520    4 -2.546161  0.0636
> Z2          -0.333549  0.062031    4 -5.377127  0.0058
>   Correlation:
>          (Intr) FAMPEC UNEMP
> Y        0.168
> Z1      -0.429  0.080
> Z2      -0.997 -0.188  0.366
> 
> Standardized Within-Group Residuals:
>         Min         Q1        Med         Q3        Max
> -6.3778888 -0.5291287  0.2963226  0.6260023  2.6226880
> 
> Number of Observations: 5952
> Number of Groups: 7
> 
> Doran, Harold wrote:
>> As Andrew noted, you need to provide more information. But, what I see
>> is that your model assumes X is continuous but you say it is bounded,
>> -25 < X < 0 
>>
>>> -----Original Message-----
>>> From: r-help-bounces at stat.math.ethz.ch 
>>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of victor
>>> Sent: Wednesday, December 06, 2006 3:34 AM
>>> To: r-help at stat.math.ethz.ch
>>> Subject: [R] intercept value in lme
>>>
>>> Dear all,
>>>
>>> I've got a problem in fitting multilevel model in lme. I 
>>> don't know to much about that but suspect that something is 
>>> wrong with my model.
>>>
>>> I'm trying to fit:
>>>
>>> m1<-lme(X~Y,~1|group,data=data,na.action=na.exclude,method="ML")
>>> m2<-lme(X~Y+Z,~1|group,data=data,na.action=na.exclude,method="ML")
>>>
>>> where:
>>> X - dependent var. measured on a scale ranging from -25 to 0 
>>> Y - level 1 variable Z - level 1 variable
>>>
>>> In m1 the intercept value is equal -3, in m2 (that is after 
>>> adding Lev 2
>>> var.) is equal +16.
>>>
>>> What can be wrong with my variables? Is this possible that 
>>> intercept value exceeds scale?
>>>
>>> Best regards,
>>>
>>> victor
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894



From mbalcilar at yahoo.com  Wed Dec  6 16:21:43 2006
From: mbalcilar at yahoo.com (Mehmet Balcilar)
Date: Wed, 06 Dec 2006 17:21:43 +0200
Subject: [R] [R-pkgs] mFilter package
Message-ID: <4576E007.80308@yahoo.com>

Dear useRs,

Please find the new package mFilter version 0.1-2 on CRAN.

The package implements several time series filters useful for smoothing
and extracting trend and cyclical components of a time series. The
routines are commonly used in economics and finance, however they should
also be interest to other areas. Currently, Christiano-Fitzgerald,
Baxter-King, Hodrick-Prescott, Butterworth, and trigonometric regression
filters are included in the package.


Cheers,

-- 
Mehmet Balcilar, PhD
Associate Professor of Econometrics

Cukurova University
College of Economics & Administrative Sciences
Department of Econometrics
Balcali, Adana 01330
Turkey

Tel: +90 (322) 338-7255 (6 lines) Ext. 170
     
Mobile: +90 532 396-0145

Fax: +90 (322) 338-7283
     +90 (322) 338-7284
	     

e-mail:	mbalcilar at yahoo.com 
	mehmet at mbalcilar.net
	mbalcilar at cu.edu.tr

Homepage: http://www.mbalcilar.net

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From h.wickham at gmail.com  Wed Dec  6 18:48:16 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 6 Dec 2006 11:48:16 -0600
Subject: [R] [R-pkgs] classifly 0.2.2
Message-ID: <f8e6ff050612060948g3fa18226pc2db548e477e1481@mail.gmail.com>

The classifly package uses rggobi to visualise classification
boundaries in high-dimensions.  Given p-dimensional training data
containing d groups (the design space), a classification algorithm
(classifier) predicts which group new data belongs to. Generally the
input to these algorithms is high dimensional, and the boundaries
between groups will be high dimensional and perhaps curvilinear or
multi-facted. This R package provides methods for visualising the
division of space between the groups.

More information and a paper describing the ideas can be found at
http://had.co.nz/classifly/.

Regards,

Hadley

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From h.wickham at gmail.com  Wed Dec  6 18:47:45 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 6 Dec 2006 11:47:45 -0600
Subject: [R] [R-pkgs] rggobi 2.1.4-3
Message-ID: <f8e6ff050612060947n43afd3ffifb33e064a89fc21d@mail.gmail.com>

We are pleased to announce version 2.1.4-3 of rggobi. This release
introduces many new features, including the ability to open new
displays, and get and set tour projections.

The rggobi package provides a command-line interface to GGobi, an
interactive and dynamic graphics package. Rggobi complements GGobi's
graphical user interface, providing a way to fluidly transition
between analysis and exploration, as well as automating common tasks.
It builds on the first version of rggobi to provide a more robust and
user friendly interface.

To install rggobi, you will need to first install GGobi by following
the instructions at http://www.ggobi.org/downloads/.  You get more
details, including an introductory vignette, at
http://www.ggobi.org/rggobi/.

There are some problems with rggobi on Intel Macs (we are working on a
solution), so please email me for more details if you are keen to try
it out.  We want rggobi to be a stable and useful tool, so please do
not hesitate to email me or the GGobi mailing list
(http://www.ggobi.org/support/) if you have any problems.

Regards,

Hadley

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From ligges at statistik.uni-dortmund.de  Wed Dec  6 19:08:48 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 06 Dec 2006 19:08:48 +0100
Subject: [R] R-Help
In-Reply-To: <3ffd3bb60612060928t389f91f5t2f271b8fc38f5842@mail.gmail.com>
References: <3ffd3bb60612060928t389f91f5t2f271b8fc38f5842@mail.gmail.com>
Message-ID: <45770730.8000109@statistik.uni-dortmund.de>

You might want to contact the nortest maintainer, Juergen Gross (CCing), 
who is not listening to the traffic on this list.

Uwe Ligges

amna khan wrote:
> Respected Sir
> I am a very new user of R. I want to ask a question about "the nortest
> package". In this package how we can write the code of ad.test, cvm.test,
> ks.test for other distributions like GEV, GPA etc.
> 
> I request you to please  guide to me.
> Kind Regards
> AMNA
>



From derek.eder at lungall.gu.se  Wed Dec  6 19:14:07 2006
From: derek.eder at lungall.gu.se (Derek Eder)
Date: Wed, 06 Dec 2006 19:14:07 +0100
Subject: [R] POSIX and summer savings time
Message-ID: <4577086F.2070600@lungall.gu.se>

I have a time stamp in UTC (GMT) time:

 >  format(ISOdatetime(1970,1,1,0,0,0)+1165398135729/1000,"%Y-%m-%d 
%H:%M:%OS3")

"2006-12-06 09:42:18.823"  (note millisecond accuracy, but not relevant 
to question here)

Now, this time stamp actually "happened" at local (Swedish) time one 
hour later (10:42).

Regarding summer/winter adjustments in time ("spring forward, fall 
back"):   Is there a way of automatically recovering the local time 
adjustments for a given date?  E.g., a date/time in springtime = GMT +2 
, else GMT +1

Thanks,

Derek Eder


-- 
Derek N. Eder

Gothenburg University 
VINKLA - Vigilance and Neurocognition laboratory 

SU/Sahlgrenska
Utvecklingslab 1, Med
Gr?na str?ket 8
SE 413 45 G?teborg (Gothenburg)
Sverige (Sweden)

+46 (031)* 342 8261 (28261 inom Sahlgrenska)
+46 0704 915 714 (mobile)
+46 (031) 25 97 07 (home)

* omit the 0 when calling from outside Sweden



From greenboy21 at gmail.com  Wed Dec  6 19:28:45 2006
From: greenboy21 at gmail.com (Xu Yuan)
Date: Wed, 6 Dec 2006 13:28:45 -0500
Subject: [R] test of spatial dependence?? - ask an ecologist?
In-Reply-To: <669380.66037.qm@web56609.mail.re3.yahoo.com>
References: <493883.80128.qm@web802.biz.mail.mud.yahoo.com>
	<669380.66037.qm@web56609.mail.re3.yahoo.com>
Message-ID: <e00347d90612061028k51b8eaf0gb10837bd50d6357@mail.gmail.com>

Thanks David and Milton for replies. No, I don't have the coordiates.
In other words, my data are not point data. But I think there is a way
to test of spatial dependence for areal data or lattice data. In this
case, the variable of interest is typically the average value of an
area instead of a point. Do you how to do this?

 Thank you.
 Xu

On 12/6/06, Milton Cezar Ribeiro <milton_ruser at yahoo.com.br> wrote:
>
> I never used it, but I beleave that it is a job for "mantel.rtest()" available on "ade4" package.
>
> In fact Farrar are right, you will neet the XY coordinates. Give a look at "Legendre & Legendre" text book.
>
> HTH,
>
> Miltinho
> Brazil
>
> David Farrar <dfarrar at newrvana.com> escreveu:
>
>
> In addition to the 25 numbers, I assume you have coordinates of each field.
> Otherwise, I don't understand what you are trying to do. I think ecologists like to use a test due to Mantel in this situation.
>
> The prefix "auto" means "self," of course, the idea being that measurements of the same variable under different conditions are correlated. I guess this would be a case of "autodependence." For correlation versus dependence, check your  intro stats book.
>
> de nada,
> X'X
>
> Farrar
>
>
> Xu Yuan wrote:
> hello R-friends,
>
> I am a R beginner and try to ask a basic question:
>
> How to test the spatial dependence of a column of data? for example, I have
> 25 agricultural fields, and I measure the average slope (%) or pH for each
> field. All I have is 25 numbers.
>
> PS, could someone confirm that "spatial dependence" is equivalent to
> "spatial correlation" or "spatial autocorrelation" or not.
>
> Thank you very much.
> XY
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> [[alternative HTML version  deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>   		________________________________
  O Yahoo! est? de cara nova. Venha conferir!
>
>



From HDoran at air.org  Wed Dec  6 19:52:22 2006
From: HDoran at air.org (Doran, Harold)
Date: Wed, 6 Dec 2006 13:52:22 -0500
Subject: [R] intercept value in lme
Message-ID: <2323A6D37908A847A7C32F1E3662C80E6B088D@dc1ex01.air.org>

Dear Victor:

Firstly, why do you think something is wrong? Ignoring the fact that
your DV is not continuous for a moment and your distributional
assumptions assume it is, could it not be the case that conditional on
your covariates the changes in the intercept are correct?

I might be missing something, but to me it seems that you are concluding
that something is wrong because of the vast changes in the intercept. As
far as I can see in this thread so far we still do not know anything
about the covariates that could help diagnose the issue.

Syntactically, your lme model is correct (although you should switch to
lmer which is more supported), but you might consider a transformation
of you DV (e.g., log) to better coincide with your distributional
assumptions.

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of victor
> Sent: Wednesday, December 06, 2006 12:07 PM
> To: Doran, Harold
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] intercept value in lme
> 
> It is boundend, you're right. In fact it is -25<=X<=0
> 
> These are cross-national survey data (I was investigated 7 
> countries in each country there was 900-1700 cases).
> In fact, there was two level 2 variables, so:
> 
> m1<-lme(X~Y,~1|group,data=data,na.action=na.exclude,method="ML")
> m2<-lme(X~Y+Z1+Z2,~1|group,data=data,na.action=na.exclude,method="ML")
> 
> X is a life satisfaction factor combined from 2 other 
> variables for each case separately, of course.
> Y  - income per capita in household
> Z1 - unemployment rate in a country.
> Z2 - life expectancy in a country
> group - country
> 
> I attach a similar model where after adding Lev2 predictors 
> intercept value is even 22!
> 
> I'm sure there is my mistake somwhere but... what is wrong?
> 
> 
> 
> Linear mixed-effects model fit by maximum likelihood
>   Data: data
>         AIC      BIC    logLik
>    31140.77 31167.54 -15566.39
> 
> Random effects:
>   Formula: ~1 | country
>          (Intercept) Residual
> StdDev:   0.8698037 3.300206
> 
> Fixed effects: X ~ Y
>                  Value Std.Error   DF    t-value p-value
> (Intercept) -4.397051 0.3345368 5944 -13.143698       0
> Y           -0.000438 0.0000521 5944  -8.399448       0
>   Correlation:
>          (Intr)
> Y       -0.13
> 
> Standardized Within-Group Residuals:
>         Min         Q1        Med         Q3        Max
> -6.3855881 -0.5223116  0.2948941  0.6250717  2.6020180
> 
> Number of Observations: 5952
> Number of Groups: 7
> 
> 
> and for the second model:
> 
> Linear mixed-effects model fit by maximum likelihood
>   Data: data
>         AIC      BIC    logLik
>    31133.08 31173.23 -15560.54
> 
> Random effects:
>   Formula: ~1 | country
>          (Intercept) Residual
> StdDev:   0.3631184 3.300201
> 
> Fixed effects: X ~ Y + Z1 + Z2
>                  Value Std.Error   DF   t-value p-value
> (Intercept) 22.188828  4.912214 5944  4.517073  0.0000
> Y           -0.000440  0.000052 5944 -8.456196  0.0000
> Z1          -0.095532  0.037520    4 -2.546161  0.0636
> Z2          -0.333549  0.062031    4 -5.377127  0.0058
>   Correlation:
>          (Intr) FAMPEC UNEMP
> Y        0.168
> Z1      -0.429  0.080
> Z2      -0.997 -0.188  0.366
> 
> Standardized Within-Group Residuals:
>         Min         Q1        Med         Q3        Max
> -6.3778888 -0.5291287  0.2963226  0.6260023  2.6226880
> 
> Number of Observations: 5952
> Number of Groups: 7
> 
> Doran, Harold wrote:
> > As Andrew noted, you need to provide more information. But, 
> what I see 
> > is that your model assumes X is continuous but you say it 
> is bounded,
> > -25 < X < 0
> > 
> >> -----Original Message-----
> >> From: r-help-bounces at stat.math.ethz.ch 
> >> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of victor
> >> Sent: Wednesday, December 06, 2006 3:34 AM
> >> To: r-help at stat.math.ethz.ch
> >> Subject: [R] intercept value in lme
> >>
> >> Dear all,
> >>
> >> I've got a problem in fitting multilevel model in lme. I 
> don't know 
> >> to much about that but suspect that something is wrong 
> with my model.
> >>
> >> I'm trying to fit:
> >>
> >> m1<-lme(X~Y,~1|group,data=data,na.action=na.exclude,method="ML")
> >> m2<-lme(X~Y+Z,~1|group,data=data,na.action=na.exclude,method="ML")
> >>
> >> where:
> >> X - dependent var. measured on a scale ranging from -25 to 0 Y - 
> >> level 1 variable Z - level 1 variable
> >>
> >> In m1 the intercept value is equal -3, in m2 (that is after adding 
> >> Lev 2
> >> var.) is equal +16.
> >>
> >> What can be wrong with my variables? Is this possible that 
> intercept 
> >> value exceeds scale?
> >>
> >> Best regards,
> >>
> >> victor
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list 
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From A.Robinson at ms.unimelb.edu.au  Wed Dec  6 20:00:11 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 7 Dec 2006 06:00:11 +1100
Subject: [R] intercept value in lme
In-Reply-To: <4576F8AF.1060804@gmail.com>
References: <2323A6D37908A847A7C32F1E3662C80E6B0839@dc1ex01.air.org>
	<4576F8AF.1060804@gmail.com>
Message-ID: <20061206190011.GD70252@ms.unimelb.edu.au>

Hello Victor,

I'm afraid that this still isn't what we're looking for, in terms of
reproducible code, but we can guess.  What is the range of the 
Z1 and Z2 variables?  What is the range of the model predictions? 
If the Z1 and Z2 variables are large and positive then they will be
compensating.

Cheers

Andrew

On Wed, Dec 06, 2006 at 06:06:55PM +0100, victor wrote:
> It is boundend, you're right. In fact it is -25<=X<=0
> 
> These are cross-national survey data (I was investigated 7 countries in 
> each country there was 900-1700 cases).
> In fact, there was two level 2 variables, so:
> 
> m1<-lme(X~Y,~1|group,data=data,na.action=na.exclude,method="ML")
> m2<-lme(X~Y+Z1+Z2,~1|group,data=data,na.action=na.exclude,method="ML")
> 
> X is a life satisfaction factor combined from 2 other variables for each 
> case separately, of course.
> Y  - income per capita in household
> Z1 - unemployment rate in a country.
> Z2 - life expectancy in a country
> group - country
> 
> I attach a similar model where after adding Lev2 predictors intercept 
> value is even 22!
> 
> I'm sure there is my mistake somwhere but... what is wrong?
> 
> 
> 
> Linear mixed-effects model fit by maximum likelihood
>   Data: data
>         AIC      BIC    logLik
>    31140.77 31167.54 -15566.39
> 
> Random effects:
>   Formula: ~1 | country
>          (Intercept) Residual
> StdDev:   0.8698037 3.300206
> 
> Fixed effects: X ~ Y
>                  Value Std.Error   DF    t-value p-value
> (Intercept) -4.397051 0.3345368 5944 -13.143698       0
> Y           -0.000438 0.0000521 5944  -8.399448       0
>   Correlation:
>          (Intr)
> Y       -0.13
> 
> Standardized Within-Group Residuals:
>         Min         Q1        Med         Q3        Max
> -6.3855881 -0.5223116  0.2948941  0.6250717  2.6020180
> 
> Number of Observations: 5952
> Number of Groups: 7
> 
> 
> and for the second model:
> 
> Linear mixed-effects model fit by maximum likelihood
>   Data: data
>         AIC      BIC    logLik
>    31133.08 31173.23 -15560.54
> 
> Random effects:
>   Formula: ~1 | country
>          (Intercept) Residual
> StdDev:   0.3631184 3.300201
> 
> Fixed effects: X ~ Y + Z1 + Z2
>                  Value Std.Error   DF   t-value p-value
> (Intercept) 22.188828  4.912214 5944  4.517073  0.0000
> Y           -0.000440  0.000052 5944 -8.456196  0.0000
> Z1          -0.095532  0.037520    4 -2.546161  0.0636
> Z2          -0.333549  0.062031    4 -5.377127  0.0058
>   Correlation:
>          (Intr) FAMPEC UNEMP
> Y        0.168
> Z1      -0.429  0.080
> Z2      -0.997 -0.188  0.366
> 
> Standardized Within-Group Residuals:
>         Min         Q1        Med         Q3        Max
> -6.3778888 -0.5291287  0.2963226  0.6260023  2.6226880
> 
> Number of Observations: 5952
> Number of Groups: 7
> 
> Doran, Harold wrote:
> > As Andrew noted, you need to provide more information. But, what I see
> > is that your model assumes X is continuous but you say it is bounded,
> > -25 < X < 0 
> > 
> >> -----Original Message-----
> >> From: r-help-bounces at stat.math.ethz.ch 
> >> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of victor
> >> Sent: Wednesday, December 06, 2006 3:34 AM
> >> To: r-help at stat.math.ethz.ch
> >> Subject: [R] intercept value in lme
> >>
> >> Dear all,
> >>
> >> I've got a problem in fitting multilevel model in lme. I 
> >> don't know to much about that but suspect that something is 
> >> wrong with my model.
> >>
> >> I'm trying to fit:
> >>
> >> m1<-lme(X~Y,~1|group,data=data,na.action=na.exclude,method="ML")
> >> m2<-lme(X~Y+Z,~1|group,data=data,na.action=na.exclude,method="ML")
> >>
> >> where:
> >> X - dependent var. measured on a scale ranging from -25 to 0 
> >> Y - level 1 variable Z - level 1 variable
> >>
> >> In m1 the intercept value is equal -3, in m2 (that is after 
> >> adding Lev 2
> >> var.) is equal +16.
> >>
> >> What can be wrong with my variables? Is this possible that 
> >> intercept value exceeds scale?
> >>
> >> Best regards,
> >>
> >> victor
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide 
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From Roger.Bivand at nhh.no  Wed Dec  6 20:11:22 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 6 Dec 2006 20:11:22 +0100 (CET)
Subject: [R] test of spatial dependence?? - ask an ecologist?
In-Reply-To: <e00347d90612061028k51b8eaf0gb10837bd50d6357@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0612062009420.11952-100000@reclus.nhh.no>

On Wed, 6 Dec 2006, Xu Yuan wrote:

> Thanks David and Milton for replies. No, I don't have the coordiates.
> In other words, my data are not point data. But I think there is a way
> to test of spatial dependence for areal data or lattice data. In this
> case, the variable of interest is typically the average value of an
> area instead of a point. Do you how to do this?

But do you know where the areas are in relation to each other? Does the 
spatialCovariance package help?

Roger

> 
>  Thank you.
>  Xu
> 
> On 12/6/06, Milton Cezar Ribeiro <milton_ruser at yahoo.com.br> wrote:
> >
> > I never used it, but I beleave that it is a job for "mantel.rtest()" available on "ade4" package.
> >
> > In fact Farrar are right, you will neet the XY coordinates. Give a look at "Legendre & Legendre" text book.
> >
> > HTH,
> >
> > Miltinho
> > Brazil
> >
> > David Farrar <dfarrar at newrvana.com> escreveu:
> >
> >
> > In addition to the 25 numbers, I assume you have coordinates of each field.
> > Otherwise, I don't understand what you are trying to do. I think ecologists like to use a test due to Mantel in this situation.
> >
> > The prefix "auto" means "self," of course, the idea being that measurements of the same variable under different conditions are correlated. I guess this would be a case of "autodependence." For correlation versus dependence, check your  intro stats book.
> >
> > de nada,
> > X'X
> >
> > Farrar
> >
> >
> > Xu Yuan wrote:
> > hello R-friends,
> >
> > I am a R beginner and try to ask a basic question:
> >
> > How to test the spatial dependence of a column of data? for example, I have
> > 25 agricultural fields, and I measure the average slope (%) or pH for each
> > field. All I have is 25 numbers.
> >
> > PS, could someone confirm that "spatial dependence" is equivalent to
> > "spatial correlation" or "spatial autocorrelation" or not.
> >
> > Thank you very much.
> > XY
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > [[alternative HTML version  deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >   		________________________________
>   O Yahoo! est? de cara nova. Venha conferir!
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From mike.prager at noaa.gov  Wed Dec  6 20:45:35 2006
From: mike.prager at noaa.gov (Mike Prager)
Date: Wed, 06 Dec 2006 14:45:35 -0500
Subject: [R] Summary shows wrong maximum
References: <Pine.LNX.4.64.0612061216120.6922@gannet.stats.ox.ac.uk>
	<003401c7195a$d4bb8a80$4d908980@gne.windows.gene.com>
Message-ID: <a97en2hb004kgalc1ilfceule4q490ln1d@4ax.com>

I don't know about candidacy, and I'm not going to argue about
"correctness," but it seems to me that the only valid reasons to
limit precision of printing in a statistics program are (1) to
save space and (2) to allow for machine limitations. This is
neither. To chop off information and replace it with zeroes is
just plain nasty.


Bert Gunter <gunter.berton at gene.com> wrote:

>  
> Folks:
> 
> Is 
> 
> "So this is at best a matter of opinion, 
> and credentials do matter for opinions."
> 
> -- Brian Ripley
> 
> an R fortunes candidate?
> 
> -- Bert Gunter
> 
> 
> On Tue, 5 Dec 2006, Oliver Czoske wrote:
> 
> > On Mon, 4 Dec 2006, Uwe Ligges wrote:
> >> Sebastian Spaeth wrote:
> >>> Hi all,
> >>> I have a list with a numerical column "cum_hardreuses". By coincidence I
> >>> discovered this:
> >>>
> >>>> max(libs[,"cum_hardreuses"])
> >>> [1] 1793
> >>>
> >>>> summary(libs[,"cum_hardreuses"])
> >>>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> >>>        1       2       4      36      14    1790
> >>>
> >>> (note the max value of 1790) Ouch this is bad! Anything I can do to
> remedy
> >>> this? Known bug?
> >>
> >> No, it's a feature! See ?summary: printing is done up to 3 significant
> >> digits by default.
> >
> > Unfortunately, '1790' is printed with *four* significant digits, not
> > three. The correct representation with three significant digits would have
> > to employ scientific notation, 1.79e3.
> >
> >

-- 
Mike Prager, NOAA, Beaufort, NC
* Opinions expressed are personal and not represented otherwise.
* Any use of tradenames does not constitute a NOAA endorsement.



From gunter.berton at gene.com  Wed Dec  6 21:04:45 2006
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 6 Dec 2006 12:04:45 -0800
Subject: [R] Summary shows wrong maximum
In-Reply-To: <a97en2hb004kgalc1ilfceule4q490ln1d@4ax.com>
Message-ID: <007701c71971$c684a890$4d908980@gne.windows.gene.com>

Mike:

I offered no opinion -- and really didn't have any -- about the worthiness
of any of the comments that were made. I just liked Brian's little quotable
aside.

But since you bait me a bit ...

In general, I believe that showing th 2-3 most "important" -- **not
significant** -- digits **and no more** is desirable. By " most important" I
mean the leftmost digits which are changing in the data (there are some
caveats in the presence of extreme outliers). Printing more digits merely
obfuscates the ability of the eye/brain to perceive the patterns of change
in the data, the presumed intent of displaying it (not of storing it, of
course). Displaying excessive digits to demonstrate (usually falsely) one's
precision is evil. Clarity of communications is the standard we should
aspire to.

These views have been more eloquently expressed by  A.S.C Ehrenburg and
Howard Wainer among others...

-- Bert


Bert Gunter
Nonclinical Statistics
7-7374

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mike Prager
Sent: Wednesday, December 06, 2006 11:46 AM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] Summary shows wrong maximum

I don't know about candidacy, and I'm not going to argue about
"correctness," but it seems to me that the only valid reasons to
limit precision of printing in a statistics program are (1) to
save space and (2) to allow for machine limitations. This is
neither. To chop off information and replace it with zeroes is
just plain nasty.


Bert Gunter <gunter.berton at gene.com> wrote:

>  
> Folks:
> 
> Is 
> 
> "So this is at best a matter of opinion, 
> and credentials do matter for opinions."
> 
> -- Brian Ripley
> 
> an R fortunes candidate?
> 
> -- Bert Gunter
> 
> 
> On Tue, 5 Dec 2006, Oliver Czoske wrote:
> 
> > On Mon, 4 Dec 2006, Uwe Ligges wrote:
> >> Sebastian Spaeth wrote:
> >>> Hi all,
> >>> I have a list with a numerical column "cum_hardreuses". By coincidence
I
> >>> discovered this:
> >>>
> >>>> max(libs[,"cum_hardreuses"])
> >>> [1] 1793
> >>>
> >>>> summary(libs[,"cum_hardreuses"])
> >>>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> >>>        1       2       4      36      14    1790
> >>>
> >>> (note the max value of 1790) Ouch this is bad! Anything I can do to
> remedy
> >>> this? Known bug?
> >>
> >> No, it's a feature! See ?summary: printing is done up to 3 significant
> >> digits by default.
> >
> > Unfortunately, '1790' is printed with *four* significant digits, not
> > three. The correct representation with three significant digits would
have
> > to employ scientific notation, 1.79e3.
> >
> >

-- 
Mike Prager, NOAA, Beaufort, NC
* Opinions expressed are personal and not represented otherwise.
* Any use of tradenames does not constitute a NOAA endorsement.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From perpdgo at colpos.mx  Wed Dec  6 21:02:35 2006
From: perpdgo at colpos.mx (Paulino Perez Rodriguez)
Date: Wed, 06 Dec 2006 14:02:35 -0600
Subject: [R] Standar errors arma models
Message-ID: <web-8458391@mailadmin.colpos.mx>


Why the standadard errors of the coefficientes of the arma 
models fited by using the arima procedure in the stats 
package doesnt coincide with that of S+, minitab or SAS?


-- 
Este mensaje ha sido analizado por MailScanner
en busca de virus y otros contenidos peligrosos,
y se considera que est? limpio.



From roebuck at mdanderson.org  Wed Dec  6 23:02:47 2006
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Wed, 6 Dec 2006 16:02:47 -0600 (CST)
Subject: [R] Canonical method for S engine selection?
Message-ID: <Pine.OSF.4.58.0612061549200.103412@wotan.mdacc.tmc.edu>

Assuming script 'common.q' contains code that needed
different processing depending on interpreter
(either S-PLUS or R), what should the condition be?

if (<condition>) {
    # Do S-PLUS code
} else {
    # Do R code
}

Looking for something akin to the C preprocessor directive
USING_R, but for S.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From milton_ruser at yahoo.com.br  Wed Dec  6 23:06:27 2006
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Wed, 6 Dec 2006 22:06:27 +0000 (GMT)
Subject: [R] require(simecol) error
Message-ID: <7054.51965.qm@web56606.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061206/4f8474ca/attachment-0004.pl 

From murdoch at stats.uwo.ca  Wed Dec  6 23:11:48 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 06 Dec 2006 17:11:48 -0500
Subject: [R] Canonical method for S engine selection?
In-Reply-To: <Pine.OSF.4.58.0612061549200.103412@wotan.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0612061549200.103412@wotan.mdacc.tmc.edu>
Message-ID: <45774024.4010906@stats.uwo.ca>

On 12/6/2006 5:02 PM, Paul Roebuck wrote:
> Assuming script 'common.q' contains code that needed
> different processing depending on interpreter
> (either S-PLUS or R), what should the condition be?
> 
> if (<condition>) {
>     # Do S-PLUS code
> } else {
>     # Do R code
> }
> 
> Looking for something akin to the C preprocessor directive
> USING_R, but for S.

See ?is.R.  This function is defined in both R and current versions of 
S-PLUS; there are instructions for how to put together a test that works 
in older S-PLUS versions too.

Duncan Murdoch



From bcarvalh at jhsph.edu  Wed Dec  6 23:16:50 2006
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Wed, 6 Dec 2006 17:16:50 -0500
Subject: [R] require(simecol) error
In-Reply-To: <7054.51965.qm@web56606.mail.re3.yahoo.com>
References: <7054.51965.qm@web56606.mail.re3.yahoo.com>
Message-ID: <840A8032-06EE-4DF6-B0DB-FBE15F66705B@jhsph.edu>

The output of sessionInfo() will be helpful here.

But I can't reproduce that on R 2.4.0 Patched r40106 + simecol (0.3-11).

Maybe you should upgrade the package?

b

On Dec 6, 2006, at 5:06 PM, Milton Cezar Ribeiro wrote:

> Hi there,
>
>   I?m trying to use "simecol" package but I got the error showed  
> below. I?m runnig R version 2.4.0 (2006-10-03).
>
>   Kind regards,
>
>   miltinho
>   Brazil
>   ---
>> require(simecol)
> Loading required package: simecol
> Error in loadNamespace(package, c(which.lib.loc, lib.loc),  
> keep.source = keep.source) :
>         in 'simecol' methods specified for export, but none  
> defined: fixInit, fixParms, fixTimes, plot, print, solver,  
> solver<-, out, inputs, inputs<-, main, main<-, equations,  
> equations<-, sim, parms, parms<-, init, init<-, times, times<-
> [1] FALSE
>   -----



From tlumley at u.washington.edu  Wed Dec  6 23:18:19 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 6 Dec 2006 14:18:19 -0800 (PST)
Subject: [R] Canonical method for S engine selection?
In-Reply-To: <Pine.OSF.4.58.0612061549200.103412@wotan.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0612061549200.103412@wotan.mdacc.tmc.edu>
Message-ID: <Pine.LNX.4.64.0612061412560.2069@homer21.u.washington.edu>

On Wed, 6 Dec 2006, Paul Roebuck wrote:

> Assuming script 'common.q' contains code that needed
> different processing depending on interpreter
> (either S-PLUS or R), what should the condition be?
>

I believe
   exists("is.R") && is.R()
is a reliable condition.

 	-thomas



From backer at psych.uib.no  Wed Dec  6 23:44:49 2006
From: backer at psych.uib.no (Tom Backer Johnsen)
Date: Wed, 06 Dec 2006 23:44:49 +0100
Subject: [R] Calling R functions in Delphi
In-Reply-To: <el6sv8$tlp$1@sea.gmane.org>
References: <OF3A5C81C3.5AEE7555-ON8525723A.0069E1BB-8525723A.006ADF77@abtassoc.com>	<4575AE08.8010304@psych.uib.no>
	<el6sv8$tlp$1@sea.gmane.org>
Message-ID: <457747E1.2070207@psych.uib.no>

Earl F. Glynn wrote:
> Thanks for the great example, Tom.
> 
> "Tom Backer Johnsen" <backer at psych.uib.no> wrote in message 
> news:4575AE08.8010304 at psych.uib.no...
>> Anna Belova wrote:
> 
>>> We would like to call quantile() function from the R-package STATS in a
>>> Delphi program. If this is possible, could anyone provide us with an
>>> example?
>> It is possible, and in principle simple.  The essentials:  (1) Write a
>> file containing the something like a script in R with whatever
>> commands. (2) Start a process involving the execution of R with a
>> command line containing two arguments, the name of the command file
>> and the file where you want the output (results) to be. (3) wait for
>> the process to stop.  So, here is a function (returns true if
>> everyhing worked OK) that does that:
> 
> . . .
> 
>>    CreateOK := CreateProcess(Nil, PChar('R.exe ' + CommandLine), nil,
>>       nil,False, CREATE_NEW_PROCESS_GROUP+NORMAL_PRIORITY_CLASS, nil,
>>       nil, StartInfo, proc_info);
> 
> I had to give the full path to the R executable to get this to work:
> 
>    CreateOK := CreateProcess(Nil, PChar('C:\Program 
> Files\R\R-2.4.0\bin\R.exe ' + CommandLine), nil,
>        nil,False, CREATE_NEW_PROCESS_GROUP+NORMAL_PRIORITY_CLASS, nil,
>        nil, StartInfo, proc_info);

That (I think) would depend on whether the directory to the R.exe is 
in the path for the Windows system you use (which I seem to remember I 
added in my environment).  In any case, I was looking for some kind of 
an interface to R late last spring, and this was what I arrived at. 
Which worked.
> 
> I used Delphi 7 to test StartRAndWait with this button press event:
> 
> procedure TForm1.Button1Click(Sender: TObject);
>   VAR
>     Command: STRING;
> begin
>   Screen.Cursor := crHourGlass;
>   TRY
>     Command := 'CMD  BATCH  Sample.R  SampleOutput.txt';
>     StartRAndWait(Command);
>   FINALLY
>     Screen.Cursor := crDefault
>   END
> end;

Looks sensible to me.
> 
> 
> Sample.R file
> =====================
> sink('quantile.txt')
> quantile(0:100)
> sink()
> =====================
> 
> I used sink in the R script to isolate the output of the R quantile command 
> to help any parsing of the output:
> 
> SampleOutput.txt
> =====================
> R version 2.4.0 (2006-10-03)
> Copyright (C) 2006 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
>   Natural language support but running in an English locale
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
>> sink('quantile.txt')
>> quantile(0:100)
>> sink()
> 
> =====================
> 
> 
> quantile.txt
> =====================
>   0%  25%  50%  75% 100%
>    0   25   50   75  100
> =====================
> 
> 
> Tinn-R is written in Delphi, so its source code should be a great example of 
> a Delphi/R interface.  I've never studied the source code -- that's been on 
> my "to do" list for months --, but I'm guessing it uses RCOm, like 
> Hans-Peter suggested.  Nevertheless, Tom's example above may also be quite 
> useful.

That is a good suggestion.  I'll have to have a look at that.  Thank you!

Tom
> 
> efg
> 
> Earl F. Glynn
> Scientific Programmer
> Stowers Institute for Medical Research
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
+----------------------------------------------------------------+
| Tom Backer Johnsen, Psychometrics Unit,  Faculty of Psychology |
| University of Bergen, Christies gt. 12, N-5015 Bergen,  NORWAY |
| Tel : +47-5558-9185                        Fax : +47-5558-9879 |
| Email : backer at psych.uib.no    URL : http://www.galton.uib.no/ |
+----------------------------------------------------------------+



From bal44 at cornell.edu  Wed Dec  6 23:46:28 2006
From: bal44 at cornell.edu (Brooke LaFlamme)
Date: Wed, 6 Dec 2006 17:46:28 -0500 (EST)
Subject: [R] Adding terms to a function
Message-ID: <670629156.1165445188212.JavaMail.webber@orpheus6.dataserver.cornell.edu>

Hi all,

I am running R version 2.4.0 on Windows XP. I am new and have the following question:

I have a dataset of columns named x1, x2, x3...xn. I would like to write a linear regression using lm that looks like this:

lm(y~x1+x2+x3+...+xn)

If I try to use the following code, I only get the model for y~x1+xn:

 n<-ncol(dataset)
 	 model<-lm(y~x1)
	for(i in 1:n) {
		model.new<-update(model, .~.+dataset[,i])
		            }
The purpose of this is so I can use stepAIC with model.new as the upper scope and model as the lower. 

I know there must be a simple way to do this, but I am not yet familiar with much syntax. Any help appreciated!
--
Brooke LaFlamme
Cornell University



From blomsp at ozemail.com.au  Thu Dec  7 00:30:07 2006
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Thu, 07 Dec 2006 10:30:07 +1100
Subject: [R] Adding terms to a function
In-Reply-To: <670629156.1165445188212.JavaMail.webber@orpheus6.dataserver.cornell.edu>
References: <670629156.1165445188212.JavaMail.webber@orpheus6.dataserver.cornell.edu>
Message-ID: <4577527F.3000504@ozemail.com.au>

How about this:

form <- formula(paste("y ~", paste("x", 1:n, sep="",  collapse=" + ")))
model <- lm(form)

HTH,

Simon.

Brooke LaFlamme wrote:
> Hi all,
>
> I am running R version 2.4.0 on Windows XP. I am new and have the following question:
>
> I have a dataset of columns named x1, x2, x3...xn. I would like to write a linear regression using lm that looks like this:
>
> lm(y~x1+x2+x3+...+xn)
>
> If I try to use the following code, I only get the model for y~x1+xn:
>
>  n<-ncol(dataset)
>  	 model<-lm(y~x1)
> 	for(i in 1:n) {
> 		model.new<-update(model, .~.+dataset[,i])
> 		            }
> The purpose of this is so I can use stepAIC with model.new as the upper scope and model as the lower. 
>
> I know there must be a simple way to do this, but I am not yet familiar with much syntax. Any help appreciated!
> --
> Brooke LaFlamme
> Cornell University
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>   


-- 
Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat. 
Centre for Resource and Environmental Studies
The Australian National University              
Canberra ACT 0200                               
Australia                                       
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer 
can be extracted from a given body of data.
- John Tukey.



From pensterfuzzer at yahoo.de  Thu Dec  7 01:15:09 2006
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Thu, 7 Dec 2006 01:15:09 +0100 (CET)
Subject: [R] AIC for heckit
Message-ID: <467807.91212.qm@web23008.mail.ird.yahoo.com>

Thanks for the hint, Jay!
But somehow it seems like the included $probit object
is not of class glm and I 
couldn't find an AIC property on it. I tried it your
way. Any other suggestions 
regarding how I can evaluate the fit of the first-step
selection model included 
in heckit()?

Best,
   Werner


> From: "Jay Emerson" <jayemerson at gmail.com>
> Subject: Re: [R] AIC for heckit
> To: r-help at stat.math.ethz.ch
> Message-ID:
> 
<d4588dec0612010525s6d788716of30a1066eb50f4c2 at mail.gmail.com>
> Content-Type: text/plain
> 
>> > I have used the heckit function in micEcon.
>> > ...
>> > How can I then get the AIC for this model?
> 
> It appears that the heckit $probit object is of
class 'glm' and so, for
> example:
> 
> main.result <- heckit(whateveryouaredoing)        #
Do your heckit()...
> probit.result <- main.result$probit         # The
glm object produced by
> heckit()
> probit.aic <- probit.result$aic                 #
The AIC, see ?glm
> 
> should have what you need, ready to go.  I used
these tedious names and
> three lines of code just to be clear about what is
what (I wouldn't really
> do it this way).  !)
> 
> Jay
> 
> -- John W. Emerson (Jay) Assistant Professor of
Statistics Director of Graduate Studies Department of
Statistics Yale University
http://www.stat.yale.edu/~jay



From alexander.geisler at gmail.com  Thu Dec  7 01:20:49 2006
From: alexander.geisler at gmail.com (Alexander Geisler)
Date: Thu, 07 Dec 2006 01:20:49 +0100
Subject: [R] Simulation in R
Message-ID: <45775E61.2030802@gmail.com>

Hello!

I have the following problem.

My code:

--snip--

ergebnisse <- rep(0, each=2)
stichproben <- rep(0, each=2)

for (i in seq(1:2)) {
n <- dim(daten)[1]  	
ix <- sample(n,200) 	# producing samples
samp_i <- daten[ix,]  	
stichproben[i] <- samp_i     # doesn???t works

# Calculation of the model:
posterior_i <- MCMClogit(y ~ fbl.ind + fekq3 + febitda4 + fuvs + fkru + 
fzd + fur3, data=samp_i, b0=prior, B0=precision, tune=0.5) # calculation
ergebnisse[i] <- summary(posterior_i)  # saving the results (works)
}

--snip--

I have a data set called "daten". I produce samples of the size 200. The 
samples are saved in samp_i.

Question:
How is the easiest way to save this samples. My code doesn't work, only 
the first column of the sample samp_i is in stichproben[i]. I understand 
why.
My idea is to define a array stichproben and then save a matrix in the 
particular fields of the array. But things like
y <- matrix(c(samp_1),nrow=200, ncol=8)
and then saving y in the array stichproben doesn't work.
How is it possible to define a matrix with the content of my samples 
(samp_i) and but them into an array stichproben?
Or is there an easier way?

With kind regards
Alex

-- 
Alexander Geisler * Kaltenbach 151 * A-6272 Kaltenbach
email: alexander.geisler at gmx.at | alexander.geisler at gmail.com
phone: +43 650 / 811 61 90 | skpye: al1405ex



From etiennesky at yahoo.com  Thu Dec  7 01:43:21 2006
From: etiennesky at yahoo.com (Etienne)
Date: Wed, 6 Dec 2006 19:43:21 -0500 (EST)
Subject: [R] barplot - how to force vertical axis to cover entire plot area
Message-ID: <20061207004321.89150.qmail@web36903.mail.mud.yahoo.com>

I'm using barplot with the following call:
  
barplot(stat_data[[5]][,],axes=TRUE,axisnames=TRUE,axis.lty=1,xlab=xlab,ylab=ylab,beside=TRUE,las=1,font.lab=2,font.axis=1,legend.text=TRUE)

On some data, the vertical axis does not cover the
whole plot area and the last tick mark is smaller than
the maximum value.

I tried setting the ylim values but even with that,
some plots are still not OK, it just shrinks the
length of the bars.

Attached is a png example of the problem.  I hope it
gets through.

Thanks,
Etienne

__________________________________________________


-------------- next part --------------
A non-text attachment was scrubbed...
Name: precipday_mex_total.png
Type: image/png
Size: 3363 bytes
Desc: 1841399767-precipday_mex_total.png
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20061206/331cc872/attachment-0006.png 

From ggrothendieck at gmail.com  Thu Dec  7 03:41:38 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 6 Dec 2006 21:41:38 -0500
Subject: [R] Adding terms to a function
In-Reply-To: <670629156.1165445188212.JavaMail.webber@orpheus6.dataserver.cornell.edu>
References: <670629156.1165445188212.JavaMail.webber@orpheus6.dataserver.cornell.edu>
Message-ID: <971536df0612061841l72af2fb1i55a56a0e97a9396@mail.gmail.com>

Using the builtin anscombe data set try this where we note that
the first 4 columns are x1, ..., x4 and the fifth column is y1.

   for(i in 1:4) print(coef(lm(y1 ~., anscombe[c(1:i, 5)])))


On 12/6/06, Brooke LaFlamme <bal44 at cornell.edu> wrote:
> Hi all,
>
> I am running R version 2.4.0 on Windows XP. I am new and have the following question:
>
> I have a dataset of columns named x1, x2, x3...xn. I would like to write a linear regression using lm that looks like this:
>
> lm(y~x1+x2+x3+...+xn)
>
> If I try to use the following code, I only get the model for y~x1+xn:
>
>  n<-ncol(dataset)
>         model<-lm(y~x1)
>        for(i in 1:n) {
>                model.new<-update(model, .~.+dataset[,i])
>                            }
> The purpose of this is so I can use stepAIC with model.new as the upper scope and model as the lower.
>
> I know there must be a simple way to do this, but I am not yet familiar with much syntax. Any help appreciated!
> --
> Brooke LaFlamme
> Cornell University
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From o.samarasinghe at auckland.ac.nz  Thu Dec  7 05:03:35 2006
From: o.samarasinghe at auckland.ac.nz (Samarasinghe, Oshadhi Erandika)
Date: Thu, 7 Dec 2006 17:03:35 +1300
Subject: [R] Heteroscedasticity consistent standard errors for Spatial error
	models
Message-ID: <1E11F4042C05ED4BAA6BA96319DA56610FCE7ECE@comxchg1.com.auckland.ac.nz>

Hello,

Could anyone please tell me how to estimate Heteroscedasticity
Consistent standard errors for a Spatial error model? All the functions
I have looked at only works for lm objects.

Thank you very much!

- Oshadhi



From aiminy at iastate.edu  Thu Dec  7 06:15:28 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Wed, 06 Dec 2006 23:15:28 -0600
Subject: [R] change factor level 1,2,3 to red,blue,dark
Message-ID: <6.1.2.0.2.20061206231209.01c52590@aiminy.mail.iastate.edu>

I am new to R. Maybe this is very simple question.
I have a dataframe, there is column that is factor.
This factor has three level that 1,2,3.
Now I want to change these  level(1,2,3) to level(red,blue,dark).
Does anybody how to do this job?

Thank you very much

Aimin



From ethan.johnsons at gmail.com  Thu Dec  7 06:29:21 2006
From: ethan.johnsons at gmail.com (Ethan Johnsons)
Date: Thu, 7 Dec 2006 00:29:21 -0500
Subject: [R] Chi-Square Goodness-of-Fit test
In-Reply-To: <45759138.3020708@u.washington.edu>
References: <5cd96f050612041835w58408121id58bac82b03e34b6@mail.gmail.com>
	<4574E15A.7050607@ozemail.com.au>
	<91BD8318-8A1F-4D1B-99D4-BB324D9D53C5@u.washington.edu>
	<5cd96f050612042124t58ab54ecje6f00184a92ebe3a@mail.gmail.com>
	<45759138.3020708@u.washington.edu>
Message-ID: <5cd96f050612062129p5b3bc5dfx22e59100d9226272@mail.gmail.com>

By looking at R thread, it seems that the approach is:

(1) cut the data into bins (you can use hist() to do this);
(2) calculate the expected numbers in each bin using the differences
of the CDF (pnorm, pexp, etc.);
(3) calculate sum((exp-obs)^2/exp);
(4) find the tail probability of the chi-square distribution (pchisq).

I am a newbie in R.  Your help will be greatly appreciated.

Thx

ej

On 12/5/06, Don McKenzie <dmck at u.washington.edu> wrote:
> Ethan Johnsons wrote:
> > If we use this data as an example, does ks.test still valid?
> >
> > E.Coli Group    Observed    Expected
> > A    57    77.9
> > B    330    547.1
> > C    2132    2126.7
> > D    4584    4283.3
> > E    4604    4478.5
> > F    2119    2431.1
> > G    659    684.1
> > H    251    107.2
> You can use the test with any numeric data I believe.  Whether it is
> valid is more a question
> for a statistician than for R.   :-)
>
> Don
>
> --
> ___________________________________
>
> Don McKenzie, Research Ecologist
> Pacific Wildland Fire Sciences Lab
> USDA Forest Service
> 400 N 34th St. #201
> Seattle, WA 98103, USA
> (206) 732-7824
> donaldmckenzie at fs.fed.us
>
> Affiliate Assistant Professor
> College of Forest Resources
> CSES Climate Impacts Group
> University of Washington
> dmck at u.washington.edu
> __________________________________
>
>



From epistat at gmail.com  Thu Dec  7 06:41:14 2006
From: epistat at gmail.com (zhijie zhang)
Date: Thu, 7 Dec 2006 13:41:14 +0800
Subject: [R] errors when setting up R2.4.0-win32.exe
Message-ID: <2fc17e30612062141u5d8bbaf8rcce1902d8d13022c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061207/9f1b1292/attachment-0004.pl 

From amnakhan493 at gmail.com  Thu Dec  7 07:39:26 2006
From: amnakhan493 at gmail.com (amna khan)
Date: Thu, 7 Dec 2006 11:39:26 +0500
Subject: [R] Fwd: R-Help
In-Reply-To: <3ffd3bb60612060928t389f91f5t2f271b8fc38f5842@mail.gmail.com>
References: <3ffd3bb60612060928t389f91f5t2f271b8fc38f5842@mail.gmail.com>
Message-ID: <3ffd3bb60612062239v306b060g6c9c72199d52bfcd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061207/fce71397/attachment-0004.pl 

From vicctorr at gmail.com  Thu Dec  7 08:14:14 2006
From: vicctorr at gmail.com (victor)
Date: Thu, 07 Dec 2006 08:14:14 +0100
Subject: [R] intercept value in lme
In-Reply-To: <4576FE60.6070402@optonline.net>
References: <2323A6D37908A847A7C32F1E3662C80E6B0839@dc1ex01.air.org>
	<4576F8AF.1060804@gmail.com> <4576FE60.6070402@optonline.net>
Message-ID: <4577BF46.6070008@gmail.com>

Thanks to all of you!
Yes, you're right - I didn't take into consideration the ranges of 
predicors which are quite large. I think the matter over and realize 
that my assumption that something have to be wrong doesn't have in fact 
any reason except "strange" look of the value.
Centering helped (as suggested by Chuck) especially in interpretation 
and helped me to understand what is really going on in the model.

Thank you once again - these are my first experiences with R as like as 
with multilevel models, so... thank you for your patience!

Best regards,

victor

Chuck Cleland wrote:
> victor wrote:
>> It is boundend, you're right. In fact it is -25<=X<=0
>>
>> These are cross-national survey data (I was investigated 7 countries in 
>> each country there was 900-1700 cases).
>> In fact, there was two level 2 variables, so:
>>
>> m1<-lme(X~Y,~1|group,data=data,na.action=na.exclude,method="ML")
>> m2<-lme(X~Y+Z1+Z2,~1|group,data=data,na.action=na.exclude,method="ML")
>>
>> X is a life satisfaction factor combined from 2 other variables for each 
>> case separately, of course.
>> Y  - income per capita in household
>> Z1 - unemployment rate in a country.
>> Z2 - life expectancy in a country
>> group - country
> 
> Victor:
>   What happens if you center Y, Z1, and Z2 so that 0 corresponds to the
> mean for each?  As it is, zero is a very unusual value for each of these
> variables.  Do you really want to estimate the value of X when income =
> 0, unemployment = 0, and life expectancy = 0?  If I understand
> correctly, I think that's why the intercept value looks unusual to you.
> 
>> I attach a similar model where after adding Lev2 predictors intercept 
>> value is even 22!
>>
>> I'm sure there is my mistake somwhere but... what is wrong?
>>
>>
>>
>> Linear mixed-effects model fit by maximum likelihood
>>   Data: data
>>         AIC      BIC    logLik
>>    31140.77 31167.54 -15566.39
>>
>> Random effects:
>>   Formula: ~1 | country
>>          (Intercept) Residual
>> StdDev:   0.8698037 3.300206
>>
>> Fixed effects: X ~ Y
>>                  Value Std.Error   DF    t-value p-value
>> (Intercept) -4.397051 0.3345368 5944 -13.143698       0
>> Y           -0.000438 0.0000521 5944  -8.399448       0
>>   Correlation:
>>          (Intr)
>> Y       -0.13
>>
>> Standardized Within-Group Residuals:
>>         Min         Q1        Med         Q3        Max
>> -6.3855881 -0.5223116  0.2948941  0.6250717  2.6020180
>>
>> Number of Observations: 5952
>> Number of Groups: 7
>>
>>
>> and for the second model:
>>
>> Linear mixed-effects model fit by maximum likelihood
>>   Data: data
>>         AIC      BIC    logLik
>>    31133.08 31173.23 -15560.54
>>
>> Random effects:
>>   Formula: ~1 | country
>>          (Intercept) Residual
>> StdDev:   0.3631184 3.300201
>>
>> Fixed effects: X ~ Y + Z1 + Z2
>>                  Value Std.Error   DF   t-value p-value
>> (Intercept) 22.188828  4.912214 5944  4.517073  0.0000
>> Y           -0.000440  0.000052 5944 -8.456196  0.0000
>> Z1          -0.095532  0.037520    4 -2.546161  0.0636
>> Z2          -0.333549  0.062031    4 -5.377127  0.0058
>>   Correlation:
>>          (Intr) FAMPEC UNEMP
>> Y        0.168
>> Z1      -0.429  0.080
>> Z2      -0.997 -0.188  0.366
>>
>> Standardized Within-Group Residuals:
>>         Min         Q1        Med         Q3        Max
>> -6.3778888 -0.5291287  0.2963226  0.6260023  2.6226880
>>
>> Number of Observations: 5952
>> Number of Groups: 7
>>
>> Doran, Harold wrote:
>>> As Andrew noted, you need to provide more information. But, what I see
>>> is that your model assumes X is continuous but you say it is bounded,
>>> -25 < X < 0 
>>>
>>>> -----Original Message-----
>>>> From: r-help-bounces at stat.math.ethz.ch 
>>>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of victor
>>>> Sent: Wednesday, December 06, 2006 3:34 AM
>>>> To: r-help at stat.math.ethz.ch
>>>> Subject: [R] intercept value in lme
>>>>
>>>> Dear all,
>>>>
>>>> I've got a problem in fitting multilevel model in lme. I 
>>>> don't know to much about that but suspect that something is 
>>>> wrong with my model.
>>>>
>>>> I'm trying to fit:
>>>>
>>>> m1<-lme(X~Y,~1|group,data=data,na.action=na.exclude,method="ML")
>>>> m2<-lme(X~Y+Z,~1|group,data=data,na.action=na.exclude,method="ML")
>>>>
>>>> where:
>>>> X - dependent var. measured on a scale ranging from -25 to 0 
>>>> Y - level 1 variable Z - level 1 variable
>>>>
>>>> In m1 the intercept value is equal -3, in m2 (that is after 
>>>> adding Lev 2
>>>> var.) is equal +16.
>>>>
>>>> What can be wrong with my variables? Is this possible that 
>>>> intercept value exceeds scale?
>>>>
>>>> Best regards,
>>>>
>>>> victor
>>>>
>>>> ______________________________________________
>>>> R-help at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide 
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>



From ripley at stats.ox.ac.uk  Thu Dec  7 08:19:51 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 7 Dec 2006 07:19:51 +0000 (GMT)
Subject: [R] POSIX and summer savings time
In-Reply-To: <4577086F.2070600@lungall.gu.se>
References: <4577086F.2070600@lungall.gu.se>
Message-ID: <Pine.LNX.4.64.0612070712210.7251@gannet.stats.ox.ac.uk>

On Wed, 6 Dec 2006, Derek Eder wrote:

> I have a time stamp in UTC (GMT) time:
>
> >  format(ISOdatetime(1970,1,1,0,0,0)+1165398135729/1000,"%Y-%m-%d
> %H:%M:%OS3")
>
> "2006-12-06 09:42:18.823"  (note millisecond accuracy, but not relevant
> to question here)

But it is the wrong answer, and not what my system gives.

> Now, this time stamp actually "happened" at local (Swedish) time one
> hour later (10:42).

So you need to tell R that it was in UTC, which is what the 'tz' argument 
is for:

> (z <- ISOdatetime(1970,1,1,0,0,0, tz="UTC")+1165398135729/1000)
[1] "2006-12-06 09:42:15 UTC"
> format(z, "%Y-%m-%d %H:%M:%OS3", tz="CET")
[1] "2006-12-06 10:42:15.729"

> Regarding summer/winter adjustments in time ("spring forward, fall
> back"):   Is there a way of automatically recovering the local time
> adjustments for a given date?  E.g., a date/time in springtime = GMT +2
> , else GMT +1

Is the above not enough?  You can unpick it if you want to get the shift.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Dec  7 08:26:43 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 7 Dec 2006 07:26:43 +0000 (GMT)
Subject: [R] Standar errors arma models
In-Reply-To: <web-8458391@mailadmin.colpos.mx>
References: <web-8458391@mailadmin.colpos.mx>
Message-ID: <Pine.LNX.4.64.0612070721290.7251@gannet.stats.ox.ac.uk>

On Wed, 6 Dec 2006, Paulino Perez Rodriguez wrote:

>
> Why the standadard errors of the coefficientes of the arma
> models fited by using the arima procedure in the stats
> package doesnt coincide with that of S+, minitab or SAS?

Possibly because R is using superior methodology (full ML fitting).
Note that the help page says:

      The results are likely to be different from S-PLUS's 'arima.mle',
      which computes a conditional likelihood and does not include a
      mean in the model.  Further, the convention used by 'arima.mle'
      reverses the signs of the MA coefficients.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From petr.pikal at precheza.cz  Thu Dec  7 08:28:22 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 07 Dec 2006 08:28:22 +0100
Subject: [R] Simulation in R
In-Reply-To: <45775E61.2030802@gmail.com>
Message-ID: <4577D0A6.21121.440043@localhost>

Hi

On 7 Dec 2006 at 1:20, Alexander Geisler wrote:

Date sent:      	Thu, 07 Dec 2006 01:20:49 +0100
From:           	Alexander Geisler <alexander.geisler at gmail.com>
To:             	r-help at stat.math.ethz.ch
Subject:        	[R] Simulation in R

> Hello!
> 
> I have the following problem.
> 
> My code:
> 
> --snip--
> 
> ergebnisse <- rep(0, each=2)
> stichproben <- rep(0, each=2)
> 
> for (i in seq(1:2)) {
> n <- dim(daten)[1]  	
> ix <- sample(n,200) 	# producing samples
> samp_i <- daten[ix,]  	
> stichproben[i] <- samp_i     # doesn??????t works

If I understand your code correctly, you could use list.

stichproben <-vector("list",2)
and
stichproben[[i]] <- samp_i

> 
> # Calculation of the model:
> posterior_i <- MCMClogit(y ~ fbl.ind + fekq3 + febitda4 + fuvs + fkru
> + fzd + fur3, data=samp_i, b0=prior, B0=precision, tune=0.5) #
> calculation ergebnisse[i] <- summary(posterior_i)  # saving the
> results (works) }
> 
> --snip--
> 
> I have a data set called "daten". I produce samples of the size 200.
> The samples are saved in samp_i.
> 
> Question:
> How is the easiest way to save this samples. My code doesn't work,
> only the first column of the sample samp_i is in stichproben[i]. I
> understand why. My idea is to define a array stichproben and then save
> a matrix in the particular fields of the array. But things like y <-
> matrix(c(samp_1),nrow=200, ncol=8) and then saving y in the array
> stichproben doesn't work. How is it possible to define a matrix with
> the content of my samples (samp_i) and but them into an array
> stichproben? Or is there an easier way?

Try to look into some documentation to matrix and array. These have 
limitations that values have to be the same type, but are usually 
faster to manipulate than data frame. The behavior of objects and 
assignments depends on nature of objects. The complexity of objects 
increases in a row

vector < matrix < array < data.frame < list

and similarly changes possible ways of indexing and susetting

HTH
Petr

> 
> With kind regards
> Alex
> 
> -- 
> Alexander Geisler * Kaltenbach 151 * A-6272 Kaltenbach
> email: alexander.geisler at gmx.at | alexander.geisler at gmail.com
> phone: +43 650 / 811 61 90 | skpye: al1405ex
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

Petr Pikal
petr.pikal at precheza.cz



From Achim.Zeileis at wu-wien.ac.at  Thu Dec  7 08:47:18 2006
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Thu, 7 Dec 2006 08:47:18 +0100 (CET)
Subject: [R] Heteroscedasticity consistent standard errors for Spatial
 error	models
In-Reply-To: <1E11F4042C05ED4BAA6BA96319DA56610FCE7ECE@comxchg1.com.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0612070838390.5722-100000@disco.wu-wien.ac.at>

On Thu, 7 Dec 2006, Samarasinghe, Oshadhi Erandika wrote:

> Hello,
>
> Could anyone please tell me how to estimate Heteroscedasticity
> Consistent standard errors for a Spatial error model? All the functions
> I have looked at only works for lm objects.

I assume that you looked also at the "sandwich" package: The methods there
do not only work for "lm" objects but are object-oriented, appropriate
methods are already provided for a range of different object classes. So,
in principle, you can plug in other models as well, potentially including
spatial models if appropriate methods are provided. See
  vignette("sandwich-OOP", package = "sandwich")

Disclaimer: I'm not sure whether the spatial structure of spatial models
will be appropriately captured by the class of estimators implemented in
"sandwich". But someone who knows spatial models and their HC covariances
should be able to figure that out from the vignette above. I'm also not
sure what specialized methods exist...

Best,
Z


> Thank you very much!
>
> - Oshadhi
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>



From GORDIJN_E at schiphol.nl  Thu Dec  7 08:48:45 2006
From: GORDIJN_E at schiphol.nl (E. Gordijn)
Date: Thu, 07 Dec 2006 08:48:45 +0100
Subject: [R] Splitting a dataframe at the results of tapply
Message-ID: <4577D56C.04A9.00D8.0@schiphol.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061207/75283bd2/attachment-0005.pl 

From ligges at statistik.uni-dortmund.de  Thu Dec  7 09:51:17 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 07 Dec 2006 09:51:17 +0100
Subject: [R] Fwd: R-Help
In-Reply-To: <3ffd3bb60612062239v306b060g6c9c72199d52bfcd@mail.gmail.com>
References: <3ffd3bb60612060928t389f91f5t2f271b8fc38f5842@mail.gmail.com>
	<3ffd3bb60612062239v306b060g6c9c72199d52bfcd@mail.gmail.com>
Message-ID: <4577D605.8040306@statistik.uni-dortmund.de>

Why do you repost this request to R-help?
I already pointed you to the package maintainer!

Uwe Ligges

amna khan wrote:
> ---------- Forwarded message ----------
> From: amna khan <amnakhan493 at gmail.com>
> Date: Dec 6, 2006 10:28 PM
> Subject: R-Help
> To: R-help at lists.r-project.org
> 
> Respected Sir
> I am a very new user of R. I want to ask a question about "the nortest
> package". In this package how we can write the code of ad.test, cvm.test,
> ks.test for other distributions like GEV, GPA etc.
> 
> I request you to please  guide to me.
> Kind Regards
> AMNA
>



From dimitris.rizopoulos at med.kuleuven.be  Thu Dec  7 10:08:08 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Thu, 7 Dec 2006 10:08:08 +0100
Subject: [R] Splitting a dataframe at the results of tapply
References: <4577D56C.04A9.00D8.0@schiphol.nl>
Message-ID: <004901c719df$36b1c590$0540210a@www.domain>

try this:

dat <- data.frame(Id, Noise, Height)
##############
dat <- dat[order(dat$Id), ]
ind <- unlist(tapply(dat$Noise, dat$Id, function(x) x == max(x)))
dat[ind, ]
dat[!ind, ]


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "E. Gordijn" <GORDIJN_E at schiphol.nl>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, December 07, 2006 8:48 AM
Subject: [R] Splitting a dataframe at the results of tapply


>I have got a dataframe containing measurement of aircraft noise like
> this:
>
>> Id <- c(1,4,5,2,3,6,4,1,2,5,6,3)
>> Noise <- c(88,94,97,98,92,56,103,102,87,95,92,97)
>> Height <- c(190, 150, 120, 115, 188, 104, 101, 189, 146, 111, 124,
> 126)
>>
>> df <- data.frame(Id, Noise, Height)
> Now I would like to split this in two new dataframes. The first one
> containing the rows with the maximum Noise for each Id and in the 
> second
> the other rows.
>
> I manage to find that maximum Noise levels...
>
>> m <- tapply(df$Noise, Id.factor, max)
>> m
>   1   2   3   4   5   6
> 102  98  97 103  97  92
>
> But how do I split my dataframe?
>
>
> -- 
>    Ed Gordijn
>    Adviseur geluidscapaciteit
>
>    Amsterdam Airport Schiphol
>    Business Area Aviation (A/CAP/EC)
>    Postbus 7501,  1118 ZG  Schiphol
>    Bezoekadres: Evert v/d Beekstraat 202, 1118 CP  Schiphol
>
>    tel       020 601 32 22
>    fax      020 601 21 34
>    e-mail  gordijn_e at schiphol.nl
>
>    meer informatie is te vinden op www.schiphol.nl
> --
>
>
> -------------------------------------------------------------------
> This e-mail may contain confidential and privileged 
> material...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From Roger.Bivand at nhh.no  Thu Dec  7 10:18:16 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 7 Dec 2006 10:18:16 +0100 (CET)
Subject: [R] Heteroscedasticity consistent standard errors for Spatial
 error	models
In-Reply-To: <Pine.LNX.4.44.0612070838390.5722-100000@disco.wu-wien.ac.at>
Message-ID: <Pine.LNX.4.44.0612071010590.12632-100000@reclus.nhh.no>

On Thu, 7 Dec 2006, Achim Zeileis wrote:

> On Thu, 7 Dec 2006, Samarasinghe, Oshadhi Erandika wrote:
> 
> > Hello,
> >
> > Could anyone please tell me how to estimate Heteroscedasticity
> > Consistent standard errors for a Spatial error model? All the functions
> > I have looked at only works for lm objects.
> 
> I assume that you looked also at the "sandwich" package: The methods there
> do not only work for "lm" objects but are object-oriented, appropriate
> methods are already provided for a range of different object classes. So,
> in principle, you can plug in other models as well, potentially including
> spatial models if appropriate methods are provided. See
>   vignette("sandwich-OOP", package = "sandwich")
> 
> Disclaimer: I'm not sure whether the spatial structure of spatial models
> will be appropriately captured by the class of estimators implemented in
> "sandwich". But someone who knows spatial models and their HC covariances
> should be able to figure that out from the vignette above. I'm also not
> sure what specialized methods exist...

Typically, the use of HC covariances with these kinds of models is an 
inappropriate fix for missing variables and possibly also wrong functional 
forms. Some supervisors want them, but in practice fitting a better 
specified model is superior. It is also possible to sample from the fitted 
model - I've been looking at MH sampling from MCMCpack - and that I feel 
is a way to go if the model is badly specified and you can't do anything 
about it. 

Settings where "natural experiments" exist are also very helpful, with
shifts in coefficient values and/or standard errors indicating whether the
hypothesised cause of difference actually had an effect.

It can probably be done, and some journals/referees/supervisors etc. want 
HC covariances, but I'm afraid that doesn't necessarily mean that they are 
any use in practice with these pretty rough kinds of models.

Roger

> 
> Best,
> Z
> 
> 
> > Thank you very much!
> >
> > - Oshadhi
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From justin_bem at yahoo.fr  Thu Dec  7 10:21:28 2006
From: justin_bem at yahoo.fr (justin bem)
Date: Thu, 7 Dec 2006 09:21:28 +0000 (GMT)
Subject: [R]  Simulation in R
Message-ID: <20061207092128.36360.qmail@web23001.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061207/6f5dbe9e/attachment-0005.pl 

From p.dalgaard at biostat.ku.dk  Thu Dec  7 10:34:23 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 07 Dec 2006 10:34:23 +0100
Subject: [R] errors when setting up R2.4.0-win32.exe
In-Reply-To: <2fc17e30612062141u5d8bbaf8rcce1902d8d13022c@mail.gmail.com>
References: <2fc17e30612062141u5d8bbaf8rcce1902d8d13022c@mail.gmail.com>
Message-ID: <4577E01F.6090104@biostat.ku.dk>

zhijie zhang wrote:
> Dear Ruser,
>   Today, i download R2.4.0-win32.exe, but can't set it up successfully. The
> error informaiton is :
> *"0x000038e4"memory quoted by "ox6c7f22b3" can't be "readonly".*
> My operating system in WindowXP. Where goes wrong?
> Thanks.
>
>
>   
If your computer is speaking Chinese, then this may be due to a bug that 
was fixed in R-patched. At this point in time, you might as well try out 
the test build of 2.4.1 beta, at

http://cran.r-project.org/bin/windows/base/rtest.html



From info at aghmed.fsnet.co.uk  Thu Dec  7 10:53:47 2006
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 07 Dec 2006 09:53:47 +0000
Subject: [R] beginning my R-learning
In-Reply-To: <6.0.3.0.0.20061204141530.01e1a960@pop.sbcglobal.yahoo.com>
References: <6.0.3.0.0.20061204141530.01e1a960@pop.sbcglobal.yahoo.com>
Message-ID: <7.0.0.16.0.20061207094809.019aa198@aghmed.fsnet.co.uk>

At 22:16 04/12/2006, Michael McCulloch wrote:
>Hello,
>I'm just beginning to learn R. What books/online learning modules 
>with datasets would you suggest?
>Thank you!

If
a) you already know some statistics
b) you want to use R as a tool in your applied statistical work
then
@BOOK{venables02,
   author = {Venables, W N and Ripley, B D},
   year = 2002,
   title = {Modern applied statistics with {S}},
   publisher = {Springer-Verlag},
   address = {New York},
   keywords = {statistics, general, software}
}
is worth considering. It is quite terse though (it is one of the few 
books I have which I wish were longer) and not so suitable if you are 
also learning statistics at the same time.



>Best wishes,
>Michael
>
>
>____________________________________
>
>Michael McCulloch
>Pine Street Clinic
>Pine Street Foundation
>124 Pine Street, San Anselmo, CA 94960-2674
>tel     415.407.1357
>fax     415.485.1065
>email:  mm at pinest.org
>web:    www.pinest.org
>         www.pinestreetfoundation.org
>         www.medepi.net/meta
>
>

Michael Dewey
http://www.aghmed.fsnet.co.uk



From GORDIJN_E at schiphol.nl  Thu Dec  7 11:15:42 2006
From: GORDIJN_E at schiphol.nl (E. Gordijn)
Date: Thu, 07 Dec 2006 11:15:42 +0100
Subject: [R] Betr.: Re:  Splitting a dataframe at the results of tapply
In-Reply-To: <004901c719df$36b1c590$0540210a@www.domain>
References: <4577D56C.04A9.00D8.0@schiphol.nl>
	<004901c719df$36b1c590$0540210a@www.domain>
Message-ID: <4577F7DD.04A9.00D8.0@schiphol.nl>

Hi Dimitris,

This works fine.

Thanks!, Ed
-- 

-- 
    Ed Gordijn
    Adviseur geluidscapaciteit

    Amsterdam Airport Schiphol
    Business Area Aviation (A/CAP/EC)
    Postbus 7501,  1118 ZG  Schiphol 
    Bezoekadres: Evert v/d Beekstraat 202, 1118 CP  Schiphol

    tel       020 601 32 22
    fax      020 601 21 34
    e-mail  gordijn_e at schiphol.nl 

    meer informatie is te vinden op www.schiphol.nl 
--


-------------------------------------------------------------------
This e-mail may contain confidential and privileged material...{{dropped}}



From derek.eder at lungall.gu.se  Thu Dec  7 11:16:32 2006
From: derek.eder at lungall.gu.se (Derek Eder)
Date: Thu, 07 Dec 2006 11:16:32 +0100
Subject: [R]  POSIX and summer savings time redux
In-Reply-To: <Pine.LNX.4.64.0612070712210.7251@gannet.stats.ox.ac.uk>
References: <4577086F.2070600@lungall.gu.se>
	<Pine.LNX.4.64.0612070712210.7251@gannet.stats.ox.ac.uk>
Message-ID: <4577EA00.4000800@lungall.gu.se>

When I tried Professor Ripley's example (below), the "tz" argument 
failed to adjust clock time from UTC.

 > (z <- ISOdatetime(1970,1,1,0,0,0, tz="UTC")+1165398135729/1000)
[1] "2006-12-06 09:42:15 UTC"


 > format(z, "%Y-%m-%d %H:%M:%OS3",tz = "CET")
[1] "2006-12-06 09:42:15.729"
# expected CET (Central European Time) clock time is UTC + 1 hour time 
zone adjustment


Am I running into platform dependencies?

(my platform)
platform       i386-pc-mingw32            
arch           i386                       
os             mingw32                    
system         i386, mingw32              
status                                    
major          2                          
minor          4.0                        
year           2006                       
month          10                         
day            03                         
svn rev        39566                      
language       R                          
version.string R version 2.4.0 (2006-10-03)


Thank you most sincerely,

Derek Eder



Prof Brian Ripley wrote:
> On Wed, 6 Dec 2006, Derek Eder wrote:
>
>> I have a time stamp in UTC (GMT) time:
>>
>> >  format(ISOdatetime(1970,1,1,0,0,0)+1165398135729/1000,"%Y-%m-%d
>> %H:%M:%OS3")
>>
>> "2006-12-06 09:42:18.823"  (note millisecond accuracy, but not relevant
>> to question here)
>
> But it is the wrong answer, and not what my system gives.
>
>> Now, this time stamp actually "happened" at local (Swedish) time one
>> hour later (10:42).
>
> So you need to tell R that it was in UTC, which is what the 'tz' 
> argument is for:
>
>> (z <- ISOdatetime(1970,1,1,0,0,0, tz="UTC")+1165398135729/1000)
> [1] "2006-12-06 09:42:15 UTC"
>> format(z, "%Y-%m-%d %H:%M:%OS3", tz="CET")
> [1] "2006-12-06 10:42:15.729"
>
>> Regarding summer/winter adjustments in time ("spring forward, fall
>> back"):   Is there a way of automatically recovering the local time
>> adjustments for a given date?  E.g., a date/time in springtime = GMT +2
>> , else GMT +1
>
> Is the above not enough?  You can unpick it if you want to get the shift.
>


-- 
Derek N. Eder

Gothenburg University 
VINKLA - Vigilance and Neurocognition laboratory 

SU/Sahlgrenska
Utvecklingslab 1, Med
Gr?na str?ket 8
SE 413 45 G?teborg (Gothenburg)
Sverige (Sweden)

+46 (031)* 342 8261 (28261 inom Sahlgrenska)
+46 0704 915 714 (mobile)
+46 (031) 25 97 07 (home)

* omit the 0 when calling from outside Sweden



From dan.bebber at plants.ox.ac.uk  Thu Dec  7 12:08:49 2006
From: dan.bebber at plants.ox.ac.uk (Dan Bebber)
Date: Thu, 7 Dec 2006 11:08:49 -0000
Subject: [R] lmer, p-values and all that
Message-ID: <000801c719f0$12779220$d22401a3@plants.ox.ac.uk>

Hello,
I've just located the illuminating explanation by Douglas Bates on degrees 
of freedom in mixed models.
The take-home message appears to be: don't trust the p-values from lme.
Questions:
Should I give up hypothesis testing for fixed effects terms in mixed models?
Has my time spent reading Pinheiro & Bates been in vain?
Is there a publication on this issue?

Thanks,
Dan Bebber

Department of Plant Sciences
University of Oxford



From ripley at stats.ox.ac.uk  Thu Dec  7 12:09:54 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 7 Dec 2006 11:09:54 +0000 (GMT)
Subject: [R] POSIX and summer savings time redux
In-Reply-To: <4577EA00.4000800@lungall.gu.se>
References: <4577086F.2070600@lungall.gu.se>
	<Pine.LNX.4.64.0612070712210.7251@gannet.stats.ox.ac.uk>
	<4577EA00.4000800@lungall.gu.se>
Message-ID: <Pine.LNX.4.64.0612071101220.10578@gannet.stats.ox.ac.uk>

CET is not a valid timezone *on Windows*: please do RTFM.
E.g. ?Sys.timezone says

      'Sys.timezone' returns an OS-specific character string, possibly
      an empty string.  It may be possible to set the timezone via the
      environment variable '"TZ"': see 'as.POSIXlt'. Windows is
      notorious for naming its timezones differently from the official
      names.

and ?as.POSIXlt points you at

      a specification of the form 'GST-1GDT',

which seems to be the same as CET, and that works on my Windows laptop.
It is also possible that tz="" works for you: it seems to for me when I 
set my machine to CET.

On Thu, 7 Dec 2006, Derek Eder wrote:

> When I tried Professor Ripley's example (below), the "tz" argument
> failed to adjust clock time from UTC.
>
> > (z <- ISOdatetime(1970,1,1,0,0,0, tz="UTC")+1165398135729/1000)
> [1] "2006-12-06 09:42:15 UTC"
>
>
> > format(z, "%Y-%m-%d %H:%M:%OS3",tz = "CET")
> [1] "2006-12-06 09:42:15.729"
> # expected CET (Central European Time) clock time is UTC + 1 hour time
> zone adjustment
>
>
> Am I running into platform dependencies?
>
> (my platform)
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          4.0
> year           2006
> month          10
> day            03
> svn rev        39566
> language       R
> version.string R version 2.4.0 (2006-10-03)
>
>
> Thank you most sincerely,
>
> Derek Eder
>
>
>
> Prof Brian Ripley wrote:
>> On Wed, 6 Dec 2006, Derek Eder wrote:
>>
>>> I have a time stamp in UTC (GMT) time:
>>>
>>>>  format(ISOdatetime(1970,1,1,0,0,0)+1165398135729/1000,"%Y-%m-%d
>>> %H:%M:%OS3")
>>>
>>> "2006-12-06 09:42:18.823"  (note millisecond accuracy, but not relevant
>>> to question here)
>>
>> But it is the wrong answer, and not what my system gives.
>>
>>> Now, this time stamp actually "happened" at local (Swedish) time one
>>> hour later (10:42).
>>
>> So you need to tell R that it was in UTC, which is what the 'tz'
>> argument is for:
>>
>>> (z <- ISOdatetime(1970,1,1,0,0,0, tz="UTC")+1165398135729/1000)
>> [1] "2006-12-06 09:42:15 UTC"
>>> format(z, "%Y-%m-%d %H:%M:%OS3", tz="CET")
>> [1] "2006-12-06 10:42:15.729"
>>
>>> Regarding summer/winter adjustments in time ("spring forward, fall
>>> back"):   Is there a way of automatically recovering the local time
>>> adjustments for a given date?  E.g., a date/time in springtime = GMT +2
>>> , else GMT +1
>>
>> Is the above not enough?  You can unpick it if you want to get the shift.
>>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Thu Dec  7 12:09:30 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 07 Dec 2006 12:09:30 +0100
Subject: [R] barplot - how to force vertical axis to cover entire plot
 area
In-Reply-To: <20061207004321.89150.qmail@web36903.mail.mud.yahoo.com>
References: <20061207004321.89150.qmail@web36903.mail.mud.yahoo.com>
Message-ID: <4577F66A.3010405@statistik.uni-dortmund.de>



Etienne wrote:
> I'm using barplot with the following call:
>   
> barplot(stat_data[[5]][,],axes=TRUE,axisnames=TRUE,axis.lty=1,xlab=xlab,ylab=ylab,beside=TRUE,las=1,font.lab=2,font.axis=1,legend.text=TRUE)


The example is not reproducible and poorly formatted. Please read the 
posting guide.


> On some data, the vertical axis does not cover the
> whole plot area and the last tick mark is smaller than
> the maximum value.
> 
> I tried setting the ylim values but even with that,
> some plots are still not OK, it just shrinks the
> length of the bars.


R tries to make the plot pretty, i.e. stop with some tick mark like 200, 
but not e.g. 242.

Perhaps you want to make a box() around the plot?


Uwe Ligges



> Attached is a png example of the problem.  I hope it
> gets through.
> 
> Thanks,
> Etienne
> 
> __________________________________________________
> 
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ligges at statistik.uni-dortmund.de  Thu Dec  7 12:10:38 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 07 Dec 2006 12:10:38 +0100
Subject: [R] change factor level 1,2,3 to red,blue,dark
In-Reply-To: <6.1.2.0.2.20061206231209.01c52590@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061206231209.01c52590@aiminy.mail.iastate.edu>
Message-ID: <4577F6AE.8070807@statistik.uni-dortmund.de>



Aimin Yan wrote:
> I am new to R. Maybe this is very simple question.
> I have a dataframe, there is column that is factor.
> This factor has three level that 1,2,3.
> Now I want to change these  level(1,2,3) to level(red,blue,dark).
> Does anybody how to do this job?


levels(dataframe$column) <- c("red", "blue", "dark")

Uwe Ligges

> Thank you very much
> 
> Aimin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From gregor.gorjanc at bfro.uni-lj.si  Thu Dec  7 12:10:52 2006
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Thu, 7 Dec 2006 11:10:52 +0000 (UTC)
Subject: [R] change factor level 1,2,3 to red,blue,dark
References: <6.1.2.0.2.20061206231209.01c52590@aiminy.mail.iastate.edu>
Message-ID: <loom.20061207T120744-401@post.gmane.org>

Aimin Yan <aiminy <at> iastate.edu> writes:
> I am new to R. Maybe this is very simple question.
> I have a dataframe, there is column that is factor.
> This factor has three level that 1,2,3.
> Now I want to change these  level(1,2,3) to level(red,blue,dark).
> Does anybody how to do this job?

levels() help page has entry about this. Try

x <- factor(round(runif(n=10, min=1, max=3)))
x
 [1] 3 1 1 3 1 2 2 2 1 2
Levels: 1 2 3

levels(x) <- list(red=c(1), blue=c(2), dark=c(3))
x
 [1] dark red  red  dark red  blue blue blue red  blue
Levels: red blue dark

You have factor in data.frame, so you have to use

levels(myDF$x) <- ...


Gregor



From ruhil at ohio.edu  Thu Dec  7 12:42:29 2006
From: ruhil at ohio.edu (Anirudh V. S. Ruhil)
Date: Thu, 07 Dec 2006 06:42:29 -0500
Subject: [R] Calculating distance given coordinates
Message-ID: <EC249BE24D248A01608928A3@[192.168.1.105]>

Given the following data (see below) on nest locations (fid.albers = 149, 
148, etc.), I need to (a) calculate the distance between all fid pairs, and 
(b) flag all nests within an user-specified radius. What syntax will 
accomplish both tasks? If it helps, I have the nest locations as eastings 
and northings as well but thought better of estimating distance by 
calculating the root of the hypotenuse between all nest pairs.

     x.albers y.albers fid.albers
[1,]   723557   671748        149
[2,]   723384   671867        148
[3,]   723375   671757        147
[4,]   723363   671824        146

best

Ani

Anirudh V. S. Ruhil, Ph.D.
Sr. Research Associate
Voinovich Center for Leadership and Public Affairs
Ohio University
Building 21, The Ridges
Athens, OH 45701-2979
Tel: 740.597.1949 | Fax: 740.597.3057



From ibrahimmutlay at gmail.com  Thu Dec  7 13:19:29 2006
From: ibrahimmutlay at gmail.com (=?ISO-8859-9?Q?=DDbrahim_Mutlay?=)
Date: Thu, 7 Dec 2006 07:19:29 -0500
Subject: [R] Taguchi Design
Message-ID: <eb21cbcd0612070419r450211fewb20051c89d6799a5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061207/7233af6f/attachment-0005.pl 

From Philip.Leifeld at gmx.de  Thu Dec  7 13:27:33 2006
From: Philip.Leifeld at gmx.de (Philip Leifeld)
Date: Thu, 07 Dec 2006 13:27:33 +0100
Subject: [R] incidence and adjacency matrix conversion
In-Reply-To: <815b70590612051417ga74d036g12822d94e7ec8189@mail.gmail.com>
References: <4575E4DA.6040808@uni-konstanz.de>
	<815b70590612051417ga74d036g12822d94e7ec8189@mail.gmail.com>
Message-ID: <457808B5.7020902@gmx.de>

Thanks, David. I tried converting my rectangular matrix to a network 
object and then back to a square matrix. This works for a small 
artificial dataset (e.g. 2x5), but when I try this on my 1790x45 or 
transposed 45x1790 matrix, R keeps working for a couple of minutes and 
then crashes completely without having saved any data first. I assume 
something is wrong with my data?

Cheers
Philip

David Barron wrote:
> I think you can do this using the network package.  Look at the
> as.network.matrix and as.matrix.network functions, for example.
> 
>> how can I convert an m x n incidence matrix into an m x m adjacency
>> matrix or an n x n adjacency matrix? The current matrix contains binary
>> data, hence the new matrix would contain counts of common occurrences.



From ibrahimmutlay at gmail.com  Thu Dec  7 14:10:27 2006
From: ibrahimmutlay at gmail.com (=?ISO-8859-9?Q?=DDbrahim_Mutlay?=)
Date: Thu, 7 Dec 2006 08:10:27 -0500
Subject: [R] Taguchi Design
In-Reply-To: <45780B2E.203@optonline.net>
References: <eb21cbcd0612070419r450211fewb20051c89d6799a5@mail.gmail.com>
	<45780B2E.203@optonline.net>
Message-ID: <eb21cbcd0612070510v221bc70dy68b0f197a1794633@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061207/80c0c577/attachment-0005.pl 

From gsmatos1 at ig.com.br  Thu Dec  7 14:16:55 2006
From: gsmatos1 at ig.com.br (gsmatos1)
Date: Thu, 7 Dec 2006 10:16:55 -0300
Subject: [R] Help to understand an Error using summary to an mcmc object
Message-ID: <20061207_131655_097018.gsmatos1@ig.com.br>

Hi, 

I used the MCMCirtKd function of MCMCpack: 

posterior2 <- MCMCirtKd(data, dimensions = 2, 
+                    burnin = 5000, mcmc = 50000, thin = 10, 
+ verbose = 10000, B0 = .25, store.item = TRUE, item.constraints = 
beta.constraints) 

And after apply the comand summary() I got some erros and warnings that I 
could not understand: 

summary.posterior2 <- summary(posterior2) 

Error: NA/NaN/Inf in foreign function call (arg 1) 
In addition: Warning messages: 
1: algorithm did not converge in: glm.fit(x = X, y = Y, weights = weights, 
start = start, etastart = etastart, 
2: step size truncated due to divergence 
Error: NA/NaN/Inf in foreign function call (arg 1) 
In addition: There were 42 warnings (use warnings() to see them) 
Error: NA/NaN/Inf in foreign function call (arg 1) 
In addition: There were 35 warnings (use warnings() to see them) 
Error in glm.fit(x = X, y = Y, weights = weights, start = start, etastart = 
etastart,  : 
        inner loop 1; cannot correct step size 
In addition: There were 49 warnings (use warnings() to see them) 
Error: NA/NaN/Inf in foreign function call (arg 1) 
In addition: Warning messages: 
1: algorithm did not converge in: glm.fit(x = X, y = Y, weights = weights, 
start = start, etastart = etastart, 
2: algorithm did not converge in: glm.fit(x = X, y = Y, weights = weights, 
start = start, etastart = etastart, 
3: algorithm did not converge in: glm.fit(x = X, y = Y, weights = weights, 
start = start, etastart = etastart, 
4: algorithm did not converge in: glm.fit(x = X, y = Y, weights = weights, 
start = start, etastart = etastart, 
5: algorithm did not converge in: glm.fit(x = X, y = Y, weights = weights, 
start = start, etastart = etastart, 
6: algorithm did not converge in: glm.fit(x = X, y = Y, weights = weights, 
start = start, etastart = etastart, 
7: algorithm did not converge in: glm.fit(x = X, y = Y, weights = weights, 
start = start, etastart = etastart, 
8: step size truncated due to divergence 
Error: NA/NaN/Inf in foreign function call (arg 1) 
In addition: There were 29 warnings (use warnings() to see them) 

Thanks for any comment. 
Gilberto Matos. 



From megh700004 at yahoo.com  Thu Dec  7 09:35:07 2006
From: megh700004 at yahoo.com (Megh Dal)
Date: Thu, 7 Dec 2006 00:35:07 -0800 (PST)
Subject: [R] Merging two data sets
Message-ID: <841799.12620.qm@web58115.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061207/692873d9/attachment-0005.pl 

From tamir at imp.univie.ac.at  Thu Dec  7 14:45:52 2006
From: tamir at imp.univie.ac.at (Ido M. Tamir)
Date: Thu, 7 Dec 2006 14:45:52 +0100
Subject: [R] templating library for R
Message-ID: <200612071445.52698.tamir@imp.univie.ac.at>

Hi,

does anybody know of a templating library for R,
like velocity or freemarker?

It doesn't have to be very fancy just a bit
better than sub in replacing tags in a text (not
necessarily html) file.

thank you very much for your answer.

Ido



From mdsumner at utas.edu.au  Wed Dec  6 21:32:09 2006
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Thu, 07 Dec 2006 07:32:09 +1100
Subject: [R] [R-pkgs] trip package on CRAN
In-Reply-To: <45772784.2030509@utas.edu.au>
References: <50369.219.88.201.195.1165011305.squirrel@www.stat.auckland.ac.nz>
	<45772784.2030509@utas.edu.au>
Message-ID: <457728C9.5050209@utas.edu.au>

 Hello,

 The 'trip' package provides extensions to the 'sp' spatial classes for 
animal track data.

 Trip objects are created from SpatialPointsDataFrame objects by 
specifying the columns containing ID and date-time data. Argos formats 
can be read directly, and there are functions for basic speed filtering 
and spatial gridding of time spent. Tight integration with 'sp' means 
that projections and general I/O can be handled using 'rgdal'. (This 
really is excellent and so I thank the developers of these and 
supporting packages).

Trip is intended for use with location data that are irregularly spaced 
in time - this contrasts with the rationale behind the traj class in 
'adehabitat'. Primarily it has been developed with marine animal data in 
mind, but the validation of trip classes used should general for many 
applications.

 There is a short vignette available from here -  it's not integrated 
into the CRAN-available package yet.

 http://staff.acecrc.org.au/~mdsumner/Rutas/trip.pdf

 Cheers, Michael Sumner

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From Mark.Leeds at morganstanley.com  Thu Dec  7 15:32:22 2006
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Thu, 7 Dec 2006 09:32:22 -0500
Subject: [R] Merging two data sets
In-Reply-To: <841799.12620.qm@web58115.mail.re3.yahoo.com>
Message-ID: <D3AEEDA31E57474B840BEBC25A8A8344B64412@NYWEXMB23.msad.ms.com>

if you read them in as zoo objects , you can then use merge.zoo but but
I need to
Send you an example of reading them in as zoo objects.
Hold on.

I also have your binders on my shelf ready to send. I've just been
forgetting/busy.



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Megh Dal
Sent: Thursday, December 07, 2006 3:35 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Merging two data sets

Dear all R users,
   
  Suppose I have two datasets:
   
  g = 
   
     8/11/2005                92.75 
     9/11/2005                92.30 
  10/11/2005                92.55 
  11/11/2005                93.90 
  11/14/2005                94.20 
  11/15/2005                94.40 
  11/16/2005                93.90 
  11/22/2005                94.60 
  11/24/2005                95.50 
  2/12/2005               101.00 
   
  and, 
   
  h = 
     11/8/2005    45.930
   11/9/2005    45.820
  11/10/2005   45.815
  11/11/2005   45.780
  11/12/2005    45.630
  11/13/2005    45.630
  11/14/2005    45.630
  11/15/2005    45.710
  11/16/2005    45.715
 11/17/2005     45.815
   
  I want to merge these two dataset like this:
   
     8/11/2005                92.75      NA
     9/11/2005                92.30      NA
  10/11/2005                92.55      NA
  11/11/2005                93.90     45.780
  11/14/2005                94.20     45.630
  11/15/2005                94.40     45.710
  11/16/2005                93.90     45.715
  11/22/2005                94.60      NA
  11/24/2005                95.50      NA
  2/12/2005               101.00       NA
   
  i.e. the length of final dataset should be same as 'g' regardless that
of 2nd dataset.
   
   
  Can anyone tell me how to do this?
   
  I already used ?merge function like this:
   
  h = merge(g,f, by.x="Date", by.y="Date", sort=F, all.x=T, all.y = F,
all=F)
   
  But it is not giving the thing that I want.
   
  Thanks


 
---------------------------------

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}



From mike.prager at noaa.gov  Thu Dec  7 15:39:19 2006
From: mike.prager at noaa.gov (Mike Prager)
Date: Thu, 07 Dec 2006 09:39:19 -0500
Subject: [R] Summary shows wrong maximum
References: <a97en2hb004kgalc1ilfceule4q490ln1d@4ax.com>
	<007701c71971$c684a890$4d908980@gne.windows.gene.com>
Message-ID: <4k8gn2h8kfggeu99fb42gs0edr6q7b43uq@4ax.com>

Bert--

Well, in an attempt to be pithy, I think I lost my message.

The comment was directed not at you specifically, but at the
idea that, given four print positions, one would ever want to
print zeroes instead of data without an explicit warning.

I quite agree with your comments on precision.  However, if more
than those two or three digits are *printed*, I think they
should be as accurate as possible, or accompanied in each place
by a written disclaimer.

Let's say that the mean of the data is not zero, but that the
precision is well within the range of floating point.  Then,
information is being thrown away for no clear reason.  What
makes it "nasty" in my opinion is that the information *appears*
to be there.  (Maybe this is a problem in semiotics.)  So while
I don't think "1.01e3" is more correct than "1010", it does not
appear to be conveying information that has been stripped from
the result.

Is the following really how we want R to work?

> a <- c(19001., 19002., 19003., 19006.)
> summary(a)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  19000   19000   19000   19000   19000   19010 

Respectfully,
--Mike



Bert Gunter <gunter.berton at gene.com> wrote:

> Mike:
> 
> I offered no opinion -- and really didn't have any -- about the worthiness
> of any of the comments that were made. I just liked Brian's little quotable
> aside.
> 
> But since you bait me a bit ...
> 
> In general, I believe that showing th 2-3 most "important" -- **not
> significant** -- digits **and no more** is desirable. By " most important" I
> mean the leftmost digits which are changing in the data (there are some
> caveats in the presence of extreme outliers). Printing more digits merely
> obfuscates the ability of the eye/brain to perceive the patterns of change
> in the data, the presumed intent of displaying it (not of storing it, of
> course). Displaying excessive digits to demonstrate (usually falsely) one's
> precision is evil. Clarity of communications is the standard we should
> aspire to.
> 
> These views have been more eloquently expressed by  A.S.C Ehrenburg and
> Howard Wainer among others...
> 
> -- Bert
> 
> 
> Bert Gunter
> Nonclinical Statistics
> 7-7374
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mike Prager
> Sent: Wednesday, December 06, 2006 11:46 AM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] Summary shows wrong maximum
> 
> I don't know about candidacy, and I'm not going to argue about
> "correctness," but it seems to me that the only valid reasons to
> limit precision of printing in a statistics program are (1) to
> save space and (2) to allow for machine limitations. This is
> neither. To chop off information and replace it with zeroes is
> just plain nasty.
> 
> 
> Bert Gunter <gunter.berton at gene.com> wrote:
> 
> >  
> > Folks:
> > 
> > Is 
> > 
> > "So this is at best a matter of opinion, 
> > and credentials do matter for opinions."
> > 
> > -- Brian Ripley
> > 
> > an R fortunes candidate?
> > 
> > -- Bert Gunter
> > 
> > 
> > On Tue, 5 Dec 2006, Oliver Czoske wrote:
> > 
> > > On Mon, 4 Dec 2006, Uwe Ligges wrote:
> > >> Sebastian Spaeth wrote:
> > >>> Hi all,
> > >>> I have a list with a numerical column "cum_hardreuses". By coincidence
> I
> > >>> discovered this:
> > >>>
> > >>>> max(libs[,"cum_hardreuses"])
> > >>> [1] 1793
> > >>>
> > >>>> summary(libs[,"cum_hardreuses"])
> > >>>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> > >>>        1       2       4      36      14    1790
> > >>>
> > >>> (note the max value of 1790) Ouch this is bad! Anything I can do to
> > remedy
> > >>> this? Known bug?
> > >>
> > >> No, it's a feature! See ?summary: printing is done up to 3 significant
> > >> digits by default.
> > >
> > > Unfortunately, '1790' is printed with *four* significant digits, not
> > > three. The correct representation with three significant digits would
> have
> > > to employ scientific notation, 1.79e3.
> > >
> > >

-- 
Mike Prager, NOAA, Beaufort, NC
* Opinions expressed are personal and not represented otherwise.
* Any use of tradenames does not constitute a NOAA endorsement.



From dfarrar at newrvana.com  Thu Dec  7 15:42:11 2006
From: dfarrar at newrvana.com (David Farrar)
Date: Thu, 7 Dec 2006 06:42:11 -0800 (PST)
Subject: [R] test of spatial dependence?? - ask an ecologist?
In-Reply-To: <Pine.LNX.4.44.0612062009420.11952-100000@reclus.nhh.no>
Message-ID: <376709.23692.qm@web811.biz.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061207/b730a430/attachment-0005.pl 

From Philip.Leifeld at uni-konstanz.de  Thu Dec  7 16:55:51 2006
From: Philip.Leifeld at uni-konstanz.de (Philip Leifeld)
Date: Thu, 07 Dec 2006 16:55:51 +0100
Subject: [R] incidence and adjacency matrix conversion
Message-ID: <45783987.4040707@uni-konstanz.de>

Thanks, David. I tried converting my rectangular matrix to a network 
object and then back to a square matrix. This works for a small 
artificial dataset (e.g. 2x5), but when I try this on my 1790x45 or 
transposed 45x1790 matrix, R keeps working for a couple of minutes and 
then crashes completely without having saved any data first. I assume 
something is wrong with my data?

Cheers
Philip

David Barron wrote:
 > I think you can do this using the network package.  Look at the
 > as.network.matrix and as.matrix.network functions, for example.
 >
 >> how can I convert an m x n incidence matrix into an m x m adjacency
 >> matrix or an n x n adjacency matrix? The current matrix contains binary
 >> data, hence the new matrix would contain counts of common occurrences.



From Anna_Belova at abtassoc.com  Thu Dec  7 17:04:27 2006
From: Anna_Belova at abtassoc.com (Anna Belova)
Date: Thu, 7 Dec 2006 11:04:27 -0500
Subject: [R]  Calling R functions in Delphi
Message-ID: <OF84F33D2C.B3E20991-ON8525723D.0057E24C-8525723D.00584C76@abtassoc.com>


Dear All,

Thank you very much for all the insights!

We truly appreciate your thought and your time.

--Anna
-----------------------------------------
Anna Belova
Abt Associates Inc.
4800 Montgomery Ln, St 600
Bethesda, MD-20814
phone: 301-347-5304
http://www.abtassociates.com/environment

-----------------------------------------
This message may contain privileged and confidential informa...{{dropped}}



From rab45+ at pitt.edu  Thu Dec  7 17:02:38 2006
From: rab45+ at pitt.edu (Rick Bilonick)
Date: Thu, 07 Dec 2006 11:02:38 -0500
Subject: [R] groupedData Error Using outer=TRUE
Message-ID: <1165507358.3532.13.camel@localhost.localdomain>

I'm using groupedData from nlme. I set up a groupedData data.frame with
outer=~group1. When I try to plot with outer=TRUE, I get "subscript out
of bounds." This happens most of the time. When it works, I get
spaghetti-type plots for comparing groups. But I don't understand why it
doesn't usually work.

> longa.mod.1.gd <- groupedData(mod1.logit~time|
name/eye,outer=~group1,data=longa.mod.1)
> plot(longa.mod.1.gd)
> plot(longa.mod.1.gd,outer=TRUE)
Error in attribs[["outer"]][[displayLevel]] :
        subscript out of bounds

What am I doing wrong?

Rick B.



From marsh at uri.edu  Thu Dec  7 17:40:55 2006
From: marsh at uri.edu (Marshall Feldman)
Date: Thu, 7 Dec 2006 11:40:55 -0500
Subject: [R] FW: test of spatial dependence?? - ask a geographer (was ask an
	ecologist)?
Message-ID: <009501c71a1e$77356ec0$0200a8c0@Zippy>



No, you do not necessarily need the XY coordinates. You can also use polygon
(field, in your case) adjacency information. See Rogerson, Peter A. 2001.
_Statistical methods for geography_. Thousand Oaks: Sage.

You might also look at GeoDA, a free and soon-to-be open source spatial
analysis package. For your application, it might be easier to use than R. Go
to https://www.geoda.uiuc.edu/.

	Marshall Feldman
	Center for Urban Studies and Research
	The University of Rhode Island

-----Original Message-----
From: Milton Cezar Ribeiro [mailto:milton_ruser at yahoo.com.br] 
Sent: Wednesday, December 06, 2006 8:26 AM
To: David Farrar; Xu Yuan; r-help at stat.math.ethz.ch
Subject: Re: [R] test of spatial dependence?? - ask an ecologist?

I never used it, but I beleave that it is a job for "mantel.rtest()"
available on "ade4" package.
   
  In fact Farrar are right, you will neet the XY coordinates. Give a look at
"Legendre & Legendre" text book.
   
  HTH,
   
  Miltinho
  Brazil

David Farrar <dfarrar at newrvana.com> escreveu:
  

In addition to the 25 numbers, I assume you have coordinates of each field.
Otherwise, I don't understand what you are trying to do. I think ecologists
like to use a test due to Mantel in this situation. 

The prefix "auto" means "self," of course, the idea being that measurements
of the same variable under different conditions are correlated. I guess this
would be a case of "autodependence." For correlation versus dependence,
check your intro stats book. 

de nada, 
X'X 

Farrar 


Xu Yuan wrote:
hello R-friends,

I am a R beginner and try to ask a basic question:

How to test the spatial dependence of a column of data? for example, I have
25 agricultural fields, and I measure the average slope (%) or pH for each
field. All I have is 25 numbers.

PS, could someone confirm that "spatial dependence" is equivalent to
"spatial correlation" or "spatial autocorrelation" or not.

Thank you very much.
XY

[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


 		
---------------------------------

	[[alternative HTML version deleted]]





Dr. Marshall Feldman, PhD
Director of Research and Academic Affairs
Center for Urban Studies and Research 
The University of Rhode Island
email: marsh @ uri.edu (remove spaces) 
telephone: (401) 277-5218 (Providence); (401) 874-5953 (Kingston)
fax: (401) 277-5464 (Providence); (401) 874-5511 (Kingston)
Providence address:
206E Shepard Building
80 Washington Street
Providence, RI 02903-1819
Kingston address:
310 Lippitt Hall
Kingston, RI 02881-0815



From R.C.NAVARRO at cgiar.org  Thu Dec  7 17:47:11 2006
From: R.C.NAVARRO at cgiar.org (Navarro, Rolando (CIP))
Date: Thu, 7 Dec 2006 11:47:11 -0500
Subject: [R] Rmpi help
Message-ID: <B7B34444ECA41A41AC47DABA057CE7A2011D5392@webmail.cip.cgiar.org>

Hi team,

I am beginning on R and I try to install Rmpi library and I have problems, I have installed LAM-MPI on Rocks;

[rcnavarro at hpc-cip ~]$ laminfo
             LAM/MPI: 7.1.1
              Prefix: /opt/lam/gnu
        Architecture: x86_64-unknown-linux-gnu
       Configured by: root
       Configured on: Wed Oct 19 18:12:25 EDT 2005
      Configure host: rocks-156.sdsc.edu
      Memory manager: ptmalloc2
          C bindings: yes
        C++ bindings: yes
    Fortran bindings: yes
          C compiler: gcc
        C++ compiler: g++
    Fortran compiler: g77
     Fortran symbols: double_underscore
         C profiling: yes
       C++ profiling: yes
   Fortran profiling: yes
      C++ exceptions: no
      Thread support: yes
       ROMIO support: yes
        IMPI support: no
       Debug support: no
        Purify clean: no
            SSI boot: globus (API v1.1, Module v0.6)
            SSI boot: rsh (API v1.1, Module v1.1)
            SSI boot: slurm (API v1.1, Module v1.0)
            SSI coll: lam_basic (API v1.1, Module v7.1)
            SSI coll: shmem (API v1.1, Module v1.0)
            SSI coll: smp (API v1.1, Module v1.2)
             SSI rpi: crtcp (API v1.1, Module v1.1)
             SSI rpi: lamd (API v1.0, Module v7.1)
             SSI rpi: tcp (API v1.0, Module v7.1)
             SSI rpi: sysv (API v1.0, Module v7.1)
             SSI rpi: usysv (API v1.0, Module v7.1)
              SSI cr: self (API v1.0, Module v1.0)

But I have problems with Rmpi library:
[rcnavarro at hpc-cip ~]$ mpirun -np 6 -v RMPISNOW
16004 RMPISNOW running on n0 (o)
16005 RMPISNOW running on n0 (o)
mpirun: cannot start RMPISNOW on n1: No such file or directory

R version 2.4.0 (2006-10-03)
Copyright (C) 2006 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.


R version 2.4.0 (2006-10-03)
Copyright (C) 2006 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

Error: 'package.description' is defunct.
Use 'packageDescription' instead.
See help("Defunct")
Error in library(Rmpi) : .First.lib failed for 'Rmpi'
Error: 'package.description' is defunct.
Use 'packageDescription' instead.
See help("Defunct")
Error in library(Rmpi) : .First.lib failed for 'Rmpi'
Error in dyn.unload(x) : dynamic/shared library '/paracel/R/lib64/R/library/Rmpi/libs/Rmpi.so' was not loaded
Error in dyn.unload(x) : dynamic/shared library '/paracel/R/lib64/R/library/Rmpi/libs/Rmpi.so' was not loaded

I dont understand, why?

Please help me.

Cheers

Navarro Jara, Rolando 
Cisco Certified Network Associate - CCNA
Acesss Grid Project - Information Technology Unit 
International Potato Center 
Phone: 511 - 3496017 Ext. 2146
 


Navarro Jara, Rolando 
Cisco Certified Network Associate - CCNA
Acesss Grid Project - Information Technology Unit 
International Potato Center 
Phone: 511 - 3496017 Ext. 2146



From maechler at stat.math.ethz.ch  Thu Dec  7 18:24:36 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 7 Dec 2006 18:24:36 +0100
Subject: [R] incidence and adjacency matrix conversion
In-Reply-To: <4575E4DA.6040808@uni-konstanz.de>
References: <4575E4DA.6040808@uni-konstanz.de>
Message-ID: <17784.20052.99879.155988@stat.math.ethz.ch>

>>>>> "Phil" == Philip Leifeld <Philip.Leifeld at uni-konstanz.de>
>>>>>     on Tue, 05 Dec 2006 22:30:02 +0100 writes:

    Phil> Dear all,
    Phil> how can I convert an m x n incidence matrix into an m x m adjacency 
    Phil> matrix or an n x n adjacency matrix? The current matrix contains binary 
    Phil> data, hence the new matrix would contain counts of common occurrences.

You have not given a self contained reproducible example
which would even be useful in such a case..

But just to be sure that the solution is not as simple as I
thought it was -- namely I thought, that for binary matrices,
crossprod()  and tcrossprod() would give what you'd want :

> n <-   10 ; m <- 4
> set.seed(1)
> M <- matrix(as.logical(rbinom(n*m, size=1, prob = 0.3)), n,m)
> symnum(M)
             
 [1,] . . | .
 [2,] . . . .
 [3,] . . . .
 [4,] | . . .
 [5,] . | . |
 [6,] | . . .
 [7,] | | . |
 [8,] . | . .
 [9,] . . | |
[10,] . | . .
> print.table(A.1 <- tcrossprod(M), zero = ".")
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    1    .    .    .    .    .    .    .    1     .
 [2,]    .    .    .    .    .    .    .    .    .     .
 [3,]    .    .    .    .    .    .    .    .    .     .
 [4,]    .    .    .    1    .    1    1    .    .     .
 [5,]    .    .    .    .    2    .    2    1    1     1
 [6,]    .    .    .    1    .    1    1    .    .     .
 [7,]    .    .    .    1    2    1    3    1    1     1
 [8,]    .    .    .    .    1    .    1    1    .     1
 [9,]    1    .    .    .    1    .    1    .    2     .
[10,]    .    .    .    .    1    .    1    1    .     1
> print.table(A.2 <-  crossprod(M), zero = ".")
     [,1] [,2] [,3] [,4]
[1,]    3    1    .    1
[2,]    1    4    .    2
[3,]    .    .    2    1
[4,]    1    2    1    3
> 


    Phil> Thank you for your help.

you're welcome (if it did help).

Martin Maechler, ETH Zurich



From aiminy at iastate.edu  Thu Dec  7 18:29:35 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Thu, 07 Dec 2006 11:29:35 -0600
Subject: [R] plot SVM
Message-ID: <6.1.2.0.2.20061207112821.01ca56d8@aiminy.mail.iastate.edu>

I use svm , then I want to do like this
But give me this error. Does anyone know how to solve these?

Aimin

 > plot(m.svm,p5.new,As~Cur)
Error in scale(newdata[, object$scaled, drop = FALSE], center = 
object$x.scale$"scaled:center",  :
         (subscript) logical subscript too long



From istoyanov at ecolab.bas.bg  Thu Dec  7 18:34:04 2006
From: istoyanov at ecolab.bas.bg (Ivailo Stoyanov)
Date: Thu, 07 Dec 2006 19:34:04 +0200
Subject: [R] help-links.sh not found by help.start() -- do I need to
	recompile?
Message-ID: <4578508C.30807@ecolab.bas.bg>

Dear Rexperts,

after building R 2.4.0 from source in a temporary directory (*without* 
installation), and subsequently moving the whole source/build tree to 
another location, I have noticed that I had to change the variables 
R_SHARE_DIR, R_INCLUDE_DIR, and R_DOC_DIR in the wrapper-script 
/lib/R/bin/R as to reflect the current situation.

However, when I try to run the HTML help via help.start() I still get an 
error message saying that:

sh: /tmp/r-project-build/usr/lib/R/share/sh/help-links.sh: No such file 
or directory

Interestingly, the system still tries to search for scripts in 
/tmp/r-project-build/, the temporary build directory that clearly isn't 
valid now.

My question is: has the mentioned path become hard-coded in the binaries 
or am I
missing some config-file/wrapper script that needs to be edited in order 
to reflect the current state?

Thank you in advance for any hints!

All the best,
Ivailo



From marc_schwartz at comcast.net  Thu Dec  7 18:51:07 2006
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 07 Dec 2006 11:51:07 -0600
Subject: [R] help-links.sh not found by help.start() -- do I need
	to	recompile?
In-Reply-To: <4578508C.30807@ecolab.bas.bg>
References: <4578508C.30807@ecolab.bas.bg>
Message-ID: <1165513867.4655.16.camel@localhost.localdomain>

On Thu, 2006-12-07 at 19:34 +0200, Ivailo Stoyanov wrote:
> Dear Rexperts,
> 
> after building R 2.4.0 from source in a temporary directory (*without* 
> installation), and subsequently moving the whole source/build tree to 
> another location, I have noticed that I had to change the variables 
> R_SHARE_DIR, R_INCLUDE_DIR, and R_DOC_DIR in the wrapper-script 
> /lib/R/bin/R as to reflect the current situation.
> 
> However, when I try to run the HTML help via help.start() I still get an 
> error message saying that:
> 
> sh: /tmp/r-project-build/usr/lib/R/share/sh/help-links.sh: No such file 
> or directory
> 
> Interestingly, the system still tries to search for scripts in 
> /tmp/r-project-build/, the temporary build directory that clearly isn't 
> valid now.
> 
> My question is: has the mentioned path become hard-coded in the binaries 
> or am I
> missing some config-file/wrapper script that needs to be edited in order 
> to reflect the current state?
> 
> Thank you in advance for any hints!
> 
> All the best,
> Ivailo

When you "moved" the source/build tree to "another location", did you
use 'make install' as root, or did you use 'mv' or 'cp'?

The former is the _proper_ way to actually install R, after building
from source and this is covered in the R Admin Manual. See:

  http://cran.r-project.org/doc/manuals/R-admin.html#Installation

HTH,

Marc Schwartz



From istoyanov at ecolab.bas.bg  Thu Dec  7 19:15:10 2006
From: istoyanov at ecolab.bas.bg (Ivailo Stoyanov)
Date: Thu, 07 Dec 2006 20:15:10 +0200
Subject: [R] help-links.sh not found by help.start() -- do I need to
	recompile?
Message-ID: <45785A2E.6090502@ecolab.bas.bg>

> When you "moved" the source/build tree to "another location", did you
> use 'make install' as root, or did you use 'mv' or 'cp'?

No, I haven't used "make install" because I prefer to run R from within 
the build location.

> The former is the _proper_ way to actually install R, after building
> from source and this is covered in the R Admin Manual. See:
> 
>   http://cran.r-project.org/doc/manuals/R-admin.html#Installation

AFAIK, the approach of running R from within the build location is fully 
valid as it is noted at the end of section "2.1 Simple compilation", 
just above the cited one:

"... Note: you do not need to install R: you can run it from where it 
was built."

All the best,
Ivailo



From p.dalgaard at biostat.ku.dk  Thu Dec  7 19:28:00 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 07 Dec 2006 19:28:00 +0100
Subject: [R] help-links.sh not found by help.start() -- do I need
	to	recompile?
In-Reply-To: <45785A2E.6090502@ecolab.bas.bg>
References: <45785A2E.6090502@ecolab.bas.bg>
Message-ID: <45785D30.90301@biostat.ku.dk>

Ivailo Stoyanov wrote:
>> When you "moved" the source/build tree to "another location", did you
>> use 'make install' as root, or did you use 'mv' or 'cp'?
>>     
>
> No, I haven't used "make install" because I prefer to run R from within 
> the build location.
>
>   
>> The former is the _proper_ way to actually install R, after building
>> from source and this is covered in the R Admin Manual. See:
>>
>>   http://cran.r-project.org/doc/manuals/R-admin.html#Installation
>>     
>
> AFAIK, the approach of running R from within the build location is fully 
> valid as it is noted at the end of section "2.1 Simple compilation", 
> just above the cited one:
>   
Yes, but then it is not "actually installed".
> "... Note: you do not need to install R: you can run it from where it 
> was built."
>   
You can, but note that it doesn't say that you can move the build 
location afterwards, and in fact, you can not, because of the 
non-relative pathnames.
> All the best,
> Ivailo
>



From marc_schwartz at comcast.net  Thu Dec  7 19:35:44 2006
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 07 Dec 2006 12:35:44 -0600
Subject: [R] help-links.sh not found by help.start() -- do I need
	to	recompile?
In-Reply-To: <45785A2E.6090502@ecolab.bas.bg>
References: <45785A2E.6090502@ecolab.bas.bg>
Message-ID: <1165516544.4655.34.camel@localhost.localdomain>

On Thu, 2006-12-07 at 20:15 +0200, Ivailo Stoyanov wrote:
> > When you "moved" the source/build tree to "another location", did you
> > use 'make install' as root, or did you use 'mv' or 'cp'?
> 
> No, I haven't used "make install" because I prefer to run R from within 
> the build location.
> 
> > The former is the _proper_ way to actually install R, after building
> > from source and this is covered in the R Admin Manual. See:
> > 
> >   http://cran.r-project.org/doc/manuals/R-admin.html#Installation
> 
> AFAIK, the approach of running R from within the build location is fully 
> valid as it is noted at the end of section "2.1 Simple compilation", 
> just above the cited one:
> 
> "... Note: you do not need to install R: you can run it from where it 
> was built."
> 
> All the best,
> Ivailo

A key piece of information not in your original post was that you were
not "installing" R, but wanted to run it from whence it was built...and
then moved it and were attempting to run it from a new location.

You will need to change $R_HOME, which defines the primary home
directory for the currently running R session.  This is defined in the
main R startup script, which will be in the 'bin' sub-directory for your
R tree.

I have not validated this that will do it, but short of re-building R in
the new location, this should work I think. Many of the environmental
vars are hard coded during the build process and then modified during a
"make install" based upon build time configuration options. If you want
to install R in a non-default location, I would suggest considering
modifying the ./configure options and then building to suit your needs.

HTH,

Marc



From istoyanov at ecolab.bas.bg  Thu Dec  7 19:47:27 2006
From: istoyanov at ecolab.bas.bg (Ivailo Stoyanov)
Date: Thu, 07 Dec 2006 20:47:27 +0200
Subject: [R] help-links.sh not found by help.start() -- do I need
	to	recompile?
In-Reply-To: <45785D30.90301@biostat.ku.dk>
References: <45785A2E.6090502@ecolab.bas.bg> <45785D30.90301@biostat.ku.dk>
Message-ID: <457861BF.1020700@ecolab.bas.bg>

Peter Dalgaard wrote:
[snip]
>> AFAIK, the approach of running R from within the build location is 
>> fully valid as it is noted at the end of section "2.1 Simple 
>> compilation", just above the cited one:
>>   
> Yes, but then it is not "actually installed".
[snip]
>> "... Note: you do not need to install R: you can run it from where it 
>> was built."
>>   
> You can, but note that it doesn't say that you can move the build 
> location afterwards, and in fact, you can not, because of the 
> non-relative pathnames.

Actually, I have used R for a long time without any (apparent) problems 
being "installed" this way. I just changed the mentioned variables 
manually, and everything was running just fine -- until I needed to 
check the HTML help recently. Therefore I thought that I've missed to 
fix some config-file in an analogous maner to solve the problem with the 
script that wasn't found by the system.

I assume that I have to recompile (something that I was hoping to avoid 
due to the rather decent system I use currently) to get this issue 
fixed. Am I right?



From ross at biostat.ucsf.edu  Thu Dec  7 20:03:08 2006
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 07 Dec 2006 11:03:08 -0800
Subject: [R] making a grid of points
Message-ID: <1165518188.1551.36.camel@iron.psg.net>

I'd like to evaluate a function at each point on a 2 or 3-D grid.  Is
there some function that already does this, or generates the grid of
points?

My search has led me to the grid and lattice packages, and I found a
reference to the sp package (e.g., SpatialGrid) for this.  There are
things in there that might be relevant, but at first blush many of them
are embedded in other concepts (grobs, shingles, rugs) and don't
obviously solve the problem.

I know this is not a hard thing to program, but I suspect someone has
already done it.  Any pointers?

Thanks.
-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062



From PAlspach at hortresearch.co.nz  Thu Dec  7 20:09:43 2006
From: PAlspach at hortresearch.co.nz (Peter Alspach)
Date: Fri, 8 Dec 2006 08:09:43 +1300
Subject: [R] making a grid of points
Message-ID: <EC0F8FF776F3F74E9C63CE16641C962801AB4143@AKLEXB02.hort.net.nz>


Ross

I think you want

?expand.grid

BTW, help.search('grid') finds this.

Cheers ......

Peter Alspach


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ross Boylan
> Sent: Friday, 8 December 2006 8:03 a.m.
> To: r-help
> Subject: [R] making a grid of points
>
> I'd like to evaluate a function at each point on a 2 or 3-D
> grid.  Is there some function that already does this, or
> generates the grid of points?
>
> My search has led me to the grid and lattice packages, and I
> found a reference to the sp package (e.g., SpatialGrid) for
> this.  There are things in there that might be relevant, but
> at first blush many of them are embedded in other concepts
> (grobs, shingles, rugs) and don't obviously solve the problem.
>
> I know this is not a hard thing to program, but I suspect
> someone has already done it.  Any pointers?
>
> Thanks.
> --
> Ross Boylan                                      wk:  (415) 514-8146
> 185 Berry St #5700                               ross at biostat.ucsf.edu
> Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
> University of California, San Francisco
> San Francisco, CA 94107-1739                     hm:  (415) 550-1062
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________________

The contents of this e-mail are privileged and/or confidenti...{{dropped}}



From ross at biostat.ucsf.edu  Thu Dec  7 20:18:28 2006
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 07 Dec 2006 11:18:28 -0800
Subject: [R] making a grid of points
In-Reply-To: <EC0F8FF776F3F74E9C63CE16641C962801AB4143@AKLEXB02.hort.net.nz>
References: <EC0F8FF776F3F74E9C63CE16641C962801AB4143@AKLEXB02.hort.net.nz>
Message-ID: <1165519108.1551.38.camel@iron.psg.net>

On Fri, 2006-12-08 at 08:09 +1300, Peter Alspach wrote:
> Ross
> 
> I think you want
> 
> ?expand.grid
> 
> BTW, help.search('grid') finds this.
> 
> Cheers ......
> 
> Peter Alspach
> 
I can't believe I missed that--my eye just jumped to all the stuff in
the grid package.  Thank you.
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ross Boylan
> > Sent: Friday, 8 December 2006 8:03 a.m.
> > To: r-help
> > Subject: [R] making a grid of points
> >
> > I'd like to evaluate a function at each point on a 2 or 3-D
> > grid.  Is there some function that already does this, or
> > generates the grid of points?
> >
> > My search has led me to the grid and lattice packages, and I
> > found a reference to the sp package (e.g., SpatialGrid) for
> > this.  There are things in there that might be relevant, but
> > at first blush many of them are embedded in other concepts
> > (grobs, shingles, rugs) and don't obviously solve the problem.
> >
> > I know this is not a hard thing to program, but I suspect
> > someone has already done it.  Any pointers?
> >
> > Thanks.
> > --
> > Ross Boylan                                      wk:  (415) 514-8146
> > 185 Berry St #5700                               ross at biostat.ucsf.edu
> > Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
> > University of California, San Francisco
> > San Francisco, CA 94107-1739                     hm:  (415) 550-1062
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________________
> 
> The contents of this e-mail are privileged and/or confidential to the
> named recipient and are not to be used by any other person and/or
> organisation. If you have received this e-mail in error, please notify
> the sender and delete all material pertaining to this e-mail.
> ______________________________________________________
-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062



From Roger.Bivand at nhh.no  Thu Dec  7 20:32:56 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 7 Dec 2006 20:32:56 +0100 (CET)
Subject: [R] making a grid of points
In-Reply-To: <1165518188.1551.36.camel@iron.psg.net>
Message-ID: <Pine.LNX.4.44.0612072030030.5021-100000@reclus.nhh.no>

On Thu, 7 Dec 2006, Ross Boylan wrote:

> I'd like to evaluate a function at each point on a 2 or 3-D grid.  Is
> there some function that already does this, or generates the grid of
> points?
> 
> My search has led me to the grid and lattice packages, and I found a
> reference to the sp package (e.g., SpatialGrid) for this.  There are
> things in there that might be relevant, but at first blush many of them
> are embedded in other concepts (grobs, shingles, rugs) and don't
> obviously solve the problem.
> 
> I know this is not a hard thing to program, but I suspect someone has
> already done it.  Any pointers?

Which "space" are your points in? The sp package might help if the data 
are spatial/geographical, but I think that expand.grid() is your friend, 
followed by one of the apply() family to run your function on each row of 
the data frame output by expand.grid().

Roger


> 
> Thanks.
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From istoyanov at ecolab.bas.bg  Thu Dec  7 20:39:46 2006
From: istoyanov at ecolab.bas.bg (Ivailo Stoyanov)
Date: Thu, 07 Dec 2006 21:39:46 +0200
Subject: [R] help-links.sh not found by help.start() -- do I need
	to	recompile?
In-Reply-To: <45785D30.90301@biostat.ku.dk>
References: <45785A2E.6090502@ecolab.bas.bg> <45785D30.90301@biostat.ku.dk>
Message-ID: <45786E02.8030307@ecolab.bas.bg>

Marc Schwartz wrote:
> I have not validated this that will do it, but short of re-building R in
> the new location, this should work I think. Many of the environmental
> vars are hard coded during the build process and then modified during a
> "make install" based upon build time configuration options. If you want
> to install R in a non-default location, I would suggest considering
> modifying the ./configure options and then building to suit your needs.
> 
> HTH,
> 
> Marc

OK, I'll check the ./configure options passed through the build script I 
used last time.

Thanks to all helpers so far,
Ivailo



From deepayan.sarkar at gmail.com  Thu Dec  7 20:58:31 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 7 Dec 2006 11:58:31 -0800
Subject: [R] groupedData Error Using outer=TRUE
In-Reply-To: <1165507358.3532.13.camel@localhost.localdomain>
References: <1165507358.3532.13.camel@localhost.localdomain>
Message-ID: <eb555e660612071158w3d5b3666n7c36e56670cc846e@mail.gmail.com>

On 12/7/06, Rick Bilonick <rab45+ at pitt.edu> wrote:
> I'm using groupedData from nlme. I set up a groupedData data.frame with
> outer=~group1. When I try to plot with outer=TRUE, I get "subscript out
> of bounds." This happens most of the time. When it works, I get
> spaghetti-type plots for comparing groups. But I don't understand why it
> doesn't usually work.
>
> > longa.mod.1.gd <- groupedData(mod1.logit~time|
> name/eye,outer=~group1,data=longa.mod.1)
> > plot(longa.mod.1.gd)
> > plot(longa.mod.1.gd,outer=TRUE)
> Error in attribs[["outer"]][[displayLevel]] :
>         subscript out of bounds
>
> What am I doing wrong?

Hard to say:

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-Deepayan



From istoyanov at ecolab.bas.bg  Thu Dec  7 21:11:08 2006
From: istoyanov at ecolab.bas.bg (Ivailo Stoyanov)
Date: Thu, 07 Dec 2006 22:11:08 +0200
Subject: [R] help-links.sh not found by help.start() -- do I need
	to	recompile?
In-Reply-To: <45785D30.90301@biostat.ku.dk>
References: <45785A2E.6090502@ecolab.bas.bg> <45785D30.90301@biostat.ku.dk>
Message-ID: <4578755C.1040907@ecolab.bas.bg>

Thanks to the valuable hints posted, I managed to track down the source 
of the problem -- a copy of the *uncorrected* /usr/lib/R/bin/R script 
was left over in /usr/bin.

Thank you again for the patience!

Greets,
Ivailo



From o.samarasinghe at auckland.ac.nz  Thu Dec  7 21:29:22 2006
From: o.samarasinghe at auckland.ac.nz (Samarasinghe, Oshadhi Erandika)
Date: Fri, 8 Dec 2006 09:29:22 +1300
Subject: [R] Heteroscedasticity consistent standard errors for Spatial
	error models
In-Reply-To: <Pine.LNX.4.44.0612071010590.12632-100000@reclus.nhh.no>
Message-ID: <1E11F4042C05ED4BAA6BA96319DA56610FCE7ECF@comxchg1.com.auckland.ac.nz>


Thank you very much for your help, much appreciated.


Regards,

Oshadhi Samarasinghe
RA
Department of Economics 
University of Auckland
New Zealand 

-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: Thursday, 7 December 2006 10:18 p.m.
To: Achim Zeileis
Cc: Samarasinghe, Oshadhi Erandika; r-help at stat.math.ethz.ch
Subject: Re: [R] Heteroscedasticity consistent standard errors for
Spatial error models

On Thu, 7 Dec 2006, Achim Zeileis wrote:

> On Thu, 7 Dec 2006, Samarasinghe, Oshadhi Erandika wrote:
> 
> > Hello,
> >
> > Could anyone please tell me how to estimate Heteroscedasticity 
> > Consistent standard errors for a Spatial error model? All the 
> > functions I have looked at only works for lm objects.
> 
> I assume that you looked also at the "sandwich" package: The methods 
> there do not only work for "lm" objects but are object-oriented, 
> appropriate methods are already provided for a range of different 
> object classes. So, in principle, you can plug in other models as 
> well, potentially including spatial models if appropriate methods are
provided. See
>   vignette("sandwich-OOP", package = "sandwich")
> 
> Disclaimer: I'm not sure whether the spatial structure of spatial 
> models will be appropriately captured by the class of estimators 
> implemented in "sandwich". But someone who knows spatial models and 
> their HC covariances should be able to figure that out from the 
> vignette above. I'm also not sure what specialized methods exist...

Typically, the use of HC covariances with these kinds of models is an
inappropriate fix for missing variables and possibly also wrong
functional forms. Some supervisors want them, but in practice fitting a
better specified model is superior. It is also possible to sample from
the fitted model - I've been looking at MH sampling from MCMCpack - and
that I feel is a way to go if the model is badly specified and you can't
do anything about it. 

Settings where "natural experiments" exist are also very helpful, with
shifts in coefficient values and/or standard errors indicating whether
the hypothesised cause of difference actually had an effect.

It can probably be done, and some journals/referees/supervisors etc.
want HC covariances, but I'm afraid that doesn't necessarily mean that
they are any use in practice with these pretty rough kinds of models.

Roger

> 
> Best,
> Z
> 
> 
> > Thank you very much!
> >
> > - Oshadhi
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

--
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From backer at psych.uib.no  Thu Dec  7 21:35:15 2006
From: backer at psych.uib.no (Tom Backer Johnsen)
Date: Thu, 07 Dec 2006 21:35:15 +0100
Subject: [R] I do not understand this
Message-ID: <45787B03.6060603@psych.uib.no>

A few days ago there was a thread on calling R from Delphi to which 
there were several useful responses.  Now I responded as well, with 
what I regard as a useful contribution.  Shortly after that, I was not 
able to able to see the thread in my newsreader (Thunderbird). 
Suddenly, yesterday I could see the thread again, and now it has 
vanished, at least from my sight.

Now.  Is there an error in my reader, or more likely, an error in my 
use of the reader.  Or, has the thread been deleted for some reason. 
I wonder ...

Tom
-- 
+----------------------------------------------------------------+
| Tom Backer Johnsen, Psychometrics Unit,  Faculty of Psychology |
| University of Bergen, Christies gt. 12, N-5015 Bergen,  NORWAY |
| Tel : +47-5558-9185                        Fax : +47-5558-9879 |
| Email : backer at psych.uib.no    URL : http://www.galton.uib.no/ |
+----------------------------------------------------------------+



From gerifalte28 at hotmail.com  Thu Dec  7 22:05:18 2006
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Thu, 07 Dec 2006 14:05:18 -0700
Subject: [R] I do not understand this
In-Reply-To: <45787B03.6060603@psych.uib.no>
References: <45787B03.6060603@psych.uib.no>
Message-ID: <4578820E.3080400@hotmail.com>

I use thunderbird as my newsreader and I see the thread just fine. So, 
don't worry, nobody has deleted what you regard as a useful contribution.

Regards

Francisco

Dr. Francisco J. Zagmutt
College of Veterinary Medicine and Biomedical Sciences
Colorado State University


Tom Backer Johnsen wrote:
> A few days ago there was a thread on calling R from Delphi to which 
> there were several useful responses.  Now I responded as well, with 
> what I regard as a useful contribution.  Shortly after that, I was not 
> able to able to see the thread in my newsreader (Thunderbird). 
> Suddenly, yesterday I could see the thread again, and now it has 
> vanished, at least from my sight.
> 
> Now.  Is there an error in my reader, or more likely, an error in my 
> use of the reader.  Or, has the thread been deleted for some reason. 
> I wonder ...
> 
> Tom



From p.dalgaard at biostat.ku.dk  Thu Dec  7 22:09:47 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 07 Dec 2006 22:09:47 +0100
Subject: [R] I do not understand this
In-Reply-To: <45787B03.6060603@psych.uib.no>
References: <45787B03.6060603@psych.uib.no>
Message-ID: <4578831B.90606@biostat.ku.dk>

Tom Backer Johnsen wrote:
> A few days ago there was a thread on calling R from Delphi to which 
> there were several useful responses.  Now I responded as well, with 
> what I regard as a useful contribution.  Shortly after that, I was not 
> able to able to see the thread in my newsreader (Thunderbird). 
> Suddenly, yesterday I could see the thread again, and now it has 
> vanished, at least from my sight.
>
> Now.  Is there an error in my reader, or more likely, an error in my 
> use of the reader.  Or, has the thread been deleted for some reason. 
> I wonder ...
>
> Tom
>   
How are you reading R-help?

Fundamentally, R-help is email based, so once a mail is sent, only the 
receiver is involved in where it gets (mis)filed.

If you are using a mail-to-news gateway like gmane, then there could be 
an issue with retention times. However, in the case of gmane, I doubt 
that would be the case because the thread is here:

http://thread.gmane.org/gmane.comp.lang.r.general/75135/focus=75164



From alexander.geisler at gmail.com  Thu Dec  7 22:33:05 2006
From: alexander.geisler at gmail.com (Alexander Geisler)
Date: Thu, 07 Dec 2006 22:33:05 +0100
Subject: [R] Simulation in R - Part 2
Message-ID: <45788891.90001@gmail.com>

Hello!

So, the simulation works (drawing 100 samples and then calculate the
model for each sample). Here is the code:

--snip--
# sample size n=200
ergebnisse200 <- rep(0, each=100)
stichproben200 <- vector(?list?, 100)
default200 <- rep(0, each=100)

for (i in seq(1:100)) {
n <- dim(daten)[1]  	
ix <- sample(n,200) 	
samp_i <- daten[ix,]  	# draw samples
y <- sum(samp_i$y)     # number of defaults
stichproben200[[i]] <- samp_i  # saving the samples
default200[i] <- y   # saving the number of defaults

# Modell berechnen:
posterior_i <- MCMClogit(y ~ fbl.ind + fekq3 + febitda4 + fuvs + fkru +
fzd + fur3, data=samp_i, b0=prior, B0=precision, tune=0.5) # calculation
ergebnisse200[i] <- summary(posterior_i)  # saving the results
}

# write out the solutions into an excel-file
write.csv2(ergebnisse200, "ergebnisse.csv")
--snip--

My solution has the following form:

http://img296.imageshack.us/my.php?image=ergebnissewa0.jpg

write.csv2 makes the right thing, but in the excel-file, if I open the
csv-file in excel, several objects are next to each other (I'm missing
the line break after each object of the array); look at
http://img67.imageshack.us/my.php?image=ergebnisseexcelbg7.jpg
The problem is that there is an error message by importing the csv in 
excel, because there are to many columns needed to import the 100 objects.

So, my question:
Is it possible to write the 100 objects of the array among each other.
Like as it can be seen in R 
(http://img296.imageshack.us/my.php?image=ergebnissewa0.jpg)?
Another way is to produce 50 samples in a first turn and then produce 50 
samples again in another turn, but this can not be a "clean" solution 
(and surely not the only one).

Hopefully you can help me and this is the last question for my simulation.

Thanks for your efforts
Alex

-- 
Alexander Geisler * Kaltenbach 151 * A-6272 Kaltenbach
email: alexander.geisler at gmx.at | alexander.geisler at gmail.com
phone: +43 650 / 811 61 90 | skpye: al1405ex



From ggrothendieck at gmail.com  Thu Dec  7 22:38:52 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 7 Dec 2006 16:38:52 -0500
Subject: [R] templating library for R
In-Reply-To: <200612071445.52698.tamir@imp.univie.ac.at>
References: <200612071445.52698.tamir@imp.univie.ac.at>
Message-ID: <971536df0612071338k6d378a32ve24a1fb03c973bd6@mail.gmail.com>

I am not familiar with velocity or freemarker but
the gsubfn package can do string interpolation
somewhat similar to perl.  The gsubfn and strapply
functions in that package can handle arbitrary regular
expressions in a similar way. See:

http://code.google.com/p/gsubfn/



On 12/7/06, Ido M. Tamir <tamir at imp.univie.ac.at> wrote:
> Hi,
>
> does anybody know of a templating library for R,
> like velocity or freemarker?
>
> It doesn't have to be very fancy just a bit
> better than sub in replacing tags in a text (not
> necessarily html) file.
>
> thank you very much for your answer.
>
> Ido
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From aiminy at iastate.edu  Thu Dec  7 22:42:04 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Thu, 07 Dec 2006 15:42:04 -0600
Subject: [R] svm plot question
Message-ID: <6.1.2.0.2.20061207153850.01c32ac8@aiminy.mail.iastate.edu>

I run the following code, all other is ok,
but plot(m.svm,p5.new,As~Cur) is not ok

Anyone know why?

install.packages("e1071")
library(e1071)
library(MASS)
p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
p5.new<-subset(p5,select=-Ms)
p5.new$Y<-factor(p5.new$Y)
levels(p5.new$Y) <- list(Out=c(1), In=c(0))
attach(p5.new)
m.svm<-svm(Y~P+Aa+As+Cur,data=p5.new)
summary(m.svm)
plot(m.svm,p5.new,As~Cur)

Here is output:

 > install.packages("e1071")
--- Please select a CRAN mirror for use in this session ---
trying URL 
'http://rh-mirror.linux.iastate.edu/CRAN/bin/windows/contrib/2.4/e1071_1.5-16.zip'
Content type 'application/zip' length 592258 bytes
opened URL
downloaded 578Kb

package 'e1071' successfully unpacked and MD5 sums checked

The downloaded packages are in
         C:\Documents and Settings\aiminy\Local 
Settings\Temp\RtmpY0B2qb\downloaded_packages
updating HTML package descriptions
 > library(e1071)
Loading required package: class
 > library(MASS)
 > p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
 > p5.new<-subset(p5,select=-Ms)
 > p5.new$Y<-factor(p5.new$Y)
 > levels(p5.new$Y) <- list(Out=c(1), In=c(0))
 > attach(p5.new)
 > m.svm<-svm(Y~P+Aa+As+Cur,data=p5.new)
 > summary(m.svm)

Call:
svm(formula = Y ~ P + Aa + As + Cur, data = p5.new)


Parameters:
    SVM-Type:  C-classification
  SVM-Kernel:  radial
        cost:  1
       gamma:  0.04

Number of Support Vectors:  758

  ( 382 376 )


Number of Classes:  2

Levels:
  Out In



 > plot(m.svm,p5.new,As~Cur)
Error in scale(newdata[, object$scaled, drop = FALSE], center = 
object$x.scale$"scaled:center",  :
         (subscript) logical subscript too long
 >
 >



From backer at psych.uib.no  Thu Dec  7 22:58:09 2006
From: backer at psych.uib.no (Tom Backer Johnsen)
Date: Thu, 07 Dec 2006 22:58:09 +0100
Subject: [R] I do not understand this
In-Reply-To: <4578831B.90606@biostat.ku.dk>
References: <45787B03.6060603@psych.uib.no> <4578831B.90606@biostat.ku.dk>
Message-ID: <45788E71.9000002@psych.uib.no>

Peter Dalgaard wrote:
> Tom Backer Johnsen wrote:
>> A few days ago there was a thread on calling R from Delphi to which 
>> there were several useful responses.  Now I responded as well, with 
>> what I regard as a useful contribution.  Shortly after that, I was not 
>> able to able to see the thread in my newsreader (Thunderbird). 
>> Suddenly, yesterday I could see the thread again, and now it has 
>> vanished, at least from my sight.
>>
>> Now.  Is there an error in my reader, or more likely, an error in my 
>> use of the reader.  Or, has the thread been deleted for some reason. I 
>> wonder ...
>>
>> Tom
>>   
> How are you reading R-help?

Well, using Thunderbird with a filter, throwing everything with [R] in 
the subject line into a category or box.
> 
> Fundamentally, R-help is email based, so once a mail is sent, only the 
> receiver is involved in where it gets (mis)filed.

That's what I thought, so it may have something to do with my 
settings.  Strange, but I have never seen this before.
> 
> If you are using a mail-to-news gateway like gmane, then there could be 
> an issue with retention times. However, in the case of gmane, I doubt 
> that would be the case because the thread is here:
> 
> http://thread.gmane.org/gmane.comp.lang.r.general/75135/focus=75164

OK.  That's a relief.  I'll switch both mode "paranoid" and "wonder" 
to off and look at the settings of my mail program.  In any case, 
thank you!!

And by the way, your book is very nice for an R newbie like me.

Tom

+----------------------------------------------------------------+
| Tom Backer Johnsen, Psychometrics Unit,  Faculty of Psychology |
| University of Bergen, Christies gt. 12, N-5015 Bergen,  NORWAY |
| Tel : +47-5558-9185                        Fax : +47-5558-9879 |
| Email : backer at psych.uib.no    URL : http://www.galton.uib.no/ |
+----------------------------------------------------------------+



From lisawang at uhnres.utoronto.ca  Fri Dec  8 00:01:02 2006
From: lisawang at uhnres.utoronto.ca (Lisa Wang)
Date: Thu, 07 Dec 2006 18:01:02 -0500
Subject: [R] How to use read.xls in R
Message-ID: <45789D2E.3DC56261@uhnres.utoronto.ca>

Hello there,

In gdata package, read.xls is to be used for reading excel data (from
windows). 
The following is my code:('C:/session/sampledata.xls' is where the file
is stored)

data1<-read.xls('C:/session/sampledata.xls',sheet=1)

and I got the following error message:
Error in system(cmd, intern = !verbose) : perl not found

Could you please tell me what I have done wrong and how I should do it?

Thanks a lot

Lisa Wang 
Princess Margaret Hospital, Toronto, Ca
tel:416 946 4551



From sundar.dorai-raj at pdf.com  Fri Dec  8 00:06:19 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 07 Dec 2006 15:06:19 -0800
Subject: [R] How to use read.xls in R
In-Reply-To: <45789D2E.3DC56261@uhnres.utoronto.ca>
References: <45789D2E.3DC56261@uhnres.utoronto.ca>
Message-ID: <45789E6B.3070803@pdf.com>



Lisa Wang said the following on 12/7/2006 3:01 PM:
> Hello there,
> 
> In gdata package, read.xls is to be used for reading excel data (from
> windows). 
> The following is my code:('C:/session/sampledata.xls' is where the file
> is stored)
> 
> data1<-read.xls('C:/session/sampledata.xls',sheet=1)
> 
> and I got the following error message:
> Error in system(cmd, intern = !verbose) : perl not found
> 
> Could you please tell me what I have done wrong and how I should do it?
> 
> Thanks a lot
> 
> Lisa Wang 
> Princess Margaret Hospital, Toronto, Ca
> tel:416 946 4551
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Please reread ?read.xls. Quote from the "Note" section:

"Either a working version of Perl must be present in the executable 
search path, or the exact path of the perl executable must be provided 
via the perl argument. See the examples below for an illustration."

You need to install perl.

http://www.activestate.com/Products/ActivePerl/Download.html

HTH,

--sundar



From blomsp at ozemail.com.au  Fri Dec  8 00:29:53 2006
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Fri, 08 Dec 2006 10:29:53 +1100
Subject: [R] lmer, p-values and all that
In-Reply-To: <000801c719f0$12779220$d22401a3@plants.ox.ac.uk>
References: <000801c719f0$12779220$d22401a3@plants.ox.ac.uk>
Message-ID: <4578A3F1.2040408@ozemail.com.au>

Try using mcmcsamp() to sample from the posterior distribution of the 
parameter estimates. You can calculate a p-value from that, if that is 
your desire. Instructions are in the R wiki:  
http://wiki.r-project.org/rwiki/doku.php?id=guides:lmer-tests

HTH,

Simon.


Dan Bebber wrote:
> Hello,
> I've just located the illuminating explanation by Douglas Bates on degrees 
> of freedom in mixed models.
> The take-home message appears to be: don't trust the p-values from lme.
> Questions:
> Should I give up hypothesis testing for fixed effects terms in mixed models?
> Has my time spent reading Pinheiro & Bates been in vain?
> Is there a publication on this issue?
>
> Thanks,
> Dan Bebber
>
> Department of Plant Sciences
> University of Oxford
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>   


-- 
Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat. 
Centre for Resource and Environmental Studies
The Australian National University              
Canberra ACT 0200                               
Australia                                       
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer 
can be extracted from a given body of data.
- John Tukey.



From ggrothendieck at gmail.com  Fri Dec  8 01:05:20 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 7 Dec 2006 19:05:20 -0500
Subject: [R] How to use read.xls in R
In-Reply-To: <45789D2E.3DC56261@uhnres.utoronto.ca>
References: <45789D2E.3DC56261@uhnres.utoronto.ca>
Message-ID: <971536df0612071605u2dcfcf77oa381fa6eb6cff75b@mail.gmail.com>

You need perl installed for it to work.
Although you normally would not need to use them note the
verbose= and perl= arguments on the read.xls command.

If you don't want to install perl try using RODBC:

      library(RODBC)
      z <- odbcConnectExcel("/a.xls")
      dd <- sqlFetch(z,"Sheet1")
      close(z)


On 12/7/06, Lisa Wang <lisawang at uhnres.utoronto.ca> wrote:
> Hello there,
>
> In gdata package, read.xls is to be used for reading excel data (from
> windows).
> The following is my code:('C:/session/sampledata.xls' is where the file
> is stored)
>
> data1<-read.xls('C:/session/sampledata.xls',sheet=1)
>
> and I got the following error message:
> Error in system(cmd, intern = !verbose) : perl not found
>
> Could you please tell me what I have done wrong and how I should do it?
>
> Thanks a lot
>
> Lisa Wang
> Princess Margaret Hospital, Toronto, Ca
> tel:416 946 4551
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From gerifalte28 at hotmail.com  Fri Dec  8 01:52:22 2006
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Thu, 07 Dec 2006 17:52:22 -0700
Subject: [R] How to use read.xls in R
In-Reply-To: <971536df0612071605u2dcfcf77oa381fa6eb6cff75b@mail.gmail.com>
References: <45789D2E.3DC56261@uhnres.utoronto.ca>
	<971536df0612071605u2dcfcf77oa381fa6eb6cff75b@mail.gmail.com>
Message-ID: <4578B746.4010801@hotmail.com>

Or alternatively you can use xlsReadWrite package

install.packages(xlsReadWrite)
library(xlsReadWrite)
read.xls("sampledata.xls")

Regards,

Francisco

Dr. Francisco J. Zagmutt
College of Veterinary Medicine and Biomedical Sciences
Colorado State University


Gabor Grothendieck wrote:
> You need perl installed for it to work.
> Although you normally would not need to use them note the
> verbose= and perl= arguments on the read.xls command.
> 
> If you don't want to install perl try using RODBC:
> 
>       library(RODBC)
>       z <- odbcConnectExcel("/a.xls")
>       dd <- sqlFetch(z,"Sheet1")
>       close(z)
> 
> 
> On 12/7/06, Lisa Wang <lisawang at uhnres.utoronto.ca> wrote:
>> Hello there,
>>
>> In gdata package, read.xls is to be used for reading excel data (from
>> windows).
>> The following is my code:('C:/session/sampledata.xls' is where the file
>> is stored)
>>
>> data1<-read.xls('C:/session/sampledata.xls',sheet=1)
>>
>> and I got the following error message:
>> Error in system(cmd, intern = !verbose) : perl not found
>>
>> Could you please tell me what I have done wrong and how I should do it?
>>
>> Thanks a lot
>>
>> Lisa Wang
>> Princess Margaret Hospital, Toronto, Ca
>> tel:416 946 4551
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From gerifalte28 at hotmail.com  Fri Dec  8 01:52:22 2006
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Thu, 07 Dec 2006 17:52:22 -0700
Subject: [R] How to use read.xls in R
In-Reply-To: <971536df0612071605u2dcfcf77oa381fa6eb6cff75b@mail.gmail.com>
References: <45789D2E.3DC56261@uhnres.utoronto.ca>
	<971536df0612071605u2dcfcf77oa381fa6eb6cff75b@mail.gmail.com>
Message-ID: <4578B746.4010801@hotmail.com>

Or alternatively you can use xlsReadWrite package

install.packages(xlsReadWrite)
library(xlsReadWrite)
read.xls("sampledata.xls")

Regards,

Francisco

Dr. Francisco J. Zagmutt
College of Veterinary Medicine and Biomedical Sciences
Colorado State University


Gabor Grothendieck wrote:
> You need perl installed for it to work.
> Although you normally would not need to use them note the
> verbose= and perl= arguments on the read.xls command.
> 
> If you don't want to install perl try using RODBC:
> 
>       library(RODBC)
>       z <- odbcConnectExcel("/a.xls")
>       dd <- sqlFetch(z,"Sheet1")
>       close(z)
> 
> 
> On 12/7/06, Lisa Wang <lisawang at uhnres.utoronto.ca> wrote:
>> Hello there,
>>
>> In gdata package, read.xls is to be used for reading excel data (from
>> windows).
>> The following is my code:('C:/session/sampledata.xls' is where the file
>> is stored)
>>
>> data1<-read.xls('C:/session/sampledata.xls',sheet=1)
>>
>> and I got the following error message:
>> Error in system(cmd, intern = !verbose) : perl not found
>>
>> Could you please tell me what I have done wrong and how I should do it?
>>
>> Thanks a lot
>>
>> Lisa Wang
>> Princess Margaret Hospital, Toronto, Ca
>> tel:416 946 4551
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From A.Robinson at ms.unimelb.edu.au  Fri Dec  8 03:42:14 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 8 Dec 2006 13:42:14 +1100
Subject: [R] groupedData Error Using outer=TRUE
In-Reply-To: <1165507358.3532.13.camel@localhost.localdomain>
References: <1165507358.3532.13.camel@localhost.localdomain>
Message-ID: <20061208024214.GA75038@ms.unimelb.edu.au>

Rick,

I think that it will be easier for us to comment if you send us
reproducible code.  Cna you reproduce the error, for example, using
one of the datasets that accompanise the nlme package?  If so, please
send us that code.  If not, then there could bea problem with your
data.  Either way, we're in a better position to help you.

Cheers,

Andrew

On Thu, Dec 07, 2006 at 11:02:38AM -0500, Rick Bilonick wrote:
> I'm using groupedData from nlme. I set up a groupedData data.frame with
> outer=~group1. When I try to plot with outer=TRUE, I get "subscript out
> of bounds." This happens most of the time. When it works, I get
> spaghetti-type plots for comparing groups. But I don't understand why it
> doesn't usually work.
> 
> > longa.mod.1.gd <- groupedData(mod1.logit~time|
> name/eye,outer=~group1,data=longa.mod.1)
> > plot(longa.mod.1.gd)
> > plot(longa.mod.1.gd,outer=TRUE)
> Error in attribs[["outer"]][[displayLevel]] :
>         subscript out of bounds
> 
> What am I doing wrong?
> 
> Rick B.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From aiminy at iastate.edu  Fri Dec  8 04:32:01 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Thu, 07 Dec 2006 21:32:01 -0600
Subject: [R] please help me for svm plot question
Message-ID: <6.1.2.0.2.20061207213137.01d09e88@aiminy.mail.iastate.edu>

I run the following code, all other is ok,
but plot(m.svm,p5.new,As~Cur) is not ok

Anyone know why?

install.packages("e1071")
library(e1071)
library(MASS)
p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
p5.new<-subset(p5,select=-Ms)
p5.new$Y<-factor(p5.new$Y)
levels(p5.new$Y) <- list(Out=c(1), In=c(0))
attach(p5.new)
m.svm<-svm(Y~P+Aa+As+Cur,data=p5.new)
summary(m.svm)
plot(m.svm,p5.new,As~Cur)

Here is output:

 > install.packages("e1071")
--- Please select a CRAN mirror for use in this session ---
trying URL 
'http://rh-mirror.linux.iastate.edu/CRAN/bin/windows/contrib/2.4/e1071_1.5-16.zip'
Content type 'application/zip' length 592258 bytes
opened URL
downloaded 578Kb

package 'e1071' successfully unpacked and MD5 sums checked

The downloaded packages are in
         C:\Documents and Settings\aiminy\Local 
Settings\Temp\RtmpY0B2qb\downloaded_packages
updating HTML package descriptions
 > library(e1071)
Loading required package: class
 > library(MASS)
 > p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
 > p5.new<-subset(p5,select=-Ms)
 > p5.new$Y<-factor(p5.new$Y)
 > levels(p5.new$Y) <- list(Out=c(1), In=c(0))
 > attach(p5.new)
 > m.svm<-svm(Y~P+Aa+As+Cur,data=p5.new)
 > summary(m.svm)

Call:
svm(formula = Y ~ P + Aa + As + Cur, data = p5.new)


Parameters:
    SVM-Type:  C-classification
  SVM-Kernel:  radial
        cost:  1
       gamma:  0.04

Number of Support Vectors:  758

  ( 382 376 )


Number of Classes:  2

Levels:
  Out In



 > plot(m.svm,p5.new,As~Cur)
Error in scale(newdata[, object$scaled, drop = FALSE], center = 
object$x.scale$"scaled:center",  :
         (subscript) logical subscript too long
 >
 >



From aiminy at iastate.edu  Fri Dec  8 04:48:39 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Thu, 07 Dec 2006 21:48:39 -0600
Subject: [R] please help me for svm plot question
Message-ID: <6.1.2.0.2.20061207214835.01d135f0@aiminy.mail.iastate.edu>

I run the following code, all other is ok,
but plot(m.svm,p5.new,As~Cur) is not ok

Anyone know why?

install.packages("e1071")
library(e1071)
library(MASS)
p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
p5.new<-subset(p5,select=-Ms)
p5.new$Y<-factor(p5.new$Y)
levels(p5.new$Y) <- list(Out=c(1), In=c(0))
attach(p5.new)
m.svm<-svm(Y~P+Aa+As+Cur,data=p5.new)
summary(m.svm)
plot(m.svm,p5.new,As~Cur)

Here is output:

 > install.packages("e1071")
--- Please select a CRAN mirror for use in this session ---
trying URL 
'http://rh-mirror.linux.iastate.edu/CRAN/bin/windows/contrib/2.4/e1071_1.5-16.zip'
Content type 'application/zip' length 592258 bytes
opened URL
downloaded 578Kb

package 'e1071' successfully unpacked and MD5 sums checked

The downloaded packages are in
         C:\Documents and Settings\aiminy\Local 
Settings\Temp\RtmpY0B2qb\downloaded_packages
updating HTML package descriptions
 > library(e1071)
Loading required package: class
 > library(MASS)
 > p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
 > p5.new<-subset(p5,select=-Ms)
 > p5.new$Y<-factor(p5.new$Y)
 > levels(p5.new$Y) <- list(Out=c(1), In=c(0))
 > attach(p5.new)
 > m.svm<-svm(Y~P+Aa+As+Cur,data=p5.new)
 > summary(m.svm)

Call:
svm(formula = Y ~ P + Aa + As + Cur, data = p5.new)


Parameters:
    SVM-Type:  C-classification
  SVM-Kernel:  radial
        cost:  1
       gamma:  0.04

Number of Support Vectors:  758

  ( 382 376 )


Number of Classes:  2

Levels:
  Out In



 > plot(m.svm,p5.new,As~Cur)
Error in scale(newdata[, object$scaled, drop = FALSE], center = 
object$x.scale$"scaled:center",  :
         (subscript) logical subscript too long
 >
 >



From aiminy at iastate.edu  Fri Dec  8 05:09:28 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Thu, 07 Dec 2006 22:09:28 -0600
Subject: [R] svm code, what is wrong here?
Message-ID: <6.1.2.0.2.20061207220849.01ccba38@aiminy.mail.iastate.edu>


 > install.packages("e1071")
Warning: package 'e1071' is in use and will not be installed
 > library(e1071)
 > library(MASS)
 > p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
 > attach(p5)

         The following object(s) are masked from p5 ( position 3 ) :

          Aa As Cur Ms P Y


         The following object(s) are masked from p5 ( position 4 ) :

          Aa As Cur Ms P Y

 > m.svm<-svm(as.factor(Y)~.,data=p5)
 > summary(m.svm)

Call:
svm(formula = as.factor(Y) ~ ., data = p5)


Parameters:
    SVM-Type:  C-classification
  SVM-Kernel:  radial
        cost:  1
       gamma:  0.03846154

Number of Support Vectors:  755

  ( 377 378 )


Number of Classes:  2

Levels:
  0 1



 > plot(m.svm,p5,As~Cur)
Error in scale(newdata[, object$scaled, drop = FALSE], center = 
object$x.scale$"scaled:center",  :
         (subscript) logical subscript too long
 >
 >



From aiminy at iastate.edu  Fri Dec  8 05:33:50 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Thu, 07 Dec 2006 22:33:50 -0600
Subject: [R] plot.svm
Message-ID: <6.1.2.0.2.20061207223301.01ce8b08@aiminy.mail.iastate.edu>

where is plot.svm method?
I just find plot(svm, data, formula) method

Aimin



From wdelport at botzoo.uct.ac.za  Fri Dec  8 08:27:44 2006
From: wdelport at botzoo.uct.ac.za (Wayne Delport)
Date: Fri, 8 Dec 2006 09:27:44 +0200
Subject: [R] formula format for parameter estimation
Message-ID: <c752717b7efbe7d0a43545bbeaf97238@botzoo.uct.ac.za>

Hello, I am trying to input the following formula into R for parameter 
estimation. I don't quite have the just of formula syntax. I understand 
simple basic regression (y ~ x), but how do I do the ff:

y = ( b0*x )/(x + b1),

where b0 and b1 are parameters that need to be solved. Any 
help/suggestions for a newbie would be much appreciated. thanks ./w

Wayne Delport

Molecular Ecology and Evolution Programme
Department of Genetics
University of Pretoria
Pretoria
0002
South Africa

Percy FitzPatrick Institute of African Ornithology
University of Cape Town
Rondebosch
Cape Town
7701
South Africa

"640K ought to be enough for anybody" Bill Gates, 1981

"I love deadlines, I love the whooshing noise they make as they go by." 
Douglas Adams



From simon.kempf at web.de  Fri Dec  8 09:12:34 2006
From: simon.kempf at web.de (Simon P. Kempf)
Date: Fri, 8 Dec 2006 09:12:34 +0100
Subject: [R] Multiple Imputation / Non Parametric Models / Combining Results
Message-ID: <E1GsaqY-0000JP-00@smtp08.web.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061208/6421fb4b/attachment-0005.pl 

From andza at osi.lv  Fri Dec  8 09:36:37 2006
From: andza at osi.lv (Andris Jankevics)
Date: Fri, 8 Dec 2006 10:36:37 +0200
Subject: [R] question about apply function
Message-ID: <200612081036.38036.andza@osi.lv>

Dear R-Users,

For example i have a data matrix with five samples and three variables.

DATA <- matrix(c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5),nrow=5,ncol=3,byrow=TRUE)
colnames (DATA) <- c("V1","V2","V3")
rownames (DATA) <- c("S1","S2","S3","S4","S5")

I want to normalize all samples to same sum of variables:

NormFun <- function (i) {(i*(1/sum(i)))}

Dnorm <- apply(DATA,1,NormFun)

Why I am getting tranposed matrix Dnorm? And with my experimental data (with 
32k variables) i am getting a slighty different results from:

apply(DATA,1,NormFun)
apply(t(DATA),2,NormFun)

Thankyou,

Andris Jankevics



From dimitris.rizopoulos at med.kuleuven.be  Fri Dec  8 09:48:41 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 8 Dec 2006 09:48:41 +0100
Subject: [R] question about apply function
References: <200612081036.38036.andza@osi.lv>
Message-ID: <006701c71aa5$a9215b10$0540210a@www.domain>

in this case you may use something like the following:

DATA <- matrix(1:5, 5, 3)
dimnames(DATA) <- list(c("S1","S2","S3","S4","S5"), c("V1","V2","V3"))
#####################
DATA / rowSums(DATA)
DATA / rep(colSums(DATA), each = nrow(DATA))


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Andris Jankevics" <andza at osi.lv>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, December 08, 2006 9:36 AM
Subject: [R] question about apply function


> Dear R-Users,
>
> For example i have a data matrix with five samples and three 
> variables.
>
> DATA <- 
> matrix(c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5),nrow=5,ncol=3,byrow=TRUE)
> colnames (DATA) <- c("V1","V2","V3")
> rownames (DATA) <- c("S1","S2","S3","S4","S5")
>
> I want to normalize all samples to same sum of variables:
>
> NormFun <- function (i) {(i*(1/sum(i)))}
>
> Dnorm <- apply(DATA,1,NormFun)
>
> Why I am getting tranposed matrix Dnorm? And with my experimental 
> data (with
> 32k variables) i am getting a slighty different results from:
>
> apply(DATA,1,NormFun)
> apply(t(DATA),2,NormFun)
>
> Thankyou,
>
> Andris Jankevics
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From gustaf.rydevik at gmail.com  Fri Dec  8 09:59:16 2006
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Fri, 8 Dec 2006 11:59:16 +0300
Subject: [R] filled.contour and NA's
In-Reply-To: <456DE30F.7090002@gmail.com>
References: <456DE30F.7090002@gmail.com>
Message-ID: <45f568c70612080059k38506424hb294ab029fc0ad59@mail.gmail.com>

On 11/29/06, antonio rodriguez <antonio.raju at gmail.com> wrote:
> Hi,
>
> I'm trying to do a filled.contour plot where some points are labelled as
> NA. How do I could plot this kind of graphics, so NA points are coloured
> black,  keeping the levels of remaining points. NA's values represent
> land points (meaningless), and what I want to plot is the levels of a
> variable over the sea.


Hi Antonio,

I haven't seen a reply to your question yet, so I'll make a try.

I'm having the same issue myself. What I've ended up doing is
replacing NA's with a big negative value, define "levels" as one color
for negative values, and a regular scale above. This gives a fairly
good separation between what areas contain data, and what doesn't. To
make NA's black, I suppose one would have to define your own
colour.palette, but I haven't looked into it.

Hope this helps, and let me know if you've found a better solution!

Best,

Gustaf Rydevik



From wolfram at fischer-zim.ch  Fri Dec  8 10:52:55 2006
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Fri, 8 Dec 2006 10:52:55 +0100
Subject: [R] lattice: defining an own function using args for "formula" and
	"groups"
Message-ID: <20061208095255.GA4092@s1x.fischer-zim.local>


x.fun <- function( formula, data ) dotplot( formula, data )
x.grp <- function( formula, groups, data ) dotplot( formula, groups, data )

data( barley )

> x.fun( variety ~ yield | site, data=barley )
# no problem

> dotplot( variety ~ yield | site, groups=year, data=barley )
# no problem

> x.grp( variety ~ yield | site, groups=year, data=barley )
object "year" not found 	# that's my error, so I do:

> x.grp( variety ~ yield | site, groups=barley$year, data=barley )
Error in eval(expr, envir, enclos) : numeric 'envir' arg not of length one

> traceback()
9: eval(substitute(groups), data, environment(formula))
8: bwplot.formula(x = formula, data = c(2, 2, 2, 2, 2, 2, 2, 2,  ...

Why it is a problem calling x.grp() and no problem calling x.fun() ?
What could I do to get work x.grp() ?

Thanks - Wolfram



From gustaf.rydevik at gmail.com  Fri Dec  8 10:58:01 2006
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Fri, 8 Dec 2006 12:58:01 +0300
Subject: [R] Aggregate?
Message-ID: <45f568c70612080158r310a7d67v8688b6ca2c0264f1@mail.gmail.com>

Hi All,

I think i'm failing to undersatnd how aggregate() is supposed to work.

example:

 test1<-sample(c(0,1),100,replace=T)
test2<-sample(letters,100,replace=T)
aggregate(test1,list(test2),sum)
Error in data.frame(w, lapply(y, unlist, use.names = FALSE)) :
        arguments imply differing number of rows: 26, 0

I thought this would give me a list containing the number of ones that
"belong" to each letter. What am I doing wrong?

Thanks in advance,

Gustaf

-- 
email:gustaf.rydevik at gmail.com
tel: +46(0)703051451
address: Kantorsgatan 50:190 75424 Uppsala Sweden



From justin_bem at yahoo.fr  Fri Dec  8 11:03:08 2006
From: justin_bem at yahoo.fr (justin bem)
Date: Fri, 8 Dec 2006 10:03:08 +0000 (GMT)
Subject: [R] Re :  formula format for parameter estimation
Message-ID: <20061208100308.44145.qmail@web23013.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061208/b28f4f5a/attachment-0005.pl 

From jenny197806 at yahoo.se  Fri Dec  8 11:30:17 2006
From: jenny197806 at yahoo.se (Jenny persson)
Date: Fri, 8 Dec 2006 11:30:17 +0100 (CET)
Subject: [R] How to plot two variables in the same qqnorm-plot?
Message-ID: <248548.44174.qm@web28009.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061208/fb023d28/attachment-0005.pl 

From I.Visser at uva.nl  Fri Dec  8 11:48:57 2006
From: I.Visser at uva.nl (Ingmar Visser)
Date: Fri, 08 Dec 2006 11:48:57 +0100
Subject: [R] Aggregate?
In-Reply-To: <45f568c70612080158r310a7d67v8688b6ca2c0264f1@mail.gmail.com>
Message-ID: <C19F01A9.B873%I.Visser@uva.nl>

It does that for me without errors ...
(R 2.3.1 on Mac OSX 10.4.8)
Best, Ingmar


> From: Gustaf Rydevik <gustaf.rydevik at gmail.com>
> Date: Fri, 8 Dec 2006 12:58:01 +0300
> To: <r-help at stat.math.ethz.ch>
> Subject: [R] Aggregate?
> 
> Hi All,
> 
> I think i'm failing to undersatnd how aggregate() is supposed to work.
> 
> example:
> 
>  test1<-sample(c(0,1),100,replace=T)
> test2<-sample(letters,100,replace=T)
> aggregate(test1,list(test2),sum)
> Error in data.frame(w, lapply(y, unlist, use.names = FALSE)) :
>         arguments imply differing number of rows: 26, 0
> 
> I thought this would give me a list containing the number of ones that
> "belong" to each letter. What am I doing wrong?
> 
> Thanks in advance,
> 
> Gustaf
> 
> -- 
> email:gustaf.rydevik at gmail.com
> tel: +46(0)703051451
> address: Kantorsgatan 50:190 75424 Uppsala Sweden
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From dimitris.rizopoulos at med.kuleuven.be  Fri Dec  8 11:50:54 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 8 Dec 2006 11:50:54 +0100
Subject: [R] How to plot two variables in the same qqnorm-plot?
References: <248548.44174.qm@web28009.mail.ukl.yahoo.com>
Message-ID: <00af01c71ab6$be20a910$0540210a@www.domain>

try this:

z1 <- rnorm(100)
z2 <- rt(100, 3)
##########
q1 <- qqnorm(z1, plot.it = FALSE)
q2 <- qqnorm(z2, plot.it = FALSE)
plot(range(q1$x, q2$x), range(q1$y, q2$y), type = "n")
points(q1)
points(q2, col = "red", pch = 3)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Jenny persson" <jenny197806 at yahoo.se>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, December 08, 2006 11:30 AM
Subject: [R] How to plot two variables in the same qqnorm-plot?


>  Dear all,
>
>  I have two variables called c2 and c3 and want to plot these 
> variables in the same qqnorm-plot with two different symbols or 
> colors to distinguish them so I can easily compare the variables 
> aginst each other. How can I do in R? I only manage to do two 
> separated qqnorn-plots.
>
>  Thanks for your help,
>
>  All the best,
>  Jenny
>
>
>
>  c2=
>  -0.1545775144 -0.0601161235 -0.1454710903 
> 0.1893182564 -0.0470586789
>  -0.0740945381 -0.0041386301 
> 0.0889232833 -0.0418779055 -0.0184595989
>  -0.1116784460 0.5286719173 -0.0714560939 -0.1160750488 0.2479689612
>  -0.0255424336 -0.1802256606 -0.1436590798 
> 0.2091955894 -0.0408695231
>  -0.0097490458 0.4674886420 0.1310178029 0.2518403775
>
>  c3=
>  -0.1696564482 -0.1126714841 -0.1460504793 
> 0.1674967485 -0.0181011669
>  -0.0671367425 0.3261235871 0.0125372613 -0.0970306822 0.0066345879
>  -0.0438274488 0.8376670819 -0.1195411677 -0.0735540655 0.2999832105
>  -0.0133914650 -0.1020235781 -0.0929364933 
> 0.1909337727 -0.0198168723
>  0.0544515704 0.5744399944 0.5022208978 -0.1494894501
>
>
>
>
>
>
> ---------------------------------
>
> Stava r?tt! Stava l?tt! Yahoo! Mails stavkontroll tar hand om 
> tryckfelen och mycket mer! F? den p? http://se.mail.yahoo.com
> [[alternative HTML version deleted]]
>
>


--------------------------------------------------------------------------------


> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From miri.dago at virgilio.it  Fri Dec  8 12:56:42 2006
From: miri.dago at virgilio.it (miri.dago at virgilio.it)
Date: Fri, 8 Dec 2006 12:56:42 +0100 (GMT+01:00)
Subject: [R] MAXIMIZATION WITH CONSTRAINTS
Message-ID: <10f61ec2426.miri.dago@virgilio.it>

Dear R users, 
I?m a graduate students and in my master thesis I  must 
obtain the values of the parameters x_i which maximize this  
Multinomial log?likelihood function
log(n!)-sum_{i=1]^4 log(n_i!)+sum_
{i=1}^4 n_i log(x_i)

under the following constraints:
a) sum_i x_i=1, 
x_i>=0, 
b) x_1<=x_2+x_3+x_4
c)x_2<=x_3+x_4
I have been using the 
?ConstrOptim? R-function with the instructions I report below, and I 
have tried to implement them with different values of ?n?. BUT I have 
encountered 2 problems:

1) the result of the maximization is the same 
of the minimization, i.e. the maximum value of the   function is equal 
to the minimum (TOO OFTEN)
2) a lot of times the algorithm returns 
errors such as ?value out of range in 'gammafn'? 

In both cases 1) 2) 
I don?t know where is the problem, which is my mistake. Can you help 
me?! Do you know another way to solve my problem of maximization under 
constraints? 
THANKS!

My R instructions

n=c(10,20,3,5)
n1=n[1]
n2=n
[2]
n3=n[3]
n4=n[4]

logfr=function(x) { ##function to maximize 
x1= x
[1] 
x2= x[2] 
x3= x[3]
x4= x[4]
log(factorial(sum(n)))-sum(log
(factorial(n)))+sum(n*log(x)) 
} 
grr.log <- function(x) { ## Gradient 
of 'log fr'
x1=x[1] 
x2=x[2] 
x3=x[3]
x4=x[4]
return(n/x)
} 
par.start= 
c(.19999999,.15,.4,.25)
constr.coeff = rbind(diag(1,4,4),c(-1,1,1,1),c
(0,-1,1,1),c(-1,-1,-1,-1), c(1,1,1,1))
constr.tn= c(0,0,0,0,0,0,-1,.
9999999)
min= constrOptim(par.start, logfr, grr.log, ui=constr.coeff, 
ci=constr.tn)
max=constrOptim(par.start, logfr, grr.log, ui=constr.
coeff, ci=constr.tn, control=list(fnscale=-1))



From arun.kumar.saha at gmail.com  Fri Dec  8 13:00:29 2006
From: arun.kumar.saha at gmail.com (Arun Kumar Saha)
Date: Fri, 8 Dec 2006 17:30:29 +0530
Subject: [R] fmincon equivalent in R
Message-ID: <d4c57560612080400q5d3efedfwd6fd6b47d060fa39@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061208/6b353d8c/attachment-0005.pl 

From ggrothendieck at gmail.com  Fri Dec  8 13:07:09 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 8 Dec 2006 07:07:09 -0500
Subject: [R] lattice: defining an own function using args for "formula"
	and "groups"
In-Reply-To: <20061208095255.GA4092@s1x.fischer-zim.local>
References: <20061208095255.GA4092@s1x.fischer-zim.local>
Message-ID: <971536df0612080407h1e674060v9723de10d73a65d9@mail.gmail.com>

Don't know of a more straight forward way but this works. It constructs
a new call to bwplot from the one to x.grp2 and evaluates it in the
parent environment:

library(lattice)
x.grp2 <- function(x, groups, data) {
    cl <- match.call()
    cl[[1]] <- as.name("bwplot")
    eval.parent(cl)
}

x.grp2( variety ~ yield | site, year, barley )


On 12/8/06, Wolfram Fischer <wolfram at fischer-zim.ch> wrote:
>
> x.fun <- function( formula, data ) dotplot( formula, data )
> x.grp <- function( formula, groups, data ) dotplot( formula, groups, data )
>
> data( barley )
>
> > x.fun( variety ~ yield | site, data=barley )
> # no problem
>
> > dotplot( variety ~ yield | site, groups=year, data=barley )
> # no problem
>
> > x.grp( variety ~ yield | site, groups=year, data=barley )
> object "year" not found         # that's my error, so I do:
>
> > x.grp( variety ~ yield | site, groups=barley$year, data=barley )
> Error in eval(expr, envir, enclos) : numeric 'envir' arg not of length one
>
> > traceback()
> 9: eval(substitute(groups), data, environment(formula))
> 8: bwplot.formula(x = formula, data = c(2, 2, 2, 2, 2, 2, 2, 2,  ...
>
> Why it is a problem calling x.grp() and no problem calling x.fun() ?
> What could I do to get work x.grp() ?
>
> Thanks - Wolfram
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From petr.pikal at precheza.cz  Fri Dec  8 13:18:10 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 08 Dec 2006 13:18:10 +0100
Subject: [R] Aggregate?
In-Reply-To: <45f568c70612080158r310a7d67v8688b6ca2c0264f1@mail.gmail.com>
Message-ID: <45796612.29497.155743B@localhost>

Hi

look to your workspace by ls(). I bet there is some mismatch in 
variables as your example works for me without any error. You 
probably redefined sum function.

>  test1<-sample(c(0,1),100,replace=T)
> test2<-sample(letters,100,replace=T)
> aggregate(test1,list(test2),sum)
   Group.1 x
1        b 1
2        c 3
3        d 1
4        e 4

> sum<-5
> aggregate(test1,list(test2),sum)
Error in FUN(X[[1]], ...) : argument "INDEX" is missing, with no 
default

HTH
Petr





On 8 Dec 2006 at 12:58, Gustaf Rydevik wrote:

Date sent:      	Fri, 8 Dec 2006 12:58:01 +0300
From:           	"Gustaf Rydevik" <gustaf.rydevik at gmail.com>
To:             	r-help at stat.math.ethz.ch
Subject:        	[R] Aggregate?

> Hi All,
> 
> I think i'm failing to undersatnd how aggregate() is supposed to work.
> 
> example:
> 
>  test1<-sample(c(0,1),100,replace=T)
> test2<-sample(letters,100,replace=T)
> aggregate(test1,list(test2),sum)
> Error in data.frame(w, lapply(y, unlist, use.names = FALSE)) :
>         arguments imply differing number of rows: 26, 0
> 
> I thought this would give me a list containing the number of ones that
> "belong" to each letter. What am I doing wrong?
> 
> Thanks in advance,
> 
> Gustaf
> 
> -- 
> email:gustaf.rydevik at gmail.com
> tel: +46(0)703051451
> address: Kantorsgatan 50:190 75424 Uppsala Sweden
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

Petr Pikal
petr.pikal at precheza.cz



From ked at nilu.no  Fri Dec  8 13:20:10 2006
From: ked at nilu.no (=?ISO-8859-1?Q?K=E5re?= Edvardsen)
Date: Fri, 08 Dec 2006 13:20:10 +0100
Subject: [R] A smal fitting problem...
Message-ID: <1165580410.8500.181.camel@localhost.localdomain>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061208/eaf43743/attachment-0005.pl 

From alex at transitive.com  Fri Dec  8 13:27:25 2006
From: alex at transitive.com (Alex Brown)
Date: Fri, 8 Dec 2006 12:27:25 +0000
Subject: [R] missing factor levels in a lattice barchart panel cause
	unexpected failure
Message-ID: <36BC5C60-1632-4E36-8005-2BA11AF449C5@transitive.com>

Hi all - I'm trying to generate lattice barchart graphs with missing  
values, and came across the following:

This does not run.  I would expect it to:

library(lattice)
D = data.frame(X=1, Y=factor(letters[2], letters[1:2]))
barchart(~ X, D, groups=Y)

Error in grid.Call.graphics("L_rect", x$x, x$y, x$width, x$height,  
resolveHJust(x$just,  :
	invalid line type

which is simply solved by changing the factor levels:

D$Y = factor(D$Y)
barchart(~ X, D, groups=Y)

or by filling factor levels from the bottom:

D = data.frame(X=1, Y=factor(letters[1], letters[1:2]))
barchart(~ X, D, groups=Y)

However, the failure is important, because it causes the following to  
fail, no matter how Y is levelled

E = data.frame(X=c(1,2,3,4), Y=factor(letters[c(1,2,1,2)], letters 
[1:2]), Z=factor(c("F","F","G","H")));
barchart(~ X | Z, E, groups=Y)

Which is an example of a comparison over multiple tests Z for  
different parameter Y where some Y are missing.

alternative version:

E = data.frame(X=c(1,2,3,4), Y=letters[c(1,2,1,2)], Z=letters[c 
(7,7,8,9)]);
barchart(~ X | Z, E, groups=Y)

I have updated to 2.4.0 and lattice 0.14-16 and the problem still  
exists.

-Alex Brown



From david.meyer at wu-wien.ac.at  Fri Dec  8 13:32:00 2006
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Fri, 08 Dec 2006 13:32:00 +0100
Subject: [R] svm plot question
In-Reply-To: <6.1.2.0.2.20061207170402.01ca1058@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061207170402.01ca1058@aiminy.mail.iastate.edu>
Message-ID: <45795B40.2060105@wu-wien.ac.at>

Aimin:

1) Please do not spam the r-help list---one request per issue (and two
private mails to the code author) really suffice. Not all contributors
to the R-project are on-line 24/24, and have time to provide immediate
answers.

2) The error occurs because plot.svm() currently does not set valid
defaults for categorical dimensions you are conditioning on for your
2D-plot (in your example: 'P' and 'Aa') which certainly is a bug. I will
commit a fix for the next release of e1071. For the time being, you will
have to explicitly specify the levels of 'P' and 'Aa':

plot(m.svm,p5.new,As~Cur, slice = list(P = factor("821p", levels =
levels(P)), Aa = factor("ALA", levels = levels(Aa))))

(Note that the defaults for the "slice" argument are completely
arbitrary anyway).

Thanks for pointing this out,

David

Aimin Yan wrote:
> I have a question about svm in R
> 
> I run the following code, all other is ok,
> but plot(m.svm,p5.new,As~Cur) is not ok
> 
> Do you know why?
> 
> install.packages("e1071")
> library(e1071)
> library(MASS)
> p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
> p5.new<-subset(p5,select=-Ms)
> p5.new$Y<-factor(p5.new$Y)
> levels(p5.new$Y) <- list(Out=c(1), In=c(0))
> attach(p5.new)
> m.svm<-svm(Y~P+Aa+As+Cur,data=p5.new)
> summary(m.svm)
> plot(m.svm,p5.new,As~Cur)
> 
> Here is output:
> 
>> install.packages("e1071")
> --- Please select a CRAN mirror for use in this session ---
> trying URL
> 'http://rh-mirror.linux.iastate.edu/CRAN/bin/windows/contrib/2.4/e1071_1.5-16.zip'
> 
> Content type 'application/zip' length 592258 bytes
> opened URL
> downloaded 578Kb
> 
> package 'e1071' successfully unpacked and MD5 sums checked
> 
> The downloaded packages are in
>         C:\Documents and Settings\aiminy\Local
> Settings\Temp\RtmpY0B2qb\downloaded_packages
> updating HTML package descriptions
>> library(e1071)
> Loading required package: class
>> library(MASS)
>> p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
>> p5.new<-subset(p5,select=-Ms)
>> p5.new$Y<-factor(p5.new$Y)
>> levels(p5.new$Y) <- list(Out=c(1), In=c(0))
>> attach(p5.new)
>> m.svm<-svm(Y~P+Aa+As+Cur,data=p5.new)
>> summary(m.svm)
> 
> Call:
> svm(formula = Y ~ P + Aa + As + Cur, data = p5.new)
> 
> 
> Parameters:
>    SVM-Type:  C-classification
>  SVM-Kernel:  radial
>        cost:  1
>       gamma:  0.04
> 
> Number of Support Vectors:  758
> 
>  ( 382 376 )
> 
> 
> Number of Classes:  2
> 
> Levels:
>  Out In
> 
> 
> 
>> plot(m.svm,p5.new,As~Cur)
> Error in scale(newdata[, object$scaled, drop = FALSE], center =
> object$x.scale$"scaled:center",  :
>         (subscript) logical subscript too long
>>
>>
> 
> 
> 

-- 
Dr. David Meyer
Department of Information Systems and Operations

Vienna University of Economics and Business Administration
Augasse 2-6, A-1090 Wien, Austria, Europe
Tel: +43-1-313 36 4393
Fax: +43-1-313 36 90 4393
HP:  http://wi.wu-wien.ac.at/~meyer/



From vettorazzi at econ.uni-hamburg.de  Fri Dec  8 13:37:09 2006
From: vettorazzi at econ.uni-hamburg.de (Eik Uni)
Date: Fri, 08 Dec 2006 13:37:09 +0100
Subject: [R] A smal fitting problem...
In-Reply-To: <1165580410.8500.181.camel@localhost.localdomain>
References: <1165580410.8500.181.camel@localhost.localdomain>
Message-ID: <45795C75.60906@econ.uni-hamburg.de>

If you really want to fit a horizontal line then the best estimate 
(meaning least squares) for b is mean(y), regardless of the actual x 
values, which becomes clear if you look at your design matrix / 
regressor matrix  .
In general least squares regression could be done with lsfit(). In your 
case the design matrix (X matrix) is a simple vector of ones.


K?re Edvardsen schrieb:
> Dear R-helpers,
>
> I'm for sure not familiar with R, but it seem like a nice sofware tool,
> so I've decided to try using it.
>
> Here is my problem I just can't figure out:
>
> I'd like to do least square fit of a straight horizontal (a = 0) line y
> = ax + b through some data points
>
> x = (3,4,5,6,7,8)
>
> y = (0.62, 0.99, 0.83, 0.69, 0.76, 0.82)
>
> How would i find b?????
>
> All the best,
> Ked
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From andy_liaw at merck.com  Fri Dec  8 13:37:13 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 8 Dec 2006 07:37:13 -0500
Subject: [R] plot.svm
In-Reply-To: <6.1.2.0.2.20061207223301.01ce8b08@aiminy.mail.iastate.edu>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA035C1910@usctmx1106.merck.com>

Try

debug(e1071:::plot.svm)

and then re-run your plot command, stepping through one line at a time
and see where it fails.

Andy 

From: Aimin Yan
> 
> where is plot.svm method?
> I just find plot(svm, data, formula) method
> 
> Aimin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From mothsailor at googlemail.com  Fri Dec  8 13:42:15 2006
From: mothsailor at googlemail.com (David Barron)
Date: Fri, 8 Dec 2006 12:42:15 +0000
Subject: [R] A smal fitting problem...
In-Reply-To: <1165580410.8500.181.camel@localhost.localdomain>
References: <1165580410.8500.181.camel@localhost.localdomain>
Message-ID: <815b70590612080442v4f91dd7cl60b4990e2d341cd@mail.gmail.com>

b = mean(y)

On 08/12/06, K?re Edvardsen <ked at nilu.no> wrote:
> Dear R-helpers,
>
> I'm for sure not familiar with R, but it seem like a nice sofware tool,
> so I've decided to try using it.
>
> Here is my problem I just can't figure out:
>
> I'd like to do least square fit of a straight horizontal (a = 0) line y
> = ax + b through some data points
>
> x = (3,4,5,6,7,8)
>
> y = (0.62, 0.99, 0.83, 0.69, 0.76, 0.82)
>
> How would i find b?????
>
> All the best,
> Ked
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP



From petr.pikal at precheza.cz  Fri Dec  8 14:02:53 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 08 Dec 2006 14:02:53 +0100
Subject: [R] Simulation in R - Part 2
In-Reply-To: <45788891.90001@gmail.com>
Message-ID: <4579708D.15253.17E64E2@localhost>

Hi

from write.csv help page:
x the object to be written, preferably a matrix or data frame. If 
not, it is attempted to coerce x to a data frame. 

So array is not a kind of object which can be saved as you want 
without some complication. Basically it is a plain vector with dim 
attributes and write.csv do its best to coerce it to data frame, but 
here you definitely need to do the transformation on your own.

You either shall use list and then transfer it to data frame by

do.call(rbind, the.list) # or something similar

or try to reshape your array e.g. by using melt and cast from reshape 
package to the form suitable for data frame transformation.

HTH
Petr



On 7 Dec 2006 at 22:33, Alexander Geisler wrote:

Date sent:      	Thu, 07 Dec 2006 22:33:05 +0100
From:           	Alexander Geisler <alexander.geisler at gmail.com>
To:             	r-help at stat.math.ethz.ch
Subject:        	[R] Simulation in R - Part 2

> Hello!
> 
> So, the simulation works (drawing 100 samples and then calculate the
> model for each sample). Here is the code:
> 
> --snip--
> # sample size n=200
> ergebnisse200 <- rep(0, each=100)
> stichproben200 <- vector(???list???, 100)
> default200 <- rep(0, each=100)
> 
> for (i in seq(1:100)) {
> n <- dim(daten)[1]  	
> ix <- sample(n,200) 	
> samp_i <- daten[ix,]  	# draw samples
> y <- sum(samp_i$y)     # number of defaults
> stichproben200[[i]] <- samp_i  # saving the samples
> default200[i] <- y   # saving the number of defaults
> 
> # Modell berechnen:
> posterior_i <- MCMClogit(y ~ fbl.ind + fekq3 + febitda4 + fuvs + fkru
> + fzd + fur3, data=samp_i, b0=prior, B0=precision, tune=0.5) #
> calculation ergebnisse200[i] <- summary(posterior_i)  # saving the
> results }
> 
> # write out the solutions into an excel-file
> write.csv2(ergebnisse200, "ergebnisse.csv")
> --snip--
> 
> My solution has the following form:
> 
> http://img296.imageshack.us/my.php?image=ergebnissewa0.jpg
> 
> write.csv2 makes the right thing, but in the excel-file, if I open the
> csv-file in excel, several objects are next to each other (I'm missing
> the line break after each object of the array); look at
> http://img67.imageshack.us/my.php?image=ergebnisseexcelbg7.jpg The
> problem is that there is an error message by importing the csv in
> excel, because there are to many columns needed to import the 100
> objects.
> 
> So, my question:
> Is it possible to write the 100 objects of the array among each other.
> Like as it can be seen in R
> (http://img296.imageshack.us/my.php?image=ergebnissewa0.jpg)? Another
> way is to produce 50 samples in a first turn and then produce 50
> samples again in another turn, but this can not be a "clean" solution
> (and surely not the only one).
> 
> Hopefully you can help me and this is the last question for my
> simulation.
> 
> Thanks for your efforts
> Alex
> 
> -- 
> Alexander Geisler * Kaltenbach 151 * A-6272 Kaltenbach
> email: alexander.geisler at gmx.at | alexander.geisler at gmail.com
> phone: +43 650 / 811 61 90 | skpye: al1405ex
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

Petr Pikal
petr.pikal at precheza.cz



From bolker at zoo.ufl.edu  Fri Dec  8 14:47:19 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Fri, 8 Dec 2006 13:47:19 +0000 (UTC)
Subject: [R] fmincon equivalent in R
References: <d4c57560612080400q5d3efedfwd6fd6b47d060fa39@mail.gmail.com>
Message-ID: <loom.20061208T143910-750@post.gmane.org>

Arun Kumar Saha <arun.kumar.saha <at> gmail.com> writes:

> 
> Dear all R users,
> 
> I am wondering if there are any function for Constraint optimization in R.
> Especially i am looking for a R - equivalent of "fmincon" function in
> MATLAB.
> 
> Thanks and regards,
> Arun
> 

  Unfortunately, the built-in functions in R only handle "box constraints"
(independent inequality constraints on each parameter), via method "L-BFGS-B"
in optim() or via nlminb(), or linear inequality constraints
via constrOptim().  
   You might try doing an RSiteSearch() for "Lagrange multiplier" -- that
will provide potential solutions to your problem, but you'll very much
have to roll your own.

  (If any R-helpers out there would like to correct me or provide pointers
to examples of Lagrange multiplier implementations in R, that would be
great ...)

   Ben Bolker



From katharina.vedovelli at gmail.com  Fri Dec  8 14:57:24 2006
From: katharina.vedovelli at gmail.com (Katharina Vedovelli)
Date: Fri, 8 Dec 2006 14:57:24 +0100
Subject: [R]  Remove " from a string
Message-ID: <80545240612080557o4e71db09l719cf1f8f7fe0223@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061208/89cb6914/attachment-0005.pl 

From jhallman at frb.gov  Fri Dec  8 14:59:33 2006
From: jhallman at frb.gov (jhallman at frb.gov)
Date: Fri, 08 Dec 2006 08:59:33 -0500
Subject: [R] dyn.load and function calls without 'PACKAGE' argument
Message-ID: <20061208135933.E180D5362E@mail.rsma.frb.gov>

I'm writing a package that interfaces to the FAME database, via a
library of compiled C routines accessible through a Linux .so file.  My
.onLoad() function loads the .so like this:

dyn.load("/opt/fame/timeiq/lib/linux_x86/libjchli.so", local = F)

and after that I also load my own fame.so via

library.dynam("fame", package = "fame")

The code in fame.so uses functions found in libjchli.so, making the
'local = F' argument in dyn.load() necessary.  But since Fame symbols
are found in libjchli.so, which is NOT part of my package, I can't, for
example, do this:

.C("cfmfin", status = integer(1), PACKAGE = "fame")

since the PACKAGE argument tells R to look only in fame.so for symbols.
Instead, I have to do it without specifying 'PACKAGE', i.e., 

.C("cfmfin", status = integer(1))

This works, but 'R CMD check' complains: 

"Foreign function calls without 'PACKAGE' argument:"

followed by a list of the functions called from libjchli.so.

Is there a way to make R CMD check happy here?

Jeff



From jholtman at gmail.com  Fri Dec  8 15:04:51 2006
From: jholtman at gmail.com (jim holtman)
Date: Fri, 8 Dec 2006 06:04:51 -0800
Subject: [R] Remove " from a string
In-Reply-To: <80545240612080557o4e71db09l719cf1f8f7fe0223@mail.gmail.com>
References: <80545240612080557o4e71db09l719cf1f8f7fe0223@mail.gmail.com>
Message-ID: <644e1f320612080604o1594f047k8f6a343b98c0055e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061208/f33d91a7/attachment-0005.pl 

From scionforbai at gmail.com  Fri Dec  8 15:11:18 2006
From: scionforbai at gmail.com (Scionforbai)
Date: Fri, 8 Dec 2006 15:11:18 +0100
Subject: [R] Remove " from a string
In-Reply-To: <80545240612080557o4e71db09l719cf1f8f7fe0223@mail.gmail.com>
References: <80545240612080557o4e71db09l719cf1f8f7fe0223@mail.gmail.com>
Message-ID: <e9ee1f0a0612080611h74d0057eoda193f7b51d30bb9@mail.gmail.com>

If I understand what you need,

> Number=2
> x <- paste("NameOfFunction",as.character(Number),sep="")
> x
[1] "NameOfFunction2"

And you can use do.call(x, ...) to "get" your function.
Hope it helps,

Scionforbai



From justin_bem at yahoo.fr  Fri Dec  8 15:13:49 2006
From: justin_bem at yahoo.fr (justin bem)
Date: Fri, 8 Dec 2006 15:13:49 +0100 (CET)
Subject: [R] Re :  A smal fitting problem...
Message-ID: <20061208141349.84025.qmail@web23010.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061208/07ca554a/attachment-0005.pl 

From marc_schwartz at comcast.net  Fri Dec  8 15:13:55 2006
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 08 Dec 2006 08:13:55 -0600
Subject: [R] Remove " from a string
In-Reply-To: <80545240612080557o4e71db09l719cf1f8f7fe0223@mail.gmail.com>
References: <80545240612080557o4e71db09l719cf1f8f7fe0223@mail.gmail.com>
Message-ID: <1165587235.4860.11.camel@localhost.localdomain>

On Fri, 2006-12-08 at 14:57 +0100, Katharina Vedovelli wrote:
> Hi all!
> 
> I have lots of functions called in the following pattern
> 'NameOfFunctionNumber' where the name always stays the same and the number
> varies from 1 to 98.
> Another function which I run in advance returns the number of the function
> which has to be called next.
> 
> Now I want to combine 'NameOfFunction' with the 'Number' returned so that i
> can call the desired function.
> I do this by:
> 
> x<-c("NameOfFunction",Number)
> z<-paste(x,collapse="")
> z
> 
> which returns
> 
> "NameOfFunctionNumber"
> 
> My Problem is that R doesn't recognise this as the name of my function
> because of the " at the beginning and the end.
> Is there a way of getting rid of those? Or does anybody know another way of
> solving this problem?
> 
> Thanks a lot for your help!
> Cheers,
> Katharina

It is not entirely clear what your ultimate goal is, thus there may be a
(much) better approach than calling functions in this manner. What do
the functions actually do and does the output vary based upon some
attribute (ie. the class) of the argument such that using R's typical
function dispatch method would be more suitable.

However, to address the specific question, at least two options:

 NameOfFunction21 <- function(x) x^2

> eval(call(paste("NameOfFunction", 21, sep = ""),  21))
[1] 441

> do.call(paste("NameOfFunction", 21, sep = ""),  list(21))
[1] 441

In both cases, the result is to evaluate the function call, with 21 as
the argument.  See ?call, ?eval and ?do.call for more information.

HTH,

Marc Schwartz



From dimitris.rizopoulos at med.kuleuven.be  Fri Dec  8 15:17:18 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 8 Dec 2006 15:17:18 +0100
Subject: [R] Remove " from a string
References: <80545240612080557o4e71db09l719cf1f8f7fe0223@mail.gmail.com>
Message-ID: <00af01c71ad3$91d58660$0540210a@www.domain>

try this:

f1 <- function(x) x + 1
f2 <- function(x) x + 2
f3 <- function(x) x + 3

###########

FunNam <- "f1"
eval(call(FunNam, x = 1:5))

FunNam <- "f2"
eval(call(FunNam, x = 1:5))

FunNam <- "f3"
eval(call(FunNam, x = 1:5))


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Katharina Vedovelli" <katharina.vedovelli at gmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, December 08, 2006 2:57 PM
Subject: [R] Remove " from a string


> Hi all!
>
> I have lots of functions called in the following pattern
> 'NameOfFunctionNumber' where the name always stays the same and the 
> number
> varies from 1 to 98.
> Another function which I run in advance returns the number of the 
> function
> which has to be called next.
>
> Now I want to combine 'NameOfFunction' with the 'Number' returned so 
> that i
> can call the desired function.
> I do this by:
>
> x<-c("NameOfFunction",Number)
> z<-paste(x,collapse="")
> z
>
> which returns
>
> "NameOfFunctionNumber"
>
> My Problem is that R doesn't recognise this as the name of my 
> function
> because of the " at the beginning and the end.
> Is there a way of getting rid of those? Or does anybody know another 
> way of
> solving this problem?
>
> Thanks a lot for your help!
> Cheers,
> Katharina
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From rfrancois at mango-solutions.com  Fri Dec  8 15:31:48 2006
From: rfrancois at mango-solutions.com (Romain Francois)
Date: Fri, 08 Dec 2006 14:31:48 +0000
Subject: [R] JOB: R/S programmers at Mango Solutions (UK)
Message-ID: <45797754.8060406@mango-solutions.com>

Hello,

Due to the continued growth of Mango Solutions, we are now inviting
applications for the following positions:

* Senior R/S Programmer:
http://www.mango-solutions.com/company/jobuk13.html

* R/S Programmer:
http://www.mango-solutions.com/company/jobuk14.html

To view all available positions at Mango Solutions, visit the Careers page
at http://www.mango-solutions.com/company/careers.html


Kind regards,

Romain.

*mangosolutions*
data analysis that delivers

-- 
Mango Solutions
Tel  +44 1249 467 467
Fax  +44 1249 467 468
Mob  +44 7813 526 123
data analysis that delivers



From kubovy at virginia.edu  Fri Dec  8 15:34:37 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Fri, 8 Dec 2006 09:34:37 -0500
Subject: [R] A smal fitting problem...
In-Reply-To: <815b70590612080442v4f91dd7cl60b4990e2d341cd@mail.gmail.com>
References: <1165580410.8500.181.camel@localhost.localdomain>
	<815b70590612080442v4f91dd7cl60b4990e2d341cd@mail.gmail.com>
Message-ID: <6CD7B279-51CE-49AB-B09A-903506DC7CBF@virginia.edu>

On Dec 8, 2006, at 7:42 AM, David Barron wrote:

> b = mean(y)
>
> On 08/12/06, K?re Edvardsen <ked at nilu.no> wrote:
>> Dear R-helpers,
>>
>> I'm for sure not familiar with R, but it seem like a nice sofware  
>> tool,
>> so I've decided to try using it.
>>
>> Here is my problem I just can't figure out:
>>
>> I'd like to do least square fit of a straight horizontal (a = 0)  
>> line y
>> = ax + b through some data points
>>
>> x = (3,4,5,6,7,8)
>>
>> y = (0.62, 0.99, 0.83, 0.69, 0.76, 0.82)
>>
>> How would i find b?????

And in the context of linear models:
x <- 3:8
y <- c(0.62, 0.99, 0.83, 0.69, 0.76, 0.82)
lm(y ~ 1)
_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/



From kubovy at virginia.edu  Fri Dec  8 16:23:57 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Fri, 8 Dec 2006 10:23:57 -0500
Subject: [R] Sweave and warning messages
Message-ID: <F517FF0A-C329-4CA2-8A7F-1D0D9D72E031@virginia.edu>

How does one tell Sweave() to include analysis warning messages in  
the verbatim output?
_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/



From Greg.Snow at intermountainmail.org  Fri Dec  8 17:08:11 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 8 Dec 2006 09:08:11 -0700
Subject: [R] Remove " from a string
Message-ID: <07E228A5BE53C24CAD490193A7381BBB6F2D1C@LP-EXCHVS07.CO.IHC.COM>

The best approach is probably to load all of your functions into a list:

> myfunctions <- list()
> myfunctions[[1]] <- NameOfFunction1
> myfunctions[[2]] <- NameOfFunction2
...

Or

> myfunctions <- list()
> for (i in 1:98){
+ myfunctions[[i]] <- get( paste('NameOfFunction',i,sep='') )
+ }
>

Then you can run the function like:

> myfunctions[[Number]](data, ...)

You could use 'get' directly, but the list of functions is probably
cleaner.

Hope this helps, 


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Katharina
Vedovelli
Sent: Friday, December 08, 2006 6:57 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Remove " from a string

Hi all!

I have lots of functions called in the following pattern
'NameOfFunctionNumber' where the name always stays the same and the
number varies from 1 to 98.
Another function which I run in advance returns the number of the
function which has to be called next.

Now I want to combine 'NameOfFunction' with the 'Number' returned so
that i can call the desired function.
I do this by:

x<-c("NameOfFunction",Number)
z<-paste(x,collapse="")
z

which returns

"NameOfFunctionNumber"

My Problem is that R doesn't recognise this as the name of my function
because of the " at the beginning and the end.
Is there a way of getting rid of those? Or does anybody know another way
of solving this problem?

Thanks a lot for your help!
Cheers,
Katharina

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From Knut-krueger at einthal.de  Fri Dec  8 17:17:13 2006
From: Knut-krueger at einthal.de (Knut Krueger)
Date: Fri, 08 Dec 2006 17:17:13 +0100
Subject: [R] how to create data.frame with dynamic count of values
Message-ID: <45799009.6020905@einthal.de>

Hello R-Group

I found how to fill the data.frame ->
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/70843.html

N1 <- rnorm(4)
N2 <- rnorm(4)
N3 <- rnorm(4)
N4 <- rnorm(4)
X1 <- LETTERS[1:4]
###################
nams <- c(paste("N", 1:4, sep = ""), "X1")
dat <- data.frame(lapply(nams, get))
names(dat) <- nams
dat


But I need also to create a dynamic count of numeric vectors
items = 15
VarSize <-10

N1 <- rep(0,VarSize)
N2 <- rep(0,VarSize)
N3 <- rep(0,VarSize)
N4 <- rep(0,VarSize)
N5 <- rep(0,VarSize)
...
N15<- rep(0,VarSize)  # 15 items


Thank you in advance
Knut



From gunter.berton at gene.com  Fri Dec  8 17:34:44 2006
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 8 Dec 2006 08:34:44 -0800
Subject: [R] Remove " from a string
In-Reply-To: <1165587235.4860.11.camel@localhost.localdomain>
Message-ID: <002001c71ae6$c5286e70$4d908980@gne.windows.gene.com>

 I second Marc's comments below, but for amusement, another alternative to
the (undesirable) eval(call()) construction is:

> foo<-function(x)x^2
> get("foo")(1:5)
[1]  1  4  9 16 25

I believe this is equally undesirable, however, and as Marc said, making
your function a function of two arguments or something similar would be the
better approach.


Bert Gunter
Genentech Nonclinical Statistics
South San Francisco, CA 94404


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marc Schwartz
Sent: Friday, December 08, 2006 6:14 AM
To: Katharina Vedovelli
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Remove " from a string

On Fri, 2006-12-08 at 14:57 +0100, Katharina Vedovelli wrote:
> Hi all!
> 
> I have lots of functions called in the following pattern
> 'NameOfFunctionNumber' where the name always stays the same and the number
> varies from 1 to 98.
> Another function which I run in advance returns the number of the function
> which has to be called next.
> 
> Now I want to combine 'NameOfFunction' with the 'Number' returned so that
i
> can call the desired function.
> I do this by:
> 
> x<-c("NameOfFunction",Number)
> z<-paste(x,collapse="")
> z
> 
> which returns
> 
> "NameOfFunctionNumber"
> 
> My Problem is that R doesn't recognise this as the name of my function
> because of the " at the beginning and the end.
> Is there a way of getting rid of those? Or does anybody know another way
of
> solving this problem?
> 
> Thanks a lot for your help!
> Cheers,
> Katharina

It is not entirely clear what your ultimate goal is, thus there may be a
(much) better approach than calling functions in this manner. What do
the functions actually do and does the output vary based upon some
attribute (ie. the class) of the argument such that using R's typical
function dispatch method would be more suitable.

However, to address the specific question, at least two options:

 NameOfFunction21 <- function(x) x^2

> eval(call(paste("NameOfFunction", 21, sep = ""),  21))
[1] 441

> do.call(paste("NameOfFunction", 21, sep = ""),  list(21))
[1] 441

In both cases, the result is to evaluate the function call, with 21 as
the argument.  See ?call, ?eval and ?do.call for more information.

HTH,

Marc Schwartz

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From pchen at uni-bielefeld.de  Fri Dec  8 18:16:22 2006
From: pchen at uni-bielefeld.de (pchen at uni-bielefeld.de)
Date: Fri, 08 Dec 2006 12:16:22 -0500
Subject: [R] dynamic panel data estimation
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E6B0830@dc1ex01.air.org>
References: <2323A6D37908A847A7C32F1E3662C80E6B0830@dc1ex01.air.org>
Message-ID: <f6d9e15564ef.45795796@uni-bielefeld.de>

Hello every one,

is there an R package that can handle dynamic panel data model aviablable ?

thank you for help

chen



From tlumley at u.washington.edu  Fri Dec  8 18:32:19 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 8 Dec 2006 09:32:19 -0800 (PST)
Subject: [R] MAXIMIZATION WITH CONSTRAINTS
In-Reply-To: <10f61ec2426.miri.dago@virgilio.it>
References: <10f61ec2426.miri.dago@virgilio.it>
Message-ID: <Pine.LNX.4.64.0612080915400.27415@homer23.u.washington.edu>

On Fri, 8 Dec 2006, miri.dago at virgilio.it wrote:

> Dear R users, I??m a graduate students and in my master thesis I must
> obtain the values of the parameters x_i which maximize this Multinomial 
> log??likelihood function log(n!)-sum_{i=1]^4 log(n_i!)+sum_ {i=1}^4 n_i 
> log(x_i)

>under the following constraints:
>a) sum_i x_i=1, x_i>=0, 
>b) x_1<=x_2+x_3+x_4
>c)x_2<=x_3+x_4
>I have been using the 
>??ConstrOptim?? R-function with the instructions I report below, and I 
>have tried to implement them with different values of ??n??. BUT I have 
>encountered 2 problems:

The problem is that the first constraint is not an inequality but an 
equality. Writing it as two inequalities results in the feasible region 
for the optimization being a very narrow slice of four-dimensional space, 
which makes the optimization difficult.

There are at least two ways to fix the problem.  The first is to note that 
the loglikelihood is monotone in each x, so that sum_i x_i <=1 is 
sufficient when maximizing.  The second is to reparametrize in terms of 
three parameters.

Minimization is more challenging, because the loglikelihood does not have 
a minimum. It is negative infinite when any x_i is zero and the 
corresponding n is non-zero.

 	-thomas


My R instructions

n=c(10,20,3,5)
n1=n[1]
n2=n
[2]
n3=n[3]
n4=n[4]

logfr=function(x) { ##function to maximize 
x1= x
[1] 
x2= x[2] 
x3= x[3]
x4= x[4]
log(factorial(sum(n)))-sum(log
(factorial(n)))+sum(n*log(x)) 
} 
grr.log <- function(x) { ## Gradient 
of 'log fr'
x1=x[1] 
x2=x[2] 
x3=x[3]
x4=x[4]
return(n/x)
} 
par.start= 
c(.19999999,.15,.4,.25)
constr.coeff = rbind(diag(1,4,4),c(-1,1,1,1),c
(0,-1,1,1),c(-1,-1,-1,-1), c(1,1,1,1))
constr.tn= c(0,0,0,0,0,0,-1,.
9999999)
min= constrOptim(par.start, logfr, grr.log, ui=constr.coeff, 
ci=constr.tn)
max=constrOptim(par.start, logfr, grr.log, ui=constr.
coeff, ci=constr.tn, control=list(fnscale=-1))

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From perpdgo at colpos.mx  Fri Dec  8 19:28:48 2006
From: perpdgo at colpos.mx (Paulino Perez Rodriguez)
Date: Fri, 08 Dec 2006 12:28:48 -0600
Subject: [R] Solve non linear system of equations
Message-ID: <web-8515164@mailadmin.colpos.mx>


Hello, how do Ito solve a non linear system of equations 
in R?

-- 
Este mensaje ha sido analizado por MailScanner
en busca de virus y otros contenidos peligrosos,
y se considera que est? limpio.



From arun.kumar.saha at gmail.com  Fri Dec  8 19:36:35 2006
From: arun.kumar.saha at gmail.com (Arun Kumar Saha)
Date: Sat, 9 Dec 2006 00:06:35 +0530
Subject: [R] Constraint Optimization problem.
Message-ID: <d4c57560612081036k5531b61ve5b45b1c4be33bd9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061209/6e0bc8a5/attachment-0005.pl 

From antonio.raju at gmail.com  Fri Dec  8 20:05:03 2006
From: antonio.raju at gmail.com (antonio rodriguez)
Date: Fri, 08 Dec 2006 20:05:03 +0100
Subject: [R] filled.contour and NA's
In-Reply-To: <45f568c70612080059k38506424hb294ab029fc0ad59@mail.gmail.com>
References: <456DE30F.7090002@gmail.com>
	<45f568c70612080059k38506424hb294ab029fc0ad59@mail.gmail.com>
Message-ID: <4579B75F.3060803@gmail.com>

Hi Gustaf

> I'm having the same issue myself. What I've ended up doing is
> replacing NA's with a big negative value, define "levels" as one color
> for negative values, and a regular scale above. 

How to define 'levels' as one color for negative values and a regular 
scale above? I don't know how the syntax within the filled.contour 
function shoul be.

BR

Antonio


> This gives a fairly
> good separation between what areas contain data, and what doesn't. To
> make NA's black, I suppose one would have to define your own
> colour.palette, but I haven't looked into it.
>
> Hope this helps, and let me know if you've found a better solution!
>
> Best,
>
> Gustaf Rydevik
>



From macq at llnl.gov  Fri Dec  8 20:00:23 2006
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 8 Dec 2006 11:00:23 -0800
Subject: [R] how to create data.frame with dynamic count of values
In-Reply-To: <45799009.6020905@einthal.de>
References: <45799009.6020905@einthal.de>
Message-ID: <p06230901c19f64995171@[128.115.153.6]>

I don't understand what you're asking for.

But if your goal is to create N1 through N15 in order to use them to 
fill a data frame, then it can be much simpler:

items <- 15
VarSize <- 10

tmp <- matrix(0,nrow=VarSize,ncol=items)
tmp <- data.frame(tmp)
names(tmp) <- paste('N',seq(items),sep='')

## of course, this next only works if VarSize <= length(letters)
tmp$X1 <- letters[1:VarSize]

You could instead start with

tmp <- matrix( rnorm(VarSize*items) , nrow=VarSize , ncol=items)

-Don

At 5:17 PM +0100 12/8/06, Knut Krueger wrote:
>Hello R-Group
>
>I found how to fill the data.frame ->
>http://finzi.psych.upenn.edu/R/Rhelp02a/archive/70843.html
>
>N1 <- rnorm(4)
>N2 <- rnorm(4)
>N3 <- rnorm(4)
>N4 <- rnorm(4)
>X1 <- LETTERS[1:4]
>###################
>nams <- c(paste("N", 1:4, sep = ""), "X1")
>dat <- data.frame(lapply(nams, get))
>names(dat) <- nams
>dat
>
>
>But I need also to create a dynamic count of numeric vectors
>items = 15
>VarSize <-10
>
>N1 <- rep(0,VarSize)
>N2 <- rep(0,VarSize)
>N3 <- rep(0,VarSize)
>N4 <- rep(0,VarSize)
>N5 <- rep(0,VarSize)
>...
>N15<- rep(0,VarSize)  # 15 items
>
>
>Thank you in advance
>Knut
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From swlazlowski at googlemail.com  Fri Dec  8 20:26:14 2006
From: swlazlowski at googlemail.com (Szymon Wlazlowski)
Date: Fri, 8 Dec 2006 19:26:14 +0000
Subject: [R] Paste function and backslash
Message-ID: <40c421450612081126h3740e226j2be3d14ad6631c30@mail.gmail.com>

Dear useRs,

calls and results below:
> paste("\ \n")
[1] " \n"
*but*
> paste("\ \N")
[1] " N"
Question: Is that by design? If so, how can I obtain simple LaTeX-type:
[1] "\N"

> version
platform       i386-pc-linux-gnu
arch           i386
os             linux-gnu
system         i386, linux-gnu
status
major          2
minor          4.0
year           2006
month          10
day            03
svn rev        39566
language       R
version.string R version 2.4.0 (2006-10-03)
-- 
Szymon Wlazlowski



From aiminy at iastate.edu  Fri Dec  8 20:27:52 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Fri, 08 Dec 2006 13:27:52 -0600
Subject: [R] svm plot question
In-Reply-To: <45795B40.2060105@wu-wien.ac.at>
References: <6.1.2.0.2.20061207170402.01ca1058@aiminy.mail.iastate.edu>
	<45795B40.2060105@wu-wien.ac.at>
Message-ID: <6.1.2.0.2.20061208132230.01c76d08@aiminy.mail.iastate.edu>

thanks, I did get this plot.
Before I have this problem, I did get a plot by my code.
However after I change a little my code. it doesn't work.
It is pity not saving my original code.

Now the question is the plot I get using your code is different from
what I got before.
Moreover I did remember I use plot(m.svm,p5.new,As~Cur)

Do you know why?

Thanks,

Aimin

At 06:32 AM 12/8/2006, David Meyer wrote:
>Aimin:
>
>1) Please do not spam the r-help list---one request per issue (and two
>private mails to the code author) really suffice. Not all contributors
>to the R-project are on-line 24/24, and have time to provide immediate
>answers.
>
>2) The error occurs because plot.svm() currently does not set valid
>defaults for categorical dimensions you are conditioning on for your
>2D-plot (in your example: 'P' and 'Aa') which certainly is a bug. I will
>commit a fix for the next release of e1071. For the time being, you will
>have to explicitly specify the levels of 'P' and 'Aa':
>
>plot(m.svm,p5.new,As~Cur, slice = list(P = factor("821p", levels =
>levels(P)), Aa = factor("ALA", levels = levels(Aa))))
>
>(Note that the defaults for the "slice" argument are completely
>arbitrary anyway).
>
>Thanks for pointing this out,
>
>David
>
>Aimin Yan wrote:
> > I have a question about svm in R
> >
> > I run the following code, all other is ok,
> > but plot(m.svm,p5.new,As~Cur) is not ok
> >
> > Do you know why?
> >
> > install.packages("e1071")
> > library(e1071)
> > library(MASS)
> > p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
> > p5.new<-subset(p5,select=-Ms)
> > p5.new$Y<-factor(p5.new$Y)
> > levels(p5.new$Y) <- list(Out=c(1), In=c(0))
> > attach(p5.new)
> > m.svm<-svm(Y~P+Aa+As+Cur,data=p5.new)
> > summary(m.svm)
> > plot(m.svm,p5.new,As~Cur)
> >
> > Here is output:
> >
> >> install.packages("e1071")
> > --- Please select a CRAN mirror for use in this session ---
> > trying URL
> > 
> 'http://rh-mirror.linux.iastate.edu/CRAN/bin/windows/contrib/2.4/e1071_1.5-16.zip'
> >
> > Content type 'application/zip' length 592258 bytes
> > opened URL
> > downloaded 578Kb
> >
> > package 'e1071' successfully unpacked and MD5 sums checked
> >
> > The downloaded packages are in
> >         C:\Documents and Settings\aiminy\Local
> > Settings\Temp\RtmpY0B2qb\downloaded_packages
> > updating HTML package descriptions
> >> library(e1071)
> > Loading required package: class
> >> library(MASS)
> >> p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
> >> p5.new<-subset(p5,select=-Ms)
> >> p5.new$Y<-factor(p5.new$Y)
> >> levels(p5.new$Y) <- list(Out=c(1), In=c(0))
> >> attach(p5.new)
> >> m.svm<-svm(Y~P+Aa+As+Cur,data=p5.new)
> >> summary(m.svm)
> >
> > Call:
> > svm(formula = Y ~ P + Aa + As + Cur, data = p5.new)
> >
> >
> > Parameters:
> >    SVM-Type:  C-classification
> >  SVM-Kernel:  radial
> >        cost:  1
> >       gamma:  0.04
> >
> > Number of Support Vectors:  758
> >
> >  ( 382 376 )
> >
> >
> > Number of Classes:  2
> >
> > Levels:
> >  Out In
> >
> >
> >
> >> plot(m.svm,p5.new,As~Cur)
> > Error in scale(newdata[, object$scaled, drop = FALSE], center =
> > object$x.scale$"scaled:center",  :
> >         (subscript) logical subscript too long
> >>
> >>
> >
> >
> >
>
>--
>Dr. David Meyer
>Department of Information Systems and Operations
>
>Vienna University of Economics and Business Administration
>Augasse 2-6, A-1090 Wien, Austria, Europe
>Tel: +43-1-313 36 4393
>Fax: +43-1-313 36 90 4393
>HP:  http://wi.wu-wien.ac.at/~meyer/



From Roger.Bivand at nhh.no  Fri Dec  8 20:34:40 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 8 Dec 2006 20:34:40 +0100 (CET)
Subject: [R] Paste function and backslash
In-Reply-To: <40c421450612081126h3740e226j2be3d14ad6631c30@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0612082033230.4912-100000@reclus.nhh.no>

On Fri, 8 Dec 2006, Szymon Wlazlowski wrote:

> Dear useRs,
> 
> calls and results below:
> > paste("\ \n")
> [1] " \n"
> *but*
> > paste("\ \N")
> [1] " N"
> Question: Is that by design? If so, how can I obtain simple LaTeX-type:
> [1] "\N"

FAQ 7.37:

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-does-backslash-behave-strangely-inside-strings_003f


> 
> > version
> platform       i386-pc-linux-gnu
> arch           i386
> os             linux-gnu
> system         i386, linux-gnu
> status
> major          2
> minor          4.0
> year           2006
> month          10
> day            03
> svn rev        39566
> language       R
> version.string R version 2.4.0 (2006-10-03)
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Etron777 at web.de  Fri Dec  8 22:14:23 2006
From: Etron777 at web.de (Knut Krueger)
Date: Fri, 08 Dec 2006 22:14:23 +0100
Subject: [R] how to create data.frame with dynamic count of values
Message-ID: <4579D5AF.5050907@web.de>

Hello R-Group

I found how to fill the data.frame ->
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/70843.html

N1 <- rnorm(4)
N2 <- rnorm(4)
N3 <- rnorm(4)
N4 <- rnorm(4)
X1 <- LETTERS[1:4]
###################
nams <- c(paste("N", 1:4, sep = ""), "X1")
dat <- data.frame(lapply(nams, get))
names(dat) <- nams
dat


But I need also to create a dynamic count of numeric vectors
items = 15
VarSize <-10

N1 <- rep(0,VarSize)
N2 <- rep(0,VarSize)
N3 <- rep(0,VarSize)
N4 <- rep(0,VarSize)
N5 <- rep(0,VarSize)
...
N15<- rep(0,VarSize)  # 15 items


Thank you in advance
Knut



From Mark.Leeds at morganstanley.com  Fri Dec  8 22:16:49 2006
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Fri, 8 Dec 2006 16:16:49 -0500
Subject: [R] any way to make the code more efficient ?
Message-ID: <D3AEEDA31E57474B840BEBC25A8A8344B64430@NYWEXMB23.msad.ms.com>

The code bekow works so this is why I didn't include the data to
reproduce it. The  loops about 500
times and each time, a zoo object with 1400 rows and 4 columns gets
created. ( the rows represent minutes so each file is one day 
worth of data). Inside the loop, I keep rbinding the newly created zoo
object to the current zoo object so that it gets bigger and 
bigger over time.

Eventually, the new zoo object, fullaggfxdata,  containing all the days
of data is created.

I was just wondering if there is a more efficient way of doing this. I
do know the number of times the loop will be done at the beginning so
maybe creating the a matrix or data frame at the beginning and putting
the daily ones in something like that would
Make it be faster. But, the proboem with this is I eventually do need a
zoo object.  I ask this question because at around the 250
mark of the loop, things start to slow down significiantly and I think I
remember reading somewhere that doing an rbind of something to itself is
not a good idea.  Thanks. 

#=======================================================================
===============================================

start<-1

for (filecounter in (1:length(datafilenames))) { 

print(paste("File Counter = ", filecounter))
datafile= paste(datadir,"/",datafilenames[filecounter],sep="")
aggfxdata<-clnaggcompcurrencyfile(fxfile=datafile,aggminutes=aggminutes,
fillholes=1)
logbidask<-log(aggfxdata[,"bidask"]) 
aggfxdata<-cbind(aggfxdata,logbidask)

if ( start == 1 ) {
fullaggfxdata<-aggfxdata
start<-0
} else {
fullaggfxdata<-rbind(fullaggfxdata,aggfxdata)
}


}

#=======================================================================
==================================
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}



From aiminy at iastate.edu  Fri Dec  8 22:23:16 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Fri, 08 Dec 2006 15:23:16 -0600
Subject: [R] question for if else
Message-ID: <6.1.2.0.2.20061208151819.01c19ed8@aiminy.mail.iastate.edu>

I have a data set like this
I want to assign "outward" to Y if sc <90 and assign "inward" to Y if sc>=90.
then cbind(p1982,Y) to get like these

p aa as ms cur sc Y
1 154l_aa ARG 152.04 108.83 -0.1020140  92.10410   inward
2 154l_aa THR  15.86  28.32  0.2563560 103.67100    inward
3 154l_aa ASP  65.13  59.16  0.0312137   7.27311     outward
4 154l_aa CYS  57.20  49.85 -0.0549589  72.97930    outward
5 154l_aa TYR  28.87  31.75  0.0526457  96.11660     inward
6 154l_aa ASN  31.14  31.09  0.0632711  55.65980    outward

does anyone know how to these?

Aimin

 > head(p1982)
         p  aa     as     ms        cur        sc
1 154l_aa ARG 152.04 108.83 -0.1020140  92.10410
2 154l_aa THR  15.86  28.32  0.2563560 103.67100
3 154l_aa ASP  65.13  59.16  0.0312137   7.27311
4 154l_aa CYS  57.20  49.85 -0.0549589  72.97930
5 154l_aa TYR  28.87  31.75  0.0526457  96.11660
6 154l_aa ASN  31.14  31.09  0.0632711  55.65980



From rvaradhan at jhmi.edu  Fri Dec  8 23:20:37 2006
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Fri, 8 Dec 2006 17:20:37 -0500
Subject: [R] any way to make the code more efficient ?
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A8344B64430@NYWEXMB23.msad.ms.com>
Message-ID: <000301c71b17$16647ab0$7c94100a@win.ad.jhu.edu>


Using "rbind" almost always slows things down significantly.  You should
define the objects "aggfxdata" and "fullaggfxdata" before the loop and then
assign appropriate values to the corresponding rows and/or columns.  

Ravi.

----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Leeds, Mark (IED)
Sent: Friday, December 08, 2006 4:17 PM
To: r-help at stat.math.ethz.ch
Subject: [R] any way to make the code more efficient ?

The code bekow works so this is why I didn't include the data to
reproduce it. The  loops about 500
times and each time, a zoo object with 1400 rows and 4 columns gets
created. ( the rows represent minutes so each file is one day 
worth of data). Inside the loop, I keep rbinding the newly created zoo
object to the current zoo object so that it gets bigger and 
bigger over time.

Eventually, the new zoo object, fullaggfxdata,  containing all the days
of data is created.

I was just wondering if there is a more efficient way of doing this. I
do know the number of times the loop will be done at the beginning so
maybe creating the a matrix or data frame at the beginning and putting
the daily ones in something like that would
Make it be faster. But, the proboem with this is I eventually do need a
zoo object.  I ask this question because at around the 250
mark of the loop, things start to slow down significiantly and I think I
remember reading somewhere that doing an rbind of something to itself is
not a good idea.  Thanks. 

#=======================================================================
===============================================

start<-1

for (filecounter in (1:length(datafilenames))) { 

print(paste("File Counter = ", filecounter))
datafile= paste(datadir,"/",datafilenames[filecounter],sep="")
aggfxdata<-clnaggcompcurrencyfile(fxfile=datafile,aggminutes=aggminutes,
fillholes=1)
logbidask<-log(aggfxdata[,"bidask"]) 
aggfxdata<-cbind(aggfxdata,logbidask)

if ( start == 1 ) {
fullaggfxdata<-aggfxdata
start<-0
} else {
fullaggfxdata<-rbind(fullaggfxdata,aggfxdata)
}


}

#=======================================================================
==================================
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From Mark.Leeds at morganstanley.com  Fri Dec  8 23:30:19 2006
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Fri, 8 Dec 2006 17:30:19 -0500
Subject: [R] any way to make the code more efficient ?
In-Reply-To: <000301c71b17$16647ab0$7c94100a@win.ad.jhu.edu>
Message-ID: <D3AEEDA31E57474B840BEBC25A8A8344B64433@NYWEXMB23.msad.ms.com>

ravi : I appreciate your help but could you be a little more specific
about what you mean ? I can just stack
aggfxdata below the current full one ( the rbind works out the ordrering
by date because it's a zoo object )  
so it's not a question of where to put the new one. It's a question of
how to avoid rbind ? I apologize because I don't think I 
understand what you are saying. Or maybe it's not possible to avoid
rbind ? Thanks.


-----Original Message-----
From: Ravi Varadhan [mailto:rvaradhan at jhmi.edu] 
Sent: Friday, December 08, 2006 5:21 PM
To: Leeds, Mark (IED); r-help at stat.math.ethz.ch
Subject: RE: [R] any way to make the code more efficient ?


Using "rbind" almost always slows things down significantly.  You should
define the objects "aggfxdata" and "fullaggfxdata" before the loop and
then assign appropriate values to the corresponding rows and/or columns.


Ravi.

------------------------------------------------------------------------
----
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:
http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

------------------------------------------------------------------------
----
--------

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Leeds, Mark (IED)
Sent: Friday, December 08, 2006 4:17 PM
To: r-help at stat.math.ethz.ch
Subject: [R] any way to make the code more efficient ?

The code bekow works so this is why I didn't include the data to
reproduce it. The  loops about 500 times and each time, a zoo object
with 1400 rows and 4 columns gets created. ( the rows represent minutes
so each file is one day worth of data). Inside the loop, I keep rbinding
the newly created zoo object to the current zoo object so that it gets
bigger and bigger over time.

Eventually, the new zoo object, fullaggfxdata,  containing all the days
of data is created.

I was just wondering if there is a more efficient way of doing this. I
do know the number of times the loop will be done at the beginning so
maybe creating the a matrix or data frame at the beginning and putting
the daily ones in something like that would Make it be faster. But, the
proboem with this is I eventually do need a zoo object.  I ask this
question because at around the 250 mark of the loop, things start to
slow down significiantly and I think I remember reading somewhere that
doing an rbind of something to itself is not a good idea.  Thanks. 

#=======================================================================
===============================================

start<-1

for (filecounter in (1:length(datafilenames))) { 

print(paste("File Counter = ", filecounter)) datafile=
paste(datadir,"/",datafilenames[filecounter],sep="")
aggfxdata<-clnaggcompcurrencyfile(fxfile=datafile,aggminutes=aggminutes,
fillholes=1)
logbidask<-log(aggfxdata[,"bidask"])
aggfxdata<-cbind(aggfxdata,logbidask)

if ( start == 1 ) {
fullaggfxdata<-aggfxdata
start<-0
} else {
fullaggfxdata<-rbind(fullaggfxdata,aggfxdata)
}


}

#=======================================================================
==================================
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to
buy/se...{{dropped}}

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}



From aiminy at iastate.edu  Fri Dec  8 23:45:05 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Fri, 08 Dec 2006 16:45:05 -0600
Subject: [R] (no subject)
Message-ID: <6.1.2.0.2.20061208164248.01be2020@aiminy.mail.iastate.edu>

I have a data set like this:
if I want to less than 200000 obs from this data set.
How can I do these?

 > str(p1982)
'data.frame':   465979 obs. of  6 variables:
  $ p  : Factor w/ 1982 levels "154l_aa","1A0P_aa",..: 1 1 1 1 1 1 1 1 1 1 ...
  $ aa : Factor w/ 19 levels "ALA","ARG","ASN",..: 2 16 4 5 18 3 19 3 2 9 ...
  $ as : num  152.0  15.9  65.1  57.2  28.9 ...
  $ ms : num  108.8  28.3  59.2  49.9  31.8 ...
  $ cur: num  -0.1020  0.2564  0.0312 -0.0550  0.0526 ...
  $ sc : num   92.10 103.67   7.27  72.98  96.12 ...



From jholtman at gmail.com  Fri Dec  8 23:52:54 2006
From: jholtman at gmail.com (jim holtman)
Date: Fri, 8 Dec 2006 14:52:54 -0800
Subject: [R] (no subject)
In-Reply-To: <6.1.2.0.2.20061208164248.01be2020@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061208164248.01be2020@aiminy.mail.iastate.edu>
Message-ID: <644e1f320612081452u63f15d79x845810747f42275f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061208/fc6282e5/attachment-0005.pl 

From cberry at tajo.ucsd.edu  Fri Dec  8 23:52:55 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Fri, 8 Dec 2006 14:52:55 -0800
Subject: [R] any way to make the code more efficient ?
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A8344B64430@NYWEXMB23.msad.ms.com>
References: <D3AEEDA31E57474B840BEBC25A8A8344B64430@NYWEXMB23.msad.ms.com>
Message-ID: <Pine.LNX.4.64.0612081437270.29508@tajo.ucsd.edu>



Save your intermediate results as a list of matrices.

Then rbind them all at once using do.call.

It looks like this will save 23 seconds (see below), if you are running on 
a PC like mine (AMD 2GHz, WinXP ).

But I wonder, if 23 a mere seconds is all you save is this really worth 
worrying about??

Maybe you are losing time elsewhere.

If so, you need to profile this run and/or track memory usage.


> amat <- NULL
> mat.1400.by.4 <- matrix(1:(1400*4),nc=4)
> system.time(for (i in 1:500) amat <- rbind(amat, mat.1400.by.4 ))
[1] 20.05  1.53 23.24    NA    NA
> 
> list.of.matrices <- rep( list( mat.1400.by.4 ) , 500 )
> system.time( amat2 <- do.call(rbind, list.of.matrices ) )
[1] 0.08 0.00 0.08   NA   NA
> all.equal(amat,amat2)
[1] TRUE
>

On Fri, 8 Dec 2006, Leeds, Mark (IED) wrote:

> The code bekow works so this is why I didn't include the data to
> reproduce it. The  loops about 500
> times and each time, a zoo object with 1400 rows and 4 columns gets
> created. ( the rows represent minutes so each file is one day
> worth of data). Inside the loop, I keep rbinding the newly created zoo
> object to the current zoo object so that it gets bigger and
> bigger over time.
>
> Eventually, the new zoo object, fullaggfxdata,  containing all the days
> of data is created.
>
> I was just wondering if there is a more efficient way of doing this. I
> do know the number of times the loop will be done at the beginning so
> maybe creating the a matrix or data frame at the beginning and putting
> the daily ones in something like that would
> Make it be faster. But, the proboem with this is I eventually do need a
> zoo object.  I ask this question because at around the 250
> mark of the loop, things start to slow down significiantly and I think I
> remember reading somewhere that doing an rbind of something to itself is
> not a good idea.  Thanks.
>
> #=======================================================================
> ===============================================
>
> start<-1
>
> for (filecounter in (1:length(datafilenames))) {
>
> print(paste("File Counter = ", filecounter))
> datafile= paste(datadir,"/",datafilenames[filecounter],sep="")
> aggfxdata<-clnaggcompcurrencyfile(fxfile=datafile,aggminutes=aggminutes,
> fillholes=1)
> logbidask<-log(aggfxdata[,"bidask"])
> aggfxdata<-cbind(aggfxdata,logbidask)
>
> if ( start == 1 ) {
> fullaggfxdata<-aggfxdata
> start<-0
> } else {
> fullaggfxdata<-rbind(fullaggfxdata,aggfxdata)
> }
>
>
> }
>
> #=======================================================================
> ==================================
> --------------------------------------------------------
>
> This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717



From andy_liaw at merck.com  Fri Dec  8 23:53:50 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 8 Dec 2006 17:53:50 -0500
Subject: [R] any way to make the code more efficient ?
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A8344B64433@NYWEXMB23.msad.ms.com>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA035C1BCF@usctmx1106.merck.com>

I don't know about efficiency, but at least for readability, you may
want to do the following:

1. Indent your code.
2. Create a list of appropriate length, and populate the list with
objects you're creating in the loop.
3. After the loop, use do.call(rbind, list).

HTH,
Andy 

From: Leeds, Mark (IED)
> 
> ravi : I appreciate your help but could you be a little more 
> specific about what you mean ? I can just stack aggfxdata 
> below the current full one ( the rbind works out the 
> ordrering by date because it's a zoo object ) so it's not a 
> question of where to put the new one. It's a question of how 
> to avoid rbind ? I apologize because I don't think I 
> understand what you are saying. Or maybe it's not possible to 
> avoid rbind ? Thanks.
> 
> 
> -----Original Message-----
> From: Ravi Varadhan [mailto:rvaradhan at jhmi.edu]
> Sent: Friday, December 08, 2006 5:21 PM
> To: Leeds, Mark (IED); r-help at stat.math.ethz.ch
> Subject: RE: [R] any way to make the code more efficient ?
> 
> 
> Using "rbind" almost always slows things down significantly.  
> You should
> define the objects "aggfxdata" and "fullaggfxdata" before the loop and
> then assign appropriate values to the corresponding rows 
> and/or columns.
> 
> 
> Ravi.
> 
> --------------------------------------------------------------
> ----------
> ----
> -------
> 
> Ravi Varadhan, Ph.D.
> 
> Assistant Professor, The Center on Aging and Health
> 
> Division of Geriatric Medicine and Gerontology 
> 
> Johns Hopkins University
> 
> Ph: (410) 502-2619
> 
> Fax: (410) 614-9625
> 
> Email: rvaradhan at jhmi.edu
> 
> Webpage:
> http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html
> 
>  
> 
> --------------------------------------------------------------
> ----------
> ----
> --------
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Leeds, 
> Mark (IED)
> Sent: Friday, December 08, 2006 4:17 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] any way to make the code more efficient ?
> 
> The code bekow works so this is why I didn't include the data to
> reproduce it. The  loops about 500 times and each time, a zoo object
> with 1400 rows and 4 columns gets created. ( the rows 
> represent minutes
> so each file is one day worth of data). Inside the loop, I 
> keep rbinding
> the newly created zoo object to the current zoo object so that it gets
> bigger and bigger over time.
> 
> Eventually, the new zoo object, fullaggfxdata,  containing 
> all the days
> of data is created.
> 
> I was just wondering if there is a more efficient way of doing this. I
> do know the number of times the loop will be done at the beginning so
> maybe creating the a matrix or data frame at the beginning and putting
> the daily ones in something like that would Make it be 
> faster. But, the
> proboem with this is I eventually do need a zoo object.  I ask this
> question because at around the 250 mark of the loop, things start to
> slow down significiantly and I think I remember reading somewhere that
> doing an rbind of something to itself is not a good idea.  Thanks. 
> 
> #=============================================================
> ==========
> ===============================================
> 
> start<-1
> 
> for (filecounter in (1:length(datafilenames))) { 
> 
> print(paste("File Counter = ", filecounter)) datafile=
> paste(datadir,"/",datafilenames[filecounter],sep="")
> aggfxdata<-clnaggcompcurrencyfile(fxfile=datafile,aggminutes=a
> ggminutes,
> fillholes=1)
> logbidask<-log(aggfxdata[,"bidask"])
> aggfxdata<-cbind(aggfxdata,logbidask)
> 
> if ( start == 1 ) {
> fullaggfxdata<-aggfxdata
> start<-0
> } else {
> fullaggfxdata<-rbind(fullaggfxdata,aggfxdata)
> }
> 
> 
> }
> 
> #=============================================================
> ==========
> ==================================
> --------------------------------------------------------
> 
> This is not an offer (or solicitation of an offer) to
> buy/se...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> --------------------------------------------------------
> 
> This is not an offer (or solicitation of an offer) to 
> buy/se...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From jholtman at gmail.com  Sat Dec  9 00:02:09 2006
From: jholtman at gmail.com (jim holtman)
Date: Fri, 8 Dec 2006 15:02:09 -0800
Subject: [R] question for if else
In-Reply-To: <6.1.2.0.2.20061208151819.01c19ed8@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061208151819.01c19ed8@aiminy.mail.iastate.edu>
Message-ID: <644e1f320612081502h31cac00fo4f9c7025e5db3cc5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061208/e9863649/attachment-0005.pl 

From jholtman at gmail.com  Sat Dec  9 00:03:02 2006
From: jholtman at gmail.com (jim holtman)
Date: Fri, 8 Dec 2006 15:03:02 -0800
Subject: [R] question for if else
In-Reply-To: <644e1f320612081502h31cac00fo4f9c7025e5db3cc5@mail.gmail.com>
References: <6.1.2.0.2.20061208151819.01c19ed8@aiminy.mail.iastate.edu>
	<644e1f320612081502h31cac00fo4f9c7025e5db3cc5@mail.gmail.com>
Message-ID: <644e1f320612081503u3ced0c19ke10e2ca14e76ee6a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061208/aff95601/attachment-0005.pl 

From jholtman at gmail.com  Sat Dec  9 00:09:04 2006
From: jholtman at gmail.com (jim holtman)
Date: Fri, 8 Dec 2006 15:09:04 -0800
Subject: [R] how to create data.frame with dynamic count of values
In-Reply-To: <4579D5AF.5050907@web.de>
References: <4579D5AF.5050907@web.de>
Message-ID: <644e1f320612081509j2f5ded0bqae6894349a38d603@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061208/012feee9/attachment-0005.pl 

From peterson at heritage.nv.gov  Sat Dec  9 00:25:08 2006
From: peterson at heritage.nv.gov (Eric Peterson)
Date: Fri, 8 Dec 2006 15:25:08 -0800
Subject: [R] trouble with cloud output to bmp when in loop
Message-ID: <EXCH-FE11NgDPex1Egl000035c5@mail.state.nv.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061208/a5a921c7/attachment-0005.pl 

From ripley at stats.ox.ac.uk  Sat Dec  9 00:46:09 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 8 Dec 2006 23:46:09 +0000 (GMT)
Subject: [R] trouble with cloud output to bmp when in loop
In-Reply-To: <EXCH-FE11NgDPex1Egl000035c5@mail.state.nv.us>
References: <EXCH-FE11NgDPex1Egl000035c5@mail.state.nv.us>
Message-ID: <Pine.LNX.4.64.0612082342520.30113@gannet.stats.ox.ac.uk>

This is FAQ Q7.22

On Fri, 8 Dec 2006, Eric Peterson wrote:

> I have some data that I need to view in various 3-D clouds.  To better see
> the cloud structure on a 2-D screen I would like to output a bunch of bmp
> files with clouds at slightly different angles, then run them through an
> external program to animate them.  But I'm having trouble getting cloud()
> from the lattice package to output to bmp files.  Oddly, this is only a
> problem when outputting multiple files in a loop.
>
> WORKS FINE:
>>  bmp("d:/test2.bmp"); cloud(z~x+y); dev.off()
>
> ALSO WORKS:
>> bmp("d:/test01.bmp"); cloud(z~x+y); dev.off(); bmp("d:/test02.bmp");
> cloud(z~x+y); dev.off();
>
> DOES NOT WORK (produces blank bitmaps):
>> for(i in 1:3) {bmp("d:/test2.bmp"); cloud(z~x+y); dev.off()}
>
> Is this a bug?
>
> Is there a way to make this work?
>
> (working in MS Windows XP x64 with R 2.4.0)
>
> Thanks!
>
> ---
>
> Eric B. Peterson
>
> Vegetation Ecologist
>
> Nevada Natural Heritage Program
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Please do take note here.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dfarrar at newrvana.com  Sat Dec  9 00:47:48 2006
From: dfarrar at newrvana.com (David Farrar)
Date: Fri, 8 Dec 2006 15:47:48 -0800 (PST)
Subject: [R] any way to make the code more efficient ?
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A8344B64433@NYWEXMB23.msad.ms.com>
Message-ID: <123074.53923.qm@web813.biz.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061208/7421e22b/attachment-0005.pl 

From nbvale at gmail.com  Sat Dec  9 02:03:41 2006
From: nbvale at gmail.com (Nuno Vale)
Date: Sat, 9 Dec 2006 01:03:41 +0000
Subject: [R] Run Sample R (Linux)
Message-ID: <84ef61090612081703h16da7bcem244d677bab45f743@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061209/f9ea7097/attachment-0005.pl 

From deepayan.sarkar at gmail.com  Sat Dec  9 02:41:09 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 8 Dec 2006 17:41:09 -0800
Subject: [R] trouble with cloud output to bmp when in loop
In-Reply-To: <EXCH-FE11NgDPex1Egl000035c5@mail.state.nv.us>
References: <EXCH-FE11NgDPex1Egl000035c5@mail.state.nv.us>
Message-ID: <eb555e660612081741g343e8besfb3efc98d4aa5dc9@mail.gmail.com>

On 12/8/06, Eric Peterson <peterson at heritage.nv.gov> wrote:
> I have some data that I need to view in various 3-D clouds.  To better see
> the cloud structure on a 2-D screen I would like to output a bunch of bmp
> files with clouds at slightly different angles, then run them through an
> external program to animate them.  But I'm having trouble getting cloud()
> from the lattice package to output to bmp files.  Oddly, this is only a
> problem when outputting multiple files in a loop.
>
> WORKS FINE:
> >  bmp("d:/test2.bmp"); cloud(z~x+y); dev.off()
>
> ALSO WORKS:
> > bmp("d:/test01.bmp"); cloud(z~x+y); dev.off(); bmp("d:/test02.bmp");
> cloud(z~x+y); dev.off();
>
> DOES NOT WORK (produces blank bitmaps):
> > for(i in 1:3) {bmp("d:/test2.bmp"); cloud(z~x+y); dev.off()}
>
> Is this a bug?

No, but it's a FAQ:

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-do-lattice_002ftrellis-graphics-not-work_003f

-Deepayan



From broe.1 at osu.edu  Sat Dec  9 02:47:39 2006
From: broe.1 at osu.edu (Michael Broe)
Date: Fri, 8 Dec 2006 20:47:39 -0500
Subject: [R] R[1821] *** -[NSBundle load]: Error loading code
Message-ID: <1F0C0375-0A69-49F7-AB74-A6FB3573B7CC@osu.edu>

I get the following error message every time I run R. I am on an  
Intel Mac, Mac OS X, 10.4.8:

2006-12-08 16:59:40.564 R[1821] *** -[NSBundle load]: Error loading  
code /Users/michael/Library/InputManagers/Smart Crash Reports/Smart  
Crash Reports.bundle/Contents/MacOS/Smart Crash Reports for bundle / 
Users/michael/Library/InputManagers/Smart Crash Reports/Smart Crash  
Reports.bundle, error code 2 (link edit error code 0, error number 0 ())
 >

[Apologies if this has been answered before, I'm new to the list, and  
searched as well as I could...]

Thanks in advance for any advice.

Cheers,
Mike



From wuz108 at stat.psu.edu  Sat Dec  9 02:58:13 2006
From: wuz108 at stat.psu.edu (Wei Zhang)
Date: Fri, 8 Dec 2006 20:58:13 -0500 (EST)
Subject: [R] Problem of Running Simulations for Monte Carlo Spatial
 Segregation Test using Spatialkernel Package
Message-ID: <1046.128.118.87.215.1165629493.squirrel@imap.stat.psu.edu>

Hello,

When I used "spseg" function in the spatialkernel package to run Monte
Carlo spatial segregation test, R would not let me run more than 50
simulations. That is, I tried to run the following code,

sp <- spseg(pts, bin, hcv, opt=3, ntest=1000, poly=polyb)

where pts was a 116*2 matrix containing lat/long; bin was a vector
containing categorical types with length of 116; hcv was the selected
bandwidth; polyb was a 4*2 matrix which would form a rectangle. But R
immediately gave an error message "cannot locate vector of size". I used
gc() but it would not help. I could only make it work when ntest=50 or
less.

Any suggestion is appreciated.

Wei Zhang



From stonexu1984 at yahoo.com  Sat Dec  9 06:06:38 2006
From: stonexu1984 at yahoo.com (Rick Xu)
Date: Fri, 8 Dec 2006 21:06:38 -0800 (PST)
Subject: [R] How to identify structural breaks in GARCH?
Message-ID: <817496.82776.qm@web32708.mail.mud.yahoo.com>

hi all, I am trying to find some break points in GARCH
model. Is there any function for it? any suggestion is
appreciated!

Thanks

Rick


 
____________________________________________________________________________________
Cheap talk?



From ethan.johnsons at gmail.com  Sat Dec  9 07:39:37 2006
From: ethan.johnsons at gmail.com (Ethan Johnsons)
Date: Sat, 9 Dec 2006 01:39:37 -0500
Subject: [R] Simulation with R
Message-ID: <5cd96f050612082239g5633cf8au36d3451a9b03fd05@mail.gmail.com>

An apparatus exists whereby a collection of balls is displaced to the
top of a stack by suction. A top level (Level 1) each ball is shifted
1 unit to the left or 1 unit to the right at random with equal
probability. The ball then drops down to level 2. At Level 2, each
ball is again shifted 1 unit to the left or 1 unit to the right at
random. The process continues for 15 levels and the balls are
collected at the bottom for a short time until being collected by
suction to the top.

Can we do a simulation of the process using R with 100 balls, and plot
the frequency distribution of the position of the balls at the bottom
with respect to the entry position?

thx in advance

ej



From p.dalgaard at biostat.ku.dk  Sat Dec  9 10:26:38 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 09 Dec 2006 10:26:38 +0100
Subject: [R] Run Sample R (Linux)
In-Reply-To: <84ef61090612081703h16da7bcem244d677bab45f743@mail.gmail.com>
References: <84ef61090612081703h16da7bcem244d677bab45f743@mail.gmail.com>
Message-ID: <457A814E.4020809@biostat.ku.dk>

Nuno Vale wrote:
> Hi, all
> How do I run sample R (Linux). I open R, find a prompt an now what?
>   
Start by reading the "Introduction to R" manual. It is probably 
available somewhere in your installation (different linux versions have 
it in different places), or from
http://cran.r-project.org/manuals.html

In particular, run the example session in Appendix A.



From Knut-krueger at einthal.de  Sat Dec  9 10:27:44 2006
From: Knut-krueger at einthal.de (Knut Krueger)
Date: Sat, 09 Dec 2006 10:27:44 +0100
Subject: [R] [OT] sorry for sending two mails ... and thank's for the answers
In-Reply-To: <45799009.6020905@einthal.de>
References: <45799009.6020905@einthal.de>
Message-ID: <457A8190.7090206@einthal.de>

Does anybody know why this mail did not appear for more than 6 hours?
I thought that my URL might be at any blacklist, so I created a web.de 
account and resent the mail after a couple of hours.

Regards Knut



From david.meyer at wu-wien.ac.at  Sat Dec  9 11:06:04 2006
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Sat, 09 Dec 2006 11:06:04 +0100
Subject: [R] svm plot question
In-Reply-To: <6.1.2.0.2.20061208132230.01c76d08@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061207170402.01ca1058@aiminy.mail.iastate.edu>
	<45795B40.2060105@wu-wien.ac.at>
	<6.1.2.0.2.20061208132230.01c76d08@aiminy.mail.iastate.edu>
Message-ID: <457A8A8C.8050503@wu-wien.ac.at>

Aimin:

hard to tell. IMO, without specifying defaults, it could only work with
purely numeric data since factors were wrongly processed.

David.

Aimin Yan wrote:
> thanks, I did get this plot.
> Before I have this problem, I did get a plot by my code.
> However after I change a little my code. it doesn't work.
> It is pity not saving my original code.
> 
> Now the question is the plot I get using your code is different from
> what I got before.
> Moreover I did remember I use plot(m.svm,p5.new,As~Cur)
> 
> Do you know why?
> 
> Thanks,
> 
> Aimin
> 
> At 06:32 AM 12/8/2006, David Meyer wrote:
>> Aimin:
>>
>> 1) Please do not spam the r-help list---one request per issue (and two
>> private mails to the code author) really suffice. Not all contributors
>> to the R-project are on-line 24/24, and have time to provide immediate
>> answers.
>>
>> 2) The error occurs because plot.svm() currently does not set valid
>> defaults for categorical dimensions you are conditioning on for your
>> 2D-plot (in your example: 'P' and 'Aa') which certainly is a bug. I will
>> commit a fix for the next release of e1071. For the time being, you will
>> have to explicitly specify the levels of 'P' and 'Aa':
>>
>> plot(m.svm,p5.new,As~Cur, slice = list(P = factor("821p", levels =
>> levels(P)), Aa = factor("ALA", levels = levels(Aa))))
>>
>> (Note that the defaults for the "slice" argument are completely
>> arbitrary anyway).
>>
>> Thanks for pointing this out,
>>
>> David
>>
>> Aimin Yan wrote:
>> > I have a question about svm in R
>> >
>> > I run the following code, all other is ok,
>> > but plot(m.svm,p5.new,As~Cur) is not ok
>> >
>> > Do you know why?
>> >
>> > install.packages("e1071")
>> > library(e1071)
>> > library(MASS)
>> > p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
>> > p5.new<-subset(p5,select=-Ms)
>> > p5.new$Y<-factor(p5.new$Y)
>> > levels(p5.new$Y) <- list(Out=c(1), In=c(0))
>> > attach(p5.new)
>> > m.svm<-svm(Y~P+Aa+As+Cur,data=p5.new)
>> > summary(m.svm)
>> > plot(m.svm,p5.new,As~Cur)
>> >
>> > Here is output:
>> >
>> >> install.packages("e1071")
>> > --- Please select a CRAN mirror for use in this session ---
>> > trying URL
>> >
>> 'http://rh-mirror.linux.iastate.edu/CRAN/bin/windows/contrib/2.4/e1071_1.5-16.zip'
>>
>> >
>> > Content type 'application/zip' length 592258 bytes
>> > opened URL
>> > downloaded 578Kb
>> >
>> > package 'e1071' successfully unpacked and MD5 sums checked
>> >
>> > The downloaded packages are in
>> >         C:\Documents and Settings\aiminy\Local
>> > Settings\Temp\RtmpY0B2qb\downloaded_packages
>> > updating HTML package descriptions
>> >> library(e1071)
>> > Loading required package: class
>> >> library(MASS)
>> >> p5 <- read.csv("http://www.public.iastate.edu/~aiminy/data/p_5_2.csv")
>> >> p5.new<-subset(p5,select=-Ms)
>> >> p5.new$Y<-factor(p5.new$Y)
>> >> levels(p5.new$Y) <- list(Out=c(1), In=c(0))
>> >> attach(p5.new)
>> >> m.svm<-svm(Y~P+Aa+As+Cur,data=p5.new)
>> >> summary(m.svm)
>> >
>> > Call:
>> > svm(formula = Y ~ P + Aa + As + Cur, data = p5.new)
>> >
>> >
>> > Parameters:
>> >    SVM-Type:  C-classification
>> >  SVM-Kernel:  radial
>> >        cost:  1
>> >       gamma:  0.04
>> >
>> > Number of Support Vectors:  758
>> >
>> >  ( 382 376 )
>> >
>> >
>> > Number of Classes:  2
>> >
>> > Levels:
>> >  Out In
>> >
>> >
>> >
>> >> plot(m.svm,p5.new,As~Cur)
>> > Error in scale(newdata[, object$scaled, drop = FALSE], center =
>> > object$x.scale$"scaled:center",  :
>> >         (subscript) logical subscript too long
>> >>
>> >>
>> >
>> >
>> >
>>
>> -- 
>> Dr. David Meyer
>> Department of Information Systems and Operations
>>
>> Vienna University of Economics and Business Administration
>> Augasse 2-6, A-1090 Wien, Austria, Europe
>> Tel: +43-1-313 36 4393
>> Fax: +43-1-313 36 90 4393
>> HP:  http://wi.wu-wien.ac.at/~meyer/
> 
> 
> 
> 

-- 
Dr. David Meyer
Department of Information Systems and Operations

Vienna University of Economics and Business Administration
Augasse 2-6, A-1090 Wien, Austria, Europe
Tel: +43-1-313 36 4393
Fax: +43-1-313 36 90 4393
HP:  http://wi.wu-wien.ac.at/~meyer/



From bolker at zoo.ufl.edu  Sat Dec  9 14:43:08 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Sat, 9 Dec 2006 13:43:08 +0000 (UTC)
Subject: [R] Simulation with R
References: <5cd96f050612082239g5633cf8au36d3451a9b03fd05@mail.gmail.com>
Message-ID: <loom.20061209T144228-224@post.gmane.org>

Ethan Johnsons <ethan.johnsons <at> gmail.com> writes:

> 
> An apparatus exists ...
> 
> Can we do a simulation of the process using R with 100 balls, and plot
> the frequency distribution of the position of the balls at the bottom
> with respect to the entry position?
> 

  Can you make a plausible case that this isn't a homework problem?

  Ben Bolker



From jsorkin at grecc.umaryland.edu  Sat Dec  9 15:26:11 2006
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Sat, 09 Dec 2006 09:26:11 -0500
Subject: [R] Precision - or lack there of
In-Reply-To: <loom.20061209T144228-224@post.gmane.org>
References: <5cd96f050612082239g5633cf8au36d3451a9b03fd05@mail.gmail.com>
	<loom.20061209T144228-224@post.gmane.org>
Message-ID: <457A811B.A712.00CB.0@grecc.umaryland.edu>

R 2.3.1
Windows XP 

I am surprised at the lack of precision in R, as noted below. I would
expect the values to be closer to zero, particularly the later examples
where the sample size is quite large.

> mean(rnorm(500,0,1))
[1] -0.03209727
> mean(rnorm(5000,0,1))
[1] -0.005991322
> mean(rnorm(50000,0,1))
[1] -0.0006160524
> mean(rnorm(500000,0,1))
[1] -0.001254309
> mean(rnorm(5000000,0,1))
[1] 0.0004633778
> mean(rnorm(50000000,0,1))
[1] -0.0001325764

I would appreciate any thoughts. Is the lack of precision due to
running on a 32-bit system?

Thanks,
John


John Sorkin M.D., Ph.D.
Chief, Biostatistics and Informatics
Baltimore VA Medical Center GRECC,
University of Maryland School of Medicine Claude D. Pepper OAIC,
University of Maryland Clinical Nutrition Research Unit, and
Baltimore VA Center Stroke of Excellence

University of Maryland School of Medicine
Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524

(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)
jsorkin at grecc.umaryland.edu

Confidentiality Statement:
This email message, including any attachments, is for the so...{{dropped}}



From p.dalgaard at biostat.ku.dk  Sat Dec  9 15:41:55 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 09 Dec 2006 15:41:55 +0100
Subject: [R] Precision - or lack there of
In-Reply-To: <457A811B.A712.00CB.0@grecc.umaryland.edu>
References: <5cd96f050612082239g5633cf8au36d3451a9b03fd05@mail.gmail.com>	<loom.20061209T144228-224@post.gmane.org>
	<457A811B.A712.00CB.0@grecc.umaryland.edu>
Message-ID: <457ACB33.8030207@biostat.ku.dk>

John Sorkin wrote:
> R 2.3.1
> Windows XP 
>
> I am surprised at the lack of precision in R, as noted below. I would
> expect the values to be closer to zero, particularly the later examples
> where the sample size is quite large.
>
>   
>> mean(rnorm(500,0,1))
>>     
> [1] -0.03209727
>   
>> mean(rnorm(5000,0,1))
>>     
> [1] -0.005991322
>   
>> mean(rnorm(50000,0,1))
>>     
> [1] -0.0006160524
>   
>> mean(rnorm(500000,0,1))
>>     
> [1] -0.001254309
>   
>> mean(rnorm(5000000,0,1))
>>     
> [1] 0.0004633778
>   
>> mean(rnorm(50000000,0,1))
>>     
> [1] -0.0001325764
>
> I would appreciate any thoughts. Is the lack of precision due to
> running on a 32-bit system?
>
> Thanks,
> John
>
>
> J

Looks OK to me. The theoretical SEM in the latter case is 
sqrt(1/5e7)==0.0001414214.



From jsorkin at grecc.umaryland.edu  Sat Dec  9 15:48:04 2006
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Sat, 09 Dec 2006 09:48:04 -0500
Subject: [R] Precision - or lack there of
In-Reply-To: <457ACB33.8030207@biostat.ku.dk>
References: <5cd96f050612082239g5633cf8au36d3451a9b03fd05@mail.gmail.com>	<loom.20061209T144228-224@post.gmane.org>
	<457A811B.A712.00CB.0@grecc.umaryland.edu><457A811B.A712.00CB.0@grecc.umaryland.edu>
	<457ACB33.8030207@biostat.ku.dk>
Message-ID: <457A863B.A712.00CB.0@grecc.umaryland.edu>

Indeed, you are correct! In never pays to do stats too early in the
morning!
John

John Sorkin M.D., Ph.D.
Chief, Biostatistics and Informatics
Baltimore VA Medical Center GRECC,
University of Maryland School of Medicine Claude D. Pepper OAIC,
University of Maryland Clinical Nutrition Research Unit, and
Baltimore VA Center Stroke of Excellence

University of Maryland School of Medicine
Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524

(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)
jsorkin at grecc.umaryland.edu

>>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> 12/9/2006 9:41 AM >>>
John Sorkin wrote:
> R 2.3.1
> Windows XP 
>
> I am surprised at the lack of precision in R, as noted below. I
would
> expect the values to be closer to zero, particularly the later
examples
> where the sample size is quite large.
>
>   
>> mean(rnorm(500,0,1))
>>     
> [1] -0.03209727
>   
>> mean(rnorm(5000,0,1))
>>     
> [1] -0.005991322
>   
>> mean(rnorm(50000,0,1))
>>     
> [1] -0.0006160524
>   
>> mean(rnorm(500000,0,1))
>>     
> [1] -0.001254309
>   
>> mean(rnorm(5000000,0,1))
>>     
> [1] 0.0004633778
>   
>> mean(rnorm(50000000,0,1))
>>     
> [1] -0.0001325764
>
> I would appreciate any thoughts. Is the lack of precision due to
> running on a 32-bit system?
>
> Thanks,
> John
>
>
> J

Looks OK to me. The theoretical SEM in the latter case is 
sqrt(1/5e7)==0.0001414214.

Confidentiality Statement:
This email message, including any attachments, is for the so...{{dropped}}



From nbvale at gmail.com  Sat Dec  9 16:21:03 2006
From: nbvale at gmail.com (Nuno Vale)
Date: Sat, 9 Dec 2006 15:21:03 +0000
Subject: [R] R in linux
Message-ID: <84ef61090612090721k1b99b171xf252c4504d94407f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061209/b9e429c3/attachment-0005.pl 

From adi at roda.ro  Sat Dec  9 17:08:03 2006
From: adi at roda.ro (Adrian DUSA)
Date: Sat, 9 Dec 2006 18:08:03 +0200
Subject: [R] Count cases by indicator
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA035369B3@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA035369B3@usctmx1106.merck.com>
Message-ID: <200612091808.03931.adi@roda.ro>

Dear Serguei and Andy,

I was away for a few days so I appologize for this late reply. I cannot help 
but noticing Serguei's problem is somewhat suited to the QCA package.
For example, the 2^k combinations can be created simply with:

library(QCA)
cmat <- createMatrix(9)


As to the problem itself, the solution would be:

m <- as.data.frame(matrix(df$x, ncol=9, byrow=TRUE))
rownames(m) <- levels(df$case)
m$OUT <- 0
truthTable(m, outcome="OUT", show.cases=TRUE)

The result seconds Andy's result.

If Serguei wants the entire matrix, then use the "inside" argument:
truthTable(df, outcome="OUT", inside=TRUE)

I hope it helps,
Adrian


On Monday 04 December 2006 15:24, Liaw, Andy wrote:
> I might be missing something, but the data you showed don't seem to
> match your expectation.  Firstly, 111111111 in binary is 511 in decimal,
> so your "coordinates" are off by 1.  Secondly, for the data you've
> shown, the matrix equivalent look like:
>
> m <- matrix(df$x, ncol=9, byrow=TRUE)
> rownames(m) <- levels(df$cases)
> print(m)
>
>          [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
> 093/0188    0    0    1    0    1    1    1    1    1
> 093/0206    0    0    0    0    0    0    0    0    0
> 093/0216    0    1    1    1    1    1    0    1    1
> 093/0305    0    1    1    1    1    1    1    1    1
> 093/0325    0    0    0    0    0    0    0    0    0
> 093/0449    0    0    0    0    0    0    0    0    0
> 093/0473    0    0    1    1    1    1    1    1    1
> 093/0499    0    0    1    1    1    1    1    1    1
>
> The counts of unique occurances are:
>
> table(do.call(paste, c(as.data.frame(m), sep="")
>
> 000000000 001011111 001111111 011111011 011111111
>         3         1         2         1         1
>
> which do not agree with yours.
>
> If I understood what you wanted, I would do:
>
> R> table(rowSums(matrix(2^(0:8) * df$x, ncol=9, byrow=TRUE)))
>
>   0 446 500 508 510
>   3   1   1   2   1
>
> Andy
>
>
> From: Serguei Kaniovski
>
> > Hi,
> >
> > In the data below, "case" represents cases, "x" binary
> > states. Each "case" has exactly 9 "x", ie is a binary vector
> > of length 9.
> >
> > There are 2^9=512 possible combinations of binary states in a
> > given "case", ie 512 possible vectors. I generate these in
> > the order of the decimals the vectors represent, as:
> >
> > cmat<-as.matrix(expand.grid(rep(list(0:1),9)))
> > cmat<-cmat[nrow(cmat):1,ncol(cmat):1]
> >
> > "cmat" contains the binary vectors as rows.
> >
> > QUESTION: I would like to know how often each of the 512
> > vectors occurs in "case".
> >
> > With these data, the output should be a vector with 2^9=512
> > coordinates, having 2,2,1,3, as, respectively, the coordinate
> > number 129, 193, 449, 512, and zeros in all other coordinates.
> >
> > Thank you for your help,
> > Serguei
> >
> > df<-read.delim("clipboard",sep=";")
> >
> > DATA:
> > case;x
> > 093/0188;0
> > 093/0188;0
> > 093/0188;1
> > 093/0188;0
> > 093/0188;1
> > 093/0188;1
> > 093/0188;1
> > 093/0188;1
> > 093/0188;1
> > 093/0206;0
> > 093/0206;0
> > 093/0206;0
> > 093/0206;0
> > 093/0206;0
> > 093/0206;0
> > 093/0206;0
> > 093/0206;0
> > 093/0206;0
> > 093/0216;0
> > 093/0216;1
> > 093/0216;1
> > 093/0216;1
> > 093/0216;1
> > 093/0216;1
> > 093/0216;0
> > 093/0216;1
> > 093/0216;1
> > 093/0305;0
> > 093/0305;1
> > 093/0305;1
> > 093/0305;1
> > 093/0305;1
> > 093/0305;1
> > 093/0305;1
> > 093/0305;1
> > 093/0305;1
> > 093/0325;0
> > 093/0325;0
> > 093/0325;0
> > 093/0325;0
> > 093/0325;0
> > 093/0325;0
> > 093/0325;0
> > 093/0325;0
> > 093/0325;0
> > 093/0449;0
> > 093/0449;0
> > 093/0449;0
> > 093/0449;0
> > 093/0449;0
> > 093/0449;0
> > 093/0449;0
> > 093/0449;0
> > 093/0449;0
> > 093/0473;0
> > 093/0473;0
> > 093/0473;1
> > 093/0473;1
> > 093/0473;1
> > 093/0473;1
> > 093/0473;1
> > 093/0473;1
> > 093/0473;1
> > 093/0499;0
> > 093/0499;0
> > 093/0499;1
> > 093/0499;1
> > 093/0499;1
> > 093/0499;1
> > 093/0499;1
> > 093/0499;1
> > 093/0499;1
> > --
> > ___________________________________________________________________
> >
> > Austrian Institute of Economic Research (WIFO)
> >
> > Name: Serguei Kaniovski			P.O.Box 91
> > Tel.: +43-1-7982601-231			Arsenal Objekt 20
> > Fax:  +43-1-7989386			1103 Vienna, Austria
> > Mail: Serguei.Kaniovski at wifo.ac.at
> >
> > http://www.wifo.ac.at/Serguei.Kaniovski
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ---------------------------------------------------------------------------
>--- Notice:  This e-mail message, together with any
> attachments,...{{dropped}}

-- 
Adrian DUSA
Arhiva Romana de Date Sociale
Bd. Schitu Magureanu nr.1
050025 Bucuresti sectorul 5
Romania
Tel./Fax: +40 21 3126618 \
          +40 21 3120210 / int.101



From murdoch at stats.uwo.ca  Sat Dec  9 17:39:10 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 09 Dec 2006 11:39:10 -0500
Subject: [R] Precision - or lack there of
In-Reply-To: <457A811B.A712.00CB.0@grecc.umaryland.edu>
References: <5cd96f050612082239g5633cf8au36d3451a9b03fd05@mail.gmail.com>	<loom.20061209T144228-224@post.gmane.org>
	<457A811B.A712.00CB.0@grecc.umaryland.edu>
Message-ID: <457AE6AE.7090602@stats.uwo.ca>

On 12/9/2006 9:26 AM, John Sorkin wrote:
> R 2.3.1
> Windows XP 
> 
> I am surprised at the lack of precision in R, as noted below. I would
> expect the values to be closer to zero, particularly the later examples
> where the sample size is quite large.

These are all cases where the theoretical distributions are easy to 
calculate, and the results you are getting are not particularly unusual:
> 
>> mean(rnorm(500,0,1))
> [1] -0.03209727

 > pnorm(-0.03209727, sd=1/sqrt(500))
[1] 0.2364660

>> mean(rnorm(5000,0,1))
> [1] -0.005991322

 > pnorm(-0.005991322, sd=1/sqrt(5000))
[1] 0.3359104

[skipped some]

>> mean(rnorm(50000,0,1))
> [1] -0.0006160524
>> mean(rnorm(500000,0,1))
> [1] -0.001254309
>> mean(rnorm(5000000,0,1))
> [1] 0.0004633778
>> mean(rnorm(50000000,0,1))
> [1] -0.0001325764

 > pnorm(-0.0001325764, sd=1/sqrt(50000000))
[1] 0.1742618

> 
> I would appreciate any thoughts. Is the lack of precision due to
> running on a 32-bit system?

No, the lack of precision seems to be due to the distributions you are 
sampling from.

Duncan Murdoch

> 
> Thanks,
> John
> 
> 
> John Sorkin M.D., Ph.D.
> Chief, Biostatistics and Informatics
> Baltimore VA Medical Center GRECC,
> University of Maryland School of Medicine Claude D. Pepper OAIC,
> University of Maryland Clinical Nutrition Research Unit, and
> Baltimore VA Center Stroke of Excellence
> 
> University of Maryland School of Medicine
> Division of Gerontology
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> 
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> jsorkin at grecc.umaryland.edu
> 
> Confidentiality Statement:
> This email message, including any attachments, is for the so...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From marco at imada.sdu.dk  Sat Dec  9 18:00:23 2006
From: marco at imada.sdu.dk (Marco Chiarandini)
Date: Sat, 9 Dec 2006 18:00:23 +0100 (CET)
Subject: [R] Survfit plots in trellis graphics
Message-ID: <Pine.LNX.4.61.0612091752150.21896@minnie.imada.sdu.dk>

Dear all,

is there a way to produce survfit plots in a trellis environment?

I am trying this:

print(Ecdf(~time | size*type, groups=alg,data=B,subscripts=TRUE,
            panel=function(x,groups,subscripts)
            {
              t <- survfit(Surv(time[subscripts],event[subscripts])~groups[subscripts],data=B,conf.type="none")
              panel.xyplot(t[1]$time,1-t[1]$ssurv,type="s",lty=2)
              panel.xyplot(t[2]$time,1-t[2]$ssurv,type="s",lty=2)
            }
)



but things get messed up if I try log transformations and to plot
confidence intervals.


- Marco.


--
Marco Chiarandini                     http://www.imada.sdu.dk/~marco
Department of Mathematics	      Email: marco AT imada.sdu.dk
and Computer Science,		      Phone: +45 6550 4031
University of Southern Denmark        Fax: +45 6593 2691



From cberry at tajo.ucsd.edu  Sat Dec  9 18:09:09 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Sat, 9 Dec 2006 09:09:09 -0800
Subject: [R] R in linux
In-Reply-To: <84ef61090612090721k1b99b171xf252c4504d94407f@mail.gmail.com>
References: <84ef61090612090721k1b99b171xf252c4504d94407f@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0612090902040.18187@tajo.ucsd.edu>

On Sat, 9 Dec 2006, Nuno Vale wrote:

> Hi again, thank you for your reply but i wanted something a bit diferent.
> I have R in linux but cant get a graphical interface working so i am running
> from the console.
> How do i run a program i've writen. I have it saved as a file but cant seem
> to find out how to execute it.
> Is it in R, or do i use other of the programs in R's folder and pass the
> name of the file as arg.?


Hmmm. Sounds like you want to "Execute commands from a file".

Following Peter Dalgaard's advice in response to your earlier query, viz.

 	Start by reading the "Introduction to R" manual

would have led you to the answer to your question in section

 	1.10 Executing commands from or diverting output to a file




>
> Thanks for your time,
> Nuno Vale
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717



From ethan.johnsons at gmail.com  Sat Dec  9 18:35:06 2006
From: ethan.johnsons at gmail.com (Ethan Johnsons)
Date: Sat, 9 Dec 2006 12:35:06 -0500
Subject: [R] Error in rmultinom(n, size,
	prob) : too few positive probabilities
Message-ID: <5cd96f050612090935m11c5c33dh6aecc611076974d3@mail.gmail.com>

// R 2.3.1

Can someone please explain why this error returns?

> y=numeric(100)
> x=matrix(runif(16),4,4)
> for(i in 2:100)
+    {
+     y[i]=which(rmultinom(1, size = 1, prob = x[y[i-1], ])==1)
+    }
Error in rmultinom(n, size, prob) : too few positive probabilities

thx much

ej



From ligges at statistik.uni-dortmund.de  Sat Dec  9 18:41:58 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 09 Dec 2006 18:41:58 +0100
Subject: [R] Error in rmultinom(n, size,
	prob) : too few positive probabilities
In-Reply-To: <5cd96f050612090935m11c5c33dh6aecc611076974d3@mail.gmail.com>
References: <5cd96f050612090935m11c5c33dh6aecc611076974d3@mail.gmail.com>
Message-ID: <457AF566.3030700@statistik.uni-dortmund.de>



Ethan Johnsons wrote:
> // R 2.3.1
> 
> Can someone please explain why this error returns?
> 
>> y=numeric(100)
>> x=matrix(runif(16),4,4)
>> for(i in 2:100)
> +    {
> +     y[i]=which(rmultinom(1, size = 1, prob = x[y[i-1], ])==1)
> +    }
> Error in rmultinom(n, size, prob) : too few positive probabilities

y is 0, hence prob=x[y[i-1], ] is empty
You can try it out step by step yourself.

Uwe Ligges




> thx much
> 
> ej
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From mark at wardle.org  Sat Dec  9 20:40:05 2006
From: mark at wardle.org (Mark Wardle)
Date: Sat, 09 Dec 2006 19:40:05 +0000
Subject: [R] Show number at risk on Kaplan Meier curve
Message-ID: <457B1115.3010701@wardle.org>

Dear all,

I'm using the "survival" package with R 2.4.0 on Mac OS X 10.4.8.

I have two core statistics books (one of which is Altman's medical stats
book) which suggest showing the number of individuals at risk at
different time intervals on the Kaplan-Meier curve.

My plot shows two curves that later cross, because of one significant
outlier.

I have two queries:

Is there an easy way of displaying number of individuals at risk at a
specific time interval?

Is there a way to stop plotting when the number of individuals at risk
reaches a certain minimum threshold to reduce the risk of such an
outlier problem?

If there is no easy solution, then I suppose I shall have to perform the
logic myself, calculating when individuals "drop out", and overlaying
that onto the plot?

Many thanks,

Mark

-- 
Specialist Registrar and Clinical Research Fellow,
Department of Neurology, Cardiff University, UK



From jsorkin at grecc.umaryland.edu  Sat Dec  9 20:51:21 2006
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Sat, 09 Dec 2006 14:51:21 -0500
Subject: [R] Precision - or lack there of
In-Reply-To: <457AE6AE.7090602@stats.uwo.ca>
References: <5cd96f050612082239g5633cf8au36d3451a9b03fd05@mail.gmail.com>	<loom.20061209T144228-224@post.gmane.org>
	<457A811B.A712.00CB.0@grecc.umaryland.edu><457A811B.A712.00CB.0@grecc.umaryland.edu>
	<457AE6AE.7090602@stats.uwo.ca>
Message-ID: <457ACD69020000CB000058BA@medicine.umaryland.edu>

Ducan,
First, thank you for your reply. 
As I previously noted in a reply to Peter Dalgaard, you, and he, are
correct. I missed something quite obvious. Sometimes it does not pay to
do statistics early in the morning! Again, many thanks,
John

John Sorkin M.D., Ph.D.
Chief, Biostatistics and Informatics
Baltimore VA Medical Center GRECC,
University of Maryland School of Medicine Claude D. Pepper OAIC,
University of Maryland Clinical Nutrition Research Unit, and
Baltimore VA Center Stroke of Excellence

University of Maryland School of Medicine
Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524

(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)
jsorkin at grecc.umaryland.edu

>>> Duncan Murdoch <murdoch at stats.uwo.ca> 12/09/06 11:39 AM >>>
On 12/9/2006 9:26 AM, John Sorkin wrote:
> R 2.3.1
> Windows XP 
> 
> I am surprised at the lack of precision in R, as noted below. I
would
> expect the values to be closer to zero, particularly the later
examples
> where the sample size is quite large.

These are all cases where the theoretical distributions are easy to 
calculate, and the results you are getting are not particularly
unusual:
> 
>> mean(rnorm(500,0,1))
> [1] -0.03209727

 > pnorm(-0.03209727, sd=1/sqrt(500))
[1] 0.2364660

>> mean(rnorm(5000,0,1))
> [1] -0.005991322

 > pnorm(-0.005991322, sd=1/sqrt(5000))
[1] 0.3359104

[skipped some]

>> mean(rnorm(50000,0,1))
> [1] -0.0006160524
>> mean(rnorm(500000,0,1))
> [1] -0.001254309
>> mean(rnorm(5000000,0,1))
> [1] 0.0004633778
>> mean(rnorm(50000000,0,1))
> [1] -0.0001325764

 > pnorm(-0.0001325764, sd=1/sqrt(50000000))
[1] 0.1742618

> 
> I would appreciate any thoughts. Is the lack of precision due to
> running on a 32-bit system?

No, the lack of precision seems to be due to the distributions you are

sampling from.

Duncan Murdoch

> 
> Thanks,
> John
> 
> 
> John Sorkin M.D., Ph.D.
> Chief, Biostatistics and Informatics
> Baltimore VA Medical Center GRECC,
> University of Maryland School of Medicine Claude D. Pepper OAIC,
> University of Maryland Clinical Nutrition Research Unit, and
> Baltimore VA Center Stroke of Excellence
> 
> University of Maryland School of Medicine
> Division of Gerontology
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> 
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> jsorkin at grecc.umaryland.edu 
> 
> Confidentiality Statement:
> This email message, including any attachments, is for the\...{{dropped}}



From connect.chris at gmail.com  Sat Dec  9 21:50:44 2006
From: connect.chris at gmail.com (Chris Linton)
Date: Sat, 9 Dec 2006 15:50:44 -0500
Subject: [R] WinBUGS14 and R
Message-ID: <b05bf6c40612091250l40db271ejc105f5a2b4349f83@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061209/5cda367d/attachment-0005.pl 

From cberry at tajo.ucsd.edu  Sat Dec  9 21:56:54 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Sat, 9 Dec 2006 12:56:54 -0800
Subject: [R] Show number at risk on Kaplan Meier curve
In-Reply-To: <457B1115.3010701@wardle.org>
References: <457B1115.3010701@wardle.org>
Message-ID: <Pine.LNX.4.64.0612091230590.20069@tajo.ucsd.edu>

On Sat, 9 Dec 2006, Mark Wardle wrote:

> Dear all,
>
> I'm using the "survival" package with R 2.4.0 on Mac OS X 10.4.8.
>
> I have two core statistics books (one of which is Altman's medical stats
> book) which suggest showing the number of individuals at risk at
> different time intervals on the Kaplan-Meier curve.
>
> My plot shows two curves that later cross, because of one significant
> outlier.
>
> I have two queries:
>
> Is there an easy way of displaying number of individuals at risk at a
> specific time interval?
>
> Is there a way to stop plotting when the number of individuals at risk
> reaches a certain minimum threshold to reduce the risk of such an
> outlier problem?

The R questions are easily answered.

-------------
Look at

 	?survfit.object

These commands will plot while the risk set exceeds 5 and indicate at the 
bottom what the risk set sizes are at each step.

> fit <- survfit(Surv(time, status) ~ 1, data = aml)
> plot(fit, xlim=c(0, max(fit$time[fit$n.risk>=5])-0.5 ) )
> text( fit$time, 0, format(fit$n.risk), cex = 0.7 )

-------------

However, as to whether this 'reduces the risk of an outlier problem', 
failing to show what you think of as an 'outlier' may not be good 
statistical practice. Some treatments do indeed have crossing survival 
curves, and your 'outlier' may be the tip of an unexpected, emerging 
(albeit dimly perceived) iceberg.

HTH

> 
>
> If there is no easy solution, then I suppose I shall have to perform the
> logic myself, calculating when individuals "drop out", and overlaying
> that onto the plot?
>
> Many thanks,
>
> Mark
>
> -- 
> Specialist Registrar and Clinical Research Fellow,
> Department of Neurology, Cardiff University, UK
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717



From ibrahimmutlay at gmail.com  Sat Dec  9 22:02:36 2006
From: ibrahimmutlay at gmail.com (=?ISO-8859-9?Q?=DDbrahim_Mutlay?=)
Date: Sat, 9 Dec 2006 16:02:36 -0500
Subject: [R] Rcmdr package
Message-ID: <eb21cbcd0612091302n2f8a5fb0kf5646c6c6aa584da@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061209/ac6565d4/attachment-0005.pl 

From neil.a.mcleod at gmail.com  Sat Dec  9 22:28:13 2006
From: neil.a.mcleod at gmail.com (Neil McLeod)
Date: Sat, 9 Dec 2006 16:28:13 -0500
Subject: [R] Filtering a data frame by regular expression
Message-ID: <2c4b23d60612091328q49513805gd94bc1a0b4f0bf9d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061209/359e2ffc/attachment-0005.pl 

From p.dalgaard at biostat.ku.dk  Sat Dec  9 22:32:17 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 09 Dec 2006 22:32:17 +0100
Subject: [R] Rcmdr package
In-Reply-To: <eb21cbcd0612091302n2f8a5fb0kf5646c6c6aa584da@mail.gmail.com>
References: <eb21cbcd0612091302n2f8a5fb0kf5646c6c6aa584da@mail.gmail.com>
Message-ID: <457B2B61.40304@biostat.ku.dk>

?brahim Mutlay wrote:
> Dear R users,
>
> I want to install the Rcmdr package in a Quantian linux machine, but, when i
> tried that, following commands appeared:
>
>
> ** building package indices ...
> * DONE (Rcmdr)
>
> The downloaded packages are in
>         /tmp/RtmpuOikyk/downloaded_packages
>   
>> library("Rcmdr")
>>     
> Loading required package: tcltk
> Error in firstlib(which.lib.loc, package) :
>         Tcl/Tk support is not available on this system
> Error: package 'tcltk' could not be loaded
>   
>> library("tcltk")
>>     
> Error in firstlib(which.lib.loc, package) :
>         Tcl/Tk support is not available on this system
> Error in library("tcltk") : .First.lib failed for 'tcltk'
>
> I do not know why my OS does not support the Tcl/Tk.
>
>   
That is not clear. I believe it normally would. Did you compile R 
yourself or did it come with Quantian? Did you perchance forget to 
install the tcl/tk libraries (including devel packages if you did the 
compile)?
> Sincereley....
>   
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From edd at debian.org  Sat Dec  9 22:38:43 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 9 Dec 2006 15:38:43 -0600
Subject: [R] Rcmdr package
In-Reply-To: <eb21cbcd0612091302n2f8a5fb0kf5646c6c6aa584da@mail.gmail.com>
References: <eb21cbcd0612091302n2f8a5fb0kf5646c6c6aa584da@mail.gmail.com>
Message-ID: <17787.11491.636796.549561@basebud.nulle.part>


On 9 December 2006 at 16:02, ?brahim Mutlay wrote:
| Dear R users,
| 
| I want to install the Rcmdr package in a Quantian linux machine, but, when i
| tried that, following commands appeared:

Well, Quantian should already contain Rcmdr, albeit an older version given
that there hasn't been a Quantian release in a while.
 
| ** building package indices ...
| * DONE (Rcmdr)
| 
| The downloaded packages are in
|         /tmp/RtmpuOikyk/downloaded_packages
| > library("Rcmdr")
| Loading required package: tcltk
| Error in firstlib(which.lib.loc, package) :
|         Tcl/Tk support is not available on this system
| Error: package 'tcltk' could not be loaded
| > library("tcltk")
| Error in firstlib(which.lib.loc, package) :
|         Tcl/Tk support is not available on this system
| Error in library("tcltk") : .First.lib failed for 'tcltk'
| 
| I do not know why my OS does not support the Tcl/Tk.

Neitehr do I, and Quantian 'as shipped' obviously contains working R, tcltk,
Rcmdr and a number of other applications. 

Did you rebuild R and not build tcl/tk support with it?  What does this
command show on your box?  tcltk is indicated by the third element:

edd at basebud:~> echo "capabilities()" | R --no-save | tail -6
> capabilities()
    jpeg      png    tcltk      X11 http/ftp  sockets   libxml     fifo
    TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE
  cledit    iconv      NLS
   FALSE     TRUE     TRUE
>

Hth, Dirk

 

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison



From jholtman at gmail.com  Sat Dec  9 22:42:58 2006
From: jholtman at gmail.com (jim holtman)
Date: Sat, 9 Dec 2006 13:42:58 -0800
Subject: [R] Filtering a data frame by regular expression
In-Reply-To: <2c4b23d60612091328q49513805gd94bc1a0b4f0bf9d@mail.gmail.com>
References: <2c4b23d60612091328q49513805gd94bc1a0b4f0bf9d@mail.gmail.com>
Message-ID: <644e1f320612091342qc619c71w9e724681d5d50c20@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061209/01abcc67/attachment-0005.pl 

From ccleland at optonline.net  Sat Dec  9 22:44:19 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Sat, 09 Dec 2006 16:44:19 -0500
Subject: [R] Filtering a data frame by regular expression
In-Reply-To: <2c4b23d60612091328q49513805gd94bc1a0b4f0bf9d@mail.gmail.com>
References: <2c4b23d60612091328q49513805gd94bc1a0b4f0bf9d@mail.gmail.com>
Message-ID: <457B2E33.20601@optonline.net>

Neil McLeod wrote:
> Hello,
> 
> I am having difficulty filtering a data frame.
> 
> I would like to take all the rows of a data frame where column A contains
> the regular expression "UTI" (or some other regex). Here's what I've got:
> 
> utiRE <- function (avector) {
> occurs <- c()
> r1 <- "UTI"
> for (x in avector) {
> if (!is.na(grep(r1,x,perl=TRUE))) {
> occurs <- c(occurs, TRUE)
> } else {
> occurs <- c(occurs, FALSE)
> }
> 
> 
> I know this is a clunky way of doing it, but I tried more natural ways first
> (i.e. without iteration), to no avail. I think the problem is that when I
> iterate through the list, the strings in avector get turned into numbers.
> 
> Any solutions?

  The following approach works for me:

iris[grep("a$", iris$Species),]

iris[grep("^v", as.character(iris$Species)),]

> Thanks!

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894



From ibrahimmutlay at gmail.com  Sat Dec  9 23:09:51 2006
From: ibrahimmutlay at gmail.com (=?ISO-8859-9?Q?=DDbrahim_Mutlay?=)
Date: Sat, 9 Dec 2006 17:09:51 -0500
Subject: [R] Rcmdr package
In-Reply-To: <17787.11491.636796.549561@basebud.nulle.part>
References: <eb21cbcd0612091302n2f8a5fb0kf5646c6c6aa584da@mail.gmail.com>
	<17787.11491.636796.549561@basebud.nulle.part>
Message-ID: <eb21cbcd0612091409v5be56a8bx24174fa1d5d30986@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061209/9f019a69/attachment-0005.pl 

From pnovackg at westga.edu  Sat Dec  9 23:14:14 2006
From: pnovackg at westga.edu (Phil Novack-Gottshall)
Date: Sat, 09 Dec 2006 17:14:14 -0500
Subject: [R] Multiple label colors for leafs in plot(as.dendrogram(x))
Message-ID: <6.2.3.4.0.20061209170239.02acf320@mail.westga.edu>



From neil.a.mcleod at gmail.com  Sat Dec  9 23:15:15 2006
From: neil.a.mcleod at gmail.com (Neil McLeod)
Date: Sat, 9 Dec 2006 17:15:15 -0500
Subject: [R] Filtering a data frame by regular expression
In-Reply-To: <457B2E33.20601@optonline.net>
References: <2c4b23d60612091328q49513805gd94bc1a0b4f0bf9d@mail.gmail.com>
	<457B2E33.20601@optonline.net>
Message-ID: <2c4b23d60612091415k552a63e3s3f6866b9cd4b572@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061209/e3bcb403/attachment-0005.pl 

From edd at debian.org  Sat Dec  9 23:41:11 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 9 Dec 2006 16:41:11 -0600
Subject: [R] Rcmdr package
In-Reply-To: <eb21cbcd0612091409v5be56a8bx24174fa1d5d30986@mail.gmail.com>
References: <eb21cbcd0612091302n2f8a5fb0kf5646c6c6aa584da@mail.gmail.com>
	<17787.11491.636796.549561@basebud.nulle.part>
	<eb21cbcd0612091409v5be56a8bx24174fa1d5d30986@mail.gmail.com>
Message-ID: <17787.15239.103588.318464@basebud.nulle.part>


On 9 December 2006 at 17:09, ?brahim Mutlay wrote:
| Dear Mr. Eddelbuettel,

[ Well if you want to be formal, Dr Eddelbuettel is more appropriate.  But
Dirk is easier on your keyboard ... ]

| in R, i wrote the command of capabilities(), and the result was such like:
| 
| > capabilities()
| Xlib: connection to ":0.0" refused by server
| Xlib: No protocol specified
| 
|     jpeg      png    tcltk      X11 http/ftp  sockets   libxml     fifo
|    FALSE    FALSE    FALSE    FALSE     TRUE     TRUE     TRUE     TRUE
|   cledit    iconv      NLS
|     TRUE     TRUE     TRUE
| 
| My R version is 2.4.0, so, the version was compiled by me but i do not know
| about building the Tcl/Tk support. In fact, i followed the directions in the
| "INSTALL" file. Now i can't remember problems, if exist, at the installation
| process.

So you chose to build your own R instead of using the package I maintain for
Debian, and which I install onto Quantian.  No problem so far --- but you
happened to build R without jpeg, png, tcltk, or x11. There is a clear
message that configure prints at the end of its run that you probably
overlooked.  Maybe you want to revisit the extensive documentation
in the various READMEs and in the 'R Administration' manual?

As Peter told you, you need to make sure that you have all the required
development packages.  On a Debian system such as Quantian, this is easily
achieved via 'apt-get build-dep r-base' which would install all potentially
missing build-dependencies for the r-base package.  Eg on a Ubuntu 'edgy'
system I have here, a 'simulated' run (ie not actually installing it) starts
at

root at joe:~ # apt-get -s build-dep r-base
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following NEW packages will be installed:
  bison gfortran gfortran-4.1 libgfortran1-dev libmpfr1 libreadline5-dev
  refblas3-dev tcl8.4-dev texi2html tk8.4-dev
0 upgraded, 10 newly installed, 0 to remove and 0 not upgraded.

so the system can figure out itself what it needs. For comparison. on my
Debian box all pieces are present:

basebud:~# apt-get -s build-dep r-base
Reading package lists... Done
Building dependency tree... Done
0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded

Good luck,  Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison



From ibrahimmutlay at gmail.com  Sun Dec 10 00:29:25 2006
From: ibrahimmutlay at gmail.com (=?ISO-8859-9?Q?=DDbrahim_Mutlay?=)
Date: Sat, 9 Dec 2006 18:29:25 -0500
Subject: [R] Rcmdr package
In-Reply-To: <17787.15239.103588.318464@basebud.nulle.part>
References: <eb21cbcd0612091302n2f8a5fb0kf5646c6c6aa584da@mail.gmail.com>
	<17787.11491.636796.549561@basebud.nulle.part>
	<eb21cbcd0612091409v5be56a8bx24174fa1d5d30986@mail.gmail.com>
	<17787.15239.103588.318464@basebud.nulle.part>
Message-ID: <eb21cbcd0612091529v799ccd80x7ffa41553aea799a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061209/37563226/attachment-0005.pl 

From tuechler at gmx.at  Sun Dec 10 00:52:26 2006
From: tuechler at gmx.at (Heinz Tuechler)
Date: Sun, 10 Dec 2006 00:52:26 +0100
Subject: [R] convenient way to combine Surv objects?
Message-ID: <3.0.6.32.20061210005226.00afec18@pop.gmx.net>

Dear All,

is there a convenient way to combine Surv objects?
Imagine two Surv objects as in the following example.
Is it possible to combine them into one _Surv_ object?
I tried rbind(), cbind(), c(), merge(), but none of these function does,
what I would like.
So I drafted a method for rbind.Surv (see below), but I would be happy
about a better solution.

Ideas? Comments?

Thanks,
Heinz

R version 2.4.0 Patched (2006-11-03 r39792)
Windows XP

library(survival)
## create example data
so1 <- Surv(1:5, c(0, 0, 1, 0, 1))
so2 <- Surv(6:8, c(1, 0, 0))
### "combinefunction"(so1, so2)
## desired result:
[1] 1+ 2+ 3  4+ 5  6  7+ 8+

### Surv method for rbind - untested  
rbind.Surv <- function(..., deparse.level = 1)
{
  so <- list(...)
  ## check objects for number of columns
  so.dims <- sapply(so, dim)[2, ] # colums of each so
  min.so.cols <- min(so.dims)
  max.so.cols <- max(so.dims)
  ## if max range == 3 insert zero column in so with only 2 columns
  if (min.so.cols == 2 & max.so.cols == 3)
    for (i in seq(along=so)) {
      if (dim(so[[i]])[2] == 2) so[[i]] <- cbind(0, so[[i]])
    }
  ## function to get column in list element
  elco <- function(element,column) {element[,column]}
  if (max.so.cols == 2)
    return(Surv(unlist(sapply(so, elco, 1)), unlist(sapply(so, elco, 2))))
  else
    return(Surv(unlist(sapply(so, elco, 1)), unlist(sapply(so, elco, 2)),
                unlist(sapply(so, elco, 3))))
}

rbind(so1, so2)



From edd at debian.org  Sun Dec 10 02:11:02 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 9 Dec 2006 19:11:02 -0600
Subject: [R] Rcmdr package
In-Reply-To: <eb21cbcd0612091529v799ccd80x7ffa41553aea799a@mail.gmail.com>
References: <eb21cbcd0612091302n2f8a5fb0kf5646c6c6aa584da@mail.gmail.com>
	<17787.11491.636796.549561@basebud.nulle.part>
	<eb21cbcd0612091409v5be56a8bx24174fa1d5d30986@mail.gmail.com>
	<17787.15239.103588.318464@basebud.nulle.part>
	<eb21cbcd0612091529v799ccd80x7ffa41553aea799a@mail.gmail.com>
Message-ID: <17787.24230.709322.438045@basebud.nulle.part>


On 9 December 2006 at 18:29, ?brahim Mutlay wrote:
| My intent in installing a newer R version is just an approach that "newer is
| better". So, i'm a "teenager" statistician and R user, thus, i can not
| discriminate a newer tar.gz package from stable debian packages. But you're
| right about that i should use R coming from Quantian or maintained for
| Debian.
| 
| I tried "apt-get...." command, so, i faced to the words:
| 
| root at quantian:/home/mutlay/r# apt-get -s build-dep r-base
| Reading package lists... Done
| Building dependency tree... Done
| W: Couldn't stat source package list http://ndiswrapper.sourceforge.net ./
| Packages (/var/lib/apt/lists/ndiswrapper.sourceforge.net_debian_._Packages)
| - stat (2 No such file or directory)
| W: Couldn't stat source package list http://kanotix.com ./ Packages
| (/var/lib/apt/lists/kanotix.com_files_debian_._Packages) - stat (2 No such
| file or directory)
| W: You may want to run apt-get update to correct these problems
| E: You must put some 'source' URIs in your sources.list

It's the package manager telling you that two entries are not responding. You
should comment them out.

If all that is too complicated for you then ... maybe you should just run
Quantian "as is" ?  

There is a reason why there are more than six gigabytes of *installed* and
*configured* software ready to run -- installation can be tricky and tedious.
Quantian already has R, it has Rcmdr, and it has thousands more packages.
Why not use Quantian as-is if you can't get the newer stuff installed?

Regards, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison



From hodgess at gator.dt.uh.edu  Sun Dec 10 02:51:56 2006
From: hodgess at gator.dt.uh.edu (Erin Hodgess)
Date: Sat, 9 Dec 2006 19:51:56 -0600
Subject: [R]  DOE teaching suggestions?
Message-ID: <200612100151.kBA1pug5029578@gator.dt.uh.edu>

Dear R People:

I will be teaching an undergraduate Design of Experiments class
in the Spring Semester.  It will be very much an applied course.

My question, please:  has anyone used R for a course like this, please?

I've tried Rcmdr for a regression course and just plain command
line for a time series course.

Should I use Rcmdr, or teach them to use the command line, OR is there
something else, please?

Thanks in advance!

Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu



From dkaplan at education.wisc.edu  Sun Dec 10 05:39:19 2006
From: dkaplan at education.wisc.edu (David Kaplan)
Date: Sat, 09 Dec 2006 22:39:19 -0600
Subject: [R] R and LaTeX
Message-ID: <457B8F77.4070702@education.wisc.edu>

Hi all,

I have started using LaTeX for writing papers and I have heard that R 
works well with LaTeX.  I'm specifically interested in how I can have 
LaTeX read in R generated graphics - for example graphs formed by 
matplot, or other such  processes.  Does anyone out there use LaTeX and 
can point me in the right direction?

Thanks

David



-- 
=======================================================================
David Kaplan, Ph.D.
Professor
Department of Educational Psychology
University of Wisconsin - Madison
Educational Sciences, Room 1061
1025 W. Johnson Street
Madison, WI 53706

email: dkaplan at education.wisc.edu
Web:   http://www.education.wisc.edu/edpsych/facstaff/kaplan/kaplan.htm
Phone: 608-262-0836
Fax:   608-262-0843



From Kevin.Wang at maths.anu.edu.au  Sun Dec 10 06:11:27 2006
From: Kevin.Wang at maths.anu.edu.au (Ko-Kang Kevin Wang)
Date: Sun, 10 Dec 2006 16:11:27 +1100
Subject: [R] R and LaTeX
In-Reply-To: <457B8F77.4070702@education.wisc.edu>
References: <457B8F77.4070702@education.wisc.edu>
Message-ID: <457B96FF.8060903@maths.anu.edu.au>

Hi David,

You can export the graphs in (encapsulated) postscript format, or in 
PDF/PNG/JPEG format.  The following functions may be helpful:
   postscript()
   png()
   pdf()

You may also want to check out Sweave 
(http://www.ci.tuwien.ac.at/~leisch/Sweave/), it allows you to integrate 
LaTeX and R neatly.

Cheers,

Kevin

David Kaplan wrote:
> Hi all,
> 
> I have started using LaTeX for writing papers and I have heard that R 
> works well with LaTeX.  I'm specifically interested in how I can have 
> LaTeX read in R generated graphics - for example graphs formed by 
> matplot, or other such  processes.  Does anyone out there use LaTeX and 
> can point me in the right direction?
> 
> Thanks
> 
> David
> 
> 
> 


-- 
Ko-Kang Kevin Wang
Ph (H): +61-2-612 57471
Ph (M): +61-40-4518301
http://wwwmaths.anu.edu.au/~wangk/personal/



From A.Robinson at ms.unimelb.edu.au  Sun Dec 10 06:54:32 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 10 Dec 2006 16:54:32 +1100
Subject: [R] R and LaTeX
In-Reply-To: <457B8F77.4070702@education.wisc.edu>
References: <457B8F77.4070702@education.wisc.edu>
Message-ID: <20061210055432.GN4342@ms.unimelb.edu.au>

Hi David,

I strongly recommend that you use Sweave to mediate LaTeX and R.

http://www.ci.tuwien.ac.at/~leisch/Sweave/FAQ.html

Cheers

Andrew

On Sat, Dec 09, 2006 at 10:39:19PM -0600, David Kaplan wrote:
> Hi all,
> 
> I have started using LaTeX for writing papers and I have heard that R 
> works well with LaTeX.  I'm specifically interested in how I can have 
> LaTeX read in R generated graphics - for example graphs formed by 
> matplot, or other such  processes.  Does anyone out there use LaTeX and 
> can point me in the right direction?
> 
> Thanks
> 
> David
> 
> 
> 
> -- 
> =======================================================================
> David Kaplan, Ph.D.
> Professor
> Department of Educational Psychology
> University of Wisconsin - Madison
> Educational Sciences, Room 1061
> 1025 W. Johnson Street
> Madison, WI 53706
> 
> email: dkaplan at education.wisc.edu
> Web:   http://www.education.wisc.edu/edpsych/facstaff/kaplan/kaplan.htm
> Phone: 608-262-0836
> Fax:   608-262-0843
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From ethan.johnsons at gmail.com  Sun Dec 10 08:27:09 2006
From: ethan.johnsons at gmail.com (Ethan Johnsons)
Date: Sun, 10 Dec 2006 02:27:09 -0500
Subject: [R] bootstrap sample with R
Message-ID: <5cd96f050612092327v2b2fba8ey5b8dea1c4c439c62@mail.gmail.com>

How do you draw a bootstrap sample of size 9, with replacement, from
the random dataset I drew?   Is there a function for it in R?

9 random samples.

>rnorm(9, 0, 1)

[1]  1.2071538  0.3183367 -1.4237989 -0.4050909  0.9953866  0.9588178  0.9180879
[8] -0.1509696 -1.2230688


thx

ej



From Dimitris.Rizopoulos at med.kuleuven.be  Sun Dec 10 10:01:07 2006
From: Dimitris.Rizopoulos at med.kuleuven.be (Dimitrios Rizopoulos)
Date: Sun, 10 Dec 2006 10:01:07 +0100
Subject: [R] bootstrap sample with R
In-Reply-To: <5cd96f050612092327v2b2fba8ey5b8dea1c4c439c62@mail.gmail.com>
References: <5cd96f050612092327v2b2fba8ey5b8dea1c4c439c62@mail.gmail.com>
Message-ID: <20061210100107.fkbjc2ro6wpw0s0s@webmail4.kuleuven.be>

you need ?sample(), e.g.,

x <- rnorm(9)
sample(x, replace = TRUE)


I hope it helps.

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
      http://www.student.kuleuven.be/~m0390867/dimitris.htm


Quoting Ethan Johnsons <ethan.johnsons at gmail.com>:

> How do you draw a bootstrap sample of size 9, with replacement, from
> the random dataset I drew?   Is there a function for it in R?
>
> 9 random samples.
>
>> rnorm(9, 0, 1)
>
> [1]  1.2071538  0.3183367 -1.4237989 -0.4050909  0.9953866    
> 0.9588178  0.9180879
> [8] -0.1509696 -1.2230688
>
>
> thx
>
> ej
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>



Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From thpe at hhbio.wasser.tu-dresden.de  Sun Dec 10 10:47:46 2006
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Sun, 10 Dec 2006 10:47:46 +0100
Subject: [R] require(simecol) error
In-Reply-To: <7054.51965.qm@web56606.mail.re3.yahoo.com>
References: <7054.51965.qm@web56606.mail.re3.yahoo.com>
Message-ID: <457BD7C2.6090005@hhbio.wasser.tu-dresden.de>

Hello,

thanks for using simecol. The "official" version 0.3-11 from CRAN has no
problems with R 2.4.0. However, it was necessary to re-build simecol 
0.3-12 (under development version from my homepage) to run under 2.4.0.

I've just uploaded a fixed version to www.simecol.de. The next stable 
version will be available from CRAN as usual.

Thanks for your report, please excuse this inconvenience.

Thomas P.


Milton Cezar Ribeiro wrote:
> Hi there,
>    
>   I?m trying to use "simecol" package but I got the error showed below. I?m runnig R version 2.4.0 (2006-10-03).
>    
>   Kind regards,
>    
>   miltinho
>   Brazil
>   ---
>   > require(simecol)
> Loading required package: simecol
> Error in loadNamespace(package, c(which.lib.loc, lib.loc), keep.source = keep.source) : 
>         in 'simecol' methods specified for export, but none defined: fixInit, fixParms, fixTimes, plot, print, solver, solver<-, out, inputs, inputs<-, main, main<-, equations, equations<-, sim, parms, parms<-, init, init<-, times, times<-
> [1] FALSE
>   -----
>    
> 
>  __________________________________________________
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From aiminy at iastate.edu  Sun Dec 10 11:18:32 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Sun, 10 Dec 2006 04:18:32 -0600
Subject: [R] extract R code from Sweave file
Message-ID: <6.1.2.0.2.20061210041655.01c44858@aiminy.mail.iastate.edu>

I want to extract all chunk codes from file" 557_project.Rnw". why this is 
not ok?

thanks,

Aimin

 > Rtangle("557_project.Rnw",output="557_project")
Error in Rtangle("557_project.Rnw", output = "557_project") :
         unused argument(s) ("557_project.Rnw", output = "557_project")



From jenny197806 at yahoo.se  Sun Dec 10 11:25:41 2006
From: jenny197806 at yahoo.se (Jenny persson)
Date: Sun, 10 Dec 2006 11:25:41 +0100 (CET)
Subject: [R] how to sort random numbers according to the sample ?
Message-ID: <20061210102542.74308.qmail@web28014.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061210/587bd01c/attachment-0005.pl 

From ronggui.huang at gmail.com  Sun Dec 10 11:28:54 2006
From: ronggui.huang at gmail.com (ronggui)
Date: Sun, 10 Dec 2006 18:28:54 +0800
Subject: [R] extract R code from Sweave file
In-Reply-To: <6.1.2.0.2.20061210041655.01c44858@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061210041655.01c44858@aiminy.mail.iastate.edu>
Message-ID: <38b9f0350612100228w6a37b43v28f1b534ed368da1@mail.gmail.com>

try
>Stangle("557_project.Rnw",output="557_project")

On 12/10/06, Aimin Yan <aiminy at iastate.edu> wrote:
> I want to extract all chunk codes from file" 557_project.Rnw". why this is
> not ok?
>
> thanks,
>
> Aimin
>
>  > Rtangle("557_project.Rnw",output="557_project")
> Error in Rtangle("557_project.Rnw", output = "557_project") :
>          unused argument(s) ("557_project.Rnw", output = "557_project")
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Ronggui Huang
Department of Sociology
Fudan University, Shanghai, China
??????
????????????????



From aiminy at iastate.edu  Sun Dec 10 11:48:45 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Sun, 10 Dec 2006 04:48:45 -0600
Subject: [R] set up directory for R when I start R
Message-ID: <6.1.2.0.2.20061210044729.01c284c0@aiminy.mail.iastate.edu>

I want to set default directory for R when I start R.
How to do this?

Thanks,

Aimin



From dieter.menne at menne-biomed.de  Sun Dec 10 11:59:07 2006
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Sun, 10 Dec 2006 10:59:07 +0000 (UTC)
Subject: [R] set up directory for R when I start R
References: <6.1.2.0.2.20061210044729.01c284c0@aiminy.mail.iastate.edu>
Message-ID: <loom.20061210T115836-859@post.gmane.org>

Aimin Yan <aiminy <at> iastate.edu> writes:

> 
> I want to set default directory for R when I start R.
> How to do this?
> 
?setwd

In Windows, I prefer the method described in

http://tolstoy.newcastle.edu.au/R/help/00b/2454.html

Dieter



From Dimitris.Rizopoulos at med.kuleuven.be  Sun Dec 10 12:01:19 2006
From: Dimitris.Rizopoulos at med.kuleuven.be (Dimitrios Rizopoulos)
Date: Sun, 10 Dec 2006 12:01:19 +0100
Subject: [R] how to sort random numbers according to the sample ?
In-Reply-To: <20061210102542.74308.qmail@web28014.mail.ukl.yahoo.com>
References: <20061210102542.74308.qmail@web28014.mail.ukl.yahoo.com>
Message-ID: <20061210120119.0c6djj6b83u8s0g0@webmail4.kuleuven.be>

in your example you need

r <- matrix(runif(12), 4, 3)
x <- c(6, 8, 9, 11)
########
apply(r, 2, function(y) x[order(y)])


however, you can directly use sample(), i.e.,

sapply(1:3, function(i) sample(x))


I hope it helps.

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
      http://www.student.kuleuven.be/~m0390867/dimitris.htm


Quoting Jenny persson <jenny197806 at yahoo.se>:

> Dear R-users,
>
>   ####  below is my code to randomized x three times.
>
>   > x=c(6,8,9,11)
>> plan=NULL
>> for(i in 1:3){
> + set.seed(i)
> + r<-runif(x)
> + plan=cbind(plan,r)
> + }
>
>
>
>   #####  which gave the matrix
>
>   > plan
>              r                  r         r
> [1,] 0.2655087 0.1848823 0.1680415
> [2,] 0.3721239 0.7023740 0.8075164
> [3,] 0.5728534 0.5733263 0.3849424
> [4,] 0.9082078 0.1680519 0.3277343
>
>   #### and order numbers
>
>>  apply(plan,2,order)
>        r r r
> [1,] 1 4 1
> [2,] 2 1 4
> [3,] 3 3 3
> [4,] 4 2 2
>
>   ### My question is, is there a way to order the matrix "plan"   
> according to x so I don't have to check that 1 is corresponding to   
> 6, 2 corresponds to 8 , 3 to 9 and 4 to 11. I mean after ordering   
> matrix "plan " the result should be
>
>        r   r     r
> [1,] 6   11   6
> [2,] 8   6   11
> [3,] 9   9     9
> [4,] 11 8     8
>
>   Thanks for any help,
>
>   All the bests,
>   Jenny
>
>
> ---------------------------------
>
> Stava r?tt! Stava l?tt! Yahoo! Mails stavkontroll tar hand om   
> tryckfelen och mycket mer! F? den p? http://se.mail.yahoo.com
> 	[[alternative HTML version deleted]]
>
>



Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From jim at bitwrit.com.au  Sun Dec 10 12:45:11 2006
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 10 Dec 2006 22:45:11 +1100
Subject: [R] set up directory for R when I start R
In-Reply-To: <6.1.2.0.2.20061210044729.01c284c0@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061210044729.01c284c0@aiminy.mail.iastate.edu>
Message-ID: <457BF347.8070703@bitwrit.com.au>

Aimin Yan wrote:
> I want to set default directory for R when I start R.
> How to do this?
> 
Hi Aimin,
There is a discussion of how to set up different start up commands, 
usually for attaching to icons, in "Kickstarting R":

http://cran.r-project.org/doc/contrib/Lemon-kickstart/kr_start.html

You can also write an R file that can branch to a number of different 
directories on start up. Basically a bunch of statements like:

cat("(C)at studies\n")
cat("(D)og studies\n")
...
answer<-readline("")
if(toupper(strsplit(answer,"")[1]) == "C") setwd("/home/jim/cats")
if(toupper(strsplit(answer,"")[1]) == "D") setwd("/home/jim/dogs")
...


Jim



From f.harrell at vanderbilt.edu  Sun Dec 10 14:43:52 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sun, 10 Dec 2006 07:43:52 -0600
Subject: [R] Show number at risk on Kaplan Meier curve
In-Reply-To: <457B1115.3010701@wardle.org>
References: <457B1115.3010701@wardle.org>
Message-ID: <457C0F18.9060005@vanderbilt.edu>

Mark Wardle wrote:
> Dear all,
> 
> I'm using the "survival" package with R 2.4.0 on Mac OS X 10.4.8.
> 
> I have two core statistics books (one of which is Altman's medical stats
> book) which suggest showing the number of individuals at risk at
> different time intervals on the Kaplan-Meier curve.
> 
> My plot shows two curves that later cross, because of one significant
> outlier.
> 
> I have two queries:
> 
> Is there an easy way of displaying number of individuals at risk at a
> specific time interval?
> 
> Is there a way to stop plotting when the number of individuals at risk
> reaches a certain minimum threshold to reduce the risk of such an
> outlier problem?
> 
> If there is no easy solution, then I suppose I shall have to perform the
> logic myself, calculating when individuals "drop out", and overlaying
> that onto the plot?
> 
> Many thanks,
> 
> Mark
> 

library(Design) # which also requires the Hmisc package
f <- cph( ..., surv=TRUE)
survplot(f, ..., n.risk=TRUE)

?survplot for details


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From jenny197806 at yahoo.se  Sun Dec 10 14:58:22 2006
From: jenny197806 at yahoo.se (Jenny persson)
Date: Sun, 10 Dec 2006 14:58:22 +0100 (CET)
Subject: [R] question about data manipulation
Message-ID: <20061210135822.40474.qmail@web28009.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061210/afcf94d3/attachment-0005.pl 

From lobry at biomserv.univ-lyon1.fr  Sun Dec 10 15:45:13 2006
From: lobry at biomserv.univ-lyon1.fr (Jean lobry)
Date: Sun, 10 Dec 2006 15:45:13 +0100
Subject: [R] Sweave and warning messages
Message-ID: <p0600200cc1a1c7e177a8@[134.214.34.142]>

>How does one tell Sweave() to include analysis warning
>messages in the verbatim output?

That's something I would like to know too. If you are not
affraid by a shameless hack, you can use sink() to redirect
stderr into the LaTeX output file and redefine warning()
to encapsulate this within a Soutput environment:

Sweaving this file:
http://pbil.univ-lyon1.fr/members/lobry/R/warning.rnw
gives me this result:
http://pbil.univ-lyon1.fr/members/lobry/R/warning.pdf

Best,
-- 
Jean R. Lobry            (lobry at biomserv.univ-lyon1.fr)
Laboratoire BBE-CNRS-UMR-5558, Univ. C. Bernard - LYON I,
43 Bd 11/11/1918, F-69622 VILLEURBANNE CEDEX, FRANCE
allo  : +33 472 43 27 56     fax    : +33 472 43 13 88
http://pbil.univ-lyon1.fr/members/lobry/



From jholtman at gmail.com  Sun Dec 10 15:52:21 2006
From: jholtman at gmail.com (jim holtman)
Date: Sun, 10 Dec 2006 06:52:21 -0800
Subject: [R] question about data manipulation
In-Reply-To: <20061210135822.40474.qmail@web28009.mail.ukl.yahoo.com>
References: <20061210135822.40474.qmail@web28009.mail.ukl.yahoo.com>
Message-ID: <644e1f320612100652l1f6f0535mfe612fe9ad4a53fb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061210/ad192bac/attachment-0005.pl 

From ligges at statistik.uni-dortmund.de  Sun Dec 10 15:59:17 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 10 Dec 2006 15:59:17 +0100
Subject: [R] R and LaTeX
In-Reply-To: <20061210055432.GN4342@ms.unimelb.edu.au>
References: <457B8F77.4070702@education.wisc.edu>
	<20061210055432.GN4342@ms.unimelb.edu.au>
Message-ID: <457C20C5.3060201@statistik.uni-dortmund.de>

Or if you mean how to annotate plots with mathematical symbols and 
formulas, see ?plotmath.

Uwe Ligges

Andrew Robinson wrote:
> Hi David,
> 
> I strongly recommend that you use Sweave to mediate LaTeX and R.
> 
> http://www.ci.tuwien.ac.at/~leisch/Sweave/FAQ.html
> 
> Cheers
> 
> Andrew
> 
> On Sat, Dec 09, 2006 at 10:39:19PM -0600, David Kaplan wrote:
>> Hi all,
>>
>> I have started using LaTeX for writing papers and I have heard that R 
>> works well with LaTeX.  I'm specifically interested in how I can have 
>> LaTeX read in R generated graphics - for example graphs formed by 
>> matplot, or other such  processes.  Does anyone out there use LaTeX and 
>> can point me in the right direction?
>>
>> Thanks
>>
>> David
>>
>>
>>
>> -- 
>> =======================================================================
>> David Kaplan, Ph.D.
>> Professor
>> Department of Educational Psychology
>> University of Wisconsin - Madison
>> Educational Sciences, Room 1061
>> 1025 W. Johnson Street
>> Madison, WI 53706
>>
>> email: dkaplan at education.wisc.edu
>> Web:   http://www.education.wisc.edu/edpsych/facstaff/kaplan/kaplan.htm
>> Phone: 608-262-0836
>> Fax:   608-262-0843
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>



From h.wickham at gmail.com  Sun Dec 10 16:04:25 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 10 Dec 2006 09:04:25 -0600
Subject: [R] question about data manipulation
In-Reply-To: <20061210135822.40474.qmail@web28009.mail.ukl.yahoo.com>
References: <20061210135822.40474.qmail@web28009.mail.ukl.yahoo.com>
Message-ID: <f8e6ff050612100704x33f58422p4e7450ee01fa021d@mail.gmail.com>

On 12/10/06, Jenny persson <jenny197806 at yahoo.se> wrote:
>   Dear all,
>
>   I have a dataset
>
>
>   dat<- pep[c(420:423,1258:1261,2096:2099),c(3,4,7,14)]
>
>
>        Slide  Block       Name     pearson_res
>   2102    23     2 CTERQANFLGKIWPS  0.07618407
>   2103    23     2 ATLEEMMTACQGVGG  1.93543619
>   2104    23     2 IPVGEIYKRWIILGL  0.22211959
>   2105    23     2 MFSALSEGATPQDLN -0.08249410
>   3662    24     2 CTERQANFLGKIWPS -0.10250513
>   3663    24     2 ATLEEMMTACQGVGG -0.05479617
>   3664    24     2 IPVGEIYKRWIILGL  0.14669877
>   3665    24     2 MFSALSEGATPQDLN -0.19059432
>   6782    30     2 CTERQANFLGKIWPS -0.01064459
>   6783    30     2 ATLEEMMTACQGVGG -0.03758618
>   6784    30     2 IPVGEIYKRWIILGL  0.20724517
>   6785    30     2 MFSALSEGATPQDLN -0.23034595
>
>
>   where all slides (23,24,30) have the same name. I want to rearrange the dataset so it will have the matrix look
>
>           Name    slide=23 slide=24 slide=30 block
>   CTERQANFLGKIWPS
>   ATLEEMMTACQGVGG
>   IPVGEIYKRWIILGL
>   MFSALSEGATPQDLN
>
>   the pearson_res values will be filled under each slide corresponding to the name-variable.
>
>   I find manipulating data like this is quite tricky. Thanks for your help.

You might want to have a look at the reshape package,
http://had.co.nz/reshape, which aims to make these operations simple.

For your example, something like the following should work:

dm <- melt(dat, id=c("Slide", "Block","Name"))
cast(dm, Name ~ Slide + Block)
cast(dm, Name ~ Block + Slide)

or even
cast(dm, Name ~ Block ~ Slide)
depending on what you want to do with the data next.

Regards,

Hadley



From ligges at statistik.uni-dortmund.de  Sun Dec 10 16:12:50 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 10 Dec 2006 16:12:50 +0100
Subject: [R] WinBUGS14 and R
In-Reply-To: <b05bf6c40612091250l40db271ejc105f5a2b4349f83@mail.gmail.com>
References: <b05bf6c40612091250l40db271ejc105f5a2b4349f83@mail.gmail.com>
Message-ID: <457C23F2.8010605@statistik.uni-dortmund.de>

Try to use paths without blanks in it.
If that does not work, please provide some reproducible example (e.g., I 
do not have "abs.4diff").


BTW: "(is greyed out)" means cannot be used now (buttons appear greyed 
out in the GUI). Hence the error happened before (in the check line).


Uwe Ligges


Chris Linton wrote:
> I'm trying to call BUGS from R.  But it's not working.  R freezes up and
> BUGS gives me a strange output in the log.  Just to know, BUGS is
> registered.  The modified date on the keys file is today (Dec. 9th).  It
> should be fully registered so that I can use it fully.  And, the BUGS model
> is syntactically correct.  Any suggestions would be very helpful.
> 
> Here is my BUGS model:
> model {
>     for (i in 1:n){
>         y[i] ~ dnorm (y.hat[i], tau.y)
>         y.hat[i] <- a[county[i]] + b[county[i]]*x[i]
>     }
> 
> for (j in 1:J){
>     a[j] ~ dnorm (0, .0001)
>     b[j] ~ dnorm (b.hat, tau.b)
>     }
> 
> b.hat ~ dnorm (0, .0001)
> tau.b <- pow(sigma.b, -2)
> sigma.b ~ dnorm (0, 100)
> tau.y <- pow(sigma.y, -2)
> sigma.y ~ dunif (0, 100)
> }
> 
> 
> Here is my R code used to call BUGS:
> y <- abs.4diff
> n <- length(abs.4diff)
> x <- log.ineq
> 
> uniq.name <- unique(country_name)
> J <- length(uniq.name)
> country <- rep (NA, J)
> for (i in 1:J){
>     country[country_name==uniq.name[i]] <- i
> }
> 
> ineq.bugs <- list ("n", "J", "y", "country", "x")
> ineq.inits <- function (){
>     list(a=rnorm(J), b=rnorm(J), b.hat=rnorm(1), sigma.y=runif(1),
> sigma.b=runif(1))}
> ineq.parameters <- c("a", "b", "b.hat", "sigma.y", "sigma.b")
> 
> ineq1 <- bugs (ineq.bugs, ineq.inits, ineq.parameters, "C:/Documents and
> Settings/Chris/Desktop/4330/attempt2.bug", n.chains=3, n.iter=10,
> debug=TRUE)
> 
> 
> 
> After I run the R code, R will crash and WinBUGS14 will post this in the
> log:
> 
> display(log)
> check(C:/Documents and Settings/Chris/Desktop/4330/attempt2.txt)
> expected left pointing arrow <- or twiddles ~
> data(C:/Documents and Settings/Chris/data.txt)
> command #Bugs:data cannot be executed (is greyed out)
> compile(3)
> inits(1,C:/Documents and Settings/Chris/inits1.txt)
> command #Bugs:inits cannot be executed (is greyed out)
> inits(2,C:/Documents and Settings/Chris/inits2.txt)
> command #Bugs:inits cannot be executed (is greyed out)
> inits(3,C:/Documents and Settings/Chris/inits3.txt)
> command #Bugs:inits cannot be executed (is greyed out)
> gen.inits()
> command #Bugs:gen.inits cannot be executed (is greyed out)
> thin.updater(1)
> update(5)
> command #Bugs:update cannot be executed (is greyed out)
> set(a)
> command #Bugs:set cannot be executed (is greyed out)
> set(b)
> command #Bugs:set cannot be executed (is greyed out)
> set(b.hat)
> command #Bugs:set cannot be executed (is greyed out)
> set(sigma.y)
> command #Bugs:set cannot be executed (is greyed out)
> set(sigma.b)
> command #Bugs:set cannot be executed (is greyed out)
> set(deviance)
> command #Bugs:set cannot be executed (is greyed out)
> dic.set()
> command #Bugs:dic.set cannot be executed (is greyed out)
> update(5)
> command #Bugs:update cannot be executed (is greyed out)
> coda(*,C:/Documents and Settings/Chris/coda)
> command #Bugs:coda cannot be executed (is greyed out)
> stats(*)
> command #Bugs:stats cannot be executed (is greyed out)
> dic.stats()
> 
> DIC
> history(*,C:/Documents and Settings/Chris/history.odc)
> command #Bugs:history cannot be executed (is greyed out)
> save(C:/Documents and Settings/Chris/log.odc)
> save(C:/Documents and Settings/Chris/log.txt)
> 
> 
> 
> I'm not sure what "(is greyed out)" means.  But, BUGS supposed give really
> poor explanations of its errors.  So, it could mean anything.  Any advice
> will be greatly appreciated.
> 
> 
> Thank you for your time,
> 
> Chris Linton
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jsorkin at grecc.umaryland.edu  Sun Dec 10 17:20:13 2006
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Sun, 10 Dec 2006 11:20:13 -0500
Subject: [R] bootstrap sample with R
In-Reply-To: <5cd96f050612092327v2b2fba8ey5b8dea1c4c439c62@mail.gmail.com>
References: <5cd96f050612092327v2b2fba8ey5b8dea1c4c439c62@mail.gmail.com>
Message-ID: <457BED6D020000CB000058F7@medicine.umaryland.edu>

Ethan,
It is quite easy if you use the sample function with replace=TRUE:

> y<-rnorm(9,0,1)
> y
[1]  0.0625366 -0.1225751  0.1335859 -1.5930572  0.2493484 -0.1926270
-0.5615023
[8]  0.7537500  1.4977661
> sample(y,replace=TRUE)
[1]  1.4977661  0.1335859  0.0625366  0.2493484 -0.1225751  1.4977661 
0.7537500
[8]  0.2493484  0.0625366

John

John Sorkin M.D., Ph.D.
Chief, Biostatistics and Informatics
Baltimore VA Medical Center GRECC,
University of Maryland School of Medicine Claude D. Pepper OAIC,
University of Maryland Clinical Nutrition Research Unit, and
Baltimore VA Center Stroke of Excellence

University of Maryland School of Medicine
Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524

(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)
jsorkin at grecc.umaryland.edu

>>> "Ethan Johnsons" <ethan.johnsons at gmail.com> 12/10/06 2:27 AM >>>
How do you draw a bootstrap sample of size 9, with replacement, from
the random dataset I drew?   Is there a function for it in R?

9 random samples.

>rnorm(9, 0, 1)

[1]  1.2071538  0.3183367 -1.4237989 -0.4050909  0.9953866  0.9588178 
0.9180879
[8] -0.1509696 -1.2230688


thx

ej

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code.

Confidentiality Statement:
This email message, including any attachments, is for the so...{{dropped}}



From mark at wardle.org  Sun Dec 10 17:53:13 2006
From: mark at wardle.org (Mark Wardle)
Date: Sun, 10 Dec 2006 16:53:13 +0000
Subject: [R] Show number at risk on Kaplan Meier curve
In-Reply-To: <457C0F18.9060005@vanderbilt.edu>
References: <457B1115.3010701@wardle.org> <457C0F18.9060005@vanderbilt.edu>
Message-ID: <457C3B79.3040805@wardle.org>

Frank E Harrell Jr wrote:

> 
> library(Design) # which also requires the Hmisc package
> f <- cph( ..., surv=TRUE)
> survplot(f, ..., n.risk=TRUE)
> 
> ?survplot for details
> 
> 


Thank you for the replies.

Both solutions perfectly - and I've now another package to experiment
with - so I'm very grateful!

My work is looking at natural history rather than the effects of an
intervention, so I'm not too worried about stopping the curves when
there are one or two long-lifers. I think that is a reasonable thing to
do anyway!

Best wishes,

Mark



From pensterfuzzer at yahoo.de  Sun Dec 10 18:56:29 2006
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Sun, 10 Dec 2006 18:56:29 +0100 (CET)
Subject: [R] Modeling problem with Multinomial Logit
Message-ID: <20061210175630.1935.qmail@web23007.mail.ird.yahoo.com>

Hi,

I have a problem modeling a multinomial regression.
This is the tentative function:
multinom(resp ~ age + sex + ... +
I(log(wage)),data=work)

resp is a factor with 4 levels.
My problem is that the variable wage should only go
into the equation for 
certain levels of resp and should be zero for the
others.

I would be very grateful if somebody could tell me how
I can model this in R.

Thanks a million,
   Werner



From mothsailor at googlemail.com  Sun Dec 10 19:39:08 2006
From: mothsailor at googlemail.com (David Barron)
Date: Sun, 10 Dec 2006 18:39:08 +0000
Subject: [R] Modeling problem with Multinomial Logit
In-Reply-To: <20061210175630.1935.qmail@web23007.mail.ird.yahoo.com>
References: <20061210175630.1935.qmail@web23007.mail.ird.yahoo.com>
Message-ID: <815b70590612101039y1c2f8cfo44973ca34447280b@mail.gmail.com>

Do you mean something like this (assuming that it is levels 1 and 2
that should be zero):

resp <- factor(sample(1:4,100,replace=TRUE))
wage <- rnorm(100,100,5)

new.wage <- ifelse(resp==1|resp==2,0,log(wage))
multinom(resp ~ new.wage)

On 10/12/06, Werner Wernersen <pensterfuzzer at yahoo.de> wrote:
> Hi,
>
> I have a problem modeling a multinomial regression.
> This is the tentative function:
> multinom(resp ~ age + sex + ... +
> I(log(wage)),data=work)
>
> resp is a factor with 4 levels.
> My problem is that the variable wage should only go
> into the equation for
> certain levels of resp and should be zero for the
> others.
>
> I would be very grateful if somebody could tell me how
> I can model this in R.
>
> Thanks a million,
>    Werner
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP



From pnovackg at westga.edu  Sun Dec 10 19:46:49 2006
From: pnovackg at westga.edu (Phil Novack-Gottshall)
Date: Sun, 10 Dec 2006 13:46:49 -0500
Subject: [R] Multiple label colors for leafs in plot(as.dendrogram(x))
Message-ID: <6.2.3.4.0.20061210134310.02acc020@mail.westga.edu>

Greetings:

[Apologies if duplicate; I am resending because original format 
prevented viewing.]

Is there a way to get plot.dendrogram (or some other dendrogram 
plotting function) to have multiple label colors for leaves?  It 
seems the nodePar parameters only allow control of branch (inner 
nodes) and leaves (outer nodes), without allowing different leaves 
(or inner nodes) to have different colors.

I am attempting to produce a dendrogram where different factors 
(groups of related species) are plotted as different colors.  The 
number of species is too large to read labels, so assigning labels 
[as in examples(agnes)] is not possible.  Visually, I am trying to 
assess the degree in which the different species groups form distinct 
versus tangled clusters.  (Ordination is showing this pattern 
clearly, but I would like to see it in a dendrogram, too.)

Thanks for any recommendations,
Phil


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
   Phil 
Novack-Gottshall                        pnovackg at westga.edu 


   Assistant Professor
   Department of Geosciences
   University of West Georgia
   Carrollton, GA 30118-3100
   Phone: 678-839-4061
   Fax: 678-839-4071
   http://www.westga.edu/~pnovackg
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From spencer.graves at pdf.com  Sun Dec 10 19:59:05 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 10 Dec 2006 10:59:05 -0800
Subject: [R] DOE teaching suggestions?
In-Reply-To: <200612100151.kBA1pug5029578@gator.dt.uh.edu>
References: <200612100151.kBA1pug5029578@gator.dt.uh.edu>
Message-ID: <457C58F9.7060807@pdf.com>

Hi, Erin: 

      Are you planning to have them design and conduct an actual 
physical experiment as part of the class?  You may know that Bill Hunter 
(the second Hunter of Box, Hunter & Hunter) wrote articles about doing 
this, and I found it extremely helpful.   Things happen with real 
physical experiments that can't be duplicated with any kind of computer 
simulation. 

      I think I've gotten good results assigning team projects of their 
own choosing.  I found it necessary to have "design review" 
presentations in the middle of the class.  These presentations give you 
feedback on their understanding of the class material to that date.  
They also give you an opportunity to suggest improvements before they 
actually do the experiment. 

      This is not what you asked, but I hope you find it useful, anyway. 
      Best Wishes,
      Spencer Graves    

Erin Hodgess wrote:
> Dear R People:
>
> I will be teaching an undergraduate Design of Experiments class
> in the Spring Semester.  It will be very much an applied course.
>
> My question, please:  has anyone used R for a course like this, please?
>
> I've tried Rcmdr for a regression course and just plain command
> line for a time series course.
>
> Should I use Rcmdr, or teach them to use the command line, OR is there
> something else, please?
>
> Thanks in advance!
>
> Sincerely,
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgess at gator.uhd.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From kbenoit at tcd.ie  Sun Dec 10 20:22:17 2006
From: kbenoit at tcd.ie (Kenneth Benoit)
Date: Sun, 10 Dec 2006 19:22:17 +0000
Subject: [R] R2WinBUGS and calling WinBUGS in Crossover/WINE
Message-ID: <457C5E69.1030404@tcd.ie>

Hi there - I have a question for any of you who use R2WinBUGS to call 
WinBUGS using the useWINE option in that package.

I have Codeweaver's Crossover emulator installed on my Intel Mac with 
WinBUGS working fine if I start it from Crossover.  But there is 
supposed to be a way to start it directly from a command line, which I 
could pass to the R2WinBUGS using the bugs(..., useWINE="something") 
argument.

Has anyone tried this yet?  Thanks!

Ken

Kenneth Benoit
Associate Professor of Political Science
Department of Political Science, Trinity College
Dublin 2, Ireland
http://benoit.tcd.ie
Tel: 353-1-608-2491
Fax: 353-1-677-0546



From milton_ruser at yahoo.com.br  Sun Dec 10 20:28:33 2006
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Sun, 10 Dec 2006 19:28:33 +0000 (GMT)
Subject: [R] sample "n" random positions from a matrix
Message-ID: <687436.75963.qm@web56612.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061210/d706a007/attachment-0005.pl 

From saldanha.plangeo at gmail.com  Sun Dec 10 21:02:09 2006
From: saldanha.plangeo at gmail.com (Raphael Saldanha)
Date: Sun, 10 Dec 2006 17:02:09 -0300
Subject: [R] ANOVA K-means
Message-ID: <c85849370612101202u2a68a4d7v89eeeb0fa4a9e961@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061210/451f785f/attachment-0005.pl 

From phhs80 at gmail.com  Sun Dec 10 21:22:43 2006
From: phhs80 at gmail.com (Paul Smith)
Date: Sun, 10 Dec 2006 20:22:43 +0000
Subject: [R] sample "n" random positions from a matrix
In-Reply-To: <687436.75963.qm@web56612.mail.re3.yahoo.com>
References: <687436.75963.qm@web56612.mail.re3.yahoo.com>
Message-ID: <6ade6f6c0612101222k45b24f1av9a454534989885a@mail.gmail.com>

On 12/10/06, Milton Cezar Ribeiro <milton_ruser at yahoo.com.br> wrote:
>   I have a binary matrix (dim 100x100) filled with values 0 and 1. I need select a record "n" positions of that matrix when values are 1. How can I do that?

Do you mean extracting the indexes of n randomly chosen elements of
the matrix which are equal to one?

Paul



From A.Robinson at ms.unimelb.edu.au  Sun Dec 10 21:21:47 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 11 Dec 2006 07:21:47 +1100
Subject: [R] lmer, gamma family, log link: interpreting random effects
Message-ID: <20061210202147.GP4342@ms.unimelb.edu.au>

Dear all,

I'm curious about how to interpret the results of the following code.
The first model is directly from the help page of lmer; the second is
the same model but using the Gamma family with log link.  The fixed
effects make sense, because

y = 251.40510 + 10.46729 * Days

is about the same as 

log(y) = 5.53613298  + 0.03502057 * Days

but the random effects seem quite disproportionate. Am I missing
something obvious, or is this a bug?

Cheers

Andrew

> require(lme4)
> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> fixef(fm1)
(Intercept)        Days 
  251.40510    10.46729 
> ranef(fm1)
An object of class "ranef.lmer"
[[1]]
    (Intercept)        Days
308   2.2713451   9.1966961
309 -40.3825921  -8.6223099
310 -38.9403378  -5.4521894
330  23.6656443  -4.8100611
331  22.2391295  -3.0662861
332   9.0324969  -0.2709760
333  16.8277808  -0.2214775
334  -7.2256113   1.0733822
335  -0.3503176 -10.7492136
337  34.8784025   8.6302064
349 -25.1898574   1.1699674
350 -13.0500361   6.6107496
351   4.5697621  -3.0138529
352  20.8539011   3.5376139
369   3.2744289   0.8723798
370 -25.5865985   4.8179542
371   0.8049003  -0.9877807
372  12.3075594   1.2851975

> fm1.g.log <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,  family=Gamma(link="log"))
> fixef(fm1.g.log)
(Intercept)        Days 
 5.53613298  0.03502057 
> ranef(fm1.g.log)
An object of class "ranef.lmer"
[[1]]
      (Intercept)          Days
308  6.817799e-10  4.462209e-09
309 -1.367226e-09 -6.921681e-09
310 -1.120295e-09 -5.303576e-09
330  1.173973e-10 -6.049948e-10
331  2.104704e-10  1.531865e-10
332  1.501432e-10  6.721697e-10
333  3.048322e-10  1.103687e-09
334 -6.193655e-11 -7.056224e-11
335 -7.539673e-10 -4.999876e-09
337  1.263556e-09  6.502735e-09
349 -3.974501e-10 -1.294252e-09
350  2.112016e-10  2.125564e-09
351 -1.220139e-10 -1.095394e-09
352  6.412044e-10  3.215876e-09
369  1.231353e-10  6.292502e-10
370 -1.520576e-10  4.003904e-10
371 -5.220764e-11 -4.587212e-10
372  3.234287e-10  1.484018e-09


-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From arnholt at cs.appstate.edu  Sun Dec 10 21:45:07 2006
From: arnholt at cs.appstate.edu (Alan Arnholt)
Date: Sun, 10 Dec 2006 15:45:07 -0500 (EST)
Subject: [R] Noncentral t & F distributions
Message-ID: <Pine.LNX.4.64.0612101542510.20114@cs.appstate.edu>

Dear List:

The square of the noncentral t-statistic with noncentrality parameter 
\delta is a noncentral F with noncentrality parameter \lambda=\delta^2. 
So, t^2_{\nu,\delta} = F_{1,\nu,\lambda=\delta^2}.  Consequently, it 
should follow that t^2_{1-\alpha/2,\nu,\delta} = 
f_{1-alpha,1,\vu,\lambda=\delta^2}.  However, this is not what is 
happening with the following code.  The central distributions agree as 
they should but the noncentral distributions do not.  Am I missing 
something or is there a bug in the code?

> alpha <- 0.05
> nu <- 10
> NCP <- c(0,1,2,3)
> TV <- (qt(1-alpha/2,nu,NCP))^2
> FV <- qf(1-alpha,1,nu,NCP^2)
> rbind(TV,FV)
        [,1]      [,2]     [,3]     [,4]
TV 4.964603 12.535179 24.58013 41.71937
FV 4.964603  9.285829 18.98771 32.97855
> TV <- (qt(1-alpha/2,nu,NCP))^2
> FV <- qf(1-alpha/2,1,nu,NCP^2)
> rbind(TV,FV)
        [,1]     [,2]     [,3]     [,4]
TV 4.964603 12.53518 24.58013 41.71937
FV 6.936728 12.56450 24.58023 41.71937

Thanks,

Alan-

> version
                _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          4.0
year           2006
month          10
day            03
svn rev        39566
language       R
version.string R version 2.4.0 (2006-10-03)


Alan T. Arnholt
Associate Professor
Dept. of Mathematical Sciences
Appalachian State University
TEL: 828 262 2863
FAX: 828 265 8617



From p.dalgaard at biostat.ku.dk  Sun Dec 10 22:09:24 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun, 10 Dec 2006 22:09:24 +0100
Subject: [R] Noncentral t & F distributions
In-Reply-To: <Pine.LNX.4.64.0612101542510.20114@cs.appstate.edu>
References: <Pine.LNX.4.64.0612101542510.20114@cs.appstate.edu>
Message-ID: <457C7784.3020105@biostat.ku.dk>

Alan Arnholt wrote:
> Dear List:
>
> The square of the noncentral t-statistic with noncentrality parameter 
> \delta is a noncentral F with noncentrality parameter \lambda=\delta^2. 
> So, t^2_{\nu,\delta} = F_{1,\nu,\lambda=\delta^2}.  Consequently, it 
> should follow that t^2_{1-\alpha/2,\nu,\delta} = 
> f_{1-alpha,1,\vu,\lambda=\delta^2}.  However, this is not what is 
> happening with the following code.  The central distributions agree as 
> they should but the noncentral distributions do not.  Am I missing 
> something or is there a bug in the code?
>
>   
You're missing something: The noncentral t is not symmetric, so there's 
no obvious relation between qf(1-alpha), qt(alpha/2) and qt(1-alpha/2)

>> alpha <- 0.05
>> nu <- 10
>> NCP <- c(0,1,2,3)
>> TV <- (qt(1-alpha/2,nu,NCP))^2
>> FV <- qf(1-alpha,1,nu,NCP^2)
>> rbind(TV,FV)
>>     
>         [,1]      [,2]     [,3]     [,4]
> TV 4.964603 12.535179 24.58013 41.71937
> FV 4.964603  9.285829 18.98771 32.97855
>   
>> TV <- (qt(1-alpha/2,nu,NCP))^2
>> FV <- qf(1-alpha/2,1,nu,NCP^2)
>> rbind(TV,FV)
>>     
>         [,1]     [,2]     [,3]     [,4]
> TV 4.964603 12.53518 24.58013 41.71937
> FV 6.936728 12.56450 24.58023 41.71937
>   

> rbind(pt(sqrt(FV),nu,NCP,lower=F),  pt(-sqrt(FV),nu,NCP))

      [,1]         [,2]         [,3]       [,4]

[1,] 0.025 0.0496216546 4.999922e-02 5.0000e-02

[2,] 0.025 0.0003783451 7.776214e-07 7.8153e-10

> colSums(rbind(pt(sqrt(FV),nu,NCP,lower=F),  pt(-sqrt(FV),nu,NCP)))

[1] 0.05 0.05 0.05 0.05


> Thanks,
>
> Alan-
>
>   
>> version
>>     
>                 _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          4.0
> year           2006
> month          10
> day            03
> svn rev        39566
> language       R
> version.string R version 2.4.0 (2006-10-03)
>
>
> Alan T. Arnholt
> Associate Professor
> Dept. of Mathematical Sciences
> Appalachian State University
> TEL: 828 262 2863
> FAX: 828 265 8617
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From bolker at zoo.ufl.edu  Sun Dec 10 22:19:37 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Sun, 10 Dec 2006 21:19:37 +0000 (UTC)
Subject: [R] R2WinBUGS and calling WinBUGS in Crossover/WINE
References: <457C5E69.1030404@tcd.ie>
Message-ID: <loom.20061210T221719-542@post.gmane.org>

Kenneth Benoit <kbenoit <at> tcd.ie> writes:

> 
> Hi there - I have a question for any of you who use R2WinBUGS to call 
> WinBUGS using the useWINE option in that package.
> 
> I have Codeweaver's Crossover emulator installed on my Intel Mac with 
> WinBUGS working fine if I start it from Crossover.  But there is 
> supposed to be a way to start it directly from a command line, which I 
> could pass to the R2WinBUGS using the bugs(..., useWINE="something") 
> argument.
> 
> Has anyone tried this yet?  Thanks!
> 

   useWINE=TRUE.  You may have to set some environment
variables (e.g. WINE is the path to your WINE executable).
It's supposed to just work out of the box.  I have some
fixes that I've been meaning to upload to complement
the existing stuff, but haven't.  If you run into
trouble drop me a line.

 Ben Bolker



From fhduan at gmail.com  Sun Dec 10 22:58:58 2006
From: fhduan at gmail.com (Frank Duan)
Date: Sun, 10 Dec 2006 15:58:58 -0600
Subject: [R] Problem with loading "library(Matrix)" at Ubuntu
Message-ID: <3b9172310612101358o27692257v42a4aeba35aca38d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061210/71029498/attachment-0005.pl 

From theoni.photopoulos at gmail.com  Sun Dec 10 23:40:18 2006
From: theoni.photopoulos at gmail.com (Theoni Photopoulos)
Date: Sun, 10 Dec 2006 22:40:18 +0000
Subject: [R] Offset for Poisson GLM
Message-ID: <9d3e6d080612101440i5f781fc6r9597f648d1cad1bb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061210/0bcdd9b7/attachment-0005.pl 

From edd at debian.org  Sun Dec 10 23:56:23 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 10 Dec 2006 16:56:23 -0600
Subject: [R] Problem with loading "library(Matrix)" at Ubuntu
In-Reply-To: <3b9172310612101358o27692257v42a4aeba35aca38d@mail.gmail.com>
References: <3b9172310612101358o27692257v42a4aeba35aca38d@mail.gmail.com>
Message-ID: <17788.37015.737657.350887@basebud.nulle.part>


Frank,

On 10 December 2006 at 15:58, Frank Duan wrote:
| Dear All,
| 
| After upgrading to R-2.4.0-dapper2 (my system is ubuntu 6.06 LTS), I often
| met problems when loading some packages like Matrix.
| 
| Here is the details:
| 
| > library(Matrix)
| Error in loadNamespace(package, c(which.lib.loc, lib.loc), keep.source =
| keep.source) :
|         in 'Matrix' methods specified for export, but none defined: Arith,
| Math, Math2, +, %*%, Schur, as.matrix, chol, colMeans, colSums, coerce,
| crossprod, determinant, diag, dim, dimnames, dimnames<-, expand, expm,
| kronecker, image, norm, rcond, rowMeans, rowSums, show, solve, t, tcrossprod
| Error: package/namespace load failed for 'Matrix'
| 
| Here is my system:
| 
| > sessionInfo()
| R version 2.4.0 (2006-10-03)
| i486-pc-linux-gnu
| 
| locale:
| LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
| 
| attached base packages:
| [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
| [7] "base"
| 
| 
| I have re-installed the packages after the upgrade. Anyone experienced the
| similar problems?
| 
| Thanks for your help,

This works for me. Are you sure you did 'update.packages()' for everything
R-related, and also have current Ubuntu packages so that you have current
compilers?

Lastly, make sure you don't have Ubuntu's r-cran-matrix _and_ a direct
installation via R...

Hth, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison



From o.samarasinghe at auckland.ac.nz  Mon Dec 11 00:12:30 2006
From: o.samarasinghe at auckland.ac.nz (Samarasinghe, Oshadhi Erandika)
Date: Mon, 11 Dec 2006 12:12:30 +1300
Subject: [R] Use of bread() function
Message-ID: <1E11F4042C05ED4BAA6BA96319DA56610FCE7ED2@comxchg1.com.auckland.ac.nz>


Hello,

I am trying to extract an estimator for the bread of the sandwich
function. I used bread(fitted model) however it seems that I have missed
something as an error message "no applicable method for "bread" appears.

My fitted model is a Spatial simultaneous autoregressive error
model.(errorsarlm in spdep package)

Can anyone please tell me what I might be doing wrong?

Your help is much appreciated.

Thank you,

Oshadhi Samarasinghe.
RA
Department of Economics 
University of Auckland
New Zealand



From Achim.Zeileis at wu-wien.ac.at  Mon Dec 11 00:36:50 2006
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Mon, 11 Dec 2006 00:36:50 +0100 (CET)
Subject: [R] Use of bread() function
In-Reply-To: <1E11F4042C05ED4BAA6BA96319DA56610FCE7ED2@comxchg1.com.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0612110028080.6686-100000@disco.wu-wien.ac.at>

> I am trying to extract an estimator for the bread of the sandwich
> function. I used bread(fitted model) however it seems that I have missed
> something as an error message "no applicable method for "bread" appears.

This is pretty explicit, don't you think?

> My fitted model is a Spatial simultaneous autoregressive error
> model.(errorsarlm in spdep package)
>
> Can anyone please tell me what I might be doing wrong?

You did not look close enough at the docs in the sandwich package:
sandwich() can compute sandwich estimators from fitted models if there is
a bread() and an estfun() method. For errorsarlm neither exists and has to
be provided by you!
As I told you before, I do not know how easy (or sensible) it is, to set
up these methods based on the information available in errorsarlm. But the
vignette (and the source code) provide some worked examples for other
classes.
Roger Bivand added to this that the whole HC/sandwich approach implemented
in the sandwich package is probably not the most sensible thing to use
with spatial data...
Z



From dylan.beaudette at gmail.com  Mon Dec 11 01:00:06 2006
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Sun, 10 Dec 2006 16:00:06 -0800
Subject: [R] cohen kappa for two-way table
Message-ID: <3c5546140612101600o3dc649f0v97eebd9a7a101838@mail.gmail.com>

Greetings,

I am a bit confused by the results returned by the functions:
cohen.kappa {concord}
classAgreement {e1071}

when using a two-way table.


for example, if I have an matrix A, and a similar matrix B (same
dimensions), then:

matrix A and B can be found:
http://casoilresource.lawr.ucdavis.edu/drupal/files/a_40.txt
http://casoilresource.lawr.ucdavis.edu/drupal/files/b_40.txt

A <- matrix(unlist( read.table('a_40.txt'), use.names=FALSE), ncol=14)
B <- matrix(unlist( read.table('b_40.txt'), use.names=FALSE), ncol=14)

# compute cohen's kappa, default settings:
cohen.kappa(table(A,B))
Kappa test for nominally classified data
9 categories - 90 methods
kappa (Cohen) = 0.97353 , Z = 45.4465 , p = 0
kappa (Siegel) = -0.00744097 , Z = -0.0794501 , p = 0.531663
kappa (2*PA-1) = 0.947061


# compute cohen's kappa - type = counts
cohen.kappa(table(A,B), type='counts')

Different row sums, a no-classification category was added.

Kappa test for nominally classified data
91 categories - 22 methods
kappa (Siegel) = 0.168593 , Z = 2.50298 , p = 0.00615762
kappa (2*PA-1) = 0.71485

it seems like the second method (type='counts') is the correct way to
use a contingency table... but am i correct?

Secondly, when using the classAgreements() function I get different numbers:

classAgreement(table(A,B))
$diag
[1] 0.03296703

$kappa
[1] 0.02180419

$rand
[1] 0.9874325

$crand
[1] 0.7648124



Perhaps I am mis-reading the relevant manual pages. Can anyone shed
some light on the proper use, and therfore interpretation of these two
methods - when using a contingency table as input?

Thanks in advance,

Dylan



From bolker at zoo.ufl.edu  Mon Dec 11 01:31:30 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Mon, 11 Dec 2006 00:31:30 +0000 (UTC)
Subject: [R] Simulation with R
References: <5cd96f050612082239g5633cf8au36d3451a9b03fd05@mail.gmail.com>
Message-ID: <loom.20061211T012111-336@post.gmane.org>

Ethan Johnsons <ethan.johnsons <at> gmail.com> writes:

> 
> An apparatus exists whereby a collection of balls is displaced to the
> top of a stack by suction. A top level (Level 1) each ball is shifted
> 1 unit to the left or 1 unit to the right at random with equal
> probability. The ball then drops down to level 2. At Level 2, each
> ball is again shifted 1 unit to the left or 1 unit to the right at
> random. The process continues for 15 levels and the balls are
> collected at the bottom for a short time until being collected by
> suction to the top.
> 
> Can we do a simulation of the process using R with 100 balls, and plot
> the frequency distribution of the position of the balls at the bottom
> with respect to the entry position?
> 

  After poking around a bit, I see from your Google groups profile
that you are (or at least claim to be) self-teaching yourself
biostats -- which explains your really heavy posting record
here and in other stats forums and means this isn't 
necessarily homework.
(I know, I could just keep my mouth shut).  It would
probably be helpful if it were possible for you to find someone
local to help with some of these questions, as many of them are 
basic stats questions ...

  As for this question -- this process generates a binomial distribution.
Some ways of simulating the frequency distribution are
(1) use rbinom() to sample a number of left- moves for
each of 100 balls -- then the number of right-moves is known,
and you can calculate the ending position
(2) construct a string of 1 and -1 values
for each ball
(either use sample(c(-1,1),size=100,replace=TRUE),
or something involving sign(runif(100),-1,1)) and
use cumsum() to calculate the final position
(3) use a for() loop to sample values and calculate
the position one step at a time [move <- sample(c(-1,1));
cpos <- cpos+move; etc.]

#1 is by far the most efficient, #3 the least, but
might be the most transparent.

  Would you consider "giving back to the community" by writing
up some of the most useful advice you've gotten
for the R wiki?

  Ben Bolker



From fhduan at gmail.com  Mon Dec 11 01:40:17 2006
From: fhduan at gmail.com (Frank Duan)
Date: Sun, 10 Dec 2006 18:40:17 -0600
Subject: [R] Problem with loading "library(Matrix)" at Ubuntu
In-Reply-To: <17788.37015.737657.350887@basebud.nulle.part>
References: <3b9172310612101358o27692257v42a4aeba35aca38d@mail.gmail.com>
	<17788.37015.737657.350887@basebud.nulle.part>
Message-ID: <3b9172310612101640n6f7480f1w3f481518451eb2e5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061210/4d0cdce4/attachment-0005.pl 

From gerifalte28 at hotmail.com  Mon Dec 11 03:35:01 2006
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Sun, 10 Dec 2006 19:35:01 -0700
Subject: [R] sample "n" random positions from a matrix
In-Reply-To: <687436.75963.qm@web56612.mail.re3.yahoo.com>
References: <687436.75963.qm@web56612.mail.re3.yahoo.com>
Message-ID: <457CC3D5.3000804@hotmail.com>

Milton,

If I understand your problem correctly, you want to take (and store) a 
random sample of the indexes of a matrix for values equal to 1.  If 
that's the case the following may work for you:

m=matrix(sample(c(0,1),100*100,replace=T),nrow=100,ncol=100) #Creates matrix

idxsample=function(m,n){
   idx=which(m==1,F)#Index of positions of 1's in the matrix
   pos=sample(idx,n,replace=F)#Random sample of matrix indexes
   return(pos)
}

This call will sample and store 20 "positions" with value==1 in your matrix
pos=idxsample(m,n=20)

you can then use the resulting object to retrieve the values from your 
matrix i.e.
m[pos] (not surprisingly, all == 1)


I hope this helps,

Francisco


Dr. Francisco J. Zagmutt
College of Veterinary Medicine and Biomedical Sciences
Colorado State University


Milton Cezar Ribeiro wrote:
> Hi there,
>    
>   I have a binary matrix (dim 100x100) filled with values 0 and 1. I need select a record "n" positions of that matrix when values are 1. How can I do that?
>    
>   Thanks for all,
>   Miltinho
>   Brazil
> 
>  		
> ---------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From cberry at tajo.ucsd.edu  Mon Dec 11 05:00:57 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Sun, 10 Dec 2006 20:00:57 -0800
Subject: [R] sample "n" random positions from a matrix
In-Reply-To: <687436.75963.qm@web56612.mail.re3.yahoo.com>
References: <687436.75963.qm@web56612.mail.re3.yahoo.com>
Message-ID: <Pine.LNX.4.64.0612101955090.3078@tajo.ucsd.edu>

On Sun, 10 Dec 2006, Milton Cezar Ribeiro wrote:

> Hi there,
>
>  I have a binary matrix (dim 100x100) filled with values 0 and 1. I need
>  select a record "n" positions of that matrix when values are 1. How can
>  I do that?
>

Is this what you want?

> mat.100 <- diag(100) # just for instance
> n <- 7  # supposing you want 7
> which( mat.100==1, arr.ind=T )[ sample( 100, n ), ]
      row col
[1,]  99  99
[2,]  93  93
[3,]  36  36
[4,]  74  74
[5,]  11  11
[6,]   3   3
[7,]  21  21
>

[...]

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717



From cberry at tajo.ucsd.edu  Mon Dec 11 05:04:40 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Sun, 10 Dec 2006 20:04:40 -0800
Subject: [R] sample "n" random positions from a matrix
In-Reply-To: <Pine.LNX.4.64.0612101955090.3078@tajo.ucsd.edu>
References: <687436.75963.qm@web56612.mail.re3.yahoo.com>
	<Pine.LNX.4.64.0612101955090.3078@tajo.ucsd.edu>
Message-ID: <Pine.LNX.4.64.0612102003350.3078@tajo.ucsd.edu>

On Sun, 10 Dec 2006, Charles C. Berry wrote:

> On Sun, 10 Dec 2006, Milton Cezar Ribeiro wrote:
>
>>  Hi there,
>>
>>   I have a binary matrix (dim 100x100) filled with values 0 and 1. I need
>>   select a record "n" positions of that matrix when values are 1. How can
>>   I do that?
>> 
>
> Is this what you want?
>
>>  mat.100 <- diag(100) # just for instance
>>  n <- 7  # supposing you want 7
>>  which( mat.100==1, arr.ind=T )[ sample( 100, n ), ]
>     row col
> [1,]  99  99
> [2,]  93  93
> [3,]  36  36
> [4,]  74  74
> [5,]  11  11
> [6,]   3   3
> [7,]  21  21

OOPS! That only works when there is exactly one one in each row. This is 
what is needed generally:

> index.of.ones <- which(mat.100==1,arr.ind=T)
> index.of.ones[ sample( nrow( index.of.ones ), n ), ]
      row col
[1,]  82  82
[2,]  36  36
[3,]  54  54
[4,]  89  89
[5,]  88  88
[6,]  52  52
[7,]  65  65
>


>> 
>
> [...]
>
> Charles C. Berry                        (858) 534-2098
>                                         Dept of Family/Preventive Medicine
> E mailto:cberry at tajo.ucsd.edu	         UC San Diego
> http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717
>
>
>
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717



From ajackson at oplnk.net  Mon Dec 11 05:12:18 2006
From: ajackson at oplnk.net (Alan Jackson)
Date: Sun, 10 Dec 2006 22:12:18 -0600
Subject: [R] Small Rcmdr issue
Message-ID: <20061210221218.7e255856.ajackson@oplnk.net>

Just installed Rcmdr on a Linux box.

When I exit from both Rcmdr and R together from the regular Rcmdr exit menu,
it leaves my xterm with "stty -echo", so that nothing that is typed appears.
If I exit only Rcmdr, and then exit R normally, everything is okay (stty echo).

Other than that minor irritant, everything seems to work just fine.

Linux 2.6.16-gentoo-r3
Athlon 64 X2 3800+
R version 2.4.0 (2006-10-03)
Rcmdr Version 1.2-5


-- 
-----------------------------------------------------------------------
| Alan K. Jackson            | To see a World in a Grain of Sand      |
| alan at ajackson.org          | And a Heaven in a Wild Flower,         |
| www.ajackson.org           | Hold Infinity in the palm of your hand |
| Houston, Texas             | And Eternity in an hour. - Blake       |



From ajackson at oplnk.net  Mon Dec 11 05:19:10 2006
From: ajackson at oplnk.net (Alan Jackson)
Date: Sun, 10 Dec 2006 22:19:10 -0600
Subject: [R] Small Rcmdr issue
Message-ID: <20061210221910.de7dcb83.ajackson@oplnk.net>

Just installed Rcmdr on a Linux box.

When I exit from both Rcmdr and R together from the regular Rcmdr exit menu,
it leaves my xterm with "stty -echo", so that nothing that is typed appears.
If I exit only Rcmdr, and then exit R normally, everything is okay (stty echo).

Other than that minor irritant, everything seems to work just fine.

Linux 2.6.16-gentoo-r3
Athlon 64 X2 3800+
R version 2.4.0 (2006-10-03)
Rcmdr Version 1.2-5


-- 
-----------------------------------------------------------------------
| Alan K. Jackson            | To see a World in a Grain of Sand      |
| alan at ajackson.org          | And a Heaven in a Wild Flower,         |
| www.ajackson.org           | Hold Infinity in the palm of your hand |
| Houston, Texas             | And Eternity in an hour. - Blake       |



From Rhelp at ajackson.org  Mon Dec 11 05:20:53 2006
From: Rhelp at ajackson.org (Alan Jackson)
Date: Sun, 10 Dec 2006 22:20:53 -0600
Subject: [R] Small Rcmdr issue
Message-ID: <20061210222053.58adbdbf.Rhelp@ajackson.org>

Just installed Rcmdr on a Linux box.

When I exit from both Rcmdr and R together from the regular Rcmdr exit menu,
it leaves my xterm with "stty -echo", so that nothing that is typed appears.
If I exit only Rcmdr, and then exit R normally, everything is okay (stty echo).

Other than that minor irritant, everything seems to work just fine.

Linux 2.6.16-gentoo-r3
Athlon 64 X2 3800+
R version 2.4.0 (2006-10-03)
Rcmdr Version 1.2-5

-- 
-----------------------------------------------------------------------
| Alan K. Jackson            | To see a World in a Grain of Sand      |
| alan at ajackson.org          | And a Heaven in a Wild Flower,         |
| www.ajackson.org           | Hold Infinity in the palm of your hand |
| Houston, Texas             | And Eternity in an hour. - Blake       |



From macq at llnl.gov  Mon Dec 11 05:34:16 2006
From: macq at llnl.gov (Don MacQueen)
Date: Sun, 10 Dec 2006 20:34:16 -0800
Subject: [R] how to create data.frame with dynamic count of values
In-Reply-To: <4579D5AF.5050907@web.de>
References: <4579D5AF.5050907@web.de>
Message-ID: <p06210202c1a28f247290@[192.168.11.9]>

Perhaps you didn't want a dataframe with columns N1 to N15 in it.

Perhaps the assign() function is what you are looking for. Something 
similar to:

nams <- paste('N',1:15,sep='')
for (nm in nams) assign(nm,rep(0,VarSize))

-Don

At 10:14 PM +0100 12/8/06, Knut Krueger wrote:
>Hello R-Group
>
>I found how to fill the data.frame ->
>http://finzi.psych.upenn.edu/R/Rhelp02a/archive/70843.html
>
>N1 <- rnorm(4)
>N2 <- rnorm(4)
>N3 <- rnorm(4)
>N4 <- rnorm(4)
>X1 <- LETTERS[1:4]
>###################
>nams <- c(paste("N", 1:4, sep = ""), "X1")
>dat <- data.frame(lapply(nams, get))
>names(dat) <- nams
>dat
>
>
>But I need also to create a dynamic count of numeric vectors
>items = 15
>VarSize <-10
>
>N1 <- rep(0,VarSize)
>N2 <- rep(0,VarSize)
>N3 <- rep(0,VarSize)
>N4 <- rep(0,VarSize)
>N5 <- rep(0,VarSize)
>...
>N15<- rep(0,VarSize)  # 15 items
>
>
>Thank you in advance
>Knut
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


-- 
---------------------------------
Don MacQueen
Lawrence Livermore National Laboratory
Livermore, CA, USA



From cincinattikid at bigpond.com  Sun Dec 10 13:06:53 2006
From: cincinattikid at bigpond.com (Alfonso Sammassimo)
Date: Sun, 10 Dec 2006 23:06:53 +1100
Subject: [R] using zoo for daily stock prices
Message-ID: <003601c71c53$ae4c7ca0$0300a8c0@Vaio>

Hi all,

Please forgive this newbie posting to the list for the first time if I 
haven't followed proper procedure. I have read through many of the archives 
and find them most useful in learning R.

I have ten years daily data (stock closing prices) which I read in zoo 
format. I am having problems coding R to run a count of how many days in 
each month have a price higher than the first day of that month. I then wish 
to compare counts for all months. Along these lines, is there a simple way 
to index to certain dates(eg first of month, last of month, any specific 
date in one month) and keep looping over each month using such a reference 
point, and then assessing the results for each month?

Any guidance would be sincerely appreciated,

Alfonso Sammassimo
Melbourne, Australia.



From perpdgo at colpos.mx  Mon Dec 11 01:24:06 2006
From: perpdgo at colpos.mx (Paulino Perez Rodriguez)
Date: Sun, 10 Dec 2006 18:24:06 -0600
Subject: [R] solving non linear system of eq
Message-ID: <web-8574660@mailadmin.colpos.mx>


Hello all R users:

How can I solve a non linear system of equations using R?

-- 
Este mensaje ha sido analizado por MailScanner
en busca de virus y otros contenidos peligrosos,
y se considera que est? limpio.



From gustaf.rydevik at gmail.com  Mon Dec 11 08:35:51 2006
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Mon, 11 Dec 2006 10:35:51 +0300
Subject: [R] filled.contour and NA's
In-Reply-To: <4579B75F.3060803@gmail.com>
References: <456DE30F.7090002@gmail.com>
	<45f568c70612080059k38506424hb294ab029fc0ad59@mail.gmail.com>
	<4579B75F.3060803@gmail.com>
Message-ID: <45f568c70612102335h4ea45f41y6e22290be19b4bf6@mail.gmail.com>

On 12/8/06, antonio rodriguez <antonio.raju at gmail.com> wrote:
> Hi Gustaf
>
> > I'm having the same issue myself. What I've ended up doing is
> > replacing NA's with a big negative value, define "levels" as one color
> > for negative values, and a regular scale above.
>
> How to define 'levels' as one color for negative values and a regular
> scale above? I don't know how the syntax within the filled.contour
> function shoul be.
>
> BR
>
> Antonio
>

Hi Antonio,

I just meant something like

filled.contours(x,y,x,levels=c(-1,seq(0,1,0.1)),color.palette=heat.colors)

This will give a fairly sharp delination for non-valid data, but still
using the same palette. If you want a totally distinct color, I
suppose you have to define your own palette  (And I don't know how to
do that)

/Gustaf

-- 
email:gustaf.rydevik at gmail.com
tel: +46(0)703051451
address: Kantorsgatan 50:190 75424 Uppsala Sweden



From RKrug at sun.ac.za  Mon Dec 11 09:11:01 2006
From: RKrug at sun.ac.za (Rainer M Krug)
Date: Mon, 11 Dec 2006 10:11:01 +0200
Subject: [R] two ggplot and colour=x question
Message-ID: <457D1295.9050103@sun.ac.za>

Hi

I am using ggplot with the aesthetic=list(..., colour=x, ...)

ggplot()
ggline()

I have four different values in x ("ren", "cyn", "mixed", "bare") and I 
have two questions

1) I would like to assign specific colours to the values, i.e. green, 
red, blue and brown. How can I do this? I did not understand 
map_colour_brewer.

2) I don't want the legend top be plot. How can I disable the legend to 
be plotted?

Thanks

Rainer

-- 
Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology and Entomology
University of Stellenbosch
Matieland 7602
South Africa

Tel:		+27 - (0)72 808 2975 (w)
Fax:		+27 - (0)86 516 2782
Fax:		+27 - (0)21 808 3304 (w)
Cell:		+27 - (0)83 9479 042

email:	RKrug at sun.ac.za
       	Rainer at krugs.de



From jim at bitwrit.com.au  Mon Dec 11 09:23:37 2006
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 11 Dec 2006 19:23:37 +1100
Subject: [R] cohen kappa for two-way table
In-Reply-To: <3c5546140612101600o3dc649f0v97eebd9a7a101838@mail.gmail.com>
References: <3c5546140612101600o3dc649f0v97eebd9a7a101838@mail.gmail.com>
Message-ID: <457D1589.5060005@bitwrit.com.au>

Dylan Beaudette wrote:
> Greetings,
> 
> I am a bit confused by the results returned by the functions:
> cohen.kappa {concord}
> classAgreement {e1071}
> 
> when using a two-way table.
> 
> 
> for example, if I have an matrix A, and a similar matrix B (same
> dimensions), then:
> 
> matrix A and B can be found:
> http://casoilresource.lawr.ucdavis.edu/drupal/files/a_40.txt
> http://casoilresource.lawr.ucdavis.edu/drupal/files/b_40.txt
> 
> A <- matrix(unlist( read.table('a_40.txt'), use.names=FALSE), ncol=14)
> B <- matrix(unlist( read.table('b_40.txt'), use.names=FALSE), ncol=14)
> 
If I interpret this correctly, you are considering the numbers in A and 
B to be nominal variables representing levels of some data attribute.
What cohen.kappa wants is:

1(type=counts) a matrix of counts where each cell represents the number 
of methods (rows are different methods) that classified the data objects 
into levels (columns are different levels).
2(type=scores) a matrix of scores where each cell represents the level 
assigned by a method (rows again) to a data object (columns are data 
objects here).

If your numbers are counts, you can get a sensible kappa for _each_ matrix.
If your numbers are scores, you can get a sensible kappa by specifying 
type=scores for _each_ matrix
As far as I can see, you are computing a sparsely populated table of the 
two matrices and passing that, and I don't see how that can give a 
meaningful result. I suspect that the numbers might be counts in the 
first place, but they are being used as scores.

> Secondly, when using the classAgreements() function I get different numbers:
> 
I'll let someone who knows more about the classAgreement function deal 
with this.

Jim



From kbenoit at tcd.ie  Mon Dec 11 09:37:34 2006
From: kbenoit at tcd.ie (Kenneth Benoit)
Date: Mon, 11 Dec 2006 08:37:34 +0000
Subject: [R] R2WinBUGS and calling WinBUGS in Crossover MAC BETA
In-Reply-To: <loom.20061210T221719-542@post.gmane.org>
References: <457C5E69.1030404@tcd.ie> <loom.20061210T221719-542@post.gmane.org>
Message-ID: <457D18CE.3040904@tcd.ie>

Ben Bolker wrote:
> Kenneth Benoit <kbenoit <at> tcd.ie> writes:
> 
>> Hi there - I have a question for any of you who use R2WinBUGS to call 
>> WinBUGS using the useWINE option in that package.
>>
>> I have Codeweaver's Crossover emulator installed on my Intel Mac with 
>> WinBUGS working fine if I start it from Crossover.  But there is 
>> supposed to be a way to start it directly from a command line, which I 
>> could pass to the R2WinBUGS using the bugs(..., useWINE="something") 
>> argument.
>>
>> Has anyone tried this yet?  Thanks!
>>
> 
>    useWINE=TRUE.  You may have to set some environment
> variables (e.g. WINE is the path to your WINE executable).
> It's supposed to just work out of the box.  I have some
> fixes that I've been meaning to upload to complement
> the existing stuff, but haven't.  If you run into
> trouble drop me a line.
> 
>  Ben Bolker

Many thanks for that quick reply.  I have tried useWINE=TRUE but this 
does not work on the Mac.  I am using CrossOver for Mac Beta (6.0.0b2). 
  When I call:

bugs(..., useWINE=TRUE, newWINE=TRUE)

then I get this message:
Error in if (!nchar(WINEPATH)) { : argument is of length zero

I think the problem is that the command line call for cxoffice (similar 
to "wine") is different on the Mac from the Linux version.  For instance 
I have the following application bundles:

/Applications/CrossOver.app/
~/Applications/CrossOver/WinBUGS14.app

but I cannot figure out how to start WinBUGS14.app from the command 
line.  If I did then I could supply this command to bugs(..., WINE="").

Best,

Ken



From Knut-krueger at einthal.de  Mon Dec 11 09:51:03 2006
From: Knut-krueger at einthal.de (Knut Krueger)
Date: Mon, 11 Dec 2006 09:51:03 +0100
Subject: [R] Switch and integer
Message-ID: <457D1BF7.7040306@einthal.de>

I searched the help list and the manual, but I do not find my mistake.
Switch is working with character , with integer, but not in the third 
example

Regards Knut


count1 <- 0
test 
=c("3","9","3","9","3","9","8","9","8","9","8","9","3","9","3","9","5","9","3","9","1","2","7","9","3","9","1","1","2","2","3","9","2","1","2","5","9","8","9","1","2")
count1 <- "0"
for (i in 1:length(test))
  switch (EXPR=test[i],
      "5" =     print(test[i]),
      "6" =     print(test[i]),
      "7" =     print(test[i]),
      "8" =     print(test[i]),
      "9" =     print(test[i])
      )
  count1
#         example from helpfile
for(i in c(-1:3,9))  print(switch(i, 1,2,3,4))

# -------- not working
test 
=c(3,9,3,9,3,9,8,9,8,9,8,9,3,9,3,9,5,9,3,9,1,2,7,9,3,9,1,1,2,2,3,9,2,1,2,5,9,8,9,1,2)
count1 <- 0
for (i in 1:length(test))
  switch (EXPR=test[i],
      4 =     count1 <- count1 +1,
      5 =     count1 <- count1 +1,
      6 =     count1 <- count1 +1,
      7 =     count1 <- count1 +1,
      8 =     count1 <- count1 +1
      )
  count1



From webmaster at xen.net  Mon Dec 11 10:02:10 2006
From: webmaster at xen.net (Ricardo =?ISO-8859-1?Q?Rodr=EDguez=20-=20Your=20XEN=20ICT=20Team?=)
Date: Mon, 11 Dec 2006 10:02:10 +0100
Subject: [R] barplot - how to force vertical axis to cover entire
	plot	area
References: 5ee8a48fa828d4b2d820c286459e5795
Message-ID: <20061211T100210Z_C5AC00020000@xen.net>

Hi, Etienne,
 
I've seen this while working with barplot and never been able to understand the general rule, but by setting ylim high enough, I've always been able to draw a y axis covering the biggest values.
 
Could you send a data subset to reproduce the issue? Thanks.
 
Best,
 
Ricardo
 
--
Ricardo Rodr?guez
Your XEN ICT Team

>>> Etienne<etiennesky at yahoo.com> 7/12/2006 01:43 >>>

I'm using barplot with the following call:
  
barplot(stat_data[[5]][,],axes=TRUE,axisnames=TRUE,axis.lty=1,xlab=xlab,ylab=ylab,beside=TRUE,las=1,font.lab=2,font.axis=1,legend.text=TRUE)

On some data, the vertical axis does not cover the
whole plot area and the last tick mark is smaller than
the maximum value.

I tried setting the ylim values but even with that,
some plots are still not OK, it just shrinks the
length of the bars.

Attached is a png example of the problem.  I hope it
gets through.

Thanks,
Etienne



From mothsailor at googlemail.com  Mon Dec 11 10:42:28 2006
From: mothsailor at googlemail.com (David Barron)
Date: Mon, 11 Dec 2006 09:42:28 +0000
Subject: [R] Switch and integer
In-Reply-To: <457D1BF7.7040306@einthal.de>
References: <457D1BF7.7040306@einthal.de>
Message-ID: <815b70590612110142j2f305388h2b7934e22adca60e@mail.gmail.com>

>From the help entry for switch:

If the value of EXPR is an integer between 1 and nargs()-1 then the
corresponding element of ... is evaluated and the result returned.

So, for integers you don't give names to the elements in ...  This should work:

test=c(3,9,3,9,3,9,8,9,8,9,8,9,3,9,3,9,5,9,3,9,1,2,7,9,3,9,1,1,2,2,3,9,2,1,2,5,9,8,9,1,2)
count1 <- 0
for (i in 1:length(test))
 switch(EXPR=test[i],
     NULL,
     NULL,
     NULL,
     count1 <- count1 +1,
     count1 <- count1 +1,
     count1 <- count1 +1,
     count1 <- count1 +1,
     count1 <- count1 +1,
     NULL
     )
 count1


On 11/12/06, Knut Krueger <Knut-krueger at einthal.de> wrote:
> I searched the help list and the manual, but I do not find my mistake.
> Switch is working with character , with integer, but not in the third
> example
>
> Regards Knut
>
>
> count1 <- 0
> test
> =c("3","9","3","9","3","9","8","9","8","9","8","9","3","9","3","9","5","9","3","9","1","2","7","9","3","9","1","1","2","2","3","9","2","1","2","5","9","8","9","1","2")
> count1 <- "0"
> for (i in 1:length(test))
>   switch (EXPR=test[i],
>       "5" =     print(test[i]),
>       "6" =     print(test[i]),
>       "7" =     print(test[i]),
>       "8" =     print(test[i]),
>       "9" =     print(test[i])
>       )
>   count1
> #         example from helpfile
> for(i in c(-1:3,9))  print(switch(i, 1,2,3,4))
>
> # -------- not working
> test
> =c(3,9,3,9,3,9,8,9,8,9,8,9,3,9,3,9,5,9,3,9,1,2,7,9,3,9,1,1,2,2,3,9,2,1,2,5,9,8,9,1,2)
> count1 <- 0
> for (i in 1:length(test))
>   switch (EXPR=test[i],
>       4 =     count1 <- count1 +1,
>       5 =     count1 <- count1 +1,
>       6 =     count1 <- count1 +1,
>       7 =     count1 <- count1 +1,
>       8 =     count1 <- count1 +1
>       )
>   count1
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP



From ericr at mcs.st-and.ac.uk  Mon Dec 11 10:42:36 2006
From: ericr at mcs.st-and.ac.uk (Eric Rexstad)
Date: Mon, 11 Dec 2006 09:42:36 +0000
Subject: [R] Experimental Design with R
Message-ID: <457D280C.5010901@mcs.st-and.ac.uk>

Erin:

You may want to examine this PDF in the contributed documentation area 
of R-project:

http://cran.r-project.org/doc/contrib/Vikneswaran-ED_companion.pdf

-- 
Eric Rexstad
Research Unit for Wildlife Population Assessment
Centre for Research into Ecological and Environmental Modelling
University of St. Andrews
St. Andrews Scotland KY16 9LZ
+44 (0)1334 461833



From dieter.menne at menne-biomed.de  Mon Dec 11 10:47:01 2006
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Mon, 11 Dec 2006 09:47:01 +0000 (UTC)
Subject: [R] Switch and integer
References: <457D1BF7.7040306@einthal.de>
Message-ID: <loom.20061211T104126-79@post.gmane.org>

Knut Krueger <Knut-krueger <at> einthal.de> writes:

> 
> Switch is working with character , with integer, but not in the third 
> example
... 
> # -------- not working
test = c(3,9,3,9,3,9,8,9,8,9,8,9,3,9,3,9,5,9,3,9,1,2,7,9,3,9,1,1,
2,2,3,9,2,1,2,5, 9,8,9,1,2)
> count1 <- 0
> for (i in 1:length(test))
>   switch (EXPR=test[i],
>       4 =     count1 <- count1 +1,
>       5 =     count1 <- count1 +1,
>       6 =     count1 <- count1 +1,
>       7 =     count1 <- count1 +1,
>       8 =     count1 <- count1 +1
>       )
>   count1
> 

switch has a different behavior when an integer is use, which is a bit hidden 
in the term "corresponding". 

"If the value of EXPR is an integer between 1 and nargs()-1 then the
corresponding element of ... is evaluated and the result returned."

So something like the example below might come close to what you want. 
In each case you have to add the default last item to avoid a NULL.

"In the case of no match, if there's a further argument in switch that one 
is returned, otherwise NULL."

Dieter

test =c(4,5,8,1,13)
count1 <- 0
for (i in 1:length(test)) {
  count1 <- switch (EXPR=as.character(test[i]),
      "4" =     count1 +1,
      "5" =     count1 +1,
      "6" =     count1 +1,
      "7" =     count1 +1,
      "8" =     count1 +1,
      count1
      )
}
count1



From dieter.menne at menne-biomed.de  Mon Dec 11 10:49:52 2006
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Mon, 11 Dec 2006 09:49:52 +0000 (UTC)
Subject: [R] solving non linear system of eq
References: <web-8574660@mailadmin.colpos.mx>
Message-ID: <loom.20061211T104916-103@post.gmane.org>

Paulino Perez Rodriguez <perpdgo <at> colpos.mx> writes:

> How can I solve a non linear system of equations using R?

Have your tried to enter "nonlinear equations" into http://search.r-project.org?

Dieter



From Da.McPhee at Queens-Belfast.AC.UK  Mon Dec 11 12:24:00 2006
From: Da.McPhee at Queens-Belfast.AC.UK (Da.McPhee at Queens-Belfast.AC.UK)
Date: 11 Dec 2006 11:24:00 +0000
Subject: [R] FW: R
In-Reply-To: <01a901c7121f$8527e960$2386758f@AJWORKDELL>
References: <D0BF9C78D1C45C418541C852C8944FE20118F56C@qub-xchange-01.ads.qub.ac.uk>
	<Prayer.1.0.12.0611101617230.11386@localhost.localdomain>
	<01a901c7121f$8527e960$2386758f@AJWORKDELL>
Message-ID: <Prayer.1.0.12.0612111124001.29798@localhost.localdomain>

Hi Ricky / AJ

Progress of sorts. I got passed the last problem by looking at the makefiles
but run in to the next one, see below. 

It has created files in /contrib/R-2.4.0. there is an " R " under 
/contrib/R-2.4.0/bin/R.

Running it gives :-


/contrib/R-2.4.0/bin/R

R version 2.4.0 (2006-10-03)
Copyright (C) 2006 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.


 *** caught segfault ***
address 40b843f0, cause 'memory not mapped'

Traceback:
 1: .Call("La_dgesv", a, b, tol, PACKAGE = "base")
 2: solve.default(rgb)
 3: solve(rgb)
 4: drop(whitexyz %*% solve(rgb))
 5: make.rgb(red = c(0.625, 0.34), green = c(0.28, 0.595), blue = c(0.155, 
0.07), gamma = 1.8, white = "D65", name = "Apple RGB")
 6: eval(expr, envir, enclos)
 7: eval(i, envir)
 8: sys.source(codeFile, env, keep.source = keep.source)
 9: try(sys.source(codeFile, env, keep.source = keep.source)) 10: 
loadNamespace(package, c(which.lib.loc, lib.loc), keep.source = 
keep.source) 11: try({ ns <- loadNamespace(package, c(which.lib.loc, 
lib.loc), keep.source = keep.source) dataPath <- file.path(which.lib.loc, 
package, "data") env <- attachNamespace(ns, pos = pos, dataPath = 
dataPath)}) 12: library(package, lib.loc = lib.loc, character.only = TRUE, 
logical = TRUE, warn.conflicts = warn.conflicts, keep.source = keep.source, 
version = version) 13: require(pkg, quietly = TRUE, warn.conflicts = FALSE, 
character.only = TRUE, save = FALSE) 14: .First.sys()

Possible actions:
1: abort (with core dump)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection: 14
aborting ...
Segmentation fault (core dumped)

The make command fails with :-

make[4]: Leaving directory `/contrib/R-2.4.0/src/library/grDevices/src'

 *** caught segfault ***
address 4084b2f0, cause 'memory not mapped'

Traceback:
 1: .Call("La_dgesv", a, b, tol, PACKAGE = "base")
 2: solve.default(rgb)
 3: solve(rgb)
 4: drop(whitexyz %*% solve(rgb))
 5: make.rgb(red = c(0.625, 0.34), green = c(0.28, 0.595), blue = c(0.155, 
0.07), gamma = 1.8, white = "D65", name = "Apple RGB")
 6: eval(expr, envir, enclos)
 7: eval(i, envir)
 8: sys.source(codeFile, env, keep.source = keep.source)
 9: try(sys.source(codeFile, env, keep.source = keep.source)) 10: 
loadNamespace(package, lib.loc, keep.source, TRUE, TRUE) 11: 
code2LazyLoadDB(package, lib.loc = lib.loc, keep.source = keep.source, 
compress = compress) 12: tools:::makeLazyLoading("grDevices") aborting ... 
/bin/sh: 18508 Memory fault(coredump) make[3]: *** [all] Error 139 make[3]: 
Leaving directory `/contrib/R-2.4.0/src/library/grDevices' make[2]: *** [R] 
Error 1 make[2]: Leaving directory `/contrib/R-2.4.0/src/library' make[1]: 
*** [R] Error 1 make[1]: Leaving directory `/contrib/R-2.4.0/src' make: *** 
[R] Error 1

Do not hold out much hope from mailing list, as they did not answer my last
email, but have included it anyway.

Cheers

Derek


================================

Derek McPhee
Information Services
Queen's University Belfast
e-mail da.mcphee at qub.ac.uk
Tel 028 90973840
Fax 028 90975066



From andreas.plank at web.de  Mon Dec 11 12:37:31 2006
From: andreas.plank at web.de (Andreas Plank)
Date: Mon, 11 Dec 2006 12:37:31 +0100
Subject: [R] Weighted averaging partial least squares regression
Message-ID: <1165837051.6063.45.camel@chironomus.local>

Hello, 

is it possible in R to calculate a Weighted averaging partial least
squares regression? I'm not firm in statistics and didn't found anything
about weighted averaging in combination with PLS in the help archives.
Or is it possible to develop a workaround with the pls-package?

thanks for help in advance
Andreas Plank


-- 
_____________________________________________
Dipl. Biol. Andreas Plank 
FU Berlin 
Institute of Geological Science
Department Palaeontology
Malteserstr. 74-100, House D 
12249 Berlin 
Germany 
phone.: +49(0)30-83870-271
fax.:   +49(0)30-83870-745
http://userpage.fu-berlin.de/~jevers/plank_a.htm



From p.dalgaard at biostat.ku.dk  Mon Dec 11 13:09:08 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 11 Dec 2006 13:09:08 +0100
Subject: [R] FW: R
In-Reply-To: <Prayer.1.0.12.0612111124001.29798@localhost.localdomain>
References: <D0BF9C78D1C45C418541C852C8944FE20118F56C@qub-xchange-01.ads.qub.ac.uk>	<Prayer.1.0.12.0611101617230.11386@localhost.localdomain>	<01a901c7121f$8527e960$2386758f@AJWORKDELL>
	<Prayer.1.0.12.0612111124001.29798@localhost.localdomain>
Message-ID: <457D4A64.8020806@biostat.ku.dk>

Da.McPhee at Queens-Belfast.AC.UK wrote:
> Hi Ricky / AJ
>
> Progress of sorts. I got passed the last problem by looking at the makefiles
> but run in to the next one, see below. 
>
> It has created files in /contrib/R-2.4.0. there is an " R " under 
> /contrib/R-2.4.0/bin/R.
>
> Running it gives :-
>
>
> /contrib/R-2.4.0/bin/R
>
> R version 2.4.0 (2006-10-03)
> Copyright (C) 2006 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
>
>  *** caught segfault ***
> address 40b843f0, cause 'memory not mapped'
>
> Traceback:
>  1: .Call("La_dgesv", a, b, tol, PACKAGE = "base")
>  2: solve.default(rgb)
>  3: solve(rgb)
>  4: drop(whitexyz %*% solve(rgb))
>  5: make.rgb(red = c(0.625, 0.34), green = c(0.28, 0.595), blue = c(0.155, 
> 0.07), gamma = 1.8, white = "D65", name = "Apple RGB")
>  6: eval(expr, envir, enclos)
>  7: eval(i, envir)
>  8: sys.source(codeFile, env, keep.source = keep.source)
>  9: try(sys.source(codeFile, env, keep.source = keep.source)) 10: 
> loadNamespace(package, c(which.lib.loc, lib.loc), keep.source = 
> keep.source) 11: try({ ns <- loadNamespace(package, c(which.lib.loc, 
> lib.loc), keep.source = keep.source) dataPath <- file.path(which.lib.loc, 
> package, "data") env <- attachNamespace(ns, pos = pos, dataPath = 
> dataPath)}) 12: library(package, lib.loc = lib.loc, character.only = TRUE, 
> logical = TRUE, warn.conflicts = warn.conflicts, keep.source = keep.source, 
> version = version) 13: require(pkg, quietly = TRUE, warn.conflicts = FALSE, 
> character.only = TRUE, save = FALSE) 14: .First.sys()
>
> Possible actions:
> 1: abort (with core dump)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection: 14
> aborting ...
> Segmentation fault (core dumped)
>
> The make command fails with :-
>
> make[4]: Leaving directory `/contrib/R-2.4.0/src/library/grDevices/src'
>
>  *** caught segfault ***
> address 4084b2f0, cause 'memory not mapped'
>
> Traceback:
>  1: .Call("La_dgesv", a, b, tol, PACKAGE = "base")
>  2: solve.default(rgb)
>  3: solve(rgb)
>  4: drop(whitexyz %*% solve(rgb))
>  5: make.rgb(red = c(0.625, 0.34), green = c(0.28, 0.595), blue = c(0.155, 
> 0.07), gamma = 1.8, white = "D65", name = "Apple RGB")
>  6: eval(expr, envir, enclos)
>  7: eval(i, envir)
>  8: sys.source(codeFile, env, keep.source = keep.source)
>  9: try(sys.source(codeFile, env, keep.source = keep.source)) 10: 
> loadNamespace(package, lib.loc, keep.source, TRUE, TRUE) 11: 
> code2LazyLoadDB(package, lib.loc = lib.loc, keep.source = keep.source, 
> compress = compress) 12: tools:::makeLazyLoading("grDevices") aborting ... 
> /bin/sh: 18508 Memory fault(coredump) make[3]: *** [all] Error 139 make[3]: 
> Leaving directory `/contrib/R-2.4.0/src/library/grDevices' make[2]: *** [R] 
> Error 1 make[2]: Leaving directory `/contrib/R-2.4.0/src/library' make[1]: 
> *** [R] Error 1 make[1]: Leaving directory `/contrib/R-2.4.0/src' make: *** 
> [R] Error 1
>
> Do not hold out much hope from mailing list, as they did not answer my last
> email, but have included it anyway.
>
>   
"They" might not have had enough information to go on (and r-devel had 
been a better target). Things like OS and computer versions. (I can't 
seem to find the earlier report though).

Looks like you have broken lapack libraries, so you may want to upgrade 
them or override the selection made during the configure phase.

Make sure to read
http://cran.r-project.org/doc/manuals/R-admin.html
and in particular Appendix A3 which discusses some of these issues.

> Cheers
>
> Derek
>
>
> ================================
>
> Derek McPhee
> Information Services
> Queen's University Belfast
> e-mail da.mcphee at qub.ac.uk
> Tel 028 90973840
> Fax 028 90975066
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From square_id at yahoo.com  Mon Dec 11 13:31:20 2006
From: square_id at yahoo.com (Dedy Angsana)
Date: Mon, 11 Dec 2006 04:31:20 -0800 (PST)
Subject: [R] (no subject)
Message-ID: <20061211123120.82834.qmail@web30205.mail.mud.yahoo.com>

 
 


 
____________________________________________________________________________________
Want to start your own business?



From Knut-krueger at einthal.de  Mon Dec 11 13:33:59 2006
From: Knut-krueger at einthal.de (Knut Krueger)
Date: Mon, 11 Dec 2006 13:33:59 +0100
Subject: [R] Switch and integer
In-Reply-To: <815b70590612110142j2f305388h2b7934e22adca60e@mail.gmail.com>
References: <457D1BF7.7040306@einthal.de>
	<815b70590612110142j2f305388h2b7934e22adca60e@mail.gmail.com>
Message-ID: <457D5037.2020708@einthal.de>

David Barron schrieb:
>
> If the value of EXPR is an integer between 1 and nargs()-1 then the
> corresponding element of ... is evaluated and the result returned.
>
Thank you, I wondered about the
> integer between 1 and nargs()-1
and the example from the help file for(i in c(-1:3,9))  print(switch(i,
1,2,3,4))
No see I  that the 1,2,3,4 is the output not the value, but it's not
very clear for me ho it works.
I will try to find it out ...
The switch for Integer is very different from C++ or Pascal .. maybe
this was the reason for the problem.

Regards Knut



From square_id at yahoo.com  Mon Dec 11 13:34:40 2006
From: square_id at yahoo.com (Dedy Angsana)
Date: Mon, 11 Dec 2006 04:34:40 -0800 (PST)
Subject: [R] monte carlo simulation in R
Message-ID: <20061211123440.50143.qmail@web30210.mail.mud.yahoo.com>

i want to learn about monte carlo simulation in R,
also about variance reduction techniques in monte
carlo, especialy antithetic variates and control
variates. can you give me an example of the code? or
where i can find the journal or article or guide?

thx for the answers...



From jmb at mssl.ucl.ac.uk  Mon Dec 11 13:28:17 2006
From: jmb at mssl.ucl.ac.uk (Jenny Barnes)
Date: Mon, 11 Dec 2006 12:28:17 +0000 (GMT)
Subject: [R] upside down image/data
Message-ID: <200612111228.kBBCSHrj013960@msslhb.mssl.ucl.ac.uk>

Dear R-community,

I am looking for some simple advice - I have a matrix (therefore 2 dimensional) 
of global temperature. 

Having read R-help I think that when I ask R to image() or levelplot() my matrix 
will it actually appear upside down - I think I therefore need to use the line:
> levelplot(temperature.matrix[,ncol(output.temp):1], ........)
to get it looking like it was on the globe due to the matrix rows increasing in 
number down the matrix in its dimensions on longitude and latitude but the 
y-axis coordinates increase up the axis.

Can anyone simply tell me whether this is correct as I find it very hard to know 
which way up my data should be and I cannot tell which is correct simply by 
looking at it!

Many thanks for your time in reading this problem,

Jenny Barnes

~~~~~~~~~~~~~~~~~~~~~~~~~~
Jennifer Barnes
PhD student - long range drought prediction
Climate Extremes
Department of Space and Climate Physics
University College London
Holmbury St Mary, Dorking
Surrey
RH5 6NT
01483 204149
07916 139187
Web: http://climate.mssl.ucl.ac.uk



From jfox at mcmaster.ca  Mon Dec 11 14:21:16 2006
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 11 Dec 2006 08:21:16 -0500
Subject: [R] Small Rcmdr issue
In-Reply-To: <20061210222053.58adbdbf.Rhelp@ajackson.org>
Message-ID: <20061211132116.OCZW24907.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Alan,

I've noticed that problem too, and have no idea why it happens. The function
that's executed when you select "Exit -> From Commander and R" is pretty
simple:

closeCommanderAndR <- function(){
    response <- closeCommander()
    if (response == "cancel") return()
    cat("\n")
    quit(save="no")
    }

If anyone knows how I can fix the problem, I'd be happy to so do.

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Alan Jackson
> Sent: Sunday, December 10, 2006 11:21 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Small Rcmdr issue
> 
> Just installed Rcmdr on a Linux box.
> 
> When I exit from both Rcmdr and R together from the regular 
> Rcmdr exit menu, it leaves my xterm with "stty -echo", so 
> that nothing that is typed appears.
> If I exit only Rcmdr, and then exit R normally, everything is 
> okay (stty echo).
> 
> Other than that minor irritant, everything seems to work just fine.
> 
> Linux 2.6.16-gentoo-r3
> Athlon 64 X2 3800+
> R version 2.4.0 (2006-10-03)
> Rcmdr Version 1.2-5
> 
> --
> --------------------------------------------------------------
> ---------
> | Alan K. Jackson            | To see a World in a Grain of 
> Sand      |
> | alan at ajackson.org          | And a Heaven in a Wild Flower, 
>         |
> | www.ajackson.org           | Hold Infinity in the palm of 
> your hand |
> | Houston, Texas             | And Eternity in an hour. - 
> Blake       |
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From p.dalgaard at biostat.ku.dk  Mon Dec 11 14:49:44 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 11 Dec 2006 14:49:44 +0100
Subject: [R] Small Rcmdr issue
In-Reply-To: <20061211132116.OCZW24907.tomts20-srv.bellnexxia.net@JohnDesktop8300>
References: <20061211132116.OCZW24907.tomts20-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <457D61F8.3080907@biostat.ku.dk>

John Fox wrote:
> Dear Alan,
>
> I've noticed that problem too, and have no idea why it happens. The function
> that's executed when you select "Exit -> From Commander and R" is pretty
> simple:
>
> closeCommanderAndR <- function(){
>     response <- closeCommander()
>     if (response == "cancel") return()
>     cat("\n")
>     quit(save="no")
>     }
>
> If anyone knows how I can fix the problem, I'd be happy to so do.
>   
I think I've seen this outside Rcmdr too, possibly with "R-g tk" but I 
can't seem to reproduce it now.
I don't think it's your problem, but if you get a handle on where the 
issue lies, please let us know. (Of course, you can always just reset 
the terminal or blind-type "stty sane", but it would be nicer to get rid 
of the issue altogether).

     -p

> Regards,
>  John
>
> --------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox 
> -------------------------------- 
>
>   
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch 
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Alan Jackson
>> Sent: Sunday, December 10, 2006 11:21 PM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] Small Rcmdr issue
>>
>> Just installed Rcmdr on a Linux box.
>>
>> When I exit from both Rcmdr and R together from the regular 
>> Rcmdr exit menu, it leaves my xterm with "stty -echo", so 
>> that nothing that is typed appears.
>> If I exit only Rcmdr, and then exit R normally, everything is 
>> okay (stty echo).
>>
>> Other than that minor irritant, everything seems to work just fine.
>>
>> Linux 2.6.16-gentoo-r3
>> Athlon 64 X2 3800+
>> R version 2.4.0 (2006-10-03)
>> Rcmdr Version 1.2-5
>>



From milton_ruser at yahoo.com.br  Mon Dec 11 15:07:30 2006
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Mon, 11 Dec 2006 14:07:30 +0000 (GMT)
Subject: [R] organizing stats from a list of models
Message-ID: <537238.65913.qm@web56609.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061211/aa49ca89/attachment-0005.pl 

From b.jacobs at pandora.be  Mon Dec 11 15:27:19 2006
From: b.jacobs at pandora.be (Bert Jacobs)
Date: Mon, 11 Dec 2006 15:27:19 +0100
Subject: [R] Getting DataFrame Name from Text String
In-Reply-To: AAAAAOXvfE/tUWVMujI1J0cWacvEqCUA
Message-ID: <20061211142719.9900D2300F2@adicia.telenet-ops.be>

Hi,

I have the following simple function

Testfunc = function(x)
{
Test = subset(x, var1 <= 1000)
}

Suppose I have a dataframe ?dat1? then the command Testfunc(dat1) gives a
correct result.

The problem is that the name of dataframe to be used in the function can be
found in a vector (Dfname). The value of the vector can change in eg.

Dfname = ??dat1??
Or
Dfname = ? dat2 ?
Or
...

How can I pass this string into the function so that the correct database is
used. Thx for helping me out.

Bert



From h.wickham at gmail.com  Mon Dec 11 15:29:45 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 11 Dec 2006 08:29:45 -0600
Subject: [R] two ggplot and colour=x question
In-Reply-To: <457D1295.9050103@sun.ac.za>
References: <457D1295.9050103@sun.ac.za>
Message-ID: <f8e6ff050612110629t63f362d2r14f89978ddf6b2b5@mail.gmail.com>

> I am using ggplot with the aesthetic=list(..., colour=x, ...)
>
> ggplot()
> ggline()
>
> I have four different values in x ("ren", "cyn", "mixed", "bare") and I
> have two questions
>
> 1) I would like to assign specific colours to the values, i.e. green,
> red, blue and brown. How can I do this? I did not understand
> map_colour_brewer.

There's not really an easy way to do this at the moment.  However, you
can create a new variable containing the colours you want to use and
then use a manual scale so they aren't converted automatically:

df$colour <- c("red","blue","yellow","orange)[df$myvar]
p <- ggplot(data=df, aes=list(x=x,y=y,colour=colour)
scmanual(p, "colour")

> 2) I don't want the legend top be plot. How can I disable the legend to
> be plotted?

If you use a manual scale (as above) there won't be a legend, or more
generally you can do:

p$legend.position <- "none"
to turn of the legend (see ?ggopt for other options)

Hadley



From h.wickham at gmail.com  Mon Dec 11 15:37:46 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 11 Dec 2006 08:37:46 -0600
Subject: [R] filled.contour and NA's
In-Reply-To: <456DE30F.7090002@gmail.com>
References: <456DE30F.7090002@gmail.com>
Message-ID: <f8e6ff050612110637i21e7908bx6dffc99aaba09f3a@mail.gmail.com>

> I'm trying to do a filled.contour plot where some points are labelled as
> NA. How do I could plot this kind of graphics, so NA points are coloured
> black,  keeping the levels of remaining points. NA's values represent
> land points (meaningless), and what I want to plot is the levels of a
> variable over the sea.

You can also do this using ggplot, although you don't have quite as
much control over the appearance of the contours (you do get more
control over other things)

install.packages("ggplot", dep=T)
library(ggplot)

# Set up appropriate data structure
dimnames(ene) <- list(y, x)
names(dimnames(ene)) <- c("y", "x")
enem <- melt(ene)

p <- ggplot(na.omit(enem), aes=list(x=x, y=y, z=value, fill=value))
p <- ggtile(p)
p <- ggcontour(p)
scfillgradient(p)
scfillgradient(p, low="white", high="blue")

Regards,

Hadley



From h.wickham at gmail.com  Mon Dec 11 15:41:58 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 11 Dec 2006 08:41:58 -0600
Subject: [R] organizing stats from a list of models
In-Reply-To: <537238.65913.qm@web56609.mail.re3.yahoo.com>
References: <537238.65913.qm@web56609.mail.re3.yahoo.com>
Message-ID: <f8e6ff050612110641l3dda44b7pdf92b8af24c5b5b0@mail.gmail.com>

>   I have a list of models (about 600 glm models) and I included the prefix "mod_" on their name. Now I would like retrieve the list from the R environment and save their AICs (and other info) on a table. I?m trying something like:

I have some (rather un)tested code:

findmodels <- function(modeltype = "lm", dataset, pattern) {
	ls <- ls(".GlobalEnv", pattern=pattern)
	mods <- ls[sapply(ls, function(x) inherits(get(x), modeltype))]
	if (!missing(dataset)) {
		data.name <- function(x) as.character(x$call[["data"]])
		mods <- mods[sapply(mods, function(x) data.name == dataset)]
	}
	
	models <- lapply(mods, get)
	class(models) <- c("ensemble", class(models))
	models
}

summary.ensemble <- function(object, ...) {
	fits <- data.frame(t(sapply(object, function(mod) {
		sum <- summary(mod)
		c(
			df = .df(mod),
			logL = logLik(mod),
			AIC = -AIC(mod),
			BIC = -AIC(mod, k=log(length(fitted(mod)))),
			R2 = sum$r.squared,
			adjR2 = sum$adj.r.squared
		)
	})))
	fits$model <- factor(names(object))
	rownames(fits) <- paste("m", fits$model, sep="")
	fits
}

Hopefully that should give you an idea on how to proceed.

Regards,

Hadley



From RKrug at sun.ac.za  Mon Dec 11 15:50:58 2006
From: RKrug at sun.ac.za (Rainer M Krug)
Date: Mon, 11 Dec 2006 16:50:58 +0200
Subject: [R] two ggplot and colour=x question
In-Reply-To: <f8e6ff050612110629t63f362d2r14f89978ddf6b2b5@mail.gmail.com>
References: <457D1295.9050103@sun.ac.za>
	<f8e6ff050612110629t63f362d2r14f89978ddf6b2b5@mail.gmail.com>
Message-ID: <457D7052.2030704@sun.ac.za>

Thanks a lot for your help - I'll try it out and let you know if I still 
have problems.

Rainer

hadley wickham wrote:
>> I am using ggplot with the aesthetic=list(..., colour=x, ...)
>>
>> ggplot()
>> ggline()
>>
>> I have four different values in x ("ren", "cyn", "mixed", "bare") and I
>> have two questions
>>
>> 1) I would like to assign specific colours to the values, i.e. green,
>> red, blue and brown. How can I do this? I did not understand
>> map_colour_brewer.
> 
> There's not really an easy way to do this at the moment.  However, you
> can create a new variable containing the colours you want to use and
> then use a manual scale so they aren't converted automatically:
> 
> df$colour <- c("red","blue","yellow","orange)[df$myvar]
> p <- ggplot(data=df, aes=list(x=x,y=y,colour=colour)
> scmanual(p, "colour")
> 
>> 2) I don't want the legend top be plot. How can I disable the legend to
>> be plotted?
> 
> If you use a manual scale (as above) there won't be a legend, or more
> generally you can do:
> 
> p$legend.position <- "none"
> to turn of the legend (see ?ggopt for other options)
> 
> Hadley


-- 
Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology and Entomology
University of Stellenbosch
Matieland 7602
South Africa

Tel:		+27 - (0)72 808 2975 (w)
Fax:		+27 - (0)86 516 2782
Fax:		+27 - (0)21 808 3304 (w)
Cell:		+27 - (0)83 9479 042

email:	RKrug at sun.ac.za
       	Rainer at krugs.de



From ucfagls at ucl.ac.uk  Mon Dec 11 15:47:23 2006
From: ucfagls at ucl.ac.uk (ucfagls at ucl.ac.uk)
Date: Mon, 11 Dec 2006 14:47:23 +0000
Subject: [R] Weighted averaging partial least squares regression
In-Reply-To: <1165837051.6063.45.camel@chironomus.local>
References: <1165837051.6063.45.camel@chironomus.local>
Message-ID: <20061211144723.0a6j3owhbko8wggc@www.webmail.ucl.ac.uk>

Quoting Andreas Plank <andreas.plank at web.de>:

> Hello,
>
> is it possible in R to calculate a Weighted averaging partial least
> squares regression? I'm not firm in statistics and didn't found anything
> about weighted averaging in combination with PLS in the help archives.
> Or is it possible to develop a workaround with the pls-package?

Nothing in R that is publicly available. It is certainly possible to 
modify the
pls package (I did so for package cocorresp, but that does something slightly
different to what you want).

Steve Juggins is writing an R package that includes WA-PLS, you might wish to
contact him to see if there is an early version available that you might use.
His University web pages are here:

http://www.campus.ncl.ac.uk/staff/Stephen.Juggins/

And you'll find his email address on them.

HTH

Gavin Simpson

>
> thanks for help in advance
> Andreas Plank
>
>
> --
> _____________________________________________
> Dipl. Biol. Andreas Plank
> FU Berlin
> Institute of Geological Science
> Department Palaeontology
> Malteserstr. 74-100, House D
> 12249 Berlin
> Germany
> phone.: +49(0)30-83870-271
> fax.:   +49(0)30-83870-745
> http://userpage.fu-berlin.de/~jevers/plank_a.htm
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From wl at eimb.ru  Mon Dec 11 15:49:52 2006
From: wl at eimb.ru (Vladimir Eremeev)
Date: Mon, 11 Dec 2006 14:49:52 +0000 (UTC)
Subject: [R] Getting DataFrame Name from Text String
References: <20061211142719.9900D2300F2@adicia.telenet-ops.be>
Message-ID: <loom.20061211T154906-958@post.gmane.org>

consider get or as.name



From spencer.graves at pdf.com  Mon Dec 11 16:03:47 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 11 Dec 2006 07:03:47 -0800
Subject: [R] DOE teaching suggestions?
In-Reply-To: <200612100151.kBA1pug5029578@gator.dt.uh.edu>
References: <200612100151.kBA1pug5029578@gator.dt.uh.edu>
Message-ID: <457D7353.8080102@pdf.com>

Hi, Erin:

	  Also, have you seen the "BHH2" package, companion to Box, Hunter and 
Hunter (2005) Statistics for Experimenters, 2nd ed. (Wiley)?

	  Hope this helps.
	  Spencer Graves
############################
      Are you planning to have them design and conduct an actual
physical experiment as part of the class?  You may know that Bill Hunter
(the second Hunter of Box, Hunter & Hunter) wrote articles about doing
this, and I found it extremely helpful.   Things happen with real
physical experiments that can't be duplicated with any kind of computer
simulation.

      I think I've gotten good results assigning team projects of their
own choosing.  I found it necessary to have "design review"
presentations in the middle of the class.  These presentations give you
feedback on their understanding of the class material to that date.
They also give you an opportunity to suggest improvements before they
actually do the experiment.

      This is not what you asked, but I hope you find it useful, anyway.
      Best Wishes,
      Spencer Graves

Erin Hodgess wrote:
> Dear R People:
>
> I will be teaching an undergraduate Design of Experiments class
> in the Spring Semester.  It will be very much an applied course.
>
> My question, please:  has anyone used R for a course like this, please?
>
> I've tried Rcmdr for a regression course and just plain command
> line for a time series course.
>
> Should I use Rcmdr, or teach them to use the command line, OR is there
> something else, please?
>
> Thanks in advance!
>
> Sincerely,
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgess at gator.uhd.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From michela.cameletti at unibg.it  Mon Dec 11 16:11:40 2006
From: michela.cameletti at unibg.it (Michela Cameletti)
Date: Mon, 11 Dec 2006 16:11:40 +0100 (CET)
Subject: [R] double boostrap with clusterApplyLB
Message-ID: <3563.193.204.253.13.1165849900.squirrel@mailserver.unibg.it>

Dear R-Users,
we are using a linux-cluster with RMPI and the snow package.
We would like to do a double boostrap.
We have a general function that implements the first boostrap (the outer) and
we are wondering if we can include another bootstrap (the inner) in the
same general function including another clusterApplyLB.

For example:

general function = function(...) {
      clusterApplyLB(cl, fun,...) }
where "fun" is the function for the inner boostrap

outer bootstrap = clusterApplyLB(cl,general function,...)

Does R accept this kind of expression?
Thank you very much in advance,
Michela and Marco



From E.Fucikova at nioo.knaw.nl  Mon Dec 11 17:04:03 2006
From: E.Fucikova at nioo.knaw.nl (Fucikova, Eva)
Date: Mon, 11 Dec 2006 17:04:03 +0100
Subject: [R] How to write a two-way interaction as a random effect in a lmer
	model?
Message-ID: <1276C0564833F043AB4C85ED8DA9CFE50117C36B@ctemail1.nioo.int>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061211/0f94f4b6/attachment-0005.pl 

From jamal115 at yahoo.com  Mon Dec 11 17:37:38 2006
From: jamal115 at yahoo.com (Syed M. Jamal)
Date: Mon, 11 Dec 2006 16:37:38 +0000 (GMT)
Subject: [R] Difference in outputs of random mixed effect models (lmer
	function)
Message-ID: <986983.43054.qm@web51304.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061211/9c075eb3/attachment-0005.pl 

From ethan.johnsons at gmail.com  Mon Dec 11 17:46:04 2006
From: ethan.johnsons at gmail.com (Ethan Johnsons)
Date: Mon, 11 Dec 2006 11:46:04 -0500
Subject: [R] similarity test with R
Message-ID: <5cd96f050612110846u44a0d22cpa282abc3997d7db0@mail.gmail.com>

>x=c(3.05176E-05,0.000457764,0.003204346,0.0138855,0.04165649,0.09164429,0.1527405,0.1963806,0.1963806,0.1527405,0.09164429,0.04165649,0.0138855,0.003204346,0.000457764,3.05176E-05)
>y=c(0.0000306,0.0004566,0.0031985,0.0139083,0.0415539,0.0917678,0.1528134,0.1962831,0.1962994,0.1527996,0.0917336,0.0415497,0.0139308,0.0031917,0.0004529,0.0000301)

I tried chisq.test, t-test, prop.test, etc, but the p-value is very
high, which is not 'statistically significant'.  With these data sets,
I want to compare the similarity, which it is very close to identical
if you plot them.    I am wondering if there is any test that can
verify the similarity of the two data sets.

thx much

ej



From ccleland at optonline.net  Mon Dec 11 17:53:49 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Mon, 11 Dec 2006 11:53:49 -0500
Subject: [R] similarity test with R
In-Reply-To: <5cd96f050612110846u44a0d22cpa282abc3997d7db0@mail.gmail.com>
References: <5cd96f050612110846u44a0d22cpa282abc3997d7db0@mail.gmail.com>
Message-ID: <457D8D1D.4080604@optonline.net>

Ethan Johnsons wrote:
>> x=c(3.05176E-05,0.000457764,0.003204346,0.0138855,0.04165649,0.09164429,0.1527405,0.1963806,0.1963806,0.1527405,0.09164429,0.04165649,0.0138855,0.003204346,0.000457764,3.05176E-05)
>> y=c(0.0000306,0.0004566,0.0031985,0.0139083,0.0415539,0.0917678,0.1528134,0.1962831,0.1962994,0.1527996,0.0917336,0.0415497,0.0139308,0.0031917,0.0004529,0.0000301)
> 
> I tried chisq.test, t-test, prop.test, etc, but the p-value is very
> high, which is not 'statistically significant'.  With these data sets,
> I want to compare the similarity, which it is very close to identical
> if you plot them.    I am wondering if there is any test that can
> verify the similarity of the two data sets.
> 
> thx much

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/82001.html

library(equivalence)

> ej
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894



From coforfe at gmail.com  Mon Dec 11 18:01:15 2006
From: coforfe at gmail.com (Carlos Ortega)
Date: Mon, 11 Dec 2006 18:01:15 +0100
Subject: [R] Getting DataFrame Name from Text String
In-Reply-To: <loom.20061211T154906-958@post.gmane.org>
References: <20061211142719.9900D2300F2@adicia.telenet-ops.be>
	<loom.20061211T154906-958@post.gmane.org>
Message-ID: <7b18cd4d0612110901t5d6f38cdla01702dcac895e38@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061211/e12538d9/attachment-0005.pl 

From bernarduse1 at yahoo.fr  Mon Dec 11 18:05:00 2006
From: bernarduse1 at yahoo.fr (Marc Bernard)
Date: Mon, 11 Dec 2006 18:05:00 +0100 (CET)
Subject: [R] lmer message
Message-ID: <79199.58622.qm@web23407.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061211/ba039a7a/attachment-0005.pl 

From spencer.graves at pdf.com  Mon Dec 11 18:11:08 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 11 Dec 2006 09:11:08 -0800
Subject: [R] DOE teaching suggestions?
In-Reply-To: <200612100151.kBA1pug5029578@gator.dt.uh.edu>
References: <200612100151.kBA1pug5029578@gator.dt.uh.edu>
Message-ID: <457D912C.9000301@pdf.com>

Hi, Erin:

	  Also, have you seen the "BsMD" package ("Bayes Screening and Model 
Discrimination"), also discussed in Box Hunger and Hunter (2005).

	  Spencer Graves
##################
	  Also, have you seen the "BHH2" package, companion to Box, Hunter and
Hunter (2005) Statistics for Experimenters, 2nd ed. (Wiley)?

	  Hope this helps.
	  Spencer Graves
############################
      Are you planning to have them design and conduct an actual
physical experiment as part of the class?  You may know that Bill Hunter
(the second Hunter of Box, Hunter & Hunter) wrote articles about doing
this, and I found it extremely helpful.   Things happen with real
physical experiments that can't be duplicated with any kind of computer
simulation.

      I think I've gotten good results assigning team projects of their
own choosing.  I found it necessary to have "design review"
presentations in the middle of the class.  These presentations give you
feedback on their understanding of the class material to that date.
They also give you an opportunity to suggest improvements before they
actually do the experiment.

      This is not what you asked, but I hope you find it useful, anyway.
      Best Wishes,
      Spencer Graves

Erin Hodgess wrote:
> Dear R People:
>
> I will be teaching an undergraduate Design of Experiments class
> in the Spring Semester.  It will be very much an applied course.
>
> My question, please:  has anyone used R for a course like this, please?
>
> I've tried Rcmdr for a regression course and just plain command
> line for a time series course.
>
> Should I use Rcmdr, or teach them to use the command line, OR is there
> something else, please?
>
> Thanks in advance!
>
> Sincerely,
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgess at gator.uhd.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From ibrahimmutlay at gmail.com  Mon Dec 11 18:38:23 2006
From: ibrahimmutlay at gmail.com (=?ISO-8859-9?Q?=DDbrahim_Mutlay?=)
Date: Mon, 11 Dec 2006 12:38:23 -0500
Subject: [R] Solution of Rcmdr Problem in Quantian OS, Thanks...
Message-ID: <eb21cbcd0612110938m169c2c3egb6fff8617747e4de@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061211/fd5acd71/attachment-0005.pl 

From mike.prager at noaa.gov  Mon Dec 11 19:03:34 2006
From: mike.prager at noaa.gov (Mike Prager)
Date: Mon, 11 Dec 2006 13:03:34 -0500
Subject: [R] R and LaTeX
References: <457B8F77.4070702@education.wisc.edu>
Message-ID: <rt6rn2dv1niiu9gr2v8runofq4nano7m8u@4ax.com>

David Kaplan <dkaplan at education.wisc.edu> wrote:

> Hi all,
> 
> I have started using LaTeX for writing papers and I have heard that R 
> works well with LaTeX.  I'm specifically interested in how I can have 
> LaTeX read in R generated graphics - for example graphs formed by 
> matplot, or other such  processes.  Does anyone out there use LaTeX and 
> can point me in the right direction?

> David

David--

The basic paradigm is to save the graph from R in encapsulated
Postscript format.  The procedure can vary slightly by the OS
you are using R under.  Under Windows, I usually generate the
graphics in the windows() device, then use savePlot to save it
to eps.

In Latex, you can put 

\usepackage{graphicx}

in the document preamble and something like

\begin{figure}[!th]
\includegraphics[height=8in]{figurename.eps}\\
\end{figure}

into the text to put the figure in a float.  To put in exactly
where the statement occurs, omit putting it into a figure
environment.

HTH,

--Mike

-- 
Mike Prager, NOAA, Beaufort, NC
* Opinions expressed are personal and not represented otherwise.
* Any use of tradenames does not constitute a NOAA endorsement.



From efg at stowers-institute.org  Mon Dec 11 20:21:53 2006
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Mon, 11 Dec 2006 13:21:53 -0600
Subject: [R] set up directory for R when I start R
References: <6.1.2.0.2.20061210044729.01c284c0@aiminy.mail.iastate.edu>
	<loom.20061210T115836-859@post.gmane.org>
Message-ID: <elkb4l$51l$1@sea.gmane.org>

"Dieter Menne" <dieter.menne at menne-biomed.de> wrote in message 
news:loom.20061210T115836-859 at post.gmane.org...
> Aimin Yan <aiminy <at> iastate.edu> writes:
>
>>
>> I want to set default directory for R when I start R.
>> How to do this?
>>
> ?setwd
>
> In Windows, I prefer the method described in
>
> http://tolstoy.newcastle.edu.au/R/help/00b/2454.html

I learned a similar trick by using Regedit to set the registry keys 
directly.  (Years ago someone showed me this trick to start a DOS session). 
Apparently, either "\Directory\shell" or "\Folder\shell" do the same thing. 
Do you know if there is a difference?

I checked and your suggestion can be modified to even specify a http_proxy, 
if needed:

For example, this works for me under Windows XP, including the proxy server, 
from any directory chosen using Windows Explorer:

------------
Windows Registry Editor Version 5.00

[HKEY_CLASSES_ROOT\Folder\shell\R\command]
@="C:\\Program Files\\R\\R-2.4.0\\bin\\Rgui.exe 
http_proxy=http://proxy01:8080 http_proxy_user=ask"
-----------

The above was the exported registry key from what I set manually using 
RegEdit. I used simply "R" instead of "Run R", like you suggested.


efg

Earl F. Glynn
Bioinformatics
Stowers Institute for Medical Research



From playtime at freemail.gr  Mon Dec 11 21:07:30 2006
From: playtime at freemail.gr (Mihalis Tsoukalos)
Date: Mon, 11 Dec 2006 22:07:30 +0200
Subject: [R] Cannot scale my map
Message-ID: <C987B173-FFD0-4D8A-B022-5DD6A4A67ECF@freemail.gr>

Dear list,

I have the following problem:

I want to plot my data and display a map at the same graph. The  
problem is that my map is not properly sized (is very small). It  
appears at the bottom-left side of the output.
I am using the following R commands:

{
plot(Time, col="lightgrey")
title("Connections per Minute")
map("world", fill=TRUE, lwd=0.25, col="green", add=TRUE)
box()
}

Please note that Time contains data in the following format:
00:00
00:01
...
22:04, etc.

Can you please help me?

many thanks in advance,
Mihalis.

---
Show me a Mac user, and I 'll show you a creative user.



From Mark.Leeds at morganstanley.com  Mon Dec 11 21:15:11 2006
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Mon, 11 Dec 2006 15:15:11 -0500
Subject: [R] behavior of ewma function
Message-ID: <D3AEEDA31E57474B840BEBC25A8A8344F39144@NYWEXMB23.msad.ms.com>

I have the ewma function as shown below. I think I copied it from an
oldSplus help page on filter and
then modified it with a lot of help from Achim.

ewma<-function(x,lambda = 1, init = x[1]) {

rval<-filter(lambda*coredata(x),filter=(1-lambda),method="recursive",ini
t=init)
rval<-zoo(coredata(rval),index(x))
rval
}

It sort of works but , if there are NA values in the input series such
as

x<-c(NA,2,3,4,5,NA,6,7,8,9,10,11,12,13,14,15)

y<-ewma(x,.01)

y

  1         2         3         4         5         6         7
8         9        10        11        12        13        14        15
16 

0.0000000 0.0200000 0.0498000 0.0893020 0.1384090  NA 0.0000000
0.0700000 0.1493000 0.2378070 0.3354289 0.4420746 0.5576539 0.6820774
0.8152566 0.9571040

So, ewma starts off with a zero if there is an NA and this is misleading
in terms of the exponentially weighted
moving average numbers calculated going forward. Maybe this has
something to do
Woth the fact that I set init equal x[1] ? The NA in the 6th spot is
fine but is there any way to 

1) return an NA value when the input into the series is an NA ?

2) start the exponentially weighted moving average at the next non NA
value ?

So, essentually, for the example above, I would prefer the output to be

NA, 2, 2*.01 + .99*3 = 2.99, 2.99*.01 + .99*4 = 3.9899, 3.9899*.01+
0.99*5 = 4.989, 4.989 ( because of the NA ),
4.989*.01 + 0.99* 6 = 5.989 etc.

This might be too complex to get but atleast is it possible to get NA
where the inputs were NA  and not use zeros
for smoothing going forward ? Thanks.








 





P.S : The code in ewma may look a little different than one is used to
but that is because it is sometimes run with
The inputs being zoo objects so coredate and index are needed.
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}



From Mark.Leeds at morganstanley.com  Mon Dec 11 21:26:07 2006
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Mon, 11 Dec 2006 15:26:07 -0500
Subject: [R] behavior of ewma function
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A8344F39144@NYWEXMB23.msad.ms.com>
Message-ID: <D3AEEDA31E57474B840BEBC25A8A8344F39145@NYWEXMB23.msad.ms.com>

I just had an idea but I'm not sure how to do it. Create a non NA series
( which I can do ) and smooth
that series ( whh I can do ). Then, after that smoothed series is
created, put the NAs back into the smoothed series
in their appropriate places ( which I don't know how to do ).
 
If anyone does know how to do that, the help would be appreciated.



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Leeds, Mark (IED)
Sent: Monday, December 11, 2006 3:15 PM
To: r-help at stat.math.ethz.ch
Subject: [R] behavior of ewma function

I have the ewma function as shown below. I think I copied it from an
oldSplus help page on filter and then modified it with a lot of help
from Achim.

ewma<-function(x,lambda = 1, init = x[1]) {

rval<-filter(lambda*coredata(x),filter=(1-lambda),method="recursive",ini
t=init)
rval<-zoo(coredata(rval),index(x))
rval
}

It sort of works but , if there are NA values in the input series such
as

x<-c(NA,2,3,4,5,NA,6,7,8,9,10,11,12,13,14,15)

y<-ewma(x,.01)

y

  1         2         3         4         5         6         7
8         9        10        11        12        13        14        15
16 

0.0000000 0.0200000 0.0498000 0.0893020 0.1384090  NA 0.0000000
0.0700000 0.1493000 0.2378070 0.3354289 0.4420746 0.5576539 0.6820774
0.8152566 0.9571040

So, ewma starts off with a zero if there is an NA and this is misleading
in terms of the exponentially weighted moving average numbers calculated
going forward. Maybe this has something to do Woth the fact that I set
init equal x[1] ? The NA in the 6th spot is fine but is there any way to


1) return an NA value when the input into the series is an NA ?

2) start the exponentially weighted moving average at the next non NA
value ?

So, essentually, for the example above, I would prefer the output to be

NA, 2, 2*.01 + .99*3 = 2.99, 2.99*.01 + .99*4 = 3.9899, 3.9899*.01+
0.99*5 = 4.989, 4.989 ( because of the NA ),
4.989*.01 + 0.99* 6 = 5.989 etc.

This might be too complex to get but atleast is it possible to get NA
where the inputs were NA  and not use zeros for smoothing going forward
? Thanks.








 





P.S : The code in ewma may look a little different than one is used to
but that is because it is sometimes run with The inputs being zoo
objects so coredate and index are needed.
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to
buy/se...{{dropped}}

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}



From info at aghmed.fsnet.co.uk  Mon Dec 11 21:32:27 2006
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Mon, 11 Dec 2006 20:32:27 +0000
Subject: [R] Multiple Imputation / Non Parametric Models / Combining
 Results
In-Reply-To: <E1GsaqY-0000JP-00@smtp08.web.de>
References: <E1GsaqY-0000JP-00@smtp08.web.de>
Message-ID: <7.0.0.16.0.20061211203113.00adf998@aghmed.fsnet.co.uk>

At 08:12 08/12/2006, Simon P. Kempf wrote:
>Dear R-Users,
>
>
>
>The following question is more of general nature than a merely technical
>one.  Nevertheless I hope someone get me some answers.
>
>

I am in no sense an expert in this area but since 
it seems that noone else has answered so far; I 
wonder whether the mitools package from CRAN helps?


>I have been using the mice package to perform the multiple imputations. So
>far, everything works fine with the standard regressions analysis.
>
>
>
>However, I am wondering, if it is theoretically correct to perform
>nonparametric models (GAM, spline smoothing etc.) with multiple imputed
>datasets. If yes, how can I combine the results in order to show the
>uncertainty?
>
>
>
>In the research field of real estate economics, the problem of missing data
>is often ignored respectively unmentioned. However, GAM, spline smoothing
>etc. become increasingly popular. In my research, I would like to use
>multiple imputed datasets and GAM, but I am unsure how present single
>results.
>
>
>
>Again I want to apologize that this is a rather theoretical statistical
>question than a technical question on R.
>
>
>
>Thanks in advance for any hints and advices.
>
>
>
>Simon
>
>
>
>
>
>
>
>
>
>
>
>Simon P. Kempf
>
>Dipl.-Kfm. MScRE Immobilien?konom (ebs)
>
>Wissenschaftlicher Assistent
>
>
>
>B?ro:
>
>IREBS Immobilienakademie
>
>c/o ebs Immobilienakademie GmbH
>
>Berliner Str. 26a
>
>13507 Berlin
>
>
>
>Privat:
>
>Dunckerstra?e 60
>
>10439 Berlin
>
>
>
>Mobil: 0176 7002 6687
>
>Email:  <mailto:simon.kempf at web.de> simon.kempf at web.de
>
>
>
>
>         [[alternative HTML version deleted]]

Michael Dewey
http://www.aghmed.fsnet.co.uk



From Ray.Brownrigg at mcs.vuw.ac.nz  Mon Dec 11 21:32:53 2006
From: Ray.Brownrigg at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Tue, 12 Dec 2006 09:32:53 +1300
Subject: [R] Cannot scale my map
In-Reply-To: <C987B173-FFD0-4D8A-B022-5DD6A4A67ECF@freemail.gr>
References: <C987B173-FFD0-4D8A-B022-5DD6A4A67ECF@freemail.gr>
Message-ID: <200612120932.53874.Ray.Brownrigg@mcs.vuw.ac.nz>

On Tuesday 12 December 2006 09:07, Mihalis Tsoukalos wrote:
> Dear list,
>
> I have the following problem:
>
> I want to plot my data and display a map at the same graph. The
> problem is that my map is not properly sized (is very small). It
> appears at the bottom-left side of the output.
> I am using the following R commands:
>
> {
> plot(Time, col="lightgrey")
> title("Connections per Minute")
> map("world", fill=TRUE, lwd=0.25, col="green", add=TRUE)
> box()
> }
>
> Please note that Time contains data in the following format:
> 00:00
> 00:01
> ...
> 22:04, etc.
>
> Can you please help me?
>
Well, the only way a map(..., add=TRUE) will work is if the original scale is 
in the order of latitude and longitude in degrees.  It is not clear exactly 
how the data you are plotting relates to the map you want.

If you just want the map as a 'background', then you will need to rescale one 
or other of the plots.

Hope this helps,
Ray Brownrigg



From playtime at freemail.gr  Mon Dec 11 21:52:05 2006
From: playtime at freemail.gr (Mihalis Tsoukalos)
Date: Mon, 11 Dec 2006 22:52:05 +0200
Subject: [R] Cannot scale my map
In-Reply-To: <200612120932.53874.Ray.Brownrigg@mcs.vuw.ac.nz>
References: <C987B173-FFD0-4D8A-B022-5DD6A4A67ECF@freemail.gr>
	<200612120932.53874.Ray.Brownrigg@mcs.vuw.ac.nz>
Message-ID: <945A28D4-BFAC-4B0C-ABDC-4359ADB23C11@freemail.gr>

On Mon 11 Dec 2006, at 22:32 , Ray Brownrigg wrote:

> On Tuesday 12 December 2006 09:07, Mihalis Tsoukalos wrote:
>> Dear list,
>>
>> I have the following problem:
>>
>> I want to plot my data and display a map at the same graph. The
>> problem is that my map is not properly sized (is very small). It
>> appears at the bottom-left side of the output.
>> I am using the following R commands:
>>
>> {
>> plot(Time, col="lightgrey")
>> title("Connections per Minute")
>> map("world", fill=TRUE, lwd=0.25, col="green", add=TRUE)
>> box()
>> }
>>
>> Please note that Time contains data in the following format:
>> 00:00
>> 00:01
>> ...
>> 22:04, etc.
>>
>> Can you please help me?
>
> If you just want the map as a 'background', then you will need to  
> rescale one
> or other of the plots.

Dear Ray,
thanks for answering.

I just want the map as a "background" but I do not know how to  
rescale it.
Can anyone help me?

thanks!
Mihalis.

---
Show me a Mac user, and I 'll show you a creative user.



From murdoch at stats.uwo.ca  Mon Dec 11 22:08:26 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 11 Dec 2006 16:08:26 -0500
Subject: [R] set up directory for R when I start R
In-Reply-To: <elkb4l$51l$1@sea.gmane.org>
References: <6.1.2.0.2.20061210044729.01c284c0@aiminy.mail.iastate.edu>	<loom.20061210T115836-859@post.gmane.org>
	<elkb4l$51l$1@sea.gmane.org>
Message-ID: <457DC8CA.9040604@stats.uwo.ca>

On 12/11/2006 2:21 PM, Earl F. Glynn wrote:
> "Dieter Menne" <dieter.menne at menne-biomed.de> wrote in message 
> news:loom.20061210T115836-859 at post.gmane.org...
>> Aimin Yan <aiminy <at> iastate.edu> writes:
>>
>>>
>>> I want to set default directory for R when I start R.
>>> How to do this?
>>>
>> ?setwd
>>
>> In Windows, I prefer the method described in
>>
>> http://tolstoy.newcastle.edu.au/R/help/00b/2454.html
> 
> I learned a similar trick by using Regedit to set the registry keys 
> directly.  (Years ago someone showed me this trick to start a DOS session). 
> Apparently, either "\Directory\shell" or "\Folder\shell" do the same thing. 
> Do you know if there is a difference?

Folders are shell objects, directories are file system objects. 
Normally the file system is mapped to folders, but there are other 
folders too, e.g. the network neighbourhood, printers, etc.

Duncan Murdoch

> 
> I checked and your suggestion can be modified to even specify a http_proxy, 
> if needed:
> 
> For example, this works for me under Windows XP, including the proxy server, 
> from any directory chosen using Windows Explorer:
> 
> ------------
> Windows Registry Editor Version 5.00
> 
> [HKEY_CLASSES_ROOT\Folder\shell\R\command]
> @="C:\\Program Files\\R\\R-2.4.0\\bin\\Rgui.exe 
> http_proxy=http://proxy01:8080 http_proxy_user=ask"
> -----------
> 
> The above was the exported registry key from what I set manually using 
> RegEdit. I used simply "R" instead of "Run R", like you suggested.
> 
> 
> efg
> 
> Earl F. Glynn
> Bioinformatics
> Stowers Institute for Medical Research
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From Mark.Leeds at morganstanley.com  Mon Dec 11 22:20:33 2006
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Mon, 11 Dec 2006 16:20:33 -0500
Subject: [R] I think this modified ewma function works if anyone is
	interested
Message-ID: <D3AEEDA31E57474B840BEBC25A8A8344F39146@NYWEXMB23.msad.ms.com>

I think this modified version of ewma works for anyone who is
interested. It gets rid of any NAs, smoothes the
resulting series and then puts the NAs back in at their correct spots.
The only catch is that the input has to be a zoo object. 
Sometimes I shock myself.


ewmab<-function(x,lambda = 1, init = x[1]) {

oldindex<-index(x)

temp<-as.vector(!is.na(x))
x<-x[temp]

rval<-filter(lambda*coredata(x),filter=(1-lambda),method="recursive",ini
t=init)
nonmissingzoo<-zoo(matrix(coredata(rval),nc=1),index(x))
rval<-merge(zoo(,oldindex),nonmissingzoo)

rval

}
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}



From p.murrell at auckland.ac.nz  Mon Dec 11 22:39:55 2006
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 12 Dec 2006 10:39:55 +1300
Subject: [R] global option settings for grid and lattice?
In-Reply-To: <455DDA59.30602@uchicago.edu>
References: <455DDA59.30602@uchicago.edu>
Message-ID: <457DD02B.6050006@stat.auckland.ac.nz>

Hi


Zepu Zhang wrote:
> Hello,
> 
> I'd like to be able to set options for grid and lattice globally, once 
> for all subsequent plots, just like what ps.options() does. I walked 
> through the functions of Grid and didn't find it. The following are 
> related things that are available:
> 
> get.gpar()
> trellis.par.set()
> 
> any ideas? thanks.


ps.options() sets the defaults for a PostScript output device.  It has
no effect, for example, on screen output.

The top-level grid viewport takes most of its default settings from the
device, so it should pick up ps.options() settings (WHEN you are drawing
to a PostScript device).  All grid drawing uses default settings from
the current viewport unless explicitly overridden, so ps.options()
settings should carry through to your drawing (IF you are only using grid).

Lattice decides for itself what the default graphics settings should be
(again, based on the type of device you are drawing to, but using
lattice defaults, NOT ps.options() defaults).  You might want to look at
?trellis.device and read about themes to gain control over default
lattice settings.

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From Mark.Hindell at utas.edu.au  Mon Dec 11 22:50:50 2006
From: Mark.Hindell at utas.edu.au (Mark Hindell)
Date: Tue, 12 Dec 2006 08:50:50 +1100
Subject: [R] hermite and Bezier splines
Message-ID: <7.0.1.0.2.20061212084644.02497180@utas.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061212/44d0d509/attachment-0005.pl 

From vidal.jean at gmail.com  Mon Dec 11 23:06:45 2006
From: vidal.jean at gmail.com (Jean Vidal)
Date: Mon, 11 Dec 2006 23:06:45 +0100
Subject: [R] Problem with sas.get function in Hmisc
Message-ID: <51d3ecb0612111406t136379a1rc74a2bff15589ff7@mail.gmail.com>

Thomas,

As F Harrel in a preceding message told me that you are the maintainer
of Hmisc package,
I write directly to you, with copy to the Rhelp list in case someone
encountered the same problem and find some benefit in the response.

I used quite often the function sas.get in Hmisc library which I is
very, very useful.
But, as trying to reuse it today it seems not to function anymore.
I tried everything I could imagine this afternoon, with no success.

Here is my last test.
'datatest' is a very simple SAS dataset (V9.1) with only 3 variables,
100 obs, no format.
Sas.get produces this ouput :
> bs2m <- sas.get(library="C:/test","datatest")
Syntaxe du nom de fichier, de r?pertoire ou de volume incorrecte.
Error in sas.get(library = "C:/test", "datatest") :
        SAS job failed with status 1
In addition: Warning message:
'cmd' execution failed with error code 1 in: shell(cmd, wait = TRUE,
intern = output)

In the R temp directory there is only one file : SaS678418be.3.sas,
containing the usual SAS
program (macro and  macro call).
I can run it from R with :
> sys("sas -sysin C:/Temp/RtmpuC23qb/SaS678418be.3.sas")
character(0)
and I get two files with dict (SaS678418be.1.sas) and data (SaS678418be.2.sas).
So the SAS step seems to work fine.

Do you have an idea of what went wrong ?
I tried to run old R progs with sas.get which used to work, and have
the same problem.

Thank you in advance.

> version
               _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          4.0
year           2006
month          10
day            03
svn rev        39566
language       R
version.string R version 2.4.0 (2006-10-03)



From ibrahimmutlay at gmail.com  Tue Dec 12 00:26:23 2006
From: ibrahimmutlay at gmail.com (=?ISO-8859-9?Q?=DDbrahim_Mutlay?=)
Date: Mon, 11 Dec 2006 18:26:23 -0500
Subject: [R] EBimage package for materials science
Message-ID: <eb21cbcd0612111526o34daa3edw3d4247b69c965c81@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061211/67ddf8f8/attachment-0005.pl 

From JRSTEAR at sandia.gov  Tue Dec 12 00:41:38 2006
From: JRSTEAR at sandia.gov (Jon Stearley)
Date: Mon, 11 Dec 2006 16:41:38 -0700
Subject: [R] a web interface to identify()
Message-ID: <895C31EE-2EBE-4C75-8D72-9E79BD88F8F9@sandia.gov>

i have a function like this:
  # show a plot and run a script when the user clicks on a plot,
  # where the script arguments correspond to the user-selected point.
  blah <- function(x, y) {
    plot(y~x)
    n <- identify(x=x, y=y)
    com <- system(command=paste("bleh", names(y)[n]))
  }

i would like to do this via a web page instead of x11() etc.  eg:
  1) a user clicks on an image in their web browser
  2) the i,j coordinate is sent to the server
  3) a single R process determines the nearest data point
  4) the server sends a new page to the client, based on attributes  
of the selected data point

i've browsed the R web interface options and frankly don't know which  
to pick, or maybe they are all overkill for what i am trying to  
accomplish?  perhaps the easiest thing to do is use ismap to capture  
the i,j coords, the receiving cgi script connects to an R process for  
the data lookup, and then responds to the browsing client  
appropriately.  the data set involved is very large, so i'd need a  
single R process sitting there waiting for such queries in order to  
avoid initialize&load time - this is the part i am particularly  
unclear how to do.

any ideas/suggestions/guidance on the best approach would be much  
appreciated.  thank you.

-- 
+--------------------------------------------------------------+
| Jon Stearley                  (505) 845-7571  (FAX 844-9297) |
| Sandia National Laboratories  Scalable Systems Integration   |
+--------------------------------------------------------------+



From helprhelp at gmail.com  Tue Dec 12 01:05:46 2006
From: helprhelp at gmail.com (Weiwei Shi)
Date: Mon, 11 Dec 2006 19:05:46 -0500
Subject: [R] implementation of t.test
Message-ID: <cdf817830612111605k58b7b2f3neb5e7fb4c3c50c0c@mail.gmail.com>

Hi, there:

for some reason, I need to look at t.test at coding level. Can anyone
here suggest a place to start with?

thanks.

-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III



From alexnerdy at hotmail.com  Tue Dec 12 01:09:19 2006
From: alexnerdy at hotmail.com (Alexander Nervedi)
Date: Tue, 12 Dec 2006 00:09:19 +0000
Subject: [R] strings as factors
Message-ID: <BAY18-F221E0A5ED51EAB081A689FBBD70@phx.gbl>

Hi,
To be able to match cases with a benchmark I need to have a data.frame with 
a character id variable. however, I am surprised why this seems to be so 
hard. In fact I was  unable to succeed. Here is what I tried:

>test1 <-expand.grid(ID = 1:2, sex = c("male","female"))
>is(test1[,2])
[1] "factor"   "oldClass"
>test2 <-expand.grid(ID = 1:2, sex = c('male','female'))
>is(test2[,2])
[1] "factor"   "oldClass"
>test3 <-expand.grid(ID = 1:2, sex = I(c("male","female")))
>is(test3[,2])
[1] "factor"   "oldClass"
>test4 <-expand.grid(ID = 1:2, sex = I(c('male','female')))
>is(test4[,2])
[1] "factor"   "oldClass"
>options(stringsAsFactors = FALSE)
>options("stringsAsFactors")
$stringsAsFactors
[1] FALSE

>test5 <-expand.grid(ID = 1:2, sex = I(c('male','female')))
>is(test5[,2])
[1] "factor"   "oldClass"


is there anyway I can get sex to be a character?

Arnab

_________________________________________________________________
Visit MSN Holiday Challenge for your chance to win up to $50,000 in Holiday



From Jared.O'Connell at csiro.au  Tue Dec 12 01:45:40 2006
From: Jared.O'Connell at csiro.au (Jared.O'Connell at csiro.au)
Date: Tue, 12 Dec 2006 09:45:40 +0900
Subject: [R] Combining bitmaps and plots - file too large
Message-ID: <F83C6ACE124F3E4D83B3A90C9CA0922D07186C@exwa3-per.nexus.csiro.au>

Hello,

I wish to draw a bitmap image and a standard plot in a split window,
multiple times, output to a pdf eg.

library(pixmap)
pdf("test.pdf")
for(i in 1:50) {
	par(mfrow=c(1,2))
	p1 = read.pnm(paste("img",i,".ppm",sep=""))
	plot(x,y)
}
dev.off()

The end result is a pdf file > 1GB, obviously not very portable.  The
.ppm's I'm using are around 1MB so they are not some huge resolution.
I've tried several different methods of optimising .pdfs externally (eg.
ps2pdf -dPDFSETTINGs=\screen) without much luck.

Any suggestions?

Regards,

Jared



From harshal at yahoo-inc.com  Tue Dec 12 01:55:27 2006
From: harshal at yahoo-inc.com (Harshal D Dedhia)
Date: Mon, 11 Dec 2006 16:55:27 -0800
Subject: [R] Hourly Time Series
Message-ID: <959DC0987E39DB43B963EA5ADC9E1A29015F809C@SNV-XCHMAIL2.xch.corp.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061211/02992036/attachment-0005.pl 

From cberry at tajo.ucsd.edu  Tue Dec 12 02:06:01 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Mon, 11 Dec 2006 17:06:01 -0800
Subject: [R] implementation of t.test
In-Reply-To: <cdf817830612111605k58b7b2f3neb5e7fb4c3c50c0c@mail.gmail.com>
References: <cdf817830612111605k58b7b2f3neb5e7fb4c3c50c0c@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0612111654140.14753@tajo.ucsd.edu>

On Mon, 11 Dec 2006, Weiwei Shi wrote:

> Hi, there:
>
> for some reason, I need to look at t.test at coding level. Can anyone
> here suggest a place to start with?

You mean how to read the code??

Like this:

> t.test # print the function
function (x, ...)
UseMethod("t.test")
<environment: namespace:stats>
> # that told me 't.test' has S3 methods
> methods(t.test)
[1] t.test.default* t.test.formula*

    Non-visible functions are asterisked
> # that told me what they were
> # and that I need ':::' to see them
> page(stats:::t.test.default,"print")
> page(stats:::t.test.formula,"print")
> # looks like you want to study t.test.default

see
 	?methods
 	?":::"

HTH

> [...]

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717



From Bill.Venables at csiro.au  Tue Dec 12 04:30:33 2006
From: Bill.Venables at csiro.au (Bill.Venables at csiro.au)
Date: Tue, 12 Dec 2006 13:30:33 +1000
Subject: [R] strings as factors
Message-ID: <B998A44C8986644EA8029CFE6396A9248409A9@exqld2-bne.qld.csiro.au>

Here is a possibility:

> test <- expand.grid(id = 1:2, sex = c('male', 'female'))
> sapply(test, class)
       id       sex 
"integer"  "factor" 
> test <- transform(test, sex = as.character(sex))
> sapply(test, class)
         id         sex 
  "integer" "character" 


But I am surprised at the reason you give for needing it as a character
vector, because factors often act as character vectors under matching
anyway.

> sexf <- factor(test[[2]])
> sexf
[1] male   male   female female
Levels: female male

> which(sexf %in% "male")
[1] 1 2
> which(sexf == "male")
[1] 1 2

Bill Venables
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Alexander Nervedi
Sent: Tuesday, 12 December 2006 10:09 AM
To: r-help at stat.math.ethz.ch
Subject: [R] strings as factors

Hi,
To be able to match cases with a benchmark I need to have a data.frame
with 
a character id variable. however, I am surprised why this seems to be so

hard. In fact I was  unable to succeed. Here is what I tried:

>test1 <-expand.grid(ID = 1:2, sex = c("male","female"))
>is(test1[,2])
[1] "factor"   "oldClass"
>test2 <-expand.grid(ID = 1:2, sex = c('male','female'))
>is(test2[,2])
[1] "factor"   "oldClass"
>test3 <-expand.grid(ID = 1:2, sex = I(c("male","female")))
>is(test3[,2])
[1] "factor"   "oldClass"
>test4 <-expand.grid(ID = 1:2, sex = I(c('male','female')))
>is(test4[,2])
[1] "factor"   "oldClass"
>options(stringsAsFactors = FALSE)
>options("stringsAsFactors")
$stringsAsFactors
[1] FALSE

>test5 <-expand.grid(ID = 1:2, sex = I(c('male','female')))
>is(test5[,2])
[1] "factor"   "oldClass"


is there anyway I can get sex to be a character?

Arnab

_________________________________________________________________
Visit MSN Holiday Challenge for your chance to win up to $50,000 in
Holiday

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From Ying.Lu at Colorado.EDU  Tue Dec 12 05:40:45 2006
From: Ying.Lu at Colorado.EDU (LU YING)
Date: Mon, 11 Dec 2006 21:40:45 -0700 (MST)
Subject: [R] help on determining operating system
Message-ID: <Pine.LNX.4.64.0612112125160.26701@sobek.colorado.edu>

Dear list,

I am an R user and I also write my own package in R(sometime i need to 
write  in C), and right now i am thinking about buying a new 
workstation--and i am trying to decide if i should get 
a mac with OS X or a linux machine (for example Dell).

I have experience using R on linux (but i have been just a user and never 
been a admin) but i am hesitating of managing a linux system on my own 
(btw I would like to have my new workstation to be used as a server), so 
right now I am leaning toward of buying a Mac Pro. But from the website, 
it sounds like R doesnt work quite well with Mac operating system 
yet...so I was wondering if anybody here have any experiences of 
using/developing R package on a Mac machine? Is it smooth enough?

(oh by the way, i am not a Mac user yet, Windows has been the primary 
operating system that i used, but after hearing many good things 
of OS X, I am really interested in switching over.)

any suggestions are appreciated!

Ying


Ying Lu
Assistant Professor
Dept. Sociology
U-Colorado at Boulder



From greenboy21 at gmail.com  Tue Dec 12 06:53:25 2006
From: greenboy21 at gmail.com (Xu Yuan)
Date: Tue, 12 Dec 2006 00:53:25 -0500
Subject: [R] how to define w matrix in my case?
Message-ID: <e00347d90612112153g1c048032vbcb39c7b7b1b6252@mail.gmail.com>

hello list,

I have N agricultural fields (some of them share borders, some don't)
with ph as the variable of interest. Since I want to test the spatial
autocorrelation, I need to come up with the w matrix. The first and
easy way that came to my brain was the binary relationship, i.e., the
w matrix is all 1s and 0s with 1 meaning two fields sharing border and
0 not. So I checked the distribution of the N fields, and I manually
defined a NxN matrix with 1s and 0s. I list the variable of interest
(ph) as a vector with N elements, and plan to use moran or moran.test
to test the spatial autocorrelation. However, I had difficulty to run
the code. Anyone has suggestions about my case where the areal/lattice
data are irregular?

Please also let me know if moran or moran.test is the correct command to use.

Thanks.
XY



From playtime at freemail.gr  Tue Dec 12 07:54:51 2006
From: playtime at freemail.gr (Mihalis Tsoukalos)
Date: Tue, 12 Dec 2006 08:54:51 +0200
Subject: [R] help on determining operating system
In-Reply-To: <Pine.LNX.4.64.0612112125160.26701@sobek.colorado.edu>
References: <Pine.LNX.4.64.0612112125160.26701@sobek.colorado.edu>
Message-ID: <6A711B20-6A1B-4A56-B168-E0F425F75519@freemail.gr>

On Tue 12 Dec 2006, at 06:40 , LU YING wrote:

> Dear list,
>
> I am an R user and I also write my own package in R(sometime i need to
> write  in C), and right now i am thinking about buying a new
> workstation--and i am trying to decide if i should get
> a mac with OS X or a linux machine (for example Dell).
>
> I have experience using R on linux (but i have been just a user and  
> never
> been a admin) but i am hesitating of managing a linux system on my own
> (btw I would like to have my new workstation to be used as a  
> server), so
> right now I am leaning toward of buying a Mac Pro. But from the  
> website,
> it sounds like R doesnt work quite well with Mac operating system
> yet...so I was wondering if anybody here have any experiences of
> using/developing R package on a Mac machine? Is it smooth enough?
>
> (oh by the way, i am not a Mac user yet, Windows has been the primary
> operating system that i used, but after hearing many good things
> of OS X, I am really interested in switching over.)
>
> any suggestions are appreciated!
>
> Ying

Hi Ying.

I am using R on both a PowerMac and a MacBook. I do not do any  
development but as far as using R I do not have any problems.
Please note that software such as Parallels (http:// 
www.parallels.com), allows you to run Linux on a Mac Intel (such as  
Mac Pro) without problems, in case you need it.

Feel free to ask more questions,
Mihalis.

----
Mac for Productivity, Unix for Development, and Windows for Solitaire



From kaplan at santafe.edu  Tue Dec 12 08:26:00 2006
From: kaplan at santafe.edu (t.d. kaplan)
Date: Tue, 12 Dec 2006 00:26:00 -0700
Subject: [R] multiple x-axis labels on plot
Message-ID: <f6aa47200612112326g3804e1efwe7f9cf7227cef03d@mail.gmail.com>

hi,

how can i set multiple x-axis labels on a plot? in effect, i want
to set 2 x-axis labels and values on the tick marks. is it possible
to have one running on the bottom (as is the default) and another
running across the top of a plot?

like:

xlab-1
---------
|       |
|       |
---------
xlab-0


thanks.



From d.varkey at fisheries.ubc.ca  Tue Dec 12 08:46:00 2006
From: d.varkey at fisheries.ubc.ca (Divya Alice Varkey)
Date: Mon, 11 Dec 2006 23:46:00 -0800
Subject: [R] surface plot
Message-ID: <4347B80691A0F042B5503761D1B4AE8F2BA5AE@aerl08.aerl.ubc.dom>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061211/f72dd3ec/attachment-0005.pl 

From ligges at statistik.uni-dortmund.de  Tue Dec 12 08:59:34 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 12 Dec 2006 08:59:34 +0100
Subject: [R] surface plot
In-Reply-To: <4347B80691A0F042B5503761D1B4AE8F2BA5AE@aerl08.aerl.ubc.dom>
References: <4347B80691A0F042B5503761D1B4AE8F2BA5AE@aerl08.aerl.ubc.dom>
Message-ID: <457E6166.6010704@statistik.uni-dortmund.de>

Perhaps you are looking for ?persp.

Uwe Ligges

Divya Alice Varkey wrote:
> Hi,
> 
>  
> 
> I have been trying to make a surface plot using R - I came across
> functions like plot.surface, surface but I could not use these functions
> as they seem to be in FOO package which I cannot load. I also want to
> make a plane that fits the surface plot.
> 
> Can anyone help?
> 
>  
> 
> divya
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ligges at statistik.uni-dortmund.de  Tue Dec 12 09:00:34 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 12 Dec 2006 09:00:34 +0100
Subject: [R] multiple x-axis labels on plot
In-Reply-To: <f6aa47200612112326g3804e1efwe7f9cf7227cef03d@mail.gmail.com>
References: <f6aa47200612112326g3804e1efwe7f9cf7227cef03d@mail.gmail.com>
Message-ID: <457E61A2.4080600@statistik.uni-dortmund.de>



t.d. kaplan wrote:
> hi,
> 
> how can i set multiple x-axis labels on a plot? in effect, i want
> to set 2 x-axis labels and values on the tick marks. is it possible
> to have one running on the bottom (as is the default) and another
> running across the top of a plot?


Yes, for plotting axes separately, see ?axis.
For plotting annotation along the margins of the plot, see ?mtext.

Uwe Ligges

> like:
> 
> xlab-1
> ---------
> |       |
> |       |
> ---------
> xlab-0
> 
> 
> thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jmb at mssl.ucl.ac.uk  Tue Dec 12 11:12:15 2006
From: jmb at mssl.ucl.ac.uk (Jenny Barnes)
Date: Tue, 12 Dec 2006 10:12:15 +0000 (GMT)
Subject: [R] how do you interpolate a gaussian grid to a standard 2.5 degree
	grid?
Message-ID: <200612121012.kBCACFDq015513@msslhb.mssl.ucl.ac.uk>

Dear R-help community,

I have looked on the R search site and archives but cannot find mention of a way 
of interpolating a gaussian distribution of data to a standard 2.5 degree grid. 

I have two global dataset and I need to correlate - unfortunately one is a 2.5 
degree grid dim[longitude=144,latitude=72] and one is gaussian 
dim[longitude=192,latitude=94].

I would rally appreciate hearing back from any of you who may have wanted to 
interpolate your data is this way. If there is no ready-made function you know 
of but you are willing to share your own methods I would also appreciate any 
pointers.

Many thanks for your time,

Jenny Barnes


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Jennifer Barnes
PhD student - long range drought prediction
Climate Extremes
Department of Space and Climate Physics
University College London
Holmbury St Mary, Dorking
Surrey
RH5 6NT
Web: http://climate.mssl.ucl.ac.uk



From david.lindelof at epfl.ch  Tue Dec 12 11:37:53 2006
From: david.lindelof at epfl.ch (David =?ISO-8859-1?Q?Lindel=F6f?=)
Date: Tue, 12 Dec 2006 11:37:53 +0100
Subject: [R] Sweave, Xfig, pdflatex and \setkeys
Message-ID: <1165919873.4758.18.camel@lesopriv3.epfl.ch>

Dear useRs,

How does one include graphics created with Xfig with LaTeX fonts into
Sweave?

If I create a graphic with Xfig with some Computer Modern fonts, I
choose to export it as combined PDF and LaTeX. So I get two files, one
foo.pdf with the drawings without the text and foo.pdftex with some
LaTeX code that ensures the text lands in the right place together with
the drawing. I'm supposed to \input{} this file in my LaTeX document.

Trouble is that Sweave defines (with \setkeys) the default width of
\includegraphics to be 0.8 times the \textwidth. The result is that the
graphic is scaled, but not the text.

I was looking for a way to temporarily undefine the default width of
included graphics, but without success. Does anyone know how to undo a
definition that has been set with \setkeys?

Or does anyone has another workaround for including xfig graphics with
LaTeX text in Sweave?

Looking forward to your help,
--
--------------------------------------------------
David Lindel?f
Station 18
LESO-PB/EPFL
1015 Lausanne
tel +41-21-693.5556
mob +41-79-415.6641
fax +41-21-693.2722
e-mail david.lindelof at epfl.ch
url http://lesowww.epfl.ch/doctorants/lindelof/
weblog http://visnet.ch/~lindelof/smartbuildings/
--------------------------------------------------

In the force if Yoda's so strong, construct a sentence with words in
the proper order then why can't he?



From connect.chris at gmail.com  Tue Dec 12 12:52:02 2006
From: connect.chris at gmail.com (Chris Linton)
Date: Tue, 12 Dec 2006 06:52:02 -0500
Subject: [R] logistic reg & predict function
Message-ID: <b05bf6c40612120352w4a961b08t39d7e559a701ce2c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061212/87704ec6/attachment-0005.pl 

From rita.sousa at ine.pt  Tue Dec 12 12:55:58 2006
From: rita.sousa at ine.pt (Rita Sousa)
Date: Tue, 12 Dec 2006 11:55:58 -0000
Subject: [R] tklistbox...
Message-ID: <2F01C2D1A2A44B41BD01DDE5F72E1CAB01A1F604@rngpew02.drn.ine.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061212/a80702e2/attachment-0005.pl 

From csardi at rmki.kfki.hu  Tue Dec 12 13:05:52 2006
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Tue, 12 Dec 2006 13:05:52 +0100
Subject: [R] tklistbox...
In-Reply-To: <2F01C2D1A2A44B41BD01DDE5F72E1CAB01A1F604@rngpew02.drn.ine.pt>
References: <2F01C2D1A2A44B41BD01DDE5F72E1CAB01A1F604@rngpew02.drn.ine.pt>
Message-ID: <20061212120552.GD30212@localdomain>

Rita,

give the exportselection=FALSE argument to tklistbox.
(If i'm not mistaken.)

G.

On Tue, Dec 12, 2006 at 11:55:58AM -0000, Rita Sousa wrote:
> Hi everyone, 
> 
> I have different listboxes in the same toplevel window. 
> The problem is, if I select (by left clicking) one of those listbox
> elements, the current selection in the other listboxes is cleared! 
> Anybody knows how I can prevent this? 
> 
> Thanks,
> 
> ---------------------------------------------------
> Rita Sousa
> DME - ME: Departamento de Metodologia Estat?stica - M?todos Estat?sticos
> INE - DRP: Instituto Nacional de Estat?stica - Delega??o Regional do Porto 
> Tel.: 22 6072016 (Extens?o: 4116)
> --------------------------------------------------- 
[...]

-- 
Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK



From j.zutt at tudelft.nl  Tue Dec 12 13:22:52 2006
From: j.zutt at tudelft.nl (Jonne Zutt)
Date: Tue, 12 Dec 2006 13:22:52 +0100
Subject: [R] tklistbox...
Message-ID: <1165926172.341.1.camel@dutiih.st.ewi.tudelft.nl>

Hi Rita,

This is the option you are looking for:

Command-Line Name: -exportselection
Database Name: exportSelection
Database Class: ExportSelection
    Specifies whether or not a selection in the widget should also be
the
    X selection. The value may have any of the forms accepted by
    Tcl_GetBoolean, such as true, false, 0, 1, yes, or no. If the
    selection is exported, then selecting in the widget deselects the
    current X selection, selecting outside the widget deselects any
widget
    selection, and the widget will respond to selection retrieval
requests
    when it has a selection. The default is usually for widgets to
export
    selections.

Use it by giving tklistbox the argument exportselection=0.

JeeBee.



From dimitri.mahieux at student.uclouvain.be  Tue Dec 12 14:10:00 2006
From: dimitri.mahieux at student.uclouvain.be (Mahieux Dimitri)
Date: Tue, 12 Dec 2006 14:10:00 +0100
Subject: [R] Unable to build a package
Message-ID: <457EAA28.7000809@student.uclouvain.be>

Hi everybody,

I've recently write my first R package and when I run :
    R CMD check myPackage

I got the following message :
* Installing *source* package 'myPackage' ...
** R
** save image
Error in exists(x, envir, mode, inherits) :
    invalid first argument
Error: unable to load R code in package 'myPackage'
Execution halted
ERROR: execution of package source for 'myPackage' failed
** Removing '/home/dmahieux/svn/microarray/src/package.Rcheck/myPackage'

In this package, I've 2 classes :
 - a virtual one : MArrayExperiment
 - a second which extend the first one : AffyExperiment.

I think that the problem is when building AffyExperiment , the 
MArrayExperiment is not yet known and so the exists function is aborded.

Is there a special trick to tell that the MArrayExperiment class is 
present in my package ?

Sincerely...



From jmb at mssl.ucl.ac.uk  Tue Dec 12 14:43:02 2006
From: jmb at mssl.ucl.ac.uk (Jenny Barnes)
Date: Tue, 12 Dec 2006 13:43:02 +0000 (GMT)
Subject: [R] how do you interpolate a gaussian grid to a standard 2.5
	degreegrid?
Message-ID: <200612121343.kBCDh1Gf015904@msslhb.mssl.ucl.ac.uk>

Thanks Roger,

I shall have a further look at expand.grid() and the fields package and see what 
I can do!

Jenny

>
>Jenny:
>
>If you have two matrices, and know the grid values of the x and y sequences, 
you can use expand.grid() and some trial and error to make a data frame with 
longitude, latitude, and value. From there, I think Krig (or Tps) in the fields 
package will help, with the "Distance=" argument set to rdist.earth. The next 
release of the gstat package is also going to support Great Circle distances, 
but the fields package is written by scientists close to your interests, and is 
already available. You do need to know the latitude spacings, though.
>
>---
>Roger Bivand, NHH, Helleveien 30, N-5045 Bergen,
>Roger.Bivand at nhh.no
>
>
>
>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch on behalf of Jenny Barnes
>Sent: Tue 12.12.2006 11:12
>To: r-help at stat.math.ethz.ch
>Subject: [R] how do you interpolate a gaussian grid to a standard 2.5 
degreegrid?
> 
>Dear R-help community,
>
>I have looked on the R search site and archives but cannot find mention of a 
way 
>of interpolating a gaussian distribution of data to a standard 2.5 degree grid. 
>
>I have two global dataset and I need to correlate - unfortunately one is a 2.5 
>degree grid dim[longitude=144,latitude=72] and one is gaussian 
>dim[longitude=192,latitude=94].
>
>I would rally appreciate hearing back from any of you who may have wanted to 
>interpolate your data is this way. If there is no ready-made function you know 
>of but you are willing to share your own methods I would also appreciate any 
>pointers.
>
>Many thanks for your time,
>
>Jenny Barnes
>
>
>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>Jennifer Barnes
>PhD student - long range drought prediction
>Climate Extremes
>Department of Space and Climate Physics
>University College London
>Holmbury St Mary, Dorking
>Surrey
>RH5 6NT
>Web: http://climate.mssl.ucl.ac.uk
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Jennifer Barnes
PhD student - long range drought prediction
Climate Extremes
Department of Space and Climate Physics
University College London
Holmbury St Mary, Dorking
Surrey
RH5 6NT
01483 204149
07916 139187
Web: http://climate.mssl.ucl.ac.uk



From justin_bem at yahoo.fr  Tue Dec 12 15:40:52 2006
From: justin_bem at yahoo.fr (justin bem)
Date: Tue, 12 Dec 2006 14:40:52 +0000 (GMT)
Subject: [R] Re :  implementation of t.test
Message-ID: <20061212144052.6008.qmail@web23008.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061212/eb1fee48/attachment-0005.pl 

From Timothy.Mak at iop.kcl.ac.uk  Tue Dec 12 15:40:14 2006
From: Timothy.Mak at iop.kcl.ac.uk (Timothy.Mak at iop.kcl.ac.uk)
Date: Tue, 12 Dec 2006 14:40:14 +0000
Subject: [R] 2 questions
Message-ID: <OFCB4A8FAB.CEF35E5E-ON80257242.004C9E87-80257242.00518E3A@iop.kcl.ac.uk>

Hi all, 

I'm new here. Want to ask two possibly quite basic questions: 

1. How can I clear all objects in one stroke? 
2. How can I perform a regression with independent variables specified by 
an object? 

Thanks, 

Tim



From sebastian.weber at physik.tu-darmstadt.de  Tue Dec 12 16:04:17 2006
From: sebastian.weber at physik.tu-darmstadt.de (Sebastian Weber)
Date: Tue, 12 Dec 2006 16:04:17 +0100
Subject: [R] 2 questions
In-Reply-To: <OFCB4A8FAB.CEF35E5E-ON80257242.004C9E87-80257242.00518E3A@iop.kcl.ac.uk>
References: <OFCB4A8FAB.CEF35E5E-ON80257242.004C9E87-80257242.00518E3A@iop.kcl.ac.uk>
Message-ID: <1165935857.7616.6.camel@rock.kraft.de>

Hi!

> I'm new here. Want to ask two possibly quite basic questions: 
> 
> 1. How can I clear all objects in one stroke? 

how about

rm(ls())

> 2. How can I perform a regression with independent variables specified by 
> an object? 

?h, no spontaneous idea.

Greetings,

Sebastian

> 
> Thanks, 
> 
> Tim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From justin_bem at yahoo.fr  Tue Dec 12 16:25:24 2006
From: justin_bem at yahoo.fr (justin bem)
Date: Tue, 12 Dec 2006 15:25:24 +0000 (GMT)
Subject: [R] Re : Re :  implementation of t.test
Message-ID: <20061212152524.86631.qmail@web23014.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061212/a54d9dfb/attachment-0005.pl 

From zhuanshi.he at gmail.com  Tue Dec 12 16:47:03 2006
From: zhuanshi.he at gmail.com (Zhuanshi He)
Date: Tue, 12 Dec 2006 10:47:03 -0500
Subject: [R] how do you interpolate a gaussian grid to a standard 2.5
	degree grid?
In-Reply-To: <200612121012.kBCACFDq015513@msslhb.mssl.ucl.ac.uk>
References: <200612121012.kBCACFDq015513@msslhb.mssl.ucl.ac.uk>
Message-ID: <2a8feb1c0612120747p136ae863h7bf516c00c4f659@mail.gmail.com>

Hi Jenny,

Maybe the following links will be useful for you. Both of thoes are
used in meteorological and climate research community. But u can used
the codes to create the data values that you need.


g2fsh : Interpolates a scalar quantity from a Gaussian grid to a fixed grid.

http://www.ncl.ucar.edu/Document/Functions/Built-in/g2fsh.shtml


g2fshv : Interpolates a vector quantity from a Gaussian grid to a fixed grid.
http://www.ncl.ucar.edu/Document/Functions/Built-in/g2fshv.shtml


In addition, both of those functions based on a package named
SPHEREPACK (http://www.cisl.ucar.edu/css/software/spherepack/ ).

you can write call subroutines shipped from SPHEREPACK to get values
at your fixed grids.

Good luck.

Zhuanshi He



On 12/12/06, Jenny Barnes <jmb at mssl.ucl.ac.uk> wrote:
>
> Dear R-help community,
>
> I have looked on the R search site and archives but cannot find mention of a way
> of interpolating a gaussian distribution of data to a standard 2.5 degree grid.
>
> I have two global dataset and I need to correlate - unfortunately one is a 2.5
> degree grid dim[longitude=144,latitude=72] and one is gaussian
> dim[longitude=192,latitude=94].
>
> I would rally appreciate hearing back from any of you who may have wanted to
> interpolate your data is this way. If there is no ready-made function you know
> of but you are willing to share your own methods I would also appreciate any
> pointers.
>
> Many thanks for your time,
>
> Jenny Barnes
>
>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Jennifer Barnes
> PhD student - long range drought prediction
> Climate Extremes
> Department of Space and Climate Physics
> University College London
> Holmbury St Mary, Dorking
> Surrey
> RH5 6NT
> Web: http://climate.mssl.ucl.ac.uk
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


-- 
Zhuanshi He / Z. He (PhD)
Waterloo Centre for Atmospheric Sciences (WCAS)
Department of Chemistry
Phy Bldg, Rm 2022
University of Waterloo,
Waterloo, ON N2L 3G1
Canada
Tel: +1-519-888-4567 ext 38053        FAX: +1-519-746-0435



From jgarcia at ija.csic.es  Tue Dec 12 16:59:11 2006
From: jgarcia at ija.csic.es (javier garcia-pintado)
Date: Tue, 12 Dec 2006 16:59:11 +0100
Subject: [R] expression()
Message-ID: <457ED1CF.2060500@ija.csic.es>

Hi,
I'm trying to use expression() to write a text to a graphic in the margin.

Using:

mtext(expression(beta),side=1,line=2)

writes a perfect beta greek character, but I need to add a subindex
"max", and I'm trying:

mtext(paste(expression(beta),"max"),side=1,line=2)

simply writes "beta max" in the plot.

Please, Could you tell me what I'm doing wrong?

By the way, is there a way to add Latex expressions to graphics? Then I
could use the Latex expression: $\beta_{\mathrm{max}}$. This also would
be very useful for me for more complex expressions in plots.

Best regards,

Javier

-- 
Javier Garc?a-Pintado
Institute of Earth Sciences Jaume Almera (CSIC)
Lluis Sole Sabaris s/n, 08028 Barcelona
Phone: +34 934095410
Fax:   +34 934110012
e-mail:jgarcia at ija.csic.es 


From macq at llnl.gov  Tue Dec 12 17:02:58 2006
From: macq at llnl.gov (Don MacQueen)
Date: Tue, 12 Dec 2006 08:02:58 -0800
Subject: [R] help on determining operating system
In-Reply-To: <Pine.LNX.4.64.0612112125160.26701@sobek.colorado.edu>
References: <Pine.LNX.4.64.0612112125160.26701@sobek.colorado.edu>
Message-ID: <p06210200c1a480b73f2c@[192.168.11.9]>

R works very well with the Mac operating system, in my experience.

Packages with simple C should be easy; I have several packages of my 
own that use Fortran, just one or two subroutines each, and I have no 
difficulty building them.

I'm no expert, but as I understand it, Apple has done some things on 
the unix side that are somewhat different than what you'll see on a 
typical Linux; if you try to work with what Apple has done, in the 
way that Apple has designed it to be used, you will have a lot to 
learn. But I've done just fine without it for my rather simple needs.

In my opinion, if you want to use mainstream desktop applications 
like Microsoft Office and also work in a unix-like environment, on 
the same computer, OS X is the way to go. You can run R in 
command-line mode at a unix prompt, as on Linux, or using the console 
app, similar to how it's done on Windows.

-Don

At 9:40 PM -0700 12/11/06, LU  YING wrote:
>Dear list,
>
>I am an R user and I also write my own package in R(sometime i need to
>write  in C), and right now i am thinking about buying a new
>workstation--and i am trying to decide if i should get
>a mac with OS X or a linux machine (for example Dell).
>
>I have experience using R on linux (but i have been just a user and never
>been a admin) but i am hesitating of managing a linux system on my own
>(btw I would like to have my new workstation to be used as a server), so
>right now I am leaning toward of buying a Mac Pro. But from the website,
>it sounds like R doesnt work quite well with Mac operating system
>yet...so I was wondering if anybody here have any experiences of
>using/developing R package on a Mac machine? Is it smooth enough?
>
>(oh by the way, i am not a Mac user yet, Windows has been the primary
>operating system that i used, but after hearing many good things
>of OS X, I am really interested in switching over.)
>
>any suggestions are appreciated!
>
>Ying
>
>
>Ying Lu
>Assistant Professor
>Dept. Sociology
>U-Colorado at Boulder
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


-- 
---------------------------------
Don MacQueen
Lawrence Livermore National Laboratory
Livermore, CA, USA



From bcarvalh at jhsph.edu  Tue Dec 12 17:04:27 2006
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Tue, 12 Dec 2006 11:04:27 -0500
Subject: [R] expression()
In-Reply-To: <457ED1CF.2060500@ija.csic.es>
References: <457ED1CF.2060500@ija.csic.es>
Message-ID: <F5A97ABA-8B6C-4EC7-A40C-B93D724B8CA6@jhsph.edu>

mtext(expression(beta[max]), side=1, line=2)

is it what you want?

b

On Dec 12, 2006, at 10:59 AM, javier garcia-pintado wrote:

> Hi,
> I'm trying to use expression() to write a text to a graphic in the  
> margin.
>
> Using:
>
> mtext(expression(beta),side=1,line=2)
>
> writes a perfect beta greek character, but I need to add a subindex
> "max", and I'm trying:
>
> mtext(paste(expression(beta),"max"),side=1,line=2)
>
> simply writes "beta max" in the plot.
>
> Please, Could you tell me what I'm doing wrong?
>
> By the way, is there a way to add Latex expressions to graphics?  
> Then I
> could use the Latex expression: $\beta_{\mathrm{max}}$. This also  
> would
> be very useful for me for more complex expressions in plots.
>
> Best regards,
>
> Javier
>
> -- 
> Javier Garc?a-Pintado
> Institute of Earth Sciences Jaume Almera (CSIC)
> Lluis Sole Sabaris s/n, 08028 Barcelona
> Phone: +34 934095410
> Fax:   +34 934110012
> e-mail:jgarcia at ija.csic.es
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From scionforbai at gmail.com  Tue Dec 12 17:05:35 2006
From: scionforbai at gmail.com (Scionforbai)
Date: Tue, 12 Dec 2006 17:05:35 +0100
Subject: [R] expression()
In-Reply-To: <457ED1CF.2060500@ija.csic.es>
References: <457ED1CF.2060500@ija.csic.es>
Message-ID: <e9ee1f0a0612120805i28fdc2bbmb829a40c05a1ec85@mail.gmail.com>

Hallo,

for the first question:
mtext(expression(beta[max]),side=1,line=2)

and:
?plotmath
demo(plotmath)
for the second.

Hope it helped,
Scionforbai



From bjorn.vancampenhout at ua.ac.be  Tue Dec 12 16:51:16 2006
From: bjorn.vancampenhout at ua.ac.be (Van Campenhout Bjorn)
Date: Tue, 12 Dec 2006 16:51:16 +0100
Subject: [R] 2 questions
References: <OFCB4A8FAB.CEF35E5E-ON80257242.004C9E87-80257242.00518E3A@iop.kcl.ac.uk>
	<1165935857.7616.6.camel@rock.kraft.de>
Message-ID: <0EE866100C01984EAE6AC3AE56EDFE530C2122@xmail05.ad.ua.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061212/305507cf/attachment-0005.pl 

From aiminy at iastate.edu  Tue Dec 12 17:13:19 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Tue, 12 Dec 2006 10:13:19 -0600
Subject: [R] Is my data set too large
Message-ID: <6.1.2.0.2.20061212100856.01c05aa8@aiminy.mail.iastate.edu>

I have a data set like this.
I want to do glm, but I get this error:

Error in model.matrix.default(mt, mf, contrasts) :
         cannot allocate vector of length 932889958

I am wondering if my data set is too large or I did something wrong.

Is there some limitation for data size for R?

thanks,

Aimin


 > p1982<- read.csv("p_1982_aa.csv")
 > names(p1982)
[1] "p"   "aa"  "as"  "ms"  "cur" "sc"
 > str(p1982)
'data.frame':   465979 obs. of  6 variables:
  $ p  : Factor w/ 1982 levels "154l_aa","1A0P_aa",..: 1 1 1 1 1 1 1 1 1 1 ...
  $ aa : Factor w/ 19 levels "ALA","ARG","ASN",..: 2 16 4 5 18 3 19 3 2 9 ...
  $ as : num  152.0  15.9  65.1  57.2  28.9 ...
  $ ms : num  108.8  28.3  59.2  49.9  31.8 ...
  $ cur: num  -0.1020  0.2564  0.0312 -0.0550  0.0526 ...
  $ sc : num   92.10 103.67   7.27  72.98  96.12 ...
 > attach(p1982)
 > m<-glm(sc~p+aa+as+cur,data=p1982)
Error in model.matrix.default(mt, mf, contrasts) :
         cannot allocate vector of length 932889958
 >



From jmb at mssl.ucl.ac.uk  Tue Dec 12 16:56:19 2006
From: jmb at mssl.ucl.ac.uk (Jenny Barnes)
Date: Tue, 12 Dec 2006 15:56:19 +0000 (GMT)
Subject: [R] how do you interpolate a gaussian grid to a standard 2.5
	degree grid?
Message-ID: <200612121556.kBCFuI1x016519@msslhb.mssl.ucl.ac.uk>

Zhuanshi

Thanks for that! I've never seen that website before and it looks really useful! 
I think those functions look a lot more straight forward than any of the others 
I've seen today in my searching. 

I'll let you know if I get it sorted!

Jenny

>
>Hi Jenny,
>
>Maybe the following links will be useful for you. Both of thoes are
>used in meteorological and climate research community. But u can used
>the codes to create the data values that you need.
>
>
>g2fsh : Interpolates a scalar quantity from a Gaussian grid to a fixed grid.
>
>http://www.ncl.ucar.edu/Document/Functions/Built-in/g2fsh.shtml
>
>
>g2fshv : Interpolates a vector quantity from a Gaussian grid to a fixed grid.
>http://www.ncl.ucar.edu/Document/Functions/Built-in/g2fshv.shtml
>
>
>In addition, both of those functions based on a package named
>SPHEREPACK (http://www.cisl.ucar.edu/css/software/spherepack/ ).
>
>you can write call subroutines shipped from SPHEREPACK to get values
>at your fixed grids.
>
>Good luck.
>
>Zhuanshi He
>
>
>
>On 12/12/06, Jenny Barnes <jmb at mssl.ucl.ac.uk> wrote:
>>
>> Dear R-help community,
>>
>> I have looked on the R search site and archives but cannot find mention of a 
way
>> of interpolating a gaussian distribution of data to a standard 2.5 degree 
grid.
>>
>> I have two global dataset and I need to correlate - unfortunately one is a 
2.5
>> degree grid dim[longitude=144,latitude=72] and one is gaussian
>> dim[longitude=192,latitude=94].
>>
>> I would rally appreciate hearing back from any of you who may have wanted to
>> interpolate your data is this way. If there is no ready-made function you 
know
>> of but you are willing to share your own methods I would also appreciate any
>> pointers.
>>
>> Many thanks for your time,
>>
>> Jenny Barnes
>>
>>
>> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>> Jennifer Barnes
>> PhD student - long range drought prediction
>> Climate Extremes
>> Department of Space and Climate Physics
>> University College London
>> Holmbury St Mary, Dorking
>> Surrey
>> RH5 6NT
>> Web: http://climate.mssl.ucl.ac.uk
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
>
>-- 
>Zhuanshi He / Z. He (PhD)
>Waterloo Centre for Atmospheric Sciences (WCAS)
>Department of Chemistry
>Phy Bldg, Rm 2022
>University of Waterloo,
>Waterloo, ON N2L 3G1
>Canada
>Tel: +1-519-888-4567 ext 38053        FAX: +1-519-746-0435

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Jennifer Barnes
PhD student - long range drought prediction
Climate Extremes
Department of Space and Climate Physics
University College London
Holmbury St Mary, Dorking
Surrey
RH5 6NT
01483 204149
07916 139187
Web: http://climate.mssl.ucl.ac.uk



From bent.nielsen at nuffield.oxford.ac.uk  Tue Dec 12 17:27:03 2006
From: bent.nielsen at nuffield.oxford.ac.uk (Bent Nielsen)
Date: Tue, 12 Dec 2006 16:27:03 +0000
Subject: [R] black and white colormodel for postscript figure
Message-ID: <20061212162703.229649E047@webmail222.herald.ox.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061212/8d6b185f/attachment-0002.pl 

From aiminy at iastate.edu  Tue Dec 12 17:31:30 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Tue, 12 Dec 2006 10:31:30 -0600
Subject: [R] memory.size question
Message-ID: <6.1.2.0.2.20061212103041.01c34df0@aiminy.mail.iastate.edu>

How to deal with this question?

Aimin


 > plot(p1982)
Error: cannot allocate vector of size 3640 Kb
In addition: Warning messages:
1: Reached total allocation of 494Mb: see help(memory.size)
2: Reached total allocation of 494Mb: see help(memory.size)
3: Reached total allocation of 494Mb: see help(memory.size)
4: Reached total allocation of 494Mb: see help(memory.size)
5: Reached total allocation of 494Mb: see help(memory.size)
6: Reached total allocation of 494Mb: see help(memory.size)



From carmei3 at web.de  Tue Dec 12 17:36:45 2006
From: carmei3 at web.de (Carmen Meier)
Date: Tue, 12 Dec 2006 17:36:45 +0100
Subject: [R] par(mfrow ..  how to minimize the interspace
Message-ID: <457EDA9D.90106@web.de>

Is there a possibility to minimize the interspace between the graphs or 
better is it possible to overlap the graphs a little bit?

example from ?lm:

ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group <- gl(2,10,20, labels=c("Ctl","Trt"))
weight <- c(ctl, trt)
anova(lm.D9 <- lm(weight ~ group))
summary(lm.D90 <- lm(weight ~ group - 1))# omitting intercept
summary(resid(lm.D9) - resid(lm.D90)) #- residuals almost identical

opar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
plot(lm.D9, las = 1)      # Residuals, Fitted, ...
par(opar)

 
With regards Carmen



From P.Dalgaard at biostat.ku.dk  Tue Dec 12 17:40:13 2006
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 12 Dec 2006 17:40:13 +0100
Subject: [R] Is my data set too large
In-Reply-To: <6.1.2.0.2.20061212100856.01c05aa8@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061212100856.01c05aa8@aiminy.mail.iastate.edu>
Message-ID: <457EDB6D.9060704@biostat.ku.dk>

Aimin Yan wrote:
> I have a data set like this.
> I want to do glm, but I get this error:
>
> Error in model.matrix.default(mt, mf, contrasts) :
>          cannot allocate vector of length 932889958
>
> I am wondering if my data set is too large or I did something wrong.
>
> Is there some limitation for data size for R?
>
> thanks,
>
> Aimin
>
>
>  > p1982<- read.csv("p_1982_aa.csv")
>  > names(p1982)
> [1] "p"   "aa"  "as"  "ms"  "cur" "sc"
>  > str(p1982)
> 'data.frame':   465979 obs. of  6 variables:
>   $ p  : Factor w/ 1982 levels "154l_aa","1A0P_aa",..: 1 1 1 1 1 1 1 1 1 1 ...
>   $ aa : Factor w/ 19 levels "ALA","ARG","ASN",..: 2 16 4 5 18 3 19 3 2 9 ...
>   $ as : num  152.0  15.9  65.1  57.2  28.9 ...
>   $ ms : num  108.8  28.3  59.2  49.9  31.8 ...
>   $ cur: num  -0.1020  0.2564  0.0312 -0.0550  0.0526 ...
>   $ sc : num   92.10 103.67   7.27  72.98  96.12 ...
>  > attach(p1982)
>  > m<-glm(sc~p+aa+as+cur,data=p1982)
> Error in model.matrix.default(mt, mf, contrasts) :
>          cannot allocate vector of length 932889958
>   

Your "p" is a factor with many levels, so the design matrix for your
model is roughly 500000 x 2000. That gives 1 billion (US) entries of 8
bytes, so you need at least 8 GB just to store the design matrix. So
either you don't want "p" in the model or you have indeed exceeded your
capacity.
>  >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From Greg.Snow at intermountainmail.org  Tue Dec 12 17:44:16 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Tue, 12 Dec 2006 09:44:16 -0700
Subject: [R] hermite and Bezier splines
Message-ID: <07E228A5BE53C24CAD490193A7381BBB6F2FE2@LP-EXCHVS07.CO.IHC.COM>

The grid package does xsplines which can approximate bezier and other
splines, see grid.xspline and xsplineGrob.

Hope this helps, 


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mark Hindell
Sent: Monday, December 11, 2006 2:51 PM
To: r-help at stat.math.ethz.ch
Subject: [R] hermite and Bezier splines

Does anyone know how to do hermite or

Bezier splines in R? I can find Matlab routines, but really need to
implement them in R. Failing that I'd be interested in other conformal
splines. I need to smooth and interpolate animal tracking data.





Antarctic Wildlife Research Unit
School of Zoology
University of Tasmania
PO Box 252-05
Hobart
TAS, 7001
Australia

Phone:  (0)3 6226 2645
Fax:            (0)3 6226 2745


http://www.zoo.utas.edu.au/awru/ 
	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From helprhelp at gmail.com  Tue Dec 12 18:01:53 2006
From: helprhelp at gmail.com (Weiwei Shi)
Date: Tue, 12 Dec 2006 12:01:53 -0500
Subject: [R] implementation of t.test
In-Reply-To: <Pine.LNX.4.64.0612111654140.14753@tajo.ucsd.edu>
References: <cdf817830612111605k58b7b2f3neb5e7fb4c3c50c0c@mail.gmail.com>
	<Pine.LNX.4.64.0612111654140.14753@tajo.ucsd.edu>
Message-ID: <cdf817830612120901m311b8bd1r960ae2a5602052a3@mail.gmail.com>

I think what i want is code in C or Java.  But thanks though.

On 12/11/06, Charles C. Berry <cberry at tajo.ucsd.edu> wrote:
> On Mon, 11 Dec 2006, Weiwei Shi wrote:
>
> > Hi, there:
> >
> > for some reason, I need to look at t.test at coding level. Can anyone
> > here suggest a place to start with?
>
> You mean how to read the code??
>
> Like this:
>
> > t.test # print the function
> function (x, ...)
> UseMethod("t.test")
> <environment: namespace:stats>
> > # that told me 't.test' has S3 methods
> > methods(t.test)
> [1] t.test.default* t.test.formula*
>
>     Non-visible functions are asterisked
> > # that told me what they were
> > # and that I need ':::' to see them
> > page(stats:::t.test.default,"print")
> > page(stats:::t.test.formula,"print")
> > # looks like you want to study t.test.default
>
> see
>         ?methods
>         ?":::"
>
> HTH
>
> > [...]
>
> Charles C. Berry                        (858) 534-2098
>                                           Dept of Family/Preventive Medicine
> E mailto:cberry at tajo.ucsd.edu            UC San Diego
> http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717
>
>
>


-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From ripley at stats.ox.ac.uk  Tue Dec 12 18:26:27 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 12 Dec 2006 17:26:27 +0000 (GMT)
Subject: [R] black and white colormodel for postscript figure
In-Reply-To: <20061212162703.229649E047@webmail222.herald.ox.ac.uk>
References: <20061212162703.229649E047@webmail222.herald.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0612121711410.32380@gannet.stats.ox.ac.uk>

On Tue, 12 Dec 2006, Bent Nielsen wrote:

> I would like to produce simple black and white postscript figures for
> publishing.   A black/white or grayscale or CMYK colormodel can be used, but not
> RGB colours.
>
> Can I produce postscript graphs in R that satisfy this?

Unfortunately not directly: the graphics driver only uses RGB.

However, if the plot only contains 'black and white', it probably actually 
only contains black, indicated by '0 0 0 rgb' (as white is normally 
transparent).  Edit that to '0 setgray'.  If you do have any white, edit
'1 1 1 rgb' to '1 setgray'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Dec 12 18:29:43 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 12 Dec 2006 17:29:43 +0000 (GMT)
Subject: [R] par(mfrow ..  how to minimize the interspace
In-Reply-To: <457EDA9D.90106@web.de>
References: <457EDA9D.90106@web.de>
Message-ID: <Pine.LNX.4.64.0612121726380.32380@gannet.stats.ox.ac.uk>

You want to change the settings of the margins (mar not oma).  Try
mar=c(2.1, 4.1, 2.1, 0) as a starting point.

On Tue, 12 Dec 2006, Carmen Meier wrote:

> Is there a possibility to minimize the interspace between the graphs or
> better is it possible to overlap the graphs a little bit?
>
> example from ?lm:
>
> ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
> trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
> group <- gl(2,10,20, labels=c("Ctl","Trt"))
> weight <- c(ctl, trt)
> anova(lm.D9 <- lm(weight ~ group))
> summary(lm.D90 <- lm(weight ~ group - 1))# omitting intercept
> summary(resid(lm.D9) - resid(lm.D90)) #- residuals almost identical
>
> opar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
> plot(lm.D9, las = 1)      # Residuals, Fitted, ...
> par(opar)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Tue Dec 12 18:28:29 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 12 Dec 2006 18:28:29 +0100
Subject: [R] memory.size question
In-Reply-To: <6.1.2.0.2.20061212103041.01c34df0@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061212103041.01c34df0@aiminy.mail.iastate.edu>
Message-ID: <457EE6BD.20206@statistik.uni-dortmund.de>

See ?Memory and the FAQs as the posting guide suggests to do before 
posting questions.

Uwe Ligges

Aimin Yan wrote:
> How to deal with this question?
> 
> Aimin
> 
> 
>  > plot(p1982)
> Error: cannot allocate vector of size 3640 Kb
> In addition: Warning messages:
> 1: Reached total allocation of 494Mb: see help(memory.size)
> 2: Reached total allocation of 494Mb: see help(memory.size)
> 3: Reached total allocation of 494Mb: see help(memory.size)
> 4: Reached total allocation of 494Mb: see help(memory.size)
> 5: Reached total allocation of 494Mb: see help(memory.size)
> 6: Reached total allocation of 494Mb: see help(memory.size)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Tue Dec 12 18:30:09 2006
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 12 Dec 2006 09:30:09 -0800
Subject: [R] 2 questions
In-Reply-To: <0EE866100C01984EAE6AC3AE56EDFE530C2122@xmail05.ad.ua.ac.be>
Message-ID: <002a01c71e13$2d119f50$4d908980@gne.windows.gene.com>

Warning: Something of a personal rant, clearly reflecting my own hangups,
and having nothing to do with my company or anyone else! A good reason for
most to stop reading now....

While you will find respondents on this list on the whole quite gracious in
their willingness to help newbies learn R, there are limits to this
patience. In particular, questions of the sort below seem to me, at least to
be clear announcements that the original poster has **not** read the posting
guide, nor has made an honest attempt to learn R by studying what I think is
quite good basic documentation (see, for example, "An Introduction to R";
CRAN lists many more similar resources). While I grant that sometimes the
online help is a bit terse, I don't think that anyone who has made an honest
attempt to read the basic docs would ask such questions. If I am wrong in
this, I apologize. But, if not, then I consider the questions unworthy of my
time to respond to. Whether right or wrong, queries posted in a way that
conveys that impression are less likely to elicit good replies. I guess the
moral is that on this list anyway, good behavior is rewarded, and bad
behavior is ignored.

Cheers,
Bert Gunter

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Van Campenhout Bjorn
Sent: Tuesday, December 12, 2006 7:51 AM
To: r-help
Cc: Timothy.Mak at iop.kcl.ac.uk
Subject: Re: [R] 2 questions

>Hi!

>> I'm new here. Want to ask two possibly quite basic questions:
>>
>> 1. How can I clear all objects in one stroke?

>how about

>rm(ls())

try

rm(list=ls())


Bjorn
> 2. How can I perform a regression with independent variables specified by
> an object?

Dh, no spontaneous idea.

Greetings,

Sebastian

>
> Thanks,
>
> Tim
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From K.Boughey at uea.ac.uk  Tue Dec 12 19:07:09 2006
From: K.Boughey at uea.ac.uk (K.Boughey at uea.ac.uk)
Date: Tue, 12 Dec 2006 18:07:09 -0000 (GMT)
Subject: [R] Calculating AICc using conditional logistic regression
Message-ID: <1864.139.222.99.29.1165946829.squirrel@ueawebmail.uea.ac.uk>

I have a case-control study that I'm analysing using the conditional
logistic regression function clogit from the survival package.

I would like to calculate the AICc of the models I fit using clogit.

I have a variety of scripts that can calculate AICc for models with a
logLik method, but clogit does not appear to use this method.

Is there a way I can calculate AICc from clogit in R?

Many thanks,
Katherine Boughey

-- 
School of Environmental Sciences
University of East Anglia
Norwich
NR4 7TJ


From alex at transitive.com  Tue Dec 12 19:17:46 2006
From: alex at transitive.com (Alex Brown)
Date: Tue, 12 Dec 2006 18:17:46 +0000
Subject: [R] missing factor levels in a lattice barchart panel cause
	unexpected failure
In-Reply-To: <36BC5C60-1632-4E36-8005-2BA11AF449C5@transitive.com>
References: <36BC5C60-1632-4E36-8005-2BA11AF449C5@transitive.com>
Message-ID: <C62F5EC7-BEE1-4B2B-82CF-D205F25ED0EE@transitive.com>

I think I've found the problem, and a sort of fix, for this issue.

It appears in the panel.barchart function

each of the clauses in the function has a set of lines roughly like:

             groups <- as.numeric(groupSub(groups, ...))
             vals <- sort(unique(groups))
             nvals <- length(vals)
             col <- rep(col, length = nvals)
             border <- rep(border, length = nvals)
             lty <- rep(lty, length = nvals)
             lwd <- rep(lwd, length = nvals)
             height <- box.ratio/(1 + nvals * box.ratio)
             if (reference)
                 panel.abline(v = origin, col = reference.line$col,
                   lty = reference.line$lty, lwd = reference.line$lwd)
             for (i in unique(y)) {
                 ok <- y == i
                 nok <- sum(ok, na.rm = TRUE)
                 panel.rect(x = rep(origin, nok), y = (i + height *
                   (groups[ok] - (nvals + 1)/2)), col = col[groups[ok]],
                   border = border[groups[ok]], lty = lty[groups[ok]],
                   lwd = lwd[groups[ok]], height = rep(height,
                     nok), width = x[ok] - origin, just = c("left",
                     "centre"))
             }

Which sets the parameter lty (and others) to NA in the example below.

> D = data.frame(X=1, Y=factor(letters[2], letters[1:2]))
> barchart(~ X, D, groups=Y)

This (NA) is because:

groups=[1] b
Levels: a b

thus the code then does

groups==2
vals==2
nvals==1
ok==TRUE

hence

groups[ok] == 2

but

length(lwd) == 1

thus

lwd[groups[ok]] == lwd[2] == NA

This is due to the mistaken assumption that the numeric component of  
groups must be a subset of the 1:length(groups), when in fact it can  
be a subset of 1:length(levels(groups)).


a silly fix:
----

replacing

             groups <- as.numeric(groupSub(groups, ...))
             vals <- sort(unique(groups))
             nvals <- length(vals)

with

             nvals <- length(levels(groups))
             groups <- as.numeric(groupSub(groups, ...))

fixes my example, but it clearly short of a full solution.

This example causes the same error, with a different situation.

Q = data.frame(X=c(NaN, 1), Y=factor(letters[1:2], letters[1:2]))
barchart(~ X, Q, groups=Y)

-Alex Brown

panel.barchart.fixed =
function (x, y, box.ratio = 1, horizontal = TRUE, origin = NULL,
     reference = TRUE, stack = FALSE, groups = NULL, col = if (is.null 
(groups)) plot.polygon$col else superpose.polygon$col,
     border = if (is.null(groups)) plot.polygon$border else  
superpose.polygon$border,
     lty = if (is.null(groups)) plot.polygon$lty else  
superpose.polygon$lty,
     lwd = if (is.null(groups)) plot.polygon$lwd else  
superpose.polygon$lwd,
     ...)
{
     if (!is.null(groups) && !is.factor(groups))
         groups <- factor(groups)
     keep <- (function(x, y, groups, subscripts, ...) {
         !is.na(x) & !is.na(y) & if (is.null(groups))
             TRUE
         else !is.na(groups[subscripts])
     })(x = x, y = y, groups = groups, ...)
     if (!any(keep))
         return()
     x <- as.numeric(x[keep])
     y <- as.numeric(y[keep])
     plot.polygon <- trellis.par.get("plot.polygon")
     superpose.polygon <- trellis.par.get("superpose.polygon")
     reference.line <- trellis.par.get("reference.line")
     groupSub <- function(groups, subscripts, ...) groups[subscripts 
[keep]]
     if (horizontal) {
         if (is.null(groups)) {
             if (is.null(origin)) {
                 origin <- current.panel.limits()$xlim[1]
                 reference <- FALSE
             }
             height <- box.ratio/(1 + box.ratio)
             if (reference)
                 panel.abline(v = origin, col = reference.line$col,
                   lty = reference.line$lty, lwd = reference.line$lwd)
             panel.rect(x = rep(origin, length(y)), y = y, height =  
rep(height,
                 length(y)), width = x - origin, border = border,
                 col = col, lty = lty, lwd = lwd, just = c("left",
                   "centre"))
         }
         else if (stack) {
             if (!is.null(origin) && origin != 0)
                 warning("origin forced to 0 for stacked bars")
             nvals <- length(levels(groups))
             groups <- as.numeric(groupSub(groups, ...))
             col <- rep(col, length = nvals)
             border <- rep(border, length = nvals)
             lty <- rep(lty, length = nvals)
             lwd <- rep(lwd, length = nvals)
             height <- box.ratio/(1 + box.ratio)
             if (reference)
                 panel.abline(v = origin, col = reference.line$col,
                   lty = reference.line$lty, lwd = reference.line$lwd)
             for (i in unique(y)) {
                 ok <- y == i
                 ord <- sort.list(groups[ok])
                 pos <- x[ok][ord] > 0
                 nok <- sum(pos, na.rm = TRUE)
                 if (nok > 0)
                   panel.rect(x = cumsum(c(0, x[ok][ord][pos][-nok])),
                     y = rep(i, nok), col = col[groups[ok][ord][pos]],
                     border = border[groups[ok][ord][pos]], lty = lty 
[groups[ok][ord][pos]],
                     lwd = lwd[groups[ok][ord][pos]], height = rep 
(height,
                       nok), width = x[ok][ord][pos], just = c("left",
                       "centre"))
                 neg <- x[ok][ord] < 0
                 nok <- sum(neg, na.rm = TRUE)
                 if (nok > 0)
                   panel.rect(x = cumsum(c(0, x[ok][ord][neg][-nok])),
                     y = rep(i, nok), col = col[groups[ok][ord][neg]],
                     border = border[groups[ok][ord][neg]], lty = lty 
[groups[ok][ord][neg]],
                     lwd = lwd[groups[ok][ord][neg]], height = rep 
(height,
                       nok), width = x[ok][ord][neg], just = c("left",
                       "centre"))
             }
         }
         else {
             if (is.null(origin)) {
                 origin <- current.panel.limits()$xlim[1]
                 reference <- FALSE
             }
             nvals <- length(levels(groups))
             groups <- as.numeric(groupSub(groups, ...))
             col <- rep(col, length = nvals)
             border <- rep(border, length = nvals)
             lty <- rep(lty, length = nvals)
             lwd <- rep(lwd, length = nvals)
             height <- box.ratio/(1 + nvals * box.ratio)
             if (reference)
                 panel.abline(v = origin, col = reference.line$col,
                   lty = reference.line$lty, lwd = reference.line$lwd)
             for (i in unique(y)) {
                 ok <- y == i
                 nok <- sum(ok, na.rm = TRUE)
                 panel.rect(x = rep(origin, nok), y = (i + height *
                   (groups[ok] - (nvals + 1)/2)), col = col[groups[ok]],
                   border = border[groups[ok]], lty = lty[groups[ok]],
                   lwd = lwd[groups[ok]], height = rep(height,
                     nok), width = x[ok] - origin, just = c("left",
                     "centre"))
             }
         }
     }
     else {
         if (is.null(groups)) {
             if (is.null(origin)) {
                 origin <- current.panel.limits()$ylim[1]
                 reference <- FALSE
             }
             width <- box.ratio/(1 + box.ratio)
             if (reference)
                 panel.abline(h = origin, col = reference.line$col,
                   lty = reference.line$lty, lwd = reference.line$lwd)
             panel.rect(x = x, y = rep(origin, length(x)), col = col,
                 border = border, lty = lty, lwd = lwd, width = rep 
(width,
                   length(x)), height = y - origin, just = c("centre",
                   "bottom"))
         }
         else if (stack) {
             if (!is.null(origin) && origin != 0)
                 warning("origin forced to 0 for stacked bars")

	       nvals <- length(levels(groups))
             groups <- as.numeric(groupSub(groups, ...))
             col <- rep(col, length = nvals)
             border <- rep(border, length = nvals)
             lty <- rep(lty, length = nvals)
             lwd <- rep(lwd, length = nvals)
             width <- box.ratio/(1 + box.ratio)
             if (reference)
                 panel.abline(h = origin, col = reference.line$col,
                   lty = reference.line$lty, lwd = reference.line$lwd)
             for (i in unique(x)) {
                 ok <- x == i
                 ord <- sort.list(groups[ok])
                 pos <- y[ok][ord] > 0
                 nok <- sum(pos, na.rm = TRUE)
                 if (nok > 0)
                   panel.rect(x = rep(i, nok), y = cumsum(c(0,
                     y[ok][ord][pos][-nok])), col = col[groups[ok] 
[ord][pos]],
                     border = border[groups[ok][ord][pos]], lty = lty 
[groups[ok][ord][pos]],
                     lwd = lwd[groups[ok][ord][pos]], width = rep(width,
                       nok), height = y[ok][ord][pos], just = c 
("centre",
                       "bottom"))
                 neg <- y[ok][ord] < 0
                 nok <- sum(neg, na.rm = TRUE)
                 if (nok > 0)
                   panel.rect(x = rep(i, nok), y = cumsum(c(0,
                     y[ok][ord][neg][-nok])), col = col[groups[ok] 
[ord][neg]],
                     border = border[groups[ok][ord][neg]], lty = lty 
[groups[ok][ord][neg]],
                     lwd = lwd[groups[ok][ord][neg]], width = rep(width,
                       nok), height = y[ok][ord][neg], just = c 
("centre",
                       "bottom"))
             }
         }
         else {
             if (is.null(origin)) {
                 origin <- current.panel.limits()$ylim[1]
                 reference = FALSE
             }
             nvals <- length(levels(groups))

             groups <- as.numeric(groupSub(groups, ...))
             col <- rep(col, length = nvals)
             border <- rep(border, length = nvals)
             lty <- rep(lty, length = nvals)
             lwd <- rep(lwd, length = nvals)
             width <- box.ratio/(1 + nvals * box.ratio)
             if (reference)
                 panel.abline(h = origin, col = reference.line$col,
                   lty = reference.line$lty, lwd = reference.line$lwd)
             for (i in unique(x)) {
                 ok <- x == i
                 nok <- sum(ok, na.rm = TRUE)
                 panel.rect(x = (i + width * (groups[ok] - (nvals +
                   1)/2)), y = rep(origin, nok), col = col[groups[ok]],
                   border = border[groups[ok]], lty = lty[groups[ok]],
                   lwd = lwd[groups[ok]], width = rep(width, nok),
                   height = y[ok] - origin, just = c("centre",
                     "bottom"))
             }
         }
     }
}


On 8 Dec 2006, at 12:27, Alex Brown wrote:

> Hi all - I'm trying to generate lattice barchart graphs with missing
> values, and came across the following:
>
> This does not run.  I would expect it to:
>
> library(lattice)
> D = data.frame(X=1, Y=factor(letters[2], letters[1:2]))
> barchart(~ X, D, groups=Y)
>
> Error in grid.Call.graphics("L_rect", x$x, x$y, x$width, x$height,
> resolveHJust(x$just,  :
> 	invalid line type
>
> which is simply solved by changing the factor levels:
>
> D$Y = factor(D$Y)
> barchart(~ X, D, groups=Y)
>
> or by filling factor levels from the bottom:
>
> D = data.frame(X=1, Y=factor(letters[1], letters[1:2]))
> barchart(~ X, D, groups=Y)
>
> However, the failure is important, because it causes the following to
> fail, no matter how Y is levelled
>
> E = data.frame(X=c(1,2,3,4), Y=factor(letters[c(1,2,1,2)], letters
> [1:2]), Z=factor(c("F","F","G","H")));
> barchart(~ X | Z, E, groups=Y)
>
> Which is an example of a comparison over multiple tests Z for
> different parameter Y where some Y are missing.
>
> alternative version:
>
> E = data.frame(X=c(1,2,3,4), Y=letters[c(1,2,1,2)], Z=letters[c
> (7,7,8,9)]);
> barchart(~ X | Z, E, groups=Y)
>
> I have updated to 2.4.0 and lattice 0.14-16 and the problem still
> exists.
>
> -Alex Brown
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kevin.thorpe at utoronto.ca  Tue Dec 12 19:22:47 2006
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Tue, 12 Dec 2006 13:22:47 -0500
Subject: [R] Sweave, Xfig, pdflatex and \setkeys
In-Reply-To: <1165919873.4758.18.camel@lesopriv3.epfl.ch>
References: <1165919873.4758.18.camel@lesopriv3.epfl.ch>
Message-ID: <457EF377.2010805@utoronto.ca>

David Lindel?f wrote:
> Dear useRs,
> 
> How does one include graphics created with Xfig with LaTeX fonts into
> Sweave?
> 
> If I create a graphic with Xfig with some Computer Modern fonts, I
> choose to export it as combined PDF and LaTeX. So I get two files, one
> foo.pdf with the drawings without the text and foo.pdftex with some
> LaTeX code that ensures the text lands in the right place together with
> the drawing. I'm supposed to \input{} this file in my LaTeX document.
> 
> Trouble is that Sweave defines (with \setkeys) the default width of
> \includegraphics to be 0.8 times the \textwidth. The result is that the
> graphic is scaled, but not the text.
> 
> I was looking for a way to temporarily undefine the default width of
> included graphics, but without success. Does anyone know how to undo a
> definition that has been set with \setkeys?
> 
> Or does anyone has another workaround for including xfig graphics with
> LaTeX text in Sweave?
> 
> Looking forward to your help,

If you knew what setting you needed, you could try

\setkeys{Gin}{width=whatever}

before your include, and set it back to the default afterward with

\setkeys{Gin}{width=0.8\textwidth}

I have run into this myself, but since I was also using beamer, it
wasn't at all obvious what I should try for the setting, so I don't
know if this will work.  I have used this to rescale the imported
graphics from R.  Fortunately, the graphic I created in xfig could
be completely specified in LaTeX, and so I exported it in that format
and imported it with \scalebox{0.5}{\input{xfigfile.latex}}

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Department of Public Health Sciences
Faculty of Medicine, University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.6057


From tariq.khan at gmail.com  Tue Dec 12 19:27:26 2006
From: tariq.khan at gmail.com (=?ISO-8859-1?Q?=A8Tariq_Khan?=)
Date: Tue, 12 Dec 2006 18:27:26 +0000
Subject: [R] S4 'properties' - creating 'slot' functions?
Message-ID: <2310043c0612121027h492587c3v92a2d1b66cd6b3aa@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061212/5efaede2/attachment.pl 

From tariq.khan at gmail.com  Tue Dec 12 19:30:01 2006
From: tariq.khan at gmail.com (=?ISO-8859-1?Q?=A8Tariq_Khan?=)
Date: Tue, 12 Dec 2006 18:30:01 +0000
Subject: [R] S4 property slots as functions?
Message-ID: <2310043c0612121030y21d0ba2bp8a9dde79f7847142@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061212/0688e9bb/attachment.pl 

From Greg.Snow at intermountainmail.org  Tue Dec 12 19:43:00 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Tue, 12 Dec 2006 11:43:00 -0700
Subject: [R] par(mfrow ..  how to minimize the interspace
Message-ID: <07E228A5BE53C24CAD490193A7381BBB7395C4@LP-EXCHVS07.CO.IHC.COM>

If you really want to overlap the graphs, then look at the subplot
function in the TeachingDemos package (you would first need to create a
blank graph with no or minimal margins, then use subplot to place your
graphs within the blank graph).

You may also want to look at the lattice package for doing arrays of
graphs with the graph boxes aligning and axes only on the outer plots. 


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Carmen Meier
Sent: Tuesday, December 12, 2006 9:37 AM
To: R-help
Subject: [R] par(mfrow .. how to minimize the interspace

Is there a possibility to minimize the interspace between the graphs or
better is it possible to overlap the graphs a little bit?

example from ?lm:

ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group <- gl(2,10,20, labels=c("Ctl","Trt")) weight <- c(ctl, trt)
anova(lm.D9 <- lm(weight ~ group))
summary(lm.D90 <- lm(weight ~ group - 1))# omitting intercept
summary(resid(lm.D9) - resid(lm.D90)) #- residuals almost identical

opar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
plot(lm.D9, las = 1)      # Residuals, Fitted, ...
par(opar)

 
With regards Carmen

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From arsenije at ist.utl.pt  Tue Dec 12 20:15:50 2006
From: arsenije at ist.utl.pt (Vladan Arsenijevic)
Date: Tue, 12 Dec 2006 19:15:50 +0000
Subject: [R] wavethrash
Message-ID: <1165950950.457effe647289@oldmail.ist.utl.pt>


Hi all!
Changing boundary conditions (bc) from "periodic" to "symmetric" in wd (discrete
wavelet transform function) results in increasing of number of wavelet
coefficients. I have a set of 1024 points (i.e. 10 resolution levels), so
instead of 1023 (like in "periodic" case) wavelet coefficients I get 1079.
On the other hand, accessD gives me the right number of coefficient per level,
but the values differ from wd$D (those coefficients are the same in "periodic"
case whether we call wd$D or accessD).
Does anyone have an explanation?
Cheers!


From mtmorgan at fhcrc.org  Tue Dec 12 20:24:13 2006
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 12 Dec 2006 11:24:13 -0800
Subject: [R] S4 'properties' - creating 'slot' functions?
In-Reply-To: <2310043c0612121027h492587c3v92a2d1b66cd6b3aa@mail.gmail.com> 
	=?iso-8859-1?q?=28=A8Tariq?= Khan's message of "Tue,
	12 Dec 2006 18:27:26 +0000")
References: <2310043c0612121027h492587c3v92a2d1b66cd6b3aa@mail.gmail.com>
Message-ID: <6phejr4c3z6.fsf@gopher4.fhcrc.org>

Hi Tariq

Some discussion of this topic a while ago on the R-devel newsgroup;
bottom line is that there is no consensus and a certain amount of
resistance to make R conform to the implementation of other languages
(and not exploit R's unique strengths).

https://stat.ethz.ch/pipermail/r-devel/2006-September/042854.html
https://stat.ethz.ch/pipermail/r-devel/2006-September/042864.html

You could implement something fancier (e.g., a method for "$" or "[["
or "@" or a suite of generics "get_x"), but I kind of like (because
'slot' is a function with a well-defined purpose, so why not make it a
generic?)

setGeneric("slot")

setMethod("slot",
          signature=signature(object="A", name="character"),
          function(object, name)
          ## do anything, e.g., restrict access to specific slots
          ## alternatively, dispatch on name with 'switch'
          if (name %in% slotNames(class(object))) callNextMethod()
          else stop("slot '", name, "' undefined"))

setGeneric("slot<-",
           signature=c("object", "name", "value"))

setReplaceMethod("slot",
                 signature(object="A", name="character", value="ANY"),
                 function(object, name, check=TRUE, value)
                 if (name %in% slotNames(class(object))) callNextMethod()
                 else stop("slot '", name, "' cannot be assigned"))

and then

> setClass("A",
+          representation=representation(x="numeric"))
[1] "A"
> a <- new("A", x=1:5)
> slot(a, "y")
Error in slot(a, "y") : slot 'y' undefined
> slot(a, "x") <- 5:1
> slot(a, "x")
[1] 5 4 3 2 1

A class could be defined to implement the dispatch, so other classes
just have to inherit from that.

Discussion may be veering toward the R-devel newsgroup.

Martin

"?Tariq Khan" <tariq.khan at gmail.com> writes:

> Dear R users!
>
> Several languages like C# or VB allow one to create properties; typically
> these are under 'get', 'set' tags. My question is this really, what are
> similar or comparable strategies in R, and what might be preferred? I have a
> couple of situations where I want a certain computation to belong to a
> class, but I do not really want to seperate it out to a stand-alone
> function.
>
> Here are a couple of options I see possible in R, and if I use the last
> described option (see option C below), is there a way to access the object
> with something like in C# or C++ where one would probably use the 'this'
> keyword or the 'me' keyword in VB from within the property?:
>
> A) MyObject at Property is static and must be handled carefully if it depends
> on other slots of the class. If one of the slots changes, then because this
> slot is static (containing only the value), it will not change to reflect
> the update.
>
> B) MyObject at Property is deprecated, and special accessor functions are used.
> The bio group seems to favor this option. So one would use:
> Property(MyObject). The drawback I see with this is that there is no strong
> relationship between Property and MyObject; they are not explicitly related
> via a class structure, and in some way this defeats the point of class
> structures.
>
> C) Let MyObject at Property be a function, so in order to fetch the slot object
> we would use MyObject at Property(); the question here is can I use something
> like a 'this' keyword to access other slots of thr object without having to
> pass the whole class as a parameter to this slot function, ie the
> round-about, clumsy way would have to look like MyObject at Property(MyObject).
> Ideally, the pseudo-code I have in mind might look like this for an object
> with two slots (A and B)
>
> Object at A = function() return(.this at B)
>
>
> Thoughts and considerations would be very interesting.
>
> -Tariq
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Martin T. Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From kbenoit at tcd.ie  Tue Dec 12 20:38:41 2006
From: kbenoit at tcd.ie (Kenneth Benoit)
Date: Tue, 12 Dec 2006 19:38:41 +0000
Subject: [R] help on determining operating system
In-Reply-To: <Pine.LNX.4.64.0612112125160.26701@sobek.colorado.edu>
References: <Pine.LNX.4.64.0612112125160.26701@sobek.colorado.edu>
Message-ID: <457F0541.9040701@tcd.ie>

Hi - I don't want to ignite any holy wars, but for 10 years until last 
year I used Linux, I occasionally use a Windows machine at home, and 
last year switched to Mac OS.  Of all the GUIs for R out there, the mac 
is the best by far IMHO.  And R on my macbook is faster than on a 
pentium 4 3.2GHz running either linux or win xp.

Ken

LU YING wrote:
> Dear list,
> 
> I am an R user and I also write my own package in R(sometime i need to 
> write  in C), and right now i am thinking about buying a new 
> workstation--and i am trying to decide if i should get 
> a mac with OS X or a linux machine (for example Dell).
> 
> I have experience using R on linux (but i have been just a user and never 
> been a admin) but i am hesitating of managing a linux system on my own 
> (btw I would like to have my new workstation to be used as a server), so 
> right now I am leaning toward of buying a Mac Pro. But from the website, 
> it sounds like R doesnt work quite well with Mac operating system 
> yet...so I was wondering if anybody here have any experiences of 
> using/developing R package on a Mac machine? Is it smooth enough?
> 
> (oh by the way, i am not a Mac user yet, Windows has been the primary 
> operating system that i used, but after hearing many good things 
> of OS X, I am really interested in switching over.)
> 
> any suggestions are appreciated!
> 
> Ying
> 
> 
> Ying Lu
> Assistant Professor
> Dept. Sociology
> U-Colorado at Boulder
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Kenneth Benoit
Associate Professor of Political Science
Department of Political Science, Trinity College
Dublin 2, Ireland
http://benoit.tcd.ie
Tel: 353-1-608-2491
Fax: 353-1-677-0546


From HDoran at air.org  Tue Dec 12 20:46:56 2006
From: HDoran at air.org (Doran, Harold)
Date: Tue, 12 Dec 2006 14:46:56 -0500
Subject: [R] help on determining operating system
Message-ID: <2323A6D37908A847A7C32F1E3662C80E6B0AFE@dc1ex01.air.org>

BTW, Mac OS sits on the Darwin unix system. So, you have all the
benefits of Mac and can access unix via the terminal (Steve Jobs is
brilliant). Things like emacs are waiting for you to use on the Mac. I
haven't explored whether one can install R on the Mac and use it via the
unix interface (or whether there is any reason to do so).

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Kenneth Benoit
> Sent: Tuesday, December 12, 2006 2:39 PM
> To: LU YING
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] help on determining operating system
> 
> Hi - I don't want to ignite any holy wars, but for 10 years 
> until last year I used Linux, I occasionally use a Windows 
> machine at home, and last year switched to Mac OS.  Of all 
> the GUIs for R out there, the mac is the best by far IMHO.  
> And R on my macbook is faster than on a pentium 4 3.2GHz 
> running either linux or win xp.
> 
> Ken
> 
> LU YING wrote:
> > Dear list,
> > 
> > I am an R user and I also write my own package in 
> R(sometime i need to 
> > write  in C), and right now i am thinking about buying a new 
> > workstation--and i am trying to decide if i should get 
> > a mac with OS X or a linux machine (for example Dell).
> > 
> > I have experience using R on linux (but i have been just a 
> user and never 
> > been a admin) but i am hesitating of managing a linux 
> system on my own 
> > (btw I would like to have my new workstation to be used as 
> a server), so 
> > right now I am leaning toward of buying a Mac Pro. But from 
> the website, 
> > it sounds like R doesnt work quite well with Mac operating system 
> > yet...so I was wondering if anybody here have any experiences of 
> > using/developing R package on a Mac machine? Is it smooth enough?
> > 
> > (oh by the way, i am not a Mac user yet, Windows has been 
> the primary 
> > operating system that i used, but after hearing many good things 
> > of OS X, I am really interested in switching over.)
> > 
> > any suggestions are appreciated!
> > 
> > Ying
> > 
> > 
> > Ying Lu
> > Assistant Professor
> > Dept. Sociology
> > U-Colorado at Boulder
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > 
> 
> 
> -- 
> Kenneth Benoit
> Associate Professor of Political Science
> Department of Political Science, Trinity College
> Dublin 2, Ireland
> http://benoit.tcd.ie
> Tel: 353-1-608-2491
> Fax: 353-1-677-0546
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From cberry at tajo.ucsd.edu  Tue Dec 12 20:49:45 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Tue, 12 Dec 2006 11:49:45 -0800
Subject: [R] Calculating AICc using conditional logistic regression
In-Reply-To: <1864.139.222.99.29.1165946829.squirrel@ueawebmail.uea.ac.uk>
References: <1864.139.222.99.29.1165946829.squirrel@ueawebmail.uea.ac.uk>
Message-ID: <Pine.LNX.4.64.0612121133470.24112@tajo.ucsd.edu>

On Tue, 12 Dec 2006, K.Boughey at uea.ac.uk wrote:

> I have a case-control study that I'm analysing using the conditional
> logistic regression function clogit from the survival package.
>
> I would like to calculate the AICc of the models I fit using clogit.
>
> I have a variety of scripts that can calculate AICc for models with a
> logLik method, but clogit does not appear to use this method.
>
> Is there a way I can calculate AICc from clogit in R?

Review

 	?logLik
 	?coxph.object

and then roll your own logLik.coxph.

Here is one version:

logLik.coxph <-
     function(object,...) {
         y <-  -1 * (object$loglik[1] - object$loglik[2])
         class(y) <- "logLik"
         attr(y,'df')<- sum(!is.na(object$coef))
         y
}

Try it like this:
> fit <- clogit(case ~ spontaneous + induced + strata(stratum), data = 
infert)
> logLik(fit)
'log Lik.' 26.57712 (df=2)
>

[...]

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717


From p.murrell at auckland.ac.nz  Tue Dec 12 20:58:27 2006
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 13 Dec 2006 08:58:27 +1300
Subject: [R] a web interface to identify()
In-Reply-To: <895C31EE-2EBE-4C75-8D72-9E79BD88F8F9@sandia.gov>
References: <895C31EE-2EBE-4C75-8D72-9E79BD88F8F9@sandia.gov>
Message-ID: <457F09E3.9010607@stat.auckland.ac.nz>

Hi


Jon Stearley wrote:
> i have a function like this:
>   # show a plot and run a script when the user clicks on a plot,
>   # where the script arguments correspond to the user-selected point.
>   blah <- function(x, y) {
>     plot(y~x)
>     n <- identify(x=x, y=y)
>     com <- system(command=paste("bleh", names(y)[n]))
>   }
> 
> i would like to do this via a web page instead of x11() etc.  eg:
>   1) a user clicks on an image in their web browser
>   2) the i,j coordinate is sent to the server
>   3) a single R process determines the nearest data point
>   4) the server sends a new page to the client, based on attributes  
> of the selected data point
> 
> i've browsed the R web interface options and frankly don't know which  
> to pick, or maybe they are all overkill for what i am trying to  
> accomplish?  perhaps the easiest thing to do is use ismap to capture  
> the i,j coords, the receiving cgi script connects to an R process for  
> the data lookup, and then responds to the browsing client  
> appropriately.  the data set involved is very large, so i'd need a  
> single R process sitting there waiting for such queries in order to  
> avoid initialize&load time - this is the part i am particularly  
> unclear how to do.
> 
> any ideas/suggestions/guidance on the best approach would be much  
> appreciated.  thank you.


Maybe Barry Rowlingson's imagemap is all you need?
http://www.maths.lancs.ac.uk/Software/Imagemap/

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From jropers at freesurf.Fr  Tue Dec 12 21:13:16 2006
From: jropers at freesurf.Fr (jropers@freesurf.fr)
Date: Tue, 12 Dec 2006 21:13:16 +0100
Subject: [R] ifelse question
Message-ID: <457F0D5C.8040908@freesurf.Fr>

Dear R-helpers,
How come that in the following code the rnorm() function is evaluated only once for each branch of the 'ifelse' ? 

x <- rnorm(10)
y1 <- ifelse(x > 0, rnorm(1) ,  rnorm(1))


What is the right way to make it called/evaluated for each row, apart from a 'for' loop ?

Thanks, 

Jacques.


From goran.brostrom at gmail.com  Tue Dec 12 21:18:26 2006
From: goran.brostrom at gmail.com (=?UTF-8?Q?G=C3=B6ran_Brostr=C3=B6m?=)
Date: Tue, 12 Dec 2006 21:18:26 +0100
Subject: [R] Segfault in pure R code
Message-ID: <148ed8180612121218pea45e0agcdb39a8b9fe9ff43@mail.gmail.com>

I just caught a segfault:

> courses("Ingrid")

 *** caught segfault ***
address 0x99b279c, cause 'memory not mapped'

Traceback:
 1: structure(y, class = oldClass(x), row.names = attr(x, "row.names"))
 2: `[.data.frame`(gudata, -(1:5))
 3: gudata[-(1:5)]
 4: names(gudata[-(1:5)])
 5: inherits(x, "factor")
 6: is.factor(table)
 7: match(x, table, nomatch = 0)
 8: who %in% names(gudata[-(1:5)])
 9: courses("Ingrid")

when running a function 'courses' in an R package without compiled
code. Is this "possible"? I have got many segfaults when testing my
own packages, but it has always been caused by stupidities in C or
Fortran code, never with pure R code.

So, before I start debugging, I'd like to know if a segfault in pure R
code indicates  a bug in R itself, or if it can be in my function?

I have used 'courses' many times before without problems.

Thanks,

G?ran
++++++++++++++++++++++++++++++++++++++
> sessionInfo()
R version 2.4.0 Patched (2006-10-29 r39744)
i686-pc-linux-gnu


-- 
G?ran Brostr?m


From jropers at freesurf.Fr  Tue Dec 12 21:24:16 2006
From: jropers at freesurf.Fr (jropers@freesurf.fr)
Date: Tue, 12 Dec 2006 21:24:16 +0100
Subject: [R] ifelse question
Message-ID: <457F0FF0.1090305@freesurf.Fr>

Dear R-helpers,
How come that in the following code the rnorm() function is evaluated 
only once for each branch of the 'ifelse' ?

x <- rnorm(10)
y1 <- ifelse(x > 0, rnorm(1) ,  rnorm(1))

What is the right way to make it called/evaluated for each row, apart 
from a 'for' loop ?

Thanks,
Jacques.


From Mark.Leeds at morganstanley.com  Tue Dec 12 21:27:18 2006
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Tue, 12 Dec 2006 15:27:18 -0500
Subject: [R] ifelse question
In-Reply-To: <457F0D5C.8040908@freesurf.Fr>
Message-ID: <D3AEEDA31E57474B840BEBC25A8A8344F39165@NYWEXMB23.msad.ms.com>

ifelse is vectorized but there is no way you could know what's
happening with that command
 because you have rnorm(1) for both conditions. I think you mean to have
something different in one of them ?

Whewn I run your code in my R session, I get 10 values for y1, so there
isn't anything wrong except
That you have the same statement for both cases.




-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
jropers at freesurf.fr
Sent: Tuesday, December 12, 2006 3:13 PM
To: r-help at stat.math.ethz.ch
Subject: [R] ifelse question

Dear R-helpers,
How come that in the following code the rnorm() function is evaluated
only once for each branch of the 'ifelse' ? 

x <- rnorm(10)
y1 <- ifelse(x > 0, rnorm(1) ,  rnorm(1))


What is the right way to make it called/evaluated for each row, apart
from a 'for' loop ?

Thanks, 

Jacques.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From matthew_wiener at merck.com  Tue Dec 12 21:33:16 2006
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Tue, 12 Dec 2006 15:33:16 -0500
Subject: [R] help on determining operating system  [Broadcast]
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E6B0AFE@dc1ex01.air.org>
Message-ID: <4E9A692D8755DF478B56A2892388EE1F01546389@usctmx1118.merck.com>

You can indeed compile and run R directly through the unix layer in Mac
OS (or at least you could about 2 years ago, which was the last time I
tried).

Regards,

Matt Wiener 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Doran, Harold
Sent: Tuesday, December 12, 2006 2:47 PM
To: Kenneth Benoit; LU YING
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] help on determining operating system [Broadcast]

BTW, Mac OS sits on the Darwin unix system. So, you have all the
benefits of Mac and can access unix via the terminal (Steve Jobs is
brilliant). Things like emacs are waiting for you to use on the Mac. I
haven't explored whether one can install R on the Mac and use it via the
unix interface (or whether there is any reason to do so).

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Kenneth Benoit
> Sent: Tuesday, December 12, 2006 2:39 PM
> To: LU YING
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] help on determining operating system
> 
> Hi - I don't want to ignite any holy wars, but for 10 years 
> until last year I used Linux, I occasionally use a Windows 
> machine at home, and last year switched to Mac OS.  Of all 
> the GUIs for R out there, the mac is the best by far IMHO.  
> And R on my macbook is faster than on a pentium 4 3.2GHz 
> running either linux or win xp.
> 
> Ken
> 
> LU YING wrote:
> > Dear list,
> > 
> > I am an R user and I also write my own package in 
> R(sometime i need to 
> > write  in C), and right now i am thinking about buying a new 
> > workstation--and i am trying to decide if i should get 
> > a mac with OS X or a linux machine (for example Dell).
> > 
> > I have experience using R on linux (but i have been just a 
> user and never 
> > been a admin) but i am hesitating of managing a linux 
> system on my own 
> > (btw I would like to have my new workstation to be used as 
> a server), so 
> > right now I am leaning toward of buying a Mac Pro. But from 
> the website, 
> > it sounds like R doesnt work quite well with Mac operating system 
> > yet...so I was wondering if anybody here have any experiences of 
> > using/developing R package on a Mac machine? Is it smooth enough?
> > 
> > (oh by the way, i am not a Mac user yet, Windows has been 
> the primary 
> > operating system that i used, but after hearing many good things 
> > of OS X, I am really interested in switching over.)
> > 
> > any suggestions are appreciated!
> > 
> > Ying
> > 
> > 
> > Ying Lu
> > Assistant Professor
> > Dept. Sociology
> > U-Colorado at Boulder
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > 
> 
> 
> -- 
> Kenneth Benoit
> Associate Professor of Political Science
> Department of Political Science, Trinity College
> Dublin 2, Ireland
> http://benoit.tcd.ie
> Tel: 353-1-608-2491
> Fax: 353-1-677-0546
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}


From JRSTEAR at sandia.gov  Tue Dec 12 21:35:23 2006
From: JRSTEAR at sandia.gov (Jon Stearley)
Date: Tue, 12 Dec 2006 13:35:23 -0700
Subject: [R] a web interface to identify()
In-Reply-To: <457F09E3.9010607@stat.auckland.ac.nz>
References: <895C31EE-2EBE-4C75-8D72-9E79BD88F8F9@sandia.gov>
	<457F09E3.9010607@stat.auckland.ac.nz>
Message-ID: <603100C2-66ED-4736-8F09-9AE289044739@sandia.gov>


On Dec 12, 2006, at 12:58 PM, Paul Murrell wrote:
>
> Maybe Barry Rowlingson's imagemap is all you need?
> http://www.maths.lancs.ac.uk/Software/Imagemap/

Thank you for that suggestion.  Unfortunately the plots can involve  
hundreds of thousands of points, and our initial tests with imagemap  
indicated that for this many points it takes too long and generates  
too heavy an html document.  So we are looking for a lighter weight  
solution in order to keep the application responsive.  Current  
thought is to use fifo's between cgi scripts and a single persistent  
R process...

-jon


From jropers at freesurf.Fr  Tue Dec 12 21:46:01 2006
From: jropers at freesurf.Fr (jropers@freesurf.fr)
Date: Tue, 12 Dec 2006 21:46:01 +0100
Subject: [R] ifelse question
Message-ID: <457F1509.8080009@freesurf.Fr>

What is puzzling me is that rnorm(1) is only evaluated *twice*, one time 
for each branch, with only 2 different random deviates, instead of 
giving ten different random deviates. y1 has indeed 10 values but with 
only 2 different ones.
I would like to have rnorm be evaluated for each row and collect ten 
*different* random deviates.

y1
 [1] 0.4087172 0.7707796 0.4087172 0.4087172 0.7707796 0.4087172 0.4087172
 [8] 0.7707796 0.7707796 0.4087172


Thanks.

Jacques.


From goran.brostrom at gmail.com  Tue Dec 12 21:46:46 2006
From: goran.brostrom at gmail.com (=?UTF-8?Q?G=C3=B6ran_Brostr=C3=B6m?=)
Date: Tue, 12 Dec 2006 21:46:46 +0100
Subject: [R] ifelse question
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A8344F39165@NYWEXMB23.msad.ms.com>
References: <457F0D5C.8040908@freesurf.Fr>
	<D3AEEDA31E57474B840BEBC25A8A8344F39165@NYWEXMB23.msad.ms.com>
Message-ID: <148ed8180612121246q4c61a263oe8f4dd6052593575@mail.gmail.com>

On 12/12/06, Leeds, Mark (IED) <Mark.Leeds at morganstanley.com> wrote:
> ifelse is vectorized but there is no way you could know what's
> happening with that command
>  because you have rnorm(1) for both conditions. I think you mean to have
> something different in one of them ?
>
> Whewn I run your code in my R session, I get 10 values for y1, so there
> isn't anything wrong except
> That you have the same statement for both cases.

But you got only two (eventually one) distinct values, right? Look at
the code for 'ifelse': yes and no are only called once each, then
recycled to desired length.

I guess you want something like

x <- rnorm(10)
y <- rnorm(10)
z <- rnorm(10)
y1 <- ifelse(x > 0, y, z)

but this whole business is probabilistically the same as

x <- rnorm(10)
y1 <- rnorm(10)

which of course is faster and more transparent.

G?ran
>
>
>
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
> jropers at freesurf.fr
> Sent: Tuesday, December 12, 2006 3:13 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] ifelse question
>
> Dear R-helpers,
> How come that in the following code the rnorm() function is evaluated
> only once for each branch of the 'ifelse' ?
>
> x <- rnorm(10)
> y1 <- ifelse(x > 0, rnorm(1) ,  rnorm(1))
>
>
> What is the right way to make it called/evaluated for each row, apart
> from a 'for' loop ?
>
> Thanks,
>
> Jacques.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> --------------------------------------------------------
>
> This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
G?ran Brostr?m


From p.dalgaard at biostat.ku.dk  Tue Dec 12 22:01:31 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 12 Dec 2006 22:01:31 +0100
Subject: [R] Segfault in pure R code
In-Reply-To: <148ed8180612121218pea45e0agcdb39a8b9fe9ff43@mail.gmail.com>
References: <148ed8180612121218pea45e0agcdb39a8b9fe9ff43@mail.gmail.com>
Message-ID: <457F18AB.4020109@biostat.ku.dk>

G?ran Brostr?m wrote:
> I just caught a segfault:
>
>   
>> courses("Ingrid")
>>     
>
>  *** caught segfault ***
> address 0x99b279c, cause 'memory not mapped'
>
> Traceback:
>  1: structure(y, class = oldClass(x), row.names = attr(x, "row.names"))
>  2: `[.data.frame`(gudata, -(1:5))
>  3: gudata[-(1:5)]
>  4: names(gudata[-(1:5)])
>  5: inherits(x, "factor")
>  6: is.factor(table)
>  7: match(x, table, nomatch = 0)
>  8: who %in% names(gudata[-(1:5)])
>  9: courses("Ingrid")
>
> when running a function 'courses' in an R package without compiled
> code. Is this "possible"? I have got many segfaults when testing my
> own packages, but it has always been caused by stupidities in C or
> Fortran code, never with pure R code.
>
> So, before I start debugging, I'd like to know if a segfault in pure R
> code indicates  a bug in R itself, or if it can be in my function?
>
>   
By definition, reproducible segfaults in R code are bugs in R, unless 
caused by abuse of .C calls or similar. (Irreproducible ones are often 
hardware faults.)

However, at least presently, you are the only one with a handle on the 
bug. So either you get to do the debugging or you have to provide 
something that others can reproduce.

Astarting point could be to run R under the debugger (R -d gdb)  and 
generate a C backtrace, then look at the variables involved.

(Further discussion should probably go on r-devel instead of r-help).

-p
 
> I have used 'courses' many times before without problems.
>
> Thanks,
>
> G?ran
> ++++++++++++++++++++++++++++++++++++++
>   
>> sessionInfo()
>>     
> R version 2.4.0 Patched (2006-10-29 r39744)
> i686-pc-linux-gnu
>
>
>


From jropers at gmail.com  Tue Dec 12 22:11:04 2006
From: jropers at gmail.com (Jacques Ropers)
Date: Tue, 12 Dec 2006 22:11:04 +0100
Subject: [R] ifelse question
In-Reply-To: <148ed8180612121246q4c61a263oe8f4dd6052593575@mail.gmail.com>
References: <457F0D5C.8040908@freesurf.Fr>	<D3AEEDA31E57474B840BEBC25A8A8344F39165@NYWEXMB23.msad.ms.com>
	<148ed8180612121246q4c61a263oe8f4dd6052593575@mail.gmail.com>
Message-ID: <457F1AE8.3040809@gmail.com>


> But you got only two (eventually one) distinct values, right? Look at
> the code for 'ifelse': yes and no are only called once each, then
> recycled to desired length.
>
> I guess you want something like
>
> x <- rnorm(10)
> y <- rnorm(10)
> z <- rnorm(10)
> y1 <- ifelse(x > 0, y, z)
>   
Thanks for the help.

Although this would do the trick, is there a way to call repetitively 
rnorm (rpois...) *inside the ifelse* rather than constructing the vector 
outside ? Like in the following where cos() and sin() functions are 
evaluated for each row :
x <- rnorm(10)
y1 <- ifelse(x > 0, cos(x), sin(x))

I am trying to understand the difference of behaviour. R acts as if 
rnorm(1) return value were known after the first call and does not 
evaluate rnorm(1) in

y1 <- ifelse(x > 0, rnorm(1) ,  rnorm(1))

again after the first evaluation.


Jacques.


From p.dalgaard at biostat.ku.dk  Tue Dec 12 22:10:38 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 12 Dec 2006 22:10:38 +0100
Subject: [R] ifelse question
In-Reply-To: <457F1509.8080009@freesurf.Fr>
References: <457F1509.8080009@freesurf.Fr>
Message-ID: <457F1ACE.4090307@biostat.ku.dk>

jropers at freesurf.fr wrote:
> What is puzzling me is that rnorm(1) is only evaluated *twice*, one time 
> for each branch, with only 2 different random deviates, instead of 
> giving ten different random deviates. y1 has indeed 10 values but with 
> only 2 different ones.
>   
I find it more puzzling why you expect that ifelse,  a function of three 
vector arguments, would cause its input arguments to be reevaluated for  
every element of the result.
 
> I would like to have rnorm be evaluated for each row and collect ten 
> *different* random deviates.
>
> y1
>  [1] 0.4087172 0.7707796 0.4087172 0.4087172 0.7707796 0.4087172 0.4087172
>  [8] 0.7707796 0.7707796 0.4087172
>
>
> Thanks.
>
> Jacques.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tplate at blackmesacapital.com  Tue Dec 12 22:17:57 2006
From: tplate at blackmesacapital.com (Tony Plate)
Date: Tue, 12 Dec 2006 14:17:57 -0700
Subject: [R] ifelse question
In-Reply-To: <457F1AE8.3040809@gmail.com>
References: <457F0D5C.8040908@freesurf.Fr>	<D3AEEDA31E57474B840BEBC25A8A8344F39165@NYWEXMB23.msad.ms.com>	<148ed8180612121246q4c61a263oe8f4dd6052593575@mail.gmail.com>
	<457F1AE8.3040809@gmail.com>
Message-ID: <457F1C85.5060801@blackmesacapital.com>

I think you can find your answer if you study this part of the 
documentation for ifelse:

Details:
If yes or no are too short, their elements are recycled. yes will be 
evaluated if and only if any element of test is true, and analogously 
for no.

Also, consider this call:

ifelse(1:12 > 5, 1:3, 11:14)

-- Tony Plate

Jacques Ropers wrote:
>>But you got only two (eventually one) distinct values, right? Look at
>>the code for 'ifelse': yes and no are only called once each, then
>>recycled to desired length.
>>
>>I guess you want something like
>>
>>x <- rnorm(10)
>>y <- rnorm(10)
>>z <- rnorm(10)
>>y1 <- ifelse(x > 0, y, z)
>>  
> 
> Thanks for the help.
> 
> Although this would do the trick, is there a way to call repetitively 
> rnorm (rpois...) *inside the ifelse* rather than constructing the vector 
> outside ? Like in the following where cos() and sin() functions are 
> evaluated for each row :
> x <- rnorm(10)
> y1 <- ifelse(x > 0, cos(x), sin(x))
> 
> I am trying to understand the difference of behaviour. R acts as if 
> rnorm(1) return value were known after the first call and does not 
> evaluate rnorm(1) in
> 
> y1 <- ifelse(x > 0, rnorm(1) ,  rnorm(1))
> 
> again after the first evaluation.
> 
> 
> Jacques.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jropers at freesurf.Fr  Tue Dec 12 22:24:33 2006
From: jropers at freesurf.Fr (jropers@freesurf.fr)
Date: Tue, 12 Dec 2006 22:24:33 +0100
Subject: [R] ifelse question
In-Reply-To: <457F1ACE.4090307@biostat.ku.dk>
References: <457F1509.8080009@freesurf.Fr> <457F1ACE.4090307@biostat.ku.dk>
Message-ID: <457F1E11.4020304@freesurf.Fr>

...ifelse,  a function of three **vector** arguments....

Yes !!
I misunderstood the functioning of ifelse.
Thanks
Jacques.


Peter Dalgaard wrote:
> jropers at freesurf.fr wrote:
>> What is puzzling me is that rnorm(1) is only evaluated *twice*, one 
>> time for each branch, with only 2 different random deviates, instead 
>> of giving ten different random deviates. y1 has indeed 10 values but 
>> with only 2 different ones.
>>   
> I find it more puzzling why you expect that ifelse,  a function of 
> three vector arguments, would cause its input arguments to be 
> reevaluated for  every element of the result.
>
>> I would like to have rnorm be evaluated for each row and collect ten 
>> *different* random deviates.
>>
>> y1
>>  [1] 0.4087172 0.7707796 0.4087172 0.4087172 0.7707796 0.4087172 
>> 0.4087172
>>  [8] 0.7707796 0.7707796 0.4087172
>>
>>
>> Thanks.
>>
>> Jacques.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>   
>
>


From wade.wall at gmail.com  Tue Dec 12 23:31:06 2006
From: wade.wall at gmail.com (Wade Wall)
Date: Tue, 12 Dec 2006 17:31:06 -0500
Subject: [R] missing data using BIOENV function
Message-ID: <e23082be0612121431y7ef2fe2cq12aab0304d8ba66@mail.gmail.com>

Hi all,

I am trying to use the BIOENV function in the Vegan package and am
wondering if there is a way to perform the function with missing
values.  Is there a way to pass use="pairwise.complete.obs" to the cor
function? Or is this the wrong way to approach it?

Thanks

Wade


From deepayan.sarkar at gmail.com  Tue Dec 12 23:39:55 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 12 Dec 2006 14:39:55 -0800
Subject: [R] missing factor levels in a lattice barchart panel cause
	unexpected failure
In-Reply-To: <C62F5EC7-BEE1-4B2B-82CF-D205F25ED0EE@transitive.com>
References: <36BC5C60-1632-4E36-8005-2BA11AF449C5@transitive.com>
	<C62F5EC7-BEE1-4B2B-82CF-D205F25ED0EE@transitive.com>
Message-ID: <eb555e660612121439u6a04e69ar815f86508fa8ea56@mail.gmail.com>

On 12/12/06, Alex Brown <alex at transitive.com> wrote:
> I think I've found the problem, and a sort of fix, for this issue.
>
> It appears in the panel.barchart function
>
> each of the clauses in the function has a set of lines roughly like:
>
>              groups <- as.numeric(groupSub(groups, ...))
>              vals <- sort(unique(groups))
>              nvals <- length(vals)
>              col <- rep(col, length = nvals)
>              border <- rep(border, length = nvals)
>              lty <- rep(lty, length = nvals)
>              lwd <- rep(lwd, length = nvals)
>              height <- box.ratio/(1 + nvals * box.ratio)
>              if (reference)
>                  panel.abline(v = origin, col = reference.line$col,
>                    lty = reference.line$lty, lwd = reference.line$lwd)
>              for (i in unique(y)) {
>                  ok <- y == i
>                  nok <- sum(ok, na.rm = TRUE)
>                  panel.rect(x = rep(origin, nok), y = (i + height *
>                    (groups[ok] - (nvals + 1)/2)), col = col[groups[ok]],
>                    border = border[groups[ok]], lty = lty[groups[ok]],
>                    lwd = lwd[groups[ok]], height = rep(height,
>                      nok), width = x[ok] - origin, just = c("left",
>                      "centre"))
>              }
>
> Which sets the parameter lty (and others) to NA in the example below.
>
> > D = data.frame(X=1, Y=factor(letters[2], letters[1:2]))
> > barchart(~ X, D, groups=Y)
>
> This (NA) is because:
>
> groups=[1] b
> Levels: a b
>
> thus the code then does
>
> groups==2
> vals==2
> nvals==1
> ok==TRUE
>
> hence
>
> groups[ok] == 2
>
> but
>
> length(lwd) == 1
>
> thus
>
> lwd[groups[ok]] == lwd[2] == NA
>
> This is due to the mistaken assumption that the numeric component of
> groups must be a subset of the 1:length(groups), when in fact it can
> be a subset of 1:length(levels(groups)).
>
>
> a silly fix:
> ----
>
> replacing
>
>              groups <- as.numeric(groupSub(groups, ...))
>              vals <- sort(unique(groups))
>              nvals <- length(vals)
>
> with
>
>              nvals <- length(levels(groups))
>              groups <- as.numeric(groupSub(groups, ...))
>
> fixes my example, but it clearly short of a full solution.

Why? Seems fine to me. I'll post an update after R 2.4.1 is out next week.

-Deepayan


From Jared.O'Connell at csiro.au  Wed Dec 13 00:26:43 2006
From: Jared.O'Connell at csiro.au (Jared.O'Connell at csiro.au)
Date: Wed, 13 Dec 2006 08:26:43 +0900
Subject: [R]  Combining bitmaps and plots - file too large
Message-ID: <F83C6ACE124F3E4D83B3A90C9CA0922D3F2391@exwa3-per.nexus.csiro.au>

I found a half decent solution to this, output the plots then combine
them with the image files in a latex document (using some messy
shellscripting).  

Sweave would be more suitable, but this worked fine.

cheers,

Jared


From gnachman at llamas.org  Wed Dec 13 00:34:46 2006
From: gnachman at llamas.org (George Nachman)
Date: Tue, 12 Dec 2006 15:34:46 -0800
Subject: [R] How to sum one column in a data frame keyed on other columns
Message-ID: <e57d5aec0612121534p4fe5699bv38f82fa9f8dadf1b@mail.gmail.com>

I have a data frame that looks like this:

url         time somethingirrelevant visits
www.foo.com 1:00 xxx                 100
www.foo.com 1:00 yyy                 50
www.foo.com 2:00 xyz                 25
www.bar.com 1:00 xxx                 200
www.bar.com 1:00 zzz                 200
www.foo.com 2:00 xxx                 500

I'd like to write some code that takes this as input and outputs
something like this:

url         time total_vists
www.foo.com 1:00 150
www.foo.com 2:00 525
www.bar.com 1:00 400

In other words, I need to calculate the sum of visits for each unique
tuple of (url,time).

I can do it with this code, but it's very slow, and doesn't seem like
the right approach:

keys = list()
getkey = function(m,cols,index) { paste(m[index,cols],collapse=",")  }
for (i in 1:nrow(data)) { keys[[getkey(data,1:2,i)]] = 0 }
for (i in 1:nrow(data)) { keys[[getkey(data,1:2,i)]] =
keys[[getkey(data,1:2,i)]] + data[i,4] }

I'm sure there's a more functional-programming approach to this
problem! Any ideas?


From blomsp at ozemail.com.au  Wed Dec 13 00:56:33 2006
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Wed, 13 Dec 2006 10:56:33 +1100
Subject: [R] How to sum one column in a data frame keyed on other columns
In-Reply-To: <e57d5aec0612121534p4fe5699bv38f82fa9f8dadf1b@mail.gmail.com>
References: <e57d5aec0612121534p4fe5699bv38f82fa9f8dadf1b@mail.gmail.com>
Message-ID: <457F41B1.9010408@ozemail.com.au>

You could look at the reshape package, using sum as the aggregate function.

HTH,

Simon.

George Nachman wrote:
> I have a data frame that looks like this:
>
> url         time somethingirrelevant visits
> www.foo.com 1:00 xxx                 100
> www.foo.com 1:00 yyy                 50
> www.foo.com 2:00 xyz                 25
> www.bar.com 1:00 xxx                 200
> www.bar.com 1:00 zzz                 200
> www.foo.com 2:00 xxx                 500
>
> I'd like to write some code that takes this as input and outputs
> something like this:
>
> url         time total_vists
> www.foo.com 1:00 150
> www.foo.com 2:00 525
> www.bar.com 1:00 400
>
> In other words, I need to calculate the sum of visits for each unique
> tuple of (url,time).
>
> I can do it with this code, but it's very slow, and doesn't seem like
> the right approach:
>
> keys = list()
> getkey = function(m,cols,index) { paste(m[index,cols],collapse=",")  }
> for (i in 1:nrow(data)) { keys[[getkey(data,1:2,i)]] = 0 }
> for (i in 1:nrow(data)) { keys[[getkey(data,1:2,i)]] =
> keys[[getkey(data,1:2,i)]] + data[i,4] }
>
> I'm sure there's a more functional-programming approach to this
> problem! Any ideas?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>   


-- 
Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat. 
Centre for Resource and Environmental Studies
The Australian National University              
Canberra ACT 0200                               
Australia                                       
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer 
can be extracted from a given body of data.
- John Tukey.


From marc_schwartz at comcast.net  Wed Dec 13 01:05:51 2006
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Tue, 12 Dec 2006 18:05:51 -0600
Subject: [R] How to sum one column in a data frame keyed on other	columns
In-Reply-To: <e57d5aec0612121534p4fe5699bv38f82fa9f8dadf1b@mail.gmail.com>
References: <e57d5aec0612121534p4fe5699bv38f82fa9f8dadf1b@mail.gmail.com>
Message-ID: <1165968351.4912.1.camel@localhost.localdomain>

On Tue, 2006-12-12 at 15:34 -0800, George Nachman wrote:
> I have a data frame that looks like this:
> 
> url         time somethingirrelevant visits
> www.foo.com 1:00 xxx                 100
> www.foo.com 1:00 yyy                 50
> www.foo.com 2:00 xyz                 25
> www.bar.com 1:00 xxx                 200
> www.bar.com 1:00 zzz                 200
> www.foo.com 2:00 xxx                 500
> 
> I'd like to write some code that takes this as input and outputs
> something like this:
> 
> url         time total_vists
> www.foo.com 1:00 150
> www.foo.com 2:00 525
> www.bar.com 1:00 400
> 
> In other words, I need to calculate the sum of visits for each unique
> tuple of (url,time).
> 
> I can do it with this code, but it's very slow, and doesn't seem like
> the right approach:
> 
> keys = list()
> getkey = function(m,cols,index) { paste(m[index,cols],collapse=",")  }
> for (i in 1:nrow(data)) { keys[[getkey(data,1:2,i)]] = 0 }
> for (i in 1:nrow(data)) { keys[[getkey(data,1:2,i)]] =
> keys[[getkey(data,1:2,i)]] + data[i,4] }
> 
> I'm sure there's a more functional-programming approach to this
> problem! Any ideas?

See ?aggregate

If your dataframe is called 'DF':

> aggregate(DF$visits, list(DF$url, DF$time), sum)
      Group.1 Group.2   x
1 www.bar.com    1:00 400
2 www.foo.com    1:00 150
3 www.foo.com    2:00 525


HTH,

Marc Schwartz


From jholtman at gmail.com  Wed Dec 13 01:07:11 2006
From: jholtman at gmail.com (jim holtman)
Date: Tue, 12 Dec 2006 16:07:11 -0800
Subject: [R] How to sum one column in a data frame keyed on other columns
In-Reply-To: <e57d5aec0612121534p4fe5699bv38f82fa9f8dadf1b@mail.gmail.com>
References: <e57d5aec0612121534p4fe5699bv38f82fa9f8dadf1b@mail.gmail.com>
Message-ID: <644e1f320612121607w1268a244qb5f45a97138265cb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061212/edaa725d/attachment.pl 

From montez at bu.edu  Wed Dec 13 01:07:22 2006
From: montez at bu.edu (Maria Montez)
Date: Tue, 12 Dec 2006 16:07:22 -0800
Subject: [R] combinations of m objects into r groups
Message-ID: <457F443A.8000502@bu.edu>

Hi!

Suppose I have m objects. I need to find out what are all possible ways 
I can group those m objects into r groups. Moreover, I need to create a 
matrix that contains what those arrangements are. I've created code for 
when r=2 but I've come to a halt when trying to generalize it into r groups.

For example, if I have m=6 objects and I want to arrange them into 
groups of r=2, there are a total of 41 possible arrangements. I would 
like a matrix of the form (showing only 9 possible arrangements):

  c1 c2 c3 c4 c5 c6 c7 c8 c9
1  1  2  2  2  2  2  1  1  1
2  2  1  2  2  2  2  1  2  2
3  2  2  1  2  2  2  2  1  2
4  2  2  2  1  2  2  2  2  1
5  2  2  2  2  1  2  2  2  2
6  2  2  2  2  2  1  2  2  2

This means that arrangement c1 puts object 1 into group 1 and all other 
objects into group 2.

I've created code for this particular example with two groups. I'm using 
the subsets function which I've found posted online, in a post that 
references page 149 of Venables and Ripley (2nd ed).

#subsets function computes all possibles combinations of n objects r at a time 
subsets<-function(r,n,v=1:n)
{
        if(r<=0) NULL else
        if(r>=n) v[1:n] else
        rbind(cbind(v[1],Recall(r-1,n-1,v[-1])), Recall(r, n-1,v[-1]))
}
#labels for objects
r <- c("1100","1010","1001","0110","0101","0011")
m<-length(r)
for (k in 1:trunc(m/2)){
  a <- subsets(k, m)
  for (i in 1:dim(a)[1]){
    sub <- rep(2, m)
    b <- a[i,]
    for (j in 1:length(b)){
      sub[b[j]]=1
    }
    r <- data.frame(r, sub)
  }
}
names <- c("xcomb")
for (i in 1:(dim(r)[2]-1)) {
  names <- c(names,paste("c",i,sep=""))
}
names(r) <- names

Any suggestions?

Thanks, Maria








After searching for help I found a


From Bill.Venables at csiro.au  Wed Dec 13 01:32:11 2006
From: Bill.Venables at csiro.au (Bill.Venables at csiro.au)
Date: Wed, 13 Dec 2006 10:32:11 +1000
Subject: [R] How to sum one column in a data frame keyed on other columns
Message-ID: <B998A44C8986644EA8029CFE6396A9248409B9@exqld2-bne.qld.csiro.au>

Here is an elementary way of doing it: 

> dat
          url time somethingirrelevant visits
1 www.foo.com 1:00                 xxx    100
2 www.foo.com 1:00                 yyy     50
3 www.foo.com 2:00                 xyz     25
4 www.bar.com 1:00                 xxx    200
5 www.bar.com 1:00                 zzz    200
6 www.foo.com 2:00                 xxx    500
> dat <- transform(dat, key = paste(url, time))
> total_visits <- with(dat, tapply(visits, key, sum))
> m <- match(names(total_visits), dat$key)
> tdat <- cbind(dat[m, c("url", "time")], total_visits)
> tdat
          url time total_visits
4 www.bar.com 1:00          400
1 www.foo.com 1:00          150
3 www.foo.com 2:00          525
> 

This should not be too difficult to morph into a fairly general
function.  Here's what I might do [warning: somewhat obscure code
follows]

sumUp <- function(dat, key_list, sum_list) {
  key <- with(dat, do.call("paste", dat[, key_list, drop = FALSE]))
  totals <- as.matrix(sapply(dat[, sum_list, drop = FALSE], tapply, key,
sum))
  dimnames(totals)[[2]] <- paste("total", sum_list, sep = "_")
  m <- match(dimnames(totals)[[1]], key)
  cbind(dat[m, key_list, drop = FALSE], totals)
}

check:

> sumUp(dat, c("url", "time"), "visits")
          url time total_visits
4 www.bar.com 1:00          400
1 www.foo.com 1:00          150
3 www.foo.com 2:00          525

> sumUp(dat, "url", "visits")
          url total_visits
4 www.bar.com          400
1 www.foo.com          675

Question for the reader: why to you need 'drop = FALSE' (in three
places)?

Bill Venables. 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of George Nachman
Sent: Wednesday, 13 December 2006 9:35 AM
To: r-help at stat.math.ethz.ch
Subject: [R] How to sum one column in a data frame keyed on other
columns

I have a data frame that looks like this:

url         time somethingirrelevant visits
www.foo.com 1:00 xxx                 100
www.foo.com 1:00 yyy                 50
www.foo.com 2:00 xyz                 25
www.bar.com 1:00 xxx                 200
www.bar.com 1:00 zzz                 200
www.foo.com 2:00 xxx                 500

I'd like to write some code that takes this as input and outputs
something like this:

url         time total_vists
www.foo.com 1:00 150
www.foo.com 2:00 525
www.bar.com 1:00 400

In other words, I need to calculate the sum of visits for each unique
tuple of (url,time).

I can do it with this code, but it's very slow, and doesn't seem like
the right approach:

keys = list()
getkey = function(m,cols,index) { paste(m[index,cols],collapse=",")  }
for (i in 1:nrow(data)) { keys[[getkey(data,1:2,i)]] = 0 }
for (i in 1:nrow(data)) { keys[[getkey(data,1:2,i)]] =
keys[[getkey(data,1:2,i)]] + data[i,4] }

I'm sure there's a more functional-programming approach to this
problem! Any ideas?

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Wed Dec 13 01:35:35 2006
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 12 Dec 2006 16:35:35 -0800
Subject: [R] combinations of m objects into r groups
In-Reply-To: <457F443A.8000502@bu.edu>
Message-ID: <003301c71e4e$9d1e00a0$4d908980@gne.windows.gene.com>

This issue has come up before:

RSiteSearch("nkpartitions") 

will find references for you on CRAN.

You might also try
http://ranau.cs.ui.ac.id/book/AlgDesignManual/BOOK/BOOK4/NODE153.HTM

for some background, or google on "set partitions".

Bottom line: it ain't trivial.

Cheers,

Bert Gunter
Genentech Nonclinical Statistics
South San Francisco, CA 94404

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Maria Montez
Sent: Tuesday, December 12, 2006 4:07 PM
To: r-help at stat.math.ethz.ch
Subject: [R] combinations of m objects into r groups

Hi!

Suppose I have m objects. I need to find out what are all possible ways 
I can group those m objects into r groups. Moreover, I need to create a 
matrix that contains what those arrangements are. I've created code for 
when r=2 but I've come to a halt when trying to generalize it into r groups.

For example, if I have m=6 objects and I want to arrange them into 
groups of r=2, there are a total of 41 possible arrangements. I would 
like a matrix of the form (showing only 9 possible arrangements):

  c1 c2 c3 c4 c5 c6 c7 c8 c9
1  1  2  2  2  2  2  1  1  1
2  2  1  2  2  2  2  1  2  2
3  2  2  1  2  2  2  2  1  2
4  2  2  2  1  2  2  2  2  1
5  2  2  2  2  1  2  2  2  2
6  2  2  2  2  2  1  2  2  2

This means that arrangement c1 puts object 1 into group 1 and all other 
objects into group 2.

I've created code for this particular example with two groups. I'm using 
the subsets function which I've found posted online, in a post that 
references page 149 of Venables and Ripley (2nd ed).

#subsets function computes all possibles combinations of n objects r at a
time 
subsets<-function(r,n,v=1:n)
{
        if(r<=0) NULL else
        if(r>=n) v[1:n] else
        rbind(cbind(v[1],Recall(r-1,n-1,v[-1])), Recall(r, n-1,v[-1]))
}
#labels for objects
r <- c("1100","1010","1001","0110","0101","0011")
m<-length(r)
for (k in 1:trunc(m/2)){
  a <- subsets(k, m)
  for (i in 1:dim(a)[1]){
    sub <- rep(2, m)
    b <- a[i,]
    for (j in 1:length(b)){
      sub[b[j]]=1
    }
    r <- data.frame(r, sub)
  }
}
names <- c("xcomb")
for (i in 1:(dim(r)[2]-1)) {
  names <- c(names,paste("c",i,sep=""))
}
names(r) <- names

Any suggestions?

Thanks, Maria








After searching for help I found a

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gnachman at llamas.org  Wed Dec 13 03:20:48 2006
From: gnachman at llamas.org (George Nachman)
Date: Tue, 12 Dec 2006 18:20:48 -0800
Subject: [R] How to sum one column in a data frame keyed on other columns
In-Reply-To: <B998A44C8986644EA8029CFE6396A9248409B9@exqld2-bne.qld.csiro.au>
References: <B998A44C8986644EA8029CFE6396A9248409B9@exqld2-bne.qld.csiro.au>
Message-ID: <e57d5aec0612121820le3c4198vc95a90d756aa34e0@mail.gmail.com>

Thanks, everyone, for the help!

Bill:
This looks like a really great general solution, but unfortunately I
get an error when I call sumUp:

Error in "[.data.frame"(dat, , key_list, drop = FALSE) :
        invalid subscript type

I'm running 2.2.1 because that's the latest I can get on
ubuntu...could that be the problem?


On 12/12/06, Bill.Venables at csiro.au <Bill.Venables at csiro.au> wrote:
> Here is an elementary way of doing it:
>
> > dat
>           url time somethingirrelevant visits
> 1 www.foo.com 1:00                 xxx    100
> 2 www.foo.com 1:00                 yyy     50
> 3 www.foo.com 2:00                 xyz     25
> 4 www.bar.com 1:00                 xxx    200
> 5 www.bar.com 1:00                 zzz    200
> 6 www.foo.com 2:00                 xxx    500
> > dat <- transform(dat, key = paste(url, time))
> > total_visits <- with(dat, tapply(visits, key, sum))
> > m <- match(names(total_visits), dat$key)
> > tdat <- cbind(dat[m, c("url", "time")], total_visits)
> > tdat
>           url time total_visits
> 4 www.bar.com 1:00          400
> 1 www.foo.com 1:00          150
> 3 www.foo.com 2:00          525
> >
>
> This should not be too difficult to morph into a fairly general
> function.  Here's what I might do [warning: somewhat obscure code
> follows]
>
> sumUp <- function(dat, key_list, sum_list) {
>   key <- with(dat, do.call("paste", dat[, key_list, drop = FALSE]))
>   totals <- as.matrix(sapply(dat[, sum_list, drop = FALSE], tapply, key,
> sum))
>   dimnames(totals)[[2]] <- paste("total", sum_list, sep = "_")
>   m <- match(dimnames(totals)[[1]], key)
>   cbind(dat[m, key_list, drop = FALSE], totals)
> }
>
> check:
>
> > sumUp(dat, c("url", "time"), "visits")
>           url time total_visits
> 4 www.bar.com 1:00          400
> 1 www.foo.com 1:00          150
> 3 www.foo.com 2:00          525
>
> > sumUp(dat, "url", "visits")
>           url total_visits
> 4 www.bar.com          400
> 1 www.foo.com          675
>
> Question for the reader: why to you need 'drop = FALSE' (in three
> places)?
>
> Bill Venables.
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of George Nachman
> Sent: Wednesday, 13 December 2006 9:35 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] How to sum one column in a data frame keyed on other
> columns
>
> I have a data frame that looks like this:
>
> url         time somethingirrelevant visits
> www.foo.com 1:00 xxx                 100
> www.foo.com 1:00 yyy                 50
> www.foo.com 2:00 xyz                 25
> www.bar.com 1:00 xxx                 200
> www.bar.com 1:00 zzz                 200
> www.foo.com 2:00 xxx                 500
>
> I'd like to write some code that takes this as input and outputs
> something like this:
>
> url         time total_vists
> www.foo.com 1:00 150
> www.foo.com 2:00 525
> www.bar.com 1:00 400
>
> In other words, I need to calculate the sum of visits for each unique
> tuple of (url,time).
>
> I can do it with this code, but it's very slow, and doesn't seem like
> the right approach:
>
> keys = list()
> getkey = function(m,cols,index) { paste(m[index,cols],collapse=",")  }
> for (i in 1:nrow(data)) { keys[[getkey(data,1:2,i)]] = 0 }
> for (i in 1:nrow(data)) { keys[[getkey(data,1:2,i)]] =
> keys[[getkey(data,1:2,i)]] + data[i,4] }
>
> I'm sure there's a more functional-programming approach to this
> problem! Any ideas?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From aiminy at iastate.edu  Wed Dec 13 06:59:19 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Tue, 12 Dec 2006 23:59:19 -0600
Subject: [R] estimate variance
Message-ID: <6.1.2.0.2.20061212234845.01c19948@aiminy.mail.iastate.edu>

I have data like this

aa    p   sc
met  p1  34
met  p1  56
met  p2  45
met  p2  33
ser  p1  34
ser  p1  56
ser  p2  45
ser  p2  33
...

I want to estimate the following variances for:
sc in p1 for met
sc in p2 for met
sc between p1 and p2 for met
sc for met

sc in p1 for ser
sc in p2 for ser
sc between p1 and p2 for ser
sc for ser


Does anybody how to write code for this?


From gerifalte28 at hotmail.com  Wed Dec 13 07:18:55 2006
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Tue, 12 Dec 2006 23:18:55 -0700
Subject: [R] estimate variance
In-Reply-To: <6.1.2.0.2.20061212234845.01c19948@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061212234845.01c19948@aiminy.mail.iastate.edu>
Message-ID: <457F9B4F.8060002@hotmail.com>

assuming your data is called dat, you can use:

tapply(dat$sc, INDEX=list(p=dat$p, aa=dat$aa), var)

see ?tapply and ?var

I hope this helps

Francisco



Aimin Yan wrote:
> I have data like this
> 
> aa    p   sc
> met  p1  34
> met  p1  56
> met  p2  45
> met  p2  33
> ser  p1  34
> ser  p1  56
> ser  p2  45
> ser  p2  33
> ....
> 
> I want to estimate the following variances for:
> sc in p1 for met
> sc in p2 for met
> sc between p1 and p2 for met
> sc for met
> 
> sc in p1 for ser
> sc in p2 for ser
> sc between p1 and p2 for ser
> sc for ser
> 
> 
> Does anybody how to write code for this?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From RKrug at sun.ac.za  Wed Dec 13 08:46:52 2006
From: RKrug at sun.ac.za (Rainer M Krug)
Date: Wed, 13 Dec 2006 09:46:52 +0200
Subject: [R] exporting a table to latex
Message-ID: <457FAFEC.5090002@sun.ac.za>

Hi

I am using the latex() command from the Hmisc package to export  table 
to latex. For formating of the values, I use the format() function. But 
I don't manage to get the format of the values right: I don't want 
scientific notation, but if I say scientific=FALSE, I get many digits 
after the decimal point which I can not control with digits=... and 
nsmall=... in the format command.

Is there another way of formating the values to three decimal digits?

Or another way of exporting them to LaTeX?

Thanks

Rainer

-- 
Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology and Entomology
University of Stellenbosch
Matieland 7602
South Africa

Tel:		+27 - (0)72 808 2975 (w)
Fax:		+27 - (0)86 516 2782
Fax:		+27 - (0)21 808 3304 (w)
Cell:		+27 - (0)83 9479 042

email:	RKrug at sun.ac.za
       	Rainer at krugs.de


From dieter.menne at menne-biomed.de  Wed Dec 13 10:00:26 2006
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Wed, 13 Dec 2006 09:00:26 +0000 (UTC)
Subject: [R] exporting a table to latex
References: <457FAFEC.5090002@sun.ac.za>
Message-ID: <loom.20061213T095631-50@post.gmane.org>

Rainer M Krug <RKrug <at> sun.ac.za> writes:

> I am using the latex() command from the Hmisc package to export  table 
> to latex. For formating of the values, I use the format() function. But 
> I don't manage to get the format of the values right: I don't want 
> scientific notation, but if I say scientific=FALSE, I get many digits 
> after the decimal point which I can not control with digits=... and 
> nsmall=... in the format command.
> 
> Is there another way of formating the values to three decimal digits?
> 
> Or another way of exporting them to LaTeX?

There were a few bugs in the current versions of format.df (called by latex),
and the "scientific" problem could have been among them.

Try to download latex.s from 

http://biostat.mc.vanderbilt.edu/svn/R/Hmisc/branches/release_3.2-1/R/latex.s

do 

library(Hmisc)
source("latex.s")

and check if the problem disappears. If it does, write a mail to [charles.dupont
at vanderbilt.edu] and ask him to make the version public as soon as possible.

Dieter


From vidal.jean at gmail.com  Wed Dec 13 10:02:10 2006
From: vidal.jean at gmail.com (Jean Vidal)
Date: Wed, 13 Dec 2006 10:02:10 +0100
Subject: [R] Problem with sas.get function in Hmisc
In-Reply-To: <457F0DDF.4060208@rhoworld.com>
References: <452BC18D.5020801@rhoworld.com> <457F0DDF.4060208@rhoworld.com>
Message-ID: <51d3ecb0612130102q562df3fdy2998be6d82b043fc@mail.gmail.com>

The workaround you point seems to be the solution for the moment.
I not sure I will have time (and courage) to try to figure out where
the bug comes from. Hope a more literate R programmer than me is
willing to dive in...

Thank you for your answer.

2006/12/12, Agustin Calatroni <acalatro at rhoworld.com>:
> Jean, I saw your email to the R-help mailing list. I also notice the
> problem a few months back and email the maintainer (Charles Dupont) but
> never got a response. Since I used the function a lot and in order to
> avoid the error I use version 3.0-12 instead of updating the a newer
> version. To download the earlier version use the following site:
> http://cran.r-project.org/bin/windows/contrib/2.2/ If you figure out
> another way around the problem I will be interested in knowing the solution.
>
> Sincerely,
>
>
> -- Agustin Calatroni
>
> Agustin Calatroni wrote:
> > I been having the following problem when I updated the Hmisc package
> > from version 3.0-12 to version 3.1-1.
> >
> > Create dataset under SAS:
> > data a;
> >  do i = 1 to 100;
> >   x = rannor(0);
> >   output;
> >  end;
> > run;
> >
> > Hmisc version 3.0-12:
> > library(Hmisc)
> > sas.get('C:\\Documents and Settings\\novell\\My Documents\\SAS
> > Temp\\_TD3428','a')
> >
> > NO PROBLEM
> >
> > Hmisc version 3.1-1:
> > library(Hmisc)
> > sas.get('C:\\Documents and Settings\\novell\\My Documents\\SAS
> > Temp\\_TD3428','a')
> >
> > The filename, directory name, or volume label syntax is incorrect.
> > Error in sas.get("C:\\Documents and Settings\\novell\\My Documents\\SAS
> > Temp\\_TD3428",  :
> >         SAS job failed with status 1
> > In addition: Warning message:
> > 'cmd' execution failed with error code 1 in: shell(cmd, wait = TRUE,
> > intern = output)
> >
> > R.Version()
> > $platform
> > [1] "i386-pc-mingw32"
> > $arch
> > [1] "i386"
> > $os
> > [1] "mingw32"
> > $system
> > [1] "i386, mingw32"
> > $status
> > [1] ""
> > $major
> > [1] "2"
> > $minor
> > [1] "3.1"
> > $year
> > [1] "2006"
> > $month
> > [1] "06"
> > $day
> > [1] "01"
> > $`svn rev`
> > [1] "38247"
> > $language
> > [1] "R"
> > $version.string
> > [1] "Version 2.3.1 (2006-06-01)"
> >
> > Thanks for Hmisc and Design packages, they are an invaluable resource.
> > Sorry if this is a stupid question and I missed something obvious.
> >
>
>


From shubhak at ambaresearch.com  Wed Dec 13 10:38:01 2006
From: shubhak at ambaresearch.com (Shubha Vishwanath Karanth)
Date: Wed, 13 Dec 2006 15:08:01 +0530
Subject: [R] Problem in Converting Zoo Objects to Dataframes
Message-ID: <A36876D3F8A5734FA84A4338135E7CC3A76716@BAN-MAILSRV03.Amba.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061213/ef026a6c/attachment.pl 

From RKrug at sun.ac.za  Wed Dec 13 10:52:59 2006
From: RKrug at sun.ac.za (Rainer M Krug)
Date: Wed, 13 Dec 2006 11:52:59 +0200
Subject: [R] exporting a table to latex
In-Reply-To: <loom.20061213T095631-50@post.gmane.org>
References: <457FAFEC.5090002@sun.ac.za>
	<loom.20061213T095631-50@post.gmane.org>
Message-ID: <457FCD7B.8040509@sun.ac.za>

Dieter Menne wrote:
> Rainer M Krug <RKrug <at> sun.ac.za> writes:
> 
>> I am using the latex() command from the Hmisc package to export  table 
>> to latex. For formating of the values, I use the format() function. But 
>> I don't manage to get the format of the values right: I don't want 
>> scientific notation, but if I say scientific=FALSE, I get many digits 
>> after the decimal point which I can not control with digits=... and 
>> nsmall=... in the format command.
>>
>> Is there another way of formating the values to three decimal digits?
>>
>> Or another way of exporting them to LaTeX?
> 
> There were a few bugs in the current versions of format.df (called by latex),
> and the "scientific" problem could have been among them.
> 
> Try to download latex.s from 
> 
> http://biostat.mc.vanderbilt.edu/svn/R/Hmisc/branches/release_3.2-1/R/latex.s
> 
> do 
> 
> library(Hmisc)
> source("latex.s")
Thanks - I did it but it still doesn't work.

I should have mentioned that I am using the function format() from the 
base package to create a data.frame which I then give to latex() to 
export - without formating from latex(). I am not using the format 
functions of the Hmisc package as I read that there are problems with them.

Rainer



> 
> and check if the problem disappears. If it does, write a mail to [charles.dupont
> at vanderbilt.edu] and ask him to make the version public as soon as possible.
> 
> Dieter
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology and Entomology
University of Stellenbosch
Matieland 7602
South Africa

Tel:		+27 - (0)72 808 2975 (w)
Fax:		+27 - (0)86 516 2782
Fax:		+27 - (0)21 808 3304 (w)
Cell:		+27 - (0)83 9479 042

email:	RKrug at sun.ac.za
       	Rainer at krugs.de


From lukanlu at yahoo.co.uk  Wed Dec 13 11:28:16 2006
From: lukanlu at yahoo.co.uk (lu kan)
Date: Wed, 13 Dec 2006 10:28:16 +0000 (GMT)
Subject: [R] Install R in Linux
Message-ID: <20061213102816.35197.qmail@web28007.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061213/1ec4d122/attachment.pl 

From maechler at stat.math.ethz.ch  Wed Dec 13 11:42:22 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 13 Dec 2006 11:42:22 +0100
Subject: [R] ifelse misusage become more and more frequent...
In-Reply-To: <457F1E11.4020304@freesurf.Fr>
References: <457F1509.8080009@freesurf.Fr> <457F1ACE.4090307@biostat.ku.dk>
	<457F1E11.4020304@freesurf.Fr>
Message-ID: <17791.55566.562687.131@stat.math.ethz.ch>

>>>>> "jropers at freesurf" == jropers at freesurf fr <jropers at freesurf.Fr>
>>>>>     on Tue, 12 Dec 2006 22:24:33 +0100 writes:

    jropers at freesurf> ...ifelse, a function of three **vector**
    jropers at freesurf> arguments....  Yes !!  I misunderstood the
    jropers at freesurf> functioning of ifelse.  

Seems to happen more an more often.
When I teach "R programming" I nowadays usually emphasize that people
should often *NOT* use ifelse().
In other words, I think ifelse() is much over-used in situations
where something else would be both clearer and more efficient.

Is there a document / book around which lures people into
misusing ifelse() so frequently?

Martin Maechler, ETH Zurich

    jropers at freesurf> Peter Dalgaard wrote:
    >> jropers at freesurf.fr wrote:
    >>> What is puzzling me is that rnorm(1) is only evaluated
    >>> *twice*, one time for each branch, with only 2 different
    >>> random deviates, instead of giving ten different random
    >>> deviates. y1 has indeed 10 values but with only 2
    >>> different ones.
    >>> 
    >> I find it more puzzling why you expect that ifelse, a
    >> function of three vector arguments, would cause its input
    >> arguments to be reevaluated for every element of the
    >> result.


From u9470002 at cc.kmu.edu.tw  Wed Dec 13 12:14:18 2006
From: u9470002 at cc.kmu.edu.tw (u9470002)
Date: Wed, 13 Dec 2006 19:14:18 +0800
Subject: [R] Questions about saving output files and popup
Message-ID: <20061213105332.M34472@cc.kmu.edu.tw>

Hi all:

   After calculating in R I want to show the answer and some explanations not
graphic plots in another new device and then save it as txt.file. However, I
couldn't find any package or command to do it yet. I know some commands about
generating graphics on different types of display or printing device. ex :
windows(), postscript(), pdf() and etc. But these all works for graphic plots,
not words. And I know I could save it as txt file by "selecting them and
choosing the button of save to file". However,it would be better for me if I
can save it as txt.file or pdf.file by command line. I would like to ask is it
possible to do these in R? 
 
  Welcome your any advise, I will be appreciate it very very much.
  Thanks in advance.
 
 
Regards,
Ruby Chen(Taiwan)

--
Miou-Ting Chen ?????@
Graduate Institute of Clinical Pharmacy
College of Pharmacy Kaohsiung Medical University


From mam3xs at gmail.com  Wed Dec 13 12:19:27 2006
From: mam3xs at gmail.com (Michael Sun)
Date: Wed, 13 Dec 2006 11:19:27 +0000
Subject: [R] persp() problem
Message-ID: <fe005e260612130319v228410ccwa31201c02fcd76a7@mail.gmail.com>

Dear list,

I have a problem on persp()

x <- u1data #first coloum in attached data
y <- u2data #second coloum in attached data
f <- function(x,y){qgev(pnorm(rhoF*qnorm(pnorm((qnorm(y)-rho2*qnorm(x)/sqrt(1-rho2^2))))
                   +sqrt(1-rhoF^2)*qnorm(0.95)),-0.3935119, 0.4227890,
 0.2701648)}
z <- outer(x,y,f)
persp(x,y,z)

The R will display:
"Error in persp.default(x, y, z) : increasing 'x' and 'y' values expected"

So I try to adjust it to:

testx <- unique(sort(u1data))
testy <- unique(u2data[order(u1data)])
testf <- function(testx,testy){qgev(pnorm(rhoF*qnorm(pnorm((qnorm(testy)-rho2*qnorm(testx)/sqrt(1-rho2^2))))

+sqrt(1-rhoF^2)*qnorm(0.95)),-0.3935119, 0.4227890,  0.2701648)}
testz <- unique(outer(testx,testy,testf)[order(u1data)])

BUT SAME WARN:

"Error in persp.default(testx, testy, testz) :
        increasing 'x' and 'y' values expected "

So how can I use persp in this situation?????? Thanks for any help!

========================================================
Besides that I also want to enquiry on how to build the martix below?

    [,1] [,2] [,3] [,4] [,5].......[,676]
 [1,]  1   NA   NA   NA   NA
 [2,]  NA   5   NA   NA   NA
 [3,]  NA   NA   7   NA   NA
 [4,]  NA   NA   NA   9   NA
 [5,]  NA   NA   NA   NA  12
  .    .
  .    .
  .
 [676,]

Appreciate for any reply.

Thank you,

With regards
Mc
-------------- next part --------------
0.3102202 0.6118165 0.898893
0.1153732 0.889533 0.9403834
0.1939559 0.008136975 0.752973
0.9999848 0.8709167 0.9363419
0.7327573 0.5331876 0.889305
0.142052 0.7996472 0.9241059
0.5789939 0.6572769 0.904507
0.7628466 0.7408237 0.9154523
0.8063378 0.8264442 0.928366
0.3868742 0.8406373 0.9308378
0.1201804 0.5251654 0.8883977
0.1073146 0.5495656 0.8913543
0.3801476 0.4933598 0.8844978
0.1704377 0.3456871 0.8655715
0.5100424 0.6447163 0.9029398
0.1004252 0.6747806 0.9067755
0.4969747 0.2788576 0.855801
0.9503927 0.4357328 0.877291
0.7038206 0.1551265 0.833016
0.4496465 0.2228675 0.8465589
0.3152238 0.4508357 0.8792615
0.8595227 0.1699521 0.8362594
0.8781077 0.442257 0.8781285
0.9926326 0.4477713 0.8787715
0.5001015 0.4227189 0.8757058
0.7418432 0.2242488 0.8467729
0.8401202 0.4881974 0.8838192
0.3141832 0.5075416 0.886233
0.9387748 0.76381 0.9186662
0.5421865 0.7493546 0.9166607
0.6063368 0.4569826 0.8799987
0.07328759 0.5085049 0.8863852
0.3523433 0.239639 0.8494759
0.2143498 0.1904935 0.8405416
0.0043028 0.2351062 0.8487917
0.2200048 0.525856 0.888467
0.929427 0.7432261 0.91576
0.4657704 0.02713088 0.781553
0.4974512 0.1951512 0.8414202
0.3032740 0.6642617 0.9054128
0.9586954 0.5320473 0.8891269
0.8522317 0.641292 0.9024777
0.7172216 0.7869344 0.9221045
0.5019212 0.5607276 0.8926608
0.6892507 0.722802 0.9130005
0.5197227 0.547926 0.8911097
0.6910355 0.4711651 0.8817452
0.1635166 0.5960693 0.8969858
0.6157443 0.3740314 0.8693667
0.3012652 0.3860136 0.8709832
0.7918442 0.5396737 0.8900836
0.7781783 0.7286279 0.9137793
0.5959097 0.6063727 0.8982006
0.5335883 0.5932636 0.8966064
0.4868495 0.4225826 0.8756897
0.3517952 0.242862 0.8500197
0.8330476 0.638904 0.9021835
0.1146440 0.03340253 0.786976
0.3653549 0.1617220 0.8345306
0.3287211 0.05560717 0.8008241
0.3507715 0.6139207 0.899147
0.3250503 0.4740786 0.882139
0.4259684 0.4225980 0.8756974
0.3831548 0.342748 0.86514
0.9297493 0.2764793 0.8553747
0.5209303 0.1444220 0.830535
0.2882225 0.4086862 0.8739324
0.06696263 0.05796908 0.8020525
0.2569928 0.6683259 0.9059325
0.737885 0.2643880 0.8535031
0.3417781 0.7339068 0.9145383
0.3003221 0.3746508 0.86948
0.6078735 0.08374094 0.8128343
0.7575533 0.2061716 0.8434881
0.04393339 0.2817576 0.856314
0.03873323 0.5468552 0.8910451
0.2659629 0.9524063 0.9580801
0.3318478 0.09184787 0.8157145
0.01326908 0.7941016 0.9232865
0.9531499 0.4246153 0.8758845
0.7878766 0.3739315 0.8693344
0.4278367 0.1187609 0.8239353
0.4751271 0.1594320 0.8340107
0.1298515 0.3193727 0.8618747
0.3889802 0.2466491 0.8506491
0.8919073 0.8100828 0.9256764
0.1007718 0.736085 0.914866
0.349479 0.5494373 0.8913082
0.6323708 0.5641948 0.8930688
0.4892277 0.592541 0.8965224
0.4317011 0.4708038 0.8817252
0.3640796 0.4606731 0.8804793
0.01587231 0.7557596 0.9176387
0.4029896 0.7396784 0.9153261
0.770008 0.6728253 0.9064569
0.7758348 0.3790344 0.870014
0.9256958 0.3866791 0.8709969
0.6965112 0.4335875 0.8770627
0.7327289 0.7813275 0.9212618
0.5994686 0.6169224 0.8994933
0.4861951 0.4077528 0.8737927
0.6227905 0.7492211 0.916635
0.2875190 0.754739 0.9174414
0.3583206 0.7108705 0.911435
0.2379315 0.7160225 0.9121322
0.2701988 0.371379 0.869047
0.2939349 0.2881057 0.8572388
0.686119 0.3435468 0.8652209
0.737684 0.1018767 0.818933
0.1022111 0.4620055 0.8806782
0.06743866 0.001328434 0.7155677
0.3189881 0.8103201 0.9257696
0.002606828 0.2529638 0.85179
0.754083 0.7591491 0.9180267
0.7783337 0.6120818 0.8988813
0.09418842 0.4592762 0.8803417
0.1289346 0.05072358 0.7982676
0.7680676 0.723607 0.913101
0.09463494 0.3502957 0.8662194
0.6247462 0.4354511 0.8773048
0.5472626 0.2640714 0.8534728
0.8046991 0.4033715 0.8731942
0.992037 0.8971756 0.9419815
0.1490033 0.5284286 0.8887884
0.1480197 0.5933815 0.8966606
0.4580494 0.5930807 0.8965908
0.4352076 0.4091756 0.8739806
0.3295796 0.1434968 0.8303327
0.431351 0.1096168 0.8213174
0.3167224 0.0862319 0.8137642
0.7067212 0.3611669 0.8676301
0.2601349 0.276127 0.8554021
0.4183247 0.7391175 0.9152474
0.5419186 0.5523624 0.8916447
0.9137419 0.8009559 0.9242306
0.9947217 0.7134031 0.9116726
0.7504282 0.1754408 0.8374331
0.3895617 0.3479445 0.8658571
0.6451314 0.6753639 0.9067933
0.6406233 0.3609228 0.867604
0.1448996 0.4616181 0.8806225
0.07675675 0.2447339 0.8503745
0.7305003 0.6765511 0.9069367
0.4862806 0.7636162 0.9186905
0.3355425 0.4680102 0.8813898
0.1981130 0.06148056 0.8037123
0.7579405 0.3969405 0.8723663
0.6168173 0.5598662 0.892546
0.4375986 0.5554698 0.8920301
0.4461622 0.7040231 0.910523
0.8777072 0.5413942 0.8902793
0.6782004 0.7177896 0.9123287
0.7209967 0.7495791 0.9166762
0.3230692 0.4923728 0.8843828
0.4387517 0.5043017 0.8858267
0.5148218 0.4466403 0.8787188
0.3047676 0.7538997 0.917321
0.9527929 0.1671429 0.8356328
0.9513049 0.3790206 0.8699783
0.6636276 0.5972614 0.8970817
0.1938244 0.4355477 0.8773607
0.3600900 0.4452904 0.8785646
0.2040542 0.2728078 0.8548912
0.4846581 0.2225607 0.846501
0.7091428 0.239741 0.8494566
0.5655244 2.537281e-05 0.6471484
0.4467683 0.1794644 0.838298
0.5270517 0.2173856 0.8455707
0.4940919 0.3665292 0.8683744
0.7128475 0.00847929 0.7538282
0.6727687 0.03073103 0.7847315
0.7023412 0.1143117 0.8226524
0.6435959 0.8386252 0.9304646
0.4167312 0.6090668 0.8985462
0.682974 0.7439136 0.9158887
0.5743695 0.9627705 0.9624433
0.4746829 0.2658398 0.8537617
0.2591787 0.05880024 0.802423
0.5281165 0.6724808 0.906436
0.2721701 0.4292930 0.8765619
0.5527161 0.5641951 0.8930761
0.4820321 0.5303901 0.8889902
0.519115 0.6716372 0.9063293
0.06265548 0.955931 0.9595114
0.3800652 0.7018464 0.9102427
0.3546165 0.415416 0.8747885
0.6800597 0.9266552 0.9495428
0.4970227 0.9582172 0.960424
0.5395118 0.999861 1.021719
0.3521434 0.5106511 0.8866073
0.6013237 0.7820113 0.9213758
0.8364799 0.7461522 0.9161836
0.571522 0.9823802 0.9742642
0.4043184 0.5279379 0.8887002
0.7320448 0.08124245 0.8118969
0.4386114 0.7264156 0.9135103
0.649196 0.4673266 0.8812757
0.2198846 0.4410754 0.878052
0.2285649 0.6274793 0.900828
0.5241012 0.8958289 0.9417466
0.362962 0.315014 0.8612168
0.3052995 0.3960945 0.8723014
0.905782 0.3447792 0.8653598
0.8931942 0.6032726 0.8977864
0.4266403 0.4421003 0.8781588
0.6388304 0.6090837 0.8985284
0.56878 0.579462 0.8949255
0.2950412 0.7102818 0.9113629
0.8296596 0.9120703 0.9456078
0.8635411 0.5362425 0.889658
0.9661249 0.6000882 0.897377
0.8104151 0.7164646 0.9121375
0.6788884 0.6432019 0.9027357
0.8568189 0.3015897 0.8591981
0.8460857 0.5678257 0.8934844
0.3145571 0.1828112 0.8389946
0.8994917 0.4629269 0.8806988
0.3515329 0.6217972 0.9001149
0.2874208 0.5560029 0.892109
0.4120654 0.7204939 0.9127143
0.1825168 0.5184448 0.887573
0.9755303 0.7021669 0.9102076
0.6491138 0.7110952 0.9114395
0.3967447 0.3955594 0.8722225
0.7102073 0.1843923 0.8392725
0.2964985 0.1360965 0.8285183
0.1869265 0.5907168 0.8963308
0.4028261 0.757025 0.9177552
0.6887386 0.7294083 0.9138946
0.8914899 0.7315796 0.9141653
0.4680622 0.6889618 0.9085565
0.5421646 0.551866 0.8915845
0.3836133 0.3281107 0.863089
0.7949356 0.698984 0.9098294
0.652499 0.7218326 0.9128735
0.923453 0.5489377 0.8911828
0.872984 0.1647356 0.835132
0.9080439 0.3139736 0.8610017
0.9078707 0.3264533 0.862792
0.1497525 0.6098135 0.8986666
0.2727475 0.5059691 0.886046
0.1080346 0.6117073 0.8989056
0.7163249 0.4961443 0.884806
0.1665438 0.7095927 0.9112861
0.1147964 0.7040084 0.9105571
0.6361728 0.4526705 0.8794596
0.2948908 0.6166378 0.899486
0.2754661 0.7791832 0.9209829
0.5040162 0.4605482 0.8804507
0.7755624 0.7083473 0.9110629
0.007938672 0.6512774 0.9038441
0.2143095 0.7018575 0.9102607
0.4256598 0.3218441 0.862193
0.7021327 0.1471694 0.83117
0.8541683 0.5130324 0.8868449
0.8165188 0.8621911 0.9347445
0.6407761 0.48237 0.8831282
0.5312793 0.5385175 0.88997
0.4844806 0.6393667 0.902276
0.8293853 0.7139695 0.9118023
0.9128633 0.716203 0.9120864
0.5514199 0.503507 0.8857197
0.3412234 0.7031551 0.910418
0.4681908 0.8509374 0.932675
0.5099785 0.897836 0.9422059
0.613507 0.8843356 0.9392177
0.5615576 0.5944772 0.8967518
0.2233283 0.5227858 0.8880943
0.7192387 0.1106780 0.8215985
0.6253335 0.5056905 0.8859786
0.3923049 0.7112349 0.9114802
0.5103654 0.6072716 0.8983182
0.8546338 0.6290934 0.9009646
0.2189133 0.4025152 0.8731445
0.1557879 0.9385458 0.9531978
0.3178054 0.4950795 0.884714
0.4594106 0.4929672 0.8844424
0.2145317 0.6494829 0.9035634
0.7338679 0.0743877 0.8092418
0.2910765 7.344265e-06 0.6282273
0.6739632 0.04388068 0.7941999
0.4262167 0.788432 0.9223558
0.815637 0.4462349 0.8786363
0.4944984 0.0325375 0.7862377
0.5482012 0.6671962 0.9057626
0.7203222 0.6536981 0.904044
0.6473953 0.4267527 0.8762038
0.1459738 0.2673097 0.8540337
0.3430013 0.9186308 0.9473533
0.3968373 0.6025617 0.8977525
0.4825984 0.8971687 0.942055
0.6915212 0.4134755 0.8745077
0.7016574 0.2524424 0.8515746
0.4246859 0.7426717 0.9157385
0.004345354 0.7664402 0.9191835
0.03124377 0.8600277 0.93442
0.2576312 0.2757442 0.8553429
0.2569686 0.7540984 0.9173539
0.1386583 0.5013163 0.8854969
0.004756962 0.5166277 0.8874133
0.6976297 0.4815717 0.8830245
0.697404 0.4244274 0.8759037
0.8112176 0.5899199 0.8961713
0.713734 0.3745925 0.8694313
0.8887044 0.85696 0.9337461
0.2278300 0.9559154 0.9594826
0.9451097 0.5987058 0.8972164
0.1199859 0.713117 0.9117607
0.2427017 0.8342876 0.9297474
0.3799076 0.6385965 0.9021895
0.780296 0.3971621 0.8723923
0.4833612 0.6403189 0.9023944
0.6143626 0.6414991 0.9025297
0.7478517 0.8341564 0.9296813
0.5848616 0.2031911 0.842948
0.803453 0.02763294 0.7819796
0.8947829 0.1982048 0.8419586
0.5401919 0.3691551 0.8687224
0.8064726 0.2461822 0.8505264
0.9174961 0.9000155 0.9426684
0.8649377 0.7263216 0.9134553
0.368144 0.3114216 0.860695
0.3960397 0.7991588 0.9240037
0.7474788 0.7891092 0.9224306
0.8244429 0.4399955 0.8778534
0.4090636 0.9744874 0.9686875
0.60864 0.3629311 0.8678787
0.8792287 0.1042003 0.8196308
0.5568143 0.6392743 0.9022581
0.2410288 0.7310255 0.9141548
0.5096632 0.5728588 0.8941298
0.6754568 0.7334808 0.9144511
0.9016902 0.8356986 0.929927
0.794581 0.823762 0.9279195
0.3333656 0.7053623 0.9107092
0.7280451 0.919738 0.9476197
0.5522382 0.1590644 0.8339207
0.6466815 0.6127797 0.8989805
0.8000029 0.4637126 0.8808121
0.5983007 0.4788531 0.8827005
0.01127508 0.5186316 0.8876452
0.013699 0.563469 0.8930714
0.2427855 0.8413799 0.9309814
0.7656437 0.8558567 0.933556
0.7712339 0.6979084 0.9096916
0.7820254 0.2107216 0.8443285
0.2098941 0.3466435 0.8656979
0.6803271 5.67055e-05 0.6599548
0.8533364 0.04563989 0.79525
0.3460994 0.4376786 0.8776115
0.1276769 0.8358598 0.9300324
0.1840423 0.5695211 0.893758
0.1898183 4.343381e-13 0.4279754
0.5374682 3.43534e-07 0.5847877
0.9653777 0.2941263 0.8580566
0.793583 0.7093681 0.9111959
0.767547 0.2485699 0.8509283
0.6692159 0.9999993 1.049294
0.8284223 0.1368672 0.8286505
0.9165768 0.7461044 0.9161635
0.07780481 0.2581183 0.8525758
0.8283647 0.07059201 0.8076717
0.4945938 0.08162078 0.8120646
0.7121621 0.5978781 0.897152
0.003852813 0.1328189 0.8277767
0.7119404 0.05172274 0.7987407
0.8855203 0.6257442 0.900546
0.9218816 0.8273478 0.9285
0.9233806 0.7509503 0.9168407
0.2593601 0.08886668 0.8146992
0.5798519 0.8080687 0.9253888
0.2083358 0.9943995 0.9891006
0.9928156 0.811554 0.925873
0.6316176 0.7618544 0.9184253
0.2909255 0.2391205 0.8493947
0.4806987 0.05703826 0.8015291
0.8148117 0.6490257 0.9034478
0.5015989 0.7569907 0.917742
0.618849 0.8112648 0.925896
0.8680278 0.1261190 0.8258788
0.9843081 0.4610686 0.8804365
0.981136 0.5933233 0.8965434
0.3402781 0.7650686 0.9189122
0.636855 0.6395097 0.9022802
0.1015914 0.9004152 0.9428428
0.01417522 0.1301853 0.8270804
0.01399330 0.4096037 0.8741114
0.3585436 0.1450862 0.830711
0.8398029 0.6609509 0.9049425
0.5550948 0.8041808 0.9247759
0.3279216 0.3477294 0.8658338
0.800509 0.7437003 0.9158468
0.8634276 0.2644834 0.8535005
0.4027558 0.03161294 0.7854964
0.9603643 0.08939088 0.814781
0.8684457 0.2258063 0.847029
0.2337130 0.6693651 0.906067
0.8418288 0.06168066 0.8037274
0.6960713 0.236729 0.8489459
0.9778375 0.1392889 0.8292076
0.909325 0.4792852 0.8827139
0.6743998 0.001302298 0.7150928
0.002995692 0.3198894 0.862011
0.7865613 0.8194578 0.9272093
0.7795525 0.7334021 0.9144298
0.983064 0.3390965 0.8645403
0.8615933 0.2985286 0.8587428
0.008317132 0.2811343 0.8562448
0.3336097 0.5237279 0.8881966
0.6511454 0.5833166 0.895386
0.8859316 0.6190705 0.899724
0.01688167 0.1500001 0.8319426
0.002360940 0.1319095 0.8275506
0.6274613 0.5826939 0.8953125
0.008114898 0.6664864 0.9057595
0.001045473 0.2242417 0.8469188
0.0508478 0.4957073 0.8848329
0.5888479 0.914019 0.946127
0.7740566 0.8235836 0.9278921
0.8057038 0.3660084 0.8682713
0.4770886 0.6560355 0.9043598
0.5256923 0.8803939 0.938396
0.8566784 0.7790501 0.9209085
0.7719712 0.6309976 0.901211
0.1469819 0.8088482 0.9255534
0.2189924 0.03436754 0.7877055
0.9558648 0.1629045 0.8347084
0.9225076 0.2217156 0.846293
0.8208944 0.8208895 0.9274408
0.2174652 0.1468581 0.8311496
0.618421 0.4026186 0.8731176
0.6247648 0.7436365 0.9158555
0.2372800 0.2181356 0.8457368
0.7013663 0.8468071 0.931908
0.7868276 0.9131027 0.945875
0.6576328 0.585279 0.8956237
0.9719215 0.4717628 0.8817672
0.7798435 0.1481837 0.8313995
0.6780997 0.5981976 0.8971944
0.3070307 0.1875593 0.8399491
0.4197094 0.5990637 0.8973235
0.5040344 0.1640605 0.8350302
0.8834981 0.6167573 0.89944
0.1481133 0.8285937 0.9287888
0.1471865 0.6445625 0.9029578
0.1327257 0.6725547 0.906486
0.3433113 0.6927705 0.9090613
0.2946019 0.4352499 0.8773112
0.003406429 0.3938362 0.8720895
0.2857042 0.5735738 0.8942374
0.6455505 0.2243478 0.8468013
0.9490315 0.2099423 0.8441508
0.04602036 0.3690979 0.8687822
0.1056053 0.7631722 0.918667
0.6817949 0.528255 0.8887128
0.5644347 0.6491707 0.9034914
0.7570488 0.7966135 0.9235781
0.6593145 0.2074085 0.84373
0.8925004 0.6638273 0.9052974
0.1246228 0.4961518 0.8848695
0.7857138 0.542488 0.890425
0.8963653 0.2669431 0.8538854
0.6514738 0.7706894 0.919701
0.2293905 0.8438272 0.9314158
0.3912309 0.6160558 0.8994053
0.2982153 0.5130745 0.8869073
0.4044714 0.7306236 0.9140846
0.9431583 0.616781 0.8994294
0.04552623 0.8735693 0.9370548
0.7237478 0.6736022 0.9065609
0.6859905 0.8343209 0.9297154
0.7823167 0.7148671 0.9119277
0.9521752 0.3384298 0.8644647
0.2351690 0.243558 0.85015
0.3056817 0.5057963 0.8860215
0.5686026 0.6364396 0.901905
0.7356786 0.4167618 0.8749232
0.2266795 0.7380897 0.915124
0.3347846 0.8819222 0.9387305
0.3956415 0.8593319 0.9342383
0.7768104 0.8177261 0.9269268
0.3056832 0.5966309 0.8970376
0.5204085 0.8136706 0.9262912
0.2521421 0.3396209 0.8647196
0.2473847 0.2164454 0.8454306
0.1108629 0.4169697 0.8750187
0.2838937 0.3549462 0.8668274
0.5465899 0.5446338 0.8907089
0.1034264 0.7386064 0.9152123
0.2498704 0.09973506 0.8183126
0.1136003 0.2718162 0.8547505
0.4172970 0.5540139 0.8918557
0.1390018 0.8442352 0.9314993
0.005563172 0.8066043 0.9252453
0.5818675 0.6424044 0.9026453
0.1430274 0.674245 0.9066999
0.03769988 0.4290427 0.8765737
0.8556575 0.3844797 0.870722
0.8775405 0.417829 0.8750397
0.9104062 0.6323445 0.9013568
0.1074026 0.2182002 0.8457692
0.7204749 0.1104211 0.821523
0.3492221 0.3339966 0.8639225
0.1576476 0.4215118 0.8755896
0.9048666 0.6262912 0.9006098
0.4718103 0.2724998 0.8548135
0.4361739 0.09929708 0.8181518
0.2972725 0.7777231 0.9207644
0.5665044 0.8808408 0.938486
0.738228 0.5602356 0.8925787
0.5540302 0.5708308 0.89388
0.1375065 0.8168868 0.9268497
0.07578065 0.3489205 0.8660352
0.3726154 0.2491216 0.851061
0.6368203 0.7509145 0.9168716
0.8306685 0.777946 0.9207484
0.2833806 0.5546789 0.8919492
0.09934053 0.6805804 0.9075179
0.1655332 0.8468221 0.9319582
0.2844294 0.8254702 0.928249
0.1464508 0.9015246 0.943096
0.389557 0.6143054 0.8991906
0.1621419 0.6400966 0.9023995
0.0971209 0.4490999 0.8790752
0.2709383 0.8486465 0.9322756
0.4742362 0.4121831 0.874363
0.6779411 0.5489203 0.8912153
0.5392679 0.3478413 0.8658285
0.4443618 0.6275902 0.9008207
0.08832718 0.5932862 0.8966598
0.5118831 0.01596035 0.7684642
0.9978362 0.2475618 0.850678
0.2128232 0.9456008 0.9555712
0.1790925 0.6703308 0.9061963
0.7668958 0.4674435 0.8812775
0.1564061 0.2451245 0.8504234
0.1336754 0.3983315 0.8726147
0.0975977 0.2043324 0.8432229
0.01216834 0.2339812 0.8485838
0.1569461 0.5324595 0.8892754
0.04365445 0.4410925 0.8780887
0.2494574 0.02976159 0.7839518
0.7012898 0.4499832 0.879118
0.4708703 0.4863704 0.8836344
0.5920373 0.707517 0.910971
0.9561298 0.1947485 0.8412737
0.4952743 0.03657176 0.7893157
0.915553 0.4239565 0.875812
0.7713963 0.06609137 0.805744
0.05493889 0.2130792 0.844855
0.6821484 0.7026926 0.9103274
0.5336243 0.91109 0.9453866
0.6867021 0.7411612 0.9155066
0.975979 0.04527906 0.7949923
0.837784 0.74753 0.9163759
0.4934895 0.416351 0.8748948
0.005828299 0.3566607 0.8671348
0.3310498 0.8961609 0.9418372
0.03192657 0.850284 0.932612
0.08457336 0.6901218 0.9087509
0.2031292 0.4299748 0.8766564
0.7614405 0.7459437 0.9161635
0.2555080 0.674626 0.9067344
0.7083119 0.4501719 0.8791408
0.945163 0.1646992 0.8351056
0.06908377 0.2324591 0.8482912
0.03880391 0.2281361 0.8475513
0.5105381 0.8672677 0.9357525
0.05855021 0.5165195 0.8873631
0.1300929 0.8829 0.9389577
0.1747403 0.1704515 0.8364469
0.2981974 0.1595222 0.8340497
0.0055007 0.3530877 0.8666484
0.7576901 0.264833 0.8535717
0.6933019 0.5738702 0.8942353
0.6443269 0.2171339 0.8455133
0.4122726 0.490008 0.884085
0.08336114 0.6785415 0.9072598
0.5589743 0.7387024 0.9151783
0.92432 0.6836011 0.907813
0.9606246 0.1255525 0.825702
0.4450934 0.2194885 0.8459569
0.5807345 0.4559498 0.8798728
0.6236046 0.5395055 0.890081
0.5478731 0.8940408 0.9413413
0.8278164 0.5863816 0.8957387
0.8017402 0.2607101 0.8529055
0.7423169 0.7402687 0.9153777
0.4548012 0.4569796 0.8800124
0.1770415 0.5387303 0.8900318
0.9073766 0.3520192 0.8663556
0.1492733 0.1125281 0.8222042
0.07429098 0.2712785 0.8546752
0.3683862 0.6588343 0.9047215
0.680869 0.7330059 0.9143857
0.7384956 0.6025491 0.8977193
0.3808318 0.3140541 0.861076
0.2843261 0.6324584 0.9014375
0.1436439 0.5258806 0.8884804
0.4224504 0.5743372 0.8943168
0.7524093 0.3438394 0.8652539
0.9357195 0.5169828 0.8873079
0.4036766 0.6824951 0.9077281
0.1014471 0.7351924 0.9147434
0.3524282 0.3972935 0.8724525
0.9483054 0.3513068 0.8662465
0.4396423 0.4028961 0.8731704
0.3531021 0.2731345 0.8549248
0.4443184 0.3142964 0.8611048
0.3768978 0.5842775 0.8955275
0.2466269 0.2663774 0.8538713
0.5962991 0.00470513 0.7410197
0.3756412 0.2967521 0.858532
0.04994566 0.2117102 0.8446063
0.1080174 0.4622149 0.880703
0.3629230 0.5252755 0.8883814
0.1887335 0.292769 0.8579568
0.3519446 0.7994556 0.9240536
0.1217339 0.1401854 0.8295575
0.174763 0.618114 0.8996812
0.4586664 0.6402342 0.902386
0.5343869 0.3013533 0.8592008
0.2161009 0.3156891 0.861331
0.17651 0.4887034 0.8839512
0.9917181 0.4244217 0.8758332
0.604959 0.2353208 0.8487147
0.8332544 0.5308923 0.8890146
0.51212 0.596579 0.8970123
0.5994383 0.2876340 0.8571365
0.8807404 0.4205335 0.875384
0.072703 0.503507 0.8857772
0.1272491 0.7729678 0.9200844
0.5047155 0.903465 0.943523
0.1129428 0.8151764 0.9265756
0.546922 0.6979866 0.909723
0.9591556 0.02840703 0.7826478
0.8617191 0.1017775 0.8188833
0.6370122 0.1468348 0.831098
0.431313 0.7198841 0.9126308
0.1316088 0.8709087 0.9365054
0.7881227 0.8493899 0.9323656
0.6531763 0.6218253 0.9000913
0.790503 0.6167768 0.899456
0.8466432 0.9889855 0.9807199
0.6609452 0.3529404 0.8665161
0.9637131 0.1053617 0.8199601
0.6903624 0.3402932 0.8647688
0.8406482 0.3099546 0.8604301
0.4943412 0.5324295 0.8892361
0.5210708 0.1568008 0.8334152
0.9086716 0.5761234 0.8944793
0.09083374 0.5520557 0.891659
0.6066495 0.5805193 0.8950504
0.5294395 0.5708622 0.893886
0.02075211 0.8740981 0.9371722
0.3150380 0.4126541 0.874439
0.8028235 0.4867181 0.8836432
0.5138899 0.2777579 0.855629
0.2610341 0.4841342 0.883381
0.2810478 0.4913972 0.884268
0.9002693 0.4355419 0.8772805
0.7717612 0.6170158 0.8994875
0.8091782 0.598264 0.897188
0.5719824 0.6296076 0.9010587
0.5029268 0.5059016 0.8860156
0.613944 0.2153304 0.8451901
0.2244824 0.1831607 0.8390764
0.7980058 0.1371974 0.8287375
0.932274 0.4284666 0.8763795
0.6961254 0.4558324 0.8798468
0.3442136 0.1641236 0.8350606
0.5064431 0.1621777 0.8346166
0.4151743 0.4776614 0.882571
0.06262435 0.7949185 0.9233896
0.7819505 0.6249127 0.9004582
0.5856734 0.3304368 0.8633984

From david.lindelof at epfl.ch  Wed Dec 13 12:38:04 2006
From: david.lindelof at epfl.ch (David =?ISO-8859-1?Q?Lindel=F6f?=)
Date: Wed, 13 Dec 2006 12:38:04 +0100
Subject: [R] Sweave, Xfig, pdflatex and \setkeys
In-Reply-To: <457EF377.2010805@utoronto.ca>
References: <1165919873.4758.18.camel@lesopriv3.epfl.ch>
	<457EF377.2010805@utoronto.ca>
Message-ID: <1166009884.5698.5.camel@lesopriv3.epfl.ch>

On Tue, 2006-12-12 at 13:22 -0500, Kevin E. Thorpe wrote:
> > Trouble is that Sweave defines (with \setkeys) the default width of
> > \includegraphics to be 0.8 times the \textwidth. The result is that the
> > graphic is scaled, but not the text.
> > 
> > I was looking for a way to temporarily undefine the default width of
> > included graphics, but without success. Does anyone know how to undo a
> > definition that has been set with \setkeys?

> If you knew what setting you needed, you could try
> 
> \setkeys{Gin}{width=whatever}
> 
> before your include, and set it back to the default afterward with
> 
> \setkeys{Gin}{width=0.8\textwidth}

Yes, but the trouble is that for arbitrary figures created with Xfig I
cannot know what the correct width is going to be. And I could not find
any help on how to undefine variables set with \setkeys.

> I have run into this myself, but since I was also using beamer, it
> wasn't at all obvious what I should try for the setting, so I don't
> know if this will work.  I have used this to rescale the imported
> graphics from R.  Fortunately, the graphic I created in xfig could
> be completely specified in LaTeX, and so I exported it in that format
> and imported it with \scalebox{0.5}{\input{xfigfile.latex}}

But then you are severly limited, aren't you? For instance, you cannot
draw lines with slopes other that multiples of 45 degrees?

Cheers,
--
--------------------------------------------------
David Lindel?f
Station 18
LESO-PB/EPFL
1015 Lausanne
tel +41-21-693.5556
mob +41-79-415.6641
fax +41-21-693.2722
e-mail david.lindelof at epfl.ch
url http://lesowww.epfl.ch/doctorants/lindelof/
weblog http://visnet.ch/~lindelof/smartbuildings/
--------------------------------------------------

COBOL:
	An exercise in Artificial Inelegance.


From jgarcia at ija.csic.es  Wed Dec 13 12:38:53 2006
From: jgarcia at ija.csic.es (javier garcia-pintado)
Date: Wed, 13 Dec 2006 12:38:53 +0100
Subject: [R] expression()
In-Reply-To: <F5A97ABA-8B6C-4EC7-A40C-B93D724B8CA6@jhsph.edu>
References: <457ED1CF.2060500@ija.csic.es>
	<F5A97ABA-8B6C-4EC7-A40C-B93D724B8CA6@jhsph.edu>
Message-ID: <457FE64D.40807@ija.csic.es>

Thanks you,
this works right.

I just would like to note one thing:
although I've found italic() in the help for plotmath and I can see that
the italic function:

mtext(expression(italic(beta)[max]),side=1,line=2)

does not work on the greek beta character.

Though not strictly necessary, this would be perfect for my plots, as I
use them for papers to be published.

Wishes,
Javier
------------------------------------------
Benilton Carvalho wrote:
> mtext(expression(beta[max]), side=1, line=2)
>
> is it what you want?
>
> b
>
> On Dec 12, 2006, at 10:59 AM, javier garcia-pintado wrote:
>
>> Hi,
>> I'm trying to use expression() to write a text to a graphic in the 
>> margin.
>>
>> Using:
>>
>> mtext(expression(beta),side=1,line=2)
>>
>> writes a perfect beta greek character, but I need to add a subindex
>> "max", and I'm trying:
>>
>> mtext(paste(expression(beta),"max"),side=1,line=2)
>>
>> simply writes "beta max" in the plot.
>>
>> Please, Could you tell me what I'm doing wrong?
>>
>> By the way, is there a way to add Latex expressions to graphics?  Then I
>> could use the Latex expression: $\beta_{\mathrm{max}}$. This also  would
>> be very useful for me for more complex expressions in plots.
>>
>> Best regards,
>>
>> Javier
>>
>> -- 
>> Javier Garc?a-Pintado
>> Institute of Earth Sciences Jaume Almera (CSIC)
>> Lluis Sole Sabaris s/n, 08028 Barcelona
>> Phone: +34 934095410
>> Fax:   +34 934110012
>> e-mail:jgarcia at ija.csic.es
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Javier Garc?a-Pintado
Institute of Earth Sciences Jaume Almera (CSIC)
Lluis Sole Sabaris s/n, 08028 Barcelona
Phone: +34 934095410
Fax:   +34 934110012
e-mail:jgarcia at ija.csic.es 


From alex at transitive.com  Wed Dec 13 12:56:12 2006
From: alex at transitive.com (Alex Brown)
Date: Wed, 13 Dec 2006 11:56:12 +0000
Subject: [R] How to sum one column in a data frame keyed on other columns
In-Reply-To: <e57d5aec0612121820le3c4198vc95a90d756aa34e0@mail.gmail.com>
References: <B998A44C8986644EA8029CFE6396A9248409B9@exqld2-bne.qld.csiro.au>
	<e57d5aec0612121820le3c4198vc95a90d756aa34e0@mail.gmail.com>
Message-ID: <D95C981E-64CB-4C0C-AACF-C1B6415DB230@transitive.com>

Hi George

   I'm running ubuntu dapper badger with 2.4.0.

add  the line

   deb http://cran.R-project.org/bin/linux/ubuntu dapper/

   to your  /etc/apt/sources.list

-Alex Brown

On 13 Dec 2006, at 02:20, George Nachman wrote:

> Thanks, everyone, for the help!
>
> Bill:
> This looks like a really great general solution, but unfortunately I
> get an error when I call sumUp:
>
> Error in "[.data.frame"(dat, , key_list, drop = FALSE) :
>         invalid subscript type
>
> I'm running 2.2.1 because that's the latest I can get on
> ubuntu...could that be the problem?
>
>
> On 12/12/06, Bill.Venables at csiro.au <Bill.Venables at csiro.au> wrote:
>> Here is an elementary way of doing it:
>>
>>> dat
>>           url time somethingirrelevant visits
>> 1 www.foo.com 1:00                 xxx    100
>> 2 www.foo.com 1:00                 yyy     50
>> 3 www.foo.com 2:00                 xyz     25
>> 4 www.bar.com 1:00                 xxx    200
>> 5 www.bar.com 1:00                 zzz    200
>> 6 www.foo.com 2:00                 xxx    500
>>> dat <- transform(dat, key = paste(url, time))
>>> total_visits <- with(dat, tapply(visits, key, sum))
>>> m <- match(names(total_visits), dat$key)
>>> tdat <- cbind(dat[m, c("url", "time")], total_visits)
>>> tdat
>>           url time total_visits
>> 4 www.bar.com 1:00          400
>> 1 www.foo.com 1:00          150
>> 3 www.foo.com 2:00          525
>>>
>>
>> This should not be too difficult to morph into a fairly general
>> function.  Here's what I might do [warning: somewhat obscure code
>> follows]
>>
>> sumUp <- function(dat, key_list, sum_list) {
>>   key <- with(dat, do.call("paste", dat[, key_list, drop = FALSE]))
>>   totals <- as.matrix(sapply(dat[, sum_list, drop = FALSE],  
>> tapply, key,
>> sum))
>>   dimnames(totals)[[2]] <- paste("total", sum_list, sep = "_")
>>   m <- match(dimnames(totals)[[1]], key)
>>   cbind(dat[m, key_list, drop = FALSE], totals)
>> }
>>
>> check:
>>
>>> sumUp(dat, c("url", "time"), "visits")
>>           url time total_visits
>> 4 www.bar.com 1:00          400
>> 1 www.foo.com 1:00          150
>> 3 www.foo.com 2:00          525
>>
>>> sumUp(dat, "url", "visits")
>>           url total_visits
>> 4 www.bar.com          400
>> 1 www.foo.com          675
>>
>> Question for the reader: why to you need 'drop = FALSE' (in three
>> places)?
>>
>> Bill Venables.
>>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of George Nachman
>> Sent: Wednesday, 13 December 2006 9:35 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] How to sum one column in a data frame keyed on other
>> columns
>>
>> I have a data frame that looks like this:
>>
>> url         time somethingirrelevant visits
>> www.foo.com 1:00 xxx                 100
>> www.foo.com 1:00 yyy                 50
>> www.foo.com 2:00 xyz                 25
>> www.bar.com 1:00 xxx                 200
>> www.bar.com 1:00 zzz                 200
>> www.foo.com 2:00 xxx                 500
>>
>> I'd like to write some code that takes this as input and outputs
>> something like this:
>>
>> url         time total_vists
>> www.foo.com 1:00 150
>> www.foo.com 2:00 525
>> www.bar.com 1:00 400
>>
>> In other words, I need to calculate the sum of visits for each unique
>> tuple of (url,time).
>>
>> I can do it with this code, but it's very slow, and doesn't seem like
>> the right approach:
>>
>> keys = list()
>> getkey = function(m,cols,index) { paste(m 
>> [index,cols],collapse=",")  }
>> for (i in 1:nrow(data)) { keys[[getkey(data,1:2,i)]] = 0 }
>> for (i in 1:nrow(data)) { keys[[getkey(data,1:2,i)]] =
>> keys[[getkey(data,1:2,i)]] + data[i,4] }
>>
>> I'm sure there's a more functional-programming approach to this
>> problem! Any ideas?
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch at stats.uwo.ca  Wed Dec 13 12:56:41 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 13 Dec 2006 06:56:41 -0500
Subject: [R] persp() problem
In-Reply-To: <fe005e260612130319v228410ccwa31201c02fcd76a7@mail.gmail.com>
References: <fe005e260612130319v228410ccwa31201c02fcd76a7@mail.gmail.com>
Message-ID: <457FEA79.1000600@stats.uwo.ca>

On 12/13/2006 6:19 AM, Michael Sun wrote:
> Dear list,
> 
> I have a problem on persp()
> 
> x <- u1data #first coloum in attached data
> y <- u2data #second coloum in attached data
> f <- function(x,y){qgev(pnorm(rhoF*qnorm(pnorm((qnorm(y)-rho2*qnorm(x)/sqrt(1-rho2^2))))
>                    +sqrt(1-rhoF^2)*qnorm(0.95)),-0.3935119, 0.4227890,
>  0.2701648)}
> z <- outer(x,y,f)
> persp(x,y,z)
> 
> The R will display:
> "Error in persp.default(x, y, z) : increasing 'x' and 'y' values expected"
> 
> So I try to adjust it to:
> 
> testx <- unique(sort(u1data))
> testy <- unique(u2data[order(u1data)])

This doesn't make sense for persp. It wants the x and y values to be 
increasing over their range, and looks best with equally spaced values.

You are more likely to want something like

testx <- seq(min(u1data), max(u1data), len=100)
testy <- seq(min(u2data), max(u2data), len=100)

If you want to plot points where you observed data, you can use
the trans3d function, as in the persp examples.

Duncan Murdoch

> testf <- function(testx,testy){qgev(pnorm(rhoF*qnorm(pnorm((qnorm(testy)-rho2*qnorm(testx)/sqrt(1-rho2^2))))
> 
> +sqrt(1-rhoF^2)*qnorm(0.95)),-0.3935119, 0.4227890,  0.2701648)}
> testz <- unique(outer(testx,testy,testf)[order(u1data)])
> 
> BUT SAME WARN:
> 
> "Error in persp.default(testx, testy, testz) :
>         increasing 'x' and 'y' values expected "
> 
> So how can I use persp in this situation?????? Thanks for any help!
> 
> ========================================================
> Besides that I also want to enquiry on how to build the martix below?
> 
>     [,1] [,2] [,3] [,4] [,5].......[,676]
>  [1,]  1   NA   NA   NA   NA
>  [2,]  NA   5   NA   NA   NA
>  [3,]  NA   NA   7   NA   NA
>  [4,]  NA   NA   NA   9   NA
>  [5,]  NA   NA   NA   NA  12
>   .    .
>   .    .
>   .
>  [676,]
> 
> Appreciate for any reply.
> 
> Thank you,
> 
> With regards
> Mc
> 
> 
> ------------------------------------------------------------------------
> 
> 0.3102202 0.6118165 0.898893
> 0.1153732 0.889533 0.9403834
> 0.1939559 0.008136975 0.752973
> 0.9999848 0.8709167 0.9363419
> 0.7327573 0.5331876 0.889305
> 0.142052 0.7996472 0.9241059
> 0.5789939 0.6572769 0.904507
> 0.7628466 0.7408237 0.9154523
> 0.8063378 0.8264442 0.928366
> 0.3868742 0.8406373 0.9308378
> 0.1201804 0.5251654 0.8883977
> 0.1073146 0.5495656 0.8913543
> 0.3801476 0.4933598 0.8844978
> 0.1704377 0.3456871 0.8655715
> 0.5100424 0.6447163 0.9029398
> 0.1004252 0.6747806 0.9067755
> 0.4969747 0.2788576 0.855801
> 0.9503927 0.4357328 0.877291
> 0.7038206 0.1551265 0.833016
> 0.4496465 0.2228675 0.8465589
> 0.3152238 0.4508357 0.8792615
> 0.8595227 0.1699521 0.8362594
> 0.8781077 0.442257 0.8781285
> 0.9926326 0.4477713 0.8787715
> 0.5001015 0.4227189 0.8757058
> 0.7418432 0.2242488 0.8467729
> 0.8401202 0.4881974 0.8838192
> 0.3141832 0.5075416 0.886233
> 0.9387748 0.76381 0.9186662
> 0.5421865 0.7493546 0.9166607
> 0.6063368 0.4569826 0.8799987
> 0.07328759 0.5085049 0.8863852
> 0.3523433 0.239639 0.8494759
> 0.2143498 0.1904935 0.8405416
> 0.0043028 0.2351062 0.8487917
> 0.2200048 0.525856 0.888467
> 0.929427 0.7432261 0.91576
> 0.4657704 0.02713088 0.781553
> 0.4974512 0.1951512 0.8414202
> 0.3032740 0.6642617 0.9054128
> 0.9586954 0.5320473 0.8891269
> 0.8522317 0.641292 0.9024777
> 0.7172216 0.7869344 0.9221045
> 0.5019212 0.5607276 0.8926608
> 0.6892507 0.722802 0.9130005
> 0.5197227 0.547926 0.8911097
> 0.6910355 0.4711651 0.8817452
> 0.1635166 0.5960693 0.8969858
> 0.6157443 0.3740314 0.8693667
> 0.3012652 0.3860136 0.8709832
> 0.7918442 0.5396737 0.8900836
> 0.7781783 0.7286279 0.9137793
> 0.5959097 0.6063727 0.8982006
> 0.5335883 0.5932636 0.8966064
> 0.4868495 0.4225826 0.8756897
> 0.3517952 0.242862 0.8500197
> 0.8330476 0.638904 0.9021835
> 0.1146440 0.03340253 0.786976
> 0.3653549 0.1617220 0.8345306
> 0.3287211 0.05560717 0.8008241
> 0.3507715 0.6139207 0.899147
> 0.3250503 0.4740786 0.882139
> 0.4259684 0.4225980 0.8756974
> 0.3831548 0.342748 0.86514
> 0.9297493 0.2764793 0.8553747
> 0.5209303 0.1444220 0.830535
> 0.2882225 0.4086862 0.8739324
> 0.06696263 0.05796908 0.8020525
> 0.2569928 0.6683259 0.9059325
> 0.737885 0.2643880 0.8535031
> 0.3417781 0.7339068 0.9145383
> 0.3003221 0.3746508 0.86948
> 0.6078735 0.08374094 0.8128343
> 0.7575533 0.2061716 0.8434881
> 0.04393339 0.2817576 0.856314
> 0.03873323 0.5468552 0.8910451
> 0.2659629 0.9524063 0.9580801
> 0.3318478 0.09184787 0.8157145
> 0.01326908 0.7941016 0.9232865
> 0.9531499 0.4246153 0.8758845
> 0.7878766 0.3739315 0.8693344
> 0.4278367 0.1187609 0.8239353
> 0.4751271 0.1594320 0.8340107
> 0.1298515 0.3193727 0.8618747
> 0.3889802 0.2466491 0.8506491
> 0.8919073 0.8100828 0.9256764
> 0.1007718 0.736085 0.914866
> 0.349479 0.5494373 0.8913082
> 0.6323708 0.5641948 0.8930688
> 0.4892277 0.592541 0.8965224
> 0.4317011 0.4708038 0.8817252
> 0.3640796 0.4606731 0.8804793
> 0.01587231 0.7557596 0.9176387
> 0.4029896 0.7396784 0.9153261
> 0.770008 0.6728253 0.9064569
> 0.7758348 0.3790344 0.870014
> 0.9256958 0.3866791 0.8709969
> 0.6965112 0.4335875 0.8770627
> 0.7327289 0.7813275 0.9212618
> 0.5994686 0.6169224 0.8994933
> 0.4861951 0.4077528 0.8737927
> 0.6227905 0.7492211 0.916635
> 0.2875190 0.754739 0.9174414
> 0.3583206 0.7108705 0.911435
> 0.2379315 0.7160225 0.9121322
> 0.2701988 0.371379 0.869047
> 0.2939349 0.2881057 0.8572388
> 0.686119 0.3435468 0.8652209
> 0.737684 0.1018767 0.818933
> 0.1022111 0.4620055 0.8806782
> 0.06743866 0.001328434 0.7155677
> 0.3189881 0.8103201 0.9257696
> 0.002606828 0.2529638 0.85179
> 0.754083 0.7591491 0.9180267
> 0.7783337 0.6120818 0.8988813
> 0.09418842 0.4592762 0.8803417
> 0.1289346 0.05072358 0.7982676
> 0.7680676 0.723607 0.913101
> 0.09463494 0.3502957 0.8662194
> 0.6247462 0.4354511 0.8773048
> 0.5472626 0.2640714 0.8534728
> 0.8046991 0.4033715 0.8731942
> 0.992037 0.8971756 0.9419815
> 0.1490033 0.5284286 0.8887884
> 0.1480197 0.5933815 0.8966606
> 0.4580494 0.5930807 0.8965908
> 0.4352076 0.4091756 0.8739806
> 0.3295796 0.1434968 0.8303327
> 0.431351 0.1096168 0.8213174
> 0.3167224 0.0862319 0.8137642
> 0.7067212 0.3611669 0.8676301
> 0.2601349 0.276127 0.8554021
> 0.4183247 0.7391175 0.9152474
> 0.5419186 0.5523624 0.8916447
> 0.9137419 0.8009559 0.9242306
> 0.9947217 0.7134031 0.9116726
> 0.7504282 0.1754408 0.8374331
> 0.3895617 0.3479445 0.8658571
> 0.6451314 0.6753639 0.9067933
> 0.6406233 0.3609228 0.867604
> 0.1448996 0.4616181 0.8806225
> 0.07675675 0.2447339 0.8503745
> 0.7305003 0.6765511 0.9069367
> 0.4862806 0.7636162 0.9186905
> 0.3355425 0.4680102 0.8813898
> 0.1981130 0.06148056 0.8037123
> 0.7579405 0.3969405 0.8723663
> 0.6168173 0.5598662 0.892546
> 0.4375986 0.5554698 0.8920301
> 0.4461622 0.7040231 0.910523
> 0.8777072 0.5413942 0.8902793
> 0.6782004 0.7177896 0.9123287
> 0.7209967 0.7495791 0.9166762
> 0.3230692 0.4923728 0.8843828
> 0.4387517 0.5043017 0.8858267
> 0.5148218 0.4466403 0.8787188
> 0.3047676 0.7538997 0.917321
> 0.9527929 0.1671429 0.8356328
> 0.9513049 0.3790206 0.8699783
> 0.6636276 0.5972614 0.8970817
> 0.1938244 0.4355477 0.8773607
> 0.3600900 0.4452904 0.8785646
> 0.2040542 0.2728078 0.8548912
> 0.4846581 0.2225607 0.846501
> 0.7091428 0.239741 0.8494566
> 0.5655244 2.537281e-05 0.6471484
> 0.4467683 0.1794644 0.838298
> 0.5270517 0.2173856 0.8455707
> 0.4940919 0.3665292 0.8683744
> 0.7128475 0.00847929 0.7538282
> 0.6727687 0.03073103 0.7847315
> 0.7023412 0.1143117 0.8226524
> 0.6435959 0.8386252 0.9304646
> 0.4167312 0.6090668 0.8985462
> 0.682974 0.7439136 0.9158887
> 0.5743695 0.9627705 0.9624433
> 0.4746829 0.2658398 0.8537617
> 0.2591787 0.05880024 0.802423
> 0.5281165 0.6724808 0.906436
> 0.2721701 0.4292930 0.8765619
> 0.5527161 0.5641951 0.8930761
> 0.4820321 0.5303901 0.8889902
> 0.519115 0.6716372 0.9063293
> 0.06265548 0.955931 0.9595114
> 0.3800652 0.7018464 0.9102427
> 0.3546165 0.415416 0.8747885
> 0.6800597 0.9266552 0.9495428
> 0.4970227 0.9582172 0.960424
> 0.5395118 0.999861 1.021719
> 0.3521434 0.5106511 0.8866073
> 0.6013237 0.7820113 0.9213758
> 0.8364799 0.7461522 0.9161836
> 0.571522 0.9823802 0.9742642
> 0.4043184 0.5279379 0.8887002
> 0.7320448 0.08124245 0.8118969
> 0.4386114 0.7264156 0.9135103
> 0.649196 0.4673266 0.8812757
> 0.2198846 0.4410754 0.878052
> 0.2285649 0.6274793 0.900828
> 0.5241012 0.8958289 0.9417466
> 0.362962 0.315014 0.8612168
> 0.3052995 0.3960945 0.8723014
> 0.905782 0.3447792 0.8653598
> 0.8931942 0.6032726 0.8977864
> 0.4266403 0.4421003 0.8781588
> 0.6388304 0.6090837 0.8985284
> 0.56878 0.579462 0.8949255
> 0.2950412 0.7102818 0.9113629
> 0.8296596 0.9120703 0.9456078
> 0.8635411 0.5362425 0.889658
> 0.9661249 0.6000882 0.897377
> 0.8104151 0.7164646 0.9121375
> 0.6788884 0.6432019 0.9027357
> 0.8568189 0.3015897 0.8591981
> 0.8460857 0.5678257 0.8934844
> 0.3145571 0.1828112 0.8389946
> 0.8994917 0.4629269 0.8806988
> 0.3515329 0.6217972 0.9001149
> 0.2874208 0.5560029 0.892109
> 0.4120654 0.7204939 0.9127143
> 0.1825168 0.5184448 0.887573
> 0.9755303 0.7021669 0.9102076
> 0.6491138 0.7110952 0.9114395
> 0.3967447 0.3955594 0.8722225
> 0.7102073 0.1843923 0.8392725
> 0.2964985 0.1360965 0.8285183
> 0.1869265 0.5907168 0.8963308
> 0.4028261 0.757025 0.9177552
> 0.6887386 0.7294083 0.9138946
> 0.8914899 0.7315796 0.9141653
> 0.4680622 0.6889618 0.9085565
> 0.5421646 0.551866 0.8915845
> 0.3836133 0.3281107 0.863089
> 0.7949356 0.698984 0.9098294
> 0.652499 0.7218326 0.9128735
> 0.923453 0.5489377 0.8911828
> 0.872984 0.1647356 0.835132
> 0.9080439 0.3139736 0.8610017
> 0.9078707 0.3264533 0.862792
> 0.1497525 0.6098135 0.8986666
> 0.2727475 0.5059691 0.886046
> 0.1080346 0.6117073 0.8989056
> 0.7163249 0.4961443 0.884806
> 0.1665438 0.7095927 0.9112861
> 0.1147964 0.7040084 0.9105571
> 0.6361728 0.4526705 0.8794596
> 0.2948908 0.6166378 0.899486
> 0.2754661 0.7791832 0.9209829
> 0.5040162 0.4605482 0.8804507
> 0.7755624 0.7083473 0.9110629
> 0.007938672 0.6512774 0.9038441
> 0.2143095 0.7018575 0.9102607
> 0.4256598 0.3218441 0.862193
> 0.7021327 0.1471694 0.83117
> 0.8541683 0.5130324 0.8868449
> 0.8165188 0.8621911 0.9347445
> 0.6407761 0.48237 0.8831282
> 0.5312793 0.5385175 0.88997
> 0.4844806 0.6393667 0.902276
> 0.8293853 0.7139695 0.9118023
> 0.9128633 0.716203 0.9120864
> 0.5514199 0.503507 0.8857197
> 0.3412234 0.7031551 0.910418
> 0.4681908 0.8509374 0.932675
> 0.5099785 0.897836 0.9422059
> 0.613507 0.8843356 0.9392177
> 0.5615576 0.5944772 0.8967518
> 0.2233283 0.5227858 0.8880943
> 0.7192387 0.1106780 0.8215985
> 0.6253335 0.5056905 0.8859786
> 0.3923049 0.7112349 0.9114802
> 0.5103654 0.6072716 0.8983182
> 0.8546338 0.6290934 0.9009646
> 0.2189133 0.4025152 0.8731445
> 0.1557879 0.9385458 0.9531978
> 0.3178054 0.4950795 0.884714
> 0.4594106 0.4929672 0.8844424
> 0.2145317 0.6494829 0.9035634
> 0.7338679 0.0743877 0.8092418
> 0.2910765 7.344265e-06 0.6282273
> 0.6739632 0.04388068 0.7941999
> 0.4262167 0.788432 0.9223558
> 0.815637 0.4462349 0.8786363
> 0.4944984 0.0325375 0.7862377
> 0.5482012 0.6671962 0.9057626
> 0.7203222 0.6536981 0.904044
> 0.6473953 0.4267527 0.8762038
> 0.1459738 0.2673097 0.8540337
> 0.3430013 0.9186308 0.9473533
> 0.3968373 0.6025617 0.8977525
> 0.4825984 0.8971687 0.942055
> 0.6915212 0.4134755 0.8745077
> 0.7016574 0.2524424 0.8515746
> 0.4246859 0.7426717 0.9157385
> 0.004345354 0.7664402 0.9191835
> 0.03124377 0.8600277 0.93442
> 0.2576312 0.2757442 0.8553429
> 0.2569686 0.7540984 0.9173539
> 0.1386583 0.5013163 0.8854969
> 0.004756962 0.5166277 0.8874133
> 0.6976297 0.4815717 0.8830245
> 0.697404 0.4244274 0.8759037
> 0.8112176 0.5899199 0.8961713
> 0.713734 0.3745925 0.8694313
> 0.8887044 0.85696 0.9337461
> 0.2278300 0.9559154 0.9594826
> 0.9451097 0.5987058 0.8972164
> 0.1199859 0.713117 0.9117607
> 0.2427017 0.8342876 0.9297474
> 0.3799076 0.6385965 0.9021895
> 0.780296 0.3971621 0.8723923
> 0.4833612 0.6403189 0.9023944
> 0.6143626 0.6414991 0.9025297
> 0.7478517 0.8341564 0.9296813
> 0.5848616 0.2031911 0.842948
> 0.803453 0.02763294 0.7819796
> 0.8947829 0.1982048 0.8419586
> 0.5401919 0.3691551 0.8687224
> 0.8064726 0.2461822 0.8505264
> 0.9174961 0.9000155 0.9426684
> 0.8649377 0.7263216 0.9134553
> 0.368144 0.3114216 0.860695
> 0.3960397 0.7991588 0.9240037
> 0.7474788 0.7891092 0.9224306
> 0.8244429 0.4399955 0.8778534
> 0.4090636 0.9744874 0.9686875
> 0.60864 0.3629311 0.8678787
> 0.8792287 0.1042003 0.8196308
> 0.5568143 0.6392743 0.9022581
> 0.2410288 0.7310255 0.9141548
> 0.5096632 0.5728588 0.8941298
> 0.6754568 0.7334808 0.9144511
> 0.9016902 0.8356986 0.929927
> 0.794581 0.823762 0.9279195
> 0.3333656 0.7053623 0.9107092
> 0.7280451 0.919738 0.9476197
> 0.5522382 0.1590644 0.8339207
> 0.6466815 0.6127797 0.8989805
> 0.8000029 0.4637126 0.8808121
> 0.5983007 0.4788531 0.8827005
> 0.01127508 0.5186316 0.8876452
> 0.013699 0.563469 0.8930714
> 0.2427855 0.8413799 0.9309814
> 0.7656437 0.8558567 0.933556
> 0.7712339 0.6979084 0.9096916
> 0.7820254 0.2107216 0.8443285
> 0.2098941 0.3466435 0.8656979
> 0.6803271 5.67055e-05 0.6599548
> 0.8533364 0.04563989 0.79525
> 0.3460994 0.4376786 0.8776115
> 0.1276769 0.8358598 0.9300324
> 0.1840423 0.5695211 0.893758
> 0.1898183 4.343381e-13 0.4279754
> 0.5374682 3.43534e-07 0.5847877
> 0.9653777 0.2941263 0.8580566
> 0.793583 0.7093681 0.9111959
> 0.767547 0.2485699 0.8509283
> 0.6692159 0.9999993 1.049294
> 0.8284223 0.1368672 0.8286505
> 0.9165768 0.7461044 0.9161635
> 0.07780481 0.2581183 0.8525758
> 0.8283647 0.07059201 0.8076717
> 0.4945938 0.08162078 0.8120646
> 0.7121621 0.5978781 0.897152
> 0.003852813 0.1328189 0.8277767
> 0.7119404 0.05172274 0.7987407
> 0.8855203 0.6257442 0.900546
> 0.9218816 0.8273478 0.9285
> 0.9233806 0.7509503 0.9168407
> 0.2593601 0.08886668 0.8146992
> 0.5798519 0.8080687 0.9253888
> 0.2083358 0.9943995 0.9891006
> 0.9928156 0.811554 0.925873
> 0.6316176 0.7618544 0.9184253
> 0.2909255 0.2391205 0.8493947
> 0.4806987 0.05703826 0.8015291
> 0.8148117 0.6490257 0.9034478
> 0.5015989 0.7569907 0.917742
> 0.618849 0.8112648 0.925896
> 0.8680278 0.1261190 0.8258788
> 0.9843081 0.4610686 0.8804365
> 0.981136 0.5933233 0.8965434
> 0.3402781 0.7650686 0.9189122
> 0.636855 0.6395097 0.9022802
> 0.1015914 0.9004152 0.9428428
> 0.01417522 0.1301853 0.8270804
> 0.01399330 0.4096037 0.8741114
> 0.3585436 0.1450862 0.830711
> 0.8398029 0.6609509 0.9049425
> 0.5550948 0.8041808 0.9247759
> 0.3279216 0.3477294 0.8658338
> 0.800509 0.7437003 0.9158468
> 0.8634276 0.2644834 0.8535005
> 0.4027558 0.03161294 0.7854964
> 0.9603643 0.08939088 0.814781
> 0.8684457 0.2258063 0.847029
> 0.2337130 0.6693651 0.906067
> 0.8418288 0.06168066 0.8037274
> 0.6960713 0.236729 0.8489459
> 0.9778375 0.1392889 0.8292076
> 0.909325 0.4792852 0.8827139
> 0.6743998 0.001302298 0.7150928
> 0.002995692 0.3198894 0.862011
> 0.7865613 0.8194578 0.9272093
> 0.7795525 0.7334021 0.9144298
> 0.983064 0.3390965 0.8645403
> 0.8615933 0.2985286 0.8587428
> 0.008317132 0.2811343 0.8562448
> 0.3336097 0.5237279 0.8881966
> 0.6511454 0.5833166 0.895386
> 0.8859316 0.6190705 0.899724
> 0.01688167 0.1500001 0.8319426
> 0.002360940 0.1319095 0.8275506
> 0.6274613 0.5826939 0.8953125
> 0.008114898 0.6664864 0.9057595
> 0.001045473 0.2242417 0.8469188
> 0.0508478 0.4957073 0.8848329
> 0.5888479 0.914019 0.946127
> 0.7740566 0.8235836 0.9278921
> 0.8057038 0.3660084 0.8682713
> 0.4770886 0.6560355 0.9043598
> 0.5256923 0.8803939 0.938396
> 0.8566784 0.7790501 0.9209085
> 0.7719712 0.6309976 0.901211
> 0.1469819 0.8088482 0.9255534
> 0.2189924 0.03436754 0.7877055
> 0.9558648 0.1629045 0.8347084
> 0.9225076 0.2217156 0.846293
> 0.8208944 0.8208895 0.9274408
> 0.2174652 0.1468581 0.8311496
> 0.618421 0.4026186 0.8731176
> 0.6247648 0.7436365 0.9158555
> 0.2372800 0.2181356 0.8457368
> 0.7013663 0.8468071 0.931908
> 0.7868276 0.9131027 0.945875
> 0.6576328 0.585279 0.8956237
> 0.9719215 0.4717628 0.8817672
> 0.7798435 0.1481837 0.8313995
> 0.6780997 0.5981976 0.8971944
> 0.3070307 0.1875593 0.8399491
> 0.4197094 0.5990637 0.8973235
> 0.5040344 0.1640605 0.8350302
> 0.8834981 0.6167573 0.89944
> 0.1481133 0.8285937 0.9287888
> 0.1471865 0.6445625 0.9029578
> 0.1327257 0.6725547 0.906486
> 0.3433113 0.6927705 0.9090613
> 0.2946019 0.4352499 0.8773112
> 0.003406429 0.3938362 0.8720895
> 0.2857042 0.5735738 0.8942374
> 0.6455505 0.2243478 0.8468013
> 0.9490315 0.2099423 0.8441508
> 0.04602036 0.3690979 0.8687822
> 0.1056053 0.7631722 0.918667
> 0.6817949 0.528255 0.8887128
> 0.5644347 0.6491707 0.9034914
> 0.7570488 0.7966135 0.9235781
> 0.6593145 0.2074085 0.84373
> 0.8925004 0.6638273 0.9052974
> 0.1246228 0.4961518 0.8848695
> 0.7857138 0.542488 0.890425
> 0.8963653 0.2669431 0.8538854
> 0.6514738 0.7706894 0.919701
> 0.2293905 0.8438272 0.9314158
> 0.3912309 0.6160558 0.8994053
> 0.2982153 0.5130745 0.8869073
> 0.4044714 0.7306236 0.9140846
> 0.9431583 0.616781 0.8994294
> 0.04552623 0.8735693 0.9370548
> 0.7237478 0.6736022 0.9065609
> 0.6859905 0.8343209 0.9297154
> 0.7823167 0.7148671 0.9119277
> 0.9521752 0.3384298 0.8644647
> 0.2351690 0.243558 0.85015
> 0.3056817 0.5057963 0.8860215
> 0.5686026 0.6364396 0.901905
> 0.7356786 0.4167618 0.8749232
> 0.2266795 0.7380897 0.915124
> 0.3347846 0.8819222 0.9387305
> 0.3956415 0.8593319 0.9342383
> 0.7768104 0.8177261 0.9269268
> 0.3056832 0.5966309 0.8970376
> 0.5204085 0.8136706 0.9262912
> 0.2521421 0.3396209 0.8647196
> 0.2473847 0.2164454 0.8454306
> 0.1108629 0.4169697 0.8750187
> 0.2838937 0.3549462 0.8668274
> 0.5465899 0.5446338 0.8907089
> 0.1034264 0.7386064 0.9152123
> 0.2498704 0.09973506 0.8183126
> 0.1136003 0.2718162 0.8547505
> 0.4172970 0.5540139 0.8918557
> 0.1390018 0.8442352 0.9314993
> 0.005563172 0.8066043 0.9252453
> 0.5818675 0.6424044 0.9026453
> 0.1430274 0.674245 0.9066999
> 0.03769988 0.4290427 0.8765737
> 0.8556575 0.3844797 0.870722
> 0.8775405 0.417829 0.8750397
> 0.9104062 0.6323445 0.9013568
> 0.1074026 0.2182002 0.8457692
> 0.7204749 0.1104211 0.821523
> 0.3492221 0.3339966 0.8639225
> 0.1576476 0.4215118 0.8755896
> 0.9048666 0.6262912 0.9006098
> 0.4718103 0.2724998 0.8548135
> 0.4361739 0.09929708 0.8181518
> 0.2972725 0.7777231 0.9207644
> 0.5665044 0.8808408 0.938486
> 0.738228 0.5602356 0.8925787
> 0.5540302 0.5708308 0.89388
> 0.1375065 0.8168868 0.9268497
> 0.07578065 0.3489205 0.8660352
> 0.3726154 0.2491216 0.851061
> 0.6368203 0.7509145 0.9168716
> 0.8306685 0.777946 0.9207484
> 0.2833806 0.5546789 0.8919492
> 0.09934053 0.6805804 0.9075179
> 0.1655332 0.8468221 0.9319582
> 0.2844294 0.8254702 0.928249
> 0.1464508 0.9015246 0.943096
> 0.389557 0.6143054 0.8991906
> 0.1621419 0.6400966 0.9023995
> 0.0971209 0.4490999 0.8790752
> 0.2709383 0.8486465 0.9322756
> 0.4742362 0.4121831 0.874363
> 0.6779411 0.5489203 0.8912153
> 0.5392679 0.3478413 0.8658285
> 0.4443618 0.6275902 0.9008207
> 0.08832718 0.5932862 0.8966598
> 0.5118831 0.01596035 0.7684642
> 0.9978362 0.2475618 0.850678
> 0.2128232 0.9456008 0.9555712
> 0.1790925 0.6703308 0.9061963
> 0.7668958 0.4674435 0.8812775
> 0.1564061 0.2451245 0.8504234
> 0.1336754 0.3983315 0.8726147
> 0.0975977 0.2043324 0.8432229
> 0.01216834 0.2339812 0.8485838
> 0.1569461 0.5324595 0.8892754
> 0.04365445 0.4410925 0.8780887
> 0.2494574 0.02976159 0.7839518
> 0.7012898 0.4499832 0.879118
> 0.4708703 0.4863704 0.8836344
> 0.5920373 0.707517 0.910971
> 0.9561298 0.1947485 0.8412737
> 0.4952743 0.03657176 0.7893157
> 0.915553 0.4239565 0.875812
> 0.7713963 0.06609137 0.805744
> 0.05493889 0.2130792 0.844855
> 0.6821484 0.7026926 0.9103274
> 0.5336243 0.91109 0.9453866
> 0.6867021 0.7411612 0.9155066
> 0.975979 0.04527906 0.7949923
> 0.837784 0.74753 0.9163759
> 0.4934895 0.416351 0.8748948
> 0.005828299 0.3566607 0.8671348
> 0.3310498 0.8961609 0.9418372
> 0.03192657 0.850284 0.932612
> 0.08457336 0.6901218 0.9087509
> 0.2031292 0.4299748 0.8766564
> 0.7614405 0.7459437 0.9161635
> 0.2555080 0.674626 0.9067344
> 0.7083119 0.4501719 0.8791408
> 0.945163 0.1646992 0.8351056
> 0.06908377 0.2324591 0.8482912
> 0.03880391 0.2281361 0.8475513
> 0.5105381 0.8672677 0.9357525
> 0.05855021 0.5165195 0.8873631
> 0.1300929 0.8829 0.9389577
> 0.1747403 0.1704515 0.8364469
> 0.2981974 0.1595222 0.8340497
> 0.0055007 0.3530877 0.8666484
> 0.7576901 0.264833 0.8535717
> 0.6933019 0.5738702 0.8942353
> 0.6443269 0.2171339 0.8455133
> 0.4122726 0.490008 0.884085
> 0.08336114 0.6785415 0.9072598
> 0.5589743 0.7387024 0.9151783
> 0.92432 0.6836011 0.907813
> 0.9606246 0.1255525 0.825702
> 0.4450934 0.2194885 0.8459569
> 0.5807345 0.4559498 0.8798728
> 0.6236046 0.5395055 0.890081
> 0.5478731 0.8940408 0.9413413
> 0.8278164 0.5863816 0.8957387
> 0.8017402 0.2607101 0.8529055
> 0.7423169 0.7402687 0.9153777
> 0.4548012 0.4569796 0.8800124
> 0.1770415 0.5387303 0.8900318
> 0.9073766 0.3520192 0.8663556
> 0.1492733 0.1125281 0.8222042
> 0.07429098 0.2712785 0.8546752
> 0.3683862 0.6588343 0.9047215
> 0.680869 0.7330059 0.9143857
> 0.7384956 0.6025491 0.8977193
> 0.3808318 0.3140541 0.861076
> 0.2843261 0.6324584 0.9014375
> 0.1436439 0.5258806 0.8884804
> 0.4224504 0.5743372 0.8943168
> 0.7524093 0.3438394 0.8652539
> 0.9357195 0.5169828 0.8873079
> 0.4036766 0.6824951 0.9077281
> 0.1014471 0.7351924 0.9147434
> 0.3524282 0.3972935 0.8724525
> 0.9483054 0.3513068 0.8662465
> 0.4396423 0.4028961 0.8731704
> 0.3531021 0.2731345 0.8549248
> 0.4443184 0.3142964 0.8611048
> 0.3768978 0.5842775 0.8955275
> 0.2466269 0.2663774 0.8538713
> 0.5962991 0.00470513 0.7410197
> 0.3756412 0.2967521 0.858532
> 0.04994566 0.2117102 0.8446063
> 0.1080174 0.4622149 0.880703
> 0.3629230 0.5252755 0.8883814
> 0.1887335 0.292769 0.8579568
> 0.3519446 0.7994556 0.9240536
> 0.1217339 0.1401854 0.8295575
> 0.174763 0.618114 0.8996812
> 0.4586664 0.6402342 0.902386
> 0.5343869 0.3013533 0.8592008
> 0.2161009 0.3156891 0.861331
> 0.17651 0.4887034 0.8839512
> 0.9917181 0.4244217 0.8758332
> 0.604959 0.2353208 0.8487147
> 0.8332544 0.5308923 0.8890146
> 0.51212 0.596579 0.8970123
> 0.5994383 0.2876340 0.8571365
> 0.8807404 0.4205335 0.875384
> 0.072703 0.503507 0.8857772
> 0.1272491 0.7729678 0.9200844
> 0.5047155 0.903465 0.943523
> 0.1129428 0.8151764 0.9265756
> 0.546922 0.6979866 0.909723
> 0.9591556 0.02840703 0.7826478
> 0.8617191 0.1017775 0.8188833
> 0.6370122 0.1468348 0.831098
> 0.431313 0.7198841 0.9126308
> 0.1316088 0.8709087 0.9365054
> 0.7881227 0.8493899 0.9323656
> 0.6531763 0.6218253 0.9000913
> 0.790503 0.6167768 0.899456
> 0.8466432 0.9889855 0.9807199
> 0.6609452 0.3529404 0.8665161
> 0.9637131 0.1053617 0.8199601
> 0.6903624 0.3402932 0.8647688
> 0.8406482 0.3099546 0.8604301
> 0.4943412 0.5324295 0.8892361
> 0.5210708 0.1568008 0.8334152
> 0.9086716 0.5761234 0.8944793
> 0.09083374 0.5520557 0.891659
> 0.6066495 0.5805193 0.8950504
> 0.5294395 0.5708622 0.893886
> 0.02075211 0.8740981 0.9371722
> 0.3150380 0.4126541 0.874439
> 0.8028235 0.4867181 0.8836432
> 0.5138899 0.2777579 0.855629
> 0.2610341 0.4841342 0.883381
> 0.2810478 0.4913972 0.884268
> 0.9002693 0.4355419 0.8772805
> 0.7717612 0.6170158 0.8994875
> 0.8091782 0.598264 0.897188
> 0.5719824 0.6296076 0.9010587
> 0.5029268 0.5059016 0.8860156
> 0.613944 0.2153304 0.8451901
> 0.2244824 0.1831607 0.8390764
> 0.7980058 0.1371974 0.8287375
> 0.932274 0.4284666 0.8763795
> 0.6961254 0.4558324 0.8798468
> 0.3442136 0.1641236 0.8350606
> 0.5064431 0.1621777 0.8346166
> 0.4151743 0.4776614 0.882571
> 0.06262435 0.7949185 0.9233896
> 0.7819505 0.6249127 0.9004582
> 0.5856734 0.3304368 0.8633984
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marco at imada.sdu.dk  Wed Dec 13 12:57:37 2006
From: marco at imada.sdu.dk (Marco Chiarandini)
Date: Wed, 13 Dec 2006 12:57:37 +0100 (CET)
Subject: [R] Passing arguments to panels in trellis plots
Message-ID: <Pine.LNX.4.61.0612131250210.21896@minnie.imada.sdu.dk>

Dear all,

I am trying to produce survfit plots in a trellis environment and I
would like the plots to be logarithmic.

I am trying this:

print(Ecdf(~time | size*type, groups=alg,data=B,subscripts=TRUE,
            panel=function(x,groups,subscripts)
            {
              t <- survfit(Surv(time[subscripts],event[subscripts])~groups[subscripts],data=B)
              panel.xyplot(t[1]$time,1-t[1]$ssurv,type="s",lty=2)
              panel.xyplot(t[2]$time,1-t[2]$ssurv,type="s",lty=2)
            },
 	   scale=list(log=TRUE)
)



but data are transformed in logarithm before being passed to the panel
and hence the output of the function survfit is not the expected one.

Is there a way to plot this correctly, ie, having first the survfit
computed and then the plot, like in:

plot(survfit(Surv(time,event)~groups,data=B),log=true)

Thanks in advance.

- Marco.


--
Marco Chiarandini                     http://www.imada.sdu.dk/~marco
Department of Mathematics	      Email: marco AT imada.sdu.dk
and Computer Science,		      Phone: +45 6550 4031
University of Southern Denmark        Fax: +45 6593 2691


From ccleland at optonline.net  Wed Dec 13 12:58:39 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 13 Dec 2006 06:58:39 -0500
Subject: [R] Questions about saving output files and popup
In-Reply-To: <20061213105332.M34472@cc.kmu.edu.tw>
References: <20061213105332.M34472@cc.kmu.edu.tw>
Message-ID: <457FEAEF.6020402@optonline.net>

u9470002 wrote:
> Hi all:
> 
>    After calculating in R I want to show the answer and some explanations not
> graphic plots in another new device and then save it as txt.file. However, I
> couldn't find any package or command to do it yet. I know some commands about
> generating graphics on different types of display or printing device. ex :
> windows(), postscript(), pdf() and etc. But these all works for graphic plots,
> not words. And I know I could save it as txt file by "selecting them and
> choosing the button of save to file". However,it would be better for me if I
> can save it as txt.file or pdf.file by command line. I would like to ask is it
> possible to do these in R? 
>  
>   Welcome your any advise, I will be appreciate it very very much.
>   Thanks in advance.

RSiteSearch("text output", restrict="functions")

  should point you to a number of potential tools.  Also, have a look at
?sink in particular.

> Regards,
> Ruby Chen(Taiwan)
> 
> --
> Miou-Ting Chen ?????@
> Graduate Institute of Clinical Pharmacy
> College of Pharmacy Kaohsiung Medical University
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From ripley at stats.ox.ac.uk  Wed Dec 13 13:24:40 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 13 Dec 2006 12:24:40 +0000 (GMT)
Subject: [R] expression()
In-Reply-To: <457FE64D.40807@ija.csic.es>
References: <457ED1CF.2060500@ija.csic.es>
	<F5A97ABA-8B6C-4EC7-A40C-B93D724B8CA6@jhsph.edu>
	<457FE64D.40807@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0612131222590.6286@gannet.stats.ox.ac.uk>

On Wed, 13 Dec 2006, javier garcia-pintado wrote:

> Thanks you,
> this works right.
>
> I just would like to note one thing:
> although I've found italic() in the help for plotmath and I can see that
> the italic function:
>
> mtext(expression(italic(beta)[max]),side=1,line=2)
>
> does not work on the greek beta character.

No, and there is no italic symbol font in the R graphics model so no means 
of plotting such a symbol.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gsmatos1 at ig.com.br  Wed Dec 13 13:34:04 2006
From: gsmatos1 at ig.com.br (gsmatos1)
Date: Wed, 13 Dec 2006 09:34:04 -0300
Subject: [R] Error to install fMultivar package
Message-ID: <20061213_123404_074050.gsmatos1@ig.com.br>

Hi, 

I tried to install fMultivar package but an error occurs that I could not 
understand. 
(I've been worked with linux / Ubuntu 6.06 LTS) 

> install.packages("fMultivar") 
Warning in install.packages("fMultivar") : argument 'lib' is missing: using 
/usr /local/lib/R/site-library 
--- Please select a CRAN mirror for use in this session --- 
Loading Tcl/Tk interface ... done 
trying URL 
'http://lmq.esalq.usp.br/CRAN/src/contrib/fMultivar_221.10065.tar.gz' 
Content type 'application/x-gzip' length 1152747 bytes 
opened URL 
================================================== 
downloaded 1125Kb 

* Installing *source* package 'fMultivar' ... 
** libs 
gcc -I/usr/share/R/include -I/usr/share/R/include      -fpic  -g -O2 
-std=gnu99 -c 00A-randomF77.c -o 00A-randomF77.o 
gcc -I/usr/share/R/include -I/usr/share/R/include      -fpic  -g -O2 
-std=gnu99 -c 00B-GarchBEKK.c -o 00B-GarchBEKK.o 
g77   -fpic  -g -O2 -c 42A-1ReggressionModelling.f -o 
42A-1ReggressionModelling.o 
g77   -fpic  -g -O2 -c 42A-2RegressionModelling.f -o 
42A-2RegressionModelling.o 
gcc -I/usr/share/R/include -I/usr/share/R/include      -fpic  -g -O2 
-std=gnu99 -c 42A-3RegressionModelling.c -o 42A-3RegressionModelling.o 
g77   -fpic  -g -O2 -c 42B-RegressionTests.f -o 42B-RegressionTests.o 
g77   -fpic  -g -O2 -c 46A-VectorMatrixAddon.f -o 46A-VectorMatrixAddon.o 
gcc -I/usr/share/R/include -I/usr/share/R/include      -fpic  -g -O2 
-std=gnu99 -c 46B-MissingValues.c -o 46B-MissingValues.og77   -fpic  -g -O2 
-c 47B-MultivariateDistribution.f -o 47B-MultivariateDistribution.o 
gcc -I/usr/share/R/include -I/usr/share/R/include      -fpic  -g -O2 
-std=gnu99 -c runfunc.c -o runfunc.o 
gcc -shared  -o fMultivar.so 00A-randomF77.o 00B-GarchBEKK.o 
42A-1ReggressionModelling.o 42A-2RegressionModelling.o 
42A-3RegressionModelling.o 42B-RegressionTests.o 46A-VectorMatrixAddon.o 
46B-MissingValues.o 47B-MultivariateDistribution.o runfunc.o -lblas-3 -lg2c 
-lm -lgcc_s -L/usr/lib/R/lib -lR 
/usr/bin/ld: cannot find -lblas-3 
collect2: ld returned 1 exit status 
make: *** [fMultivar.so] Error 1 
ERROR: compilation failed for package 'fMultivar' 
** Removing '/usr/local/lib/R/site-library/fMultivar' 

The downloaded packages are in 
        /tmp/RtmpXxDoFd/downloaded_packages 
Warning message: 
installation of package 'fMultivar' had non-zero exit status in: 
install.packages("fMultivar") 
> 

Thanks in advance for any help! 
Gilberto. 



From anilomjf at yahoo.es  Wed Dec 13 13:39:16 2006
From: anilomjf at yahoo.es (Francisco J Molina)
Date: Wed, 13 Dec 2006 13:39:16 +0100
Subject: [R] (no subject)
Message-ID: <17791.62580.588375.222061@localhost.localdomain>


Hi,

Let us suppose I have a list 

x = list ()
x $ name1 = 1
x $ name2 = 'a'

in the work environment.

Let us suppose that in the body of a function I want to acces to a component of x by
using its name as argument of that function. How can this by done? For instance, I was
expecting

f = function ( name ) x $ name

to output 

1 ( that is, x $ name1 )

when I command f ( name1 ) or f ( 'name1' ), but that is not happening. Does anyone knows
how I can fix f to give me x $ name, while the argument is still the name of the
component of x?

Thank you.


From lukanlu at yahoo.co.uk  Wed Dec 13 13:40:36 2006
From: lukanlu at yahoo.co.uk (lu kan)
Date: Wed, 13 Dec 2006 12:40:36 +0000 (GMT)
Subject: [R] Install R in Linux
Message-ID: <20061213124036.79263.qmail@web28008.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061213/2bbf4cbf/attachment.pl 

From scionforbai at gmail.com  Wed Dec 13 13:52:03 2006
From: scionforbai at gmail.com (Scionforbai)
Date: Wed, 13 Dec 2006 13:52:03 +0100
Subject: [R] (no subject)
In-Reply-To: <17791.62580.588375.222061@localhost.localdomain>
References: <17791.62580.588375.222061@localhost.localdomain>
Message-ID: <e9ee1f0a0612130452r2855e9d6n374ed39b169bd6a4@mail.gmail.com>

Just read some introductory R tutorial...

> x = list ()
> x $ name1 = 1
> x $ name2 = 'a'
> x
$name1
[1] 1

$name2
[1] "a"
> name <- "name1"
> x[name]
$name1
[1] 1
> x[[name]]
[1] 1

> name <- "name2"
> x[name]
$name2
[1] "a"
> x[[name]]
[1] "a"


Bye,
Scionforbai


From P.Dalgaard at biostat.ku.dk  Wed Dec 13 14:06:08 2006
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 13 Dec 2006 14:06:08 +0100
Subject: [R] Install R in Linux
In-Reply-To: <20061213124036.79263.qmail@web28008.mail.ukl.yahoo.com>
References: <20061213124036.79263.qmail@web28008.mail.ukl.yahoo.com>
Message-ID: <457FFAC0.1020009@biostat.ku.dk>

lu kan wrote:
> Hi, Is it possible to install R in a linux box (Debian) without being a root. I know I can compile the R source code, but there is no F77 compiler on the box. So is it possible to install binary R without being a root?
>   
(We did see it the first time!!)

In a word, no. Either you need to install the binaries as root or
install sufficient build tools as root. There's a slight chance that you
could unpack the Debian binaries somewhere and then fix up the paths,
but you're on your own.


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ligges at statistik.uni-dortmund.de  Wed Dec 13 14:06:27 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 13 Dec 2006 14:06:27 +0100
Subject: [R] (no subject)
In-Reply-To: <17791.62580.588375.222061@localhost.localdomain>
References: <17791.62580.588375.222061@localhost.localdomain>
Message-ID: <457FFAD3.3000304@statistik.uni-dortmund.de>



Francisco J Molina wrote:
> Hi,
> 
> Let us suppose I have a list 
> 
> x = list ()
> x $ name1 = 1
> x $ name2 = 'a'
> 
> in the work environment.
> 
> Let us suppose that in the body of a function I want to acces to a component of x by
> using its name as argument of that function. How can this by done? For instance, I was
> expecting
> 
> f = function ( name ) x $ name

f <- function(name) x[[name]]
Please read the docs such as help("$").

Uwe Ligges


> to output 
> 
> 1 ( that is, x $ name1 )
> 
> when I command f ( name1 ) or f ( 'name1' ), but that is not happening. Does anyone knows
> how I can fix f to give me x $ name, while the argument is still the name of the
> component of x?
> 
> Thank you.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From scionforbai at gmail.com  Wed Dec 13 14:13:36 2006
From: scionforbai at gmail.com (Scionforbai)
Date: Wed, 13 Dec 2006 14:13:36 +0100
Subject: [R] Error to install fMultivar package
In-Reply-To: <20061213_123404_074050.gsmatos1@ig.com.br>
References: <20061213_123404_074050.gsmatos1@ig.com.br>
Message-ID: <e9ee1f0a0612130513u124d7682s2b08792677961d53@mail.gmail.com>

Just a few tip, I don't know very much about ubuntu. Relevant is:

> /usr/bin/ld: cannot find -lblas-3

It means, it doesn't find the library blas-3 (libblas-3). Maybe they
are installed on your system but in a non-standard dir. Look around
("locate blas", if updatedb is set on your system); if you find them,
a symlink could fix the issue; if not, maybe you need to install atlas
or the atlas-dev, something like:

http://packages.ubuntulinux.org/dapper/devel/atlas3-sse2-dev

(sorry, I don't know if "dapper" == 6.06, but I don't think it can vary so much)
Just give a try, and use apt to download all the required libs.


Try also to add "dependencies=TRUE" to install.packages().

Does it help?

Scionforbai


From info at aghmed.fsnet.co.uk  Wed Dec 13 14:37:12 2006
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Wed, 13 Dec 2006 13:37:12 +0000
Subject: [R] ifelse misusage become more and more frequent...
In-Reply-To: <17791.55566.562687.131@stat.math.ethz.ch>
References: <457F1509.8080009@freesurf.Fr> <457F1ACE.4090307@biostat.ku.dk>
	<457F1E11.4020304@freesurf.Fr>
	<17791.55566.562687.131@stat.math.ethz.ch>
Message-ID: <7.0.0.16.0.20061213133018.01997a10@aghmed.fsnet.co.uk>

At 10:42 13/12/2006, Martin Maechler wrote:
> >>>>> "jropers at freesurf" == jropers at freesurf fr <jropers at freesurf.Fr>
> >>>>>     on Tue, 12 Dec 2006 22:24:33 +0100 writes:
>
>     jropers at freesurf> ...ifelse, a function of three **vector**
>     jropers at freesurf> arguments....  Yes !!  I misunderstood the
>     jropers at freesurf> functioning of ifelse.
>
>Seems to happen more an more often.
>When I teach "R programming" I nowadays usually emphasize that people
>should often *NOT* use ifelse().
>In other words, I think ifelse() is much over-used in situations
>where something else would be both clearer and more efficient.
>
>Is there a document / book around which lures people into
>misusing ifelse() so frequently?

Perhaps it is because here two concepts are involved which may be 
less familiar to people: program control and vectorisation. I wonder 
whether the manual pages for ifelse and if need to do more than just 
See also the other one. I notice that the page for if has a very 
helpful health warning about putting braces round everything. This is 
unusual in the manual pages which usually describe what is rather 
than tell you explicitly what to do to achieve salvation. Perhaps I 
could suggest that the if page tells you what error message you get 
when you wanted ifelse and that the ifelse page has a health warning 
along the lines of 'ifelse is not if and they are often confused with 
difficult to understand results'.

[snip]


Michael Dewey
http://www.aghmed.fsnet.co.uk


From schmidti82 at gmx.de  Tue Dec 12 17:39:29 2006
From: schmidti82 at gmx.de (Ilka Schmidt)
Date: Tue, 12 Dec 2006 17:39:29 +0100
Subject: [R] R_Code
Message-ID: <20061212163929.178510@gmx.net>

Hello!

I need the Code of the functions runif and rexp. Where can I get them? Can You help me? 

I thank you for an answer!

bye Ilka
--


From thomas.harte at yahoo.com  Wed Dec 13 14:52:55 2006
From: thomas.harte at yahoo.com (Thomas Harte)
Date: Wed, 13 Dec 2006 05:52:55 -0800 (PST)
Subject: [R] upside down image/data
Message-ID: <993899.98771.qm@web30208.mail.mud.yahoo.com>

	rm(list=ls(all=TRUE))
	graphics.off()
	# make a test matrix:
	nr<- 3
	nc<- 4
	# the data:
	( m<- matrix((1:(nr*nc)), nr, nc) )
	     [,1] [,2] [,3] [,4]
	[1,]    1    4    7   10
	[2,]    2    5    8   11
	[3,]    3    6    9   12

	# the way that levelplot (and image) displays the data:
	t(m)[dim(t(m))[1]:1, ]
	     [,1] [,2] [,3]
	[1,]   10   11   12
	[2,]    7    8    9
	[3,]    4    5    6
	[4,]    1    2    3

	# undo what levelplot does by performing the inverse transformation
	inverse<- function(x) t(x[dim(x)[1]:1, ]) 

	windows(); levelplot(m, main="levelplot(m)")
	windows(); levelplot(inverse(m), main="levelplot(inverse(m))")

	> Message: 7
	> Date: Mon, 11 Dec 2006 12:28:17 +0000 (GMT)
	> From: Jenny Barnes <jmb at mssl.ucl.ac.uk>
	> Subject: [R] upside down image/data
	> To: r-help at stat.math.ethz.ch
	> Message-ID: <200612111228.kBBCSHrj013960 at msslhb.mssl.ucl.ac.uk>
	> Content-Type: TEXT/plain; charset=us-ascii
	> 
	> Dear R-community,
	> 
	> I am looking for some simple advice - I have a matrix (therefore 2 dimensional) 
	> of global temperature. 
	> 
	> Having read R-help I think that when I ask R to image() or levelplot() my matrix 
	> will it actually appear upside down - I think I therefore need to use the line:
	> > levelplot(temperature.matrix[,ncol(output.temp):1], ........)
	> to get it looking like it was on the globe due to the matrix rows increasing in 
	> number down the matrix in its dimensions on longitude and latitude but the 
	> y-axis coordinates increase up the axis.
	> 
	> Can anyone simply tell me whether this is correct as I find it very hard to know 
	> which way up my data should be and I cannot tell which is correct simply by 
	> looking at it!
	> 
	> Many thanks for your time in reading this problem,
	> 
	> Jenny Barnes


From murdoch at stats.uwo.ca  Wed Dec 13 15:08:26 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 13 Dec 2006 09:08:26 -0500
Subject: [R] R_Code
In-Reply-To: <20061212163929.178510@gmx.net>
References: <20061212163929.178510@gmx.net>
Message-ID: <4580095A.6010508@stats.uwo.ca>

On 12/12/2006 11:39 AM, Ilka Schmidt wrote:
> Hello!
> 
> I need the Code of the functions runif and rexp. Where can I get them? Can You help me? 
> 
> I thank you for an answer!
> 
> bye Ilka

Just type the names.  For example:

 > runif
function (n, min = 0, max = 1)
.Internal(runif(n, min, max))
<environment: namespace:stats>

This indicates that all the work is being done by the internal function 
named runif.  You'll need the R source to find that.  For example, start at

https://svn.r-project.org/R/trunk/src/main/names.c

the file that establishes the relation between ".Internal" names and C 
function names.  It has:

{"runif",	do_random2,	9,	11,	3,	{PP_FUNCALL, PREC_FN,	0}},

which is not very good news for you:  do_random2 handles a lot of 
different distributions.  So you'll need to find where that function is 
(it's in src/main/random.c), trace through it to see how it handles code 
9 (it calls runif in src/nmath/runif.c), and so on.

I hope that helps a bit, but what you're asking is not easy.

Duncan Murdoch


From jmb at mssl.ucl.ac.uk  Wed Dec 13 15:06:00 2006
From: jmb at mssl.ucl.ac.uk (Jenny Barnes)
Date: Wed, 13 Dec 2006 14:06:00 +0000 (GMT)
Subject: [R] upside down image/data
Message-ID: <200612131406.kBDE60v4017445@msslhb.mssl.ucl.ac.uk>

Thomas,

Thank you for this example, makes it easier to see what levelplot does - does 
this mean that EVERY time I want to plot with levelplot() I have to not only 
reverse the columns [,ncol(output.temp):1] but also have to transform the matrix 
as below? I am only suprised as I don't remember having read about this in the 
R-info in ?levelplot or R-help website and it seems like a fundamental thing to 
know if using levelplot! 

Thanks,

Jenny

>
>	rm(list=ls(all=TRUE))
>	graphics.off()
>	# make a test matrix:
>	nr<- 3
>	nc<- 4
>	# the data:
>	( m<- matrix((1:(nr*nc)), nr, nc) )
>	     [,1] [,2] [,3] [,4]
>	[1,]    1    4    7   10
>	[2,]    2    5    8   11
>	[3,]    3    6    9   12
>
>	# the way that levelplot (and image) displays the data:
>	t(m)[dim(t(m))[1]:1, ]
>	     [,1] [,2] [,3]
>	[1,]   10   11   12
>	[2,]    7    8    9
>	[3,]    4    5    6
>	[4,]    1    2    3
>
>	# undo what levelplot does by performing the inverse transformation
>	inverse<- function(x) t(x[dim(x)[1]:1, ]) 
>
>	windows(); levelplot(m, main="levelplot(m)")
>	windows(); levelplot(inverse(m), main="levelplot(inverse(m))")
>
>	> Message: 7
>	> Date: Mon, 11 Dec 2006 12:28:17 +0000 (GMT)
>	> From: Jenny Barnes <jmb at mssl.ucl.ac.uk>
>	> Subject: [R] upside down image/data
>	> To: r-help at stat.math.ethz.ch
>	> Message-ID: <200612111228.kBBCSHrj013960 at msslhb.mssl.ucl.ac.uk>
>	> Content-Type: TEXT/plain; charset=us-ascii
>	> 
>	> Dear R-community,
>	> 
>	> I am looking for some simple advice - I have a matrix (therefore 2 
dimensional) 
>	> of global temperature. 
>	> 
>	> Having read R-help I think that when I ask R to image() or levelplot() 
my matrix 
>	> will it actually appear upside down - I think I therefore need to use 
the line:
>	> > levelplot(temperature.matrix[,ncol(output.temp):1], ........)
>	> to get it looking like it was on the globe due to the matrix rows 
increasing in 
>	> number down the matrix in its dimensions on longitude and latitude but 
the 
>	> y-axis coordinates increase up the axis.
>	> 
>	> Can anyone simply tell me whether this is correct as I find it very 
hard to know 
>	> which way up my data should be and I cannot tell which is correct 
simply by 
>	> looking at it!
>	> 
>	> Many thanks for your time in reading this problem,
>	> 
>	> Jenny Barnes
>
>

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Jennifer Barnes
PhD student - long range drought prediction
Climate Extremes
Department of Space and Climate Physics
University College London
Holmbury St Mary, Dorking
Surrey
RH5 6NT
01483 204149
07916 139187
Web: http://climate.mssl.ucl.ac.uk


From megh700004 at yahoo.com  Wed Dec 13 13:08:22 2006
From: megh700004 at yahoo.com (Megh Dal)
Date: Wed, 13 Dec 2006 04:08:22 -0800 (PST)
Subject: [R] Test for Kurtosis.
Message-ID: <270547.8808.qm@web58108.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061213/d260ae84/attachment.pl 

From rab45+ at pitt.edu  Wed Dec 13 15:25:45 2006
From: rab45+ at pitt.edu (Rick Bilonick)
Date: Wed, 13 Dec 2006 09:25:45 -0500
Subject: [R] Skipping Results with Errors in a Loop
Message-ID: <1166019945.3593.12.camel@localhost.localdomain>

I'm estimating models using lme in a for loop. Sometimes the model
doesn't converge or there are other problems. This causes the evaluation
to stop prematurely. I can't remember the function name that I need to
use to allow the loop to continue until the end. Could someone remind me
the name of the function? I've tried searching but haven't hit upon the
function.

Rick B.


From antonio.fabio at gmail.com  Wed Dec 13 15:34:20 2006
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Wed, 13 Dec 2006 15:34:20 +0100
Subject: [R] Skipping Results with Errors in a Loop
In-Reply-To: <1166019945.3593.12.camel@localhost.localdomain>
References: <1166019945.3593.12.camel@localhost.localdomain>
Message-ID: <b0808fdc0612130634i6c834b00pe6640eb95777b80c@mail.gmail.com>

?try

2006/12/13, Rick Bilonick <rab45+ a pitt.edu>:
> I'm estimating models using lme in a for loop. Sometimes the model
> doesn't converge or there are other problems. This causes the evaluation
> to stop prematurely. I can't remember the function name that I need to
> use to allow the loop to continue until the end. Could someone remind me
> the name of the function? I've tried searching but haven't hit upon the
> function.
>
> Rick B.
>
> ______________________________________________
> R-help a stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Antonio, Fabio Di Narzo
Ph.D. student at
Department of Statistical Sciences
University of Bologna, Italy


From thomas.harte at yahoo.com  Wed Dec 13 15:43:51 2006
From: thomas.harte at yahoo.com (Thomas Harte)
Date: Wed, 13 Dec 2006 06:43:51 -0800 (PST)
Subject: [R] upside down image/data
In-Reply-To: <200612131406.kBDE60v4017445@msslhb.mssl.ucl.ac.uk>
Message-ID: <20061213144351.83936.qmail@web30209.mail.mud.yahoo.com>

the transform that i provided orientates the data matrix so that when plotted with image
or levelplot the result is isomorphic to what you see when you print the matrix at the r
prompt.

i don't know what your data look like---"commented, minimal, self-contained, reproducible
code" would help---but you should be able to work out exactly what way you want your data
to appear by playing with the example code. i would advise you to produce a data matrix
the way you want to see it on the screen, just like the matrix m in the example code, and
then view the output with levelplot(inverse(m)), in which case, the answer to your
question is you only need to transform the data with inverse() once you get your data
matrix to look the way you want at the r prompt. 


--- Jenny Barnes <jmb at mssl.ucl.ac.uk> wrote:

> Thomas,
> 
> Thank you for this example, makes it easier to see what levelplot does - does 
> this mean that EVERY time I want to plot with levelplot() I have to not only 
> reverse the columns [,ncol(output.temp):1] but also have to transform the matrix 
> as below? I am only suprised as I don't remember having read about this in the 
> R-info in ?levelplot or R-help website and it seems like a fundamental thing to 
> know if using levelplot! 
> 
> Thanks,
> 
> Jenny
> 
> >
> >	rm(list=ls(all=TRUE))
> >	graphics.off()
> >	# make a test matrix:
> >	nr<- 3
> >	nc<- 4
> >	# the data:
> >	( m<- matrix((1:(nr*nc)), nr, nc) )
> >	     [,1] [,2] [,3] [,4]
> >	[1,]    1    4    7   10
> >	[2,]    2    5    8   11
> >	[3,]    3    6    9   12
> >
> >	# the way that levelplot (and image) displays the data:
> >	t(m)[dim(t(m))[1]:1, ]
> >	     [,1] [,2] [,3]
> >	[1,]   10   11   12
> >	[2,]    7    8    9
> >	[3,]    4    5    6
> >	[4,]    1    2    3
> >
> >	# undo what levelplot does by performing the inverse transformation
> >	inverse<- function(x) t(x[dim(x)[1]:1, ]) 
> >
> >	windows(); levelplot(m, main="levelplot(m)")
> >	windows(); levelplot(inverse(m), main="levelplot(inverse(m))")
> >
> >	> Message: 7
> >	> Date: Mon, 11 Dec 2006 12:28:17 +0000 (GMT)
> >	> From: Jenny Barnes <jmb at mssl.ucl.ac.uk>
> >	> Subject: [R] upside down image/data
> >	> To: r-help at stat.math.ethz.ch
> >	> Message-ID: <200612111228.kBBCSHrj013960 at msslhb.mssl.ucl.ac.uk>
> >	> Content-Type: TEXT/plain; charset=us-ascii
> >	> 
> >	> Dear R-community,
> >	> 
> >	> I am looking for some simple advice - I have a matrix (therefore 2 
> dimensional) 
> >	> of global temperature. 
> >	> 
> >	> Having read R-help I think that when I ask R to image() or levelplot() 
> my matrix 
> >	> will it actually appear upside down - I think I therefore need to use 
> the line:
> >	> > levelplot(temperature.matrix[,ncol(output.temp):1], ........)
> >	> to get it looking like it was on the globe due to the matrix rows 
> increasing in 
> >	> number down the matrix in its dimensions on longitude and latitude but 
> the 
> >	> y-axis coordinates increase up the axis.
> >	> 
> >	> Can anyone simply tell me whether this is correct as I find it very 
> hard to know 
> >	> which way up my data should be and I cannot tell which is correct 
> simply by 
> >	> looking at it!
> >	> 
> >	> Many thanks for your time in reading this problem,
> >	> 
> >	> Jenny Barnes
> >
> >
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Jennifer Barnes
> PhD student - long range drought prediction
> Climate Extremes
> Department of Space and Climate Physics
> University College London
> Holmbury St Mary, Dorking
> Surrey
> RH5 6NT
> 01483 204149
> 07916 139187
> Web: http://climate.mssl.ucl.ac.uk
> 
> 
>


From gkoru at umbc.edu  Wed Dec 13 15:50:20 2006
From: gkoru at umbc.edu (A. Gunes Koru)
Date: Wed, 13 Dec 2006 09:50:20 -0500
Subject: [R] counting process and output of survfit
Message-ID: <a0af71460612130650l799f6f3ekbc7d030c65238fdd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061213/ced016e6/attachment.pl 

From jmb at mssl.ucl.ac.uk  Wed Dec 13 15:53:23 2006
From: jmb at mssl.ucl.ac.uk (Jenny Barnes)
Date: Wed, 13 Dec 2006 14:53:23 +0000 (GMT)
Subject: [R] upside down image/data
Message-ID: <200612131453.kBDErNYD017522@msslhb.mssl.ucl.ac.uk>

Thanks Thomas,

My data arrays each contain 0.5million data points so I couldn't really 
reproduce them unfortunately. Next time I will try and offer some exapmle code 
simplified with comments in order to help you and the others on R-help 
understand my problem more easily. I appreciate your help and advise and I know 
it will be very usefull in learning about handling these huge datasets more 
accurately.

Jenny

>
>the transform that i provided orientates the data matrix so that when plotted 
with image
>or levelplot the result is isomorphic to what you see when you print the matrix 
at the r
>prompt.
>
>i don't know what your data look like---"commented, minimal, self-contained, 
reproducible
>code" would help---but you should be able to work out exactly what way you want 
your data
>to appear by playing with the example code. i would advise you to produce a 
data matrix
>the way you want to see it on the screen, just like the matrix m in the example 
code, and
>then view the output with levelplot(inverse(m)), in which case, the answer to 
your
>question is you only need to transform the data with inverse() once you get 
your data
>matrix to look the way you want at the r prompt. 
>
>
>--- Jenny Barnes <jmb at mssl.ucl.ac.uk> wrote:
>
>> Thomas,
>> 
>> Thank you for this example, makes it easier to see what levelplot does - does 
>> this mean that EVERY time I want to plot with levelplot() I have to not only 
>> reverse the columns [,ncol(output.temp):1] but also have to transform the 
matrix 
>> as below? I am only suprised as I don't remember having read about this in 
the 
>> R-info in ?levelplot or R-help website and it seems like a fundamental thing 
to 
>> know if using levelplot! 
>> 
>> Thanks,
>> 
>> Jenny
>> 
>> >
>> >	rm(list=ls(all=TRUE))
>> >	graphics.off()
>> >	# make a test matrix:
>> >	nr<- 3
>> >	nc<- 4
>> >	# the data:
>> >	( m<- matrix((1:(nr*nc)), nr, nc) )
>> >	     [,1] [,2] [,3] [,4]
>> >	[1,]    1    4    7   10
>> >	[2,]    2    5    8   11
>> >	[3,]    3    6    9   12
>> >
>> >	# the way that levelplot (and image) displays the data:
>> >	t(m)[dim(t(m))[1]:1, ]
>> >	     [,1] [,2] [,3]
>> >	[1,]   10   11   12
>> >	[2,]    7    8    9
>> >	[3,]    4    5    6
>> >	[4,]    1    2    3
>> >
>> >	# undo what levelplot does by performing the inverse transformation
>> >	inverse<- function(x) t(x[dim(x)[1]:1, ]) 
>> >
>> >	windows(); levelplot(m, main="levelplot(m)")
>> >	windows(); levelplot(inverse(m), main="levelplot(inverse(m))")
>> >
>> >	> Message: 7
>> >	> Date: Mon, 11 Dec 2006 12:28:17 +0000 (GMT)
>> >	> From: Jenny Barnes <jmb at mssl.ucl.ac.uk>
>> >	> Subject: [R] upside down image/data
>> >	> To: r-help at stat.math.ethz.ch
>> >	> Message-ID: <200612111228.kBBCSHrj013960 at msslhb.mssl.ucl.ac.uk>
>> >	> Content-Type: TEXT/plain; charset=us-ascii
>> >	> 
>> >	> Dear R-community,
>> >	> 
>> >	> I am looking for some simple advice - I have a matrix (therefore 2 
>> dimensional) 
>> >	> of global temperature. 
>> >	> 
>> >	> Having read R-help I think that when I ask R to image() or levelplot() 
>> my matrix 
>> >	> will it actually appear upside down - I think I therefore need to use 
>> the line:
>> >	> > levelplot(temperature.matrix[,ncol(output.temp):1], ........)
>> >	> to get it looking like it was on the globe due to the matrix rows 
>> increasing in 
>> >	> number down the matrix in its dimensions on longitude and latitude but 
>> the 
>> >	> y-axis coordinates increase up the axis.
>> >	> 
>> >	> Can anyone simply tell me whether this is correct as I find it very 
>> hard to know 
>> >	> which way up my data should be and I cannot tell which is correct 
>> simply by 
>> >	> looking at it!
>> >	> 
>> >	> Many thanks for your time in reading this problem,
>> >	> 
>> >	> Jenny Barnes
>> >
>> >
>> 
>> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>> Jennifer Barnes
>> PhD student - long range drought prediction
>> Climate Extremes
>> Department of Space and Climate Physics
>> University College London
>> Holmbury St Mary, Dorking
>> Surrey
>> RH5 6NT
>> 01483 204149
>> 07916 139187
>> Web: http://climate.mssl.ucl.ac.uk
>> 
>> 
>> 
>

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Jennifer Barnes
PhD student - long range drought prediction
Climate Extremes
Department of Space and Climate Physics
University College London
Holmbury St Mary, Dorking
Surrey
RH5 6NT
01483 204149
07916 139187
Web: http://climate.mssl.ucl.ac.uk


From murdoch at stats.uwo.ca  Wed Dec 13 16:01:36 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 13 Dec 2006 10:01:36 -0500
Subject: [R] persp() problem
In-Reply-To: <fe005e260612130657o70b214a6w3c30191e0aba04d3@mail.gmail.com>
References: <fe005e260612130319v228410ccwa31201c02fcd76a7@mail.gmail.com>	
	<457FEA79.1000600@stats.uwo.ca>
	<fe005e260612130657o70b214a6w3c30191e0aba04d3@mail.gmail.com>
Message-ID: <458015D0.4030002@stats.uwo.ca>

On 12/13/2006 9:57 AM, Michael Sun wrote:
> Dear Duncan,
> Thank you very much for your quick reply. The comands below really worked
> testx <- seq(min(u1data), max(u1data), len=100)
> testy <- seq(min(u2data), max(u2data), len=100)
> 
> And you are right, I do need my observed data.
>  can trans3d plot all my observed data?

No, trans3d just transforms the observed points to the appropriate 
coordinates in the 2d plot from persp.  You'll need to use points() or 
some other function to actually do the plotting.

One limitation of the algorithm used by persp (the painter's algorithm) 
is that it only works when things are drawn in a certain order.  You may 
find that you'll get errors (points that should be hidden showing up) 
using this approach.  If that's a problem, you might want to switch to 
using persp3d and points3d from the rgl package.

Duncan Murdoch


> 
> Thank you
> Best regards
> Mc
> 
> On 12/13/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>
>> On 12/13/2006 6:19 AM, Michael Sun wrote:
>> > Dear list,
>> >
>> > I have a problem on persp()
>> >
>> > x <- u1data #first coloum in attached data
>> > y <- u2data #second coloum in attached data
>> > f <-
>> function(x,y){qgev(pnorm(rhoF*qnorm(pnorm((qnorm(y)-rho2*qnorm(x)/sqrt(1-rho2^2))))
>> >                    +sqrt(1-rhoF^2)*qnorm(0.95)),-0.3935119, 0.4227890,
>> >  0.2701648)}
>> > z <- outer(x,y,f)
>> > persp(x,y,z)
>> >
>> > The R will display:
>> > "Error in persp.default(x, y, z) : increasing 'x' and 'y' values
>> expected"
>> >
>> > So I try to adjust it to:
>> >
>> > testx <- unique(sort(u1data))
>> > testy <- unique(u2data[order(u1data)])
>>
>> This doesn't make sense for persp. It wants the x and y values to be
>> increasing over their range, and looks best with equally spaced values.
>>
>> You are more likely to want something like
>>
>> testx <- seq(min(u1data), max(u1data), len=100)
>> testy <- seq(min(u2data), max(u2data), len=100)
>>
>> If you want to plot points where you observed data, you can use
>> the trans3d function, as in the persp examples.
>>
>> Duncan Murdoch
>>
>> > testf <-
>> function(testx,testy){qgev(pnorm(rhoF*qnorm(pnorm((qnorm(testy)-rho2*qnorm(testx)/sqrt(1-rho2^2))))
>> >
>> > +sqrt(1-rhoF^2)*qnorm(0.95)),-0.3935119, 0.4227890,  0.2701648)}
>> > testz <- unique(outer(testx,testy,testf)[order(u1data)])
>> >
>> > BUT SAME WARN:
>> >
>> > "Error in persp.default(testx, testy, testz) :
>> >         increasing 'x' and 'y' values expected "
>> >
>> > So how can I use persp in this situation?????? Thanks for any help!
>> >
>> > ========================================================
>> > Besides that I also want to enquiry on how to build the martix below?
>> >
>> >     [,1] [,2] [,3] [,4] [,5].......[,676]
>> >  [1,]  1   NA   NA   NA   NA
>> >  [2,]  NA   5   NA   NA   NA
>> >  [3,]  NA   NA   7   NA   NA
>> >  [4,]  NA   NA   NA   9   NA
>> >  [5,]  NA   NA   NA   NA  12
>> >   .    .
>> >   .    .
>> >   .
>> >  [676,]
>> >
>> > Appreciate for any reply.
>> >
>> > Thank you,
>> >
>> > With regards
>> > Mc
>> >
>> >
>> > ------------------------------------------------------------------------
>> >
>> > 0.3102202 0.6118165 0.898893
>> > 0.1153732 0.889533 0.9403834
>> > 0.1939559 0.008136975 0.752973
>> > 0.9999848 0.8709167 0.9363419
>> > 0.7327573 0.5331876 0.889305
>> > 0.142052 0.7996472 0.9241059
>> > 0.5789939 0.6572769 0.904507
>> > 0.7628466 0.7408237 0.9154523
>> > 0.8063378 0.8264442 0.928366
>> > 0.3868742 0.8406373 0.9308378
>> > 0.1201804 0.5251654 0.8883977
>> > 0.1073146 0.5495656 0.8913543
>> > 0.3801476 0.4933598 0.8844978
>> > 0.1704377 0.3456871 0.8655715
>> > 0.5100424 0.6447163 0.9029398
>> > 0.1004252 0.6747806 0.9067755
>> > 0.4969747 0.2788576 0.855801
>> > 0.9503927 0.4357328 0.877291
>> > 0.7038206 0.1551265 0.833016
>> > 0.4496465 0.2228675 0.8465589
>> > 0.3152238 0.4508357 0.8792615
>> > 0.8595227 0.1699521 0.8362594
>> > 0.8781077 0.442257 0.8781285
>> > 0.9926326 0.4477713 0.8787715
>> > 0.5001015 0.4227189 0.8757058
>> > 0.7418432 0.2242488 0.8467729
>> > 0.8401202 0.4881974 0.8838192
>> > 0.3141832 0.5075416 0.886233
>> > 0.9387748 0.76381 0.9186662
>> > 0.5421865 0.7493546 0.9166607
>> > 0.6063368 0.4569826 0.8799987
>> > 0.07328759 0.5085049 0.8863852
>> > 0.3523433 0.239639 0.8494759
>> > 0.2143498 0.1904935 0.8405416
>> > 0.0043028 0.2351062 0.8487917
>> > 0.2200048 0.525856 0.888467
>> > 0.929427 0.7432261 0.91576
>> > 0.4657704 0.02713088 0.781553
>> > 0.4974512 0.1951512 0.8414202
>> > 0.3032740 0.6642617 0.9054128
>> > 0.9586954 0.5320473 0.8891269
>> > 0.8522317 0.641292 0.9024777
>> > 0.7172216 0.7869344 0.9221045
>> > 0.5019212 0.5607276 0.8926608
>> > 0.6892507 0.722802 0.9130005
>> > 0.5197227 0.547926 0.8911097
>> > 0.6910355 0.4711651 0.8817452
>> > 0.1635166 0.5960693 0.8969858
>> > 0.6157443 0.3740314 0.8693667
>> > 0.3012652 0.3860136 0.8709832
>> > 0.7918442 0.5396737 0.8900836
>> > 0.7781783 0.7286279 0.9137793
>> > 0.5959097 0.6063727 0.8982006
>> > 0.5335883 0.5932636 0.8966064
>> > 0.4868495 0.4225826 0.8756897
>> > 0.3517952 0.242862 0.8500197
>> > 0.8330476 0.638904 0.9021835
>> > 0.1146440 0.03340253 0.786976
>> > 0.3653549 0.1617220 0.8345306
>> > 0.3287211 0.05560717 0.8008241
>> > 0.3507715 0.6139207 0.899147
>> > 0.3250503 0.4740786 0.882139
>> > 0.4259684 0.4225980 0.8756974
>> > 0.3831548 0.342748 0.86514
>> > 0.9297493 0.2764793 0.8553747
>> > 0.5209303 0.1444220 0.830535
>> > 0.2882225 0.4086862 0.8739324
>> > 0.06696263 0.05796908 0.8020525
>> > 0.2569928 0.6683259 0.9059325
>> > 0.737885 0.2643880 0.8535031
>> > 0.3417781 0.7339068 0.9145383
>> > 0.3003221 0.3746508 0.86948
>> > 0.6078735 0.08374094 0.8128343
>> > 0.7575533 0.2061716 0.8434881
>> > 0.04393339 0.2817576 0.856314
>> > 0.03873323 0.5468552 0.8910451
>> > 0.2659629 0.9524063 0.9580801
>> > 0.3318478 0.09184787 0.8157145
>> > 0.01326908 0.7941016 0.9232865
>> > 0.9531499 0.4246153 0.8758845
>> > 0.7878766 0.3739315 0.8693344
>> > 0.4278367 0.1187609 0.8239353
>> > 0.4751271 0.1594320 0.8340107
>> > 0.1298515 0.3193727 0.8618747
>> > 0.3889802 0.2466491 0.8506491
>> > 0.8919073 0.8100828 0.9256764
>> > 0.1007718 0.736085 0.914866
>> > 0.349479 0.5494373 0.8913082
>> > 0.6323708 0.5641948 0.8930688
>> > 0.4892277 0.592541 0.8965224
>> > 0.4317011 0.4708038 0.8817252
>> > 0.3640796 0.4606731 0.8804793
>> > 0.01587231 0.7557596 0.9176387
>> > 0.4029896 0.7396784 0.9153261
>> > 0.770008 0.6728253 0.9064569
>> > 0.7758348 0.3790344 0.870014
>> > 0.9256958 0.3866791 0.8709969
>> > 0.6965112 0.4335875 0.8770627
>> > 0.7327289 0.7813275 0.9212618
>> > 0.5994686 0.6169224 0.8994933
>> > 0.4861951 0.4077528 0.8737927
>> > 0.6227905 0.7492211 0.916635
>> > 0.2875190 0.754739 0.9174414
>> > 0.3583206 0.7108705 0.911435
>> > 0.2379315 0.7160225 0.9121322
>> > 0.2701988 0.371379 0.869047
>> > 0.2939349 0.2881057 0.8572388
>> > 0.686119 0.3435468 0.8652209
>> > 0.737684 0.1018767 0.818933
>> > 0.1022111 0.4620055 0.8806782
>> > 0.06743866 0.001328434 0.7155677
>> > 0.3189881 0.8103201 0.9257696
>> > 0.002606828 0.2529638 0.85179
>> > 0.754083 0.7591491 0.9180267
>> > 0.7783337 0.6120818 0.8988813
>> > 0.09418842 0.4592762 0.8803417
>> > 0.1289346 0.05072358 0.7982676
>> > 0.7680676 0.723607 0.913101
>> > 0.09463494 0.3502957 0.8662194
>> > 0.6247462 0.4354511 0.8773048
>> > 0.5472626 0.2640714 0.8534728
>> > 0.8046991 0.4033715 0.8731942
>> > 0.992037 0.8971756 0.9419815
>> > 0.1490033 0.5284286 0.8887884
>> > 0.1480197 0.5933815 0.8966606
>> > 0.4580494 0.5930807 0.8965908
>> > 0.4352076 0.4091756 0.8739806
>> > 0.3295796 0.1434968 0.8303327
>> > 0.431351 0.1096168 0.8213174
>> > 0.3167224 0.0862319 0.8137642
>> > 0.7067212 0.3611669 0.8676301
>> > 0.2601349 0.276127 0.8554021
>> > 0.4183247 0.7391175 0.9152474
>> > 0.5419186 0.5523624 0.8916447
>> > 0.9137419 0.8009559 0.9242306
>> > 0.9947217 0.7134031 0.9116726
>> > 0.7504282 0.1754408 0.8374331
>> > 0.3895617 0.3479445 0.8658571
>> > 0.6451314 0.6753639 0.9067933
>> > 0.6406233 0.3609228 0.867604
>> > 0.1448996 0.4616181 0.8806225
>> > 0.07675675 0.2447339 0.8503745
>> > 0.7305003 0.6765511 0.9069367
>> > 0.4862806 0.7636162 0.9186905
>> > 0.3355425 0.4680102 0.8813898
>> > 0.1981130 0.06148056 0.8037123
>> > 0.7579405 0.3969405 0.8723663
>> > 0.6168173 0.5598662 0.892546
>> > 0.4375986 0.5554698 0.8920301
>> > 0.4461622 0.7040231 0.910523
>> > 0.8777072 0.5413942 0.8902793
>> > 0.6782004 0.7177896 0.9123287
>> > 0.7209967 0.7495791 0.9166762
>> > 0.3230692 0.4923728 0.8843828
>> > 0.4387517 0.5043017 0.8858267
>> > 0.5148218 0.4466403 0.8787188
>> > 0.3047676 0.7538997 0.917321
>> > 0.9527929 0.1671429 0.8356328
>> > 0.9513049 0.3790206 0.8699783
>> > 0.6636276 0.5972614 0.8970817
>> > 0.1938244 0.4355477 0.8773607
>> > 0.3600900 0.4452904 0.8785646
>> > 0.2040542 0.2728078 0.8548912
>> > 0.4846581 0.2225607 0.846501
>> > 0.7091428 0.239741 0.8494566
>> > 0.5655244 2.537281e-05 0.6471484
>> > 0.4467683 0.1794644 0.838298
>> > 0.5270517 0.2173856 0.8455707
>> > 0.4940919 0.3665292 0.8683744
>> > 0.7128475 0.00847929 0.7538282
>> > 0.6727687 0.03073103 0.7847315
>> > 0.7023412 0.1143117 0.8226524
>> > 0.6435959 0.8386252 0.9304646
>> > 0.4167312 0.6090668 0.8985462
>> > 0.682974 0.7439136 0.9158887
>> > 0.5743695 0.9627705 0.9624433
>> > 0.4746829 0.2658398 0.8537617
>> > 0.2591787 0.05880024 0.802423
>> > 0.5281165 0.6724808 0.906436
>> > 0.2721701 0.4292930 0.8765619
>> > 0.5527161 0.5641951 0.8930761
>> > 0.4820321 0.5303901 0.8889902
>> > 0.519115 0.6716372 0.9063293
>> > 0.06265548 0.955931 0.9595114
>> > 0.3800652 0.7018464 0.9102427
>> > 0.3546165 0.415416 0.8747885
>> > 0.6800597 0.9266552 0.9495428
>> > 0.4970227 0.9582172 0.960424
>> > 0.5395118 0.999861 1.021719
>> > 0.3521434 0.5106511 0.8866073
>> > 0.6013237 0.7820113 0.9213758
>> > 0.8364799 0.7461522 0.9161836
>> > 0.571522 0.9823802 0.9742642
>> > 0.4043184 0.5279379 0.8887002
>> > 0.7320448 0.08124245 0.8118969
>> > 0.4386114 0.7264156 0.9135103
>> > 0.649196 0.4673266 0.8812757
>> > 0.2198846 0.4410754 0.878052
>> > 0.2285649 0.6274793 0.900828
>> > 0.5241012 0.8958289 0.9417466
>> > 0.362962 0.315014 0.8612168
>> > 0.3052995 0.3960945 0.8723014
>> > 0.905782 0.3447792 0.8653598
>> > 0.8931942 0.6032726 0.8977864
>> > 0.4266403 0.4421003 0.8781588
>> > 0.6388304 0.6090837 0.8985284
>> > 0.56878 0.579462 0.8949255
>> > 0.2950412 0.7102818 0.9113629
>> > 0.8296596 0.9120703 0.9456078
>> > 0.8635411 0.5362425 0.889658
>> > 0.9661249 0.6000882 0.897377
>> > 0.8104151 0.7164646 0.9121375
>> > 0.6788884 0.6432019 0.9027357
>> > 0.8568189 0.3015897 0.8591981
>> > 0.8460857 0.5678257 0.8934844
>> > 0.3145571 0.1828112 0.8389946
>> > 0.8994917 0.4629269 0.8806988
>> > 0.3515329 0.6217972 0.9001149
>> > 0.2874208 0.5560029 0.892109
>> > 0.4120654 0.7204939 0.9127143
>> > 0.1825168 0.5184448 0.887573
>> > 0.9755303 0.7021669 0.9102076
>> > 0.6491138 0.7110952 0.9114395
>> > 0.3967447 0.3955594 0.8722225
>> > 0.7102073 0.1843923 0.8392725
>> > 0.2964985 0.1360965 0.8285183
>> > 0.1869265 0.5907168 0.8963308
>> > 0.4028261 0.757025 0.9177552
>> > 0.6887386 0.7294083 0.9138946
>> > 0.8914899 0.7315796 0.9141653
>> > 0.4680622 0.6889618 0.9085565
>> > 0.5421646 0.551866 0.8915845
>> > 0.3836133 0.3281107 0.863089
>> > 0.7949356 0.698984 0.9098294
>> > 0.652499 0.7218326 0.9128735
>> > 0.923453 0.5489377 0.8911828
>> > 0.872984 0.1647356 0.835132
>> > 0.9080439 0.3139736 0.8610017
>> > 0.9078707 0.3264533 0.862792
>> > 0.1497525 0.6098135 0.8986666
>> > 0.2727475 0.5059691 0.886046
>> > 0.1080346 0.6117073 0.8989056
>> > 0.7163249 0.4961443 0.884806
>> > 0.1665438 0.7095927 0.9112861
>> > 0.1147964 0.7040084 0.9105571
>> > 0.6361728 0.4526705 0.8794596
>> > 0.2948908 0.6166378 0.899486
>> > 0.2754661 0.7791832 0.9209829
>> > 0.5040162 0.4605482 0.8804507
>> > 0.7755624 0.7083473 0.9110629
>> > 0.007938672 0.6512774 0.9038441
>> > 0.2143095 0.7018575 0.9102607
>> > 0.4256598 0.3218441 0.862193
>> > 0.7021327 0.1471694 0.83117
>> > 0.8541683 0.5130324 0.8868449
>> > 0.8165188 0.8621911 0.9347445
>> > 0.6407761 0.48237 0.8831282
>> > 0.5312793 0.5385175 0.88997
>> > 0.4844806 0.6393667 0.902276
>> > 0.8293853 0.7139695 0.9118023
>> > 0.9128633 0.716203 0.9120864
>> > 0.5514199 0.503507 0.8857197
>> > 0.3412234 0.7031551 0.910418
>> > 0.4681908 0.8509374 0.932675
>> > 0.5099785 0.897836 0.9422059
>> > 0.613507 0.8843356 0.9392177
>> > 0.5615576 0.5944772 0.8967518
>> > 0.2233283 0.5227858 0.8880943
>> > 0.7192387 0.1106780 0.8215985
>> > 0.6253335 0.5056905 0.8859786
>> > 0.3923049 0.7112349 0.9114802
>> > 0.5103654 0.6072716 0.8983182
>> > 0.8546338 0.6290934 0.9009646
>> > 0.2189133 0.4025152 0.8731445
>> > 0.1557879 0.9385458 0.9531978
>> > 0.3178054 0.4950795 0.884714
>> > 0.4594106 0.4929672 0.8844424
>> > 0.2145317 0.6494829 0.9035634
>> > 0.7338679 0.0743877 0.8092418
>> > 0.2910765 7.344265e-06 0.6282273
>> > 0.6739632 0.04388068 0.7941999
>> > 0.4262167 0.788432 0.9223558
>> > 0.815637 0.4462349 0.8786363
>> > 0.4944984 0.0325375 0.7862377
>> > 0.5482012 0.6671962 0.9057626
>> > 0.7203222 0.6536981 0.904044
>> > 0.6473953 0.4267527 0.8762038
>> > 0.1459738 0.2673097 0.8540337
>> > 0.3430013 0.9186308 0.9473533
>> > 0.3968373 0.6025617 0.8977525
>> > 0.4825984 0.8971687 0.942055
>> > 0.6915212 0.4134755 0.8745077
>> > 0.7016574 0.2524424 0.8515746
>> > 0.4246859 0.7426717 0.9157385
>> > 0.004345354 0.7664402 0.9191835
>> > 0.03124377 0.8600277 0.93442
>> > 0.2576312 0.2757442 0.8553429
>> > 0.2569686 0.7540984 0.9173539
>> > 0.1386583 0.5013163 0.8854969
>> > 0.004756962 0.5166277 0.8874133
>> > 0.6976297 0.4815717 0.8830245
>> > 0.697404 0.4244274 0.8759037
>> > 0.8112176 0.5899199 0.8961713
>> > 0.713734 0.3745925 0.8694313
>> > 0.8887044 0.85696 0.9337461
>> > 0.2278300 0.9559154 0.9594826
>> > 0.9451097 0.5987058 0.8972164
>> > 0.1199859 0.713117 0.9117607
>> > 0.2427017 0.8342876 0.9297474
>> > 0.3799076 0.6385965 0.9021895
>> > 0.780296 0.3971621 0.8723923
>> > 0.4833612 0.6403189 0.9023944
>> > 0.6143626 0.6414991 0.9025297
>> > 0.7478517 0.8341564 0.9296813
>> > 0.5848616 0.2031911 0.842948
>> > 0.803453 0.02763294 0.7819796
>> > 0.8947829 0.1982048 0.8419586
>> > 0.5401919 0.3691551 0.8687224
>> > 0.8064726 0.2461822 0.8505264
>> > 0.9174961 0.9000155 0.9426684
>> > 0.8649377 0.7263216 0.9134553
>> > 0.368144 0.3114216 0.860695
>> > 0.3960397 0.7991588 0.9240037
>> > 0.7474788 0.7891092 0.9224306
>> > 0.8244429 0.4399955 0.8778534
>> > 0.4090636 0.9744874 0.9686875
>> > 0.60864 0.3629311 0.8678787
>> > 0.8792287 0.1042003 0.8196308
>> > 0.5568143 0.6392743 0.9022581
>> > 0.2410288 0.7310255 0.9141548
>> > 0.5096632 0.5728588 0.8941298
>> > 0.6754568 0.7334808 0.9144511
>> > 0.9016902 0.8356986 0.929927
>> > 0.794581 0.823762 0.9279195
>> > 0.3333656 0.7053623 0.9107092
>> > 0.7280451 0.919738 0.9476197
>> > 0.5522382 0.1590644 0.8339207
>> > 0.6466815 0.6127797 0.8989805
>> > 0.8000029 0.4637126 0.8808121
>> > 0.5983007 0.4788531 0.8827005
>> > 0.01127508 0.5186316 0.8876452
>> > 0.013699 0.563469 0.8930714
>> > 0.2427855 0.8413799 0.9309814
>> > 0.7656437 0.8558567 0.933556
>> > 0.7712339 0.6979084 0.9096916
>> > 0.7820254 0.2107216 0.8443285
>> > 0.2098941 0.3466435 0.8656979
>> > 0.6803271 5.67055e-05 0.6599548
>> > 0.8533364 0.04563989 0.79525
>> > 0.3460994 0.4376786 0.8776115
>> > 0.1276769 0.8358598 0.9300324
>> > 0.1840423 0.5695211 0.893758
>> > 0.1898183 4.343381e-13 0.4279754
>> > 0.5374682 3.43534e-07 0.5847877
>> > 0.9653777 0.2941263 0.8580566
>> > 0.793583 0.7093681 0.9111959
>> > 0.767547 0.2485699 0.8509283
>> > 0.6692159 0.9999993 1.049294
>> > 0.8284223 0.1368672 0.8286505
>> > 0.9165768 0.7461044 0.9161635
>> > 0.07780481 0.2581183 0.8525758
>> > 0.8283647 0.07059201 0.8076717
>> > 0.4945938 0.08162078 0.8120646
>> > 0.7121621 0.5978781 0.897152
>> > 0.003852813 0.1328189 0.8277767
>> > 0.7119404 0.05172274 0.7987407
>> > 0.8855203 0.6257442 0.900546
>> > 0.9218816 0.8273478 0.9285
>> > 0.9233806 0.7509503 0.9168407
>> > 0.2593601 0.08886668 0.8146992
>> > 0.5798519 0.8080687 0.9253888
>> > 0.2083358 0.9943995 0.9891006
>> > 0.9928156 0.811554 0.925873
>> > 0.6316176 0.7618544 0.9184253
>> > 0.2909255 0.2391205 0.8493947
>> > 0.4806987 0.05703826 0.8015291
>> > 0.8148117 0.6490257 0.9034478
>> > 0.5015989 0.7569907 0.917742
>> > 0.618849 0.8112648 0.925896
>> > 0.8680278 0.1261190 0.8258788
>> > 0.9843081 0.4610686 0.8804365
>> > 0.981136 0.5933233 0.8965434
>> > 0.3402781 0.7650686 0.9189122
>> > 0.636855 0.6395097 0.9022802
>> > 0.1015914 0.9004152 0.9428428
>> > 0.01417522 0.1301853 0.8270804
>> > 0.01399330 0.4096037 0.8741114
>> > 0.3585436 0.1450862 0.830711
>> > 0.8398029 0.6609509 0.9049425
>> > 0.5550948 0.8041808 0.9247759
>> > 0.3279216 0.3477294 0.8658338
>> > 0.800509 0.7437003 0.9158468
>> > 0.8634276 0.2644834 0.8535005
>> > 0.4027558 0.03161294 0.7854964
>> > 0.9603643 0.08939088 0.814781
>> > 0.8684457 0.2258063 0.847029
>> > 0.2337130 0.6693651 0.906067
>> > 0.8418288 0.06168066 0.8037274
>> > 0.6960713 0.236729 0.8489459
>> > 0.9778375 0.1392889 0.8292076
>> > 0.909325 0.4792852 0.8827139
>> > 0.6743998 0.001302298 0.7150928
>> > 0.002995692 0.3198894 0.862011
>> > 0.7865613 0.8194578 0.9272093
>> > 0.7795525 0.7334021 0.9144298
>> > 0.983064 0.3390965 0.8645403
>> > 0.8615933 0.2985286 0.8587428
>> > 0.008317132 0.2811343 0.8562448
>> > 0.3336097 0.5237279 0.8881966
>> > 0.6511454 0.5833166 0.895386
>> > 0.8859316 0.6190705 0.899724
>> > 0.01688167 0.1500001 0.8319426
>> > 0.002360940 0.1319095 0.8275506
>> > 0.6274613 0.5826939 0.8953125
>> > 0.008114898 0.6664864 0.9057595
>> > 0.001045473 0.2242417 0.8469188
>> > 0.0508478 0.4957073 0.8848329
>> > 0.5888479 0.914019 0.946127
>> > 0.7740566 0.8235836 0.9278921
>> > 0.8057038 0.3660084 0.8682713
>> > 0.4770886 0.6560355 0.9043598
>> > 0.5256923 0.8803939 0.938396
>> > 0.8566784 0.7790501 0.9209085
>> > 0.7719712 0.6309976 0.901211
>> > 0.1469819 0.8088482 0.9255534
>> > 0.2189924 0.03436754 0.7877055
>> > 0.9558648 0.1629045 0.8347084
>> > 0.9225076 0.2217156 0.846293
>> > 0.8208944 0.8208895 0.9274408
>> > 0.2174652 0.1468581 0.8311496
>> > 0.618421 0.4026186 0.8731176
>> > 0.6247648 0.7436365 0.9158555
>> > 0.2372800 0.2181356 0.8457368
>> > 0.7013663 0.8468071 0.931908
>> > 0.7868276 0.9131027 0.945875
>> > 0.6576328 0.585279 0.8956237
>> > 0.9719215 0.4717628 0.8817672
>> > 0.7798435 0.1481837 0.8313995
>> > 0.6780997 0.5981976 0.8971944
>> > 0.3070307 0.1875593 0.8399491
>> > 0.4197094 0.5990637 0.8973235
>> > 0.5040344 0.1640605 0.8350302
>> > 0.8834981 0.6167573 0.89944
>> > 0.1481133 0.8285937 0.9287888
>> > 0.1471865 0.6445625 0.9029578
>> > 0.1327257 0.6725547 0.906486
>> > 0.3433113 0.6927705 0.9090613
>> > 0.2946019 0.4352499 0.8773112
>> > 0.003406429 0.3938362 0.8720895
>> > 0.2857042 0.5735738 0.8942374
>> > 0.6455505 0.2243478 0.8468013
>> > 0.9490315 0.2099423 0.8441508
>> > 0.04602036 0.3690979 0.8687822
>> > 0.1056053 0.7631722 0.918667
>> > 0.6817949 0.528255 0.8887128
>> > 0.5644347 0.6491707 0.9034914
>> > 0.7570488 0.7966135 0.9235781
>> > 0.6593145 0.2074085 0.84373
>> > 0.8925004 0.6638273 0.9052974
>> > 0.1246228 0.4961518 0.8848695
>> > 0.7857138 0.542488 0.890425
>> > 0.8963653 0.2669431 0.8538854
>> > 0.6514738 0.7706894 0.919701
>> > 0.2293905 0.8438272 0.9314158
>> > 0.3912309 0.6160558 0.8994053
>> > 0.2982153 0.5130745 0.8869073
>> > 0.4044714 0.7306236 0.9140846
>> > 0.9431583 0.616781 0.8994294
>> > 0.04552623 0.8735693 0.9370548
>> > 0.7237478 0.6736022 0.9065609
>> > 0.6859905 0.8343209 0.9297154
>> > 0.7823167 0.7148671 0.9119277
>> > 0.9521752 0.3384298 0.8644647
>> > 0.2351690 0.243558 0.85015
>> > 0.3056817 0.5057963 0.8860215
>> > 0.5686026 0.6364396 0.901905
>> > 0.7356786 0.4167618 0.8749232
>> > 0.2266795 0.7380897 0.915124
>> > 0.3347846 0.8819222 0.9387305
>> > 0.3956415 0.8593319 0.9342383
>> > 0.7768104 0.8177261 0.9269268
>> > 0.3056832 0.5966309 0.8970376
>> > 0.5204085 0.8136706 0.9262912
>> > 0.2521421 0.3396209 0.8647196
>> > 0.2473847 0.2164454 0.8454306
>> > 0.1108629 0.4169697 0.8750187
>> > 0.2838937 0.3549462 0.8668274
>> > 0.5465899 0.5446338 0.8907089
>> > 0.1034264 0.7386064 0.9152123
>> > 0.2498704 0.09973506 0.8183126
>> > 0.1136003 0.2718162 0.8547505
>> > 0.4172970 0.5540139 0.8918557
>> > 0.1390018 0.8442352 0.9314993
>> > 0.005563172 0.8066043 0.9252453
>> > 0.5818675 0.6424044 0.9026453
>> > 0.1430274 0.674245 0.9066999
>> > 0.03769988 0.4290427 0.8765737
>> > 0.8556575 0.3844797 0.870722
>> > 0.8775405 0.417829 0.8750397
>> > 0.9104062 0.6323445 0.9013568
>> > 0.1074026 0.2182002 0.8457692
>> > 0.7204749 0.1104211 0.821523
>> > 0.3492221 0.3339966 0.8639225
>> > 0.1576476 0.4215118 0.8755896
>> > 0.9048666 0.6262912 0.9006098
>> > 0.4718103 0.2724998 0.8548135
>> > 0.4361739 0.09929708 0.8181518
>> > 0.2972725 0.7777231 0.9207644
>> > 0.5665044 0.8808408 0.938486
>> > 0.738228 0.5602356 0.8925787
>> > 0.5540302 0.5708308 0.89388
>> > 0.1375065 0.8168868 0.9268497
>> > 0.07578065 0.3489205 0.8660352
>> > 0.3726154 0.2491216 0.851061
>> > 0.6368203 0.7509145 0.9168716
>> > 0.8306685 0.777946 0.9207484
>> > 0.2833806 0.5546789 0.8919492
>> > 0.09934053 0.6805804 0.9075179
>> > 0.1655332 0.8468221 0.9319582
>> > 0.2844294 0.8254702 0.928249
>> > 0.1464508 0.9015246 0.943096
>> > 0.389557 0.6143054 0.8991906
>> > 0.1621419 0.6400966 0.9023995
>> > 0.0971209 0.4490999 0.8790752
>> > 0.2709383 0.8486465 0.9322756
>> > 0.4742362 0.4121831 0.874363
>> > 0.6779411 0.5489203 0.8912153
>> > 0.5392679 0.3478413 0.8658285
>> > 0.4443618 0.6275902 0.9008207
>> > 0.08832718 0.5932862 0.8966598
>> > 0.5118831 0.01596035 0.7684642
>> > 0.9978362 0.2475618 0.850678
>> > 0.2128232 0.9456008 0.9555712
>> > 0.1790925 0.6703308 0.9061963
>> > 0.7668958 0.4674435 0.8812775
>> > 0.1564061 0.2451245 0.8504234
>> > 0.1336754 0.3983315 0.8726147
>> > 0.0975977 0.2043324 0.8432229
>> > 0.01216834 0.2339812 0.8485838
>> > 0.1569461 0.5324595 0.8892754
>> > 0.04365445 0.4410925 0.8780887
>> > 0.2494574 0.02976159 0.7839518
>> > 0.7012898 0.4499832 0.879118
>> > 0.4708703 0.4863704 0.8836344
>> > 0.5920373 0.707517 0.910971
>> > 0.9561298 0.1947485 0.8412737
>> > 0.4952743 0.03657176 0.7893157
>> > 0.915553 0.4239565 0.875812
>> > 0.7713963 0.06609137 0.805744
>> > 0.05493889 0.2130792 0.844855
>> > 0.6821484 0.7026926 0.9103274
>> > 0.5336243 0.91109 0.9453866
>> > 0.6867021 0.7411612 0.9155066
>> > 0.975979 0.04527906 0.7949923
>> > 0.837784 0.74753 0.9163759
>> > 0.4934895 0.416351 0.8748948
>> > 0.005828299 0.3566607 0.8671348
>> > 0.3310498 0.8961609 0.9418372
>> > 0.03192657 0.850284 0.932612
>> > 0.08457336 0.6901218 0.9087509
>> > 0.2031292 0.4299748 0.8766564
>> > 0.7614405 0.7459437 0.9161635
>> > 0.2555080 0.674626 0.9067344
>> > 0.7083119 0.4501719 0.8791408
>> > 0.945163 0.1646992 0.8351056
>> > 0.06908377 0.2324591 0.8482912
>> > 0.03880391 0.2281361 0.8475513
>> > 0.5105381 0.8672677 0.9357525
>> > 0.05855021 0.5165195 0.8873631
>> > 0.1300929 0.8829 0.9389577
>> > 0.1747403 0.1704515 0.8364469
>> > 0.2981974 0.1595222 0.8340497
>> > 0.0055007 0.3530877 0.8666484
>> > 0.7576901 0.264833 0.8535717
>> > 0.6933019 0.5738702 0.8942353
>> > 0.6443269 0.2171339 0.8455133
>> > 0.4122726 0.490008 0.884085
>> > 0.08336114 0.6785415 0.9072598
>> > 0.5589743 0.7387024 0.9151783
>> > 0.92432 0.6836011 0.907813
>> > 0.9606246 0.1255525 0.825702
>> > 0.4450934 0.2194885 0.8459569
>> > 0.5807345 0.4559498 0.8798728
>> > 0.6236046 0.5395055 0.890081
>> > 0.5478731 0.8940408 0.9413413
>> > 0.8278164 0.5863816 0.8957387
>> > 0.8017402 0.2607101 0.8529055
>> > 0.7423169 0.7402687 0.9153777
>> > 0.4548012 0.4569796 0.8800124
>> > 0.1770415 0.5387303 0.8900318
>> > 0.9073766 0.3520192 0.8663556
>> > 0.1492733 0.1125281 0.8222042
>> > 0.07429098 0.2712785 0.8546752
>> > 0.3683862 0.6588343 0.9047215
>> > 0.680869 0.7330059 0.9143857
>> > 0.7384956 0.6025491 0.8977193
>> > 0.3808318 0.3140541 0.861076
>> > 0.2843261 0.6324584 0.9014375
>> > 0.1436439 0.5258806 0.8884804
>> > 0.4224504 0.5743372 0.8943168
>> > 0.7524093 0.3438394 0.8652539
>> > 0.9357195 0.5169828 0.8873079
>> > 0.4036766 0.6824951 0.9077281
>> > 0.1014471 0.7351924 0.9147434
>> > 0.3524282 0.3972935 0.8724525
>> > 0.9483054 0.3513068 0.8662465
>> > 0.4396423 0.4028961 0.8731704
>> > 0.3531021 0.2731345 0.8549248
>> > 0.4443184 0.3142964 0.8611048
>> > 0.3768978 0.5842775 0.8955275
>> > 0.2466269 0.2663774 0.8538713
>> > 0.5962991 0.00470513 0.7410197
>> > 0.3756412 0.2967521 0.858532
>> > 0.04994566 0.2117102 0.8446063
>> > 0.1080174 0.4622149 0.880703
>> > 0.3629230 0.5252755 0.8883814
>> > 0.1887335 0.292769 0.8579568
>> > 0.3519446 0.7994556 0.9240536
>> > 0.1217339 0.1401854 0.8295575
>> > 0.174763 0.618114 0.8996812
>> > 0.4586664 0.6402342 0.902386
>> > 0.5343869 0.3013533 0.8592008
>> > 0.2161009 0.3156891 0.861331
>> > 0.17651 0.4887034 0.8839512
>> > 0.9917181 0.4244217 0.8758332
>> > 0.604959 0.2353208 0.8487147
>> > 0.8332544 0.5308923 0.8890146
>> > 0.51212 0.596579 0.8970123
>> > 0.5994383 0.2876340 0.8571365
>> > 0.8807404 0.4205335 0.875384
>> > 0.072703 0.503507 0.8857772
>> > 0.1272491 0.7729678 0.9200844
>> > 0.5047155 0.903465 0.943523
>> > 0.1129428 0.8151764 0.9265756
>> > 0.546922 0.6979866 0.909723
>> > 0.9591556 0.02840703 0.7826478
>> > 0.8617191 0.1017775 0.8188833
>> > 0.6370122 0.1468348 0.831098
>> > 0.431313 0.7198841 0.9126308
>> > 0.1316088 0.8709087 0.9365054
>> > 0.7881227 0.8493899 0.9323656
>> > 0.6531763 0.6218253 0.9000913
>> > 0.790503 0.6167768 0.899456
>> > 0.8466432 0.9889855 0.9807199
>> > 0.6609452 0.3529404 0.8665161
>> > 0.9637131 0.1053617 0.8199601
>> > 0.6903624 0.3402932 0.8647688
>> > 0.8406482 0.3099546 0.8604301
>> > 0.4943412 0.5324295 0.8892361
>> > 0.5210708 0.1568008 0.8334152
>> > 0.9086716 0.5761234 0.8944793
>> > 0.09083374 0.5520557 0.891659
>> > 0.6066495 0.5805193 0.8950504
>> > 0.5294395 0.5708622 0.893886
>> > 0.02075211 0.8740981 0.9371722
>> > 0.3150380 0.4126541 0.874439
>> > 0.8028235 0.4867181 0.8836432
>> > 0.5138899 0.2777579 0.855629
>> > 0.2610341 0.4841342 0.883381
>> > 0.2810478 0.4913972 0.884268
>> > 0.9002693 0.4355419 0.8772805
>> > 0.7717612 0.6170158 0.8994875
>> > 0.8091782 0.598264 0.897188
>> > 0.5719824 0.6296076 0.9010587
>> > 0.5029268 0.5059016 0.8860156
>> > 0.613944 0.2153304 0.8451901
>> > 0.2244824 0.1831607 0.8390764
>> > 0.7980058 0.1371974 0.8287375
>> > 0.932274 0.4284666 0.8763795
>> > 0.6961254 0.4558324 0.8798468
>> > 0.3442136 0.1641236 0.8350606
>> > 0.5064431 0.1621777 0.8346166
>> > 0.4151743 0.4776614 0.882571
>> > 0.06262435 0.7949185 0.9233896
>> > 0.7819505 0.6249127 0.9004582
>> > 0.5856734 0.3304368 0.8633984
>> >
>> >
>> > ------------------------------------------------------------------------
>> >
>> > ______________________________________________
>> > R-help at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


From efg at stowers-institute.org  Wed Dec 13 17:09:37 2006
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Wed, 13 Dec 2006 10:09:37 -0600
Subject: [R] set up directory for R when I start R
References: <6.1.2.0.2.20061210044729.01c284c0@aiminy.mail.iastate.edu>	<loom.20061210T115836-859@post.gmane.org><elkb4l$51l$1@sea.gmane.org>
	<457DC8CA.9040604@stats.uwo.ca>
Message-ID: <elp8k4$v0k$1@sea.gmane.org>

"Duncan Murdoch" <murdoch at stats.uwo.ca> wrote in message 
news:457DC8CA.9040604 at stats.uwo.ca...
> On 12/11/2006 2:21 PM, Earl F. Glynn wrote:
>> "Dieter Menne" <dieter.menne at menne-biomed.de> wrote in message
>> news:loom.20061210T115836-859 at post.gmane.org...
>>> Aimin Yan <aiminy <at> iastate.edu> writes:
>>>>
>>>> I want to set default directory for R when I start R.
>>>> How to do this?
>>>
>>> In Windows, I prefer the method described in
>>>
>>> http://tolstoy.newcastle.edu.au/R/help/00b/2454.html

If R version-specific registry keys are used, one can even select from 
multiple versions of R by right clicking on a directory from Windows 
Explorer:

To add key for R 2.4.0:

R2.4.0.reg  (delete the proxy part if not needed)
-----
Windows Registry Editor Version 5.00

[HKEY_CLASSES_ROOT\Folder\shell\R 2.4.0]

[HKEY_CLASSES_ROOT\Folder\shell\R 2.4.0\command]
@="C:\\Program Files\\R\\R-2.4.0\\bin\\Rgui.exe 
http_proxy=http://proxy01:8080 http_proxy_user=ask"
-----


To delete this key:

R2.4.0-Delete.reg
-----
Windows Registry Editor Version 5.00

[-HKEY_CLASSES_ROOT\Folder\shell\R 2.4.0]
-----

These files can be edited with Windows Notepad and modified for other 
versions.

efg

 Earl F. Glynn
Bioinformatics
Stowers Institute for Medical Research


From Rau at demogr.mpg.de  Wed Dec 13 17:12:38 2006
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Wed, 13 Dec 2006 17:12:38 +0100
Subject: [R] exporting a table to latex
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E6013DB670@HERMES.demogr.mpg.de>

Hi, 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Rainer M Krug
> Sent: Wednesday, December 13, 2006 8:47 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] exporting a table to latex

> Is there another way of formating the values to three decimal digits?
> 
> Or another way of exporting them to LaTeX?
> 
I hope I did not oversee any emails concerning your question. Typically,
I use the xtable-package. Please let me know if the following code is
not doing what you hope for.

Best,
Roland


mydata <- data.frame(Category=LETTERS[1:10], Percentage=runif(10))

library(xtable)

xtable(mydata, digits=c(0,0,3)) ### LaTeX format => default
#### you can even create an HTML table
print(xtable(mydata, digits=c(0,0,5)), type="HTML")


----------
This mail has been sent through the MPI for Demographic Rese...{{dropped}}


From edd at debian.org  Wed Dec 13 17:18:04 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 13 Dec 2006 10:18:04 -0600
Subject: [R] Error to install fMultivar package
In-Reply-To: <20061213_123404_074050.gsmatos1@ig.com.br>
References: <20061213_123404_074050.gsmatos1@ig.com.br>
Message-ID: <20061213161804.GA27719@eddelbuettel.com>

On Wed, Dec 13, 2006 at 09:34:04AM -0300, gsmatos1 wrote:
Content-Description: Mail message body
> Hi, 
> 
> I tried to install fMultivar package but an error occurs that I could not 
> understand. 
> (I've been worked with linux / Ubuntu 6.06 LTS) 

This would be quicker:

     $ sudo apt-get install r-cran-fmulitvar

(if you enabled the Universe repositories in /etc/apt/sources.list).

> > install.packages("fMultivar") 
> Warning in install.packages("fMultivar") : argument 'lib' is missing: using 
> /usr /local/lib/R/site-library 
> --- Please select a CRAN mirror for use in this session --- 
> Loading Tcl/Tk interface ... done 
> trying URL 
> 'http://lmq.esalq.usp.br/CRAN/src/contrib/fMultivar_221.10065.tar.gz' 
> Content type 'application/x-gzip' length 1152747 bytes 
> opened URL 
> ================================================== 
> downloaded 1125Kb 
> 
> * Installing *source* package 'fMultivar' ... 
> ** libs 
> gcc -I/usr/share/R/include -I/usr/share/R/include      -fpic  -g -O2 
> -std=gnu99 -c 00A-randomF77.c -o 00A-randomF77.o 
> gcc -I/usr/share/R/include -I/usr/share/R/include      -fpic  -g -O2 
> -std=gnu99 -c 00B-GarchBEKK.c -o 00B-GarchBEKK.o 
> g77   -fpic  -g -O2 -c 42A-1ReggressionModelling.f -o 
> 42A-1ReggressionModelling.o 
> g77   -fpic  -g -O2 -c 42A-2RegressionModelling.f -o 
> 42A-2RegressionModelling.o 
> gcc -I/usr/share/R/include -I/usr/share/R/include      -fpic  -g -O2 
> -std=gnu99 -c 42A-3RegressionModelling.c -o 42A-3RegressionModelling.o 
> g77   -fpic  -g -O2 -c 42B-RegressionTests.f -o 42B-RegressionTests.o 
> g77   -fpic  -g -O2 -c 46A-VectorMatrixAddon.f -o 46A-VectorMatrixAddon.o 
> gcc -I/usr/share/R/include -I/usr/share/R/include      -fpic  -g -O2 
> -std=gnu99 -c 46B-MissingValues.c -o 46B-MissingValues.og77   -fpic  -g -O2 
> -c 47B-MultivariateDistribution.f -o 47B-MultivariateDistribution.o 
> gcc -I/usr/share/R/include -I/usr/share/R/include      -fpic  -g -O2 
> -std=gnu99 -c runfunc.c -o runfunc.o 
> gcc -shared  -o fMultivar.so 00A-randomF77.o 00B-GarchBEKK.o 
> 42A-1ReggressionModelling.o 42A-2RegressionModelling.o 
> 42A-3RegressionModelling.o 42B-RegressionTests.o 46A-VectorMatrixAddon.o 
> 46B-MissingValues.o 47B-MultivariateDistribution.o runfunc.o -lblas-3 -lg2c 
> -lm -lgcc_s -L/usr/lib/R/lib -lR 
> /usr/bin/ld: cannot find -lblas-3 
> collect2: ld returned 1 exit status 
> make: *** [fMultivar.so] Error 1 
> ERROR: compilation failed for package 'fMultivar' 
> ** Removing '/usr/local/lib/R/site-library/fMultivar' 
> 
> The downloaded packages are in 
>         /tmp/RtmpXxDoFd/downloaded_packages 
> Warning message: 
> installation of package 'fMultivar' had non-zero exit status in: 
> install.packages("fMultivar") 

It is a FAQ for Debian and Ubuntu -- you "forgot" to install
r-base-dev which provides a fairly complete development emv. for R on
Debian / Ubuntu, so do

       $ sudo apt-get install r-base-dev
       
Besides, given that there _is_ a source package, you could also use
its information on Build-Dependencies:

       $ sudo apt-get build-dep r-cran-fmultivar
       
Hth, Dirk       

> > 
> 
> Thanks in advance for any help! 
> Gilberto. 
> 
> 

> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From rab45+ at pitt.edu  Wed Dec 13 17:39:46 2006
From: rab45+ at pitt.edu (Rick Bilonick)
Date: Wed, 13 Dec 2006 11:39:46 -0500
Subject: [R] Obtaining Estimates of the Random Effects Parameters
Message-ID: <1166027986.3593.34.camel@localhost.localdomain>

I'm running simulation using lme and sometimes the estimated
variance-covariance matrix is not positive definite so that the
intervals function won't work for the random effect coefficients. I've
tried varcomp from the ape package but this does not return all the
coefficients. How can I extract the random effect coefficients without
using intervals?

Rick B.


From HDoran at air.org  Wed Dec 13 17:44:03 2006
From: HDoran at air.org (Doran, Harold)
Date: Wed, 13 Dec 2006 11:44:03 -0500
Subject: [R] Obtaining Estimates of the Random Effects Parameters
Message-ID: <2323A6D37908A847A7C32F1E3662C80E6B0B55@dc1ex01.air.org>

?VarCorr 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Rick Bilonick
> Sent: Wednesday, December 13, 2006 11:40 AM
> To: R Help
> Subject: [R] Obtaining Estimates of the Random Effects Parameters
> 
> I'm running simulation using lme and sometimes the estimated 
> variance-covariance matrix is not positive definite so that 
> the intervals function won't work for the random effect 
> coefficients. I've tried varcomp from the ape package but 
> this does not return all the coefficients. How can I extract 
> the random effect coefficients without using intervals?
> 
> Rick B.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From RKrug at sun.ac.za  Wed Dec 13 18:01:06 2006
From: RKrug at sun.ac.za (Rainer M Krug)
Date: Wed, 13 Dec 2006 19:01:06 +0200
Subject: [R] exporting a table to latex
In-Reply-To: <8B08A3A1EA7AAC41BE24C750338754E6013DB670@HERMES.demogr.mpg.de>
References: <8B08A3A1EA7AAC41BE24C750338754E6013DB670@HERMES.demogr.mpg.de>
Message-ID: <458031D2.5080500@sun.ac.za>

Rau, Roland wrote:
> Hi, 
> 
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch 
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Rainer M Krug
>> Sent: Wednesday, December 13, 2006 8:47 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] exporting a table to latex
> 
>> Is there another way of formating the values to three decimal digits?
>>
>> Or another way of exporting them to LaTeX?
>>
> I hope I did not oversee any emails concerning your question. Typically,

No, you didn't.

> I use the xtable-package. Please let me know if the following code is
> not doing what you hope for.

It's perfect. Doing exactly what I wanted it to do - Thanks a lot

Raienr
> 
> Best,
> Roland
> 
> 
> mydata <- data.frame(Category=LETTERS[1:10], Percentage=runif(10))
> 
> library(xtable)
> 
> xtable(mydata, digits=c(0,0,3)) ### LaTeX format => default
> #### you can even create an HTML table
> print(xtable(mydata, digits=c(0,0,5)), type="HTML")
> 
> 
> ----------
> This mail has been sent through the MPI for Demographic Research.  Should you receive a mail that is apparently from a MPI user without this text displayed, then the address has most likely been faked. If you are uncertain about the validity of this message, please check the mail header or ask your system administrator for assistance.
> 


-- 
Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology and Entomology
University of Stellenbosch
Matieland 7602
South Africa

Tel:		+27 - (0)72 808 2975 (w)
Fax:		+27 - (0)86 516 2782
Fax:		+27 - (0)21 808 3304 (w)
Cell:		+27 - (0)83 9479 042

email:	RKrug at sun.ac.za
       	Rainer at krugs.de


From E.Husain at exeter.ac.uk  Wed Dec 13 18:25:01 2006
From: E.Husain at exeter.ac.uk (Ellen Husain)
Date: Wed, 13 Dec 2006 17:25:01 -0000 (GMT)
Subject: [R] why are my multiple box & whisker plots so small?
Message-ID: <1699.144.173.249.179.1166030701.squirrel@www.webmail.ex.ac.uk>

Hi all,

I'm sure this is reallly basic, but I just can get it to work. I want to
plot six box & whisker plots together to make one figure so that they
appear one below the next.

I can do this using >par(mfrow=c(6,1)), but each box&whisker plots end up
vertically compressed to the point where I can't see the actual bars, and
there is a large amount of white space between each one.

 I have tried reducing the margins using "mar", but nothing happens. I've
also tried using "plt" to make the plot area bigger, but this has no
effect either.

Can anyone help?

Many thanks in advance,

Ellen.

--


From rolf at math.unb.ca  Wed Dec 13 18:51:59 2006
From: rolf at math.unb.ca (rolf at math.unb.ca)
Date: Wed, 13 Dec 2006 13:51:59 -0400 (AST)
Subject: [R] why are my multiple box & whisker plots so small?
Message-ID: <200612131751.kBDHpxn8028156@weisner.math.unb.ca>


> I'm sure this is reallly basic, but I just can get it to work. I want
> to plot six box & whisker plots together to make one figure so that
> they appear one below the next.
> 
> I can do this using >par(mfrow=c(6,1)), but each box&whisker plots
> end up vertically compressed to the point where I can't see the
> actual bars, and there is a large amount of white space between each
> one.
> 
> I have tried reducing the margins using "mar", but nothing happens.

	You must be plotting them verically --- which is silly.
	There is simply no room to stack them vertically above each
	other.  This is a sub-optimal way of going at it anyway.

	I.e. you could do:

	par(mfrow=c(6,1),mar=c(0,3,0,2))
	boxplot(x1,horizontal=TRUE)
                .
                .
                .
	boxplot(x6,horizontal=TRUE)

	where x1, ..., x6 are your 6 data sets, and get an
	almost-reasonable plot.  But the axes are cramped and the
	alignment is out of whack.

	Much better to do:

	boxplot(list(x1,x2,x3,x4,x5,x6),horizontal=TRUE)

	the possibility of which is indicated in the help,
	which I suggest you read.

> I've also tried using "plt" to make the plot area bigger, but this
> has no effect either.

	If things don't fit, they don't fit.  Wonderful as it is,
	R can't work magic.

				cheers,

					Rolf Turner
					rolf at math.unb.ca


From dlvanbrunt at gmail.com  Wed Dec 13 18:53:24 2006
From: dlvanbrunt at gmail.com (David L. Van Brunt, Ph.D.)
Date: Wed, 13 Dec 2006 12:53:24 -0500
Subject: [R] Slightly off-topic, but probably funny to this group...
Message-ID: <d332d3e10612130953t3a6ccfe8h2610bc5c39f053e3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061213/66b60486/attachment.pl 

From gerifalte28 at hotmail.com  Wed Dec 13 19:13:52 2006
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Wed, 13 Dec 2006 11:13:52 -0700
Subject: [R] why are my multiple box & whisker plots so small?
In-Reply-To: <1699.144.173.249.179.1166030701.squirrel@www.webmail.ex.ac.uk>
References: <1699.144.173.249.179.1166030701.squirrel@www.webmail.ex.ac.uk>
Message-ID: <458042E0.20904@hotmail.com>

Please remember to add a sample of reproducible code when you post to 
this list (as recommended in the posting guide).

You probably want to use the lattice package i.e.

library(lattice)
?bwplot


Francisco


Ellen Husain wrote:
> Hi all,
> 
> I'm sure this is reallly basic, but I just can get it to work. I want to
> plot six box & whisker plots together to make one figure so that they
> appear one below the next.
> 
> I can do this using >par(mfrow=c(6,1)), but each box&whisker plots end up
> vertically compressed to the point where I can't see the actual bars, and
> there is a large amount of white space between each one.
> 
>  I have tried reducing the margins using "mar", but nothing happens. I've
> also tried using "plt" to make the plot area bigger, but this has no
> effect either.
> 
> Can anyone help?
> 
> Many thanks in advance,
> 
> Ellen.
> 
> --
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From aiminy at iastate.edu  Wed Dec 13 19:42:43 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Wed, 13 Dec 2006 12:42:43 -0600
Subject: [R] install.packages
Message-ID: <6.1.2.0.2.20061213124120.01c10978@aiminy.mail.iastate.edu>

I try to type this in my R-winEdt.
but I got these. Do you know?

Aimin

 > 
install.packages('http://rh-mirror.linux.iastate.edu/CRAN/bin/windows/contrib/2.4/plotrix_2.1-6.zip')
Warning in download.packages(pkgs, destdir = tmpd, available = available,  :
          no package 
'http://rh-mirror.linux.iastate.edu/CRAN/bin/windows/contrib/2.4/plotrix_2.1-6.zip' 
at the repositories


From p.murrell at auckland.ac.nz  Wed Dec 13 19:48:32 2006
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu, 14 Dec 2006 07:48:32 +1300
Subject: [R] expression()
In-Reply-To: <457FE64D.40807@ija.csic.es>
References: <457ED1CF.2060500@ija.csic.es>	<F5A97ABA-8B6C-4EC7-A40C-B93D724B8CA6@jhsph.edu>
	<457FE64D.40807@ija.csic.es>
Message-ID: <45804B00.9050205@stat.auckland.ac.nz>

Hi


javier garcia-pintado wrote:
> Thanks you,
> this works right.
> 
> I just would like to note one thing:
> although I've found italic() in the help for plotmath and I can see that
> the italic function:
> 
> mtext(expression(italic(beta)[max]),side=1,line=2)
> 
> does not work on the greek beta character.
> 
> Though not strictly necessary, this would be perfect for my plots, as I
> use them for papers to be published.


Take a look at
http://www.stat.auckland.ac.nz/~paul/Talks/fonts.pdf
(and maybe http://www.stat.auckland.ac.nz/~paul/Talks/fonts.tar.gz)
especially the latter half on mathematical formulas in plots, which
shows an example of using TeX fonts in R plots.
It includes links to further materials and explanations.

Paul


> Wishes,
> Javier
> ------------------------------------------
> Benilton Carvalho wrote:
>> mtext(expression(beta[max]), side=1, line=2)
>>
>> is it what you want?
>>
>> b
>>
>> On Dec 12, 2006, at 10:59 AM, javier garcia-pintado wrote:
>>
>>> Hi,
>>> I'm trying to use expression() to write a text to a graphic in the 
>>> margin.
>>>
>>> Using:
>>>
>>> mtext(expression(beta),side=1,line=2)
>>>
>>> writes a perfect beta greek character, but I need to add a subindex
>>> "max", and I'm trying:
>>>
>>> mtext(paste(expression(beta),"max"),side=1,line=2)
>>>
>>> simply writes "beta max" in the plot.
>>>
>>> Please, Could you tell me what I'm doing wrong?
>>>
>>> By the way, is there a way to add Latex expressions to graphics?  Then I
>>> could use the Latex expression: $\beta_{\mathrm{max}}$. This also  would
>>> be very useful for me for more complex expressions in plots.
>>>
>>> Best regards,
>>>
>>> Javier
>>>
>>> -- 
>>> Javier Garc?a-Pintado
>>> Institute of Earth Sciences Jaume Almera (CSIC)
>>> Lluis Sole Sabaris s/n, 08028 Barcelona
>>> Phone: +34 934095410
>>> Fax:   +34 934110012
>>> e-mail:jgarcia at ija.csic.es
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From bcarvalh at jhsph.edu  Wed Dec 13 19:48:52 2006
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Wed, 13 Dec 2006 13:48:52 -0500
Subject: [R] install.packages
In-Reply-To: <6.1.2.0.2.20061213124120.01c10978@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061213124120.01c10978@aiminy.mail.iastate.edu>
Message-ID: <1E294893-AB0B-4525-A733-D94D02988CC0@jhsph.edu>

install.packages("plotrix")

b.

On Dec 13, 2006, at 1:42 PM, Aimin Yan wrote:

> I try to type this in my R-winEdt.
> but I got these. Do you know?
>
> Aimin
>
>>
> install.packages('http://rh-mirror.linux.iastate.edu/CRAN/bin/ 
> windows/contrib/2.4/plotrix_2.1-6.zip')
> Warning in download.packages(pkgs, destdir = tmpd, available =  
> available,  :
>           no package
> 'http://rh-mirror.linux.iastate.edu/CRAN/bin/windows/contrib/2.4/ 
> plotrix_2.1-6.zip'
> at the repositories
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From deepayan.sarkar at gmail.com  Wed Dec 13 21:24:13 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 13 Dec 2006 12:24:13 -0800
Subject: [R] Passing arguments to panels in trellis plots
In-Reply-To: <Pine.LNX.4.61.0612131250210.21896@minnie.imada.sdu.dk>
References: <Pine.LNX.4.61.0612131250210.21896@minnie.imada.sdu.dk>
Message-ID: <eb555e660612131224r213fe3d1ge47d6d8a1925b916@mail.gmail.com>

On 12/13/06, Marco Chiarandini <marco at imada.sdu.dk> wrote:
> Dear all,
>
> I am trying to produce survfit plots in a trellis environment and I
> would like the plots to be logarithmic.
>
> I am trying this:
>
> print(Ecdf(~time | size*type, groups=alg,data=B,subscripts=TRUE,
>             panel=function(x,groups,subscripts)
>             {
>               t <- survfit(Surv(time[subscripts],event[subscripts])~groups[subscripts],data=B)
>               panel.xyplot(t[1]$time,1-t[1]$ssurv,type="s",lty=2)
>               panel.xyplot(t[2]$time,1-t[2]$ssurv,type="s",lty=2)
>             },
>            scale=list(log=TRUE)
> )
>
>
>
> but data are transformed in logarithm before being passed to the panel
> and hence the output of the function survfit is not the expected one.
>
> Is there a way to plot this correctly, ie, having first the survfit
> computed and then the plot, like in:
>
> plot(survfit(Surv(time,event)~groups,data=B),log=true)

Since you haven't bothered to follow the posting guide at all, it took
me a while to figure out that you live in that alternate R universe
created by Prof Harrell. Can't help you there, but in the standard
universe, things seem fairly simple:


library(survival)

fm <- survfit(Surv(time, status) ~ x, data=aml)

xyplot(surv ~ time, data = fm, type = "s",
       groups = rep(names(strata), strata))

xyplot(surv ~ time, data = fm, type = "s",
       groups = rep(names(strata), strata),
       scales = list(log = TRUE))

xyplot(surv + lower + upper ~ time | rep(names(strata), strata),
       data = fm, type = "s",
       scales = list(y = list(log = TRUE)))

-Deepayan


From elvis at xlsolutions-corp.com  Wed Dec 13 23:06:33 2006
From: elvis at xlsolutions-corp.com (elvis at xlsolutions-corp.com)
Date: Wed, 13 Dec 2006 15:06:33 -0700
Subject: [R] Course***January-February 2007*** R/Splus Fundamentals and
	Programming Techniques @ 7 cities: New York, San Diego,
	Washington DC, San Francisco, Chicago, Seattle, Princeton
Message-ID: <20061213150633.9f08cc34deb45d78e54b3b5664e21546.e2a52ab523.wbe@email.secureserver.net>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud to
announce our January-February 2007 "R/S-plus Fundamentals and
Programming
Techniques" : www.xlsolutions-corp.com/Rfund.htm

*** New York / January 8-9, 2007
*** San Diego / January 8-9, 2007
*** Washington DC / January 18-19, 2007
*** New York  / January 18-19, 2007
*** Boston / January 18-19, 2007
*** San Francisco / January 25-26, 2007     
*** Chicago / February 1-2, 2007
*** Seattle / February 1-2, 2007
*** San Diego / February 8-9, 2007
*** Princeton / February 15-16, 2007

Should we bring this course to your city? please let us know!

Reserve your seat now at the early bird rates! Payment due AFTER
the class

Course Description:

This two-day beginner to intermediate R/S-plus course focuses on a
broad spectrum of topics, from reading raw data to a comparison of R
and S. We will learn the essentials of data manipulation, graphical
visualization and R/S-plus programming. We will explore statistical
data analysis tools,including graphics with data sets. How to enhance
your plots, build your own packages (librairies) and connect via
ODBC,etc.
We will perform some statistical modeling and fit linear regression
models. Participants are encouraged to bring data for interactive
sessions

With the following outline:

- An Overview of R and S
- Data Manipulation and Graphics
- Using Lattice Graphics
- A Comparison of R and S-Plus
- How can R Complement SAS?
- Writing Functions
- Avoiding Loops
- Vectorization
- Statistical Modeling
- Project Management
- Techniques for Effective use of R and S
- Enhancing Plots
- Using High-level Plotting Functions
- Building and Distributing Packages (libraries)
- Connecting; ODBC, Rweb, Orca via sockets and via Rjava


Email us for group discounts.
Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578
Visit us: www.xlsolutions-corp.com/training.htm
Please let us know if you and your colleagues are interested in this
classto take advantage of group discount. Register now to secure your
seat!

Interested in R/Splus Advanced course? email us.


Cheers,
Elvis Miller, PhD
Manager Training.
XLSolutions Corporation
206 686 1578
www.xlsolutions-corp.com
elvis at xlsolutions-corp.com


From marco at imada.sdu.dk  Wed Dec 13 23:53:30 2006
From: marco at imada.sdu.dk (Marco Chiarandini)
Date: Wed, 13 Dec 2006 23:53:30 +0100 (CET)
Subject: [R] Passing arguments to panels in trellis plots
In-Reply-To: <eb555e660612131224r213fe3d1ge47d6d8a1925b916@mail.gmail.com>
References: <Pine.LNX.4.61.0612131250210.21896@minnie.imada.sdu.dk>
	<eb555e660612131224r213fe3d1ge47d6d8a1925b916@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0612132333390.30570@minnie.imada.sdu.dk>

Dear Deepayan,


> Since you haven't bothered to follow the posting guide at all, it took
> me a while to figure out that you live in that alternate R universe
> created by Prof Harrell. Can't help you there, but in the standard
> universe, things seem fairly simple:


I am sorry for not having been clear. I hope this time I get closer to
the correct post practice.

Here is what I am trying to do:

D <- expand.grid(rep=c(1:10),b=c("M","N"),a=c("10","20"),alg=c("A","B"))
D1 <- data.frame(D[,c(2,3,4)],time=runif(80,1,100))
D2 <- data.frame(D1,event=rbinom(80,1,0.9))

library(survival)
library(lattice)
library(Hmisc)
Ecdf(~time | a*b, groups=alg,data=D2,
              subscripts=TRUE,
              panel=function(x,groups,subscripts)
              {
                t <-
              survfit(Surv(time[subscripts],event[subscripts])~groups[subscripts],
                             data=D2,type="kaplan-meier",
                             conf.type="plain",conf.int=.95, se.fit=T)
                panel.xyplot(t[2]$time,1-t[2]$surv,type="s",lty=2)
                panel.xyplot(t[1]$time,1-t[1]$surv,type="s",lty=1)
              }
           )


Although not very elegant this does the job. Nevertheless, when I try to
add:

scales = list(log=TRUE)

in the Ecdf fucntion above I incurr in problems because the
transformation of data occurs before applying the function Surv.

Hence my question, is there a way to plot survfit in trellis plots with
different strata (the alg factor above) in the same plot and conditional
to combination of other factors (the a and b factors above)?


Here is my sessionInfo():

R version 2.4.0 (2006-10-03)
i686-pc-linux-gnu

locale:
LC_CTYPE=en_DK.UTF-8;LC_NUMERIC=C;LC_TIME=C;LC_COLLATE=C;LC_MONETARY=C;LC_MESSAGES=C;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C

attached base packages:
[1] "grid"      "splines"   "methods"   "stats"     "graphics"
"grDevices"
[7] "utils"     "datasets"  "base"

other attached packages:
    Hmisc  lattice survival
  "3.1-2" "0.14-9"   "2.29"


Regards,

- Marco.


--
Marco Chiarandini                     http://www.imada.sdu.dk/~marco
Department of Mathematics	      Email: marco at imada.sdu.dk
and Computer Science,		      Phone: +45 6550 4031
University of Southern Denmark        Fax: +45 6593 2691


From kmw at mail.rockefeller.edu  Thu Dec 14 00:04:31 2006
From: kmw at mail.rockefeller.edu (Knut M. Wittkowski)
Date: Wed, 13 Dec 2006 18:04:31 -0500
Subject: [R] How to avoid test for NAs in foreign function call
Message-ID: <7.0.1.0.0.20061213174310.01e54e50@rockefeller.edu>

We have packed logical vectors into integers, 32 flags at a time and 
then want to AND or OR these vectors of "integers" using other C functions.

The problem: occasionally, the packed sequence of 32 logical values 
resembles NA, causing the error message:

Error in bitAND(packed1, packed2, lenx) :
         NAs in foreign function call (arg 1)

How does one instruct R to avoid checking for NAs?

Knut M. Wittkowski, PhD,DSc
------------------------------------------
The Rockefeller University,
Center for Clinical and Translational Science
Research Design and Biostatistics,
1230 York Ave #121B, Box 322, NY,NY 10021
+1(212)327-7175, +1(212)327-8450 (Fax), kmw at rockefeller.edu
http://www.rockefeller.edu/ccts/rdbs.php


From Hong.Ooi at iag.com.au  Thu Dec 14 00:56:33 2006
From: Hong.Ooi at iag.com.au (Hong Ooi)
Date: Thu, 14 Dec 2006 10:56:33 +1100
Subject: [R] Problem with sas.get function in Hmisc
Message-ID: <200612132358.kBDNwgqX002051@hypatia.math.ethz.ch>


_______________________________________________________________________________________


After digging around in the sas.get code, I found a change that seems to
be causing the problem:

old version:

    ...
    status <- sys(paste(sasprog, sasin, "-log", log.file),
        output = FALSE)
    ...

new version:

    ...
    status <- sys(paste(shQuote(sasprog), shQuote(sasin), "-log", 
        shQuote(log.file)), output = FALSE)
    ...


For some reason, sys() bombs when given a command string with quotes in
it. The string works fine when pasted into a command line window, so
maybe it's a problem with the WinXP commmand interpreter? In any case,
changing the sys() call to system() seems to fix the problem.

    ...
    status <- system(paste(shQuote(sasprog), shQuote(sasin), "-log", 
        shQuote(log.file)))
    ...


-- 
Hong Ooi
Senior Research Analyst, IAG Limited
388 George St, Sydney NSW 2000
+61 (2) 9292 1566
-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jean Vidal
Sent: Wednesday, 13 December 2006 8:02 PM
To: acalatro at rhoworld.com
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Problem with sas.get function in Hmisc

The workaround you point seems to be the solution for the moment.
I not sure I will have time (and courage) to try to figure out where
the bug comes from. Hope a more literate R programmer than me is
willing to dive in...

Thank you for your answer.

2006/12/12, Agustin Calatroni <acalatro at rhoworld.com>:
> Jean, I saw your email to the R-help mailing list. I also notice the
> problem a few months back and email the maintainer (Charles Dupont)
but
> never got a response. Since I used the function a lot and in order to
> avoid the error I use version 3.0-12 instead of updating the a newer
> version. To download the earlier version use the following site:
> http://cran.r-project.org/bin/windows/contrib/2.2/ If you figure out
> another way around the problem I will be interested in knowing the
solution.
>
> Sincerely,
>
>
> -- Agustin Calatroni
>
> Agustin Calatroni wrote:
> > I been having the following problem when I updated the Hmisc package
> > from version 3.0-12 to version 3.1-1.
> >
> > Create dataset under SAS:
> > data a;
> >  do i = 1 to 100;
> >   x = rannor(0);
> >   output;
> >  end;
> > run;
> >
> > Hmisc version 3.0-12:
> > library(Hmisc)
> > sas.get('C:\\Documents and Settings\\novell\\My Documents\\SAS
> > Temp\\_TD3428','a')
> >
> > NO PROBLEM
> >
> > Hmisc version 3.1-1:
> > library(Hmisc)
> > sas.get('C:\\Documents and Settings\\novell\\My Documents\\SAS
> > Temp\\_TD3428','a')
> >
> > The filename, directory name, or volume label syntax is incorrect.
> > Error in sas.get("C:\\Documents and Settings\\novell\\My
Documents\\SAS
> > Temp\\_TD3428",  :
> >         SAS job failed with status 1
> > In addition: Warning message:
> > 'cmd' execution failed with error code 1 in: shell(cmd, wait = TRUE,
> > intern = output)
> >
> > R.Version()
> > $platform
> > [1] "i386-pc-mingw32"
> > $arch
> > [1] "i386"
> > $os
> > [1] "mingw32"
> > $system
> > [1] "i386, mingw32"
> > $status
> > [1] ""
> > $major
> > [1] "2"
> > $minor
> > [1] "3.1"
> > $year
> > [1] "2006"
> > $month
> > [1] "06"
> > $day
> > [1] "01"
> > $`svn rev`
> > [1] "38247"
> > $language
> > [1] "R"
> > $version.string
> > [1] "Version 2.3.1 (2006-06-01)"
> >
> > Thanks for Hmisc and Design packages, they are an invaluable
resource.
> > Sorry if this is a stupid question and I missed something obvious.
> >
>
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

_______________________________________________________________________________________

The information transmitted in this message and its attachme...{{dropped}}


From Keith.Chamberlain at colorado.edu  Thu Dec 14 01:23:45 2006
From: Keith.Chamberlain at colorado.edu (Keith.Chamberlain at colorado.edu)
Date: Wed, 13 Dec 2006 17:23:45 -0700
Subject: [R] Extracting tolerance in R?
In-Reply-To: <mailman.7.1166007604.22202.r-help@stat.math.ethz.ch>
References: <mailman.7.1166007604.22202.r-help@stat.math.ethz.ch>
Message-ID: <1166055825.458099917fda4@webmail.colorado.edu>

Dear list,

How is the tolerance for a model parameter in an lm() call extracted?

I did not see a solution in the documentation for lm(), or predict(), nor in the
archives using 'tolerance' as the search string. I also checked into the nlme
package, though nothing popped out at me.

Sincerely,
KeithC.


From jwd at surewest.net  Thu Dec 14 01:28:11 2006
From: jwd at surewest.net (J Dougherty)
Date: Wed, 13 Dec 2006 16:28:11 -0800
Subject: [R] Obiously obsolete
In-Reply-To: <457ED1CF.2060500@ija.csic.es>
References: <457ED1CF.2060500@ija.csic.es>
Message-ID: <200612131628.11255.jwd@surewest.net>

On Tuesday 12 December 2006 07:59, javier garcia-pintado wrote:
> "beta max"

Sorry, couldn't resist.

JD


From RMan54 at cox.net  Thu Dec 14 01:32:38 2006
From: RMan54 at cox.net (RMan54)
Date: Wed, 13 Dec 2006 16:32:38 -0800 (PST)
Subject: [R] Reverse order of grouping factor in grouppedData
Message-ID: <7864653.post@talk.nabble.com>


I created the following groupedData object (nlme library):

gd <- groupedData(Conc ~ Time | Subj,
    order.groups=T,
    FUN = myf,
    data=mydata)

The idea of the myf function is to reverse the order of the grouping factor
Subj (or better, reorder from largest to smallest). In the mydata data set,
Subj is an integer that gets converted into a factor in the groupedData
object.
Does anyone knows how to write this function myf?

It may be even impossible to do it this way because the function is applied
on the dependent variable Conc (default in the package is mean), while I
need to apply my stuff on the factor Subj.

The lattice plot routines underneath the nlme library (like xyplot)
unfortunately start plotting the panels on the bottom of the page and up. In
order to have the order in a logical fashion (smallest to highest subj
number starting on top of the page and down), I need to reorder in the
groupedData object.


-- 
View this message in context: http://www.nabble.com/Reverse-order-of-grouping-factor-in-grouppedData-tf2817711.html#a7864653
Sent from the R help mailing list archive at Nabble.com.


From deepayan.sarkar at gmail.com  Thu Dec 14 02:02:07 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 13 Dec 2006 17:02:07 -0800
Subject: [R] Reverse order of grouping factor in grouppedData
In-Reply-To: <7864653.post@talk.nabble.com>
References: <7864653.post@talk.nabble.com>
Message-ID: <eb555e660612131702t5a447564y6cd5d23f33c697cc@mail.gmail.com>

On 12/13/06, RMan54 <RMan54 at cox.net> wrote:
>
> I created the following groupedData object (nlme library):
>
> gd <- groupedData(Conc ~ Time | Subj,
>     order.groups=T,
>     FUN = myf,
>     data=mydata)
>
> The idea of the myf function is to reverse the order of the grouping factor
> Subj (or better, reorder from largest to smallest). In the mydata data set,
> Subj is an integer that gets converted into a factor in the groupedData
> object.
> Does anyone knows how to write this function myf?
>
> It may be even impossible to do it this way because the function is applied
> on the dependent variable Conc (default in the package is mean), while I
> need to apply my stuff on the factor Subj.
>
> The lattice plot routines underneath the nlme library (like xyplot)
> unfortunately start plotting the panels on the bottom of the page and up. In
> order to have the order in a logical fashion (smallest to highest subj
> number starting on top of the page and down), I need to reorder in the
> groupedData object.

Why? Why not consider the more natural solution of reordering while
plotting? The 'as.table' argument of xyplot allows you to order panels
from top to bottom, and arguments to xyplot etc can be passed to
plot(groupedData.obj...) calls directly. If you feel that the default
is "unfortunate", you can even change it globally using

lattice.options(default.args = list(as.table = TRUE))

-Deepayan


From ccleland at optonline.net  Thu Dec 14 02:07:16 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 13 Dec 2006 20:07:16 -0500
Subject: [R] Extracting tolerance in R?
In-Reply-To: <1166055825.458099917fda4@webmail.colorado.edu>
References: <mailman.7.1166007604.22202.r-help@stat.math.ethz.ch>
	<1166055825.458099917fda4@webmail.colorado.edu>
Message-ID: <4580A3C4.3020103@optonline.net>

Keith.Chamberlain at colorado.edu wrote:
> Dear list,
> 
> How is the tolerance for a model parameter in an lm() call extracted?
> 
> I did not see a solution in the documentation for lm(), or predict(), nor in the
> archives using 'tolerance' as the search string. I also checked into the nlme
> package, though nothing popped out at me.

vif() in the car package gives variance inflation factors.

tolerance = 1/vif

> Sincerely,
> KeithC.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From deepayan.sarkar at gmail.com  Thu Dec 14 02:17:14 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 13 Dec 2006 17:17:14 -0800
Subject: [R] Passing arguments to panels in trellis plots
In-Reply-To: <Pine.LNX.4.61.0612132333390.30570@minnie.imada.sdu.dk>
References: <Pine.LNX.4.61.0612131250210.21896@minnie.imada.sdu.dk>
	<eb555e660612131224r213fe3d1ge47d6d8a1925b916@mail.gmail.com>
	<Pine.LNX.4.61.0612132333390.30570@minnie.imada.sdu.dk>
Message-ID: <eb555e660612131717y54c376cfm3b7d2a3dc4d8acff@mail.gmail.com>

On 12/13/06, Marco Chiarandini <marco at imada.sdu.dk> wrote:
> Dear Deepayan,
>
>
> > Since you haven't bothered to follow the posting guide at all, it took
> > me a while to figure out that you live in that alternate R universe
> > created by Prof Harrell. Can't help you there, but in the standard
> > universe, things seem fairly simple:
>
>
> I am sorry for not having been clear. I hope this time I get closer to
> the correct post practice.
>
> Here is what I am trying to do:
>
> D <- expand.grid(rep=c(1:10),b=c("M","N"),a=c("10","20"),alg=c("A","B"))
> D1 <- data.frame(D[,c(2,3,4)],time=runif(80,1,100))
> D2 <- data.frame(D1,event=rbinom(80,1,0.9))
>
> library(survival)
> library(lattice)
> library(Hmisc)
> Ecdf(~time | a*b, groups=alg,data=D2,
>               subscripts=TRUE,
>               panel=function(x,groups,subscripts)
>               {
>                 t <-
>               survfit(Surv(time[subscripts],event[subscripts])~groups[subscripts],
>                              data=D2,type="kaplan-meier",
>                              conf.type="plain",conf.int=.95, se.fit=T)
>                 panel.xyplot(t[2]$time,1-t[2]$surv,type="s",lty=2)
>                 panel.xyplot(t[1]$time,1-t[1]$surv,type="s",lty=1)
>               }
>            )
>
>
> Although not very elegant this does the job. Nevertheless, when I try to
> add:
>
> scales = list(log=TRUE)
>
> in the Ecdf fucntion above I incurr in problems because the
> transformation of data occurs before applying the function Surv.

Yes, that's a feature of lattice.

> Hence my question, is there a way to plot survfit in trellis plots with
> different strata (the alg factor above) in the same plot and conditional
> to combination of other factors (the a and b factors above)?

Not if you insist on using 'scales = list(log = TRUE)' to specify log
scales. Use a different argument that gets passed to the panel
function, and then use it in the panel function. I suspect you are
using Ecdf simply to get a probability scale on the y-axis; the proper
way to specify data-based limits is to write a prepanel function, as
explained in ?xyplot.

-Deepayan


From slacey at umich.edu  Thu Dec 14 03:49:47 2006
From: slacey at umich.edu (Steven Lacey)
Date: Wed, 13 Dec 2006 21:49:47 -0500
Subject: [R] strategy for doing an ANOVA on unbalanced data
Message-ID: <007701c71f2a$8541d4c0$6400a8c0@zephyr>

Hi, 

I would like some help deciding if and how to average my data before running
an ANOVA. Let me first describe the data and what makes it unique.
Hopefully, that will generate some ideas because I am not sure what kind of
model I need to use. I don't know how to describe this succinctly, so please
bear with me. This is my last analysis for my dissertation and I really
could use some help.

I have 3 factors:
	
Mapping: 5 levels, between-subjects 
Finger: 4 levels, within-subjects
Subject: 40 subjects, 8 nested within each level of mapping

Mapping is crossed with finger. So, I have 160 observations; 5 mappings x 4
fingers x 8 subjects. However, these observations are not all independent as
there are only 40 subjects. The 4 observation per subject are not
replicates, as they are observed under different conditions. For each of
these 160 "experimental units" I have multiple dependent variables. 

I take one of these dependent variables, nd, and perform a cluster analysis
nested within the 20 levels of mapping x finger. That is, I take the 8
values for each combination of mapping and finger and cluster them. Each
time I request a 3 cluster solution. This adds a fourth factor to the
analysis, cluster. 

I want to know if some other dependent variable, ti, which is not involved
in the clustering, differs by cluster. How do I test this? 

I quickly run into a couple of problems.
1) The observations at each level of cluster are neither entirely
independent nor entirely dependent. How do I handle this?
2) The mean of each cluster is "incorrect". The mean is biased by the number
of experimental units at each level of mapping x finger that contribute to
that cluster. 

				Subject
Mapping 	finger 	1   2   3   4   5   6   7   8
Color		index       2   3   1   1   1   2   1   2 (cluster)

				Subject
Mapping 	finger 	9   10  11  12  13  14  15  16
Shape		middle      2   2   2   2   3   2   1   2 (cluster)

For instance, the values entered into cluster 1, for instance, are biased by
the fact that 4 of the experimental units are from the color-index cell and
1 is from the shape-middle cell. Cluster membership is not balanced with
respect to levels of mapping x finger. I would like the mean for each
cluster to be "unweighted" with respect to levels of mapping x finger. That
is, I would like the modeled mean for cluster 1 to be the mean of 20 means,
one from each level of mapping x finger for this cluster. How would I
achieve this?

My solution has been to average over the experimental units at each
combination of mapping, finger, and cluster. This yields 60 averaged
observations. The data look like the following:
	
			Cluster
Mapping-finger	1	2	3
Color-index
Color-middle
Color-ring
Color-little
Shape-index
. . .

I then do a repeated-measures ANOVA, treating cluster as a within-subjects
factor and Mapping-finger factor (20 levels) as a random effect. This seems
reasonable because the observations are matched by the mapping-finger
factor. The effect of cluster is significant. But, is this analysis
legitimate? What happened to the variability between the unaveraged
experimental units? Is that indirectly represented in the model? If so,
where and how? Can I talk about the effect of cluster as affecting
individual subjects even though the random factor is mapping-finger not
subjects?

Error: rep(gl(20, 1), 3)
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals 19  78596    4137               

Error: rep(gl(20, 1), 3):gl(3, 20)
          Df Sum Sq Mean Sq F value   Pr(>F)   
gl(3, 20)  2  19820    9910  6.9592 0.002659 **
Residuals 38  54113    1424                    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

I have included the unaveraged data below. 

Thank you for any help you can provide, 

Steve


"tmp1" <-
structure(list(mapping = structure(as.integer(c(1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 
5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 
3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 
5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 
4, 5, 5, 5, 5, 5, 5, 5)), .Label = c("color", "shape", "letter", 
"compatible", "incompatible"), class = "factor"), finger =
structure(as.integer(c(1, 
2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 
1, 1, 2, 2, 2, 2, 3, 4, 4, 1, 2, 3, 3, 3, 3, 4, 1, 2, 2, 2, 2, 
2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 1, 2, 2, 3, 3, 4, 1, 2, 2, 3, 
3, 3, 4, 4, 1, 2, 3, 3, 3, 3, 4, 4, 4, 1, 2, 2, 2, 2, 3, 3, 4, 
4, 1, 1, 1, 2, 2, 3, 3, 3, 4, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 4, 
4, 4, 4, 4, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 1, 1, 1, 1, 
1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 
4, 4, 4, 4, 4, 1, 1, 1, 1, 2, 3, 4)), .Label = c("index", "middle", 
"ring", "little"), class = "factor"), Subject = structure(as.integer(c(1, 
1, 2, 4, 6, 7, 2, 7, 8, 1, 2, 10, 11, 9, 13, 15, 10, 11, 15, 
10, 12, 16, 21, 22, 21, 22, 23, 24, 23, 21, 23, 30, 27, 25, 29, 
30, 32, 31, 36, 33, 34, 35, 38, 40, 33, 36, 39, 40, 33, 35, 36, 
38, 39, 40, 4, 5, 8, 1, 6, 6, 12, 10, 12, 9, 12, 16, 11, 15, 
19, 19, 17, 20, 21, 24, 19, 22, 24, 31, 28, 30, 31, 32, 27, 28, 
26, 27, 33, 35, 38, 36, 37, 35, 37, 38, 37, 2, 3, 5, 6, 7, 8, 
3, 3, 4, 5, 3, 4, 5, 7, 8, 9, 13, 14, 15, 16, 11, 14, 16, 13, 
14, 9, 13, 14, 17, 18, 20, 23, 24, 17, 18, 20, 18, 19, 22, 17, 
18, 20, 25, 26, 27, 28, 29, 32, 25, 26, 29, 26, 31, 25, 28, 29, 
30, 32, 34, 37, 39, 40, 39, 34, 34)), .Label = c("1", "2", "3", 
"4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", 
"16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", 
"27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", 
"38", "39", "40"), class = c("ordered", "factor")), cluster =
structure(as.integer(c(1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3)), .Label = c("slowest", "moderate", 
"fastest"), class = c("ordered", "factor")), ti = c(63.1004276803134, 
-23.2992754096397, -135.957917918668, 42.7865713093507, 40.6495491827651, 
30.9835635847383, -140.456315927602, 16.1884759276633, -89.540435241939, 
31.7971254876269, -29.4232163522977, -25.1278025126572, -12.4566535167804, 
37.4289344617898, 52.5706302338991, -35.8413047438251, 15.2155259231272, 
2.79001951428484, -74.016437811255, 34.0472876514206, 8.23236516636759, 
41.752385308372, 6.86452959238867, -9.04240128098512, -35.5546654074403, 
-25.5058760190386, -31.6500756806436, -80.0839944596871, -178.282994307473, 
14.0652868642960, -54.1115243880536, -51.9682404685031, -54.9501041501482, 
-42.7431807244454, 16.6243910954292, -22.4431847176876, -14.7035707173501, 
-18.1056055182825, -49.7109985071331, -65.2909026882744, 119.501461368539, 
-27.0759830958289, 105.287851617557, -95.9423287716085, -86.0069936272954, 
-59.0894321514947, 20.8884421023127, -118.656165569357, -63.9198321967824, 
1.96187161119022, -153.768707101974, 49.3725736606709, 63.7546555849159, 
-12.7991590297592, 56.8196174117707, -9.31749776409478, -13.2032252050034, 
8.7394525690294, 26.8836983079709, 74.8622974499625, -4.27206914920544, 
33.6865400099209, -81.0876079273623, -9.57784097773667, 3.53941649430584, 
-43.1966556137174, 19.9505522181613, 31.1093048715892, -2.81846107124408, 
-16.4634071989511, -56.2626091719525, 5.8894597113893, -11.9460426501163, 
-50.5016604604713, 32.5846987625618, -6.58024973176658, 24.9634141295032, 
-29.7109602506806, -59.2110304133438, -33.073404186089, -71.242648484072, 
-59.7536863171843, -18.9735253330240, -56.0906981355611, -48.8598997546233, 
-23.1287373512131, -84.6533103813389, 21.5708032453866, 8.21368474082069, 
16.4365994699192, 71.586596869219, -45.6241843743441, 235.334517416515, 
101.332858707625, 140.604896021264, 12.1196300208124, 122.132015696109, 
37.0374068952659, 75.5952402766181, 94.4578687986073, 53.9870738026712, 
67.1856211307736, 77.1640848276398, 50.8498395189965, -78.4933065893263, 
95.1069600779013, 73.149329272702, -4.9339023803459, 113.586145614935, 
21.0193638623337, 22.883456523432, 25.435232226029, 24.3953597764337, 
18.6575664551592, -29.0022097713646, 10.4364866129519, 27.1594565069105, 
10.2399003236453, 14.7130660648562, 65.9229552720177, 72.592470053935, 
74.5394338773406, 67.9822705454202, 119.281862515375, 42.6436509977648, 
48.8182384714562, 16.9719600025627, 51.9587360263067, 47.7585090033625, 
4.61299932897614, -88.703759098076, 14.0860299350686, 13.7666737583254, 
-74.7564309039725, 110.686393495531, 47.5857765231565, 101.863081945050, 
-28.6193204179635, -30.6037063002317, -58.0976833896048, -30.7896122613757, 
-36.7538888196661, -43.1772014522395, -30.636780420773, -33.9709296084748, 
-22.5891682772131, -37.0311490456283, -45.2255618875948, -13.3899512263205, 
7.82870987793496, -47.7610311277551, -0.0190839046758119, -24.7251829424596,

62.6549969288884, -52.5006031302601, -41.0342563813402, -159.347540607221, 
0.608912472459365, -50.5971346100457, 66.386987819285)), .Names =
c("mapping", 
"finger", "Subject", "cluster", "ti"), row.names = c("1", "2", 
"3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", 
"15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", 
"26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", 
"37", "38", "39", "40", "41", "42", "43", "44", "45", "46", "47", 
"48", "49", "50", "51", "52", "53", "54", "55", "56", "57", "58", 
"59", "60", "61", "62", "63", "64", "65", "66", "67", "68", "69", 
"70", "71", "72", "73", "74", "75", "76", "77", "78", "79", "80", 
"81", "82", "83", "84", "85", "86", "87", "88", "89", "90", "91", 
"92", "93", "94", "95", "96", "97", "98", "99", "100", "101", 
"102", "103", "104", "105", "106", "107", "108", "109", "110", 
"111", "112", "113", "114", "115", "116", "117", "118", "119", 
"120", "121", "122", "123", "124", "125", "126", "127", "128", 
"129", "130", "131", "132", "133", "134", "135", "136", "137", 
"138", "139", "140", "141", "142", "143", "144", "145", "146", 
"147", "148", "149", "150", "151", "152", "153", "154", "155", 
"156", "157", "158", "159", "160"), class = "data.frame")


From eyngele at yahoo.com  Thu Dec 14 06:18:18 2006
From: eyngele at yahoo.com (Elena)
Date: Wed, 13 Dec 2006 21:18:18 -0800 (PST)
Subject: [R] Syntax for getting covariance matrix
Message-ID: <20061214051818.90866.qmail@web50801.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061213/2cb33ef2/attachment.pl 

From Keith.Chamberlain at colorado.edu  Thu Dec 14 06:47:34 2006
From: Keith.Chamberlain at colorado.edu (KeithC.)
Date: Wed, 13 Dec 2006 22:47:34 -0700
Subject: [R] Extracting tolerance in R?
In-Reply-To: <4580A3C4.3020103@optonline.net>
Message-ID: <007d01c71f43$5b6f01e0$0700000a@KLab>

Dear Chuck,

Thank you. Vif() is exactly what I needed!

Sincerely,
KeithC.


From aiminy at iastate.edu  Thu Dec 14 07:02:33 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Thu, 14 Dec 2006 00:02:33 -0600
Subject: [R] subset question
Message-ID: <6.1.2.0.2.20061213235132.01bfd3c0@aiminy.mail.iastate.edu>

I have a data set p1982, its structure is the following

Then I take 20 observations from this dataset, and assign to pr.

in p1982, p has 1982 levels, in dataset pr,  p should have 1 levels.

But I do str(pr), it shows that p still has 1982 levels.

also for these

 > pr$aa
  [1] ARG THR ASP CYS TYR ASN VAL ASN ARG ILE ASP THR THR ALA SER CYS LYS 
THR ALA LYS
Levels: ALA ARG ASN ASP CYS GLN GLU HIS ILE LEU LYS MET PHE PRO SER THR TRP 
TYR VAL

it seems pr$aa don't have level GLU, but it list this level.

I don't understand this, Is there some reason for these?

thanks,



 > str(p1982)
'data.frame':   465979 obs. of  6 variables:
  $ p  : Factor w/ 1982 levels "154l_aa","1A0P_aa",..: 1 1 1 1 1 1 1 1 1 1 ...
  $ aa : Factor w/ 19 levels "ALA","ARG","ASN",..: 2 16 4 5 18 3 19 3 2 9 ...
  $ as : num  152.0  15.9  65.1  57.2  28.9 ...
  $ ms : num  108.8  28.3  59.2  49.9  31.8 ...
  $ cur: num  -0.1020  0.2564  0.0312 -0.0550  0.0526 ...
  $ sc : num   92.10 103.67   7.27  72.98  96.12 ...

 > pr<-p1982[1:20,]

 > str(pr)
'data.frame':   20 obs. of  6 variables:
  $ p  : Factor w/ 1982 levels "154l_aa","1A0P_aa",..: 1 1 1 1 1 1 1 1 1 1 ...
  $ aa : Factor w/ 19 levels "ALA","ARG","ASN",..: 2 16 4 5 18 3 19 3 2 9 ...
  $ as : num  152.0  15.9  65.1  57.2  28.9 ...
  $ ms : num  108.8  28.3  59.2  49.9  31.8 ...
  $ cur: num  -0.1020  0.2564  0.0312 -0.0550  0.0526 ...
  $ sc : num   92.10 103.67   7.27  72.98  96.12 ...

 > pr
          p  aa     as     ms         cur        sc
1  154l_aa ARG 152.04 108.83 -0.10201400  92.10410
2  154l_aa THR  15.86  28.32  0.25635600 103.67100
3  154l_aa ASP  65.13  59.16  0.03121370   7.27311
4  154l_aa CYS  57.20  49.85 -0.05495890  72.97930
5  154l_aa TYR  28.87  31.75  0.05264570  96.11660
6  154l_aa ASN  31.14  31.09  0.06327110  55.65980
7  154l_aa VAL   0.00   0.00  0.00000000 142.92100
8  154l_aa ASN  83.46  62.03 -0.10425800  78.38800
9  154l_aa ARG 156.02 111.52 -0.12303800  70.28280
10 154l_aa ILE   6.71  18.37  0.29933600 150.02100
11 154l_aa ASP  86.45  59.83 -0.15856600  73.52120
12 154l_aa THR  26.39  33.68  0.06101840 133.57200
13 154l_aa THR 107.61  70.48 -0.17145100  72.48660
14 154l_aa ALA   2.31   5.40  0.24000000  90.67890
15 154l_aa SER  30.16  30.08 -0.00753989  96.24600
16 154l_aa CYS  60.11  46.86 -0.09648100  32.19480
17 154l_aa LYS 127.05  95.48 -0.11545500  81.00930
18 154l_aa THR   5.74  18.45  0.27963100 164.13100
19 154l_aa ALA   0.00   0.00  0.00000000  68.85680
20 154l_aa LYS 113.58  81.72 -0.12914300  49.38620
 >


From rmh at temple.edu  Thu Dec 14 07:27:23 2006
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 14 Dec 2006 01:27:23 -0500 (EST)
Subject: [R] subset question
Message-ID: <20061214012723.BPR44095@po-d.temple.edu>

help("[.factor")


a <- factor(letters[1:5])
a
a[1:3]
a[1:3, drop=T]


From ripley at stats.ox.ac.uk  Thu Dec 14 08:11:13 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 14 Dec 2006 07:11:13 +0000 (GMT)
Subject: [R] Syntax for getting covariance matrix
In-Reply-To: <20061214051818.90866.qmail@web50801.mail.yahoo.com>
References: <20061214051818.90866.qmail@web50801.mail.yahoo.com>
Message-ID: <Pine.LNX.4.64.0612140708530.21816@gannet.stats.ox.ac.uk>

On Wed, 13 Dec 2006, Elena wrote:

> I am new at using R and was wondering if someone can give me the exact 
> syntax for getting the covariance matrix.
>
> I used logit to generate the equation. Specifically the syntax was:
>
> glm(formula = Status ~ A + B + C + D + E, family = binomial(link = logit),
> data = logit)
>
> Do you know the syntax to get the covariance matrix? Thanks!

Of what?  If you meant the estimators of the coefficients, see ?vcov.

> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

PLEASE do as we ask.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From RMan54 at cox.net  Thu Dec 14 08:22:41 2006
From: RMan54 at cox.net (RMan54)
Date: Wed, 13 Dec 2006 23:22:41 -0800 (PST)
Subject: [R] xyplot: discrete points + continuous curve per panel
Message-ID: <7867892.post@talk.nabble.com>


I have a number of x, y observations (Time, Conc) for a number of Subjects
(with subject number Subj) and Doses. I can plot the individual points with
xyplot fine:

xyplot(Conc ~ Time | Subj,
         Groups=Dose,
         data=myData,
         panel =  function(x,y) { 
              panel.xyplot(x, y) 
              panel.superpose(???) # Needs more here 
         } 
) 

I also like to plot on each panel (there is one Subj per panel) a continuous
curve with predictions that I can calculate from a rather complicated
function:

myPred <- (time, subj, dose) {
       returns predicted value of Conc for a given time, subj and dose
}

The predicted curves are different for each panel.

How do I plot the predictions? I have tried to add panel.superinpose in the
xyplot portion but can't link to the myPred function. I also know about
panel.curve but couldn't make it work.

My attempt is to calculate the predictions on the fly. Is this possible? Or
do I need to calculate all predictions first and put the results in a data
frame.
Thanks for any help,
Rene
-- 
View this message in context: http://www.nabble.com/xyplot%3A-discrete-points-%2B-continuous-curve-per-panel-tf2818931.html#a7867892
Sent from the R help mailing list archive at Nabble.com.


From xmeng at capitalbio.com  Thu Dec 14 08:52:10 2006
From: xmeng at capitalbio.com (XinMeng)
Date: Thu, 14 Dec 2006 15:52:10 +0800
Subject: [R] digital length
Message-ID: <366082730.14577@capitalbio.com>

Hell sir:
How can I control the digital length of data?

e.g:
0.1234 is the output of an algorithm.
What I want is 0.12 instead.

How can I get this ?

Thanks a lot!

My best


From randsnews at gmail.com  Thu Dec 14 09:10:45 2006
From: randsnews at gmail.com (S.Q. WEN)
Date: Thu, 14 Dec 2006 16:10:45 +0800
Subject: [R] How to sort data points in high dimension space
Message-ID: <8b340d720612140010s57f0b2f0nae635668ea72a35c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061214/e0d3f549/attachment.pl 

From kubovy at virginia.edu  Thu Dec 14 09:11:43 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Thu, 14 Dec 2006 03:11:43 -0500
Subject: [R] digital length
In-Reply-To: <366082730.14577@capitalbio.com>
References: <366082730.14577@capitalbio.com>
Message-ID: <8060932E-14EE-43F4-978D-60F8867E07EE@virginia.edu>

?Round

On Dec 14, 2006, at 2:52 AM, XinMeng wrote:

> How can I control the digital length of data?
>
> e.g:
> 0.1234 is the output of an algorithm.
> What I want is 0.12 instead.

_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/


From ligges at statistik.uni-dortmund.de  Thu Dec 14 09:40:46 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 14 Dec 2006 09:40:46 +0100
Subject: [R] install.packages
In-Reply-To: <6.1.2.0.2.20061213124120.01c10978@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061213124120.01c10978@aiminy.mail.iastate.edu>
Message-ID: <45810E0E.3060805@statistik.uni-dortmund.de>



Aimin Yan wrote:
> I try to type this in my R-winEdt.


AAAARRRRGH! Again and again I have to tell that RWinEdt is just some 
enhancement for an editor that may help for you R programming, but is 
not related to any error messages you receive from R!


> but I got these. Do you know?


Yes, you are not reading any documentation at all, obviously. Please try 
to reduce your mail traffic on R-help by simply reading some 
documentation (and the posting guide!) from time to time. Thank you.

Uwe Ligges


> Aimin
> 
>  > 
> install.packages('http://rh-mirror.linux.iastate.edu/CRAN/bin/windows/contrib/2.4/plotrix_2.1-6.zip')
> Warning in download.packages(pkgs, destdir = tmpd, available = available,  :
>           no package 
> 'http://rh-mirror.linux.iastate.edu/CRAN/bin/windows/contrib/2.4/plotrix_2.1-6.zip' 
> at the repositories
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Dec 14 10:17:42 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 14 Dec 2006 10:17:42 +0100
Subject: [R] xyplot: discrete points + continuous curve per panel
In-Reply-To: <7867892.post@talk.nabble.com>
Message-ID: <458124C6.23793.8364B8@localhost>

Hi

there is probably better solution but you can try to fiidle with this 
idea, which adds stight lines to each panel one after another. 

# based on Gabor Grothendieck's code suggestion
# adds straight lines to panels in lattice plots

addLine<- function(...) {
tcL <- trellis.currentLayout()
for(i in 1:nrow(tcL))
  for(j in 1:ncol(tcL))
    if (tcL[i,j] > 0) {
        trellis.focus("panel", j, i, highlight = FALSE)
        panel.abline(...)
        trellis.unfocus()
        }
}

You need to change panel.abline(...) part maybe to panel.curve or 
panel.segments or?

HTH
Petr



On 13 Dec 2006 at 23:22, RMan54 wrote:

Date sent:      	Wed, 13 Dec 2006 23:22:41 -0800 (PST)
From:           	RMan54 <RMan54 at cox.net>
To:             	r-help at stat.math.ethz.ch
Subject:        	[R] xyplot: discrete points + continuous curve per panel

> 
> I have a number of x, y observations (Time, Conc) for a number of
> Subjects (with subject number Subj) and Doses. I can plot the
> individual points with xyplot fine:
> 
> xyplot(Conc ~ Time | Subj,
>          Groups=Dose,
>          data=myData,
>          panel =  function(x,y) { 
>               panel.xyplot(x, y) 
>               panel.superpose(???) # Needs more here 
>          } 
> ) 
> 
> I also like to plot on each panel (there is one Subj per panel) a
> continuous curve with predictions that I can calculate from a rather
> complicated function:
> 
> myPred <- (time, subj, dose) {
>        returns predicted value of Conc for a given time, subj and dose
> }
> 
> The predicted curves are different for each panel.
> 
> How do I plot the predictions? I have tried to add panel.superinpose
> in the xyplot portion but can't link to the myPred function. I also
> know about panel.curve but couldn't make it work.
> 
> My attempt is to calculate the predictions on the fly. Is this
> possible? Or do I need to calculate all predictions first and put the
> results in a data frame. Thanks for any help, Rene -- View this
> message in context:
> http://www.nabble.com/xyplot%3A-discrete-points-%2B-continuous-curve-p
> er-panel-tf2818931.html#a7867892 Sent from the R help mailing list
> archive at Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

Petr Pikal
petr.pikal at precheza.cz


From birdandfish99 at gmail.com  Thu Dec 14 11:20:14 2006
From: birdandfish99 at gmail.com (Bird Fish)
Date: Thu, 14 Dec 2006 02:20:14 -0800
Subject: [R] Welcome to the "R-help" mailing list
In-Reply-To: <mailman.0.1166082289.4369.r-help@stat.math.ethz.ch>
References: <mailman.0.1166082289.4369.r-help@stat.math.ethz.ch>
Message-ID: <3f6db1e70612140220u1b2e9c20k80f376863fbbadb0@mail.gmail.com>

Dear Colleagues
I am a very new member here. If my question sounds silly to you, I apologize
in advance.

If I have a complicated function without an explicit expression. ( For
example, the price of  American put option p is a function of the current
stock price S and expected future volatility sigma, but there is no clean
elementary function that would map (S, sigma) to p, in fact, p has to be
calculated with a sophisticated procedure.

In such case, is there a function in R to find sigma, with S and p known?
Also, is there a way to find the derivative of p with regard to sigma?

Could anyone please shed some light on it? Your help will be highly
appreciated!!!

Best
Bird and Fish

From r.hankin at noc.soton.ac.uk  Thu Dec 14 11:31:35 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Thu, 14 Dec 2006 10:31:35 +0000
Subject: [R] Welcome to the "R-help" mailing list
In-Reply-To: <3f6db1e70612140220u1b2e9c20k80f376863fbbadb0@mail.gmail.com>
References: <mailman.0.1166082289.4369.r-help@stat.math.ethz.ch>
	<3f6db1e70612140220u1b2e9c20k80f376863fbbadb0@mail.gmail.com>
Message-ID: <735D9B32-7B1A-444A-9708-BBC791168DBD@soc.soton.ac.uk>

Hi

you could use interpolant() of the emulator package,
for a Gaussian process approach,
or approx() [or appproxfun()] if linear interpolation
is acceptable.

HTH


Robin



On 14 Dec 2006, at 10:20, Bird Fish wrote:

> Dear Colleagues
> I am a very new member here. If my question sounds silly to you, I  
> apologize
> in advance.
>
> If I have a complicated function without an explicit expression. ( For
> example, the price of  American put option p is a function of the  
> current
> stock price S and expected future volatility sigma, but there is no  
> clean
> elementary function that would map (S, sigma) to p, in fact, p has  
> to be
> calculated with a sophisticated procedure.
>
> In such case, is there a function in R to find sigma, with S and p  
> known?
> Also, is there a way to find the derivative of p with regard to sigma?
>
> Could anyone please shed some light on it? Your help will be highly
> appreciated!!!
>
> Best
> Bird and Fish
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From r.hankin at noc.soton.ac.uk  Thu Dec 14 11:32:14 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Thu, 14 Dec 2006 10:32:14 +0000
Subject: [R] two connected graphs
Message-ID: <FEDA5AC6-A9BC-4D3F-BAEA-F87FFF161279@soc.soton.ac.uk>

Hi

I have two datasets, A and B, consisting of two columns of numbers
representing x and y coordinates.

They have 10 and 6 rows respectively.

I want to plot two scattergraphs, one above the other.

The lower graph to contain A (10 points) and the upper
graph to contain B (six points).

The x-axes of the two graphs must line up.

I then want to draw straight lines that connect points
of  B to a particular point (or points)  of A.

How do I do this?


--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From Ralf.Finne at syh.fi  Thu Dec 14 11:50:44 2006
From: Ralf.Finne at syh.fi (Ralf Finne)
Date: Thu, 14 Dec 2006 12:50:44 +0200
Subject: [R] Contents of R-packages
Message-ID: <458148A4020000EE00002421@valhall.syh.fi>

Hi experts,
How do I see the contents of a package that looks
interesting?  Efter I have loded the package, is there
an command that gives me the contents or even better
a summary or introduction. 
Ralf Finne
SYH University of Applied Sciences, Finland


From dickgiesser at gmail.com  Thu Dec 14 11:56:26 2006
From: dickgiesser at gmail.com (Benjamin Dickgiesser)
Date: Thu, 14 Dec 2006 10:56:26 +0000
Subject: [R] Fit Frechet Distribution
Message-ID: <b75d67340612140256p48bb4c5cn713081bccb93bd26@mail.gmail.com>

Hi everyone,

is there a function to fit a frechet distribution? The only thing I
found is gev.fit from ismev which fits a generalized extreme value
distribution (if shape>1 => Frechet) . Is there a function to only fit
a frechet?

Thank you
Benjamin


From ccleland at optonline.net  Thu Dec 14 12:13:55 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 14 Dec 2006 06:13:55 -0500
Subject: [R] Contents of R-packages
In-Reply-To: <458148A4020000EE00002421@valhall.syh.fi>
References: <458148A4020000EE00002421@valhall.syh.fi>
Message-ID: <458131F3.1030506@optonline.net>

Ralf Finne wrote:
> Hi experts,
> How do I see the contents of a package that looks
> interesting?  Efter I have loded the package, is there
> an command that gives me the contents or even better
> a summary or introduction. 

> library(yags) # Load the package

> search() # Where is the package?
 [1] ".GlobalEnv"        "package:yags"
 [3] "package:nlme"      "package:car"
 [5] "package:stats"     "package:graphics"
 [7] "package:grDevices" "package:utils"
 [9] "package:datasets"  "package:methods"
[11] "Autoloads"         "package:base"

> ls(2) # What is in the package?
 [1] "ar1mat"           "csmat"
 [3] "mvnsamp"          "print.yagsResult"
 [5] "yags"             "yags.adeqReport"
 [7] "yags.control"     "yags.glmReport"
 [9] "yags.make.libu"   "yags.wcorReport"

> ?yags # Help for a particular function

  Also, follow the package links here for brief descriptions, reference
manuals, and vignettes:

http://cran.us.r-project.org/src/contrib/PACKAGES.html

> Ralf Finne
> SYH University of Applied Sciences, Finland
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From friedrich.leisch at stat.uni-muenchen.de  Thu Dec 14 12:16:31 2006
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Thu, 14 Dec 2006 12:16:31 +0100
Subject: [R] Sweave, Xfig, pdflatex and \setkeys
In-Reply-To: <1166009884.5698.5.camel@lesopriv3.epfl.ch>
References: <1165919873.4758.18.camel@lesopriv3.epfl.ch>
	<457EF377.2010805@utoronto.ca>
	<1166009884.5698.5.camel@lesopriv3.epfl.ch>
Message-ID: <17793.12943.959262.488722@lxh5.stat.uni-muenchen.de>

>>>>> On Wed, 13 Dec 2006 12:38:04 +0100,
>>>>> David Lindel?f (DL) wrote:

  > On Tue, 2006-12-12 at 13:22 -0500, Kevin E. Thorpe wrote:
  >> > Trouble is that Sweave defines (with \setkeys) the default width of
  >> > \includegraphics to be 0.8 times the \textwidth. The result is that the
  >> > graphic is scaled, but not the text.
  >> > 
  >> > I was looking for a way to temporarily undefine the default width of
  >> > included graphics, but without success. Does anyone know how to undo a
  >> > definition that has been set with \setkeys?

  >> If you knew what setting you needed, you could try
  >> 
  >> \setkeys{Gin}{width=whatever}
  >> 
  >> before your include, and set it back to the default afterward with
  >> 
  >> \setkeys{Gin}{width=0.8\textwidth}

  > Yes, but the trouble is that for arbitrary figures created with Xfig I
  > cannot know what the correct width is going to be. And I could not find
  > any help on how to undefine variables set with \setkeys.

Yes, I should document Sweave.sty much better ...

  \usepackage[nogin]{Sweave}

in your .Rnw file will do the trick, i.e., not set any Gin keys.

HTH,
Fritz

-- 
-----------------------------------------------------------------------
Prof. Dr. Friedrich Leisch 

Institut f?r Statistik                          Tel: (+49 89) 2180 3165
Ludwig-Maximilians-Universit?t                  Fax: (+49 89) 2180 5308
Ludwigstra?e 33
D-80539 M?nchen                 http://www.stat.uni-muenchen.de/~leisch


From gchappi at gmail.com  Thu Dec 14 12:24:47 2006
From: gchappi at gmail.com (Hans-Peter)
Date: Thu, 14 Dec 2006 12:24:47 +0100
Subject: [R] R_Code
In-Reply-To: <4580095A.6010508@stats.uwo.ca>
References: <20061212163929.178510@gmx.net> <4580095A.6010508@stats.uwo.ca>
Message-ID: <47fce0650612140324p214b3ab5jfdf42179913b7f53@mail.gmail.com>

2006/12/13, Duncan Murdoch <murdoch at stats.uwo.ca>:
[snipped]

Good description. Thank you!!

-- 
Regards,
Hans-Peter


From amsa36060 at yahoo.com  Thu Dec 14 12:26:26 2006
From: amsa36060 at yahoo.com (Amir Safari)
Date: Thu, 14 Dec 2006 03:26:26 -0800 (PST)
Subject: [R] lmacfPlot in fBasics
Message-ID: <482008.43751.qm@web60425.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061214/7a78b880/attachment.pl 

From rajesh.k at imperial.ac.uk  Thu Dec 14 12:29:56 2006
From: rajesh.k at imperial.ac.uk (Rajesh Krishnan)
Date: Thu, 14 Dec 2006 11:29:56 +0000
Subject: [R] Function to fit a STARIMA model
Message-ID: <458135B4.7000806@imperial.ac.uk>

Hi all,

I was wondering if there is a function available in any of the R add-on 
packages that could be used to fit a STARIMA (Phillip E. Pfeifer and 
Stuart Jay Deutsch. (1980). "A STARIMA Model-Building Procedure with 
Application to Description and Regional Forecasting," Transactions of 
the Institute of British Geographers 5(3), 330-349.) model?

Thanks,

Rajesh.


From Timothy.Mak at iop.kcl.ac.uk  Thu Dec 14 13:06:09 2006
From: Timothy.Mak at iop.kcl.ac.uk (Timothy.Mak at iop.kcl.ac.uk)
Date: Thu, 14 Dec 2006 12:06:09 +0000
Subject: [R] How do I create an object in the Global environment from a
	function
Message-ID: <OF3BBF1ACA.6F42DA61-ON80257244.0042305F-80257244.004374A7@iop.kcl.ac.uk>

Hi all, 

Say I have created an object b in my function 

myfunc <- function() b <- 34

How can I make b an object in the Global environment and not just in the 
environment of myfunc? 

Thanks, 

Tim


From RKrug at sun.ac.za  Thu Dec 14 13:42:15 2006
From: RKrug at sun.ac.za (Rainer M Krug)
Date: Thu, 14 Dec 2006 14:42:15 +0200
Subject: [R] How do I create an object in the Global environment from
 a	function
In-Reply-To: <OF3BBF1ACA.6F42DA61-ON80257244.0042305F-80257244.004374A7@iop.kcl.ac.uk>
References: <OF3BBF1ACA.6F42DA61-ON80257244.0042305F-80257244.004374A7@iop.kcl.ac.uk>
Message-ID: <458146A7.4000007@sun.ac.za>

Timothy.Mak at iop.kcl.ac.uk wrote:
> Hi all, 
> 
> Say I have created an object b in my function 
> 
> myfunc <- function() b <- 34

myfunc <- function() b <<- 34
                      ---------

Rainer

> 
> How can I make b an object in the Global environment and not just in the 
> environment of myfunc? 
> 
> Thanks, 
> 
> Tim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology and Entomology
University of Stellenbosch
Matieland 7602
South Africa

Tel:		+27 - (0)72 808 2975 (w)
Fax:		+27 - (0)86 516 2782
Fax:		+27 - (0)21 808 3304 (w)
Cell:		+27 - (0)83 9479 042

email:	RKrug at sun.ac.za
       	Rainer at krugs.de


From jenny197806 at yahoo.se  Thu Dec 14 13:54:27 2006
From: jenny197806 at yahoo.se (Jenny persson)
Date: Thu, 14 Dec 2006 13:54:27 +0100 (CET)
Subject: [R] question about for loop
Message-ID: <20061214125427.1766.qmail@web28007.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: inte tillg?nglig
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061214/3ac79a40/attachment.pl 

From jmb at mssl.ucl.ac.uk  Thu Dec 14 13:56:16 2006
From: jmb at mssl.ucl.ac.uk (Jenny Barnes)
Date: Thu, 14 Dec 2006 12:56:16 +0000 (GMT)
Subject: [R] loop is going to take 26 hours - needs to be quicker!
Message-ID: <200612141256.kBECuFUw019825@msslhb.mssl.ucl.ac.uk>

Dear R-help,

I have a loop, which is set to take about 26 hours to run at the rate it's going 
- this is ridiculous and I really need your help to find a more efficient way of 
loading up my array gpcc.array:

#My data is stored in a table format with all the data in one long column 
#running though every longitute, for every latitude, for every year. The 
#original data is sotred as gpcc.data2 where dim(gpcc.data2) = [476928,5] where 
#the 5th column is the data:

#make the array in the format I need [longitude,latitude,years]

gpcc.array <- array(NA, c(144,72,46)) 

n=0
for(k in 1:46){
for(j in 1:72){
for(i in 1:144){
n <- n+1
gpcc.array[i,j,k] <- gpcc.data2[n,5]
print(j)
}
}
}

So it runs through all the longs for every lat for every year - which is the 
order the data is running down the column in gpcc.data2 so n increses by 1 each 
time and each data point is pulled off....

It needs to be a lot quicker, I'd appreciate any ideas!

Many thanks for taking time to read this,

Jenny Barnes

~~~~~~~~~~~~~~~~~~
Jennifer Barnes
PhD student - long range drought prediction
Climate Extremes
Department of Space and Climate Physics
University College London
Holmbury St Mary, Dorking
Surrey
RH5 6NT
01483 204149
07916 139187
Web: http://climate.mssl.ucl.ac.uk


From ccleland at optonline.net  Thu Dec 14 14:08:55 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 14 Dec 2006 08:08:55 -0500
Subject: [R] Contents of R-packages
In-Reply-To: <458148A4020000EE00002421@valhall.syh.fi>
References: <458148A4020000EE00002421@valhall.syh.fi>
Message-ID: <45814CE7.4000002@optonline.net>

Ralf Finne wrote:
> Hi experts,
> How do I see the contents of a package that looks
> interesting?  Efter I have loded the package, is there
> an command that gives me the contents or even better
> a summary or introduction. 

  The following, which was mentioned to me off the list, also provides
useful summaries within R:

library(help="vcd") # Summaries of vcd package and functions

> Ralf Finne
> SYH University of Applied Sciences, Finland
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From RKrug at sun.ac.za  Thu Dec 14 14:24:13 2006
From: RKrug at sun.ac.za (Rainer M Krug)
Date: Thu, 14 Dec 2006 15:24:13 +0200
Subject: [R] loop is going to take 26 hours - needs to be quicker!
In-Reply-To: <200612141256.kBECuFUw019825@msslhb.mssl.ucl.ac.uk>
References: <200612141256.kBECuFUw019825@msslhb.mssl.ucl.ac.uk>
Message-ID: <4581507D.9030508@sun.ac.za>

Jenny Barnes wrote:
> Dear R-help,
> 
> I have a loop, which is set to take about 26 hours to run at the rate it's going 
> - this is ridiculous and I really need your help to find a more efficient way of 
> loading up my array gpcc.array:
> 
> #My data is stored in a table format with all the data in one long column 
> #running though every longitute, for every latitude, for every year. The 
> #original data is sotred as gpcc.data2 where dim(gpcc.data2) = [476928,5] where 
> #the 5th column is the data:
> 
> #make the array in the format I need [longitude,latitude,years]
> 
> gpcc.array <- array(NA, c(144,72,46)) 
> 
> n=0
> for(k in 1:46){
> for(j in 1:72){
> for(i in 1:144){
> n <- n+1
> gpcc.array[i,j,k] <- gpcc.data2[n,5]
> print(j)
> }
> }
> }

I don't know if it is faster - but adding three columns to qpcc.data, 
one for longitude, one for lattitude and one for year (using rep() as 
they are in sequence) and the using reshape() might be faster?


> 
> So it runs through all the longs for every lat for every year - which is the 
> order the data is running down the column in gpcc.data2 so n increses by 1 each 
> time and each data point is pulled off....
> 
> It needs to be a lot quicker, I'd appreciate any ideas!
> 
> Many thanks for taking time to read this,
> 
> Jenny Barnes
> 
> ~~~~~~~~~~~~~~~~~~
> Jennifer Barnes
> PhD student - long range drought prediction
> Climate Extremes
> Department of Space and Climate Physics
> University College London
> Holmbury St Mary, Dorking
> Surrey
> RH5 6NT
> 01483 204149
> 07916 139187
> Web: http://climate.mssl.ucl.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology and Entomology
University of Stellenbosch
Matieland 7602
South Africa

Tel:		+27 - (0)72 808 2975 (w)
Fax:		+27 - (0)86 516 2782
Fax:		+27 - (0)21 808 3304 (w)
Cell:		+27 - (0)83 9479 042

email:	RKrug at sun.ac.za
       	Rainer at krugs.de


From murdoch at stats.uwo.ca  Thu Dec 14 14:17:24 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 14 Dec 2006 08:17:24 -0500
Subject: [R] loop is going to take 26 hours - needs to be quicker!
In-Reply-To: <200612141256.kBECuFUw019825@msslhb.mssl.ucl.ac.uk>
References: <200612141256.kBECuFUw019825@msslhb.mssl.ucl.ac.uk>
Message-ID: <45814EE4.8040508@stats.uwo.ca>

On 12/14/2006 7:56 AM, Jenny Barnes wrote:
> Dear R-help,
> 
> I have a loop, which is set to take about 26 hours to run at the rate it's going 
> - this is ridiculous and I really need your help to find a more efficient way of 
> loading up my array gpcc.array:
> 
> #My data is stored in a table format with all the data in one long column 
> #running though every longitute, for every latitude, for every year. The 
> #original data is sotred as gpcc.data2 where dim(gpcc.data2) = [476928,5] where 
> #the 5th column is the data:
> 
> #make the array in the format I need [longitude,latitude,years]
> 
> gpcc.array <- array(NA, c(144,72,46)) 
> 
> n=0
> for(k in 1:46){
> for(j in 1:72){
> for(i in 1:144){
> n <- n+1
> gpcc.array[i,j,k] <- gpcc.data2[n,5]
> print(j)
> }
> }
> }
> 
> So it runs through all the longs for every lat for every year - which is the 
> order the data is running down the column in gpcc.data2 so n increses by 1 each 
> time and each data point is pulled off....
> 
> It needs to be a lot quicker, I'd appreciate any ideas!

I think the loop above is equivalent to

gpcc.array <- array(gpcc.data2[,5], c(144, 72, 46))

which would certainly be a lot quicker.  You should check that the 
values are loaded in the right order (probably on a smaller example!). 
If not, you should change the order of indices when you create the 
array, and use the aperm() function to get them the way you want afterwards.

Duncan Murdoch


From petr.pikal at precheza.cz  Thu Dec 14 14:26:40 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 14 Dec 2006 14:26:40 +0100
Subject: [R] question about for loop
In-Reply-To: <20061214125427.1766.qmail@web28007.mail.ukl.yahoo.com>
Message-ID: <45815F20.27933.167603E@localhost>

Hi

well, we do not know how is your data organised so it is only a 
guess.

On 14 Dec 2006 at 13:54, Jenny persson wrote:

Date sent:      	Thu, 14 Dec 2006 13:54:27 +0100 (CET)
From:           	Jenny persson <jenny197806 at yahoo.se>
To:             	r-help at stat.math.ethz.ch
Subject:        	[R] question about for loop

> 
>   Dear R-experts,
> 
>   I have a dataset of 4 patients and each patient has many records at
>   four different time points. I have done 4 different qqnorm plots on
>   the same graph where each plot represents the records of one patient
>   at each time point. I would like to do the same graph for the
>   remaining patiens, but instead of repeating the below procedure
>   three more times I would like to have a for loop so when I run the
>   loop I would get four graphs of the four patients at the same time,
>   where each graph has 4 different qqnorm plots representing the data
>   at  four time points for each patient. I tried to do the loop but
>   couldn't make it work. 
> 
>   below is the code used to the graph for one patient. sli-4 - sli_7
>   contain records at four time points. dat=dataset, y=records,
>   Slide=time point
> 
> 

based on assumption dat has a column pat.no (numeric)

for (i in dat$pat.no)

{
dat.p<-dat[i,]

>   ### Patient 200004

# here change all dat to dat.p
> 
>   sli_4=dat$y[dat$Slide==4 & dat$Control==0]
>   sli_5=dat$y[dat$Slide==5 & dat$Control==0]
>   sli_6=dat$y[dat$Slide==6 & dat$Control==0]
>   sli_7=dat$y[dat$Slide==7 & dat$Control==0]
> 
>   ### qq-plot of patient 200004
>   q_sli4<-qqnorm(sli_4,plot.it=FALSE)
>   q_sli5<-qqnorm(sli_5,plot.it=FALSE)
>   q_sli6<-qqnorm(sli_6,plot.it=FALSE)
>   q_sli7<-qqnorm(sli_7,plot.it=FALSE)
> 
>   plot(range(q_sli4,q_sli5,q_sli6,q_sli7),range(q_sli4,q_sli5,q_sli6,q
>   _sli7),type="n", xlab = "Theoretical Quantiles",col.main="blue",
>   main = "Normal Q-Q Plot of index for patient 200004",ylab = "Sample

# here you shall consult expression or bquote help page

>   Quantiles") points(q_sli4,col=4,pch=0,cex=1)
>   points(q_sli5,col=3,pch=1,cex=1) points(q_sli6,col=2,pch=2,cex=1)
>   points(q_sli7,col=1,pch=3,cex=1) legend("topleft",c("Day 0", "56
>   days","112 days", "252 days"),col=c(4,3,2,1),
>   text.col=c(4,3,2,1),pch=c(0,1,2,3),bg="bisque") abline(0,0)

}

# here is the end of your plotting

However you need either to save your plots to some files (see pdf, 
png) or to tell to your progrem to wait with further plotting until 
you look at your plot.

HTH
Petr

> 
> 
>   Thanks alot for your help,
> 
>   All the bests,
>   Jenny
> 
> 
> ---------------------------------
> 
> 
> 
> 
> ---------------------------------
> 
> 
>  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

Petr Pikal
petr.pikal at precheza.cz


From Serguei.Kaniovski at wifo.ac.at  Thu Dec 14 14:29:25 2006
From: Serguei.Kaniovski at wifo.ac.at (Serguei Kaniovski)
Date: Thu, 14 Dec 2006 14:29:25 +0100
Subject: [R] Delete all dimnames
Message-ID: <OF567A4C37.25E9099D-ONC1257244.0049B394-C1257244.004A1A4B@wsr.ac.at>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061214/0742f7ba/attachment.pl 

From j.van_den_hoff at fz-rossendorf.de  Thu Dec 14 14:30:01 2006
From: j.van_den_hoff at fz-rossendorf.de (Joerg van den Hoff)
Date: Thu, 14 Dec 2006 14:30:01 +0100
Subject: [R] sapply problem
Message-ID: <458151D9.5080009@fz-rossendorf.de>

I have encountered the following problem: I need to extract from
a list of lists equally named compenents who happen to be 'one row'
data frames. a trivial example would be:

a <- list(list(
df = data.frame(A = 1, B = 2, C = 3)), list(df = data.frame(A = 4,B = 5,C = 6)))

I want the extracted compenents to fill up a matrix or data frame row by row.
the obvious thing to do seems:

b <- sapply(a, "[[", "df")
b <- t(b)

now `b' looks all right:

b
class(b)

but it turns out that all elements in this matrix are one element lists:

class(b[1,1])

which prevents any further standard processing of `b' (like `colMeans', e.g.)

question 1: is their a straightforward way to enforce that `b' contains
simple numbers as elements right from the start (instead of something like
apply(b, 1:2, "class<-", "numeric") afterwards)?

question 2: should not sapply do this further 'simplification' anyway in a situation
like this (matrix elements turn out to be one-element lists)?

regards

joerg


From jmb at mssl.ucl.ac.uk  Thu Dec 14 14:28:03 2006
From: jmb at mssl.ucl.ac.uk (Jenny Barnes)
Date: Thu, 14 Dec 2006 13:28:03 +0000 (GMT)
Subject: [R] loop is going to take 26 hours - needs to be quicker!
Message-ID: <200612141328.kBEDS3xh019836@msslhb.mssl.ucl.ac.uk>

Dear R-help,

I forgot to mention that I need the array in that format because I am going to 
do the same thing for another dataset of precipitation (ncep.data2) so they are 
both arrays of dimensions [144,72,46] so that I can correlate them globally and 
plot a visual image of the global correlations between the 2 datasets.... One of 
the datasets has a land mask applied to it already so it should be clear to see 
the land and pick ot the locations (i.e.over Europe) where there is strongest 
and weakest correlation.....that is the ultimate goal.

Following Rainer's response I should also point out that the columns in 
gpcc.data2 (with dimensions dim(gpcc.data2) = [476928,5]) are:

[,1]="Year", [,2]="month" (which is just january so always 1), [,3]="latitude", 
[,4]="longitude" and [,5]="data". All I want in the gpcc.array is the data not 
the longitudes and latitude values...hope that helps clear it up a bit!

I look forward to hearing any more ideas, thanks again for your time in reading 
this,

Jenny Barnes

>
>Jenny Barnes wrote:
>> Dear R-help,
>> 
>> I have a loop, which is set to take about 26 hours to run at the rate it's 
going 
>> - this is ridiculous and I really need your help to find a more efficient way 
of 
>> loading up my array gpcc.array:
>> 
>> #My data is stored in a table format with all the data in one long column 
>> #running though every longitute, for every latitude, for every year. The 
>> #original data is sotred as gpcc.data2 where dim(gpcc.data2) = [476928,5] 
where 
>> #the 5th column is the data:
>> 
>> #make the array in the format I need [longitude,latitude,years]
>> 
>> gpcc.array <- array(NA, c(144,72,46)) 
>> 
>> n=0
>> for(k in 1:46){
>> for(j in 1:72){
>> for(i in 1:144){
>> n <- n+1
>> gpcc.array[i,j,k] <- gpcc.data2[n,5]
>> print(j)
>> }
>> }
>> }
>
>I don't know if it is faster - but adding three columns to qpcc.data, 
>one for longitude, one for lattitude and one for year (using rep() as 
>they are in sequence) and the using reshape() might be faster?
>
>
>> 
>> So it runs through all the longs for every lat for every year - which is the 
>> order the data is running down the column in gpcc.data2 so n increses by 1 
each 
>> time and each data point is pulled off....
>> 
>> It needs to be a lot quicker, I'd appreciate any ideas!
>> 
>> Many thanks for taking time to read this,
>> 
>> Jenny Barnes
>> 
>> ~~~~~~~~~~~~~~~~~~
>> Jennifer Barnes
>> PhD student - long range drought prediction
>> Climate Extremes
>> Department of Space and Climate Physics
>> University College London
>> Holmbury St Mary, Dorking
>> Surrey
>> RH5 6NT
>> 01483 204149
>> 07916 139187
>> Web: http://climate.mssl.ucl.ac.uk
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>-- 
>Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
>Biology (UCT)
>
>Department of Conservation Ecology and Entomology
>University of Stellenbosch
>Matieland 7602
>South Africa
>
>Tel:		+27 - (0)72 808 2975 (w)
>Fax:		+27 - (0)86 516 2782
>Fax:		+27 - (0)21 808 3304 (w)
>Cell:		+27 - (0)83 9479 042
>
>email:	RKrug at sun.ac.za
>       	Rainer at krugs.de

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Jennifer Barnes
PhD student - long range drought prediction
Climate Extremes
Department of Space and Climate Physics
University College London
Holmbury St Mary, Dorking
Surrey
RH5 6NT
01483 204149
07916 139187
Web: http://climate.mssl.ucl.ac.uk


From mothsailor at googlemail.com  Thu Dec 14 14:33:42 2006
From: mothsailor at googlemail.com (David Barron)
Date: Thu, 14 Dec 2006 13:33:42 +0000
Subject: [R] loop is going to take 26 hours - needs to be quicker!
In-Reply-To: <4581507D.9030508@sun.ac.za>
References: <200612141256.kBECuFUw019825@msslhb.mssl.ucl.ac.uk>
	<4581507D.9030508@sun.ac.za>
Message-ID: <815b70590612140533m1e6a3a96ka1bfc91ee25c05b6@mail.gmail.com>

What about

gpcc.array <- array(gpcc.data2[,5], dim=c(144,72,46))

On 14/12/06, Rainer M Krug <RKrug at sun.ac.za> wrote:
> Jenny Barnes wrote:
> > Dear R-help,
> >
> > I have a loop, which is set to take about 26 hours to run at the rate it's going
> > - this is ridiculous and I really need your help to find a more efficient way of
> > loading up my array gpcc.array:
> >
> > #My data is stored in a table format with all the data in one long column
> > #running though every longitute, for every latitude, for every year. The
> > #original data is sotred as gpcc.data2 where dim(gpcc.data2) = [476928,5] where
> > #the 5th column is the data:
> >
> > #make the array in the format I need [longitude,latitude,years]
> >
> > gpcc.array <- array(NA, c(144,72,46))
> >
> > n=0
> > for(k in 1:46){
> > for(j in 1:72){
> > for(i in 1:144){
> > n <- n+1
> > gpcc.array[i,j,k] <- gpcc.data2[n,5]
> > print(j)
> > }
> > }
> > }
>
> I don't know if it is faster - but adding three columns to qpcc.data,
> one for longitude, one for lattitude and one for year (using rep() as
> they are in sequence) and the using reshape() might be faster?
>
>
> >
> > So it runs through all the longs for every lat for every year - which is the
> > order the data is running down the column in gpcc.data2 so n increses by 1 each
> > time and each data point is pulled off....
> >
> > It needs to be a lot quicker, I'd appreciate any ideas!
> >
> > Many thanks for taking time to read this,
> >
> > Jenny Barnes
> >
> > ~~~~~~~~~~~~~~~~~~
> > Jennifer Barnes
> > PhD student - long range drought prediction
> > Climate Extremes
> > Department of Space and Climate Physics
> > University College London
> > Holmbury St Mary, Dorking
> > Surrey
> > RH5 6NT
> > 01483 204149
> > 07916 139187
> > Web: http://climate.mssl.ucl.ac.uk
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
> --
> Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
> Biology (UCT)
>
> Department of Conservation Ecology and Entomology
> University of Stellenbosch
> Matieland 7602
> South Africa
>
> Tel:            +27 - (0)72 808 2975 (w)
> Fax:            +27 - (0)86 516 2782
> Fax:            +27 - (0)21 808 3304 (w)
> Cell:           +27 - (0)83 9479 042
>
> email:  RKrug at sun.ac.za
>         Rainer at krugs.de
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP


From marc_schwartz at comcast.net  Thu Dec 14 14:33:41 2006
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 14 Dec 2006 07:33:41 -0600
Subject: [R] loop is going to take 26 hours - needs to be quicker!
In-Reply-To: <200612141256.kBECuFUw019825@msslhb.mssl.ucl.ac.uk>
References: <200612141256.kBECuFUw019825@msslhb.mssl.ucl.ac.uk>
Message-ID: <1166103222.10089.9.camel@localhost.localdomain>

On Thu, 2006-12-14 at 12:56 +0000, Jenny Barnes wrote:
> Dear R-help,
> 
> I have a loop, which is set to take about 26 hours to run at the rate it's going 
> - this is ridiculous and I really need your help to find a more efficient way of 
> loading up my array gpcc.array:
> 
> #My data is stored in a table format with all the data in one long column 
> #running though every longitute, for every latitude, for every year. The 
> #original data is sotred as gpcc.data2 where dim(gpcc.data2) = [476928,5] where 
> #the 5th column is the data:
> 
> #make the array in the format I need [longitude,latitude,years]
> 
> gpcc.array <- array(NA, c(144,72,46)) 
> 
> n=0
> for(k in 1:46){
> for(j in 1:72){
> for(i in 1:144){
> n <- n+1
> gpcc.array[i,j,k] <- gpcc.data2[n,5]
> print(j)
> }
> }
> }
> 
> So it runs through all the longs for every lat for every year - which is the 
> order the data is running down the column in gpcc.data2 so n increses by 1 each 
> time and each data point is pulled off....
> 
> It needs to be a lot quicker, I'd appreciate any ideas!
> 
> Many thanks for taking time to read this,
> 
> Jenny Barnes

Take a "whole object" approach to this problem. You are also wasting a
lot of time by printing the values of 'j' in the loop.


> gpcc.data2 <- matrix(rnorm(476928 * 5), ncol = 5)

> dim(gpcc.data2)
[1] 476928      5
> str(gpcc.data2)
 num [1:476928, 1:5]  2.7385 -0.0438 -0.1084  0.8768 -1.0024 ...


> system.time(gpcc.array <- array(gpcc.data2[, 5], 
                                  dim = c(144, 72, 46)))
[1] 0.024 0.026 0.078 0.000 0.000

You should verify the order of the values and adjust the indices
accordingly, if the above results in an out of order array.

HTH,

Marc Schwartz


From RKrug at sun.ac.za  Thu Dec 14 14:46:07 2006
From: RKrug at sun.ac.za (Rainer M Krug)
Date: Thu, 14 Dec 2006 15:46:07 +0200
Subject: [R] loop is going to take 26 hours - needs to be quicker!
In-Reply-To: <815b70590612140533m1e6a3a96ka1bfc91ee25c05b6@mail.gmail.com>
References: <200612141256.kBECuFUw019825@msslhb.mssl.ucl.ac.uk>	
	<4581507D.9030508@sun.ac.za>
	<815b70590612140533m1e6a3a96ka1bfc91ee25c05b6@mail.gmail.com>
Message-ID: <4581559F.10909@sun.ac.za>

David Barron wrote:
> What about
> 
> gpcc.array <- array(gpcc.data2[,5], dim=c(144,72,46))

I guess this will be slightly faster then my suggestion :-) ?

> 
> On 14/12/06, Rainer M Krug <RKrug at sun.ac.za> wrote:
>> Jenny Barnes wrote:
>> > Dear R-help,
>> >
>> > I have a loop, which is set to take about 26 hours to run at the 
>> rate it's going
>> > - this is ridiculous and I really need your help to find a more 
>> efficient way of
>> > loading up my array gpcc.array:
>> >
>> > #My data is stored in a table format with all the data in one long 
>> column
>> > #running though every longitute, for every latitude, for every year. 
>> The
>> > #original data is sotred as gpcc.data2 where dim(gpcc.data2) = 
>> [476928,5] where
>> > #the 5th column is the data:
>> >
>> > #make the array in the format I need [longitude,latitude,years]
>> >
>> > gpcc.array <- array(NA, c(144,72,46))
>> >
>> > n=0
>> > for(k in 1:46){
>> > for(j in 1:72){
>> > for(i in 1:144){
>> > n <- n+1
>> > gpcc.array[i,j,k] <- gpcc.data2[n,5]
>> > print(j)
>> > }
>> > }
>> > }
>>
>> I don't know if it is faster - but adding three columns to qpcc.data,
>> one for longitude, one for lattitude and one for year (using rep() as
>> they are in sequence) and the using reshape() might be faster?
>>
>>
>> >
>> > So it runs through all the longs for every lat for every year - 
>> which is the
>> > order the data is running down the column in gpcc.data2 so n 
>> increses by 1 each
>> > time and each data point is pulled off....
>> >
>> > It needs to be a lot quicker, I'd appreciate any ideas!
>> >
>> > Many thanks for taking time to read this,
>> >
>> > Jenny Barnes
>> >


-- 
Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Department of Conservation Ecology and Entomology
University of Stellenbosch
Matieland 7602
South Africa

Tel:		+27 - (0)72 808 2975 (w)
Fax:		+27 - (0)86 516 2782
Fax:		+27 - (0)21 808 3304 (w)
Cell:		+27 - (0)83 9479 042

email:	RKrug at sun.ac.za
       	Rainer at krugs.de


From skiadas at hanover.edu  Thu Dec 14 14:40:01 2006
From: skiadas at hanover.edu (Charilaos Skiadas)
Date: Thu, 14 Dec 2006 08:40:01 -0500
Subject: [R] How do I create an object in the Global environment from
	a	function
In-Reply-To: <458146A7.4000007@sun.ac.za>
References: <OF3BBF1ACA.6F42DA61-ON80257244.0042305F-80257244.004374A7@iop.kcl.ac.uk>
	<458146A7.4000007@sun.ac.za>
Message-ID: <4E7A9B62-053E-4331-8B31-C526390EB4BA@hanover.edu>

On Dec 14, 2006, at 7:42 AM, Rainer M Krug wrote:

> myfunc <- function() b <<- 34

I would add a warning here. It is generally not a good idea for a  
function to have side-effects. In this case, if there is a globally  
defined value for b already, it will be overwritten. If this function  
is in a package say, and someone else uses it, or you use it after a  
very long time and have forgotten its internals and the fact that  
it's messing with the Global Environment, this might lead to some  
bugs that are really hard to spot.

> Rainer

Haris


From petr.pikal at precheza.cz  Thu Dec 14 14:39:53 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 14 Dec 2006 14:39:53 +0100
Subject: [R] loop is going to take 26 hours - needs to be quicker!
In-Reply-To: <200612141256.kBECuFUw019825@msslhb.mssl.ucl.ac.uk>
Message-ID: <45816239.5342.1737A05@localhost>

Hi

if I understand correctly, you have one column you need to reformat 
into array. Array is basically a vector with dim attribute. Therefore 
if your data were properly sorted you could use just

gpcc.array <- array(gpccnata2[,5], c(144,72,46))

to reformat column 5 of your data frame. But you shall be 100% sure 
you really want an array and not any other data form.

HTH
Petr
 


On 14 Dec 2006 at 12:56, Jenny Barnes wrote:

Date sent:      	Thu, 14 Dec 2006 12:56:16 +0000 (GMT)
From:           	Jenny Barnes <jmb at mssl.ucl.ac.uk>
To:             	r-help at stat.math.ethz.ch
Subject:        	[R] loop is going to take 26 hours - needs to be quicker!
Send reply to:  	Jenny Barnes <jmb at mssl.ucl.ac.uk>
	<mailto:r-help-request at stat.math.ethz.ch?subject=unsubscribe>
	<mailto:r-help-request at stat.math.ethz.ch?subject=subscribe>

> Dear R-help,
> 
> I have a loop, which is set to take about 26 hours to run at the rate
> it's going - this is ridiculous and I really need your help to find a
> more efficient way of loading up my array gpcc.array:
> 
> #My data is stored in a table format with all the data in one long
> #column running though every longitute, for every latitude, for every
> #year. The original data is sotred as gpcc.data2 where dim(gpcc.data2)
> #= [476928,5] where the 5th column is the data:
> 
> #make the array in the format I need [longitude,latitude,years]
> 
> gpcc.array <- array(NA, c(144,72,46)) 
> 
> n=0
> for(k in 1:46){
> for(j in 1:72){
> for(i in 1:144){
> n <- n+1
> gpcc.array[i,j,k] <- gpcc.data2[n,5]
> print(j)
> }
> }
> }
> 
> So it runs through all the longs for every lat for every year - which
> is the order the data is running down the column in gpcc.data2 so n
> increses by 1 each time and each data point is pulled off....
> 
> It needs to be a lot quicker, I'd appreciate any ideas!
> 
> Many thanks for taking time to read this,
> 
> Jenny Barnes
> 
> ~~~~~~~~~~~~~~~~~~
> Jennifer Barnes
> PhD student - long range drought prediction
> Climate Extremes
> Department of Space and Climate Physics
> University College London
> Holmbury St Mary, Dorking
> Surrey
> RH5 6NT
> 01483 204149
> 07916 139187
> Web: http://climate.mssl.ucl.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

Petr Pikal
petr.pikal at precheza.cz


From prati at icmc.usp.br  Thu Dec 14 14:41:34 2006
From: prati at icmc.usp.br (Ronaldo Prati)
Date: Thu, 14 Dec 2006 11:41:34 -0200
Subject: [R] Model formula question
Message-ID: <b2f853f40612140541s3a6c1637g68d37c5c836aec6f@mail.gmail.com>

Hi all,

I'm not familiar with R programming and I'm trying to reproduce a
result from a paper.

Basically, I have a dataset which I would like to model in terms of
successive increments, i.e. (y denote empirical values of y)

y_1 = y1,

y_2 = y1 + delta1,

y_3 = y1 + delta1 + delta2.

...

y_m = y1 + sum_2^m delta j

where delta_j donote successive increments in the y-values, i.e.

delta j = y_j - y_(j-1).

In order to estimate y-values, I'm assuming that delta j is
approximately equal to kj**u, such that my regression model should be
something like this:

^y_1 = a1

^y_2 = a1 + k2**u

^y_3 = a1 + k2**u + k3**u

...

^y_m = a1 + k2**u + k3**u + ... + km**u

or, generically

^yi = a1 + k * sum_j=2^i  j**u

and I need to fit a non-linear least-squares regression model to find
the tripplet a1,k,u. I had a look to the gnm package, but I don't have
the lesser idea how to formulate this problem to use this package. Can
someone help me with that?

cheers,

Ronaldo


From jmb at mssl.ucl.ac.uk  Thu Dec 14 14:41:23 2006
From: jmb at mssl.ucl.ac.uk (Jenny Barnes)
Date: Thu, 14 Dec 2006 13:41:23 +0000 (GMT)
Subject: [R] loop is going to take 26 hours - needs to be quicker!
Message-ID: <200612141341.kBEDfN2l019839@msslhb.mssl.ucl.ac.uk>

Dear R-help,

Thank you for the responses off everyone- you'll be please to hear Duncan that 
using: 
> gpcc.array <- array(gpcc.data2[,5], c(144, 72, 46))
was spot-on, worked like a dream. The data is in the correct places as I checked 
with the text file. It took literally 2 seconds - quite an improvement time on 
the predicted 26 hours :-)

I really really appreciate your help, you're all very very kind people.

Merry Christmas,

Jenny Barnes



>Date: Thu, 14 Dec 2006 08:17:24 -0500
>From: Duncan Murdoch <murdoch at stats.uwo.ca>
>User-Agent: Thunderbird 1.5.0.8 (Windows/20061025)
>MIME-Version: 1.0
>To: Jenny Barnes <jmb at mssl.ucl.ac.uk>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] loop is going to take 26 hours - needs to be quicker!
>Content-Transfer-Encoding: 7bit
>X-MSSL-MailScanner-Information: Please contact the ISP for more information
>X-MSSL-MailScanner: No virus found
>X-MSSL-MailScanner-SpamCheck: not spam, SpamAssassin (score=-4.9, required 5, 
BAYES_00 -4.90)
>
>On 12/14/2006 7:56 AM, Jenny Barnes wrote:
>> Dear R-help,
>> 
>> I have a loop, which is set to take about 26 hours to run at the rate it's 
going 
>> - this is ridiculous and I really need your help to find a more efficient way 
of 
>> loading up my array gpcc.array:
>> 
>> #My data is stored in a table format with all the data in one long column 
>> #running though every longitute, for every latitude, for every year. The 
>> #original data is sotred as gpcc.data2 where dim(gpcc.data2) = [476928,5] 
where 
>> #the 5th column is the data:
>> 
>> #make the array in the format I need [longitude,latitude,years]
>> 
>> gpcc.array <- array(NA, c(144,72,46)) 
>> 
>> n=0
>> for(k in 1:46){
>> for(j in 1:72){
>> for(i in 1:144){
>> n <- n+1
>> gpcc.array[i,j,k] <- gpcc.data2[n,5]
>> print(j)
>> }
>> }
>> }
>> 
>> So it runs through all the longs for every lat for every year - which is the 
>> order the data is running down the column in gpcc.data2 so n increses by 1 
each 
>> time and each data point is pulled off....
>> 
>> It needs to be a lot quicker, I'd appreciate any ideas!
>
>I think the loop above is equivalent to
>
>gpcc.array <- array(gpcc.data2[,5], c(144, 72, 46))
>
>which would certainly be a lot quicker.  You should check that the 
>values are loaded in the right order (probably on a smaller example!). 
>If not, you should change the order of indices when you create the 
>array, and use the aperm() function to get them the way you want afterwards.
>
>Duncan Murdoch

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Jennifer Barnes
PhD student - long range drought prediction
Climate Extremes
Department of Space and Climate Physics
University College London
Holmbury St Mary, Dorking
Surrey
RH5 6NT
01483 204149
07916 139187
Web: http://climate.mssl.ucl.ac.uk


From petr.pikal at precheza.cz  Thu Dec 14 14:44:58 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 14 Dec 2006 14:44:58 +0100
Subject: [R] Delete all dimnames
In-Reply-To: <OF567A4C37.25E9099D-ONC1257244.0049B394-C1257244.004A1A4B@wsr.ac.at>
Message-ID: <4581636A.8805.178214E@localhost>

Hi

try to read ?matrix help page. It leads you to dimnames and

dimmnames($amat)<-NULL

strips dimnames from matrix.

HTH
Petr




On 14 Dec 2006 at 14:29, Serguei Kaniovski wrote:

To:             	r-help at stat.math.ethz.ch
From:           	Serguei Kaniovski <Serguei.Kaniovski at wifo.ac.at>
Date sent:      	Thu, 14 Dec 2006 14:29:25 +0100
Subject:        	[R] Delete all dimnames

> Hello, how can I get rid of all dimnames so that:
> $amat
>     Var3 Var2 Var1 
> 8 1    1    1    1 1 1 1 1 0 0 0 0 0 0 0
> 7 1    1    1    0 1 0 0 0 1 0 0 0 0 0 0
> 6 1    1    0    1 0 1 0 0 0 1 0 0 0 0 0
> 5 1    1    0    0 0 0 0 0 0 0 1 0 0 0 0
> 4 1    0    1    1 0 0 1 0 0 0 0 1 0 0 0
> 3 1    0    1    0 0 0 0 0 0 0 0 0 1 0 0
> 2 1    0    0    1 0 0 0 0 0 0 0 0 0 1 0
> 1 1    0    0    0 0 0 0 0 0 0 0 0 0 0 1
> 
> is displayed with [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] in rows, and
> the same in columns. The matrix was generated using "apply"
> 
> Serguei
> ___________________________________________________________________
> 
> Austrian Institute of Economic Research (WIFO)
> 
> Name: Serguei Kaniovski         P.O.Box 91
> Tel.: +43-1-7982601-231                 Arsenal Objekt 20
> Fax: +43-1-7989386                      1103 Vienna, Austria
> Mail: Serguei.Kaniovski at wifo.ac.at      A-1030 Wien
> 
> http://www.wifo.ac.at/Serguei.Kaniovski
> 
>  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

Petr Pikal
petr.pikal at precheza.cz


From rcprati at gmail.com  Thu Dec 14 14:59:32 2006
From: rcprati at gmail.com (Ronaldo Prati)
Date: Thu, 14 Dec 2006 11:59:32 -0200
Subject: [R] Model formula question
In-Reply-To: <b2f853f40612140541s3a6c1637g68d37c5c836aec6f@mail.gmail.com>
References: <b2f853f40612140541s3a6c1637g68d37c5c836aec6f@mail.gmail.com>
Message-ID: <b2f853f40612140559q59449720y80aa5c47766b4cca@mail.gmail.com>

Hi all,

I'm not familiar with R programming and I'm trying to reproduce a
result from a paper.

Basically, I have a dataset which I would like to model in terms of
successive increments, i.e. (y denote empirical values of y)

y_1 = y1,

y_2 = y1 + delta1,

y_3 = y1 + delta1 + delta2.

...

y_m = y1 + sum_2^m delta j

where delta_j donote successive increments in the y-values, i.e.

delta j = y_j - y_(j-1).

In order to estimate y-values, I'm assuming that delta j is
approximately equal to kj**u, such that my regression model should be
something like this:

^y_1 = a1

^y_2 = a1 + k2**u

^y_3 = a1 + k2**u + k3**u

...

^y_m = a1 + k2**u + k3**u + ... + km**u

or, generically

^yi = a1 + k * sum_j=2^i  j**u

and I need to fit a non-linear least-squares regression model to find
the tripplet a1,k,u. I had a look to the gnm package, but I don't have
the lesser idea how to formulate this problem to use this package. Can
someone help me with that?

cheers,

Ronaldo


From robert-mcfadden at o2.pl  Thu Dec 14 15:01:16 2006
From: robert-mcfadden at o2.pl (robert-mcfadden at o2.pl)
Date: Thu, 14 Dec 2006 15:01:16 +0100
Subject: [R] =?utf-8?q?matrix_-_change_values?=
Message-ID: <59b64ad5.5ea32544.4581592c.c64bf@o2.pl>

Dear R Users,
I have a matrix A, and I want to change every value of this matrix if these values are greater than an assuming value. For a vector it is simple, e.g. a<-c(1:10); a[a>5]<-0. 
Of course, I can change matrix to vector, assign a value then change vector to matrix. But does there exist simpler way?
Any suggestion are appreciate.
Rob


From j.van_den_hoff at fz-rossendorf.de  Thu Dec 14 15:05:22 2006
From: j.van_den_hoff at fz-rossendorf.de (Joerg van den Hoff)
Date: Thu, 14 Dec 2006 15:05:22 +0100
Subject: [R] Delete all dimnames
In-Reply-To: <OF567A4C37.25E9099D-ONC1257244.0049B394-C1257244.004A1A4B@wsr.ac.at>
References: <OF567A4C37.25E9099D-ONC1257244.0049B394-C1257244.004A1A4B@wsr.ac.at>
Message-ID: <45815A22.4070501@fz-rossendorf.de>

Serguei Kaniovski wrote:
> Hello, how can I get rid of all dimnames so that:
> $amat
>     Var3 Var2 Var1 
> 8 1    1    1    1 1 1 1 1 0 0 0 0 0 0 0
> 7 1    1    1    0 1 0 0 0 1 0 0 0 0 0 0
> 6 1    1    0    1 0 1 0 0 0 1 0 0 0 0 0
> 5 1    1    0    0 0 0 0 0 0 0 1 0 0 0 0
> 4 1    0    1    1 0 0 1 0 0 0 0 1 0 0 0
> 3 1    0    1    0 0 0 0 0 0 0 0 0 1 0 0
> 2 1    0    0    1 0 0 0 0 0 0 0 0 0 1 0
> 1 1    0    0    0 0 0 0 0 0 0 0 0 0 0 1
> 
> is displayed with [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] in rows, and the 
> same in columns. The matrix was generated using "apply"
> 
>


dimnames(mat) <- NULL


From balvenie at in29.com  Thu Dec 14 15:03:52 2006
From: balvenie at in29.com (The Balvenie)
Date: Thu, 14 Dec 2006 15:03:52 +0100
Subject: [R] The Balvenie : Remportez trois whisky d'exception
Message-ID: <86bb6137b7fdfe0736effbac63cbad88@localhost.localdomain>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061214/80c6bc46/attachment.pl 

From sarah.goslee at gmail.com  Thu Dec 14 15:17:06 2006
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 14 Dec 2006 09:17:06 -0500
Subject: [R] Delete all dimnames
In-Reply-To: <OF567A4C37.25E9099D-ONC1257244.0049B394-C1257244.004A1A4B@wsr.ac.at>
References: <OF567A4C37.25E9099D-ONC1257244.0049B394-C1257244.004A1A4B@wsr.ac.at>
Message-ID: <efb536d50612140617j4dc4175cx9bff62e4179c1d10@mail.gmail.com>

On 12/14/06, Serguei Kaniovski <Serguei.Kaniovski at wifo.ac.at> wrote:
> Hello, how can I get rid of all dimnames so that:

> test
  a b c
A 1 4 7
B 2 5 8
C 3 6 9
> dimnames(test) <- list(NULL, NULL)
>  test
     [,1] [,2] [,3]
[1,]    1    4    7
[2,]    2    5    8
[3,]    3    6    9

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From Timothy.Mak at iop.kcl.ac.uk  Thu Dec 14 15:37:41 2006
From: Timothy.Mak at iop.kcl.ac.uk (Timothy.Mak at iop.kcl.ac.uk)
Date: Thu, 14 Dec 2006 14:37:41 +0000
Subject: [R] Stepwise regression
Message-ID: <OF1DEF5CAC.833101C7-ON80257244.004F7E4E-80257244.0051543D@iop.kcl.ac.uk>

Dear all, 

I am wondering why the step() procedure in R has the description 'Select a 
formula-based model by AIC'. 

I have been using Stata and SPSS and neither package made any reference to 
AIC in its stepwise procedure, and I read from an earlier R-Help post that 
step() is really the 'usual' way for doing stepwise (R Help post from Prof 
Ripley, Fri, 2 Apr 1999 05:06:03 +0100 (BST)). 

My understanding of the 'usual' way of doing say forward regression is 
that variables whose p value drops below a criterion (commonly 0.05) 
become candidates for being included in the model, and the one with the 
lowest p among these gets chosen, and the step is repeated until all p 
values not in the model are above 0.05, cf Hosmer and Lemeshow (1989) 
Applied Logistic Regression. The procedure does not require examination of 
the AIC. 

I am not well aquainted with R enough to understand the codes used in 
step(), so can somebody tell me how step() works?

Thanks very much, 

Tim


From b.rowlingson at lancaster.ac.uk  Thu Dec 14 16:17:32 2006
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 14 Dec 2006 15:17:32 +0000
Subject: [R] loop is going to take 26 hours - needs to be quicker!
In-Reply-To: <200612141341.kBEDfN2l019839@msslhb.mssl.ucl.ac.uk>
References: <200612141341.kBEDfN2l019839@msslhb.mssl.ucl.ac.uk>
Message-ID: <45816B0C.30104@lancaster.ac.uk>

Jenny Barnes wrote:
> Dear R-help,
> 
> Thank you for the responses off everyone- you'll be please to hear Duncan that 
> using: 
>> gpcc.array <- array(gpcc.data2[,5], c(144, 72, 46))
> was spot-on, worked like a dream. The data is in the correct places as I checked 
> with the text file. It took literally 2 seconds - quite an improvement time on 
> the predicted 26 hours :-)
> 

  However now you cant tell your supervisor that your data manipulation 
will take 26 hours - giving you a day to get your Xmas shopping done...

Barry


From jrkrideau at yahoo.ca  Thu Dec 14 16:25:53 2006
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 14 Dec 2006 10:25:53 -0500 (EST)
Subject: [R] two connected graphs
In-Reply-To: <FEDA5AC6-A9BC-4D3F-BAEA-F87FFF161279@soc.soton.ac.uk>
Message-ID: <907827.51128.qm@web32802.mail.mud.yahoo.com>


--- Robin Hankin <r.hankin at noc.soton.ac.uk> wrote:

> Hi
> 
> I have two datasets, A and B, consisting of two
> columns of numbers
> representing x and y coordinates.
> 
> They have 10 and 6 rows respectively.
> 
> I want to plot two scattergraphs, one above the
> other.
> 
> The lower graph to contain A (10 points) and the
> upper
> graph to contain B (six points).
> 
> The x-axes of the two graphs must line up.
> 
> I then want to draw straight lines that connect
> points
> of  B to a particular point (or points)  of A.
> 
> How do I do this?

?par and read up on mfrow for the two graphs.


Here is something that may help for the lines
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/1926.html

The code below will  work but I had to figure out the
arrow coordinates by trial and error and there must be
a better way.

aa <- c(1:10)
bb <- c(1:6)
op <- par(mfrow = c(2,1), oma=c(1,0,3,0), las=1, xpd =
NA )
plot(aa)
plot(bb)
arrows( 3,3, 4.9, 21.5, length=0)


From jrkrideau at yahoo.ca  Thu Dec 14 16:44:23 2006
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 14 Dec 2006 10:44:23 -0500 (EST)
Subject: [R] Install R in Linux
In-Reply-To: <457FFAC0.1020009@biostat.ku.dk>
Message-ID: <20061214154423.11534.qmail@web32814.mail.mud.yahoo.com>


--- Peter Dalgaard <P.Dalgaard at biostat.ku.dk> wrote:

> lu kan wrote:
> > Hi, Is it possible to install R in a linux box
> (Debian) without being a root. I know I can compile
> the R source code, but there is no F77 compiler on
> the box. So is it possible to install binary R
> without being a root?
> >   
> (We did see it the first time!!)
> 
> In a word, no. Either you need to install the
> binaries as root or
> install sufficient build tools as root. There's a
> slight chance that you
> could unpack the Debian binaries somewhere and then
> fix up the paths,
> but you're on your own.
   
If you really need to use it and are not root, a slow
but workable approach is to install R on a USB stick
and run from there.  

I have done this for R.2.3.1 but I have not upgraded
to a newer package.


From jmb at mssl.ucl.ac.uk  Thu Dec 14 16:48:21 2006
From: jmb at mssl.ucl.ac.uk (Jenny Barnes)
Date: Thu, 14 Dec 2006 15:48:21 +0000 (GMT)
Subject: [R] loop is going to take 26 hours - needs to be quicker!
Message-ID: <200612141548.kBEFmLLm020089@msslhb.mssl.ucl.ac.uk>

Dear Patrick,

Thank you for the link - I'd advise anyone who's started using R to have a look 
at these as well - any help is always appreciated. I've downloaded the S Poetry 
and will hit the books tomorrow and get reading it!

Jenny


>
>S Poetry may be of use to you -- especially the chapter
>on arrays which discusses 3 dimensional arrays in particular.
>
>Patrick Burns
>patrick at burns-stat.com
>+44 (0)20 8525 0696
>http://www.burns-stat.com
>(home of S Poetry and "A Guide for the Unwilling S User")
>
>Jenny Barnes wrote:
>
>>Dear R-help,
>>
>>I forgot to mention that I need the array in that format because I am going to 
>>do the same thing for another dataset of precipitation (ncep.data2) so they 
are 
>>both arrays of dimensions [144,72,46] so that I can correlate them globally 
and 
>>plot a visual image of the global correlations between the 2 datasets.... One 
of 
>>the datasets has a land mask applied to it already so it should be clear to 
see 
>>the land and pick ot the locations (i.e.over Europe) where there is strongest 
>>and weakest correlation.....that is the ultimate goal.
>>
>>Following Rainer's response I should also point out that the columns in 
>>gpcc.data2 (with dimensions dim(gpcc.data2) = [476928,5]) are:
>>
>>[,1]="Year", [,2]="month" (which is just january so always 1), 
[,3]="latitude", 
>>[,4]="longitude" and [,5]="data". All I want in the gpcc.array is the data not 
>>the longitudes and latitude values...hope that helps clear it up a bit!
>>
>>I look forward to hearing any more ideas, thanks again for your time in 
reading 
>>this,
>>
>>Jenny Barnes
>>
>>  
>>
>>>Jenny Barnes wrote:
>>>    
>>>
>>>>Dear R-help,
>>>>
>>>>I have a loop, which is set to take about 26 hours to run at the rate it's 
>>>>      
>>>>
>>going 
>>  
>>
>>>>- this is ridiculous and I really need your help to find a more efficient 
way 
>>>>      
>>>>
>>of 
>>  
>>
>>>>loading up my array gpcc.array:
>>>>
>>>>#My data is stored in a table format with all the data in one long column 
>>>>#running though every longitute, for every latitude, for every year. The 
>>>>#original data is sotred as gpcc.data2 where dim(gpcc.data2) = [476928,5] 
>>>>      
>>>>
>>where 
>>  
>>
>>>>#the 5th column is the data:
>>>>
>>>>#make the array in the format I need [longitude,latitude,years]
>>>>
>>>>gpcc.array <- array(NA, c(144,72,46)) 
>>>>
>>>>n=0
>>>>for(k in 1:46){
>>>>for(j in 1:72){
>>>>for(i in 1:144){
>>>>n <- n+1
>>>>gpcc.array[i,j,k] <- gpcc.data2[n,5]
>>>>print(j)
>>>>}
>>>>}
>>>>}
>>>>      
>>>>
>>>I don't know if it is faster - but adding three columns to qpcc.data, 
>>>one for longitude, one for lattitude and one for year (using rep() as 
>>>they are in sequence) and the using reshape() might be faster?
>>>
>>>
>>>    
>>>
>>>>So it runs through all the longs for every lat for every year - which is the 
>>>>order the data is running down the column in gpcc.data2 so n increses by 1 
>>>>      
>>>>
>>each 
>>  
>>
>>>>time and each data point is pulled off....
>>>>
>>>>It needs to be a lot quicker, I'd appreciate any ideas!
>>>>
>>>>Many thanks for taking time to read this,
>>>>
>>>>Jenny Barnes
>>>>
>>>>~~~~~~~~~~~~~~~~~~
>>>>Jennifer Barnes
>>>>PhD student - long range drought prediction
>>>>Climate Extremes
>>>>Department of Space and Climate Physics
>>>>University College London
>>>>Holmbury St Mary, Dorking
>>>>Surrey
>>>>RH5 6NT
>>>>01483 204149
>>>>07916 139187
>>>>Web: http://climate.mssl.ucl.ac.uk
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>>      
>>>>
>>>-- 
>>>Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
>>>Biology (UCT)
>>>
>>>Department of Conservation Ecology and Entomology
>>>University of Stellenbosch
>>>Matieland 7602
>>>South Africa
>>>
>>>Tel:		+27 - (0)72 808 2975 (w)
>>>Fax:		+27 - (0)86 516 2782
>>>Fax:		+27 - (0)21 808 3304 (w)
>>>Cell:		+27 - (0)83 9479 042
>>>
>>>email:	RKrug at sun.ac.za
>>>      	Rainer at krugs.de
>>>    
>>>
>>
>>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>>Jennifer Barnes
>>PhD student - long range drought prediction
>>Climate Extremes
>>Department of Space and Climate Physics
>>University College London
>>Holmbury St Mary, Dorking
>>Surrey
>>RH5 6NT
>>01483 204149
>>07916 139187
>>Web: http://climate.mssl.ucl.ac.uk
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>  
>>

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Jennifer Barnes
PhD student - long range drought prediction
Climate Extremes
Department of Space and Climate Physics
University College London
Holmbury St Mary, Dorking
Surrey
RH5 6NT
01483 204149
07916 139187
Web: http://climate.mssl.ucl.ac.uk


From bbands at gmail.com  Thu Dec 14 16:59:21 2006
From: bbands at gmail.com (BBands)
Date: Thu, 14 Dec 2006 07:59:21 -0800
Subject: [R] Install R in Linux
In-Reply-To: <20061213102816.35197.qmail@web28007.mail.ukl.yahoo.com>
References: <20061213102816.35197.qmail@web28007.mail.ukl.yahoo.com>
Message-ID: <6e8360ad0612140759h63a0e28emaeefdf0a83c522ca@mail.gmail.com>

On 12/13/06, lu kan <lukanlu at yahoo.co.uk> wrote:
> Hi, Is it possible to install R in a linux box (Debian) without being a root. I know I can compile the R source code, but there is no F77 compiler on the box. So is it possible to install binary R without being a root?

If you can get the F77 compiler installed you can configure, make,
test and run R from its bin directory without being root. I did this
last night on a SuSE box with 2.4.0 prior to doing a final make
install as root.

     jab
-- 
John Bollinger, CFA, CMT
www.BollingerBands.com

If you advance far enough, you arrive at the beginning.


From murdoch at stats.uwo.ca  Thu Dec 14 17:06:24 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 14 Dec 2006 11:06:24 -0500
Subject: [R] matrix - change values
In-Reply-To: <59b64ad5.5ea32544.4581592c.c64bf@o2.pl>
References: <59b64ad5.5ea32544.4581592c.c64bf@o2.pl>
Message-ID: <45817680.9040707@stats.uwo.ca>

robert-mcfadden at o2.pl wrote:
> Dear R Users,
> I have a matrix A, and I want to change every value of this matrix if these values are greater than an assuming value. For a vector it is simple, e.g. a<-c(1:10); a[a>5]<-0. 
> Of course, I can change matrix to vector, assign a value then change vector to matrix. But does there exist simpler way?

The same syntax as for a vector:

A[A>5] <- 0

Remember that matrices are just vectors with a dim attribute.  The dim 
attribute is unchanged by this operation:

 > A <- matrix(1:10, 2, 5)
 > A
     [,1] [,2] [,3] [,4] [,5]
[1,]    1    3    5    7    9
[2,]    2    4    6    8   10
 > A[A>5] <- 0
 > A
     [,1] [,2] [,3] [,4] [,5]
[1,]    1    3    5    0    0
[2,]    2    4    0    0    0

Duncan Murdoch


From Greg.Snow at intermountainmail.org  Thu Dec 14 17:11:14 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 14 Dec 2006 09:11:14 -0700
Subject: [R] two connected graphs
Message-ID: <07E228A5BE53C24CAD490193A7381BBB739860@LP-EXCHVS07.CO.IHC.COM>

See the first set of examples in the help for the cnvrt.coords function
in the TeachingDemos Package. 

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Robin Hankin
Sent: Thursday, December 14, 2006 3:32 AM
To: RHelp help
Subject: [R] two connected graphs

Hi

I have two datasets, A and B, consisting of two columns of numbers
representing x and y coordinates.

They have 10 and 6 rows respectively.

I want to plot two scattergraphs, one above the other.

The lower graph to contain A (10 points) and the upper graph to contain
B (six points).

The x-axes of the two graphs must line up.

I then want to draw straight lines that connect points of  B to a
particular point (or points)  of A.

How do I do this?


--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton European Way, Southampton SO14
3ZH, UK
  tel  023-8059-7743

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From tplate at acm.org  Thu Dec 14 17:16:57 2006
From: tplate at acm.org (Tony Plate)
Date: Thu, 14 Dec 2006 09:16:57 -0700
Subject: [R] How to avoid test for NAs in foreign function call
In-Reply-To: <7.0.1.0.0.20061213174310.01e54e50@rockefeller.edu>
References: <7.0.1.0.0.20061213174310.01e54e50@rockefeller.edu>
Message-ID: <458178F9.5060104@acm.org>

Supply NAOK=TRUE argument to .C; the help page for .C() contains the 
following:

Usage
                 .C(name, ..., NAOK = FALSE, DUP = TRUE, PACKAGE)

Also, you might want to consider using the "raw" data type instead of 
integers -- that way you should have fewer problems with R code making 
unwanted interpretations of certain bit patterns.

-- Tony Plate

Knut M. Wittkowski wrote:
> We have packed logical vectors into integers, 32 flags at a time and 
> then want to AND or OR these vectors of "integers" using other C functions.
> 
> The problem: occasionally, the packed sequence of 32 logical values 
> resembles NA, causing the error message:
> 
> Error in bitAND(packed1, packed2, lenx) :
>          NAs in foreign function call (arg 1)
> 
> How does one instruct R to avoid checking for NAs?
> 
> Knut M. Wittkowski, PhD,DSc
> ------------------------------------------
> The Rockefeller University,
> Center for Clinical and Translational Science
> Research Design and Biostatistics,
> 1230 York Ave #121B, Box 322, NY,NY 10021
> +1(212)327-7175, +1(212)327-8450 (Fax), kmw at rockefeller.edu
> http://www.rockefeller.edu/ccts/rdbs.php
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From apjaworski at mmm.com  Thu Dec 14 17:17:47 2006
From: apjaworski at mmm.com (apjaworski at mmm.com)
Date: Thu, 14 Dec 2006 10:17:47 -0600
Subject: [R] matrix - change values
In-Reply-To: <59b64ad5.5ea32544.4581592c.c64bf@o2.pl>
Message-ID: <OFE5B63733.DD83CA74-ON86257244.0058B34E-86257244.00598500@mmm.com>

Rob,

Try

a[a>5]<-0

Yup.  It works for matrices (and for arrays).  It also works with the
replacement value being a vector.  For example, try

b <- array(1:24, dim=c(3, 4, 2))
b[(b>8) & (b<17)] <- 101:108

I think the reason it works like this is that internally array are stored
as vectors.

Cheers,

Andy

__________________________________
Andy Jaworski
518-1-01
Process Laboratory
3M Corporate Research Laboratory
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


                                                                           
             robert-mcfadden at o                                             
             2.pl                                                          
             Sent by:                                                   To 
             r-help-bounces at st         r-help at stat.math.ethz.ch            
             at.math.ethz.ch                                            cc 
                                                                           
                                                                   Subject 
             12/14/2006 08:01          [R] matrix - change values          
             AM                                                            
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           




Dear R Users,
I have a matrix A, and I want to change every value of this matrix if these
values are greater than an assuming value. For a vector it is simple, e.g.
a<-c(1:10); a[a>5]<-0.
Of course, I can change matrix to vector, assign a value then change vector
to matrix. But does there exist simpler way?
Any suggestion are appreciate.
Rob

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From joachim.claudet at gmail.com  Thu Dec 14 17:21:57 2006
From: joachim.claudet at gmail.com (Joachim Claudet)
Date: Thu, 14 Dec 2006 17:21:57 +0100
Subject: [R] Asymmetrical ANOVA / contrasts
Message-ID: <45817A25.4040706@gmail.com>

Dear all,

I have problems to code contrasts for performing an asymmetrical anova 
with aov(). I am using aov() because I want to get the Mean Squares for 
further analyses. I didn't find any solution to my problem in the help 
files of functions aov(), contrasts(), C(), etc.
Let's say I have three locations, one with treatment P, and two with 
treatment C:
 > loc=factor(c(P1,P1,P1,P1,P1,C1,C1,C1,C1,C1,C2,C2,C2,C2,C2))
And here is my variable:
 > X=c(21,23,34,32,23,9,4,5,6,8,3,2,8,7,6)
I want to test the effect of location P versus location C
Here is what I have done:
 > contrasts(loc)=contr.treatment(3)
 > aov(X~C(loc,c(2,-1,-1)))
This gives me exactly the same result as if I was doing simply 
aov(X~loc) without first coding for the contrasts.
I have also tried:
 > aov(X~loc,contrasts=contrasts(loc))

Could somebody tell me how to do?
Any help would be greatly appreciated.
Thanks,
Joachim Claudet.

-- 
<?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><

Joachim Claudet

PhD

EPHE - CNRS FRE 2935
52, avenue Paul Alduy
66860 Perpignan cedex
Tel : 33 4 68662055
Fax : 33 4 68503686


<?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><


From Greg.Snow at intermountainmail.org  Thu Dec 14 17:25:56 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 14 Dec 2006 09:25:56 -0700
Subject: [R] matrix - change values
Message-ID: <07E228A5BE53C24CAD490193A7381BBB73986D@LP-EXCHVS07.CO.IHC.COM>

A matrix is already a vector, you don't need to do the transformations,
just do the same thing directly:

> tmp <- matrix( sample(1:12), ncol=3 )
> tmp
     [,1] [,2] [,3]
[1,]   11    1    6
[2,]    3    7    9
[3,]    4   12    8
[4,]    2    5   10
> tmp[tmp > 5] <- 0
> tmp
     [,1] [,2] [,3]
[1,]    0    1    0
[2,]    3    0    0
[3,]    4    0    0
[4,]    2    5    0

If on the other hand, your matrix is really a data frame then functions
like lapply, sapply, transform may help.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
robert-mcfadden at o2.pl
Sent: Thursday, December 14, 2006 7:01 AM
To: r-help at stat.math.ethz.ch
Subject: [R] matrix - change values

Dear R Users,
I have a matrix A, and I want to change every value of this matrix if
these values are greater than an assuming value. For a vector it is
simple, e.g. a<-c(1:10); a[a>5]<-0. 
Of course, I can change matrix to vector, assign a value then change
vector to matrix. But does there exist simpler way?
Any suggestion are appreciate.
Rob

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From joachim.claudet at gmail.com  Thu Dec 14 17:35:27 2006
From: joachim.claudet at gmail.com (Joachim Claudet)
Date: Thu, 14 Dec 2006 17:35:27 +0100
Subject: [R] Asymmetrical ANOVA / contrasts
Message-ID: <45817D4F.90600@gmail.com>

Dear all,

I have problems to code contrasts for performing an asymmetrical anova 
with aov(). I am using aov() because I want to get the Mean Squares for 
further analyses. I didn't find any solution to my problem in the help 
files of functions aov(), contrasts(), C(), etc.
Let's say I have three locations, one with treatment P, and two with 
treatment C:
 > loc=factor(c(P1,P1,P1,P1,P1,C1,C1,C1,C1,C1,C2,C2,C2,C2,C2))
And here is my variable:
 > X=c(21,23,34,32,23,9,4,5,6,8,3,2,8,7,6)
I want to test the effect of location P versus location C
Here is what I have done:
 > contrasts(loc)=contr.treatment(3)
 > aov(X~C(loc,c(2,-1,-1)))
This gives me exactly the same result as if I was doing simply 
aov(X~loc) without first coding for the contrasts.
I have also tried:
 > aov(X~loc,contrasts=contrasts(loc))

Could somebody tell me how to do?
Any help would be greatly appreciated.
Thanks,
Joachim Claudet.

-- 
<?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><

Joachim Claudet

PhD

EPHE - CNRS FRE 2935
52, avenue Paul Alduy
66860 Perpignan cedex
Tel : 33 4 68662055
Fax : 33 4 68503686


<?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><


From Timothy.Mak at iop.kcl.ac.uk  Thu Dec 14 17:28:12 2006
From: Timothy.Mak at iop.kcl.ac.uk (Timothy.Mak at iop.kcl.ac.uk)
Date: Thu, 14 Dec 2006 16:28:12 +0000
Subject: [R] Stepwise regression
Message-ID: <OFB06F0016.41809156-ON80257244.005A73F0-80257244.005B723A@iop.kcl.ac.uk>

Dear all, 

I am wondering why the step() procedure in R has the description 'Select a 
formula-based model by AIC'. 

I have been using Stata and SPSS and neither package made any reference to 
AIC in its stepwise procedure, and I read from an earlier R-Help post that 
step() is really the 'usual' way for doing stepwise (R Help post from Prof 
Ripley, Fri, 2 Apr 1999 05:06:03 +0100 (BST)). 

My understanding of the 'usual' way of doing say forward regression is 
that variables whose p value drops below a criterion (commonly 0.05) 
become candidates for being included in the model, and the one with the 
lowest p among these gets chosen, and the step is repeated until all p 
values not in the model are above 0.05, cf Hosmer and Lemeshow (1989) 
Applied Logistic Regression. The procedure does not require examination of 
the AIC. 

I am not well aquainted with R enough to understand the codes used in 
step(), so can somebody tell me how step() works?

Thanks very much, 

Tim


From robert-mcfadden at o2.pl  Thu Dec 14 17:40:50 2006
From: robert-mcfadden at o2.pl (robert-mcfadden at o2.pl)
Date: Thu, 14 Dec 2006 17:40:50 +0100
Subject: [R] =?utf-8?q?matrix_-_change_values?=
In-Reply-To: <59b64ad5.5ea32544.4581592c.c64bf@o2.pl>
References: <59b64ad5.5ea32544.4581592c.c64bf@o2.pl>
Message-ID: <460ad1a.36a45342.45817e92.bce56@o2.pl>

I would like to thanks everybody for helpful suggestion. 
Rob


Od: robert-mcfadden w o2.pl
Do: r-help w stat.math.ethz.ch
Data: 14 grudnia 2006 15:01
Temat: [R] matrix - change values

> Dear R Users,
> I have a matrix A, and I want to change every value of this matrix if these values are greater than an assuming value. For a vector it is simple, e.g. a<-c(1:10); a[a>5]<-0. 
> Of course, I can change matrix to vector, assign a value then change vector to matrix. But does there exist simpler way?
> Any suggestion are appreciate.
> Rob
> 
> ______________________________________________
> R-help w stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From helprhelp at gmail.com  Thu Dec 14 17:41:31 2006
From: helprhelp at gmail.com (Weiwei Shi)
Date: Thu, 14 Dec 2006 11:41:31 -0500
Subject: [R] sapply problem
In-Reply-To: <458151D9.5080009@fz-rossendorf.de>
References: <458151D9.5080009@fz-rossendorf.de>
Message-ID: <cdf817830612140841w44ce492dw6e1ae37ab1b8bc8c@mail.gmail.com>

> c <- apply(b, c(1,2), unlist)
> c
     A B C
[1,] 1 2 3
[2,] 4 5 6
> class(c[1,1])
[1] "numeric"


On 12/14/06, Joerg van den Hoff <j.van_den_hoff at fz-rossendorf.de> wrote:
> I have encountered the following problem: I need to extract from
> a list of lists equally named compenents who happen to be 'one row'
> data frames. a trivial example would be:
>
> a <- list(list(
> df = data.frame(A = 1, B = 2, C = 3)), list(df = data.frame(A = 4,B = 5,C = 6)))
>
> I want the extracted compenents to fill up a matrix or data frame row by row.
> the obvious thing to do seems:
>
> b <- sapply(a, "[[", "df")
> b <- t(b)
>
> now `b' looks all right:
>
> b
> class(b)
>
> but it turns out that all elements in this matrix are one element lists:
>
> class(b[1,1])
>
> which prevents any further standard processing of `b' (like `colMeans', e.g.)
>
> question 1: is their a straightforward way to enforce that `b' contains
> simple numbers as elements right from the start (instead of something like
> apply(b, 1:2, "class<-", "numeric") afterwards)?
>
> question 2: should not sapply do this further 'simplification' anyway in a situation
> like this (matrix elements turn out to be one-element lists)?
>
> regards
>
> joerg
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From sundar.dorai-raj at pdf.com  Thu Dec 14 17:50:13 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 14 Dec 2006 10:50:13 -0600
Subject: [R] sapply problem
In-Reply-To: <458151D9.5080009@fz-rossendorf.de>
References: <458151D9.5080009@fz-rossendorf.de>
Message-ID: <458180C5.7020500@pdf.com>



Joerg van den Hoff said the following on 12/14/2006 7:30 AM:
> I have encountered the following problem: I need to extract from
> a list of lists equally named compenents who happen to be 'one row'
> data frames. a trivial example would be:
> 
> a <- list(list(
> df = data.frame(A = 1, B = 2, C = 3)), list(df = data.frame(A = 4,B = 5,C = 6)))
> 
> I want the extracted compenents to fill up a matrix or data frame row by row.
> the obvious thing to do seems:
> 
> b <- sapply(a, "[[", "df")
> b <- t(b)
> 
> now `b' looks all right:
> 
> b
> class(b)
> 
> but it turns out that all elements in this matrix are one element lists:
> 
> class(b[1,1])
> 
> which prevents any further standard processing of `b' (like `colMeans', e.g.)
> 
> question 1: is their a straightforward way to enforce that `b' contains
> simple numbers as elements right from the start (instead of something like
> apply(b, 1:2, "class<-", "numeric") afterwards)?
> 

Try this:

a <- list(list(df = data.frame(A = 1, B = 2, C = 3)),
           list(df = data.frame(A = 4, B = 5, C = 6)))
b <- do.call("rbind", sapply(a, "[", "df"))
b


> question 2: should not sapply do this further 'simplification' anyway in a situation
> like this (matrix elements turn out to be one-element lists)?
> 

I think it does as it much as it knows how. I think you might believe 
that matrix elements can only contain numeric values. This is not a 
valid assumption. Take this example:

 > a <- list(1)
 > b <- list(2)
 > (m <- matrix(c(a, b), 2, 1))
      [,1]
[1,] 1
[2,] 2
 > class(m[1, 1])
[1] "list"
 > class(m[2, 1])
[1] "list"

HTH,

--sundar

> regards
> 
> joerg
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at comcast.net  Thu Dec 14 18:02:47 2006
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 14 Dec 2006 11:02:47 -0600
Subject: [R] Stepwise regression
In-Reply-To: <OF1DEF5CAC.833101C7-ON80257244.004F7E4E-80257244.0051543D@iop.kcl.ac.uk>
References: <OF1DEF5CAC.833101C7-ON80257244.004F7E4E-80257244.0051543D@iop.kcl.ac.uk>
Message-ID: <1166115767.4516.4.camel@localhost.localdomain>

On Thu, 2006-12-14 at 14:37 +0000, Timothy.Mak at iop.kcl.ac.uk wrote:
> Dear all, 
> 
> I am wondering why the step() procedure in R has the description 'Select a 
> formula-based model by AIC'. 
> 
> I have been using Stata and SPSS and neither package made any reference to 
> AIC in its stepwise procedure, and I read from an earlier R-Help post that 
> step() is really the 'usual' way for doing stepwise (R Help post from Prof 
> Ripley, Fri, 2 Apr 1999 05:06:03 +0100 (BST)). 
> 
> My understanding of the 'usual' way of doing say forward regression is 
> that variables whose p value drops below a criterion (commonly 0.05) 
> become candidates for being included in the model, and the one with the 
> lowest p among these gets chosen, and the step is repeated until all p 
> values not in the model are above 0.05, cf Hosmer and Lemeshow (1989) 
> Applied Logistic Regression. The procedure does not require examination of 
> the AIC. 
> 
> I am not well aquainted with R enough to understand the codes used in 
> step(), so can somebody tell me how step() works?
> 
> Thanks very much, 
> 
> Tim

> library(fortunes)

> fortune("stepwise")

Frank Harrell: Here is an easy approach that will yield results only
slightly less valid than one actually using the response variable:
  x <- data.frame(x1, x2, x3, x4, ..., other potential predictors)
  x[ , sample(ncol(x))]
Andy Liaw: Hmm... Shouldn't that be something like:
  x[, sample(ncol(x), ceiling(ncol(x) * runif(1)))]
   -- Frank Harrell and Andy Liaw (about alternative strategies for
      stepwise regression and `random parsimony')
      R-help (May 2005)


But seriously, using:

  RSiteSearch("stepwise")

will provide links to prior discussions on why the use of stepwise based
model building is to be avoided.

A copy of Frank's book (more info here):

  http://biostat.mc.vanderbilt.edu/twiki/bin/view/Main/RmS

will also provide insight.


HTH,

Marc Schwartz


From btyner at stat.purdue.edu  Thu Dec 14 18:04:52 2006
From: btyner at stat.purdue.edu (Benjamin Tyner)
Date: Thu, 14 Dec 2006 12:04:52 -0500
Subject: [R] "convert" shingle to factor when overlap=0
Message-ID: <45818434.9020503@stat.purdue.edu>

What is the recommended way to "convert" a shingle to a factor (when 
overlap=0)? In other words, I want to know in which interval each 
observation falls.

Thanks,
Ben


From cberry at tajo.ucsd.edu  Thu Dec 14 18:06:43 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Thu, 14 Dec 2006 09:06:43 -0800
Subject: [R] two connected graphs
In-Reply-To: <FEDA5AC6-A9BC-4D3F-BAEA-F87FFF161279@soc.soton.ac.uk>
References: <FEDA5AC6-A9BC-4D3F-BAEA-F87FFF161279@soc.soton.ac.uk>
Message-ID: <Pine.LNX.4.64.0612140859381.15714@tajo.ucsd.edu>

On Thu, 14 Dec 2006, Robin Hankin wrote:

> Hi
>
> I have two datasets, A and B, consisting of two columns of numbers
> representing x and y coordinates.
>
> They have 10 and 6 rows respectively.
>
> I want to plot two scattergraphs, one above the other.
>
> The lower graph to contain A (10 points) and the upper
> graph to contain B (six points).
>
> The x-axes of the two graphs must line up.
>
> I then want to draw straight lines that connect points
> of  B to a particular point (or points)  of A.
>
> How do I do this?

Use the grid package.

You'll want to study the xscale arg of the viewport function (to set up 
your two plots using the same scale)

Calls to grid.move.to, seekViewport, and grid.line.to can be used to 
connect points in different plots (viewports)

> [...]

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717


From livio.fenga at uniroma2.it  Fri Dec 15 02:08:33 2006
From: livio.fenga at uniroma2.it (Livio Fenga)
Date: Thu, 14 Dec 2006 18:08:33 -0700
Subject: [R] Problems with ARIMA commands
Message-ID: <4581F591.7030505@uniroma2.it>

Hi!
I have to fit 36 ARMA models  (all combination from the order (0,0) to 
the order (5,5) ) to 1000 bootstrap replication from each of 1000 
simulated time series following an ARMA(2,1) process. The simulated 
series are generated by ARIMA.SIM command.

The problem is the following: the esimation procedure of ARMA 
coefficient stops after the estimation of a certain number of bootstrap 
replication (it ranges from 10,15 to 55) always before the 10-th 
simulated serie due to an "error in solve.default(res$hessian * n.used) 
:  Lapack routine dgesv: is   the system is exactely singiular" .

I tried to modify the command OPTIM in the command ARIMA, it worked but 
not when  I try to apply this modified OPTIM in the ARMA command. In 
other words I put an error in the OPTIM command but ARMA ignores it and 
gives me parameters estimation.

Another (related) question is the following:  is there a way to modify 
ARIMA command in order to get only the estimated coefficients and the AIC ?

I really would like to thank for the kind attention.

Best,

Livio Fenga



Chiacchiera con i tuoi amici in tempo reale! 
 http://it.yahoo.com/mail_it/foot/*http://it.messenger.yahoo.com


From Greg.Snow at intermountainmail.org  Thu Dec 14 18:35:07 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 14 Dec 2006 10:35:07 -0700
Subject: [R] Asymmetrical ANOVA / contrasts
Message-ID: <07E228A5BE53C24CAD490193A7381BBB739898@LP-EXCHVS07.CO.IHC.COM>

You need to specify the how.many argument to C (otherwise it tries to be helpful by creating an additional orthogonal contrast), like this:

 > aov(X~C(loc,c(2,-1,-1),how.many=1))

One of the ways to see what is going on is to do:

> fit1 <- aov(X~C(loc,c(2,-1,-1)), x=TRUE)
> fit2 <- aov(X~C(loc,c(2,-1,-1),how.many=1), x=TRUE)
> fit1$x
> fit2$x

This shows you exactly the x matrix being used, in your case it also shows that you are comparing C1 to the average of C2 and P1 (factor orders the levels alphabetically by default).

You may also want to look at the 'split' argument in the summary.aov function.

Hope this helps,


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Joachim Claudet
Sent: Thursday, December 14, 2006 9:35 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Asymmetrical ANOVA / contrasts

Dear all,

I have problems to code contrasts for performing an asymmetrical anova with aov(). I am using aov() because I want to get the Mean Squares for further analyses. I didn't find any solution to my problem in the help files of functions aov(), contrasts(), C(), etc.
Let's say I have three locations, one with treatment P, and two with treatment C:
 > loc=factor(c(P1,P1,P1,P1,P1,C1,C1,C1,C1,C1,C2,C2,C2,C2,C2))
And here is my variable:
 > X=c(21,23,34,32,23,9,4,5,6,8,3,2,8,7,6)
I want to test the effect of location P versus location C Here is what I have done:
 > contrasts(loc)=contr.treatment(3)
 > aov(X~C(loc,c(2,-1,-1)))
This gives me exactly the same result as if I was doing simply
aov(X~loc) without first coding for the contrasts.
I have also tried:
 > aov(X~loc,contrasts=contrasts(loc))

Could somebody tell me how to do?
Any help would be greatly appreciated.
Thanks,
Joachim Claudet.

--
<?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><

Joachim Claudet

PhD

EPHE - CNRS FRE 2935
52, avenue Paul Alduy
66860 Perpignan cedex
Tel : 33 4 68662055
Fax : 33 4 68503686


<?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From BEN at SSANET.COM  Thu Dec 14 18:39:27 2006
From: BEN at SSANET.COM (Ben Fairbank)
Date: Thu, 14 Dec 2006 11:39:27 -0600
Subject: [R] Better way to change the name of a column in a dataframe?
Message-ID: <CA612484A337C6479EA341DF9EEE14AC05B7CDB5@hercules.ssainfo>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061214/2e3fbca1/attachment.pl 

From Greg.Snow at intermountainmail.org  Thu Dec 14 18:53:02 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 14 Dec 2006 10:53:02 -0700
Subject: [R] Stepwise regression
Message-ID: <07E228A5BE53C24CAD490193A7381BBB7398A7@LP-EXCHVS07.CO.IHC.COM>

You may want to look at a book that was published more recently than 17
years ago (computing has changed a lot since then).  Doing stepwise
regression using p-values is one approach (and when p-values were the
easiest (only) thing to compute, it was reasonable to use them).  But
think about how many p-values you would be computing and comparing to
0.05 in a stepwise regression, now think about how many you would have
computed if your data had come from a different sample, what is your
type I error rate?  Is the usual p-value theory even meaningful in this
situation?

There are several criteria that can be used in stepwise regression to
decide which term to add/drop, p-value (or F-statistic) is only 1,
others include AIC, BIC, Adjusted R-squared, PRESS, gut feeling, prior
knowledge, cost, ...

 Some of these have properties better than p-values, but most still
suffer from the fact that a small change in the data can result in a
very different model.

Look at the lars, lasso2, and BMA packages for some more modern
alternatives to stepwise regression.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
Timothy.Mak at iop.kcl.ac.uk
Sent: Thursday, December 14, 2006 9:28 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Stepwise regression

Dear all, 

I am wondering why the step() procedure in R has the description 'Select
a formula-based model by AIC'. 

I have been using Stata and SPSS and neither package made any reference
to AIC in its stepwise procedure, and I read from an earlier R-Help post
that
step() is really the 'usual' way for doing stepwise (R Help post from
Prof Ripley, Fri, 2 Apr 1999 05:06:03 +0100 (BST)). 

My understanding of the 'usual' way of doing say forward regression is
that variables whose p value drops below a criterion (commonly 0.05)
become candidates for being included in the model, and the one with the
lowest p among these gets chosen, and the step is repeated until all p
values not in the model are above 0.05, cf Hosmer and Lemeshow (1989)
Applied Logistic Regression. The procedure does not require examination
of the AIC. 

I am not well aquainted with R enough to understand the codes used in
step(), so can somebody tell me how step() works?

Thanks very much, 

Tim

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Thu Dec 14 18:57:49 2006
From: jholtman at gmail.com (jim holtman)
Date: Thu, 14 Dec 2006 09:57:49 -0800
Subject: [R] sapply problem
In-Reply-To: <458151D9.5080009@fz-rossendorf.de>
References: <458151D9.5080009@fz-rossendorf.de>
Message-ID: <644e1f320612140957u3d7dd75fwe23ddc0548e80b09@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061214/48783f7b/attachment.pl 

From rcprati at gmail.com  Thu Dec 14 19:08:25 2006
From: rcprati at gmail.com (Ronaldo Prati)
Date: Thu, 14 Dec 2006 16:08:25 -0200
Subject: [R] Model formula
Message-ID: <b2f853f40612141008q642fef34qad7e0f298ff4cff2@mail.gmail.com>

Hi there,

I've sent this e-mail to the list twice but didn't get it back from
the list. Have it reach list members?

cheers,

Ronaldo


---------- Forwarded message ----------
From: Ronaldo Prati <rcprati at gmail.com>
Date: 14/12/2006 11:59
Subject: Model formula question
To: r-help at stat.math.ethz.ch


Hi all,

I'm not familiar with R programming and I'm trying to reproduce a
result from a paper.

Basically, I have a dataset which I would like to model in terms of
successive increments, i.e. (y denote empirical values of y)

y_1 = y1,

y_2 = y1 + delta1,

y_3 = y1 + delta1 + delta2.

...

y_m = y1 + sum_2^m delta j

where delta_j donote successive increments in the y-values, i.e.

delta j = y_j - y_(j-1).

In order to estimate y-values, I'm assuming that delta j is
approximately equal to kj**u, such that my regression model should be
something like this:

^y_1 = a1

^y_2 = a1 + k2**u

^y_3 = a1 + k2**u + k3**u

...

^y_m = a1 + k2**u + k3**u + ... + km**u

or, generically

^yi = a1 + k * sum_j=2^i  j**u

and I need to fit a non-linear least-squares regression model to find
the tripplet a1,k,u. I had a look to the gnm package, but I don't have
the lesser idea how to formulate this problem to use this package. Can
someone help me with that?

cheers,

Ronaldo


From bernard.gregorry at yahoo.fr  Thu Dec 14 19:13:30 2006
From: bernard.gregorry at yahoo.fr (Bernard Gregory)
Date: Thu, 14 Dec 2006 19:13:30 +0100 (CET)
Subject: [R] persistant: Matlab->R
Message-ID: <20061214181330.23060.qmail@web28115.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061214/9b74d745/attachment.pl 

From RMan54 at cox.net  Thu Dec 14 19:35:58 2006
From: RMan54 at cox.net (Rene Braeckman)
Date: Thu, 14 Dec 2006 10:35:58 -0800
Subject: [R] xyplot: discrete points + continuous curve per panel
In-Reply-To: <458124C6.23793.8364B8@localhost>
Message-ID: <013b01c71fae$b2d5e000$0900a8c0@rman>

I will give this a try. However, this is based on row and columns of the
panels and not on the SUBJ and DOSE information that I need to calculate the
continuous curve.
Rene 

-----Original Message-----
From: Petr Pikal [mailto:petr.pikal at precheza.cz] 
Sent: Thursday, December 14, 2006 1:18 AM
To: RMan54; r-help at stat.math.ethz.ch
Subject: Re: [R] xyplot: discrete points + continuous curve per panel

Hi

there is probably better solution but you can try to fiidle with this idea,
which adds stight lines to each panel one after another. 

# based on Gabor Grothendieck's code suggestion # adds straight lines to
panels in lattice plots

addLine<- function(...) {
tcL <- trellis.currentLayout()
for(i in 1:nrow(tcL))
  for(j in 1:ncol(tcL))
    if (tcL[i,j] > 0) {
        trellis.focus("panel", j, i, highlight = FALSE)
        panel.abline(...)
        trellis.unfocus()
        }
}

You need to change panel.abline(...) part maybe to panel.curve or
panel.segments or?

HTH
Petr



On 13 Dec 2006 at 23:22, RMan54 wrote:

Date sent:      	Wed, 13 Dec 2006 23:22:41 -0800 (PST)
From:           	RMan54 <RMan54 at cox.net>
To:             	r-help at stat.math.ethz.ch
Subject:        	[R] xyplot: discrete points + continuous curve per
panel

> 
> I have a number of x, y observations (Time, Conc) for a number of 
> Subjects (with subject number Subj) and Doses. I can plot the 
> individual points with xyplot fine:
> 
> xyplot(Conc ~ Time | Subj,
>          Groups=Dose,
>          data=myData,
>          panel =  function(x,y) { 
>               panel.xyplot(x, y) 
>               panel.superpose(???) # Needs more here 
>          }
> )
> 
> I also like to plot on each panel (there is one Subj per panel) a 
> continuous curve with predictions that I can calculate from a rather 
> complicated function:
> 
> myPred <- (time, subj, dose) {
>        returns predicted value of Conc for a given time, subj and dose 
> }
> 
> The predicted curves are different for each panel.
> 
> How do I plot the predictions? I have tried to add panel.superinpose 
> in the xyplot portion but can't link to the myPred function. I also 
> know about panel.curve but couldn't make it work.
> 
> My attempt is to calculate the predictions on the fly. Is this 
> possible? Or do I need to calculate all predictions first and put the 
> results in a data frame. Thanks for any help, Rene -- View this 
> message in context:
> http://www.nabble.com/xyplot%3A-discrete-points-%2B-continuous-curve-p
> er-panel-tf2818931.html#a7867892 Sent from the R help mailing list 
> archive at Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented, 
> minimal, self-contained, reproducible code.

Petr Pikal
petr.pikal at precheza.cz


From fisk at bowdoin.edu  Thu Dec 14 19:53:56 2006
From: fisk at bowdoin.edu (steve)
Date: Thu, 14 Dec 2006 13:53:56 -0500
Subject: [R] rotated histogram
Message-ID: <45819DC4.6080906@bowdoin.edu>

I would like to make a scatterplot, with a histogram of the x and y 
variables above and to the right . I can use layout to set up the areas, 
and hist(x,y) works fine for the upper histogram. However, I need a 
rotated histogram on the right, and I don't know how to do this. I've 
seen a solution with a bar plot on the right, but I'd like to use a 
histogram. Do you know how I can do this?

Steve


From marc_schwartz at comcast.net  Thu Dec 14 20:19:02 2006
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 14 Dec 2006 13:19:02 -0600
Subject: [R] rotated histogram
In-Reply-To: <45819DC4.6080906@bowdoin.edu>
References: <45819DC4.6080906@bowdoin.edu>
Message-ID: <1166123942.4516.48.camel@localhost.localdomain>

On Thu, 2006-12-14 at 13:53 -0500, steve wrote:
> I would like to make a scatterplot, with a histogram of the x and y 
> variables above and to the right . I can use layout to set up the areas, 
> and hist(x,y) works fine for the upper histogram. However, I need a 
> rotated histogram on the right, and I don't know how to do this. I've 
> seen a solution with a bar plot on the right, but I'd like to use a 
> histogram. Do you know how I can do this?
> 
> Steve

What's wrong with the example in ?layout below the comment:

##-- Create a scatterplot with marginal histograms -----

?

HTH,

Marc Schwartz


From p.murrell at auckland.ac.nz  Thu Dec 14 20:36:23 2006
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri, 15 Dec 2006 08:36:23 +1300
Subject: [R] two connected graphs
In-Reply-To: <Pine.LNX.4.64.0612140859381.15714@tajo.ucsd.edu>
References: <FEDA5AC6-A9BC-4D3F-BAEA-F87FFF161279@soc.soton.ac.uk>
	<Pine.LNX.4.64.0612140859381.15714@tajo.ucsd.edu>
Message-ID: <4581A7B7.7050701@stat.auckland.ac.nz>

Hi


Charles C. Berry wrote:
> On Thu, 14 Dec 2006, Robin Hankin wrote:
> 
>> Hi
>>
>> I have two datasets, A and B, consisting of two columns of numbers
>> representing x and y coordinates.
>>
>> They have 10 and 6 rows respectively.
>>
>> I want to plot two scattergraphs, one above the other.
>>
>> The lower graph to contain A (10 points) and the upper
>> graph to contain B (six points).
>>
>> The x-axes of the two graphs must line up.
>>
>> I then want to draw straight lines that connect points
>> of  B to a particular point (or points)  of A.
>>
>> How do I do this?
> 
> Use the grid package.
> 
> You'll want to study the xscale arg of the viewport function (to set up 
> your two plots using the same scale)
> 
> Calls to grid.move.to, seekViewport, and grid.line.to can be used to 
> connect points in different plots (viewports)


See the example in "The grid Graphics Package" R News 2(2)
http://cran.r-project.org/doc/Rnews/Rnews_2002-2.pdf

Paul


>> [...]
> 
> Charles C. Berry                        (858) 534-2098
>                                           Dept of Family/Preventive Medicine
> E mailto:cberry at tajo.ucsd.edu	         UC San Diego
> http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From Charles.Annis at StatisticalEngineering.com  Thu Dec 14 21:10:52 2006
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Thu, 14 Dec 2006 15:10:52 -0500
Subject: [R] persistant: Matlab->R
In-Reply-To: <20061214181330.23060.qmail@web28115.mail.ukl.yahoo.com>
Message-ID: <00da01c71fbb$f4e37040$6400a8c0@DD4XFW31>

It might be helpful to those not familiar with Matlab to tell us what
function "persistent" does.

Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  614-455-3265
http://www.StatisticalEngineering.com
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Bernard Gregory
Sent: Thursday, December 14, 2006 1:14 PM
To: r-help at stat.math.ethz.ch
Subject: [R] persistant: Matlab->R

Dear list members,

Could anyone tell me if there is an equivalent of the Matlab declaration
'persistant' in R?

Thank you very much,

Bernard Gregorry.
(Matlaber converted to R).

 		
---------------------------------

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gsmatos1 at ig.com.br  Thu Dec 14 20:27:08 2006
From: gsmatos1 at ig.com.br (gsmatos1)
Date: Thu, 14 Dec 2006 16:27:08 -0300
Subject: [R] Error to install fMultivar package
Message-ID: <20061214_192708_060920.gsmatos1@ig.com.br>


 Hello, 

I tried the first issue of Dirk and it was all right: 

>This would be quicker: 
> 
> $ sudo apt-get install r-cran-fmulitvar 
> 

(I've already had enabled the Universe repositories in 
/etc/apt/sources.list. ) 

I think it was realy related with some lib and packages dependencies. 

Thank's for all! 
Gilberto. 

Em (10:18:04), Dirk Eddelbuettel escreveu: 
>On Wed, Dec 13, 2006 at 09:34:04AM -0300, gsmatos1 wrote: 
>Content-Description: Mail message body 
>> Hi, 
>> 
>> I tried to install fMultivar package but an error occurs that I could not 
>> understand. 
>> (I've been worked with linux / Ubuntu 6.06 LTS) 
> 
>This would be quicker: 
> 
> $ sudo apt-get install r-cran-fmulitvar 
> 
>(if you enabled the Universe repositories in /etc/apt/sources.list). 
> 
>> > install.packages("fMultivar") 
... 
>> trying URL 
>> 'http://lmq.esalq.usp.br/CRAN/src/contrib/fMultivar_221.10065.tar.gz' 
>> Content type 'application/x-gzip' length 1152747 bytes 
>> opened URL 
>> ================================================== 
>> downloaded 1125Kb 
>> 
>> * Installing *source* package 'fMultivar' ... 
>> ** libs 
>> gcc -I/usr/share/R/include -I/usr/share/R/include -fpic -g -O2 
>> -std=gnu99 -c 00A-randomF77.c -o 00A-randomF77.o 
>> gcc -I/usr/share/R/include -I/usr/share/R/include -fpic -g -O2 
>> -std=gnu99 -c 00B-GarchBEKK.c -o 00B-GarchBEKK.o 
>> g77 -fpic -g -O2 -c 42A-1ReggressionModelling.f -o 
>> 42A-1ReggressionModelling.o 
>> g77 -fpic -g -O2 -c 42A-2RegressionModelling.f -o 
>> 42A-2RegressionModelling.o 
>> gcc -I/usr/share/R/include -I/usr/share/R/include -fpic -g -O2 
>> -std=gnu99 -c 42A-3RegressionModelling.c -o 42A-3RegressionModelling.o 
>> g77 -fpic -g -O2 -c 42B-RegressionTests.f -o 42B-RegressionTests.o 
>> g77 -fpic -g -O2 -c 46A-VectorMatrixAddon.f -o 46A-VectorMatrixAddon.o 
>> gcc -I/usr/share/R/include -I/usr/share/R/include -fpic -g -O2 
>> -std=gnu99 -c 46B-MissingValues.c -o 46B-MissingValues.og77 -fpic -g 
>-O2 
>> -c 47B-MultivariateDistribution.f -o 47B-MultivariateDistribution.o 
>> gcc -I/usr/share/R/include -I/usr/share/R/include -fpic -g -O2 
>> -std=gnu99 -c runfunc.c -o runfunc.o 
>> gcc -shared -o fMultivar.so 00A-randomF77.o 00B-GarchBEKK.o 
>> 42A-1ReggressionModelling.o 42A-2RegressionModelling.o 
>> 42A-3RegressionModelling.o 42B-RegressionTests.o 46A-VectorMatrixAddon.o 
>> 46B-MissingValues.o 47B-MultivariateDistribution.o runfunc.o -lblas-3 
>-lg2c 
>> -lm -lgcc_s -L/usr/lib/R/lib -lR 
>> /usr/bin/ld: cannot find -lblas-3 
>> collect2: ld returned 1 exit status 
>> make: *** [fMultivar.so] Error 1 
>> ERROR: compilation failed for package 'fMultivar' 
>> ** Removing '/usr/local/lib/R/site-library/fMultivar' 
>> 
>> The downloaded packages are in 
>> /tmp/RtmpXxDoFd/downloaded_packages 
>> Warning message: 
>> installation of package 'fMultivar' had non-zero exit status in: 
>> install.packages("fMultivar") 
> 
>It is a FAQ for Debian and Ubuntu -- you "forgot" to install 
>r-base-dev which provides a fairly complete development emv. for R on 
>Debian / Ubuntu, so do 
> 
> $ sudo apt-get install r-base-dev 
> 
>Besides, given that there _is_ a source package, you could also use 
>its information on Build-Dependencies: 
> 
> $ sudo apt-get build-dep r-cran-fmultivar 
> 
>Hth, Dirk 
> 
>> > 
>> 
>> Thanks in advance for any help! 
>> Gilberto. 
>> 
>> 
> 
>> ______________________________________________ 
>> R-help em stat.math.ethz.ch mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-help 
>> PLEASE do read the posting guide 
>http://www.R-project.org/posting-guide.html 
>> and provide commented, minimal, self-contained, reproducible code. 
> 
>-- 
>Hell, there are no rules here - we're trying to accomplish something. 
> -- Thomas A. Edison 
> 
>______________________________________________ 
>R-help em stat.math.ethz.ch mailing list 
>https://stat.ethz.ch/mailman/listinfo/r-help 
>PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html 
>and provide commented, minimal, self-contained, reproducible code. 
> 
>---------- 



From hb at stat.berkeley.edu  Thu Dec 14 21:14:23 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Fri, 15 Dec 2006 07:14:23 +1100
Subject: [R] How do I create an object in the Global environment from a
	function
In-Reply-To: <458146A7.4000007@sun.ac.za>
References: <OF3BBF1ACA.6F42DA61-ON80257244.0042305F-80257244.004374A7@iop.kcl.ac.uk>
	<458146A7.4000007@sun.ac.za>
Message-ID: <59d7961d0612141214j5a6ce1ah61d77113ace003f0@mail.gmail.com>

Please note that help("<<-") says:

"The operators '<<-' and '->>' cause a search to made through the
     environment for an existing definition of the variable being
     assigned.  If such a variable is found (and its binding is not
     locked) then its value is redefined, otherwise assignment takes
     place in the global environment."

Thus, if you really want to make sure to assign it to the global
environment you should do:

  assign("b", value, envir=globalenv())

/Henrik

On 12/14/06, Rainer M Krug <RKrug at sun.ac.za> wrote:
> Timothy.Mak at iop.kcl.ac.uk wrote:
> > Hi all,
> >
> > Say I have created an object b in my function
> >
> > myfunc <- function() b <- 34
>
> myfunc <- function() b <<- 34
>                       ---------
>
> Rainer
>
> >
> > How can I make b an object in the Global environment and not just in the
> > environment of myfunc?
> >
> > Thanks,
> >
> > Tim
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
> --
> Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
> Biology (UCT)
>
> Department of Conservation Ecology and Entomology
> University of Stellenbosch
> Matieland 7602
> South Africa
>
> Tel:            +27 - (0)72 808 2975 (w)
> Fax:            +27 - (0)86 516 2782
> Fax:            +27 - (0)21 808 3304 (w)
> Cell:           +27 - (0)83 9479 042
>
> email:  RKrug at sun.ac.za
>         Rainer at krugs.de
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Roy.Mendelssohn at noaa.gov  Thu Dec 14 21:21:07 2006
From: Roy.Mendelssohn at noaa.gov (Roy Mendelssohn)
Date: Thu, 14 Dec 2006 12:21:07 -0800
Subject: [R] persistant: Matlab->R
In-Reply-To: <00da01c71fbb$f4e37040$6400a8c0@DD4XFW31>
References: <00da01c71fbb$f4e37040$6400a8c0@DD4XFW31>
Message-ID: <p06230912c1a76279646f@[161.55.17.183]>

At 3:10 PM -0500 12/14/06, Charles Annis, P.E. wrote:
>It might be helpful to those not familiar with Matlab to tell us what
>function "persistent" does.
>
>Charles Annis, P.E.
>
>Charles.Annis at StatisticalEngineering.com
>phone: 561-352-9699
>eFax:  614-455-3265
>http://www.StatisticalEngineering.com


Independent response  (I was not the original  poster)

  help persistent
  PERSISTENT Define persistent variable.
     PERSISTENT X Y Z defines X, Y, and Z as variables that are local
     to the function in which they are declared yet their values are
     retained in memory between calls to the function.  Persistent
     variables are similar to global variables because MATLAB creates
     permanent storage for both.  They differ from global variables in
     that persistent variables are known only to the function in which
     they are declared.  This prevents persistent variables from being
     changed by other functions or from the MATLAB command line.

     Persistent variables are cleared when the M-file is cleared from
     memory or when the M-file is changed.  To keep an M-file in memory
     until MATLAB quits, use MLOCK.

     If the persistent variable does not exist the first time you issue
     the PERSISTENT statement, it will be initialized to the empty matrix.

     It is an error to declare a variable persistent if a variable with
     the same name exists in the current workspace.

     See also global, clear, mlock, munlock, mislocked.


     Reference page in Help browser
        doc persistent

-- 
**********************
"The contents of this message do not reflect any position of the U.S. 
Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
1352 Lighthouse Avenue
Pacific Grove, CA 93950-2097

e-mail: Roy.Mendelssohn at noaa.gov (Note new e-mail address)
voice: (831)-648-9029
fax: (831)-648-8440
www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."


From h.wickham at gmail.com  Thu Dec 14 21:21:15 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 14 Dec 2006 12:21:15 -0800
Subject: [R] two connected graphs
In-Reply-To: <FEDA5AC6-A9BC-4D3F-BAEA-F87FFF161279@soc.soton.ac.uk>
References: <FEDA5AC6-A9BC-4D3F-BAEA-F87FFF161279@soc.soton.ac.uk>
Message-ID: <f8e6ff050612141221j10b1f27ak5a4b86cd1fe152d2@mail.gmail.com>

If you're not already familiar with M & N plots (by Diaconis and
Friedman), you should have a look at:
http://www.slac.stanford.edu/cgi-wrap/getdoc/slac-pub-2495.pdf

Hadley

On 12/14/06, Robin Hankin <r.hankin at noc.soton.ac.uk> wrote:
> Hi
>
> I have two datasets, A and B, consisting of two columns of numbers
> representing x and y coordinates.
>
> They have 10 and 6 rows respectively.
>
> I want to plot two scattergraphs, one above the other.
>
> The lower graph to contain A (10 points) and the upper
> graph to contain B (six points).
>
> The x-axes of the two graphs must line up.
>
> I then want to draw straight lines that connect points
> of  B to a particular point (or points)  of A.
>
> How do I do this?
>
>
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>   tel  023-8059-7743
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From cberry at tajo.ucsd.edu  Thu Dec 14 21:33:39 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Thu, 14 Dec 2006 12:33:39 -0800
Subject: [R] persistant: Matlab->R
In-Reply-To: <20061214181330.23060.qmail@web28115.mail.ukl.yahoo.com>
References: <20061214181330.23060.qmail@web28115.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.64.0612141230570.17829@tajo.ucsd.edu>


It is just my guess that the 'open.account' example in 10.7 Scope of 
Introduciton to R is what you are after.

If I understand what 'presistent' means, the 'total' in the example is 
approximately equal to a persistent variable.


On Thu, 14 Dec 2006, Bernard Gregory wrote:

> Dear list members,
>
> Could anyone tell me if there is an equivalent of the Matlab declaration 'persistant' in R?
>
> Thank you very much,
>
> Bernard Gregorry.
> (Matlaber converted to R).
>
>
> ---------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717


From deepayan.sarkar at gmail.com  Thu Dec 14 21:39:44 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 14 Dec 2006 12:39:44 -0800
Subject: [R] xyplot: discrete points + continuous curve per panel
In-Reply-To: <7867892.post@talk.nabble.com>
References: <7867892.post@talk.nabble.com>
Message-ID: <eb555e660612141239o707f4bc1x3b0923b08dc59e44@mail.gmail.com>

On 12/13/06, RMan54 <RMan54 at cox.net> wrote:
>
> I have a number of x, y observations (Time, Conc) for a number of Subjects
> (with subject number Subj) and Doses. I can plot the individual points with
> xyplot fine:
>
> xyplot(Conc ~ Time | Subj,
>          Groups=Dose,
>          data=myData,
>          panel =  function(x,y) {
>               panel.xyplot(x, y)
>               panel.superpose(???) # Needs more here
>          }
> )
>
> I also like to plot on each panel (there is one Subj per panel) a continuous
> curve with predictions that I can calculate from a rather complicated
> function:
>
> myPred <- (time, subj, dose) {
>        returns predicted value of Conc for a given time, subj and dose
> }
>
> The predicted curves are different for each panel.
>
> How do I plot the predictions? I have tried to add panel.superinpose in the
> xyplot portion but can't link to the myPred function. I also know about
> panel.curve but couldn't make it work.
>
> My attempt is to calculate the predictions on the fly. Is this possible? Or
> do I need to calculate all predictions first and put the results in a data
> frame.

Depends on how much work you are willing to do. There is no reason for
panel.curve to not work, provided you give it a "curve" to plot. This
is normally done in the form of a vectorized function of one variable,
which will be called with a vector of values spanning the x-axis of
your plot. It is your responsibility to construct such a function
inside each panel (presumably it would involve your myPred function).

The easy way, that generally works well for longitudinal data (with
increasing x values within a panel), is to add a column of predicted
values to your data frame. For most model fitting routines in R, the
paradigm is:

fm <- some.model(y ~ whatever, data = mydata, ...)
mydata$fit <- fitted(fm)

xyplot(y + fit ~ whatever,
       type = list("p", "l"), distribute.type = TRUE)

A real example being:

library(lme4)
data(Oxboys, package = "nlme")
Oxboys$fit <- fitted(lmer(height ~ age + (1|Subject), data = Oxboys))
xyplot(height + fit ~ age | Subject, Oxboys,
       type = c("p", "l"), distribute.type = TRUE,
       aspect = "xy")


Things will be more complicated if you already have a grouping
variable (the solution is to pass down the vector of fitted values to
the panel function and use 'subscripts' to retrieve the ones that
belong in the panel).

-Deepayan


From jzedlewski at hbs.edu  Thu Dec 14 21:57:41 2006
From: jzedlewski at hbs.edu (John Zedlewski)
Date: Thu, 14 Dec 2006 15:57:41 -0500
Subject: [R] max.col: bug or just oddity?
Message-ID: <5918c61f0612141257i2e0c4ffdl387c1b854a37ed23@mail.gmail.com>

I've noticed that the max.col function with the default "random"
option often gives unexpected results. For instance, in this test, it
seems clear what the answer should be:

> # second col should always be max
> x1 = cbind(1:10, 2:11, -Inf)
>
> # this works fine
> max.col(x1, "first")
 [1] 2 2 2 2 2 2 2 2 2 2
>
> # this gives random answers
> max.col(x1)
> [1] 3 1 1 2 3 3 1 3 1 1

Ouch! max.col is randomizing across all values.
Even without infinite values, something similar can happen:

> # test 2 --- tolerance problems
>
> # clearly column 3 is the max
> x1 = cbind(-1e9 * 1:10, 1:10, 2:11)
>
> # again, first method works:
> max.col(x1, "first")
 [1] 3 3 3 3 3 3 3 3 3 3
>
> # but random doesn't
> max.col(x1)
 [1] 2 3 2 3 3 2 2 2 3 2
>

The max.col docs say " there is a relative tolerance of 1e-5, relative
to the largest entry in the row", but it's really using the maximum
absolute value entry in the row (appl/maxcol.c, line 35 in R 2.4.0).
Is this necessary for some sort of S-plus compatibility? If so, I
think it would be good to make this absolute value property very clear
in the docs, since it can cause subtle bugs (and did for me).

Personally, I think the behavior is much nicer with the following patch:

--- rplain/R-2.4.0/src/appl/maxcol.c    2006-04-09 18:19:58.000000000 -0400
+++ R-2.4.0/src/appl/maxcol.c   2006-12-14 15:30:56.000000000 -0500
@@ -26,13 +26,14 @@
        do_rand = *ties_meth == 1;

     for (r = 0; r < n_r; r++) {
-       /* first check row for any NAs and find the largest abs(entry) */
+       /* first check row for any NAs and find the largest entry */
        large = 0.0;
        isna = FALSE;
        for (c = 0; c < *nc; c++) {
            a = matrix[r + c * n_r];
            if (ISNAN(a)) { isna = TRUE; break; }
-           if (do_rand) large = fmax2(large, fabs(a));
+           if (!R_FINITE(a)) continue;
+           if (do_rand) large = fmax2(large, a);
        }
        if (isna) { maxes[r] = NA_INTEGER; continue; }

--------------------------------------- END
-------------------------------------------------

This gives the expected behavior in the two examples above.


From fisk at bowdoin.edu  Thu Dec 14 22:06:53 2006
From: fisk at bowdoin.edu (steve)
Date: Thu, 14 Dec 2006 16:06:53 -0500
Subject: [R] rotated histogram
Message-ID: <4581BCED.5010804@bowdoin.edu>

I guess it's ok; I was wondering why there is no argument to hist that 
allows rotation (e.g. rotated=TRUE)

Steve


Marc Schwartz wrote:
 > On Thu, 2006-12-14 at 13:53 -0500, steve wrote:
 >> I would like to make a scatterplot, with a histogram of the x and y
 >> variables above and to the right . I can use layout to set up the 
areas,
 >> and hist(x,y) works fine for the upper histogram. However, I need a
 >> rotated histogram on the right, and I don't know how to do this. I've
 >> seen a solution with a bar plot on the right, but I'd like to use a
 >> histogram. Do you know how I can do this?
 >>
 >> Steve
 >
 > What's wrong with the example in ?layout below the comment:
 >
 > ##-- Create a scatterplot with marginal histograms -----
 >
 > ?


From Greg.Snow at intermountainmail.org  Thu Dec 14 22:12:34 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 14 Dec 2006 14:12:34 -0700
Subject: [R] persistant: Matlab->R
Message-ID: <07E228A5BE53C24CAD490193A7381BBB73993D@LP-EXCHVS07.CO.IHC.COM>

It looks like the same process can be accomplished by using 'local' and
declaring the 'persistant' variables in a local scope, then the function
within that same scope, for example:

> inc <- local( { n <- 0; function(){n <<- n + 1; return(n)} } )
> inc
function(){n <<- n + 1; return(n)}
<environment: 0x09a8fee0>
> inc()
[1] 1
> inc()
[1] 2
> inc()
[1] 3
> inc()
[1] 4

Using local in R is a little more flexible in that you can have
variables that are shared between multiple functions, but not easily
accessable to the world at large:

> n <- 5
> incdec <- local( {n <- 0;
+ list(inc=function(){ n <<- n+1; return(n) },
+ dec=function(){ n <<- n-1; return(n) }
+ )})
> incdec$inc()
[1] 1
> incdec$inc()
[1] 2
> incdec$inc()
[1] 3
> incdec$dec()
[1] 2
> incdec$dec()
[1] 1
> incdec$inc()
[1] 2
> n
[5]


Hope this helps,


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Bernard Gregory
Sent: Thursday, December 14, 2006 11:14 AM
To: r-help at stat.math.ethz.ch
Subject: [R] persistant: Matlab->R

Dear list members,

Could anyone tell me if there is an equivalent of the Matlab declaration
'persistant' in R?

Thank you very much,

Bernard Gregorry.
(Matlaber converted to R).

 		
---------------------------------

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From btyner at stat.purdue.edu  Thu Dec 14 22:23:10 2006
From: btyner at stat.purdue.edu (Benjamin Tyner)
Date: Thu, 14 Dec 2006 16:23:10 -0500
Subject: [R]  Better way to change the name of a column in a dataframe?
Message-ID: <4581C0BE.5010301@stat.purdue.edu>

Ben,

Unless I misunderstand your question, why not just use

names(frame)[3]<-"col3"


From fisk at bowdoin.edu  Thu Dec 14 22:37:51 2006
From: fisk at bowdoin.edu (steve)
Date: Thu, 14 Dec 2006 16:37:51 -0500
Subject: [R] Nicely formatted tables
Message-ID: <4581C42F.2020007@bowdoin.edu>

If I use latex(summary(X)) where X is a data frame with four
variables I get something like

    Rainfall       Education         Popden        Nonwhite    
 Min.   :10.00   Min.   : 9.00   Min.   :1441   Min.   : 0.80  
 1st Qu.:32.75   1st Qu.:10.40   1st Qu.:3104   1st Qu.: 4.95  
 Median :38.00   Median :11.05   Median :3567   Median :10.40  
 Mean   :37.37   Mean   :10.97   Mean   :3866   Mean   :11.87  
 3rd Qu.:43.25   3rd Qu.:11.50   3rd Qu.:4520   3rd Qu.:15.65  
 Max.   :60.00   Max.   :12.30   Max.   :9699   Max.   :38.50  


where the row headings are repeated four times times.
Is there an easy way to get a nicely formatted table,
something like

        Rainfall     Education   Popden    Nonwhite    
 Min.     10.00       9.00        1441        0.80  
 1st Qu.  32.75      10.40        3104        4.95  
 Median   38.00      11.05        3567       10.40  
 Mean     37.37      10.97        3866       11.87  
 3rd Qu.  43.25      11.50        4520       15.65  
 Max.     60.00      12.30        9699       38.50  


Steve


From p.dalgaard at biostat.ku.dk  Thu Dec 14 22:58:41 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 14 Dec 2006 22:58:41 +0100
Subject: [R] Nicely formatted tables
In-Reply-To: <4581C42F.2020007@bowdoin.edu>
References: <4581C42F.2020007@bowdoin.edu>
Message-ID: <4581C911.2060109@biostat.ku.dk>

steve wrote:
> If I use latex(summary(X)) where X is a data frame with four
> variables I get something like
>
>     Rainfall       Education         Popden        Nonwhite    
>  Min.   :10.00   Min.   : 9.00   Min.   :1441   Min.   : 0.80  
>  1st Qu.:32.75   1st Qu.:10.40   1st Qu.:3104   1st Qu.: 4.95  
>  Median :38.00   Median :11.05   Median :3567   Median :10.40  
>  Mean   :37.37   Mean   :10.97   Mean   :3866   Mean   :11.87  
>  3rd Qu.:43.25   3rd Qu.:11.50   3rd Qu.:4520   3rd Qu.:15.65  
>  Max.   :60.00   Max.   :12.30   Max.   :9699   Max.   :38.50  
>
>
> where the row headings are repeated four times times.
> Is there an easy way to get a nicely formatted table,
> something like
>
>         Rainfall     Education   Popden    Nonwhite    
>  Min.     10.00       9.00        1441        0.80  
>  1st Qu.  32.75      10.40        3104        4.95  
>  Median   38.00      11.05        3567       10.40  
>  Mean     37.37      10.97        3866       11.87  
>  3rd Qu.  43.25      11.50        4520       15.65  
>  Max.     60.00      12.30        9699       38.50  
>
>
>   
Hmm, no. Not without further ado. The function summary.data.frame 
produces a table with character entries like "Min. : 1.00 ".

To do better, you first have to note that it can only possibly work for 
purely numeric data frames. If you have one of those, then you might 
base something off sapply(X, summary), except that it won't work if only 
some columns have NA's. Here's an idea:

> my.summary <- function(x){s <- summary(x); if (length(s)==6) 
       c(s,"NA's"=0) else s}
> sapply(airquality,my.summary)
         Ozone Solar.R   Wind  Temp Month  Day
Min.      1.00     7.0  1.700 56.00 5.000  1.0
1st Qu.  18.00   115.8  7.400 72.00 6.000  8.0
Median   31.50   205.0  9.700 79.00 7.000 16.0
Mean     42.13   185.9  9.958 77.88 6.993 15.8
3rd Qu.  63.25   258.8 11.500 85.00 8.000 23.0
Max.    168.00   334.0 20.700 97.00 9.000 31.0
NA's     37.00     7.0  0.000  0.00 0.000  0.0

However, there's an issue with the NA count getting displayed to
three decimal places...


From marc_schwartz at comcast.net  Thu Dec 14 23:01:34 2006
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 14 Dec 2006 16:01:34 -0600
Subject: [R] Nicely formatted tables
In-Reply-To: <4581C42F.2020007@bowdoin.edu>
References: <4581C42F.2020007@bowdoin.edu>
Message-ID: <1166133694.4516.68.camel@localhost.localdomain>

On Thu, 2006-12-14 at 16:37 -0500, steve wrote:
> If I use latex(summary(X)) where X is a data frame with four
> variables I get something like
> 
>     Rainfall       Education         Popden        Nonwhite    
>  Min.   :10.00   Min.   : 9.00   Min.   :1441   Min.   : 0.80  
>  1st Qu.:32.75   1st Qu.:10.40   1st Qu.:3104   1st Qu.: 4.95  
>  Median :38.00   Median :11.05   Median :3567   Median :10.40  
>  Mean   :37.37   Mean   :10.97   Mean   :3866   Mean   :11.87  
>  3rd Qu.:43.25   3rd Qu.:11.50   3rd Qu.:4520   3rd Qu.:15.65  
>  Max.   :60.00   Max.   :12.30   Max.   :9699   Max.   :38.50  
> 
> 
> where the row headings are repeated four times times.
> Is there an easy way to get a nicely formatted table,
> something like
> 
>         Rainfall     Education   Popden    Nonwhite    
>  Min.     10.00       9.00        1441        0.80  
>  1st Qu.  32.75      10.40        3104        4.95  
>  Median   38.00      11.05        3567       10.40  
>  Mean     37.37      10.97        3866       11.87  
>  3rd Qu.  43.25      11.50        4520       15.65  
>  Max.     60.00      12.30        9699       38.50  
> 
> 
> Steve

The problem is that summary(), as above, returns a character based
table/matrix.  For example, using the 'iris' data set:

> summary(iris[, 1:4])
  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
 Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  
 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  
 Median :5.800   Median :3.000   Median :4.350   Median :1.300  
 Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  
 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  
 Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  


> str(summary(iris[, 1:4]))
 'table' chr [1:6, 1:4] "Min.   :4.300  " "1st Qu.:5.100  " ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:6] "" "" "" "" ...
  ..$ : chr [1:4] " Sepal.Length" " Sepal.Width" " Petal.Length" " Petal.Width"


Hence, the numbers are not separate from the labels, but part of the
table elements. 

I might be tempted to construct a better underlying function that just
returned the summary statistics as unformatted numbers in a matrix. It
seems to me that there are such functions, for example in the Hmisc and
the doBY packages, on CRAN. Since you are using latex(), you already
have Hmisc.

That being said, you could brute force something like this:

# See ?strsplit and ?sapply

mat <- matrix(sapply(strsplit(summary(iris[, 1:4]), ":"), "[[", 2), 
              ncol = 4)

> mat
     [,1]      [,2]      [,3]      [,4]     
[1,] "4.300  " "2.000  " "1.000  " "0.100  "
[2,] "5.100  " "2.800  " "1.600  " "0.300  "
[3,] "5.800  " "3.000  " "4.350  " "1.300  "
[4,] "5.843  " "3.057  " "3.758  " "1.199  "
[5,] "6.400  " "3.300  " "5.100  " "1.800  "
[6,] "7.900  " "4.400  " "6.900  " "2.500  "


Then add the row and column titles:

rownames(mat) <- c("Min", "1st Qu", "Median", "Mean", "3rd Qu", "Max")

colnames(mat) <- colnames(iris[1:4])


> mat
       Sepal.Length Sepal.Width Petal.Length Petal.Width
Min    "4.300  "    "2.000  "   "1.000  "    "0.100  "  
1st Qu "5.100  "    "2.800  "   "1.600  "    "0.300  "  
Median "5.800  "    "3.000  "   "4.350  "    "1.300  "  
Mean   "5.843  "    "3.057  "   "3.758  "    "1.199  "  
3rd Qu "6.400  "    "3.300  "   "5.100  "    "1.800  "  
Max    "7.900  "    "4.400  "   "6.900  "    "2.500  "  


> latex(mat, file = "")
% latex.default(mat, file = "") 
%
\begin{table}[!tbp]
 \begin{center}
 \begin{tabular}{lllll}\hline\hline
\multicolumn{1}{l}{mat}&
\multicolumn{1}{c}{Sepal.Length}&
\multicolumn{1}{c}{Sepal.Width}&
\multicolumn{1}{c}{Petal.Length}&
\multicolumn{1}{c}{Petal.Width}
\\ \hline
Min&4.300  &2.000  &1.000  &0.100  \\
1st Qu&5.100  &2.800  &1.600  &0.300  \\
Median&5.800  &3.000  &4.350  &1.300  \\
Mean&5.843  &3.057  &3.758  &1.199  \\
3rd Qu&6.400  &3.300  &5.100  &1.800  \\
Max&7.900  &4.400  &6.900  &2.500  \\
\hline
\end{tabular}

\end{center}

\end{table}



HTH,

Marc Schwartz


From mike.prager at noaa.gov  Thu Dec 14 23:05:20 2006
From: mike.prager at noaa.gov (Mike Prager)
Date: Thu, 14 Dec 2006 17:05:20 -0500
Subject: [R] Better way to change the name of a column in a dataframe?
References: <CA612484A337C6479EA341DF9EEE14AC05B7CDB5@hercules.ssainfo>
Message-ID: <7dh3o2d91ruct20ehguap5vvokeudlm292@4ax.com>

"Ben Fairbank" <BEN at SSANET.COM> wrote:

> [...] I want to correct or otherwise change the name of one of the
> columns, I can do so with 
> 
> > dimnames(frame)[[2]][which(dimnames(frame)[[2]]=="cmlo3")] <- "col3"
> 
> This seems cumbersome and not very intuitive.  How can one accomplish
> this more simply?

This is slightly simpler than what you had:

      names(frame)[which(names(frame) == "cmlo3")] <- "col3"

There are probably better ways still. 

-- 
Mike Prager, NOAA, Beaufort, NC
* Opinions expressed are personal and not represented otherwise.
* Any use of tradenames does not constitute a NOAA endorsement.


From philipp.pagel.lists at t-online.de  Thu Dec 14 23:05:50 2006
From: philipp.pagel.lists at t-online.de (Philipp Pagel)
Date: Thu, 14 Dec 2006 23:05:50 +0100
Subject: [R] legend/plotmath/substitute problem
Message-ID: <20061214220550.GA11605@gsf.de>


	Dear R Experts,

I am trying to produce a legend for a series of plots which are
generated in a loop. The legend is supposed to look like this:

2000: gamma=1.8

where gamma is replaced by the greek letter and both the year and the
value of gamma are stored in variables.

Everything works fine as long as I have only one data series:

year = 2001
g = 1.9
plot(1)
legend('top', legend=substitute(paste(year, ': ', gamma, '=', g), list(year=year, g=g)) )


My problem starts, when I want to put more than one series of data in
the plot and accordingly need one legend row per data series:

year1 = 2001
year2 = 2005
g1 = 1.9
g2 = 1.7
plot(1)
legend('top', 
	legend=c(
		substitute(paste(year, ': ', gamma, '=', g), list(year=year1, g=g1)),
		substitute(paste(year, ': ', gamma, '=', g), list(year=year2, g=g2))
	)
)

This obviously does not produce the desired result. Apparently, I am not
generating a list of expressions, as intended. So I thought, maybe R uses a
variety of the recycling rule here and tried:

year = c(2001, 2005)
g = c(1.9, 1.7)
plot(1)
legend('top',
    legend=list(
        substitute(paste(year, ': ', gamma, '=', g), list(year=year, g=g)),
    )
)

No succes, either...

I have read and re-read the documentation for legend, expression, substitute
and plotmath but can't figure it out. Even drinking a cup of tea prepared from
fine-cut man page printouts didn't lead to satori.

I'm probably missing something simple. Any hints are highly appreciated.

Thanks
	Philipp

-- 
Dr. Philipp Pagel                            Tel.  +49-8161-71 2131
Dept. of Genome Oriented Bioinformatics      Fax.  +49-8161-71 2186
Technical University of Munich
85350 Freising, Germany
http://mips.gsf.de/staff/pagel


From Max.Kuhn at pfizer.com  Thu Dec 14 23:09:18 2006
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Thu, 14 Dec 2006 17:09:18 -0500
Subject: [R] Nicely formatted tables
Message-ID: <71257D09F114DA4A8E134DEAC70F25D306ED58B7@groamrexm03.amer.pfizer.com>

How about:

> apply(iris[, 1:4], 2, summary)
        Sepal.Length Sepal.Width Petal.Length Petal.Width
Min.           4.300       2.000        1.000       0.100
1st Qu.        5.100       2.800        1.600       0.300
Median         5.800       3.000        4.350       1.300
Mean           5.843       3.057        3.758       1.199
3rd Qu.        6.400       3.300        5.100       1.800
Max.           7.900       4.400        6.900       2.500

Max 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marc Schwartz
Sent: Thursday, December 14, 2006 5:02 PM
To: steve
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Nicely formatted tables

On Thu, 2006-12-14 at 16:37 -0500, steve wrote:
> If I use latex(summary(X)) where X is a data frame with four
> variables I get something like
> 
>     Rainfall       Education         Popden        Nonwhite    
>  Min.   :10.00   Min.   : 9.00   Min.   :1441   Min.   : 0.80  
>  1st Qu.:32.75   1st Qu.:10.40   1st Qu.:3104   1st Qu.: 4.95  
>  Median :38.00   Median :11.05   Median :3567   Median :10.40  
>  Mean   :37.37   Mean   :10.97   Mean   :3866   Mean   :11.87  
>  3rd Qu.:43.25   3rd Qu.:11.50   3rd Qu.:4520   3rd Qu.:15.65  
>  Max.   :60.00   Max.   :12.30   Max.   :9699   Max.   :38.50  
> 
> 
> where the row headings are repeated four times times.
> Is there an easy way to get a nicely formatted table,
> something like
> 
>         Rainfall     Education   Popden    Nonwhite    
>  Min.     10.00       9.00        1441        0.80  
>  1st Qu.  32.75      10.40        3104        4.95  
>  Median   38.00      11.05        3567       10.40  
>  Mean     37.37      10.97        3866       11.87  
>  3rd Qu.  43.25      11.50        4520       15.65  
>  Max.     60.00      12.30        9699       38.50  
> 
> 
> Steve

The problem is that summary(), as above, returns a character based
table/matrix.  For example, using the 'iris' data set:

> summary(iris[, 1:4])
  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
 Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  
 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  
 Median :5.800   Median :3.000   Median :4.350   Median :1.300  
 Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  
 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  
 Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  


> str(summary(iris[, 1:4]))
 'table' chr [1:6, 1:4] "Min.   :4.300  " "1st Qu.:5.100  " ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:6] "" "" "" "" ...
  ..$ : chr [1:4] " Sepal.Length" " Sepal.Width" " Petal.Length" "
Petal.Width"


Hence, the numbers are not separate from the labels, but part of the
table elements. 

I might be tempted to construct a better underlying function that just
returned the summary statistics as unformatted numbers in a matrix. It
seems to me that there are such functions, for example in the Hmisc and
the doBY packages, on CRAN. Since you are using latex(), you already
have Hmisc.

That being said, you could brute force something like this:

# See ?strsplit and ?sapply

mat <- matrix(sapply(strsplit(summary(iris[, 1:4]), ":"), "[[", 2), 
              ncol = 4)

> mat
     [,1]      [,2]      [,3]      [,4]     
[1,] "4.300  " "2.000  " "1.000  " "0.100  "
[2,] "5.100  " "2.800  " "1.600  " "0.300  "
[3,] "5.800  " "3.000  " "4.350  " "1.300  "
[4,] "5.843  " "3.057  " "3.758  " "1.199  "
[5,] "6.400  " "3.300  " "5.100  " "1.800  "
[6,] "7.900  " "4.400  " "6.900  " "2.500  "


Then add the row and column titles:

rownames(mat) <- c("Min", "1st Qu", "Median", "Mean", "3rd Qu", "Max")

colnames(mat) <- colnames(iris[1:4])


> mat
       Sepal.Length Sepal.Width Petal.Length Petal.Width
Min    "4.300  "    "2.000  "   "1.000  "    "0.100  "  
1st Qu "5.100  "    "2.800  "   "1.600  "    "0.300  "  
Median "5.800  "    "3.000  "   "4.350  "    "1.300  "  
Mean   "5.843  "    "3.057  "   "3.758  "    "1.199  "  
3rd Qu "6.400  "    "3.300  "   "5.100  "    "1.800  "  
Max    "7.900  "    "4.400  "   "6.900  "    "2.500  "  


> latex(mat, file = "")
% latex.default(mat, file = "") 
%
\begin{table}[!tbp]
 \begin{center}
 \begin{tabular}{lllll}\hline\hline
\multicolumn{1}{l}{mat}&
\multicolumn{1}{c}{Sepal.Length}&
\multicolumn{1}{c}{Sepal.Width}&
\multicolumn{1}{c}{Petal.Length}&
\multicolumn{1}{c}{Petal.Width}
\\ \hline
Min&4.300  &2.000  &1.000  &0.100  \\
1st Qu&5.100  &2.800  &1.600  &0.300  \\
Median&5.800  &3.000  &4.350  &1.300  \\
Mean&5.843  &3.057  &3.758  &1.199  \\
3rd Qu&6.400  &3.300  &5.100  &1.800  \\
Max&7.900  &4.400  &6.900  &2.500  \\
\hline
\end{tabular}

\end{center}

\end{table}



HTH,

Marc Schwartz

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From marc_schwartz at comcast.net  Thu Dec 14 23:18:17 2006
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 14 Dec 2006 16:18:17 -0600
Subject: [R] Nicely formatted tables
In-Reply-To: <71257D09F114DA4A8E134DEAC70F25D306ED58B7@groamrexm03.amer.pfizer.com>
References: <71257D09F114DA4A8E134DEAC70F25D306ED58B7@groamrexm03.amer.pfizer.com>
Message-ID: <1166134697.4516.73.camel@localhost.localdomain>

On Thu, 2006-12-14 at 17:09 -0500, Kuhn, Max wrote:
> How about:
> 
> > apply(iris[, 1:4], 2, summary)
>         Sepal.Length Sepal.Width Petal.Length Petal.Width
> Min.           4.300       2.000        1.000       0.100
> 1st Qu.        5.100       2.800        1.600       0.300
> Median         5.800       3.000        4.350       1.300
> Mean           5.843       3.057        3.758       1.199
> 3rd Qu.        6.400       3.300        5.100       1.800
> Max.           7.900       4.400        6.900       2.500
> 
> Max 

<snip>

Yep, that will do it too Max.  :-)

Thanks for pointing it out.

Clearly, in need of more oxygen to the old cranium...

Regards,

Marc


From A.Robinson at ms.unimelb.edu.au  Thu Dec 14 23:24:08 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 15 Dec 2006 09:24:08 +1100
Subject: [R] Better way to change the name of a column in a dataframe?
In-Reply-To: <7dh3o2d91ruct20ehguap5vvokeudlm292@4ax.com>
References: <CA612484A337C6479EA341DF9EEE14AC05B7CDB5@hercules.ssainfo>
	<7dh3o2d91ruct20ehguap5vvokeudlm292@4ax.com>
Message-ID: <20061214222408.GB4342@ms.unimelb.edu.au>

Hi,

names(frame)[names(frame) == "cmlo3"] <- "col3"

should also work

Cheers

Andrew

On Thu, Dec 14, 2006 at 05:05:20PM -0500, Mike Prager wrote:
> "Ben Fairbank" <BEN at SSANET.COM> wrote:
> 
> > [...] I want to correct or otherwise change the name of one of the
> > columns, I can do so with 
> > 
> > > dimnames(frame)[[2]][which(dimnames(frame)[[2]]=="cmlo3")] <- "col3"
> > 
> > This seems cumbersome and not very intuitive.  How can one accomplish
> > this more simply?
> 
> This is slightly simpler than what you had:
> 
>       names(frame)[which(names(frame) == "cmlo3")] <- "col3"
> 
> There are probably better ways still. 
> 
> -- 
> Mike Prager, NOAA, Beaufort, NC
> * Opinions expressed are personal and not represented otherwise.
> * Any use of tradenames does not constitute a NOAA endorsement.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/


From frainj at gmail.com  Fri Dec 15 00:19:34 2006
From: frainj at gmail.com (John C Frain)
Date: Thu, 14 Dec 2006 23:19:34 +0000
Subject: [R] Install R in Linux
In-Reply-To: <20061213102816.35197.qmail@web28007.mail.ukl.yahoo.com>
References: <20061213102816.35197.qmail@web28007.mail.ukl.yahoo.com>
Message-ID: <fad888a10612141519i232a698dk2b187111aefa0c44@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061214/832bfdae/attachment.pl 

From murdoch at stats.uwo.ca  Fri Dec 15 00:25:49 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 14 Dec 2006 18:25:49 -0500
Subject: [R] legend/plotmath/substitute problem
In-Reply-To: <20061214220550.GA11605@gsf.de>
References: <20061214220550.GA11605@gsf.de>
Message-ID: <4581DD7D.3060802@stats.uwo.ca>

On 12/14/2006 5:05 PM, Philipp Pagel wrote:
> 	Dear R Experts,
> 
> I am trying to produce a legend for a series of plots which are
> generated in a loop. The legend is supposed to look like this:
> 
> 2000: gamma=1.8
> 
> where gamma is replaced by the greek letter and both the year and the
> value of gamma are stored in variables.
> 
> Everything works fine as long as I have only one data series:
> 
> year = 2001
> g = 1.9
> plot(1)
> legend('top', legend=substitute(paste(year, ': ', gamma, '=', g), list(year=year, g=g)) )
> 
> 
> My problem starts, when I want to put more than one series of data in
> the plot and accordingly need one legend row per data series:
> 
> year1 = 2001
> year2 = 2005
> g1 = 1.9
> g2 = 1.7
> plot(1)
> legend('top', 
> 	legend=c(
> 		substitute(paste(year, ': ', gamma, '=', g), list(year=year1, g=g1)),
> 		substitute(paste(year, ': ', gamma, '=', g), list(year=year2, g=g2))
> 	)
> )
> 
> This obviously does not produce the desired result. Apparently, I am not
> generating a list of expressions, as intended. So I thought, maybe R uses a
> variety of the recycling rule here and tried:

The problem is that legend wants an expression, but substitute() isn't 
returning one, it's returning a call, and c(call1,call2) produces a list 
of two calls, not an expression holding two calls.  So the following 
would work, but there might be something more elegant:

year1 = 2001
year2 = 2005
g1 = 1.9
g2 = 1.7
plot(1)
legend('top',
	legend=c(
		as.expression(substitute(paste(year, ': ', gamma, '=', g), 
list(year=year1, g=g1))),
		as.expression(substitute(paste(year, ': ', gamma, '=', g), 
list(year=year2, g=g2)))
	)
)

Duncan Murdoch

> 
> year = c(2001, 2005)
> g = c(1.9, 1.7)
> plot(1)
> legend('top',
>     legend=list(
>         substitute(paste(year, ': ', gamma, '=', g), list(year=year, g=g)),
>     )
> )
> 
> No succes, either...
> 
> I have read and re-read the documentation for legend, expression, substitute
> and plotmath but can't figure it out. Even drinking a cup of tea prepared from
> fine-cut man page printouts didn't lead to satori.
> 
> I'm probably missing something simple. Any hints are highly appreciated.
> 
> Thanks
> 	Philipp
>


From p.pagel at gsf.de  Fri Dec 15 00:33:31 2006
From: p.pagel at gsf.de (Philipp Pagel)
Date: Fri, 15 Dec 2006 00:33:31 +0100
Subject: [R] legend/plotmath/substitute problem
In-Reply-To: <4581DD7D.3060802@stats.uwo.ca>
References: <20061214220550.GA11605@gsf.de> <4581DD7D.3060802@stats.uwo.ca>
Message-ID: <20061214233331.GB1601@gsf.de>

On Thu, Dec 14, 2006 at 06:25:49PM -0500, Duncan Murdoch wrote:
> On 12/14/2006 5:05 PM, Philipp Pagel wrote:
> >My problem starts, when I want to put more than one series of data in
> >the plot and accordingly need one legend row per data series:
> >
> >year1 = 2001
> >year2 = 2005
> >g1 = 1.9
> >g2 = 1.7
> >plot(1)
> >legend('top', 
> >	legend=c(
> >		substitute(paste(year, ': ', gamma, '=', g), 
> >		list(year=year1, g=g1)),
> >		substitute(paste(year, ': ', gamma, '=', g), 
> >		list(year=year2, g=g2))
> >	)
> >)
> >
> >This obviously does not produce the desired result. Apparently, I am not
> >generating a list of expressions, as intended. So I thought, maybe R uses a
> >variety of the recycling rule here and tried:
> 
> The problem is that legend wants an expression, but substitute() isn't 
> returning one, it's returning a call, and c(call1,call2) produces a list 
> of two calls, not an expression holding two calls.  So the following 
> would work, but there might be something more elegant:

Thanks a lot! Learned something, again.

cu
	Philipp

-- 
Dr. Philipp Pagel                            Tel.  +49-8161-71 2131
Dept. of Genome Oriented Bioinformatics      Fax.  +49-8161-71 2186
Technical University of Munich
85350 Freising, Germany
http://mips.gsf.de/staff/pagel


From milton_ruser at yahoo.com.br  Fri Dec 15 01:01:41 2006
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Fri, 15 Dec 2006 00:01:41 +0000 (GMT)
Subject: [R] Contents of R-packages
In-Reply-To: <458131F3.1030506@optonline.net>
Message-ID: <210769.63625.qm@web56611.mail.re3.yahoo.com>

Um texto embutido e sem conjunto de caracteres especificado associado...
Nome: n?o dispon?vel
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061215/fe1d092b/attachment.pl 

From fisk at bowdoin.edu  Fri Dec 15 01:14:40 2006
From: fisk at bowdoin.edu (steve)
Date: Thu, 14 Dec 2006 19:14:40 -0500
Subject: [R] Nicely formatted tables
Message-ID: <4581E8F0.5010401@bowdoin.edu>

> apply(iris[, 1:4], 2, summary)

Nice solution!
However,  latex(apply(iris[, 1:4], 2, summary))
has the odd effect that the upper left corner  is "apply".
This is the "title", so to produce a file "abc.tex" and have an empty 
upper left corner you need

latex(apply(iris[, 1:4], 2, summary),title="",file="abc.tex")

And, since I wanted a more compact table, the following works just as 
expected:

latex(format(apply(iris[, 1:4], 2, 
summary),digits=2),title="",file="abc.tex")

thank you!

Steve


From bal44 at cornell.edu  Fri Dec 15 01:33:46 2006
From: bal44 at cornell.edu (Brooke LaFlamme)
Date: Thu, 14 Dec 2006 19:33:46 -0500 (EST)
Subject: [R] sorting by name
Message-ID: <2142364966.1166142826323.JavaMail.webber@orpheus6.dataserver.cornell.edu>

Hi all,

I'm not sure that there is really a way to do this, but I thought I'd see if anyone knew.

I have a file with 1 to n columns all named something like X1, X2, X3....Xn.

I have another file that has in one column n number of rows. Each row has a number in it (not in order; the ordering of the numbers is important but it isn't in count order).

Basically, I would like to order the columns in the first file by the numbers in the rows of the second file. So, if file#2 has these numbers in rows 1-4:

         [,1]      
 [1,]   2 
 [2,]   3 
 [3,]   1 
 [4,]   4

I would like the first file to look like this:

    X2 X3 X1 X4 
1        
 Instead of the original order:

    X1 X2 X3 X4 
1        

Is this possible? 

The point of this all is to run a stepwise linear regression that first regresses on X2, then adds in X3, X1, X4 in that order, stopping at each step to assess whether to drop one or more of the previously added variables. 

Thank you in advance for any suggestions!

Brooke LaFlamme


From gunter.berton at gene.com  Fri Dec 15 02:03:19 2006
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 14 Dec 2006 17:03:19 -0800
Subject: [R] sorting by name
In-Reply-To: <2142364966.1166142826323.JavaMail.webber@orpheus6.dataserver.cornell.edu>
Message-ID: <004e01c71fe4$cfacc780$4d908980@gne.windows.gene.com>

This is trivial.

help("[") and "An Introduction to R" will tell you how.

P.S. As earlier posts today have mentioned, stepwise variable selection is
generally a bad idea.

Bert Gunter
Genentech Nonclinical Statistics
South San Francisco, CA 94404


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Brooke LaFlamme
Sent: Thursday, December 14, 2006 4:34 PM
To: r-help at stat.math.ethz.ch
Subject: [R] sorting by name

Hi all,

I'm not sure that there is really a way to do this, but I thought I'd see if
anyone knew.

I have a file with 1 to n columns all named something like X1, X2, X3....Xn.

I have another file that has in one column n number of rows. Each row has a
number in it (not in order; the ordering of the numbers is important but it
isn't in count order).

Basically, I would like to order the columns in the first file by the
numbers in the rows of the second file. So, if file#2 has these numbers in
rows 1-4:

         [,1]      
 [1,]   2 
 [2,]   3 
 [3,]   1 
 [4,]   4

I would like the first file to look like this:

    X2 X3 X1 X4 
1        
 Instead of the original order:

    X1 X2 X3 X4 
1        

Is this possible? 

The point of this all is to run a stepwise linear regression that first
regresses on X2, then adds in X3, X1, X4 in that order, stopping at each
step to assess whether to drop one or more of the previously added
variables. 

Thank you in advance for any suggestions!

Brooke LaFlamme

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From RMan54 at cox.net  Fri Dec 15 07:13:25 2006
From: RMan54 at cox.net (RMan54)
Date: Thu, 14 Dec 2006 22:13:25 -0800 (PST)
Subject: [R] xyplot: discrete points + continuous curve per panel
In-Reply-To: <eb555e660612141239o707f4bc1x3b0923b08dc59e44@mail.gmail.com>
References: <7867892.post@talk.nabble.com>
	<eb555e660612141239o707f4bc1x3b0923b08dc59e44@mail.gmail.com>
Message-ID: <7886826.post@talk.nabble.com>


Great. I will be trying to use panel.curve and pass a custom curve function
as first argument (called test() below). I can use which. packet to get
access to the panel number to produce the correct curve for each panel but
what I really need is the active Subj (actSubj) for each panel. Not sure but
it seems that Subj is passed on to the functions but in replicates. Here is
what I came up with to eliminate the replication and to calculate activeSubj
for each panel in test(). Is this the correct way? How can  I pass on Subj
and Dose directly to test()? Thanks, Rene

test <-function(x) {
    activeSubj <- unique(Subj)[which.packet()]
    x          # returns y=x for testing only
}
      
xyplot(Conc ~ Time | Subj,
       groups=Dose,
       data = mydata,
       as.table=T,
       panel = function(x,y) {
           panel.xyplot(x,y)
           panel.curve(test, n=2)
           }
       )




Deepayan Sarkar wrote:
> 
> On 12/13/06, RMan54 <RMan54 at cox.net> wrote:
>>
>> I have a number of x, y observations (Time, Conc) for a number of
>> Subjects
>> (with subject number Subj) and Doses. I can plot the individual points
>> with
>> xyplot fine:
>>
>> xyplot(Conc ~ Time | Subj,
>>          Groups=Dose,
>>          data=myData,
>>          panel =  function(x,y) {
>>               panel.xyplot(x, y)
>>               panel.superpose(???) # Needs more here
>>          }
>> )
>>
>> I also like to plot on each panel (there is one Subj per panel) a
>> continuous
>> curve with predictions that I can calculate from a rather complicated
>> function:
>>
>> myPred <- (time, subj, dose) {
>>        returns predicted value of Conc for a given time, subj and dose
>> }
>>
>> The predicted curves are different for each panel.
>>
>> How do I plot the predictions? I have tried to add panel.superinpose in
>> the
>> xyplot portion but can't link to the myPred function. I also know about
>> panel.curve but couldn't make it work.
>>
>> My attempt is to calculate the predictions on the fly. Is this possible?
>> Or
>> do I need to calculate all predictions first and put the results in a
>> data
>> frame.
> 
> Depends on how much work you are willing to do. There is no reason for
> panel.curve to not work, provided you give it a "curve" to plot. This
> is normally done in the form of a vectorized function of one variable,
> which will be called with a vector of values spanning the x-axis of
> your plot. It is your responsibility to construct such a function
> inside each panel (presumably it would involve your myPred function).
> 
> The easy way, that generally works well for longitudinal data (with
> increasing x values within a panel), is to add a column of predicted
> values to your data frame. For most model fitting routines in R, the
> paradigm is:
> 
> fm <- some.model(y ~ whatever, data = mydata, ...)
> mydata$fit <- fitted(fm)
> 
> xyplot(y + fit ~ whatever,
>        type = list("p", "l"), distribute.type = TRUE)
> 
> A real example being:
> 
> library(lme4)
> data(Oxboys, package = "nlme")
> Oxboys$fit <- fitted(lmer(height ~ age + (1|Subject), data = Oxboys))
> xyplot(height + fit ~ age | Subject, Oxboys,
>        type = c("p", "l"), distribute.type = TRUE,
>        aspect = "xy")
> 
> 
> Things will be more complicated if you already have a grouping
> variable (the solution is to pass down the vector of fitted values to
> the panel function and use 'subscripts' to retrieve the ones that
> belong in the panel).
> 
> -Deepayan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/xyplot%3A-discrete-points-%2B-continuous-curve-per-panel-tf2818931.html#a7886826
Sent from the R help mailing list archive at Nabble.com.


From ronggui.huang at gmail.com  Fri Dec 15 08:54:04 2006
From: ronggui.huang at gmail.com (ronggui)
Date: Fri, 15 Dec 2006 15:54:04 +0800
Subject: [R] How to load Rcmd without Commander() ?
Message-ID: <38b9f0350612142354q57e5afdcr187c9da417966e1b@mail.gmail.com>

I would like to use the reliability() function in Rcmdr package, but
not the GUI, so I would to load Rcmd without Commander() running
automatically.

Is there any easy way to get it? Thanks.


-- 
Ronggui Huang
Department of Sociology
Fudan University, Shanghai, China
??????
????????????????


From j.van_den_hoff at fz-rossendorf.de  Fri Dec 15 08:58:00 2006
From: j.van_den_hoff at fz-rossendorf.de (Joerg van den Hoff)
Date: Fri, 15 Dec 2006 08:58:00 +0100
Subject: [R] Better way to change the name of a column in a dataframe?
In-Reply-To: <CA612484A337C6479EA341DF9EEE14AC05B7CDB5@hercules.ssainfo>
References: <CA612484A337C6479EA341DF9EEE14AC05B7CDB5@hercules.ssainfo>
Message-ID: <45825588.90101@fz-rossendorf.de>

Ben Fairbank wrote:
> Hello R users --
> 
>  
> 
> If I have a dataframe such as the following, named "frame" with the
> columns intended to be named col1 through col6,
> 
>  
> 
>> frame
> 
>      col1 col2 cmlo3 col4 col5 col6
> 
> [1,]    3   10     2    6    5    7
> 
> [2,]    6    8     4   10    7    1
> 
> [3,]    7    5     1    3    1    8
> 
> [4,]   10    6     5    4    9    2
> 
>  
> 
> and I want to correct or otherwise change the name of one of the
> columns, I can do so with 
> 
>  
> 
>> dimnames(frame)[[2]][which(dimnames(frame)[[2]]=="cmlo3")] <- "col3"
> 
>  
> 
> which renames the offending column:
> 
>  
> 
>> frame
> 
>      col1 col2 col3 col4 col5 col6
> 
> [1,]    3   10    2    6    5    7
> 
> [2,]    6    8    4   10    7    1
> 
> [3,]    7    5    1    3    1    8
> 
> [4,]   10    6    5    4    9    2
> 
>  
> 
> This seems cumbersome and not very intuitive.  How can one accomplish
> this more simply?
> 
>  
well I would simply use

names(frame)[3] = 'col3'

(supposing you know the column number of your offending column anyway).


From vidal.jean at gmail.com  Fri Dec 15 11:51:22 2006
From: vidal.jean at gmail.com (Jean Vidal)
Date: Fri, 15 Dec 2006 11:51:22 +0100
Subject: [R] Problem with sas.get function in Hmisc
In-Reply-To: <4580939f.0d6cc3e4.0b49.ffff9991SMTPIN_ADDED@mx.google.com>
References: <4580939f.0d6cc3e4.0b49.ffff9991SMTPIN_ADDED@mx.google.com>
Message-ID: <51d3ecb0612150251s2045c10ega7eef0928c99bc26@mail.gmail.com>

Hello Hong,

Thanks a lot for the solution you sent. It works fine now.

2006/12/14, Hong Ooi <Hong.Ooi at iag.com.au>:
>
> _______________________________________________________________________________________
>
> Note: This e-mail is subject to the disclaimer contained at the bottom of this message.
> _______________________________________________________________________________________
>
>
> After digging around in the sas.get code, I found a change that seems to
> be causing the problem:
>
> old version:
>
>    ...
>    status <- sys(paste(sasprog, sasin, "-log", log.file),
>        output = FALSE)
>    ...
>
> new version:
>
>    ...
>    status <- sys(paste(shQuote(sasprog), shQuote(sasin), "-log",
>        shQuote(log.file)), output = FALSE)
>    ...
>
>
> For some reason, sys() bombs when given a command string with quotes in
> it. The string works fine when pasted into a command line window, so
> maybe it's a problem with the WinXP commmand interpreter? In any case,
> changing the sys() call to system() seems to fix the problem.
>
>    ...
>    status <- system(paste(shQuote(sasprog), shQuote(sasin), "-log",
>        shQuote(log.file)))
>    ...
>
>
> --
> Hong Ooi
> Senior Research Analyst, IAG Limited
> 388 George St, Sydney NSW 2000
> +61 (2) 9292 1566
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jean Vidal
> Sent: Wednesday, 13 December 2006 8:02 PM
> To: acalatro at rhoworld.com
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Problem with sas.get function in Hmisc
>
> The workaround you point seems to be the solution for the moment.
> I not sure I will have time (and courage) to try to figure out where
> the bug comes from. Hope a more literate R programmer than me is
> willing to dive in...
>
> Thank you for your answer.
>
> 2006/12/12, Agustin Calatroni <acalatro at rhoworld.com>:
> > Jean, I saw your email to the R-help mailing list. I also notice the
> > problem a few months back and email the maintainer (Charles Dupont)
> but
> > never got a response. Since I used the function a lot and in order to
> > avoid the error I use version 3.0-12 instead of updating the a newer
> > version. To download the earlier version use the following site:
> > http://cran.r-project.org/bin/windows/contrib/2.2/ If you figure out
> > another way around the problem I will be interested in knowing the
> solution.
> >
> > Sincerely,
> >
> >
> > -- Agustin Calatroni
> >
> > Agustin Calatroni wrote:
> > > I been having the following problem when I updated the Hmisc package
> > > from version 3.0-12 to version 3.1-1.
> > >
> > > Create dataset under SAS:
> > > data a;
> > >  do i = 1 to 100;
> > >   x = rannor(0);
> > >   output;
> > >  end;
> > > run;
> > >
> > > Hmisc version 3.0-12:
> > > library(Hmisc)
> > > sas.get('C:\\Documents and Settings\\novell\\My Documents\\SAS
> > > Temp\\_TD3428','a')
> > >
> > > NO PROBLEM
> > >
> > > Hmisc version 3.1-1:
> > > library(Hmisc)
> > > sas.get('C:\\Documents and Settings\\novell\\My Documents\\SAS
> > > Temp\\_TD3428','a')
> > >
> > > The filename, directory name, or volume label syntax is incorrect.
> > > Error in sas.get("C:\\Documents and Settings\\novell\\My
> Documents\\SAS
> > > Temp\\_TD3428",  :
> > >         SAS job failed with status 1
> > > In addition: Warning message:
> > > 'cmd' execution failed with error code 1 in: shell(cmd, wait = TRUE,
> > > intern = output)
> > >
> > > R.Version()
> > > $platform
> > > [1] "i386-pc-mingw32"
> > > $arch
> > > [1] "i386"
> > > $os
> > > [1] "mingw32"
> > > $system
> > > [1] "i386, mingw32"
> > > $status
> > > [1] ""
> > > $major
> > > [1] "2"
> > > $minor
> > > [1] "3.1"
> > > $year
> > > [1] "2006"
> > > $month
> > > [1] "06"
> > > $day
> > > [1] "01"
> > > $`svn rev`
> > > [1] "38247"
> > > $language
> > > [1] "R"
> > > $version.string
> > > [1] "Version 2.3.1 (2006-06-01)"
> > >
> > > Thanks for Hmisc and Design packages, they are an invaluable
> resource.
> > > Sorry if this is a stupid question and I missed something obvious.
> > >
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> _______________________________________________________________________________________
>
> The information transmitted in this message and its attach...{{dropped}}


From carmei3 at web.de  Fri Dec 15 12:23:05 2006
From: carmei3 at web.de (Carmen Meier)
Date: Fri, 15 Dec 2006 12:23:05 +0100
Subject: [R] ks.test "greater" and "less"
Message-ID: <45828599.2020504@web.de>

Hello r-group
I have a question to the ks.test.
I would expect different values for less and greater between data1 and 
data2.
Does anybody could explain  my point of misunderstanding the function?

data1<-c(8,12,43,70)
data2<- c(70,43,12,8)

ks.test(data1,"pnorm")
ks.test(data1,"pnorm",alternative ="less")    #expected < 0.001
ks.test(data1,"pnorm",alternative ="greater") #expected =1


ks.test(data2,"pnorm")
ks.test(data2,"pnorm",alternative ="less")  #expected =1
ks.test(data2,"pnorm",alternative ="greater") #expected < 0.001


With regards Carmen


From Roger.Bivand at nhh.no  Fri Dec 15 12:29:47 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 15 Dec 2006 12:29:47 +0100 (CET)
Subject: [R] Function to fit a STARIMA model
In-Reply-To: <458135B4.7000806@imperial.ac.uk>
Message-ID: <Pine.LNX.4.44.0612151226490.4685-100000@reclus.nhh.no>

On Thu, 14 Dec 2006, Rajesh Krishnan wrote:

> Hi all,
> 
> I was wondering if there is a function available in any of the R add-on 
> packages that could be used to fit a STARIMA (Phillip E. Pfeifer and 
> Stuart Jay Deutsch. (1980). "A STARIMA Model-Building Procedure with 
> Application to Description and Regional Forecasting," Transactions of 
> the Institute of British Geographers 5(3), 330-349.) model?

I'm afraid there is no such function. The approach has been used very
little since it was proposed, and probably more work has been done on
spatial panel models (not yet in R) and in the hierarchical model
framework (again not yet in R, although the spBayes package may offer some
possibilities).

> 
> Thanks,
> 
> Rajesh.
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From istoyanov at ecolab.bas.bg  Fri Dec 15 12:52:21 2006
From: istoyanov at ecolab.bas.bg (Ivailo Stoyanov)
Date: Fri, 15 Dec 2006 13:52:21 +0200
Subject: [R] Installing rgl package under Ubuntu
Message-ID: <1166183541.6025.11.camel@localhost>

Dear Rexperts,

lately I'm having troubles installing the rgl package via
install.packages("rgl", dependencies=T) in the R 2.4.0 backport running
under Ubuntu 6.06 LTS. I get the following error messages, despite
having installed libx11-dev (as recommended in a similar post about SUSE
10.1):

trying URL 'http://cran.xedio.de/src/contrib/rgl_0.68.tar.gz'
Content type 'application/x-gzip' length 701566 bytes
opened URL
==================================================
downloaded 685Kb

* Installing *source* package 'rgl' ...
checking for gcc... gcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ANSI C... none needed
checking how to run the C preprocessor... gcc -E
checking for X... no
configure: error: X11 not found but required, configure aborted.
ERROR: configuration failed for package 'rgl'
** Removing '/usr/local/lib/R/site-library/rgl'

The downloaded packages are in
        /tmp/Rtmpni68vG/downloaded_packages
Warning message:
installation of package 'rgl' had non-zero exit status in:
install.packages("rgl", dependencies = T)
+---------------------------------------+

Has anyone experienced a similar problem, and what would be the
resolution of the "X11 not found" message?

Thank you in advance!

Greets,
Ivailo


From Heather.Turner at warwick.ac.uk  Fri Dec 15 13:09:52 2006
From: Heather.Turner at warwick.ac.uk (Turner, Heather)
Date: Fri, 15 Dec 2006 12:09:52 -0000
Subject: [R] Model formula question
References: <b2f853f40612140541s3a6c1637g68d37c5c836aec6f@mail.gmail.com>
Message-ID: <1072002710EB6047A212400EEB65F0060A7309@ELDER.ads.warwick.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061215/d45235da/attachment.pl 

From kalyansikha at yahoo.com  Fri Dec 15 13:29:13 2006
From: kalyansikha at yahoo.com (Bhanu Kalyan.K)
Date: Fri, 15 Dec 2006 04:29:13 -0800 (PST)
Subject: [R] Query regarding linking R with Matlab
Message-ID: <20061215122913.67988.qmail@web34308.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061215/28ea7aef/attachment.pl 

From Heather.Turner at warwick.ac.uk  Fri Dec 15 13:41:17 2006
From: Heather.Turner at warwick.ac.uk (Turner, Heather)
Date: Fri, 15 Dec 2006 12:41:17 -0000
Subject: [R] Model formula question
References: <b2f853f40612140541s3a6c1637g68d37c5c836aec6f@mail.gmail.com>
Message-ID: <1072002710EB6047A212400EEB65F0060A730D@ELDER.ads.warwick.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061215/6ff62855/attachment.pl 

From bjorn.vancampenhout at ua.ac.be  Fri Dec 15 13:44:48 2006
From: bjorn.vancampenhout at ua.ac.be (Van Campenhout Bjorn)
Date: Fri, 15 Dec 2006 13:44:48 +0100
Subject: [R] Installing rgl package under Ubuntu
In-Reply-To: <1166183541.6025.11.camel@localhost>
Message-ID: <0EE866100C01984EAE6AC3AE56EDFE53314BE2@xmail05.ad.ua.ac.be>


> Dear Rexperts,
> 
> lately I'm having troubles installing the rgl package via 
> install.packages("rgl", dependencies=T) in the R 2.4.0 
> backport running under Ubuntu 6.06 LTS. I get the following 
> error messages, despite having installed libx11-dev (as 
> recommended in a similar post about SUSE
> 10.1):
> 
> trying URL 'http://cran.xedio.de/src/contrib/rgl_0.68.tar.gz'
> Content type 'application/x-gzip' length 701566 bytes opened 
> URL ==================================================
> downloaded 685Kb
> 
> * Installing *source* package 'rgl' ...
> checking for gcc... gcc
> checking for C compiler default output file name... a.out 
> checking whether the C compiler works... yes checking whether 
> we are cross compiling... no checking for suffix of executables...
> checking for suffix of object files... o checking whether we 
> are using the GNU C compiler... yes checking whether gcc 
> accepts -g... yes checking for gcc option to accept ANSI C... 
> none needed checking how to run the C preprocessor... gcc -E 
> checking for X... no
> configure: error: X11 not found but required, configure aborted.
> ERROR: configuration failed for package 'rgl'
> ** Removing '/usr/local/lib/R/site-library/rgl'
> 
> The downloaded packages are in
>         /tmp/Rtmpni68vG/downloaded_packages
> Warning message:
> installation of package 'rgl' had non-zero exit status in:
> install.packages("rgl", dependencies = T)
> +---------------------------------------+
> 
> Has anyone experienced a similar problem, and what would be 
> the resolution of the "X11 not found" message?

On my ubuntu 6.06 LTS, I pass the test (tho I do get errors later during
compilation).  When checking for X, it says:
 
...
Checking for X... Libraries /usr/X11R6/lib, headers
...

I compiled R 2.4.0 from source, which also gave me some trouble when
checking for X.  I think I solved it by installing xserver-xorg-dev.
Hope this gives you some pointers


Bjorn

> 
> Thank you in advance!
> 
> Greets,
> Ivailo
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From istoyanov at ecolab.bas.bg  Fri Dec 15 14:06:10 2006
From: istoyanov at ecolab.bas.bg (Ivailo Stoyanov)
Date: Fri, 15 Dec 2006 15:06:10 +0200
Subject: [R] Installing rgl package under Ubuntu
In-Reply-To: <0EE866100C01984EAE6AC3AE56EDFE53314BE2@xmail05.ad.ua.ac.be>
References: <0EE866100C01984EAE6AC3AE56EDFE53314BE2@xmail05.ad.ua.ac.be>
Message-ID: <1166187970.8375.2.camel@localhost>

On Fri, 2006-12-15 at 13:44 +0100, Van Campenhout Bjorn wrote:

[snip]

> On my ubuntu 6.06 LTS, I pass the test (tho I do get errors later during
> compilation).  When checking for X, it says:
>  
> ...
> Checking for X... Libraries /usr/X11R6/lib, headers
> ...
> 
> I compiled R 2.4.0 from source, which also gave me some trouble when
> checking for X.  I think I solved it by installing xserver-xorg-dev.
> Hope this gives you some pointers
> 
> 
> Bjorn

I installed xserver-xorg-dev, but the problem persists :(

Any other hints?

Ivailo


From P.Dalgaard at biostat.ku.dk  Fri Dec 15 14:14:16 2006
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 15 Dec 2006 14:14:16 +0100
Subject: [R] Installing rgl package under Ubuntu
In-Reply-To: <1166187970.8375.2.camel@localhost>
References: <0EE866100C01984EAE6AC3AE56EDFE53314BE2@xmail05.ad.ua.ac.be>
	<1166187970.8375.2.camel@localhost>
Message-ID: <45829FA8.6050105@biostat.ku.dk>

Ivailo Stoyanov wrote:
> On Fri, 2006-12-15 at 13:44 +0100, Van Campenhout Bjorn wrote:
>
> [snip]
>
>   
>> On my ubuntu 6.06 LTS, I pass the test (tho I do get errors later during
>> compilation).  When checking for X, it says:
>>  
>> ...
>> Checking for X... Libraries /usr/X11R6/lib, headers
>> ...
>>
>> I compiled R 2.4.0 from source, which also gave me some trouble when
>> checking for X.  I think I solved it by installing xserver-xorg-dev.
>> Hope this gives you some pointers
>>
>>
>> Bjorn
>>     
>
> I installed xserver-xorg-dev, but the problem persists :(
>
> Any other hints?
>   
I don't think that is the right package (xserver...dev sounds like
something  for developing X11 servers). Look for something like
xorg-x11-devel  or thereabouts. You likely also need some packages with
"GL" or "Mesa" in the name plus their "dev" versions.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From istoyanov at ecolab.bas.bg  Fri Dec 15 14:35:16 2006
From: istoyanov at ecolab.bas.bg (Ivailo Stoyanov)
Date: Fri, 15 Dec 2006 15:35:16 +0200
Subject: [R] Installing rgl package under Ubuntu
In-Reply-To: <45829FA8.6050105@biostat.ku.dk>
References: <0EE866100C01984EAE6AC3AE56EDFE53314BE2@xmail05.ad.ua.ac.be>
	<1166187970.8375.2.camel@localhost>  <45829FA8.6050105@biostat.ku.dk>
Message-ID: <1166189716.8375.8.camel@localhost>

On Fri, 2006-12-15 at 14:14 +0100, Peter Dalgaard wrote:
> I don't think that is the right package (xserver...dev sounds like
> something  for developing X11 servers). Look for something like
> xorg-x11-devel  or thereabouts. You likely also need some packages with
> "GL" or "Mesa" in the name plus their "dev" versions.

I have located x11-proto-gl-dev and libgl-mesa-dev via synaptic as
containing "gl" "mesa" and "dev", but installing them doesn't get the
problem resoved...

Ivailo


From e.rapsomaniki at mail.cryst.bbk.ac.uk  Fri Dec 15 14:42:25 2006
From: e.rapsomaniki at mail.cryst.bbk.ac.uk (Eleni Rapsomaniki)
Date: Fri, 15 Dec 2006 13:42:25 +0000
Subject: [R] Plotting multiple smooth lines on the same graph
Message-ID: <1166190144.4582a641009a0@webmail.cryst.bbk.ac.uk>

Hi

Say we have the following data sets:
d1=cbind(rnorm(100,1,1), rnorm(100,10,50))
d2=cbind(rnorm(100,5,1), rnorm(100,1,5))

I want to plot them both on the same graph with a curve fitted for each. 
I could call scatter.smooth to plot the first curve, but how do I add the
second?

scatter.smooth(d1)

Many thanks
Eleni Rapsomaniki


From istoyanov at ecolab.bas.bg  Fri Dec 15 14:56:14 2006
From: istoyanov at ecolab.bas.bg (Ivailo Stoyanov)
Date: Fri, 15 Dec 2006 15:56:14 +0200
Subject: [R] [Resolved] Installing rgl package under Ubuntu
In-Reply-To: <45829FA8.6050105@biostat.ku.dk>
References: <0EE866100C01984EAE6AC3AE56EDFE53314BE2@xmail05.ad.ua.ac.be>
	<1166187970.8375.2.camel@localhost>  <45829FA8.6050105@biostat.ku.dk>
Message-ID: <1166190974.8375.18.camel@localhost>

On Fri, 2006-12-15 at 14:14 +0100, Peter Dalgaard wrote:
> I don't think that is the right package (xserver...dev sounds like
> something  for developing X11 servers). Look for something like
> xorg-x11-devel  or thereabouts. You likely also need some packages with
> "GL" or "Mesa" in the name plus their "dev" versions.

Installing libxt-dev (mentioned in the R-admin manual) helped somewhat
further, but the I've got:

 trying URL 'http://cran.xedio.de/src/contrib/rgl_0.68.tar.gz'
Content type 'application/x-gzip' length 701566 bytes
opened URL
==================================================
downloaded 685Kb

* Installing *source* package 'rgl' ...
checking for gcc... gcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ANSI C... none needed
checking how to run the C preprocessor... gcc -E
checking for X... libraries /usr/X11R6/lib, headers
checking for libpng-config... yes
configure: using libpng-config
configure: using libpng dynamic linkage
configure: creating ./config.status
config.status: creating src/Makevars
** libs
g++ -I/usr/share/R/include -I/usr/share/R/include -I -DHAVE_PNG_H
-I/usr/include/libpng12 -Iext     -fpic  -g -O2 -c api.cpp -o api.o
In file included from glgui.hpp:9,
                 from gui.hpp:11,
                 from rglview.h:10,
                 from Device.hpp:11,
                 from DeviceManager.hpp:9,
                 from api.cpp:14:
opengl.hpp:24:20: error: GL/glu.h: No such file or directory
api.cpp: In function ?void rgl_user2window(int*, int*, double*, double*,
double*, double*, int*)?:
api.cpp:761: error: ?gluProject? was not declared in this scope
api.cpp: In function ?void rgl_window2user(int*, int*, double*, double*,
double*, double*, int*)?:
api.cpp:789: error: ?gluUnProject? was not declared in this scope
make: *** [api.o] Error 1
chmod: cannot access `/usr/local/lib/R/site-library/rgl/libs/*': No such
file or directory
ERROR: compilation failed for package 'rgl'
** Removing '/usr/local/lib/R/site-library/rgl'
+---------------------------------------------+

Now, knowing the missing file (i.e. glu.h, from the more informative
feedback) I searched http://packages.ubuntu.com for the package
containing glu.h. This turned out to be libglu1-mesa-dev -- installing
it resolved the problem, but now I have to clear up the mess with the
unnecessarily installed *dev packages;)

Thanks for the helpful pointers!

Ivailo


From murdoch at stats.uwo.ca  Fri Dec 15 14:55:34 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 15 Dec 2006 08:55:34 -0500
Subject: [R] Installing rgl package under Ubuntu
In-Reply-To: <1166189716.8375.8.camel@localhost>
References: <0EE866100C01984EAE6AC3AE56EDFE53314BE2@xmail05.ad.ua.ac.be>	<1166187970.8375.2.camel@localhost>
	<45829FA8.6050105@biostat.ku.dk>
	<1166189716.8375.8.camel@localhost>
Message-ID: <4582A956.8000003@stats.uwo.ca>

On 12/15/2006 8:35 AM, Ivailo Stoyanov wrote:
> On Fri, 2006-12-15 at 14:14 +0100, Peter Dalgaard wrote:
>> I don't think that is the right package (xserver...dev sounds like
>> something  for developing X11 servers). Look for something like
>> xorg-x11-devel  or thereabouts. You likely also need some packages with
>> "GL" or "Mesa" in the name plus their "dev" versions.
> 
> I have located x11-proto-gl-dev and libgl-mesa-dev via synaptic as
> containing "gl" "mesa" and "dev", but installing them doesn't get the
> problem resoved...

rgl needs to know where the X11 headers and libs are, and it appears 
that the configure script (which was written by autoconfig) isn't 
finding them.  You probably need to specify them manually, when you run 
configure:

   --x-includes=DIR    X include files are in DIR
   --x-libraries=DIR   X library files are in DIR

If you built R, you can find where R found these by looking at the 
config.log:  search for X_CFLAGS and X_LIBS, and you'll see something like

X_CFLAGS=' -I/usr/X11R6/include'
X_LIBS=' -L/usr/X11R6/lib -lX11 -lXt -lXmu'

which should mean that this would install rgl on this system:

R CMD INSTALL rgl --configure-args="--x-includes=/usr/X11R6/include 
--x-libraries=/usr/X11R6/lib"

(In fact, the configure script found them in those locations by itself.)

Duncan Murdoch


From istoyanov at ecolab.bas.bg  Fri Dec 15 15:01:42 2006
From: istoyanov at ecolab.bas.bg (Ivailo Stoyanov)
Date: Fri, 15 Dec 2006 16:01:42 +0200
Subject: [R] Installing rgl package under Ubuntu
In-Reply-To: <4582A956.8000003@stats.uwo.ca>
References: <0EE866100C01984EAE6AC3AE56EDFE53314BE2@xmail05.ad.ua.ac.be>
	<1166187970.8375.2.camel@localhost>  <45829FA8.6050105@biostat.ku.dk>
	<1166189716.8375.8.camel@localhost>  <4582A956.8000003@stats.uwo.ca>
Message-ID: <1166191302.8375.24.camel@localhost>

On Fri, 2006-12-15 at 08:55 -0500, Duncan Murdoch wrote:
[snip]
> rgl needs to know where the X11 headers and libs are, and it appears 
> that the configure script (which was written by autoconfig) isn't 
> finding them.  You probably need to specify them manually, when you run 
> configure:
> 
>    --x-includes=DIR    X include files are in DIR
>    --x-libraries=DIR   X library files are in DIR
> 
> If you built R, you can find where R found these by looking at the 
> config.log:  search for X_CFLAGS and X_LIBS, and you'll see something like
> 
> X_CFLAGS=' -I/usr/X11R6/include'
> X_LIBS=' -L/usr/X11R6/lib -lX11 -lXt -lXmu'
> 
> which should mean that this would install rgl on this system:
> 
> R CMD INSTALL rgl --configure-args="--x-includes=/usr/X11R6/include 
> --x-libraries=/usr/X11R6/lib"
> 
> (In fact, the configure script found them in those locations by itself.)
> 
> Duncan Murdoch

Thanks for the response, but meanwhile I figured the solution and have
just posted it to the list!

It seems that the r-base-dev package from the Ubuntu R backport doesn't
provide *all* the packages necessary to build add-on libraries.

Greets,
Ivailo


From murdoch at stats.uwo.ca  Fri Dec 15 15:03:41 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 15 Dec 2006 09:03:41 -0500
Subject: [R] Installing rgl package under Ubuntu
In-Reply-To: <1166191302.8375.24.camel@localhost>
References: <0EE866100C01984EAE6AC3AE56EDFE53314BE2@xmail05.ad.ua.ac.be>	
	<1166187970.8375.2.camel@localhost>
	<45829FA8.6050105@biostat.ku.dk>	
	<1166189716.8375.8.camel@localhost> <4582A956.8000003@stats.uwo.ca>
	<1166191302.8375.24.camel@localhost>
Message-ID: <4582AB3D.6060502@stats.uwo.ca>

On 12/15/2006 9:01 AM, Ivailo Stoyanov wrote:
> On Fri, 2006-12-15 at 08:55 -0500, Duncan Murdoch wrote:
> [snip]
>> rgl needs to know where the X11 headers and libs are, and it appears 
>> that the configure script (which was written by autoconfig) isn't 
>> finding them.  You probably need to specify them manually, when you run 
>> configure:
>> 
>>    --x-includes=DIR    X include files are in DIR
>>    --x-libraries=DIR   X library files are in DIR
>> 
>> If you built R, you can find where R found these by looking at the 
>> config.log:  search for X_CFLAGS and X_LIBS, and you'll see something like
>> 
>> X_CFLAGS=' -I/usr/X11R6/include'
>> X_LIBS=' -L/usr/X11R6/lib -lX11 -lXt -lXmu'
>> 
>> which should mean that this would install rgl on this system:
>> 
>> R CMD INSTALL rgl --configure-args="--x-includes=/usr/X11R6/include 
>> --x-libraries=/usr/X11R6/lib"
>> 
>> (In fact, the configure script found them in those locations by itself.)
>> 
>> Duncan Murdoch
> 
> Thanks for the response, but meanwhile I figured the solution and have
> just posted it to the list!
> 
> It seems that the r-base-dev package from the Ubuntu R backport doesn't
> provide *all* the packages necessary to build add-on libraries.

I don't think it could:  package writers are free to require anything 
they like.  rgl may be the only package requiring the OpenGL 
headers/libs, for instance.

Duncan Murdoch


From jfox at mcmaster.ca  Fri Dec 15 15:12:36 2006
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 15 Dec 2006 09:12:36 -0500
Subject: [R] How to load Rcmd without Commander() ?
In-Reply-To: <38b9f0350612142354q57e5afdcr187c9da417966e1b@mail.gmail.com>
Message-ID: <20061215141235.WSYW6280.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear Ronggui,

The Commander() function is called in the Rcmdr .onAttach() function, so
library(Rcmdr) automatically starts up the GUI. You could use
Rcmdr:::reliability(S), where S is the covariance matrix among the items,
without libraryI(Rcmdr). Perhaps somewhat better would be to make a copy of
the function in the global environment via reliability <-
Rcmdr:::reliability.

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of ronggui
> Sent: Friday, December 15, 2006 2:54 AM
> To: R-Help
> Subject: [R] How to load Rcmd without Commander() ?
> 
> I would like to use the reliability() function in Rcmdr 
> package, but not the GUI, so I would to load Rcmd without 
> Commander() running automatically.
> 
> Is there any easy way to get it? Thanks.
> 
> 
> --
> Ronggui Huang
> Department of Sociology
> Fudan University, Shanghai, China
> ??????
> ????????????????
> 
>


From ccleland at optonline.net  Fri Dec 15 15:14:06 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 15 Dec 2006 09:14:06 -0500
Subject: [R] Plotting multiple smooth lines on the same graph
In-Reply-To: <1166190144.4582a641009a0@webmail.cryst.bbk.ac.uk>
References: <1166190144.4582a641009a0@webmail.cryst.bbk.ac.uk>
Message-ID: <4582ADAE.1080303@optonline.net>

Eleni Rapsomaniki wrote:
> Hi
> 
> Say we have the following data sets:
> d1=cbind(rnorm(100,1,1), rnorm(100,10,50))
> d2=cbind(rnorm(100,5,1), rnorm(100,1,5))
> 
> I want to plot them both on the same graph with a curve fitted for each. 
> I could call scatter.smooth to plot the first curve, but how do I add the
> second?

  I would probably restructure the data and use xyplot() in the lattice
package, but you also could do something along these lines:

d1 <- cbind(rnorm(100), rnorm(100,3,1))
d2 <- cbind(rnorm(100), rnorm(100,1,1))

plot(d1[,1], d1[,2], xlim=range(c(d1[,1], d2[,1])),
                     ylim=range(c(d1[,2], d2[,2])),
                     col="blue", xlab="X", ylab="Y")

points(d2[,1], d2[,2], col="red")
points(loess.smooth(d1[,1], d1[,2]), type="l", col="blue")
points(loess.smooth(d2[,1], d2[,2]), type="l", col="red")

> scatter.smooth(d1)
> 
> Many thanks
> Eleni Rapsomaniki
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From istoyanov at ecolab.bas.bg  Fri Dec 15 15:15:57 2006
From: istoyanov at ecolab.bas.bg (Ivailo Stoyanov)
Date: Fri, 15 Dec 2006 16:15:57 +0200
Subject: [R] Installing rgl package under Ubuntu
In-Reply-To: <4582AB3D.6060502@stats.uwo.ca>
References: <0EE866100C01984EAE6AC3AE56EDFE53314BE2@xmail05.ad.ua.ac.be>
	<1166187970.8375.2.camel@localhost>  <45829FA8.6050105@biostat.ku.dk>
	<1166189716.8375.8.camel@localhost>  <4582A956.8000003@stats.uwo.ca>
	<1166191302.8375.24.camel@localhost>  <4582AB3D.6060502@stats.uwo.ca>
Message-ID: <1166192157.8375.29.camel@localhost>

On Fri, 2006-12-15 at 09:03 -0500, Duncan Murdoch wrote:
[snip]
> I don't think it could:  package writers are free to require anything 
> they like.  rgl may be the only package requiring the OpenGL 
> headers/libs, for instance.
> 
> Duncan Murdoch

You're right, but until I had libxt-dev on my system I couldn't find out
what else I need to build rgl successfully.

Ivailo


From edd at debian.org  Fri Dec 15 15:23:31 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 15 Dec 2006 08:23:31 -0600
Subject: [R] Installing rgl package under Ubuntu
In-Reply-To: <1166191302.8375.24.camel@localhost>
References: <0EE866100C01984EAE6AC3AE56EDFE53314BE2@xmail05.ad.ua.ac.be>
	<1166187970.8375.2.camel@localhost>
	<45829FA8.6050105@biostat.ku.dk>
	<1166189716.8375.8.camel@localhost> <4582A956.8000003@stats.uwo.ca>
	<1166191302.8375.24.camel@localhost>
Message-ID: <17794.45027.413067.852523@basebud.nulle.part>


On 15 December 2006 at 16:01, Ivailo Stoyanov wrote:
| It seems that the r-base-dev package from the Ubuntu R backport doesn't
| provide *all* the packages necessary to build add-on libraries.

Re-read and re-think what you wrote there: you expect the r-base-dev package
to provide _all_ possible dependencies for _all_ possible packages. The
Oracle of Delphi in a few lines of a meta file?

That obviously can't work.  r-base-dev tries to give you all you need to
compile the _most common_ packages by providing essentially what R itself
needs.  Specialised packages that use other, more arcane libraries and
headers such as OpenGL are obviously not included.

Lastly, I can only urge users of Debian and Ubuntu to remember that because
we have _native_ packages on Debian and Ubuntu, we also have _native_
Build-Depends information.  Had you tried

	$ sudo apt-get build-dep r-cran-rgl

you might have gotten to the finish line much quicker.

Regards, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From roger.bos at us.rothschild.com  Fri Dec 15 15:36:17 2006
From: roger.bos at us.rothschild.com (Bos, Roger)
Date: Fri, 15 Dec 2006 09:36:17 -0500
Subject: [R] persistant: Matlab->R
Message-ID: <D8C95B444AD6EE4AAD638D818A9CFD340EE9F9@RINNYCSE000.rth.ad.rothschild.com>

To the extent that 'persistent' means 'global', global in R is: <<-, so
r <- 1 is local scope and r <<- 1 is global scope.

HTH, 

Roger
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Charles C. Berry
Sent: Thursday, December 14, 2006 3:34 PM
To: Bernard Gregory
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] persistant: Matlab->R


It is just my guess that the 'open.account' example in 10.7 Scope of
Introduciton to R is what you are after.

If I understand what 'presistent' means, the 'total' in the example is
approximately equal to a persistent variable.


On Thu, 14 Dec 2006, Bernard Gregory wrote:

> Dear list members,
>
> Could anyone tell me if there is an equivalent of the Matlab
declaration 'persistant' in R?
>
> Thank you very much,
>
> Bernard Gregorry.
> (Matlaber converted to R).
>
>
> ---------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive
Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

********************************************************************** * 
This message is for the named person's use only. It may 
contain confidential, proprietary or legally privileged 
information. No right to confidential or privileged treatment 
of this message is waived or lost by any error in 
transmission. If you have received this message in error, 
please immediately notify the sender by e-mail, 
delete the message and all copies from your system and destroy 
any hard copies. You must not, directly or indirectly, use, 
disclose, distribute, print or copy any part of this message 
if you are not the intended recipient.


From santiagote at gmail.com  Fri Dec 15 16:15:03 2006
From: santiagote at gmail.com (Santiago Cilintano)
Date: Fri, 15 Dec 2006 12:15:03 -0300
Subject: [R] series de tiempo diarias
Message-ID: <cedd6fb60612150715u41e82a55w99387d352dad2b0d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061215/d5c0081d/attachment.pl 

From j.van_den_hoff at fz-rossendorf.de  Fri Dec 15 16:32:24 2006
From: j.van_den_hoff at fz-rossendorf.de (Joerg van den Hoff)
Date: Fri, 15 Dec 2006 16:32:24 +0100
Subject: [R] sapply problem
In-Reply-To: <458180C5.7020500@pdf.com>
References: <458151D9.5080009@fz-rossendorf.de> <458180C5.7020500@pdf.com>
Message-ID: <4582C008.3050903@fz-rossendorf.de>

Sundar Dorai-Raj wrote:
> 
> 
> Joerg van den Hoff said the following on 12/14/2006 7:30 AM:
>> I have encountered the following problem: I need to extract from
>> a list of lists equally named compenents who happen to be 'one row'
>> data frames. a trivial example would be:
>>
>> a <- list(list(
>> df = data.frame(A = 1, B = 2, C = 3)), list(df = data.frame(A = 4,B = 
>> 5,C = 6)))
>>
>> I want the extracted compenents to fill up a matrix or data frame row 
>> by row.
>> the obvious thing to do seems:
>>
>> b <- sapply(a, "[[", "df")
>> b <- t(b)
>>
>> now `b' looks all right:
>>
>> b
>> class(b)
>>
>> but it turns out that all elements in this matrix are one element lists:
>>
>> class(b[1,1])
>>
>> which prevents any further standard processing of `b' (like 
>> `colMeans', e.g.)
>>
>> question 1: is their a straightforward way to enforce that `b' contains
>> simple numbers as elements right from the start (instead of something 
>> like
>> apply(b, 1:2, "class<-", "numeric") afterwards)?
>>
> 
> Try this:
> 
> a <- list(list(df = data.frame(A = 1, B = 2, C = 3)),
>           list(df = data.frame(A = 4, B = 5, C = 6)))
> b <- do.call("rbind", sapply(a, "[", "df"))
> b
> 
> 
>> question 2: should not sapply do this further 'simplification' anyway 
>> in a situation
>> like this (matrix elements turn out to be one-element lists)?
>>
> 
> I think it does as it much as it knows how. I think you might believe 
> that matrix elements can only contain numeric values. This is not a 
> valid assumption. Take this example:
> 
>  > a <- list(1)
>  > b <- list(2)
>  > (m <- matrix(c(a, b), 2, 1))
>      [,1]
> [1,] 1
> [2,] 2
>  > class(m[1, 1])
> [1] "list"
>  > class(m[2, 1])
> [1] "list"
> 
> HTH,
> 
> --sundar
> 
>> regards
>>
>> joerg
>>

thanks for the help to everybody. the proposal of sundar seems the most concise one (if it 
is also efficient I'll see with larger data sets ..).

with regards to my question no. 2: sure I realize that I _can_ have a sensible matrix 
consisting of elements that are lists. with regards to `sapply' and the intention (as I 
understand it) to simplify as much as is sensible possible (`sapply' unlists usually 
everything it can), I think it would be desirable if `sapply' would detect this admittedly 
very special case: "a matrix of one-element lists whose sole list elements are atomic of 
length 1" (which was my case and is exactly your example above).

of course, I don't know whether such a special treatment (probably meaning further 
recursive tests in `sapply') would slow down `sapply' significantly in general (which 
would be an argument against such a change of `sapply') or maybe it is against the actual
purpose of sapply -- I'm not sure.

anyway, thanks again,

joerg


From istoyanov at ecolab.bas.bg  Fri Dec 15 16:34:56 2006
From: istoyanov at ecolab.bas.bg (Ivailo Stoyanov)
Date: Fri, 15 Dec 2006 17:34:56 +0200
Subject: [R] Installing rgl package under Ubuntu
Message-ID: <1166196896.15281.23.camel@localhost>

> On 15 December 2006 at 16:01, Ivailo Stoyanov wrote:
> | It seems that the r-base-dev package from the Ubuntu R backport doesn't
> | provide *all* the packages necessary to build add-on libraries.
> 
> Re-read and re-think what you wrote there: you expect the r-base-dev package
> to provide _all_ possible dependencies for _all_ possible packages. The
> Oracle of Delphi in a few lines of a meta file?
> 
> That obviously can't work.  r-base-dev tries to give you all you need to
> compile the _most common_ packages by providing essentially what R itself
> needs.  Specialised packages that use other, more arcane libraries and
> headers such as OpenGL are obviously not included.

Dirk,

I'm obviously not that deep into the Debian/Ubuntu package management,
and these considerations of mine should be taken just as what they are
-- considerations of a puzzled R user that has some problems with
building some package;)

> Lastly, I can only urge users of Debian and Ubuntu to remember that because
> we have _native_ packages on Debian and Ubuntu, we also have _native_
> Build-Depends information.  Had you tried
> 
> 	$ sudo apt-get build-dep r-cran-rgl
> 
> you might have gotten to the finish line much quicker.

Thanks a lot for this hint! It is very useful and I would definitely
hit the target much easier if I knew about that. The source for the
problem at hand have to be sought back in times when I relied too much
on the native cran-r-* packages, until I found that not everything is
available natively, so I started to install only the *-base packages
and to rely on the *-dev one to provide the dependencies I need to
build needed ad-on libraries manually. Actually, until now everything
went just fine this way, and I still appreciate much such cases that
fill my (still numerous) knowledge gaps.

> Regards, Dirk

Greets,
Ivailo


From santiagote at gmail.com  Fri Dec 15 16:41:12 2006
From: santiagote at gmail.com (Santiago Cilintano)
Date: Fri, 15 Dec 2006 12:41:12 -0300
Subject: [R] daily time series
Message-ID: <cedd6fb60612150741q405a478cgad3e013bce62f43f@mail.gmail.com>

Se ha borrado un texto insertado con un juego de caracteres sin especificar...
Nombre: no disponible
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061215/5aa501ed/attachment.pl 

From Mark.Leeds at morganstanley.com  Fri Dec 15 17:10:29 2006
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Fri, 15 Dec 2006 11:10:29 -0500
Subject: [R] daily time series
In-Reply-To: <cedd6fb60612150741q405a478cgad3e013bce62f43f@mail.gmail.com>
Message-ID: <D3AEEDA31E57474B840BEBC25A8A8344F391B0@NYWEXMB23.msad.ms.com>

I think you can fit them using arima() whch I think is part of the
base.


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Santiago
Cilintano
Sent: Friday, December 15, 2006 10:41 AM
To: r-help at stat.math.ethz.ch
Subject: [R] daily time series

Is there some package in R to model daily univariate time series? We
want to model more than one seasonality using the Box-Jenkins' method.
That is, we want to model a series with both a yearly and weekly
seasonal component.

thanks , Santiago Cilintano

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From petr.pikal at precheza.cz  Fri Dec 15 17:47:03 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 15 Dec 2006 17:47:03 +0100
Subject: [R] Plotting multiple smooth lines on the same graph
In-Reply-To: <1166190144.4582a641009a0@webmail.cryst.bbk.ac.uk>
Message-ID: <4582DF97.26169.12A889F@localhost>

Hi

you can either use supsmu smoother

plot(d1) # make sure limits for axes are OK (which is not in this 
case and you need to set xlim and ylim accordingly
lines(supsmu(d1[,1], d1[,2]))
points(d2, pch=2) 
lines(supsmu(d2[,1], d2[,2]))

or you can use loess smoother which is used in scatter.smooth and do 
some ordering before plotting and similar plot lines points lines 
construction.

HTH
Petr


On 15 Dec 2006 at 13:42, Eleni Rapsomaniki wrote:

Date sent:      	Fri, 15 Dec 2006 13:42:25 +0000
From:           	Eleni Rapsomaniki <e.rapsomaniki at mail.cryst.bbk.ac.uk>
To:             	r-help at stat.math.ethz.ch
Subject:        	[R] Plotting multiple smooth lines on the same graph

> Hi
> 
> Say we have the following data sets:
> d1=cbind(rnorm(100,1,1), rnorm(100,10,50))
> d2=cbind(rnorm(100,5,1), rnorm(100,1,5))
> 
> I want to plot them both on the same graph with a curve fitted for
> each. I could call scatter.smooth to plot the first curve, but how do
> I add the second?
> 
> scatter.smooth(d1)
> 
> Many thanks
> Eleni Rapsomaniki
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

Petr Pikal
petr.pikal at precheza.cz


From villegas.ro at gmail.com  Fri Dec 15 19:50:49 2006
From: villegas.ro at gmail.com (R. Villegas)
Date: Fri, 15 Dec 2006 19:50:49 +0100
Subject: [R] series de tiempo diarias
In-Reply-To: <cedd6fb60612150715u41e82a55w99387d352dad2b0d@mail.gmail.com>
References: <cedd6fb60612150715u41e82a55w99387d352dad2b0d@mail.gmail.com>
Message-ID: <29cf68350612151050t54b140b3tcef7623e280db5b2@mail.gmail.com>

2006/12/15, Santiago Cilintano <santiagote at gmail.com>:
> Existe alg?n paquete en donde puedo modelizar espec?ficamente series diarias
> univariadas siguiendo la metodolog?a de Box-Jenkins?
> C?mo modelizar mas de una estacionalidad en dichas series por ejemplo una
> estacionalidad semanal y anual?
>
> GRacias
> Santiago Cilintano
>
>         [[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

Classical time series modelling tools are contained in the stats
package and include  arima()  for ARIMA modelling and Box-Jenkins-type
analysis.

Please read the posting-guide, http://www.r-project.org/posting-guide.html


From muenchen at utk.edu  Fri Dec 15 21:34:15 2006
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Fri, 15 Dec 2006 15:34:15 -0500
Subject: [R] Switching labels on a factor
Message-ID: <7270AEC73132194E8BC0EE06B35D93D84A061C@UTKFSVS3.utk.tennessee.edu>

Hi All,

I'm perplexed by the way the unclass function displays a factor whose
labels have been swapped with the relevel function. I realize it won't
affect any results and that the relevel did nothing useful in this
particular case. I'm just doing it to learn ways to manipulate factors.
The display of unclass leaves me feeling that the relevel had failed.

I've checked three books & searched R-help, but found no mention of this
particular issue.  

The program below demonstrates the problem. Is this a bug, or is there a
reason for it to work this way?

Thanks,
Bob

mystring<-
("id,workshop,gender,q1,q2,q3,q4
 1,1,f,1,1,5,1
 2,2,f,2,1,4,1
 3,1,f,2,2,4,3
 4,2,f,3,1, ,3
 5,1,m,4,5,2,4
 6,2,m,5,4,5,5
 7,1,m,5,3,4,4
 8,2,m,4,5,5,9")
mydata<-read.table(textConnection(mystring),
   header=TRUE,sep=",",row.names="id",na.strings="9")
mydata

# Create a gender Releveled variable, gR. 
# Now 1=m, 2=f
mydata$gR <- relevel(mydata$gender, "m")

# Print the data to show that the labels of gR match those of gender.
mydata

# Show that the underlying codes have indeed reversed.
as.numeric(mydata$gender)
as.numeric(mydata$gR)

# Unclass the two variables to see that print order 
# implies that both the codes and labels have
# flipped, cancelling each other out. For gR,
# m appears to be associated with 2, and f with 1
unclass(mydata$gender)
unclass(mydata$gR)

=========================================================
  Bob Muenchen (pronounced Min'-chen), Manager  
  Statistical Consulting Center
  U of TN Office of Information Technology
  200 Stokely Management Center, Knoxville, TN 37996-0520
  Voice: (865) 974-5230  
  FAX:   (865) 974-4810
  Email: muenchen at utk.edu
  Web:   http://oit.utk.edu/scc, 
  News:  http://listserv.utk.edu/archives/statnews.html


From RMan54 at cox.net  Fri Dec 15 21:41:06 2006
From: RMan54 at cox.net (RMan54)
Date: Fri, 15 Dec 2006 12:41:06 -0800 (PST)
Subject: [R] xyplot: legend title + legend on 1 line
Message-ID: <7898800.post@talk.nabble.com>


Does anybody know how in xyplot to put the legend title on one line with the
legend? I can get the legend on one line with columns=... but the title is
always on top. I tried a custom key with key=... and text=... but I can't
put the title text in front of the plotting symbol.

I am looking for the following layout of the legend, on one line:

"Legend Title:" + plot symbol1 + legend text1 + plot symbol2 + legend text2
+ ...

Thanks. Rene
 
-- 
View this message in context: http://www.nabble.com/xyplot%3A-legend-title-%2B-legend-on-1-line-tf2829327.html#a7898800
Sent from the R help mailing list archive at Nabble.com.


From deepayan.sarkar at gmail.com  Fri Dec 15 22:01:56 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 15 Dec 2006 13:01:56 -0800
Subject: [R] xyplot: legend title + legend on 1 line
In-Reply-To: <7898800.post@talk.nabble.com>
References: <7898800.post@talk.nabble.com>
Message-ID: <eb555e660612151301q324b99fctf8e7924f20014c6@mail.gmail.com>

On 12/15/06, RMan54 <RMan54 at cox.net> wrote:
>
> Does anybody know how in xyplot to put the legend title on one line with the
> legend? I can get the legend on one line with columns=... but the title is
> always on top. I tried a custom key with key=... and text=... but I can't
> put the title text in front of the plotting symbol.
>
> I am looking for the following layout of the legend, on one line:
>
> "Legend Title:" + plot symbol1 + legend text1 + plot symbol2 + legend text2
> + ...

You can create a grob (grid object) representing this legend, or a
function that produces such a grob, and pass it to xyplot through the
'legend' argument (see ?xyplot). The 'key' argument essentially
controls one such built-in function, namely 'draw.key', which does not
support such legends.

Note however, that column types can be repeated in key, so you might
be able to fake such a legend. E.g.:


xyplot(1 ~ 1,
       key =
       list(text = list("title: ", font = 2),
            points = list(pch = 1),
            text = list("1"),
            points = list(pch = 2),
            text = list("2")))

-Deepayan


From RMan54 at cox.net  Fri Dec 15 23:12:22 2006
From: RMan54 at cox.net (RMan54)
Date: Fri, 15 Dec 2006 14:12:22 -0800 (PST)
Subject: [R] xyplot: logarithmic y-axis
Message-ID: <7900202.post@talk.nabble.com>


This should be simple but I am struggling. I like to easily switch in xyplot
between a linear or logarithmic y-axis by setting a logical flag logY to
False or True. This switch changes the scales argument of xyplot. I found
out that the original two-dimentional data (Conc vs Time in my case) are
converted to log10(Conc) if log=TRUE in scales, but it appears that
functions like panel.curve need to provide the y values in log10 form (if
there is an automatic method, I would like to know). I therefore like to
pass on the value logY to my custom panel.curve function. How do I do that?
I think that the value of logY should go into xyplot that should pass it on
to the panel function and then to the panel.curve function.

Thanks, -Rene

logY=TRUE

# Custom panel.curve function
myCurve <-function(x, log) {
    f <- ...   #  calculate curve here
    if (log==TRUE) f <- log10(f)
    return(f)
}

xyplot(Conc ~ Time | Subj,
       groups=Dose,
       data = mydata,
       as.table=TRUE,
       scales=list(y=list(log=logY)),
       panel = function(...) {
           panel.abline(h=c(0, 50, 100, 150, 200, 250) ,
                      v=c(0,24,48,72,96), col.line="gray")
           panel.xyplot(...)
           panel.curve(myCurve, from=0, to=96, n=300))
           }
       )

-- 
View this message in context: http://www.nabble.com/xyplot%3A-logarithmic-y-axis-tf2829755.html#a7900202
Sent from the R help mailing list archive at Nabble.com.


From deepayan.sarkar at gmail.com  Fri Dec 15 23:26:47 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 15 Dec 2006 14:26:47 -0800
Subject: [R] xyplot: logarithmic y-axis
In-Reply-To: <7900202.post@talk.nabble.com>
References: <7900202.post@talk.nabble.com>
Message-ID: <eb555e660612151426s30981295r30e3d3ee123f412f@mail.gmail.com>

On 12/15/06, RMan54 <RMan54 at cox.net> wrote:
>
> This should be simple but I am struggling. I like to easily switch in xyplot
> between a linear or logarithmic y-axis by setting a logical flag logY to
> False or True. This switch changes the scales argument of xyplot. I found
> out that the original two-dimentional data (Conc vs Time in my case) are
> converted to log10(Conc) if log=TRUE in scales, but it appears that
> functions like panel.curve need to provide the y values in log10 form (if
> there is an automatic method, I would like to know). I therefore like to
> pass on the value logY to my custom panel.curve function. How do I do that?
> I think that the value of logY should go into xyplot that should pass it on
> to the panel function and then to the panel.curve function.

It probably should, but doesn't.

-Deepayan


From bklick1 at jhmi.edu  Fri Dec 15 23:38:26 2006
From: bklick1 at jhmi.edu (BRENDAN KLICK)
Date: Fri, 15 Dec 2006 17:38:26 -0500
Subject: [R] DF for GAM function (mgcv package)
Message-ID: <4582DD92020000F500007D2A@cis27.hosts.jhmi.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061215/603e9a9a/attachment.pl 

From RMan54 at cox.net  Fri Dec 15 23:41:49 2006
From: RMan54 at cox.net (RMan54)
Date: Fri, 15 Dec 2006 14:41:49 -0800 (PST)
Subject: [R] xyplot: logarithmic y-axis
In-Reply-To: <eb555e660612151426s30981295r30e3d3ee123f412f@mail.gmail.com>
References: <7900202.post@talk.nabble.com>
	<eb555e660612151426s30981295r30e3d3ee123f412f@mail.gmail.com>
Message-ID: <7900634.post@talk.nabble.com>


Please take no offence since none was intended. What I meant is that it
should be simple for me to know how to do this but it isn't because of my
inexperience. I  think that the lattice package is great.

However, how can I pass on my own varaibles through xyplot?

Thanks, -Rene


Deepayan Sarkar wrote:
> 
> On 12/15/06, RMan54 <RMan54 at cox.net> wrote:
>>
>> This should be simple but I am struggling. I like to easily switch in
>> xyplot
>> between a linear or logarithmic y-axis by setting a logical flag logY to
>> False or True. This switch changes the scales argument of xyplot. I found
>> out that the original two-dimentional data (Conc vs Time in my case) are
>> converted to log10(Conc) if log=TRUE in scales, but it appears that
>> functions like panel.curve need to provide the y values in log10 form (if
>> there is an automatic method, I would like to know). I therefore like to
>> pass on the value logY to my custom panel.curve function. How do I do
>> that?
>> I think that the value of logY should go into xyplot that should pass it
>> on
>> to the panel function and then to the panel.curve function.
> 
> It probably should, but doesn't.
> 
> -Deepayan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/xyplot%3A-logarithmic-y-axis-tf2829755.html#a7900634
Sent from the R help mailing list archive at Nabble.com.


From deepayan.sarkar at gmail.com  Fri Dec 15 23:57:07 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 15 Dec 2006 14:57:07 -0800
Subject: [R] xyplot: logarithmic y-axis
In-Reply-To: <7900634.post@talk.nabble.com>
References: <7900202.post@talk.nabble.com>
	<eb555e660612151426s30981295r30e3d3ee123f412f@mail.gmail.com>
	<7900634.post@talk.nabble.com>
Message-ID: <eb555e660612151457u5858ccdag9f344000e833a5ab@mail.gmail.com>

On 12/15/06, RMan54 <RMan54 at cox.net> wrote:
>
> Please take no offence since none was intended. What I meant is that it
> should be simple for me to know how to do this but it isn't because of my
> inexperience. I  think that the lattice package is great.

I didn't mean to suggest that I was offended. I only agreed with you
that it would be nice if there were a way of knowing inside the panel
function whether a log scale is being used, and informing you that
there isn't.

> However, how can I pass on my own varaibles through xyplot?

Any arguments not recognized by xyplot will be passed to the panel function.

-Deepayan

>
> Thanks, -Rene
>
>
> Deepayan Sarkar wrote:
> >
> > On 12/15/06, RMan54 <RMan54 at cox.net> wrote:
> >>
> >> This should be simple but I am struggling. I like to easily switch in
> >> xyplot
> >> between a linear or logarithmic y-axis by setting a logical flag logY to
> >> False or True. This switch changes the scales argument of xyplot. I found
> >> out that the original two-dimentional data (Conc vs Time in my case) are
> >> converted to log10(Conc) if log=TRUE in scales, but it appears that
> >> functions like panel.curve need to provide the y values in log10 form (if
> >> there is an automatic method, I would like to know). I therefore like to
> >> pass on the value logY to my custom panel.curve function. How do I do
> >> that?
> >> I think that the value of logY should go into xyplot that should pass it
> >> on
> >> to the panel function and then to the panel.curve function.
> >
> > It probably should, but doesn't.
> >
> > -Deepayan


From RMan54 at cox.net  Sat Dec 16 00:16:38 2006
From: RMan54 at cox.net (RMan54)
Date: Fri, 15 Dec 2006 15:16:38 -0800 (PST)
Subject: [R] xyplot: logarithmic y-axis
In-Reply-To: <eb555e660612151457u5858ccdag9f344000e833a5ab@mail.gmail.com>
References: <7900202.post@talk.nabble.com>
	<eb555e660612151426s30981295r30e3d3ee123f412f@mail.gmail.com>
	<7900634.post@talk.nabble.com>
	<eb555e660612151457u5858ccdag9f344000e833a5ab@mail.gmail.com>
Message-ID: <7901073.post@talk.nabble.com>


I added logY as the last argument to xyplot and in my curve function. I got
the following error message:

Error in myCurve(x) : argument "log" is missing, with no default

myCurve <-function(x, log) {
    f <- ... # calculate curve here
    if (log==T) f <- log10(f)
    return(f)
}

logY=T
xyplot(Conc ~ Time | Subj,
       groups=Dose,
       data = mydata,
       scales=list(x=list(at=seq(0,96,24)), y=list(log=logY)),
       panel = function(...) {
           panel.abline(h=c(0, 50, 100, 150, 200, 250) ,
                      v=c(0,24,48,72,96), col.line="gray")
           panel.xyplot(...)
           panel.curve(myCurve, from=0, to=96, n=300, ..., log=logY)
           },
       logY
       )




Deepayan Sarkar wrote:
> 
> On 12/15/06, RMan54 <RMan54 at cox.net> wrote:
>>
>> Please take no offence since none was intended. What I meant is that it
>> should be simple for me to know how to do this but it isn't because of my
>> inexperience. I  think that the lattice package is great.
> 
> I didn't mean to suggest that I was offended. I only agreed with you
> that it would be nice if there were a way of knowing inside the panel
> function whether a log scale is being used, and informing you that
> there isn't.
> 
>> However, how can I pass on my own varaibles through xyplot?
> 
> Any arguments not recognized by xyplot will be passed to the panel
> function.
> 
> -Deepayan
> 
>>
>> Thanks, -Rene
>>
>>
>> Deepayan Sarkar wrote:
>> >
>> > On 12/15/06, RMan54 <RMan54 at cox.net> wrote:
>> >>
>> >> This should be simple but I am struggling. I like to easily switch in
>> >> xyplot
>> >> between a linear or logarithmic y-axis by setting a logical flag logY
>> to
>> >> False or True. This switch changes the scales argument of xyplot. I
>> found
>> >> out that the original two-dimentional data (Conc vs Time in my case)
>> are
>> >> converted to log10(Conc) if log=TRUE in scales, but it appears that
>> >> functions like panel.curve need to provide the y values in log10 form
>> (if
>> >> there is an automatic method, I would like to know). I therefore like
>> to
>> >> pass on the value logY to my custom panel.curve function. How do I do
>> >> that?
>> >> I think that the value of logY should go into xyplot that should pass
>> it
>> >> on
>> >> to the panel function and then to the panel.curve function.
>> >
>> > It probably should, but doesn't.
>> >
>> > -Deepayan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/xyplot%3A-logarithmic-y-axis-tf2829755.html#a7901073
Sent from the R help mailing list archive at Nabble.com.


From villegas.ro at gmail.com  Sat Dec 16 00:27:16 2006
From: villegas.ro at gmail.com (R. Villegas)
Date: Sat, 16 Dec 2006 00:27:16 +0100
Subject: [R] ks.test "greater" and "less"
In-Reply-To: <45828599.2020504@web.de>
References: <45828599.2020504@web.de>
Message-ID: <29cf68350612151527t2d7fd565k10242d7064b38f47@mail.gmail.com>

2006/12/15, Carmen Meier <carmei3 at web.de>:
> Hello r-group
> I have a question to the ks.test.
> I would expect different values for less and greater between data1 and
> data2.
> Does anybody could explain  my point of misunderstanding the function?
>
> data1<-c(8,12,43,70)
> data2<- c(70,43,12,8)
>
> ks.test(data1,"pnorm")
> ks.test(data1,"pnorm",alternative ="less")    #expected < 0.001
> ks.test(data1,"pnorm",alternative ="greater") #expected =1
>
>
> ks.test(data2,"pnorm")
> ks.test(data2,"pnorm",alternative ="less")  #expected =1
> ks.test(data2,"pnorm",alternative ="greater") #expected < 0.001
>
>
> With regards Carmen
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Possible  you are unable to use the Kolmogorov?Smirnov test given that
the sample size is small.


From deepayan.sarkar at gmail.com  Sat Dec 16 00:43:57 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 15 Dec 2006 15:43:57 -0800
Subject: [R] xyplot: logarithmic y-axis
In-Reply-To: <7901073.post@talk.nabble.com>
References: <7900202.post@talk.nabble.com>
	<eb555e660612151426s30981295r30e3d3ee123f412f@mail.gmail.com>
	<7900634.post@talk.nabble.com>
	<eb555e660612151457u5858ccdag9f344000e833a5ab@mail.gmail.com>
	<7901073.post@talk.nabble.com>
Message-ID: <eb555e660612151543h5ff09735x4f5e0fe7e28c6f9f@mail.gmail.com>

On 12/15/06, RMan54 <RMan54 at cox.net> wrote:
>
> I added logY as the last argument to xyplot and in my curve function. I got
> the following error message:
>
> Error in myCurve(x) : argument "log" is missing, with no default
>
> myCurve <-function(x, log) {
>     f <- ... # calculate curve here
>     if (log==T) f <- log10(f)
>     return(f)
> }
>
> logY=T
> xyplot(Conc ~ Time | Subj,
>        groups=Dose,
>        data = mydata,
>        scales=list(x=list(at=seq(0,96,24)), y=list(log=logY)),
>        panel = function(...) {
>            panel.abline(h=c(0, 50, 100, 150, 200, 250) ,
>                       v=c(0,24,48,72,96), col.line="gray")
>            panel.xyplot(...)
>            panel.curve(myCurve, from=0, to=96, n=300, ..., log=logY)
>            },
>        logY
>        )

You need to learn more about (1) R functions and (2) R's scoping
rules. Your last argument (logY) is not doing what you think it's
doing (which doesn't really matter because of the scoping rules).

Your error is caused because in

panel.curve(myCurve, from=0, to=96, n=300, ..., log=logY)

the 'log' argument is not being passed to myCurve (nor is it supposed
to). However, you should be able to replace it by

panel.curve(myCurve(x, log = logY), from=0, to=96, n=300, ...)

-Deepayan


From macq at llnl.gov  Sat Dec 16 01:49:25 2006
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 15 Dec 2006 16:49:25 -0800
Subject: [R] Better way to change the name of a column in a dataframe?
In-Reply-To: <CA612484A337C6479EA341DF9EEE14AC05B7CDB5@hercules.ssainfo>
References: <CA612484A337C6479EA341DF9EEE14AC05B7CDB5@hercules.ssainfo>
Message-ID: <p06230913c1a8f2cbae1c@[128.115.153.6]>

And there is the rename.vars() function in the gdata package.
-Don

At 11:39 AM -0600 12/14/06, Ben Fairbank wrote:
>Hello R users --
>
>
>
>If I have a dataframe such as the following, named "frame" with the
>columns intended to be named col1 through col6,
>
>
>
>>  frame
>
>      col1 col2 cmlo3 col4 col5 col6
>
>[1,]    3   10     2    6    5    7
>
>[2,]    6    8     4   10    7    1
>
>[3,]    7    5     1    3    1    8
>
>[4,]   10    6     5    4    9    2
>
>
>
>and I want to correct or otherwise change the name of one of the
>columns, I can do so with
>
>
>
>>  dimnames(frame)[[2]][which(dimnames(frame)[[2]]=="cmlo3")] <- "col3"
>
>
>
>which renames the offending column:
>
>
>
>>  frame
>
>      col1 col2 col3 col4 col5 col6
>
>[1,]    3   10    2    6    5    7
>
>[2,]    6    8    4   10    7    1
>
>[3,]    7    5    1    3    1    8
>
>[4,]   10    6    5    4    9    2
>
>
>
>This seems cumbersome and not very intuitive.  How can one accomplish
>this more simply?
>
>
>
>With thanks for any suggestions,
>
>
>
>Ben Fairbank
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA


From baud-bovy.gabriel at hsr.it  Sat Dec 16 01:57:25 2006
From: baud-bovy.gabriel at hsr.it (baud-bovy.gabriel at hsr.it)
Date: Sat, 16 Dec 2006 01:57:25 +0100
Subject: [R] how to adjust link function in logistic regression to predict
 the proportion of correct responses in 2AFC task?
Message-ID: <6.2.3.4.0.20061216001441.03746570@mail.hsr.it>


I have would like to use logistic regression to analyze the
percentage of correct responses in a 2 alternative forced
choice task. The question is whether one needs to take into
account the fact expected probabilities for the percentage of
correct responses ranges between 0.5 and 1 in this case and
how to adjust the link function accordingly in R (see details below).

Gabriel

Subjects were asked to match a tactile stimulus
(shape A or B) with a visual template (response a or b).
The exact stimulus properties depended on the
experimental factors ecc (3 levels: 0.4, 0.7 and 1.0)
and kappa (also 3 levels:  0.75, 1, 1.25), which yielded
nine experimental conditions. Five subjects participated
to the experiment and each stimulus was presented 10 times
in each experimental condition.

The following table reports the pooled responses of the
5 subjects.

     |       |           kappa          |
     |       |  0.75      1.0     1.25  |
ecc | shape +--------+--------+--------+
     |       |  resp  |  resp  |  resp  |
     |       |  a   b |  a   b |  a   b |
----+-------+--------+--------+--------+
0.4 |   A   |  41  9 |  38 12 | 35  15 |
     |   B   |   3 47 |   7 43 | 11  39 |
----+-------+--------+--------+--------+
0.7 |   A   |  22 28 |  33 17 | 39  11 |
     |   B   |  10 40 |  21 29 | 24  26 |
----+-------+--------+--------+--------+
1.0 |    A   |  26 24 |  26 24 | 28  22 |
     |   B   |  20 30 |  18 32 | 25  25 |
----+-------+--------+--------+--------+

For this analysis, I define "correct response" as
the resp=a for shape=A and resp=b for shape=B.
The proportions of correct responses are therefore:

     |       |           kappa          |
ecc | shape |  0.75      1.0     1.25  |
----+-------+--------+--------+--------+
0.4 |   A   |  0.82  |  0.76  |  0.70  |
     |   B   |  0.94  |  0.86  |  0.78  |
----+-------+--------+--------+--------+
0.7 |   A   |  0.44  |  0.66  |  0.78  |
     |   B   |  0.80  |  0.58  |  0.52  |
----+-------+--------+--------+--------+
1.0 |    A   |  0.52  |  0.52  |  0.56  |
     |   B   |  0.60  |  0.62  |  0.50  |
----+-------+--------+--------+--------+

The proportion of correct response is the
largest for ecc=0.4 and, in general, smallest
for ecc=1 as expected. It was expected that
proportions of correct response would be
close to 0.5 when ecc=1 because shapes
A and  B were the same in this condition.

I would like to use the logistic regression
to assess the effect of the shape, ecc and kappa
on the proportion of correct responses. For example,

glm(resp~shape*ecc*kappa,data=data,link=binomial)

or, better,

gee(resp~shape*ecc*kappa,id=subject,data=data,family=binomial,
         corstr = "exchangeable")

given the fact that data that are correlated because
the 50 responses come from five subjects.
My first question is rather statistical: do I need to
take into account the fact that the values of these proportions
are expected to range in the interval [0.5-1] (0.5 corresponding
to a random response) ? It seems to me that some sort
of correction is needed as it is the case when one fits
a psychometric function to this type of data (e.g. probit
is rescaled to fit inside the [0.5-1] interval and the absolute
threshold is defined as the point where the probit reaches
the 0.75 probability level).

Second, how can one implement a link function of the
type f(x) = (1+exp(x)/(1+exp(x)))/2 in R?

Third, can it be also done with gee and/or glmm?

---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 02 2643 4839 (office)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 2643 4891 (secretary)
20132 Milan, Italy               fax: (+39) 02 2643 4892


From lyhin at netvigator.com  Sat Dec 16 02:22:15 2006
From: lyhin at netvigator.com (Dr L. Y Hin)
Date: Sat, 16 Dec 2006 09:22:15 +0800
Subject: [R] Seeking advice on lattice package in R2.4.0 concerning stripplot
Message-ID: <002101c720b0$9f27ff40$104efea9@yourgk68c57jh8>

Dear all,

I am using the R 2.4.0 environment on Windows XP SP2 
machine and trying to use the lattice package version 
0.14-9 which you have kindly written to share with the 
R community.

I have a question concerning the stripplot which I'd be very
grateful if you can kindly advise me on:

I used the dataset called trydata to plot a graph using
stripplot (dataset attached), and the scripts used to 
procude the plot is as follows:

trydata<-dget("trydata")
stripplot(Position~Count|y*Grouping,jitter=T,group=subtype,
data=trydata,xlab="Count rate (%)",
pch=c(0,3,6,5),
key=list(text=list(c("GS in front", "GS at the back",
"MS in front","MS at the back")),
points = Rows(trellis.par.get("superpose.symbol"),1:4),
columns=2))

When I plotted the graph and viewed it on
R, the legend and the datapoint shapes are
correct. However, when I export it into .pdf
form using the pulldown menu in R, the legend for 
"GS in front" is incorrect. 
Instead if being a prism, it became
a circle. How can I get around this?
I've attached the figure thus generated in pdf form
for your kind consideration.

Specifically, how can I modify the specifications in the
command to produce the correct pch type in the legend 
as in the chart itself?

Thank you very much in advance for your kind advice.

Best
Lin
-------------- next part --------------
A non-text attachment was scrubbed...
Name: trydatafigure.pdf
Type: application/pdf
Size: 13614 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20061216/c233eaae/attachment.pdf 

From ripley at stats.ox.ac.uk  Sat Dec 16 07:01:15 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 16 Dec 2006 06:01:15 +0000 (GMT)
Subject: [R] how to adjust link function in logistic regression to
 predict the proportion of correct responses in 2AFC task?
In-Reply-To: <6.2.3.4.0.20061216001441.03746570@mail.hsr.it>
References: <6.2.3.4.0.20061216001441.03746570@mail.hsr.it>
Message-ID: <Pine.LNX.4.64.0612160543320.30570@gannet.stats.ox.ac.uk>

On Sat, 16 Dec 2006, baud-bovy.gabriel at hsr.it wrote:

> I have would like to use logistic regression to analyze the
> percentage of correct responses in a 2 alternative forced
> choice task. The question is whether one needs to take into
> account the fact expected probabilities for the percentage of
> correct responses ranges between 0.5 and 1 in this case.

Yes.

> Second, how can one implement a link function of the
> type f(x) = (1+exp(x)/(1+exp(x)))/2 in R?

Looking at make.link() should give you enough to go on.

> Third, can it be also done with gee and/or glmm?

For gee, you need to change the C-level internals. (I've done this in the 
far past for S-PLUS but not for R.)  It would be easier to use yags (but I 
think you still need to dive into the internals).

What 'glmm' did you have in mind?  Looks like e.g. glmmML and glmmPQL will 
work with the new link.

[...]

Someone may have been here already: e.g.
http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1434755

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sat Dec 16 07:24:22 2006
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Sat, 16 Dec 2006 06:24:22 +0000 (GMT Standard Time)
Subject: [R] Seeking advice on lattice package in R2.4.0 concerning
 stripplot
In-Reply-To: <002101c720b0$9f27ff40$104efea9@yourgk68c57jh8>
References: <002101c720b0$9f27ff40$104efea9@yourgk68c57jh8>
Message-ID: <Pine.WNT.4.64.0612160613280.2684@Petrel>

The problem looks to be that you are specifying the types of symbols in two 
ways:

> pch=c(0,3,6,5),

> points = Rows(trellis.par.get("superpose.symbol"),1:4),

The simplest thing to do is to run your code directly on the pdf() device,
but you could experiment with other ways of setting the key.

(We don't have the data, so cannot test these ideas.)

On Sat, 16 Dec 2006, Dr L. Y Hin wrote:

> Dear all,
>
> I am using the R 2.4.0 environment on Windows XP SP2 machine and trying to 
> use the lattice package version 0.14-9 which you have kindly written to share 
> with the R community.
>
> I have a question concerning the stripplot which I'd be very
> grateful if you can kindly advise me on:
>
> I used the dataset called trydata to plot a graph using
> stripplot (dataset attached), and the scripts used to procude the plot is as 
> follows:
>
> trydata<-dget("trydata")
> stripplot(Position~Count|y*Grouping,jitter=T,group=subtype,
> data=trydata,xlab="Count rate (%)",
> pch=c(0,3,6,5),
> key=list(text=list(c("GS in front", "GS at the back",
> "MS in front","MS at the back")),
> points = Rows(trellis.par.get("superpose.symbol"),1:4),
> columns=2))
>
> When I plotted the graph and viewed it on
> R, the legend and the datapoint shapes are
> correct. However, when I export it into .pdf
> form using the pulldown menu in R, the legend for "GS in front" is incorrect. 
> Instead if being a prism, it became
> a circle. How can I get around this?
> I've attached the figure thus generated in pdf form
> for your kind consideration.
>
> Specifically, how can I modify the specifications in the
> command to produce the correct pch type in the legend as in the chart itself?
>
> Thank you very much in advance for your kind advice.
>
> Best
> Lin
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kknoblauch at free.fr  Sat Dec 16 08:36:04 2006
From: kknoblauch at free.fr (Ken Knoblauch)
Date: Sat, 16 Dec 2006 08:36:04 +0100
Subject: [R] how to adjust link function in logistic regression to predict
	the proportion of correct responses in 2AFC task?
Message-ID: <CD173E62-269D-41A0-9317-C442D4678138@free.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061216/2eb2b2db/attachment.pl 

From ripley at stats.ox.ac.uk  Sat Dec 16 08:42:46 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 16 Dec 2006 07:42:46 +0000 (GMT)
Subject: [R] how to adjust link function in logistic regression to
 predict the proportion of correct responses in 2AFC task?
In-Reply-To: <CD173E62-269D-41A0-9317-C442D4678138@free.fr>
References: <CD173E62-269D-41A0-9317-C442D4678138@free.fr>
Message-ID: <Pine.LNX.4.64.0612160737470.1987@gannet.stats.ox.ac.uk>

On Sat, 16 Dec 2006, Ken Knoblauch wrote:

> In theory, the probability of correct responses ranges between 0.5 and 1 
> here, but in practice it is frequent to find cases where the observed 
> proportion of correct responses is a little less.  The number of trials 
> is limited, after all.  The inverse of this link function generates a 
> Nan when this occurs.  Is that a problem? and if so, how can it be dealt 
> with here?

No. Links apply to fitted values, not observed proportions, and R link 
functions have a validity function to ensure they are used correctly.


> Thank you.
>
> I have used the gnlr function in Lindsey's gnlm package for this problem in
> the past, but glm would be simpler, it seems to me.
>
> @Article{pmid16817511,
>  Author="Yssaad-Fesselier, Rosa and Knoblauch, Kenneth",
>  Title="{{M}odeling psychometric functions in {R}}",
>  Journal="Behav Res Methods",
>  Year="2006",
>  Volume="38",
>  Number="1",
>  Pages="28--41",
>  Month="Feb"
> }
>
>
>
>> On Sat, 16 Dec 2006, baud-bovy.gabriel at hsr.it wrote:
>> 
>>> I have would like to use logistic regression to analyze the
>>> percentage of correct responses in a 2 alternative forced
>>> choice task. The question is whether one needs to take into
>>> account the fact expected probabilities for the percentage of
>>> correct responses ranges between 0.5 and 1 in this case.
>> 
>> Yes.
>> 
>>> Second, how can one implement a link function of the
>>> type f(x) = (1+exp(x)/(1+exp(x)))/2 in R?
>> 
>> Looking at make.link() should give you enough to go on.
>> 
>>> Third, can it be also done with gee and/or glmm?
>> 
>> For gee, you need to change the C-level internals. (I've done this in the
>> far past for S-PLUS but not for R.)  It would be easier to use yags (but I
>> think you still need to dive into the internals).
>> 
>> What 'glmm' did you have in mind?  Looks like e.g. glmmML and glmmPQL will
>> work with the new link.
>> 
>> [...]
>> 
>> Someone may have been here already: e.g.
>> http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1434755
>> 
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> --
> Ken Knoblauch
> Inserm U371
> Institut Cellule Souche et Cerveau
> D?partement Neurosciences Int?gratives
> 18 avenue du Doyen L?pine
> 69500 Bron
> France
> tel: +33 (0)4 72 91 34 77
> fax: +33 (0)4 72 91 34 61
> portable: +33 (0)6 84 10 64 10
> http://www.lyon.inserm.fr/371/

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From baud-bovy.gabriel at hsr.it  Sat Dec 16 12:45:03 2006
From: baud-bovy.gabriel at hsr.it (baud-bovy.gabriel at hsr.it)
Date: Sat, 16 Dec 2006 12:45:03 +0100
Subject: [R] how to adjust link function in logistic regression to
 predict the proportion of correct responses in 2AFC task?
In-Reply-To: <Pine.LNX.4.64.0612160543320.30570@gannet.stats.ox.ac.uk>
References: <6.2.3.4.0.20061216001441.03746570@mail.hsr.it>
	<Pine.LNX.4.64.0612160543320.30570@gannet.stats.ox.ac.uk>
Message-ID: <6.2.3.4.0.20061216103048.036fd330@mail.hsr.it>


At 07:01 AM 12/16/2006, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

>What 'glmm' did you have in mind?  Looks like e.g. glmmML and 
>glmmPQL will work with the new link.
>
>Someone may have been here already: e.g.
>http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1434755

Thank you for your reply and the above link. I am not sure yet which
function to use.  I am new at logistic regression for repeated-measure
designs and its various implementations in R.

glmmML seems to require changes at the C-level:
<http://www.stat.umu.se/forskning/reports/glmmML.pdf>http://www.stat.umu.se/forskning/reports/glmmML.pdf 


The new link might apparently be added to glmmPQL entirely at the
R-level.

>Looking at make.link() should give you enough to go on.

If I understood your suggestion well, it is sufficient to add a new
link for the binomial family by extending the make.link function
and adding, say, a "half-logit" link (both for the glm and lme call in
glmPQL).

Then, the call to glmmPQL could be

glmmPQL(resp~shape*ecc*kappa,
         random=~1|subject,
         family=binomial("half-logit"),
         data,
         correlation=corCompSymm(form=~1|subject))

assuming that resp=1 if response is correct and 0 otherwise,
a random intercept (as in glmmML) and an "exchangeable" correlation structure.

Note that it might be better to specify a "random slope" in
this context (since proportions are expected to vary between 0.5 and 1
for all subjects, the main difference being that some subjects might
have a steeper S-shaped curve than others) but I am not sure how to do it.

Regards,

Gabriel Baud-Bovy
UHSR University, Milan, Italy


From princenerdy at hotmail.com  Fri Dec 15 06:15:48 2006
From: princenerdy at hotmail.com (wayne tan)
Date: Fri, 15 Dec 2006 13:15:48 +0800
Subject: [R] optimizing inverse student-t
Message-ID: <BAY118-F18A063D67A5673AEF85B0AA8D40@phx.gbl>

i need to optimize the inverse cdf of student-t  qt(y^(1/k))+qt(1+p+y) with 
respect to y, is it possible to do it in R?


From Ekkehardt.Peters at LUA.Brandenburg.de  Fri Dec 15 10:26:33 2006
From: Ekkehardt.Peters at LUA.Brandenburg.de (Peters, Ekkehardt)
Date: Fri, 15 Dec 2006 10:26:33 +0100
Subject: [R] Fit Frechet Distribution
Message-ID: <C3D2EAC5840D444DB92CE053B0DF97BC1972DA@MAIL05.lua.mlur.ad.lvnbb.de>

A way to solve this problem is transform the three parameters from the
GEV-distribution into Frechet. Have a look at Thomas & Reiss,
Statistical Analysis of Extreme Values, or the thesis of Han Zhongxian,
Actuarial modelling of extremal events... The last is free in the web. I
am myself using the package evd by Alec Stephenson.

Best wishes 
Ekkehardt


From carmei3 at web.de  Sat Dec 16 17:52:56 2006
From: carmei3 at web.de (Carmen Meier)
Date: Sat, 16 Dec 2006 17:52:56 +0100
Subject: [R] ks.test "greater" and "less"
In-Reply-To: <29cf68350612160722y11b3be33vfd22635332fca48e@mail.gmail.com>
References: <45828599.2020504@web.de>	
	<29cf68350612151527t2d7fd565k10242d7064b38f47@mail.gmail.com>	
	<4583BC4A.6040902@web.de>
	<29cf68350612160722y11b3be33vfd22635332fca48e@mail.gmail.com>
Message-ID: <45842468.3010002@web.de>

R. Villegas schrieb:
> 2
>>
>> data1<-c(8,12,43,70)
>> data2<- c(70,43,12,8)
>> is the same for ks.test, isn't it?
>>
> Yes, it's the same. Wich version of R have you?.
2.4.0

Carmen


From bolker at zoo.ufl.edu  Sat Dec 16 19:52:33 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Sat, 16 Dec 2006 18:52:33 +0000 (UTC)
Subject: [R] optimizing inverse student-t
References: <BAY118-F18A063D67A5673AEF85B0AA8D40@phx.gbl>
Message-ID: <loom.20061216T194952-307@post.gmane.org>

wayne tan <princenerdy <at> hotmail.com> writes:

> 
> i need to optimize the inverse cdf of student-t  qt(y^(1/k))+qt(1+p+y) with 
> respect to y, is it possible to do it in R?
> 

  try ?optimize
  if you need more detail, you should give us more detail.
(I'm assuming e.g. that y is a scalar variable, p and k are
fixed scalars)

   Ben Bolker

PS

> library(fortunes)
> fortune("Yoda")

Evelyn Hall: I would like to know how (if) I can extract some of the
information from the summary of my nlme.
Simon Blomberg: This is R. There is no if. Only how.
   -- Evelyn Hall and Simon `Yoda' Blomberg
      R-help (April 2005)


From mir.k at gmx.at  Sat Dec 16 14:53:11 2006
From: mir.k at gmx.at (mirca heli)
Date: Sat, 16 Dec 2006 14:53:11 +0100
Subject: [R] object combinations
Message-ID: <20061216135311.302750@gmx.net>

hello list,

i've got 8 objects and i want to calculate a list with all combinations of them. the output should contain the object names.
for example: object1 & 2, 1 $ 3, ...

best regards
mirca
-- 
"Ein Herz f?r Kinder" - Ihre Spende hilft! Aktion: www.deutschlandsegelt.de
Unser Dankesch?n: Ihr Name auf dem Segel der 1. deutschen America's Cup-Yacht!


From ripley at stats.ox.ac.uk  Sat Dec 16 21:34:52 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 16 Dec 2006 20:34:52 +0000 (GMT)
Subject: [R] ks.test "greater" and "less"
In-Reply-To: <29cf68350612151527t2d7fd565k10242d7064b38f47@mail.gmail.com>
References: <45828599.2020504@web.de>
	<29cf68350612151527t2d7fd565k10242d7064b38f47@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0612160512300.29524@gannet.stats.ox.ac.uk>

On Sat, 16 Dec 2006, R. Villegas wrote:

> 2006/12/15, Carmen Meier <carmei3 at web.de>:
>> Hello r-group
>> I have a question to the ks.test.
>> I would expect different values for less and greater between data1 and
>> data2.
>> Does anybody could explain  my point of misunderstanding the function?

The help page says:

      This is a comparison of cumulative distribution
      functions, and the test statistic is the maximum difference in
      value, with the statistic in the '"greater"' alternative being D^+
      = max_u [ F_x(u) - F_y(u) ].

data1 and data2 have the same empirical CDF, so should and do give the 
same value of the test statistic.

We cannot know what you misunderstanding is, since you have not explained 
your expectations.


>> data1<-c(8,12,43,70)
>> data2<- c(70,43,12,8)
>>
>> ks.test(data1,"pnorm")
>> ks.test(data1,"pnorm",alternative ="less")    #expected < 0.001
>> ks.test(data1,"pnorm",alternative ="greater") #expected =1
>>
>>
>> ks.test(data2,"pnorm")
>> ks.test(data2,"pnorm",alternative ="less")  #expected =1
>> ks.test(data2,"pnorm",alternative ="greater") #expected < 0.001
>>
>>
>> With regards Carmen

> Possible  you are unable to use the Kolmogorov??Smirnov test given that
> the sample size is small.

You can: the distribution theory is exact.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ggrothendieck at gmail.com  Sat Dec 16 22:36:47 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 16 Dec 2006 16:36:47 -0500
Subject: [R] Hourly Time Series
In-Reply-To: <959DC0987E39DB43B963EA5ADC9E1A29015F809C@SNV-XCHMAIL2.xch.corp.yahoo.com>
References: <959DC0987E39DB43B963EA5ADC9E1A29015F809C@SNV-XCHMAIL2.xch.corp.yahoo.com>
Message-ID: <971536df0612161336s5e5324ddp8c90355b137c613f@mail.gmail.com>

Using zoo would allow you to retain the date/time portion.  In ts you would
have to represent them as numbers; however, as you can easily switch
from zoo to ts you probably want to use zoo in the first instance:

library(zoo)
library(chron)
Lines <- "DateID        HourID        Metrics
20060920    0                1
20060920    1                2"
z <- read.zoo(textConnection(Lines), header = TRUE, format = "%Y%m%d")
metrics <- aggregate(z[,2], chron(unclass(time(z))) + unclass(z[,1])/24, sum)
metrics
as.ts(metrics)


On 12/11/06, Harshal D Dedhia <harshal at yahoo-inc.com> wrote:
> I have hourly data for approximately 21 days in the following format
>
> DateID        HourID        Metrics
> 20060920    0                xxxxxx
> 20060920    1                xxxxxx
>
> The hour ids correspond to one hour windows starting 00:00 to 23:59.
>
> I have never dealt with TS data before. What is the best way to handle
> this data? TS objects or use the Zoo package?
>
> Thanks in advance.
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Sat Dec 16 22:45:24 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 16 Dec 2006 16:45:24 -0500
Subject: [R] using zoo for daily stock prices
In-Reply-To: <003601c71c53$ae4c7ca0$0300a8c0@Vaio>
References: <003601c71c53$ae4c7ca0$0300a8c0@Vaio>
Message-ID: <971536df0612161345s14d17055n7f064e49ef67131e@mail.gmail.com>

See aggregate.zoo and maybe ?rollapply
For date manipluations see R News 4/1 help desk article and the table at
the end of that article, in particular.
Suggest you also read and follow the last line on every r-help message
when posting.

On 12/10/06, Alfonso Sammassimo <cincinattikid at bigpond.com> wrote:
> Hi all,
>
> Please forgive this newbie posting to the list for the first time if I
> haven't followed proper procedure. I have read through many of the archives
> and find them most useful in learning R.
>
> I have ten years daily data (stock closing prices) which I read in zoo
> format. I am having problems coding R to run a count of how many days in
> each month have a price higher than the first day of that month. I then wish
> to compare counts for all months. Along these lines, is there a simple way
> to index to certain dates(eg first of month, last of month, any specific
> date in one month) and keep looping over each month using such a reference
> point, and then assessing the results for each month?
>
> Any guidance would be sincerely appreciated,
>
> Alfonso Sammassimo
> Melbourne, Australia.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jhallman at frb.gov  Sat Dec 16 22:46:02 2006
From: jhallman at frb.gov (Jeffrey J. Hallman)
Date: 16 Dec 2006 16:46:02 -0500
Subject: [R] Hourly Time Series
References: <959DC0987E39DB43B963EA5ADC9E1A29015F809C@SNV-XCHMAIL2.xch.corp.yahoo.com>
	<971536df0612161336s5e5324ddp8c90355b137c613f@mail.gmail.com>
Message-ID: <xmrodq3346d.fsf@mralx1.rsma.frb.gov>

The 'fame' package I submitted to CRAN can handle hourly, minutely, and
secondly series.  The first submission I made last night did not build
correctly on a Linux machine without the FAME libraries, but the one I put up
this morning has fixed that. It should be available soon, unless I missed
another problem (entirely possible).
-- 
Jeff


From jholtman at gmail.com  Sun Dec 17 00:13:05 2006
From: jholtman at gmail.com (jim holtman)
Date: Sat, 16 Dec 2006 18:13:05 -0500
Subject: [R] object combinations
In-Reply-To: <20061216135311.302750@gmx.net>
References: <20061216135311.302750@gmx.net>
Message-ID: <644e1f320612161513q9968ca0la41c4693cd6529c9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061216/95d86a38/attachment.pl 

From pealco at gmail.com  Sun Dec 17 05:20:19 2006
From: pealco at gmail.com (Pedro Alcocer)
Date: Sat, 16 Dec 2006 23:20:19 -0500
Subject: [R] Collapsing across trials
Message-ID: <99c5443d0612162020w3838a865ud58fac375e65cea3@mail.gmail.com>

Hello,

My ultimate goal is a repeated measures (mixed model) ANOVA, however,
my present question is about how to reorganize my data into the format
that the ANOVA commands expect. In particular, how to collapse across
trials. (I am using the tutorial at
[http://personality-project.org/r/r.anova.html] for the mixed model
ANOVA)

The data I am using looks like this. A subject sees 10 trials per
condition and there are 2 conditions. I want the average of all the
reaction times (RTs) from a subject looking a one condition. I also
want to retain List in the final output.

Subj	List	Condition	RT
2	1	C		338
2	1	C		227
2	1	C		430
2	1	C		621
2	1	C		255
2	1	C		348
2	1	C		280
2	1	C		356
2	1	C		272
2	1	C		346
3	2	C		489
3	2	C		426
3	2	C		352
3	2	C		351
3	2	C		349
3	2	C		403
3	2	C		336
3	2	C		278
3	2	C		365
3	2	C		271
2	1	D		360
2	1	D		374
2	1	D		326
2	1	D		363
2	1	D		290
2	1	D		458
2	1	D		295
2	1	D		362
2	1	D		285
2	1	D		277
3	2	D		354
3	2	D		352
3	2	D		362
3	2	D		360
3	2	D		334
3	2	D		365
3	2	D		335
3	2	D		391
3	2	D		272
3	2	D		618

The result should look like this:
2	1	C		(AVG)
3	2	C		(AVG)
2	1	D		(AVG)
3	2	D		(AVG)

Where (AVG) is the average of the 10 trials.

The above is a simplified case. How can I do this with multiple RT
measurements per subject? In other words, the above, but with more
than one RT column per subject.

Resulting in:

Subj	List	Condition	RT1		RT2		RT3		RT4		RT5
2	1	C		(AVG1)	(AVG2)	(AVG2)	(AVG2)	(AVG2)
3	2	C		(AVG1)	(AVG2)	(AVG2)	(AVG2)	(AVG2)
2	1	D		(AVG1)	(AVG2)	(AVG2)	(AVG2)	(AVG2)
3	2	D		(AVG1)	(AVG2)	(AVG2)	(AVG2)	(AVG2)

I've come across the apply and aggregate functions in online
documentation, and I have the suspicion that they may be called for
here, but their application isn't clear to me. I am fairly new to R.

(I am using R 2.4.0 on Mac OS X.)

I'd appreciate any insights.

Pedro Alcocer
University of Florida


From h.wickham at gmail.com  Sun Dec 17 07:34:00 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 16 Dec 2006 22:34:00 -0800
Subject: [R] Collapsing across trials
In-Reply-To: <99c5443d0612162020w3838a865ud58fac375e65cea3@mail.gmail.com>
References: <99c5443d0612162020w3838a865ud58fac375e65cea3@mail.gmail.com>
Message-ID: <f8e6ff050612162234u5e063a7bw3aa63436c19256ef@mail.gmail.com>

On 12/16/06, Pedro Alcocer <pealco at gmail.com> wrote:
> Hello,
>
> My ultimate goal is a repeated measures (mixed model) ANOVA, however,
> my present question is about how to reorganize my data into the format
> that the ANOVA commands expect. In particular, how to collapse across
> trials. (I am using the tutorial at
> [http://personality-project.org/r/r.anova.html] for the mixed model
> ANOVA)
>
> The data I am using looks like this. A subject sees 10 trials per
> condition and there are 2 conditions. I want the average of all the
> reaction times (RTs) from a subject looking a one condition. I also
> want to retain List in the final output.

Have a look at the reshape package, http://had.co.nz/reshape.

The following code should do what you want:

install.packages("reshape")
library(reshape)
dfm <- melt(df, id=c("Subj", "List","Condition"))
cast(Subj + List + Condition ~ variable , mean)

(that should work with any number of rt variables)

Hadley


From pealco at gmail.com  Sun Dec 17 07:54:29 2006
From: pealco at gmail.com (Pedro Alcocer)
Date: Sun, 17 Dec 2006 01:54:29 -0500
Subject: [R] Collapsing across trials
In-Reply-To: <f8e6ff050612162234u5e063a7bw3aa63436c19256ef@mail.gmail.com>
References: <99c5443d0612162020w3838a865ud58fac375e65cea3@mail.gmail.com>
	<f8e6ff050612162234u5e063a7bw3aa63436c19256ef@mail.gmail.com>
Message-ID: <99c5443d0612162254x7c88bd6ei6b741558db26da43@mail.gmail.com>

Thanks so much, Hadley. That's exactly what I needed.

My only comment is that the line

cast(Subj + List + Condition ~ variable , mean)

should be

cast(dfm, Subj + List + Condition ~ variable , mean)

Your excellent demo on your site cleared that up quickly, however.

Thanks again,

Pedro




On 12/17/06, hadley wickham <h.wickham at gmail.com> wrote:
> On 12/16/06, Pedro Alcocer <pealco at gmail.com> wrote:
> > Hello,
> >
> > My ultimate goal is a repeated measures (mixed model) ANOVA, however,
> > my present question is about how to reorganize my data into the format
> > that the ANOVA commands expect. In particular, how to collapse across
> > trials. (I am using the tutorial at
> > [http://personality-project.org/r/r.anova.html] for the mixed model
> > ANOVA)
> >
> > The data I am using looks like this. A subject sees 10 trials per
> > condition and there are 2 conditions. I want the average of all the
> > reaction times (RTs) from a subject looking a one condition. I also
> > want to retain List in the final output.
>
> Have a look at the reshape package, http://had.co.nz/reshape.
>
> The following code should do what you want:
>
> install.packages("reshape")
> library(reshape)
> dfm <- melt(df, id=c("Subj", "List","Condition"))
> cast(Subj + List + Condition ~ variable , mean)
>
> (that should work with any number of rt variables)
>
> Hadley
>


From patrick.giraudoux at univ-fcomte.fr  Sun Dec 17 09:15:30 2006
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 17 Dec 2006 09:15:30 +0100
Subject: [R] X11 fonts and Ubuntu
Message-ID: <4584FCA2.5030207@univ-fcomte.fr>

Hi,

I am moving from Windows XP to Ubuntu 6.10 and installed R 2.4.0. When I 
run eg plot.lm  (things work fine with plot.default - eg 
plot(rnorm(30),rnorm(30)))

plot(lmobject)

I can get the first plot and then this message:

Hit <Return> to see next plot:
Error in text.default(x, y, labels.id[ind],cex=cex, xpd=TRUE, :
    could not find any X11 fonts
Check that the Font Path is correct

I have googled through the R-help list and it seems that such troubles 
already occured sometimes (see link below and threads)

http://lists.freebsd.org/pipermail/freebsd-ports/2005-June/024091.html
http://tolstoy.newcastle.edu.au/R/help/06/03/23864.html

but did not find solution. Some messages claim it is a X11 problem (not 
R) some others suggest it may come from R. Some also mention that UTF-8 
may be a problem (though I don't have specific message on this from R). 
I have re-installed x11-common via the Synaptic package manager (so I 
suppose X11 is well installed) without improvement. I have checked 
/etc/X11/ xorg.conf

Section "Files"
    FontPath "/usr/share/X11/fonts/misc"
    FontPath "/usr/share/X11/fonts/100dpi/:unscaled"
    FontPath "/usr/share/X11/fonts/75dpi/:unscaled"
    FontPath "/usr/share/X11/fonts/Type1"
    FontPath "/usr/share/X11/fonts/100dpi"
    FontPath "/usr/share/X11/fonts/75dpi"
    FontPath "/usr/share/fonts/X11/misc"
    FontPath "/var/lib/defoma/x-ttcidfont-conf.d/dirs/TrueType"
Endsection

but cannot identify where the problem is actually thus no remedy.

Any idea?


From carmei3 at web.de  Sun Dec 17 10:33:42 2006
From: carmei3 at web.de (Carmen Meier)
Date: Sun, 17 Dec 2006 10:33:42 +0100
Subject: [R] ks.test "greater" and "less"
In-Reply-To: <Pine.LNX.4.64.0612160512300.29524@gannet.stats.ox.ac.uk>
References: <45828599.2020504@web.de>
	<29cf68350612151527t2d7fd565k10242d7064b38f47@mail.gmail.com>
	<Pine.LNX.4.64.0612160512300.29524@gannet.stats.ox.ac.uk>
Message-ID: <45850EF6.80008@web.de>

Prof Brian Ripley schrieb:
> On Sat, 16 Dec 2006, R. Villegas wrote:
>
>> 2006/12/15, Carmen Meier <carmei3 at web.de>:
>>> Hello r-group
>>> I have a question to the ks.test.
>>> I would expect different values for less and greater between data1 and
>>> data2.
>>> Does anybody could explain  my point of misunderstanding the function?
>
> The help page says:
>
>      This is a comparison of cumulative distribution
>      functions, and the test statistic is the maximum difference in
>      value, with the statistic in the '"greater"' alternative being D^+
>      = max_u [ F_x(u) - F_y(u) ].
>
> data1 and data2 have the same empirical CDF, so should and do give the 
> same value of the test statistic.
>
> We cannot know what you misunderstanding is, since you have not 
> explained your expectations.
>
Thank you for your answers,
seems that I was abusing the R-Group for statistical question which 
should be posted in f.e. sci.stat.edu.

.. the misunderstanding was, that I thought ks.test is different between 
sort order decreasing and increasing.

With regards Carmen


From rich.fitzjohn at gmail.com  Sun Dec 17 10:51:46 2006
From: rich.fitzjohn at gmail.com (Rich FitzJohn)
Date: Sun, 17 Dec 2006 22:51:46 +1300
Subject: [R] X11 fonts and Ubuntu
In-Reply-To: <4584FCA2.5030207@univ-fcomte.fr>
References: <4584FCA2.5030207@univ-fcomte.fr>
Message-ID: <5934ae570612170151o70520ffcq94f66011f3cabe47@mail.gmail.com>

Hi,

I have observed this as well (Debian etch, R 2.4.0), with "small" cex
values when drawing text.

My LANG environment variable was set to "en_NZ.UTF-8"; setting this to
"C" or "en_NZ" seems to prevent the error occuring.  I presume my
installation is missing a few fonts, yours may be too.

HTH,
Rich

 Setting the environment variable LANG=C before running R seems to
work as a workaround (normally this is en_NZ.UTF-8

On 12/17/06, Patrick Giraudoux <patrick.giraudoux at univ-fcomte.fr> wrote:
> Hi,
>
> I am moving from Windows XP to Ubuntu 6.10 and installed R 2.4.0. When I
> run eg plot.lm  (things work fine with plot.default - eg
> plot(rnorm(30),rnorm(30)))
>
> plot(lmobject)
>
> I can get the first plot and then this message:
>
> Hit <Return> to see next plot:
> Error in text.default(x, y, labels.id[ind],cex=cex, xpd=TRUE, :
>     could not find any X11 fonts
> Check that the Font Path is correct
>
> I have googled through the R-help list and it seems that such troubles
> already occured sometimes (see link below and threads)
>
> http://lists.freebsd.org/pipermail/freebsd-ports/2005-June/024091.html
> http://tolstoy.newcastle.edu.au/R/help/06/03/23864.html
>
> but did not find solution. Some messages claim it is a X11 problem (not
> R) some others suggest it may come from R. Some also mention that UTF-8
> may be a problem (though I don't have specific message on this from R).
> I have re-installed x11-common via the Synaptic package manager (so I
> suppose X11 is well installed) without improvement. I have checked
> /etc/X11/ xorg.conf
>
> Section "Files"
>     FontPath "/usr/share/X11/fonts/misc"
>     FontPath "/usr/share/X11/fonts/100dpi/:unscaled"
>     FontPath "/usr/share/X11/fonts/75dpi/:unscaled"
>     FontPath "/usr/share/X11/fonts/Type1"
>     FontPath "/usr/share/X11/fonts/100dpi"
>     FontPath "/usr/share/X11/fonts/75dpi"
>     FontPath "/usr/share/fonts/X11/misc"
>     FontPath "/var/lib/defoma/x-ttcidfont-conf.d/dirs/TrueType"
> Endsection
>
> but cannot identify where the problem is actually thus no remedy.
>
> Any idea?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Rich FitzJohn
rich.fitzjohn <at> gmail.com


From webmaster at citedesjeunes.com  Sun Dec 17 13:06:20 2006
From: webmaster at citedesjeunes.com (Webmaster)
Date: Sun, 17 Dec 2006 13:06:20 +0100
Subject: [R] Draw a circle on a filled.contour() plot
Message-ID: <84CC7344-49E5-4291-8D54-CD79C5C132DC@citedesjeunes.com>

Hi all,

I'm trying to use symbols() to draw a circle of a given radius at a  
given position onto a filled.contour() plot. The commands I issue are:

> filled.contour(y,x,z,levels=seq 
> (0.02,1.0,len=50),color.palette=colorRampPalette(c 
> ("blue","yellow","red")),title=title(main="",xlab="",ylab=""))
> symbols(0.62,0.0,circles=c(2.5),add=TRUE,inches=FALSE

As can be seen on the resulting PDF file (http://www.eleves.ens.fr/ 
home/coudert/hist_2d.pdf), the circle appears to have the right  
radius but its center is not the correct one [0.62, 0]. What am I  
missing here?

Thanks for your help,
FX

PS: complete input (5 lines), data file for the contour plot and PDF  
result on my system can be found at:
Data file: http://www.eleves.ens.fr/home/coudert/hist_2d
R script: http://www.eleves.ens.fr/home/coudert/hist_2d.R
PDF result: http://www.eleves.ens.fr/home/coudert/hist_2d.pdf


From murdoch at stats.uwo.ca  Sun Dec 17 13:32:43 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 17 Dec 2006 07:32:43 -0500
Subject: [R] Draw a circle on a filled.contour() plot
In-Reply-To: <84CC7344-49E5-4291-8D54-CD79C5C132DC@citedesjeunes.com>
References: <84CC7344-49E5-4291-8D54-CD79C5C132DC@citedesjeunes.com>
Message-ID: <458538EB.6010902@stats.uwo.ca>

On 12/17/2006 7:06 AM, Webmaster wrote:
> Hi all,
> 
> I'm trying to use symbols() to draw a circle of a given radius at a  
> given position onto a filled.contour() plot. The commands I issue are:
> 
>> filled.contour(y,x,z,levels=seq 
>> (0.02,1.0,len=50),color.palette=colorRampPalette(c 
>> ("blue","yellow","red")),title=title(main="",xlab="",ylab=""))
>> symbols(0.62,0.0,circles=c(2.5),add=TRUE,inches=FALSE
> 
> As can be seen on the resulting PDF file (http://www.eleves.ens.fr/ 
> home/coudert/hist_2d.pdf), the circle appears to have the right  
> radius but its center is not the correct one [0.62, 0]. What am I  
> missing here?

There's a note on the man page about this:

The output produced by 'filled.contour' is actually a combination
      of two plots; one is the filled contour and one is the legend.
      Two separate coordinate systems are set up for these two plots,
      but they are only used internally - once the function has returned
      these coordinate systems are lost.  If you want to annotate the
      main contour plot, for example to add points, you can specify
      graphics commands in the 'plot.axes' argument.  An example is
      given below.

Duncan Murdoch
> 
> Thanks for your help,
> FX
> 
> PS: complete input (5 lines), data file for the contour plot and PDF  
> result on my system can be found at:
> Data file: http://www.eleves.ens.fr/home/coudert/hist_2d
> R script: http://www.eleves.ens.fr/home/coudert/hist_2d.R
> PDF result: http://www.eleves.ens.fr/home/coudert/hist_2d.pdf
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Sun Dec 17 13:56:22 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 17 Dec 2006 07:56:22 -0500
Subject: [R] Collapsing across trials
In-Reply-To: <99c5443d0612162020w3838a865ud58fac375e65cea3@mail.gmail.com>
References: <99c5443d0612162020w3838a865ud58fac375e65cea3@mail.gmail.com>
Message-ID: <971536df0612170456p18e9c7f1j7d49a80ec5540d36@mail.gmail.com>

Try

aggregate(DF[4], DF[1:3], mean)


On 12/16/06, Pedro Alcocer <pealco at gmail.com> wrote:
> Hello,
>
> My ultimate goal is a repeated measures (mixed model) ANOVA, however,
> my present question is about how to reorganize my data into the format
> that the ANOVA commands expect. In particular, how to collapse across
> trials. (I am using the tutorial at
> [http://personality-project.org/r/r.anova.html] for the mixed model
> ANOVA)
>
> The data I am using looks like this. A subject sees 10 trials per
> condition and there are 2 conditions. I want the average of all the
> reaction times (RTs) from a subject looking a one condition. I also
> want to retain List in the final output.
>
> Subj    List    Condition       RT
> 2       1       C               338
> 2       1       C               227
> 2       1       C               430
> 2       1       C               621
> 2       1       C               255
> 2       1       C               348
> 2       1       C               280
> 2       1       C               356
> 2       1       C               272
> 2       1       C               346
> 3       2       C               489
> 3       2       C               426
> 3       2       C               352
> 3       2       C               351
> 3       2       C               349
> 3       2       C               403
> 3       2       C               336
> 3       2       C               278
> 3       2       C               365
> 3       2       C               271
> 2       1       D               360
> 2       1       D               374
> 2       1       D               326
> 2       1       D               363
> 2       1       D               290
> 2       1       D               458
> 2       1       D               295
> 2       1       D               362
> 2       1       D               285
> 2       1       D               277
> 3       2       D               354
> 3       2       D               352
> 3       2       D               362
> 3       2       D               360
> 3       2       D               334
> 3       2       D               365
> 3       2       D               335
> 3       2       D               391
> 3       2       D               272
> 3       2       D               618
>
> The result should look like this:
> 2       1       C               (AVG)
> 3       2       C               (AVG)
> 2       1       D               (AVG)
> 3       2       D               (AVG)
>
> Where (AVG) is the average of the 10 trials.
>
> The above is a simplified case. How can I do this with multiple RT
> measurements per subject? In other words, the above, but with more
> than one RT column per subject.
>
> Resulting in:
>
> Subj    List    Condition       RT1             RT2             RT3             RT4             RT5
> 2       1       C               (AVG1)  (AVG2)  (AVG2)  (AVG2)  (AVG2)
> 3       2       C               (AVG1)  (AVG2)  (AVG2)  (AVG2)  (AVG2)
> 2       1       D               (AVG1)  (AVG2)  (AVG2)  (AVG2)  (AVG2)
> 3       2       D               (AVG1)  (AVG2)  (AVG2)  (AVG2)  (AVG2)
>
> I've come across the apply and aggregate functions in online
> documentation, and I have the suspicion that they may be called for
> here, but their application isn't clear to me. I am fairly new to R.
>
> (I am using R 2.4.0 on Mac OS X.)
>
> I'd appreciate any insights.
>
> Pedro Alcocer
> University of Florida
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From nono.231 at gmail.com  Sun Dec 17 15:12:54 2006
From: nono.231 at gmail.com (Ilias Soumpasis)
Date: Sun, 17 Dec 2006 16:12:54 +0200
Subject: [R] X11 fonts and Ubuntu
In-Reply-To: <4584FCA2.5030207@univ-fcomte.fr>
References: <4584FCA2.5030207@univ-fcomte.fr>
Message-ID: <3ff92a550612170612l3c4473c6tf072964ac547799d@mail.gmail.com>

2006/12/17, Patrick Giraudoux <patrick.giraudoux at univ-fcomte.fr>:
> Hi,
>
> I am moving from Windows XP to Ubuntu 6.10 and installed R 2.4.0. When I
> run eg plot.lm  (things work fine with plot.default - eg
> plot(rnorm(30),rnorm(30)))
>
> plot(lmobject)
>
> I can get the first plot and then this message:
>
> Hit <Return> to see next plot:
> Error in text.default(x, y, labels.id[ind],cex=cex, xpd=TRUE, :
>     could not find any X11 fonts
> Check that the Font Path is correct
>
> I have googled through the R-help list and it seems that such troubles
> already occured sometimes (see link below and threads)
>
> http://lists.freebsd.org/pipermail/freebsd-ports/2005-June/024091.html
> http://tolstoy.newcastle.edu.au/R/help/06/03/23864.html
>
> but did not find solution. Some messages claim it is a X11 problem (not
> R) some others suggest it may come from R. Some also mention that UTF-8
> may be a problem (though I don't have specific message on this from R).
> I have re-installed x11-common via the Synaptic package manager (so I
> suppose X11 is well installed) without improvement. I have checked
> /etc/X11/ xorg.conf
>
> Section "Files"
>     FontPath "/usr/share/X11/fonts/misc"
>     FontPath "/usr/share/X11/fonts/100dpi/:unscaled"
>     FontPath "/usr/share/X11/fonts/75dpi/:unscaled"
>     FontPath "/usr/share/X11/fonts/Type1"
>     FontPath "/usr/share/X11/fonts/100dpi"
>     FontPath "/usr/share/X11/fonts/75dpi"
>     FontPath "/usr/share/fonts/X11/misc"
>     FontPath "/var/lib/defoma/x-ttcidfont-conf.d/dirs/TrueType"
> Endsection

You 'll have  to change the /usr/share/X11/fonts/ to
/usr/share/fonts/X11/. I have read many having similar problems and
solved them this way. The location changed so that all the fonts to be
under fonts). So give it a try and I believe that it will be fine.

>
> but cannot identify where the problem is actually thus no remedy.
>
> Any idea?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From webmaster at citedesjeunes.com  Sun Dec 17 15:31:25 2006
From: webmaster at citedesjeunes.com (Webmaster)
Date: Sun, 17 Dec 2006 15:31:25 +0100
Subject: [R] Draw a circle on a filled.contour() plot
In-Reply-To: <458538EB.6010902@stats.uwo.ca>
References: <84CC7344-49E5-4291-8D54-CD79C5C132DC@citedesjeunes.com>
	<458538EB.6010902@stats.uwo.ca>
Message-ID: <18F0349D-D4A8-4065-B406-A58320F2C229@citedesjeunes.com>

> The output produced by 'filled.contour' is actually a combination
>      of two plots; one is the filled contour and one is the legend.
>      Two separate coordinate systems are set up for these two plots,
>      but they are only used internally - once the function has  
> returned
>      these coordinate systems are lost.  If you want to annotate the
>      main contour plot, for example to add points, you can specify
>      graphics commands in the 'plot.axes' argument.  An example is
>      given below.

Thanks!

I now have another question (hopefully the last) for which I couldn't  
find an answer in the mailing-list archives: how can I get rid of the  
color key on the contour.filled() plot? I that question, unanswered,  
in a post one year ago on this same list, so I hope it's by any mean  
possible... (I think it's possible to change the code completely and  
use image(), but it's much less pretty).

FX


From patrick.giraudoux at univ-fcomte.fr  Sun Dec 17 16:01:21 2006
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 17 Dec 2006 16:01:21 +0100
Subject: [R] X11 fonts and Ubuntu
In-Reply-To: <3ff92a550612170612l3c4473c6tf072964ac547799d@mail.gmail.com>
References: <4584FCA2.5030207@univ-fcomte.fr>
	<3ff92a550612170612l3c4473c6tf072964ac547799d@mail.gmail.com>
Message-ID: <45855BC1.9080509@univ-fcomte.fr>

Did try it. Works fine now. Just need to reboot after having modified 
/etc/X11/ xorg.conf as following according to your instructions:

Section "Files"

    # path to defoma fonts
    FontPath     "/usr/share/fonts/X11/misc"
    FontPath     "/usr/share/fonts/X11/cyrillic"
    FontPath     "/usr/share/fonts/X11/100dpi/:unscaled"
    FontPath     "/usr/share/fonts/X11/75dpi/:unscaled"
    FontPath     "/usr/share/fonts/X11/Type1"
    FontPath     "/usr/share/fonts/X11/100dpi"
    FontPath     "/usr/share/fonts/X11/75dpi"
    FontPath     "/usr/share/fonts/X11/misc"
    FontPath     "/var/lib/defoma/x-ttcidfont-conf.d/dirs/TrueType"
EndSection

Thanks a lot,

Patrick


Ilias Soumpasis a ?crit :
> 2006/12/17, Patrick Giraudoux <patrick.giraudoux at univ-fcomte.fr>:
>> Hi,
>>
>> I am moving from Windows XP to Ubuntu 6.10 and installed R 2.4.0. When I
>> run eg plot.lm  (things work fine with plot.default - eg
>> plot(rnorm(30),rnorm(30)))
>>
>> plot(lmobject)
>>
>> I can get the first plot and then this message:
>>
>> Hit <Return> to see next plot:
>> Error in text.default(x, y, labels.id[ind],cex=cex, xpd=TRUE, :
>>     could not find any X11 fonts
>> Check that the Font Path is correct
>>
>> I have googled through the R-help list and it seems that such troubles
>> already occured sometimes (see link below and threads)
>>
>> http://lists.freebsd.org/pipermail/freebsd-ports/2005-June/024091.html
>> http://tolstoy.newcastle.edu.au/R/help/06/03/23864.html
>>
>> but did not find solution. Some messages claim it is a X11 problem (not
>> R) some others suggest it may come from R. Some also mention that UTF-8
>> may be a problem (though I don't have specific message on this from R).
>> I have re-installed x11-common via the Synaptic package manager (so I
>> suppose X11 is well installed) without improvement. I have checked
>> /etc/X11/ xorg.conf
>>
>> Section "Files"
>>     FontPath "/usr/share/X11/fonts/misc"
>>     FontPath "/usr/share/X11/fonts/100dpi/:unscaled"
>>     FontPath "/usr/share/X11/fonts/75dpi/:unscaled"
>>     FontPath "/usr/share/X11/fonts/Type1"
>>     FontPath "/usr/share/X11/fonts/100dpi"
>>     FontPath "/usr/share/X11/fonts/75dpi"
>>     FontPath "/usr/share/fonts/X11/misc"
>>     FontPath "/var/lib/defoma/x-ttcidfont-conf.d/dirs/TrueType"
>> Endsection
>
> You 'll have  to change the /usr/share/X11/fonts/ to
> /usr/share/fonts/X11/. I have read many having similar problems and
> solved them this way. The location changed so that all the fonts to be
> under fonts). So give it a try and I believe that it will be fine.
>
>>
>> but cannot identify where the problem is actually thus no remedy.
>>
>> Any idea?
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


From murdoch at stats.uwo.ca  Sun Dec 17 16:04:37 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 17 Dec 2006 10:04:37 -0500
Subject: [R] Draw a circle on a filled.contour() plot
In-Reply-To: <18F0349D-D4A8-4065-B406-A58320F2C229@citedesjeunes.com>
References: <84CC7344-49E5-4291-8D54-CD79C5C132DC@citedesjeunes.com>
	<458538EB.6010902@stats.uwo.ca>
	<18F0349D-D4A8-4065-B406-A58320F2C229@citedesjeunes.com>
Message-ID: <45855C85.9040706@stats.uwo.ca>

On 12/17/2006 9:31 AM, Webmaster wrote:
>> The output produced by 'filled.contour' is actually a combination
>>      of two plots; one is the filled contour and one is the legend.
>>      Two separate coordinate systems are set up for these two plots,
>>      but they are only used internally - once the function has  
>> returned
>>      these coordinate systems are lost.  If you want to annotate the
>>      main contour plot, for example to add points, you can specify
>>      graphics commands in the 'plot.axes' argument.  An example is
>>      given below.
> 
> Thanks!
> 
> I now have another question (hopefully the last) for which I couldn't  
> find an answer in the mailing-list archives: how can I get rid of the  
> color key on the contour.filled() plot? I that question, unanswered,  
> in a post one year ago on this same list, so I hope it's by any mean  
> possible... (I think it's possible to change the code completely and  
> use image(), but it's much less pretty).

I don't see any option in there, so you might have to write your own 
version to do it.  The source for the regular function is in

http://svn.r-project.org/R/trunk/src/library/graphics/R/filled.contour.R

and the part that plots the key is

     ## Plot the 'plot key' (scale):
     mar <- mar.orig
     mar[4] <- mar[2]
     mar[2] <- 1
     par(mar = mar)
     plot.new()
     plot.window(xlim=c(0,1), ylim=range(levels), xaxs="i", yaxs="i")
     rect(0, levels[-length(levels)], 1, levels[-1], col = col)
     if (missing(key.axes)) {
         if (axes)
             axis(4)
     }
     else key.axes
     box()
     if (!missing(key.title))
	key.title

You'd probably also want to change the layout, because you won't want 
the blank space there.  Or possibly you could get the results you want 
from contour(), which doesn't plot the scale.

Duncan Murdoch


From renaud.lancelot at gmail.com  Sun Dec 17 16:40:28 2006
From: renaud.lancelot at gmail.com (Renaud Lancelot)
Date: Sun, 17 Dec 2006 16:40:28 +0100
Subject: [R] Draw a circle on a filled.contour() plot
In-Reply-To: <18F0349D-D4A8-4065-B406-A58320F2C229@citedesjeunes.com>
References: <84CC7344-49E5-4291-8D54-CD79C5C132DC@citedesjeunes.com>
	<458538EB.6010902@stats.uwo.ca>
	<18F0349D-D4A8-4065-B406-A58320F2C229@citedesjeunes.com>
Message-ID: <c2ee56800612170740vd3139d8oa072b881ece727cb@mail.gmail.com>

Try levelplot in package lattice instead of filled.contour: you will
be able to annotate the plot using the grid package. Moreover, you can
remove the key using the colorkey argument.

library(lattice)
library(grid)
z <- as.matrix(read.table("hist_2d"))
dimnames(z) <- NULL
Data <- expand.grid(x = seq(-4.45, 4.45, len = 90),
                    y = seq(-4.45, 4.45, len = 90))
Data$z <- c(z)
rm(z)
Cols <- colorRampPalette(c("white", "blue","yellow","red"))
levelplot(z ~ x * y, data = Data,
  aspect = 1, colorkey = FALSE, col.regions = Cols(6),
    panel = function(...){
      panel.levelplot(...)
      grid.circle(x = 0.62, y = 0, r = 2.5, default.units = "native")
      })

Best,

Renaud

2006/12/17, Webmaster <webmaster at citedesjeunes.com>:
> > The output produced by 'filled.contour' is actually a combination
> >      of two plots; one is the filled contour and one is the legend.
> >      Two separate coordinate systems are set up for these two plots,
> >      but they are only used internally - once the function has
> > returned
> >      these coordinate systems are lost.  If you want to annotate the
> >      main contour plot, for example to add points, you can specify
> >      graphics commands in the 'plot.axes' argument.  An example is
> >      given below.
>
> Thanks!
>
> I now have another question (hopefully the last) for which I couldn't
> find an answer in the mailing-list archives: how can I get rid of the
> color key on the contour.filled() plot? I that question, unanswered,
> in a post one year ago on this same list, so I hope it's by any mean
> possible... (I think it's possible to change the code completely and
> use image(), but it's much less pretty).
>
> FX
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Renaud LANCELOT
D?partement Elevage et M?decine V?t?rinaire (EMVT) du CIRAD
Directeur adjoint charg? des affaires scientifiques

CIRAD, Animal Production and Veterinary Medicine Department
Deputy director for scientific affairs

Campus international de Baillarguet
TA 30 / B (B?t. B, Bur. 214)
34398 Montpellier Cedex 5 - France
T?l   +33 (0)4 67 59 37 17
Secr. +33 (0)4 67 59 39 04
Fax   +33 (0)4 67 59 37 95


From cpujoll at gmail.com  Sun Dec 17 18:05:51 2006
From: cpujoll at gmail.com (claire pujoll)
Date: Sun, 17 Dec 2006 18:05:51 +0100
Subject: [R] question
In-Reply-To: <ac12a4de0612121157j44cdd51dnb4f0363421de190a@mail.gmail.com>
References: <ac12a4de0612121157j44cdd51dnb4f0363421de190a@mail.gmail.com>
Message-ID: <ac12a4de0612170905p62fd407cua18e299ab2f14757@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061217/5029831b/attachment.pl 

From cpujoll at gmail.com  Sun Dec 17 18:10:46 2006
From: cpujoll at gmail.com (claire pujoll)
Date: Sun, 17 Dec 2006 18:10:46 +0100
Subject: [R] question
In-Reply-To: <ac12a4de0612170905p62fd407cua18e299ab2f14757@mail.gmail.com>
References: <ac12a4de0612121157j44cdd51dnb4f0363421de190a@mail.gmail.com>
	<ac12a4de0612170905p62fd407cua18e299ab2f14757@mail.gmail.com>
Message-ID: <ac12a4de0612170910ve17c7c6i760ed9cdcf52f5d9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061217/109c9d63/attachment.pl 

From drindskopf at gc.cuny.edu  Sun Dec 17 18:40:29 2006
From: drindskopf at gc.cuny.edu (David Rindskopf)
Date: Sun, 17 Dec 2006 12:40:29 -0500
Subject: [R] hblm program: porting from Splus to R
Message-ID: <4a8201c72202$726d8e90$0602a8c0@IBMLaptopA20>

I am replying to the email below my signature;
it is nominally about dmp files, but apparently
specific to problems with Bill DuMouchel's
hblm program.

I have been using this program
on Splus for years, and ran into some of the
same problems Jack did in trying to get it into
R.  I talked with Bill about it, and he didn't
know that there would be any problems; he
assumed that R was functionally identical to
Splus, and that the program should run.
Unfortunately, of course, that's not true.
I'm too much of a novice to figure it out, but
at least some problems seem to involve
scoping rule differences.  The NA coercion
apparently is something else, perhaps a character
being coerced to numeric?

As for legal issues, I can try to contact Bill
to be sure, but it seems obvious he intends the
program to be in the (noncommercial) public
domain.  The program remains on the AT&T
web site years after he left, and he seemed
perfectly fine with my attempt to port it to R.
At one time he had intended to develop a
commercial version, but as of the last time I
spoke with him (a couple of years ago) that
was on permanent hold.

If any of you are also interested in hblm,
I'd be glad to try to help resolve the technical
(and any legal) issues that arise.  The program
has wonderful graphics for meta-analysis,
though others are catching up now.

David
___________________________________

David Rindskopf
Educational Psychology
CUNY Graduate Center
365 Fifth Avenue
New York, NY 10016

(212) 817-8287
(212) 208-2690  (FAX)

____________________________________


Re: [R] Can anyone read a S-PLUS .dmp file for me?
Prof Brian Ripley
Wed, 06 Dec 2006 05:38:04 -0800
On Wed, 6 Dec 2006, John McHenry wrote:

> Anyone?

Yes, I can read it, but what use is that to you?  Given that it is someone
else's copyright work, I am not at liberty to redistribute a different
version:

   hblm and associated programs Copyright 1995 by William DuMouchel.
   Permission is given for not-for-profit redistribution of the hblm
   programs so long as this About.hblm variable is included unmodified.
   Please report problems, failures and successes of this program to
   [EMAIL PROTECTED]

The reason for the error is that it appears to contain invalid S data
frames.  (They are in invalid in R and in current S-PLUS, but they seems
also to have been invalid in S3.  Restoring dumps used to be one way to
create invalid objects, but many of the loopholes have been plugged in R.)

>
> John McHenry <[EMAIL PROTECTED]> wrote:    Hi WizaRds,
>
>  I tried reading the S-PLUS file
>
>  ftp://ftp.research.att.com/dist/bayes-meta/hblm.dmp
>
>  into R using
>
>  data.restore("hblm.dmp")
>
>  but I got an error:
>
>  Error in attributes(value) <- thelist[-match(c(".Data", ".Dim",
".Dimnames",
>  :
> row names must be 'character' or 'integer', not 'double'
> In addition: Warning message:
> NAs introduced by coercion
>
>  Does anyone know how to read this type of S-PLUS file into R? I am not
> familiar with it.
>  On http://cran.r-project.org/doc/manuals/R-data.html it is suggested that
>  "it is usually more reliable to dump the object(s) in S-PLUS and source
the
> dumpfile in R"
>  See also, http://tolstoy.newcastle.edu.au/R/help/05/12/18209.html
>
>  I don't know how this file was created. Could someone with S-PLUS access
> please see if they can read it?
>
>  Thanks!
>
>  Jack.


From aiminy at iastate.edu  Sun Dec 17 19:14:44 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Sun, 17 Dec 2006 12:14:44 -0600
Subject: [R] Start Matlab server in R 2.4.0
Message-ID: <6.1.2.0.2.20061217115548.01b989c8@aiminy.mail.iastate.edu>

In order to start matlab server in R , I using the following commands

getwd()
setwd("D:\R_matlab")
install.packages("R.oo")
install.packages("R.matlab")
install.packages("R.utils")
library(R.matlab)
Matlab$startServer()

a minimized MATLAB Command Window come out,
but I can't make this window become larger. Does anyone know why?

I type "Matlab$startServer()" again, I get another MATLAB Command Window
and I can maximize this window, From this window: I see such message:

  To get started, type one of these: helpwin, helpdesk, or demo.
   For product information, visit www.mathworks.com.

Matlab v7.x or higher detected.
Saving with option -V6.
Added InputStreamByteWrapper to dynamic Java CLASSPATH.
----------------------
Matlab server started!
----------------------
Trying to open server socket (port 9999)...??? Java exception occurred:
java.net.BindException: Address already in use: JVM_Bind

	at java.net.PlainSocketImpl.socketBind(Native Method)

	at java.net.PlainSocketImpl.bind(Unknown Source)

	at java.net.ServerSocket.bind(Unknown Source)

	at java.net.ServerSocket.<init>(Unknown Source)

	at java.net.ServerSocket.<init>(Unknown Source)
.

Error in ==> MatlabServer at 113
server = ServerSocket(port);

?

Does anyone would like to point out what is reason for these?

I am new to R.matlab. I am not sure if this question is too silly. Before I 
post this
question here, I did try to do google search to find answer by myself. 
But  I didn't get point.
If this question bother you too much, I am really sorry for this.

Thanks,

Aimin Yan


From spencer.graves at pdf.com  Sun Dec 17 22:38:55 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 17 Dec 2006 13:38:55 -0800
Subject: [R] Find S4 Generic?
Message-ID: <4585B8EF.9010005@pdf.com>

      How can I get the R code for "E" in the "distrEx" package?  The 
function call 'dumpMethods("E", "E.R")' created "E.R" in the working 
directory.  Unfortunately, it apparently contains 0 bytes. 

      Thanks,
      Spencer Graves


From Jean.Coursol at math.u-psud.fr  Sun Dec 17 23:04:34 2006
From: Jean.Coursol at math.u-psud.fr (Jean.Coursol at math.u-psud.fr)
Date: Sun, 17 Dec 2006 23:04:34 +0100
Subject: [R] Draw a circle on a filled.contour() plot
In-Reply-To: <c2ee56800612170740vd3139d8oa072b881ece727cb@mail.gmail.com>
References: <84CC7344-49E5-4291-8D54-CD79C5C132DC@citedesjeunes.com>
	<458538EB.6010902@stats.uwo.ca>
	<18F0349D-D4A8-4065-B406-A58320F2C229@citedesjeunes.com>
	<c2ee56800612170740vd3139d8oa072b881ece727cb@mail.gmail.com>
Message-ID: <20061217230434.ezqo9fm8o4wogogk@webmail.math.u-psud.fr>

Use my function filled.next:

filled.next <- function(fun) {
         mar.orig <- mar <- par("mar")
         w <- (3 + mar[2]) * par("csi") * 2.54
         layout(matrix(c(2, 1), nc = 2), widths = c(1, lcm(w)))
         mar[4] <- 1
         par(mar = mar)
         par(mfg=c(1,2))
         par(new=TRUE)
         fun
         par(mar = mar.orig)
}

# then

filled.contour(y,x,z,levels=seq(0.02,1.0,len=50),
     color.palette=colorRampPalette(c("blue","yellow","red")),
     title=title(main="",xlab="",ylab=""))
filled.next(symbols(0.62,0.0,circles=c(2.5),add=TRUE,inches=FALSE))



With plot function in filled.next, don't forget to add xaxs='i', yaxs='i'...

Jean Coursol

----------------------------------------------

Quoting Renaud Lancelot <renaud.lancelot at gmail.com>:

> Try levelplot in package lattice instead of filled.contour: you will
> be able to annotate the plot using the grid package. Moreover, you can
> remove the key using the colorkey argument.
>
> library(lattice)
> library(grid)
> z <- as.matrix(read.table("hist_2d"))
> dimnames(z) <- NULL
> Data <- expand.grid(x = seq(-4.45, 4.45, len = 90),
>                     y = seq(-4.45, 4.45, len = 90))
> Data$z <- c(z)
> rm(z)
> Cols <- colorRampPalette(c("white", "blue","yellow","red"))
> levelplot(z ~ x * y, data = Data,
>   aspect = 1, colorkey = FALSE, col.regions = Cols(6),
>     panel = function(...){
>       panel.levelplot(...)
>       grid.circle(x = 0.62, y = 0, r = 2.5, default.units = "native")
>       })
>
> Best,
>
> Renaud
>
> 2006/12/17, Webmaster <webmaster at citedesjeunes.com>:
>> > The output produced by 'filled.contour' is actually a combination
>> >      of two plots; one is the filled contour and one is the legend.
>> >      Two separate coordinate systems are set up for these two plots,
>> >      but they are only used internally - once the function has
>> > returned
>> >      these coordinate systems are lost.  If you want to annotate the
>> >      main contour plot, for example to add points, you can specify
>> >      graphics commands in the 'plot.axes' argument.  An example is
>> >      given below.
>>
>> Thanks!
>>
>> I now have another question (hopefully the last) for which I couldn't
>> find an answer in the mailing-list archives: how can I get rid of the
>> color key on the contour.filled() plot? I that question, unanswered,
>> in a post one year ago on this same list, so I hope it's by any mean
>> possible... (I think it's possible to change the code completely and
>> use image(), but it's much less pretty).
>>
>> FX
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Renaud LANCELOT
> D?partement Elevage et M?decine V?t?rinaire (EMVT) du CIRAD
> Directeur adjoint charg? des affaires scientifiques
>
> CIRAD, Animal Production and Veterinary Medicine Department
> Deputy director for scientific affairs
>
> Campus international de Baillarguet
> TA 30 / B (B?t. B, Bur. 214)
> 34398 Montpellier Cedex 5 - France
> T?l   +33 (0)4 67 59 37 17
> Secr. +33 (0)4 67 59 39 04
> Fax   +33 (0)4 67 59 37 95
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From henrikb at braju.com  Sun Dec 17 23:15:41 2006
From: henrikb at braju.com (Henrik Bengtsson)
Date: Mon, 18 Dec 2006 09:15:41 +1100
Subject: [R] Query regarding linking R with Matlab
In-Reply-To: <20061215122913.67988.qmail@web34308.mail.mud.yahoo.com>
References: <20061215122913.67988.qmail@web34308.mail.mud.yahoo.com>
Message-ID: <59d7961d0612171415p1edabe9eib19aab9fd6070f5b@mail.gmail.com>

Hi,

what operating system are you on and what version of Matlab do you have?

In general you should be able to get started with R.matlab by first
installing all required packages from CRAN:

install.packages(c("R.oo", "R.utils", "R.matlab"))

Then load the package:

library(R.matlab)

>From there just follow the example in help(Matlab):

# Create a Matlab client
matlab <- Matlab(host="localhost", port=9998)

# Connect to the Matlab server
if (!open(matlab))
  throw("Matlab server is not running: waited 30 seconds.")

# Run Matlab expressions on the Matlab server
res <- evaluate(matlab, "A=1+2;", "B=ones(2,20);")

# Get Matlab variables
data <- getVariable(matlab, c("A", "B"))
cat("Received variables:\n")
str(data)

...

# When done, close the Matlab client, which will also shutdown
# the Matlab server and the connection to it.
close(matlab)

Hope this helps

Henrik

On 12/15/06, Bhanu Kalyan.K <kalyansikha at yahoo.com> wrote:
> Thank you sir for your prompt reply.
>  Currently i am stuck at point where I need to call an available Matlab
> program from an R 2.4.0 interface. How can I do this? I have downloaded the
> R.matlab file and also the manual in pdf. But still i am not able to get
> through the problem. I will be grateful to you if you can elaborate me on
> this.
>
>  Awaiting your reply,
>
>  regards,
>  Bhanu Kalyan K
>
>
> Bhanu Kalyan K
> BTech CSE Final Year
> reach4kalyan at gmail.com
> Tel :+91-9885238228
>
>  __________________________________________________
> Do You Yahoo!?
> Tired of spam? Yahoo! Mail has the best spam protection around
> http://mail.yahoo.com


From hb at stat.berkeley.edu  Sun Dec 17 23:26:14 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Mon, 18 Dec 2006 09:26:14 +1100
Subject: [R] Start Matlab server in R 2.4.0
In-Reply-To: <6.1.2.0.2.20061217115548.01b989c8@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061217115548.01b989c8@aiminy.mail.iastate.edu>
Message-ID: <59d7961d0612171426i5912471v89c6e1df2776ad95@mail.gmail.com>

Hi.

On 12/18/06, Aimin Yan <aiminy at iastate.edu> wrote:
> In order to start matlab server in R , I using the following commands
>
> getwd()
> setwd("D:\R_matlab")
> install.packages("R.oo")
> install.packages("R.matlab")
> install.packages("R.utils")
> library(R.matlab)
> Matlab$startServer()
>
> a minimized MATLAB Command Window come out,
> but I can't make this window become larger. Does anyone know why?

You can change this, by calling

  Matlab$startServer(minimize=FALSE)

On Windows, Matlab is started minimized by default, because the
information in that window is of no interest (except for debugging)
and you cannot type anything in that window anyway.  However, read
further...

>
> I type "Matlab$startServer()" again, I get another MATLAB Command Window
> and I can maximize this window, From this window: I see such message:
>
>   To get started, type one of these: helpwin, helpdesk, or demo.
>    For product information, visit www.mathworks.com.
>
> Matlab v7.x or higher detected.
> Saving with option -V6.
> Added InputStreamByteWrapper to dynamic Java CLASSPATH.
> ----------------------
> Matlab server started!
> ----------------------
> Trying to open server socket (port 9999)...??? Java exception occurred:
> java.net.BindException: Address already in use: JVM_Bind
>
>         at java.net.PlainSocketImpl.socketBind(Native Method)
>
>         at java.net.PlainSocketImpl.bind(Unknown Source)
>
>         at java.net.ServerSocket.bind(Unknown Source)
>
>         at java.net.ServerSocket.<init>(Unknown Source)
>
>         at java.net.ServerSocket.<init>(Unknown Source)
> .
>
> Error in ==> MatlabServer at 113
> server = ServerSocket(port);
>
> ?
>
> Does anyone would like to point out what is reason for these?

The reason for this is that you already started one Matlab session
using (default) port 9999.  When you start the second one, the error
message (from Java) says that that port is already taken.  So this is
expected.  However, I am not sure why you can't maximize the first,
but the second.  Odd.  However, ...

>
> I am new to R.matlab. I am not sure if this question is too silly. Before I
> post this
> question here, I did try to do google search to find answer by myself.
> But  I didn't get point.
> If this question bother you too much, I am really sorry for this.

You do not have to start the Matlab server explicitly like this;
instead setup a Matlab object in R as illustrated in the
help(R.matlab) example and the server will be started when you call
open() on that object, e.g.

matlab <- Matlab(host="localhost", port=9998)
if (!open(matlab))
  throw("Matlab server is not running: waited 30 seconds.")

# If you get here, you have a working R-Matlab connection
BCD <- matrix(rnorm(10000), ncol=100)
setVariable(matlab, ABCD=ABCD)  # Send to Matlab
data <- getVariable(matlab, "ABCD") # Receive from Matlab
str(data)

The open() call will call Matlab$startServer() for you, and on Windows
it will be minimized, so in that sense there is no change.  But again,
there is not much for you to see there.

Hope this helps

Henrik

>
> Thanks,
>
> Aimin Yan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From milton_ruser at yahoo.com.br  Sun Dec 17 23:54:56 2006
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Sun, 17 Dec 2006 22:54:56 +0000 (GMT)
Subject: [R] fischer.test help
Message-ID: <929450.69054.qm@web56615.mail.re3.yahoo.com>

Um texto embutido e sem conjunto de caracteres especificado associado...
Nome: n?o dispon?vel
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061217/91002ee1/attachment.pl 

From ripley at stats.ox.ac.uk  Mon Dec 18 00:37:51 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 17 Dec 2006 23:37:51 +0000 (GMT)
Subject: [R] Find S4 Generic?
In-Reply-To: <4585B8EF.9010005@pdf.com>
References: <4585B8EF.9010005@pdf.com>
Message-ID: <Pine.LNX.4.64.0612172334300.26773@gannet.stats.ox.ac.uk>

Do you want E (type 'E') or its methods (getMethods(E) works for me)?

On Sun, 17 Dec 2006, Spencer Graves wrote:

>      How can I get the R code for "E" in the "distrEx" package?  The
> function call 'dumpMethods("E", "E.R")' created "E.R" in the working
> directory.  Unfortunately, it apparently contains 0 bytes.

See ?dumpMethods: you need to specify 'where' (as it says you may).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Mon Dec 18 01:17:51 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 18 Dec 2006 01:17:51 +0100
Subject: [R] fischer.test help
In-Reply-To: <929450.69054.qm@web56615.mail.re3.yahoo.com>
References: <929450.69054.qm@web56615.mail.re3.yahoo.com>
Message-ID: <4585DE2F.9010608@biostat.ku.dk>

Milton Cezar Ribeiro wrote:
> Hi there,
>    
>   I?m trying to follow the reading of the book "The Nature of Scientific Evidence" (by Mark Taper and Subhash Lele) using R. I would like to preparar R scritps from the exercises of this book available to world wide community. To do so, I will need some help of our R-helpers;
>    
>   On this book, the author proposed we use Fisher?s p-value tests for a pig sex rate = 0.5 from observed male=7929 and female 8304 (total = 16233). The authors sad "Under the assumed binomial distribution, the probability of observing 7929 male is .0000823; any observation with fewer than 7929 or more than 8303 males will have a probability less than or equal to .00008233 and thus be considered an extreme event". 
>    
>   They also sad "Summing the probability of all extreme events, we find that probability of observing an event as extrem as or more extreme than the observed 7929 males is 0.003331".
>    
>   How can a reach up these same p-values?
>   
dbinom, pbinom, binom.test

(This is an exact test in the binomial distribution, not what is 
commonly known as Fisher's exact test, which is for independence in a 
2x2 table.)

>    
>   Kind regards,
>    
>   Miltinho
>   Brazil
>
>  __________________________________________________
>
>
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Alexander.Herr at csiro.au  Mon Dec 18 01:56:50 2006
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Mon, 18 Dec 2006 10:56:50 +1000
Subject: [R] surface3d grid from xyz dataframe
Message-ID: <062AE320EF971E40ACD0F6C93391D769BD0BCD@exqld1-tsv.nexus.csiro.au>

Hi List,

I am trying to plot a grid with an overlayed height. I have a dataframe
with four variables:
x,y,gridvalue,height. The dataframe has 2.5mio observations (ie grid
points),

I assign colors through the gridvalue using map_color_gradient thus
producing:
x,y,gridvalue,height,gridcol as variables of the dataframe. The grid
dimensions are 1253 x 2001 (=2507253 data points).

My attempts with surface3d fail, mainly because I cannot produce the
matrix required for the height input. 

elev.to.list{CTFS} fails with: "Error in matrix(elevfile$elev, nrow=
1+ydim/gridsize, ncol=1+xdim/gridsize. : attempt to set an attribute on
NULL" which I assume means it requires a square grid (=quadrates).

Any ideas/help appreciated
Thanks
Herry


Dr Alexander Herr
Spatial and statistical analyst
CSIRO, Sustainable Ecosystems
Davies Laboratory,
University Drive, Douglas, QLD 4814 
Private Mail Bag, Aitkenvale, QLD 4814
 
Phone/www 
(07) 4753 8510; 4753 8650(fax)
Home: http://herry.ausbats.org.au
Webadmin ABS: http://ausbats.org.au
Sustainable Ecosystems: http://www.cse.csiro.au/


From murdoch at stats.uwo.ca  Mon Dec 18 02:49:46 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 17 Dec 2006 20:49:46 -0500
Subject: [R] surface3d grid from xyz dataframe
In-Reply-To: <062AE320EF971E40ACD0F6C93391D769BD0BCD@exqld1-tsv.nexus.csiro.au>
References: <062AE320EF971E40ACD0F6C93391D769BD0BCD@exqld1-tsv.nexus.csiro.au>
Message-ID: <4585F3BA.5050404@stats.uwo.ca>

On 12/17/2006 7:56 PM, Alexander.Herr at csiro.au wrote:
> Hi List,
> 
> I am trying to plot a grid with an overlayed height. I have a dataframe
> with four variables:
> x,y,gridvalue,height. The dataframe has 2.5mio observations (ie grid
> points),
> 
> I assign colors through the gridvalue using map_color_gradient thus
> producing:
> x,y,gridvalue,height,gridcol as variables of the dataframe. The grid
> dimensions are 1253 x 2001 (=2507253 data points).
> 
> My attempts with surface3d fail, mainly because I cannot produce the
> matrix required for the height input. 
> 
> elev.to.list{CTFS} fails with: "Error in matrix(elevfile$elev, nrow=
> 1+ydim/gridsize, ncol=1+xdim/gridsize. : attempt to set an attribute on
> NULL" which I assume means it requires a square grid (=quadrates).

When you are asking a question about a function from a contributed 
package, please state which package you found it in.  There's a 
surface3d function in the rgl package; is that the one you're using?  It 
takes input in the same format as contour() uses.  That is:  the x 
values should be a vector of values corresponding to the rows of a 
matrix, the y values correspond to the columns, the z values are in a 
matrix.

Since your data is in a dataframe, it's not the right shape.  How to get 
it into the right shape depends a lot on what the pattern of your data 
really is.  Do you have a relatively small number of x and y values, 
corresponding to rows and columns, or are they scattered over the 
region?  If the former, I'd convert them to integer values marking the 
positions, then use those to index into a matrix to place the z values 
there.

e.g. with data like this:

x y z
1 1 1
1 2 2
2 1 3
2 2 4

the x and y values are already integer valued, so you could use

x <- sort(unique(data$x))
y <- sort(unique(data$y))
z <- matrix(NA, length(x), length(y))
z[cbind(data$x, data$y)] <- data$z

Duncan Murdoch


From mharan at stat.psu.edu  Mon Dec 18 05:19:21 2006
From: mharan at stat.psu.edu (Murali Haran)
Date: Sun, 17 Dec 2006 23:19:21 -0500
Subject: [R] Rmath: R libraries from C on Mac OS X
Message-ID: <458616C9.5000108@stat.psu.edu>

Dear R-experts,

I have been having trouble using R's standalone random number generators 
from C on my Mac OS X 10.4.8 system.

I try to compile my C program in the following way:
gcc -Wall -o helloMac helloMac.c -lm -lRmath
I get the following error:
/usr/bin/ld: can't locate file for: -lRmath

I am unable to locate Rmath on my machine. The problem appears to be 
that no libRmath.a was built on my Mac OS X installation. 

Any pointers (perhaps to a step by step guide for a _beginner_ on how to 
install this and then how to compile the C code) would be most 
appreciated.For completeness, here is my C code (adapted from code that 
works fine on Linux):

#include<string.h>
#include<stdio.h>
#include<stdlib.h>
#define MATHLIB_STANDALONE 1
#include 
"/Library/Frameworks/R.framework/Versions/2.3/Resources/include/i386/Rmath.h"

int main(int argc, char *argv[]) {

  printf("hello world\n");
  printf("%lf\n",rnorm(5,2));
  return(0);
}

Many thanks in advance.

Murali


From cressonim at nhlbi.nih.gov  Mon Dec 18 06:15:59 2006
From: cressonim at nhlbi.nih.gov (Cressoni, Massimo (NIH/NHLBI) [F])
Date: Mon, 18 Dec 2006 00:15:59 -0500
Subject: [R] proc GLM with R
Message-ID: <B0F504209244B14EA9A4C1DFB599B9224FFDCB@NIHCESMLBX6.nih.gov>

I want to migrate from SAS to R.
I used proc mixed to do comparison between multiple groups and to perform
multiple comparison between groups since, as far as I know, proc mixed does not make assumptions about the data and so 
it is better than a simple anova (data must only be normal).
Es. how can I translate a code like this (two way anova with a factor of 
repetition) :


proc mixed;
class kind  PEEP codice;
model PaO2_FiO2 = kind PEEP kind*PEEP;
repeated /type = un sub=codice;
lsmeans kind*PEEP /adjust=bon;
run;

codice is a unique identifier of patient
kind is a variable which subdivided the patient (i.e. red or brown hairs)
PEEP is positive end expiratory pressure. These are the steps of a clinical
trial. Patient did the trial at PEEP = 5 and PEEP = 10

Thank you

Massimo Cressoni

run;


From edd at debian.org  Mon Dec 18 06:20:43 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 17 Dec 2006 23:20:43 -0600
Subject: [R] Rmath: R libraries from C on Mac OS X
In-Reply-To: <458616C9.5000108@stat.psu.edu>
References: <458616C9.5000108@stat.psu.edu>
Message-ID: <17798.9515.770484.641074@basebud.nulle.part>


On 17 December 2006 at 23:19, Murali Haran wrote:
| I have been having trouble using R's standalone random number generators 
| from C on my Mac OS X 10.4.8 system.
| 
| I try to compile my C program in the following way:
| gcc -Wall -o helloMac helloMac.c -lm -lRmath
| I get the following error:
| /usr/bin/ld: can't locate file for: -lRmath
| 
| I am unable to locate Rmath on my machine. The problem appears to be 
| that no libRmath.a was built on my Mac OS X installation. 
| 
| Any pointers (perhaps to a step by step guide for a _beginner_ on how to 
| install this and then how to compile the C code) would be most 
| appreciated.For completeness, here is my C code (adapted from code that 
| works fine on Linux):

As you indicate yourself, the issue is presumably that there is no libRmath.
So you need to build one.  For the Debian/Ubuntu packages, we do the
following:

        # make standalone math lib
	(cd src/nmath/standalone;				\
		$(MAKE)	CFLAGS="$(cflags) -D_REENTRANT"		\
			CXXFLAGS="$(cxxflags) -D_REENTRANT"	\
			FFLAGS="$(fcflags) -D_REENTRANT"	\
			CC=${compiler}				\
			CXX=${cxxcompiler}			\
			${fortrancompiler}			\
			libRmath_la_LDFLAGS=-Wl,-soname,libRmath.so.$(somaj) \
			)

I would expect that you need to do a similar

	$ cd src/nmath/standalone && make

along with whichever flags you may need.  Details can surely be found in the
'R Admin' manual you may want to consult for this.

Hth, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From Mat.Vanderklift at csiro.au  Mon Dec 18 02:07:52 2006
From: Mat.Vanderklift at csiro.au (Mat.Vanderklift at csiro.au)
Date: Mon, 18 Dec 2006 10:07:52 +0900
Subject: [R] Replacing labels with symbols in biplot
Message-ID: <F83C6ACE124F3E4D83B3A90C9CA0922D269EEB@exwa3-per.nexus.csiro.au>

Dear all
I would like to replace labels for x in biplot() with symbols (points)
that will visually illustrate different classes/groups. After an
unsuccessful search through the documents and archives, I turn to the
list for help - any suggestions that can point me in the right
direction?
Thanks
Mat Vanderklift


From Guojing.Yang at cdu.edu.au  Mon Dec 18 05:57:21 2006
From: Guojing.Yang at cdu.edu.au (Guojing Yang)
Date: Mon, 18 Dec 2006 14:27:21 +0930
Subject: [R] A question on lmer() function
Message-ID: <5A3E65F71DFAAE41AC2D20B61B177C5ED0F991@CDU-MAIL.cdu-staff.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061218/9eff0deb/attachment.pl 

From petr.pikal at precheza.cz  Mon Dec 18 09:19:39 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 18 Dec 2006 09:19:39 +0100
Subject: [R] Draw a circle on a filled.contour() plot
In-Reply-To: <45855C85.9040706@stats.uwo.ca>
References: <18F0349D-D4A8-4065-B406-A58320F2C229@citedesjeunes.com>
Message-ID: <45865D2B.15071.6DDBC7@localhost>

Hi

On 17 Dec 2006 at 10:04, Duncan Murdoch wrote:

Date sent:      	Sun, 17 Dec 2006 10:04:37 -0500
From:           	Duncan Murdoch <murdoch at stats.uwo.ca>
To:             	Webmaster <webmaster at citedesjeunes.com>
Copies to:      	r-help at stat.math.ethz.ch
Subject:        	Re: [R] Draw a circle on a filled.contour() plot

> On 12/17/2006 9:31 AM, Webmaster wrote:
> >> The output produced by 'filled.contour' is actually a combination
> >>      of two plots; one is the filled contour and one is the legend.
> >>      Two separate coordinate systems are set up for these two
> >>      plots, but they are only used internally - once the function
> >>      has  
> >> returned
> >>      these coordinate systems are lost.  If you want to annotate
> >>      the main contour plot, for example to add points, you can
> >>      specify graphics commands in the 'plot.axes' argument.  An
> >>      example is given below.
> > 
> > Thanks!
> > 
> > I now have another question (hopefully the last) for which I
> > couldn't  find an answer in the mailing-list archives: how can I get
> > rid of the  color key on the contour.filled() plot? I that question,
> > unanswered,  in a post one year ago on this same list, so I hope
> > it's by any mean  possible... (I think it's possible to change the
> > code completely and  use image(), but it's much less pretty).

You possibly can use

image(...)
contour(..., add=T)

to get contours overlayed e.g.

x <- y <- seq(-4*pi, 4*pi, len=27)
r <- sqrt(outer(x^2, y^2, "+"))
image(z = z <- cos(r^2)*exp(-r/6), col=gray((0:32)/32))
image(z, axes = FALSE, main = "Math can be beautiful ...",
      xlab = expression(cos(r^2) * e^{-r/6}))
contour(z, add = TRUE, drawlabels = FALSE)

HTH
Petr



> 
> I don't see any option in there, so you might have to write your own
> version to do it.  The source for the regular function is in
> 
> http://svn.r-project.org/R/trunk/src/library/graphics/R/filled.contour
> .R
> 
> and the part that plots the key is
> 
>      ## Plot the 'plot key' (scale):
>      mar <- mar.orig
>      mar[4] <- mar[2]
>      mar[2] <- 1
>      par(mar = mar)
>      plot.new()
>      plot.window(xlim=c(0,1), ylim=range(levels), xaxs="i", yaxs="i")
>      rect(0, levels[-length(levels)], 1, levels[-1], col = col) if
>      (missing(key.axes)) {
>          if (axes)
>              axis(4)
>      }
>      else key.axes
>      box()
>      if (!missing(key.title))
>  key.title
> 
> You'd probably also want to change the layout, because you won't want
> the blank space there.  Or possibly you could get the results you want
> from contour(), which doesn't plot the scale.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

Petr Pikal
petr.pikal at precheza.cz


From r.hankin at noc.soton.ac.uk  Mon Dec 18 09:24:59 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Mon, 18 Dec 2006 08:24:59 +0000
Subject: [R] write() gotcha
Message-ID: <6ABA5A3B-B7C4-4278-A193-FCC72A4D809B@soc.soton.ac.uk>

Hi

I used write() the other day to save some results.

It seems that write() does not record the full precision of
the objects being written:


 > write(pi,file="~/f",ncolumns=1)
 > pi.saved <- scan("~/f")
Read 1 item
 > dput(pi)
3.14159265358979
 > dput(pi.saved)
3.141593
 > pi-pi.saved
[1] -3.464102e-07
 >


This difficulty was particularly difficult to find because pi.saved   
*looks*
the same as pi.



What's going on here?






 > R.Version()
$platform
[1] "powerpc-apple-darwin8.7.0"

$arch
[1] "powerpc"

$os
[1] "darwin8.7.0"

$system
[1] "powerpc, darwin8.7.0"

$status
[1] ""

$major
[1] "2"

$minor
[1] "4.0"

$year
[1] "2006"

$month
[1] "10"

$day
[1] "03"

$`svn rev`
[1] "39566"

$language
[1] "R"

$version.string
[1] "R version 2.4.0 (2006-10-03)"


--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From xmeng at capitalbio.com  Mon Dec 18 10:03:29 2006
From: xmeng at capitalbio.com (XinMeng)
Date: Mon, 18 Dec 2006 17:03:29 +0800
Subject: [R] plot
Message-ID: <366432610.28012@capitalbio.com>

Hello sir:
a data with 2 columns:
id x
a  1
b  2
c  3

I wanna get such kind of plot:
x: a b c
y:1 2 3

But the plot command doesn't permit string character as x.

How can I get it ?

Thanks a lot !

My best


From ripley at stats.ox.ac.uk  Mon Dec 18 09:50:16 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 18 Dec 2006 08:50:16 +0000 (GMT)
Subject: [R] write() gotcha
In-Reply-To: <6ABA5A3B-B7C4-4278-A193-FCC72A4D809B@soc.soton.ac.uk>
References: <6ABA5A3B-B7C4-4278-A193-FCC72A4D809B@soc.soton.ac.uk>
Message-ID: <Pine.LNX.4.64.0612180848080.2591@gannet.stats.ox.ac.uk>

On Mon, 18 Dec 2006, Robin Hankin wrote:

> Hi
>
> I used write() the other day to save some results.

Why not save()?  It is the only way to preserve the results exactly.

> It seems that write() does not record the full precision of
> the objects being written:
>
>
> > write(pi,file="~/f",ncolumns=1)
> > pi.saved <- scan("~/f")
> Read 1 item
> > dput(pi)
> 3.14159265358979
> > dput(pi.saved)
> 3.141593
> > pi-pi.saved
> [1] -3.464102e-07
> >
>
>
> This difficulty was particularly difficult to find because pi.saved
> *looks*
> the same as pi.
>
>
>
> What's going on here?

See ?cat, for which write is a wrapper.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From r.hankin at noc.soton.ac.uk  Mon Dec 18 10:07:58 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Mon, 18 Dec 2006 09:07:58 +0000
Subject: [R] write() gotcha
In-Reply-To: <Pine.LNX.4.64.0612180848080.2591@gannet.stats.ox.ac.uk>
References: <6ABA5A3B-B7C4-4278-A193-FCC72A4D809B@soc.soton.ac.uk>
	<Pine.LNX.4.64.0612180848080.2591@gannet.stats.ox.ac.uk>
Message-ID: <154F2686-5378-4E9E-AEA4-96207DF08962@soc.soton.ac.uk>


On 18 Dec 2006, at 08:50, Prof Brian Ripley wrote:

> On Mon, 18 Dec 2006, Robin Hankin wrote:
>
>> Hi
>>
>> I used write() the other day to save some results.
>
> Why not save()?  It is the only way to preserve the results exactly.
>
>> It seems that write() does not record the full precision of
>> the objects being written:
>>
>> [snip]
>>
>> What's going on here?
>
> See ?cat, for which write is a wrapper.
>
>



Professor Ripley

Thanks for this.  I'll use save() instead.

Also, could we clarify this issue in the write() manpage?  Although its
behaviour is  clear from the code, I'm sure other R users would
appreciate a hint or a warning that precision might be lost.  It cost
me a few hours of worry last night!



--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From ripley at stats.ox.ac.uk  Mon Dec 18 10:27:49 2006
From: ripley at stats.ox.ac.uk (Brian Ripley)
Date: Mon, 18 Dec 2006 09:27:49 +0000 (GMT)
Subject: [R] write() gotcha
In-Reply-To: <154F2686-5378-4E9E-AEA4-96207DF08962@soc.soton.ac.uk>
References: <6ABA5A3B-B7C4-4278-A193-FCC72A4D809B@soc.soton.ac.uk>
	<Pine.LNX.4.64.0612180848080.2591@gannet.stats.ox.ac.uk>
	<154F2686-5378-4E9E-AEA4-96207DF08962@soc.soton.ac.uk>
Message-ID: <Pine.LNX.4.64.0612180926020.10101@auk.stats>

On Mon, 18 Dec 2006, Robin Hankin wrote:

>
> On 18 Dec 2006, at 08:50, Prof Brian Ripley wrote:
>
>> On Mon, 18 Dec 2006, Robin Hankin wrote:
>> 
>>> Hi
>>> 
>>> I used write() the other day to save some results.
>> 
>> Why not save()?  It is the only way to preserve the results exactly.
>> 
>>> It seems that write() does not record the full precision of
>>> the objects being written:
>>> 
>>> [snip]
>>> 
>>> What's going on here?
>> 
>> See ?cat, for which write is a wrapper.
>> 
>> 
>
>
>
> Professor Ripley
>
> Thanks for this.  I'll use save() instead.
>
> Also, could we clarify this issue in the write() manpage?  Although its
> behaviour is  clear from the code, I'm sure other R users would
> appreciate a hint or a warning that precision might be lost.  It cost
> me a few hours of worry last night!

Already done (via a xref to cat for the format used)!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From joachim.claudet at gmail.com  Mon Dec 18 10:42:16 2006
From: joachim.claudet at gmail.com (Joachim Claudet)
Date: Mon, 18 Dec 2006 10:42:16 +0100
Subject: [R] Aggregate with numerous factors
Message-ID: <45866278.8000009@gmail.com>

Dear list members,

I am facing some problems using the aggregate() function.
I want to calculate a sum and a mean of one variable over the 
combination of 12 factors with the aggregate() function to avoid loops 
but it doesn't work (or the job is far too long, it exceeds 2 hours). It 
works with a fewer number of factors, so I constructed a factor being 
the levels combination of 7 factors (I need the other ones being on 
their own). I had then 6 factors, but it still doesn't work.
Could someone tell me how to fix the problem or know another function I 
could use ?
Thank you very much,
Joachim Claudet.

-- 
<?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><

Joachim Claudet

PhD

EPHE - CNRS FRE 2935
52, avenue Paul Alduy
66860 Perpignan cedex
Tel : 33 4 68662055
Fax : 33 4 68503686


<?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><  <?)))><


From ccleland at optonline.net  Mon Dec 18 10:46:58 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Mon, 18 Dec 2006 04:46:58 -0500
Subject: [R] plot
In-Reply-To: <366432610.28012@capitalbio.com>
References: <366432610.28012@capitalbio.com>
Message-ID: <45866392.5070705@optonline.net>

XinMeng wrote:
> Hello sir:
> a data with 2 columns:
> id x
> a  1
> b  2
> c  3
> 
> I wanna get such kind of plot:
> x: a b c
> y:1 2 3
> 
> But the plot command doesn't permit string character as x.
> 
> How can I get it ?

  What sort of plot do you want?  For a barplot() of x with bars labeled
by id you could do this:

df <- data.frame(id = c("a","b","c"), x = 1:3, stringsAsFactors=FALSE)
with(df, barplot(x, names.arg = id))

> Thanks a lot !
> 
> My best
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From iriskolder at yahoo.com  Mon Dec 18 11:19:48 2006
From: iriskolder at yahoo.com (Iris Kolder)
Date: Mon, 18 Dec 2006 02:19:48 -0800 (PST)
Subject: [R] Memory problem on a  linux cluster using a large data set
Message-ID: <20061218101948.96145.qmail@web51702.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061218/1d35b181/attachment.pl 

From P.Dalgaard at biostat.ku.dk  Mon Dec 18 11:15:13 2006
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 18 Dec 2006 11:15:13 +0100
Subject: [R] R 2.4.1 is released
Message-ID: <45866A31.5070504@biostat.ku.dk>

I've rolled up R-2.4.1.tar.gz a short while ago. This is a maintenance
release and fixes a number of mostly minor bugs. See the full list
of changes below.

You can get it (in a short while) from

http://cran.r-project.org/src/base/R-2/R-2.4.1.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you. Binaries
for various platforms will appear in due course.
 
        For the R Core Team

        Peter Dalgaard

These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:

a8efde35b940278de19730d326f58449  AUTHORS
eb723b61539feef013de476e68b5c50a  COPYING
a6f89e2100d9b6cdffcea4f398e37343  COPYING.LIB
62b256c4a06aeed7401c9430f1e41d0f  FAQ
70447ae7f2c35233d3065b004aa4f331  INSTALL
06f14fbf950fbc7df31028344c78163b  NEWS
88bbd6781faedc788a1cbd434194480c  ONEWS
4f004de59e24a52d0f500063b4603bcb  OONEWS
92b33fd2c3e770d595c1a472889230d5  R-2.4.1.tar.gz
92b33fd2c3e770d595c1a472889230d5  R-latest.tar.gz
433182754c05c2cf7a04ad0da474a1d0  README
020479f381d5f9038dcb18708997f5da  RESOURCES
4eaf8a3e428694523edc16feb0140206  THANKS


Here is the relevant bit of the NEWS file:

               CHANGES IN R VERSION 2.4.1


INSTALLATION

    o   The extraction of info from Subversion for an SVN checkout now
        also works for svn >= 1.4.0.  However, on Windows the 'Last
        Changed Date' will be in the local timezone, and not in GMT as
        previously.

    o   configure uses code borrowed from autoconf 2.60 to try harder to
        ensure that a C99-compliant compiler is used.  (It does so by
        appending to CC.)  This avoids problems with systems such as FC5
        which override CFLAGS and thereby lose flags such as -std=gnu99.


NEW FEATURES

    o   rainbow(), heat.colors(), terrain.colors(), topo.colors() and
        cm.colors() all gain an 'alpha' argument to be passed to hsv().

    o   dput() will give an incorrect representation of the row names
        of a data frame with integer row names.  This is now corrected
        when the object is recreated.


C-LEVEL FACILITIES

    o   Using STRICT_R_HEADERS applies to more reported clashes with
        Windows headers, including Calloc and Realloc.  These and
        Free need to be prefixed by R_ when STRICT_R_HEADERS is defined.


DEPRECATED & DEFUNCT

    o   The previously undocumented behaviour of structure() in adding a
        class when specifying "tsp" or "levels" attributes is now
        deprecated (with a warning).


BUG FIXES

    o   Fixed warning() to use .dfltWarn intead of .dfltStop for default
        handling (PR#9274).

    o   R would slow down when the product of the length of a vector and
        the length of a character vector used to subset it exceeded 2^31.
        (PR#9280)

    o   merge() now allows zero-row data frames.

    o   add1.lm() had been broken by other changes for weighted fits.

    o   axis.POSIXct() would sometimes give the wrong labels.

    o   Help for a method call would fail. (PR#9291)

    o   gzfile() returned an object of class "file" not "gzfile". (PR#9271)

    o   load()ing from a connection had a logic bug in when it closed
        the connection. (PR#9271)

    o   The lowess() algorithm is unstable if the MAD of the residuals
        becomes (effectively) zero: R now terminates the iterations at
        that point.  (This may result in quite different answers.)

        The 'delta' argument was incorrectly documented.  (PR#9264)

    o   abbreviate() would only work for strings of up to 8191 bytes,
        but this was not checked.  Now longer strings are errors.

    o   Drawing X11 rotated text was buggy for VERY small (negative)
        angle of rotation.  Reported by Ben Bolker. (PR#9301)

    o   The X11 data editor would crash in an MBCS locale if R was
        compiled with FC's CFLAGS that add buffer overflow and
        stack-smashing detection.

    o   rect() was not accepting border=NA in some cases involving
        cross-hatching.

    o   Fixes to S4 group generics to ensure that the correct number of
        active arguments are in the signature of the group and all
        members.  Also a fix to keep the 'groupMembers' slot up to date.

    o   S4 group generic "Logic" (with '&', '|', but not '!') has been
        created, following the green book (apart from '!').

    o   removeClass() now takes care to remove any subclass references
        to the deleted class.

    o   mle() (in stats4) might not have worked as intended when the
        order of parameters in 'start' differed from that in the
        log-likelihood.  (PR#9313)

    o   dotchart() now properly restores par() settings after itself.

    o   system() on Mac OS X was blocking arbitrary signals during the
        call although only SIGPROF was meant to be blocked.

    o   methods cached via callNextMethod() and (sometimes) as() were
        being cached as directly specified although in fact they were
        inherited.  Caused problems in later search for inherited methods.

    o   str() works properly for method definitions and other S4-classed
        function objects.

    o   JAVA_LIBS are now set correctly on MacOS X.

    o   Fix null-termination issue suspected of causing crash with Fedora
        Extra RPMS (PR#9339, Justin Harrington, analysis and fix from Bill
        Dunlap).

    o   Namespaces restored via a saved session silently failed to cache
        their methods because the methods package was not yet
        attached.  Fixed by attaching methods before restoring data.

    o   rbind()ing a list to a data frame generated invalid row names,
        which were an error in 2.4.0. (PR#9346)

    o   boxplot.stats(x) now returns the correct minimum instead of an
        error for x <- c(1,Inf,Inf,Inf), and hence boxplot(x) "works".

    o   promptClass() now uses \linkS4class{<ClassName>} instead of
        of \link{<ClassName>-class}.

    o   gc() no longer reports nonsense values for the number of used
        Vcells if the true value exceeds 2^31 (and hence over 16Gb of
        heap is in use): it now reports NA. (PR#9345)

    o   rapply() now detects more user errors in supplying arguments.
(PR#9349)

    o   boxplot() was ignoring argument 'boxfill'. (PR#9352)

    o   plot.lm(which = 6, id.n = 0) did not work. (PR#9333)

    o   .deparseOpts("delayPromises") was not matching the C code,
        returning 64 rather than 32.

    o   bxp() could use partial matching on 'pars' when finding
        defaults for some of its parameters, e.g. a setting of 'cex.axis'
        in 'pars' or inline was used to set a default for 'outcex'.

    o   acf() now allows lag.max = 0 except when type="partial", and
        forces the lag 0 autocorrelation to 1. (PR#9360)

    o   hist(*, include.lowest=., right=., plot=FALSE) does not warn
        anymore, (PR#9356) and more.

    o   Some bugs in caching superclass/subclass relations and in
        removing those relations on detach and on removeClass() have
        been fixed.

    o   readBin() could return one too many strings if 'n' was an
        over-estimate. (PR#9361)

    o   A request for an opaque colour in the pdf() device after a
        translucent one did not set the transparency back to opaque in
        2.4.0.

        Semi-transparent background colours were not being plotted on
        the pdf() device.

    o   plot.lm(which=5) in the case of constant leverage re-ordered
        the factor levels but not the residuals, so the labelling by
        factor level was often incorrect.

    o   packBits() was not accepting a logical argument. (PR#9374)

    o   make install was omitting doc/FAQ and doc/RESOURCES.

    o   A two-sample t.test(x, y, var.equal=TRUE) did not allow one of the
        groups to be of size one.

    o   The "ts" method for print() failed on some corrupted objects
        of class "ts", e.g. those without a "tsp" attribute.

    o   structure() reordered the "class" value given if there was a
        "tsp" value specified.

    o   pairs() now does pass appropriate parts of '...' to the
        'diag.panel' argument. (PR#9384)

    o   plot.lm() was using an incorrect estimate of dispersion for
        some GLMs (including family=binomial and family=poisson).
        (PR#9316)

    o   Subsetting operators were setting R_Visible too early, so
        assignments in arguments could make the result invisible.
        (PR#9263)

    o   The tk-GUI was displaying a warning due to an extra comma in
        the list of manuals (PR#9396)

    o   packageDescription() now gives an explicit error on a corrupt
        DESCRIPTION file.

    o   There was a scoping issue with tcltk callbacks given as
        unevaluated expressions. This has only been partially fixed, a
        complete fix probably requires redesign.

    o   trace() had its return value documented incorrectly and was
        sometimes visible when it should not have been.

    o   pchisq() would sometimes use the wrong tail when calculating
        non-central probabilities with lower.tail = FALSE. (PR#9406)

    o   rm() could remove the wrong objects when passed an expression.
        (PR#9399)  Now only names are allowed in the '...' argument,
        and the incorrect documentation of what happened with
        character objects is corrected.

    o   url() was not supporting 'encoding' except on file:// URLs.



-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907

_______________________________________________
R-announce at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From P.Dalgaard at biostat.ku.dk  Mon Dec 18 11:55:10 2006
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 18 Dec 2006 11:55:10 +0100
Subject: [R] Aggregate with numerous factors
In-Reply-To: <45866278.8000009@gmail.com>
References: <45866278.8000009@gmail.com>
Message-ID: <4586738E.4040608@biostat.ku.dk>

Joachim Claudet wrote:
> Dear list members,
>
> I am facing some problems using the aggregate() function.
> I want to calculate a sum and a mean of one variable over the 
> combination of 12 factors with the aggregate() function to avoid loops 
> but it doesn't work (or the job is far too long, it exceeds 2 hours). It 
> works with a fewer number of factors, so I constructed a factor being 
> the levels combination of 7 factors (I need the other ones being on 
> their own). I had then 6 factors, but it still doesn't work.
> Could someone tell me how to fix the problem or know another function I 
> could use ?
> Thank you very much,
> Joachim Claudet.
>
>   
aggregate() is (currently) a wrapper for tapply(), so generates a table
which is indexed by the cartesian product of all the factors. If many cells
are empty, you can reduce the work by calculating the interaction factor up
front and remove levels that are not present in the data. This is pretty
much
the idea you already had, unless you forgot the bit about removing unused
levels. You could potentially extend the idea to all 12 factors, and then
extract the ones you want "on their own" from the result.

Alternatively, rewrite aggregate() and send us a patch ;-)

It is not necessarily all that hard. Here's a rough idea

IX <- as.data.frame(by)
OO <- do.call(order,IX)
Y <- x[OO,]
g <- cumsum(!duplicated(IX))
FF <- unique(IX)
cbind(FF, sapply(split(x,g),FUN))

(completely untested, of course, and if it works, it works only for a
single-column x; otherwise, you need a loop over the columns somehow.)

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From P.Dalgaard at biostat.ku.dk  Mon Dec 18 12:11:52 2006
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 18 Dec 2006 12:11:52 +0100
Subject: [R] Aggregate with numerous factors
In-Reply-To: <4586738E.4040608@biostat.ku.dk>
References: <45866278.8000009@gmail.com> <4586738E.4040608@biostat.ku.dk>
Message-ID: <45867778.3050407@biostat.ku.dk>

Peter Dalgaard wrote:
> Alternatively, rewrite aggregate() and send us a patch ;-)
>
> It is not necessarily all that hard. Here's a rough idea
>
> IX <- as.data.frame(by)
> OO <- do.call(order,IX)
> Y <- x[OO,]
> g <- cumsum(!duplicated(IX))
> FF <- unique(IX)
> cbind(FF, sapply(split(x,g),FUN))
>
> (completely untested, of course, and if it works, it works only for a
> single-column x; otherwise, you need a loop over the columns somehow.
>   
I see two glaring blunders already...

You need IX[OO,] in two places, and split(Y, g) not x

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From osiander.meixner at hp.com  Mon Dec 18 12:15:26 2006
From: osiander.meixner at hp.com (Meixner, Osiander (CRT Austria))
Date: Mon, 18 Dec 2006 12:15:26 +0100
Subject: [R] odfWeave: avoid zip.exe version 2.1 (Windows)
Message-ID: <A1CEF60D1E4CAB4FB6A4A40A5B60C833025761E5@AUIEXC02.emea.cpqcorp.net>


odfWeave: avoid zip.exe version 2.1 on Windows

Problem:
========

After weaving with odfWeave the .odt file can not be opened with
OpenOfice.org 2.1 Writer. Writer instead launches the Filter Selection
but none of the formats offered works.

My system:
  R-2.4.0
  odfWeave 0.4.4 package from CRAN
  OpenOffice.org 2.1 full install
  odt-test files: the included .odt files from the odfWeave package
  Windows XP Professional


Analysis with Winzip shows that the .odt file is incomplete: the odt is
missing the directories
  Configurations2
  META-INF
  Thumbnails



Solution:
=========

I had an older zip.exe on my system: Zip 2.1 (April 27th 1996) which
causes the troubles.

Zip 2.32 (June 19th 2006) works.

I downloaded the file zip232xN from http://www.info-zip.org/ (Poland
server)


-- 
Osiander


From Timothy.Mak at iop.kcl.ac.uk  Mon Dec 18 12:06:46 2006
From: Timothy.Mak at iop.kcl.ac.uk (Timothy.Mak at iop.kcl.ac.uk)
Date: Mon, 18 Dec 2006 11:06:46 +0000
Subject: [R] return()
Message-ID: <OFFB56F4D3.5C9B006B-ON80257248.003CC983-80257248.003E0833@iop.kcl.ac.uk>

Dear R Help, 

Why is it that if you try to return more than one objects using return(), 
it says it is 'deprecated'? So how do I return more than 1 objects back to 
the parent function? 

Thanks, 

Tim


From j.zutt at tudelft.nl  Mon Dec 18 12:29:04 2006
From: j.zutt at tudelft.nl (Jonne Zutt)
Date: Mon, 18 Dec 2006 12:29:04 +0100
Subject: [R] return()
In-Reply-To: <OFFB56F4D3.5C9B006B-ON80257248.003CC983-80257248.003E0833@iop.kcl.ac.uk>
References: <OFFB56F4D3.5C9B006B-ON80257248.003CC983-80257248.003E0833@iop.kcl.ac.uk>
Message-ID: <45867B80.2060800@tudelft.nl>

Well, put it in a list and return that list.
It's all written in ?return by the way.

Timothy.Mak at iop.kcl.ac.uk wrote:
> Dear R Help, 
>
> Why is it that if you try to return more than one objects using return(), 
> it says it is 'deprecated'? So how do I return more than 1 objects back to 
> the parent function? 
>
> Thanks, 
>
> Tim
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sarah.goslee at gmail.com  Mon Dec 18 12:53:17 2006
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 18 Dec 2006 06:53:17 -0500
Subject: [R] Replacing labels with symbols in biplot
In-Reply-To: <F83C6ACE124F3E4D83B3A90C9CA0922D269EEB@exwa3-per.nexus.csiro.au>
References: <F83C6ACE124F3E4D83B3A90C9CA0922D269EEB@exwa3-per.nexus.csiro.au>
Message-ID: <efb536d50612180353h2c2dcc89l940131b13a4f7c3f@mail.gmail.com>

Hi Mat,

You can more-or-less do what you want with the xlabs argument to
biplot. It only takes characters, rather than the normal plot symbol
codes, though. If you need symbols, you can "cheat" with things like
+ o x. I usually use letters for the different groups within the data:

> temp <- matrix(runif(50), nrow=10)
> temp.pca <- princomp(temp)
> biplot(temp.pca, xlabs=c("A", "A", "B", "B", "B", "C", "C", "C", "D", "D"))
>

Sarah

On 12/17/06, Mat.Vanderklift at csiro.au <Mat.Vanderklift at csiro.au> wrote:
> Dear all
> I would like to replace labels for x in biplot() with symbols (points)
> that will visually illustrate different classes/groups.

-- 
Sarah Goslee
http://www.stringpage.com
http://www.functionaldiversity.org


From ripley at stats.ox.ac.uk  Mon Dec 18 13:21:40 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 18 Dec 2006 12:21:40 +0000 (GMT)
Subject: [R] Window help files on networked drives may not be visible
Message-ID: <Pine.LNX.4.64.0612181212300.788@gannet.stats.ox.ac.uk>

Now R 2.4.x defaults to CHM help, you may encounter a problem with a 
fairly recent Windows security patch described in

http://www.helpscribble.com/chmnetwork.html
http://support.microsoft.com/kb/896358

This may apply if you have R itself or some library on a networked drive 
or share.  Apart from the workarounds described in those URLs, there is an 
R-specific workaround: delete the pkgname/chtml folders in network-mounted 
libraries (when R will revert to text help for those packages), or 
customize the startup and select one of the other help options.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Mon Dec 18 14:08:34 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 18 Dec 2006 08:08:34 -0500
Subject: [R] return()
In-Reply-To: <OFFB56F4D3.5C9B006B-ON80257248.003CC983-80257248.003E0833@iop.kcl.ac.uk>
References: <OFFB56F4D3.5C9B006B-ON80257248.003CC983-80257248.003E0833@iop.kcl.ac.uk>
Message-ID: <458692D2.7090401@stats.uwo.ca>

On 12/18/2006 6:06 AM, Timothy.Mak at iop.kcl.ac.uk wrote:
> Dear R Help, 
> 
> Why is it that if you try to return more than one objects using return(), 
> it says it is 'deprecated'? So how do I return more than 1 objects back to 
> the parent function? 

Put them in a list, e.g.

return(a,b)

should be coded as

return(list(a,b))

Duncan Murdoch


From jrkrideau at yahoo.ca  Mon Dec 18 15:19:57 2006
From: jrkrideau at yahoo.ca (John Kane)
Date: Mon, 18 Dec 2006 09:19:57 -0500 (EST)
Subject: [R] plot
In-Reply-To: <366432610.28012@capitalbio.com>
Message-ID: <20061218141958.83385.qmail@web32808.mail.mud.yahoo.com>


--- XinMeng <xmeng at capitalbio.com> wrote:

> Hello sir:
> a data with 2 columns:
> id x
> a  1
> b  2
> c  3
> 
> I wanna get such kind of plot:
> x: a b c
> y:1 2 3
> 
> But the plot command doesn't permit string character
> as x.
> 
> How can I get it ?
> 
> Thanks a lot !
> 
> My best

It is not clear exactly what kind of a plot you want
but is it something like this?

x <- c("a", "b", "c")
y <- c(1,2,3)
plot(y, axes=F)
axis(1, at=c(1:3), labels= x)
axis(2, at = y, labels=y)
box()


From muenchen at utk.edu  Mon Dec 18 17:10:59 2006
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Mon, 18 Dec 2006 11:10:59 -0500
Subject: [R] Applying variable labels across a data frame
Message-ID: <7270AEC73132194E8BC0EE06B35D93D84A081E@UTKFSVS3.utk.tennessee.edu>

Hi All,

I'm working on a class example that demonstrates one way to deal with
factors and their labels. I create a function called myLabeler and apply
it with lapply. It works on the whole data frame when I subscript it as
in lapply( myQFvars[ ,myQFnames ], myLabeler ) but does not work if I
leave the [] subscripts off. I would appreciate it if anyone could tell
me why. The program below works up until the final two statements.

Thanks,
Bob


# Assigning factor labels to potentially lots of vars.

mystring<-
("id,workshop,gender,q1,q2,q3,q4
 1,1,f,1,1,5,1
 2,2,f,2,1,4,1
 3,1,f,2,2,4,3
 4,2,f,3,1, ,3
 5,1,m,4,5,2,4
 6,2,m,5,4,5,5
 7,1,m,5,3,4,4
 8,2,m,4,5,5,9")

mydata<-read.table(textConnection(mystring),
   header=TRUE,sep=",",row.names="id",na.strings="9")
print(mydata)

# Create copies of q variables to use as factors
# so we can count them.
myQlevels <- c(1,2,3,4,5)
myQlabels <- c("Strongly Disagree",
               "Disagree",
               "Neutral",
               "Agree",
               "Strongly Agree")
print(myQlevels)
print(myQlabels)

# Generate two sets of var names to use.
myQnames  <-   paste( "q",  1:4, sep="")
myQFnames <- paste( "qf", 1:4, sep="")
print(myQnames) #The original names.
print(myQFnames)  #The names for new factor variables.

# Extract the q variables to a separate data frame.
myQFvars <- mydata[ ,myQnames]
print(myQFvars)

# Rename all the variables with F for Factor.
colnames(myQFvars) <- myQFnames
print(myQFvars)

# Create a function to apply the labels to lots of variables.
myLabeler <- function(x) { factor(x, myQlevels, myQlabels) }

# Here's how to use the function on one variable.
summary( myLabeler(myQFvars["qf1"]) )

#Apply it to all the variables. This method works.
myQFvars[ ,myQFnames] <- lapply( myQFvars[ ,myQFnames ], myLabeler )
summary(myQFvars) #Here are the results I wanted.

# This is the same as above but using the unsubscripted
# data frame name. It does not work.
myTest <- lapply( myQFvars, myLabeler )
summary(myTest) #I'm not sure what these results are.

=========================================================
  Bob Muenchen (pronounced Min'-chen), Manager  
  Statistical Consulting Center
  U of TN Office of Information Technology
  200 Stokely Management Center, Knoxville, TN 37996-0520
  Voice: (865) 974-5230  
  FAX:   (865) 974-4810
  Email: muenchen at utk.edu
  Web:   http://oit.utk.edu/scc, 
  News:  http://listserv.utk.edu/archives/statnews.html


From spencer.graves at pdf.com  Mon Dec 18 17:15:38 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 18 Dec 2006 08:15:38 -0800
Subject: [R] Find S4 Generic?
In-Reply-To: <Pine.LNX.4.64.0612172334300.26773@gannet.stats.ox.ac.uk>
References: <4585B8EF.9010005@pdf.com>
	<Pine.LNX.4.64.0612172334300.26773@gannet.stats.ox.ac.uk>
Message-ID: <4586BEAA.5090204@pdf.com>

Dear Prof. Ripley: 

      Thanks very much.  That works.  I got stuck on the help page for 
"dumpMethods" and failed to check "See Also". 

      Best Wishes,
      Spencer Graves

Prof Brian Ripley wrote:
> Do you want E (type 'E') or its methods (getMethods(E) works for me)?
>
> On Sun, 17 Dec 2006, Spencer Graves wrote:
>
>>      How can I get the R code for "E" in the "distrEx" package?  The
>> function call 'dumpMethods("E", "E.R")' created "E.R" in the working
>> directory.  Unfortunately, it apparently contains 0 bytes.
>
> See ?dumpMethods: you need to specify 'where' (as it says you may).
>


From baud-bovy.gabriel at hsr.it  Mon Dec 18 17:32:42 2006
From: baud-bovy.gabriel at hsr.it (Gabriel Baud-Bovy)
Date: Mon, 18 Dec 2006 17:32:42 +0100
Subject: [R] Applying variable labels across a data frame
In-Reply-To: <7270AEC73132194E8BC0EE06B35D93D84A081E@UTKFSVS3.utk.tennes
	see.edu>
References: <7270AEC73132194E8BC0EE06B35D93D84A081E@UTKFSVS3.utk.tennessee.edu>
Message-ID: <6.2.3.4.0.20061218173153.036f16b0@mail.hsr.it>

You get a list, not a data.frame. Try,

as.data.frame(lapply( myQFvars, myLabeler ))

Gabriel

At 05:10 PM 12/18/2006, Muenchen, Robert A (Bob) wrote:
>Hi All,
>
>I'm working on a class example that demonstrates one way to deal with
>factors and their labels. I create a function called myLabeler and apply
>it with lapply. It works on the whole data frame when I subscript it as
>in lapply( myQFvars[ ,myQFnames ], myLabeler ) but does not work if I
>leave the [] subscripts off. I would appreciate it if anyone could tell
>me why. The program below works up until the final two statements.
>
>Thanks,
>Bob
>
>
># Assigning factor labels to potentially lots of vars.
>
>mystring<-
>("id,workshop,gender,q1,q2,q3,q4
>  1,1,f,1,1,5,1
>  2,2,f,2,1,4,1
>  3,1,f,2,2,4,3
>  4,2,f,3,1, ,3
>  5,1,m,4,5,2,4
>  6,2,m,5,4,5,5
>  7,1,m,5,3,4,4
>  8,2,m,4,5,5,9")
>
>mydata<-read.table(textConnection(mystring),
>    header=TRUE,sep=",",row.names="id",na.strings="9")
>print(mydata)
>
># Create copies of q variables to use as factors
># so we can count them.
>myQlevels <- c(1,2,3,4,5)
>myQlabels <- c("Strongly Disagree",
>                "Disagree",
>                "Neutral",
>                "Agree",
>                "Strongly Agree")
>print(myQlevels)
>print(myQlabels)
>
># Generate two sets of var names to use.
>myQnames  <-   paste( "q",  1:4, sep="")
>myQFnames <- paste( "qf", 1:4, sep="")
>print(myQnames) #The original names.
>print(myQFnames)  #The names for new factor variables.
>
># Extract the q variables to a separate data frame.
>myQFvars <- mydata[ ,myQnames]
>print(myQFvars)
>
># Rename all the variables with F for Factor.
>colnames(myQFvars) <- myQFnames
>print(myQFvars)
>
># Create a function to apply the labels to lots of variables.
>myLabeler <- function(x) { factor(x, myQlevels, myQlabels) }
>
># Here's how to use the function on one variable.
>summary( myLabeler(myQFvars["qf1"]) )
>
>#Apply it to all the variables. This method works.
>myQFvars[ ,myQFnames] <- lapply( myQFvars[ ,myQFnames ], myLabeler )
>summary(myQFvars) #Here are the results I wanted.
>
># This is the same as above but using the unsubscripted
># data frame name. It does not work.
>myTest <- lapply( myQFvars, myLabeler )
>summary(myTest) #I'm not sure what these results are.
>
>=========================================================
>   Bob Muenchen (pronounced Min'-chen), Manager
>   Statistical Consulting Center
>   U of TN Office of Information Technology
>   200 Stokely Management Center, Knoxville, TN 37996-0520
>   Voice: (865) 974-5230
>   FAX:   (865) 974-4810
>   Email: muenchen at utk.edu
>   Web:   http://oit.utk.edu/scc,
>   News:  http://listserv.utk.edu/archives/statnews.html
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 02 2643 4839 (office)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 2643 4891 (secretary)
20132 Milan, Italy               fax: (+39) 02 2643 4892


From Wolfgang.Viechtbauer at STAT.unimaas.nl  Mon Dec 18 18:01:57 2006
From: Wolfgang.Viechtbauer at STAT.unimaas.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 18 Dec 2006 18:01:57 +0100
Subject: [R] Distance between x-axis values and title
Message-ID: <329A68716B57D54E8D39FD3F8A4A84DF057D5CB4@um-mail0136.unimaas.nl>

Dear All,

I looked at help(par), but could not figure out which setting controls the distance between the x-axis values and the x-axis title. Any pointer would be appreciated!

Thanks in advance,

-- 
Wolfgang Viechtbauer 
?Department of Methodology and Statistics 
?University of Maastricht, The Netherlands 
?http://www.wvbauer.com/


From candrews at buffalo.edu  Mon Dec 18 18:04:38 2006
From: candrews at buffalo.edu (Chris Andrews)
Date: Mon, 18 Dec 2006 12:04:38 -0500
Subject: [R] Switching labels on a factor
Message-ID: <4586CA26.5060505@buffalo.edu>


Bob,

This is I think exactly what one wants to have happen.  The first four observations are still women.  Both the labels and the underlying integers should change.  (If you want to give all the people sex changes, try Relevel in the Epi package.

mydata$afterthechange <- Relevel(mydata$gender, list(m="f", f="m"))
mydata


  workshop gender q1 q2 q3 q4 gR afterthechange
1        1      f  1  1  5  1  f              m
2        2      f  2  1  4  1  f              m
3        1      f  2  2  4  3  f              m
4        2      f  3  1 NA  3  f              m
5        1      m  4  5  2  4  m              f
6        2      m  5  4  5  5  m              f
7        1      m  5  3  4  4  m              f
8        2      m  4  5  5 NA  m              f


unclass(mydata$afterthechange)
[1] 1 1 1 1 2 2 2 2
attr(,"levels")
[1] "m" "f"

Chris


Date: Fri, 15 Dec 2006 15:34:15 -0500
From: "Muenchen, Robert A (Bob)" <muenchen at utk.edu>
Subject: [R] Switching labels on a factor
To: <R-help at stat.math.ethz.ch>
Message-ID:
	<7270AEC73132194E8BC0EE06B35D93D84A061C at UTKFSVS3.utk.tennessee.edu>
Content-Type: text/plain;	charset="US-ASCII"

Hi All,

I'm perplexed by the way the unclass function displays a factor whose
labels have been swapped with the relevel function. I realize it won't
affect any results and that the relevel did nothing useful in this
particular case. I'm just doing it to learn ways to manipulate factors.
The display of unclass leaves me feeling that the relevel had failed.

I've checked three books & searched R-help, but found no mention of this
particular issue.  

The program below demonstrates the problem. Is this a bug, or is there a
reason for it to work this way?

Thanks,
Bob

mystring<-
("id,workshop,gender,q1,q2,q3,q4
 1,1,f,1,1,5,1
 2,2,f,2,1,4,1
 3,1,f,2,2,4,3
 4,2,f,3,1, ,3
 5,1,m,4,5,2,4
 6,2,m,5,4,5,5
 7,1,m,5,3,4,4
 8,2,m,4,5,5,9")
mydata<-read.table(textConnection(mystring),
   header=TRUE,sep=",",row.names="id",na.strings="9")
mydata

# Create a gender Releveled variable, gR. 
# Now 1=m, 2=f
mydata$gR <- relevel(mydata$gender, "m")

# Print the data to show that the labels of gR match those of gender.
mydata

# Show that the underlying codes have indeed reversed.
as.numeric(mydata$gender)
as.numeric(mydata$gR)

# Unclass the two variables to see that print order 
# implies that both the codes and labels have
# flipped, cancelling each other out. For gR,
# m appears to be associated with 2, and f with 1
unclass(mydata$gender)
unclass(mydata$gR)

=========================================================
  Bob Muenchen (pronounced Min'-chen), Manager  
  Statistical Consulting Center
  U of TN Office of Information Technology
  200 Stokely Management Center, Knoxville, TN 37996-0520
  Voice: (865) 974-5230  
  FAX:   (865) 974-4810
  Email: muenchen at utk.edu
  Web:   http://oit.utk.edu/scc, 
  News:  http://listserv.utk.edu/archives/statnews.html




-- 
Christopher Andrews, PhD
SUNY Buffalo, Department of Biostatistics
242 Farber Hall, candrews at buffalo.edu, 716 829 2756


From Roger.Bivand at nhh.no  Mon Dec 18 18:12:14 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 18 Dec 2006 18:12:14 +0100 (CET)
Subject: [R] write() gotcha
In-Reply-To: <6ABA5A3B-B7C4-4278-A193-FCC72A4D809B@soc.soton.ac.uk>
Message-ID: <Pine.LNX.4.44.0612181810260.1708-100000@reclus.nhh.no>

On Mon, 18 Dec 2006, Robin Hankin wrote:

> Hi
> 
> I used write() the other day to save some results.
> 
> It seems that write() does not record the full precision of
> the objects being written:
> 
> 
>  > write(pi,file="~/f",ncolumns=1)
>  > pi.saved <- scan("~/f")
> Read 1 item
>  > dput(pi)
> 3.14159265358979
>  > dput(pi.saved)
> 3.141593
>  > pi-pi.saved
> [1] -3.464102e-07
>  >
> 
> 
> This difficulty was particularly difficult to find because pi.saved   
> *looks*
> the same as pi.
> 
> 
> 
> What's going on here?
> 

Use options(digits=) to control the output. ?write says write() is a 
wrapper for cat(), so:

options("digits"=16)
cat(pi, "\n")
write(pi,file="~/f",ncolumns=1)
pi.saved <- scan("~/f")
dput(pi.saved)
dput(pi)

looks OK


> 
> 
> 
> 
> 
>  > R.Version()
> $platform
> [1] "powerpc-apple-darwin8.7.0"
> 
> $arch
> [1] "powerpc"
> 
> $os
> [1] "darwin8.7.0"
> 
> $system
> [1] "powerpc, darwin8.7.0"
> 
> $status
> [1] ""
> 
> $major
> [1] "2"
> 
> $minor
> [1] "4.0"
> 
> $year
> [1] "2006"
> 
> $month
> [1] "10"
> 
> $day
> [1] "03"
> 
> $`svn rev`
> [1] "39566"
> 
> $language
> [1] "R"
> 
> $version.string
> [1] "R version 2.4.0 (2006-10-03)"
> 
> 
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>   tel  023-8059-7743
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From ripley at stats.ox.ac.uk  Mon Dec 18 18:19:18 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 18 Dec 2006 17:19:18 +0000 (GMT)
Subject: [R] Distance between x-axis values and title
In-Reply-To: <329A68716B57D54E8D39FD3F8A4A84DF057D5CB4@um-mail0136.unimaas.nl>
References: <329A68716B57D54E8D39FD3F8A4A84DF057D5CB4@um-mail0136.unimaas.nl>
Message-ID: <Pine.LNX.4.64.0612181716330.19877@gannet.stats.ox.ac.uk>

On Mon, 18 Dec 2006, Viechtbauer Wolfgang (STAT) wrote:

> Dear All,
>
> I looked at help(par), but could not figure out which setting controls 
> the distance between the x-axis values and the x-axis title. Any pointer 
> would be appreciated!

mgp: looking at An Introduction to R may help you find your way around 
par().


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jrkrideau at yahoo.ca  Mon Dec 18 18:44:49 2006
From: jrkrideau at yahoo.ca (John Kane)
Date: Mon, 18 Dec 2006 12:44:49 -0500 (EST)
Subject: [R] Distance between x-axis values and title
In-Reply-To: <329A68716B57D54E8D39FD3F8A4A84DF057D5CB4@um-mail0136.unimaas.nl>
Message-ID: <20061218174449.76050.qmail@web32812.mail.mud.yahoo.com>


--- "Viechtbauer Wolfgang (STAT)"
<Wolfgang.Viechtbauer at STAT.unimaas.nl> wrote:

> Dear All,
> 
> I looked at help(par), but could not figure out
> which setting controls the distance between the
> x-axis values and the x-axis title. Any pointer
> would be appreciated!
> 
> Thanks in advance,
> 
 ?mpg probably
Is this what you want 

catb <- c( 1,2,3,4,5,6)
dogb <- c(2,4,6,8,10, 12)
plot(catb,dogb, mgp=c(3,1,0))
# vs
plot(catb,dogb, mgp=c(2,1,0))


From Wolfgang.Viechtbauer at STAT.unimaas.nl  Mon Dec 18 18:54:02 2006
From: Wolfgang.Viechtbauer at STAT.unimaas.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 18 Dec 2006 18:54:02 +0100
Subject: [R] Distance between x-axis values and title
In-Reply-To: <20061218174449.76050.qmail@web32812.mail.mud.yahoo.com>
Message-ID: <329A68716B57D54E8D39FD3F8A4A84DF057D5CB5@um-mail0136.unimaas.nl>

Thanks to all who responded so quickly! Yes, I totally overlooked par(mpg). Exactly what I was looking for.

-- 
Wolfgang Viechtbauer 
?Department of Methodology and Statistics 
?University of Maastricht, The Netherlands 
?http://www.wvbauer.com/ 


> -----Original Message-----
> From: John Kane [mailto:jrkrideau at yahoo.ca]
> Sent: Monday, December 18, 2006 18:45
> To: Viechtbauer Wolfgang (STAT); r-help at stat.math.ethz.ch
> Subject: Re: [R] Distance between x-axis values and title
> 
> 
> --- "Viechtbauer Wolfgang (STAT)"
> <Wolfgang.Viechtbauer at STAT.unimaas.nl> wrote:
> 
> > Dear All,
> >
> > I looked at help(par), but could not figure out
> > which setting controls the distance between the
> > x-axis values and the x-axis title. Any pointer
> > would be appreciated!
> >
> > Thanks in advance,
> >
>  ?mpg probably
> Is this what you want
> 
> catb <- c( 1,2,3,4,5,6)
> dogb <- c(2,4,6,8,10, 12)
> plot(catb,dogb, mgp=c(3,1,0))
> # vs
> plot(catb,dogb, mgp=c(2,1,0))


From heberto.ghezzo at mcgill.ca  Mon Dec 18 18:54:31 2006
From: heberto.ghezzo at mcgill.ca (R Heberto Ghezzo, Dr)
Date: Mon, 18 Dec 2006 12:54:31 -0500
Subject: [R] lmer formula
Message-ID: <05BE78B0CF1BBC4BBA4AA255568D8611029A998D@EXCHANGE2VS1.campus.mcgill.ca>

Hello,
I have some problems trying to write up the formula for lmer.
I have 43 subjects ( random factor) which were seen twice ( Visit : repeated measure - fixed). on each visit the patient performed a graded effort exercise ( effort : repeated measures, ordered,  fixed 4 levels).
So Subject is a random factor, Effort is crossed with Visit and both are repeated measures, the efforts are ordered as it is a cummulative test.
The model
y ~ Visit * Effort + (Visit | Subject) + (Effort | Subject) 
seems appropriate but how can I get a linear-quadratic trend for effort? 
Also the Covar matrix for the repeated measures is 8 by 8 . It is not blocked beacuse there is the possibility of a learning effect between the visits. How can I specify this?
Thanks for any help with this model.
Heberto Ghezzo Ph.D.
Meakins-Christie Labs
Mc Gill University
Montreal - Canada


From rork at athens.net  Mon Dec 18 19:19:24 2006
From: rork at athens.net (rork)
Date: Mon, 18 Dec 2006 10:19:24 -0800 (PST)
Subject: [R] Replay recorded plot with new layout
Message-ID: <7933646.post@talk.nabble.com>


Folks,
Please help with a graphics problem, I am running R2.4.0 on Windows XP.
In much earlier version of R (1.3? about December 2001)
I could 
  par(mfrow=c(1,1))
  plot(1,1,xlab="X",ylab="Y")
  plot1<-recordPlot()
  plot(2,2,xlab="X2",ylab="Y2")
  plot2<-recordPlot()
  par(mfrow=c(2,1))
  plot1
  plot2

and produce the same effect as the following (the above no longer produces
this layout):
  
  par(mfrow=c(2,1))
  plot(1,1,xlab="X",ylab="Y")
  plot(2,2,xlab="X2",ylab="Y2")

It seems replaying plots now uses the original par or layout that was in
effect when they were recorded.
Is there some new method that allows a saved plot to be replayed in a new
layout.  

As the graphical display of data and model predictions, plots are often the
end result of a lengthy bit of data manipulation and modeling, with layers
of points and lines and text, etc, and I like to be able to see a larger
version of the graph, and then when they are all produced, replay them with
a more concise page layout.  I'd appreciate your help in making the
transition to the new R version.

Thanks,
rork



-- 
View this message in context: http://www.nabble.com/Replay-recorded-plot-with-new-layout-tf2841465.html#a7933646
Sent from the R help mailing list archive at Nabble.com.


From mtmorgan at fhcrc.org  Mon Dec 18 19:32:05 2006
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 18 Dec 2006 10:32:05 -0800
Subject: [R] Memory problem on a  linux cluster using a large data set
In-Reply-To: <20061218101948.96145.qmail@web51702.mail.yahoo.com> (Iris
	Kolder's message of "Mon, 18 Dec 2006 02:19:48 -0800 (PST)")
References: <20061218101948.96145.qmail@web51702.mail.yahoo.com>
Message-ID: <6ph8xh5ukbe.fsf@gopher4.fhcrc.org>

Iris --

I hope the following helps; I think you have too much data for a
32-bit machine.

Martin

Iris Kolder <iriskolder at yahoo.com> writes:

> Hello,
>  
> I have a large data set 320.000 rows and 1000 columns. All the data
> has the values 0,1,2.

It seems like a single copy of this data set will be at least a couple
of gigabytes; I think you'll have access to only 4 GB on a 32-bit
machine (see section 8 of the R Installation and Administration guide),
and R will probably end up, even in the best of situations, making at
least a couple of copies of your data. Probably you'll need a 64-bit
machine, or figure out algorithms that work on chunks of data.

> on a linux cluster with R version R 2.1.0.  which operates on a 32

This is quite old, and in general it seems like R has become more
sensitive to big-data issues and tracking down unnecessary memory
copying.

> ?cannot allocate vector size 1240 kb?. I?ve searched through

use traceback() or options(error=recover) to figure out where this is
actually occurring.

> SNP <- read.table("file.txt", header=FALSE, sep="")    # read in data file

This makes a data.frame, and data frames have several aspects (e.g.,
automatic creation of row names on sub-setting) that can be problematic
in terms of memory use. Probably better to use a matrix, for which:

     'read.table' is not the right tool for reading large matrices,
     especially those with many columns: it is designed to read _data
     frames_ which may have columns of very different classes. Use
     'scan' instead.

(from the help page for read.table). I'm not sure of the details of
the algorithms you'll invoke, but it might be a false economy to try
to get scan to read in 'small' versions (e.g., integer, rather than
numeric) of the data -- the algorithms might insist on numeric data,
and then make a copy during coercion from your small version to
numeric.

> SNP$total.NAs = rowSums(is.na(SN         # calculate the number of NA per row and adds a colum with total Na's

This adds a column to the data.frame or matrix, probably causing at
least one copy of the entire data. Create a separate vector instead,
even though this unties the coordination between columns that a data
frame provides.

> SNP  = t(as.matrix(SNP))                          # transpose rows and columns

This will also probably trigger a copy; 

> snp.na<-SNP

R might be clever enough to figure out that this simple assignment
does not trigger a copy. But it probably means that any subsequent
modification of snp.na or SNP *will* trigger a copy, so avoid the
assignment if possible.

> snp.roughfix<-na.roughfix(snp.na)                                             
> fSNP<-factor(snp.roughfix[, 1])                # Asigns factor to case control status
>  
> snp.narf<- randomForest(snp.roughfix[,-1], fSNP, na.action=na.roughfix, ntree=500, mtry=10, importance=TRUE, keep.forest=FALSE, do.trace=100)

Now you're entirely in the hands of the randomForest. If memory
problems occur here, perhaps you'll have gained enough experience to
point the package maintainer to the problem and suggest a possible
solution.

> set it should be able to cope with that amount. Perhaps someone has
> tried this before in R or is Fortram a better choice? I added my R

If you mean a pure Fortran solution, including coding the random
forest algorithm, then of course you have complete control over memory
management. You'd still likely be limited to addressing 4 GB of
memory. 


> I wrote a script to remove all the rows with more than 46 missing
> values. This works perfect on a smaller dataset. But the problem
> arises when I try to run it on the larger data set I get an error
> ?cannot allocate vector size 1240 kb?. I?ve searched through
> previous posts and found out that it might be because i?m running it
> on a linux cluster with R version R 2.1.0.  which operates on a 32
> bit processor. But I could not find a solution for this problem. The
> cluster is a really fast one and should be able to cope with these
> large amounts of data the systems configuration are Speed: 3.4 GHz,
> memory 4GByte. Is there a way to change the settings or processor
> under R? I want to run the function Random Forest on my large data
> set it should be able to cope with that amount. Perhaps someone has
> tried this before in R or is Fortram a better choice? I added my R
> script down below.
>  
> Best regards,
>  
> Iris Kolder
>  
> SNP <- read.table("file.txt", header=FALSE, sep="")    # read in data file
> SNP[SNP==9]<-NA                                   # change missing values from a 9 to a NA
> SNP$total.NAs = rowSums(is.na(SN         # calculate the number of NA per row and adds a colum with total Na's
> SNP = SNP[ SNP$total.NAs < 46,  ]         # create a subset with no more than 5%(46) NA's 
> SNP$total.NAs=NULL                              # remove added column with sum of NA's
> SNP  = t(as.matrix(SNP))                          # transpose rows and columns
> set.seed(1)                                                                                   
> snp.na<-SNP 
> snp.roughfix<-na.roughfix(snp.na)                                             
> fSNP<-factor(snp.roughfix[, 1])                # Asigns factor to case control status
>  
> snp.narf<- randomForest(snp.roughfix[,-1], fSNP, na.action=na.roughfix, ntree=500, mtry=10, importance=TRUE, keep.forest=FALSE, do.trace=100)
>  
> print(snp.narf)
>
> __________________________________________________
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Martin T. Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From andy_liaw at merck.com  Mon Dec 18 19:48:23 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 18 Dec 2006 13:48:23 -0500
Subject: [R] Memory problem on a linux cluster using a large data set
 [Broadcast]
In-Reply-To: <6ph8xh5ukbe.fsf@gopher4.fhcrc.org>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA03649814@usctmx1106.merck.com>

In addition to my off-list reply to Iris (pointing her to an old post of
mine that detailed the memory requirement of RF in R), she might
consider the following:

- Use larger nodesize
- Use sampsize to control the size of bootstrap samples

Both of these have the effect of reducing sizes of trees grown.  For a
data set that large, it may not matter to grow smaller trees.

Still, with data of that size, I'd say 64-bit is the better solution.

Cheers,
Andy

From: Martin Morgan
> 
> Iris --
> 
> I hope the following helps; I think you have too much data 
> for a 32-bit machine.
> 
> Martin
> 
> Iris Kolder <iriskolder at yahoo.com> writes:
> 
> > Hello,
> >  
> > I have a large data set 320.000 rows and 1000 columns. All the data 
> > has the values 0,1,2.
> 
> It seems like a single copy of this data set will be at least 
> a couple of gigabytes; I think you'll have access to only 4 
> GB on a 32-bit machine (see section 8 of the R Installation 
> and Administration guide), and R will probably end up, even 
> in the best of situations, making at least a couple of copies 
> of your data. Probably you'll need a 64-bit machine, or 
> figure out algorithms that work on chunks of data.
> 
> > on a linux cluster with R version R 2.1.0.  which operates on a 32
> 
> This is quite old, and in general it seems like R has become 
> more sensitive to big-data issues and tracking down 
> unnecessary memory copying.
> 
> > "cannot allocate vector size 1240 kb". I've searched through
> 
> use traceback() or options(error=recover) to figure out where 
> this is actually occurring.
> 
> > SNP <- read.table("file.txt", header=FALSE, sep="")    # 
> read in data file
> 
> This makes a data.frame, and data frames have several aspects 
> (e.g., automatic creation of row names on sub-setting) that 
> can be problematic in terms of memory use. Probably better to 
> use a matrix, for which:
> 
>      'read.table' is not the right tool for reading large matrices,
>      especially those with many columns: it is designed to read _data
>      frames_ which may have columns of very different classes. Use
>      'scan' instead.
> 
> (from the help page for read.table). I'm not sure of the 
> details of the algorithms you'll invoke, but it might be a 
> false economy to try to get scan to read in 'small' versions 
> (e.g., integer, rather than
> numeric) of the data -- the algorithms might insist on 
> numeric data, and then make a copy during coercion from your 
> small version to numeric.
> 
> > SNP$total.NAs = rowSums(is.na(SN         # calculate the 
> number of NA per row and adds a colum with total Na's
> 
> This adds a column to the data.frame or matrix, probably 
> causing at least one copy of the entire data. Create a 
> separate vector instead, even though this unties the 
> coordination between columns that a data frame provides.
> 
> > SNP  = t(as.matrix(SNP))                          # 
> transpose rows and columns
> 
> This will also probably trigger a copy; 
> 
> > snp.na<-SNP
> 
> R might be clever enough to figure out that this simple 
> assignment does not trigger a copy. But it probably means 
> that any subsequent modification of snp.na or SNP *will* 
> trigger a copy, so avoid the assignment if possible.
> 
> > snp.roughfix<-na.roughfix(snp.na)                           
>                   
> > fSNP<-factor(snp.roughfix[, 1])                # Asigns 
> factor to case control status
> >  
> > snp.narf<- randomForest(snp.roughfix[,-1], fSNP, 
> > na.action=na.roughfix, ntree=500, mtry=10, importance=TRUE, 
> > keep.forest=FALSE, do.trace=100)
> 
> Now you're entirely in the hands of the randomForest. If 
> memory problems occur here, perhaps you'll have gained enough 
> experience to point the package maintainer to the problem and 
> suggest a possible solution.
> 
> > set it should be able to cope with that amount. Perhaps someone has 
> > tried this before in R or is Fortram a better choice? I added my R
> 
> If you mean a pure Fortran solution, including coding the 
> random forest algorithm, then of course you have complete 
> control over memory management. You'd still likely be limited 
> to addressing 4 GB of memory. 
> 
> 
> > I wrote a script to remove all the rows with more than 46 missing 
> > values. This works perfect on a smaller dataset. But the problem 
> > arises when I try to run it on the larger data set I get an error 
> > "cannot allocate vector size 1240 kb". I've searched 
> through previous 
> > posts and found out that it might be because i'm running it 
> on a linux 
> > cluster with R version R 2.1.0.  which operates on a 32 bit 
> processor. 
> > But I could not find a solution for this problem. The cluster is a 
> > really fast one and should be able to cope with these large 
> amounts of 
> > data the systems configuration are Speed: 3.4 GHz, memory 
> 4GByte. Is 
> > there a way to change the settings or processor under R? I 
> want to run 
> > the function Random Forest on my large data set it should 
> be able to 
> > cope with that amount. Perhaps someone has tried this 
> before in R or 
> > is Fortram a better choice? I added my R script down below.
> >  
> > Best regards,
> >  
> > Iris Kolder
> >  
> > SNP <- read.table("file.txt", header=FALSE, sep="")    # 
> read in data file
> > SNP[SNP==9]<-NA                                   # change 
> missing values from a 9 to a NA
> > SNP$total.NAs = rowSums(is.na(SN         # calculate the 
> number of NA per row and adds a colum with total Na's
> > SNP = SNP[ SNP$total.NAs < 46,  ]         # create a subset 
> with no more than 5%(46) NA's 
> > SNP$total.NAs=NULL                              # remove 
> added column with sum of NA's
> > SNP  = t(as.matrix(SNP))                          # 
> transpose rows and columns
> > set.seed(1)                                                 
>                                   
> > snp.na<-SNP 
> > snp.roughfix<-na.roughfix(snp.na)                           
>                   
> > fSNP<-factor(snp.roughfix[, 1])                # Asigns 
> factor to case control status
> >  
> > snp.narf<- randomForest(snp.roughfix[,-1], fSNP, 
> > na.action=na.roughfix, ntree=500, mtry=10, importance=TRUE, 
> > keep.forest=FALSE, do.trace=100)
> >  
> > print(snp.narf)
> >
> > __________________________________________________
> >
> >
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Martin T. Morgan
> Bioconductor / Computational Biology
> http://bioconductor.org
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}


From larsfromspace at web.de  Mon Dec 18 19:58:11 2006
From: larsfromspace at web.de (downunder)
Date: Mon, 18 Dec 2006 10:58:11 -0800 (PST)
Subject: [R]  Replacing values
Message-ID: <7934402.post@talk.nabble.com>


Hi all,

I have to recode some values in a dataset. for example changing all zeros to
"." or 999 would be also ok. does anybody know how to do this? thanks in
advance. lars
-- 
View this message in context: http://www.nabble.com/-R--Replacing-values-tf2841687.html#a7934402
Sent from the R help mailing list archive at Nabble.com.


From rork at athens.net  Mon Dec 18 21:31:42 2006
From: rork at athens.net (Ray Souter)
Date: Mon, 18 Dec 2006 15:31:42 -0500
Subject: [R]  Replay recorded plot with new layout
Message-ID: <001001c722e4$5b36e2c0$0301a8c0@THX1138>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061218/eaa828e4/attachment.pl 

From marc_schwartz at comcast.net  Mon Dec 18 21:55:45 2006
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Mon, 18 Dec 2006 14:55:45 -0600
Subject: [R] Replacing values
In-Reply-To: <7934402.post@talk.nabble.com>
References: <7934402.post@talk.nabble.com>
Message-ID: <1166475345.4771.70.camel@localhost.localdomain>

On Mon, 2006-12-18 at 10:58 -0800, downunder wrote:
> Hi all,
> 
> I have to recode some values in a dataset. for example changing all zeros to
> "." or 999 would be also ok. does anybody know how to do this? thanks in
> advance. lars

R has its own missing value designator, which is NA.  A "." or "999"
would not be handled in a consistent fashion by most R functions,
whereas NA would be. As you will note below, "." would be rejected in
numerical operations.

For example (see ?mean):

> mean(c(1, 2, 3, 0))
[1] 1.5

> mean(c(1, 2, 3, NA))
[1] NA

> mean(c(1, 2, 3, NA), na.rm = TRUE)
[1] 2

> mean(c(1, 2, 3, .), na.rm = TRUE)
Error in mean(c(1, 2, 3, .), na.rm = TRUE) : 
	object "." not found

> mean(c(1, 2, 3, 999), na.rm = TRUE)
[1] 251.25


See ?NA and ?is.na and take note of the assignment usage in the latter.

To provide some examples:

1. Vector

> Vec <- sample(0:5, 10, replace = TRUE)
> Vec
 [1] 5 3 4 5 1 4 4 0 1 0

> is.na(Vec) <- Vec == 0
> Vec
 [1]  5  3  4  5  1  4  4 NA  1 NA


2. Matrix

> Mat <- matrix(sample(0:5, 20, replace = TRUE), ncol = 4)
> Mat
     [,1] [,2] [,3] [,4]
[1,]    4    4    1    4
[2,]    3    1    1    3
[3,]    3    0    1    0
[4,]    2    2    0    5
[5,]    4    0    5    1

> is.na(Mat) <- Mat == 0

> Mat
     [,1] [,2] [,3] [,4]
[1,]    4    4    1    4
[2,]    3    1    1    3
[3,]    3   NA    1   NA
[4,]    2    2   NA    5
[5,]    4   NA    5    1



3. Dataframe

> iris.tmp <- iris[1:10, ]
> iris.tmp
   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1           5.1         3.5          1.4         0.2  setosa
2           4.9         3.0          1.4         0.2  setosa
3           4.7         3.2          1.3         0.2  setosa
4           4.6         3.1          1.5         0.2  setosa
5           5.0         3.6          1.4         0.2  setosa
6           5.4         3.9          1.7         0.4  setosa
7           4.6         3.4          1.4         0.3  setosa
8           5.0         3.4          1.5         0.2  setosa
9           4.4         2.9          1.4         0.2  setosa
10          4.9         3.1          1.5         0.1  setosa


> iris.tmp$Sepal.Length[sample(10, 3)] <- 0
> iris.tmp$Sepal.Width[sample(10, 3)] <- 0
> iris.tmp$Petal.Length[sample(10, 3)] <- 0
> iris.tmp$Petal.Width[sample(10, 3)] <- 0


> iris.tmp
   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1           5.1         0.0          0.0         0.2  setosa
2           4.9         0.0          1.4         0.2  setosa
3           4.7         0.0          1.3         0.0  setosa
4           4.6         3.1          1.5         0.2  setosa
5           5.0         3.6          1.4         0.0  setosa
6           5.4         3.9          0.0         0.0  setosa
7           0.0         3.4          1.4         0.3  setosa
8           0.0         3.4          0.0         0.2  setosa
9           4.4         2.9          1.4         0.2  setosa
10          0.0         3.1          1.5         0.1  setosa


> is.na(iris.tmp) <- iris.tmp == 0

> iris.tmp
   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1           5.1          NA           NA         0.2  setosa
2           4.9          NA          1.4         0.2  setosa
3           4.7          NA          1.3          NA  setosa
4           4.6         3.1          1.5         0.2  setosa
5           5.0         3.6          1.4          NA  setosa
6           5.4         3.9           NA          NA  setosa
7            NA         3.4          1.4         0.3  setosa
8            NA         3.4           NA         0.2  setosa
9           4.4         2.9          1.4         0.2  setosa
10           NA         3.1          1.5         0.1  setosa


> summary(iris.tmp)
  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width 
 Min.   :4.400   Min.   :2.900   Min.   :1.300   Min.   :0.1  
 1st Qu.:4.650   1st Qu.:3.100   1st Qu.:1.400   1st Qu.:0.2  
 Median :4.900   Median :3.400   Median :1.400   Median :0.2  
 Mean   :4.871   Mean   :3.343   Mean   :1.414   Mean   :0.2  
 3rd Qu.:5.050   3rd Qu.:3.500   3rd Qu.:1.450   3rd Qu.:0.2  
 Max.   :5.400   Max.   :3.900   Max.   :1.500   Max.   :0.3  
 NA's   :3.000   NA's   :3.000   NA's   :3.000   NA's   :3.0  
       Species  
 setosa    :10  
 versicolor: 0  
 virginica : 0  



If you want a more generic approach to replacing values based upon
logical conditions, there is also the replace() function:

> iris.tmp$Sepal.Length <- with(iris.tmp, 
                                replace(Sepal.Length, 
                                        Sepal.Length > 5.0, 999))

> iris.tmp
   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1         999.0          NA           NA         0.2  setosa
2           4.9          NA          1.4         0.2  setosa
3           4.7          NA          1.3          NA  setosa
4           4.6         3.1          1.5         0.2  setosa
5           5.0         3.6          1.4          NA  setosa
6         999.0         3.9           NA          NA  setosa
7            NA         3.4          1.4         0.3  setosa
8            NA         3.4           NA         0.2  setosa
9           4.4         2.9          1.4         0.2  setosa
10           NA         3.1          1.5         0.1  setosa


See ?replace for more information and note that the assignment does not
happen "in place", you need to assign the result.

Finally, if you are reading in data sets from ASCII files using one of
the read.table() family of functions, take note of the 'na.strings'
argument, which will define the incoming values that you want to
explicitly set to missing (NA) during the import process.
See ?read.table for more information.

HTH,

Marc Schwartz


From RMan54 at cox.net  Mon Dec 18 22:48:14 2006
From: RMan54 at cox.net (Rene Braeckman)
Date: Mon, 18 Dec 2006 13:48:14 -0800
Subject: [R] plot
In-Reply-To: <366432610.28012@capitalbio.com>
Message-ID: <003801c722ee$389de060$0900a8c0@rman>

You can do something like this for a scatter plot:

x <- c("a","b","c")
y <- c(1,2,3)

xnum <- rep(1:length(x))
plot(x=xnum, y=y, xlab="x", xaxt="n")
axis(side=1, at=xnum, labels=x)

This fakes a numerical axis and suppresses the y-axis labels that you then
draw with the axis function the way that you want them. If you play with the
xnum vector, you can have different spacing of the points in the
x-direction.

Rene

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of XinMeng
Sent: Monday, December 18, 2006 1:03 AM
To: r-help at stat.math.ethz.ch
Subject: [R] plot

Hello sir:
a data with 2 columns:
id x
a  1
b  2
c  3

I wanna get such kind of plot:
x: a b c
y:1 2 3

But the plot command doesn't permit string character as x.

How can I get it ?

Thanks a lot !

My best

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From fjbuch at gmail.com  Mon Dec 18 23:36:25 2006
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Mon, 18 Dec 2006 17:36:25 -0500
Subject: [R] Plotting individual survival plots
Message-ID: <bd93cdad0612181436i33f6e2cja4eb010423f84186@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061218/77d2be32/attachment.pl 

From tlumley at u.washington.edu  Mon Dec 18 23:43:43 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 18 Dec 2006 14:43:43 -0800 (PST)
Subject: [R] Plotting individual survival plots
In-Reply-To: <bd93cdad0612181436i33f6e2cja4eb010423f84186@mail.gmail.com>
References: <bd93cdad0612181436i33f6e2cja4eb010423f84186@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0612181442580.8162@homer22.u.washington.edu>

On Mon, 18 Dec 2006, Farrel Buchinsky wrote:

> Using the survival library, it is possible to get a plot of all the subjects
> in a sample and it is possible to get a plot of all subgroups in the same
> plot. How does one get a separate plot for each subgroup?

There is an example in ?survfit of how to plot a single subgroup, and you 
can just wrap it in a loop to plot all the subgroups.

 	-thomas


> plot(survfit(Surv(time,death==1)~group),col=1:10)
>
> The above results in a hideous graphic representation.
>
> I would prefer to specify
>
> par(mfrow = c(2, 5))
>
> and have each plot separately
>
>
> -- 
> Farrel
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From fjbuch at gmail.com  Tue Dec 19 01:26:05 2006
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Mon, 18 Dec 2006 19:26:05 -0500
Subject: [R] Plotting individual survival plots
In-Reply-To: <Pine.LNX.4.64.0612181442580.8162@homer22.u.washington.edu>
References: <bd93cdad0612181436i33f6e2cja4eb010423f84186@mail.gmail.com>
	<Pine.LNX.4.64.0612181442580.8162@homer22.u.washington.edu>
Message-ID: <bd93cdad0612181626o6f3864f0m90e2151b5e42d47a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061218/b10dad0a/attachment.pl 

From Alexander.Herr at csiro.au  Tue Dec 19 02:25:00 2006
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Tue, 19 Dec 2006 11:25:00 +1000
Subject: [R] surface3d grid from xyz dataframe
Message-ID: <062AE320EF971E40ACD0F6C93391D769BD0CC3@exqld1-tsv.nexus.csiro.au>

Thanks Duncan,

yes it is surface3d{rgl} I am trying. Unfortunately your solution
doesn't work with the data (I get a subscript out of bounds error, after
converting to integer and assigning the matrix to z via z[cbind(data$x,
data$y)] <- data$z). 

As outlined previously, I have a dataframe with realworld coordinates,
so they are not integer (and numeric negative for x) and it is large (ie
~2.5mio rows). I can see two options:

(1) a function that creates a matrix from the current data to enable use
of surface3d. This involves converting x and y into integer positive
values and dealing with gridvalues of x,y pairs that are now the same
through the conversion.


(2) a plotting function that accepts a dataframe for plotting 3d surface
with a color associated with gridvalue and height values in the third
dimension

I was hoping that someone had already invented the wheel.

Any suggestions welcome
Thanx Herry

Dr Alexander Herr
Spatial and statistical analyst
CSIRO, Sustainable Ecosystems
Davies Laboratory,
University Drive, Douglas, QLD 4814 
Private Mail Bag, Aitkenvale, QLD 4814
 
Phone/www 
(07) 4753 8510; 4753 8650(fax)
Home: http://herry.ausbats.org.au
Webadmin ABS: http://ausbats.org.au
Sustainable Ecosystems: http://www.cse.csiro.au/
--------------------------------------------


-----Original Message-----
From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca] 
Sent: Monday, December 18, 2006 11:50 AM
To: Herr, Alexander Herr - Herry (CSE, Townsville)
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] surface3d grid from xyz dataframe

On 12/17/2006 7:56 PM, Alexander.Herr at csiro.au wrote:
> Hi List,
> 
> I am trying to plot a grid with an overlayed height. I have a 
> dataframe with four variables:
> x,y,gridvalue,height. The dataframe has 2.5mio observations (ie grid 
> points),
> 
> I assign colors through the gridvalue using map_color_gradient thus
> producing:
> x,y,gridvalue,height,gridcol as variables of the dataframe. The grid 
> dimensions are 1253 x 2001 (=2507253 data points).
> 
> My attempts with surface3d fail, mainly because I cannot produce the 
> matrix required for the height input.
> 
> elev.to.list{CTFS} fails with: "Error in matrix(elevfile$elev, nrow=
> 1+ydim/gridsize, ncol=1+xdim/gridsize. : attempt to set an attribute 
> 1+on
> NULL" which I assume means it requires a square grid (=quadrates).

When you are asking a question about a function from a contributed
package, please state which package you found it in.  There's a
surface3d function in the rgl package; is that the one you're using?  It
takes input in the same format as contour() uses.  That is:  the x
values should be a vector of values corresponding to the rows of a
matrix, the y values correspond to the columns, the z values are in a
matrix.

Since your data is in a dataframe, it's not the right shape.  How to get
it into the right shape depends a lot on what the pattern of your data
really is.  Do you have a relatively small number of x and y values,
corresponding to rows and columns, or are they scattered over the
region?  If the former, I'd convert them to integer values marking the
positions, then use those to index into a matrix to place the z values
there.

e.g. with data like this:

x y z
1 1 1
1 2 2
2 1 3
2 2 4

the x and y values are already integer valued, so you could use

x <- sort(unique(data$x))
y <- sort(unique(data$y))
z <- matrix(NA, length(x), length(y))
z[cbind(data$x, data$y)] <- data$z

Duncan Murdoch


From roman.ahmed at buseco.monash.edu.au  Tue Dec 19 02:42:00 2006
From: roman.ahmed at buseco.monash.edu.au (Roman Akhter Ahmed)
Date: Tue, 19 Dec 2006 12:42:00 +1100
Subject: [R] unique columns of a matrix
Message-ID: <45874368.90801@buseco.monash.edu.au>

Dear all,

I have a matrix of repeating columns in R, for example a matrix X is

          [,1]   [,2]   [,3]   [,4]
[1,]       1      1      1      1
[2,]       1      1      2      2

I want to store unique columns of the matrix X in a new matrix Y. 
Therefore, Y will be

          [,1]   [,2]  
[1,]       1      1    
[2,]       1      2

It will be really appreciated if you can provide me some function for 
this job.
Thanks for your time and effort in advance,
Roman

-- 
----------------------------------------------------------------------
Roman Akhter Ahmed (Ph.D. Candidate)
Department of Econometrics and Business Statistics
Room 659, Building 11 (East Wing), Clayton Campus
Monash University, Victoria 3800, Australia
Ph.: +61 3 9905 8346 (W), +61 3 9543 1958 (R)
Web: http://www.buseco.monash.edu.au/staff/profile.php?uid=rahmed
----------------------------------------------------------------------


From jfox at mcmaster.ca  Tue Dec 19 03:49:43 2006
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 18 Dec 2006 21:49:43 -0500
Subject: [R] unique columns of a matrix
In-Reply-To: <45874368.90801@buseco.monash.edu.au>
Message-ID: <20061219024943.TNWM5067.tomts5-srv.bellnexxia.net@JohnDesktop8300>

Dear Roman,

You can use unique(X, MARGIN=2). See ?unique for details.

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Roman 
> Akhter Ahmed
> Sent: Monday, December 18, 2006 8:42 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] unique columns of a matrix
> 
> Dear all,
> 
> I have a matrix of repeating columns in R, for example a matrix X is
> 
>           [,1]   [,2]   [,3]   [,4]
> [1,]       1      1      1      1
> [2,]       1      1      2      2
> 
> I want to store unique columns of the matrix X in a new matrix Y. 
> Therefore, Y will be
> 
>           [,1]   [,2]  
> [1,]       1      1    
> [2,]       1      2
> 
> It will be really appreciated if you can provide me some 
> function for this job.
> Thanks for your time and effort in advance, Roman
> 
> --
> ----------------------------------------------------------------------
> Roman Akhter Ahmed (Ph.D. Candidate)
> Department of Econometrics and Business Statistics Room 659, 
> Building 11 (East Wing), Clayton Campus Monash University, 
> Victoria 3800, Australia
> Ph.: +61 3 9905 8346 (W), +61 3 9543 1958 (R)
> Web: http://www.buseco.monash.edu.au/staff/profile.php?uid=rahmed
> ----------------------------------------------------------------------
> 
>


From readams at colby.edu  Tue Dec 19 04:18:45 2006
From: readams at colby.edu (readams at colby.edu)
Date: Mon, 18 Dec 2006 22:18:45 -0500
Subject: [R] Random Effects Model
Message-ID: <20061218221845.0x7imssdvggsgwgk@webmail.colby.edu>

Hello,

I am new to R, and I am trying to figure out how to use it for a  
random effects model. I am using version 2.4.0, and I also have the  
book Applied Linear Regression by Sanford Weisberg.

I have four variables: Swimmer, Sex, Swim, and Difference.  Swimmer  
identifies the number assigned to a particular person. Sex is  
male/female. Swim identifies the number swim from 1 to 6. Difference  
is my variable of interest (random).

The book says I should run something like this:

> library(nlme)
> data(FREE) #FREE is my dataset
> xyplot(Difference~Swim|Type, group=Swimmer, data=FREE,
+     panel.groups=function(x,y,...){
+       panel.linejoin(x,y,horizontal=FALSE,...)}
+     )
> m1 <- lme(Difference~Swim+Type, data=FREE, random=~1+Type|Swimmer)
> m2 <- update(m1, random=~1|Swimmer)

I've pretty much decided that xyplot doesn't work. Instead, I think  
plot will work much better.  I keep getting errors about Type. Can  
someone explain this to me? Does the code above look right?

Any kind of help will be appreciated...

Thanks in advance!

Ryan


From RMan54 at cox.net  Tue Dec 19 04:56:07 2006
From: RMan54 at cox.net (Rene Braeckman)
Date: Mon, 18 Dec 2006 19:56:07 -0800
Subject: [R] Random Effects Model
In-Reply-To: <20061218221845.0x7imssdvggsgwgk@webmail.colby.edu>
Message-ID: <004d01c72321$9c901650$0900a8c0@rman>

If these are the only variables, you are missing Type. Swim and Type are
both conditioning variables that you need to provide. Maybe your intention
is to use Sex instead of Type.
Try:

?xyplot

And look under x as the 1st argument for xyplot.

Rene 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of readams at colby.edu
Sent: Monday, December 18, 2006 7:19 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Random Effects Model

Hello,

I am new to R, and I am trying to figure out how to use it for a random
effects model. I am using version 2.4.0, and I also have the book Applied
Linear Regression by Sanford Weisberg.

I have four variables: Swimmer, Sex, Swim, and Difference.  Swimmer
identifies the number assigned to a particular person. Sex is male/female.
Swim identifies the number swim from 1 to 6. Difference is my variable of
interest (random).

The book says I should run something like this:

> library(nlme)
> data(FREE) #FREE is my dataset
> xyplot(Difference~Swim|Type, group=Swimmer, data=FREE,
+     panel.groups=function(x,y,...){
+       panel.linejoin(x,y,horizontal=FALSE,...)}
+     )
> m1 <- lme(Difference~Swim+Type, data=FREE, random=~1+Type|Swimmer)
> m2 <- update(m1, random=~1|Swimmer)

I've pretty much decided that xyplot doesn't work. Instead, I think plot
will work much better.  I keep getting errors about Type. Can someone
explain this to me? Does the code above look right?

Any kind of help will be appreciated...

Thanks in advance!

Ryan

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From shubhakaranth at gmail.com  Tue Dec 19 07:40:43 2006
From: shubhakaranth at gmail.com (Shubha Karanth)
Date: Tue, 19 Dec 2006 12:10:43 +0530
Subject: [R] Problem in Dates
Message-ID: <67e4ea330612182240p6b25e1c0v88f7608f37fa0e9d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061219/4d9ddf29/attachment.pl 

From shubhak at ambaresearch.com  Tue Dec 19 08:12:29 2006
From: shubhak at ambaresearch.com (Shubha Vishwanath Karanth)
Date: Tue, 19 Dec 2006 12:42:29 +0530
Subject: [R] FW: Problem in Dates
Message-ID: <A36876D3F8A5734FA84A4338135E7CC3AD93FF@BAN-MAILSRV03.Amba.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061219/e11034dd/attachment.pl 

From jzhang1982 at gmail.com  Tue Dec 19 09:05:00 2006
From: jzhang1982 at gmail.com (Zhang Jian)
Date: Tue, 19 Dec 2006 16:05:00 +0800
Subject: [R] how to replace some objects?
Message-ID: <3f2938d50612190005h2b0f56c0h952e19f53081b944@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061219/041f18cd/attachment.pl 

From jacques.veslot at good.ibl.fr  Tue Dec 19 09:27:40 2006
From: jacques.veslot at good.ibl.fr (Jacques VESLOT)
Date: Tue, 19 Dec 2006 09:27:40 +0100
Subject: [R] how to replace some objects?
In-Reply-To: <3f2938d50612190005h2b0f56c0h952e19f53081b944@mail.gmail.com>
References: <3f2938d50612190005h2b0f56c0h952e19f53081b944@mail.gmail.com>
Message-ID: <4587A27C.60407@good.ibl.fr>

you can use as.numeric(factor( )); in your example:
 > ex <- sample(letters[1:3], 10, T)
 > ex
  [1] "b" "b" "c" "b" "a" "a" "b" "b" "a" "a"

 > as.numeric(factor(ex))
  [1] 2 2 3 2 1 1 2 2 1 1

if the order is different, use levels:

 > as.numeric(factor(ex, levels=letters[3:1]))
  [1] 2 2 1 2 3 3 2 2 3 3

-------------------------------------------------------------------
Jacques VESLOT

CNRS UMR 8090
I.B.L (2?me ?tage)
1 rue du Professeur Calmette
B.P. 245
59019 Lille Cedex

Tel : 33 (0)3.20.87.10.44
Fax : 33 (0)3.20.87.10.31

http://www-good.ibl.fr
-------------------------------------------------------------------

Zhang Jian a ?crit :
> I want to replace some objects in one row or column.For example,
> One colume: a,b,a,c,b,b,a,a,c.
> I want to replace "a" with "1", "b" with "2", and "c" with "3".
> Like this: 1,2,1,3,2,2,1,1,3.
> 
> How to do it? I donot know how to do it. Thanks.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wangtong at usc.edu  Tue Dec 19 09:57:24 2006
From: wangtong at usc.edu (Tong Wang)
Date: Tue, 19 Dec 2006 00:57:24 -0800
Subject: [R] A question about debug package
Message-ID: <e0fedaeb3f8f.458738f4@usc.edu>

Hi all,
     I am using the debug package, and I would like some commands executed automatically as I quit by qqq( ),  
I tried the on.exit( ) , but it doesn't work in this case.   Any suggestions on this?   
 
thanks a lot .

tong


From jzhang1982 at gmail.com  Tue Dec 19 10:08:19 2006
From: jzhang1982 at gmail.com (Zhang Jian)
Date: Tue, 19 Dec 2006 17:08:19 +0800
Subject: [R] how to replace some objects?
In-Reply-To: <4587A27C.60407@good.ibl.fr>
References: <3f2938d50612190005h2b0f56c0h952e19f53081b944@mail.gmail.com>
	<4587A27C.60407@good.ibl.fr>
Message-ID: <3f2938d50612190108me257547s527983c85ca835b4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061219/f4630b56/attachment.pl 

From jacques.veslot at good.ibl.fr  Tue Dec 19 10:13:25 2006
From: jacques.veslot at good.ibl.fr (Jacques VESLOT)
Date: Tue, 19 Dec 2006 10:13:25 +0100
Subject: [R] how to replace some objects?
In-Reply-To: <3f2938d50612190108me257547s527983c85ca835b4@mail.gmail.com>
References: <3f2938d50612190005h2b0f56c0h952e19f53081b944@mail.gmail.com>	
	<4587A27C.60407@good.ibl.fr>
	<3f2938d50612190108me257547s527983c85ca835b4@mail.gmail.com>
Message-ID: <4587AD35.7080004@good.ibl.fr>

similarly:
as.character(factor(c("abca","coma"),labels=c("aaa","bbb")))
-------------------------------------------------------------------
Jacques VESLOT

CNRS UMR 8090
I.B.L (2?me ?tage)
1 rue du Professeur Calmette
B.P. 245
59019 Lille Cedex

Tel : 33 (0)3.20.87.10.44
Fax : 33 (0)3.20.87.10.31

http://www-good.ibl.fr
-------------------------------------------------------------------


Zhang Jian a ?crit :
> The example is simply.But the other example:
> One column: acba,coma,acmo,acmo,acba,coma
> I want to replace "acba" with "aaa", "coma" with "bbb", and "acmo" with 
> "ddd".
> Like this: aaa,bbb,ddd,ddd,aaa,bbb
> How to do it?
> Thanks.
> 
>  
> On 12/19/06, *Jacques VESLOT* <jacques.veslot at good.ibl.fr 
> <mailto:jacques.veslot at good.ibl.fr>> wrote:
> 
>     you can use as.numeric(factor( )); in your example:
>      > ex <- sample(letters[1:3], 10, T)
>      > ex
>     [1] "b" "b" "c" "b" "a" "a" "b" "b" "a" "a"
> 
>      > as.numeric(factor(ex))
>     [1] 2 2 3 2 1 1 2 2 1 1
> 
>     if the order is different, use levels:
> 
>      > as.numeric(factor(ex, levels=letters[3:1]))
>     [1] 2 2 1 2 3 3 2 2 3 3
> 
>     -------------------------------------------------------------------
>     Jacques VESLOT
> 
>     CNRS UMR 8090
>     I.B.L (2?me ?tage)
>     1 rue du Professeur Calmette
>     B.P. 245
>     59019 Lille Cedex
> 
>     Tel : 33 (0)3.20.87.10.44
>     Fax : 33 (0)3.20.87.10.31
> 
>     http://www-good.ibl.fr
>     -------------------------------------------------------------------
> 
>     Zhang Jian a ?crit :
>      > I want to replace some objects in one row or column.For example,
>      > One colume: a,b,a,c,b,b,a,a,c.
>      > I want to replace "a" with "1", "b" with "2", and "c" with "3".
>      > Like this: 1,2,1,3,2,2,1,1,3.
>      >
>      > How to do it? I donot know how to do it. Thanks.
>      >
>      >       [[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at stat.math.ethz.ch <mailto:R-help at stat.math.ethz.ch>
>     mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
> 
>


From info at aghmed.fsnet.co.uk  Tue Dec 19 12:40:09 2006
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Tue, 19 Dec 2006 11:40:09 +0000
Subject: [R] proc GLM with R
In-Reply-To: <B0F504209244B14EA9A4C1DFB599B9224FFDCB@NIHCESMLBX6.nih.gov
 >
References: <B0F504209244B14EA9A4C1DFB599B9224FFDCB@NIHCESMLBX6.nih.gov>
Message-ID: <7.0.0.16.0.20061219113438.019b8e48@aghmed.fsnet.co.uk>

At 05:15 18/12/2006, Cressoni, Massimo \(NIH/NHLBI\) [F] wrote:
>I want to migrate from SAS to R.
>I used proc mixed to do comparison between multiple groups and to perform
>multiple comparison between groups since, as far as I know, proc 
>mixed does not make assumptions about the data and so
>it is better than a simple anova (data must only be normal).
>Es. how can I translate a code like this (two way anova with a factor of
>repetition) :
>
>
>proc mixed;
>class kind  PEEP codice;
>model PaO2_FiO2 = kind PEEP kind*PEEP;
>repeated /type = un sub=codice;
>lsmeans kind*PEEP /adjust=bon;
>run;
>
>codice is a unique identifier of patient
>kind is a variable which subdivided the patient (i.e. red or brown hairs)
>PEEP is positive end expiratory pressure. These are the steps of a clinical
>trial. Patient did the trial at PEEP = 5 and PEEP = 10

You could investigate either nlme or lme4
The best documentation for nlme (which should be included in your system) is
@BOOK{pinheiro00,
   author = {Pinheiro, J C and Bates, D M},
   year = 2000,
   title = {Mixed-effects models in {S} and {S-PLUS}},
   publisher = {Springer-Verlag},
   address = {New York},
   keywords = {glm; mixed models}
}
lme4 is a more recent development by Bates which as yet has slightly 
fewer helper functions and no book.

Since you are assuming normal error you can use nlme. I am afraid I 
do not read SAS so I think it would be wrong of me to try to 
translate your example (traddutore, traditore and all that)


>Thank you
>
>Massimo Cressoni
>
>run;

Michael Dewey
http://www.aghmed.fsnet.co.uk


From fridolin.wild at wu-wien.ac.at  Tue Dec 19 12:41:44 2006
From: fridolin.wild at wu-wien.ac.at (Fridolin Wild)
Date: Tue, 19 Dec 2006 12:41:44 +0100
Subject: [R] configure help
Message-ID: <4587CFF8.8070602@wu-wien.ac.at>


Hello,

as I just spent a (too long) while searching
for a way how to persistantly switch back the help display
routines from chm to text, here a small documentation
how to do that with the windows version of R.

The windows installer asks which help type
you want to use, I wanted to test the chm
version -- which I didn't like.

If you after installation want to switch back,
you have to edit

    << myRdirectory\etc\Rprofile.site >>

and change the line

    options(chmhelp=TRUE)

back to

    options(chmhelp=FALSE)

It would be nice if -- in a future release -- this
also could be changed in the GUI settings.

Best,
Fridolin

-- 
Fridolin Wild, Institute for Information Systems and New Media,
Vienna University of Economics and Business Administration (WUW),
Augasse 2-6, A-1090 Wien, Austria
fon +43-1-31336-4488, fax +43-1-31336-746


From kubovy at virginia.edu  Tue Dec 19 12:49:51 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Tue, 19 Dec 2006 06:49:51 -0500
Subject: [R] how to replace some objects?
In-Reply-To: <3f2938d50612190005h2b0f56c0h952e19f53081b944@mail.gmail.com>
References: <3f2938d50612190005h2b0f56c0h952e19f53081b944@mail.gmail.com>
Message-ID: <2B79EAB2-3D67-4FD6-ABD0-BBA573495E20@virginia.edu>

On Dec 19, 2006, at 3:05 AM, Zhang Jian wrote:

> I want to replace some objects in one row or column.For example,
> One colume: a,b,a,c,b,b,a,a,c.
> I want to replace "a" with "1", "b" with "2", and "c" with "3".
> Like this: 1,2,1,3,2,2,1,1,3.

let <- c('a', 'b', 'a', 'c', 'b', 'b', 'a', 'a', 'c')
library(car)
num <- recode(let, " 'a' = 1; 'b' = 2; else = 3 ")

_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/


From ripley at stats.ox.ac.uk  Tue Dec 19 13:15:11 2006
From: ripley at stats.ox.ac.uk (Brian Ripley)
Date: Tue, 19 Dec 2006 12:15:11 +0000 (GMT)
Subject: [R] configure help
In-Reply-To: <4587CFF8.8070602@wu-wien.ac.at>
References: <4587CFF8.8070602@wu-wien.ac.at>
Message-ID: <Pine.LNX.4.64.0612191211191.6091@auk.stats>

On Tue, 19 Dec 2006, Fridolin Wild wrote:

>
> Hello,
>
> as I just spent a (too long) while searching
> for a way how to persistantly switch back the help display
> routines from chm to text, here a small documentation
> how to do that with the windows version of R.
>
> The windows installer asks which help type
> you want to use, I wanted to test the chm
> version -- which I didn't like.
>
> If you after installation want to switch back,
> you have to edit
>
>    << myRdirectory\etc\Rprofile.site >>
>
> and change the line
>
>    options(chmhelp=TRUE)
>
> back to
>
>    options(chmhelp=FALSE)
>
> It would be nice if -- in a future release -- this
> also could be changed in the GUI settings.

But it has nothing to do with the GUI preferences: it applies to the 
command-line version of R as well.

What about ?help did you not understand? It says

           chmhelp = getOption("chmhelp"),
           ...
  chmhelp: logical (or 'NULL'). Only relevant under Windows. If 'TRUE'
           the Compiled HTML version of the help on the topic will be
           shown in a help viewer.

so you need to set options(chmhelp=FALSE): it is up to you where you set 
it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From news at gavofyork.fastmail.fm  Tue Dec 19 13:02:59 2006
From: news at gavofyork.fastmail.fm (Gav Wood)
Date: Tue, 19 Dec 2006 12:02:59 +0000
Subject: [R] 1-D Image as label?
Message-ID: <em8kdk$hpo$1@sea.gmane.org>

I have a data set for visualisation that comprises several sets of 1-D 
points over a given time span (the time span of the experiment). These 
are basically just several variable-length arrays of values whose units 
are seconds.

I have several sets of further data relating to the nature of the 
experiment; Each describes each second in the experiment with an RGB 
colour triplet; this amounts to a 1 dimensional bitmap image whose axis 
is the same time axis of the former data set.

I envisage one possible visualisation with the X axis (time) being 
annotated with one set of the colours from the latter data set. The Y 
axis would be either a histogram of the points from the former dataset, 
or (better, since the points are somewhat imprecise) a probability 
density function over time, derived from the gathered times themselves 
but assuming each represents an event that happened somewhere close to 
it. I am looking into using a density estimation function for this, as 
described in http://en.wikipedia.org/wiki/Density_estimation

This brings me to my question;

What would be the easiest way of annotating an axis with an array of 
colour triplets?

Thanks for any insights/information you can offer,

Gav


From mdu at ceh.ac.uk  Tue Dec 19 14:38:58 2006
From: mdu at ceh.ac.uk (Mike Dunbar)
Date: Tue, 19 Dec 2006 13:38:58 +0000
Subject: [R] Random Effects Model
Message-ID: <s587eb91.037@wpo.nerc.ac.uk>

Hi Ryan

Your model code suggests that Type is a variable that you have in your FREE data frame, but you don't mention it, that is probably part of your problem?

The second question is how are your data structured? Sex goes in the fixed part of the model. Swimmer is almost certainly goes in the random component, as you have identified. The question is what to do with Swim. This could either be the key variable of interest or simply a label representing replicates. What is the hypothesis you're trying to test? When swimmers 1..n undertake swim 1 is this all at the same time? If this is the case, do you have reason to believe that there could be some similarlites (not sure what, maybe temperature, wind conditions, fatigue) between swimmers on the same swim? 

Without information on the data structure then its difficult to suggest anything further. As a first guess you could try comparing:

m1 <- lme(Difference~Sex, random=~1|Swimmer, data=FREE)
m2 <- lme(Difference~Sex, random=~1|Swimmer/Swim, data=FREE)

With Swim in the fixed component of the model you're suggesting a linear relationship between Difference and Swim, are you sure this is what you want? If you really think Swim should be in the fixed compoent then you might want to compare:

m3 <- lme(Difference~Sex*Swim, random=~1|Swimmer, data=FREE)
m4 <- lme(Difference~Sex*Swim, random=~Swim|Swimmer, data=FREE)

The latter will fit an overall relationship between Difference and Swim, and then estimate both intercept and slope random effects for Swim.

regards

Mike D


>>> <readams at colby.edu> 19/12/2006 03:18 >>>
Hello,

I am new to R, and I am trying to figure out how to use it for a  
random effects model. I am using version 2.4.0, and I also have the  
book Applied Linear Regression by Sanford Weisberg.

I have four variables: Swimmer, Sex, Swim, and Difference.  Swimmer  
identifies the number assigned to a particular person. Sex is  
male/female. Swim identifies the number swim from 1 to 6. Difference  
is my variable of interest (random).

The book says I should run something like this:

> library(nlme)
> data(FREE) #FREE is my dataset
> xyplot(Difference~Swim|Type, group=Swimmer, data=FREE,
+     panel.groups=function(x,y,...){
+       panel.linejoin(x,y,horizontal=FALSE,...)}
+     )
> m1 <- lme(Difference~Swim+Type, data=FREE, random=~1+Type|Swimmer)
> m2 <- update(m1, random=~1|Swimmer)

I've pretty much decided that xyplot doesn't work. Instead, I think  
plot will work much better.  I keep getting errors about Type. Can  
someone explain this to me? Does the code above look right?

Any kind of help will be appreciated...

Thanks in advance!

Ryan

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code.


-- 
This message (and any attachments) is for the recipient only...{{dropped}}


From fridolin.wild at wu-wien.ac.at  Tue Dec 19 14:56:57 2006
From: fridolin.wild at wu-wien.ac.at (Fridolin Wild)
Date: Tue, 19 Dec 2006 14:56:57 +0100
Subject: [R] configure help
In-Reply-To: <Pine.LNX.4.64.0612191211191.6091@auk.stats>
References: <4587CFF8.8070602@wu-wien.ac.at>
	<Pine.LNX.4.64.0612191211191.6091@auk.stats>
Message-ID: <4587EFA9.8030705@wu-wien.ac.at>


Hey Brian,

> But it has nothing to do with the GUI preferences: it applies to the 
> command-line version of R as well.

I was suspecting this argument ;) -- however, I think
from a usability point of view it should be possible
to re-set the default setting also somewhere *within*
the GUI if the GUI installer allows to set it. Maybe
in a different place?

> What about ?help did you not understand? It says

That is where I found how to set it (for my current
workspace). Finding where I can set it *permanently*
was more difficult (especially when you never had
the need to mingle with R-profiles before).

That's why I decided to document it here in the
mailinglist just in case others have troubles
finding it, too.

Best,
Fridolin


From ggrothendieck at gmail.com  Tue Dec 19 15:08:19 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 19 Dec 2006 09:08:19 -0500
Subject: [R] Problem in Dates
In-Reply-To: <67e4ea330612182240p6b25e1c0v88f7608f37fa0e9d@mail.gmail.com>
References: <67e4ea330612182240p6b25e1c0v88f7608f37fa0e9d@mail.gmail.com>
Message-ID: <971536df0612190608r24a5a913h8cfdc2726923668f@mail.gmail.com>

Read R News 4/1 help desk article and the last line of every message to r-help.
Also putting POSIXlt objects into data frames is asking for trouble.

On 12/19/06, Shubha Karanth <shubhakaranth at gmail.com> wrote:
> Hi Experts,
>
>
>
> I have a problem in Dates.
>
>
>
> I have a zoo object called 'intra'. And the class of index(intra) is
> ("Chron" "Dates" "Time"). I need to put the index of this zoo object into a
> data frame. So I used,
>
>
>
> idat<-data.frame(Datetime=as.POSIXlt(index(intra),"GMT"))
>
>
>
>
>
> But I get the values of 'idat' to be:
>
>
>
> "01joulu2006 09:59:59"
>
> "01joulu2006 10:09:59"
>
> "01joulu2006 10:19:59"
>
> "01joulu2006 10:30:00"
>
> "01joulu2006 10:40:00"
>
> "01joulu2006 10:50:00"
>
>
>
>
>
> But I need the 'idat' format to be:
>
>
>
> 2006-12-01 13:30:00
>
> 2006-12-01 13:40:00
>
> 2006-12-01 13:50:00
>
> 2006-12-01 14:00:00
>
> 2006-12-01 14:10:00
>
> 2006-12-01 14:19:59
>
> 2006-12-01 14:29:59
>
>
>
>
>
> i.e., instead of joulu (The finnish version of December) I need to get in
> the number format. How do I do this? Do I need to change the OS date format?
>
>
>
> Because I read a documentation which says "Unfortunately, the documentation
> of POSIXt objects is Operating system dependent and especially under MS
> Windows several problems appear in the management of time zones and day
> light saving times" (Source: R Documentation, timeDate Class). Thought this
> may help you?
>
>
>
> Thank you,
>
> Shubha.
>
>        [[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From bates at stat.wisc.edu  Tue Dec 19 15:50:12 2006
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 19 Dec 2006 08:50:12 -0600
Subject: [R] A question on lmer() function
In-Reply-To: <5A3E65F71DFAAE41AC2D20B61B177C5ED0F991@CDU-MAIL.cdu-staff.local>
References: <5A3E65F71DFAAE41AC2D20B61B177C5ED0F991@CDU-MAIL.cdu-staff.local>
Message-ID: <40e66e0b0612190650h5431ddd3yf60dfb92e1fafdf6@mail.gmail.com>

On 12/17/06, Guojing Yang <Guojing.Yang at cdu.edu.au> wrote:
> Dear R users,
>      We have encountered a slight problem when using the lmer()
> function:
>
>   1. Data description: 11 locations; Nt: monthly mosquito population
> density from 1994-2005 in each location.
>   2. Question: to examine the degree of spatial heterogeneity in the
> system by testing model support for single versus multiple intercepts
> and slopes for the location effect. We applied the lmer() function and
> introduced location as spatial effect. Four different models were
> generated as following:
> a.      1 intercept & 1 slope :  lmer(r~log(N)+(1|location)), where r <-
> log(Nt/Nt-1) and location is a random effect.
> b.      Multi-intercept & 1 slope: lmer(r~location+log(N)+(1|location))
> c.      1 slope & multi-intercept: ??????
> d.      Multi-intercept & multi-slope:
> lmer(r~location*log(N)+(1|location))

I'm not exactly sure what you want to do here but you definitely
should not have location as a fixed-effects term and a random effects
term of the form (1|location).  Such terms would be confounded.

I think the models you want to fit would all have an (implicit)
intercept and a log(N) term in the fixed effects.  They would differ
in terms of whether you have a random effect for the intercept by
location and/or a random effect for the slope with respect to log(N)
by location.  Four variants are

#  random effects for intercept only
lmer(r ~ log(N) + (1|location))

# random effects for slope only
lmer(r ~ log(N) + (0+log(N)|location))

# possibly correlated random effects for intercept and slope
lmer(r ~ log(N) + (log(N)|location))

# independent random effects for intercept and slope
lmer(r ~ log(N) + (1|location) + (0+log(N)|location))

> As you can see, we have had trouble defining model c. Does anyone know
> how to code this using lmer? We really appreciate any response.
> Guojing
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From suncertain at gmail.com  Tue Dec 19 16:28:36 2006
From: suncertain at gmail.com (HelponR)
Date: Tue, 19 Dec 2006 09:28:36 -0600
Subject: [R] nonparametric significance test for one sample
Message-ID: <4ab0fb470612190728q41340e0bgdf03d504562bf923@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061219/6f4683db/attachment.pl 

From Ralf.Finne at syh.fi  Tue Dec 19 16:31:32 2006
From: Ralf.Finne at syh.fi (Ralf Finne)
Date: Tue, 19 Dec 2006 17:31:32 +0200
Subject: [R] Neural Network with Multiple Outputs
Message-ID: <458821F4020000EE00002509@valhall.syh.fi>

Hi! I want to use an artificial neural network of
type MLP (Multi Level Perception) as a kind of
generalized regression.  In this case there are several
binary outputs.  I have been using Matlab with
good results.  But has anybody found a good
package in R.
Ralf Finne
SYH University of Applied Sciences, Finland


From jrkrideau at yahoo.ca  Tue Dec 19 16:33:42 2006
From: jrkrideau at yahoo.ca (John Kane)
Date: Tue, 19 Dec 2006 10:33:42 -0500 (EST)
Subject: [R] Replacing values
In-Reply-To: <7934402.post@talk.nabble.com>
Message-ID: <841497.56438.qm@web32807.mail.mud.yahoo.com>


--- downunder <larsfromspace at web.de> wrote:

> 
> Hi all,
> 
> I have to recode some values in a dataset. for
> example changing all zeros to
> "." or 999 would be also ok. does anybody know how
> to do this? thanks in
> advance. lars

Hi Lars.
Marc has warned you about . 999 vs NA 

A couple of approachs:
aa <- c(2,3,5,7,7, 3)
aa[aa==7] <- 5
aa

or
library(car)
?recode


From jgarcia at ija.csic.es  Tue Dec 19 16:48:38 2006
From: jgarcia at ija.csic.es (javier garcia-pintado)
Date: Tue, 19 Dec 2006 16:48:38 +0100
Subject: [R] xaxt="n" for image()
Message-ID: <458809D6.3050501@ija.csic.es>

Hi,
The argument xaxt="n" for removing the x axis from a image plot does not
work for me.
I'm really using a function called plot.grassmeta() in library GRASS
that is a wrapper for image(), but it seems to me that the problem is
not in plot.grassmeta() but in image().

If I'm right could you tell me if there is a way to remove one axis from
a call to image()?

Thanks and wishes,

Javier
-----------------------------

-- 
Javier Garc?a-Pintado
Institute of Earth Sciences Jaume Almera (CSIC)
Lluis Sole Sabaris s/n, 08028 Barcelona
Phone: +34 934095410
Fax:   +34 934110012
e-mail:jgarcia at ija.csic.es 


From aajakh at yahoo.com  Tue Dec 19 16:52:46 2006
From: aajakh at yahoo.com (ahmad ajakh)
Date: Tue, 19 Dec 2006 07:52:46 -0800 (PST)
Subject: [R] configure help
Message-ID: <20061219155247.68050.qmail@web37910.mail.mud.yahoo.com>

Hi All,

I ma running R under windows with xemacs and ESS.
The Rprofile.site options, somehow gets overridden by xemacs and my options
in Rprofile.site are not taken into account while they are when I use Rgui.
How can I specify my options if I am using xemacs? and what configuration file
xemacs+ess use for R.
Thanks
AA

----- Original Message ----
From: Brian Ripley <ripley at stats.ox.ac.uk>
To: Fridolin Wild <fridolin.wild at wu-wien.ac.at>
Cc: r-help at stat.math.ethz.ch
Sent: Tuesday, December 19, 2006 7:15:11 AM
Subject: Re: [R] configure help

On Tue, 19 Dec 2006, Fridolin Wild wrote:

>
> Hello,
>
> as I just spent a (too long) while searching
> for a way how to persistantly switch back the help display
> routines from chm to text, here a small documentation
> how to do that with the windows version of R.
>
> The windows installer asks which help type
> you want to use, I wanted to test the chm
> version -- which I didn't like.
>
> If you after installation want to switch back,
> you have to edit
>
>    << myRdirectory\etc\Rprofile.site >>
>
> and change the line
>
>    options(chmhelp=TRUE)
>
> back to
>
>    options(chmhelp=FALSE)
>
> It would be nice if -- in a future release -- this
> also could be changed in the GUI settings.

But it has nothing to do with the GUI preferences: it applies to the 
command-line version of R as well.

What about ?help did you not understand? It says

           chmhelp = getOption("chmhelp"),
           ...
  chmhelp: logical (or 'NULL'). Only relevant under Windows. If 'TRUE'
           the Compiled HTML version of the help on the topic will be
           shown in a help viewer.

so you need to set options(chmhelp=FALSE): it is up to you where you set 
it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From kubovy at virginia.edu  Tue Dec 19 17:04:56 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Tue, 19 Dec 2006 11:04:56 -0500
Subject: [R] Problem with glmmADMB
Message-ID: <C443FB31-D0BB-471B-91AA-20F4A1852AB9@virginia.edu>

library(glmmADMB)
#Example for   glmm.admb
data(epil2)
glmm.admb(y~Base*trt+Age 
+Visit,random=~Visit,group="subject",data=epil2,family="nbinom")

Gives:
Error in glmm.admb(y ~ Base * trt + Age + Visit, random = ~Visit,  
group = "subject",  :
	The function maximizer failed

******************
R version 2.4.1 RC (2006-12-14 r40181)
powerpc-apple-darwin8.8.0

locale:
C

attached base packages:
[1] "utils"     "stats"     "graphics"  "grDevices" "datasets"   
"methods"   "base"

other attached packages:
glmmADMB       JGR    iplots    JavaGD     rJava      MASS   lattice
     "0.3"  "1.4-14"   "1.0-5"   "0.3-5"  "0.4-12"  "7.2-30" "0.14-16"

_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/


From robert.lischke at zmms.tu-berlin.de  Tue Dec 19 17:11:15 2006
From: robert.lischke at zmms.tu-berlin.de (Robert Lischke)
Date: Tue, 19 Dec 2006 17:11:15 +0100
Subject: [R] Summary Tables for t.test?
Message-ID: <45880F23.8080805@zmms.tu-berlin.de>

Hi there,

kind of a newbie-question, but anyway: is there a way to aggregate a
nice table with input and results of a t-Test?

I'm looking for something like a summary of Mean, Median, SD (seperated
for both distributions) and p-value, df, etc. for the t-Test.

I'm asking because i need a dozen of them and want to avoid putting
those together by hand (output as LaTeX would be a nice extra ;)

Best Greetings,



Robert


From detlef.steuer at hsu-hamburg.de  Tue Dec 19 17:34:25 2006
From: detlef.steuer at hsu-hamburg.de (Detlef Steuer)
Date: Tue, 19 Dec 2006 17:34:25 +0100
Subject: [R] R 2.4.1  changes for SuSE users
Message-ID: <20061219173425.62a4bcb5.detlef.steuer@hsu-hamburg.de>

Hi UseRs!

RPMs for SuSE Versions 9.3 to 10.2 and bleeding edge aka openSUSE_Factory
are available at

http://software.opensuse.org/download/home:/dsteuer/

as I shifted the creation of these packages onto the Opensuse Build Service compiler farm.
You can use the directories therein as installation sources for the respective versions of SuSE Linux.

My goal is to put R-base back onto (open)suse's installation DVD, as it was a long, long time ago. Well, may be before there were DVDs :-)
As the opensuse developers will take into account the usage of their repository to determine what new packages to include, I recommend using opensuse.org to download the R packages. Besides R-base you'll  find littler and emacs-ess rpms for download. 
R-patched and R-devel will be added soon .

I will not, for the moment, maintain the CRAN directories as installation sources, only as a repository for downloading rpms for a manual install. (There were strange problems anyway ...) So CRAN will stay complete, but I?ll use the comfort of the build service by opensuse.
If the build service will stop some day, I?ll once again start to put proper installation sources on CRAN.

Happy R?ing!
Detlef

---
Detlef Steuer
Helmut-Schmidt-Universit?t Hamburg
FB WOW
steuer at hsu-hh.de


From hskaug at gmail.com  Tue Dec 19 17:55:19 2006
From: hskaug at gmail.com (H. Skaug)
Date: Tue, 19 Dec 2006 17:55:19 +0100
Subject: [R]  Problem with glmmADMB
Message-ID: <ed96c8240612190855y602500e0h5e7d735f27af7e1f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061219/39db403f/attachment.pl 

From suncertain at gmail.com  Tue Dec 19 17:55:58 2006
From: suncertain at gmail.com (HelponR)
Date: Tue, 19 Dec 2006 10:55:58 -0600
Subject: [R] Fwd: nonparametric significance test for one sample
In-Reply-To: <4ab0fb470612190728q41340e0bgdf03d504562bf923@mail.gmail.com>
References: <4ab0fb470612190728q41340e0bgdf03d504562bf923@mail.gmail.com>
Message-ID: <4ab0fb470612190855k61eeff02od9c0388dd3b8df97@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061219/924eec66/attachment.pl 

From federico.ambrogi at istitutotumori.mi.it  Tue Dec 19 18:03:22 2006
From: federico.ambrogi at istitutotumori.mi.it (Ambrogi Federico)
Date: Tue, 19 Dec 2006 18:03:22 +0100
Subject: [R] effect plot
Message-ID: <7CFFC9251C01BD48A07D2DBDA8488E1E0387DEF7@EXCHSRVR02.int.milano>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061219/44582f0b/attachment.pl 

From elvis at xlsolutions-corp.com  Tue Dec 19 19:40:55 2006
From: elvis at xlsolutions-corp.com (elvis at xlsolutions-corp.com)
Date: Tue, 19 Dec 2006 11:40:55 -0700
Subject: [R] Course***Salt Lake City** R/Splus Fundamentals and Programming
	Techniques
Message-ID: <20061219114055.9f08cc34deb45d78e54b3b5664e21546.eabdae2100.wbe@email.secureserver.net>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud to
announce our Salt Lake City "R/S-plus Fundamentals and
Programming
Techniques" : www.xlsolutions-corp.com/Rfund.htm

*** Salt Lake City / February 15-16, 2007

Should we bring this course to your city? please let us know!

Reserve your seat now at the early bird rates! Payment due AFTER
the class

Course Description:

This two-day beginner to intermediate R/S-plus course focuses on a
broad spectrum of topics, from reading raw data to a comparison of R
and S. We will learn the essentials of data manipulation, graphical
visualization and R/S-plus programming. We will explore statistical
data analysis tools,including graphics with data sets. How to enhance
your plots, build your own packages (librairies) and connect via
ODBC,etc.
We will perform some statistical modeling and fit linear regression
models. Participants are encouraged to bring data for interactive
sessions

With the following outline:

- An Overview of R and S
- Data Manipulation and Graphics
- Using Lattice Graphics
- A Comparison of R and S-Plus
- How can R Complement SAS?
- Writing Functions
- Avoiding Loops
- Vectorization
- Statistical Modeling
- Project Management
- Techniques for Effective use of R and S
- Enhancing Plots
- Using High-level Plotting Functions
- Building and Distributing Packages (libraries)
- Connecting; ODBC, Rweb, Orca via sockets and via Rjava


Email us for group discounts.
Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578
Visit us: www.xlsolutions-corp.com/training.htm
Please let us know if you and your colleagues are interested in this
classto take advantage of group discount. Register now to secure your
seat!

Interested in R/Splus Advanced course? email us.


Cheers,
Elvis Miller, PhD
Manager Training.
XLSolutions Corporation
206 686 1578
www.xlsolutions-corp.com
elvis at xlsolutions-corp.com


From Greg.Snow at intermountainmail.org  Tue Dec 19 19:43:14 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Tue, 19 Dec 2006 11:43:14 -0700
Subject: [R] nonparametric significance test for one sample
Message-ID: <07E228A5BE53C24CAD490193A7381BBB739D17@LP-EXCHVS07.CO.IHC.COM>

If you data is truly limited to be non-negative and you are testing a
null hypothesis that the true distribution mean is 0, then the test is
fairly straight forward.  There exists only one distribution with mean 0
and all values required to be >= 0 and that is a point mass of 1 at 0.
So if all of your data values are 0 then that means a p-value of 1 and
if any data values are greater than 0 (even if it is only 1 value and it
is only slightly greater than 0) then the p-value is 0.

If you want to then estimate what the true mean is for an unknown
distribution, then you may want to look at using a bootstrap estimate.

Hope this helps, 


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of HelponR
Sent: Tuesday, December 19, 2006 8:29 AM
To: r-help
Subject: [R] nonparametric significance test for one sample

Hello, Gurus:

I tried to test if the sample mean of a dataset is zero.

The data has 1500 numbers with a lot of zeros and some small positive
numbers. The data range on [0,1] but the distribution is unknown.
It is zero inflated anyway.

I tried to use the  Wilcoxon Signed Ranks test. But I read from this
website that it does assume the population pdf is symmetric.

http://www.cas.lancs.ac.uk/glossary_v1.1/nonparam.html#wsrt
"The Wilcoxon Signed Ranks test does not require the assumption that the
population is normally distributed. In many applications, this test is
used in place of the one sample
t-test<http://www.cas.lancs.ac.uk/glossary_v1.1/hyptest.html#1sampt>when
the normality assumption is questionable. It is a more powerful
alternative to the sign test, but does assume that the population
probability distribution is symmetric."

I wonder if wilcox.test( ) in R also assumes the symmetric pdf?

I checked the sign test too. But "the sign *test* is not *testing
equality*of population "

If wilcox.test() cannot work for my data, I wonder if you could suggest
a kind of test? I already tried t-test (assume normality) but I want to
find something else.

Many thanks!

S

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From sfalcon at fhcrc.org  Tue Dec 19 20:16:57 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 19 Dec 2006 11:16:57 -0800
Subject: [R] BioC Advanced Course Jan 10th-12th (Space Still Available)
Message-ID: <m2odpzg0gm.fsf@ziti.local>

Hello all,

There is still space available for the upcoming BioC Advanced Course
being held in Seattle January 10th-12th.

For details and registration, please visit:
https://secure.bioconductor.org/biocadv/

Best Wishes,

+ seth

--
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From zelickr at pdx.edu  Tue Dec 19 20:52:16 2006
From: zelickr at pdx.edu (Randy Zelick)
Date: Tue, 19 Dec 2006 11:52:16 -0800 (PST)
Subject: [R] fit sine?
Message-ID: <Pine.GSO.4.62.0612191145500.22991@freke.odin.pdx.edu>

Hello list,

I am making scatterplots of data that vary sinusoidally over 24 hours. 
With a bit of previous help from this list, I now can get an x-axis with 
time tics from 00:00 on the left edge to 12:00 in the middle and 00:00 on 
the right edge, i.e., just 24 hours.

Now I would like to fit a sin function to the plot. I've looked all over 
CRAN and the web in general, but have not found a method or package for 
this.

Can anyone make a suggestion?

Thanks,

=Randy=


Using R 2.4.0 on Solaris (unix).


R. Zelick				email: zelickr at pdx.edu
Department of Biology			voice: 503-725-3086
Portland State University		fax:   503-725-3888

mailing:
P.O. Box 751
Portland, OR 97207

shipping:
1719 SW 10th Ave, Room 246
Portland, OR 97201


From basu.15 at osu.edu  Tue Dec 19 21:31:20 2006
From: basu.15 at osu.edu (DEEPANKAR BASU)
Date: Tue, 19 Dec 2006 15:31:20 -0500
Subject: [R] attach and object masking
Message-ID: <45b34b460871.46087145b34b@osu.edu>

Hi R users!

I am new to R. When I try to attach a simple dataset using the attach() command, I get the following message:

> attach(data1)

        The following object(s) are masked from package:base :

         write

Can someone tell me what this means? (`write' is the name of a variable in the dataset). And, do I need to do do something about this.

Thanks.


From tlumley at u.washington.edu  Tue Dec 19 21:46:53 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 19 Dec 2006 12:46:53 -0800 (PST)
Subject: [R] attach and object masking
In-Reply-To: <45b34b460871.46087145b34b@osu.edu>
References: <45b34b460871.46087145b34b@osu.edu>
Message-ID: <Pine.LNX.4.64.0612191236030.29263@homer24.u.washington.edu>

On Tue, 19 Dec 2006, DEEPANKAR BASU wrote:

> Hi R users!
>
> I am new to R. When I try to attach a simple dataset using the attach() command, I get the following message:
>
>> attach(data1)
>
>        The following object(s) are masked from package:base :
>
>         write
>
> Can someone tell me what this means? (`write' is the name of a variable 
> in the dataset). And, do I need to do do something about this.
>

It means that 'write' is the name of a variable in the dataset. R is 
warning you that you have two things called 'write' -- your variable and a 
function in the base package.

It also means that you have missed at least three upgrades of R (the 
fourth is just out) since in version 2.3.0 and more recent you don't get 
the warning when a variable and a function have the same name, only for 
two variables or two functions.  There have been quite a lot of other 
changes since your version of R, so it would be worth upgrading.

 	-thomas


From tlumley at u.washington.edu  Tue Dec 19 21:52:42 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 19 Dec 2006 12:52:42 -0800 (PST)
Subject: [R] attach and object masking
In-Reply-To: <Pine.LNX.4.64.0612191236030.29263@homer24.u.washington.edu>
References: <45b34b460871.46087145b34b@osu.edu>
	<Pine.LNX.4.64.0612191236030.29263@homer24.u.washington.edu>
Message-ID: <Pine.LNX.4.64.0612191250410.29263@homer24.u.washington.edu>

On Tue, 19 Dec 2006, Thomas Lumley wrote:
>
> It also means that you have missed at least three upgrades of R (the
> fourth is just out) since in version 2.3.0 and more recent you don't get
> the warning when a variable and a function have the same name, only for
> two variables or two functions.  There have been quite a lot of other
> changes since your version of R, so it would be worth upgrading.
>

I just noticed I didn't say explicitly whether you need to do anything 
else about the warning. You don't.

 	-thomas


From A.Robinson at ms.unimelb.edu.au  Tue Dec 19 21:53:30 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 20 Dec 2006 07:53:30 +1100
Subject: [R] Problem with glmmADMB
In-Reply-To: <C443FB31-D0BB-471B-91AA-20F4A1852AB9@virginia.edu>
References: <C443FB31-D0BB-471B-91AA-20F4A1852AB9@virginia.edu>
Message-ID: <20061219205330.GD56246@ms.unimelb.edu.au>

Hi Michael,

this error should be reported to the package maintainer, whom I assume
to be the package author, Dave Fournier.  I saw on his website:

Questions relating to the R-package should be posted to the ADMB user
forum under the topic "ADMB NBMM for R"

http://otter-rsch.com/admbre/examples/glmmadmb/glmmADMB.html

Cheers

Andrew

On Tue, Dec 19, 2006 at 11:04:56AM -0500, Michael Kubovy wrote:
> library(glmmADMB)
> #Example for   glmm.admb
> data(epil2)
> glmm.admb(y~Base*trt+Age 
> +Visit,random=~Visit,group="subject",data=epil2,family="nbinom")
> 
> Gives:
> Error in glmm.admb(y ~ Base * trt + Age + Visit, random = ~Visit,  
> group = "subject",  :
> 	The function maximizer failed
> 
> ******************
> R version 2.4.1 RC (2006-12-14 r40181)
> powerpc-apple-darwin8.8.0
> 
> locale:
> C
> 
> attached base packages:
> [1] "utils"     "stats"     "graphics"  "grDevices" "datasets"   
> "methods"   "base"
> 
> other attached packages:
> glmmADMB       JGR    iplots    JavaGD     rJava      MASS   lattice
>      "0.3"  "1.4-14"   "1.0-5"   "0.3-5"  "0.4-12"  "7.2-30" "0.14-16"
> 
> _____________________________
> Professor Michael Kubovy
> University of Virginia
> Department of Psychology
> USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
> Parcels:    Room 102        Gilmer Hall
>          McCormick Road    Charlottesville, VA 22903
> Office:    B011    +1-434-982-4729
> Lab:        B019    +1-434-982-4751
> Fax:        +1-434-982-4766
> WWW:    http://www.people.virginia.edu/~mk9y/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/


From br44114 at gmail.com  Tue Dec 19 22:12:28 2006
From: br44114 at gmail.com (bogdan romocea)
Date: Tue, 19 Dec 2006 16:12:28 -0500
Subject: [R] fit sine?
Message-ID: <8d5a36350612191312m50848719sfe5a99b496edcee2@mail.gmail.com>

Read up on the discrete Fourier transform:
http://en.wikipedia.org/wiki/Discrete_Fourier_transform
http://en.wikipedia.org/wiki/Frequency_spectrum#Spectrum_analysis


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Randy Zelick
> Sent: Tuesday, December 19, 2006 2:52 PM
> To: R list server posting
> Subject: [R] fit sine?
>
> Hello list,
>
> I am making scatterplots of data that vary sinusoidally over
> 24 hours.
> With a bit of previous help from this list, I now can get an
> x-axis with
> time tics from 00:00 on the left edge to 12:00 in the middle
> and 00:00 on
> the right edge, i.e., just 24 hours.
>
> Now I would like to fit a sin function to the plot. I've
> looked all over
> CRAN and the web in general, but have not found a method or
> package for
> this.
>
> Can anyone make a suggestion?
>
> Thanks,
>
> =Randy=
>
>
> Using R 2.4.0 on Solaris (unix).
>
>
> R. Zelick				email: zelickr at pdx.edu
> Department of Biology			voice: 503-725-3086
> Portland State University		fax:   503-725-3888
>
> mailing:
> P.O. Box 751
> Portland, OR 97207
>
> shipping:
> 1719 SW 10th Ave, Room 246
> Portland, OR 97201
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jfox at mcmaster.ca  Tue Dec 19 22:13:16 2006
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 19 Dec 2006 16:13:16 -0500
Subject: [R] effect plot
In-Reply-To: <7CFFC9251C01BD48A07D2DBDA8488E1E0387DEF7@EXCHSRVR02.int.milano>
Message-ID: <20061219211315.ZEJT8030.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear Ambrogi,


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Ambrogi Federico
> Sent: Tuesday, December 19, 2006 12:03 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] effect plot
> 
> Dear R users,
> 
> Is there a simple way to use the effect function 
> (library(effects)) with a GEE estimated model?

Not that I'm aware. 

Sorry,
 John

> 
>  
> 
> library(gee)
> 
> library(MASS)
> 
> library(effects)
> 
> attach(epil)
> 
>  
> 
> b = gee(y ~ lbase*trt + lage + V4, family=poisson, id=subject,
> corstr="exchangeable")
> 
>  
> 
> plot(effect("lbase*trt", b))
> 
> # Errore in effect("lbase*trt", b) : nessun metodo 
> applicabile per "effect"
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Tue Dec 19 23:33:49 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 19 Dec 2006 22:33:49 +0000 (GMT)
Subject: [R] xaxt="n" for image()
In-Reply-To: <458809D6.3050501@ija.csic.es>
References: <458809D6.3050501@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0612192231230.15148@gannet.stats.ox.ac.uk>

As the footer says,

PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

> example(image)
> image(x, y, volcano, col = terrain.colors(100), xaxt="n")

works as is should, and we have no way to reproduce what _you_ did.

On Tue, 19 Dec 2006, javier garcia-pintado wrote:

> The argument xaxt="n" for removing the x axis from a image plot does not
> work for me.
> I'm really using a function called plot.grassmeta() in library GRASS
> that is a wrapper for image(), but it seems to me that the problem is
> not in plot.grassmeta() but in image().
>
> If I'm right could you tell me if there is a way to remove one axis from
> a call to image()?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Dec 19 23:38:18 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 19 Dec 2006 22:38:18 +0000 (GMT)
Subject: [R] configure help
In-Reply-To: <20061219155247.68050.qmail@web37910.mail.mud.yahoo.com>
References: <20061219155247.68050.qmail@web37910.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0612192234480.15148@gannet.stats.ox.ac.uk>

This is the wrong list for ESS questions, as both the FAQ and rw-FAQ point 
out.

However, if you read ?Startup you will see that Rprofile.site is not 
necessarily read on startup (and this is why I gave a more careful answer 
to Fridolin, for his instructions are not generic).


On Tue, 19 Dec 2006, ahmad ajakh wrote:

> Hi All,
>
> I ma running R under windows with xemacs and ESS.
> The Rprofile.site options, somehow gets overridden by xemacs and my options
> in Rprofile.site are not taken into account while they are when I use Rgui.
> How can I specify my options if I am using xemacs? and what configuration file
> xemacs+ess use for R.
> Thanks
> AA
>
> ----- Original Message ----
> From: Brian Ripley <ripley at stats.ox.ac.uk>
> To: Fridolin Wild <fridolin.wild at wu-wien.ac.at>
> Cc: r-help at stat.math.ethz.ch
> Sent: Tuesday, December 19, 2006 7:15:11 AM
> Subject: Re: [R] configure help
>
> On Tue, 19 Dec 2006, Fridolin Wild wrote:
>
>>
>> Hello,
>>
>> as I just spent a (too long) while searching
>> for a way how to persistantly switch back the help display
>> routines from chm to text, here a small documentation
>> how to do that with the windows version of R.
>>
>> The windows installer asks which help type
>> you want to use, I wanted to test the chm
>> version -- which I didn't like.
>>
>> If you after installation want to switch back,
>> you have to edit
>>
>>    << myRdirectory\etc\Rprofile.site >>
>>
>> and change the line
>>
>>    options(chmhelp=TRUE)
>>
>> back to
>>
>>    options(chmhelp=FALSE)
>>
>> It would be nice if -- in a future release -- this
>> also could be changed in the GUI settings.
>
> But it has nothing to do with the GUI preferences: it applies to the
> command-line version of R as well.
>
> What about ?help did you not understand? It says
>
>           chmhelp = getOption("chmhelp"),
>           ...
>  chmhelp: logical (or 'NULL'). Only relevant under Windows. If 'TRUE'
>           the Compiled HTML version of the help on the topic will be
>           shown in a help viewer.
>
> so you need to set options(chmhelp=FALSE): it is up to you where you set
> it.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From semafory at wp.pl  Wed Dec 20 00:01:13 2006
From: semafory at wp.pl (Marcin Jaworski)
Date: Wed, 20 Dec 2006 00:01:13 +0100
Subject: [R] attach and object masking
In-Reply-To: <45b34b460871.46087145b34b@osu.edu>
References: <45b34b460871.46087145b34b@osu.edu>
Message-ID: <20061219230113.269883970@smtp.wp.pl>

DEEPANKAR BASU <basu.15 at osu.edu> wrote:

>Hi R users!
>
>I am new to R. When I try to attach a simple dataset using the attach()
>command, I get the following message:
>
>> attach(data1)
>
>        The following object(s) are masked from package:base :
>
>         write
>
>Can someone tell me what this means? (`write' is the name of a variable
>in the dataset). And, do I need to do do something about this.

Hi,
I guess, you need not to do anything, unless you want to work with the 
variable 'write' from dataset you try to attach. But if you do want use
it safely (?), one way is to rename the variable from your dataset, not
to double the name from the package that is already attached (check 
out search() to know the pecking order ;) and use ?attach to interprete 
the help page for yourself). The package gdata make the renaming process
easier for me.

MJ


From basu.15 at osu.edu  Tue Dec 19 23:59:27 2006
From: basu.15 at osu.edu (DEEPANKAR BASU)
Date: Tue, 19 Dec 2006 17:59:27 -0500
Subject: [R] Upgrading
Message-ID: <4aefc14ab4a8.4ab4a84aefc1@osu.edu>

Hi!

As per Thomas' advice, I upgraded R by using "update.packages()" and got the following warning messages:

Warning messages:
1: installation of package 'lmtest' had non-zero exit status in: install.packages(update[, "Package"], instlib, contriburl = contriburl,
2: installation of package 'quadprog' had non-zero exit status in: install.packages(update[, "Package"], instlib, contriburl = contriburl,
3: installation of package 'cluster' had non-zero exit status in: install.packages(update[, "Package"], instlib, contriburl = contriburl,
4: installation of package 'tseries' had non-zero exit status in: install.packages(update[, "Package"], instlib, contriburl = contriburl,

Do I need to worry about these messages? Do I need to do something else to complete the upgrade process?

Another question: what is the command for renaming an existing variable?

Thanks.
Deepankar


From larsfromspace at web.de  Wed Dec 20 00:07:54 2006
From: larsfromspace at web.de (downunder)
Date: Tue, 19 Dec 2006 15:07:54 -0800 (PST)
Subject: [R] Replacing values
In-Reply-To: <1166475345.4771.70.camel@localhost.localdomain>
References: <7934402.post@talk.nabble.com>
	<1166475345.4771.70.camel@localhost.localdomain>
Message-ID: <7956809.post@talk.nabble.com>


Hi Marc,


thanks a lot. Your hint wiht logical conditions helped me already. Problem
is I am working with SAS beside of R. In SAS the import of data and data
manipulation is not that easy, thats why I try to code the data in the right
format. So Thanks a lot for your hints. greetings lars 

-- 
View this message in context: http://www.nabble.com/-R--Replacing-values-tf2841687.html#a7956809
Sent from the R help mailing list archive at Nabble.com.


From tlumley at u.washington.edu  Wed Dec 20 00:20:18 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 19 Dec 2006 15:20:18 -0800 (PST)
Subject: [R] Upgrading
In-Reply-To: <4aefc14ab4a8.4ab4a84aefc1@osu.edu>
References: <4aefc14ab4a8.4ab4a84aefc1@osu.edu>
Message-ID: <Pine.LNX.4.64.0612191518420.29263@homer24.u.washington.edu>

On Tue, 19 Dec 2006, DEEPANKAR BASU wrote:

> Hi!
>
> As per Thomas' advice, I upgraded R by using "update.packages()" and got 
> the following warning messages:

That was not my advice on how to upgrade. update.packages() updates the 
packages. You need to download a new version of R itself.  You will then 
need to update or reinstall the packages. The warning messages are because 
you are updating to versions of the packages that do not run on your old 
version of R.

 	-thomas



> Warning messages:
> 1: installation of package 'lmtest' had non-zero exit status in: install.packages(update[, "Package"], instlib, contriburl = contriburl,
> 2: installation of package 'quadprog' had non-zero exit status in: install.packages(update[, "Package"], instlib, contriburl = contriburl,
> 3: installation of package 'cluster' had non-zero exit status in: install.packages(update[, "Package"], instlib, contriburl = contriburl,
> 4: installation of package 'tseries' had non-zero exit status in: install.packages(update[, "Package"], instlib, contriburl = contriburl,
>
> Do I need to worry about these messages? Do I need to do something else to complete the upgrade process?
>
> Another question: what is the command for renaming an existing variable?
>
> Thanks.
> Deepankar
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From larsfromspace at web.de  Wed Dec 20 00:58:45 2006
From: larsfromspace at web.de (downunder)
Date: Tue, 19 Dec 2006 15:58:45 -0800 (PST)
Subject: [R] Replacing values
In-Reply-To: <841497.56438.qm@web32807.mail.mud.yahoo.com>
References: <7934402.post@talk.nabble.com>
	<841497.56438.qm@web32807.mail.mud.yahoo.com>
Message-ID: <7967398.post@talk.nabble.com>


Hi John,

your example works also fine. Thats what I am looking for. Thanks so far.
Greetings lars



-- 
View this message in context: http://www.nabble.com/-R--Replacing-values-tf2841687.html#a7967398
Sent from the R help mailing list archive at Nabble.com.


From aajakh at yahoo.com  Wed Dec 20 01:26:10 2006
From: aajakh at yahoo.com (ahmad ajakh)
Date: Tue, 19 Dec 2006 16:26:10 -0800 (PST)
Subject: [R] configure help
Message-ID: <20061220002610.61566.qmail@web37911.mail.mud.yahoo.com>

Thanks Prof. Ripley

Your point about the ESS list is well taken. I did read the "initialization at the start of  an R session" but could not figure out
why some of the options are ignored in the Rprofile.site. But I found out that theses options are re-defined in init.el file in .xemacs directory
which seems obvious now to me. 

Thanks again for your help.
AA.

----- Original Message ----
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
To: ahmad ajakh <aajakh at yahoo.com>
Cc: Fridolin Wild <fridolin.wild at wu-wien.ac.at>; r-help at stat.math.ethz.ch
Sent: Tuesday, December 19, 2006 5:38:18 PM
Subject: Re: [R] configure help

This is the wrong list for ESS questions, as both the FAQ and rw-FAQ point 
out.

However, if you read ?Startup you will see that Rprofile.site is not 
necessarily read on startup (and this is why I gave a more careful answer 
to Fridolin, for his instructions are not generic).


On Tue, 19 Dec 2006, ahmad ajakh wrote:

> Hi All,
>
> I ma running R under windows with xemacs and ESS.
> The Rprofile.site options, somehow gets overridden by xemacs and my options
> in Rprofile.site are not taken into account while they are when I use Rgui.
> How can I specify my options if I am using xemacs? and what configuration file
> xemacs+ess use for R.
> Thanks
> AA
>
> ----- Original Message ----
> From: Brian Ripley <ripley at stats.ox.ac.uk>
> To: Fridolin Wild <fridolin.wild at wu-wien.ac.at>
> Cc: r-help at stat.math.ethz.ch
> Sent: Tuesday, December 19, 2006 7:15:11 AM
> Subject: Re: [R] configure help
>
> On Tue, 19 Dec 2006, Fridolin Wild wrote:
>
>>
>> Hello,
>>
>> as I just spent a (too long) while searching
>> for a way how to persistantly switch back the help display
>> routines from chm to text, here a small documentation
>> how to do that with the windows version of R.
>>
>> The windows installer asks which help type
>> you want to use, I wanted to test the chm
>> version -- which I didn't like.
>>
>> If you after installation want to switch back,
>> you have to edit
>>
>>    << myRdirectory\etc\Rprofile.site >>
>>
>> and change the line
>>
>>    options(chmhelp=TRUE)
>>
>> back to
>>
>>    options(chmhelp=FALSE)
>>
>> It would be nice if -- in a future release -- this
>> also could be changed in the GUI settings.
>
> But it has nothing to do with the GUI preferences: it applies to the
> command-line version of R as well.
>
> What about ?help did you not understand? It says
>
>           chmhelp = getOption("chmhelp"),
>           ...
>  chmhelp: logical (or 'NULL'). Only relevant under Windows. If 'TRUE'
>           the Compiled HTML version of the help on the topic will be
>           shown in a help viewer.
>
> so you need to set options(chmhelp=FALSE): it is up to you where you set
> it.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From muenchen at utk.edu  Wed Dec 20 02:06:29 2006
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Tue, 19 Dec 2006 20:06:29 -0500
Subject: [R] Switching labels on a factor
In-Reply-To: <4586CA26.5060505@buffalo.edu>
Message-ID: <7270AEC73132194E8BC0EE06B35D93D84F2BCD@UTKFSVS3.utk.tennessee.edu>

Chris,

Argh!!! I was writing a reply just now insisting that the output below
makes no sense when it finally hit me: the first line of output from the
unclass function is just the data and bears no relationship whatsoever
with the order of the "m" and "f" below it. I had gotten the idea that
it picked up on the first value and so displayed the label to match. I
don't even want to think about how much time I spent working on a
"problem" that was nonexistent!

Thank you very much for your help!

Bob

> unclass(mydata$gR)
[1] 2 2 2 2 1 1 1 1
attr(,"levels")
[1] "m" "f"


=========================================================
Bob Muenchen (pronounced Min'-chen), Manager 
Statistical Consulting Center
U of TN Office of Information Technology
200 Stokely Management Center, Knoxville, TN 37996-0520
Voice: (865) 974-5230 
FAX: (865) 974-4810
Email: muenchen at utk.edu
Web: http://oit.utk.edu/scc, 
News: http://listserv.utk.edu/archives/statnews.html
=========================================================


-----Original Message-----
From: Chris Andrews [mailto:candrews at buffalo.edu] 
Sent: Monday, December 18, 2006 12:05 PM
To: Muenchen, Robert A (Bob)
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Switching labels on a factor


Bob,

This is I think exactly what one wants to have happen.  The first four
observations are still women.  Both the labels and the underlying
integers should change.  (If you want to give all the people sex
changes, try Relevel in the Epi package.

mydata$afterthechange <- Relevel(mydata$gender, list(m="f", f="m"))
mydata


  workshop gender q1 q2 q3 q4 gR afterthechange
1        1      f  1  1  5  1  f              m
2        2      f  2  1  4  1  f              m
3        1      f  2  2  4  3  f              m
4        2      f  3  1 NA  3  f              m
5        1      m  4  5  2  4  m              f
6        2      m  5  4  5  5  m              f
7        1      m  5  3  4  4  m              f
8        2      m  4  5  5 NA  m              f


unclass(mydata$afterthechange)
[1] 1 1 1 1 2 2 2 2
attr(,"levels")
[1] "m" "f"

Chris


Date: Fri, 15 Dec 2006 15:34:15 -0500
From: "Muenchen, Robert A (Bob)" <muenchen at utk.edu>
Subject: [R] Switching labels on a factor
To: <R-help at stat.math.ethz.ch>
Message-ID:
	
<7270AEC73132194E8BC0EE06B35D93D84A061C at UTKFSVS3.utk.tennessee.edu>
Content-Type: text/plain;	charset="US-ASCII"

Hi All,

I'm perplexed by the way the unclass function displays a factor whose
labels have been swapped with the relevel function. I realize it won't
affect any results and that the relevel did nothing useful in this
particular case. I'm just doing it to learn ways to manipulate factors.
The display of unclass leaves me feeling that the relevel had failed.

I've checked three books & searched R-help, but found no mention of this
particular issue.  

The program below demonstrates the problem. Is this a bug, or is there a
reason for it to work this way?

Thanks,
Bob

mystring<-
("id,workshop,gender,q1,q2,q3,q4
 1,1,f,1,1,5,1
 2,2,f,2,1,4,1
 3,1,f,2,2,4,3
 4,2,f,3,1, ,3
 5,1,m,4,5,2,4
 6,2,m,5,4,5,5
 7,1,m,5,3,4,4
 8,2,m,4,5,5,9")
mydata<-read.table(textConnection(mystring),
   header=TRUE,sep=",",row.names="id",na.strings="9")
mydata

# Create a gender Releveled variable, gR. 
# Now 1=m, 2=f
mydata$gR <- relevel(mydata$gender, "m")

# Print the data to show that the labels of gR match those of gender.
mydata

# Show that the underlying codes have indeed reversed.
as.numeric(mydata$gender)
as.numeric(mydata$gR)

# Unclass the two variables to see that print order 
# implies that both the codes and labels have
# flipped, cancelling each other out. For gR,
# m appears to be associated with 2, and f with 1
unclass(mydata$gender)
unclass(mydata$gR)

=========================================================
  Bob Muenchen (pronounced Min'-chen), Manager  
  Statistical Consulting Center
  U of TN Office of Information Technology
  200 Stokely Management Center, Knoxville, TN 37996-0520
  Voice: (865) 974-5230  
  FAX:   (865) 974-4810
  Email: muenchen at utk.edu
  Web:   http://oit.utk.edu/scc, 
  News:  http://listserv.utk.edu/archives/statnews.html




-- 
Christopher Andrews, PhD
SUNY Buffalo, Department of Biostatistics
242 Farber Hall, candrews at buffalo.edu, 716 829 2756


From liujcheng at gmail.com  Wed Dec 20 02:58:44 2006
From: liujcheng at gmail.com (liu, jcheng)
Date: Wed, 20 Dec 2006 09:58:44 +0800
Subject: [R] how to do muliple comparisons in linear mixed models
Message-ID: <32f489f80612191758j305383b4sc3cc8c1b31cc481b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061220/4642228c/attachment.pl 

From aiminy at iastate.edu  Wed Dec 20 03:52:34 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Tue, 19 Dec 2006 20:52:34 -0600
Subject: [R] R.matlab question
Message-ID: <6.1.2.0.2.20061219204859.01c24408@aiminy.mail.iastate.edu>

Does anyone know how to solve this question about R.matlab?
I am in windowsXP, my matlab is matlab 7.0.0 19920(R14)

thanks,

Aimin

 > matlab <- Matlab(host="localhost", port=9998)
 > if (!open(matlab)) throw("Matlab server is not running: waited 30 seconds.")
Error in list("throw("Matlab server is not running: waited 30 seconds.")" = 
<environment>,  :

[2006-12-17 22:26:03] Exception: Matlab server is not running: waited 30 
seconds.
   at throw(Exception(...))
   at throw.default("Matlab server is not running: waited 30 seconds.")
   at throw("Matlab server is not running: waited 30 seconds.")
In addition: There were 30 warnings (use warnings() to see them)
 > warnings
function (...)
UseMethod("warnings")
 > warnings()
Warning messages:
1: localhost:9998 cannot be opened
2: localhost:9998 cannot be opened
3: localhost:9998 cannot be opened
4: localhost:9998 cannot be opened
5: localhost:9998 cannot be opened
6: localhost:9998 cannot be opened
7: localhost:9998 cannot be opened
8: localhost:9998 cannot be opened
9: localhost:9998 cannot be opened
10: localhost:9998 cannot be opened
11: localhost:9998 cannot be opened
12: localhost:9998 cannot be opened
13: localhost:9998 cannot be opened
14: localhost:9998 cannot be opened
15: localhost:9998 cannot be opened
16: localhost:9998 cannot be opened
17: localhost:9998 cannot be opened
18: localhost:9998 cannot be opened
19: localhost:9998 cannot be opened
20: localhost:9998 cannot be opened
21: localhost:9998 cannot be opened
22: localhost:9998 cannot be opened
23: localhost:9998 cannot be opened
24: localhost:9998 cannot be opened
25: localhost:9998 cannot be opened
26: localhost:9998 cannot be opened
27: localhost:9998 cannot be opened
28: localhost:9998 cannot be opened
29: localhost:9998 cannot be opened
30: localhost:9998 cannot be opened
 >


From asaithambi at ntu.edu.sg  Wed Dec 20 06:37:15 2006
From: asaithambi at ntu.edu.sg (Kesavan Asaithambi)
Date: Wed, 20 Dec 2006 13:37:15 +0800
Subject: [R] biocondutor installation problem
Message-ID: <7CD06E15ADF4104A9F2E4DC2DE678F89044482B3@EXCHANGE21.staff.main.ntu.edu.sg>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061220/b60393af/attachment.pl 

From biterbilen at yahoo.com  Wed Dec 20 08:37:58 2006
From: biterbilen at yahoo.com (biter bilen)
Date: Tue, 19 Dec 2006 23:37:58 -0800 (PST)
Subject: [R] call by reference
Message-ID: <20061220073758.69355.qmail@web52314.mail.yahoo.com>

Can anyone help me about pass by reference of arguments in R functions? 

I have read about .Alias in base package however it is defunct and there is no replacement for it. 

Thanks in advance.


From ripley at stats.ox.ac.uk  Wed Dec 20 10:04:08 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 20 Dec 2006 09:04:08 +0000 (GMT)
Subject: [R] call by reference
In-Reply-To: <20061220073758.69355.qmail@web52314.mail.yahoo.com>
References: <20061220073758.69355.qmail@web52314.mail.yahoo.com>
Message-ID: <Pine.LNX.4.64.0612200856480.11752@gannet.stats.ox.ac.uk>

Can you tell us what you want to do with 'pass/call by reference'?

If you want an R function to alter its argument then it is possible 
(KalmanLike is an example), but it should only be possible via C code.
And if you know enough to do that, you probably would not be asking (and 
definitely not be asking on R-help rather than R-devel).

On Tue, 19 Dec 2006, biter bilen wrote:

> Can anyone help me about pass by reference of arguments in R functions?
>
> I have read about .Alias in base package however it is defunct and there 
> is no replacement for it.

That's not a fair summary of the help entry for .Alias.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From guillet at stat.ucl.ac.be  Wed Dec 20 10:11:25 2006
From: guillet at stat.ucl.ac.be (guillet at stat.ucl.ac.be)
Date: Wed, 20 Dec 2006 10:11:25 +0100 (CET)
Subject: [R] call by reference
In-Reply-To: <Pine.LNX.4.64.0612200856480.11752@gannet.stats.ox.ac.uk>
References: <20061220073758.69355.qmail@web52314.mail.yahoo.com>
	<Pine.LNX.4.64.0612200856480.11752@gannet.stats.ox.ac.uk>
Message-ID: <1707.88.123.88.127.1166605885.squirrel@stat2ux.stat.ucl.ac.be>

> Can you tell us what you want to do with 'pass/call by reference'?
>
> If you want an R function to alter its argument then it is possible
> (KalmanLike is an example), but it should only be possible via C code.
> And if you know enough to do that, you probably would not be asking (and
> definitely not be asking on R-help rather than R-devel).
>
> On Tue, 19 Dec 2006, biter bilen wrote:
>
>> Can anyone help me about pass by reference of arguments in R functions?
>>
>> I have read about .Alias in base package however it is defunct and there
>> is no replacement for it.
>
> That's not a fair summary of the help entry for .Alias.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr.pikal at precheza.cz  Wed Dec 20 10:47:44 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 20 Dec 2006 10:47:44 +0100
Subject: [R] Upgrading
In-Reply-To: <Pine.LNX.4.64.0612191518420.29263@homer24.u.washington.edu>
References: <4aefc14ab4a8.4ab4a84aefc1@osu.edu>
Message-ID: <458914D0.25260.A66B26@localhost>

Hi

as the addition to Thomas's answer.

On 19 Dec 2006 at 15:20, Thomas Lumley wrote:

Date sent:      	Tue, 19 Dec 2006 15:20:18 -0800 (PST)
From:           	Thomas Lumley <tlumley at u.washington.edu>
To:             	DEEPANKAR BASU <basu.15 at osu.edu>
Copies to:      	R-help at stat.math.ethz.ch
Subject:        	Re: [R] Upgrading

> On Tue, 19 Dec 2006, DEEPANKAR BASU wrote:
> 
> > Hi!
> >
> > As per Thomas' advice, I upgraded R by using "update.packages()" and
> > got the following warning messages:
> 
> That was not my advice on how to upgrade. update.packages() updates
> the packages. You need to download a new version of R itself.  You
> will then need to update or reinstall the packages. The warning
> messages are because you are updating to versions of the packages that
> do not run on your old version of R.

<snip>

> >
> > Another question: what is the command for renaming an existing
> > variable?

e.g. if the variable is in data frame

names(your.data)[position.of.old.column.name] <- "new.column.name"
BTW, reading et least some docummentation could help you a lot with 
these issues.

HTH
Petr


> >
> > Thanks.
> > Deepankar
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html and provide commented,
> > minimal, self-contained, reproducible code.
> >
> 
> Thomas Lumley			Assoc. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington, Seattle
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

Petr Pikal
petr.pikal at precheza.cz


From mark_difford at yahoo.co.uk  Wed Dec 20 11:17:56 2006
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Wed, 20 Dec 2006 10:17:56 +0000 (GMT)
Subject: [R] RuleFit & quantreg: partial dependence plots;
	showing an effect
Message-ID: <20061220101756.806.qmail@web27310.mail.ukl.yahoo.com>

Dear List,

I would greatly appreciate help on the following matter:

The RuleFit program of Professor Friedman uses partial dependence plots
to explore the effect of an explanatory variable on the response
variable, after accounting for the average effects of the other
variables.  The plot method [plot(summary(rq(y ~ x1 + x2,
t=seq(.1,.9,.05))))] of Professor Koenker's quantreg program appears to
do the same thing.


Question:
Is there a difference between these two types of plot in the manner in which they depict the relationship between explanatory variables and the response variable ?

Thank you inav for your help.

Regards,
Mark Difford.

------------------------------------------------------------- 
Mark Difford
Ph.D. candidate, Botany Department,
Nelson Mandela Metropolitan University,
Port Elizabeth, SA.


From kalyansikha at yahoo.com  Wed Dec 20 11:39:38 2006
From: kalyansikha at yahoo.com (Bhanu Kalyan.K)
Date: Wed, 20 Dec 2006 02:39:38 -0800 (PST)
Subject: [R] Query regarding linking R with Matlab
Message-ID: <20061220103938.27823.qmail@web34307.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061220/3f780896/attachment.pl 

From hb at stat.berkeley.edu  Wed Dec 20 11:45:57 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 20 Dec 2006 21:45:57 +1100
Subject: [R] R.matlab question
In-Reply-To: <6.1.2.0.2.20061219204859.01c24408@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061219204859.01c24408@aiminy.mail.iastate.edu>
Message-ID: <59d7961d0612200245o42ceaaf2ka0c69f34d91aa6f0@mail.gmail.com>

Hi.

On 12/20/06, Aimin Yan <aiminy at iastate.edu> wrote:
> Does anyone know how to solve this question about R.matlab?
> I am in windowsXP, my matlab is matlab 7.0.0 19920(R14)
>
> thanks,
>
> Aimin
>
>  > matlab <- Matlab(host="localhost", port=9998)
>  > if (!open(matlab)) throw("Matlab server is not running: waited 30 seconds.")
> Error in list("throw("Matlab server is not running: waited 30 seconds.")" =
> <environment>,  :
>
> [2006-12-17 22:26:03] Exception: Matlab server is not running: waited 30
> seconds.
>    at throw(Exception(...))
>    at throw.default("Matlab server is not running: waited 30 seconds.")
>    at throw("Matlab server is not running: waited 30 seconds.")
> In addition: There were 30 warnings (use warnings() to see them)
>  > warnings
> function (...)
> UseMethod("warnings")
>  > warnings()
> Warning messages:
> 1: localhost:9998 cannot be opened
> 2: localhost:9998 cannot be opened
[snip]
> 30: localhost:9998 cannot be opened

This could be because your firewall is blocking R from connecting
to Matlab.  Try a few different port numbers.  I recently learned that
the current default port in R.matlab might not be the best one;
different port intervals are reserved for different purposes, cf.
http://www.iana.org/assignments/port-numbers.  That document indicates
that a port number in [49152, 65535] might be better.  See if this
helps.  Does someone else knowof a port interval that is more likely
to work in general?

You can also tell the Matlab object to report more details what it is
trying to do by setting the verbosity threshold, i.e.
setVerbose(matlab, threshold=-1); the lower the threshold the more
details you'll see.

Cheers

Henrik

>  >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From b.otto at uke.uni-hamburg.de  Wed Dec 20 11:55:11 2006
From: b.otto at uke.uni-hamburg.de (Benjamin Otto)
Date: Wed, 20 Dec 2006 11:55:11 +0100
Subject: [R] Rotating a distribution plot by 90 degrees
Message-ID: <000001c72425$54c5fd80$336f12ac@matrix.com>

Hi,

Can I rotate a plot (e.g. a distribution plot) by 90 degrees? The barplot
function provides the "horiz" command but that's not availeable for the base
package functions. I found an old advice from Paul Murrell on a similar
problem suggesting to use viewports (grid package). Yet I couldn't reproduce
his examples successfully. And going through the examples in the current
grid package help pages left me with the feeling that viewport and the
plot/points function don't match because the latter automatically clears the
old device.

Is there some way to rotate a "plot" at all or am I forced to use the
barplot function instead?

Regards,

Benjamin


P.S.: For further explanation: I would like to plot something like

+-----+-----+
|     |     |
|  0  |  1  |
|     |     |
+-----+-----+
|     |     |
|  2  |  3  |
|     |     |
+-----+-----+

where image 1 is some function plot in normal mode, image 2 is a function
plot rotated by 90 degrees and image 3 is something depending on the two
functions.


-- 
Benjamin Otto
Universitaetsklinikum Eppendorf Hamburg
Institut fuer Klinische Chemie
Martinistrasse 52
20246 Hamburg


From hb at stat.berkeley.edu  Wed Dec 20 12:00:16 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 20 Dec 2006 22:00:16 +1100
Subject: [R] Query regarding linking R with Matlab
In-Reply-To: <20061220103938.27823.qmail@web34307.mail.mud.yahoo.com>
References: <20061220103938.27823.qmail@web34307.mail.mud.yahoo.com>
Message-ID: <59d7961d0612200300o547b95dfw94220e251a2603a5@mail.gmail.com>

Hi.

On 12/20/06, Bhanu Kalyan.K <kalyansikha at yahoo.com> wrote:
>
> Sir,
>
> I am still new to the R-matlab interfacing. I will explain you the problem statement more clearly.
>
> The following is a matlab code. (swissroll.m)
>  =========================================================
>
> % SWISS ROLL DATASET
>
>   N=2000;
>   K=12;
>   d=2;
>
> clf; colordef none; colormap jet; set(gcf,'Position',[200,400,620,200]);
>
> % PLOT TRUE MANIFOLD
>   tt0 = (3*pi/2)*(1+2*[0:0.02:1]); hh = [0:0.125:1]*30;
>   xx = (tt0.*cos(tt0))'*ones(size(hh));
>   yy = ones(size(tt0))'*hh;
>   zz = (tt0.*sin(tt0))'*ones(size(hh));
>   cc = tt0'*ones(size(hh));
>
>   subplot(1,3,1); cla;
>   surf(xx,yy,zz,cc);
>   view([12 20]); grid off; axis off; hold on;
>   lnx=-5*[3,3,3;3,-4,3]; lny=[0,0,0;32,0,0]; lnz=-5*[3,3,3;3,3,-3];
>   lnh=line(lnx,lny,lnz);
>   set(lnh,'Color',[1,1,1],'LineWidth',2,'LineStyle','-','Clipping','off');
>    axis([-15,20,0,32,-15,15]);
>
> % GENERATE SAMPLED DATA
>   tt = (3*pi/2)*(1+2*rand(1,N));  height = 21*rand(1,N);
>   X = [tt.*cos(tt); height; tt.*sin(tt)];
>
> % SCATTERPLOT OF SAMPLED DATA
>   subplot(1,3,2); cla;
>   scatter3(X(1,:),X(2,:),X(3,:),12,tt,'+');
>   view([12 20]); grid off; axis off; hold on;
>   lnh=line(lnx,lny,lnz);
>   set(lnh,'Color',[1,1,1],'LineWidth',2,'LineStyle','-','Clipping','off');
>   axis([-15,20,0,32,-15,15]); drawnow;
>
> % RUN LLE ALGORITHM
> Y=lle(X,K,d);
>
> % SCATTERPLOT OF EMBEDDING
>   subplot(1,3,3); cla;
>   scatter(Y(1,:),Y(2,:),12,tt,'+');
>   grid off;
>   set(gca,'XTick',[]); set(gca,'YTick',[]);
>
> ===========================================================
>
> I must write a program in R, which will call this swissroll.m file. The output (of swissroll.m) must be shown in R interface and not in matlab . Is it possible?  How  can i do it? Kindly bear with me as i am not very comfortable with R. Though i have read your help(Matlab) and the examples, i did not find any clear documentation regarding calling an external file in R. Please help me on this.

The R.matlab package basically allows you to *evaluate* Matlab code
sent from R as text strings.  In addition you can transfer *data
structures* between R and Matlab (in both directions).  So, instead of
running Matlab in one window and R in another, typing some commands in
Matlab, saving data to file, moving over to R and load that data file
into R etc, the R.matlab package allows you to do all that from within
R.  That is the main idea behind R.matlab.  Thus, you cannot generate
graphs in Matlab and magically expect them to be transferred to R.
However, like when you run Matlab "by hand" you can save graphs to
file, e.g. PNG or EPS files.  The R.matlab interface allows you to
tell Matlab to do that from within R.

To run (=evaluate) your 'swissroll.m' Matlab script from R

matlab <- Matlab(host="localhost", port=9998)
if (!open(matlab))
  throw("Matlab server is not running: waited 30 seconds.")
res <- evaluate(matlab, "swissroll")

This will then open *Matlab* windows displaying the figures.

You can import the Matlab variables of interest to R by:

vars <- getVariable(matlab, c("Y", "X", "K", "d"))

...and the work with the variables in R instead, e.g. Y <- vars$Y.

Hope this helps

Henrik

>
> regards,
> Bhanu Kalyan K
>
>
>
> Bhanu Kalyan K
>   BTech CSE Final Year
>   reach4kalyan at gmail.com
>   Tel :+91-9885238228
>
>  __________________________________________________
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From shubhak at ambaresearch.com  Wed Dec 20 12:03:51 2006
From: shubhak at ambaresearch.com (Shubha Vishwanath Karanth)
Date: Wed, 20 Dec 2006 16:33:51 +0530
Subject: [R] FW: R Version Problem in using write.foreign+SAS
Message-ID: <A36876D3F8A5734FA84A4338135E7CC3B3E0A7@BAN-MAILSRV03.Amba.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061220/c44daa78/attachment.pl 

From shubhak at ambaresearch.com  Wed Dec 20 12:33:53 2006
From: shubhak at ambaresearch.com (Shubha Vishwanath Karanth)
Date: Wed, 20 Dec 2006 17:03:53 +0530
Subject: [R] Where to find the code in the foreign library?
Message-ID: <A36876D3F8A5734FA84A4338135E7CC3B3E0C4@BAN-MAILSRV03.Amba.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061220/aa1e3923/attachment.pl 

From shubhakaranth at gmail.com  Wed Dec 20 12:38:04 2006
From: shubhakaranth at gmail.com (Shubha Karanth)
Date: Wed, 20 Dec 2006 17:08:04 +0530
Subject: [R] Fwd: Where to find the code in the foreign library?
In-Reply-To: <A36876D3F8A5734FA84A4338135E7CC3B3E0C4@BAN-MAILSRV03.Amba.com>
References: <A36876D3F8A5734FA84A4338135E7CC3B3E0C4@BAN-MAILSRV03.Amba.com>
Message-ID: <67e4ea330612200338g1947cc49j99a497666b5350a2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061220/bec26852/attachment.pl 

From shubhakaranth at gmail.com  Wed Dec 20 12:44:38 2006
From: shubhakaranth at gmail.com (Shubha Karanth)
Date: Wed, 20 Dec 2006 17:14:38 +0530
Subject: [R] R Version Problem in using write.foreign+SAS
In-Reply-To: <A36876D3F8A5734FA84A4338135E7CC3B3E0A2@BAN-MAILSRV03.Amba.com>
References: <A36876D3F8A5734FA84A4338135E7CC3B3E0A2@BAN-MAILSRV03.Amba.com>
Message-ID: <67e4ea330612200344r13ebd637je89a8b2c96bc2f6f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061220/745a4c63/attachment.pl 

From stevenmh at muohio.edu  Wed Dec 20 13:25:02 2006
From: stevenmh at muohio.edu (Martin Henry H. Stevens)
Date: Wed, 20 Dec 2006 07:25:02 -0500
Subject: [R] How to write a two-way interaction as a random effect in a
	lmer model?
In-Reply-To: <1276C0564833F043AB4C85ED8DA9CFE50117C36B@ctemail1.nioo.int>
References: <1276C0564833F043AB4C85ED8DA9CFE50117C36B@ctemail1.nioo.int>
Message-ID: <A04C0FED-01D6-4A49-9066-01B9AA3A8B26@muohio.edu>

Hi Eva,
A couple questions:
Are repeated measurements taken on rnr? Is rnr "subject"?
Is stress a continuous variable?

See below.
On Dec 11, 2006, at 11:04 AM, Fucikova, Eva wrote:

> Dear All,
>
>
>
> I am working with linear mixed-effects models using the lme4  
> package in
> R. I created a model with the lmer function including some main  
> effects,
> a two-way interaction and a random effect. Now I am searching how I
> could incorporate an interaction between the random effect and one of
> the fixed effects.
>
>
>
> I tried to express the interaction in:
>
> recap_random3<-lmer(breath~handling+stress+stress:handling+(1|rnr) 
> +(0|rn
> r:stress))
>

lmer will want rnr:stress to be a factor, but (0|factor) doesn't make  
sense. To test for random variation in slopes, you want (stress |  
rnr), (or (1|rnr) + (0+stress | rnr) for uncorrelated slopes).

> however R gives me the following error message
>
> :
>
> Error in eval(expr, envir, enclos) : fl[[2]] must be a factor of  
> length
> 1744
>
> In addition: Warning messages:
>
> 1: numerical expression has 1744 elements: only the first used in:
> rnr:stress
>
> 2: numerical expression has 1744 elements: only the first used in:
> rnr:stress
>
>
>
> If I fit this model in SPSS, this gives me output, but I don't know
> whether I can trust that.
>
>
>
>
>
> Therefore I went to look for an alternative:
>
> After looking at the help function in R for lmer I deduced these  
> models.
>
>
> Examples from R
>
> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
> (fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject),
> sleepstudy))
> anova(fm1, fm2)
>
>
>
>
>
> My models would then look like this:
>
>
>
> recap_random0<-lmer(breath~handling+stress (1|rnr))
>
> recap_random1<-lmer(breath~handling+stress (1|rnr)+(0+stress|rnr))
>
Or rather with a plus sign
>
> recap_random0<-lmer(breath~handling+stress + (1|rnr))
>
> recap_random1<-lmer(breath~handling+stress + (1|rnr)+(0+stress|rnr))
or

>
> recap_random0<-lmer(breath~handling+stress (stress | rnr))


>
>
> However, I do not know how to interpret the results. Does the model  
> see
> stress|rnr as an interaction between stress and rnr, or did it take
> stress nested in rnr.
>
>
>
>> summary(recap_random1)
>
> Linear mixed-effects model fit by REML
>
> Formula: breath ~ handling + stress + stress:handling + (1 | rnr) +  
> (0 +
> stress | rnr)
>
>   AIC  BIC logLik MLdeviance REMLdeviance
>
>  9748 9781  -4868       9719         9736
>
> Random effects:
>
>  Groups   Name        Variance Std.Dev.
>
>  rnr      (Intercept) 55.6711  7.4613                       # BUT
>
>  rnr      stress      15.2805  3.9090                       # Does  
> this
> output line express the interaction???
>
If the model statement was correct, these would be variances  
associated with the intercepts and slopes of different levels of rnr.  
Thus, I would call that rnr by stress interaction.

Cheers,
Hank
>  Residual              7.4567  2.7307                    # If not, how
> should the interaction output look like?
>
> number of obs: 1744, groups: rnr, 217; rnr, 217
>
>
>
> Fixed effects:
>
>                  Estimate Std. Error t value
>
> (Intercept)     28.164471   0.716359   39.32
>
> handling         0.012477   0.012330    1.01
>
> stress           0.636979   0.416011    1.53
>
>
>
> Correlation of Fixed Effects:
>
>             (Intr) hndlng stress
>
> handling    -0.645
>
> stress      -0.517  0.667
>
>
>
>
>
> Could anybody please give me an advice how to solve this problem?  
> Which
> way is correct to express interaction in the random factors? How  
> should
> the output look like?
>
>
>
> Thank you in advance,
>
> Eva Fucikova
>
>
>
> ********************************************
>
> Msc. Eva Fucikova
> Netherlands Institute of Ecology (NIOO-KNAW)
> PO Box 40
> 6666 ZG Heteren
> The Netherlands
> tel.: +31 (0)26 4791248
> Email:E.Fucikova at nioo.knaw.nl
>
> *******************************************
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



Hank Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"

If you send an attachment, please try to send it in a format anyone  
can read, such as PDF, text, Open Document Format, HTML, or RTF.  
Please try not to send me MS Word or PowerPoint attachments-
Why? See:  http://www.gnu.org/philosophy/no-word-attachments.html


From istoyanov at ecolab.bas.bg  Wed Dec 20 13:31:04 2006
From: istoyanov at ecolab.bas.bg (Ivailo Stoyanov)
Date: Wed, 20 Dec 2006 14:31:04 +0200
Subject: [R] Replacing values
In-Reply-To: <7934402.post@talk.nabble.com>
References: <7934402.post@talk.nabble.com>
Message-ID: <1166617865.15536.3.camel@localhost>

On Mon, 2006-12-18 at 10:58 -0800, downunder wrote:
> Hi all,
> 
> I have to recode some values in a dataset. for example changing all zeros to
> "." or 999 would be also ok. does anybody know how to do this? thanks in
> advance. lars

Lars,

I would perform all such "editing" tasks in a spreadsheet, where I
easily could run a Find & Replace function over the dataset. Then,
export and read.table("the_exported_file.txt") will get the data into R,
where you could continue at wish.

HTH,

Ivailo


From shubhak at ambaresearch.com  Wed Dec 20 13:36:17 2006
From: shubhak at ambaresearch.com (Shubha Vishwanath Karanth)
Date: Wed, 20 Dec 2006 18:06:17 +0530
Subject: [R] R Version Problem in using write.foreign+SAS
Message-ID: <A36876D3F8A5734FA84A4338135E7CC3B3E0FA@BAN-MAILSRV03.Amba.com>

Hi,

If I am using R 2.4.0, and work with write.foreign command, I get the
datetime format as 01Dec2006 00:00:00, because the built in function
(foreign:::writeForeignSAS) has the fixed format for Datetimes and the
format is "%d%b%Y %H:%M:%S". And that's the reason why I get the
datetime as 01Dec2006 00:00:00 instead of 2006-12-01 00:00:00.

So, R users, could I make this code flexible to use any datetime
formats? Also where could I see locate this code in the foreign package
itself?

Thank you,
Shubha.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Shubha Karanth
Sent: 20. joulukuuta 2006 17:15
To: r-help at stat.math.ethz.ch
Subject: [R] R Version Problem in using write.foreign+SAS

Hi experts,



I have a problem in Write.foreign command (SAS).



I have a data frame called d.

>d

 Datetime

2006-12-01 00:00:00

2006-12-01 00:10:00

2006-12-01 00:20:00

2006-12-01 00:30:00

2006-12-01 00:40:00

>class(d$Datetime)

[1] "POSIXt"  "POSIXct"



Then I tried with,



write.foreign(d,"Z:\\try_i.sas7bdat"," Z:\\try_i.sas
",package="SAS",dataname="g")



If I use R 2.4.0 version I get the below text file generated.



"01Dec2006 00:00:00"

"01Dec2006 00:10:00"

"01Dec2006 00:20:00"

"01Dec2006 00:30:00"

"01Dec2006 00:40:00"





If I use R 2.2.0 version I get the below text file generated.



2006-12-01 00:00:00

2006-12-01 00:10:00

2006-12-01 00:20:00

2006-12-01 00:30:00

2006-12-01 00:40:00





But I need to use R 2.4.0 and get the text file generated by R 2.2.0.





Could somebody help me on this?



Thank you.

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From christian.hoffmann at wsl.ch  Wed Dec 20 14:40:43 2006
From: christian.hoffmann at wsl.ch (Christian Hoffmann)
Date: Wed, 20 Dec 2006 14:40:43 +0100
Subject: [R] DBI + ROracle problem with parser ??
Message-ID: <45893D5B.6010804@wsl.ch>

Hi,

Database queries using the combination DBI + ROracle are handicapped by
quirks in the pipeline between the textual representation of the query
and the database engine Oracle.

dbGetQuery(conn, query):

work:
dbGetQuery(conn, "select * from dual")
dbGetQuery(conn, "select * from dual /* comment */")
dbGetQuery(conn, "select /* comment */ * from dual")

don't:
dbGetQuery(conn, "\nselect * from dual")
dbGetQuery(conn, "select\n * from dual")
dbGetQuery(conn, "/* comment */ select * from dual")

best
ch

-- 
Dr. Christian W. Hoffmann,
Swiss Federal Research Institute WSL
Zuercherstrasse 111, CH-8903 Birmensdorf, Switzerland
Tel +41-44-7392-277 (office), -111(exchange), -215  (fax)
christian.hoffmann at wsl.ch,  www.wsl.ch/staff/christian.hoffmann


From rkoenker at uiuc.edu  Wed Dec 20 14:57:02 2006
From: rkoenker at uiuc.edu (roger koenker)
Date: Wed, 20 Dec 2006 07:57:02 -0600
Subject: [R] RuleFit & quantreg: partial dependence plots;
	showing an effect
In-Reply-To: <20061220101756.806.qmail@web27310.mail.ukl.yahoo.com>
References: <20061220101756.806.qmail@web27310.mail.ukl.yahoo.com>
Message-ID: <9AC6425F-84C3-422C-AB72-CC4ED6CE04D3@uiuc.edu>

They are entirely different:  Rulefit is a fiendishly clever  
combination of decision tree  formulation
of models and L1-regularization intended to select parsimonious fits  
to very complicated
responses yielding e.g. piecewise constant functions.  Rulefit   
estimates the  conditional
mean of the response over the covariate space, but permits a very  
flexible, but linear in
parameters specifications of the covariate effects on the conditional  
mean.  The quantile
regression plotting you refer to adopts a fixed, linear specification  
for conditional quantile
functions and given that specification depicts how the covariates  
influence the various
conditional quantiles of the response.   Thus, roughly speaking,  
Rulefit is focused on
flexibility in the x-space, maintaining the classical conditional  
mean objective; while
QR is trying to be more flexible in the y-direction, and maintaining  
a fixed, linear
in parameters specification for the covariate effects at each quantile.


url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Champaign, IL 61820


On Dec 20, 2006, at 4:17 AM, Mark Difford wrote:

> Dear List,
>
> I would greatly appreciate help on the following matter:
>
> The RuleFit program of Professor Friedman uses partial dependence  
> plots
> to explore the effect of an explanatory variable on the response
> variable, after accounting for the average effects of the other
> variables.  The plot method [plot(summary(rq(y ~ x1 + x2,
> t=seq(.1,.9,.05))))] of Professor Koenker's quantreg program  
> appears to
> do the same thing.
>
>
> Question:
> Is there a difference between these two types of plot in the manner  
> in which they depict the relationship between explanatory variables  
> and the response variable ?
>
> Thank you inav for your help.
>
> Regards,
> Mark Difford.
>
> -------------------------------------------------------------
> Mark Difford
> Ph.D. candidate, Botany Department,
> Nelson Mandela Metropolitan University,
> Port Elizabeth, SA.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rvaradhan at jhmi.edu  Wed Dec 20 15:43:18 2006
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Wed, 20 Dec 2006 09:43:18 -0500
Subject: [R] RuleFit & quantreg: partial dependence plots;
	showing an effect
In-Reply-To: <9AC6425F-84C3-422C-AB72-CC4ED6CE04D3@uiuc.edu>
Message-ID: <002901c72445$302cbc50$7c94100a@win.ad.jhu.edu>

Dear Roger,

Is it possible to combine the two ideas that you mentioned: (1) algorithmic
approaches of Breiman, Friedman, and others that achieve flexibility in the
predictor space, and (2) robust and flexible regression like QR that achieve
flexibility in the response space, so as to achieve complete flexibility?
If it is possible, are you or anyone else in the R community working on
this?

Thanks,
Ravi.

----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of roger koenker
Sent: Wednesday, December 20, 2006 8:57 AM
To: Mark Difford
Cc: R-help list
Subject: Re: [R] RuleFit & quantreg: partial dependence plots; showing an
effect

They are entirely different:  Rulefit is a fiendishly clever  
combination of decision tree  formulation
of models and L1-regularization intended to select parsimonious fits  
to very complicated
responses yielding e.g. piecewise constant functions.  Rulefit   
estimates the  conditional
mean of the response over the covariate space, but permits a very  
flexible, but linear in
parameters specifications of the covariate effects on the conditional  
mean.  The quantile
regression plotting you refer to adopts a fixed, linear specification  
for conditional quantile
functions and given that specification depicts how the covariates  
influence the various
conditional quantiles of the response.   Thus, roughly speaking,  
Rulefit is focused on
flexibility in the x-space, maintaining the classical conditional  
mean objective; while
QR is trying to be more flexible in the y-direction, and maintaining  
a fixed, linear
in parameters specification for the covariate effects at each quantile.


url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Champaign, IL 61820


On Dec 20, 2006, at 4:17 AM, Mark Difford wrote:

> Dear List,
>
> I would greatly appreciate help on the following matter:
>
> The RuleFit program of Professor Friedman uses partial dependence  
> plots
> to explore the effect of an explanatory variable on the response
> variable, after accounting for the average effects of the other
> variables.  The plot method [plot(summary(rq(y ~ x1 + x2,
> t=seq(.1,.9,.05))))] of Professor Koenker's quantreg program  
> appears to
> do the same thing.
>
>
> Question:
> Is there a difference between these two types of plot in the manner  
> in which they depict the relationship between explanatory variables  
> and the response variable ?
>
> Thank you inav for your help.
>
> Regards,
> Mark Difford.
>
> -------------------------------------------------------------
> Mark Difford
> Ph.D. candidate, Botany Department,
> Nelson Mandela Metropolitan University,
> Port Elizabeth, SA.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From sfalcon at fhcrc.org  Wed Dec 20 16:14:15 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 20 Dec 2006 07:14:15 -0800
Subject: [R] biocondutor installation problem
In-Reply-To: <7CD06E15ADF4104A9F2E4DC2DE678F89044482B3@EXCHANGE21.staff.main.ntu.edu.sg>
	(Kesavan Asaithambi's message of "Wed,
	20 Dec 2006 13:37:15 +0800")
References: <7CD06E15ADF4104A9F2E4DC2DE678F89044482B3@EXCHANGE21.staff.main.ntu.edu.sg>
Message-ID: <m2mz5i4n20.fsf@ziti.local>

I'm pretty sure your subject should be:

  Help configure R to use web proxy on RHEL4.

You don't have a Bioconductor specific problem (yet).

"Kesavan Asaithambi" <asaithambi at ntu.edu.sg> writes:
>> source("http://www.bioconductor.org/biocLite.R")
>
> Error in file(file, "r", encoding = encoding) :
>
>         unable to open connection
>
> In addition: Warning message:
>
> unable to connect to 'www.bioconductor.org' on port 80.

Did you try reading the help for download.file?  Start R and then do:

   help(download.file)

+ seth


From rkoenker at uiuc.edu  Wed Dec 20 16:58:30 2006
From: rkoenker at uiuc.edu (roger koenker)
Date: Wed, 20 Dec 2006 09:58:30 -0600
Subject: [R] RuleFit & quantreg: partial dependence plots;
	showing an effect
In-Reply-To: <002901c72445$302cbc50$7c94100a@win.ad.jhu.edu>
References: <002901c72445$302cbc50$7c94100a@win.ad.jhu.edu>
Message-ID: <D600E806-5F8B-43C3-B900-3EFE56C2E1F8@uiuc.edu>



On Dec 20, 2006, at 8:43 AM, Ravi Varadhan wrote:

> Dear Roger,
>
> Is it possible to combine the two ideas that you mentioned: (1)  
> algorithmic
> approaches of Breiman, Friedman, and others that achieve  
> flexibility in the
> predictor space, and (2) robust and flexible regression like QR  
> that achieve
> flexibility in the response space, so as to achieve complete  
> flexibility?
> If it is possible, are you or anyone else in the R community  
> working on
> this?
>
>
There are some tentative steps in this direction.  One is the rqss()  
fitting
in my quantreg package which does QR fitting with additive models
using total variation as a roughness penalty for nonlinear terms.
Another, along more tree structured lines, is Nicolai Meinshausen's
quantregforest package.
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of roger koenker
> Sent: Wednesday, December 20, 2006 8:57 AM
> To: Mark Difford
> Cc: R-help list
> Subject: Re: [R] RuleFit & quantreg: partial dependence plots;  
> showing an
> effect
>
> They are entirely different:  Rulefit is a fiendishly clever
> combination of decision tree  formulation
> of models and L1-regularization intended to select parsimonious fits
> to very complicated
> responses yielding e.g. piecewise constant functions.  Rulefit
> estimates the  conditional
> mean of the response over the covariate space, but permits a very
> flexible, but linear in
> parameters specifications of the covariate effects on the conditional
> mean.  The quantile
> regression plotting you refer to adopts a fixed, linear specification
> for conditional quantile
> functions and given that specification depicts how the covariates
> influence the various
> conditional quantiles of the response.   Thus, roughly speaking,
> Rulefit is focused on
> flexibility in the x-space, maintaining the classical conditional
> mean objective; while
> QR is trying to be more flexible in the y-direction, and maintaining
> a fixed, linear
> in parameters specification for the covariate effects at each  
> quantile.
>
>
> url:    www.econ.uiuc.edu/~roger            Roger Koenker
> email    rkoenker at uiuc.edu            Department of Economics
> vox:     217-333-4558                University of Illinois
> fax:       217-244-6678                Champaign, IL 61820
>
>
> On Dec 20, 2006, at 4:17 AM, Mark Difford wrote:
>
>> Dear List,
>>
>> I would greatly appreciate help on the following matter:
>>
>> The RuleFit program of Professor Friedman uses partial dependence
>> plots
>> to explore the effect of an explanatory variable on the response
>> variable, after accounting for the average effects of the other
>> variables.  The plot method [plot(summary(rq(y ~ x1 + x2,
>> t=seq(.1,.9,.05))))] of Professor Koenker's quantreg program
>> appears to
>> do the same thing.
>>
>>
>> Question:
>> Is there a difference between these two types of plot in the manner
>> in which they depict the relationship between explanatory variables
>> and the response variable ?
>>
>> Thank you inav for your help.
>>
>> Regards,
>> Mark Difford.
>>
>> -------------------------------------------------------------
>> Mark Difford
>> Ph.D. candidate, Botany Department,
>> Nelson Mandela Metropolitan University,
>> Port Elizabeth, SA.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From news at gavofyork.fastmail.fm  Wed Dec 20 17:05:40 2006
From: news at gavofyork.fastmail.fm (Gav Wood)
Date: Wed, 20 Dec 2006 16:05:40 +0000
Subject: [R] Newbie data organisation/structures question...
Message-ID: <embn0k$amp$1@sea.gmane.org>

Howdo folks,

So my data is in this sort of format:

P  T  I
1  1  (1, 2, 3)
2  1  (2, 4)
1  2  (1, 3, 6, 7)
2  2  (6)

And I want to be able to quickly get:

1: The I when both P and T are given. e.g.:
P = 2, T = 2; I = (6)

2: The concatenated vector of Is when P and a subset of T is given, e.g.:
P = 1, T = 1:2;  Is = (1, 2, 3, 1, 3, 6, 7)

3: The length of that vector.

It would also be nice to have:

4: A list of Is when either P or T is given. e.g.:
P = 2: I = (2, 4), (6)
T = 1: I = (1, 2, 3), (1, 3, 6, 7)

Currently, I have a matrix of P x T, whose elements are lists of a 
single item, the vector I. I call this 'm'.

(1) is easy; just m[P, T][[1]]
(2) and (3) are apparently much harder. For 3, I'm resorting to:

total <- 0
for(p in 1:length(m[,T]))
	total <- total + length(m[p,T][[1]]);

And something similar for 2.

There must surely be a better way of doing this; but what is it?

Cheers,

Gav


From basu.15 at osu.edu  Wed Dec 20 17:37:10 2006
From: basu.15 at osu.edu (DEEPANKAR BASU)
Date: Wed, 20 Dec 2006 11:37:10 -0500
Subject: [R] Upgrading
Message-ID: <5b87605b5236.5b52365b8760@osu.edu>

Thanks for the comments. I had got Thomas' message wrong the first time. Now, I have downloaded and re-installed the latest version of R. After reading the "administration and maintenance" manual, I added

deb http://cran.R-project.org/bin/linux/ubuntu dapper/

to my sources.list file and used apt-get to install the latest version. After the installation, I used update.packages() from with R to update all the packages. Let me know if this was what was required or I made some mistake. 

I have two questions:
1. When a new version of R is released (every 6 months or so I believe) will I have to uninstall the version of R in my machine and then download and install the latest version?
2. When I used update.packages() from within R (after installing the latest version), I still got the following warning messages:

Warning messages:
1: installation of package 'cluster' had non-zero exit status in: install.packages(update[, "Package"], instlib, contriburl = contriburl,
2: installation of package 'mgcv' had non-zero exit status in: install.packages(update[, "Package"], instlib, contriburl = contriburl,
3: cannot create HTML package index in: tools:::unix.packages.html(.Library)

I cannot understand what to make of these?

Thanks for all the help.

Deepankar



----- Original Message -----
From: Petr Pikal <petr.pikal at precheza.cz>
Date: Wednesday, December 20, 2006 4:47 am
Subject: Re: [R] Upgrading

> Hi
> 
> as the addition to Thomas's answer.
> 
> On 19 Dec 2006 at 15:20, Thomas Lumley wrote:
> 
> Date sent:      	Tue, 19 Dec 2006 15:20:18 -0800 (PST)
> From:           	Thomas Lumley <tlumley at u.washington.edu>
> To:             	DEEPANKAR BASU <basu.15 at osu.edu>
> Copies to:      	R-help at stat.math.ethz.ch
> Subject:        	Re: [R] Upgrading
> 
> > On Tue, 19 Dec 2006, DEEPANKAR BASU wrote:
> > 
> > > Hi!
> > >
> > > As per Thomas' advice, I upgraded R by using 
> "update.packages()" and
> > > got the following warning messages:
> > 
> > That was not my advice on how to upgrade. update.packages() updates
> > the packages. You need to download a new version of R itself.  You
> > will then need to update or reinstall the packages. The warning
> > messages are because you are updating to versions of the packages 
> that> do not run on your old version of R.
> 
> <snip>
> 
> > >
> > > Another question: what is the command for renaming an existing
> > > variable?
> 
> e.g. if the variable is in data frame
> 
> names(your.data)[position.of.old.column.name] <- "new.column.name"
> BTW, reading et least some docummentation could help you a lot with 
> these issues.
> 
> HTH
> Petr
> 
> 
> > >
> > > Thanks.
> > > Deepankar
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html and provide commented,
> > > minimal, self-contained, reproducible code.
> > >
> > 
> > Thomas Lumley                	Assoc. Professor, Biostatistics
> > tlumley at u.washington.edu	University of Washington, Seattle
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html and provide commented,
> > minimal, self-contained, reproducible code.
> 
> Petr Pikal
> petr.pikal at precheza.cz
> 
>


From makerdogan at yahoo.com.tr  Wed Dec 20 17:49:58 2006
From: makerdogan at yahoo.com.tr (Mehmet Akif ERDOGAN)
Date: Wed, 20 Dec 2006 18:49:58 +0200 (EET)
Subject: [R] help for multinominal logistic regression code
Message-ID: <217814.60216.qm@web26004.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061220/28b7d7e0/attachment.pl 

From vbarstat at gmail.com  Wed Dec 20 17:51:31 2006
From: vbarstat at gmail.com (michele de meo)
Date: Wed, 20 Dec 2006 17:51:31 +0100
Subject: [R] writing R extension
Message-ID: <9d6774620612200851k4f5610cduf606591236fd97e7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061220/e13384ed/attachment.pl 

From sarah.goslee at gmail.com  Wed Dec 20 18:09:47 2006
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 20 Dec 2006 12:09:47 -0500
Subject: [R] writing R extension
In-Reply-To: <9d6774620612200851k4f5610cduf606591236fd97e7@mail.gmail.com>
References: <9d6774620612200851k4f5610cduf606591236fd97e7@mail.gmail.com>
Message-ID: <efb536d50612200909m50f32c95g580573aa67256722@mail.gmail.com>

For a very simple library, you really only need chapter 1 of the manual
on writing R extensions, which even describes the "helper functions"
that take some of the work out of making a "proper" package.

If that's still too complex, you could also save your function to a file
and load it as needed with source(). That will give the user the
same effect.

source("/path/to/my/stuff/myfiles.R")

Since you didn't tell us OS or anything else about your system,
it's hard to be more specific.

Sarah

On 12/20/06, michele de meo <vbarstat at gmail.com> wrote:
> I'd like to develop a simple library in R in which to save my
> particular functions.
> I have read the manual on "Writing R Extensions" but it's too
> difficult. Someone could help me?
>
> I want only save my personal function (recorded in R-code, not in C) in
> "myLibrary" and I want to call it with:
>
>  >library (myLibrary).
>
> After this, the functions should be available directly in R.
>
> I know that it's possible to save functions in the workspace, but I
> need this functions in a library.
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.functionaldiversity.org


From rvaradhan at jhmi.edu  Wed Dec 20 18:12:39 2006
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Wed, 20 Dec 2006 12:12:39 -0500
Subject: [R] RuleFit & quantreg: partial dependence plots;
	showing an effect
In-Reply-To: <D600E806-5F8B-43C3-B900-3EFE56C2E1F8@uiuc.edu>
Message-ID: <001801c7245a$0df42870$7c94100a@win.ad.jhu.edu>

Thanks, Roger.  These should be very useful tools.

Ravi.

----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------


-----Original Message-----
From: roger koenker [mailto:rkoenker at uiuc.edu] 
Sent: Wednesday, December 20, 2006 10:59 AM
To: Ravi Varadhan
Cc: 'Mark Difford'; 'R-help list'
Subject: Re: [R] RuleFit & quantreg: partial dependence plots; showing an
effect



On Dec 20, 2006, at 8:43 AM, Ravi Varadhan wrote:

> Dear Roger,
>
> Is it possible to combine the two ideas that you mentioned: (1)  
> algorithmic
> approaches of Breiman, Friedman, and others that achieve  
> flexibility in the
> predictor space, and (2) robust and flexible regression like QR  
> that achieve
> flexibility in the response space, so as to achieve complete  
> flexibility?
> If it is possible, are you or anyone else in the R community  
> working on
> this?
>
>
There are some tentative steps in this direction.  One is the rqss()  
fitting
in my quantreg package which does QR fitting with additive models
using total variation as a roughness penalty for nonlinear terms.
Another, along more tree structured lines, is Nicolai Meinshausen's
quantregforest package.
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of roger koenker
> Sent: Wednesday, December 20, 2006 8:57 AM
> To: Mark Difford
> Cc: R-help list
> Subject: Re: [R] RuleFit & quantreg: partial dependence plots;  
> showing an
> effect
>
> They are entirely different:  Rulefit is a fiendishly clever
> combination of decision tree  formulation
> of models and L1-regularization intended to select parsimonious fits
> to very complicated
> responses yielding e.g. piecewise constant functions.  Rulefit
> estimates the  conditional
> mean of the response over the covariate space, but permits a very
> flexible, but linear in
> parameters specifications of the covariate effects on the conditional
> mean.  The quantile
> regression plotting you refer to adopts a fixed, linear specification
> for conditional quantile
> functions and given that specification depicts how the covariates
> influence the various
> conditional quantiles of the response.   Thus, roughly speaking,
> Rulefit is focused on
> flexibility in the x-space, maintaining the classical conditional
> mean objective; while
> QR is trying to be more flexible in the y-direction, and maintaining
> a fixed, linear
> in parameters specification for the covariate effects at each  
> quantile.
>
>
> url:    www.econ.uiuc.edu/~roger            Roger Koenker
> email    rkoenker at uiuc.edu            Department of Economics
> vox:     217-333-4558                University of Illinois
> fax:       217-244-6678                Champaign, IL 61820
>
>
> On Dec 20, 2006, at 4:17 AM, Mark Difford wrote:
>
>> Dear List,
>>
>> I would greatly appreciate help on the following matter:
>>
>> The RuleFit program of Professor Friedman uses partial dependence
>> plots
>> to explore the effect of an explanatory variable on the response
>> variable, after accounting for the average effects of the other
>> variables.  The plot method [plot(summary(rq(y ~ x1 + x2,
>> t=seq(.1,.9,.05))))] of Professor Koenker's quantreg program
>> appears to
>> do the same thing.
>>
>>
>> Question:
>> Is there a difference between these two types of plot in the manner
>> in which they depict the relationship between explanatory variables
>> and the response variable ?
>>
>> Thank you inav for your help.
>>
>> Regards,
>> Mark Difford.
>>
>> -------------------------------------------------------------
>> Mark Difford
>> Ph.D. candidate, Botany Department,
>> Nelson Mandela Metropolitan University,
>> Port Elizabeth, SA.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Wed Dec 20 18:22:43 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 20 Dec 2006 17:22:43 +0000 (GMT)
Subject: [R] help for multinominal logistic regression code
In-Reply-To: <217814.60216.qm@web26004.mail.ukl.yahoo.com>
References: <217814.60216.qm@web26004.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.64.0612201718520.12201@gannet.stats.ox.ac.uk>

If you meant 'multinomial', help.search("multinomial") and 
help.search("logistic") both get you to multinom in package nnet.
That is support software for a book, where the detailed documentation is.

On Wed, 20 Dec 2006, Mehmet Akif ERDOGAN wrote:

> Dear all,
>
>  firstly I would like to say I am a beginner user for R and also 
> naturally a new member of this mail list. This means I have newer read 
> previous mails before.

You could look in the list archives, though.

>  I need a small help for my analysis. I want to perform a multinominal 
> logistic regression for my data set. But as I told before I am a 
> beginner for R and I couldn't find the code for multinominal logistic 
> regression.
>
>  Could you please help me for multinominal logistic regression code?
>
>  Thank you for your attention.
>
>  Best wishes,
>
>  Mehmet Akif Erdogan
>  Msc Student of
>  Cukurova University,
>  Landscape Architecture Dept.,
>  01330 Adana/TURKEY

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From b.rowlingson at lancaster.ac.uk  Wed Dec 20 18:31:09 2006
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 20 Dec 2006 17:31:09 +0000
Subject: [R] writing R extension
In-Reply-To: <efb536d50612200909m50f32c95g580573aa67256722@mail.gmail.com>
References: <9d6774620612200851k4f5610cduf606591236fd97e7@mail.gmail.com>
	<efb536d50612200909m50f32c95g580573aa67256722@mail.gmail.com>
Message-ID: <4589735D.1040406@lancaster.ac.uk>

Sarah Goslee wrote:

> If that's still too complex, you could also save your function to a file
> and load it as needed with source(). That will give the user the
> same effect.
> 
> source("/path/to/my/stuff/myfiles.R")
> 
> Since you didn't tell us OS or anything else about your system,
> it's hard to be more specific.
> 

  Yikes No!

  That will load all the objects into the current workspace. If you save 
when you quit, you'll end up with umpteen copies of your package code!

  For simple bundles of functions, it would be better to use save() to 
save them all to a .RData-type file and then 'attach()' it. This way it 
doesn't get stuck in your workspace. So:

  > foo=function(x){x^2}
  > bar=function(y){y^6}
  > baz=function(z){z*3}

  > myFunctions=c("foo","bar","baz")
  > save(list=myFunctions,file="myFunctions.RData")

then quit R, start R in another workspace:

  > attach("/path/to/wherever/you/put/myFunctions.RData")
  > foo(2)
    [1] 4

  Building proper _packages_ (never call them 'libraries' - libraries 
are collections of packages) isn't that hard once you've done it a dozen 
times, although I'm starting the find the bondage and discipline of 
packaging R code getting to me.

Barry


From dieter.menne at menne-biomed.de  Wed Dec 20 18:33:09 2006
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Wed, 20 Dec 2006 17:33:09 +0000 (UTC)
Subject: [R] how to do muliple comparisons in linear mixed models
References: <32f489f80612191758j305383b4sc3cc8c1b31cc481b@mail.gmail.com>
Message-ID: <loom.20061220T183230-932@post.gmane.org>

liu, jcheng <liujcheng <at> gmail.com> writes:

>     i want to compare the several main effects in a linear model. i wonder
> how to do the multiple comparisons for less confident intervals.

Package multcomp by Torsten Hothorn.

Dieter


From gchappi at gmail.com  Wed Dec 20 18:42:47 2006
From: gchappi at gmail.com (Hans-Peter)
Date: Wed, 20 Dec 2006 18:42:47 +0100
Subject: [R] writing R extension
In-Reply-To: <9d6774620612200851k4f5610cduf606591236fd97e7@mail.gmail.com>
References: <9d6774620612200851k4f5610cduf606591236fd97e7@mail.gmail.com>
Message-ID: <47fce0650612200942i40ded3x70ecabdcbce9a7d1@mail.gmail.com>

2006/12/20, michele de meo <vbarstat at gmail.com>:
> I'd like to develop a simple library in R in which to save my
> particular functions.

> I know that it's possible to save functions in the workspace, but I
> need this functions in a library.

- As an option you could also save the function in a textfile and
source it in the beginning of an R session (-> e.g. in the
profile.site file in RHOME\etc

- Otherwise you will have to re-read about building packages. Packages
are great (e.g. for consistent documentation, tests, ...) but have the
disadvantage that they are more complicated and less flexible than
just sourcing code. If your code changes (often) I'd recommend to
automate the whole package-building-process.

If you are on windows, maybe the following which I had laying around will help:

<<
Download and Install
--------------------
- Perl: http://activestate.com/store/activeperl/
- Rtools: http://www.murdoch-sutherland.com/Rtools/tools.zip
  (extract in a directory like e.g. programme\R\Rtools)
- MS HTML Help Workshop:
http://msdn.microsoft.com/library/en-us/htmlhelp/html/hwmicrosofthtmlhelpdownloads.asp
- TeX: 	download current version at: http://www.miktex.org/
	at the moment:
http://prdownloads.sourceforge.net/miktex/basic-miktex-2.5.2471.exe?download

Adjust Windows environmental variables (~System->Erweitert->Umgebungsvariablen)
--------------------
- PATH: In this variable the paths to the installed programs above
have to be. With the installation this has normally be done
automatically. For the Rtools you have to do it yourself: add the path
to the tools bin folder. Take care not to change the other paths. And
check if the path for the programs above are correct/included. A GOOD
IDEA is to copy the whole path in a text editor, modify and copy it
back.
- If I remember correctly the TeX program needs a nonstandard temp
directory variable: "TMPDIR". Add this variable to the system
variables, choose the same value as for the other temp variable (TEMP,
TMP, ...).

Optional tools
-------------
- yap (to read *.dvi files, maybe this is already included in the
miktex TeX download)

Additonal info
-------------
[1] http://statmath.wu-wien.ac.at/staff/dekic/Rwin/
[2] http://statmath.wu-wien.ac.at/staff/dekic/Rwin/LinkedDocuments/Anleitung.pdf
[3] http://www.murdoch-sutherland.com/Rtools/
>>

Use package.skeleton to make a prototype (this is VERY useful). To
build the packages you can use bat (batch) files, e.g. something like:
set rver=2.3.1
set rcmd="C:\Programme\R\R-%rver%\bin\Rcmd.exe"
%rcmd% check %prj%
%rcmd% INSTALL --docs="txt,html,example,chm" --library=../../TempInstall %prj%

-- 
Regards,
Hans-Peter


From marc_schwartz at comcast.net  Wed Dec 20 18:50:56 2006
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Wed, 20 Dec 2006 11:50:56 -0600
Subject: [R] Newbie data organisation/structures question...
In-Reply-To: <embn0k$amp$1@sea.gmane.org>
References: <embn0k$amp$1@sea.gmane.org>
Message-ID: <1166637056.4677.52.camel@localhost.localdomain>

On Wed, 2006-12-20 at 16:05 +0000, Gav Wood wrote:
> Howdo folks,
> 
> So my data is in this sort of format:
> 
> P  T  I
> 1  1  (1, 2, 3)
> 2  1  (2, 4)
> 1  2  (1, 3, 6, 7)
> 2  2  (6)
> 
> And I want to be able to quickly get:
> 
> 1: The I when both P and T are given. e.g.:
> P = 2, T = 2; I = (6)
> 
> 2: The concatenated vector of Is when P and a subset of T is given, e.g.:
> P = 1, T = 1:2;  Is = (1, 2, 3, 1, 3, 6, 7)
> 
> 3: The length of that vector.
> 
> It would also be nice to have:
> 
> 4: A list of Is when either P or T is given. e.g.:
> P = 2: I = (2, 4), (6)
> T = 1: I = (1, 2, 3), (1, 3, 6, 7)
> 
> Currently, I have a matrix of P x T, whose elements are lists of a 
> single item, the vector I. I call this 'm'.
> 
> (1) is easy; just m[P, T][[1]]
> (2) and (3) are apparently much harder. For 3, I'm resorting to:
> 
> total <- 0
> for(p in 1:length(m[,T]))
> 	total <- total + length(m[p,T][[1]]);
> 
> And something simiThis then giveslar for 2.
> 
> There must surely be a better way of doing this; but what is it?
> 
> Cheers,
> 
> Gav

Reading in your data using:

DF <- read.fwf("clipboard", widths = c(3, 3, 12),
               skip = 1)

colnames(DF) <- c("P", "T", "I")


Substitute your actual data file name for 'clipboard' above.


Note that I skip the header row, as the "T" causes problems, since it
wants to be converted to 'TRUE' (logical, not char) upon import,
screwing up the column widths. I then assign the colnames post import.

This then gives me:

> DF
  P T            I
1 1 1    (1, 2, 3)
2 2 1       (2, 4)
3 1 2 (1, 3, 6, 7)
4 2 2          (6)

Given the manipulations that you appear to want to do, I would first
strip the parens from "I" to make subsequent operations easier:

DF$I <- gsub("\\(|\\)", "", DF$I)

So:

> DF
  P T          I
1 1 1    1, 2, 3
2 2 1       2, 4
3 1 2 1, 3, 6, 7
4 2 2          6


Now, split the character vector based DF$I into components and convert
it to numeric lists:

> DF$I <- lapply(strsplit(DF$I, split = ","), as.numeric)

> DF
  P T          I
1 1 1    1, 2, 3
2 2 1       2, 4
3 1 2 1, 3, 6, 7
4 2 2          6

# Look at the structure of 'DF'
> str(DF)
'data.frame':	4 obs. of  3 variables:
 $ P: num  1 2 1 2
 $ T: num  1 1 2 2
 $ I:List of 4
  ..$ : num  1 2 3
  ..$ : num  2 4
  ..$ : num  1 3 6 7
  ..$ : num 6


Now for your manipulations above:

1: The I when both P and T are given. e.g.:
P = 2, T = 2; I = (6)

> subset(DF, (P == 2) & (T == 2), select = I)
  I
4 6


2: The concatenated vector of Is when P and a subset of T is given,
e.g.:
P = 1, T = 1:2;  Is = (1, 2, 3, 1, 3, 6, 7)

> unlist(subset(DF, (P == 1) & (T %in% 1:2), select = I))
I1 I2 I3 I4 I5 I6 I7 
 1  2  3  1  3  6  7

or you can use:

> as.vector(unlist(subset(DF, (P == 1) & (T %in% 1:2), select = I)))
[1] 1 2 3 1 3 6 7

which strips the name attributes from the vector.



3: The length of that vector.

> length(unlist(subset(DF, (P == 1) & (T %in% 1:2), select = I)))
[1] 7



4: A list of Is when either P or T is given. e.g.:
P = 2: I = (2, 4), (6)
T = 1: I = (1, 2, 3), (1, 3, 6, 7)


> subset(DF, P == 2, select = I)
     I
2 2, 4
4    6


> subset(DF, T == 1, select = I)
        I
1 1, 2, 3
2    2, 4

Note that your example above for 'T == 1' in 4 is incorrect based upon
your example data. "(1, 3, 6, 7)" is on the row where T == 2.   :-)


See ?read.fwf, ?read.table, ?subset, ?split, ?gsub, ?lapply, ?unlist, ?Syntax and ?Comparison for more information.

HTH,

Marc Schwartz


From kubovy at virginia.edu  Wed Dec 20 19:14:48 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Wed, 20 Dec 2006 13:14:48 -0500
Subject: [R] Newbie data organisation/structures question...
In-Reply-To: <embn0k$amp$1@sea.gmane.org>
References: <embn0k$amp$1@sea.gmane.org>
Message-ID: <D2B4B0E1-B7CE-4E26-B542-0E66C57BCBBE@virginia.edu>

On Dec 20, 2006, at 11:05 AM, Gav Wood wrote:

> So my data is in this sort of format:
>
> P  T  I
> 1  1  (1, 2, 3)
> 2  1  (2, 4)
> 1  2  (1, 3, 6, 7)
> 2  2  (6)

Not knowing why you organized the data as you did, let me suggest  
another approach:

iv <- c(1, 2, 3, 2, 4, 1, 3, 6, 7, 6)
p <- c(1, 1, 1, 2, 2, 1, 1, 1, 1, 2)
t <- rep(1:2, each = 5)
dat <- data.frame(iv, p, t)

> And I want to be able to quickly get:
>
> The I when both P and T are given. e.g.:
> P = 2, T = 2; I = (6)

subset(dat, p == 2 & t ==2)$iv

> The concatenated vector of Is when P and a subset of T is given, e.g.:
> P = 1, T = 1:2;  Is = (1, 2, 3, 1, 3, 6, 7)

(iv1 <- subset(dat, p == 1)$iv)

> The length of that vector.

length(iv1)

> A list of Is when either P or T is given. e.g.:
> P = 2: I = (2, 4), (6)
> T = 1: I = (1, 2, 3), (1, 3, 6, 7)

list(p2t1 = subset(dat, p == 2 & t ==1)$iv, p2t2 = subset(dat, p == 2  
& t ==2)$iv)
list(p1t1 = subset(dat, p == 1 & t ==1)$iv, p1t2 = subset(dat, p == 1  
& t ==2)$iv) # correcting your requirement to get your result

There are many other ways of getting the results you need as Marc  
Schwartz pointed out in his reply.
_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/


From aajakh at yahoo.com  Wed Dec 20 20:30:04 2006
From: aajakh at yahoo.com (ahmad ajakh)
Date: Wed, 20 Dec 2006 11:30:04 -0800 (PST)
Subject: [R] writing R extension
Message-ID: <20061220193004.51714.qmail@web37903.mail.mud.yahoo.com>

Hi all,
I am dealing with the same issue here and I was wondering whether it would be possible to just save
the R compliled function objects in a directory and just attach the directory to the search path.
(I am using R2.4.0+ESS+Xemacs in windows XP). 

Thanks.
AA.


----- Original Message ----
From: Sarah Goslee <sarah.goslee at gmail.com>
To: michele de meo <vbarstat at gmail.com>
Cc: r-help at stat.math.ethz.ch
Sent: Wednesday, December 20, 2006 12:09:47 PM
Subject: Re: [R] writing R extension

For a very simple library, you really only need chapter 1 of the manual
on writing R extensions, which even describes the "helper functions"
that take some of the work out of making a "proper" package.

If that's still too complex, you could also save your function to a file
and load it as needed with source(). That will give the user the
same effect.

source("/path/to/my/stuff/myfiles.R")

Since you didn't tell us OS or anything else about your system,
it's hard to be more specific.

Sarah

On 12/20/06, michele de meo <vbarstat at gmail.com> wrote:
> I'd like to develop a simple library in R in which to save my
> particular functions.
> I have read the manual on "Writing R Extensions" but it's too
> difficult. Someone could help me?
>
> I want only save my personal function (recorded in R-code, not in C) in
> "myLibrary" and I want to call it with:
>
>  >library (myLibrary).
>
> After this, the functions should be available directly in R.
>
> I know that it's possible to save functions in the workspace, but I
> need this functions in a library.
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.functionaldiversity.org

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Greg.Snow at intermountainmail.org  Wed Dec 20 20:34:18 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 20 Dec 2006 12:34:18 -0700
Subject: [R] Rotating a distribution plot by 90 degrees
Message-ID: <07E228A5BE53C24CAD490193A7381BBB739EB6@LP-EXCHVS07.CO.IHC.COM>

Does the following code do what you want?

x <- c( rnorm(50,10,2), rnorm(30,20,2) )
y <- 2+3*x + rnorm(80)

d.x <- density(x)
d.y <- density(y)

layout( matrix( c(0,2,2,1,3,3,1,3,3),ncol=3) )

plot(d.x$x, d.x$y, xlim=range(x), type='l')
plot(d.y$y, d.y$x, ylim=range(y), xlim=rev(range(d.y$y)), type='l')
plot(x,y, xlim=range(x), ylim=range(y) )

If not, be more specific in describing what you want.

Hope this helps,


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Benjamin Otto
Sent: Wednesday, December 20, 2006 3:55 AM
To: R-Help
Subject: [R] Rotating a distribution plot by 90 degrees

Hi,

Can I rotate a plot (e.g. a distribution plot) by 90 degrees? The
barplot function provides the "horiz" command but that's not availeable
for the base package functions. I found an old advice from Paul Murrell
on a similar problem suggesting to use viewports (grid package). Yet I
couldn't reproduce his examples successfully. And going through the
examples in the current grid package help pages left me with the feeling
that viewport and the plot/points function don't match because the
latter automatically clears the old device.

Is there some way to rotate a "plot" at all or am I forced to use the
barplot function instead?

Regards,

Benjamin


P.S.: For further explanation: I would like to plot something like

+-----+-----+
|     |     |
|  0  |  1  |
|     |     |
+-----+-----+
|     |     |
|  2  |  3  |
|     |     |
+-----+-----+

where image 1 is some function plot in normal mode, image 2 is a
function plot rotated by 90 degrees and image 3 is something depending
on the two functions.


--
Benjamin Otto
Universitaetsklinikum Eppendorf Hamburg
Institut fuer Klinische Chemie
Martinistrasse 52
20246 Hamburg

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Greg.Snow at intermountainmail.org  Wed Dec 20 20:43:33 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 20 Dec 2006 12:43:33 -0700
Subject: [R] fit sine?
Message-ID: <07E228A5BE53C24CAD490193A7381BBB739EB8@LP-EXCHVS07.CO.IHC.COM>

Look at the functions: nls, optimize, optim.  Also look at the packages
circular and CircStats.

Hope this helps, 


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Randy Zelick
Sent: Tuesday, December 19, 2006 12:52 PM
To: R list server posting
Subject: [R] fit sine?

Hello list,

I am making scatterplots of data that vary sinusoidally over 24 hours. 
With a bit of previous help from this list, I now can get an x-axis with
time tics from 00:00 on the left edge to 12:00 in the middle and 00:00
on the right edge, i.e., just 24 hours.

Now I would like to fit a sin function to the plot. I've looked all over
CRAN and the web in general, but have not found a method or package for
this.

Can anyone make a suggestion?

Thanks,

=Randy=


Using R 2.4.0 on Solaris (unix).


R. Zelick				email: zelickr at pdx.edu
Department of Biology			voice: 503-725-3086
Portland State University		fax:   503-725-3888

mailing:
P.O. Box 751
Portland, OR 97207

shipping:
1719 SW 10th Ave, Room 246
Portland, OR 97201

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Wed Dec 20 21:06:08 2006
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 20 Dec 2006 15:06:08 -0500
Subject: [R] writing R extension
In-Reply-To: <20061220193004.51714.qmail@web37903.mail.mud.yahoo.com>
References: <20061220193004.51714.qmail@web37903.mail.mud.yahoo.com>
Message-ID: <efb536d50612201206s15bef8b3sa8736f4af102f1c2@mail.gmail.com>

Hi,

> I am dealing with the same issue here and I was wondering whether it would be possible to just save
> the R compliled function objects in a directory and just attach the directory to the search path.
> (I am using R2.4.0+ESS+Xemacs in windows XP).


The other method that I'm familiar with uses save() and load() rather than
attach. It may be possible to use attach() in some other method.

> temp1 <- function(x) {x * x}
> temp2 <- function(x) {x + x}
> temp1(3)
[1] 9
> temp2(3)
[1] 6
> save(list=ls(), file="testfns")
> q(save="no")

# start R
> ls()
character(0)
> load("testfns")
> ls()
[1] "temp1" "temp2"


My personal preference is the text source file approach, but opinions
obviously vary on that. I do keep "final" versions in a package.

And yes, the proper term is package, but it seems that if the entity
in question is stored in  /usr/lib/R/library (on my linux system), and
loaded with the function library() the occasional slip might be forgiven?

Sarah
-- 
Sarah Goslee
http://www.stringpage.com
http://www.functionaldiversity.org


From tariq.khan at gmail.com  Wed Dec 20 21:32:52 2006
From: tariq.khan at gmail.com (=?ISO-8859-1?Q?=A8Tariq_Khan?=)
Date: Wed, 20 Dec 2006 20:32:52 +0000
Subject: [R] writing R extension
In-Reply-To: <efb536d50612201206s15bef8b3sa8736f4af102f1c2@mail.gmail.com>
References: <20061220193004.51714.qmail@web37903.mail.mud.yahoo.com>
	<efb536d50612201206s15bef8b3sa8736f4af102f1c2@mail.gmail.com>
Message-ID: <2310043c0612201232u494c5c86ld122c0637c7addd1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061220/277e7b78/attachment.pl 

From tobygass at warnercnr.colostate.edu  Wed Dec 20 21:22:35 2006
From: tobygass at warnercnr.colostate.edu (Toby Gass)
Date: Wed, 20 Dec 2006 13:22:35 -0700
Subject: [R] Reformat meteorological data
Message-ID: <001c01c72478$17a95fc0$03125281@Q11>

Dear HelpeRs:

I have a data set in the following format,
which will be familiar to those of you working
with NCDC climate data.

Example:

Year <- rep(1:3, each = 3)
Year <- c(Year,Year)
ID <- rep(1:2, each = 9)
Jan <- runif(18, min = 0, max = 20)
Feb <- runif(18, min = 0, max = 20)
Mar <- runif(18, min = 0, max = 20)
var <- gl(3,1,18,label = c("snow","rain","temp"))
data <-data.frame(row.names = c(1:18),ID, Year, var, Jan, 
Feb, Mar)


The actual dataset has 12 months, about 100 years, 6 ID's,
many more levels in "var", and includes NA's.


I would like to convert the data to the following format:

ID Year Month Rain Snow Temp
1     1     Jan     value  value value
1     1     Feb     value value value
1     1     Mar     value value value
. . . . .
. . . . .
. . . . .
1     2     Jan     value value value
1     2     Feb     value value value
1     2     Mar     value value value
. . . . . .
. . . . . .
. . . . . .
1     3     Jan     value value value
1     3     Feb     value value value
1     3     Mar     value value value
. . . . . .
. . . . . .
2     1     Jan     value value value
2     1     Feb     value value value
2     1     Mar     value value value
. . . . .
. . . . .
. . . . .
2     2     Jan     value value value
2     2     Feb     value value value
2     2     Mar     value value value

and so on.

I'd appreciate some code that would help accomplish this.
Since I'm not an R expert, code that is somewhat transparent
might be more helpful to me than the shortest possible 
option.

Thank you.


Toby Gass
Department of Forest, Rangeland, and Watershed Stewardship
Warner College of Natural Resources
Colorado State University
Fort Collins, CO  80523
Phone: 970-491-7257


From HStevens at MUOhio.edu  Wed Dec 20 22:20:52 2006
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Wed, 20 Dec 2006 16:20:52 -0500
Subject: [R] lme4 mcmcsamp matrix not PD
In-Reply-To: <40e66e0b0612200515h107f6b97k5f7b50384bb1d1db@mail.gmail.com>
References: <1276C0564833F043AB4C85ED8DA9CFE50117C36B@ctemail1.nioo.int>
	<A04C0FED-01D6-4A49-9066-01B9AA3A8B26@muohio.edu>
	<40e66e0b0612200515h107f6b97k5f7b50384bb1d1db@mail.gmail.com>
Message-ID: <8E2085D6-14F9-4706-B561-824F9E300135@MUOhio.edu>

Hi folks,
I am not providing a small replicable example, because I assume the  
problem is related to my quirky data (~650 obs.).
I am using the latest lme4, matrix and coda, and R 2.4.0.

I frequently get the following error message for this particular lmer  
model. I do not get this message for the vast majority of my uses of  
mcmcsamp.

I was wondering if it might be characteristic of particular kinds of  
problems.

 > modb <- lmer(log(basal+1) ~ nutrient*amd +  (1|rack) +  (1| 
gen:amd), data=dat.b2)

 > mod.mc <- mcmcsamp(modb, n=10^4)

Error: Matrix is not pd after safe_pd_matrix!
Error in t(.Call(mer_MCMCsamp, object, saveb, n, trans, verbose)) :
	error in evaluating the argument 'x' in selecting a method for  
function 't'

Cheers,
Hank

Dr. Hank Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/

"E Pluribus Unum"


From marion.echard at cirad.fr  Wed Dec 20 22:33:32 2006
From: marion.echard at cirad.fr (Marion Echard)
Date: Wed, 20 Dec 2006 18:33:32 -0300
Subject: [R] daisy() and agnes() output
Message-ID: <4589AC2C.8040707@cirad.fr>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20061220/8a6bc1c8/attachment.pl 

From h.wickham at gmail.com  Wed Dec 20 22:31:41 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 20 Dec 2006 13:31:41 -0800
Subject: [R] Reformat meteorological data
In-Reply-To: <001c01c72478$17a95fc0$03125281@Q11>
References: <001c01c72478$17a95fc0$03125281@Q11>
Message-ID: <f8e6ff050612201331r4fb632e1g3c731e142f6f11bb@mail.gmail.com>

Hi Toby,

Have a look at the reshape package, http://had.co.nz.

Code something like the following should do what you want:

library(reshape)
dfm <- melt(data, id=1:3)
dfm <- rename(dfm, c(variable = "month")) # to make it more obvious

cast(dfm, ... ~ var)

Hadley

On 12/20/06, Toby Gass <tobygass at warnercnr.colostate.edu> wrote:
> Dear HelpeRs:
>
> I have a data set in the following format,
> which will be familiar to those of you working
> with NCDC climate data.
>
> Example:
>
> Year <- rep(1:3, each = 3)
> Year <- c(Year,Year)
> ID <- rep(1:2, each = 9)
> Jan <- runif(18, min = 0, max = 20)
> Feb <- runif(18, min = 0, max = 20)
> Mar <- runif(18, min = 0, max = 20)
> var <- gl(3,1,18,label = c("snow","rain","temp"))
> data <-data.frame(row.names = c(1:18),ID, Year, var, Jan,
> Feb, Mar)
>
>
> The actual dataset has 12 months, about 100 years, 6 ID's,
> many more levels in "var", and includes NA's.
>
>
> I would like to convert the data to the following format:
>
> ID Year Month Rain Snow Temp
> 1     1     Jan     value  value value
> 1     1     Feb     value value value
> 1     1     Mar     value value value
> . . . . .
> . . . . .
> . . . . .
> 1     2     Jan     value value value
> 1     2     Feb     value value value
> 1     2     Mar     value value value
> . . . . . .
> . . . . . .
> . . . . . .
> 1     3     Jan     value value value
> 1     3     Feb     value value value
> 1     3     Mar     value value value
> . . . . . .
> . . . . . .
> 2     1     Jan     value value value
> 2     1     Feb     value value value
> 2     1     Mar     value value value
> . . . . .
> . . . . .
> . . . . .
> 2     2     Jan     value value value
> 2     2     Feb     value value value
> 2     2     Mar     value value value
>
> and so on.
>
> I'd appreciate some code that would help accomplish this.
> Since I'm not an R expert, code that is somewhat transparent
> might be more helpful to me than the shortest possible
> option.
>
> Thank you.
>
>
> Toby Gass
> Department of Forest, Rangeland, and Watershed Stewardship
> Warner College of Natural Resources
> Colorado State University
> Fort Collins, CO  80523
> Phone: 970-491-7257
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kuruvill at fas.harvard.edu  Wed Dec 20 22:36:50 2006
From: kuruvill at fas.harvard.edu (Finny Kuruvilla)
Date: Wed, 20 Dec 2006 16:36:50 -0500 (EST)
Subject: [R] mclust priors
Message-ID: <Pine.LNX.4.64.0612201626070.948@ls01.fas.harvard.edu>

I am currently exploring mclust to do clustering by Gaussian mixture
modeling.  There are typically 1-5 clusters in my datasets.

In the latest version of mclust (version 3), there is now the ability
to specify priors.  However, I am confused about the implementation.
I've read through the documentation about priorControl() and
defaultPrior() which describe the specification of a single prior for
a dataset.  But I often have a prior for all of my clusters -- how do
I specify that, i.e. give the program multiple means and multiple
covariance matrices for where I believe the clusters will be a priori?

Thanks,
Finny Kuruvilla

*****************************************************************
Finny Kuruvilla, MD, PhD
Harvard Medical School Fellowship Program in Transfusion Medicine
Broad Institute of MIT and Harvard
Homepage: http://www.people.fas.harvard.edu/~kuruvill/home/


From aajakh at yahoo.com  Wed Dec 20 23:41:43 2006
From: aajakh at yahoo.com (ahmad ajakh)
Date: Wed, 20 Dec 2006 14:41:43 -0800 (PST)
Subject: [R] writing R extension
Message-ID: <20061220224143.66979.qmail@web37915.mail.mud.yahoo.com>

Thanks Barry,
I tested this solution and it works. Thanks also to Sarah Goslee for bringing up
alternative ideas. I guess I need to get into building proper packages now.
AA.

----- Original Message ----
From: Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
Cc: r-help at stat.math.ethz.ch
Sent: Wednesday, December 20, 2006 12:31:09 PM
Subject: Re: [R] writing R extension

Sarah Goslee wrote:

> If that's still too complex, you could also save your function to a file
> and load it as needed with source(). That will give the user the
> same effect.
> 
> source("/path/to/my/stuff/myfiles.R")
> 
> Since you didn't tell us OS or anything else about your system,
> it's hard to be more specific.
> 

  Yikes No!

  That will load all the objects into the current workspace. If you save 
when you quit, you'll end up with umpteen copies of your package code!

  For simple bundles of functions, it would be better to use save() to 
save them all to a .RData-type file and then 'attach()' it. This way it 
doesn't get stuck in your workspace. So:

  > foo=function(x){x^2}
  > bar=function(y){y^6}
  > baz=function(z){z*3}

  > myFunctions=c("foo","bar","baz")
  > save(list=myFunctions,file="myFunctions.RData")

then quit R, start R in another workspace:

  > attach("/path/to/wherever/you/put/myFunctions.RData")
  > foo(2)
    [1] 4

  Building proper _packages_ (never call them 'libraries' - libraries 
are collections of packages) isn't that hard once you've done it a dozen 
times, although I'm starting the find the bondage and discipline of 
packaging R code getting to me.

Barry

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From auxsvr at yahoo.com  Thu Dec 21 00:19:02 2006
From: auxsvr at yahoo.com (MrJ Man)
Date: Wed, 20 Dec 2006 15:19:02 -0800 (PST)
Subject: [R] How to use strings from a data.frame as the argument of an
	expression() for plot
Message-ID: <944895.38974.qm@web56406.mail.re3.yahoo.com>

Greetings,

I would like to use a data.frame with strings to feed
the expression() in the title of a plot. The way I did
this is:

molecules
<-data.frame(name=c("o3","no","no2"),expression=c("quote(O[3])","quote(NO)","quote(NO[2])"))

for (mol in c(5,7,9)) {
 plot(x, y, type="b",
main=eval(substitute(expression(paste(mol," Year
2005")),
 
list(mol=eval(parse("",text=toString(molecules$expression[(mol-3)/2])))))))
}

However, this looks cumbersome and I'm sure there is a
way to do this in R that is much more simple. The
complexity of the expression above is mainly due to
the fact that the only way I could find to convert a
string read from a data.frame into a symbol was to
enclose it in "quote(symbol)" and call toString on the
result, since selecting string data from a data.frame
returns an object that is not a string (why is this
so? A data.frame with doubles returns doubles).

What do you think?

Thanks in advance.


From SBlanchard at coh.org  Thu Dec 21 00:26:48 2006
From: SBlanchard at coh.org (Blanchard, Suzette)
Date: Wed, 20 Dec 2006 15:26:48 -0800
Subject: [R] \Sexpr in MikTex
Message-ID: <309869D6EA32AB4A90722D8F74F892BB0C000ABC@EXCH-VS3.coh.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061220/f1a3111f/attachment.pl 

From HDoran at air.org  Thu Dec 21 00:29:25 2006
From: HDoran at air.org (Doran, Harold)
Date: Wed, 20 Dec 2006 18:29:25 -0500
Subject: [R] \Sexpr in MikTex
References: <309869D6EA32AB4A90722D8F74F892BB0C000ABC@EXCH-VS3.coh.org>
Message-ID: <2323A6D37908A847A7C32F1E3662C80E04E6C7@dc1ex01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061220/43686693/attachment.pl 

From ggrothendieck at gmail.com  Thu Dec 21 00:34:03 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 20 Dec 2006 18:34:03 -0500
Subject: [R] How to use strings from a data.frame as the argument of an
	expression() for plot
In-Reply-To: <944895.38974.qm@web56406.mail.re3.yahoo.com>
References: <944895.38974.qm@web56406.mail.re3.yahoo.com>
Message-ID: <971536df0612201534m779844eal4089adea53bdfce4@mail.gmail.com>

Try this:


e <- expression(O[3], NO, NO[2])
opar <- par(mfrow = c(2,2))
for(i in 1:3) plot(1, 1, type = "b", main = bquote(.(e[[i]]) ~ Year ~ 2005))
par(opar)

Also please read the last line to every post to r-help and particularly note
the part about reproducible examples.   x and y.were undefined.

On 12/20/06, MrJ Man <auxsvr at yahoo.com> wrote:
> Greetings,
>
> I would like to use a data.frame with strings to feed
> the expression() in the title of a plot. The way I did
> this is:
>
> molecules
> <-data.frame(name=c("o3","no","no2"),expression=c("quote(O[3])","quote(NO)","quote(NO[2])"))
>
> for (mol in c(5,7,9)) {
>  plot(x, y, type="b",
> main=eval(substitute(expression(paste(mol," Year
> 2005")),
>
> list(mol=eval(parse("",text=toString(molecules$expression[(mol-3)/2])))))))
> }
>
> However, this looks cumbersome and I'm sure there is a
> way to do this in R that is much more simple. The
> complexity of the expression above is mainly due to
> the fact that the only way I could find to convert a
> string read from a data.frame into a symbol was to
> enclose it in "quote(symbol)" and call toString on the
> result, since selecting string data from a data.frame
> returns an object that is not a string (why is this
> so? A data.frame with doubles returns doubles).
>
> What do you think?
>
> Thanks in advance.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From auxsvr at yahoo.com  Thu Dec 21 01:31:56 2006
From: auxsvr at yahoo.com (MrJ Man)
Date: Wed, 20 Dec 2006 16:31:56 -0800 (PST)
Subject: [R] How to use strings from a data.frame as the argument of an
	expression() for plot
Message-ID: <293762.68448.qm@web56406.mail.re3.yahoo.com>

Thanks for your response; one more thing: Is it
possible to use a data.frame 
for the same effect, as these values are associated
with some others (I could 
of course use them separately, but merging them in a
data.frame should be 
possible in R)?

> Try this:
>
>
> e <- expression(O[3], NO, NO[2])
> opar <- par(mfrow = c(2,2))
> for(i in 1:3) plot(1, 1, type = "b", main =
bquote(.(e[[i]]) ~ Year ~
> 2005)) par(opar)
>
> Also please read the last line to every post to
r-help and particularly
> note the part about reproducible examples.   x and
y.were undefined.
>


From jzhang1982 at gmail.com  Thu Dec 21 01:45:55 2006
From: jzhang1982 at gmail.com (Zhang Jian)
Date: Thu, 21 Dec 2006 08:45:55 +0800
Subject: [R] how to change the date (Year, Month,
	Day) to Julian date in R language?
Message-ID: <3f2938d50612201645u6b37ef58j6dd379d1bb0dba3d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061221/aeb6a6a8/attachment.pl 

From jholtman at gmail.com  Thu Dec 21 01:51:21 2006
From: jholtman at gmail.com (jim holtman)
Date: Wed, 20 Dec 2006 19:51:21 -0500
Subject: [R] how to change the date (Year, Month,
	Day) to Julian date in R language?
In-Reply-To: <3f2938d50612201645u6b37ef58j6dd379d1bb0dba3d@mail.gmail.com>
References: <3f2938d50612201645u6b37ef58j6dd379d1bb0dba3d@mail.gmail.com>
Message-ID: <644e1f320612201651y60a70a2au1dcfb92509fbfc9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061220/5fe0b40e/attachment.pl 

From wade.wall at gmail.com  Thu Dec 21 02:34:57 2006
From: wade.wall at gmail.com (Wade Wall)
Date: Wed, 20 Dec 2006 20:34:57 -0500
Subject: [R] lda plotting: labeling x axis and changing y-axis scale
Message-ID: <e23082be0612201734k7df2f15dvd99b24be722f3e35@mail.gmail.com>

Hi all,

I have performed an lda on two groups and have plotted using
plot(x.lda), with x.lda being my lda results.  I have forgotten how to
change the labels of the of the x-axes (they are currently listed as
Group1 and Group 13), and to rescale the y-axis to reflect frequency.
If anyone knows how to do it, I would greatly appreciate the
information.

Wade


From sdfrost at ucsd.edu  Thu Dec 21 01:53:25 2006
From: sdfrost at ucsd.edu (Simon Frost)
Date: Wed, 20 Dec 2006 16:53:25 -0800
Subject: [R] Spline models in sspir
Message-ID: <1166662405.4564.25.camel@penguin.local>

Dear R-Help,

I'm trying to learn the sspir package for state space modeling. Has
anyone coded a cubic spline smoother (continuous time) in state space
format in sspir? The syntax for setting up the various matrices would be
really helpful.

Best
Simon
-- 
Simon D.W. Frost, D.Phil.
Assistant Adjunct Professor of Pathology
University of California, San Diego
Mailcode 8208
UCSD Antiviral Research Center
150 W. Washington St.
San Diego, CA 92103
Tel: +1 619 543 8898
Fax: +1 619 543 5094
Email: sdfrost at ucsd.edu


From ggrothendieck at gmail.com  Thu Dec 21 03:19:56 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 20 Dec 2006 21:19:56 -0500
Subject: [R] How to use strings from a data.frame as the argument of an
	expression() for plot
In-Reply-To: <293762.68448.qm@web56406.mail.re3.yahoo.com>
References: <293762.68448.qm@web56406.mail.re3.yahoo.com>
Message-ID: <971536df0612201819x7251b911vc5028180f44840aa@mail.gmail.com>

Just store them as strings in the data frame and then perform a conversion
to expressions prior to the loop:


DF <- data.frame(s = c("O[3]", "NO", "NO[2]"), stringsAsFactors = FALSE)
e <- parse(text = DF$s)
... continue with prior solution ...

On 12/20/06, MrJ Man <auxsvr at yahoo.com> wrote:
> Thanks for your response; one more thing: Is it
> possible to use a data.frame
> for the same effect, as these values are associated
> with some others (I could
> of course use them separately, but merging them in a
> data.frame should be
> possible in R)?
>
> > Try this:
> >
> >
> > e <- expression(O[3], NO, NO[2])
> > opar <- par(mfrow = c(2,2))
> > for(i in 1:3) plot(1, 1, type = "b", main =
> bquote(.(e[[i]]) ~ Year ~
> > 2005)) par(opar)
> >
> > Also please read the last line to every post to
> r-help and particularly
> > note the part about reproducible examples.   x and
> y.were undefined.
> >
>
>
> __________________________________________________
> Do You Yahoo!?
> Tired of spam?  Yahoo! Mail has the best spam protection around
> http://mail.yahoo.com
>


From murdoch at stats.uwo.ca  Thu Dec 21 04:05:26 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 20 Dec 2006 22:05:26 -0500
Subject: [R] \Sexpr in MikTex
In-Reply-To: <309869D6EA32AB4A90722D8F74F892BB0C000ABC@EXCH-VS3.coh.org>
References: <309869D6EA32AB4A90722D8F74F892BB0C000ABC@EXCH-VS3.coh.org>
Message-ID: <4589F9F6.8080003@stats.uwo.ca>

On 12/20/2006 6:26 PM, Blanchard, Suzette wrote:
> Greetings,   \Sexpr{} has worked on MikTex with earlier versions of R, I can not seem to get it to work with
> R-2.4.0.  I run Sweave with MikTex using the following statement in Run under Accessories. 
> latex -include-directory="C:\Program Files\R\R-2.4.0\share\texmf" "C:\Documents and Settings\Suzette\Desktop\MyFile\MyProgram.tex"

There should be two hyphens in the option, i.e. --include-directory, 
shouldn't there?

This should be automatically put in place if you used

R CMD Sweave MyProgram.tex

from a command line.

Duncan Murdoch

>  
> Any advice would be much appreciated,
> Suzette
>  
>  
> Suzette Blanchard, Ph.D.
> Assistant Professor, Dept. of Biostatistics
> City of Hope National Medical Center
>   and Beckman Research Institute
> 1500 East Duarte Road, Duarte, CA 91010-3000
> sblanchard at coh.org <mailto:sblanchard at coh.org> 
> ph: (626) 256-4673 ext: 64446
>  
> 
> "EMF <COH.org>" made the following annotations.
> ------------------------------------------------------------------------------
> SECURITY/CONFIDENTIALITY WARNING:  This message and any atta...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From shubhak at ambaresearch.com  Thu Dec 21 05:54:22 2006
From: shubhak at ambaresearch.com (Shubha Vishwanath Karanth)
Date: Thu, 21 Dec 2006 10:24:22 +0530
Subject: [R] FW:  R Version Problem in using write.foreign+SAS
Message-ID: <A36876D3F8A5734FA84A4338135E7CC3B3E2A9@BAN-MAILSRV03.Amba.com>

Could I find a solution for this? Please please please... How can I
change the built in code of "foreign:::writeForeignSAS" for the format?

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Shubha Vishwanath
Karanth
Sent: Wednesday, December 20, 2006 6:06 PM
To: Shubha Karanth; r-help at stat.math.ethz.ch
Subject: Re: [R] R Version Problem in using write.foreign+SAS

Hi,

If I am using R 2.4.0, and work with write.foreign command, I get the
datetime format as 01Dec2006 00:00:00, because the built in function
(foreign:::writeForeignSAS) has the fixed format for Datetimes and the
format is "%d%b%Y %H:%M:%S". And that's the reason why I get the
datetime as 01Dec2006 00:00:00 instead of 2006-12-01 00:00:00.

So, R users, could I make this code flexible to use any datetime
formats? Also where could I see locate this code in the foreign package
itself?

Thank you,
Shubha.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Shubha Karanth
Sent: 20. joulukuuta 2006 17:15
To: r-help at stat.math.ethz.ch
Subject: [R] R Version Problem in using write.foreign+SAS

Hi experts,



I have a problem in Write.foreign command (SAS).



I have a data frame called d.

>d

 Datetime

2006-12-01 00:00:00

2006-12-01 00:10:00

2006-12-01 00:20:00

2006-12-01 00:30:00

2006-12-01 00:40:00

>class(d$Datetime)

[1] "POSIXt"  "POSIXct"



Then I tried with,



write.foreign(d,"Z:\\try_i.sas7bdat"," Z:\\try_i.sas
",package="SAS",dataname="g")



If I use R 2.4.0 version I get the below text file generated.



"01Dec2006 00:00:00"

"01Dec2006 00:10:00"

"01Dec2006 00:20:00"

"01Dec2006 00:30:00"

"01Dec2006 00:40:00"





If I use R 2.2.0 version I get the below text file generated.



2006-12-01 00:00:00

2006-12-01 00:10:00

2006-12-01 00:20:00

2006-12-01 00:30:00

2006-12-01 00:40:00





But I need to use R 2.4.0 and get the text file generated by R 2.2.0.





Could somebody help me on this?



Thank you.

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From biterbilen at yahoo.com  Thu Dec 21 06:40:09 2006
From: biterbilen at yahoo.com (biter bilen)
Date: Wed, 20 Dec 2006 21:40:09 -0800 (PST)
Subject: [R] call by reference
Message-ID: <20061221054010.13089.qmail@web52303.mail.yahoo.com>



a = 9
    b = 8
    print (a)
    print (b)
    fa<-function(bS, aV) {
            aV <<- 3
            assign(bS,3,env = .GlobalEnv)
    }
    fa("b", a)
    print (a) #9
    print (b) #3 #only this call is ok



----- Original Message ----
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
To: biter bilen <biterbilen at yahoo.com>
Cc: r-help at stat.math.ethz.ch
Sent: Wednesday, December 20, 2006 11:04:08 AM
Subject: Re: [R] call by reference

Can you tell us what you want to do with 'pass/call by reference'?

If you want an R function to alter its argument then it is possible 
(KalmanLike is an example), but it should only be possible via C code.
And if you know enough to do that, you probably would not be asking (and 
definitely not be asking on R-help rather than R-devel).

On Tue, 19 Dec 2006, biter bilen wrote:

> Can anyone help me about pass by reference of arguments in R functions?
>
> I have read about .Alias in base package however it is defunct and there 
> is no replacement for it.

That's not a fair summary of the help entry for .Alias.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tobias_elbert at hotmail.com  Thu Dec 21 07:06:28 2006
From: tobias_elbert at hotmail.com (Tobias)
Date: Wed, 20 Dec 2006 22:06:28 -0800 (PST)
Subject: [R] Problems with Optimization
Message-ID: <8003228.post@talk.nabble.com>


Dear R-helpers,

I am having following problem:

Let P be an observed quantity, F(...) a function describing P, and e = P -
F(...) the error. 

F(...) is essentially a truncated mean whose value is obtained via
integrating from some value X to inf over a probability density with six
parameters. That's what usually causes the problem: for certain parameter
values, the integral goes very quickly to infinity which the optimization
algorithm can't handle. At least nlm() and some of the optim() algorithms
cant. The default optim() algorithm appears to be able to handle it (takes
very long to converge though) and so is nlminb(). 

My question is thus not really about which algorithm to use but rather
whether there is a 'on error ... do...' catcher in R? I have had a look at
try() but I am not quite sure if that is what I am looking for. I
essentially look for a command that, in plain English, allows me to specify
that if the integral goes to infinity, skip these parameters, and simply
continue optimizing into another direction.

Is this possible? How do you guys handle situtations like this?


Regards

Tobias
-- 
View this message in context: http://www.nabble.com/Problems-with-Optimization-tf2863893.html#a8003228
Sent from the R help mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Thu Dec 21 07:23:47 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 21 Dec 2006 06:23:47 +0000 (GMT)
Subject: [R] Problems with Optimization
In-Reply-To: <8003228.post@talk.nabble.com>
References: <8003228.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0612210619260.11393@gannet.stats.ox.ac.uk>

On Wed, 20 Dec 2006, Tobias wrote:

>
> Dear R-helpers,
>
> I am having following problem:
>
> Let P be an observed quantity, F(...) a function describing P, and e = P -
> F(...) the error.
>
> F(...) is essentially a truncated mean whose value is obtained via
> integrating from some value X to inf over a probability density with six
> parameters. That's what usually causes the problem: for certain parameter
> values, the integral goes very quickly to infinity which the optimization
> algorithm can't handle. At least nlm() and some of the optim() algorithms
> cant. The default optim() algorithm appears to be able to handle it (takes
> very long to converge though) and so is nlminb().

>From the help page

      Function 'fn' can return 'NA' or 'Inf' if the function cannot be
      evaluated at the supplied value, but the initial value must have a
      computable finite value of 'fn'. (Except for method '"L-BFGS-B"'
      where the values should always be finite.)

so you are not being fair to the R developers (who were kind enough to 
both implement and document this).

> My question is thus not really about which algorithm to use but rather
> whether there is a 'on error ... do...' catcher in R? I have had a look at
> try() but I am not quite sure if that is what I am looking for. I
> essentially look for a command that, in plain English, allows me to specify
> that if the integral goes to infinity, skip these parameters, and simply
> continue optimizing into another direction.

Given that the underlying algorithms are in C not R, this is what 
returning NA asks them to do.

> Is this possible? How do you guys handle situtations like this?

In the documented way, returning NA.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tobias_elbert at hotmail.com  Thu Dec 21 07:37:59 2006
From: tobias_elbert at hotmail.com (Tobias)
Date: Wed, 20 Dec 2006 22:37:59 -0800 (PST)
Subject: [R] Problems with Optimization
In-Reply-To: <Pine.LNX.4.64.0612210619260.11393@gannet.stats.ox.ac.uk>
References: <8003228.post@talk.nabble.com>
	<Pine.LNX.4.64.0612210619260.11393@gannet.stats.ox.ac.uk>
Message-ID: <8003417.post@talk.nabble.com>


My apologies if this came across as unfair. This was by no means intended. I
find R to be a fantastic software and at least for my needs faster and more
comfortable to use than commercial ones such as Matlab. 

I am just wondering, because I implemented the same code on GAUSS and it
seemed to handle it a lot faster. I am by no means an expert on the
intrinsics of R or Gauss, simply a user, but if the algorithms are
implemented through C how come that it takes longer? Again, don't take this
as being unfair. I am just curious. 

...a puzzled Tobias  





Prof Brian Ripley wrote:
> 
> On Wed, 20 Dec 2006, Tobias wrote:
> 
>>
>> Dear R-helpers,
>>
>> I am having following problem:
>>
>> Let P be an observed quantity, F(...) a function describing P, and e = P
>> -
>> F(...) the error.
>>
>> F(...) is essentially a truncated mean whose value is obtained via
>> integrating from some value X to inf over a probability density with six
>> parameters. That's what usually causes the problem: for certain parameter
>> values, the integral goes very quickly to infinity which the optimization
>> algorithm can't handle. At least nlm() and some of the optim() algorithms
>> cant. The default optim() algorithm appears to be able to handle it
>> (takes
>> very long to converge though) and so is nlminb().
> 
>>From the help page
> 
>       Function 'fn' can return 'NA' or 'Inf' if the function cannot be
>       evaluated at the supplied value, but the initial value must have a
>       computable finite value of 'fn'. (Except for method '"L-BFGS-B"'
>       where the values should always be finite.)
> 
> so you are not being fair to the R developers (who were kind enough to 
> both implement and document this).
> 
>> My question is thus not really about which algorithm to use but rather
>> whether there is a 'on error ... do...' catcher in R? I have had a look
>> at
>> try() but I am not quite sure if that is what I am looking for. I
>> essentially look for a command that, in plain English, allows me to
>> specify
>> that if the integral goes to infinity, skip these parameters, and simply
>> continue optimizing into another direction.
> 
> Given that the underlying algorithms are in C not R, this is what 
> returning NA asks them to do.
> 
>> Is this possible? How do you guys handle situtations like this?
> 
> In the documented way, returning NA.
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Problems-with-Optimization-tf2863893.html#a8003417
Sent from the R help mailing list archive at Nabble.com.


From hb at stat.berkeley.edu  Thu Dec 21 08:45:41 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Thu, 21 Dec 2006 18:45:41 +1100
Subject: [R] call by reference
In-Reply-To: <20061220073758.69355.qmail@web52314.mail.yahoo.com>
References: <20061220073758.69355.qmail@web52314.mail.yahoo.com>
Message-ID: <59d7961d0612202345m4f9a6f07tf827be5c489ca0a0@mail.gmail.com>

There is no support for 'call by reference' in the S language, and
this is intentionally, but you can use environments to imitate it, cf.
?environment.  See also the R.oo package.

/Henrik

On 12/20/06, biter bilen <biterbilen at yahoo.com> wrote:
> Can anyone help me about pass by reference of arguments in R functions?
>
> I have read about .Alias in base package however it is defunct and there is no replacement for it.
>
> Thanks in advance.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From istoyanov at ecolab.bas.bg  Thu Dec 21 08:53:06 2006
From: istoyanov at ecolab.bas.bg (Ivailo Stoyanov)
Date: Thu, 21 Dec 2006 09:53:06 +0200
Subject: [R] Upgrading
In-Reply-To: <5b87605b5236.5b52365b8760@osu.edu>
References: <5b87605b5236.5b52365b8760@osu.edu>
Message-ID: <1166687586.5047.11.camel@localhost>

On Wed, 2006-12-20 at 11:37 -0500, DEEPANKAR BASU wrote:
> Thanks for the comments. I had got Thomas' message wrong the first time. Now, I have downloaded and re-installed the latest version of R. After reading the "administration and maintenance" manual, I added
> 
> deb http://cran.R-project.org/bin/linux/ubuntu dapper/
> 
> to my sources.list file and used apt-get to install the latest version. After the installation, I used update.packages() from with R to update all the packages. Let me know if this was what was required or I made some mistake. 
> 
> I have two questions:
> 1. When a new version of R is released (every 6 months or so I believe) will I have to uninstall the version of R in my machine and then download and install the latest version?
> 2. When I used update.packages() from within R (after installing the latest version), I still got the following warning messages:
> 
> Warning messages:
> 1: installation of package 'cluster' had non-zero exit status in: install.packages(update[, "Package"], instlib, contriburl = contriburl,
> 2: installation of package 'mgcv' had non-zero exit status in: install.packages(update[, "Package"], instlib, contriburl = contriburl,
> 3: cannot create HTML package index in: tools:::unix.packages.html(.Library)

The "cannot create HTML package index" message hints toward insufficient
privileges -- during "update.packages()" R should run with administrator
privileges, so you have to start it via "sudo R". The reason for the
other error messages could be also unavailable source packages due to
interrupted network connectivity, but generally the best approach is to
set up a larger number of scrollback lines in the terminal (the default
could be insufficient) and to inspect the output for the specific reason
for the "non-zero exit status". Please note, that you may also need
r-base-dev (along with some other) installed in order to successfully
compile any of the packages available at CRAN.

HTH,
Ivailo


From krcabrer at une.net.co  Thu Dec 21 08:53:41 2006
From: krcabrer at une.net.co (Kenneth Cabrera)
Date: Thu, 21 Dec 2006 02:53:41 -0500
Subject: [R] A problem with "copy()" in the svIO package
Message-ID: <op.tkwf7rv4lgnhok@davinci.une.net.co>

Hi R-users:

When I type the following code in R, using
the svIO package I got a problem only with
the "latex" type option.(With "raw", "ascii" and
"html" options, it works fine).

x<-1:50
copy('x', type='latex', objname='x')
Erro en file.info(fn <- c(...)) : argumento del nombre de archivo inv?lido

Thank you for your help.

Kenneth

--


From weigand.stephen at charter.net  Thu Dec 21 09:15:01 2006
From: weigand.stephen at charter.net (Stephen D. Weigand)
Date: Thu, 21 Dec 2006 02:15:01 -0600
Subject: [R] FW:  R Version Problem in using write.foreign+SAS
In-Reply-To: <A36876D3F8A5734FA84A4338135E7CC3B3E2A9@BAN-MAILSRV03.Amba.com>
References: <A36876D3F8A5734FA84A4338135E7CC3B3E2A9@BAN-MAILSRV03.Amba.com>
Message-ID: <4d4947a6959e0e53a99a216052b08d05@charter.net>

Shubha,

On Dec 20, 2006, at 10:54 PM, Shubha Vishwanath Karanth wrote:

> Could I find a solution for this? Please please please... How can I
> change the built in code of "foreign:::writeForeignSAS" for the format?

I tend not to change originals if I can help it, so I would create my 
own
version and call it writeForeignSAS2 as follows:

### Make a copy and write it out
writeForeignSAS2 <- foreign:::writeForeignSAS
dump("writeForeignSAS2", "writeForeignSAS2.R")
### Now make desired changes to the new version and then
### source it in
source("writeForeignSAS2.R")

### call write.foreign and specify your particular 'package'
write.foreign(df, datafile, codefile, package = "SAS2", ...)


> -----Original Message-----
> Sent: Wednesday, December 20, 2006 6:06 PM
> To: Shubha Karanth; r-help at stat.math.ethz.ch
> Subject: Re: [R] R Version Problem in using write.foreign+SAS
>
> Hi,
>
> If I am using R 2.4.0, and work with write.foreign command, I get the
> datetime format as 01Dec2006 00:00:00, because the built in function
> (foreign:::writeForeignSAS) has the fixed format for Datetimes and the
> format is "%d%b%Y %H:%M:%S". And that's the reason why I get the
> datetime as 01Dec2006 00:00:00 instead of 2006-12-01 00:00:00.
>
> So, R users, could I make this code flexible to use any datetime
> formats?

Probably not. As of SAS 9.13, the date part of a datetime
that SAS reads in has to be of the form ddmmmyy or ddmmmyyyy. That's
why this format is used in writeForeignSAS.  (I could joke about SAS
saving more flexible datetime formats and informats for version 10.)

Some more specifics below.

> Also where could I see locate this code in the foreign package
> itself?
>
> Thank you,
> Shubha.
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Shubha Karanth
> Sent: 20. joulukuuta 2006 17:15
> To: r-help at stat.math.ethz.ch
> Subject: [R] R Version Problem in using write.foreign+SAS
>
> Hi experts,
>
> I have a problem in Write.foreign command (SAS).
>
> I have a data frame called d.
>
>> d
>
>  Datetime
>
> 2006-12-01 00:00:00
> 2006-12-01 00:10:00
> 2006-12-01 00:20:00
> 2006-12-01 00:30:00
> 2006-12-01 00:40:00
>
>> class(d$Datetime)
>
> [1] "POSIXt"  "POSIXct"
>
> Then I tried with,
>
> write.foreign(d,"Z:\\try_i.sas7bdat"," Z:\\try_i.sas
> ",package="SAS",dataname="g")
>
> If I use R 2.4.0 version I get the below text file generated.
>
> "01Dec2006 00:00:00"
> "01Dec2006 00:10:00"
> "01Dec2006 00:20:00"
> "01Dec2006 00:30:00"
> "01Dec2006 00:40:00"

This is the only format for datetime variables SAS will understand.

> If I use R 2.2.0 version I get the below text file generated.
>
> 2006-12-01 00:00:00
> 2006-12-01 00:10:00
> 2006-12-01 00:20:00
> 2006-12-01 00:30:00
> 2006-12-01 00:40:00

In earlier versions of writeForeignSAS, the 'datafile' was written
out this way but the 'codefile' didn't treat the variable as a
datetime variable.

If you want the data written out in a certain format, you can
convert the variable to character with

d$mydatetime <- format(d$mydatetime)

But this means that the 'codefile' will tell SAS to read
the variable in as a character variable.

>
> But I need to use R 2.4.0 and get the text file generated by R 2.2.0.
>
> Could somebody help me on this?
>
> Thank you.
>


Stephen Weigand
Rochester, Minnesota, USA


From mark_difford at yahoo.co.uk  Thu Dec 21 10:53:18 2006
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Thu, 21 Dec 2006 09:53:18 +0000 (GMT)
Subject: [R] RuleFit & quantreg: partial dependence plots;
	showing an effect
Message-ID: <20061221095318.79150.qmail@web27303.mail.ukl.yahoo.com>

Dear Professors Koenker and Varadhan,

Thank you for your detailed and engaging replies.  The (very) muddy waters clear slowly, but only if I keep moving my hands!

Kind regards,
Mark Difford.
 
Mark Difford
Ph.D. candidate, Botany Department,
Nelson Mandela Metropolitan University,
Port Elizabeth, SA.

----- Original Message ----
From: roger koenker <rkoenker at uiuc.edu>
To: Mark Difford <mark_difford at yahoo.co.uk>
Cc: R-help list <r-help at stat.math.ethz.ch>
Sent: Wednesday, 20 December, 2006 3:57:02 PM
Subject: Re: [R] RuleFit & quantreg: partial dependence plots; showing an effect

They are entirely different:  Rulefit is a fiendishly clever  
combination of decision tree  formulation
of models and L1-regularization intended to select parsimonious fits  
to very complicated
responses yielding e.g. piecewise constant functions.  Rulefit   
estimates the  conditional
mean of the response over the covariate space, but permits a very  
flexible, but linear in
parameters specifications of the covariate effects on the conditional  
mean.  The quantile
regression plotting you refer to adopts a fixed, linear specification  
for conditional quantile
functions and given that specification depicts how the covariates  
influence the various
conditional quantiles of the response.   Thus, roughly speaking,  
Rulefit is focused on
flexibility in the x-space, maintaining the classical conditional  
mean objective; while
QR is trying to be more flexible in the y-direction, and maintaining  
a fixed, linear
in parameters specification for the covariate effects at each quantile.


url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Champaign, IL 61820


On Dec 20, 2006, at 4:17 AM, Mark Difford wrote:

> Dear List,
>
> I would greatly appreciate help on the following matter:
>
> The RuleFit program of Professor Friedman uses partial dependence  
> plots
> to explore the effect of an explanatory variable on the response
> variable, after accounting for the average effects of the other
> variables.  The plot method [plot(summary(rq(y ~ x1 + x2,
> t=seq(.1,.9,.05))))] of Professor Koenker's quantreg program  
> appears to
> do the same thing.
>
>
> Question:
> Is there a difference between these two types of plot in the manner  
> in which they depict the relationship between explanatory variables  
> and the response variable ?
>
> Thank you inav for your help.
>
> Regards,
> Mark Difford.
>
> -------------------------------------------------------------
> Mark Difford
> Ph.D. candidate, Botany Department,
> Nelson Mandela Metropolitan University,
> Port Elizabeth, SA.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.





Send instant messages to your online friends http://uk.messenger.yahoo.com


From ggrothendieck at gmail.com  Thu Dec 21 11:29:23 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 21 Dec 2006 05:29:23 -0500
Subject: [R] call by reference
In-Reply-To: <20061221054010.13089.qmail@web52303.mail.yahoo.com>
References: <20061221054010.13089.qmail@web52303.mail.yahoo.com>
Message-ID: <971536df0612210229p103302fascfde1b44ddfd79d1@mail.gmail.com>

You can do this:


   fb <- function(bS, env = parent.frame()) {
        bS <- deparse(substitute(bS))
        assign(bS, 3, env = env)
   }
   fb(bS)
   bS
   rm(bS)
  # or corresponding to your code
  fb(bS, env = .GlobalEnv)

Of course when typed in both give the same result since the global environment
is the parent frame.

Please use <- and = consistently and properly space your source code.

On 12/21/06, biter bilen <biterbilen at yahoo.com> wrote:
>
>
> a = 9
>    b = 8
>    print (a)
>    print (b)
>    fa<-function(bS, aV) {
>            aV <<- 3
>            assign(bS,3,env = .GlobalEnv)
>    }
>    fa("b", a)
>    print (a) #9
>    print (b) #3 #only this call is ok
>
>
>
> ----- Original Message ----
> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> To: biter bilen <biterbilen at yahoo.com>
> Cc: r-help at stat.math.ethz.ch
> Sent: Wednesday, December 20, 2006 11:04:08 AM
> Subject: Re: [R] call by reference
>
> Can you tell us what you want to do with 'pass/call by reference'?
>
> If you want an R function to alter its argument then it is possible
> (KalmanLike is an example), but it should only be possible via C code.
> And if you know enough to do that, you probably would not be asking (and
> definitely not be asking on R-help rather than R-devel).
>
> On Tue, 19 Dec 2006, biter bilen wrote:
>
> > Can anyone help me about pass by reference of arguments in R functions?
> >
> > I have read about .Alias in base package however it is defunct and there
> > is no replacement for it.
>
> That's not a fair summary of the help entry for .Alias.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From HDoran at air.org  Thu Dec 21 12:16:53 2006
From: HDoran at air.org (Doran, Harold)
Date: Thu, 21 Dec 2006 06:16:53 -0500
Subject: [R] \Sexpr in MikTex
References: <309869D6EA32AB4A90722D8F74F892BB0C000ABC@EXCH-VS3.coh.org>
	<4589F9F6.8080003@stats.uwo.ca>
Message-ID: <2323A6D37908A847A7C32F1E3662C80E04E6C9@dc1ex01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061221/b36b33f1/attachment.pl 

From b.otto at uke.uni-hamburg.de  Thu Dec 21 10:58:34 2006
From: b.otto at uke.uni-hamburg.de (Benjamin Otto)
Date: Thu, 21 Dec 2006 10:58:34 +0100
Subject: [R] Rotating a distribution plot by 90 degrees
Message-ID: <000701c724e6$96167280$336f12ac@matrix.com>

I forgot one thing:

Gregs example results in what I seek. However he has roteted the data in his
"mind" and in the data submitted to the plot command. What I would like to
know is whether I can use the "plot" command to make some normal plot and
add some second command which rotates the data for me...

Regards

Benjamin


-----Urspr?ngliche Nachricht-----
Von: Benjamin Otto [mailto:b.otto at uke.uni-hamburg.de] 
Gesendet: 21 December 2006 10:51
An: 'Greg Snow'; 'R-Help'; 'Knut Krueger'
Betreff: Re: [R] Rotating a distribution plot by 90 degrees

 
Hi Knut, hi Greg,

Thanks for the quick help!

@Greg:
Yes THAT?S exactly what I meant. Thanks for the example.

@Knut:
Thanks for the hint. However my problem was that the combination of "plot"
and grid wasn't working. But probably it isn't supposed to.

Regards
Benjamin


----------------------------------------------------------------------------
----

Knut wrote:

> Did you find these manuals for the Grid package?

> http://www.stat.auckland.ac.nz/~paul/grid/doc/rotated.pdf

> http://www.stat.auckland.ac.nz/~paul/grid/grid.html

> Regards Knut



-----Urspr?ngliche Nachricht-----
Von: Greg Snow [mailto:Greg.Snow at intermountainmail.org] 
Gesendet: 20 December 2006 20:34
An: Benjamin Otto; R-Help
Betreff: RE: [R] Rotating a distribution plot by 90 degrees

Does the following code do what you want?

x <- c( rnorm(50,10,2), rnorm(30,20,2) ) y <- 2+3*x + rnorm(80)

d.x <- density(x)
d.y <- density(y)

layout( matrix( c(0,2,2,1,3,3,1,3,3),ncol=3) )

plot(d.x$x, d.x$y, xlim=range(x), type='l') plot(d.y$y, d.y$x,
ylim=range(y), xlim=rev(range(d.y$y)), type='l') plot(x,y, xlim=range(x),
ylim=range(y) )

If not, be more specific in describing what you want.

Hope this helps,


--
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Benjamin Otto
Sent: Wednesday, December 20, 2006 3:55 AM
To: R-Help
Subject: [R] Rotating a distribution plot by 90 degrees

Hi,

Can I rotate a plot (e.g. a distribution plot) by 90 degrees? The
barplot function provides the "horiz" command but that's not availeable
for the base package functions. I found an old advice from Paul Murrell
on a similar problem suggesting to use viewports (grid package). Yet I
couldn't reproduce his examples successfully. And going through the
examples in the current grid package help pages left me with the feeling
that viewport and the plot/points function don't match because the
latter automatically clears the old device.

Is there some way to rotate a "plot" at all or am I forced to use the
barplot function instead?

Regards,

Benjamin


P.S.: For further explanation: I would like to plot something like

+-----+-----+
|     |     |
|  0  |  1  |
|     |     |
+-----+-----+
|     |     |
|  2  |  3  |
|     |     |
+-----+-----+

where image 1 is some function plot in normal mode, image 2 is a
function plot rotated by 90 degrees and image 3 is something depending
on the two functions.


--
Benjamin Otto
Universitaetsklinikum Eppendorf Hamburg
Institut fuer Klinische Chemie
Martinistrasse 52
20246 Hamburg

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From b.otto at uke.uni-hamburg.de  Thu Dec 21 10:50:49 2006
From: b.otto at uke.uni-hamburg.de (Benjamin Otto)
Date: Thu, 21 Dec 2006 10:50:49 +0100
Subject: [R] Rotating a distribution plot by 90 degrees
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBB739EB6@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <000601c724e5$8148efa0$336f12ac@matrix.com>

 
Hi Knut, hi Greg,

Thanks for the quick help!

@Greg:
Yes THAT?S exactly what I meant. Thanks for the example.

@Knut:
Thanks for the hint. However my problem was that the combination of "plot"
and grid wasn't working. But probably it isn't supposed to.

Regards 
Benjamin


----------------------------------------------------------------------------
----

Knut wrote:

> Did you find these manuals for the Grid package?

> http://www.stat.auckland.ac.nz/~paul/grid/doc/rotated.pdf

> http://www.stat.auckland.ac.nz/~paul/grid/grid.html

> Regards Knut



-----Urspr?ngliche Nachricht-----
Von: Greg Snow [mailto:Greg.Snow at intermountainmail.org] 
Gesendet: 20 December 2006 20:34
An: Benjamin Otto; R-Help
Betreff: RE: [R] Rotating a distribution plot by 90 degrees

Does the following code do what you want?

x <- c( rnorm(50,10,2), rnorm(30,20,2) ) y <- 2+3*x + rnorm(80)

d.x <- density(x)
d.y <- density(y)

layout( matrix( c(0,2,2,1,3,3,1,3,3),ncol=3) )

plot(d.x$x, d.x$y, xlim=range(x), type='l') plot(d.y$y, d.y$x,
ylim=range(y), xlim=rev(range(d.y$y)), type='l') plot(x,y, xlim=range(x),
ylim=range(y) )

If not, be more specific in describing what you want.

Hope this helps,


--
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Benjamin Otto
Sent: Wednesday, December 20, 2006 3:55 AM
To: R-Help
Subject: [R] Rotating a distribution plot by 90 degrees

Hi,

Can I rotate a plot (e.g. a distribution plot) by 90 degrees? The
barplot function provides the "horiz" command but that's not availeable
for the base package functions. I found an old advice from Paul Murrell
on a similar problem suggesting to use viewports (grid package). Yet I
couldn't reproduce his examples successfully. And going through the
examples in the current grid package help pages left me with the feeling
that viewport and the plot/points function don't match because the
latter automatically clears the old device.

Is there some way to rotate a "plot" at all or am I forced to use the
barplot function instead?

Regards,

Benjamin


P.S.: For further explanation: I would like to plot something like

+-----+-----+
|     |     |
|  0  |  1  |
|     |     |
+-----+-----+
|     |     |
|  2  |  3  |
|     |     |
+-----+-----+

where image 1 is some function plot in normal mode, image 2 is a
function plot rotated by 90 degrees and image 3 is something depending
on the two functions.


--
Benjamin Otto
Universitaetsklinikum Eppendorf Hamburg
Institut fuer Klinische Chemie
Martinistrasse 52
20246 Hamburg

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From fjmolina at soe.ucsc.edu  Thu Dec 21 13:38:34 2006
From: fjmolina at soe.ucsc.edu (fjmolina at soe.ucsc.edu)
Date: Thu, 21 Dec 2006 04:38:34 -0800 (PST)
Subject: [R] Add line to plot. The line falls outside the current plot.
Message-ID: <39829.88.1.173.10.1166704714.squirrel@webmail.soe.ucsc.edu>

Hi,

I have plotted the graph of x^2 and I would like to add to
it a line that is currently outside of the plot ( the points of the line
fall outside of the plot ). When I use the function 'lines' the graphics
window does not became larger to show this line.

Is there any way I can fix this?

Also, how can I eliminate the axis from the plot?

Thank you.


From j.zutt at tudelft.nl  Thu Dec 21 13:51:43 2006
From: j.zutt at tudelft.nl (Jonne Zutt)
Date: Thu, 21 Dec 2006 13:51:43 +0100
Subject: [R] Add line to plot. The line falls outside the current plot.
In-Reply-To: <39829.88.1.173.10.1166704714.squirrel@webmail.soe.ucsc.edu>
References: <39829.88.1.173.10.1166704714.squirrel@webmail.soe.ucsc.edu>
Message-ID: <1166705503.32580.2.camel@dutiih.st.ewi.tudelft.nl>


Use xlim and ylim to your call to plot (see ?plot and ?par).
So, plot(..your.parameters.., xlim=c(minx, maxx), ylim=c(miny,maxy))

Replace minx,maxx,miny,maxy by numbers.
Usually, the function range() comes in very handy here, see ?range

Jonne.

On Thu, 2006-12-21 at 04:38 -0800, fjmolina at soe.ucsc.edu wrote:
> Hi,
> 
> I have plotted the graph of x^2 and I would like to add to
> it a line that is currently outside of the plot ( the points of the line
> fall outside of the plot ). When I use the function 'lines' the graphics
> window does not became larger to show this line.
> 
> Is there any way I can fix this?
> 
> Also, how can I eliminate the axis from the plot?
> 
> Thank you.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From iriskolder at yahoo.com  Thu Dec 21 14:07:08 2006
From: iriskolder at yahoo.com (Iris Kolder)
Date: Thu, 21 Dec 2006 05:07:08 -0800 (PST)
Subject: [R] Memory problem on a linux cluster using a large data set
	[Broadcast]
Message-ID: <20061221130709.60458.qmail@web51704.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061221/7b8ab520/attachment.pl 

From murdoch at stats.uwo.ca  Thu Dec 21 14:31:47 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 21 Dec 2006 08:31:47 -0500
Subject: [R] \Sexpr in MikTex
In-Reply-To: <4589F9F6.8080003@stats.uwo.ca>
References: <309869D6EA32AB4A90722D8F74F892BB0C000ABC@EXCH-VS3.coh.org>
	<4589F9F6.8080003@stats.uwo.ca>
Message-ID: <458A8CC3.7010706@stats.uwo.ca>

Wow, that's a lot of errors in my post.  Sorry about that.  You should 
probably just ignore it completely.

Duncan Murdoch

On 12/20/2006 10:05 PM, Duncan Murdoch wrote:
> On 12/20/2006 6:26 PM, Blanchard, Suzette wrote:
>> Greetings,   \Sexpr{} has worked on MikTex with earlier versions of R, I can not seem to get it to work with
>> R-2.4.0.  I run Sweave with MikTex using the following statement in Run under Accessories. 
>> latex -include-directory="C:\Program Files\R\R-2.4.0\share\texmf" "C:\Documents and Settings\Suzette\Desktop\MyFile\MyProgram.tex"
> 
> There should be two hyphens in the option, i.e. --include-directory, 
> shouldn't there?
> 
> This should be automatically put in place if you used
> 
> R CMD Sweave MyProgram.tex
> 
> from a command line.
> 
> Duncan Murdoch
> 
>>  
>> Any advice would be much appreciated,
>> Suzette
>>  
>>  
>> Suzette Blanchard, Ph.D.
>> Assistant Professor, Dept. of Biostatistics
>> City of Hope National Medical Center
>>   and Beckman Research Institute
>> 1500 East Duarte Road, Duarte, CA 91010-3000
>> sblanchard at coh.org <mailto:sblanchard at coh.org> 
>> ph: (626) 256-4673 ext: 64446
>>  
>> 
>> "EMF <COH.org>" made the following annotations.
>> ------------------------------------------------------------------------------
>> SECURITY/CONFIDENTIALITY WARNING:  This message and any atta...{{dropped}}
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From meinhardploner at gmx.net  Thu Dec 21 14:34:13 2006
From: meinhardploner at gmx.net (Meinhard Ploner)
Date: Thu, 21 Dec 2006 14:34:13 +0100
Subject: [R] where is the source code of bca.ci?
Message-ID: <2239EE16-8CD6-44C0-B3FC-63CB89D2FF19@gmx.net>

i was searching for the source of bca.ci, a function of the package  
boot. I tried

require(boot, keep.source=TRUE)

but again the source was not viewable. How should i do?
Best regards

Meinhard Ploner

----------------
PS
 > version
                _
platform       i386-apple-darwin8.8.1
arch           i386
os             darwin8.8.1
system         i386, darwin8.8.1
status
major          2
minor          4.0
year           2006
month          10
day            03
svn rev        39566
language       R
version.string R version 2.4.0 (2006-10-03)


From dusa.adrian at gmail.com  Thu Dec 21 14:42:52 2006
From: dusa.adrian at gmail.com (Adrian Dusa)
Date: Thu, 21 Dec 2006 15:42:52 +0200
Subject: [R] how to replace some objects?
In-Reply-To: <2B79EAB2-3D67-4FD6-ABD0-BBA573495E20@virginia.edu>
References: <3f2938d50612190005h2b0f56c0h952e19f53081b944@mail.gmail.com>
	<2B79EAB2-3D67-4FD6-ABD0-BBA573495E20@virginia.edu>
Message-ID: <200612211542.52419.dusa.adrian@gmail.com>

On Tuesday 19 December 2006 13:49, Michael Kubovy wrote:
> On Dec 19, 2006, at 3:05 AM, Zhang Jian wrote:
> > I want to replace some objects in one row or column.For example,
> > One colume: a,b,a,c,b,b,a,a,c.
> > I want to replace "a" with "1", "b" with "2", and "c" with "3".
> > Like this: 1,2,1,3,2,2,1,1,3.
>
> let <- c('a', 'b', 'a', 'c', 'b', 'b', 'a', 'a', 'c')
> library(car)
> num <- recode(let, " 'a' = 1; 'b' = 2; else = 3 ")

Or, since the initial vector has letters only:
> as.numeric(factor(let))
[1] 1 2 1 3 2 2 1 1 3

Hth,
Adrian

-- 
Adrian Dusa
Romanian Social Data Archive
1, Schitu Magureanu Bd
050025 Bucharest sector 5
Romania
Tel./Fax: +40 21 3126618 \
          +40 21 3120210 / int.101


From rreiss at exponent.com  Thu Dec 21 14:45:36 2006
From: rreiss at exponent.com (Richard Reiss)
Date: Thu, 21 Dec 2006 05:45:36 -0800
Subject: [R] Poisson mixed effects model
Message-ID: <CF13ED94B9C31B469D7F9249FD93679801738DF5@EXCHANGE0.exponent.com>



Hello,

I am fitting a Poisson mixed effects model.  I have the number of eggs
(Eggs) laid by a quail and looking at the effect of dosage of a chemical
(Dose) in the study.  I have counts of eggs laid by week of the study,
so I am including the week number (Week) as a random effect.  I'm using
the lme4 package.

I have,

> mod1 <- lmer(Eggs~Dose + (1|Week),family=poisson)
> summary(mod1)
Generalized linear mixed model fit using PQL 
Formula: Eggs ~ Dose + (1 | Week) 
 Family: poisson(log link)
   AIC   BIC logLik deviance
 112.2 117.8 -53.11    106.2
Random effects:
 Groups Name        Variance Std.Dev.
 Week   (Intercept) 0.011693 0.10813 
number of obs: 48, groups: Week, 12

Estimated scale (compare to 1)  1.339789 

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)    
(Intercept)  4.699e+00  3.656e-02  128.53   <2e-16 ***
Dose        -4.768e-04  4.177e-05  -11.41   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Correlation of Fixed Effects:
     (Intr)
Dose -0.324


My problem is that I need to find the lower limit on the dose that
causes a 10% effect.  I can get the dose that causes a 10% effect, but
getting the lower-limit is not straightforward.  Thus, I have
reparameterized the model in terms of this dosage and want to re-fit.
The reparameterized model is:

Log(E(Eggs)) = A - (B/A*0.1)*Dose

where E(Eggs) is the expected value from the Poisson distribution, A is
the intercept and B is the dose causing a 10% reduction.  Is it possible
to directly fit A and B in this case within lmer (and other R models)?
I don't see how to code this? Can someone point me to documentation that
shows how to do this?

Thanks.

Rick


From ccleland at optonline.net  Thu Dec 21 14:48:23 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 21 Dec 2006 08:48:23 -0500
Subject: [R] where is the source code of bca.ci?
In-Reply-To: <2239EE16-8CD6-44C0-B3FC-63CB89D2FF19@gmx.net>
References: <2239EE16-8CD6-44C0-B3FC-63CB89D2FF19@gmx.net>
Message-ID: <458A90A7.3090309@optonline.net>

Meinhard Ploner wrote:
> i was searching for the source of bca.ci, a function of the package  
> boot. I tried
> 
> require(boot, keep.source=TRUE)
> 
> but again the source was not viewable. How should i do?

  If you download the source package
(http://cran.at.r-project.org/src/contrib/boot_1.2-27.tar.gz) and unpack
the compressed archive, you will see the bca.ci function in the file
called bootfuns.q .

> Best regards
> 
> Meinhard Ploner
> 
> ----------------
> PS
>  > version
>                 _
> platform       i386-apple-darwin8.8.1
> arch           i386
> os             darwin8.8.1
> system         i386, darwin8.8.1
> status
> major          2
> minor          4.0
> year           2006
> month          10
> day            03
> svn rev        39566
> language       R
> version.string R version 2.4.0 (2006-10-03)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From marc_schwartz at comcast.net  Thu Dec 21 14:48:57 2006
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 21 Dec 2006 07:48:57 -0600
Subject: [R] where is the source code of bca.ci?
In-Reply-To: <2239EE16-8CD6-44C0-B3FC-63CB89D2FF19@gmx.net>
References: <2239EE16-8CD6-44C0-B3FC-63CB89D2FF19@gmx.net>
Message-ID: <1166708937.4700.98.camel@localhost.localdomain>

On Thu, 2006-12-21 at 14:34 +0100, Meinhard Ploner wrote:
> i was searching for the source of bca.ci, a function of the package  
> boot. I tried
> 
> require(boot, keep.source=TRUE)
> 
> but again the source was not viewable. How should i do?
> Best regards
> 
> Meinhard Ploner

You can see a "representation" of the source code by using:

  boot:::bca.ci

For more information on the ":::" syntax see ?":::"

The "true" source code would be in the boot package tarball, available
from a CRAN mirror (eg.):

  http://cran.r-project.org/src/contrib/Descriptions/boot.html

HTH,

Marc Schwartz


From meinhardploner at gmx.net  Thu Dec 21 14:52:32 2006
From: meinhardploner at gmx.net (Meinhard Ploner)
Date: Thu, 21 Dec 2006 14:52:32 +0100
Subject: [R] where is the source code of bca.ci?
In-Reply-To: <458A90A7.3090309@optonline.net>
References: <2239EE16-8CD6-44C0-B3FC-63CB89D2FF19@gmx.net>
	<458A90A7.3090309@optonline.net>
Message-ID: <65ADFD78-47AB-4A41-9BC0-6A074BBEE77E@gmx.net>

Chuck and Marc,
thanks for the good answers!
MP

On Dec 21, 2006, at 2:48 PM, Chuck Cleland wrote:

> Meinhard Ploner wrote:
>> i was searching for the source of bca.ci, a function of the package
>> boot. I tried
>>
>> require(boot, keep.source=TRUE)
>>
>> but again the source was not viewable. How should i do?
>
>   If you download the source package
> (http://cran.at.r-project.org/src/contrib/boot_1.2-27.tar.gz) and  
> unpack
> the compressed archive, you will see the bca.ci function in the file
> called bootfuns.q .
>
>> Best regards
>>
>> Meinhard Ploner
>>
>> ----------------
>> PS
>>> version
>>                 _
>> platform       i386-apple-darwin8.8.1
>> arch           i386
>> os             darwin8.8.1
>> system         i386, darwin8.8.1
>> status
>> major          2
>> minor          4.0
>> year           2006
>> month          10
>> day            03
>> svn rev        39566
>> language       R
>> version.string R version 2.4.0 (2006-10-03)
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> -- 
> Chuck Cleland, Ph.D.
> NDRI, Inc.
> 71 West 23rd Street, 8th floor
> New York, NY 10010
> tel: (212) 845-4495 (Tu, Th)
> tel: (732) 512-0171 (M, W, F)
> fax: (917) 438-0894


From ripley at stats.ox.ac.uk  Thu Dec 21 14:55:02 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 21 Dec 2006 13:55:02 +0000 (GMT)
Subject: [R] where is the source code of bca.ci?
In-Reply-To: <2239EE16-8CD6-44C0-B3FC-63CB89D2FF19@gmx.net>
References: <2239EE16-8CD6-44C0-B3FC-63CB89D2FF19@gmx.net>
Message-ID: <Pine.LNX.4.64.0612211353010.27813@gannet.stats.ox.ac.uk>

On Thu, 21 Dec 2006, Meinhard Ploner wrote:

> i was searching for the source of bca.ci, a function of the package
> boot. I tried

Actually only of the namespace 'boot'.

> require(boot, keep.source=TRUE)
>
> but again the source was not viewable. How should i do?

This is discussed in a recent R NEWS.  Note that

> boot:::bca.ci
> getAnywhere("bca.ci")

both work.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jrkrideau at yahoo.ca  Thu Dec 21 15:08:29 2006
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 21 Dec 2006 09:08:29 -0500 (EST)
Subject: [R] Add line to plot. The line falls outside the current plot.
In-Reply-To: <39829.88.1.173.10.1166704714.squirrel@webmail.soe.ucsc.edu>
Message-ID: <423890.93745.qm@web32815.mail.mud.yahoo.com>


--- fjmolina at soe.ucsc.edu wrote:

> Also, how can I eliminate the axis from the plot?

?plot.default  

axes=FALSE

?par
xast="n"


From uka at sam.sdu.dk  Thu Dec 21 15:15:43 2006
From: uka at sam.sdu.dk (Ulrich Kaiser)
Date: Thu, 21 Dec 2006 15:15:43 +0100
Subject: [R] data -> data matrix that can be used in regressions
Message-ID: <1891181E17AFC84989C9E7FB98C28D27719572@ADM-EXCH0C.adm.c.sdu.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061221/dc781154/attachment.pl 

From jrkrideau at yahoo.ca  Thu Dec 21 15:36:33 2006
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 21 Dec 2006 09:36:33 -0500 (EST)
Subject: [R] data -> data matrix that can be used in regressions
In-Reply-To: <1891181E17AFC84989C9E7FB98C28D27719572@ADM-EXCH0C.adm.c.sdu.dk>
Message-ID: <20061221143633.3252.qmail@web32815.mail.mud.yahoo.com>


--- Ulrich Kaiser <uka at sam.sdu.dk> wrote:

> Dear R users,

> I have spent most of this day figuring out how to
> read STATA data into R
> (which eventually worked) and to run a simple OLS
> regression. It seems
> that the manuals are written in the most general and
> abstract way which
> does not really make it easy to understand what's
> going on.
>
> I'd be glad if somebody could save my day by:
> 
>  
> 
> telling me how to define a matrix from the variables
> I read into R's
> memory, supposing that the variable are "lkiosk" and
> "lvisits".

Mymatrix <- cbind(lkiosk,lvisits)

Do a class(Mymatrix) to check this.

You might find a simple tutorial like
http://www.math.ilstu.edu/dhkim/Rstuff/Rtutor.html to
be of help. I certainly have.


From f.harrell at vanderbilt.edu  Thu Dec 21 15:50:27 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 21 Dec 2006 08:50:27 -0600
Subject: [R] Penalized Canonical Variates
Message-ID: <458A9F33.6010207@vanderbilt.edu>

In the excellent paper by Hastie, Buja, and Tibshirani "Penalized 
Discriminant Analysis" the authors developed penalized discriminant 
functions that incorporated shrinkage on the predictor parameters.  This 
is a shrunken version of a canonical correlation analysis in which dummy 
variables appear on the left hand side.  Canonical variates are 
frequently overfitted and in some cases shrinkage is needed 
simultaneously on the left and right hand sides.  For example, one may 
have a multi-group discrimination problem where some of the groups have 
low frequencies and need to borrow information from the other groups. 
As another example, if one generated data from the linear model Y = X + 
residual and found optimum transformations of X and Y that maximized R^2 
  using canonical variates allowing for quadratic transformations, a b c 
d are solved for in the multivariate regression aY^2 + bY = cX^2 + dX. 
  Without penalization, the fitted model will be too nonlinear for small 
sample sizes.  Penalizing nonlinear terms would help.  Does anyone know 
of a method or code that does both-sides penalization for canonical 
variates (multivariate least-squares regression)?

Thanks
Frank
-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From basu.15 at osu.edu  Thu Dec 21 16:10:40 2006
From: basu.15 at osu.edu (DEEPANKAR BASU)
Date: Thu, 21 Dec 2006 10:10:40 -0500
Subject: [R] Upgrading
Message-ID: <75a707756ff3.756ff375a707@osu.edu>

Thanks for the suggestions; they resolved the problems. First I installed r-base-dev and then started R via sudo R. Now, when I used update.packages(), the process completed without any warning messages.

Deepankar

----- Original Message -----
From: Ivailo Stoyanov <istoyanov at ecolab.bas.bg>
Date: Thursday, December 21, 2006 2:53 am
Subject: Re: [R] Upgrading

> On Wed, 2006-12-20 at 11:37 -0500, DEEPANKAR BASU wrote:
> > Thanks for the comments. I had got Thomas' message wrong the 
> first time. Now, I have downloaded and re-installed the latest 
> version of R. After reading the "administration and maintenance" 
> manual, I added
> > 
> > deb http://cran.R-project.org/bin/linux/ubuntu dapper/
> > 
> > to my sources.list file and used apt-get to install the latest 
> version. After the installation, I used update.packages() from with 
> R to update all the packages. Let me know if this was what was 
> required or I made some mistake. 
> > 
> > I have two questions:
> > 1. When a new version of R is released (every 6 months or so I 
> believe) will I have to uninstall the version of R in my machine 
> and then download and install the latest version?
> > 2. When I used update.packages() from within R (after installing 
> the latest version), I still got the following warning messages:
> > 
> > Warning messages:
> > 1: installation of package 'cluster' had non-zero exit status in: 
> install.packages(update[, "Package"], instlib, contriburl = 
> contriburl,> 2: installation of package 'mgcv' had non-zero exit 
> status in: install.packages(update[, "Package"], instlib, 
> contriburl = contriburl,
> > 3: cannot create HTML package index in: 
> tools:::unix.packages.html(.Library)
> The "cannot create HTML package index" message hints toward 
> insufficientprivileges -- during "update.packages()" R should run 
> with administrator
> privileges, so you have to start it via "sudo R". The reason for the
> other error messages could be also unavailable source packages due to
> interrupted network connectivity, but generally the best approach 
> is to
> set up a larger number of scrollback lines in the terminal (the 
> defaultcould be insufficient) and to inspect the output for the 
> specific reason
> for the "non-zero exit status". Please note, that you may also need
> r-base-dev (along with some other) installed in order to successfully
> compile any of the packages available at CRAN.
> 
> HTH,
> Ivailo
> 
>


From ggrothendieck at gmail.com  Thu Dec 21 16:17:03 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 21 Dec 2006 10:17:03 -0500
Subject: [R] data -> data matrix that can be used in regressions
In-Reply-To: <1891181E17AFC84989C9E7FB98C28D27719572@ADM-EXCH0C.adm.c.sdu.dk>
References: <1891181E17AFC84989C9E7FB98C28D27719572@ADM-EXCH0C.adm.c.sdu.dk>
Message-ID: <971536df0612210717ya4deb0fg4cceb7d8e94d2b90@mail.gmail.com>

Do a google search for

   cran contributed documentation

and at the first hit you will find numerous introductions that may be
of use to you.

Also read the last line of every post to r-help.

On 12/21/06, Ulrich Kaiser <uka at sam.sdu.dk> wrote:
> Dear R users,
>
>
>
> I have spent most of this day figuring out how to read STATA data into R
> (which eventually worked) and to run a simple OLS regression. It seems
> that the manuals are written in the most general and abstract way which
> does not really make it easy to understand what's going on.
>
>
>
> I'd be glad if somebody could save my day by:
>
>
>
> telling me how to define a matrix from the variables I read into R's
> memory, supposing that the variable are "lkiosk" and "lvisits".
>
>
>
> Thank you very much!
>
>
>
> Best regards,
>
>
>
> Uli
>
>
>
>
>
> ***********************************************************
>
> Ulrich Kaiser, Dr. rer. pol.
>
> Professor of Econometrics and its Applications
>
> Dept. of Business and Economics
>
> University of Southern Denmark at Odense
>
> Campusvej 55
>
> 5230 Odense M
>
> Phone: +45 6550 3363
>
> Fax: +45 6615 8790
>
> http://www.sam.sdu.dk/staff/uka
>
>
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pbruce at statistics.com  Thu Dec 21 16:30:36 2006
From: pbruce at statistics.com (Peter C. Bruce)
Date: Thu, 21 Dec 2006 10:30:36 -0500
Subject: [R] Online course - Modeling in R
Message-ID: <6.1.0.6.2.20061221102415.04e79ec0@mail.statistics.com>

Drs. Brian Everitt and Torsten Hothorn will present their online course 
"Modeling in R" at statistics.com Jan. 19 - Feb. 16.   Participants can ask 
questions and exchange comments with Drs. Everitt and Hothorn via a private 
discussion board throughout the period.

In this course you learn how to use R to build statistical models and use 
them to analyze data. Multiple regression is covered first, then logistic 
regression and the generalized linear model (multiple regression and 
logistic regression illustrated as special cases). The Poisson model for 
count data, and the concept of overdispersion are also covered. You learn 
how to analyze longitudinal data using straightforward graphics and simple 
inferential approaches, then mixed-effects models and the generalized 
estimating approach for such data. The course emphasizes how to fit the 
models listed and interpret results, rather than how to derive the 
theoretical background of the models.

Brian Everitt and Torsten Hothorn are the authors of "A Handbook of 
Statistical Analyses Using R."  Brian Everitt is Professor Emeritus, King's 
College, London, and author of more than 50 books on statistics, including 
"Applied Multivariate Analysis" and "Statistical Aspects of the Design and 
Analysis of Clinical Trials."  Torsten Hothorn is Lecturer of Statistics at 
the Institut fur Medizininformatik, Biometrie und Epidemiologie, 
Friedrich-Alexander-Universitat, Erlangen-Nurnberg, Germany, and the author 
of over 4 dozen scholarly papers in peer-reviewed journals and other 
publications.

Details/prerequisites:
http://www.statistics.com/courses/modelingr/

The course takes place online at statistics.com in a series of 4 weekly 
lessons and assignments, and requires about 7-15 hours/week. Participate at 
your own convenience; there are no set times when you are required to be 
online.

Peter Bruce
pbruce at statistics.com


From Greg.Snow at intermountainmail.org  Thu Dec 21 16:50:20 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 21 Dec 2006 08:50:20 -0700
Subject: [R] Rotating a distribution plot by 90 degrees
Message-ID: <07E228A5BE53C24CAD490193A7381BBB739F81@LP-EXCHVS07.CO.IHC.COM>

The gridBase package supports the mixing of traditional graphs in grid viewports, that may do what you want (But I am not a grid expert, so can't tell you anything more on that).  You could also create a plot, save it as a graphics file, read it back in rotated and add it to a plot, but that seems like even more work.

You will want to be careful and think things through even if you find an easy way to rotate the plots, if you do the default plot of a density, rotate it and put it next to a scatterplot, then the axes are unlikely to line up correctly (that is why my example explicitly sets xlim and ylim).  It seems to me that once you think through everything needed to get the axes to line up, switching the x and y arguments is simpler than calling another function to rotate things (unless of course the plot you want to rotate is an already canned routine that does not have a horiz argument or works just by switching x and y). 


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: Benjamin Otto [mailto:b.otto at uke.uni-hamburg.de] 
Sent: Thursday, December 21, 2006 2:59 AM
To: Greg Snow; 'R-Help'; 'Knut Krueger'
Subject: AW: [R] Rotating a distribution plot by 90 degrees

I forgot one thing:

Gregs example results in what I seek. However he has roteted the data in his "mind" and in the data submitted to the plot command. What I would like to know is whether I can use the "plot" command to make some normal plot and add some second command which rotates the data for me...

Regards

Benjamin


-----Urspr?ngliche Nachricht-----
Von: Benjamin Otto [mailto:b.otto at uke.uni-hamburg.de]
Gesendet: 21 December 2006 10:51
An: 'Greg Snow'; 'R-Help'; 'Knut Krueger'
Betreff: Re: [R] Rotating a distribution plot by 90 degrees

 
Hi Knut, hi Greg,

Thanks for the quick help!

@Greg:
Yes THAT'S exactly what I meant. Thanks for the example.

@Knut:
Thanks for the hint. However my problem was that the combination of "plot"
and grid wasn't working. But probably it isn't supposed to.

Regards
Benjamin


----------------------------------------------------------------------------
----

Knut wrote:

> Did you find these manuals for the Grid package?

> http://www.stat.auckland.ac.nz/~paul/grid/doc/rotated.pdf

> http://www.stat.auckland.ac.nz/~paul/grid/grid.html

> Regards Knut



-----Urspr?ngliche Nachricht-----
Von: Greg Snow [mailto:Greg.Snow at intermountainmail.org]
Gesendet: 20 December 2006 20:34
An: Benjamin Otto; R-Help
Betreff: RE: [R] Rotating a distribution plot by 90 degrees

Does the following code do what you want?

x <- c( rnorm(50,10,2), rnorm(30,20,2) ) y <- 2+3*x + rnorm(80)

d.x <- density(x)
d.y <- density(y)

layout( matrix( c(0,2,2,1,3,3,1,3,3),ncol=3) )

plot(d.x$x, d.x$y, xlim=range(x), type='l') plot(d.y$y, d.y$x, ylim=range(y), xlim=rev(range(d.y$y)), type='l') plot(x,y, xlim=range(x),
ylim=range(y) )

If not, be more specific in describing what you want.

Hope this helps,


--
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Benjamin Otto
Sent: Wednesday, December 20, 2006 3:55 AM
To: R-Help
Subject: [R] Rotating a distribution plot by 90 degrees

Hi,

Can I rotate a plot (e.g. a distribution plot) by 90 degrees? The barplot function provides the "horiz" command but that's not availeable for the base package functions. I found an old advice from Paul Murrell on a similar problem suggesting to use viewports (grid package). Yet I couldn't reproduce his examples successfully. And going through the examples in the current grid package help pages left me with the feeling that viewport and the plot/points function don't match because the latter automatically clears the old device.

Is there some way to rotate a "plot" at all or am I forced to use the barplot function instead?

Regards,

Benjamin


P.S.: For further explanation: I would like to plot something like

+-----+-----+
|     |     |
|  0  |  1  |
|     |     |
+-----+-----+
|     |     |
|  2  |  3  |
|     |     |
+-----+-----+

where image 1 is some function plot in normal mode, image 2 is a function plot rotated by 90 degrees and image 3 is something depending on the two functions.


--
Benjamin Otto
Universitaetsklinikum Eppendorf Hamburg
Institut fuer Klinische Chemie
Martinistrasse 52
20246 Hamburg

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From tlumley at u.washington.edu  Thu Dec 21 17:07:26 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 21 Dec 2006 08:07:26 -0800 (PST)
Subject: [R] Memory problem on a linux cluster using a large data set
 [Broadcast]
In-Reply-To: <20061221130709.60458.qmail@web51704.mail.yahoo.com>
References: <20061221130709.60458.qmail@web51704.mail.yahoo.com>
Message-ID: <Pine.LNX.4.64.0612210758480.26400@homer22.u.washington.edu>

On Thu, 21 Dec 2006, Iris Kolder wrote:

> Thank you all for your help!
>
> So with all your suggestions we will try to run it on a computer with a 
> 64 bits proccesor. But i've been told that the new R versions all work 
> on a 32bits processor. I read in other posts that only the old R 
> versions were capable of larger data sets and were running under 64 bit 
> proccesors. I also read that they are adapting the new R version for 64 
> bits proccesors again so does anyone now if there is a version available 
> that we could use?

Huh?  R 2.4.x runs perfectly happily accessing large memory under Linux on 
64bit processors (and Solaris, and probably others). I think it even works 
on Mac OS X now.

For example:
> x<-rnorm(1e9)
> gc()
              used   (Mb) gc trigger   (Mb)   max used   (Mb)
Ncells     222881   12.0     467875   25.0     350000   18.7
Vcells 1000115046 7630.3 1000475743 7633.1 1000115558 7630.3


         -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From SBlanchard at coh.org  Thu Dec 21 17:32:53 2006
From: SBlanchard at coh.org (Blanchard, Suzette)
Date: Thu, 21 Dec 2006 08:32:53 -0800
Subject: [R] \Sexpr in MikTex
References: <309869D6EA32AB4A90722D8F74F892BB0C000ABC@EXCH-VS3.coh.org>
	<4589F9F6.8080003@stats.uwo.ca> <458A8CC3.7010706@stats.uwo.ca>
Message-ID: <B71FC19AE77F854F98B2B6A51554C6F7027F05B9@EXCH-VS3.coh.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061221/46627de1/attachment.pl 

From mtmorgan at fhcrc.org  Thu Dec 21 18:07:01 2006
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 21 Dec 2006 09:07:01 -0800
Subject: [R] Memory problem on a linux cluster using a large data set
 [Broadcast]
In-Reply-To: <Pine.LNX.4.64.0612210758480.26400@homer22.u.washington.edu>
	(Thomas
	Lumley's message of "Thu, 21 Dec 2006 08:07:26 -0800 (PST)")
References: <20061221130709.60458.qmail@web51704.mail.yahoo.com>
	<Pine.LNX.4.64.0612210758480.26400@homer22.u.washington.edu>
Message-ID: <6phirg5rxe2.fsf@gopher4.fhcrc.org>

Section 8 of the Installation and Administration guide says that on
64-bit architectures the 'size of a block of memory allocated is
limited to 2^32-1 (8 GB) bytes'.

The wording 'a block of memory' here is important, because this sets a
limit on a single allocation rather than the memory consumed by an R
session. The size of the allocation of the original poster was
something like 300,000 SNPs x 1000 individuals x 8 bytes (depending on
representation, I guess) = about 2.3 GB so there is still some room
for even larger data.

Obviously it's important to think carefully about how the statistical
analysis of such a large volume of data will proceed, and be
interpreted.

Martin

Thomas Lumley <tlumley at u.washington.edu> writes:

> On Thu, 21 Dec 2006, Iris Kolder wrote:
>
>> Thank you all for your help!
>>
>> So with all your suggestions we will try to run it on a computer with a 
>> 64 bits proccesor. But i've been told that the new R versions all work 
>> on a 32bits processor. I read in other posts that only the old R 
>> versions were capable of larger data sets and were running under 64 bit 
>> proccesors. I also read that they are adapting the new R version for 64 
>> bits proccesors again so does anyone now if there is a version available 
>> that we could use?
>
> Huh?  R 2.4.x runs perfectly happily accessing large memory under Linux on 
> 64bit processors (and Solaris, and probably others). I think it even works 
> on Mac OS X now.
>
> For example:
>> x<-rnorm(1e9)
>> gc()
>               used   (Mb) gc trigger   (Mb)   max used   (Mb)
> Ncells     222881   12.0     467875   25.0     350000   18.7
> Vcells 1000115046 7630.3 1000475743 7633.1 1000115558 7630.3
>
>
>          -thomas
>
> Thomas Lumley			Assoc. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington, Seattle
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Martin T. Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From ssj1364 at gmail.com  Thu Dec 21 21:01:40 2006
From: ssj1364 at gmail.com (sj)
Date: Thu, 21 Dec 2006 13:01:40 -0700
Subject: [R] : newbie estimating survival curve w/ survfit for coxph
Message-ID: <1c6126db0612211201i7fdd16e2r709fec1596de11ea@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061221/b6134b3a/attachment.pl 

From rmpruzek at yahoo.com  Thu Dec 21 21:39:49 2006
From: rmpruzek at yahoo.com (bobp)
Date: Thu, 21 Dec 2006 12:39:49 -0800 (PST)
Subject: [R] iplots/JGR on OS X 10.4.8
Message-ID: <8014572.post@talk.nabble.com>


iMac Intel Core Duo; OS X 10.4.8; Java 1.5.0_06; R 2.4.1; JGR 1.4-14; rJava
0.4-12; iplots 1.0-5

I'm unable to get JGR or iplots to load using "library(JGR)" or
"library(iplots)", respectively. This feels like it might be a classpath or
Mac look-and-feel issue, but I'm not sure where to go with it at this point.
I've searched the fora and web to no avail.

Any pointers are appreciated.

> install.packages("JGR",dep=TRUE)
> library(JGR)
Loading required package: iplots
Error in .jnew("org/rosuda/iplots/Framework") : 
	Failed to create object of class `org/rosuda/iplots/Framework'
In addition: Warning message:
NewObject("org/rosuda/iplots/Framework","()V",...) failed 
Error: package 'iplots' could not be loaded
Exception in thread "main" java.lang.NoClassDefFoundError
	at com.apple.mrj.MRJPriv.registerAboutHandler(MRJPriv.java:281)
	at
com.apple.mrj.MRJApplicationUtils.registerAboutHandler(MRJApplicationUtils.java:64)
	at org.rosuda.util.PlatformMac.registerHandlers(PlatformMac.java:43)
	at org.rosuda.util.PlatformMac.<init>(PlatformMac.java:20)
	at org.rosuda.iplots.PlatformMac.<init>(PlatformMac.java:16)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at
sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:494)
	at java.lang.Class.newInstance0(Class.java:350)
	at java.lang.Class.newInstance(Class.java:303)
	at org.rosuda.util.Platform.initPlatform(Platform.java:44)
	at org.rosuda.iplots.Framework.<init>(Framework.java:48)
> 


or in the case of iplots directly...


> library(iplots)
Error in .jnew("org/rosuda/iplots/Framework") : 
	Failed to create object of class `org/rosuda/iplots/Framework'
In addition: Warning message:
NewObject("org/rosuda/iplots/Framework","()V",...) failed 
Error in library(iplots) : .First.lib failed for 'iplots'
Exception in thread "main" java.lang.NoClassDefFoundError
	at com.apple.mrj.MRJPriv.registerAboutHandler(MRJPriv.java:281)
	at
com.apple.mrj.MRJApplicationUtils.registerAboutHandler(MRJApplicationUtils.java:64)
	at org.rosuda.util.PlatformMac.registerHandlers(PlatformMac.java:43)
	at org.rosuda.util.PlatformMac.<init>(PlatformMac.java:20)
	at org.rosuda.iplots.PlatformMac.<init>(PlatformMac.java:16)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at
sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:494)
	at java.lang.Class.newInstance0(Class.java:350)
	at java.lang.Class.newInstance(Class.java:303)
	at org.rosuda.util.Platform.initPlatform(Platform.java:44)
	at org.rosuda.iplots.Framework.<init>(Framework.java:48)
> 

-- 
View this message in context: http://www.nabble.com/iplots-JGR-on-OS-X-10.4.8-tf2867552.html#a8014572
Sent from the R help mailing list archive at Nabble.com.


From HStevens at MUOhio.edu  Thu Dec 21 22:22:49 2006
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Thu, 21 Dec 2006 16:22:49 -0500
Subject: [R] lme4 mcmcsamp matrix not PD
In-Reply-To: <8E2085D6-14F9-4706-B561-824F9E300135@MUOhio.edu>
References: <1276C0564833F043AB4C85ED8DA9CFE50117C36B@ctemail1.nioo.int>
	<A04C0FED-01D6-4A49-9066-01B9AA3A8B26@muohio.edu>
	<40e66e0b0612200515h107f6b97k5f7b50384bb1d1db@mail.gmail.com>
	<8E2085D6-14F9-4706-B561-824F9E300135@MUOhio.edu>
Message-ID: <7E819CF8-8A0A-4AA2-A3E1-16CC49D166A7@MUOhio.edu>

Hi folks,
A follow up - this problem happens only stochastically. Further, a  
little trial and error indicates that using mathod="Laplace" or  
method="AGQ" reduces the frequency of the problem. Why? I have no  
idea, and even this could be my own wishful interpretation of my  
trial and error.
-Hank
On Dec 20, 2006, at 4:20 PM, Martin Henry H. Stevens wrote:

> Hi folks,
> I am not providing a small replicable example, because I assume the
> problem is related to my quirky data (~650 obs.).
> I am using the latest lme4, matrix and coda, and R 2.4.0.
>
> I frequently get the following error message for this particular lmer
> model. I do not get this message for the vast majority of my uses of
> mcmcsamp.
>
> I was wondering if it might be characteristic of particular kinds of
> problems.
>
>> modb <- lmer(log(basal+1) ~ nutrient*amd +  (1|rack) +  (1|
> gen:amd), data=dat.b2)
>
>> mod.mc <- mcmcsamp(modb, n=10^4)
>
> Error: Matrix is not pd after safe_pd_matrix!
> Error in t(.Call(mer_MCMCsamp, object, saveb, n, trans, verbose)) :
> 	error in evaluating the argument 'x' in selecting a method for
> function 't'
>
> Cheers,
> Hank
>
> Dr. Hank Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
>
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/~stevenmh/
> http://www.muohio.edu/ecology/
> http://www.muohio.edu/botany/
>
> "E Pluribus Unum"
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



Dr. Hank Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/

"E Pluribus Unum"


From cberry at tajo.ucsd.edu  Thu Dec 21 23:24:03 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Thu, 21 Dec 2006 14:24:03 -0800
Subject: [R] : newbie estimating survival curve w/ survfit for coxph
In-Reply-To: <1c6126db0612211201i7fdd16e2r709fec1596de11ea@mail.gmail.com>
References: <1c6126db0612211201i7fdd16e2r709fec1596de11ea@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0612211405410.17355@tajo.ucsd.edu>


Spencer,

It always helps to look at the documentation for the objects you use.

 	?survfit.object

tells you:

-----------

COMPONENTS

 	strata

 	   if there are multiple curves, this component gives the number
            of elements of the time etc. vectors corresponding to the first
            curve, the second curve, and so on. The names of the elements
            are labels for the curves.


-----------

Note:

> z$strata
rx=1 rx=2
    7    3
>


If it is still not obvious what gives, look at

 	plot(z)

then at z$time, z$strata, and z$surv.


On Thu, 21 Dec 2006, sj wrote:

> I am wondering how to estimate the survival curve for a particular case(s)
> given a coxph model
>
> using this example code:
>
> #fit a cox proportional hazards model and plot the
>     #predicted survival curve
>     fit <- coxph(
> Surv(futime,fustat)~resid.ds+strata(rx)+ecog.ps+age,data=ovarian[1:23,])
>     z <- survfit(fit,newdata=ovarian[24:26,],individual=F)
>     zs <- z$surv
>     zt <- z$time
>
> I get the following output:
>
>              24              25           26
> [1,] 0.9740399 0.91737529 0.9873785
> [2,] 0.9431988 0.82552974 0.9721557
> [3,] 0.9023088 0.71387936 0.9515702
> [4,] 0.8518865 0.59121499 0.9255099
> [5,] 0.7269607 0.35151309 0.8572808
> [6,] 0.6130966 0.20108501 0.7895814
> [7,] 0.2807720 0.01553603 0.5415119
> [8,] 0.9159643 0.74991615 0.9584975
> [9,] 0.8225510 0.52704511 0.9099799
> [10,] 0.7058027 0.31906859 0.8451399
>
> [1]  59 115 156 268 329 431 638 464 475 563
>
> I am not sure what I am getting here, I was expecting to get three survival
> curves for each scenario in the "newdata" however the survival curves don't
> seem to be monotonically decreasing with time. I get the feeling that this
> has something to do with the use of strata(rx) in the model, but I am no
> sure how to sort it out.
>
> any help is appreciated,
>
> best regards,
>
> Spencer
>

[ irrelevant prior msg deleted ]



Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717


From fhduan at gmail.com  Thu Dec 21 23:28:03 2006
From: fhduan at gmail.com (Frank Duan)
Date: Thu, 21 Dec 2006 16:28:03 -0600
Subject: [R] Drawing a 3-D plot for PCA?
Message-ID: <3b9172310612211428s74581e99if7d857152d362222@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061221/86d578ad/attachment.pl 

From h.wickham at gmail.com  Thu Dec 21 23:47:51 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 21 Dec 2006 14:47:51 -0800
Subject: [R] Drawing a 3-D plot for PCA?
In-Reply-To: <3b9172310612211428s74581e99if7d857152d362222@mail.gmail.com>
References: <3b9172310612211428s74581e99if7d857152d362222@mail.gmail.com>
Message-ID: <f8e6ff050612211447o221d201btc4c3f0e00a2fb22@mail.gmail.com>

> Can anyone point me a hint (package) how to draw a 3D plot using the first 3

You might want to have a look at ggobi (http://www.ggobi.org) and
rggobi (http://www.ggobi.org/rggobi) which will allow you to look at
any number of principle coordinates.  (And don't forgot to look at the
high ones - interesting structure is often revealed there)

Hadley


From richard.c.yeh at bankofamerica.com  Thu Dec 21 23:54:44 2006
From: richard.c.yeh at bankofamerica.com (Yeh, Richard C)
Date: Thu, 21 Dec 2006 17:54:44 -0500
Subject: [R] multinom(nnet) analogy for biglm package?
Message-ID: <31AFBE76660ED2459C6F75E6EDFD203C05D183D4@ex2k.bankofamerica.com>

I would like to perform a multinomial logistic regression on a large
data set, but do not know how.  I've only thought of a few possibilities
and write to seek advice and guidance on them or deepening or expanding
my search.

On smaller data sets, I have successfully loaded the data and issued
commands such as:

length(levels(factor(data$response)))
[1] 6		# implies polychotomy
library(nnet)
result <- multinom(data$response ~ 1 + data$var1 + data$var2 + ...)
# (I am interested in at most ten 
# parameters; usually less than six) 

For a 60-MB comma-separated-values text-format data file (with a few
hundred thousand records), object.size(data) returns roughly 86 MB.  Now
I am considering loading a 7-GB data file (with about 30 million
records).  (In the near future, I may be interested in loading a 50-GB
data file, but right now I am still trying things out on smaller sets.)
What should I do?

1. I recall some discussion from August 2006 about the use of the biglm
package.  (Subject: lean and mean lm/glm?)  This seems potentially very
useful, but it's not clear to me how to fit a multinomial response.  Can
I get bigglm to fit polychotomous data?

2. Earlier, I thought I ran across an example (perhaps in V&R's MASS4 or
Harrell's Regression Modeling Strategies) showing how to use glm and an
appropriate family specification to perform a multinomial logistic
regression, but now I cannot find the example.  This is what had to be
done before the multinom() function became available, and it still
works, but I need a reference or example --- can anyone point me to it?
I suspect part of my problem is that I do not understand the
documentation on 'family': I'm not sure what the 'object' argument is,
defined:

"object: the function family accesses the family objects which are
stored within objects created by modelling functions (e.g., glm)."

My impression is that glm() returns a glm object.  I'm not sure what to
write there.

If the example doesn't exist, my brain may have [wishfully] inserted the
"multinomial" into my memory.  It's clear that glm can be used for
[ordinary/binomial] logistic regression.

3. I have skimmed Chen & Ripley's papers on computing near the data, but
suspect that I will need to do quite a lot of work (read: careful
reading, hand holding, and development) to adapt their solution.

4. I have briefly browsed the documentation on setting larger memory
size flags, but suspect that that's not a scalable route.  My desktop
WinXP PC has 2 GB of RAM; a linux computer I prefer has 8 GB, and I
suspect both copies of R were compiled as 32-bit (but I don't know how
to verify this).

box$ uname -a
Linux box 2.4.21-32.0.1.ELsmp #1 SMP Tue May 17 17:52:23 EDT 2005 i686
i686 i386 GNU/Linux
box$ R --max-vsize='4G'
WARNING: --max-vsize=4G=4'M': too large and ignored

5. If all else fails, I can sample the data and check the sample for an
appropriate distribution.

Richard

212-933-3305 / richard.c.yeh at bankofamerica.com


NOTICE TO RECIPIENTS: Any information contained in or attached to this message is intended solely for the use of the intended recipient(s). If you are not the intended recipient of this transmittal, you are hereby notified that you received this transmittal in error, and we request that you please delete and destroy all copies and attachments in your possession, notify the sender that you have received this communication in error, and note that any review or dissemination of, or the taking of any action in reliance on, this communication is expressly prohibited. 
 
Banc of America Securities LLC ("BAS") does not accept time-sensitive, action-oriented messages or transaction orders, including orders to purchase or sell securities, via e-mail.
 
Regular internet e-mail transmission cannot be guaranteed to be secure or error-free.  Therefore, we do not represent that this information is complete or accurate, and it should not be relied upon as such.  If you prefer to communicate with BAS using secure (i.e., encrypted) e-mail transmission, please notify the sender.  Otherwise, you will be deemed to have consented to communicate with BAS via regular internet e-mail transmission.  Please note that BAS reserves the right to intercept, monitor, and retain all e-mail messages (including secure e-mail messages) sent to or from its systems as permitted by applicable law.
 
----------------------------------------------------------------------
 
IRS Circular 230 Disclosure:
Bank of America Corporation and its affiliates, including BAS, ("Bank of America") do not provide tax advice. Accordingly, any statements contained herein as to tax matters were neither written nor intended by the sender or Bank of America to be used and cannot be used by any taxpayer for the purpose of avoiding tax penalties that may be imposed on such taxpayer. If any person uses or refers to any such tax statement in promoting, marketing or recommending a partnership or other entity, investment plan or arrangement to any taxpayer, then the statement expressed above is being delivered to support the promotion or marketing of the transaction or matter addressed, and the recipient should seek advice based on its particular circumstances from an independent tax advisor.


From richard.c.yeh at bankofamerica.com  Fri Dec 22 00:06:22 2006
From: richard.c.yeh at bankofamerica.com (Yeh, Richard C)
Date: Thu, 21 Dec 2006 18:06:22 -0500
Subject: [R] multinom(nnet) analogy for biglm package?
In-Reply-To: <31AFBE76660ED2459C6F75E6EDFD203C05D183D4@ex2k.bankofamerica.com>
Message-ID: <31AFBE76660ED2459C6F75E6EDFD203C05D183DE@ex2k.bankofamerica.com>

OK, well, seeing Thomas Lumley's post earlier today, I figured out the
answer to #4:

> gc()
           used  (Mb) gc trigger  (Mb)  max used  (Mb)
Ncells  1115191  29.8    3469679  92.7  13981968 373.4
Vcells 14796791 112.9   79783730 608.8 124640525 951.0
> c <- rnorm(1e9)
Error in rnorm(1e+09) : cannot allocate vector of length 1000000000

I am using:

R version 2.4.0 Patched (2006-10-03 r39576)


212-933-3305 / richard.c.yeh at bankofamerica.com 
-----Original Message-----
suspect both copies of R were compiled as 32-bit (but I don't know how
to verify this).


NOTICE TO RECIPIENTS: Any information contained in or attached to this message is intended solely for the use of the intended recipient(s). If you are not the intended recipient of this transmittal, you are hereby notified that you received this transmittal in error, and we request that you please delete and destroy all copies and attachments in your possession, notify the sender that you have received this communication in error, and note that any review or dissemination of, or the taking of any action in reliance on, this communication is expressly prohibited. 
 
Banc of America Securities LLC ("BAS") does not accept time-sensitive, action-oriented messages or transaction orders, including orders to purchase or sell securities, via e-mail.
 
Regular internet e-mail transmission cannot be guaranteed to be secure or error-free.  Therefore, we do not represent that this information is complete or accurate, and it should not be relied upon as such.  If you prefer to communicate with BAS using secure (i.e., encrypted) e-mail transmission, please notify the sender.  Otherwise, you will be deemed to have consented to communicate with BAS via regular internet e-mail transmission.  Please note that BAS reserves the right to intercept, monitor, and retain all e-mail messages (including secure e-mail messages) sent to or from its systems as permitted by applicable law.
 
----------------------------------------------------------------------
 
IRS Circular 230 Disclosure:
Bank of America Corporation and its affiliates, including BAS, ("Bank of America") do not provide tax advice. Accordingly, any statements contained herein as to tax matters were neither written nor intended by the sender or Bank of America to be used and cannot be used by any taxpayer for the purpose of avoiding tax penalties that may be imposed on such taxpayer. If any person uses or refers to any such tax statement in promoting, marketing or recommending a partnership or other entity, investment plan or arrangement to any taxpayer, then the statement expressed above is being delivered to support the promotion or marketing of the transaction or matter addressed, and the recipient should seek advice based on its particular circumstances from an independent tax advisor.


From ripley at stats.ox.ac.uk  Fri Dec 22 05:19:59 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 22 Dec 2006 04:19:59 +0000 (GMT)
Subject: [R] multinom(nnet) analogy for biglm package?
In-Reply-To: <31AFBE76660ED2459C6F75E6EDFD203C05D183DE@ex2k.bankofamerica.com>
References: <31AFBE76660ED2459C6F75E6EDFD203C05D183DE@ex2k.bankofamerica.com>
Message-ID: <Pine.LNX.4.64.0612220415140.5538@gannet.stats.ox.ac.uk>

Here is the direct way:

> .Machine$sizeof.pointer
[1] 8

on a 64-bit system.  You can also figure it out from the size of the 
Ncells, clearly 28 bytes in your example.

You seem to believe a multinomial logistic regression is a GLM: it is not.


On Thu, 21 Dec 2006, Yeh, Richard C wrote:

> OK, well, seeing Thomas Lumley's post earlier today, I figured out the
> answer to #4:
>
>> gc()
>           used  (Mb) gc trigger  (Mb)  max used  (Mb)
> Ncells  1115191  29.8    3469679  92.7  13981968 373.4
> Vcells 14796791 112.9   79783730 608.8 124640525 951.0
>> c <- rnorm(1e9)
> Error in rnorm(1e+09) : cannot allocate vector of length 1000000000
>
> I am using:
>
> R version 2.4.0 Patched (2006-10-03 r39576)
>
>
> 212-933-3305 / richard.c.yeh at bankofamerica.com
> -----Original Message-----
> suspect both copies of R were compiled as 32-bit (but I don't know how
> to verify this).
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kkthird at yahoo.com  Fri Dec 22 06:10:25 2006
From: kkthird at yahoo.com (KKThird@Yahoo.Com)
Date: Thu, 21 Dec 2006 21:10:25 -0800 (PST)
Subject: [R] Math expression with object to evaluate
Message-ID: <452509.39464.qm@web52509.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061221/44b5ab59/attachment.pl 

From Abhijit.Dasgupta at mail.jci.tju.edu  Fri Dec 22 07:47:00 2006
From: Abhijit.Dasgupta at mail.jci.tju.edu (Abhijit Dasgupta)
Date: Fri, 22 Dec 2006 01:47:00 -0500
Subject: [R] odfWeave problem
Message-ID: <458B7F64.3080204@mail.jci.tju.edu>

Hi,

I'm trying to customize some formating for a table using odfWeave. I'm 
having some trouble getting the formatting to work. I've defined the 
following format defns:

origStyleDefs <- getStyleDefs()

StyleDefs=origStyleDefs
StyleDefs$ArialLeftBold$parentStyleName=''
StyleDefs$ArialLeftBold$type='Paragraph'
StyleDefs$ArialLeftBold$textAlign='left'
StyleDefs$ArialLeftBold$fontName='Arial'
StyleDefs$ArialLeftBold$fontSize='12pt'
StyleDefs$ArialLeftBold$fontType='bold'
StyleDefs$ArialLeftBold$fontColor='#000000'

StyleDefs$ArialNormalRight$parentStyleName=''
StyleDefs$ArialNormalRight$type='Paragraph'
StyleDefs$ArialNormalRight$textAlign='end'
StyleDefs$ArialNormalRight$fontName='Arial'
StyleDefs$ArialNormalRight$fontSize='12pt'
StyleDefs$ArialNormalRight$fontType='italic'
StyleDefs$ArialNormalRight$fontColor='#000000'

#StyleDefs$ArialItalic = StyleDefs$ArialNormal
#StyleDefs$ArialItalic$fontType='italic'

setStyleDefs(StyleDefs)

The ArialNormalRight definition isn't working, though the ArialLeftBold 
is. Could someone help?

Looking at the code, odfWeave uses functions readXML and addStyleDefs, 
which I cannot find. How should I go about finding these?

Abhijit Dasgupta, Ph.D.

Assistant Professor | Division of Biostatistics
Department of Pharmacology and Experimental Therapeutics | Thomas 
Jefferson University
1015 Chestnut St | Suite M100 | Philadelphia, PA 19107
Ph: (215) 503-9201 | Fax: (215) 503-3804


From ligges at statistik.uni-dortmund.de  Fri Dec 22 08:46:31 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 22 Dec 2006 08:46:31 +0100
Subject: [R] Math expression with object to evaluate
In-Reply-To: <452509.39464.qm@web52509.mail.yahoo.com>
References: <452509.39464.qm@web52509.mail.yahoo.com>
Message-ID: <458B8D57.6070508@statistik.uni-dortmund.de>

You might want to read the "R Help Desk: Automation of Mathematical 
Annotation in Plots" in R News 2 (3), 32-34.
and you will understand that the following works:

plot(x, y, main =
   substitute("ID is" * ID.i * ", " * italic(R)^2 ==
               r2.i * {", RMSE" == error.i},
              list(ID.i = ID.i, r2.i = r2.i, error.i = error.i)))

For the next time, please make your example reproducible as the posting 
guide asks you to do.

Uwe Ligges



KKThird at Yahoo.Com wrote:
> Hello.
> 
> I have a question that probably has a simple answer.
> 
> I have a loop where several figures are plotted with each iteration. I calculate some descriptives to put in the title of the figure. When I use expression, since I want to combine math plotting symbols and the descriptives I calculate, I get an error. Here is an example of the code that I tried:
> 
> plot(x,y, main=expression(paste("ID is", ID.i, italic(R)^2, r2.i, "RMSE", error.i)))
> 
> where ID.i, r2.i, and error.i change for each iteration of the loop. I suppose the problem is that expression does not know to treat each of these as objects rather than part of a mathematical expression. Is there a way to display the value of ID.i, r2.i, and error.i within the expression? 
> 
> Thanks for any thoughts,
> Ken
> 
>  __________________________________________________
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nicolas.mazziotta at swing.be  Fri Dec 22 08:54:22 2006
From: nicolas.mazziotta at swing.be (Nicolas Mazziotta)
Date: Fri, 22 Dec 2006 08:54:22 +0100
Subject: [R] multiline system call
Message-ID: <200612220854.22158.nicolas.mazziotta@swing.be>

Hello,

I am trying to call sendmail from within R via system(). As sendmail reads 
from STDIN, I need to pass a multiline input as an argument.

E.g. (not working):

	system('sendmail -f xxx at swing.be -t yyy at swing.be\ntest\n.\n')

I tried a lot of ways to type the EOL characters, but cannot get them work the 
right way. This leads to several problems. For instance, R waits for me to 
enter <control-D> at the end of the sequence.

Thanks for any help.



-- 
Nicolas Mazziotta

The contents of this e-mail, including any attachments, are ...{{dropped}}


From Francois.EHRENMANN at igh.cnrs.fr  Fri Dec 22 09:10:57 2006
From: Francois.EHRENMANN at igh.cnrs.fr (Francois EHRENMANN)
Date: Fri, 22 Dec 2006 09:10:57 +0100
Subject: [R] Build a matrix using JRI
Message-ID: <458B9311.40808@igh.cnrs.fr>

Hi everyone

I'm a new user of R and JRI for a project (debian + eclipse + Java + JRI).

I need to build a matrix from datas and i proceed like this :

First step :  create the  matrix (Rengine re)
  re.idleEval("A <- mat.or.vec(10,40)",true);

Second Step : feed the structure
  re.idleEval("A[1,1] <- 39",true);
  re.idleEval("A[1,2] <- 10",true);
  re.idleEval("A[1,3] <- 5",true);
  ...
  re.idleEval("A[10,40] <- 16",true);

I want finaly to obtain the matrix result, passing these datas to R :
  REXP x = re.idleEval("A", true);
and i make this command to see results :
  Supervisor.trace(this, x.toString());

and i have as output :

[REAL* (39.0, 10.0, 5.0, 24.0, 30.0, 5.0, 9.0, 16.0, 0.0, 0.0, 4.0, 4.0, 
2.0, 4.0, 4.0, 4.0, 2.0, 2.0, 0.0, 0.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 
2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 4.0, 4.0, 4.0, 4.0, 2.0, 1.0, 0.0, 0.0, 
1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 2.0, 0.0, 0.0, 4.0, 4.0, 1.0, 1.0, 
2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 8.0, 3.0, 1.0, 
0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 3.0, 0.0, 0.0, 4.0, 4.0, 
0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0, 3.0, 0.0, 2.0, 2.0, 0.0, 
3.0, 4.0, 0.0, 0.0, ... (300 more values follow))]

Passing my datas to R (using R in a console), i obtain this output that 
i want to have using java and JRI but it doesn't work :

[,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
[1,]   39    4    3    2    1    4    2    2    4     3     1     2     2
[2,]   10    4    3    2    1    4    2    2    4     3     1     5     0
[3,]    5    2    2    4    2    1    0    0    0     0     0     0     0
[4,]   24    4    1    4    1    1    2    1    2     2     3     1     2
[5,]   30    4    3    4    3    2    2    2    2     2     1     3     2
[6,]    5    4    3    4    3    2    8    0    0     0     0     0     0
[7,]    9    2    2    2    2    1    3    2    1     3     0     0     0
[8,]   16    2    3    1    2    1    1    3    2     4     2     1     4
[9,]    0    0    0    0    0    0    0    0    0     0     0     0     0
[10,]    0    0    0    0    0    0    0    0    0     0     0     0     0
     [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] 
[,25]
[1,]     4     2     1     4     1     4     1     1     2     1     
2     2
[2,]     0     0     0     0     0     0     0     0     0     0     
0     0
[3,]     0     0     0     0     0     0     0     0     0     0     
0     0
[4,]     1     1     3     2     4     2     1     4     2     4     
4     4
[5,]     1     3     2     3     1     2     1     1     3     2     
4     2
[6,]     0     0     0     0     0     0     0     0     0     0     
0     0
[7,]     0     0     0     0     0     0     0     0     0     0     
0     0
[8,]     2     4     4     4    11     0     0     0     0     0     
0     0
[9,]     0     0     0     0     0     0     0     0     0     0     
0     0
[10,]     0     0     0     0     0     0     0     0     0     0     
0     0
     [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] 
[,37]
[1,]     3     1     2     1     1     3     2     4     2     1     
4     2
[2,]     0     0     0     0     0     0     0     0     0     0     
0     0
[3,]     0     0     0     0     0     0     0     0     0     0     
0     0
[4,]     3     0     0     0     0     0     0     0     0     0     
0     0
[5,]     1     4     2     4     4     4     0     0     0     0     
0     0
[6,]     0     0     0     0     0     0     0     0     0     0     
0     0
[7,]     0     0     0     0     0     0     0     0     0     0     
0     0
[8,]     0     0     0     0     0     0     0     0     0     0     
0     0
[9,]     0     0     0     0     0     0     0     0     0     0     
0     0
[10,]     0     0     0     0     0     0     0     0     0     0     
0     0
     [,38] [,39] [,40]
[1,]     4     4     4
[2,]     0     0     0
[3,]     0     0     0
[4,]     0     0     0
[5,]     0     0     0
[6,]     0     0     0
[7,]     0     0     0
[8,]     0     0     0
[9,]     0     0     0
[10,]     0     0     0

Is possible to obtain this format above using java and jri ? if yes, 
what i have to use in the jri package ?

Thank you very much to all

Cheers

Fran?ois

-- 
Fran?ois Ehrenmann - IE cdd

Equipe IMGT (Marie-Paule LEFRANC),
the international ImMunoGeneTics information system?
http://imgt.cines.fr
IMGT, LIGM, IGH, UPR CNRS 1142, 141 rue de la Cardonille
34396 Montpellier Cedex 5 FRANCE
Tel: +33 (0)4 99 61 99 28 - Fax: +33 (0)4 99 61 99 01
e-mail: Francois.Ehrenmann at igh.cnrs.fr


From maechler at stat.math.ethz.ch  Fri Dec 22 09:35:26 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 22 Dec 2006 09:35:26 +0100
Subject: [R] A problem with "copy()" in the svIO package
In-Reply-To: <op.tkwf7rv4lgnhok@davinci.une.net.co>
References: <op.tkwf7rv4lgnhok@davinci.une.net.co>
Message-ID: <17803.39118.292494.517745@stat.math.ethz.ch>

Hi Kenneth,

what did the package maintainer of the  svIO  answer to you when
you asked him about this?

I think the posting guide asks you pretty explicitly to ask the
package maintainer *) about such problem.

*) You find the maintainer e.g., from
     packageDescription("svIO")
or   library(help = svIO)

Regards,
Martin

>>>>> "Kenneth" == Kenneth Cabrera <krcabrer at une.net.co>
>>>>>     on Thu, 21 Dec 2006 02:53:41 -0500 writes:

    >> Hi R-users: When I type the following code in R,
    >> using the svIO package I got a problem only with
    >> the "latex" type option.(With "raw", "ascii" and
    >> "html" options, it works fine).

    >> x<-1:50 copy('x', type='latex', objname='x') Erro
    >> en file.info(fn <- c(...)) : argumento del nombre
    >> de archivo inv?lido

    >> Thank you for your help.

    >> Kenneth


    >> ______________________________________________
    >> R-help at stat.math.ethz.ch mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-help

    >> PLEASE do read the posting guide
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Please..
    >> http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.


From gavin.simpson at ucl.ac.uk  Fri Dec 22 09:37:36 2006
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 22 Dec 2006 08:37:36 +0000
Subject: [R] Drawing a 3-D plot for PCA?
In-Reply-To: <3b9172310612211428s74581e99if7d857152d362222@mail.gmail.com>
References: <3b9172310612211428s74581e99if7d857152d362222@mail.gmail.com>
Message-ID: <1166776656.2986.4.camel@dhcppc2.my.nat.localnet>

On Thu, 2006-12-21 at 16:28 -0600, Frank Duan wrote:
> Hi All,
> 
> Can anyone point me a hint (package) how to draw a 3D plot using the first 3
> components from PCA?
> 
> Thanks a lot,
> 
> FD

See ?ordiplot3d and ?ordirgl in package vegan. rda() in that package can
be used to perform PCA, which can then be drawn in 3D using the rgl
package or the scatterplot3d package, the former allowing dynamic
rotation and zooming of the ordination configuration.

HTH

G

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [t] +44 (0)20 7679 0522
ECRC                              [f] +44 (0)20 7679 0565
UCL Department of Geography
Pearson Building                  [e] gavin.simpsonATNOSPAMucl.ac.uk
Gower Street
London, UK                        [w] http://www.ucl.ac.uk/~ucfagls/
WC1E 6BT                          [w] http://www.freshwaters.org.uk/
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From leblois at clipper.ens.fr  Fri Dec 22 11:17:07 2006
From: leblois at clipper.ens.fr (Arthur Leblois)
Date: Fri, 22 Dec 2006 11:17:07 +0100 (MET)
Subject: [R] Pb with R.matlab
Message-ID: <Pine.GSO.4.63.0612221105480.3777@clipper.ens.fr>


Hello,

I have problems running the R.matlab package. I work with R 2.3.1, under 
windows (using the Rgui). It seems that, even after loading the package, 
the "simple" functions such as writeMat() or readMat() are not recognized.

For example, the following script leads to an error:

> install.packages("R.matlab")
--- Please select a CRAN mirror for use in this session ---
essai de l'URL 
'http://cran.miroir-francais.fr/bin/windows/contrib/2.3/R.matlab_1.1.2.zip'
Content type 'application/zip' length 177859 bytes
URL ouverte
downloaded 173Kb

package 'R.matlab' successfully unpacked and MD5 sums checked

The downloaded packages are in
         C:\Documents and Settings\Arthur Leblois\Local 
Settings\Temp\RtmpPyR7qb\downloaded_packages
updating HTML package descriptions

> A <- matrix(1:27, ncol=3)
> B <- as.matrix(1:10)
> writeMat("matrix.mat", A=A, B=B)
Erreur : impossible de trouver la fonction "writeMat"


(the last line means, in french: "Error: function "writeMat" not found")

If anyone has an idea what is happening and why it doesn't work, please 
let me know.

Arthur Leblois


From tkremund98 at hotmail.com  Wed Dec 20 18:18:54 2006
From: tkremund98 at hotmail.com (Todd Remund)
Date: Wed, 20 Dec 2006 10:18:54 -0700
Subject: [R] Kalman Filter in Control situation.
Message-ID: <BAY121-F396E6B34FE6C9B6A781DBD4CF0@phx.gbl>

I am looking for a Kalman filter that can handle a control input.  I thought 
that l.SS was suitable however, I can't get it to work, and wonder if I am 
not using the right function.  What I want is a Kalman filter that accepts 
exogenous inputs where the input is found using the algebraic Ricatti 
equation solution to a penalty function.  If K is the gain matrix then the 
exogenous input would be u_t = -Kx_n,  where x_n is the Kalman filter state 
estimate.  These inputs would be entered as such x_t = Ax_t-1 + Bu_t-1 + 
Ge_t.  Is l.SS in the dse1 package the correct parametrization of the Kalman 
filter?

Thank you very much,
Todd Remund


From petr.pikal at precheza.cz  Fri Dec 22 12:02:29 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 22 Dec 2006 12:02:29 +0100
Subject: [R] Pb with R.matlab
In-Reply-To: <Pine.GSO.4.63.0612221105480.3777@clipper.ens.fr>
Message-ID: <458BC955.23569.E3590C@localhost>

Hi

you probably installed (downloaded and unpacked) a package but you 
forgot to load it to R and therefore R does not know that you want to 
use it.

library(R.matlab)

see
?library
and R-intro.html

HTH
Petr

On 22 Dec 2006 at 11:17, Arthur Leblois wrote:

Date sent:      	Fri, 22 Dec 2006 11:17:07 +0100 (MET)
From:           	Arthur Leblois <leblois at clipper.ens.fr>
To:             	r-help at stat.math.ethz.ch
Subject:        	[R] Pb with R.matlab

> 
> Hello,
> 
> I have problems running the R.matlab package. I work with R 2.3.1,
> under windows (using the Rgui). It seems that, even after loading the
> package, the "simple" functions such as writeMat() or readMat() are
> not recognized.
> 
> For example, the following script leads to an error:
> 
> > install.packages("R.matlab")
> --- Please select a CRAN mirror for use in this session ---
> essai de l'URL 
> 'http://cran.miroir-francais.fr/bin/windows/contrib/2.3/R.matlab_1.1.2
> .zip' Content type 'application/zip' length 177859 bytes URL ouverte
> downloaded 173Kb
> 
> package 'R.matlab' successfully unpacked and MD5 sums checked
> 
> The downloaded packages are in
>          C:\Documents and Settings\Arthur Leblois\Local 
> Settings\Temp\RtmpPyR7qb\downloaded_packages
> updating HTML package descriptions
> 
> > A <- matrix(1:27, ncol=3)
> > B <- as.matrix(1:10)
> > writeMat("matrix.mat", A=A, B=B)
> Erreur : impossible de trouver la fonction "writeMat"
> 
> 
> (the last line means, in french: "Error: function "writeMat" not
> found")
> 
> If anyone has an idea what is happening and why it doesn't work,
> please let me know.
> 
> Arthur Leblois
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.

Petr Pikal
petr.pikal at precheza.cz


From leblois at clipper.ens.fr  Fri Dec 22 12:05:36 2006
From: leblois at clipper.ens.fr (Arthur Leblois)
Date: Fri, 22 Dec 2006 12:05:36 +0100 (MET)
Subject: [R] Pb with R.matlab
In-Reply-To: <458BC955.23569.E3590C@localhost>
References: <458BC955.23569.E3590C@localhost>
Message-ID: <Pine.GSO.4.63.0612221204490.3777@clipper.ens.fr>


Thank you. This was a mistake from me, I actually did not load the 
package.
Sorry for this!
Arthur


On Fri, 22 Dec 2006, Petr Pikal wrote:

> Hi
>
> you probably installed (downloaded and unpacked) a package but you
> forgot to load it to R and therefore R does not know that you want to
> use it.
>
> library(R.matlab)
>
> see
> ?library
> and R-intro.html
>
> HTH
> Petr
>
> On 22 Dec 2006 at 11:17, Arthur Leblois wrote:
>
> Date sent:      	Fri, 22 Dec 2006 11:17:07 +0100 (MET)
> From:           	Arthur Leblois <leblois at clipper.ens.fr>
> To:             	r-help at stat.math.ethz.ch
> Subject:        	[R] Pb with R.matlab
>
>>
>> Hello,
>>
>> I have problems running the R.matlab package. I work with R 2.3.1,
>> under windows (using the Rgui). It seems that, even after loading the
>> package, the "simple" functions such as writeMat() or readMat() are
>> not recognized.
>>
>> For example, the following script leads to an error:
>>
>>> install.packages("R.matlab")
>> --- Please select a CRAN mirror for use in this session ---
>> essai de l'URL
>> 'http://cran.miroir-francais.fr/bin/windows/contrib/2.3/R.matlab_1.1.2
>> .zip' Content type 'application/zip' length 177859 bytes URL ouverte
>> downloaded 173Kb
>>
>> package 'R.matlab' successfully unpacked and MD5 sums checked
>>
>> The downloaded packages are in
>>          C:\Documents and Settings\Arthur Leblois\Local
>> Settings\Temp\RtmpPyR7qb\downloaded_packages
>> updating HTML package descriptions
>>
>>> A <- matrix(1:27, ncol=3)
>>> B <- as.matrix(1:10)
>>> writeMat("matrix.mat", A=A, B=B)
>> Erreur : impossible de trouver la fonction "writeMat"
>>
>>
>> (the last line means, in french: "Error: function "writeMat" not
>> found")
>>
>> If anyone has an idea what is happening and why it doesn't work,
>> please let me know.
>>
>> Arthur Leblois
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html and provide commented,
>> minimal, self-contained, reproducible code.
>
> Petr Pikal
> petr.pikal at precheza.cz
>


From sernova at mail.ru  Fri Dec 22 12:13:24 2006
From: sernova at mail.ru (Natasha Sernova)
Date: Fri, 22 Dec 2006 14:13:24 +0300
Subject: [R] ape-package
Message-ID: <E1GxiL6-000OSF-00.sernova-mail-ru@f89.mail.ru>

Dear Sir or Madam,

I am very new to R, and I am trying to install seqinr-package.
In the manual I read that I need to install ape-package first, and I failed to do it.
I had the following error messges:

/usr/bin/ld: cannot find -lgfortran
collect2: ld returned 1 exit status
make: *** [ape.so] ?????? 1
ERROR: compilation failed for package 'ape'
** Removing '/usr/lib/R/library/ape'

What to do with this and how to install it?
Many thanks in advance!
Natasha


From ggrothendieck at gmail.com  Fri Dec 22 13:25:40 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 22 Dec 2006 07:25:40 -0500
Subject: [R] Math expression with object to evaluate
In-Reply-To: <452509.39464.qm@web52509.mail.yahoo.com>
References: <452509.39464.qm@web52509.mail.yahoo.com>
Message-ID: <971536df0612220425t15dc3b2aicbb68bcfa25c76d7@mail.gmail.com>

Use bquote:

ID <- 3
plot(1,1, main = bquote(ID ~ is ~ .(ID)))

Also please read the last line of every message to r-help regarding
reproducible examples.  (None of your variables were defined.)

On 12/22/06, KKThird at Yahoo.Com <kkthird at yahoo.com> wrote:
> Hello.
>
> I have a question that probably has a simple answer.
>
> I have a loop where several figures are plotted with each iteration. I calculate some descriptives to put in the title of the figure. When I use expression, since I want to combine math plotting symbols and the descriptives I calculate, I get an error. Here is an example of the code that I tried:
>
> plot(x,y, main=expression(paste("ID is", ID.i, italic(R)^2, r2.i, "RMSE", error.i)))
>
> where ID.i, r2.i, and error.i change for each iteration of the loop. I suppose the problem is that expression does not know to treat each of these as objects rather than part of a mathematical expression. Is there a way to display the value of ID.i, r2.i, and error.i within the expression?
>
> Thanks for any thoughts,
> Ken
>
>  __________________________________________________
>
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From istoyanov at ecolab.bas.bg  Fri Dec 22 13:54:48 2006
From: istoyanov at ecolab.bas.bg (Ivailo Stoyanov)
Date: Fri, 22 Dec 2006 14:54:48 +0200
Subject: [R] ape-package
In-Reply-To: <E1GxiL6-000OSF-00.sernova-mail-ru@f89.mail.ru>
References: <E1GxiL6-000OSF-00.sernova-mail-ru@f89.mail.ru>
Message-ID: <1166792088.10998.5.camel@localhost>

On Fri, 2006-12-22 at 14:13 +0300, Natasha Sernova wrote:
> Dear Sir or Madam,
> 
> I am very new to R, and I am trying to install seqinr-package.
> In the manual I read that I need to install ape-package first, and I failed to do it.
> I had the following error messges:
> 
> /usr/bin/ld: cannot find -lgfortran
> collect2: ld returned 1 exit status
> make: *** [ape.so] ?????? 1
> ERROR: compilation failed for package 'ape'
> ** Removing '/usr/lib/R/library/ape'
> 
> What to do with this and how to install it?
> Many thanks in advance!
> Natasha

First, it would be useful if we could know the distribution you're using
(the /usr/bin/ld message lets me to assume that you're on Linux), so
please provide some more details so that we could help you out of the
situation.

Ivailo


From Morneau at Engref.Fr  Fri Dec 22 14:13:10 2006
From: Morneau at Engref.Fr (Francois MORNEAU)
Date: Fri, 22 Dec 2006 14:13:10 +0100
Subject: [R] Pb with R.matlab
In-Reply-To: <Pine.GSO.4.63.0612221105480.3777@clipper.ens.fr>
Message-ID: <002b01c725ca$ee1bf6a0$2e6436c1@Npeco0b>

Hello  Arthur,

Load the package first before using functions:

> library(R.matlab)

Regards,

Fran?ois

-----Message d'origine-----
De : Arthur Leblois [mailto:leblois at clipper.ens.fr] 
Envoy? : vendredi 22 d?cembre 2006 11:17
? : r-help at stat.math.ethz.ch
Objet : [R] Pb with R.matlab


Hello,

I have problems running the R.matlab package. I work with R 2.3.1, under
windows (using the Rgui). It seems that, even after loading the package, the
"simple" functions such as writeMat() or readMat() are not recognized.

For example, the following script leads to an error:

> install.packages("R.matlab")
--- Please select a CRAN mirror for use in this session --- essai de l'URL
'http://cran.miroir-francais.fr/bin/windows/contrib/2.3/R.matlab_1.1.2.zip'
Content type 'application/zip' length 177859 bytes URL ouverte downloaded
173Kb

package 'R.matlab' successfully unpacked and MD5 sums checked

The downloaded packages are in
         C:\Documents and Settings\Arthur Leblois\Local
Settings\Temp\RtmpPyR7qb\downloaded_packages
updating HTML package descriptions

> A <- matrix(1:27, ncol=3)
> B <- as.matrix(1:10)
> writeMat("matrix.mat", A=A, B=B)
Erreur : impossible de trouver la fonction "writeMat"


(the last line means, in french: "Error: function "writeMat" not found")

If anyone has an idea what is happening and why it doesn't work, please let
me know.

Arthur Leblois


From therneau at mayo.edu  Fri Dec 22 15:06:09 2006
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 22 Dec 2006 08:06:09 -0600 (CST)
Subject: [R] newbie estimating survival curve w/ survfit for coxph
Message-ID: <200612221406.kBME6Ai28487@hsrnfs-101.mayo.edu>

 fit <- coxph(Surv(futime,fustat)~ age +strata(rx), data=ovarian,
 	              subset=1:23)
 curves <- survfit(fit, newdata=ovarian[24:26,])
 

 I don't think this is mentioned in the documentation (I'll have to fix that!),
but subscripting works for survfit objects.  In this case there are 2 strata
and 3 subjects, and

   curves[1,2]  will return the survival curve for strata 1, subject 2.
   curves[2,1]  will return the survival curve for strata 2, subject 1,
etc.

	Terry Therneau


From sarah.goslee at gmail.com  Fri Dec 22 15:27:39 2006
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 22 Dec 2006 09:27:39 -0500
Subject: [R] odfWeave problem
In-Reply-To: <458B7F64.3080204@mail.jci.tju.edu>
References: <458B7F64.3080204@mail.jci.tju.edu>
Message-ID: <efb536d50612220627o150f19e9uf9ed4d610bb6aa1e@mail.gmail.com>

Hi,

"Doesn't work" is kind of vague... what is or isnt' happening?

But in this case, I think it might be easy:


On 12/22/06, Abhijit Dasgupta <Abhijit.Dasgupta at mail.jci.tju.edu> wrote:
> Hi,

> StyleDefs$ArialNormalRight$textAlign='end'

I think this should be 'right' rather than 'end.

The ODF XML specification is available online, but you can also make
a toy example in OpenOffice and then look at its XML if you want to find
out what a particular format code is.
http://www.oasis-open.org/committees/tc_home.php?wg_abbrev=office

For example, make a small table in OpenOffice with one of the cells
aligned right, and save it. Find the file, and unzip it into its components.
The XML code for your applied formatting will be in content.xml. If you
used styles instead of direct formatting, some kinds of styles go in styles.xml
and some in content.xml. The same is true for styles applied through
odfWeave.

Sarah
-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Fri Dec 22 15:52:55 2006
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 22 Dec 2006 09:52:55 -0500
Subject: [R] odfWeave problem
In-Reply-To: <efb536d50612220627o150f19e9uf9ed4d610bb6aa1e@mail.gmail.com>
References: <458B7F64.3080204@mail.jci.tju.edu>
	<efb536d50612220627o150f19e9uf9ed4d610bb6aa1e@mail.gmail.com>
Message-ID: <efb536d50612220652m55b1a88bh5d9644b13b33930@mail.gmail.com>

Sorry, I zipped you off a reply without actually having OpenOffice
available - never wise.

First, both "right" and "end" work for me as alignment specifications,
though OpenOffice itself seems to use "end".

Here's the R code I'm using to define the styles:


	# Now to specify the styles themselves
	# The default list has 10 styles in it right now.
	existingStyles <- getStyleDefs()

	# Use one of the cell styles as a template for the new cell style
	# The style definition contains information on background
	# color, alignment, and borders.


	# Style 3 is a bit different. Here I want to change the text color,
	# which is specified in a different style definition.
	newStyle3 <- existingStyles$ArialCentered
	newStyle3$fontColor <- "#0000cc"
   newStyle3$textAlign <- "right"


	# Finally, the new styles need to be set.
	existingStyles <- c(existingStyles, newStyle1=list(newStyle1),
newStyle2=list(newStyle2), newStyle3=list(newStyle3))
	setStyleDefs(existingStyles)

And here's the code block from the ODF document:


<<Table1,echo=FALSE,results=xml>>=
	# here's the same example data as in table 1
	x <- data.frame(Var1=1:3, Var2=4:6, Var3=7:9, row.names=c("A", "B", "C"))

	# Here's a matrix specifying the desired styles for each cell in the table
	# This could be p-values for the correlations in x, for example. For
	# this example, I'm just making it up. There are three possible styles,
	# as well as the default style.
	# The style matrix must have an additional column for the row names.
	y <- matrix(c(0, 0, 0, 1,0,0,3,0,1,2,0,2), byrow=FALSE, nrow=3, ncol=4)
	y <- data.frame(y)
	colnames(y) <- c("rownames", "Var1", "Var2", "Var3")


	# Now, to specify when to use these new styles.
	# tableStyles() will provide the default styles for each
	# element of x
	# note that I'm creating the styles for x based on y,
	# which already has the extra column for row names.
	x.styles <- tableStyles(y, header=colnames(y))

	# every element of x has two associated styles
	# for the cells, text style is in text and cell style is in cells
	# for headers, it is in header and headerCell

	# newStyle3 is a text style.
	x.styles$text[y == 3] <- "newStyle3"


	odfTable(x, useRowNames = TRUE, styles = x.styles)
@

I hope this example is more helpful than my previous email!

If you are interested, I have a longer, heavily-commented, example
of figure and table styles for odfWeave that I'm planning to put
online shortly. I'd be happy to send you a copy.

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From jrkrideau at yahoo.ca  Fri Dec 22 15:58:45 2006
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 22 Dec 2006 09:58:45 -0500 (EST)
Subject: [R] lda plotting: labeling x axis and changing y-axis scale
In-Reply-To: <e23082be0612201734k7df2f15dvd99b24be722f3e35@mail.gmail.com>
Message-ID: <522847.44140.qm@web32803.mail.mud.yahoo.com>


--- Wade Wall <wade.wall at gmail.com> wrote:

> Hi all,
> 
> I have performed an lda on two groups and have
> plotted using
> plot(x.lda), with x.lda being my lda results.  I
> have forgotten how to
> change the labels of the of the x-axes (they are
> currently listed as
> Group1 and Group 13), and to rescale the y-axis to
> reflect frequency.
> If anyone knows how to do it, I would greatly
> appreciate the
> information.
> 
> Wade

Wade,
Are you asking about a specific ploting routine in lda
or just how to use the basic plot function.  If the
latter try ?plot.default for what you need.


From bcutayar at lfdj.com  Fri Dec 22 16:18:41 2006
From: bcutayar at lfdj.com (bcutayar at lfdj.com)
Date: Fri, 22 Dec 2006 16:18:41 +0100
Subject: [R] absent
Message-ID: <OFCBC5325A.F0FA2414-ONC125724C.00541BDB-C125724C.00541BDB@lfdj.com>




Je serai absent(e) ? partir du  22/12/2006 de retour le 27/12/2006.

Je vous r?pondrais d?s mon retour le 27/12.
Si urgence, merci de contacter M.Bidart (5503).


Si vous n'etes pas destinataires de ce message, merci d'aver...{{dropped}}


From Mark.Leeds at morganstanley.com  Fri Dec 22 16:39:10 2006
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Fri, 22 Dec 2006 10:39:10 -0500
Subject: [R] Kalman Filter in Control situation.
In-Reply-To: <BAY121-F396E6B34FE6C9B6A781DBD4CF0@phx.gbl>
Message-ID: <D3AEEDA31E57474B840BEBC25A8A8344F39294@NYWEXMB23.msad.ms.com>

you have to be really careful because
There are two versions of the kalman filter in terms of notation ( even
where you don't have exogenous )

Y_t = F_tprime*theta_t-1 + epsilon_t
G_t = G_t*theta_t-1 + omega_t
-----------------------------------------

Y_t = F_tprime*theta_t + epsilon_t
G_t = G_t*theta_t-1 + omega_t

I haven't looked at any of the kalman filter routines ( there something
in the base KalmanLike, dlm package
Has one and I guess dsel and probabyl others ) but I think hey usually
explain which notation they are using.

The two variations above derive different recursions but you get the
same answer at each step
as long as you estimate the variances consistently depending on the
framework.




-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Todd Remund
Sent: Wednesday, December 20, 2006 12:19 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Kalman Filter in Control situation.

I am looking for a Kalman filter that can handle a control input.  I
thought that l.SS was suitable however, I can't get it to work, and
wonder if I am not using the right function.  What I want is a Kalman
filter that accepts exogenous inputs where the input is found using the
algebraic Ricatti equation solution to a penalty function.  If K is the
gain matrix then the exogenous input would be u_t = -Kx_n,  where x_n is
the Kalman filter state estimate.  These inputs would be entered as such
x_t = Ax_t-1 + Bu_t-1 + Ge_t.  Is l.SS in the dse1 package the correct
parametrization of the Kalman filter?

Thank you very much,
Todd Remund

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From yumikow at student.ethz.ch  Fri Dec 22 17:18:18 2006
From: yumikow at student.ethz.ch (Watanabe  Yumiko)
Date: Fri, 22 Dec 2006 17:18:18 +0100
Subject: [R] question
Message-ID: <02B14BC73C5E77459C6BA58E0F6FD63089DF30@EX3.d.ethz.ch>

I have a question about R.
I would like to simulate a following model.
 
Xt+1=Xt(1+b)        
 
"b" is a random variable. 
 
to get 10 plots.
 
I haven't used R program, how can I code on R to 
run above simulation?
 
It rould be grateful if you kindly answer...
 
thank you.
 
yumiko watanabe


From dsohal at gmail.com  Fri Dec 22 17:25:30 2006
From: dsohal at gmail.com (Davendra Sohal)
Date: Fri, 22 Dec 2006 11:25:30 -0500
Subject: [R] Pelora problem
Message-ID: <c2f237040612220825jcd1f873uba312a579e1bac18@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061222/3568ae9f/attachment.pl 

From simon.kempf at web.de  Fri Dec 22 17:32:38 2006
From: simon.kempf at web.de (Simon P. Kempf)
Date: Fri, 22 Dec 2006 17:32:38 +0100
Subject: [R] plot.mids  / Error in plot.new() : figure margins too large
Message-ID: <E1GxnKD-0008D3-00@smtp06.web.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061222/01c81719/attachment.pl 

From srgibbon at googlemail.com  Fri Dec 22 17:52:42 2006
From: srgibbon at googlemail.com (Simon Gibbon)
Date: Fri, 22 Dec 2006 16:52:42 +0000
Subject: [R] iplots/JGR on OS X 10.4.8
In-Reply-To: <8014572.post@talk.nabble.com>
References: <8014572.post@talk.nabble.com>
Message-ID: <bd659d230612220852t74cee848hebb7c9eee4ec95f4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061222/ae30d816/attachment.pl 

From mike.prager at noaa.gov  Fri Dec 22 18:35:15 2006
From: mike.prager at noaa.gov (Mike Prager)
Date: Fri, 22 Dec 2006 12:35:15 -0500
Subject: [R] question
References: <02B14BC73C5E77459C6BA58E0F6FD63089DF30@EX3.d.ethz.ch>
Message-ID: <up5oo2lu5jinkftv85da1sd3ci6in60f70@4ax.com>

You will not learn anything unless you do your own homework.

"Watanabe  Yumiko" <yumikow at student.ethz.ch> wrote:

> I have a question about R.
> I would like to simulate a following model.
>  
> Xt+1=Xt(1+b)        
>  
> "b" is a random variable. 
>  
> to get 10 plots.
>  
> I haven't used R program, how can I code on R to 
> run above simulation?
>  
> It rould be grateful if you kindly answer...
>  
> thank you.
>  
> yumiko watanabe
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Mike Prager, NOAA, Beaufort, NC
* Opinions expressed are personal and not represented otherwise.
* Any use of tradenames does not constitute a NOAA endorsement.


From mike.prager at noaa.gov  Fri Dec 22 18:45:40 2006
From: mike.prager at noaa.gov (Mike Prager)
Date: Fri, 22 Dec 2006 12:45:40 -0500
Subject: [R] writing R extension
References: <20061220193004.51714.qmail@web37903.mail.mud.yahoo.com>
Message-ID: <i16oo2hdj62eekulc2pf24sui1d7fnujsg@4ax.com>

ahmad ajakh <aajakh at yahoo.com> wrote:

> Hi all,
> I am dealing with the same issue here and I was wondering whether it would be possible to just save
> the R compliled function objects in a directory and just attach the directory to the search path.
> (I am using R2.4.0+ESS+Xemacs in windows XP). 
> 
> Thanks.
> AA.

Yes.  That is what I do with my own functions.  It is MUCH
simpler than writing a package, though not as functional (no
help pages for example.)

Make sure the workspace has only the functions you need, then
save it.  In your .Rprofile, you can put a line like

attach("d:/R/MHP/MHPmisc/.RData")

to add the workspace to the search path.  

This has the advantage that the functions don't show up when you
type ls() -- but they do when you type ls(nn), where nn is the
position of the added workspace on the search path.

I use the following script, stored in file 00make.r in the same
directory as the functions, to speed this up:

#==============================
## Script 00make.r   MHP
## This clears the current workspace, sources all the scripts
## found in the working directory, and then saves the
## workspace for use by later R sessions

# Clear all existing objects in workspace:
rm(list=ls())

# Make a list of all R source files in this directory:
flist = list.files(path = ".", pattern = ".+\.r")

# Remove from the list all files containing the string "00":
# Such files should be used for temporary functions or
# scripts like this one.
flist2 = flist[-grep("00", flist)]

# Source the files:
for (i in 1:length(flist2)) {
   cat("Sourcing", flist2[i],"\n")
   source(flist2[i])
   }
# Remove temporary objects:
rm(i, flist, flist2)
# Save workspace:
save.image()
# Write message to user:
cat("\nNOTE: The workspace has been saved with all
functions.\n",
    "     When exiting R, please do NOT save again.\n")
ls() in
#===============================

-- 
Mike Prager, NOAA, Beaufort, NC
* Opinions expressed are personal and not represented otherwise.
* Any use of tradenames does not constitute a NOAA endorsement.


From wade.wall at gmail.com  Fri Dec 22 18:52:45 2006
From: wade.wall at gmail.com (Wade Wall)
Date: Fri, 22 Dec 2006 12:52:45 -0500
Subject: [R] lda plotting: labeling x axis and changing y-axis scale
In-Reply-To: <522847.44140.qm@web32803.mail.mud.yahoo.com>
References: <e23082be0612201734k7df2f15dvd99b24be722f3e35@mail.gmail.com>
	<522847.44140.qm@web32803.mail.mud.yahoo.com>
Message-ID: <e23082be0612220952p740f40d3ta34d26ac9df49372@mail.gmail.com>

Sorry I wasn't clearer.  I believe that it was a specialized function,
but it may have been plot().

What I am basically trying to do is alter the y-axis to represent
frequency and change the labels on the plotting of the linear
discriminant analysis results.  I can't seem to do this with plot(),
if you know another function, that would be great.  Or if you know how
to alter the y-axis and label the two group names,  that would be
great also.  I have been working at it for a while and am kicking
myself for not saving the commands as a script.

Thanks,

Wade Wall

On 12/22/06, John Kane <jrkrideau at yahoo.ca> wrote:
>
> --- Wade Wall <wade.wall at gmail.com> wrote:
>
> > Hi all,
> >
> > I have performed an lda on two groups and have
> > plotted using
> > plot(x.lda), with x.lda being my lda results.  I
> > have forgotten how to
> > change the labels of the of the x-axes (they are
> > currently listed as
> > Group1 and Group 13), and to rescale the y-axis to
> > reflect frequency.
> > If anyone knows how to do it, I would greatly
> > appreciate the
> > information.
> >
> > Wade
>
> Wade,
> Are you asking about a specific ploting routine in lda
> or just how to use the basic plot function.  If the
> latter try ?plot.default for what you need.
>
> __________________________________________________
> Do You Yahoo!?
> Tired of spam?  Yahoo! Mail has the best spam protection around
> http://mail.yahoo.com
>


From richard.c.yeh at bankofamerica.com  Fri Dec 22 19:40:22 2006
From: richard.c.yeh at bankofamerica.com (Yeh, Richard C)
Date: Fri, 22 Dec 2006 13:40:22 -0500
Subject: [R] multinom(nnet) analogy for biglm package?
In-Reply-To: <Pine.LNX.4.64.0612220415140.5538@gannet.stats.ox.ac.uk>
Message-ID: <31AFBE76660ED2459C6F75E6EDFD203C05D1862D@ex2k.bankofamerica.com>

Dear Prof. Ripley,

Many thanks for your reply, especially during the holiday season!

> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> You seem to believe a multinomial logistic regression is a GLM: it is
not.

With one line, you've struck the heart of one of my problems.

As a follow-up question, would you (or anyone else) care to comment on
the feasibility of using R to perform multinomial logistic regression on
a large data set?

The scale of the problem is similar to the one you and Fei Chen treated:
instead of insurance policies, I am considering residential mortgages.
I read that you and Fei Chen used a generalized linear model, which I
understand you are saying does not apply to my approach.  But, it's not
obvious to me why I cannot just guess some coefficients, partition the
large data file into digestible excerpts, score each excerpt with a
log-likelihood function, combine the scores and gradients, and iterate
the guess.  Is that totally different from what you described in
"Statistical Computing and Databases" (Proc. DSC 2003)?

Thanks again for helping me as I consider how to approach my problem!

Richard

212-933-3305 / richard.c.yeh at bankofamerica.com


NOTICE TO RECIPIENTS: Any information contained in or attach...{{dropped}}


From paul.macmanus at gmail.com  Fri Dec 22 19:47:39 2006
From: paul.macmanus at gmail.com (Paul MacManus)
Date: Fri, 22 Dec 2006 10:47:39 -0800
Subject: [R] unexpected conversion from POSIXlt to POSIXct
Message-ID: <cef427a00612221047m4cc623fesba718c743d970e9d@mail.gmail.com>

The documentation for DateTime classes in R 2.3.0 says that limited
arithmetic is available for both POSIXlt and POSIXct. It needs to make
clear that POSIXlt can be converted to POSIXct without warning under
arithmetic operations

EXAMPLE

ISOdatetime(2003, 1, 1, 0, 0,0) -> dd
as.POSIXlt(dd) -> dd          ## set class of dd to POSIXlt
dd+1 -> ee                        ## ee now has class POSIXct


From tariq.khan at gmail.com  Fri Dec 22 19:55:21 2006
From: tariq.khan at gmail.com (=?ISO-8859-1?Q?=A8Tariq_Khan?=)
Date: Fri, 22 Dec 2006 18:55:21 +0000
Subject: [R] question
In-Reply-To: <up5oo2lu5jinkftv85da1sd3ci6in60f70@4ax.com>
References: <02B14BC73C5E77459C6BA58E0F6FD63089DF30@EX3.d.ethz.ch>
	<up5oo2lu5jinkftv85da1sd3ci6in60f70@4ax.com>
Message-ID: <2310043c0612221055r1a31f140w7c6ec386b96cd293@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061222/153def6c/attachment.pl 

From cberry at tajo.ucsd.edu  Fri Dec 22 20:05:27 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Fri, 22 Dec 2006 11:05:27 -0800
Subject: [R] multiline system call
In-Reply-To: <200612220854.22158.nicolas.mazziotta@swing.be>
References: <200612220854.22158.nicolas.mazziotta@swing.be>
Message-ID: <Pine.LNX.4.64.0612221054520.25432@tajo.ucsd.edu>



Look at the help page for ?system, especially the  'input=' arg.

Maybe this sort of strategy will fly:


> system("sh",intern=T,input=c("echo x","echo y"))
[1] "x" "y"
>

In your case, maybe

system('sh' input=c('sendmail -f xxx at swing.be -t yyy at swing.be','test','.')

or

system('sendmail -f xxx at swing.be -t yyy at swing.be', input='test')

will do it.

On Fri, 22 Dec 2006, Nicolas Mazziotta wrote:

> Hello,
>
> I am trying to call sendmail from within R via system(). As sendmail reads
> from STDIN, I need to pass a multiline input as an argument.
>
> E.g. (not working):
>
> 	system('sendmail -f xxx at swing.be -t yyy at swing.be\ntest\n.\n')
>
> I tried a lot of ways to type the EOL characters, but cannot get them work the
> right way. This leads to several problems. For instance, R waits for me to
> enter <control-D> at the end of the sequence.
>
> Thanks for any help.
>
>
>
> -- 
> Nicolas Mazziotta
>
> The contents of this e-mail, including any attachments, are ...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717


From pgilbert at bank-banque-canada.ca  Fri Dec 22 20:31:37 2006
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 22 Dec 2006 14:31:37 -0500
Subject: [R] Kalman Filter in Control situation.
In-Reply-To: <BAY121-F396E6B34FE6C9B6A781DBD4CF0@phx.gbl>
References: <BAY121-F396E6B34FE6C9B6A781DBD4CF0@phx.gbl>
Message-ID: <458C3299.3000605@bank-banque-canada.ca>

Todd Remund wrote:
> I am looking for a Kalman filter that can handle a control input.  I thought 
> that l.SS was suitable however, I can't get it to work, and wonder if I am 
> not using the right function.  What I want is a Kalman filter that accepts 
> exogenous inputs where the input is found using the algebraic Ricatti 
> equation solution to a penalty function.  If K is the gain matrix then the 
> exogenous input would be u_t = -Kx_n,  where x_n is the Kalman filter state 
> estimate.  These inputs would be entered as such x_t = Ax_t-1 + Bu_t-1 + 
> Ge_t.  

The control input u for l.SS in dse must be specified as (multivariate) 
series (i.e. all periods) in the call to l.SS. So the input does not 
really permit a control (feedback) rule like you seem to have in mind, 
unless you are thinking of the steady state solution to the Ricatti 
equation. However, it does look like this might be specified in the gain 
matrix as part of the state feedback, rather than as an input. (BTW, 
your situation is one where the widely used term "exogenous" is clearly 
incorrect, thus my preference for calling this "input".)

Another (inefficient) possibility would be to iterate to a solution.

>Is l.SS in the dse1 package the correct parametrization of the Kalman 
> filter?

I think it is correct, following some of the classic references. 
However, as Mark Leeds pointed out, there are different conventions. (I 
think, actually, more than two even without considering the input 
series.) The dse specification is a bit special regarding the input, in 
that the input is shifted so that time t can feed through to the state 
and affect the output in the same period t. This is important in some 
economics application, especially at annual frequencies. Others solve 
this problem by having inputs bypass the state and feed directly through 
to the output, in which case the state no longer summarizes the dynamics 
of the process, and is not a state vector in the classic sense.

Paul Gilbert

> 
> Thank you very much,
> Todd Remund
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential inform...{{dropped}}


From yul.zhou at gmail.com  Fri Dec 22 20:36:04 2006
From: yul.zhou at gmail.com (Yuli Zhou)
Date: Fri, 22 Dec 2006 14:36:04 -0500
Subject: [R] heatmap with levelplot?
Message-ID: <ba3cd7630612221136h4cdd1f77s32f2030da0626563@mail.gmail.com>

Hi,

How do I anchor z=0 to the white color in a levelplot so that
the color changes from cyan to magenta precisely as
z changes from negative to positive? Also is it easy to change
color scheme, say to blue/red as it's more dramatic? Is there a
better function for showing heatmap with a color bar?

Thanks in advance for any help, I've played with image,
heatmap and levelplot a little and haven't gotten very far.

Yuli Zhou


From nicolas.mazziotta at swing.be  Fri Dec 22 20:36:03 2006
From: nicolas.mazziotta at swing.be (Nicolas Mazziotta)
Date: Fri, 22 Dec 2006 20:36:03 +0100
Subject: [R] multiline system call
In-Reply-To: <Pine.LNX.4.64.0612221054520.25432@tajo.ucsd.edu>
References: <200612220854.22158.nicolas.mazziotta@swing.be>
	<Pine.LNX.4.64.0612221054520.25432@tajo.ucsd.edu>
Message-ID: <200612222036.03578.nicolas.mazziotta@swing.be>

Dear Sir,

Le vendredi 22 d?cembre 2006 20:05, vous avez ?crit :
> system("sh",intern=T,input=c("echo x","echo y"))

Thanks for the advice, but I do not find doc about the input arg for the 
system function. Besides,

$> system("sh",intern=T,input=c("echo x","echo y"))
Erreur dans system("sh", intern = T, input = c("echo x", "echo y")) :
        unused argument(s) (input = c("echo x", "echo y"))

Is R version 2.4.0 (2006-10-03) too old?

Best regards,


-- 
Nicolas Mazziotta

The contents of this e-mail, including any attachments, are ...{{dropped}}


From ggrothendieck at gmail.com  Fri Dec 22 21:07:20 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 22 Dec 2006 15:07:20 -0500
Subject: [R] multiline system call
In-Reply-To: <200612222036.03578.nicolas.mazziotta@swing.be>
References: <200612220854.22158.nicolas.mazziotta@swing.be>
	<Pine.LNX.4.64.0612221054520.25432@tajo.ucsd.edu>
	<200612222036.03578.nicolas.mazziotta@swing.be>
Message-ID: <971536df0612221207o65f6ba21m4c0a1f927324d14b@mail.gmail.com>

Its only available on Windows.

On 12/22/06, Nicolas Mazziotta <nicolas.mazziotta at swing.be> wrote:
> Dear Sir,
>
> Le vendredi 22 d?cembre 2006 20:05, vous avez ?crit :
> > system("sh",intern=T,input=c("echo x","echo y"))
>
> Thanks for the advice, but I do not find doc about the input arg for the
> system function. Besides,
>
> $> system("sh",intern=T,input=c("echo x","echo y"))
> Erreur dans system("sh", intern = T, input = c("echo x", "echo y")) :
>        unused argument(s) (input = c("echo x", "echo y"))
>
> Is R version 2.4.0 (2006-10-03) too old?
>
> Best regards,
>
>
> --
> Nicolas Mazziotta
>
> The contents of this e-mail, including any attachments, are ...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From deepayan.sarkar at gmail.com  Fri Dec 22 21:16:50 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 22 Dec 2006 12:16:50 -0800
Subject: [R] heatmap with levelplot?
In-Reply-To: <ba3cd7630612221136h4cdd1f77s32f2030da0626563@mail.gmail.com>
References: <ba3cd7630612221136h4cdd1f77s32f2030da0626563@mail.gmail.com>
Message-ID: <eb555e660612221216k1742e82g7dd1fc535dc86402@mail.gmail.com>

On 12/22/06, Yuli Zhou <yul.zhou at gmail.com> wrote:
> Hi,
>
> How do I anchor z=0 to the white color in a levelplot so that
> the color changes from cyan to magenta precisely as
> z changes from negative to positive?

The changepoints are defined by 'at', and the colors are chosen more
or less linearly, so you need to make sure 0 is near the center of
your 'at'. E.g.

levelplot(cor(mtcars), at = seq(-1.01, 1.01, length = 20))


> Also is it easy to change
> color scheme, say to blue/red as it's more dramatic?

Sure, e.g.

bluered = colorRampPalette(c("red", "white", "blue"), space = "Lab")
levelplot(volcano, col.regions = bluered(100), cuts = 99)


> Is there a
> better function for showing heatmap with a color bar?
>
> Thanks in advance for any help, I've played with image,
> heatmap and levelplot a little and haven't gotten very far.
>
> Yuli Zhou
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From daniel.berg2 at gmail.com  Fri Dec 22 21:38:49 2006
From: daniel.berg2 at gmail.com (Daniel Berg)
Date: Fri, 22 Dec 2006 21:38:49 +0100
Subject: [R] building R-package under windows - error - in
	options("deafultPackages") was not found
Message-ID: <f13f1c9c0612221238q652cf3d4t8b30a5f1922ea53a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061222/190b7c65/attachment.pl 

From cberry at tajo.ucsd.edu  Fri Dec 22 23:31:22 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Fri, 22 Dec 2006 14:31:22 -0800
Subject: [R] multiline system call
In-Reply-To: <971536df0612221207o65f6ba21m4c0a1f927324d14b@mail.gmail.com>
References: <200612220854.22158.nicolas.mazziotta@swing.be>
	<Pine.LNX.4.64.0612221054520.25432@tajo.ucsd.edu>
	<200612222036.03578.nicolas.mazziotta@swing.be>
	<971536df0612221207o65f6ba21m4c0a1f927324d14b@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0612221343360.1011@tajo.ucsd.edu>

On Fri, 22 Dec 2006, Gabor Grothendieck wrote:

> Its only available on Windows.

Right, but on linux this works

> system("echo x\necho y",intern=T)
[1] "x" "y"
> system("echo x ; echo y",intern=T)
[1] "x" "y"

so you don't really need input=...

But rereading Nicolas original post, it looks like the problem is 
terminating the input with a ctrl-D.

Perhaps a workaround is to pipe the input into sendmail (I recall sendmail 
accepts input from sdtin) from 'echo'

Note that the single quotes are needed to protect the '\n's until echo is 
ready to act:

> system("echo 'a \n b \n c' | wc ",intern=T)
[1] "      3       3      10"
>

I have exim - not sendmail, but this sends a msg from/to me on my linux 
box:

system("echo 'To:cberry\nthis is a test' | /usr/sbin/exim -f cberry at tajo.ucsd.edu -t "

Maybe this will work for Nicolas.

>
> On 12/22/06, Nicolas Mazziotta <nicolas.mazziotta at swing.be> wrote:
>> Dear Sir,
>>
>> Le vendredi 22 d?cembre 2006 20:05, vous avez ?crit :
>>> system("sh",intern=T,input=c("echo x","echo y"))
>>
>> Thanks for the advice, but I do not find doc about the input arg for the
>> system function. Besides,
>>
>> $> system("sh",intern=T,input=c("echo x","echo y"))
>> Erreur dans system("sh", intern = T, input = c("echo x", "echo y")) :
>>        unused argument(s) (input = c("echo x", "echo y"))
>>
>> Is R version 2.4.0 (2006-10-03) too old?
>>
>> Best regards,
>>
>>
>> --
>> Nicolas Mazziotta
>>
>> The contents of this e-mail, including any attachments, are ...{{dropped}}
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717

From aajakh at yahoo.com  Fri Dec 22 23:45:33 2006
From: aajakh at yahoo.com (ahmad ajakh)
Date: Fri, 22 Dec 2006 14:45:33 -0800 (PST)
Subject: [R] writing R extension
Message-ID: <20061222224533.22514.qmail@web37913.mail.mud.yahoo.com>

Thanks Mike.
AA.

----- Original Message ----
From: Mike Prager <mike.prager at noaa.gov>
To: r-help at stat.math.ethz.ch
Sent: Friday, December 22, 2006 12:45:40 PM
Subject: Re: [R] writing R extension

ahmad ajakh <aajakh at yahoo.com> wrote:

> Hi all,
> I am dealing with the same issue here and I was wondering whether it would be possible to just save
> the R compliled function objects in a directory and just attach the directory to the search path.
> (I am using R2.4.0+ESS+Xemacs in windows XP). 
> 
> Thanks.
> AA.

Yes.  That is what I do with my own functions.  It is MUCH
simpler than writing a package, though not as functional (no
help pages for example.)

Make sure the workspace has only the functions you need, then
save it.  In your .Rprofile, you can put a line like

attach("d:/R/MHP/MHPmisc/.RData")

to add the workspace to the search path.  

This has the advantage that the functions don't show up when you
type ls() -- but they do when you type ls(nn), where nn is the
position of the added workspace on the search path.

I use the following script, stored in file 00make.r in the same
directory as the functions, to speed this up:

#==============================
## Script 00make.r   MHP
## This clears the current workspace, sources all the scripts
## found in the working directory, and then saves the
## workspace for use by later R sessions

# Clear all existing objects in workspace:
rm(list=ls())

# Make a list of all R source files in this directory:
flist = list.files(path = ".", pattern = ".+\.r")

# Remove from the list all files containing the string "00":
# Such files should be used for temporary functions or
# scripts like this one.
flist2 = flist[-grep("00", flist)]

# Source the files:
for (i in 1:length(flist2)) {
   cat("Sourcing", flist2[i],"\n")
   source(flist2[i])
   }
# Remove temporary objects:
rm(i, flist, flist2)
# Save workspace:
save.image()
# Write message to user:
cat("\nNOTE: The workspace has been saved with all
functions.\n",
    "     When exiting R, please do NOT save again.\n")
ls() in
#===============================

-- 
Mike Prager, NOAA, Beaufort, NC
* Opinions expressed are personal and not represented otherwise.
* Any use of tradenames does not constitute a NOAA endorsement.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From suncertain at gmail.com  Sat Dec 23 00:01:10 2006
From: suncertain at gmail.com (HelponR)
Date: Fri, 22 Dec 2006 17:01:10 -0600
Subject: [R] nonparametric significance test for one sample
In-Reply-To: <4ab0fb470612201050x2ed5122t5ce17b50a8f2369@mail.gmail.com>
References: <07E228A5BE53C24CAD490193A7381BBB739D17@LP-EXCHVS07.CO.IHC.COM>
	<4ab0fb470612191523m4e7478c8x6e0b644bd3787c6c@mail.gmail.com>
	<07E228A5BE53C24CAD490193A7381BBB12A0E9@LP-EXCHVS07.CO.IHC.COM>
	<4ab0fb470612201050x2ed5122t5ce17b50a8f2369@mail.gmail.com>
Message-ID: <4ab0fb470612221501n76000aefl5c7fb0a62f92e9bb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061222/5f695b77/attachment.pl 

From bolker at zoo.ufl.edu  Sat Dec 23 02:22:57 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Sat, 23 Dec 2006 01:22:57 +0000 (UTC)
Subject: [R] nonparametric significance test for one sample
References: <07E228A5BE53C24CAD490193A7381BBB739D17@LP-EXCHVS07.CO.IHC.COM>
	<4ab0fb470612191523m4e7478c8x6e0b644bd3787c6c@mail.gmail.com>
	<07E228A5BE53C24CAD490193A7381BBB12A0E9@LP-EXCHVS07.CO.IHC.COM>
	<4ab0fb470612201050x2ed5122t5ce17b50a8f2369@mail.gmail.com>
	<4ab0fb470612221501n76000aefl5c7fb0a62f92e9bb@mail.gmail.com>
Message-ID: <loom.20061223T021858-795@post.gmane.org>

HelponR <suncertain <at> gmail.com> writes:

> 
> Hi, Greg:
> 
> Just let you know that the beta regression package in R can only work for
> data on the open interval (0, 1)
> 
> Do you know any good test of mean for beta distribution? How to verify
> if the data is beta distributed?
> 
> For example, I may want to test the null :
> 
> mean <= 0.0000000001
> 
> I think your idea of testing zero for nonnegative numbers makes sense. But
> it seems to make a null hypothesis on a distribution, not simply mean.
> 
> I could be bettered off if I can find a good nonparametric test which does
> not assume symmetry or a test for beta distribution if the beta
> distribution can be verified.
> 
> Many thanks,
> 
> S

  Possibly contrary to what the documentation for the
beta regression package, the beta distribution has
finite density for 0 and 1 _if_ the shape parameters
are large enough/variance parameter is small enough
(but probably this is not your situation, if you
have lots of zeros).

  fitdistr() in the MASS package will give
a maximum-likelihood fit of the beta distribution
to a univariate distribution, but if you want
to calculate profile confidence limits etc. you
might want to look into the mle() function in 
the stats4 package ...

  Ben Bolker


From Abhijit.Dasgupta at mail.jci.tju.edu  Sat Dec 23 06:03:02 2006
From: Abhijit.Dasgupta at mail.jci.tju.edu (Abhijit Dasgupta)
Date: Sat, 23 Dec 2006 00:03:02 -0500
Subject: [R] bug in odfWeave
Message-ID: <458CB886.30409@mail.jci.tju.edu>

Hi,

I think there is a minor bug in odfWeave. In the function odfStyleGen, 
the following line has an extra "=":

           if(length(grep("italic", thisStyle$fontType)))
               fontText <- c(fontText, tagattr("fo:font-style=", "italic"))
 
This is creating an error if some text needs to be formatted as italic, 
since the corresponding entry in style.xml is "fo:font-style==italic". 
For the windows version, which I'm using, I can't correct since the R 
files are packaged in odfWeave.rdb (or at least I don't know how). 
Hopefully Max Kuhn or someone can update the windows binary to correct 
this.

Abhijit Dasgupta

PS: I found the bug after downloading the source files.


From suncertain at gmail.com  Sat Dec 23 06:07:12 2006
From: suncertain at gmail.com (HelponR)
Date: Fri, 22 Dec 2006 23:07:12 -0600
Subject: [R] nonparametric significance test for one sample
In-Reply-To: <loom.20061223T021858-795@post.gmane.org>
References: <07E228A5BE53C24CAD490193A7381BBB739D17@LP-EXCHVS07.CO.IHC.COM>
	<4ab0fb470612191523m4e7478c8x6e0b644bd3787c6c@mail.gmail.com>
	<07E228A5BE53C24CAD490193A7381BBB12A0E9@LP-EXCHVS07.CO.IHC.COM>
	<4ab0fb470612201050x2ed5122t5ce17b50a8f2369@mail.gmail.com>
	<4ab0fb470612221501n76000aefl5c7fb0a62f92e9bb@mail.gmail.com>
	<loom.20061223T021858-795@post.gmane.org>
Message-ID: <4ab0fb470612222107p1baadd56xca10643d6822f9bd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061222/0ef3c82a/attachment.pl 

From bgreen at dyson.brisnet.org.au  Sat Dec 23 06:07:32 2006
From: bgreen at dyson.brisnet.org.au (Bob Green)
Date: Sat, 23 Dec 2006 15:07:32 +1000
Subject: [R] complex barplot enquiry
Message-ID: <5.1.0.14.0.20061223144502.00d4bc20@pop3.brisnet.org.au>

Hello,

I was hoping for some advice to resolve a problem I am having trouble with.

The data consists of a series of pre and post variables, in a dataframe 
called 'offend'. I am interested in graphically depicting the pre & post 
values for a factor variable called 'decision' which has 4 values : nusm, 
fit, unsound & unfit. An example of a pre and post variable is: pre.damage 
and post.damage (data below). I wanted to exclude all values = 0, and 
collapse the remaining values into 3 categories .e.g 1, 2-5, 6 plus.

For each 'decision' group the final graph would contain the alternating pre 
and post values for 'damage'.  For example, for 'fit' the first bar would 
have a pre value = 18 & a post value = 4, the second pre bar would = 17 and 
the post bar = 2, and the third pre bar would = 2  & the post = 1.

I have experimented with lattice, entering the values (e.g as per above), 
however I was hoping to find a solution to directly extract the data from 
the dataframe as I wanted to generate 16 such graphs.

Any assistance is much appreciated,


regards

Bob Green

 > table(decision,pre.damage)
          pre.damage
decision    0      1   2   3   4   5   6   7   8   9  10  11  13  14 20
   fit           89   18    9   4   2   2   1   0   0   1   0   0   0   0   0
   nusm     158  44  15   5   5   6   6   3   1   1   2   0   0   0   0
   unfit         27    2   2   0   0   1   0   0   0   0   0   0   0   0   0
   unsound 333  68  36   8   5   4   1   0   0   0   0   1   1   1   1

 > table(decision,post.damage)
          post.damage
decision    0      1    2   3   4   5   6   7  10  12  13
   fit     	     119    4    1   1   0   0   0   0   1   0   0
   nusm     212  16   11   2   0   2   1   1   0   1   0
   unfit         31    1    0   0   0   0   0   0   0   0   0
   unsound 441    8    5   3   1   0   0   0   0   0   1


From nicolas.mazziotta at swing.be  Sat Dec 23 07:12:09 2006
From: nicolas.mazziotta at swing.be (Nicolas Mazziotta)
Date: Sat, 23 Dec 2006 07:12:09 +0100
Subject: [R] multiline system call
In-Reply-To: <Pine.LNX.4.64.0612221343360.1011@tajo.ucsd.edu>
References: <200612220854.22158.nicolas.mazziotta@swing.be>
	<971536df0612221207o65f6ba21m4c0a1f927324d14b@mail.gmail.com>
	<Pine.LNX.4.64.0612221343360.1011@tajo.ucsd.edu>
Message-ID: <200612230712.09746.nicolas.mazziotta@swing.be>

Le vendredi 22 d?cembre 2006 23:31, Charles C. Berry a ?crit?:
> Perhaps a workaround is to pipe the input into sendmail (I recall sendmail
> accepts input from sdtin) from 'echo'

This works fine this way. Thanks a lot.

(but note that my 2.4.0 linux binary does not accept the "input=xyz" as an 
argument of the system() function.)

-- 
Nicolas Mazziotta

The contents of this e-mail, including any attachments, are ...{{dropped}}


From ripley at stats.ox.ac.uk  Sat Dec 23 08:26:36 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 23 Dec 2006 07:26:36 +0000 (GMT)
Subject: [R] multiline system call
In-Reply-To: <200612230712.09746.nicolas.mazziotta@swing.be>
References: <200612220854.22158.nicolas.mazziotta@swing.be>
	<971536df0612221207o65f6ba21m4c0a1f927324d14b@mail.gmail.com>
	<Pine.LNX.4.64.0612221343360.1011@tajo.ucsd.edu>
	<200612230712.09746.nicolas.mazziotta@swing.be>
Message-ID: <Pine.LNX.4.64.0612230723390.18209@gannet.stats.ox.ac.uk>

On Sat, 23 Dec 2006, Nicolas Mazziotta wrote:

> Le vendredi 22 d?cembre 2006 23:31, Charles C. Berry a ?crit?:
>> Perhaps a workaround is to pipe the input into sendmail (I recall sendmail
>> accepts input from sdtin) from 'echo'
>
> This works fine this way. Thanks a lot.
>
> (but note that my 2.4.0 linux binary does not accept the "input=xyz" as an
> argument of the system() function.)

Nor should it, but you failed to tell us what your OS was, and it matters 
in this query (as in many others) which is why the posting guide asked 
you to supply such information.

system() differs fundamentally by OS: it uses a shell on Unix-alikes but 
not on Windows.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ligges at statistik.uni-dortmund.de  Sat Dec 23 12:17:56 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 23 Dec 2006 12:17:56 +0100
Subject: [R] building R-package under windows - error -
 in	options("deafultPackages") was not found
In-Reply-To: <f13f1c9c0612221238q652cf3d4t8b30a5f1922ea53a@mail.gmail.com>
References: <f13f1c9c0612221238q652cf3d4t8b30a5f1922ea53a@mail.gmail.com>
Message-ID: <458D1064.8040704@statistik.uni-dortmund.de>



Daniel Berg wrote:
> Dear all,
> 
> I have been building R packages under windows on my old pc, successfully.
> Now I have bought a new pc, still running windows, and I am trying to build
> the same R packages as before, but now without the same success. I have
> installed the Rtools, perl, mingw and added them to the environment
> variables.
> I am running Windows XP Professional on a Thinkpad T60. I have installed
> R-2.4.1, ActivePerl 5.8.8 Build 819, MinGW 5.1.2, and I downloaded
> tools.zipfrom
> http://www.murdoch-sutherland.com/Rtools.
> 
> I receive the following error message:
> 
> $ Rcmd build --binary copulaGOF/
> * checking for file 'mypackage/DESCRIPTION' ... OK
> * preparing 'copulaGOF' :
> * checking DESCRIPTION meta-information ... ERROR

Looks like something is wrong with your DESCRIPTION file. Can you send 
us the contents of that file?

Uwe Ligges


> During startup - Warning messages :
> ' in: library(package, lib.loc = lob.loc, character.only = TRUE, logical =
> TRUE,
>  in options("defaultPackages") was not found
> 
> In my package I have included a zzz.r file that contains the following,
> perhaps this is the cause?
> .First.lib <-function (lib, pkg)   {
>     library(adapt)
>     library(copula)
>     library(fBasics)
>     library(mvtnorm)
>     runif(1)
>     library.dynam("mypackage", package="mypackage")
> }
> 
> Any help or comments is most welcome. Thank you.
> 
> Best wishes,
> Daniel Berg
> -----
> danielberg.no
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Sat Dec 23 12:45:46 2006
From: ripley at stats.ox.ac.uk (Brian Ripley)
Date: Sat, 23 Dec 2006 11:45:46 +0000 (GMT)
Subject: [R] building R-package under windows - error - in
 options("deafultPackages") was not found
In-Reply-To: <458D1064.8040704@statistik.uni-dortmund.de>
References: <f13f1c9c0612221238q652cf3d4t8b30a5f1922ea53a@mail.gmail.com>
	<458D1064.8040704@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.64.0612231143300.7744@auk.stats>

On Sat, 23 Dec 2006, Uwe Ligges wrote:

>
>
> Daniel Berg wrote:
>> Dear all,
>>
>> I have been building R packages under windows on my old pc, successfully.
>> Now I have bought a new pc, still running windows, and I am trying to build
>> the same R packages as before, but now without the same success. I have
>> installed the Rtools, perl, mingw and added them to the environment
>> variables.
>> I am running Windows XP Professional on a Thinkpad T60. I have installed
>> R-2.4.1, ActivePerl 5.8.8 Build 819, MinGW 5.1.2, and I downloaded
>> tools.zipfrom
>> http://www.murdoch-sutherland.com/Rtools.
>>
>> I receive the following error message:
>>
>> $ Rcmd build --binary copulaGOF/
>> * checking for file 'mypackage/DESCRIPTION' ... OK
>> * preparing 'copulaGOF' :
>> * checking DESCRIPTION meta-information ... ERROR
>
> Looks like something is wrong with your DESCRIPTION file. Can you send
> us the contents of that file?

I think rather with his R: the message below says 'During startup', and 
indicates that one of the default packages is missing.  That would mean 
that it has not got to running the code to look at DESCRIPTION.

>
> Uwe Ligges
>
>
>> During startup - Warning messages :
>> ' in: library(package, lib.loc = lob.loc, character.only = TRUE, logical =
>> TRUE,
>>  in options("defaultPackages") was not found
>>
>> In my package I have included a zzz.r file that contains the following,
>> perhaps this is the cause?
>> .First.lib <-function (lib, pkg)   {
>>     library(adapt)
>>     library(copula)
>>     library(fBasics)
>>     library(mvtnorm)
>>     runif(1)
>>     library.dynam("mypackage", package="mypackage")
>> }
>>
>> Any help or comments is most welcome. Thank you.
>>
>> Best wishes,
>> Daniel Berg
>> -----
>> danielberg.no
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Hansens at metro.dst.or.us  Sat Dec 23 01:35:10 2006
From: Hansens at metro.dst.or.us (Steven Hansen)
Date: Fri, 22 Dec 2006 16:35:10 -0800
Subject: [R] seek() - What is the largest integer that can be used?
Message-ID: <20061222T163510Z_827D00180000@metro.dst.or.us>

I am attempting to use seek() to navigate through a large binary file (3GB).  I would like to move to a file position which would require my "where" value to be greater than 2*10^9.  This doesn't appear to be working, however.  Is there any way around this problem on a 32-bit OS?  If not I plan to modify my code to move through the binary file in smaller steps.  I was curious as to whether there was another solution.
Thank you for your help.
-Steve

Steve Hansen
Transportation Planner
Metro
600 NE Grand Ave
Portland, OR 97232
(503)797-1894
hansens at metro.dst.or.us

From liuwensui at gmail.com  Sat Dec 23 16:56:11 2006
From: liuwensui at gmail.com (Wensui Liu)
Date: Sat, 23 Dec 2006 10:56:11 -0500
Subject: [R] OT: any recommendation for scripting language
Message-ID: <1115a2b00612230756g7cf6fd0emcbec62b832402d05@mail.gmail.com>

Right now, I am using SAS and S+/R. As a new year resolution, I am
planning to learn a scripting language.

from statisticians' point of view, which scripting language is worth
to learn, perl, python, or any other recommendation? (Most likely, I
will be learning it in windows.) Since I am not in research, I will
prefer one widely used in industry and related to statistical work.

if you recommend one, I will really appreciate it if you could point
out a good source for learning as well.

thank you so much!

Have a happy holiday.

wensui


From ggrothendieck at gmail.com  Sat Dec 23 17:46:17 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 23 Dec 2006 11:46:17 -0500
Subject: [R] OT: any recommendation for scripting language
In-Reply-To: <1115a2b00612230756g7cf6fd0emcbec62b832402d05@mail.gmail.com>
References: <1115a2b00612230756g7cf6fd0emcbec62b832402d05@mail.gmail.com>
Message-ID: <971536df0612230846r38b310b9y5dcce01c7a049c2a@mail.gmail.com>

I used gawk and perl prior to using R but as I got more proficient in
R I found I could do just about everything in R itself and have largely
forgotten perl at this point and rarely use gawk either.  I must say
I never liked perl and if python were more mature back then I
probably would have used that.

I do use Windows batch commands and javascript, e.g.
  http://code.google.com/p/batchfiles/
for situations where I want self contained, no dependency, installation
and configuration scripts; however, I don't really like Windows batch
commands and if it were not for the requirement of no dependencies
I would not use it.   This does have the disadvantage of not being
portable to other OSes but the no dependency requirement is
overriding in these situations.

Maybe if you could discuss what you intend to do more can be said.

On 12/23/06, Wensui Liu <liuwensui at gmail.com> wrote:
> Right now, I am using SAS and S+/R. As a new year resolution, I am
> planning to learn a scripting language.
>
> from statisticians' point of view, which scripting language is worth
> to learn, perl, python, or any other recommendation? (Most likely, I
> will be learning it in windows.) Since I am not in research, I will
> prefer one widely used in industry and related to statistical work.
>
> if you recommend one, I will really appreciate it if you could point
> out a good source for learning as well.
>
> thank you so much!
>
> Have a happy holiday.
>
> wensui
>


From ripley at stats.ox.ac.uk  Sat Dec 23 18:25:13 2006
From: ripley at stats.ox.ac.uk (Brian Ripley)
Date: Sat, 23 Dec 2006 17:25:13 +0000 (GMT)
Subject: [R] seek() - What is the largest integer that can be used?
In-Reply-To: <20061222T163510Z_827D00180000@metro.dst.or.us>
References: <20061222T163510Z_827D00180000@metro.dst.or.us>
Message-ID: <Pine.LNX.4.64.0612231718190.22158@auk.stats>

This is discussed in the R-admin manual.  You cannot use integers, and 
'where' is documented as numeric, not integer.  You may have to set 
options at configure time, depending on your OS (although recent versions 
of R are good at figuring these out).

On decent 32-bit OSes this does work.  You haven't studied the posting 
guide and hence failed to tell us what yours is, nor have you provided

> commented, minimal, self-contained, reproducible code

(Nor have you told us your R version.)

On Fri, 22 Dec 2006, Steven Hansen wrote:

> I am attempting to use seek() to navigate through a large binary file 
> (3GB).  I would like to move to a file position which would require my 
> "where" value to be greater than 2*10^9.  This doesn't appear to be 
> working, however.  Is there any way around this problem on a 32-bit OS? 
> If not I plan to modify my code to move through the binary file in 
> smaller steps.  I was curious as to whether there was another solution.

That will not work unless your OS supports seek on files > 2GB, in which 
case direct seek should work.

> Thank you for your help.
> -Steve
>
> Steve Hansen
> Transportation Planner
> Metro
> 600 NE Grand Ave
> Portland, OR 97232
> (503)797-1894
> hansens at metro.dst.or.us
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kubovy at virginia.edu  Sat Dec 23 19:23:21 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Sat, 23 Dec 2006 13:23:21 -0500
Subject: [R] complex barplot enquiry
In-Reply-To: <5.1.0.14.0.20061223144502.00d4bc20@pop3.brisnet.org.au>
References: <5.1.0.14.0.20061223144502.00d4bc20@pop3.brisnet.org.au>
Message-ID: <8EFDF87D-F60B-4769-BA16-7F40B947FF25@virginia.edu>

On Dec 23, 2006, at 12:07 AM, Bob Green wrote:

<snip>

> The data consists of a series of pre and post variables, in a  
> dataframe
> called 'offend'. I am interested in graphically depicting the pre &  
> post
> values for a factor variable called 'decision' which has 4 values :  
> nusm,
> fit, unsound & unfit. An example of a pre and post variable is:  
> pre.damage
> and post.damage (data below). I wanted to exclude all values = 0, and
> collapse the remaining values into 3 categories .e.g 1, 2-5, 6 plus.
>
> For each 'decision' group the final graph would contain the  
> alternating pre
> and post values for 'damage'.  For example, for 'fit' the first bar  
> would
> have a pre value = 18 & a post value = 4, the second pre bar would  
> = 17 and
> the post bar = 2, and the third pre bar would = 2  & the post = 1.

<snip>

> > table(decision,pre.damage)
>           pre.damage
> decision    0      1   2   3   4   5   6   7   8   9  10  11  13   
> 14 20
>    fit           89   18    9   4   2   2   1   0   0   1   0   0    
> 0   0   0
>    nusm     158  44  15   5   5   6   6   3   1   1   2   0   0    
> 0   0
>    unfit         27    2   2   0   0   1   0   0   0   0   0   0    
> 0   0   0
>    unsound 333  68  36   8   5   4   1   0   0   0   0   1   1   1   1
>
> > table(decision,post.damage)
>           post.damage
> decision    0      1    2   3   4   5   6   7  10  12  13
>    fit     	     119    4    1   1   0   0   0   0   1   0   0
>    nusm     212  16   11   2   0   2   1   1   0   1   0
>    unfit         31    1    0   0   0   0   0   0   0   0   0
>    unsound 441    8    5   3   1   0   0   0   0   0   1

Could you please post commands to define the df 'offend'?
_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/


From hold9309 at uidaho.edu  Sat Dec 23 19:50:40 2006
From: hold9309 at uidaho.edu (Zack Holden)
Date: Sat, 23 Dec 2006 10:50:40 -0800
Subject: [R] Canonical analysis with class variable?
Message-ID: <ENELKPGLMLHJKMFDAGLCEEHPCFAA.hold9309@uidaho.edu>

Dear list,

I'm trying to compare two sets of variables using canonical analysis. My X
variables include 3 climate indices, all continuous. My Y variables describe
a set of 3 environmental moisture measurements. However, I would also like
to include a class variable for habitat type.

My colleaugue was able to do this in SAS, but we could not find a way to do
it in R.

Is anyone familiar enough with manova techniques in R to tell me whether
this is possible, and if it is, how to do it?

Thanks in advance for any advice,

Zack


From ivowel at gmail.com  Sat Dec 23 20:51:00 2006
From: ivowel at gmail.com (ivo welch)
Date: Sat, 23 Dec 2006 14:51:00 -0500
Subject: [R] simple NLS query
Message-ID: <50d1c22d0612231151s68eec055wb23fd17ebfc6c220@mail.gmail.com>

dear R experts:  I am trying to orient myself using nls().  so, I am
just trying to copy and adapt an example in the nls() function:

  > d= data.frame( y= runif(10), x= runif(10) )
  > nls( y ~ 1/(1+x), data = d, start= list(x=0.5,y=0.5), trace=TRUE)
  Error in n%%respLength : non-numeric argument to binary operator

the error message seems internal, so it would be nicer if there was a
better error message.  I presume my mistake is so basic that an R
expert sees the problem in 1 second.

(if I manage to figure this one out, my next step will be to learn how
I can get [presumably asymptotic ML] standard errors on estimated
coefficients.  I hope I am looking in the right direction with the
nls() function.)

advice appreciated.

regards,

/ivo


From gregor.gorjanc at bfro.uni-lj.si  Sat Dec 23 20:54:21 2006
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Sat, 23 Dec 2006 20:54:21 +0100
Subject: [R] [Fwd: [AGDG-LIST:428] Summer Course in Guelph]
Message-ID: <458D896D.3070407@bfro.uni-lj.si>



-------- Original Message --------
Subject: [AGDG-LIST:428] Summer Course in Guelph
Date: Fri, 22 Dec 2006 09:12:24 -0500
From: Larry Schaeffer <lrs at uoguelph.ca>
Reply-To: lrs at uoguelph.ca
To: Animal Geneticist's Discussion <agdg-list at colostate.edu>

The Centre for Genetic Improvement of Livestock at the University of
Guelph is pleased
to announce a one week summer course entitled "Animal Breeding
Applications Using R" to be
given by Bill Szkotnicki and Larry Schaeffer from June 11 to June 15,
2007.  Details will be
available in the new year on the CGIL website:
http://cgil.uoguelph.ca/

The content of the course will be:

Introduction to R
Getting data in and out
Introductory statistical models
Packages and graphics functions
Distributions and simulations
Developing your own functions
Accessing the operating system
The R API
Database connectivity
Programming in R using Fortran and C subroutines
Animal breeding applications
- Inbreeding routines
- Animal models
- Iteration on data
- Maternal genetic effects
- Multiple traits
- Random regression
- Threshold models
- Genomic applications

On the application form you will be able to indicate particular problems
that
you would like to see covered, and we will try to work them into the
course.


-- 
Lep pozdrav / With regards,
    Gregor Gorjanc
----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.


From cberry at tajo.ucsd.edu  Sat Dec 23 22:03:34 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Sat, 23 Dec 2006 13:03:34 -0800
Subject: [R] simple NLS query
In-Reply-To: <50d1c22d0612231151s68eec055wb23fd17ebfc6c220@mail.gmail.com>
References: <50d1c22d0612231151s68eec055wb23fd17ebfc6c220@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0612231251140.8986@tajo.ucsd.edu>



See the nls help page:

Arguments

 	formula a nonlinear model formula including variables and parameters.

and you have

 	y ~ 1/(1+x)

which does not seem to match the requirement of the help page.

What are the unknowns for which you were hoping nls would solve??

On Sat, 23 Dec 2006, ivo welch wrote:

> dear R experts:  I am trying to orient myself using nls().  so, I am
> just trying to copy and adapt an example in the nls() function:
>
>  > d= data.frame( y= runif(10), x= runif(10) )
>  > nls( y ~ 1/(1+x), data = d, start= list(x=0.5,y=0.5), trace=TRUE)
>  Error in n%%respLength : non-numeric argument to binary operator
>
> the error message seems internal, so it would be nicer if there was a
> better error message.  I presume my mistake is so basic that an R
> expert sees the problem in 1 second.
>
> (if I manage to figure this one out, my next step will be to learn how
> I can get [presumably asymptotic ML] standard errors on estimated
> coefficients.

Look at the help page for nls. Specifically under 'Details'.


I hope I am looking in the right direction with the
> nls() function.)
>
> advice appreciated.
>
> regards,
>
> /ivo
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717


From ivowel at gmail.com  Sat Dec 23 22:36:09 2006
From: ivowel at gmail.com (ivo welch)
Date: Sat, 23 Dec 2006 16:36:09 -0500
Subject: [R] simple NLS query
In-Reply-To: <Pine.LNX.4.64.0612231251140.8986@tajo.ucsd.edu>
References: <50d1c22d0612231151s68eec055wb23fd17ebfc6c220@mail.gmail.com>
	<Pine.LNX.4.64.0612231251140.8986@tajo.ucsd.edu>
Message-ID: <50d1c22d0612231336p4811fb8ct4862e98b3561bd2d@mail.gmail.com>

duh!  thanks.

  summary(nls( y ~ 1/(1+b*x), data = d, start= list(b=0.5)))

works, of course.

/iaw


On 12/23/06, Charles C. Berry <cberry at tajo.ucsd.edu> wrote:
>
>
> See the nls help page:
>
> Arguments
>
>         formula a nonlinear model formula including variables and parameters.
>
> and you have
>
>         y ~ 1/(1+x)
>
> which does not seem to match the requirement of the help page.
>
> What are the unknowns for which you were hoping nls would solve??
>
> On Sat, 23 Dec 2006, ivo welch wrote:
>
> > dear R experts:  I am trying to orient myself using nls().  so, I am
> > just trying to copy and adapt an example in the nls() function:
> >
> >  > d= data.frame( y= runif(10), x= runif(10) )
> >  > nls( y ~ 1/(1+x), data = d, start= list(x=0.5,y=0.5), trace=TRUE)
> >  Error in n%%respLength : non-numeric argument to binary operator
> >
> > the error message seems internal, so it would be nicer if there was a
> > better error message.  I presume my mistake is so basic that an R
> > expert sees the problem in 1 second.
> >
> > (if I manage to figure this one out, my next step will be to learn how
> > I can get [presumably asymptotic ML] standard errors on estimated
> > coefficients.
>
> Look at the help page for nls. Specifically under 'Details'.
>
>
> I hope I am looking in the right direction with the
> > nls() function.)
> >
> > advice appreciated.
> >
> > regards,
> >
> > /ivo
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> Charles C. Berry                        (858) 534-2098
>                                           Dept of Family/Preventive Medicine
> E mailto:cberry at tajo.ucsd.edu            UC San Diego
> http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717
>
>
>


From fisk at bowdoin.edu  Sun Dec 24 00:14:44 2006
From: fisk at bowdoin.edu (steve)
Date: Sat, 23 Dec 2006 18:14:44 -0500
Subject: [R] Hmisc - latex - table.env not observed
Message-ID: <emkd92$f92$1@sea.gmane.org>

The following code

library(Hmisc)
x = 1:10
y = x
latex(summary(x~y),table.env=FALSE)
latex(summary(cbind(x,y)),table.env=FALSE)

should produce latex output that is not a table. The second  one 
produces just a tabular, as it should. However, the first one produces a 
tabular embedded in a table. (This is the effect if you leave 
table.env=FALSE out).


From jingjiangyan at gmail.com  Sun Dec 24 02:08:02 2006
From: jingjiangyan at gmail.com (jingjiang yan)
Date: Sun, 24 Dec 2006 09:08:02 +0800
Subject: [R] how to do the "double substitute" in a loop?
Message-ID: <edc929b40612231708k37bcf4c6x8dfa0160df64bfa@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061224/b312efd7/attachment.pl 

From jholtman at gmail.com  Sun Dec 24 02:35:14 2006
From: jholtman at gmail.com (jim holtman)
Date: Sat, 23 Dec 2006 20:35:14 -0500
Subject: [R] how to do the "double substitute" in a loop?
In-Reply-To: <edc929b40612231708k37bcf4c6x8dfa0160df64bfa@mail.gmail.com>
References: <edc929b40612231708k37bcf4c6x8dfa0160df64bfa@mail.gmail.com>
Message-ID: <644e1f320612231735h68411a4ay84372e000f8cf426@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061223/e5b0c810/attachment.pl 

From ivowel at gmail.com  Sun Dec 24 02:46:46 2006
From: ivowel at gmail.com (ivo welch)
Date: Sat, 23 Dec 2006 20:46:46 -0500
Subject: [R] extend summary.lm for hccm?
Message-ID: <50d1c22d0612231746g7129024cla25d39a6264bbda1@mail.gmail.com>

dear R experts:

I wonder whether it is possible to extend the summary method for the
lm function, so that it uses an option "hccm" (well, model "hc0").  In
my line of work, it is pretty much required in reporting of almost all
linear regressions these days, which means that it would be very nice
not to have to manually library car, then sqrt the diagonal, and
recompute T-stats; instead, I would love to get everything in the same
format as the current output---except errors heteroskedasticity
adjusted.

easy or hard?

regards,

/iaw


From jim at bitwrit.com.au  Sun Dec 24 03:55:00 2006
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 24 Dec 2006 13:55:00 +1100
Subject: [R] OT: any recommendation for scripting language
In-Reply-To: <1115a2b00612230756g7cf6fd0emcbec62b832402d05@mail.gmail.com>
References: <1115a2b00612230756g7cf6fd0emcbec62b832402d05@mail.gmail.com>
Message-ID: <458DEC04.3030204@bitwrit.com.au>

Wensui Liu wrote:
> Right now, I am using SAS and S+/R. As a new year resolution, I am
> planning to learn a scripting language.
> 
> from statisticians' point of view, which scripting language is worth
> to learn, perl, python, or any other recommendation? (Most likely, I
> will be learning it in windows.) Since I am not in research, I will
> prefer one widely used in industry and related to statistical work.
> 
> if you recommend one, I will really appreciate it if you could point
> out a good source for learning as well.
> 
Hi Wensui,
I use Tcl-Tk quite a bit. I found it very easy to learn, and as you can 
see from the tcl-tk package in R, very flexible. It is particularly good 
at spanning the range from a slick-looking GUI to low level file and 
computation operations. I'm currently using it to pick individual 
records out of a database, calculate age and sex specific deviations 
from population norms and then present a graphical display to the user.

There is not only excellent documentation available for Tcl-Tk, but 
several newsgroups and wikis.

http://www.tcl.tk

Jim


From edd at debian.org  Sun Dec 24 05:16:04 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 23 Dec 2006 22:16:04 -0600
Subject: [R] extend summary.lm for hccm?
In-Reply-To: <50d1c22d0612231746g7129024cla25d39a6264bbda1@mail.gmail.com>
References: <50d1c22d0612231746g7129024cla25d39a6264bbda1@mail.gmail.com>
Message-ID: <17805.65284.624986.607931@basebud.nulle.part>


On 23 December 2006 at 20:46, ivo welch wrote:
| I wonder whether it is possible to extend the summary method for the
| lm function, so that it uses an option "hccm" (well, model "hc0").  In
| my line of work, it is pretty much required in reporting of almost all
| linear regressions these days, which means that it would be very nice
| not to have to manually library car, then sqrt the diagonal, and
| recompute T-stats; instead, I would love to get everything in the same
| format as the current output---except errors heteroskedasticity
| adjusted.
| 
| easy or hard?

Did you consider the 'sandwich' package? A simple

	> install.packages("sandwich")
	> library(sandwich)
	> ?vcovHC
	> ?vcovHAC
	
should get you there.

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From christos at nuverabio.com  Sun Dec 24 06:06:05 2006
From: christos at nuverabio.com (Christos Hatzis)
Date: Sun, 24 Dec 2006 00:06:05 -0500
Subject: [R] how to 'get' an object that is part of a list
Message-ID: <003001c72719$37b39490$0202a8c0@headquarters.silicoinsights>

This might be an trivial thing but I am stuck.

Consider: 
 
xx <- list(a=1:5, b=letters[1:5])
 
Although object xx is accessible through its name,
how can object xx$b be accessed similarly through its name?
 
> get("xx")
$a
[1] 1 2 3 4 5

$b
[1] "a" "b" "c" "d" "e"

> get("xx$b")
Error in get(x, envir, mode, inherits) : variable "xx$b" was not found
 
get("xx")$b will not work in my case because it will probably require
parsing to make it work within a function. E.g.

my.length <- function(...) {
	names <- as.character(substitute(list(...)))[-1]
	sapply(names, FUN=function(x){y <- get(x); length(y)})
}
> my.length(xx)
xx 
 2 
> my.length(xx$a)
Error in get(x, envir, mode, inherits) : variable "xx$a" was not found
> my.length(xx$a, xx$b)
Error in get(x, envir, mode, inherits) : variable "xx$a" was not found
	
Thank you.
 
Christos Hatzis, Ph.D.
Nuvera Biosciences, Inc.
400 West Cummings Park
Suite 5350
Woburn, MA 01801
Tel: 781-938-3830
www.nuverabio.com


From f.harrell at vanderbilt.edu  Sun Dec 24 06:34:18 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 23 Dec 2006 23:34:18 -0600
Subject: [R] Hmisc - latex - table.env not observed
In-Reply-To: <emkd92$f92$1@sea.gmane.org>
References: <emkd92$f92$1@sea.gmane.org>
Message-ID: <458E115A.8070707@vanderbilt.edu>

steve wrote:
> The following code
> 
> library(Hmisc)
> x = 1:10
> y = x
> latex(summary(x~y),table.env=FALSE)
> latex(summary(cbind(x,y)),table.env=FALSE)
> 
> should produce latex output that is not a table. The second  one 
> produces just a tabular, as it should. However, the first one produces a 
> tabular embedded in a table. (This is the effect if you leave 
> table.env=FALSE out).

summary(x~y) produces a summary.formula.response object and 
latex.summary.formula.response generates a caption for the table. 
Whenever latex.default sees a caption it sets table.env to TRUE.

You might try the ctable option if you have the ctable style installed 
in LaTeX or we can think about respecting table.env more fully.  But I 
wouldn't know what to do with the caption then.

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From jholtman at gmail.com  Sun Dec 24 07:10:38 2006
From: jholtman at gmail.com (jim holtman)
Date: Sun, 24 Dec 2006 01:10:38 -0500
Subject: [R] how to 'get' an object that is part of a list
In-Reply-To: <003001c72719$37b39490$0202a8c0@headquarters.silicoinsights>
References: <003001c72719$37b39490$0202a8c0@headquarters.silicoinsights>
Message-ID: <644e1f320612232210h3272d5e3k96f4188038fb8a27@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061224/4ea455a4/attachment.pl 

From christos at nuverabio.com  Sun Dec 24 07:14:21 2006
From: christos at nuverabio.com (Christos Hatzis)
Date: Sun, 24 Dec 2006 01:14:21 -0500
Subject: [R] how to 'get' an object that is part of a list
In-Reply-To: <644e1f320612232210h3272d5e3k96f4188038fb8a27@mail.gmail.com>
Message-ID: <003501c72722$c0e78c40$0202a8c0@headquarters.silicoinsights>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061224/3e7066dc/attachment.pl 

From murdoch at stats.uwo.ca  Sun Dec 24 11:54:34 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 24 Dec 2006 05:54:34 -0500
Subject: [R] how to 'get' an object that is part of a list
In-Reply-To: <003001c72719$37b39490$0202a8c0@headquarters.silicoinsights>
References: <003001c72719$37b39490$0202a8c0@headquarters.silicoinsights>
Message-ID: <458E5C6A.6030404@stats.uwo.ca>

On 12/24/2006 12:06 AM, Christos Hatzis wrote:
> This might be an trivial thing but I am stuck.
> 
> Consider: 
>  
> xx <- list(a=1:5, b=letters[1:5])
>  
> Although object xx is accessible through its name,
> how can object xx$b be accessed similarly through its name?

name <- "b"
xx[[name]]

will work.

Duncan Murdoch

>  
>> get("xx")
> $a
> [1] 1 2 3 4 5
> 
> $b
> [1] "a" "b" "c" "d" "e"
> 
>> get("xx$b")
> Error in get(x, envir, mode, inherits) : variable "xx$b" was not found
>  
> get("xx")$b will not work in my case because it will probably require
> parsing to make it work within a function. E.g.
> 
> my.length <- function(...) {
> 	names <- as.character(substitute(list(...)))[-1]
> 	sapply(names, FUN=function(x){y <- get(x); length(y)})
> }
>> my.length(xx)
> xx 
>  2 
>> my.length(xx$a)
> Error in get(x, envir, mode, inherits) : variable "xx$a" was not found
>> my.length(xx$a, xx$b)
> Error in get(x, envir, mode, inherits) : variable "xx$a" was not found
> 	
> Thank you.
>  
> Christos Hatzis, Ph.D.
> Nuvera Biosciences, Inc.
> 400 West Cummings Park
> Suite 5350
> Woburn, MA 01801
> Tel: 781-938-3830
> www.nuverabio.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Sun Dec 24 13:41:24 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 24 Dec 2006 07:41:24 -0500
Subject: [R] how to 'get' an object that is part of a list
In-Reply-To: <644e1f320612232210h3272d5e3k96f4188038fb8a27@mail.gmail.com>
References: <003001c72719$37b39490$0202a8c0@headquarters.silicoinsights>
	<644e1f320612232210h3272d5e3k96f4188038fb8a27@mail.gmail.com>
Message-ID: <971536df0612240441w44e2843etf32538ae37f1d604@mail.gmail.com>

Is this what you are looking for:

> my.length.2 <- function(...) {
+    f <- function(nm, val) length(val)
+    mapply(f, make.names(as.list(match.call()[-1])), list(...))
+ }
> my.length.2(xx, xx$b)
  xx xx.b
   2    5

On 12/24/06, jim holtman <jholtman at gmail.com> wrote:
> use 'eval' and 'parse'
>
>
> > xx
> $a
> [1] 1 2 3 4 5
>
> $b
> [1] "a" "b" "c" "d" "e"
>
> > eval(parse(text='xx$a'))
> [1] 1 2 3 4 5
> >
>
> So that way you can pass in the character string and then 'parse' it.
>
>
>
> On 12/24/06, Christos Hatzis <christos at nuverabio.com> wrote:
> >
> > This might be an trivial thing but I am stuck.
> >
> > Consider:
> >
> > xx <- list(a=1:5, b=letters[1:5])
> >
> > Although object xx is accessible through its name,
> > how can object xx$b be accessed similarly through its name?
> >
> > > get("xx")
> > $a
> > [1] 1 2 3 4 5
> >
> > $b
> > [1] "a" "b" "c" "d" "e"
> >
> > > get("xx$b")
> > Error in get(x, envir, mode, inherits) : variable "xx$b" was not found
> >
> > get("xx")$b will not work in my case because it will probably require
> > parsing to make it work within a function. E.g.
> >
> > my.length <- function(...) {
> >        names <- as.character(substitute(list(...)))[-1]
> >        sapply(names, FUN=function(x){y <- get(x); length(y)})
> > }
> > > my.length(xx)
> > xx
> > 2
> > > my.length(xx$a)
> > Error in get(x, envir, mode, inherits) : variable "xx$a" was not found
> > > my.length(xx$a, xx$b)
> > Error in get(x, envir, mode, inherits) : variable "xx$a" was not found
> >
> > Thank you.
> >
> > Christos Hatzis, Ph.D.
> > Nuvera Biosciences, Inc.
> > 400 West Cummings Park
> > Suite 5350
> > Woburn, MA 01801
> > Tel: 781-938-3830
> > www.nuverabio.com
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> --
> Jim Holtman
> Cincinnati, OH
> +1 513 646 9390
>
> What is the problem you are trying to solve?
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jfox at mcmaster.ca  Sun Dec 24 15:45:44 2006
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 24 Dec 2006 09:45:44 -0500
Subject: [R] extend summary.lm for hccm?
In-Reply-To: <17805.65284.624986.607931@basebud.nulle.part>
Message-ID: <20061224144542.QOCZ17401.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Dirk and Ivo,

It's true that the sandwich package has more extensive facilities for
sandwich variance estimation than the hccm function in the car package, but
I think that the thrust of Ivo's question is to get a model summary that
automatically uses the adjusted standard errors rather than having to
compute them and use them "manually."  Here's one approach, which could be
modified slightly if Ivo wants "hc0" as the default; it could also be
adapted to use the sandwich package.

I hope this helps,
 John

----------- snip --------------

summaryHCCM <- function(model, ...) UseMethod("summaryHCCM")

summaryHCCM.lm <- function(model, type=c("hc3", "hc0", "hc1", "hc2", "hc4"),

    ...){
    if (!require(car)) stop("Required car package is missing.")
    type <- match.arg(type)
    V <- hccm(model, type=type)
    sumry <- summary(model)
    table <- coef(sumry)
    table[,2] <- sqrt(diag(V))
    table[,3] <- table[,1]/table[,2]
    table[,4] <- 2*pt(abs(table[,3]), df.residual(model), lower.tail=FALSE)
    sumry$coefficients <- table
    print(sumry)
    cat("Note: Heteroscedasticity-consistant standard errors using
adjustment",
        type, "\n")
    }    

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Dirk 
> Eddelbuettel
> Sent: Saturday, December 23, 2006 11:16 PM
> To: ivo welch
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] extend summary.lm for hccm?
> 
> 
> On 23 December 2006 at 20:46, ivo welch wrote:
> | I wonder whether it is possible to extend the summary 
> method for the 
> | lm function, so that it uses an option "hccm" (well, model 
> "hc0").  In 
> | my line of work, it is pretty much required in reporting of 
> almost all 
> | linear regressions these days, which means that it would be 
> very nice 
> | not to have to manually library car, then sqrt the diagonal, and 
> | recompute T-stats; instead, I would love to get everything 
> in the same 
> | format as the current output---except errors heteroskedasticity 
> | adjusted.
> | 
> | easy or hard?
> 
> Did you consider the 'sandwich' package? A simple
> 
> 	> install.packages("sandwich")
> 	> library(sandwich)
> 	> ?vcovHC
> 	> ?vcovHAC
> 	
> should get you there.
> 
> Dirk
> 
> --
> Hell, there are no rules here - we're trying to accomplish something. 
>                                                   -- Thomas A. Edison
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From f.harrell at vanderbilt.edu  Sun Dec 24 16:28:43 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sun, 24 Dec 2006 09:28:43 -0600
Subject: [R] extend summary.lm for hccm?
In-Reply-To: <20061224144542.QOCZ17401.tomts10-srv.bellnexxia.net@JohnDesktop8300>
References: <20061224144542.QOCZ17401.tomts10-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <458E9CAB.6000001@vanderbilt.edu>

John Fox wrote:
> Dear Dirk and Ivo,
> 
> It's true that the sandwich package has more extensive facilities for
> sandwich variance estimation than the hccm function in the car package, but
> I think that the thrust of Ivo's question is to get a model summary that
> automatically uses the adjusted standard errors rather than having to
> compute them and use them "manually."  Here's one approach, which could be
> modified slightly if Ivo wants "hc0" as the default; it could also be
> adapted to use the sandwich package.
> 
> I hope this helps,
>  John

Another approach:

library(Design)  # also requires library(Hmisc)
f <- ols(y ~ x1 + x2, x=TRUE, y=TRUE)
f <- robcov(f)   # sandwich; also allows clustering.  Also see bootcov
anova(f)         # all later steps use sandwich variance matrix
summmary(f)
contrast(f, list(x1=.5), list(x1=.2))

BUT note that sandwich covariance matrix estimators can have poor mean 
squared error (a paper by Bill Gould in Stata Technical Bulletin years 
ago related to logistic regression showed an example with a 100-fold 
increase in the variance of a variance estimate) and can give you the 
right estimate of the wrong quantity (reference below).

Frank Harrell

@Article{free06so,
   author =               {Freedman, David A.},
   title =                {On the so-called ``{Huber} sandwich 
estimator'' and
``robust standard errors''},
   journal =      The American Statistician,
   year =                 2006,
   volume =               60,
   pages =                {299-302},
   annote =               {nice summary of derivation of sandwich
estimators;questions why we should be interested in getting the right
variance of the wrong parameters when the model doesn't fit}
}


> 
> ----------- snip --------------
> 
> summaryHCCM <- function(model, ...) UseMethod("summaryHCCM")
> 
> summaryHCCM.lm <- function(model, type=c("hc3", "hc0", "hc1", "hc2", "hc4"),
> 
>     ...){
>     if (!require(car)) stop("Required car package is missing.")
>     type <- match.arg(type)
>     V <- hccm(model, type=type)
>     sumry <- summary(model)
>     table <- coef(sumry)
>     table[,2] <- sqrt(diag(V))
>     table[,3] <- table[,1]/table[,2]
>     table[,4] <- 2*pt(abs(table[,3]), df.residual(model), lower.tail=FALSE)
>     sumry$coefficients <- table
>     print(sumry)
>     cat("Note: Heteroscedasticity-consistant standard errors using
> adjustment",
>         type, "\n")
>     }    
> 
> --------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox 
> -------------------------------- 
> 
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch 
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Dirk 
>> Eddelbuettel
>> Sent: Saturday, December 23, 2006 11:16 PM
>> To: ivo welch
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] extend summary.lm for hccm?
>>
>>
>> On 23 December 2006 at 20:46, ivo welch wrote:
>> | I wonder whether it is possible to extend the summary 
>> method for the 
>> | lm function, so that it uses an option "hccm" (well, model 
>> "hc0").  In 
>> | my line of work, it is pretty much required in reporting of 
>> almost all 
>> | linear regressions these days, which means that it would be 
>> very nice 
>> | not to have to manually library car, then sqrt the diagonal, and 
>> | recompute T-stats; instead, I would love to get everything 
>> in the same 
>> | format as the current output---except errors heteroskedasticity 
>> | adjusted.
>> | 
>> | easy or hard?
>>
>> Did you consider the 'sandwich' package? A simple
>>
>> 	> install.packages("sandwich")
>> 	> library(sandwich)
>> 	> ?vcovHC
>> 	> ?vcovHAC
>> 	
>> should get you there.
>>
>> Dirk
>>
>> --



-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From jfox at mcmaster.ca  Sun Dec 24 17:30:57 2006
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 24 Dec 2006 11:30:57 -0500
Subject: [R] extend summary.lm for hccm?
In-Reply-To: <458E9CAB.6000001@vanderbilt.edu>
Message-ID: <20061224163055.SXJY1773.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Frank,

If I remember Freedman's recent paper correctly, he argues that sandwich
variance estimator, though problematic in general, is not problematic in the
case that White described -- an otherwise correctly specified linear model
with heteroscedasticity estimated by least-squares. 

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Frank 
> E Harrell Jr
> Sent: Sunday, December 24, 2006 10:29 AM
> To: John Fox
> Cc: r-help at stat.math.ethz.ch; 'ivo welch'; 'Dirk Eddelbuettel'
> Subject: Re: [R] extend summary.lm for hccm?
> 
> John Fox wrote:
> > Dear Dirk and Ivo,
> > 
> > It's true that the sandwich package has more extensive 
> facilities for 
> > sandwich variance estimation than the hccm function in the car 
> > package, but I think that the thrust of Ivo's question is to get a 
> > model summary that automatically uses the adjusted standard errors 
> > rather than having to compute them and use them "manually."  Here's 
> > one approach, which could be modified slightly if Ivo wants 
> "hc0" as 
> > the default; it could also be adapted to use the sandwich package.
> > 
> > I hope this helps,
> >  John
> 
> Another approach:
> 
> library(Design)  # also requires library(Hmisc) f <- ols(y ~ 
> x1 + x2, x=TRUE, y=TRUE)
> f <- robcov(f)   # sandwich; also allows clustering.  Also see bootcov
> anova(f)         # all later steps use sandwich variance matrix
> summmary(f)
> contrast(f, list(x1=.5), list(x1=.2))
> 
> BUT note that sandwich covariance matrix estimators can have 
> poor mean squared error (a paper by Bill Gould in Stata 
> Technical Bulletin years ago related to logistic regression 
> showed an example with a 100-fold increase in the variance of 
> a variance estimate) and can give you the right estimate of 
> the wrong quantity (reference below).
> 
> Frank Harrell
> 
> @Article{free06so,
>    author =               {Freedman, David A.},
>    title =                {On the so-called ``{Huber} sandwich 
> estimator'' and
> ``robust standard errors''},
>    journal =      The American Statistician,
>    year =                 2006,
>    volume =               60,
>    pages =                {299-302},
>    annote =               {nice summary of derivation of sandwich
> estimators;questions why we should be interested in getting 
> the right variance of the wrong parameters when the model 
> doesn't fit} }
> 
> 
> > 
> > ----------- snip --------------
> > 
> > summaryHCCM <- function(model, ...) UseMethod("summaryHCCM")
> > 
> > summaryHCCM.lm <- function(model, type=c("hc3", "hc0", 
> "hc1", "hc2", 
> > "hc4"),
> > 
> >     ...){
> >     if (!require(car)) stop("Required car package is missing.")
> >     type <- match.arg(type)
> >     V <- hccm(model, type=type)
> >     sumry <- summary(model)
> >     table <- coef(sumry)
> >     table[,2] <- sqrt(diag(V))
> >     table[,3] <- table[,1]/table[,2]
> >     table[,4] <- 2*pt(abs(table[,3]), df.residual(model), 
> lower.tail=FALSE)
> >     sumry$coefficients <- table
> >     print(sumry)
> >     cat("Note: Heteroscedasticity-consistant standard errors using 
> > adjustment",
> >         type, "\n")
> >     }    
> > 
> > --------------------------------
> > John Fox
> > Department of Sociology
> > McMaster University
> > Hamilton, Ontario
> > Canada L8S 4M4
> > 905-525-9140x23604
> > http://socserv.mcmaster.ca/jfox
> > --------------------------------
> > 
> >> -----Original Message-----
> >> From: r-help-bounces at stat.math.ethz.ch 
> >> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Dirk 
> >> Eddelbuettel
> >> Sent: Saturday, December 23, 2006 11:16 PM
> >> To: ivo welch
> >> Cc: r-help at stat.math.ethz.ch
> >> Subject: Re: [R] extend summary.lm for hccm?
> >>
> >>
> >> On 23 December 2006 at 20:46, ivo welch wrote:
> >> | I wonder whether it is possible to extend the summary
> >> method for the
> >> | lm function, so that it uses an option "hccm" (well, model
> >> "hc0").  In
> >> | my line of work, it is pretty much required in reporting of
> >> almost all
> >> | linear regressions these days, which means that it would be
> >> very nice
> >> | not to have to manually library car, then sqrt the diagonal, and 
> >> | recompute T-stats; instead, I would love to get everything
> >> in the same
> >> | format as the current output---except errors heteroskedasticity 
> >> | adjusted.
> >> | 
> >> | easy or hard?
> >>
> >> Did you consider the 'sandwich' package? A simple
> >>
> >> 	> install.packages("sandwich")
> >> 	> library(sandwich)
> >> 	> ?vcovHC
> >> 	> ?vcovHAC
> >> 	
> >> should get you there.
> >>
> >> Dirk
> >>
> >> --
> 
> 
> 
> -- 
> Frank E Harrell Jr   Professor and Chair           School of Medicine
>                       Department of Biostatistics   
> Vanderbilt University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From f.harrell at vanderbilt.edu  Sun Dec 24 17:44:29 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sun, 24 Dec 2006 10:44:29 -0600
Subject: [R] extend summary.lm for hccm?
In-Reply-To: <20061224163055.SXJY1773.tomts13-srv.bellnexxia.net@JohnDesktop8300>
References: <20061224163055.SXJY1773.tomts13-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <458EAE6D.2020209@vanderbilt.edu>

John Fox wrote:
> Dear Frank,
> 
> If I remember Freedman's recent paper correctly, he argues that sandwich
> variance estimator, though problematic in general, is not problematic in the
> case that White described -- an otherwise correctly specified linear model
> with heteroscedasticity estimated by least-squares. 
> 
> Regards,
>  John

That's right John although the precision of the variance estimators is 
still worth studying in that case.

Best regards,
Frank

> 
> --------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox 
> -------------------------------- 
> 
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch 
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Frank 
>> E Harrell Jr
>> Sent: Sunday, December 24, 2006 10:29 AM
>> To: John Fox
>> Cc: r-help at stat.math.ethz.ch; 'ivo welch'; 'Dirk Eddelbuettel'
>> Subject: Re: [R] extend summary.lm for hccm?
>>
>> John Fox wrote:
>>> Dear Dirk and Ivo,
>>>
>>> It's true that the sandwich package has more extensive 
>> facilities for 
>>> sandwich variance estimation than the hccm function in the car 
>>> package, but I think that the thrust of Ivo's question is to get a 
>>> model summary that automatically uses the adjusted standard errors 
>>> rather than having to compute them and use them "manually."  Here's 
>>> one approach, which could be modified slightly if Ivo wants 
>> "hc0" as 
>>> the default; it could also be adapted to use the sandwich package.
>>>
>>> I hope this helps,
>>>  John
>> Another approach:
>>
>> library(Design)  # also requires library(Hmisc) f <- ols(y ~ 
>> x1 + x2, x=TRUE, y=TRUE)
>> f <- robcov(f)   # sandwich; also allows clustering.  Also see bootcov
>> anova(f)         # all later steps use sandwich variance matrix
>> summmary(f)
>> contrast(f, list(x1=.5), list(x1=.2))
>>
>> BUT note that sandwich covariance matrix estimators can have 
>> poor mean squared error (a paper by Bill Gould in Stata 
>> Technical Bulletin years ago related to logistic regression 
>> showed an example with a 100-fold increase in the variance of 
>> a variance estimate) and can give you the right estimate of 
>> the wrong quantity (reference below).
>>
>> Frank Harrell
>>
>> @Article{free06so,
>>    author =               {Freedman, David A.},
>>    title =                {On the so-called ``{Huber} sandwich 
>> estimator'' and
>> ``robust standard errors''},
>>    journal =      The American Statistician,
>>    year =                 2006,
>>    volume =               60,
>>    pages =                {299-302},
>>    annote =               {nice summary of derivation of sandwich
>> estimators;questions why we should be interested in getting 
>> the right variance of the wrong parameters when the model 
>> doesn't fit} }
>>
>>
>>> ----------- snip --------------
>>>
>>> summaryHCCM <- function(model, ...) UseMethod("summaryHCCM")
>>>
>>> summaryHCCM.lm <- function(model, type=c("hc3", "hc0", 
>> "hc1", "hc2", 
>>> "hc4"),
>>>
>>>     ...){
>>>     if (!require(car)) stop("Required car package is missing.")
>>>     type <- match.arg(type)
>>>     V <- hccm(model, type=type)
>>>     sumry <- summary(model)
>>>     table <- coef(sumry)
>>>     table[,2] <- sqrt(diag(V))
>>>     table[,3] <- table[,1]/table[,2]
>>>     table[,4] <- 2*pt(abs(table[,3]), df.residual(model), 
>> lower.tail=FALSE)
>>>     sumry$coefficients <- table
>>>     print(sumry)
>>>     cat("Note: Heteroscedasticity-consistant standard errors using 
>>> adjustment",
>>>         type, "\n")
>>>     }    
>>>
>>> --------------------------------
>>> John Fox
>>> Department of Sociology
>>> McMaster University
>>> Hamilton, Ontario
>>> Canada L8S 4M4
>>> 905-525-9140x23604
>>> http://socserv.mcmaster.ca/jfox
>>> --------------------------------
>>>
>>>> -----Original Message-----
>>>> From: r-help-bounces at stat.math.ethz.ch 
>>>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Dirk 
>>>> Eddelbuettel
>>>> Sent: Saturday, December 23, 2006 11:16 PM
>>>> To: ivo welch
>>>> Cc: r-help at stat.math.ethz.ch
>>>> Subject: Re: [R] extend summary.lm for hccm?
>>>>
>>>>
>>>> On 23 December 2006 at 20:46, ivo welch wrote:
>>>> | I wonder whether it is possible to extend the summary
>>>> method for the
>>>> | lm function, so that it uses an option "hccm" (well, model
>>>> "hc0").  In
>>>> | my line of work, it is pretty much required in reporting of
>>>> almost all
>>>> | linear regressions these days, which means that it would be
>>>> very nice
>>>> | not to have to manually library car, then sqrt the diagonal, and 
>>>> | recompute T-stats; instead, I would love to get everything
>>>> in the same
>>>> | format as the current output---except errors heteroskedasticity 
>>>> | adjusted.
>>>> | 
>>>> | easy or hard?
>>>>
>>>> Did you consider the 'sandwich' package? A simple
>>>>
>>>> 	> install.packages("sandwich")
>>>> 	> library(sandwich)
>>>> 	> ?vcovHC
>>>> 	> ?vcovHAC
>>>> 	
>>>> should get you there.
>>>>
>>>> Dirk


From bbands at gmail.com  Sun Dec 24 18:12:27 2006
From: bbands at gmail.com (BBands)
Date: Sun, 24 Dec 2006 09:12:27 -0800
Subject: [R] OT: any recommendation for scripting language
In-Reply-To: <1115a2b00612230756g7cf6fd0emcbec62b832402d05@mail.gmail.com>
References: <1115a2b00612230756g7cf6fd0emcbec62b832402d05@mail.gmail.com>
Message-ID: <6e8360ad0612240912m1f6b5378u98a84d4fb13cfc8e@mail.gmail.com>

On 12/23/06, Wensui Liu <liuwensui at gmail.com> wrote:
> if you recommend one, I will really appreciate it if you could point
> out a good source for learning as well.

We have found Python to be the perfect choice for our work. Python is
a high-level, cross-platform language that is easy to learn/write with
an extensive set of libraries. It supports object and procedural
programming styles equally well, so one may match the style to the
task. If is also an excellent 'glue' language, easily tying together
diverse programs in various environments.   There is great
connectivity with R though rpy and RSpython. Here are links to some of
the connectors we use:

R
http://rpy.sourceforge.net/
http://www.omegahat.org/RSPython/
Database
http://sourceforge.net/projects/mysql-python
http://www.initd.org/tracker/pysqlite
Graphics
http://gnuplot-py.sourceforge.net/
Windows--COM, DDE...
http://sourceforge.net/projects/pywin32/

The Python tutorial is the place to start:

http://docs.python.org/tut/

     jab
-- 
John Bollinger, CFA, CMT
www.BollingerBands.com

If you advance far enough, you arrive at the beginning.


From ivowel at gmail.com  Sun Dec 24 19:34:09 2006
From: ivowel at gmail.com (ivo welch)
Date: Sun, 24 Dec 2006 13:34:09 -0500
Subject: [R] extend summary.lm for hccm?
In-Reply-To: <458EAE6D.2020209@vanderbilt.edu>
References: <20061224163055.SXJY1773.tomts13-srv.bellnexxia.net@JohnDesktop8300>
	<458EAE6D.2020209@vanderbilt.edu>
Message-ID: <50d1c22d0612241034r260c2fe8x2641f21e2eb7f2d1@mail.gmail.com>

thank you, everybody.  It's hard to find much fault with R, but one
feature that would be nice to have would be hooks to output functions
that make it easy to augment to the output---e.g., to add a new
statistic to summary (e.g., mean, sd, different stderrs).  not a big
flaw, because one can write replacement functions...

 /ivo


From rickhg12hs at gmail.com  Sun Dec 24 20:03:06 2006
From: rickhg12hs at gmail.com (Richard Graham)
Date: Sun, 24 Dec 2006 13:03:06 -0600
Subject: [R] OT: any recommendation for scripting language
In-Reply-To: <1115a2b00612230756g7cf6fd0emcbec62b832402d05@mail.gmail.com>
References: <1115a2b00612230756g7cf6fd0emcbec62b832402d05@mail.gmail.com>
Message-ID: <9410b37b0612241103x197cae67j6fc9736f7b11a36d@mail.gmail.com>

On 12/23/06, Wensui Liu <liuwensui at gmail.com> wrote:
> from statisticians' point of view, which scripting language is worth
> to learn, perl, python, or any other recommendation? (Most likely, I
> will be learning it in windows.) Since I am not in research, I will
> prefer one widely used in industry and related to statistical work.

It seems R would be the language of choice if you require "related to
statistical work".  I would be surprised if any general scripting
language would restrict themselves to statistics.

> if you recommend one, I will really appreciate it if you could point
> out a good source for learning as well.

I find Ruby to be the closest language to the way I think about
programming.  It's fully object oriented, dynamically typed,
open-source, free, and runs on just about any platform.  Sophisticated
IDE's are available and it can also run easily from the command line
(like Perl).  Ruby is fun to use.

There are a lot of online Ruby resources and also printed material.
Here are just a few.

Language overview:
http://en.wikipedia.org/wiki/Ruby_%28programming_language%29

Main Website:
http://www.ruby-lang.org/en/

Learning Ruby:
http://pine.fm/LearnToProgram/
http://www.math.umd.edu/~dcarrera/ruby/0.3/index.html
http://poignantguide.net/ruby/

Give it a try online:
http://tryruby.hobix.com/

Book:
http://www.rubycentral.com/book/
[NB:  This free online book is for Ruby 1.6. Another printed and PDF
book is available for Ruby 1.8]
http://pragmaticprogrammer.com/titles/ruby/index.html

Newsgroup:
http://groups.google.com/group/comp.lang.ruby

> thank you so much!

Your welcome!

> Have a happy holiday.

Thank you, I am.  8-)  I hope everyone is having a nice holiday.

Richard Graham


From larsfromspace at web.de  Mon Dec 25 03:30:44 2006
From: larsfromspace at web.de (downunder)
Date: Sun, 24 Dec 2006 18:30:44 -0800 (PST)
Subject: [R]  Higher Dimensional Matrices
Message-ID: <8044673.post@talk.nabble.com>


Hi all.

I want to calculate partial correlations while controlling for one or more
variables. That works already fine when I control for example just for x[,1]
and x[,2] that gives me one single correlation matrix and i have to to it
for 
x [,1]...x[,10]. That would give me out 10 matrices. Controlling for 2
Variables 100 matrices. how  
can I run a loop to get f.e the 10 or 100 matrices at once? I appreciate for
every hint. have nice holidays. 

greetings lars

x<-read.table("C:/.....dat")
dim(x) #200x10
a<-matrix(0,200,10)
for (i in 1:10)
a[,i] <- residuals(lm(x[,i]~1+x[,1]+x[,2]))
b<-matrix(0,200,10)
for (i in 1:10)
b[,i] <- residuals(lm(x[,i]~1+x[,1]+x[,2]))
#a=round(a,5)
#b=round(b,5)
d=cor(a,b)
d
-- 
View this message in context: http://www.nabble.com/-R--Higher-Dimensional-Matrices-tf2878430.html#a8044673
Sent from the R help mailing list archive at Nabble.com.


From christos at nuverabio.com  Mon Dec 25 08:09:10 2006
From: christos at nuverabio.com (Christos Hatzis)
Date: Mon, 25 Dec 2006 02:09:10 -0500
Subject: [R] how to 'get' an object that is part of a list
In-Reply-To: <971536df0612240441w44e2843etf32538ae37f1d604@mail.gmail.com>
Message-ID: <001501c727f3$940e74a0$0202a8c0@headquarters.silicoinsights>

Thank you Gabor.  Very interesting solution.
If I get it right, the first argument in function f is just a placeholder to
help extract the right element out of the list(...) that is passed to
length.  Very smart trick.

Jim's solution appears a bit simpler, at least along the lines that I was
thinking:

my.length <- function(...) {
	names <- as.character(substitute(list(...)))[-1]
	sapply(names, function(x){y <- eval(parse(text=x)); length(y)})
} 

-Christos

-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Sent: Sunday, December 24, 2006 7:41 AM
To: jim holtman
Cc: christos at nuverabio.com; 
Subject: Re: [R] how to 'get' an object that is part of a list

Is this what you are looking for:

> my.length.2 <- function(...) {
+    f <- function(nm, val) length(val)
+    mapply(f, make.names(as.list(match.call()[-1])), list(...)) }
> my.length.2(xx, xx$b)
  xx xx.b
   2    5

On 12/24/06, jim holtman <jholtman at gmail.com> wrote:
> use 'eval' and 'parse'
>
>
> > xx
> $a
> [1] 1 2 3 4 5
>
> $b
> [1] "a" "b" "c" "d" "e"
>
> > eval(parse(text='xx$a'))
> [1] 1 2 3 4 5
> >
>
> So that way you can pass in the character string and then 'parse' it.
>
>
>
> On 12/24/06, Christos Hatzis <christos at nuverabio.com> wrote:
> >
> > This might be an trivial thing but I am stuck.
> >
> > Consider:
> >
> > xx <- list(a=1:5, b=letters[1:5])
> >
> > Although object xx is accessible through its name, how can object 
> > xx$b be accessed similarly through its name?
> >
> > > get("xx")
> > $a
> > [1] 1 2 3 4 5
> >
> > $b
> > [1] "a" "b" "c" "d" "e"
> >
> > > get("xx$b")
> > Error in get(x, envir, mode, inherits) : variable "xx$b" was not 
> > found
> >
> > get("xx")$b will not work in my case because it will probably 
> > require parsing to make it work within a function. E.g.
> >
> > my.length <- function(...) {
> >        names <- as.character(substitute(list(...)))[-1]
> >        sapply(names, FUN=function(x){y <- get(x); length(y)}) }
> > > my.length(xx)
> > xx
> > 2
> > > my.length(xx$a)
> > Error in get(x, envir, mode, inherits) : variable "xx$a" was not 
> > found
> > > my.length(xx$a, xx$b)
> > Error in get(x, envir, mode, inherits) : variable "xx$a" was not 
> > found
> >
> > Thank you.
> >
> > Christos Hatzis, Ph.D.
> > Nuvera Biosciences, Inc.
> > 400 West Cummings Park
> > Suite 5350
> > Woburn, MA 01801
> > Tel: 781-938-3830
> > www.nuverabio.com
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> --
> Jim Holtman
> Cincinnati, OH
> +1 513 646 9390
>
> What is the problem you are trying to solve?
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From daniel.berg2 at gmail.com  Mon Dec 25 10:44:06 2006
From: daniel.berg2 at gmail.com (Daniel Berg)
Date: Mon, 25 Dec 2006 10:44:06 +0100
Subject: [R] building R-package under windows - error - in
	options("deafultPackages") was not found
In-Reply-To: <Pine.LNX.4.64.0612231143300.7744@auk.stats>
References: <f13f1c9c0612221238q652cf3d4t8b30a5f1922ea53a@mail.gmail.com>
	<458D1064.8040704@statistik.uni-dortmund.de>
	<Pine.LNX.4.64.0612231143300.7744@auk.stats>
Message-ID: <f13f1c9c0612250144m2616d866r64873272d18084e3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061225/8c52d2ce/attachment.pl 

From ggrothendieck at gmail.com  Mon Dec 25 14:33:54 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 25 Dec 2006 08:33:54 -0500
Subject: [R] how to 'get' an object that is part of a list
In-Reply-To: <001501c727f3$940e74a0$0202a8c0@headquarters.silicoinsights>
References: <971536df0612240441w44e2843etf32538ae37f1d604@mail.gmail.com>
	<001501c727f3$940e74a0$0202a8c0@headquarters.silicoinsights>
Message-ID: <971536df0612250533n6ba6e8f4o75975036512154ae@mail.gmail.com>

my.length.2 also has the advantage of eliminating the eval.

On 12/25/06, Christos Hatzis <christos at nuverabio.com> wrote:
> Thank you Gabor.  Very interesting solution.
> If I get it right, the first argument in function f is just a placeholder to
> help extract the right element out of the list(...) that is passed to
> length.  Very smart trick.
>
> Jim's solution appears a bit simpler, at least along the lines that I was
> thinking:
>
> my.length <- function(...) {
>        names <- as.character(substitute(list(...)))[-1]
>        sapply(names, function(x){y <- eval(parse(text=x)); length(y)})
> }
>
> -Christos
>
> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Sent: Sunday, December 24, 2006 7:41 AM
> To: jim holtman
> Cc: christos at nuverabio.com;
> Subject: Re: [R] how to 'get' an object that is part of a list
>
> Is this what you are looking for:
>
> > my.length.2 <- function(...) {
> +    f <- function(nm, val) length(val)
> +    mapply(f, make.names(as.list(match.call()[-1])), list(...)) }
> > my.length.2(xx, xx$b)
>  xx xx.b
>   2    5
>
> On 12/24/06, jim holtman <jholtman at gmail.com> wrote:
> > use 'eval' and 'parse'
> >
> >
> > > xx
> > $a
> > [1] 1 2 3 4 5
> >
> > $b
> > [1] "a" "b" "c" "d" "e"
> >
> > > eval(parse(text='xx$a'))
> > [1] 1 2 3 4 5
> > >
> >
> > So that way you can pass in the character string and then 'parse' it.
> >
> >
> >
> > On 12/24/06, Christos Hatzis <christos at nuverabio.com> wrote:
> > >
> > > This might be an trivial thing but I am stuck.
> > >
> > > Consider:
> > >
> > > xx <- list(a=1:5, b=letters[1:5])
> > >
> > > Although object xx is accessible through its name, how can object
> > > xx$b be accessed similarly through its name?
> > >
> > > > get("xx")
> > > $a
> > > [1] 1 2 3 4 5
> > >
> > > $b
> > > [1] "a" "b" "c" "d" "e"
> > >
> > > > get("xx$b")
> > > Error in get(x, envir, mode, inherits) : variable "xx$b" was not
> > > found
> > >
> > > get("xx")$b will not work in my case because it will probably
> > > require parsing to make it work within a function. E.g.
> > >
> > > my.length <- function(...) {
> > >        names <- as.character(substitute(list(...)))[-1]
> > >        sapply(names, FUN=function(x){y <- get(x); length(y)}) }
> > > > my.length(xx)
> > > xx
> > > 2
> > > > my.length(xx$a)
> > > Error in get(x, envir, mode, inherits) : variable "xx$a" was not
> > > found
> > > > my.length(xx$a, xx$b)
> > > Error in get(x, envir, mode, inherits) : variable "xx$a" was not
> > > found
> > >
> > > Thank you.
> > >
> > > Christos Hatzis, Ph.D.
> > > Nuvera Biosciences, Inc.
> > > 400 West Cummings Park
> > > Suite 5350
> > > Woburn, MA 01801
> > > Tel: 781-938-3830
> > > www.nuverabio.com
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >
> >
> > --
> > Jim Holtman
> > Cincinnati, OH
> > +1 513 646 9390
> >
> > What is the problem you are trying to solve?


From Achim.Zeileis at wu-wien.ac.at  Mon Dec 25 14:38:07 2006
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Mon, 25 Dec 2006 14:38:07 +0100 (CET)
Subject: [R] extend summary.lm for hccm?
In-Reply-To: <20061224144542.QOCZ17401.tomts10-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <Pine.LNX.4.44.0612251406500.8229-100000@disco.wu-wien.ac.at>

On Sun, 24 Dec 2006, John Fox wrote:

> Dear Dirk and Ivo,
>
> It's true that the sandwich package has more extensive facilities for
> sandwich variance estimation than the hccm function in the car package, but
> I think that the thrust of Ivo's question is to get a model summary that
> automatically uses the adjusted standard errors rather than having to
> compute them and use them "manually."

I've written the function coeftest() in package "lmtest" for this purpose.
With this you can
  coeftest(obj, vcov = sandwich)
or you can put this into a specialized summary() function as John
suggested (where you probably would want the F statistic to use the other
vcov as well). See also function waldtest() in "lmtest",
linear.hypothesis() in "car" and
  vignette("sandwich", package = "sandwich")

Although this works, it is still a nuisance to use a different function
and not summary() directly. In addition, it would also be nice to plug in
different vcovs into confint() or predict() methods. Of course, one could
write different generics or overload the methods in certain packages.
However, I guess that many practitioners want to use different vcov
estimators - especially in the social and political scieneces, and
econometrics etc. - so that this might justify that the original "lm" (and
"glm") methods are extended to allow for plugging in different vcov
matrices. Maybe we could try to convince R-core to include somthing like
this?

Best wishes,
Z


From jfox at mcmaster.ca  Mon Dec 25 16:01:59 2006
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 25 Dec 2006 10:01:59 -0500
Subject: [R] extend summary.lm for hccm?
In-Reply-To: <Pine.LNX.4.44.0612251406500.8229-100000@disco.wu-wien.ac.at>
Message-ID: <20061225150156.ZBJX17401.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Achim,

> -----Original Message-----
> From: Achim Zeileis [mailto:Achim.Zeileis at wu-wien.ac.at] 
> Sent: Monday, December 25, 2006 8:38 AM
> To: John Fox
> Cc: 'Dirk Eddelbuettel'; 'ivo welch'; r-help at stat.math.ethz.ch
> Subject: Re: [R] extend summary.lm for hccm?
> 
> On Sun, 24 Dec 2006, John Fox wrote:
> 
> > Dear Dirk and Ivo,
> >
> > It's true that the sandwich package has more extensive 
> facilities for 
> > sandwich variance estimation than the hccm function in the car 
> > package, but I think that the thrust of Ivo's question is to get a 
> > model summary that automatically uses the adjusted standard errors 
> > rather than having to compute them and use them "manually."
> 
> I've written the function coeftest() in package "lmtest" for 
> this purpose.
> With this you can
>   coeftest(obj, vcov = sandwich)

Since coeftest() already exists in a package, I think that this is a
preferable solution.

> or you can put this into a specialized summary() function as 
> John suggested (where you probably would want the F statistic 
> to use the other vcov as well). 

Good point. Here's a modified version that also fixes up the F-test:

summaryHCCM.lm <- function(model, type=c("hc3", "hc0", "hc1", "hc2", "hc4"),

    ...){
    if (!require(car)) stop("Required car package is missing.")
    type <- match.arg(type)
    V <- hccm(model, type=type)
    sumry <- summary(model)
    table <- coef(sumry)
    table[,2] <- sqrt(diag(V))
    table[,3] <- table[,1]/table[,2]
    table[,4] <- 2*pt(abs(table[,3]), df.residual(model), lower.tail=FALSE)
    sumry$coefficients <- table
    p <- nrow(table)
    hyp <- if (has.intercept(model)) cbind(0, diag(p - 1)) else diag(p)
    sumry$fstatistic[1] <- linear.hypothesis(model, hyp,
white.adjust=type)[2,"F"]
    print(sumry)
    cat("Note: Heteroscedasticity-consistant standard errors using
adjustment",
        type, "\n")
    }

Regards,
 John

> See also function waldtest() 
> in "lmtest",
> linear.hypothesis() in "car" and
>   vignette("sandwich", package = "sandwich")
> 
> Although this works, it is still a nuisance to use a 
> different function and not summary() directly. In addition, 
> it would also be nice to plug in different vcovs into 
> confint() or predict() methods. Of course, one could write 
> different generics or overload the methods in certain packages.
> However, I guess that many practitioners want to use 
> different vcov estimators - especially in the social and 
> political scieneces, and econometrics etc. - so that this 
> might justify that the original "lm" (and
> "glm") methods are extended to allow for plugging in 
> different vcov matrices. Maybe we could try to convince 
> R-core to include somthing like this?
> 
> Best wishes,
> Z
> 
> 
>


From fisk at bowdoin.edu  Mon Dec 25 16:21:55 2006
From: fisk at bowdoin.edu (steve)
Date: Mon, 25 Dec 2006 10:21:55 -0500
Subject: [R] Hmisc - some latex problems
Message-ID: <emoqak$6di$1@sea.gmane.org>

If I use latex with describe:
(faithful is the Old faithful data)

latex(describe(faithful),file="describe.tex")

then the first few lines of describe.tex are

\begin{spacing}{0.7}
\begin{center} \bf faithful \\ 2 Variables~~~~~ 272 ~Observations 
\end{center}

I have two problems. First, I don't know what package
the environment "spacing" comes from. (There is also a command \smaller, 
but that is from the relsize package. Perhaps the latex man page could 
list the latex packages that are necessary to create correct output.)

Second, I use the memoir class, and it flags \bf as an error -
\textbf should be used instead. A correct version would be


\begin{center}\textbf{  faithful \\ 2 Variables~~~~~ 272 
~Observations}\end{center}

thank you,

Steve


From f.harrell at vanderbilt.edu  Mon Dec 25 16:50:08 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Mon, 25 Dec 2006 09:50:08 -0600
Subject: [R] Hmisc - some latex problems
In-Reply-To: <emoqak$6di$1@sea.gmane.org>
References: <emoqak$6di$1@sea.gmane.org>
Message-ID: <458FF330.606@vanderbilt.edu>

steve wrote:
> If I use latex with describe:
> (faithful is the Old faithful data)
> 
> latex(describe(faithful),file="describe.tex")
> 
> then the first few lines of describe.tex are
> 
> \begin{spacing}{0.7}
> \begin{center} \bf faithful \\ 2 Variables~~~~~ 272 ~Observations 
> \end{center}
> 
> I have two problems. First, I don't know what package
> the environment "spacing" comes from. (There is also a command \smaller, 
> but that is from the relsize package. Perhaps the latex man page could 
> list the latex packages that are necessary to create correct output.)

The latex object created by latex.describe lists the necessary styles - 
setspace and relsize - but I'll make that clear in the documentation. 
Note for debian linux users - these styles are included in the package 
tetex-extra.

> 
> Second, I use the memoir class, and it flags \bf as an error -
> \textbf should be used instead. A correct version would be
> 
> 
> \begin{center}\textbf{  faithful \\ 2 Variables~~~~~ 272 
> ~Observations}\end{center}

Thanks - will fix in next release

Frank

> 
> thank you,
> 
> Steve


From aiminy at iastate.edu  Mon Dec 25 18:35:17 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Mon, 25 Dec 2006 11:35:17 -0600
Subject: [R] Problem to generate training data set and test data set
Message-ID: <6.1.2.0.2.20061225112056.01c5c4e0@aiminy.mail.iastate.edu>

I have a full data set like this:

    aa bas    aas bms   ams bcu        acu     omega       y
1 ALA   0 127.71   0 69.99   0 -0.2498560  79.91470 outward
2 PRO   0  68.55   0 55.44   0 -0.0949008  76.60380 outward
3 ALA   0  52.72   0 47.82   0 -0.0396550  52.19970 outward
4 PHE   0  22.62   0 31.21   0  0.1270330 169.52500  inward
5 SER   0  71.32   0 52.84   0 -0.1312380   7.47528 outward
6 VAL   0  12.92   0 22.40   0  0.1728390 149.09400  inward
......................................................................................


aa have 19 levels, and there are different number of observation for each 
levels.
I want to pick 75% of observations of each levels randomly to generate a 
training set,
and 25% of observation of each levels to generate a testing set.

Does anyone know to do this?

Thanks

Aimin Yan


From miguel.tremblay at ptaff.ca  Mon Dec 25 21:10:23 2006
From: miguel.tremblay at ptaff.ca (Miguel Tremblay)
Date: Mon, 25 Dec 2006 15:10:23 -0500 (EST)
Subject: [R] No fonts in graphics using GDD
Message-ID: <Pine.LNX.4.64.0612251508440.14703@octet.ca>

I have problem to have fonts in graphics using GDD.

R version: R 2.2.1 (2005-12-20).
GDD version: GDD_0.1-8.tar.gz
Platform: Linux 2.6.17-gentoo-r8 #2 SMP Sat Nov 4 21:16:47 EST 2006 i686 
Intel(R) Pentium(R) 4 CPU 3.00GHz GenuineIntel GNU/Linux


I have configured the basefont.mapping file accordingly to the path of the 
font on my computer:
base.norm:/usr/share/fonts/corefonts/arial.ttf
base.ital:/usr/share/fonts/corefonts/ariali.ttf
base.bold:/usr/share/fonts/corefonts/arialbd.ttf
base.bita:/usr/share/fonts/corefonts/arialbi.ttf

Those files exists and are present at the right place:
ls /usr/share/fonts/corefonts/arial*.ttf
/usr/share/fonts/corefonts/arial.ttf 
/usr/share/fonts/corefonts/arialbi.ttf
/usr/share/fonts/corefonts/arialbd.ttf 
/usr/share/fonts/corefonts/ariali.ttf

In R, when I import the GDD library and look at the font path, they are 
correct:
> library('GDD')
> .Call("gdd_look_up_font", NULL)
[1] "/usr/share/fonts/corefonts/arial.ttf"
[2] "/usr/share/fonts/corefonts/arialbd.ttf"
[3] "/usr/share/fonts/corefonts/ariali.ttf"
[4] "/usr/share/fonts/corefonts/arialbi.ttf"
[5] NA


When I create a graphic, there is no font:
> library(GDD)
> GDD()
> plot(rnorm)
> dev.off()

I have went through the following threads and it did'nt help:
http://mailman.rz.uni-augsburg.de/pipermail/stats-rosuda-devel/2006q1/000197.html
http://tolstoy.newcastle.edu.au/R/help/06/04/25159.html


The ouptut of my GDD installation is:
R CMD INSTALL GDD_0.1-8.tar.gz
* Installing *source* package 'GDD' ...
checking for gcc... i686-pc-linux-gnu-gcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether i686-pc-linux-gnu-gcc accepts -g... yes
checking for i686-pc-linux-gnu-gcc option to accept ANSI C... none needed
checking how to run the C preprocessor... i686-pc-linux-gnu-gcc -E
checking for egrep... grep -E
checking for ANSI C header files... yes
checking for sys/wait.h that is POSIX.1 compatible... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking for string.h... (cached) yes
checking sys/time.h usability... yes
checking sys/time.h presence... yes
checking for sys/time.h... yes
checking for unistd.h... (cached) yes
checking for an ANSI C-conforming const... yes
checking whether time.h and sys/time.h may both be included... yes
checking for stdlib.h... (cached) yes
checking for GNU libc compatible malloc... yes
checking return type of signal handlers... void
checking for memset... yes
checking for mkdir... yes
checking for rmdir... yes
checking for gdlib-config... /usr/bin/gdlib-config
libgd-flags according to gdlib-config:
    -I/usr/include -L/usr/lib -ljpeg -lfontconfig -lpng12 -lz -lm
if that is not correct, fix your gd installation
checking gd.h usability... yes
checking gd.h presence... yes
checking for gd.h... yes
checking for gdImageCreateFromPng in -lgd... yes
checking usability of FreeType in GD... yes
checking whether GD programs can be compiled... yes
configure: creating ./config.status
config.status: creating src/Makevars
config.status: creating src/gddconfig.h
** libs
i686-pc-linux-gnu-gcc -I/usr/lib/R/include -I/usr/include -I/usr/include 
-DHAVE_GDDCONFIG_H -I. -Iinclude -I/usr/local/include 
-D_FILE_OFFSET_BITS=64 -D_LARGEFILE64_SOURCE -D_LARGEFILE_SOURCE -O2 
-march=pentium4 -fomit-frame-pointer -pipe -fPIC  -D_FILE_OFFSET_BITS=64 
-D_LARGEFILE64_SOURCE -D_LARGEFILE_SOURCE -O2 -march=pentium4 
-fomit-frame-pointer -pipe -c GDD.c -o GDD.o
i686-pc-linux-gnu-gcc -I/usr/lib/R/include -I/usr/include -I/usr/include 
-DHAVE_GDDCONFIG_H -I. -Iinclude -I/usr/local/include 
-D_FILE_OFFSET_BITS=64 -D_LARGEFILE64_SOURCE -D_LARGEFILE_SOURCE -O2 
-march=pentium4 -fomit-frame-pointer -pipe -fPIC  -D_FILE_OFFSET_BITS=64 
-D_LARGEFILE64_SOURCE -D_LARGEFILE_SOURCE -O2 -march=pentium4 
-fomit-frame-pointer -pipe -c GDDtalk.c -o GDDtalk.o
i686-pc-linux-gnu-gcc -shared  -o GDD.so GDD.o GDDtalk.o -L/usr/lib 
-L/usr/lib -lgd  -ljpeg -lfontconfig -lpng12 -lz -lm  -L/usr/lib/R/lib -lR
** R
** inst
** help
  >>> Building/Updating help pages for package 'GDD'
      Formats: text html latex example
   GDD                               text    html    latex   example
   GDDfont                           text    html    latex   example
** building package indices ...
* DONE (GDD)



Anyone can help me with this?


Miguel Tremblay
http://ptaff.ca/miguel/


From christos at nuverabio.com  Mon Dec 25 23:08:26 2006
From: christos at nuverabio.com (Christos Hatzis)
Date: Mon, 25 Dec 2006 17:08:26 -0500
Subject: [R] how to 'get' an object that is part of a list
In-Reply-To: <971536df0612250533n6ba6e8f4o75975036512154ae@mail.gmail.com>
Message-ID: <001401c72871$34007850$0202a8c0@headquarters.silicoinsights>

True.  Thanks again. 

-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Sent: Monday, December 25, 2006 8:34 AM
To: christos at nuverabio.com
Cc: r-help at hypatia.math.ethz.ch
Subject: Re: [R] how to 'get' an object that is part of a list

my.length.2 also has the advantage of eliminating the eval.

On 12/25/06, Christos Hatzis <christos at nuverabio.com> wrote:
> Thank you Gabor.  Very interesting solution.
> If I get it right, the first argument in function f is just a 
> placeholder to help extract the right element out of the list(...) 
> that is passed to length.  Very smart trick.
>
> Jim's solution appears a bit simpler, at least along the lines that I 
> was
> thinking:
>
> my.length <- function(...) {
>        names <- as.character(substitute(list(...)))[-1]
>        sapply(names, function(x){y <- eval(parse(text=x)); length(y)}) 
> }
>
> -Christos
>
> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Sent: Sunday, December 24, 2006 7:41 AM
> To: jim holtman
> Cc: christos at nuverabio.com;
> Subject: Re: [R] how to 'get' an object that is part of a list
>
> Is this what you are looking for:
>
> > my.length.2 <- function(...) {
> +    f <- function(nm, val) length(val)
> +    mapply(f, make.names(as.list(match.call()[-1])), list(...)) }
> > my.length.2(xx, xx$b)
>  xx xx.b
>   2    5
>
> On 12/24/06, jim holtman <jholtman at gmail.com> wrote:
> > use 'eval' and 'parse'
> >
> >
> > > xx
> > $a
> > [1] 1 2 3 4 5
> >
> > $b
> > [1] "a" "b" "c" "d" "e"
> >
> > > eval(parse(text='xx$a'))
> > [1] 1 2 3 4 5
> > >
> >
> > So that way you can pass in the character string and then 'parse' it.
> >
> >
> >
> > On 12/24/06, Christos Hatzis <christos at nuverabio.com> wrote:
> > >
> > > This might be an trivial thing but I am stuck.
> > >
> > > Consider:
> > >
> > > xx <- list(a=1:5, b=letters[1:5])
> > >
> > > Although object xx is accessible through its name, how can object 
> > > xx$b be accessed similarly through its name?
> > >
> > > > get("xx")
> > > $a
> > > [1] 1 2 3 4 5
> > >
> > > $b
> > > [1] "a" "b" "c" "d" "e"
> > >
> > > > get("xx$b")
> > > Error in get(x, envir, mode, inherits) : variable "xx$b" was not 
> > > found
> > >
> > > get("xx")$b will not work in my case because it will probably 
> > > require parsing to make it work within a function. E.g.
> > >
> > > my.length <- function(...) {
> > >        names <- as.character(substitute(list(...)))[-1]
> > >        sapply(names, FUN=function(x){y <- get(x); length(y)}) }
> > > > my.length(xx)
> > > xx
> > > 2
> > > > my.length(xx$a)
> > > Error in get(x, envir, mode, inherits) : variable "xx$a" was not 
> > > found
> > > > my.length(xx$a, xx$b)
> > > Error in get(x, envir, mode, inherits) : variable "xx$a" was not 
> > > found
> > >
> > > Thank you.
> > >
> > > Christos Hatzis, Ph.D.
> > > Nuvera Biosciences, Inc.
> > > 400 West Cummings Park
> > > Suite 5350
> > > Woburn, MA 01801
> > > Tel: 781-938-3830
> > > www.nuverabio.com
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list 
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >
> >
> > --
> > Jim Holtman
> > Cincinnati, OH
> > +1 513 646 9390
> >
> > What is the problem you are trying to solve?


From franco at grex.cyberspace.org  Tue Dec 26 00:25:33 2006
From: franco at grex.cyberspace.org (Frank Grex)
Date: Mon, 25 Dec 2006 18:25:33 -0500 (EST)
Subject: [R] Bayesian data mining
Message-ID: <Pine.BSO.4.63.0612251817440.31320@grex.cyberspace.org>

Hi, I need a help to know whether I can perform the following in R:
I have a set of observations (Ns) and each observation is drawn from a 
poisson distribution with an unkown mean, lambda. The set of lambdas in 
their turn are drawn from a common prior distribution which is supposed to 
be a a mixture of two gamma distributions.
Is there a way to determine the poisson means in R, given the Ns and the 
probabilities?
And how can one determine the two alphas and the two betas of the gamma 
mixtures? I am assuming there will be an MLE somewhere.
This is to help me understand and apply William DuMouchel concept of 
datamining especially in his article: "Bayesian data mining in large 
frequency tables". Thanks


From franco at grex.cyberspace.org  Tue Dec 26 00:31:33 2006
From: franco at grex.cyberspace.org (Frank Grex)
Date: Mon, 25 Dec 2006 18:31:33 -0500 (EST)
Subject: [R] Bayesian data mining (fwd)
Message-ID: <Pine.BSO.4.63.0612251830460.3501@grex.cyberspace.org>

Hi, I need a help to know whether I can perform the following in R:
I have a set of observations (Ns) and each observation is drawn from a
poisson distribution with an unkown mean, lambda. The set of lambdas in
their turn are drawn from a common prior distribution which is supposed to
be a a mixture of two gamma distributions.
Is there a way to determine the poisson means in R, given the Ns and the
probabilities?
And how can one determine the two alphas and the two betas of the gamma
mixtures? I am assuming there will be an MLE somewhere.
This is to help me understand and apply William DuMouchel concept of
datamining especially in his article: "Bayesian data mining in large
frequency tables". Thanks

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From milton_ruser at yahoo.com.br  Tue Dec 26 01:03:44 2006
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Tue, 26 Dec 2006 00:03:44 +0000 (GMT)
Subject: [R] defining color sequence in image()
Message-ID: <973009.27835.qm@web56608.mail.re3.yahoo.com>

Um texto embutido e sem conjunto de caracteres especificado associado...
Nome: n?o dispon?vel
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061226/61abf9fb/attachment.pl 

From jim at bitwrit.com.au  Tue Dec 26 01:16:20 2006
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 26 Dec 2006 11:16:20 +1100
Subject: [R] Problem to generate training data set and test data set
In-Reply-To: <6.1.2.0.2.20061225112056.01c5c4e0@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061225112056.01c5c4e0@aiminy.mail.iastate.edu>
Message-ID: <459069D4.8080103@bitwrit.com.au>

Aimin Yan wrote:
> I have a full data set like this:
> 
>     aa bas    aas bms   ams bcu        acu     omega       y
> 1 ALA   0 127.71   0 69.99   0 -0.2498560  79.91470 outward
> 2 PRO   0  68.55   0 55.44   0 -0.0949008  76.60380 outward
> 3 ALA   0  52.72   0 47.82   0 -0.0396550  52.19970 outward
> 4 PHE   0  22.62   0 31.21   0  0.1270330 169.52500  inward
> 5 SER   0  71.32   0 52.84   0 -0.1312380   7.47528 outward
> 6 VAL   0  12.92   0 22.40   0  0.1728390 149.09400  inward
> ......................................................................................
> 
> 
> aa have 19 levels, and there are different number of observation for each 
> levels.
> I want to pick 75% of observations of each levels randomly to generate a 
> training set,
> and 25% of observation of each levels to generate a testing set.
> 
Hi Aimin,
I haven't tested this exhaustively, but I think it does what you want.

get.prob.sample<-function(x,prob=0.5) {
  xlevels<-levels(as.factor(x))
  xlength<-length(x)
  xsamp<-rep(FALSE,xlength)
  for(i in xlevels) {
   lengthi<-length(x[x == i])
   xsamp[sample(which(x == i),lengthi*prob)]<-TRUE
  }
  return(xsamp)
}

get.prob.sample(mydata$aa,0.75)

Jim


From Bill.Venables at csiro.au  Tue Dec 26 01:59:45 2006
From: Bill.Venables at csiro.au (Bill.Venables at csiro.au)
Date: Tue, 26 Dec 2006 10:59:45 +1000
Subject: [R] Higher Dimensional Matrices
Message-ID: <B998A44C8986644EA8029CFE6396A924840A8E@exqld2-bne.qld.csiro.au>

Lars from space [sic] asks:
> -----Original Message-----

> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of downunder
> Sent: Monday, 25 December 2006 12:31 PM To: r-help at stat.math.ethz.ch
> Subject: [R] Higher Dimensional Matrices
> 
> 
> Hi all.
> 
> I want to calculate partial correlations while controlling for one
> or more variables. That works already fine when I control for
> example just for x[,1] and x[,2] that gives me one single
> correlation matrix and i have to to it for x [,1]...x[,10]. That
> would give me out 10 matrices. Controlling for 2 Variables 100
> matrices. how can I run a loop to get f.e the 10 or 100 matrices at
> once? I appreciate for every hint. have nice holidays.

I don't quite understand this.  You have 10 variables and you want to
find the partial correlations controlling for two of them at a time.
If you take each possible set of two variables to condition upon at a
time, this would give you choose(10, 2) = 45 matrices, wouldn't it?
Where do you get '10 or 100' matrices from?

> 
> greetings lars
> 
> x <- read.table("C:/.....dat")
> dim(x) #200x10
> a <- matrix(0,200,10)
> for (i in 1:10)
> a[,i] <- residuals(lm(x[,i]~1+x[,1]+x[,2]))
> b <- matrix(0,200,10)
> for (i in 1:10)
> b[,i] <- residuals(lm(x[,i]~1+x[,1]+x[,2]))
> #a=round(a,5)
> #b=round(b,5)
> d <- cor(a,b)
> d

But a and b are the same, aren't they?  Why do you need to compute
them twice?  Why not just use cor(a, a) [which is the same as cor(a),
of course]?

There is a more serious problem here, though.  Your residuals are
after regression on x[, 1:2] so if you *select* x[, 1:2] as the
y-variables in your regression then the residuals are going to be
zero, but in practice round-off error.  so the first two rows and
columns of d will be correlations with round-off error,
i.e. misleading junk.  It doesn't make sense to include the
conditioning variables in the correlation matrix *conditioning on
them*.  Only the 8 x 8 matrix of the others among themselves is
defined, really.

So how do we do it?  Here are a few pointers.

To start, here is a function that uses a somewhat more compact way of
finding the partial correlations than your method.  Sorting out how it
works should be a useful exercise.

partialCorr <- function (cond, mat) 
	cor(qr.resid(qr(cbind(1, mat[, cond])), mat[, -cond]))

To find the matrix of partial correlations conditioning on x[, 1:2]
you would use

d <- partialCorr(c(1,2), x)

So how to do it for all possible conditioning pairs of variables.
Well you could do it in an obvious loop:

cmats <- array(0, c(8,8,45))
k <- 0
for(i in 1:9) for(j in (i+1):10) {
    k <- k+1
    cmats[, , k] <- partialCorr(c(i, j), x)
}

Now the results are in a 3-way array, but without any kind of labels.
Perhaps you should think about how to fix that one yourself...

With more than two conditioning variables you should probably use a
function to generate the subsets of the appropriate size rather than
trying to write ever more deeply nested loops.  There are plenty of
functions around to do this.

Bill Venables.


From mardones.p at gmail.com  Tue Dec 26 06:07:57 2006
From: mardones.p at gmail.com (Pedro Mardones)
Date: Tue, 26 Dec 2006 00:07:57 -0500
Subject: [R] sequential row selection in dataframe
Message-ID: <83dca7860612252107j60f4836aq6cf3debc1dec4045@mail.gmail.com>

Dear all;

I'm wondering if there is any 'efficient' approach for selecting a
sample of 'every nth rows'  from a dataframe. For example, let's use
the dataframe GAGurine in MASS library:

> length(GAGurine[,1])
[1] 314

# select an 75% of the dataset, i.e. = 236 rows, every 2 rows starting
from row 1
> test<-GAGurine[seq(1,314,2),]
> length(test[,1])
[1] 157

# so, I still need another 79 rows, one way could be:
test2<-GAGurine[-seq(1,314,2),]
> length(test2[,1])
[1] 157
> test3<-test2[seq(1,157,2),]

# and then
final<-rbind(test2,test3)
> length(final[,1])
[1] 236

Does anyone have a better idea to get the same results but without
creating different datasets like test2 and test3?

Thanks
PM


From larsfromspace at web.de  Tue Dec 26 07:15:08 2006
From: larsfromspace at web.de (downunder)
Date: Mon, 25 Dec 2006 22:15:08 -0800 (PST)
Subject: [R] Higher Dimensional Matrices
In-Reply-To: <B998A44C8986644EA8029CFE6396A924840A8E@exqld2-bne.qld.csiro.au>
References: <B998A44C8986644EA8029CFE6396A924840A8E@exqld2-bne.qld.csiro.au>
Message-ID: <8051407.post@talk.nabble.com>


Hi Bill. Thanks for your extensive hints especially with arrays. 
That solves my problem now and I am also able to control for every
combination of variables.

Have a merry christmas. lars


> 
> x <- read.table("C:/.....dat")
> dim(x) #200x10
> a <- matrix(0,200,10)
> for (i in 1:10)
> a[,i] <- residuals(lm(x[,i]~1+x[,1]+x[,2]))
> b <- matrix(0,200,10)
> for (i in 1:10)
> b[,i] <- residuals(lm(x[,i]~1+x[,1]+x[,2]))
> #a=round(a,5)
> #b=round(b,5)
> d <- cor(a,b)
> d

But a and b are the same, aren't they?  Why do you need to compute
them twice?  Why not just use cor(a, a) [which is the same as cor(a),
of course]?

There is a more serious problem here, though.  Your residuals are
after regression on x[, 1:2] so if you *select* x[, 1:2] as the
y-variables in your regression then the residuals are going to be
zero, but in practice round-off error.  so the first two rows and
columns of d will be correlations with round-off error,
i.e. misleading junk.  It doesn't make sense to include the
conditioning variables in the correlation matrix *conditioning on
them*.  Only the 8 x 8 matrix of the others among themselves is
defined, really.

So how do we do it?  Here are a few pointers.

To start, here is a function that uses a somewhat more compact way of
finding the partial correlations than your method.  Sorting out how it
works should be a useful exercise.

partialCorr <- function (cond, mat) 
	cor(qr.resid(qr(cbind(1, mat[, cond])), mat[, -cond]))

To find the matrix of partial correlations conditioning on x[, 1:2]
you would use

d <- partialCorr(c(1,2), x)

So how to do it for all possible conditioning pairs of variables.
Well you could do it in an obvious loop:

cmats <- array(0, c(8,8,45))
k <- 0
for(i in 1:9) for(j in (i+1):10) {
    k <- k+1
    cmats[, , k] <- partialCorr(c(i, j), x)
}

Now the results are in a 3-way array, but without any kind of labels.
Perhaps you should think about how to fix that one yourself...

With more than two conditioning variables you should probably use a
function to generate the subsets of the appropriate size rather than
trying to write ever more deeply nested loops.  There are plenty of
functions around to do this.

Bill Venables.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



-- 
View this message in context: http://www.nabble.com/Re%3A--R--Higher-Dimensional-Matrices-tf2880928.html#a8051407
Sent from the R help mailing list archive at Nabble.com.


From justin_bem at yahoo.fr  Tue Dec 26 07:41:16 2006
From: justin_bem at yahoo.fr (justin bem)
Date: Tue, 26 Dec 2006 06:41:16 +0000 (GMT)
Subject: [R] Merry Xmas
Message-ID: <20061226064116.53756.qmail@web23014.mail.ird.yahoo.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20061226/dba2335d/attachment.pl 

From gzhu at peak6.com  Tue Dec 26 00:13:46 2006
From: gzhu at peak6.com (Geoffrey Zhu)
Date: Mon, 25 Dec 2006 17:13:46 -0600
Subject: [R] HOW TO: vectorize an iterative process.
Message-ID: <99F81FFD0EA54E4DA8D4F1BFE272F3410821BE@ppi-mail1.chicago.peak6.net>

SGkgRXZlcnlvbmUsDQogDQpJIGFtIHN0dWNrIHdpdGggYSBzaW1wbGUgcHJvYmxlbS4gU3Vw
cG9zZSBJIGhhdmUgYSB2ZWN0b3IgeCwgYW5kIEkgd2FudCB0byBjYWxjdWxhdGUgeVtpXT14
W2krMV0teFtpXSwgaXQgaXMgdmVyeSBlYXN5LiBJIGp1c3QgbmVlZCB0byB3cml0ZSB5PC14
WzI6bGVuZ3RoKHgpXS14WzE6bGVuZ3RoKHgpLTFdLiANCiANCk5vdyBpZiBJIGtub3cgeSwg
YW5kIHdhbnQgdG8ga25vdyB0aGUgdmVjdG9yIHggZGVmaW5lZCBieSB4W2ldPXhbaS0xXSt5
W2ktMV0gZm9yIGFsbCBpLCBob3cgY2FuIEkgZG8gdGhpcyB3aXRob3V0IGEgbG9vcD8gDQog
DQpUaGFua3MsDQpHZW9mZnJleQ0KIA0KDQpfX19fX19fX19fX19fX19fX19fX19fX19fX19f
X19fX19fX19fX19fX19fX19fX19fX19fX19fCgoKVGhlIGluZm9ybWF0aW9uIGluIHRoaXMg
ZW1haWwgb3IgaW4gYW55IGZpbGUgYXR0YWNoZWQgaGVyZXRvIGlzCmludGVuZGVkIG9ubHkg
Zm9yIHRoZSBwZXJzb25hbCBhbmQgY29uZmlkZW50aWFsIHVzZSBvZiB0aGUgaW5kaXZpZHVh
bApvciBlbnRpdHkgdG8gd2hpY2ggaXQgaXMgYWRkcmVzc2VkIGFuZCBtYXkgY29udGFpbiBp
bmZvcm1hdGlvbiB0aGF0IGlzCnByb3ByaWV0YXJ5IGFuZCBjb25maWRlbnRpYWwuIElmIHlv
dSBhcmUgbm90IHRoZSBpbnRlbmRlZCByZWNpcGllbnQgb2YKdGhpcyBtZXNzYWdlIHlvdSBh
cmUgaGVyZWJ5IG5vdGlmaWVkIHRoYXQgYW55IHJldmlldywgZGlzc2VtaW5hdGlvbiwKZGlz
dHJpYnV0aW9uIG9yIGNvcHlpbmcgb2YgdGhpcyBtZXNzYWdlIGlzIHN0cmljdGx5IHByb2hp
Yml0ZWQuIFRoaXMgY29tbXVuaWNhdGlvbiBpcyBmb3IgaW5mb3JtYXRpb24gcHVycG9zZXMg
b25seSBhbmQgc2hvdWxkIG5vdCBiZSByZWdhcmRlZCBhcyBhbiBvZmZlciB0byBzZWxsIG9y
IGFzIGEgc29saWNpdGF0aW9uIG9mIGFuIG9mZmVyIHRvIGJ1eSBhbnkgZmluYW5jaWFsIHBy
b2R1Y3QuIEVtYWlsIHRyYW5zbWlzc2lvbiBjYW5ub3QgYmUgZ3VhcmFudGVlZCB0byBiZSBz
ZWN1cmUgb3IgZXJyb3ItZnJlZS4NCg==


From s_michalski at o2.pl  Mon Dec 25 13:36:50 2006
From: s_michalski at o2.pl (Sebastian Michalski)
Date: Mon, 25 Dec 2006 13:36:50 +0100
Subject: [R] writing to S-PLUS .dat file
Message-ID: <005001c72821$59e96bd0$51cf1251@smicha>

Dear Users,
I am new to R. I use write() to write my data in .txt format. I'd like 
to write to a disc any kind of data in a .dat S-PLUS format.
Please help.
SM


From Achim.Zeileis at wu-wien.ac.at  Mon Dec 25 14:57:04 2006
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Mon, 25 Dec 2006 14:57:04 +0100 (CET)
Subject: [R] extend summary.lm for hccm?
In-Reply-To: <20061224163055.SXJY1773.tomts13-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <Pine.LNX.4.44.0612251439200.8229-100000@disco.wu-wien.ac.at>

On Sun, 24 Dec 2006, John Fox wrote:

> If I remember Freedman's recent paper correctly, he argues that sandwich
> variance estimator, though problematic in general, is not problematic in the
> case that White described -- an otherwise correctly specified linear model
> with heteroscedasticity estimated by least-squares.

More generally, sandwich-type estimators are valid (i.e., estimate
the right quantity, although not necessarily precisely, as Frank pointed
out) in situations where the estimating functions are correctly specified
but remaining aspets of the likelihood (not captured in the estimating
functions) are potentially not.

In linear models, it is easy to see what this means: the mean function has
to be correctly specified (i.e., the errors have zero mean) but the
correlation structure of the errors (i.e., their (co-)variances) might
differ from the usual assumptions. In GLMs, in particular logistic
regression, it is much more difficult to see against which types of
misspecification sandwich-based inference is robust.

Freedman's paper stresses the point that many model misspecifications also
imply misspecified estimating functions (and in his example this is rather
obvious) so that consequently the sandwich-type estimators estimate the
wrong quantity.

Best wishes,
Z


From kubovy at virginia.edu  Tue Dec 26 13:42:07 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Tue, 26 Dec 2006 07:42:07 -0500
Subject: [R] sequential row selection in dataframe
In-Reply-To: <83dca7860612252107j60f4836aq6cf3debc1dec4045@mail.gmail.com>
References: <83dca7860612252107j60f4836aq6cf3debc1dec4045@mail.gmail.com>
Message-ID: <391D1BF6-1D23-4661-8208-E2CCC4EBFB9B@virginia.edu>

On Dec 26, 2006, at 12:07 AM, Pedro Mardones wrote:

> I'm wondering if there is any 'efficient' approach for selecting a
> sample of 'every nth rows'  from a dataframe. For example, let's use
> the dataframe GAGurine in MASS library:
>
>> length(GAGurine[,1])
> [1] 314
>
> # select an 75% of the dataset, i.e. = 236 rows, every 2 rows starting
> from row 1
>> test<-GAGurine[seq(1,314,2),]
>> length(test[,1])
> [1] 157
>
> # so, I still need another 79 rows, one way could be:
> test2<-GAGurine[-seq(1,314,2),]
>> length(test2[,1])
> [1] 157
>> test3<-test2[seq(1,157,2),]
>
> # and then
> final<-rbind(test2,test3)
>> length(final[,1])
> [1] 236
>
> Does anyone have a better idea to get the same results but without
> creating different datasets like test2 and test3?

A probabilistic approach:

len <- length(GAGurine[,1])
GAGu <- GAGurine[sample(1:len, round(.75 * len)), ] # 236 rows

A deterministic one:

nr <- 1 #or 2
GAGu2 <- GAGurine[-seq(nr, len, 4),] # drop every 4th, giving 235 rows
nr <- 3 # or 4
will give 236 rows.
_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/


From gzhu at peak6.com  Tue Dec 26 16:33:49 2006
From: gzhu at peak6.com (Geoffrey Zhu)
Date: Tue, 26 Dec 2006 09:33:49 -0600
Subject: [R] vectorizing an iterative process.
Message-ID: <99F81FFD0EA54E4DA8D4F1BFE272F34102E907DB@ppi-mail1.chicago.peak6.net>

Hi Everyone,
 
I am stuck with a simple problem. Suppose I have a vector x, and I want
to calculate y[i]=3Dx[i+1]-x[i], it is very easy. I just need to write
y<-x[2:length(x)]-x[1:length(x)-1]. 
 
Now if I know y, and want to know the vector x defined by
x[i]=3Dx[i-1]+y[i-1] for all i, how can I do this without a loop? 
 
Thanks,
Geoffrey

PS. Sorry if you see a duplicate message. The previous one was in a
weird format that most people would not be able to read.

_______________________________________________________=0A=
=0A=
=0A=
The information in this email or in any file attached hereto is=0A=
intended only for the personal and confidential use of the individual=0A=
or entity to which it is addressed and may contain information that is=0A=
proprietary and confidential. If you are not the intended recipient of=0A=
this message you are hereby notified that any review, dissemination,=0A=
distribution or copying of this message is strictly prohibited. This communi=
cation is for information purposes only and should not be regarded as an off=
er to sell or as a solicitation of an offer to buy any financial product. Em=
ail transmission cannot be guaranteed to be secure or error-free.


From rmh at temple.edu  Tue Dec 26 16:55:45 2006
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 26 Dec 2006 10:55:45 -0500 (EST)
Subject: [R] vectorizing an iterative process.
Message-ID: <20061226105545.BQR80455@po-d.temple.edu>

> x[i]=3Dx[i-1]+y[i-1] for all i, how can I do this without a loop? 

It looks like
   x <- cumsum(y)

What does 3D mean?


From gzhu at peak6.com  Tue Dec 26 17:02:35 2006
From: gzhu at peak6.com (Geoffrey Zhu)
Date: Tue, 26 Dec 2006 10:02:35 -0600
Subject: [R] vectorizing an iterative process.
Message-ID: <99F81FFD0EA54E4DA8D4F1BFE272F34102E907EB@ppi-mail1.chicago.peak6.net>

Hi Richard,

3D is automatically generated by the mailing list software, probably
because I had ] followed by =3D without a space in the original post. 

What I meant was to calculate x[i] =3D x[i-1] + y[i-1] 

For example, if X <- 1:10

Then I want the vector Y to be 1, 3, 6, 10, 15, 21, 28, 36, 45, 55, or
in other words Y[i] =3D y[i-1] + x[i]. 

Yes, cumsum does the trick for this. This is what I need. Thanks.

Just curious, do you know how to calculate the more generic x[i] <- f(
x[i-1], y[i-1] )?

Thanks,
Geoffrey



-----Original Message-----
From: Richard M. Heiberger [mailto:rmh at temple.edu] 
Sent: Tuesday, December 26, 2006 9:56 AM
To: Geoffrey Zhu; r-help at stat.math.ethz.ch
Subject: Re: [R] vectorizing an iterative process.

> x[i]=3D3Dx[i-1]+y[i-1] for all i, how can I do this without a loop? 

It looks like
   x <- cumsum(y)

What does 3D mean?



_______________________________________________________=0A=
=0A=
=0A=
The information in this email or in any file attached hereto is=0A=
intended only for the personal and confidential use of the individual=0A=
or entity to which it is addressed and may contain information that is=0A=
proprietary and confidential. If you are not the intended recipient of=0A=
this message you are hereby notified that any review, dissemination,=0A=
distribution or copying of this message is strictly prohibited. This communi=
cation is for information purposes only and should not be regarded as an off=
er to sell or as a solicitation of an offer to buy any financial product. Em=
ail transmission cannot be guaranteed to be secure or error-free.


From h.wickham at gmail.com  Tue Dec 26 17:04:37 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 26 Dec 2006 08:04:37 -0800
Subject: [R] vectorizing an iterative process.
In-Reply-To: <20061226105545.BQR80455@po-d.temple.edu>
References: <20061226105545.BQR80455@po-d.temple.edu>
Message-ID: <f8e6ff050612260804v53a099feybabf471bf278bc31@mail.gmail.com>

> > x[i]=3Dx[i-1]+y[i-1] for all i, how can I do this without a loop?
>
> It looks like
>    x <- cumsum(y)
>
> What does 3D mean?

The =3D is probably an encoding error - it should just be =.

In general to vectorise an iterative problem, you will need to solve
the recurrence relation
(http://en.wikipedia.org/wiki/Recurrence_relation), although I think
it's pretty tricky in general, and there's no guarantee that the
vectorised/non-recursive form will be more efficient.

Hadley


From gzhu at peak6.com  Tue Dec 26 17:05:55 2006
From: gzhu at peak6.com (Geoffrey Zhu)
Date: Tue, 26 Dec 2006 10:05:55 -0600
Subject: [R] vectorizing an iterative process.
Message-ID: <99F81FFD0EA54E4DA8D4F1BFE272F34102E907ED@ppi-mail1.chicago.peak6.net>

I meant  x[i] <- x[i-1] + y[i-1] and Y[i] <- y[i-1] + x[i] below.

The mailing list software just keep adding 3D's. Sorry. 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Geoffrey Zhu
Sent: Tuesday, December 26, 2006 10:03 AM
To: Richard M. Heiberger; r-help at stat.math.ethz.ch
Subject: Re: [R] vectorizing an iterative process.

Hi Richard,

3D is automatically generated by the mailing list software, probably
because I had ] followed by =3D3D without a space in the original post. 

What I meant was to calculate x[i] =3D3D x[i-1] + y[i-1] 

For example, if X <- 1:10

Then I want the vector Y to be 1, 3, 6, 10, 15, 21, 28, 36, 45, 55, or
in other words Y[i] =3D3D y[i-1] + x[i]. 

Yes, cumsum does the trick for this. This is what I need. Thanks.

Just curious, do you know how to calculate the more generic x[i] <- f(
x[i-1], y[i-1] )?

Thanks,
Geoffrey



-----Original Message-----
From: Richard M. Heiberger [mailto:rmh at temple.edu]
Sent: Tuesday, December 26, 2006 9:56 AM
To: Geoffrey Zhu; r-help at stat.math.ethz.ch
Subject: Re: [R] vectorizing an iterative process.

> x[i]=3D3D3Dx[i-1]+y[i-1] for all i, how can I do this without a loop? 

It looks like
   x <- cumsum(y)

What does 3D mean?



_______________________________________________________=3D0A=3D
=3D0A=3D
=3D0A=3D
The information in this email or in any file attached hereto is=3D0A=3D
intended only for the personal and confidential use of the
individual=3D0A=3D or entity to which it is addressed and may contain
information that is=3D0A=3D proprietary and confidential. If you are not the
intended recipient of=3D0A=3D this message you are hereby notified that any
review, dissemination,=3D0A=3D distribution or copying of this message is
strictly prohibited. This communi=3D cation is for information purposes
only and should not be regarded as an off=3D er to sell or as a
solicitation of an offer to buy any financial product. Em=3D ail
transmission cannot be guaranteed to be secure or error-free.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



_______________________________________________________=0A=
=0A=
=0A=
The information in this email or in any file attached hereto is=0A=
intended only for the personal and confidential use of the individual=0A=
or entity to which it is addressed and may contain information that is=0A=
proprietary and confidential. If you are not the intended recipient of=0A=
this message you are hereby notified that any review, dissemination,=0A=
distribution or copying of this message is strictly prohibited. This communi=
cation is for information purposes only and should not be regarded as an off=
er to sell or as a solicitation of an offer to buy any financial product. Em=
ail transmission cannot be guaranteed to be secure or error-free.


From ompandey at gmail.com  Tue Dec 26 17:20:45 2006
From: ompandey at gmail.com (Om)
Date: Tue, 26 Dec 2006 21:50:45 +0530
Subject: [R] Colored Dendrogram
Message-ID: <aa697c6a0612260820g1d1d6312x207dcd74a87e4fe8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061226/a7739cd6/attachment.pl 

From christos at nuverabio.com  Tue Dec 26 17:58:07 2006
From: christos at nuverabio.com (Christos Hatzis)
Date: Tue, 26 Dec 2006 11:58:07 -0500
Subject: [R] vectorizing an iterative process.
In-Reply-To: <99F81FFD0EA54E4DA8D4F1BFE272F34102E907ED@ppi-mail1.chicago.peak6.net>
Message-ID: <002d01c7290f$05080b50$0e010a0a@headquarters.silicoinsights>

In your case, the recurrence relationship for x can be solved easily:
Notice that 

sum{i=1,n}(x[i]-x[i-1]) = x[n] - x[0] 

and therefore

x[n] = x[0] + sum{i=1,n}(y[i-1] for n=1, N, with the appropriate initial
condition for i=0, (x[0],y[0]).

Thus cumsum on y will give you a direct answer.

-Christos

Christos Hatzis, Ph.D.
Nuvera Biosciences, Inc.
400 West Cummings Park
Suite 5350
Woburn, MA 01801
Tel: 781-938-3830
www.nuverabio.com
 
  

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Geoffrey Zhu
Sent: Tuesday, December 26, 2006 11:06 AM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] vectorizing an iterative process.

I meant  x[i] <- x[i-1] + y[i-1] and Y[i] <- y[i-1] + x[i] below.

The mailing list software just keep adding 3D's. Sorry. 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Geoffrey Zhu
Sent: Tuesday, December 26, 2006 10:03 AM
To: Richard M. Heiberger; r-help at stat.math.ethz.ch
Subject: Re: [R] vectorizing an iterative process.

Hi Richard,

3D is automatically generated by the mailing list software, probably because
I had ] followed by =3D3D without a space in the original post. 

What I meant was to calculate x[i] =3D3D x[i-1] + y[i-1] 

For example, if X <- 1:10

Then I want the vector Y to be 1, 3, 6, 10, 15, 21, 28, 36, 45, 55, or in
other words Y[i] =3D3D y[i-1] + x[i]. 

Yes, cumsum does the trick for this. This is what I need. Thanks.

Just curious, do you know how to calculate the more generic x[i] <- f(
x[i-1], y[i-1] )?

Thanks,
Geoffrey



-----Original Message-----
From: Richard M. Heiberger [mailto:rmh at temple.edu]
Sent: Tuesday, December 26, 2006 9:56 AM
To: Geoffrey Zhu; r-help at stat.math.ethz.ch
Subject: Re: [R] vectorizing an iterative process.

> x[i]=3D3D3Dx[i-1]+y[i-1] for all i, how can I do this without a loop? 

It looks like
   x <- cumsum(y)

What does 3D mean?



_______________________________________________________=3D0A=3D
=3D0A=3D
=3D0A=3D
The information in this email or in any file attached hereto is=3D0A=3D
intended only for the personal and confidential use of the
individual=3D0A=3D or entity to which it is addressed and may contain
information that is=3D0A=3D proprietary and confidential. If you are not the
intended recipient of=3D0A=3D this message you are hereby notified that any
review, dissemination,=3D0A=3D distribution or copying of this message is
strictly prohibited. This communi=3D cation is for information purposes only
and should not be regarded as an off=3D er to sell or as a solicitation of
an offer to buy any financial product. Em=3D ail transmission cannot be
guaranteed to be secure or error-free.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



_______________________________________________________=0A=
=0A=
=0A=
The information in this email or in any file attached hereto is=0A= intended
only for the personal and confidential use of the individual=0A= or entity
to which it is addressed and may contain information that is=0A= proprietary
and confidential. If you are not the intended recipient of=0A= this message
you are hereby notified that any review, dissemination,=0A= distribution or
copying of this message is strictly prohibited. This communi= cation is for
information purposes only and should not be regarded as an off= er to sell
or as a solicitation of an offer to buy any financial product. Em= ail
transmission cannot be guaranteed to be secure or error-free.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From cberry at tajo.ucsd.edu  Tue Dec 26 18:43:38 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Tue, 26 Dec 2006 09:43:38 -0800
Subject: [R] Problem to generate training data set and test data set
In-Reply-To: <6.1.2.0.2.20061225112056.01c5c4e0@aiminy.mail.iastate.edu>
References: <6.1.2.0.2.20061225112056.01c5c4e0@aiminy.mail.iastate.edu>
Message-ID: <Pine.LNX.4.64.0612260929020.30860@tajo.ucsd.edu>


What you describe is called stratified sampling. It was discusssed last 
month (and other times) on this list:

 	http://finzi.psych.upenn.edu/R/Rhelp02a/archive/90220.html

Using

 	RSiteSearch("stratified sampling")

will produce many hits to relevant articles and packages.



On Mon, 25 Dec 2006, Aimin Yan wrote:

> I have a full data set like this:
>
>    aa bas    aas bms   ams bcu        acu     omega       y
> 1 ALA   0 127.71   0 69.99   0 -0.2498560  79.91470 outward
> 2 PRO   0  68.55   0 55.44   0 -0.0949008  76.60380 outward
> 3 ALA   0  52.72   0 47.82   0 -0.0396550  52.19970 outward
> 4 PHE   0  22.62   0 31.21   0  0.1270330 169.52500  inward
> 5 SER   0  71.32   0 52.84   0 -0.1312380   7.47528 outward
> 6 VAL   0  12.92   0 22.40   0  0.1728390 149.09400  inward
> ......................................................................................
>
>
> aa have 19 levels, and there are different number of observation for each
> levels.
> I want to pick 75% of observations of each levels randomly to generate a
> training set,
> and 25% of observation of each levels to generate a testing set.
>
> Does anyone know to do this?
>
> Thanks
>
> Aimin Yan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717


From gzhu at peak6.com  Tue Dec 26 18:45:43 2006
From: gzhu at peak6.com (Geoffrey Zhu)
Date: Tue, 26 Dec 2006 11:45:43 -0600
Subject: [R] vectorizing an iterative process.
Message-ID: <99F81FFD0EA54E4DA8D4F1BFE272F34102E90814@ppi-mail1.chicago.peak6.net>

Yes, this solves my problem. Thanks for your help.

-----Original Message-----
From: Christos Hatzis [mailto:christos at nuverabio.com] 
Sent: Tuesday, December 26, 2006 10:58 AM
To: Geoffrey Zhu; r-help at stat.math.ethz.ch
Subject: RE: [R] vectorizing an iterative process.

In your case, the recurrence relationship for x can be solved easily:
Notice that 

sum{i=3D1,n}(x[i]-x[i-1]) =3D x[n] - x[0] 

and therefore

x[n] =3D x[0] + sum{i=3D1,n}(y[i-1] for n=3D1, N, with the appropriate initi=
al
condition for i=3D0, (x[0],y[0]).

Thus cumsum on y will give you a direct answer.

-Christos

Christos Hatzis, Ph.D.
Nuvera Biosciences, Inc.
400 West Cummings Park
Suite 5350
Woburn, MA 01801
Tel: 781-938-3830
www.nuverabio.com
 
  

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Geoffrey Zhu
Sent: Tuesday, December 26, 2006 11:06 AM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] vectorizing an iterative process.

I meant  x[i] <- x[i-1] + y[i-1] and Y[i] <- y[i-1] + x[i] below.

The mailing list software just keep adding 3D's. Sorry. 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Geoffrey Zhu
Sent: Tuesday, December 26, 2006 10:03 AM
To: Richard M. Heiberger; r-help at stat.math.ethz.ch
Subject: Re: [R] vectorizing an iterative process.

Hi Richard,

3D is automatically generated by the mailing list software, probably
because I had ] followed by =3D3D3D without a space in the original post. 

What I meant was to calculate x[i] =3D3D3D x[i-1] + y[i-1] 

For example, if X <- 1:10

Then I want the vector Y to be 1, 3, 6, 10, 15, 21, 28, 36, 45, 55, or
in other words Y[i] =3D3D3D y[i-1] + x[i]. 

Yes, cumsum does the trick for this. This is what I need. Thanks.

Just curious, do you know how to calculate the more generic x[i] <- f(
x[i-1], y[i-1] )?

Thanks,
Geoffrey



-----Original Message-----
From: Richard M. Heiberger [mailto:rmh at temple.edu]
Sent: Tuesday, December 26, 2006 9:56 AM
To: Geoffrey Zhu; r-help at stat.math.ethz.ch
Subject: Re: [R] vectorizing an iterative process.

> x[i]=3D3D3D3Dx[i-1]+y[i-1] for all i, how can I do this without a loop? 

It looks like
   x <- cumsum(y)

What does 3D mean?



_______________________________________________________=3D3D0A=3D3D
=3D3D0A=3D3D
=3D3D0A=3D3D
The information in this email or in any file attached hereto is=3D3D0A=3D3D
intended only for the personal and confidential use of the
individual=3D3D0A=3D3D or entity to which it is addressed and may contain
information that is=3D3D0A=3D3D proprietary and confidential. If you are not
the intended recipient of=3D3D0A=3D3D this message you are hereby notified
that any review, dissemination,=3D3D0A=3D3D distribution or copying of this
message is strictly prohibited. This communi=3D3D cation is for
information purposes only and should not be regarded as an off=3D3D er to
sell or as a solicitation of an offer to buy any financial product.
Em=3D3D ail transmission cannot be guaranteed to be secure or error-free.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



_______________________________________________________=3D0A=3D
=3D0A=3D
=3D0A=3D
The information in this email or in any file attached hereto is=3D0A=3D
intended only for the personal and confidential use of the
individual=3D0A=3D or entity to which it is addressed and may contain
information that is=3D0A=3D proprietary and confidential. If you are not the
intended recipient of=3D0A=3D this message you are hereby notified that any
review, dissemination,=3D0A=3D distribution or copying of this message is
strictly prohibited. This communi=3D cation is for information purposes
only and should not be regarded as an off=3D er to sell or as a
solicitation of an offer to buy any financial product. Em=3D ail
transmission cannot be guaranteed to be secure or error-free.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.






_______________________________________________________=0A=
=0A=
=0A=
The information in this email or in any file attached hereto is=0A=
intended only for the personal and confidential use of the individual=0A=
or entity to which it is addressed and may contain information that is=0A=
proprietary and confidential. If you are not the intended recipient of=0A=
this message you are hereby notified that any review, dissemination,=0A=
distribution or copying of this message is strictly prohibited. This communi=
cation is for information purposes only and should not be regarded as an off=
er to sell or as a solicitation of an offer to buy any financial product. Em=
ail transmission cannot be guaranteed to be secure or error-free.


From jdnewmil at dcn.davis.ca.us  Tue Dec 26 18:54:06 2006
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 26 Dec 2006 09:54:06 -0800
Subject: [R] Rating competitors
Message-ID: <459161BE.6020703@dcn.davis.ca.us>

I am looking for hints on how to estimate ratings for competitors
in an ongoing pairwise competition using R... my particular area of
interest being the game of Go, but the idea of identifying ratings
(on a continuous scale) rather than relative rankings seems easily
generalized to other competitions so I thought someone might be
studying something related already.

I presume the rating of a competitor would be best modeled as a random
variate on the rating scale, and an encounter between two
competitors would be represented by a binary result.  Logistic regression
seems promising, but I am at a loss how to represent the model since
the pairings are arbitrary and not necessarily repeated often.

I have read about some approaches to estimating ratings for Go,
but they seem to involve optimization using assumed distributions
rather than model fitting which characterizes analysis in R.

Does any of this sound familiar? Suggestions for reading, anyone?

-- 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From p.dalgaard at biostat.ku.dk  Tue Dec 26 18:56:45 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 26 Dec 2006 18:56:45 +0100
Subject: [R] vectorizing an iterative process.
In-Reply-To: <99F81FFD0EA54E4DA8D4F1BFE272F34102E907ED@ppi-mail1.chicago.peak6.net>
References: <99F81FFD0EA54E4DA8D4F1BFE272F34102E907ED@ppi-mail1.chicago.peak6.net>
Message-ID: <4591625D.8000705@biostat.ku.dk>

Geoffrey Zhu wrote:
> I meant  x[i] <- x[i-1] + y[i-1] and Y[i] <- y[i-1] + x[i] below.
>
> The mailing list software just keep adding 3D's. Sorry. 
>   
Rather, I suspect that *your* mailer is sending in Quoted-Printable, 
without setting the appropriate headers. Take a look at

 http://mail.python.org/pipermail/mailman-users/2003-December/033425.html

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Geoffrey Zhu
> Sent: Tuesday, December 26, 2006 10:03 AM
> To: Richard M. Heiberger; r-help at stat.math.ethz.ch
> Subject: Re: [R] vectorizing an iterative process.
>
> Hi Richard,
>
> 3D is automatically generated by the mailing list software, probably
> because I had ] followed by =3D3D without a space in the original post. 
>
> What I meant was to calculate x[i] =3D3D x[i-1] + y[i-1] 
>
> For example, if X <- 1:10
>
> Then I want the vector Y to be 1, 3, 6, 10, 15, 21, 28, 36, 45, 55, or
> in other words Y[i] =3D3D y[i-1] + x[i]. 
>
> Yes, cumsum does the trick for this. This is what I need. Thanks.
>
> Just curious, do you know how to calculate the more generic x[i] <- f(
> x[i-1], y[i-1] )?
>
> Thanks,
> Geoffrey
>
>
>
> -----Original Message-----
> From: Richard M. Heiberger [mailto:rmh at temple.edu]
> Sent: Tuesday, December 26, 2006 9:56 AM
> To: Geoffrey Zhu; r-help at stat.math.ethz.ch
> Subject: Re: [R] vectorizing an iterative process.
>
>   
>> x[i]=3D3D3Dx[i-1]+y[i-1] for all i, how can I do this without a loop? 
>>     
>
> It looks like
>    x <- cumsum(y)
>
> What does 3D mean?
>
>
>
> _______________________________________________________=3D0A=3D
> =3D0A=3D
> =3D0A=3D
> The information in this email or in any file attached hereto is=3D0A=3D
> intended only for the personal and confidential use of the
> individual=3D0A=3D or entity to which it is addressed and may contain
> information that is=3D0A=3D proprietary and confidential. If you are not the
> intended recipient of=3D0A=3D this message you are hereby notified that any
> review, dissemination,=3D0A=3D distribution or copying of this message is
> strictly prohibited. This communi=3D cation is for information purposes
> only and should not be regarded as an off=3D er to sell or as a
> solicitation of an offer to buy any financial product. Em=3D ail
> transmission cannot be guaranteed to be secure or error-free.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> _______________________________________________________=0A=
> =0A=
> =0A=
> The information in this email or in any file attached hereto is=0A=
> intended only for the personal and confidential use of the individual=0A=
> or entity to which it is addressed and may contain information that is=0A=
> proprietary and confidential. If you are not the intended recipient of=0A=
> this message you are hereby notified that any review, dissemination,=0A=
> distribution or copying of this message is strictly prohibited. This communi=
> cation is for information purposes only and should not be regarded as an off=
> er to sell or as a solicitation of an offer to buy any financial product. Em=
> ail transmission cannot be guaranteed to be secure or error-free.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From spencer.graves at pdf.com  Tue Dec 26 19:14:53 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 26 Dec 2006 10:14:53 -0800
Subject: [R] Rating competitors
In-Reply-To: <459161BE.6020703@dcn.davis.ca.us>
References: <459161BE.6020703@dcn.davis.ca.us>
Message-ID: <4591669D.4090108@pdf.com>

      Have you considered Bradley-Terry models?   RSiteSearch("bradley", 
"functions") just returned 31 hits for me. 

      Hope this helps. 
      Spencer Graves

Jeff Newmiller wrote:
> I am looking for hints on how to estimate ratings for competitors
> in an ongoing pairwise competition using R... my particular area of
> interest being the game of Go, but the idea of identifying ratings
> (on a continuous scale) rather than relative rankings seems easily
> generalized to other competitions so I thought someone might be
> studying something related already.
>
> I presume the rating of a competitor would be best modeled as a random
> variate on the rating scale, and an encounter between two
> competitors would be represented by a binary result.  Logistic regression
> seems promising, but I am at a loss how to represent the model since
> the pairings are arbitrary and not necessarily repeated often.
>
> I have read about some approaches to estimating ratings for Go,
> but they seem to involve optimization using assumed distributions
> rather than model fitting which characterizes analysis in R.
>
> Does any of this sound familiar? Suggestions for reading, anyone?
>
>


From cberry at tajo.ucsd.edu  Tue Dec 26 19:53:33 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Tue, 26 Dec 2006 10:53:33 -0800
Subject: [R] Rating competitors
In-Reply-To: <459161BE.6020703@dcn.davis.ca.us>
References: <459161BE.6020703@dcn.davis.ca.us>
Message-ID: <Pine.LNX.4.64.0612261020460.30860@tajo.ucsd.edu>



There is a substantial literature on 'statistics in sports' and pairwise 
comparisons are of obvious interest. Here is a starting point:

 	http://www.amstat.org/sections/sis/

You might browse the newsletters posted there.

You might enjoy:

Bridging Different Eras in Sports by Scott M. Berry, Patrick D. Larkey, C. 
Shane Reese; Journal of the American Statistical Association, Vol. 94, 
1999

or

Baseball's All-Time Best Hitters: How Statistics Can Level the Playing 
Field by Michael J. Schell

 	http://press.princeton.edu/titles/6550.html


On Tue, 26 Dec 2006, Jeff Newmiller wrote:

> I am looking for hints on how to estimate ratings for competitors
> in an ongoing pairwise competition using R... my particular area of
> interest being the game of Go, but the idea of identifying ratings
> (on a continuous scale) rather than relative rankings seems easily
> generalized to other competitions so I thought someone might be
> studying something related already.
>
> I presume the rating of a competitor would be best modeled as a random
> variate on the rating scale, and an encounter between two
> competitors would be represented by a binary result.  Logistic regression
> seems promising, but I am at a loss how to represent the model since
> the pairings are arbitrary and not necessarily repeated often.
>
> I have read about some approaches to estimating ratings for Go,
> but they seem to involve optimization using assumed distributions
> rather than model fitting which characterizes analysis in R.
>
> Does any of this sound familiar? Suggestions for reading, anyone?
>
> -- 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717


From ivowel at gmail.com  Tue Dec 26 19:53:54 2006
From: ivowel at gmail.com (ivo welch)
Date: Tue, 26 Dec 2006 13:53:54 -0500
Subject: [R] slightly inconsistent behavior
Message-ID: <50d1c22d0612261053g6ef4ecd2vf480574b28531941@mail.gmail.com>

dear R experts:

This is just a minor, minor nuisance, but I thought I would point it out:

> dataset <- read.table(file=pipe(cmdline), header =T,
+                   na.strings=c("NaN", "C","I","M", "E"), sep=",",
as.is=T, nrows=99999999);
Error: cannot allocate vector of size 781249 Kb

If I extend nrows by a few more 9's, the error goes away.  Similarly,
if I use much fewer observations, the error goes away.

regards,

/iaw


From kubovy at virginia.edu  Tue Dec 26 19:56:24 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Tue, 26 Dec 2006 13:56:24 -0500
Subject: [R] Rating competitors
In-Reply-To: <4591669D.4090108@pdf.com>
References: <459161BE.6020703@dcn.davis.ca.us> <4591669D.4090108@pdf.com>
Message-ID: <DCC2D5B7-004B-4C15-ABBC-8E5635FDF7E9@virginia.edu>

I would start with elimination-by-aspects models:
?eba
I would read the Tversky 1972 paper (cited on the help page for the  
eba() function), which is brilliant.

Jeff Newmiller wrote:

> I am looking for hints on how to estimate ratings for competitors
> in an ongoing pairwise competition using R... my particular area of
> interest being the game of Go, but the idea of identifying ratings
> (on a continuous scale) rather than relative rankings seems easily
> generalized to other competitions so I thought someone might be
> studying something related already.
>
> I presume the rating of a competitor would be best modeled as a random
> variate on the rating scale, and an encounter between two
> competitors would be represented by a binary result.  Logistic  
> regression
> seems promising, but I am at a loss how to represent the model since
> the pairings are arbitrary and not necessarily repeated often.
_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/


From Greg.Snow at intermountainmail.org  Tue Dec 26 21:38:07 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Tue, 26 Dec 2006 13:38:07 -0700
Subject: [R] Rating competitors
Message-ID: <07E228A5BE53C24CAD490193A7381BBB73A180@LP-EXCHVS07.CO.IHC.COM>

One approach that is already coded in R is the Bradley-Terry model
(found in the BradleyTerry package of all places).

This could be a good place to start if you want something quick, others
have given you references if you want more detail and/or control. 


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jeff Newmiller
Sent: Tuesday, December 26, 2006 10:54 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Rating competitors

I am looking for hints on how to estimate ratings for competitors in an
ongoing pairwise competition using R... my particular area of interest
being the game of Go, but the idea of identifying ratings (on a
continuous scale) rather than relative rankings seems easily generalized
to other competitions so I thought someone might be studying something
related already.

I presume the rating of a competitor would be best modeled as a random
variate on the rating scale, and an encounter between two competitors
would be represented by a binary result.  Logistic regression seems
promising, but I am at a loss how to represent the model since the
pairings are arbitrary and not necessarily repeated often.

I have read about some approaches to estimating ratings for Go, but they
seem to involve optimization using assumed distributions rather than
model fitting which characterizes analysis in R.

Does any of this sound familiar? Suggestions for reading, anyone?

--
------------------------------------------------------------------------
---
Jeff Newmiller                        The     .....       .....  Go
Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
Go...
                                       Live:   OO#.. Dead: OO#..
Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.
rocks...1k

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgreen at dyson.brisnet.org.au  Tue Dec 26 22:27:00 2006
From: bgreen at dyson.brisnet.org.au (Bob Green)
Date: Wed, 27 Dec 2006 07:27:00 +1000
Subject: [R] McNemar test in R & SPSS
Message-ID: <5.1.0.14.0.20061226080023.00ce7fe0@pop3.brisnet.org.au>

Hello,

I am hoping someone can clarify why I might obtain a quite different value 
in R & SPSS  for a McNemar test I ran.

Firstly, here is the R syntax & output


R OUTPUT

 > mctest <- as.table(matrix(c(128,29,331,430),
+ ncol =2, dimnames = list(group=c("preMHT","postMHT"),
+ assault=c("yes","no"))))

 > mctest
               assault
group       yes  no
   preMHT  128 331
   postMHT  29 430

 >  mcnemar.test(mctest,correct=F)

         McNemar's Chi-squared test

data:  mctest
McNemar's chi-squared = 253.3444, df = 1, p-value < 2.2e-16


SPSS OUTPUT

The same data was inputted in SPSS. Regarding the first table SPSS 
generated - it lists the number of cases in each combination of categories. 
The diagonal contains the number of cases with the same response on both 
variables, while the off diagonal contains cases that have different 
responses on the 2 variables. The overall chisquare value is much lower 
than the value obtained using R, though still significant.


pre02 & post02

pre02   post02

         0       1
0       311     20
1       119     9


Test Statistics(b)

  pre02 & post02

N               459
Chi-Square(a)   69.094
Asymp. Sig.     .000

a  Continuity Corrected
b  McNemar Test


Any assistance is much appreciated,

Bob Green


From p.dalgaard at biostat.ku.dk  Tue Dec 26 22:52:56 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 26 Dec 2006 22:52:56 +0100
Subject: [R] McNemar test in R & SPSS
In-Reply-To: <5.1.0.14.0.20061226080023.00ce7fe0@pop3.brisnet.org.au>
References: <5.1.0.14.0.20061226080023.00ce7fe0@pop3.brisnet.org.au>
Message-ID: <459199B8.6010408@biostat.ku.dk>

Bob Green wrote:
> Hello,
>
> I am hoping someone can clarify why I might obtain a quite different value 
> in R & SPSS  for a McNemar test I ran.
>
> Firstly, here is the R syntax & output
>
>
> R OUTPUT
>
>  > mctest <- as.table(matrix(c(128,29,331,430),
> + ncol =2, dimnames = list(group=c("preMHT","postMHT"),
> + assault=c("yes","no"))))
>
>  > mctest
>                assault
> group       yes  no
>    preMHT  128 331
>    postMHT  29 430
>
>  >  mcnemar.test(mctest,correct=F)
>
>          McNemar's Chi-squared test
>
> data:  mctest
> McNemar's chi-squared = 253.3444, df = 1, p-value < 2.2e-16
>
>
> SPSS OUTPUT
>
> The same data was inputted in SPSS. Regarding the first table SPSS 
> generated - it lists the number of cases in each combination of categories. 
> The diagonal contains the number of cases with the same response on both 
> variables, while the off diagonal contains cases that have different 
> responses on the 2 variables. The overall chisquare value is much lower 
> than the value obtained using R, though still significant.
>
>
> pre02 & post02
>
> pre02   post02
>
>          0       1
> 0       311     20
> 1       119     9
>
>
> Test Statistics(b)
>
>   pre02 & post02
>
> N               459
> Chi-Square(a)   69.094
> Asymp. Sig.     .000
>
> a  Continuity Corrected
> b  McNemar Test
>
>
> Any assistance is much appreciated,
>   
Well, you can't expect R to give the correct result if you feed it the 
wrong matrix, can you?

> d <- read.table(stdin())

0:          0       1

1: 0       311     20

2: 1       119     9

3: 

> d

   X0 X1

0 311 20

1 119  9

> mcnemar.test(as.matrix(d),correct=F)

        McNemar's Chi-squared test

data:  as.matrix(d) 

McNemar's chi-squared = 70.5108, df = 1, p-value < 2.2e-16

> mcnemar.test(as.matrix(d),correct=T)

        McNemar's Chi-squared test with continuity correction

data:  as.matrix(d) 

McNemar's chi-squared = 69.0935, df = 1, p-value < 2.2e-16



> Bob Green
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From cberry at tajo.ucsd.edu  Tue Dec 26 18:24:04 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Tue, 26 Dec 2006 09:24:04 -0800
Subject: [R] extend summary.lm for hccm?
In-Reply-To: <Pine.LNX.4.44.0612251439200.8229-100000@disco.wu-wien.ac.at>
References: <Pine.LNX.4.44.0612251439200.8229-100000@disco.wu-wien.ac.at>
Message-ID: <Pine.LNX.4.64.0612260910420.30860@tajo.ucsd.edu>

On Mon, 25 Dec 2006, Achim Zeileis wrote:

> On Sun, 24 Dec 2006, John Fox wrote:
>
>> If I remember Freedman's recent paper correctly, he argues that sandwich
>> variance estimator, though problematic in general, is not problematic in the
>> case that White described -- an otherwise correctly specified linear model
>> with heteroscedasticity estimated by least-squares.
>
> More generally, sandwich-type estimators are valid (i.e., estimate
> the right quantity, although not necessarily precisely, as Frank pointed
> out) in situations where the estimating functions are correctly specified
> but remaining aspets of the likelihood (not captured in the estimating
> functions) are potentially not.

Not exactly. The asymptotic properites are good, but in samples of 
moderate size the properties (including both biasedness and variance) can 
be surprisingly bad. And if you are trying to calculate a p-value, getting 
a too-small variance estimate gives you spuriously small p-values. FWIW, 
I've seen a case in which the nominal size of a test based on the sandwich 
estimator was several orders of magnitude smaller than a test with correct 
nominal size.

There is a modest literature on this. Some refs:

Background Papers:

Drum M, McCullagh P. Comment. Statistical Science 1993; 8:300-301.

Freedman DA. On the So-Called "Huber Sandwich Estimator" and "Robust"
Standard Errors. The American Statistician, Volume 60, Number 4, 
November 2006, pp. 299-302(4)

-----

Some Proposed Corrections:

Fay MP and Graubard BI. Small-Sample Adjustments for
Walt-Type Tests Using Sandwich Estimators. Biometrics 2001; 57:
1198-1206.

Guo X, Pan W, Connett JE, Hannan PJ and French SA.  Small-sample
performance of the robust score test and its modifications in
generalized estimating equations Statistics in Medicine 2005;
24:3479-3495

Mancl LA and DeRouen TA, A Covariance Estimator for GEE with Improved
Small-Sample Properties. Biometrics 2001; 57:126-134.

Morel JG, Bokossa MC, and Neerchal NK.  Small Sample Correction for
the Variance of GEE Estimators Biometrical Journal 2003; 45(4):
395-409.

Pan W and Wall MM. Small-sample adjustments in using the
sandwich variance estimator in generalized estimating
equations. Statistics in Medicine  2002; 21:1429-1441.


HTH,

Chuck

>
> In linear models, it is easy to see what this means: the mean function has
> to be correctly specified (i.e., the errors have zero mean) but the
> correlation structure of the errors (i.e., their (co-)variances) might
> differ from the usual assumptions. In GLMs, in particular logistic
> regression, it is much more difficult to see against which types of
> misspecification sandwich-based inference is robust.
>
> Freedman's paper stresses the point that many model misspecifications also
> imply misspecified estimating functions (and in his example this is rather
> obvious) so that consequently the sandwich-type estimators estimate the
> wrong quantity.
>
> Best wishes,
> Z
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717


From bgreen at dyson.brisnet.org.au  Tue Dec 26 23:23:16 2006
From: bgreen at dyson.brisnet.org.au (Bob Green)
Date: Wed, 27 Dec 2006 08:23:16 +1000
Subject: [R] McNemar test in R & SPSS
In-Reply-To: <459199B8.6010408@biostat.ku.dk>
References: <5.1.0.14.0.20061226080023.00ce7fe0@pop3.brisnet.org.au>
	<5.1.0.14.0.20061226080023.00ce7fe0@pop3.brisnet.org.au>
Message-ID: <5.1.0.14.0.20061227080535.00d5edd8@pop3.brisnet.org.au>

Peter,

Thanks for your reply. To perform the analysis in R, I used the table 
format suggested in the book by Everitt & Hothorn, whereas in SPSS the 
analysis was performed directly from the 2 variables, rather than using 
count data.

There is still something I don't understand  - I tried to replicate the 
syntax from your e-mail but my computer just kept waiting - what am I still 
doing wrong?


  mctest <- as.table(matrix(c(128,29,331,430), ncol =2, dimnames = 
list(group=c("preMHT","postMHT"), assault=c("yes","no"))))
 > d <- read.table(stdin())
0: mcnemar.test(as.matrix(d),correct=F)
1:

Thanks again

Bob


At 10:52 PM 26/12/2006 +0100, Peter Dalgaard wrote:
>Bob Green wrote:
>>Hello,
>>
>>I am hoping someone can clarify why I might obtain a quite different 
>>value in R & SPSS  for a McNemar test I ran.
>>
>>Firstly, here is the R syntax & output
>>
>>
>>R OUTPUT
>>
>>  > mctest <- as.table(matrix(c(128,29,331,430),
>>+ ncol =2, dimnames = list(group=c("preMHT","postMHT"),
>>+ assault=c("yes","no"))))
>>
>>  > mctest
>>                assault
>>group       yes  no
>>    preMHT  128 331
>>    postMHT  29 430
>>
>>  >  mcnemar.test(mctest,correct=F)
>>
>>          McNemar's Chi-squared test
>>
>>data:  mctest
>>McNemar's chi-squared = 253.3444, df = 1, p-value < 2.2e-16
>>
>>
>>SPSS OUTPUT
>>
>>The same data was inputted in SPSS. Regarding the first table SPSS 
>>generated - it lists the number of cases in each combination of 
>>categories. The diagonal contains the number of cases with the same 
>>response on both variables, while the off diagonal contains cases that 
>>have different responses on the 2 variables. The overall chisquare value 
>>is much lower than the value obtained using R, though still significant.
>>
>>
>>pre02 & post02
>>
>>pre02   post02
>>
>>          0       1
>>0       311     20
>>1       119     9
>>
>>
>>Test Statistics(b)
>>
>>   pre02 & post02
>>
>>N               459
>>Chi-Square(a)   69.094
>>Asymp. Sig.     .000
>>
>>a  Continuity Corrected
>>b  McNemar Test
>>
>>
>>Any assistance is much appreciated,
>>
>Well, you can't expect R to give the correct result if you feed it the 
>wrong matrix, can you?
>
>>d <- read.table(stdin())
>
>0:          0       1
>
>1: 0       311     20
>
>2: 1       119     9
>
>3:
>>d
>
>   X0 X1
>
>0 311 20
>
>1 119  9
>
>>mcnemar.test(as.matrix(d),correct=F)
>
>        McNemar's Chi-squared test
>
>data:  as.matrix(d)
>McNemar's chi-squared = 70.5108, df = 1, p-value < 2.2e-16
>
>>mcnemar.test(as.matrix(d),correct=T)
>
>        McNemar's Chi-squared test with continuity correction
>
>data:  as.matrix(d)
>McNemar's chi-squared = 69.0935, df = 1, p-value < 2.2e-16
>
>
>
>>Bob Green
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>


From p.dalgaard at biostat.ku.dk  Tue Dec 26 23:52:19 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 26 Dec 2006 23:52:19 +0100
Subject: [R] McNemar test in R & SPSS
In-Reply-To: <5.1.0.14.0.20061227080535.00d5edd8@pop3.brisnet.org.au>
References: <5.1.0.14.0.20061226080023.00ce7fe0@pop3.brisnet.org.au>	<5.1.0.14.0.20061226080023.00ce7fe0@pop3.brisnet.org.au>
	<5.1.0.14.0.20061227080535.00d5edd8@pop3.brisnet.org.au>
Message-ID: <4591A7A3.9080601@biostat.ku.dk>

Bob Green wrote:
> Peter,
>
> Thanks for your reply. To perform the analysis in R, I used the table 
> format suggested in the book by Everitt & Hothorn, whereas in SPSS the 
> analysis was performed directly from the 2 variables, rather than using 
> count data.
>   
You still need the right table.

matrix(c(128,29,331,430), ncol =2,....)

consists of the two marginal tables, which has strictly less information than the crosstabulation of pre and post values. I expect every text on the McNemar test makes this point, and I'd be highly surprised if E&H really suggested that you should use the table that you did.

> There is still something I don't understand  - I tried to replicate the 
> syntax from your e-mail but my computer just kept waiting - what am I still 
> doing wrong?
>   
You need to give it the data when it starts with the "0:"-style prompt, 
end with a blank line, as shown. It's just a device for cutting and 
pasting your table. I might as well have used

d <- matrix(c(311,119,20,9), ncol=2)

Or, with the raw data to hand

d <- table(preMHT, postMHT)


>
>   mctest <- as.table(matrix(c(128,29,331,430), ncol =2, dimnames = 
> list(group=c("preMHT","postMHT"), assault=c("yes","no"))))
>  > d <- read.table(stdin())
> 0: mcnemar.test(as.matrix(d),correct=F)
> 1:
>
> Thanks again
>
> Bob
>
>
> At 10:52 PM 26/12/2006 +0100, Peter Dalgaard wrote:
>   
>> Bob Green wrote:
>>     
>>> Hello,
>>>
>>> I am hoping someone can clarify why I might obtain a quite different 
>>> value in R & SPSS  for a McNemar test I ran.
>>>
>>> Firstly, here is the R syntax & output
>>>
>>>
>>> R OUTPUT
>>>
>>>  > mctest <- as.table(matrix(c(128,29,331,430),
>>> + ncol =2, dimnames = list(group=c("preMHT","postMHT"),
>>> + assault=c("yes","no"))))
>>>
>>>  > mctest
>>>                assault
>>> group       yes  no
>>>    preMHT  128 331
>>>    postMHT  29 430
>>>
>>>  >  mcnemar.test(mctest,correct=F)
>>>
>>>          McNemar's Chi-squared test
>>>
>>> data:  mctest
>>> McNemar's chi-squared = 253.3444, df = 1, p-value < 2.2e-16
>>>
>>>
>>> SPSS OUTPUT
>>>
>>> The same data was inputted in SPSS. Regarding the first table SPSS 
>>> generated - it lists the number of cases in each combination of 
>>> categories. The diagonal contains the number of cases with the same 
>>> response on both variables, while the off diagonal contains cases that 
>>> have different responses on the 2 variables. The overall chisquare value 
>>> is much lower than the value obtained using R, though still significant.
>>>
>>>
>>> pre02 & post02
>>>
>>> pre02   post02
>>>
>>>          0       1
>>> 0       311     20
>>> 1       119     9
>>>
>>>
>>> Test Statistics(b)
>>>
>>>   pre02 & post02
>>>
>>> N               459
>>> Chi-Square(a)   69.094
>>> Asymp. Sig.     .000
>>>
>>> a  Continuity Corrected
>>> b  McNemar Test
>>>
>>>
>>> Any assistance is much appreciated,
>>>
>>>       
>> Well, you can't expect R to give the correct result if you feed it the 
>> wrong matrix, can you?
>>
>>     
>>> d <- read.table(stdin())
>>>       
>> 0:          0       1
>>
>> 1: 0       311     20
>>
>> 2: 1       119     9
>>
>> 3:
>>     
>>> d
>>>       
>>   X0 X1
>>
>> 0 311 20
>>
>> 1 119  9
>>
>>     
>>> mcnemar.test(as.matrix(d),correct=F)
>>>       
>>        McNemar's Chi-squared test
>>
>> data:  as.matrix(d)
>> McNemar's chi-squared = 70.5108, df = 1, p-value < 2.2e-16
>>
>>     
>>> mcnemar.test(as.matrix(d),correct=T)
>>>       
>>        McNemar's Chi-squared test with continuity correction
>>
>> data:  as.matrix(d)
>> McNemar's chi-squared = 69.0935, df = 1, p-value < 2.2e-16
>>
>>
>>
>>     
>>> Bob Green
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>       
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From osman.al.radi at gmail.com  Tue Dec 26 23:56:15 2006
From: osman.al.radi at gmail.com (Osman Al-Radi)
Date: Tue, 26 Dec 2006 17:56:15 -0500
Subject: [R] xyplot line colors
Message-ID: <c9955100612261456x657213e3u855a1112c251d843@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061226/94aa8aaf/attachment.pl 

From ggrothendieck at gmail.com  Wed Dec 27 00:16:30 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 26 Dec 2006 18:16:30 -0500
Subject: [R] xyplot line colors
In-Reply-To: <c9955100612261456x657213e3u855a1112c251d843@mail.gmail.com>
References: <c9955100612261456x657213e3u855a1112c251d843@mail.gmail.com>
Message-ID: <971536df0612261516j7d33500cpc0a83d716d70484b@mail.gmail.com>

Set the colors yourself using the par.settings= argument of xyplot or
trellis.par.set.  See ?xyplot and ?trellis.par.set for more info.

If you follow the instructions on the last line of every post to r-help you
will get more detailed answers.

On 12/26/06, Osman Al-Radi <osman.al.radi at gmail.com> wrote:
> Hello,
>
> I have a longitudinal data with about 30 subjects. I used xyplot() to plot
> the longitudinal data. One problem is that xyplot() recycles the color of
> auto.key so that every 7th subject has the same color (symbol if setps() was
> used). Is there a way so that every subject will have a unique color or
> symbol?
>
> Thanks
>
> Osman
>
> --
> Osman O. Al-Radi, MD, MSc, FRCSC
> Fellow, Cardiovascular Surgery
> The Hospital for Sick Children
> University of Toronto, Canada
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dfarrar at newrvana.com  Wed Dec 27 00:53:23 2006
From: dfarrar at newrvana.com (David Farrar)
Date: Tue, 26 Dec 2006 15:53:23 -0800 (PST)
Subject: [R] Bayesian data mining
In-Reply-To: <Pine.BSO.4.63.0612251817440.31320@grex.cyberspace.org>
Message-ID: <690559.33919.qm@web803.biz.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061226/916e23d5/attachment.pl 

From aajakh at yahoo.com  Wed Dec 27 02:05:32 2006
From: aajakh at yahoo.com (ahmad ajakh)
Date: Tue, 26 Dec 2006 17:05:32 -0800 (PST)
Subject: [R] plotting time series with zoo pckg
Message-ID: <20061227010532.43180.qmail@web37914.mail.mud.yahoo.com>

Hi all,

I am using the zoo package to plot time series. I have a problem with formatting the axes.
my zoo object (z) looks like the following.

                c1      
1992-01-10     21     
1992-01-17     34     
1992-01-24     33  
1992-01-31     41     
1992-02-07     39     
1992-02-14     38     
1992-02-21     37    
1992-02-28     28     
1992-03-06     33     
1992-03-13     40  

plot.zoo(z) produces a plot with the labels on the x-axis that I cannot control.
I want a an xtick every 10 data points with corresponding date labels.
I have tried different combination of axis command without success
any idea?
Thanks


From ggrothendieck at gmail.com  Wed Dec 27 02:31:07 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 26 Dec 2006 20:31:07 -0500
Subject: [R] plotting time series with zoo pckg
In-Reply-To: <20061227010532.43180.qmail@web37914.mail.mud.yahoo.com>
References: <20061227010532.43180.qmail@web37914.mail.mud.yahoo.com>
Message-ID: <971536df0612261731x539b39feqba91907185f422b1@mail.gmail.com>

Try this:


# test data
library(zoo)
z <- structure(c(21, 34, 33, 41, 39, 38, 37, 28, 33, 40),
     index = structure(c(8044, 8051, 8058, 8065, 8072, 8079, 8086,
     8093, 8100, 8107), class = "Date"), class = "zoo")
z

# plot without X axis
plot(z, xaxt = "n")

# unlabelled tick at each point
axis(1, time(z), lab = FALSE)

# labelled tick every third point
dd <- time(z)[seq(1, length(z), 3)]
axis(1, dd, as.character(dd), cex.axis = 0.7, tcl = -0.7)



On 12/26/06, ahmad ajakh <aajakh at yahoo.com> wrote:
> Hi all,
>
> I am using the zoo package to plot time series. I have a problem with formatting the axes.
> my zoo object (z) looks like the following.
>
>                c1
> 1992-01-10     21
> 1992-01-17     34
> 1992-01-24     33
> 1992-01-31     41
> 1992-02-07     39
> 1992-02-14     38
> 1992-02-21     37
> 1992-02-28     28
> 1992-03-06     33
> 1992-03-13     40
>
> plot.zoo(z) produces a plot with the labels on the x-axis that I cannot control.
> I want a an xtick every 10 data points with corresponding date labels.
> I have tried different combination of axis command without success
> any idea?
> Thanks
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From aajakh at yahoo.com  Wed Dec 27 03:39:06 2006
From: aajakh at yahoo.com (ahmad ajakh)
Date: Tue, 26 Dec 2006 18:39:06 -0800 (PST)
Subject: [R] plotting time series with zoo pckg
Message-ID: <20061227023906.51003.qmail@web37905.mail.mud.yahoo.com>

Dear Gabor,
Thank you for your quick reply.
This solution works for my univariate zoo class time series. I first tried
it for a timeseries with 4 columns of data, it did not plot the labels nor the
ticks, I tried it on a one dim timeseries (one column zoo class data as the example 
in the question) and it worked!  is there something that I am missing?
Thanks again.
AA.


----- Original Message ----
From: Gabor Grothendieck <ggrothendieck at gmail.com>
To: ahmad ajakh <aajakh at yahoo.com>
Cc: r-help at stat.math.ethz.ch
Sent: Tuesday, December 26, 2006 8:31:07 PM
Subject: Re: [R] plotting time series with zoo pckg

Try this:


# test data
library(zoo)
z <- structure(c(21, 34, 33, 41, 39, 38, 37, 28, 33, 40),
     index = structure(c(8044, 8051, 8058, 8065, 8072, 8079, 8086,
     8093, 8100, 8107), class = "Date"), class = "zoo")
z

# plot without X axis
plot(z, xaxt = "n")

# unlabelled tick at each point
axis(1, time(z), lab = FALSE)

# labelled tick every third point
dd <- time(z)[seq(1, length(z), 3)]
axis(1, dd, as.character(dd), cex.axis = 0.7, tcl = -0.7)



On 12/26/06, ahmad ajakh <aajakh at yahoo.com> wrote:
> Hi all,
>
> I am using the zoo package to plot time series. I have a problem with formatting the axes.
> my zoo object (z) looks like the following.
>
>                c1
> 1992-01-10     21
> 1992-01-17     34
> 1992-01-24     33
> 1992-01-31     41
> 1992-02-07     39
> 1992-02-14     38
> 1992-02-21     37
> 1992-02-28     28
> 1992-03-06     33
> 1992-03-13     40
>
> plot.zoo(z) produces a plot with the labels on the x-axis that I cannot control.
> I want a an xtick every 10 data points with corresponding date labels.
> I have tried different combination of axis command without success
> any idea?
> Thanks
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From aajakh at yahoo.com  Wed Dec 27 03:45:53 2006
From: aajakh at yahoo.com (ahmad ajakh)
Date: Tue, 26 Dec 2006 18:45:53 -0800 (PST)
Subject: [R] writing to S-PLUS .dat file
Message-ID: <20061227024553.63769.qmail@web37908.mail.mud.yahoo.com>

Hi Sebastian

try
save(x,y, file = "filename.txt", ascii = TRUE)
where x, y are your R objects. You should read
?save
good luck
AA.

----- Original Message ----
From: Sebastian Michalski <s_michalski at o2.pl>
To: r-help at stat.math.ethz.ch
Sent: Monday, December 25, 2006 7:36:50 AM
Subject: [R] writing to S-PLUS .dat file

Dear Users,
I am new to R. I use write() to write my data in .txt format. I'd like 
to write to a disc any kind of data in a .dat S-PLUS format.
Please help.
SM

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jingjiangyan at gmail.com  Wed Dec 27 03:58:20 2006
From: jingjiangyan at gmail.com (jingjiangyan)
Date: Wed, 27 Dec 2006 10:58:20 +0800
Subject: [R] how to transform string to variable name in a fuction?
References: <mailman.5.1167130803.32510.r-help@stat.math.ethz.ch>
Message-ID: <200612271057593121969@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061227/eb3c5dfb/attachment.pl 

From liuwensui at gmail.com  Wed Dec 27 04:05:54 2006
From: liuwensui at gmail.com (Wensui Liu)
Date: Tue, 26 Dec 2006 22:05:54 -0500
Subject: [R] how to transform string to variable name in a fuction?
In-Reply-To: <200612271057593121969@gmail.com>
References: <mailman.5.1167130803.32510.r-help@stat.math.ethz.ch>
	<200612271057593121969@gmail.com>
Message-ID: <1115a2b00612261905t2f18f10bjff5c056e8f4df268@mail.gmail.com>

try ?assign

On 12/26/06, jingjiangyan <jingjiangyan at gmail.com> wrote:
> there is a data frame, like this:
> > df
>   aa       bb
> 1  a     20.27802
> 2  b     22.10664
> 3  c     21.33470
> 4  a     22.32898
> 5  b     19.73760
> 6  c     20.38979
> .....(suppressed)
> what I want to do is to copy the data frame's rows into different data frames according to the levels of 'aa' column,
> > df.a <- df[df[,1]=='a',] ; df.b <- df[df[,1]=='b',] ; ....
> > df.a
>   aa       bb
> 1  a 20.27802
> 4  a 22.32898
> ...
>
> So, when completed, there should be df.a, df.b,df.c, etc.
> If we could do this by hand, it is pretty fine.  But could I write a loop to do this ?
> when I tried this using a funciton, there is a problem.
>
> > for ( i in levels(df[,1])) {
> +  name = paste('df',i,sep='')
> +  name <- df[df[,1]==i,]
> + }
> > name
>   aa       bb
> 3  c 21.33470
> 6  c 20.38979
> > ls()
> [1] "df"   "i"    "name"
> > i
> [1] "c"
> there is not data frames df.a, df.b,etc.
>
> Could you please give me some suggestion?
> I have found that write a function in R for a beginner is difficult. Is there  any tutorial on writing the functions in R?
> Furthermore, someone also said that loop is not used as frequently as in other script language (e.g. bash, perl). So, If you have any other smart means do this more efficiently, please let me know, I would appreciate your kindness.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
WenSui Liu
A lousy statistician who happens to know a little programming
(http://spaces.msn.com/statcompute/blog)


From ggrothendieck at gmail.com  Wed Dec 27 05:17:44 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 26 Dec 2006 23:17:44 -0500
Subject: [R] plotting time series with zoo pckg
In-Reply-To: <20061227023906.51003.qmail@web37905.mail.mud.yahoo.com>
References: <20061227023906.51003.qmail@web37905.mail.mud.yahoo.com>
Message-ID: <971536df0612262017h65ca4e39r36365ae28d0a3ac1@mail.gmail.com>

Please read the last line of every message to r-help and follow that.

On 12/26/06, ahmad ajakh <aajakh at yahoo.com> wrote:
> Dear Gabor,
> Thank you for your quick reply.
> This solution works for my univariate zoo class time series. I first tried
> it for a timeseries with 4 columns of data, it did not plot the labels nor the
> ticks, I tried it on a one dim timeseries (one column zoo class data as the example
> in the question) and it worked!  is there something that I am missing?
> Thanks again.
> AA.
>
>
> ----- Original Message ----
> From: Gabor Grothendieck <ggrothendieck at gmail.com>
> To: ahmad ajakh <aajakh at yahoo.com>
> Cc: r-help at stat.math.ethz.ch
> Sent: Tuesday, December 26, 2006 8:31:07 PM
> Subject: Re: [R] plotting time series with zoo pckg
>
> Try this:
>
>
> # test data
> library(zoo)
> z <- structure(c(21, 34, 33, 41, 39, 38, 37, 28, 33, 40),
>     index = structure(c(8044, 8051, 8058, 8065, 8072, 8079, 8086,
>     8093, 8100, 8107), class = "Date"), class = "zoo")
> z
>
> # plot without X axis
> plot(z, xaxt = "n")
>
> # unlabelled tick at each point
> axis(1, time(z), lab = FALSE)
>
> # labelled tick every third point
> dd <- time(z)[seq(1, length(z), 3)]
> axis(1, dd, as.character(dd), cex.axis = 0.7, tcl = -0.7)
>
>
>
> On 12/26/06, ahmad ajakh <aajakh at yahoo.com> wrote:
> > Hi all,
> >
> > I am using the zoo package to plot time series. I have a problem with formatting the axes.
> > my zoo object (z) looks like the following.
> >
> >                c1
> > 1992-01-10     21
> > 1992-01-17     34
> > 1992-01-24     33
> > 1992-01-31     41
> > 1992-02-07     39
> > 1992-02-14     38
> > 1992-02-21     37
> > 1992-02-28     28
> > 1992-03-06     33
> > 1992-03-13     40
> >
> > plot.zoo(z) produces a plot with the labels on the x-axis that I cannot control.
> > I want a an xtick every 10 data points with corresponding date labels.
> > I have tried different combination of axis command without success
> > any idea?
> > Thanks
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
>
> __________________________________________________
> Do You Yahoo!?
> Tired of spam?  Yahoo! Mail has the best spam protection around
> http://mail.yahoo.com
>


From ggrothendieck at gmail.com  Wed Dec 27 05:20:32 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 26 Dec 2006 23:20:32 -0500
Subject: [R] how to transform string to variable name in a fuction?
In-Reply-To: <200612271057593121969@gmail.com>
References: <mailman.5.1167130803.32510.r-help@stat.math.ethz.ch>
	<200612271057593121969@gmail.com>
Message-ID: <971536df0612262020p576855dx50eab4719b79dab8@mail.gmail.com>

In the following the components of ss are the data frames in question:

ss <- split(df, df$aa)

On 12/26/06, jingjiangyan <jingjiangyan at gmail.com> wrote:
> there is a data frame, like this:
> > df
>  aa       bb
> 1  a     20.27802
> 2  b     22.10664
> 3  c     21.33470
> 4  a     22.32898
> 5  b     19.73760
> 6  c     20.38979
> .....(suppressed)
> what I want to do is to copy the data frame's rows into different data frames according to the levels of 'aa' column,
> > df.a <- df[df[,1]=='a',] ; df.b <- df[df[,1]=='b',] ; ....
> > df.a
>  aa       bb
> 1  a 20.27802
> 4  a 22.32898
> ...
>
> So, when completed, there should be df.a, df.b,df.c, etc.
> If we could do this by hand, it is pretty fine.  But could I write a loop to do this ?
> when I tried this using a funciton, there is a problem.
>
> > for ( i in levels(df[,1])) {
> +  name = paste('df',i,sep='')
> +  name <- df[df[,1]==i,]
> + }
> > name
>  aa       bb
> 3  c 21.33470
> 6  c 20.38979
> > ls()
> [1] "df"   "i"    "name"
> > i
> [1] "c"
> there is not data frames df.a, df.b,etc.
>
> Could you please give me some suggestion?
> I have found that write a function in R for a beginner is difficult. Is there  any tutorial on writing the functions in R?
> Furthermore, someone also said that loop is not used as frequently as in other script language (e.g. bash, perl). So, If you have any other smart means do this more efficiently, please let me know, I would appreciate your kindness.
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgreen at dyson.brisnet.org.au  Wed Dec 27 08:39:43 2006
From: bgreen at dyson.brisnet.org.au (Bob Green)
Date: Wed, 27 Dec 2006 17:39:43 +1000
Subject: [R] McNemar test in R & SPSS
In-Reply-To: <4591A7A3.9080601@biostat.ku.dk>
References: <5.1.0.14.0.20061227080535.00d5edd8@pop3.brisnet.org.au>
	<5.1.0.14.0.20061226080023.00ce7fe0@pop3.brisnet.org.au>
	<5.1.0.14.0.20061226080023.00ce7fe0@pop3.brisnet.org.au>
	<5.1.0.14.0.20061227080535.00d5edd8@pop3.brisnet.org.au>
Message-ID: <5.1.0.14.0.20061227141903.00d51670@pop3.brisnet.org.au>


>Peter,

  I now see the original E & H table was based on matched pairs not the raw 
counts. I now understand this much better and have the syntax generates 
results that correspond with your results  (and SPSS),

Thanks again,

Bob


From jdnewmil at dcn.davis.ca.us  Wed Dec 27 08:41:16 2006
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 26 Dec 2006 23:41:16 -0800
Subject: [R] Rating competitors
In-Reply-To: <4591669D.4090108@pdf.com>
References: <459161BE.6020703@dcn.davis.ca.us> <4591669D.4090108@pdf.com>
Message-ID: <4592239C.5050902@dcn.davis.ca.us>

Spencer Graves wrote:
>      Have you considered Bradley-Terry models?   RSiteSearch("bradley", 
> "functions") just returned 31 hits for me.
>      Hope this helps.      Spencer Graves

Thanks to everyone who responded... this was very helpful. I have a bit of
reading and investigation to do.

I think the Bradley-Terry model is going to be sufficient for my purposes,
if I can figure out how to model handicaps.  The eba library mentioned by
Kubovy seems more complex than what I need now, but it does look interesting
and if I can obtain a copy of the Tversky paper I will read it.  The SIS
link mentioned by Berry didn't seem to have much, but the article on
Bridging Different Eras in Sports is quite interesting.

> Jeff Newmiller wrote:
> 
>> I am looking for hints on how to estimate ratings for competitors
>> in an ongoing pairwise competition using R... my particular area of
>> interest being the game of Go, but the idea of identifying ratings
>> (on a continuous scale) rather than relative rankings seems easily
>> generalized to other competitions so I thought someone might be
>> studying something related already.
>>
>> I presume the rating of a competitor would be best modeled as a random
>> variate on the rating scale, and an encounter between two
>> competitors would be represented by a binary result.  Logistic regression
>> seems promising, but I am at a loss how to represent the model since
>> the pairings are arbitrary and not necessarily repeated often.
>>
>> I have read about some approaches to estimating ratings for Go,
>> but they seem to involve optimization using assumed distributions
>> rather than model fitting which characterizes analysis in R.
>>
>> Does any of this sound familiar? Suggestions for reading, anyone?
>>
>>   
> 
> 


-- 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From hb at stat.berkeley.edu  Wed Dec 27 09:26:06 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 27 Dec 2006 19:26:06 +1100
Subject: [R] Query regarding linking R with Matlab
In-Reply-To: <20061227060728.90241.qmail@web34307.mail.mud.yahoo.com>
References: <59d7961d0612200300o547b95dfw94220e251a2603a5@mail.gmail.com>
	<20061227060728.90241.qmail@web34307.mail.mud.yahoo.com>
Message-ID: <59d7961d0612270026t792e5678l49427282997db034@mail.gmail.com>

Hi,

It might be that R can't find Matlab; then you have to specify option
'matlab', see help(Matlab).  Try also a different port. Try to add a
line setVerbose(matlab, -2) to get more detailed output what is going
on;

matlab <- Matlab(host="localhost", port=9998)
setVerbose(matlab, -2)
if (!open(matlab))
  throw("Matlab server is not running: waited 30 seconds.")

If you can't get it to work, send the output of the above.

/Henrik

On 12/27/06, Bhanu Kalyan.K <kalyansikha at yahoo.com> wrote:
> Respected Sir,
>
> I thank you for your concern. I have worked with the code that you have
> provided. But it has generated errors like:
>
> > if (!open(matlab))
> +   throw("Matlab server is not running: waited 30 seconds.")
>  //This command is not responding even after 30 seconds.
>
> > res <- evaluate(matlab, "swissroll")
> Error in writeBin(con = con, as.integer(b), size = 1) :
>         invalid connection
>
> > vars <- getVariable(matlab, c("Y", "X", "K", "d"))
> Error in writeBin(con = con, as.integer(b), size = 1) :
>         invalid connection
> Kindly help me with this.
>
> Regards
> Bhanu Kalyan K
>
>
> Bhanu Kalyan K
> BTech CSE Final Year
> reach4kalyan at gmail.com
> Tel :+91-9885238228
>
>  __________________________________________________
> Do You Yahoo!?
> Tired of spam? Yahoo! Mail has the best spam protection around
> http://mail.yahoo.com


From hb at stat.berkeley.edu  Wed Dec 27 09:26:06 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 27 Dec 2006 19:26:06 +1100
Subject: [R] Query regarding linking R with Matlab
In-Reply-To: <20061227060728.90241.qmail@web34307.mail.mud.yahoo.com>
References: <59d7961d0612200300o547b95dfw94220e251a2603a5@mail.gmail.com>
	<20061227060728.90241.qmail@web34307.mail.mud.yahoo.com>
Message-ID: <59d7961d0612270026t792e5678l49427282997db034@mail.gmail.com>

Hi,

It might be that R can't find Matlab; then you have to specify option
'matlab', see help(Matlab).  Try also a different port. Try to add a
line setVerbose(matlab, -2) to get more detailed output what is going
on;

matlab <- Matlab(host="localhost", port=9998)
setVerbose(matlab, -2)
if (!open(matlab))
  throw("Matlab server is not running: waited 30 seconds.")

If you can't get it to work, send the output of the above.

/Henrik

On 12/27/06, Bhanu Kalyan.K <kalyansikha at yahoo.com> wrote:
> Respected Sir,
>
> I thank you for your concern. I have worked with the code that you have
> provided. But it has generated errors like:
>
> > if (!open(matlab))
> +   throw("Matlab server is not running: waited 30 seconds.")
>  //This command is not responding even after 30 seconds.
>
> > res <- evaluate(matlab, "swissroll")
> Error in writeBin(con = con, as.integer(b), size = 1) :
>         invalid connection
>
> > vars <- getVariable(matlab, c("Y", "X", "K", "d"))
> Error in writeBin(con = con, as.integer(b), size = 1) :
>         invalid connection
> Kindly help me with this.
>
> Regards
> Bhanu Kalyan K
>
>
> Bhanu Kalyan K
> BTech CSE Final Year
> reach4kalyan at gmail.com
> Tel :+91-9885238228
>
>  __________________________________________________
> Do You Yahoo!?
> Tired of spam? Yahoo! Mail has the best spam protection around
> http://mail.yahoo.com


From nicolas.mazziotta at swing.be  Wed Dec 27 11:00:12 2006
From: nicolas.mazziotta at swing.be (Nicolas Mazziotta)
Date: Wed, 27 Dec 2006 11:00:12 +0100
Subject: [R] fitting all models in log-lm
Message-ID: <200612271100.12302.nicolas.mazziotta@swing.be>

Hello,

I am trying to use R to carry out loglinear analysis. So far, starting from a 
previous post in this list 
(http://finzi.psych.upenn.edu/R/Rhelp02a/archive/33698.html), I have been 
able to use loglm() to generate likelihood ratio.

I now try to find a function that generates all the models and another one to 
compare them.

Thanks for any help.

-- 
Nicolas Mazziotta

The contents of this e-mail, including any attachments, are ...{{dropped}}


From Abhijit.Dasgupta at mail.jci.tju.edu  Wed Dec 27 11:11:46 2006
From: Abhijit.Dasgupta at mail.jci.tju.edu (Abhijit Dasgupta)
Date: Wed, 27 Dec 2006 05:11:46 -0500
Subject: [R] how to transform string to variable name in a fuction?
In-Reply-To: <200612271057593121969@gmail.com>
References: <mailman.5.1167130803.32510.r-help@stat.math.ethz.ch>
	<200612271057593121969@gmail.com>
Message-ID: <459246E2.3090105@mail.jci.tju.edu>

I believe the "split" function should work in this case.
 From the help file:

split(x, f, drop = FALSE, ...)
split(x, f, drop = FALSE, ...) <- value
unsplit(value, f, drop = FALSE)


      Arguments

|x| 	vector or data frame containing values to be divided into groups.
|f| 	a ?factor? in the sense that |as.factor <factor.html>(f)| defines 
the grouping, or a list of such factors in which case their interaction 
is used for the grouping.
|drop| 	logical indicating if levels that do not occur should be dropped 
(if |f| is a |factor| or a list).
|value| 	a list of vectors or data frames compatible with a splitting of 
|x|. Recycling applies if the lengths do not match.
|...| 	further potential arguments passed to methods.



Abhijit Dasgupta, Ph.D.

Assistant Professor | Division of Biostatistics
Department of Pharmacology and Experimental Therapeutics | Thomas 
Jefferson University
1015 Chestnut St | Suite M100 | Philadelphia, PA 19107
Ph: (215) 503-9201 | Fax: (215) 503-3804

jingjiangyan wrote:
> there is a data frame, like this:
>   
>> df
>>     
>   aa       bb
> 1  a     20.27802
> 2  b     22.10664
> 3  c     21.33470
> 4  a     22.32898
> 5  b     19.73760
> 6  c     20.38979
> .....(suppressed)
> what I want to do is to copy the data frame's rows into different data frames according to the levels of 'aa' column, 
>   
>> df.a <- df[df[,1]=='a',] ; df.b <- df[df[,1]=='b',] ; ....
>> df.a
>>     
>   aa       bb
> 1  a 20.27802
> 4  a 22.32898
> ...
>
> So, when completed, there should be df.a, df.b,df.c, etc. 
> If we could do this by hand, it is pretty fine.  But could I write a loop to do this ?
> when I tried this using a funciton, there is a problem.
>
>   
>> for ( i in levels(df[,1])) {
>>     
> +  name = paste('df',i,sep='')
> +  name <- df[df[,1]==i,]
> + }
>   
>> name
>>     
>   aa       bb
> 3  c 21.33470
> 6  c 20.38979
>   
>> ls()
>>     
> [1] "df"   "i"    "name"
>   
>> i
>>     
> [1] "c"
> there is not data frames df.a, df.b,etc.
>
> Could you please give me some suggestion?
> I have found that write a function in R for a beginner is difficult. Is there  any tutorial on writing the functions in R? 
> Furthermore, someone also said that loop is not used as frequently as in other script language (e.g. bash, perl). So, If you have any other smart means do this more efficiently, please let me know, I would appreciate your kindness.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Knut-krueger at einthal.de  Wed Dec 27 11:22:11 2006
From: Knut-krueger at einthal.de (Knut Krueger)
Date: Wed, 27 Dec 2006 11:22:11 +0100
Subject: [R] axis and times() problem
Message-ID: <45924953.9070100@einthal.de>

Dear R-Group,
the first example is working as expected, but I need the plot without 
the box,
normally no problem, but I am not able to get the x-axis formatted as 
times with the axis, command.
I tried a lot of things, nothing was working so I used the most easy 
axis command in the second example here ....
 
# working
  library(chron) # for times()
  library(graphics)# for axis
    par(cex=1.2,lwd=1)
  x <- c(times("12:15:00"),times("15:30:00"))
    y <- c(1,5)
    plot(x, y, type="n",adj=0, asp=0, xlab="", ylab="",font.axis=2,yaxt='n')

# axis() command problem:
    par(cex=1.2,lwd=1)
  x <- c(times("12:15:00"),times("15:30:00"))
    y <- c(1,5)
    plot(x, y,axes=FALSE, type="n",adj=0, asp=0, xlab="", 
ylab="",font.axis=2,yaxt='n')
  axis(1)


Maybe anybody could help me to disable the box around the plot and get 
the x-axis formatted as times

Regards Knut


From Tord.Snall at nvb.slu.se  Wed Dec 27 12:12:04 2006
From: Tord.Snall at nvb.slu.se (=?ISO-8859-1?Q?Tord_Sn=E4ll?=)
Date: Wed, 27 Dec 2006 12:12:04 +0100
Subject: [R] counties in different colours using map()
Message-ID: <45925504.2060401@nvb.slu.se>

Hi,
I would like to plot a map of US counties using different colors. map() 
seems to be the function to use, e.g.
library(maps); map('usa'); map('county', 'colorado', add=T,fill = T, 
col=c(1:5))
plots Colorado counties using colours 1 to 5.

However, I want each color to represent a certain value - a value to be 
picked from a data frame.
This code should show a correspoding map at the level of states:
state.names <- system('tr "[A-Z]" "[a-z]"', state.name)
map.states <- unix('sed "s/:.*//"', map(names=T,plot=F))
state.to.map <- match(map.states, state.names)
color<- votes.repub[state.to.map, votes.year = 1900] / 100
map('state', fill=T, col=color); map('state', add=T)
It is copied from page 6 in
Richard A. Becker, and Allan R. Wilks, "Maps in S", AT&T Bell 
Laboratories Statistics Research Report [93.2], 1993.
http://public.research.att.com/areas/stat/doc/93.2.ps

I also wonder whether the county names are available in the database 
used by map(), and, if yes, how to extract or utilize them.

Thanks!

Tord

-- 

Tord Sn?ll
Department of Conservation Biology
Swedish University of Agricultural Sciences (SLU)
P.O. 7002, SE-750 07 Uppsala, Sweden
Office/Mobile/Fax
+46-18-672612/+46-730-891356/+46-18-673537
E-mail: tord.snall at nvb.slu.se
www.nvb.slu.se/staff_tordsnall


From ggrothendieck at gmail.com  Wed Dec 27 13:32:58 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 27 Dec 2006 07:32:58 -0500
Subject: [R] axis and times() problem
In-Reply-To: <45924953.9070100@einthal.de>
References: <45924953.9070100@einthal.de>
Message-ID: <971536df0612270432q6da9143cu8c0a611508ba39e7@mail.gmail.com>

Try:

plot(x, y, bty = "n", xaxs = "i", yaxs = "i")

Actually I think there may be a bug here since the axes do not intersect.

On 12/27/06, Knut Krueger <Knut-krueger at einthal.de> wrote:
> Dear R-Group,
> the first example is working as expected, but I need the plot without
> the box,
> normally no problem, but I am not able to get the x-axis formatted as
> times with the axis, command.
> I tried a lot of things, nothing was working so I used the most easy
> axis command in the second example here ....
>
> # working
>  library(chron) # for times()
>  library(graphics)# for axis
>    par(cex=1.2,lwd=1)
>  x <- c(times("12:15:00"),times("15:30:00"))
>    y <- c(1,5)
>    plot(x, y, type="n",adj=0, asp=0, xlab="", ylab="",font.axis=2,yaxt='n')
>
> # axis() command problem:
>    par(cex=1.2,lwd=1)
>  x <- c(times("12:15:00"),times("15:30:00"))
>    y <- c(1,5)
>    plot(x, y,axes=FALSE, type="n",adj=0, asp=0, xlab="",
> ylab="",font.axis=2,yaxt='n')
>  axis(1)
>
>
> Maybe anybody could help me to disable the box around the plot and get
> the x-axis formatted as times
>
> Regards Knut
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Wed Dec 27 13:57:24 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 27 Dec 2006 12:57:24 +0000 (GMT)
Subject: [R] slightly inconsistent behavior
In-Reply-To: <50d1c22d0612261053g6ef4ecd2vf480574b28531941@mail.gmail.com>
References: <50d1c22d0612261053g6ef4ecd2vf480574b28531941@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0612271247290.2046@gannet.stats.ox.ac.uk>

What do you think is `slightly inconsistent behavior' here?  (You seem to 
be quite consistent in not telling us such relevant facts, including your 
OS and version of R!)

If you think that the memory usage of R should be monotone in the size of 
the problem, your expectations are unfounded.  Here it is likely you are 
seeing memory fragmentation on a 32-bit OS: see help("Memory-limits").

But setting nrows=99999999 and 'extend nrows by a few more 9's' seems to 
me suggesting something like nrows=9999999999 which is invalid and gives
a warning message you did not mention.

On Tue, 26 Dec 2006, ivo welch wrote:

> dear R experts:
>
> This is just a minor, minor nuisance, but I thought I would point it out:
>
>> dataset <- read.table(file=pipe(cmdline), header =T,
> +                   na.strings=c("NaN", "C","I","M", "E"), sep=",",
> as.is=T, nrows=99999999);
> Error: cannot allocate vector of size 781249 Kb
>
> If I extend nrows by a few more 9's, the error goes away.  Similarly,
> if I use much fewer observations, the error goes away.
>
> regards,
>
> /iaw
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

PLEASE do, at long last.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Wed Dec 27 14:57:46 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 27 Dec 2006 14:57:46 +0100
Subject: [R] building R-package under windows - error - in
 options("deafultPackages") was not found
In-Reply-To: <f13f1c9c0612250144m2616d866r64873272d18084e3@mail.gmail.com>
References: <f13f1c9c0612221238q652cf3d4t8b30a5f1922ea53a@mail.gmail.com>	
	<458D1064.8040704@statistik.uni-dortmund.de>	
	<Pine.LNX.4.64.0612231143300.7744@auk.stats>
	<f13f1c9c0612250144m2616d866r64873272d18084e3@mail.gmail.com>
Message-ID: <45927BDA.9020904@statistik.uni-dortmund.de>

Given the lines after "Description:" have been wrapped during e-mail 
transfer and are in one line in your DESCRIPTION file, here are two guesses:
- You have some additional library added that contains a broken 
installation of some base package?
- You have declared some non-existing default packages in some Rprofile 
or whereever that are not existing?

Anyway, you might want to send the whole package in a private message.

Uwe Ligges



Daniel Berg wrote:
> I have tried to uninstall R-2.4.1 and reinstall it but I still get the same
> error message. I have also tried reinstalling both mingw and perl, both 
> with
> no effect.
> 
> My DESCRIPTION file:
> 
> Package: copulaGOF
> Type: Package
> Title: Copula simulation, estimation and goodness-of-fit
> Version: 1.5
> Date: 2006-12-15
> Author: Daniel Berg, Henrik Bakken (Norwegian Computing Center)
> Depends: adapt, copula, fBasics, mnormt, mvtnorm, scatterplot3d, sn
> Maintainer: Daniel Berg <daniel at danielberg.no>
> URL: www.danielberg.no
> Description: Functions for copula simulation, estimation and 
> goodness-of-fit
> testing. Includes functions for simulating and estimating higher 
> dimensional
> distributions.
> License: GPL Version 2 or later, GSL-1.6
> 
> and the error message read:
> $ Rcmd build --binary copulaGOF
> * checking for file 'copulaGOF/DESCRIPTION' ... OK
> * preparing 'copulaGOF' :
> * checking DESCRIPTION meta-information ... ERROR
> During startup - Warning messages:
> '  in: library(package, lib.loc = lib.loc, character.only = TRUE, logical =
> TRUE,
> in options("defaultPackages") was not found
> 
> I don't have access to binaries of older versions of R now but will try 
> with
> older version after the holidays to see if this has an effect.
> 
> Regards,
> Daniel
> 
> On 12/23/06, Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>>
>> On Sat, 23 Dec 2006, Uwe Ligges wrote:
>>
>> >
>> >
>> > Daniel Berg wrote:
>> >> Dear all,
>> >>
>> >> I have been building R packages under windows on my old pc,
>> successfully.
>> >> Now I have bought a new pc, still running windows, and I am trying to
>> build
>> >> the same R packages as before, but now without the same success. I 
>> have
>> >> installed the Rtools, perl, mingw and added them to the environment
>> >> variables.
>> >> I am running Windows XP Professional on a Thinkpad T60. I have
>> installed
>> >> R-2.4.1, ActivePerl 5.8.8 Build 819, MinGW 5.1.2, and I downloaded
>> >> tools.zipfrom
>> >> http://www.murdoch-sutherland.com/Rtools.
>> >>
>> >> I receive the following error message:
>> >>
>> >> $ Rcmd build --binary copulaGOF/
>> >> * checking for file 'mypackage/DESCRIPTION' ... OK
>> >> * preparing 'copulaGOF' :
>> >> * checking DESCRIPTION meta-information ... ERROR
>> >
>> > Looks like something is wrong with your DESCRIPTION file. Can you send
>> > us the contents of that file?
>>
>> I think rather with his R: the message below says 'During startup', and
>> indicates that one of the default packages is missing.  That would mean
>> that it has not got to running the code to look at DESCRIPTION.
>>
>> >
>> > Uwe Ligges
>> >
>> >
>> >> During startup - Warning messages :
>> >> ' in: library(package, lib.loc = lob.loc, character.only = TRUE,
>> logical =
>> >> TRUE,
>> >>  in options("defaultPackages") was not found
>> >>
>> >> In my package I have included a zzz.r file that contains the 
>> following,
>> >> perhaps this is the cause?
>> >> .First.lib <-function (lib, pkg)   {
>> >>     library(adapt)
>> >>     library(copula)
>> >>     library(fBasics)
>> >>     library(mvtnorm)
>> >>     runif(1)
>> >>     library.dynam("mypackage", package="mypackage")
>> >> }
>> >>
>> >> Any help or comments is most welcome. Thank you.
>> >>
>> >> Best wishes,
>> >> Daniel Berg
>> >> -----
>> >> danielberg.no
>> >>
>> >>      [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at stat.math.ethz.ch mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> <http://www.stats.ox.ac.uk/%7Eripley/>
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
> 
> 
>


From bbands at gmail.com  Wed Dec 27 17:36:00 2006
From: bbands at gmail.com (BBands)
Date: Wed, 27 Dec 2006 08:36:00 -0800
Subject: [R] stacked plots
Message-ID: <6e8360ad0612270836i77074067y2a9cdc431892f5f8@mail.gmail.com>

Dear helpeRs,

Is there a better method of producing stacked charts than
par(mfrow(3,1)), plot(x), plot(y), plot(z)? What I would like to do is
produce a chart of several panes stacked vertically with no space
between them so they appeared to be a single figure. I've attached a
small example, though it is not clear that it will make it, as the
posting guide doesn't say which sort of images are allowed--it is a
gif. My data will be in zoo objects like those from get.hist.quote()
with the data for the extra panes in additional columns.

Thanks in advance,

    jab
-- 
John Bollinger, CFA, CMT
www.BollingerBands.com

If you advance far enough, you arrive at the beginning.

From aajakh at yahoo.com  Wed Dec 27 17:36:24 2006
From: aajakh at yahoo.com (ahmad ajakh)
Date: Wed, 27 Dec 2006 08:36:24 -0800 (PST)
Subject: [R] plotting time series with zoo pckg
Message-ID: <20061227163624.9434.qmail@web37914.mail.mud.yahoo.com>

Dear Gabor,
sorry for not posting the code. below I have a piece of code that generates
a multivariate zoo data (3 columns) and graphs it using the axis
commands to generate the labels. This does not work. However, if one
extracts one column the labelling works using the same commands!
I cannot figure out what I am missing here.
Thanks for any suggestion.
AA.
I am using R version 2.4.0 (windows XP) and zoo package version 1.2-1(2006-09-20).


#-----Begin------------------------------------------
# Let's take the previous example to create a simple zoo data.
 z <- structure(c(21,34,33,41,39,38,37,28,33,40),
                index = structure(c(8044,8051,8058,8065,8072,
                8079,8086,8093,8100,8107), class="Date"), class = "zoo")

# generating 3 random vectors with the same length as z.
jx1 <- rnorm(10); jx2 <- rnorm(10); jx3 <- rnorm(10)
# create a zoo class data using the random vectors.
jx  <- cbind(jx1,jx2,jx3)
z1  <- zoo(jx, index(z))
# now we just repete the previous example.
plot(z1, xaxt = "n")
axis(1, time(z1), lab = FALSE)
jd <- time(z1)[seq(1, dim(z1)[[1]], 3)]
axis(1,jd, as.character(jd),cex.axis = 0.8, tcl = -0.7, las = 2)
# now we extract one column of z1 and graph it with the same axis commands.
z2 <- z1[,1, drop = F]
windows()
plot(z2, xaxt = "n")
axis(1, time(z2), lab = FALSE)
jd <- time(z2)[seq(1, dim(z2)[[1]], 3)]
axis(1,jd, as.character(jd),cex.axis = 0.8, tcl = -0.7, las = 2)
#-------------------End-----------------------------------

----- Original Message ----
From: Gabor Grothendieck <ggrothendieck at gmail.com>
To: ahmad ajakh <aajakh at yahoo.com>
Cc: r-help at stat.math.ethz.ch
Sent: Tuesday, December 26, 2006 11:17:44 PM
Subject: Re: [R] plotting time series with zoo pckg

Please read the last line of every message to r-help and follow that.

On 12/26/06, ahmad ajakh <aajakh at yahoo.com> wrote:
> Dear Gabor,
> Thank you for your quick reply.
> This solution works for my univariate zoo class time series. I first tried
> it for a timeseries with 4 columns of data, it did not plot the labels nor the
> ticks, I tried it on a one dim timeseries (one column zoo class data as the example
> in the question) and it worked!  is there something that I am missing?
> Thanks again.
> AA.
>
>
> ----- Original Message ----
> From: Gabor Grothendieck <ggrothendieck at gmail.com>
> To: ahmad ajakh <aajakh at yahoo.com>
> Cc: r-help at stat.math.ethz.ch
> Sent: Tuesday, December 26, 2006 8:31:07 PM
> Subject: Re: [R] plotting time series with zoo pckg
>
> Try this:
>
>
> # test data
> library(zoo)
> z <- structure(c(21, 34, 33, 41, 39, 38, 37, 28, 33, 40),
>     index = structure(c(8044, 8051, 8058, 8065, 8072, 8079, 8086,
>     8093, 8100, 8107), class = "Date"), class = "zoo")
> z
>
> # plot without X axis
> plot(z, xaxt = "n")
>
> # unlabelled tick at each point
> axis(1, time(z), lab = FALSE)
>
> # labelled tick every third point
> dd <- time(z)[seq(1, length(z), 3)]
> axis(1, dd, as.character(dd), cex.axis = 0.7, tcl = -0.7)
>
>
>
> On 12/26/06, ahmad ajakh <aajakh at yahoo.com> wrote:
> > Hi all,
> >
> > I am using the zoo package to plot time series. I have a problem with formatting the axes.
> > my zoo object (z) looks like the following.
> >
> >                c1
> > 1992-01-10     21
> > 1992-01-17     34
> > 1992-01-24     33
> > 1992-01-31     41
> > 1992-02-07     39
> > 1992-02-14     38
> > 1992-02-21     37
> > 1992-02-28     28
> > 1992-03-06     33
> > 1992-03-13     40
> >
> > plot.zoo(z) produces a plot with the labels on the x-axis that I cannot control.
> > I want a an xtick every 10 data points with corresponding date labels.
> > I have tried different combination of axis command without success
> > any idea?
> > Thanks
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
>
> __________________________________________________
> Do You Yahoo!?

> http://mail.yahoo.com
>


From jacinthe at gmx.de  Wed Dec 27 17:42:06 2006
From: jacinthe at gmx.de (jacinthe at gmx.de)
Date: Wed, 27 Dec 2006 17:42:06 +0100
Subject: [R] how to suppress a "loading required package: ..." message
Message-ID: <20061227164206.222130@gmx.net>

Hi,

how to suppress a "loading required package:... " message?

Kind regards

Jaci
--


From bbands at gmail.com  Wed Dec 27 17:52:19 2006
From: bbands at gmail.com (BBands)
Date: Wed, 27 Dec 2006 08:52:19 -0800
Subject: [R] how to suppress a "loading required package: ..." message
In-Reply-To: <20061227164206.222130@gmx.net>
References: <20061227164206.222130@gmx.net>
Message-ID: <6e8360ad0612270852o66150620k3d4d5f3bc1d848e4@mail.gmail.com>

On 12/27/06, jacinthe at gmx.de <jacinthe at gmx.de> wrote:
> Hi,
>
> how to suppress a "loading required package:... " message?

require(package, quiet=TRUE)

     jab
-- 
John Bollinger, CFA, CMT
www.BollingerBands.com

If you advance far enough, you arrive at the beginning.


From Greg.Snow at intermountainmail.org  Wed Dec 27 18:03:35 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 27 Dec 2006 10:03:35 -0700
Subject: [R] Formatting an arry to typeset as a table
Message-ID: <07E228A5BE53C24CAD490193A7381BBB12A0ED@LP-EXCHVS07.CO.IHC.COM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061227/cffbd05b/attachment.pl 

From ggrothendieck at gmail.com  Wed Dec 27 18:08:41 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 27 Dec 2006 12:08:41 -0500
Subject: [R] plotting time series with zoo pckg
In-Reply-To: <20061227163624.9434.qmail@web37914.mail.mud.yahoo.com>
References: <20061227163624.9434.qmail@web37914.mail.mud.yahoo.com>
Message-ID: <971536df0612270908u1c83a64aq2950b67499bb8c99@mail.gmail.com>

To do it with plot.zoo one has to create a custom panel.

Another approach is to use xyplot.zoo since that supports custom scales
directly.   Note that the ?xyplot.zoo examples contain code that is along the
lines of the xyplot.zoo solution.

Here are examples of both approaches:

library(zoo)
# test data
z <- structure(c(21,34,33,41,39,38,37,28,33,40),
                index = structure(c(8044,8051,8058,8065,8072,
                8079,8086,8093,8100,8107), class="Date"), class = "zoo")
set.seed(1) # needed to make it reproducible
jx1 <- rnorm(10); jx2 <- rnorm(10); jx3 <- rnorm(10)
# create a zoo class data using the random vectors.
jx  <- cbind(jx1,jx2,jx3)
z1  <- zoo(jx, index(z))


# 1. plot.zoo solution using custom panel function, my.panel
my.panel <- function(...) {
   lines(...)
   if (parent.frame()$j == ncol(z1)) {
      # following line only if non-labelled ticks wanted for each point
      axis(1, at = time(z1), lab = FALSE)
      ix <- seq(1, length(z1), 3)
      labs <- format(time(z1)[ix], "%b-%d")
      axis(1, at = time(z1)[ix], lab = labs, tcl = -0.7, cex.axis = 0.7)
   }
}
plot(z1, panel = my.panel, xaxt = "n")

# 2. xyplot.zoo solution
# z1 is from above

library(lattice)
ix <- seq(1, length(z1), 3)
labs <- format(time(z1)[ix], "%b-%d")
xyplot(z1, scales = list(x = list(at = time(z1)[ix], labels = labs)))

# only need following if non-labelled ticks are to be added for each point
trellis.focus("panel", 1, 1, clip.off = TRUE)
panel.axis("bottom", check.overlap = TRUE, outside = TRUE, labels = FALSE,
   tck = .7, at = time(z1))
trellis.unfocus()


On 12/27/06, ahmad ajakh <aajakh at yahoo.com> wrote:
> Dear Gabor,
> sorry for not posting the code. below I have a piece of code that generates
> a multivariate zoo data (3 columns) and graphs it using the axis
> commands to generate the labels. This does not work. However, if one
> extracts one column the labelling works using the same commands!
> I cannot figure out what I am missing here.
> Thanks for any suggestion.
> AA.
> I am using R version 2.4.0 (windows XP) and zoo package version 1.2-1(2006-09-20).
>
>
> #-----Begin------------------------------------------
> # Let's take the previous example to create a simple zoo data.
>  z <- structure(c(21,34,33,41,39,38,37,28,33,40),
>                index = structure(c(8044,8051,8058,8065,8072,
>                8079,8086,8093,8100,8107), class="Date"), class = "zoo")
>
> # generating 3 random vectors with the same length as z.
> jx1 <- rnorm(10); jx2 <- rnorm(10); jx3 <- rnorm(10)
> # create a zoo class data using the random vectors.
> jx  <- cbind(jx1,jx2,jx3)
> z1  <- zoo(jx, index(z))
> # now we just repete the previous example.
> plot(z1, xaxt = "n")
> axis(1, time(z1), lab = FALSE)
> jd <- time(z1)[seq(1, dim(z1)[[1]], 3)]
> axis(1,jd, as.character(jd),cex.axis = 0.8, tcl = -0.7, las = 2)
> # now we extract one column of z1 and graph it with the same axis commands.
> z2 <- z1[,1, drop = F]
> windows()
> plot(z2, xaxt = "n")
> axis(1, time(z2), lab = FALSE)
> jd <- time(z2)[seq(1, dim(z2)[[1]], 3)]
> axis(1,jd, as.character(jd),cex.axis = 0.8, tcl = -0.7, las = 2)
> #-------------------End-----------------------------------
>
> ----- Original Message ----
> From: Gabor Grothendieck <ggrothendieck at gmail.com>
> To: ahmad ajakh <aajakh at yahoo.com>
> Cc: r-help at stat.math.ethz.ch
> Sent: Tuesday, December 26, 2006 11:17:44 PM
> Subject: Re: [R] plotting time series with zoo pckg
>
> Please read the last line of every message to r-help and follow that.
>
> On 12/26/06, ahmad ajakh <aajakh at yahoo.com> wrote:
> > Dear Gabor,
> > Thank you for your quick reply.
> > This solution works for my univariate zoo class time series. I first tried
> > it for a timeseries with 4 columns of data, it did not plot the labels nor the
> > ticks, I tried it on a one dim timeseries (one column zoo class data as the example
> > in the question) and it worked!  is there something that I am missing?
> > Thanks again.
> > AA.
> >
> >
> > ----- Original Message ----
> > From: Gabor Grothendieck <ggrothendieck at gmail.com>
> > To: ahmad ajakh <aajakh at yahoo.com>
> > Cc: r-help at stat.math.ethz.ch
> > Sent: Tuesday, December 26, 2006 8:31:07 PM
> > Subject: Re: [R] plotting time series with zoo pckg
> >
> > Try this:
> >
> >
> > # test data
> > library(zoo)
> > z <- structure(c(21, 34, 33, 41, 39, 38, 37, 28, 33, 40),
> >     index = structure(c(8044, 8051, 8058, 8065, 8072, 8079, 8086,
> >     8093, 8100, 8107), class = "Date"), class = "zoo")
> > z
> >
> > # plot without X axis
> > plot(z, xaxt = "n")
> >
> > # unlabelled tick at each point
> > axis(1, time(z), lab = FALSE)
> >
> > # labelled tick every third point
> > dd <- time(z)[seq(1, length(z), 3)]
> > axis(1, dd, as.character(dd), cex.axis = 0.7, tcl = -0.7)
> >
> >
> >
> > On 12/26/06, ahmad ajakh <aajakh at yahoo.com> wrote:
> > > Hi all,
> > >
> > > I am using the zoo package to plot time series. I have a problem with formatting the axes.
> > > my zoo object (z) looks like the following.
> > >
> > >                c1
> > > 1992-01-10     21
> > > 1992-01-17     34
> > > 1992-01-24     33
> > > 1992-01-31     41
> > > 1992-02-07     39
> > > 1992-02-14     38
> > > 1992-02-21     37
> > > 1992-02-28     28
> > > 1992-03-06     33
> > > 1992-03-13     40
> > >
> > > plot.zoo(z) produces a plot with the labels on the x-axis that I cannot control.
> > > I want a an xtick every 10 data points with corresponding date labels.
> > > I have tried different combination of axis command without success
> > > any idea?
> > > Thanks
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >
> >
> >
> > __________________________________________________
> > Do You Yahoo!?
> > Tired of spam?  Yahoo! Mail has the best spam protection around
> > http://mail.yahoo.com
> >
>
>
>
>
> __________________________________________________
> Do You Yahoo!?
> Tired of spam?  Yahoo! Mail has the best spam protection around
> http://mail.yahoo.com
>


From ggrothendieck at gmail.com  Wed Dec 27 18:10:08 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 27 Dec 2006 12:10:08 -0500
Subject: [R] stacked plots
In-Reply-To: <6e8360ad0612270836i77074067y2a9cdc431892f5f8@mail.gmail.com>
References: <6e8360ad0612270836i77074067y2a9cdc431892f5f8@mail.gmail.com>
Message-ID: <971536df0612270910l7bad409bi930833780e07df2@mail.gmail.com>

If this is time series data try

library(zoo)
example(plot.zoo)
example(xyplot.zoo)

to see if any of those fit your requirements.

On 12/27/06, BBands <bbands at gmail.com> wrote:
> Dear helpeRs,
>
> Is there a better method of producing stacked charts than
> par(mfrow(3,1)), plot(x), plot(y), plot(z)? What I would like to do is
> produce a chart of several panes stacked vertically with no space
> between them so they appeared to be a single figure. I've attached a
> small example, though it is not clear that it will make it, as the
> posting guide doesn't say which sort of images are allowed--it is a
> gif. My data will be in zoo objects like those from get.hist.quote()
> with the data for the extra panes in additional columns.
>
> Thanks in advance,
>
>    jab
> --
> John Bollinger, CFA, CMT
> www.BollingerBands.com
>
> If you advance far enough, you arrive at the beginning.
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From edd at debian.org  Wed Dec 27 18:37:36 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 27 Dec 2006 11:37:36 -0600
Subject: [R] stacked plots
In-Reply-To: <6e8360ad0612270836i77074067y2a9cdc431892f5f8@mail.gmail.com>
References: <6e8360ad0612270836i77074067y2a9cdc431892f5f8@mail.gmail.com>
Message-ID: <17810.44896.774844.284754@basebud.nulle.part>


John,

On 27 December 2006 at 08:36, BBands wrote:
| Dear helpeRs,
| 
| Is there a better method of producing stacked charts than
| par(mfrow(3,1)), plot(x), plot(y), plot(z)? What I would like to do is
| produce a chart of several panes stacked vertically with no space
| between them so they appeared to be a single figure. I've attached a
| small example, though it is not clear that it will make it, as the
| posting guide doesn't say which sort of images are allowed--it is a
| gif. My data will be in zoo objects like those from get.hist.quote()
| with the data for the extra panes in additional columns.

Do you remember the bollingerBands example we worked on a few years ago and
that is still at Romain's incredible R Graph Gallery at
      http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=65

It uses layout, you can also use the simpler par(mfrow=...) approach *if* you
also reduce bottom and top spacing accordingly as e.g. in the plot functions
in the script referenced above.

Cheers, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From edd at debian.org  Wed Dec 27 18:39:52 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 27 Dec 2006 11:39:52 -0600
Subject: [R] how to suppress a "loading required package: ..." message
In-Reply-To: <6e8360ad0612270852o66150620k3d4d5f3bc1d848e4@mail.gmail.com>
References: <20061227164206.222130@gmx.net>
	<6e8360ad0612270852o66150620k3d4d5f3bc1d848e4@mail.gmail.com>
Message-ID: <17810.45032.805061.648736@basebud.nulle.part>


On 27 December 2006 at 08:52, BBands wrote:
| On 12/27/06, jacinthe at gmx.de <jacinthe at gmx.de> wrote:
| > Hi,
| >
| > how to suppress a "loading required package:... " message?
| 
| require(package, quiet=TRUE)

Some packages insist on talking even when they are asked to be quiet, in
which case I have also resorted to wrapping sink() around the loading:

	> sink("/dev/null")
	> library(Hmisc)
	> sink()
	> cat("Hi again\n")
	Hi again
	> 

Hth, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From bbands at gmail.com  Wed Dec 27 18:55:36 2006
From: bbands at gmail.com (BBands)
Date: Wed, 27 Dec 2006 09:55:36 -0800
Subject: [R] stacked plots
In-Reply-To: <17810.44896.774844.284754@basebud.nulle.part>
References: <6e8360ad0612270836i77074067y2a9cdc431892f5f8@mail.gmail.com>
	<17810.44896.774844.284754@basebud.nulle.part>
Message-ID: <6e8360ad0612270955m6156f49u7e2c1307e7979c92@mail.gmail.com>

On 12/27/06, Dirk Eddelbuettel <edd at debian.org> wrote:
> Do you remember the bollingerBands example we worked on a few years ago and
> that is still at Romain's incredible R Graph Gallery at
>       http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=65
>
> It uses layout, you can also use the simpler par(mfrow=...) approach *if* you
> also reduce bottom and top spacing accordingly as e.g. in the plot functions
> in the script referenced above.

I do indeed remember that, it was a nice piece of work that I learned
a lot from. At the time you mentioned there were some newer methods in
the works that might serve better, which prompted my question after an
appropriate delay. ;-)

    jab
-- 
John Bollinger, CFA, CMT
www.BollingerBands.com

If you advance far enough, you arrive at the beginning.


From mihainica at yahoo.com  Wed Dec 27 18:56:12 2006
From: mihainica at yahoo.com (Mihai Nica)
Date: Wed, 27 Dec 2006 09:56:12 -0800 (PST)
Subject: [R] counties in different colours using map()
Message-ID: <20061227175612.12051.qmail@web50802.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061227/b326d659/attachment.pl 

From ggrothendieck at gmail.com  Wed Dec 27 19:21:23 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 27 Dec 2006 13:21:23 -0500
Subject: [R] how to suppress a "loading required package: ..." message
In-Reply-To: <17810.45032.805061.648736@basebud.nulle.part>
References: <20061227164206.222130@gmx.net>
	<6e8360ad0612270852o66150620k3d4d5f3bc1d848e4@mail.gmail.com>
	<17810.45032.805061.648736@basebud.nulle.part>
Message-ID: <971536df0612271021v1c1327b1i69e86ebf557b5a36@mail.gmail.com>

Or try:

   invisible(capture.output(library(Hmisc)))




On 12/27/06, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 27 December 2006 at 08:52, BBands wrote:
> | On 12/27/06, jacinthe at gmx.de <jacinthe at gmx.de> wrote:
> | > Hi,
> | >
> | > how to suppress a "loading required package:... " message?
> |
> | require(package, quiet=TRUE)
>
> Some packages insist on talking even when they are asked to be quiet, in
> which case I have also resorted to wrapping sink() around the loading:
>
>        > sink("/dev/null")
>        > library(Hmisc)
>        > sink()
>        > cat("Hi again\n")
>        Hi again
>        >
>
> Hth, Dirk
>
> --
> Hell, there are no rules here - we're trying to accomplish something.
>                                                  -- Thomas A. Edison
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From f.harrell at vanderbilt.edu  Wed Dec 27 19:30:43 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Wed, 27 Dec 2006 12:30:43 -0600
Subject: [R] how to suppress a "loading required package: ..." message
In-Reply-To: <17810.45032.805061.648736@basebud.nulle.part>
References: <20061227164206.222130@gmx.net>	<6e8360ad0612270852o66150620k3d4d5f3bc1d848e4@mail.gmail.com>
	<17810.45032.805061.648736@basebud.nulle.part>
Message-ID: <4592BBD3.9050109@vanderbilt.edu>

Dirk Eddelbuettel wrote:
> On 27 December 2006 at 08:52, BBands wrote:
> | On 12/27/06, jacinthe at gmx.de <jacinthe at gmx.de> wrote:
> | > Hi,
> | >
> | > how to suppress a "loading required package:... " message?
> | 
> | require(package, quiet=TRUE)
> 
> Some packages insist on talking even when they are asked to be quiet, in
> which case I have also resorted to wrapping sink() around the loading:
> 
> 	> sink("/dev/null")
> 	> library(Hmisc)

For that one, do options(Hverbose=FALSE) before library(Hmisc)

Frank

> 	> sink()
> 	> cat("Hi again\n")
> 	Hi again
> 	> 
> 
> Hth, Dirk
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From aajakh at yahoo.com  Wed Dec 27 19:29:44 2006
From: aajakh at yahoo.com (ahmad ajakh)
Date: Wed, 27 Dec 2006 10:29:44 -0800 (PST)
Subject: [R] stacked plots
Message-ID: <20061227182944.43713.qmail@web37914.mail.mud.yahoo.com>

Hi John,

I cannot see the attached file but if you read the vignette of the zoo package
there is an example with Lucent stock price (High Low Open Close) doing what you want.
the command plot(z) (z being the zoo multivariate object) produces the graph that
you want I guess. Also there are some posts today on how to label them.
good luck
AA.

----- Original Message ----
From: BBands <bbands at gmail.com>
To: R-Help <r-help at stat.math.ethz.ch>
Sent: Wednesday, December 27, 2006 11:36:00 AM
Subject: [R] stacked plots

Dear helpeRs,

Is there a better method of producing stacked charts than
par(mfrow(3,1)), plot(x), plot(y), plot(z)? What I would like to do is
produce a chart of several panes stacked vertically with no space
between them so they appeared to be a single figure. I've attached a
small example, though it is not clear that it will make it, as the
posting guide doesn't say which sort of images are allowed--it is a
gif. My data will be in zoo objects like those from get.hist.quote()
with the data for the extra panes in additional columns.

Thanks in advance,

    jab
-- 
John Bollinger, CFA, CMT
www.BollingerBands.com

If you advance far enough, you arrive at the beginning.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From taojurongbe at yahoo.com  Wed Dec 27 12:14:53 2006
From: taojurongbe at yahoo.com (Taiwo Ojurongbe)
Date: Wed, 27 Dec 2006 03:14:53 -0800 (PST)
Subject: [R] Consensus Fork Index
Message-ID: <20061227111453.96950.qmail@web60417.mail.yahoo.com>

Dear All,

I am trying to automate series of dendrograms for
binary data in R as well as calculate the Consensus
Fork Index (Colless' index). I'll appreciate any
assistance with regards to this.

Thank you and best regards,

Taiwo


From hustqiufeng at sohu.com  Wed Dec 27 17:49:08 2006
From: hustqiufeng at sohu.com (Feng Qiu)
Date: Wed, 27 Dec 2006 11:49:08 -0500
Subject: [R]  How to debug R program?
Message-ID: <008d01c729d6$f84fada0$bfcc4dc7@Aglog>



> Hi everyone:
>       I wrote a R program which has loops. When I run the program, it 
> crashed. I would like to identify in which loop the pragram crashed, how 
> can I debug ?  I'm new to R, could somebody please give me a general idea 
> about debugging in R.(I'm a C/C++ programmer and have general knowledge 
> about program debugging.)
>      Thank you!
>
> Best,
>
> Feng
>


From DrJones at alum.MIT.edu  Wed Dec 27 19:43:39 2006
From: DrJones at alum.MIT.edu (Thomas L Jones)
Date: Wed, 27 Dec 2006 13:43:39 -0500
Subject: [R] Question about predict function
Message-ID: <000301c729e6$f1bd4b40$2f01a8c0@DrJones>

I am working with a non-parametic smoothing operation using a 
Generalized Additive Model. It is a bivariate data set. I know how to 
do the smooth, and out comes a nice smooth curve.

Now I want to find the value of the smoothed curve for several values 
of x (the abscissa). This can be done (please correct me if I am 
wrong) by using the predict.gam function. You feed the predict.gam 
function a data frame, telling it what you want.

Let's start with the predict.gam function. Are you supposed to be able 
to look up how to use it? E.g., what goes into the various columns of 
the data frame? I do have a working function call for predict. It 
says:

pred_out <- predict (mod, data.frame (x = x), type = "response")

(mod is the model)

Now, if you tell me that x = x, I will believe you. But what is meant 
by "data.frame (x = x)", I know not.

Or would it better to call the class, names, and str functions, using 
some well chosen objects?

Tom Jones


From fqiu at gatech.edu  Wed Dec 27 04:37:35 2006
From: fqiu at gatech.edu (Feng Qiu)
Date: Tue, 26 Dec 2006 22:37:35 -0500
Subject: [R]  How to write string dynamicly?
References: <153111.79503.qm@web56613.mail.re3.yahoo.com>
Message-ID: <005101c7296a$212df280$bfcc4dc7@Aglog>

Hi everyone:
         I'm trying to compose a string dynamicly for the parameter input of 
some function. For example:
In package MASS, function lda() require to input the name of predictor 
variable. Let's say the 16th column is the predictor variable. Then we call 
the function like this: lda(V16~., data=mydata). I don't want to hard-code 
the call, instead, I would like to use a dynamic expression for this 
parameter so that I can use my program on different set of data.
        I guess there are some function that can do this, but I didn't find 
it in "Introduction to R" so far, could someone please tell me this kind of 
function? Thank you!

Best,

Feng


From izmirlian at nih.gov  Wed Dec 27 16:44:54 2006
From: izmirlian at nih.gov (Grant Izmirlian)
Date: Wed, 27 Dec 2006 10:44:54 -0500
Subject: [R] R-help Digest, Vol 46, Issue 27
In-Reply-To: <mailman.4.1167217203.4732.r-help@stat.math.ethz.ch>
References: <mailman.4.1167217203.4732.r-help@stat.math.ethz.ch>
Message-ID: <200612271044.54298.izmirlian@nih.gov>

On Wednesday 27 December 2006 06:00, r-help-request at stat.math.ethz.ch wrote:
> jingjiangyan

I agree, you can use 'assign'. To be more explicit, you could use the 
following function. 

jingjiangyan <- 
function(formula, data)
{
  m <- match.call()
  "%,%" <- function(x,y)paste(x,y,sep="")
  d.nm <- as.character(m$data)
  y.nm <- as.character(formula[[2]])
  x.nm <- as.character(formula[[3]])
  for(i in levels(data[[x.nm]])){
    var.name <- d.nm %,% "." %,% i
    var.val <- data[[y.nm]][data[[x.nm]]==i]
    cmd <- var.name %,% " <- " %,% var.val
    eval(cmd)
    assign(var.name, var.val, globalenv())
  }
}

Next, assuming the data.frame listed in the previous posting, 'df' 
exists in your workspace, the call 

  jingjiangyan(bb ~ aa, data=df)

would produce the desired results.

Cheers,
Grant Izmirlian
-- 
????? ?????????


From wayne.hallstrom at yahoo.ca  Wed Dec 27 02:30:50 2006
From: wayne.hallstrom at yahoo.ca (wayne hallstrom)
Date: Tue, 26 Dec 2006 20:30:50 -0500 (EST)
Subject: [R] model comparison + use of offset in glmmPQL
Message-ID: <20061227013050.72602.qmail@web59012.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061226/6fdafdcf/attachment.pl 

From ggrothendieck at gmail.com  Wed Dec 27 19:56:26 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 27 Dec 2006 13:56:26 -0500
Subject: [R] How to write string dynamicly?
In-Reply-To: <005101c7296a$212df280$bfcc4dc7@Aglog>
References: <153111.79503.qm@web56613.mail.re3.yahoo.com>
	<005101c7296a$212df280$bfcc4dc7@Aglog>
Message-ID: <971536df0612271056t21ef6053ncf81702e3318f2fa@mail.gmail.com>

Try:

lda(iris[-5], iris[,5])

On 12/26/06, Feng Qiu <fqiu at gatech.edu> wrote:
> Hi everyone:
>         I'm trying to compose a string dynamicly for the parameter input of
> some function. For example:
> In package MASS, function lda() require to input the name of predictor
> variable. Let's say the 16th column is the predictor variable. Then we call
> the function like this: lda(V16~., data=mydata). I don't want to hard-code
> the call, instead, I would like to use a dynamic expression for this
> parameter so that I can use my program on different set of data.
>        I guess there,- are some function that can do this, but I didn't find
> it in "Introduction to R" so far, could someone please tell me this kind of
> function? Thank you!
>
> Best,
>
> Feng
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From maechler at stat.math.ethz.ch  Wed Dec 27 20:02:44 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 27 Dec 2006 20:02:44 +0100
Subject: [R] vectorizing an iterative process.
In-Reply-To: <99F81FFD0EA54E4DA8D4F1BFE272F34102E907ED@ppi-mail1.chicago.peak6.net>
References: <99F81FFD0EA54E4DA8D4F1BFE272F34102E907ED@ppi-mail1.chicago.peak6.net>
Message-ID: <17810.50004.787228.662177@stat.math.ethz.ch>

>>>>> "Geoffrey" == Geoffrey Zhu <gzhu at peak6.com>
>>>>>     on Tue, 26 Dec 2006 10:05:55 -0600 writes:

    Geoffrey> I meant  x[i] <- x[i-1] + y[i-1] and Y[i] <- y[i-1] + x[i] below.
    Geoffrey> The mailing list software just keep adding 3D's. Sorry. 

It's not the mailing list software - not per se at least.
Rather it's your own e-mail software's behavior (maybe in
conjunction with our (i.e. r-help's) mail server software configuration)
If I write
   x[i] = x[i-i]
then I'm pretty sure you won't get an extra "3D" when you'll
read it.

Regards
Martin Maechler
ETH Zurich (where the R-help list is running from)


From aajakh at yahoo.com  Wed Dec 27 20:08:01 2006
From: aajakh at yahoo.com (ahmad ajakh)
Date: Wed, 27 Dec 2006 11:08:01 -0800 (PST)
Subject: [R] plotting time series with zoo pckg
Message-ID: <20061227190801.42602.qmail@web37905.mail.mud.yahoo.com>

Thank you Gabor. This is very helpful.
AA.

----- Original Message ----
From: Gabor Grothendieck <ggrothendieck at gmail.com>
To: ahmad ajakh <aajakh at yahoo.com>
Cc: r-help at stat.math.ethz.ch
Sent: Wednesday, December 27, 2006 12:08:41 PM
Subject: Re: [R] plotting time series with zoo pckg

To do it with plot.zoo one has to create a custom panel.

Another approach is to use xyplot.zoo since that supports custom scales
directly.   Note that the ?xyplot.zoo examples contain code that is along the
lines of the xyplot.zoo solution.

Here are examples of both approaches:

library(zoo)
# test data
z <- structure(c(21,34,33,41,39,38,37,28,33,40),
                index = structure(c(8044,8051,8058,8065,8072,
                8079,8086,8093,8100,8107), class="Date"), class = "zoo")
set.seed(1) # needed to make it reproducible
jx1 <- rnorm(10); jx2 <- rnorm(10); jx3 <- rnorm(10)
# create a zoo class data using the random vectors.
jx  <- cbind(jx1,jx2,jx3)
z1  <- zoo(jx, index(z))


# 1. plot.zoo solution using custom panel function, my.panel
my.panel <- function(...) {
   lines(...)
   if (parent.frame()$j == ncol(z1)) {
      # following line only if non-labelled ticks wanted for each point
      axis(1, at = time(z1), lab = FALSE)
      ix <- seq(1, length(z1), 3)
      labs <- format(time(z1)[ix], "%b-%d")
      axis(1, at = time(z1)[ix], lab = labs, tcl = -0.7, cex.axis = 0.7)
   }
}
plot(z1, panel = my.panel, xaxt = "n")

# 2. xyplot.zoo solution
# z1 is from above

library(lattice)
ix <- seq(1, length(z1), 3)
labs <- format(time(z1)[ix], "%b-%d")
xyplot(z1, scales = list(x = list(at = time(z1)[ix], labels = labs)))

# only need following if non-labelled ticks are to be added for each point
trellis.focus("panel", 1, 1, clip.off = TRUE)
panel.axis("bottom", check.overlap = TRUE, outside = TRUE, labels = FALSE,
   tck = .7, at = time(z1))
trellis.unfocus()


On 12/27/06, ahmad ajakh <aajakh at yahoo.com> wrote:
> Dear Gabor,
> sorry for not posting the code. below I have a piece of code that generates
> a multivariate zoo data (3 columns) and graphs it using the axis
> commands to generate the labels. This does not work. However, if one
> extracts one column the labelling works using the same commands!
> I cannot figure out what I am missing here.
> Thanks for any suggestion.
> AA.
> I am using R version 2.4.0 (windows XP) and zoo package version 1.2-1(2006-09-20).
>
>
> #-----Begin------------------------------------------
> # Let's take the previous example to create a simple zoo data.
>  z <- structure(c(21,34,33,41,39,38,37,28,33,40),
>                index = structure(c(8044,8051,8058,8065,8072,
>                8079,8086,8093,8100,8107), class="Date"), class = "zoo")
>
> # generating 3 random vectors with the same length as z.
> jx1 <- rnorm(10); jx2 <- rnorm(10); jx3 <- rnorm(10)
> # create a zoo class data using the random vectors.
> jx  <- cbind(jx1,jx2,jx3)
> z1  <- zoo(jx, index(z))
> # now we just repete the previous example.
> plot(z1, xaxt = "n")
> axis(1, time(z1), lab = FALSE)
> jd <- time(z1)[seq(1, dim(z1)[[1]], 3)]
> axis(1,jd, as.character(jd),cex.axis = 0.8, tcl = -0.7, las = 2)
> # now we extract one column of z1 and graph it with the same axis commands.
> z2 <- z1[,1, drop = F]
> windows()
> plot(z2, xaxt = "n")
> axis(1, time(z2), lab = FALSE)
> jd <- time(z2)[seq(1, dim(z2)[[1]], 3)]
> axis(1,jd, as.character(jd),cex.axis = 0.8, tcl = -0.7, las = 2)
> #-------------------End-----------------------------------
>
> ----- Original Message ----
> From: Gabor Grothendieck <ggrothendieck at gmail.com>
> To: ahmad ajakh <aajakh at yahoo.com>
> Cc: r-help at stat.math.ethz.ch
> Sent: Tuesday, December 26, 2006 11:17:44 PM
> Subject: Re: [R] plotting time series with zoo pckg
>
> Please read the last line of every message to r-help and follow that.
>
> On 12/26/06, ahmad ajakh <aajakh at yahoo.com> wrote:
> > Dear Gabor,
> > Thank you for your quick reply.
> > This solution works for my univariate zoo class time series. I first tried
> > it for a timeseries with 4 columns of data, it did not plot the labels nor the
> > ticks, I tried it on a one dim timeseries (one column zoo class data as the example
> > in the question) and it worked!  is there something that I am missing?
> > Thanks again.
> > AA.
> >
> >
> > ----- Original Message ----
> > From: Gabor Grothendieck <ggrothendieck at gmail.com>
> > To: ahmad ajakh <aajakh at yahoo.com>
> > Cc: r-help at stat.math.ethz.ch
> > Sent: Tuesday, December 26, 2006 8:31:07 PM
> > Subject: Re: [R] plotting time series with zoo pckg
> >
> > Try this:
> >
> >
> > # test data
> > library(zoo)
> > z <- structure(c(21, 34, 33, 41, 39, 38, 37, 28, 33, 40),
> >     index = structure(c(8044, 8051, 8058, 8065, 8072, 8079, 8086,
> >     8093, 8100, 8107), class = "Date"), class = "zoo")
> > z
> >
> > # plot without X axis
> > plot(z, xaxt = "n")
> >
> > # unlabelled tick at each point
> > axis(1, time(z), lab = FALSE)
> >
> > # labelled tick every third point
> > dd <- time(z)[seq(1, length(z), 3)]
> > axis(1, dd, as.character(dd), cex.axis = 0.7, tcl = -0.7)
> >
> >
> >
> > On 12/26/06, ahmad ajakh <aajakh at yahoo.com> wrote:
> > > Hi all,
> > >
> > > I am using the zoo package to plot time series. I have a problem with formatting the axes.
> > > my zoo object (z) looks like the following.
> > >
> > >                c1
> > > 1992-01-10     21
> > > 1992-01-17     34
> > > 1992-01-24     33
> > > 1992-01-31     41
> > > 1992-02-07     39
> > > 1992-02-14     38
> > > 1992-02-21     37
> > > 1992-02-28     28
> > > 1992-03-06     33
> > > 1992-03-13     40
> > >
> > > plot.zoo(z) produces a plot with the labels on the x-axis that I cannot control.
> > > I want a an xtick every 10 data points with corresponding date labels.
> > > I have tried different combination of axis command without success
> > > any idea?
> > > Thanks
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >
> >
> >
> > __________________________________________________
> > Do You Yahoo!?

> > http://mail.yahoo.com
> >
>
>
>
>
> __________________________________________________
> Do You Yahoo!?

> http://mail.yahoo.com
>


From ccleland at optonline.net  Wed Dec 27 20:37:31 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 27 Dec 2006 14:37:31 -0500
Subject: [R] Question about predict function
In-Reply-To: <000301c729e6$f1bd4b40$2f01a8c0@DrJones>
References: <000301c729e6$f1bd4b40$2f01a8c0@DrJones>
Message-ID: <4592CB7B.5050200@optonline.net>

Thomas L Jones wrote:
> I am working with a non-parametic smoothing operation using a 
> Generalized Additive Model. It is a bivariate data set. I know how to 
> do the smooth, and out comes a nice smooth curve.
> 
> Now I want to find the value of the smoothed curve for several values 
> of x (the abscissa). This can be done (please correct me if I am 
> wrong) by using the predict.gam function. You feed the predict.gam 
> function a data frame, telling it what you want.
> 
> Let's start with the predict.gam function. Are you supposed to be able 
> to look up how to use it? E.g., what goes into the various columns of 
> the data frame? I do have a working function call for predict. It 
> says:
> 
> pred_out <- predict (mod, data.frame (x = x), type = "response")
> 
> (mod is the model)
> 
> Now, if you tell me that x = x, I will believe you. But what is meant 
> by "data.frame (x = x)", I know not.
> 
> Or would it better to call the class, names, and str functions, using 
> some well chosen objects?

  Does this help?

library(gam)
data(kyphosis)

kyphosis.gam <- gam(Kyphosis ~ s(Age,4) + Number, family = binomial,
data=kyphosis)

predict(kyphosis.gam, data.frame(Age = c(10,100,200), Number = 3),
type="response")

          1           2           3
0.019098701 0.248043366 0.005807921

  The data frame should contain the predictor variables in the model and
the values for the variables should be those at which you want a prediction.

> Tom Jones
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From efg at stowers-institute.org  Wed Dec 27 21:33:07 2006
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Wed, 27 Dec 2006 14:33:07 -0600
Subject: [R] counties in different colours using map()
References: <45925504.2060401@nvb.slu.se>
Message-ID: <emula5$pta$1@sea.gmane.org>

The following example shows how to get/display the county names:

library(maps)

# Get County Data
m <- map('county', 'colorado', plot=FALSE)
names(m)
m$names   # State,County names

# The names appear to be in alphabetical order by state, e.g.:
> m$names[1:3]
[1] "colorado,adams"    "colorado,alamosa"  "colorado,arapahoe"

# Show county names on map
map.text('county', 'colorado', proj='bonne', param=45)

# Show county indices on map
map.text('county', 'colorado', proj='bonne', param=45, 
labels=paste(1:length(m$names)))

#or perhaps
map.text('county', 'colorado', proj='bonne', param=45, 
labels=paste(1:length(m$names)), col=1:length(m$names))


You can use your own labels vector above to show county abbreviations 
instead of full names, or other info, if desired.

Once you get the mapping of the counties, you can connect to other sources 
of information.

efg

"Tord Sn?ll" <Tord.Snall at nvb.slu.se> wrote in message 
news:45925504.2060401 at nvb.slu.se...
Hi,
I would like to plot a map of US counties using different colors. map()
seems to be the function to use, e.g.
library(maps); map('usa'); map('county', 'colorado', add=T,fill = T,
col=c(1:5))
plots Colorado counties using colours 1 to 5.

However, I want each color to represent a certain value - a value to be
picked from a data frame.
This code should show a correspoding map at the level of states:
state.names <- system('tr "[A-Z]" "[a-z]"', state.name)
map.states <- unix('sed "s/:.*//"', map(names=T,plot=F))
state.to.map <- match(map.states, state.names)
color<- votes.repub[state.to.map, votes.year = 1900] / 100
map('state', fill=T, col=color); map('state', add=T)
It is copied from page 6 in
Richard A. Becker, and Allan R. Wilks, "Maps in S", AT&T Bell
Laboratories Statistics Research Report [93.2], 1993.
http://public.research.att.com/areas/stat/doc/93.2.ps

I also wonder whether the county names are available in the database
used by map(), and, if yes, how to extract or utilize them.

Thanks!

Tord


From fjbuch at gmail.com  Wed Dec 27 22:16:05 2006
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Wed, 27 Dec 2006 16:16:05 -0500
Subject: [R] Google Desktop Search and R script files
Message-ID: <bd93cdad0612271316x496bc381pba4a0402e6730e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061227/f0cf79db/attachment.pl 

From br44114 at gmail.com  Wed Dec 27 22:32:30 2006
From: br44114 at gmail.com (bogdan romocea)
Date: Wed, 27 Dec 2006 16:32:30 -0500
Subject: [R] Google Desktop Search and R script files
Message-ID: <8d5a36350612271332k16caf58andf14f4830cff3262@mail.gmail.com>

If you're on Windows switch to
http://www.copernic.com/en/products/desktop-search/index.html ,
last time I looked it was quite a lot better than Google Desktop Search.


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Farrel
> Buchinsky
> Sent: Wednesday, December 27, 2006 4:16 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Google Desktop Search and R script files
>
> I want to be able to search my saved R script files on my hard drive.
> Thankfully the files are all saved with the .R filename
> extension which
> means that "filetype:R" in the Google Desktop Search (GDS)
> box limits the
> search to those files. Unfortunately if I put any other term
> in the search
> box (for example, "hist" to find scripts where I have created
> a histogram)
> then GDS does not find it. It only seems to index based on
> the filename and
> not on the contents of the file. So for instance, if I had a
> file called
> HistAnalysis.R then the search "filetype:R hist" would find it.
>
> Google web based search is working correctly (As somebody pointed out
> previously). I am only having the problem with GDS. Has
> anyone succeeded
> with what I am attempting to do.
>
> --
> Farrel Buchinsky
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rmh at temple.edu  Wed Dec 27 22:43:35 2006
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 27 Dec 2006 16:43:35 -0500 (EST)
Subject: [R] Google Desktop Search and R script files
Message-ID: <20061227164335.BQU22948@po-d.temple.edu>

Go to the gooogle desktop preferences page and install
Larry's Any Text File Indexer 1.00 by Larry Gadea (Index any file extension specified as plaintext)

then tell it to search the .R and other extensions as plaintext.
Google will then index all indicated files on your harddisk and will
find them very fast.


From sledepi at operamail.com  Wed Dec 27 22:49:57 2006
From: sledepi at operamail.com (sloan jones)
Date: Wed, 27 Dec 2006 22:49:57 +0100
Subject: [R] Help with histograms
Message-ID: <20061227214958.046A443E0D@ws5-1.us4.outblaze.com>


I would like to make one histogram combining two value vectors. One vector has more than 50 entries and the other only has 16. Both vectors contain dates in the POSIXct format. I need to be able to highlight the 16 entries from the smaller data set. 

Is it possible to do this with the hist function? Which function should I use?

Sloan

-- 
_______________________________________________
Surf the Web in a faster, safer and easier way:
Download Opera 9 at http://www.opera.com


From fjbuch at gmail.com  Wed Dec 27 23:47:45 2006
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Wed, 27 Dec 2006 17:47:45 -0500
Subject: [R] Google Desktop Search and R script files
References: <20061227164335.BQU22948@po-d.temple.edu>
Message-ID: <emut6e$eov$1@sea.gmane.org>

Wonderful. I did it and it works perfectly. Thanks a lot.

"Richard M. Heiberger" <rmh at temple.edu> wrote in message 
news:20061227164335.BQU22948 at po-d.temple.edu...
> Go to the gooogle desktop preferences page and install
> Larry's Any Text File Indexer 1.00 by Larry Gadea (Index any file 
> extension specified as plaintext)
>
> then tell it to search the .R and other extensions as plaintext.
> Google will then index all indicated files on your harddisk and will
> find them very fast.

-- 
Farrel Buchinsky, MD
Pediatric Otolaryngologist
Allegheny General Hospital
Pittsburgh, PA


From fjbuch at gmail.com  Wed Dec 27 23:54:12 2006
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Wed, 27 Dec 2006 17:54:12 -0500
Subject: [R] Google Desktop Search and R script files
References: <8d5a36350612271332k16caf58andf14f4830cff3262@mail.gmail.com>
Message-ID: <emutik$fpf$1@sea.gmane.org>

Thank you for your advice. I have read quite a bit about Copernic Desktop 
Search. Nevertheless, I chose not to download yet another indexing program. 
I am very happy with Google Desktop Search and particularly how well it 
integrates with many other features. Therefore, when I saw the reply to my 
original posting that allowed me to simply download a GDS add-on, I decided 
to go with that.


"bogdan romocea" <br44114 at gmail.com> wrote in message 
news:8d5a36350612271332k16caf58andf14f4830cff3262 at mail.gmail.com...
> If you're on Windows switch to
> http://www.copernic.com/en/products/desktop-search/index.html ,
> last time I looked it was quite a lot better than Google Desktop Search.


From Greg.Snow at intermountainmail.org  Thu Dec 28 00:44:36 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 27 Dec 2006 16:44:36 -0700
Subject: [R] Help with histograms
References: <20061227214958.046A443E0D@ws5-1.us4.outblaze.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBB12A0F0@LP-EXCHVS07.CO.IHC.COM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061227/4f0075a1/attachment.pl 

From greenboy21 at gmail.com  Thu Dec 28 01:14:35 2006
From: greenboy21 at gmail.com (Xu Yuan)
Date: Wed, 27 Dec 2006 19:14:35 -0500
Subject: [R] how to test difference in my case?
Message-ID: <e00347d90612271614k44b1e2dbif233b5f7d4882b8d@mail.gmail.com>

hello all,

I wonder if anyone could give me a hint on which statistical technique
I should use and how to carry it out in R in my case. Thanks in
advance.

My data is composed of two columns, the same numerical variable
(continuous) from actual measurement and model prediction. My
objective is to compare the data agreement (if there is significant
difference) and make conclusions about the model efficiency. Since the
measured and predicted variable was based on the same unit, the first
test came into my mind was paired t-test. However, the paired
difference is not normal (p-value = 0.0048 from SAS proc univariate).
In this case, I can either do a wilcoxon signed-rank test or do
transformations about the data. I was told that wilcoxon signed-rank
test is not as widely recognized as paired t-test in the literature,
so I prefer to do transformation. My question is: do I need to do
transformations on both columns of original data, or just the paired
difference? What transformation is appropriate? I thought about log
transformation, but if I find significant (or no significant)
difference between the logged data (measured and predicted), can I say
there is significant (or no significant) difference between the
original data?


After this step of analysis, I will convert the continuous numerical
data into qualitative categorical ranking (value=1, 2, 3 and 4). Which
statistical test and R command should I use to compare the ranking
agreement between the actual measurement and prediction?

Thank you very much for helping me out. I haven't slept since a long
time ago and this is kind of emergency. If there is any confusion
about my description, please let me know.

Regards,
XY


From hb at stat.berkeley.edu  Thu Dec 28 03:16:41 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Thu, 28 Dec 2006 13:16:41 +1100
Subject: [R] Query regarding linking R with Matlab
In-Reply-To: <429242.18235.qm@web34302.mail.mud.yahoo.com>
References: <59d7961d0612270026t792e5678l49427282997db034@mail.gmail.com>
	<429242.18235.qm@web34302.mail.mud.yahoo.com>
Message-ID: <59d7961d0612271816o1e46599end6f8eb9226e46532@mail.gmail.com>

Hi.

>From what you tell me you manage to start Matlab in the background by calling:

  Matlab$startServer()

but that R fails to connect to Matlab by:

  matlab <- Matlab(host="localhost", port=9998)
  if (!open(matlab))
    throw("Matlab server is not running: waited 30 seconds.")

Sorry for not being explicit enough; if no port is given,
Matlab$startServer() will setup up Matlab to listen to port 9999 (as
explained in the help), but then you try to communicate with it via
port 9998.  I realize that the example might be a bit confusing since
it is using port 9998 (for the purpose of illustrating the fact that
you can choose another port).

Either try the above with   Matlab$startServer(port=9998), *or*, maybe simpler:

  Matlab$startServer()
  matlab <- Matlab(host="localhost")
  if (!open(matlab))
    throw("Matlab server is not running: waited 30 seconds.")

Does this work for you?

Henrik

On 12/27/06, Bhanu Kalyan.K <kalyansikha at yahoo.com> wrote:
>
> > library("R.matlab")
> Loading required package: R.oo
> R.oo v1.2.3 (2006-09-07) successfully loaded. See ?R.oo for help.
> R.matlab v1.1.2 (2006-05-08) successfully loaded. See ?R.matlab for help.
>
> > help(Matlab)
>
> > Matlab$startServer()Loading required package: R.utils
> R.utils v0.8.0 (2006-08-21) successfully loaded. See ?R.utils for help.
> [1] 0
> // Here a Matlab window opened but that window couldnot be maximized.
>
> > matlab <- Matlab(host="localhost", port=9998)
>
> > matlab
> [1] "Matlab: The Matlab host is 'localhost' and communication goes via port
> 9998. Objects are passed via the local file system (remote=FALSE). The
> connection to the Matlab server is closed (not opened)."
>
> > setVerbose(matlab, -2)
>
> > open(matlab)
> Opens a blocked connection to host 'localhost' (port 9998)...
>  Try #0.
>  Try #1.
>  Try #2.
>  Try #3.
>  Try #4.
>  Try #5.
>  Try #6.
>  Try #7.
>  Try #8.
>  Try #9.
>  Try #10.
>  Try #11.
>  Try #12.
>
> There were 12 warnings (use warnings() to see them)
> Opens a blocked connection to host 'localhost' (port 9998)...done
>
> > if (!open(matlab))
> +   throw("Matlab server is not running: waited 30 seconds.")
> Opens a blocked connection to host 'localhost' (port 9998)...
>  Try #0.
>  Try #1.
> // I 'stopped' the computation here
> Warning message:
> localhost:9998 cannot be opened Opens a blocked connection to host
> 'localhost' (port 9998)...done
>
> This is the output obtained after running the commands. Kindly go through
> the above commands and help me identify the problem.
>
> Regards,
> Bhanu Kalyan K
>
>
> Bhanu Kalyan K
> BTech CSE Final Year
> reach4kalyan at gmail.com
> Tel :+91-9885238228
>
>  __________________________________________________
> Do You Yahoo!?
> Tired of spam? Yahoo! Mail has the best spam protection around
> http://mail.yahoo.com


From hb at stat.berkeley.edu  Thu Dec 28 03:19:33 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Thu, 28 Dec 2006 13:19:33 +1100
Subject: [R] R.matlab question
In-Reply-To: <59d7961d0612200245o42ceaaf2ka0c69f34d91aa6f0@mail.gmail.com>
References: <6.1.2.0.2.20061219204859.01c24408@aiminy.mail.iastate.edu>
	<59d7961d0612200245o42ceaaf2ka0c69f34d91aa6f0@mail.gmail.com>
Message-ID: <59d7961d0612271819x36989602kde9747b836c9cf05@mail.gmail.com>

Hi,

a follow up after realizing that you might not have started the Matlab
application to listen on port 9998.  Try:

Matlab$startServer(port=9998)

and then

matlab <- Matlab(host="localhost", port=9998)
if (!open(matlab)) throw("Matlab server is not running: waited 30 seconds.")

Does this help?

Henrik

On 12/20/06, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
> Hi.
>
> On 12/20/06, Aimin Yan <aiminy at iastate.edu> wrote:
> > Does anyone know how to solve this question about R.matlab?
> > I am in windowsXP, my matlab is matlab 7.0.0 19920(R14)
> >
> > thanks,
> >
> > Aimin
> >
> >  > matlab <- Matlab(host="localhost", port=9998)
> >  > if (!open(matlab)) throw("Matlab server is not running: waited 30 seconds.")
> > Error in list("throw("Matlab server is not running: waited 30 seconds.")" =
> > <environment>,  :
> >
> > [2006-12-17 22:26:03] Exception: Matlab server is not running: waited 30
> > seconds.
> >    at throw(Exception(...))
> >    at throw.default("Matlab server is not running: waited 30 seconds.")
> >    at throw("Matlab server is not running: waited 30 seconds.")
> > In addition: There were 30 warnings (use warnings() to see them)
> >  > warnings
> > function (...)
> > UseMethod("warnings")
> >  > warnings()
> > Warning messages:
> > 1: localhost:9998 cannot be opened
> > 2: localhost:9998 cannot be opened
> [snip]
> > 30: localhost:9998 cannot be opened
>
> This could be because your firewall is blocking R from connecting
> to Matlab.  Try a few different port numbers.  I recently learned that
> the current default port in R.matlab might not be the best one;
> different port intervals are reserved for different purposes, cf.
> http://www.iana.org/assignments/port-numbers.  That document indicates
> that a port number in [49152, 65535] might be better.  See if this
> helps.  Does someone else knowof a port interval that is more likely
> to work in general?
>
> You can also tell the Matlab object to report more details what it is
> trying to do by setting the verbosity threshold, i.e.
> setVerbose(matlab, threshold=-1); the lower the threshold the more
> details you'll see.
>
> Cheers
>
> Henrik
>
> >  >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From edd at debian.org  Thu Dec 28 03:55:57 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 27 Dec 2006 20:55:57 -0600
Subject: [R] how to suppress a "loading required package: ..." message
In-Reply-To: <4592BBD3.9050109@vanderbilt.edu>
References: <20061227164206.222130@gmx.net>
	<6e8360ad0612270852o66150620k3d4d5f3bc1d848e4@mail.gmail.com>
	<17810.45032.805061.648736@basebud.nulle.part>
	<4592BBD3.9050109@vanderbilt.edu>
Message-ID: <17811.12861.497098.420657@basebud.nulle.part>



Frank,

On 27 December 2006 at 12:30, Frank E Harrell Jr wrote:
| Dirk Eddelbuettel wrote:
| > On 27 December 2006 at 08:52, BBands wrote:
| > | On 12/27/06, jacinthe at gmx.de <jacinthe at gmx.de> wrote:
| > | > how to suppress a "loading required package:... " message?
| > | 
| > | require(package, quiet=TRUE)
| > 
| > Some packages insist on talking even when they are asked to be quiet, in
| > which case I have also resorted to wrapping sink() around the loading:
| > 
| > 	> sink("/dev/null")
| > 	> library(Hmisc)
| 
| For that one, do options(Hverbose=FALSE) before library(Hmisc)

With all due respect, I think you are misguided here. Per-package options for
verbosity strike me as suboptimal. IMHO, if options("verbose") is FALSE, or
if the quiet argument to require() has been given, Hmisc should simply be
quiet.

In any event, Gabor's one-liner is preferable here as it is generic.

Dirk


-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From perronbe at gmail.com  Thu Dec 28 05:18:22 2006
From: perronbe at gmail.com (Brian Edward)
Date: Wed, 27 Dec 2006 22:18:22 -0600
Subject: [R] Dates in R
Message-ID: <1e6b5c080612272018h123fc9e5ve60ac551bff89df3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061227/f480738b/attachment.pl 

From jholtman at gmail.com  Thu Dec 28 05:38:50 2006
From: jholtman at gmail.com (jim holtman)
Date: Wed, 27 Dec 2006 23:38:50 -0500
Subject: [R] Dates in R
In-Reply-To: <1e6b5c080612272018h123fc9e5ve60ac551bff89df3@mail.gmail.com>
References: <1e6b5c080612272018h123fc9e5ve60ac551bff89df3@mail.gmail.com>
Message-ID: <644e1f320612272038l55193ec9q64bc57eb9e00df07@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061227/4b57da25/attachment.pl 

From macq at llnl.gov  Thu Dec 28 07:07:41 2006
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 27 Dec 2006 22:07:41 -0800
Subject: [R] Dates in R
In-Reply-To: <1e6b5c080612272018h123fc9e5ve60ac551bff89df3@mail.gmail.com>
References: <1e6b5c080612272018h123fc9e5ve60ac551bff89df3@mail.gmail.com>
Message-ID: <p06210201c1b90ee2bf2f@[10.0.1.88]>

See the documentation for

   as.Date

Something like (untested):

as.Date(Date1, '"%m%d%y") - as.Date(Date2,"%m%d%y")

That's assuming Date1 and Date2 have already been loaded into R, and 
are character vectors. They would have to be character vectors in 
order to display the leading zero, as in 032398.

-Don

At 10:18 PM -0600 12/27/06, Brian Edward wrote:
>Hello all,
>
>Can somebody point me to references or provide some code on dealing with
>this date issue.  Basically, I have two vectors of values that represent
>dates.  I want to convert these values into a date format and subtract the
>differences to show elapsed time in days.  More specifically, here is the
>example:
>
>Date1      Date2
>032398    061585
>032398    061585
>111694    101994
>111694    101994
>062695    021595
>051898    111597
>072495    040195
>072495    040195
>
>The dates are in the mmddyy format, but when I attempt to format these in R
>with the function, date.mmddyy(Date1), I get very odd results.  Any help on
>this matter would be greatly appreciated!
>
>Thanks in advance,
>Brian
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


-- 
---------------------------------
Don MacQueen
Lawrence Livermore National Laboratory
Livermore, CA, USA


From f.harrell at vanderbilt.edu  Thu Dec 28 07:22:52 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 28 Dec 2006 00:22:52 -0600
Subject: [R] how to suppress a "loading required package: ..." message
In-Reply-To: <17811.12861.497098.420657@basebud.nulle.part>
References: <20061227164206.222130@gmx.net>	<6e8360ad0612270852o66150620k3d4d5f3bc1d848e4@mail.gmail.com>	<17810.45032.805061.648736@basebud.nulle.part>	<4592BBD3.9050109@vanderbilt.edu>
	<17811.12861.497098.420657@basebud.nulle.part>
Message-ID: <459362BC.3080108@vanderbilt.edu>

Dirk Eddelbuettel wrote:
> 
> Frank,
> 
> On 27 December 2006 at 12:30, Frank E Harrell Jr wrote:
> | Dirk Eddelbuettel wrote:
> | > On 27 December 2006 at 08:52, BBands wrote:
> | > | On 12/27/06, jacinthe at gmx.de <jacinthe at gmx.de> wrote:
> | > | > how to suppress a "loading required package:... " message?
> | > | 
> | > | require(package, quiet=TRUE)
> | > 
> | > Some packages insist on talking even when they are asked to be quiet, in
> | > which case I have also resorted to wrapping sink() around the loading:
> | > 
> | > 	> sink("/dev/null")
> | > 	> library(Hmisc)
> | 
> | For that one, do options(Hverbose=FALSE) before library(Hmisc)
> 
> With all due respect, I think you are misguided here. Per-package options for
> verbosity strike me as suboptimal. IMHO, if options("verbose") is FALSE, or
> if the quiet argument to require() has been given, Hmisc should simply be
> quiet.

Dirk,

I spent a significant amount of time a year ago trying to get the more 
general approach to work but to no avail.  As I recall there either was 
missing documentation or some failure of the system to pass a correct 
argument to .First.lib.  Hence the creation of the workaround.

Frank

> 
> In any event, Gabor's one-liner is preferable here as it is generic.
> 
> Dirk
> 
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From richard.c.yeh at gmail.com  Thu Dec 28 07:43:13 2006
From: richard.c.yeh at gmail.com (Richard C. Yeh)
Date: Thu, 28 Dec 2006 01:43:13 -0500
Subject: [R] Colored Dendrogram
In-Reply-To: <aa697c6a0612260820g1d1d6312x207dcd74a87e4fe8@mail.gmail.com>
References: <aa697c6a0612260820g1d1d6312x207dcd74a87e4fe8@mail.gmail.com>
Message-ID: <op.tk9bmby7v1kyqc@dice.ics.local>

In your colLab function, you are assigning the label colors using the  
mycols 4-element vector, which you generated using the rainbow()  
function.  So, to pick colors using the values in vector c, normalize c  
and then try the colorRamp function.

I don't know how to use that function, myself, so instead I did:

# Generate lots of colors, starting at blue (0.6) and ending at red (0)
# We started at blue because you wanted blue for the lower-valued elements
# and red for the higher-valued elements.
pal <- rainbow(4000,start=0.5,end=0.05)
# Normalize vector c to the range 0-1 (well, not really)
# and scale the range to a color index
mycols <- pal[length(pal)*c/max(c)]

Then define your colLab function and run.


On Tue, 26 Dec 2006 11:20:45 -0500, Om <ompandey at gmail.com> wrote:
> In this dendrogram, each leaf is colored differently. But, I do not want  
> the
> leaf colored on a random basis. I want to assign color for leaf on basis  
> of
> some criterion.
>
> My actual problem: How to generate a dendrogram with the leaf colored
> according to the values in the second matrix (which is 4x1 dim, say  
> matrix
> c)? Meaning, the leaf 1 and 2 should be colored in neighboring spectra of
> color (say different shade of red) and leaf 3 and 4 in a different color
> (say different shade of blue)
>
> Below is R code and data matrix


From msw10 at duke.edu  Thu Dec 28 08:26:54 2006
From: msw10 at duke.edu (Michael Wolosin)
Date: Thu, 28 Dec 2006 00:26:54 -0700
Subject: [R] importing bitmap images to R
Message-ID: <5.2.1.1.1.20061228001646.01b978a8@imap.duke.edu>

All -

I'm creating some plots in R that I would like to overlay on images that 
are created outside of R.

I've used "image" before to plot image-like data within R, and have added 
vector plots on top of them, but I can't find a way to read in an external 
bitmap file into R and use that.

Currently the external files are .png's, but I could generate a few other 
types, if something else might be easier to import.

Thanks,
-Mike


From justin_bem at yahoo.fr  Thu Dec 28 08:35:41 2006
From: justin_bem at yahoo.fr (justin bem)
Date: Thu, 28 Dec 2006 07:35:41 +0000 (GMT)
Subject: [R] Re :  how to test difference in my case?
Message-ID: <20061228073541.29557.qmail@web23013.mail.ird.yahoo.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20061228/7661fb2e/attachment.pl 

From Etron777 at web.de  Thu Dec 28 10:10:06 2006
From: Etron777 at web.de (Knut Krueger)
Date: Thu, 28 Dec 2006 10:10:06 +0100
Subject: [R] axis and times() problem
In-Reply-To: <971536df0612270432q6da9143cu8c0a611508ba39e7@mail.gmail.com>
References: <45924953.9070100@einthal.de>
	<971536df0612270432q6da9143cu8c0a611508ba39e7@mail.gmail.com>
Message-ID: <459389EE.2030908@web.de>

Thank you for your answer
> Actually I think there may be a bug here since the axes do not intersect.
>   

Should I report this or did you report it already as a possible bug?


From Etron777 at web.de  Thu Dec 28 10:16:19 2006
From: Etron777 at web.de (Knut Krueger)
Date: Thu, 28 Dec 2006 10:16:19 +0100
Subject: [R] Plot window - save as Postscript question
Message-ID: <45938B63.1050403@web.de>

R  2.4.0 for Windows
The following plot appears as a squared window (as all r-plots)
Not all subtitles are visible, but  all subtitle will appear, when  
changing the aspect ratio of the plot window with the mouse to a wide 
format.
But does not work when using the save as postscript menu item from the 
plot window.
is there any solution for that?

opar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
mp <- barplot2(VADeaths) # default
mp <- barplot2(VADeaths) # default
mp <- barplot2(VADeaths) # default
mp <- barplot2(VADeaths) # default
par(opar)

Regards Knut


From tomas.goicoa at unavarra.es  Thu Dec 28 10:21:45 2006
From: tomas.goicoa at unavarra.es (Tomas Goicoa)
Date: Thu, 28 Dec 2006 10:21:45 +0100
Subject: [R] split-plot multiple comparisons
Message-ID: <6.0.3.0.0.20061227102853.01ade6c8@pop.unavarra.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061228/b854ca83/attachment.pl 

From yangguoyi.ou at gmail.com  Thu Dec 28 01:54:42 2006
From: yangguoyi.ou at gmail.com (yangguoyi.ou)
Date: Thu, 28 Dec 2006 01:54:42 +0100
Subject: [R] LU bug in Matrix package
Message-ID: <000001c72a1a$c30fb010$f300a8c0@dtud3ae7605c7f>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061228/a325bbbc/attachment.pl 

From hb at stat.berkeley.edu  Thu Dec 28 10:51:20 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Thu, 28 Dec 2006 20:51:20 +1100
Subject: [R] Query regarding linking R with Matlab
In-Reply-To: <20061228063137.37983.qmail@web34307.mail.mud.yahoo.com>
References: <59d7961d0612270026t792e5678l49427282997db034@mail.gmail.com>
	<20061228063137.37983.qmail@web34307.mail.mud.yahoo.com>
Message-ID: <59d7961d0612280151s6fc88868h691c812370335c80@mail.gmail.com>

On 12/28/06, Bhanu Kalyan.K <kalyansikha at yahoo.com> wrote:
> Respected Sir,
>
> It worked.
>
> > open(matlab)
> [1] TRUE

Good.

>
> But however, the 'evaluate' function is not responding.
> When i give the command as:
>
>  > res <- evaluate(matlab, "A=1+2;", "B=ones(2,20);")
>
> The R interface is not returning any value though i wait for 3-4 minutes.

This example should respond more or less instantaneously.

> Same is the case with
>
> > close(matlab)
>
> This is not closing the matlab window, neither it is throwing any warning.
> It is just asking me to wait but finally outputs no result. I am forced to
> "stop the current computation".

Ok, let's turn on all output you can in order to troubleshoot this.
Make sure to do:

  setVerbose(matlab, -2)

before those non-responding calls.  You may also start the Matlab
server in a non-minimized window by calling:

  Matlab$startServer(minimize=FALSE)

This will allow you to see what the Matlab server is doing.  What do you get?

/H

PS. Normally the above should work out of the box; I'm not sure why
you experience all these problems. DS.

>
> Now please guide me as to how to evaluate some matlab expressions.
>
> Thanking you,
>
>
> Regards
> Bhanu Kalyan K
>
>
>
> Bhanu Kalyan K
> BTech CSE Final Year
> reach4kalyan at gmail.com
> Tel :+91-9885238228
>
>  __________________________________________________
> Do You Yahoo!?
> Tired of spam? Yahoo! Mail has the best spam protection around
> http://mail.yahoo.com


From ligges at statistik.uni-dortmund.de  Thu Dec 28 10:55:53 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 28 Dec 2006 10:55:53 +0100
Subject: [R] importing bitmap images to R
In-Reply-To: <5.2.1.1.1.20061228001646.01b978a8@imap.duke.edu>
References: <5.2.1.1.1.20061228001646.01b978a8@imap.duke.edu>
Message-ID: <459394A9.70503@statistik.uni-dortmund.de>

See package pixmap and Paul Murrel's talk from useR!2006:
http://www.r-project.org/useR-2006/Slides/Murrell.pdf

Uwe Ligges


Michael Wolosin wrote:
> All -
> 
> I'm creating some plots in R that I would like to overlay on images that 
> are created outside of R.
> 
> I've used "image" before to plot image-like data within R, and have added 
> vector plots on top of them, but I can't find a way to read in an external 
> bitmap file into R and use that.
> 
> Currently the external files are .png's, but I could generate a few other 
> types, if something else might be easier to import.
> 
> Thanks,
> -Mike
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.uni-dortmund.de  Thu Dec 28 10:56:42 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 28 Dec 2006 10:56:42 +0100
Subject: [R] Plot window - save as Postscript question
In-Reply-To: <45938B63.1050403@web.de>
References: <45938B63.1050403@web.de>
Message-ID: <459394DA.7090503@statistik.uni-dortmund.de>



Knut Krueger wrote:
> R  2.4.0 for Windows
> The following plot appears as a squared window (as all r-plots)
> Not all subtitles are visible, but  all subtitle will appear, when  
> changing the aspect ratio of the plot window with the mouse to a wide 
> format.
> But does not work when using the save as postscript menu item from the 
> plot window.
> is there any solution for that?


Yes: Use the postscript() device explicitly and define the width and 
height in the function call.

Uwe Ligges


> opar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
> mp <- barplot2(VADeaths) # default
> mp <- barplot2(VADeaths) # default
> mp <- barplot2(VADeaths) # default
> mp <- barplot2(VADeaths) # default
> par(opar)
> 
> Regards Knut
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Thu Dec 28 11:34:46 2006
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 28 Dec 2006 21:34:46 +1100
Subject: [R] counties in different colours using map()
In-Reply-To: <45925504.2060401@nvb.slu.se>
References: <45925504.2060401@nvb.slu.se>
Message-ID: <45939DC6.8080502@bitwrit.com.au>

Tord Sn?ll wrote:
> Hi,
> I would like to plot a map of US counties using different colors. map() 
> seems to be the function to use, e.g.
> library(maps); map('usa'); map('county', 'colorado', add=T,fill = T, 
> col=c(1:5))
> plots Colorado counties using colours 1 to 5.
> 
> However, I want each color to represent a certain value - a value to be 
> picked from a data frame.
> This code should show a correspoding map at the level of states:
> state.names <- system('tr "[A-Z]" "[a-z]"', state.name)
> map.states <- unix('sed "s/:.*//"', map(names=T,plot=F))
> state.to.map <- match(map.states, state.names)
> color<- votes.repub[state.to.map, votes.year = 1900] / 100
> map('state', fill=T, col=color); map('state', add=T)
>
Hi Tord,
I don't know if this matches the color to the state as I couldn't get 
your "unix" function to work, but it does what I think you want.

library(maps)
map("usa")
data(votes.repub)
library(plotrix)
state.col<-color.scale(votes.repub[,30],c(0,1),0,c(1,0))
map("state",fill=TRUE,col=state.col)

Jim


From hb at stat.berkeley.edu  Thu Dec 28 12:08:16 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Thu, 28 Dec 2006 22:08:16 +1100
Subject: [R] Query regarding linking R with Matlab
In-Reply-To: <59d7961d0612280245r4c172d71xf6232f6a61504d61@mail.gmail.com>
References: <59d7961d0612280151s6fc88868h691c812370335c80@mail.gmail.com>
	<20061228102701.19780.qmail@web34306.mail.mud.yahoo.com>
	<59d7961d0612280245r4c172d71xf6232f6a61504d61@mail.gmail.com>
Message-ID: <59d7961d0612280308v37cff21ep56cb4cd30eec3620@mail.gmail.com>

[Forwarding to r-help for completeness. /Henrik]

---------- Forwarded message ----------
From: Henrik Bengtsson <hb at stat.berkeley.edu>
Date: Dec 28, 2006 9:45 PM
Subject: Re: [R] Query regarding linking R with Matlab
To: kalyansikha at yahoo.com


Hi.

On 12/28/06, Bhanu Kalyan.K <kalyansikha at yahoo.com> wrote:
> Respected Sir,
> I am sorry that i forgot to 'setVerbose'. Now when that is set, The result
> is:
>
> > Matlab$startServer(minimize=FALSE)
> [1] 0
>
> > matlab <- Matlab(host="localhost")
>
> > open(matlab)
> [1] TRUE
>
> > setVerbose(matlab, -2)
>
> > res <- evaluate(matlab, "A=1+2;", "B=ones(2,20);")
>
> Sending expression on the Matlab server to be evaluated...: 'A=1+2;
> B=ones(2,20);'
> Received an 'OK' reply (0) from the Matlab server.
> Evaluated expression on the Matlab server with return code 0.
>
> > res
> NULL
>
> > close(matlab)
> Closing connection to host 'localhost' (port 9999)...
>  Received an 'OK' reply (0) from the Matlab server.
> Closing connection to host 'localhost' (port 9999)...done
>
> What should "res" object contain finally when we are doing
> res <- evaluate(matlab, "A=1+2;", "B=ones(2,20);") ??

The return value of evaluate() is NULL when successful (I noticed the
help is saying '0'; I've corrected that for the next version).
Anyway, 'res' contains nothing of interest.  If there is any error on
the Matlab side, an error is thrown in R giving you the details.

What you might want to do is:

data <- getVariable(matlab, "A")
str(data)

>
> once i do
> close(matlab), the matlab server is shutdown,

Yes, the server script is shut down, but Matlab is left running on
purpose so you have a chance to continue working with the Matlab
session by hand.

> However, when i ask for the
> values of A & B in matlab window, the output is displayed correctly. The
> matlab window outputs thus:
> ? A
>
> A =
>
>      3
>
> ? B
>
> B =
>
>   Columns 1 through 17
>
>      1     1     1     1     1     1     1     1     1     1     1     1
> 1     1     1     1     1
>      1     1     1     1     1     1     1     1     1     1     1     1
> 1     1     1     1     1
>
>   Columns 18 through 20
>
>      1     1     1
>      1     1     1
>
> What do you interpret?

That everything is now working as expected.  See the example of
help(Matlab) to get more ideas how to interact with Matlab from R.

Cheers

Henrik

> Kindly let me know
>
>
> Regards
> Bhanu Kalyan K
>
>
> Bhanu Kalyan K
> BTech CSE Final Year
> reach4kalyan at gmail.com
> Tel :+91-9885238228
>
>  __________________________________________________
> Do You Yahoo!?
> Tired of spam? Yahoo! Mail has the best spam protection around
> http://mail.yahoo.com


From wl at eimb.ru  Thu Dec 28 12:31:49 2006
From: wl at eimb.ru (Vladimir Eremeev)
Date: Thu, 28 Dec 2006 11:31:49 +0000 (UTC)
Subject: [R] How to debug R program?
References: <008d01c729d6$f84fada0$bfcc4dc7@Aglog>
Message-ID: <loom.20061228T122536-353@post.gmane.org>

> Hi everyone:

Please, refer to the chapter 9 of the "R language definition" ($R_HOME/doc/
manual/r-lang.pdf)

The simplest way is using print() functions.

Besides the debugging functions described in the manual, you can use the very 
powerful package debug, developed by Mark Bravington.   
 
>       I wrote a R program which has loops. When I run the program, it 
> crashed. I would like to identify in which loop the pragram crashed, how 
> can I debug ?  I'm new to R, could somebody please give me a general idea 
> about debugging in R.(I'm a C/C++ programmer and have general knowledge 
> about program debugging.)
>      Thank you!
> 
> Best,


From ggrothendieck at gmail.com  Thu Dec 28 12:38:32 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 28 Dec 2006 06:38:32 -0500
Subject: [R] How to debug R program?
In-Reply-To: <loom.20061228T122536-353@post.gmane.org>
References: <008d01c729d6$f84fada0$bfcc4dc7@Aglog>
	<loom.20061228T122536-353@post.gmane.org>
Message-ID: <971536df0612280338r1ddab57v7ba7c2819213b9d6@mail.gmail.com>

On 12/28/06, Vladimir Eremeev <wl at eimb.ru> wrote:
> > Hi everyone:
>
> Please, refer to the chapter 9 of the "R language definition" ($R_HOME/doc/
> manual/r-lang.pdf)
>
> The simplest way is using print() functions.

Note that on Mac and Windows you may need to use flush.console() as well
if you intend to do this in a loop to be sure that the last print executed is
actually printed prior to the crash.  See ?flush.console

>
> Besides the debugging functions described in the manual, you can use the very
> powerful package debug, developed by Mark Bravington.
>
> >       I wrote a R program which has loops. When I run the program, it
> > crashed. I would like to identify in which loop the pragram crashed, how
> > can I debug ?  I'm new to R, could somebody please give me a general idea
> > about debugging in R.(I'm a C/C++ programmer and have general knowledge
> > about program debugging.)
> >      Thank you!
> >
> > Best,
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Etron777 at web.de  Thu Dec 28 13:27:49 2006
From: Etron777 at web.de (Knut Krueger)
Date: Thu, 28 Dec 2006 13:27:49 +0100
Subject: [R] Plot window - save as Postscript question
In-Reply-To: <459394DA.7090503@statistik.uni-dortmund.de>
References: <45938B63.1050403@web.de>
	<459394DA.7090503@statistik.uni-dortmund.de>
Message-ID: <4593B845.5090800@web.de>

Uwe Ligges schrieb:
>   
> Yes: Use the postscript() device explicitly and define the width and 
> height in the function call.
>
>   
I tried it before but I think I did a mistake:
Does the width and height command not work with
If paper="letter" ?
The plot was cutted at the upper boarder of the "paper"

I tried it with paper="special" and it worked now
Best regards Knut


From a.l.w.kuijper at rug.nl  Thu Dec 28 15:08:48 2006
From: a.l.w.kuijper at rug.nl (Bram Kuijper)
Date: Thu, 28 Dec 2006 15:08:48 +0100
Subject: [R] lattice xyplot: plot multiple lines with different colors
Message-ID: <4593CFF0.4070507@rug.nl>

Hi everyone,

I am using the lattice package to plot some simulation results, by using 
the function xyplot(). However, I cannot find a way to plot multiple 
lines within the same xyplot and to have each of the lines be drawn in a 
different color.

This is what I am currently doing:

xyplot(a + b + c ~ x, my_data, panel = panel.lines)

but, of course, all lines are drawn in the same color.


What I would prefer, would be to first print a single line in an xyplot 
and then add a new line, and so on (since I want to dynamically 
determine the number of lines that need to be plotted). For example, 
something like this would be nice:

for(i = 1:length(lines_to_be_drawn)) {
     xyplot(lines_to_be_drawn[i] ~ x, my_data, panel = {some function 
setting a different color});

	// do some other functions like plotting legend, parameters
}

(although in this putative example, a new xyplot is drawn over the old 
one every time).

anyone any idea to plot multiple lines with different colors in a single 
xyplot? I'd like to stick to the lattice package, since this package has 
more layout possibilities over the traditional plotting functions in R.

cheers,
Bram


From ggrothendieck at gmail.com  Thu Dec 28 15:21:02 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 28 Dec 2006 09:21:02 -0500
Subject: [R] lattice xyplot: plot multiple lines with different colors
In-Reply-To: <4593CFF0.4070507@rug.nl>
References: <4593CFF0.4070507@rug.nl>
Message-ID: <971536df0612280621g62059ac4gbcffc13cc165807e@mail.gmail.com>

Try this:


library(lattice)
x <- 1:10

xyplot(x/max(x) ~ x, type = "n", col = "blue", ylim = 0:1)
for(i in 1:3) {
	trellis.focus("panel", 1, 1)
	panel.lines(x, x^i/max(x^i), col = i)
	trellis.unfocus()
}




On 12/28/06, Bram Kuijper <a.l.w.kuijper at rug.nl> wrote:
> Hi everyone,
>
> I am using the lattice package to plot some simulation results, by using
> the function xyplot(). However, I cannot find a way to plot multiple
> lines within the same xyplot and to have each of the lines be drawn in a
> different color.
>
> This is what I am currently doing:
>
> xyplot(a + b + c ~ x, my_data, panel = panel.lines)
>
> but, of course, all lines are drawn in the same color.
>
>
> What I would prefer, would be to first print a single line in an xyplot
> and then add a new line, and so on (since I want to dynamically
> determine the number of lines that need to be plotted). For example,
> something like this would be nice:
>
> for(i = 1:length(lines_to_be_drawn)) {
>     xyplot(lines_to_be_drawn[i] ~ x, my_data, panel = {some function
> setting a different color});
>
>        // do some other functions like plotting legend, parameters
> }
>
> (although in this putative example, a new xyplot is drawn over the old
> one every time).
>
> anyone any idea to plot multiple lines with different colors in a single
> xyplot? I'd like to stick to the lattice package, since this package has
> more layout possibilities over the traditional plotting functions in R.
>
> cheers,
> Bram
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ccleland at optonline.net  Thu Dec 28 15:21:49 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 28 Dec 2006 09:21:49 -0500
Subject: [R] lattice xyplot: plot multiple lines with different colors
In-Reply-To: <4593CFF0.4070507@rug.nl>
References: <4593CFF0.4070507@rug.nl>
Message-ID: <4593D2FD.6020904@optonline.net>

Bram Kuijper wrote:
> Hi everyone,
> 
> I am using the lattice package to plot some simulation results, by using 
> the function xyplot(). However, I cannot find a way to plot multiple 
> lines within the same xyplot and to have each of the lines be drawn in a 
> different color.
> 
> This is what I am currently doing:
> 
> xyplot(a + b + c ~ x, my_data, panel = panel.lines)
> 
> but, of course, all lines are drawn in the same color.
> 
> 
> What I would prefer, would be to first print a single line in an xyplot 
> and then add a new line, and so on (since I want to dynamically 
> determine the number of lines that need to be plotted). For example, 
> something like this would be nice:
> 
> for(i = 1:length(lines_to_be_drawn)) {
>      xyplot(lines_to_be_drawn[i] ~ x, my_data, panel = {some function 
> setting a different color});
> 
> 	// do some other functions like plotting legend, parameters
> }
> 
> (although in this putative example, a new xyplot is drawn over the old 
> one every time).
> 
> anyone any idea to plot multiple lines with different colors in a single 
> xyplot? I'd like to stick to the lattice package, since this package has 
> more layout possibilities over the traditional plotting functions in R.

  I don't know about dynamically determining the number of lines, but
the following gives different colors for each line automatically:

library(lattice)
df <- data.frame(a = runif(10), b = runif(10), c = runif(10), x = 1:10)
xyplot(a + b + c ~ x, data = df, type = "l", auto.key=TRUE)

> cheers,
> Bram
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From mhbrugman at gmail.com  Thu Dec 28 15:26:38 2006
From: mhbrugman at gmail.com (Martijn Brugman)
Date: Thu, 28 Dec 2006 15:26:38 +0100
Subject: [R] Cochran-Armitage statistics
Message-ID: <dde3deee0612280626r6179d91bnb4c08a34405b0d3d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061228/52874501/attachment.pl 

From muenchen at utk.edu  Thu Dec 28 15:47:29 2006
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Thu, 28 Dec 2006 09:47:29 -0500
Subject: [R] Aggregation using list with Hmisc summarize function
Message-ID: <7270AEC73132194E8BC0EE06B35D93D84F3444@UTKFSVS3.utk.tennessee.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061228/9204583f/attachment.pl 

From aiminy at iastate.edu  Thu Dec 28 16:46:34 2006
From: aiminy at iastate.edu (Aimin Yan)
Date: Thu, 28 Dec 2006 09:46:34 -0600
Subject: [R] R.matlab question
In-Reply-To: <59d7961d0612271819x36989602kde9747b836c9cf05@mail.gmail.co
 m>
References: <6.1.2.0.2.20061219204859.01c24408@aiminy.mail.iastate.edu>
	<59d7961d0612200245o42ceaaf2ka0c69f34d91aa6f0@mail.gmail.com>
	<59d7961d0612271819x36989602kde9747b836c9cf05@mail.gmail.com>
Message-ID: <6.2.3.4.2.20061228094321.0385b780@aiminy.mail.iastate.edu>

I am appreciated that you still remember my question.
I try this one, it works now.
thank you very, very much.

Aimin

At 08:19 PM 12/27/2006, Henrik Bengtsson wrote:
>Hi,
>
>a follow up after realizing that you might not have started the Matlab
>application to listen on port 9998.  Try:
>
>Matlab$startServer(port=9998)
>
>and then
>
>matlab <- Matlab(host="localhost", port=9998)
>if (!open(matlab)) throw("Matlab server is not running: waited 30 seconds.")
>
>Does this help?
>
>Henrik
>
>On 12/20/06, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
>>Hi.
>>
>>On 12/20/06, Aimin Yan <aiminy at iastate.edu> wrote:
>> > Does anyone know how to solve this question about R.matlab?
>> > I am in windowsXP, my matlab is matlab 7.0.0 19920(R14)
>> >
>> > thanks,
>> >
>> > Aimin
>> >
>> >  > matlab <- Matlab(host="localhost", port=9998)
>> >  > if (!open(matlab)) throw("Matlab server is not running: 
>> waited 30 seconds.")
>> > Error in list("throw("Matlab server is not running: waited 30 
>> seconds.")" =
>> > <environment>,  :
>> >
>> > [2006-12-17 22:26:03] Exception: Matlab server is not running: waited 30
>> > seconds.
>> >    at throw(Exception(...))
>> >    at throw.default("Matlab server is not running: waited 30 seconds.")
>> >    at throw("Matlab server is not running: waited 30 seconds.")
>> > In addition: There were 30 warnings (use warnings() to see them)
>> >  > warnings
>> > function (...)
>> > UseMethod("warnings")
>> >  > warnings()
>> > Warning messages:
>> > 1: localhost:9998 cannot be opened
>> > 2: localhost:9998 cannot be opened
>>[snip]
>> > 30: localhost:9998 cannot be opened
>>
>>This could be because your firewall is blocking R from connecting
>>to Matlab.  Try a few different port numbers.  I recently learned that
>>the current default port in R.matlab might not be the best one;
>>different port intervals are reserved for different purposes, cf.
>>http://www.iana.org/assignments/port-numbers.  That document indicates
>>that a port number in [49152, 65535] might be better.  See if this
>>helps.  Does someone else knowof a port interval that is more likely
>>to work in general?
>>
>>You can also tell the Matlab object to report more details what it is
>>trying to do by setting the verbosity threshold, i.e.
>>setVerbose(matlab, threshold=-1); the lower the threshold the more
>>details you'll see.
>>
>>Cheers
>>
>>Henrik
>>
>> >  >
>> >
>> > ______________________________________________
>> > R-help at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >


From f.harrell at vanderbilt.edu  Thu Dec 28 17:28:00 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 28 Dec 2006 10:28:00 -0600
Subject: [R] Aggregation using list with Hmisc summarize function
In-Reply-To: <7270AEC73132194E8BC0EE06B35D93D84F3444@UTKFSVS3.utk.tennessee.edu>
References: <7270AEC73132194E8BC0EE06B35D93D84F3444@UTKFSVS3.utk.tennessee.edu>
Message-ID: <4593F090.5070600@vanderbilt.edu>

Muenchen, Robert A (Bob) wrote:
> Hi All,
> 
>  
> 
> I'm using the Hmisc summarize function and used list instead of llist to
> provide the by variables. It generated an error message. Is this a bug,
> or do I misunderstand how Hmisc works with lists? The program below
> demonstrates the error message.
> 
>  
> 
> Thanks,
> 
> Bob
> 
>  
> 
> x<-1:8
> 
> group <- c(1,1,1,1,2,2,2,2)
> 
> gender<- c(1,2,1,2,1,2,1,2)
> 
>  
> 
> mydata<-data.frame(x,group,gender)
> 
> attach(mydata)
> 
>  
> 
> # Creating a list using Hmisc llist works:
> 
> summarize(x, by=llist(group,gender), FUN=mean, na.rm=TRUE) 
> 
>  
> 
> # Creating a list using built-in list function does not:
> 
> summarize(x, by= list(group,gender), FUN=mean, na.rm=TRUE)

Use llist so summarize will know how to label the output.

Also your attach( ) is not functional as your variables are already in 
the search path.  Whenever you do need to attach, consider the use of 
with( ) instead.

Frank

> 
>  
> 
> =========================================================
> Bob Muenchen (pronounced Min'-chen), Manager 
> Statistical Consulting Center
> U of TN Office of Information Technology


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From ggrothendieck at gmail.com  Thu Dec 28 17:37:32 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 28 Dec 2006 11:37:32 -0500
Subject: [R] Aggregation using list with Hmisc summarize function
In-Reply-To: <7270AEC73132194E8BC0EE06B35D93D84F3444@UTKFSVS3.utk.tennessee.edu>
References: <7270AEC73132194E8BC0EE06B35D93D84F3444@UTKFSVS3.utk.tennessee.edu>
Message-ID: <971536df0612280837s57cf185bs580dc713cf9568bf@mail.gmail.com>

Note that you don't really need list or llist in this case:

summarize(x, by = mydata[2:3], FUN = mean, na.rm = TRUE)

Also you could use aggregate:

aggregate(mydata[1], mydata[2:3], mean, na.rm = TRUE)


On 12/28/06, Muenchen, Robert A (Bob) <muenchen at utk.edu> wrote:
> Hi All,
>
>
>
> I'm using the Hmisc summarize function and used list instead of llist to
> provide the by variables. It generated an error message. Is this a bug,
> or do I misunderstand how Hmisc works with lists? The program below
> demonstrates the error message.
>
>
>
> Thanks,
>
> Bob
>
>
>
> x<-1:8
>
> group <- c(1,1,1,1,2,2,2,2)
>
> gender<- c(1,2,1,2,1,2,1,2)
>
>
>
> mydata<-data.frame(x,group,gender)
>
> attach(mydata)
>
>
>
> # Creating a list using Hmisc llist works:
>
> summarize(x, by=llist(group,gender), FUN=mean, na.rm=TRUE)
>
>
>
> # Creating a list using built-in list function does not:
>
> summarize(x, by= list(group,gender), FUN=mean, na.rm=TRUE)
>
>
>
> =========================================================
> Bob Muenchen (pronounced Min'-chen), Manager
> Statistical Consulting Center
> U of TN Office of Information Technology
> 200 Stokely Management Center, Knoxville, TN 37996-0520
> Voice: (865) 974-5230
> FAX: (865) 974-4810
> Email: muenchen at utk.edu
> Web: http://oit.utk.edu/scc <http://oit.utk.edu/scc> ,
> News: http://listserv.utk.edu/archives/statnews.html
> <http://listserv.utk.edu/archives/statnews.html>
> =========================================================
>
>
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tlumley at u.washington.edu  Thu Dec 28 18:17:13 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 28 Dec 2006 09:17:13 -0800 (PST)
Subject: [R] LU bug in Matrix package
In-Reply-To: <000001c72a1a$c30fb010$f300a8c0@dtud3ae7605c7f>
References: <000001c72a1a$c30fb010$f300a8c0@dtud3ae7605c7f>
Message-ID: <Pine.LNX.4.64.0612280908181.29933@homer21.u.washington.edu>

On Thu, 28 Dec 2006, yangguoyi.ou wrote:

> There is a bug in Matrix package, please check it, thanks!

You didn't say what R code you ran to get that output or why you think it 
is wrong.

Let us experiment to see if we can guess what the problem is from the 
limited information provided
> x<-t(Matrix(1:25,5))
> x
5 x 5 Matrix of class "dgeMatrix"
      [,1] [,2] [,3] [,4] [,5]
[1,]    1    2    3    4    5
[2,]    6    7    8    9   10
[3,]   11   12   13   14   15
[4,]   16   17   18   19   20
[5,]   21   22   23   24   25

> lux<-lu(x)
Warning message:
Exact singularity detected during LU decomposition.

Now check that the decomposition is correct
> with(expand(a), P%*%L%*%U)
5 x 5 Matrix of class "dgeMatrix"
      [,1] [,2] [,3] [,4] [,5]
[1,]    1    2    3    4    5
[2,]    6    7    8    9   10
[3,]   11   12   13   14   15
[4,]   16   17   18   19   20
[5,]   21   22   23   24   25

Ok, it is correct.
Now let's Look at the matrices

> expand(a)
$L
5 x 5 Matrix of class "dtrMatrix"
      [,1]       [,2]       [,3]       [,4]       [,5]
[1,] 1.00000000          .          .          .          .
[2,] 0.04761905 1.00000000          .          .          .
[3,] 0.52380952 0.50000000 1.00000000          .          .
[4,] 0.28571429 0.75000000 0.35400130 1.00000000          .
[5,] 0.76190476 0.25000000 0.50000000 0.00000000 1.00000000

$U
5 x 5 Matrix of class "dtrMatrix"
      [,1]          [,2]          [,3]          [,4]          [,5]
[1,]  2.100000e+01  2.200000e+01  2.300000e+01  2.400000e+01  2.500000e+01
[2,]             .  9.523810e-01  1.904762e+00  2.857143e+00  3.809524e+00
[3,]             .             . -1.919092e-15 -3.711332e-15 -5.614541e-15
[4,]             .             .             .  3.781500e-16  6.288326e-16
[5,]             .             .             .             .  0.000000e+00

$P
5 x 5 sparse Matrix of class "pMatrix"

[1,] . 1 . . .
[2,] . . . 1 .
[3,] . . 1 . .
[4,] . . . . 1
[5,] 1 . . . .


Perhaps the output was a trimmed version of this? The L and U matrices 
agree, but you didn't show the permutation matrix.

Did you just miss the fact that the decomposition is P%*%L%*%U? If you 
aren't used to S4 classes it is easy to miss the fact that class?LU 
gives help on the structure of the "LU" class, and if you try to guess 
what the components are without the documentation it is easy to be 
confused.


 	-thomas




>
>
>
>
> Matlab result:
>
>
>
> x =
>
>     1     2     3     4     5
>
>     6     7     8     9    10
>
>    11    12    13    14    15
>
>    16    17    18    19    20
>
>    21    22    23    24    25
>
>
>
>>> lu(x)
>
>
>
> ans =
>
>
>
>   21.0000   22.0000   23.0000   24.0000   25.0000
>
>    0.0476    0.9524    1.9048    2.8571    3.8095
>
>    0.7619    0.2500   -0.0000   -0.0000   -0.0000
>
>    0.5238    0.5000    0.4839         0    0.0000
>
>    0.2857    0.7500   -0.0645         0    0.0000
>
>
>
>
>
> Gsl result:
>
>
>
> 21 22 23 24 25
>
> 0.047619 0.952381 1.90476 2.85714 3.80952
>
> 0.761905 0.25 -3.44169e-015 -6.88338e-015 -1.03251e-014
>
> 0.52381 0.5 -0.0322581 -1.77636e-015 -1.66533e-015
>
> 0.285714 0.75 -0.0645161 -0 2.22045e-016
>
>
>
>
>
> R result:
>
> $L
>
> 5 x 5 Matrix of class "dtrMatrix"
>
>     [,1]       [,2]       [,3]       [,4]       [,5]
>
> [1,] 1.00000000          .          .          .          .
>
> [2,] 0.04761905 1.00000000          .          .          .
>
> [3,] 0.52380952 0.50000000 1.00000000          .          .
>
> [4,] 0.28571429 0.75000000 0.35400130 1.00000000          .
>
> [5,] 0.76190476 0.25000000 0.50000000 0.00000000 1.00000000
>
>
>
> $U
>
> 5 x 5 Matrix of class "dtrMatrix"
>
>     [,1]          [,2]          [,3]          [,4]          [,5]
>
> [1,]  2.100000e+01  2.200000e+01  2.300000e+01  2.400000e+01  2.500000e+01
>
> [2,]             .  9.523810e-01  1.904762e+00  2.857143e+00  3.809524e+00
>
> [3,]             .             . -1.919092e-15 -3.711332e-15 -5.614541e-15
>
> [4,]             .             .             .  3.781500e-16  6.288326e-16
>
> [5,]             .             .             .             .  0.000000e+00
>
>
>
>
>
>
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From perronbe at gmail.com  Thu Dec 28 18:48:34 2006
From: perronbe at gmail.com (Brian Edward)
Date: Thu, 28 Dec 2006 11:48:34 -0600
Subject: [R] Dates in R
In-Reply-To: <p06210201c1b90ee2bf2f@10.0.1.88>
References: <1e6b5c080612272018h123fc9e5ve60ac551bff89df3@mail.gmail.com>
	<p06210201c1b90ee2bf2f@10.0.1.88>
Message-ID: <1e6b5c080612280948j98eb412h9fee30af2a143a98@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061228/880df242/attachment.pl 

From cberry at tajo.ucsd.edu  Thu Dec 28 18:54:25 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Thu, 28 Dec 2006 09:54:25 -0800
Subject: [R] importing bitmap images to R
In-Reply-To: <5.2.1.1.1.20061228001646.01b978a8@imap.duke.edu>
References: <5.2.1.1.1.20061228001646.01b978a8@imap.duke.edu>
Message-ID: <Pine.LNX.4.64.0612280940530.11219@tajo.ucsd.edu>



Following the posting guide suggests

 	RSiteSearch("bitmap")

which leads to

 	http://finzi.psych.upenn.edu/R/Rhelp02a/archive/28384.html
and
 	http://finzi.psych.upenn.edu/R/Rhelp02a/archive/65284.html

On Thu, 28 Dec 2006, Michael Wolosin wrote:

> All -
>
> I'm creating some plots in R that I would like to overlay on images that
> are created outside of R.
>
> I've used "image" before to plot image-like data within R, and have added
> vector plots on top of them, but I can't find a way to read in an external
> bitmap file into R and use that.
>
> Currently the external files are .png's, but I could generate a few other
> types, if something else might be easier to import.
>
> Thanks,
> -Mike
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717


From fjbuch at gmail.com  Thu Dec 28 19:45:56 2006
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Thu, 28 Dec 2006 13:45:56 -0500
Subject: [R] RODBC not working when connecting to a Sybase database
Message-ID: <bd93cdad0612281045r499e7bebl1740ecba5be73628@mail.gmail.com>

What is this error message about and how do I troubleshoot it?
> sqlTables(channel)
Error in .Call("RODBCFetchRows", attr(channel, "handle_ptr"), max, buffsize,  :
        negative length vectors are not allowed
The channel was created as such
channel <- odbcConnect("Labdata")
I think this is telling me that my odbcConnect command worked

> odbcGetInfo(channel)
                 DBMS_Name                   DBMS_Ver
"Adaptive Server Anywhere"               "09.00.0002"
           Driver_ODBC_Ver           Data_Source_Name
                   "03.52"                  "Labdata"
               Driver_Name                 Driver_Ver
             "DBODBC9.DLL"               "09.00.0000"
                  ODBC_Ver                Server_Name
              "03.52.0000"                     "CGS9"



-- 
Farrel Buchinsky


From jholtman at gmail.com  Thu Dec 28 19:52:10 2006
From: jholtman at gmail.com (jim holtman)
Date: Thu, 28 Dec 2006 13:52:10 -0500
Subject: [R] Dates in R
In-Reply-To: <1e6b5c080612280948j98eb412h9fee30af2a143a98@mail.gmail.com>
References: <1e6b5c080612272018h123fc9e5ve60ac551bff89df3@mail.gmail.com>
	<p06210201c1b90ee2bf2f@10.0.1.88>
	<1e6b5c080612280948j98eb412h9fee30af2a143a98@mail.gmail.com>
Message-ID: <644e1f320612281052t39778821n6814842555d88e3c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061228/2c41d205/attachment.pl 

From palmar379 at yahoo.es  Thu Dec 28 20:47:28 2006
From: palmar379 at yahoo.es (Pedro Ramirez)
Date: Thu, 28 Dec 2006 20:47:28 +0100 (CET)
Subject: [R] CV by rpart/mvpart
Message-ID: <20061228194728.36652.qmail@web27511.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061228/5410da8f/attachment.pl 

From palmar379 at yahoo.es  Thu Dec 28 20:52:35 2006
From: palmar379 at yahoo.es (Pedro Ramirez)
Date: Thu, 28 Dec 2006 20:52:35 +0100 (CET)
Subject: [R] CV by rpart/mvpart
Message-ID: <20061228195235.72332.qmail@web27508.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061228/0980fdf7/attachment.pl 

From dkaplan at education.wisc.edu  Thu Dec 28 22:03:25 2006
From: dkaplan at education.wisc.edu (David Kaplan)
Date: Thu, 28 Dec 2006 15:03:25 -0600
Subject: [R] Error message using normality test in vars
Message-ID: <4594311D.2080807@education.wisc.edu>

Hi all,

I'm running a vector-time series model with the vars package.  When I 
test the univariate and multivariate normality of the residuals using 
normality(), I get the results, but also this warning

Warning messages:
1: longer object length
         is not a multiple of shorter object length in: b2 - rep(3, 4)
2: longer object length
         is not a multiple of shorter object length in: b2 - rep(3, 4)


What does this mean and do I need to worry about it.

Thanks in advance,

David


-- 
=======================================================================
David Kaplan, Ph.D.
Professor
Department of Educational Psychology
University of Wisconsin - Madison
Educational Sciences, Room 1061
1025 W. Johnson Street
Madison, WI 53706

email: dkaplan at education.wisc.edu
Web:   http://www.education.wisc.edu/edpsych/facstaff/kaplan/kaplan.htm
Phone: 608-262-0836
Fax:   608-262-0843


From helprhelp at gmail.com  Thu Dec 28 22:18:45 2006
From: helprhelp at gmail.com (Weiwei Shi)
Date: Thu, 28 Dec 2006 16:18:45 -0500
Subject: [R] CV by rpart/mvpart
In-Reply-To: <20061228194728.36652.qmail@web27511.mail.ukl.yahoo.com>
References: <20061228194728.36652.qmail@web27511.mail.ukl.yahoo.com>
Message-ID: <cdf817830612281318h505c730cy288f00be7e5d747c@mail.gmail.com>

n-fold cv is easy to be implemented in R by yourself. you can create
10 folds' samples by yourself and disable cv in rpart. Then you can
use the same sample sets to compare different methods.

HTH

weiwei

On 12/28/06, Pedro Ramirez <palmar379 at yahoo.es> wrote:
> Dear R-list,
>
> I am using the rpart/mvpart-package for selecting a right-sized regression tree by 10-fold cross-validation. My question: Is there a possibility to find out for every observation in which of the ten folds it is lying? I want to use the same folds for validating another regression method (moving averages) in order to choose the better one.
>
> Thanks a lot,
> Pedro
>
>
> ---------------------------------
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From ivowel at gmail.com  Thu Dec 28 22:51:44 2006
From: ivowel at gmail.com (ivo welch)
Date: Thu, 28 Dec 2006 16:51:44 -0500
Subject: [R] min, median, mean on data frame (matrix)
Message-ID: <50d1c22d0612281351q29811e2eq4def7d723e5489f6@mail.gmail.com>

dear r experts:

I know its almost surely documented.  if d is a data frame

median(d)  <-- fails (message is "need numeric data")
min(d)  <-- succeeds, but gives a scalar.
mean(d)  <-- gives a vector

I am wondering whether this could be changed into something more
consistent.  most naturally, the functions might just always return a
vector.

of course, if this change were made and if I wanted the old min() and
max() behavior on a data frame, I would need to first flatten the
data.

just a thought...

/iaw


From ggrothendieck at gmail.com  Thu Dec 28 23:00:09 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 28 Dec 2006 17:00:09 -0500
Subject: [R] min, median, mean on data frame (matrix)
In-Reply-To: <50d1c22d0612281351q29811e2eq4def7d723e5489f6@mail.gmail.com>
References: <50d1c22d0612281351q29811e2eq4def7d723e5489f6@mail.gmail.com>
Message-ID: <971536df0612281400s4405daf1tc9949ad82c1bf056@mail.gmail.com>

One can use sapply to get a consistent set of idioms despite the underlying
inconsistency of the functions themselves (using the builtin dataset anscombe):

sapply(anscombe, median)
sapply(anscombe, min)
sapply(anscombe, mean)

On 12/28/06, ivo welch <ivowel at gmail.com> wrote:
> dear r experts:
>
> I know its almost surely documented.  if d is a data frame
>
> median(d)  <-- fails (message is "need numeric data")
> min(d)  <-- succeeds, but gives a scalar.
> mean(d)  <-- gives a vector
>
> I am wondering whether this could be changed into something more
> consistent.  most naturally, the functions might just always return a
> vector.
>
> of course, if this change were made and if I wanted the old min() and
> max() behavior on a data frame, I would need to first flatten the
> data.
>
> just a thought...
>
> /iaw
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From zack_holden at hotmail.com  Thu Dec 28 19:53:19 2006
From: zack_holden at hotmail.com (zack holden)
Date: Thu, 28 Dec 2006 18:53:19 +0000
Subject: [R] MANOVA-CANCOR with class variable?
Message-ID: <BAY125-F109D1FACC8177A5D118D3287C70@phx.gbl>

Dear list,

I'm trying to compare two sets of variables using canonical analysis. My X 
variables include 3 climate indices, all continuous. My Y variables describe 
a set of 3 environmental moisture measurements. However, I would also like 
to include a class variable for habitat type.

My colleaugue was able to do this in SAS, but we could not find a way to do 
it in R.

Is anyone familiar enough with manova techniques in R to tell me whether 
this is possible, and if it is, how to do it?

Thanks in advance for any advice,

Zack


From sarifkin at MIT.EDU  Thu Dec 28 22:05:12 2006
From: sarifkin at MIT.EDU (scott rifkin)
Date: Thu, 28 Dec 2006 16:05:12 -0500
Subject: [R] lmer: Interpreting random effects contrasts and model
	formulation
Message-ID: <45943188.7050703@mit.edu>

I'm trying to fit a nested mixed model using lmer and have some 
questions about the output and my model formulations.

I have replicate measures on Lines which are strictly nested within 
Populations.

(a) So if I want to fit a model where Line is a random effect and 
Populations are fixed and the random Line effect is constant across 
Populations, I have:
measure_ijk = mu + P_i + L_ij + e_ijk where L ~ N(0,s_L)
measure ~ 1 + Population + (1|Population:Line)

(b) If instead I want to allow the random Line effect to be Population 
specific, I put:
measure_ijk = mu + P_i + L_ij + e_ijk where L_i ~ N(0,s_L_i)
measure ~ 1 + Population + (Population | Population:Line)

(c) Question 1:  if instead, I put:
measure ~ 1 + Population + (1 | Population:Line) + (Population | 
Population:Line)
would the model be:
measure_ijk = mu + P_i + L_ij + e_ijk where L_i ~ N(0,s_L_i)+N(0,s_L) ?

(d) Question 2:  in (b) above, the part of the output from 
summary(model) corresponding to (Population | Population:Line) is:

Random effects:
 Groups   Name        Variance   Std.Dev. Corr
 pop:line (Intercept) 52.1214951 7.219522
          popP1       39.5706524 6.290521 0.995
          popP2       24.8629456 4.986276 0.994 0.986
          popP3        0.6350483 0.796899 0.993 0.985 0.982
          popP4        1.4422308 1.200929 0.992 0.986 0.985 0.980
 Residual              0.0025377 0.050375

How do I interpret these contrasts?  If it were fixed effects, it would 
be treatment contrasts which I understand.  Is it a similar thing here 
where the Variance of 39.57 for popP1 is actually:
Variance(popP0 - popP1) = Variance(popP0) + Variance(popP1) - 
2*Corr(popP0,popP1)*StdDev(popP0)*StdDev(popP1)
=> 39.57 = 52.12 + StdDev(popP1)^2 - 2*0.995*7.219522*StdDev(popP1)

(e) Question 3:  For the model (c), there is another line at the top of 
the results with the intercept corresponding to (1|Population:Line). 

Random effects:
 Groups   Name        Variance   Std.Dev. Corr
 pop:line (Intercept)  3.2490952 1.802525
 pop:line (Intercept) 47.1995788 6.870195
e          popP1       44.6401379 6.681328 0.995
          popP2       34.1298102 5.842072 0.994 0.980
          popP3        0.8056185 0.897563 0.991 0.983 0.983
          popP4        2.5663700 1.601989 0.993 0.985 0.985 0.983
 Residual              0.0025374 0.050372

How does this play into the estimates? (I suspect this will become clear 
when I understand the answer to question d)

Thanks much,
Scott Rifkin


From fjbuch at gmail.com  Fri Dec 29 03:21:51 2006
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Thu, 28 Dec 2006 21:21:51 -0500
Subject: [R] Genotypes are not all the same
Message-ID: <bd93cdad0612281821o9979b55v64c76f9c83083658@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061228/9dc6a271/attachment.pl 

From gregor.gorjanc at bfro.uni-lj.si  Fri Dec 29 04:16:28 2006
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Fri, 29 Dec 2006 03:16:28 +0000 (UTC)
Subject: [R] Genotypes are not all the same
References: <bd93cdad0612281821o9979b55v64c76f9c83083658@mail.gmail.com>
Message-ID: <loom.20061229T041400-554@post.gmane.org>

Farrel Buchinsky <fjbuch <at> gmail.com> writes:
> Clearly g1 and g2 are not exactly the same even though they are the same
> class.
> I can make g2 behave as g1 if i type
> g3<-genotype(g2)
> g3 then behaves as it should.
> 
> The issue may have arrisen since g2 is just a subset of a much bigger object
> that was created using reshape command in the base package or maybe melt and
> cast in the reshape package. Can anyone enlighten me?

genotype class behaves internally much like factor class. I guess that
levels/alleles were dropped somewhere. You have to figure out where this 
happened.

Gregor


From Greg.Snow at intermountainmail.org  Fri Dec 29 04:23:35 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 28 Dec 2006 20:23:35 -0700
Subject: [R] sequential row selection in dataframe
References: <83dca7860612252107j60f4836aq6cf3debc1dec4045@mail.gmail.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBB12A0F5@LP-EXCHVS07.CO.IHC.COM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061228/58ed4f88/attachment.pl 

From hustqiufeng at sohu.com  Fri Dec 29 07:01:48 2006
From: hustqiufeng at sohu.com (Feng Qiu)
Date: Fri, 29 Dec 2006 01:01:48 -0500
Subject: [R] How to write string dynamicly?
References: <153111.79503.qm@web56613.mail.re3.yahoo.com>
	<005101c7296a$212df280$bfcc4dc7@Aglog>
	<971536df0612271056t21ef6053ncf81702e3318f2fa@mail.gmail.com>
Message-ID: <003601c72b0e$d996e570$6a6b114c@Aglog>

Hi Gabor:
          Thank you!  But it didn't work. Since lda() takes the variable 
name as the input parameter. So what I was trying to do is "make the name 
dynamically". I used sprintf() to generate a variable name, such as "V16". 
But it seems that the function doesn't recognize the generated name. For 
example, lda(V16,data=mydata) works, But,
lda(sprintf("V%d",k),data=mydata) does not work, where k=16.  So I guess the 
name generated by sprintf is not the parameter wanted. But I have no idea 
about it.

Best,

Feng


----- Original Message ----- 
From: "Gabor Grothendieck" <ggrothendieck at gmail.com>
To: "Feng Qiu" <fqiu at gatech.edu>
Cc: <r-help at stat.math.ethz.ch>
Sent: Wednesday, December 27, 2006 1:56 PM
Subject: Re: [R] How to write string dynamicly?


> Try:
>
> lda(iris[-5], iris[,5])
>
> On 12/26/06, Feng Qiu <fqiu at gatech.edu> wrote:
>> Hi everyone:
>>         I'm trying to compose a string dynamicly for the parameter input 
>> of
>> some function. For example:
>> In package MASS, function lda() require to input the name of predictor
>> variable. Let's say the 16th column is the predictor variable. Then we 
>> call
>> the function like this: lda(V16~., data=mydata). I don't want to 
>> hard-code
>> the call, instead, I would like to use a dynamic expression for this
>> parameter so that I can use my program on different set of data.
>>        I guess there,- are some function that can do this, but I didn't 
>> find
>> it in "Introduction to R" so far, could someone please tell me this kind 
>> of
>> function? Thank you!
>>
>> Best,
>>
>> Feng
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From ggrothendieck at gmail.com  Fri Dec 29 07:44:12 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 29 Dec 2006 01:44:12 -0500
Subject: [R] How to write string dynamicly?
In-Reply-To: <003601c72b0e$d996e570$6a6b114c@Aglog>
References: <153111.79503.qm@web56613.mail.re3.yahoo.com>
	<005101c7296a$212df280$bfcc4dc7@Aglog>
	<971536df0612271056t21ef6053ncf81702e3318f2fa@mail.gmail.com>
	<003601c72b0e$d996e570$6a6b114c@Aglog>
Message-ID: <971536df0612282244g471fff1ep93584c473cde2f37@mail.gmail.com>

Try this:

idx <- match("Species", names(iris))
lda(iris[-idx], iris[,idx])


On 12/29/06, Feng Qiu <hustqiufeng at sohu.com> wrote:
> Hi Gabor:
>          Thank you!  But it didn't work.
> Since lda() takes the variable
> name as the input parameter.

That is not correct.  It takes the variable itself, not its name, as input.

> So what I was trying to do is "make the name
> dynamically". I used sprintf() to generate a variable name, such as "V16".
> But it seems that the function doesn't recognize the generated name. For
> example, lda(V16,data=mydata) works, But,

That is not a valid argument sequence.  See ?lda

> lda(sprintf("V%d",k),data=mydata) does not work, where k=16.  So I guess the
> name generated by sprintf is not the parameter wanted. But I have no idea
> about it.
>
> Best,
>
> Feng
>
>
> ----- Original Message -----
> From: "Gabor Grothendieck" <ggrothendieck at gmail.com>
> To: "Feng Qiu" <fqiu at gatech.edu>
> Cc: <r-help at stat.math.ethz.ch>
> Sent: Wednesday, December 27, 2006 1:56 PM
> Subject: Re: [R] How to write string dynamicly?
>
>
> > Try:
> >
> > lda(iris[-5], iris[,5])
> >
> > On 12/26/06, Feng Qiu <fqiu at gatech.edu> wrote:
> >> Hi everyone:
> >>         I'm trying to compose a string dynamicly for the parameter input
> >> of
> >> some function. For example:
> >> In package MASS, function lda() require to input the name of predictor
> >> variable. Let's say the 16th column is the predictor variable. Then we
> >> call
> >> the function like this: lda(V16~., data=mydata). I don't want to
> >> hard-code
> >> the call, instead, I would like to use a dynamic expression for this
> >> parameter so that I can use my program on different set of data.
> >>        I guess there,- are some function that can do this, but I didn't
> >> find
> >> it in "Introduction to R" so far, could someone please tell me this kind
> >> of
> >> function? Thank you!
> >>
> >> Best,
> >>
> >> Feng
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
>


From ripley at stats.ox.ac.uk  Fri Dec 29 08:18:34 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 29 Dec 2006 07:18:34 +0000 (GMT)
Subject: [R] CV by rpart/mvpart
In-Reply-To: <cdf817830612281318h505c730cy288f00be7e5d747c@mail.gmail.com>
References: <20061228194728.36652.qmail@web27511.mail.ukl.yahoo.com>
	<cdf817830612281318h505c730cy288f00be7e5d747c@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0612290715530.17430@gannet.stats.ox.ac.uk>

On Thu, 28 Dec 2006, Weiwei Shi wrote:

> n-fold cv is easy to be implemented in R by yourself. you can create
> 10 folds' samples by yourself and disable cv in rpart. Then you can
> use the same sample sets to compare different methods.

BUT, rpart uses CV to select the cost-complexity parameter, so you need 
not to disable its internal CV or you are not using rpart.  CV for 
parameter tuning and CV for validation are not the same thing.

There are examples of using n-fold CV for validation, including with 
trees, in MASS4.

>
> HTH
>
> weiwei
>
> On 12/28/06, Pedro Ramirez <palmar379 at yahoo.es> wrote:
>> Dear R-list,
>>
>> I am using the rpart/mvpart-package for selecting a right-sized 
>> regression tree by 10-fold cross-validation. My question: Is there a 
>> possibility to find out for every observation in which of the ten folds 
>> it is lying? I want to use the same folds for validating another 
>> regression method (moving averages) in order to choose the better one.
>>
>> Thanks a lot,
>> Pedro


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From johnwestmason at yahoo.com  Fri Dec 29 08:30:39 2006
From: johnwestmason at yahoo.com (John Mason)
Date: Thu, 28 Dec 2006 23:30:39 -0800 (PST)
Subject: [R] t-test
Message-ID: <861248.93830.qm@web59015.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061228/36645e84/attachment.pl 

From shubhak at ambaresearch.com  Fri Dec 29 09:44:01 2006
From: shubhak at ambaresearch.com (Shubha Vishwanath Karanth)
Date: Fri, 29 Dec 2006 14:14:01 +0530
Subject: [R] R for Reuters
Message-ID: <A36876D3F8A5734FA84A4338135E7CC3BC6875@BAN-MAILSRV03.Amba.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061229/8bbd3c60/attachment.pl 

From p.dalgaard at biostat.ku.dk  Fri Dec 29 09:58:51 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 29 Dec 2006 09:58:51 +0100
Subject: [R] t-test
In-Reply-To: <861248.93830.qm@web59015.mail.re1.yahoo.com>
References: <861248.93830.qm@web59015.mail.re1.yahoo.com>
Message-ID: <4594D8CB.2090103@biostat.ku.dk>

John Mason wrote:
> I have downloaded the latest version of R and continue to have the same problem I did with the previuos version which is that I am unable to run a two-sample t-test in R-commander. I can run a paired t-test and a one sample t-test but not a two-sample t-test or one factor ANOVA. The data have been both imported and entered directly into R-cmdr and I can run regressions and basic data summaries on these data but not the t-tests described above. Any ideas? Windows XP on a Dell built within last year.
>    
>   John
>   
Have you converted your grouping variables to factors? Rcmdr is pretty 
insistent on that point.


From jdnewmil at dcn.davis.ca.us  Fri Dec 29 11:00:34 2006
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 29 Dec 2006 02:00:34 -0800
Subject: [R] BradleyTerry "subscript out of bounds"
Message-ID: <4594E742.3090507@dcn.davis.ca.us>

I don't see the problem with the following... the citations and
baseball data work fine, but my simulated data seems to give
BTm a headache. What am I missing?

---
library(BradleyTerry)
library(doBy)
ng <- 100
players <- factor( sort( c( "jeff", "mike", "paul", "rich" ) ) )
np <- length( players )
p1 <- factor( c( rep( "jeff", ng )
                , rep( levels( players ), np ) )
             , levels=players )
p2 <- factor( c( rep( "mike", ng )
                , rep( levels( players ), each=np ) )
             , levels=players )
p1s <- c( rnorm( n=ng, mean=-0.5, sd=2 ), rep( 1, np^2 ) )
p2s <- c( rnorm( n=ng, mean=0.5, sd=2 ), rep( 0, np^2 ) )
results <- data.frame(
     winner=factor( levels(players)[ ifelse(p1s<p2s,p2,p1)], levels=players )
   , loser=factor( levels(players)[ ifelse(p1s<p2s,p1,p2) ], levels=players)
   , Freq=c( rep( 1, ng ), rep( 1, np^2) ) )
results <- summaryBy(Freq ~ winner + loser, data=results, FUN=c(sum) )
attr(results, "names") <- c( "winner", "loser", "Freq" )
results.btm <- BTm( results ~ .. ) # this spits out an error:
----
Error in BTm(results ~ ..) : subscript out of bounds

 > sessionInfo()
R version 2.0.1, 2004-11-15, i386-pc-linux-gnu

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"

other attached packages:
BradleyTerry         brlr         doBy        Hmisc
      "0.8-5"      "0.8-8"        "1.6"      "3.0-1"

I have also tried this on Windows XP with R version 2.3.1 with same result.
-- 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From unwin at math.uni-augsburg.de  Fri Dec 29 11:19:49 2006
From: unwin at math.uni-augsburg.de (Antony Unwin)
Date: Fri, 29 Dec 2006 11:19:49 +0100
Subject: [R] Help with histograms
Message-ID: <76B1109F-E112-4AF2-B96B-538314E101C2@math.uni-augsburg.de>

The iPlots package provides interactive graphics.  One way to to what  
you want to do would be to create a variable with all values and a  
second binary variable recording which are the 16 special cases.   
Draw an interactive histogram of the first with ihist and an  
interactive barchart of the second with ibar.  Then click on the bar  
for the 16 special cases.

Antony


From hodgess at gator.dt.uh.edu  Fri Dec 29 11:35:39 2006
From: hodgess at gator.dt.uh.edu (Erin Hodgess)
Date: Fri, 29 Dec 2006 04:35:39 -0600
Subject: [R]  strange logical results
Message-ID: <200612291035.kBTAZca3003934@gator.dt.uh.edu>

Dear R People:  

I am getting some odd results when using logical operators:

> x <- seq(from=-1,to=1,by=0.1)

> > x
 [1] -1.0 -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.0  0.1  0.2  0.3  0.4
[16]  0.5  0.6  0.7  0.8  0.9  1.0
> x == -1
 [1]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.9
 [1] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.8
 [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.7
 [1] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.6
 [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.5
 [1] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.4
 [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> 

Should this show as true also, please?

I saw this in both Windows and LINUX Versions 2.4.0

Thanks in advance,
Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu


From ccleland at optonline.net  Fri Dec 29 12:16:00 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 29 Dec 2006 06:16:00 -0500
Subject: [R] strange logical results
In-Reply-To: <200612291035.kBTAZca3003934@gator.dt.uh.edu>
References: <200612291035.kBTAZca3003934@gator.dt.uh.edu>
Message-ID: <4594F8F0.2050302@optonline.net>

Erin Hodgess wrote:
> Dear R People:  
> 
> I am getting some odd results when using logical operators:
> 
>> x <- seq(from=-1,to=1,by=0.1)
> 
>>> x
>  [1] -1.0 -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.0  0.1  0.2  0.3  0.4
> [16]  0.5  0.6  0.7  0.8  0.9  1.0
>> x == -1
>  [1]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>> x == -0.9
>  [1] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>> x == -0.8
>  [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>> x == -0.7
>  [1] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>> x == -0.6
>  [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>> x == -0.5
>  [1] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
> [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>> x == -0.4
>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> 
> Should this show as true also, please?

  They are not exactly equal.  You could use all.equal() to test for
nearly equal.

> x[7] == -0.4
[1] FALSE

> all.equal(x[7], -0.4)
[1] TRUE

> all.equal(x[7], -0.4, tol = 0)
[1] "Mean relative  difference: 2.775558e-16"

> I saw this in both Windows and LINUX Versions 2.4.0
> 
> Thanks in advance,
> Sincerely,
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgess at gator.uhd.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From Bernhard_Pfaff at fra.invesco.com  Fri Dec 29 14:17:20 2006
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Fri, 29 Dec 2006 13:17:20 -0000
Subject: [R] Error message using normality test in vars
In-Reply-To: <4594311D.2080807@education.wisc.edu>
Message-ID: <E4A9111DA23BA048B9A46686BF727CF461BE9C@DEFRAXMB01.corp.amvescap.net>

>
>I'm running a vector-time series model with the vars package.  When I 
>test the univariate and multivariate normality of the residuals using 
>normality(), I get the results, but also this warning
>
>Warning messages:
>1: longer object length
>         is not a multiple of shorter object length in: b2 - rep(3, 4)
>2: longer object length
>         is not a multiple of shorter object length in: b2 - rep(3, 4)
>
>
>What does this mean and do I need to worry about it.
>

Dear David,

thanks for pointing this out. The warning is caused in the calculation
of the kurtosis in function .jb.multi which is contained in
R/internal.R. The relevant expression should be 'rep(3, K)'. An updated
version of package 'vars' will be submitted in due course. I will ship
you version of the corrected package off list.

Best,
Bernhard
*****************************************************************
Confidentiality Note: The information contained in this mess...{{dropped}}


From shuguang at gmail.com  Fri Dec 29 14:28:09 2006
From: shuguang at gmail.com (Sun, Shuguang)
Date: Fri, 29 Dec 2006 21:28:09 +0800
Subject: [R] What's meaning of the lambda in nlrq output
Message-ID: <459517E9.4010208@gmail.com>

I used the nlrq function in the package "quantreg". There is a lambda in
the output when I set trace=TRUE.

With different start point, the results are converged, but the last
lambda is different.
I want to know the meaning "lambda=1" and "lambda=0".

Many Thanks!

Examples of output
1. Where the last lambda=1:
108.6581 :  0.3 8.0
iter    0 value 108.658087
final  value 49.875178
converged
lambda = 0.6304686
49.87518 :  0.3539175 5.6116474
iter    0 value 48.123700
final  value 48.120120
converged
lambda = 0.7646881
48.12012 :  0.4701847 6.4582566
iter    0 value 47.833255
final  value 47.832257
converged
lambda = 0.8588522
47.83226 :  0.5052472 6.8564865
final  value 47.802009
converged
lambda = 1
47.80201 :  0.5257616 7.0207726
iter    0 value 47.776363
final  value 47.747994
stopped after 4 iterations
lambda = 0.5044797
47.74799 :  0.5474859 7.1612348
final  value 47.746067
converged
lambda = 1
47.74607 :  0.5503345 7.1881443
iter    0 value 47.746099
final  value 47.746099
converged
lambda = 0.999864
47.7461 :  0.5502692 7.1879762

2. Where the last lambda=0:
54.16497 :  0.6 8.0
iter    0 value 54.164967
final  value 47.768140
converged
lambda = 0.2133083
47.76814 :  0.5560481 7.2205976
iter    0 value 47.768140
final  value 47.767343
converged
lambda = 0.004997877
47.76734 :  0.5557633 7.2172873
iter    0 value 47.787967
final  value 47.747700
stopped after 3 iterations
lambda = 0.1719594
47.7477 :  0.547935 7.165428
iter    0 value 47.799883
final  value 47.747700
converged
lambda = 0
47.7477 :  0.547935 7.165428


-- 
Shg SUN
@China


From aajakh at yahoo.com  Fri Dec 29 15:00:49 2006
From: aajakh at yahoo.com (ahmad ajakh)
Date: Fri, 29 Dec 2006 06:00:49 -0800 (PST)
Subject: [R] R for Reuters
Message-ID: <20061229140049.83673.qmail@web37902.mail.mud.yahoo.com>

Hi Shubha,
There is no reuter link in R. It does not exist in Splus either nor in matlab.
Apparently this is a legal type of issue from reuter who is keeping its data proprietary.
AA.

----- Original Message ----
From: Shubha Vishwanath Karanth <shubhak at ambaresearch.com>
To: r-help at stat.math.ethz.ch
Sent: Friday, December 29, 2006 3:44:01 AM
Subject: [R] R for Reuters

Can we download data of Reuters from R? Just like we have RBloomberg, do
we have something like RReuters? Is this under the developing stage?


    [[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From therneau at mayo.edu  Fri Dec 29 15:25:09 2006
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 29 Dec 2006 08:25:09 -0600 (CST)
Subject: [R] CV by rpart/mvpart
Message-ID: <200612291425.kBTEP9i05760@hsrnfs-101.mayo.edu>

  The rpart function allows one to give the cross-validation groups explicitly.
So if the number of observations was 10, you could use
   > rpart( y ~ x1 + x2, data=mydata, xval=c(1,1,2,2,3,3,1,3,2,1))
which causes observations 1,2,7, and 10 to be left out of the first xval
sample, 3,4, and 9 out of the second, etc.   

 I was going to write "read the manual page for control.rpart", but it seems
I forgot to put this feature into the documentation!  

	Terry Therneau
	
> On 12/28/06, Pedro Ramirez <palmar379 at yahoo.es> wrote:
>> Dear R-list,
>>
>> I am using the rpart/mvpart-package for selecting a right-sized 
>> regression tree by 10-fold cross-validation. My question: Is there a 
>> possibility to find out for every observation in which of the ten folds 
>> it is lying? I want to use the same folds for validating another 
>> regression method (moving averages) in order to choose the better one.
>>
>> Thanks a lot,
>> Pedro


From tfjbl at mail.uas.alaska.edu  Fri Dec 29 15:39:26 2006
From: tfjbl at mail.uas.alaska.edu (tfjbl at mail.uas.alaska.edu)
Date: Fri, 29 Dec 2006 05:39:26 -0900
Subject: [R] How to debug R program?
Message-ID: <8b6aa8ce93.8ce938b6aa@mail.uas.alaska.edu>

On Loops:
The "apply" coomands are better, faster than loops. If there are lots 
of loops or nested loops then you should be able to replace some of the 
loops with an apply command. If you have nested loops I'd recommend 
replacing loops on the inside first.
R  seems better designed using the apply commands.
It seems to be optimized for memory usage.

I found this especially true when I was doing numerical analysis and/or 
boot strap types of things.

Quotes from help:
Description:

     Returns a vector or array or list of values obtained by applying a
     function to margins of an array.





good luck



>       I wrote a R program which has loops. When I run the program, it 
> crashed. I would like to identify in which loop the pragram crashed, 
how 
> can I debug ?  I'm new to R, could somebody please give me a general 
idea 
> about debugging in R.(I'm a C/C++ programmer and have general 
knowledge 
> about program debugging.)
>      Thank you!
> 
> Best,


From santiagote at gmail.com  Fri Dec 29 16:40:15 2006
From: santiagote at gmail.com (Santiago Cilintano)
Date: Fri, 29 Dec 2006 12:40:15 -0300
Subject: [R] problems with arima()
Message-ID: <cedd6fb60612290740y29a2cf5bw33b0b874aff2750@mail.gmail.com>

Se ha borrado un texto insertado con un juego de caracteres sin especificar...
Nombre: no disponible
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061229/b93e0ffb/attachment.pl 

From Greg.Snow at intermountainmail.org  Fri Dec 29 16:44:00 2006
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 29 Dec 2006 08:44:00 -0700
Subject: [R] strange logical results
Message-ID: <07E228A5BE53C24CAD490193A7381BBB73A43A@LP-EXCHVS07.CO.IHC.COM>

This is FAQ 7.31 in the R FAQ.

Basically computers in general have problems exactly representing all
but a few floating point numbers, so while 2 numbers may look the same
when displayed (rounded to a couple of digits), they are different if
you look at them in full precision due to different roundings.
Functions like all.equal deal with this by checking to see if numbers
are close enough rather than equal.

The general rule is to not expect exact equality between floating point
numbers.  This is a problem for computers in general, not just R.

Hope this helps, 


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Erin Hodgess
Sent: Friday, December 29, 2006 3:36 AM
To: r-help at stat.math.ethz.ch
Subject: [R] strange logical results

Dear R People:  

I am getting some odd results when using logical operators:

> x <- seq(from=-1,to=1,by=0.1)

> > x
 [1] -1.0 -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.0  0.1  0.2
0.3  0.4 [16]  0.5  0.6  0.7  0.8  0.9  1.0
> x == -1
 [1]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.9
 [1] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.8
 [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.7
 [1] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.6
 [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.5
 [1] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE
FALSE [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.4
 [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> 

Should this show as true also, please?

I saw this in both Windows and LINUX Versions 2.4.0

Thanks in advance,
Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences University of Houston -
Downtown
mailto: hodgess at gator.uhd.edu

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From hustqiufeng at sohu.com  Fri Dec 29 16:54:08 2006
From: hustqiufeng at sohu.com (Feng Qiu)
Date: Fri, 29 Dec 2006 10:54:08 -0500
Subject: [R] How to write string dynamicly?
References: <153111.79503.qm@web56613.mail.re3.yahoo.com>
	<005101c7296a$212df280$bfcc4dc7@Aglog>
	<971536df0612271056t21ef6053ncf81702e3318f2fa@mail.gmail.com>
	<003601c72b0e$d996e570$6a6b114c@Aglog>
	<3948d9e50612282249y45baa70bv7c02d361dca75890@mail.gmail.com>
Message-ID: <003001c72b61$9c2e71a0$6a6b114c@Aglog>

Thank you guys,  that works.
I thought the string would first be converted into a formula object in 
lda().
using "paste" and "names"  is much more concise than "sprintf".

Best,

Feng

----- Original Message ----- 
From: "talepanda" <talepanda at gmail.com>
To: "Feng Qiu" <hustqiufeng at sohu.com>
Cc: "Gabor Grothendieck" <ggrothendieck at gmail.com>; 
<r-help at stat.math.ethz.ch>
Sent: Friday, December 29, 2006 1:49 AM
Subject: Re: [R] How to write string dynamicly?


> Try this:
>
> lda(formula(paste(names(iris)[5],"~.")),iris)
>
> You have to create *formula* object from string and pass it to lda().
>
> On 12/29/06, Feng Qiu <hustqiufeng at sohu.com> wrote:
>> Hi Gabor:
>>           Thank you!  But it didn't work. Since lda() takes the variable 
>> name as the input parameter. So what I was trying to do is "make the name 
>> dynamically". I used sprintf() to generate a variable name, such as 
>> "V16". But it seems that the function doesn't recognize the generated 
>> name. For example, lda(V16,data=mydata) works, But,
>> lda(sprintf("V%d",k),data=mydata) does not work, where k=16.  So I guess 
>> the
>> name generated by sprintf is not the parameter wanted. But I have no idea 
>> about it.
>>
>> Best,
>>
>> Feng
>>
>>
>> ----- Original Message ----- 
>> From: "Gabor Grothendieck" <ggrothendieck at gmail.com>
>> To: "Feng Qiu" <fqiu at gatech.edu>
>> Cc: <r-help at stat.math.ethz.ch>
>> Sent: Wednesday, December 27, 2006 1:56 PM
>> Subject: Re: [R] How to write string dynamicly?
>>
>>
>> > Try:
>> >
>> > lda(iris[-5], iris[,5])
>> >
>> > On 12/26/06, Feng Qiu <fqiu at gatech.edu> wrote:
>> >> Hi everyone:
>> >>         I'm trying to compose a string dynamicly for the parameter 
>> >> input of
>> >> some function. For example:
>> >> In package MASS, function lda() require to input the name of predictor
>> >> variable. Let's say the 16th column is the predictor variable. Then we 
>> >> call
>> >> the function like this: lda(V16~., data=mydata). I don't want to 
>> >> hard-code
>> >> the call, instead, I would like to use a dynamic expression for this
>> >> parameter so that I can use my program on different set of data.
>> >>        I guess there,- are some function that can do this, but I 
>> >> didn't find
>> >> it in "Introduction to R" so far, could someone please tell me this 
>> >> kind of
>> >> function? Thank you!
>> >>
>> >> Best,
>> >>
>> >> Feng
>> >>
>> >> ______________________________________________
>> >> R-help at stat.math.ethz.ch mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide 
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


From klijunjie at gmail.com  Fri Dec 29 18:54:33 2006
From: klijunjie at gmail.com (=?GB2312?B?wO6/ob3c?=)
Date: Sat, 30 Dec 2006 01:54:33 +0800
Subject: [R] Why giving negative density when doing kernel density estimate?
Message-ID: <dff718fc0612290954v42ab27b5x336bef6ce9fffbf9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061230/d179a14a/attachment.pl 

From ssj1364 at gmail.com  Fri Dec 29 19:15:07 2006
From: ssj1364 at gmail.com (sj)
Date: Fri, 29 Dec 2006 11:15:07 -0700
Subject: [R]  coded to categorical variables in a large dataset
Message-ID: <1c6126db0612291015k5f0e9ef1r968d91488a7fe81c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061229/1ee479fd/attachment.pl 

From ccleland at optonline.net  Fri Dec 29 19:27:57 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 29 Dec 2006 13:27:57 -0500
Subject: [R] coded to categorical variables in a large dataset
In-Reply-To: <1c6126db0612291015k5f0e9ef1r968d91488a7fe81c@mail.gmail.com>
References: <1c6126db0612291015k5f0e9ef1r968d91488a7fe81c@mail.gmail.com>
Message-ID: <45955E2D.9040002@optonline.net>

sj wrote:
> I am working with a dataset where there are 5 possible outcomes (coded 1:5),
> I would like to create 5 categorical variables (event1...event5). I am using
> a for loop an if statements, but I have a large dataset( approx 100,000
> rows) it takes quite a bit of time, is there a way to speed this up? Here is
> some sample code of what I am currently doing.

  Here is one way you might do it:

X <- sample(1:5, 100, replace=TRUE)

# Your 5 event variables in a matrix
model.matrix(lm(rnorm(length(X)) ~ as.factor(X) - 1))

  Also, along the lines of your approach below, the following using
ifelse() might be better:

event3 <- ifelse(test2 == 3, 1, 0)

  I'm sure other people will post different solutions probably more
elegant than these.

> test2 <-rep(seq(1:5),2000)
> 
> event1 <- rep(0,nrow(test2))
> event2 <- rep(0,nrow(test2))
> event3 <- rep(0,nrow(test2))
> event4 <- rep(0,nrow(test2))
> event5 <- rep(0,nrow(test2))
> 
> for(i in 1:length(event1))
> {
>     if (test2[i]==1)
>     {
>         event1[i]=1
>     }
> 
>     if (test2[i]==2)
>     {
>         event2[i]=1
>     }
> 
>     if (test2[i]==3)
>     {
>         event3[i]=1
>     }
> 
>     if (test2[i]==4)
>     {
>         event4[i]=1
>     }
> 
>     if (test2[i]==5)
>     {
>         event5[i]=1
>     }
> }
> 
> 
> 
> thanks,
> 
> Spencer
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From rmh at temple.edu  Fri Dec 29 20:11:14 2006
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 29 Dec 2006 14:11:14 -0500 (EST)
Subject: [R] coded to categorical variables in a large dataset
Message-ID: <20061229141114.BQX86597@po-d.temple.edu>

## The main reason for wanting such a coding is to use it in
## a linear model.  Therefore, declare the variable to be a factor
## and use it directly.


tmp <- sample(1:5, 40, replace=TRUE)
tmpf <- factor(tmp)
tmp.y <- rnorm(40)

tmp.aov <- aov(tmp.y ~ tmpf)
summary(tmp.aov)

contrasts(tmpf)

update(tmp.aov, x=TRUE)$x[1:6,]

## If you really want to see the redundant column 1 of
## of the contrasts, that can be done with the statement

contrasts(tmpf)
contrasts(tmpf, how.many=5) <- contr.treatment(5, contrasts=FALSE)
contrasts(tmpf)

tmp2.aov <- aov(tmp.y ~ tmpf)
summary(tmp2.aov)
update(tmp2.aov, x=TRUE)$x[1:6,]


From jholtman at gmail.com  Fri Dec 29 20:14:48 2006
From: jholtman at gmail.com (jim holtman)
Date: Fri, 29 Dec 2006 14:14:48 -0500
Subject: [R] coded to categorical variables in a large dataset
In-Reply-To: <1c6126db0612291015k5f0e9ef1r968d91488a7fe81c@mail.gmail.com>
References: <1c6126db0612291015k5f0e9ef1r968d91488a7fe81c@mail.gmail.com>
Message-ID: <644e1f320612291114k7e98fcd1pc0f2662af2b2259e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061229/b476d7c2/attachment.pl 

From gzhu at peak6.com  Fri Dec 29 20:16:28 2006
From: gzhu at peak6.com (Geoffrey Zhu)
Date: Fri, 29 Dec 2006 13:16:28 -0600
Subject: [R] Difference of array and vector
Message-ID: <99F81FFD0EA54E4DA8D4F1BFE272F3410304328A@ppi-mail1.chicago.peak6.net>

Hi,

I am really new at R. Does anyone know what is the real difference of
vector and array, except that many operations that expect an array does
not work on a vector?

Thanks,
Geoffrey

_______________________________________________________=0A=
=0A=
=0A=
The information in this email or in any file attached hereto is=0A=
intended only for the personal and confidential use of the individual=0A=
or entity to which it is addressed and may contain information that is=0A=
proprietary and confidential. If you are not the intended recipient of=0A=
this message you are hereby notified that any review, dissemination,=0A=
distribution or copying of this message is strictly prohibited. This communi=
cation is for information purposes only and should not be regarded as an off=
er to sell or as a solicitation of an offer to buy any financial product. Em=
ail transmission cannot be guaranteed to be secure or error-free.


From ggrothendieck at gmail.com  Fri Dec 29 20:40:47 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 29 Dec 2006 14:40:47 -0500
Subject: [R] coded to categorical variables in a large dataset
In-Reply-To: <1c6126db0612291015k5f0e9ef1r968d91488a7fe81c@mail.gmail.com>
References: <1c6126db0612291015k5f0e9ef1r968d91488a7fe81c@mail.gmail.com>
Message-ID: <971536df0612291140w34dfc4f3m2ede9354af71f16c@mail.gmail.com>

As Richard has already pointed out you may only need to convert your
numeric vector to a factor but just in case here are a few direct answers:


Using X from Chuck's post here are two ways of creating a 100x5
matrix of indicator variables:

model.matrix(~ X-1, list(X = factor(X)))
outer(X, 1:5, "==")+0

# To create eventi variables
# here is a way of creating them

event1 <- (X == 1) + 0 # and similarly for 2, 3, 4, 5

# or do it in a loop
for(i in 1:5) assign(paste("event", i, sep = ""), (X == i) + 0)

# or create as columns of a data frame
f <- function(i, j) (X == j) + 0
as.data.frame(mapply(f, paste("event", 1:5, sep = ""), 1:5))



On 12/29/06, sj <ssj1364 at gmail.com> wrote:
> I am working with a dataset where there are 5 possible outcomes (coded 1:5),
> I would like to create 5 categorical variables (event1...event5). I am using
> a for loop an if statements, but I have a large dataset( approx 100,000
> rows) it takes quite a bit of time, is there a way to speed this up? Here is
> some sample code of what I am currently doing.
>
> test2 <-rep(seq(1:5),2000)
>
> event1 <- rep(0,nrow(test2))
> event2 <- rep(0,nrow(test2))
> event3 <- rep(0,nrow(test2))
> event4 <- rep(0,nrow(test2))
> event5 <- rep(0,nrow(test2))
>
> for(i in 1:length(event1))
> {
>    if (test2[i]==1)
>    {
>        event1[i]=1
>    }
>
>    if (test2[i]==2)
>    {
>        event2[i]=1
>    }
>
>    if (test2[i]==3)
>    {
>        event3[i]=1
>    }
>
>    if (test2[i]==4)
>    {
>        event4[i]=1
>    }
>
>    if (test2[i]==5)
>    {
>        event5[i]=1
>    }
> }
>
>
>
> thanks,
>
> Spencer
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mike.prager at noaa.gov  Fri Dec 29 20:52:50 2006
From: mike.prager at noaa.gov (Mike Prager)
Date: Fri, 29 Dec 2006 14:52:50 -0500
Subject: [R] OT: any recommendation for scripting language
References: <1115a2b00612230756g7cf6fd0emcbec62b832402d05@mail.gmail.com>
Message-ID: <fasap2tcj59sivcpfgpbop8225u3l9auiu@4ax.com>

"Wensui Liu" <liuwensui at gmail.com> wrote:

> Right now, I am using SAS and S+/R. As a new year resolution, I am
> planning to learn a scripting language.
> 
> from statisticians' point of view, which scripting language is worth
> to learn, perl, python, or any other recommendation? (Most likely, I
> will be learning it in windows.) Since I am not in research, I will
> prefer one widely used in industry and related to statistical work.

I would second the recommendation by John Bollinger to look into
Python.  I haven't used Ruby, so I can't compare the two
languages, but compared to Perl, Python has is considerably
easier to understand and maintain. The language is widely used
and is available on several platforms.   The Python Web site
includes tutorials, and the download includes an IDE with an
interface to extensive help files.

http://www.python.org/


-- 
Mike Prager, NOAA, Beaufort, NC
* Opinions expressed are personal and not represented otherwise.
* Any use of tradenames does not constitute a NOAA endorsement.


From kubovy at virginia.edu  Fri Dec 29 21:08:36 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Fri, 29 Dec 2006 15:08:36 -0500
Subject: [R] Difference of array and vector
In-Reply-To: <99F81FFD0EA54E4DA8D4F1BFE272F3410304328A@ppi-mail1.chicago.peak6.net>
References: <99F81FFD0EA54E4DA8D4F1BFE272F3410304328A@ppi-mail1.chicago.peak6.net>
Message-ID: <E770E5A1-053B-4FB3-B290-B984350536C0@virginia.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061229/522c5e30/attachment.pl 

From topkatz at msn.com  Fri Dec 29 21:33:05 2006
From: topkatz at msn.com (Talbot Katz)
Date: Fri, 29 Dec 2006 15:33:05 -0500
Subject: [R] Failure loading library into second R 2.3.1 session on Windows
	XP
Message-ID: <BAY132-F4AF091C5FB8640F5FAFE6AAC60@phx.gbl>

Hi.

I am using R 2.3.1 on Windows XP.  I had installed a library package into my 
first session and wanted the same package in my second session, so I went 
out to the CRAN mirror and tried to install the package, and got the 
following message:

*********************************************************************

>utils:::menuInstallPkgs()
trying URL 
'http://cran.ssds.ucdavis.edu/bin/windows/contrib/2.3/corpcor_1.4.4.zip'
Content type 'application/zip' length 133068 bytes
opened URL
downloaded 129Kb

package 'corpcor' successfully unpacked and MD5 sums checked
Warning: cannot remove prior installation of package 'corpcor'

The downloaded packages are in
        C:\Documents and Settings\Talbot\Local 
Settings\Temp\RtmplCxarb\downloaded_packages
updating HTML package descriptions
>library(corpcor)
Error in library(corpcor) : there is no package called 'corpcor'

*********************************************************************


After rebooting my machine, I dug into this a little further.  Upon 
installing a package from a CRAN mirror, it seems to stay on my hard drive, 
and I can load it in subsequent sessions from the "Load package..." menu 
without going back to get it from a CRAN mirror.  However, if I do happen to 
retrieve it again from a CRAN mirror, it appears that may corrupt the 
version that was saved, and it no longer will be available from the "Load 
package..." menu.  A reboot and re-retrieval of the package makes it 
available again; I don't know whether there's any less drastic solution.

This behavior doesn't occur with every package, but I have experienced it 
with two different packages (corpcor and copula), so there seems to be 
something going on.  I didn't see anything in the FAQ page about this, I 
wonder if anyone can tell me more about this issue.

Thanks!


--  TMK  --
212-460-5430	home
917-656-5351	cell


From damerdji at gmail.com  Fri Dec 29 22:16:35 2006
From: damerdji at gmail.com (Halim Damerdji)
Date: Fri, 29 Dec 2006 13:16:35 -0800
Subject: [R] installation problems
Message-ID: <928aa1b70612291316y52247cf6kf016e83269d4f1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061229/e5c2caf1/attachment.pl 

From ligges at statistik.uni-dortmund.de  Fri Dec 29 22:57:22 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 29 Dec 2006 22:57:22 +0100
Subject: [R] installation problems
In-Reply-To: <928aa1b70612291316y52247cf6kf016e83269d4f1@mail.gmail.com>
References: <928aa1b70612291316y52247cf6kf016e83269d4f1@mail.gmail.com>
Message-ID: <45958F42.1000201@statistik.uni-dortmund.de>



Halim Damerdji wrote:
> Hi,
> 
> I installed R-2.4.0 and R-2.4.1 on linux redhat (RHEL 3.0), and am
> encountering the following messages below. I searched the R FAQs and over
> the net, but couldn't find helpful information.
> 
> When I "check-all" I do see some diff's (e.g., for "stats", nls.Rout and
> nls.Rout.save in tests/stats.Rcheck/tests; "cluster"; and "rpart'). I don't
> know if this is relevant.

Minor differences due to numerical inaccuracies in the last digits are 
expected.

For the error below: You have probably some old workspace or a library 
with outdated packages around. Delete and try again.

Best,
Uwe Ligges

> 
> I have no problem with R-2.0.1, which I installed 1 1/2 years ago, and the
> Windows  version.  But I would like to use the recent versions.
> 
> I would greatly appreciate any help. Thanks in advance.
> 
> -Halim Damerdji
> 
> 
> 
> % path_to_R_script/R
> R version 2.4.0 (2006-10-03)
> Copyright (C) 2006 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> == etc.
> Type 'q()' to quit R.
> 
> Error in `parent.env<-`(`*tmp*`, value = NULL) :
>     use of NULL environment is defunct
> == twice
> In addition: Warning message:
> package utils in options("defaultPackages") was not found
> Error in `parent.env<-`(`*tmp*`, value = NULL) :
>     use of NULL environment is defunct
> == same for graphics
> In addition: Warning message:
> package stats in options("defaultPackages") was not found
> == same for methods
> 
>> help()
> Error : Could not find function "help"
>> x <- rnorm(20)
> Error : Could not find function "rnorm"
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From fjbuch at gmail.com  Fri Dec 29 23:02:35 2006
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Fri, 29 Dec 2006 17:02:35 -0500
Subject: [R] Difference of array and vector
References: <99F81FFD0EA54E4DA8D4F1BFE272F3410304328A@ppi-mail1.chicago.peak6.net>
	<E770E5A1-053B-4FB3-B290-B984350536C0@virginia.edu>
Message-ID: <en438v$jsi$1@sea.gmane.org>

I had had problems getting my head around what an array was as opposed to a 
data frame and where vectors fitted into the two.
I found a useful URL on the same website eluded to below.
http://www.burns-stat.com/pages/Tutor/unwilling_S.pdf
Go to the heading "The Look and Feel of Objects"

Farrel

"Michael Kubovy" <kubovy at virginia.edu> wrote in message 
news:E770E5A1-053B-4FB3-B290-B984350536C0 at virginia.edu...
> # Here's a vector:
> letv <- letters
> is.vector(letv)
>
> # Here's an array:
> leta <- as.array(letters)
> is.array(leta)
> attributes(letv)
> attributes(leta)
>
> To understand the importance of attributes:
> http://www.burns-stat.com/pages/Spoetry/essentials.pdf
> There Burns writes (p. 3):
> "An S array is merely a vector that has a dim attribute, and
> optionally a dimnames attribute."
> _____________________________
> Professor Michael Kubovy
> University of Virginia
> Department of Psychology
> USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
> Parcels:    Room 102        Gilmer Hall
>         McCormick Road    Charlottesville, VA 22903
> Office:    B011    +1-434-982-4729
> Lab:        B019    +1-434-982-4751
> Fax:        +1-434-982-4766
> WWW:    http://www.people.virginia.edu/~mk9y/
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.uni-dortmund.de  Fri Dec 29 23:05:15 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 29 Dec 2006 23:05:15 +0100
Subject: [R] Failure loading library into second R 2.3.1 session on
 Windows XP
In-Reply-To: <BAY132-F4AF091C5FB8640F5FAFE6AAC60@phx.gbl>
References: <BAY132-F4AF091C5FB8640F5FAFE6AAC60@phx.gbl>
Message-ID: <4595911B.9070905@statistik.uni-dortmund.de>

You can only expect that update / reinstall a ***package*** works if you 
have not yet loaded it into your R session.
Hence close R, start it without loading the relevant package and then 
update/reinstall.

Best,
Uwe Ligges


Talbot Katz wrote:
> Hi.
> 
> I am using R 2.3.1 on Windows XP.  I had installed a library package into my 
> first session and wanted the same package in my second session, so I went 
> out to the CRAN mirror and tried to install the package, and got the 
> following message:
> 
> *********************************************************************
> 
>> utils:::menuInstallPkgs()
> trying URL 
> 'http://cran.ssds.ucdavis.edu/bin/windows/contrib/2.3/corpcor_1.4.4.zip'
> Content type 'application/zip' length 133068 bytes
> opened URL
> downloaded 129Kb
> 
> package 'corpcor' successfully unpacked and MD5 sums checked
> Warning: cannot remove prior installation of package 'corpcor'
> 
> The downloaded packages are in
>         C:\Documents and Settings\Talbot\Local 
> Settings\Temp\RtmplCxarb\downloaded_packages
> updating HTML package descriptions
>> library(corpcor)
> Error in library(corpcor) : there is no package called 'corpcor'
> 
> *********************************************************************
> 
> 
> After rebooting my machine, I dug into this a little further.  Upon 
> installing a package from a CRAN mirror, it seems to stay on my hard drive, 
> and I can load it in subsequent sessions from the "Load package..." menu 
> without going back to get it from a CRAN mirror.  However, if I do happen to 
> retrieve it again from a CRAN mirror, it appears that may corrupt the 
> version that was saved, and it no longer will be available from the "Load 
> package..." menu.  A reboot and re-retrieval of the package makes it 
> available again; I don't know whether there's any less drastic solution.
> 
> This behavior doesn't occur with every package, but I have experienced it 
> with two different packages (corpcor and copula), so there seems to be 
> something going on.  I didn't see anything in the FAQ page about this, I 
> wonder if anyone can tell me more about this issue.
> 
> Thanks!
> 
> 
> --  TMK  --
> 212-460-5430	home
> 917-656-5351	cell
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ssj1364 at gmail.com  Fri Dec 29 23:37:06 2006
From: ssj1364 at gmail.com (sj)
Date: Fri, 29 Dec 2006 15:37:06 -0700
Subject: [R]  Survfit with a coxph object
Message-ID: <1c6126db0612291437x4e4dc04ajc71a4780a970175@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061229/f602ef9a/attachment.pl 

From topkatz at msn.com  Sat Dec 30 00:00:15 2006
From: topkatz at msn.com (Talbot Katz)
Date: Fri, 29 Dec 2006 18:00:15 -0500
Subject: [R] Failure loading library into second R 2.3.1 session on
	Windows XP
In-Reply-To: <4595911B.9070905@statistik.uni-dortmund.de>
Message-ID: <BAY132-F40F95224C46C04923ACF95AAC60@phx.gbl>

Hi Uwe.

Thank you so much for responding!  I guess I wasn't entirely clear about the 
problem.  If I make the mistake of trying to install a package from CRAN in 
a second session after I've already installed it in a previous session, it 
won't install in the second session, and even if I close the second session 
and open a subsequent newer session, it won't install in that one either.  
At least, I can't figure out how to do it, because it's no longer in the 
"Load packages..." menu, and if I load it from CRAN, I get that funny error 
message:
	Warning: cannot remove prior installation of package 'corpcor'

Now, after having gone through this, I know enough not to reload a package 
from CRAN.  But it appears that the only ways to solve the problem, if it 
occurs, are pretty drastic, either reboot the machine (which is what I did) 
or reinstall R (which seems to be what you're suggesting?).  I was hoping 
that there might be a better alternative, or at least that the development 
team might look into this issue for future releases.  This doesn't affect 
every package, but I've seen it in the first two packages I tried it with.

--  TMK  --
212-460-5430	home
917-656-5351	cell



>From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
>To: Talbot Katz <topkatz at msn.com>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] Failure loading library into second R 2.3.1 session on 
>Windows XP
>Date: Fri, 29 Dec 2006 23:05:15 +0100
>
>You can only expect that update / reinstall a ***package*** works if you 
>have not yet loaded it into your R session.
>Hence close R, start it without loading the relevant package and then 
>update/reinstall.
>
>Best,
>Uwe Ligges
>
>
>Talbot Katz wrote:
>>Hi.
>>
>>I am using R 2.3.1 on Windows XP.  I had installed a library package into 
>>my first session and wanted the same package in my second session, so I 
>>went out to the CRAN mirror and tried to install the package, and got the 
>>following message:
>>
>>*********************************************************************
>>
>>>utils:::menuInstallPkgs()
>>trying URL 
>>'http://cran.ssds.ucdavis.edu/bin/windows/contrib/2.3/corpcor_1.4.4.zip'
>>Content type 'application/zip' length 133068 bytes
>>opened URL
>>downloaded 129Kb
>>
>>package 'corpcor' successfully unpacked and MD5 sums checked
>>Warning: cannot remove prior installation of package 'corpcor'
>>
>>The downloaded packages are in
>>         C:\Documents and Settings\Talbot\Local 
>>Settings\Temp\RtmplCxarb\downloaded_packages
>>updating HTML package descriptions
>>>library(corpcor)
>>Error in library(corpcor) : there is no package called 'corpcor'
>>
>>*********************************************************************
>>
>>
>>After rebooting my machine, I dug into this a little further.  Upon 
>>installing a package from a CRAN mirror, it seems to stay on my hard 
>>drive, and I can load it in subsequent sessions from the "Load package..." 
>>menu without going back to get it from a CRAN mirror.  However, if I do 
>>happen to retrieve it again from a CRAN mirror, it appears that may 
>>corrupt the version that was saved, and it no longer will be available 
>>from the "Load package..." menu.  A reboot and re-retrieval of the package 
>>makes it available again; I don't know whether there's any less drastic 
>>solution.
>>
>>This behavior doesn't occur with every package, but I have experienced it 
>>with two different packages (corpcor and copula), so there seems to be 
>>something going on.  I didn't see anything in the FAQ page about this, I 
>>wonder if anyone can tell me more about this issue.
>>
>>Thanks!
>>
>>
>>--  TMK  --
>>212-460-5430	home
>>917-656-5351	cell
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide 
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From cberry at tajo.ucsd.edu  Sat Dec 30 00:25:55 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Fri, 29 Dec 2006 15:25:55 -0800
Subject: [R] coded to categorical variables in a large dataset
In-Reply-To: <1c6126db0612291015k5f0e9ef1r968d91488a7fe81c@mail.gmail.com>
References: <1c6126db0612291015k5f0e9ef1r968d91488a7fe81c@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0612291511470.24622@tajo.ucsd.edu>

On Fri, 29 Dec 2006, sj wrote:

> I am working with a dataset where there are 5 possible outcomes (coded 1:5),
> I would like to create 5 categorical variables (event1...event5). I am using
> a for loop an if statements, but I have a large dataset( approx 100,000
> rows) it takes quite a bit of time, is there a way to speed this up? Here is
> some sample code of what I am currently doing.
>
> test2 <-rep(seq(1:5),2000)
>
[...]

As Richard suggested you may not want to do this at all, but ...

If you want these as a matrix, this is fast and direct:

 	mat <- diag(5)[ test2, ]

If not as a matrix

 	event1 <- as.numeric( test2 == 1 )

is concise and

 	for (i in 1:5) assign(paste("event",i,sep=""), as.numeric( test2==i ))

is about as fast as you can get.

HTH,

Chuck


Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717


From Bill.Venables at csiro.au  Sat Dec 30 01:02:35 2006
From: Bill.Venables at csiro.au (Bill.Venables at csiro.au)
Date: Sat, 30 Dec 2006 10:02:35 +1000
Subject: [R] strange logical results
Message-ID: <B998A44C8986644EA8029CFE6396A924840A90@exqld2-bne.qld.csiro.au>

Hi Erin,

You would be safe on a machine that represented floating point numbers
in base 10, and I haven't seen one of those for such a long time... All
modern machines use base 2 for floating point numbers.

The moral of the story is not to believe what you see printed.  The
number you see printed innocently as '-0.4' has been arrived at by two
different processes and uses two different *approximations* to the real
thing on a binary machine, and my chance they have arrived at a slightly
different result.  Slight, but enough to make '==' ring the alarm.  Here
is a demo.

> x <- seq(-1,1,by=0.1)
> x[7] - (-0.4)
[1] 1.110223e-16

So the method used by seq() to arrive at an approximation to -0.4 is
just slightly different from the method used by the parser when it reads
the characters '-0.4' and translates them into a floating point number.
It just so happens that for the others you checked the two
approximations agreed, but you can't trust that to happen all the time.

Moral of the story: don't use the '==' or '!=' operators with floating
point numbers.  It's an old tale but still current.

OK, so what can you do to implement the idea of checking equality
'within a tolerance'?  I'm glad you asked.  You can write a couple of
binary operators yourself.  There is an object called .Machine that is a
list of machine constants.  The obvious one to compare the difference
with is .Machine$double.eps

> `%~=%` <- function(a, b) abs(a - b) < .Machine$double.eps
> `%~!%` <- function(a, b) abs(a - b) > .Machine$double.eps
> x %~=% -0.4
 [1] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE
FALSE FALSE FALSE
[15] FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x %~!% -0.4
 [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE
TRUE  TRUE  TRUE
[15]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE

The world is approximately sane once more.

Bill Venables.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Erin Hodgess
Sent: Friday, 29 December 2006 8:36 PM
To: r-help at stat.math.ethz.ch
Subject: [R] strange logical results

Dear R People:  

I am getting some odd results when using logical operators:

> x <- seq(from=-1,to=1,by=0.1)

> > x
 [1] -1.0 -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.0  0.1  0.2
0.3  0.4
[16]  0.5  0.6  0.7  0.8  0.9  1.0
> x == -1
 [1]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.9
 [1] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.8
 [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.7
 [1] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.6
 [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.5
 [1] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE
FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> x == -0.4
 [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> 

Should this show as true also, please?

I saw this in both Windows and LINUX Versions 2.4.0

Thanks in advance,
Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From hb at stat.berkeley.edu  Sat Dec 30 01:02:41 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Sat, 30 Dec 2006 11:02:41 +1100
Subject: [R] Failure loading library into second R 2.3.1 session on
	Windows XP
In-Reply-To: <BAY132-F40F95224C46C04923ACF95AAC60@phx.gbl>
References: <4595911B.9070905@statistik.uni-dortmund.de>
	<BAY132-F40F95224C46C04923ACF95AAC60@phx.gbl>
Message-ID: <59d7961d0612291602h1dd3126ew1df9a06cbfdb7e3@mail.gmail.com>

Hi,

it sounds like you mixing up the words "install" and "load".
Basically, you only have to *install* a package once on your computer,
but have to load it for every R session which you are going to use it
in.

So, in your case install it once, using either

 install.packages("corpcor")

or the corresponding menu in RGui (on Windows), and then use

 library(corpcor)

every time you want to *load* the package (typically once per R session).

See "An Introduction to R" for further explainations.

Details: When you try to install a package a second time the previous
installation is overwritten. However, if another R session has the
same package loaded, some of the files of the package might be looked,
and won't be released until the package is unloaded or you quit the R
session.  Thus, when you try to install the package a second time (in
another R session or even the same) it will not work.  This is
expected.

Hope this helps

Henrik


On 12/30/06, Talbot Katz <topkatz at msn.com> wrote:
> Hi Uwe.
>
> Thank you so much for responding!  I guess I wasn't entirely clear about the
> problem.  If I make the mistake of trying to install a package from CRAN in
> a second session after I've already installed it in a previous session, it
> won't install in the second session, and even if I close the second session
> and open a subsequent newer session, it won't install in that one either.
> At least, I can't figure out how to do it, because it's no longer in the
> "Load packages..." menu, and if I load it from CRAN, I get that funny error
> message:
>         Warning: cannot remove prior installation of package 'corpcor'
>
> Now, after having gone through this, I know enough not to reload a package
> from CRAN.  But it appears that the only ways to solve the problem, if it
> occurs, are pretty drastic, either reboot the machine (which is what I did)
> or reinstall R (which seems to be what you're suggesting?).  I was hoping
> that there might be a better alternative, or at least that the development
> team might look into this issue for future releases.  This doesn't affect
> every package, but I've seen it in the first two packages I tried it with.
>
> --  TMK  --
> 212-460-5430    home
> 917-656-5351    cell
>
>
>
> >From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
> >To: Talbot Katz <topkatz at msn.com>
> >CC: r-help at stat.math.ethz.ch
> >Subject: Re: [R] Failure loading library into second R 2.3.1 session on
> >Windows XP
> >Date: Fri, 29 Dec 2006 23:05:15 +0100
> >
> >You can only expect that update / reinstall a ***package*** works if you
> >have not yet loaded it into your R session.
> >Hence close R, start it without loading the relevant package and then
> >update/reinstall.
> >
> >Best,
> >Uwe Ligges
> >
> >
> >Talbot Katz wrote:
> >>Hi.
> >>
> >>I am using R 2.3.1 on Windows XP.  I had installed a library package into
> >>my first session and wanted the same package in my second session, so I
> >>went out to the CRAN mirror and tried to install the package, and got the
> >>following message:
> >>
> >>*********************************************************************
> >>
> >>>utils:::menuInstallPkgs()
> >>trying URL
> >>'http://cran.ssds.ucdavis.edu/bin/windows/contrib/2.3/corpcor_1.4.4.zip'
> >>Content type 'application/zip' length 133068 bytes
> >>opened URL
> >>downloaded 129Kb
> >>
> >>package 'corpcor' successfully unpacked and MD5 sums checked
> >>Warning: cannot remove prior installation of package 'corpcor'
> >>
> >>The downloaded packages are in
> >>         C:\Documents and Settings\Talbot\Local
> >>Settings\Temp\RtmplCxarb\downloaded_packages
> >>updating HTML package descriptions
> >>>library(corpcor)
> >>Error in library(corpcor) : there is no package called 'corpcor'
> >>
> >>*********************************************************************
> >>
> >>
> >>After rebooting my machine, I dug into this a little further.  Upon
> >>installing a package from a CRAN mirror, it seems to stay on my hard
> >>drive, and I can load it in subsequent sessions from the "Load package..."
> >>menu without going back to get it from a CRAN mirror.  However, if I do
> >>happen to retrieve it again from a CRAN mirror, it appears that may
> >>corrupt the version that was saved, and it no longer will be available
> >>from the "Load package..." menu.  A reboot and re-retrieval of the package
> >>makes it available again; I don't know whether there's any less drastic
> >>solution.
> >>
> >>This behavior doesn't occur with every package, but I have experienced it
> >>with two different packages (corpcor and copula), so there seems to be
> >>something going on.  I didn't see anything in the FAQ page about this, I
> >>wonder if anyone can tell me more about this issue.
> >>
> >>Thanks!
> >>
> >>
> >>--  TMK  --
> >>212-460-5430  home
> >>917-656-5351  cell
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide
> >>http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From damerdji at gmail.com  Sat Dec 30 02:18:22 2006
From: damerdji at gmail.com (Halim Damerdji)
Date: Fri, 29 Dec 2006 17:18:22 -0800
Subject: [R] installation problems
In-Reply-To: <45958F42.1000201@statistik.uni-dortmund.de>
References: <928aa1b70612291316y52247cf6kf016e83269d4f1@mail.gmail.com>
	<45958F42.1000201@statistik.uni-dortmund.de>
Message-ID: <928aa1b70612291718w1266f164h305a11a89d043766@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061229/8c3f3082/attachment.pl 

From spluque at gmail.com  Sat Dec 30 06:17:15 2006
From: spluque at gmail.com (Sebastian P. Luque)
Date: Fri, 29 Dec 2006 23:17:15 -0600
Subject: [R] wrapping mle()
Message-ID: <8764buj738.fsf@patagonia.sebmags.homelinux.org>

Hi,

How can we set the environment for the minuslog function in mle()?  The
call in this code fails because the "ll" function cannot find the object
'y'.  Modifying from the example in ?mle:


library(stats4)
ll <- function(ymax=15, xhalf=6) {
    -sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))
}
fit.mle <- function(FUN, x, y) {
    loglik.fun <- match.fun(FUN)
    mle(loglik.fun, method="L-BFGS-B", lower=c(0, 0))
}
fit.mle("ll", x=0:10, y=c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8))


How should "fit.mle" be constructed so that "ll" works on the appropriate
environment?  Thanks in advance for any advice on this.


-- 
Seb


From ggrothendieck at gmail.com  Sat Dec 30 06:30:23 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 30 Dec 2006 00:30:23 -0500
Subject: [R] wrapping mle()
In-Reply-To: <8764buj738.fsf@patagonia.sebmags.homelinux.org>
References: <8764buj738.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <971536df0612292130g26ac8286k4df7c5499c97e609@mail.gmail.com>

Add the line marked ### so that the environment of loglik.fun is reset to
the environment within fit.mle so that it can find y there:

library(stats4)
ll <- function(ymax=15, xhalf=6) {
   -sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))
}
fit.mle <- function(FUN, x, y) {
   loglik.fun <- match.fun(FUN)
   environment(loglik.fun) <- environment() ###
   mle(loglik.fun, method="L-BFGS-B", lower=c(0, 0))
}
fit.mle("ll", x=0:10, y=c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8))



On 12/30/06, Sebastian P. Luque <spluque at gmail.com> wrote:
> Hi,
>
> How can we set the environment for the minuslog function in mle()?  The
> call in this code fails because the "ll" function cannot find the object
> 'y'.  Modifying from the example in ?mle:
>
>
> library(stats4)
> ll <- function(ymax=15, xhalf=6) {
>    -sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))
> }
> fit.mle <- function(FUN, x, y) {
>    loglik.fun <- match.fun(FUN)
>    mle(loglik.fun, method="L-BFGS-B", lower=c(0, 0))
> }
> fit.mle("ll", x=0:10, y=c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8))
>
>
> How should "fit.mle" be constructed so that "ll" works on the appropriate
> environment?  Thanks in advance for any advice on this.
>
>
> --
> Seb
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Sat Dec 30 08:16:35 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 30 Dec 2006 07:16:35 +0000 (GMT)
Subject: [R] Failure loading library into second R 2.3.1 session on
 Windows XP
In-Reply-To: <4595911B.9070905@statistik.uni-dortmund.de>
References: <BAY132-F4AF091C5FB8640F5FAFE6AAC60@phx.gbl>
	<4595911B.9070905@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.64.0612300715440.3400@gannet.stats.ox.ac.uk>

On Fri, 29 Dec 2006, Uwe Ligges wrote:

> You can only expect that update / reinstall a ***package*** works if you
> have not yet loaded it into your R session.
> Hence close R, start it without loading the relevant package and then
> update/reinstall.

And for the record, this is answered in rw-FAQ Q4.8.

>
> Best,
> Uwe Ligges
>
>
> Talbot Katz wrote:
>> Hi.
>>
>> I am using R 2.3.1 on Windows XP.  I had installed a library package into my
>> first session and wanted the same package in my second session, so I went
>> out to the CRAN mirror and tried to install the package, and got the
>> following message:
>>
>> *********************************************************************
>>
>>> utils:::menuInstallPkgs()
>> trying URL
>> 'http://cran.ssds.ucdavis.edu/bin/windows/contrib/2.3/corpcor_1.4.4.zip'
>> Content type 'application/zip' length 133068 bytes
>> opened URL
>> downloaded 129Kb
>>
>> package 'corpcor' successfully unpacked and MD5 sums checked
>> Warning: cannot remove prior installation of package 'corpcor'
>>
>> The downloaded packages are in
>>         C:\Documents and Settings\Talbot\Local
>> Settings\Temp\RtmplCxarb\downloaded_packages
>> updating HTML package descriptions
>>> library(corpcor)
>> Error in library(corpcor) : there is no package called 'corpcor'
>>
>> *********************************************************************
>>
>>
>> After rebooting my machine, I dug into this a little further.  Upon
>> installing a package from a CRAN mirror, it seems to stay on my hard drive,
>> and I can load it in subsequent sessions from the "Load package..." menu
>> without going back to get it from a CRAN mirror.  However, if I do happen to
>> retrieve it again from a CRAN mirror, it appears that may corrupt the
>> version that was saved, and it no longer will be available from the "Load
>> package..." menu.  A reboot and re-retrieval of the package makes it
>> available again; I don't know whether there's any less drastic solution.
>>
>> This behavior doesn't occur with every package, but I have experienced it
>> with two different packages (corpcor and copula), so there seems to be
>> something going on.  I didn't see anything in the FAQ page about this, I
>> wonder if anyone can tell me more about this issue.
>>
>> Thanks!
>>
>>
>> --  TMK  --
>> 212-460-5430	home
>> 917-656-5351	cell
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sat Dec 30 08:41:48 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 30 Dec 2006 07:41:48 +0000 (GMT)
Subject: [R] wrapping mle()
In-Reply-To: <8764buj738.fsf@patagonia.sebmags.homelinux.org>
References: <8764buj738.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <Pine.LNX.4.64.0612300721090.3400@gannet.stats.ox.ac.uk>

On Fri, 29 Dec 2006, Sebastian P. Luque wrote:

> Hi,
>
> How can we set the environment for the minuslog function in mle()?  The
> call in this code fails because the "ll" function cannot find the object
> 'y'.  Modifying from the example in ?mle:
>
>
> library(stats4)
> ll <- function(ymax=15, xhalf=6) {
>    -sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))
> }
> fit.mle <- function(FUN, x, y) {
>    loglik.fun <- match.fun(FUN)
>    mle(loglik.fun, method="L-BFGS-B", lower=c(0, 0))
> }
> fit.mle("ll", x=0:10, y=c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8))
>
>
> How should "fit.mle" be constructed so that "ll" works on the appropriate
> environment?  Thanks in advance for any advice on this.

You need to set the environment of ll to that containing your data 
objects.  This would happen automatically if you defined ll in the 
function fit.mle.  A brutal solution would be

fit.mle <- function(FUN, x, y) {
    loglik.fun <- match.fun(FUN)
    environment(loglik.fun) <- sys.frame(sys.nframe())
    mle(loglik.fun, method="L-BFGS-B", lower=c(0, 0))
}

but of course that would remove the previous environment from the scope, 
so you may need something like

    env <- sys.frame(sys.nframe())
    parent.env(env) <- environment(ll)
    environment(loglik.fun) <- env


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hb at stat.berkeley.edu  Sat Dec 30 08:47:58 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Sat, 30 Dec 2006 18:47:58 +1100
Subject: [R] Evaluating Entire Matlab code at a time
In-Reply-To: <20061230064130.20649.qmail@web34303.mail.mud.yahoo.com>
References: <20061230064130.20649.qmail@web34303.mail.mud.yahoo.com>
Message-ID: <59d7961d0612292347t6e9e1758l55d57a00d195b960@mail.gmail.com>

Hi.

On 12/30/06, Bhanu Kalyan.K <kalyansikha at yahoo.com> wrote:
> Dear Mr.Bengtsson,
>
> The steps you have suggested are working for single lines of matlab
> statements. But, as i mentioned earlier, If i want to see the output of an
> entire matlab code (say swissroll.m) then you suggested me to do
> res <- evaluate(matlab, "swissroll").
> When i did this the output looks something like:
>
> > res <- evaluate(matlab, "swissroll")
>
>  Sending expression on the Matlab server to be evaluated...: 'swissroll'
>  Received an 'MatlabException' reply (-1) from the Matlab server: 'Undefined
> function or variable 'lle'.'
>  Error in list("evaluate(matlab, "swissroll")" = <environment>,
> "evaluate.Matlab(matlab, "swissroll")" = <environment>,  :
>
>  [2006-12-30 11:58:32] Exception: MatlabException: Undefined function or
> variable 'lle'.
>    at throw(Exception(...))
>    at throw.default("MatlabException: ", lasterr)
>    at throw("MatlabException: ", lasterr)
>    at readResult.Matlab(this)
>    at readResult(this)
>    at evaluate.Matlab(matlab, "swissroll")
>    at evaluate(matlab, "swissroll")
>
> // Here another matlab window titled "Figure no.1" (corresponding to the
> actual matlab output of swissroll.m) opened, but the window is blank. No
> output is being displayed. However,  when i used the same command for
> another matlab code, kMeansCluster.m, the warnings/Exceptions generated are
> similar to that os swissroll.m. Here is the output:
>
> > res <- evaluate(matlab, "kMeansCluster;")
>
> Sending expression on the Matlab server to be evaluated...: 'kMeansCluster;'
> Received an 'MatlabException' reply (-1) from the Matlab server: 'Undefined
> function or variable 'kMeansCluster'.'
> Error in list("evaluate(matlab, "kMeansCluster;")" = <environment>,
> "evaluate.Matlab(matlab, "kMeansCluster;")" = <environment>,  :
>
> [2006-12-30 11:56:34] Exception: MatlabException: Undefined function or
> variable 'kMeansCluster'.
>   at throw(Exception(...))
>   at throw.default("MatlabException: ", lasterr)
>   at throw("MatlabException: ", lasterr)
>   at readResult.Matlab(this)
>   at readResult(this)
>   at evaluate.Matlab(matlab, "kMeansCluster;")
>   at evaluate(matlab, "kMeansCluster;")
>
> The warnings generated are almost similar for those two different matlab
> codes. So i feel that the problem lies with the R and not the code. What do
> u suggest? how to deal with this?

To me this looks like Matlab can't find those commands, and then it
has nothing to with R. Make sure your Matlab scripts are available in
the Matlab path or in the working directory of Matlab.  You check the
working directory of Matlab with:

 evaluate(matlab, "pwd=cd();");
 pwd <- getVariable(matlab, "pwd")$pwd;
 print(pwd);

Check to see if your scripts are in the working directory:

 evaluate(matlab, "files=dir();")
 files <- getVariable(matlab, "files")$files
 unlist(files["name",,])

If not, you have to update your Matlab path or change the working directory.

Hope this helps

Henrik

>
>
>
>
> Bhanu Kalyan K
> BTech CSE Final Year
> reach4kalyan at gmail.com
> Tel :+91-9885238228
>
>  __________________________________________________
> Do You Yahoo!?
> Tired of spam? Yahoo! Mail has the best spam protection around
> http://mail.yahoo.com


From patrick.giraudoux at univ-fcomte.fr  Sat Dec 30 08:59:01 2006
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 30 Dec 2006 08:59:01 +0100
Subject: [R] plot methods in sp
Message-ID: <45961C45.4040306@univ-fcomte.fr>

Dear listers,

I am working since a while with the sp package and still wonder how the 
plot methods are managed with sp spatial objects. For instance, 
SpatialPolygonsDataFrame objects have obviously a plot method. However 
it cannot be found in the list provided by methods(plot) . Furthermore 
?plot.SpatialPolygonsDataFrame, nor ?plot.SpatialPolygons, etc.. provide 
a help, though the lattice function spplot is adequately documented.

On the other hand, plot(myobject, border="grey"), with myobject a 
SpatialPolygonsDataframe is well interpreted and recalls the syntax of 
plot.polylist of matools (though myobject is far from being a polylist...).

Can anybody (especially the package's authors...) comment on this? Where 
a help with the list of the plot function arguments can be found?

Thanks for any hint,

Patrick


From aldi at wustl.edu  Sat Dec 30 10:04:55 2006
From: aldi at wustl.edu (Aldi Kraja)
Date: Sat, 30 Dec 2006 03:04:55 -0600
Subject: [R] Error: cannot take a sample larger than the population
Message-ID: <45962BB7.3000505@wustl.edu>

Hi,
In Splus7 this statement
xlrmN1 <- sample(c(0,1,2),400 ,prob=c(0.02 ,0.93 ,0.05 ))
worked fine, but in R the interpreter reports that the length of the 
vector to chose c(0,1,2) is shorter than the size of many times I want 
to be selected from the vector c(0,1,2).
Any good reason?
See below the error.

 > xlrmN1 <- sample(c(0,1,2),400 ,prob=c(0.02 ,0.93 ,0.05 ))
Error in sample(length(x), size, replace, prob) :
        cannot take a sample larger than the population
 when 'replace = FALSE'
Execution halted

TIA,

Aldi

--


From ripley at stats.ox.ac.uk  Sat Dec 30 10:13:23 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 30 Dec 2006 09:13:23 +0000 (GMT)
Subject: [R] Why giving negative density when doing kernel density
 estimate?
In-Reply-To: <dff718fc0612290954v42ab27b5x336bef6ce9fffbf9@mail.gmail.com>
References: <dff718fc0612290954v42ab27b5x336bef6ce9fffbf9@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0612300908170.30859@gannet.stats.ox.ac.uk>

This is called 'rounding error', and has been discussed here previously.
If it matters to you (why?) use pmax(0, kde$y).

When doing numerical calculations you should always be aware that the 
numerical results will differ from algebraic ones, and that is all that is 
happening here.

On Sat, 30 Dec 2006, ?????? wrote:

> Why? And how to solve it?  The code and result are following,
>
>
>> data=rnorm(50)
>>
>> kde=density(data,n=20,from=-1,to=10)
>>
>> kde$x;kde$y
> [1] -1.0000000 -0.4210526  0.1578947  0.7368421  1.3157895  1.8947368
> [7]  2.4736842  3.0526316  3.6315789  4.2105263  4.7894737  5.3684211
> [13]  5.9473684  6.5263158  7.1052632  7.6842105  8.2631579  8.8421053
> [19]  9.4210526 10.0000000
> [1]  2.422392e-01  3.877025e-01  4.746580e-01  2.757747e-01  1.787630e-01
> [6]  1.102396e-01  2.331694e-02  3.294412e-04  2.260746e-07  6.996146e-12
> [11] -1.179461e-18 -1.226790e-17  8.892545e-18  1.144173e-17 -1.881253e-17
> [16] -2.782621e-17 -5.314722e-18 -1.691545e-17 -1.986261e-17 -2.498227e-17
>
> Best,
>
> Junjie Li
>
> Tsinghua Univercity
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From kalyansikha at yahoo.com  Sat Dec 30 10:42:28 2006
From: kalyansikha at yahoo.com (Bhanu Kalyan.K)
Date: Sat, 30 Dec 2006 01:42:28 -0800 (PST)
Subject: [R] Evaluating Entire Matlab code at a time
In-Reply-To: <59d7961d0612292347t6e9e1758l55d57a00d195b960@mail.gmail.com>
Message-ID: <289796.39887.qm@web34312.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061230/e73cfc01/attachment.pl 

From kalyansikha at yahoo.com  Sat Dec 30 10:42:28 2006
From: kalyansikha at yahoo.com (Bhanu Kalyan.K)
Date: Sat, 30 Dec 2006 01:42:28 -0800 (PST)
Subject: [R] Evaluating Entire Matlab code at a time
In-Reply-To: <59d7961d0612292347t6e9e1758l55d57a00d195b960@mail.gmail.com>
Message-ID: <289796.39887.qm@web34312.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061230/e73cfc01/attachment-0001.pl 

From hb at stat.berkeley.edu  Sat Dec 30 10:51:32 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Sat, 30 Dec 2006 20:51:32 +1100
Subject: [R] Evaluating Entire Matlab code at a time
In-Reply-To: <289796.39887.qm@web34312.mail.mud.yahoo.com>
References: <59d7961d0612292347t6e9e1758l55d57a00d195b960@mail.gmail.com>
	<289796.39887.qm@web34312.mail.mud.yahoo.com>
Message-ID: <59d7961d0612300151u29bd355fo5e25d687d01b13c6@mail.gmail.com>

This is very odd, but maybe 'cd' is not a command on your Windows
Matlab installation.  I tried the same code on a Unix installation (I
don't have access to Matlab for Windows but others have been using
R.matlab there successfully).  Find out what the command for getting
the current directory in your Matlab version is and use that instead.

You could also troubleshoot by this:

1. Start Matlab using Matlab$startServer(minimize=FALSE)
2. Setup the Matlab connection from R and close it with close(matlab).
3. Go to the Matlab windows and try the commands that failed for you
    when called from R. This will give you a hint.

Remember, there is nothing magic going on.  Think about the R Matlab
connection as R is typing the Matlab commands for you; anything you
can do in that Matlab windows which you did close(matlab) on you can
do with evaluate(matlab, ...) - before closing it that is.

/Henrik

On 12/30/06, Bhanu Kalyan.K <kalyansikha at yahoo.com> wrote:
> Dear Mr. Bengtsson,
>
> I worked on the code you sent. But, I dont think it is responding either.
> Kindly verify.
>
> > evaluate(matlab, "pwd=cd();");
>
> Sending expression on the Matlab server to be evaluated...: 'pwd=cd();'
> Received an 'MatlabException' reply (-1) from the Matlab server: 'Error:
> Expected a variable, function, or constant, found ")".'
> Error in list("evaluate(matlab, "pwd=cd();")" = <environment>,
> "evaluate.Matlab(matlab, "pwd=cd();")" = <environment>,  :
>
> [2006-12-30 15:08:34] Exception: MatlabException: Error: Expected a
> variable, function, or constant, found ")".
>   at throw(Exception(...))
>   at throw.default("MatlabException: ", lasterr)
>   at throw("MatlabException: ", lasterr)
>   at readResult.Matlab(this)
>   at readResult(this)
>   at evaluate.Matlab(matlab, "pwd=cd();")
>   at evaluate(matlab, "pwd=cd();")
>
> > pwd <- getVariable(matlab, "pwd")$pwd;
>
> Retrieving variables from the Matlab server: 'pwd'
> Sending expression on the Matlab server to be evaluated...: 'variables =
> {'pwd'};'
> Received an 'OK' reply (0) from the Matlab server.
> Evaluated expression on the Matlab server with return code 0.
> Asks the Matlab server to send variables via the local file system...
> Error in readChar(con = con, nchars = nbrOfBytes) :
>         invalid value for 'nchar'
>
> > print(pwd);
>
> Error in print(pwd) : object "pwd" not found
>
> > evaluate(matlab, "files=dir();")
>
> Sending expression on the Matlab server to be evaluated...: 'files=dir();'
> Error in readChar(con = con, nchars = nbrOfBytes) :
>         invalid value for 'nchar'
>
> Kindly verify and let me know the solution.
>
> Regards,
> Bhanu Kalyan K
>
>
>
> Bhanu Kalyan K
> BTech CSE Final Year
> reach4kalyan at gmail.com
> Tel :+91-9885238228
>
>  __________________________________________________
> Do You Yahoo!?
> Tired of spam? Yahoo! Mail has the best spam protection around
> http://mail.yahoo.com


From ccleland at optonline.net  Sat Dec 30 11:45:07 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Sat, 30 Dec 2006 05:45:07 -0500
Subject: [R] Error: cannot take a sample larger than the population
In-Reply-To: <45962BB7.3000505@wustl.edu>
References: <45962BB7.3000505@wustl.edu>
Message-ID: <45964333.1060207@optonline.net>

Aldi Kraja wrote:
> Hi,
> In Splus7 this statement
> xlrmN1 <- sample(c(0,1,2),400 ,prob=c(0.02 ,0.93 ,0.05 ))
> worked fine, but in R the interpreter reports that the length of the 
> vector to chose c(0,1,2) is shorter than the size of many times I want 
> to be selected from the vector c(0,1,2).
> Any good reason?
> See below the error.
> 
>  > xlrmN1 <- sample(c(0,1,2),400 ,prob=c(0.02 ,0.93 ,0.05 ))
> Error in sample(length(x), size, replace, prob) :
>         cannot take a sample larger than the population
>  when 'replace = FALSE'
> Execution halted

  So why not use replace = TRUE ?

xlrmN1 <- sample(c(0,1,2),400 ,prob=c(0.02 ,0.93 ,0.05 ), replace=TRUE)

table(xlrmN1)
xlrmN1
  0   1   2
  5 373  22

prop.table(table(xlrmN1))
xlrmN1
     0      1      2
0.0125 0.9325 0.0550

> TIA,
> 
> Aldi
> 
> --
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From ligges at statistik.uni-dortmund.de  Sat Dec 30 14:29:22 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 30 Dec 2006 14:29:22 +0100
Subject: [R] Failure loading library into second R 2.3.1 session on
 Windows XP
In-Reply-To: <BAY132-F40F95224C46C04923ACF95AAC60@phx.gbl>
References: <BAY132-F40F95224C46C04923ACF95AAC60@phx.gbl>
Message-ID: <459669B2.8090006@statistik.uni-dortmund.de>



Talbot Katz wrote:
> Hi Uwe.
> 
> Thank you so much for responding!  I guess I wasn't entirely clear about 
> the problem.  If I make the mistake of trying to install a package from 
> CRAN in a second session after I've already installed it in a previous 
> session, it won't install in the second session, and even if I close the 
> second session and open a subsequent newer session, it won't install in 
> that one either.  At least, I can't figure out how to do it, because 
> it's no longer in the "Load packages..." menu, and if I load it from 
> CRAN, I get that funny error message:
>     Warning: cannot remove prior installation of package 'corpcor'


> Now, after having gone through this, I know enough not to reload a 
> package from CRAN.  But it appears that the only ways to solve the 
> problem, if it occurs, are pretty drastic, either reboot the machine 
> (which is what I did) or reinstall R (which seems to be what you're 
> suggesting?).  I was hoping that there might be a better alternative, or 
> at least that the development team might look into this issue for future 
> releases.  This doesn't affect every package, but I've seen it in the 
> first two packages I tried it with.

No, you just have to close all running R processes, restart R and 
reinstall the package (without having it loaded by any R process). There 
is no reason to reboot the machine.

Please distinguish between installing and loading a package.

Uwe Ligges



> --  TMK  --
> 212-460-5430    home
> 917-656-5351    cell
> 
> 
> 
>> From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
>> To: Talbot Katz <topkatz at msn.com>
>> CC: r-help at stat.math.ethz.ch
>> Subject: Re: [R] Failure loading library into second R 2.3.1 session 
>> on Windows XP
>> Date: Fri, 29 Dec 2006 23:05:15 +0100
>>
>> You can only expect that update / reinstall a ***package*** works if 
>> you have not yet loaded it into your R session.
>> Hence close R, start it without loading the relevant package and then 
>> update/reinstall.
>>
>> Best,
>> Uwe Ligges
>>
>>
>> Talbot Katz wrote:
>>> Hi.
>>>
>>> I am using R 2.3.1 on Windows XP.  I had installed a library package 
>>> into my first session and wanted the same package in my second 
>>> session, so I went out to the CRAN mirror and tried to install the 
>>> package, and got the following message:
>>>
>>> *********************************************************************
>>>
>>>> utils:::menuInstallPkgs()
>>> trying URL 
>>> 'http://cran.ssds.ucdavis.edu/bin/windows/contrib/2.3/corpcor_1.4.4.zip'
>>> Content type 'application/zip' length 133068 bytes
>>> opened URL
>>> downloaded 129Kb
>>>
>>> package 'corpcor' successfully unpacked and MD5 sums checked
>>> Warning: cannot remove prior installation of package 'corpcor'
>>>
>>> The downloaded packages are in
>>>         C:\Documents and Settings\Talbot\Local 
>>> Settings\Temp\RtmplCxarb\downloaded_packages
>>> updating HTML package descriptions
>>>> library(corpcor)
>>> Error in library(corpcor) : there is no package called 'corpcor'
>>>
>>> *********************************************************************
>>>
>>>
>>> After rebooting my machine, I dug into this a little further.  Upon 
>>> installing a package from a CRAN mirror, it seems to stay on my hard 
>>> drive, and I can load it in subsequent sessions from the "Load 
>>> package..." menu without going back to get it from a CRAN mirror.  
>>> However, if I do happen to retrieve it again from a CRAN mirror, it 
>>> appears that may corrupt the version that was saved, and it no longer 
>>> will be available from the "Load package..." menu.  A reboot and 
>>> re-retrieval of the package makes it available again; I don't know 
>>> whether there's any less drastic solution.
>>>
>>> This behavior doesn't occur with every package, but I have 
>>> experienced it with two different packages (corpcor and copula), so 
>>> there seems to be something going on.  I didn't see anything in the 
>>> FAQ page about this, I wonder if anyone can tell me more about this 
>>> issue.
>>>
>>> Thanks!
>>>
>>>
>>> --  TMK  --
>>> 212-460-5430    home
>>> 917-656-5351    cell
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
>


From f.harrell at vanderbilt.edu  Sat Dec 30 15:35:29 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 30 Dec 2006 08:35:29 -0600
Subject: [R] Survfit with a coxph object
In-Reply-To: <1c6126db0612291437x4e4dc04ajc71a4780a970175@mail.gmail.com>
References: <1c6126db0612291437x4e4dc04ajc71a4780a970175@mail.gmail.com>
Message-ID: <45967931.4080101@vanderbilt.edu>

sj wrote:
> I am fitting a coxph model on a large dataset (approx 100,000 patients), and
> then trying to estimate the survival curves for several new patients based
> on the coxph object using survfit.  When I run coxph I get the coxph object
> back fairly quickly however when I try to run survfit  it does not come
> back. I  am wondering if their is a more efficient way to get predicted
> survival curves from a coxph object.predict.coxph does not seem to generate
> survival curves.
> 
> here is some sample code that mirrors what I am trying to do with my
> dataset, I get results using this code but it still takes a long time, my
> dataset includes quite a few more covariates, so any suggestions on speeding
> this up would be greatly appreciated.
> 
> 
> library(survival)
> ### generate sample data
> time <- rexp(100000,(1/180))
> ag <- rnorm(100000,38,12)
> sx <- sample(x=c(0,1),100000,replace=TRUE)
> ac <- factor(sample(x=c(1,2,3,4,5),100000,replace=TRUE),levels=c(1:5))
> ev <- sample(x=c(0,1),100000,replace=TRUE)
> c1 <- as.data.frame(cbind(ag,sx,ac))

cl <- data.frame(ag, sex, ac)

> 
> #generate newdata
> ts <- as.data.frame
> (cbind(ag[23:24],sx[1000:1001],factor(ac[9000:9001],levels=c(1:5))))
> colnames(ts) <- c("ag","sx","ac")
> 
> 
> cph <- coxph(Surv(time,ev)~ ag+sx+ac,data=c1)

Don't need data= since everything is already available.

> 
> survfit(cph,newdata=ts,individual=F)

The delay is probably due to computations of confidence limits.  If you 
don't need them or don't mind using approximate confidence limits you 
can get very quick estimates using

library(Design)
f <- cph(Surv(time,ev) ~ ..., surv=TRUE)   # do ?cph
survplot(f, ...)  # do ?survplot
survest(f, ...)   # do ?survest
survfit(f, ...)   # do ?survfit

Or create a nomogram that gives users almost instant computations of 
survival probabilities at selected times without using a computer. 
There are examples of this in my book Regression Modeling Strategies. 
Do ?nomogram which has an example of drawing a nomogram that shows 
median, 3-month, and 6-month survival estimates from a parametric 
survival model fit, which you can also do with the Cox model using cph 
(a wrapper for coxph).

Frank Harrell

> 
> 
> 
> thanks,
> 
> Spencer
> 

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From alan.gibson at gmail.com  Sat Dec 30 14:00:20 2006
From: alan.gibson at gmail.com (Alan Gibson)
Date: Sat, 30 Dec 2006 05:00:20 -0800
Subject: [R] Crosstab from sql dump
Message-ID: <a2f3b2d90612300500h33c2fff0m8190c69fb56394dc@mail.gmail.com>

Hello all,,

Im looking for a simple function to produce a crosstab from a dumped
sql query result. Its very hard to produce crosstabs with most
databases (Access being the exception), so with the vast array of R
packages, Im sure this has to have already been implemented somewhere.

Examples are always good:
Take a csv dump like

name code
user1 100
user2 100
user1 200
user2 210
user1 300
user2 300

and produce

user1 user2
100 100
200 210
300 300

Thanks in advance for any suggestions,

Alan


From spluque at gmail.com  Sat Dec 30 16:47:26 2006
From: spluque at gmail.com (Sebastian P. Luque)
Date: Sat, 30 Dec 2006 09:47:26 -0600
Subject: [R] wrapping mle()
References: <8764buj738.fsf@patagonia.sebmags.homelinux.org>
	<Pine.LNX.4.64.0612300721090.3400@gannet.stats.ox.ac.uk>
Message-ID: <87fyaxidwx.fsf@patagonia.sebmags.homelinux.org>

On Sat, 30 Dec 2006 07:41:48 +0000 (GMT),
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

[...]

> You need to set the environment of ll to that containing your data
> objects.  This would happen automatically if you defined ll in the
> function fit.mle.  A brutal solution would be

> fit.mle <- function(FUN, x, y) { loglik.fun <- match.fun(FUN)
> environment(loglik.fun) <- sys.frame(sys.nframe()) mle(loglik.fun,
> method="L-BFGS-B", lower=c(0, 0))
> }

> but of course that would remove the previous environment from the scope,
> so you may need something like

>     env <- sys.frame(sys.nframe()) parent.env(env) <- environment(ll)
> environment(loglik.fun) <- env

Thanks to both of you.  I really need to get to grips with environments.


Happy new year,

-- 
Seb


From aldi at wustl.edu  Sat Dec 30 16:55:39 2006
From: aldi at wustl.edu (Aldi Kraja)
Date: Sat, 30 Dec 2006 09:55:39 -0600
Subject: [R] Error: cannot take a sample larger than the population
In-Reply-To: <45962BB7.3000505@wustl.edu>
References: <45962BB7.3000505@wustl.edu>
Message-ID: <45968BFB.7010907@wustl.edu>

Partial Summary and discussion:
=====================
Thank you to Chao Gai, Chuck Cleland, and Jim Lemon for their suggestion 
to use replace=T in R.
There is a problem though (see below)

In the Splus7, sample is defined as
-------------
sample(x, size = n, replace = F, prob = NULL, n = NULL, ...)  where 
replace=F
In Splus7

xlrmN1 <- sample(c(0,1,2),400 ,prob=c(0.02 ,0.93 ,0.05 ))

and the 

table(xlrmN1)/400
    0    1    2
 0.02 0.93 0.05
show that "sample" is working exactly as expected based on the prob vector.

When "sample" is used in Splus7 with replacement we see the following 
result:
 > xlrmN1 <- sample(c(0,1,2),400 ,replace=T,prob=c(0.02 ,0.93 ,0.05 ))
 > table(xlrmN1)/400
      0     1      2
 0.0125 0.925 0.0625
which I think is working again as expected.

In the R, sample is defined as
---------

sample(x, size, replace = FALSE, prob = NULL)

So the above statement with replace=F did not work (reported error)
but with replace=T produced,

> table(xlrmN1)/400
xlrmN1
     0      1      2 
0.0200 0.9225 0.0575 

which is not exactly the sample with the probabilities provided (0.02,0.93,0.05)

Now let's return to the concept of replace=F and replace=T.
When I ask "sample" to select a sample of 400 from a vector of 3 with NO replacement, I would think the following
a). create a very large sample from 0, 1, and 2. b). From this large sample, based on the prob vector select without replacement.
c). As result I expect the probability of selected sample to be exactly the same with the prob vector (As in Splus7)

When I ask "sample" to select a sample of 400 from a vector of 3 with replacement, I would think the following
a). create a very large sample from 0, 1, and 2. b). From this large sample, based on the prob vector select with replacement, 
which means some of the previous selected 0, 1, 2 can be selected again.
c). As result I expect the probability of selected sample to be NOT exactly the same with the prob vector (As in Splus7 and R).

So there are two conclusions: "sample" in R is not working correct, OR I am missing some precision as a rounding error to produce

prob=c(0.02 ,0.93 ,0.05 ).
Am I misunderstanding the "sample" function in R?

Any suggestions are appreciated.
TIA,

Aldi

Aldi Kraja wrote:

>Hi,
>In Splus7 this statement
>xlrmN1 <- sample(c(0,1,2),400 ,prob=c(0.02 ,0.93 ,0.05 ))
>worked fine, but in R the interpreter reports that the length of the 
>vector to chose c(0,1,2) is shorter than the size of many times I want 
>to be selected from the vector c(0,1,2).
>Any good reason?
>See below the error.
>
> > xlrmN1 <- sample(c(0,1,2),400 ,prob=c(0.02 ,0.93 ,0.05 ))
>Error in sample(length(x), size, replace, prob) :
>        cannot take a sample larger than the population
> when 'replace = FALSE'
>Execution halted
>
>TIA,
>
>Aldi
>
>--
>
>  
>

--


From dieter.menne at menne-biomed.de  Sat Dec 30 17:54:49 2006
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Sat, 30 Dec 2006 16:54:49 +0000 (UTC)
Subject: [R] Crosstab from sql dump
References: <a2f3b2d90612300500h33c2fff0m8190c69fb56394dc@mail.gmail.com>
Message-ID: <loom.20061230T175331-421@post.gmane.org>

Alan Gibson <alan.gibson <at> gmail.com> writes:

> Im looking for a simple function to produce a crosstab from a dumped
> sql query result. 


xtabs in stats is a simple solution, but package reshape is much more flexible
and comes with a good introduction.pdf.

Dieter


From chaogai at duineveld.demon.nl  Sat Dec 30 17:57:21 2006
From: chaogai at duineveld.demon.nl (chao gai)
Date: Sat, 30 Dec 2006 17:57:21 +0100
Subject: [R] Error: cannot take a sample larger than the population
In-Reply-To: <45968BFB.7010907@wustl.edu>
References: <45962BB7.3000505@wustl.edu> <45968BFB.7010907@wustl.edu>
Message-ID: <200612301757.23254.chaogai@duineveld.demon.nl>

Aldi,

Your concept of sample is different from mine. 
I would expect with replacement to be equivalent for a for loop of sampling 
without replacement.
samples <- 1:400
for (i in 1:400) samples[i] <- sample(c(0,1,2),1 ,prob=c(0.02 ,0.93 ,0.05 ))
Sampling without replacement:
first :  sample(c(0,1,2),1 ,prob=c(0.02 ,0.93 ,0.05 ))
second: depending on first (suppose 2 was selected)
	 sample(c(0,1),1 ,prob=c(0.02 ,0.93)/.95)
third: whatever is remaining with probability 1.

n.b. the second is equivalent to  sample(c(0,1),1 ,prob=c(0.02 ,0.93)), since 
sample normalized the probabilities itself.

Concerning your result:
observed <- c(0.0200, 0.9225, 0.0575 )*400
expected  <- c(0.02 ,0.93 ,0.05 )*400
stat <- sum((observed-expected)^2/expected)
pchisq(stat,2,lower=FALSE)
[1] 0.788915

Seems ok to me.

Cheers,
Kees



On Saturday 30 December 2006 16:55, Aldi Kraja wrote:
> Partial Summary and discussion:
> =====================
> Thank you to Chao Gai, Chuck Cleland, and Jim Lemon for their suggestion
> to use replace=T in R.
> There is a problem though (see below)
>
> In the Splus7, sample is defined as
> -------------
> sample(x, size = n, replace = F, prob = NULL, n = NULL, ...)  where
> replace=F
> In Splus7
>
> xlrmN1 <- sample(c(0,1,2),400 ,prob=c(0.02 ,0.93 ,0.05 ))
>
> and the
>
> table(xlrmN1)/400
>     0    1    2
>  0.02 0.93 0.05
> show that "sample" is working exactly as expected based on the prob vector.
>
> When "sample" is used in Splus7 with replacement we see the following
>
> result:
>  > xlrmN1 <- sample(c(0,1,2),400 ,replace=T,prob=c(0.02 ,0.93 ,0.05 ))
>  > table(xlrmN1)/400
>
>       0     1      2
>  0.0125 0.925 0.0625
> which I think is working again as expected.
>
> In the R, sample is defined as
> ---------
>
> sample(x, size, replace = FALSE, prob = NULL)
>
> So the above statement with replace=F did not work (reported error)
> but with replace=T produced,
>
> > table(xlrmN1)/400
>
> xlrmN1
>      0      1      2
> 0.0200 0.9225 0.0575
>
> which is not exactly the sample with the probabilities provided
> (0.02,0.93,0.05)
>
> Now let's return to the concept of replace=F and replace=T.
> When I ask "sample" to select a sample of 400 from a vector of 3 with NO
> replacement, I would think the following a). create a very large sample
> from 0, 1, and 2. b). From this large sample, based on the prob vector
> select without replacement. c). As result I expect the probability of
> selected sample to be exactly the same with the prob vector (As in Splus7)
>
> When I ask "sample" to select a sample of 400 from a vector of 3 with
> replacement, I would think the following a). create a very large sample
> from 0, 1, and 2. b). From this large sample, based on the prob vector
> select with replacement, which means some of the previous selected 0, 1, 2
> can be selected again. c). As result I expect the probability of selected
> sample to be NOT exactly the same with the prob vector (As in Splus7 and
> R).
>
> So there are two conclusions: "sample" in R is not working correct, OR I am
> missing some precision as a rounding error to produce
>
> prob=c(0.02 ,0.93 ,0.05 ).
> Am I misunderstanding the "sample" function in R?
>
> Any suggestions are appreciated.
> TIA,
>
> Aldi
>
> Aldi Kraja wrote:
> >Hi,
> >In Splus7 this statement
> >xlrmN1 <- sample(c(0,1,2),400 ,prob=c(0.02 ,0.93 ,0.05 ))
> >worked fine, but in R the interpreter reports that the length of the
> >vector to chose c(0,1,2) is shorter than the size of many times I want
> >to be selected from the vector c(0,1,2).
> >Any good reason?
> >See below the error.
> >
> > > xlrmN1 <- sample(c(0,1,2),400 ,prob=c(0.02 ,0.93 ,0.05 ))
> >
> >Error in sample(length(x), size, replace, prob) :
> >        cannot take a sample larger than the population
> > when 'replace = FALSE'
> >Execution halted
> >
> >TIA,
> >
> >Aldi
> >
> >--
>
> --
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented, minimal,
> self-contained, reproducible code.


From klijunjie at gmail.com  Sat Dec 30 18:11:06 2006
From: klijunjie at gmail.com (=?GB2312?B?wO6/ob3c?=)
Date: Sun, 31 Dec 2006 01:11:06 +0800
Subject: [R] Why giving negative density when doing kernel density
	estimate?
In-Reply-To: <Pine.LNX.4.64.0612300908170.30859@gannet.stats.ox.ac.uk>
References: <dff718fc0612290954v42ab27b5x336bef6ce9fffbf9@mail.gmail.com>
	<Pine.LNX.4.64.0612300908170.30859@gannet.stats.ox.ac.uk>
Message-ID: <dff718fc0612300911l2c49281cxe22f461963f9c790@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061231/8a2850ed/attachment.pl 

From ccleland at optonline.net  Sat Dec 30 20:24:19 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Sat, 30 Dec 2006 14:24:19 -0500
Subject: [R] Error: cannot take a sample larger than the population
In-Reply-To: <45968BFB.7010907@wustl.edu>
References: <45962BB7.3000505@wustl.edu> <45968BFB.7010907@wustl.edu>
Message-ID: <4596BCE3.6070605@optonline.net>

Aldi Kraja wrote:
> Partial Summary and discussion:
> =====================
> Thank you to Chao Gai, Chuck Cleland, and Jim Lemon for their suggestion 
> to use replace=T in R.
> There is a problem though (see below)
> 
> In the Splus7, sample is defined as
> -------------
> sample(x, size = n, replace = F, prob = NULL, n = NULL, ...)  where 
> replace=F
> In Splus7
> 
> xlrmN1 <- sample(c(0,1,2),400 ,prob=c(0.02 ,0.93 ,0.05 ))
> 
> and the 
> 
> table(xlrmN1)/400
>     0    1    2
>  0.02 0.93 0.05
> show that "sample" is working exactly as expected based on the prob vector.
> 
> When "sample" is used in Splus7 with replacement we see the following 
> result:
>  > xlrmN1 <- sample(c(0,1,2),400 ,replace=T,prob=c(0.02 ,0.93 ,0.05 ))
>  > table(xlrmN1)/400
>       0     1      2
>  0.0125 0.925 0.0625
> which I think is working again as expected.
> 
> In the R, sample is defined as
> ---------
> 
> sample(x, size, replace = FALSE, prob = NULL)
> 
> So the above statement with replace=F did not work (reported error)
> but with replace=T produced,
> 
>> table(xlrmN1)/400
> xlrmN1
>      0      1      2 
> 0.0200 0.9225 0.0575 
> 
> which is not exactly the sample with the probabilities provided (0.02,0.93,0.05)
> 
> Now let's return to the concept of replace=F and replace=T.
> When I ask "sample" to select a sample of 400 from a vector of 3 with NO replacement, I would think the following
> a). create a very large sample from 0, 1, and 2. b). From this large sample, based on the prob vector select without replacement.
> c). As result I expect the probability of selected sample to be exactly the same with the prob vector (As in Splus7)
> 
> When I ask "sample" to select a sample of 400 from a vector of 3 with replacement, I would think the following
> a). create a very large sample from 0, 1, and 2. b). From this large sample, based on the prob vector select with replacement, 
> which means some of the previous selected 0, 1, 2 can be selected again.
> c). As result I expect the probability of selected sample to be NOT exactly the same with the prob vector (As in Splus7 and R).
> 
> So there are two conclusions: "sample" in R is not working correct, OR I am missing some precision as a rounding error to produce
> 
> prob=c(0.02 ,0.93 ,0.05 ).
> Am I misunderstanding the "sample" function in R?

  Yes, I think you are misunderstanding sample() in R.  If you want
those exact proportions in your xlrmN1 but with the observations in a
random order, you could do this:

> xlrmN1 <- rep(c(0,1,2), c(.02*400,.93*400,.05*400))[sample(400)]

> prop.table(table(xlrmN1))
xlrmN1
   0    1    2
0.02 0.93 0.05

> Any suggestions are appreciated.
> TIA,
> 
> Aldi
> 
> Aldi Kraja wrote:
> 
>> Hi,
>> In Splus7 this statement
>> xlrmN1 <- sample(c(0,1,2),400 ,prob=c(0.02 ,0.93 ,0.05 ))
>> worked fine, but in R the interpreter reports that the length of the 
>> vector to chose c(0,1,2) is shorter than the size of many times I want 
>> to be selected from the vector c(0,1,2).
>> Any good reason?
>> See below the error.
>>
>>> xlrmN1 <- sample(c(0,1,2),400 ,prob=c(0.02 ,0.93 ,0.05 ))
>> Error in sample(length(x), size, replace, prob) :
>>        cannot take a sample larger than the population
>> when 'replace = FALSE'
>> Execution halted
>>
>> TIA,
>>
>> Aldi
>>
>> --
>>
>>  
>>
> 
> --
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From luke at stat.uiowa.edu  Sat Dec 30 22:46:01 2006
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Sat, 30 Dec 2006 15:46:01 -0600 (CST)
Subject: [R] wrapping mle()
In-Reply-To: <971536df0612292130g26ac8286k4df7c5499c97e609@mail.gmail.com>
References: <8764buj738.fsf@patagonia.sebmags.homelinux.org>
	<971536df0612292130g26ac8286k4df7c5499c97e609@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0612301545060.4532@itasca2.wildberry.org>

It is much cleaner to do this sort of thing with lexical scope.  For
example,

     mkll <- function(x, y) {
        function(ymax=15, xhalf=6) {
           -sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))
        }
     }

creates a log-likelihood likelyhood function for data x,y that can
then be used by

     fit.mle <- function(mkfun, x, y) {
         loglik.fun <- mkfun(x, y)
         mle(loglik.fun, method="L-BFGS-B", lower=c(0, 0))
     }

as in


     > fit.mle(mkll, x=0:10, y=c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8))

     Call:
     mle(minuslogl = loglik.fun, method = "L-BFGS-B", lower = c(0,
         0))

     Coefficients:
          ymax     xhalf
     24.999420  3.055779

It is not clear why you want to be able to pass ll as a character
string or why you want to assume that the thing passed in will refer
to variables named 'x' and 'y', both usually bad ideas, so this
specific approach may not apply, but something variant should.

The ability to use environment(f)<-env to change the environment of a
function is one of the most dubious language features of R (maybe the
most dubious, though there are a couple of other strong contenders)
and should not be used except in very rare circumstances.

Best,

luke

On Sat, 30 Dec 2006, Gabor Grothendieck wrote:

> Add the line marked ### so that the environment of loglik.fun is reset to
> the environment within fit.mle so that it can find y there:
>
> library(stats4)
> ll <- function(ymax=15, xhalf=6) {
>   -sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))
> }
> fit.mle <- function(FUN, x, y) {
>   loglik.fun <- match.fun(FUN)
>   environment(loglik.fun) <- environment() ###
>   mle(loglik.fun, method="L-BFGS-B", lower=c(0, 0))
> }
> fit.mle("ll", x=0:10, y=c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8))
>
>
>
> On 12/30/06, Sebastian P. Luque <spluque at gmail.com> wrote:
>> Hi,
>>
>> How can we set the environment for the minuslog function in mle()?  The
>> call in this code fails because the "ll" function cannot find the object
>> 'y'.  Modifying from the example in ?mle:
>>
>>
>> library(stats4)
>> ll <- function(ymax=15, xhalf=6) {
>>    -sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))
>> }
>> fit.mle <- function(FUN, x, y) {
>>    loglik.fun <- match.fun(FUN)
>>    mle(loglik.fun, method="L-BFGS-B", lower=c(0, 0))
>> }
>> fit.mle("ll", x=0:10, y=c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8))
>>
>>
>> How should "fit.mle" be constructed so that "ll" works on the appropriate
>> environment?  Thanks in advance for any advice on this.
>>
>>
>> --
>> Seb
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From spluque at gmail.com  Sat Dec 30 23:42:42 2006
From: spluque at gmail.com (Sebastian P. Luque)
Date: Sat, 30 Dec 2006 16:42:42 -0600
Subject: [R] wrapping mle()
References: <8764buj738.fsf@patagonia.sebmags.homelinux.org>
	<971536df0612292130g26ac8286k4df7c5499c97e609@mail.gmail.com>
	<Pine.LNX.4.64.0612301545060.4532@itasca2.wildberry.org>
Message-ID: <874prdhuot.fsf@patagonia.sebmags.homelinux.org>

On Sat, 30 Dec 2006 15:46:01 -0600 (CST),
Luke Tierney <luke at stat.uiowa.edu> wrote:

> It is much cleaner to do this sort of thing with lexical scope.  For
> example,

>     mkll <- function(x, y) {
>        function(ymax=15, xhalf=6) {
>           -sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))
>        }
>     }

> creates a log-likelihood likelyhood function for data x,y that can
> then be used by

>     fit.mle <- function(mkfun, x, y) {
>         loglik.fun <- mkfun(x, y)
>         mle(loglik.fun, method="L-BFGS-B", lower=c(0, 0))
>     }

> as in


>     > fit.mle(mkll, x=0:10, y=c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8))

>     Call:
>     mle(minuslogl = loglik.fun, method = "L-BFGS-B", lower = c(0,
>         0))

>     Coefficients:
>          ymax     xhalf
>     24.999420  3.055779

Thanks Luke, this looks excellent.


> It is not clear why you want to be able to pass ll as a character string
> or why you want to assume that the thing passed in will refer to
> variables named 'x' and 'y', both usually bad ideas, so this specific
> approach may not apply, but something variant should.

In the real case, I need to provide two different log likelihood
functions, and then tell fit.mle() which one to use in a given call.  I
was actually defining 'x' and 'y' as formal arguments to fit.mle().
Wouldn't that ensure that the original ll() would refer to the correct
variables?  In any case, it was easy to use your suggestion almost by
direct analogy, which makes the code much more readable.  Thanks a lot.

In the case I describe though, why would it be a bad idea to use a string
to refer to the function, and then use match.fun()?  I actually picked up
the idea from functions such as apply() and friends.


> The ability to use environment(f)<-env to change the environment of a
> function is one of the most dubious language features of R (maybe the
> most dubious, though there are a couple of other strong contenders) and
> should not be used except in very rare circumstances.

Keeping the lexical scoping technique you showed in mind should help stay
away from that.


Cheers,

-- 
Seb


From webmaster at xen.net  Sun Dec 31 00:25:27 2006
From: webmaster at xen.net (=?ISO-8859-1?Q?Ricardo=20Rodr=EDguez?=)
Date: Sun, 31 Dec 2006 00:25:27 +0100
Subject: [R] getting a new factor
Message-ID: <s597038a.091@niloufer.xen.net>

Hi all,

Given a data frame as...

> head(veg)
     genus      species trophia type geo zone importance
1 Sphagnum  subsecundum       M        A   En        100
2 Sphagnum denticulatum       M        A   En        200
3  Molinia     caerulea       M        A   En        300
4 Sphagnum    flexuosum       M        A   En        400
5   Juncus   squarrosus       M        A   En        500
6    Carex     echinata       M        A   En        600

I do need a new one with a new factor constructed from a concatenation of the two first columns, genus and species. I am guessing this must be a simple matter while working with R, but I am stuck at this point.

Any help will be welcome! Thanks.

---
Ricardo Rodr?guez
Your XEN ICT Team


From liuwensui at gmail.com  Sun Dec 31 00:27:56 2006
From: liuwensui at gmail.com (Wensui Liu)
Date: Sat, 30 Dec 2006 18:27:56 -0500
Subject: [R] OT: any recommendation for scripting language
In-Reply-To: <1115a2b00612230756g7cf6fd0emcbec62b832402d05@mail.gmail.com>
References: <1115a2b00612230756g7cf6fd0emcbec62b832402d05@mail.gmail.com>
Message-ID: <1115a2b00612301527i6da15afdw76e17174c5243bdc@mail.gmail.com>

Dear Experts,

Thank you so much for your opinions. I probably will go with python.

Following your suggestion, I started reading some tutorials but have a
quick question. In the sense of statistical computing, is there
anything that can be easily done with python but not with SAS/R? Could
you please give such an example?

Wish you all have a happy new year!

wensui

On 12/23/06, Wensui Liu <liuwensui at gmail.com> wrote:
> Right now, I am using SAS and S+/R. As a new year resolution, I am
> planning to learn a scripting language.
>
> from statisticians' point of view, which scripting language is worth
> to learn, perl, python, or any other recommendation? (Most likely, I
> will be learning it in windows.) Since I am not in research, I will
> prefer one widely used in industry and related to statistical work.
>
> if you recommend one, I will really appreciate it if you could point
> out a good source for learning as well.
>
> thank you so much!
>
> Have a happy holiday.
>
> wensui
>


-- 
WenSui Liu
A lousy statistician who happens to know a little programming
(http://spaces.msn.com/statcompute/blog)


From rmh at temple.edu  Sun Dec 31 00:47:05 2006
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sat, 30 Dec 2006 18:47:05 -0500 (EST)
Subject: [R] getting a new factor
Message-ID: <20061230184705.BQZ97181@po-d.temple.edu>

> tmp <- data.frame(G=factor(letters[c(1,2,3,1,2,3)]), 
+                   S=factor(LETTERS[c(1,1,1,2,2,2)]))
> tmp
  G S
1 a A
2 b A
3 c A
4 a B
5 b B
6 c B
> tmp$G.S <- with(tmp, interaction(G, S))
> tmp
  G S G.S
1 a A a.A
2 b A b.A
3 c A c.A
4 a B a.B
5 b B b.B
6 c B c.B
>


From alan.gibson at gmail.com  Sun Dec 31 00:51:57 2006
From: alan.gibson at gmail.com (Alan Gibson)
Date: Sat, 30 Dec 2006 15:51:57 -0800
Subject: [R] Crosstab from sql dump
In-Reply-To: <loom.20061230T175331-421@post.gmane.org>
References: <a2f3b2d90612300500h33c2fff0m8190c69fb56394dc@mail.gmail.com>
	<loom.20061230T175331-421@post.gmane.org>
Message-ID: <a2f3b2d90612301551h7daf7a19mb6f748a2f5d307bb@mail.gmail.com>

thanks for all the tips.

using 'unstack(read.table('/tmp/codes', header=TRUE))' gets me

  user1 user2
1   100   100
2   200   200
3   300   300

where /tmp/codes contains

code name
100 user1
200 user1
300 user1
100 user2
200 user2
300 user2

so unstack is exactly what i was looking for. for the record, it is
probably a good idea to specify which column is values and which is
group indicator like 'unstack(read.table('/tmp/crap', header=TRUE),
"code ~ name")' in case your columns are in a different order.

alan

On 12/30/06, Dieter Menne <dieter.menne at menne-biomed.de> wrote:
> Alan Gibson <alan.gibson <at> gmail.com> writes:
>
> > Im looking for a simple function to produce a crosstab from a dumped
> > sql query result.
>
>
> xtabs in stats is a simple solution, but package reshape is much more flexible
> and comes with a good introduction.pdf.
>
> Dieter
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bbands at gmail.com  Sun Dec 31 02:53:30 2006
From: bbands at gmail.com (BBands)
Date: Sat, 30 Dec 2006 17:53:30 -0800
Subject: [R] OT: any recommendation for scripting language
In-Reply-To: <1115a2b00612301527i6da15afdw76e17174c5243bdc@mail.gmail.com>
References: <1115a2b00612230756g7cf6fd0emcbec62b832402d05@mail.gmail.com>
	<1115a2b00612301527i6da15afdw76e17174c5243bdc@mail.gmail.com>
Message-ID: <6e8360ad0612301753o2494cb45gc76d499f4a33035b@mail.gmail.com>

On 12/30/06, Wensui Liu <liuwensui at gmail.com> wrote:
> Dear Experts,
>
> Thank you so much for your opinions. I probably will go with python.
>
> Following your suggestion, I started reading some tutorials but have a
> quick question. In the sense of statistical computing, is there
> anything that can be easily done with python but not with SAS/R? Could
> you please give such an example?

I gather that just about anything can be done in R and have seen some
pretty amazing examples, but I come from "the right tool for the job"
school as contrasted to the "when you have a hammer everything begins
to look like a nail" school. As a consequence I tend to use R for
statistics, SQL for database management, gnuplot for graphics and
Python for general programming and glue... A lot of that has to do
with the order in which I learned the tools, for example I am much
faster/more productive with gnuplot than with R graphics, but that gap
is narrowing as I climb R's grade.

    jab--not an expert, just a traveller
-- 
John Bollinger, CFA, CMT
www.BollingerBands.com

If you advance far enough, you arrive at the beginning.


From ggrothendieck at gmail.com  Sun Dec 31 02:59:13 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 30 Dec 2006 20:59:13 -0500
Subject: [R] wrapping mle()
In-Reply-To: <Pine.LNX.4.64.0612301545060.4532@itasca2.wildberry.org>
References: <8764buj738.fsf@patagonia.sebmags.homelinux.org>
	<971536df0612292130g26ac8286k4df7c5499c97e609@mail.gmail.com>
	<Pine.LNX.4.64.0612301545060.4532@itasca2.wildberry.org>
Message-ID: <971536df0612301759q42454370obee8a87fde2db7ac@mail.gmail.com>

That has two disadvantages:

(1) it only works if the user is defining ll himself; however, if the
user is getting
ll from somewhere else then its not applicable since the user no
longer controls its
scope whereas resetting the environment method still works

(2) its "cleaner" for the developer but harder for the user who is now
forced into
a more complicated construct, i.e. the nested double function construct

By the way, here is one additional solution using the proto package that
avoids explicitly resetting of the environment in favor implicitly setting it.
A new proto object is created which to hold FUN and since proto methods have
their object as their scope, their environment is implicitly reset:

library(proto)
library(stats4)
ll <- function(ymax=15, xhalf=6) {
  -sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))
}
fit.mle <- function(FUN, x, y)
  mle(proto(FUN = match.fun(FUN))[["FUN"]], method="L-BFGS-B", lower=c(0, 0))
fit.mle("ll", x=0:10, y=c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8))






On 12/30/06, Luke Tierney <luke at stat.uiowa.edu> wrote:
> It is much cleaner to do this sort of thing with lexical scope.  For
> example,
>
>     mkll <- function(x, y) {
>        function(ymax=15, xhalf=6) {
>           -sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))
>        }
>     }
>
> creates a log-likelihood likelyhood function for data x,y that can
> then be used by
>
>     fit.mle <- function(mkfun, x, y) {
>         loglik.fun <- mkfun(x, y)
>         mle(loglik.fun, method="L-BFGS-B", lower=c(0, 0))
>     }
>
> as in
>
>
>     > fit.mle(mkll, x=0:10, y=c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8))
>
>     Call:
>     mle(minuslogl = loglik.fun, method = "L-BFGS-B", lower = c(0,
>         0))
>
>     Coefficients:
>          ymax     xhalf
>     24.999420  3.055779
>
> It is not clear why you want to be able to pass ll as a character
> string or why you want to assume that the thing passed in will refer
> to variables named 'x' and 'y', both usually bad ideas, so this
> specific approach may not apply, but something variant should.
>
> The ability to use environment(f)<-env to change the environment of a
> function is one of the most dubious language features of R (maybe the
> most dubious, though there are a couple of other strong contenders)
> and should not be used except in very rare circumstances.
>
> Best,
>
> luke
>
> On Sat, 30 Dec 2006, Gabor Grothendieck wrote:
>
> > Add the line marked ### so that the environment of loglik.fun is reset to
> > the environment within fit.mle so that it can find y there:
> >
> > library(stats4)
> > ll <- function(ymax=15, xhalf=6) {
> >   -sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))
> > }
> > fit.mle <- function(FUN, x, y) {
> >   loglik.fun <- match.fun(FUN)
> >   environment(loglik.fun) <- environment() ###
> >   mle(loglik.fun, method="L-BFGS-B", lower=c(0, 0))
> > }
> > fit.mle("ll", x=0:10, y=c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8))
> >
> >
> >
> > On 12/30/06, Sebastian P. Luque <spluque at gmail.com> wrote:
> >> Hi,
> >>
> >> How can we set the environment for the minuslog function in mle()?  The
> >> call in this code fails because the "ll" function cannot find the object
> >> 'y'.  Modifying from the example in ?mle:
> >>
> >>
> >> library(stats4)
> >> ll <- function(ymax=15, xhalf=6) {
> >>    -sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))
> >> }
> >> fit.mle <- function(FUN, x, y) {
> >>    loglik.fun <- match.fun(FUN)
> >>    mle(loglik.fun, method="L-BFGS-B", lower=c(0, 0))
> >> }
> >> fit.mle("ll", x=0:10, y=c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8))
> >>
> >>
> >> How should "fit.mle" be constructed so that "ll" works on the appropriate
> >> environment?  Thanks in advance for any advice on this.
> >>
> >>
> >> --
> >> Seb
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>


From ggrothendieck at gmail.com  Sun Dec 31 03:05:43 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 30 Dec 2006 21:05:43 -0500
Subject: [R] OT: any recommendation for scripting language
In-Reply-To: <1115a2b00612301527i6da15afdw76e17174c5243bdc@mail.gmail.com>
References: <1115a2b00612230756g7cf6fd0emcbec62b832402d05@mail.gmail.com>
	<1115a2b00612301527i6da15afdw76e17174c5243bdc@mail.gmail.com>
Message-ID: <971536df0612301805n32514bdj68a799a4c8e37642@mail.gmail.com>

Its easier to write command line filters using perl/python/gawk than R.
Its possible in R but awkward as there is no good way (platform
independent,easy to use) of referring to stdin data.

Something as simple as

gawk 1

which just copies its input to its output is pretty awkward in R.  What
R really needs is the ability to write:

R -f myprog.R < myinput.dat > myoutput.data

and have myprog.R refer to myinput.dat via /dev/stdin .


On 12/30/06, Wensui Liu <liuwensui at gmail.com> wrote:
> Dear Experts,
>
> Thank you so much for your opinions. I probably will go with python.
>
> Following your suggestion, I started reading some tutorials but have a
> quick question. In the sense of statistical computing, is there
> anything that can be easily done with python but not with SAS/R? Could
> you please give such an example?
>
> Wish you all have a happy new year!
>
> wensui
>
> On 12/23/06, Wensui Liu <liuwensui at gmail.com> wrote:
> > Right now, I am using SAS and S+/R. As a new year resolution, I am
> > planning to learn a scripting language.
> >
> > from statisticians' point of view, which scripting language is worth
> > to learn, perl, python, or any other recommendation? (Most likely, I
> > will be learning it in windows.) Since I am not in research, I will
> > prefer one widely used in industry and related to statistical work.
> >
> > if you recommend one, I will really appreciate it if you could point
> > out a good source for learning as well.
> >
> > thank you so much!
> >
> > Have a happy holiday.
> >
> > wensui
> >
>
>
> --
> WenSui Liu
> A lousy statistician who happens to know a little programming
> (http://spaces.msn.com/statcompute/blog)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From john.kornak at ucsf.edu  Sun Dec 31 03:55:30 2006
From: john.kornak at ucsf.edu (John Kornak)
Date: Sat, 30 Dec 2006 18:55:30 -0800
Subject: [R] rimage package broken with fedora upgrade
Message-ID: <459726A2.9080202@ucsf.edu>


Dear R list members

I would be grateful if anyone could guide me to a solution for fixing my 
rimage package problem described below.

I recently upgraded my machine from fedora core 3 to fedora core 6 and 
then upgraded R from version 2.3.1 from version 2.4.1.

I then fired up R, tried to load the rimage library and received the 
following messages:

  > library(rimage)
Error in dyn.load(x, as.logical(local), as.logical(now)) :
         unable to load shared library 
'/usr/lib/R/library/rimage/libs/rimage.so':
   /usr/lib/R/library/rimage/libs/rimage.so: cannot restore segment prot 
after reloc: Permission denied
Error in library(rimage) : .First.lib failed for 'rimage'
 >

I tried removing and re-installing rimage. The install seemed to go well 
but I received the identical error messages upon loading. (I provide the 
output from the package re-install at the very end of this email in case 
it is useful.)

I am running R version 2.4.1 and fc6 on a dual boot (with XP) Pentium 4 
Dell Dimension 8250. I have both fftw-2.1.5 and fftw-3.1.2 on my machine 
within /usr/local and .

rimage was working fine on the same machine before I upgraded from R 
2.3.1 and fc3.

I searched online but was unable to find any relevant posts.

Thanks again

John
-- 
John Kornak,PhD
Assistant Professor
Departments of Radiology, and Epidemiology & Biostatistics
University of California, San Francisco
Box 0946
San Francisco, CA 94143
Tel: (415) 353-4740
fax: (415) 353-9423
Email: john.kornak at ucsf.edu

#############################################

 > install.packages("rimage")
trying URL 'http://cran.cnr.Berkeley.edu/src/contrib/rimage_0.5-7.tar.gz'
Content type 'application/x-gzip' length 331029 bytes
opened URL
==================================================
downloaded 323Kb

* Installing *source* package 'rimage' ...
checking for g++... g++
checking for C++ compiler default output... a.out
checking whether the C++ compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
checking for gcc... gcc
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ANSI C... none needed
checking how to run the C preprocessor... gcc -E
checking for egrep... grep -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking fftw.h usability... yes
checking fftw.h presence... yes
checking for fftw.h... yes
checking jpeglib.h usability... yes
checking jpeglib.h presence... yes
checking for jpeglib.h... yes
checking for inline... inline
checking for stdlib.h... (cached) yes
checking for GNU libc compatible malloc... yes
configure: creating ./config.status
config.status: creating src/Makevars
** libs
g++ -I/usr/lib/R/include -I/usr/lib/R/include -g -O2 
-I/usr/local/include    -fpic  -O3 -g -c equalize.cpp -o equalize.o
gcc -I/usr/lib/R/include -I/usr/lib/R/include -g -O2 
-I/usr/local/include    -fpic  -O3 -g -std=gnu99 -c fftw_access_func.c 
-o fftw_access_func.o
g++ -I/usr/lib/R/include -I/usr/lib/R/include -g -O2 
-I/usr/local/include    -fpic  -O3 -g -c freqfilters.cpp -o freqfilters.o
g++ -I/usr/lib/R/include -I/usr/lib/R/include -g -O2 
-I/usr/local/include    -fpic  -O3 -g -c interface.cpp -o interface.o
gcc -I/usr/lib/R/include -I/usr/lib/R/include -g -O2 
-I/usr/local/include    -fpic  -O3 -g -std=gnu99 -c jpegio.c -o jpegio.o
gcc -I/usr/lib/R/include -I/usr/lib/R/include -g -O2 
-I/usr/local/include    -fpic  -O3 -g -std=gnu99 -c laplacian.c -o 
laplacian.o
laplacian.c: In function ?laplacian?:
laplacian.c:14: warning: implicit declaration of function ?clearFrame?
g++ -I/usr/lib/R/include -I/usr/lib/R/include -g -O2 
-I/usr/local/include    -fpic  -O3 -g -c matrix.cpp -o matrix.o
gcc -I/usr/lib/R/include -I/usr/lib/R/include -g -O2 
-I/usr/local/include    -fpic  -O3 -g -std=gnu99 -c smooth.c -o smooth.o
gcc -I/usr/lib/R/include -I/usr/lib/R/include -g -O2 
-I/usr/local/include    -fpic  -O3 -g -std=gnu99 -c sobel.c -o sobel.o
g++ -shared -Bdirect,--hash-stype=both,-Wl,-O1 -o rimage.so equalize.o 
fftw_access_func.o freqfilters.o interface.o jpegio.o laplacian.o 
matrix.o smooth.o sobel.o -ljpeg -lfftw  -L/usr/lib/R/lib -lR
** R
** data
** help
  >>> Building/Updating help pages for package 'rimage'
      Formats: text html latex example
   cat                               text    html    latex   example
   clipping                          text    html    latex   example
   equalize                          text    html    latex   example
   fftImg                            text    html    latex   example
   fftw                              text    html    latex
   highpass                          text    html    latex   example
   imageType                         text    html    latex   example
   imagematrix                       text    html    latex   example
   laplacian                         text    html    latex   example
   logo                              text    html    latex   example
   lowpass                           text    html    latex   example
   meanImg                           text    html    latex   example
   minImg                            text    html    latex   example
   normalize                         text    html    latex   example
   plot.imagematrix                  text    html    latex   example
   print.imagematrix                 text    html    latex   example
   read.jpeg                         text    html    latex   example
   rgb2grey                          text    html    latex   example
   sobel                             text    html    latex   example
   sobel.h                           text    html    latex   example
   sobel.v                           text    html    latex   example
   thresholding                      text    html    latex   example
** building package indices ...
* DONE (rimage)

The downloaded packages are in
         /tmp/RtmprJeHV4/downloaded_packages
 > library(rimage)
Error in dyn.load(x, as.logical(local), as.logical(now)) :
         unable to load shared library 
'/usr/lib/R/library/rimage/libs/rimage.so':
   /usr/lib/R/library/rimage/libs/rimage.so: cannot restore segment prot 
after reloc: Permission denied
Error in library(rimage) : .First.lib failed for 'rimage'
 >


From Manuel.A.Morales at williams.edu  Sun Dec 31 04:04:35 2006
From: Manuel.A.Morales at williams.edu (Manuel Morales)
Date: Sat, 30 Dec 2006 22:04:35 -0500
Subject: [R] getting a new factor
In-Reply-To: <s597038a.091@niloufer.xen.net>
References: <s597038a.091@niloufer.xen.net>
Message-ID: <1167534276.20438.2.camel@solidago.localdomain>

On Sun, 2006-12-31 at 00:25 +0100, Ricardo Rodr?guez wrote:
> Hi all,
> 
> Given a data frame as...
> 
> > head(veg)
>      genus      species trophia type geo zone importance
> 1 Sphagnum  subsecundum       M        A   En        100
> 2 Sphagnum denticulatum       M        A   En        200
> 3  Molinia     caerulea       M        A   En        300
> 4 Sphagnum    flexuosum       M        A   En        400
> 5   Juncus   squarrosus       M        A   En        500
> 6    Carex     echinata       M        A   En        600
> 
> I do need a new one with a new factor constructed from a concatenation of the two first columns, genus and species. I am guessing this must be a simple matter while working with R, but I am stuck at this point.

veg$genus.species <- paste(veg$genus,veg$species)

will add a new column combining genus and species.


-- 
Manuel A. Morales
http://mutualism.williams.edu
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: This is a digitally signed message part
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20061230/270b8505/attachment.bin 

From aikidasgupta at gmail.com  Sun Dec 31 04:11:03 2006
From: aikidasgupta at gmail.com (Abhijit Dasgupta)
Date: Sat, 30 Dec 2006 22:11:03 -0500
Subject: [R] getting a new factor
In-Reply-To: <s597038a.091@niloufer.xen.net>
References: <s597038a.091@niloufer.xen.net>
Message-ID: <45972A47.2040108@mail.jci.tju.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061230/7cf1a88b/attachment.pl 

From magepost at googlemail.com  Sun Dec 31 04:42:16 2006
From: magepost at googlemail.com (Oleg Sklyar)
Date: Sun, 31 Dec 2006 03:42:16 +0000
Subject: [R] importing bitmap images to R
In-Reply-To: <5.2.1.1.1.20061228001646.01b978a8@imap.duke.edu>
References: <5.2.1.1.1.20061228001646.01b978a8@imap.duke.edu>
Message-ID: <399fc6f10612301942q7cd65b23v2435fe97208c80a7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061231/2c40a656/attachment.pl 

From magepost at googlemail.com  Sun Dec 31 04:51:42 2006
From: magepost at googlemail.com (Oleg Sklyar)
Date: Sun, 31 Dec 2006 03:51:42 +0000
Subject: [R] rimage package broken with fedora upgrade
In-Reply-To: <459726A2.9080202@ucsf.edu>
References: <459726A2.9080202@ucsf.edu>
Message-ID: <399fc6f10612301951v34c77ee4uf70886054369c1e8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061231/4657ae3e/attachment.pl 

From fjbuch at gmail.com  Sun Dec 31 07:19:50 2006
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Sun, 31 Dec 2006 01:19:50 -0500
Subject: [R] Genotype importing from Sequenom
Message-ID: <bd93cdad0612302219m5aeeed0fw4cb6bee7621b0244@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061231/2a136437/attachment.pl 

From jim at bitwrit.com.au  Sun Dec 31 07:53:07 2006
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 31 Dec 2006 17:53:07 +1100
Subject: [R] Genotype importing from Sequenom
In-Reply-To: <bd93cdad0612302219m5aeeed0fw4cb6bee7621b0244@mail.gmail.com>
References: <bd93cdad0612302219m5aeeed0fw4cb6bee7621b0244@mail.gmail.com>
Message-ID: <45975E53.8030401@bitwrit.com.au>

Farrel Buchinsky wrote:
> Sequenom has an odd format of calling a SNP genotype
> 
> gg
>  [1] "C"  "GA" "A"  "C"  "C"  "AG" "C"  "C"  "T"  "G"
> 
> homozygous A is called A and heterozygous is called AT
> The genetics package cannot handle the fact that some genotypes are declared
> with 2 letter while other are declared with only 1. Consequently the
> genotype() or makeGenotypes() will not work.
> 
> I need to either find a clever way that the genetics package actually does
> do this. I think it may reside in the "method" argument but do not know how
> to manipulat it. Alternatively I have to come up with some nifty string
> manipulation. Any ideas?
> 
gg1char<-nchar(gg)==1
gg[gg1char]<-paste(gg[gg1char],gg[gg1char],sep="")

Jim


From fjbuch at gmail.com  Sun Dec 31 07:59:56 2006
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Sun, 31 Dec 2006 01:59:56 -0500
Subject: [R] Genotype importing from Sequenom
In-Reply-To: <45975E53.8030401@bitwrit.com.au>
References: <bd93cdad0612302219m5aeeed0fw4cb6bee7621b0244@mail.gmail.com>
	<45975E53.8030401@bitwrit.com.au>
Message-ID: <bd93cdad0612302259o519fcea7w54197ccee7a42c83@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061231/0e0df917/attachment.pl 

From fjbuch at gmail.com  Sun Dec 31 08:17:16 2006
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Sun, 31 Dec 2006 02:17:16 -0500
Subject: [R] Does SQL group by have a heavy duty equivalent in R
Message-ID: <bd93cdad0612302317j674e7e4dk257ac5707964f1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061231/3bfdc727/attachment.pl 

From johnson4 at babel.ling.upenn.edu  Sun Dec 31 10:19:06 2006
From: johnson4 at babel.ling.upenn.edu (Daniel Ezra Johnson)
Date: Sun, 31 Dec 2006 01:19:06 -0800
Subject: [R] zero random effect sizes with binomial lmer
Message-ID: <265AE1A0-C0DA-4C2A-9E3D-3630941732F0@ling.upenn.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20061231/24485088/attachment.pl 

From gregor.gorjanc at bfro.uni-lj.si  Sun Dec 31 13:55:44 2006
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Sun, 31 Dec 2006 12:55:44 +0000 (UTC)
Subject: [R] zero random effect sizes with binomial lmer
References: <265AE1A0-C0DA-4C2A-9E3D-3630941732F0@ling.upenn.edu>
Message-ID: <loom.20061231T135340-487@post.gmane.org>

Daniel Ezra Johnson <johnson4 <at> babel.ling.upenn.edu> writes:
...
> If one compares the random effect estimates, in fact, one sees that  
> they are in the correct proportion, with the expected signs. They are  
> just approximately eight orders of magnitude too small. Is this a bug?
...

BLUPs are essentially shrinkage estimates, where shrinkage is determined with
magnitude of variance. Lower variance more shrinkage towards the mean - zero 
in this case. So this is not a bug.

Gregor


From baron at psych.upenn.edu  Sun Dec 31 16:32:49 2006
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sun, 31 Dec 2006 10:32:49 -0500
Subject: [R] rimage package broken with fedora upgrade
In-Reply-To: <399fc6f10612301951v34c77ee4uf70886054369c1e8@mail.gmail.com>
References: <459726A2.9080202@ucsf.edu>
	<399fc6f10612301951v34c77ee4uf70886054369c1e8@mail.gmail.com>
Message-ID: <20061231153249.GA1890@psych.upenn.edu>

Responding to the original post, which I did not save.

> On 31/12/06, John Kornak <john.kornak at ucsf.edu> wrote:
> >
> >
> > Dear R list members
> >
> > I would be grateful if anyone could guide me to a solution for fixing my
> > rimage package problem described below.
> >
> > I recently upgraded my machine from fedora core 3 to fedora core 6 and
> > then upgraded R from version 2.3.1 from version 2.4.1.
> >
> > I then fired up R, tried to load the rimage library and received the
> > following messages:
> >
> >   > library(rimage)
> > Error in dyn.load(x, as.logical(local), as.logical(now)) :
> >          unable to load shared library
> > '/usr/lib/R/library/rimage/libs/rimage.so':
> >    /usr/lib/R/library/rimage/libs/rimage.so: cannot restore segment prot
> > after reloc: Permission denied
> > Error in library(rimage) : .First.lib failed for 'rimage'

I had the same problem, but, unfortunately, a slightly different error 
message.  My error message said:

> library(rimage)
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
        unable to load shared library
'/usr/lib/R/library/rimage/libs/rimage.so':
  libfftw.so.2: cannot open shared object file: No such file or
directory
Error in library(rimage) : .First.lib failed for 'rimage'

So I took the hint and said

yum install libfftw.so.2

and this installed libfftw,
which cured the problem.

But you did not get this error message about libfftw.

Jon


From h.wickham at gmail.com  Sun Dec 31 16:58:34 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 31 Dec 2006 07:58:34 -0800
Subject: [R] Does SQL group by have a heavy duty equivalent in R
In-Reply-To: <bd93cdad0612302317j674e7e4dk257ac5707964f1@mail.gmail.com>
References: <bd93cdad0612302317j674e7e4dk257ac5707964f1@mail.gmail.com>
Message-ID: <f8e6ff050612310758p11f96c0dl256ac5b15d11dc2c@mail.gmail.com>

> nr.attempts
> <-aggregate(RawSeq$GENOTYPE_ID,list(sample=RawSeq$SAMPLE_ID,assay=RawSeq$ASSAY_ID),length)
> This was simply to figure out how many times the same piece of information
> had been obtained. I ran out of patience. It took beyond forever and tapply
> did not perform much better. The reshape package did not help - it implied
> one was out of luck if the data was not numeric. All of my data is character
> or factor.

The reshape package will work if all your data is numeric, or all of
it is character - it doesn't work with a mix.  I will try and make
this more clear in the documentation.
However, depending on the size and structure of your data it may not
be any faster than tapply or aggregate.

Hadley


From HDoran at air.org  Sun Dec 31 17:19:34 2006
From: HDoran at air.org (Doran, Harold)
Date: Sun, 31 Dec 2006 11:19:34 -0500
Subject: [R] OT: any recommendation for scripting language
Message-ID: <2323A6D37908A847A7C32F1E3662C80E6B0E5F@dc1ex01.air.org>

I'm a bit new with python, but have found it extremely easy to learn and
use. I have been using it to pre-process some text files that we often
deal with and need to be formatted in a certain way before they can be
used for statistical analysis in another software program.

I suppose there is one thing I've learned that can make python a bit
more useful than R. It is possible to use Freeze to make your python
programs stand alone executables. So, if you have any need to have a
non-programmer replicate something easily, you can write a python
program and even make a GUI with Tkinter that will work on any platform
(as I understand it). 

Just the other day, a colleague and I wrote programs to process a text
file. His was SAS and mine was python and both gave the same end result.
My python code was about 4 lines long whereas his SAS code was
ridiculously long and hard to understand. We settled a bet than python
is better for this kind of stuff.

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wensui Liu
> Sent: Saturday, December 30, 2006 6:28 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] OT: any recommendation for scripting language
> 
> Dear Experts,
> 
> Thank you so much for your opinions. I probably will go with python.
> 
> Following your suggestion, I started reading some tutorials 
> but have a quick question. In the sense of statistical 
> computing, is there anything that can be easily done with 
> python but not with SAS/R? Could you please give such an example?
> 
> Wish you all have a happy new year!
> 
> wensui
> 
> On 12/23/06, Wensui Liu <liuwensui at gmail.com> wrote:
> > Right now, I am using SAS and S+/R. As a new year resolution, I am 
> > planning to learn a scripting language.
> >
> > from statisticians' point of view, which scripting language 
> is worth 
> > to learn, perl, python, or any other recommendation? (Most 
> likely, I 
> > will be learning it in windows.) Since I am not in research, I will 
> > prefer one widely used in industry and related to statistical work.
> >
> > if you recommend one, I will really appreciate it if you 
> could point 
> > out a good source for learning as well.
> >
> > thank you so much!
> >
> > Have a happy holiday.
> >
> > wensui
> >
> 
> 
> --
> WenSui Liu
> A lousy statistician who happens to know a little programming
> (http://spaces.msn.com/statcompute/blog)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From alfilnegro.sv at gmail.com  Sun Dec 31 17:43:32 2006
From: alfilnegro.sv at gmail.com (Ricardo Rios)
Date: Sun, 31 Dec 2006 10:43:32 -0600
Subject: [R] Which programming paradigm does R
Message-ID: <50a711930612310843p38933bc7tfbc485012ac4d9e9@mail.gmail.com>

Hi wizards, I have a question. Which programming paradigm does R
handle? . Iam looking for this information but I didn't found nothing.

 Thanks in advance.




personal web site:
http://www.geocities.com/ricardo_rios_sv/index.html



-- 
personal web site:
http://www.geocities.com/ricardo_rios_sv/index.html


From ggrothendieck at gmail.com  Sun Dec 31 17:58:44 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 31 Dec 2006 11:58:44 -0500
Subject: [R] Which programming paradigm does R
In-Reply-To: <50a711930612310843p38933bc7tfbc485012ac4d9e9@mail.gmail.com>
References: <50a711930612310843p38933bc7tfbc485012ac4d9e9@mail.gmail.com>
Message-ID: <971536df0612310858x3e4161cbg9b3f497a63396c5b@mail.gmail.com>

Its object oriented inspired by the  Dylan language and Scheme.  Some additional
information is available in this thread:
https://stat.ethz.ch/pipermail/r-help/2003-July/036437.html

There are also a number of packages which layer other programming
language models on top of R:

- R.oo provides for conventional OO
  http://www.maths.lth.se/help/R/R.oo/

- proto provides for the prototype programming model (i.e. classless OO)
  http://hhbio.wasser.tu-dresden.de/projects/proto/


On 12/31/06, Ricardo Rios <alfilnegro.sv at gmail.com> wrote:
> Hi wizards, I have a question. Which programming paradigm does R
> handle? . Iam looking for this information but I didn't found nothing.
>
>  Thanks in advance.
>
>
>
>
> personal web site:
> http://www.geocities.com/ricardo_rios_sv/index.html
>
>
>
> --
> personal web site:
> http://www.geocities.com/ricardo_rios_sv/index.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From johnson4 at babel.ling.upenn.edu  Sun Dec 31 18:27:41 2006
From: johnson4 at babel.ling.upenn.edu (Daniel Ezra Johnson)
Date: Sun, 31 Dec 2006 12:27:41 -0500 (EST)
Subject: [R] (no subject)
Message-ID: <Pine.LNX.4.63.0612311212520.20533@babel.ling.upenn.edu>

> > If one compares the random effect estimates, in fact, one sees that
> > they are in the correct proportion, with the expected signs. They are
> > just approximately eight orders of magnitude too small. Is this a bug?
>
> BLUPs are essentially shrinkage estimates, where shrinkage is
> determined with magnitude of variance. Lower variance more
> shrinkage towards the mean - zero in this case. So this is not a bug.
>
> Gregor

I doubled each data set by duplicating each Subject. There are now
46 subjects in each group instead of 23. So now A and B differ in 2
observations out of 322. The lmer resuls are sensible.

I know BLUPs are not like regular parameters, but doubling (or cutting
in half) the data should not, in my opinion, cause this behavior. There
is a lot of room for the original A variance estimate to be lower than B,
maybe it should be 0.05, 0.01, 0.05, or whatever, but not < .0000000005.

"DOUBLED" (Laplace)
A
Groups  Name        Variance Std.Dev.
Subject (Intercept) 1.759    1.326
Item    (Intercept) 0.178    0.422
number of obs: 322, groups: Subject, 46; Item, 7
B
Groups  Name        Variance Std.Dev.
Subject (Intercept) 1.892    1.376
Item    (Intercept) 0.319    0.564
number of obs: 322, groups: Subject, 46; Item, 7

"ORIGINAL" (Laplace)
A
Groups Name Variance Std.Dev.
Subject (Intercept) 1.63    1.28
Item (Intercept) 5.00e-10 2.24e-05
number of obs: 161, groups: Subject, 23; Item, 7
B
Groups  Name        Variance Std.Dev.
Subject (Intercept) 1.712    1.308
Item    (Intercept) 0.109    0.330
number of obs: 161, groups: Subject, 23; Item, 7

By the way, using the PQL method instead of Laplace "fails"
even more badly with the original data (and gives very
different estimates with the doubled data).

"DOUBLED" (PQL)
A
Groups  Name        Variance Std.Dev.
Subject (Intercept) 2.997    1.731
Item    (Intercept) 0.509    0.713
number of obs: 322, groups: Subject, 46; Item, 7
B
Subject (Intercept) 3.317    1.821
Item    (Intercept) 0.725    0.852
number of obs: 322, groups: Subject, 46; Item, 7
"ORIGINAL" (PQL)
A
1: Estimated variance for factor Item
  is effectively zero
in: LMEopt(x = mer, value = cv)
2: Estimated variance for factors Subject, Item
  is effectively zero
in: LMEopt(x = mer, value = cv)
B
Estimated variance for factors Subject, Item
  is effectively zero
in: LMEopt(x = mer, value = cv)

I understand that the between-Item variance is low, and probably
it is no greater than what you would expect to occur by chance,
but isn't that what hypothesis testing is for (anova, etc.)?

Is my best way around the algorithm returning zero to do
what I have done above, with my real data? That is, duplicate
(or triplicate) Subjects to increase my data size, and thereby
get a reasonably comparable (if wrong) estimate of the Item variance?
Zero is not a reasonable estimate in any of these data sets.

Thanks,
Daniel

> A.fit # "DOUBLED" DATA A
Generalized linear mixed model fit using Laplace
Formula: Response ~ (1 | Subject) + (1 | Item)
    Data: A
Family: binomial(logit link)
AIC BIC logLik deviance
232 243   -113      226
Random effects:
Groups  Name        Variance Std.Dev.
Subject (Intercept) 1.759    1.326
Item    (Intercept) 0.178    0.422
number of obs: 322, groups: Subject, 46; Item, 7

Estimated scale (compare to  1 )  0.81576

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   -2.601      0.327   -7.95  1.9e-15 ***
---

> B.fit  # "DOUBLED" DATA B
Generalized linear mixed model fit using Laplace
Formula: Response ~ (1 | Subject) + (1 | Item)
    Data: B
Family: binomial(logit link)
AIC BIC logLik deviance
237 249   -116      231
Random effects:
Groups  Name        Variance Std.Dev.
Subject (Intercept) 1.892    1.376
Item    (Intercept) 0.319    0.564
number of obs: 322, groups: Subject, 46; Item, 7

Estimated scale (compare to  1 )  0.8052

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)    -2.61       0.36   -7.25  4.1e-13 ***

> ranef(A.fit)$Item  # "DOUBLED" DATA A
   (Intercept)
1   -0.084969
2   -0.084969
3   -0.084969
4    0.325780
5   -0.308044
6    0.515590        # 10 1's, 36 0's
7    0.325780
> ranef(B.fit)$Item  # "DOUBLED" DATA B
   (Intercept)
1    -0.11962
2    -0.11962
3    -0.11962
4     0.42389
5    -0.43555
6     0.88322        # 12 1's, 34 0's
7     0.42389

On Dec 31, 2006, at 1:19 AM, Daniel Ezra Johnson wrote:

I am fitting models to the responses to a questionnaire that has seven 
yes/no questions (Item). For each combination of Subject and Item, the 
variable Response is coded as 0 or 1.

I want to include random effects for both Subject and Item. While I 
understand that the datasets are fairly small, and there are a lot of 
invariant subjects, I do not understand something that is happening here, 
and in comparing other subsets of the data.

In the data below, which has been adjusted to show this phenomenon 
clearly, the Subject random effect variance is comparable for A (1.63) and 
B (1.712), but the Item random effect variance comes out as 0.109 for B 
and essentially zero for A (5.00e-10).

Note that the only difference between data set A and data set B occurs on 
row 19, where a single instance of Response is changed.

Item			avg. Response in A		avg. Response in B
1				9%				9%
2				9%				9%
3				9%				9%
4				17%				17%
5				4%				4%
6				22%		<->		26%
7				17%				17%

Why does the Item random effect sometimes "crash" to zero? Surely there is 
some more reasonable estimate of the Item effect than zero. The items 
still have clearly different Response behavior.

If one compares the random effect estimates, in fact, one sees that they 
are in the correct proportion, with the expected signs. They are just 
approximately eight orders of magnitude too small. Is this a bug?

More broadly, is it hopeless to analyze this data in this manner, or else, 
what should I try doing differently? It would be very useful to be able to 
have reliable estimates of random effect sizes, even when they are rather 
small.

I've included replicable code below, sorry that I did not know how to make 
it more compact!

a1 <- c(0,0,0,0,0,0,0)
a2 <- c(0,0,0,0,0,0,0)
a3 <- c(0,0,0,0,0,0,0)
a4 <- c(0,0,0,0,0,0,0)
a5 <- c(0,0,0,0,0,0,0)
a6 <- c(0,0,0,0,0,0,0)
a7 <- c(0,0,0,0,0,0,0)
a8 <- c(0,0,0,0,0,0,0)
a9 <- c(0,0,0,0,0,0,0)
a10 <- c(0,0,0,0,0,0,0)
a11 <- c(0,0,0,0,0,0,0)
a12 <- c(0,0,0,0,0,0,0)
a13 <- c(0,0,0,0,0,0,1)
a14 <- c(0,0,0,0,0,0,1)
a15 <- c(0,0,0,0,0,1,0)
a16 <- c(0,0,0,0,1,0,0)
a17 <- c(0,0,0,1,0,0,0)
a18 <- c(0,0,1,0,0,0,0)
a19 <- c(0,1,0,0,0,0,0)  # differs
a20 <- c(0,1,0,0,0,1,0)
a21 <- c(0,0,0,1,0,1,1)
a22 <- c(1,0,0,1,0,1,1)
a23 <- c(1,0,1,1,0,1,0)
aa <- 
rbind(a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11,a12,a13,a14,a15,a16,a17,a18,a19,a20,a21,a22,a23)

b1 <- c(0,0,0,0,0,0,0)
b2 <- c(0,0,0,0,0,0,0)
b3 <- c(0,0,0,0,0,0,0)
b4 <- c(0,0,0,0,0,0,0)
b5 <- c(0,0,0,0,0,0,0)
b6 <- c(0,0,0,0,0,0,0)
b7 <- c(0,0,0,0,0,0,0)
b8 <- c(0,0,0,0,0,0,0)
b9 <- c(0,0,0,0,0,0,0)
b10 <- c(0,0,0,0,0,0,0)
b11 <- c(0,0,0,0,0,0,0)
b12 <- c(0,0,0,0,0,0,0)
b13 <- c(0,0,0,0,0,0,1)
b14 <- c(0,0,0,0,0,0,1)
b15 <- c(0,0,0,0,0,1,0)
b16 <- c(0,0,0,0,1,0,0)
b17 <- c(0,0,0,1,0,0,0)
b18 <- c(0,0,1,0,0,0,0)
b19 <- c(0,1,0,0,0,1,0)  # differs
b20 <- c(0,1,0,0,0,1,0)
b21 <- c(0,0,0,1,0,1,1)
b22 <- c(1,0,0,1,0,1,1)
b23 <- c(1,0,1,1,0,1,0)
bb <- 
rbind(b1,b2,b3,b4,b5,b6,b7,b8,b9,b10,b11,b12,b13,b14,b15,b16,b17,b18,b19,b20,b21,b22,b23)

a <- array(0, c(161,3), list(NULL, c("Subject","Item","Response")))
 	for (s in c(1:23))
 		for (i in c(1:7))
 			a[7*(s-1)+i,] <- c(s,i,aa[s,i])
A <- data.frame(a)

b <- array(0, c(161,3), list(NULL,c("Subject","Item","Response")))
 	for (s in c(1:23))
 		for (i in c(1:7))
 			b[7*(s-1)+i,] <- c(s,i,bb[s,i])
B <- data.frame(b)

A.fit <- lmer(Response~(1|Subject)+(1|Item),A,binomial)
B.fit <- lmer(Response~(1|Subject)+(1|Item),B,binomial)
A.fit
B.fit
ranef(A.fit)$Item
ranef(B.fit)$Item

Generalized linear mixed model fit using Laplace
Formula: Response ~ (1 | Subject) + (1 | Item)
    Data: A
Family: binomial(logit link)
AIC BIC logLik deviance
120 129  -56.8      114
Random effects:
Groups  Name        Variance Std.Dev.
Subject (Intercept) 1.63e+00 1.28e+00
Item    (Intercept) 5.00e-10 2.24e-05
number of obs: 161, groups: Subject, 23; Item, 7

Estimated scale (compare to  1 )  0.83326

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   -2.517      0.395   -6.38  1.8e-10 ***

    Data: B
Family: binomial(logit link)
AIC BIC logLik deviance
123 133  -58.6      117
Random effects:
Groups  Name        Variance Std.Dev.
Subject (Intercept) 1.712    1.308
Item    (Intercept) 0.109    0.330
number of obs: 161, groups: Subject, 23; Item, 7

Estimated scale (compare to  1 )  0.81445

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   -2.498      0.415   -6.02  1.8e-09 ***
---
> ranef(A.fit)$Item
   (Intercept)
1 -2.8011e-10
2 -2.8011e-10
3 -2.8011e-10
4  7.1989e-10
5 -7.8011e-10
6  1.2199e-09    # 5 1's, 18 0's
7  7.1989e-10
> ranef(B.fit)$Item
   (Intercept)
1   -0.056937
2   -0.056937
3   -0.056937
4    0.120293
5   -0.146925
6    0.293893    # 6 1's, 17 0's
7    0.120293


From johnson4 at babel.ling.upenn.edu  Sun Dec 31 18:32:11 2006
From: johnson4 at babel.ling.upenn.edu (Daniel Ezra Johnson)
Date: Sun, 31 Dec 2006 12:32:11 -0500 (EST)
Subject: [R] zero random effect sizes with binomial lmer
Message-ID: <Pine.LNX.4.63.0612311228300.20533@babel.ling.upenn.edu>

> > If one compares the random effect estimates, in fact, one sees that
> > they are in the correct proportion, with the expected signs. They are
> > just approximately eight orders of magnitude too small. Is this a bug?
> 
> BLUPs are essentially shrinkage estimates, where shrinkage is
> determined with magnitude of variance. Lower variance more
> shrinkage towards the mean - zero in this case. So this is not a bug.
> 
> Gregor

I doubled each data set by duplicating each Subject. There are now
46 subjects in each group instead of 23. So now A and B differ in 2
observations out of 322. The lmer resuls are sensible.

I know BLUPs are not like regular parameters, but doubling (or cutting
in half) the data should not, in my opinion, cause this behavior. There
is a lot of room for the original A variance estimate to be lower than B,
maybe it should be 0.05, 0.01, 0.05, or whatever, but not < .0000000005.

"DOUBLED" (Laplace)
A
Groups  Name        Variance Std.Dev.
Subject (Intercept) 1.759    1.326
Item    (Intercept) 0.178    0.422
number of obs: 322, groups: Subject, 46; Item, 7
B
Groups  Name        Variance Std.Dev.
Subject (Intercept) 1.892    1.376
Item    (Intercept) 0.319    0.564
number of obs: 322, groups: Subject, 46; Item, 7

"ORIGINAL" (Laplace)
A
Groups Name Variance Std.Dev.
Subject (Intercept) 1.63    1.28
Item (Intercept) 5.00e-10 2.24e-05
number of obs: 161, groups: Subject, 23; Item, 7
B
Groups  Name        Variance Std.Dev.
Subject (Intercept) 1.712    1.308
Item    (Intercept) 0.109    0.330
number of obs: 161, groups: Subject, 23; Item, 7

By the way, using the PQL method instead of Laplace "fails"
even more badly with the original data (and gives very
different estimates with the doubled data).

"DOUBLED" (PQL)
A
Groups  Name        Variance Std.Dev.
Subject (Intercept) 2.997    1.731
Item    (Intercept) 0.509    0.713
number of obs: 322, groups: Subject, 46; Item, 7
B
Subject (Intercept) 3.317    1.821
Item    (Intercept) 0.725    0.852
number of obs: 322, groups: Subject, 46; Item, 7

"ORIGINAL" (PQL)
A
1: Estimated variance for factor Item
  is effectively zero
in: LMEopt(x = mer, value = cv)
2: Estimated variance for factors Subject, Item
  is effectively zero
in: LMEopt(x = mer, value = cv)
B
Estimated variance for factors Subject, Item
  is effectively zero
in: LMEopt(x = mer, value = cv)

I understand that the between-Item variance is low, and probably
it is no greater than what you would expect to occur by chance,
but isn't that what hypothesis testing is for (anova, etc.)?

Is my best way around the algorithm returning zero to do
what I have done above, with my real data? That is, duplicate
(or triplicate) Subjects to increase my data size, and thereby
get a reasonably comparable (if wrong) estimate of the Item variance?
Zero is not a reasonable estimate in any of these data sets.

Thanks,
Daniel

> A.fit # "DOUBLED" DATA A
Generalized linear mixed model fit using Laplace
Formula: Response ~ (1 | Subject) + (1 | Item)
    Data: A
Family: binomial(logit link)
AIC BIC logLik deviance
232 243   -113      226
Random effects:
Groups  Name        Variance Std.Dev.
Subject (Intercept) 1.759    1.326
Item    (Intercept) 0.178    0.422
number of obs: 322, groups: Subject, 46; Item, 7

Estimated scale (compare to  1 )  0.81576

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   -2.601      0.327   -7.95  1.9e-15 ***
---

> B.fit  # "DOUBLED" DATA B
Generalized linear mixed model fit using Laplace
Formula: Response ~ (1 | Subject) + (1 | Item)
    Data: B
Family: binomial(logit link)
AIC BIC logLik deviance
237 249   -116      231
Random effects:
Groups  Name        Variance Std.Dev.
Subject (Intercept) 1.892    1.376
Item    (Intercept) 0.319    0.564
number of obs: 322, groups: Subject, 46; Item, 7

Estimated scale (compare to  1 )  0.8052

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)    -2.61       0.36   -7.25  4.1e-13 ***

> ranef(A.fit)$Item  # "DOUBLED" DATA A
   (Intercept)
1   -0.084969
2   -0.084969
3   -0.084969
4    0.325780
5   -0.308044
6    0.515590        # 10 1's, 36 0's
7    0.325780
> ranef(B.fit)$Item  # "DOUBLED" DATA B
   (Intercept)
1    -0.11962
2    -0.11962
3    -0.11962
4     0.42389
5    -0.43555
6     0.88322        # 12 1's, 34 0's
7     0.42389

On Dec 31, 2006, at 1:19 AM, Daniel Ezra Johnson wrote:

I am fitting models to the responses to a questionnaire that has seven 
yes/no questions (Item). For each combination of Subject and Item, the 
variable Response is coded as 0 or 1.

I want to include random effects for both Subject and Item. While I 
understand that the datasets are fairly small, and there are a lot of 
invariant subjects, I do not understand something that is happening here, 
and in comparing other subsets of the data.

In the data below, which has been adjusted to show this phenomenon 
clearly, the Subject random effect variance is comparable for A (1.63) and 
B (1.712), but the Item random effect variance comes out as 0.109 for B 
and essentially zero for A (5.00e-10).

Note that the only difference between data set A and data set B occurs on 
row 19, where a single instance of Response is changed.

Item			avg. Response in A		avg. Response in B
1				9%				9%
2				9%				9%
3				9%				9%
4				17%				17%
5				4%				4%
6				22%		<->		26%
7				17%				17%

Why does the Item random effect sometimes "crash" to zero? Surely there is 
some more reasonable estimate of the Item effect than zero. The items 
still have clearly different Response behavior.

If one compares the random effect estimates, in fact, one sees that they 
are in the correct proportion, with the expected signs. They are just 
approximately eight orders of magnitude too small. Is this a bug?

More broadly, is it hopeless to analyze this data in this manner, or else, 
what should I try doing differently? It would be very useful to be able to 
have reliable estimates of random effect sizes, even when they are rather 
small.

I've included replicable code below, sorry that I did not know how to make 
it more compact!

a1 <- c(0,0,0,0,0,0,0)
a2 <- c(0,0,0,0,0,0,0)
a3 <- c(0,0,0,0,0,0,0)
a4 <- c(0,0,0,0,0,0,0)
a5 <- c(0,0,0,0,0,0,0)
a6 <- c(0,0,0,0,0,0,0)
a7 <- c(0,0,0,0,0,0,0)
a8 <- c(0,0,0,0,0,0,0)
a9 <- c(0,0,0,0,0,0,0)
a10 <- c(0,0,0,0,0,0,0)
a11 <- c(0,0,0,0,0,0,0)
a12 <- c(0,0,0,0,0,0,0)
a13 <- c(0,0,0,0,0,0,1)
a14 <- c(0,0,0,0,0,0,1)
a15 <- c(0,0,0,0,0,1,0)
a16 <- c(0,0,0,0,1,0,0)
a17 <- c(0,0,0,1,0,0,0)
a18 <- c(0,0,1,0,0,0,0)
a19 <- c(0,1,0,0,0,0,0)  # differs
a20 <- c(0,1,0,0,0,1,0)
a21 <- c(0,0,0,1,0,1,1)
a22 <- c(1,0,0,1,0,1,1)
a23 <- c(1,0,1,1,0,1,0)
aa <- 
rbind(a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11,a12,a13,a14,a15,a16,a17,a18,a19,a20,a21,a22,a23)

b1 <- c(0,0,0,0,0,0,0)
b2 <- c(0,0,0,0,0,0,0)
b3 <- c(0,0,0,0,0,0,0)
b4 <- c(0,0,0,0,0,0,0)
b5 <- c(0,0,0,0,0,0,0)
b6 <- c(0,0,0,0,0,0,0)
b7 <- c(0,0,0,0,0,0,0)
b8 <- c(0,0,0,0,0,0,0)
b9 <- c(0,0,0,0,0,0,0)
b10 <- c(0,0,0,0,0,0,0)
b11 <- c(0,0,0,0,0,0,0)
b12 <- c(0,0,0,0,0,0,0)
b13 <- c(0,0,0,0,0,0,1)
b14 <- c(0,0,0,0,0,0,1)
b15 <- c(0,0,0,0,0,1,0)
b16 <- c(0,0,0,0,1,0,0)
b17 <- c(0,0,0,1,0,0,0)
b18 <- c(0,0,1,0,0,0,0)
b19 <- c(0,1,0,0,0,1,0)  # differs
b20 <- c(0,1,0,0,0,1,0)
b21 <- c(0,0,0,1,0,1,1)
b22 <- c(1,0,0,1,0,1,1)
b23 <- c(1,0,1,1,0,1,0)
bb <- 
rbind(b1,b2,b3,b4,b5,b6,b7,b8,b9,b10,b11,b12,b13,b14,b15,b16,b17,b18,b19,b20,b21,b22,b23)

a <- array(0, c(161,3), list(NULL, c("Subject","Item","Response")))
 	for (s in c(1:23))
 		for (i in c(1:7))
 			a[7*(s-1)+i,] <- c(s,i,aa[s,i])
A <- data.frame(a)

b <- array(0, c(161,3), list(NULL,c("Subject","Item","Response")))
 	for (s in c(1:23))
 		for (i in c(1:7))
 			b[7*(s-1)+i,] <- c(s,i,bb[s,i])
B <- data.frame(b)

A.fit <- lmer(Response~(1|Subject)+(1|Item),A,binomial)
B.fit <- lmer(Response~(1|Subject)+(1|Item),B,binomial)
A.fit
B.fit
ranef(A.fit)$Item
ranef(B.fit)$Item

Generalized linear mixed model fit using Laplace
Formula: Response ~ (1 | Subject) + (1 | Item)
    Data: A
Family: binomial(logit link)
AIC BIC logLik deviance
120 129  -56.8      114
Random effects:
Groups  Name        Variance Std.Dev.
Subject (Intercept) 1.63e+00 1.28e+00
Item    (Intercept) 5.00e-10 2.24e-05
number of obs: 161, groups: Subject, 23; Item, 7

Estimated scale (compare to  1 )  0.83326

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   -2.517      0.395   -6.38  1.8e-10 ***

    Data: B
Family: binomial(logit link)
AIC BIC logLik deviance
123 133  -58.6      117
Random effects:
Groups  Name        Variance Std.Dev.
Subject (Intercept) 1.712    1.308
Item    (Intercept) 0.109    0.330
number of obs: 161, groups: Subject, 23; Item, 7

Estimated scale (compare to  1 )  0.81445

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   -2.498      0.415   -6.02  1.8e-09 ***
---
ranef(A.fit)$Item
   (Intercept)
1 -2.8011e-10
2 -2.8011e-10
3 -2.8011e-10
4  7.1989e-10
5 -7.8011e-10
6  1.2199e-09    # 5 1's, 18 0's
7  7.1989e-10
ranef(B.fit)$Item
   (Intercept)
1   -0.056937
2   -0.056937
3   -0.056937
4    0.120293
5   -0.146925
6    0.293893    # 6 1's, 17 0's
7    0.120293


From webmaster at xen.net  Sun Dec 31 19:18:50 2006
From: webmaster at xen.net (=?ISO-8859-1?Q?Ricardo=20Rodr=EDguez?=)
Date: Sun, 31 Dec 2006 19:18:50 +0100
Subject: [R] tabulate: switching columns and rows
Message-ID: <s5980d3c.098@niloufer.xen.net>

Hi all,

Please, is there any way of controlling factors in row/columns when using ftable/xtabs? As far as I can see, the last cross-clasifing variable in the formula will appear in columns. The previous ones, in rows. For instance, is it possible to make  tension and replicate appear in columns?

ftable(xtabs(breaks ~ wool + tension + replicate, data = warpbreaks))

After some years using SAS proc tabulate I am afraid I don't get the point with R and cross-tabulation :-( 

Thanks you very much and Happy New Year!

Ricardo

---
Ricardo Rodr?guez
Your XEN ICT Team


From h.wickham at gmail.com  Sun Dec 31 19:33:11 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 31 Dec 2006 10:33:11 -0800
Subject: [R] tabulate: switching columns and rows
In-Reply-To: <s5980d3c.098@niloufer.xen.net>
References: <s5980d3c.098@niloufer.xen.net>
Message-ID: <f8e6ff050612311033j7255e9d1u803a7597b5ce685@mail.gmail.com>

Hi Ricardo,

> Please, is there any way of controlling factors in row/columns when using ftable/xtabs? As far as I can see, the last cross-clasifing variable in the formula will appear in columns. The previous ones, in rows. For instance, is it possible to make  tension and replicate appear in columns?
>
> ftable(xtabs(breaks ~ wool + tension + replicate, data = warpbreaks))
>
> After some years using SAS proc tabulate I am afraid I don't get the point with R and cross-tabulation :-(

You might want to have a look at the reshape package,
http://had.co.nz/reshape, which provides a more general and flexible
framework for reshaping data in R.

The version of warpbreaks I have doesn't have the replicate variable,
so unfortunately I can't provide you with example code for this case.
However, you should be able to figure it out for your data using the
documentation available on the website.

Regards,

Hadley


From webmaster at xen.net  Sun Dec 31 19:44:04 2006
From: webmaster at xen.net (Ricardo =?ISO-8859-1?Q?Rodr=EDguez=20-=20Your=20XEN=20ICT=20Team?=)
Date: 31 Dec 2006 19:44:04 +0100
Subject: [R] tabulate: switching columns and rows
References: d7449f972ba9eb03b48f9911905446b7
Message-ID: <20061231T194404Z_C5AC00020000@xen.net>

>>> hadley wickham<h.wickham at gmail.com> 31/12/2006 19:33 >>>

>Hi Ricardo,

>You might want to have a look at the reshape package,
>http://had.co.nz/reshape, which provides a more general and flexible
>framework for reshaping data in R.
>
>The version of warpbreaks I have doesn't have the replicate variable,
>so unfortunately I can't provide you with example code for this case.
>However, you should be able to figure it out for your data using the
>documentation available on the website.

Thanks, Hadley,
 
My fault: I've not provided the line concerning replicate variable. It is included in ?xtabs:

warpbreaks$replicate <- rep(1:9, len = 54)

It will be great to have an example with these given data. Anyway, I will have a look to reshape at the given site. Thanks a lot!

Cheers,

Ricardo




--
Ricardo Rodr?guez
Your XEN ICT Team


From ggrothendieck at gmail.com  Sun Dec 31 19:50:34 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 31 Dec 2006 13:50:34 -0500
Subject: [R] tabulate: switching columns and rows
In-Reply-To: <s5980d3c.098@niloufer.xen.net>
References: <s5980d3c.098@niloufer.xen.net>
Message-ID: <971536df0612311050nb8c3578s23eacfeed4dfe5ab@mail.gmail.com>

Add the argument col.vars = 2:3 to your ftable call.  See ?ftable

On 12/31/06, Ricardo Rodr?guez <webmaster at xen.net> wrote:
> Hi all,
>
> Please, is there any way of controlling factors in row/columns when using ftable/xtabs? As far as I can see, the last cross-clasifing variable in the formula will appear in columns. The previous ones, in rows. For instance, is it possible to make  tension and replicate appear in columns?
>
> ftable(xtabs(breaks ~ wool + tension + replicate, data = warpbreaks))
>
> After some years using SAS proc tabulate I am afraid I don't get the point with R and cross-tabulation :-(
>
> Thanks you very much and Happy New Year!
>
> Ricardo
>
> ---
> Ricardo Rodr?guez
> Your XEN ICT Team
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From johnson4 at babel.ling.upenn.edu  Sun Dec 31 19:50:40 2006
From: johnson4 at babel.ling.upenn.edu (Daniel Ezra Johnson)
Date: Sun, 31 Dec 2006 13:50:40 -0500 (EST)
Subject: [R] zero random effect sizes with binomial lmer
Message-ID: <Pine.LNX.4.63.0612311250330.23497@babel.ling.upenn.edu>

I've found a way to make this problem, if it's not a bug, more clear. 
I've taken my original data set A and simply doubled it with 
AA<-rbind(A,A).

Doing so, instead of this:

Random effects: # A
  Groups  Name        Variance Std.Dev.
  Subject (Intercept) 1.63e+00 1.28e+00
  Item    (Intercept) 5.00e-10 2.24e-05
number of obs: 161, groups: Subject, 23; Item, 7

I get this:

Random effects: # AA
  Groups  Name        Variance Std.Dev.
  Subject (Intercept) 3.728    1.931
  Item    (Intercept) 0.319    0.565
number of obs: 322, groups: Subject, 23; Item, 7

I think I understand why the Subject effect increases. On a per-Response 
basis, there is more variation between Subjects. However, the 
probability (hence log odds, etc.) of the Response seems to be 
constant, so I am not sure. In any case, the ranef variance increases by 
a factor of 2.3, going from A to AA:

Response 1:0	Dataset A	Dataset AA
Subject  1	 0 :  7		 0 : 14
Subject  2	 0 :  7		 0 : 14
Subject  3	 0 :  7		 0 : 14
Subject  4	 0 :  7		 0 : 14
Subject  5	 0 :  7		 0 : 14
Subject  6	 0 :  7		 0 : 14
Subject  7	 0 :  7		 0 : 14
Subject  8	 0 :  7		 0 : 14
Subject  9	 0 :  7		 0 : 14
Subject 10	 0 :  7		 0 : 14
Subject 11	 0 :  7		 0 : 14
Subject 12	 0 :  7		 0 : 14
Subject 13	 1 :  6		 2 : 12
Subject 14	 1 :  6		 2 : 12
Subject 15	 1 :  6		 2 : 12
Subject 16	 1 :  6		 2 : 12
Subject 17	 1 :  6		 2 : 12
Subject 18	 1 :  6		 2 : 12
Subject 19	 1 :  6		 2 : 12
Subject 20	 2 :  5		 4 : 10
Subject 21	 3 :  4		 6 :  8
Subject 22	 4 :  3		 8 :  6
Subject 23	 4 :  3		 8 :  6

Ranef s^2	 1.630		 3.728

Comparing the Items, though, we have:

Response 1:0	Dataset A	Dataset AA
Item 1		 2 : 21		 4 : 42
Item 2		 2 : 21		 4 : 42
Item 3		 2 : 21		 4 : 42
Item 4		 4 : 19		 8 : 38
Item 5		 1 : 22		 2 : 44 
Item 6		 5 : 18		10 : 36 
Item 7		 4 : 19		 8 : 38

Ranef s^2:	 5.00xe-10	 0.319

Looking at this completely naively, I don't understand why whatever 
statistical difference doubling the data for each Item makes, shouldn't be 
similar to what happened above, for Subject. Instead, we have an estimate 
of zero for the smaller data set.

I realize that I don't understand the actual mathematics by which the 
BLUPs (and thus the variances) are calculated, but something seems wrong 
here. Obviously between A and AA nothing changes as far as the interaction 
of Subject and Item in particular combinations.

How should i best understand this behavior of lmer, and what is my best 
advice for obtaining reliable random effect size estimates from data like 
this? Are the estimates at least reliable when they are NOT zero?

Thanks,
Daniel

P.S. I'll point out again that the by multiplying the "zero" ranef 
estimate for A by an enormous constant (see blow), it is almost identical 
to thet for AA. Obviously these coefficients derive from the marginal 
proportions in the data. And I understand that with small N's, the random 
effect may not be signifiicant. But that shouldn't mean that the estimate 
is zero, right (compare fixed effect coefficients, which are often 
non-zero, yet not significant...)

a1 <- c(0,0,0,0,0,0,0)
a2 <- c(0,0,0,0,0,0,0)
a3 <- c(0,0,0,0,0,0,0)
a4 <- c(0,0,0,0,0,0,0)
a5 <- c(0,0,0,0,0,0,0)
a6 <- c(0,0,0,0,0,0,0)
a7 <- c(0,0,0,0,0,0,0)
a8 <- c(0,0,0,0,0,0,0)
a9 <- c(0,0,0,0,0,0,0)
a10 <- c(0,0,0,0,0,0,0)
a11 <- c(0,0,0,0,0,0,0)
a12 <- c(0,0,0,0,0,0,0)
a13 <- c(0,0,0,0,0,0,1)
a14 <- c(0,0,0,0,0,0,1)
a15 <- c(0,0,0,0,0,1,0)
a16 <- c(0,0,0,0,1,0,0)
a17 <- c(0,0,0,1,0,0,0)
a18 <- c(0,0,1,0,0,0,0)
a19 <- c(0,1,0,0,0,0,0)
a20 <- c(0,1,0,0,0,1,0)
a21 <- c(0,0,0,1,0,1,1)
a22 <- c(1,0,0,1,0,1,1)
a23 <- c(1,0,1,1,0,1,0)
aa <- 
rbind(a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11,a12,a13,a14,a15,a16,a17,a18,a19,a20,a21,a22,a23)

a <- array(0, c(161,3), list(NULL, c("Subject","Item","Response")))
 	for (s in c(1:23))
 		for (i in c(1:7))
 			a[7*(s-1)+i,] <- c(s,i,aa[s,i])

A <- data.frame(a)
AA <- rbind(A,A)

A.fit <- lmer(Response~(1|Subject)+(1|Item),A,binomial)
AA.fit <- lmer(Response~(1|Subject)+(1|Item),B,binomial)

A.fit
AA.fit

ranef(A.fit)$Item
(ranef(A.fit)$Item)*578500000
ranef(AA.fit)$Item


From h.wickham at gmail.com  Sun Dec 31 19:58:53 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 31 Dec 2006 10:58:53 -0800
Subject: [R] tabulate: switching columns and rows
In-Reply-To: <20061231T194404Z_C5AC00020000@xen.net>
References: <20061231T194404Z_C5AC00020000@xen.net>
Message-ID: <f8e6ff050612311058p7b79e274y1f2742a02cbfc6ed@mail.gmail.com>

> Thanks, Hadley,
>
> My fault: I've not provided the line concerning replicate variable. It is included in ?xtabs:
>
> warpbreaks$replicate <- rep(1:9, len = 54)
>
> It will be great to have an example with these given data. Anyway, I will have a look to reshape at the given site. Thanks a lot!


install.packages("reshape")
library(reshape)

wm <- melt(warpbreaks, m="breaks")
cast(wm, wool ~ tension + replicate)

# Or as a 3d array
cast(wm, wool ~ tension ~ replicate)

# Or aggregate over replicates:
cast(wm, wool ~ tension, mean)
cast(wm, wool ~ tension, length)

Regards,

Hadley


From A.Robinson at ms.unimelb.edu.au  Sun Dec 31 21:41:33 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 1 Jan 2007 07:41:33 +1100
Subject: [R] zero random effect sizes with binomial lmer
In-Reply-To: <loom.20061231T135340-487@post.gmane.org>
References: <265AE1A0-C0DA-4C2A-9E3D-3630941732F0@ling.upenn.edu>
	<loom.20061231T135340-487@post.gmane.org>
Message-ID: <20061231204133.GQ56246@ms.unimelb.edu.au>

I'm not sure that shrinkage is the answer, in this case.  I observed a
similar problem with the gamma distribution, which I mentioned here:

http://tolstoy.newcastle.edu.au/R/e2/help/06/12/6903.html

Since there hasn't been any discussion, I'm starting to think that it
is a bug.

Andrew

On Sun, Dec 31, 2006 at 12:55:44PM +0000, Gregor Gorjanc wrote:
> Daniel Ezra Johnson <johnson4 <at> babel.ling.upenn.edu> writes:
> ...
> > If one compares the random effect estimates, in fact, one sees that  
> > they are in the correct proportion, with the expected signs. They are  
> > just approximately eight orders of magnitude too small. Is this a bug?
> ...
> 
> BLUPs are essentially shrinkage estimates, where shrinkage is determined with
> magnitude of variance. Lower variance more shrinkage towards the mean - zero 
> in this case. So this is not a bug.
> 
> Gregor
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/


From fjbuch at gmail.com  Sun Dec 31 22:16:55 2006
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Sun, 31 Dec 2006 16:16:55 -0500
Subject: [R] Does SQL group by have a heavy duty equivalent in R
References: <bd93cdad0612302317j674e7e4dk257ac5707964f1@mail.gmail.com>
	<f8e6ff050612310758p11f96c0dl256ac5b15d11dc2c@mail.gmail.com>
Message-ID: <en99cb$o63$1@sea.gmane.org>

I converted the whole data frame to character by using
as.matrix

And then using a posting that explained how to get the naming conventions 
back (which had been lost when converting to matrix)

Anything that I did not list with the id's it insisted in including them 
with the measured variables. In other words it would not let me drop.

despite

melted<-melt(BigDF, id=c("SAMPLE_ID","ASSAY_ID"), 
measured=c("GENOTYPE_ID","DESCRIPTION"))

unique(melted$variable)
 [1] CUSTOMER       PROJECT        PLATE          EXPERIMENT     CHIP 
WELL_POSITION  GENOTYPE_ID    DESCRIPTION    ENTRY_OPERATOR
[10] INTERACT       PLATEc
Levels: CUSTOMER PROJECT PLATE EXPERIMENT CHIP WELL_POSITION GENOTYPE_ID 
DESCRIPTION ENTRY_OPERATOR INTERACT PLATEc


I should have only got GENOTYPE_ID    and DESCRIPTION

"hadley wickham" <h.wickham at gmail.com> wrote in message 
news:f8e6ff050612310758p11f96c0dl256ac5b15d11dc2c at mail.gmail.com...
>> nr.attempts
>> <-aggregate(RawSeq$GENOTYPE_ID,list(sample=RawSeq$SAMPLE_ID,assay=RawSeq$ASSAY_ID),length)
>> This was simply to figure out how many times the same piece of 
>> information
>> had been obtained. I ran out of patience. It took beyond forever and 
>> tapply
>> did not perform much better. The reshape package did not help - it 
>> implied
>> one was out of luck if the data was not numeric. All of my data is 
>> character
>> or factor.
>
> The reshape package will work if all your data is numeric, or all of
> it is character - it doesn't work with a mix.  I will try and make
> this more clear in the documentation.
> However, depending on the size and structure of your data it may not
> be any faster than tapply or aggregate.
>
> Hadley
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gregor.gorjanc at bfro.uni-lj.si  Sun Dec 31 22:58:30 2006
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Sun, 31 Dec 2006 21:58:30 +0000 (UTC)
Subject: [R] zero random effect sizes with binomial lmer
References: <265AE1A0-C0DA-4C2A-9E3D-3630941732F0@ling.upenn.edu>
Message-ID: <loom.20061231T225546-249@post.gmane.org>

Daniel Ezra Johnson <johnson4 <at> babel.ling.upenn.edu> writes:
...
> More broadly, is it hopeless to analyze this data in this manner, or  
> else, what should I try doing differently? It would be very useful to  
> be able to have reliable estimates of random effect sizes, even when  
> they are rather small.
...

You might try with mcmcsamp to get a better view of posterior distributions of
your parameters. It might be the case that MLE for item variance is near 0, while
its posterior distribution covers also values that are higher than 0.

Gregor


From gregor.gorjanc at bfro.uni-lj.si  Sun Dec 31 23:06:07 2006
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Sun, 31 Dec 2006 22:06:07 +0000 (UTC)
Subject: [R] zero random effect sizes with binomial lmer
References: <Pine.LNX.4.63.0612311228300.20533@babel.ling.upenn.edu>
Message-ID: <loom.20061231T225841-659@post.gmane.org>

Daniel Ezra Johnson <johnson4 <at> babel.ling.upenn.edu> writes:
> > > If one compares the random effect estimates, in fact, one sees that
> > > they are in the correct proportion, with the expected signs. They are
> > > just approximately eight orders of magnitude too small. Is this a bug?
> > 
> > BLUPs are essentially shrinkage estimates, where shrinkage is
> > determined with magnitude of variance. Lower variance more
> > shrinkage towards the mean - zero in this case. So this is not a bug.
> > 
> > Gregor
> 
> I doubled each data set by duplicating each Subject. There are now
> 46 subjects in each group instead of 23. So now A and B differ in 2
> observations out of 322. The lmer resuls are sensible.

Why would you want to do that? Doubling your data set is not what you
want as you are hacking the analysis. You should definitely avoid this for
real analysis!

> I know BLUPs are not like regular parameters, but doubling (or cutting
> in half) the data should not, in my opinion, cause this behavior. There
> is a lot of room for the original A variance estimate to be lower than B,
> maybe it should be 0.05, 0.01, 0.05, or whatever, but not < .0000000005.

This is numerical procedure and if log-likelihood is flat then it might happen
that algorithms give you such estimates. When you doubled the data
log-likelihood gets more peaked shape and then it seems reasonable that
estimates are more consistent.

> I understand that the between-Item variance is low, and probably
> it is no greater than what you would expect to occur by chance,
> but isn't that what hypothesis testing is for (anova, etc.)?

Yes, but "anova etc." is not a super tool. If you get parameter estimates that
are essentially 0, do you still need hypothesis testing?

> Is my best way around the algorithm returning zero to do
> what I have done above, with my real data? That is, duplicate
> (or triplicate) Subjects to increase my data size, and thereby
> get a reasonably comparable (if wrong) estimate of the Item variance?
> Zero is not a reasonable estimate in any of these data sets.

No!

Try with mcmcsamp and then you might get better view of posterior distribution
of item variance. I think that MLE is near zero with some support for positive 
values. Try to play with lmer i.e. with starting values etc. 

Additionally, why do you want to estimate variances separately for dataset A and
B. Can you really suggest that they should be different between datasets?

Gregor


From johnson4 at babel.ling.upenn.edu  Sun Dec 31 23:50:45 2006
From: johnson4 at babel.ling.upenn.edu (Daniel Ezra Johnson)
Date: Sun, 31 Dec 2006 17:50:45 -0500 (EST)
Subject: [R] zero random effect sizes with binomial lmer
Message-ID: <Pine.LNX.4.63.0612311744310.3632@babel.ling.upenn.edu>

Gregor,

Thanks for your replies.

1) Yes, I have tweaked the data to show as clearly as I can that this is a 
bug, that a tiny change in initial conditions causes the collapse of a 
reasonable 'parameter' estimate.

2) mcmcsamp() does not work (currently) for binomial fitted models.

3) This is an issue of what happens when the sample is too small. For all 
larger data sets I have gotten a ranef variance between 0.05 and 1.00 or 
so.

It makes no sense to say that as the data set gets smaller, the systematic 
variation between Items goes away. It doesn't, as I've shown. In the data 
above, certain Items were still 10+ times as likely (log-odds wise) to 
have Response==1 as others.

It may make sense to say that the effect becomes unestimable, due to its 
small size. But my understanding is not that this should make the 
algorithm return zero as an estimated value.

D


From johnson4 at babel.ling.upenn.edu  Sun Dec 31 10:28:40 2006
From: johnson4 at babel.ling.upenn.edu (Daniel Ezra Johnson)
Date: Sun, 31 Dec 2006 04:28:40 -0500 (EST)
Subject: [R] zero random effect sizes with binomial lmer [sorry,
	ignore previous]
Message-ID: <Pine.LNX.4.63.0612310424090.2213@babel.ling.upenn.edu>

I am fitting models to the responses to a questionnaire that has
seven yes/no questions (Item). For each combination of Subject and
Item, the variable Response is coded as 0 or 1.

I want to include random effects for both Subject and Item. While I
understand that the datasets are fairly small, and there are a lot of
invariant subjects, I do not understand something that is happening
here, and in comparing other subsets of the data.

In the data below, which has been adjusted to show this phenomenon
clearly, the Subject random effect variance is comparable for A
(1.63) and B (1.712), but the Item random effect variance comes out
as 0.109 for B and essentially zero for A (5.00e-10).

Note that the only difference between data set A and data set B
occurs on row 19, where a single instance of Response is changed.

Item	avg. in A (%)	avg. in B (%)
1	9		9
2	9		9
3	9		9
4	17		17
5	4%		4
6	22	<->	26
7	17		17

Why does the Item random effect sometimes "crash" to zero, so sensitively? 
Surely there is some more reasonable estimate of the Item effect here than 
zero. The items still have clearly different Response behavior.

If one compares the random effect estimates, in fact, one sees that
they are in the correct proportion, with the expected signs. They are
just approximately eight orders of magnitude too small. Is this a bug?

More broadly, is it hopeless to analyze this data in this manner, or
else, what should I try doing differently? It would be very useful to
be able to have reliable estimates of random effect sizes, even when
they are rather small.

I've included replicable code below, sorry that I did not know how to
make it more compact!

a1 <- c(0,0,0,0,0,0,0)
a2 <- c(0,0,0,0,0,0,0)
a3 <- c(0,0,0,0,0,0,0)
a4 <- c(0,0,0,0,0,0,0)
a5 <- c(0,0,0,0,0,0,0)
a6 <- c(0,0,0,0,0,0,0)
a7 <- c(0,0,0,0,0,0,0)
a8 <- c(0,0,0,0,0,0,0)
a9 <- c(0,0,0,0,0,0,0)
a10 <- c(0,0,0,0,0,0,0)
a11 <- c(0,0,0,0,0,0,0)
a12 <- c(0,0,0,0,0,0,0)
a13 <- c(0,0,0,0,0,0,1)
a14 <- c(0,0,0,0,0,0,1)
a15 <- c(0,0,0,0,0,1,0)
a16 <- c(0,0,0,0,1,0,0)
a17 <- c(0,0,0,1,0,0,0)
a18 <- c(0,0,1,0,0,0,0)
a19 <- c(0,1,0,0,0,0,0)
a20 <- c(0,1,0,0,0,1,0)
a21 <- c(0,0,0,1,0,1,1)
a22 <- c(1,0,0,1,0,1,1)
a23 <- c(1,0,1,1,0,1,0)
aa <- rbind
(a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11,a12,a13,a14,a15,a16,a17,a18,a19,a20,
a21,a22,a23)

b1 <- c(0,0,0,0,0,0,0)
b2 <- c(0,0,0,0,0,0,0)
b3 <- c(0,0,0,0,0,0,0)
b4 <- c(0,0,0,0,0,0,0)
b5 <- c(0,0,0,0,0,0,0)
b6 <- c(0,0,0,0,0,0,0)
b7 <- c(0,0,0,0,0,0,0)
b8 <- c(0,0,0,0,0,0,0)
b9 <- c(0,0,0,0,0,0,0)
b10 <- c(0,0,0,0,0,0,0)
b11 <- c(0,0,0,0,0,0,0)
b12 <- c(0,0,0,0,0,0,0)
b13 <- c(0,0,0,0,0,0,1)
b14 <- c(0,0,0,0,0,0,1)
b15 <- c(0,0,0,0,0,1,0)
b16 <- c(0,0,0,0,1,0,0)
b17 <- c(0,0,0,1,0,0,0)
b18 <- c(0,0,1,0,0,0,0)
b19 <- c(0,1,0,0,0,1,0)
b20 <- c(0,1,0,0,0,1,0)
b21 <- c(0,0,0,1,0,1,1)
b22 <- c(1,0,0,1,0,1,1)
b23 <- c(1,0,1,1,0,1,0)
bb <- rbind
(b1,b2,b3,b4,b5,b6,b7,b8,b9,b10,b11,b12,b13,b14,b15,b16,b17,b18,b19,b20,
b21,b22,b23)

a <- array(0, c(161,3), list(NULL,c("Subject","Item","Response")))
 	for (s in c(1:23))
 		for (i in c(1:7))
 			a[7*(s-1)+i,] <- c(s,i,aa[s,i])
A <- data.frame(a)

b <- array(0, c(161,3), list(NULL,c("Subject","Item","Response")))
 	for (s in c(1:23))
 		for (i in c(1:7))
 			b[7*(s-1)+i,] <- c(s,i,bb[s,i])
B <- data.frame(b)

A.fit <- lmer(Response~(1|Subject)+(1|Item),A,binomial)
B.fit <- lmer(Response~(1|Subject)+(1|Item),B,binomial)
A.fit
B.fit
ranef(A.fit)$Item
ranef(B.fit)$Item

Generalized linear mixed model fit using Laplace
Formula: Response ~ (1 | Subject) + (1 | Item)
     Data: A
Family: binomial(logit link)
AIC BIC logLik deviance
120 129  -56.8      114
Random effects:
Groups  Name        Variance Std.Dev.
Subject (Intercept) 1.63e+00 1.28e+00
Item    (Intercept) 5.00e-10 2.24e-05
number of obs: 161, groups: Subject, 23; Item, 7

Estimated scale (compare to  1 )  0.83326

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)
(Intercept)   -2.517      0.395   -6.38  1.8e-10 ***

  > B.fit
Generalized linear mixed model fit using Laplace
Formula: Response ~ (1 | Subject) + (1 | Item)
     Data: B
Family: binomial(logit link)
AIC BIC logLik deviance
123 133  -58.6      117
Random effects:
Groups  Name        Variance Std.Dev.
Subject (Intercept) 1.712    1.308
Item    (Intercept) 0.109    0.330
number of obs: 161, groups: Subject, 23; Item, 7

Estimated scale (compare to  1 )  0.81445

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)
(Intercept)   -2.498      0.415   -6.02  1.8e-09 ***

  > ranef(A.fit)$Item
    (Intercept)
1 -2.8011e-10
2 -2.8011e-10
3 -2.8011e-10
4  7.1989e-10
5 -7.8011e-10
6  1.2199e-09
7  7.1989e-10

  > ranef(B.fit)$Item
    (Intercept)
1   -0.056937
2   -0.056937
3   -0.056937
4    0.120293
5   -0.146925
6    0.293893
7    0.120293


From sezaugg at gmx.ch  Sun Dec 31 14:16:06 2006
From: sezaugg at gmx.ch (Serge Zaugg)
Date: Sun, 31 Dec 2006 14:16:06 +0100
Subject: [R] kernel density estimation with  many variables (50 variables)
Message-ID: <20061231131606.66590@gmx.net>


Hello, 

Does any one know an R-function that  performs kernel density estimation when there are many variables ? My data has up to 50 variables and  several thousand data points.  

Does any one know an alternative method to perform nonparametric density estimation on high dimensional data ?

Many thanks for the help

Serge Zaugg



--


