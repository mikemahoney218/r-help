From drjimlemon at gmail.com  Mon Jan  1 00:16:32 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 1 Jan 2018 10:16:32 +1100
Subject: [R] Draw Overlapping Circles with shaded tracks
In-Reply-To: <CAE9stmd-Qx2tFb+vSoJ5aWpAS_VyF++BWZDPfuuzb_hQqnd-vw@mail.gmail.com>
References: <CAE9stmfEke0yLe4w+crBWF7uCFfvseLqCrJYOxxu1BsNnch+2w@mail.gmail.com>
 <CA+8X3fWsJeoTWAVx569oDQ3m-CODn=gDFRVQjmzzNZsJODoHVQ@mail.gmail.com>
 <1651743274.6758450.1514725859996@mail.yahoo.com>
 <cc6657ea-3733-d7aa-abc2-74d2e0a160a3@yahoo.fr>
 <CAE9stmd-Qx2tFb+vSoJ5aWpAS_VyF++BWZDPfuuzb_hQqnd-vw@mail.gmail.com>
Message-ID: <CA+8X3fW15JmA+qXNAVEcbhG9iv_9CFLLe8Eicg=aByQy=T5_7g@mail.gmail.com>

Hi Abou,
Sure:

library(plotrix)
pdf("circles.pdf")
plot(0:10,type="n",axes=FALSE,xlab="",ylab="")
ymult=getYmult()
draw.circle(4,5,radius=3,border="#ff0000aa",lwd=10)
for(angle in seq(0,1.95*pi,by=0.05*pi))
 draw.circle(4+3*cos(angle),5+3*sin(angle)*ymult,
  radius=runif(1,0.05,0.1),col="#00ff00aa")
draw.circle(6,5,radius=3,border="#0000ffaa",lwd=10)
for(angle in seq(0,1.95*pi,by=0.05*pi))
 draw.circle(6+3*cos(angle),5+3*sin(angle)*ymult,
  radius=runif(1,0.05,0.1),col="#ffff00aa")
dev.off()

You're right, it's really ugly.

Thanks John, how could I have forgotten.

Jim

On Mon, Jan 1, 2018 at 1:13 AM, AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
> Dear All:
>
> Thank you very much for all of you.
>
> I just have one more thing. Is there a way to fill the borders with small
> dots, may be different sizes.
>
> I tried to do it, but it looks ugly.
>
> Here what I tried:
>
>
>
>
> library(plotrix)
>
>
> plot(0:10, 0:10, type="n",axes=FALSE,xlab="",ylab="")   #### 0:5,
>
> draw.circle(4,5,radius=3,border="#ff0000aa", lwd=75)
>
> draw.circle(4,5,radius=2.50,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=2.55,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=2.60,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=2.65,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=2.70,border="red",lty=3,lwd=3)
>
> draw.circle(4,5,radius=2.75,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=2.80,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=2.85,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=2.90,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=2.95,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=3.0,border="red",lty=3,lwd=3)
>
> draw.circle(4,5,radius=3.05,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=3.10,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=3.15,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=3.20,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=3.25,border="red",lty=3,lwd=3)
>
>
> draw.circle(4,5,radius=3.30,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=3.35,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=3.40,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=3.45,border="red",lty=3,lwd=3)
> draw.circle(4,5,radius=3.50,border="red",lty=3,lwd=3)
>
>
>
> draw.circle(7.5,5,radius=3,border="#0000ffaa",lwd=75)
>
>
> draw.circle(7.5,5,radius=2.50,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=2.55,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=2.60,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=2.65,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=2.70,border="blue",lty=3,lwd=3)
>
> draw.circle(7.5,5,radius=2.75,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=2.80,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=2.85,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=2.90,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=2.95,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=3.0,border="blue",lty=3,lwd=3)
>
> draw.circle(7.5,5,radius=3.05,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=3.10,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=3.15,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=3.20,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=3.25,border="blue",lty=3,lwd=3)
>
>
> draw.circle(7.5,5,radius=3.30,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=3.35,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=3.40,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=3.45,border="blue",lty=3,lwd=3)
> draw.circle(7.5,5,radius=3.50,border="blue",lty=3,lwd=3)
>
>
>
> Once again thank you very much
>
> abou
>
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor of Statistics*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>
> On Sun, Dec 31, 2017 at 8:40 AM, Marc Girondot via R-help <
> r-help at r-project.org> wrote:
>
>> Another solution:
>>
>> library("HelpersMG") plot(0:10,type="n",axes=FALSE,xlab="",ylab="",
>> asp=1) ellipse(center.x = 3, center.y = 5, radius.x = 5, radius.y = 5,
>> lwd=10, col=NA, border=rgb(red = 1, green = 0, blue=0, alpha = 0.5))
>> ellipse(center.x = 8, center.y = 5, radius.x = 5, radius.y = 5, lwd=10,
>> col=NA, border=rgb(red = 0, green = 1, blue=0, alpha = 0.5))
>>
>>
>> (Without the graphic example, it is difficult to know what tit was
>> supposed to do !)
>>
>> Marc
>>
>> Le 31/12/2017 ? 14:10, John Kane via R-help a ?crit :
>> > That code nees the plotrix package:
>> > library(plotrix)
>> > pdf("circles.pdf")
>> > plot(0:10,type="n",axes=FALSE,xlab="",ylab="")
>> > draw.circle(4,5,radius=3,border="#ff0000aa",lwd=10)
>> > draw.circle(6,5,radius=3,border="#0000ffaa",lwd=10)
>> > dev.off()
>> >
>> >
>> >
>> >
>> >      On Friday, December 29, 2017, 6:06:32 PM EST, Jim Lemon <
>> drjimlemon at gmail.com> wrote:
>> >
>> >   Hi Abou,
>> > Without an illustration it's hard to work out what you want. here is a
>> > simple example of two circles using semi-transparency. Is this any
>> > help?
>> >
>> > pdf("circles.pdf")
>> > plot(0:10,type="n",axes=FALSE,xlab="",ylab="")
>> > draw.circle(4,5,radius=3,border="#ff0000aa",lwd=10)
>> > draw.circle(6,5,radius=3,border="#0000ffaa",lwd=10)
>> > dev.off()
>> >
>> > Jim
>> >
>> > On Fri, Dec 29, 2017 at 9:45 PM, AbouEl-Makarim Aboueissa
>> > <abouelmakarim1962 at gmail.com> wrote:
>> >> Dear All:
>> >>
>> >>
>> >> I am wondering if there is a way in R to draw these two circles with
>> shaded
>> >> tracks in both circles using R, and make both circles uncovered. I am
>> >> trying to make it in MS words, but I could not. Your help will be highly
>> >> appreciated.
>> >>
>> >>
>> >> In my previous post I added the image of the two circles, but the post
>> >> never published. I just thought to resent the post again without the
>> image.
>> >>
>> >> with many thanks
>> >> abou
>> >> ______________________
>> >>
>> >>
>> >> *AbouEl-Makarim Aboueissa, PhD*
>> >>
>> >> *Professor of Statistics*
>> >>
>> >> *Department of Mathematics and Statistics*
>> >> *University of Southern Maine*
>> >>
>> >>          [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mak.hholly at gmail.com  Mon Jan  1 21:02:30 2018
From: mak.hholly at gmail.com (greg holly)
Date: Mon, 1 Jan 2018 23:02:30 +0300
Subject: [R] Error in adabag
Message-ID: <CAM9Qe4hQawK7FrhMzqKh9yd8aCkHezjBmapZ_39Qub67zDO4mw@mail.gmail.com>

Hi all;

Happy new year. I have got the following error

rror in if (nrow(object$splits) > 0) { : argument is of length zero

 when I am running the following codes.

train <- c(sample(1:27,18), sample(28:54, 18), sample(55:81, 8))
 a2011.adaboost <- boosting(median_kod ~ ., data = b[train, ], boos=TRUE,
mfinal = 10,  control = rpart.control(minsplit = 0))

Regards,

Greg

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Jan  1 21:36:32 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 01 Jan 2018 12:36:32 -0800
Subject: [R] Error in adabag
In-Reply-To: <CAM9Qe4hQawK7FrhMzqKh9yd8aCkHezjBmapZ_39Qub67zDO4mw@mail.gmail.com>
References: <CAM9Qe4hQawK7FrhMzqKh9yd8aCkHezjBmapZ_39Qub67zDO4mw@mail.gmail.com>
Message-ID: <F7E85B43-7683-487F-9684-692627FE045B@dcn.davis.ca.us>

Not reproducible [1][2][3]. (Missing references to packages and "b" data frame.) Also, posting with html format makes extracting your code unreliable, so set your email program to send plain text for this mailing list. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 
-- 
Sent from my phone. Please excuse my brevity.

On January 1, 2018 12:02:30 PM PST, greg holly <mak.hholly at gmail.com> wrote:
>Hi all;
>
>Happy new year. I have got the following error
>
>rror in if (nrow(object$splits) > 0) { : argument is of length zero
>
> when I am running the following codes.
>
>train <- c(sample(1:27,18), sample(28:54, 18), sample(55:81, 8))
>a2011.adaboost <- boosting(median_kod ~ ., data = b[train, ],
>boos=TRUE,
>mfinal = 10,  control = rpart.control(minsplit = 0))
>
>Regards,
>
>Greg
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Mon Jan  1 23:44:11 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 2 Jan 2018 11:44:11 +1300
Subject: [R] Discrete valued time series data sets.
Message-ID: <adee1460-ecc5-d07b-dcd0-40acef4836ca@auckland.ac.nz>


I am looking for (publicly available) examples of discrete valued time 
series data sets.  I have googled around a bit and have found lots of 
articles and books on discrete valued time series, but have had no 
success in locating sites at which data are available.

Can anyone make any useful suggestions?

Thanks.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ericjberger at gmail.com  Tue Jan  2 18:04:06 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Tue, 2 Jan 2018 19:04:06 +0200
Subject: [R] Discrete valued time series data sets.
In-Reply-To: <adee1460-ecc5-d07b-dcd0-40acef4836ca@auckland.ac.nz>
References: <adee1460-ecc5-d07b-dcd0-40acef4836ca@auckland.ac.nz>
Message-ID: <CAGgJW76qk-Nf15pjPqb1w54FECw7G1SDnEm3tnYY=1wJeedAMg@mail.gmail.com>

Hi Rolf,
I looked at
https://docs.microsoft.com/en-us/azure/sql-database/sql-database-public-data-sets

One of the first sets in the list is the airline time series (I think it is
also used in dplyr examples).

https://www.transtats.bts.gov/OT_Delay/OT_DelayCause1.asp

You might find other possibilities in that list.

HTH,
Eric


On Tue, Jan 2, 2018 at 12:44 AM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

>
> I am looking for (publicly available) examples of discrete valued time
> series data sets.  I have googled around a bit and have found lots of
> articles and books on discrete valued time series, but have had no success
> in locating sites at which data are available.
>
> Can anyone make any useful suggestions?
>
> Thanks.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Tue Jan  2 18:30:05 2018
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 2 Jan 2018 09:30:05 -0800
Subject: [R] httr::content without message
Message-ID: <FFC721F2-7729-481A-984B-68357A73FF4E@noaa.gov>

Hi All:

I am using httr to download files form a service, in this case a .csv file.  When I use httr::content on the result,  I get a message.  Since this will be in a package.  I want to suppress the message,  but haven't figured out how to do so.

The following should reproduce the result:

myURL <- 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1sstdmday.csvp?time[0:1:last]'
r1 <- httr::GET(myURL)
junk <- httr::content(r1)

when the last command is run, you get:

Parsed with column specification:
cols(
  `time (UTC)` = col_datetime(format = "")
)

I want to suppress that output.

Thanks,

-Roy

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From dwinsemius at comcast.net  Tue Jan  2 18:44:13 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 2 Jan 2018 09:44:13 -0800
Subject: [R] httr::content without message
In-Reply-To: <FFC721F2-7729-481A-984B-68357A73FF4E@noaa.gov>
References: <FFC721F2-7729-481A-984B-68357A73FF4E@noaa.gov>
Message-ID: <0B14996F-8422-47DB-B055-18D782ED834F@comcast.net>


> On Jan 2, 2018, at 9:30 AM, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
> 
> Hi All:
> 
> I am using httr to download files form a service, in this case a .csv file.  When I use httr::content on the result,  I get a message.  Since this will be in a package.  I want to suppress the message,  but haven't figured out how to do so.
> 
> The following should reproduce the result:
> 
> myURL <- 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1sstdmday.csvp?time[0:1:last]'
> r1 <- httr::GET(myURL)
> junk <- httr::content(r1)

Instead try:

junk <- suppressMessages(httr::content(r1))

> 

> when the last command is run, you get:
> 
> Parsed with column specification:
> cols(
>  `time (UTC)` = col_datetime(format = "")
> )
> 
> I want to suppress that output.
> 
> Thanks,
> 
> -Roy
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected" 
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From btupper at bigelow.org  Tue Jan  2 18:44:49 2018
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 2 Jan 2018 12:44:49 -0500
Subject: [R] httr::content without message
In-Reply-To: <FFC721F2-7729-481A-984B-68357A73FF4E@noaa.gov>
References: <FFC721F2-7729-481A-984B-68357A73FF4E@noaa.gov>
Message-ID: <C55D703D-FDD3-450E-B521-2E5343D14471@bigelow.org>

Ahoy!

That's a message generated by the readr::read_table() function (or it's friends).  You can suppress it a number of ways, but this should work as httr::content() will pass through arguments, like col_types = cols(), to the file reader.

junk <- httr::content(r1, col_types = cols())

See more here...

https://blog.rstudio.com/2016/08/05/readr-1-0-0/ <https://blog.rstudio.com/2016/08/05/readr-1-0-0/>


Cheers,
Ben



> On Jan 2, 2018, at 12:30 PM, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
> 
> Hi All:
> 
> I am using httr to download files form a service, in this case a .csv file.  When I use httr::content on the result,  I get a message.  Since this will be in a package.  I want to suppress the message,  but haven't figured out how to do so.
> 
> The following should reproduce the result:
> 
> myURL <- 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1sstdmday.csvp?time[0:1:last]'
> r1 <- httr::GET(myURL)
> junk <- httr::content(r1)
> 
> when the last command is run, you get:
> 
> Parsed with column specification:
> cols(
>  `time (UTC)` = col_datetime(format = "")
> )
> 
> I want to suppress that output.
> 
> Thanks,
> 
> -Roy
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected" 
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecocast Reports: http://seascapemodeling.org/ecocast.html
Tick Reports: https://report.bigelow.org/tick/
Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/




	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Jan  2 18:46:18 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 2 Jan 2018 09:46:18 -0800
Subject: [R] httr::content without message
In-Reply-To: <FFC721F2-7729-481A-984B-68357A73FF4E@noaa.gov>
References: <FFC721F2-7729-481A-984B-68357A73FF4E@noaa.gov>
Message-ID: <CAF8bMcYXbXzG_cqN8Cpx+wf_mnOAw9+ytXekLAX1FfJ1d+W--A@mail.gmail.com>

You can suppress all messages from that command with
    junk <- suppressMessages(httr::content(r1))

If you only want to suppress that specific message you can use
withCallingHandlers:
    junk <- withCallingHandlers(
        httr::content(r1),
        message=function(e){
            if (grepl("Parsed with column specification",
conditionMessage(e))) {
               invokeRestart("muffleMessage")
            }
         }
      )


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Jan 2, 2018 at 9:30 AM, Roy Mendelssohn - NOAA Federal <
roy.mendelssohn at noaa.gov> wrote:

> Hi All:
>
> I am using httr to download files form a service, in this case a .csv
> file.  When I use httr::content on the result,  I get a message.  Since
> this will be in a package.  I want to suppress the message,  but haven't
> figured out how to do so.
>
> The following should reproduce the result:
>
> myURL <- 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/
> erdMH1sstdmday.csvp?time[0:1:last]'
> r1 <- httr::GET(myURL)
> junk <- httr::content(r1)
>
> when the last command is run, you get:
>
> Parsed with column specification:
> cols(
>   `time (UTC)` = col_datetime(format = "")
> )
>
> I want to suppress that output.
>
> Thanks,
>
> -Roy
>
> **********************
> "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK
> Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Tue Jan  2 18:53:45 2018
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 2 Jan 2018 09:53:45 -0800
Subject: [R] httr::content without message
In-Reply-To: <C55D703D-FDD3-450E-B521-2E5343D14471@bigelow.org>
References: <FFC721F2-7729-481A-984B-68357A73FF4E@noaa.gov>
 <C55D703D-FDD3-450E-B521-2E5343D14471@bigelow.org>
Message-ID: <8B45160B-A1EE-425C-82F6-3E9E73DF9978@noaa.gov>

Thanks to all that replied.  I had just looked through the httr code and sure enough for a .csv mime time it calls readr::read_csv().  The httr::content docs suggest not using automatic parsing in a package,  rather to determine mime type and parse yourself and Ben's suggestion also works if I do:

junk <- readr::read_csv(r1$content, col_types = cols())

Perfect.  Using httr rather than putting the url in any of the read.csv or read_csv type code allows me greater control if the request fails.

Thanks again,

-Roy

> On Jan 2, 2018, at 9:44 AM, Ben Tupper <btupper at bigelow.org> wrote:
> 
> Ahoy!
> 
> That's a message generated by the readr::read_table() function (or it's friends).  You can suppress it a number of ways, but this should work as httr::content() will pass through arguments, like col_types = cols(), to the file reader.
> 
> junk <- httr::content(r1, col_types = cols())
> 
> See more here...
> 
> https://blog.rstudio.com/2016/08/05/readr-1-0-0/
> 
> 
> Cheers,
> Ben
> 
> 
> 
>> On Jan 2, 2018, at 12:30 PM, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
>> 
>> Hi All:
>> 
>> I am using httr to download files form a service, in this case a .csv file.  When I use httr::content on the result,  I get a message.  Since this will be in a package.  I want to suppress the message,  but haven't figured out how to do so.
>> 
>> The following should reproduce the result:
>> 
>> myURL <- 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1sstdmday.csvp?time[0:1:last]'
>> r1 <- httr::GET(myURL)
>> junk <- httr::content(r1)
>> 
>> when the last command is run, you get:
>> 
>> Parsed with column specification:
>> cols(
>>  `time (UTC)` = col_datetime(format = "")
>> )
>> 
>> I want to suppress that output.
>> 
>> Thanks,
>> 
>> -Roy
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new street address***
>> 110 McAllister Way
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>> 
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected" 
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
> 
> Ecocast Reports: http://seascapemodeling.org/ecocast.html
> Tick Reports: https://report.bigelow.org/tick/
> Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/
> 
> 
> 

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From btupper at bigelow.org  Tue Jan  2 19:09:05 2018
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 2 Jan 2018 13:09:05 -0500
Subject: [R] httr::content without message
In-Reply-To: <8B45160B-A1EE-425C-82F6-3E9E73DF9978@noaa.gov>
References: <FFC721F2-7729-481A-984B-68357A73FF4E@noaa.gov>
 <C55D703D-FDD3-450E-B521-2E5343D14471@bigelow.org>
 <8B45160B-A1EE-425C-82F6-3E9E73DF9978@noaa.gov>
Message-ID: <58ADDE10-617B-4C83-987C-9361058E629A@bigelow.org>

That's good to know about when to auto-parse and when not to.  There is quite a big stable of tools to check the response before you try to read...

> httr::http_error(r1)
[1] FALSE

> httr::http_status(r1)
$category
[1] "Success"

$reason
[1] "OK"

$message
[1] "Success: (200) OK"

and

> httr::http_type(r1)
[1] "text/csv"


> On Jan 2, 2018, at 12:53 PM, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
> 
> Thanks to all that replied.  I had just looked through the httr code and sure enough for a .csv mime time it calls readr::read_csv().  The httr::content docs suggest not using automatic parsing in a package,  rather to determine mime type and parse yourself and Ben's suggestion also works if I do:
> 
> junk <- readr::read_csv(r1$content, col_types = cols())
> 
> Perfect.  Using httr rather than putting the url in any of the read.csv or read_csv type code allows me greater control if the request fails.
> 
> Thanks again,
> 
> -Roy
> 
>> On Jan 2, 2018, at 9:44 AM, Ben Tupper <btupper at bigelow.org> wrote:
>> 
>> Ahoy!
>> 
>> That's a message generated by the readr::read_table() function (or it's friends).  You can suppress it a number of ways, but this should work as httr::content() will pass through arguments, like col_types = cols(), to the file reader.
>> 
>> junk <- httr::content(r1, col_types = cols())
>> 
>> See more here...
>> 
>> https://blog.rstudio.com/2016/08/05/readr-1-0-0/
>> 
>> 
>> Cheers,
>> Ben
>> 
>> 
>> 
>>> On Jan 2, 2018, at 12:30 PM, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
>>> 
>>> Hi All:
>>> 
>>> I am using httr to download files form a service, in this case a .csv file.  When I use httr::content on the result,  I get a message.  Since this will be in a package.  I want to suppress the message,  but haven't figured out how to do so.
>>> 
>>> The following should reproduce the result:
>>> 
>>> myURL <- 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1sstdmday.csvp?time[0:1:last]'
>>> r1 <- httr::GET(myURL)
>>> junk <- httr::content(r1)
>>> 
>>> when the last command is run, you get:
>>> 
>>> Parsed with column specification:
>>> cols(
>>> `time (UTC)` = col_datetime(format = "")
>>> )
>>> 
>>> I want to suppress that output.
>>> 
>>> Thanks,
>>> 
>>> -Roy
>>> 
>>> **********************
>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>> **********************
>>> Roy Mendelssohn
>>> Supervisory Operations Research Analyst
>>> NOAA/NMFS
>>> Environmental Research Division
>>> Southwest Fisheries Science Center
>>> ***Note new street address***
>>> 110 McAllister Way
>>> Santa Cruz, CA 95060
>>> Phone: (831)-420-3666
>>> Fax: (831) 420-3980
>>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>> 
>>> "Old age and treachery will overcome youth and skill."
>>> "From those who have been given much, much will be expected" 
>>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>> 
>> Ecocast Reports: http://seascapemodeling.org/ecocast.html
>> Tick Reports: https://report.bigelow.org/tick/
>> Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/
>> 
>> 
>> 
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected" 
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecocast Reports: http://seascapemodeling.org/ecocast.html
Tick Reports: https://report.bigelow.org/tick/
Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/




	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Tue Jan  2 22:55:11 2018
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 2 Jan 2018 22:55:11 +0100 (CET)
Subject: [R] Discrete valued time series data sets.
In-Reply-To: <CAGgJW76qk-Nf15pjPqb1w54FECw7G1SDnEm3tnYY=1wJeedAMg@mail.gmail.com>
References: <adee1460-ecc5-d07b-dcd0-40acef4836ca@auckland.ac.nz>
 <CAGgJW76qk-Nf15pjPqb1w54FECw7G1SDnEm3tnYY=1wJeedAMg@mail.gmail.com>
Message-ID: <alpine.DEB.2.21.1801022254030.30947@paninaro>

The "tscount" package (see http://doi.org/10.18637/jss.v082.i05) comes 
with several count data time series. Maybe this is the kind of discrete 
data you were interested in?

hth,
Z

On Tue, 2 Jan 2018, Eric Berger wrote:

> Hi Rolf,
> I looked at
> https://docs.microsoft.com/en-us/azure/sql-database/sql-database-public-data-sets
>
> One of the first sets in the list is the airline time series (I think it is
> also used in dplyr examples).
>
> https://www.transtats.bts.gov/OT_Delay/OT_DelayCause1.asp
>
> You might find other possibilities in that list.
>
> HTH,
> Eric
>
>
> On Tue, Jan 2, 2018 at 12:44 AM, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
>
>>
>> I am looking for (publicly available) examples of discrete valued time
>> series data sets.  I have googled around a bit and have found lots of
>> articles and books on discrete valued time series, but have had no success
>> in locating sites at which data are available.
>>
>> Can anyone make any useful suggestions?
>>
>> Thanks.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From traxplayer at gmail.com  Wed Jan  3 00:38:32 2018
From: traxplayer at gmail.com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Wed, 3 Jan 2018 00:38:32 +0100
Subject: [R] Help with first S3-class
Message-ID: <CAGAA5bdgVsLpS3sRjPMMEM85zUwiOLc5FaqwoyoC9bLaQQ0LpQ@mail.gmail.com>

Hi,

  I am trying to understand S3 classes. I have read several tutorials about
the topics but I am still a bit confused. I guess it is because it is
so different from
Java OOP.

  I have pasted my attempt at creating a bank-account class below and
my problems are:

1. What should be added some plot.default() calls the account$plot() method ?
2. What should the account$plot() be implemented to show some kind of plot ?
3. How can one function inside "me"-list called another function. Eg.
How can account$plot() call account$pastSaldo() ?

Here are my code. Feel free to comment on any aspect of the code.
ps. I hope I have manage to strip HTML.

Regards
Martin



account <- function(owner = NULL) {
    thisEnv <- environment()

    pastSaldo <- vector()
    saldo <- 0
    owner <- owner

    me <- list(
    thisEnv = thisEnv,

         getEnv = function() { return(get("thisEnv", thisEnv)) },

         balance = function() { return(get("saldo", thisEnv)) },

        deposit = function(value) {
            assign("pastSaldo", append(pastSaldo, saldo), thisEnv)
            assign("saldo", saldo + value, thisEnv)
        },

        withdraw = function(value) {
           assign("pastSaldo", append(pastSaldo, saldo), thisEnv)
           assign("saldo", saldo - value, thisEnv)
        },

       pastSaldo = function() {
          return(pastSaldo)
      },

      plot = function() {
         plot.new()
         lines(list(y = pastSaldo, x = seq_along(pastSaldo)))
       }
    )
    assign('this', me, envir = thisEnv)

    class(me) <- append(class(me), "account")
    return(me)
}

FirstAccount <- account("Martin")
FirstAccount$deposit(100)
FirstAccount$withdraw(50)
FirstAccount$deposit(200)
FirstAccount$balance()
FirstAccount$pastSaldo()

FirstAccount$plot()

plot(FirstAccount)                            # fails
plot.account(FirstAccount)               # fails


From r.turner at auckland.ac.nz  Wed Jan  3 00:42:09 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 3 Jan 2018 12:42:09 +1300
Subject: [R] Discrete valued time series data sets.
In-Reply-To: <CAGgJW76qk-Nf15pjPqb1w54FECw7G1SDnEm3tnYY=1wJeedAMg@mail.gmail.com>
References: <adee1460-ecc5-d07b-dcd0-40acef4836ca@auckland.ac.nz>
 <CAGgJW76qk-Nf15pjPqb1w54FECw7G1SDnEm3tnYY=1wJeedAMg@mail.gmail.com>
Message-ID: <b82e0b22-aeac-443c-696e-8499825a3914@auckland.ac.nz>

On 03/01/18 06:04, Eric Berger wrote:
> Hi Rolf,
> I looked at 
> https://docs.microsoft.com/en-us/azure/sql-database/sql-database-public-data-sets
> 
> One of the first sets in the list is the airline time series (I think it 
> is also used in dplyr examples).
> 
> https://www.transtats.bts.gov/OT_Delay/OT_DelayCause1.asp
> 
> You might find other possibilities in that list.

Thanks Eric.  That site looks very useful.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Wed Jan  3 00:51:14 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 3 Jan 2018 12:51:14 +1300
Subject: [R] Discrete valued time series data sets.
In-Reply-To: <alpine.DEB.2.21.1801022254030.30947@paninaro>
References: <adee1460-ecc5-d07b-dcd0-40acef4836ca@auckland.ac.nz>
 <CAGgJW76qk-Nf15pjPqb1w54FECw7G1SDnEm3tnYY=1wJeedAMg@mail.gmail.com>
 <alpine.DEB.2.21.1801022254030.30947@paninaro>
Message-ID: <2a1912e8-be63-7318-6cd0-0a101b49967a@auckland.ac.nz>

On 03/01/18 10:55, Achim Zeileis wrote:
> The "tscount" package (see http://doi.org/10.18637/jss.v082.i05) comes 
> with several count data time series. Maybe this is the kind of discrete 
> data you were interested in?

Yes, that's very useful.  Thanks.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From murdoch.duncan at gmail.com  Wed Jan  3 00:52:47 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 2 Jan 2018 18:52:47 -0500
Subject: [R] Help with first S3-class
In-Reply-To: <CAGAA5bdgVsLpS3sRjPMMEM85zUwiOLc5FaqwoyoC9bLaQQ0LpQ@mail.gmail.com>
References: <CAGAA5bdgVsLpS3sRjPMMEM85zUwiOLc5FaqwoyoC9bLaQQ0LpQ@mail.gmail.com>
Message-ID: <70708e1e-9543-5611-92fa-c666839e961a@gmail.com>

On 02/01/2018 6:38 PM, Martin M?ller Skarbiniks Pedersen wrote:
> Hi,
> 
>    I am trying to understand S3 classes. I have read several tutorials about
> the topics but I am still a bit confused. I guess it is because it is
> so different from
> Java OOP.

What you do below isn't S3.  S3 is a system where the classes are 
secondary to the generic functions.  Methods "belong" to generics, they 
don't belong to classes.  As far as I can see, you hardly make use of S3 
methods and generics at all.

For the style you're using, the R6 or R.oo packages might be more suitable.

> 
>    I have pasted my attempt at creating a bank-account class below and
> my problems are:
> 
> 1. What should be added some plot.default() calls the account$plot() method ?

No, you need to define a function called "plot.account" whose signature 
is compatible with plot, i.e. arguments (x, y, ...), possibly with extra 
parameters as well.  It should do the plotting.

> 2. What should the account$plot() be implemented to show some kind of plot ?

The plot.account function could call account$plot(); it can do whatever 
you want to plot the object.

> 3. How can one function inside "me"-list called another function. Eg.
> How can account$plot() call account$pastSaldo() ?

There's no particular support for having them see each other the way 
you've defined them.  A better way to define them would be as local 
functions within the account body; then they'd be able to see each other 
without any prefix.

Duncan Murdoch
> 
> Here are my code. Feel free to comment on any aspect of the code.
> ps. I hope I have manage to strip HTML.
> 
> Regards
> Martin
> 
> 
> 
> account <- function(owner = NULL) {
>      thisEnv <- environment()
> 
>      pastSaldo <- vector()
>      saldo <- 0
>      owner <- owner
> 
>      me <- list(
>      thisEnv = thisEnv,
> 
>           getEnv = function() { return(get("thisEnv", thisEnv)) },
> 
>           balance = function() { return(get("saldo", thisEnv)) },
> 
>          deposit = function(value) {
>              assign("pastSaldo", append(pastSaldo, saldo), thisEnv)
>              assign("saldo", saldo + value, thisEnv)
>          },
> 
>          withdraw = function(value) {
>             assign("pastSaldo", append(pastSaldo, saldo), thisEnv)
>             assign("saldo", saldo - value, thisEnv)
>          },
> 
>         pastSaldo = function() {
>            return(pastSaldo)
>        },
> 
>        plot = function() {
>           plot.new()
>           lines(list(y = pastSaldo, x = seq_along(pastSaldo)))
>         }
>      )
>      assign('this', me, envir = thisEnv)
> 
>      class(me) <- append(class(me), "account")
>      return(me)
> }
> 
> FirstAccount <- account("Martin")
> FirstAccount$deposit(100)
> FirstAccount$withdraw(50)
> FirstAccount$deposit(200)
> FirstAccount$balance()
> FirstAccount$pastSaldo()
> 
> FirstAccount$plot()
> 
> plot(FirstAccount)                            # fails
> plot.account(FirstAccount)               # fails
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From traxplayer at gmail.com  Wed Jan  3 01:07:17 2018
From: traxplayer at gmail.com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Wed, 3 Jan 2018 01:07:17 +0100
Subject: [R] Help with first S3-class
In-Reply-To: <70708e1e-9543-5611-92fa-c666839e961a@gmail.com>
References: <CAGAA5bdgVsLpS3sRjPMMEM85zUwiOLc5FaqwoyoC9bLaQQ0LpQ@mail.gmail.com>
 <70708e1e-9543-5611-92fa-c666839e961a@gmail.com>
Message-ID: <CAGAA5bcvmqGXPnG-+7jfMwBrhNZ1OeFQzKWy6Hb9o7dRYeQU6Q@mail.gmail.com>

On 3 January 2018 at 00:52, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 02/01/2018 6:38 PM, Martin M?ller Skarbiniks Pedersen wrote:
>>
>> Hi,
>>
>>    I am trying to understand S3 classes. I have read several tutorials
>> about
>> the topics but I am still a bit confused. I guess it is because it is
>> so different from
>> Java OOP.
>
>
> What you do below isn't S3.  S3 is a system where the classes are secondary
> to the generic functions.  Methods "belong" to generics, they don't belong
> to classes.  As far as I can see, you hardly make use of S3 methods and
> generics at all.
>
> For the style you're using, the R6 or R.oo packages might be more suitable.

OK. Thanks, I will rewrite the code.

I read the guide at https://www.programiz.com/r-programming/S3-class
to make the code.
And used the part under: 1.3.2. Local Environment Approach

There is a picture of Wickham and it is sponsored by Datacamp so I was
thinking it was a good place for a guide ?!

Regards
Martin


From traxplayer at gmail.com  Wed Jan  3 01:35:16 2018
From: traxplayer at gmail.com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Wed, 3 Jan 2018 01:35:16 +0100
Subject: [R] Help with first S3-class
In-Reply-To: <70708e1e-9543-5611-92fa-c666839e961a@gmail.com>
References: <CAGAA5bdgVsLpS3sRjPMMEM85zUwiOLc5FaqwoyoC9bLaQQ0LpQ@mail.gmail.com>
 <70708e1e-9543-5611-92fa-c666839e961a@gmail.com>
Message-ID: <CAGAA5bdp96sp_1j=BHESByGazhOE4xwAGHipRaKXxQxiktdnVw@mail.gmail.com>

On 3 January 2018 at 00:52, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 02/01/2018 6:38 PM, Martin M?ller Skarbiniks Pedersen wrote:
>>
>> Hi,
>>
>>    I am trying to understand S3 classes. I have read several tutorials
>> about
>> the topics but I am still a bit confused. I guess it is because it is
>> so different from
>> Java OOP.
>
>
> What you do below isn't S3.  S3 is a system where the classes are secondary
> to the generic functions.  Methods "belong" to generics, they don't belong
> to classes.  As far as I can see, you hardly make use of S3 methods and
> generics at all.

Here is my second attempt making a S3-class.
But something is wrong with the deposit.account() ? Thanks for any help.

I expect this output:

[1] 0
Martin
Saldo is:  100

but I get this:

[1] 100
Martin
Saldo is:  0

Regards
Martin

account <- function(owner = NULL) {
if (is.null(owner)) stop("Owner can't be NULL")
value <- list(owner = owner, saldo = 0)
attr(value, "class") <- "account"
value
}

balance <- function(obj) { UseMethod("balance") }

balance.account <- function(obj) {
obj$saldo
}

deposit <- function(obj, amount) { UseMethod("deposit") }

deposit.account <- function(obj, amount) {
obj$saldo <- obj$saldo + amount
}

print.account <- function(obj) {
cat(obj$owner, "\n")
cat("Saldo is: ", obj$saldo, "\n")
}

A1 <- account("Martin")
deposit(A1, 100)
balance(A1)
print(A1)


From traxplayer at gmail.com  Wed Jan  3 01:37:01 2018
From: traxplayer at gmail.com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Wed, 3 Jan 2018 01:37:01 +0100
Subject: [R] Help with first S3-class
In-Reply-To: <CAGAA5bdp96sp_1j=BHESByGazhOE4xwAGHipRaKXxQxiktdnVw@mail.gmail.com>
References: <CAGAA5bdgVsLpS3sRjPMMEM85zUwiOLc5FaqwoyoC9bLaQQ0LpQ@mail.gmail.com>
 <70708e1e-9543-5611-92fa-c666839e961a@gmail.com>
 <CAGAA5bdp96sp_1j=BHESByGazhOE4xwAGHipRaKXxQxiktdnVw@mail.gmail.com>
Message-ID: <CAGAA5becTiY27px3mTK1aEL8+Gp0q-oqeaCAPwono1dZaXmWTA@mail.gmail.com>

Some mistake:

> I expect this output:

[1] 100
Martin
Saldo is: 100

but I get

[1] 0
Martn
Saldo is: 0


From jdnewmil at dcn.davis.ca.us  Wed Jan  3 08:36:16 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 02 Jan 2018 23:36:16 -0800
Subject: [R] Help with first S3-class
In-Reply-To: <CAGAA5becTiY27px3mTK1aEL8+Gp0q-oqeaCAPwono1dZaXmWTA@mail.gmail.com>
References: <CAGAA5bdgVsLpS3sRjPMMEM85zUwiOLc5FaqwoyoC9bLaQQ0LpQ@mail.gmail.com>
 <70708e1e-9543-5611-92fa-c666839e961a@gmail.com>
 <CAGAA5bdp96sp_1j=BHESByGazhOE4xwAGHipRaKXxQxiktdnVw@mail.gmail.com>
 <CAGAA5becTiY27px3mTK1aEL8+Gp0q-oqeaCAPwono1dZaXmWTA@mail.gmail.com>
Message-ID: <AE2D9089-82D2-4AB2-B661-FFCBB875C491@dcn.davis.ca.us>

Function arguments are not pass-by-reference... they are pass-by-value. You need to return the altered object to the caller when you are done messing with it.

Note that R is a data processing language... your example will not scale to real world use cases because you make no use of vectorization to handle multiple accounts. It is better to focus on the functional aspect of computing and let the objects carry the results until you have a chance to summarize or plot them.  Study the "lm" function and associated print and plot methods. 
-- 
Sent from my phone. Please excuse my brevity.

On January 2, 2018 4:37:01 PM PST, "Martin M?ller Skarbiniks Pedersen" <traxplayer at gmail.com> wrote:
>Some mistake:
>
>> I expect this output:
>
>[1] 100
>Martin
>Saldo is: 100
>
>but I get
>
>[1] 0
>Martn
>Saldo is: 0
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From traxplayer at gmail.com  Wed Jan  3 13:11:17 2018
From: traxplayer at gmail.com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Wed, 3 Jan 2018 13:11:17 +0100
Subject: [R] Help with first S3-class
In-Reply-To: <AE2D9089-82D2-4AB2-B661-FFCBB875C491@dcn.davis.ca.us>
References: <CAGAA5bdgVsLpS3sRjPMMEM85zUwiOLc5FaqwoyoC9bLaQQ0LpQ@mail.gmail.com>
 <70708e1e-9543-5611-92fa-c666839e961a@gmail.com>
 <CAGAA5bdp96sp_1j=BHESByGazhOE4xwAGHipRaKXxQxiktdnVw@mail.gmail.com>
 <CAGAA5becTiY27px3mTK1aEL8+Gp0q-oqeaCAPwono1dZaXmWTA@mail.gmail.com>
 <AE2D9089-82D2-4AB2-B661-FFCBB875C491@dcn.davis.ca.us>
Message-ID: <CAGAA5beHwCGmcPPqYtNUJ-XknTTMmJbZ1obs9rZXYen5t4OZ0w@mail.gmail.com>

On 3 January 2018 at 08:36, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> Function arguments are not pass-by-reference... they are pass-by-value. You need to return the altered object to the caller when you are done messing with it.

Thanks.
Of course. Now it is working.


> Note that R is a data processing language... your example will not scale to real world use cases because you make no use of vectorization to handle multiple accounts.

> It is better to focus on the functional aspect of computing and let the objects carry the results until you have a chance to summarize or plot them.  Study the "lm" function and associated print and plot methods.

Thanks for these suggestions. It is very helpful.

Regards
Martin


From bogaso.christofer at gmail.com  Wed Jan  3 15:26:27 2018
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Wed, 3 Jan 2018 19:56:27 +0530
Subject: [R] Help with Regular expression
Message-ID: <CA+dpOJ=q5+kx9rFyU+ovXCCCsLFgbG_QMAjW=897m2zzQEnTGw@mail.gmail.com>

Hi,

I was working on following expression :

"\":\"03-JAN-2018 16:00:00\""


This is basically a combination of Date and Time mixed with some Noise.

I want to extract only Date and Time part i.e. "03-JAN-2018 16:00:00

I tried following :

gsub("![0-9][0-9]-[a-zA-Z][a-zA-Z][a-zA-Z]-[0-9][0-9][0-9][0-9]
[0-9][0-9]:[0-9][0-9]:[0-9][0-9]", "", "\":\"03-JAN-2018 16:00:00\"",
ignore.case = TRUE)

Obviously, with above code, I am removing that portion of my string
which I actually I wanted!

How can I reverse above code, so that I will be removing that portion
of my string which I actually I ***NOT*** wanted?

Thanks for your time.

Happy New Year!


From r at catwhisker.org  Wed Jan  3 15:32:05 2018
From: r at catwhisker.org (David Wolfskill)
Date: Wed, 3 Jan 2018 06:32:05 -0800
Subject: [R] Help with Regular expression
In-Reply-To: <CA+dpOJ=q5+kx9rFyU+ovXCCCsLFgbG_QMAjW=897m2zzQEnTGw@mail.gmail.com>
References: <CA+dpOJ=q5+kx9rFyU+ovXCCCsLFgbG_QMAjW=897m2zzQEnTGw@mail.gmail.com>
Message-ID: <20180103143205.GI1258@albert.catwhisker.org>

On Wed, Jan 03, 2018 at 07:56:27PM +0530, Christofer Bogaso wrote:
> Hi,
> 
> I was working on following expression :
> 
> "\":\"03-JAN-2018 16:00:00\""
> 
> 
> This is basically a combination of Date and Time mixed with some Noise.
> 
> I want to extract only Date and Time part i.e. "03-JAN-2018 16:00:00
> 
> I tried following :
> 
> gsub("![0-9][0-9]-[a-zA-Z][a-zA-Z][a-zA-Z]-[0-9][0-9][0-9][0-9]
> [0-9][0-9]:[0-9][0-9]:[0-9][0-9]", "", "\":\"03-JAN-2018 16:00:00\"",
> ignore.case = TRUE)
> 
> Obviously, with above code, I am removing that portion of my string
> which I actually I wanted!
> 
> How can I reverse above code, so that I will be removing that portion
> of my string which I actually I ***NOT*** wanted?
> ....

You may find strptime() more suitable for the intended purpose.

Peace,
david
-- 
David H. Wolfskill				r at catwhisker.org
If you want the best Fake News, go to the best source of it: Donald J. Trump.

See http://www.catwhisker.org/~david/publickey.gpg for my public key.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 603 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180103/0f273b60/attachment.sig>

From jos.lommerse at certara.com  Wed Jan  3 14:09:52 2018
From: jos.lommerse at certara.com (Jos Lommerse)
Date: Wed, 3 Jan 2018 13:09:52 +0000
Subject: [R]  start values for random effects in nlme
Message-ID: <BLUPR18MB006638E87F726286EA121ECF9D1E0@BLUPR18MB0066.namprd18.prod.outlook.com>

Hi Lindsey,

Yeah, I do realize that this answer gets to you 12 years too late, however, it may be helpful to others in future.
I have been struggling with the same issue. When analysing the source code (https://svn.r-project.org/R-packages/trunk/nlme/R/nlme.R)
I found out that the E matrix needs rownames referring to the random effect of each group in the dataset, something like:
rownames(E) <- c("subjectname1","subjectname2","subjectname3",.....).
Then your code should run perfectly OK.

Example:
----------
library(nlme)

data <- data.frame(a=c(1,2,3,4,5,1,2,3,4,5,1,2,3,4,5),
                   b=c(2,3,4,5,7,3,4,5,7,8,3,5,6,8,9),
                   ID=c(rep('X',5),rep('Y',5),rep('Z',5)))

# Random effect matrix E:
E <- as.matrix(c(-0.1,0.2,0.3))
rownames(E) <- c('X','Y','Z')
fm1 <- nlme(b ~ par1*a + par2*exp(IIV),
            data = data,
            fixed = list(par1 ~ 1, par2 ~ 1),
            random = IIV ~ 1 | ID,
            start = list(fixed = c(1,1), random= E))
summary(fm1)
---------

Kind regards,
Jos Lommerse, Certara


NOTICE: The information contained in this electronic mail message is intended only for the personal and confidential 
use of the designated recipient(s) named above. This message may be an attorney-client communication, may be protected 
by the work product doctrine, and may be subject to a protective order. As such, this message is privileged and 
confidential. If the reader of this message is not the intended recipient or an agent responsible for delivering it to 
the intended recipient, you are hereby notified that you have received this message in error and that any review, 
dissemination, distribution, or copying of this message is strictly prohibited. If you have received this 
communication in error, please notify us immediately by telephone and e-mail and destroy any and all copies of this 
message in your possession (whether hard copies or electronically stored copies). Thank you.

buSp9xeMeKEbrUze

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Jan  3 20:50:33 2018
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 3 Jan 2018 19:50:33 +0000
Subject: [R] Help with Regular expression
In-Reply-To: <CA+dpOJ=q5+kx9rFyU+ovXCCCsLFgbG_QMAjW=897m2zzQEnTGw@mail.gmail.com>
References: <CA+dpOJ=q5+kx9rFyU+ovXCCCsLFgbG_QMAjW=897m2zzQEnTGw@mail.gmail.com>
Message-ID: <5450bc60-ab36-bccb-f1ec-5f92359b9c51@sapo.pt>

Hello,

I believe the following regex will do it.

x <- "\":\"03-JAN-2018 16:00:00\""

sub('^.*(\\d{2}-\\w{3}-\\d{4} \\d{2}:\\d{2}:\\d{2})[:"]', '\\1', x)


Hope this helps,

Rui Barradas

On 1/3/2018 2:26 PM, Christofer Bogaso wrote:
> Hi,
> 
> I was working on following expression :
> 
> "\":\"03-JAN-2018 16:00:00\""
> 
> 
> This is basically a combination of Date and Time mixed with some Noise.
> 
> I want to extract only Date and Time part i.e. "03-JAN-2018 16:00:00
> 
> I tried following :
> 
> gsub("![0-9][0-9]-[a-zA-Z][a-zA-Z][a-zA-Z]-[0-9][0-9][0-9][0-9]
> [0-9][0-9]:[0-9][0-9]:[0-9][0-9]", "", "\":\"03-JAN-2018 16:00:00\"",
> ignore.case = TRUE)
> 
> Obviously, with above code, I am removing that portion of my string
> which I actually I wanted!
> 
> How can I reverse above code, so that I will be removing that portion
> of my string which I actually I ***NOT*** wanted?
> 
> Thanks for your time.
> 
> Happy New Year!
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chkstr at unife.it  Wed Jan  3 20:53:08 2018
From: chkstr at unife.it (Saptorshee Kanto Chakraborty)
Date: Wed, 3 Jan 2018 20:53:08 +0100
Subject: [R] HOW TO FILTER DATA
Message-ID: <CAAr3ZhgerCecmpDMnuUfwg22=EGsSv2oDz8eaM-wv+UWKusUNw@mail.gmail.com>

Hello,

I have a data of Patents from OECD in delimited text format with IPC being
one column, I want to filter the data by selecting only certain IPC in that
column and delete other rows which do not have my required IPCs. Please,
can anybody guide me doing it, also the IPC codes are string variables.

The data is somewhat like below, but its a huge dataset containing more
than 11 million rows


Appln_id|Prio_Year|App_year|IPC
1|1999|2000|H04Q007/32
1|1999|2000|G06K019/077
1|1999|2000|H01R012/18
1|1999|2000|G06K017/00
1|1999|2000|H04M001/2745
1|1999|2000|G06K007/00
1|1999|2000|H04M001/02
1|1999|2000|H04M001/275
2|1991|1992|C12N015/62
2|1991|1992|C12N015/09
2|1991|1992|C07K019/00
2|1991|1992|C07K016/26



Thanking You

	[[alternative HTML version deleted]]


From motyocska at yahoo.com  Wed Jan  3 20:57:10 2018
From: motyocska at yahoo.com (Andras Farkas)
Date: Wed, 3 Jan 2018 19:57:10 +0000 (UTC)
Subject: [R] summary.rms help
References: <1741080969.8978385.1515009430548.ref@mail.yahoo.com>
Message-ID: <1741080969.8978385.1515009430548@mail.yahoo.com>

Dear All,
using the example from the help of summary.rms

library(rms)
n <- 1000    # define sample size 
set.seed(17) # so can reproduce the results 
age            <- rnorm(n, 50, 10) 
blood.pressure <- rnorm(n, 120, 15) 
cholesterol    <- rnorm(n, 200, 25) 
sex            <- factor(sample(c('female','male'), n,TRUE)) 
label(age)            <- 'Age'      # label is in Hmisc 
label(cholesterol)    <- 'Total Cholesterol' 
label(blood.pressure) <- 'Systolic Blood Pressure' 
label(sex)            <- 'Sex' 
units(cholesterol)    <- 'mg/dl'   # uses units.default in Hmisc 
units(blood.pressure) <- 'mmHg' 
# Specify population model for log odds that Y=1 
L <- .4*(sex=='male') + .045*(age-50) + 
(log(cholesterol - 10)-5.2)*(-2*(sex=='female') + 2*(sex=='male')) 
# Simulate binary y to have Prob(y=1) = 1/[1+exp(-L)] 
y <- ifelse(runif(n) < plogis(L), 1, 0) 
ddist <- datadist(age, blood.pressure, cholesterol, sex) 
options(datadist='ddist') 
fit <- lrm(y ~ blood.pressure + sex * (age + rcs(cholesterol,4)))
s <- summary(fit) 
plot(s)
as you will see the plot will by default include the low and high values from the summary printed on the plot to the right of the variable name... Any thoughts on how printing these low and high values can be suppressed, ie: prevent them from being printed?

 
appreciate your help,
Andras


From dwinsemius at comcast.net  Wed Jan  3 22:14:02 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 3 Jan 2018 13:14:02 -0800
Subject: [R] summary.rms help
In-Reply-To: <1741080969.8978385.1515009430548@mail.yahoo.com>
References: <1741080969.8978385.1515009430548.ref@mail.yahoo.com>
 <1741080969.8978385.1515009430548@mail.yahoo.com>
Message-ID: <F0BF8917-95FF-4C1C-B1EB-C65AAC1914B0@comcast.net>


> On Jan 3, 2018, at 11:57 AM, Andras Farkas via R-help <r-help at r-project.org> wrote:
> 
> Dear All,
> using the example from the help of summary.rms
> 
> library(rms)
> n <- 1000    # define sample size 
> set.seed(17) # so can reproduce the results 
> age            <- rnorm(n, 50, 10) 
> blood.pressure <- rnorm(n, 120, 15) 
> cholesterol    <- rnorm(n, 200, 25) 
> sex            <- factor(sample(c('female','male'), n,TRUE)) 
> label(age)            <- 'Age'      # label is in Hmisc 
> label(cholesterol)    <- 'Total Cholesterol' 
> label(blood.pressure) <- 'Systolic Blood Pressure' 
> label(sex)            <- 'Sex' 
> units(cholesterol)    <- 'mg/dl'   # uses units.default in Hmisc 
> units(blood.pressure) <- 'mmHg' 
> # Specify population model for log odds that Y=1 
> L <- .4*(sex=='male') + .045*(age-50) + 
> (log(cholesterol - 10)-5.2)*(-2*(sex=='female') + 2*(sex=='male')) 
> # Simulate binary y to have Prob(y=1) = 1/[1+exp(-L)] 
> y <- ifelse(runif(n) < plogis(L), 1, 0) 
> ddist <- datadist(age, blood.pressure, cholesterol, sex) 
> options(datadist='ddist') 
> fit <- lrm(y ~ blood.pressure + sex * (age + rcs(cholesterol,4)))
> s <- summary(fit) 
> plot(s)
> as you will see the plot will by default include the low and high values from the summary printed on the plot to the right of the variable name... Any thoughts on how printing these low and high values can be suppressed, ie: prevent them from being printed?
> 

Luke, ... Look at the code!

The values are suppressed if the "Diff." has NA's so ...

s[ , "Diff."] <- NA
plot(s)

-- 
David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From ruipbarradas at sapo.pt  Wed Jan  3 22:45:51 2018
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 3 Jan 2018 21:45:51 +0000
Subject: [R] HOW TO FILTER DATA
In-Reply-To: <CAAr3ZhgerCecmpDMnuUfwg22=EGsSv2oDz8eaM-wv+UWKusUNw@mail.gmail.com>
References: <CAAr3ZhgerCecmpDMnuUfwg22=EGsSv2oDz8eaM-wv+UWKusUNw@mail.gmail.com>
Message-ID: <9dddef4a-8234-4e8b-f821-ba82d77a525d@sapo.pt>

Hello,

If you want to select rows with just one IPC, use `==`.
If you want to select rows with several IPC's, use `%in%`.
See the code below for the two ways of doing this.


oecd <- read.table(text = "
Appln_id|Prio_Year|App_year|IPC
1|1999|2000|H04Q007/32
1|1999|2000|G06K019/077
1|1999|2000|H01R012/18
1|1999|2000|G06K017/00
1|1999|2000|H04M001/2745
1|1999|2000|G06K007/00
1|1999|2000|H04M001/02
1|1999|2000|H04M001/275
2|1991|1992|C12N015/62
2|1991|1992|C12N015/09
2|1991|1992|C07K019/00
2|1991|1992|C07K016/26
", header = TRUE, sep = "|")


select_one <- "H04Q007/32"
select_many <- c("H04Q007/32", "H04M001/275")

oecd2 <- subset(oecd, IPC == select_one)
oecd3 <- subset(oecd, IPC %in% select_many)


Hope this helps,

Rui Barradas

On 1/3/2018 7:53 PM, Saptorshee Kanto Chakraborty wrote:
> Hello,
> 
> I have a data of Patents from OECD in delimited text format with IPC being
> one column, I want to filter the data by selecting only certain IPC in that
> column and delete other rows which do not have my required IPCs. Please,
> can anybody guide me doing it, also the IPC codes are string variables.
> 
> The data is somewhat like below, but its a huge dataset containing more
> than 11 million rows
> 
> 
> Appln_id|Prio_Year|App_year|IPC
> 1|1999|2000|H04Q007/32
> 1|1999|2000|G06K019/077
> 1|1999|2000|H01R012/18
> 1|1999|2000|G06K017/00
> 1|1999|2000|H04M001/2745
> 1|1999|2000|G06K007/00
> 1|1999|2000|H04M001/02
> 1|1999|2000|H04M001/275
> 2|1991|1992|C12N015/62
> 2|1991|1992|C12N015/09
> 2|1991|1992|C07K019/00
> 2|1991|1992|C07K016/26
> 
> 
> 
> Thanking You
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruanleilei at gmail.com  Wed Jan  3 21:54:44 2018
From: ruanleilei at gmail.com (Leilei Ruan)
Date: Wed, 3 Jan 2018 15:54:44 -0500
Subject: [R] HOW TO FILTER DATA
In-Reply-To: <CAAr3ZhgerCecmpDMnuUfwg22=EGsSv2oDz8eaM-wv+UWKusUNw@mail.gmail.com>
References: <CAAr3ZhgerCecmpDMnuUfwg22=EGsSv2oDz8eaM-wv+UWKusUNw@mail.gmail.com>
Message-ID: <CAJ+cKahfV6Qamac7V9jWeX04Gsq+sN1LfZ_n8iNZh1gXJP14Yw@mail.gmail.com>

Try the code below:


df <- read_delim("C:/Users/lruan1/Desktop/1112.csv", "|", escape_double =
FALSE, trim_ws = TRUE)

df_new <- subset(df,df$IPC == 'H04M001/02'| df$IPC == 'C07K016/26' )

You can add more condition with "|" in the subset function. Good luck!

On Wed, Jan 3, 2018 at 2:53 PM, Saptorshee Kanto Chakraborty <
chkstr at unife.it> wrote:

> Hello,
>
> I have a data of Patents from OECD in delimited text format with IPC being
> one column, I want to filter the data by selecting only certain IPC in that
> column and delete other rows which do not have my required IPCs. Please,
> can anybody guide me doing it, also the IPC codes are string variables.
>
> The data is somewhat like below, but its a huge dataset containing more
> than 11 million rows
>
>
> Appln_id|Prio_Year|App_year|IPC
> 1|1999|2000|H04Q007/32
> 1|1999|2000|G06K019/077
> 1|1999|2000|H01R012/18
> 1|1999|2000|G06K017/00
> 1|1999|2000|H04M001/2745
> 1|1999|2000|G06K007/00
> 1|1999|2000|H04M001/02
> 1|1999|2000|H04M001/275
> 2|1991|1992|C12N015/62
> 2|1991|1992|C12N015/09
> 2|1991|1992|C07K019/00
> 2|1991|1992|C07K016/26
>
>
>
> Thanking You
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Thu Jan  4 17:41:36 2018
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 4 Jan 2018 16:41:36 +0000
Subject: [R] HOW TO FILTER DATA
In-Reply-To: <CAJ+cKahfV6Qamac7V9jWeX04Gsq+sN1LfZ_n8iNZh1gXJP14Yw@mail.gmail.com>
References: <CAAr3ZhgerCecmpDMnuUfwg22=EGsSv2oDz8eaM-wv+UWKusUNw@mail.gmail.com>
 <CAJ+cKahfV6Qamac7V9jWeX04Gsq+sN1LfZ_n8iNZh1gXJP14Yw@mail.gmail.com>
Message-ID: <676B33C0-F043-44A0-8DFB-29D762DF46FB@llnl.gov>

Just a couple of minor comments:

> help.search('read_delim')
No vignettes or demos or help files found with alias or concept or
title matching 'read_delim' using regular expression matching.

read_delim is not part of base R; it must come from some unnamed non-base package. I'd recommend using base R as much as possible for someone who is new to R, as I suspect the original poster is.

The call to subset would be better written as

  df_new <- subset(df, IPC == 'H04M001/02' | IPC == 'C07K016/26' )
instead of
  df_new <- subset(df, df$IPC == 'H04M001/02' | df$IPC == 'C07K016/26' )

IPC is a variable within the data frame, so it is unnecessary to include the data frame's name in the logical expression.

-Don


--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

On 1/3/18, 12:54 PM, "R-help on behalf of Leilei Ruan" <r-help-bounces at r-project.org on behalf of ruanleilei at gmail.com> wrote:

    Try the code below:
    
    
    df <- read_delim("C:/Users/lruan1/Desktop/1112.csv", "|", escape_double =
    FALSE, trim_ws = TRUE)
    
    df_new <- subset(df,df$IPC == 'H04M001/02'| df$IPC == 'C07K016/26' )
    
    You can add more condition with "|" in the subset function. Good luck!
    
    On Wed, Jan 3, 2018 at 2:53 PM, Saptorshee Kanto Chakraborty <
    chkstr at unife.it> wrote:
    
    > Hello,
    >
    > I have a data of Patents from OECD in delimited text format with IPC being
    > one column, I want to filter the data by selecting only certain IPC in that
    > column and delete other rows which do not have my required IPCs. Please,
    > can anybody guide me doing it, also the IPC codes are string variables.
    >
    > The data is somewhat like below, but its a huge dataset containing more
    > than 11 million rows
    >
    >
    > Appln_id|Prio_Year|App_year|IPC
    > 1|1999|2000|H04Q007/32
    > 1|1999|2000|G06K019/077
    > 1|1999|2000|H01R012/18
    > 1|1999|2000|G06K017/00
    > 1|1999|2000|H04M001/2745
    > 1|1999|2000|G06K007/00
    > 1|1999|2000|H04M001/02
    > 1|1999|2000|H04M001/275
    > 2|1991|1992|C12N015/62
    > 2|1991|1992|C12N015/09
    > 2|1991|1992|C07K019/00
    > 2|1991|1992|C07K016/26
    >
    >
    >
    > Thanking You
    >
    >         [[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/
    > posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    >
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From marc_grt at yahoo.fr  Thu Jan  4 21:12:12 2018
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Thu, 4 Jan 2018 21:12:12 +0100
Subject: [R] format integer numbers with leading 0
Message-ID: <b1407cc4-bf7a-0f0f-6702-3810a712d54d@yahoo.fr>

Dear R-er,

I would like format integer number as characters with leading 0 for a 
fixed width, for example:

1 shoud be "01"
2 shoud be "02"
20 should be "20"

Now I use:

x <- c(1, 2, 20)

gsub(" ", "0", format(x, width=2))

But I suspect more elegant way could be done directly with format 
options, but I don't find.

Thanks a lot

Marc


From r at catwhisker.org  Thu Jan  4 21:15:11 2018
From: r at catwhisker.org (David Wolfskill)
Date: Thu, 4 Jan 2018 12:15:11 -0800
Subject: [R] format integer numbers with leading 0
In-Reply-To: <b1407cc4-bf7a-0f0f-6702-3810a712d54d@yahoo.fr>
References: <b1407cc4-bf7a-0f0f-6702-3810a712d54d@yahoo.fr>
Message-ID: <20180104201511.GT1258@albert.catwhisker.org>

On Thu, Jan 04, 2018 at 09:12:12PM +0100, Marc Girondot via R-help wrote:
> Dear R-er,
> 
> I would like format integer number as characters with leading 0 for a 
> fixed width, for example:
> 
> 1 shoud be "01"
> 2 shoud be "02"
> 20 should be "20"
> 
> Now I use:
> 
> x <- c(1, 2, 20)
> 
> gsub(" ", "0", format(x, width=2))
> 
> But I suspect more elegant way could be done directly with format 
> options, but I don't find.

> x <- c(1, 2, 20)
> sprintf("%02d", x)
[1] "01" "02" "20"
> 

Peace,
david
-- 
David H. Wolfskill				r at catwhisker.org
If you want the best Fake News, go to the best source of it: Donald J. Trump.

See http://www.catwhisker.org/~david/publickey.gpg for my public key.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 603 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180104/72ecb827/attachment.sig>

From lasse at lassekliemann.de  Thu Jan  4 21:34:02 2018
From: lasse at lassekliemann.de (Lasse Kliemann)
Date: Thu, 04 Jan 2018 21:34:02 +0100
Subject: [R] format integer numbers with leading 0
In-Reply-To: <b1407cc4-bf7a-0f0f-6702-3810a712d54d@yahoo.fr>
References: <b1407cc4-bf7a-0f0f-6702-3810a712d54d@yahoo.fr>
Message-ID: <87a7xt4b45.fsf@lassekliemann.de>

Marc Girondot via R-help <r-help at r-project.org> writes:

> I would like format integer number as characters with leading 0 for a 
> fixed width, for example:
>
> 1 shoud be "01"
> 2 shoud be "02"
> 20 should be "20"

formatC(x, width=2, flag="0")
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 832 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180104/4e503279/attachment.sig>

From marc_grt at yahoo.fr  Thu Jan  4 21:37:56 2018
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Thu, 4 Jan 2018 21:37:56 +0100
Subject: [R] format integer numbers with leading 0
Message-ID: <a63c8e9d-91ef-4b65-5bc9-f286f21c9a58@yahoo.fr>

Dear R-er,

I would like format integer number as characters with leading 0 for a 
fixed width, for example:

1 shoud be "01"
2 shoud be "02"
20 should be "20"

Now I use:

x <- c(1, 2, 20)

gsub(" ", "0", format(x, width=2))

But I suspect more elegant way could be done directly with format 
options, but I don't find.

Thanks a lot

Marc


From chalabi.elahe at yahoo.de  Thu Jan  4 21:45:21 2018
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Thu, 4 Jan 2018 20:45:21 +0000 (UTC)
Subject: [R] Random Forest tree labels
References: <1068658583.1053251.1515098721906.ref@mail.yahoo.com>
Message-ID: <1068658583.1053251.1515098721906@mail.yahoo.com>

Hi all, 


I have built a Random Forest using Caret package, however, I don't understand how the splits are labeled in trees. My dataset contains the frequency of the words in the speeches of the people:

'data.frame':	499 obs. of 608 variables:
$ alright : num 1 0 0 0 0 0 0 1 2 1 ...
$ bad : num 1 0 0 0 0 0 0 0 0 0 ...
$ boy : num 1 2 1 1 0 2 2 4 2 1 ...
$ cooki : num 1 2 2 1 0 1 1 4 2 3 ...
$ curtain : num 1 0 0 0 0 2 0 2 0 0 ...
$ dish : num 2 1 0 1 0 0 1 2 2 2 ...
$ doesnt : num 1 0 0 0 0 0 0 0 1 0 ...

why are splits labeled for example with 0.5?
Thanks for any help,

Elahe
-------------- next part --------------
A non-text attachment was scrubbed...
Name: tree.PNG
Type: image/png
Size: 50718 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180104/a000a148/attachment.png>

From dcepulic at gmail.com  Fri Jan  5 15:49:31 2018
From: dcepulic at gmail.com (=?UTF-8?B?RG9taW5payDEhmVwdWxpxIc=?=)
Date: Fri, 5 Jan 2018 15:49:31 +0100
Subject: [R] Calculating the correlations of nested random effects in lme4
Message-ID: <CAGbn3HaYV38x43f0F+inNS1_-7yt+DBCohb=11H43KcvQBAwSw@mail.gmail.com>

I postulate the following model

    AC <- glmer(Accuracy ~ RT*Group + (1+RT|Group:subject) +
(1+RT|Group:Trial), data = da, family = binomial, verbose = T)


Here I predict Accuracy from RT, Group (which has values 0 or 1) and the
interaction of Group and RT (those are the fixed effects). I also estimate
the random effects for both intercepts and slopes for subjects and
different trials. However, these random effects are nested in one of the
mentioned two groups. That means that I calculate the subject random
effects separately for group 0 and for group 1. Also, the trial random
effects are calculated separately for group 0 and for group 1.

The results are following:

    Random effects:
     Groups             Name            Variance Std.Dev. Corr
     Group:subject (Intercept)         0.9785   0.9892
                                     RT         0.1434   0.3787   -0.77
     Group:Trial   (Intercept)            0.7694   0.8772
                                   RT           0.1047   0.3236   -0.68
    Number of obs: 39401, groups:  Group:subject, 438; Group:Trial, 180

    Fixed effects:
                     Estimate Std. Error z value Pr(>|z|)
    (Intercept)       2.72834    0.11997  22.742  < 2e-16 ***
    RT                 -0.98367    0.05909 -16.647  < 2e-16 ***
    Group1           -0.12424    0.16829  -0.738  0.46036
    RT:Group1       0.23286    0.08163   2.853  0.00434 **

All the random effects coefficients represent the effects for Group 0  and
1 random effects together, without differentiating them. I would like to
get the following:

1) estimations for subject and trial random effects in group 0 and in group
1 separately (Variance and Correlations).

2) estimations of the correlations between random slopes in subjects in
group 0 and group 1.

Questions:

3) Can lme4 and lmerTest do this? If yes, how?

4) If it cannot, is it justified to do separate models for group 0 and for
group 1, and then compare the results? the problem here is that I don't get
the statistical test of the RT:Group1 interaction.

5) Is it justified to extract the random effects for different groups and
then calculate the correlations, and variances manually? If yes, is it more
reasonable to extract the random effects from the model where the
interaction between RT and Group is included, or from the models which are
separated according to the group (as mentioned in question 4). I know that
you get different results than when letting lme4 calculate the coefficients
due to the marginal probabilities...

Thanks!

*EDIT A*
Roland from CrossValidated suggested to try and specify the random effects
as this:
(RT * Group | Group:subject) + (RT * Group | Group:Trial)

This is what I got:

    Random effects:
     Groups           Name             Variance Std.Dev. Corr
     Group:subject  (Intercept)       0.88355  0.9400
                             RT               0.11654  0.3414
-0.87
                            Group1          0.68278  0.8263   -0.32
0.26
                          RT:Group1        0.12076  0.3475   -0.01 -0.28
-0.24

     Group:Trial   (Intercept)         0.64182  0.8011
                           RT                 0.09434  0.3071
-0.76
                    Group1                  0.75896  0.8712   -0.37
0.29
                    RT:Group1             0.15605  0.3950    0.29 -0.53
-0.52
    Number of obs: 39401, groups:  Group:subject, 438; Group:Trial, 180

    Fixed effects:
                     Estimate Std. Error z value Pr(>|z|)
    (Intercept)       2.70777    0.11273  24.021  < 2e-16 ***
    RT               -0.98825    0.05821 -16.976  < 2e-16 ***
    Group1           -0.08302    0.16997  -0.488  0.62525
    RT:Group1         0.25620    0.08793   2.914  0.00357 **
    ---
    Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

    convergence code: 0
    unable to evaluate scaled gradient
    Model failed to converge: degenerate  Hessian with 5 negative
eigenvalues


*A1*) This looks like what I was looking for, especially when I run the
command. However, the model did not converge

    convergence code: 0
    unable to evaluate scaled gradient
    Model failed to converge: degenerate  Hessian with 5 negative
eigenvalues

What should I do with these warnings?

*A2*) I am a bit baffeled when I extract random effects
ranef(mod$Group:subject)

                       (Intercept)            RT
Group1          RT:Group1
    0:251001     -1.308168428  0.4780271048  0.352869565    -0.0737619415
    0:251002      1.050036079 -0.3071004273 -0.294625317    -0.0334146992
    0:251003     -1.220858015  0.4676770866  0.326114487    -0.0949017322
    0:251004      0.944849620 -0.2545466823 -0.268350172    -0.0564150418
    ...
    1:251001     -0.197649527  0.0839724493 -0.649897297    -0.1228681971
    1:251002      0.710716899 -0.2103765167  0.006884114    -0.2151618897
    1:251003     -0.402869078  0.1326561677 -0.344966110     0.0257983193
    1:251004     -0.321174375  0.0874198115  0.191529601     0.1521126993

I already have nested subjects in rownames (0:251001) - so that means
subject 251001 in group 0, and then again I have values for each subject in
group 0 (intercept column) and group 1(Group1 column). The same is with
slope. What does this data show me?

What is the difference between defining random factors as
`1+RT|Group:subject` and then looking at Intercept and RT values for
0:subject1, 0:subject2...., 1:subject1, 1:subject2...

and

defining random factors as `RT*Group|subject` and looking at the various
columns (Intercept, RT, Group1, RT:Group1) for subject1, subject 2 etc.?

Thank you,
Dominik

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Fri Jan  5 17:31:21 2018
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Fri, 5 Jan 2018 16:31:21 +0000 (UTC)
Subject: [R] Document Term Matrix
References: <1704703550.1782265.1515169881556.ref@mail.yahoo.com>
Message-ID: <1704703550.1782265.1515169881556@mail.yahoo.com>

Hi,

Does anyone know what is maximal term length in Document Term Matrix?


<<DocumentTermMatrix (documents: 255, terms: 858)>>
Non-/sparse entries: 8081/210709
Sparsity           : 96%
Maximal term length: 12
Weighting          : term frequency (tf)

Thanks for any help!
Elahe


From arun.kumar.saha at gmail.com  Fri Jan  5 21:46:12 2018
From: arun.kumar.saha at gmail.com (Arun Kumar Saha)
Date: Sat, 6 Jan 2018 02:16:12 +0530
Subject: [R] Help with Regular expression
Message-ID: <CAPVuaOcPUSxFY5QECKU3mEDqiMAMMmCv1GgoQGXresGBY-TeZg@mail.gmail.com>

Hi Bogaso,

I see your ultimate goal is to extract the Date-time part from your
expression, then below should help :

> as.POSIXlt(gsub("[^0-9a-zA-Z]", "", "\":\"03-JAN-2018 16:00:00\""),
format = "%d%b%Y%H%M%OS")

[1] "2018-01-03 16:00:00 GMT"
_____________________________________________________

Arun Kumar Saha, FRM
QUANTITATIVE RISK AND HEDGE CONSULTING SPECIALIST
 LinkedIn: http://in.linkedin.com/in/ArunFRM
 Personal : http://WWW.ARUNSAHA.IN  <http://WWW.ARUNSAHA.IN>
_____________________________________________________

	[[alternative HTML version deleted]]


From bogaso.christofer at gmail.com  Sat Jan  6 14:27:07 2018
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sat, 6 Jan 2018 18:57:07 +0530
Subject: [R] How to programmatically save a web-page using R (mimicking
	Command+S)
Message-ID: <CA+dpOJmuPUgLhO6j3Pfpk2o2ofPB0+1raD0i4tRqg1DOmbftdw@mail.gmail.com>

Hi,

I would appreciate if someone can give me a pointer on how to save a
webpage programmatically using R.

For example, let say I have this webpage open in my browser:

http://www.bseindia.com/stock-share-price/dabur-india-ltd/dabur/500096/

When manually I save this page, I just press Command+S (using Mac) and
then this page get saved in hard-disk

Now I want R to mimic this same job that I do using Command-S

So far I have tried with readLines() however the output content is
different than what I could achieve using Command+S

Any help will be highly appreciated.

Thanks for your time.


From henrik.bengtsson at gmail.com  Sat Jan  6 14:44:29 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sat, 6 Jan 2018 05:44:29 -0800
Subject: [R] How to programmatically save a web-page using R (mimicking
	Command+S)
In-Reply-To: <CA+dpOJmuPUgLhO6j3Pfpk2o2ofPB0+1raD0i4tRqg1DOmbftdw@mail.gmail.com>
References: <CA+dpOJmuPUgLhO6j3Pfpk2o2ofPB0+1raD0i4tRqg1DOmbftdw@mail.gmail.com>
Message-ID: <CAFDcVCTrokvog0+Q4sUR+zyCy2wVE7CgrWuyigKXAfyoekFCUg@mail.gmail.com>

The 'webshot' package (on CRAN) can do this.

Henrik

On Jan 6, 2018 05:27, "Christofer Bogaso" <bogaso.christofer at gmail.com>
wrote:

> Hi,
>
> I would appreciate if someone can give me a pointer on how to save a
> webpage programmatically using R.
>
> For example, let say I have this webpage open in my browser:
>
> http://www.bseindia.com/stock-share-price/dabur-india-ltd/dabur/500096/
>
> When manually I save this page, I just press Command+S (using Mac) and
> then this page get saved in hard-disk
>
> Now I want R to mimic this same job that I do using Command-S
>
> So far I have tried with readLines() however the output content is
> different than what I could achieve using Command+S
>
> Any help will be highly appreciated.
>
> Thanks for your time.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ashimkapoor at gmail.com  Sun Jan  7 06:07:41 2018
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Sun, 7 Jan 2018 10:37:41 +0530
Subject: [R] SpreadLevelPlot for more than one factor
Message-ID: <CAC8=1erwSbShZ46SvbN_MGYEwDsV-15uGSriNxA6J_KcF0zUTw@mail.gmail.com>

Dear All,

I want a transformation which will make the spread of the response at  all
combinations
of  2 factors the same.

See for example :

boxplot(breaks ~ tension * wool, warpbreaks)

The closest I  can do is :

spreadLevelPlot(breaks ~tension , warpbreaks)
spreadLevelPlot(breaks ~ wool , warpbreaks)

I want to do :

spreadLevelPlot(breaks ~tension * wool, warpbreaks)

But I get :

> spreadLevelPlot(breaks ~tension * wool , warpbreaks)
Error in spreadLevelPlot.formula(breaks ~ tension * wool, warpbreaks) :
  right-hand side of model has more than one variable

What is the corresponding appropriate function for 2 factors ?

Many thanks,
Ashim

	[[alternative HTML version deleted]]


From ashimkapoor at gmail.com  Sun Jan  7 06:29:07 2018
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Sun, 7 Jan 2018 10:59:07 +0530
Subject: [R] SpreadLevelPlot for more than one factor
In-Reply-To: <CAC8=1erwSbShZ46SvbN_MGYEwDsV-15uGSriNxA6J_KcF0zUTw@mail.gmail.com>
References: <CAC8=1erwSbShZ46SvbN_MGYEwDsV-15uGSriNxA6J_KcF0zUTw@mail.gmail.com>
Message-ID: <CAC8=1epWDMTBpRDFbmPd51DatmTWFWetpZLUqwOf6NKSOxUadw@mail.gmail.com>

Dear All,

we need to do :

library(car) for the spreadLevelPlot function

I forgot to say that.

Apologies,
Ashim

On Sun, Jan 7, 2018 at 10:37 AM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear All,
>
> I want a transformation which will make the spread of the response at  all
> combinations
> of  2 factors the same.
>
> See for example :
>
> boxplot(breaks ~ tension * wool, warpbreaks)
>
> The closest I  can do is :
>
> spreadLevelPlot(breaks ~tension , warpbreaks)
> spreadLevelPlot(breaks ~ wool , warpbreaks)
>
> I want to do :
>
> spreadLevelPlot(breaks ~tension * wool, warpbreaks)
>
> But I get :
>
> > spreadLevelPlot(breaks ~tension * wool , warpbreaks)
> Error in spreadLevelPlot.formula(breaks ~ tension * wool, warpbreaks) :
>   right-hand side of model has more than one variable
>
> What is the corresponding appropriate function for 2 factors ?
>
> Many thanks,
> Ashim
>

	[[alternative HTML version deleted]]


From ashimkapoor at gmail.com  Sun Jan  7 10:35:16 2018
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Sun, 7 Jan 2018 15:05:16 +0530
Subject: [R] SpreadLevelPlot for more than one factor
In-Reply-To: <CAC8=1epWDMTBpRDFbmPd51DatmTWFWetpZLUqwOf6NKSOxUadw@mail.gmail.com>
References: <CAC8=1erwSbShZ46SvbN_MGYEwDsV-15uGSriNxA6J_KcF0zUTw@mail.gmail.com>
 <CAC8=1epWDMTBpRDFbmPd51DatmTWFWetpZLUqwOf6NKSOxUadw@mail.gmail.com>
Message-ID: <CAC8=1ertdQOt4DJHww8UP+mcSURRdjVjLgH50m-oRs4sJZdd5Q@mail.gmail.com>

Dear All,

I did this :

> v = wool:tension
> spreadLevelPlot(breaks ~ v)
    LowerHinge Median UpperHinge Hinge-Spread
B:H         15     17         21            6
A:M         18     21         30           12
A:H         18     24         28           10
B:M         21     28         39           18
B:L         20     29         31           11
A:L         26     51         54           28

Suggested power transformation:  -0.2756176

So the ans is approximately  = -.2

My query is:corresponding to  p , what is the corresponding power
transformation defined as? Is it x^p  or (x^p -1) / p ?

Which one of the following is the final transformation ? Please clarify.
> boxplot(breaks ^ -.2 ~v)
> boxplot((breaks^-.2 -1)/(-.2)~v)
>

Best Regards,
Ashim

On Sun, Jan 7, 2018 at 10:59 AM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear All,
>
> we need to do :
>
> library(car) for the spreadLevelPlot function
>
> I forgot to say that.
>
> Apologies,
> Ashim
>
> On Sun, Jan 7, 2018 at 10:37 AM, Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
>
>> Dear All,
>>
>> I want a transformation which will make the spread of the response at
>> all combinations
>> of  2 factors the same.
>>
>> See for example :
>>
>> boxplot(breaks ~ tension * wool, warpbreaks)
>>
>> The closest I  can do is :
>>
>> spreadLevelPlot(breaks ~tension , warpbreaks)
>> spreadLevelPlot(breaks ~ wool , warpbreaks)
>>
>> I want to do :
>>
>> spreadLevelPlot(breaks ~tension * wool, warpbreaks)
>>
>> But I get :
>>
>> > spreadLevelPlot(breaks ~tension * wool , warpbreaks)
>> Error in spreadLevelPlot.formula(breaks ~ tension * wool, warpbreaks) :
>>   right-hand side of model has more than one variable
>>
>> What is the corresponding appropriate function for 2 factors ?
>>
>> Many thanks,
>> Ashim
>>
>
>

	[[alternative HTML version deleted]]


From akshay_e4 at hotmail.com  Sun Jan  7 13:29:41 2018
From: akshay_e4 at hotmail.com (akshay kulkarni)
Date: Sun, 7 Jan 2018 12:29:41 +0000
Subject: [R] help needed on quantmod....
Message-ID: <SL2P216MB0091F66FE5DB4FD9F0587EBFC8120@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,

                            I am using quantmod to work with stock prices...


I am trying to append the data got from getQuote to the one got by getSymbols. The function is named "apnd".  The code is as  follows:


function(x){
              if ((class(x) == "xts") || (class(x) == "zoo")){
                sym <- deparse(substitute(x))
                y <- getQuote(sym)
             # convert to xts
                y1 <- y[,-c(3,4)]
                y2 <- y1[,c("Trade Time","Open","High","Low","Last","Volume")]
             yxts <- xts(y2[, -1], as.Date(y2[, 1]))
             yxts$Adjusted <- yxts[, 'Last']
           return(rbind(x, yxts))

}
              if(class(x) == "list"){
                 for(j in 1:length(x)){
                    sym <- deparse(substitute(x[[j]]))
                y <- getQuote(sym)
             # convert to xts
                y1 <- y[,-c(3,4)]
                y2 <- y1[,c("Trade Time","Open","High","Low","Last","Volume")]
             yxts[[j]] <- xts(y2[, -1], as.Date(y2[, 1]))
             yxts[[j]]$Adjusted <- yxts[[j]][, 'Last']
             yxts[[j]] <- rbind(x[[j]], yxts[[j]])
                                       }
             return(yxts)
}
}

the part with class == xts or zoo is working fine. However, the part with class == list is not working. The point is, instead of running apnd for each stock, I create the list of stock names and run apnd with a for loop. However it is not working.


Any help will be highly appreciated

Very many thanks for your precious time..


yours sincerely,

AKSHAY M KULKARNI


	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sun Jan  7 14:37:20 2018
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 7 Jan 2018 13:37:20 +0000
Subject: [R] help needed on quantmod....
In-Reply-To: <SL2P216MB0091F66FE5DB4FD9F0587EBFC8120@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091F66FE5DB4FD9F0587EBFC8120@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <eb605e83-f3e7-67da-0a52-4d8075b25d7e@sapo.pt>

Hello,

How are you calling your function? Can you show us the actual code?
I am testing it like the following.

apnd(list("IBM"))
Error in 
download.file(paste("https://finance.yahoo.com/d/quotes.csv?s=",  :
   cannot open URL 
'https://finance.yahoo.com/d/quotes.csv?s=IBM&f=d1t1l1c1p2ohgv'
In addition: Warning message:
In download.file(paste("https://finance.yahoo.com/d/quotes.csv?s=",  :
   InternetOpenUrl failed: 'N?o foi poss?vel processar o nome ou o 
endere?o do servidor'


So it's a server error. Note that getSymbols("IBM") works as expected.

Hope this helps,

Rui Barradas

On 1/7/2018 12:29 PM, akshay kulkarni wrote:
> dear members,
> 
>                              I am using quantmod to work with stock prices...
> 
> 
> I am trying to append the data got from getQuote to the one got by getSymbols. The function is named "apnd".  The code is as  follows:
> 
> 
> function(x){
>                if ((class(x) == "xts") || (class(x) == "zoo")){
>                  sym <- deparse(substitute(x))
>                  y <- getQuote(sym)
>               # convert to xts
>                  y1 <- y[,-c(3,4)]
>                  y2 <- y1[,c("Trade Time","Open","High","Low","Last","Volume")]
>               yxts <- xts(y2[, -1], as.Date(y2[, 1]))
>               yxts$Adjusted <- yxts[, 'Last']
>             return(rbind(x, yxts))
> 
> }
>                if(class(x) == "list"){
>                   for(j in 1:length(x)){
>                      sym <- deparse(substitute(x[[j]]))
>                  y <- getQuote(sym)
>               # convert to xts
>                  y1 <- y[,-c(3,4)]
>                  y2 <- y1[,c("Trade Time","Open","High","Low","Last","Volume")]
>               yxts[[j]] <- xts(y2[, -1], as.Date(y2[, 1]))
>               yxts[[j]]$Adjusted <- yxts[[j]][, 'Last']
>               yxts[[j]] <- rbind(x[[j]], yxts[[j]])
>                                         }
>               return(yxts)
> }
> }
> 
> the part with class == xts or zoo is working fine. However, the part with class == list is not working. The point is, instead of running apnd for each stock, I create the list of stock names and run apnd with a for loop. However it is not working.
> 
> 
> Any help will be highly appreciated
> 
> Very many thanks for your precious time..
> 
> 
> yours sincerely,
> 
> AKSHAY M KULKARNI
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jfox at mcmaster.ca  Sun Jan  7 15:35:15 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Sun, 7 Jan 2018 14:35:15 +0000
Subject: [R] SpreadLevelPlot for more than one factor
In-Reply-To: <30617_1515301673_w0757qS5022949_CAC8=1erwSbShZ46SvbN_MGYEwDsV-15uGSriNxA6J_KcF0zUTw@mail.gmail.com>
References: <30617_1515301673_w0757qS5022949_CAC8=1erwSbShZ46SvbN_MGYEwDsV-15uGSriNxA6J_KcF0zUTw@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836754E17@FHSDB2D11-2.csu.mcmaster.ca>

Dear Ashim,

Try spreadLevelPlot(breaks ~ interaction(tension, wool), data=warpbreaks) .

I hope this helps,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
> Kapoor
> Sent: Sunday, January 7, 2018 12:08 AM
> To: r-help at r-project.org
> Subject: [R] SpreadLevelPlot for more than one factor
> 
> Dear All,
> 
> I want a transformation which will make the spread of the response at  all
> combinations of  2 factors the same.
> 
> See for example :
> 
> boxplot(breaks ~ tension * wool, warpbreaks)
> 
> The closest I  can do is :
> 
> spreadLevelPlot(breaks ~tension , warpbreaks) spreadLevelPlot(breaks ~ wool ,
> warpbreaks)
> 
> I want to do :
> 
> spreadLevelPlot(breaks ~tension * wool, warpbreaks)
> 
> But I get :
> 
> > spreadLevelPlot(breaks ~tension * wool , warpbreaks)
> Error in spreadLevelPlot.formula(breaks ~ tension * wool, warpbreaks) :
>   right-hand side of model has more than one variable
> 
> What is the corresponding appropriate function for 2 factors ?
> 
> Many thanks,
> Ashim
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcepulic at gmail.com  Sun Jan  7 15:46:00 2018
From: dcepulic at gmail.com (=?UTF-8?B?RG9taW5payDEhmVwdWxpxIc=?=)
Date: Sun, 7 Jan 2018 15:46:00 +0100
Subject: [R] Defining interaction in random effects in lme4
Message-ID: <CAGbn3Hb+ccw0Y+ZYCXvDJA9syNAqUG152BpQ3xZPqmoyPr+PGg@mail.gmail.com>

Dear everybody!

My fixed-effects-only model looks like this: glmer(Accuracy ~ C.RT*Group,
data = da)

C.RT is the reaction time variable, and Group is a categorical variable
with 0 and 1 as values. I would like to specify that main intercept, Group
intercept, C.RT slope and C.RT*Group slope vary across subjects and trials.

All subjects have values in Group = 0 and in Group = 1. Trials are nested
within Group because each trial belongs either to Group = 0 or Group = 1.
How should I specify the model?

My ideas were:

   1. glmer(Accuracy ~ C.RT*Group + (C.RT*Group|subject) + (1+C.RT|trial),
   data = da)

or
    2. glmer(Accuracy ~ C.RT*Group + (1+C.RT|Group:subject) +
(1+C.RT|Group:trial), data = da)

Here, Group:trial does not make much sense as trials are *per se* divided
in Group 0 or Group 1.

What is, in your opinion, the best way to specify the model that I want to
test?

Additionally, the difference between (1+C.RT|Group:subject) and
(C.RT*Object|subject) is not clear to me. Can someone also shed some light
here?

Thanks,
Dominik!

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Jan  7 20:05:35 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 7 Jan 2018 11:05:35 -0800
Subject: [R] Defining interaction in random effects in lme4
In-Reply-To: <CAGbn3Hb+ccw0Y+ZYCXvDJA9syNAqUG152BpQ3xZPqmoyPr+PGg@mail.gmail.com>
References: <CAGbn3Hb+ccw0Y+ZYCXvDJA9syNAqUG152BpQ3xZPqmoyPr+PGg@mail.gmail.com>
Message-ID: <CAGxFJbTE5Me5DkFrEHQZLm4c+w=3u6sXM3xG6Xm+JrUKkVPb2w@mail.gmail.com>

Probably better to post this on the r-sig-mixed-models list.

Cheers,
Bert



On Jan 7, 2018 12:20 PM, "Dominik ?epuli?" <dcepulic at gmail.com> wrote:

> Dear everybody!
>
> My fixed-effects-only model looks like this: glmer(Accuracy ~ C.RT*Group,
> data = da)
>
> C.RT is the reaction time variable, and Group is a categorical variable
> with 0 and 1 as values. I would like to specify that main intercept, Group
> intercept, C.RT slope and C.RT*Group slope vary across subjects and trials.
>
> All subjects have values in Group = 0 and in Group = 1. Trials are nested
> within Group because each trial belongs either to Group = 0 or Group = 1.
> How should I specify the model?
>
> My ideas were:
>
>    1. glmer(Accuracy ~ C.RT*Group + (C.RT*Group|subject) + (1+C.RT|trial),
>    data = da)
>
> or
>     2. glmer(Accuracy ~ C.RT*Group + (1+C.RT|Group:subject) +
> (1+C.RT|Group:trial), data = da)
>
> Here, Group:trial does not make much sense as trials are *per se* divided
> in Group 0 or Group 1.
>
> What is, in your opinion, the best way to specify the model that I want to
> test?
>
> Additionally, the difference between (1+C.RT|Group:subject) and
> (C.RT*Object|subject) is not clear to me. Can someone also shed some light
> here?
>
> Thanks,
> Dominik!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From esawiek at gmail.com  Mon Jan  8 04:13:09 2018
From: esawiek at gmail.com (Ek Esawi)
Date: Sun, 7 Jan 2018 22:13:09 -0500
Subject: [R] Replace NAs in split lists
Message-ID: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>

Hi all--

I stumbled on this problem online. I did not like the solution given
there which was a long UDF. I thought why cannot split and l/s apply
work here. My aim is to split the data frame, use l/sapply, make
changes on the split lists and combine the split lists to new data
frame with the desired changes/output.

The data frame shown below has a column named ID which has 2 variables
a and b; i want to replace the NAs on the Value column by 2, which is
the only numeric entry, for ID=a and by 5 for ID=b.

I worked out the solution but could not replace the results in the split lists.

Original dataframe , df1
  ID ID_2 Firist Value
1  a   aa   TRUE     2
2  a   ab  FALSE    NA
3  a   ac  FALSE    NA
4  b   aa   TRUE     5
5  b   ab  FALSE    NA
Sdf1
$a
ID ID_2 Firist Value
1  a   aa   TRUE     2
2  a   ab  FALSE    NA
3  a   ac  FALSE    NA
$b
  ID ID_2 Firist Value
4  b   aa   TRUE     5
5  b   ab  FALSE    NA
Desired results
ID ID_2 Firist Value
1  a   aa   TRUE    2
2  a   ab  FALSE    2
3  a   ac  FALSE    2

$b
  ID ID_2 Firist Value
4  b   aa   TRUE     5
5  b   ab  FALSE     5

My code

sdf <- split(df1,df$ID)
lapply(sdf, function(z) ifelse(is.na(z$Value),z$Value[!is.na(z$Value)],z$Value))
result:
$ a: num [1:3] 2 2 2
$ b: num [1:2] 5 5

How could I put these two lists back in the split data frame, sdf1?
Then I could use do.call to reassemble a data frame from the split
lists,

Thanks,
EK


From esawiek at gmail.com  Mon Jan  8 04:35:59 2018
From: esawiek at gmail.com (Ek Esawi)
Date: Sun, 7 Jan 2018 22:35:59 -0500
Subject: [R] Replace NAs in split lists
In-Reply-To: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>
References: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>
Message-ID: <CA+ZkTxs9+cGS7Yyazr5D1o+rX+YprOym79ERmaQdLq0hY6WvbA@mail.gmail.com>

I just came up with a solution right after i posted the question, but
i figured there must be a better and shorter one.than my solution
sdf1[[1]][1,4]<-lapplyresults[[1]]
sdf1[[2]][1,4]<-lapplyresults[[2]]

EK

On Sun, Jan 7, 2018 at 10:13 PM, Ek Esawi <esawiek at gmail.com> wrote:
> Hi all--
>
> I stumbled on this problem online. I did not like the solution given
> there which was a long UDF. I thought why cannot split and l/s apply
> work here. My aim is to split the data frame, use l/sapply, make
> changes on the split lists and combine the split lists to new data
> frame with the desired changes/output.
>
> The data frame shown below has a column named ID which has 2 variables
> a and b; i want to replace the NAs on the Value column by 2, which is
> the only numeric entry, for ID=a and by 5 for ID=b.
>
> I worked out the solution but could not replace the results in the split lists.
>
> Original dataframe , df1
>   ID ID_2 Firist Value
> 1  a   aa   TRUE     2
> 2  a   ab  FALSE    NA
> 3  a   ac  FALSE    NA
> 4  b   aa   TRUE     5
> 5  b   ab  FALSE    NA
> Sdf1
> $a
> ID ID_2 Firist Value
> 1  a   aa   TRUE     2
> 2  a   ab  FALSE    NA
> 3  a   ac  FALSE    NA
> $b
>   ID ID_2 Firist Value
> 4  b   aa   TRUE     5
> 5  b   ab  FALSE    NA
> Desired results
> ID ID_2 Firist Value
> 1  a   aa   TRUE    2
> 2  a   ab  FALSE    2
> 3  a   ac  FALSE    2
>
> $b
>   ID ID_2 Firist Value
> 4  b   aa   TRUE     5
> 5  b   ab  FALSE     5
>
> My code
>
> sdf <- split(df1,df$ID)
> lapply(sdf, function(z) ifelse(is.na(z$Value),z$Value[!is.na(z$Value)],z$Value))
> result:
> $ a: num [1:3] 2 2 2
> $ b: num [1:2] 5 5
>
> How could I put these two lists back in the split data frame, sdf1?
> Then I could use do.call to reassemble a data frame from the split
> lists,
>
> Thanks,
> EK


From petr.pikal at precheza.cz  Mon Jan  8 07:21:23 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 8 Jan 2018 06:21:23 +0000
Subject: [R] Replace NAs in split lists
In-Reply-To: <CA+ZkTxs9+cGS7Yyazr5D1o+rX+YprOym79ERmaQdLq0hY6WvbA@mail.gmail.com>
References: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>
 <CA+ZkTxs9+cGS7Yyazr5D1o+rX+YprOym79ERmaQdLq0hY6WvbA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD2CA1@SRVEXCHCM301.precheza.cz>

Hi

library(zoo)

has function na.locf, which probably can do what you want.

so something like (untested)

sdf1.fill<-lapply(sdf1, na.locf)
do.call(rbind, sdf1.fill)

Cheers.
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ek Esawi
> Sent: Monday, January 8, 2018 4:36 AM
> To: r-help at r-project.org
> Subject: Re: [R] Replace NAs in split lists
>
> I just came up with a solution right after i posted the question, but i figured
> there must be a better and shorter one.than my solution sdf1[[1]][1,4]<-
> lapplyresults[[1]]
> sdf1[[2]][1,4]<-lapplyresults[[2]]
>
> EK
>
> On Sun, Jan 7, 2018 at 10:13 PM, Ek Esawi <esawiek at gmail.com> wrote:
> > Hi all--
> >
> > I stumbled on this problem online. I did not like the solution given
> > there which was a long UDF. I thought why cannot split and l/s apply
> > work here. My aim is to split the data frame, use l/sapply, make
> > changes on the split lists and combine the split lists to new data
> > frame with the desired changes/output.
> >
> > The data frame shown below has a column named ID which has 2 variables
> > a and b; i want to replace the NAs on the Value column by 2, which is
> > the only numeric entry, for ID=a and by 5 for ID=b.
> >
> > I worked out the solution but could not replace the results in the split lists.
> >
> > Original dataframe , df1
> >   ID ID_2 Firist Value
> > 1  a   aa   TRUE     2
> > 2  a   ab  FALSE    NA
> > 3  a   ac  FALSE    NA
> > 4  b   aa   TRUE     5
> > 5  b   ab  FALSE    NA
> > Sdf1
> > $a
> > ID ID_2 Firist Value
> > 1  a   aa   TRUE     2
> > 2  a   ab  FALSE    NA
> > 3  a   ac  FALSE    NA
> > $b
> >   ID ID_2 Firist Value
> > 4  b   aa   TRUE     5
> > 5  b   ab  FALSE    NA
> > Desired results
> > ID ID_2 Firist Value
> > 1  a   aa   TRUE    2
> > 2  a   ab  FALSE    2
> > 3  a   ac  FALSE    2
> >
> > $b
> >   ID ID_2 Firist Value
> > 4  b   aa   TRUE     5
> > 5  b   ab  FALSE     5
> >
> > My code
> >
> > sdf <- split(df1,df$ID)
> > lapply(sdf, function(z)
> > ifelse(is.na(z$Value),z$Value[!is.na(z$Value)],z$Value))
> > result:
> > $ a: num [1:3] 2 2 2
> > $ b: num [1:2] 5 5
> >
> > How could I put these two lists back in the split data frame, sdf1?
> > Then I could use do.call to reassemble a data frame from the split
> > lists,
> >
> > Thanks,
> > EK
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jdnewmil at dcn.davis.ca.us  Mon Jan  8 07:36:47 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 07 Jan 2018 22:36:47 -0800
Subject: [R] Replace NAs in split lists
In-Reply-To: <CA+ZkTxs9+cGS7Yyazr5D1o+rX+YprOym79ERmaQdLq0hY6WvbA@mail.gmail.com>
References: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>
 <CA+ZkTxs9+cGS7Yyazr5D1o+rX+YprOym79ERmaQdLq0hY6WvbA@mail.gmail.com>
Message-ID: <6A4BD65A-AB19-44E1-B8E7-B4BE075578B7@dcn.davis.ca.us>

Why do you want to modify df1?

Why not just reassemble the parts as a new data frame and use that going forward in your calculations? That is generally the preferred approach in R so you can re-do your calculations easily if you find a mistake later. 
-- 
Sent from my phone. Please excuse my brevity.

On January 7, 2018 7:35:59 PM PST, Ek Esawi <esawiek at gmail.com> wrote:
>I just came up with a solution right after i posted the question, but
>i figured there must be a better and shorter one.than my solution
>sdf1[[1]][1,4]<-lapplyresults[[1]]
>sdf1[[2]][1,4]<-lapplyresults[[2]]
>
>EK
>
>On Sun, Jan 7, 2018 at 10:13 PM, Ek Esawi <esawiek at gmail.com> wrote:
>> Hi all--
>>
>> I stumbled on this problem online. I did not like the solution given
>> there which was a long UDF. I thought why cannot split and l/s apply
>> work here. My aim is to split the data frame, use l/sapply, make
>> changes on the split lists and combine the split lists to new data
>> frame with the desired changes/output.
>>
>> The data frame shown below has a column named ID which has 2
>variables
>> a and b; i want to replace the NAs on the Value column by 2, which is
>> the only numeric entry, for ID=a and by 5 for ID=b.
>>
>> I worked out the solution but could not replace the results in the
>split lists.
>>
>> Original dataframe , df1
>>   ID ID_2 Firist Value
>> 1  a   aa   TRUE     2
>> 2  a   ab  FALSE    NA
>> 3  a   ac  FALSE    NA
>> 4  b   aa   TRUE     5
>> 5  b   ab  FALSE    NA
>> Sdf1
>> $a
>> ID ID_2 Firist Value
>> 1  a   aa   TRUE     2
>> 2  a   ab  FALSE    NA
>> 3  a   ac  FALSE    NA
>> $b
>>   ID ID_2 Firist Value
>> 4  b   aa   TRUE     5
>> 5  b   ab  FALSE    NA
>> Desired results
>> ID ID_2 Firist Value
>> 1  a   aa   TRUE    2
>> 2  a   ab  FALSE    2
>> 3  a   ac  FALSE    2
>>
>> $b
>>   ID ID_2 Firist Value
>> 4  b   aa   TRUE     5
>> 5  b   ab  FALSE     5
>>
>> My code
>>
>> sdf <- split(df1,df$ID)
>> lapply(sdf, function(z)
>ifelse(is.na(z$Value),z$Value[!is.na(z$Value)],z$Value))
>> result:
>> $ a: num [1:3] 2 2 2
>> $ b: num [1:2] 5 5
>>
>> How could I put these two lists back in the split data frame, sdf1?
>> Then I could use do.call to reassemble a data frame from the split
>> lists,
>>
>> Thanks,
>> EK
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rahulsharm9 at gmail.com  Mon Jan  8 00:01:16 2018
From: rahulsharm9 at gmail.com (Rahul Sharm)
Date: Sun, 7 Jan 2018 15:01:16 -0800
Subject: [R] foverlaps data.table error
Message-ID: <CABL1_Mb5WpqS-q3=e1KKntoLcfJxTbPcROi_oC4MtFe=2p4iKw@mail.gmail.com>

Hello All
Have 2 tables
dt1:
start end kwh10min
2013-04-01 00:00:54 UTC 2013-04-01 01:00:10 UTC 0.05
2013-04-01 00:40:26 UTC 2013-04-01 00:50:00 UTC 0.1
2013-04-01 02:13:20 UTC 2013-04-01 04:53:42 UTC 0.15
2013-04-02 02:22:00 UTC 2013-04-01 04:33:12 UTC 0.2
2013-04-01 02:26:23 UTC 2013-04-01 04:05:12 UTC 0.25
2013-04-01 02:42:47 UTC 2013-04-01 04:34:33 UTC 0.3
2013-04-01 02:53:12 UTC 2013-04-03 05:27:05 UTC 0.35
2013-04-02 02:54:08 UTC 2013-04-02 05:31:15 UTC 0.4
2013-04-03 02:57:16 UTC 2013-04-03 05:29:32 UTC 0.45
dt2: start and end are 10 minute interval blocks spanning 2013-4-1 00:00:00
to 2013-04-04

I want to add the column 3 of dt1 to map as long as the start and end time
are within the 10 minute blocks and keep appending the columns

ideally the output should be
4/1/2013 0:00
4/1/2013 0:10
0.05 0

4/1/2013 0:10
4/1/2013 0:20
0.05 0

4/1/2013 0:20
4/1/2013 0:30
0.05 0

4/1/2013 0:30
4/1/2013 0:40
0.05 0

4/1/2013 0:40
4/1/2013 0:50
0.05 0.01

4/1/2013 0:50
4/1/2013 1:00
0.05 0.01
I tried
setkey(dums,start,end)
setkey(map,start,end)
foverlaps(map,dums,type="within",nomatch=0L)

I keep getting the error
Error in foverlaps(map, dums, type = "within", nomatch = 0L) :
  All entries in column start should be <= corresponding entries in column
end in data.table 'y'

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Jan  8 09:12:42 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 8 Jan 2018 00:12:42 -0800 (PST)
Subject: [R] Replace NAs in split lists
In-Reply-To: <6A4BD65A-AB19-44E1-B8E7-B4BE075578B7@dcn.davis.ca.us>
References: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>
 <CA+ZkTxs9+cGS7Yyazr5D1o+rX+YprOym79ERmaQdLq0hY6WvbA@mail.gmail.com>
 <6A4BD65A-AB19-44E1-B8E7-B4BE075578B7@dcn.davis.ca.us>
Message-ID: <alpine.BSF.2.00.1801080000200.20051@pedal.dcn.davis.ca.us>

Upon closer examination I see that you are not using the split version of 
df1 as I usually would, so here is a reproducible example:

#----
df1 <- read.table( text=
"ID ID_2 Firist Value
1  a   aa   TRUE     2
2  a   ab  FALSE    NA
3  a   ac  FALSE    NA
4  b   aa   TRUE     5
5  b   ab  FALSE    NA
", header=TRUE, as.is=TRUE )

sdf <- split( df1, df1$ID )
# note the extra [ 1 ] in case you have more than one non-NA value 
# per ID
sdf2 <- lapply( sdf
               , function( z ) {
                  z$Value <- ifelse( is.na( z$Value )
                                   , z$Value[ !is.na( z$Value ) ][ 1 ]
                                   , z$Value
                                   )
                  z
                 }
               )
df2 <- do.call( rbind, sdf2 )
df2
#>     ID ID_2 Firist Value
#> a.1  a   aa   TRUE     2
#> a.2  a   ab  FALSE     2
#> a.3  a   ac  FALSE     2
#> b.4  b   aa   TRUE     5
#> b.5  b   ab  FALSE     5

# or using tidyverse methods

library(dplyr)
#>
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#>
#>     filter, lag
#> The following objects are masked from 'package:base':
#>
#>     intersect, setdiff, setequal, union
df3 <- (   df1
        %>% group_by( ID )
        %>% do({
               mutate( .
                     , Value = ifelse( is.na( Value )
                                     , Value[ !is.na( Value ) ][ 1 ]
                                     , Value
                                     )
                     )
            })
        %>% ungroup
        )
df3
#> # A tibble: 5 x 4
#>   ID    ID_2  Firist Value
#>   <chr> <chr> <lgl>  <int>
#> 1 a     aa    T          2
#> 2 a     ab    F          2
#> 3 a     ac    F          2
#> 4 b     aa    T          5
#> 5 b     ab    F          5
#----

On Sun, 7 Jan 2018, Jeff Newmiller wrote:

> Why do you want to modify df1?
>
> Why not just reassemble the parts as a new data frame and use that going 
> forward in your calculations? That is generally the preferred approach 
> in R so you can re-do your calculations easily if you find a mistake 
> later.
> -- 
> Sent from my phone. Please excuse my brevity.
>
> On January 7, 2018 7:35:59 PM PST, Ek Esawi <esawiek at gmail.com> wrote:
>> I just came up with a solution right after i posted the question, but
>> i figured there must be a better and shorter one.than my solution
>> sdf1[[1]][1,4]<-lapplyresults[[1]]
>> sdf1[[2]][1,4]<-lapplyresults[[2]]
>>
>> EK
>>
>> On Sun, Jan 7, 2018 at 10:13 PM, Ek Esawi <esawiek at gmail.com> wrote:
>>> Hi all--
>>>
>>> I stumbled on this problem online. I did not like the solution given
>>> there which was a long UDF. I thought why cannot split and l/s apply
>>> work here. My aim is to split the data frame, use l/sapply, make
>>> changes on the split lists and combine the split lists to new data
>>> frame with the desired changes/output.
>>>
>>> The data frame shown below has a column named ID which has 2
>> variables
>>> a and b; i want to replace the NAs on the Value column by 2, which is
>>> the only numeric entry, for ID=a and by 5 for ID=b.
>>>
>>> I worked out the solution but could not replace the results in the
>> split lists.
>>>
>>> Original dataframe , df1
>>>   ID ID_2 Firist Value
>>> 1  a   aa   TRUE     2
>>> 2  a   ab  FALSE    NA
>>> 3  a   ac  FALSE    NA
>>> 4  b   aa   TRUE     5
>>> 5  b   ab  FALSE    NA
>>> Sdf1
>>> $a
>>> ID ID_2 Firist Value
>>> 1  a   aa   TRUE     2
>>> 2  a   ab  FALSE    NA
>>> 3  a   ac  FALSE    NA
>>> $b
>>>   ID ID_2 Firist Value
>>> 4  b   aa   TRUE     5
>>> 5  b   ab  FALSE    NA
>>> Desired results
>>> ID ID_2 Firist Value
>>> 1  a   aa   TRUE    2
>>> 2  a   ab  FALSE    2
>>> 3  a   ac  FALSE    2
>>>
>>> $b
>>>   ID ID_2 Firist Value
>>> 4  b   aa   TRUE     5
>>> 5  b   ab  FALSE     5
>>>
>>> My code
>>>
>>> sdf <- split(df1,df$ID)
>>> lapply(sdf, function(z)
>> ifelse(is.na(z$Value),z$Value[!is.na(z$Value)],z$Value))
>>> result:
>>> $ a: num [1:3] 2 2 2
>>> $ b: num [1:2] 5 5
>>>
>>> How could I put these two lists back in the split data frame, sdf1?
>>> Then I could use do.call to reassemble a data frame from the split
>>> lists,
>>>
>>> Thanks,
>>> EK
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Mon Jan  8 09:36:21 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 8 Jan 2018 00:36:21 -0800 (PST)
Subject: [R] foverlaps data.table error
In-Reply-To: <CABL1_Mb5WpqS-q3=e1KKntoLcfJxTbPcROi_oC4MtFe=2p4iKw@mail.gmail.com>
References: <CABL1_Mb5WpqS-q3=e1KKntoLcfJxTbPcROi_oC4MtFe=2p4iKw@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1801080018390.20051@pedal.dcn.davis.ca.us>

Disclaimer: I am not a user of this package.

1) This is a plain text mailing list... your email was mangled in transit. 
Send in plain text format to the R mailing lists to avoid confusing 
potential respondents.

2) It is bad form to post here and not point out that you have already 
asked elsewhere [1]. It looks like you already received a quality answer 
there. Failing to link to previous threads is almost as impolite as 
cross-posting to multiple mailing lists... read the Posting Guide for more 
on mailing list etiquette.

3) Note that there is a mailing list intended for questions about this 
package: the datatable-help mailing list.

[1] https://stackoverflow.com/questions/48141991/foverlaps-and-within-in-data-table

On Sun, 7 Jan 2018, Rahul Sharm wrote:

> Hello All
> Have 2 tables
> dt1:
> start end kwh10min
> 2013-04-01 00:00:54 UTC 2013-04-01 01:00:10 UTC 0.05
> 2013-04-01 00:40:26 UTC 2013-04-01 00:50:00 UTC 0.1
> 2013-04-01 02:13:20 UTC 2013-04-01 04:53:42 UTC 0.15
> 2013-04-02 02:22:00 UTC 2013-04-01 04:33:12 UTC 0.2
> 2013-04-01 02:26:23 UTC 2013-04-01 04:05:12 UTC 0.25
> 2013-04-01 02:42:47 UTC 2013-04-01 04:34:33 UTC 0.3
> 2013-04-01 02:53:12 UTC 2013-04-03 05:27:05 UTC 0.35
> 2013-04-02 02:54:08 UTC 2013-04-02 05:31:15 UTC 0.4
> 2013-04-03 02:57:16 UTC 2013-04-03 05:29:32 UTC 0.45
> dt2: start and end are 10 minute interval blocks spanning 2013-4-1 00:00:00
> to 2013-04-04
>
> I want to add the column 3 of dt1 to map as long as the start and end time
> are within the 10 minute blocks and keep appending the columns
>
> ideally the output should be
> 4/1/2013 0:00
> 4/1/2013 0:10
> 0.05 0
>
> 4/1/2013 0:10
> 4/1/2013 0:20
> 0.05 0
>
> 4/1/2013 0:20
> 4/1/2013 0:30
> 0.05 0
>
> 4/1/2013 0:30
> 4/1/2013 0:40
> 0.05 0
>
> 4/1/2013 0:40
> 4/1/2013 0:50
> 0.05 0.01
>
> 4/1/2013 0:50
> 4/1/2013 1:00
> 0.05 0.01
> I tried
> setkey(dums,start,end)
> setkey(map,start,end)
> foverlaps(map,dums,type="within",nomatch=0L)
>
> I keep getting the error
> Error in foverlaps(map, dums, type = "within", nomatch = 0L) :
>  All entries in column start should be <= corresponding entries in column
> end in data.table 'y'
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From petr.pikal at precheza.cz  Mon Jan  8 11:29:40 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 8 Jan 2018 10:29:40 +0000
Subject: [R] Replace NAs in split lists
In-Reply-To: <alpine.BSF.2.00.1801080000200.20051@pedal.dcn.davis.ca.us>
References: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>
 <CA+ZkTxs9+cGS7Yyazr5D1o+rX+YprOym79ERmaQdLq0hY6WvbA@mail.gmail.com>
 <6A4BD65A-AB19-44E1-B8E7-B4BE075578B7@dcn.davis.ca.us>
 <alpine.BSF.2.00.1801080000200.20051@pedal.dcn.davis.ca.us>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD2E37@SRVEXCHCM301.precheza.cz>

Hi

With the example, na.locf seems to be the easiest way.
> library(zoo)

> na.locf(df1)
  ID ID_2 Firist Value
1  a   aa   TRUE     2
2  a   ab  FALSE     2
3  a   ac  FALSE     2
4  b   aa   TRUE     5
5  b   ab  FALSE     5

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff
> Newmiller
> Sent: Monday, January 8, 2018 9:13 AM
> To: r-help at r-project.org; Ek Esawi <esawiek at gmail.com>
> Subject: Re: [R] Replace NAs in split lists
>
> Upon closer examination I see that you are not using the split version of
> df1 as I usually would, so here is a reproducible example:
>
> #----
> df1 <- read.table( text=
> "ID ID_2 Firist Value
> 1  a   aa   TRUE     2
> 2  a   ab  FALSE    NA
> 3  a   ac  FALSE    NA
> 4  b   aa   TRUE     5
> 5  b   ab  FALSE    NA
> ", header=TRUE, as.is=TRUE )
>
> sdf <- split( df1, df1$ID )
> # note the extra [ 1 ] in case you have more than one non-NA value # per ID
> sdf2 <- lapply( sdf
>                , function( z ) {
>                   z$Value <- ifelse( is.na( z$Value )
>                                    , z$Value[ !is.na( z$Value ) ][ 1 ]
>                                    , z$Value
>                                    )
>                   z
>                  }
>                )
> df2 <- do.call( rbind, sdf2 )
> df2
> #>     ID ID_2 Firist Value
> #> a.1  a   aa   TRUE     2
> #> a.2  a   ab  FALSE     2
> #> a.3  a   ac  FALSE     2
> #> b.4  b   aa   TRUE     5
> #> b.5  b   ab  FALSE     5
>
> # or using tidyverse methods
>
> library(dplyr)
> #>
> #> Attaching package: 'dplyr'
> #> The following objects are masked from 'package:stats':
> #>
> #>     filter, lag
> #> The following objects are masked from 'package:base':
> #>
> #>     intersect, setdiff, setequal, union
> df3 <- (   df1
>         %>% group_by( ID )
>         %>% do({
>                mutate( .
>                      , Value = ifelse( is.na( Value )
>                                      , Value[ !is.na( Value ) ][ 1 ]
>                                      , Value
>                                      )
>                      )
>             })
>         %>% ungroup
>         )
> df3
> #> # A tibble: 5 x 4
> #>   ID    ID_2  Firist Value
> #>   <chr> <chr> <lgl>  <int>
> #> 1 a     aa    T          2
> #> 2 a     ab    F          2
> #> 3 a     ac    F          2
> #> 4 b     aa    T          5
> #> 5 b     ab    F          5
> #----
>
> On Sun, 7 Jan 2018, Jeff Newmiller wrote:
>
> > Why do you want to modify df1?
> >
> > Why not just reassemble the parts as a new data frame and use that
> > going forward in your calculations? That is generally the preferred
> > approach in R so you can re-do your calculations easily if you find a
> > mistake later.
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > On January 7, 2018 7:35:59 PM PST, Ek Esawi <esawiek at gmail.com> wrote:
> >> I just came up with a solution right after i posted the question, but
> >> i figured there must be a better and shorter one.than my solution
> >> sdf1[[1]][1,4]<-lapplyresults[[1]]
> >> sdf1[[2]][1,4]<-lapplyresults[[2]]
> >>
> >> EK
> >>
> >> On Sun, Jan 7, 2018 at 10:13 PM, Ek Esawi <esawiek at gmail.com> wrote:
> >>> Hi all--
> >>>
> >>> I stumbled on this problem online. I did not like the solution given
> >>> there which was a long UDF. I thought why cannot split and l/s apply
> >>> work here. My aim is to split the data frame, use l/sapply, make
> >>> changes on the split lists and combine the split lists to new data
> >>> frame with the desired changes/output.
> >>>
> >>> The data frame shown below has a column named ID which has 2
> >> variables
> >>> a and b; i want to replace the NAs on the Value column by 2, which
> >>> is the only numeric entry, for ID=a and by 5 for ID=b.
> >>>
> >>> I worked out the solution but could not replace the results in the
> >> split lists.
> >>>
> >>> Original dataframe , df1
> >>>   ID ID_2 Firist Value
> >>> 1  a   aa   TRUE     2
> >>> 2  a   ab  FALSE    NA
> >>> 3  a   ac  FALSE    NA
> >>> 4  b   aa   TRUE     5
> >>> 5  b   ab  FALSE    NA
> >>> Sdf1
> >>> $a
> >>> ID ID_2 Firist Value
> >>> 1  a   aa   TRUE     2
> >>> 2  a   ab  FALSE    NA
> >>> 3  a   ac  FALSE    NA
> >>> $b
> >>>   ID ID_2 Firist Value
> >>> 4  b   aa   TRUE     5
> >>> 5  b   ab  FALSE    NA
> >>> Desired results
> >>> ID ID_2 Firist Value
> >>> 1  a   aa   TRUE    2
> >>> 2  a   ab  FALSE    2
> >>> 3  a   ac  FALSE    2
> >>>
> >>> $b
> >>>   ID ID_2 Firist Value
> >>> 4  b   aa   TRUE     5
> >>> 5  b   ab  FALSE     5
> >>>
> >>> My code
> >>>
> >>> sdf <- split(df1,df$ID)
> >>> lapply(sdf, function(z)
> >> ifelse(is.na(z$Value),z$Value[!is.na(z$Value)],z$Value))
> >>> result:
> >>> $ a: num [1:3] 2 2 2
> >>> $ b: num [1:2] 5 5
> >>>
> >>> How could I put these two lists back in the split data frame, sdf1?
> >>> Then I could use do.call to reassemble a data frame from the split
> >>> lists,
> >>>
> >>> Thanks,
> >>> EK
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From akhileshsingh.igkv at gmail.com  Sat Jan  6 14:19:49 2018
From: akhileshsingh.igkv at gmail.com (Akhilesh Singh)
Date: Sat, 6 Jan 2018 18:49:49 +0530
Subject: [R] Error occurring in "emmeans" package for the two data sets I
 used. Please help.
Message-ID: <CACLgfx1BtE5dd4ELTu6rHva48zJ0AGfJ1PzH7323_iqD9WGG=A@mail.gmail.com>

I am a Professor of Statistics at Indira Gandhi Krishi Vishwavidyalaya,
Raipur, India. While teaching in class about analysis of variance using R,
I was doing a one-way analysis for the two data-sets given below in the
R-class. I got a typical error in "emmeans" package, please help:

Data-set-1:
--------------
Medley and Clements (1998) investigated the impact of zinc contamination
(and other heavy metals) on the diversity of diatom species in the USA
Rocky Mountains. The diversity of diatoms (number of species) and degree of
zinc contamination (categorized as either of high, medium, low or natural
background level) were recorded from between four and six sampling stations
within each of six streams known to be polluted, as given below:

stream=c("Eagle", "Eagle", "Eagle", "Eagle", "Blue", "Blue",
         "Blue", "Blue", "Blue", "Blue", "Blue", "Snake", "Snake",
         "Snake", "Snake", "Snake", "Arkan", "Arkan", "Arkan",
         "Arkan", "Arkan", "Arkan", "Arkan", "Chalk", "Chalk",
         "Chalk", "Chalk", "Chalk", "Splat", "Splat", "Splat",
         "Splat", "Splat", "Splat")

zinc=c("BACK", "HIGH", "HIGH", "MED", "BACK", "HIGH", "BACK", "BACK",
       "HIGH", "MED", "MED", "BACK", "MED", "HIGH", "HIGH", "HIGH",
       "LOW", "LOW", "LOW", "LOW", "MED", "MED", "LOW", "LOW",
       "HIGH", "HIGH", "MED", "LOW", "BACK", "BACK", "MED", "LOW",
       "MED", "BACK")

diversity=c(2.27, 1.25, 1.15, 1.62, 1.7, 0.63, 2.05, 1.98, 1.04,
            2.19, 2.1, 2.2, 2.06, 1.9, 1.88, 0.85, 1.4, 2.18, 1.83,
            1.88, 2.02, 1.94, 2.1, 2.38, 1.43, 1.37, 1.75, 2.83,
            1.53, 0.76, 0.8, 1.66, 0.98, 1.89)

medley.clementis=data.frame(stream,zinc,diversity)

I did the one-way anova:
-------------------------------

medley.clementis.aov=with(medley.clementis, aov(diversity ~ zinc))

anova(medley.clementis)

Then, I tried to do post hoc analysis using "emmeans" package following
command:
-----------------------------------------------------------------------------------------------

emmeans::emmeans(medley.clementis.aov, "zinc")


This gives following error:
----------------------------------
Error in recover_data.call(fcall, delete.response(terms(object)),
object$na.action,  :
  object 'possibly.random' not found
Error in ref_grid(object, ...) :
  Perhaps a 'data' or 'params' argument is needed



Data-set-2:
---------------
Keough and Raimondi (1995) examined the effects of four biofilm types (SL:
sterile unfilmed substrate, NL: netted laboratory biofilms, UL: unnetted
laboratory biofilms and F: netted field biofilms) on the recruitment of
serpulid larvae. Substrates treated with one of the four biofilm types were
left in shallow marine waters for one week after which the number of newly
recruited serpulid worms were counted, as given below:

biofilm=c("SL", "SL", "SL", "SL", "SL", "SL", "SL", "UL", "UL", "UL",
          "UL", "UL", "UL", "UL", "NL", "NL", "NL", "NL", "NL", "NL",
          "NL", "F", "F", "F", "F", "F", "F", "F")

serpulid=c(61, 113, 123, 75, 75, 83, 95, 143, 81, 101, 155, 156, 193,
           163, 203, 159, 139, 161, 179, 97, 157, 128.5, 204.5,
           108.5, 116.5, 140.5, 160.5, 87.5)

keough.raimondi=data.frame(biofilm,serpulid)

Applied log-transformation:
-------------------------------------------
keough.raimondi.ln=transform(keough.raimondi, serpulid.ln=log(serpulid))

I did the one-way anova, with contrasts defined below:
------------------------------------------------------------------------
contrasts(keough.raimondi.ln$biofilm) <- cbind(c(0, 1, 0, -1),
                            c(2, -1, 0, -1), c(-1, -1, 3, -1))
keough.raimondi.ln$biofilm

keough.contr.list <- list(biofilm = list('NL vs UL' = 1,
              'F vs (NL & UL)' = 2, 'SL vs (F & NL & UL)' = 3))
keough.contr.list

One-way anova:
----------------------
keough.raimondi.ln.aov=with(keough.raimondi.ln, aov(serpulid.ln ~ biofilm))

summary(keough.raimondi.ln.aov,split=keough.contr.list)


Then, I tried to do post hoc analysis using "emmeans" package following
command:
-----------------------------------------------------------------------------------------------

emmeans(keough.raimondi.ln.aov, ~ biofilm)


This gives following error:
----------------------------------
Error in recover_data.call(fcall, delete.response(terms(object)),
object$na.action,  :
  object 'possibly.random' not found
Error in ref_grid(object, ...) :
  Perhaps a 'data' or 'params' argument is needed


Help Needed:
------------------
On many other data sets and data frame I successfully used "emmeans"
package using the help available in R.

But, for the above two data-sets, I consistently got the same error as
described above.

I do not know what is amiss. Where I am missing or whatever is wrong, I
request the entire R-team to help me to solve above problem. Thanking in
advance.


Dr. A.K. Singh
Professor and Head
Department of Agricultural Statistics
Indira Gandhi Krishi Vishwavidyalaya
Raipur-492012, Chhattisgarh, India
Mob: +918770625795
Email: akhileshsingh.igkv at gmail.com
WhatsApp: +919039202968

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Jan  8 15:19:40 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 08 Jan 2018 06:19:40 -0800
Subject: [R] Replace NAs in split lists
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD2E37@SRVEXCHCM301.precheza.cz>
References: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>
 <CA+ZkTxs9+cGS7Yyazr5D1o+rX+YprOym79ERmaQdLq0hY6WvbA@mail.gmail.com>
 <6A4BD65A-AB19-44E1-B8E7-B4BE075578B7@dcn.davis.ca.us>
 <alpine.BSF.2.00.1801080000200.20051@pedal.dcn.davis.ca.us>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD2E37@SRVEXCHCM301.precheza.cz>
Message-ID: <EAB5FC6C-AD76-439F-B346-7A89D8C3982D@dcn.davis.ca.us>

Yes, you are right if the IDs are always sequentially-adjacent and the first non-NA value appears in the first record for each ID.
-- 
Sent from my phone. Please excuse my brevity.

On January 8, 2018 2:29:40 AM PST, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>Hi
>
>With the example, na.locf seems to be the easiest way.
>> library(zoo)
>
>> na.locf(df1)
>  ID ID_2 Firist Value
>1  a   aa   TRUE     2
>2  a   ab  FALSE     2
>3  a   ac  FALSE     2
>4  b   aa   TRUE     5
>5  b   ab  FALSE     5
>
>Cheers
>Petr
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff
>> Newmiller
>> Sent: Monday, January 8, 2018 9:13 AM
>> To: r-help at r-project.org; Ek Esawi <esawiek at gmail.com>
>> Subject: Re: [R] Replace NAs in split lists
>>
>> Upon closer examination I see that you are not using the split
>version of
>> df1 as I usually would, so here is a reproducible example:
>>
>> #----
>> df1 <- read.table( text=
>> "ID ID_2 Firist Value
>> 1  a   aa   TRUE     2
>> 2  a   ab  FALSE    NA
>> 3  a   ac  FALSE    NA
>> 4  b   aa   TRUE     5
>> 5  b   ab  FALSE    NA
>> ", header=TRUE, as.is=TRUE )
>>
>> sdf <- split( df1, df1$ID )
>> # note the extra [ 1 ] in case you have more than one non-NA value #
>per ID
>> sdf2 <- lapply( sdf
>>                , function( z ) {
>>                   z$Value <- ifelse( is.na( z$Value )
>>                                    , z$Value[ !is.na( z$Value ) ][ 1
>]
>>                                    , z$Value
>>                                    )
>>                   z
>>                  }
>>                )
>> df2 <- do.call( rbind, sdf2 )
>> df2
>> #>     ID ID_2 Firist Value
>> #> a.1  a   aa   TRUE     2
>> #> a.2  a   ab  FALSE     2
>> #> a.3  a   ac  FALSE     2
>> #> b.4  b   aa   TRUE     5
>> #> b.5  b   ab  FALSE     5
>>
>> # or using tidyverse methods
>>
>> library(dplyr)
>> #>
>> #> Attaching package: 'dplyr'
>> #> The following objects are masked from 'package:stats':
>> #>
>> #>     filter, lag
>> #> The following objects are masked from 'package:base':
>> #>
>> #>     intersect, setdiff, setequal, union
>> df3 <- (   df1
>>         %>% group_by( ID )
>>         %>% do({
>>                mutate( .
>>                      , Value = ifelse( is.na( Value )
>>                                      , Value[ !is.na( Value ) ][ 1 ]
>>                                      , Value
>>                                      )
>>                      )
>>             })
>>         %>% ungroup
>>         )
>> df3
>> #> # A tibble: 5 x 4
>> #>   ID    ID_2  Firist Value
>> #>   <chr> <chr> <lgl>  <int>
>> #> 1 a     aa    T          2
>> #> 2 a     ab    F          2
>> #> 3 a     ac    F          2
>> #> 4 b     aa    T          5
>> #> 5 b     ab    F          5
>> #----
>>
>> On Sun, 7 Jan 2018, Jeff Newmiller wrote:
>>
>> > Why do you want to modify df1?
>> >
>> > Why not just reassemble the parts as a new data frame and use that
>> > going forward in your calculations? That is generally the preferred
>> > approach in R so you can re-do your calculations easily if you find
>a
>> > mistake later.
>> > --
>> > Sent from my phone. Please excuse my brevity.
>> >
>> > On January 7, 2018 7:35:59 PM PST, Ek Esawi <esawiek at gmail.com>
>wrote:
>> >> I just came up with a solution right after i posted the question,
>but
>> >> i figured there must be a better and shorter one.than my solution
>> >> sdf1[[1]][1,4]<-lapplyresults[[1]]
>> >> sdf1[[2]][1,4]<-lapplyresults[[2]]
>> >>
>> >> EK
>> >>
>> >> On Sun, Jan 7, 2018 at 10:13 PM, Ek Esawi <esawiek at gmail.com>
>wrote:
>> >>> Hi all--
>> >>>
>> >>> I stumbled on this problem online. I did not like the solution
>given
>> >>> there which was a long UDF. I thought why cannot split and l/s
>apply
>> >>> work here. My aim is to split the data frame, use l/sapply, make
>> >>> changes on the split lists and combine the split lists to new
>data
>> >>> frame with the desired changes/output.
>> >>>
>> >>> The data frame shown below has a column named ID which has 2
>> >> variables
>> >>> a and b; i want to replace the NAs on the Value column by 2,
>which
>> >>> is the only numeric entry, for ID=a and by 5 for ID=b.
>> >>>
>> >>> I worked out the solution but could not replace the results in
>the
>> >> split lists.
>> >>>
>> >>> Original dataframe , df1
>> >>>   ID ID_2 Firist Value
>> >>> 1  a   aa   TRUE     2
>> >>> 2  a   ab  FALSE    NA
>> >>> 3  a   ac  FALSE    NA
>> >>> 4  b   aa   TRUE     5
>> >>> 5  b   ab  FALSE    NA
>> >>> Sdf1
>> >>> $a
>> >>> ID ID_2 Firist Value
>> >>> 1  a   aa   TRUE     2
>> >>> 2  a   ab  FALSE    NA
>> >>> 3  a   ac  FALSE    NA
>> >>> $b
>> >>>   ID ID_2 Firist Value
>> >>> 4  b   aa   TRUE     5
>> >>> 5  b   ab  FALSE    NA
>> >>> Desired results
>> >>> ID ID_2 Firist Value
>> >>> 1  a   aa   TRUE    2
>> >>> 2  a   ab  FALSE    2
>> >>> 3  a   ac  FALSE    2
>> >>>
>> >>> $b
>> >>>   ID ID_2 Firist Value
>> >>> 4  b   aa   TRUE     5
>> >>> 5  b   ab  FALSE     5
>> >>>
>> >>> My code
>> >>>
>> >>> sdf <- split(df1,df$ID)
>> >>> lapply(sdf, function(z)
>> >> ifelse(is.na(z$Value),z$Value[!is.na(z$Value)],z$Value))
>> >>> result:
>> >>> $ a: num [1:3] 2 2 2
>> >>> $ b: num [1:2] 5 5
>> >>>
>> >>> How could I put these two lists back in the split data frame,
>sdf1?
>> >>> Then I could use do.call to reassemble a data frame from the
>split
>> >>> lists,
>> >>>
>> >>> Thanks,
>> >>> EK
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                        Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>________________________________
>Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>ur?eny pouze jeho adres?t?m.
>Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>kopie vyma?te ze sv?ho syst?mu.
>Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
>V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
>ze strany p??jemce s dodatkem ?i odchylkou.
>- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>zn?m?.
>
>This e-mail and any documents attached to it may be confidential and
>are intended only for its intended recipients.
>If you received this e-mail by mistake, please immediately inform its
>sender. Delete the contents of this e-mail with all attachments and its
>copies from your system.
>If you are not the intended recipient of this e-mail, you are not
>authorized to use, disseminate, copy or disclose this e-mail in any
>manner.
>The sender of this e-mail shall not be liable for any possible damage
>caused by modifications of the e-mail or by delay with transfer of the
>email.
>
>In case that this e-mail forms part of business dealings:
>- the sender reserves the right to end negotiations about entering into
>a contract in any time, for any reason, and without stating any
>reasoning.
>- if the e-mail contains an offer, the recipient is entitled to
>immediately accept such offer; The sender of this e-mail (offer)
>excludes any acceptance of the offer on the part of the recipient
>containing any amendment or variation.
>- the sender insists on that the respective contract is concluded only
>upon an express mutual agreement on all its aspects.
>- the sender of this e-mail informs that he/she is not authorized to
>enter into any contracts on behalf of the company except for cases in
>which he/she is expressly authorized to do so in writing, and such
>authorization or power of attorney is submitted to the recipient or the
>person represented by the recipient, or the existence of such
>authorization is known to the recipient of the person represented by
>the recipient.


From ericjberger at gmail.com  Mon Jan  8 15:41:33 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Mon, 8 Jan 2018 16:41:33 +0200
Subject: [R] Replace NAs in split lists
In-Reply-To: <EAB5FC6C-AD76-439F-B346-7A89D8C3982D@dcn.davis.ca.us>
References: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>
 <CA+ZkTxs9+cGS7Yyazr5D1o+rX+YprOym79ERmaQdLq0hY6WvbA@mail.gmail.com>
 <6A4BD65A-AB19-44E1-B8E7-B4BE075578B7@dcn.davis.ca.us>
 <alpine.BSF.2.00.1801080000200.20051@pedal.dcn.davis.ca.us>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD2E37@SRVEXCHCM301.precheza.cz>
 <EAB5FC6C-AD76-439F-B346-7A89D8C3982D@dcn.davis.ca.us>
Message-ID: <CAGgJW76V2d=AFKhY4uY5Nprm=niho9x0vxvKgcfmNa9jCQscng@mail.gmail.com>

You can enforce these assumptions by sorting on multiple columns, which
leads to

na.locf(df1[ order(df1$ID,df1$Value), ])



On Mon, Jan 8, 2018 at 4:19 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Yes, you are right if the IDs are always sequentially-adjacent and the
> first non-NA value appears in the first record for each ID.
> --
> Sent from my phone. Please excuse my brevity.
>
> On January 8, 2018 2:29:40 AM PST, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> >Hi
> >
> >With the example, na.locf seems to be the easiest way.
> >> library(zoo)
> >
> >> na.locf(df1)
> >  ID ID_2 Firist Value
> >1  a   aa   TRUE     2
> >2  a   ab  FALSE     2
> >3  a   ac  FALSE     2
> >4  b   aa   TRUE     5
> >5  b   ab  FALSE     5
> >
> >Cheers
> >Petr
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff
> >> Newmiller
> >> Sent: Monday, January 8, 2018 9:13 AM
> >> To: r-help at r-project.org; Ek Esawi <esawiek at gmail.com>
> >> Subject: Re: [R] Replace NAs in split lists
> >>
> >> Upon closer examination I see that you are not using the split
> >version of
> >> df1 as I usually would, so here is a reproducible example:
> >>
> >> #----
> >> df1 <- read.table( text=
> >> "ID ID_2 Firist Value
> >> 1  a   aa   TRUE     2
> >> 2  a   ab  FALSE    NA
> >> 3  a   ac  FALSE    NA
> >> 4  b   aa   TRUE     5
> >> 5  b   ab  FALSE    NA
> >> ", header=TRUE, as.is=TRUE )
> >>
> >> sdf <- split( df1, df1$ID )
> >> # note the extra [ 1 ] in case you have more than one non-NA value #
> >per ID
> >> sdf2 <- lapply( sdf
> >>                , function( z ) {
> >>                   z$Value <- ifelse( is.na( z$Value )
> >>                                    , z$Value[ !is.na( z$Value ) ][ 1
> >]
> >>                                    , z$Value
> >>                                    )
> >>                   z
> >>                  }
> >>                )
> >> df2 <- do.call( rbind, sdf2 )
> >> df2
> >> #>     ID ID_2 Firist Value
> >> #> a.1  a   aa   TRUE     2
> >> #> a.2  a   ab  FALSE     2
> >> #> a.3  a   ac  FALSE     2
> >> #> b.4  b   aa   TRUE     5
> >> #> b.5  b   ab  FALSE     5
> >>
> >> # or using tidyverse methods
> >>
> >> library(dplyr)
> >> #>
> >> #> Attaching package: 'dplyr'
> >> #> The following objects are masked from 'package:stats':
> >> #>
> >> #>     filter, lag
> >> #> The following objects are masked from 'package:base':
> >> #>
> >> #>     intersect, setdiff, setequal, union
> >> df3 <- (   df1
> >>         %>% group_by( ID )
> >>         %>% do({
> >>                mutate( .
> >>                      , Value = ifelse( is.na( Value )
> >>                                      , Value[ !is.na( Value ) ][ 1 ]
> >>                                      , Value
> >>                                      )
> >>                      )
> >>             })
> >>         %>% ungroup
> >>         )
> >> df3
> >> #> # A tibble: 5 x 4
> >> #>   ID    ID_2  Firist Value
> >> #>   <chr> <chr> <lgl>  <int>
> >> #> 1 a     aa    T          2
> >> #> 2 a     ab    F          2
> >> #> 3 a     ac    F          2
> >> #> 4 b     aa    T          5
> >> #> 5 b     ab    F          5
> >> #----
> >>
> >> On Sun, 7 Jan 2018, Jeff Newmiller wrote:
> >>
> >> > Why do you want to modify df1?
> >> >
> >> > Why not just reassemble the parts as a new data frame and use that
> >> > going forward in your calculations? That is generally the preferred
> >> > approach in R so you can re-do your calculations easily if you find
> >a
> >> > mistake later.
> >> > --
> >> > Sent from my phone. Please excuse my brevity.
> >> >
> >> > On January 7, 2018 7:35:59 PM PST, Ek Esawi <esawiek at gmail.com>
> >wrote:
> >> >> I just came up with a solution right after i posted the question,
> >but
> >> >> i figured there must be a better and shorter one.than my solution
> >> >> sdf1[[1]][1,4]<-lapplyresults[[1]]
> >> >> sdf1[[2]][1,4]<-lapplyresults[[2]]
> >> >>
> >> >> EK
> >> >>
> >> >> On Sun, Jan 7, 2018 at 10:13 PM, Ek Esawi <esawiek at gmail.com>
> >wrote:
> >> >>> Hi all--
> >> >>>
> >> >>> I stumbled on this problem online. I did not like the solution
> >given
> >> >>> there which was a long UDF. I thought why cannot split and l/s
> >apply
> >> >>> work here. My aim is to split the data frame, use l/sapply, make
> >> >>> changes on the split lists and combine the split lists to new
> >data
> >> >>> frame with the desired changes/output.
> >> >>>
> >> >>> The data frame shown below has a column named ID which has 2
> >> >> variables
> >> >>> a and b; i want to replace the NAs on the Value column by 2,
> >which
> >> >>> is the only numeric entry, for ID=a and by 5 for ID=b.
> >> >>>
> >> >>> I worked out the solution but could not replace the results in
> >the
> >> >> split lists.
> >> >>>
> >> >>> Original dataframe , df1
> >> >>>   ID ID_2 Firist Value
> >> >>> 1  a   aa   TRUE     2
> >> >>> 2  a   ab  FALSE    NA
> >> >>> 3  a   ac  FALSE    NA
> >> >>> 4  b   aa   TRUE     5
> >> >>> 5  b   ab  FALSE    NA
> >> >>> Sdf1
> >> >>> $a
> >> >>> ID ID_2 Firist Value
> >> >>> 1  a   aa   TRUE     2
> >> >>> 2  a   ab  FALSE    NA
> >> >>> 3  a   ac  FALSE    NA
> >> >>> $b
> >> >>>   ID ID_2 Firist Value
> >> >>> 4  b   aa   TRUE     5
> >> >>> 5  b   ab  FALSE    NA
> >> >>> Desired results
> >> >>> ID ID_2 Firist Value
> >> >>> 1  a   aa   TRUE    2
> >> >>> 2  a   ab  FALSE    2
> >> >>> 3  a   ac  FALSE    2
> >> >>>
> >> >>> $b
> >> >>>   ID ID_2 Firist Value
> >> >>> 4  b   aa   TRUE     5
> >> >>> 5  b   ab  FALSE     5
> >> >>>
> >> >>> My code
> >> >>>
> >> >>> sdf <- split(df1,df$ID)
> >> >>> lapply(sdf, function(z)
> >> >> ifelse(is.na(z$Value),z$Value[!is.na(z$Value)],z$Value))
> >> >>> result:
> >> >>> $ a: num [1:3] 2 2 2
> >> >>> $ b: num [1:2] 5 5
> >> >>>
> >> >>> How could I put these two lists back in the split data frame,
> >sdf1?
> >> >>> Then I could use do.call to reassemble a data frame from the
> >split
> >> >>> lists,
> >> >>>
> >> >>> Thanks,
> >> >>> EK
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >>
> >>
> >-----------------------------------------------------------
> ----------------
> >> Jeff Newmiller                        The     .....       .....  Go
> >Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >Go...
> >>                                        Live:   OO#.. Dead: OO#..
> >Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> >rocks...1k
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >________________________________
> >Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> >ur?eny pouze jeho adres?t?m.
> >Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> >neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> >kopie vyma?te ze sv?ho syst?mu.
> >Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> >email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> >Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> >modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> >V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> >- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> >smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> >- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> >p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
> >ze strany p??jemce s dodatkem ?i odchylkou.
> >- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> >v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> >- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> >spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> >zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> >adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> >p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> >zn?m?.
> >
> >This e-mail and any documents attached to it may be confidential and
> >are intended only for its intended recipients.
> >If you received this e-mail by mistake, please immediately inform its
> >sender. Delete the contents of this e-mail with all attachments and its
> >copies from your system.
> >If you are not the intended recipient of this e-mail, you are not
> >authorized to use, disseminate, copy or disclose this e-mail in any
> >manner.
> >The sender of this e-mail shall not be liable for any possible damage
> >caused by modifications of the e-mail or by delay with transfer of the
> >email.
> >
> >In case that this e-mail forms part of business dealings:
> >- the sender reserves the right to end negotiations about entering into
> >a contract in any time, for any reason, and without stating any
> >reasoning.
> >- if the e-mail contains an offer, the recipient is entitled to
> >immediately accept such offer; The sender of this e-mail (offer)
> >excludes any acceptance of the offer on the part of the recipient
> >containing any amendment or variation.
> >- the sender insists on that the respective contract is concluded only
> >upon an express mutual agreement on all its aspects.
> >- the sender of this e-mail informs that he/she is not authorized to
> >enter into any contracts on behalf of the company except for cases in
> >which he/she is expressly authorized to do so in writing, and such
> >authorization or power of attorney is submitted to the recipient or the
> >person represented by the recipient, or the existence of such
> >authorization is known to the recipient of the person represented by
> >the recipient.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Jan  8 16:45:26 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 08 Jan 2018 07:45:26 -0800
Subject: [R] Replace NAs in split lists
In-Reply-To: <CAGgJW76V2d=AFKhY4uY5Nprm=niho9x0vxvKgcfmNa9jCQscng@mail.gmail.com>
References: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>
 <CA+ZkTxs9+cGS7Yyazr5D1o+rX+YprOym79ERmaQdLq0hY6WvbA@mail.gmail.com>
 <6A4BD65A-AB19-44E1-B8E7-B4BE075578B7@dcn.davis.ca.us>
 <alpine.BSF.2.00.1801080000200.20051@pedal.dcn.davis.ca.us>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD2E37@SRVEXCHCM301.precheza.cz>
 <EAB5FC6C-AD76-439F-B346-7A89D8C3982D@dcn.davis.ca.us>
 <CAGgJW76V2d=AFKhY4uY5Nprm=niho9x0vxvKgcfmNa9jCQscng@mail.gmail.com>
Message-ID: <C41A81D1-605E-4F2B-973C-418266078C45@dcn.davis.ca.us>

"Enforce" is overstating it... results will differ if there are no non-NA values for a given ID, and there is a potential further discrepancy if there are multiple non-NA values. But these issues were not identified by the OP, so may not be relevant in their case. 
-- 
Sent from my phone. Please excuse my brevity.

On January 8, 2018 6:41:33 AM PST, Eric Berger <ericjberger at gmail.com> wrote:
>You can enforce these assumptions by sorting on multiple columns, which
>leads to
>
>na.locf(df1[ order(df1$ID,df1$Value), ])
>
>
>
>On Mon, Jan 8, 2018 at 4:19 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Yes, you are right if the IDs are always sequentially-adjacent and
>the
>> first non-NA value appears in the first record for each ID.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On January 8, 2018 2:29:40 AM PST, PIKAL Petr
><petr.pikal at precheza.cz>
>> wrote:
>> >Hi
>> >
>> >With the example, na.locf seems to be the easiest way.
>> >> library(zoo)
>> >
>> >> na.locf(df1)
>> >  ID ID_2 Firist Value
>> >1  a   aa   TRUE     2
>> >2  a   ab  FALSE     2
>> >3  a   ac  FALSE     2
>> >4  b   aa   TRUE     5
>> >5  b   ab  FALSE     5
>> >
>> >Cheers
>> >Petr
>> >
>> >> -----Original Message-----
>> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>Jeff
>> >> Newmiller
>> >> Sent: Monday, January 8, 2018 9:13 AM
>> >> To: r-help at r-project.org; Ek Esawi <esawiek at gmail.com>
>> >> Subject: Re: [R] Replace NAs in split lists
>> >>
>> >> Upon closer examination I see that you are not using the split
>> >version of
>> >> df1 as I usually would, so here is a reproducible example:
>> >>
>> >> #----
>> >> df1 <- read.table( text=
>> >> "ID ID_2 Firist Value
>> >> 1  a   aa   TRUE     2
>> >> 2  a   ab  FALSE    NA
>> >> 3  a   ac  FALSE    NA
>> >> 4  b   aa   TRUE     5
>> >> 5  b   ab  FALSE    NA
>> >> ", header=TRUE, as.is=TRUE )
>> >>
>> >> sdf <- split( df1, df1$ID )
>> >> # note the extra [ 1 ] in case you have more than one non-NA value
>#
>> >per ID
>> >> sdf2 <- lapply( sdf
>> >>                , function( z ) {
>> >>                   z$Value <- ifelse( is.na( z$Value )
>> >>                                    , z$Value[ !is.na( z$Value ) ][
>1
>> >]
>> >>                                    , z$Value
>> >>                                    )
>> >>                   z
>> >>                  }
>> >>                )
>> >> df2 <- do.call( rbind, sdf2 )
>> >> df2
>> >> #>     ID ID_2 Firist Value
>> >> #> a.1  a   aa   TRUE     2
>> >> #> a.2  a   ab  FALSE     2
>> >> #> a.3  a   ac  FALSE     2
>> >> #> b.4  b   aa   TRUE     5
>> >> #> b.5  b   ab  FALSE     5
>> >>
>> >> # or using tidyverse methods
>> >>
>> >> library(dplyr)
>> >> #>
>> >> #> Attaching package: 'dplyr'
>> >> #> The following objects are masked from 'package:stats':
>> >> #>
>> >> #>     filter, lag
>> >> #> The following objects are masked from 'package:base':
>> >> #>
>> >> #>     intersect, setdiff, setequal, union
>> >> df3 <- (   df1
>> >>         %>% group_by( ID )
>> >>         %>% do({
>> >>                mutate( .
>> >>                      , Value = ifelse( is.na( Value )
>> >>                                      , Value[ !is.na( Value ) ][ 1
>]
>> >>                                      , Value
>> >>                                      )
>> >>                      )
>> >>             })
>> >>         %>% ungroup
>> >>         )
>> >> df3
>> >> #> # A tibble: 5 x 4
>> >> #>   ID    ID_2  Firist Value
>> >> #>   <chr> <chr> <lgl>  <int>
>> >> #> 1 a     aa    T          2
>> >> #> 2 a     ab    F          2
>> >> #> 3 a     ac    F          2
>> >> #> 4 b     aa    T          5
>> >> #> 5 b     ab    F          5
>> >> #----
>> >>
>> >> On Sun, 7 Jan 2018, Jeff Newmiller wrote:
>> >>
>> >> > Why do you want to modify df1?
>> >> >
>> >> > Why not just reassemble the parts as a new data frame and use
>that
>> >> > going forward in your calculations? That is generally the
>preferred
>> >> > approach in R so you can re-do your calculations easily if you
>find
>> >a
>> >> > mistake later.
>> >> > --
>> >> > Sent from my phone. Please excuse my brevity.
>> >> >
>> >> > On January 7, 2018 7:35:59 PM PST, Ek Esawi <esawiek at gmail.com>
>> >wrote:
>> >> >> I just came up with a solution right after i posted the
>question,
>> >but
>> >> >> i figured there must be a better and shorter one.than my
>solution
>> >> >> sdf1[[1]][1,4]<-lapplyresults[[1]]
>> >> >> sdf1[[2]][1,4]<-lapplyresults[[2]]
>> >> >>
>> >> >> EK
>> >> >>
>> >> >> On Sun, Jan 7, 2018 at 10:13 PM, Ek Esawi <esawiek at gmail.com>
>> >wrote:
>> >> >>> Hi all--
>> >> >>>
>> >> >>> I stumbled on this problem online. I did not like the solution
>> >given
>> >> >>> there which was a long UDF. I thought why cannot split and l/s
>> >apply
>> >> >>> work here. My aim is to split the data frame, use l/sapply,
>make
>> >> >>> changes on the split lists and combine the split lists to new
>> >data
>> >> >>> frame with the desired changes/output.
>> >> >>>
>> >> >>> The data frame shown below has a column named ID which has 2
>> >> >> variables
>> >> >>> a and b; i want to replace the NAs on the Value column by 2,
>> >which
>> >> >>> is the only numeric entry, for ID=a and by 5 for ID=b.
>> >> >>>
>> >> >>> I worked out the solution but could not replace the results in
>> >the
>> >> >> split lists.
>> >> >>>
>> >> >>> Original dataframe , df1
>> >> >>>   ID ID_2 Firist Value
>> >> >>> 1  a   aa   TRUE     2
>> >> >>> 2  a   ab  FALSE    NA
>> >> >>> 3  a   ac  FALSE    NA
>> >> >>> 4  b   aa   TRUE     5
>> >> >>> 5  b   ab  FALSE    NA
>> >> >>> Sdf1
>> >> >>> $a
>> >> >>> ID ID_2 Firist Value
>> >> >>> 1  a   aa   TRUE     2
>> >> >>> 2  a   ab  FALSE    NA
>> >> >>> 3  a   ac  FALSE    NA
>> >> >>> $b
>> >> >>>   ID ID_2 Firist Value
>> >> >>> 4  b   aa   TRUE     5
>> >> >>> 5  b   ab  FALSE    NA
>> >> >>> Desired results
>> >> >>> ID ID_2 Firist Value
>> >> >>> 1  a   aa   TRUE    2
>> >> >>> 2  a   ab  FALSE    2
>> >> >>> 3  a   ac  FALSE    2
>> >> >>>
>> >> >>> $b
>> >> >>>   ID ID_2 Firist Value
>> >> >>> 4  b   aa   TRUE     5
>> >> >>> 5  b   ab  FALSE     5
>> >> >>>
>> >> >>> My code
>> >> >>>
>> >> >>> sdf <- split(df1,df$ID)
>> >> >>> lapply(sdf, function(z)
>> >> >> ifelse(is.na(z$Value),z$Value[!is.na(z$Value)],z$Value))
>> >> >>> result:
>> >> >>> $ a: num [1:3] 2 2 2
>> >> >>> $ b: num [1:2] 5 5
>> >> >>>
>> >> >>> How could I put these two lists back in the split data frame,
>> >sdf1?
>> >> >>> Then I could use do.call to reassemble a data frame from the
>> >split
>> >> >>> lists,
>> >> >>>
>> >> >>> Thanks,
>> >> >>> EK
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> PLEASE do read the posting guide
>> >> >> http://www.R-project.org/posting-guide.html
>> >> >> and provide commented, minimal, self-contained, reproducible
>code.
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible
>code.
>> >> >
>> >>
>> >>
>> >-----------------------------------------------------------
>> ----------------
>> >> Jeff Newmiller                        The     .....       ..... 
>Go
>> >Live...
>> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. 
>Live
>> >Go...
>> >>                                        Live:   OO#.. Dead: OO#..
>> >Playing
>> >> Research Engineer (Solar/Batteries            O.O#.       #.O#. 
>with
>> >> /Software/Embedded Controllers)               .OO#.       .OO#.
>> >rocks...1k
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> >________________________________
>> >Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>jsou
>> >ur?eny pouze jeho adres?t?m.
>> >Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> >neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a
>jeho
>> >kopie vyma?te ze sv?ho syst?mu.
>> >Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>> >email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> >Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>> >modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>> >
>> >V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> >- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> >smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> >- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>> >p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet?
>nab?dky
>> >ze strany p??jemce s dodatkem ?i odchylkou.
>> >- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> >v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> >- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> >spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>> >zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>> >adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>> >p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m
>zastoupen?
>> >zn?m?.
>> >
>> >This e-mail and any documents attached to it may be confidential and
>> >are intended only for its intended recipients.
>> >If you received this e-mail by mistake, please immediately inform
>its
>> >sender. Delete the contents of this e-mail with all attachments and
>its
>> >copies from your system.
>> >If you are not the intended recipient of this e-mail, you are not
>> >authorized to use, disseminate, copy or disclose this e-mail in any
>> >manner.
>> >The sender of this e-mail shall not be liable for any possible
>damage
>> >caused by modifications of the e-mail or by delay with transfer of
>the
>> >email.
>> >
>> >In case that this e-mail forms part of business dealings:
>> >- the sender reserves the right to end negotiations about entering
>into
>> >a contract in any time, for any reason, and without stating any
>> >reasoning.
>> >- if the e-mail contains an offer, the recipient is entitled to
>> >immediately accept such offer; The sender of this e-mail (offer)
>> >excludes any acceptance of the offer on the part of the recipient
>> >containing any amendment or variation.
>> >- the sender insists on that the respective contract is concluded
>only
>> >upon an express mutual agreement on all its aspects.
>> >- the sender of this e-mail informs that he/she is not authorized to
>> >enter into any contracts on behalf of the company except for cases
>in
>> >which he/she is expressly authorized to do so in writing, and such
>> >authorization or power of attorney is submitted to the recipient or
>the
>> >person represented by the recipient, or the existence of such
>> >authorization is known to the recipient of the person represented by
>> >the recipient.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From esawiek at gmail.com  Mon Jan  8 17:03:45 2018
From: esawiek at gmail.com (Ek Esawi)
Date: Mon, 8 Jan 2018 11:03:45 -0500
Subject: [R] Replace NAs in split lists
In-Reply-To: <alpine.BSF.2.00.1801080000200.20051@pedal.dcn.davis.ca.us>
References: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>
 <CA+ZkTxs9+cGS7Yyazr5D1o+rX+YprOym79ERmaQdLq0hY6WvbA@mail.gmail.com>
 <6A4BD65A-AB19-44E1-B8E7-B4BE075578B7@dcn.davis.ca.us>
 <alpine.BSF.2.00.1801080000200.20051@pedal.dcn.davis.ca.us>
Message-ID: <CA+ZkTxtuQT3r3E0DHA+-PVWX+AMXvGybzPxTADuNDbSFt=kUrQ@mail.gmail.com>

Thank you Jeff. Your code works, as usual , perfectly. I am just
wondering why if i put the whole code in one line, i get an error
message.
sdf2 <- lapply( sdf, function(z){z$Value
<-ifelse(is.na(z$Value),z$Value[!is.na(z$Value)][1],z$Value)z})
error. unexpected symbol in sdf2

Thanks again

EK


On Mon, Jan 8, 2018 at 3:12 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> Upon closer examination I see that you are not using the split version of
> df1 as I usually would, so here is a reproducible example:
>
> #----
> df1 <- read.table( text=
> "ID ID_2 Firist Value
> 1  a   aa   TRUE     2
> 2  a   ab  FALSE    NA
> 3  a   ac  FALSE    NA
> 4  b   aa   TRUE     5
> 5  b   ab  FALSE    NA
> ", header=TRUE, as.is=TRUE )
>
> sdf <- split( df1, df1$ID )
> # note the extra [ 1 ] in case you have more than one non-NA value # per ID
> sdf2 <- lapply( sdf
>               , function( z ) {
>                  z$Value <- ifelse( is.na( z$Value )
>                                   , z$Value[ !is.na( z$Value ) ][ 1 ]
>                                   , z$Value
>                                   )
>                  z
>                 }
>               )
> df2 <- do.call( rbind, sdf2 )
> df2
> #>     ID ID_2 Firist Value
> #> a.1  a   aa   TRUE     2
> #> a.2  a   ab  FALSE     2
> #> a.3  a   ac  FALSE     2
> #> b.4  b   aa   TRUE     5
> #> b.5  b   ab  FALSE     5
>
> # or using tidyverse methods
>
> library(dplyr)
> #>
> #> Attaching package: 'dplyr'
> #> The following objects are masked from 'package:stats':
> #>
> #>     filter, lag
> #> The following objects are masked from 'package:base':
> #>
> #>     intersect, setdiff, setequal, union
> df3 <- (   df1
>        %>% group_by( ID )
>        %>% do({
>               mutate( .
>                     , Value = ifelse( is.na( Value )
>                                     , Value[ !is.na( Value ) ][ 1 ]
>                                     , Value
>                                     )
>                     )
>            })
>        %>% ungroup
>        )
> df3
> #> # A tibble: 5 x 4
> #>   ID    ID_2  Firist Value
> #>   <chr> <chr> <lgl>  <int>
> #> 1 a     aa    T          2
> #> 2 a     ab    F          2
> #> 3 a     ac    F          2
> #> 4 b     aa    T          5
> #> 5 b     ab    F          5
> #----
>
>
> On Sun, 7 Jan 2018, Jeff Newmiller wrote:
>
>> Why do you want to modify df1?
>>
>> Why not just reassemble the parts as a new data frame and use that going
>> forward in your calculations? That is generally the preferred approach in R
>> so you can re-do your calculations easily if you find a mistake later.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On January 7, 2018 7:35:59 PM PST, Ek Esawi <esawiek at gmail.com> wrote:
>>>
>>> I just came up with a solution right after i posted the question, but
>>> i figured there must be a better and shorter one.than my solution
>>> sdf1[[1]][1,4]<-lapplyresults[[1]]
>>> sdf1[[2]][1,4]<-lapplyresults[[2]]
>>>
>>> EK
>>>
>>> On Sun, Jan 7, 2018 at 10:13 PM, Ek Esawi <esawiek at gmail.com> wrote:
>>>>
>>>> Hi all--
>>>>
>>>> I stumbled on this problem online. I did not like the solution given
>>>> there which was a long UDF. I thought why cannot split and l/s apply
>>>> work here. My aim is to split the data frame, use l/sapply, make
>>>> changes on the split lists and combine the split lists to new data
>>>> frame with the desired changes/output.
>>>>
>>>> The data frame shown below has a column named ID which has 2
>>>
>>> variables
>>>>
>>>> a and b; i want to replace the NAs on the Value column by 2, which is
>>>> the only numeric entry, for ID=a and by 5 for ID=b.
>>>>
>>>> I worked out the solution but could not replace the results in the
>>>
>>> split lists.
>>>>
>>>>
>>>> Original dataframe , df1
>>>>   ID ID_2 Firist Value
>>>> 1  a   aa   TRUE     2
>>>> 2  a   ab  FALSE    NA
>>>> 3  a   ac  FALSE    NA
>>>> 4  b   aa   TRUE     5
>>>> 5  b   ab  FALSE    NA
>>>> Sdf1
>>>> $a
>>>> ID ID_2 Firist Value
>>>> 1  a   aa   TRUE     2
>>>> 2  a   ab  FALSE    NA
>>>> 3  a   ac  FALSE    NA
>>>> $b
>>>>   ID ID_2 Firist Value
>>>> 4  b   aa   TRUE     5
>>>> 5  b   ab  FALSE    NA
>>>> Desired results
>>>> ID ID_2 Firist Value
>>>> 1  a   aa   TRUE    2
>>>> 2  a   ab  FALSE    2
>>>> 3  a   ac  FALSE    2
>>>>
>>>> $b
>>>>   ID ID_2 Firist Value
>>>> 4  b   aa   TRUE     5
>>>> 5  b   ab  FALSE     5
>>>>
>>>> My code
>>>>
>>>> sdf <- split(df1,df$ID)
>>>> lapply(sdf, function(z)
>>>
>>> ifelse(is.na(z$Value),z$Value[!is.na(z$Value)],z$Value))
>>>>
>>>> result:
>>>> $ a: num [1:3] 2 2 2
>>>> $ b: num [1:2] 5 5
>>>>
>>>> How could I put these two lists back in the split data frame, sdf1?
>>>> Then I could use do.call to reassemble a data frame from the split
>>>> lists,
>>>>
>>>> Thanks,
>>>> EK
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------


From jdnewmil at dcn.davis.ca.us  Mon Jan  8 17:44:30 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 08 Jan 2018 08:44:30 -0800
Subject: [R] Replace NAs in split lists
In-Reply-To: <CA+ZkTxtuQT3r3E0DHA+-PVWX+AMXvGybzPxTADuNDbSFt=kUrQ@mail.gmail.com>
References: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>
 <CA+ZkTxs9+cGS7Yyazr5D1o+rX+YprOym79ERmaQdLq0hY6WvbA@mail.gmail.com>
 <6A4BD65A-AB19-44E1-B8E7-B4BE075578B7@dcn.davis.ca.us>
 <alpine.BSF.2.00.1801080000200.20051@pedal.dcn.davis.ca.us>
 <CA+ZkTxtuQT3r3E0DHA+-PVWX+AMXvGybzPxTADuNDbSFt=kUrQ@mail.gmail.com>
Message-ID: <51D57C03-CDB4-4AD8-8DFA-E8B0894ED7A9@dcn.davis.ca.us>

I don't know. You seem to be posting in HTML so your code is mangled. Can you post plain text and use the reprex package to make sure it produces the errorin a clean R session? 
-- 
Sent from my phone. Please excuse my brevity.

On January 8, 2018 8:03:45 AM PST, Ek Esawi <esawiek at gmail.com> wrote:
>Thank you Jeff. Your code works, as usual , perfectly. I am just
>wondering why if i put the whole code in one line, i get an error
>message.
>sdf2 <- lapply( sdf, function(z){z$Value
><-ifelse(is.na(z$Value),z$Value[!is.na(z$Value)][1],z$Value)z})
>error. unexpected symbol in sdf2
>
>Thanks again
>
>EK
>
>
>On Mon, Jan 8, 2018 at 3:12 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> Upon closer examination I see that you are not using the split
>version of
>> df1 as I usually would, so here is a reproducible example:
>>
>> #----
>> df1 <- read.table( text=
>> "ID ID_2 Firist Value
>> 1  a   aa   TRUE     2
>> 2  a   ab  FALSE    NA
>> 3  a   ac  FALSE    NA
>> 4  b   aa   TRUE     5
>> 5  b   ab  FALSE    NA
>> ", header=TRUE, as.is=TRUE )
>>
>> sdf <- split( df1, df1$ID )
>> # note the extra [ 1 ] in case you have more than one non-NA value #
>per ID
>> sdf2 <- lapply( sdf
>>               , function( z ) {
>>                  z$Value <- ifelse( is.na( z$Value )
>>                                   , z$Value[ !is.na( z$Value ) ][ 1 ]
>>                                   , z$Value
>>                                   )
>>                  z
>>                 }
>>               )
>> df2 <- do.call( rbind, sdf2 )
>> df2
>> #>     ID ID_2 Firist Value
>> #> a.1  a   aa   TRUE     2
>> #> a.2  a   ab  FALSE     2
>> #> a.3  a   ac  FALSE     2
>> #> b.4  b   aa   TRUE     5
>> #> b.5  b   ab  FALSE     5
>>
>> # or using tidyverse methods
>>
>> library(dplyr)
>> #>
>> #> Attaching package: 'dplyr'
>> #> The following objects are masked from 'package:stats':
>> #>
>> #>     filter, lag
>> #> The following objects are masked from 'package:base':
>> #>
>> #>     intersect, setdiff, setequal, union
>> df3 <- (   df1
>>        %>% group_by( ID )
>>        %>% do({
>>               mutate( .
>>                     , Value = ifelse( is.na( Value )
>>                                     , Value[ !is.na( Value ) ][ 1 ]
>>                                     , Value
>>                                     )
>>                     )
>>            })
>>        %>% ungroup
>>        )
>> df3
>> #> # A tibble: 5 x 4
>> #>   ID    ID_2  Firist Value
>> #>   <chr> <chr> <lgl>  <int>
>> #> 1 a     aa    T          2
>> #> 2 a     ab    F          2
>> #> 3 a     ac    F          2
>> #> 4 b     aa    T          5
>> #> 5 b     ab    F          5
>> #----
>>
>>
>> On Sun, 7 Jan 2018, Jeff Newmiller wrote:
>>
>>> Why do you want to modify df1?
>>>
>>> Why not just reassemble the parts as a new data frame and use that
>going
>>> forward in your calculations? That is generally the preferred
>approach in R
>>> so you can re-do your calculations easily if you find a mistake
>later.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On January 7, 2018 7:35:59 PM PST, Ek Esawi <esawiek at gmail.com>
>wrote:
>>>>
>>>> I just came up with a solution right after i posted the question,
>but
>>>> i figured there must be a better and shorter one.than my solution
>>>> sdf1[[1]][1,4]<-lapplyresults[[1]]
>>>> sdf1[[2]][1,4]<-lapplyresults[[2]]
>>>>
>>>> EK
>>>>
>>>> On Sun, Jan 7, 2018 at 10:13 PM, Ek Esawi <esawiek at gmail.com>
>wrote:
>>>>>
>>>>> Hi all--
>>>>>
>>>>> I stumbled on this problem online. I did not like the solution
>given
>>>>> there which was a long UDF. I thought why cannot split and l/s
>apply
>>>>> work here. My aim is to split the data frame, use l/sapply, make
>>>>> changes on the split lists and combine the split lists to new data
>>>>> frame with the desired changes/output.
>>>>>
>>>>> The data frame shown below has a column named ID which has 2
>>>>
>>>> variables
>>>>>
>>>>> a and b; i want to replace the NAs on the Value column by 2, which
>is
>>>>> the only numeric entry, for ID=a and by 5 for ID=b.
>>>>>
>>>>> I worked out the solution but could not replace the results in the
>>>>
>>>> split lists.
>>>>>
>>>>>
>>>>> Original dataframe , df1
>>>>>   ID ID_2 Firist Value
>>>>> 1  a   aa   TRUE     2
>>>>> 2  a   ab  FALSE    NA
>>>>> 3  a   ac  FALSE    NA
>>>>> 4  b   aa   TRUE     5
>>>>> 5  b   ab  FALSE    NA
>>>>> Sdf1
>>>>> $a
>>>>> ID ID_2 Firist Value
>>>>> 1  a   aa   TRUE     2
>>>>> 2  a   ab  FALSE    NA
>>>>> 3  a   ac  FALSE    NA
>>>>> $b
>>>>>   ID ID_2 Firist Value
>>>>> 4  b   aa   TRUE     5
>>>>> 5  b   ab  FALSE    NA
>>>>> Desired results
>>>>> ID ID_2 Firist Value
>>>>> 1  a   aa   TRUE    2
>>>>> 2  a   ab  FALSE    2
>>>>> 3  a   ac  FALSE    2
>>>>>
>>>>> $b
>>>>>   ID ID_2 Firist Value
>>>>> 4  b   aa   TRUE     5
>>>>> 5  b   ab  FALSE     5
>>>>>
>>>>> My code
>>>>>
>>>>> sdf <- split(df1,df$ID)
>>>>> lapply(sdf, function(z)
>>>>
>>>> ifelse(is.na(z$Value),z$Value[!is.na(z$Value)],z$Value))
>>>>>
>>>>> result:
>>>>> $ a: num [1:3] 2 2 2
>>>>> $ b: num [1:2] 5 5
>>>>>
>>>>> How could I put these two lists back in the split data frame,
>sdf1?
>>>>> Then I could use do.call to reassemble a data frame from the split
>>>>> lists,
>>>>>
>>>>> Thanks,
>>>>> EK
>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------


From esawiek at gmail.com  Mon Jan  8 17:55:40 2018
From: esawiek at gmail.com (Ek Esawi)
Date: Mon, 8 Jan 2018 11:55:40 -0500
Subject: [R] Replace NAs in split lists
In-Reply-To: <51D57C03-CDB4-4AD8-8DFA-E8B0894ED7A9@dcn.davis.ca.us>
References: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>
 <CA+ZkTxs9+cGS7Yyazr5D1o+rX+YprOym79ERmaQdLq0hY6WvbA@mail.gmail.com>
 <6A4BD65A-AB19-44E1-B8E7-B4BE075578B7@dcn.davis.ca.us>
 <alpine.BSF.2.00.1801080000200.20051@pedal.dcn.davis.ca.us>
 <CA+ZkTxtuQT3r3E0DHA+-PVWX+AMXvGybzPxTADuNDbSFt=kUrQ@mail.gmail.com>
 <51D57C03-CDB4-4AD8-8DFA-E8B0894ED7A9@dcn.davis.ca.us>
Message-ID: <CA+ZkTxt4ErFfWGaG9uDkvu-M1iJ7ZNauF79AadBK9tj_1L9h0A@mail.gmail.com>

OPS!  Sorry i did indeed posted the code in HTML; should have known better.

ifelse(is.na(z$Value),z$Value[!is.na(z$Value)][1],z$Value)z})
error. unexpected symbol in sdf2

On Mon, Jan 8, 2018 at 11:44 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> I don't know. You seem to be posting in HTML so your code is mangled. Can you post plain text and use the reprex package to make sure it produces the errorin a clean R session?
> --
> Sent from my phone. Please excuse my brevity.
>
> On January 8, 2018 8:03:45 AM PST, Ek Esawi <esawiek at gmail.com> wrote:
>>Thank you Jeff. Your code works, as usual , perfectly. I am just
>>wondering why if i put the whole code in one line, i get an error
>>message.
>>sdf2 <- lapply( sdf, function(z){z$Value
>><-ifelse(is.na(z$Value),z$Value[!is.na(z$Value)][1],z$Value)z})
>>error. unexpected symbol in sdf2
>>
>>Thanks again
>>
>>EK
>>
>>
>>On Mon, Jan 8, 2018 at 3:12 AM, Jeff Newmiller
>><jdnewmil at dcn.davis.ca.us> wrote:
>>> Upon closer examination I see that you are not using the split
>>version of
>>> df1 as I usually would, so here is a reproducible example:
>>>
>>> #----
>>> df1 <- read.table( text=
>>> "ID ID_2 Firist Value
>>> 1  a   aa   TRUE     2
>>> 2  a   ab  FALSE    NA
>>> 3  a   ac  FALSE    NA
>>> 4  b   aa   TRUE     5
>>> 5  b   ab  FALSE    NA
>>> ", header=TRUE, as.is=TRUE )
>>>
>>> sdf <- split( df1, df1$ID )
>>> # note the extra [ 1 ] in case you have more than one non-NA value #
>>per ID
>>> sdf2 <- lapply( sdf
>>>               , function( z ) {
>>>                  z$Value <- ifelse( is.na( z$Value )
>>>                                   , z$Value[ !is.na( z$Value ) ][ 1 ]
>>>                                   , z$Value
>>>                                   )
>>>                  z
>>>                 }
>>>               )
>>> df2 <- do.call( rbind, sdf2 )
>>> df2
>>> #>     ID ID_2 Firist Value
>>> #> a.1  a   aa   TRUE     2
>>> #> a.2  a   ab  FALSE     2
>>> #> a.3  a   ac  FALSE     2
>>> #> b.4  b   aa   TRUE     5
>>> #> b.5  b   ab  FALSE     5
>>>
>>> # or using tidyverse methods
>>>
>>> library(dplyr)
>>> #>
>>> #> Attaching package: 'dplyr'
>>> #> The following objects are masked from 'package:stats':
>>> #>
>>> #>     filter, lag
>>> #> The following objects are masked from 'package:base':
>>> #>
>>> #>     intersect, setdiff, setequal, union
>>> df3 <- (   df1
>>>        %>% group_by( ID )
>>>        %>% do({
>>>               mutate( .
>>>                     , Value = ifelse( is.na( Value )
>>>                                     , Value[ !is.na( Value ) ][ 1 ]
>>>                                     , Value
>>>                                     )
>>>                     )
>>>            })
>>>        %>% ungroup
>>>        )
>>> df3
>>> #> # A tibble: 5 x 4
>>> #>   ID    ID_2  Firist Value
>>> #>   <chr> <chr> <lgl>  <int>
>>> #> 1 a     aa    T          2
>>> #> 2 a     ab    F          2
>>> #> 3 a     ac    F          2
>>> #> 4 b     aa    T          5
>>> #> 5 b     ab    F          5
>>> #----
>>>
>>>
>>> On Sun, 7 Jan 2018, Jeff Newmiller wrote:
>>>
>>>> Why do you want to modify df1?
>>>>
>>>> Why not just reassemble the parts as a new data frame and use that
>>going
>>>> forward in your calculations? That is generally the preferred
>>approach in R
>>>> so you can re-do your calculations easily if you find a mistake
>>later.
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On January 7, 2018 7:35:59 PM PST, Ek Esawi <esawiek at gmail.com>
>>wrote:
>>>>>
>>>>> I just came up with a solution right after i posted the question,
>>but
>>>>> i figured there must be a better and shorter one.than my solution
>>>>> sdf1[[1]][1,4]<-lapplyresults[[1]]
>>>>> sdf1[[2]][1,4]<-lapplyresults[[2]]
>>>>>
>>>>> EK
>>>>>
>>>>> On Sun, Jan 7, 2018 at 10:13 PM, Ek Esawi <esawiek at gmail.com>
>>wrote:
>>>>>>
>>>>>> Hi all--
>>>>>>
>>>>>> I stumbled on this problem online. I did not like the solution
>>given
>>>>>> there which was a long UDF. I thought why cannot split and l/s
>>apply
>>>>>> work here. My aim is to split the data frame, use l/sapply, make
>>>>>> changes on the split lists and combine the split lists to new data
>>>>>> frame with the desired changes/output.
>>>>>>
>>>>>> The data frame shown below has a column named ID which has 2
>>>>>
>>>>> variables
>>>>>>
>>>>>> a and b; i want to replace the NAs on the Value column by 2, which
>>is
>>>>>> the only numeric entry, for ID=a and by 5 for ID=b.
>>>>>>
>>>>>> I worked out the solution but could not replace the results in the
>>>>>
>>>>> split lists.
>>>>>>
>>>>>>
>>>>>> Original dataframe , df1
>>>>>>   ID ID_2 Firist Value
>>>>>> 1  a   aa   TRUE     2
>>>>>> 2  a   ab  FALSE    NA
>>>>>> 3  a   ac  FALSE    NA
>>>>>> 4  b   aa   TRUE     5
>>>>>> 5  b   ab  FALSE    NA
>>>>>> Sdf1
>>>>>> $a
>>>>>> ID ID_2 Firist Value
>>>>>> 1  a   aa   TRUE     2
>>>>>> 2  a   ab  FALSE    NA
>>>>>> 3  a   ac  FALSE    NA
>>>>>> $b
>>>>>>   ID ID_2 Firist Value
>>>>>> 4  b   aa   TRUE     5
>>>>>> 5  b   ab  FALSE    NA
>>>>>> Desired results
>>>>>> ID ID_2 Firist Value
>>>>>> 1  a   aa   TRUE    2
>>>>>> 2  a   ab  FALSE    2
>>>>>> 3  a   ac  FALSE    2
>>>>>>
>>>>>> $b
>>>>>>   ID ID_2 Firist Value
>>>>>> 4  b   aa   TRUE     5
>>>>>> 5  b   ab  FALSE     5
>>>>>>
>>>>>> My code
>>>>>>
>>>>>> sdf <- split(df1,df$ID)
>>>>>> lapply(sdf, function(z)
>>>>>
>>>>> ifelse(is.na(z$Value),z$Value[!is.na(z$Value)],z$Value))
>>>>>>
>>>>>> result:
>>>>>> $ a: num [1:3] 2 2 2
>>>>>> $ b: num [1:2] 5 5
>>>>>>
>>>>>> How could I put these two lists back in the split data frame,
>>sdf1?
>>>>>> Then I could use do.call to reassemble a data frame from the split
>>>>>> lists,
>>>>>>
>>>>>> Thanks,
>>>>>> EK
>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>Go...
>>>                                       Live:   OO#.. Dead: OO#..
>>Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>rocks...1k
>>>
>>---------------------------------------------------------------------------


From wdunlap at tibco.com  Mon Jan  8 18:07:53 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 8 Jan 2018 09:07:53 -0800
Subject: [R] Replace NAs in split lists
In-Reply-To: <CA+ZkTxt4ErFfWGaG9uDkvu-M1iJ7ZNauF79AadBK9tj_1L9h0A@mail.gmail.com>
References: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>
 <CA+ZkTxs9+cGS7Yyazr5D1o+rX+YprOym79ERmaQdLq0hY6WvbA@mail.gmail.com>
 <6A4BD65A-AB19-44E1-B8E7-B4BE075578B7@dcn.davis.ca.us>
 <alpine.BSF.2.00.1801080000200.20051@pedal.dcn.davis.ca.us>
 <CA+ZkTxtuQT3r3E0DHA+-PVWX+AMXvGybzPxTADuNDbSFt=kUrQ@mail.gmail.com>
 <51D57C03-CDB4-4AD8-8DFA-E8B0894ED7A9@dcn.davis.ca.us>
 <CA+ZkTxt4ErFfWGaG9uDkvu-M1iJ7ZNauF79AadBK9tj_1L9h0A@mail.gmail.com>
Message-ID: <CAF8bMcbdjnV0q19nGL5T2q7tS6QiSqpgjTBQSC_JU1ocF+0Huw@mail.gmail.com>

I don't get exactly that error message,
  > ifelse(is.na(z$Value),z$Value[!is.na(z$Value)][1],z$Value)z})
  Error: unexpected symbol in "ifelse(is.na(z$Value),z$Value[!is.na
(z$Value)][1],z$Value)z"
The 'symbol' in "unexpected symbol" refers to a "name" ('z' in this case).
The problem is usually at the end of the code snippet shown in the error
message as in
  > f(a)b # missing newline or semicolon?
  Error: unexpected symbol in "f(a)b"
or
  > f(a b) # missing comma?
  Error: unexpected symbol in "f(a b"

You need a newline or semicolon between the end of 'ifelse(...)' and 'z' or
maybe
you don't want the z there at all.

After you fix that it will complain about the unmatched right brace and
parenthesis.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Jan 8, 2018 at 8:55 AM, Ek Esawi <esawiek at gmail.com> wrote:

> OPS!  Sorry i did indeed posted the code in HTML; should have known better.
>
> ifelse(is.na(z$Value),z$Value[!is.na(z$Value)][1],z$Value)z})
> error. unexpected symbol in sdf2
>
> On Mon, Jan 8, 2018 at 11:44 AM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
> > I don't know. You seem to be posting in HTML so your code is mangled.
> Can you post plain text and use the reprex package to make sure it produces
> the errorin a clean R session?
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > On January 8, 2018 8:03:45 AM PST, Ek Esawi <esawiek at gmail.com> wrote:
> >>Thank you Jeff. Your code works, as usual , perfectly. I am just
> >>wondering why if i put the whole code in one line, i get an error
> >>message.
> >>sdf2 <- lapply( sdf, function(z){z$Value
> >><-ifelse(is.na(z$Value),z$Value[!is.na(z$Value)][1],z$Value)z})
> >>error. unexpected symbol in sdf2
> >>
> >>Thanks again
> >>
> >>EK
> >>
> >>
> >>On Mon, Jan 8, 2018 at 3:12 AM, Jeff Newmiller
> >><jdnewmil at dcn.davis.ca.us> wrote:
> >>> Upon closer examination I see that you are not using the split
> >>version of
> >>> df1 as I usually would, so here is a reproducible example:
> >>>
> >>> #----
> >>> df1 <- read.table( text=
> >>> "ID ID_2 Firist Value
> >>> 1  a   aa   TRUE     2
> >>> 2  a   ab  FALSE    NA
> >>> 3  a   ac  FALSE    NA
> >>> 4  b   aa   TRUE     5
> >>> 5  b   ab  FALSE    NA
> >>> ", header=TRUE, as.is=TRUE )
> >>>
> >>> sdf <- split( df1, df1$ID )
> >>> # note the extra [ 1 ] in case you have more than one non-NA value #
> >>per ID
> >>> sdf2 <- lapply( sdf
> >>>               , function( z ) {
> >>>                  z$Value <- ifelse( is.na( z$Value )
> >>>                                   , z$Value[ !is.na( z$Value ) ][ 1 ]
> >>>                                   , z$Value
> >>>                                   )
> >>>                  z
> >>>                 }
> >>>               )
> >>> df2 <- do.call( rbind, sdf2 )
> >>> df2
> >>> #>     ID ID_2 Firist Value
> >>> #> a.1  a   aa   TRUE     2
> >>> #> a.2  a   ab  FALSE     2
> >>> #> a.3  a   ac  FALSE     2
> >>> #> b.4  b   aa   TRUE     5
> >>> #> b.5  b   ab  FALSE     5
> >>>
> >>> # or using tidyverse methods
> >>>
> >>> library(dplyr)
> >>> #>
> >>> #> Attaching package: 'dplyr'
> >>> #> The following objects are masked from 'package:stats':
> >>> #>
> >>> #>     filter, lag
> >>> #> The following objects are masked from 'package:base':
> >>> #>
> >>> #>     intersect, setdiff, setequal, union
> >>> df3 <- (   df1
> >>>        %>% group_by( ID )
> >>>        %>% do({
> >>>               mutate( .
> >>>                     , Value = ifelse( is.na( Value )
> >>>                                     , Value[ !is.na( Value ) ][ 1 ]
> >>>                                     , Value
> >>>                                     )
> >>>                     )
> >>>            })
> >>>        %>% ungroup
> >>>        )
> >>> df3
> >>> #> # A tibble: 5 x 4
> >>> #>   ID    ID_2  Firist Value
> >>> #>   <chr> <chr> <lgl>  <int>
> >>> #> 1 a     aa    T          2
> >>> #> 2 a     ab    F          2
> >>> #> 3 a     ac    F          2
> >>> #> 4 b     aa    T          5
> >>> #> 5 b     ab    F          5
> >>> #----
> >>>
> >>>
> >>> On Sun, 7 Jan 2018, Jeff Newmiller wrote:
> >>>
> >>>> Why do you want to modify df1?
> >>>>
> >>>> Why not just reassemble the parts as a new data frame and use that
> >>going
> >>>> forward in your calculations? That is generally the preferred
> >>approach in R
> >>>> so you can re-do your calculations easily if you find a mistake
> >>later.
> >>>> --
> >>>> Sent from my phone. Please excuse my brevity.
> >>>>
> >>>> On January 7, 2018 7:35:59 PM PST, Ek Esawi <esawiek at gmail.com>
> >>wrote:
> >>>>>
> >>>>> I just came up with a solution right after i posted the question,
> >>but
> >>>>> i figured there must be a better and shorter one.than my solution
> >>>>> sdf1[[1]][1,4]<-lapplyresults[[1]]
> >>>>> sdf1[[2]][1,4]<-lapplyresults[[2]]
> >>>>>
> >>>>> EK
> >>>>>
> >>>>> On Sun, Jan 7, 2018 at 10:13 PM, Ek Esawi <esawiek at gmail.com>
> >>wrote:
> >>>>>>
> >>>>>> Hi all--
> >>>>>>
> >>>>>> I stumbled on this problem online. I did not like the solution
> >>given
> >>>>>> there which was a long UDF. I thought why cannot split and l/s
> >>apply
> >>>>>> work here. My aim is to split the data frame, use l/sapply, make
> >>>>>> changes on the split lists and combine the split lists to new data
> >>>>>> frame with the desired changes/output.
> >>>>>>
> >>>>>> The data frame shown below has a column named ID which has 2
> >>>>>
> >>>>> variables
> >>>>>>
> >>>>>> a and b; i want to replace the NAs on the Value column by 2, which
> >>is
> >>>>>> the only numeric entry, for ID=a and by 5 for ID=b.
> >>>>>>
> >>>>>> I worked out the solution but could not replace the results in the
> >>>>>
> >>>>> split lists.
> >>>>>>
> >>>>>>
> >>>>>> Original dataframe , df1
> >>>>>>   ID ID_2 Firist Value
> >>>>>> 1  a   aa   TRUE     2
> >>>>>> 2  a   ab  FALSE    NA
> >>>>>> 3  a   ac  FALSE    NA
> >>>>>> 4  b   aa   TRUE     5
> >>>>>> 5  b   ab  FALSE    NA
> >>>>>> Sdf1
> >>>>>> $a
> >>>>>> ID ID_2 Firist Value
> >>>>>> 1  a   aa   TRUE     2
> >>>>>> 2  a   ab  FALSE    NA
> >>>>>> 3  a   ac  FALSE    NA
> >>>>>> $b
> >>>>>>   ID ID_2 Firist Value
> >>>>>> 4  b   aa   TRUE     5
> >>>>>> 5  b   ab  FALSE    NA
> >>>>>> Desired results
> >>>>>> ID ID_2 Firist Value
> >>>>>> 1  a   aa   TRUE    2
> >>>>>> 2  a   ab  FALSE    2
> >>>>>> 3  a   ac  FALSE    2
> >>>>>>
> >>>>>> $b
> >>>>>>   ID ID_2 Firist Value
> >>>>>> 4  b   aa   TRUE     5
> >>>>>> 5  b   ab  FALSE     5
> >>>>>>
> >>>>>> My code
> >>>>>>
> >>>>>> sdf <- split(df1,df$ID)
> >>>>>> lapply(sdf, function(z)
> >>>>>
> >>>>> ifelse(is.na(z$Value),z$Value[!is.na(z$Value)],z$Value))
> >>>>>>
> >>>>>> result:
> >>>>>> $ a: num [1:3] 2 2 2
> >>>>>> $ b: num [1:2] 5 5
> >>>>>>
> >>>>>> How could I put these two lists back in the split data frame,
> >>sdf1?
> >>>>>> Then I could use do.call to reassemble a data frame from the split
> >>>>>> lists,
> >>>>>>
> >>>>>> Thanks,
> >>>>>> EK
> >>>>>
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>
> >>----------------------------------------------------------
> -----------------
> >>> Jeff Newmiller                        The     .....       .....  Go
> >>Live...
> >>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >>Go...
> >>>                                       Live:   OO#.. Dead: OO#..
> >>Playing
> >>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >>> /Software/Embedded Controllers)               .OO#.       .OO#.
> >>rocks...1k
> >>>
> >>----------------------------------------------------------
> -----------------
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Mon Jan  8 17:19:47 2018
From: ruipbarradas at sapo.pt (ruipbarradas)
Date: Mon, 08 Jan 2018 16:19:47 +0000
Subject: [R] Replace NAs in split lists
Message-ID: <dp6wbn0ymcgeejm2uqlwkkqd.1515428387418@email.android.com>

Because you need to separate the instructions with a ; (semi-colon).
Hope this helps
Rui Barradas


Enviado a partir do meu smartphone Samsung Galaxy.-------- Mensagem original --------De: Ek Esawi <esawiek at gmail.com> Data: 08/01/2018  16:03  (GMT+00:00) Para: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>, r-help at r-project.org Assunto: Re: [R] Replace NAs in split lists 
Thank you Jeff. Your code works, as usual , perfectly. I am just
wondering why if i put the whole code in one line, i get an error
message.
sdf2 <- lapply( sdf, function(z){z$Value
<-ifelse(is.na(z$Value),z$Value[!is.na(z$Value)][1],z$Value)z})
error. unexpected symbol in sdf2

Thanks again

EK


On Mon, Jan 8, 2018 at 3:12 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> Upon closer examination I see that you are not using the split version of
> df1 as I usually would, so here is a reproducible example:
>
> #----
> df1 <- read.table( text=
> "ID ID_2 Firist Value
> 1? a?? aa?? TRUE???? 2
> 2? a?? ab? FALSE??? NA
> 3? a?? ac? FALSE??? NA
> 4? b?? aa?? TRUE???? 5
> 5? b?? ab? FALSE??? NA
> ", header=TRUE, as.is=TRUE )
>
> sdf <- split( df1, df1$ID )
> # note the extra [ 1 ] in case you have more than one non-NA value # per ID
> sdf2 <- lapply( sdf
>?????????????? , function( z ) {
>????????????????? z$Value <- ifelse( is.na( z$Value )
>?????????????????????????????????? , z$Value[ !is.na( z$Value ) ][ 1 ]
>?????????????????????????????????? , z$Value
>?????????????????????????????????? )
>????????????????? z
>???????????????? }
>?????????????? )
> df2 <- do.call( rbind, sdf2 )
> df2
> #>???? ID ID_2 Firist Value
> #> a.1? a?? aa?? TRUE???? 2
> #> a.2? a?? ab? FALSE???? 2
> #> a.3? a?? ac? FALSE???? 2
> #> b.4? b?? aa?? TRUE???? 5
> #> b.5? b?? ab? FALSE???? 5
>
> # or using tidyverse methods
>
> library(dplyr)
> #>
> #> Attaching package: 'dplyr'
> #> The following objects are masked from 'package:stats':
> #>
> #>???? filter, lag
> #> The following objects are masked from 'package:base':
> #>
> #>???? intersect, setdiff, setequal, union
> df3 <- (?? df1
>??????? %>% group_by( ID )
>??????? %>% do({
>?????????????? mutate( .
>???????????????????? , Value = ifelse( is.na( Value )
>???????????????????????????????????? , Value[ !is.na( Value ) ][ 1 ]
>???????????????????????????????????? , Value
>???????????????????????????????????? )
>???????????????????? )
>??????????? })
>??????? %>% ungroup
>??????? )
> df3
> #> # A tibble: 5 x 4
> #>?? ID??? ID_2? Firist Value
> #>?? <chr> <chr> <lgl>? <int>
> #> 1 a???? aa??? T????????? 2
> #> 2 a???? ab??? F????????? 2
> #> 3 a???? ac??? F????????? 2
> #> 4 b???? aa??? T????????? 5
> #> 5 b???? ab??? F????????? 5
> #----
>
>
> On Sun, 7 Jan 2018, Jeff Newmiller wrote:
>
>> Why do you want to modify df1?
>>
>> Why not just reassemble the parts as a new data frame and use that going
>> forward in your calculations? That is generally the preferred approach in R
>> so you can re-do your calculations easily if you find a mistake later.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On January 7, 2018 7:35:59 PM PST, Ek Esawi <esawiek at gmail.com> wrote:
>>>
>>> I just came up with a solution right after i posted the question, but
>>> i figured there must be a better and shorter one.than my solution
>>> sdf1[[1]][1,4]<-lapplyresults[[1]]
>>> sdf1[[2]][1,4]<-lapplyresults[[2]]
>>>
>>> EK
>>>
>>> On Sun, Jan 7, 2018 at 10:13 PM, Ek Esawi <esawiek at gmail.com> wrote:
>>>>
>>>> Hi all--
>>>>
>>>> I stumbled on this problem online. I did not like the solution given
>>>> there which was a long UDF. I thought why cannot split and l/s apply
>>>> work here. My aim is to split the data frame, use l/sapply, make
>>>> changes on the split lists and combine the split lists to new data
>>>> frame with the desired changes/output.
>>>>
>>>> The data frame shown below has a column named ID which has 2
>>>
>>> variables
>>>>
>>>> a and b; i want to replace the NAs on the Value column by 2, which is
>>>> the only numeric entry, for ID=a and by 5 for ID=b.
>>>>
>>>> I worked out the solution but could not replace the results in the
>>>
>>> split lists.
>>>>
>>>>
>>>> Original dataframe , df1
>>>>?? ID ID_2 Firist Value
>>>> 1? a?? aa?? TRUE???? 2
>>>> 2? a?? ab? FALSE??? NA
>>>> 3? a?? ac? FALSE??? NA
>>>> 4? b?? aa?? TRUE???? 5
>>>> 5? b?? ab? FALSE??? NA
>>>> Sdf1
>>>> $a
>>>> ID ID_2 Firist Value
>>>> 1? a?? aa?? TRUE???? 2
>>>> 2? a?? ab? FALSE??? NA
>>>> 3? a?? ac? FALSE??? NA
>>>> $b
>>>>?? ID ID_2 Firist Value
>>>> 4? b?? aa?? TRUE???? 5
>>>> 5? b?? ab? FALSE??? NA
>>>> Desired results
>>>> ID ID_2 Firist Value
>>>> 1? a?? aa?? TRUE??? 2
>>>> 2? a?? ab? FALSE??? 2
>>>> 3? a?? ac? FALSE??? 2
>>>>
>>>> $b
>>>>?? ID ID_2 Firist Value
>>>> 4? b?? aa?? TRUE???? 5
>>>> 5? b?? ab? FALSE???? 5
>>>>
>>>> My code
>>>>
>>>> sdf <- split(df1,df$ID)
>>>> lapply(sdf, function(z)
>>>
>>> ifelse(is.na(z$Value),z$Value[!is.na(z$Value)],z$Value))
>>>>
>>>> result:
>>>> $ a: num [1:3] 2 2 2
>>>> $ b: num [1:2] 5 5
>>>>
>>>> How could I put these two lists back in the split data frame, sdf1?
>>>> Then I could use do.call to reassemble a data frame from the split
>>>> lists,
>>>>
>>>> Thanks,
>>>> EK
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller??????????????????????? The???? .....?????? .....? Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>??????? Basics: ##.#.?????? ##.#.? Live Go...
>?????????????????????????????????????? Live:?? OO#.. Dead: OO#..? Playing
> Research Engineer (Solar/Batteries??????????? O.O#.?????? #.O#.? with
> /Software/Embedded Controllers)?????????????? .OO#.?????? .OO#.? rocks...1k
> ---------------------------------------------------------------------------

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From esawiek at gmail.com  Mon Jan  8 20:09:43 2018
From: esawiek at gmail.com (Ek Esawi)
Date: Mon, 8 Jan 2018 14:09:43 -0500
Subject: [R] Replace NAs in split lists
In-Reply-To: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>
References: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>
Message-ID: <CA+ZkTxt3yJTfweFhwWNti3mjPNqXEt3JRstWRhVgK6OvVykdEg@mail.gmail.com>

Thank you all. Now everything works. Happy 2018 and beyond
EK

On Sun, Jan 7, 2018 at 10:13 PM, Ek Esawi <esawiek at gmail.com> wrote:
> Hi all--
>
> I stumbled on this problem online. I did not like the solution given
> there which was a long UDF. I thought why cannot split and l/s apply
> work here. My aim is to split the data frame, use l/sapply, make
> changes on the split lists and combine the split lists to new data
> frame with the desired changes/output.
>
> The data frame shown below has a column named ID which has 2 variables
> a and b; i want to replace the NAs on the Value column by 2, which is
> the only numeric entry, for ID=a and by 5 for ID=b.
>
> I worked out the solution but could not replace the results in the split lists.
>
> Original dataframe , df1
>   ID ID_2 Firist Value
> 1  a   aa   TRUE     2
> 2  a   ab  FALSE    NA
> 3  a   ac  FALSE    NA
> 4  b   aa   TRUE     5
> 5  b   ab  FALSE    NA
> Sdf1
> $a
> ID ID_2 Firist Value
> 1  a   aa   TRUE     2
> 2  a   ab  FALSE    NA
> 3  a   ac  FALSE    NA
> $b
>   ID ID_2 Firist Value
> 4  b   aa   TRUE     5
> 5  b   ab  FALSE    NA
> Desired results
> ID ID_2 Firist Value
> 1  a   aa   TRUE    2
> 2  a   ab  FALSE    2
> 3  a   ac  FALSE    2
>
> $b
>   ID ID_2 Firist Value
> 4  b   aa   TRUE     5
> 5  b   ab  FALSE     5
>
> My code
>
> sdf <- split(df1,df$ID)
> lapply(sdf, function(z) ifelse(is.na(z$Value),z$Value[!is.na(z$Value)],z$Value))
> result:
> $ a: num [1:3] 2 2 2
> $ b: num [1:2] 5 5
>
> How could I put these two lists back in the split data frame, sdf1?
> Then I could use do.call to reassemble a data frame from the split
> lists,
>
> Thanks,
> EK


From romanolson at yonsei.ac.kr  Tue Jan  9 03:23:34 2018
From: romanolson at yonsei.ac.kr (Olson Roman)
Date: Tue, 9 Jan 2018 11:23:34 +0900
Subject: [R] No keyboard control in the R terminal
Message-ID: <9834AF3D-4DD8-40DC-88ED-B9E77A399DB6@yonsei.ac.kr>

Dear R Users,

There is no R keyboard control in my R terminal. Specifically, I can not use the up and down arrows, use autocomplete, or ?backspace? to delete. I am using R 3.3.3 on 
Linux <snip> 2.6.18-164.el5 #1 SMP Thu Sep 3 03:28:30 EDT 2009 x86_64 x86_64 x86_64 GNU/Linux

Is this an R bug?

Best,
-R

From petr.pikal at precheza.cz  Tue Jan  9 06:51:28 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 9 Jan 2018 05:51:28 +0000
Subject: [R] Replace NAs in split lists
In-Reply-To: <C41A81D1-605E-4F2B-973C-418266078C45@dcn.davis.ca.us>
References: <CA+ZkTxuJ8Yg3qrOu4aUzKYE8zbvwdQPg1FqrvvGhzYQxVptKOA@mail.gmail.com>
 <CA+ZkTxs9+cGS7Yyazr5D1o+rX+YprOym79ERmaQdLq0hY6WvbA@mail.gmail.com>
 <6A4BD65A-AB19-44E1-B8E7-B4BE075578B7@dcn.davis.ca.us>
 <alpine.BSF.2.00.1801080000200.20051@pedal.dcn.davis.ca.us>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD2E37@SRVEXCHCM301.precheza.cz>
 <EAB5FC6C-AD76-439F-B346-7A89D8C3982D@dcn.davis.ca.us>
 <CAGgJW76V2d=AFKhY4uY5Nprm=niho9x0vxvKgcfmNa9jCQscng@mail.gmail.com>
 <C41A81D1-605E-4F2B-973C-418266078C45@dcn.davis.ca.us>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD2F65@SRVEXCHCM301.precheza.cz>

Hi

Yes, that is why I mentioned "the example". Of course if there are missing values in other columns or data layout is different, na.locf could give undesired result.

However it is simple and works with data similar to the example.

Cheers
Petr

> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Monday, January 8, 2018 4:45 PM
> To: Eric Berger <ericjberger at gmail.com>
> Cc: PIKAL Petr <petr.pikal at precheza.cz>; r-help at r-project.org; Ek Esawi
> <esawiek at gmail.com>
> Subject: Re: [R] Replace NAs in split lists
>
> "Enforce" is overstating it... results will differ if there are no non-NA values for
> a given ID, and there is a potential further discrepancy if there are multiple
> non-NA values. But these issues were not identified by the OP, so may not be
> relevant in their case.
> --
> Sent from my phone. Please excuse my brevity.
>
> On January 8, 2018 6:41:33 AM PST, Eric Berger <ericjberger at gmail.com>
> wrote:
> >You can enforce these assumptions by sorting on multiple columns, which
> >leads to
> >
> >na.locf(df1[ order(df1$ID,df1$Value), ])
> >
> >
> >
> >On Mon, Jan 8, 2018 at 4:19 PM, Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> Yes, you are right if the IDs are always sequentially-adjacent and
> >the
> >> first non-NA value appears in the first record for each ID.
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On January 8, 2018 2:29:40 AM PST, PIKAL Petr
> ><petr.pikal at precheza.cz>
> >> wrote:
> >> >Hi
> >> >
> >> >With the example, na.locf seems to be the easiest way.
> >> >> library(zoo)
> >> >
> >> >> na.locf(df1)
> >> >  ID ID_2 Firist Value
> >> >1  a   aa   TRUE     2
> >> >2  a   ab  FALSE     2
> >> >3  a   ac  FALSE     2
> >> >4  b   aa   TRUE     5
> >> >5  b   ab  FALSE     5
> >> >
> >> >Cheers
> >> >Petr
> >> >
> >> >> -----Original Message-----
> >> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> >Jeff
> >> >> Newmiller
> >> >> Sent: Monday, January 8, 2018 9:13 AM
> >> >> To: r-help at r-project.org; Ek Esawi <esawiek at gmail.com>
> >> >> Subject: Re: [R] Replace NAs in split lists
> >> >>
> >> >> Upon closer examination I see that you are not using the split
> >> >version of
> >> >> df1 as I usually would, so here is a reproducible example:
> >> >>
> >> >> #----
> >> >> df1 <- read.table( text=
> >> >> "ID ID_2 Firist Value
> >> >> 1  a   aa   TRUE     2
> >> >> 2  a   ab  FALSE    NA
> >> >> 3  a   ac  FALSE    NA
> >> >> 4  b   aa   TRUE     5
> >> >> 5  b   ab  FALSE    NA
> >> >> ", header=TRUE, as.is=TRUE )
> >> >>
> >> >> sdf <- split( df1, df1$ID )
> >> >> # note the extra [ 1 ] in case you have more than one non-NA value
> >#
> >> >per ID
> >> >> sdf2 <- lapply( sdf
> >> >>                , function( z ) {
> >> >>                   z$Value <- ifelse( is.na( z$Value )
> >> >>                                    , z$Value[ !is.na( z$Value ) ][
> >1
> >> >]
> >> >>                                    , z$Value
> >> >>                                    )
> >> >>                   z
> >> >>                  }
> >> >>                )
> >> >> df2 <- do.call( rbind, sdf2 )
> >> >> df2
> >> >> #>     ID ID_2 Firist Value
> >> >> #> a.1  a   aa   TRUE     2
> >> >> #> a.2  a   ab  FALSE     2
> >> >> #> a.3  a   ac  FALSE     2
> >> >> #> b.4  b   aa   TRUE     5
> >> >> #> b.5  b   ab  FALSE     5
> >> >>
> >> >> # or using tidyverse methods
> >> >>
> >> >> library(dplyr)
> >> >> #>
> >> >> #> Attaching package: 'dplyr'
> >> >> #> The following objects are masked from 'package:stats':
> >> >> #>
> >> >> #>     filter, lag
> >> >> #> The following objects are masked from 'package:base':
> >> >> #>
> >> >> #>     intersect, setdiff, setequal, union
> >> >> df3 <- (   df1
> >> >>         %>% group_by( ID )
> >> >>         %>% do({
> >> >>                mutate( .
> >> >>                      , Value = ifelse( is.na( Value )
> >> >>                                      , Value[ !is.na( Value ) ][ 1
> >]
> >> >>                                      , Value
> >> >>                                      )
> >> >>                      )
> >> >>             })
> >> >>         %>% ungroup
> >> >>         )
> >> >> df3
> >> >> #> # A tibble: 5 x 4
> >> >> #>   ID    ID_2  Firist Value
> >> >> #>   <chr> <chr> <lgl>  <int>
> >> >> #> 1 a     aa    T          2
> >> >> #> 2 a     ab    F          2
> >> >> #> 3 a     ac    F          2
> >> >> #> 4 b     aa    T          5
> >> >> #> 5 b     ab    F          5
> >> >> #----
> >> >>
> >> >> On Sun, 7 Jan 2018, Jeff Newmiller wrote:
> >> >>
> >> >> > Why do you want to modify df1?
> >> >> >
> >> >> > Why not just reassemble the parts as a new data frame and use
> >that
> >> >> > going forward in your calculations? That is generally the
> >preferred
> >> >> > approach in R so you can re-do your calculations easily if you
> >find
> >> >a
> >> >> > mistake later.
> >> >> > --
> >> >> > Sent from my phone. Please excuse my brevity.
> >> >> >
> >> >> > On January 7, 2018 7:35:59 PM PST, Ek Esawi <esawiek at gmail.com>
> >> >wrote:
> >> >> >> I just came up with a solution right after i posted the
> >question,
> >> >but
> >> >> >> i figured there must be a better and shorter one.than my
> >solution
> >> >> >> sdf1[[1]][1,4]<-lapplyresults[[1]]
> >> >> >> sdf1[[2]][1,4]<-lapplyresults[[2]]
> >> >> >>
> >> >> >> EK
> >> >> >>
> >> >> >> On Sun, Jan 7, 2018 at 10:13 PM, Ek Esawi <esawiek at gmail.com>
> >> >wrote:
> >> >> >>> Hi all--
> >> >> >>>
> >> >> >>> I stumbled on this problem online. I did not like the solution
> >> >given
> >> >> >>> there which was a long UDF. I thought why cannot split and l/s
> >> >apply
> >> >> >>> work here. My aim is to split the data frame, use l/sapply,
> >make
> >> >> >>> changes on the split lists and combine the split lists to new
> >> >data
> >> >> >>> frame with the desired changes/output.
> >> >> >>>
> >> >> >>> The data frame shown below has a column named ID which has 2
> >> >> >> variables
> >> >> >>> a and b; i want to replace the NAs on the Value column by 2,
> >> >which
> >> >> >>> is the only numeric entry, for ID=a and by 5 for ID=b.
> >> >> >>>
> >> >> >>> I worked out the solution but could not replace the results in
> >> >the
> >> >> >> split lists.
> >> >> >>>
> >> >> >>> Original dataframe , df1
> >> >> >>>   ID ID_2 Firist Value
> >> >> >>> 1  a   aa   TRUE     2
> >> >> >>> 2  a   ab  FALSE    NA
> >> >> >>> 3  a   ac  FALSE    NA
> >> >> >>> 4  b   aa   TRUE     5
> >> >> >>> 5  b   ab  FALSE    NA
> >> >> >>> Sdf1
> >> >> >>> $a
> >> >> >>> ID ID_2 Firist Value
> >> >> >>> 1  a   aa   TRUE     2
> >> >> >>> 2  a   ab  FALSE    NA
> >> >> >>> 3  a   ac  FALSE    NA
> >> >> >>> $b
> >> >> >>>   ID ID_2 Firist Value
> >> >> >>> 4  b   aa   TRUE     5
> >> >> >>> 5  b   ab  FALSE    NA
> >> >> >>> Desired results
> >> >> >>> ID ID_2 Firist Value
> >> >> >>> 1  a   aa   TRUE    2
> >> >> >>> 2  a   ab  FALSE    2
> >> >> >>> 3  a   ac  FALSE    2
> >> >> >>>
> >> >> >>> $b
> >> >> >>>   ID ID_2 Firist Value
> >> >> >>> 4  b   aa   TRUE     5
> >> >> >>> 5  b   ab  FALSE     5
> >> >> >>>
> >> >> >>> My code
> >> >> >>>
> >> >> >>> sdf <- split(df1,df$ID)
> >> >> >>> lapply(sdf, function(z)
> >> >> >> ifelse(is.na(z$Value),z$Value[!is.na(z$Value)],z$Value))
> >> >> >>> result:
> >> >> >>> $ a: num [1:3] 2 2 2
> >> >> >>> $ b: num [1:2] 5 5
> >> >> >>>
> >> >> >>> How could I put these two lists back in the split data frame,
> >> >sdf1?
> >> >> >>> Then I could use do.call to reassemble a data frame from the
> >> >split
> >> >> >>> lists,
> >> >> >>>
> >> >> >>> Thanks,
> >> >> >>> EK
> >> >> >>
> >> >> >> ______________________________________________
> >> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >see
> >> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >> PLEASE do read the posting guide
> >> >> >> http://www.R-project.org/posting-guide.html
> >> >> >> and provide commented, minimal, self-contained, reproducible
> >code.
> >> >> >
> >> >> > ______________________________________________
> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >see
> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> > PLEASE do read the posting guide
> >> >> > http://www.R-project.org/posting-guide.html
> >> >> > and provide commented, minimal, self-contained, reproducible
> >code.
> >> >> >
> >> >>
> >> >>
> >> >-----------------------------------------------------------
> >> ----------------
> >> >> Jeff Newmiller                        The     .....       .....
> >Go
> >> >Live...
> >> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.
> >Live
> >> >Go...
> >> >>                                        Live:   OO#.. Dead: OO#..
> >> >Playing
> >> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.
> >with
> >> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> >> >rocks...1k
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> >________________________________
> >> >Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
> >jsou
> >> >ur?eny pouze jeho adres?t?m.
> >> >Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> >> >neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a
> >jeho
> >> >kopie vyma?te ze sv?ho syst?mu.
> >> >Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> >> >email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> >> >Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> >> >modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >> >
> >> >V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> >> >- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> >> >smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> >> >- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> >> >p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet?
> >nab?dky
> >> >ze strany p??jemce s dodatkem ?i odchylkou.
> >> >- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> >> >v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> >> >- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> >> >spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> >> >zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> >> >adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> >> >p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m
> >zastoupen?
> >> >zn?m?.
> >> >
> >> >This e-mail and any documents attached to it may be confidential and
> >> >are intended only for its intended recipients.
> >> >If you received this e-mail by mistake, please immediately inform
> >its
> >> >sender. Delete the contents of this e-mail with all attachments and
> >its
> >> >copies from your system.
> >> >If you are not the intended recipient of this e-mail, you are not
> >> >authorized to use, disseminate, copy or disclose this e-mail in any
> >> >manner.
> >> >The sender of this e-mail shall not be liable for any possible
> >damage
> >> >caused by modifications of the e-mail or by delay with transfer of
> >the
> >> >email.
> >> >
> >> >In case that this e-mail forms part of business dealings:
> >> >- the sender reserves the right to end negotiations about entering
> >into
> >> >a contract in any time, for any reason, and without stating any
> >> >reasoning.
> >> >- if the e-mail contains an offer, the recipient is entitled to
> >> >immediately accept such offer; The sender of this e-mail (offer)
> >> >excludes any acceptance of the offer on the part of the recipient
> >> >containing any amendment or variation.
> >> >- the sender insists on that the respective contract is concluded
> >only
> >> >upon an express mutual agreement on all its aspects.
> >> >- the sender of this e-mail informs that he/she is not authorized to
> >> >enter into any contracts on behalf of the company except for cases
> >in
> >> >which he/she is expressly authorized to do so in writing, and such
> >> >authorization or power of attorney is submitted to the recipient or
> >the
> >> >person represented by the recipient, or the existence of such
> >> >authorization is known to the recipient of the person represented by
> >> >the recipient.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html and provide commented, minimal, self-contained,
> >> reproducible code.
> >>

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jdnewmil at dcn.davis.ca.us  Tue Jan  9 07:07:06 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 08 Jan 2018 22:07:06 -0800
Subject: [R] No keyboard control in the R terminal
In-Reply-To: <9834AF3D-4DD8-40DC-88ED-B9E77A399DB6@yonsei.ac.kr>
References: <9834AF3D-4DD8-40DC-88ED-B9E77A399DB6@yonsei.ac.kr>
Message-ID: <391E2355-3406-4EB8-8C8E-9A44A91804BE@dcn.davis.ca.us>

Unlikely. My guess is you compiled it yourself without having readline development support installed where the configure script could find it.
-- 
Sent from my phone. Please excuse my brevity.

On January 8, 2018 6:23:34 PM PST, Olson Roman <romanolson at yonsei.ac.kr> wrote:
>Dear R Users,
>
>There is no R keyboard control in my R terminal. Specifically, I can
>not use the up and down arrows, use autocomplete, or ?backspace? to
>delete. I am using R 3.3.3 on 
>Linux <snip> 2.6.18-164.el5 #1 SMP Thu Sep 3 03:28:30 EDT 2009 x86_64
>x86_64 x86_64 GNU/Linux
>
>Is this an R bug?
>
>Best,
>-R
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sibylle.stoeckli at gmx.ch  Tue Jan  9 09:19:07 2018
From: sibylle.stoeckli at gmx.ch (=?iso-8859-1?Q?Sibylle_St=F6ckli?=)
Date: Tue, 9 Jan 2018 09:19:07 +0100
Subject: [R] barplot_add=TRUE
Message-ID: <6645F2A6-41FE-4962-8718-385B8C890CB2@gmx.ch>

Dear R users

aim
Barplot of insect trap catches (y variable trapcatch) at one specific station (variable FiBL_Hecke) from week 1-52 ( x variable week).
It works well using the function tapply (sum trapcatch per week, males and females not separated), however, I intend to separate the y variable trapcatch in males and females (variable m_w: m and w)

problem
I used the function "add" to merge two bar plots (males and females). Unfortunately the second barplot masks the first barplot.

question
Is there a function to "mathematically" add the values from both barplots with the aim the barplot presenting the total trap (males and females) catches per week?



Hecke<-trap[trap$station=="FiBL_Hecke",] # station = Hecke
m<-Hecke[Hecke$m_w=="m",] # male trap catches
w<-Hecke[Hecke$m_w=="w",] # female trap catches

barplot(m$trapcatch, ylab="Y", space=0.5, col=c("grey0"), ylim=c(0,450), las=2, cex.lab=0.9, cex.axis=0.9, cex.names=0.9)
barplot(w$trapcatch,space=0.5, add=TRUE, beside=FALSE, col=c("grey50"), xaxt="n", yaxt="n")

Thanks a lot
Sibylle
	[[alternative HTML version deleted]]


From Gerrit.Eichner at math.uni-giessen.de  Tue Jan  9 09:30:27 2018
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 9 Jan 2018 09:30:27 +0100
Subject: [R] barplot_add=TRUE
In-Reply-To: <6645F2A6-41FE-4962-8718-385B8C890CB2@gmx.ch>
References: <6645F2A6-41FE-4962-8718-385B8C890CB2@gmx.ch>
Message-ID: <3b9e0178-aa51-b545-9abe-60efc32234bc@math.uni-giessen.de>

Hi, Sibylle,

since you write '"mathematically" add', does

barplot(rbind(m$trapcatch, w$trapcatch))

do what you want (modulo layout details)?

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 09.01.2018 um 09:19 schrieb Sibylle St?ckli:
> Dear R users
> 
> aim
> Barplot of insect trap catches (y variable trapcatch) at one specific station (variable FiBL_Hecke) from week 1-52 ( x variable week).
> It works well using the function tapply (sum trapcatch per week, males and females not separated), however, I intend to separate the y variable trapcatch in males and females (variable m_w: m and w)
> 
> problem
> I used the function "add" to merge two bar plots (males and females). Unfortunately the second barplot masks the first barplot.
> 
> question
> Is there a function to "mathematically" add the values from both barplots with the aim the barplot presenting the total trap (males and females) catches per week?
> 
> 
> 
> Hecke<-trap[trap$station=="FiBL_Hecke",] # station = Hecke
> m<-Hecke[Hecke$m_w=="m",] # male trap catches
> w<-Hecke[Hecke$m_w=="w",] # female trap catches
> 
> barplot(m$trapcatch, ylab="Y", space=0.5, col=c("grey0"), ylim=c(0,450), las=2, cex.lab=0.9, cex.axis=0.9, cex.names=0.9)
> barplot(w$trapcatch,space=0.5, add=TRUE, beside=FALSE, col=c("grey50"), xaxt="n", yaxt="n")
> 
> Thanks a lot
> Sibylle
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r.turner at auckland.ac.nz  Mon Jan  8 22:44:05 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 9 Jan 2018 10:44:05 +1300
Subject: [R] [FORGED] Error occurring in "emmeans" package for the two
 data sets I used. Please help.
In-Reply-To: <CACLgfx1BtE5dd4ELTu6rHva48zJ0AGfJ1PzH7323_iqD9WGG=A@mail.gmail.com>
References: <CACLgfx1BtE5dd4ELTu6rHva48zJ0AGfJ1PzH7323_iqD9WGG=A@mail.gmail.com>
Message-ID: <3ab856eb-4d56-a2a9-9ea5-3bc9bb1a25e9@auckland.ac.nz>


On 07/01/18 02:19, Akhilesh Singh wrote:

> I am a Professor of Statistics at Indira Gandhi Krishi Vishwavidyalaya,
> Raipur, India. While teaching in class about analysis of variance using R,
> I was doing a one-way analysis for the two data-sets given below in the
> R-class. I got a typical error in "emmeans" package, please help:
> 
> Data-set-1:
> --------------
> Medley and Clements (1998) investigated the impact of zinc contamination
> (and other heavy metals) on the diversity of diatom species in the USA
> Rocky Mountains. The diversity of diatoms (number of species) and degree of
> zinc contamination (categorized as either of high, medium, low or natural
> background level) were recorded from between four and six sampling stations
> within each of six streams known to be polluted, as given below:
> 
> stream=c("Eagle", "Eagle", "Eagle", "Eagle", "Blue", "Blue",
>           "Blue", "Blue", "Blue", "Blue", "Blue", "Snake", "Snake",
>           "Snake", "Snake", "Snake", "Arkan", "Arkan", "Arkan",
>           "Arkan", "Arkan", "Arkan", "Arkan", "Chalk", "Chalk",
>           "Chalk", "Chalk", "Chalk", "Splat", "Splat", "Splat",
>           "Splat", "Splat", "Splat")
> 
> zinc=c("BACK", "HIGH", "HIGH", "MED", "BACK", "HIGH", "BACK", "BACK",
>         "HIGH", "MED", "MED", "BACK", "MED", "HIGH", "HIGH", "HIGH",
>         "LOW", "LOW", "LOW", "LOW", "MED", "MED", "LOW", "LOW",
>         "HIGH", "HIGH", "MED", "LOW", "BACK", "BACK", "MED", "LOW",
>         "MED", "BACK")
> 
> diversity=c(2.27, 1.25, 1.15, 1.62, 1.7, 0.63, 2.05, 1.98, 1.04,
>              2.19, 2.1, 2.2, 2.06, 1.9, 1.88, 0.85, 1.4, 2.18, 1.83,
>              1.88, 2.02, 1.94, 2.1, 2.38, 1.43, 1.37, 1.75, 2.83,
>              1.53, 0.76, 0.8, 1.66, 0.98, 1.89)
> 
> medley.clementis=data.frame(stream,zinc,diversity)
> 
> I did the one-way anova:
> -------------------------------
> 
> medley.clementis.aov=with(medley.clementis, aov(diversity ~ zinc))
> 
> anova(medley.clementis)
> 
> Then, I tried to do post hoc analysis using "emmeans" package following
> command:
> -----------------------------------------------------------------------------------------------
> 
> emmeans::emmeans(medley.clementis.aov, "zinc")
> 
> 
> This gives following error:
> ----------------------------------
> Error in recover_data.call(fcall, delete.response(terms(object)),
> object$na.action,  :
>    object 'possibly.random' not found
> Error in ref_grid(object, ...) :
>    Perhaps a 'data' or 'params' argument is needed
> 
> 
> 
> Data-set-2:
> ---------------
> Keough and Raimondi (1995) examined the effects of four biofilm types (SL:
> sterile unfilmed substrate, NL: netted laboratory biofilms, UL: unnetted
> laboratory biofilms and F: netted field biofilms) on the recruitment of
> serpulid larvae. Substrates treated with one of the four biofilm types were
> left in shallow marine waters for one week after which the number of newly
> recruited serpulid worms were counted, as given below:
> 
> biofilm=c("SL", "SL", "SL", "SL", "SL", "SL", "SL", "UL", "UL", "UL",
>            "UL", "UL", "UL", "UL", "NL", "NL", "NL", "NL", "NL", "NL",
>            "NL", "F", "F", "F", "F", "F", "F", "F")
> 
> serpulid=c(61, 113, 123, 75, 75, 83, 95, 143, 81, 101, 155, 156, 193,
>             163, 203, 159, 139, 161, 179, 97, 157, 128.5, 204.5,
>             108.5, 116.5, 140.5, 160.5, 87.5)
> 
> keough.raimondi=data.frame(biofilm,serpulid)
> 
> Applied log-transformation:
> -------------------------------------------
> keough.raimondi.ln=transform(keough.raimondi, serpulid.ln=log(serpulid))
> 
> I did the one-way anova, with contrasts defined below:
> ------------------------------------------------------------------------
> contrasts(keough.raimondi.ln$biofilm) <- cbind(c(0, 1, 0, -1),
>                              c(2, -1, 0, -1), c(-1, -1, 3, -1))
> keough.raimondi.ln$biofilm
> 
> keough.contr.list <- list(biofilm = list('NL vs UL' = 1,
>                'F vs (NL & UL)' = 2, 'SL vs (F & NL & UL)' = 3))
> keough.contr.list
> 
> One-way anova:
> ----------------------
> keough.raimondi.ln.aov=with(keough.raimondi.ln, aov(serpulid.ln ~ biofilm))
> 
> summary(keough.raimondi.ln.aov,split=keough.contr.list)
> 
> 
> Then, I tried to do post hoc analysis using "emmeans" package following
> command:
> -----------------------------------------------------------------------------------------------
> 
> emmeans(keough.raimondi.ln.aov, ~ biofilm)
> 
> 
> This gives following error:
> ----------------------------------
> Error in recover_data.call(fcall, delete.response(terms(object)),
> object$na.action,  :
>    object 'possibly.random' not found
> Error in ref_grid(object, ...) :
>    Perhaps a 'data' or 'params' argument is needed
> 
> 
> Help Needed:
> ------------------
> On many other data sets and data frame I successfully used "emmeans"
> package using the help available in R.
> 
> But, for the above two data-sets, I consistently got the same error as
> described above.
> 
> I do not know what is amiss. Where I am missing or whatever is wrong, I
> request the entire R-team to help me to solve above problem.

Well, you don't need the *entire* R-team!!! It probably (in some sense) 
includes millions of people. :-)

> Thanking in advance.

Thanks for your thorough and well set out description of the problem.
Your reproducible examples were flawless.

I am not *completely* certain, but this looks to me like a bug in emmeans.

I have therefore taken the liberty of cc-ing this reply to Russell Lenth 
(the maintainer of emmeans) to get his take on the issue.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From drjimlemon at gmail.com  Tue Jan  9 09:55:43 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 9 Jan 2018 19:55:43 +1100
Subject: [R] barplot_add=TRUE
In-Reply-To: <6645F2A6-41FE-4962-8718-385B8C890CB2@gmx.ch>
References: <6645F2A6-41FE-4962-8718-385B8C890CB2@gmx.ch>
Message-ID: <CA+8X3fXkf3yEY7rxoQYo-Zye+Sg8bQTA5RVboN3VqPvpN2GJAQ@mail.gmail.com>

Hi Sibylle,
I might have the wrong idea, but does this:

hecke<-matrix(sample(1:40,104,TRUE),nrow=2)
library(plotrix)
barp(hecke,col=c("lightblue","pink"))
legend(43,40,c("M","F"),fill=c("lightblue","pink"))

do what you want? It is also possible to display this as a nested bar
plot showing males and females within total catch.

Jim


On Tue, Jan 9, 2018 at 7:19 PM, Sibylle St?ckli <sibylle.stoeckli at gmx.ch> wrote:
> Dear R users
>
> aim
> Barplot of insect trap catches (y variable trapcatch) at one specific station (variable FiBL_Hecke) from week 1-52 ( x variable week).
> It works well using the function tapply (sum trapcatch per week, males and females not separated), however, I intend to separate the y variable trapcatch in males and females (variable m_w: m and w)
>
> problem
> I used the function "add" to merge two bar plots (males and females). Unfortunately the second barplot masks the first barplot.
>
> question
> Is there a function to "mathematically" add the values from both barplots with the aim the barplot presenting the total trap (males and females) catches per week?
>
>
>
> Hecke<-trap[trap$station=="FiBL_Hecke",] # station = Hecke
> m<-Hecke[Hecke$m_w=="m",] # male trap catches
> w<-Hecke[Hecke$m_w=="w",] # female trap catches
>
> barplot(m$trapcatch, ylab="Y", space=0.5, col=c("grey0"), ylim=c(0,450), las=2, cex.lab=0.9, cex.axis=0.9, cex.names=0.9)
> barplot(w$trapcatch,space=0.5, add=TRUE, beside=FALSE, col=c("grey50"), xaxt="n", yaxt="n")
>
> Thanks a lot
> Sibylle
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From amrrs.data at gmail.com  Mon Jan  8 19:23:08 2018
From: amrrs.data at gmail.com (AMR RS)
Date: Mon, 8 Jan 2018 23:53:08 +0530
Subject: [R] [R-pkgs] 'coindeskr' to access coindesk API Bitcoin Price
	(Historic)
Message-ID: <CAE6U0BaV911HuMoBMX8z0rw9WciCh=4GBbFqfNh2crcXDiSfrw@mail.gmail.com>

Hello Rusers,

Introducing *coindeskr - *an R package to access coindesk API Bitcoin Price
Index (Including Historic Price).

https://github.com/amrrs/coindeskr

https://cran.r-project.org/package=coindeskr

Please share your feedback using it.

Regards,
Abdul

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From sibylle.stoeckli at gmx.ch  Tue Jan  9 10:24:04 2018
From: sibylle.stoeckli at gmx.ch (=?iso-8859-1?Q?Sibylle_St=F6ckli?=)
Date: Tue, 9 Jan 2018 10:24:04 +0100
Subject: [R] barplot_add=TRUE
In-Reply-To: <3b9e0178-aa51-b545-9abe-60efc32234bc@math.uni-giessen.de>
References: <6645F2A6-41FE-4962-8718-385B8C890CB2@gmx.ch>
 <3b9e0178-aa51-b545-9abe-60efc32234bc@math.uni-giessen.de>
Message-ID: <47BBA5AA-DC04-4C9C-9923-7649BD0AB405@gmx.ch>

Dear Gerrit

Thanks a lot. "rbind" seems to be the right function. Unfortunately there is a shift in the x-axis (see pdf). There are 52 trapcatch values each, m and w, but m$trapcatch and w$trapcatch are shifted up to x-value 60. 
The follow-up lines for temp and humidity are fine. 

Thanks
Sibylle






setwd("~/Desktop/DatenLogger2017")  #  am Mac sks
trap = read.delim("SWD_Trap_week-new.txt", na.strings="*", header=TRUE)  
climate = read.delim("Agrometeo_week-2017.txt", na.strings="*", header=TRUE)    
names(trap)
names(climate)


Hecke<-trap[trap$station=="FiBL_Hecke",]
m<-Hecke[Hecke$m_w=="m",]
w<-Hecke[Hecke$m_w=="w",]
par(mar=c(5,4,4,10))
barplot(rbind(m$trapcatch, w$trapcatch), ylim=c(0,350))
axis(1, 1:52)

par(new=T) 
plot(climate$Week,climate$Frick_Temp.mittel, type="n", axes=F, ylim=c(0,25), ylab="", xlab="", xaxt="n")
lines(climate$Week, climate$Frick_Temp.mittel, lty=2, lwd=2, col="blue")
axis(4,las=1, cex.axis=0.8, col="blue")
mtext(side=4, line=2.5, "Mittlere Temperatur (?C)", cex=0.8, col="blue")

par(new=T) 
plot(climate$Week,climate$Frick_Feuchte.mittel, type="n", axes=F, ylim=c(0,100), ylab="", xlab="", xaxt="n")
lines(climate$Week, climate$Frick_Feuchte.mittel, lty=2, lwd=2, col="darkgreen")
axis(4,las=1, line=5.5, cex.axis=0.8, col="darkgreen")
mtext(side=4, line=7.5, "Mittlere Feuchte (%)", cex=0.8, col="dark green")




Am 09.01.2018 um 09:30 schrieb Gerrit Eichner:

> Hi, Sibylle,
> 
> since you write '"mathematically" add', does
> 
> barplot(rbind(m$trapcatch, w$trapcatch))
> 
> do what you want (modulo layout details)?
> 
> Hth  --  Gerrit
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
> Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
> ---------------------------------------------------------------------
> 
> Am 09.01.2018 um 09:19 schrieb Sibylle St?ckli:
>> Dear R users
>> aim
>> Barplot of insect trap catches (y variable trapcatch) at one specific station (variable FiBL_Hecke) from week 1-52 ( x variable week).
>> It works well using the function tapply (sum trapcatch per week, males and females not separated), however, I intend to separate the y variable trapcatch in males and females (variable m_w: m and w)
>> problem
>> I used the function "add" to merge two bar plots (males and females). Unfortunately the second barplot masks the first barplot.
>> question
>> Is there a function to "mathematically" add the values from both barplots with the aim the barplot presenting the total trap (males and females) catches per week?
>> Hecke<-trap[trap$station=="FiBL_Hecke",] # station = Hecke
>> m<-Hecke[Hecke$m_w=="m",] # male trap catches
>> w<-Hecke[Hecke$m_w=="w",] # female trap catches
>> barplot(m$trapcatch, ylab="Y", space=0.5, col=c("grey0"), ylim=c(0,450), las=2, cex.lab=0.9, cex.axis=0.9, cex.names=0.9)
>> barplot(w$trapcatch,space=0.5, add=TRUE, beside=FALSE, col=c("grey50"), xaxt="n", yaxt="n")
>> Thanks a lot
>> Sibylle
>> 	[[alternative HTML version deleted]]
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Gerrit.Eichner at math.uni-giessen.de  Tue Jan  9 16:11:56 2018
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 9 Jan 2018 16:11:56 +0100
Subject: [R] barplot_add=TRUE
In-Reply-To: <47BBA5AA-DC04-4C9C-9923-7649BD0AB405@gmx.ch>
References: <6645F2A6-41FE-4962-8718-385B8C890CB2@gmx.ch>
 <3b9e0178-aa51-b545-9abe-60efc32234bc@math.uni-giessen.de>
 <47BBA5AA-DC04-4C9C-9923-7649BD0AB405@gmx.ch>
Message-ID: <779d2a6f-dea1-e451-970b-7943b5d3186b@math.uni-giessen.de>

Dear Sibylle!

Am 09.01.2018 um 10:24 schrieb Sibylle St?ckli:
> Dear Gerrit
> 
> Thanks a lot. "rbind" seems to be the right function. Unfortunately 
> there is a shift in the x-axis (see pdf). There are 52 trapcatch values 
> each, m and w, but m$trapcatch and w$trapcatch are shifted up to x-value 
> 60.
> The follow-up lines for temp and humidity are fine.

Hm, I'm not quite sure if you are asking another question here ... ;-)
But I assume you do.

However, without knowledge about the structure of Hecke or m,
respectively, in particular about their row numbers, it is impossible
to spot the cause of your "problem". I suggest you check the structure
of m:

str(m)

I suspect you'll see that the assumption of 52 trapcatch values is
somehow wrong.

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
---------------------------------------------------------------------
> 
> Thanks
> Sibylle
> 
> 
> 
> 
> 
> 
> 
> setwd("~/Desktop/DatenLogger2017") #? am Mac sks
> trap= read.delim("SWD_Trap_week-new.txt", na.strings="*", header=TRUE)
> climate= read.delim("Agrometeo_week-2017.txt", na.strings="*", header=TRUE)
> names(trap)
> names(climate)
> 
> 
> Hecke<-trap[trap$station=="FiBL_Hecke",]
> m<-Hecke[Hecke$m_w=="m",]
> w<-Hecke[Hecke$m_w=="w",]
> par(mar=c(5,4,4,10))
> barplot(rbind(m$trapcatch, w$trapcatch), ylim=c(0,350))
> axis(1, 1:52)
> 
> par(new=T)
> plot(climate$Week,climate$Frick_Temp.mittel, type="n", axes=F, 
> ylim=c(0,25), ylab="", xlab="", xaxt="n")
> lines(climate$Week, climate$Frick_Temp.mittel, lty=2, lwd=2, col="blue")
> axis(4,las=1, cex.axis=0.8, col="blue")
> mtext(side=4, line=2.5, "Mittlere Temperatur (?C)", cex=0.8, col="blue")
> 
> par(new=T)
> plot(climate$Week,climate$Frick_Feuchte.mittel, type="n", axes=F, 
> ylim=c(0,100), ylab="", xlab="", xaxt="n")
> lines(climate$Week, climate$Frick_Feuchte.mittel, lty=2, lwd=2, 
> col="darkgreen")
> axis(4,las=1, line=5.5, cex.axis=0.8, col="darkgreen")
> mtext(side=4, line=7.5, "Mittlere Feuchte (%)", cex=0.8, col="dark green")
> 
> 
> 
> 
> Am 09.01.2018 um 09:30 schrieb Gerrit Eichner:
> 
>> Hi, Sibylle,
>>
>> since you write '"mathematically" add', does
>>
>> barplot(rbind(m$trapcatch, w$trapcatch))
>>
>> do what you want (modulo layout details)?
>>
>> Hth ?-- ?Gerrit
>>
>> ---------------------------------------------------------------------
>> Dr. Gerrit Eichner ??????????????????Mathematical Institute, Room 212
>> gerrit.eichner at math.uni-giessen.de 
>> <mailto:gerrit.eichner at math.uni-giessen.de> ??Justus-Liebig-University 
>> Giessen
>> Tel: +49-(0)641-99-32104 ?????????Arndtstr. 2, 35392 Giessen, Germany
>> Fax: +49-(0)641-99-32109 http://www.uni-giessen.de/eichner
>> ---------------------------------------------------------------------
>>
>> Am 09.01.2018 um 09:19 schrieb Sibylle St?ckli:
>>> Dear R users
>>> aim
>>> Barplot of insect trap catches (y variable trapcatch) at one specific 
>>> station (variable FiBL_Hecke) from week 1-52 ( x variable week).
>>> It works well using the function tapply (sum trapcatch per week, 
>>> males and females not separated), however, I intend to separate the y 
>>> variable trapcatch in males and females (variable m_w: m and w)
>>> problem
>>> I used the function "add" to merge two bar plots (males and females). 
>>> Unfortunately the second barplot masks the first barplot.
>>> question
>>> Is there a function to "mathematically" add the values from both 
>>> barplots with the aim the barplot presenting the total trap (males 
>>> and females) catches per week?
>>> Hecke<-trap[trap$station=="FiBL_Hecke",] # station = Hecke
>>> m<-Hecke[Hecke$m_w=="m",] # male trap catches
>>> w<-Hecke[Hecke$m_w=="w",] # female trap catches
>>> barplot(m$trapcatch, ylab="Y", space=0.5, col=c("grey0"), 
>>> ylim=c(0,450), las=2, cex.lab=0.9, cex.axis=0.9, cex.names=0.9)
>>> barplot(w$trapcatch,space=0.5, add=TRUE, beside=FALSE, 
>>> col=c("grey50"), xaxt="n", yaxt="n")
>>> Thanks a lot
>>> Sibylle
>>> [[alternative HTML version deleted]]
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To 
>>> UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To 
>> UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From ashimkapoor at gmail.com  Tue Jan  9 16:18:34 2018
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Tue, 9 Jan 2018 20:48:34 +0530
Subject: [R] SpreadLevelPlot for more than one factor
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836754E17@FHSDB2D11-2.csu.mcmaster.ca>
References: <30617_1515301673_w0757qS5022949_CAC8=1erwSbShZ46SvbN_MGYEwDsV-15uGSriNxA6J_KcF0zUTw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836754E17@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAC8=1erFivyNhvqhnpS0Wj-KPBEUdH00NvFPN4NV2xwte+osDA@mail.gmail.com>

Dear Sir,

Many thanks for your reply.

I have a query.

I have a whole set of distributions which should be made normal /
homoscedastic. Take for instance the warpbreaks data set.

We have the following boxplots for the warpbreaks dataset:

a. boxplot(breaks ~ wool)
b. boxplot(breaks ~ tension)
c. boxplot(breaks ~ interaction(wool,tension))
d. boxplot(breaks ~ wool @ each level of tension)
e. boxplot(breaks ~ tension @ each level of wool)

Now should we not be making a-e normal and homoscedastic? Should we not
make a giant collection of boxplots from a-e and use the SpreadLevelPlot on
this entire collection?

A second query : (d) and (e) are the distribution of the simple effects of
factor wool and tension @ each level of the other. Is that correct?  Are
(a) and (b) the distribution of the main effect of wool and tension? Please
confirm.

Best Regards,
Ashim


On Sun, Jan 7, 2018 at 8:05 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Ashim,
>
> Try spreadLevelPlot(breaks ~ interaction(tension, wool), data=warpbreaks) .
>
> I hope this helps,
>  John
>
> -----------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socialsciences.mcmaster.ca/jfox/
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
> > Kapoor
> > Sent: Sunday, January 7, 2018 12:08 AM
> > To: r-help at r-project.org
> > Subject: [R] SpreadLevelPlot for more than one factor
> >
> > Dear All,
> >
> > I want a transformation which will make the spread of the response at
> all
> > combinations of  2 factors the same.
> >
> > See for example :
> >
> > boxplot(breaks ~ tension * wool, warpbreaks)
> >
> > The closest I  can do is :
> >
> > spreadLevelPlot(breaks ~tension , warpbreaks) spreadLevelPlot(breaks ~
> wool ,
> > warpbreaks)
> >
> > I want to do :
> >
> > spreadLevelPlot(breaks ~tension * wool, warpbreaks)
> >
> > But I get :
> >
> > > spreadLevelPlot(breaks ~tension * wool , warpbreaks)
> > Error in spreadLevelPlot.formula(breaks ~ tension * wool, warpbreaks) :
> >   right-hand side of model has more than one variable
> >
> > What is the corresponding appropriate function for 2 factors ?
> >
> > Many thanks,
> > Ashim
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From salvatore.s.mangiafico at gmail.com  Tue Jan  9 15:48:41 2018
From: salvatore.s.mangiafico at gmail.com (Sal Mangiafico)
Date: Tue, 9 Jan 2018 09:48:41 -0500
Subject: [R] [FORGED] Error occurring in "emmeans" package for the two
 data sets I used. Please help.
In-Reply-To: <3ab856eb-4d56-a2a9-9ea5-3bc9bb1a25e9@auckland.ac.nz>
References: <CACLgfx1BtE5dd4ELTu6rHva48zJ0AGfJ1PzH7323_iqD9WGG=A@mail.gmail.com>
 <3ab856eb-4d56-a2a9-9ea5-3bc9bb1a25e9@auckland.ac.nz>
Message-ID: <ea1e0624-8de1-fafb-e4c9-92ff232d86e0@gmail.com>

One way to avoid this error is to create the aov without using the with 
function, but instead use the data= option in the aov function.

That is,

medley2 = aov(diversity ~ zinc, data=medley.clementis)
emmeans::emmeans(medley2, "zinc")

You can see the difference in the calls:

medley2$call
medley.clementis.aov$call

This works for the other data set as well, e.g.

keough2 = aov(serpulid.ln ~ biofilm, data=keough.raimondi.ln)

~ Sal Mangiafico


On 1/8/2018 4:44 PM, Rolf Turner wrote:
>
> On 07/01/18 02:19, Akhilesh Singh wrote:
>
>> I am a Professor of Statistics at Indira Gandhi Krishi Vishwavidyalaya,
>> Raipur, India. While teaching in class about analysis of variance 
>> using R,
>> I was doing a one-way analysis for the two data-sets given below in the
>> R-class. I got a typical error in "emmeans" package, please help:
>>
>> Data-set-1:
>> --------------
>> Medley and Clements (1998) investigated the impact of zinc contamination
>> (and other heavy metals) on the diversity of diatom species in the USA
>> Rocky Mountains. The diversity of diatoms (number of species) and 
>> degree of
>> zinc contamination (categorized as either of high, medium, low or 
>> natural
>> background level) were recorded from between four and six sampling 
>> stations
>> within each of six streams known to be polluted, as given below:
>>
>> stream=c("Eagle", "Eagle", "Eagle", "Eagle", "Blue", "Blue",
>> ????????? "Blue", "Blue", "Blue", "Blue", "Blue", "Snake", "Snake",
>> ????????? "Snake", "Snake", "Snake", "Arkan", "Arkan", "Arkan",
>> ????????? "Arkan", "Arkan", "Arkan", "Arkan", "Chalk", "Chalk",
>> ????????? "Chalk", "Chalk", "Chalk", "Splat", "Splat", "Splat",
>> ????????? "Splat", "Splat", "Splat")
>>
>> zinc=c("BACK", "HIGH", "HIGH", "MED", "BACK", "HIGH", "BACK", "BACK",
>> ??????? "HIGH", "MED", "MED", "BACK", "MED", "HIGH", "HIGH", "HIGH",
>> ??????? "LOW", "LOW", "LOW", "LOW", "MED", "MED", "LOW", "LOW",
>> ??????? "HIGH", "HIGH", "MED", "LOW", "BACK", "BACK", "MED", "LOW",
>> ??????? "MED", "BACK")
>>
>> diversity=c(2.27, 1.25, 1.15, 1.62, 1.7, 0.63, 2.05, 1.98, 1.04,
>> ???????????? 2.19, 2.1, 2.2, 2.06, 1.9, 1.88, 0.85, 1.4, 2.18, 1.83,
>> ???????????? 1.88, 2.02, 1.94, 2.1, 2.38, 1.43, 1.37, 1.75, 2.83,
>> ???????????? 1.53, 0.76, 0.8, 1.66, 0.98, 1.89)
>>
>> medley.clementis=data.frame(stream,zinc,diversity)
>>
>> I did the one-way anova:
>> -------------------------------
>>
>> medley.clementis.aov=with(medley.clementis, aov(diversity ~ zinc))
>>
>> anova(medley.clementis)
>>
>> Then, I tried to do post hoc analysis using "emmeans" package following
>> command:
>> ----------------------------------------------------------------------------------------------- 
>>
>>
>> emmeans::emmeans(medley.clementis.aov, "zinc")
>>
>>
>> This gives following error:
>> ----------------------------------
>> Error in recover_data.call(fcall, delete.response(terms(object)),
>> object$na.action,? :
>> ?? object 'possibly.random' not found
>> Error in ref_grid(object, ...) :
>> ?? Perhaps a 'data' or 'params' argument is needed
>>
>>
>>
>> Data-set-2:
>> ---------------
>> Keough and Raimondi (1995) examined the effects of four biofilm types 
>> (SL:
>> sterile unfilmed substrate, NL: netted laboratory biofilms, UL: unnetted
>> laboratory biofilms and F: netted field biofilms) on the recruitment of
>> serpulid larvae. Substrates treated with one of the four biofilm 
>> types were
>> left in shallow marine waters for one week after which the number of 
>> newly
>> recruited serpulid worms were counted, as given below:
>>
>> biofilm=c("SL", "SL", "SL", "SL", "SL", "SL", "SL", "UL", "UL", "UL",
>> ?????????? "UL", "UL", "UL", "UL", "NL", "NL", "NL", "NL", "NL", "NL",
>> ?????????? "NL", "F", "F", "F", "F", "F", "F", "F")
>>
>> serpulid=c(61, 113, 123, 75, 75, 83, 95, 143, 81, 101, 155, 156, 193,
>> ??????????? 163, 203, 159, 139, 161, 179, 97, 157, 128.5, 204.5,
>> ??????????? 108.5, 116.5, 140.5, 160.5, 87.5)
>>
>> keough.raimondi=data.frame(biofilm,serpulid)
>>
>> Applied log-transformation:
>> -------------------------------------------
>> keough.raimondi.ln=transform(keough.raimondi, serpulid.ln=log(serpulid))
>>
>> I did the one-way anova, with contrasts defined below:
>> ------------------------------------------------------------------------
>> contrasts(keough.raimondi.ln$biofilm) <- cbind(c(0, 1, 0, -1),
>> ???????????????????????????? c(2, -1, 0, -1), c(-1, -1, 3, -1))
>> keough.raimondi.ln$biofilm
>>
>> keough.contr.list <- list(biofilm = list('NL vs UL' = 1,
>> ?????????????? 'F vs (NL & UL)' = 2, 'SL vs (F & NL & UL)' = 3))
>> keough.contr.list
>>
>> One-way anova:
>> ----------------------
>> keough.raimondi.ln.aov=with(keough.raimondi.ln, aov(serpulid.ln ~ 
>> biofilm))
>>
>> summary(keough.raimondi.ln.aov,split=keough.contr.list)
>>
>>
>> Then, I tried to do post hoc analysis using "emmeans" package following
>> command:
>> ----------------------------------------------------------------------------------------------- 
>>
>>
>> emmeans(keough.raimondi.ln.aov, ~ biofilm)
>>
>>
>> This gives following error:
>> ----------------------------------
>> Error in recover_data.call(fcall, delete.response(terms(object)),
>> object$na.action,? :
>> ?? object 'possibly.random' not found
>> Error in ref_grid(object, ...) :
>> ?? Perhaps a 'data' or 'params' argument is needed
>>
>>
>> Help Needed:
>> ------------------
>> On many other data sets and data frame I successfully used "emmeans"
>> package using the help available in R.
>>
>> But, for the above two data-sets, I consistently got the same error as
>> described above.
>>
>> I do not know what is amiss. Where I am missing or whatever is wrong, I
>> request the entire R-team to help me to solve above problem.
>
> Well, you don't need the *entire* R-team!!! It probably (in some 
> sense) includes millions of people. :-)
>
>> Thanking in advance.
>
> Thanks for your thorough and well set out description of the problem.
> Your reproducible examples were flawless.
>
> I am not *completely* certain, but this looks to me like a bug in 
> emmeans.
>
> I have therefore taken the liberty of cc-ing this reply to Russell 
> Lenth (the maintainer of emmeans) to get his take on the issue.
>
> cheers,
>
> Rolf Turner
>


	[[alternative HTML version deleted]]


From davidsmi at microsoft.com  Tue Jan  9 18:47:01 2018
From: davidsmi at microsoft.com (David Smith (CDA))
Date: Tue, 9 Jan 2018 17:47:01 +0000
Subject: [R] Revolutions blog: December 2017 roundup
Message-ID: <SN6PR2101MB09272A712D22BB1063EB7DAAC8100@SN6PR2101MB0927.namprd21.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests have
written about R at the Revolutions blog (http://blog.revolutionanalytics.com)
and every month I post a summary of articles from the previous month of
particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of December:

Hadley Wickham's Shiny app for making eggnog:
http://blog.revolutionanalytics.com/2017/12/merry-christmas-and-happy-new-year.html

Using R to analyze the vocal range of pop singers:
http://blog.revolutionanalytics.com/2017/12/because-its-friday-deck-the-halls.html

A tour of the data.table package from its creator, Matt Dowle:
http://blog.revolutionanalytics.com/2017/12/data-table-video.html

The European R Users Meeting (eRum) will be held in Budapest, May 14-18:
http://blog.revolutionanalytics.com/2017/12/erum-2018.html

Winners of the ASA Police Data Challenge student visualization contest:
http://blog.revolutionanalytics.com/2017/12/police-data-challenge.html

An introduction to seplyr, a re-skinning of the dplyr package to a standard
evaluation interface:
http://blog.revolutionanalytics.com/2017/12/introduction-to-seplyr.html

How to run R (and the rest of the Linux ecosystem) in the Windows Subsystem for
Linux:
http://blog.revolutionanalytics.com/2017/12/r-in-the-windows-subsystem-for-linux.html

A chart of Bechdel scores, showing representation of women in movies over time:
http://blog.revolutionanalytics.com/2017/12/a-chart-of-bechdel-test-scores.html

The British Ecological Society's Guide to Reproducible Science advocates the use
of R and Rmarkdown:
http://blog.revolutionanalytics.com/2017/12/bes-reproducible-science.html

Eight modules from the Microsoft AI School cover Microsoft R and SQL Server ML
Services: http://blog.revolutionanalytics.com/2017/12/ml-server-ai-path.html

And some general interest stories (not necessarily related to R):

* Kate Crawford's keynote from NIPS 2017 on the issue of bias in artificial
  intelligence applications:
  http://blog.revolutionanalytics.com/2017/12/the-trouble-with-bias-by-kate-crawford.html,
  a topic also covered in the Microsoft AI Blog
  http://blog.revolutionanalytics.com/2017/12/on-the-biases-in-data.html

* The original Star Wars movie was a dud before it was rescued in editing:
  http://blog.revolutionanalytics.com/2017/12/because-its-friday-editing-star-wars.html

* I'm now a member of the Cloud Developer Advocates team at Microsoft:
  http://blog.revolutionanalytics.com/2017/12/cloud-advocate.html

* A Disney animator draws in 3-D with a virtual reality kit:
  http://blog.revolutionanalytics.com/2017/12/because-its-friday-3-d-animation.html

* A very, very wide web page visualizes the Solar System to scale:
  http://blog.revolutionanalytics.com/2017/12/because-its-friday-1-pixel-moon.html

As always, thanks for the comments and please keep sending suggestions to
me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
Developer Advocate, Microsoft Cloud & Enterprise 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From ss5505 at cumc.columbia.edu  Tue Jan  9 19:32:15 2018
From: ss5505 at cumc.columbia.edu (Sariya, Sanjeev)
Date: Tue, 9 Jan 2018 18:32:15 +0000
Subject: [R] UseDevel: version requires a more recent R
Message-ID: <BY1PR0201MB10003D955D7473F44003EDED81100@BY1PR0201MB1000.namprd02.prod.outlook.com>

Hello R experts:

I need a developer version of a Bioconductor library.

> sessionInfo()
R version 3.4.2 (2017-09-28)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

When I try to useDevel it fails.

I've removed packages and again loaded but I get the same error message.

remove.packages("BiocInstaller")
source("https://bioconductor.org/biocLite.R")
library(BiocInstaller)

Bioconductor version 3.6 (BiocInstaller 1.28.0), ?biocLite for help


> useDevel()

Error: 'devel' version requires a more recent R

I'm running into this error for few days now. I close R after removing biocInstaller and proceed with following steps.

Please guide me to fix this.

Thanks,
SS

	[[alternative HTML version deleted]]


From HDoran at air.org  Tue Jan  9 19:47:22 2018
From: HDoran at air.org (Doran, Harold)
Date: Tue, 9 Jan 2018 18:47:22 +0000
Subject: [R] Revolutions blog: December 2017 roundup
In-Reply-To: <SN6PR2101MB09272A712D22BB1063EB7DAAC8100@SN6PR2101MB0927.namprd21.prod.outlook.com>
References: <SN6PR2101MB09272A712D22BB1063EB7DAAC8100@SN6PR2101MB0927.namprd21.prod.outlook.com>
Message-ID: <DM2PR0501MB128089AA9AC2C8D59CB67F08CA100@DM2PR0501MB1280.namprd05.prod.outlook.com>

The blog post that the vocal range directs to is *highly* offensive and off color and in very poo taste to share with this group. 

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David Smith (CDA) via R-help
Sent: Tuesday, January 09, 2018 12:47 PM
To: r-help at r-project.org
Subject: [R] Revolutions blog: December 2017 roundup

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests have written about R at the Revolutions blog (http://blog.revolutionanalytics.com)
and every month I post a summary of articles from the previous month of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the month of December:

Hadley Wickham's Shiny app for making eggnog:
http://blog.revolutionanalytics.com/2017/12/merry-christmas-and-happy-new-year.html

Using R to analyze the vocal range of pop singers:
http://blog.revolutionanalytics.com/2017/12/because-its-friday-deck-the-halls.html

A tour of the data.table package from its creator, Matt Dowle:
http://blog.revolutionanalytics.com/2017/12/data-table-video.html

The European R Users Meeting (eRum) will be held in Budapest, May 14-18:
http://blog.revolutionanalytics.com/2017/12/erum-2018.html

Winners of the ASA Police Data Challenge student visualization contest:
http://blog.revolutionanalytics.com/2017/12/police-data-challenge.html

An introduction to seplyr, a re-skinning of the dplyr package to a standard evaluation interface:
http://blog.revolutionanalytics.com/2017/12/introduction-to-seplyr.html

How to run R (and the rest of the Linux ecosystem) in the Windows Subsystem for
Linux:
http://blog.revolutionanalytics.com/2017/12/r-in-the-windows-subsystem-for-linux.html

A chart of Bechdel scores, showing representation of women in movies over time:
http://blog.revolutionanalytics.com/2017/12/a-chart-of-bechdel-test-scores.html

The British Ecological Society's Guide to Reproducible Science advocates the use of R and Rmarkdown:
http://blog.revolutionanalytics.com/2017/12/bes-reproducible-science.html

Eight modules from the Microsoft AI School cover Microsoft R and SQL Server ML
Services: http://blog.revolutionanalytics.com/2017/12/ml-server-ai-path.html

And some general interest stories (not necessarily related to R):

* Kate Crawford's keynote from NIPS 2017 on the issue of bias in artificial
  intelligence applications:
  http://blog.revolutionanalytics.com/2017/12/the-trouble-with-bias-by-kate-crawford.html,
  a topic also covered in the Microsoft AI Blog
  http://blog.revolutionanalytics.com/2017/12/on-the-biases-in-data.html

* The original Star Wars movie was a dud before it was rescued in editing:
  http://blog.revolutionanalytics.com/2017/12/because-its-friday-editing-star-wars.html

* I'm now a member of the Cloud Developer Advocates team at Microsoft:
  http://blog.revolutionanalytics.com/2017/12/cloud-advocate.html

* A Disney animator draws in 3-D with a virtual reality kit:
  http://blog.revolutionanalytics.com/2017/12/because-its-friday-3-d-animation.html

* A very, very wide web page visualizes the Solar System to scale:
  http://blog.revolutionanalytics.com/2017/12/because-its-friday-1-pixel-moon.html

As always, thanks for the comments and please keep sending suggestions to me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

--
David M Smith <davidsmi at microsoft.com>
Developer Advocate, Microsoft Cloud & Enterprise
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From martin.morgan at roswellpark.org  Tue Jan  9 19:39:13 2018
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Tue, 9 Jan 2018 13:39:13 -0500
Subject: [R] UseDevel: version requires a more recent R
In-Reply-To: <BY1PR0201MB10003D955D7473F44003EDED81100@BY1PR0201MB1000.namprd02.prod.outlook.com>
References: <BY1PR0201MB10003D955D7473F44003EDED81100@BY1PR0201MB1000.namprd02.prod.outlook.com>
Message-ID: <b4485f00-ae1a-6ccf-9522-8889926204b7@roswellpark.org>

Ask questions about Bioconductor on the support site

   https://support.bioconductor.org

Bioconductor versions are tied to particular R versions. The current 
Bioc-devel requires use of R-devel. You're using R-3.4.2, so need to 
install the devel version of R.

Additional information is at

   http://bioconductor.org/developers/how-to/useDevel/

Martin Morgan

On 01/09/2018 01:32 PM, Sariya, Sanjeev wrote:
> Hello R experts:
> 
> I need a developer version of a Bioconductor library.
> 
>> sessionInfo()
> R version 3.4.2 (2017-09-28)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> When I try to useDevel it fails.
> 
> I've removed packages and again loaded but I get the same error message.
> 
> remove.packages("BiocInstaller")
> source("https://bioconductor.org/biocLite.R")
> library(BiocInstaller)
> 
> Bioconductor version 3.6 (BiocInstaller 1.28.0), ?biocLite for help
> 
> 
>> useDevel()
> 
> Error: 'devel' version requires a more recent R
> 
> I'm running into this error for few days now. I close R after removing biocInstaller and proceed with following steps.
> 
> Please guide me to fix this.
> 
> Thanks,
> SS
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


This email message may contain legally privileged and/or...{{dropped:2}}


From bgunter.4567 at gmail.com  Tue Jan  9 20:03:45 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 9 Jan 2018 11:03:45 -0800
Subject: [R] UseDevel: version requires a more recent R
In-Reply-To: <BY1PR0201MB10003D955D7473F44003EDED81100@BY1PR0201MB1000.namprd02.prod.outlook.com>
References: <BY1PR0201MB10003D955D7473F44003EDED81100@BY1PR0201MB1000.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbSn=f41gmaTy0HgTtw0GLWH6JxyKt2O2yZxSkKf5VAtDg@mail.gmail.com>

Obvious response:

Post this on the Bioconductor support site, not here:

https://support.bioconductor.org/

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jan 9, 2018 at 10:32 AM, Sariya, Sanjeev
<ss5505 at cumc.columbia.edu> wrote:
> Hello R experts:
>
> I need a developer version of a Bioconductor library.
>
>> sessionInfo()
> R version 3.4.2 (2017-09-28)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> When I try to useDevel it fails.
>
> I've removed packages and again loaded but I get the same error message.
>
> remove.packages("BiocInstaller")
> source("https://bioconductor.org/biocLite.R")
> library(BiocInstaller)
>
> Bioconductor version 3.6 (BiocInstaller 1.28.0), ?biocLite for help
>
>
>> useDevel()
>
> Error: 'devel' version requires a more recent R
>
> I'm running into this error for few days now. I close R after removing biocInstaller and proceed with following steps.
>
> Please guide me to fix this.
>
> Thanks,
> SS
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Jan  9 20:16:26 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 09 Jan 2018 11:16:26 -0800
Subject: [R] UseDevel: version requires a more recent R
In-Reply-To: <BY1PR0201MB10003D955D7473F44003EDED81100@BY1PR0201MB1000.namprd02.prod.outlook.com>
References: <BY1PR0201MB10003D955D7473F44003EDED81100@BY1PR0201MB1000.namprd02.prod.outlook.com>
Message-ID: <91AEC318-B3F3-4211-B37D-8DC5B64A2070@dcn.davis.ca.us>

Wrong forum.

https://support.bioconductor.org/
-- 
Sent from my phone. Please excuse my brevity.

On January 9, 2018 10:32:15 AM PST, "Sariya, Sanjeev" <ss5505 at cumc.columbia.edu> wrote:
>Hello R experts:
>
>I need a developer version of a Bioconductor library.
>
>> sessionInfo()
>R version 3.4.2 (2017-09-28)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows 7 x64 (build 7601) Service Pack 1
>
>When I try to useDevel it fails.
>
>I've removed packages and again loaded but I get the same error
>message.
>
>remove.packages("BiocInstaller")
>source("https://bioconductor.org/biocLite.R")
>library(BiocInstaller)
>
>Bioconductor version 3.6 (BiocInstaller 1.28.0), ?biocLite for help
>
>
>> useDevel()
>
>Error: 'devel' version requires a more recent R
>
>I'm running into this error for few days now. I close R after removing
>biocInstaller and proceed with following steps.
>
>Please guide me to fix this.
>
>Thanks,
>SS
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Tue Jan  9 21:21:18 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 10 Jan 2018 09:21:18 +1300
Subject: [R] [FORGED] Re:  Revolutions blog: December 2017 roundup
In-Reply-To: <DM2PR0501MB128089AA9AC2C8D59CB67F08CA100@DM2PR0501MB1280.namprd05.prod.outlook.com>
References: <SN6PR2101MB09272A712D22BB1063EB7DAAC8100@SN6PR2101MB0927.namprd21.prod.outlook.com>
 <DM2PR0501MB128089AA9AC2C8D59CB67F08CA100@DM2PR0501MB1280.namprd05.prod.outlook.com>
Message-ID: <3a2ac8cc-1546-06b0-e934-a79bf8ff394f@auckland.ac.nz>


On 10/01/18 07:47, Doran, Harold wrote:

> The blog post that the vocal range directs to is *highly* offensive and
> off color and in very poo taste to share with this group.

Huh?  And furthermore ???.

cheers,

Rolf

P. S.  Moreover:  "poo taste"!!! :-)

R.


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Tue Jan  9 21:45:03 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 10 Jan 2018 09:45:03 +1300
Subject: [R] [FORGED] RE: [FORGED] Re: Revolutions blog: December 2017
 roundup
In-Reply-To: <DM2PR0501MB128023D81180D0AA74EAD5F6CA100@DM2PR0501MB1280.namprd05.prod.outlook.com>
References: <SN6PR2101MB09272A712D22BB1063EB7DAAC8100@SN6PR2101MB0927.namprd21.prod.outlook.com>
 <DM2PR0501MB128089AA9AC2C8D59CB67F08CA100@DM2PR0501MB1280.namprd05.prod.outlook.com>
 <3a2ac8cc-1546-06b0-e934-a79bf8ff394f@auckland.ac.nz>
 <DM2PR0501MB128023D81180D0AA74EAD5F6CA100@DM2PR0501MB1280.namprd05.prod.outlook.com>
Message-ID: <ac1e6499-2712-6352-4346-4d5b46dd9cc6@auckland.ac.nz>


On 10/01/18 09:31, Doran, Harold wrote:

> It would be better for you to instead read the blog post that
> uses extremely derogatory language instead of your silly post below.

I did read it, somewhat cursorily I admit, and saw no derogatory 
language whatever, which is why I was puzzled.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ruipbarradas at sapo.pt  Tue Jan  9 23:11:41 2018
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 9 Jan 2018 22:11:41 +0000
Subject: [R] [FORGED] RE: [FORGED] Re: Revolutions blog: December 2017
 roundup
In-Reply-To: <ac1e6499-2712-6352-4346-4d5b46dd9cc6@auckland.ac.nz>
References: <SN6PR2101MB09272A712D22BB1063EB7DAAC8100@SN6PR2101MB0927.namprd21.prod.outlook.com>
 <DM2PR0501MB128089AA9AC2C8D59CB67F08CA100@DM2PR0501MB1280.namprd05.prod.outlook.com>
 <3a2ac8cc-1546-06b0-e934-a79bf8ff394f@auckland.ac.nz>
 <DM2PR0501MB128023D81180D0AA74EAD5F6CA100@DM2PR0501MB1280.namprd05.prod.outlook.com>
 <ac1e6499-2712-6352-4346-4d5b46dd9cc6@auckland.ac.nz>
Message-ID: <838ec416-6856-a7f7-b430-6454b9e05ec9@sapo.pt>

Hello,

I didn't like the video but that has nothing to do with the language, I 
just happen to prefer other type(s) of music.

Rui Barradas

On 1/9/2018 8:45 PM, Rolf Turner wrote:
> 
> On 10/01/18 09:31, Doran, Harold wrote:
> 
>> It would be better for you to instead read the blog post that
>> uses extremely derogatory language instead of your silly post below.
> 
> I did read it, somewhat cursorily I admit, and saw no derogatory 
> language whatever, which is why I was puzzled.
> 
> cheers,
> 
> Rolf
>


From amelia_marsh08 at yahoo.com  Wed Jan 10 07:35:25 2018
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Wed, 10 Jan 2018 06:35:25 +0000 (UTC)
Subject: [R] Error installing ggplot2 package
References: <1945260298.253230.1515566125847.ref@mail.yahoo.com>
Message-ID: <1945260298.253230.1515566125847@mail.yahoo.com>

DeaR Forum,
I am trying to install the library ggplot2.?
Currently I am using following R version
R version 3.4.1 (2017-06-30) -- "Single Candle"Copyright (C) 2017 The R Foundation for Statistical ComputingPlatform: x86_64-w64-mingw32/x64 (64-bit)

However, when I try to install ggplot2 and few other packages, I am getting following error.
> library(ggplot2)Error: package or namespace load failed for ?ggplot2? in readRDS(pfile):?error reading from connectionIn addition: Warning message:package ?ggplot2? was built under R version 3.5.0?

I wonder about the R version 3.5.0 as I checked on the CRAN site, the latest R version is R 3.4.3. I have in fact tried installing older versions too, but the error message remains same. Please guide.
Regards
Amelia





	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Jan 10 16:40:40 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 10 Jan 2018 07:40:40 -0800
Subject: [R] Error installing ggplot2 package
In-Reply-To: <1945260298.253230.1515566125847@mail.yahoo.com>
References: <1945260298.253230.1515566125847.ref@mail.yahoo.com>
 <1945260298.253230.1515566125847@mail.yahoo.com>
Message-ID: <CAGxFJbStDDq3=3omMx2ngFeX6bf+pqMQBYbb70ig88GaxcOSyw@mail.gmail.com>

Point of clarification:

Packages other than those that are part of the "standard" r distro
must first be "installed" from a package repository -- typically CRAN
-- via the install.packages()*  function before they can be accessed
via the library() or require() function. Have you done this? See
?installed.packages if you are unsure.

Also, R must know what libraries to look in for any packages to be
loaded via the library() function. see ?library for possibly relevant
help on specifying the location if needed.

Finally, apologies if I am offbase on this; others may understand your
error message better than I and give you a more appropriate response.


*Or through a suitable GUI interface that call install.packages().

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jan 9, 2018 at 10:35 PM, Amelia Marsh via R-help
<r-help at r-project.org> wrote:
> DeaR Forum,
> I am trying to install the library ggplot2.
> Currently I am using following R version
> R version 3.4.1 (2017-06-30) -- "Single Candle"Copyright (C) 2017 The R Foundation for Statistical ComputingPlatform: x86_64-w64-mingw32/x64 (64-bit)
>
> However, when I try to install ggplot2 and few other packages, I am getting following error.
>> library(ggplot2)Error: package or namespace load failed for ?ggplot2? in readRDS(pfile): error reading from connectionIn addition: Warning message:package ?ggplot2? was built under R version 3.5.0
>
> I wonder about the R version 3.5.0 as I checked on the CRAN site, the latest R version is R 3.4.3. I have in fact tried installing older versions too, but the error message remains same. Please guide.
> Regards
> Amelia
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Wed Jan 10 17:17:07 2018
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 10 Jan 2018 11:17:07 -0500
Subject: [R] Error installing ggplot2 package
In-Reply-To: <CAGxFJbStDDq3=3omMx2ngFeX6bf+pqMQBYbb70ig88GaxcOSyw@mail.gmail.com>
References: <1945260298.253230.1515566125847.ref@mail.yahoo.com>
 <1945260298.253230.1515566125847@mail.yahoo.com>
 <CAGxFJbStDDq3=3omMx2ngFeX6bf+pqMQBYbb70ig88GaxcOSyw@mail.gmail.com>
Message-ID: <A19643F7-7AFE-473B-99CF-D9A6AAD86D78@me.com>

Hi,

If I am reading the messages below correctly, it would seem that Amelia did install ggplot2.

However, what is not clear is the source and version of the ggplot2 package that she installed.

The message would suggest that she installed a version of ggplot2 that was built for R-devel, which is to be R version 3.5.0 and thus, is not compatible with the current release/patch versions of R.

Also, according to the NEWS file for R-devel:

  http://stat.ethz.ch/R-manual/R-devel/doc/html/NEWS.html

specifically right at the top:

"? The default version for save(), saveRDS(), serialize() and similar has been changed to 3. Objects saved with version 3 are not readable by earlier versions of R.

This includes saved workspaces."


That might also explain the readRDS(pfile) related error message.

If Amelia downloaded the *wrong* (e.g. R-devel) Windows binary version of ggplot2 from CRAN (currently ggplot2_2.2.1.zip) with the intent to install it locally, for example, rather than just using:

 install.packages("ggplot2")

as Bert notes below, that might explain the errors.

Amelia, can you provide more details?

Regards,

Marc Schwartz



> On Jan 10, 2018, at 10:40 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Point of clarification:
> 
> Packages other than those that are part of the "standard" r distro
> must first be "installed" from a package repository -- typically CRAN
> -- via the install.packages()*  function before they can be accessed
> via the library() or require() function. Have you done this? See
> ?installed.packages if you are unsure.
> 
> Also, R must know what libraries to look in for any packages to be
> loaded via the library() function. see ?library for possibly relevant
> help on specifying the location if needed.
> 
> Finally, apologies if I am offbase on this; others may understand your
> error message better than I and give you a more appropriate response.
> 
> 
> *Or through a suitable GUI interface that call install.packages().
> 
> Cheers,
> Bert
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Tue, Jan 9, 2018 at 10:35 PM, Amelia Marsh via R-help
> <r-help at r-project.org> wrote:
>> DeaR Forum,
>> I am trying to install the library ggplot2.
>> Currently I am using following R version
>> R version 3.4.1 (2017-06-30) -- "Single Candle"Copyright (C) 2017 The R Foundation for Statistical ComputingPlatform: x86_64-w64-mingw32/x64 (64-bit)
>> 
>> However, when I try to install ggplot2 and few other packages, I am getting following error.
>>> library(ggplot2)Error: package or namespace load failed for ?ggplot2? in readRDS(pfile): error reading from connectionIn addition: Warning message:package ?ggplot2? was built under R version 3.5.0
>> 
>> I wonder about the R version 3.5.0 as I checked on the CRAN site, the latest R version is R 3.4.3. I have in fact tried installing older versions too, but the error message remains same. Please guide.
>> Regards
>> Amelia
>> 
>> 
>> 
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From akhileshsingh.igkv at gmail.com  Wed Jan 10 07:45:03 2018
From: akhileshsingh.igkv at gmail.com (Akhilesh Singh)
Date: Wed, 10 Jan 2018 12:15:03 +0530
Subject: [R] [FORGED] Error occurring in "emmeans" package for the two
 data sets I used. Please help.
In-Reply-To: <CACLgfx35fU0O8CKUFJDmh4xUha7oTAKwGMD9bSSAewu-A4W3RQ@mail.gmail.com>
References: <CACLgfx1BtE5dd4ELTu6rHva48zJ0AGfJ1PzH7323_iqD9WGG=A@mail.gmail.com>
 <3ab856eb-4d56-a2a9-9ea5-3bc9bb1a25e9@auckland.ac.nz>
 <ea1e0624-8de1-fafb-e4c9-92ff232d86e0@gmail.com>
 <CACLgfx2-tUHQSvZ=74iaCxNDFdMCf6Z8+GH79pd9q6rGTN7n+A@mail.gmail.com>
 <CACLgfx35fU0O8CKUFJDmh4xUha7oTAKwGMD9bSSAewu-A4W3RQ@mail.gmail.com>
Message-ID: <CACLgfx2GeP6O1QqO2hSgo5be-HtHLYZRJpxh_NXdwzenK3szXA@mail.gmail.com>

Thanks for your kind reply. Problem is solved. However, it's "confidence
interval / treatment comparison plot" is not taking main title. And the
fonts of axes labels can not be changed using 'cex' parameter. I will
appreciate if you could help in this matter too.

Dr. A. K. Singh

On 09-Jan-2018 8:18 PM, "Sal Mangiafico" <salvatore.s.mangiafico at gmail.com>
wrote:

One way to avoid this error is to create the aov without using the with
function, but instead use the data= option in the aov function.

That is,

medley2 = aov(diversity ~ zinc, data=medley.clementis)
emmeans::emmeans(medley2, "zinc")

You can see the difference in the calls:

medley2$call
medley.clementis.aov$call

This works for the other data set as well, e.g.

keough2 = aov(serpulid.ln ~ biofilm, data=keough.raimondi.ln)

~ Sal Mangiafico

On 1/8/2018 4:44 PM, Rolf Turner wrote:


On 07/01/18 02:19, Akhilesh Singh wrote:

I am a Professor of Statistics at Indira Gandhi Krishi Vishwavidyalaya,
Raipur, India. While teaching in class about analysis of variance using R,
I was doing a one-way analysis for the two data-sets given below in the
R-class. I got a typical error in "emmeans" package, please help:

Data-set-1:
--------------
Medley and Clements (1998) investigated the impact of zinc contamination
(and other heavy metals) on the diversity of diatom species in the USA
Rocky Mountains. The diversity of diatoms (number of species) and degree of
zinc contamination (categorized as either of high, medium, low or natural
background level) were recorded from between four and six sampling stations
within each of six streams known to be polluted, as given below:

stream=c("Eagle", "Eagle", "Eagle", "Eagle", "Blue", "Blue",
          "Blue", "Blue", "Blue", "Blue", "Blue", "Snake", "Snake",
          "Snake", "Snake", "Snake", "Arkan", "Arkan", "Arkan",
          "Arkan", "Arkan", "Arkan", "Arkan", "Chalk", "Chalk",
          "Chalk", "Chalk", "Chalk", "Splat", "Splat", "Splat",
          "Splat", "Splat", "Splat")

zinc=c("BACK", "HIGH", "HIGH", "MED", "BACK", "HIGH", "BACK", "BACK",
        "HIGH", "MED", "MED", "BACK", "MED", "HIGH", "HIGH", "HIGH",
        "LOW", "LOW", "LOW", "LOW", "MED", "MED", "LOW", "LOW",
        "HIGH", "HIGH", "MED", "LOW", "BACK", "BACK", "MED", "LOW",
        "MED", "BACK")

diversity=c(2.27, 1.25, 1.15, 1.62, 1.7, 0.63, 2.05, 1.98, 1.04,
             2.19, 2.1, 2.2, 2.06, 1.9, 1.88, 0.85, 1.4, 2.18, 1.83,
             1.88, 2.02, 1.94, 2.1, 2.38, 1.43, 1.37, 1.75, 2.83,
             1.53, 0.76, 0.8, 1.66, 0.98, 1.89)

medley.clementis=data.frame(stream,zinc,diversity)

I did the one-way anova:
-------------------------------

medley.clementis.aov=with(medley.clementis, aov(diversity ~ zinc))

anova(medley.clementis)

Then, I tried to do post hoc analysis using "emmeans" package following
command:
------------------------------------------------------------
-----------------------------------

emmeans::emmeans(medley.clementis.aov, "zinc")


This gives following error:
----------------------------------
Error in recover_data.call(fcall, delete.response(terms(object)),
object$na.action,  :
   object 'possibly.random' not found
Error in ref_grid(object, ...) :
   Perhaps a 'data' or 'params' argument is needed



Data-set-2:
---------------
Keough and Raimondi (1995) examined the effects of four biofilm types (SL:
sterile unfilmed substrate, NL: netted laboratory biofilms, UL: unnetted
laboratory biofilms and F: netted field biofilms) on the recruitment of
serpulid larvae. Substrates treated with one of the four biofilm types were
left in shallow marine waters for one week after which the number of newly
recruited serpulid worms were counted, as given below:

biofilm=c("SL", "SL", "SL", "SL", "SL", "SL", "SL", "UL", "UL", "UL",
           "UL", "UL", "UL", "UL", "NL", "NL", "NL", "NL", "NL", "NL",
           "NL", "F", "F", "F", "F", "F", "F", "F")

serpulid=c(61, 113, 123, 75, 75, 83, 95, 143, 81, 101, 155, 156, 193,
            163, 203, 159, 139, 161, 179, 97, 157, 128.5, 204.5,
            108.5, 116.5, 140.5, 160.5, 87.5)

keough.raimondi=data.frame(biofilm,serpulid)

Applied log-transformation:
-------------------------------------------
keough.raimondi.ln=transform(keough.raimondi, serpulid.ln=log(serpulid))

I did the one-way anova, with contrasts defined below:
------------------------------------------------------------------------
contrasts(keough.raimondi.ln$biofilm) <- cbind(c(0, 1, 0, -1),
                             c(2, -1, 0, -1), c(-1, -1, 3, -1))
keough.raimondi.ln$biofilm

keough.contr.list <- list(biofilm = list('NL vs UL' = 1,
               'F vs (NL & UL)' = 2, 'SL vs (F & NL & UL)' = 3))
keough.contr.list

One-way anova:
----------------------
keough.raimondi.ln.aov=with(keough.raimondi.ln, aov(serpulid.ln ~ biofilm))

summary(keough.raimondi.ln.aov,split=keough.contr.list)


Then, I tried to do post hoc analysis using "emmeans" package following
command:
------------------------------------------------------------
-----------------------------------

emmeans(keough.raimondi.ln.aov, ~ biofilm)


This gives following error:
----------------------------------
Error in recover_data.call(fcall, delete.response(terms(object)),
object$na.action,  :
   object 'possibly.random' not found
Error in ref_grid(object, ...) :
   Perhaps a 'data' or 'params' argument is needed


Help Needed:
------------------
On many other data sets and data frame I successfully used "emmeans"
package using the help available in R.

But, for the above two data-sets, I consistently got the same error as
described above.

I do not know what is amiss. Where I am missing or whatever is wrong, I
request the entire R-team to help me to solve above problem.


Well, you don't need the *entire* R-team!!! It probably (in some sense)
includes millions of people. :-)

Thanking in advance.


Thanks for your thorough and well set out description of the problem.
Your reproducible examples were flawless.

I am not *completely* certain, but this looks to me like a bug in emmeans.

I have therefore taken the liberty of cc-ing this reply to Russell Lenth
(the maintainer of emmeans) to get his take on the issue.

cheers,

Rolf Turner

	[[alternative HTML version deleted]]


From elisae675 at gmail.com  Wed Jan 10 11:11:59 2018
From: elisae675 at gmail.com (elisa elisa)
Date: Wed, 10 Jan 2018 10:11:59 +0000
Subject: [R] Problem with dbFD function in FD library
Message-ID: <CAFOQ0KP7Ra-hShkNEG9CwY0oeHt-q+Wtn64ewNxLeAKj=jCcsA@mail.gmail.com>

Dear all,

I have a question about FD package. I?m trying to calculate functional
diversity indices using insect data. My trait data includes dispersal
ability (0, 0.5, 1), body size (continuous) and five feeding guilds coded
as in percentages (for example; 0,0,0.5,0.5,0)  since some of the species
can have two different feeding guilds. However, the package only calculates
when I run ?calc.Frich= F? and gives the Feve, Fdis, RaoQ and CWM values
for my data. When I run the function with ?calc.Frich=T?, I see the warning
that I wrote below and no one of the values are calculated.

Could you please tell me how can I fix this problem and have the FRic value
for my data?



Func.div?dbFD ( trait_data, abundance_data, calc.FRic = T, corr="cailliez",
w.abun = T, CWM.type = "all" )


FRic: Dimensionality reduction was required. The last PCoA axis (out of 6
in total) was removed.

FRic: Quality of the reduced-space representation = 0.9402678

QH6114 qhull precision error: initial simplex is not convex.
Distance=-2.7e-15

Error in convhulln(tr.FRic, "FA") : Received error code 2 from qhull.


Best,

Elisae

	[[alternative HTML version deleted]]


From devazresearch at gmail.com  Wed Jan 10 17:41:26 2018
From: devazresearch at gmail.com (deva d)
Date: Wed, 10 Jan 2018 17:41:26 +0100
Subject: [R] R-hts
Message-ID: <CAKuYVCWraUYQZT=bA-8g9Da+y3EXOO9G=x38QSfx6jFBLgwXsQ@mail.gmail.com>

dear all,

i need some help in structuring my data file for a hierarchical time series
analysis.

can someone help please ?

i have a 600 row database in the nature of a panel data, with 3 time series
values of interest. the data also has 4 classificatory variables comprising
a code for each entity in the panel, a value for time (year), and
classification of type of entity and a further sub-group of the type.

i am unable to structure the data file for performing the hts analysis.

thanks in advance.

*....*

*Deva*


...............



*in search of knowledge, everyday something is added ....*

*in search of wisdom, everyday something is dropped  ... an old Chinese
Proverb*
:::::::::::::::::::::::::

	[[alternative HTML version deleted]]


From jrkrideau at yahoo.ca  Wed Jan 10 18:12:20 2018
From: jrkrideau at yahoo.ca (John Kane)
Date: Wed, 10 Jan 2018 17:12:20 +0000 (UTC)
Subject: [R] R-hts
In-Reply-To: <CAKuYVCWraUYQZT=bA-8g9Da+y3EXOO9G=x38QSfx6jFBLgwXsQ@mail.gmail.com>
References: <CAKuYVCWraUYQZT=bA-8g9Da+y3EXOO9G=x38QSfx6jFBLgwXsQ@mail.gmail.com>
Message-ID: <123829139.522139.1515604340433@mail.yahoo.com>

Have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
and 
http://adv-r.had.co.nz/Reproducibility.html


 

    On Wednesday, January 10, 2018, 11:51:22 AM EST, deva d <devazresearch at gmail.com> wrote:  
 
 dear all,

i need some help in structuring my data file for a hierarchical time series
analysis.

can someone help please ?

i have a 600 row database in the nature of a panel data, with 3 time series
values of interest. the data also has 4 classificatory variables comprising
a code for each entity in the panel, a value for time (year), and
classification of type of entity and a further sub-group of the type.

i am unable to structure the data file for performing the hts analysis.

thanks in advance.

*....*

*Deva*


...............



*in search of knowledge, everyday something is added ....*

*in search of wisdom, everyday something is dropped? ... an old Chinese
Proverb*
:::::::::::::::::::::::::

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From jeremiejuste at gmail.com  Wed Jan 10 18:19:59 2018
From: jeremiejuste at gmail.com (=?UTF-8?B?SsOpcsOpbWllIEp1c3Rl?=)
Date: Wed, 10 Jan 2018 18:19:59 +0100
Subject: [R] R-hts
In-Reply-To: <CAKuYVCWraUYQZT=bA-8g9Da+y3EXOO9G=x38QSfx6jFBLgwXsQ@mail.gmail.com>
References: <CAKuYVCWraUYQZT=bA-8g9Da+y3EXOO9G=x38QSfx6jFBLgwXsQ@mail.gmail.com>
Message-ID: <CAPHJcdCA-CsXctXAt6K46xd7_pWV4iXo18HznKJKV8pUm6jJpA@mail.gmail.com>

Hello,

Have a look at the plm package
https://cran.r-project.org/web/packages/plm/index.html
It has a convenient way to structure your data into panel according to some
id.

Best regards,
Jeremie



On Wed, Jan 10, 2018 at 5:41 PM, deva d <devazresearch at gmail.com> wrote:

> dear all,
>
> i need some help in structuring my data file for a hierarchical time series
> analysis.
>
> can someone help please ?
>
> i have a 600 row database in the nature of a panel data, with 3 time series
> values of interest. the data also has 4 classificatory variables comprising
> a code for each entity in the panel, a value for time (year), and
> classification of type of entity and a further sub-group of the type.
>
> i am unable to structure the data file for performing the hts analysis.
>
> thanks in advance.
>
> *....*
>
> *Deva*
>
>
> ...............
>
>
>
> *in search of knowledge, everyday something is added ....*
>
> *in search of wisdom, everyday something is dropped  ... an old Chinese
> Proverb*
> :::::::::::::::::::::::::
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
J?r?mie Juste

	[[alternative HTML version deleted]]


From devazresearch at gmail.com  Wed Jan 10 18:49:27 2018
From: devazresearch at gmail.com (deva d)
Date: Wed, 10 Jan 2018 18:49:27 +0100
Subject: [R] R-hts
In-Reply-To: <CAPHJcdCA-CsXctXAt6K46xd7_pWV4iXo18HznKJKV8pUm6jJpA@mail.gmail.com>
References: <CAKuYVCWraUYQZT=bA-8g9Da+y3EXOO9G=x38QSfx6jFBLgwXsQ@mail.gmail.com>
 <CAPHJcdCA-CsXctXAt6K46xd7_pWV4iXo18HznKJKV8pUm6jJpA@mail.gmail.com>
Message-ID: <CAKuYVCXSds8wKwxvrzKsg2sXLdK-75FQaP0EN-mbcxgmLkRW3A@mail.gmail.com>

Thanks Jeremie

My data has 40 entities clustered into 2 types (rural/urban) & two sub
groups in each (bug/small).

Panel will give me for all 40 v/s time id.

Suppose I need to see rural v/s time or big urban v/s time, then how should
I obtain findings...?

Kindly advise is possible.



Thanks and regards,

Deva

-- sent from my handphone

On Jan 10, 2018 10:50 PM, "J?r?mie Juste" <jeremiejuste at gmail.com> wrote:

> Hello,
>
> Have a look at the plm package https://cran.r-project.org/
> web/packages/plm/index.html
> It has a convenient way to structure your data into panel according to
> some id.
>
> Best regards,
> Jeremie
>
>
>
> On Wed, Jan 10, 2018 at 5:41 PM, deva d <devazresearch at gmail.com> wrote:
>
>> dear all,
>>
>> i need some help in structuring my data file for a hierarchical time
>> series
>> analysis.
>>
>> can someone help please ?
>>
>> i have a 600 row database in the nature of a panel data, with 3 time
>> series
>> values of interest. the data also has 4 classificatory variables
>> comprising
>> a code for each entity in the panel, a value for time (year), and
>> classification of type of entity and a further sub-group of the type.
>>
>> i am unable to structure the data file for performing the hts analysis.
>>
>> thanks in advance.
>>
>> *....*
>>
>> *Deva*
>>
>>
>> ...............
>>
>>
>>
>> *in search of knowledge, everyday something is added ....*
>>
>> *in search of wisdom, everyday something is dropped  ... an old Chinese
>> Proverb*
>> :::::::::::::::::::::::::
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> J?r?mie Juste
>

	[[alternative HTML version deleted]]


From raphaelprates at outlook.com  Wed Jan 10 19:09:25 2018
From: raphaelprates at outlook.com (Raphael Prates)
Date: Wed, 10 Jan 2018 18:09:25 +0000
Subject: [R]  [shiny] How to read current URL address
In-Reply-To: <RO1PR80MB04607AD5ED5C6C8968BCEE99BE110@RO1PR80MB0460.lamprd80.prod.outlook.com>
References: <RO1PR80MB04607AD5ED5C6C8968BCEE99BE110@RO1PR80MB0460.lamprd80.prod.outlook.com>
Message-ID: <RO1PR80MB0460C07F09BBE2F22998AAB0BE110@RO1PR80MB0460.lamprd80.prod.outlook.com>


Dears,

I am trying to read the URL name  (i.e "www.google.com") that I was redirected by my own code.

What I already found that could help:


session$clientData$url_protocol
session$clientData$url_hostname
session$clientData$url_pathname
session$clientData$url_port
session$clientData$url_search

But then when I try to use this code in my server function the bellow Error appears:

> urlSearch <- session$clientData$url_search
Error in .getReactiveEnvironment()$currentContext() :
  Operation not allowed without an active reactive context. (You tried to do something that can only be done from inside a reactive expression or observer.)

Could anyone help with this? Considering that the reactive I will not use this value to renderText or to put this values on my shiny website?


Thnx

	[[alternative HTML version deleted]]


From abouelmakarim1962 at gmail.com  Wed Jan 10 19:50:50 2018
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Wed, 10 Jan 2018 13:50:50 -0500
Subject: [R] svm
Message-ID: <CAE9stmeKOKbBg7PiL3Wo_CNDNKXwci4mk4-O8ERJVnxpqu5NnQ@mail.gmail.com>

Dear All:


I am trying to use the R function "svm" with  "type =C-classification" ,
but I got the following error message


SVM.Model1 <- svm(type ~ ., data=my.data.x1x2y, *type='C-classification'*,
kernel='linear',scale=FALSE)

*Error in eval(predvars, data, env) : object 'type' not found*


I am wondering if I should install a specific R package(s).



*Here is my codes:*


feature.x1 <- c(0.25,0.5,1,1,1.5,2,2.25,2.5,2,1,3,   5,3.75,
1,3.5,4,4,5,5.5,6,6,6.5)

length(feature.x1)



feature.x2 <- c(2,3.5,1,2.5,1.75,2,1.75,1.5,2.5,1,1,
 3.5,3.5,5.8,3,4,4.5,5,4,1,4,3)

length(feature.x2)


y <- c(rep(-1,11), rep(1,11))

typey<-as.factor(y)


my.data.x1x2y <- data.frame(feature.x1, feature.x2, typey)

my.data.x1x2y



install.packages("e1071")

library(e1071)



SVM.Model1 <- svm(type ~ ., data=my.data.x1x2y, type='C-classification',
kernel='linear',scale=FALSE)

plot(my.data.x1x2y[,-3],col=(typey+3)/2, pch=18, xlim=c(-1,6), ylim=c(-1,6))

box(lwd = 2, col="darkgreen")







with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Jan 10 19:54:30 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 10 Jan 2018 10:54:30 -0800
Subject: [R] svm
In-Reply-To: <CAE9stmeKOKbBg7PiL3Wo_CNDNKXwci4mk4-O8ERJVnxpqu5NnQ@mail.gmail.com>
References: <CAE9stmeKOKbBg7PiL3Wo_CNDNKXwci4mk4-O8ERJVnxpqu5NnQ@mail.gmail.com>
Message-ID: <F897D3E0-64BE-423F-9ABF-25B001B666C9@comcast.net>


> On Jan 10, 2018, at 10:50 AM, AbouEl-Makarim Aboueissa <abouelmakarim1962 at gmail.com> wrote:
> 
> Dear All:
> 
> 
> I am trying to use the R function "svm" with  "type =C-classification" ,
> but I got the following error message
> 
> 
> SVM.Model1 <- svm(type ~ ., data=my.data.x1x2y, *type='C-classification'*,
> kernel='linear',scale=FALSE)
> 
> *Error in eval(predvars, data, env) : object 'type' not found*

Yopu misspelled the name of your "typey" variable.
> 
> 
> I am wondering if I should install a specific R package(s).
> 
> 
> 
> *Here is my codes:*
> 
> 
> feature.x1 <- c(0.25,0.5,1,1,1.5,2,2.25,2.5,2,1,3,   5,3.75,
> 1,3.5,4,4,5,5.5,6,6,6.5)
> 
> length(feature.x1)
> 
> 
> 
> feature.x2 <- c(2,3.5,1,2.5,1.75,2,1.75,1.5,2.5,1,1,
> 3.5,3.5,5.8,3,4,4.5,5,4,1,4,3)
> 
> length(feature.x2)
> 
> 
> y <- c(rep(-1,11), rep(1,11))
> 
> typey<-as.factor(y)
> 
> 
> my.data.x1x2y <- data.frame(feature.x1, feature.x2, typey)
> 
> my.data.x1x2y
> 
> 
> 
> install.packages("e1071")
> 
> library(e1071)
> 
> 
> 
> SVM.Model1 <- svm(type ~ ., data=my.data.x1x2y, type='C-classification',
> kernel='linear',scale=FALSE)
> 
> plot(my.data.x1x2y[,-3],col=(typey+3)/2, pch=18, xlim=c(-1,6), ylim=c(-1,6))
> 
> box(lwd = 2, col="darkgreen")
> 
> 
> 
> 
> 
> 
> 
> with many thanks
> abou
> ______________________
> 
> 
> *AbouEl-Makarim Aboueissa, PhD*
> 
> *Professor of Statistics*
> 
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From abouelmakarim1962 at gmail.com  Wed Jan 10 20:41:36 2018
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Wed, 10 Jan 2018 14:41:36 -0500
Subject: [R] svm --- type~.
Message-ID: <CAE9stmdpMS9n5NCMesdOJ5dcefM5X5_BBQqAGYBOxF80B7A-hg@mail.gmail.com>

Dear All: Just fixed where is the problem


I am trying to use the R function "svm" with  "type~." , but I got the
following error message


SVM.Model1 <- svm(type ~ ., data=my.data.x1x2y, *type='C-classification'*,
kernel='linear',scale=FALSE)

*Error in eval(predvars, data, env) : object 'type' not found*


I am wondering if I should install a specific R package(s).



*Here is my codes:*


feature.x1 <- c(0.25,0.5,1,1,1.5,2,2.25,2.5,2,1,3,   5,3.75,
1,3.5,4,4,5,5.5,6,6,6.5)

length(feature.x1)



feature.x2 <- c(2,3.5,1,2.5,1.75,2,1.75,1.5,2.5,1,1,
 3.5,3.5,5.8,3,4,4.5,5,4,1,4,3)

length(feature.x2)


y <- c(rep(-1,11), rep(1,11))

typey<-as.factor(y)


my.data.x1x2y <- data.frame(feature.x1, feature.x2, typey)

my.data.x1x2y



install.packages("e1071")

library(e1071)



SVM.Model1 <- svm(type ~ ., data=my.data.x1x2y, type='C-classification',
kernel='linear',scale=FALSE)

plot(my.data.x1x2y[,-3],col=(typey+3)/2, pch=18, xlim=c(-1,6), ylim=c(-1,6))

box(lwd = 2, col="darkgreen")





with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From abouelmakarim1962 at gmail.com  Wed Jan 10 20:42:49 2018
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Wed, 10 Jan 2018 14:42:49 -0500
Subject: [R] svm --- type~.
In-Reply-To: <CAE9stmdpMS9n5NCMesdOJ5dcefM5X5_BBQqAGYBOxF80B7A-hg@mail.gmail.com>
References: <CAE9stmdpMS9n5NCMesdOJ5dcefM5X5_BBQqAGYBOxF80B7A-hg@mail.gmail.com>
Message-ID: <CAE9stmc0mVTGCZK_SLaXHWGnixvdcgeD_mScJ=8KBieO3zs3-g@mail.gmail.com>

got it

thank you
abou

______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*

*Department of Mathematics and Statistics*
*University of Southern Maine*


On Wed, Jan 10, 2018 at 2:41 PM, AbouEl-Makarim Aboueissa <
abouelmakarim1962 at gmail.com> wrote:

> Dear All: Just fixed where is the problem
>
>
> I am trying to use the R function "svm" with  "type~." , but I got the
> following error message
>
>
> SVM.Model1 <- svm(type ~ ., data=my.data.x1x2y, *type='C-classification'*,
> kernel='linear',scale=FALSE)
>
> *Error in eval(predvars, data, env) : object 'type' not found*
>
>
> I am wondering if I should install a specific R package(s).
>
>
>
> *Here is my codes:*
>
>
> feature.x1 <- c(0.25,0.5,1,1,1.5,2,2.25,2.5,2,1,3,   5,3.75,
> 1,3.5,4,4,5,5.5,6,6,6.5)
>
> length(feature.x1)
>
>
>
> feature.x2 <- c(2,3.5,1,2.5,1.75,2,1.75,1.5,2.5,1,1,
>  3.5,3.5,5.8,3,4,4.5,5,4,1,4,3)
>
> length(feature.x2)
>
>
> y <- c(rep(-1,11), rep(1,11))
>
> typey<-as.factor(y)
>
>
> my.data.x1x2y <- data.frame(feature.x1, feature.x2, typey)
>
> my.data.x1x2y
>
>
>
> install.packages("e1071")
>
> library(e1071)
>
>
>
> SVM.Model1 <- svm(type ~ ., data=my.data.x1x2y, type='C-classification',
> kernel='linear',scale=FALSE)
>
> plot(my.data.x1x2y[,-3],col=(typey+3)/2, pch=18, xlim=c(-1,6),
> ylim=c(-1,6))
>
> box(lwd = 2, col="darkgreen")
>
>
>
>
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor of Statistics*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>

	[[alternative HTML version deleted]]


From mr.lucedan at hotmail.it  Wed Jan 10 21:00:04 2018
From: mr.lucedan at hotmail.it (Luca Danieli)
Date: Wed, 10 Jan 2018 20:00:04 +0000
Subject: [R] Information installation package sjPlot
Message-ID: <CWXP265MB0216F34FD9C21931FD0C1133F6110@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>

Hi all,

I am new. I am installing the library sjPlot on Ubunto 16.10 and I guess it is installing some dependencies. But it is taking more than 1.5 hours, is it possible?

It has right now halted (hope momentarily) in installing the package 'rstan', particularly the file lang__grammars__statement_grammar_inst.o

Other packages installed include: dygraphs, colourpicker, raster.

Is it good or is something going wrong?

Luca

Get Outlook for Android<https://aka.ms/ghei36>


	[[alternative HTML version deleted]]


From jeremiejuste at gmail.com  Wed Jan 10 21:20:47 2018
From: jeremiejuste at gmail.com (=?UTF-8?B?SsOpcsOpbWllIEp1c3Rl?=)
Date: Wed, 10 Jan 2018 21:20:47 +0100
Subject: [R] R-hts
In-Reply-To: <123829139.522139.1515604340433@mail.yahoo.com>
References: <CAKuYVCWraUYQZT=bA-8g9Da+y3EXOO9G=x38QSfx6jFBLgwXsQ@mail.gmail.com>
 <123829139.522139.1515604340433@mail.yahoo.com>
Message-ID: <CAPHJcdBE2UarJDCNGeOz=DZZUETSkGrcrcskJntYtuX156wPpQ@mail.gmail.com>

Hello,

It's difficult to help without a sample of the format. Can you provide a
short sample like 10 lines and a few columns.?

Best regards,
Jeremie


On Wed, Jan 10, 2018 at 6:12 PM, John Kane via R-help <r-help at r-project.org>
wrote:

> Have a look at http://stackoverflow.com/questions/5963269/how-to-make-
> a-great-r-reproducible-example
> and
> http://adv-r.had.co.nz/Reproducibility.html
>
>
>
>
>     On Wednesday, January 10, 2018, 11:51:22 AM EST, deva d <
> devazresearch at gmail.com> wrote:
>
>  dear all,
>
> i need some help in structuring my data file for a hierarchical time series
> analysis.
>
> can someone help please ?
>
> i have a 600 row database in the nature of a panel data, with 3 time series
> values of interest. the data also has 4 classificatory variables comprising
> a code for each entity in the panel, a value for time (year), and
> classification of type of entity and a further sub-group of the type.
>
> i am unable to structure the data file for performing the hts analysis.
>
> thanks in advance.
>
> *....*
>
> *Deva*
>
>
> ...............
>
>
>
> *in search of knowledge, everyday something is added ....*
>
> *in search of wisdom, everyday something is dropped  ... an old Chinese
> Proverb*
> :::::::::::::::::::::::::
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
J?r?mie Juste

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Jan 10 23:02:29 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 10 Jan 2018 14:02:29 -0800
Subject: [R] R-hts
In-Reply-To: <CAPHJcdBE2UarJDCNGeOz=DZZUETSkGrcrcskJntYtuX156wPpQ@mail.gmail.com>
References: <CAKuYVCWraUYQZT=bA-8g9Da+y3EXOO9G=x38QSfx6jFBLgwXsQ@mail.gmail.com>
 <123829139.522139.1515604340433@mail.yahoo.com>
 <CAPHJcdBE2UarJDCNGeOz=DZZUETSkGrcrcskJntYtuX156wPpQ@mail.gmail.com>
Message-ID: <9EDE572E-49F3-4229-9BD8-867802E96934@dcn.davis.ca.us>

You are the one with data. Supply what you have (or a simulated version of same, hence the reading recommendation) using dput, and someone may suggest how to transform it. In most cases a simple tabular format (data frame) is sufficient. 
-- 
Sent from my phone. Please excuse my brevity.

On January 10, 2018 12:20:47 PM PST, "J?r?mie Juste" <jeremiejuste at gmail.com> wrote:
>Hello,
>
>It's difficult to help without a sample of the format. Can you provide
>a
>short sample like 10 lines and a few columns.?
>
>Best regards,
>Jeremie
>
>
>On Wed, Jan 10, 2018 at 6:12 PM, John Kane via R-help
><r-help at r-project.org>
>wrote:
>
>> Have a look at
>http://stackoverflow.com/questions/5963269/how-to-make-
>> a-great-r-reproducible-example
>> and
>> http://adv-r.had.co.nz/Reproducibility.html
>>
>>
>>
>>
>>     On Wednesday, January 10, 2018, 11:51:22 AM EST, deva d <
>> devazresearch at gmail.com> wrote:
>>
>>  dear all,
>>
>> i need some help in structuring my data file for a hierarchical time
>series
>> analysis.
>>
>> can someone help please ?
>>
>> i have a 600 row database in the nature of a panel data, with 3 time
>series
>> values of interest. the data also has 4 classificatory variables
>comprising
>> a code for each entity in the panel, a value for time (year), and
>> classification of type of entity and a further sub-group of the type.
>>
>> i am unable to structure the data file for performing the hts
>analysis.
>>
>> thanks in advance.
>>
>> *....*
>>
>> *Deva*
>>
>>
>> ...............
>>
>>
>>
>> *in search of knowledge, everyday something is added ....*
>>
>> *in search of wisdom, everyday something is dropped  ... an old
>Chinese
>> Proverb*
>> :::::::::::::::::::::::::
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>-- 
>J?r?mie Juste
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Jan 11 00:22:19 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 10 Jan 2018 15:22:19 -0800
Subject: [R] R-hts
In-Reply-To: <9EDE572E-49F3-4229-9BD8-867802E96934@dcn.davis.ca.us>
References: <CAKuYVCWraUYQZT=bA-8g9Da+y3EXOO9G=x38QSfx6jFBLgwXsQ@mail.gmail.com>
 <123829139.522139.1515604340433@mail.yahoo.com>
 <CAPHJcdBE2UarJDCNGeOz=DZZUETSkGrcrcskJntYtuX156wPpQ@mail.gmail.com>
 <9EDE572E-49F3-4229-9BD8-867802E96934@dcn.davis.ca.us>
Message-ID: <283794EC-D9F2-4AFC-95C5-8AD204A1AC6E@dcn.davis.ca.us>

Sorry J?r?mie, I mis-read who the OP was. Deva needs to get the ball rolling. 

I would say that for a hierarchical analysis the sample data generally needs to be larger than for other types of analysis to illustrate correlation between classification variables or the example calculation will break. That is, 10 rows will likely be insufficient for a dry run. 

-- 
Sent from my phone. Please excuse my brevity.

On January 10, 2018 2:02:29 PM PST, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>You are the one with data. Supply what you have (or a simulated version
>of same, hence the reading recommendation) using dput, and someone may
>suggest how to transform it. In most cases a simple tabular format
>(data frame) is sufficient. 
>-- 
>Sent from my phone. Please excuse my brevity.
>
>On January 10, 2018 12:20:47 PM PST, "J?r?mie Juste"
><jeremiejuste at gmail.com> wrote:
>>Hello,
>>
>>It's difficult to help without a sample of the format. Can you provide
>>a
>>short sample like 10 lines and a few columns.?
>>
>>Best regards,
>>Jeremie
>>
>>
>>On Wed, Jan 10, 2018 at 6:12 PM, John Kane via R-help
>><r-help at r-project.org>
>>wrote:
>>
>>> Have a look at
>>http://stackoverflow.com/questions/5963269/how-to-make-
>>> a-great-r-reproducible-example
>>> and
>>> http://adv-r.had.co.nz/Reproducibility.html
>>>
>>>
>>>
>>>
>>>     On Wednesday, January 10, 2018, 11:51:22 AM EST, deva d <
>>> devazresearch at gmail.com> wrote:
>>>
>>>  dear all,
>>>
>>> i need some help in structuring my data file for a hierarchical time
>>series
>>> analysis.
>>>
>>> can someone help please ?
>>>
>>> i have a 600 row database in the nature of a panel data, with 3 time
>>series
>>> values of interest. the data also has 4 classificatory variables
>>comprising
>>> a code for each entity in the panel, a value for time (year), and
>>> classification of type of entity and a further sub-group of the
>type.
>>>
>>> i am unable to structure the data file for performing the hts
>>analysis.
>>>
>>> thanks in advance.
>>>
>>> *....*
>>>
>>> *Deva*
>>>
>>>
>>> ...............
>>>
>>>
>>>
>>> *in search of knowledge, everyday something is added ....*
>>>
>>> *in search of wisdom, everyday something is dropped  ... an old
>>Chinese
>>> Proverb*
>>> :::::::::::::::::::::::::
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>>-- 
>>J?r?mie Juste
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Eric.Goodwin at cawthron.org.nz  Wed Jan 10 23:27:17 2018
From: Eric.Goodwin at cawthron.org.nz (Eric Goodwin)
Date: Wed, 10 Jan 2018 22:27:17 +0000
Subject: [R] termplot intervals - SE or CI?
In-Reply-To: <e9bb293e-bf66-6684-9efc-b15b8dcd6042@gmail.com>
References: <E0D9C5E15741224AB7AA910ECEB678E50A4C7C61@ci011.cawthron.org.nz>
 <e9bb293e-bf66-6684-9efc-b15b8dcd6042@gmail.com>
Message-ID: <E0D9C5E15741224AB7AA910ECEB678E50AB26FA3@Ci011.cawthron.org.nz>

Thanks for your prompt reply Duncan.  

I had indeed assumed they were what the help file says until observation raised doubts, which is why I queried it.

>From reading the code for termplot(), it seems that either the predict() function doesn't return the 1x standard error, or the curves plotted by the termplot() function are not 1x standard errors.  If they're not 1x standard errors, it seems misleading to call them (e.g. in the help file) "standard errors".

The "se.fit" returned by a call in termplot() to predict() is multiplied by 2 (in termplot's function se.lines()) before it is plotted as a curve described as "standard errors" by the help file.

Thus, again, it seems that either termplot() is not plotting standard errors, or predict() is not returning standard errors in se.fit.

Cheers,

Eric

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Wednesday, 29 June 2016 12:02
To: Eric Goodwin <Eric.Goodwin at cawthron.org.nz>; r-help at R-project.org
Subject: Re: [R] termplot intervals - SE or CI?

On 28/06/2016 4:53 PM, Eric Goodwin wrote:
> Hello,
>
> A reviewer queried what the intervals were on the termplot I provided in a report.  The help file for termplot() suggests they're standard errors (se=T), but in the code the se.fit values from predict() are multiplied by 2, suggesting it's a rough 95% confidence interval, is that right?

I would assume they are what the help file says, but if I wasn't sure, I'd work them out for a simple case from first principles, and compare to what the code gives.

Duncan Murdoch


> Many thanks,
>
> Eric Goodwin
> Scientific data analyst | Coastal and Freshwater Group Cawthron 
> Institute Phone +64 (0)3 548 2319 | Mobile 027 439 1141 
> eric.goodwin at cawthron.org.nz<mailto:eric.goodwin at cawthron.org.nz> | 
> www.cawthron.org.nz<http://www.cawthron.org.nz/>
>
>
> ######################################################################
> ###############
>
> Note:
> This message is for the named person's use only.  It=2...{{dropped:30}}


From devazresearch at gmail.com  Thu Jan 11 02:49:16 2018
From: devazresearch at gmail.com (deva d)
Date: Thu, 11 Jan 2018 02:49:16 +0100
Subject: [R] R-hts
Message-ID: <CAKuYVCXxxpEvbet2kBLg4Vd3wSGybZrSaG1QTZQbt4YbiRAqkA@mail.gmail.com>

thanks jeff and jeremie,

i am attaching 40 rows of the data, randomly picked from the large table.

the vars are - entity (1-46, with some missing IDs not included due to
missing data), group (1/2), sub group (1/2/3/4), year (2002-2016), y, x1
and x2 - large values included due to size of players - (may not be
considered as outliers as they constitute the sample and are important
countrywide entities)

hope this helps.

i thought an hts may be a better analytical tool compared to panel (a pivot
table in excel helps me obtain some aggregation), hence the query ...

thanks for your guidance,

*....*

*Deva*


...............



*in search of knowledge, everyday something is added ....*

*in search of wisdom, everyday something is dropped  ... an old Chinese
Proverb*
:::::::::::::::::::::::::

On Thu, Jan 11, 2018 at 12:22 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Sorry J?r?mie, I mis-read who the OP was. Deva needs to get the ball
> rolling.
>
> I would say that for a hierarchical analysis the sample data generally
> needs to be larger than for other types of analysis to illustrate
> correlation between classification variables or the example calculation
> will break. That is, 10 rows will likely be insufficient for a dry run.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> On January 10, 2018 2:02:29 PM PST, Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us> wrote:
> >You are the one with data. Supply what you have (or a simulated version
> >of same, hence the reading recommendation) using dput, and someone may
> >suggest how to transform it. In most cases a simple tabular format
> >(data frame) is sufficient.
> >--
> >Sent from my phone. Please excuse my brevity.
> >
> >On January 10, 2018 12:20:47 PM PST, "J?r?mie Juste"
> ><jeremiejuste at gmail.com> wrote:
> >>Hello,
> >>
> >>It's difficult to help without a sample of the format. Can you provide
> >>a
> >>short sample like 10 lines and a few columns.?
> >>
> >>Best regards,
> >>Jeremie
> >>
> >>
> >>On Wed, Jan 10, 2018 at 6:12 PM, John Kane via R-help
> >><r-help at r-project.org>
> >>wrote:
> >>
> >>> Have a look at
> >>http://stackoverflow.com/questions/5963269/how-to-make-
> >>> a-great-r-reproducible-example
> >>> and
> >>> http://adv-r.had.co.nz/Reproducibility.html
> >>>
> >>>
> >>>
> >>>
> >>>     On Wednesday, January 10, 2018, 11:51:22 AM EST, deva d <
> >>> devazresearch at gmail.com> wrote:
> >>>
> >>>  dear all,
> >>>
> >>> i need some help in structuring my data file for a hierarchical time
> >>series
> >>> analysis.
> >>>
> >>> can someone help please ?
> >>>
> >>> i have a 600 row database in the nature of a panel data, with 3 time
> >>series
> >>> values of interest. the data also has 4 classificatory variables
> >>comprising
> >>> a code for each entity in the panel, a value for time (year), and
> >>> classification of type of entity and a further sub-group of the
> >type.
> >>>
> >>> i am unable to structure the data file for performing the hts
> >>analysis.
> >>>
> >>> thanks in advance.
> >>>
> >>> *....*
> >>>
> >>> *Deva*
> >>>
> >>>
> >>> ...............
> >>>
> >>>
> >>>
> >>> *in search of knowledge, everyday something is added ....*
> >>>
> >>> *in search of wisdom, everyday something is dropped  ... an old
> >>Chinese
> >>> Proverb*
> >>> :::::::::::::::::::::::::
> >>>
> >>>     [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/
> >>> posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/
> >>> posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >>
> >>--
> >>J?r?mie Juste
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >>______________________________________________
> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide
> >>http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From pdalgd at gmail.com  Thu Jan 11 09:29:00 2018
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 11 Jan 2018 09:29:00 +0100
Subject: [R] termplot intervals - SE or CI?
In-Reply-To: <E0D9C5E15741224AB7AA910ECEB678E50AB26FA3@Ci011.cawthron.org.nz>
References: <E0D9C5E15741224AB7AA910ECEB678E50A4C7C61@ci011.cawthron.org.nz>
 <e9bb293e-bf66-6684-9efc-b15b8dcd6042@gmail.com>
 <E0D9C5E15741224AB7AA910ECEB678E50AB26FA3@Ci011.cawthron.org.nz>
Message-ID: <7E257835-0EAA-4731-8553-88783BF789D4@gmail.com>

From ?termplot:

col.se, lty.se, lwd.se: color, line type and line width for the
          ?twice-standard-error curve? when ?se = TRUE?.

...which is findable, but might usefully also be made explicit in the definition of the se= argument.

-pd

> On 10 Jan 2018, at 23:27 , Eric Goodwin <Eric.Goodwin at cawthron.org.nz> wrote:
> 
> Thanks for your prompt reply Duncan.  
> 
> I had indeed assumed they were what the help file says until observation raised doubts, which is why I queried it.
> 
> From reading the code for termplot(), it seems that either the predict() function doesn't return the 1x standard error, or the curves plotted by the termplot() function are not 1x standard errors.  If they're not 1x standard errors, it seems misleading to call them (e.g. in the help file) "standard errors".
> 
> The "se.fit" returned by a call in termplot() to predict() is multiplied by 2 (in termplot's function se.lines()) before it is plotted as a curve described as "standard errors" by the help file.
> 
> Thus, again, it seems that either termplot() is not plotting standard errors, or predict() is not returning standard errors in se.fit.
> 
> Cheers,
> 
> Eric
> 
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
> Sent: Wednesday, 29 June 2016 12:02
> To: Eric Goodwin <Eric.Goodwin at cawthron.org.nz>; r-help at R-project.org
> Subject: Re: [R] termplot intervals - SE or CI?
> 
> On 28/06/2016 4:53 PM, Eric Goodwin wrote:
>> Hello,
>> 
>> A reviewer queried what the intervals were on the termplot I provided in a report.  The help file for termplot() suggests they're standard errors (se=T), but in the code the se.fit values from predict() are multiplied by 2, suggesting it's a rough 95% confidence interval, is that right?
> 
> I would assume they are what the help file says, but if I wasn't sure, I'd work them out for a simple case from first principles, and compare to what the code gives.
> 
> Duncan Murdoch
> 
> 
>> Many thanks,
>> 
>> Eric Goodwin
>> Scientific data analyst | Coastal and Freshwater Group Cawthron 
>> Institute Phone +64 (0)3 548 2319 | Mobile 027 439 1141 
>> eric.goodwin at cawthron.org.nz<mailto:eric.goodwin at cawthron.org.nz> | 
>> www.cawthron.org.nz<http://www.cawthron.org.nz/>
>> 
>> 
>> ######################################################################
>> ###############
>> 
>> Note:
>> This message is for the named person's use only.  It=2...{{dropped:30}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From russell-lenth at uiowa.edu  Wed Jan 10 18:01:40 2018
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Wed, 10 Jan 2018 17:01:40 +0000
Subject: [R] [FORGED] Error occurring in "emmeans" package for the two
 data sets I used. Please help.
In-Reply-To: <CACLgfx2GeP6O1QqO2hSgo5be-HtHLYZRJpxh_NXdwzenK3szXA@mail.gmail.com>
References: <CACLgfx1BtE5dd4ELTu6rHva48zJ0AGfJ1PzH7323_iqD9WGG=A@mail.gmail.com>
 <3ab856eb-4d56-a2a9-9ea5-3bc9bb1a25e9@auckland.ac.nz>
 <ea1e0624-8de1-fafb-e4c9-92ff232d86e0@gmail.com>
 <CACLgfx2-tUHQSvZ=74iaCxNDFdMCf6Z8+GH79pd9q6rGTN7n+A@mail.gmail.com>
 <CACLgfx35fU0O8CKUFJDmh4xUha7oTAKwGMD9bSSAewu-A4W3RQ@mail.gmail.com>
 <CACLgfx2GeP6O1QqO2hSgo5be-HtHLYZRJpxh_NXdwzenK3szXA@mail.gmail.com>
Message-ID: <DM5PR04MB076229D2BCB4F9AF12EBF803F1110@DM5PR04MB0762.namprd04.prod.outlook.com>

This seems to be an entirely new question.

The ?plot.emmGrid()? function returns a graphic object of class ?ggplot? (by default) or ?lattice? (if called with ?engine = ?lattice??). You should use the provisions in those respective packages (ggplot2 or lattice) to control the details of the plot. In the case of lattice, additional arguments are passed via ?...? in the call. In the case of ggplot, one may ?add? other ggplot:: functions to modify the plot.

Russ

Russell V. Lenth? -? Professor Emeritus
Department of Statistics and Actuarial Science?? 
The University of Iowa ?-? Iowa City, IA 52242? USA?? 
Voice (319)335-0712 (Dept. office)? -? FAX (319)335-3017




From: Akhilesh Singh [mailto:akhileshsingh.igkv at gmail.com] 
Sent: Wednesday, January 10, 2018 12:45 AM
To: Sal Mangiafico <salvatore.s.mangiafico at gmail.com>
Cc: Rolf Turner <r.turner at auckland.ac.nz>; r-help mailing list <r-help at r-project.org>; Lenth, Russell V <russell-lenth at uiowa.edu>
Subject: Re: [R] [FORGED] Error occurring in "emmeans" package for the two data sets I used. Please help.

Thanks for your kind reply. Problem is solved. However, it's "confidence interval / treatment comparison plot" is not taking main title. And the fonts of axes labels can not be changed using 'cex' parameter. I will appreciate if you could help in this matter too.

Dr. A. K. Singh

On 09-Jan-2018 8:18 PM, "Sal Mangiafico" <mailto:salvatore.s.mangiafico at gmail.com> wrote:
One way to avoid this error is to create the aov without using the with function, but instead use the data= option in the aov function.
That is,
medley2 = aov(diversity ~ zinc, data=medley.clementis)
emmeans::emmeans(medley2, "zinc")
You can see the difference in the calls:
medley2$call
medley.clementis.aov$call
This works for the other data set as well, e.g.
keough2 = aov(serpulid.ln ~ biofilm, data=keough.raimondi.ln)
~ Sal Mangiafico

On 1/8/2018 4:44 PM, Rolf Turner wrote:

On 07/01/18 02:19, Akhilesh Singh wrote: 


I am a Professor of Statistics at Indira Gandhi Krishi Vishwavidyalaya, 
Raipur, India. While teaching in class about analysis of variance using R, 
I was doing a one-way analysis for the two data-sets given below in the 
R-class. I got a typical error in "emmeans" package, please help: 

Data-set-1: 
-------------- 
Medley and Clements (1998) investigated the impact of zinc contamination 
(and other heavy metals) on the diversity of diatom species in the USA 
Rocky Mountains. The diversity of diatoms (number of species) and degree of 
zinc contamination (categorized as either of high, medium, low or natural 
background level) were recorded from between four and six sampling stations 
within each of six streams known to be polluted, as given below: 

stream=c("Eagle", "Eagle", "Eagle", "Eagle", "Blue", "Blue", 
????????? "Blue", "Blue", "Blue", "Blue", "Blue", "Snake", "Snake", 
????????? "Snake", "Snake", "Snake", "Arkan", "Arkan", "Arkan", 
????????? "Arkan", "Arkan", "Arkan", "Arkan", "Chalk", "Chalk", 
????????? "Chalk", "Chalk", "Chalk", "Splat", "Splat", "Splat", 
????????? "Splat", "Splat", "Splat") 

zinc=c("BACK", "HIGH", "HIGH", "MED", "BACK", "HIGH", "BACK", "BACK", 
??????? "HIGH", "MED", "MED", "BACK", "MED", "HIGH", "HIGH", "HIGH", 
??????? "LOW", "LOW", "LOW", "LOW", "MED", "MED", "LOW", "LOW", 
??????? "HIGH", "HIGH", "MED", "LOW", "BACK", "BACK", "MED", "LOW", 
??????? "MED", "BACK") 

diversity=c(2.27, 1.25, 1.15, 1.62, 1.7, 0.63, 2.05, 1.98, 1.04, 
???????????? 2.19, 2.1, 2.2, 2.06, 1.9, 1.88, 0.85, 1.4, 2.18, 1.83, 
???????????? 1.88, 2.02, 1.94, 2.1, 2.38, 1.43, 1.37, 1.75, 2.83, 
???????????? 1.53, 0.76, 0.8, 1.66, 0.98, 1.89) 

medley.clementis=data.frame(stream,zinc,diversity) 

I did the one-way anova: 
------------------------------- 

medley.clementis.aov=with(medley.clementis, aov(diversity ~ zinc)) 

anova(medley.clementis) 

Then, I tried to do post hoc analysis using "emmeans" package following 
command: 
----------------------------------------------------------------------------------------------- 

emmeans::emmeans(medley.clementis.aov, "zinc") 


This gives following error: 
---------------------------------- 
Error in recover_data.call(fcall, delete.response(terms(object)), 
object$na.action,? : 
?? object 'possibly.random' not found 
Error in ref_grid(object, ...) : 
?? Perhaps a 'data' or 'params' argument is needed 



Data-set-2: 
--------------- 
Keough and Raimondi (1995) examined the effects of four biofilm types (SL: 
sterile unfilmed substrate, NL: netted laboratory biofilms, UL: unnetted 
laboratory biofilms and F: netted field biofilms) on the recruitment of 
serpulid larvae. Substrates treated with one of the four biofilm types were 
left in shallow marine waters for one week after which the number of newly 
recruited serpulid worms were counted, as given below: 

biofilm=c("SL", "SL", "SL", "SL", "SL", "SL", "SL", "UL", "UL", "UL", 
?????????? "UL", "UL", "UL", "UL", "NL", "NL", "NL", "NL", "NL", "NL", 
?????????? "NL", "F", "F", "F", "F", "F", "F", "F") 

serpulid=c(61, 113, 123, 75, 75, 83, 95, 143, 81, 101, 155, 156, 193, 
??????????? 163, 203, 159, 139, 161, 179, 97, 157, 128.5, 204.5, 
??????????? 108.5, 116.5, 140.5, 160.5, 87.5) 

keough.raimondi=data.frame(biofilm,serpulid) 

Applied log-transformation: 
------------------------------------------- 
keough.raimondi.ln=transform(keough.raimondi, serpulid.ln=log(serpulid)) 

I did the one-way anova, with contrasts defined below: 
------------------------------------------------------------------------ 
contrasts(keough.raimondi.ln$biofilm) <- cbind(c(0, 1, 0, -1), 
???????????????????????????? c(2, -1, 0, -1), c(-1, -1, 3, -1)) 
keough.raimondi.ln$biofilm 

keough.contr.list <- list(biofilm = list('NL vs UL' = 1, 
?????????????? 'F vs (NL & UL)' = 2, 'SL vs (F & NL & UL)' = 3)) 
keough.contr.list 

One-way anova: 
---------------------- 
keough.raimondi.ln.aov=with(keough.raimondi.ln, aov(serpulid.ln ~ biofilm)) 

summary(keough.raimondi.ln.aov,split=keough.contr.list) 


Then, I tried to do post hoc analysis using "emmeans" package following 
command: 
----------------------------------------------------------------------------------------------- 

emmeans(keough.raimondi.ln.aov, ~ biofilm) 


This gives following error: 
---------------------------------- 
Error in recover_data.call(fcall, delete.response(terms(object)), 
object$na.action,? : 
?? object 'possibly.random' not found 
Error in ref_grid(object, ...) : 
?? Perhaps a 'data' or 'params' argument is needed 


Help Needed: 
------------------ 
On many other data sets and data frame I successfully used "emmeans" 
package using the help available in R. 

But, for the above two data-sets, I consistently got the same error as 
described above. 

I do not know what is amiss. Where I am missing or whatever is wrong, I 
request the entire R-team to help me to solve above problem. 

Well, you don't need the *entire* R-team!!! It probably (in some sense) includes millions of people. :-) 


Thanking in advance. 

Thanks for your thorough and well set out description of the problem. 
Your reproducible examples were flawless. 

I am not *completely* certain, but this looks to me like a bug in emmeans. 

I have therefore taken the liberty of cc-ing this reply to Russell Lenth (the maintainer of emmeans) to get his take on the issue. 

cheers, 

Rolf Turner 



From piburnjo at ornl.gov  Wed Jan 10 16:18:59 2018
From: piburnjo at ornl.gov (Piburn, Jesse O.)
Date: Wed, 10 Jan 2018 15:18:59 +0000
Subject: [R] [R-pkgs] Release of wbstats 0.2 on CRAN
Message-ID: <5b0a5b51692f497d8eb4683229f1beaa@EXCHCS35.ornl.gov>

Hi all

I'm happy to announce a new version of wbstats is now available on CRAN.

wbstats is an R package for searching and downloading data from the World Bank API that includes access to all annual, monthly, and quarterly indicators

in addition to bug fixes. Version 0.2 now

  *   Uses version 2 of the World Bank API. This includes data that is unavailable in the previous world bank API
  *   Has the ability to return data in a "wide" format (indicators are columns) with the return_wide = TRUE option
  *   More explicit error messaging
  *   Has a lastUpdated field for each data source


CRAN: https://CRAN.R-project.org/package=wbstats
Github: https://github.com/GIST-ORNL/wbstats

A getting started with wbstats article, including examples with sf, ggplot2, and leaflet
https://jesse.netlify.com/2018/01/05/getting-started-with-wbstats-a-world-bank-r-package/


Thanks!
Jesse


Jesse Piburn
Research Scientist in Geographic Data Sciences
Geographic Information Science & Technology Group
Computational Sciences and Engineering Division
Oak Ridge National Laboratory
1 Bethel Valley Road P.O. Box 2008 MS-6134
Oak Ridge, TN 37831 6134
Office Phone: 865 576 9318
Mobile Phone (preferred): 865 621 9034
Email: piburnjo at ornl.gov


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From simon.wood at bath.edu  Thu Jan 11 18:25:30 2018
From: simon.wood at bath.edu (Simon Wood)
Date: Thu, 11 Jan 2018 17:25:30 +0000
Subject: [R] GAM Poisson
In-Reply-To: <CAMLwc7Na59in7aVRxf6oBuk4YepsjaBsaUOdwi3VazZKcnL7Sw@mail.gmail.com>
References: <CAMLwc7Na59in7aVRxf6oBuk4YepsjaBsaUOdwi3VazZKcnL7Sw@mail.gmail.com>
Message-ID: <e9a25b1c-1ffa-0e0e-eebf-689617f62886@bath.edu>

Not exactly, as by default you are using a log link in the Poisson 
model, but not the Gaussian model. Simon


On 14/12/17 22:57, Miluji Sb wrote:
> Dear all,
>
> I apologize as this may not be a strictly R question. I am running GAM
> models using the mgcv package.
>
> I was wondering if the interpretation of the smooth splines of the 'x'
> variable is the same in the following two cases:
>
> # Linear probability model
> m1 <- gam(count ~ factor(city) + factor(year) + s(x),
> data=data,na.action=na.omit)
>
> # Poisson
> m2 <- gam(count ~ factor(city) + factor(year) + s(x),data=data,
> family=poisson,na.action=na.omit)
>
> Thank you!
>
> Sincerely,
>
> Milu
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
+44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190


From mramzi43 at gmail.com  Thu Jan 11 20:15:51 2018
From: mramzi43 at gmail.com (muhammad ramzi)
Date: Fri, 12 Jan 2018 03:15:51 +0800
Subject: [R] application of R
Message-ID: <CAFk3T_d3xtYrL3kARgmK5G=xyYM0+dg7WzzTKcQkc1Mk_HGTWw@mail.gmail.com>

hello guys,

i am a petroleum engineering student and i will be having a long semester
break and currently i am learning THE R PROGRAMMING LANGUAGE just out of
interest. I would just like to know if i am able to design a business
analysis software using R as in create a type of software that can be sold
to business people. can this be done in R language?

another thing is if i do learn this all the way, what advantages will it
give me in terms of future prospects and career development?

	[[alternative HTML version deleted]]


From Eric.Goodwin at cawthron.org.nz  Thu Jan 11 20:52:44 2018
From: Eric.Goodwin at cawthron.org.nz (Eric Goodwin)
Date: Thu, 11 Jan 2018 19:52:44 +0000
Subject: [R] termplot intervals - SE or CI?
In-Reply-To: <7E257835-0EAA-4731-8553-88783BF789D4@gmail.com>
References: <E0D9C5E15741224AB7AA910ECEB678E50A4C7C61@ci011.cawthron.org.nz>
 <e9bb293e-bf66-6684-9efc-b15b8dcd6042@gmail.com>
 <E0D9C5E15741224AB7AA910ECEB678E50AB26FA3@Ci011.cawthron.org.nz>
 <7E257835-0EAA-4731-8553-88783BF789D4@gmail.com>
Message-ID: <E0D9C5E15741224AB7AA910ECEB678E50AB282D1@Ci011.cawthron.org.nz>

Peter,

Thanks very much.  Good spotting, and that confirms what I'd deduced from the code.

I think you're right that it would be useful to either make that explicit in the definition of the se argument (and in the description, which also describes them as standard errors), or expose the ff argument of the se.lines() function, so that it can be set during the call to termplot(), by the user.  The selection of 2.0 as a scaling factor is presumably an approximation of 1.96, to give roughly 95% confidence intervals, but it's possible users might want to specify some other scaling factor.

Cheers,

Eric Goodwin

-----Original Message-----
From: peter dalgaard [mailto:pdalgd at gmail.com] 
Sent: Thursday, 11 January 2018 21:29
To: Eric Goodwin <Eric.Goodwin at cawthron.org.nz>
Cc: Duncan Murdoch <murdoch.duncan at gmail.com>; r-help at R-project.org
Subject: Re: [R] termplot intervals - SE or CI?

From ?termplot:

col.se, lty.se, lwd.se: color, line type and line width for the
          ?twice-standard-error curve? when ?se = TRUE?.

...which is findable, but might usefully also be made explicit in the definition of the se= argument.

-pd

> On 10 Jan 2018, at 23:27 , Eric Goodwin <Eric.Goodwin at cawthron.org.nz> wrote:
> 
> Thanks for your prompt reply Duncan.  
> 
> I had indeed assumed they were what the help file says until observation raised doubts, which is why I queried it.
> 
> From reading the code for termplot(), it seems that either the predict() function doesn't return the 1x standard error, or the curves plotted by the termplot() function are not 1x standard errors.  If they're not 1x standard errors, it seems misleading to call them (e.g. in the help file) "standard errors".
> 
> The "se.fit" returned by a call in termplot() to predict() is multiplied by 2 (in termplot's function se.lines()) before it is plotted as a curve described as "standard errors" by the help file.
> 
> Thus, again, it seems that either termplot() is not plotting standard errors, or predict() is not returning standard errors in se.fit.
> 
> Cheers,
> 
> Eric
> 
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Wednesday, 29 June 2016 12:02
> To: Eric Goodwin <Eric.Goodwin at cawthron.org.nz>; r-help at R-project.org
> Subject: Re: [R] termplot intervals - SE or CI?
> 
> On 28/06/2016 4:53 PM, Eric Goodwin wrote:
>> Hello,
>> 
>> A reviewer queried what the intervals were on the termplot I provided in a report.  The help file for termplot() suggests they're standard errors (se=T), but in the code the se.fit values from predict() are multiplied by 2, suggesting it's a rough 95% confidence interval, is that right?
> 
> I would assume they are what the help file says, but if I wasn't sure, I'd work them out for a simple case from first principles, and compare to what the code gives.
> 
> Duncan Murdoch
> 
> 
>> Many thanks,
>> 
>> Eric Goodwin
>> Scientific data analyst | Coastal and Freshwater Group Cawthron 
>> Institute Phone +64 (0)3 548 2319 | Mobile 027 439 1141 
>> eric.goodwin at cawthron.org.nz<mailto:eric.goodwin at cawthron.org.nz> | 
>> www.cawthron.org.nz<http://www.cawthron.org.nz/>
>> 
>> 
>> #####################################################################
>> #
>> ###############
>> 
>> Note:
>> This message is for the named person's use only.  
>> It=2...{{dropped:30}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com










#####################################################################################

Note:
This message is for the named person's use only.  It may contain confidential, proprietary or legally privileged information.  If you receive this message in error, please immediately delete it and all copies of it from your system, destroy any hard copies of it and notify the 
sender.  You must not, directly or indirectly, use, disclose, distribute, print, or copy any part of this message if you are not the intended recipient. Cawthron reserves the right to monitor all e-mail communications through its networks. Any opinions expressed in this 
message are those of the individual sender, except where the message states otherwise and the sender is authorised to make that statement.

This e-mail message has been scanned and cleared by MailMarshal 
#####################################################################################

From marc_schwartz at me.com  Thu Jan 11 21:43:15 2018
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 11 Jan 2018 15:43:15 -0500
Subject: [R] application of R
In-Reply-To: <CAFk3T_d3xtYrL3kARgmK5G=xyYM0+dg7WzzTKcQkc1Mk_HGTWw@mail.gmail.com>
References: <CAFk3T_d3xtYrL3kARgmK5G=xyYM0+dg7WzzTKcQkc1Mk_HGTWw@mail.gmail.com>
Message-ID: <E4B06B10-BC38-49D0-A928-49190BD57894@me.com>



> On Jan 11, 2018, at 2:15 PM, muhammad ramzi <mramzi43 at gmail.com> wrote:
> 
> hello guys,
> 
> i am a petroleum engineering student and i will be having a long semester
> break and currently i am learning THE R PROGRAMMING LANGUAGE just out of
> interest. I would just like to know if i am able to design a business
> analysis software using R as in create a type of software that can be sold
> to business people. can this be done in R language?
> 
> another thing is if i do learn this all the way, what advantages will it
> give me in terms of future prospects and career development?


Hi,

To your first question, as R is open source and released under the GPL, there are legal issues that you will need to consider, which will be specific to the details of your plans, how your "application" is built, how it interacts with R, and importantly, the copying and distribution of the end product.

You should, first and foremost, contact a lawyer familiar with open source software, specifically GPL compatible licenses, so that you can get proper legal advice, which you will not get here. You risk legal/financial liabilities down the road if not done in compliance with the license requirements.

As a first pass, you should read:

  https://cran.r-project.org/doc/FAQ/R-FAQ.html#Can-I-use-R-for-commercial-purposes_003f

and

  https://www.gnu.org/licenses/old-licenses/gpl-2.0-faq.html

so that you can gain initial insights into some of the general implications of building a product for distribution (whether you give it away or sell it) that depends upon a GPL licensed application. 

Whether or not there is utility for the application you envision such that people would be willing to pay for it, will depend upon a variety of factors, not the least of which is what competition you face and the value of your planned application over others that are already in the marketplace.

To your second question, you are asking a biased, self selected audience. Thus, take that into account for any responses that you may get.

The responses relative to advantages are going to be, to some extent, broadly industry specific. That being said, in many domains, knowing R, along with other relevant applications and programming languages can only be beneficial in many cases.

R is becoming increasingly popular (e.g. see: https://www.tiobe.com/tiobe-index/). However, depending upon the subject matter domain you will work in and to a large extent, the company or institution you will work for, those factors can have a material influence on the role that R might play in that environment.

Others can perhaps chime in with other thoughts and perhaps even industry specific insights for you.

Regards,

Marc Schwartz


From karagullemre at gmail.com  Thu Jan 11 22:02:32 2018
From: karagullemre at gmail.com (=?utf-8?Q?Emre_Karag=C3=BClle?=)
Date: Fri, 12 Jan 2018 00:02:32 +0300
Subject: [R] Fwd: Time Series with Neural Networks
References: <5a4209e6.429a500a.5852b.942c@mx.google.com>
Message-ID: <5DB50874-CCE1-4A55-B687-6E60A54F36E5@gmail.com>


> Hi,
> I am would like to ask few questions.
> I am trying to forecast  hourly electricity prices by 24 hours ahead.
> I have hourly data starting from 2015*12*18 to 2017-10-24
> and I have defined the data as time series as written in the code below.
>  
> Then I am trying do neural network with 23 non-seasonal dummies and 1 seasonal dummy.
> But I don?t know whether training set is enough.( Guess it is 50 hours in here?)
>  
> The problem is that I couldn?t 24 for output here. How can I make such forecast?
> And my MASE score (6.95 in the Test set) is not good. Could be related to shortness of training set?
>  
> The Code:
>  
> library(zoo)
> library(readxl)
> setwd("C:/Users/emrek/Dropbox/2017-2018 Master Thesis/DATA")
> epias <- read_excel("eski.epias.xlsx")
>  
>  
> nPTF <- epias$`PTF (TL/MWh)`
> nSMF<- epias$`SMF(TL/MWh)`
> nC<- epias$`TT(MWh)`
> nEAK<- epias$`EAK-Toplam (MWh)`
> nTP<- epias$`Toplam (MWh)`
>  
> times     <- seq(from=as.POSIXct("2015-12-18 00:00:00"), to=as.POSIXct("2017-10-24 23:00:00"), by="hour")
> mydata <- rnorm(length(times))
>  
> PTF <- zoo(nPTF, order.by=times )
> SMF <- zoo(nSMF, order.by=times )
> C <- zoo(nC, order.by=times )
> EAK <- zoo(nEAK, order.by=times )
> TP<- zoo(nTP, order.by=times )
> SH <- (EAK-TP)
>  
> epias <- cbind(PTF,C,SH)
> View(epias)
>  
> #neural networks
> library(forecast)
> set.seed(201)
> epias.nn <- nnetar(PTF, repeats = 50, p=23, P=1, size =12)
> summary(epias.nn$model[[1]])
>  
> epias.pred <- forecast(epias.nn, h= 24)
> accuracy(epias.pred, 24)
>  
> plot(PTF, ylim=c(0,500) , ylab=  , xlab= , bty="l", xaxt="n", xlim=c(as.POSIXct("2017-10-20 00:00:00"),as.POSIXct("2017-10-25 23:00:00")) , lty=1 )
>  
> lines(epias.pred$fitted,lwd = 2,col="blue")
>  
>  
> Best Regards,
> --
> Emre
>  

	[[alternative HTML version deleted]]


From alemtzb at ciencias.unam.mx  Thu Jan 11 23:33:42 2018
From: alemtzb at ciencias.unam.mx (=?UTF-8?Q?Alejandra_Mart=C3=ADnez_Blancas?=)
Date: Thu, 11 Jan 2018 16:33:42 -0600
Subject: [R] setting constraints on gam
Message-ID: <CAJ9CH8W-NKch4ns9r10i=GqLxw+yRH=ZRiqkQ6Tr8OaeFxDRdw@mail.gmail.com>

I am fitting a model in which the response variable y is a function of
two independent, quantitative variables x1 and x2; thus: y = f(x1,
x2). For reasons I do not believe to be important for the purpose of
this post, I find it desirable to find f by means of GAM; also, I
require principal effects and interactions to be specified separately,
so I am using using te and ti tensors. Thus, I am using the following
command:



f = gam(y ~ te(x1) + te(x2) + ti(x1, x2))



This results in a model that corresponds to one of the hypotheses I am
testing. Nevertheless, another hypothesis requires that, when one of
the independent variables (say x2) is zero, the value of y is
unaffected by the other variable (in this example x1). In other words
f(x1, 0) = k for every value of x1, where k is a constant to be
estimated. For x2 values other than zero I would like to let GAM
choose the appropriate function relating x1 and y. Is there a way to
specify such model in mgcv?


From orvaquim at gmail.com  Fri Jan 12 00:21:28 2018
From: orvaquim at gmail.com (Orvalho Augusto)
Date: Thu, 11 Jan 2018 15:21:28 -0800
Subject: [R] Information installation package sjPlot
In-Reply-To: <CWXP265MB0216F34FD9C21931FD0C1133F6110@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>
References: <CWXP265MB0216F34FD9C21931FD0C1133F6110@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <CAF4WX-dVwyBd5tQEDKOuGZswiYyWEY8+4YCbyG86fbeH4ZWTwQ@mail.gmail.com>

That is very strange.

I am using Ubuntu 16.04 and managed to install it in less than 5 minutes.

OA

On Wed, Jan 10, 2018 at 12:00 PM, Luca Danieli <mr.lucedan at hotmail.it>
wrote:

> Hi all,
>
> I am new. I am installing the library sjPlot on Ubunto 16.10 and I guess
> it is installing some dependencies. But it is taking more than 1.5 hours,
> is it possible?
>
> It has right now halted (hope momentarily) in installing the package
> 'rstan', particularly the file lang__grammars__statement_grammar_inst.o
>
> Other packages installed include: dygraphs, colourpicker, raster.
>
> Is it good or is something going wrong?
>
> Luca
>
> Get Outlook for Android<https://aka.ms/ghei36>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From abouelmakarim1962 at gmail.com  Fri Jan 12 01:43:05 2018
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Thu, 11 Jan 2018 19:43:05 -0500
Subject: [R] shading (fill) the area between two lines
Message-ID: <CAE9stmehj9Aw8qtsUe69A2M5UANerPw6G2n3NfqA5oqdz0VW0g@mail.gmail.com>

Dear All:


I am trying to shade the area between the two lines; *line 1* and *line 2*.



You can use this code as an example.


x100<-c(-1,1,2,3,4,5,6,3)
y100<-c(4,5,3,1,4,4,2,-1)

plot(x100,y100)


*#####  line1*

abline(a=-(Beta0-1)/Beta[1,2], b=-Beta[1,1]/Beta[1,2], lwd = 3,
col="skyblue", lty=3) ##### lty=3,

*##### line 2*

abline(a=-(Beta0+1)/Beta[1,2], b=-Beta[1,1]/Beta[1,2], lwd = 3,
col="skyblue", lty=3) ##### lty=3,




thank you very much for your help
with thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Jan 12 01:49:15 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 11 Jan 2018 19:49:15 -0500
Subject: [R] shading (fill) the area between two lines
In-Reply-To: <CAE9stmehj9Aw8qtsUe69A2M5UANerPw6G2n3NfqA5oqdz0VW0g@mail.gmail.com>
References: <CAE9stmehj9Aw8qtsUe69A2M5UANerPw6G2n3NfqA5oqdz0VW0g@mail.gmail.com>
Message-ID: <ee5b176a-4ea8-2462-1434-e220746ffa89@gmail.com>

On 11/01/2018 7:43 PM, AbouEl-Makarim Aboueissa wrote:
> Dear All:
> 
> 
> I am trying to shade the area between the two lines; *line 1* and *line 2*.

The help page for polygon() gives some examples of this.

Duncan Murdoch
> 
> 
> 
> You can use this code as an example.
> 
> 
> x100<-c(-1,1,2,3,4,5,6,3)
> y100<-c(4,5,3,1,4,4,2,-1)
> 
> plot(x100,y100)
> 
> 
> *#####  line1*
> 
> abline(a=-(Beta0-1)/Beta[1,2], b=-Beta[1,1]/Beta[1,2], lwd = 3,
> col="skyblue", lty=3) ##### lty=3,
> 
> *##### line 2*
> 
> abline(a=-(Beta0+1)/Beta[1,2], b=-Beta[1,1]/Beta[1,2], lwd = 3,
> col="skyblue", lty=3) ##### lty=3,
> 
> 
> 
> 
> thank you very much for your help
> with thanks
> abou
> ______________________
> 
> 
> *AbouEl-Makarim Aboueissa, PhD*
> 
> *Professor of Statistics*
> 
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mramzi43 at gmail.com  Fri Jan 12 04:09:20 2018
From: mramzi43 at gmail.com (muhammad ramzi)
Date: Fri, 12 Jan 2018 11:09:20 +0800
Subject: [R] application of R
In-Reply-To: <E4B06B10-BC38-49D0-A928-49190BD57894@me.com>
References: <CAFk3T_d3xtYrL3kARgmK5G=xyYM0+dg7WzzTKcQkc1Mk_HGTWw@mail.gmail.com>
 <E4B06B10-BC38-49D0-A928-49190BD57894@me.com>
Message-ID: <4009BDBD-CB8F-4B3F-8944-ACFE95300E31@gmail.com>

Thank you very much this really helped me a lot . 
So actually why would people learn R(other than personal interests ) if you can't really build anything that can be sold ? I'm sorry if I'm asking bad questions 


> On 12 Jan 2018, at 4:43 AM, Marc Schwartz <marc_schwartz at me.com> wrote:
> 
> 
> 
>> On Jan 11, 2018, at 2:15 PM, muhammad ramzi <mramzi43 at gmail.com> wrote:
>> 
>> hello guys,
>> 
>> i am a petroleum engineering student and i will be having a long semester
>> break and currently i am learning THE R PROGRAMMING LANGUAGE just out of
>> interest. I would just like to know if i am able to design a business
>> analysis software using R as in create a type of software that can be sold
>> to business people. can this be done in R language?
>> 
>> another thing is if i do learn this all the way, what advantages will it
>> give me in terms of future prospects and career development?
> 
> 
> Hi,
> 
> To your first question, as R is open source and released under the GPL, there are legal issues that you will need to consider, which will be specific to the details of your plans, how your "application" is built, how it interacts with R, and importantly, the copying and distribution of the end product.
> 
> You should, first and foremost, contact a lawyer familiar with open source software, specifically GPL compatible licenses, so that you can get proper legal advice, which you will not get here. You risk legal/financial liabilities down the road if not done in compliance with the license requirements.
> 
> As a first pass, you should read:
> 
>  https://cran.r-project.org/doc/FAQ/R-FAQ.html#Can-I-use-R-for-commercial-purposes_003f
> 
> and
> 
>  https://www.gnu.org/licenses/old-licenses/gpl-2.0-faq.html
> 
> so that you can gain initial insights into some of the general implications of building a product for distribution (whether you give it away or sell it) that depends upon a GPL licensed application. 
> 
> Whether or not there is utility for the application you envision such that people would be willing to pay for it, will depend upon a variety of factors, not the least of which is what competition you face and the value of your planned application over others that are already in the marketplace.
> 
> To your second question, you are asking a biased, self selected audience. Thus, take that into account for any responses that you may get.
> 
> The responses relative to advantages are going to be, to some extent, broadly industry specific. That being said, in many domains, knowing R, along with other relevant applications and programming languages can only be beneficial in many cases.
> 
> R is becoming increasingly popular (e.g. see: https://www.tiobe.com/tiobe-index/). However, depending upon the subject matter domain you will work in and to a large extent, the company or institution you will work for, those factors can have a material influence on the role that R might play in that environment.
> 
> Others can perhaps chime in with other thoughts and perhaps even industry specific insights for you.
> 
> Regards,
> 
> Marc Schwartz
> 


From jdnewmil at dcn.davis.ca.us  Fri Jan 12 05:40:10 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 11 Jan 2018 20:40:10 -0800
Subject: [R] application of R
In-Reply-To: <4009BDBD-CB8F-4B3F-8944-ACFE95300E31@gmail.com>
References: <CAFk3T_d3xtYrL3kARgmK5G=xyYM0+dg7WzzTKcQkc1Mk_HGTWw@mail.gmail.com>
 <E4B06B10-BC38-49D0-A928-49190BD57894@me.com>
 <4009BDBD-CB8F-4B3F-8944-ACFE95300E31@gmail.com>
Message-ID: <A0AA2267-554F-42C7-A1E1-A8ADD1E1A929@dcn.davis.ca.us>

Because many technical people need to accomplish statistical data analysis with computers that depend on existing algorithms applied in new ways, or with new algorithms that are not implemented by commercial software.  Often such people have no desire to provide step-by-step support of their tools for every user of their code indefinitely, so developing commercial software for others is less useful to them than having access to existing software that can be adapted. They often find that allowing others access to their code is a reasonable trade for being able to re-use the work of others before them. 

You might read the book "The Cathedral and the Bazaar" for more detail about this perspective, but this line of discussion is not really on topic here.
-- 
Sent from my phone. Please excuse my brevity.

On January 11, 2018 7:09:20 PM PST, muhammad ramzi <mramzi43 at gmail.com> wrote:
>Thank you very much this really helped me a lot . 
>So actually why would people learn R(other than personal interests ) if
>you can't really build anything that can be sold ? I'm sorry if I'm
>asking bad questions 
>
>
>> On 12 Jan 2018, at 4:43 AM, Marc Schwartz <marc_schwartz at me.com>
>wrote:
>> 
>> 
>> 
>>> On Jan 11, 2018, at 2:15 PM, muhammad ramzi <mramzi43 at gmail.com>
>wrote:
>>> 
>>> hello guys,
>>> 
>>> i am a petroleum engineering student and i will be having a long
>semester
>>> break and currently i am learning THE R PROGRAMMING LANGUAGE just
>out of
>>> interest. I would just like to know if i am able to design a
>business
>>> analysis software using R as in create a type of software that can
>be sold
>>> to business people. can this be done in R language?
>>> 
>>> another thing is if i do learn this all the way, what advantages
>will it
>>> give me in terms of future prospects and career development?
>> 
>> 
>> Hi,
>> 
>> To your first question, as R is open source and released under the
>GPL, there are legal issues that you will need to consider, which will
>be specific to the details of your plans, how your "application" is
>built, how it interacts with R, and importantly, the copying and
>distribution of the end product.
>> 
>> You should, first and foremost, contact a lawyer familiar with open
>source software, specifically GPL compatible licenses, so that you can
>get proper legal advice, which you will not get here. You risk
>legal/financial liabilities down the road if not done in compliance
>with the license requirements.
>> 
>> As a first pass, you should read:
>> 
>> 
>https://cran.r-project.org/doc/FAQ/R-FAQ.html#Can-I-use-R-for-commercial-purposes_003f
>> 
>> and
>> 
>>  https://www.gnu.org/licenses/old-licenses/gpl-2.0-faq.html
>> 
>> so that you can gain initial insights into some of the general
>implications of building a product for distribution (whether you give
>it away or sell it) that depends upon a GPL licensed application. 
>> 
>> Whether or not there is utility for the application you envision such
>that people would be willing to pay for it, will depend upon a variety
>of factors, not the least of which is what competition you face and the
>value of your planned application over others that are already in the
>marketplace.
>> 
>> To your second question, you are asking a biased, self selected
>audience. Thus, take that into account for any responses that you may
>get.
>> 
>> The responses relative to advantages are going to be, to some extent,
>broadly industry specific. That being said, in many domains, knowing R,
>along with other relevant applications and programming languages can
>only be beneficial in many cases.
>> 
>> R is becoming increasingly popular (e.g. see:
>https://www.tiobe.com/tiobe-index/). However, depending upon the
>subject matter domain you will work in and to a large extent, the
>company or institution you will work for, those factors can have a
>material influence on the role that R might play in that environment.
>> 
>> Others can perhaps chime in with other thoughts and perhaps even
>industry specific insights for you.
>> 
>> Regards,
>> 
>> Marc Schwartz
>> 
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ericjberger at gmail.com  Fri Jan 12 06:54:39 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Fri, 12 Jan 2018 07:54:39 +0200
Subject: [R] application of R
In-Reply-To: <A0AA2267-554F-42C7-A1E1-A8ADD1E1A929@dcn.davis.ca.us>
References: <CAFk3T_d3xtYrL3kARgmK5G=xyYM0+dg7WzzTKcQkc1Mk_HGTWw@mail.gmail.com>
 <E4B06B10-BC38-49D0-A928-49190BD57894@me.com>
 <4009BDBD-CB8F-4B3F-8944-ACFE95300E31@gmail.com>
 <A0AA2267-554F-42C7-A1E1-A8ADD1E1A929@dcn.davis.ca.us>
Message-ID: <CAGgJW77qMSZUbgFrnvpzE8ToHTRWU7Y-iO76uMhpM5V8yE5_zg@mail.gmail.com>

Marc and Jeff give excellent advice. Since you have a commercial
perspective, here are two more points to consider:
1. There are companies that sell software built on R. For example, the
company Rstudio.com develops both free and "professional" versions of its
products RStudio and Shiny.
2. You ask about selling software. Switch hats and think about buying
software. Some real-world problems can be solved using commercial products
such as Matlab (which costs thousands of dollars.) For some of these
problems, the world of R (and more generally CRAN - the Comprehensive R
Archive Network - https://cran.r-project.org/ - where you can find many of
the freely available R-packages) is a great alternative and it is free.

On Fri, Jan 12, 2018 at 6:40 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Because many technical people need to accomplish statistical data analysis
> with computers that depend on existing algorithms applied in new ways, or
> with new algorithms that are not implemented by commercial software.  Often
> such people have no desire to provide step-by-step support of their tools
> for every user of their code indefinitely, so developing commercial
> software for others is less useful to them than having access to existing
> software that can be adapted. They often find that allowing others access
> to their code is a reasonable trade for being able to re-use the work of
> others before them.
>
> You might read the book "The Cathedral and the Bazaar" for more detail
> about this perspective, but this line of discussion is not really on topic
> here.
> --
> Sent from my phone. Please excuse my brevity.
>
> On January 11, 2018 7:09:20 PM PST, muhammad ramzi <mramzi43 at gmail.com>
> wrote:
> >Thank you very much this really helped me a lot .
> >So actually why would people learn R(other than personal interests ) if
> >you can't really build anything that can be sold ? I'm sorry if I'm
> >asking bad questions
> >
> >
> >> On 12 Jan 2018, at 4:43 AM, Marc Schwartz <marc_schwartz at me.com>
> >wrote:
> >>
> >>
> >>
> >>> On Jan 11, 2018, at 2:15 PM, muhammad ramzi <mramzi43 at gmail.com>
> >wrote:
> >>>
> >>> hello guys,
> >>>
> >>> i am a petroleum engineering student and i will be having a long
> >semester
> >>> break and currently i am learning THE R PROGRAMMING LANGUAGE just
> >out of
> >>> interest. I would just like to know if i am able to design a
> >business
> >>> analysis software using R as in create a type of software that can
> >be sold
> >>> to business people. can this be done in R language?
> >>>
> >>> another thing is if i do learn this all the way, what advantages
> >will it
> >>> give me in terms of future prospects and career development?
> >>
> >>
> >> Hi,
> >>
> >> To your first question, as R is open source and released under the
> >GPL, there are legal issues that you will need to consider, which will
> >be specific to the details of your plans, how your "application" is
> >built, how it interacts with R, and importantly, the copying and
> >distribution of the end product.
> >>
> >> You should, first and foremost, contact a lawyer familiar with open
> >source software, specifically GPL compatible licenses, so that you can
> >get proper legal advice, which you will not get here. You risk
> >legal/financial liabilities down the road if not done in compliance
> >with the license requirements.
> >>
> >> As a first pass, you should read:
> >>
> >>
> >https://cran.r-project.org/doc/FAQ/R-FAQ.html#Can-I-use-
> R-for-commercial-purposes_003f
> >>
> >> and
> >>
> >>  https://www.gnu.org/licenses/old-licenses/gpl-2.0-faq.html
> >>
> >> so that you can gain initial insights into some of the general
> >implications of building a product for distribution (whether you give
> >it away or sell it) that depends upon a GPL licensed application.
> >>
> >> Whether or not there is utility for the application you envision such
> >that people would be willing to pay for it, will depend upon a variety
> >of factors, not the least of which is what competition you face and the
> >value of your planned application over others that are already in the
> >marketplace.
> >>
> >> To your second question, you are asking a biased, self selected
> >audience. Thus, take that into account for any responses that you may
> >get.
> >>
> >> The responses relative to advantages are going to be, to some extent,
> >broadly industry specific. That being said, in many domains, knowing R,
> >along with other relevant applications and programming languages can
> >only be beneficial in many cases.
> >>
> >> R is becoming increasingly popular (e.g. see:
> >https://www.tiobe.com/tiobe-index/). However, depending upon the
> >subject matter domain you will work in and to a large extent, the
> >company or institution you will work for, those factors can have a
> >material influence on the role that R might play in that environment.
> >>
> >> Others can perhaps chime in with other thoughts and perhaps even
> >industry specific insights for you.
> >>
> >> Regards,
> >>
> >> Marc Schwartz
> >>
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Fri Jan 12 08:36:26 2018
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 12 Jan 2018 08:36:26 +0100
Subject: [R] application of R
In-Reply-To: <4009BDBD-CB8F-4B3F-8944-ACFE95300E31@gmail.com>
References: <CAFk3T_d3xtYrL3kARgmK5G=xyYM0+dg7WzzTKcQkc1Mk_HGTWw@mail.gmail.com>
 <E4B06B10-BC38-49D0-A928-49190BD57894@me.com>
 <4009BDBD-CB8F-4B3F-8944-ACFE95300E31@gmail.com>
Message-ID: <C79A4E1C-601B-4974-950C-BCB69473A560@xs4all.nl>


> On 12 Jan 2018, at 04:09, muhammad ramzi <mramzi43 at gmail.com> wrote:
> 
> Thank you very much this really helped me a lot . 
> So actually why would people learn R(other than personal interests ) if you can't really build anything that can be sold ? I'm sorry if I'm asking bad questions 
> 


Google with the phrase "opensource why"  and start reading.

Berend Hasselman


From mramzi43 at gmail.com  Fri Jan 12 06:17:37 2018
From: mramzi43 at gmail.com (muhammad ramzi)
Date: Fri, 12 Jan 2018 13:17:37 +0800
Subject: [R] application of R
In-Reply-To: <A0AA2267-554F-42C7-A1E1-A8ADD1E1A929@dcn.davis.ca.us>
References: <CAFk3T_d3xtYrL3kARgmK5G=xyYM0+dg7WzzTKcQkc1Mk_HGTWw@mail.gmail.com>
 <E4B06B10-BC38-49D0-A928-49190BD57894@me.com>
 <4009BDBD-CB8F-4B3F-8944-ACFE95300E31@gmail.com>
 <A0AA2267-554F-42C7-A1E1-A8ADD1E1A929@dcn.davis.ca.us>
Message-ID: <5BAD377B-5111-4481-ABA0-C53090C0BD6E@gmail.com>

Oh I see thank you very much now I understand. So for me as I am considered an intermediate in R and also C++ what kind of programming language I could take up and learn to make a commercial statistical software ? Any advices as well ?

> On 12 Jan 2018, at 12:40 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Because many technical people need to accomplish statistical data analysis with computers that depend on existing algorithms applied in new ways, or with new algorithms that are not implemented by commercial software.  Often such people have no desire to provide step-by-step support of their tools for every user of their code indefinitely, so developing commercial software for others is less useful to them than having access to existing software that can be adapted. They often find that allowing others access to their code is a reasonable trade for being able to re-use the work of others before them. 
> 
> You might read the book "The Cathedral and the Bazaar" for more detail about this perspective, but this line of discussion is not really on topic here.
> -- 
> Sent from my phone. Please excuse my brevity.
> 
>> On January 11, 2018 7:09:20 PM PST, muhammad ramzi <mramzi43 at gmail.com> wrote:
>> Thank you very much this really helped me a lot . 
>> So actually why would people learn R(other than personal interests ) if
>> you can't really build anything that can be sold ? I'm sorry if I'm
>> asking bad questions 
>> 
>> 
>>> On 12 Jan 2018, at 4:43 AM, Marc Schwartz <marc_schwartz at me.com>
>> wrote:
>>> 
>>> 
>>> 
>>>> On Jan 11, 2018, at 2:15 PM, muhammad ramzi <mramzi43 at gmail.com>
>> wrote:
>>>> 
>>>> hello guys,
>>>> 
>>>> i am a petroleum engineering student and i will be having a long
>> semester
>>>> break and currently i am learning THE R PROGRAMMING LANGUAGE just
>> out of
>>>> interest. I would just like to know if i am able to design a
>> business
>>>> analysis software using R as in create a type of software that can
>> be sold
>>>> to business people. can this be done in R language?
>>>> 
>>>> another thing is if i do learn this all the way, what advantages
>> will it
>>>> give me in terms of future prospects and career development?
>>> 
>>> 
>>> Hi,
>>> 
>>> To your first question, as R is open source and released under the
>> GPL, there are legal issues that you will need to consider, which will
>> be specific to the details of your plans, how your "application" is
>> built, how it interacts with R, and importantly, the copying and
>> distribution of the end product.
>>> 
>>> You should, first and foremost, contact a lawyer familiar with open
>> source software, specifically GPL compatible licenses, so that you can
>> get proper legal advice, which you will not get here. You risk
>> legal/financial liabilities down the road if not done in compliance
>> with the license requirements.
>>> 
>>> As a first pass, you should read:
>>> 
>>> 
>> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Can-I-use-R-for-commercial-purposes_003f
>>> 
>>> and
>>> 
>>> https://www.gnu.org/licenses/old-licenses/gpl-2.0-faq.html
>>> 
>>> so that you can gain initial insights into some of the general
>> implications of building a product for distribution (whether you give
>> it away or sell it) that depends upon a GPL licensed application. 
>>> 
>>> Whether or not there is utility for the application you envision such
>> that people would be willing to pay for it, will depend upon a variety
>> of factors, not the least of which is what competition you face and the
>> value of your planned application over others that are already in the
>> marketplace.
>>> 
>>> To your second question, you are asking a biased, self selected
>> audience. Thus, take that into account for any responses that you may
>> get.
>>> 
>>> The responses relative to advantages are going to be, to some extent,
>> broadly industry specific. That being said, in many domains, knowing R,
>> along with other relevant applications and programming languages can
>> only be beneficial in many cases.
>>> 
>>> R is becoming increasingly popular (e.g. see:
>> https://www.tiobe.com/tiobe-index/). However, depending upon the
>> subject matter domain you will work in and to a large extent, the
>> company or institution you will work for, those factors can have a
>> material influence on the role that R might play in that environment.
>>> 
>>> Others can perhaps chime in with other thoughts and perhaps even
>> industry specific insights for you.
>>> 
>>> Regards,
>>> 
>>> Marc Schwartz
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From simon.wood at bath.edu  Fri Jan 12 10:20:47 2018
From: simon.wood at bath.edu (Simon Wood)
Date: Fri, 12 Jan 2018 09:20:47 +0000
Subject: [R] setting constraints on gam
In-Reply-To: <CAJ9CH8W-NKch4ns9r10i=GqLxw+yRH=ZRiqkQ6Tr8OaeFxDRdw@mail.gmail.com>
References: <CAJ9CH8W-NKch4ns9r10i=GqLxw+yRH=ZRiqkQ6Tr8OaeFxDRdw@mail.gmail.com>
Message-ID: <0274324f-4f04-e39b-6bd0-a6eaabf7330c@bath.edu>

There probably is a way, but it involves some programming. You would 
need to clone a smooth constructor (e.g. for the "cr" class), and then 
modify it to add a linear constraint matrix C to the returned smooth 
object. If b are the smooth coefficients then C should? be the matrix 
such that s(0) = Cb (you can get this from the Predict.matrix method for 
the class). Then the constraint Cb=0 will be applied during basis setup, 
and is equivalent to s(0)=0.

Now you can use your cloned class in a tensor product smooth, using the 
'ti' constructor. Suppose your cloned smooth class is called "foo", then

ti(x,z,bs="foo",mc=c(0,1))

will create a smooth for which s(x,0)=0. Your requirement that s(x,0)=k 
is then taken care of by the model intercept.

If you want to try something similar with the full nested structure it's 
more complicated still. Then I think you would need something like

s(x,by=as.numeric(z!=0)) + s(z) + ti(x,z,bs=c("cr","foo"))

Simon


On 11/01/18 22:33, Alejandra Mart?nez Blancas wrote:
> I am fitting a model in which the response variable y is a function of
> two independent, quantitative variables x1 and x2; thus: y = f(x1,
> x2). For reasons I do not believe to be important for the purpose of
> this post, I find it desirable to find f by means of GAM; also, I
> require principal effects and interactions to be specified separately,
> so I am using using te and ti tensors. Thus, I am using the following
> command:
>
>
>
> f = gam(y ~ te(x1) + te(x2) + ti(x1, x2))
>
>
>
> This results in a model that corresponds to one of the hypotheses I am
> testing. Nevertheless, another hypothesis requires that, when one of
> the independent variables (say x2) is zero, the value of y is
> unaffected by the other variable (in this example x1). In other words
> f(x1, 0) = k for every value of x1, where k is a constant to be
> estimated. For x2 values other than zero I would like to let GAM
> choose the appropriate function relating x1 and y. Is there a way to
> specify such model in mgcv?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
+44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190


From pdalgd at gmail.com  Fri Jan 12 10:34:58 2018
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 12 Jan 2018 10:34:58 +0100
Subject: [R] application of R
In-Reply-To: <5BAD377B-5111-4481-ABA0-C53090C0BD6E@gmail.com>
References: <CAFk3T_d3xtYrL3kARgmK5G=xyYM0+dg7WzzTKcQkc1Mk_HGTWw@mail.gmail.com>
 <E4B06B10-BC38-49D0-A928-49190BD57894@me.com>
 <4009BDBD-CB8F-4B3F-8944-ACFE95300E31@gmail.com>
 <A0AA2267-554F-42C7-A1E1-A8ADD1E1A929@dcn.davis.ca.us>
 <5BAD377B-5111-4481-ABA0-C53090C0BD6E@gmail.com>
Message-ID: <E779F682-8D2F-4409-82BC-E0B356887266@gmail.com>

In the (approximate) words of Ross Ihaka: R could have been made commercial and then it might have had like 500 users instead of millions.

Programming language aside, there isn't really much of a market for new, closed source, statistical programs, at least not unless you get to a level of sophistication which is way beyond the capacity of any single person (e.g. in the field of maths software, Mathematica is not likely to be replaceable by a free alternative anytime soon, but that is huge!).

More likely, there is a market in consulting and in-house application development, both of which can quite conveniently be done with R. If you are good at it, that is.

-pd

> On 12 Jan 2018, at 06:17 , muhammad ramzi <mramzi43 at gmail.com> wrote:
> 
> Oh I see thank you very much now I understand. So for me as I am considered an intermediate in R and also C++ what kind of programming language I could take up and learn to make a commercial statistical software ? Any advices as well ?

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From loris.bennett at fu-berlin.de  Fri Jan 12 13:49:17 2018
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Fri, 12 Jan 2018 13:49:17 +0100
Subject: [R] R minor version
Message-ID: <878td3utrm.fsf@hornfels.zedat.fu-berlin.de>

Hi,

When I install a package as a non-root user, it gets saved in a path
such as

  ~/R/x86_64-unknown-linux-gnu-library/3.4

for any R version 3.4.x.  Thus, if I want to install the packages
somewhere else, as root say, I might do

  install.packages("somepackage","/some/where/else/R/site-library/3.4")

In this case I would then want to construct the appropriate path in,
say, /etc/Rprofile to allow the packages to be found.

However, using R.Version() gives me

  > R.Version()$minor
  [1] "4.3"

I can obviously extract the "real" minor version from the string, but
shouldn't there be a more straightforward way to obtain the part of the
version that is used in .libPaths() by default?

Or am I misunderstanding something?

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From imane.chafiki.fst at gmail.com  Fri Jan 12 16:42:18 2018
From: imane.chafiki.fst at gmail.com (imane hajar)
Date: Fri, 12 Jan 2018 15:42:18 +0000
Subject: [R] Help with packages (methods, stats, stats4)
Message-ID: <CAP8kRH7oGunrh9o=4CjeCAx3ygPxHy_sdyE7D4gukefTpOdbLA@mail.gmail.com>

hello,
Can you please give me a hand with this problem,well i can't install these
packages:
- stats
- methods
- stats4

when i tried the following command :  *library(help = "stats") * , it gave
me this output (*see picture*), so i contacted the Maintainer of the
package at (*R-core at r-project.org <R-core at r-project.org>*) but he said that
i write to the wrong place.

(i want to install those packages in order to use the "DVstats" package)

(i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )

thank you
Regards
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1.PNG
Type: image/png
Size: 13253 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180112/595276ef/attachment.png>

From wdunlap at tibco.com  Fri Jan 12 17:42:41 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 12 Jan 2018 08:42:41 -0800
Subject: [R] R minor version
In-Reply-To: <878td3utrm.fsf@hornfels.zedat.fu-berlin.de>
References: <878td3utrm.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <CAF8bMcZvCFsJ6_yYyNWiTrbsdTczSJ4kz=n5EoGYiAUUR-n-EQ@mail.gmail.com>

> .expand_R_libs_env_var("poof/%p/%v")
[1] "poof/x86_64-w64-mingw32/3.4"



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jan 12, 2018 at 4:49 AM, Loris Bennett <loris.bennett at fu-berlin.de>
wrote:

> Hi,
>
> When I install a package as a non-root user, it gets saved in a path
> such as
>
>   ~/R/x86_64-unknown-linux-gnu-library/3.4
>
> for any R version 3.4.x.  Thus, if I want to install the packages
> somewhere else, as root say, I might do
>
>   install.packages("somepackage","/some/where/else/R/site-library/3.4")
>
> In this case I would then want to construct the appropriate path in,
> say, /etc/Rprofile to allow the packages to be found.
>
> However, using R.Version() gives me
>
>   > R.Version()$minor
>   [1] "4.3"
>
> I can obviously extract the "real" minor version from the string, but
> shouldn't there be a more straightforward way to obtain the part of the
> version that is used in .libPaths() by default?
>
> Or am I misunderstanding something?
>
> Cheers,
>
> Loris
>
> --
> Dr. Loris Bennett (Mr.)
> ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Jan 12 18:20:17 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 12 Jan 2018 12:20:17 -0500
Subject: [R] Help with packages (methods, stats, stats4)
In-Reply-To: <CAP8kRH7oGunrh9o=4CjeCAx3ygPxHy_sdyE7D4gukefTpOdbLA@mail.gmail.com>
References: <CAP8kRH7oGunrh9o=4CjeCAx3ygPxHy_sdyE7D4gukefTpOdbLA@mail.gmail.com>
Message-ID: <bf20642f-2e3e-d8f3-31fd-51d158b77676@gmail.com>

On 12/01/2018 10:42 AM, imane hajar wrote:
> hello,
> Can you please give me a hand with this problem,well i can't install these
> packages:
> - stats
> - methods
> - stats4

Those are all base packages which are part of R.  If you have R, you 
have them.  They can't be updated without updating all of R.

Duncan Murdoch

> 
> when i tried the following command :  *library(help = "stats") * , it gave
> me this output (*see picture*), so i contacted the Maintainer of the
> package at (*R-core at r-project.org <R-core at r-project.org>*) but he said that
> i write to the wrong place.
> 
> (i want to install those packages in order to use the "DVstats" package)
> 
> (i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )
> 
> thank you
> Regards
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Fri Jan 12 18:20:58 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 12 Jan 2018 09:20:58 -0800
Subject: [R] Help with packages (methods, stats, stats4)
In-Reply-To: <CAP8kRH7oGunrh9o=4CjeCAx3ygPxHy_sdyE7D4gukefTpOdbLA@mail.gmail.com>
References: <CAP8kRH7oGunrh9o=4CjeCAx3ygPxHy_sdyE7D4gukefTpOdbLA@mail.gmail.com>
Message-ID: <CAGxFJbSYV37bQd5ipRhr0Jq2kq1SqgG3BigwYa0MmfwCXRf6Bg@mail.gmail.com>

There appears to be a lot here that you don't understand, and a little
reading woud be a better way for you to resolve your confusion I believe.
Read Section 6 of the "R Installation and Administration" manual that ships
with R. There you will find that the stats and methods packages are already
installed. ?library tells you how to load them for use in your session. See
also ?install.packages and links for how to download and install package
from R package depositories, which mosty means CRAN.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jan 12, 2018 at 7:42 AM, imane hajar <imane.chafiki.fst at gmail.com>
wrote:

> hello,
> Can you please give me a hand with this problem,well i can't install these
> packages:
> - stats
> - methods
> - stats4
>
> when i tried the following command :  *library(help = "stats") * , it gave
> me this output (*see picture*), so i contacted the Maintainer of the
> package at (*R-core at r-project.org <R-core at r-project.org>*) but he said
> that
> i write to the wrong place.
>
> (i want to install those packages in order to use the "DVstats" package)
>
> (i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )
>
> thank you
> Regards
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Jan 12 18:46:43 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 12 Jan 2018 09:46:43 -0800
Subject: [R] Help with packages (methods, stats, stats4)
In-Reply-To: <CAP8kRH60T4ZDd4ow_ary3PT3-q+aime=sp7nQR-MUTW_-6yA8w@mail.gmail.com>
References: <CAP8kRH7oGunrh9o=4CjeCAx3ygPxHy_sdyE7D4gukefTpOdbLA@mail.gmail.com>
 <CAGxFJbSYV37bQd5ipRhr0Jq2kq1SqgG3BigwYa0MmfwCXRf6Bg@mail.gmail.com>
 <CAP8kRH60T4ZDd4ow_ary3PT3-q+aime=sp7nQR-MUTW_-6yA8w@mail.gmail.com>
Message-ID: <CAGxFJbQaSiutz8D9neCd=5+2xngf9gXeNCPaZw-_rw+g=q_8zg@mail.gmail.com>

1. Unless there is a good reason not to, please always cc the list. As you
note, I may misunderstand or just be too stupid, so you increase your
chance of getting a good answer by ccing them, which I have done here

2. It looks like you need  to install the multcomp package. Have you?

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jan 12, 2018 at 9:42 AM, imane hajar <imane.chafiki.fst at gmail.com>
wrote:

> Hello Mr Gunter ,
> i am sorry for distrubing you again ,i think its just a miss understanding
> of the problem, i said in the last lines of my msj that my main problem is
> that i cant use " DVstats" , i installed it using install.packages("DVstat
> s") and it seems ok , but when i use the following line : library(DVstats)
> , this error message appear : Error: package or namespace load failed for
> ?DVstats? in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
> versionCheck = vI[[j]]): there is no package called ?multcomp? .
>
> so my final thoughts went with a hypothesis of what , maybe by updating R
> something happend with the bundled packages.
>
> (please bare with my english , i speak french )
>
> Thank you
>
> Regards
>
>
>
> 2018-01-12 17:20 GMT+00:00 Bert Gunter <bgunter.4567 at gmail.com>:
>
>> There appears to be a lot here that you don't understand, and a little
>> reading woud be a better way for you to resolve your confusion I believe.
>> Read Section 6 of the "R Installation and Administration" manual that ships
>> with R. There you will find that the stats and methods packages are already
>> installed. ?library tells you how to load them for use in your session. See
>> also ?install.packages and links for how to download and install package
>> from R package depositories, which mosty means CRAN.
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Fri, Jan 12, 2018 at 7:42 AM, imane hajar <imane.chafiki.fst at gmail.com
>> > wrote:
>>
>>> hello,
>>> Can you please give me a hand with this problem,well i can't install
>>> these
>>> packages:
>>> - stats
>>> - methods
>>> - stats4
>>>
>>> when i tried the following command :  *library(help = "stats") * , it
>>> gave
>>> me this output (*see picture*), so i contacted the Maintainer of the
>>> package at (*R-core at r-project.org <R-core at r-project.org>*) but he said
>>> that
>>> i write to the wrong place.
>>>
>>> (i want to install those packages in order to use the "DVstats" package)
>>>
>>> (i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )
>>>
>>> thank you
>>> Regards
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From imane.chafiki.fst at gmail.com  Fri Jan 12 17:37:14 2018
From: imane.chafiki.fst at gmail.com (imane hajar)
Date: Fri, 12 Jan 2018 16:37:14 +0000
Subject: [R] Help with packages (methods, stats, stats4)
In-Reply-To: <CAP8kRH7oGunrh9o=4CjeCAx3ygPxHy_sdyE7D4gukefTpOdbLA@mail.gmail.com>
References: <CAP8kRH7oGunrh9o=4CjeCAx3ygPxHy_sdyE7D4gukefTpOdbLA@mail.gmail.com>
Message-ID: <CAP8kRH4VJ96+uADBwdP3R20OfLONRi8+K0ZfTyctYiwnX1uftw@mail.gmail.com>

hello ,

i am so sorry , i figure it out.

im sending this msj to the moderator to stop the approval of the mail .

have a good day.


2018-01-12 15:42 GMT+00:00 imane hajar <imane.chafiki.fst at gmail.com>:

> hello,
> Can you please give me a hand with this problem,well i can't install
> these packages:
> - stats
> - methods
> - stats4
>
> when i tried the following command :  *library(help = "stats") * , it
> gave me this output (*see picture*), so i contacted the Maintainer of the
> package at (*R-core at r-project.org <R-core at r-project.org>*) but he said
> that i write to the wrong place.
>
> (i want to install those packages in order to use the "DVstats" package)
>
> (i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )
>
> thank you
> Regards
>

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Fri Jan 12 19:11:53 2018
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Fri, 12 Jan 2018 19:11:53 +0100
Subject: [R] Help with packages (methods, stats, stats4)
In-Reply-To: <CAP8kRH4VJ96+uADBwdP3R20OfLONRi8+K0ZfTyctYiwnX1uftw@mail.gmail.com>
References: <CAP8kRH7oGunrh9o=4CjeCAx3ygPxHy_sdyE7D4gukefTpOdbLA@mail.gmail.com>
 <CAP8kRH4VJ96+uADBwdP3R20OfLONRi8+K0ZfTyctYiwnX1uftw@mail.gmail.com>
Message-ID: <CALJKBv_7Ms79aajFshFhQO6rQRHRxg-uWELkW-WXPGb4nEMb3g@mail.gmail.com>

Hi,
Did you try install.packages('stats').
Let we know about your   Sys.info()
Karim

On Fri, Jan 12, 2018 at 5:37 PM, imane hajar <imane.chafiki.fst at gmail.com>
wrote:

> hello ,
>
> i am so sorry , i figure it out.
>
> im sending this msj to the moderator to stop the approval of the mail .
>
> have a good day.
>
>
> 2018-01-12 15:42 GMT+00:00 imane hajar <imane.chafiki.fst at gmail.com>:
>
> > hello,
> > Can you please give me a hand with this problem,well i can't install
> > these packages:
> > - stats
> > - methods
> > - stats4
> >
> > when i tried the following command :  *library(help = "stats") * , it
> > gave me this output (*see picture*), so i contacted the Maintainer of the
> > package at (*R-core at r-project.org <R-core at r-project.org>*) but he said
> > that i write to the wrong place.
> >
> > (i want to install those packages in order to use the "DVstats" package)
> >
> > (i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )
> >
> > thank you
> > Regards
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Jan 12 19:20:57 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 12 Jan 2018 13:20:57 -0500
Subject: [R] Help with packages (methods, stats, stats4)
In-Reply-To: <CALJKBv_7Ms79aajFshFhQO6rQRHRxg-uWELkW-WXPGb4nEMb3g@mail.gmail.com>
References: <CAP8kRH7oGunrh9o=4CjeCAx3ygPxHy_sdyE7D4gukefTpOdbLA@mail.gmail.com>
 <CAP8kRH4VJ96+uADBwdP3R20OfLONRi8+K0ZfTyctYiwnX1uftw@mail.gmail.com>
 <CALJKBv_7Ms79aajFshFhQO6rQRHRxg-uWELkW-WXPGb4nEMb3g@mail.gmail.com>
Message-ID: <53983e76-0798-f17b-dc9c-f9e2416d0a64@gmail.com>

On 12/01/2018 1:11 PM, Karim Mezhoud wrote:
> Hi,
> Did you try install.packages('stats').

That will not work, as stats is a base package.  It comes with R, and 
can't be changed.  The stats package should never be missing in a proper 
install of R.

Duncan Murdoch

> Let we know about your   Sys.info()
> Karim
> 
> On Fri, Jan 12, 2018 at 5:37 PM, imane hajar <imane.chafiki.fst at gmail.com>
> wrote:
> 
>> hello ,
>>
>> i am so sorry , i figure it out.
>>
>> im sending this msj to the moderator to stop the approval of the mail .
>>
>> have a good day.
>>
>>
>> 2018-01-12 15:42 GMT+00:00 imane hajar <imane.chafiki.fst at gmail.com>:
>>
>>> hello,
>>> Can you please give me a hand with this problem,well i can't install
>>> these packages:
>>> - stats
>>> - methods
>>> - stats4
>>>
>>> when i tried the following command :  *library(help = "stats") * , it
>>> gave me this output (*see picture*), so i contacted the Maintainer of the
>>> package at (*R-core at r-project.org <R-core at r-project.org>*) but he said
>>> that i write to the wrong place.
>>>
>>> (i want to install those packages in order to use the "DVstats" package)
>>>
>>> (i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )
>>>
>>> thank you
>>> Regards
>>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kmezhoud at gmail.com  Fri Jan 12 19:25:43 2018
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Fri, 12 Jan 2018 19:25:43 +0100
Subject: [R] Help with packages (methods, stats, stats4)
In-Reply-To: <53983e76-0798-f17b-dc9c-f9e2416d0a64@gmail.com>
References: <CAP8kRH7oGunrh9o=4CjeCAx3ygPxHy_sdyE7D4gukefTpOdbLA@mail.gmail.com>
 <CAP8kRH4VJ96+uADBwdP3R20OfLONRi8+K0ZfTyctYiwnX1uftw@mail.gmail.com>
 <CALJKBv_7Ms79aajFshFhQO6rQRHRxg-uWELkW-WXPGb4nEMb3g@mail.gmail.com>
 <53983e76-0798-f17b-dc9c-f9e2416d0a64@gmail.com>
Message-ID: <CALJKBv_v-CFgGVHRGaWx_c45+jW8RQvvpXygAhXe5EyuYsmPJA@mail.gmail.com>

Yes,
You are right. I mean
install.packages('DVstats').
Actually, it seems that DVstats does not have maintainer
https://github.com/USGS-R/DVstats
Karim

On Fri, Jan 12, 2018 at 7:20 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 12/01/2018 1:11 PM, Karim Mezhoud wrote:
>
>> Hi,
>> Did you try install.packages('stats').
>>
>
> That will not work, as stats is a base package.  It comes with R, and
> can't be changed.  The stats package should never be missing in a proper
> install of R.
>
> Duncan Murdoch
>
>
> Let we know about your   Sys.info()
>> Karim
>>
>> On Fri, Jan 12, 2018 at 5:37 PM, imane hajar <imane.chafiki.fst at gmail.com
>> >
>> wrote:
>>
>> hello ,
>>>
>>> i am so sorry , i figure it out.
>>>
>>> im sending this msj to the moderator to stop the approval of the mail .
>>>
>>> have a good day.
>>>
>>>
>>> 2018-01-12 15:42 GMT+00:00 imane hajar <imane.chafiki.fst at gmail.com>:
>>>
>>> hello,
>>>> Can you please give me a hand with this problem,well i can't install
>>>> these packages:
>>>> - stats
>>>> - methods
>>>> - stats4
>>>>
>>>> when i tried the following command :  *library(help = "stats") * , it
>>>> gave me this output (*see picture*), so i contacted the Maintainer of
>>>> the
>>>> package at (*R-core at r-project.org <R-core at r-project.org>*) but he said
>>>> that i write to the wrong place.
>>>>
>>>> (i want to install those packages in order to use the "DVstats" package)
>>>>
>>>> (i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )
>>>>
>>>> thank you
>>>> Regards
>>>>
>>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From cadeb at usgs.gov  Fri Jan 12 19:44:38 2018
From: cadeb at usgs.gov (Cade, Brian)
Date: Fri, 12 Jan 2018 11:44:38 -0700
Subject: [R] glm$effects
Message-ID: <CAM5M9BS6akBVVn2oAFVbuNQBhkwCjsMVA_BHrbV6HR02myY4sA@mail.gmail.com>

I know I must be missing something obvious, but checking help and googling
a bit did not turn up a useable answer.  When I've estimated a glm() model
object (my example is with just identity link with gaussian family so I
could have used lm() instead), one of the terms returned in the model
object is listed as $effects.  What are these quantities?  I have not been
able to relate them to the $coefficients, $fitted.values, $resid, or $y
completely.  For example, if I estimate the simplest model with just an
intercept term, the $effects for the n observations differ from $y by a
constant quantity except for one of the values.

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Jan 12 20:03:30 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 12 Jan 2018 11:03:30 -0800
Subject: [R] glm$effects
In-Reply-To: <CAM5M9BS6akBVVn2oAFVbuNQBhkwCjsMVA_BHrbV6HR02myY4sA@mail.gmail.com>
References: <CAM5M9BS6akBVVn2oAFVbuNQBhkwCjsMVA_BHrbV6HR02myY4sA@mail.gmail.com>
Message-ID: <CAGxFJbRvWekQbjYt6Kxnps+bTbm=9XWQqG0hH5BkWwY5HPgWJQ@mail.gmail.com>

See ?effects

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jan 12, 2018 at 10:44 AM, Cade, Brian <cadeb at usgs.gov> wrote:

> I know I must be missing something obvious, but checking help and googling
> a bit did not turn up a useable answer.  When I've estimated a glm() model
> object (my example is with just identity link with gaussian family so I
> could have used lm() instead), one of the terms returned in the model
> object is listed as $effects.  What are these quantities?  I have not been
> able to relate them to the $coefficients, $fitted.values, $resid, or $y
> completely.  For example, if I estimate the simplest model with just an
> intercept term, the $effects for the n observations differ from $y by a
> constant quantity except for one of the values.
>
> Brian
>
> Brian S. Cade, PhD
>
> U. S. Geological Survey
> Fort Collins Science Center
> 2150 Centre Ave., Bldg. C
> Fort Collins, CO  80526-8818
>
> email:  cadeb at usgs.gov <brian_cade at usgs.gov>
> tel:  970 226-9326
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Fri Jan 12 20:09:56 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 12 Jan 2018 11:09:56 -0800
Subject: [R] R minor version
In-Reply-To: <CAF8bMcZvCFsJ6_yYyNWiTrbsdTczSJ4kz=n5EoGYiAUUR-n-EQ@mail.gmail.com>
References: <878td3utrm.fsf@hornfels.zedat.fu-berlin.de>
 <CAF8bMcZvCFsJ6_yYyNWiTrbsdTczSJ4kz=n5EoGYiAUUR-n-EQ@mail.gmail.com>
Message-ID: <CAFDcVCSCEw6s1emJC9Zq6i-GxiogDJE1EogryCON-w4OOJY1pQ@mail.gmail.com>

This can be controlled by environment variables R_LIBS, R_LIBS_SITE,
and R_LIBS_USER, which support "conversion specifiers".  See
help(".libPaths") or aliases help("R_LIBS") etc.  You can set these in
in any of the Renviron files (~/.Renviron, /path/to/R/etc/Renviron,
/path/to/R/etc/Renviron.site).

It sounds like you're trying to set up a site-wide package library to
be shared among users.  If so, add a line:

R_LIBS_SITE=/some/where/else/R/site-%p-library/%v

and make sure that folder exists, otherwise it's silently dropped from
.libPaths().

/Henrik


On Fri, Jan 12, 2018 at 8:42 AM, William Dunlap via R-help
<r-help at r-project.org> wrote:
>> .expand_R_libs_env_var("poof/%p/%v")
> [1] "poof/x86_64-w64-mingw32/3.4"
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Jan 12, 2018 at 4:49 AM, Loris Bennett <loris.bennett at fu-berlin.de>
> wrote:
>
>> Hi,
>>
>> When I install a package as a non-root user, it gets saved in a path
>> such as
>>
>>   ~/R/x86_64-unknown-linux-gnu-library/3.4
>>
>> for any R version 3.4.x.  Thus, if I want to install the packages
>> somewhere else, as root say, I might do
>>
>>   install.packages("somepackage","/some/where/else/R/site-library/3.4")
>>
>> In this case I would then want to construct the appropriate path in,
>> say, /etc/Rprofile to allow the packages to be found.
>>
>> However, using R.Version() gives me
>>
>>   > R.Version()$minor
>>   [1] "4.3"
>>
>> I can obviously extract the "real" minor version from the string, but
>> shouldn't there be a more straightforward way to obtain the part of the
>> version that is used in .libPaths() by default?
>>
>> Or am I misunderstanding something?
>>
>> Cheers,
>>
>> Loris
>>
>> --
>> Dr. Loris Bennett (Mr.)
>> ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri Jan 12 21:01:59 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 12 Jan 2018 15:01:59 -0500
Subject: [R] Help with packages (methods, stats, stats4)
In-Reply-To: <CALJKBv_v-CFgGVHRGaWx_c45+jW8RQvvpXygAhXe5EyuYsmPJA@mail.gmail.com>
References: <CAP8kRH7oGunrh9o=4CjeCAx3ygPxHy_sdyE7D4gukefTpOdbLA@mail.gmail.com>
 <CAP8kRH4VJ96+uADBwdP3R20OfLONRi8+K0ZfTyctYiwnX1uftw@mail.gmail.com>
 <CALJKBv_7Ms79aajFshFhQO6rQRHRxg-uWELkW-WXPGb4nEMb3g@mail.gmail.com>
 <53983e76-0798-f17b-dc9c-f9e2416d0a64@gmail.com>
 <CALJKBv_v-CFgGVHRGaWx_c45+jW8RQvvpXygAhXe5EyuYsmPJA@mail.gmail.com>
Message-ID: <d4aa6a9c-44be-a595-6b27-5f18ea1b1571@gmail.com>

On 12/01/2018 1:25 PM, Karim Mezhoud wrote:
> Yes,
> You are right. I mean
> install.packages('DVstats').

That won't work either, because DVstats is not on CRAN.

> Actually, it seems that DVstats does not have maintainer
> https://github.com/USGS-R/DVstats

You can try

install.packages("devtools")  # if not already installed...
devtools::install_github("USGS-R/DVstats")


but that fails for me, with this message:

ERROR: dependencies ?smwrBase?, ?smwrGraphs?, ?smwrStats?, ?smwrQW? are 
not available for package ?DVstats?

It doesn't look promising.

Duncan Murdoch

> Karim
> 
> On Fri, Jan 12, 2018 at 7:20 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> 
>> On 12/01/2018 1:11 PM, Karim Mezhoud wrote:
>>
>>> Hi,
>>> Did you try install.packages('stats').
>>>
>>
>> That will not work, as stats is a base package.  It comes with R, and
>> can't be changed.  The stats package should never be missing in a proper
>> install of R.
>>
>> Duncan Murdoch
>>
>>
>> Let we know about your   Sys.info()
>>> Karim
>>>
>>> On Fri, Jan 12, 2018 at 5:37 PM, imane hajar <imane.chafiki.fst at gmail.com
>>>>
>>> wrote:
>>>
>>> hello ,
>>>>
>>>> i am so sorry , i figure it out.
>>>>
>>>> im sending this msj to the moderator to stop the approval of the mail .
>>>>
>>>> have a good day.
>>>>
>>>>
>>>> 2018-01-12 15:42 GMT+00:00 imane hajar <imane.chafiki.fst at gmail.com>:
>>>>
>>>> hello,
>>>>> Can you please give me a hand with this problem,well i can't install
>>>>> these packages:
>>>>> - stats
>>>>> - methods
>>>>> - stats4
>>>>>
>>>>> when i tried the following command :  *library(help = "stats") * , it
>>>>> gave me this output (*see picture*), so i contacted the Maintainer of
>>>>> the
>>>>> package at (*R-core at r-project.org <R-core at r-project.org>*) but he said
>>>>> that i write to the wrong place.
>>>>>
>>>>> (i want to install those packages in order to use the "DVstats" package)
>>>>>
>>>>> (i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )
>>>>>
>>>>> thank you
>>>>> Regards
>>>>>
>>>>>
>>>>           [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>


From dwinsemius at comcast.net  Fri Jan 12 21:51:34 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Jan 2018 12:51:34 -0800
Subject: [R] Help with packages (methods, stats, stats4)
In-Reply-To: <d4aa6a9c-44be-a595-6b27-5f18ea1b1571@gmail.com>
References: <CAP8kRH7oGunrh9o=4CjeCAx3ygPxHy_sdyE7D4gukefTpOdbLA@mail.gmail.com>
 <CAP8kRH4VJ96+uADBwdP3R20OfLONRi8+K0ZfTyctYiwnX1uftw@mail.gmail.com>
 <CALJKBv_7Ms79aajFshFhQO6rQRHRxg-uWELkW-WXPGb4nEMb3g@mail.gmail.com>
 <53983e76-0798-f17b-dc9c-f9e2416d0a64@gmail.com>
 <CALJKBv_v-CFgGVHRGaWx_c45+jW8RQvvpXygAhXe5EyuYsmPJA@mail.gmail.com>
 <d4aa6a9c-44be-a595-6b27-5f18ea1b1571@gmail.com>
Message-ID: <8747B165-721F-4F28-A38A-E09A5B875A0E@comcast.net>


> On Jan 12, 2018, at 12:01 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 12/01/2018 1:25 PM, Karim Mezhoud wrote:
>> Yes,
>> You are right. I mean
>> install.packages('DVstats').
> 
> That won't work either, because DVstats is not on CRAN.
> 
>> Actually, it seems that DVstats does not have maintainer
>> https://github.com/USGS-R/DVstats
> 
> You can try
> 
> install.packages("devtools")  # if not already installed...
> devtools::install_github("USGS-R/DVstats")
> 
> 
> but that fails for me, with this message:
> 
> ERROR: dependencies ?smwrBase?, ?smwrGraphs?, ?smwrStats?, ?smwrQW? are not available for package ?DVstats?
> 
> It doesn't look promising.

If you read the Instructions linked from https://github.com/USGS-R/smwrBase you find that the USGS maintains a repository which they expect one to add to your repo-list. Read:

https://owi.usgs.gov/R/training-curriculum/installr/

....

rprofile_path = file.path(Sys.getenv("HOME"), ".Rprofile"
)
write(
'\noptions(repos=c(getOption(\'repos\
'),
    CRAN=\'
https://cloud.r-project.org\
',
    USGS=\'
https://owi.usgs.gov/R\'))\n'
,
      rprofile_path, 
      append =  TRUE)

cat(
'Your Rprofile has been updated to include GRAN.
    Please restart R for changes to take effect.'
)

They do have a misleading statement at the end of that page regarding the MacOS. It's true that Rtools are not needed for package development, but a casual reader could well conclude that meant no package development ancillary programs were needed. They _should_ have said that Apple's XCode of the proper version as well as the Command Line Tools were needed for package development on MacOS/OSX. I do have those installed. When I attempted installation I got partial success with:

install.packages(c('smwrBase', 'smwrGraphs', 'smwrStats', 'smwrQW'), repo='https://owi.usgs.gov/R/', type="source")

# However the lack of zCompositions (a CRAN package) initially prevented installation of smwrQW
# once  that dependency was installed I was able to install smwrQW and DVstats

install.packages( 'smwrQW', repo='https://owi.usgs.gov/R/', type="source")
install.packages( 'DVstats', repo='https://owi.usgs.gov/R/', type="source")

#resulting in...

> library(DVstats)
This information is preliminary or provisional and
is subject to revision. It is being provided to meet
the need for timely best science. The information
has not received final approval by the U.S. Geological
Survey (USGS) and is provided on the condition that
neither the USGS nor the U.S. Government shall be held
liable for any damages resulting from the authorized
or unauthorized use of the information.
                        
****Orphaned Package****
This package is looking for a new maintainer. For more information, 
see: https://owi.usgs.gov/R/packages.html#orphan



> 
> Duncan Murdoch
> 
>> Karim
>> On Fri, Jan 12, 2018 at 7:20 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>>> On 12/01/2018 1:11 PM, Karim Mezhoud wrote:
>>> 
>>>> Hi,
>>>> Did you try install.packages('stats').
>>>> 
>>> 
>>> That will not work, as stats is a base package.  It comes with R, and
>>> can't be changed.  The stats package should never be missing in a proper
>>> install of R.
>>> 
>>> Duncan Murdoch
>>> 
>>> 
>>> Let we know about your   Sys.info()
>>>> Karim
>>>> 
>>>> On Fri, Jan 12, 2018 at 5:37 PM, imane hajar <imane.chafiki.fst at gmail.com
>>>>> 
>>>> wrote:
>>>> 
>>>> hello ,
>>>>> 
>>>>> i am so sorry , i figure it out.
>>>>> 
>>>>> im sending this msj to the moderator to stop the approval of the mail .
>>>>> 
>>>>> have a good day.
>>>>> 
>>>>> 
>>>>> 2018-01-12 15:42 GMT+00:00 imane hajar <imane.chafiki.fst at gmail.com>:
>>>>> 
>>>>> hello,
>>>>>> Can you please give me a hand with this problem,well i can't install
>>>>>> these packages:
>>>>>> - stats
>>>>>> - methods
>>>>>> - stats4
>>>>>> 
>>>>>> when i tried the following command :  *library(help = "stats") * , it
>>>>>> gave me this output (*see picture*), so i contacted the Maintainer of
>>>>>> the
>>>>>> package at (*R-core at r-project.org <R-core at r-project.org>*) but he said
>>>>>> that i write to the wrong place.
>>>>>> 
>>>>>> (i want to install those packages in order to use the "DVstats" package)
>>>>>> 
>>>>>> (i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )
>>>>>> 
>>>>>> thank you
>>>>>> Regards
>>>>>> 
>>>>>> 
>>>>>          [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> 
>>>>         [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From alemtzb at ciencias.unam.mx  Fri Jan 12 23:50:44 2018
From: alemtzb at ciencias.unam.mx (=?UTF-8?Q?Alejandra_Mart=C3=ADnez_Blancas?=)
Date: Fri, 12 Jan 2018 16:50:44 -0600
Subject: [R] setting constraints on gam
In-Reply-To: <0274324f-4f04-e39b-6bd0-a6eaabf7330c@bath.edu>
References: <CAJ9CH8W-NKch4ns9r10i=GqLxw+yRH=ZRiqkQ6Tr8OaeFxDRdw@mail.gmail.com>
 <0274324f-4f04-e39b-6bd0-a6eaabf7330c@bath.edu>
Message-ID: <CAJ9CH8XjwCPAyiTiC9XcyQMOowWOaqaZcKRwTgKaV7v7QaaYCA@mail.gmail.com>

Thanks Simon, by cloning a smooth construct do you mean copying and
modifying the smooth constructor code? Could you pleas elaborate on
your answer? Which is the Predict.matrix method?

2018-01-12 3:20 GMT-06:00 Simon Wood <simon.wood at bath.edu>:
> There probably is a way, but it involves some programming. You would need to
> clone a smooth constructor (e.g. for the "cr" class), and then modify it to
> add a linear constraint matrix C to the returned smooth object. If b are the
> smooth coefficients then C should  be the matrix such that s(0) = Cb (you
> can get this from the Predict.matrix method for the class). Then the
> constraint Cb=0 will be applied during basis setup, and is equivalent to
> s(0)=0.
>
> Now you can use your cloned class in a tensor product smooth, using the 'ti'
> constructor. Suppose your cloned smooth class is called "foo", then
>
> ti(x,z,bs="foo",mc=c(0,1))
>
> will create a smooth for which s(x,0)=0. Your requirement that s(x,0)=k is
> then taken care of by the model intercept.
>
> If you want to try something similar with the full nested structure it's
> more complicated still. Then I think you would need something like
>
> s(x,by=as.numeric(z!=0)) + s(z) + ti(x,z,bs=c("cr","foo"))
>
> Simon
>
>
>
> On 11/01/18 22:33, Alejandra Mart?nez Blancas wrote:
>>
>> I am fitting a model in which the response variable y is a function of
>> two independent, quantitative variables x1 and x2; thus: y = f(x1,
>> x2). For reasons I do not believe to be important for the purpose of
>> this post, I find it desirable to find f by means of GAM; also, I
>> require principal effects and interactions to be specified separately,
>> so I am using using te and ti tensors. Thus, I am using the following
>> command:
>>
>>
>>
>> f = gam(y ~ te(x1) + te(x2) + ti(x1, x2))
>>
>>
>>
>> This results in a model that corresponds to one of the hypotheses I am
>> testing. Nevertheless, another hypothesis requires that, when one of
>> the independent variables (say x2) is zero, the value of y is
>> unaffected by the other variable (in this example x1). In other words
>> f(x1, 0) = k for every value of x1, where k is a constant to be
>> estimated. For x2 values other than zero I would like to let GAM
>> choose the appropriate function relating x1 and y. Is there a way to
>> specify such model in mgcv?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
> +44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Sat Jan 13 11:31:30 2018
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sat, 13 Jan 2018 10:31:30 +0000
Subject: [R] setting constraints on gam
In-Reply-To: <CAJ9CH8XjwCPAyiTiC9XcyQMOowWOaqaZcKRwTgKaV7v7QaaYCA@mail.gmail.com>
References: <CAJ9CH8W-NKch4ns9r10i=GqLxw+yRH=ZRiqkQ6Tr8OaeFxDRdw@mail.gmail.com>
 <0274324f-4f04-e39b-6bd0-a6eaabf7330c@bath.edu>
 <CAJ9CH8XjwCPAyiTiC9XcyQMOowWOaqaZcKRwTgKaV7v7QaaYCA@mail.gmail.com>
Message-ID: <61f1bb74-6597-7092-12a1-9d6676af4572@dewey.myzen.co.uk>

Dear Alejandra

in case you want to move on before Simon replies see inline

On 12/01/2018 22:50, Alejandra Mart?nez Blancas wrote:
> Thanks Simon, by cloning a smooth construct do you mean copying and
> modifying the smooth constructor code?

That is what I understand him to mean yes. (I believe it is clon in 
Spanish if that helps).

  Could you pleas elaborate on
> your answer? Which is the Predict.matrix method?
> 
> 2018-01-12 3:20 GMT-06:00 Simon Wood <simon.wood at bath.edu>:
>> There probably is a way, but it involves some programming. You would need to
>> clone a smooth constructor (e.g. for the "cr" class), and then modify it to
>> add a linear constraint matrix C to the returned smooth object. If b are the
>> smooth coefficients then C should  be the matrix such that s(0) = Cb (you
>> can get this from the Predict.matrix method for the class). Then the
>> constraint Cb=0 will be applied during basis setup, and is equivalent to
>> s(0)=0.
>>
>> Now you can use your cloned class in a tensor product smooth, using the 'ti'
>> constructor. Suppose your cloned smooth class is called "foo", then
>>
>> ti(x,z,bs="foo",mc=c(0,1))
>>
>> will create a smooth for which s(x,0)=0. Your requirement that s(x,0)=k is
>> then taken care of by the model intercept.
>>
>> If you want to try something similar with the full nested structure it's
>> more complicated still. Then I think you would need something like
>>
>> s(x,by=as.numeric(z!=0)) + s(z) + ti(x,z,bs=c("cr","foo"))
>>
>> Simon
>>
>>
>>
>> On 11/01/18 22:33, Alejandra Mart?nez Blancas wrote:
>>>
>>> I am fitting a model in which the response variable y is a function of
>>> two independent, quantitative variables x1 and x2; thus: y = f(x1,
>>> x2). For reasons I do not believe to be important for the purpose of
>>> this post, I find it desirable to find f by means of GAM; also, I
>>> require principal effects and interactions to be specified separately,
>>> so I am using using te and ti tensors. Thus, I am using the following
>>> command:
>>>
>>>
>>>
>>> f = gam(y ~ te(x1) + te(x2) + ti(x1, x2))
>>>
>>>
>>>
>>> This results in a model that corresponds to one of the hypotheses I am
>>> testing. Nevertheless, another hypothesis requires that, when one of
>>> the independent variables (say x2) is zero, the value of y is
>>> unaffected by the other variable (in this example x1). In other words
>>> f(x1, 0) = k for every value of x1, where k is a constant to be
>>> estimated. For x2 values other than zero I would like to let GAM
>>> choose the appropriate function relating x1 and y. Is there a way to
>>> specify such model in mgcv?
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
>> +44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From bogaso.christofer at gmail.com  Sat Jan 13 22:06:58 2018
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 14 Jan 2018 02:36:58 +0530
Subject: [R] How to programmatically save a web-page using R (mimicking
	Command+S)
In-Reply-To: <CAFDcVCTrokvog0+Q4sUR+zyCy2wVE7CgrWuyigKXAfyoekFCUg@mail.gmail.com>
References: <CA+dpOJmuPUgLhO6j3Pfpk2o2ofPB0+1raD0i4tRqg1DOmbftdw@mail.gmail.com>
 <CAFDcVCTrokvog0+Q4sUR+zyCy2wVE7CgrWuyigKXAfyoekFCUg@mail.gmail.com>
Message-ID: <CA+dpOJnakjoYsyBGNpE+5PE31pAfdR1QstwyRAiYcjpp8x5ucA@mail.gmail.com>

Hi Henrik,

Thanks for your pointer. Saving via PDF is working for me, however, in
many cases, it is unusually taking a long time.

In many cases I am facing Error too as below. This is particularly
occurring if I trigger Multicore calculation option

webshot.js returned failure value: 1

Just wondering if there is any other direct ways to achieve the same.

Thanks,

On Sat, Jan 6, 2018 at 7:14 PM, Henrik Bengtsson
<henrik.bengtsson at gmail.com> wrote:
> The 'webshot' package (on CRAN) can do this.
>
> Henrik
>
> On Jan 6, 2018 05:27, "Christofer Bogaso" <bogaso.christofer at gmail.com>
> wrote:
>>
>> Hi,
>>
>> I would appreciate if someone can give me a pointer on how to save a
>> webpage programmatically using R.
>>
>> For example, let say I have this webpage open in my browser:
>>
>> http://www.bseindia.com/stock-share-price/dabur-india-ltd/dabur/500096/
>>
>> When manually I save this page, I just press Command+S (using Mac) and
>> then this page get saved in hard-disk
>>
>> Now I want R to mimic this same job that I do using Command-S
>>
>> So far I have tried with readLines() however the output content is
>> different than what I could achieve using Command+S
>>
>> Any help will be highly appreciated.
>>
>> Thanks for your time.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From iwritecode2 at gmail.com  Sat Jan 13 22:14:35 2018
From: iwritecode2 at gmail.com (Robert Wilkins)
Date: Sat, 13 Jan 2018 16:14:35 -0500
Subject: [R] Clinical Trial data sets in public domain?
Message-ID: <CAGW5CW_dNKDpOnK9qxAuLG7LwMezDFnFMwNBLXzC0QxEvHQMjQ@mail.gmail.com>

Is anybody using R to do analysis of clinical trial datasets that have been
put in the public domain (which are super hard to find). Not only a single
data table, but the actual database, with a handful of data tables with
one-to-one or many-to-one relationships?

[ For example, "Adverse Events" and "Patient Info" are two datasets with a
many-to-one relationship, the "Patient Info" dataset has precisely one row
for each patient who received a dose of study drug.]

Robert Wilkins

	[[alternative HTML version deleted]]


From es at enricoschumann.net  Sun Jan 14 09:51:51 2018
From: es at enricoschumann.net (Enrico Schumann)
Date: Sun, 14 Jan 2018 09:51:51 +0100
Subject: [R] How to programmatically save a web-page using R (mimicking
	Command+S)
In-Reply-To: <CA+dpOJmuPUgLhO6j3Pfpk2o2ofPB0+1raD0i4tRqg1DOmbftdw@mail.gmail.com>
 (Christofer Bogaso's message of "Sat, 6 Jan 2018 18:57:07 +0530")
References: <CA+dpOJmuPUgLhO6j3Pfpk2o2ofPB0+1raD0i4tRqg1DOmbftdw@mail.gmail.com>
Message-ID: <871sisomag.fsf@enricoschumann.net>

On Sat, 06 Jan 2018, Christofer Bogaso writes:

> Hi,
>
> I would appreciate if someone can give me a pointer on how to save a
> webpage programmatically using R.
>
> For example, let say I have this webpage open in my browser:
>
> http://www.bseindia.com/stock-share-price/dabur-india-ltd/dabur/500096/
>
> When manually I save this page, I just press Command+S (using Mac) and
> then this page get saved in hard-disk
>
> Now I want R to mimic this same job that I do using Command-S
>
> So far I have tried with readLines() however the output content is
> different than what I could achieve using Command+S
>
> Any help will be highly appreciated.
>
> Thanks for your time.
>

The command-line utility 'wget' can download websites,
including graphics, etc. Look for 'mirror' in its
documentation if you want to download the complete
site. It is usually available by default on Unix-style
systems; I am sure there is a version for Mac. If you
insist on using R, you could write a simple wrapper,
using ?system or ?system2.


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From jfox at mcmaster.ca  Sun Jan 14 16:35:34 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Sun, 14 Jan 2018 15:35:34 +0000
Subject: [R] SpreadLevelPlot for more than one factor
In-Reply-To: <CAC8=1erFivyNhvqhnpS0Wj-KPBEUdH00NvFPN4NV2xwte+osDA@mail.gmail.com>
References: <30617_1515301673_w0757qS5022949_CAC8=1erwSbShZ46SvbN_MGYEwDsV-15uGSriNxA6J_KcF0zUTw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836754E17@FHSDB2D11-2.csu.mcmaster.ca>
 <CAC8=1erFivyNhvqhnpS0Wj-KPBEUdH00NvFPN4NV2xwte+osDA@mail.gmail.com>
Message-ID: <D680E093.7ED5%jfox@mcmaster.ca>

Dear Ashim,

I?ll address your questions briefly but they?re really not appropriate for
this list, which is for questions about using R, not general statistical
questions. 

(1) The relevant distribution is within cells of the wool x tension
cross-classification because it?s the deviations from the cell means that
are supposed to be normally distributed with equal variance. In the
warpbreaks data there are only 9 cases per cell. If you examine all of
these deviations simultaneously, that?s equivalent to examining the
residuals from the two-way ANOVA model fit to the data.

(2) Yes, (d) and (e) visualize simple effects, and (a) and (b) visualize
main effects, the latter only because the data are balanced.

Best,
 John

-------------------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: http://socserv.mcmaster.ca/jfox/




On 2018-01-09, 10:18 AM, "Ashim Kapoor" <ashimkapoor at gmail.com> wrote:

>Dear Sir,
>
>
>Many thanks for your reply.
>
>
>I have a query.
>
>
>
>I have a whole set of distributions which should be made normal /
>homoscedastic. Take for instance the warpbreaks data set.
>
>
>
>We have the following boxplots for the warpbreaks dataset:
>
>
>a. boxplot(breaks ~ wool)
>
>b. boxplot(breaks ~ tension)
>
>c. boxplot(breaks ~ interaction(wool,tension))
>d. boxplot(breaks ~ wool @ each level of tension)
>e. boxplot(breaks ~ tension @ each level of wool)
>
>
>Now should we not be making a-e normal and homoscedastic? Should we not
>make a giant collection of boxplots from a-e and use the SpreadLevelPlot
>on this entire collection?
>
>
>A second query : (d) and (e) are the distribution of the simple effects
>of factor wool and tension @ each level of the other. Is that correct?
>Are (a) and (b) the distribution of the main effect of wool and tension?
>Please confirm.
>
>
>
>Best Regards,
>Ashim
>
>
>
>
>
>
>
>
>
>On Sun, Jan 7, 2018 at 8:05 PM, Fox, John
><jfox at mcmaster.ca> wrote:
>
>Dear Ashim,
>
>Try spreadLevelPlot(breaks ~ interaction(tension, wool), data=warpbreaks)
>.
>
>I hope this helps,
> John
>
>-----------------------------
>John Fox, Professor Emeritus
>McMaster University
>Hamilton, Ontario, Canada
>Web: 
>socialsciences.mcmaster.ca/jfox/ <http://socialsciences.mcmaster.ca/jfox/>
>
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
>> Kapoor
>> Sent: Sunday, January 7, 2018 12:08 AM
>> To: r-help at r-project.org
>> Subject: [R] SpreadLevelPlot for more than one factor
>>
>> Dear All,
>>
>> I want a transformation which will make the spread of the response at
>>all
>> combinations of  2 factors the same.
>>
>> See for example :
>>
>> boxplot(breaks ~ tension * wool, warpbreaks)
>>
>> The closest I  can do is :
>>
>> spreadLevelPlot(breaks ~tension , warpbreaks) spreadLevelPlot(breaks ~
>>wool ,
>> warpbreaks)
>>
>> I want to do :
>>
>> spreadLevelPlot(breaks ~tension * wool, warpbreaks)
>>
>> But I get :
>>
>> > spreadLevelPlot(breaks ~tension * wool , warpbreaks)
>> Error in spreadLevelPlot.formula(breaks ~ tension * wool, warpbreaks) :
>>   right-hand side of model has more than one variable
>>
>> What is the corresponding appropriate function for 2 factors ?
>>
>> Many thanks,
>> Ashim
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> 
>https://stat.ethz.ch/mailman/listinfo/r-help
><https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide
>http://www.R-project.org/posting- <http://www.R-project.org/posting->
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>


From lists at dewey.myzen.co.uk  Sun Jan 14 17:28:24 2018
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 14 Jan 2018 16:28:24 +0000
Subject: [R] Clinical Trial data sets in public domain?
In-Reply-To: <CAGW5CW_dNKDpOnK9qxAuLG7LwMezDFnFMwNBLXzC0QxEvHQMjQ@mail.gmail.com>
References: <CAGW5CW_dNKDpOnK9qxAuLG7LwMezDFnFMwNBLXzC0QxEvHQMjQ@mail.gmail.com>
Message-ID: <98b47c35-6458-90e4-5489-2be53784114a@dewey.myzen.co.uk>

Dear Robert

This might seem more suited to the Open Data site in the Stack Exchange 
family. The answer must depend on what you mean by public domain as data 
sets are available from drug company sites on application but presumably 
with restrictions on re-publication.

Michael

On 13/01/2018 21:14, Robert Wilkins wrote:
> Is anybody using R to do analysis of clinical trial datasets that have been
> put in the public domain (which are super hard to find). Not only a single
> data table, but the actual database, with a handful of data tables with
> one-to-one or many-to-one relationships?
> 
> [ For example, "Adverse Events" and "Patient Info" are two datasets with a
> many-to-one relationship, the "Patient Info" dataset has precisely one row
> for each patient who received a dose of study drug.]
> 
> Robert Wilkins
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From ycding at coh.org  Sun Jan 14 18:17:42 2018
From: ycding at coh.org (Ding, Yuan Chun)
Date: Sun, 14 Jan 2018 17:17:42 +0000
Subject: [R] consolidate three function into one
Message-ID: <A86C6438FB909A409DDEF926277952B6A5F75A@PPWEXCH2KX14.coh.org>

HI R users,

I construct dendrogram tree and cut the tree into different clusters, then generate survival curves by the following three functions. All variables are included in an inputfile. 

Can you help me to consolidate the following three function into one functions?  I thought about using if  else function, but not sure how to do it.

Thank you,

Ding

# function to generate RFS
RFS2cluster <- function( inputfile ) {
  cluster2<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
                               data = inputfile)
  
  ggsurvplot(cluster2, data = inputfile, risk.table = F,
             palette = c("red", "black"),
             ylim=c(0,1),
             ggtheme = theme_bw(),
             xlab="Relapse Free Suvival (Days)",
             main = "Survival curve",
             pval = TRUE,
             font.x =  16,
             font.y = 16,
             font.tickslab = 14,
             font.legend =c(14,"plain","black"),
             legend = "bottom", 
             legend.title = "Tree Cluster",
             legend.labs = c("Cluster1", "Cluster2"), lty=1, lwd=3)
}

RFS3cluster <- function( inputfile ) {
  cluster3<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
                     data = inputfile)
  
  ggsurvplot(cluster3, data = inputfile, risk.table = F,
             palette = c("red", "black", "green"),
             ylim=c(0,1),
             ggtheme = theme_bw(),
             xlab="Relapse Free Suvival (Days)",
             main = "Survival curve",
             pval = TRUE,
             font.x =  16,
             font.y = 16,
             font.tickslab = 14,
             font.legend =c(14,"plain","black"),
             legend = "bottom", 
             legend.title = "Tree Cluster",
             legend.labs = c("Cluster1", "Cluster2", "Cluster3"), lty=1, lwd=3)
}

RFS4cluster <- function( inputfile ) {
  cluster4<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
                     data = inputfile)
  
  ggsurvplot(cluster4, data = inputfile, risk.table = F,
             palette = c("red", "black", "green", "blue"),
             ylim=c(0,1),
             ggtheme = theme_bw(),
             xlab="Relapse Free Suvival (Days)",
             main = "Survival curve",
             pval = TRUE,
             font.x =  16,
             font.y = 16,
             font.tickslab = 14,
             font.legend =c(14,"plain","black"),
             legend = "bottom", 
             legend.title = "Tree Cluster",
             legend.labs = c("Cluster1", "Cluster2", "Cluster3", "Cluster4"), lty=1, lwd=3)
}

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of imane hajar
Sent: Friday, January 12, 2018 7:42 AM
To: r-help at r-project.org
Subject: [R] Help with packages (methods, stats, stats4)

[Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]





hello,
Can you please give me a hand with this problem,well i can't install these
packages:
- stats
- methods
- stats4

when i tried the following command :  *library(help = "stats") * , it gave me this output (*see picture*), so i contacted the Maintainer of the package at (*R-core at r-project.org <R-core at r-project.org>*) but he said that i write to the wrong place.

(i want to install those packages in order to use the "DVstats" package)

(i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )

thank you
Regards


---------------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-
This message (and any attachments) are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
---------------------------------------------------------------------


From ycding at coh.org  Sun Jan 14 19:01:02 2018
From: ycding at coh.org (Ding, Yuan Chun)
Date: Sun, 14 Jan 2018 18:01:02 +0000
Subject: [R] consolidate three function into one
In-Reply-To: <CAGxFJbR3o5ozohXSkgqueROYCO=NsWdWZMP73GnM29TB0J0Dsg@mail.gmail.com>
References: <A86C6438FB909A409DDEF926277952B6A5F75A@PPWEXCH2KX14.coh.org>
 <CAGxFJbR3o5ozohXSkgqueROYCO=NsWdWZMP73GnM29TB0J0Dsg@mail.gmail.com>
Message-ID: <A86C6438FB909A409DDEF926277952B6A607A5@PPWEXCH2KX14.coh.org>

Hi Bert,

Thank you, yes, you are right.  I want to consolidate the three functions into one functions by adding more arguments, adding flexibility  to accommodate  the number of clusters or  the number of Kaplan Meier  curves generated in one figure.  So, I just need to define one function.

Thanks,

Ding

From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Sunday, January 14, 2018 9:50 AM
To: Ding, Yuan Chun <ycding at coh.org>
Subject: Re: [R] consolidate three function into one

I have not looked at your code *at all*, so I am not sure what exactly you mean by "consolidate."
Is this what you are after?

f1 <- function(...) { code 1}
f2 <- function(...) { code 2}
f3 <- function(...) { code 3}
## can be "consolidated as":
f <- function( someargs, ...){
if( expr(someargs)) f1(...)
else if(expr2(someargs)) f2(...)
else f3(...)
}
The "..." argument to f can soak up any named additional arguments you wish to pass to f1, f2, or f3.
My apologies if this is offbase or too vague, and feel free to ignore in that case. I don't have the patience to go trough your code in detail. Others may and give you what you want.
Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Jan 14, 2018 at 9:17 AM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org>> wrote:
HI R users,

I construct dendrogram tree and cut the tree into different clusters, then generate survival curves by the following three functions. All variables are included in an inputfile.

Can you help me to consolidate the following three function into one functions?  I thought about using if  else function, but not sure how to do it.

Thank you,

Ding

# function to generate RFS
RFS2cluster <- function( inputfile ) {
  cluster2<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
                               data = inputfile)

  ggsurvplot(cluster2, data = inputfile, risk.table = F,
             palette = c("red", "black"),
             ylim=c(0,1),
             ggtheme = theme_bw(),
             xlab="Relapse Free Suvival (Days)",
             main = "Survival curve",
             pval = TRUE,
             font.x =  16,
             font.y = 16,
             font.tickslab = 14,
             font.legend =c(14,"plain","black"),
             legend = "bottom",
             legend.title = "Tree Cluster",
             legend.labs = c("Cluster1", "Cluster2"), lty=1, lwd=3)
}

RFS3cluster <- function( inputfile ) {
  cluster3<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
                     data = inputfile)

  ggsurvplot(cluster3, data = inputfile, risk.table = F,
             palette = c("red", "black", "green"),
             ylim=c(0,1),
             ggtheme = theme_bw(),
             xlab="Relapse Free Suvival (Days)",
             main = "Survival curve",
             pval = TRUE,
             font.x =  16,
             font.y = 16,
             font.tickslab = 14,
             font.legend =c(14,"plain","black"),
             legend = "bottom",
             legend.title = "Tree Cluster",
             legend.labs = c("Cluster1", "Cluster2", "Cluster3"), lty=1, lwd=3)
}

RFS4cluster <- function( inputfile ) {
  cluster4<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
                     data = inputfile)

  ggsurvplot(cluster4, data = inputfile, risk.table = F,
             palette = c("red", "black", "green", "blue"),
             ylim=c(0,1),
             ggtheme = theme_bw(),
             xlab="Relapse Free Suvival (Days)",
             main = "Survival curve",
             pval = TRUE,
             font.x =  16,
             font.y = 16,
             font.tickslab = 14,
             font.legend =c(14,"plain","black"),
             legend = "bottom",
             legend.title = "Tree Cluster",
             legend.labs = c("Cluster1", "Cluster2", "Cluster3", "Cluster4"), lty=1, lwd=3)
}

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of imane hajar
Sent: Friday, January 12, 2018 7:42 AM
To: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: [R] Help with packages (methods, stats, stats4)

[Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]





hello,
Can you please give me a hand with this problem,well i can't install these
packages:
- stats
- methods
- stats4

when i tried the following command :  *library(help = "stats") * , it gave me this output (*see picture*), so i contacted the Maintainer of the package at (*R-core at r-project.org<mailto:R-core at r-project.org> <R-core at r-project.org<mailto:R-core at r-project.org>>*) but he said that i write to the wrong place.

(i want to install those packages in order to use the "DVstats" package)

(i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )

thank you
Regards


---------------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-
This message (and any attachments) are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to r
 eceive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
---------------------------------------------------------------------

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From ycding at coh.org  Sun Jan 14 22:21:28 2018
From: ycding at coh.org (Ding, Yuan Chun)
Date: Sun, 14 Jan 2018 21:21:28 +0000
Subject: [R] consolidate three function into one
In-Reply-To: <CAGxFJbR3o5ozohXSkgqueROYCO=NsWdWZMP73GnM29TB0J0Dsg@mail.gmail.com>
References: <A86C6438FB909A409DDEF926277952B6A5F75A@PPWEXCH2KX14.coh.org>
 <CAGxFJbR3o5ozohXSkgqueROYCO=NsWdWZMP73GnM29TB0J0Dsg@mail.gmail.com>
Message-ID: <A86C6438FB909A409DDEF926277952B6A6080B@PPWEXCH2KX14.coh.org>

Hi Bert,

I am sorry to bother you on weekend.

I am still struggling on defining a correct function.

I first defined the function RFS (see below), then run it by provide the two argument.

m52.2cluster <-RFS(inputfile =allinfo_m52, N=2 )

I do not get error message, but no figure displays on screen. I do not know what is going on.

Can you help me a little more on this issue?

Thank you,

Ding

# function to generate RFS
RFS <- function( inputfile, N ) {
  cluster<- survfit(Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ clusters,
                               data = inputfile)

         if( N==2) {palette <- c("red", "black")
                           legend.labs <- c("Cluster1", "Cluster2")
                            }

  else if(N==3) {palette <- c("red", "black", "green")
                      legend.labs <- c("Cluster1", "Cluster2", "Cluster3")
                            }

                 else {palette <- c("red", "black","green", "blue")
                           legend.labs <- c("Cluster1", "Cluster2", "Cluster3", "Cluster4")
                          }

  ggsurvplot(cluster, data = inputfile, risk.table = F,
             palette = palette,
             ylim=c(0,1),ggtheme = theme_bw(),xlab="Relapse Free Suvival (Days)",
             main = "Survival curve",pval = TRUE,font.x =  16,font.y = 16,
             font.tickslab = 14,font.legend =c(14,"plain","black"),
             legend = "bottom",
             legend.title = "Tree Cluster",
             legend.labs = legend.labs,
             lty=1, lwd=3)
                                }

From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Sunday, January 14, 2018 9:50 AM
To: Ding, Yuan Chun <ycding at coh.org>
Subject: Re: [R] consolidate three function into one

I have not looked at your code *at all*, so I am not sure what exactly you mean by "consolidate."
Is this what you are after?

f1 <- function(...) { code 1}
f2 <- function(...) { code 2}
f3 <- function(...) { code 3}
## can be "consolidated as":
f <- function( someargs, ...){
if( expr(someargs)) f1(...)
else if(expr2(someargs)) f2(...)
else f3(...)
}
The "..." argument to f can soak up any named additional arguments you wish to pass to f1, f2, or f3.
My apologies if this is offbase or too vague, and feel free to ignore in that case. I don't have the patience to go trough your code in detail. Others may and give you what you want.
Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Jan 14, 2018 at 9:17 AM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org>> wrote:
HI R users,

I construct dendrogram tree and cut the tree into different clusters, then generate survival curves by the following three functions. All variables are included in an inputfile.

Can you help me to consolidate the following three function into one functions?  I thought about using if  else function, but not sure how to do it.

Thank you,

Ding

# function to generate RFS
RFS2cluster <- function( inputfile ) {
  cluster2<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
                               data = inputfile)

  ggsurvplot(cluster2, data = inputfile, risk.table = F,
             palette = c("red", "black"),
             ylim=c(0,1),
             ggtheme = theme_bw(),
             xlab="Relapse Free Suvival (Days)",
             main = "Survival curve",
             pval = TRUE,
             font.x =  16,
             font.y = 16,
             font.tickslab = 14,
             font.legend =c(14,"plain","black"),
             legend = "bottom",
             legend.title = "Tree Cluster",
             legend.labs = c("Cluster1", "Cluster2"), lty=1, lwd=3)
}

RFS3cluster <- function( inputfile ) {
  cluster3<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
                     data = inputfile)

  ggsurvplot(cluster3, data = inputfile, risk.table = F,
             palette = c("red", "black", "green"),
             ylim=c(0,1),
             ggtheme = theme_bw(),
             xlab="Relapse Free Suvival (Days)",
             main = "Survival curve",
             pval = TRUE,
             font.x =  16,
             font.y = 16,
             font.tickslab = 14,
             font.legend =c(14,"plain","black"),
             legend = "bottom",
             legend.title = "Tree Cluster",
             legend.labs = c("Cluster1", "Cluster2", "Cluster3"), lty=1, lwd=3)
}

RFS4cluster <- function( inputfile ) {
  cluster4<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
                     data = inputfile)

  ggsurvplot(cluster4, data = inputfile, risk.table = F,
             palette = c("red", "black", "green", "blue"),
             ylim=c(0,1),
             ggtheme = theme_bw(),
             xlab="Relapse Free Suvival (Days)",
             main = "Survival curve",
             pval = TRUE,
             font.x =  16,
             font.y = 16,
             font.tickslab = 14,
             font.legend =c(14,"plain","black"),
             legend = "bottom",
             legend.title = "Tree Cluster",
             legend.labs = c("Cluster1", "Cluster2", "Cluster3", "Cluster4"), lty=1, lwd=3)
}

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of imane hajar
Sent: Friday, January 12, 2018 7:42 AM
To: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: [R] Help with packages (methods, stats, stats4)

[Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]





hello,
Can you please give me a hand with this problem,well i can't install these
packages:
- stats
- methods
- stats4

when i tried the following command :  *library(help = "stats") * , it gave me this output (*see picture*), so i contacted the Maintainer of the package at (*R-core at r-project.org<mailto:R-core at r-project.org> <R-core at r-project.org<mailto:R-core at r-project.org>>*) but he said that i write to the wrong place.

(i want to install those packages in order to use the "DVstats" package)

(i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )

thank you
Regards


---------------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-
This message (and any attachments) are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to r
 eceive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
---------------------------------------------------------------------

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From rmh at temple.edu  Sun Jan 14 22:33:41 2018
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sun, 14 Jan 2018 16:33:41 -0500
Subject: [R] consolidate three function into one
In-Reply-To: <A86C6438FB909A409DDEF926277952B6A6080B@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6A5F75A@PPWEXCH2KX14.coh.org>
 <CAGxFJbR3o5ozohXSkgqueROYCO=NsWdWZMP73GnM29TB0J0Dsg@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A6080B@PPWEXCH2KX14.coh.org>
Message-ID: <CAGx1TMC_UGr79xxq570Ycnyg90S=UHC9gBJmM2pmdWpugKOMWQ@mail.gmail.com>

FAQ 7.22
You must print a ggplot object, for example with
print(m52.2cluster)

For the FAQ, run the line
   system.file("../../doc/FAQ")
in R on your computer.
Open up the resulting filepath in your favorite editor and scroll down to 7.22

On Sun, Jan 14, 2018 at 4:21 PM, Ding, Yuan Chun <ycding at coh.org> wrote:
> Hi Bert,
>
> I am sorry to bother you on weekend.
>
> I am still struggling on defining a correct function.
>
> I first defined the function RFS (see below), then run it by provide the two argument.
>
> m52.2cluster <-RFS(inputfile =allinfo_m52, N=2 )
>
> I do not get error message, but no figure displays on screen. I do not know what is going on.
>
> Can you help me a little more on this issue?
>
> Thank you,
>
> Ding
>
> # function to generate RFS
> RFS <- function( inputfile, N ) {
>   cluster<- survfit(Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ clusters,
>                                data = inputfile)
>
>          if( N==2) {palette <- c("red", "black")
>                            legend.labs <- c("Cluster1", "Cluster2")
>                             }
>
>   else if(N==3) {palette <- c("red", "black", "green")
>                       legend.labs <- c("Cluster1", "Cluster2", "Cluster3")
>                             }
>
>                  else {palette <- c("red", "black","green", "blue")
>                            legend.labs <- c("Cluster1", "Cluster2", "Cluster3", "Cluster4")
>                           }
>
>   ggsurvplot(cluster, data = inputfile, risk.table = F,
>              palette = palette,
>              ylim=c(0,1),ggtheme = theme_bw(),xlab="Relapse Free Suvival (Days)",
>              main = "Survival curve",pval = TRUE,font.x =  16,font.y = 16,
>              font.tickslab = 14,font.legend =c(14,"plain","black"),
>              legend = "bottom",
>              legend.title = "Tree Cluster",
>              legend.labs = legend.labs,
>              lty=1, lwd=3)
>                                 }
>
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> Sent: Sunday, January 14, 2018 9:50 AM
> To: Ding, Yuan Chun <ycding at coh.org>
> Subject: Re: [R] consolidate three function into one
>
> I have not looked at your code *at all*, so I am not sure what exactly you mean by "consolidate."
> Is this what you are after?
>
> f1 <- function(...) { code 1}
> f2 <- function(...) { code 2}
> f3 <- function(...) { code 3}
> ## can be "consolidated as":
> f <- function( someargs, ...){
> if( expr(someargs)) f1(...)
> else if(expr2(someargs)) f2(...)
> else f3(...)
> }
> The "..." argument to f can soak up any named additional arguments you wish to pass to f1, f2, or f3.
> My apologies if this is offbase or too vague, and feel free to ignore in that case. I don't have the patience to go trough your code in detail. Others may and give you what you want.
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sun, Jan 14, 2018 at 9:17 AM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org>> wrote:
> HI R users,
>
> I construct dendrogram tree and cut the tree into different clusters, then generate survival curves by the following three functions. All variables are included in an inputfile.
>
> Can you help me to consolidate the following three function into one functions?  I thought about using if  else function, but not sure how to do it.
>
> Thank you,
>
> Ding
>
> # function to generate RFS
> RFS2cluster <- function( inputfile ) {
>   cluster2<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
>                                data = inputfile)
>
>   ggsurvplot(cluster2, data = inputfile, risk.table = F,
>              palette = c("red", "black"),
>              ylim=c(0,1),
>              ggtheme = theme_bw(),
>              xlab="Relapse Free Suvival (Days)",
>              main = "Survival curve",
>              pval = TRUE,
>              font.x =  16,
>              font.y = 16,
>              font.tickslab = 14,
>              font.legend =c(14,"plain","black"),
>              legend = "bottom",
>              legend.title = "Tree Cluster",
>              legend.labs = c("Cluster1", "Cluster2"), lty=1, lwd=3)
> }
>
> RFS3cluster <- function( inputfile ) {
>   cluster3<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
>                      data = inputfile)
>
>   ggsurvplot(cluster3, data = inputfile, risk.table = F,
>              palette = c("red", "black", "green"),
>              ylim=c(0,1),
>              ggtheme = theme_bw(),
>              xlab="Relapse Free Suvival (Days)",
>              main = "Survival curve",
>              pval = TRUE,
>              font.x =  16,
>              font.y = 16,
>              font.tickslab = 14,
>              font.legend =c(14,"plain","black"),
>              legend = "bottom",
>              legend.title = "Tree Cluster",
>              legend.labs = c("Cluster1", "Cluster2", "Cluster3"), lty=1, lwd=3)
> }
>
> RFS4cluster <- function( inputfile ) {
>   cluster4<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
>                      data = inputfile)
>
>   ggsurvplot(cluster4, data = inputfile, risk.table = F,
>              palette = c("red", "black", "green", "blue"),
>              ylim=c(0,1),
>              ggtheme = theme_bw(),
>              xlab="Relapse Free Suvival (Days)",
>              main = "Survival curve",
>              pval = TRUE,
>              font.x =  16,
>              font.y = 16,
>              font.tickslab = 14,
>              font.legend =c(14,"plain","black"),
>              legend = "bottom",
>              legend.title = "Tree Cluster",
>              legend.labs = c("Cluster1", "Cluster2", "Cluster3", "Cluster4"), lty=1, lwd=3)
> }
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of imane hajar
> Sent: Friday, January 12, 2018 7:42 AM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] Help with packages (methods, stats, stats4)
>
> [Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]
>
>
>
>
>
> hello,
> Can you please give me a hand with this problem,well i can't install these
> packages:
> - stats
> - methods
> - stats4
>
> when i tried the following command :  *library(help = "stats") * , it gave me this output (*see picture*), so i contacted the Maintainer of the package at (*R-core at r-project.org<mailto:R-core at r-project.org> <R-core at r-project.org<mailto:R-core at r-project.org>>*) but he said that i write to the wrong place.
>
> (i want to install those packages in order to use the "DVstats" package)
>
> (i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )
>
> thank you
> Regards
>
>
> ---------------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
> This message (and any attachments) are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to r
>  eceive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
> ---------------------------------------------------------------------
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ashimkapoor at gmail.com  Mon Jan 15 10:52:18 2018
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Mon, 15 Jan 2018 15:22:18 +0530
Subject: [R] SpreadLevelPlot for more than one factor
In-Reply-To: <D680E093.7ED5%jfox@mcmaster.ca>
References: <30617_1515301673_w0757qS5022949_CAC8=1erwSbShZ46SvbN_MGYEwDsV-15uGSriNxA6J_KcF0zUTw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836754E17@FHSDB2D11-2.csu.mcmaster.ca>
 <CAC8=1erFivyNhvqhnpS0Wj-KPBEUdH00NvFPN4NV2xwte+osDA@mail.gmail.com>
 <D680E093.7ED5%jfox@mcmaster.ca>
Message-ID: <CAC8=1eqayYrUmjgRUa_3YWSnwWYSF4a_D+q2_ik9b76kPBD87Q@mail.gmail.com>

Dear Sir,

Many thanks and Best Regards,
Ashim.

On Sun, Jan 14, 2018 at 9:05 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Ashim,
>
> I?ll address your questions briefly but they?re really not appropriate for
> this list, which is for questions about using R, not general statistical
> questions.
>
> (1) The relevant distribution is within cells of the wool x tension
> cross-classification because it?s the deviations from the cell means that
> are supposed to be normally distributed with equal variance. In the
> warpbreaks data there are only 9 cases per cell. If you examine all of
> these deviations simultaneously, that?s equivalent to examining the
> residuals from the two-way ANOVA model fit to the data.
>
> (2) Yes, (d) and (e) visualize simple effects, and (a) and (b) visualize
> main effects, the latter only because the data are balanced.
>
> Best,
>  John
>
> -------------------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: http://socserv.mcmaster.ca/jfox/
>
>
>
>
> On 2018-01-09, 10:18 AM, "Ashim Kapoor" <ashimkapoor at gmail.com> wrote:
>
> >Dear Sir,
> >
> >
> >Many thanks for your reply.
> >
> >
> >I have a query.
> >
> >
> >
> >I have a whole set of distributions which should be made normal /
> >homoscedastic. Take for instance the warpbreaks data set.
> >
> >
> >
> >We have the following boxplots for the warpbreaks dataset:
> >
> >
> >a. boxplot(breaks ~ wool)
> >
> >b. boxplot(breaks ~ tension)
> >
> >c. boxplot(breaks ~ interaction(wool,tension))
> >d. boxplot(breaks ~ wool @ each level of tension)
> >e. boxplot(breaks ~ tension @ each level of wool)
> >
> >
> >Now should we not be making a-e normal and homoscedastic? Should we not
> >make a giant collection of boxplots from a-e and use the SpreadLevelPlot
> >on this entire collection?
> >
> >
> >A second query : (d) and (e) are the distribution of the simple effects
> >of factor wool and tension @ each level of the other. Is that correct?
> >Are (a) and (b) the distribution of the main effect of wool and tension?
> >Please confirm.
> >
> >
> >
> >Best Regards,
> >Ashim
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >On Sun, Jan 7, 2018 at 8:05 PM, Fox, John
> ><jfox at mcmaster.ca> wrote:
> >
> >Dear Ashim,
> >
> >Try spreadLevelPlot(breaks ~ interaction(tension, wool), data=warpbreaks)
> >.
> >
> >I hope this helps,
> > John
> >
> >-----------------------------
> >John Fox, Professor Emeritus
> >McMaster University
> >Hamilton, Ontario, Canada
> >Web:
> >socialsciences.mcmaster.ca/jfox/ <http://socialsciences.mcmaster.ca/jfox/
> >
> >
> >
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
> >> Kapoor
> >> Sent: Sunday, January 7, 2018 12:08 AM
> >> To: r-help at r-project.org
> >> Subject: [R] SpreadLevelPlot for more than one factor
> >>
> >> Dear All,
> >>
> >> I want a transformation which will make the spread of the response at
> >>all
> >> combinations of  2 factors the same.
> >>
> >> See for example :
> >>
> >> boxplot(breaks ~ tension * wool, warpbreaks)
> >>
> >> The closest I  can do is :
> >>
> >> spreadLevelPlot(breaks ~tension , warpbreaks) spreadLevelPlot(breaks ~
> >>wool ,
> >> warpbreaks)
> >>
> >> I want to do :
> >>
> >> spreadLevelPlot(breaks ~tension * wool, warpbreaks)
> >>
> >> But I get :
> >>
> >> > spreadLevelPlot(breaks ~tension * wool , warpbreaks)
> >> Error in spreadLevelPlot.formula(breaks ~ tension * wool, warpbreaks) :
> >>   right-hand side of model has more than one variable
> >>
> >> What is the corresponding appropriate function for 2 factors ?
> >>
> >> Many thanks,
> >> Ashim
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>
> >https://stat.ethz.ch/mailman/listinfo/r-help
> ><https://stat.ethz.ch/mailman/listinfo/r-help>
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting- <http://www.R-project.org/posting->
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> >
>
>

	[[alternative HTML version deleted]]


From archerrish at gmail.com  Mon Jan 15 09:58:55 2018
From: archerrish at gmail.com (Max Shell)
Date: Mon, 15 Jan 2018 16:58:55 +0800
Subject: [R] Time-dependent coefficients in a Cox model with categorical
	variants
Message-ID: <CAKpGb9DB2sCFjFfrQZSx+n4wN5L8t68ZKLDa6pqLuwkGywK2FA@mail.gmail.com>

Suppose I have a dataset contain three variants, looks like
> head(dta)

  Sex    tumorsize    Histology       time         status
    0            1.5            2              12.1000             0
    1            1.8            1              38.4000             0
.....................

Sex: 1 for male; 0 for female., two levels
Histology: 1 for SqCC; 2 for High risk AC; 3 for low risk AC, three levels
Now I need to get a Time-dependent coefficients cox fit:

library(survival)
for(i in c(1,3) dta[,i] <- factor(dta[,i])
fit <-
  coxph(
    Surv(time, status) ~  Sex + tumorsize +  Histology + tt(Histology),
    data = dta,
    tt = function(x, t, ...) x * log(t)
  )

But  I keep gettting this error says:

Error in if (any(infs)) warning(paste("Loglik converged before variable ",  :
  missing value where TRUE/FALSE needed
In addition: Warning message:
In Ops.factor(x, log(t)) : ?*? not meaningful for factors.

How can I fix it? I know that the "Sex" and "Histology" are both
categorical variants. I  want to have a model that have two ?(t) = a +
blog(t) for each histology level.
Thank you?


From alejandra7galan at gmail.com  Mon Jan 15 10:29:05 2018
From: alejandra7galan at gmail.com (Alejandra Lopez-Galan)
Date: Mon, 15 Jan 2018 19:29:05 +1000
Subject: [R] sum multiple csv files
Message-ID: <CAEu_PQNC=AfAoJWMrMWeGdmb=EkuSKPnXyeZY5DmNS-tV5QHEQ@mail.gmail.com>

Hi, I am pretty new to R and I would apreciatte very much your help to
solve my problem. I have 40 csv files that have the same structure, and I
want to merge them into a single data frame.

I already have load and combined all the cvs files into a large list, and I
created two

filenames <- list.files('data',full.names=TRUE)

All_data <- lapply(filenames,function(i){
  ###read cvs files and add the row and column names to each data frame###
  read.csv(i, header=FALSE, sep = "", col.names = col_names, row.names =
row_names)
 })

However I would like to sum the rows of cvs files to get a single data
frame (each cvs file has 47 rows and colunms, so the final data frame
should have the same). I could only do it one by one data data frame, but I
was wondering if anyone could give an idea of how to write a function for
this.

Thanks,
Alejandra

	[[alternative HTML version deleted]]


From michal.burda at centrum.cz  Mon Jan 15 12:04:13 2018
From: michal.burda at centrum.cz (Michal Burda)
Date: Mon, 15 Jan 2018 12:04:13 +0100
Subject: [R] max and pmax of NA and NaN
Message-ID: <CAP4zaHOJMNWk_7Feh5Zhcyrm5mfEpcJ26RZoN9UNmfOM-csE0A@mail.gmail.com>

Dear R users,

is the following OK?

> max(NA, NaN)
[1] NA
> max(NaN, NA)
[1] NA
> pmax(NaN, NA)
[1] NA
> pmax(NA, NaN)
[1] NaN


...or is it a bug? Documentation says that NA has a higher priority over
NaN.


Best regards, Michal Burda

	[[alternative HTML version deleted]]


From jeremiejuste at gmail.com  Mon Jan 15 13:17:00 2018
From: jeremiejuste at gmail.com (Jeremie Juste)
Date: Mon, 15 Jan 2018 13:17:00 +0100
Subject: [R] sum multiple csv files
In-Reply-To: <CAEu_PQNC=AfAoJWMrMWeGdmb=EkuSKPnXyeZY5DmNS-tV5QHEQ@mail.gmail.com>
 (Alejandra Lopez-Galan's message of "Mon, 15 Jan 2018 19:29:05 +1000")
References: <CAEu_PQNC=AfAoJWMrMWeGdmb=EkuSKPnXyeZY5DmNS-tV5QHEQ@mail.gmail.com>
Message-ID: <87fu77pb9f.fsf@gmail.com>

Alejandra Lopez-Galan <alejandra7galan at gmail.com> writes:
Hello,

I'm not sure to fully answer you question but I'll give it a try. I'll
use the library "data.table" as I forgot how to do it in base R. If you
don't have it you will have to install it by doing

> install.packages(data.table,repos ="http://cran.us.r-project.org")

let's say you have this list of data.frame

> lapply(1:2,function(x) data.frame(B=letters[1:10],A=rnorm(10)))

## [[1]]
##     B          A
##  1 a  1.8276026
##  2 b  0.2870562
##  3 c -0.6304431
##  4 d  0.3066375
##  5 e  0.3274438
##  6 f  0.3370640
##  7 g -1.6660051
##  8 h -0.3736336
##  9 i  0.1494459
## 10 j -1.0036616

## [[2]]
##     B          A
##  1 a -1.1488812
##  2 b -0.4423796
##  3 c -0.2690834
##  4 d -1.1390742
##  5 e  0.7142574
##  6 f  0.3316523
##  7 g  0.3187546
##  8 h  0.1099996
##  9 i  0.3972000
## 10 j  0.4749161

and want to sum the A column for each data.frame then you can use the
following:

# Assign the list to the variable aa
aa <- lapply(1:2,function(x) data.table(B=letters[1:10],A=rnorm(10)))

then:
> >lapply(aa,function(x) data.table(x)[,sum(A)])

## [[1]]
## [1] 6.533179

## [[2]]
## [1] 2.075677


Notice that I converted the each data.frame to a data.table and then sum
the column A.

If you want to bind the resutls together you can do
do.call(rbind,lapply(aa,function(x) data.table(x)[,sum(A)]))

          [,1]
[1,] -9.377476
[2,] -3.853971

HTH,

Best Regards,

Jeremie







> Hi, I am pretty new to R and I would apreciatte very much your help to
> solve my problem. I have 40 csv files that have the same structure, and I
> want to merge them into a single data frame.
>
> I already have load and combined all the cvs files into a large list, and I
> created two
>
> filenames <- list.files('data',full.names=TRUE)
>
> All_data <- lapply(filenames,function(i){
>   ###read cvs files and add the row and column names to each data frame###
>   read.csv(i, header=FALSE, sep = "", col.names = col_names, row.names =
> row_names)
>  })
>
> However I would like to sum the rows of cvs files to get a single data
> frame (each cvs file has 47 rows and colunms, so the final data frame
> should have the same). I could only do it one by one data data frame, but I
> was wondering if anyone could give an idea of how to write a function for
> this.
>
> Thanks,
> Alejandra
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Jan 15 15:40:14 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 15 Jan 2018 14:40:14 +0000
Subject: [R] sum multiple csv files
In-Reply-To: <CAEu_PQNC=AfAoJWMrMWeGdmb=EkuSKPnXyeZY5DmNS-tV5QHEQ@mail.gmail.com>
References: <CAEu_PQNC=AfAoJWMrMWeGdmb=EkuSKPnXyeZY5DmNS-tV5QHEQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD3B0C@SRVEXCHCM301.precheza.cz>

Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alejandra
> Lopez-Galan
> Sent: Monday, January 15, 2018 10:29 AM
> To: r-help at r-project.org
> Subject: [R] sum multiple csv files
>
> Hi, I am pretty new to R and I would apreciatte very much your help to solve
> my problem. I have 40 csv files that have the same structure, and I want to
> merge them into a single data frame.
>
> I already have load and combined all the cvs files into a large list, and I created
> two
>
> filenames <- list.files('data',full.names=TRUE)
>
> All_data <- lapply(filenames,function(i){
>   ###read cvs files and add the row and column names to each data frame###
>   read.csv(i, header=FALSE, sep = "", col.names = col_names, row.names =
> row_names)
>  })
>
> However I would like to sum the rows of cvs files to get a single data frame
> (each cvs file has 47 rows and colunms, so the final data frame should have the
> same). I could only do it one by one data data frame, but I was wondering if

And here I am rather lost. The only possible solution (to me) is to sum all values in first row of file 1, 2, 3, ...

In that case probably the easiest way is to change list to array

aaa<-array(unlist(All_data), dim=c(47,47, 40))
result <- apply(aaa,1:2,sum)

Example:

lll <- structure(list(A = structure(list(V1 = 1:3, V2 = 4:6, V3 = 7:9,
    V4 = 10:12), .Names = c("V1", "V2", "V3", "V4"), row.names = c(NA,
-3L), class = "data.frame"), B = structure(list(V1 = 1:3, V2 = 4:6,
    V3 = 7:9, V4 = 10:12), .Names = c("V1", "V2", "V3", "V4"), row.names = c(NA,
-3L), class = "data.frame")), .Names = c("A", "B"))

> aaa<-array(unlist(lll), dim=c(3,4,2))
> aaa
, , 1

     [,1] [,2] [,3] [,4]
[1,]    1    4    7   10
[2,]    2    5    8   11
[3,]    3    6    9   12

, , 2

     [,1] [,2] [,3] [,4]
[1,]    1    4    7   10
[2,]    2    5    8   11
[3,]    3    6    9   12

> apply(aaa,1:2,sum)
     [,1] [,2] [,3] [,4]
[1,]    2    8   14   20
[2,]    4   10   16   22
[3,]    6   12   18   24

Cheers
Petr

> anyone could give an idea of how to write a function for this.
>
> Thanks,
> Alejandra
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From maechler at stat.math.ethz.ch  Mon Jan 15 16:11:43 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 15 Jan 2018 16:11:43 +0100
Subject: [R] max and pmax of NA and NaN
In-Reply-To: <CAP4zaHOJMNWk_7Feh5Zhcyrm5mfEpcJ26RZoN9UNmfOM-csE0A@mail.gmail.com>
References: <CAP4zaHOJMNWk_7Feh5Zhcyrm5mfEpcJ26RZoN9UNmfOM-csE0A@mail.gmail.com>
Message-ID: <23132.50351.13290.6797@stat.math.ethz.ch>

>>>>> Michal Burda <michal.burda at centrum.cz>
>>>>>     on Mon, 15 Jan 2018 12:04:13 +0100 writes:

    > Dear R users, is the following OK?

    >> max(NA, NaN)
    > [1] NA
    >> max(NaN, NA)
    > [1] NA
    >> pmax(NaN, NA)
    > [1] NA
    >> pmax(NA, NaN)
    > [1] NaN

    > ...or is it a bug? 

    > Documentation says that NA has a higher priority over NaN.

which documentation ??
[That would be quite a bit misleading I think. So, it should be amended ...]

    > Best regards, Michal Burda


R's help pages are *THE* reference documentation and they have 
(for a long time, I think) had :

?NaN   has in its 3rd 'Note:'

     Computations involving ?NaN? will return ?NaN? or perhaps ?NA?:
     which of those two is not guaranteed and may depend on the R
     platform (since compilers may re-order computations).

Similarly,  ?NA  contains, in its 'Details':

     Numerical computations using ?NA? will normally result in ?NA?: a
     possible exception is where ?NaN? is also involved, in which case
     either might result (which may depend on the R platform).  ........

-----

Yes, it is a bit unfortunate that this is platform dependent; if
we wanted to make this entirely consistent (as desired in a
perfect world), I'm almost sure R would become slower because
we'd have to do add some explicit "book keeping" / checking
instead of relying on the underlying C library code.

Note that for these reasons, often NaN and NA should not be
differentiated, and that's reason why using  is.na(*)  is
typically sufficient and "best" -- it gives TRUE for both NA and NaN.


Martin Maechler
ETH Zurich


From jdnewmil at dcn.davis.ca.us  Mon Jan 15 17:35:23 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 15 Jan 2018 08:35:23 -0800
Subject: [R] sum multiple csv files
In-Reply-To: <CAEu_PQNC=AfAoJWMrMWeGdmb=EkuSKPnXyeZY5DmNS-tV5QHEQ@mail.gmail.com>
References: <CAEu_PQNC=AfAoJWMrMWeGdmb=EkuSKPnXyeZY5DmNS-tV5QHEQ@mail.gmail.com>
Message-ID: <F777EAE0-38C0-4887-A34F-BC20964F9DE5@dcn.davis.ca.us>

Your message seems unclear, and as evidence the respondents are giving various answers. You should provide a small sample of input and output data as it would look in R to avoid this kind of thrashing about. See [1][2][3] for guidance. Note that you also really need to figure out how to make sure your email program sends plain text, because HTML formatting WILL be stripped by the mailing list (read the Posting Guide) and that process often garbles it. 

My own possibly-confused reading of your question ("each cvs file has 47 rows and colunms, so the final data frame should have the same") is that you do not yet understand the difference between matrices and data frames ([4]), and you want to perform matrix (element-wise) addition. This would require that you convert the data frames read in by read.csv into matrices before adding them:

All_data <- lapply(filenames
,function(i){
###read cvs files and add the row and column names to each data frame
###
 as.matrix( read.csv(i, header=FALSE, sep = "", col.names = col_names, row.names = row_names)
})

result <- Reduce( `+`, All_data )

This will fail if any of the values in your csv files are non-numeric, but dealing with that would require us to know specifics about your files or intent that you have omitted. (The dput function is indispensable for clarifying such issues [1][2].)
---

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)

[4] see "Introduction to R" (part of the R documentation)

-- 
Sent from my phone. Please excuse my brevity.

On January 15, 2018 1:29:05 AM PST, Alejandra Lopez-Galan <alejandra7galan at gmail.com> wrote:
>Hi, I am pretty new to R and I would apreciatte very much your help to
>solve my problem. I have 40 csv files that have the same structure, and
>I
>want to merge them into a single data frame.
>
>I already have load and combined all the cvs files into a large list,
>and I
>created two
>
>filenames <- list.files('data',full.names=TRUE)
>
>All_data <- lapply(filenames,function(i){
>###read cvs files and add the row and column names to each data
>frame###
> read.csv(i, header=FALSE, sep = "", col.names = col_names, row.names =
>row_names)
> })
>
>However I would like to sum the rows of cvs files to get a single data
>frame (each cvs file has 47 rows and colunms, so the final data frame
>should have the same). I could only do it one by one data data frame,
>but I
>was wondering if anyone could give an idea of how to write a function
>for
>this.
>
>Thanks,
>Alejandra
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kenneth at kidscodejeunesse.org  Mon Jan 15 17:59:34 2018
From: kenneth at kidscodejeunesse.org (kenneth dyson)
Date: Mon, 15 Jan 2018 11:59:34 -0500
Subject: [R] barplot that displays sums of values of 2 y colums grouped by
 different variables
Message-ID: <edf301d9-4327-327a-d613-c063ab0d55af@kidscodejeunesse.org>

I am trying to create a barplot displaying the sums of 2 columns of data 
grouped by a variable. the data is set up like this:

"city" "n" "y" <br>
mon 100 200 <br>
tor 209 300 <br>
edm 98 87 <br>
mon 20 76 <br>
tor 50 96 <br>
edm 62 27 <br>

the resulting plot should have city as the x-axis, 2 bars per city, 1 
representing the sum of "n" in that city, the other the sum of "y" in 
that city.

If possible also show the sum in each bar as a label?

I aggregated the data into sums like this:

sum_data <- aggregate(. ~ City,data=raw_data,sum)

this gave me the sums per city as I wanted but for some reason 1 of the 
cities is missing in the output.

Using this code for the plot:

ggplot(sum_data,aes(x = City,y = n)) + geom_bar(aes(fill = y),stat = 
"identity",position = "dodge")

gave be a bar plot with one bar per city showing the sum of y as a color 
gradient. not what I expected given the "dodge" command in geom_bar.

Thanks.


From ycding at coh.org  Mon Jan 15 18:57:13 2018
From: ycding at coh.org (Ding, Yuan Chun)
Date: Mon, 15 Jan 2018 17:57:13 +0000
Subject: [R] consolidate three function into one
In-Reply-To: <CAGx1TMC_UGr79xxq570Ycnyg90S=UHC9gBJmM2pmdWpugKOMWQ@mail.gmail.com>
References: <A86C6438FB909A409DDEF926277952B6A5F75A@PPWEXCH2KX14.coh.org>
 <CAGxFJbR3o5ozohXSkgqueROYCO=NsWdWZMP73GnM29TB0J0Dsg@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A6080B@PPWEXCH2KX14.coh.org>
 <CAGx1TMC_UGr79xxq570Ycnyg90S=UHC9gBJmM2pmdWpugKOMWQ@mail.gmail.com>
Message-ID: <A86C6438FB909A409DDEF926277952B6A60DE7@PPWEXCH2KX14.coh.org>

Hi Richard,

Thank you so much!!  I understand the problem now,  I assign a name to the "ggsurvplot" object and then add print(fig) at bottom of function definition, now figure gets printed on screen.

Ding

# function to generate RFS curves
RFS <- function( inputfile, N ) {
  cluster<- survfit(Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ clusters,
                    data = inputfile)
  if( N==2) {palette <- c("red", "black")
  legend.labs <- c("Cluster1", "Cluster2")
                     }

  else if(N==3) {palette <- c("red", "black", "green")
  legend.labs <- c("Cluster1", "Cluster2", "Cluster3")
                              }
  else {palette <- c("red", "black","green", "blue")
  legend.labs <- c("Cluster1", "Cluster2", "Cluster3", "Cluster4")
           }
  
  
  fig <-ggsurvplot(cluster, data = inputfile, risk.table = F,
             palette = palette,
             ylim=c(0,1),ggtheme = theme_bw(),xlab="Relapse Free Suvival (Days)",
             main = "Survival curve",pval = TRUE,font.x =  16,font.y = 16,
             font.tickslab = 14,font.legend =c(14,"plain","black"),
             legend = "bottom", 
             legend.title = "Tree Cluster",
             legend.labs = legend.labs, 
             lty=1, lwd=3)
  print(fig)
                                                     }

-----Original Message-----
From: Richard M. Heiberger [mailto:rmh at temple.edu] 
Sent: Sunday, January 14, 2018 1:34 PM
To: Ding, Yuan Chun <ycding at coh.org>
Cc: Bert Gunter <bgunter.4567 at gmail.com>; r-help at r-project.org
Subject: Re: [R] consolidate three function into one

FAQ 7.22
You must print a ggplot object, for example with
print(m52.2cluster)

For the FAQ, run the line
   system.file("../../doc/FAQ")
in R on your computer.
Open up the resulting filepath in your favorite editor and scroll down to 7.22

On Sun, Jan 14, 2018 at 4:21 PM, Ding, Yuan Chun <ycding at coh.org> wrote:
> Hi Bert,
>
> I am sorry to bother you on weekend.
>
> I am still struggling on defining a correct function.
>
> I first defined the function RFS (see below), then run it by provide the two argument.
>
> m52.2cluster <-RFS(inputfile =allinfo_m52, N=2 )
>
> I do not get error message, but no figure displays on screen. I do not know what is going on.
>
> Can you help me a little more on this issue?
>
> Thank you,
>
> Ding
>
> # function to generate RFS
> RFS <- function( inputfile, N ) {
>   cluster<- survfit(Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ clusters,
>                                data = inputfile)
>
>          if( N==2) {palette <- c("red", "black")
>                            legend.labs <- c("Cluster1", "Cluster2")
>                             }
>
>   else if(N==3) {palette <- c("red", "black", "green")
>                       legend.labs <- c("Cluster1", "Cluster2", "Cluster3")
>                             }
>
>                  else {palette <- c("red", "black","green", "blue")
>                            legend.labs <- c("Cluster1", "Cluster2", "Cluster3", "Cluster4")
>                           }
>
>   ggsurvplot(cluster, data = inputfile, risk.table = F,
>              palette = palette,
>              ylim=c(0,1),ggtheme = theme_bw(),xlab="Relapse Free Suvival (Days)",
>              main = "Survival curve",pval = TRUE,font.x =  16,font.y = 16,
>              font.tickslab = 14,font.legend =c(14,"plain","black"),
>              legend = "bottom",
>              legend.title = "Tree Cluster",
>              legend.labs = legend.labs,
>              lty=1, lwd=3)
>                                 }
>
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> Sent: Sunday, January 14, 2018 9:50 AM
> To: Ding, Yuan Chun <ycding at coh.org>
> Subject: Re: [R] consolidate three function into one
>
> I have not looked at your code *at all*, so I am not sure what exactly you mean by "consolidate."
> Is this what you are after?
>
> f1 <- function(...) { code 1}
> f2 <- function(...) { code 2}
> f3 <- function(...) { code 3}
> ## can be "consolidated as":
> f <- function( someargs, ...){
> if( expr(someargs)) f1(...)
> else if(expr2(someargs)) f2(...)
> else f3(...)
> }
> The "..." argument to f can soak up any named additional arguments you wish to pass to f1, f2, or f3.
> My apologies if this is offbase or too vague, and feel free to ignore in that case. I don't have the patience to go trough your code in detail. Others may and give you what you want.
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sun, Jan 14, 2018 at 9:17 AM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org>> wrote:
> HI R users,
>
> I construct dendrogram tree and cut the tree into different clusters, then generate survival curves by the following three functions. All variables are included in an inputfile.
>
> Can you help me to consolidate the following three function into one functions?  I thought about using if  else function, but not sure how to do it.
>
> Thank you,
>
> Ding
>
> # function to generate RFS
> RFS2cluster <- function( inputfile ) {
>   cluster2<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
>                                data = inputfile)
>
>   ggsurvplot(cluster2, data = inputfile, risk.table = F,
>              palette = c("red", "black"),
>              ylim=c(0,1),
>              ggtheme = theme_bw(),
>              xlab="Relapse Free Suvival (Days)",
>              main = "Survival curve",
>              pval = TRUE,
>              font.x =  16,
>              font.y = 16,
>              font.tickslab = 14,
>              font.legend =c(14,"plain","black"),
>              legend = "bottom",
>              legend.title = "Tree Cluster",
>              legend.labs = c("Cluster1", "Cluster2"), lty=1, lwd=3) }
>
> RFS3cluster <- function( inputfile ) {
>   cluster3<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
>                      data = inputfile)
>
>   ggsurvplot(cluster3, data = inputfile, risk.table = F,
>              palette = c("red", "black", "green"),
>              ylim=c(0,1),
>              ggtheme = theme_bw(),
>              xlab="Relapse Free Suvival (Days)",
>              main = "Survival curve",
>              pval = TRUE,
>              font.x =  16,
>              font.y = 16,
>              font.tickslab = 14,
>              font.legend =c(14,"plain","black"),
>              legend = "bottom",
>              legend.title = "Tree Cluster",
>              legend.labs = c("Cluster1", "Cluster2", "Cluster3"), 
> lty=1, lwd=3) }
>
> RFS4cluster <- function( inputfile ) {
>   cluster4<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
>                      data = inputfile)
>
>   ggsurvplot(cluster4, data = inputfile, risk.table = F,
>              palette = c("red", "black", "green", "blue"),
>              ylim=c(0,1),
>              ggtheme = theme_bw(),
>              xlab="Relapse Free Suvival (Days)",
>              main = "Survival curve",
>              pval = TRUE,
>              font.x =  16,
>              font.y = 16,
>              font.tickslab = 14,
>              font.legend =c(14,"plain","black"),
>              legend = "bottom",
>              legend.title = "Tree Cluster",
>              legend.labs = c("Cluster1", "Cluster2", "Cluster3", 
> "Cluster4"), lty=1, lwd=3) }
>
> -----Original Message-----
> From: R-help 
> [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.o
> rg>] On Behalf Of imane hajar
> Sent: Friday, January 12, 2018 7:42 AM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] Help with packages (methods, stats, stats4)
>
> [Attention: This email came from an external source. Do not open 
> attachments or click on links from unknown senders or unexpected 
> emails.]
>
>
>
>
>
> hello,
> Can you please give me a hand with this problem,well i can't install 
> these
> packages:
> - stats
> - methods
> - stats4
>
> when i tried the following command :  *library(help = "stats") * , it gave me this output (*see picture*), so i contacted the Maintainer of the package at (*R-core at r-project.org<mailto:R-core at r-project.org> <R-core at r-project.org<mailto:R-core at r-project.org>>*) but he said that i write to the wrong place.
>
> (i want to install those packages in order to use the "DVstats" 
> package)
>
> (i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )
>
> thank you
> Regards
>
>
> ---------------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
> This message (and any attachments) are intended solely for the 
> individual or entity to which they are addressed. This communication 
> may contain information that is privileged, confidential, or exempt 
> from disclosure under applicable law (e.g., personal health 
> information, research data, financial information). Because this 
> e-mail has been sent without encryption, individuals other than the 
> intended recipient may be able to view the information, forward it to 
> others or tamper with the information without the knowledge or consent 
> of the sender. If you are not the intended recipient, or the employee 
> or person responsible for delivering the message to the intended 
> recipient, any dissemination, distribution or copying of the 
> communication is strictly prohibited. If you received the 
> communication in error, please notify the sender immediately by 
> replying to this message and deleting the message and any accompanying 
> files from your system. If, due to the security risks, you do not wish 
> to r  eceive further communications via e-mail, please reply to this 
> message and inform the sender that you do not wish to receive further 
> e-mail from the sender. (LCP301)
> ---------------------------------------------------------------------
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To 
> UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From bgunter.4567 at gmail.com  Mon Jan 15 19:11:17 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 15 Jan 2018 10:11:17 -0800
Subject: [R] consolidate three function into one
In-Reply-To: <A86C6438FB909A409DDEF926277952B6A60DE7@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6A5F75A@PPWEXCH2KX14.coh.org>
 <CAGxFJbR3o5ozohXSkgqueROYCO=NsWdWZMP73GnM29TB0J0Dsg@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A6080B@PPWEXCH2KX14.coh.org>
 <CAGx1TMC_UGr79xxq570Ycnyg90S=UHC9gBJmM2pmdWpugKOMWQ@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A60DE7@PPWEXCH2KX14.coh.org>
Message-ID: <CAGxFJbShRGVESDbtFXmqbT=Z7P=93gWAAHHsaCyEt2-6OYnpvA@mail.gmail.com>

That is certainly OK, but you can also just use

print(ggsurvplot(...))

as your final statement.

out <- RFS( ...)

would then return the ggsurvplot object *and* graph it.

Any good R tutorial or a web search will provide more details on function
returns, which you might find useful.


Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jan 15, 2018 at 9:57 AM, Ding, Yuan Chun <ycding at coh.org> wrote:

> Hi Richard,
>
> Thank you so much!!  I understand the problem now,  I assign a name to the
> "ggsurvplot" object and then add print(fig) at bottom of function
> definition, now figure gets printed on screen.
>
> Ding
>
> # function to generate RFS curves
> RFS <- function( inputfile, N ) {
>   cluster<- survfit(Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ clusters,
>                     data = inputfile)
>   if( N==2) {palette <- c("red", "black")
>   legend.labs <- c("Cluster1", "Cluster2")
>                      }
>
>   else if(N==3) {palette <- c("red", "black", "green")
>   legend.labs <- c("Cluster1", "Cluster2", "Cluster3")
>                               }
>   else {palette <- c("red", "black","green", "blue")
>   legend.labs <- c("Cluster1", "Cluster2", "Cluster3", "Cluster4")
>            }
>
>
>   fig <-ggsurvplot(cluster, data = inputfile, risk.table = F,
>              palette = palette,
>              ylim=c(0,1),ggtheme = theme_bw(),xlab="Relapse Free Suvival
> (Days)",
>              main = "Survival curve",pval = TRUE,font.x =  16,font.y = 16,
>              font.tickslab = 14,font.legend =c(14,"plain","black"),
>              legend = "bottom",
>              legend.title = "Tree Cluster",
>              legend.labs = legend.labs,
>              lty=1, lwd=3)
>   print(fig)
>                                                      }
>
> -----Original Message-----
> From: Richard M. Heiberger [mailto:rmh at temple.edu]
> Sent: Sunday, January 14, 2018 1:34 PM
> To: Ding, Yuan Chun <ycding at coh.org>
> Cc: Bert Gunter <bgunter.4567 at gmail.com>; r-help at r-project.org
> Subject: Re: [R] consolidate three function into one
>
> FAQ 7.22
> You must print a ggplot object, for example with
> print(m52.2cluster)
>
> For the FAQ, run the line
>    system.file("../../doc/FAQ")
> in R on your computer.
> Open up the resulting filepath in your favorite editor and scroll down to
> 7.22
>
> On Sun, Jan 14, 2018 at 4:21 PM, Ding, Yuan Chun <ycding at coh.org> wrote:
> > Hi Bert,
> >
> > I am sorry to bother you on weekend.
> >
> > I am still struggling on defining a correct function.
> >
> > I first defined the function RFS (see below), then run it by provide the
> two argument.
> >
> > m52.2cluster <-RFS(inputfile =allinfo_m52, N=2 )
> >
> > I do not get error message, but no figure displays on screen. I do not
> know what is going on.
> >
> > Can you help me a little more on this issue?
> >
> > Thank you,
> >
> > Ding
> >
> > # function to generate RFS
> > RFS <- function( inputfile, N ) {
> >   cluster<- survfit(Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ clusters,
> >                                data = inputfile)
> >
> >          if( N==2) {palette <- c("red", "black")
> >                            legend.labs <- c("Cluster1", "Cluster2")
> >                             }
> >
> >   else if(N==3) {palette <- c("red", "black", "green")
> >                       legend.labs <- c("Cluster1", "Cluster2",
> "Cluster3")
> >                             }
> >
> >                  else {palette <- c("red", "black","green", "blue")
> >                            legend.labs <- c("Cluster1", "Cluster2",
> "Cluster3", "Cluster4")
> >                           }
> >
> >   ggsurvplot(cluster, data = inputfile, risk.table = F,
> >              palette = palette,
> >              ylim=c(0,1),ggtheme = theme_bw(),xlab="Relapse Free Suvival
> (Days)",
> >              main = "Survival curve",pval = TRUE,font.x =  16,font.y =
> 16,
> >              font.tickslab = 14,font.legend =c(14,"plain","black"),
> >              legend = "bottom",
> >              legend.title = "Tree Cluster",
> >              legend.labs = legend.labs,
> >              lty=1, lwd=3)
> >                                 }
> >
> > From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> > Sent: Sunday, January 14, 2018 9:50 AM
> > To: Ding, Yuan Chun <ycding at coh.org>
> > Subject: Re: [R] consolidate three function into one
> >
> > I have not looked at your code *at all*, so I am not sure what exactly
> you mean by "consolidate."
> > Is this what you are after?
> >
> > f1 <- function(...) { code 1}
> > f2 <- function(...) { code 2}
> > f3 <- function(...) { code 3}
> > ## can be "consolidated as":
> > f <- function( someargs, ...){
> > if( expr(someargs)) f1(...)
> > else if(expr2(someargs)) f2(...)
> > else f3(...)
> > }
> > The "..." argument to f can soak up any named additional arguments you
> wish to pass to f1, f2, or f3.
> > My apologies if this is offbase or too vague, and feel free to ignore in
> that case. I don't have the patience to go trough your code in detail.
> Others may and give you what you want.
> > Cheers,
> > Bert
> >
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Sun, Jan 14, 2018 at 9:17 AM, Ding, Yuan Chun <ycding at coh.org<mailto:
> ycding at coh.org>> wrote:
> > HI R users,
> >
> > I construct dendrogram tree and cut the tree into different clusters,
> then generate survival curves by the following three functions. All
> variables are included in an inputfile.
> >
> > Can you help me to consolidate the following three function into one
> functions?  I thought about using if  else function, but not sure how to do
> it.
> >
> > Thank you,
> >
> > Ding
> >
> > # function to generate RFS
> > RFS2cluster <- function( inputfile ) {
> >   cluster2<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
> >                                data = inputfile)
> >
> >   ggsurvplot(cluster2, data = inputfile, risk.table = F,
> >              palette = c("red", "black"),
> >              ylim=c(0,1),
> >              ggtheme = theme_bw(),
> >              xlab="Relapse Free Suvival (Days)",
> >              main = "Survival curve",
> >              pval = TRUE,
> >              font.x =  16,
> >              font.y = 16,
> >              font.tickslab = 14,
> >              font.legend =c(14,"plain","black"),
> >              legend = "bottom",
> >              legend.title = "Tree Cluster",
> >              legend.labs = c("Cluster1", "Cluster2"), lty=1, lwd=3) }
> >
> > RFS3cluster <- function( inputfile ) {
> >   cluster3<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
> >                      data = inputfile)
> >
> >   ggsurvplot(cluster3, data = inputfile, risk.table = F,
> >              palette = c("red", "black", "green"),
> >              ylim=c(0,1),
> >              ggtheme = theme_bw(),
> >              xlab="Relapse Free Suvival (Days)",
> >              main = "Survival curve",
> >              pval = TRUE,
> >              font.x =  16,
> >              font.y = 16,
> >              font.tickslab = 14,
> >              font.legend =c(14,"plain","black"),
> >              legend = "bottom",
> >              legend.title = "Tree Cluster",
> >              legend.labs = c("Cluster1", "Cluster2", "Cluster3"),
> > lty=1, lwd=3) }
> >
> > RFS4cluster <- function( inputfile ) {
> >   cluster4<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
> >                      data = inputfile)
> >
> >   ggsurvplot(cluster4, data = inputfile, risk.table = F,
> >              palette = c("red", "black", "green", "blue"),
> >              ylim=c(0,1),
> >              ggtheme = theme_bw(),
> >              xlab="Relapse Free Suvival (Days)",
> >              main = "Survival curve",
> >              pval = TRUE,
> >              font.x =  16,
> >              font.y = 16,
> >              font.tickslab = 14,
> >              font.legend =c(14,"plain","black"),
> >              legend = "bottom",
> >              legend.title = "Tree Cluster",
> >              legend.labs = c("Cluster1", "Cluster2", "Cluster3",
> > "Cluster4"), lty=1, lwd=3) }
> >
> > -----Original Message-----
> > From: R-help
> > [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.o
> > rg>] On Behalf Of imane hajar
> > Sent: Friday, January 12, 2018 7:42 AM
> > To: r-help at r-project.org<mailto:r-help at r-project.org>
> > Subject: [R] Help with packages (methods, stats, stats4)
> >
> > [Attention: This email came from an external source. Do not open
> > attachments or click on links from unknown senders or unexpected
> > emails.]
> >
> >
> >
> >
> >
> > hello,
> > Can you please give me a hand with this problem,well i can't install
> > these
> > packages:
> > - stats
> > - methods
> > - stats4
> >
> > when i tried the following command :  *library(help = "stats") * , it
> gave me this output (*see picture*), so i contacted the Maintainer of the
> package at (*R-core at r-project.org<mailto:R-core at r-project.org> <
> R-core at r-project.org<mailto:R-core at r-project.org>>*) but he said that i
> write to the wrong place.
> >
> > (i want to install those packages in order to use the "DVstats"
> > package)
> >
> > (i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )
> >
> > thank you
> > Regards
> >
> >
> > ---------------------------------------------------------------------
> > -SECURITY/CONFIDENTIALITY WARNING-
> > This message (and any attachments) are intended solely for the
> > individual or entity to which they are addressed. This communication
> > may contain information that is privileged, confidential, or exempt
> > from disclosure under applicable law (e.g., personal health
> > information, research data, financial information). Because this
> > e-mail has been sent without encryption, individuals other than the
> > intended recipient may be able to view the information, forward it to
> > others or tamper with the information without the knowledge or consent
> > of the sender. If you are not the intended recipient, or the employee
> > or person responsible for delivering the message to the intended
> > recipient, any dissemination, distribution or copying of the
> > communication is strictly prohibited. If you received the
> > communication in error, please notify the sender immediately by
> > replying to this message and deleting the message and any accompanying
> > files from your system. If, due to the security risks, you do not wish
> > to r  eceive further communications via e-mail, please reply to this
> > message and inform the sender that you do not wish to receive further
> > e-mail from the sender. (LCP301)
> > ---------------------------------------------------------------------
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> > UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ycding at coh.org  Mon Jan 15 19:21:37 2018
From: ycding at coh.org (Ding, Yuan Chun)
Date: Mon, 15 Jan 2018 18:21:37 +0000
Subject: [R] consolidate three function into one
In-Reply-To: <CAGxFJbShRGVESDbtFXmqbT=Z7P=93gWAAHHsaCyEt2-6OYnpvA@mail.gmail.com>
References: <A86C6438FB909A409DDEF926277952B6A5F75A@PPWEXCH2KX14.coh.org>
 <CAGxFJbR3o5ozohXSkgqueROYCO=NsWdWZMP73GnM29TB0J0Dsg@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A6080B@PPWEXCH2KX14.coh.org>
 <CAGx1TMC_UGr79xxq570Ycnyg90S=UHC9gBJmM2pmdWpugKOMWQ@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A60DE7@PPWEXCH2KX14.coh.org>
 <CAGxFJbShRGVESDbtFXmqbT=Z7P=93gWAAHHsaCyEt2-6OYnpvA@mail.gmail.com>
Message-ID: <A86C6438FB909A409DDEF926277952B6A60E02@PPWEXCH2KX14.coh.org>

Thank you, your suggestion is simpler and logically better.  I had impression that the last object in a function gets returned, so I did not add the print function at the bottom line of the function definition.  Returning an object and graph the object are different process, I am a beginner for writing R function and need to find a good guide source about writing R functions.   If you know a good book or website for guidance of R function, please let me know.

Thanks,

Ding

From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Monday, January 15, 2018 10:11 AM
To: Ding, Yuan Chun <ycding at coh.org>
Cc: Richard M. Heiberger <rmh at temple.edu>; r-help at r-project.org
Subject: Re: [R] consolidate three function into one

That is certainly OK, but you can also just use
print(ggsurvplot(...))
as your final statement.
out <- RFS( ...)
would then return the ggsurvplot object *and* graph it.

Any good R tutorial or a web search will provide more details on function returns, which you might find useful.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jan 15, 2018 at 9:57 AM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org>> wrote:
Hi Richard,

Thank you so much!!  I understand the problem now,  I assign a name to the "ggsurvplot" object and then add print(fig) at bottom of function definition, now figure gets printed on screen.

Ding

# function to generate RFS curves
RFS <- function( inputfile, N ) {
  cluster<- survfit(Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ clusters,
                    data = inputfile)
  if( N==2) {palette <- c("red", "black")
  legend.labs <- c("Cluster1", "Cluster2")
                     }

  else if(N==3) {palette <- c("red", "black", "green")
  legend.labs <- c("Cluster1", "Cluster2", "Cluster3")
                              }
  else {palette <- c("red", "black","green", "blue")
  legend.labs <- c("Cluster1", "Cluster2", "Cluster3", "Cluster4")
           }


  fig <-ggsurvplot(cluster, data = inputfile, risk.table = F,
             palette = palette,
             ylim=c(0,1),ggtheme = theme_bw(),xlab="Relapse Free Suvival (Days)",
             main = "Survival curve",pval = TRUE,font.x =  16,font.y = 16,
             font.tickslab = 14,font.legend =c(14,"plain","black"),
             legend = "bottom",
             legend.title = "Tree Cluster",
             legend.labs = legend.labs,
             lty=1, lwd=3)
  print(fig)
                                                     }

-----Original Message-----
From: Richard M. Heiberger [mailto:rmh at temple.edu<mailto:rmh at temple.edu>]
Sent: Sunday, January 14, 2018 1:34 PM
To: Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org>>
Cc: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>; r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] consolidate three function into one

FAQ 7.22
You must print a ggplot object, for example with
print(m52.2cluster)

For the FAQ, run the line
   system.file("../../doc/FAQ")
in R on your computer.
Open up the resulting filepath in your favorite editor and scroll down to 7.22

On Sun, Jan 14, 2018 at 4:21 PM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org>> wrote:
> Hi Bert,
>
> I am sorry to bother you on weekend.
>
> I am still struggling on defining a correct function.
>
> I first defined the function RFS (see below), then run it by provide the two argument.
>
> m52.2cluster <-RFS(inputfile =allinfo_m52, N=2 )
>
> I do not get error message, but no figure displays on screen. I do not know what is going on.
>
> Can you help me a little more on this issue?
>
> Thank you,
>
> Ding
>
> # function to generate RFS
> RFS <- function( inputfile, N ) {
>   cluster<- survfit(Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ clusters,
>                                data = inputfile)
>
>          if( N==2) {palette <- c("red", "black")
>                            legend.labs <- c("Cluster1", "Cluster2")
>                             }
>
>   else if(N==3) {palette <- c("red", "black", "green")
>                       legend.labs <- c("Cluster1", "Cluster2", "Cluster3")
>                             }
>
>                  else {palette <- c("red", "black","green", "blue")
>                            legend.labs <- c("Cluster1", "Cluster2", "Cluster3", "Cluster4")
>                           }
>
>   ggsurvplot(cluster, data = inputfile, risk.table = F,
>              palette = palette,
>              ylim=c(0,1),ggtheme = theme_bw(),xlab="Relapse Free Suvival (Days)",
>              main = "Survival curve",pval = TRUE,font.x =  16,font.y = 16,
>              font.tickslab = 14,font.legend =c(14,"plain","black"),
>              legend = "bottom",
>              legend.title = "Tree Cluster",
>              legend.labs = legend.labs,
>              lty=1, lwd=3)
>                                 }
>
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>]
> Sent: Sunday, January 14, 2018 9:50 AM
> To: Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org>>
> Subject: Re: [R] consolidate three function into one
>
> I have not looked at your code *at all*, so I am not sure what exactly you mean by "consolidate."
> Is this what you are after?
>
> f1 <- function(...) { code 1}
> f2 <- function(...) { code 2}
> f3 <- function(...) { code 3}
> ## can be "consolidated as":
> f <- function( someargs, ...){
> if( expr(someargs)) f1(...)
> else if(expr2(someargs)) f2(...)
> else f3(...)
> }
> The "..." argument to f can soak up any named additional arguments you wish to pass to f1, f2, or f3.
> My apologies if this is offbase or too vague, and feel free to ignore in that case. I don't have the patience to go trough your code in detail. Others may and give you what you want.
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sun, Jan 14, 2018 at 9:17 AM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org><mailto:ycding at coh.org<mailto:ycding at coh.org>>> wrote:
> HI R users,
>
> I construct dendrogram tree and cut the tree into different clusters, then generate survival curves by the following three functions. All variables are included in an inputfile.
>
> Can you help me to consolidate the following three function into one functions?  I thought about using if  else function, but not sure how to do it.
>
> Thank you,
>
> Ding
>
> # function to generate RFS
> RFS2cluster <- function( inputfile ) {
>   cluster2<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
>                                data = inputfile)
>
>   ggsurvplot(cluster2, data = inputfile, risk.table = F,
>              palette = c("red", "black"),
>              ylim=c(0,1),
>              ggtheme = theme_bw(),
>              xlab="Relapse Free Suvival (Days)",
>              main = "Survival curve",
>              pval = TRUE,
>              font.x =  16,
>              font.y = 16,
>              font.tickslab = 14,
>              font.legend =c(14,"plain","black"),
>              legend = "bottom",
>              legend.title = "Tree Cluster",
>              legend.labs = c("Cluster1", "Cluster2"), lty=1, lwd=3) }
>
> RFS3cluster <- function( inputfile ) {
>   cluster3<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
>                      data = inputfile)
>
>   ggsurvplot(cluster3, data = inputfile, risk.table = F,
>              palette = c("red", "black", "green"),
>              ylim=c(0,1),
>              ggtheme = theme_bw(),
>              xlab="Relapse Free Suvival (Days)",
>              main = "Survival curve",
>              pval = TRUE,
>              font.x =  16,
>              font.y = 16,
>              font.tickslab = 14,
>              font.legend =c(14,"plain","black"),
>              legend = "bottom",
>              legend.title = "Tree Cluster",
>              legend.labs = c("Cluster1", "Cluster2", "Cluster3"),
> lty=1, lwd=3) }
>
> RFS4cluster <- function( inputfile ) {
>   cluster4<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
>                      data = inputfile)
>
>   ggsurvplot(cluster4, data = inputfile, risk.table = F,
>              palette = c("red", "black", "green", "blue"),
>              ylim=c(0,1),
>              ggtheme = theme_bw(),
>              xlab="Relapse Free Suvival (Days)",
>              main = "Survival curve",
>              pval = TRUE,
>              font.x =  16,
>              font.y = 16,
>              font.tickslab = 14,
>              font.legend =c(14,"plain","black"),
>              legend = "bottom",
>              legend.title = "Tree Cluster",
>              legend.labs = c("Cluster1", "Cluster2", "Cluster3",
> "Cluster4"), lty=1, lwd=3) }
>
> -----Original Message-----
> From: R-help
> [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org><mailto:r-help-bounces at r-project.o<mailto:r-help-bounces at r-project.o>
> rg>] On Behalf Of imane hajar
> Sent: Friday, January 12, 2018 7:42 AM
> To: r-help at r-project.org<mailto:r-help at r-project.org><mailto:r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] Help with packages (methods, stats, stats4)
>
> [Attention: This email came from an external source. Do not open
> attachments or click on links from unknown senders or unexpected
> emails.]
>
>
>
>
>
> hello,
> Can you please give me a hand with this problem,well i can't install
> these
> packages:
> - stats
> - methods
> - stats4
>
> when i tried the following command :  *library(help = "stats") * , it gave me this output (*see picture*), so i contacted the Maintainer of the package at (*R-core at r-project.org<mailto:R-core at r-project.org><mailto:R-core at r-project.org<mailto:R-core at r-project.org>> <R-core at r-project.org<mailto:R-core at r-project.org><mailto:R-core at r-project.org<mailto:R-core at r-project.org>>>*) but he said that i write to the wrong place.
>
> (i want to install those packages in order to use the "DVstats"
> package)
>
> (i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )
>
> thank you
> Regards
>
>
> ---------------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
> This message (and any attachments) are intended solely for the
> individual or entity to which they are addressed. This communication
> may contain information that is privileged, confidential, or exempt
> from disclosure under applicable law (e.g., personal health
> information, research data, financial information). Because this
> e-mail has been sent without encryption, individuals other than the
> intended recipient may be able to view the information, forward it to
> others or tamper with the information without the knowledge or consent
> of the sender. If you are not the intended recipient, or the employee
> or person responsible for delivering the message to the intended
> recipient, any dissemination, distribution or copying of the
> communication is strictly prohibited. If you received the
> communication in error, please notify the sender immediately by
> replying to this message and deleting the message and any accompanying
> files from your system. If, due to the security risks, you do not wish
> to r  eceive further communications via e-mail, please reply to this
> message and inform the sender that you do not wish to receive further
> e-mail from the sender. (LCP301)
> ---------------------------------------------------------------------
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org><mailto:R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To
> UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Jan 15 19:38:23 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 15 Jan 2018 10:38:23 -0800
Subject: [R] consolidate three function into one
In-Reply-To: <A86C6438FB909A409DDEF926277952B6A60E02@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6A5F75A@PPWEXCH2KX14.coh.org>
 <CAGxFJbR3o5ozohXSkgqueROYCO=NsWdWZMP73GnM29TB0J0Dsg@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A6080B@PPWEXCH2KX14.coh.org>
 <CAGx1TMC_UGr79xxq570Ycnyg90S=UHC9gBJmM2pmdWpugKOMWQ@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A60DE7@PPWEXCH2KX14.coh.org>
 <CAGxFJbShRGVESDbtFXmqbT=Z7P=93gWAAHHsaCyEt2-6OYnpvA@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A60E02@PPWEXCH2KX14.coh.org>
Message-ID: <CAGxFJbR4O7G3DqRedkPf23djSCmz-ZX26nJegXZDO60pXXRWVw@mail.gmail.com>

"Good" tutorials are a matter of personal taste -- what's good for me may
be terrible for you, and vice-versa.

One set of recommendations is here:

https://www.rstudio.com/online-learning/#R

but you may do even better by web search on "R tutorials" or "Writing R
function tutorials" and the like.

You should certainly have a look at the "Introduction to R" tutorial that
ships with R, since it's immediately available. It's a bit old, however.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jan 15, 2018 at 10:21 AM, Ding, Yuan Chun <ycding at coh.org> wrote:

> Thank you, your suggestion is simpler and logically better.  I had
> impression that the last object in a function gets returned, so I did not
> add the print function at the bottom line of the function definition.
> Returning an object and graph the object are different process, I am a
> beginner for writing R function and need to find a good guide source about
> writing R functions.   If you know a good book or website for guidance of R
> function, please let me know.
>
>
>
> Thanks,
>
>
>
> Ding
>
>
>
> *From:* Bert Gunter [mailto:bgunter.4567 at gmail.com]
> *Sent:* Monday, January 15, 2018 10:11 AM
> *To:* Ding, Yuan Chun <ycding at coh.org>
> *Cc:* Richard M. Heiberger <rmh at temple.edu>; r-help at r-project.org
> *Subject:* Re: [R] consolidate three function into one
>
>
>
> That is certainly OK, but you can also just use
>
> print(ggsurvplot(...))
>
> as your final statement.
>
> out <- RFS( ...)
>
> would then return the ggsurvplot object *and* graph it.
>
>
>
> Any good R tutorial or a web search will provide more details on function
> returns, which you might find useful.
>
>
>
>
>
> Cheers,
>
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>
> On Mon, Jan 15, 2018 at 9:57 AM, Ding, Yuan Chun <ycding at coh.org> wrote:
>
> Hi Richard,
>
> Thank you so much!!  I understand the problem now,  I assign a name to the
> "ggsurvplot" object and then add print(fig) at bottom of function
> definition, now figure gets printed on screen.
>
> Ding
>
> # function to generate RFS curves
> RFS <- function( inputfile, N ) {
>   cluster<- survfit(Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ clusters,
>                     data = inputfile)
>   if( N==2) {palette <- c("red", "black")
>   legend.labs <- c("Cluster1", "Cluster2")
>                      }
>
>   else if(N==3) {palette <- c("red", "black", "green")
>   legend.labs <- c("Cluster1", "Cluster2", "Cluster3")
>                               }
>   else {palette <- c("red", "black","green", "blue")
>   legend.labs <- c("Cluster1", "Cluster2", "Cluster3", "Cluster4")
>            }
>
>
>   fig <-ggsurvplot(cluster, data = inputfile, risk.table = F,
>              palette = palette,
>              ylim=c(0,1),ggtheme = theme_bw(),xlab="Relapse Free Suvival
> (Days)",
>              main = "Survival curve",pval = TRUE,font.x =  16,font.y = 16,
>              font.tickslab = 14,font.legend =c(14,"plain","black"),
>              legend = "bottom",
>              legend.title = "Tree Cluster",
>              legend.labs = legend.labs,
>              lty=1, lwd=3)
>   print(fig)
>                                                      }
>
> -----Original Message-----
> From: Richard M. Heiberger [mailto:rmh at temple.edu]
> Sent: Sunday, January 14, 2018 1:34 PM
> To: Ding, Yuan Chun <ycding at coh.org>
> Cc: Bert Gunter <bgunter.4567 at gmail.com>; r-help at r-project.org
> Subject: Re: [R] consolidate three function into one
>
> FAQ 7.22
> You must print a ggplot object, for example with
> print(m52.2cluster)
>
> For the FAQ, run the line
>    system.file("../../doc/FAQ")
> in R on your computer.
> Open up the resulting filepath in your favorite editor and scroll down to
> 7.22
>
> On Sun, Jan 14, 2018 at 4:21 PM, Ding, Yuan Chun <ycding at coh.org> wrote:
> > Hi Bert,
> >
> > I am sorry to bother you on weekend.
> >
> > I am still struggling on defining a correct function.
> >
> > I first defined the function RFS (see below), then run it by provide the
> two argument.
> >
> > m52.2cluster <-RFS(inputfile =allinfo_m52, N=2 )
> >
> > I do not get error message, but no figure displays on screen. I do not
> know what is going on.
> >
> > Can you help me a little more on this issue?
> >
> > Thank you,
> >
> > Ding
> >
> > # function to generate RFS
> > RFS <- function( inputfile, N ) {
> >   cluster<- survfit(Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ clusters,
> >                                data = inputfile)
> >
> >          if( N==2) {palette <- c("red", "black")
> >                            legend.labs <- c("Cluster1", "Cluster2")
> >                             }
> >
> >   else if(N==3) {palette <- c("red", "black", "green")
> >                       legend.labs <- c("Cluster1", "Cluster2",
> "Cluster3")
> >                             }
> >
> >                  else {palette <- c("red", "black","green", "blue")
> >                            legend.labs <- c("Cluster1", "Cluster2",
> "Cluster3", "Cluster4")
> >                           }
> >
> >   ggsurvplot(cluster, data = inputfile, risk.table = F,
> >              palette = palette,
> >              ylim=c(0,1),ggtheme = theme_bw(),xlab="Relapse Free Suvival
> (Days)",
> >              main = "Survival curve",pval = TRUE,font.x =  16,font.y =
> 16,
> >              font.tickslab = 14,font.legend =c(14,"plain","black"),
> >              legend = "bottom",
> >              legend.title = "Tree Cluster",
> >              legend.labs = legend.labs,
> >              lty=1, lwd=3)
> >                                 }
> >
> > From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> > Sent: Sunday, January 14, 2018 9:50 AM
> > To: Ding, Yuan Chun <ycding at coh.org>
> > Subject: Re: [R] consolidate three function into one
> >
> > I have not looked at your code *at all*, so I am not sure what exactly
> you mean by "consolidate."
> > Is this what you are after?
> >
> > f1 <- function(...) { code 1}
> > f2 <- function(...) { code 2}
> > f3 <- function(...) { code 3}
> > ## can be "consolidated as":
> > f <- function( someargs, ...){
> > if( expr(someargs)) f1(...)
> > else if(expr2(someargs)) f2(...)
> > else f3(...)
> > }
> > The "..." argument to f can soak up any named additional arguments you
> wish to pass to f1, f2, or f3.
> > My apologies if this is offbase or too vague, and feel free to ignore in
> that case. I don't have the patience to go trough your code in detail.
> Others may and give you what you want.
> > Cheers,
> > Bert
> >
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Sun, Jan 14, 2018 at 9:17 AM, Ding, Yuan Chun <ycding at coh.org<mailto:
> ycding at coh.org>> wrote:
> > HI R users,
> >
> > I construct dendrogram tree and cut the tree into different clusters,
> then generate survival curves by the following three functions. All
> variables are included in an inputfile.
> >
> > Can you help me to consolidate the following three function into one
> functions?  I thought about using if  else function, but not sure how to do
> it.
> >
> > Thank you,
> >
> > Ding
> >
> > # function to generate RFS
> > RFS2cluster <- function( inputfile ) {
> >   cluster2<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
> >                                data = inputfile)
> >
> >   ggsurvplot(cluster2, data = inputfile, risk.table = F,
> >              palette = c("red", "black"),
> >              ylim=c(0,1),
> >              ggtheme = theme_bw(),
> >              xlab="Relapse Free Suvival (Days)",
> >              main = "Survival curve",
> >              pval = TRUE,
> >              font.x =  16,
> >              font.y = 16,
> >              font.tickslab = 14,
> >              font.legend =c(14,"plain","black"),
> >              legend = "bottom",
> >              legend.title = "Tree Cluster",
> >              legend.labs = c("Cluster1", "Cluster2"), lty=1, lwd=3) }
> >
> > RFS3cluster <- function( inputfile ) {
> >   cluster3<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
> >                      data = inputfile)
> >
> >   ggsurvplot(cluster3, data = inputfile, risk.table = F,
> >              palette = c("red", "black", "green"),
> >              ylim=c(0,1),
> >              ggtheme = theme_bw(),
> >              xlab="Relapse Free Suvival (Days)",
> >              main = "Survival curve",
> >              pval = TRUE,
> >              font.x =  16,
> >              font.y = 16,
> >              font.tickslab = 14,
> >              font.legend =c(14,"plain","black"),
> >              legend = "bottom",
> >              legend.title = "Tree Cluster",
> >              legend.labs = c("Cluster1", "Cluster2", "Cluster3"),
> > lty=1, lwd=3) }
> >
> > RFS4cluster <- function( inputfile ) {
> >   cluster4<- survfit(Surv(RFS_days, OV_Had_a_Recurrence_CODE) ~ clusters,
> >                      data = inputfile)
> >
> >   ggsurvplot(cluster4, data = inputfile, risk.table = F,
> >              palette = c("red", "black", "green", "blue"),
> >              ylim=c(0,1),
> >              ggtheme = theme_bw(),
> >              xlab="Relapse Free Suvival (Days)",
> >              main = "Survival curve",
> >              pval = TRUE,
> >              font.x =  16,
> >              font.y = 16,
> >              font.tickslab = 14,
> >              font.legend =c(14,"plain","black"),
> >              legend = "bottom",
> >              legend.title = "Tree Cluster",
> >              legend.labs = c("Cluster1", "Cluster2", "Cluster3",
> > "Cluster4"), lty=1, lwd=3) }
> >
> > -----Original Message-----
> > From: R-help
> > [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.o
> > rg>] On Behalf Of imane hajar
> > Sent: Friday, January 12, 2018 7:42 AM
> > To: r-help at r-project.org<mailto:r-help at r-project.org>
> > Subject: [R] Help with packages (methods, stats, stats4)
> >
> > [Attention: This email came from an external source. Do not open
> > attachments or click on links from unknown senders or unexpected
> > emails.]
> >
> >
> >
> >
> >
> > hello,
> > Can you please give me a hand with this problem,well i can't install
> > these
> > packages:
> > - stats
> > - methods
> > - stats4
> >
> > when i tried the following command :  *library(help = "stats") * , it
> gave me this output (*see picture*), so i contacted the Maintainer of the
> package at (*R-core at r-project.org<mailto:R-core at r-project.org> <
> R-core at r-project.org<mailto:R-core at r-project.org>>*) but he said that i
> write to the wrong place.
> >
> > (i want to install those packages in order to use the "DVstats"
> > package)
> >
> > (i have the latest version of R (3.4.3 ) and Rstudio(1.2.240) )
> >
> > thank you
> > Regards
> >
> >
> > ---------------------------------------------------------------------
> > -SECURITY/CONFIDENTIALITY WARNING-
> > This message (and any attachments) are intended solely for the
> > individual or entity to which they are addressed. This communication
> > may contain information that is privileged, confidential, or exempt
> > from disclosure under applicable law (e.g., personal health
> > information, research data, financial information). Because this
> > e-mail has been sent without encryption, individuals other than the
> > intended recipient may be able to view the information, forward it to
> > others or tamper with the information without the knowledge or consent
> > of the sender. If you are not the intended recipient, or the employee
> > or person responsible for delivering the message to the intended
> > recipient, any dissemination, distribution or copying of the
> > communication is strictly prohibited. If you received the
> > communication in error, please notify the sender immediately by
> > replying to this message and deleting the message and any accompanying
> > files from your system. If, due to the security risks, you do not wish
> > to r  eceive further communications via e-mail, please reply to this
> > message and inform the sender that you do not wish to receive further
> > e-mail from the sender. (LCP301)
> > ---------------------------------------------------------------------
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> > UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From marcelomarianosilva at gmail.com  Mon Jan 15 18:49:18 2018
From: marcelomarianosilva at gmail.com (Marcelo Mariano Silva)
Date: Mon, 15 Jan 2018 15:49:18 -0200
Subject: [R] About levene.test
Message-ID: <CANZDV5BkchaEGjZ+Q1v4Mo4NhXJFWi+nrYza_BNAy9UhXG9hNA@mail.gmail.com>

Hi,

What package(s) must I install  so that I can apply the Levene' test in my
data?

I tried 'lawstat' but dependency ?VGAM? is not available for this package.


I am using Rstudio Version 1.1.383


Tks

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Mon Jan 15 20:17:09 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 15 Jan 2018 19:17:09 +0000
Subject: [R] About levene.test
In-Reply-To: <15270_1516043592_w0FJDCYe022908_CANZDV5BkchaEGjZ+Q1v4Mo4NhXJFWi+nrYza_BNAy9UhXG9hNA@mail.gmail.com>
References: <15270_1516043592_w0FJDCYe022908_CANZDV5BkchaEGjZ+Q1v4Mo4NhXJFWi+nrYza_BNAy9UhXG9hNA@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83675D685@FHSDB2D11-2.csu.mcmaster.ca>

Dear Mariano,

See the function leveneTest() in the car package.

I hope that this helps,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marcelo
> Mariano Silva
> Sent: Monday, January 15, 2018 12:49 PM
> To: r-help at r-project.org
> Subject: [R] About levene.test
> 
> Hi,
> 
> What package(s) must I install  so that I can apply the Levene' test in my data?
> 
> I tried 'lawstat' but dependency ?VGAM? is not available for this package.
> 
> 
> I am using Rstudio Version 1.1.383
> 
> 
> Tks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From bgunter.4567 at gmail.com  Mon Jan 15 20:28:38 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 15 Jan 2018 11:28:38 -0800
Subject: [R] About levene.test
In-Reply-To: <CANZDV5BkchaEGjZ+Q1v4Mo4NhXJFWi+nrYza_BNAy9UhXG9hNA@mail.gmail.com>
References: <CANZDV5BkchaEGjZ+Q1v4Mo4NhXJFWi+nrYza_BNAy9UhXG9hNA@mail.gmail.com>
Message-ID: <CAGxFJbS7k6OENPp_x_7sqxjAX9d2webY35gFL6T0t+RVthtcSA@mail.gmail.com>

For your and perhaps other's reference, the RStudio version has nothing to
do with this. Rstudio is merely a a GUI IDE for R itself, and it's the R
(or R package) version that matters.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jan 15, 2018 at 9:49 AM, Marcelo Mariano Silva <
marcelomarianosilva at gmail.com> wrote:

> Hi,
>
> What package(s) must I install  so that I can apply the Levene' test in my
> data?
>
> I tried 'lawstat' but dependency ?VGAM? is not available for this package.
>
>
> I am using Rstudio Version 1.1.383
>
>
> Tks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Mon Jan 15 20:34:30 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Mon, 15 Jan 2018 21:34:30 +0200
Subject: [R] barplot that displays sums of values of 2 y colums grouped
 by different variables
In-Reply-To: <edf301d9-4327-327a-d613-c063ab0d55af@kidscodejeunesse.org>
References: <edf301d9-4327-327a-d613-c063ab0d55af@kidscodejeunesse.org>
Message-ID: <CAGgJW74Psa=L48zAXfG99=_CjMc8hUFWoW+BTvk7hZ55ugOYDQ@mail.gmail.com>

'position="dodge"' has no effect in the plot because the x-axis is a factor
variable. The bars do not need to be moved to avoid each other. The
'aes(fill=y)' is specifying that you want the color gradient to capture the
sums in the 'y' variable. You might be better off to use 'no' and 'yes'
rather than 'n' and 'y' to avoid confusion. Then you would see that the
statement would be 'aes(fill=yes)'. Summary: the height of each bar
represents the sum of the 'no' for that city, and the color of each bar
represents the sum of the 'yes' for that city. Your code is fine, unless
that is not what you were trying to do.

HTH,
Eric


On Mon, Jan 15, 2018 at 6:59 PM, kenneth dyson <kenneth at kidscodejeunesse.org
> wrote:

> I am trying to create a barplot displaying the sums of 2 columns of data
> grouped by a variable. the data is set up like this:
>
> "city" "n" "y" <br>
> mon 100 200 <br>
> tor 209 300 <br>
> edm 98 87 <br>
> mon 20 76 <br>
> tor 50 96 <br>
> edm 62 27 <br>
>
> the resulting plot should have city as the x-axis, 2 bars per city, 1
> representing the sum of "n" in that city, the other the sum of "y" in that
> city.
>
> If possible also show the sum in each bar as a label?
>
> I aggregated the data into sums like this:
>
> sum_data <- aggregate(. ~ City,data=raw_data,sum)
>
> this gave me the sums per city as I wanted but for some reason 1 of the
> cities is missing in the output.
>
> Using this code for the plot:
>
> ggplot(sum_data,aes(x = City,y = n)) + geom_bar(aes(fill = y),stat =
> "identity",position = "dodge")
>
> gave be a bar plot with one bar per city showing the sum of y as a color
> gradient. not what I expected given the "dodge" command in geom_bar.
>
> Thanks.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Mon Jan 15 20:57:31 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Mon, 15 Jan 2018 21:57:31 +0200
Subject: [R] barplot that displays sums of values of 2 y colums grouped
 by different variables
In-Reply-To: <0f0f9743-9080-4c77-8c63-f9acbd937f7e@kidscodejeunesse.org>
References: <edf301d9-4327-327a-d613-c063ab0d55af@kidscodejeunesse.org>
 <CAGgJW74Psa=L48zAXfG99=_CjMc8hUFWoW+BTvk7hZ55ugOYDQ@mail.gmail.com>
 <0f0f9743-9080-4c77-8c63-f9acbd937f7e@kidscodejeunesse.org>
Message-ID: <CAGgJW77AgW3bZ1VM_BbusGj6ZdzFZjYOvdoOSuL5ri7LNxH4YA@mail.gmail.com>

https://stackoverflow.com/questions/25070547/ggplot-side-by-side-geom-bar

On Mon, Jan 15, 2018 at 9:39 PM, Kenneth Dyson <kenneth at kidscodejeunesse.org
> wrote:

> Hi Eric,
>
> Thanks for the detailed response.
> This is not exactly what I want to do but is close.
> I want 2 bars for each city, 1 with the sum for "yes" , the other, beside
> it, with the sum for "no".
>
> I am way off track with my method here?
>
> Thanks,
> Ken
>
> Sent from Blue <http://www.bluemail.me/r?b=11745>
> On Jan 15, 2018, at 14:34, Eric Berger <ericjberger at gmail.com> wrote:
>>
>> 'position="dodge"' has no effect in the plot because the x-axis is a
>> factor variable. The bars do not need to be moved to avoid each other. The
>> 'aes(fill=y)' is specifying that you want the color gradient to capture the
>> sums in the 'y' variable. You might be better off to use 'no' and 'yes'
>> rather than 'n' and 'y' to avoid confusion. Then you would see that the
>> statement would be 'aes(fill=yes)'. Summary: the height of each bar
>> represents the sum of the 'no' for that city, and the color of each bar
>> represents the sum of the 'yes' for that city. Your code is fine, unless
>> that is not what you were trying to do.
>>
>> HTH,
>> Eric
>>
>>
>> On Mon, Jan 15, 2018 at 6:59 PM, kenneth dyson <
>> kenneth at kidscodejeunesse.org> wrote:
>>
>>> I am trying to create a barplot displaying the sums of 2 columns of data
>>> grouped by a variable. the data is set up like this:
>>>
>>> "city" "n" "y" <br>
>>> mon 100 200 <br>
>>> tor 209 300 <br>
>>> edm 98 87 <br>
>>> mon 20 76 <br>
>>> tor 50 96 <br>
>>> edm 62 27 <br>
>>>
>>> the resulting plot should have city as the x-axis, 2 bars per city, 1
>>> representing the sum of "n" in that city, the other the sum of "y" in that
>>> city.
>>>
>>> If possible also show the sum in each bar as a label?
>>>
>>> I aggregated the data into sums like this:
>>>
>>> sum_data <- aggregate(. ~ City,data=raw_data,sum)
>>>
>>> this gave me the sums per city as I wanted but for some reason 1 of the
>>> cities is missing in the output.
>>>
>>> Using this code for the plot:
>>>
>>> ggplot(sum_data,aes(x = City,y = n)) + geom_bar(aes(fill = y),stat =
>>> "identity",position = "dodge")
>>>
>>> gave be a bar plot with one bar per city showing the sum of y as a color
>>> gradient. not what I expected given the "dodge" command in geom_bar.
>>>
>>> Thanks.
>>>
>>> ______________________________ ________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Jan 15 21:12:22 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 15 Jan 2018 12:12:22 -0800
Subject: [R] Time-dependent coefficients in a Cox model with categorical
	variants
In-Reply-To: <CAKpGb9DB2sCFjFfrQZSx+n4wN5L8t68ZKLDa6pqLuwkGywK2FA@mail.gmail.com>
References: <CAKpGb9DB2sCFjFfrQZSx+n4wN5L8t68ZKLDa6pqLuwkGywK2FA@mail.gmail.com>
Message-ID: <795A9197-2663-4E48-9A88-43D6599B2CA1@comcast.net>


> On Jan 15, 2018, at 12:58 AM, Max Shell <archerrish at gmail.com> wrote:
> 
> Suppose I have a dataset contain three variants, looks like
>> head(dta)
> 
>  Sex    tumorsize    Histology       time         status
>    0            1.5            2              12.1000             0
>    1            1.8            1              38.4000             0
> .....................
> 
> Sex: 1 for male; 0 for female., two levels
> Histology: 1 for SqCC; 2 for High risk AC; 3 for low risk AC, three levels
> Now I need to get a Time-dependent coefficients cox fit:
> 
> library(survival)
> for(i in c(1,3) dta[,i] <- factor(dta[,i])
> fit <-
>  coxph(
>    Surv(time, status) ~  Sex + tumorsize +  Histology + tt(Histology),
>    data = dta,
>    tt = function(x, t, ...) x * log(t)
>  )
> 
> But  I keep gettting this error says:
> 
> Error in if (any(infs)) warning(paste("Loglik converged before variable ",  :
>  missing value where TRUE/FALSE needed
> In addition: Warning message:
> In Ops.factor(x, log(t)) : ?*? not meaningful for factors.

The error message seems pretty clear. You are passing a factor to the x parameter of the tt function, and then you are attempting to multiply that value times log(t). You are lucky that it was a factor and not jsut an integer because then you might not have gotten an error or a warning.  I worry that your hopes of separate estimates may not be easily supportable by the tt-mechanism. However, the example of its use in the help page for `coxph` shows a spline function being passed and the boundary knots and weights mush estimated, so my fears may be over-blown. The knot locations and weights are not reported in the print.coxph but it doesn't look too difficult to extract then from the attributes of the model. 

You might look at the mechanism for estimation of spline component effects to see if you can learn how to estimate multiple components:

> coef( coxph(Surv(time, status) ~ ph.ecog + tt(age), data=lung,
+      tt=function(x,t,...) pspline(x + t/365.25))  )
           ph.ecog  ps(x + t/365.25)3  ps(x + t/365.25)4  ps(x + t/365.25)5  ps(x + t/365.25)6  ps(x + t/365.25)7 
         0.4528363          0.2426635          0.4876185          0.7796924          1.0160954          1.0765967 
 ps(x + t/365.25)8  ps(x + t/365.25)9 ps(x + t/365.25)10 ps(x + t/365.25)11 ps(x + t/365.25)12 ps(x + t/365.25)13 
         1.0449439          0.9170725          0.9276695          1.1349794          1.2837341          1.7024045 
ps(x + t/365.25)14 
         2.1863712 

> attr( coxph(Surv(time, status) ~ ph.ecog + tt(age), data=lung,
+      tt=function(x,t,...) pspline(x + t/365.25))$terms, "predvars" )
list(Surv(time, status), ph.ecog, pspline(age, nterm = 10, intercept = FALSE, 
    Boundary.knots = c(39.0136892539357, 82.0848733744011), `NA` = NULL))

The coefficients for the spline also get reported as exponentiated values in the summary output. And if you  used a crossing operator in the formula you get some sort of interaction result. Whether it has any sensible interpretation is decision that's above my pay grade.

The code for `pspline` is readily available. It's not even necessary to sue the triple-colon or getAnywhere functions.

-- 
David.
> 
> How can I fix it? I know that the "Sex" and "Histology" are both
> categorical variants. I  want to have a model that have two ?(t) = a +
> blog(t) for each histology level.
> Thank you?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From drjimlemon at gmail.com  Mon Jan 15 22:22:52 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 16 Jan 2018 08:22:52 +1100
Subject: [R] barplot that displays sums of values of 2 y colums grouped
 by different variables
In-Reply-To: <edf301d9-4327-327a-d613-c063ab0d55af@kidscodejeunesse.org>
References: <edf301d9-4327-327a-d613-c063ab0d55af@kidscodejeunesse.org>
Message-ID: <CA+8X3fV=BeqY5xrBhmip2iCUWsGu5uGqrUePO59eoafuF2MMaA@mail.gmail.com>

Hi Kenneth,
I don't know about ggplot, but perhaps this will help:

kddf<-read.table(text="city n y
mon 100 200
tor 209 300
edm 98 87
mon 20 76
tor 50 96
edm 62 27",
header=TRUE,stringsAsFactors=FALSE)
library(plotrix)
barpos<-barp(t(kddf[,2:3]),names.arg=kddf[,1],xlab="City",ylab="Sum",
 main="Sums of values of 2 y columns",col=2:3)
legend(5,300,c("Sum of n","Sum, of y"),fill=2:3)
barlabels(barpos$x,barpos$y)

Jim


On Tue, Jan 16, 2018 at 3:59 AM, kenneth dyson
<kenneth at kidscodejeunesse.org> wrote:
> I am trying to create a barplot displaying the sums of 2 columns of data
> grouped by a variable. the data is set up like this:
>
> "city" "n" "y" <br>
> mon 100 200 <br>
> tor 209 300 <br>
> edm 98 87 <br>
> mon 20 76 <br>
> tor 50 96 <br>
> edm 62 27 <br>
>
> the resulting plot should have city as the x-axis, 2 bars per city, 1
> representing the sum of "n" in that city, the other the sum of "y" in that
> city.
>
> If possible also show the sum in each bar as a label?
>
> I aggregated the data into sums like this:
>
> sum_data <- aggregate(. ~ City,data=raw_data,sum)
>
> this gave me the sums per city as I wanted but for some reason 1 of the
> cities is missing in the output.
>
> Using this code for the plot:
>
> ggplot(sum_data,aes(x = City,y = n)) + geom_bar(aes(fill = y),stat =
> "identity",position = "dodge")
>
> gave be a bar plot with one bar per city showing the sum of y as a color
> gradient. not what I expected given the "dodge" command in geom_bar.
>
> Thanks.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Mon Jan 15 23:22:01 2018
From: chocold12 at gmail.com (lily li)
Date: Mon, 15 Jan 2018 15:22:01 -0700
Subject: [R] Steps to create spatial plots
Message-ID: <CAN5afy94sJGUFuQ+byRwLuA0Ayg+moHd8J1BoRuOpBNqbtZPmA@mail.gmail.com>

Hi users,

I have no clear clue about plotting spatial data. For example, I just have
a table with attribute values of each grid cell, such as elevation. Then I
have coordinates of the upper left corner in UTM, the number of rows and
columns, and grid cell size. How to create spatial plot of elevations for
the grid cells, in color ramp? Should I create a spatial grid layer with
all the polygons first? Thanks.

	[[alternative HTML version deleted]]


From roman.lustrik at gmail.com  Mon Jan 15 23:26:36 2018
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Mon, 15 Jan 2018 23:26:36 +0100
Subject: [R] Steps to create spatial plots
In-Reply-To: <CAN5afy94sJGUFuQ+byRwLuA0Ayg+moHd8J1BoRuOpBNqbtZPmA@mail.gmail.com>
References: <CAN5afy94sJGUFuQ+byRwLuA0Ayg+moHd8J1BoRuOpBNqbtZPmA@mail.gmail.com>
Message-ID: <CAHT1vpgtC+p2QSKvPvcKUaBN0KPsBt-Jdr-zh6gEZ_K1Kd9AhA@mail.gmail.com>

You will need to coerce your data into a "spatial" kind, as implemented in
`sp` or as of late, `sf` packages. You might want to give the vignettes a
whirl before you proceed.
Roughly, you will have to coerce the data to Spatial* (you could go for a
point, raster or grid type, I think) and also specify the projection. Once
you have that, plotting should be handled by packages.

Here are a few quick links that might come handy:

https://cran.r-project.org/web/views/Spatial.html
http://www.datacarpentry.org/R-spatial-raster-vector-lesson/10-vector-csv-to-shapefile-in-r/


Cheers,
Roman

On Mon, Jan 15, 2018 at 11:22 PM, lily li <chocold12 at gmail.com> wrote:

> Hi users,
>
> I have no clear clue about plotting spatial data. For example, I just have
> a table with attribute values of each grid cell, such as elevation. Then I
> have coordinates of the upper left corner in UTM, the number of rows and
> columns, and grid cell size. How to create spatial plot of elevations for
> the grid cells, in color ramp? Should I create a spatial grid layer with
> all the polygons first? Thanks.
>
> --
> --
> You received this message because you are subscribed to the ggplot2
> mailing list.
> Please provide a reproducible example: https://github.com/hadley/
> devtools/wiki/Reproducibility
>
> To post: email ggplot2 at googlegroups.com
> To unsubscribe: email ggplot2+unsubscribe at googlegroups.com
> More options: http://groups.google.com/group/ggplot2
>
> ---
> You received this message because you are subscribed to the Google Groups
> "ggplot2" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to ggplot2+unsubscribe at googlegroups.com.
> For more options, visit https://groups.google.com/d/optout.
>



-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Jan 16 00:01:52 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 15 Jan 2018 15:01:52 -0800 (PST)
Subject: [R] barplot that displays sums of values of 2 y colums grouped
 by different variables
In-Reply-To: <edf301d9-4327-327a-d613-c063ab0d55af@kidscodejeunesse.org>
References: <edf301d9-4327-327a-d613-c063ab0d55af@kidscodejeunesse.org>
Message-ID: <alpine.BSF.2.00.1801151423480.52972@pedal.dcn.davis.ca.us>

It is not generally advisable to get too fancy with stat functions in 
ggplot... things can easily get more complicated than ggplot is ready to 
handle when it comes to calculations. It is better to create data that 
corresponds directly to the graphical representations you are mapping 
them to.

Read [1] for more on this philosophy.

[1] H. Wickham, Tidy Data, Journal of Statistical Software, vol. 59, no. 
10, pp. 123, Sep. 2014. http://www.jstatsoft.org/v59/i10/

#---
library(ggplot2) # ggplot
library(dplyr)   # `%>%`, group_by, summarise
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#>
#>     filter, lag
#> The following objects are masked from 'package:base':
#>
#>     intersect, setdiff, setequal, union
library(tidyr)   # gather

dta <- read.table( text =
"city n y
mon 100 200
tor 209 300
edm 98 87
mon 20 76
tor 50 96
edm 62 27
", header = TRUE )

dta2 <- (   dta
         %>% group_by( city )
         %>% summarise( n = sum( n )
                      , y = sum( y )
                      )
         %>% gather( Response, value, -city )
         )

ggplot( dta2, aes( x=city, y=value, fill = Response ) ) +
     geom_bar( stat="identity", position="dodge" )

#' ![](https://i.imgur.com/cosFf3B.png)
#---

On Mon, 15 Jan 2018, kenneth dyson wrote:

> I am trying to create a barplot displaying the sums of 2 columns of data 
> grouped by a variable. the data is set up like this:
>
> "city" "n" "y" <br>
> mon 100 200 <br>
> tor 209 300 <br>
> edm 98 87 <br>
> mon 20 76 <br>
> tor 50 96 <br>
> edm 62 27 <br>
>
> the resulting plot should have city as the x-axis, 2 bars per city, 1 
> representing the sum of "n" in that city, the other the sum of "y" in that 
> city.
>
> If possible also show the sum in each bar as a label?
>
> I aggregated the data into sums like this:
>
> sum_data <- aggregate(. ~ City,data=raw_data,sum)
>
> this gave me the sums per city as I wanted but for some reason 1 of the 
> cities is missing in the output.
>
> Using this code for the plot:
>
> ggplot(sum_data,aes(x = City,y = n)) + geom_bar(aes(fill = y),stat = 
> "identity",position = "dodge")
>
> gave be a bar plot with one bar per city showing the sum of y as a color 
> gradient. not what I expected given the "dodge" command in geom_bar.
>
> Thanks.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Tue Jan 16 00:12:48 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 15 Jan 2018 15:12:48 -0800 (PST)
Subject: [R] Steps to create spatial plots
In-Reply-To: <CAHT1vpgtC+p2QSKvPvcKUaBN0KPsBt-Jdr-zh6gEZ_K1Kd9AhA@mail.gmail.com>
References: <CAN5afy94sJGUFuQ+byRwLuA0Ayg+moHd8J1BoRuOpBNqbtZPmA@mail.gmail.com>
 <CAHT1vpgtC+p2QSKvPvcKUaBN0KPsBt-Jdr-zh6gEZ_K1Kd9AhA@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1801151503420.54445@pedal.dcn.davis.ca.us>

Also note that there is an R-sig-geo mailing list dedicated to this topic.

You might also like to look at [1] for more on coordinate projections.

[1] https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/OverviewCoordinateReferenceSystems.pdf

On Mon, 15 Jan 2018, Roman Lu?trik wrote:

> You will need to coerce your data into a "spatial" kind, as implemented in
> `sp` or as of late, `sf` packages. You might want to give the vignettes a
> whirl before you proceed.
> Roughly, you will have to coerce the data to Spatial* (you could go for a
> point, raster or grid type, I think) and also specify the projection. Once
> you have that, plotting should be handled by packages.
>
> Here are a few quick links that might come handy:
>
> https://cran.r-project.org/web/views/Spatial.html
> http://www.datacarpentry.org/R-spatial-raster-vector-lesson/10-vector-csv-to-shapefile-in-r/
>
>
> Cheers,
> Roman
>
> On Mon, Jan 15, 2018 at 11:22 PM, lily li <chocold12 at gmail.com> wrote:
>
>> Hi users,
>>
>> I have no clear clue about plotting spatial data. For example, I just have
>> a table with attribute values of each grid cell, such as elevation. Then I
>> have coordinates of the upper left corner in UTM, the number of rows and
>> columns, and grid cell size. How to create spatial plot of elevations for
>> the grid cells, in color ramp? Should I create a spatial grid layer with
>> all the polygons first? Thanks.
>>
>> --
>> --
>> You received this message because you are subscribed to the ggplot2
>> mailing list.
>> Please provide a reproducible example: https://github.com/hadley/
>> devtools/wiki/Reproducibility
>>
>> To post: email ggplot2 at googlegroups.com
>> To unsubscribe: email ggplot2+unsubscribe at googlegroups.com
>> More options: http://groups.google.com/group/ggplot2
>>
>> ---
>> You received this message because you are subscribed to the Google Groups
>> "ggplot2" group.
>> To unsubscribe from this group and stop receiving emails from it, send an
>> email to ggplot2+unsubscribe at googlegroups.com.
>> For more options, visit https://groups.google.com/d/optout.
>>
>
>
>
> -- 
> In God we trust, all others bring data.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From chocold12 at gmail.com  Tue Jan 16 01:54:36 2018
From: chocold12 at gmail.com (lily li)
Date: Mon, 15 Jan 2018 17:54:36 -0700
Subject: [R] Steps to create spatial plots
In-Reply-To: <CAHT1vpgtC+p2QSKvPvcKUaBN0KPsBt-Jdr-zh6gEZ_K1Kd9AhA@mail.gmail.com>
References: <CAN5afy94sJGUFuQ+byRwLuA0Ayg+moHd8J1BoRuOpBNqbtZPmA@mail.gmail.com>
 <CAHT1vpgtC+p2QSKvPvcKUaBN0KPsBt-Jdr-zh6gEZ_K1Kd9AhA@mail.gmail.com>
Message-ID: <CAN5afy9duc=hbddSaKM3su9tBam5zjZM7h3Ea85Lk7Gb7XoE3w@mail.gmail.com>

Hi Roman,

Thanks for your reply. For the spatial coordinates layer, I just have
coordinates of the upper left corner, numbers of rows and columns of the
spatial map, and grid cell size. How to create a spatial layer of
coordinates from this data? Thanks.


On Mon, Jan 15, 2018 at 3:26 PM, Roman Lu?trik <roman.lustrik at gmail.com>
wrote:

> You will need to coerce your data into a "spatial" kind, as implemented in
> `sp` or as of late, `sf` packages. You might want to give the vignettes a
> whirl before you proceed.
> Roughly, you will have to coerce the data to Spatial* (you could go for a
> point, raster or grid type, I think) and also specify the projection. Once
> you have that, plotting should be handled by packages.
>
> Here are a few quick links that might come handy:
>
> https://cran.r-project.org/web/views/Spatial.html
> http://www.datacarpentry.org/R-spatial-raster-vector-
> lesson/10-vector-csv-to-shapefile-in-r/
>
>
> Cheers,
> Roman
>
> On Mon, Jan 15, 2018 at 11:22 PM, lily li <chocold12 at gmail.com> wrote:
>
>> Hi users,
>>
>> I have no clear clue about plotting spatial data. For example, I just
>> have a table with attribute values of each grid cell, such as elevation.
>> Then I have coordinates of the upper left corner in UTM, the number of rows
>> and columns, and grid cell size. How to create spatial plot of elevations
>> for the grid cells, in color ramp? Should I create a spatial grid layer
>> with all the polygons first? Thanks.
>>
>> --
>> --
>> You received this message because you are subscribed to the ggplot2
>> mailing list.
>> Please provide a reproducible example: https://github.com/hadley/devt
>> ools/wiki/Reproducibility
>>
>> To post: email ggplot2 at googlegroups.com
>> To unsubscribe: email ggplot2+unsubscribe at googlegroups.com
>> More options: http://groups.google.com/group/ggplot2
>>
>> ---
>> You received this message because you are subscribed to the Google Groups
>> "ggplot2" group.
>> To unsubscribe from this group and stop receiving emails from it, send an
>> email to ggplot2+unsubscribe at googlegroups.com.
>> For more options, visit https://groups.google.com/d/optout.
>>
>
>
>
> --
> In God we trust, all others bring data.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jan 16 02:04:03 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 15 Jan 2018 17:04:03 -0800
Subject: [R] Steps to create spatial plots
In-Reply-To: <CAN5afy9duc=hbddSaKM3su9tBam5zjZM7h3Ea85Lk7Gb7XoE3w@mail.gmail.com>
References: <CAN5afy94sJGUFuQ+byRwLuA0Ayg+moHd8J1BoRuOpBNqbtZPmA@mail.gmail.com>
 <CAHT1vpgtC+p2QSKvPvcKUaBN0KPsBt-Jdr-zh6gEZ_K1Kd9AhA@mail.gmail.com>
 <CAN5afy9duc=hbddSaKM3su9tBam5zjZM7h3Ea85Lk7Gb7XoE3w@mail.gmail.com>
Message-ID: <CAGxFJbSbPZ76RS34B44Kj5hCkfqC+m3Kq5XEOia=gA-ibNzXCg@mail.gmail.com>

>From your description, I am **guessing** that you may not want a "spatial
map" (including projections) at all, but rather something like a level
plot. See ?levelplot in the lattice package for details. Both I am sure
ggplot2 has something similar.

Apologies if I havemisunderstood your intent/specifications.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jan 15, 2018 at 4:54 PM, lily li <chocold12 at gmail.com> wrote:

> Hi Roman,
>
> Thanks for your reply. For the spatial coordinates layer, I just have
> coordinates of the upper left corner, numbers of rows and columns of the
> spatial map, and grid cell size. How to create a spatial layer of
> coordinates from this data? Thanks.
>
>
> On Mon, Jan 15, 2018 at 3:26 PM, Roman Lu?trik <roman.lustrik at gmail.com>
> wrote:
>
> > You will need to coerce your data into a "spatial" kind, as implemented
> in
> > `sp` or as of late, `sf` packages. You might want to give the vignettes a
> > whirl before you proceed.
> > Roughly, you will have to coerce the data to Spatial* (you could go for a
> > point, raster or grid type, I think) and also specify the projection.
> Once
> > you have that, plotting should be handled by packages.
> >
> > Here are a few quick links that might come handy:
> >
> > https://cran.r-project.org/web/views/Spatial.html
> > http://www.datacarpentry.org/R-spatial-raster-vector-
> > lesson/10-vector-csv-to-shapefile-in-r/
> >
> >
> > Cheers,
> > Roman
> >
> > On Mon, Jan 15, 2018 at 11:22 PM, lily li <chocold12 at gmail.com> wrote:
> >
> >> Hi users,
> >>
> >> I have no clear clue about plotting spatial data. For example, I just
> >> have a table with attribute values of each grid cell, such as elevation.
> >> Then I have coordinates of the upper left corner in UTM, the number of
> rows
> >> and columns, and grid cell size. How to create spatial plot of
> elevations
> >> for the grid cells, in color ramp? Should I create a spatial grid layer
> >> with all the polygons first? Thanks.
> >>
> >> --
> >> --
> >> You received this message because you are subscribed to the ggplot2
> >> mailing list.
> >> Please provide a reproducible example: https://github.com/hadley/devt
> >> ools/wiki/Reproducibility
> >>
> >> To post: email ggplot2 at googlegroups.com
> >> To unsubscribe: email ggplot2+unsubscribe at googlegroups.com
> >> More options: http://groups.google.com/group/ggplot2
> >>
> >> ---
> >> You received this message because you are subscribed to the Google
> Groups
> >> "ggplot2" group.
> >> To unsubscribe from this group and stop receiving emails from it, send
> an
> >> email to ggplot2+unsubscribe at googlegroups.com.
> >> For more options, visit https://groups.google.com/d/optout.
> >>
> >
> >
> >
> > --
> > In God we trust, all others bring data.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Tue Jan 16 02:11:39 2018
From: chocold12 at gmail.com (lily li)
Date: Mon, 15 Jan 2018 18:11:39 -0700
Subject: [R] Steps to create spatial plots
In-Reply-To: <CAGxFJbSbPZ76RS34B44Kj5hCkfqC+m3Kq5XEOia=gA-ibNzXCg@mail.gmail.com>
References: <CAN5afy94sJGUFuQ+byRwLuA0Ayg+moHd8J1BoRuOpBNqbtZPmA@mail.gmail.com>
 <CAHT1vpgtC+p2QSKvPvcKUaBN0KPsBt-Jdr-zh6gEZ_K1Kd9AhA@mail.gmail.com>
 <CAN5afy9duc=hbddSaKM3su9tBam5zjZM7h3Ea85Lk7Gb7XoE3w@mail.gmail.com>
 <CAGxFJbSbPZ76RS34B44Kj5hCkfqC+m3Kq5XEOia=gA-ibNzXCg@mail.gmail.com>
Message-ID: <CAN5afy-Vs4WNk1DE5ixPvgMBWA0Yw9bNe1OePAXtRKtCS2dbZg@mail.gmail.com>

The projection is UTM zone, but I meant that I don't have coordinates for
each grid cell, rather, I have coordinates for the upper left corner. The
attribute layer is elevation for each grid cell for example, I assume that
I need to create coordinates for the grid cells first? Thanks.

On Mon, Jan 15, 2018 at 6:04 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> From your description, I am **guessing** that you may not want a "spatial
> map" (including projections) at all, but rather something like a level
> plot. See ?levelplot in the lattice package for details. Both I am sure
> ggplot2 has something similar.
>
> Apologies if I havemisunderstood your intent/specifications.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Jan 15, 2018 at 4:54 PM, lily li <chocold12 at gmail.com> wrote:
>
>> Hi Roman,
>>
>> Thanks for your reply. For the spatial coordinates layer, I just have
>> coordinates of the upper left corner, numbers of rows and columns of the
>> spatial map, and grid cell size. How to create a spatial layer of
>> coordinates from this data? Thanks.
>>
>>
>> On Mon, Jan 15, 2018 at 3:26 PM, Roman Lu?trik <roman.lustrik at gmail.com>
>> wrote:
>>
>> > You will need to coerce your data into a "spatial" kind, as implemented
>> in
>> > `sp` or as of late, `sf` packages. You might want to give the vignettes
>> a
>> > whirl before you proceed.
>> > Roughly, you will have to coerce the data to Spatial* (you could go for
>> a
>> > point, raster or grid type, I think) and also specify the projection.
>> Once
>> > you have that, plotting should be handled by packages.
>> >
>> > Here are a few quick links that might come handy:
>> >
>> > https://cran.r-project.org/web/views/Spatial.html
>> > http://www.datacarpentry.org/R-spatial-raster-vector-
>> > lesson/10-vector-csv-to-shapefile-in-r/
>> >
>> >
>> > Cheers,
>> > Roman
>> >
>> > On Mon, Jan 15, 2018 at 11:22 PM, lily li <chocold12 at gmail.com> wrote:
>> >
>> >> Hi users,
>> >>
>> >> I have no clear clue about plotting spatial data. For example, I just
>> >> have a table with attribute values of each grid cell, such as
>> elevation.
>> >> Then I have coordinates of the upper left corner in UTM, the number of
>> rows
>> >> and columns, and grid cell size. How to create spatial plot of
>> elevations
>> >> for the grid cells, in color ramp? Should I create a spatial grid layer
>> >> with all the polygons first? Thanks.
>> >>
>> >> --
>> >> --
>> >> You received this message because you are subscribed to the ggplot2
>> >> mailing list.
>> >> Please provide a reproducible example: https://github.com/hadley/devt
>> >> ools/wiki/Reproducibility
>> >>
>> >> To post: email ggplot2 at googlegroups.com
>> >> To unsubscribe: email ggplot2+unsubscribe at googlegroups.com
>> >> More options: http://groups.google.com/group/ggplot2
>> >>
>> >> ---
>> >> You received this message because you are subscribed to the Google
>> Groups
>> >> "ggplot2" group.
>> >> To unsubscribe from this group and stop receiving emails from it, send
>> an
>> >> email to ggplot2+unsubscribe at googlegroups.com.
>> >> For more options, visit https://groups.google.com/d/optout.
>> >>
>> >
>> >
>> >
>> > --
>> > In God we trust, all others bring data.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Tue Jan 16 06:58:34 2018
From: chocold12 at gmail.com (lily li)
Date: Mon, 15 Jan 2018 22:58:34 -0700
Subject: [R] Steps to create spatial plots
In-Reply-To: <CAGxFJbSbPZ76RS34B44Kj5hCkfqC+m3Kq5XEOia=gA-ibNzXCg@mail.gmail.com>
References: <CAN5afy94sJGUFuQ+byRwLuA0Ayg+moHd8J1BoRuOpBNqbtZPmA@mail.gmail.com>
 <CAHT1vpgtC+p2QSKvPvcKUaBN0KPsBt-Jdr-zh6gEZ_K1Kd9AhA@mail.gmail.com>
 <CAN5afy9duc=hbddSaKM3su9tBam5zjZM7h3Ea85Lk7Gb7XoE3w@mail.gmail.com>
 <CAGxFJbSbPZ76RS34B44Kj5hCkfqC+m3Kq5XEOia=gA-ibNzXCg@mail.gmail.com>
Message-ID: <CAN5afy_MtiNPwo2YUb0C+ieSp0NO55Pmrtcs3D=OjNY0BYjdRw@mail.gmail.com>

Hi Bert,

I think you are correct that I can use levelplot, but I have a question
about converting data. For example, the statement:
levelplot(Z~X*Y), Z is row-wise from the lower left corner to the upper
right corner.
My dataset just have gridded Z data as a txt file (or can be called
matrix?), how to convert them to the vector in order for levelplot to use?
Thanks.

On Mon, Jan 15, 2018 at 6:04 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> From your description, I am **guessing** that you may not want a "spatial
> map" (including projections) at all, but rather something like a level
> plot. See ?levelplot in the lattice package for details. Both I am sure
> ggplot2 has something similar.
>
> Apologies if I havemisunderstood your intent/specifications.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Jan 15, 2018 at 4:54 PM, lily li <chocold12 at gmail.com> wrote:
>
>> Hi Roman,
>>
>> Thanks for your reply. For the spatial coordinates layer, I just have
>> coordinates of the upper left corner, numbers of rows and columns of the
>> spatial map, and grid cell size. How to create a spatial layer of
>> coordinates from this data? Thanks.
>>
>>
>> On Mon, Jan 15, 2018 at 3:26 PM, Roman Lu?trik <roman.lustrik at gmail.com>
>> wrote:
>>
>> > You will need to coerce your data into a "spatial" kind, as implemented
>> in
>> > `sp` or as of late, `sf` packages. You might want to give the vignettes
>> a
>> > whirl before you proceed.
>> > Roughly, you will have to coerce the data to Spatial* (you could go for
>> a
>> > point, raster or grid type, I think) and also specify the projection.
>> Once
>> > you have that, plotting should be handled by packages.
>> >
>> > Here are a few quick links that might come handy:
>> >
>> > https://cran.r-project.org/web/views/Spatial.html
>> > http://www.datacarpentry.org/R-spatial-raster-vector-
>> > lesson/10-vector-csv-to-shapefile-in-r/
>> >
>> >
>> > Cheers,
>> > Roman
>> >
>> > On Mon, Jan 15, 2018 at 11:22 PM, lily li <chocold12 at gmail.com> wrote:
>> >
>> >> Hi users,
>> >>
>> >> I have no clear clue about plotting spatial data. For example, I just
>> >> have a table with attribute values of each grid cell, such as
>> elevation.
>> >> Then I have coordinates of the upper left corner in UTM, the number of
>> rows
>> >> and columns, and grid cell size. How to create spatial plot of
>> elevations
>> >> for the grid cells, in color ramp? Should I create a spatial grid layer
>> >> with all the polygons first? Thanks.
>> >>
>> >> --
>> >> --
>> >> You received this message because you are subscribed to the ggplot2
>> >> mailing list.
>> >> Please provide a reproducible example: https://github.com/hadley/devt
>> >> ools/wiki/Reproducibility
>> >>
>> >> To post: email ggplot2 at googlegroups.com
>> >> To unsubscribe: email ggplot2+unsubscribe at googlegroups.com
>> >> More options: http://groups.google.com/group/ggplot2
>> >>
>> >> ---
>> >> You received this message because you are subscribed to the Google
>> Groups
>> >> "ggplot2" group.
>> >> To unsubscribe from this group and stop receiving emails from it, send
>> an
>> >> email to ggplot2+unsubscribe at googlegroups.com.
>> >> For more options, visit https://groups.google.com/d/optout.
>> >>
>> >
>> >
>> >
>> > --
>> > In God we trust, all others bring data.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Tue Jan 16 07:43:15 2018
From: chocold12 at gmail.com (lily li)
Date: Mon, 15 Jan 2018 23:43:15 -0700
Subject: [R] Steps to create spatial plots
In-Reply-To: <CAN5afy_MtiNPwo2YUb0C+ieSp0NO55Pmrtcs3D=OjNY0BYjdRw@mail.gmail.com>
References: <CAN5afy94sJGUFuQ+byRwLuA0Ayg+moHd8J1BoRuOpBNqbtZPmA@mail.gmail.com>
 <CAHT1vpgtC+p2QSKvPvcKUaBN0KPsBt-Jdr-zh6gEZ_K1Kd9AhA@mail.gmail.com>
 <CAN5afy9duc=hbddSaKM3su9tBam5zjZM7h3Ea85Lk7Gb7XoE3w@mail.gmail.com>
 <CAGxFJbSbPZ76RS34B44Kj5hCkfqC+m3Kq5XEOia=gA-ibNzXCg@mail.gmail.com>
 <CAN5afy_MtiNPwo2YUb0C+ieSp0NO55Pmrtcs3D=OjNY0BYjdRw@mail.gmail.com>
Message-ID: <CAN5afy-BDLPYYSKeZ6-qb0E+faeU1MdSWu6M0M5rchS2buhd9w@mail.gmail.com>

Sorry for the emails, I just wanted to have an example.
layer$z

1  1  3  4  6  2
2  3  4  1  2  9
1  4  5  2  1  8

How to convert the matrix to layer$z = c(1, 4, 5, 2, 1, 8, 2, 3, 4, 1, 2,
9, 1, 1, 3, 4, 6, 2)?
I think this vector is the order that levelplot can use. Thanks again.


On Mon, Jan 15, 2018 at 10:58 PM, lily li <chocold12 at gmail.com> wrote:

> Hi Bert,
>
> I think you are correct that I can use levelplot, but I have a question
> about converting data. For example, the statement:
> levelplot(Z~X*Y), Z is row-wise from the lower left corner to the upper
> right corner.
> My dataset just have gridded Z data as a txt file (or can be called
> matrix?), how to convert them to the vector in order for levelplot to use?
> Thanks.
>
> On Mon, Jan 15, 2018 at 6:04 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> From your description, I am **guessing** that you may not want a "spatial
>> map" (including projections) at all, but rather something like a level
>> plot. See ?levelplot in the lattice package for details. Both I am sure
>> ggplot2 has something similar.
>>
>> Apologies if I havemisunderstood your intent/specifications.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Mon, Jan 15, 2018 at 4:54 PM, lily li <chocold12 at gmail.com> wrote:
>>
>>> Hi Roman,
>>>
>>> Thanks for your reply. For the spatial coordinates layer, I just have
>>> coordinates of the upper left corner, numbers of rows and columns of the
>>> spatial map, and grid cell size. How to create a spatial layer of
>>> coordinates from this data? Thanks.
>>>
>>>
>>> On Mon, Jan 15, 2018 at 3:26 PM, Roman Lu?trik <roman.lustrik at gmail.com>
>>> wrote:
>>>
>>> > You will need to coerce your data into a "spatial" kind, as
>>> implemented in
>>> > `sp` or as of late, `sf` packages. You might want to give the
>>> vignettes a
>>> > whirl before you proceed.
>>> > Roughly, you will have to coerce the data to Spatial* (you could go
>>> for a
>>> > point, raster or grid type, I think) and also specify the projection.
>>> Once
>>> > you have that, plotting should be handled by packages.
>>> >
>>> > Here are a few quick links that might come handy:
>>> >
>>> > https://cran.r-project.org/web/views/Spatial.html
>>> > http://www.datacarpentry.org/R-spatial-raster-vector-
>>> > lesson/10-vector-csv-to-shapefile-in-r/
>>> >
>>> >
>>> > Cheers,
>>> > Roman
>>> >
>>> > On Mon, Jan 15, 2018 at 11:22 PM, lily li <chocold12 at gmail.com> wrote:
>>> >
>>> >> Hi users,
>>> >>
>>> >> I have no clear clue about plotting spatial data. For example, I just
>>> >> have a table with attribute values of each grid cell, such as
>>> elevation.
>>> >> Then I have coordinates of the upper left corner in UTM, the number
>>> of rows
>>> >> and columns, and grid cell size. How to create spatial plot of
>>> elevations
>>> >> for the grid cells, in color ramp? Should I create a spatial grid
>>> layer
>>> >> with all the polygons first? Thanks.
>>> >>
>>> >> --
>>> >> --
>>> >> You received this message because you are subscribed to the ggplot2
>>> >> mailing list.
>>> >> Please provide a reproducible example: https://github.com/hadley/devt
>>> >> ools/wiki/Reproducibility
>>> >>
>>> >> To post: email ggplot2 at googlegroups.com
>>> >> To unsubscribe: email ggplot2+unsubscribe at googlegroups.com
>>> >> More options: http://groups.google.com/group/ggplot2
>>> >>
>>> >> ---
>>> >> You received this message because you are subscribed to the Google
>>> Groups
>>> >> "ggplot2" group.
>>> >> To unsubscribe from this group and stop receiving emails from it,
>>> send an
>>> >> email to ggplot2+unsubscribe at googlegroups.com.
>>> >> For more options, visit https://groups.google.com/d/optout.
>>> >>
>>> >
>>> >
>>> >
>>> > --
>>> > In God we trust, all others bring data.
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Tue Jan 16 08:36:21 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Tue, 16 Jan 2018 09:36:21 +0200
Subject: [R] Steps to create spatial plots
In-Reply-To: <CAN5afy-BDLPYYSKeZ6-qb0E+faeU1MdSWu6M0M5rchS2buhd9w@mail.gmail.com>
References: <CAN5afy94sJGUFuQ+byRwLuA0Ayg+moHd8J1BoRuOpBNqbtZPmA@mail.gmail.com>
 <CAHT1vpgtC+p2QSKvPvcKUaBN0KPsBt-Jdr-zh6gEZ_K1Kd9AhA@mail.gmail.com>
 <CAN5afy9duc=hbddSaKM3su9tBam5zjZM7h3Ea85Lk7Gb7XoE3w@mail.gmail.com>
 <CAGxFJbSbPZ76RS34B44Kj5hCkfqC+m3Kq5XEOia=gA-ibNzXCg@mail.gmail.com>
 <CAN5afy_MtiNPwo2YUb0C+ieSp0NO55Pmrtcs3D=OjNY0BYjdRw@mail.gmail.com>
 <CAN5afy-BDLPYYSKeZ6-qb0E+faeU1MdSWu6M0M5rchS2buhd9w@mail.gmail.com>
Message-ID: <CAGgJW76040LC6H5y4bA1kL6OXMOS=Jm69KqcZpewkovYVG64_Q@mail.gmail.com>

If layer$z is a matrix and you want to reverse the order of the rows, you
can do:

n <- nrow(layer$z)
layer$z <- layer$z[ n:1, ]

HTH,
Eric


On Tue, Jan 16, 2018 at 8:43 AM, lily li <chocold12 at gmail.com> wrote:

> Sorry for the emails, I just wanted to have an example.
> layer$z
>
> 1  1  3  4  6  2
> 2  3  4  1  2  9
> 1  4  5  2  1  8
>
> How to convert the matrix to layer$z = c(1, 4, 5, 2, 1, 8, 2, 3, 4, 1, 2,
> 9, 1, 1, 3, 4, 6, 2)?
> I think this vector is the order that levelplot can use. Thanks again.
>
>
> On Mon, Jan 15, 2018 at 10:58 PM, lily li <chocold12 at gmail.com> wrote:
>
> > Hi Bert,
> >
> > I think you are correct that I can use levelplot, but I have a question
> > about converting data. For example, the statement:
> > levelplot(Z~X*Y), Z is row-wise from the lower left corner to the upper
> > right corner.
> > My dataset just have gridded Z data as a txt file (or can be called
> > matrix?), how to convert them to the vector in order for levelplot to
> use?
> > Thanks.
> >
> > On Mon, Jan 15, 2018 at 6:04 PM, Bert Gunter <bgunter.4567 at gmail.com>
> > wrote:
> >
> >> From your description, I am **guessing** that you may not want a
> "spatial
> >> map" (including projections) at all, but rather something like a level
> >> plot. See ?levelplot in the lattice package for details. Both I am sure
> >> ggplot2 has something similar.
> >>
> >> Apologies if I havemisunderstood your intent/specifications.
> >>
> >> Cheers,
> >> Bert
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >> On Mon, Jan 15, 2018 at 4:54 PM, lily li <chocold12 at gmail.com> wrote:
> >>
> >>> Hi Roman,
> >>>
> >>> Thanks for your reply. For the spatial coordinates layer, I just have
> >>> coordinates of the upper left corner, numbers of rows and columns of
> the
> >>> spatial map, and grid cell size. How to create a spatial layer of
> >>> coordinates from this data? Thanks.
> >>>
> >>>
> >>> On Mon, Jan 15, 2018 at 3:26 PM, Roman Lu?trik <
> roman.lustrik at gmail.com>
> >>> wrote:
> >>>
> >>> > You will need to coerce your data into a "spatial" kind, as
> >>> implemented in
> >>> > `sp` or as of late, `sf` packages. You might want to give the
> >>> vignettes a
> >>> > whirl before you proceed.
> >>> > Roughly, you will have to coerce the data to Spatial* (you could go
> >>> for a
> >>> > point, raster or grid type, I think) and also specify the projection.
> >>> Once
> >>> > you have that, plotting should be handled by packages.
> >>> >
> >>> > Here are a few quick links that might come handy:
> >>> >
> >>> > https://cran.r-project.org/web/views/Spatial.html
> >>> > http://www.datacarpentry.org/R-spatial-raster-vector-
> >>> > lesson/10-vector-csv-to-shapefile-in-r/
> >>> >
> >>> >
> >>> > Cheers,
> >>> > Roman
> >>> >
> >>> > On Mon, Jan 15, 2018 at 11:22 PM, lily li <chocold12 at gmail.com>
> wrote:
> >>> >
> >>> >> Hi users,
> >>> >>
> >>> >> I have no clear clue about plotting spatial data. For example, I
> just
> >>> >> have a table with attribute values of each grid cell, such as
> >>> elevation.
> >>> >> Then I have coordinates of the upper left corner in UTM, the number
> >>> of rows
> >>> >> and columns, and grid cell size. How to create spatial plot of
> >>> elevations
> >>> >> for the grid cells, in color ramp? Should I create a spatial grid
> >>> layer
> >>> >> with all the polygons first? Thanks.
> >>> >>
> >>> >> --
> >>> >> --
> >>> >> You received this message because you are subscribed to the ggplot2
> >>> >> mailing list.
> >>> >> Please provide a reproducible example:
> https://github.com/hadley/devt
> >>> >> ools/wiki/Reproducibility
> >>> >>
> >>> >> To post: email ggplot2 at googlegroups.com
> >>> >> To unsubscribe: email ggplot2+unsubscribe at googlegroups.com
> >>> >> More options: http://groups.google.com/group/ggplot2
> >>> >>
> >>> >> ---
> >>> >> You received this message because you are subscribed to the Google
> >>> Groups
> >>> >> "ggplot2" group.
> >>> >> To unsubscribe from this group and stop receiving emails from it,
> >>> send an
> >>> >> email to ggplot2+unsubscribe at googlegroups.com.
> >>> >> For more options, visit https://groups.google.com/d/optout.
> >>> >>
> >>> >
> >>> >
> >>> >
> >>> > --
> >>> > In God we trust, all others bring data.
> >>> >
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posti
> >>> ng-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From adr.fantini at gmail.com  Tue Jan 16 08:06:23 2018
From: adr.fantini at gmail.com (Adriano Fantini)
Date: Tue, 16 Jan 2018 08:06:23 +0100
Subject: [R] Steps to create spatial plots
In-Reply-To: <CAHT1vpgtC+p2QSKvPvcKUaBN0KPsBt-Jdr-zh6gEZ_K1Kd9AhA@mail.gmail.com>
References: <CAN5afy94sJGUFuQ+byRwLuA0Ayg+moHd8J1BoRuOpBNqbtZPmA@mail.gmail.com>
 <CAHT1vpgtC+p2QSKvPvcKUaBN0KPsBt-Jdr-zh6gEZ_K1Kd9AhA@mail.gmail.com>
Message-ID: <CANuZVD=UimHxS719kvtEXdbgczZtNi+uwDpcf1UASZWeHqKQxA@mail.gmail.com>

the latest ggplot from github (to be installed with
`devtools:install_github()`) has support for SF objects too, it's a treat!
However, sf is not exactly designed for raster data. Of course you can make
each of your cells be a square polygon, but it's not the most efficient way
for big datasets. For this the `raster` (excellent and rock stable) and
`stars` (even more excellent, but in heavy development) can be used.

Adriano Fantini

2018-01-15 23:26 GMT+01:00 Roman Lu?trik <roman.lustrik at gmail.com>:

> You will need to coerce your data into a "spatial" kind, as implemented in
> `sp` or as of late, `sf` packages. You might want to give the vignettes a
> whirl before you proceed.
> Roughly, you will have to coerce the data to Spatial* (you could go for a
> point, raster or grid type, I think) and also specify the projection. Once
> you have that, plotting should be handled by packages.
>
> Here are a few quick links that might come handy:
>
> https://cran.r-project.org/web/views/Spatial.html
> http://www.datacarpentry.org/R-spatial-raster-vector-
> lesson/10-vector-csv-to-shapefile-in-r/
>
>
> Cheers,
> Roman
>
> On Mon, Jan 15, 2018 at 11:22 PM, lily li <chocold12 at gmail.com> wrote:
>
>> Hi users,
>>
>> I have no clear clue about plotting spatial data. For example, I just
>> have a table with attribute values of each grid cell, such as elevation.
>> Then I have coordinates of the upper left corner in UTM, the number of rows
>> and columns, and grid cell size. How to create spatial plot of elevations
>> for the grid cells, in color ramp? Should I create a spatial grid layer
>> with all the polygons first? Thanks.
>>
>> --
>> --
>> You received this message because you are subscribed to the ggplot2
>> mailing list.
>> Please provide a reproducible example: https://github.com/hadley/devt
>> ools/wiki/Reproducibility
>>
>> To post: email ggplot2 at googlegroups.com
>> To unsubscribe: email ggplot2+unsubscribe at googlegroups.com
>> More options: http://groups.google.com/group/ggplot2
>>
>> ---
>> You received this message because you are subscribed to the Google Groups
>> "ggplot2" group.
>> To unsubscribe from this group and stop receiving emails from it, send an
>> email to ggplot2+unsubscribe at googlegroups.com.
>> For more options, visit https://groups.google.com/d/optout.
>>
>
>
>
> --
> In God we trust, all others bring data.
>
> --
> --
> You received this message because you are subscribed to the ggplot2
> mailing list.
> Please provide a reproducible example: https://github.com/hadley/
> devtools/wiki/Reproducibility
>
> To post: email ggplot2 at googlegroups.com
> To unsubscribe: email ggplot2+unsubscribe at googlegroups.com
> More options: http://groups.google.com/group/ggplot2
>
> ---
> You received this message because you are subscribed to the Google Groups
> "ggplot2" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to ggplot2+unsubscribe at googlegroups.com.
> For more options, visit https://groups.google.com/d/optout.
>

	[[alternative HTML version deleted]]


From jwijffels at bnosac.be  Mon Jan 15 19:29:44 2018
From: jwijffels at bnosac.be (Jan Wijffels)
Date: Mon, 15 Jan 2018 19:29:44 +0100
Subject: [R] [R-pkgs] Natural Language Processing for non-English languages
	with	udpipe
Message-ID: <CAJ9GNanA=KgGOoxpO3PUYkPQheg6pxYdJXuKs0Nwuc9JaSdHRg@mail.gmail.com>

Dear R users,

I'm happy to announce the release of version 0.3 of the udpipe R package on
CRAN (https://CRAN.R-project.org/package=udpipe). The udpipe R package is a
Natural Language Processing toolkit that provides language-agnostic
'tokenization', 'parts of speech tagging', 'lemmatization', 'morphological
feature tagging' and 'dependency parsing' of raw text. Next to text
parsing, the R package also allows you to train annotation models based on
data of 'treebanks' in 'CoNLL-U' format as provided at
http://universaldependencies.org/format.html.

The R package provides direct access to language models trained on more
than 50 languages. The following languages are directly available:

afrikaans, ancient_greek-proiel, ancient_greek, arabic, basque, belarusian,
bulgarian, catalan, chinese, coptic, croatian, czech-cac, czech-cltt,
czech, danish, dutch-lassysmall, dutch, english-lines, english-partut,
english, estonian, finnish-ftb, finnish, french-partut, french-sequoia,
french, galician-treegal, galician, german, gothic, greek, hebrew, hindi,
hungarian, indonesian, irish, italian, japanese, kazakh, korean,
latin-ittb, latin-proiel, latin, latvian, lithuanian, norwegian-bokmaal,
norwegian-nynorsk, old_church_slavonic, persian, polish, portuguese-br,
portuguese, romanian, russian-syntagrus, russian, sanskrit, serbian,
slovak, slovenian-sst, slovenian, spanish-ancora, spanish, swedish-lines,
swedish, tamil, turkish, ukrainian, urdu, uyghur, vietnamese

We hope that the package will allow other R users to build natural language
applications on top of the resulting parts of speech tags, tokens,
morphological features and dependency parsing output. And we hope in
particular that applications will arise which are not limited to English
only (like the textrank R package or the cleanNLP package to name a few)

Note that the package has no external software dependencies (no java nor
python) and depends only on 2 R packages (Rcpp and data.table), which makes
the package easy to install on any platform.

The package is available on CRAN at
https://CRAN.R-project.org/package=udpipe and is developed at
https://github.com/bnosac/udpipe
A small docusaurus website is made available at
https://bnosac.github.io/udpipe/en

We hope you enjoy using it and we would like to thank Milan Straka for all
the efforts done on UDPipe as well as all persons involved in
http://universaldependencies.org

all the best,
Jan

Jan Wijffels
Statistician
www.bnosac.be  | +32 486 611708

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From alejandra7galan at gmail.com  Tue Jan 16 09:14:10 2018
From: alejandra7galan at gmail.com (Alejandra Lopez-Galan)
Date: Tue, 16 Jan 2018 18:14:10 +1000
Subject: [R] sum multiple csv files
In-Reply-To: <F777EAE0-38C0-4887-A34F-BC20964F9DE5@dcn.davis.ca.us>
References: <CAEu_PQNC=AfAoJWMrMWeGdmb=EkuSKPnXyeZY5DmNS-tV5QHEQ@mail.gmail.com>
 <F777EAE0-38C0-4887-A34F-BC20964F9DE5@dcn.davis.ca.us>
Message-ID: <CAEu_PQOC=zvJ27qxUKLUFkvydD4GwkMdXxczyhF_b1VybTTh=A@mail.gmail.com>

Hi all,

Thanks for your help and sorry for the confusion. Also Thanks Jeff,
your solution worked well, I was trying to perform matrix
(element-wise) addition as you mentioned, but I didn't know how to
formulate my question. Thanks for the references, they also help me to
understand more.

Cheers,
Alejandra



On Tue, Jan 16, 2018 at 2:35 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Your message seems unclear, and as evidence the respondents are giving various answers. You should provide a small sample of input and output data as it would look in R to avoid this kind of thrashing about. See [1][2][3] for guidance. Note that you also really need to figure out how to make sure your email program sends plain text, because HTML formatting WILL be stripped by the mailing list (read the Posting Guide) and that process often garbles it.
>
> My own possibly-confused reading of your question ("each cvs file has 47 rows and colunms, so the final data frame should have the same") is that you do not yet understand the difference between matrices and data frames ([4]), and you want to perform matrix (element-wise) addition. This would require that you convert the data frames read in by read.csv into matrices before adding them:
>
> All_data <- lapply(filenames
> ,function(i){
> ###read cvs files and add the row and column names to each data frame
> ###
>  as.matrix( read.csv(i, header=FALSE, sep = "", col.names = col_names, row.names = row_names)
> })
>
> result <- Reduce( `+`, All_data )
>
> This will fail if any of the values in your csv files are non-numeric, but dealing with that would require us to know specifics about your files or intent that you have omitted. (The dput function is indispensable for clarifying such issues [1][2].)
> ---
>
> [1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> [2] http://adv-r.had.co.nz/Reproducibility.html
>
> [3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)
>
> [4] see "Introduction to R" (part of the R documentation)
>
> --
> Sent from my phone. Please excuse my brevity.
>
> On January 15, 2018 1:29:05 AM PST, Alejandra Lopez-Galan <alejandra7galan at gmail.com> wrote:
>>Hi, I am pretty new to R and I would apreciatte very much your help to
>>solve my problem. I have 40 csv files that have the same structure, and
>>I
>>want to merge them into a single data frame.
>>
>>I already have load and combined all the cvs files into a large list,
>>and I
>>created two
>>
>>filenames <- list.files('data',full.names=TRUE)
>>
>>All_data <- lapply(filenames,function(i){
>>###read cvs files and add the row and column names to each data
>>frame###
>> read.csv(i, header=FALSE, sep = "", col.names = col_names, row.names =
>>row_names)
>> })
>>
>>However I would like to sum the rows of cvs files to get a single data
>>frame (each cvs file has 47 rows and colunms, so the final data frame
>>should have the same). I could only do it one by one data data frame,
>>but I
>>was wondering if anyone could give an idea of how to write a function
>>for
>>this.
>>
>>Thanks,
>>Alejandra
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From styen at ntu.edu.tw  Tue Jan 16 09:43:49 2018
From: styen at ntu.edu.tw (Steven Yen)
Date: Tue, 16 Jan 2018 16:43:49 +0800
Subject: [R] Merging RData files
Message-ID: <37d117f5-6fa9-e1dc-4baf-0a45bc2b8810@ntu.edu.tw>

I ran two separate hours-long projects. Results of each were saved to 
two separate .RData files.
Content of each includes, among others, the following:

 ?????????????????? me??? se????? t???? p sig
pc21.age??????? 0.640 0.219? 2.918 0.004 ***
pc21.agesq????? 0.000 0.000??? NaN?? NaN
pc21.inc??????? 0.903 0.103? 8.752 0.000 ***
pc21.incsq????? 0.000 0.000??? NaN?? NaN
pc21.sei10????? 0.451 0.145? 3.122 0.002 ***
pc21.sblkprot? -4.334 3.387? 1.280 0.201
...

Question: How can I combine/consolidate the two .RData files into one? 
Thank you.





	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Jan 16 12:06:03 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 16 Jan 2018 06:06:03 -0500
Subject: [R] Merging RData files
In-Reply-To: <37d117f5-6fa9-e1dc-4baf-0a45bc2b8810@ntu.edu.tw>
References: <37d117f5-6fa9-e1dc-4baf-0a45bc2b8810@ntu.edu.tw>
Message-ID: <c43867a4-8518-0572-cab9-40ebe8548c6a@gmail.com>

On 16/01/2018 3:43 AM, Steven Yen wrote:
> I ran two separate hours-long projects. Results of each were saved to
> two separate .RData files.
> Content of each includes, among others, the following:
> 
>   ?????????????????? me??? se????? t???? p sig
> pc21.age??????? 0.640 0.219? 2.918 0.004 ***
> pc21.agesq????? 0.000 0.000??? NaN?? NaN
> pc21.inc??????? 0.903 0.103? 8.752 0.000 ***
> pc21.incsq????? 0.000 0.000??? NaN?? NaN
> pc21.sei10????? 0.451 0.145? 3.122 0.002 ***
> pc21.sblkprot? -4.334 3.387? 1.280 0.201
> ...
> 
> Question: How can I combine/consolidate the two .RData files into one?
> Thank you.



Load both of them, produce the object you want to save, and save it. If 
some objects have the same names in both files, do this carefully:  the 
second load will overwrite the first one.  A safe way to do it is 
described here:  https://www.r-bloggers.com/safe-loading-of-rdata-files-2/

Duncan Murdoch


From petr.pikal at precheza.cz  Tue Jan 16 12:08:39 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 16 Jan 2018 11:08:39 +0000
Subject: [R] Merging RData files
In-Reply-To: <37d117f5-6fa9-e1dc-4baf-0a45bc2b8810@ntu.edu.tw>
References: <37d117f5-6fa9-e1dc-4baf-0a45bc2b8810@ntu.edu.tw>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD3D2E@SRVEXCHCM301.precheza.cz>

Huh.

I may by completely wrong but you cannot do such "merging". .RData files are AFAIK places where all objects from given session are stored.

However you could load each .RData file and save/export result (one object).

BTW, what do you mean exactly by "combine/consolidate"?

And finally, post your questions in plain text not html, otherwise they can be mangled.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Steven Yen
> Sent: Tuesday, January 16, 2018 9:44 AM
> To: r-help at r-project.org
> Subject: [R] Merging RData files
>
> I ran two separate hours-long projects. Results of each were saved to two
> separate .RData files.
> Content of each includes, among others, the following:
>
>                     me    se      t     p sig pc21.age        0.640 0.219  2.918 0.004 ***
> pc21.agesq      0.000 0.000    NaN   NaN pc21.inc        0.903 0.103  8.752 0.000
> *** pc21.incsq      0.000 0.000    NaN   NaN
> pc21.sei10      0.451 0.145  3.122 0.002 *** pc21.sblkprot  -4.334 3.387  1.280
> 0.201 ...
>
> Question: How can I combine/consolidate the two .RData files into one?
> Thank you.
>
>
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From styen at ntu.edu.tw  Tue Jan 16 12:33:28 2018
From: styen at ntu.edu.tw (Steven Yen)
Date: Tue, 16 Jan 2018 19:33:28 +0800
Subject: [R] Merging RData files
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD3D2E@SRVEXCHCM301.precheza.cz>
References: <37d117f5-6fa9-e1dc-4baf-0a45bc2b8810@ntu.edu.tw>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD3D2E@SRVEXCHCM301.precheza.cz>
Message-ID: <97d0b576-4858-7159-4f85-c5c93ee2154c@ntu.edu.tw>

Hi all,
This is great. Again, here is what I need. I run two separate jobs (a.R 
and b.R) with results (say regression outputs) going to a.RData and 
b.RData. I like to put all results in one place (where I can retrieve 
them in one place, ab.RData). The following codes do it (I am not sure 
if line 2 is needed but I am happy). Thank you all.

load("a.RData")
save.image("ab.RData")
load("b.RData")
save.image("ab.RData")

On 1/16/2018 7:08 PM, PIKAL Petr wrote:
> Huh.
>
> I may by completely wrong but you cannot do such "merging". .RData files are AFAIK places where all objects from given session are stored.
>
> However you could load each .RData file and save/export result (one object).
>
> BTW, what do you mean exactly by "combine/consolidate"?
>
> And finally, post your questions in plain text not html, otherwise they can be mangled.
>
> Cheers
> Petr
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Steven Yen
>> Sent: Tuesday, January 16, 2018 9:44 AM
>> To: r-help at r-project.org
>> Subject: [R] Merging RData files
>>
>> I ran two separate hours-long projects. Results of each were saved to two
>> separate .RData files.
>> Content of each includes, among others, the following:
>>
>>                      me    se      t     p sig pc21.age        0.640 0.219  2.918 0.004 ***
>> pc21.agesq      0.000 0.000    NaN   NaN pc21.inc        0.903 0.103  8.752 0.000
>> *** pc21.incsq      0.000 0.000    NaN   NaN
>> pc21.sei10      0.451 0.145  3.122 0.002 *** pc21.sblkprot  -4.334 3.387  1.280
>> 0.201 ...
>>
>> Question: How can I combine/consolidate the two .RData files into one?
>> Thank you.
>>
>>
>>
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

-- 
styen at ntu.edu.tw (S.T. Yen)


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Jan 16 13:06:18 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 16 Jan 2018 07:06:18 -0500
Subject: [R] Merging RData files
In-Reply-To: <97d0b576-4858-7159-4f85-c5c93ee2154c@ntu.edu.tw>
References: <37d117f5-6fa9-e1dc-4baf-0a45bc2b8810@ntu.edu.tw>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD3D2E@SRVEXCHCM301.precheza.cz>
 <97d0b576-4858-7159-4f85-c5c93ee2154c@ntu.edu.tw>
Message-ID: <9378a346-f1bd-f5bb-8de6-16f85b6610ca@gmail.com>

On 16/01/2018 6:33 AM, Steven Yen wrote:
> Hi all,
> This is great. Again, here is what I need. I run two separate jobs (a.R
> and b.R) with results (say regression outputs) going to a.RData and
> b.RData. I like to put all results in one place (where I can retrieve
> them in one place, ab.RData). The following codes do it (I am not sure
> if line 2 is needed but I am happy). Thank you all.
> 
> load("a.RData")
> save.image("ab.RData")
> load("b.RData")
> save.image("ab.RData")

That's the same as

load("a.RData")
load("b.RData")
save.image("ab.RData")

because the second saved image overwrites the first one.  It'll be okay 
if all the variable names are different in a.RData and b.RData, but will 
lose values from a.RData if any of them have the same names as objects 
in b.RData.  See the link I posted earlier to avoid this.

Duncan Murdoch

> 
> On 1/16/2018 7:08 PM, PIKAL Petr wrote:
>> Huh.
>>
>> I may by completely wrong but you cannot do such "merging". .RData files are AFAIK places where all objects from given session are stored.
>>
>> However you could load each .RData file and save/export result (one object).
>>
>> BTW, what do you mean exactly by "combine/consolidate"?
>>
>> And finally, post your questions in plain text not html, otherwise they can be mangled.
>>
>> Cheers
>> Petr
>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Steven Yen
>>> Sent: Tuesday, January 16, 2018 9:44 AM
>>> To: r-help at r-project.org
>>> Subject: [R] Merging RData files
>>>
>>> I ran two separate hours-long projects. Results of each were saved to two
>>> separate .RData files.
>>> Content of each includes, among others, the following:
>>>
>>>                       me    se      t     p sig pc21.age        0.640 0.219  2.918 0.004 ***
>>> pc21.agesq      0.000 0.000    NaN   NaN pc21.inc        0.903 0.103  8.752 0.000
>>> *** pc21.incsq      0.000 0.000    NaN   NaN
>>> pc21.sei10      0.451 0.145  3.122 0.002 *** pc21.sblkprot  -4.334 3.387  1.280
>>> 0.201 ...
>>>
>>> Question: How can I combine/consolidate the two .RData files into one?
>>> Thank you.
>>>
>>>
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
>> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
>> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
>


From emekadonn at gmail.com  Tue Jan 16 13:08:57 2018
From: emekadonn at gmail.com (Emeka Don)
Date: Tue, 16 Jan 2018 13:08:57 +0100
Subject: [R] Packages couldn't load
Message-ID: <CAJ3tmCrfNSBMFXHKZYxex0EWDgV7yFRoo+jSfB4tN-DCXuwZew@mail.gmail.com>

Dear All,
I have been trying to install Xlsx package in R but  i have been getting
this error after the installation. Please can anyone help?

> any(grepl("xlsx",installed.packages()))
[1] TRUE
> library("xlsx")
Loading required package: rJava
Error: package or namespace load failed for ?rJava?:
 .onLoad failed in loadNamespace() for 'rJava', details:
  call: fun(libname, pkgname)
  error: JAVA_HOME cannot be determined from the Registry
Error: package ?rJava? could not be loaded
In addition: Warning messages:
1: package ?xlsx? was built under R version 3.4.3
2: package ?rJava? was built under R version 3.4.3

Thank you

-- 
Onyeuwaoma Nnaemeka Dom PhD.
Scientific Officer.
Center for Basic Space Science (CBSS)
National Space Research and Development Agency (NASRDA)
Federal Ministry of Science and Technology
University of Nigeria, Nsukka
P. M. B. 2022, Nsukka, Enugu State, Nigeria.
+2348032686377, +2347052835685
email:onyeuwaoma.emeka at cbss.nasrda.gov.ng

	[[alternative HTML version deleted]]


From styen at ntu.edu.tw  Tue Jan 16 13:13:00 2018
From: styen at ntu.edu.tw (Steven Yen)
Date: Tue, 16 Jan 2018 20:13:00 +0800
Subject: [R] Merging RData files
In-Reply-To: <9378a346-f1bd-f5bb-8de6-16f85b6610ca@gmail.com>
References: <37d117f5-6fa9-e1dc-4baf-0a45bc2b8810@ntu.edu.tw>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD3D2E@SRVEXCHCM301.precheza.cz>
 <97d0b576-4858-7159-4f85-c5c93ee2154c@ntu.edu.tw>
 <9378a346-f1bd-f5bb-8de6-16f85b6610ca@gmail.com>
Message-ID: <9cfa2848-7b1b-4a25-29b6-d87c6977d0f1@ntu.edu.tw>

Understood. In my case, a.RData and b.RData contain identical 
variables/data, plus simulation outputs from separate runs. The codes 
deliver what I need. Good to know the three lines work. Thank you.

On 1/16/2018 8:06 PM, Duncan Murdoch wrote:
> On 16/01/2018 6:33 AM, Steven Yen wrote:
>> Hi all,
>> This is great. Again, here is what I need. I run two separate jobs (a.R
>> and b.R) with results (say regression outputs) going to a.RData and
>> b.RData. I like to put all results in one place (where I can retrieve
>> them in one place, ab.RData). The following codes do it (I am not sure
>> if line 2 is needed but I am happy). Thank you all.
>>
>> load("a.RData")
>> save.image("ab.RData")
>> load("b.RData")
>> save.image("ab.RData")
>
> That's the same as
>
> load("a.RData")
> load("b.RData")
> save.image("ab.RData")
>
> because the second saved image overwrites the first one.? It'll be 
> okay if all the variable names are different in a.RData and b.RData, 
> but will lose values from a.RData if any of them have the same names 
> as objects in b.RData.? See the link I posted earlier to avoid this.
>
> Duncan Murdoch
>
>>
>> On 1/16/2018 7:08 PM, PIKAL Petr wrote:
>>> Huh.
>>>
>>> I may by completely wrong but you cannot do such "merging". .RData 
>>> files are AFAIK places where all objects from given session are stored.
>>>
>>> However you could load each .RData file and save/export result (one 
>>> object).
>>>
>>> BTW, what do you mean exactly by "combine/consolidate"?
>>>
>>> And finally, post your questions in plain text not html, otherwise 
>>> they can be mangled.
>>>
>>> Cheers
>>> Petr
>>>
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
>>>> Steven Yen
>>>> Sent: Tuesday, January 16, 2018 9:44 AM
>>>> To: r-help at r-project.org
>>>> Subject: [R] Merging RData files
>>>>
>>>> I ran two separate hours-long projects. Results of each were saved 
>>>> to two
>>>> separate .RData files.
>>>> Content of each includes, among others, the following:
>>>>
>>>> ????????????????????? me??? se????? t???? p sig pc21.age??????? 
>>>> 0.640 0.219? 2.918 0.004 ***
>>>> pc21.agesq????? 0.000 0.000??? NaN?? NaN pc21.inc 0.903 0.103? 
>>>> 8.752 0.000
>>>> *** pc21.incsq????? 0.000 0.000??? NaN?? NaN
>>>> pc21.sei10????? 0.451 0.145? 3.122 0.002 *** pc21.sblkprot -4.334 
>>>> 3.387? 1.280
>>>> 0.201 ...
>>>>
>>>> Question: How can I combine/consolidate the two .RData files into one?
>>>> Thank you.
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> ??????? [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide 
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> ________________________________
>>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a 
>>> jsou ur?eny pouze jeho adres?t?m.
>>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
>>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a 
>>> jeho kopie vyma?te ze sv?ho syst?mu.
>>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento 
>>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou 
>>> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>>>
>>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? 
>>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? 
>>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? 
>>> nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
>>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
>>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za 
>>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? 
>>> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly 
>>> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, 
>>> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m 
>>> zastoupen? zn?m?.
>>>
>>> This e-mail and any documents attached to it may be confidential and 
>>> are intended only for its intended recipients.
>>> If you received this e-mail by mistake, please immediately inform 
>>> its sender. Delete the contents of this e-mail with all attachments 
>>> and its copies from your system.
>>> If you are not the intended recipient of this e-mail, you are not 
>>> authorized to use, disseminate, copy or disclose this e-mail in any 
>>> manner.
>>> The sender of this e-mail shall not be liable for any possible 
>>> damage caused by modifications of the e-mail or by delay with 
>>> transfer of the email.
>>>
>>> In case that this e-mail forms part of business dealings:
>>> - the sender reserves the right to end negotiations about entering 
>>> into a contract in any time, for any reason, and without stating any 
>>> reasoning.
>>> - if the e-mail contains an offer, the recipient is entitled to 
>>> immediately accept such offer; The sender of this e-mail (offer) 
>>> excludes any acceptance of the offer on the part of the recipient 
>>> containing any amendment or variation.
>>> - the sender insists on that the respective contract is concluded 
>>> only upon an express mutual agreement on all its aspects.
>>> - the sender of this e-mail informs that he/she is not authorized to 
>>> enter into any contracts on behalf of the company except for cases 
>>> in which he/she is expressly authorized to do so in writing, and 
>>> such authorization or power of attorney is submitted to the 
>>> recipient or the person represented by the recipient, or the 
>>> existence of such authorization is known to the recipient of the 
>>> person represented by the recipient.
>>
>
>

-- 
styen at ntu.edu.tw (S.T. Yen)


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Jan 16 13:42:11 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 16 Jan 2018 13:42:11 +0100
Subject: [R] Packages couldn't load
In-Reply-To: <CAJ3tmCrfNSBMFXHKZYxex0EWDgV7yFRoo+jSfB4tN-DCXuwZew@mail.gmail.com>
References: <CAJ3tmCrfNSBMFXHKZYxex0EWDgV7yFRoo+jSfB4tN-DCXuwZew@mail.gmail.com>
Message-ID: <CAJuCY5zuMgOwr5DBCLDzJVhpFUeBUpnh9skyZNHL-4GX7vueSA@mail.gmail.com>

You need to make sure that the rJava package is working.

Consider using the readxl package instead of xlsx.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-01-16 13:08 GMT+01:00 Emeka Don <emekadonn at gmail.com>:
> Dear All,
> I have been trying to install Xlsx package in R but  i have been getting
> this error after the installation. Please can anyone help?
>
>> any(grepl("xlsx",installed.packages()))
> [1] TRUE
>> library("xlsx")
> Loading required package: rJava
> Error: package or namespace load failed for ?rJava?:
>  .onLoad failed in loadNamespace() for 'rJava', details:
>   call: fun(libname, pkgname)
>   error: JAVA_HOME cannot be determined from the Registry
> Error: package ?rJava? could not be loaded
> In addition: Warning messages:
> 1: package ?xlsx? was built under R version 3.4.3
> 2: package ?rJava? was built under R version 3.4.3
>
> Thank you
>
> --
> Onyeuwaoma Nnaemeka Dom PhD.
> Scientific Officer.
> Center for Basic Space Science (CBSS)
> National Space Research and Development Agency (NASRDA)
> Federal Ministry of Science and Technology
> University of Nigeria, Nsukka
> P. M. B. 2022, Nsukka, Enugu State, Nigeria.
> +2348032686377, +2347052835685
> email:onyeuwaoma.emeka at cbss.nasrda.gov.ng
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dbars at tecal.udl.cat  Tue Jan 16 13:50:34 2018
From: dbars at tecal.udl.cat (David Bars Cortina)
Date: Tue, 16 Jan 2018 13:50:34 +0100
Subject: [R] Letters group Games-Howell post hoc in R
Message-ID: <0e33806f9e73801f34522c528c307985.squirrel@correu.udl.cat>

Hello everybody,

I use the sweetpotato database included in R package:

data(sweetpotato) This dataset contains two variables: yield(continous
variable) and virus(factor variable).

Due to Levene test is significant I cannot assume homogeneity of variances
and I apply Welch test in R instead of one-way ANOVA followed by Tukey
posthoc.

Nevertheless, the problems come from when I apply posthoc test. In Tukey
posthoc test I use library(agricolae) and displays me the superscript
letters between virus groups. Therefore there are no problems.

Nevertheless, to perform Games-Howell posthoc, I use
library(userfriendlyscience) and I obtain Games-Howell output but it's
impossible for me to obtain a letter superscript comparison between virus
groups as it is obtained through library(agricolae).

The code used it was the following:

library(userfriendlyscience)

data(sweetpotato)

oneway<-oneway(sweetpotato$virus, y=sweetpotato$yield, posthoc =
'games-howell')

oneway

I try with cld() importing previously library(multcompView) but doesn't work.

Can somebody could helps me?

Thanks in advance,

David Bars.


From murdoch.duncan at gmail.com  Tue Jan 16 15:36:55 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 16 Jan 2018 09:36:55 -0500
Subject: [R] Merging RData files
In-Reply-To: <9cfa2848-7b1b-4a25-29b6-d87c6977d0f1@ntu.edu.tw>
References: <37d117f5-6fa9-e1dc-4baf-0a45bc2b8810@ntu.edu.tw>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD3D2E@SRVEXCHCM301.precheza.cz>
 <97d0b576-4858-7159-4f85-c5c93ee2154c@ntu.edu.tw>
 <9378a346-f1bd-f5bb-8de6-16f85b6610ca@gmail.com>
 <9cfa2848-7b1b-4a25-29b6-d87c6977d0f1@ntu.edu.tw>
Message-ID: <08cbcec0-a50c-3cdd-3160-4cc4763d2757@gmail.com>

On 16/01/2018 7:13 AM, Steven Yen wrote:
> Understood. In my case, a.RData and b.RData contain identical 
> variables/data, plus simulation outputs from separate runs. The codes 
> deliver what I need. Good to know the three lines work. Thank you.

You might also want to investigate saveRDS/readRDS.  Those functions are 
similar to save/load, but they only write a single variable and don't 
write variable names, so you can do things like

saveRDS(x, "x.rds")
y <- readRDS("x.rds")

to read the value of x directly into y.

Duncan Murdoch

> 
> On 1/16/2018 8:06 PM, Duncan Murdoch wrote:
>> On 16/01/2018 6:33 AM, Steven Yen wrote:
>>> Hi all,
>>> This is great. Again, here is what I need. I run two separate jobs (a.R
>>> and b.R) with results (say regression outputs) going to a.RData and
>>> b.RData. I like to put all results in one place (where I can retrieve
>>> them in one place, ab.RData). The following codes do it (I am not sure
>>> if line 2 is needed but I am happy). Thank you all.
>>>
>>> load("a.RData")
>>> save.image("ab.RData")
>>> load("b.RData")
>>> save.image("ab.RData")
>>
>> That's the same as
>>
>> load("a.RData")
>> load("b.RData")
>> save.image("ab.RData")
>>
>> because the second saved image overwrites the first one.? It'll be 
>> okay if all the variable names are different in a.RData and b.RData, 
>> but will lose values from a.RData if any of them have the same names 
>> as objects in b.RData.? See the link I posted earlier to avoid this.
>>
>> Duncan Murdoch
>>
>>>
>>> On 1/16/2018 7:08 PM, PIKAL Petr wrote:
>>>> Huh.
>>>>
>>>> I may by completely wrong but you cannot do such "merging". .RData 
>>>> files are AFAIK places where all objects from given session are stored.
>>>>
>>>> However you could load each .RData file and save/export result (one 
>>>> object).
>>>>
>>>> BTW, what do you mean exactly by "combine/consolidate"?
>>>>
>>>> And finally, post your questions in plain text not html, otherwise 
>>>> they can be mangled.
>>>>
>>>> Cheers
>>>> Petr
>>>>
>>>>> -----Original Message-----
>>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
>>>>> Steven Yen
>>>>> Sent: Tuesday, January 16, 2018 9:44 AM
>>>>> To: r-help at r-project.org
>>>>> Subject: [R] Merging RData files
>>>>>
>>>>> I ran two separate hours-long projects. Results of each were saved 
>>>>> to two
>>>>> separate .RData files.
>>>>> Content of each includes, among others, the following:
>>>>>
>>>>> ????????????????????? me??? se????? t???? p sig pc21.age        
>>>>> 0.640 0.219? 2.918 0.004 ***
>>>>> pc21.agesq????? 0.000 0.000??? NaN?? NaN pc21.inc 0.903 0.103  
>>>>> 8.752 0.000
>>>>> *** pc21.incsq????? 0.000 0.000??? NaN?? NaN
>>>>> pc21.sei10????? 0.451 0.145? 3.122 0.002 *** pc21.sblkprot -4.334 
>>>>> 3.387? 1.280
>>>>> 0.201 ...
>>>>>
>>>>> Question: How can I combine/consolidate the two .RData files into one?
>>>>> Thank you.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> ??????? [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide 
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> ________________________________
>>>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a 
>>>> jsou ur?eny pouze jeho adres?t?m.
>>>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
>>>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a 
>>>> jeho kopie vyma?te ze sv?ho syst?mu.
>>>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento 
>>>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou 
>>>> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>>>>
>>>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? 
>>>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? 
>>>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? 
>>>> nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
>>>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
>>>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za 
>>>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? 
>>>> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly 
>>>> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, 
>>>> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m 
>>>> zastoupen? zn?m?.
>>>>
>>>> This e-mail and any documents attached to it may be confidential and 
>>>> are intended only for its intended recipients.
>>>> If you received this e-mail by mistake, please immediately inform 
>>>> its sender. Delete the contents of this e-mail with all attachments 
>>>> and its copies from your system.
>>>> If you are not the intended recipient of this e-mail, you are not 
>>>> authorized to use, disseminate, copy or disclose this e-mail in any 
>>>> manner.
>>>> The sender of this e-mail shall not be liable for any possible 
>>>> damage caused by modifications of the e-mail or by delay with 
>>>> transfer of the email.
>>>>
>>>> In case that this e-mail forms part of business dealings:
>>>> - the sender reserves the right to end negotiations about entering 
>>>> into a contract in any time, for any reason, and without stating any 
>>>> reasoning.
>>>> - if the e-mail contains an offer, the recipient is entitled to 
>>>> immediately accept such offer; The sender of this e-mail (offer) 
>>>> excludes any acceptance of the offer on the part of the recipient 
>>>> containing any amendment or variation.
>>>> - the sender insists on that the respective contract is concluded 
>>>> only upon an express mutual agreement on all its aspects.
>>>> - the sender of this e-mail informs that he/she is not authorized to 
>>>> enter into any contracts on behalf of the company except for cases 
>>>> in which he/she is expressly authorized to do so in writing, and 
>>>> such authorization or power of attorney is submitted to the 
>>>> recipient or the person represented by the recipient, or the 
>>>> existence of such authorization is known to the recipient of the 
>>>> person represented by the recipient.
>>>
>>
>>
> 
> -- 
> styen at ntu.edu.tw  (S.T. Yen)
>


From paul.bivand at gmail.com  Tue Jan 16 15:58:04 2018
From: paul.bivand at gmail.com (Paul Bivand)
Date: Tue, 16 Jan 2018 14:58:04 +0000
Subject: [R] Information installation package sjPlot
In-Reply-To: <CAF4WX-dVwyBd5tQEDKOuGZswiYyWEY8+4YCbyG86fbeH4ZWTwQ@mail.gmail.com>
References: <CWXP265MB0216F34FD9C21931FD0C1133F6110@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>
 <CAF4WX-dVwyBd5tQEDKOuGZswiYyWEY8+4YCbyG86fbeH4ZWTwQ@mail.gmail.com>
Message-ID: <CAC=KSNjU9rM3pv7GyULycFEPyoa=wyE9xDe5C3-s60hYQyW-9g@mail.gmail.com>

This depends on the resources of your computer. If it's very small,
some dependencies can take a long time.

My record is the glmmTMB dependency with over 24 hours compilation (on
an old netbook).

One helpful way round can be to download the .tar.gz of the package,
close down all other programs, and run R CMD install package.tar.gz
from the command line.

Paul

On 11 January 2018 at 23:21, Orvalho Augusto <orvaquim at gmail.com> wrote:
> That is very strange.
>
> I am using Ubuntu 16.04 and managed to install it in less than 5 minutes.
>
> OA
>
> On Wed, Jan 10, 2018 at 12:00 PM, Luca Danieli <mr.lucedan at hotmail.it>
> wrote:
>
>> Hi all,
>>
>> I am new. I am installing the library sjPlot on Ubunto 16.10 and I guess
>> it is installing some dependencies. But it is taking more than 1.5 hours,
>> is it possible?
>>
>> It has right now halted (hope momentarily) in installing the package
>> 'rstan', particularly the file lang__grammars__statement_grammar_inst.o
>>
>> Other packages installed include: dygraphs, colourpicker, raster.
>>
>> Is it good or is something going wrong?
>>
>> Luca
>>
>> Get Outlook for Android<https://aka.ms/ghei36>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Jan 16 16:30:18 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 16 Jan 2018 07:30:18 -0800
Subject: [R] Merging RData files
In-Reply-To: <37d117f5-6fa9-e1dc-4baf-0a45bc2b8810@ntu.edu.tw>
References: <37d117f5-6fa9-e1dc-4baf-0a45bc2b8810@ntu.edu.tw>
Message-ID: <CAGxFJbRNTdn1uX8q=0p+ckU1fDyb4ATy2aEdYouaLNAq4UkKBQ@mail.gmail.com>

?load

Read this carefully. Pay attention to its instructions re: overwriting
existing objects.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Jan 16, 2018 at 12:43 AM, Steven Yen <styen at ntu.edu.tw> wrote:

> I ran two separate hours-long projects. Results of each were saved to
> two separate .RData files.
> Content of each includes, among others, the following:
>
>                     me    se      t     p sig
> pc21.age        0.640 0.219  2.918 0.004 ***
> pc21.agesq      0.000 0.000    NaN   NaN
> pc21.inc        0.903 0.103  8.752 0.000 ***
> pc21.incsq      0.000 0.000    NaN   NaN
> pc21.sei10      0.451 0.145  3.122 0.002 ***
> pc21.sblkprot  -4.334 3.387  1.280 0.201
> ...
>
> Question: How can I combine/consolidate the two .RData files into one?
> Thank you.
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Bernhard.Treutwein at Verwaltung.Uni-Muenchen.DE  Tue Jan 16 16:36:45 2018
From: Bernhard.Treutwein at Verwaltung.Uni-Muenchen.DE (Treutwein Bernhard)
Date: Tue, 16 Jan 2018 15:36:45 +0000
Subject: [R] flatpak installation package?
Message-ID: <78A8BD6765DCF048A628A51C3FBD1D76599868AF@MXS2.zuv.uni-muenchen.de>

Is there any chance for a distribution independent flatpak installation package for R ?

See: http://flatpak.org 

Background: I recently bought an Acer notebook with endless OS preinstalled
(see: http://endlessos.com).  It is Debian based, but uses only flatpak as installation
package format.

regards
--
? Bernhard Treutwein


From jdnewmil at dcn.davis.ca.us  Tue Jan 16 18:13:02 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 16 Jan 2018 09:13:02 -0800
Subject: [R] flatpak installation package?
In-Reply-To: <78A8BD6765DCF048A628A51C3FBD1D76599868AF@MXS2.zuv.uni-muenchen.de>
References: <78A8BD6765DCF048A628A51C3FBD1D76599868AF@MXS2.zuv.uni-muenchen.de>
Message-ID: <7F250778-AC85-44E1-90AC-E7AFF2FE0946@dcn.davis.ca.us>

Of course... R _is_ open source. However, it is unwise to assume that the volunteers scratching itches for their preferred distros will take on additional work... it is more likely that you will need to take on scratching that new itch.
-- 
Sent from my phone. Please excuse my brevity.

On January 16, 2018 7:36:45 AM PST, Treutwein Bernhard <Bernhard.Treutwein at Verwaltung.Uni-Muenchen.DE> wrote:
>Is there any chance for a distribution independent flatpak installation
>package for R ?
>
>See: http://flatpak.org 
>
>Background: I recently bought an Acer notebook with endless OS
>preinstalled
>(see: http://endlessos.com).  It is Debian based, but uses only flatpak
>as installation
>package format.
>
>regards
>--
>? Bernhard Treutwein
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kenneth at kidscodejeunesse.org  Tue Jan 16 18:21:25 2018
From: kenneth at kidscodejeunesse.org (kenneth dyson)
Date: Tue, 16 Jan 2018 12:21:25 -0500
Subject: [R] barplot that displays sums of values of 2 y colums grouped
 by different variables
In-Reply-To: <alpine.BSF.2.00.1801151423480.52972@pedal.dcn.davis.ca.us>
References: <edf301d9-4327-327a-d613-c063ab0d55af@kidscodejeunesse.org>
 <alpine.BSF.2.00.1801151423480.52972@pedal.dcn.davis.ca.us>
Message-ID: <d0e163eb-0313-9242-4ba8-d0e0f100c2f8@kidscodejeunesse.org>

Thanks everyone.

Got it to work like this, if anyone is interested:

import the data with readr, taking in only the columns that have numeric 
values ("n" and "y") and the column with the groups ("city").

aggregate the data by the group ("city") so that each variable has a sum:

|sum_data <-aggregate(.~City__c,data=raw_data,sum)|

reshape the data so that the groups are now variables (there will be 3 
columns: "city", "variable", "value"):

|library(reshape2)library(ggplot2)sums <-melt(sum_data)|

plot using ggplot:

|ggplot(sums,aes(x =city,y=value,fill =variable,ymax 
=1000))+geom_bar(stat="identity",width=.8,position ="dodge")|


On 2018-01-15 6:01 PM, Jeff Newmiller wrote:
> It is not generally advisable to get too fancy with stat functions in 
> ggplot... things can easily get more complicated than ggplot is ready 
> to handle when it comes to calculations. It is better to create data 
> that corresponds directly to the graphical representations you are 
> mapping them to.
>
> Read [1] for more on this philosophy.
>
> [1] H. Wickham, Tidy Data, Journal of Statistical Software, vol. 59, 
> no. 10, pp. 123, Sep. 2014. http://www.jstatsoft.org/v59/i10/
>
> #---
> library(ggplot2) # ggplot
> library(dplyr)?? # `%>%`, group_by, summarise
> #> Attaching package: 'dplyr'
> #> The following objects are masked from 'package:stats':
> #>
> #>???? filter, lag
> #> The following objects are masked from 'package:base':
> #>
> #>???? intersect, setdiff, setequal, union
> library(tidyr)?? # gather
>
> dta <- read.table( text =
> "city n y
> mon 100 200
> tor 209 300
> edm 98 87
> mon 20 76
> tor 50 96
> edm 62 27
> ", header = TRUE )
>
> dta2 <- (?? dta
> ??????? %>% group_by( city )
> ??????? %>% summarise( n = sum( n )
> ???????????????????? , y = sum( y )
> ???????????????????? )
> ??????? %>% gather( Response, value, -city )
> ??????? )
>
> ggplot( dta2, aes( x=city, y=value, fill = Response ) ) +
> ??? geom_bar( stat="identity", position="dodge" )
>
> #' ![](https://i.imgur.com/cosFf3B.png)
> #---
>
> On Mon, 15 Jan 2018, kenneth dyson wrote:
>
>> I am trying to create a barplot displaying the sums of 2 columns of 
>> data grouped by a variable. the data is set up like this:
>>
>> "city" "n" "y" <br>
>> mon 100 200 <br>
>> tor 209 300 <br>
>> edm 98 87 <br>
>> mon 20 76 <br>
>> tor 50 96 <br>
>> edm 62 27 <br>
>>
>> the resulting plot should have city as the x-axis, 2 bars per city, 1 
>> representing the sum of "n" in that city, the other the sum of "y" in 
>> that city.
>>
>> If possible also show the sum in each bar as a label?
>>
>> I aggregated the data into sums like this:
>>
>> sum_data <- aggregate(. ~ City,data=raw_data,sum)
>>
>> this gave me the sums per city as I wanted but for some reason 1 of 
>> the cities is missing in the output.
>>
>> Using this code for the plot:
>>
>> ggplot(sum_data,aes(x = City,y = n)) + geom_bar(aes(fill = y),stat = 
>> "identity",position = "dodge")
>>
>> gave be a bar plot with one bar per city showing the sum of y as a 
>> color gradient. not what I expected given the "dodge" command in 
>> geom_bar.
>>
>> Thanks.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --------------------------------------------------------------------------- 
>
> Jeff Newmiller??????????????????????? The???? .....?????? ..... Go 
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>??????? Basics: ##.#. ##.#.? Live Go...
> ????????????????????????????????????? Live:?? OO#.. Dead: OO#.. Playing
> Research Engineer (Solar/Batteries??????????? O.O#.?????? #.O#. with
> /Software/Embedded Controllers)?????????????? .OO#.?????? .OO#. 
> rocks...1k
> --------------------------------------------------------------------------- 
>


	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Tue Jan 16 19:57:15 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Tue, 16 Jan 2018 10:57:15 -0800
Subject: [R] Merging RData files
In-Reply-To: <CAGxFJbRNTdn1uX8q=0p+ckU1fDyb4ATy2aEdYouaLNAq4UkKBQ@mail.gmail.com>
References: <37d117f5-6fa9-e1dc-4baf-0a45bc2b8810@ntu.edu.tw>
 <CAGxFJbRNTdn1uX8q=0p+ckU1fDyb4ATy2aEdYouaLNAq4UkKBQ@mail.gmail.com>
Message-ID: <CAFDcVCQsCx-sF9vawTLS1TPzpEyFygu-1g7OGu9deU+oYxSosg@mail.gmail.com>

To expand on what Bert suggests.  Use:

loadToEnv <- function(file, ..., envir = new.env()) {
  base::load(file = file, envir = envir, ...)
}

envA <- loadToEnv("a.RData")
envB <- loadToEnv("b.RData")

and then access the objects in environments envA and envB using
environment access methods, e.g. ls(envir = envA), envA[[name]],
envA$foo, as.list(envA) [careful is large objects], ...

/H

On Tue, Jan 16, 2018 at 7:30 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> ?load
>
> Read this carefully. Pay attention to its instructions re: overwriting
> existing objects.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Tue, Jan 16, 2018 at 12:43 AM, Steven Yen <styen at ntu.edu.tw> wrote:
>
>> I ran two separate hours-long projects. Results of each were saved to
>> two separate .RData files.
>> Content of each includes, among others, the following:
>>
>>                     me    se      t     p sig
>> pc21.age        0.640 0.219  2.918 0.004 ***
>> pc21.agesq      0.000 0.000    NaN   NaN
>> pc21.inc        0.903 0.103  8.752 0.000 ***
>> pc21.incsq      0.000 0.000    NaN   NaN
>> pc21.sei10      0.451 0.145  3.122 0.002 ***
>> pc21.sblkprot  -4.334 3.387  1.280 0.201
>> ...
>>
>> Question: How can I combine/consolidate the two .RData files into one?
>> Thank you.
>>
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Tue Jan 16 20:29:33 2018
From: chocold12 at gmail.com (lily li)
Date: Tue, 16 Jan 2018 12:29:33 -0700
Subject: [R] Steps to create spatial plots
In-Reply-To: <CAGgJW76040LC6H5y4bA1kL6OXMOS=Jm69KqcZpewkovYVG64_Q@mail.gmail.com>
References: <CAN5afy94sJGUFuQ+byRwLuA0Ayg+moHd8J1BoRuOpBNqbtZPmA@mail.gmail.com>
 <CAHT1vpgtC+p2QSKvPvcKUaBN0KPsBt-Jdr-zh6gEZ_K1Kd9AhA@mail.gmail.com>
 <CAN5afy9duc=hbddSaKM3su9tBam5zjZM7h3Ea85Lk7Gb7XoE3w@mail.gmail.com>
 <CAGxFJbSbPZ76RS34B44Kj5hCkfqC+m3Kq5XEOia=gA-ibNzXCg@mail.gmail.com>
 <CAN5afy_MtiNPwo2YUb0C+ieSp0NO55Pmrtcs3D=OjNY0BYjdRw@mail.gmail.com>
 <CAN5afy-BDLPYYSKeZ6-qb0E+faeU1MdSWu6M0M5rchS2buhd9w@mail.gmail.com>
 <CAGgJW76040LC6H5y4bA1kL6OXMOS=Jm69KqcZpewkovYVG64_Q@mail.gmail.com>
Message-ID: <CAN5afy9s9s6yj1fQV-kWkojpAAcNaU9AgazYuv-oXd-TpuPArA@mail.gmail.com>

Hi Eric,

Thanks, it works. If I want to convert the matrix to the 1-D vector for the
levelplot, should I use the command below? I thought the t() is a reverse
function, but may be not.

values <- layer$z
values.v <- as.vector(t(values))

On Tue, Jan 16, 2018 at 12:36 AM, Eric Berger <ericjberger at gmail.com> wrote:

> If layer$z is a matrix and you want to reverse the order of the rows, you
> can do:
>
> n <- nrow(layer$z)
> layer$z <- layer$z[ n:1, ]
>
> HTH,
> Eric
>
>
> On Tue, Jan 16, 2018 at 8:43 AM, lily li <chocold12 at gmail.com> wrote:
>
>> Sorry for the emails, I just wanted to have an example.
>> layer$z
>>
>> 1  1  3  4  6  2
>> 2  3  4  1  2  9
>> 1  4  5  2  1  8
>>
>> How to convert the matrix to layer$z = c(1, 4, 5, 2, 1, 8, 2, 3, 4, 1, 2,
>> 9, 1, 1, 3, 4, 6, 2)?
>> I think this vector is the order that levelplot can use. Thanks again.
>>
>>
>> On Mon, Jan 15, 2018 at 10:58 PM, lily li <chocold12 at gmail.com> wrote:
>>
>> > Hi Bert,
>> >
>> > I think you are correct that I can use levelplot, but I have a question
>> > about converting data. For example, the statement:
>> > levelplot(Z~X*Y), Z is row-wise from the lower left corner to the upper
>> > right corner.
>> > My dataset just have gridded Z data as a txt file (or can be called
>> > matrix?), how to convert them to the vector in order for levelplot to
>> use?
>> > Thanks.
>> >
>> > On Mon, Jan 15, 2018 at 6:04 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> > wrote:
>> >
>> >> From your description, I am **guessing** that you may not want a
>> "spatial
>> >> map" (including projections) at all, but rather something like a level
>> >> plot. See ?levelplot in the lattice package for details. Both I am sure
>> >> ggplot2 has something similar.
>> >>
>> >> Apologies if I havemisunderstood your intent/specifications.
>> >>
>> >> Cheers,
>> >> Bert
>> >>
>> >>
>> >> Bert Gunter
>> >>
>> >> "The trouble with having an open mind is that people keep coming along
>> >> and sticking things into it."
>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>
>> >> On Mon, Jan 15, 2018 at 4:54 PM, lily li <chocold12 at gmail.com> wrote:
>> >>
>> >>> Hi Roman,
>> >>>
>> >>> Thanks for your reply. For the spatial coordinates layer, I just have
>> >>> coordinates of the upper left corner, numbers of rows and columns of
>> the
>> >>> spatial map, and grid cell size. How to create a spatial layer of
>> >>> coordinates from this data? Thanks.
>> >>>
>> >>>
>> >>> On Mon, Jan 15, 2018 at 3:26 PM, Roman Lu?trik <
>> roman.lustrik at gmail.com>
>> >>> wrote:
>> >>>
>> >>> > You will need to coerce your data into a "spatial" kind, as
>> >>> implemented in
>> >>> > `sp` or as of late, `sf` packages. You might want to give the
>> >>> vignettes a
>> >>> > whirl before you proceed.
>> >>> > Roughly, you will have to coerce the data to Spatial* (you could go
>> >>> for a
>> >>> > point, raster or grid type, I think) and also specify the
>> projection.
>> >>> Once
>> >>> > you have that, plotting should be handled by packages.
>> >>> >
>> >>> > Here are a few quick links that might come handy:
>> >>> >
>> >>> > https://cran.r-project.org/web/views/Spatial.html
>> >>> > http://www.datacarpentry.org/R-spatial-raster-vector-
>> >>> > lesson/10-vector-csv-to-shapefile-in-r/
>> >>> >
>> >>> >
>> >>> > Cheers,
>> >>> > Roman
>> >>> >
>> >>> > On Mon, Jan 15, 2018 at 11:22 PM, lily li <chocold12 at gmail.com>
>> wrote:
>> >>> >
>> >>> >> Hi users,
>> >>> >>
>> >>> >> I have no clear clue about plotting spatial data. For example, I
>> just
>> >>> >> have a table with attribute values of each grid cell, such as
>> >>> elevation.
>> >>> >> Then I have coordinates of the upper left corner in UTM, the number
>> >>> of rows
>> >>> >> and columns, and grid cell size. How to create spatial plot of
>> >>> elevations
>> >>> >> for the grid cells, in color ramp? Should I create a spatial grid
>> >>> layer
>> >>> >> with all the polygons first? Thanks.
>> >>> >>
>> >>> >> --
>> >>> >> --
>> >>> >> You received this message because you are subscribed to the ggplot2
>> >>> >> mailing list.
>> >>> >> Please provide a reproducible example:
>> https://github.com/hadley/devt
>> >>> >> ools/wiki/Reproducibility
>> >>> >>
>> >>> >> To post: email ggplot2 at googlegroups.com
>> >>> >> To unsubscribe: email ggplot2+unsubscribe at googlegroups.com
>> >>> >> More options: http://groups.google.com/group/ggplot2
>> >>> >>
>> >>> >> ---
>> >>> >> You received this message because you are subscribed to the Google
>> >>> Groups
>> >>> >> "ggplot2" group.
>> >>> >> To unsubscribe from this group and stop receiving emails from it,
>> >>> send an
>> >>> >> email to ggplot2+unsubscribe at googlegroups.com.
>> >>> >> For more options, visit https://groups.google.com/d/optout.
>> >>> >>
>> >>> >
>> >>> >
>> >>> >
>> >>> > --
>> >>> > In God we trust, all others bring data.
>> >>> >
>> >>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide http://www.R-project.org/posti
>> >>> ng-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>>
>> >>
>> >>
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From sachakouk at yahoo.fr  Tue Jan 16 23:02:34 2018
From: sachakouk at yahoo.fr (said chakouk)
Date: Tue, 16 Jan 2018 22:02:34 +0000
Subject: [R] Help
Message-ID: <0100B7E9-2DD9-45EE-840C-415553C06F11@yahoo.fr>

Hi
I try ? Iramuteq ? and when I?ll like ? methode reinert ? I have this message
 
Erreur R
Loading required package: Matrix
There were 50 or more warnings (use warnings() to see the first 50)
There were 50 or more warnings (use warnings() to see the first 50)
Error in Ntip + Nnode : non-numeric argument to binary operator
Calls: plot.dendropr -> plot.phylo
Execution halted
1
None
Loading required package: Matrix
There were 50 or more warnings (use warnings() to see the first 50)
There were 50 or more warnings (use warnings() to see the first 50)
Error in Ntip + Nnode : non-numeric argument to binary operator
Calls: plot.dendropr -> plot.phylo
Execution halted
Can you help methinks
	[[alternative HTML version deleted]]


From Gerrit.Eichner at math.uni-giessen.de  Wed Jan 17 10:55:40 2018
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 17 Jan 2018 10:55:40 +0100
Subject: [R]  effects: error when original data frame is missing
Message-ID: <2c2dee47-0163-ae05-e1dc-29c30d12e30c@math.uni-giessen.de>

Hello, everyody,

when asking, e.g., Effect() to compute the effects of a fitted,
e.g., linear model after having deleted the data frame from the
workspace for which the model was obtained an error is reported:

 > myair <- airquality
 > fm <- lm(Ozone ~ Temp, data = myair)
 > rm(myair)
 > Effect("Temp", fm)
Error in eval(model$call$data, envir) : object 'myair' not found

Has anybody a better "workaround" for this than, e.g., explicitly
saving the fitted model object fm together with its original
environment or just the data needed frame (maybe in a list like
fm.plus.origdata <- list(fm, myair = myair)) to be able to restore
the original environemt (or at least the needed opriginal data
frame) of the time when fm was created?

Thx for any hint!

  Regards  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner


From mrguilfoyle at gmail.com  Wed Jan 17 11:25:39 2018
From: mrguilfoyle at gmail.com (Mathew Guilfoyle)
Date: Wed, 17 Jan 2018 10:25:39 +0000
Subject: [R] mgcv::gam is it possible to have a 'simple' product of 1-d
	smooths?
Message-ID: <5A975B1E-CCE2-4E1E-932C-26163922F945@gmail.com>

I am trying to test out several mgcv::gam models in a scalar-on-function regression analysis.

The following is the 'hierarchy' of models I would like to test:

(1)  Y_i = a + integral[ X_i(t)*Beta(t) dt ]

(2)  Y_i = a + integral[ F{X_i(t)}*Beta(t) dt ]

(3)  Y_i = a + integral[ F{X_i(t),t} dt ]

equivalents for discrete data might be:

1)  Y_i = a + sum_t[ L_t * X_it * Beta_t ]

(2)  Y_i = a + sum_t[ L_t * F{X_it} * Beta_t ]

(3)  Y_i = a + sum_t[ L_t * F{X_it,t} ]

where Y_i are scalar outcomes for the i-th subject, and X_i(t) is a functional covariate observed at times t in [0,1,...T], and L are the quadrature weights.  Beta() and/or F{} are the functions to be estimated.   Intuitively, model 1 is a linear functional model with a (potentially non-linear) time-dependent regression coefficient (beta()) for the covariate.  Model 2 allows for a non-linear function of the covariate (F{}), but which is constant over time.  Model 3 is the full 'functional GAM' that allows for a fully flexible non-linear covariate- and time- dependent function.  

In my mind at least these would seem to form a natural step-by-step approach of increasing complexity for exploring this type of regression model.

Models 1 (linear functional) and 3 (functional GAM) are relatively straightforward to do with matrix arguments to mgcv::gam.  Assume N subjects observed at T time points.  Y is the length-N vector of scalar outcomes and X, T, and W are the N*T matrices of the functional predictor data values, their observation times, and trapezoidal quadrature weights, respectively.

Models (1) and (3) could be obtained with:

    m1 = gam(Y ~ s(T, by=I(X*W), bs='ps')
    m3 = gam(Y ~ te(X, T, by=W), bs='ps')

However, I cannot find a way to achieve model (2) where there is a 'simple' product of the smooth functions of X and T.  Effectively what I need (I think) is a way of creating a `te()` tensor product smooth but somehow constraining each marginal smooth to be the same for all values of the other variable?  Is this possible?

From mrguilfoyle at gmail.com  Wed Jan 17 11:28:12 2018
From: mrguilfoyle at gmail.com (Mathew Guilfoyle)
Date: Wed, 17 Jan 2018 10:28:12 +0000
Subject: [R] mgcv::gam is it possible to have a 'simple' product of 1-d
	smooths?
References: <5A975B1E-CCE2-4E1E-932C-26163922F945@gmail.com>
Message-ID: <A71DDF5D-CE7D-40BF-8DF7-36B689FE8372@gmail.com>

I am trying to test out several mgcv::gam models in a scalar-on-function regression analysis.

The following is the 'hierarchy' of models I would like to test:

(1)  Y_i = a + integral[ X_i(t)*Beta(t) dt ]

(2)  Y_i = a + integral[ F{X_i(t)}*Beta(t) dt ]

(3)  Y_i = a + integral[ F{X_i(t),t} dt ]

equivalents for discrete data might be:

1)  Y_i = a + sum_t[ L_t * X_it * Beta_t ]

(2)  Y_i = a + sum_t[ L_t * F{X_it} * Beta_t ]

(3)  Y_i = a + sum_t[ L_t * F{X_it,t} ]

where Y_i are scalar outcomes for the i-th subject, and X_i(t) is a functional covariate observed at times t in [0,1,...T], and L are the quadrature weights.  Beta() and/or F{} are the functions to be estimated.   Intuitively, model 1 is a linear functional model with a (potentially non-linear) time-dependent regression coefficient (beta()) for the covariate.  Model 2 allows for a non-linear function of the covariate (F{}), but which is constant over time.  Model 3 is the full 'functional GAM' that allows for a fully flexible non-linear covariate- and time- dependent function.  

In my mind at least these would seem to form a natural step-by-step approach of increasing complexity for exploring this type of regression model.

Models 1 (linear functional) and 3 (functional GAM) are relatively straightforward to do with matrix arguments to mgcv::gam.  Assume N subjects observed at T time points.  Y is the length-N vector of scalar outcomes and X, T, and W are the N*T matrices of the functional predictor data values, their observation times, and trapezoidal quadrature weights, respectively.

Models (1) and (3) could be obtained with:

   m1 = gam(Y ~ s(T, by=I(X*W), bs='ps')
   m3 = gam(Y ~ te(X, T, by=W), bs='ps')

However, I cannot find a way to achieve model (2) where there is a 'simple' product of the smooth functions of X and T.  Effectively what I need (I think) is a way of creating a `te()` tensor product smooth but somehow constraining each marginal smooth to be the same for all values of the other variable?  Is this possible?


From ericjberger at gmail.com  Wed Jan 17 13:56:02 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 17 Jan 2018 14:56:02 +0200
Subject: [R] Split charts with ggplot2, tidyquant
Message-ID: <CAGgJW75+6zyVfdLRpvWUP2VaimxFe2PnhF5VT1qfYHsQfEBEWw@mail.gmail.com>

A very common chart in the financial markets is a split chart with two time
series shown in two vertically stacked sub-charts.
A classic case would be the top panel showing the time series of historical
prices of some stock, and the bottom
panel showing the volume traded per day immediately below it. The common
x-axis is the dates of the time period covered.

I would like to create such a standard plot using ggplot2. How does one do
it?
The goals of the tidyquant package would seem to include the easy creation
of such a chart, but I could not find this in tidyquant.

Suppose it were possible to easily create such a chart in ggplot2 (or
tidyquant which uses ggplot2.)
Then with such data for numerous stocks (or other financial instruments)
one could see a grid of such charts by faceting with respect to the stock.

Thanks for any help,

Eric

	[[alternative HTML version deleted]]


From traxplayer at gmail.com  Wed Jan 17 14:16:35 2018
From: traxplayer at gmail.com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Wed, 17 Jan 2018 14:16:35 +0100
Subject: [R] roxygen2 error - x$tag operator is invalid for atomic vectors
Message-ID: <CAGAA5bcKSAu25B9gp9nNmFmE+OkL_-O-Y6Kiwef5ch3cQK42mg@mail.gmail.com>

Hi,

  I am trying to create my first R package.
  I will later today put the files on Github.

  However I gets this error and I can't find any reason for it:

R> roxygen2::roxygenise()
First time using roxygen2. Upgrading automatically...
Error in x$tag : $ operator is invalid for atomic vectors
R>

  Any ideas?

Regards
Martin M. S. Pedersen

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Wed Jan 17 14:30:02 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 17 Jan 2018 15:30:02 +0200
Subject: [R] roxygen2 error - x$tag operator is invalid for atomic
	vectors
In-Reply-To: <CAGAA5bcKSAu25B9gp9nNmFmE+OkL_-O-Y6Kiwef5ch3cQK42mg@mail.gmail.com>
References: <CAGAA5bcKSAu25B9gp9nNmFmE+OkL_-O-Y6Kiwef5ch3cQK42mg@mail.gmail.com>
Message-ID: <CAGgJW76C6kzhtJkwcVU0HKV+nenN+dMXT0wSbb85xDO1XJ93Pg@mail.gmail.com>

This is an error message from R.
For example, if you give the following R commands
>  a <- 5
> a$foo
This will generate the error message:
Error in a$foo : $ operator is invalid for atomic vectors

So you can search for the string 'x$tag' in your code (or possibly in the
package).

HTH,
Eric


On Wed, Jan 17, 2018 at 3:16 PM, Martin M?ller Skarbiniks Pedersen <
traxplayer at gmail.com> wrote:

> Hi,
>
>   I am trying to create my first R package.
>   I will later today put the files on Github.
>
>   However I gets this error and I can't find any reason for it:
>
> R> roxygen2::roxygenise()
> First time using roxygen2. Upgrading automatically...
> Error in x$tag : $ operator is invalid for atomic vectors
> R>
>
>   Any ideas?
>
> Regards
> Martin M. S. Pedersen
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Wed Jan 17 14:32:46 2018
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 17 Jan 2018 08:32:46 -0500
Subject: [R] roxygen2 error - x$tag operator is invalid for atomic
	vectors
In-Reply-To: <CAGAA5bcKSAu25B9gp9nNmFmE+OkL_-O-Y6Kiwef5ch3cQK42mg@mail.gmail.com>
References: <CAGAA5bcKSAu25B9gp9nNmFmE+OkL_-O-Y6Kiwef5ch3cQK42mg@mail.gmail.com>
Message-ID: <803014B9-0ADA-474A-AAEB-C74A8C9970CF@bigelow.org>

Hi,

It's not really a roxygen thing but a subsetting thing.

> x = c(foo = 7, tag = 8)
> x$tag
Error in x$tag : $ operator is invalid for atomic vectors

For simple vectors you want ...

> x['tag']
tag 
  8 

... or ...

> x[['tag']]
[1] 8


See more at 

> ?`$`


Cheers,
Ben
> On Jan 17, 2018, at 8:16 AM, Martin M?ller Skarbiniks Pedersen <traxplayer at gmail.com> wrote:
> 
> Hi,
> 
>  I am trying to create my first R package.
>  I will later today put the files on Github.
> 
>  However I gets this error and I can't find any reason for it:
> 
> R> roxygen2::roxygenise()
> First time using roxygen2. Upgrading automatically...
> Error in x$tag : $ operator is invalid for atomic vectors
> R>
> 
>  Any ideas?
> 
> Regards
> Martin M. S. Pedersen
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecocast Reports: http://seascapemodeling.org/ecocast.html
Tick Reports: https://report.bigelow.org/tick/
Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/




	[[alternative HTML version deleted]]


From traxplayer at gmail.com  Wed Jan 17 14:37:06 2018
From: traxplayer at gmail.com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Wed, 17 Jan 2018 14:37:06 +0100
Subject: [R] roxygen2 error - x$tag operator is invalid for atomic
	vectors
In-Reply-To: <CAGgJW76C6kzhtJkwcVU0HKV+nenN+dMXT0wSbb85xDO1XJ93Pg@mail.gmail.com>
References: <CAGAA5bcKSAu25B9gp9nNmFmE+OkL_-O-Y6Kiwef5ch3cQK42mg@mail.gmail.com>
 <CAGgJW76C6kzhtJkwcVU0HKV+nenN+dMXT0wSbb85xDO1XJ93Pg@mail.gmail.com>
Message-ID: <CAGAA5beEUWFNnanYADbnxsnNjF3AhvKxUn2WKPWM37XEZ-ceBA@mail.gmail.com>

On 17 January 2018 at 14:30, Eric Berger <ericjberger at gmail.com> wrote:

> This is an error message from R.
> For example, if you give the following R commands
> >  a <- 5
> > a$foo
> This will generate the error message:
> Error in a$foo : $ operator is invalid for atomic vectors
>
> So you can search for the string 'x$tag' in your code (or possibly in the
> package).
>

OK thanks.

Something else must be wrong because my package should only contain a
data.frame saved in .RData file

Regards
Martin

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Jan 17 14:53:19 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 17 Jan 2018 08:53:19 -0500
Subject: [R] roxygen2 error - x$tag operator is invalid for atomic
	vectors
In-Reply-To: <CAGAA5beEUWFNnanYADbnxsnNjF3AhvKxUn2WKPWM37XEZ-ceBA@mail.gmail.com>
References: <CAGAA5bcKSAu25B9gp9nNmFmE+OkL_-O-Y6Kiwef5ch3cQK42mg@mail.gmail.com>
 <CAGgJW76C6kzhtJkwcVU0HKV+nenN+dMXT0wSbb85xDO1XJ93Pg@mail.gmail.com>
 <CAGAA5beEUWFNnanYADbnxsnNjF3AhvKxUn2WKPWM37XEZ-ceBA@mail.gmail.com>
Message-ID: <3d865aa9-f29d-e007-2374-9ed13e83e2fa@gmail.com>

On 17/01/2018 8:37 AM, Martin M?ller Skarbiniks Pedersen wrote:
> On 17 January 2018 at 14:30, Eric Berger <ericjberger at gmail.com> wrote:
> 
>> This is an error message from R.
>> For example, if you give the following R commands
>>>   a <- 5
>>> a$foo
>> This will generate the error message:
>> Error in a$foo : $ operator is invalid for atomic vectors
>>
>> So you can search for the string 'x$tag' in your code (or possibly in the
>> package).
>>
> 
> OK thanks.
> 
> Something else must be wrong because my package should only contain a
> data.frame saved in .RData file

Immediately after the error, run traceback() to see where that code is 
being found.  The output might not mean much to you, but perhaps others 
here will spot the issue.

If that doesn't make the problem obvious, then post a link to your 
Github source and someone else will be able to try it.

Duncan Murdoch


From Gerrit.Eichner at math.uni-giessen.de  Wed Jan 17 15:02:01 2018
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 17 Jan 2018 15:02:01 +0100
Subject: [R] effects & lme4: error since original data frame not found
	WASeffects: error when original data frame is missing
In-Reply-To: <2c2dee47-0163-ae05-e1dc-29c30d12e30c@math.uni-giessen.de>
References: <2c2dee47-0163-ae05-e1dc-29c30d12e30c@math.uni-giessen.de>
Message-ID: <7cf95563-a575-0627-3683-8e2eb9409ff8@math.uni-giessen.de>

Hi, again,

I have to modify my query since my first (too simple)
example doesn't reflect my actual problem. Second try:

When asking Effect() inside a function to compute an effect
of an lmer-fit which uses a data frame local to the body of
the function, as in the following example (simplifying my
actual application), I get the "Error in is.data.frame(data) :
object 'X' not found":

 > foo <- function() {
+  X <- sleepstudy
+  fm <- lmer(Reaction ~ Days + (Days | Subject), data = X)
+  Effect("Days", fm)
+ }

 > foo()

Error in is.data.frame(data) : object 'X' not found


With lm-objects there is no problem:

 > foo2 <- function() {
+   X <- sleepstudy
+   fm <- lm(Reaction ~ Days, data = X)
+   Effect("Days", fm)
+ }

 > foo2()

....

Any idea how to work around this problem?
Once again, thx in advance!

  Regards  --  Gerrit

PS: > sessionInfo()
R version 3.4.2 (2017-09-28)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
[5] LC_TIME=German_Germany.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] effects_4.0-0   carData_3.0-0   lme4_1.1-14     Matrix_1.2-11 
car_2.1-5
[6] lattice_0.20-35

loaded via a namespace (and not attached):
  [1] Rcpp_0.12.13       MASS_7.3-47        grid_3.4.2 
MatrixModels_0.4-1
  [5] nlme_3.1-131       survey_3.32-1      SparseM_1.77 
minqa_1.2.4
  [9] nloptr_1.0.4       splines_3.4.2      tools_3.4.2 
survival_2.41-3
[13] pbkrtest_0.4-7     yaml_2.1.14        parallel_3.4.2 
compiler_3.4.2
[17] colorspace_1.3-2   mgcv_1.8-22        nnet_7.3-12 
quantreg_5.33

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 17.01.2018 um 10:55 schrieb Gerrit Eichner:
> Hello, everyody,
> 
> when asking, e.g., Effect() to compute the effects of a fitted,
> e.g., linear model after having deleted the data frame from the
> workspace for which the model was obtained an error is reported:
> 
>  > myair <- airquality
>  > fm <- lm(Ozone ~ Temp, data = myair)
>  > rm(myair)
>  > Effect("Temp", fm)
> Error in eval(model$call$data, envir) : object 'myair' not found
> 
> Has anybody a better "workaround" for this than, e.g., explicitly
> saving the fitted model object fm together with its original
> environment or just the data needed frame (maybe in a list like
> fm.plus.origdata <- list(fm, myair = myair)) to be able to restore
> the original environemt (or at least the needed opriginal data
> frame) of the time when fm was created?
> 
> Thx for any hint!
> 
>  ?Regards? --? Gerrit
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
> Fax: +49-(0)641-99-32109??????????? http://www.uni-giessen.de/eichner
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Gerrit.Eichner at math.uni-giessen.de  Wed Jan 17 15:49:49 2018
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 17 Jan 2018 15:49:49 +0100
Subject: [R] effects & lme4: error since original data frame
	notfoundWASeffects: error when original data frame is missing
In-Reply-To: <7cf95563-a575-0627-3683-8e2eb9409ff8@math.uni-giessen.de>
References: <2c2dee47-0163-ae05-e1dc-29c30d12e30c@math.uni-giessen.de>
 <7cf95563-a575-0627-3683-8e2eb9409ff8@math.uni-giessen.de>
Message-ID: <7383c6f7-bdf9-172e-31d3-b677a554d46d@math.uni-giessen.de>

Third "hi" in this regard and for the archives:

I found a (maybe "dirty") workaround which at least does what I need
by creating a copy of the required data frame in the .GlobalEnv by
means of assign:

foo <- function() {
   assign("X", sleepstudy, pos = 1)
   fm <- lmer(Reaction ~ Days + (Days | Subject), data = X)
   Effect("Days", fm)
}


  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 17.01.2018 um 15:02 schrieb Gerrit Eichner:
> Hi, again,
> 
> I have to modify my query since my first (too simple)
> example doesn't reflect my actual problem. Second try:
> 
> When asking Effect() inside a function to compute an effect
> of an lmer-fit which uses a data frame local to the body of
> the function, as in the following example (simplifying my
> actual application), I get the "Error in is.data.frame(data) :
> object 'X' not found":
> 
>  > foo <- function() {
> +? X <- sleepstudy
> +? fm <- lmer(Reaction ~ Days + (Days | Subject), data = X)
> +? Effect("Days", fm)
> + }
> 
>  > foo()
> 
> Error in is.data.frame(data) : object 'X' not found
> 
> 
> With lm-objects there is no problem:
> 
>  > foo2 <- function() {
> +?? X <- sleepstudy
> +?? fm <- lm(Reaction ~ Days, data = X)
> +?? Effect("Days", fm)
> + }
> 
>  > foo2()
> 
> ....
> 
> Any idea how to work around this problem?
> Once again, thx in advance!
> 
>  ?Regards? --? Gerrit
> 
> PS: > sessionInfo()
> R version 3.4.2 (2017-09-28)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=German_Germany.1252? LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
> 
> attached base packages:
> [1] stats???? graphics? grDevices utils???? datasets? methods?? base
> 
> other attached packages:
> [1] effects_4.0-0?? carData_3.0-0?? lme4_1.1-14???? Matrix_1.2-11 car_2.1-5
> [6] lattice_0.20-35
> 
> loaded via a namespace (and not attached):
>  ?[1] Rcpp_0.12.13?????? MASS_7.3-47??????? grid_3.4.2 MatrixModels_0.4-1
>  ?[5] nlme_3.1-131?????? survey_3.32-1????? SparseM_1.77 minqa_1.2.4
>  ?[9] nloptr_1.0.4?????? splines_3.4.2????? tools_3.4.2 survival_2.41-3
> [13] pbkrtest_0.4-7???? yaml_2.1.14??????? parallel_3.4.2 compiler_3.4.2
> [17] colorspace_1.3-2?? mgcv_1.8-22??????? nnet_7.3-12 quantreg_5.33
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
> Fax: +49-(0)641-99-32109??????????? http://www.uni-giessen.de/eichner
> ---------------------------------------------------------------------
> 
> Am 17.01.2018 um 10:55 schrieb Gerrit Eichner:
>> Hello, everyody,
>>
>> when asking, e.g., Effect() to compute the effects of a fitted,
>> e.g., linear model after having deleted the data frame from the
>> workspace for which the model was obtained an error is reported:
>>
>> ?> myair <- airquality
>> ?> fm <- lm(Ozone ~ Temp, data = myair)
>> ?> rm(myair)
>> ?> Effect("Temp", fm)
>> Error in eval(model$call$data, envir) : object 'myair' not found
>>
>> Has anybody a better "workaround" for this than, e.g., explicitly
>> saving the fitted model object fm together with its original
>> environment or just the data needed frame (maybe in a list like
>> fm.plus.origdata <- list(fm, myair = myair)) to be able to restore
>> the original environemt (or at least the needed opriginal data
>> frame) of the time when fm was created?
>>
>> Thx for any hint!
>>
>> ??Regards? --? Gerrit
>>
>> ---------------------------------------------------------------------
>> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
>> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
>> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
>> Fax: +49-(0)641-99-32109??????????? http://www.uni-giessen.de/eichner
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Wed Jan 17 15:55:44 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 17 Jan 2018 14:55:44 +0000
Subject: [R] effects & lme4: error since original data
	frame	notfoundWASeffects: error when original data frame is missing
In-Reply-To: <7145_1516200628_w0HEoRNN030820_7383c6f7-bdf9-172e-31d3-b677a554d46d@math.uni-giessen.de>
References: <2c2dee47-0163-ae05-e1dc-29c30d12e30c@math.uni-giessen.de>
 <7cf95563-a575-0627-3683-8e2eb9409ff8@math.uni-giessen.de>
 <7145_1516200628_w0HEoRNN030820_7383c6f7-bdf9-172e-31d3-b677a554d46d@math.uni-giessen.de>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83675DEE2@FHSDB2D11-2.csu.mcmaster.ca>

Dear Gerrit,

This issue is discussed in a vignette in the car package (both for functions in the car and effects packages): vignette("embedding", package="car") . The solution suggested there is the essentially the one that you used.

I hope this helps,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Gerrit
> Eichner
> Sent: Wednesday, January 17, 2018 9:50 AM
> To: r-help at r-project.org
> Subject: Re: [R] effects & lme4: error since original data frame
> notfoundWASeffects: error when original data frame is missing
> 
> Third "hi" in this regard and for the archives:
> 
> I found a (maybe "dirty") workaround which at least does what I need by
> creating a copy of the required data frame in the .GlobalEnv by means of
> assign:
> 
> foo <- function() {
>    assign("X", sleepstudy, pos = 1)
>    fm <- lmer(Reaction ~ Days + (Days | Subject), data = X)
>    Effect("Days", fm)
> }
> 
> 
>   Hth  --  Gerrit
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
> Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
> ---------------------------------------------------------------------
> 
> Am 17.01.2018 um 15:02 schrieb Gerrit Eichner:
> > Hi, again,
> >
> > I have to modify my query since my first (too simple) example doesn't
> > reflect my actual problem. Second try:
> >
> > When asking Effect() inside a function to compute an effect of an
> > lmer-fit which uses a data frame local to the body of the function, as
> > in the following example (simplifying my actual application), I get
> > the "Error in is.data.frame(data) :
> > object 'X' not found":
> >
> >  > foo <- function() {
> > +? X <- sleepstudy
> > +? fm <- lmer(Reaction ~ Days + (Days | Subject), data = X)
> > +? Effect("Days", fm)
> > + }
> >
> >  > foo()
> >
> > Error in is.data.frame(data) : object 'X' not found
> >
> >
> > With lm-objects there is no problem:
> >
> >  > foo2 <- function() {
> > +?? X <- sleepstudy
> > +?? fm <- lm(Reaction ~ Days, data = X)
> > +?? Effect("Days", fm)
> > + }
> >
> >  > foo2()
> >
> > ....
> >
> > Any idea how to work around this problem?
> > Once again, thx in advance!
> >
> >  ?Regards? --? Gerrit
> >
> > PS: > sessionInfo()
> > R version 3.4.2 (2017-09-28)
> > Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 8
> > x64 (build 9200)
> >
> > Matrix products: default
> >
> > locale:
> > [1]
> LC_COLLATE=German_Germany.1252? LC_CTYPE=German_Germany.1252 [3]
> > LC_MONETARY=German_Germany.1252 LC_NUMERIC=C [5]
> > LC_TIME=German_Germany.1252
> >
> > attached base packages:
> > [1] stats???? graphics? grDevices utils???? datasets? methods?? base
> >
> > other attached packages:
> > [1] effects_4.0-0?? carData_3.0-0?? lme4_1.1-14???? Matrix_1.2-11
> > car_2.1-5 [6] lattice_0.20-35
> >
> > loaded via a namespace (and not attached):
> >  ?[1] Rcpp_0.12.13?????? MASS_7.3-47??????? grid_3.4.2
> > MatrixModels_0.4-1
> >  ?[5] nlme_3.1-131?????? survey_3.32-1????? SparseM_1.77 minqa_1.2.4
> >  ?[9] nloptr_1.0.4?????? splines_3.4.2????? tools_3.4.2
> > survival_2.41-3 [13] pbkrtest_0.4-7???? yaml_2.1.14
> > parallel_3.4.2 compiler_3.4.2 [17] colorspace_1.3-2?? mgcv_1.8-22
> > nnet_7.3-12 quantreg_5.33
> >
> > ---------------------------------------------------------------------
> > Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
> > gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
> > Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
> > Fax: +49-(0)641-99-32109??????????? http://www.uni-giessen.de/eichner
> > ---------------------------------------------------------------------
> >
> > Am 17.01.2018 um 10:55 schrieb Gerrit Eichner:
> >> Hello, everyody,
> >>
> >> when asking, e.g., Effect() to compute the effects of a fitted, e.g.,
> >> linear model after having deleted the data frame from the workspace
> >> for which the model was obtained an error is reported:
> >>
> >> ?> myair <- airquality
> >> ?> fm <- lm(Ozone ~ Temp, data = myair)
> >> ?> rm(myair)
> >> ?> Effect("Temp", fm)
> >> Error in eval(model$call$data, envir) : object 'myair' not found
> >>
> >> Has anybody a better "workaround" for this than, e.g., explicitly
> >> saving the fitted model object fm together with its original
> >> environment or just the data needed frame (maybe in a list like
> >> fm.plus.origdata <- list(fm, myair = myair)) to be able to restore
> >> the original environemt (or at least the needed opriginal data
> >> frame) of the time when fm was created?
> >>
> >> Thx for any hint!
> >>
> >> ??Regards? --? Gerrit
> >>
> >> ---------------------------------------------------------------------
> >> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
> >> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
> >> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
> >> Fax: +49-(0)641-99-32109??????????? http://www.uni-giessen.de/eichner
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From traxplayer at gmail.com  Wed Jan 17 16:53:29 2018
From: traxplayer at gmail.com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Wed, 17 Jan 2018 16:53:29 +0100
Subject: [R] Help making first dataset R package
Message-ID: <CAGAA5bcdF-uZaSVRZSN0fyGYn4_R7RQSON2hy=g7EQC0LP0QRg@mail.gmail.com>

Hi,

  I am trying to make my first R package containing only a single
data.frame and documentation.

  All code can be found at:
https://github.com/MartinMSPedersen/folkeafstemninger

When I check the package I get four warnings.
I will list all warnings in this email because they migth be connected.

1.
* checking if this is a source package ... WARNING
Subdirectory ?src? contains:
  convert_from_xml.R
These are unlikely file names for src files.

2.
* checking whether package ?folkeafstemninger? can be installed ... WARNING
Found the following significant warnings:
  Warning: no source files found
See ?/home/mm/gits/folkeafstemninger.Rcheck/00install.out? for details.

3.
* checking package subdirectories ... WARNING
Subdirectory ?data? contains no data sets.
Subdirectory ?src? contains no source files.

4.
* checking contents of ?data? directory ... WARNING
Files not of a type allowed in a ?data? directory:
  ?folkeafstemninger.Rdata?
Please use e.g. ?inst/extdata? for non-R data files


 The raw xml-files I used to create the data.frame is placed under raw/
 The data.frame is saved as data/folkeafstemninger.RData
and
  The R source I wrote to convert the xml-files is placed under src/

Thanks for any help.

Regards
Martin

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Jan 17 17:03:20 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 17 Jan 2018 08:03:20 -0800
Subject: [R] Help making first dataset R package
In-Reply-To: <CAGAA5bcdF-uZaSVRZSN0fyGYn4_R7RQSON2hy=g7EQC0LP0QRg@mail.gmail.com>
References: <CAGAA5bcdF-uZaSVRZSN0fyGYn4_R7RQSON2hy=g7EQC0LP0QRg@mail.gmail.com>
Message-ID: <CAGxFJbQqX57Ohnx+OM3dqmUHuHEKsfuymX9GgkWYD5v3hRLq0Q@mail.gmail.com>

I think this would fit better on the r-package-devel list.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jan 17, 2018 at 7:53 AM, Martin M?ller Skarbiniks Pedersen <
traxplayer at gmail.com> wrote:

> Hi,
>
>   I am trying to make my first R package containing only a single
> data.frame and documentation.
>
>   All code can be found at:
> https://github.com/MartinMSPedersen/folkeafstemninger
>
> When I check the package I get four warnings.
> I will list all warnings in this email because they migth be connected.
>
> 1.
> * checking if this is a source package ... WARNING
> Subdirectory ?src? contains:
>   convert_from_xml.R
> These are unlikely file names for src files.
>
> 2.
> * checking whether package ?folkeafstemninger? can be installed ... WARNING
> Found the following significant warnings:
>   Warning: no source files found
> See ?/home/mm/gits/folkeafstemninger.Rcheck/00install.out? for details.
>
> 3.
> * checking package subdirectories ... WARNING
> Subdirectory ?data? contains no data sets.
> Subdirectory ?src? contains no source files.
>
> 4.
> * checking contents of ?data? directory ... WARNING
> Files not of a type allowed in a ?data? directory:
>   ?folkeafstemninger.Rdata?
> Please use e.g. ?inst/extdata? for non-R data files
>
>
>  The raw xml-files I used to create the data.frame is placed under raw/
>  The data.frame is saved as data/folkeafstemninger.RData
> and
>   The R source I wrote to convert the xml-files is placed under src/
>
> Thanks for any help.
>
> Regards
> Martin
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Jan 17 17:09:35 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 17 Jan 2018 17:09:35 +0100
Subject: [R] Help making first dataset R package
In-Reply-To: <CAGAA5bcdF-uZaSVRZSN0fyGYn4_R7RQSON2hy=g7EQC0LP0QRg@mail.gmail.com>
References: <CAGAA5bcdF-uZaSVRZSN0fyGYn4_R7RQSON2hy=g7EQC0LP0QRg@mail.gmail.com>
Message-ID: <CAJuCY5zEu3-vC9BHOO3+cuzjaNepVKO-Vb3xAFFZOu6cWrHbQQ@mail.gmail.com>

Dear Martin,

1 and 2. src is intended for C, C++ or Fortan files, not for R files.
See https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Non_002dR-scripts-in-packages.
Either convert your script to a function and place it in the R folder
or place the the script in inst/src.
3 and 4. Note that R is case sensitive. the extension should be .RData
instead of Rdata. See
https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Data-in-packages

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-01-17 16:53 GMT+01:00 Martin M?ller Skarbiniks Pedersen
<traxplayer at gmail.com>:
> Hi,
>
>   I am trying to make my first R package containing only a single
> data.frame and documentation.
>
>   All code can be found at:
> https://github.com/MartinMSPedersen/folkeafstemninger
>
> When I check the package I get four warnings.
> I will list all warnings in this email because they migth be connected.
>
> 1.
> * checking if this is a source package ... WARNING
> Subdirectory ?src? contains:
>   convert_from_xml.R
> These are unlikely file names for src files.
>
> 2.
> * checking whether package ?folkeafstemninger? can be installed ... WARNING
> Found the following significant warnings:
>   Warning: no source files found
> See ?/home/mm/gits/folkeafstemninger.Rcheck/00install.out? for details.
>
> 3.
> * checking package subdirectories ... WARNING
> Subdirectory ?data? contains no data sets.
> Subdirectory ?src? contains no source files.
>
> 4.
> * checking contents of ?data? directory ... WARNING
> Files not of a type allowed in a ?data? directory:
>   ?folkeafstemninger.Rdata?
> Please use e.g. ?inst/extdata? for non-R data files
>
>
>  The raw xml-files I used to create the data.frame is placed under raw/
>  The data.frame is saved as data/folkeafstemninger.RData
> and
>   The R source I wrote to convert the xml-files is placed under src/
>
> Thanks for any help.
>
> Regards
> Martin
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From archerrish at gmail.com  Wed Jan 17 17:24:15 2018
From: archerrish at gmail.com (Max Shell)
Date: Thu, 18 Jan 2018 00:24:15 +0800
Subject: [R] Assessing calibration of Cox model with time-dependent
	coefficients
Message-ID: <CAKpGb9BZXNJTHyS5MhqmnN_pxAFJfOnmvRn0T_aE24b6NXQ+Tg@mail.gmail.com>

I am trying to find methods for testing and visualizing calibration to Cox
models with time-depended coefficients. I have read this nice article
<http://journals.sagepub.com/doi/10.1177/0962280213497434>. In this paper,
we can fit three models:

fit0 <- coxph(Surv(futime, status) ~ x1 + x2 + x3, data = data0) p <-
log(predict(fit0, newdata = data1, type = "expected")) lp <- predict(fit0,
newdata = data1, type = "lp") logbase <- p - lp fit1 <- glm(y ~ offset(p),
family = poisson, data = data1) fit2 <- glm(y ~ lp + offset(logbase),
family = poisson, data = data1) group <- cut(lp, c(-Inf, quantile(lp, (1:9)
/ 10), Inf)) fit3 <- glm(y ~ -1 + group + offset(p), family = poisson, data
= data1)

Here?I simplely use data1 <- data0[1:500,]
First, I get following error when running line 5.

Error in eval(predvars, data, env) : object 'y' not found

So I modifited the code by replacing the y as status looks like this:

fit1 <- glm(status ~ offset(p), family = poisson, data = data1) fit2 <-
glm(status ~ lp + offset(logbase), family = poisson, data = data1) group <-
cut(lp, c(-Inf, quantile(lp, (1:9) / 10), Inf)) fit3 <- glm(status ~ -1 +
group + offset(p), family = poisson, data = data1)

*Is this replacing correct?*
Second, I try to introduce the time-transform use coxph with ttparament.

My code is:  fit0 <- coxph(Surv(time, status) ~ x1 + x2 + x3 + tt(x3), data
= data0, function(x, t, ...) x * t) p <- log(predict(fit0, newdata = data1,
type = "expected")) lp <- predict(fit0, newdata = data1, type = "lp")
logbase <- p - lp fit1 <- glm(status ~ offset(p), family = poisson, data =
data1) fit2 <- glm(status ~ lp + offset(logbase), family = poisson, data =
data1) group <- cut(lp, c(-Inf, quantile(lp, (1:9) / 10), Inf)) fit3 <-
glm(status ~ -1 + group + offset(p), family = poisson, data = data1)
My questions is:

   - Is the code above correct?
   - How to interpret the fit1, fit2, fit3? What's the connection between
   the three models and the calibration of the Cox model?
   - How to generate the calibration plot using fit3? The article dose have
   a section discuss this, but no code is provided.

Thank you!

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Jan 17 19:21:34 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 17 Jan 2018 10:21:34 -0800
Subject: [R] Assessing calibration of Cox model with time-dependent
	coefficients
In-Reply-To: <CAKpGb9BZXNJTHyS5MhqmnN_pxAFJfOnmvRn0T_aE24b6NXQ+Tg@mail.gmail.com>
References: <CAKpGb9BZXNJTHyS5MhqmnN_pxAFJfOnmvRn0T_aE24b6NXQ+Tg@mail.gmail.com>
Message-ID: <CAGxFJbQMASBpm5k+FbV5zOkKCQnpDxkgY=Wpm=drVf3vHRsoGA@mail.gmail.com>

1. Please repost in **plain text** as html can get mangled, as here (see
below), on this plain text list.

2. Generally, statistical issues are off topic here. stats.stackexchange.com
is one place to post such questions. Having said that, the intersection of
statistics and (on topic) R coding is often nonempty, so you may wish to
wait to see whether someone here satisfactorily answers your query before
posting on Cross Validated.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jan 17, 2018 at 8:24 AM, Max Shell <archerrish at gmail.com> wrote:

> I am trying to find methods for testing and visualizing calibration to Cox
> models with time-depended coefficients. I have read this nice article
> <http://journals.sagepub.com/doi/10.1177/0962280213497434>. In this paper,
> we can fit three models:
>
> fit0 <- coxph(Surv(futime, status) ~ x1 + x2 + x3, data = data0) p <-
> log(predict(fit0, newdata = data1, type = "expected")) lp <- predict(fit0,
> newdata = data1, type = "lp") logbase <- p - lp fit1 <- glm(y ~ offset(p),
> family = poisson, data = data1) fit2 <- glm(y ~ lp + offset(logbase),
> family = poisson, data = data1) group <- cut(lp, c(-Inf, quantile(lp, (1:9)
> / 10), Inf)) fit3 <- glm(y ~ -1 + group + offset(p), family = poisson, data
> = data1)
>
> Here?I simplely use data1 <- data0[1:500,]
> First, I get following error when running line 5.
>
> Error in eval(predvars, data, env) : object 'y' not found
>
> So I modifited the code by replacing the y as status looks like this:
>
> fit1 <- glm(status ~ offset(p), family = poisson, data = data1) fit2 <-
> glm(status ~ lp + offset(logbase), family = poisson, data = data1) group <-
> cut(lp, c(-Inf, quantile(lp, (1:9) / 10), Inf)) fit3 <- glm(status ~ -1 +
> group + offset(p), family = poisson, data = data1)
>
> *Is this replacing correct?*
> Second, I try to introduce the time-transform use coxph with ttparament.
>
> My code is:  fit0 <- coxph(Surv(time, status) ~ x1 + x2 + x3 + tt(x3), data
> = data0, function(x, t, ...) x * t) p <- log(predict(fit0, newdata = data1,
> type = "expected")) lp <- predict(fit0, newdata = data1, type = "lp")
> logbase <- p - lp fit1 <- glm(status ~ offset(p), family = poisson, data =
> data1) fit2 <- glm(status ~ lp + offset(logbase), family = poisson, data =
> data1) group <- cut(lp, c(-Inf, quantile(lp, (1:9) / 10), Inf)) fit3 <-
> glm(status ~ -1 + group + offset(p), family = poisson, data = data1)
> My questions is:
>
>    - Is the code above correct?
>    - How to interpret the fit1, fit2, fit3? What's the connection between
>    the three models and the calibration of the Cox model?
>    - How to generate the calibration plot using fit3? The article dose have
>    a section discuss this, but no code is provided.
>
> Thank you!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From maitra at email.com  Thu Jan 18 05:22:41 2018
From: maitra at email.com (Ranjan Maitra)
Date: Wed, 17 Jan 2018 22:22:41 -0600
Subject: [R] reading lisp file in R
Message-ID: <20180117222241.e545855f9f9d7c79e67dbaf8@email.com>

Dear friends,

Is there a way to read data files written in lisp into R? 

Here is the file: https://archive.ics.uci.edu/ml/machine-learning-databases/university/university.data

I would like to read it into R. Any suggestions? 

Thanks very much in advance for pointers on this and best wishes,
Ranjan

-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.


From dwinsemius at comcast.net  Thu Jan 18 05:59:48 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 17 Jan 2018 20:59:48 -0800
Subject: [R] reading lisp file in R
In-Reply-To: <20180117222241.e545855f9f9d7c79e67dbaf8@email.com>
References: <20180117222241.e545855f9f9d7c79e67dbaf8@email.com>
Message-ID: <01572A9E-F7C0-4D0D-8016-048D7A69E757@comcast.net>


> On Jan 17, 2018, at 8:22 PM, Ranjan Maitra <maitra at email.com> wrote:
> 
> Dear friends,
> 
> Is there a way to read data files written in lisp into R? 
> 
> Here is the file: https://archive.ics.uci.edu/ml/machine-learning-databases/university/university.data
> 
> I would like to read it into R. Any suggestions?

It's just a text file. What difficulties are you having?
>  
> 
> Thanks very much in advance for pointers on this and best wishes,
> Ranjan
> 
> -- 
> Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From ericjberger at gmail.com  Thu Jan 18 06:02:29 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Thu, 18 Jan 2018 07:02:29 +0200
Subject: [R] reading lisp file in R
In-Reply-To: <20180117222241.e545855f9f9d7c79e67dbaf8@email.com>
References: <20180117222241.e545855f9f9d7c79e67dbaf8@email.com>
Message-ID: <CAGgJW76se6CYEhHYSMMQm3gZSCMOPt-Mgc=6jjXAjxW2Xhm-vw@mail.gmail.com>

It seems the file contains records, with each record having 18 fields.
I would use awk (standard unix tool), creating an awk script to process the
file
into a new file with one line for each record, each line with 18 fields,
say comma-separated.
The csv file can then be easily read into R via the function read.csv.

HTH,
Eric


On Thu, Jan 18, 2018 at 6:22 AM, Ranjan Maitra <maitra at email.com> wrote:

> Dear friends,
>
> Is there a way to read data files written in lisp into R?
>
> Here is the file: https://archive.ics.uci.edu/
> ml/machine-learning-databases/university/university.data
>
> I would like to read it into R. Any suggestions?
>
> Thanks very much in advance for pointers on this and best wishes,
> Ranjan
>
> --
> Important Notice: This mailbox is ignored: e-mails are set to be deleted
> on receipt. Please respond to the mailing list if appropriate. For those
> needing to send personal or professional e-mail, please use appropriate
> addresses.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From maitra at email.com  Thu Jan 18 06:25:55 2018
From: maitra at email.com (Ranjan Maitra)
Date: Wed, 17 Jan 2018 23:25:55 -0600
Subject: [R] reading lisp file in R
In-Reply-To: <01572A9E-F7C0-4D0D-8016-048D7A69E757@comcast.net>
References: <20180117222241.e545855f9f9d7c79e67dbaf8@email.com>
 <01572A9E-F7C0-4D0D-8016-048D7A69E757@comcast.net>
Message-ID: <20180117232555.463ea9ee32831be22b306c03@email.com>

Thanks! I am trying to use it in R. (Actually, I try to give my students experiences with different kinds of files and I was wondering if there were tools available for such kinds of files. I don't know Lisp so I do not actually know what the lines towards the bottom of the file mean.(

Many thanks for your response!

Best wishes,
Ranjan

On Wed, 17 Jan 2018 20:59:48 -0800 David Winsemius <dwinsemius at comcast.net> wrote:

> 
> > On Jan 17, 2018, at 8:22 PM, Ranjan Maitra <maitra at email.com> wrote:
> > 
> > Dear friends,
> > 
> > Is there a way to read data files written in lisp into R? 
> > 
> > Here is the file: https://archive.ics.uci.edu/ml/machine-learning-databases/university/university.data
> > 
> > I would like to read it into R. Any suggestions?
> 
> It's just a text file. What difficulties are you having?
> >  
> > 
> > Thanks very much in advance for pointers on this and best wishes,
> > Ranjan
> > 
> > -- 
> > Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.


From maitra at email.com  Thu Jan 18 06:35:00 2018
From: maitra at email.com (Ranjan Maitra)
Date: Wed, 17 Jan 2018 23:35:00 -0600
Subject: [R] reading lisp file in R
In-Reply-To: <CAGgJW76se6CYEhHYSMMQm3gZSCMOPt-Mgc=6jjXAjxW2Xhm-vw@mail.gmail.com>
References: <20180117222241.e545855f9f9d7c79e67dbaf8@email.com>
 <CAGgJW76se6CYEhHYSMMQm3gZSCMOPt-Mgc=6jjXAjxW2Xhm-vw@mail.gmail.com>
Message-ID: <20180117233500.d057a08e7381040535ac20b0@email.com>

Thanks! I guess one way to do it in R would be to read the lines and then do character parsing (string-matching and other operations) to save as a data frame and forget about the lines at the end perhaps? I am not sure how general such a scheme would be: that is also something I would like to show my students, because the fact is that to be useful it should be general or easily modified for use other datasets.

Best wishes,
Ranjan

On Thu, 18 Jan 2018 07:02:29 +0200 Eric Berger <ericjberger at gmail.com> wrote:

> It seems the file contains records, with each record having 18 fields.
> I would use awk (standard unix tool), creating an awk script to process the
> file
> into a new file with one line for each record, each line with 18 fields,
> say comma-separated.
> The csv file can then be easily read into R via the function read.csv.
> 
> HTH,
> Eric
> 
> 
> On Thu, Jan 18, 2018 at 6:22 AM, Ranjan Maitra <maitra at email.com> wrote:
> 
> > Dear friends,
> >
> > Is there a way to read data files written in lisp into R?
> >
> > Here is the file: https://archive.ics.uci.edu/
> > ml/machine-learning-databases/university/university.data
> >
> > I would like to read it into R. Any suggestions?
> >
> > Thanks very much in advance for pointers on this and best wishes,
> > Ranjan
> >
> > --
> > Important Notice: This mailbox is ignored: e-mails are set to be deleted
> > on receipt. Please respond to the mailing list if appropriate. For those
> > needing to send personal or professional e-mail, please use appropriate
> > addresses.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.


From shijingeorge at yahoo.com  Thu Jan 18 01:37:06 2018
From: shijingeorge at yahoo.com (shijin mathew)
Date: Thu, 18 Jan 2018 00:37:06 +0000 (UTC)
Subject: [R] error while loading ggplot2
References: <1169171028.115694.1516235826162.ref@mail.yahoo.com>
Message-ID: <1169171028.115694.1516235826162@mail.yahoo.com>

Getting the following error while loading ggplot2.

> library(ggplot2)
Error: package or namespace load failed for ?ggplot2? in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
 object 'vI' not found
Tried different version of R and ggplot2 but still doesnt work.
Any help to resolve is appreciated. Appreciate any pointers.
-S

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Jan 18 08:34:12 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 17 Jan 2018 23:34:12 -0800
Subject: [R] error while loading ggplot2
In-Reply-To: <1169171028.115694.1516235826162@mail.yahoo.com>
References: <1169171028.115694.1516235826162.ref@mail.yahoo.com>
 <1169171028.115694.1516235826162@mail.yahoo.com>
Message-ID: <31ECB0E5-BBF7-4C88-9F1E-CA22904F80C6@dcn.davis.ca.us>

Please post using plain text... the mailing list will strip HTML anyway and mess up what you send. 

Send the output of sessionInfo() so we know what versions of R and packages you have. 
-- 
Sent from my phone. Please excuse my brevity.

On January 17, 2018 4:37:06 PM PST, shijin mathew via R-help <r-help at r-project.org> wrote:
>Getting the following error while loading ggplot2.
>
>> library(ggplot2)
>Error: package or namespace load failed for ?ggplot2? in
>loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
> object 'vI' not found
>Tried different version of R and ggplot2 but still doesnt work.
>Any help to resolve is appreciated. Appreciate any pointers.
>-S
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From peter.crowther at melandra.com  Thu Jan 18 10:20:13 2018
From: peter.crowther at melandra.com (Peter Crowther)
Date: Thu, 18 Jan 2018 09:20:13 +0000
Subject: [R] reading lisp file in R
In-Reply-To: <20180117232555.463ea9ee32831be22b306c03@email.com>
References: <20180117222241.e545855f9f9d7c79e67dbaf8@email.com>
 <01572A9E-F7C0-4D0D-8016-048D7A69E757@comcast.net>
 <20180117232555.463ea9ee32831be22b306c03@email.com>
Message-ID: <CALhdq6vpciOAq7_NF3M9M=d=Laq_Bt_JAMJTjhgq-FwA=o=vrw@mail.gmail.com>

That's a nice example of why Lisp is both powerful and terrifying - you're
looking at a Lisp *program*, not just Lisp *data*, as Lisp makes no
distinction between the two.  You just read 'em in.

The two definitions at the bottom are function definitions.  The top one
defines the def-instance function.  Reading that indicates that it accepts
an atom as a name and a list of key-value or key-range-value lists as
properties, where they keys may be repeated to give you multi-valued
attributes in your result.  The bottom one defines a function for removing
duplicate entries of the same location.

The rest of the file (apart from the included email headers) is a whole
load of calls to the def-instance function.  In Lisp, you'd define the
functions, then just run the rest of the file.

To my knowledge, there is no generic way to read Lisp "data" into anything
else, because of this quirk that data can look like anything.  If anyone
can correct me on that, great, but I'd be somewhat surprised.  Therefore,
as David intimated, the tools you need are generic tools for handling text,
and you'll have to deal with the formatting yourself.  If I were doing a
one-off transform of this file, I'd probably reach for vi... but I'm an old
Unix hacker.  I certainly wouldn't teach that tooling.  awk or perl could
certainly handle it; or if you want to give students a wider view of the
world you might wish to try ANTLR and get them to write a grammar to parse
the file.  The Clojure grammar (
https://github.com/antlr/grammars-v4/blob/master/clojure/Clojure.g4) would
be an interesting place to start, although Terence Parr's comment of "match
a bunch of crap in parentheses" would probably give a flavour of what to
implement.  Depends what else the students are learning.

Hope this helps rather than hinders.

- Peter

On 18 January 2018 at 05:25, Ranjan Maitra <maitra at email.com> wrote:

> Thanks! I am trying to use it in R. (Actually, I try to give my students
> experiences with different kinds of files and I was wondering if there were
> tools available for such kinds of files. I don't know Lisp so I do not
> actually know what the lines towards the bottom of the file mean.(
>
> Many thanks for your response!
>
> Best wishes,
> Ranjan
>
> On Wed, 17 Jan 2018 20:59:48 -0800 David Winsemius <dwinsemius at comcast.net>
> wrote:
>
> >
> > > On Jan 17, 2018, at 8:22 PM, Ranjan Maitra <maitra at email.com> wrote:
> > >
> > > Dear friends,
> > >
> > > Is there a way to read data files written in lisp into R?
> > >
> > > Here is the file: https://archive.ics.uci.edu/
> ml/machine-learning-databases/university/university.data
> > >
> > > I would like to read it into R. Any suggestions?
> >
> > It's just a text file. What difficulties are you having?
> > >
> > >
> > > Thanks very much in advance for pointers on this and best wishes,
> > > Ranjan
> > >
> > > --
> > > Important Notice: This mailbox is ignored: e-mails are set to be
> deleted on receipt. Please respond to the mailing list if appropriate. For
> those needing to send personal or professional e-mail, please use
> appropriate addresses.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> Important Notice: This mailbox is ignored: e-mails are set to be deleted
> on receipt. Please respond to the mailing list if appropriate. For those
> needing to send personal or professional e-mail, please use appropriate
> addresses.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From iliofornasero at hotmail.com  Thu Jan 18 09:58:16 2018
From: iliofornasero at hotmail.com (Ilio Fornasero)
Date: Thu, 18 Jan 2018 08:58:16 +0000
Subject: [R] Web scraping different levels of a website
Message-ID: <AM4PR0802MB2275FB1BB1805342F1CCC21EB3E80@AM4PR0802MB2275.eurprd08.prod.outlook.com>

I am web scraping a page at

http://catalog.ihsn.org/index.php/catalog#_r=&collection=&country=&dtype=&from=1890&page=1&ps=100&sid=&sk=&sort_by=nation&sort_order=&to=2017&topic=&view=s&vk=

From this url, I have built up a dataframe through the following code:

dflist <- map(.x = 1:417, .f = function(x) {
 Sys.sleep(5)
 url <- ("http://catalog.ihsn.org/index.php/catalog#_r=&collection=&country=&dtype=&from=1890&page=1&ps=100&sid=&sk=&sort_by=nation&sort_order=&to=2017&topic=&view=s&vk=")
read_html(url) %>%
html_nodes(".title a") %>%
html_text() %>%
as.data.frame()
}) %>% do.call(rbind, .)

I have repeated the same code in order to get all the data I was interested in and it seems to work perfectly, although is of course a little slow due to the Sys.sleep() thing.

My issue has raised once I have tried to scrape the single projects descriptions that should be included in the dataframe.

For instance, the first project description is at

http://catalog.ihsn.org/index.php/catalog/7118/study-description

the second project description is at

http://catalog.ihsn.org/index.php/catalog/6606/study-description

and so forth.

My problem is that I can't find a dynamic way to scrape all the projects' pages and insert them in the data frame, being the number in the URLs not progressive nor at the end of the link.

To make things clearer, this is the structure of the website I am scraping:

1.http://catalog.ihsn.org/index.php/catalog#_r=&collection=&country=&dtype=&from=1890&page=1&ps=100&sid=&sk=&sort_by=nation&sort_order=&to=2017&topic=&view=s&vk=
   1.1.   http://catalog.ihsn.org/index.php/catalog/7118
        1.1.a http://catalog.ihsn.org/index.php/catalog/7118/related_materials
        1.1.b http://catalog.ihsn.org/index.php/catalog/7118/study-description
        1.1.c. http://catalog.ihsn.org/index.php/catalog/7118/data_dictionary

I have scraped successfully level 1. but cannot level 1.1.b. (study-description) , the one I am interested in, since the dynamic element of the URL (in this case: 7118) is not consistent in the website's above 6000 pages of that level.


	[[alternative HTML version deleted]]


From meyners.m at pg.com  Thu Jan 18 13:29:57 2018
From: meyners.m at pg.com (Meyners, Michael)
Date: Thu, 18 Jan 2018 12:29:57 +0000
Subject: [R] Letters group Games-Howell post hoc in R
In-Reply-To: <0e33806f9e73801f34522c528c307985.squirrel@correu.udl.cat>
References: <0e33806f9e73801f34522c528c307985.squirrel@correu.udl.cat>
Message-ID: <CY4PR01MB237677F2F7B638FF9693C1269AE80@CY4PR01MB2376.prod.exchangelabs.com>

Apologies if I missed any earlier replies - did you check
multcompLetters in package {multcompView}?
It allows you to get connecting letters reports (if that's what you are after, I didn't check what exactly agricolae is providing here). May have to add some manual steps to combine this with any data (means or whatever) you want to report.
multcompLetters allows you to use p values or a logical (significant or not)
HTH, Michael

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David Bars
> Cortina
> Sent: Dienstag, 16. Januar 2018 13:51
> To: R-help at r-project.org
> Subject: [R] Letters group Games-Howell post hoc in R
> 
> Hello everybody,
> 
> I use the sweetpotato database included in R package:
> 
> data(sweetpotato) This dataset contains two variables: yield(continous
> variable) and virus(factor variable).
> 
> Due to Levene test is significant I cannot assume homogeneity of variances
> and I apply Welch test in R instead of one-way ANOVA followed by Tukey
> posthoc.
> 
> Nevertheless, the problems come from when I apply posthoc test. In Tukey
> posthoc test I use library(agricolae) and displays me the superscript letters
> between virus groups. Therefore there are no problems.
> 
> Nevertheless, to perform Games-Howell posthoc, I use
> library(userfriendlyscience) and I obtain Games-Howell output but it's
> impossible for me to obtain a letter superscript comparison between virus
> groups as it is obtained through library(agricolae).
> 
> The code used it was the following:
> 
> library(userfriendlyscience)
> 
> data(sweetpotato)
> 
> oneway<-oneway(sweetpotato$virus, y=sweetpotato$yield, posthoc =
> 'games-howell')
> 
> oneway
> 
> I try with cld() importing previously library(multcompView) but doesn't work.
> 
> Can somebody could helps me?
> 
> Thanks in advance,
> 
> David Bars.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From david.jankoski at hellotrip.nl  Thu Jan 18 12:58:05 2018
From: david.jankoski at hellotrip.nl (David Jankoski)
Date: Thu, 18 Jan 2018 12:58:05 +0100
Subject: [R]  Web scraping different levels of a website
Message-ID: <CAOXhLq4So+Vu63tr5qmBi-ua=RVTYFCX3h8ww5_kx0DQH5k8vA@mail.gmail.com>

Hey Ilio,

On the main website (the first link that you provided) if you
right-click on the title of any entry and select Inspect Element from
the menu, you will notice in the Developer Tools view that opens up
that the corresponding html looks like this

(example for the same link that you provided)

<div class="survey-row"
data-url="http://catalog.ihsn.org/index.php/catalog/7118" title="View
study">
    <div class="data-access-icon data-access-remote" title="Data
available from external repository"></div>
        <h2 class="title">
            <a href="http://catalog.ihsn.org/index.php/catalog/7118"
title="Demographic and Health Survey 2015">
              Demographic and Health Survey 2015
            </a>
      </h2>

Notice how the number you are after is contained within the
"survey-row" div element, in the data-url attribute. Or alternatively
withing the <a> elem within the href attribute. It's up to you which
one you want to grab but the idea would be the same i.e.

1. read in the html
2. select all list-elements by css / xpath
3. grab the fwd link

Here is an example using the first option.

url <- "http://catalog.ihsn.org/index.php/catalog#_r=&collection=&country=&dtype=&from=1890&page=1&ps=100&sid=&sk=&sort_by=nation&sort_order=&to=2017&topic=&view=s&vk="

x <-
  url %>%
  GET() %>%
  content()

x %>%
  html_nodes(".survey-row") %>%
  html_attr("data-url")

hth.
david


From anjali232 at gmail.com  Thu Jan 18 13:49:31 2018
From: anjali232 at gmail.com (Anjali Karol Nair)
Date: Thu, 18 Jan 2018 18:19:31 +0530
Subject: [R] request for code
Message-ID: <CAPGkQHi6=YvkPkNgHP8EgLVMXNDdJGSpg1TaRHByNbUp_XAyng@mail.gmail.com>

Hi,

I want to convert my MATLAB programs to R studio programs.
Kindly guide on the same.

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Thu Jan 18 14:47:08 2018
From: jholtman at gmail.com (jim holtman)
Date: Thu, 18 Jan 2018 08:47:08 -0500
Subject: [R] request for code
In-Reply-To: <CAPGkQHi6=YvkPkNgHP8EgLVMXNDdJGSpg1TaRHByNbUp_XAyng@mail.gmail.com>
References: <CAPGkQHi6=YvkPkNgHP8EgLVMXNDdJGSpg1TaRHByNbUp_XAyng@mail.gmail.com>
Message-ID: <CAAxdm-4TMexd3H-SQ1fkChjnutb1SVJhJC-CqLbk1Bj8khE0iQ@mail.gmail.com>

a simple Google search turns up several possible choices.  There is a
package 'matconv' that might serve your purposes.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Thu, Jan 18, 2018 at 7:49 AM, Anjali Karol Nair <anjali232 at gmail.com>
wrote:

> Hi,
>
> I want to convert my MATLAB programs to R studio programs.
> Kindly guide on the same.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Thu Jan 18 14:53:14 2018
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 18 Jan 2018 08:53:14 -0500
Subject: [R] request for code
In-Reply-To: <CAPGkQHi6=YvkPkNgHP8EgLVMXNDdJGSpg1TaRHByNbUp_XAyng@mail.gmail.com>
References: <CAPGkQHi6=YvkPkNgHP8EgLVMXNDdJGSpg1TaRHByNbUp_XAyng@mail.gmail.com>
Message-ID: <726D3E75-E422-4005-88C0-D9E3027C6B3F@me.com>

> On Jan 18, 2018, at 7:49 AM, Anjali Karol Nair <anjali232 at gmail.com> wrote:
> 
> Hi,
> 
> I want to convert my MATLAB programs to R studio programs.
> Kindly guide on the same.

Hi,

Using Google with a search phrase such as "MATLAB to R" will yield a number of possible resources for you such as:

  http://www.math.umaine.edu/~hiebeler/comp/matlabR.pdf

which provides a reference for associating MATLAB code to R equivalents.

You can then take it from there.

Also, a clarification on your misunderstanding above, which seems to be prevalent from what I can tell on various online fora.

R Studio is a third party GUI that sits on top of R, it is not R. Thus, "R studio programs" is not accurate. They are R programs that can be created, edited and run via the R Studio GUI.

Regards,

Marc Schwartz


From Gerrit.Eichner at math.uni-giessen.de  Thu Jan 18 15:58:01 2018
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Thu, 18 Jan 2018 15:58:01 +0100
Subject: [R] effects & lme4: error since original
	dataframenotfoundWASeffects: error when original data frame
	is missing
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC83675DEE2@FHSDB2D11-2.csu.mcmaster.ca>
References: <2c2dee47-0163-ae05-e1dc-29c30d12e30c@math.uni-giessen.de>
 <7cf95563-a575-0627-3683-8e2eb9409ff8@math.uni-giessen.de>
 <7145_1516200628_w0HEoRNN030820_7383c6f7-bdf9-172e-31d3-b677a554d46d@math.uni-giessen.de>
 <ACD1644AA6C67E4FBD0C350625508EC83675DEE2@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <aa9e3ad3-45f5-7215-417e-4427fe46f220@math.uni-giessen.de>

Thanks, John,

for your hint! (Unfortunately, I was not aware of this vignette,
but I am glad that I seem to habe been on the right track.)

Indeed very helpful, in particular of course, the warning regarding
the danger of overwriting already existing objects. That danger might
be reduced by pre-checking the intended name and if neccessary
changing it (somehow ...) automatically. (Have to think about that ...)

  Best regards  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 17.01.2018 um 15:55 schrieb Fox, John:
> Dear Gerrit,
> 
> This issue is discussed in a vignette in the car package (both for functions in the car and effects packages): vignette("embedding", package="car") . The solution suggested there is the essentially the one that you used.
> 
> I hope this helps,
>   John
> 
> -----------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socialsciences.mcmaster.ca/jfox/
> 
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Gerrit
>> Eichner
>> Sent: Wednesday, January 17, 2018 9:50 AM
>> To: r-help at r-project.org
>> Subject: Re: [R] effects & lme4: error since original data frame
>> notfoundWASeffects: error when original data frame is missing
>>
>> Third "hi" in this regard and for the archives:
>>
>> I found a (maybe "dirty") workaround which at least does what I need by
>> creating a copy of the required data frame in the .GlobalEnv by means of
>> assign:
>>
>> foo <- function() {
>>     assign("X", sleepstudy, pos = 1)
>>     fm <- lmer(Reaction ~ Days + (Days | Subject), data = X)
>>     Effect("Days", fm)
>> }
>>
>>
>>    Hth  --  Gerrit
>>
>> ---------------------------------------------------------------------
>> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
>> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
>> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
>> Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
>> ---------------------------------------------------------------------
>>
>> Am 17.01.2018 um 15:02 schrieb Gerrit Eichner:
>>> Hi, again,
>>>
>>> I have to modify my query since my first (too simple) example doesn't
>>> reflect my actual problem. Second try:
>>>
>>> When asking Effect() inside a function to compute an effect of an
>>> lmer-fit which uses a data frame local to the body of the function, as
>>> in the following example (simplifying my actual application), I get
>>> the "Error in is.data.frame(data) :
>>> object 'X' not found":
>>>
>>>   > foo <- function() {
>>> +? X <- sleepstudy
>>> +? fm <- lmer(Reaction ~ Days + (Days | Subject), data = X)
>>> +? Effect("Days", fm)
>>> + }
>>>
>>>   > foo()
>>>
>>> Error in is.data.frame(data) : object 'X' not found
>>>
>>>
>>> With lm-objects there is no problem:
>>>
>>>   > foo2 <- function() {
>>> +?? X <- sleepstudy
>>> +?? fm <- lm(Reaction ~ Days, data = X)
>>> +?? Effect("Days", fm)
>>> + }
>>>
>>>   > foo2()
>>>
>>> ....
>>>
>>> Any idea how to work around this problem?
>>> Once again, thx in advance!
>>>
>>>   ?Regards? --? Gerrit
>>>
>>> PS: > sessionInfo()
>>> R version 3.4.2 (2017-09-28)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 8
>>> x64 (build 9200)
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1]
>> LC_COLLATE=German_Germany.1252? LC_CTYPE=German_Germany.1252 [3]
>>> LC_MONETARY=German_Germany.1252 LC_NUMERIC=C [5]
>>> LC_TIME=German_Germany.1252
>>>
>>> attached base packages:
>>> [1] stats???? graphics? grDevices utils???? datasets? methods?? base
>>>
>>> other attached packages:
>>> [1] effects_4.0-0?? carData_3.0-0?? lme4_1.1-14???? Matrix_1.2-11
>>> car_2.1-5 [6] lattice_0.20-35
>>>
>>> loaded via a namespace (and not attached):
>>>   ?[1] Rcpp_0.12.13?????? MASS_7.3-47??????? grid_3.4.2
>>> MatrixModels_0.4-1
>>>   ?[5] nlme_3.1-131?????? survey_3.32-1????? SparseM_1.77 minqa_1.2.4
>>>   ?[9] nloptr_1.0.4?????? splines_3.4.2????? tools_3.4.2
>>> survival_2.41-3 [13] pbkrtest_0.4-7???? yaml_2.1.14
>>> parallel_3.4.2 compiler_3.4.2 [17] colorspace_1.3-2?? mgcv_1.8-22
>>> nnet_7.3-12 quantreg_5.33
>>>
>>> ---------------------------------------------------------------------
>>> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
>>> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
>>> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
>>> Fax: +49-(0)641-99-32109??????????? http://www.uni-giessen.de/eichner
>>> ---------------------------------------------------------------------
>>>
>>> Am 17.01.2018 um 10:55 schrieb Gerrit Eichner:
>>>> Hello, everyody,
>>>>
>>>> when asking, e.g., Effect() to compute the effects of a fitted, e.g.,
>>>> linear model after having deleted the data frame from the workspace
>>>> for which the model was obtained an error is reported:
>>>>
>>>>  ?> myair <- airquality
>>>>  ?> fm <- lm(Ozone ~ Temp, data = myair)
>>>>  ?> rm(myair)
>>>>  ?> Effect("Temp", fm)
>>>> Error in eval(model$call$data, envir) : object 'myair' not found
>>>>
>>>> Has anybody a better "workaround" for this than, e.g., explicitly
>>>> saving the fitted model object fm together with its original
>>>> environment or just the data needed frame (maybe in a list like
>>>> fm.plus.origdata <- list(fm, myair = myair)) to be able to restore
>>>> the original environemt (or at least the needed opriginal data
>>>> frame) of the time when fm was created?
>>>>
>>>> Thx for any hint!
>>>>
>>>>  ??Regards? --? Gerrit
>>>>
>>>> ---------------------------------------------------------------------
>>>> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
>>>> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
>>>> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
>>>> Fax: +49-(0)641-99-32109??????????? http://www.uni-giessen.de/eichner
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From b.rowlingson at lancaster.ac.uk  Thu Jan 18 18:04:09 2018
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 18 Jan 2018 17:04:09 +0000
Subject: [R] reading lisp file in R
In-Reply-To: <4ceda7ab4e714962b230ccf6ad34a583@AM4PR0401MB1729.eurprd04.prod.outlook.com>
References: <20180117222241.e545855f9f9d7c79e67dbaf8@email.com>
 <01572A9E-F7C0-4D0D-8016-048D7A69E757@comcast.net>
 <20180117232555.463ea9ee32831be22b306c03@email.com>
 <4ceda7ab4e714962b230ccf6ad34a583@AM4PR0401MB1729.eurprd04.prod.outlook.com>
Message-ID: <CANVKczPQqGZOKBGXFpQaoOM8ZFQsqDRCL1OYCMnHpNwBGHPH7A@mail.gmail.com>

The file also has a bunch of email headers stuck in the middle of it:


.....

 (QUALITY-OF-LIFE SCALE:1-5 4)
  (ACADEMIC-EMPHASIS HEALTH-SCIENCE)
)
-------
-------

>From LEBOWITZ at cs.columbia.edu Mon Feb 22 20:53:02 1988
Received: from zodiac by meridian (5.52/4.7)
Received: from Jessica.Stanford.EDU by ads.com (5.58/1.9)
    id AA04539; Mon, 22 Feb 88 20:59:59 PST
Received: from Portia.Stanford.EDU by jessica.Stanford.EDU with TCP; Mon,
22 Feb
 88 20:58:22 PST
Received: from columbia.edu (COLUMBIA.EDU.ARPA) by Portia.STANFORD.EDU
(1.2/Ultrix2.0-B)
    id AA11480; Mon, 22 Feb 88 20:49:53 pst
Received: from CS.COLUMBIA.EDU by columbia.edu (5.54/1.14)
    id AA10186; Mon, 22 Feb 88 23:48:44 EST
Message-Id: <8802230448.AA10186 at columbia.edu>
Date: Fri 22 Jan 88 02:50:00-EST
From: The Mailer Daemon <Mailer at cs.columbia.edu>
To: LEBOWITZ at cs.columbia.edu
Subject: Message of 18-Jan-88 20:13:54
Resent-Date: Mon 22 Feb 88 23:44:07-EST
Resent-From: Michael Lebowitz <LEBOWITZ at cs.columbia.edu>
Resent-To: souders at portia.stanford.edu
Resent-Message-Id: <12376918538.25.LEBOWITZ at CS.COLUMBIA.EDU>
Status: R

Message undeliverable and dequeued after 3 days:
souders%meridian at ADS.ARPA: Cannot connect to host
        ------------
Date: Mon 18 Jan 88 20:13:54-EST
From: Michael Lebowitz <LEBOWITZ at CS.COLUMBIA.EDU>
Subject: bigger file part 3
To: souders%meridian at ADS.ARPA
In-Reply-To: <8801182147.AA08014 at ADS.ARPA>
Message-ID: <12367705229.11.LEBOWITZ at CS.COLUMBIA.EDU>

(DEF-INSTANCE GEORGETOWN
  (STATE MARYLAND)
  (LOCATION URBAN)
  (CONTROL PRIVATE)
  (NO-OF-STUDENTS THOUS:10-15)
  (MALE:FEMALE RATIO:45:55)
....

Which dates it to 1988. Nice.

Barry



On Thu, Jan 18, 2018 at 9:20 AM, Peter Crowther <peter.crowther at melandra.com
> wrote:

> That's a nice example of why Lisp is both powerful and terrifying - you're
> looking at a Lisp *program*, not just Lisp *data*, as Lisp makes no
> distinction between the two.  You just read 'em in.
>
> The two definitions at the bottom are function definitions.  The top one
> defines the def-instance function.  Reading that indicates that it accepts
> an atom as a name and a list of key-value or key-range-value lists as
> properties, where they keys may be repeated to give you multi-valued
> attributes in your result.  The bottom one defines a function for removing
> duplicate entries of the same location.
>
> The rest of the file (apart from the included email headers) is a whole
> load of calls to the def-instance function.  In Lisp, you'd define the
> functions, then just run the rest of the file.
>
> To my knowledge, there is no generic way to read Lisp "data" into anything
> else, because of this quirk that data can look like anything.  If anyone
> can correct me on that, great, but I'd be somewhat surprised.  Therefore,
> as David intimated, the tools you need are generic tools for handling text,
> and you'll have to deal with the formatting yourself.  If I were doing a
> one-off transform of this file, I'd probably reach for vi... but I'm an old
> Unix hacker.  I certainly wouldn't teach that tooling.  awk or perl could
> certainly handle it; or if you want to give students a wider view of the
> world you might wish to try ANTLR and get them to write a grammar to parse
> the file.  The Clojure grammar (
> https://github.com/antlr/grammars-v4/blob/master/clojure/Clojure.g4) would
> be an interesting place to start, although Terence Parr's comment of "match
> a bunch of crap in parentheses" would probably give a flavour of what to
> implement.  Depends what else the students are learning.
>
> Hope this helps rather than hinders.
>
> - Peter
>
> On 18 January 2018 at 05:25, Ranjan Maitra <maitra at email.com> wrote:
>
> > Thanks! I am trying to use it in R. (Actually, I try to give my students
> > experiences with different kinds of files and I was wondering if there
> were
> > tools available for such kinds of files. I don't know Lisp so I do not
> > actually know what the lines towards the bottom of the file mean.(
> >
> > Many thanks for your response!
> >
> > Best wishes,
> > Ranjan
> >
> > On Wed, 17 Jan 2018 20:59:48 -0800 David Winsemius <
> dwinsemius at comcast.net>
> > wrote:
> >
> > >
> > > > On Jan 17, 2018, at 8:22 PM, Ranjan Maitra <maitra at email.com> wrote:
> > > >
> > > > Dear friends,
> > > >
> > > > Is there a way to read data files written in lisp into R?
> > > >
> > > > Here is the file: https://archive.ics.uci.edu/
> > ml/machine-learning-databases/university/university.data
> > > >
> > > > I would like to read it into R. Any suggestions?
> > >
> > > It's just a text file. What difficulties are you having?
> > > >
> > > >
> > > > Thanks very much in advance for pointers on this and best wishes,
> > > > Ranjan
> > > >
> > > > --
> > > > Important Notice: This mailbox is ignored: e-mails are set to be
> > deleted on receipt. Please respond to the mailing list if appropriate.
> For
> > those needing to send personal or professional e-mail, please use
> > appropriate addresses.
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > David Winsemius
> > > Alameda, CA, USA
> > >
> > > 'Any technology distinguishable from magic is insufficiently advanced.'
> >  -Gehm's Corollary to Clarke's Third Law
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >
> > --
> > Important Notice: This mailbox is ignored: e-mails are set to be deleted
> > on receipt. Please respond to the mailing list if appropriate. For those
> > needing to send personal or professional e-mail, please use appropriate
> > addresses.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From alyssafatmah.mastura at g.msuiit.edu.ph  Thu Jan 18 16:15:08 2018
From: alyssafatmah.mastura at g.msuiit.edu.ph (ALYSSA FATMAH MASTURA)
Date: Thu, 18 Jan 2018 23:15:08 +0800
Subject: [R] MCMC Estimation for Four Parametric Logistic (4PL) Item
	Response Model
Message-ID: <CABjkMnnXamUBxrpDKYib97y8FFZ0fgOgswaP0j9A0p4CtsgY6w@mail.gmail.com>

Good day Sir/Ma'am! This is Alyssa Fatmah S. Mastura taking up Master of
Science in Statistics at Mindanao State University-Iligan Institute
Technology (MSU-IIT), Philippines. I am currently working on my master's
thesis titled "Comparing the Three Estimation Methods for the Four
Parametric Logistic (4PL) Item Response Model". While I am looking for a
package about Markov chain Monte Carlo (MCMC) method for 4PL model in this
R forum, I found an sirt package of an MCMC method but only for the three
parametric normal ogive (3PNO) item response model. However, my study focus
on 4PL model. In line with this, I would like to know if there exist a
function of MCMC method for 4PL model in R language. I am asking for your
help to inform me if such function exist. I highly appreciate your response
on this matter. Thank you so much. Have a great day ahead!



Alyssa

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

-- 
---
*DISCLAIMER AND CONFIDENTIALITY NOTICE* The Mindanao Sta...{{dropped:24}}


From pdalgd at gmail.com  Thu Jan 18 18:18:07 2018
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 18 Jan 2018 18:18:07 +0100
Subject: [R] reading lisp file in R
In-Reply-To: <CANVKczPQqGZOKBGXFpQaoOM8ZFQsqDRCL1OYCMnHpNwBGHPH7A@mail.gmail.com>
References: <20180117222241.e545855f9f9d7c79e67dbaf8@email.com>
 <01572A9E-F7C0-4D0D-8016-048D7A69E757@comcast.net>
 <20180117232555.463ea9ee32831be22b306c03@email.com>
 <4ceda7ab4e714962b230ccf6ad34a583@AM4PR0401MB1729.eurprd04.prod.outlook.com>
 <CANVKczPQqGZOKBGXFpQaoOM8ZFQsqDRCL1OYCMnHpNwBGHPH7A@mail.gmail.com>
Message-ID: <48BAD3EB-3621-4065-965C-7E09AFD6F659@gmail.com>

Yes, and the structure is obviously case-insensitive. More troublesome is probably that there can be multiple ACADEMIC-EMPHASIS entries, which can be tricky to tidify. Also one would need to figure out what is the meaning of lines like

(DEFPROP BOSTON-COLLEGE0 T DUPLICATE)

-pd

> On 18 Jan 2018, at 18:04 , Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
> 
> The file also has a bunch of email headers stuck in the middle of it:
> 
> 
> .....
> 
> (QUALITY-OF-LIFE SCALE:1-5 4)
>  (ACADEMIC-EMPHASIS HEALTH-SCIENCE)
> )
> -------
> -------
> 
> From LEBOWITZ at cs.columbia.edu Mon Feb 22 20:53:02 1988
> Received: from zodiac by meridian (5.52/4.7)
> Received: from Jessica.Stanford.EDU by ads.com (5.58/1.9)
>    id AA04539; Mon, 22 Feb 88 20:59:59 PST
> Received: from Portia.Stanford.EDU by jessica.Stanford.EDU with TCP; Mon,
> 22 Feb
> 88 20:58:22 PST
> Received: from columbia.edu (COLUMBIA.EDU.ARPA) by Portia.STANFORD.EDU
> (1.2/Ultrix2.0-B)
>    id AA11480; Mon, 22 Feb 88 20:49:53 pst
> Received: from CS.COLUMBIA.EDU by columbia.edu (5.54/1.14)
>    id AA10186; Mon, 22 Feb 88 23:48:44 EST
> Message-Id: <8802230448.AA10186 at columbia.edu>
> Date: Fri 22 Jan 88 02:50:00-EST
> From: The Mailer Daemon <Mailer at cs.columbia.edu>
> To: LEBOWITZ at cs.columbia.edu
> Subject: Message of 18-Jan-88 20:13:54
> Resent-Date: Mon 22 Feb 88 23:44:07-EST
> Resent-From: Michael Lebowitz <LEBOWITZ at cs.columbia.edu>
> Resent-To: souders at portia.stanford.edu
> Resent-Message-Id: <12376918538.25.LEBOWITZ at CS.COLUMBIA.EDU>
> Status: R
> 
> Message undeliverable and dequeued after 3 days:
> souders%meridian at ADS.ARPA: Cannot connect to host
>        ------------
> Date: Mon 18 Jan 88 20:13:54-EST
> From: Michael Lebowitz <LEBOWITZ at CS.COLUMBIA.EDU>
> Subject: bigger file part 3
> To: souders%meridian at ADS.ARPA
> In-Reply-To: <8801182147.AA08014 at ADS.ARPA>
> Message-ID: <12367705229.11.LEBOWITZ at CS.COLUMBIA.EDU>
> 
> (DEF-INSTANCE GEORGETOWN
>  (STATE MARYLAND)
>  (LOCATION URBAN)
>  (CONTROL PRIVATE)
>  (NO-OF-STUDENTS THOUS:10-15)
>  (MALE:FEMALE RATIO:45:55)
> ....
> 
> Which dates it to 1988. Nice.
> 
> Barry
> 
> 
> 
> On Thu, Jan 18, 2018 at 9:20 AM, Peter Crowther <peter.crowther at melandra.com
>> wrote:
> 
>> That's a nice example of why Lisp is both powerful and terrifying - you're
>> looking at a Lisp *program*, not just Lisp *data*, as Lisp makes no
>> distinction between the two.  You just read 'em in.
>> 
>> The two definitions at the bottom are function definitions.  The top one
>> defines the def-instance function.  Reading that indicates that it accepts
>> an atom as a name and a list of key-value or key-range-value lists as
>> properties, where they keys may be repeated to give you multi-valued
>> attributes in your result.  The bottom one defines a function for removing
>> duplicate entries of the same location.
>> 
>> The rest of the file (apart from the included email headers) is a whole
>> load of calls to the def-instance function.  In Lisp, you'd define the
>> functions, then just run the rest of the file.
>> 
>> To my knowledge, there is no generic way to read Lisp "data" into anything
>> else, because of this quirk that data can look like anything.  If anyone
>> can correct me on that, great, but I'd be somewhat surprised.  Therefore,
>> as David intimated, the tools you need are generic tools for handling text,
>> and you'll have to deal with the formatting yourself.  If I were doing a
>> one-off transform of this file, I'd probably reach for vi... but I'm an old
>> Unix hacker.  I certainly wouldn't teach that tooling.  awk or perl could
>> certainly handle it; or if you want to give students a wider view of the
>> world you might wish to try ANTLR and get them to write a grammar to parse
>> the file.  The Clojure grammar (
>> https://github.com/antlr/grammars-v4/blob/master/clojure/Clojure.g4) would
>> be an interesting place to start, although Terence Parr's comment of "match
>> a bunch of crap in parentheses" would probably give a flavour of what to
>> implement.  Depends what else the students are learning.
>> 
>> Hope this helps rather than hinders.
>> 
>> - Peter
>> 
>> On 18 January 2018 at 05:25, Ranjan Maitra <maitra at email.com> wrote:
>> 
>>> Thanks! I am trying to use it in R. (Actually, I try to give my students
>>> experiences with different kinds of files and I was wondering if there
>> were
>>> tools available for such kinds of files. I don't know Lisp so I do not
>>> actually know what the lines towards the bottom of the file mean.(
>>> 
>>> Many thanks for your response!
>>> 
>>> Best wishes,
>>> Ranjan
>>> 
>>> On Wed, 17 Jan 2018 20:59:48 -0800 David Winsemius <
>> dwinsemius at comcast.net>
>>> wrote:
>>> 
>>>> 
>>>>> On Jan 17, 2018, at 8:22 PM, Ranjan Maitra <maitra at email.com> wrote:
>>>>> 
>>>>> Dear friends,
>>>>> 
>>>>> Is there a way to read data files written in lisp into R?
>>>>> 
>>>>> Here is the file: https://archive.ics.uci.edu/
>>> ml/machine-learning-databases/university/university.data
>>>>> 
>>>>> I would like to read it into R. Any suggestions?
>>>> 
>>>> It's just a text file. What difficulties are you having?
>>>>> 
>>>>> 
>>>>> Thanks very much in advance for pointers on this and best wishes,
>>>>> Ranjan
>>>>> 
>>>>> --
>>>>> Important Notice: This mailbox is ignored: e-mails are set to be
>>> deleted on receipt. Please respond to the mailing list if appropriate.
>> For
>>> those needing to send personal or professional e-mail, please use
>>> appropriate addresses.
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>> 
>>>> 'Any technology distinguishable from magic is insufficiently advanced.'
>>> -Gehm's Corollary to Clarke's Third Law
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> 
>>> --
>>> Important Notice: This mailbox is ignored: e-mails are set to be deleted
>>> on receipt. Please respond to the mailing list if appropriate. For those
>>> needing to send personal or professional e-mail, please use appropriate
>>> addresses.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From HDoran at air.org  Thu Jan 18 18:32:51 2018
From: HDoran at air.org (Doran, Harold)
Date: Thu, 18 Jan 2018 17:32:51 +0000
Subject: [R] MCMC Estimation for Four Parametric Logistic (4PL)
	Item	Response Model
In-Reply-To: <CABjkMnnXamUBxrpDKYib97y8FFZ0fgOgswaP0j9A0p4CtsgY6w@mail.gmail.com>
References: <CABjkMnnXamUBxrpDKYib97y8FFZ0fgOgswaP0j9A0p4CtsgY6w@mail.gmail.com>
Message-ID: <DM2PR0501MB12802019258C4391446DDDD1CAE80@DM2PR0501MB1280.namprd05.prod.outlook.com>

I know of no existing functions for estimating the parameters of this model using MCMC or MML. Many years ago, I wrote code to estimate this model using marginal maximum likelihood. I wrote this based on the using nlminb and gauss-hermite quadrature points from statmod. 

I could not find that code to share with you, but I do have code for estimating the 3PL in this way and you could modify the likelihood for the upper asymptote yourself.



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of ALYSSA FATMAH MASTURA
Sent: Thursday, January 18, 2018 10:15 AM
To: r-help at r-project.org
Subject: [R] MCMC Estimation for Four Parametric Logistic (4PL) Item Response Model

Good day Sir/Ma'am! This is Alyssa Fatmah S. Mastura taking up Master of Science in Statistics at Mindanao State University-Iligan Institute Technology (MSU-IIT), Philippines. I am currently working on my master's thesis titled "Comparing the Three Estimation Methods for the Four Parametric Logistic (4PL) Item Response Model". While I am looking for a package about Markov chain Monte Carlo (MCMC) method for 4PL model in this R forum, I found an sirt package of an MCMC method but only for the three parametric normal ogive (3PNO) item response model. However, my study focus on 4PL model. In line with this, I would like to know if there exist a function of MCMC method for 4PL model in R language. I am asking for your help to inform me if such function exist. I highly appreciate your response on this matter. Thank you so much. Have a great day ahead!



Alyssa

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

--
---
*DISCLAIMER AND CONFIDENTIALITY NOTICE* The Mindanao Sta...{{dropped:9}}


From profjcnash at gmail.com  Thu Jan 18 18:56:19 2018
From: profjcnash at gmail.com (ProfJCNash)
Date: Thu, 18 Jan 2018 12:56:19 -0500
Subject: [R] MCMC Estimation for Four Parametric Logistic (4PL) Item
 Response Model
In-Reply-To: <DM2PR0501MB12802019258C4391446DDDD1CAE80@DM2PR0501MB1280.namprd05.prod.outlook.com>
References: <CABjkMnnXamUBxrpDKYib97y8FFZ0fgOgswaP0j9A0p4CtsgY6w@mail.gmail.com>
 <DM2PR0501MB12802019258C4391446DDDD1CAE80@DM2PR0501MB1280.namprd05.prod.outlook.com>
Message-ID: <0dd49be5-5426-0305-be60-4308c24e5029@gmail.com>

If you have the expression of the model, package nlsr should be able to
form the Jacobian analytically for nonlinear least squares. Likelihood
approaches allow for more sophisticated loss functions, but the
optimization is generally much less reliable because one is working
with essentially squared quantities and possibly multiple minima where
some are not the ones you want.

JN

On 2018-01-18 12:32 PM, Doran, Harold wrote:
> I know of no existing functions for estimating the parameters of this model using MCMC or MML. Many years ago, I wrote code to estimate this model using marginal maximum likelihood. I wrote this based on the using nlminb and gauss-hermite quadrature points from statmod. 
> 
> I could not find that code to share with you, but I do have code for estimating the 3PL in this way and you could modify the likelihood for the upper asymptote yourself.
> 
> 
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of ALYSSA FATMAH MASTURA
> Sent: Thursday, January 18, 2018 10:15 AM
> To: r-help at r-project.org
> Subject: [R] MCMC Estimation for Four Parametric Logistic (4PL) Item Response Model
> 
> Good day Sir/Ma'am! This is Alyssa Fatmah S. Mastura taking up Master of Science in Statistics at Mindanao State University-Iligan Institute Technology (MSU-IIT), Philippines. I am currently working on my master's thesis titled "Comparing the Three Estimation Methods for the Four Parametric Logistic (4PL) Item Response Model". While I am looking for a package about Markov chain Monte Carlo (MCMC) method for 4PL model in this R forum, I found an sirt package of an MCMC method but only for the three parametric normal ogive (3PNO) item response model. However, my study focus on 4PL model. In line with this, I would like to know if there exist a function of MCMC method for 4PL model in R language. I am asking for your help to inform me if such function exist. I highly appreciate your response on this matter. Thank you so much. Have a great day ahead!
> 
> 
> 
> Alyssa
> 
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> Virus-free.
> www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> 
> --
> ---
> *DISCLAIMER AND CONFIDENTIALITY NOTICE* The Mindanao Sta...{{dropped:9}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From redmonc at gmail.com  Thu Jan 18 19:00:35 2018
From: redmonc at gmail.com (Charlie Redmon)
Date: Thu, 18 Jan 2018 12:00:35 -0600
Subject: [R] Split charts with ggplot2, tidyquant
Message-ID: <2a39d9c8-a204-4060-e3de-3548ef5ada15@gmail.com>

Could you provide some information on your data structure (e.g., are the 
two time series in separate columns in the data)? The solution is fairly 
straightforward once you have the data in the right structure. And I do 
not think tidyquant is necessary for what you want.

Best,
Charlie

-- 
Charles Redmon
GRA, Center for Research Methods and Data Analysis
PhD Student, Department of Linguistics
University of Kansas
Lawrence, KS, USA


From therneau at mayo.edu  Thu Jan 18 20:38:17 2018
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 18 Jan 2018 19:38:17 +0000
Subject: [R] Time-dependent coefficients in a Cox model with categorical
 variants
In-Reply-To: <CAKpGb9B0GnqeE+_baFbTHdFzWu=wZ12wF5RRJ2sGuqhCpyUD3Q@mail.gmail.com>
References: <mailman.1.1516014001.49160.r-help@r-project.org>
 <375144$8lsfl0@ironport10.mayo.edu>
 <CAKpGb9B0GnqeE+_baFbTHdFzWu=wZ12wF5RRJ2sGuqhCpyUD3Q@mail.gmail.com>
Message-ID: <375144$8mnpjj@ironport10.mayo.edu>


First, as others have said please obey the mailing list rules and turn of
First, as others have said please obey the mailing list rules and turn off html, not everyone uses an html email client.

Here is your code, formatted and with line numbers added.  I also fixed one error: "y" should be "status".

1. fit0 <- coxph(Surv(futime, status) ~ x1 + x2 + x3, data = data0)
2. p <- log(predict(fit0, newdata = data1, type = "expected"))
3. lp <- predict(fit0, newdata = data1, type = "lp")
4. logbase <- p - lp
5. fit1 <- glm(status ~ offset(p), family = poisson, data = data1)
6. fit2 <- glm(status~ lp + offset(logbase), family = poisson, data = data1)
7. group <- cut(lp, c(-Inf, quantile(lp, (1:9) / 10), Inf))
8. fit3 <- glm(status ~ -1 + group + offset(p), family = poisson, data = data1)

The key idea of the paper you referenced is that the counterpart to the Hosmer-Lemishow test (wrong if used directly in a Cox model) is to look at the predicted values from a Cox model as input to a Poisson regression.  That means adding the expected from the Cox model as a fixed term in the Poisson.  And like any other poisson that means offset(log(expected)) as a term.

The presence of time dependent covariates does nothing to change this, per se, since expected for time fixed is the same as for time varying.  In practice it does matter, at least philosophically.  Lines 1, 2, 5 do this just fine.

If data1 is not the same as data0, a new study say, then the test for intercept=0 from fit1 is a test of overall calibration.  Models like line 8 try to partition out where any differences actually lie.

The time-dependent covariates part lies in the fact that a single subject may be represented by multiple lines in data0 and/or data1.  Do you want to collapse that person into a single row before the glm fits?  If subject "Jones" is represented by 15 lines in the data and "Smith" by 2, it does seem a bit unfair to give Jones 15 observations in the glm fit.  But full discussion of this is as much philosophy as statistics, and is perhaps best done over a beer.

Terry T.

________________________________
From: Max Shell [archerrish at gmail.com]
Sent: Wednesday, January 17, 2018 10:25 AM
To: Therneau, Terry M., Ph.D.
Subject: Re: Time-dependent coefficients in a Cox model with categorical variants

Assessing calibration of Cox model with time-dependent coefficients<https://stats.stackexchange.com/questions/323569/assessing-calibration-of-cox-model-with-time-dependent-coefficients>

I am trying to find methods for testing and visualizing calibration to Cox models with time-depended coefficients. I have read your nice article<http://journals.sagepub.com/doi/10.1177/0962280213497434>. In this paper, we can fit three models:

fit0 <- coxph(Surv(futime, status) ~ x1 + x2 + x3, data = data0) p <- log(predict(fit0, newdata = data1, type = "expected")) lp <- predict(fit0, newdata = data1, type = "lp") logbase <- p - lp fit1 <- glm(y ~ offset(p), family = poisson, data = data1) fit2 <- glm(y ~ lp + offset(logbase), family = poisson, data = data1) group <- cut(lp, c(-Inf, quantile(lp, (1:9) / 10), Inf)) fit3 <- glm(y ~ -1 + group + offset(p), family = poisson, data = data1)

Here$B!$(BI simplely use data1$B!!(B<- data0[1:500,]

First, I get following error when running line 5.

Error in eval(predvars, data, env) : object 'y' not found

So I modifited the code by replacing the y as status looks like this:

fit1 <- glm(status ~ offset(p), family = poisson, data = data1) fit2 <- glm(status ~ lp + offset(logbase), family = poisson, data = data1) group <- cut(lp, c(-Inf, quantile(lp, (1:9) / 10), Inf)) fit3 <- glm(status ~ -1 + group + offset(p), family = poisson, data = data1)

Is this replacing correct?

Second, I try to introduce the time-transform use coxph with ttparament.

My code is:  fit0 <- coxph(Surv(time, status) ~ x1 + x2 + x3 + tt(x3), data = data0, function(x, t, ...) x * t) p <- log(predict(fit0, newdata = data1, type = "expected")) lp <- predict(fit0, newdata = data1, type = "lp") logbase <- p - lp fit1 <- glm(status ~ offset(p), family = poisson, data = data1) fit2 <- glm(status ~ lp + offset(logbase), family = poisson, data = data1) group <- cut(lp, c(-Inf, quantile(lp, (1:9) / 10), Inf)) fit3 <- glm(status ~ -1 + group + offset(p), family = poisson, data = data1)

My questions is:

  *   Is the code above correct?
  *   How to interpret the fit1, fit2, fit3? What's the connection between the three models and the calibration of the Cox model?
  *   How to generate the calibration plot using fit3? The article dose have a section discuss this, but no code is provided.

Thank you!

On Mon, Jan 15, 2018 at 9:23 PM, Therneau, Terry M., Ph.D. <therneau at mayo.edu<mailto:therneau at mayo.edu>> wrote:
The model formula " ~ Histology" knows how to change your 3 level categorical variable into two 0/1 dummy variables for a regression matrix.  The tt() call is a simple function, however, and ordinary multiplication and does not have those powers.  In this case you need to do the setup by hand : create your own 0/1 dummy variables and work with them.

sqcc <- ifelse(dta$Histology == 'Sqcc', 0, 1)
hrac <- ifelse(dta$Histology == 'High risk AC', 0, 1)
fit <- coxph(Surv(time, status) ~ Sex + sqcc + hrac + tt(sqcc) + tt(hrac),
                 data = dta, tt = list(function(x,t, ...) x*log(t),
                                       function(x, t, ...) x* log(t)))


Terry Therneau

PS I've rarely found x*log(t) to be useful, but perhaps you have already looked at the cox.zph plots and see that shape.


Suppose I have a dataset contain three variants, looks like
head(dta)
   Sex    tumorsize    Histology       time         status
     0            1.5            2              12.1000             0
     1            1.8            1              38.4000             0
.....................

Sex: 1 for male; 0 for female., two levels
Histology: 1 for SqCC; 2 for High risk AC; 3 for low risk AC, three levels
Now I need to get a Time-dependent coefficients cox fit:

library(survival)
for(i in c(1,3) dta[,i] <- factor(dta[,i])
fit <-
   coxph(
     Surv(time, status) ~  Sex + tumorsize +  Histology + tt(Histology),
     data = dta,
     tt = function(x, t, ...) x * log(t)
   )

But  I keep gettting this error says:

Error in if (any(infs)) warning(paste("Loglik converged before variable ",  :
   missing value where TRUE/FALSE needed
In addition: Warning message:
In Ops.factor(x, log(t)) : ?*? not meaningful for factors.

How can I fix it? I know that the "Sex" and "Histology" are both
categorical variants. I  want to have a model that have two ?(t) = a +
blog(t) for each histology level.
Thank you?



	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Thu Jan 18 21:11:20 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Thu, 18 Jan 2018 22:11:20 +0200
Subject: [R] Split charts with ggplot2, tidyquant
In-Reply-To: <2a39d9c8-a204-4060-e3de-3548ef5ada15@gmail.com>
References: <2a39d9c8-a204-4060-e3de-3548ef5ada15@gmail.com>
Message-ID: <CAGgJW75ZCwdXt2wbOTPAo5o-PBR=kzdE5TNo+t8uZcTekfiNiA@mail.gmail.com>

Hi Charlie,
I am comfortable to put the data in any way that works best. Here are two
possibilities: an xts and a data frame.

library(quantmod)
quantmod::getSymbols("SPY")  # creates xts variable SPY
SPYxts <- SPY[,c("SPY.Close","SPY.Volume")]
SPYdf  <- data.frame(Date=index(SPYxts),close=as.numeric(SPYxts$SPY.Close),
                     volume=as.numeric(SPYxts$SPY.Volume))
rownames(SPYdf) <- NULL

head(SPYxts)
head(SPYdf)

#           SPY.Close SPY.Volume
#2007-01-03    141.37   94807600
#2007-01-04    141.67   69620600
#2007-01-05    140.54   76645300
#2007-01-08    141.19   71655000
#2007-01-09    141.07   75680100
#2007-01-10    141.54   72428000

#        Date  close   volume
#1 2007-01-03 141.37 94807600
#2 2007-01-04 141.67 69620600
#3 2007-01-05 140.54 76645300
#4 2007-01-08 141.19 71655000
#5 2007-01-09 141.07 75680100
#6 2007-01-10 141.54 72428000

Thanks,
Eric



On Thu, Jan 18, 2018 at 8:00 PM, Charlie Redmon <redmonc at gmail.com> wrote:

> Could you provide some information on your data structure (e.g., are the
> two time series in separate columns in the data)? The solution is fairly
> straightforward once you have the data in the right structure. And I do not
> think tidyquant is necessary for what you want.
>
> Best,
> Charlie
>
> --
> Charles Redmon
> GRA, Center for Research Methods and Data Analysis
> PhD Student, Department of Linguistics
> University of Kansas
> Lawrence, KS, USA
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Jan 18 21:13:56 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 18 Jan 2018 12:13:56 -0800
Subject: [R] Time-dependent coefficients in a Cox model with categorical
	variants
In-Reply-To: <375144$8mnpjj@ironport10.mayo.edu>
References: <mailman.1.1516014001.49160.r-help@r-project.org>
 <375144$8lsfl0@ironport10.mayo.edu>
 <CAKpGb9B0GnqeE+_baFbTHdFzWu=wZ12wF5RRJ2sGuqhCpyUD3Q@mail.gmail.com>
 <375144$8mnpjj@ironport10.mayo.edu>
Message-ID: <D8524D72-6C95-4006-8D06-00B44E005A06@dcn.davis.ca.us>

Offlist... for your information...

It is unfair to suggest that the mailing list participants are at fault for using old software.  Even if the mailing list participants use email programs that can handle HTML, any email that goes through the list gets the formatting stripped, which leaves it damaged to some degree. It might not seem like this because sometimes you CAN see formatting, but that only happens when you are listed in the "To" or "Cc" fields... the rest of the list saw a stripped version regardless of how good their mail program was. Just go look at the archives to confirm this. Net result is the rest of the participants see a more or less damaged version of the discussion/code whenever HTML is used on list.
-- 
Sent from my phone. Please excuse my brevity.

On January 18, 2018 11:38:17 AM PST, "Therneau, Terry M., Ph.D." <therneau at mayo.edu> wrote:
>
>First, as others have said please obey the mailing list rules and turn
>of
>First, as others have said please obey the mailing list rules and turn
>off html, not everyone uses an html email client.
>
>Here is your code, formatted and with line numbers added.  I also fixed
>one error: "y" should be "status".
>
>1. fit0 <- coxph(Surv(futime, status) ~ x1 + x2 + x3, data = data0)
>2. p <- log(predict(fit0, newdata = data1, type = "expected"))
>3. lp <- predict(fit0, newdata = data1, type = "lp")
>4. logbase <- p - lp
>5. fit1 <- glm(status ~ offset(p), family = poisson, data = data1)
>6. fit2 <- glm(status~ lp + offset(logbase), family = poisson, data =
>data1)
>7. group <- cut(lp, c(-Inf, quantile(lp, (1:9) / 10), Inf))
>8. fit3 <- glm(status ~ -1 + group + offset(p), family = poisson, data
>= data1)
>
>The key idea of the paper you referenced is that the counterpart to the
>Hosmer-Lemishow test (wrong if used directly in a Cox model) is to look
>at the predicted values from a Cox model as input to a Poisson
>regression.  That means adding the expected from the Cox model as a
>fixed term in the Poisson.  And like any other poisson that means
>offset(log(expected)) as a term.
>
>The presence of time dependent covariates does nothing to change this,
>per se, since expected for time fixed is the same as for time varying. 
>In practice it does matter, at least philosophically.  Lines 1, 2, 5 do
>this just fine.
>
>If data1 is not the same as data0, a new study say, then the test for
>intercept=0 from fit1 is a test of overall calibration.  Models like
>line 8 try to partition out where any differences actually lie.
>
>The time-dependent covariates part lies in the fact that a single
>subject may be represented by multiple lines in data0 and/or data1.  Do
>you want to collapse that person into a single row before the glm fits?
>If subject "Jones" is represented by 15 lines in the data and "Smith"
>by 2, it does seem a bit unfair to give Jones 15 observations in the
>glm fit.  But full discussion of this is as much philosophy as
>statistics, and is perhaps best done over a beer.
>
>Terry T.
>
>________________________________
>From: Max Shell [archerrish at gmail.com]
>Sent: Wednesday, January 17, 2018 10:25 AM
>To: Therneau, Terry M., Ph.D.
>Subject: Re: Time-dependent coefficients in a Cox model with
>categorical variants
>
>Assessing calibration of Cox model with time-dependent
>coefficients<https://stats.stackexchange.com/questions/323569/assessing-calibration-of-cox-model-with-time-dependent-coefficients>
>
>I am trying to find methods for testing and visualizing calibration to
>Cox models with time-depended coefficients. I have read your nice
>article<http://journals.sagepub.com/doi/10.1177/0962280213497434>. In
>this paper, we can fit three models:
>
>fit0 <- coxph(Surv(futime, status) ~ x1 + x2 + x3, data = data0) p <-
>log(predict(fit0, newdata = data1, type = "expected")) lp <-
>predict(fit0, newdata = data1, type = "lp") logbase <- p - lp fit1 <-
>glm(y ~ offset(p), family = poisson, data = data1) fit2 <- glm(y ~ lp +
>offset(logbase), family = poisson, data = data1) group <- cut(lp,
>c(-Inf, quantile(lp, (1:9) / 10), Inf)) fit3 <- glm(y ~ -1 + group +
>offset(p), family = poisson, data = data1)
>
>Here$B!$(BI simplely use data1$B!!(B<- data0[1:500,]
>
>First, I get following error when running line 5.
>
>Error in eval(predvars, data, env) : object 'y' not found
>
>So I modifited the code by replacing the y as status looks like this:
>
>fit1 <- glm(status ~ offset(p), family = poisson, data = data1) fit2 <-
>glm(status ~ lp + offset(logbase), family = poisson, data = data1)
>group <- cut(lp, c(-Inf, quantile(lp, (1:9) / 10), Inf)) fit3 <-
>glm(status ~ -1 + group + offset(p), family = poisson, data = data1)
>
>Is this replacing correct?
>
>Second, I try to introduce the time-transform use coxph with
>ttparament.
>
>My code is:  fit0 <- coxph(Surv(time, status) ~ x1 + x2 + x3 + tt(x3),
>data = data0, function(x, t, ...) x * t) p <- log(predict(fit0, newdata
>= data1, type = "expected")) lp <- predict(fit0, newdata = data1, type
>= "lp") logbase <- p - lp fit1 <- glm(status ~ offset(p), family =
>poisson, data = data1) fit2 <- glm(status ~ lp + offset(logbase),
>family = poisson, data = data1) group <- cut(lp, c(-Inf, quantile(lp,
>(1:9) / 10), Inf)) fit3 <- glm(status ~ -1 + group + offset(p), family
>= poisson, data = data1)
>
>My questions is:
>
>  *   Is the code above correct?
>*   How to interpret the fit1, fit2, fit3? What's the connection
>between the three models and the calibration of the Cox model?
>*   How to generate the calibration plot using fit3? The article dose
>have a section discuss this, but no code is provided.
>
>Thank you!
>
>On Mon, Jan 15, 2018 at 9:23 PM, Therneau, Terry M., Ph.D.
><therneau at mayo.edu<mailto:therneau at mayo.edu>> wrote:
>The model formula " ~ Histology" knows how to change your 3 level
>categorical variable into two 0/1 dummy variables for a regression
>matrix.  The tt() call is a simple function, however, and ordinary
>multiplication and does not have those powers.  In this case you need
>to do the setup by hand : create your own 0/1 dummy variables and work
>with them.
>
>sqcc <- ifelse(dta$Histology == 'Sqcc', 0, 1)
>hrac <- ifelse(dta$Histology == 'High risk AC', 0, 1)
>fit <- coxph(Surv(time, status) ~ Sex + sqcc + hrac + tt(sqcc) +
>tt(hrac),
>                 data = dta, tt = list(function(x,t, ...) x*log(t),
>                                       function(x, t, ...) x* log(t)))
>
>
>Terry Therneau
>
>PS I've rarely found x*log(t) to be useful, but perhaps you have
>already looked at the cox.zph plots and see that shape.
>
>
>Suppose I have a dataset contain three variants, looks like
>head(dta)
>   Sex    tumorsize    Histology       time         status
>     0            1.5            2              12.1000             0
>     1            1.8            1              38.4000             0
>.....................
>
>Sex: 1 for male; 0 for female., two levels
>Histology: 1 for SqCC; 2 for High risk AC; 3 for low risk AC, three
>levels
>Now I need to get a Time-dependent coefficients cox fit:
>
>library(survival)
>for(i in c(1,3) dta[,i] <- factor(dta[,i])
>fit <-
>   coxph(
>    Surv(time, status) ~  Sex + tumorsize +  Histology + tt(Histology),
>     data = dta,
>     tt = function(x, t, ...) x * log(t)
>   )
>
>But  I keep gettting this error says:
>
>Error in if (any(infs)) warning(paste("Loglik converged before variable
>",  :
>   missing value where TRUE/FALSE needed
>In addition: Warning message:
>In Ops.factor(x, log(t)) : ?*? not meaningful for factors.
>
>How can I fix it? I know that the "Sex" and "Histology" are both
>categorical variants. I  want to have a model that have two ?(t) = a +
>blog(t) for each histology level.
>Thank you?
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Thu Jan 18 21:42:14 2018
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 18 Jan 2018 15:42:14 -0500
Subject: [R] Perform mantel test on subset of distance matrix
In-Reply-To: <CAHWk_TmucRCp67vxJrdkR02e-jegM8gaCpgu=eSCJVf=M_XujA@mail.gmail.com>
References: <CAHWk_TmucRCp67vxJrdkR02e-jegM8gaCpgu=eSCJVf=M_XujA@mail.gmail.com>
Message-ID: <CAM_vju=Pk0s1-SmF+Sr-rXPX-sDaCeA8KbjCphjiRPfN+wONZQ@mail.gmail.com>

Hi Andrew,

Yes, you cannot have NA values in your matrices.
Instead, you could incorporate a model matrix.

See Legendre, P. & Fortin, M.J. Vegetatio (1989) 80: 107.
https://doi.org/10.1007/BF00048036
for ideas.

Sarah

On Sun, Dec 31, 2017 at 12:55 PM, Andrew Marx <andrewjmarx at gmail.com> wrote:
> I'm trying to perform a mantel test that ignores specific pairs in my
> distance matrices. The reasoning is that some geographic distances
> below a certain threshold suffer from spatial autocorrelation, or
> perhaps ecological relationships become less relevant that stochastic
> processes above a certain threshold.
>
> The problem is that I can't find a way to do it. If I replace values
> in either or both of the distance matrices with NA, mantel.rtest (ade4
> package) gives the following error: Error in if (any(distmat < tol))
> warning("Zero distance(s)") : missing value where TRUE/FALSE needed
>
> Here's a trivial example that tries to exclude elements of the first
> matrix that equal 11:
>
> library(ade4)
> a <- matrix(data = 1:36, nrow = 6)
> b <- matrix(data = 1:36, nrow = 6)
> a[a==11] <- NA
> mantel.rtest(as.dist(a), as.dist(b))
>
> Is there a way to do this, either with this package or another?
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From josh.m.ulrich at gmail.com  Thu Jan 18 22:24:06 2018
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 18 Jan 2018 15:24:06 -0600
Subject: [R] Split charts with ggplot2, tidyquant
In-Reply-To: <CAGgJW75ZCwdXt2wbOTPAo5o-PBR=kzdE5TNo+t8uZcTekfiNiA@mail.gmail.com>
References: <2a39d9c8-a204-4060-e3de-3548ef5ada15@gmail.com>
 <CAGgJW75ZCwdXt2wbOTPAo5o-PBR=kzdE5TNo+t8uZcTekfiNiA@mail.gmail.com>
Message-ID: <CAPPM_gRnnCBmE1=0ZE-Z+MNdG8K2Ey5TA_2mkwNqRH3-FkAPrA@mail.gmail.com>

If you don't want to wait for a ggplot2 solution, here are two
alternatives you can use right now:

chartSeries(SPYxts)
# or (with xts > 0.10
plot(SPYxts$SPY.Close)
addSeries(SPYxts$SPY.Volume, type = "h")

You might also try autoplot.zoo(), though I've never used it.




On Thu, Jan 18, 2018 at 2:11 PM, Eric Berger <ericjberger at gmail.com> wrote:
> Hi Charlie,
> I am comfortable to put the data in any way that works best. Here are two
> possibilities: an xts and a data frame.
>
> library(quantmod)
> quantmod::getSymbols("SPY")  # creates xts variable SPY
> SPYxts <- SPY[,c("SPY.Close","SPY.Volume")]
> SPYdf  <- data.frame(Date=index(SPYxts),close=as.numeric(SPYxts$SPY.Close),
>                      volume=as.numeric(SPYxts$SPY.Volume))
> rownames(SPYdf) <- NULL
>
> head(SPYxts)
> head(SPYdf)
>
> #           SPY.Close SPY.Volume
> #2007-01-03    141.37   94807600
> #2007-01-04    141.67   69620600
> #2007-01-05    140.54   76645300
> #2007-01-08    141.19   71655000
> #2007-01-09    141.07   75680100
> #2007-01-10    141.54   72428000
>
> #        Date  close   volume
> #1 2007-01-03 141.37 94807600
> #2 2007-01-04 141.67 69620600
> #3 2007-01-05 140.54 76645300
> #4 2007-01-08 141.19 71655000
> #5 2007-01-09 141.07 75680100
> #6 2007-01-10 141.54 72428000
>
> Thanks,
> Eric
>
>
>
> On Thu, Jan 18, 2018 at 8:00 PM, Charlie Redmon <redmonc at gmail.com> wrote:
>
>> Could you provide some information on your data structure (e.g., are the
>> two time series in separate columns in the data)? The solution is fairly
>> straightforward once you have the data in the right structure. And I do not
>> think tidyquant is necessary for what you want.
>>
>> Best,
>> Charlie
>>
>> --
>> Charles Redmon
>> GRA, Center for Research Methods and Data Analysis
>> PhD Student, Department of Linguistics
>> University of Kansas
>> Lawrence, KS, USA
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2018 | www.rinfinance.com


From traxplayer at gmail.com  Fri Jan 19 02:38:42 2018
From: traxplayer at gmail.com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Fri, 19 Jan 2018 02:38:42 +0100
Subject: [R] reading lisp file in R
In-Reply-To: <20180117222241.e545855f9f9d7c79e67dbaf8@email.com>
References: <20180117222241.e545855f9f9d7c79e67dbaf8@email.com>
Message-ID: <CAGAA5bdcECg6ufZ_Jc_Zb0ep_56iKMb+4CYzdwHX_oUERXGg6A@mail.gmail.com>

Here are the beginning of a R program.
I hope it can help you writing the rest of the program.

Regards
Martin M. S. Pedersen

----

filename <- "university.data"


lines <- readLines(filename)

first <- T

for (ALine in lines) {
ALine <- sub("^ +","",ALine)
ALine <- sub(")","",ALine, fixed = T)
if (length(grep("def-instance", ALine))) {
if (first) {
first = F
}
else {
cat(paste(instance,state,control,no_of_students_thous,"\n", sep  = ","))
}
instance <- sub("(def-instance ","",ALine, fixed = T)
next
}
if (length(grep("state ", ALine))) {
state <- sub("(state ","",ALine, fixed = T)
next
}
if (length(grep("control ", ALine))) {
control <- sub("(control ","", ALine, fixed = T)
next
}
if (length(grep("no-of-students thous:", ALine))) {
no_of_students_thous <- ALine
no_of_students_thous <- sub("(no-of-students thous:","", ALine, fixed = T)
next
}
}

	[[alternative HTML version deleted]]


From shijingeorge at yahoo.com  Thu Jan 18 22:36:18 2018
From: shijingeorge at yahoo.com (shijin mathew)
Date: Thu, 18 Jan 2018 21:36:18 +0000 (UTC)
Subject: [R] error while loading ggplot2
In-Reply-To: <31ECB0E5-BBF7-4C88-9F1E-CA22904F80C6@dcn.davis.ca.us>
References: <1169171028.115694.1516235826162.ref@mail.yahoo.com>
 <1169171028.115694.1516235826162@mail.yahoo.com>
 <31ECB0E5-BBF7-4C88-9F1E-CA22904F80C6@dcn.davis.ca.us>
Message-ID: <168868805.878183.1516311378146@mail.yahoo.com>

Thnaks Jeff.
Below is the session info you requested.
R version 3.4.3 (2017-11-30)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] reshape_0.8.7       Formula_1.2-2       survival_2.41-3     lattice_0.20-35    
 [5] versions_0.3        VIM_4.7.0           data.table_1.10.4-3 colorspace_1.3-2   
 [9] nnet_7.3-12         rpart_4.1-11        fBasics_3042.89     timeSeries_3042.102
[13] timeDate_3042.101   fpc_2.1-11          rattle_5.1.0       

loaded via a namespace (and not attached):
 [1] nlme_3.1-131        pbkrtest_0.4-7      RColorBrewer_1.1-2  prabclus_2.2-6     
 [5] tools_3.4.3         lazyeval_0.2.1      mgcv_1.8-22         trimcluster_0.1-2  
 [9] sp_1.2-6            compiler_3.4.3      quantreg_5.34       SparseM_1.77       
[13] diptest_0.75-7      scales_0.5.0        lmtest_0.9-35       DEoptimR_1.0-8     
[17] mvtnorm_1.0-6       robustbase_0.92-8   randomForest_4.6-12 spatial_7.3-11     
[21] stringr_1.2.0       minqa_1.2.4         lme4_1.1-15         rlang_0.1.6        
[25] zoo_1.8-1           mclust_5.4          car_2.1-6           magrittr_1.5       
[29] modeltools_0.2-21   Matrix_1.2-12       Rcpp_0.12.14        munsell_0.4.3      
[33] stringi_1.1.6       yaml_2.1.16         MASS_7.3-47         flexmix_2.3-14     
[37] plyr_1.8.4          parallel_3.4.3      splines_3.4.3       boot_1.3-20        
[41] stats4_3.4.3        XML_3.98-1.9        rpart.plot_2.1.2    laeken_0.4.6       
[45] vcd_1.4-4           nloptr_1.0.4        MatrixModels_0.4-1  gtable_0.2.0       
[49] kernlab_0.9-25      amap_0.8-14         e1071_1.6-8         class_7.3-14       
[53] cluster_2.0.6       RGtk2_2.20.33       

    On Wednesday, January 17, 2018, 11:34:17 PM PST, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:  
 
 Please post using plain text... the mailing list will strip HTML anyway and mess up what you send. 

Send the output of sessionInfo() so we know what versions of R and packages you have. 
-- 
Sent from my phone. Please excuse my brevity.

On January 17, 2018 4:37:06 PM PST, shijin mathew via R-help <r-help at r-project.org> wrote:
>Getting the following error while loading ggplot2.
>
>> library(ggplot2)
>Error: package or namespace load failed for ?ggplot2? in
>loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
> object 'vI' not found
>Tried different version of R and ggplot2 but still doesnt work.
>Any help to resolve is appreciated. Appreciate any pointers.
>-S
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.  
	[[alternative HTML version deleted]]


From resamae.sangco at g.msuiit.edu.ph  Fri Jan 19 07:47:55 2018
From: resamae.sangco at g.msuiit.edu.ph (RESA MAE SANGCO)
Date: Fri, 19 Jan 2018 14:47:55 +0800
Subject: [R] Bayesian Analysis in GJR-GARCH (p,
	d) model with Student-t innovations
Message-ID: <CAOFNkMtsWBFRv1Nu5mhRF+dk5Fea++j-KRUPzCT=Vrgox3iOvQ@mail.gmail.com>

Good day Ma'am/Sir, I am Resa Mae R. Sangco a Master of Statistics student
from the MSU- Iligan Institute of Technology located in Iligan City,
Philippines. I am currently doing my thesis entitled ?Bayesian Analysis in
GJR-GARCH (p,d) model with Student-t innovations". In finding my posterior
distribution since it is hard to integrate, I use Markov Chain Monte Carlo
simulation particularly the Metropolis-Hasting Algorithm. Now, I search a
package in R but I only found a package ?bayesGarch?  which performs the
Bayesian estimation of the GARCH(1,1) model with Student-t innovations. In
line with this, I would like to ask if there is a package/function exist in
the Bayesian estimation in the GJR-GARCH(p,d) model with student-t
innovation. Your response is highly appreciated. Thank you!

-- 
---
*DISCLAIMER AND CONFIDENTIALITY NOTICE* The Mindanao Sta...{{dropped:30}}


From Bernhard.Treutwein at Verwaltung.Uni-Muenchen.DE  Fri Jan 19 10:05:36 2018
From: Bernhard.Treutwein at Verwaltung.Uni-Muenchen.DE (Treutwein Bernhard)
Date: Fri, 19 Jan 2018 09:05:36 +0000
Subject: [R] flatpak installation package?
In-Reply-To: <7F250778-AC85-44E1-90AC-E7AFF2FE0946@dcn.davis.ca.us>
References: <78A8BD6765DCF048A628A51C3FBD1D76599868AF@MXS2.zuv.uni-muenchen.de>
 <7F250778-AC85-44E1-90AC-E7AFF2FE0946@dcn.davis.ca.us>
Message-ID: <78A8BD6765DCF048A628A51C3FBD1D76599A85ED@MXS2.zuv.uni-muenchen.de>

Hi Jeff,

> it is more likely that you will need to take on scratching that new itch.

thanks. Should I subscribe to the developer list and ask there?

I had a deep look into the Manual "R Installation and Administration", but I
fear that this is too much unknown terrain for me. Let me recall the apparent
advantages of flatpak:

It is a distribution independent package format, where the applications run
in a kind of sandbox. Flatpak is supported by RedHat/Fedora/CentOS/Scientific 
Linux as well as Debian/Ubuntu, and Arch. So it might be worth a deeper look.

Regards
--
  Bernhard


>-----Original Message-----
>From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>Sent: Tuesday, January 16, 2018 6:13 PM
>To: r-help at r-project.org; Treutwein Bernhard; 'r-help at r-project.org'
>Subject: Re: [R] flatpak installation package?
>
>Of course... R _is_ open source. However, it is unwise to assume that the
>volunteers scratching itches for their preferred distros will take on additional
>work... it is more likely that you will need to take on scratching that new itch.
>--
>Sent from my phone. Please excuse my brevity.
>
>On January 16, 2018 7:36:45 AM PST, Treutwein Bernhard
><Bernhard.Treutwein at Verwaltung.Uni-Muenchen.DE> wrote:
>>Is there any chance for a distribution independent flatpak installation
>>package for R ?
>>
>>See: http://flatpak.org
>>
>>Background: I recently bought an Acer notebook with endless OS
>>preinstalled
>>(see: http://endlessos.com).  It is Debian based, but uses only flatpak
>>as installation
>>package format.
>>
>>regards
>>--
>>? Bernhard Treutwein
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From Bernhard.Treutwein at Verwaltung.Uni-Muenchen.DE  Fri Jan 19 10:08:34 2018
From: Bernhard.Treutwein at Verwaltung.Uni-Muenchen.DE (Treutwein Bernhard)
Date: Fri, 19 Jan 2018 09:08:34 +0000
Subject: [R] flatpak installation package?
In-Reply-To: <78A8BD6765DCF048A628A51C3FBD1D76599A85E7@MXS2.zuv.uni-muenchen.de>
References: <78A8BD6765DCF048A628A51C3FBD1D76599868AF@MXS2.zuv.uni-muenchen.de>
 <7F250778-AC85-44E1-90AC-E7AFF2FE0946@dcn.davis.ca.us>
 <78A8BD6765DCF048A628A51C3FBD1D76599A85E7@MXS2.zuv.uni-muenchen.de>
Message-ID: <78A8BD6765DCF048A628A51C3FBD1D76599A9647@MXS2.zuv.uni-muenchen.de>

>It is a distribution independent package format, where the applications run
>in a kind of sandbox. Flatpak is supported by RedHat/Fedora/CentOS/Scientific
>Linux as well as Debian/Ubuntu, and Arch. >

See also: https://flatpak.org/getting.html 

--
  Bernhard

From Bernhard.Treutwein at Verwaltung.Uni-Muenchen.DE  Fri Jan 19 13:34:33 2018
From: Bernhard.Treutwein at Verwaltung.Uni-Muenchen.DE (Treutwein Bernhard)
Date: Fri, 19 Jan 2018 12:34:33 +0000
Subject: [R] request for code
In-Reply-To: <726D3E75-E422-4005-88C0-D9E3027C6B3F@me.com>
References: <CAPGkQHi6=YvkPkNgHP8EgLVMXNDdJGSpg1TaRHByNbUp_XAyng@mail.gmail.com>
 <726D3E75-E422-4005-88C0-D9E3027C6B3F@me.com>
Message-ID: <78A8BD6765DCF048A628A51C3FBD1D76599A98AA@MXS2.zuv.uni-muenchen.de>

>  http://www.math.umaine.edu/~hiebeler/comp/matlabR.pdf

You might also look up the book published by the same author, see
http://www.math.umaine.edu/~hiebeler/comp/matlabR.html

--
  Bernhard


From btyner at gmail.com  Fri Jan 19 13:49:00 2018
From: btyner at gmail.com (Benjamin Tyner)
Date: Fri, 19 Jan 2018 07:49:00 -0500
Subject: [R] setSessionLimit
Message-ID: <bfef7faa-289d-45fc-d067-cf5547feb877@gmail.com>

Hello

The doc/NEWS.2 file mentions a setSessionLimit function, added with 
version 2.8.0

 ??? o?? setTimeLimit() function to set limits on the CPU
 ??????? and/or elapsed time for each top-level computation, and
 ??????? setSessionLimit() to set limits for the rest of the session.

However, I no longer see this function in recent versions of R, and 
there is no mention of its removal in the NEWS nor in the svn log. So 
I'm curious to learn why it was removed...does anyone recall?

Regards

Ben


From casey.youngflesh at stonybrook.edu  Thu Jan 18 23:11:48 2018
From: casey.youngflesh at stonybrook.edu (Casey Youngflesh)
Date: Thu, 18 Jan 2018 17:11:48 -0500
Subject: [R] [R-pkgs] MCMCvis 0.9.2 on CRAN
Message-ID: <CADmCUH=S7OqD0JQ=CA3juEJz89Q9dbmF63jLuCkVyiPkXW-ibA@mail.gmail.com>

The latest version of `MCMCvis` is now available on CRAN.

`MCMCvis` is an R package used to visualize, manipulate, and summarize MCMC
output. MCMC output may be derived from Bayesian model output fit with
JAGS, Stan, or other MCMC samplers.

Improvements since the last CRAN release (0.8.1) include:

* ability to calculate and plot prior posterior overlap
* ability to return number of effective samples for each parameter
* ability to accept some arguments in regular expression format
* ability to easily subset mcmc.list objects into smaller mcmc.list objects
* function to retain structure of parameters (matrix parameters in model
will be summarized by function and returned in matrix format)
* speed improvements (particularly for large model objects)

CRAN: https://CRAN.R-project.org/package=MCMCvis
GitHub: https://github.com/caseyyoungflesh/MCMCvis

Full tutorial here: http://www.caseyyoungflesh.com/software/

Cheers,

Casey

-- 
*Casey Youngflesh*
Department of Ecology and Evolution
Stony Brook University
Stony Brook, NY 11794 USA
www.caseyyoungflesh.com <http://www.caseyyoungflesh.weebly.com>

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From murdoch.duncan at gmail.com  Fri Jan 19 15:18:33 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 19 Jan 2018 09:18:33 -0500
Subject: [R] setSessionLimit
In-Reply-To: <bfef7faa-289d-45fc-d067-cf5547feb877@gmail.com>
References: <bfef7faa-289d-45fc-d067-cf5547feb877@gmail.com>
Message-ID: <0d828504-6bfc-3e8e-52c9-8de228263cf3@gmail.com>

On 19/01/2018 7:49 AM, Benjamin Tyner wrote:
> Hello
> 
> The doc/NEWS.2 file mentions a setSessionLimit function, added with
> version 2.8.0
> 
>   ??? o?? setTimeLimit() function to set limits on the CPU
>   ??????? and/or elapsed time for each top-level computation, and
>   ??????? setSessionLimit() to set limits for the rest of the session.
> 
> However, I no longer see this function in recent versions of R, and
> there is no mention of its removal in the NEWS nor in the svn log. So
> I'm curious to learn why it was removed...does anyone recall?


That looks like a typo.  If you read the ?setTimeLimit help page, you'll 
see that it also documents setSessionTimeLimit.

Duncan Murdoch


From david.jankoski at hellotrip.nl  Fri Jan 19 15:58:09 2018
From: david.jankoski at hellotrip.nl (David Jankoski)
Date: Fri, 19 Jan 2018 15:58:09 +0100
Subject: [R] Web scraping different levels of a website
Message-ID: <CAOXhLq57uvMcPhGeHXQXwbashzeMKmf3mgeKQUAPbu+dT6GSiA@mail.gmail.com>

Hey Ilio,

I revisited the previous code i posted to you and fixed some things.
This should let you collect as many studies as you like, controlled by
the num_studies arg.

If you try the below url in your browser you can see that it returns a
"simpler" version of the link you posted. To get to this you need to
hit F12 to open Developer Tools --> go to Network tab and click on the
first entry in the list --> in the right pane you should see under the
Headers tab the Request URL.

I'm not very knowledgable in sessions/cookies and what nots - but it
might be that you face some further problems. In which case you could
try to do the above on your side and then copy paste that url that you
find there in the below code. I broke the url in smaller chunks for
readability and because its easier to substitute some query
paramaters.

# load libs
library("rvest")
library("httr")
library("glue")
library("magrittr")

# number of studies to pull from catalogue
num_studies <- 42
year_from <- 1890
year_to <- 2017

# build up the url
url <-
  glue(
    "http://catalog.ihsn.org/index.php/catalog/",
    "search?view=s&",
    "ps={num_studies}&",
    "page=1&repo=&repo_ref=&sid=&_r=&sk=&vk=&",
    "from={year_from}&",
    "to={year_to}&",
    "sort_order=&sort_by=nation&_=1516371984886")

# read in the html
x <-
  url %>%
  GET() %>%
  content()

# option 1 (div with class "survey-row" --> data-url attribute)
x %>%
  html_nodes(".survey-row") %>%
  html_attr("data-url")

# option 2 (studies titles are <a> within <h2> elems)
# note that this give you some more information like the title ...
x %>%
  html_nodes("h2 a")


greetings,
david

On 18 January 2018 at 12:58, David Jankoski <david.jankoski at hellotrip.nl> wrote:
>
> Hey Ilio,
>
> On the main website (the first link that you provided) if you
> right-click on the title of any entry and select Inspect Element from
> the menu, you will notice in the Developer Tools view that opens up
> that the corresponding html looks like this
>
> (example for the same link that you provided)
>
> <div class="survey-row"
> data-url="http://catalog.ihsn.org/index.php/catalog/7118" title="View
> study">
>     <div class="data-access-icon data-access-remote" title="Data
> available from external repository"></div>
>         <h2 class="title">
>             <a href="http://catalog.ihsn.org/index.php/catalog/7118"
> title="Demographic and Health Survey 2015">
>               Demographic and Health Survey 2015
>             </a>
>       </h2>
>
> Notice how the number you are after is contained within the
> "survey-row" div element, in the data-url attribute. Or alternatively
> withing the <a> elem within the href attribute. It's up to you which
> one you want to grab but the idea would be the same i.e.
>
> 1. read in the html
> 2. select all list-elements by css / xpath
> 3. grab the fwd link
>
> Here is an example using the first option.
>
> url <- "http://catalog.ihsn.org/index.php/catalog#_r=&collection=&country=&dtype=&from=1890&page=1&ps=100&sid=&sk=&sort_by=nation&sort_order=&to=2017&topic=&view=s&vk="
>
> x <-
>   url %>%
>   GET() %>%
>   content()
>
> x %>%
>   html_nodes(".survey-row") %>%
>   html_attr("data-url")
>
> hth.
> david




-- 

David Jankoski

Teerketelsteeg 1
1012TB Amsterdam
www.hellotrip.com


From redmonc at gmail.com  Fri Jan 19 17:33:56 2018
From: redmonc at gmail.com (Charlie Redmon)
Date: Fri, 19 Jan 2018 10:33:56 -0600
Subject: [R] Split charts with ggplot2, tidyquant
In-Reply-To: <CAGgJW75ZCwdXt2wbOTPAo5o-PBR=kzdE5TNo+t8uZcTekfiNiA@mail.gmail.com>
References: <2a39d9c8-a204-4060-e3de-3548ef5ada15@gmail.com>
 <CAGgJW75ZCwdXt2wbOTPAo5o-PBR=kzdE5TNo+t8uZcTekfiNiA@mail.gmail.com>
Message-ID: <48135866-cc09-a588-8f54-0ca242c0e79a@gmail.com>

So the general strategy for getting these into separate panels in ggplot 
is to have a single variable that will be your response and a factor 
variable that indexes which original variable it came from. This can be 
accomplished in many ways, but the way I use is with the melt() function 
in the reshape2 package.
For example,

library(reshape2)
plotDF <- melt(SPYdf,
 ??? ??? ??? ??? ??? ??? id.vars="Date", # variables to replicate
 ??? ??? ??? ??? ??? ??? measure.vars=c("close", "volume"), # variables 
to create index from
 ??? ??? ??? ??? ??? ??? variable.name="parameter", # name of new 
variable for index
 ??? ??? ??? ??? ??? ??? value.name="resp") # name of what will be your 
response variable

Now the ggplot2 code:

library(ggplot2)
ggplot(plotDF, aes(x=Date, y=resp)) +
 ??? facet_wrap(~parameter, ncol=1, scales="free") +
 ??? geom_line()


Hope that does the trick!

Charlie


On 01/18/2018 02:11 PM, Eric Berger wrote:
> Hi Charlie,
> I am comfortable to put the data in any way that works best. Here are 
> two possibilities: an xts and a data frame.
>
> library(quantmod)
> quantmod::getSymbols("SPY")? # creates xts variable SPY
> SPYxts <- SPY[,c("SPY.Close","SPY.Volume")]
> SPYdf? <- 
> data.frame(Date=index(SPYxts),close=as.numeric(SPYxts$SPY.Close),
> ?volume=as.numeric(SPYxts$SPY.Volume))
> rownames(SPYdf) <- NULL
>
> head(SPYxts)
> head(SPYdf)
>
> #? ? ? ? ? ?SPY.Close SPY.Volume
> #2007-01-03? ? 141.37? ?94807600
> #2007-01-04? ? 141.67? ?69620600
> #2007-01-05? ? 140.54? ?76645300
> #2007-01-08? ? 141.19? ?71655000
> #2007-01-09? ? 141.07? ?75680100
> #2007-01-10? ? 141.54? ?72428000
>
> #? ? ? ? Date? close? ?volume
> #1 2007-01-03 141.37 94807600
> #2 2007-01-04 141.67 69620600
> #3 2007-01-05 140.54 76645300
> #4 2007-01-08 141.19 71655000
> #5 2007-01-09 141.07 75680100
> #6 2007-01-10 141.54 72428000
>
> Thanks,
> Eric
>
>
>
> On Thu, Jan 18, 2018 at 8:00 PM, Charlie Redmon <redmonc at gmail.com 
> <mailto:redmonc at gmail.com>> wrote:
>
>     Could you provide some information on your data structure (e.g.,
>     are the two time series in separate columns in the data)? The
>     solution is fairly straightforward once you have the data in the
>     right structure. And I do not think tidyquant is necessary for
>     what you want.
>
>     Best,
>     Charlie
>
>     -- 
>     Charles Redmon
>     GRA, Center for Research Methods and Data Analysis
>     PhD Student, Department of Linguistics
>     University of Kansas
>     Lawrence, KS, USA
>
>

-- 
Charles Redmon
GRA, Center for Research Methods and Data Analysis
PhD Student, Department of Linguistics
University of Kansas
Lawrence, KS, USA


From G.Rudge at bham.ac.uk  Fri Jan 19 18:51:48 2018
From: G.Rudge at bham.ac.uk (Gavin Rudge (Institute of Applied Health Research))
Date: Fri, 19 Jan 2018 17:51:48 +0000
Subject: [R] Leaflet maps.  Nudging co-incident markers
Message-ID: <B8D87DA108D62D448DBE22A7775AB6BB016F43989B@EX11.adf.bham.ac.uk>

I have a dataset showing points, with a category for each point and its location.

I simply want to display my points, in a way that users can toggle the points on and off by category.

Where I have two objects in the same category I'd like to display them nudged to appear as two distinct, but very close points.
I have made reproduceable example (the places are not real), which is loosely based on a tutorial I found recently (https://allthisblog.wordpress.com/2016/10/12/r-311-with-leaflet-tutorial/)

I have three categories of things (cafes, libraries and galleries), at three locations but have four objects in my set. This is because on of my locations has two functions - there is a cafe at a gallery (North St Gallery and the Gallery Cafe on the same site)    

If I make a selection that includes galleries and cafes there are just two points. I would like to nudge the point for the North St Galley and the Gallery Cafe so they appear as two (very close) points on the map and display the name when clicked on.

Also if anyone has any suggestions for generally tidying up the code I'd be grateful as my real version is much more complex with many more points and marker categories.   I believe there are Java libraries out there for managing markers and how they behave, but I'm hoping this can be done in the Leaflet R library somehow. 

The only solution I could think of was to interrogate the entire dataframe, identify points that were had the same co-ords and move them diagonally apart by adding and subtracting a fixed amount of longitude and latitude from the co-ordinates. 

Thanks in advance.

GavinR

Here is the code:

library(leaflet)

#make data frame of points

idno=c(1,2,3,4)
x=c(-1.9116, -1.9116,-1.9237,-1.91848)
y=c(52.4898,52.4898,52.5015,52.4851)
cat=c('Gallery','Cafe','Library','Cafe')
n=c('North St Gallery','Gallery cafe', 'South St Library', 'Coffee 2 go')
d<-data.frame(idno,x,y,cat,n)

#get a map and zoom into approx area of interest

m=leaflet()%>% setView(lng = -1.935, lat=52.485, zoom=12)
m=addTiles(m) 
m

#create groups of objects

c= subset(d,cat=="Cafe")
l= subset(d, cat=="Library")
g= subset(d, cat=="Gallery")  

#add markers
  
m=addCircleMarkers(m,
                     lng = c$x,
                     lat = c$y,
                     popup = c$n,
                     radius = 5,
                     stroke =FALSE,
                     fillOpacity = 0.75,
                     group = "1 - Cafes")
 
m=addCircleMarkers(m,
                   lng = g$x,
                   lat = g$y,
                   popup = g$n,
                   radius = 5,
                   stroke =FALSE,
                   fillOpacity = 0.75,
                   group = "2 - Galleries")

m=addCircleMarkers(m,
                   lng = l$x,
                   lat = l$y,
                   popup = l$n,
                   radius = 5,
                   stroke =FALSE,
                   fillOpacity = 0.75,
                   group = "3 - libraries")

m = addLayersControl(m, overlayGroups = c("1 - Cafes","2 - Galleries","3 - libraries"))

m


From dking at havertys.com  Fri Jan 19 15:57:34 2018
From: dking at havertys.com (Daniel King)
Date: Fri, 19 Jan 2018 14:57:34 +0000
Subject: [R] IBM Power vs Markdown
In-Reply-To: <MWHPR11MB0046246F011A47F85FF8294ECCE80@MWHPR11MB0046.namprd11.prod.outlook.com>
References: <MWHPR11MB0046246F011A47F85FF8294ECCE80@MWHPR11MB0046.namprd11.prod.outlook.com>
Message-ID: <MWHPR11MB0046B9D9D74778689682E5B8CCEF0@MWHPR11MB0046.namprd11.prod.outlook.com>


Hi, folks.

I was wondering if any of you could point me in the right direction.

Using R 3.3.3 (and later), on an IBM Power LPAR, Red Hat 7 PPC64le, markdown build fails as below.

> install.packages("markdown")
trying URL 'https://cloud.r-project.org/src/contrib/markdown_0.8.tar.gz'
Content type 'unknown' length 80583 bytes (78 KB) ==================================================
downloaded 78 KB

installing source package 'markdown' ...
** package 'markdown' successfully unpacked and MD5 sums checked
** libs
/opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c Rbase64.c -o Rbase64.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c Rinit.c -o Rinit.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c Rmarkdown.c -o Rmarkdown.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c autolink.c -o autolink.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c buffer.c -o buffer.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c houdini_href_e.c -o houdini_href_e.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c houdini_html_e.c -o houdini_html_e.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c html.c -o html.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c html_smartypants.c -o html_smartypants.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c markdown.c -o markdown.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c stack.c -o stack.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -qmkshrobj -shared -L/usr/local/lib64/R/lib -L/usr/local/lib64 -o markdown.so Rbase64.o Rinit.o Rmarkdown.o autolink.o buffer.o houdini_href_e.o houdini_html_e.o html.o html_smartypants.o markdown.o stack.o -L/usr/local/lib64/R/lib -lR
markdown.o: In function find_block_tag': /tmp/RtmpqYsbzz/R.INSTALL1cb764af1cf/markdown/src/./html_blocks.h:206: undefined reference tofind_block_tag$AF85_1'
/usr/bin/ld: markdown.so: internal symbol `find_block_tag$AF85_1' isn't defined
/usr/bin/ld: final link failed: Bad value
make: *** [markdown.so] Error 1
ERROR: compilation failed for package 'markdown'
removing '/usr/local/lib64/R/library/markdown'
The downloaded source packages are in
'/tmp/Rtmpl7vFYx/downloaded_packages'
Updating HTML index of packages in '.Library'
Making 'packages.html' ... done
Warning message:
In install.packages("markdown") :
installation of package 'markdown' had non-zero exit status

...

It looks like the issue can be traced down to, "!gperf_case_strncmp (str, s, len)" ... is there a way to trace this down further?

# tail markdown/src/html_blocks.h
      if (key <= MAX_HASH_VALUE && key >= 0)
        {
          register const char *s = wordlist[key];

          if ((((unsigned char)*str ^ (unsigned char)*s) & ~32) == 0 && !gperf_case_strncmp (str, s, len) && s[len] == '\0')
            return s;
        }
    }
  return 0;
}

Any assistance is appreciated.

A. Daniel King
Haverty Furniture Companies, Inc.


From marc_schwartz at me.com  Fri Jan 19 19:22:33 2018
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 19 Jan 2018 13:22:33 -0500
Subject: [R] IBM Power vs Markdown
In-Reply-To: <MWHPR11MB0046B9D9D74778689682E5B8CCEF0@MWHPR11MB0046.namprd11.prod.outlook.com>
References: <MWHPR11MB0046246F011A47F85FF8294ECCE80@MWHPR11MB0046.namprd11.prod.outlook.com>
 <MWHPR11MB0046B9D9D74778689682E5B8CCEF0@MWHPR11MB0046.namprd11.prod.outlook.com>
Message-ID: <F78BEDEB-7E29-4918-8F25-C598C76271AE@me.com>

Hi,

As I was doing some searching, it would appear that you also posted to the package's GitHub repo and obtained a solution there:

  https://github.com/rstudio/markdown/issues/88

For specific packages, in situations like this, contacting the package maintainer as you did, is a good first step.

For future reference, since you are running on RH, there is the R-SIG-Fedora list, which covers issues associated with running R on RH and Fedora based distros:

  https://stat.ethz.ch/mailman/listinfo/r-sig-fedora

Regards,

Marc Schwartz


> On Jan 19, 2018, at 9:57 AM, Daniel King <dking at havertys.com> wrote:
> 
> 
> Hi, folks.
> 
> I was wondering if any of you could point me in the right direction.
> 
> Using R 3.3.3 (and later), on an IBM Power LPAR, Red Hat 7 PPC64le, markdown build fails as below.
> 
>> install.packages("markdown")
> trying URL 'https://cloud.r-project.org/src/contrib/markdown_0.8.tar.gz'
> Content type 'unknown' length 80583 bytes (78 KB) ==================================================
> downloaded 78 KB
> 
> installing source package 'markdown' ...
> ** package 'markdown' successfully unpacked and MD5 sums checked
> ** libs
> /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c Rbase64.c -o Rbase64.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c Rinit.c -o Rinit.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c Rmarkdown.c -o Rmarkdown.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c autolink.c -o autolink.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c buffer.c -o buffer.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c houdini_href_e.c -o houdini_href_e.o /opt/ibm/xlC/13.1.
> 6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c houdini_html_e.c -o houdini_html_e.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c html.c -o html.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c html_smartypants.c -o html_smartypants.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c markdown.c -o markdown.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -I/usr/local/lib64/R/include -DNDEBUG -I/usr/local/include -qpic -g -O2 -qstrict -qfloat=nomaf:fenv -c stack.c -o stack.o /opt/ibm/xlC/13.1.6/bin/xlc_r -q64 -qmkshrobj -shared -L/usr/local/lib64/R/lib -L/usr/local/lib64 -o markdown.so Rbase64.o Rinit.o Rmarkdown.o autolink.o buffer.o houdini_href_e.o houdin
> i_html_e.o html.o html_smartypants.o markdown.o stack.o -L/usr/local/lib64/R/lib -lR
> markdown.o: In function find_block_tag': /tmp/RtmpqYsbzz/R.INSTALL1cb764af1cf/markdown/src/./html_blocks.h:206: undefined reference tofind_block_tag$AF85_1'
> /usr/bin/ld: markdown.so: internal symbol `find_block_tag$AF85_1' isn't defined
> /usr/bin/ld: final link failed: Bad value
> make: *** [markdown.so] Error 1
> ERROR: compilation failed for package 'markdown'
> removing '/usr/local/lib64/R/library/markdown'
> The downloaded source packages are in
> '/tmp/Rtmpl7vFYx/downloaded_packages'
> Updating HTML index of packages in '.Library'
> Making 'packages.html' ... done
> Warning message:
> In install.packages("markdown") :
> installation of package 'markdown' had non-zero exit status
> 
> ...
> 
> It looks like the issue can be traced down to, "!gperf_case_strncmp (str, s, len)" ... is there a way to trace this down further?
> 
> # tail markdown/src/html_blocks.h
>      if (key <= MAX_HASH_VALUE && key >= 0)
>        {
>          register const char *s = wordlist[key];
> 
>          if ((((unsigned char)*str ^ (unsigned char)*s) & ~32) == 0 && !gperf_case_strncmp (str, s, len) && s[len] == '\0')
>            return s;
>        }
>    }
>  return 0;
> }
> 
> Any assistance is appreciated.
> 
> A. Daniel King
> Haverty Furniture Companies, Inc.


From ericjberger at gmail.com  Fri Jan 19 20:39:43 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Fri, 19 Jan 2018 21:39:43 +0200
Subject: [R] Split charts with ggplot2, tidyquant
In-Reply-To: <48135866-cc09-a588-8f54-0ca242c0e79a@gmail.com>
References: <2a39d9c8-a204-4060-e3de-3548ef5ada15@gmail.com>
 <CAGgJW75ZCwdXt2wbOTPAo5o-PBR=kzdE5TNo+t8uZcTekfiNiA@mail.gmail.com>
 <48135866-cc09-a588-8f54-0ca242c0e79a@gmail.com>
Message-ID: <CAGgJW76zved0JXzGVVUfjxJRxhK=aGNPvqWaVTfSeAtYMC8cow@mail.gmail.com>

Hi Charlie,
Thanks. This is helpful. As mentioned in my original question, I want to be
able to plot a few such charts on the same page,
say a 2 x 2 grid with such a chart for each of 4 different stocks. Using
your solution I accomplished this by making
a list pLst of your ggplots and then calling cowplot::plot_grid(
plotlist=pLst, nrow=2, ncol=2 )  That worked fine.

The one issue  I have is that in the ggplot you suggest, the price and
volume facets are the same size. I would like them to be different sizes
(e.g. the volume facet at the bottom is generally shown smaller than the
facet above it in these types of charts.)

I tried to find out how to do it but didn't succeed. I found a couple of
relevant discussions (including Hadley writing that he did not think it was
a useful feature. :-()

https://github.com/tidyverse/ggplot2/issues/566

and an ancient one where someone seems to have been able to get a heights
parameter working in a call to facet_grid but it did not work for me.
https://kohske.wordpress.com/2010/12/25/adjusting-the-relative-space-of-a-facet-grid/

Thanks again,
Eric

p.s. Joshua thanks for your suggestions, but I was hoping for a ggplot
solution.


On Fri, Jan 19, 2018 at 6:33 PM, Charlie Redmon <redmonc at gmail.com> wrote:

> So the general strategy for getting these into separate panels in ggplot
> is to have a single variable that will be your response and a factor
> variable that indexes which original variable it came from. This can be
> accomplished in many ways, but the way I use is with the melt() function in
> the reshape2 package.
> For example,
>
> library(reshape2)
> plotDF <- melt(SPYdf,
>                         id.vars="Date", # variables to replicate
>                         measure.vars=c("close", "volume"), # variables to
> create index from
>                         variable.name="parameter", # name of new variable
> for index
>                         value.name="resp") # name of what will be your
> response variable
>
> Now the ggplot2 code:
>
> library(ggplot2)
> ggplot(plotDF, aes(x=Date, y=resp)) +
>     facet_wrap(~parameter, ncol=1, scales="free") +
>     geom_line()
>
>
> Hope that does the trick!
>
> Charlie
>
>
>
> On 01/18/2018 02:11 PM, Eric Berger wrote:
>
>> Hi Charlie,
>> I am comfortable to put the data in any way that works best. Here are two
>> possibilities: an xts and a data frame.
>>
>> library(quantmod)
>> quantmod::getSymbols("SPY")  # creates xts variable SPY
>> SPYxts <- SPY[,c("SPY.Close","SPY.Volume")]
>> SPYdf  <- data.frame(Date=index(SPYxts),close=as.numeric(SPYxts$SPY.Cl
>> ose),
>>  volume=as.numeric(SPYxts$SPY.Volume))
>> rownames(SPYdf) <- NULL
>>
>> head(SPYxts)
>> head(SPYdf)
>>
>> #           SPY.Close SPY.Volume
>> #2007-01-03    141.37   94807600
>> #2007-01-04    141.67   69620600
>> #2007-01-05    140.54   76645300
>> #2007-01-08    141.19   71655000
>> #2007-01-09    141.07   75680100
>> #2007-01-10    141.54   72428000
>>
>> #        Date  close   volume
>> #1 2007-01-03 141.37 94807600
>> #2 2007-01-04 141.67 69620600
>> #3 2007-01-05 140.54 76645300
>> #4 2007-01-08 141.19 71655000
>> #5 2007-01-09 141.07 75680100
>> #6 2007-01-10 141.54 72428000
>>
>> Thanks,
>> Eric
>>
>>
>>
>> On Thu, Jan 18, 2018 at 8:00 PM, Charlie Redmon <redmonc at gmail.com
>> <mailto:redmonc at gmail.com>> wrote:
>>
>>     Could you provide some information on your data structure (e.g.,
>>     are the two time series in separate columns in the data)? The
>>     solution is fairly straightforward once you have the data in the
>>     right structure. And I do not think tidyquant is necessary for
>>     what you want.
>>
>>     Best,
>>     Charlie
>>
>>     --     Charles Redmon
>>     GRA, Center for Research Methods and Data Analysis
>>     PhD Student, Department of Linguistics
>>     University of Kansas
>>     Lawrence, KS, USA
>>
>>
>>
> --
> Charles Redmon
> GRA, Center for Research Methods and Data Analysis
> PhD Student, Department of Linguistics
> University of Kansas
> Lawrence, KS, USA
>
>

	[[alternative HTML version deleted]]


From mdwy62 at yahoo.com  Fri Jan 19 19:47:56 2018
From: mdwy62 at yahoo.com (Mark Dwyer)
Date: Fri, 19 Jan 2018 10:47:56 -0800
Subject: [R] how to search r-help?
Message-ID: <3a9e52dc-d1ff-3f91-9f73-e84da5ce3fbf@yahoo.com>

I am new to this listand am unable to get the search tools listed on 
https://stat.ethz.ch/mailman/listinfo/r-help towork. What do people use 
to search the help archives?

 1. The google search box on http://tolstoy.newcastle.edu.au/~rking/R/
    returns a 404 error.
 2. The http://finzi.psych.upenn.edu/ site has many references but I
    don't see how to search r-help from there.
 3. The http://www.mail-archive.com/r-help at stat.math.ethz.ch/ site seems
    to stop back in December 2007.
 4. I cannot get anything useful from
    http://dir.gmane.org/gmane.comp.lang.r.general.

Thanks.

- Mark Dwyer


	[[alternative HTML version deleted]]


From mdwy62 at yahoo.com  Fri Jan 19 19:57:57 2018
From: mdwy62 at yahoo.com (Mark Dwyer)
Date: Fri, 19 Jan 2018 10:57:57 -0800
Subject: [R] how to search r-help?
In-Reply-To: <3a9e52dc-d1ff-3f91-9f73-e84da5ce3fbf@yahoo.com>
References: <3a9e52dc-d1ff-3f91-9f73-e84da5ce3fbf@yahoo.com>
Message-ID: <8960a8f2-d255-ac7d-dfd5-6b0ab2e1ca83@yahoo.com>

Also https://www.r-project.org/posting-guide.html indicates that 
RSiteSearch() within R searches R-help but in my install (3.4.3) 
RSiteSearch() only searches? "help pages, vignettes or taskviews"


On 19/01/18 10:47, Mark Dwyer wrote:
>
> I am new to this listand am unable to get the search tools listed on 
> https://stat.ethz.ch/mailman/listinfo/r-help towork. What do people 
> use to search the help archives?
>
>  1. The google search box on http://tolstoy.newcastle.edu.au/~rking/R/
>     returns a 404 error.
>  2. The http://finzi.psych.upenn.edu/ site has many references but I
>     don't see how to search r-help from there.
>  3. The http://www.mail-archive.com/r-help at stat.math.ethz.ch/ site
>     seems to stop back in December 2007.
>  4. I cannot get anything useful from
>     http://dir.gmane.org/gmane.comp.lang.r.general.
>
> Thanks.
>
> - Mark Dwyer
>


From dwinsemius at comcast.net  Fri Jan 19 21:55:46 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 19 Jan 2018 12:55:46 -0800
Subject: [R] how to search r-help?
In-Reply-To: <8960a8f2-d255-ac7d-dfd5-6b0ab2e1ca83@yahoo.com>
References: <3a9e52dc-d1ff-3f91-9f73-e84da5ce3fbf@yahoo.com>
 <8960a8f2-d255-ac7d-dfd5-6b0ab2e1ca83@yahoo.com>
Message-ID: <E641A2E6-8857-46D4-83BF-29FFAF6A78E9@comcast.net>


> On Jan 19, 2018, at 10:57 AM, Mark Dwyer via R-help <r-help at r-project.org> wrote:
> 
> Also https://www.r-project.org/posting-guide.html indicates that RSiteSearch() within R searches R-help but in my install (3.4.3) RSiteSearch() only searches  "help pages, vignettes or taskviews"
> 
> 
> On 19/01/18 10:47, Mark Dwyer wrote:
>> 
>> I am new to this listand am unable to get the search tools listed on https://stat.ethz.ch/mailman/listinfo/r-help towork. What do people use to search the help archives?
>> 
>> 1. The google search box on http://tolstoy.newcastle.edu.au/~rking/R/
>>    returns a 404 error.
>> 2. The http://finzi.psych.upenn.edu/ site has many references but I
>>    don't see how to search r-help from there.
>> 3. The http://www.mail-archive.com/r-help at stat.math.ethz.ch/ site
>>    seems to stop back in December 2007.
>> 4. I cannot get anything useful from
>>    http://dir.gmane.org/gmane.comp.lang.r.general.

For R-help I've been using:

http://markmail.org/search/?q=list%3Aorg.r-project.r-help

To find documentation, I use:

install.packages("sos")
library(sos)
findFn("topic items")

You could conceivably use Googles advanced search with the site set to the "true" Archives.

https://www.google.com/search?as_q=words+to+search&as_epq=&as_oq=&as_eq=&as_nlo=&as_nhi=&lr=&cr=&as_qdr=all&as_sitesearch=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-help%2F&as_occt=any&safe=images&as_filetype=&as_rights=

-- 
David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From bgunter.4567 at gmail.com  Fri Jan 19 21:56:21 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 19 Jan 2018 12:56:21 -0800
Subject: [R] how to search r-help?
In-Reply-To: <3a9e52dc-d1ff-3f91-9f73-e84da5ce3fbf@yahoo.com>
References: <3a9e52dc-d1ff-3f91-9f73-e84da5ce3fbf@yahoo.com>
Message-ID: <CAGxFJbRs90+=fSaizmVVnNyiqaAenz82+WsqQkPjxhDKrSeQmQ@mail.gmail.com>

Googling "r-help archive"   (!!)

brought up this:

http://r.789695.n4.nabble.com/R-help-f789696.html


-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jan 19, 2018 at 10:47 AM, Mark Dwyer via R-help <
r-help at r-project.org> wrote:

> I am new to this listand am unable to get the search tools listed on
> https://stat.ethz.ch/mailman/listinfo/r-help towork. What do people use
> to search the help archives?
>
>  1. The google search box on http://tolstoy.newcastle.edu.au/~rking/R/
>     returns a 404 error.
>  2. The http://finzi.psych.upenn.edu/ site has many references but I
>     don't see how to search r-help from there.
>  3. The http://www.mail-archive.com/r-help at stat.math.ethz.ch/ site seems
>     to stop back in December 2007.
>  4. I cannot get anything useful from
>     http://dir.gmane.org/gmane.comp.lang.r.general.
>
> Thanks.
>
> - Mark Dwyer
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Fri Jan 19 22:33:54 2018
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 19 Jan 2018 16:33:54 -0500
Subject: [R] how to search r-help?
In-Reply-To: <3a9e52dc-d1ff-3f91-9f73-e84da5ce3fbf@yahoo.com>
References: <3a9e52dc-d1ff-3f91-9f73-e84da5ce3fbf@yahoo.com>
Message-ID: <03FD5E9D-79F2-4BCE-BE05-D51EA1592B07@me.com>

> On Jan 19, 2018, at 1:47 PM, Mark Dwyer via R-help <r-help at r-project.org> wrote:
> 
> I am new to this listand am unable to get the search tools listed on 
> https://stat.ethz.ch/mailman/listinfo/r-help towork. What do people use 
> to search the help archives?
> 
> 1. The google search box on http://tolstoy.newcastle.edu.au/~rking/R/
>    returns a 404 error.
> 2. The http://finzi.psych.upenn.edu/ site has many references but I
>    don't see how to search r-help from there.
> 3. The http://www.mail-archive.com/r-help at stat.math.ethz.ch/ site seems
>    to stop back in December 2007.
> 4. I cannot get anything useful from
>    http://dir.gmane.org/gmane.comp.lang.r.general.
> 
> Thanks.
> 
> - Mark Dwyer


Hi Mark,

On the main R Project page (https://www.r-project.org) is a link menu on the left hand side, where one of the entries is "Search", which takes you to:

  https://www.r-project.org/search.html

On that page, one of the links is to rseek.org, which is the page that I use and have used for a number of years. It searches various locations of the R list archives and other online resources. Once you run a keyword search, if you select the "Support" tab, it will filter the search results to online documents and the list archives. The list archives will tend to be either from the Nabble site, which mirrors a subset of list archives, or from https://stat.ethz.ch which is the official R list archive server for all R lists.

Depending upon the keyword search, you may find that the list archive hits will be interspersed with other online resources, with a bias towards one or the other based upon the underlying Google algorithms being used.

Also, as an additional pointer, on the main R Project page is a link to "Getting Help", which takes you to:

  https://www.r-project.org/help.html

and provides a series of pointers relative to seeking help with R.

Regards,

Marc Schwartz


From jwd at surewest.net  Fri Jan 19 23:04:31 2018
From: jwd at surewest.net (John)
Date: Fri, 19 Jan 2018 14:04:31 -0800
Subject: [R] how to search r-help?
In-Reply-To: <3a9e52dc-d1ff-3f91-9f73-e84da5ce3fbf@yahoo.com>
References: <3a9e52dc-d1ff-3f91-9f73-e84da5ce3fbf@yahoo.com>
Message-ID: <20180119140431.1e356c1b@Draco.localdomain>

On Fri, 19 Jan 2018 10:47:56 -0800
Mark Dwyer via R-help <r-help at r-project.org> wrote:

> I am new to this listand am unable to get the search tools listed on 
> https://stat.ethz.ch/mailman/listinfo/r-help towork. What do people
> use to search the help archives?
> 
>  1. The google search box on http://tolstoy.newcastle.edu.au/~rking/R/
>     returns a 404 error.
>  2. The http://finzi.psych.upenn.edu/ site has many references but I
>     don't see how to search r-help from there.
>  3. The http://www.mail-archive.com/r-help at stat.math.ethz.ch/ site
> seems to stop back in December 2007.
>  4. I cannot get anything useful from
>     http://dir.gmane.org/gmane.comp.lang.r.general.
> 
> Thanks.
> 

Just about any question you can imagine for R has been asked usually
several times.  Since you don't explain what specifically you are
looking for help with, the best start is to go to the
https://www.r-project.org/help.html page and start with those
suggestions.  Nabble is another good choice, and simply entering "r
[topic]" in a search engine will usually yield hundreds of results.


From macqueen1 at llnl.gov  Fri Jan 19 23:07:40 2018
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 19 Jan 2018 22:07:40 +0000
Subject: [R] Packages couldn't load
In-Reply-To: <CAJuCY5zuMgOwr5DBCLDzJVhpFUeBUpnh9skyZNHL-4GX7vueSA@mail.gmail.com>
References: <CAJ3tmCrfNSBMFXHKZYxex0EWDgV7yFRoo+jSfB4tN-DCXuwZew@mail.gmail.com>
 <CAJuCY5zuMgOwr5DBCLDzJVhpFUeBUpnh9skyZNHL-4GX7vueSA@mail.gmail.com>
Message-ID: <7AEDCCB4-1B3C-41DC-94BF-7D3D26F49DD0@llnl.gov>

Or the openxlsx package, which does not require Java, and is similar to the xlsx package in functionality (both reads and writes, for example).

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 
?On 1/16/18, 4:42 AM, "R-help on behalf of Thierry Onkelinx" <r-help-bounces at r-project.org on behalf of thierry.onkelinx at inbo.be> wrote:

    You need to make sure that the rJava package is working.
    
    Consider using the readxl package instead of xlsx.
    
    Best regards,
    
    ir. Thierry Onkelinx
    Statisticus / Statistician
    
    Vlaamse Overheid / Government of Flanders
    INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
    AND FOREST
    Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
    thierry.onkelinx at inbo.be
    Havenlaan 88 bus 73, 1000 Brussel
    www.inbo.be
    
    ///////////////////////////////////////////////////////////////////////////////////////////
    To call in the statistician after the experiment is done may be no
    more than asking him to perform a post-mortem examination: he may be
    able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
    The plural of anecdote is not data. ~ Roger Brinner
    The combination of some data and an aching desire for an answer does
    not ensure that a reasonable answer can be extracted from a given body
    of data. ~ John Tukey
    ///////////////////////////////////////////////////////////////////////////////////////////
    
    
    
    
    2018-01-16 13:08 GMT+01:00 Emeka Don <emekadonn at gmail.com>:
    > Dear All,
    > I have been trying to install Xlsx package in R but  i have been getting
    > this error after the installation. Please can anyone help?
    >
    >> any(grepl("xlsx",installed.packages()))
    > [1] TRUE
    >> library("xlsx")
    > Loading required package: rJava
    > Error: package or namespace load failed for ?rJava?:
    >  .onLoad failed in loadNamespace() for 'rJava', details:
    >   call: fun(libname, pkgname)
    >   error: JAVA_HOME cannot be determined from the Registry
    > Error: package ?rJava? could not be loaded
    > In addition: Warning messages:
    > 1: package ?xlsx? was built under R version 3.4.3
    > 2: package ?rJava? was built under R version 3.4.3
    >
    > Thank you
    >
    > --
    > Onyeuwaoma Nnaemeka Dom PhD.
    > Scientific Officer.
    > Center for Basic Space Science (CBSS)
    > National Space Research and Development Agency (NASRDA)
    > Federal Ministry of Science and Technology
    > University of Nigeria, Nsukka
    > P. M. B. 2022, Nsukka, Enugu State, Nigeria.
    > +2348032686377, +2347052835685
    > email:onyeuwaoma.emeka at cbss.nasrda.gov.ng
    >
    >         [[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.


From mdwy62 at yahoo.com  Sat Jan 20 00:00:02 2018
From: mdwy62 at yahoo.com (Mark Dwyer)
Date: Fri, 19 Jan 2018 15:00:02 -0800
Subject: [R] how to search r-help?
In-Reply-To: <20180119140431.1e356c1b@Draco.localdomain>
References: <3a9e52dc-d1ff-3f91-9f73-e84da5ce3fbf@yahoo.com>
 <20180119140431.1e356c1b@Draco.localdomain>
Message-ID: <9dc40c1c-ee8e-43bb-c904-45fedd391733@yahoo.com>

Thank you all for these suggestions. The nabble and markmail links are 
focus(able) on r-help and easy (for me) to use.

- Mark


On 19/01/18 14:04, John wrote:
> On Fri, 19 Jan 2018 10:47:56 -0800
> Mark Dwyer via R-help <r-help at r-project.org> wrote:
>
>> I am new to this listand am unable to get the search tools listed on
>> https://stat.ethz.ch/mailman/listinfo/r-help towork. What do people
>> use to search the help archives?
>>
>>   1. The google search box on http://tolstoy.newcastle.edu.au/~rking/R/
>>      returns a 404 error.
>>   2. The http://finzi.psych.upenn.edu/ site has many references but I
>>      don't see how to search r-help from there.
>>   3. The http://www.mail-archive.com/r-help at stat.math.ethz.ch/ site
>> seems to stop back in December 2007.
>>   4. I cannot get anything useful from
>>      http://dir.gmane.org/gmane.comp.lang.r.general.
>>
>> Thanks.
>>
> Just about any question you can imagine for R has been asked usually
> several times.  Since you don't explain what specifically you are
> looking for help with, the best start is to go to the
> https://www.r-project.org/help.html page and start with those
> suggestions.  Nabble is another good choice, and simply entering "r
> [topic]" in a search engine will usually yield hundreds of results.
>


From sarah.goslee at gmail.com  Sat Jan 20 01:35:35 2018
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 20 Jan 2018 00:35:35 +0000
Subject: [R] how to search r-help?
In-Reply-To: <9dc40c1c-ee8e-43bb-c904-45fedd391733@yahoo.com>
References: <3a9e52dc-d1ff-3f91-9f73-e84da5ce3fbf@yahoo.com>
 <20180119140431.1e356c1b@Draco.localdomain>
 <9dc40c1c-ee8e-43bb-c904-45fedd391733@yahoo.com>
Message-ID: <CAM_vjumptJmh2cjPAXCuj8_-8wuBOG0vtmAdc0yN7Zq9kUm7pQ@mail.gmail.com>

rseek.org is also very helpful.

On Fri, Jan 19, 2018 at 6:00 PM Mark Dwyer via R-help <r-help at r-project.org>
wrote:

> Thank you all for these suggestions. The nabble and markmail links are
> focus(able) on r-help and easy (for me) to use.
>
> - Mark
>
>
> On 19/01/18 14:04, John wrote:
> > On Fri, 19 Jan 2018 10:47:56 -0800
> > Mark Dwyer via R-help <r-help at r-project.org> wrote:
> >
> >> I am new to this listand am unable to get the search tools listed on
> >> https://stat.ethz.ch/mailman/listinfo/r-help towork. What do people
> >> use to search the help archives?
> >>
> >>   1. The google search box on http://tolstoy.newcastle.edu.au/~rking/R/
> >>      returns a 404 error.
> >>   2. The http://finzi.psych.upenn.edu/ site has many references but I
> >>      don't see how to search r-help from there.
> >>   3. The http://www.mail-archive.com/r-help at stat.math.ethz.ch/ site
> >> seems to stop back in December 2007.
> >>   4. I cannot get anything useful from
> >>      http://dir.gmane.org/gmane.comp.lang.r.general.
> >>
> >> Thanks.
> >>
> > Just about any question you can imagine for R has been asked usually
> > several times.  Since you don't explain what specifically you are
> > looking for help with, the best start is to go to the
> > https://www.r-project.org/help.html page and start with those
> > suggestions.  Nabble is another good choice, and simply entering "r
> > [topic]" in a search engine will usually yield hundreds of results.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From chema at rinzewind.org  Sat Jan 20 02:27:21 2018
From: chema at rinzewind.org (=?iso-8859-1?Q?Jos=E9_Mar=EDa?= Mateos)
Date: Fri, 19 Jan 2018 20:27:21 -0500
Subject: [R] how to search r-help?
In-Reply-To: <3a9e52dc-d1ff-3f91-9f73-e84da5ce3fbf@yahoo.com>
References: <3a9e52dc-d1ff-3f91-9f73-e84da5ce3fbf@yahoo.com>
Message-ID: <20180120012721.GA13098@equipaje>

On Fri, Jan 19, 2018 at 10:47:56AM -0800, Mark Dwyer via R-help wrote:
>  4. I cannot get anything useful from
>     http://dir.gmane.org/gmane.comp.lang.r.general.

If I understood correctly a recent discussion on another mailing list, 
gmane.org web interface is broken, but will work if you use 
news.gmane.org using your news reader, if you use one. That won't solve 
your search problem, but just saying.

Cheers,

JMM.


From suharto_anggono at yahoo.com  Sat Jan 20 07:53:38 2018
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sat, 20 Jan 2018 06:53:38 +0000 (UTC)
Subject: [R] max and pmax of NA and NaN
References: <2146971401.1434391.1516431218722.ref@mail.yahoo.com>
Message-ID: <2146971401.1434391.1516431218722@mail.yahoo.com>

Extremes.Rd, that documents 'max' and 'pmax', has this in "Details" section, in the paragraph before the last.
By definition the min/max of a numeric vector containing an NaN is NaN, except that the min/max of any vector containing an NA is NA even if it also contains an NaN.

------------------
>>>>> Michal Burda <michal.burda at centrum.cz>
>>>>>     on Mon, 15 Jan 2018 12:04:13 +0100 writes:

    > Dear R users, is the following OK?

    >> max(NA, NaN)
    > [1] NA
    >> max(NaN, NA)
    > [1] NA
    >> pmax(NaN, NA)
    > [1] NA
    >> pmax(NA, NaN)
    > [1] NaN

    > ...or is it a bug? 

    > Documentation says that NA has a higher priority over NaN.

which documentation ??
[That would be quite a bit misleading I think. So, it should be amended ...]

    > Best regards, Michal Burda


R's help pages are *THE* reference documentation and they have 
(for a long time, I think) had :

?NaN   has in its 3rd 'Note:'

     Computations involving ?NaN? will return ?NaN? or perhaps ?NA?:
     which of those two is not guaranteed and may depend on the R
     platform (since compilers may re-order computations).

Similarly,  ?NA  contains, in its 'Details':

     Numerical computations using ?NA? will normally result in ?NA?: a
     possible exception is where ?NaN? is also involved, in which case
     either might result (which may depend on the R platform).  ........

-----

Yes, it is a bit unfortunate that this is platform dependent; if
we wanted to make this entirely consistent (as desired in a
perfect world), I'm almost sure R would become slower because
we'd have to do add some explicit "book keeping" / checking
instead of relying on the underlying C library code.

Note that for these reasons, often NaN and NA should not be
differentiated, and that's reason why using  is.na(*)  is
typically sufficient and "best" -- it gives TRUE for both NA and NaN.


Martin Maechler
ETH Zurich


From Marios.BARLAS at cea.fr  Sat Jan 20 12:20:47 2018
From: Marios.BARLAS at cea.fr (BARLAS Marios 247554)
Date: Sat, 20 Jan 2018 11:20:47 +0000
Subject: [R] Bi variate minimization  problem
Message-ID: <01BFC0B2B4ABFC4CB432008F852D76610D5A2E31@EXDAG0-A1.intra.cea.fr>

Dear all,

I'm working on the following problem:

Assume two datasets: Y, Y that represent the same physical quantity Q. Dataset X contains values of Q after an event A while dataset Y contains values of Q after an event B.

In R X, Y are vectors of the same length, containing effectivelly a number of observations of Q in each state.

Q is a continous variable.

Now, the two datasets should ideally not have any range of overlapping values. That is

max(x) << min (Y)

but that is not the reality of the problem. there are usually overlaps, bigger or smaller.

Now, what I want to do is the following:

Suppose that we choose a value P so that.

Any X <= P is understood as belonging to group X while
any Y > P is understood as belonging to group Y.

now any values of X > P or of Y <= P are wrongly understood as belonging to Y nad X effectively.

Hence we have Xerr -- > Sum( X >P) and Yerror --> Sum(Y<=P).

I want to solve this bivariate optimization problem where I want to at the same time minimize the error of X and Y for a given P. Ultimately the target is to optimize the value of P so that the errors of both X and Y are optimized.

Does any1 have some functions in mind that can help with parts of this problem ? It's not impossible to write the algorithm but it will take time and things like convergence and robustness need to be checked.... !

thank you for your help.

Best regards,
Marios Barlas

	[[alternative HTML version deleted]]


From Marios.BARLAS at cea.fr  Sat Jan 20 12:43:32 2018
From: Marios.BARLAS at cea.fr (BARLAS Marios 247554)
Date: Sat, 20 Jan 2018 11:43:32 +0000
Subject: [R] Specification: Bi variate minimization  problem
Message-ID: <01BFC0B2B4ABFC4CB432008F852D76610D5A2E42@EXDAG0-A1.intra.cea.fr>

------------------- Version 2 of my problem improving the definition of what the optimal solution would be.
Dear all,

I'm working on the following problem:

Assume two datasets: Y, Y that represent the same physical quantity Q. Dataset X contains values of Q after an event A while dataset Y contains values of Q after an event B.

In R X, Y are vectors of the same length, containing effectivelly a number of observations of Q in each state.

Q is a continous variable.

Now, the two datasets should ideally not have any range of overlapping values. That is

max(x) << min (Y)

but that is not the reality of the problem. there are usually overlaps, bigger or smaller.

Now, what I want to do is the following:

Suppose that we choose a value P so that.

Any X <= P is understood as belonging to group X while
any Y > P is understood as belonging to group Y.

now any values of X > P or of Y <= P are wrongly understood as belonging to Y nad X effectively.

Hence we have Xerr -- > Sum( X >P) and Yerror --> Sum(Y<=P).

I want to solve this bivariate optimization problem where I want to at the same time minimize the error of X and Y for a given P. Ultimately the target is to optimize the value of P so that the errors of both X and Y are optimized. More specifically, the optimal solution is one where

1. The total error (Xerr + Yerr) is minimized
2. The values or Xerr and Yerr are balanced as much as possible, probably.

Does any1 have some functions in mind that can help with parts of this problem ? It's not impossible to write the algorithm but it will take time and things like convergence and robustness need to be checked.... !

thank you for your help.

Best regards,
Marios Barlas

	[[alternative HTML version deleted]]


From akshay_e4 at hotmail.com  Sat Jan 20 12:53:50 2018
From: akshay_e4 at hotmail.com (akshay kulkarni)
Date: Sat, 20 Jan 2018 11:53:50 +0000
Subject: [R] a vector unusually getting NA values.....
Message-ID: <SL2P216MB009171AFEFCABBD9DF194CE2C8EE0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,

                             I have a function by name "ygcudf" and a list of stock names by name"snl" ( of class "list"). ygcudf acts on snl and returns a list of the most favourable  stocks. I don't wish to divulge the code of the function, for genuine reasons, but the algorithm is as follows:

        {

        k <- 1; i <- 1



       for(j in 1:length(snl)){

                                 if(snl[[j]] == "condition") {

                                       k[i] <- j

                                        i <- i+1}

                                             }

        snlf1 <- snl[k]

        return(snlf1)

}


The problem is, if we test the function by returning the vector k, it, (k), is getting NA values. i.e, instead of skipping the values of j for which the condition is false, k is getting populated by NA values. k is getting the following values (for a given snl):

        k

[1]    1 NA NA NA 5 6 NA NA 9 10 11 NA NA NA NA 16


If j is initialised to the values for which k is NA, and the function is  made to return j, it is returning the relevant j. I don't know how the k is getting NA values. Will the following change work:

      snlf1 <-  snl[na.omit(k)]


What is wrong ??


Sorry for not parting with the code...please bear with me....

your help will be highly appreciated


yours sincerely,

AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Jan 20 13:14:29 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 20 Jan 2018 07:14:29 -0500
Subject: [R] a vector unusually getting NA values.....
In-Reply-To: <SL2P216MB009171AFEFCABBD9DF194CE2C8EE0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009171AFEFCABBD9DF194CE2C8EE0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <72c66daf-de9e-7059-c5cc-56d5fcd09f98@gmail.com>

On 20/01/2018 6:53 AM, akshay kulkarni wrote:
> dear members,
> 
>                               I have a function by name "ygcudf" and a list of stock names by name"snl" ( of class "list"). ygcudf acts on snl and returns a list of the most favourable  stocks. I don't wish to divulge the code of the function, for genuine reasons, but the algorithm is as follows:
> 
>          {
> 
>          k <- 1; i <- 1
> 
> 
> 
>         for(j in 1:length(snl)){
> 
>                                   if(snl[[j]] == "condition") {
> 
>                                         k[i] <- j
> 
>                                          i <- i+1}
> 
>                                               }
> 
>          snlf1 <- snl[k]
> 
>          return(snlf1)
> 
> }
> 
> 
> The problem is, if we test the function by returning the vector k, it, (k), is getting NA values. i.e, instead of skipping the values of j for which the condition is false, k is getting populated by NA values. k is getting the following values (for a given snl):

Try this:

k <- 1
k[5] <- 5
k

and you should see what's happening.

Duncan Murdoch

> 
>          k
> 
> [1]    1 NA NA NA 5 6 NA NA 9 10 11 NA NA NA NA 16
> 
> 
> If j is initialised to the values for which k is NA, and the function is  made to return j, it is returning the relevant j. I don't know how the k is getting NA values. Will the following change work:
> 
>        snlf1 <-  snl[na.omit(k)]
> 
> 
> What is wrong ??
> 
> 
> Sorry for not parting with the code...please bear with me....
> 
> your help will be highly appreciated
> 
> 
> yours sincerely,
> 
> AKSHAY M KULKARNI
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pdalgd at gmail.com  Sat Jan 20 17:50:52 2018
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 20 Jan 2018 17:50:52 +0100
Subject: [R] max and pmax of NA and NaN
In-Reply-To: <2146971401.1434391.1516431218722@mail.yahoo.com>
References: <2146971401.1434391.1516431218722.ref@mail.yahoo.com>
 <2146971401.1434391.1516431218722@mail.yahoo.com>
Message-ID: <77EEF499-848C-4D7E-B3F8-5D1DBCF6084E@gmail.com>



> On 20 Jan 2018, at 07:53 , Suharto Anggono Suharto Anggono via R-help <r-help at r-project.org> wrote:
> 
> Extremes.Rd, that documents 'max' and 'pmax', has this in "Details" section, in the paragraph before the last.


> By definition the min/max of a numeric vector containing an NaN is NaN, except that the min/max of any vector containing an NA is NA even if it also contains an NaN.

...but how do you infer that this applies to pmin/pmax? You may want it to, but it specifically talks about the non-parallel min/max.

-pd

> 
> ------------------
>>>>>> Michal Burda <michal.burda at centrum.cz>
>>>>>>    on Mon, 15 Jan 2018 12:04:13 +0100 writes:
> 
>> Dear R users, is the following OK?
> 
>>> max(NA, NaN)
>> [1] NA
>>> max(NaN, NA)
>> [1] NA
>>> pmax(NaN, NA)
>> [1] NA
>>> pmax(NA, NaN)
>> [1] NaN
> 
>> ...or is it a bug? 
> 
>> Documentation says that NA has a higher priority over NaN.
> 
> which documentation ??
> [That would be quite a bit misleading I think. So, it should be amended ...]
> 
>> Best regards, Michal Burda
> 
> 
> R's help pages are *THE* reference documentation and they have 
> (for a long time, I think) had :
> 
> ?NaN   has in its 3rd 'Note:'
> 
>     Computations involving ?NaN? will return ?NaN? or perhaps ?NA?:
>     which of those two is not guaranteed and may depend on the R
>     platform (since compilers may re-order computations).
> 
> Similarly,  ?NA  contains, in its 'Details':
> 
>     Numerical computations using ?NA? will normally result in ?NA?: a
>     possible exception is where ?NaN? is also involved, in which case
>     either might result (which may depend on the R platform).  ........
> 
> -----
> 
> Yes, it is a bit unfortunate that this is platform dependent; if
> we wanted to make this entirely consistent (as desired in a
> perfect world), I'm almost sure R would become slower because
> we'd have to do add some explicit "book keeping" / checking
> instead of relying on the underlying C library code.
> 
> Note that for these reasons, often NaN and NA should not be
> differentiated, and that's reason why using  is.na(*)  is
> typically sufficient and "best" -- it gives TRUE for both NA and NaN.
> 
> 
> Martin Maechler
> ETH Zurich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.ca.us  Sat Jan 20 18:02:34 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 20 Jan 2018 09:02:34 -0800
Subject: [R] Specification: Bi variate minimization  problem
In-Reply-To: <01BFC0B2B4ABFC4CB432008F852D76610D5A2E42@EXDAG0-A1.intra.cea.fr>
References: <01BFC0B2B4ABFC4CB432008F852D76610D5A2E42@EXDAG0-A1.intra.cea.fr>
Message-ID: <9147E9FF-57C4-4371-977B-9C87670E484C@dcn.davis.ca.us>

You probably ought to read the CRAN Optimization Task View. [1]

You should also read the Posting Guide mentioned at the bottom of every R-help email (e.g. no homework, use plain text email). You should also read some guides on asking questions online (e.g. [2][3][4]).

[1] https://cran.r-project.org/web/views/Optimization.html

[2] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[3] http://adv-r.had.co.nz/Reproducibility.html

[4] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)
-- 
Sent from my phone. Please excuse my brevity.

On January 20, 2018 3:43:32 AM PST, BARLAS Marios 247554 <Marios.BARLAS at cea.fr> wrote:
>------------------- Version 2 of my problem improving the definition of
>what the optimal solution would be.
>Dear all,
>
>I'm working on the following problem:
>
>Assume two datasets: Y, Y that represent the same physical quantity Q.
>Dataset X contains values of Q after an event A while dataset Y
>contains values of Q after an event B.
>
>In R X, Y are vectors of the same length, containing effectivelly a
>number of observations of Q in each state.
>
>Q is a continous variable.
>
>Now, the two datasets should ideally not have any range of overlapping
>values. That is
>
>max(x) << min (Y)
>
>but that is not the reality of the problem. there are usually overlaps,
>bigger or smaller.
>
>Now, what I want to do is the following:
>
>Suppose that we choose a value P so that.
>
>Any X <= P is understood as belonging to group X while
>any Y > P is understood as belonging to group Y.
>
>now any values of X > P or of Y <= P are wrongly understood as
>belonging to Y nad X effectively.
>
>Hence we have Xerr -- > Sum( X >P) and Yerror --> Sum(Y<=P).
>
>I want to solve this bivariate optimization problem where I want to at
>the same time minimize the error of X and Y for a given P. Ultimately
>the target is to optimize the value of P so that the errors of both X
>and Y are optimized. More specifically, the optimal solution is one
>where
>
>1. The total error (Xerr + Yerr) is minimized
>2. The values or Xerr and Yerr are balanced as much as possible,
>probably.
>
>Does any1 have some functions in mind that can help with parts of this
>problem ? It's not impossible to write the algorithm but it will take
>time and things like convergence and robustness need to be checked....
>!
>
>thank you for your help.
>
>Best regards,
>Marios Barlas
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From redmonc at gmail.com  Sat Jan 20 21:19:09 2018
From: redmonc at gmail.com (Charlie Redmon)
Date: Sat, 20 Jan 2018 14:19:09 -0600
Subject: [R] Split charts with ggplot2, tidyquant
In-Reply-To: <CAGgJW76zved0JXzGVVUfjxJRxhK=aGNPvqWaVTfSeAtYMC8cow@mail.gmail.com>
References: <2a39d9c8-a204-4060-e3de-3548ef5ada15@gmail.com>
 <CAGgJW75ZCwdXt2wbOTPAo5o-PBR=kzdE5TNo+t8uZcTekfiNiA@mail.gmail.com>
 <48135866-cc09-a588-8f54-0ca242c0e79a@gmail.com>
 <CAGgJW76zved0JXzGVVUfjxJRxhK=aGNPvqWaVTfSeAtYMC8cow@mail.gmail.com>
Message-ID: <6dbde910-c628-8aa7-cdad-c45a3ba97184@gmail.com>

For this kind of control you will probably need to move to base graphics 
and utilize the `fig` argument in par(), in which case you would want to 
run the plot() command twice: once with your first outcome and once with 
your second, changing the par() settings before each one to control the 
size.


On 01/19/2018 01:39 PM, Eric Berger wrote:
> Hi Charlie,
> Thanks. This is helpful. As mentioned in my original question, I want 
> to be able to plot a few such charts on the same page,
> say a 2 x 2 grid with such a chart for each of 4 different stocks. 
> Using your solution I accomplished this by making
> a list pLst of your ggplots and then calling cowplot::plot_grid( 
> plotlist=pLst, nrow=2, ncol=2 )? That worked fine.
>
> The one issue? I have is that in the ggplot you suggest, the price and 
> volume facets are the same size. I would like them to be different sizes
> (e.g. the volume facet at the bottom is generally shown smaller than 
> the facet above it in these types of charts.)
>
> I tried to find out how to do it but didn't succeed. I found a couple 
> of relevant discussions (including Hadley writing that he did not 
> think it was a useful feature. :-()
>
> https://github.com/tidyverse/ggplot2/issues/566
>
> and an ancient one where someone seems to have been able to get a 
> heights parameter working in a call to facet_grid but it did not work 
> for me.
> https://kohske.wordpress.com/2010/12/25/adjusting-the-relative-space-of-a-facet-grid/
>
> Thanks again,
> Eric
>
> p.s. Joshua thanks for your suggestions, but I was hoping for a ggplot 
> solution.
>
>
> On Fri, Jan 19, 2018 at 6:33 PM, Charlie Redmon <redmonc at gmail.com 
> <mailto:redmonc at gmail.com>> wrote:
>
>     So the general strategy for getting these into separate panels in
>     ggplot is to have a single variable that will be your response and
>     a factor variable that indexes which original variable it came
>     from. This can be accomplished in many ways, but the way I use is
>     with the melt() function in the reshape2 package.
>     For example,
>
>     library(reshape2)
>     plotDF <- melt(SPYdf,
>     ??? ??? ??? ??? ??? ??? id.vars="Date", # variables to replicate
>     ??? ??? ??? ??? ??? ??? measure.vars=c("close", "volume"), #
>     variables to create index from
>     variable.name <http://variable.name>="parameter", # name of new
>     variable for index
>     value.name <http://value.name>="resp") # name of what will be your
>     response variable
>
>     Now the ggplot2 code:
>
>     library(ggplot2)
>     ggplot(plotDF, aes(x=Date, y=resp)) +
>     ??? facet_wrap(~parameter, ncol=1, scales="free") +
>     ??? geom_line()
>
>
>     Hope that does the trick!
>
>     Charlie
>
>
>
>     On 01/18/2018 02:11 PM, Eric Berger wrote:
>
>         Hi Charlie,
>         I am comfortable to put the data in any way that works best.
>         Here are two possibilities: an xts and a data frame.
>
>         library(quantmod)
>         quantmod::getSymbols("SPY")? # creates xts variable SPY
>         SPYxts <- SPY[,c("SPY.Close","SPY.Volume")]
>         SPYdf? <-
>         data.frame(Date=index(SPYxts),close=as.numeric(SPYxts$SPY.Close),
>         ?volume=as.numeric(SPYxts$SPY.Volume))
>         rownames(SPYdf) <- NULL
>
>         head(SPYxts)
>         head(SPYdf)
>
>         #? ? ? ? ? ?SPY.Close SPY.Volume
>         #2007-01-03? ? 141.37? ?94807600
>         #2007-01-04? ? 141.67? ?69620600
>         #2007-01-05? ? 140.54? ?76645300
>         #2007-01-08? ? 141.19? ?71655000
>         #2007-01-09? ? 141.07? ?75680100 <tel:07%C2%A0%20%C2%A075680100>
>         #2007-01-10? ? 141.54? ?72428000
>
>         #? ? ? ? Date? close? ?volume
>         #1 2007-01-03 141.37 94807600
>         #2 2007-01-04 141.67 69620600
>         #3 2007-01-05 140.54 76645300
>         #4 2007-01-08 141.19 71655000
>         #5 2007-01-09 141.07 75680100 <tel:07%2075680100>
>         #6 2007-01-10 141.54 72428000
>
>         Thanks,
>         Eric
>
>
>
>         On Thu, Jan 18, 2018 at 8:00 PM, Charlie Redmon
>         <redmonc at gmail.com <mailto:redmonc at gmail.com>
>         <mailto:redmonc at gmail.com <mailto:redmonc at gmail.com>>> wrote:
>
>         ? ? Could you provide some information on your data structure
>         (e.g.,
>         ? ? are the two time series in separate columns in the data)? The
>         ? ? solution is fairly straightforward once you have the data
>         in the
>         ? ? right structure. And I do not think tidyquant is necessary for
>         ? ? what you want.
>
>         ? ? Best,
>         ? ? Charlie
>
>         ? ? --? ? ?Charles Redmon
>         ? ? GRA, Center for Research Methods and Data Analysis
>         ? ? PhD Student, Department of Linguistics
>         ? ? University of Kansas
>         ? ? Lawrence, KS, USA
>
>
>
>     -- 
>     Charles Redmon
>     GRA, Center for Research Methods and Data Analysis
>     PhD Student, Department of Linguistics
>     University of Kansas
>     Lawrence, KS, USA
>
>

-- 
Charles Redmon
GRA, Center for Research Methods and Data Analysis
PhD Student, Department of Linguistics
University of Kansas
Lawrence, KS, USA


	[[alternative HTML version deleted]]


From maitra at email.com  Sat Jan 20 22:00:32 2018
From: maitra at email.com (Ranjan Maitra)
Date: Sat, 20 Jan 2018 15:00:32 -0600
Subject: [R] reading lisp file in R
In-Reply-To: <CAGAA5bdcECg6ufZ_Jc_Zb0ep_56iKMb+4CYzdwHX_oUERXGg6A@mail.gmail.com>
References: <20180117222241.e545855f9f9d7c79e67dbaf8@email.com>
 <CAGAA5bdcECg6ufZ_Jc_Zb0ep_56iKMb+4CYzdwHX_oUERXGg6A@mail.gmail.com>
Message-ID: <20180120150032.2b60614ff867d4226b1ef18d@email.com>

Thank you for your example. I have successfully modified it with regard to most fields. However, I think that am not going to be putting this out for my students. The class I am currently teaching is in multivariate statistics (both methods and applications, with R used for computing) and I use the opportunity to provide students with experience in handling different kinds of files. From what I can tell, this file is being read in using string operations and that is not peculiar to lisp code. 

Best wishes,
Ranjan

On Fri, 19 Jan 2018 02:38:42 +0100 Martin M?ller Skarbiniks Pedersen <traxplayer at gmail.com> wrote:

> Here are the beginning of a R program.
> I hope it can help you writing the rest of the program.
> 
> Regards
> Martin M. S. Pedersen
> 
> ----
> 
> filename <- "university.data"
> 
> 
> lines <- readLines(filename)
> 
> first <- T
> 
> for (ALine in lines) {
> ALine <- sub("^ +","",ALine)
> ALine <- sub(")","",ALine, fixed = T)
> if (length(grep("def-instance", ALine))) {
> if (first) {
> first = F
> }
> else {
> cat(paste(instance,state,control,no_of_students_thous,"\n", sep  = ","))
> }
> instance <- sub("(def-instance ","",ALine, fixed = T)
> next
> }
> if (length(grep("state ", ALine))) {
> state <- sub("(state ","",ALine, fixed = T)
> next
> }
> if (length(grep("control ", ALine))) {
> control <- sub("(control ","", ALine, fixed = T)
> next
> }
> if (length(grep("no-of-students thous:", ALine))) {
> no_of_students_thous <- ALine
> no_of_students_thous <- sub("(no-of-students thous:","", ALine, fixed = T)
> next
> }
> }
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.


From bgunter.4567 at gmail.com  Sat Jan 20 22:17:02 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 20 Jan 2018 13:17:02 -0800
Subject: [R] Split charts with ggplot2, tidyquant
In-Reply-To: <6dbde910-c628-8aa7-cdad-c45a3ba97184@gmail.com>
References: <2a39d9c8-a204-4060-e3de-3548ef5ada15@gmail.com>
 <CAGgJW75ZCwdXt2wbOTPAo5o-PBR=kzdE5TNo+t8uZcTekfiNiA@mail.gmail.com>
 <48135866-cc09-a588-8f54-0ca242c0e79a@gmail.com>
 <CAGgJW76zved0JXzGVVUfjxJRxhK=aGNPvqWaVTfSeAtYMC8cow@mail.gmail.com>
 <6dbde910-c628-8aa7-cdad-c45a3ba97184@gmail.com>
Message-ID: <CAGxFJbTZSuHzQsEdRpojJrmGkYT0Tf3v=wt1cMqH-E4ZK4pmDg@mail.gmail.com>

That (the need for base graphics) is false. It certainly **can** be done in
base graphics -- see ?layout for a perhaps more straightforward way to do
it along the lines you suggest.

However both lattice and ggplot are based on grid graphics, which has a
similar but slightly more flexible ?grid.layout function which would allow
one to size and place subsequent ggplot or lattice graphs in an arbitrary
layout as you have described (iiuc) for the base graphics case.

Perhaps even simpler would be to use the "position" argument of the
print.trellis() function to locate trellis plots. Maybe ggplot() has
something similar.

In any case, the underlying grid graphics functionality allows **much**
greater fine control of graphical elements (including rotation, for
example) -- at the cost of greater complexity. I would agree that doing it
from scratch using base grid functions is most likely overkill here,
though. But it's there.

IMHO only, the base graphics system was great in its time, but its time has
passed. Grid graphics is much more powerful because it is objects based --
that is, grid graphs are objects that can be saved, modified, and even
interacted with in flexible ways. Lattice and ggplot incarnations take
advantage of this, giving them more power and flexibility than the base
graphics capabilities can muster.

I repeat -- IMHO only! Feel free to disagree. I don't want to start any
flame wars here.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Jan 20, 2018 at 12:19 PM, Charlie Redmon <redmonc at gmail.com> wrote:

> For this kind of control you will probably need to move to base graphics
> and utilize the `fig` argument in par(), in which case you would want to
> run the plot() command twice: once with your first outcome and once with
> your second, changing the par() settings before each one to control the
> size.
>
>
> On 01/19/2018 01:39 PM, Eric Berger wrote:
> > Hi Charlie,
> > Thanks. This is helpful. As mentioned in my original question, I want
> > to be able to plot a few such charts on the same page,
> > say a 2 x 2 grid with such a chart for each of 4 different stocks.
> > Using your solution I accomplished this by making
> > a list pLst of your ggplots and then calling cowplot::plot_grid(
> > plotlist=pLst, nrow=2, ncol=2 )  That worked fine.
> >
> > The one issue  I have is that in the ggplot you suggest, the price and
> > volume facets are the same size. I would like them to be different sizes
> > (e.g. the volume facet at the bottom is generally shown smaller than
> > the facet above it in these types of charts.)
> >
> > I tried to find out how to do it but didn't succeed. I found a couple
> > of relevant discussions (including Hadley writing that he did not
> > think it was a useful feature. :-()
> >
> > https://github.com/tidyverse/ggplot2/issues/566
> >
> > and an ancient one where someone seems to have been able to get a
> > heights parameter working in a call to facet_grid but it did not work
> > for me.
> > https://kohske.wordpress.com/2010/12/25/adjusting-the-
> relative-space-of-a-facet-grid/
> >
> > Thanks again,
> > Eric
> >
> > p.s. Joshua thanks for your suggestions, but I was hoping for a ggplot
> > solution.
> >
> >
> > On Fri, Jan 19, 2018 at 6:33 PM, Charlie Redmon <redmonc at gmail.com
> > <mailto:redmonc at gmail.com>> wrote:
> >
> >     So the general strategy for getting these into separate panels in
> >     ggplot is to have a single variable that will be your response and
> >     a factor variable that indexes which original variable it came
> >     from. This can be accomplished in many ways, but the way I use is
> >     with the melt() function in the reshape2 package.
> >     For example,
> >
> >     library(reshape2)
> >     plotDF <- melt(SPYdf,
> >                             id.vars="Date", # variables to replicate
> >                             measure.vars=c("close", "volume"), #
> >     variables to create index from
> >     variable.name <http://variable.name>="parameter", # name of new
> >     variable for index
> >     value.name <http://value.name>="resp") # name of what will be your
> >     response variable
> >
> >     Now the ggplot2 code:
> >
> >     library(ggplot2)
> >     ggplot(plotDF, aes(x=Date, y=resp)) +
> >         facet_wrap(~parameter, ncol=1, scales="free") +
> >         geom_line()
> >
> >
> >     Hope that does the trick!
> >
> >     Charlie
> >
> >
> >
> >     On 01/18/2018 02:11 PM, Eric Berger wrote:
> >
> >         Hi Charlie,
> >         I am comfortable to put the data in any way that works best.
> >         Here are two possibilities: an xts and a data frame.
> >
> >         library(quantmod)
> >         quantmod::getSymbols("SPY")  # creates xts variable SPY
> >         SPYxts <- SPY[,c("SPY.Close","SPY.Volume")]
> >         SPYdf  <-
> >         data.frame(Date=index(SPYxts),close=as.numeric(SPYxts$SPY.
> Close),
> >          volume=as.numeric(SPYxts$SPY.Volume))
> >         rownames(SPYdf) <- NULL
> >
> >         head(SPYxts)
> >         head(SPYdf)
> >
> >         #           SPY.Close SPY.Volume
> >         #2007-01-03    141.37   94807600
> >         #2007-01-04    141.67   69620600
> >         #2007-01-05    140.54   76645300
> >         #2007-01-08    141.19   71655000
> >         #2007-01-09    141.07   75680100 <tel:07%C2%A0%20%C2%A075680100>
> >         #2007-01-10    141.54   72428000
> >
> >         #        Date  close   volume
> >         #1 2007-01-03 141.37 94807600
> >         #2 2007-01-04 141.67 69620600
> >         #3 2007-01-05 140.54 76645300
> >         #4 2007-01-08 141.19 71655000
> >         #5 2007-01-09 141.07 75680100 <tel:07%2075680100>
> >         #6 2007-01-10 141.54 72428000
> >
> >         Thanks,
> >         Eric
> >
> >
> >
> >         On Thu, Jan 18, 2018 at 8:00 PM, Charlie Redmon
> >         <redmonc at gmail.com <mailto:redmonc at gmail.com>
> >         <mailto:redmonc at gmail.com <mailto:redmonc at gmail.com>>> wrote:
> >
> >             Could you provide some information on your data structure
> >         (e.g.,
> >             are the two time series in separate columns in the data)? The
> >             solution is fairly straightforward once you have the data
> >         in the
> >             right structure. And I do not think tidyquant is necessary
> for
> >             what you want.
> >
> >             Best,
> >             Charlie
> >
> >             --     Charles Redmon
> >             GRA, Center for Research Methods and Data Analysis
> >             PhD Student, Department of Linguistics
> >             University of Kansas
> >             Lawrence, KS, USA
> >
> >
> >
> >     --
> >     Charles Redmon
> >     GRA, Center for Research Methods and Data Analysis
> >     PhD Student, Department of Linguistics
> >     University of Kansas
> >     Lawrence, KS, USA
> >
> >
>
> --
> Charles Redmon
> GRA, Center for Research Methods and Data Analysis
> PhD Student, Department of Linguistics
> University of Kansas
> Lawrence, KS, USA
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Jan 21 04:45:02 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 21 Jan 2018 14:45:02 +1100
Subject: [R] Leaflet maps. Nudging co-incident markers
In-Reply-To: <B8D87DA108D62D448DBE22A7775AB6BB016F43989B@EX11.adf.bham.ac.uk>
References: <B8D87DA108D62D448DBE22A7775AB6BB016F43989B@EX11.adf.bham.ac.uk>
Message-ID: <CA+8X3fWB-+GzJzwVTn7DynZRt1uq-BhShjFEBoL8qvovOy6aWQ@mail.gmail.com>

Hi Gavin,
Here's a sort of brute force way to nudge points. Might be helpful.

nudge<-function(x,y,away=0.1,tol=0.01) {
 dimx<-dim(x)
 if(missing(y) && !is.null(dimx)) {
  y<-x[,2]
  x<-x[,1]
 }
 xlen<-length(x)
 if(xlen != length(y)) stop("x and y must be the same length.")
 for(i in 1:xlen) {
  for(j in 1:xlen) {
   if(i != j) {
    dist<-sqrt((x[i]-x[j])^2 + (y[i]-y[j])^2)
    if(dist < tol) {
     if(x[i] >= x[j]) {
      x[i]<-x[i]+away
      x[j]<-x[j]-away
     } else {
      x[i]<-x[i]-away
      x[j]<-x[j]+away
     }
     if(y[i] >= y[j]) {
      y[i]<-y[i]+away
      y[j]<-y[j]-away
     } else {
      y[i]<-y[i]-away
      y[j]<-y[j]+away
     }
    }
   }
  }
 }
 return(list(x=x,y=y))
}
x=c(-1.9116, -1.9116,-1.9237,-1.91848)
y=c(52.4898,52.4898,52.5015,52.4851)
plot(nudge(x,y,0.0001,0.00001))

Jim

On Sat, Jan 20, 2018 at 4:51 AM, Gavin Rudge (Institute of Applied
Health Research) <G.Rudge at bham.ac.uk> wrote:
> I have a dataset showing points, with a category for each point and its location.
>
> I simply want to display my points, in a way that users can toggle the points on and off by category.
>
> Where I have two objects in the same category I'd like to display them nudged to appear as two distinct, but very close points.
> I have made reproduceable example (the places are not real), which is loosely based on a tutorial I found recently (https://allthisblog.wordpress.com/2016/10/12/r-311-with-leaflet-tutorial/)
>
> I have three categories of things (cafes, libraries and galleries), at three locations but have four objects in my set. This is because on of my locations has two functions - there is a cafe at a gallery (North St Gallery and the Gallery Cafe on the same site)
>
> If I make a selection that includes galleries and cafes there are just two points. I would like to nudge the point for the North St Galley and the Gallery Cafe so they appear as two (very close) points on the map and display the name when clicked on.
>
> Also if anyone has any suggestions for generally tidying up the code I'd be grateful as my real version is much more complex with many more points and marker categories.   I believe there are Java libraries out there for managing markers and how they behave, but I'm hoping this can be done in the Leaflet R library somehow.
>
> The only solution I could think of was to interrogate the entire dataframe, identify points that were had the same co-ords and move them diagonally apart by adding and subtracting a fixed amount of longitude and latitude from the co-ordinates.
>
> Thanks in advance.
>
> GavinR
>
> Here is the code:
>
> library(leaflet)
>
> #make data frame of points
>
> idno=c(1,2,3,4)
> x=c(-1.9116, -1.9116,-1.9237,-1.91848)
> y=c(52.4898,52.4898,52.5015,52.4851)
> cat=c('Gallery','Cafe','Library','Cafe')
> n=c('North St Gallery','Gallery cafe', 'South St Library', 'Coffee 2 go')
> d<-data.frame(idno,x,y,cat,n)
>
> #get a map and zoom into approx area of interest
>
> m=leaflet()%>% setView(lng = -1.935, lat=52.485, zoom=12)
> m=addTiles(m)
> m
>
> #create groups of objects
>
> c= subset(d,cat=="Cafe")
> l= subset(d, cat=="Library")
> g= subset(d, cat=="Gallery")
>
> #add markers
>
> m=addCircleMarkers(m,
>                      lng = c$x,
>                      lat = c$y,
>                      popup = c$n,
>                      radius = 5,
>                      stroke =FALSE,
>                      fillOpacity = 0.75,
>                      group = "1 - Cafes")
>
> m=addCircleMarkers(m,
>                    lng = g$x,
>                    lat = g$y,
>                    popup = g$n,
>                    radius = 5,
>                    stroke =FALSE,
>                    fillOpacity = 0.75,
>                    group = "2 - Galleries")
>
> m=addCircleMarkers(m,
>                    lng = l$x,
>                    lat = l$y,
>                    popup = l$n,
>                    radius = 5,
>                    stroke =FALSE,
>                    fillOpacity = 0.75,
>                    group = "3 - libraries")
>
> m = addLayersControl(m, overlayGroups = c("1 - Cafes","2 - Galleries","3 - libraries"))
>
> m
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marongiu.luigi at gmail.com  Sun Jan 21 09:59:02 2018
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Sun, 21 Jan 2018 09:59:02 +0100
Subject: [R] substr gives empty output
Message-ID: <CAMk+s2QZo+TJqrsGD_4BePiexhoTzBOw+GTkJYwhAY+Mj_oQpg@mail.gmail.com>

Dear all,
I have a string, let's say "testing", and I would like to extract in
sequence each letter (character) from it. But when I use substr() I only
properly get the first character, the rest is empty (""). What am I getting
wrong?
For example, I have this code:

>>>
x <- "testing"
k <- nchar(x)
for (i in 1:k) {
  y <- substr(x, i, 1)
  print(y)
}

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun Jan 21 10:17:25 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 21 Jan 2018 22:17:25 +1300
Subject: [R] [FORGED]  substr gives empty output
In-Reply-To: <CAMk+s2QZo+TJqrsGD_4BePiexhoTzBOw+GTkJYwhAY+Mj_oQpg@mail.gmail.com>
References: <CAMk+s2QZo+TJqrsGD_4BePiexhoTzBOw+GTkJYwhAY+Mj_oQpg@mail.gmail.com>
Message-ID: <84d8aa85-7dfb-3866-ce7d-f99d6ba1e36f@auckland.ac.nz>


On 21/01/18 21:59, Luigi Marongiu wrote:
> Dear all,
> I have a string, let's say "testing", and I would like to extract in
> sequence each letter (character) from it. But when I use substr() I only
> properly get the first character, the rest is empty (""). What am I getting
> wrong?

What you're getting wrong is failing the read the help for substr(). 
The third argument is "stop", not the length of the substring.

> For example, I have this code:
> 
>>>>
> x <- "testing"
> k <- nchar(x)
> for (i in 1:k) {
>    y <- substr(x, i, 1)
>    print(y)
> }

You want y <- substr(x,i,i).

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ted.harding at wlandres.net  Sun Jan 21 10:35:08 2018
From: ted.harding at wlandres.net (Ted Harding)
Date: Sun, 21 Jan 2018 09:35:08 +0000
Subject: [R] substr gives empty output
In-Reply-To: <CAMk+s2QZo+TJqrsGD_4BePiexhoTzBOw+GTkJYwhAY+Mj_oQpg@mail.gmail.com>
References: <CAMk+s2QZo+TJqrsGD_4BePiexhoTzBOw+GTkJYwhAY+Mj_oQpg@mail.gmail.com>
Message-ID: <1516527308.3894.15.camel@deb2.fort.knox.uk>

On Sun, 2018-01-21 at 09:59 +0100, Luigi Marongiu wrote:
> Dear all,
> I have a string, let's say "testing", and I would like to extract in
> sequence each letter (character) from it. But when I use substr() I only
> properly get the first character, the rest is empty (""). What am I getting
> wrong?
> For example, I have this code:
> 
> >>>
> x <- "testing"
> k <- nchar(x)
> for (i in 1:k) {
>   y <- substr(x, i, 1)
>   print(y)
> }

>From the help page
  substr(x, start, stop)
where 'start' is the position in the character vector x at which the
substring starts, and 'stop' is the position at which it stops.

Hence 'stop' must be >= 'start'; and if they are equal then you get
just the single character. That is the case in your code, when i=1;
when i > 1 then stop < start, so you get nothing. Compare with:

  x <- "testing"
  k <- nchar(x)
  for (i in 1:k) { 
    y <- substr(x, i, i)  ### was: substr(x, i, 1)
    print(y)
  }

[1] "t"
[1] "e"
[1] "s"
[1] "t"
[1] "i"
[1] "n"
[1] "g"

Hoping this helps,
Ted.


From esawiek at gmail.com  Sun Jan 21 16:50:31 2018
From: esawiek at gmail.com (Ek Esawi)
Date: Sun, 21 Jan 2018 10:50:31 -0500
Subject: [R] substr gives empty output
In-Reply-To: <CAMk+s2QZo+TJqrsGD_4BePiexhoTzBOw+GTkJYwhAY+Mj_oQpg@mail.gmail.com>
References: <CAMk+s2QZo+TJqrsGD_4BePiexhoTzBOw+GTkJYwhAY+Mj_oQpg@mail.gmail.com>
Message-ID: <CA+ZkTxubYDSZ3iqsg_=be9HBA2_3-TE95=mXbh4atvG-ri_ixQ@mail.gmail.com>

The reason you get "" is, as stated on the previous response and on
the documentation of substr function, the function "When extracting,
if start is larger than the string length then "" is returned.". This
is what happens on your function.

HTH

EK

On Sun, Jan 21, 2018 at 3:59 AM, Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
> Dear all,
> I have a string, let's say "testing", and I would like to extract in
> sequence each letter (character) from it. But when I use substr() I only
> properly get the first character, the rest is empty (""). What am I getting
> wrong?
> For example, I have this code:
>
>>>>
> x <- "testing"
> k <- nchar(x)
> for (i in 1:k) {
>   y <- substr(x, i, 1)
>   print(y)
> }
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From redmonc at gmail.com  Sun Jan 21 17:45:39 2018
From: redmonc at gmail.com (Charlie Redmon)
Date: Sun, 21 Jan 2018 10:45:39 -0600
Subject: [R] Split charts with ggplot2, tidyquant
In-Reply-To: <CAGxFJbTZSuHzQsEdRpojJrmGkYT0Tf3v=wt1cMqH-E4ZK4pmDg@mail.gmail.com>
References: <2a39d9c8-a204-4060-e3de-3548ef5ada15@gmail.com>
 <CAGgJW75ZCwdXt2wbOTPAo5o-PBR=kzdE5TNo+t8uZcTekfiNiA@mail.gmail.com>
 <48135866-cc09-a588-8f54-0ca242c0e79a@gmail.com>
 <CAGgJW76zved0JXzGVVUfjxJRxhK=aGNPvqWaVTfSeAtYMC8cow@mail.gmail.com>
 <6dbde910-c628-8aa7-cdad-c45a3ba97184@gmail.com>
 <CAGxFJbTZSuHzQsEdRpojJrmGkYT0Tf3v=wt1cMqH-E4ZK4pmDg@mail.gmail.com>
Message-ID: <d047c7e9-adcd-de11-1273-5c1d58ea974c@gmail.com>

Thanks for the reminder about lattice! I did some searching and there's 
a good example of manipulating the size of subplots using the `position` 
argument (see pp. 202-203 in the Trellis Users Guide: 
http://ml.stat.purdue.edu/stat695t/writings/Trellis.User.pdf). This is 
not within the paneling environment with the headers like in other 
trellis plots though, so you'll have to do a bit more digging to see how 
to get that to work if you need those headers.


Best,

Charlie


On 01/20/2018 03:17 PM, Bert Gunter wrote:
> That (the need for base graphics) is false. It certainly **can** be 
> done in base graphics -- see ?layout for a perhaps more 
> straightforward way to do it along the lines you suggest.
>
> However both lattice and ggplot are based on grid graphics, which has 
> a similar but slightly more flexible ?grid.layout function which would 
> allow one to size and place subsequent ggplot or lattice graphs in an 
> arbitrary layout as you have described (iiuc) for the base graphics case.
>
> Perhaps even simpler would be to use the "position" argument of the 
> print.trellis() function to locate trellis plots. Maybe ggplot() has 
> something similar.
>
> In any case, the underlying grid graphics functionality allows 
> **much** greater fine control of graphical elements (including 
> rotation, for example) -- at the cost of greater complexity. I would 
> agree that doing it from scratch using base grid functions is most 
> likely overkill here, though. But it's there.
>
> IMHO only, the base graphics system was great in its time, but its 
> time has passed. Grid graphics is much more powerful because it is 
> objects based -- that is, grid graphs are objects that can be saved, 
> modified, and even interacted with in flexible ways. Lattice and 
> ggplot incarnations take advantage of this, giving them more power and 
> flexibility than the base graphics capabilities can muster.
>
> I repeat -- IMHO only! Feel free to disagree. I don't want to start 
> any flame wars here.
>
> Cheers,
> Bert
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sat, Jan 20, 2018 at 12:19 PM, Charlie Redmon <redmonc at gmail.com 
> <mailto:redmonc at gmail.com>> wrote:
>
>     For this kind of control you will probably need to move to base
>     graphics
>     and utilize the `fig` argument in par(), in which case you would
>     want to
>     run the plot() command twice: once with your first outcome and
>     once with
>     your second, changing the par() settings before each one to
>     control the
>     size.
>
>
>     On 01/19/2018 01:39 PM, Eric Berger wrote:
>     > Hi Charlie,
>     > Thanks. This is helpful. As mentioned in my original question, I
>     want
>     > to be able to plot a few such charts on the same page,
>     > say a 2 x 2 grid with such a chart for each of 4 different stocks.
>     > Using your solution I accomplished this by making
>     > a list pLst of your ggplots and then calling cowplot::plot_grid(
>     > plotlist=pLst, nrow=2, ncol=2 )? That worked fine.
>     >
>     > The one issue? I have is that in the ggplot you suggest, the
>     price and
>     > volume facets are the same size. I would like them to be
>     different sizes
>     > (e.g. the volume facet at the bottom is generally shown smaller than
>     > the facet above it in these types of charts.)
>     >
>     > I tried to find out how to do it but didn't succeed. I found a
>     couple
>     > of relevant discussions (including Hadley writing that he did not
>     > think it was a useful feature. :-()
>     >
>     > https://github.com/tidyverse/ggplot2/issues/566
>     <https://github.com/tidyverse/ggplot2/issues/566>
>     >
>     > and an ancient one where someone seems to have been able to get a
>     > heights parameter working in a call to facet_grid but it did not
>     work
>     > for me.
>     >
>     https://kohske.wordpress.com/2010/12/25/adjusting-the-relative-space-of-a-facet-grid/
>     <https://kohske.wordpress.com/2010/12/25/adjusting-the-relative-space-of-a-facet-grid/>
>     >
>     > Thanks again,
>     > Eric
>     >
>     > p.s. Joshua thanks for your suggestions, but I was hoping for a
>     ggplot
>     > solution.
>     >
>     >
>     > On Fri, Jan 19, 2018 at 6:33 PM, Charlie Redmon
>     <redmonc at gmail.com <mailto:redmonc at gmail.com>
>     > <mailto:redmonc at gmail.com <mailto:redmonc at gmail.com>>> wrote:
>     >
>     >? ? ?So the general strategy for getting these into separate
>     panels in
>     >? ? ?ggplot is to have a single variable that will be your
>     response and
>     >? ? ?a factor variable that indexes which original variable it came
>     >? ? ?from. This can be accomplished in many ways, but the way I
>     use is
>     >? ? ?with the melt() function in the reshape2 package.
>     >? ? ?For example,
>     >
>     >? ? ?library(reshape2)
>     >? ? ?plotDF <- melt(SPYdf,
>     >? ? ???? ??? ??? ??? ??? ??? id.vars="Date", # variables to replicate
>     >? ? ???? ??? ??? ??? ??? ??? measure.vars=c("close", "volume"), #
>     >? ? ?variables to create index from
>     > variable.name <http://variable.name>
>     <http://variable.name>="parameter", # name of new
>     >? ? ?variable for index
>     > value.name <http://value.name> <http://value.name>="resp") #
>     name of what will be your
>     >? ? ?response variable
>     >
>     >? ? ?Now the ggplot2 code:
>     >
>     >? ? ?library(ggplot2)
>     >? ? ?ggplot(plotDF, aes(x=Date, y=resp)) +
>     >? ? ???? facet_wrap(~parameter, ncol=1, scales="free") +
>     >? ? ???? geom_line()
>     >
>     >
>     >? ? ?Hope that does the trick!
>     >
>     >? ? ?Charlie
>     >
>     >
>     >
>     >? ? ?On 01/18/2018 02:11 PM, Eric Berger wrote:
>     >
>     >? ? ? ? ?Hi Charlie,
>     >? ? ? ? ?I am comfortable to put the data in any way that works best.
>     >? ? ? ? ?Here are two possibilities: an xts and a data frame.
>     >
>     >? ? ? ? ?library(quantmod)
>     >? ? ? ? ?quantmod::getSymbols("SPY")? # creates xts variable SPY
>     >? ? ? ? ?SPYxts <- SPY[,c("SPY.Close","SPY.Volume")]
>     >? ? ? ? ?SPYdf? <-
>     >? ? ? ?
>     ?data.frame(Date=index(SPYxts),close=as.numeric(SPYxts$SPY.Close),
>     >? ? ? ? ??volume=as.numeric(SPYxts$SPY.Volume))
>     >? ? ? ? ?rownames(SPYdf) <- NULL
>     >
>     >? ? ? ? ?head(SPYxts)
>     >? ? ? ? ?head(SPYdf)
>     >
>     >? ? ? ? ?#? ? ? ? ? ?SPY.Close SPY.Volume
>     >? ? ? ? ?#2007-01-03? ? 141.37? ?94807600
>     >? ? ? ? ?#2007-01-04? ? 141.67? ?69620600
>     >? ? ? ? ?#2007-01-05? ? 140.54? ?76645300
>     >? ? ? ? ?#2007-01-08? ? 141.19? ?71655000
>     >? ? ? ? ?#2007-01-09? ? 141.07? ?75680100
>     <tel:07%C2%A0%20%C2%A075680100>
>     >? ? ? ? ?#2007-01-10? ? 141.54? ?72428000
>     >
>     >? ? ? ? ?#? ? ? ? Date? close? ?volume
>     >? ? ? ? ?#1 2007-01-03 141.37 94807600
>     >? ? ? ? ?#2 2007-01-04 141.67 69620600
>     >? ? ? ? ?#3 2007-01-05 140.54 76645300
>     >? ? ? ? ?#4 2007-01-08 141.19 71655000
>     >? ? ? ? ?#5 2007-01-09 141.07 75680100 <tel:07%2075680100>
>     >? ? ? ? ?#6 2007-01-10 141.54 72428000
>     >
>     >? ? ? ? ?Thanks,
>     >? ? ? ? ?Eric
>     >
>     >
>     >
>     >? ? ? ? ?On Thu, Jan 18, 2018 at 8:00 PM, Charlie Redmon
>     >? ? ? ? ?<redmonc at gmail.com <mailto:redmonc at gmail.com>
>     <mailto:redmonc at gmail.com <mailto:redmonc at gmail.com>>
>     >? ? ? ? ?<mailto:redmonc at gmail.com <mailto:redmonc at gmail.com>
>     <mailto:redmonc at gmail.com <mailto:redmonc at gmail.com>>>> wrote:
>     >
>     >? ? ? ? ?? ? Could you provide some information on your data
>     structure
>     >? ? ? ? ?(e.g.,
>     >? ? ? ? ?? ? are the two time series in separate columns in the
>     data)? The
>     >? ? ? ? ?? ? solution is fairly straightforward once you have the
>     data
>     >? ? ? ? ?in the
>     >? ? ? ? ?? ? right structure. And I do not think tidyquant is
>     necessary for
>     >? ? ? ? ?? ? what you want.
>     >
>     >? ? ? ? ?? ? Best,
>     >? ? ? ? ?? ? Charlie
>     >
>     >? ? ? ? ?? ? --? ? ?Charles Redmon
>     >? ? ? ? ?? ? GRA, Center for Research Methods and Data Analysis
>     >? ? ? ? ?? ? PhD Student, Department of Linguistics
>     >? ? ? ? ?? ? University of Kansas
>     >? ? ? ? ?? ? Lawrence, KS, USA
>     >
>     >
>     >
>     >? ? ?--
>     >? ? ?Charles Redmon
>     >? ? ?GRA, Center for Research Methods and Data Analysis
>     >? ? ?PhD Student, Department of Linguistics
>     >? ? ?University of Kansas
>     >? ? ?Lawrence, KS, USA
>     >
>     >
>
>     --
>     Charles Redmon
>     GRA, Center for Research Methods and Data Analysis
>     PhD Student, Department of Linguistics
>     University of Kansas
>     Lawrence, KS, USA
>
>
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
Charles Redmon
GRA, Center for Research Methods and Data Analysis
PhD Student, Department of Linguistics
University of Kansas
Lawrence, KS, USA


From ericjberger at gmail.com  Sun Jan 21 21:54:24 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Sun, 21 Jan 2018 22:54:24 +0200
Subject: [R] Split charts with ggplot2, tidyquant
In-Reply-To: <d047c7e9-adcd-de11-1273-5c1d58ea974c@gmail.com>
References: <2a39d9c8-a204-4060-e3de-3548ef5ada15@gmail.com>
 <CAGgJW75ZCwdXt2wbOTPAo5o-PBR=kzdE5TNo+t8uZcTekfiNiA@mail.gmail.com>
 <48135866-cc09-a588-8f54-0ca242c0e79a@gmail.com>
 <CAGgJW76zved0JXzGVVUfjxJRxhK=aGNPvqWaVTfSeAtYMC8cow@mail.gmail.com>
 <6dbde910-c628-8aa7-cdad-c45a3ba97184@gmail.com>
 <CAGxFJbTZSuHzQsEdRpojJrmGkYT0Tf3v=wt1cMqH-E4ZK4pmDg@mail.gmail.com>
 <d047c7e9-adcd-de11-1273-5c1d58ea974c@gmail.com>
Message-ID: <CAGgJW76J_3q7EJFZ7zTjg0m-1MB4Qq7UwQDtGUx9-N44aM1w5g@mail.gmail.com>

Hi Charlie and Bert,
Thank you both for the suggestions and pointers. I will look into them.

FYI I repeatedly refer to tidyquant because that package refers to itself as
"tidyquant: Tidy Quantitative Financial Analysis" and I am hoping to get the
attention of someone who is involved in the tidyquant package. The type of split
chart I am interested in is standard / prevalent in financial charting,
e.g. the charts on https://www.bloomberg.com/markets/stocks all have
an 'Indicators' button which allows you add, say, a volume chart as a
subchart below the main part of the chart.

Thanks again,
Eric



On Sun, Jan 21, 2018 at 6:45 PM, Charlie Redmon <redmonc at gmail.com> wrote:
> Thanks for the reminder about lattice! I did some searching and there's a
> good example of manipulating the size of subplots using the `position`
> argument (see pp. 202-203 in the Trellis Users Guide:
> http://ml.stat.purdue.edu/stat695t/writings/Trellis.User.pdf). This is not
> within the paneling environment with the headers like in other trellis plots
> though, so you'll have to do a bit more digging to see how to get that to
> work if you need those headers.
>
>
> Best,
>
> Charlie
>
>
> On 01/20/2018 03:17 PM, Bert Gunter wrote:
>>
>> That (the need for base graphics) is false. It certainly **can** be done
>> in base graphics -- see ?layout for a perhaps more straightforward way to do
>> it along the lines you suggest.
>>
>> However both lattice and ggplot are based on grid graphics, which has a
>> similar but slightly more flexible ?grid.layout function which would allow
>> one to size and place subsequent ggplot or lattice graphs in an arbitrary
>> layout as you have described (iiuc) for the base graphics case.
>>
>> Perhaps even simpler would be to use the "position" argument of the
>> print.trellis() function to locate trellis plots. Maybe ggplot() has
>> something similar.
>>
>> In any case, the underlying grid graphics functionality allows **much**
>> greater fine control of graphical elements (including rotation, for example)
>> -- at the cost of greater complexity. I would agree that doing it from
>> scratch using base grid functions is most likely overkill here, though. But
>> it's there.
>>
>> IMHO only, the base graphics system was great in its time, but its time
>> has passed. Grid graphics is much more powerful because it is objects based
>> -- that is, grid graphs are objects that can be saved, modified, and even
>> interacted with in flexible ways. Lattice and ggplot incarnations take
>> advantage of this, giving them more power and flexibility than the base
>> graphics capabilities can muster.
>>
>> I repeat -- IMHO only! Feel free to disagree. I don't want to start any
>> flame wars here.
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Sat, Jan 20, 2018 at 12:19 PM, Charlie Redmon <redmonc at gmail.com
>> <mailto:redmonc at gmail.com>> wrote:
>>
>>     For this kind of control you will probably need to move to base
>>     graphics
>>     and utilize the `fig` argument in par(), in which case you would
>>     want to
>>     run the plot() command twice: once with your first outcome and
>>     once with
>>     your second, changing the par() settings before each one to
>>     control the
>>     size.
>>
>>
>>     On 01/19/2018 01:39 PM, Eric Berger wrote:
>>     > Hi Charlie,
>>     > Thanks. This is helpful. As mentioned in my original question, I
>>     want
>>     > to be able to plot a few such charts on the same page,
>>     > say a 2 x 2 grid with such a chart for each of 4 different stocks.
>>     > Using your solution I accomplished this by making
>>     > a list pLst of your ggplots and then calling cowplot::plot_grid(
>>     > plotlist=pLst, nrow=2, ncol=2 )  That worked fine.
>>     >
>>     > The one issue  I have is that in the ggplot you suggest, the
>>     price and
>>     > volume facets are the same size. I would like them to be
>>     different sizes
>>     > (e.g. the volume facet at the bottom is generally shown smaller than
>>     > the facet above it in these types of charts.)
>>     >
>>     > I tried to find out how to do it but didn't succeed. I found a
>>     couple
>>     > of relevant discussions (including Hadley writing that he did not
>>     > think it was a useful feature. :-()
>>     >
>>     > https://github.com/tidyverse/ggplot2/issues/566
>>     <https://github.com/tidyverse/ggplot2/issues/566>
>>     >
>>     > and an ancient one where someone seems to have been able to get a
>>     > heights parameter working in a call to facet_grid but it did not
>>     work
>>     > for me.
>>     >
>>
>> https://kohske.wordpress.com/2010/12/25/adjusting-the-relative-space-of-a-facet-grid/
>>
>> <https://kohske.wordpress.com/2010/12/25/adjusting-the-relative-space-of-a-facet-grid/>
>>     >
>>     > Thanks again,
>>     > Eric
>>     >
>>     > p.s. Joshua thanks for your suggestions, but I was hoping for a
>>     ggplot
>>     > solution.
>>     >
>>     >
>>     > On Fri, Jan 19, 2018 at 6:33 PM, Charlie Redmon
>>     <redmonc at gmail.com <mailto:redmonc at gmail.com>
>>     > <mailto:redmonc at gmail.com <mailto:redmonc at gmail.com>>> wrote:
>>     >
>>     >     So the general strategy for getting these into separate
>>     panels in
>>     >     ggplot is to have a single variable that will be your
>>     response and
>>     >     a factor variable that indexes which original variable it came
>>     >     from. This can be accomplished in many ways, but the way I
>>     use is
>>     >     with the melt() function in the reshape2 package.
>>     >     For example,
>>     >
>>     >     library(reshape2)
>>     >     plotDF <- melt(SPYdf,
>>     >                             id.vars="Date", # variables to replicate
>>     >                             measure.vars=c("close", "volume"), #
>>     >     variables to create index from
>>     > variable.name <http://variable.name>
>>     <http://variable.name>="parameter", # name of new
>>     >     variable for index
>>     > value.name <http://value.name> <http://value.name>="resp") #
>>
>>     name of what will be your
>>     >     response variable
>>     >
>>     >     Now the ggplot2 code:
>>     >
>>     >     library(ggplot2)
>>     >     ggplot(plotDF, aes(x=Date, y=resp)) +
>>     >         facet_wrap(~parameter, ncol=1, scales="free") +
>>     >         geom_line()
>>     >
>>     >
>>     >     Hope that does the trick!
>>     >
>>     >     Charlie
>>     >
>>     >
>>     >
>>     >     On 01/18/2018 02:11 PM, Eric Berger wrote:
>>     >
>>     >         Hi Charlie,
>>     >         I am comfortable to put the data in any way that works best.
>>     >         Here are two possibilities: an xts and a data frame.
>>     >
>>     >         library(quantmod)
>>     >         quantmod::getSymbols("SPY")  # creates xts variable SPY
>>     >         SPYxts <- SPY[,c("SPY.Close","SPY.Volume")]
>>     >         SPYdf  <-
>>     >
>>      data.frame(Date=index(SPYxts),close=as.numeric(SPYxts$SPY.Close),
>>     >          volume=as.numeric(SPYxts$SPY.Volume))
>>     >         rownames(SPYdf) <- NULL
>>     >
>>     >         head(SPYxts)
>>     >         head(SPYdf)
>>     >
>>     >         #           SPY.Close SPY.Volume
>>     >         #2007-01-03    141.37   94807600
>>     >         #2007-01-04    141.67   69620600
>>     >         #2007-01-05    140.54   76645300
>>     >         #2007-01-08    141.19   71655000
>>     >         #2007-01-09    141.07   75680100
>>     <tel:07%C2%A0%20%C2%A075680100>
>>     >         #2007-01-10    141.54   72428000
>>     >
>>     >         #        Date  close   volume
>>     >         #1 2007-01-03 141.37 94807600
>>     >         #2 2007-01-04 141.67 69620600
>>     >         #3 2007-01-05 140.54 76645300
>>     >         #4 2007-01-08 141.19 71655000
>>     >         #5 2007-01-09 141.07 75680100 <tel:07%2075680100>
>>     >         #6 2007-01-10 141.54 72428000
>>     >
>>     >         Thanks,
>>     >         Eric
>>     >
>>     >
>>     >
>>     >         On Thu, Jan 18, 2018 at 8:00 PM, Charlie Redmon
>>     >         <redmonc at gmail.com <mailto:redmonc at gmail.com>
>>     <mailto:redmonc at gmail.com <mailto:redmonc at gmail.com>>
>>     >         <mailto:redmonc at gmail.com <mailto:redmonc at gmail.com>
>>     <mailto:redmonc at gmail.com <mailto:redmonc at gmail.com>>>> wrote:
>>     >
>>     >             Could you provide some information on your data
>>     structure
>>     >         (e.g.,
>>     >             are the two time series in separate columns in the
>>     data)? The
>>     >             solution is fairly straightforward once you have the
>>     data
>>     >         in the
>>     >             right structure. And I do not think tidyquant is
>>     necessary for
>>     >             what you want.
>>     >
>>     >             Best,
>>     >             Charlie
>>     >
>>     >             --     Charles Redmon
>>     >             GRA, Center for Research Methods and Data Analysis
>>     >             PhD Student, Department of Linguistics
>>     >             University of Kansas
>>     >             Lawrence, KS, USA
>>     >
>>     >
>>     >
>>     >     --
>>     >     Charles Redmon
>>     >     GRA, Center for Research Methods and Data Analysis
>>     >     PhD Student, Department of Linguistics
>>     >     University of Kansas
>>     >     Lawrence, KS, USA
>>     >
>>     >
>>
>>     --
>>     Charles Redmon
>>     GRA, Center for Research Methods and Data Analysis
>>     PhD Student, Department of Linguistics
>>     University of Kansas
>>     Lawrence, KS, USA
>>
>>
>>             [[alternative HTML version deleted]]
>>
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>     To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     <http://www.R-project.org/posting-guide.html>
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> --
> Charles Redmon
> GRA, Center for Research Methods and Data Analysis
> PhD Student, Department of Linguistics
> University of Kansas
> Lawrence, KS, USA
>


From giftedlife2014 at gmail.com  Mon Jan 22 08:01:05 2018
From: giftedlife2014 at gmail.com (Ogbos Okike)
Date: Mon, 22 Jan 2018 08:01:05 +0100
Subject: [R] Manipulating two large dataset differing by date and time
Message-ID: <CAC8ss30dqxp_wG-8T95wOpFLe-Z2yNC6N_DfHMG0eqQzrFY-7g@mail.gmail.com>

Dear Members,

Compliments of the Season!!


Below is a part of a code I use for Fourier analysis of signals. The code
handles data with the format 05 01 01    8628 (year, month, day and count)
                              05 01 02    8589 (year, month, day and count)
The sample data is attached as 2005daily.txt.

I would like to adapt the code to handle data of the form:
05 01 01 00    4009 (year, month, day, hour and count)
05 01 01 01    3969 (year, month, day, hour and count)

The sample is also attached as 2005hourly.txt.

Thank you very much for your kind inputs.

Ogbos




data <- read.table("2005daily.txt", col.names = c("year", "month", "day",
"counts"))

new.century <- data$year < 50

data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)

data$date <- as.Date(ISOdate(data$year, data$month, data$day))
x1 = data$date
 y = data$counts

From drjimlemon at gmail.com  Mon Jan 22 08:21:57 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 22 Jan 2018 18:21:57 +1100
Subject: [R] Manipulating two large dataset differing by date and time
In-Reply-To: <CAC8ss30dqxp_wG-8T95wOpFLe-Z2yNC6N_DfHMG0eqQzrFY-7g@mail.gmail.com>
References: <CAC8ss30dqxp_wG-8T95wOpFLe-Z2yNC6N_DfHMG0eqQzrFY-7g@mail.gmail.com>
Message-ID: <CA+8X3fX9=6C3nD+mAhfzXpSxkfEBGwQ-qnh87YOm9VeVccV02g@mail.gmail.com>

Hi Ogbos,
You can just use ISOdate. If you pass more values, it will process them:

ISOdate(2018,01,22)
[1] "2018-01-22 12:00:00 GMT"
> ISOdate(2018,01,22,18,17)
[1] "2018-01-22 18:17:00 GMT"

Add something like:

if(is.null(data$hour),data$hour<-12

then pass data$hour as it will default to the same value as if you
hadn't passed it.

Jim

On Mon, Jan 22, 2018 at 6:01 PM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> Dear Members,
>
> Compliments of the Season!!
>
>
> Below is a part of a code I use for Fourier analysis of signals. The code
> handles data with the format 05 01 01    8628 (year, month, day and count)
>                               05 01 02    8589 (year, month, day and count)
> The sample data is attached as 2005daily.txt.
>
> I would like to adapt the code to handle data of the form:
> 05 01 01 00    4009 (year, month, day, hour and count)
> 05 01 01 01    3969 (year, month, day, hour and count)
>
> The sample is also attached as 2005hourly.txt.
>
> Thank you very much for your kind inputs.
>
> Ogbos
>
>
>
>
> data <- read.table("2005daily.txt", col.names = c("year", "month", "day",
> "counts"))
>
> new.century <- data$year < 50
>
> data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)
>
> data$date <- as.Date(ISOdate(data$year, data$month, data$day))
> x1 = data$date
>  y = data$counts
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From giftedlife2014 at gmail.com  Mon Jan 22 09:07:06 2018
From: giftedlife2014 at gmail.com (Ogbos Okike)
Date: Mon, 22 Jan 2018 09:07:06 +0100
Subject: [R] Manipulating two large dataset differing by date and time
In-Reply-To: <CA+8X3fX9=6C3nD+mAhfzXpSxkfEBGwQ-qnh87YOm9VeVccV02g@mail.gmail.com>
References: <CAC8ss30dqxp_wG-8T95wOpFLe-Z2yNC6N_DfHMG0eqQzrFY-7g@mail.gmail.com>
 <CA+8X3fX9=6C3nD+mAhfzXpSxkfEBGwQ-qnh87YOm9VeVccV02g@mail.gmail.com>
Message-ID: <CAC8ss31JxH4Zog4J7cyNfLVdTebnoYCq9XmYy-oDbrCCzRw1Yg@mail.gmail.com>

Hello Jim,

Thank you so much for your attention. It handled the hourly data with ease.
Best wishes
Ogbos

On Mon, Jan 22, 2018 at 8:21 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Ogbos,
> You can just use ISOdate. If you pass more values, it will process them:
>
> ISOdate(2018,01,22)
> [1] "2018-01-22 12:00:00 GMT"
> > ISOdate(2018,01,22,18,17)
> [1] "2018-01-22 18:17:00 GMT"
>
> Add something like:
>
> if(is.null(data$hour),data$hour<-12
>
> then pass data$hour as it will default to the same value as if you
> hadn't passed it.
>
> Jim
>
> On Mon, Jan 22, 2018 at 6:01 PM, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> > Dear Members,
> >
> > Compliments of the Season!!
> >
> >
> > Below is a part of a code I use for Fourier analysis of signals. The code
> > handles data with the format 05 01 01    8628 (year, month, day and
> count)
> >                               05 01 02    8589 (year, month, day and
> count)
> > The sample data is attached as 2005daily.txt.
> >
> > I would like to adapt the code to handle data of the form:
> > 05 01 01 00    4009 (year, month, day, hour and count)
> > 05 01 01 01    3969 (year, month, day, hour and count)
> >
> > The sample is also attached as 2005hourly.txt.
> >
> > Thank you very much for your kind inputs.
> >
> > Ogbos
> >
> >
> >
> >
> > data <- read.table("2005daily.txt", col.names = c("year", "month", "day",
> > "counts"))
> >
> > new.century <- data$year < 50
> >
> > data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)
> >
> > data$date <- as.Date(ISOdate(data$year, data$month, data$day))
> > x1 = data$date
> >  y = data$counts
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From iliofornasero at hotmail.com  Mon Jan 22 09:27:30 2018
From: iliofornasero at hotmail.com (Ilio Fornasero)
Date: Mon, 22 Jan 2018 08:27:30 +0000
Subject: [R] Web scraping different levels of a website
In-Reply-To: <CAOXhLq57uvMcPhGeHXQXwbashzeMKmf3mgeKQUAPbu+dT6GSiA@mail.gmail.com>
References: <CAOXhLq57uvMcPhGeHXQXwbashzeMKmf3mgeKQUAPbu+dT6GSiA@mail.gmail.com>
Message-ID: <AM4PR0802MB2275F96A282ECD1CD250FA6BB3EC0@AM4PR0802MB2275.eurprd08.prod.outlook.com>

Thanks again, David.

I am trying to figure out a way to convert the lists into a data.frame.

Any hint?

The usual ways (do.call, etc) do not seem to work...

Thanks

Ilio

________________________________
Da: David Jankoski <david.jankoski at hellotrip.nl>
Inviato: venerd? 19 gennaio 2018 15:58
A: iliofornasero at hotmail.com; r-help at r-project.org
Oggetto: Re: [R] Web scraping different levels of a website

Hey Ilio,

I revisited the previous code i posted to you and fixed some things.
This should let you collect as many studies as you like, controlled by
the num_studies arg.

If you try the below url in your browser you can see that it returns a
"simpler" version of the link you posted. To get to this you need to
hit F12 to open Developer Tools --> go to Network tab and click on the
first entry in the list --> in the right pane you should see under the
Headers tab the Request URL.

I'm not very knowledgable in sessions/cookies and what nots - but it
might be that you face some further problems. In which case you could
try to do the above on your side and then copy paste that url that you
find there in the below code. I broke the url in smaller chunks for
readability and because its easier to substitute some query
paramaters.

# load libs
library("rvest")
library("httr")
library("glue")
library("magrittr")

# number of studies to pull from catalogue
num_studies <- 42
year_from <- 1890
year_to <- 2017

# build up the url
url <-
  glue(
    "http://catalog.ihsn.org/index.php/catalog/",
IHSN Survey Catalog<http://catalog.ihsn.org/index.php/catalog/>
catalog.ihsn.org
By: Central Statistics Organization - Government of the Islamic Republic of Afghanistan, United Nations Children?s Fund


    "search?view=s&",
    "ps={num_studies}&",
    "page=1&repo=&repo_ref=&sid=&_r=&sk=&vk=&",
    "from={year_from}&",
    "to={year_to}&",
    "sort_order=&sort_by=nation&_=1516371984886")

# read in the html
x <-
  url %>%
  GET() %>%
  content()

# option 1 (div with class "survey-row" --> data-url attribute)
x %>%
  html_nodes(".survey-row") %>%
  html_attr("data-url")

# option 2 (studies titles are <a> within <h2> elems)
# note that this give you some more information like the title ...
x %>%
  html_nodes("h2 a")


greetings,
david

On 18 January 2018 at 12:58, David Jankoski <david.jankoski at hellotrip.nl> wrote:
>
> Hey Ilio,
>
> On the main website (the first link that you provided) if you
> right-click on the title of any entry and select Inspect Element from
> the menu, you will notice in the Developer Tools view that opens up
> that the corresponding html looks like this
>
> (example for the same link that you provided)
>
> <div class="survey-row"
> data-url="http://catalog.ihsn.org/index.php/catalog/7118" title="View
Afghanistan - Demographic and Health Survey 2015<http://catalog.ihsn.org/index.php/catalog/7118>
catalog.ihsn.org
Author(s) Central Statistics Organization, Ansari Watt, Kabul, Afghanistan Ministry of Public Health, Wazir Akbar Khan, Kabul, Afghanistan The DHS Program, ICF ...


> study">
>     <div class="data-access-icon data-access-remote" title="Data
> available from external repository"></div>
>         <h2 class="title">
>             <a href="http://catalog.ihsn.org/index.php/catalog/7118"
Afghanistan - Demographic and Health Survey 2015<http://catalog.ihsn.org/index.php/catalog/7118>
catalog.ihsn.org
Author(s) Central Statistics Organization, Ansari Watt, Kabul, Afghanistan Ministry of Public Health, Wazir Akbar Khan, Kabul, Afghanistan The DHS Program, ICF ...


> title="Demographic and Health Survey 2015">
>               Demographic and Health Survey 2015
>             </a>
>       </h2>
>
> Notice how the number you are after is contained within the
> "survey-row" div element, in the data-url attribute. Or alternatively
> withing the <a> elem within the href attribute. It's up to you which
> one you want to grab but the idea would be the same i.e.
>
> 1. read in the html
> 2. select all list-elements by css / xpath
> 3. grab the fwd link
>
> Here is an example using the first option.
>
> url <- "http://catalog.ihsn.org/index.php/catalog#_r=&collection=&country=&dtype=&from=1890&page=1&ps=100&sid=&sk=&sort_by=nation&sort_order=&to=2017&topic=&view=s&vk="
IHSN Survey Catalog<http://catalog.ihsn.org/index.php/catalog#_r=&collection=&country=&dtype=&from=1890&page=1&ps=100&sid=&sk=&sort_by=nation&sort_order=&to=2017&topic=&view=s&vk=>
catalog.ihsn.org
By: Central Statistics Organization - Government of the Islamic Republic of Afghanistan, United Nations Children?s Fund


>
> x <-
>   url %>%
>   GET() %>%
>   content()
>
> x %>%
>   html_nodes(".survey-row") %>%
>   html_attr("data-url")
>
> hth.
> david




--

David Jankoski

Teerketelsteeg 1
1012TB Amsterdam
www.hellotrip.com<http://www.hellotrip.com>

	[[alternative HTML version deleted]]


From sharada.ramadass at gmail.com  Mon Jan 22 11:55:26 2018
From: sharada.ramadass at gmail.com (Sharada Ramadass)
Date: Mon, 22 Jan 2018 16:25:26 +0530
Subject: [R] what does the within component of varcomp (ape library) output
	indicate?
Message-ID: <CAG=Fgt9ynTtETmTsORZUChPOwNJRsnXBGnQabwJB-SYvC4AEyg@mail.gmail.com>

I am trying to use varcomp to obtain the variance partitioning across
different nested levels of random effects (say x,y and z). I get the
three variance components (for each of my along with an additional one
called 'within' from varcomp output. I am using the 'scale total
variance to 1' option and though the within component is small, it
does form a part of what explains the complete variance. I am unable
to understand what variance this 'within' defines.

Can someone kindly explain or provide a reference?

Thanks,
Sharada


From tim.howard at dec.ny.gov  Mon Jan 22 13:58:27 2018
From: tim.howard at dec.ny.gov (Howard, Tim G (DEC))
Date: Mon, 22 Jan 2018 12:58:27 +0000
Subject: [R] substr gives empty output
Message-ID: <CY1PR09MB0906E50469C1B23CA7E308D0A8EC0@CY1PR09MB0906.namprd09.prod.outlook.com>

In 

 y <- substr(x, i, 1)

your third integer needs to be the location not the number of digits, so change it to 

 y <- substr(x, i, i)

and you should get what you want. 
Cheers, 
Tim

> Date: Sun, 21 Jan 2018 10:50:31 -0500
> From: Ek Esawi <esawiek at gmail.com>
> To: Luigi Marongiu <marongiu.luigi at gmail.com>, r-help at r-project.org
> Subject: Re: [R] substr gives empty output
> Message-ID:
>         <CA+ZkTxubYDSZ3iqsg_=be9HBA2_3-TE95=mXbh4atvG-
> ri_ixQ at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
> 
> The reason you get "" is, as stated on the previous response and on the
> documentation of substr function, the function "When extracting, if start is
> larger than the string length then "" is returned.". This is what happens on
> your function.
> 
> HTH
> 
> EK
> 
> On Sun, Jan 21, 2018 at 3:59 AM, Luigi Marongiu <marongiu.luigi at gmail.com>
> wrote:
> > Dear all,
> > I have a string, let's say "testing", and I would like to extract in
> > sequence each letter (character) from it. But when I use substr() I
> > only properly get the first character, the rest is empty (""). What am
> > I getting wrong?
> > For example, I have this code:
> >
> >>>>
> > x <- "testing"
> > k <- nchar(x)
> > for (i in 1:k) {
> >   y <- substr(x, i, 1)
> >   print(y)
> > }
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 


From bgunter.4567 at gmail.com  Mon Jan 22 16:26:13 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 22 Jan 2018 07:26:13 -0800
Subject: [R] what does the within component of varcomp (ape library)
 output indicate?
In-Reply-To: <CAG=Fgt9ynTtETmTsORZUChPOwNJRsnXBGnQabwJB-SYvC4AEyg@mail.gmail.com>
References: <CAG=Fgt9ynTtETmTsORZUChPOwNJRsnXBGnQabwJB-SYvC4AEyg@mail.gmail.com>
Message-ID: <CAGxFJbSJ_u2F1--W66M9wzN3Ppzoe05J8Nc6edD28Jaj3B-rbg@mail.gmail.com>

Probably not without knowing the structure of your data.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jan 22, 2018 at 2:55 AM, Sharada Ramadass <
sharada.ramadass at gmail.com> wrote:

> I am trying to use varcomp to obtain the variance partitioning across
> different nested levels of random effects (say x,y and z). I get the
> three variance components (for each of my along with an additional one
> called 'within' from varcomp output. I am using the 'scale total
> variance to 1' option and though the within component is small, it
> does form a part of what explains the complete variance. I am unable
> to understand what variance this 'within' defines.
>
> Can someone kindly explain or provide a reference?
>
> Thanks,
> Sharada
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Jan 22 16:38:48 2018
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 22 Jan 2018 15:38:48 +0000
Subject: [R] substr gives empty output
In-Reply-To: <CY1PR09MB0906E50469C1B23CA7E308D0A8EC0@CY1PR09MB0906.namprd09.prod.outlook.com>
References: <CY1PR09MB0906E50469C1B23CA7E308D0A8EC0@CY1PR09MB0906.namprd09.prod.outlook.com>
Message-ID: <3b5dbfc044104c0ba3a41fce70328b11@exch-2p-mbx-t2.ads.tamu.edu>

There is also a way to do this without a loop:

> strsplit(x, "")
[[1]]
[1] "t" "e" "s" "t" "i" "n" "g"
# Or if you just want the vector
> strsplit(x, "")[[1]]
[1] "t" "e" "s" "t" "i" "n" "g"

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Howard, Tim G (DEC)
Sent: Monday, January 22, 2018 6:58 AM
To: r-help at r-project.org; Luigi Marongiu <marongiu.luigi at gmail.com>
Subject: Re: [R] substr gives empty output

In 

 y <- substr(x, i, 1)

your third integer needs to be the location not the number of digits, so change it to 

 y <- substr(x, i, i)

and you should get what you want. 
Cheers,
Tim

> Date: Sun, 21 Jan 2018 10:50:31 -0500
> From: Ek Esawi <esawiek at gmail.com>
> To: Luigi Marongiu <marongiu.luigi at gmail.com>, r-help at r-project.org
> Subject: Re: [R] substr gives empty output
> Message-ID:
>         <CA+ZkTxubYDSZ3iqsg_=be9HBA2_3-TE95=mXbh4atvG-
> ri_ixQ at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
> 
> The reason you get "" is, as stated on the previous response and on 
> the documentation of substr function, the function "When extracting, 
> if start is larger than the string length then "" is returned.". This 
> is what happens on your function.
> 
> HTH
> 
> EK
> 
> On Sun, Jan 21, 2018 at 3:59 AM, Luigi Marongiu 
> <marongiu.luigi at gmail.com>
> wrote:
> > Dear all,
> > I have a string, let's say "testing", and I would like to extract in 
> > sequence each letter (character) from it. But when I use substr() I 
> > only properly get the first character, the rest is empty (""). What 
> > am I getting wrong?
> > For example, I have this code:
> >
> >>>>
> > x <- "testing"
> > k <- nchar(x)
> > for (i in 1:k) {
> >   y <- substr(x, i, 1)
> >   print(y)
> > }
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From marongiu.luigi at gmail.com  Tue Jan 23 11:48:21 2018
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Tue, 23 Jan 2018 11:48:21 +0100
Subject: [R] substr gives empty output
In-Reply-To: <CY1PR09MB0906E50469C1B23CA7E308D0A8EC0@CY1PR09MB0906.namprd09.prod.outlook.com>
References: <CY1PR09MB0906E50469C1B23CA7E308D0A8EC0@CY1PR09MB0906.namprd09.prod.outlook.com>
Message-ID: <CAMk+s2RCw3=ASNBMP4UqBnxr_BmY0h1GqK5z7bR7Yv_fBGQq1Q@mail.gmail.com>

Thank you, I got it, now it works good

On Mon, Jan 22, 2018 at 1:58 PM, Howard, Tim G (DEC) <tim.howard at dec.ny.gov>
wrote:

> In
>
>  y <- substr(x, i, 1)
>
> your third integer needs to be the location not the number of digits, so
> change it to
>
>  y <- substr(x, i, i)
>
> and you should get what you want.
> Cheers,
> Tim
>
> > Date: Sun, 21 Jan 2018 10:50:31 -0500
> > From: Ek Esawi <esawiek at gmail.com>
> > To: Luigi Marongiu <marongiu.luigi at gmail.com>, r-help at r-project.org
> > Subject: Re: [R] substr gives empty output
> > Message-ID:
> >         <CA+ZkTxubYDSZ3iqsg_=be9HBA2_3-TE95=mXbh4atvG-
> > ri_ixQ at mail.gmail.com>
> > Content-Type: text/plain; charset="UTF-8"
> >
> > The reason you get "" is, as stated on the previous response and on the
> > documentation of substr function, the function "When extracting, if
> start is
> > larger than the string length then "" is returned.". This is what
> happens on
> > your function.
> >
> > HTH
> >
> > EK
> >
> > On Sun, Jan 21, 2018 at 3:59 AM, Luigi Marongiu <
> marongiu.luigi at gmail.com>
> > wrote:
> > > Dear all,
> > > I have a string, let's say "testing", and I would like to extract in
> > > sequence each letter (character) from it. But when I use substr() I
> > > only properly get the first character, the rest is empty (""). What am
> > > I getting wrong?
> > > For example, I have this code:
> > >
> > >>>>
> > > x <- "testing"
> > > k <- nchar(x)
> > > for (i in 1:k) {
> > >   y <- substr(x, i, 1)
> > >   print(y)
> > > }
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>

	[[alternative HTML version deleted]]


From mlathouri at yahoo.gr  Tue Jan 23 12:57:35 2018
From: mlathouri at yahoo.gr (Maria Lathouri)
Date: Tue, 23 Jan 2018 11:57:35 +0000 (UTC)
Subject: [R] interaction term by a factor group in gamm4
References: <395802747.5676645.1516708655330.ref@mail.yahoo.com>
Message-ID: <395802747.5676645.1516708655330@mail.yahoo.com>

Dear all, 
I am writing as I would really need your help on the problem with gamm4. I have tried to find a solution online but I wasn't very successful. 
I am running a gamm4 model with an interaction between two variable using the tensor term, t2. I have a group variable (super end group) with six factors; I would like to run the model to see the how the interaction term varies across the factor levels and get the plot for each factor in one page. Here is my code but I get the following message 

dat<-read.table("dat.txt", header=TRUE) 

str(dat) 
#'data.frame':    11744 obs. of  11 variables: 
#$ WATERBODY_ID          : Factor w/ 1994 levels "GB102021072830",..: 1 1 2 2 2 3 3 3 4 4 5 5 5 5 5 6 ... 
#$ SITE_ID              : int  157166 157166 1636 1636 1636 1635 1635 1635 134261 1631 65383 65383 65383 111828 ... 
#$ Year                  : int  2011 2014 2013 2006 2003 2002 2013 2005 2013 2006 2011 2005 2004 ... 
#$ ResidualQ95          : num  100 100 80 80 80 98 98 98 105 105 101 101 130 120 120 ... 
#$ LIFE.OE_spring        : num  1.02 1.03 1.02 1.06 1.06 1.07 1.12 1.05 1.14 1.05 1.09 1.14 1.04 0.97 0.98 ... 
#$ super.end.group      : Factor w/ 6 levels "B","C","D","E",..: 1 1 3 3 3 2 2 2 4 4 ... 
#$ X.urban.suburban      : num  0 0 0.07 0.07 0.07 0.53 0.53 0.53 8.07 8.07 0.27 0.27 0.27 0.27 0.27 0.72 ... 
#$ X.broadleaved_woodland: num  2.83 2.83 10.39 10.39 10.39 7.72 7.72 21.15 21.15 14.44 14.44 ... 
#$ X.CapWks              : num  0 0 0 0 0 0 0 0 0 0 8.11 8.11 8.11 0 0 0 42.06 42.06 7.08 0.2 ... 
#$ Hms_Poaching          : num  0 0 10 10 10 0 0 0 0 10 10 20 40 5 30 15 15 0 0 0 50 50 ... 
#$ Hms_Rsctned          : num  0 0 0 0 0 0 0 0 0 0 2480 800 1960 1160 740 0 0 960 ... 

library(gamm4) 

model<-gamm4(LIFE.OE_spring~s(ResidualQ95, by=super.end.group)+t2(ResidualQ95, Hms_Rsctned, by=super.end.group)+Year +Hms_Poaching +X.broadleaved_woodland +X.urban.suburban +X.CapWks, data=dat, random=~(1|WATERBODY_ID/SITE_ID)) 
#Warning messages: 
#1: In optwrap(optimizer, devfun, getStart(start, rho$lower, rho$pp),  : 
#  convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded 
#2: In optwrap(optimizer, devfun, opt$par, lower = rho$lower, control = control,  : 
#  convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded 

I also tried the following but I got the same message as before. 

model<-gamm4(LIFE.OE_spring~s(ResidualQ95)+t2(ResidualQ95, Hms_Rsctned, by=super.end.group)+Year+ Hms_Poaching +X.broadleaved_woodland +X.urban.suburban +X.CapWks, data=dat, random=~(1|WATERBODY_ID/SITE_ID)) 
#fixed-effect model matrix is rank deficient so dropping 1 column / coefficient 

#Warning messages: 
#1: In optwrap(optimizer, devfun, getStart(start, rho$lower, rho$pp),  : 
#  convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded 
#2: In optwrap(optimizer, devfun, opt$par, lower = rho$lower, control = control,  : 
#  convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded 

When I tried to plot, I got the following error: 
plot(model$gam, page=1) 
#Error in plot.window(...) : need finite 'ylim' values 
#In addition: Warning messages: 
#  1: In min(ll, na.rm = TRUE) : 
#  no non-missing arguments to min; returning Inf 
#  2: In max(ul, na.rm = TRUE) : 
#  no non-missing arguments to max; returning -Inf 

I would really appreciate your help. My dataset is quite large that is why I have used the str() for you to get an idea; I have attached a txt file as well as a sample of my dataset but I have trimmed it a lot so it is even smaller to fit the email size. 

Thank you very much. 

Best, 
Maria
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: dat.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180123/cae70e5b/attachment.txt>

From iliofornasero at hotmail.com  Tue Jan 23 18:31:01 2018
From: iliofornasero at hotmail.com (Ilio Fornasero)
Date: Tue, 23 Jan 2018 17:31:01 +0000
Subject: [R] Scraping from different level URLs website
Message-ID: <AM4PR0802MB2275619902FED58C4984BFCFB3E30@AM4PR0802MB2275.eurprd08.prod.outlook.com>

I am doing a research on World Bank (WB) projects on developing countries. To do so, I am scraping their website in order to collect the data I am interested in.

The structure of the webpage I want to scrape is the following:

  1.  List of countries the list of all countries in which WB has developed projects<http://projects.worldbank.org/country?lang=en&page=>

1.1. By clicking on a single country on 1. , one gets the single countries project list (that includes many webpages) it includes all the projects in a single countries <http://projects.worldbank.org/search?lang=en&searchTerm=&countrycode_exact=3A> . Of course, here I have included just one page of a single countries, but every country has a number of pages dedicated to this subject

1.1.1. By clicking on a a single project on 1.1. , one gets - among the others - the project's overview option<http://projects.worldbank.org/P155642/?lang=en&tab=overview> I am interested in.

In other words, my problem is to find out a way to create a dataframe including all the countries, a complete list of all projects for each country and an overview of any single project.


Yet, this is the code that I have (unsuccessfully) written:

WB_links <- "http://projects.worldbank.org/country?lang=en&page=projects"

 WB_proj <- function(x) {

  Sys.sleep(5)
 url <- sprintf("http://projects.worldbank.org/search?lang=en&searchTerm=&countrycode_exact=%s", x)

 html <- read_html(url)

 tibble(title = html_nodes(html, ".grid_20") %>% html_text(trim = TRUE),
     project_url = html_nodes(html, ".grid_20") %>% html_attr("href"))
    }

 WB_scrape <- map_df(1:5, WB_proj) %>%
 mutate(study_description =
       map(project_url,
           ~read_html(sprintf
     ("http://projects.worldbank.org/search?lang=en&searchTerm=&countrycode_exact=%s", .x)) %>%
            html_node() %>%
            html_text()))


Any suggestion?

Note: I am sorry if this question seems trivial, but I am quite a newbie in R and I haven't found a help on this by looking around (though I could have missed something, of course).


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Jan 23 20:38:32 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 23 Jan 2018 11:38:32 -0800
Subject: [R] Scraping from different level URLs website
In-Reply-To: <AM4PR0802MB2275619902FED58C4984BFCFB3E30@AM4PR0802MB2275.eurprd08.prod.outlook.com>
References: <AM4PR0802MB2275619902FED58C4984BFCFB3E30@AM4PR0802MB2275.eurprd08.prod.outlook.com>
Message-ID: <49B3FE82-67B9-4C91-8D76-7A83901FE847@dcn.davis.ca.us>

They seem to release their data in xml and csv formats also... why are you scraping? 
-- 
Sent from my phone. Please excuse my brevity.

On January 23, 2018 9:31:01 AM PST, Ilio Fornasero <iliofornasero at hotmail.com> wrote:
>I am doing a research on World Bank (WB) projects on developing
>countries. To do so, I am scraping their website in order to collect
>the data I am interested in.
>
>The structure of the webpage I want to scrape is the following:
>
>1.  List of countries the list of all countries in which WB has
>developed projects<http://projects.worldbank.org/country?lang=en&page=>
>
>1.1. By clicking on a single country on 1. , one gets the single
>countries project list (that includes many webpages) it includes all
>the projects in a single countries
><http://projects.worldbank.org/search?lang=en&searchTerm=&countrycode_exact=3A>
>. Of course, here I have included just one page of a single countries,
>but every country has a number of pages dedicated to this subject
>
>1.1.1. By clicking on a a single project on 1.1. , one gets - among the
>others - the project's overview
>option<http://projects.worldbank.org/P155642/?lang=en&tab=overview> I
>am interested in.
>
>In other words, my problem is to find out a way to create a dataframe
>including all the countries, a complete list of all projects for each
>country and an overview of any single project.
>
>
>Yet, this is the code that I have (unsuccessfully) written:
>
>WB_links <-
>"http://projects.worldbank.org/country?lang=en&page=projects"
>
> WB_proj <- function(x) {
>
>  Sys.sleep(5)
>url <-
>sprintf("http://projects.worldbank.org/search?lang=en&searchTerm=&countrycode_exact=%s",
>x)
>
> html <- read_html(url)
>
>tibble(title = html_nodes(html, ".grid_20") %>% html_text(trim = TRUE),
>     project_url = html_nodes(html, ".grid_20") %>% html_attr("href"))
>    }
>
> WB_scrape <- map_df(1:5, WB_proj) %>%
> mutate(study_description =
>       map(project_url,
>           ~read_html(sprintf
>("http://projects.worldbank.org/search?lang=en&searchTerm=&countrycode_exact=%s",
>.x)) %>%
>            html_node() %>%
>            html_text()))
>
>
>Any suggestion?
>
>Note: I am sorry if this question seems trivial, but I am quite a
>newbie in R and I haven't found a help on this by looking around
>(though I could have missed something, of course).
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From scottclausen at mac.com  Wed Jan 24 02:58:31 2018
From: scottclausen at mac.com (Scott Clausen)
Date: Tue, 23 Jan 2018 17:58:31 -0800
Subject: [R] Newbie - Scrape Data From PDFs?
Message-ID: <9DCA72B4-2641-4454-9A3C-9785BB26DE84@mac.com>

Hello,

I?m new to R and am using it with RStudio to learn the language. I?m doing so as I have quite a lot of traffic data I would like to explore. My problem is that all the data is located on a number of PDFs. Can someone point me to info on gathering data from other sources? I?ve been to the R FAQ and didn?t see anything and would appreciate your thoughts.

 I am quite sure now that often, very often, in matters concerning religion and politics a man's reasoning powers are not above the monkey's.

-- Mark Twain


From ericjberger at gmail.com  Wed Jan 24 08:11:23 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 24 Jan 2018 09:11:23 +0200
Subject: [R] Newbie - Scrape Data From PDFs?
In-Reply-To: <9DCA72B4-2641-4454-9A3C-9785BB26DE84@mac.com>
References: <9DCA72B4-2641-4454-9A3C-9785BB26DE84@mac.com>
Message-ID: <CAGgJW74t+DpV=wAdZ4h6oDAAKgfRCPZOSezbaM01ZzwVahmgbQ@mail.gmail.com>

Hi Scott,
I have never done this myself but I read something recently on the
r-help distribution that was related.
I just did a quick search and found a few hits that might work for you.

1. https://medium.com/@CharlesBordet/how-to-extract-and-clean-data-from-pdf-files-in-r-da11964e252e
2. http://bxhorn.com/2016/extract-data-tables-from-pdf-files-in-r/
3. https://www.rdocumentation.org/packages/textreadr/versions/0.7.0/topics/read_pdf

HTH,
Eric

On Wed, Jan 24, 2018 at 3:58 AM, Scott Clausen <scottclausen at mac.com> wrote:
> Hello,
>
> I?m new to R and am using it with RStudio to learn the language. I?m doing so as I have quite a lot of traffic data I would like to explore. My problem is that all the data is located on a number of PDFs. Can someone point me to info on gathering data from other sources? I?ve been to the R FAQ and didn?t see anything and would appreciate your thoughts.
>
>  I am quite sure now that often, very often, in matters concerning religion and politics a man's reasoning powers are not above the monkey's.
>
> -- Mark Twain
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p_connolly at slingshot.co.nz  Wed Jan 24 08:23:06 2018
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Wed, 24 Jan 2018 20:23:06 +1300
Subject: [R] Function gutenberg_download in the gutenbergr package
Message-ID: <20180124072306.GB5360@slingshot.co.nz>


I've been working through https://www.tidytextmining.com/tidytext.html
wherein everything worked until I got to this part in section 1.5

> hgwells <- gutenberg_download(c(35, 36, 5230, 159))
Determining mirror for Project Gutenberg from http://www.gutenberg.org/robot/harvest
Error in open.connection(con, "rb") : 
  Failed to connect to www.gutenberg.org port 80: Connection timed out

Which indicates the problem is at the very start:

  if (is.null(mirror)) {
    mirror <- gutenberg_get_mirror(verbose = verbose)
  }

The documentation for gutenberg_get_mirror indicates there's nothing
different I could set.

So I tried specifying my usual mirror:

> hgwells <- gutenberg_download(c(1260, 768, 969, 9182, 767), mirror = "http://cran.stat.auckland.ac.nz")
Error in read_zip_url(full_url) : could not find function "read_zip_url"
> 

Which is, indeed, strange since according to 

> help.search("read_zip_url")
Help files with alias or concept or title matching ?read_zip_url? using
regular expression matching:


gutenbergr::read_zip_url
                        Read a file from a .zip URL
  Aliases: read_zip_url

[...]

And according to 
library(help = "gutenbergr")

[...]
Index:

gutenberg_authors       Metadata about Project Gutenberg authors
gutenberg_download      Download one or more works using a Project
                        Gutenberg ID
gutenberg_get_mirror    Get the recommended mirror for Gutenberg files
gutenberg_metadata      Gutenberg metadata about each work
gutenberg_strip         Strip header and footer content from a Project
                        Gutenberg book
gutenberg_subjects      Gutenberg metadata about the subject of each
                        work
gutenberg_works         Get a filtered table of Gutenberg work metadata
read_zip_url            Read a file from a .zip URL

[...]

However, when I look at the list for that part of the search(), there
is no read_zip_url but all the rest of that list are present.  So it's
not surprising that it isn't found.  But it puzzles me that it is not
there.

Ideas as to where I should proceed gratefully appreciated.


> sessionInfo()
R version 3.4.2 (2017-09-28)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

Matrix products: default
BLAS: /home/hrapgc/local/R-3.4.2/lib/libRblas.so
LAPACK: /home/hrapgc/local/R-3.4.2/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
 [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
 [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] grDevices utils     stats     graphics  methods   base     

other attached packages:
 [1] sos_2.0-0          brew_1.0-6         gutenbergr_0.1.3   ggplot2_2.2.1     
 [5] stringr_1.2.0      bindrcpp_0.2       dplyr_0.7.4        janeaustenr_0.1.5 
 [9] tidytext_0.1.6     FactoMineR_1.38    readxl_1.0.0       tm_0.7-3          
[13] NLP_0.1-11         wordcloud_2.5      RColorBrewer_1.1-2 lattice_0.20-35   

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.13         cellranger_1.1.0     compiler_3.4.2      
 [4] plyr_1.8.4           bindr_0.1            tokenizers_0.1.4    
 [7] tools_3.4.2          gtable_0.2.0         tibble_1.3.4        
[10] nlme_3.1-131         pkgconfig_2.0.1      rlang_0.1.2         
[13] Matrix_1.2-11        psych_1.7.8          curl_3.0            
[16] parallel_3.4.2       xml2_1.1.1           cluster_2.0.6       
[19] hms_0.3              flashClust_1.01-2    grid_3.4.2          
[22] scatterplot3d_0.3-40 glue_1.1.1           ellipse_0.3-8       
[25] R6_2.2.2             foreign_0.8-69       readr_1.1.1         
[28] purrr_0.2.4          tidyr_0.7.2          reshape2_1.4.2      
[31] magrittr_1.5         scales_0.5.0         SnowballC_0.5.1     
[34] MASS_7.3-47          leaps_3.0            assertthat_0.2.0    
[37] mnormt_1.5-5         colorspace_1.3-2     labeling_0.3        
[40] stringi_1.1.5        lazyeval_0.2.1       munsell_0.4.3       
[43] slam_0.1-42          broom_0.4.2         
> 

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From ulrik.stervbo at gmail.com  Wed Jan 24 08:35:38 2018
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 24 Jan 2018 07:35:38 +0000
Subject: [R] Newbie - Scrape Data From PDFs?
In-Reply-To: <CAGgJW74t+DpV=wAdZ4h6oDAAKgfRCPZOSezbaM01ZzwVahmgbQ@mail.gmail.com>
References: <9DCA72B4-2641-4454-9A3C-9785BB26DE84@mac.com>
 <CAGgJW74t+DpV=wAdZ4h6oDAAKgfRCPZOSezbaM01ZzwVahmgbQ@mail.gmail.com>
Message-ID: <CAKVAULOWdmBkjm0fhjWF_HLAAe3ENQ1SvP=R49QBekmxbUr44g@mail.gmail.com>

I think I would use pdftk to extract the form data. All subsequent
manipulation in R.

HTH
Ulrik

Eric Berger <ericjberger at gmail.com> schrieb am Mi., 24. Jan. 2018, 08:11:

> Hi Scott,
> I have never done this myself but I read something recently on the
> r-help distribution that was related.
> I just did a quick search and found a few hits that might work for you.
>
> 1.
> https://medium.com/@CharlesBordet/how-to-extract-and-clean-data-from-pdf-files-in-r-da11964e252e
> 2. http://bxhorn.com/2016/extract-data-tables-from-pdf-files-in-r/
> 3.
> https://www.rdocumentation.org/packages/textreadr/versions/0.7.0/topics/read_pdf
>
> HTH,
> Eric
>
> On Wed, Jan 24, 2018 at 3:58 AM, Scott Clausen <scottclausen at mac.com>
> wrote:
> > Hello,
> >
> > I?m new to R and am using it with RStudio to learn the language. I?m
> doing so as I have quite a lot of traffic data I would like to explore. My
> problem is that all the data is located on a number of PDFs. Can someone
> point me to info on gathering data from other sources? I?ve been to the R
> FAQ and didn?t see anything and would appreciate your thoughts.
> >
> >  I am quite sure now that often, very often, in matters concerning
> religion and politics a man's reasoning powers are not above the monkey's.
> >
> > -- Mark Twain
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Jan 24 09:39:23 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 24 Jan 2018 00:39:23 -0800
Subject: [R] Newbie - Scrape Data From PDFs?
In-Reply-To: <CAKVAULOWdmBkjm0fhjWF_HLAAe3ENQ1SvP=R49QBekmxbUr44g@mail.gmail.com>
References: <9DCA72B4-2641-4454-9A3C-9785BB26DE84@mac.com>
 <CAGgJW74t+DpV=wAdZ4h6oDAAKgfRCPZOSezbaM01ZzwVahmgbQ@mail.gmail.com>
 <CAKVAULOWdmBkjm0fhjWF_HLAAe3ENQ1SvP=R49QBekmxbUr44g@mail.gmail.com>
Message-ID: <4A3C0978-3913-41DB-86B1-B0922CB02CB5@dcn.davis.ca.us>

And a warning to the OP... PDF files are like packages.... a wide variety of things can be inside, including text in semi-random order, or bitmap images of text... so having a tool that extracts text from the file will only be of use if your PDF files happen to be of the type that contain reasonably unscrambled  text.
-- 
Sent from my phone. Please excuse my brevity.

On January 23, 2018 11:35:38 PM PST, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
>I think I would use pdftk to extract the form data. All subsequent
>manipulation in R.
>
>HTH
>Ulrik
>
>Eric Berger <ericjberger at gmail.com> schrieb am Mi., 24. Jan. 2018,
>08:11:
>
>> Hi Scott,
>> I have never done this myself but I read something recently on the
>> r-help distribution that was related.
>> I just did a quick search and found a few hits that might work for
>you.
>>
>> 1.
>>
>https://medium.com/@CharlesBordet/how-to-extract-and-clean-data-from-pdf-files-in-r-da11964e252e
>> 2. http://bxhorn.com/2016/extract-data-tables-from-pdf-files-in-r/
>> 3.
>>
>https://www.rdocumentation.org/packages/textreadr/versions/0.7.0/topics/read_pdf
>>
>> HTH,
>> Eric
>>
>> On Wed, Jan 24, 2018 at 3:58 AM, Scott Clausen <scottclausen at mac.com>
>> wrote:
>> > Hello,
>> >
>> > I?m new to R and am using it with RStudio to learn the language.
>I?m
>> doing so as I have quite a lot of traffic data I would like to
>explore. My
>> problem is that all the data is located on a number of PDFs. Can
>someone
>> point me to info on gathering data from other sources? I?ve been to
>the R
>> FAQ and didn?t see anything and would appreciate your thoughts.
>> >
>> >  I am quite sure now that often, very often, in matters concerning
>> religion and politics a man's reasoning powers are not above the
>monkey's.
>> >
>> > -- Mark Twain
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Jan 24 16:59:04 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 24 Jan 2018 07:59:04 -0800
Subject: [R] Function gutenberg_download in the gutenbergr package
In-Reply-To: <20180124072306.GB5360@slingshot.co.nz>
References: <20180124072306.GB5360@slingshot.co.nz>
Message-ID: <1105F106-720F-40AC-AE79-7D9FAA698D98@dcn.davis.ca.us>

I have never used that package, but it seems obvious to me that you need to "reflect" on the meaning of the word "mirror". There is no reason to assume that a site hosting a mirror of the CRAN archive is also going to host a mirror of Project Gutenberg [1].

If, after you know you are giving reasonable inputs the package does not seem to work as designed, please remember that contributed packages have maintainers [2] and not all of them subscribe to r-help.

[1] https://www.gutenberg.org/MIRRORS.ALL
[2] ?maintainer
-- 
Sent from my phone. Please excuse my brevity.

On January 23, 2018 11:23:06 PM PST, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
>
>I've been working through https://www.tidytextmining.com/tidytext.html
>wherein everything worked until I got to this part in section 1.5
>
>> hgwells <- gutenberg_download(c(35, 36, 5230, 159))
>Determining mirror for Project Gutenberg from
>http://www.gutenberg.org/robot/harvest
>Error in open.connection(con, "rb") : 
>  Failed to connect to www.gutenberg.org port 80: Connection timed out
>
>Which indicates the problem is at the very start:
>
>  if (is.null(mirror)) {
>    mirror <- gutenberg_get_mirror(verbose = verbose)
>  }
>
>The documentation for gutenberg_get_mirror indicates there's nothing
>different I could set.
>
>So I tried specifying my usual mirror:
>
>> hgwells <- gutenberg_download(c(1260, 768, 969, 9182, 767), mirror =
>"http://cran.stat.auckland.ac.nz")
>Error in read_zip_url(full_url) : could not find function
>"read_zip_url"
>> 
>
>Which is, indeed, strange since according to 
>
>> help.search("read_zip_url")
>Help files with alias or concept or title matching ?read_zip_url? using
>regular expression matching:
>
>
>gutenbergr::read_zip_url
>                        Read a file from a .zip URL
>  Aliases: read_zip_url
>
>[...]
>
>And according to 
>library(help = "gutenbergr")
>
>[...]
>Index:
>
>gutenberg_authors       Metadata about Project Gutenberg authors
>gutenberg_download      Download one or more works using a Project
>                        Gutenberg ID
>gutenberg_get_mirror    Get the recommended mirror for Gutenberg files
>gutenberg_metadata      Gutenberg metadata about each work
>gutenberg_strip         Strip header and footer content from a Project
>                        Gutenberg book
>gutenberg_subjects      Gutenberg metadata about the subject of each
>                        work
>gutenberg_works         Get a filtered table of Gutenberg work metadata
>read_zip_url            Read a file from a .zip URL
>
>[...]
>
>However, when I look at the list for that part of the search(), there
>is no read_zip_url but all the rest of that list are present.  So it's
>not surprising that it isn't found.  But it puzzles me that it is not
>there.
>
>Ideas as to where I should proceed gratefully appreciated.
>
>
>> sessionInfo()
>R version 3.4.2 (2017-09-28)
>Platform: x86_64-pc-linux-gnu (64-bit)
>Running under: Ubuntu 14.04.5 LTS
>
>Matrix products: default
>BLAS: /home/hrapgc/local/R-3.4.2/lib/libRblas.so
>LAPACK: /home/hrapgc/local/R-3.4.2/lib/libRlapack.so
>
>locale:
> [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
> [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
> [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
> [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
> [9] LC_ADDRESS=C               LC_TELEPHONE=C            
>[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       
>
>attached base packages:
>[1] grDevices utils     stats     graphics  methods   base     
>
>other attached packages:
>[1] sos_2.0-0          brew_1.0-6         gutenbergr_0.1.3  
>ggplot2_2.2.1     
>[5] stringr_1.2.0      bindrcpp_0.2       dplyr_0.7.4       
>janeaustenr_0.1.5 
>[9] tidytext_0.1.6     FactoMineR_1.38    readxl_1.0.0       tm_0.7-3  
>       
>[13] NLP_0.1-11         wordcloud_2.5      RColorBrewer_1.1-2
>lattice_0.20-35   
>
>loaded via a namespace (and not attached):
> [1] Rcpp_0.12.13         cellranger_1.1.0     compiler_3.4.2      
> [4] plyr_1.8.4           bindr_0.1            tokenizers_0.1.4    
> [7] tools_3.4.2          gtable_0.2.0         tibble_1.3.4        
>[10] nlme_3.1-131         pkgconfig_2.0.1      rlang_0.1.2         
>[13] Matrix_1.2-11        psych_1.7.8          curl_3.0            
>[16] parallel_3.4.2       xml2_1.1.1           cluster_2.0.6       
>[19] hms_0.3              flashClust_1.01-2    grid_3.4.2          
>[22] scatterplot3d_0.3-40 glue_1.1.1           ellipse_0.3-8       
>[25] R6_2.2.2             foreign_0.8-69       readr_1.1.1         
>[28] purrr_0.2.4          tidyr_0.7.2          reshape2_1.4.2      
>[31] magrittr_1.5         scales_0.5.0         SnowballC_0.5.1     
>[34] MASS_7.3-47          leaps_3.0            assertthat_0.2.0    
>[37] mnormt_1.5-5         colorspace_1.3-2     labeling_0.3        
>[40] stringi_1.1.5        lazyeval_0.2.1       munsell_0.4.3       
>[43] slam_0.1-42          broom_0.4.2         
>> 
>
>-- 
>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>  
>   ___    Patrick Connolly   
> {~._.~}                   Great minds discuss ideas    
> _( Y )_  	         Average minds discuss events 
>(:_~*~_:)                  Small minds discuss people  
> (_)-(_)  	                      ..... Eleanor Roosevelt
>	  
>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From k.yuen at fugro.com  Wed Jan 24 14:59:48 2018
From: k.yuen at fugro.com (Yuen, Kam)
Date: Wed, 24 Jan 2018 13:59:48 +0000
Subject: [R] Geometry delaunayn and deldir results,
 differing results from Octave due to decimal precision?
Message-ID: <dfe9eaaf357640479d3370964a8bca37@NLLDAMEX02.ad.fugro.com>

The problem:
I would like to translate the Octave algorithm in griddata.m to R.
Within the griddata algorithm calls are made to the Delaunay function. For the R translation I have found delaunayn within the "geometry" package and also the deldir package.
Both do similar things but give slightly different results depending on the input.
The question is, what is making the results for the R packages different from each other?
And are those differences down to the decimal precision in the latter case of using 9 d.p.?
In the following example I have defined x and y to be small vectors and all three sets of results agree (but are in a different order), i.e. Octave's delaunay, geometry.delaunayn, and deldir.deldir

Octave

x = [0.9554283   0.4695926   0.0769020   0.3033320   0.3553984   0.6051734   0.8661461   0.5511353   0.5214984   0.0061548]

y = [0.851911   0.402087   0.704462   0.687721   0.939775   0.499157   0.077145   0.588351   0.454380   0.193425]

tri = delaunay(x,y)

tri =

    2    7   10

    2    9    7

    6    7    1

    6    9    7

    4    2    9

    4    2   10

    8    5    1

    8    6    1

    8    4    5

    8    6    9

    8    4    9

    3    4   10

    3    4    5


R With deldir package
x <- c(0.9554283,0.4695926,0.0769020,0.3033320,0.3553984,0.6051734,0.8661461,0.5511353,0.5214984,0.0061548)
y <- c(0.851911,0.402087,0.704462,0.687721,0.939775,0.499157,0.077145,0.588351,0.454380,0.193425)
tri <- deldir(x,y)
triMat(tri) =
      [,1] [,2] [,3]
[1,]    1    5    8
[2,]    1    6    7
[3,]    1    6    8
[4,]    2    4   10
[5,]    2    4    9
[6,]    2    7   10
[7,]    2    7    9
[8,]    3    4   10
[9,]    3    4    5
[10,]    4    5    8
[11,]    4    8    9
[12,]    6    7    9
[13,]    6    8    9

R with geometry package

x <- c(0.9554283,0.4695926,0.0769020,0.3033320,0.3553984,0.6051734,0.8661461,0.5511353,0.5214984,0.0061548)

y <- c(0.851911,0.402087,0.704462,0.687721,0.939775,0.499157,0.077145,0.588351,0.454380,0.193425)

library(geometry)

tri <- delaunayn(cbind(x,y))



tri

      [,1] [,2] [,3]

[1,]    2    7   10

[2,]    8    5    1

[3,]    6    7    1

[4,]    6    8    1

[5,]    4    2   10

[6,]    4    3   10

[7,]    4    3    5

[8,]    4    8    5

[9,]    9    6    8

[10,]    9    4    2

[11,]    9    4    8

[12,]    9    2    7

[13,]    9    6    7

As you can see, the results are identical with the exception of ordering.

*However* when I use a slightly larger set of data for input, "geometry.delaunayn" and "deldir.deldir" seems to give results that are off by one in a lot of instances.
The input for the Delaunay function has been exported from Octave to 9 d.p. and then imported into R by using the "foreign" package.

Example data is on the following link. It is a set of variables exported from Octave 'x y tri xiflat yiflat tri_list.mat'
https://pastebin.com/xELkj6r6

the variable tri_list is just the tri_list = search(x,y,tri_deldir,xiflat,yiflat) in Octave


The command history is a as follows:
library(deldir)
library(geometry)
library(foreign)
theData <- read.octave('x y tri xiflat yiflat tri_list.mat')
options(digits = 10)
x <- unlist(theData[1])
y <- unlist(theData[3])
tri_deldir <- triMat(deldir(x,y))
tri_delaunayn <- delaunayn(x,y)
tri_delaunayn <- delaunayn(cbind(x,y))
tri_list_from_deldir <- tsearch(x,y,tri_deldir,xiflat,yiflat)
xiflat <- unlist(theData[7])
yiflat <- unlist(theData[9])
tri_list_from_deldir <- tsearch(x,y,tri_deldir,xiflat,yiflat)
tri_list_from_delaunayn <- tsearch(x,y,tri_delaunayn,xiflat,yiflat)


Kam Yuen
Software Developer
T +44 (0)1491 820634| F +44 (0)1491 820599
k.yuen at fugro.com<mailto:k.yuen at fugro.com> | www.fugro.com<http://www.fugro.com/>
Fugro GB Marine Limited
Fugro House, Hithercroft Road, Wallingford, Oxfordshire OX10 9RB, UK
Registration No: 1135456 | VAT No: GB 579 3459 84


	[[alternative HTML version deleted]]


From franrspereira at gmail.com  Wed Jan 24 17:28:07 2018
From: franrspereira at gmail.com (Francisca R. Souza Pereira)
Date: Wed, 24 Jan 2018 14:28:07 -0200
Subject: [R] random sample set for regression
Message-ID: <CAB0xfdx8HpO9ELSdZ28U4nh5-EtFLJ5pUmPpkcs3YE-x67eQ4w@mail.gmail.com>

Hi,
I'm not a programmer, so I have a question about R functions,

I run the Random Forest regression models, but
I would like to run the random forest model 1000 times with different
random sample set. to check the uncertainty of the regression model
estimates.

exemple of data:
#################################
table= all
Y: all$AGB
X variables:
Variables=as.matrix(all[, c( "min", "max", "avg", "qav", "std",
                                  "ske", "kur",  "p50",  "d50",  "d06",
"d07", "d08", "dns_gap")])

rf.Model=randomForest(Variables, all$AGB, importance=T)
#################################

Can I use Monte Carlo method or Bootstrap to simulate 1000 different sample
set and Run 1000 x times the Random Forest regression?  But How can I do
that? Could somebody have an idea with the script?
Thanks!
Fran

	[[alternative HTML version deleted]]


From om2468 at hotmail.com  Wed Jan 24 18:03:51 2018
From: om2468 at hotmail.com (Oliver Morris)
Date: Wed, 24 Jan 2018 17:03:51 +0000
Subject: [R] Issue with concatenation of URL losing
Message-ID: <YTOPR01MB0219C15CAA88F13B23DAF83FC5E20@YTOPR01MB0219.CANPRD01.PROD.OUTLOOK.COM>

Thank you for your help in advance.


I am trying to pull some data back from a web service


library(httr)
sample2 <- GET("https://elevation.mapzen.com/height?json={\"range\":false,\"shape\":[{\"lat\":40.7,\"lon\":-76.5}]}&api_key=mycode")
result2 <- content(sample2)
height <- result2$height[[1]]


I would like to put by own latitude and longitude in but alas when I use paste() to combine the double quotes become stuck as literally \"


lat <-10

long <20

library(httr)
sample2 <- GET(paste("https://elevation.mapzen.com/height?json={\"range\":false,\"shape\":[{\", lat , \":40.7,\", long,\":-76.5}]}&api_key=mycode"))
result2 <- content(sample2)
height <- result2$height[[1]]


Can you please suggest a way around this, it has been driving me mad!


Thank you so much.


Oliver

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Jan 24 19:19:22 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 24 Jan 2018 10:19:22 -0800
Subject: [R] Geometry delaunayn and deldir results,
 differing results from Octave due to decimal precision?
In-Reply-To: <dfe9eaaf357640479d3370964a8bca37@NLLDAMEX02.ad.fugro.com>
References: <dfe9eaaf357640479d3370964a8bca37@NLLDAMEX02.ad.fugro.com>
Message-ID: <CAGxFJbRuwz0QQhVAaFPzuEzq-dLBLhCH1qnTQe-7JYZw-Af26Q@mail.gmail.com>

"The question is, what is making the results for the R packages different
from each other?"

There are literally thousands of R packages, contributed independently by
thousands of people. There should be no expectation of consistency or for
that matter, "correctness",  among them. Caveat emptor.

Only within the base R distribution, maintained and mostly written by the R
Core team,  might such consistency be reasonably expected.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jan 24, 2018 at 5:59 AM, Yuen, Kam <k.yuen at fugro.com> wrote:

> The problem:
> I would like to translate the Octave algorithm in griddata.m to R.
> Within the griddata algorithm calls are made to the Delaunay function. For
> the R translation I have found delaunayn within the "geometry" package and
> also the deldir package.
> Both do similar things but give slightly different results depending on
> the input.
> The question is, what is making the results for the R packages different
> from each other?
> And are those differences down to the decimal precision in the latter case
> of using 9 d.p.?
> In the following example I have defined x and y to be small vectors and
> all three sets of results agree (but are in a different order), i.e.
> Octave's delaunay, geometry.delaunayn, and deldir.deldir
>
> Octave
>
> x = [0.9554283   0.4695926   0.0769020   0.3033320   0.3553984
>  0.6051734   0.8661461   0.5511353   0.5214984   0.0061548]
>
> y = [0.851911   0.402087   0.704462   0.687721   0.939775   0.499157
>  0.077145   0.588351   0.454380   0.193425]
>
> tri = delaunay(x,y)
>
> tri =
>
>     2    7   10
>
>     2    9    7
>
>     6    7    1
>
>     6    9    7
>
>     4    2    9
>
>     4    2   10
>
>     8    5    1
>
>     8    6    1
>
>     8    4    5
>
>     8    6    9
>
>     8    4    9
>
>     3    4   10
>
>     3    4    5
>
>
> R With deldir package
> x <- c(0.9554283,0.4695926,0.0769020,0.3033320,0.3553984,0.
> 6051734,0.8661461,0.5511353,0.5214984,0.0061548)
> y <- c(0.851911,0.402087,0.704462,0.687721,0.939775,0.499157,0.
> 077145,0.588351,0.454380,0.193425)
> tri <- deldir(x,y)
> triMat(tri) =
>       [,1] [,2] [,3]
> [1,]    1    5    8
> [2,]    1    6    7
> [3,]    1    6    8
> [4,]    2    4   10
> [5,]    2    4    9
> [6,]    2    7   10
> [7,]    2    7    9
> [8,]    3    4   10
> [9,]    3    4    5
> [10,]    4    5    8
> [11,]    4    8    9
> [12,]    6    7    9
> [13,]    6    8    9
>
> R with geometry package
>
> x <- c(0.9554283,0.4695926,0.0769020,0.3033320,0.3553984,0.
> 6051734,0.8661461,0.5511353,0.5214984,0.0061548)
>
> y <- c(0.851911,0.402087,0.704462,0.687721,0.939775,0.499157,0.
> 077145,0.588351,0.454380,0.193425)
>
> library(geometry)
>
> tri <- delaunayn(cbind(x,y))
>
>
>
> tri
>
>       [,1] [,2] [,3]
>
> [1,]    2    7   10
>
> [2,]    8    5    1
>
> [3,]    6    7    1
>
> [4,]    6    8    1
>
> [5,]    4    2   10
>
> [6,]    4    3   10
>
> [7,]    4    3    5
>
> [8,]    4    8    5
>
> [9,]    9    6    8
>
> [10,]    9    4    2
>
> [11,]    9    4    8
>
> [12,]    9    2    7
>
> [13,]    9    6    7
>
> As you can see, the results are identical with the exception of ordering.
>
> *However* when I use a slightly larger set of data for input,
> "geometry.delaunayn" and "deldir.deldir" seems to give results that are off
> by one in a lot of instances.
> The input for the Delaunay function has been exported from Octave to 9
> d.p. and then imported into R by using the "foreign" package.
>
> Example data is on the following link. It is a set of variables exported
> from Octave 'x y tri xiflat yiflat tri_list.mat'
> https://pastebin.com/xELkj6r6
>
> the variable tri_list is just the tri_list = search(x,y,tri_deldir,xiflat,yiflat)
> in Octave
>
>
> The command history is a as follows:
> library(deldir)
> library(geometry)
> library(foreign)
> theData <- read.octave('x y tri xiflat yiflat tri_list.mat')
> options(digits = 10)
> x <- unlist(theData[1])
> y <- unlist(theData[3])
> tri_deldir <- triMat(deldir(x,y))
> tri_delaunayn <- delaunayn(x,y)
> tri_delaunayn <- delaunayn(cbind(x,y))
> tri_list_from_deldir <- tsearch(x,y,tri_deldir,xiflat,yiflat)
> xiflat <- unlist(theData[7])
> yiflat <- unlist(theData[9])
> tri_list_from_deldir <- tsearch(x,y,tri_deldir,xiflat,yiflat)
> tri_list_from_delaunayn <- tsearch(x,y,tri_delaunayn,xiflat,yiflat)
>
>
> Kam Yuen
> Software Developer
> T +44 (0)1491 820634| F +44 (0)1491 820599
> k.yuen at fugro.com<mailto:k.yuen at fugro.com> | www.fugro.com<http://www.
> fugro.com/>
> Fugro GB Marine Limited
> Fugro House, Hithercroft Road, Wallingford, Oxfordshire OX10 9RB, UK
> Registration No: 1135456 | VAT No: GB 579 3459 84
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Jan 24 20:29:05 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 24 Jan 2018 11:29:05 -0800
Subject: [R] Geometry delaunayn and deldir results,
 differing results from Octave due to decimal precision?
In-Reply-To: <dfe9eaaf357640479d3370964a8bca37@NLLDAMEX02.ad.fugro.com>
References: <dfe9eaaf357640479d3370964a8bca37@NLLDAMEX02.ad.fugro.com>
Message-ID: <CAF8bMcZi_s2UkA3=dG73RbzjSo4DxUNMv_WQ5KkimVi2geMYYg@mail.gmail.com>

All three results give the same collection of triangles.  They
don't all agree on whether the points in a triangle are in clockwise
or counterclockwise order.  If the orientation matters, it is a simple
matter to reverse the order of points in those that described in
the "wrong" orientation.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Jan 24, 2018 at 5:59 AM, Yuen, Kam <k.yuen at fugro.com> wrote:

> The problem:
> I would like to translate the Octave algorithm in griddata.m to R.
> Within the griddata algorithm calls are made to the Delaunay function. For
> the R translation I have found delaunayn within the "geometry" package and
> also the deldir package.
> Both do similar things but give slightly different results depending on
> the input.
> The question is, what is making the results for the R packages different
> from each other?
> And are those differences down to the decimal precision in the latter case
> of using 9 d.p.?
> In the following example I have defined x and y to be small vectors and
> all three sets of results agree (but are in a different order), i.e.
> Octave's delaunay, geometry.delaunayn, and deldir.deldir
>
> Octave
>
> x = [0.9554283   0.4695926   0.0769020   0.3033320   0.3553984
>  0.6051734   0.8661461   0.5511353   0.5214984   0.0061548]
>
> y = [0.851911   0.402087   0.704462   0.687721   0.939775   0.499157
>  0.077145   0.588351   0.454380   0.193425]
>
> tri = delaunay(x,y)
>
> tri =
>
>     2    7   10
>
>     2    9    7
>
>     6    7    1
>
>     6    9    7
>
>     4    2    9
>
>     4    2   10
>
>     8    5    1
>
>     8    6    1
>
>     8    4    5
>
>     8    6    9
>
>     8    4    9
>
>     3    4   10
>
>     3    4    5
>
>
> R With deldir package
> x <- c(0.9554283,0.4695926,0.0769020,0.3033320,0.3553984,0.
> 6051734,0.8661461,0.5511353,0.5214984,0.0061548)
> y <- c(0.851911,0.402087,0.704462,0.687721,0.939775,0.499157,0.
> 077145,0.588351,0.454380,0.193425)
> tri <- deldir(x,y)
> triMat(tri) =
>       [,1] [,2] [,3]
> [1,]    1    5    8
> [2,]    1    6    7
> [3,]    1    6    8
> [4,]    2    4   10
> [5,]    2    4    9
> [6,]    2    7   10
> [7,]    2    7    9
> [8,]    3    4   10
> [9,]    3    4    5
> [10,]    4    5    8
> [11,]    4    8    9
> [12,]    6    7    9
> [13,]    6    8    9
>
> R with geometry package
>
> x <- c(0.9554283,0.4695926,0.0769020,0.3033320,0.3553984,0.
> 6051734,0.8661461,0.5511353,0.5214984,0.0061548)
>
> y <- c(0.851911,0.402087,0.704462,0.687721,0.939775,0.499157,0.
> 077145,0.588351,0.454380,0.193425)
>
> library(geometry)
>
> tri <- delaunayn(cbind(x,y))
>
>
>
> tri
>
>       [,1] [,2] [,3]
>
> [1,]    2    7   10
>
> [2,]    8    5    1
>
> [3,]    6    7    1
>
> [4,]    6    8    1
>
> [5,]    4    2   10
>
> [6,]    4    3   10
>
> [7,]    4    3    5
>
> [8,]    4    8    5
>
> [9,]    9    6    8
>
> [10,]    9    4    2
>
> [11,]    9    4    8
>
> [12,]    9    2    7
>
> [13,]    9    6    7
>
> As you can see, the results are identical with the exception of ordering.
>
> *However* when I use a slightly larger set of data for input,
> "geometry.delaunayn" and "deldir.deldir" seems to give results that are off
> by one in a lot of instances.
> The input for the Delaunay function has been exported from Octave to 9
> d.p. and then imported into R by using the "foreign" package.
>
> Example data is on the following link. It is a set of variables exported
> from Octave 'x y tri xiflat yiflat tri_list.mat'
> https://pastebin.com/xELkj6r6
>
> the variable tri_list is just the tri_list = search(x,y,tri_deldir,xiflat,yiflat)
> in Octave
>
>
> The command history is a as follows:
> library(deldir)
> library(geometry)
> library(foreign)
> theData <- read.octave('x y tri xiflat yiflat tri_list.mat')
> options(digits = 10)
> x <- unlist(theData[1])
> y <- unlist(theData[3])
> tri_deldir <- triMat(deldir(x,y))
> tri_delaunayn <- delaunayn(x,y)
> tri_delaunayn <- delaunayn(cbind(x,y))
> tri_list_from_deldir <- tsearch(x,y,tri_deldir,xiflat,yiflat)
> xiflat <- unlist(theData[7])
> yiflat <- unlist(theData[9])
> tri_list_from_deldir <- tsearch(x,y,tri_deldir,xiflat,yiflat)
> tri_list_from_delaunayn <- tsearch(x,y,tri_delaunayn,xiflat,yiflat)
>
>
> Kam Yuen
> Software Developer
> T +44 (0)1491 820634| F +44 (0)1491 820599
> k.yuen at fugro.com<mailto:k.yuen at fugro.com> | www.fugro.com<http://www.
> fugro.com/>
> Fugro GB Marine Limited
> Fugro House, Hithercroft Road, Wallingford, Oxfordshire OX10 9RB, UK
> Registration No: 1135456 | VAT No: GB 579 3459 84
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Jan 24 20:39:15 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 24 Jan 2018 11:39:15 -0800 (PST)
Subject: [R] Geometry delaunayn and deldir results,
 differing results from Octave due to decimal precision?
In-Reply-To: <CAGxFJbRuwz0QQhVAaFPzuEzq-dLBLhCH1qnTQe-7JYZw-Af26Q@mail.gmail.com>
References: <dfe9eaaf357640479d3370964a8bca37@NLLDAMEX02.ad.fugro.com>
 <CAGxFJbRuwz0QQhVAaFPzuEzq-dLBLhCH1qnTQe-7JYZw-Af26Q@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1801241120380.41377@pedal.dcn.davis.ca.us>

I think there is some middle ground here... th	ere are some expectations of 
correctness that any user should have about various implementations of 
well-known algorithms, and there are others that are unreasonable. 
However, the normal terms of use you agree to by using open source code 
such as the deldir package require that you take all responsibility for 
incorrect results, whether from your mis-use of the code or flaws in the 
code as given to you.

* Complaining to this list about percieved shortcomings is not likely to 
help... particularly for contributed packages. As Bert says, it is up to 
the contributors sharing these packages to get it right, and I like to 
think they do so to the best of their ability or available time, and 
neither R-help users nor R Core developers should be expected to take 
responsibility for those packages.

* Numerical precision is a notoriously difficult subject, and you should 
always be prepared to encounter differences in complicated results. It is 
reasonable to expect them to be small discrepancies, but the definition of 
"small" can depend on the algorithms used, and in all cases the user must 
take responsibility for verifying results.

* Any expectation that any two implementations of a mathematical graph 
algorithm present its results in the same sequence is unreasonable. It is 
perfectly normal that different implementations sort things differently, 
so buckle down and do your own sorting before doing comparisons. I would 
further say that if you are making assumptions about result ordering in 
your current work, YOUR application of the Delaunay algorithm is broken 
and in danger of yielding incorrect results.

I suggest you sort both sets of results yourself and determine whether the 
results are accurate enough for your purposes.

On Wed, 24 Jan 2018, Bert Gunter wrote:

> "The question is, what is making the results for the R packages different
> from each other?"
>
> There are literally thousands of R packages, contributed independently by
> thousands of people. There should be no expectation of consistency or for
> that matter, "correctness",  among them. Caveat emptor.
>
> Only within the base R distribution, maintained and mostly written by the R
> Core team,  might such consistency be reasonably expected.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Wed, Jan 24, 2018 at 5:59 AM, Yuen, Kam <k.yuen at fugro.com> wrote:
>
>> The problem:
>> I would like to translate the Octave algorithm in griddata.m to R.
>> Within the griddata algorithm calls are made to the Delaunay function. For
>> the R translation I have found delaunayn within the "geometry" package and
>> also the deldir package.
>> Both do similar things but give slightly different results depending on
>> the input.
>> The question is, what is making the results for the R packages different
>> from each other?
>> And are those differences down to the decimal precision in the latter case
>> of using 9 d.p.?
>> In the following example I have defined x and y to be small vectors and
>> all three sets of results agree (but are in a different order), i.e.
>> Octave's delaunay, geometry.delaunayn, and deldir.deldir
>>
>> Octave
>>
>> x = [0.9554283   0.4695926   0.0769020   0.3033320   0.3553984
>>  0.6051734   0.8661461   0.5511353   0.5214984   0.0061548]
>>
>> y = [0.851911   0.402087   0.704462   0.687721   0.939775   0.499157
>>  0.077145   0.588351   0.454380   0.193425]
>>
>> tri = delaunay(x,y)
>>
>> tri =
>>
>>     2    7   10
>>
>>     2    9    7
>>
>>     6    7    1
>>
>>     6    9    7
>>
>>     4    2    9
>>
>>     4    2   10
>>
>>     8    5    1
>>
>>     8    6    1
>>
>>     8    4    5
>>
>>     8    6    9
>>
>>     8    4    9
>>
>>     3    4   10
>>
>>     3    4    5
>>
>>
>> R With deldir package
>> x <- c(0.9554283,0.4695926,0.0769020,0.3033320,0.3553984,0.
>> 6051734,0.8661461,0.5511353,0.5214984,0.0061548)
>> y <- c(0.851911,0.402087,0.704462,0.687721,0.939775,0.499157,0.
>> 077145,0.588351,0.454380,0.193425)
>> tri <- deldir(x,y)
>> triMat(tri) =
>>       [,1] [,2] [,3]
>> [1,]    1    5    8
>> [2,]    1    6    7
>> [3,]    1    6    8
>> [4,]    2    4   10
>> [5,]    2    4    9
>> [6,]    2    7   10
>> [7,]    2    7    9
>> [8,]    3    4   10
>> [9,]    3    4    5
>> [10,]    4    5    8
>> [11,]    4    8    9
>> [12,]    6    7    9
>> [13,]    6    8    9
>>
>> R with geometry package
>>
>> x <- c(0.9554283,0.4695926,0.0769020,0.3033320,0.3553984,0.
>> 6051734,0.8661461,0.5511353,0.5214984,0.0061548)
>>
>> y <- c(0.851911,0.402087,0.704462,0.687721,0.939775,0.499157,0.
>> 077145,0.588351,0.454380,0.193425)
>>
>> library(geometry)
>>
>> tri <- delaunayn(cbind(x,y))
>>
>>
>>
>> tri
>>
>>       [,1] [,2] [,3]
>>
>> [1,]    2    7   10
>>
>> [2,]    8    5    1
>>
>> [3,]    6    7    1
>>
>> [4,]    6    8    1
>>
>> [5,]    4    2   10
>>
>> [6,]    4    3   10
>>
>> [7,]    4    3    5
>>
>> [8,]    4    8    5
>>
>> [9,]    9    6    8
>>
>> [10,]    9    4    2
>>
>> [11,]    9    4    8
>>
>> [12,]    9    2    7
>>
>> [13,]    9    6    7
>>
>> As you can see, the results are identical with the exception of ordering.
>>
>> *However* when I use a slightly larger set of data for input,
>> "geometry.delaunayn" and "deldir.deldir" seems to give results that are off
>> by one in a lot of instances.
>> The input for the Delaunay function has been exported from Octave to 9
>> d.p. and then imported into R by using the "foreign" package.
>>
>> Example data is on the following link. It is a set of variables exported
>> from Octave 'x y tri xiflat yiflat tri_list.mat'
>> https://pastebin.com/xELkj6r6
>>
>> the variable tri_list is just the tri_list = search(x,y,tri_deldir,xiflat,yiflat)
>> in Octave
>>
>>
>> The command history is a as follows:
>> library(deldir)
>> library(geometry)
>> library(foreign)
>> theData <- read.octave('x y tri xiflat yiflat tri_list.mat')
>> options(digits = 10)
>> x <- unlist(theData[1])
>> y <- unlist(theData[3])
>> tri_deldir <- triMat(deldir(x,y))
>> tri_delaunayn <- delaunayn(x,y)
>> tri_delaunayn <- delaunayn(cbind(x,y))
>> tri_list_from_deldir <- tsearch(x,y,tri_deldir,xiflat,yiflat)
>> xiflat <- unlist(theData[7])
>> yiflat <- unlist(theData[9])
>> tri_list_from_deldir <- tsearch(x,y,tri_deldir,xiflat,yiflat)
>> tri_list_from_delaunayn <- tsearch(x,y,tri_delaunayn,xiflat,yiflat)
>>
>>
>> Kam Yuen
>> Software Developer
>> T +44 (0)1491 820634| F +44 (0)1491 820599
>> k.yuen at fugro.com<mailto:k.yuen at fugro.com> | www.fugro.com<http://www.
>> fugro.com/>
>> Fugro GB Marine Limited
>> Fugro House, Hithercroft Road, Wallingford, Oxfordshire OX10 9RB, UK
>> Registration No: 1135456 | VAT No: GB 579 3459 84
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Wed Jan 24 21:05:46 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 24 Jan 2018 12:05:46 -0800 (PST)
Subject: [R] Issue with concatenation of URL losing
In-Reply-To: <YTOPR01MB0219C15CAA88F13B23DAF83FC5E20@YTOPR01MB0219.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR01MB0219C15CAA88F13B23DAF83FC5E20@YTOPR01MB0219.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <alpine.BSF.2.00.1801241148310.41377@pedal.dcn.davis.ca.us>

a) you need to read the help pages on the paste function... more likely 
you are looking for the paste0 function because extra spaces will most 
likely break the GET request format.

b) quotes do not become "stuck" as \" ... that is a visual representation 
intended to clarify that that quote is not terminating the string but is 
actually part of it. If you want to see the contents of the string without 
the escaping, use the cat function instead of depending on the default 
print behavior (which shows the escape characters).

c) The format of the GET request string includes parameter identifiers 
"lat" and "lon"... don't get confused between those strings being sent to 
the webserver and what your variables are called. Also, following those 
strings and a colon are numeric values... those are what you need to 
replace. Your attempt did not remove the literal digits from the 
surrounding strings.

d) You really need to post plain text as the Posting Guide warns you... 
your code was getting contaminated by the mailing list "fixing" this 
mistake on your part. This may completely obstruct your meaning in future 
questions, and only you can avoid this by using your email software 
properly.

########
lat <- 40.7
lon <- -76.5
tstring1 <- 
"https://elevation.mapzen.com/height?json={\"range\":false,\"shape\":[{\"lat\":40.7,\"lon\":-76.5}]}&api_key=mycode"
cat( tstring1, "\n" ) # output on its own line
#> https://elevation.mapzen.com/height?json={"range":false,"shape":[{"lat":40.7,"lon":-76.5}]}&api_key=mycode
tstring2 <- paste0( "https://elevation.mapzen.com/height?json={\"range\":false,\"shape\":[{\"lat\":",lat,",\"lon\":",lon,"}]}&api_key=mycode" )
tstring1 == tstring2 # confirm results are the same
#> [1] TRUE
lat <- 10
lon <- 20
tstring3 <- paste0( "https://elevation.mapzen.com/height?json={\"range\":false,\"shape\":[{\"lat\":",lat,",\"lon\":",lon,"}]}&api_key=mycode" )
cat( tstring3, "\n" ) # output on its own line
#> https://elevation.mapzen.com/height?json={"range":false,"shape":[{"lat":10,"lon":20}]}&api_key=mycode
########

On Wed, 24 Jan 2018, Oliver Morris wrote:

> Thank you for your help in advance.
>
>
> I am trying to pull some data back from a web service
>
>
> library(httr)
> sample2 <- GET("https://elevation.mapzen.com/height?json={\"range\":false,\"shape\":[{\"lat\":40.7,\"lon\":-76.5}]}&api_key=mycode")
> result2 <- content(sample2)
> height <- result2$height[[1]]
>
>
> I would like to put by own latitude and longitude in but alas when I use 
> paste() to combine the double quotes become stuck as literally \"
>
>
> lat <-10
>
> long <20
>
> library(httr)
> sample2 <- GET(paste("https://elevation.mapzen.com/height?json={\"range\":false,\"shape\":[{\", lat , \":40.7,\", long,\":-76.5}]}&api_key=mycode"))
> result2 <- content(sample2)
> height <- result2$height[[1]]
>
>
> Can you please suggest a way around this, it has been driving me mad!
>
>
> Thank you so much.
>
>
> Oliver
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jmtruppia at gmail.com  Thu Jan 25 04:11:49 2018
From: jmtruppia at gmail.com (Juan Manuel Truppia)
Date: Thu, 25 Jan 2018 03:11:49 +0000
Subject: [R] Portable R in zip file for Windows
Message-ID: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>

I read a message from 2009 or 2010 where it mentioned the availability of R
for Windows in a zip file, no installation required. It would be very
useful for me. Is this still available somewhere?

Thanks

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Jan 25 04:30:34 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 24 Jan 2018 19:30:34 -0800
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
Message-ID: <98A501A6-86C8-4E7D-B3DB-7DDE34F4A9E3@dcn.davis.ca.us>

I have never used it, but Google sez look here [1]. You should learn to speak Google also.

[1] https://sourceforge.net/projects/rportable/
-- 
Sent from my phone. Please excuse my brevity.

On January 24, 2018 7:11:49 PM PST, Juan Manuel Truppia <jmtruppia at gmail.com> wrote:
>I read a message from 2009 or 2010 where it mentioned the availability
>of R
>for Windows in a zip file, no installation required. It would be very
>useful for me. Is this still available somewhere?
>
>Thanks
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ramesh.yapalparvi at icloud.com  Thu Jan 25 00:00:39 2018
From: ramesh.yapalparvi at icloud.com (Ramesh YAPALPARVI)
Date: Wed, 24 Jan 2018 23:00:39 +0000 (GMT)
Subject: [R] Help with SQLsave
Message-ID: <916f5416-9b02-436c-9141-a1eae3aed1aa@me.com>

Hi all,



I'm using RODBC library to connect to a database.

I'm trying to read a table from a database and after manipulating it would like to write to the same database but with a different table



P<-data.frame(sqlQuery(myconn,'select? *? from Demographics'))
sqlSave(myconn,p,tablename="trial",rownames=FALSE)




I'm gettng this error







Version:1.0 StartHTML:0000000107 EndHTML:0000001014 StartFragment:0000000127 EndFragment:0000000996
Error in sqlSave(myconn, p, tablename = "trial", rownames = FALSE) : 
  [RODBC] Failed exec in Update
22018 0 [Microsoft][ODBC Driver 11 for SQL Server]Invalid character value for cast specification


Thanks,

Ramesh

From dstr7320 at uni.sydney.edu.au  Thu Jan 25 01:00:04 2018
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Thu, 25 Jan 2018 00:00:04 +0000
Subject: [R] Stats reshape non-Longitudinal Example Correctness
Message-ID: <SY3PR01MB0747D26CCEE33EAD20683805CDE20@SY3PR01MB0747.ausprd01.prod.outlook.com>

Good day,

In the Examples section of the reshape function documentation is an example that reshapes that data frame state.x77. However, the resulting long data frame doesn't seem correct. It has three columns; Characteristic, Population and state. The second column probably shouldn't be named Population because it stores all of the values for all of the variables and only one of the variables in the dataset is Population. I wouldn't expect to see values for Frost in the Population column, for example. Is it a bug? I think that a column name such as Value would be appropriate.

> sessionInfo()
R Under development (unstable) (2018-01-07 r74096)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.3 LTS

--------------------------------------
Dario Strbenac
University of Sydney
Camperdown NSW 2050
Australia


From ruipbarradas at sapo.pt  Thu Jan 25 10:31:39 2018
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 25 Jan 2018 09:31:39 +0000
Subject: [R] random sample set for regression
In-Reply-To: <CAB0xfdx8HpO9ELSdZ28U4nh5-EtFLJ5pUmPpkcs3YE-x67eQ4w@mail.gmail.com>
References: <CAB0xfdx8HpO9ELSdZ28U4nh5-EtFLJ5pUmPpkcs3YE-x67eQ4w@mail.gmail.com>
Message-ID: <2846c61e-9eac-0066-424f-4429cd1b8fd6@sapo.pt>

Hello,

Can you please post the output of

dput(all)   # if all is small
dput(head(all, 30))  # if all is big

in a mail?

Hope this helps,

Rui Barradas

On 1/24/2018 4:28 PM, Francisca R. Souza Pereira wrote:
> Hi,
> I'm not a programmer, so I have a question about R functions,
> 
> I run the Random Forest regression models, but
> I would like to run the random forest model 1000 times with different
> random sample set. to check the uncertainty of the regression model
> estimates.
> 
> exemple of data:
> #################################
> table= all
> Y: all$AGB
> X variables:
> Variables=as.matrix(all[, c( "min", "max", "avg", "qav", "std",
>                                    "ske", "kur",  "p50",  "d50",  "d06",
> "d07", "d08", "dns_gap")])
> 
> rf.Model=randomForest(Variables, all$AGB, importance=T)
> #################################
> 
> Can I use Monte Carlo method or Bootstrap to simulate 1000 different sample
> set and Run 1000 x times the Random Forest regression?  But How can I do
> that? Could somebody have an idea with the script?
> Thanks!
> Fran
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jmtruppia at gmail.com  Thu Jan 25 12:37:55 2018
From: jmtruppia at gmail.com (Juan Manuel Truppia)
Date: Thu, 25 Jan 2018 11:37:55 +0000
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <98A501A6-86C8-4E7D-B3DB-7DDE34F4A9E3@dcn.davis.ca.us>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
 <98A501A6-86C8-4E7D-B3DB-7DDE34F4A9E3@dcn.davis.ca.us>
Message-ID: <CAO2XSvf2Wbwu4REL784RNp7pzxSujV7EZ0TPT_GErqAHrt9nZA@mail.gmail.com>

Im already aware of that. Needs the portable apps framework to work.
Thanks for the cheap hit by the way

On Thu, Jan 25, 2018, 00:30 Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> I have never used it, but Google sez look here [1]. You should learn to
> speak Google also.
>
> [1] https://sourceforge.net/projects/rportable/
> --
> Sent from my phone. Please excuse my brevity.
>
> On January 24, 2018 7:11:49 PM PST, Juan Manuel Truppia <
> jmtruppia at gmail.com> wrote:
> >I read a message from 2009 or 2010 where it mentioned the availability
> >of R
> >for Windows in a zip file, no installation required. It would be very
> >useful for me. Is this still available somewhere?
> >
> >Thanks
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkrideau at yahoo.ca  Thu Jan 25 13:36:57 2018
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 25 Jan 2018 12:36:57 +0000 (UTC)
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
Message-ID: <512682959.183361.1516883817546@mail.yahoo.com>

I have not done this is years, but I think that I just installed R on a USB stick and it was fine. But that was probably 10 years ago so things may have changed completely since then.
 

    On Wednesday, January 24, 2018, 10:12:09 PM EST, Juan Manuel Truppia <jmtruppia at gmail.com> wrote:  
 
 I read a message from 2009 or 2010 where it mentioned the availability of R
for Windows in a zip file, no installation required. It would be very
useful for me. Is this still available somewhere?

Thanks

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From jmtruppia at gmail.com  Thu Jan 25 13:42:01 2018
From: jmtruppia at gmail.com (Juan Manuel Truppia)
Date: Thu, 25 Jan 2018 12:42:01 +0000
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <512682959.183361.1516883817546@mail.yahoo.com>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
 <512682959.183361.1516883817546@mail.yahoo.com>
Message-ID: <CAO2XSveUkwB7YShvqU8YXyw1v7ySZEUAaG-ez6SDw2v+H7O7NA@mail.gmail.com>

Yes, that works, but I can't use USB sticks. It has to be a downloadable
zip file


On Thu, Jan 25, 2018, 09:37 John Kane <jrkrideau at yahoo.ca> wrote:

> I have not done this is years, but I think that I just installed R on a
> USB stick and it was fine. But that was probably 10 years ago so things may
> have changed completely since then.
>
>
> On Wednesday, January 24, 2018, 10:12:09 PM EST, Juan Manuel Truppia <
> jmtruppia at gmail.com> wrote:
>
>
> I read a message from 2009 or 2010 where it mentioned the availability of R
> for Windows in a zip file, no installation required. It would be very
> useful for me. Is this still available somewhere?
>
> Thanks
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Jan 25 13:57:05 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 25 Jan 2018 12:57:05 +0000
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <CAO2XSveUkwB7YShvqU8YXyw1v7ySZEUAaG-ez6SDw2v+H7O7NA@mail.gmail.com>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
 <512682959.183361.1516883817546@mail.yahoo.com>
 <CAO2XSveUkwB7YShvqU8YXyw1v7ySZEUAaG-ez6SDw2v+H7O7NA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD544F@SRVEXCHCM301.precheza.cz>

Hm. I wonder what is your intention. R is a program, it needs to be installed somewhere. You could install it on USB stick from where it could be run. But you said you cannot use USB stick.

So you need to install R program and you could probably make a zip file from this installation and put it on USB stick or to Dropbox or ...

But you most probably cannot run it from this zip file directly, you need to unzip it somewhere. In that case why not install R directly to "somewhere"?

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Juan Manuel
> Truppia
> Sent: Thursday, January 25, 2018 1:42 PM
> To: John Kane <jrkrideau at yahoo.ca>
> Cc: r-help at r-project.org
> Subject: Re: [R] Portable R in zip file for Windows
>
> Yes, that works, but I can't use USB sticks. It has to be a downloadable zip file
>
>
> On Thu, Jan 25, 2018, 09:37 John Kane <jrkrideau at yahoo.ca> wrote:
>
> > I have not done this is years, but I think that I just installed R on
> > a USB stick and it was fine. But that was probably 10 years ago so
> > things may have changed completely since then.
> >
> >
> > On Wednesday, January 24, 2018, 10:12:09 PM EST, Juan Manuel Truppia <
> > jmtruppia at gmail.com> wrote:
> >
> >
> > I read a message from 2009 or 2010 where it mentioned the availability
> > of R for Windows in a zip file, no installation required. It would be
> > very useful for me. Is this still available somewhere?
> >
> > Thanks
> >
> >     [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From istazahn at gmail.com  Thu Jan 25 14:16:23 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 25 Jan 2018 08:16:23 -0500
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <CAO2XSvf2Wbwu4REL784RNp7pzxSujV7EZ0TPT_GErqAHrt9nZA@mail.gmail.com>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
 <98A501A6-86C8-4E7D-B3DB-7DDE34F4A9E3@dcn.davis.ca.us>
 <CAO2XSvf2Wbwu4REL784RNp7pzxSujV7EZ0TPT_GErqAHrt9nZA@mail.gmail.com>
Message-ID: <CA+vqiLH2A26+1CihmUgmjtEMgGjK-t89HHJi0vAxWEuF7XReGw@mail.gmail.com>

On Jan 25, 2018 6:38 AM, "Juan Manuel Truppia" <jmtruppia at gmail.com> wrote:

Im already aware of that. Needs the portable apps framework to work.
Thanks for the cheap hit by the way


Thanks for wasting everyones time by failing to mention the things you
already looked at and why they were unsuitable. Please study
http://catb.org/~esr/faqs/smart-questions.html to learn how to avoid
repeating this mistake.

Best,
Ista

On Thu, Jan 25, 2018, 00:30 Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> I have never used it, but Google sez look here [1]. You should learn to
> speak Google also.
>
> [1] https://sourceforge.net/projects/rportable/
> --
> Sent from my phone. Please excuse my brevity.
>
> On January 24, 2018 7:11:49 PM PST, Juan Manuel Truppia <
> jmtruppia at gmail.com> wrote:
> >I read a message from 2009 or 2010 where it mentioned the availability
> >of R
> >for Windows in a zip file, no installation required. It would be very
> >useful for me. Is this still available somewhere?
> >
> >Thanks
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ggrothendieck at gmail.com  Thu Jan 25 15:19:04 2018
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 25 Jan 2018 09:19:04 -0500
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
Message-ID: <CAP01uRk0_s+QxwDigbkd+U2eKmvDvTB6a763+_UgNOJknvsTvA@mail.gmail.com>

I believe that the ordinary Windows installer for R can produce a
portable result by choosing the appropriate configuration options from the
offered screens when you run the installer  Be sure to enter the desired
path in the Select Destination Location screen, choose Yes on the
Startup options screen and ensure that all boxes are unchecked on the
Select additional tasks screen.

On Wed, Jan 24, 2018 at 10:11 PM, Juan Manuel Truppia
<jmtruppia at gmail.com> wrote:
> I read a message from 2009 or 2010 where it mentioned the availability of R
> for Windows in a zip file, no installation required. It would be very
> useful for me. Is this still available somewhere?
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From wdunlap at tibco.com  Thu Jan 25 17:16:15 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 25 Jan 2018 08:16:15 -0800
Subject: [R] Geometry delaunayn and deldir results,
 differing results from Octave due to decimal precision?
In-Reply-To: <b409be6f5b2a4d028e5353fdb32ed9b9@NLLDAMEX02.ad.fugro.com>
References: <dfe9eaaf357640479d3370964a8bca37@NLLDAMEX02.ad.fugro.com>
 <CAF8bMcZi_s2UkA3=dG73RbzjSo4DxUNMv_WQ5KkimVi2geMYYg@mail.gmail.com>
 <b409be6f5b2a4d028e5353fdb32ed9b9@NLLDAMEX02.ad.fugro.com>
Message-ID: <CAF8bMcZSgBZUZpAaLhz9kX+uNXGvi_HUxkww1DXjGRYXBw42Ag@mail.gmail.com>

I just looked at the data at the URL you posted and it looks like it
consists
of all the points in a rectangular grid.   When you triangulate a rectangle
it is
arbitrary whether you use the SW-NE or the SE-NW diagonal and that looks
like the only difference between the various algorithms.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Jan 25, 2018 at 5:14 AM, Yuen, Kam <k.yuen at fugro.com> wrote:

> Bill,
>
>
>
> It wasn?t really the orientation I was worried about.
>
> I should perhaps have phrased the question better. It was really about the
> fact that for the larger input example the triangles **are not** the same
> for each implementation.
>
> They certainly differ from the Octave implementation (not that that is in
> some way a gold standard).
>
> Anyhow the point made by yourself and others is well taken, i.e. I should
> have no expectation that different implementations will produce the same
> output.
>
>
>
> Regards,
>
>
>
> Kam
>
>
>
>
>
> *From:* William Dunlap [mailto:wdunlap at tibco.com]
> *Sent:* 24 January 2018 19:29
> *To:* Yuen, Kam <k.yuen at fugro.com>
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] Geometry delaunayn and deldir results, differing
> results from Octave due to decimal precision?
>
>
>
> All three results give the same collection of triangles.  They
>
> don't all agree on whether the points in a triangle are in clockwise
>
> or counterclockwise order.  If the orientation matters, it is a simple
>
> matter to reverse the order of points in those that described in
>
> the "wrong" orientation.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
>
> On Wed, Jan 24, 2018 at 5:59 AM, Yuen, Kam <k.yuen at fugro.com> wrote:
>
> The problem:
> I would like to translate the Octave algorithm in griddata.m to R.
> Within the griddata algorithm calls are made to the Delaunay function. For
> the R translation I have found delaunayn within the "geometry" package and
> also the deldir package.
> Both do similar things but give slightly different results depending on
> the input.
> The question is, what is making the results for the R packages different
> from each other?
> And are those differences down to the decimal precision in the latter case
> of using 9 d.p.?
> In the following example I have defined x and y to be small vectors and
> all three sets of results agree (but are in a different order), i.e.
> Octave's delaunay, geometry.delaunayn, and deldir.deldir
>
> Octave
>
> x = [0.9554283   0.4695926   0.0769020   0.3033320   0.3553984
>  0.6051734   0.8661461   0.5511353   0.5214984   0.0061548]
>
> y = [0.851911   0.402087   0.704462   0.687721   0.939775   0.499157
>  0.077145   0.588351   0.454380   0.193425]
>
> tri = delaunay(x,y)
>
> tri =
>
>     2    7   10
>
>     2    9    7
>
>     6    7    1
>
>     6    9    7
>
>     4    2    9
>
>     4    2   10
>
>     8    5    1
>
>     8    6    1
>
>     8    4    5
>
>     8    6    9
>
>     8    4    9
>
>     3    4   10
>
>     3    4    5
>
>
> R With deldir package
> x <- c(0.9554283,0.4695926,0.0769020,0.3033320,0.3553984,0.
> 6051734,0.8661461,0.5511353,0.5214984,0.0061548)
> y <- c(0.851911,0.402087,0.704462,0.687721,0.939775,0.499157,0.
> 077145,0.588351,0.454380,0.193425)
> tri <- deldir(x,y)
> triMat(tri) =
>       [,1] [,2] [,3]
> [1,]    1    5    8
> [2,]    1    6    7
> [3,]    1    6    8
> [4,]    2    4   10
> [5,]    2    4    9
> [6,]    2    7   10
> [7,]    2    7    9
> [8,]    3    4   10
> [9,]    3    4    5
> [10,]    4    5    8
> [11,]    4    8    9
> [12,]    6    7    9
> [13,]    6    8    9
>
> R with geometry package
>
> x <- c(0.9554283,0.4695926,0.0769020,0.3033320,0.3553984,0.
> 6051734,0.8661461,0.5511353,0.5214984,0.0061548)
>
> y <- c(0.851911,0.402087,0.704462,0.687721,0.939775,0.499157,0.
> 077145,0.588351,0.454380,0.193425)
>
> library(geometry)
>
> tri <- delaunayn(cbind(x,y))
>
>
>
> tri
>
>       [,1] [,2] [,3]
>
> [1,]    2    7   10
>
> [2,]    8    5    1
>
> [3,]    6    7    1
>
> [4,]    6    8    1
>
> [5,]    4    2   10
>
> [6,]    4    3   10
>
> [7,]    4    3    5
>
> [8,]    4    8    5
>
> [9,]    9    6    8
>
> [10,]    9    4    2
>
> [11,]    9    4    8
>
> [12,]    9    2    7
>
> [13,]    9    6    7
>
> As you can see, the results are identical with the exception of ordering.
>
> *However* when I use a slightly larger set of data for input,
> "geometry.delaunayn" and "deldir.deldir" seems to give results that are off
> by one in a lot of instances.
> The input for the Delaunay function has been exported from Octave to 9
> d.p. and then imported into R by using the "foreign" package.
>
> Example data is on the following link. It is a set of variables exported
> from Octave 'x y tri xiflat yiflat tri_list.mat'
> https://pastebin.com/xELkj6r6
>
> the variable tri_list is just the tri_list = search(x,y,tri_deldir,xiflat,yiflat)
> in Octave
>
>
> The command history is a as follows:
> library(deldir)
> library(geometry)
> library(foreign)
> theData <- read.octave('x y tri xiflat yiflat tri_list.mat')
> options(digits = 10)
> x <- unlist(theData[1])
> y <- unlist(theData[3])
> tri_deldir <- triMat(deldir(x,y))
> tri_delaunayn <- delaunayn(x,y)
> tri_delaunayn <- delaunayn(cbind(x,y))
> tri_list_from_deldir <- tsearch(x,y,tri_deldir,xiflat,yiflat)
> xiflat <- unlist(theData[7])
> yiflat <- unlist(theData[9])
> tri_list_from_deldir <- tsearch(x,y,tri_deldir,xiflat,yiflat)
> tri_list_from_delaunayn <- tsearch(x,y,tri_delaunayn,xiflat,yiflat)
>
>
> Kam Yuen
> Software Developer
> T +44 (0)1491 820634| F +44 (0)1491 820599
> k.yuen at fugro.com<mailto:k.yuen at fugro.com> | www.fugro.com<http://www.
> fugro.com/>
> Fugro GB Marine Limited
> Fugro House, Hithercroft Road, Wallingford, Oxfordshire OX10 9RB, UK
> Registration No: 1135456 | VAT No: GB 579 3459 84
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From albert.shuxiang.li at outlook.com  Thu Jan 25 15:42:27 2018
From: albert.shuxiang.li at outlook.com (SHUXIANG 'ALBERT' LI)
Date: Thu, 25 Jan 2018 14:42:27 +0000
Subject: [R] Help with SQLsave
In-Reply-To: <916f5416-9b02-436c-9141-a1eae3aed1aa@me.com>
References: <916f5416-9b02-436c-9141-a1eae3aed1aa@me.com>
Message-ID: <CY1PR0201MB1787C8DB1FA21B1AD2EF0563FEE10@CY1PR0201MB1787.namprd02.prod.outlook.com>

"P" is not "p"


try

sqlSave(myconn,P,tablename="trial",rownames=FALSE)


Have a wonderful day!

- Albert
________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Ramesh YAPALPARVI <ramesh.yapalparvi at icloud.com>
Sent: Wednesday, January 24, 2018 4:00:39 PM
To: R-help at r-project.org
Subject: [R] Help with SQLsave

Hi all,



I'm using RODBC library to connect to a database.

I'm trying to read a table from a database and after manipulating it would like to write to the same database but with a different table



P<-data.frame(sqlQuery(myconn,'select  *  from Demographics'))
sqlSave(myconn,p,tablename="trial",rownames=FALSE)




I'm gettng this error







Version:1.0 StartHTML:0000000107 EndHTML:0000001014 StartFragment:0000000127 EndFragment:0000000996
Error in sqlSave(myconn, p, tablename = "trial", rownames = FALSE) :
  [RODBC] Failed exec in Update
22018 0 [Microsoft][ODBC Driver 11 for SQL Server]Invalid character value for cast specification


Thanks,

Ramesh
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From laha.moyukh at gmail.com  Thu Jan 25 19:30:26 2018
From: laha.moyukh at gmail.com (Moyukh Laha)
Date: Thu, 25 Jan 2018 18:30:26 +0000
Subject: [R] Help in Plotting in "fArma" Package
Message-ID: <CAC1L6m00PadoB4wmnSYFevoPVh0HtB11_RQGn3t6wz4eHxeg3g@mail.gmail.com>

Hello,
        I am new to R and for some of my research work I am using 'fArma'
package to estimate the Hurst parameter of a time series.
        When I am ding the following command :
                                     rsFit(data, doplot = TRUE)
I am getting the R/S plot for that time series with default plot title,
font size. However, I want to  change the axis size, font size etc of this
plot, which I am unable to do as there is no formal argument here. Can
anyone suggest something about this? How can I change the font size, axis
size etc here?
Thanks.

	[[alternative HTML version deleted]]


From om2468 at hotmail.com  Thu Jan 25 18:53:38 2018
From: om2468 at hotmail.com (Oliver Morris)
Date: Thu, 25 Jan 2018 17:53:38 +0000
Subject: [R] Issue with concatenation of URL losing
In-Reply-To: <alpine.BSF.2.00.1801241148310.41377@pedal.dcn.davis.ca.us>
References: <YTOPR01MB0219C15CAA88F13B23DAF83FC5E20@YTOPR01MB0219.CANPRD01.PROD.OUTLOOK.COM>,
 <alpine.BSF.2.00.1801241148310.41377@pedal.dcn.davis.ca.us>
Message-ID: <YTOPR01MB0219DDE879FF3DE73D56AE59C5E10@YTOPR01MB0219.CANPRD01.PROD.OUTLOOK.COM>

Thank you the paste0() worked. Really appreciate the help.
________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Wednesday, January 24, 2018 8:05:46 PM
To: Oliver Morris
Cc: r-help at r-project.org
Subject: Re: [R] Issue with concatenation of URL losing

a) you need to read the help pages on the paste function... more likely
you are looking for the paste0 function because extra spaces will most
likely break the GET request format.

b) quotes do not become "stuck" as \" ... that is a visual representation
intended to clarify that that quote is not terminating the string but is
actually part of it. If you want to see the contents of the string without
the escaping, use the cat function instead of depending on the default
print behavior (which shows the escape characters).

c) The format of the GET request string includes parameter identifiers
"lat" and "lon"... don't get confused between those strings being sent to
the webserver and what your variables are called. Also, following those
strings and a colon are numeric values... those are what you need to
replace. Your attempt did not remove the literal digits from the
surrounding strings.

d) You really need to post plain text as the Posting Guide warns you...
your code was getting contaminated by the mailing list "fixing" this
mistake on your part. This may completely obstruct your meaning in future
questions, and only you can avoid this by using your email software
properly.

########
lat <- 40.7
lon <- -76.5
tstring1 <-
"https://elevation.mapzen.com/height?json={\"range\":false,\"shape\":[{\"lat\":40.7,\"lon\":-76.5}]}&api_key=mycode"
cat( tstring1, "\n" ) # output on its own line
#> https://elevation.mapzen.com/height?json={"range":false,"shape":[{"lat":40.7,"lon":-76.5}]}&api_key=mycode
tstring2 <- paste0( "https://elevation.mapzen.com/height?json={\"range\":false,\"shape\":[{\"lat\":",lat,",\"lon\":",lon,"}]}&api_key=mycode" )
tstring1 == tstring2 # confirm results are the same
#> [1] TRUE
lat <- 10
lon <- 20
tstring3 <- paste0( "https://elevation.mapzen.com/height?json={\"range\":false,\"shape\":[{\"lat\":",lat,",\"lon\":",lon,"}]}&api_key=mycode" )
cat( tstring3, "\n" ) # output on its own line
#> https://elevation.mapzen.com/height?json={"range":false,"shape":[{"lat":10,"lon":20}]}&api_key=mycode
########

On Wed, 24 Jan 2018, Oliver Morris wrote:

> Thank you for your help in advance.
>
>
> I am trying to pull some data back from a web service
>
>
> library(httr)
> sample2 <- GET("https://elevation.mapzen.com/height?json={\"range\":false,\"shape\":[{\"lat\":40.7,\"lon\":-76.5}]}&api_key=mycode")
> result2 <- content(sample2)
> height <- result2$height[[1]]
>
>
> I would like to put by own latitude and longitude in but alas when I use
> paste() to combine the double quotes become stuck as literally \"
>
>
> lat <-10
>
> long <20
>
> library(httr)
> sample2 <- GET(paste("https://elevation.mapzen.com/height?json={\"range\":false,\"shape\":[{\", lat , \":40.7,\", long,\":-76.5}]}&api_key=mycode"))
> result2 <- content(sample2)
> height <- result2$height[[1]]
>
>
[[elided Hotmail spam]]
>
>
> Thank you so much.
>
>
> Oliver
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From jmtruppia at gmail.com  Thu Jan 25 21:04:33 2018
From: jmtruppia at gmail.com (Juan Manuel Truppia)
Date: Thu, 25 Jan 2018 20:04:33 +0000
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <CAP01uRk0_s+QxwDigbkd+U2eKmvDvTB6a763+_UgNOJknvsTvA@mail.gmail.com>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
 <CAP01uRk0_s+QxwDigbkd+U2eKmvDvTB6a763+_UgNOJknvsTvA@mail.gmail.com>
Message-ID: <CAO2XSvcAuPnYWtdCHfOPm__9vtoyrY45QEMjfw9fraFWUjt3sw@mail.gmail.com>

What is wrong with you guys? I asked for a zip, like R Studio has for
example. Totally clear.
I cant execute exes. But I can unzip files.
Thanks Gabor, I had that in mind, but can't execute the exe due to security
restrictions.
Geez, really, treating people who ask questions this way just makes you
don't want to ask a single one.

On Thu, Jan 25, 2018, 11:19 Gabor Grothendieck <ggrothendieck at gmail.com>
wrote:

> I believe that the ordinary Windows installer for R can produce a
> portable result by choosing the appropriate configuration options from the
> offered screens when you run the installer  Be sure to enter the desired
> path in the Select Destination Location screen, choose Yes on the
> Startup options screen and ensure that all boxes are unchecked on the
> Select additional tasks screen.
>
> On Wed, Jan 24, 2018 at 10:11 PM, Juan Manuel Truppia
> <jmtruppia at gmail.com> wrote:
> > I read a message from 2009 or 2010 where it mentioned the availability
> of R
> > for Windows in a zip file, no installation required. It would be very
> > useful for me. Is this still available somewhere?
> >
> > Thanks
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Thu Jan 25 22:26:06 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 25 Jan 2018 16:26:06 -0500
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <CAO2XSvcAuPnYWtdCHfOPm__9vtoyrY45QEMjfw9fraFWUjt3sw@mail.gmail.com>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
 <CAP01uRk0_s+QxwDigbkd+U2eKmvDvTB6a763+_UgNOJknvsTvA@mail.gmail.com>
 <CAO2XSvcAuPnYWtdCHfOPm__9vtoyrY45QEMjfw9fraFWUjt3sw@mail.gmail.com>
Message-ID: <CA+vqiLF0zooBAW91r5GGzXBEgXYDXwQrB0w+-jJOrJaXT77JMw@mail.gmail.com>

On Jan 25, 2018 3:05 PM, "Juan Manuel Truppia" <jmtruppia at gmail.com> wrote:

What is wrong with you guys? I asked for a zip, like R Studio has for
example. Totally clear.


The responsew you recieved suggest that your question was not as clear as
you expected. You then treated a person trying to help you with disrespect.
This is not an effective way to motivate people to help you.

I cant execute exes. But I can unzip files.
Thanks Gabor, I had that in mind, but can't execute the exe due to security
restrictions.


Again, this information should have been in your original question. By
failing to mention that you had considered and rejected this option for
security reasons you caused Gabor to waste time suggesting it.

The bottom line is that you asked a lazy question and failed to include
helpful information that would have helped people help you. You then
responded rudely when people failed to read your mind. You can and should
learn do better.


Geez, really, treating people who ask questions this way just makes you
don't want to ask a single one.


Learn how to ask as I suggested and I'm confident things will go better
next time.

Best,
Ista


On Thu, Jan 25, 2018, 11:19 Gabor Grothendieck <ggrothendieck at gmail.com>
wrote:

> I believe that the ordinary Windows installer for R can produce a
> portable result by choosing the appropriate configuration options from the
> offered screens when you run the installer  Be sure to enter the desired
> path in the Select Destination Location screen, choose Yes on the
> Startup options screen and ensure that all boxes are unchecked on the
> Select additional tasks screen.
>
> On Wed, Jan 24, 2018 at 10:11 PM, Juan Manuel Truppia
> <jmtruppia at gmail.com> wrote:
> > I read a message from 2009 or 2010 where it mentioned the availability
> of R
> > for Windows in a zip file, no installation required. It would be very
> > useful for me. Is this still available somewhere?
> >
> > Thanks
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From frainj at gmail.com  Thu Jan 25 23:59:39 2018
From: frainj at gmail.com (John C Frain)
Date: Thu, 25 Jan 2018 22:59:39 +0000
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <CAO2XSvcAuPnYWtdCHfOPm__9vtoyrY45QEMjfw9fraFWUjt3sw@mail.gmail.com>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
 <CAP01uRk0_s+QxwDigbkd+U2eKmvDvTB6a763+_UgNOJknvsTvA@mail.gmail.com>
 <CAO2XSvcAuPnYWtdCHfOPm__9vtoyrY45QEMjfw9fraFWUjt3sw@mail.gmail.com>
Message-ID: <CAHrK516R_EP-fRoCyDCsV9kB2gy=gMKp=ORVrWfLkcAb7WQqKA@mail.gmail.com>

Can you please explain where you get the R-studio zip file and how you
manage to run r-studio from it without expanding it.  I do not see how this
is possible and would be delighted if you would share that knowledge with
us.  Obviously this possibility has not occurred to anyone on the list

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 25 January 2018 at 20:04, Juan Manuel Truppia <jmtruppia at gmail.com>
wrote:

> What is wrong with you guys? I asked for a zip, like R Studio has for
> example. Totally clear.
> I cant execute exes. But I can unzip files.
> Thanks Gabor, I had that in mind, but can't execute the exe due to security
> restrictions.
> Geez, really, treating people who ask questions this way just makes you
> don't want to ask a single one.
>
> On Thu, Jan 25, 2018, 11:19 Gabor Grothendieck <ggrothendieck at gmail.com>
> wrote:
>
> > I believe that the ordinary Windows installer for R can produce a
> > portable result by choosing the appropriate configuration options from
> the
> > offered screens when you run the installer  Be sure to enter the desired
> > path in the Select Destination Location screen, choose Yes on the
> > Startup options screen and ensure that all boxes are unchecked on the
> > Select additional tasks screen.
> >
> > On Wed, Jan 24, 2018 at 10:11 PM, Juan Manuel Truppia
> > <jmtruppia at gmail.com> wrote:
> > > I read a message from 2009 or 2010 where it mentioned the availability
> > of R
> > > for Windows in a zip file, no installation required. It would be very
> > > useful for me. Is this still available somewhere?
> > >
> > > Thanks
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Statistics & Software Consulting
> > GKX Group, GKX Associates Inc.
> > tel: 1-877-GKX-GROUP
> > email: ggrothendieck at gmail.com
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jmtruppia at gmail.com  Fri Jan 26 01:12:10 2018
From: jmtruppia at gmail.com (Juan Manuel Truppia)
Date: Fri, 26 Jan 2018 00:12:10 +0000
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <CAHrK516R_EP-fRoCyDCsV9kB2gy=gMKp=ORVrWfLkcAb7WQqKA@mail.gmail.com>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
 <CAP01uRk0_s+QxwDigbkd+U2eKmvDvTB6a763+_UgNOJknvsTvA@mail.gmail.com>
 <CAO2XSvcAuPnYWtdCHfOPm__9vtoyrY45QEMjfw9fraFWUjt3sw@mail.gmail.com>
 <CAHrK516R_EP-fRoCyDCsV9kB2gy=gMKp=ORVrWfLkcAb7WQqKA@mail.gmail.com>
Message-ID: <CAO2XSvcMUGAR=NDnAYgRS-jxngxCP0fj5S8fByo7OHa_agpwmQ@mail.gmail.com>

>From the R Studio downloads, look below the installers. This is off topic
however. If there is no zipped, no exe, no installation required of R, then
I thank you very much for your help and trolling.

(BTW, I think my question was pretty clear, concise and specific, I
appreciate that some of you tried to solve a problem related to what I
have, but I have already reviewed all options, and what I need is basically
a zip of a working installation of the current version of R that I can
download out of CRAN or a similar trusted site)

On Thu, Jan 25, 2018, 19:59 John C Frain <frainj at gmail.com> wrote:

> Can you please explain where you get the R-studio zip file and how you
> manage to run r-studio from it without expanding it.  I do not see how this
> is possible and would be delighted if you would share that knowledge with
> us.  Obviously this possibility has not occurred to anyone on the list
>
> John C Frain
> 3 Aranleigh Park
> <https://maps.google.com/?q=3+Aranleigh+Park+Rathfarnham+Dublin&entry=gmail&source=g>
> Rathfarnham
> <https://maps.google.com/?q=3+Aranleigh+Park+Rathfarnham+Dublin&entry=gmail&source=g>
> Dublin
> <https://maps.google.com/?q=3+Aranleigh+Park+Rathfarnham+Dublin&entry=gmail&source=g>
> 14
> Ireland
> www.tcd.ie/Economics/staff/frainj/home.html
> mailto:frainj at tcd.ie
> mailto:frainj at gmail.com
>
> On 25 January 2018 at 20:04, Juan Manuel Truppia <jmtruppia at gmail.com>
> wrote:
>
>> What is wrong with you guys? I asked for a zip, like R Studio has for
>> example. Totally clear.
>> I cant execute exes. But I can unzip files.
>> Thanks Gabor, I had that in mind, but can't execute the exe due to
>> security
>> restrictions.
>> Geez, really, treating people who ask questions this way just makes you
>> don't want to ask a single one.
>>
>> On Thu, Jan 25, 2018, 11:19 Gabor Grothendieck <ggrothendieck at gmail.com>
>> wrote:
>>
>> > I believe that the ordinary Windows installer for R can produce a
>> > portable result by choosing the appropriate configuration options from
>> the
>> > offered screens when you run the installer  Be sure to enter the desired
>> > path in the Select Destination Location screen, choose Yes on the
>> > Startup options screen and ensure that all boxes are unchecked on the
>> > Select additional tasks screen.
>> >
>> > On Wed, Jan 24, 2018 at 10:11 PM, Juan Manuel Truppia
>> > <jmtruppia at gmail.com> wrote:
>> > > I read a message from 2009 or 2010 where it mentioned the availability
>> > of R
>> > > for Windows in a zip file, no installation required. It would be very
>> > > useful for me. Is this still available somewhere?
>> > >
>> > > Thanks
>> > >
>> > >         [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> >
>> > --
>> > Statistics & Software Consulting
>> > GKX Group, GKX Associates Inc.
>> > tel: 1-877-GKX-GROUP
>> > email: ggrothendieck at gmail.com
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Jan 26 02:56:19 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 25 Jan 2018 17:56:19 -0800
Subject: [R] Help in Plotting in "fArma" Package
In-Reply-To: <CAC1L6m00PadoB4wmnSYFevoPVh0HtB11_RQGn3t6wz4eHxeg3g@mail.gmail.com>
References: <CAC1L6m00PadoB4wmnSYFevoPVh0HtB11_RQGn3t6wz4eHxeg3g@mail.gmail.com>
Message-ID: <AB67EF65-5715-4B33-821B-B459CA3374A0@comcast.net>

The documentation say that additional arguments will be passed. I suspect this will be a base graphics plot. You should look at the code of plot.rsfit to determine which arguments get processed. 

Sent from my iPhone

> On Jan 25, 2018, at 10:30 AM, Moyukh Laha <laha.moyukh at gmail.com> wrote:
> 
> Hello,
>        I am new to R and for some of my research work I am using 'fArma'
> package to estimate the Hurst parameter of a time series.
>        When I am ding the following command :
>                                     rsFit(data, doplot = TRUE)
> I am getting the R/S plot for that time series with default plot title,
> font size. However, I want to  change the axis size, font size etc of this
> plot, which I am unable to do as there is no formal argument here. Can
> anyone suggest something about this? How can I change the font size, axis
> size etc here?
> Thanks.
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Fri Jan 26 04:48:37 2018
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 25 Jan 2018 22:48:37 -0500
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <CAO2XSvcAuPnYWtdCHfOPm__9vtoyrY45QEMjfw9fraFWUjt3sw@mail.gmail.com>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
 <CAP01uRk0_s+QxwDigbkd+U2eKmvDvTB6a763+_UgNOJknvsTvA@mail.gmail.com>
 <CAO2XSvcAuPnYWtdCHfOPm__9vtoyrY45QEMjfw9fraFWUjt3sw@mail.gmail.com>
Message-ID: <CAP01uRno8Pz5qMZO=eAUa1LyCY4X8=fBiAU8Gm4YiLnuZLChAQ@mail.gmail.com>

Can you clarify what the nature of the security restriction is?

If you can't run the R installer then how it is that you could run R?
That would still involve running an external exe even if it came
in a zip file.

Could it be that the restriction is not on running exe files but on
downloading them?

If that is it then there are obvious workarounds (rename it not
to have an exe externsion or zip it using another machine,
upload to the cloud and download onto the restricted machine)
but it might be safer to just ask the powers that be to download it
for you.  You probably don't need a new version of R more than
once a year.


On Thu, Jan 25, 2018 at 3:04 PM, Juan Manuel Truppia
<jmtruppia at gmail.com> wrote:
> What is wrong with you guys? I asked for a zip, like R Studio has for
> example. Totally clear.
> I cant execute exes. But I can unzip files.
> Thanks Gabor, I had that in mind, but can't execute the exe due to security
> restrictions.
> Geez, really, treating people who ask questions this way just makes you
> don't want to ask a single one.
>
>
> On Thu, Jan 25, 2018, 11:19 Gabor Grothendieck <ggrothendieck at gmail.com>
> wrote:
>>
>> I believe that the ordinary Windows installer for R can produce a
>> portable result by choosing the appropriate configuration options from the
>> offered screens when you run the installer  Be sure to enter the desired
>> path in the Select Destination Location screen, choose Yes on the
>> Startup options screen and ensure that all boxes are unchecked on the
>> Select additional tasks screen.
>>
>> On Wed, Jan 24, 2018 at 10:11 PM, Juan Manuel Truppia
>> <jmtruppia at gmail.com> wrote:
>> > I read a message from 2009 or 2010 where it mentioned the availability
>> > of R
>> > for Windows in a zip file, no installation required. It would be very
>> > useful for me. Is this still available somewhere?
>> >
>> > Thanks
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Statistics & Software Consulting
>> GKX Group, GKX Associates Inc.
>> tel: 1-877-GKX-GROUP
>> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From syen04 at gmail.com  Fri Jan 26 09:27:55 2018
From: syen04 at gmail.com (Steven Yen)
Date: Fri, 26 Jan 2018 16:27:55 +0800
Subject: [R] Problem saving .RData file with save.image
In-Reply-To: <58e5630e-3274-b4ac-6e76-e4e8a46713d4@gmail.com>
References: <f1de81cd-9907-1782-2801-19556db2b91b@gmail.com>
 <58e5630e-3274-b4ac-6e76-e4e8a46713d4@gmail.com>
Message-ID: <be72c73d-74ab-4945-4e8f-879b8ac910f1@gmail.com>

I am running R-3.0.3 on RStudio 1.1.183. I have recently gotten the following error message while saving an .RData file with the save.image command. I have not had this problem until recently. Help appreciated.

===
Error in save.image("bope1a.RData") :
   image could not be renamed and is left in bope1a.RDataTmp


	[[alternative HTML version deleted]]


From jmtruppia at gmail.com  Fri Jan 26 11:57:34 2018
From: jmtruppia at gmail.com (Juan Manuel Truppia)
Date: Fri, 26 Jan 2018 10:57:34 +0000
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <CAP01uRno8Pz5qMZO=eAUa1LyCY4X8=fBiAU8Gm4YiLnuZLChAQ@mail.gmail.com>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
 <CAP01uRk0_s+QxwDigbkd+U2eKmvDvTB6a763+_UgNOJknvsTvA@mail.gmail.com>
 <CAO2XSvcAuPnYWtdCHfOPm__9vtoyrY45QEMjfw9fraFWUjt3sw@mail.gmail.com>
 <CAP01uRno8Pz5qMZO=eAUa1LyCY4X8=fBiAU8Gm4YiLnuZLChAQ@mail.gmail.com>
Message-ID: <CAO2XSvevsQnYQiWJQo14L7rFoLczqr_1sLa1pDYiwLAn9Mgybw@mail.gmail.com>

Pretty good question Gabor. I can execute R once it is installed (if
someone with rights installs it before) but not the installer. I can
download the installer (with some pain). I know that some installers are
actually compressed files in disguise, but I think this is not the case
with R, right?
I will study the exact nature of the restriction, and get back to you.
Nevertheless, having a installer and a "portable" version is something
pretty common (R Studio, Notepad++ and 7Zip pop to my mind now) and pretty
helpful to deal with security restrictions, so I thought R had one,
somewhere.

On Fri, Jan 26, 2018, 00:49 Gabor Grothendieck <ggrothendieck at gmail.com>
wrote:

> Can you clarify what the nature of the security restriction is?
>
> If you can't run the R installer then how it is that you could run R?
> That would still involve running an external exe even if it came
> in a zip file.
>
> Could it be that the restriction is not on running exe files but on
> downloading them?
>
> If that is it then there are obvious workarounds (rename it not
> to have an exe externsion or zip it using another machine,
> upload to the cloud and download onto the restricted machine)
> but it might be safer to just ask the powers that be to download it
> for you.  You probably don't need a new version of R more than
> once a year.
>
>
> On Thu, Jan 25, 2018 at 3:04 PM, Juan Manuel Truppia
> <jmtruppia at gmail.com> wrote:
> > What is wrong with you guys? I asked for a zip, like R Studio has for
> > example. Totally clear.
> > I cant execute exes. But I can unzip files.
> > Thanks Gabor, I had that in mind, but can't execute the exe due to
> security
> > restrictions.
> > Geez, really, treating people who ask questions this way just makes you
> > don't want to ask a single one.
> >
> >
> > On Thu, Jan 25, 2018, 11:19 Gabor Grothendieck <ggrothendieck at gmail.com>
> > wrote:
> >>
> >> I believe that the ordinary Windows installer for R can produce a
> >> portable result by choosing the appropriate configuration options from
> the
> >> offered screens when you run the installer  Be sure to enter the desired
> >> path in the Select Destination Location screen, choose Yes on the
> >> Startup options screen and ensure that all boxes are unchecked on the
> >> Select additional tasks screen.
> >>
> >> On Wed, Jan 24, 2018 at 10:11 PM, Juan Manuel Truppia
> >> <jmtruppia at gmail.com> wrote:
> >> > I read a message from 2009 or 2010 where it mentioned the availability
> >> > of R
> >> > for Windows in a zip file, no installation required. It would be very
> >> > useful for me. Is this still available somewhere?
> >> >
> >> > Thanks
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >> --
> >> Statistics & Software Consulting
> >> GKX Group, GKX Associates Inc.
> >> tel: 1-877-GKX-GROUP
> >> email: ggrothendieck at gmail.com
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>

	[[alternative HTML version deleted]]


From toth.denes at kogentum.hu  Fri Jan 26 13:45:18 2018
From: toth.denes at kogentum.hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Fri, 26 Jan 2018 13:45:18 +0100
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <CAO2XSvevsQnYQiWJQo14L7rFoLczqr_1sLa1pDYiwLAn9Mgybw@mail.gmail.com>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
 <CAP01uRk0_s+QxwDigbkd+U2eKmvDvTB6a763+_UgNOJknvsTvA@mail.gmail.com>
 <CAO2XSvcAuPnYWtdCHfOPm__9vtoyrY45QEMjfw9fraFWUjt3sw@mail.gmail.com>
 <CAP01uRno8Pz5qMZO=eAUa1LyCY4X8=fBiAU8Gm4YiLnuZLChAQ@mail.gmail.com>
 <CAO2XSvevsQnYQiWJQo14L7rFoLczqr_1sLa1pDYiwLAn9Mgybw@mail.gmail.com>
Message-ID: <b6c8d612-09a0-d1d5-8a2b-f32224ac3bc3@kogentum.hu>

Hi Juan,

you might find this useful: https://sourceforge.net/projects/rportable/

Cheers,
Denes

On 01/26/2018 11:57 AM, Juan Manuel Truppia wrote:
> Pretty good question Gabor. I can execute R once it is installed (if
> someone with rights installs it before) but not the installer. I can
> download the installer (with some pain). I know that some installers are
> actually compressed files in disguise, but I think this is not the case
> with R, right?
> I will study the exact nature of the restriction, and get back to you.
> Nevertheless, having a installer and a "portable" version is something
> pretty common (R Studio, Notepad++ and 7Zip pop to my mind now) and pretty
> helpful to deal with security restrictions, so I thought R had one,
> somewhere.
> 
> On Fri, Jan 26, 2018, 00:49 Gabor Grothendieck <ggrothendieck at gmail.com>
> wrote:
> 
>> Can you clarify what the nature of the security restriction is?
>>
>> If you can't run the R installer then how it is that you could run R?
>> That would still involve running an external exe even if it came
>> in a zip file.
>>
>> Could it be that the restriction is not on running exe files but on
>> downloading them?
>>
>> If that is it then there are obvious workarounds (rename it not
>> to have an exe externsion or zip it using another machine,
>> upload to the cloud and download onto the restricted machine)
>> but it might be safer to just ask the powers that be to download it
>> for you.  You probably don't need a new version of R more than
>> once a year.
>>
>>
>> On Thu, Jan 25, 2018 at 3:04 PM, Juan Manuel Truppia
>> <jmtruppia at gmail.com> wrote:
>>> What is wrong with you guys? I asked for a zip, like R Studio has for
>>> example. Totally clear.
>>> I cant execute exes. But I can unzip files.
>>> Thanks Gabor, I had that in mind, but can't execute the exe due to
>> security
>>> restrictions.
>>> Geez, really, treating people who ask questions this way just makes you
>>> don't want to ask a single one.
>>>
>>>
>>> On Thu, Jan 25, 2018, 11:19 Gabor Grothendieck <ggrothendieck at gmail.com>
>>> wrote:
>>>>
>>>> I believe that the ordinary Windows installer for R can produce a
>>>> portable result by choosing the appropriate configuration options from
>> the
>>>> offered screens when you run the installer  Be sure to enter the desired
>>>> path in the Select Destination Location screen, choose Yes on the
>>>> Startup options screen and ensure that all boxes are unchecked on the
>>>> Select additional tasks screen.
>>>>
>>>> On Wed, Jan 24, 2018 at 10:11 PM, Juan Manuel Truppia
>>>> <jmtruppia at gmail.com> wrote:
>>>>> I read a message from 2009 or 2010 where it mentioned the availability
>>>>> of R
>>>>> for Windows in a zip file, no installation required. It would be very
>>>>> useful for me. Is this still available somewhere?
>>>>>
>>>>> Thanks
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>
>>>> --
>>>> Statistics & Software Consulting
>>>> GKX Group, GKX Associates Inc.
>>>> tel: 1-877-GKX-GROUP
>>>> email: ggrothendieck at gmail.com
>>
>>
>>
>> --
>> Statistics & Software Consulting
>> GKX Group, GKX Associates Inc.
>> tel: 1-877-GKX-GROUP
>> email: ggrothendieck at gmail.com
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Fri Jan 26 15:26:07 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 26 Jan 2018 06:26:07 -0800
Subject: [R] Problem saving .RData file with save.image
In-Reply-To: <be72c73d-74ab-4945-4e8f-879b8ac910f1@gmail.com>
References: <f1de81cd-9907-1782-2801-19556db2b91b@gmail.com>
 <58e5630e-3274-b4ac-6e76-e4e8a46713d4@gmail.com>
 <be72c73d-74ab-4945-4e8f-879b8ac910f1@gmail.com>
Message-ID: <1337CC88-0703-43D6-8117-EF4E27E9D0E2@dcn.davis.ca.us>

Google is your friend (e.g. [1]). Gist of story is that that an existing file of that name is being "protected" by the operating system and you need to use filesystem utilities or reboot your machine to release the existing file from this condition. 

[1] https://stat.ethz.ch/pipermail/r-help/2002-April/020169.html
-- 
Sent from my phone. Please excuse my brevity.

On January 26, 2018 12:27:55 AM PST, Steven Yen <syen04 at gmail.com> wrote:
>I am running R-3.0.3 on RStudio 1.1.183. I have recently gotten the
>following error message while saving an .RData file with the save.image
>command. I have not had this problem until recently. Help appreciated.
>
>===
>Error in save.image("bope1a.RData") :
>   image could not be renamed and is left in bope1a.RDataTmp
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri Jan 26 15:29:35 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 26 Jan 2018 09:29:35 -0500
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <CAO2XSvevsQnYQiWJQo14L7rFoLczqr_1sLa1pDYiwLAn9Mgybw@mail.gmail.com>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
 <CAP01uRk0_s+QxwDigbkd+U2eKmvDvTB6a763+_UgNOJknvsTvA@mail.gmail.com>
 <CAO2XSvcAuPnYWtdCHfOPm__9vtoyrY45QEMjfw9fraFWUjt3sw@mail.gmail.com>
 <CAP01uRno8Pz5qMZO=eAUa1LyCY4X8=fBiAU8Gm4YiLnuZLChAQ@mail.gmail.com>
 <CAO2XSvevsQnYQiWJQo14L7rFoLczqr_1sLa1pDYiwLAn9Mgybw@mail.gmail.com>
Message-ID: <9967be6c-567d-423e-cf25-d243e1415178@gmail.com>

On 26/01/2018 5:57 AM, Juan Manuel Truppia wrote:
> Pretty good question Gabor. I can execute R once it is installed (if
> someone with rights installs it before) but not the installer. I can
> download the installer (with some pain). I know that some installers are
> actually compressed files in disguise, but I think this is not the case
> with R, right?
> I will study the exact nature of the restriction, and get back to you.
> Nevertheless, having a installer and a "portable" version is something
> pretty common (R Studio, Notepad++ and 7Zip pop to my mind now) and pretty
> helpful to deal with security restrictions, so I thought R had one,
> somewhere.

I don't know what's involved in putting together such a thing, but my 
guess is that official R sources will not do so.  Generally speaking, R 
doesn't support efforts to circumvent security safeguards.

When I was a member of R Core, we used to get enough trouble from false 
positive warnings from virus checkers.  If R Core started actively 
trying to support system abuse, it would cause far more trouble for them.

Of course, since R is open source, there's nothing to stop some third 
party from putting together a way to run R despite security policies 
that forbid it.  And nothing to stop them from inserting their own 
malicious code into the .zip file.

Duncan Murdoch

> 
> On Fri, Jan 26, 2018, 00:49 Gabor Grothendieck <ggrothendieck at gmail.com>
> wrote:
> 
>> Can you clarify what the nature of the security restriction is?
>>
>> If you can't run the R installer then how it is that you could run R?
>> That would still involve running an external exe even if it came
>> in a zip file.
>>
>> Could it be that the restriction is not on running exe files but on
>> downloading them?
>>
>> If that is it then there are obvious workarounds (rename it not
>> to have an exe externsion or zip it using another machine,
>> upload to the cloud and download onto the restricted machine)
>> but it might be safer to just ask the powers that be to download it
>> for you.  You probably don't need a new version of R more than
>> once a year.
>>
>>
>> On Thu, Jan 25, 2018 at 3:04 PM, Juan Manuel Truppia
>> <jmtruppia at gmail.com> wrote:
>>> What is wrong with you guys? I asked for a zip, like R Studio has for
>>> example. Totally clear.
>>> I cant execute exes. But I can unzip files.
>>> Thanks Gabor, I had that in mind, but can't execute the exe due to
>> security
>>> restrictions.
>>> Geez, really, treating people who ask questions this way just makes you
>>> don't want to ask a single one.
>>>
>>>
>>> On Thu, Jan 25, 2018, 11:19 Gabor Grothendieck <ggrothendieck at gmail.com>
>>> wrote:
>>>>
>>>> I believe that the ordinary Windows installer for R can produce a
>>>> portable result by choosing the appropriate configuration options from
>> the
>>>> offered screens when you run the installer  Be sure to enter the desired
>>>> path in the Select Destination Location screen, choose Yes on the
>>>> Startup options screen and ensure that all boxes are unchecked on the
>>>> Select additional tasks screen.
>>>>
>>>> On Wed, Jan 24, 2018 at 10:11 PM, Juan Manuel Truppia
>>>> <jmtruppia at gmail.com> wrote:
>>>>> I read a message from 2009 or 2010 where it mentioned the availability
>>>>> of R
>>>>> for Windows in a zip file, no installation required. It would be very
>>>>> useful for me. Is this still available somewhere?
>>>>>
>>>>> Thanks
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>
>>>> --
>>>> Statistics & Software Consulting
>>>> GKX Group, GKX Associates Inc.
>>>> tel: 1-877-GKX-GROUP
>>>> email: ggrothendieck at gmail.com
>>
>>
>>
>> --
>> Statistics & Software Consulting
>> GKX Group, GKX Associates Inc.
>> tel: 1-877-GKX-GROUP
>> email: ggrothendieck at gmail.com
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sorenh at math.aau.dk  Fri Jan 26 17:08:13 2018
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Fri, 26 Jan 2018 16:08:13 +0000
Subject: [R] When was the script editor introduced in Rgui for windows?
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C301065E1BBD@AD-EXCHMBX3-3.aau.dk>

Dear all,

Can anyone please tell me when the script editor was introduced in the Rgui on windows? (And/or where to look for a listing of changes throughout history).

Best regards
S?ren


From murdoch.duncan at gmail.com  Fri Jan 26 17:36:09 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 26 Jan 2018 11:36:09 -0500
Subject: [R] When was the script editor introduced in Rgui for windows?
In-Reply-To: <7E8037094A0C2146AA3E6F94DAE621C301065E1BBD@AD-EXCHMBX3-3.aau.dk>
References: <7E8037094A0C2146AA3E6F94DAE621C301065E1BBD@AD-EXCHMBX3-3.aau.dk>
Message-ID: <3f8abda4-301e-0eb9-d18f-32b84a7911b2@gmail.com>

On 26/01/2018 11:08 AM, S?ren H?jsgaard wrote:
> Dear all,
> 
> Can anyone please tell me when the script editor was introduced in the Rgui on windows? (And/or where to look for a listing of changes throughout history).

There are two places to look for changes:  the NEWS* files, and the 
Subversion change log.  You can find the former if you run

help.start()

Only the current NEWS file has a main link, but there are links to the 
older ones at the bottom of it.

The script editor is really old.  It first appeared in R 2.0.0, with an 
entry in the Windows-specific news file CHANGES.   (The CHANGES file is 
only linked into the help system on Windows.  Since R 2.15.0 Windows 
changes are announced in the same file(s) as other changes.)  The 
CHANGES entry was

- Added Rgui script editor by Chris Jackson.

This happened in svn revision 28991, which I committed in April, 2004.

Duncan Murdoch


From ss5505 at cumc.columbia.edu  Fri Jan 26 18:09:13 2018
From: ss5505 at cumc.columbia.edu (Sariya, Sanjeev)
Date: Fri, 26 Jan 2018 17:09:13 +0000
Subject: [R] How to run mixed model with related independent variables
Message-ID: <BY1PR0201MB1000043442C6E74FAF171FDC81E00@BY1PR0201MB1000.namprd02.prod.outlook.com>

I've data that look like:

Outcome             V1_AA  V1_EU  V1_NA  V2_AA  V2_EU  V2_NA
0              0.046     1.001     0.954     0.045     1.001     0.954
0              0.007     1              0.993     0.007     1              0.993
1              1.774     0.217     0.009     1.774     0.217     0.009
1              0.004     1.996     0              0.004     1.996     0
1              1.001     0.997     0.002     1.001     0.997     0.002
0              0.94        0.998     0.061     0.94        0.998     0.061
0              0.587     1.407     0.006     0.587     1.408     0.006
1              0.019     1.978     0.003     0.018     1.979     0.003

Column Outcome is dependent variable. It's dichotomous either 0 or 1.
Column 1st, 2nd, 3rd are three components of V1, similarly next three for V2. Sum of V1_AA, V1_EU and V1_NA will be two at each row. Similarly for V2 variable's components.
Here the three predictors (I'm referring as component) are related. If AA is higher then, NA and EU will be lesser.

I cannot simply use multivariate regression as:

Y ~ V1_AA + V1_EU + V1_NA

How do I proceed with these data?

Thanks!


	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Fri Jan 26 18:51:33 2018
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 26 Jan 2018 17:51:33 +0000
Subject: [R] Help in Plotting in "fArma" Package
In-Reply-To: <AB67EF65-5715-4B33-821B-B459CA3374A0@comcast.net>
References: <CAC1L6m00PadoB4wmnSYFevoPVh0HtB11_RQGn3t6wz4eHxeg3g@mail.gmail.com>
 <AB67EF65-5715-4B33-821B-B459CA3374A0@comcast.net>
Message-ID: <0A33D8CA-975C-45F5-9C26-5D6B7866D794@llnl.gov>

What Dave said, plus here's a hint. Try this example (which uses base graphics):

plot(1:5)
plot(1:5, cex.lab=2)

Then look at the help page for par
   help('par')
or
   ?par
to search for other graphics parameters (base graphics) you can use to change various things.

Success will depend, as Dave indicated, on how the package author handled the plotting options in rsFit().

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 
?On 1/25/18, 5:56 PM, "R-help on behalf of David Winsemius" <r-help-bounces at r-project.org on behalf of dwinsemius at comcast.net> wrote:

    The documentation say that additional arguments will be passed. I suspect this will be a base graphics plot. You should look at the code of plot.rsfit to determine which arguments get processed. 
    
    Sent from my iPhone
    
    > On Jan 25, 2018, at 10:30 AM, Moyukh Laha <laha.moyukh at gmail.com> wrote:
    > 
    > Hello,
    >        I am new to R and for some of my research work I am using 'fArma'
    > package to estimate the Hurst parameter of a time series.
    >        When I am ding the following command :
    >                                     rsFit(data, doplot = TRUE)
    > I am getting the R/S plot for that time series with default plot title,
    > font size. However, I want to  change the axis size, font size etc of this
    > plot, which I am unable to do as there is no formal argument here. Can
    > anyone suggest something about this? How can I change the font size, axis
    > size etc here?
    > Thanks.
    > 
    >    [[alternative HTML version deleted]]
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter.4567 at gmail.com  Fri Jan 26 18:53:04 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 26 Jan 2018 09:53:04 -0800
Subject: [R] How to run mixed model with related independent variables
In-Reply-To: <BY1PR0201MB1000043442C6E74FAF171FDC81E00@BY1PR0201MB1000.namprd02.prod.outlook.com>
References: <BY1PR0201MB1000043442C6E74FAF171FDC81E00@BY1PR0201MB1000.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbQhhu=8JLVcj_UCWreEXFpqXTi3Zmy50h57XmBdAB82Hw@mail.gmail.com>

Wrong list.

R-help is for help on R programming and related functionality, not
statistics, though the intersection is sometimes nonempty.

However, you appear to be seeking what might be described as a statistics
tutorial. You might try a statistics list like stats.stackexchange.com or
just do some studying on your own. I believe you need to learn about
"generalized linear models" which is implemented in the glm() function in
the stats package (as well as others, probably). However, you will need to
gain some background to use it properly, and this is not the venue for that.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jan 26, 2018 at 9:09 AM, Sariya, Sanjeev <ss5505 at cumc.columbia.edu>
wrote:

> I've data that look like:
>
> Outcome             V1_AA  V1_EU  V1_NA  V2_AA  V2_EU  V2_NA
> 0              0.046     1.001     0.954     0.045     1.001     0.954
> 0              0.007     1              0.993     0.007     1
> 0.993
> 1              1.774     0.217     0.009     1.774     0.217     0.009
> 1              0.004     1.996     0              0.004     1.996     0
> 1              1.001     0.997     0.002     1.001     0.997     0.002
> 0              0.94        0.998     0.061     0.94        0.998     0.061
> 0              0.587     1.407     0.006     0.587     1.408     0.006
> 1              0.019     1.978     0.003     0.018     1.979     0.003
>
> Column Outcome is dependent variable. It's dichotomous either 0 or 1.
> Column 1st, 2nd, 3rd are three components of V1, similarly next three for
> V2. Sum of V1_AA, V1_EU and V1_NA will be two at each row. Similarly for V2
> variable's components.
> Here the three predictors (I'm referring as component) are related. If AA
> is higher then, NA and EU will be lesser.
>
> I cannot simply use multivariate regression as:
>
> Y ~ V1_AA + V1_EU + V1_NA
>
> How do I proceed with these data?
>
> Thanks!
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Jan 26 19:04:16 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Jan 2018 10:04:16 -0800
Subject: [R] Help in Plotting in "fArma" Package
In-Reply-To: <0A33D8CA-975C-45F5-9C26-5D6B7866D794@llnl.gov>
References: <CAC1L6m00PadoB4wmnSYFevoPVh0HtB11_RQGn3t6wz4eHxeg3g@mail.gmail.com>
 <AB67EF65-5715-4B33-821B-B459CA3374A0@comcast.net>
 <0A33D8CA-975C-45F5-9C26-5D6B7866D794@llnl.gov>
Message-ID: <6F38823D-F942-4E8D-8EAE-D9F40F43701B@comcast.net>


> On Jan 26, 2018, at 9:51 AM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> 
> What Dave said, plus here's a hint. Try this example (which uses base graphics):
> 
> plot(1:5)
> plot(1:5, cex.lab=2)
> 
> Then look at the help page for par
>   help('par')
> or
>   ?par
> to search for other graphics parameters (base graphics) you can use to change various things.
> 
> Success will depend, as Dave indicated, on how the package author handled the plotting options in rsFit().

Actually it's an S4 method:

showMethods("show", classes="fHURST", includeDefs=TRUE)
Function: show (package methods)
object="fHURST"
function (object) 
{
    x = object
    doplot = TRUE
    cat("\nTitle:\n ", x at title, "\n", sep = "")
    cat("\nCall:\n ")
    cat(paste(deparse(x at call), sep = "\n", collapse = "\n"), 
        "\n", sep = "")
... snipped

IAnd not easily susceptible to throwing base graphics parameters at ti since it's all hard-coded. I've suggested to the OP that hacking the show method is an accessible option.

-- 
David.

> 
> -Don
> 
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
> 
> 
> ?On 1/25/18, 5:56 PM, "R-help on behalf of David Winsemius" <r-help-bounces at r-project.org on behalf of dwinsemius at comcast.net> wrote:
> 
>    The documentation say that additional arguments will be passed. I suspect this will be a base graphics plot. You should look at the code of plot.rsfit to determine which arguments get processed. 
> 
>    Sent from my iPhone
> 
>> On Jan 25, 2018, at 10:30 AM, Moyukh Laha <laha.moyukh at gmail.com> wrote:
>> 
>> Hello,
>>       I am new to R and for some of my research work I am using 'fArma'
>> package to estimate the Hurst parameter of a time series.
>>       When I am ding the following command :
>>                                    rsFit(data, doplot = TRUE)
>> I am getting the R/S plot for that time series with default plot title,
>> font size. However, I want to  change the axis size, font size etc of this
>> plot, which I am unable to do as there is no formal argument here. Can
>> anyone suggest something about this? How can I change the font size, axis
>> size etc here?
>> Thanks.
>> 
>>   [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
>    ______________________________________________
>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    https://stat.ethz.ch/mailman/listinfo/r-help
>    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>    and provide commented, minimal, self-contained, reproducible code.
> 
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From tsreprpackage at gmail.com  Fri Jan 26 15:40:56 2018
From: tsreprpackage at gmail.com (Peter Laurinec)
Date: Fri, 26 Jan 2018 15:40:56 +0100
Subject: [R] [R-pkgs] new package TSrepr
Message-ID: <CADOV6XG_p=++wHSejHkPRmns=k3T8uhyHWEPyACnZ4UGJ6gwjQ@mail.gmail.com>

Dear useRs,

I'm happy to announce a new package that has recently appeared on CRAN,
called "TSrepr" (version 1.0.0: https://CRAN.R-project.org/package=TSrepr).

TSrepr is an R package for fast time series representations computations.

Introduction to usage of TSrepr package can be found in this tutorial:
https://cran.r-project.org/web/packages/TSrepr/vignettes/TSrepr_representations_of_time_series.html

Use case with clustering of time series representations can be found here:
https://cran.r-project.org/web/packages/TSrepr/vignettes/TSrepr_representations_use_case.html

Examples how to extend TSrepr functionalities are here:
https://cran.r-project.org/web/packages/TSrepr/vignettes/TSrepr_extentions.html

Any suggestions and comments are welcome.

Best regards,
Peter Laurinec
Email: tsreprpackage at gmail.com

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From sojinkim92 at gmail.com  Fri Jan 26 23:56:16 2018
From: sojinkim92 at gmail.com (Sojin Kim)
Date: Fri, 26 Jan 2018 14:56:16 -0800
Subject: [R] plm empty model error
Message-ID: <CAC100NYEnsnz7smVhG77440ECo9UQaG3rS0z=e7oKqV3aGHWRw@mail.gmail.com>

Hi,

I am trying to estimate a two-way model with both individual and time fixed
effects. I am using plm with "twoways" specification.

plm(as.integer(yvar) ~ xvar, index = c("id", "time"), model="within",
data=dataset, effect = "twoways")

But I get keep getting the following message and I don't know what to do
about it, because I don't think anything is wrong with my indices (but
please correct me if I'm wrong on this!). : Error in plm.fit(formula, data,
model, effect, random.method, random.models,  :
  empty model

The data is attached in the email.

Thank you so much in advance for your help.

From jwd at surewest.net  Sat Jan 27 02:41:50 2018
From: jwd at surewest.net (John)
Date: Fri, 26 Jan 2018 17:41:50 -0800
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <CAO2XSvcAuPnYWtdCHfOPm__9vtoyrY45QEMjfw9fraFWUjt3sw@mail.gmail.com>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
 <CAP01uRk0_s+QxwDigbkd+U2eKmvDvTB6a763+_UgNOJknvsTvA@mail.gmail.com>
 <CAO2XSvcAuPnYWtdCHfOPm__9vtoyrY45QEMjfw9fraFWUjt3sw@mail.gmail.com>
Message-ID: <20180126174150.289cc74b@Draco.localdomain>

On Thu, 25 Jan 2018 20:04:33 +0000
Juan Manuel Truppia <jmtruppia at gmail.com> wrote:

> What is wrong with you guys? I asked for a zip, like R Studio has for
> example. Totally clear.
> I cant execute exes. But I can unzip files.
> Thanks Gabor, I had that in mind, but can't execute the exe due to
> security restrictions.
> Geez, really, treating people who ask questions this way just makes
> you don't want to ask a single one.
> 
Your concept of "totally clear" lacks a good deal of clarity.  You
pretty much ignored providing any indication of what your problem is,
how you expect to run R if you can't run an executable file, or just
about ANY useful information that could allow someone to help you
other than something you might have read seven or eight years ago. 

At a wild guess you can't write to the hard drive of what ever system
you are hoping to use and do not have rights to execute programs on
that system.  A way around that would be to run your software from a
thumb drive or similar external device.  So you might look at R
Portable (https://sourceforge.net/projects/rportable/) which employs
the PortableApps framework, but with such a sweeping lack of
information from you, don't congratulate yourself if you get a helpful
answer.  It wasn't your fault.


From bgunter.4567 at gmail.com  Sat Jan 27 03:29:39 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 26 Jan 2018 18:29:39 -0800
Subject: [R] plm empty model error
In-Reply-To: <CAC100NYEnsnz7smVhG77440ECo9UQaG3rS0z=e7oKqV3aGHWRw@mail.gmail.com>
References: <CAC100NYEnsnz7smVhG77440ECo9UQaG3rS0z=e7oKqV3aGHWRw@mail.gmail.com>
Message-ID: <CAGxFJbRuspe2r2vMmbs8yaGp9YiqXom0viZWoUp6ikF2hWZNvw@mail.gmail.com>

**Please read **and follow**  the posting guide linked below.** Your data
attachment did not make it, as most non-text files are stripped by the mail
server to avoid probems.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jan 26, 2018 at 2:56 PM, Sojin Kim <sojinkim92 at gmail.com> wrote:

> Hi,
>
> I am trying to estimate a two-way model with both individual and time fixed
> effects. I am using plm with "twoways" specification.
>
> plm(as.integer(yvar) ~ xvar, index = c("id", "time"), model="within",
> data=dataset, effect = "twoways")
>
> But I get keep getting the following message and I don't know what to do
> about it, because I don't think anything is wrong with my indices (but
> please correct me if I'm wrong on this!). : Error in plm.fit(formula, data,
> model, effect, random.method, random.models,  :
>   empty model
>
> The data is attached in the email.
>
> Thank you so much in advance for your help.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sojinkim92 at gmail.com  Sat Jan 27 06:48:58 2018
From: sojinkim92 at gmail.com (Sojin Kim)
Date: Fri, 26 Jan 2018 21:48:58 -0800
Subject: [R] plm empty model error (data is linked)
Message-ID: <CAC100NaBVXoNmyBUwJKdBM_D=ZDOYh1-7-ND0MT43EZmqSmhXA@mail.gmail.com>

Hi,

I am trying to estimate a two-way model with both individual and time fixed
effects. I am using plm with "twoways" specification.

plm(as.integer(yvar) ~ xvar, index = c("id", "time"), model="within",
data=dataset, effect = "twoways")

But I get keep getting the following message and I don't know what to do
about it, because I don't think anything is wrong with my indices (but
please correct me if I'm wrong on this!). : Error in plm.fit(formula, data,
model, effect, random.method, random.models,  :
  empty model

Here's the data:
https://drive.google.com/file/d/1p-LrZ3GdVhsat6xFCJ5FmmhUL9SvFAG5/view?usp=sharing

Thank you so much in advance for your help.

	[[alternative HTML version deleted]]


From susan.elias at maine.edu  Sat Jan 27 03:19:53 2018
From: susan.elias at maine.edu (Susan Elias)
Date: Fri, 26 Jan 2018 21:19:53 -0500
Subject: [R] GAM: mismatch between nb/polys supplied area names and data
	area names
Message-ID: <CAKXsTQNAoFWS64aKg4DDHbeqZ+O67UzkdzUaKR9wi2a+oNcpqg@mail.gmail.com>

Hello, I am new to R and running R version 3.4.3 (2017-11-30),
x86_64-apple-darwin15.6.0 (64-bit), macOS High Sierra 10.13.2.

I am running the gam package to model disease incidence (negative binomial
distribution) as a function of two covariates, and wish to incorporate
spatial correlation among areal neighbors, n = 50 polygons, identified by
"id".  For data observed over discrete spatial units, a Markov random field
can be used through the GAM syntax:
s(id, bs="mrf", xt = list(nb = nb), where the latter nb refers to an object
with a neighbor list.

The error is "Error in smooth.construct.mrf.smooth.spec(object, dk$data,
dk$knots) :
mismatch between nb/polys supplied area names and data area names".

I have read the documentation, studied the function, and looked at the
traceback, and have been careful to use matching variable types for area
names in nb and data, but have not been successful.

Any advice would be appreciated. Below are code and a data sample.

Thank you,

Susan

code:

#read in data; from a numeric polygon "IDENTIFIER" create a new polygon
"id" that is a factor
datawide <- read_csv("~/Long/ALLWIDEDATA.csv")
datawide <- transform(datawide, id = factor(formatC(IDENTIFIER, width = 2,
flag = "0")))
#NB: the new area ids are: "01", "02",..."50"

#read in the shapefile and create the neighborhood object nb,
#names(nb) must correspond to the levels of the covariate of the smooth
(i.e. the area labels)
shape<-readOGR(dsn="~/Long/MENHShape",layer=("MENHShape2"))
nb <- poly2nb(shape, queen = TRUE, snap=100, row.names=datawide$id)
names(nb) <- attr(nb, "region.id")

#run GAM spatial neighbors plus covariates
gamspcov <- gam(y2008_2014rate~s(id, bs="mrf", xt = list(nb = nb), k=20) +
s(deermi2) + s(t14), family=nb( ), data=datawide, method="MLE")

#ERROR MESSSAGE
#Error in smooth.construct.mrf.smooth.spec(object, dk$data, dk$knots) :
#  mismatch between nb/polys supplied area names and data area names
#In addition: Warning message:
#  In if (all.equal(sort(a.name), sort(levels(k))) != TRUE) stop("mismatch
between nb/polys supplied area names and data area names") :
#  the condition has length > 1 and only the first element will be used

data sample:

IDENTIFIER (num) id (factor) caserate (num) deer (num) temp (num) <more
columns>
1 01 0.0 2.0 -9.0 <etc.>
2 02 3.1 8.5 -7.0 <etc.>
...
50 50 200.0 25.0 -3 <etc.>

	[[alternative HTML version deleted]]


From mhardy at ara.com  Sat Jan 27 05:54:48 2018
From: mhardy at ara.com (Marsh Hardy ARA/RISK)
Date: Sat, 27 Jan 2018 04:54:48 +0000
Subject: [R] Newbie wants to compare 2 huge RDSs row by row.
In-Reply-To: <087A60AB6499DB4F98295F09BEE7387FBED825FD@colo-mail-2.exchange2.ara.wan>
References: <1517028086547-0.post@n4.nabble.com>,
 <087A60AB6499DB4F98295F09BEE7387FBED825FD@colo-mail-2.exchange2.ara.wan>
Message-ID: <087A60AB6499DB4F98295F09BEE7387FBED8266A@colo-mail-2.exchange2.ara.wan>

Each RDS is 40 MBs. What's a slick code to compare them row by row, IDing row numbers with mismatches?

Thanks in advance.

//


From ericjberger at gmail.com  Sat Jan 27 08:18:20 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Sat, 27 Jan 2018 09:18:20 +0200
Subject: [R] Newbie wants to compare 2 huge RDSs row by row.
In-Reply-To: <087A60AB6499DB4F98295F09BEE7387FBED8266A@colo-mail-2.exchange2.ara.wan>
References: <1517028086547-0.post@n4.nabble.com>
 <087A60AB6499DB4F98295F09BEE7387FBED825FD@colo-mail-2.exchange2.ara.wan>
 <087A60AB6499DB4F98295F09BEE7387FBED8266A@colo-mail-2.exchange2.ara.wan>
Message-ID: <CAGgJW75hTB3kRgPOujo_Gn61_P52_phxBRHN6xg+YBksN7G2rQ@mail.gmail.com>

Hi Marsh,
An RDS is not a data structure such as a data.frame. It can be anything.
For example if I want to save my objects a, b, c I could do:
> saveRDS( list(a,b,c,), file="tmp.RDS")
Then read them back later with
> myList <- readRDS( "tmp.RDS" )

Do you have additional information about your "RDSs" ?

Eric


On Sat, Jan 27, 2018 at 6:54 AM, Marsh Hardy ARA/RISK <mhardy at ara.com>
wrote:

> Each RDS is 40 MBs. What's a slick code to compare them row by row, IDing
> row numbers with mismatches?
>
> Thanks in advance.
>
> //
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Sat Jan 27 16:00:19 2018
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Sat, 27 Jan 2018 15:00:19 +0000
Subject: [R] Newbie wants to compare 2 huge RDSs row by row.
In-Reply-To: <CAGgJW75hTB3kRgPOujo_Gn61_P52_phxBRHN6xg+YBksN7G2rQ@mail.gmail.com>
References: <1517028086547-0.post@n4.nabble.com>
 <087A60AB6499DB4F98295F09BEE7387FBED825FD@colo-mail-2.exchange2.ara.wan>
 <087A60AB6499DB4F98295F09BEE7387FBED8266A@colo-mail-2.exchange2.ara.wan>
 <CAGgJW75hTB3kRgPOujo_Gn61_P52_phxBRHN6xg+YBksN7G2rQ@mail.gmail.com>
Message-ID: <CAKVAULMet25ULAn0yxc-8_FOz5tbqAZYFykvO4Y+v4fqpjnWtQ@mail.gmail.com>

Also, it will be easier to provide helpful information if you'd describe
what in your data you want to compare and what you hope to get out of the
comparison.

Best wishes,
Ulrik

Eric Berger <ericjberger at gmail.com> schrieb am Sa., 27. Jan. 2018, 08:18:

> Hi Marsh,
> An RDS is not a data structure such as a data.frame. It can be anything.
> For example if I want to save my objects a, b, c I could do:
> > saveRDS( list(a,b,c,), file="tmp.RDS")
> Then read them back later with
> > myList <- readRDS( "tmp.RDS" )
>
> Do you have additional information about your "RDSs" ?
>
> Eric
>
>
> On Sat, Jan 27, 2018 at 6:54 AM, Marsh Hardy ARA/RISK <mhardy at ara.com>
> wrote:
>
> > Each RDS is 40 MBs. What's a slick code to compare them row by row, IDing
> > row numbers with mismatches?
> >
> > Thanks in advance.
> >
> > //
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From laha.moyukh at gmail.com  Sat Jan 27 15:19:16 2018
From: laha.moyukh at gmail.com (Moyukh Laha)
Date: Sat, 27 Jan 2018 19:49:16 +0530
Subject: [R] Help in Plotting in "fArma" Package
In-Reply-To: <6F38823D-F942-4E8D-8EAE-D9F40F43701B@comcast.net>
References: <CAC1L6m00PadoB4wmnSYFevoPVh0HtB11_RQGn3t6wz4eHxeg3g@mail.gmail.com>
 <AB67EF65-5715-4B33-821B-B459CA3374A0@comcast.net>
 <0A33D8CA-975C-45F5-9C26-5D6B7866D794@llnl.gov>
 <6F38823D-F942-4E8D-8EAE-D9F40F43701B@comcast.net>
Message-ID: <CAC1L6m07krdBHZNLwFQboem=A9=gP77zM_=HF3BJnCpbJQXs=g@mail.gmail.com>

Thank you very much. Will try this.

On Fri, Jan 26, 2018 at 11:34 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Jan 26, 2018, at 9:51 AM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> >
> > What Dave said, plus here's a hint. Try this example (which uses base
> graphics):
> >
> > plot(1:5)
> > plot(1:5, cex.lab=2)
> >
> > Then look at the help page for par
> >   help('par')
> > or
> >   ?par
> > to search for other graphics parameters (base graphics) you can use to
> change various things.
> >
> > Success will depend, as Dave indicated, on how the package author
> handled the plotting options in rsFit().
>
> Actually it's an S4 method:
>
> showMethods("show", classes="fHURST", includeDefs=TRUE)
> Function: show (package methods)
> object="fHURST"
> function (object)
> {
>     x = object
>     doplot = TRUE
>     cat("\nTitle:\n ", x at title, "\n", sep = "")
>     cat("\nCall:\n ")
>     cat(paste(deparse(x at call), sep = "\n", collapse = "\n"),
>         "\n", sep = "")
> ... snipped
>
> IAnd not easily susceptible to throwing base graphics parameters at ti
> since it's all hard-coded. I've suggested to the OP that hacking the show
> method is an accessible option.
>
> --
> David.
>
> >
> > -Don
> >
> > --
> > Don MacQueen
> > Lawrence Livermore National Laboratory
> > 7000 East Ave., L-627
> > Livermore, CA 94550
> > 925-423-1062
> > Lab cell 925-724-7509
> >
> >
> > ?On 1/25/18, 5:56 PM, "R-help on behalf of David Winsemius" <
> r-help-bounces at r-project.org on behalf of dwinsemius at comcast.net> wrote:
> >
> >    The documentation say that additional arguments will be passed. I
> suspect this will be a base graphics plot. You should look at the code of
> plot.rsfit to determine which arguments get processed.
> >
> >    Sent from my iPhone
> >
> >> On Jan 25, 2018, at 10:30 AM, Moyukh Laha <laha.moyukh at gmail.com>
> wrote:
> >>
> >> Hello,
> >>       I am new to R and for some of my research work I am using 'fArma'
> >> package to estimate the Hurst parameter of a time series.
> >>       When I am ding the following command :
> >>                                    rsFit(data, doplot = TRUE)
> >> I am getting the R/S plot for that time series with default plot title,
> >> font size. However, I want to  change the axis size, font size etc of
> this
> >> plot, which I am unable to do as there is no formal argument here. Can
> >> anyone suggest something about this? How can I change the font size,
> axis
> >> size etc here?
> >> Thanks.
> >>
> >>   [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >    ______________________________________________
> >    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >    https://stat.ethz.ch/mailman/listinfo/r-help
> >    PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >    and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From spencer.graves at effectivedefense.org  Sat Jan 27 18:12:37 2018
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Sat, 27 Jan 2018 11:12:37 -0600
Subject: [R] Searching R Packages
Message-ID: <f911571b-7cc8-19a8-0ae8-379594723ed8@effectivedefense.org>

Hello, All:


	  Might you have time to review the article I recently posted to 
Wikiversity on "Searching R Packages" 
(https://en.wikiversity.org/wiki/Searching_R_Packages)?


	  Please edit this yourself or propose changes in the associated 
"Discuss" page or in an email to this list or to me.


	  My goal in this is to invite readers to turn that article into a 
proposal for improving the search capabilities in R that would 
ultimately be funded by, e.g., The R Foundation.


	  What do you think?


	  Please forward this to anyone you think might be interested.


 ????? Best Wishes,
 ????? Spencer Graves, PhD
 ????? Founder
 ????? EffectiveDefense.org
 ????? 7300 W. 107th St. # 506
 ????? Overland Park, KS 66212


From dwinsemius at comcast.net  Sat Jan 27 19:16:40 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 27 Jan 2018 10:16:40 -0800
Subject: [R] Fortune candidate
Message-ID: <79EB7A03-2EA0-4E43-969D-72B61A6037ED@comcast.net>

John (to a serial querulant):  

    ...but with such a sweeping lack of
information from you, don't congratulate yourself if you get a helpful
answer.  It wasn't your fault.


David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From rshepard at appl-ecosys.com  Sat Jan 27 19:26:05 2018
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Sat, 27 Jan 2018 10:26:05 -0800 (PST)
Subject: [R] Fortune candidate
In-Reply-To: <79EB7A03-2EA0-4E43-969D-72B61A6037ED@comcast.net>
References: <79EB7A03-2EA0-4E43-969D-72B61A6037ED@comcast.net>
Message-ID: <alpine.LNX.2.20.1801271023500.14405@salmo.appl-ecosys.com>

On Sat, 27 Jan 2018, David Winsemius wrote:

> John (to a serial querulant):
>
>    ...but with such a sweeping lack of information from you, don't 
> congratulate yourself if you get a helpful answer. It wasn't your fault.

   Looks like what H.L. Menken or P.G. Wodehouse would have written.

Rich


From mhardy at ara.com  Sat Jan 27 22:18:14 2018
From: mhardy at ara.com (Marsh Hardy ARA/RISK)
Date: Sat, 27 Jan 2018 21:18:14 +0000
Subject: [R] Newbie wants to compare 2 huge RDSs row by row.
In-Reply-To: <CAKVAULMet25ULAn0yxc-8_FOz5tbqAZYFykvO4Y+v4fqpjnWtQ@mail.gmail.com>
References: <1517028086547-0.post@n4.nabble.com>
 <087A60AB6499DB4F98295F09BEE7387FBED825FD@colo-mail-2.exchange2.ara.wan>
 <087A60AB6499DB4F98295F09BEE7387FBED8266A@colo-mail-2.exchange2.ara.wan>
 <CAGgJW75hTB3kRgPOujo_Gn61_P52_phxBRHN6xg+YBksN7G2rQ@mail.gmail.com>,
 <CAKVAULMet25ULAn0yxc-8_FOz5tbqAZYFykvO4Y+v4fqpjnWtQ@mail.gmail.com>
Message-ID: <087A60AB6499DB4F98295F09BEE7387FBED82F1D@colo-mail-2.exchange2.ara.wan>

Hi Guys, I apologize for my rank & utter newness at R.

I used summary() and found about 95 variables, both character and numeric, all with "Length:368842" I assume is the # of records.

I'd like to know the record number (row #?) of any record where the data doesn't match in the 2 files of what should be the same output.

Thanks in advance, M.

//
________________________________________
From: Ulrik Stervbo [ulrik.stervbo at gmail.com]
Sent: Saturday, January 27, 2018 10:00 AM
To: Eric Berger
Cc: Marsh Hardy ARA/RISK; r-help at r-project.org
Subject: Re: [R] Newbie wants to compare 2 huge RDSs row by row.

Also, it will be easier to provide helpful information if you'd describe what in your data you want to compare and what you hope to get out of the comparison.

Best wishes,
Ulrik

Eric Berger <ericjberger at gmail.com<mailto:ericjberger at gmail.com>> schrieb am Sa., 27. Jan. 2018, 08:18:
Hi Marsh,
An RDS is not a data structure such as a data.frame. It can be anything.
For example if I want to save my objects a, b, c I could do:
> saveRDS( list(a,b,c,), file="tmp.RDS")
Then read them back later with
> myList <- readRDS( "tmp.RDS" )

Do you have additional information about your "RDSs" ?

Eric


On Sat, Jan 27, 2018 at 6:54 AM, Marsh Hardy ARA/RISK <mhardy at ara.com<mailto:mhardy at ara.com>>
wrote:

> Each RDS is 40 MBs. What's a slick code to compare them row by row, IDing
> row numbers with mismatches?
>
> Thanks in advance.
>
> //
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Jan 27 22:26:40 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 27 Jan 2018 13:26:40 -0800
Subject: [R] Newbie wants to compare 2 huge RDSs row by row.
In-Reply-To: <087A60AB6499DB4F98295F09BEE7387FBED82F1D@colo-mail-2.exchange2.ara.wan>
References: <1517028086547-0.post@n4.nabble.com>
 <087A60AB6499DB4F98295F09BEE7387FBED825FD@colo-mail-2.exchange2.ara.wan>
 <087A60AB6499DB4F98295F09BEE7387FBED8266A@colo-mail-2.exchange2.ara.wan>
 <CAGgJW75hTB3kRgPOujo_Gn61_P52_phxBRHN6xg+YBksN7G2rQ@mail.gmail.com>
 <CAKVAULMet25ULAn0yxc-8_FOz5tbqAZYFykvO4Y+v4fqpjnWtQ@mail.gmail.com>
 <087A60AB6499DB4F98295F09BEE7387FBED82F1D@colo-mail-2.exchange2.ara.wan>
Message-ID: <C81EE7B2-A936-4FE7-98A1-5F0C57F673E0@comcast.net>


> On Jan 27, 2018, at 1:18 PM, Marsh Hardy ARA/RISK <mhardy at ara.com> wrote:
> 
> Hi Guys, I apologize for my rank & utter newness at R.
> 
> I used summary() and found about 95 variables, both character and numeric, all with "Length:368842" I assume is the # of records.
> 
> I'd like to know the record number (row #?) of any record where the data doesn't match in the 2 files of what should be the same output.

The 'length' function returns the number of items at the top level of a list. As such it returns the number of columns of a dataframe which is a type of list. The quotes around "Length:368842" make it appear that you are quoting from some sort of output, although its nature is unclear. Rather than abstracting from information that you don't know how to interpret it would have been better to include the entire output. The `summary` function is generic and therefore can vary widely in what it prints to the console.

You should instead post the output from str() applied to each of your "files". It does a better job of displaying object structure.

-- 
David.


> Thanks in advance, M.
> 
> //
> ________________________________________
> From: Ulrik Stervbo [ulrik.stervbo at gmail.com]
> Sent: Saturday, January 27, 2018 10:00 AM
> To: Eric Berger
> Cc: Marsh Hardy ARA/RISK; r-help at r-project.org
> Subject: Re: [R] Newbie wants to compare 2 huge RDSs row by row.
> 
> Also, it will be easier to provide helpful information if you'd describe what in your data you want to compare and what you hope to get out of the comparison.
> 
> Best wishes,
> Ulrik
> 
> Eric Berger <ericjberger at gmail.com<mailto:ericjberger at gmail.com>> schrieb am Sa., 27. Jan. 2018, 08:18:
> Hi Marsh,
> An RDS is not a data structure such as a data.frame. It can be anything.
> For example if I want to save my objects a, b, c I could do:
>> saveRDS( list(a,b,c,), file="tmp.RDS")
> Then read them back later with
>> myList <- readRDS( "tmp.RDS" )
> 
> Do you have additional information about your "RDSs" ?
> 
> Eric
> 
> 
> On Sat, Jan 27, 2018 at 6:54 AM, Marsh Hardy ARA/RISK <mhardy at ara.com<mailto:mhardy at ara.com>>
> wrote:
> 
>> Each RDS is 40 MBs. What's a slick code to compare them row by row, IDing
>> row numbers with mismatches?
>> 
>> Thanks in advance.
>> 
>> //
>> 
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From wdunlap at tibco.com  Sat Jan 27 22:57:49 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 27 Jan 2018 13:57:49 -0800
Subject: [R] Newbie wants to compare 2 huge RDSs row by row.
In-Reply-To: <087A60AB6499DB4F98295F09BEE7387FBED82F1D@colo-mail-2.exchange2.ara.wan>
References: <1517028086547-0.post@n4.nabble.com>
 <087A60AB6499DB4F98295F09BEE7387FBED825FD@colo-mail-2.exchange2.ara.wan>
 <087A60AB6499DB4F98295F09BEE7387FBED8266A@colo-mail-2.exchange2.ara.wan>
 <CAGgJW75hTB3kRgPOujo_Gn61_P52_phxBRHN6xg+YBksN7G2rQ@mail.gmail.com>
 <CAKVAULMet25ULAn0yxc-8_FOz5tbqAZYFykvO4Y+v4fqpjnWtQ@mail.gmail.com>
 <087A60AB6499DB4F98295F09BEE7387FBED82F1D@colo-mail-2.exchange2.ara.wan>
Message-ID: <CAF8bMcY17G7=zy-bq16BNuZGpF2xvqbegwSvTtBVz=Hn2oGFjg@mail.gmail.com>

If your two objects have class "data.frame" (look at class(objectName)) and
they
both have the same number of columns and the same order of columns and the
column types match closely enough (use all.equal(x1, x2) for that), then
you can try
     which( rowSums( x1 != x2 ) > 0)
E.g.,
> x1 <- data.frame(X=1:5, Y=rep(c("A","B"),c(3,2)))
> x2 <- data.frame(X=c(1,2,-3,-4,5), Y=rep(c("A","B"),c(2,3)))
> x1
  X Y
1 1 A
2 2 A
3 3 A
4 4 B
5 5 B
> x2
   X Y
1  1 A
2  2 A
3 -3 B
4 -4 B
5  5 B
> which( rowSums( x1 != x2 ) > 0)
[1] 3 4

If you want to allow small numeric differences but exactly character matches
you will have to get a bit fancier.  Splitting the data.frames into
character and
numeric parts and comparing each works well.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Jan 27, 2018 at 1:18 PM, Marsh Hardy ARA/RISK <mhardy at ara.com>
wrote:

> Hi Guys, I apologize for my rank & utter newness at R.
>
> I used summary() and found about 95 variables, both character and numeric,
> all with "Length:368842" I assume is the # of records.
>
> I'd like to know the record number (row #?) of any record where the data
> doesn't match in the 2 files of what should be the same output.
>
> Thanks in advance, M.
>
> //
> ________________________________________
> From: Ulrik Stervbo [ulrik.stervbo at gmail.com]
> Sent: Saturday, January 27, 2018 10:00 AM
> To: Eric Berger
> Cc: Marsh Hardy ARA/RISK; r-help at r-project.org
> Subject: Re: [R] Newbie wants to compare 2 huge RDSs row by row.
>
> Also, it will be easier to provide helpful information if you'd describe
> what in your data you want to compare and what you hope to get out of the
> comparison.
>
> Best wishes,
> Ulrik
>
> Eric Berger <ericjberger at gmail.com<mailto:ericjberger at gmail.com>> schrieb
> am Sa., 27. Jan. 2018, 08:18:
> Hi Marsh,
> An RDS is not a data structure such as a data.frame. It can be anything.
> For example if I want to save my objects a, b, c I could do:
> > saveRDS( list(a,b,c,), file="tmp.RDS")
> Then read them back later with
> > myList <- readRDS( "tmp.RDS" )
>
> Do you have additional information about your "RDSs" ?
>
> Eric
>
>
> On Sat, Jan 27, 2018 at 6:54 AM, Marsh Hardy ARA/RISK <mhardy at ara.com
> <mailto:mhardy at ara.com>>
> wrote:
>
> > Each RDS is 40 MBs. What's a slick code to compare them row by row, IDing
> > row numbers with mismatches?
> >
> > Thanks in advance.
> >
> > //
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From frainj at gmail.com  Sun Jan 28 01:47:37 2018
From: frainj at gmail.com (John C Frain)
Date: Sun, 28 Jan 2018 00:47:37 +0000
Subject: [R] Portable R in zip file for Windows
In-Reply-To: <CAO2XSvcMUGAR=NDnAYgRS-jxngxCP0fj5S8fByo7OHa_agpwmQ@mail.gmail.com>
References: <CAO2XSvcSqZamHarYi9EAP93PJKBX_kab=Ar1xxWmEdraTUrSJw@mail.gmail.com>
 <CAP01uRk0_s+QxwDigbkd+U2eKmvDvTB6a763+_UgNOJknvsTvA@mail.gmail.com>
 <CAO2XSvcAuPnYWtdCHfOPm__9vtoyrY45QEMjfw9fraFWUjt3sw@mail.gmail.com>
 <CAHrK516R_EP-fRoCyDCsV9kB2gy=gMKp=ORVrWfLkcAb7WQqKA@mail.gmail.com>
 <CAO2XSvcMUGAR=NDnAYgRS-jxngxCP0fj5S8fByo7OHa_agpwmQ@mail.gmail.com>
Message-ID: <CAHrK516cABYTFm4FWQdT1a8x+3K=CrFQdh-BzR5sdqiFskqeZg@mail.gmail.com>

When you unzip that file you have a rstudio.exe file which you appear to be
able to run.  As far as I know rstudio will not run unless you have a
version of R already installed.  The R FAQ for windows explains how to
install R if you have restricted permissions and do not want or are not
allowed to make any changes to the registry.  Using the exe install file in
this way does the same things as the zip file does in rstudio.  For flash
drive or CD you can substitute any area on your hard disk to which you have
read/write/exeute access.  As a last resort you can install in the
directory that you installed rstudio.  To get everything working together
you will need to reset some environmental variables and /or shortcuts.  You
probably needed to do this already with rstudio.

I think that it is very possible that you do not need a zipped file for R,
The FAQ tells you how to make it relocatable. This is the answer to your
question as far as I can see.  If not, I and several others do not
understand it.

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 26 January 2018 at 00:12, Juan Manuel Truppia <jmtruppia at gmail.com>
wrote:

> From the R Studio downloads, look below the installers. This is off topic
> however. If there is no zipped, no exe, no installation required of R, then
> I thank you very much for your help and trolling.
>
> (BTW, I think my question was pretty clear, concise and specific, I
> appreciate that some of you tried to solve a problem related to what I
> have, but I have already reviewed all options, and what I need is basically
> a zip of a working installation of the current version of R that I can
> download out of CRAN or a similar trusted site)
>
>
> On Thu, Jan 25, 2018, 19:59 John C Frain <frainj at gmail.com> wrote:
>
>> Can you please explain where you get the R-studio zip file and how you
>> manage to run r-studio from it without expanding it.  I do not see how this
>> is possible and would be delighted if you would share that knowledge with
>> us.  Obviously this possibility has not occurred to anyone on the list
>>
>> John C Frain
>> 3 Aranleigh Park
>> <https://maps.google.com/?q=3+Aranleigh+Park+Rathfarnham+Dublin&entry=gmail&source=g>
>> Rathfarnham
>> <https://maps.google.com/?q=3+Aranleigh+Park+Rathfarnham+Dublin&entry=gmail&source=g>
>> Dublin
>> <https://maps.google.com/?q=3+Aranleigh+Park+Rathfarnham+Dublin&entry=gmail&source=g>
>> 14
>> Ireland
>> www.tcd.ie/Economics/staff/frainj/home.html
>> mailto:frainj at tcd.ie
>> mailto:frainj at gmail.com
>>
>> On 25 January 2018 at 20:04, Juan Manuel Truppia <jmtruppia at gmail.com>
>> wrote:
>>
>>> What is wrong with you guys? I asked for a zip, like R Studio has for
>>> example. Totally clear.
>>> I cant execute exes. But I can unzip files.
>>> Thanks Gabor, I had that in mind, but can't execute the exe due to
>>> security
>>> restrictions.
>>> Geez, really, treating people who ask questions this way just makes you
>>> don't want to ask a single one.
>>>
>>> On Thu, Jan 25, 2018, 11:19 Gabor Grothendieck <ggrothendieck at gmail.com>
>>> wrote:
>>>
>>> > I believe that the ordinary Windows installer for R can produce a
>>> > portable result by choosing the appropriate configuration options from
>>> the
>>> > offered screens when you run the installer  Be sure to enter the
>>> desired
>>> > path in the Select Destination Location screen, choose Yes on the
>>> > Startup options screen and ensure that all boxes are unchecked on the
>>> > Select additional tasks screen.
>>> >
>>> > On Wed, Jan 24, 2018 at 10:11 PM, Juan Manuel Truppia
>>> > <jmtruppia at gmail.com> wrote:
>>> > > I read a message from 2009 or 2010 where it mentioned the
>>> availability
>>> > of R
>>> > > for Windows in a zip file, no installation required. It would be very
>>> > > useful for me. Is this still available somewhere?
>>> > >
>>> > > Thanks
>>> > >
>>> > >         [[alternative HTML version deleted]]
>>> > >
>>> > > ______________________________________________
>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> >
>>> >
>>> > --
>>> > Statistics & Software Consulting
>>> > GKX Group, GKX Associates Inc.
>>> > tel: 1-877-GKX-GROUP
>>> > email: ggrothendieck at gmail.com
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>

	[[alternative HTML version deleted]]


From mhardy at ara.com  Sun Jan 28 04:14:51 2018
From: mhardy at ara.com (Marsh Hardy ARA/RISK)
Date: Sun, 28 Jan 2018 03:14:51 +0000
Subject: [R] Newbie wants to compare 2 huge RDSs row by row.
In-Reply-To: <CAF8bMcY17G7=zy-bq16BNuZGpF2xvqbegwSvTtBVz=Hn2oGFjg@mail.gmail.com>
References: <1517028086547-0.post@n4.nabble.com>
 <087A60AB6499DB4F98295F09BEE7387FBED825FD@colo-mail-2.exchange2.ara.wan>
 <087A60AB6499DB4F98295F09BEE7387FBED8266A@colo-mail-2.exchange2.ara.wan>
 <CAGgJW75hTB3kRgPOujo_Gn61_P52_phxBRHN6xg+YBksN7G2rQ@mail.gmail.com>
 <CAKVAULMet25ULAn0yxc-8_FOz5tbqAZYFykvO4Y+v4fqpjnWtQ@mail.gmail.com>
 <087A60AB6499DB4F98295F09BEE7387FBED82F1D@colo-mail-2.exchange2.ara.wan>,
 <CAF8bMcY17G7=zy-bq16BNuZGpF2xvqbegwSvTtBVz=Hn2oGFjg@mail.gmail.com>
Message-ID: <087A60AB6499DB4F98295F09BEE7387FBED83080@colo-mail-2.exchange2.ara.wan>

Cool, looks like that'd do it, almost as if converting an entire record to a character string and comparing strings.

  --  M. B. Hardy, statistician
work: Applied Research Associates, S. E. Div.
      8537 Six Forks Rd., # 6000 / Raleigh, NC 27615-2963
      (919) 582-3329, fax: 582-3301
home: 1020 W. South St. / Raleigh, NC 27603-2162
      (919) 834-1245
________________________________________
From: William Dunlap [wdunlap at tibco.com]
Sent: Saturday, January 27, 2018 4:57 PM
To: Marsh Hardy ARA/RISK
Cc: Ulrik Stervbo; Eric Berger; r-help at r-project.org
Subject: Re: [R] Newbie wants to compare 2 huge RDSs row by row.

If your two objects have class "data.frame" (look at class(objectName)) and they
both have the same number of columns and the same order of columns and the
column types match closely enough (use all.equal(x1, x2) for that), then you can try
     which( rowSums( x1 != x2 ) > 0)
E.g.,
> x1 <- data.frame(X=1:5, Y=rep(c("A","B"),c(3,2)))
> x2 <- data.frame(X=c(1,2,-3,-4,5), Y=rep(c("A","B"),c(2,3)))
> x1
  X Y
1 1 A
2 2 A
3 3 A
4 4 B
5 5 B
> x2
   X Y
1  1 A
2  2 A
3 -3 B
4 -4 B
5  5 B
> which( rowSums( x1 != x2 ) > 0)
[1] 3 4

If you want to allow small numeric differences but exactly character matches
you will have to get a bit fancier.  Splitting the data.frames into character and
numeric parts and comparing each works well.

Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Sat, Jan 27, 2018 at 1:18 PM, Marsh Hardy ARA/RISK <mhardy at ara.com<mailto:mhardy at ara.com>> wrote:
Hi Guys, I apologize for my rank & utter newness at R.

I used summary() and found about 95 variables, both character and numeric, all with "Length:368842" I assume is the # of records.

I'd like to know the record number (row #?) of any record where the data doesn't match in the 2 files of what should be the same output.

Thanks in advance, M.

//
________________________________________
From: Ulrik Stervbo [ulrik.stervbo at gmail.com<mailto:ulrik.stervbo at gmail.com>]
Sent: Saturday, January 27, 2018 10:00 AM
To: Eric Berger
Cc: Marsh Hardy ARA/RISK; r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Newbie wants to compare 2 huge RDSs row by row.

Also, it will be easier to provide helpful information if you'd describe what in your data you want to compare and what you hope to get out of the comparison.

Best wishes,
Ulrik

Eric Berger <ericjberger at gmail.com<mailto:ericjberger at gmail.com><mailto:ericjberger at gmail.com<mailto:ericjberger at gmail.com>>> schrieb am Sa., 27. Jan. 2018, 08:18:
Hi Marsh,
An RDS is not a data structure such as a data.frame. It can be anything.
For example if I want to save my objects a, b, c I could do:
> saveRDS( list(a,b,c,), file="tmp.RDS")
Then read them back later with
> myList <- readRDS( "tmp.RDS" )

Do you have additional information about your "RDSs" ?

Eric


On Sat, Jan 27, 2018 at 6:54 AM, Marsh Hardy ARA/RISK <mhardy at ara.com<mailto:mhardy at ara.com><mailto:mhardy at ara.com<mailto:mhardy at ara.com>>>
wrote:

> Each RDS is 40 MBs. What's a slick code to compare them row by row, IDing
> row numbers with mismatches?
>
> Thanks in advance.
>
> //
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org><mailto:R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org><mailto:R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ulrik.stervbo at gmail.com  Sun Jan 28 09:17:40 2018
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Sun, 28 Jan 2018 08:17:40 +0000
Subject: [R] Newbie wants to compare 2 huge RDSs row by row.
In-Reply-To: <087A60AB6499DB4F98295F09BEE7387FBED83080@colo-mail-2.exchange2.ara.wan>
References: <1517028086547-0.post@n4.nabble.com>
 <087A60AB6499DB4F98295F09BEE7387FBED825FD@colo-mail-2.exchange2.ara.wan>
 <087A60AB6499DB4F98295F09BEE7387FBED8266A@colo-mail-2.exchange2.ara.wan>
 <CAGgJW75hTB3kRgPOujo_Gn61_P52_phxBRHN6xg+YBksN7G2rQ@mail.gmail.com>
 <CAKVAULMet25ULAn0yxc-8_FOz5tbqAZYFykvO4Y+v4fqpjnWtQ@mail.gmail.com>
 <087A60AB6499DB4F98295F09BEE7387FBED82F1D@colo-mail-2.exchange2.ara.wan>
 <CAF8bMcY17G7=zy-bq16BNuZGpF2xvqbegwSvTtBVz=Hn2oGFjg@mail.gmail.com>
 <087A60AB6499DB4F98295F09BEE7387FBED83080@colo-mail-2.exchange2.ara.wan>
Message-ID: <CAKVAULPQHCb-oEyJ3-=eGLb3A0_XiYwxXdcUKv6CZeeBe-fQOA@mail.gmail.com>

The anti_join from the package dplyr might also be handy.

install.package("dplyr")
library(dplyr)
anti_join (x1, x2)

You can get help on the different functions by ?function.name(), so
?anti_join() will bring you help - and examples - on the anti_join
function.

It might be worth testing your approach on a small subset of the data. That
makes it easier for you to follow what happens and evaluate the outcome.

HTH
Ulrik

Marsh Hardy ARA/RISK <mhardy at ara.com> schrieb am So., 28. Jan. 2018, 04:14:

> Cool, looks like that'd do it, almost as if converting an entire record to
> a character string and comparing strings.
>
>   --  M. B. Hardy, statistician
> work: Applied Research Associates, S. E. Div.
>       8537 Six Forks Rd., # 6000 / Raleigh, NC 27615
> <https://maps.google.com/?q=8537+Six+Forks+Rd.,+%23+6000+/+Raleigh,+NC+27615&entry=gmail&source=g>
> -2963
>       (919) 582-3329, fax: 582-3301
> home: 1020 W. South St. / Raleigh, NC 27603
> <https://maps.google.com/?q=1020+W.+South+St.+/+Raleigh,+NC+27603&entry=gmail&source=g>
> -2162
>       (919) 834-1245
> ________________________________________
> From: William Dunlap [wdunlap at tibco.com]
> Sent: Saturday, January 27, 2018 4:57 PM
> To: Marsh Hardy ARA/RISK
> Cc: Ulrik Stervbo; Eric Berger; r-help at r-project.org
> Subject: Re: [R] Newbie wants to compare 2 huge RDSs row by row.
>
> If your two objects have class "data.frame" (look at class(objectName))
> and they
> both have the same number of columns and the same order of columns and the
> column types match closely enough (use all.equal(x1, x2) for that), then
> you can try
>      which( rowSums( x1 != x2 ) > 0)
> E.g.,
> > x1 <- data.frame(X=1:5, Y=rep(c("A","B"),c(3,2)))
> > x2 <- data.frame(X=c(1,2,-3,-4,5), Y=rep(c("A","B"),c(2,3)))
> > x1
>   X Y
> 1 1 A
> 2 2 A
> 3 3 A
> 4 4 B
> 5 5 B
> > x2
>    X Y
> 1  1 A
> 2  2 A
> 3 -3 B
> 4 -4 B
> 5  5 B
> > which( rowSums( x1 != x2 ) > 0)
> [1] 3 4
>
> If you want to allow small numeric differences but exactly character
> matches
> you will have to get a bit fancier.  Splitting the data.frames into
> character and
> numeric parts and comparing each works well.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com<http://tibco.com>
>
> On Sat, Jan 27, 2018 at 1:18 PM, Marsh Hardy ARA/RISK <mhardy at ara.com
> <mailto:mhardy at ara.com>> wrote:
> Hi Guys, I apologize for my rank & utter newness at R.
>
> I used summary() and found about 95 variables, both character and numeric,
> all with "Length:368842" I assume is the # of records.
>
> I'd like to know the record number (row #?) of any record where the data
> doesn't match in the 2 files of what should be the same output.
>
> Thanks in advance, M.
>
> //
> ________________________________________
> From: Ulrik Stervbo [ulrik.stervbo at gmail.com<mailto:
> ulrik.stervbo at gmail.com>]
> Sent: Saturday, January 27, 2018 10:00 AM
> To: Eric Berger
> Cc: Marsh Hardy ARA/RISK; r-help at r-project.org<mailto:r-help at r-project.org
> >
> Subject: Re: [R] Newbie wants to compare 2 huge RDSs row by row.
>
> Also, it will be easier to provide helpful information if you'd describe
> what in your data you want to compare and what you hope to get out of the
> comparison.
>
> Best wishes,
> Ulrik
>
> Eric Berger <ericjberger at gmail.com<mailto:ericjberger at gmail.com><mailto:
> ericjberger at gmail.com<mailto:ericjberger at gmail.com>>> schrieb am Sa., 27.
> Jan. 2018, 08:18:
> Hi Marsh,
> An RDS is not a data structure such as a data.frame. It can be anything.
> For example if I want to save my objects a, b, c I could do:
> > saveRDS( list(a,b,c,), file="tmp.RDS")
> Then read them back later with
> > myList <- readRDS( "tmp.RDS" )
>
> Do you have additional information about your "RDSs" ?
>
> Eric
>
>
> On Sat, Jan 27, 2018 at 6:54 AM, Marsh Hardy ARA/RISK <mhardy at ara.com
> <mailto:mhardy at ara.com><mailto:mhardy at ara.com<mailto:mhardy at ara.com>>>
> wrote:
>
> > Each RDS is 40 MBs. What's a slick code to compare them row by row, IDing
> > row numbers with mismatches?
> >
> > Thanks in advance.
> >
> > //
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org><mailto:
> R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To
> UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org><mailto:
> R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From Michael.Lane at usq.edu.au  Sun Jan 28 13:50:12 2018
From: Michael.Lane at usq.edu.au (Michael Lane)
Date: Sun, 28 Jan 2018 12:50:12 +0000
Subject: [R] semPLS package will not load seems to be failing on loading
 package lattice
Message-ID: <1C0DA0ED816551468D27CA838814D46B012719063F@EXCH-MBX-PRD-T2.usq.edu.au>

Hi R Help Team

I recently updated my R installation to R 3.4.3 and updated to later version of R Studio and I found that the package semPLS will not load even though installed and it seems to be failing on loading package lattice

Getting the following error message:

library(semPLS)
Loading required package: lattice
Error: package or namespace load failed for 'lattice':
.onLoad failed in loadNamespace() for 'grid', details:
  call: fun(libname, pkgname)
  error: object 'C_initGrid' not found
Error: package 'lattice' could not be loaded

Any advice or help on this bug would be much appreciated

Best regards Michael

Dr Michael Lane USQ Profile<http://staffprofile.usq.edu.au/Profile/Michael-Lane>
PhD Information Systems, USQ
Email: Michael.Lane at usq.edu.au<mailto:Michael.Lane at usq.edu.au>
Ph 07 4631 1268
Mobile 0407 316 391
Academic Coordinator School of Management and Enterprise
Member of Editoral Board Australasian Journal of Information Systems<http://journal.acs.org.au/index.php/ajis>
Member of Editoral Board Journal of Information Systems Education<http://jise.org/>



_____________________________________________________________
This email (including any attached files) is confidentia...{{dropped:18}}


From henrik.bengtsson at gmail.com  Sun Jan 28 17:12:57 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sun, 28 Jan 2018 08:12:57 -0800
Subject: [R] Newbie wants to compare 2 huge RDSs row by row.
In-Reply-To: <CAKVAULPQHCb-oEyJ3-=eGLb3A0_XiYwxXdcUKv6CZeeBe-fQOA@mail.gmail.com>
References: <1517028086547-0.post@n4.nabble.com>
 <087A60AB6499DB4F98295F09BEE7387FBED825FD@colo-mail-2.exchange2.ara.wan>
 <087A60AB6499DB4F98295F09BEE7387FBED8266A@colo-mail-2.exchange2.ara.wan>
 <CAGgJW75hTB3kRgPOujo_Gn61_P52_phxBRHN6xg+YBksN7G2rQ@mail.gmail.com>
 <CAKVAULMet25ULAn0yxc-8_FOz5tbqAZYFykvO4Y+v4fqpjnWtQ@mail.gmail.com>
 <087A60AB6499DB4F98295F09BEE7387FBED82F1D@colo-mail-2.exchange2.ara.wan>
 <CAF8bMcY17G7=zy-bq16BNuZGpF2xvqbegwSvTtBVz=Hn2oGFjg@mail.gmail.com>
 <087A60AB6499DB4F98295F09BEE7387FBED83080@colo-mail-2.exchange2.ara.wan>
 <CAKVAULPQHCb-oEyJ3-=eGLb3A0_XiYwxXdcUKv6CZeeBe-fQOA@mail.gmail.com>
Message-ID: <CAFDcVCRad2rgKzgSYDWQHTfG+oyw6K6t61g=Nw6aJ7psOknE6w@mail.gmail.com>

The diffobj package (https://cran.r-project.org/package=diffobj) is
really helpful here.  It provides "diff" functions diffPrint(),
diffStr(), and diffChr() to compare two object 'x' and 'y' and provide
neat colorized summary output.

Example:

> iris2 <- iris
> iris2[122:125,4] <- iris2[122:125,4] + 0.1

> diffobj::diffPrint(iris2, iris)
< iris2
> iris
@@ 121,8 / 121,8 @@
~     Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
  120          6.0         2.2          5.0         1.5  virginica
  121          6.9         3.2          5.7         2.3  virginica
< 122          5.6         2.8          4.9         2.1  virginica
> 122          5.6         2.8          4.9         2.0  virginica
< 123          7.7         2.8          6.7         2.1  virginica
> 123          7.7         2.8          6.7         2.0  virginica
< 124          6.3         2.7          4.9         1.9  virginica
> 124          6.3         2.7          4.9         1.8  virginica
< 125          6.7         3.3          5.7         2.2  virginica
> 125          6.7         3.3          5.7         2.1  virginica
  126          7.2         3.2          6.0         1.8  virginica
  127          6.2         2.8          4.8         1.8  virginica

What's not show here is that the colored output (supported by many
terminals these days) also highlights exactly which elements in those
rows differ.

/Henrik

On Sun, Jan 28, 2018 at 12:17 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> The anti_join from the package dplyr might also be handy.
>
> install.package("dplyr")
> library(dplyr)
> anti_join (x1, x2)
>
> You can get help on the different functions by ?function.name(), so
> ?anti_join() will bring you help - and examples - on the anti_join
> function.
>
> It might be worth testing your approach on a small subset of the data. That
> makes it easier for you to follow what happens and evaluate the outcome.
>
> HTH
> Ulrik
>
> Marsh Hardy ARA/RISK <mhardy at ara.com> schrieb am So., 28. Jan. 2018, 04:14:
>
>> Cool, looks like that'd do it, almost as if converting an entire record to
>> a character string and comparing strings.
>>
>>   --  M. B. Hardy, statistician
>> work: Applied Research Associates, S. E. Div.
>>       8537 Six Forks Rd., # 6000 / Raleigh, NC 27615
>> <https://maps.google.com/?q=8537+Six+Forks+Rd.,+%23+6000+/+Raleigh,+NC+27615&entry=gmail&source=g>
>> -2963
>>       (919) 582-3329, fax: 582-3301
>> home: 1020 W. South St. / Raleigh, NC 27603
>> <https://maps.google.com/?q=1020+W.+South+St.+/+Raleigh,+NC+27603&entry=gmail&source=g>
>> -2162
>>       (919) 834-1245
>> ________________________________________
>> From: William Dunlap [wdunlap at tibco.com]
>> Sent: Saturday, January 27, 2018 4:57 PM
>> To: Marsh Hardy ARA/RISK
>> Cc: Ulrik Stervbo; Eric Berger; r-help at r-project.org
>> Subject: Re: [R] Newbie wants to compare 2 huge RDSs row by row.
>>
>> If your two objects have class "data.frame" (look at class(objectName))
>> and they
>> both have the same number of columns and the same order of columns and the
>> column types match closely enough (use all.equal(x1, x2) for that), then
>> you can try
>>      which( rowSums( x1 != x2 ) > 0)
>> E.g.,
>> > x1 <- data.frame(X=1:5, Y=rep(c("A","B"),c(3,2)))
>> > x2 <- data.frame(X=c(1,2,-3,-4,5), Y=rep(c("A","B"),c(2,3)))
>> > x1
>>   X Y
>> 1 1 A
>> 2 2 A
>> 3 3 A
>> 4 4 B
>> 5 5 B
>> > x2
>>    X Y
>> 1  1 A
>> 2  2 A
>> 3 -3 B
>> 4 -4 B
>> 5  5 B
>> > which( rowSums( x1 != x2 ) > 0)
>> [1] 3 4
>>
>> If you want to allow small numeric differences but exactly character
>> matches
>> you will have to get a bit fancier.  Splitting the data.frames into
>> character and
>> numeric parts and comparing each works well.
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com<http://tibco.com>
>>
>> On Sat, Jan 27, 2018 at 1:18 PM, Marsh Hardy ARA/RISK <mhardy at ara.com
>> <mailto:mhardy at ara.com>> wrote:
>> Hi Guys, I apologize for my rank & utter newness at R.
>>
>> I used summary() and found about 95 variables, both character and numeric,
>> all with "Length:368842" I assume is the # of records.
>>
>> I'd like to know the record number (row #?) of any record where the data
>> doesn't match in the 2 files of what should be the same output.
>>
>> Thanks in advance, M.
>>
>> //
>> ________________________________________
>> From: Ulrik Stervbo [ulrik.stervbo at gmail.com<mailto:
>> ulrik.stervbo at gmail.com>]
>> Sent: Saturday, January 27, 2018 10:00 AM
>> To: Eric Berger
>> Cc: Marsh Hardy ARA/RISK; r-help at r-project.org<mailto:r-help at r-project.org
>> >
>> Subject: Re: [R] Newbie wants to compare 2 huge RDSs row by row.
>>
>> Also, it will be easier to provide helpful information if you'd describe
>> what in your data you want to compare and what you hope to get out of the
>> comparison.
>>
>> Best wishes,
>> Ulrik
>>
>> Eric Berger <ericjberger at gmail.com<mailto:ericjberger at gmail.com><mailto:
>> ericjberger at gmail.com<mailto:ericjberger at gmail.com>>> schrieb am Sa., 27.
>> Jan. 2018, 08:18:
>> Hi Marsh,
>> An RDS is not a data structure such as a data.frame. It can be anything.
>> For example if I want to save my objects a, b, c I could do:
>> > saveRDS( list(a,b,c,), file="tmp.RDS")
>> Then read them back later with
>> > myList <- readRDS( "tmp.RDS" )
>>
>> Do you have additional information about your "RDSs" ?
>>
>> Eric
>>
>>
>> On Sat, Jan 27, 2018 at 6:54 AM, Marsh Hardy ARA/RISK <mhardy at ara.com
>> <mailto:mhardy at ara.com><mailto:mhardy at ara.com<mailto:mhardy at ara.com>>>
>> wrote:
>>
>> > Each RDS is 40 MBs. What's a slick code to compare them row by row, IDing
>> > row numbers with mismatches?
>> >
>> > Thanks in advance.
>> >
>> > //
>> >
>> > ______________________________________________
>> > R-help at r-project.org<mailto:R-help at r-project.org><mailto:
>> R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To
>> UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> > posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org><mailto:
>> R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To
>> UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>> UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mhardy at ara.com  Sun Jan 28 17:22:20 2018
From: mhardy at ara.com (Marsh Hardy ARA/RISK)
Date: Sun, 28 Jan 2018 16:22:20 +0000
Subject: [R] Newbie wants to compare 2 huge RDSs row by row.
In-Reply-To: <CAFDcVCRad2rgKzgSYDWQHTfG+oyw6K6t61g=Nw6aJ7psOknE6w@mail.gmail.com>
References: <1517028086547-0.post@n4.nabble.com>
 <087A60AB6499DB4F98295F09BEE7387FBED825FD@colo-mail-2.exchange2.ara.wan>
 <087A60AB6499DB4F98295F09BEE7387FBED8266A@colo-mail-2.exchange2.ara.wan>
 <CAGgJW75hTB3kRgPOujo_Gn61_P52_phxBRHN6xg+YBksN7G2rQ@mail.gmail.com>
 <CAKVAULMet25ULAn0yxc-8_FOz5tbqAZYFykvO4Y+v4fqpjnWtQ@mail.gmail.com>
 <087A60AB6499DB4F98295F09BEE7387FBED82F1D@colo-mail-2.exchange2.ara.wan>
 <CAF8bMcY17G7=zy-bq16BNuZGpF2xvqbegwSvTtBVz=Hn2oGFjg@mail.gmail.com>
 <087A60AB6499DB4F98295F09BEE7387FBED83080@colo-mail-2.exchange2.ara.wan>
 <CAKVAULPQHCb-oEyJ3-=eGLb3A0_XiYwxXdcUKv6CZeeBe-fQOA@mail.gmail.com>,
 <CAFDcVCRad2rgKzgSYDWQHTfG+oyw6K6t61g=Nw6aJ7psOknE6w@mail.gmail.com>
Message-ID: <087A60AB6499DB4F98295F09BEE7387FBED83406@colo-mail-2.exchange2.ara.wan>

Thanks, I think I've found the most succinct expression of differences in two data.frames...

length(which( rowSums( x1 != x2 ) > 0))

gives a count of the # of records in two data.frames that do not match.

// 
________________________________________
From: Henrik Bengtsson [henrik.bengtsson at gmail.com]
Sent: Sunday, January 28, 2018 11:12 AM
To: Ulrik Stervbo
Cc: Marsh Hardy ARA/RISK; r-help at r-project.org
Subject: Re: [R] Newbie wants to compare 2 huge RDSs row by row.

The diffobj package (https://cran.r-project.org/package=diffobj) is
really helpful here.  It provides "diff" functions diffPrint(),
diffStr(), and diffChr() to compare two object 'x' and 'y' and provide
neat colorized summary output.

Example:

> iris2 <- iris
> iris2[122:125,4] <- iris2[122:125,4] + 0.1

> diffobj::diffPrint(iris2, iris)
< iris2
> iris
@@ 121,8 / 121,8 @@
~     Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
  120          6.0         2.2          5.0         1.5  virginica
  121          6.9         3.2          5.7         2.3  virginica
< 122          5.6         2.8          4.9         2.1  virginica
> 122          5.6         2.8          4.9         2.0  virginica
< 123          7.7         2.8          6.7         2.1  virginica
> 123          7.7         2.8          6.7         2.0  virginica
< 124          6.3         2.7          4.9         1.9  virginica
> 124          6.3         2.7          4.9         1.8  virginica
< 125          6.7         3.3          5.7         2.2  virginica
> 125          6.7         3.3          5.7         2.1  virginica
  126          7.2         3.2          6.0         1.8  virginica
  127          6.2         2.8          4.8         1.8  virginica

What's not show here is that the colored output (supported by many
terminals these days) also highlights exactly which elements in those
rows differ.

/Henrik

On Sun, Jan 28, 2018 at 12:17 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> The anti_join from the package dplyr might also be handy.
>
> install.package("dplyr")
> library(dplyr)
> anti_join (x1, x2)
>
> You can get help on the different functions by ?function.name(), so
> ?anti_join() will bring you help - and examples - on the anti_join
> function.
>
> It might be worth testing your approach on a small subset of the data. That
> makes it easier for you to follow what happens and evaluate the outcome.
>
> HTH
> Ulrik
>
> Marsh Hardy ARA/RISK <mhardy at ara.com> schrieb am So., 28. Jan. 2018, 04:14:
>
>> Cool, looks like that'd do it, almost as if converting an entire record to
>> a character string and comparing strings.
>>
>> ________________________________________
>> From: William Dunlap [wdunlap at tibco.com]
>> Sent: Saturday, January 27, 2018 4:57 PM
>> To: Marsh Hardy ARA/RISK
>> Cc: Ulrik Stervbo; Eric Berger; r-help at r-project.org
>> Subject: Re: [R] Newbie wants to compare 2 huge RDSs row by row.
>>
>> If your two objects have class "data.frame" (look at class(objectName))
>> and they
>> both have the same number of columns and the same order of columns and the
>> column types match closely enough (use all.equal(x1, x2) for that), then
>> you can try
>>      which( rowSums( x1 != x2 ) > 0)
>> E.g.,
>> > x1 <- data.frame(X=1:5, Y=rep(c("A","B"),c(3,2)))
>> > x2 <- data.frame(X=c(1,2,-3,-4,5), Y=rep(c("A","B"),c(2,3)))
>> > x1
>>   X Y
>> 1 1 A
>> 2 2 A
>> 3 3 A
>> 4 4 B
>> 5 5 B
>> > x2
>>    X Y
>> 1  1 A
>> 2  2 A
>> 3 -3 B
>> 4 -4 B
>> 5  5 B
>> > which( rowSums( x1 != x2 ) > 0)
>> [1] 3 4
>>
>> If you want to allow small numeric differences but exactly character
>> matches
>> you will have to get a bit fancier.  Splitting the data.frames into
>> character and
>> numeric parts and comparing each works well.
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com<http://tibco.com>
>>
>> On Sat, Jan 27, 2018 at 1:18 PM, Marsh Hardy ARA/RISK <mhardy at ara.com
>> <mailto:mhardy at ara.com>> wrote:
>> Hi Guys, I apologize for my rank & utter newness at R.
>>
>> I used summary() and found about 95 variables, both character and numeric,
>> all with "Length:368842" I assume is the # of records.
>>
>> I'd like to know the record number (row #?) of any record where the data
>> doesn't match in the 2 files of what should be the same output.
>>
>> Thanks in advance, M.
>>
>> //
>> ________________________________________
>> From: Ulrik Stervbo [ulrik.stervbo at gmail.com<mailto:
>> ulrik.stervbo at gmail.com>]
>> Sent: Saturday, January 27, 2018 10:00 AM
>> To: Eric Berger
>> Cc: Marsh Hardy ARA/RISK; r-help at r-project.org<mailto:r-help at r-project.org
>> >
>> Subject: Re: [R] Newbie wants to compare 2 huge RDSs row by row.
>>
>> Also, it will be easier to provide helpful information if you'd describe
>> what in your data you want to compare and what you hope to get out of the
>> comparison.
>>
>> Best wishes,
>> Ulrik
>>
>> Eric Berger <ericjberger at gmail.com<mailto:ericjberger at gmail.com><mailto:
>> ericjberger at gmail.com<mailto:ericjberger at gmail.com>>> schrieb am Sa., 27.
>> Jan. 2018, 08:18:
>> Hi Marsh,
>> An RDS is not a data structure such as a data.frame. It can be anything.
>> For example if I want to save my objects a, b, c I could do:
>> > saveRDS( list(a,b,c,), file="tmp.RDS")
>> Then read them back later with
>> > myList <- readRDS( "tmp.RDS" )
>>
>> Do you have additional information about your "RDSs" ?
>>
>> Eric
>>
>>
>> On Sat, Jan 27, 2018 at 6:54 AM, Marsh Hardy ARA/RISK <mhardy at ara.com
>> <mailto:mhardy at ara.com><mailto:mhardy at ara.com<mailto:mhardy at ara.com>>>
>> wrote:
>>
>> > Each RDS is 40 MBs. What's a slick code to compare them row by row, IDing
>> > row numbers with mismatches?
>> >
>> > Thanks in advance.
>> >
>> > //
>> >
>> > ______________________________________________
>> > R-help at r-project.org<mailto:R-help at r-project.org><mailto:
>> R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To
>> UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> > posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org><mailto:
>> R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To
>> UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>> UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ericjberger at gmail.com  Sun Jan 28 17:47:45 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Sun, 28 Jan 2018 18:47:45 +0200
Subject: [R] Newbie wants to compare 2 huge RDSs row by row.
In-Reply-To: <087A60AB6499DB4F98295F09BEE7387FBED83406@colo-mail-2.exchange2.ara.wan>
References: <1517028086547-0.post@n4.nabble.com>
 <087A60AB6499DB4F98295F09BEE7387FBED825FD@colo-mail-2.exchange2.ara.wan>
 <087A60AB6499DB4F98295F09BEE7387FBED8266A@colo-mail-2.exchange2.ara.wan>
 <CAGgJW75hTB3kRgPOujo_Gn61_P52_phxBRHN6xg+YBksN7G2rQ@mail.gmail.com>
 <CAKVAULMet25ULAn0yxc-8_FOz5tbqAZYFykvO4Y+v4fqpjnWtQ@mail.gmail.com>
 <087A60AB6499DB4F98295F09BEE7387FBED82F1D@colo-mail-2.exchange2.ara.wan>
 <CAF8bMcY17G7=zy-bq16BNuZGpF2xvqbegwSvTtBVz=Hn2oGFjg@mail.gmail.com>
 <087A60AB6499DB4F98295F09BEE7387FBED83080@colo-mail-2.exchange2.ara.wan>
 <CAKVAULPQHCb-oEyJ3-=eGLb3A0_XiYwxXdcUKv6CZeeBe-fQOA@mail.gmail.com>
 <CAFDcVCRad2rgKzgSYDWQHTfG+oyw6K6t61g=Nw6aJ7psOknE6w@mail.gmail.com>
 <087A60AB6499DB4F98295F09BEE7387FBED83406@colo-mail-2.exchange2.ara.wan>
Message-ID: <CAGgJW76EhaKdN=_UfgH6=R1eArZuQ3chUaxqRzm14DGs-n9xSg@mail.gmail.com>

Hi Henrik,
Thanks for pointing out the diffobj package and the clear example. Nice!


On Sun, Jan 28, 2018 at 6:22 PM, Marsh Hardy ARA/RISK <mhardy at ara.com>
wrote:

> Thanks, I think I've found the most succinct expression of differences in
> two data.frames...
>
> length(which( rowSums( x1 != x2 ) > 0))
>
> gives a count of the # of records in two data.frames that do not match.
>
> //
> ________________________________________
> From: Henrik Bengtsson [henrik.bengtsson at gmail.com]
> Sent: Sunday, January 28, 2018 11:12 AM
> To: Ulrik Stervbo
> Cc: Marsh Hardy ARA/RISK; r-help at r-project.org
> Subject: Re: [R] Newbie wants to compare 2 huge RDSs row by row.
>
> The diffobj package (https://cran.r-project.org/package=diffobj) is
> really helpful here.  It provides "diff" functions diffPrint(),
> diffStr(), and diffChr() to compare two object 'x' and 'y' and provide
> neat colorized summary output.
>
> Example:
>
> > iris2 <- iris
> > iris2[122:125,4] <- iris2[122:125,4] + 0.1
>
> > diffobj::diffPrint(iris2, iris)
> < iris2
> > iris
> @@ 121,8 / 121,8 @@
> ~     Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
>   120          6.0         2.2          5.0         1.5  virginica
>   121          6.9         3.2          5.7         2.3  virginica
> < 122          5.6         2.8          4.9         2.1  virginica
> > 122          5.6         2.8          4.9         2.0  virginica
> < 123          7.7         2.8          6.7         2.1  virginica
> > 123          7.7         2.8          6.7         2.0  virginica
> < 124          6.3         2.7          4.9         1.9  virginica
> > 124          6.3         2.7          4.9         1.8  virginica
> < 125          6.7         3.3          5.7         2.2  virginica
> > 125          6.7         3.3          5.7         2.1  virginica
>   126          7.2         3.2          6.0         1.8  virginica
>   127          6.2         2.8          4.8         1.8  virginica
>
> What's not show here is that the colored output (supported by many
> terminals these days) also highlights exactly which elements in those
> rows differ.
>
> /Henrik
>
> On Sun, Jan 28, 2018 at 12:17 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> wrote:
> > The anti_join from the package dplyr might also be handy.
> >
> > install.package("dplyr")
> > library(dplyr)
> > anti_join (x1, x2)
> >
> > You can get help on the different functions by ?function.name(), so
> > ?anti_join() will bring you help - and examples - on the anti_join
> > function.
> >
> > It might be worth testing your approach on a small subset of the data.
> That
> > makes it easier for you to follow what happens and evaluate the outcome.
> >
> > HTH
> > Ulrik
> >
> > Marsh Hardy ARA/RISK <mhardy at ara.com> schrieb am So., 28. Jan. 2018,
> 04:14:
> >
> >> Cool, looks like that'd do it, almost as if converting an entire record
> to
> >> a character string and comparing strings.
> >>
> >> ________________________________________
> >> From: William Dunlap [wdunlap at tibco.com]
> >> Sent: Saturday, January 27, 2018 4:57 PM
> >> To: Marsh Hardy ARA/RISK
> >> Cc: Ulrik Stervbo; Eric Berger; r-help at r-project.org
> >> Subject: Re: [R] Newbie wants to compare 2 huge RDSs row by row.
> >>
> >> If your two objects have class "data.frame" (look at class(objectName))
> >> and they
> >> both have the same number of columns and the same order of columns and
> the
> >> column types match closely enough (use all.equal(x1, x2) for that), then
> >> you can try
> >>      which( rowSums( x1 != x2 ) > 0)
> >> E.g.,
> >> > x1 <- data.frame(X=1:5, Y=rep(c("A","B"),c(3,2)))
> >> > x2 <- data.frame(X=c(1,2,-3,-4,5), Y=rep(c("A","B"),c(2,3)))
> >> > x1
> >>   X Y
> >> 1 1 A
> >> 2 2 A
> >> 3 3 A
> >> 4 4 B
> >> 5 5 B
> >> > x2
> >>    X Y
> >> 1  1 A
> >> 2  2 A
> >> 3 -3 B
> >> 4 -4 B
> >> 5  5 B
> >> > which( rowSums( x1 != x2 ) > 0)
> >> [1] 3 4
> >>
> >> If you want to allow small numeric differences but exactly character
> >> matches
> >> you will have to get a bit fancier.  Splitting the data.frames into
> >> character and
> >> numeric parts and comparing each works well.
> >>
> >> Bill Dunlap
> >> TIBCO Software
> >> wdunlap tibco.com<http://tibco.com>
> >>
> >> On Sat, Jan 27, 2018 at 1:18 PM, Marsh Hardy ARA/RISK <mhardy at ara.com
> >> <mailto:mhardy at ara.com>> wrote:
> >> Hi Guys, I apologize for my rank & utter newness at R.
> >>
> >> I used summary() and found about 95 variables, both character and
> numeric,
> >> all with "Length:368842" I assume is the # of records.
> >>
> >> I'd like to know the record number (row #?) of any record where the data
> >> doesn't match in the 2 files of what should be the same output.
> >>
> >> Thanks in advance, M.
> >>
> >> //
> >> ________________________________________
> >> From: Ulrik Stervbo [ulrik.stervbo at gmail.com<mailto:
> >> ulrik.stervbo at gmail.com>]
> >> Sent: Saturday, January 27, 2018 10:00 AM
> >> To: Eric Berger
> >> Cc: Marsh Hardy ARA/RISK; r-help at r-project.org<mailto:r-
> help at r-project.org
> >> >
> >> Subject: Re: [R] Newbie wants to compare 2 huge RDSs row by row.
> >>
> >> Also, it will be easier to provide helpful information if you'd describe
> >> what in your data you want to compare and what you hope to get out of
> the
> >> comparison.
> >>
> >> Best wishes,
> >> Ulrik
> >>
> >> Eric Berger <ericjberger at gmail.com<mailto:ericjberger at gmail.com
> ><mailto:
> >> ericjberger at gmail.com<mailto:ericjberger at gmail.com>>> schrieb am Sa.,
> 27.
> >> Jan. 2018, 08:18:
> >> Hi Marsh,
> >> An RDS is not a data structure such as a data.frame. It can be anything.
> >> For example if I want to save my objects a, b, c I could do:
> >> > saveRDS( list(a,b,c,), file="tmp.RDS")
> >> Then read them back later with
> >> > myList <- readRDS( "tmp.RDS" )
> >>
> >> Do you have additional information about your "RDSs" ?
> >>
> >> Eric
> >>
> >>
> >> On Sat, Jan 27, 2018 at 6:54 AM, Marsh Hardy ARA/RISK <mhardy at ara.com
> >> <mailto:mhardy at ara.com><mailto:mhardy at ara.com<mailto:mhardy at ara.com>>>
> >> wrote:
> >>
> >> > Each RDS is 40 MBs. What's a slick code to compare them row by row,
> IDing
> >> > row numbers with mismatches?
> >> >
> >> > Thanks in advance.
> >> >
> >> > //
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org<mailto:R-help at r-project.org><mailto:
> >> R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To
> >> UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/
> >> > posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org<mailto:R-help at r-project.org><mailto:
> >> R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To
> >> UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> >> UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Jan 28 18:11:40 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 28 Jan 2018 09:11:40 -0800
Subject: [R] semPLS package will not load seems to be failing on loading
	package lattice
In-Reply-To: <1C0DA0ED816551468D27CA838814D46B012719063F@EXCH-MBX-PRD-T2.usq.edu.au>
References: <1C0DA0ED816551468D27CA838814D46B012719063F@EXCH-MBX-PRD-T2.usq.edu.au>
Message-ID: <839363B4-D19B-4748-BCF6-4FEC06ECBE17@comcast.net>


> On Jan 28, 2018, at 4:50 AM, Michael Lane <Michael.Lane at usq.edu.au> wrote:
> 
> Hi R Help Team
> 
> I recently updated my R installation to R 3.4.3 and updated to later version of R Studio and I found that the package semPLS will not load even though installed and it seems to be failing on loading package lattice
> 
> Getting the following error message:
> 
> library(semPLS)
> Loading required package: lattice
> Error: package or namespace load failed for 'lattice':
> .onLoad failed in loadNamespace() for 'grid', details:
>  call: fun(libname, pkgname)
>  error: object 'C_initGrid' not found
> Error: package 'lattice' could not be loaded

Although it is the attempt to load lattice that triggers the fault, the difficulty actually reported was with loading the 'grid' Namespace. The grid package is one of the core R packages, so I have two suggestions:

First try to load grid as a package. (Although it's a core R package, it is not automatically loaded when R starts.)

library(grid)

If that fails then you clearly have a broken installation of R, and would need to reinstall. If it doesn't fail, then the error message would seem to be a puzzle, and you should re-read the Posting Guide and follow the instructions on reported unexpected behavior which you have so far only followed very incompletely.

-- 
David.


> 
> Any advice or help on this bug would be much appreciated
> 
> Best regards Michael
> 
> Dr Michael Lane USQ Profile<http://staffprofile.usq.edu.au/Profile/Michael-Lane>
> PhD Information Systems, USQ
> Email: Michael.Lane at usq.edu.au<mailto:Michael.Lane at usq.edu.au>
> Ph 07 4631 1268
> Mobile 0407 316 391
> Academic Coordinator School of Management and Enterprise
> Member of Editoral Board Australasian Journal of Information Systems<http://journal.acs.org.au/index.php/ajis>
> Member of Editoral Board Journal of Information Systems Education<http://jise.org/>
> 
> 
> 
> _____________________________________________________________
> This email (including any attached files) is confidentia...{{dropped:18}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From phil at philipsmith.ca  Sun Jan 28 22:09:10 2018
From: phil at philipsmith.ca (phil at philipsmith.ca)
Date: Sun, 28 Jan 2018 16:09:10 -0500
Subject: [R] Plotting quarterly time series
Message-ID: <6242b48e536032f2f4153c6791213581.squirrel@webmail.philipsmith.ca>

I have a data set with quarterly time series for several variables. The
time index is recorded in column 1 of the dataframe as a character vector
"Q1 1961", "Q2 1961","Q3 1961", "Q4 1961", "Q1 1962", etc. I want to
produce line plots with ggplot2, but it seems I need to convert the time
index from character to date class. Is that right? If so, how do I make
the conversion?


From Achim.Zeileis at uibk.ac.at  Sun Jan 28 22:53:24 2018
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sun, 28 Jan 2018 22:53:24 +0100 (CET)
Subject: [R] Plotting quarterly time series
In-Reply-To: <6242b48e536032f2f4153c6791213581.squirrel@webmail.philipsmith.ca>
References: <6242b48e536032f2f4153c6791213581.squirrel@webmail.philipsmith.ca>
Message-ID: <alpine.DEB.2.21.1801282245310.16256@paninaro>

On Sun, 28 Jan 2018, phil at philipsmith.ca wrote:

> I have a data set with quarterly time series for several variables. The 
> time index is recorded in column 1 of the dataframe as a character 
> vector "Q1 1961", "Q2 1961","Q3 1961", "Q4 1961", "Q1 1962", etc. I want 
> to produce line plots with ggplot2, but it seems I need to convert the 
> time index from character to date class. Is that right? If so, how do I 
> make the conversion?

You can use the yearqtr class in the zoo package, converting with 
as.yearqtr(..., format = "Q%q %Y"). zoo also provides an autoplot() method 
for ggplot2-based time series visualizations. See ?autoplot.zoo for 
various examples.

## example data similar to your description
d <- data.frame(sin = sin(1:8), cos = cos(1:8))
d$time <- c("Q1 1961", "Q2 1961", "Q3 1961", "Q4 1961", "Q1 1962",
   "Q2 1962", "Q3 1962", "Q4 1962")

## convert to zoo series
library("zoo")
z <- zoo(as.matrix(d[, 1:2]), as.yearqtr(d$time, "Q%q %Y"))

## ggplot2 display
library("ggplot2")
autoplot(z)

## with nicer axis scaling
autoplot(z) + scale_x_yearqtr()

## some variations
autoplot(z, facets = Series ~ .) + scale_x_yearqtr() + geom_point()
autoplot(z, facets = NULL) + scale_x_yearqtr() + geom_point()


> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Sun Jan 28 23:23:53 2018
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 28 Jan 2018 17:23:53 -0500
Subject: [R] Plotting quarterly time series
In-Reply-To: <alpine.DEB.2.21.1801282245310.16256@paninaro>
References: <6242b48e536032f2f4153c6791213581.squirrel@webmail.philipsmith.ca>
 <alpine.DEB.2.21.1801282245310.16256@paninaro>
Message-ID: <CAP01uRm8Q5+AtYAmYFcRV5HBObD2AiH+osx7jLfKv-C_QXuCNQ@mail.gmail.com>

Using Achim's d this also works to generate z where FUN is a function used
to transform the index column and format is also passed to FUN.

z <- read.zoo(d, index = "time", FUN = as.yearqtr, format = "Q%q %Y")

On Sun, Jan 28, 2018 at 4:53 PM, Achim Zeileis <Achim.Zeileis at uibk.ac.at> wrote:
> On Sun, 28 Jan 2018, phil at philipsmith.ca wrote:
>
>> I have a data set with quarterly time series for several variables. The
>> time index is recorded in column 1 of the dataframe as a character vector
>> "Q1 1961", "Q2 1961","Q3 1961", "Q4 1961", "Q1 1962", etc. I want to produce
>> line plots with ggplot2, but it seems I need to convert the time index from
>> character to date class. Is that right? If so, how do I make the conversion?
>
>
> You can use the yearqtr class in the zoo package, converting with
> as.yearqtr(..., format = "Q%q %Y"). zoo also provides an autoplot() method
> for ggplot2-based time series visualizations. See ?autoplot.zoo for various
> examples.
>
> ## example data similar to your description
> d <- data.frame(sin = sin(1:8), cos = cos(1:8))
> d$time <- c("Q1 1961", "Q2 1961", "Q3 1961", "Q4 1961", "Q1 1962",
>   "Q2 1962", "Q3 1962", "Q4 1962")
>
> ## convert to zoo series
> library("zoo")
> z <- zoo(as.matrix(d[, 1:2]), as.yearqtr(d$time, "Q%q %Y"))
>
> ## ggplot2 display
> library("ggplot2")
> autoplot(z)
>
> ## with nicer axis scaling
> autoplot(z) + scale_x_yearqtr()
>
> ## some variations
> autoplot(z, facets = Series ~ .) + scale_x_yearqtr() + geom_point()
> autoplot(z, facets = NULL) + scale_x_yearqtr() + geom_point()
>
>
>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From putra_autumn86 at yahoo.com  Mon Jan 29 09:25:22 2018
From: putra_autumn86 at yahoo.com (smart hendsome)
Date: Mon, 29 Jan 2018 08:25:22 +0000 (UTC)
Subject: [R] Result show the values of fitting gamma parameter
References: <517378340.2477282.1517214322060.ref@mail.yahoo.com>
Message-ID: <517378340.2477282.1517214322060@mail.yahoo.com>

Hi,
Let say I have data by two columns A and B, and I have fit each column using the gamma distribution by 'fitdist' . I just want the result show only the shape and rate only. 

Eg:
library(fitdistrplus)

A <-c(1,2,3,4,5)

B<-c(6,7,8,9,10)

C <-cbind(A,B)
apply(C, 2, fitdist, "gamma")
Output show like this:
$A
Fitting of the distribution ' gamma ' by maximum likelihood 
Parameters:
      estimate Std. Error
shape 3.702253  2.2440052
rate  1.234126  0.8011369

$B
Fitting of the distribution ' gamma ' by maximum likelihood 
Parameters:
       estimate Std. Error
shape 31.300800   19.69176
rate   3.912649    2.48129

I want the output to be like this:
????????????? ?? A??????????????????? B
 shape 3.702253  31.300800rate  1.234126  3.912649
Can anyone solve my problem? Many thanks. 

Regards,
Zuhri




	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Mon Jan 29 11:25:44 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Mon, 29 Jan 2018 12:25:44 +0200
Subject: [R] Result show the values of fitting gamma parameter
In-Reply-To: <517378340.2477282.1517214322060@mail.yahoo.com>
References: <517378340.2477282.1517214322060.ref@mail.yahoo.com>
 <517378340.2477282.1517214322060@mail.yahoo.com>
Message-ID: <CAGgJW75Tjf4az9fPrDd5fwbP_SUu-R7YXgaGf-7h21At_L-ULw@mail.gmail.com>

Capture the results of the apply command into an object and then work with
that. Here is one way to do it:

> res <- apply(C, 2, fitdist, "gamma")
> out <- c( res$A$estimate["shape"], res$B$estimate["shape"],
res$A$estimate["rate"], res$B$estimate["rate"])
> names(out) <- c("A shape","B shape","A rate","B Rate")
> print(out)

#   A shape   B shape    A rate    B Rate
# 3.702253 31.300800  1.234126  3.912649

HTH,
Eric


On Mon, Jan 29, 2018 at 10:25 AM, smart hendsome via R-help <
r-help at r-project.org> wrote:

> Hi,
> Let say I have data by two columns A and B, and I have fit each column
> using the gamma distribution by 'fitdist' . I just want the result show
> only the shape and rate only.
>
> Eg:
> library(fitdistrplus)
>
> A <-c(1,2,3,4,5)
>
> B<-c(6,7,8,9,10)
>
> C <-cbind(A,B)
> apply(C, 2, fitdist, "gamma")
> Output show like this:
> $A
> Fitting of the distribution ' gamma ' by maximum likelihood
> Parameters:
>       estimate Std. Error
> shape 3.702253  2.2440052
> rate  1.234126  0.8011369
>
> $B
> Fitting of the distribution ' gamma ' by maximum likelihood
> Parameters:
>        estimate Std. Error
> shape 31.300800   19.69176
> rate   3.912649    2.48129
>
> I want the output to be like this:
>                  A                    B
>  shape 3.702253  31.300800rate  1.234126  3.912649
> Can anyone solve my problem? Many thanks.
>
> Regards,
> Zuhri
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Mon Jan 29 12:36:23 2018
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 29 Jan 2018 11:36:23 +0000
Subject: [R] Result show the values of fitting gamma parameter
In-Reply-To: <CAGgJW75Tjf4az9fPrDd5fwbP_SUu-R7YXgaGf-7h21At_L-ULw@mail.gmail.com>
References: <517378340.2477282.1517214322060.ref@mail.yahoo.com>
 <517378340.2477282.1517214322060@mail.yahoo.com>
 <CAGgJW75Tjf4az9fPrDd5fwbP_SUu-R7YXgaGf-7h21At_L-ULw@mail.gmail.com>
Message-ID: <66d4a12f-096b-913c-c6b0-8d31998bfbf5@sapo.pt>

Hello,

I believe the following is simpler.
It changes the OP's code a bit and uses lapply, not apply.


res2 <- lapply(C, fitdist, "gamma")
do.call(rbind, lapply(res2, `[[`, "estimate"))
#      shape     rate
#A  3.702253 1.234126
#B 31.300800 3.912649


Hope this helps,

Rui Barradas

On 1/29/2018 10:25 AM, Eric Berger wrote:
> Capture the results of the apply command into an object and then work with
> that. Here is one way to do it:
> 
>> res <- apply(C, 2, fitdist, "gamma")
>> out <- c( res$A$estimate["shape"], res$B$estimate["shape"],
> res$A$estimate["rate"], res$B$estimate["rate"])
>> names(out) <- c("A shape","B shape","A rate","B Rate")
>> print(out)
> 
> #   A shape   B shape    A rate    B Rate
> # 3.702253 31.300800  1.234126  3.912649
> 
> HTH,
> Eric
> 
> 
> On Mon, Jan 29, 2018 at 10:25 AM, smart hendsome via R-help <
> r-help at r-project.org> wrote:
> 
>> Hi,
>> Let say I have data by two columns A and B, and I have fit each column
>> using the gamma distribution by 'fitdist' . I just want the result show
>> only the shape and rate only.
>>
>> Eg:
>> library(fitdistrplus)
>>
>> A <-c(1,2,3,4,5)
>>
>> B<-c(6,7,8,9,10)
>>
>> C <-cbind(A,B)
>> apply(C, 2, fitdist, "gamma")
>> Output show like this:
>> $A
>> Fitting of the distribution ' gamma ' by maximum likelihood
>> Parameters:
>>        estimate Std. Error
>> shape 3.702253  2.2440052
>> rate  1.234126  0.8011369
>>
>> $B
>> Fitting of the distribution ' gamma ' by maximum likelihood
>> Parameters:
>>         estimate Std. Error
>> shape 31.300800   19.69176
>> rate   3.912649    2.48129
>>
>> I want the output to be like this:
>>                   A                    B
>>   shape 3.702253  31.300800rate  1.234126  3.912649
>> Can anyone solve my problem? Many thanks.
>>
>> Regards,
>> Zuhri
>>
>>
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Roger.Bivand at nhh.no  Mon Jan 29 13:24:58 2018
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 29 Jan 2018 13:24:58 +0100
Subject: [R] The R Journal, Volume 9, Issue 2
Message-ID: <alpine.LFD.2.21.1801291245030.4114@reclus.nhh.no>

Dear all,

The latest issue of The R Journal is now available at:

https://journal.r-project.org/archive/2017-2/.

New this time - quick access to news and notes 2013-to date in the 
navigation bar to the left including new Forwards and R-teaching columns; 
articles in 2017-2 may link to code and other supplementary matter from 
landing pages.

Many thanks to all contributors - especially reviewers and authors.

Best wishes,

Roger

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From ronaldo.fisher at web.de  Mon Jan 29 14:52:24 2018
From: ronaldo.fisher at web.de (ronaldo.fisher at web.de)
Date: Mon, 29 Jan 2018 14:52:24 +0100
Subject: [R] Rasterize plot in PDF output
Message-ID: <trinity-209a5ecb-cfc1-474e-a33c-135da23c1569-1517233944882@3c-app-webde-bs35>



Hello everybody out there using R,

When putting multiple plots with thousands of data points into a single PDF file, this file can get huge and take a long time to open.

The following post describes exactly the same problem in Matplotlib, as well as a nice fix for it: Matplotlib: multipage PDF with rasterized plots Particularly nice about it is, that it only rasterizes the points without rasterizing the labels. http://www.astrobetter.com/blog/2014/01/17/slim-down-your-bloated-graphics/ contains a nice example of it.

I am now looking for a similar solution in R.

stackoverflow.com/questions/8048984/plot-as-bitmap-in-pdf?rq??=1
stackoverflow.com/questions/8048984/plot-as-bitmap-in-pdf and
stackoverflow.com/questions/8048984/plot-as-bitmap-in-pdf 
all go in the right direction, but treat images which are already in raster format.


From a.antonini010 at hotmail.com  Mon Jan 29 12:49:45 2018
From: a.antonini010 at hotmail.com (a.antonini010 at hotmail.com)
Date: Mon, 29 Jan 2018 11:49:45 +0000
Subject: [R] Add ablines
Message-ID: <VI1PR06MB1759288B9032024C3F1B1E3DA5E50@VI1PR06MB1759.eurprd06.prod.outlook.com>

Good morning,
I have some problem adding ablines in Rstudio.
The lines drew by the software doesen?t match with the added values, what can I do?

pfaOK<-qcc(D[!trial], sizes=size[!trial], type="p", nsigmas=2, data.name="Polli positivi al Campylobacter")
pfaOK1<-qcc(D[!trial], sizes=size[!trial], type="p", data.name="Polli positivi al Campylobacter")

abline(h=pfaOK$limits[1], lty=1, col="red")
abline(h=pfaOK$limits[2], lty=1, col="red")

abline(h=0.02204175, col="red")
abline(h=0.1996249, col="red")

abline(h=2.204175, col="red")
abline(h=19.96249, col="red")

Thanks for the attention,
                               Arianna

Inviato da Posta<https://go.microsoft.com/fwlink/?LinkId=550986> per Windows 10


	[[alternative HTML version deleted]]


From g.white at student.unsw.edu.au  Sat Jan 27 07:03:33 2018
From: g.white at student.unsw.edu.au (Graham White)
Date: Sat, 27 Jan 2018 06:03:33 +0000
Subject: [R] [R-pkgs] New package IndexNumR: A package for computation of
	index	numbers
Message-ID: <SYXPR01MB073560D260956E1108000C07ECE70@SYXPR01MB0735.ausprd01.prod.outlook.com>

Hello useRs,

A new package, IndexNumR, has been released on CRAN.

IndexNumR provides a set of functions for computing various bilateral and multilateral indices. It is designed to compute price or quantity indices over time. Bilateral indices include Laspeyres, Paasche, Fisher, Tornqvist, Sato-Vartia, Walsh and CES, as well as elementary indices Dutot, Carli, Harmonic mean, CSWD and Jevons. All of these bilateral indices can be computed as period-on-period, fixed-base or chained.

Multilateral indices can be computed in the time series context using the GEKS methodology, and updating is provided via the window, movement or mean splice methods. The GEKS method is computed using either the Fisher or Tornqvist superlative index number methods.

The package also provides functions to compute measures of dissimilarity between time periods, which can be used to choose the linking period for chained indices.

For more information, see?https://cran.r-project.org/package=IndexNumR.?

Detailed information is contained in the package vignette at?https://cran.r-project.org/web/packages/IndexNumR/vignettes/indexnumr.html.

Issues and suggestions are welcome, and can be logged at the package Github repository https://github.com/grahamjwhite/IndexNumR.

Kind regards,?
Graham White
g.white at unswalumni.com

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From jdnewmil at dcn.davis.ca.us  Mon Jan 29 18:25:04 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 29 Jan 2018 09:25:04 -0800
Subject: [R] Add ablines
In-Reply-To: <VI1PR06MB1759288B9032024C3F1B1E3DA5E50@VI1PR06MB1759.eurprd06.prod.outlook.com>
References: <VI1PR06MB1759288B9032024C3F1B1E3DA5E50@VI1PR06MB1759.eurprd06.prod.outlook.com>
Message-ID: <94E23C14-C3B7-4236-A951-F47AD84929DB@dcn.davis.ca.us>

A) Without your data, it is very difficult to see what your problem is. You need to include both data and code to create a reproducible example. [1][2][3]

B) Please follow the guidance in the Posting Guide mentioned in the footer of every message on this list; in particular note that this is a plain text mailing list and your message will be damaged to some unpredictable extent if you don't set your email program correctly. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)
-- 
Sent from my phone. Please excuse my brevity.

On January 29, 2018 3:49:45 AM PST, "a.antonini010 at hotmail.com" <a.antonini010 at hotmail.com> wrote:
>Good morning,
>I have some problem adding ablines in Rstudio.
>The lines drew by the software doesen?t match with the added values,
>what can I do?
>
>pfaOK<-qcc(D[!trial], sizes=size[!trial], type="p", nsigmas=2,
>data.name="Polli positivi al Campylobacter")
>pfaOK1<-qcc(D[!trial], sizes=size[!trial], type="p", data.name="Polli
>positivi al Campylobacter")
>
>abline(h=pfaOK$limits[1], lty=1, col="red")
>abline(h=pfaOK$limits[2], lty=1, col="red")
>
>abline(h=0.02204175, col="red")
>abline(h=0.1996249, col="red")
>
>abline(h=2.204175, col="red")
>abline(h=19.96249, col="red")
>
>Thanks for the attention,
>                               Arianna
>
>Inviato da Posta<https://go.microsoft.com/fwlink/?LinkId=550986> per
>Windows 10
>
>
>	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Jan 29 18:59:21 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 29 Jan 2018 09:59:21 -0800
Subject: [R] Add ablines
In-Reply-To: <VI1PR06MB1759288B9032024C3F1B1E3DA5E50@VI1PR06MB1759.eurprd06.prod.outlook.com>
References: <VI1PR06MB1759288B9032024C3F1B1E3DA5E50@VI1PR06MB1759.eurprd06.prod.outlook.com>
Message-ID: <CAF8bMcaz0-9RCLnYiu98Xst2v8hEjpXXc+_zfQ_D=X6FH0NKow@mail.gmail.com>

I assume you are using the qcc package's qcc function.
example(qcc) gives an example of adding abline's to its plot:
  # add warning limits at 2 std. deviations
  q <- qcc(diameter[1:25,], type="xbar", newdata=diameter[26:40,],
plot=FALSE)
  (warn.limits <- limits.xbar(q$center, q$std.dev, q$sizes, 2))
  plot(q, restore.par = FALSE)
  abline(h = warn.limits, lty = 3, col = "chocolate")
and help(qcc) describes the 'restore.par' argument:
  restore.par: a logical value indicating whether the previous ?par?
            settings must be restored. If you need to add points, lines,
            etc. to a control chart set this to ?FALSE?.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Jan 29, 2018 at 3:49 AM, a.antonini010 at hotmail.com <
a.antonini010 at hotmail.com> wrote:

> Good morning,
> I have some problem adding ablines in Rstudio.
> The lines drew by the software doesen?t match with the added values, what
> can I do?
>
> pfaOK<-qcc(D[!trial], sizes=size[!trial], type="p", nsigmas=2, data.name="Polli
> positivi al Campylobacter")
> pfaOK1<-qcc(D[!trial], sizes=size[!trial], type="p", data.name="Polli
> positivi al Campylobacter")
>
> abline(h=pfaOK$limits[1], lty=1, col="red")
> abline(h=pfaOK$limits[2], lty=1, col="red")
>
> abline(h=0.02204175, col="red")
> abline(h=0.1996249, col="red")
>
> abline(h=2.204175, col="red")
> abline(h=19.96249, col="red")
>
> Thanks for the attention,
>                                Arianna
>
> Inviato da Posta<https://go.microsoft.com/fwlink/?LinkId=550986> per
> Windows 10
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rbaer at atsu.edu  Mon Jan 29 22:55:38 2018
From: rbaer at atsu.edu (Robert Baer)
Date: Mon, 29 Jan 2018 15:55:38 -0600
Subject: [R] Fortune candidate
In-Reply-To: <79EB7A03-2EA0-4E43-969D-72B61A6037ED@comcast.net>
References: <79EB7A03-2EA0-4E43-969D-72B61A6037ED@comcast.net>
Message-ID: <9d115e98-73ba-4315-2026-d00d3e316440@atsu.edu>

On 1/27/2018 12:16 PM, David Winsemius wrote:
> John (to a serial querulant):
>
>      ...but with such a sweeping lack of
> information from you, don't congratulate yourself if you get a helpful
> answer.  It wasn't your fault.
>
>
> David Winsemius
> Alameda, CA, USA
Second that nomination!

>
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 


--
Robert W. Baer, Ph.D.
Professor of Physiology
Kirksville College of Osteopathic Medicine
A T Still University of Health Sciences
800 W. Jefferson St
Kirksville, MO 63501
660-626-2321 Department
660-626-2965 FAX


From phil at philipsmith.ca  Tue Jan 30 03:04:18 2018
From: phil at philipsmith.ca (phil at philipsmith.ca)
Date: Mon, 29 Jan 2018 21:04:18 -0500
Subject: [R] Plotting quarterly time series
In-Reply-To: <CAP01uRm8Q5+AtYAmYFcRV5HBObD2AiH+osx7jLfKv-C_QXuCNQ@mail.gmail.com>
References: <6242b48e536032f2f4153c6791213581.squirrel@webmail.philipsmith.ca>
 <alpine.DEB.2.21.1801282245310.16256@paninaro>
 <CAP01uRm8Q5+AtYAmYFcRV5HBObD2AiH+osx7jLfKv-C_QXuCNQ@mail.gmail.com>
Message-ID: <9a00bc9415c049ad17317cbf2a4a6ad8.squirrel@webmail.philipsmith.ca>

Gentlemen,

Thank you so much for your help. You have solved my problem.

> Using Achim's d this also works to generate z where FUN is a function used
> to transform the index column and format is also passed to FUN.
>
> z <- read.zoo(d, index = "time", FUN = as.yearqtr, format = "Q%q %Y")
>
> On Sun, Jan 28, 2018 at 4:53 PM, Achim Zeileis <Achim.Zeileis at uibk.ac.at>
> wrote:
>> On Sun, 28 Jan 2018, phil at philipsmith.ca wrote:
>>
>>> I have a data set with quarterly time series for several variables. The
>>> time index is recorded in column 1 of the dataframe as a character
>>> vector
>>> "Q1 1961", "Q2 1961","Q3 1961", "Q4 1961", "Q1 1962", etc. I want to
>>> produce
>>> line plots with ggplot2, but it seems I need to convert the time index
>>> from
>>> character to date class. Is that right? If so, how do I make the
>>> conversion?
>>
>>
>> You can use the yearqtr class in the zoo package, converting with
>> as.yearqtr(..., format = "Q%q %Y"). zoo also provides an autoplot()
>> method
>> for ggplot2-based time series visualizations. See ?autoplot.zoo for
>> various
>> examples.
>>
>> ## example data similar to your description
>> d <- data.frame(sin = sin(1:8), cos = cos(1:8))
>> d$time <- c("Q1 1961", "Q2 1961", "Q3 1961", "Q4 1961", "Q1 1962",
>>   "Q2 1962", "Q3 1962", "Q4 1962")
>>
>> ## convert to zoo series
>> library("zoo")
>> z <- zoo(as.matrix(d[, 1:2]), as.yearqtr(d$time, "Q%q %Y"))
>>
>> ## ggplot2 display
>> library("ggplot2")
>> autoplot(z)
>>
>> ## with nicer axis scaling
>> autoplot(z) + scale_x_yearqtr()
>>
>> ## some variations
>> autoplot(z, facets = Series ~ .) + scale_x_yearqtr() + geom_point()
>> autoplot(z, facets = NULL) + scale_x_yearqtr() + geom_point()
>>
>>
>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>


From putra_autumn86 at yahoo.com  Tue Jan 30 06:03:17 2018
From: putra_autumn86 at yahoo.com (smart hendsome)
Date: Tue, 30 Jan 2018 05:03:17 +0000 (UTC)
Subject: [R] Simulation based on runif to get mean
References: <970980663.3360398.1517288597672.ref@mail.yahoo.com>
Message-ID: <970980663.3360398.1517288597672@mail.yahoo.com>

Hello everyone,
I have a question regarding simulating based on runif.? Let say I have generated matrix A and B based on runif. Then I find mean for each matrix A and matrix B.? I want this process to be done let say 10 times. Anyone can help me.? Actually I want make the function that I can play around with the number of simulation process that I want. Thanks.
Eg:
a <- matrix(runif(5,1, 10))

b <- matrix(runif(5,10, 20))

c <- cbind(a,b); c

mn <- apply(c,2,mean); mn

Regards,
Zuhri

	[[alternative HTML version deleted]]


From djnordlund at gmail.com  Tue Jan 30 09:58:40 2018
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Tue, 30 Jan 2018 00:58:40 -0800
Subject: [R] Simulation based on runif to get mean
In-Reply-To: <970980663.3360398.1517288597672@mail.yahoo.com>
References: <970980663.3360398.1517288597672.ref@mail.yahoo.com>
 <970980663.3360398.1517288597672@mail.yahoo.com>
Message-ID: <fc0ab289-a561-a46d-682a-f29ab88d63e4@gmail.com>

On 1/29/2018 9:03 PM, smart hendsome via R-help wrote:
> Hello everyone,
> I have a question regarding simulating based on runif.? Let say I have generated matrix A and B based on runif. Then I find mean for each matrix A and matrix B.? I want this process to be done let say 10 times. Anyone can help me.? Actually I want make the function that I can play around with the number of simulation process that I want. Thanks.
> Eg:
> a <- matrix(runif(5,1, 10))
> 
> b <- matrix(runif(5,10, 20))
> 
> c <- cbind(a,b); c
> 
> mn <- apply(c,2,mean); mn
> 
> Regards,
> Zuhri
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Here is a straight forward implementation of your code in a function 
with a parameter for the number simulations you want to run.

sim <- function(n){
   mn <- matrix(0,n, 2)
   for(i in 1:n) {
     a <- runif(5,1, 10)
     b <- runif(5,10, 20)
     c <- cbind(a,b)
     mn[i,] <- apply(c, 2, mean)
     }
   return(mn)
   }
# run 10 iterations
sim(10)

In your case, there doesn't seem to be a need to create a and b as 
matrices; vectors work just as well.  Also, several of the statements 
could be combined into one.  Whether this meets your needs depends on 
what your real world task actually is.


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From ruipbarradas at sapo.pt  Tue Jan 30 11:03:02 2018
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 30 Jan 2018 10:03:02 +0000
Subject: [R] Simulation based on runif to get mean
In-Reply-To: <fc0ab289-a561-a46d-682a-f29ab88d63e4@gmail.com>
References: <970980663.3360398.1517288597672.ref@mail.yahoo.com>
 <970980663.3360398.1517288597672@mail.yahoo.com>
 <fc0ab289-a561-a46d-682a-f29ab88d63e4@gmail.com>
Message-ID: <b63a4cae-9c22-841e-d45f-f109edeee63d@sapo.pt>

Hello,

Another way would be to use ?replicate and ?colMeans.


set.seed(2511)    # Make the results reproducible

fun <- function(n){
     f <- function(){
         a <- runif(5, 1, 10)
         b <- runif(5, 10, 20)
         colMeans(cbind(a, b))
     }
     replicate(n, f())
}

fun(10)

Hope this helps,

Rui Barradas

On 1/30/2018 8:58 AM, Daniel Nordlund wrote:
> On 1/29/2018 9:03 PM, smart hendsome via R-help wrote:
>> Hello everyone,
>> I have a question regarding simulating based on runif.? Let say I have 
>> generated matrix A and B based on runif. Then I find mean for each 
>> matrix A and matrix B.? I want this process to be done let say 10 
>> times. Anyone can help me.? Actually I want make the function that I 
>> can play around with the number of simulation process that I want. 
>> Thanks.
>> Eg:
>> a <- matrix(runif(5,1, 10))
>>
>> b <- matrix(runif(5,10, 20))
>>
>> c <- cbind(a,b); c
>>
>> mn <- apply(c,2,mean); mn
>>
>> Regards,
>> Zuhri
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> Here is a straight forward implementation of your code in a function 
> with a parameter for the number simulations you want to run.
> 
> sim <- function(n){
>  ? mn <- matrix(0,n, 2)
>  ? for(i in 1:n) {
>  ??? a <- runif(5,1, 10)
>  ??? b <- runif(5,10, 20)
>  ??? c <- cbind(a,b)
>  ??? mn[i,] <- apply(c, 2, mean)
>  ??? }
>  ? return(mn)
>  ? }
> # run 10 iterations
> sim(10)
> 
> In your case, there doesn't seem to be a need to create a and b as 
> matrices; vectors work just as well.? Also, several of the statements 
> could be combined into one.? Whether this meets your needs depends on 
> what your real world task actually is.
> 
> 
> Hope this is helpful,
> 
> Dan
>


From ericjberger at gmail.com  Tue Jan 30 11:12:36 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Tue, 30 Jan 2018 12:12:36 +0200
Subject: [R] Simulation based on runif to get mean
In-Reply-To: <b63a4cae-9c22-841e-d45f-f109edeee63d@sapo.pt>
References: <970980663.3360398.1517288597672.ref@mail.yahoo.com>
 <970980663.3360398.1517288597672@mail.yahoo.com>
 <fc0ab289-a561-a46d-682a-f29ab88d63e4@gmail.com>
 <b63a4cae-9c22-841e-d45f-f109edeee63d@sapo.pt>
Message-ID: <CAGgJW76Qi0CkDTVsNMYheV_66nPXQzO9rkdkyARxaaeQGQvVgQ@mail.gmail.com>

Or a shorter version of Rui's approach:

set.seed(2511)    # Make the results reproducible
fun <- function(n){
  f <- function(){
    c(mean(runif(5,1,10)),mean(runif(5,10,20)))
  }
  replicate(n, f())
}
fun(10)

On Tue, Jan 30, 2018 at 12:03 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Another way would be to use ?replicate and ?colMeans.
>
>
> set.seed(2511)    # Make the results reproducible
>
> fun <- function(n){
>     f <- function(){
>         a <- runif(5, 1, 10)
>         b <- runif(5, 10, 20)
>         colMeans(cbind(a, b))
>     }
>     replicate(n, f())
> }
>
> fun(10)
>
> Hope this helps,
>
> Rui Barradas
>
>
> On 1/30/2018 8:58 AM, Daniel Nordlund wrote:
>
>> On 1/29/2018 9:03 PM, smart hendsome via R-help wrote:
>>
>>> Hello everyone,
>>> I have a question regarding simulating based on runif.  Let say I have
>>> generated matrix A and B based on runif. Then I find mean for each matrix A
>>> and matrix B.  I want this process to be done let say 10 times. Anyone can
>>> help me.  Actually I want make the function that I can play around with the
>>> number of simulation process that I want. Thanks.
>>> Eg:
>>> a <- matrix(runif(5,1, 10))
>>>
>>> b <- matrix(runif(5,10, 20))
>>>
>>> c <- cbind(a,b); c
>>>
>>> mn <- apply(c,2,mean); mn
>>>
>>> Regards,
>>> Zuhri
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> Here is a straight forward implementation of your code in a function with
>> a parameter for the number simulations you want to run.
>>
>> sim <- function(n){
>>    mn <- matrix(0,n, 2)
>>    for(i in 1:n) {
>>      a <- runif(5,1, 10)
>>      b <- runif(5,10, 20)
>>      c <- cbind(a,b)
>>      mn[i,] <- apply(c, 2, mean)
>>      }
>>    return(mn)
>>    }
>> # run 10 iterations
>> sim(10)
>>
>> In your case, there doesn't seem to be a need to create a and b as
>> matrices; vectors work just as well.  Also, several of the statements could
>> be combined into one.  Whether this meets your needs depends on what your
>> real world task actually is.
>>
>>
>> Hope this is helpful,
>>
>> Dan
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From vito.muggeo at unipa.it  Tue Jan 30 12:11:56 2018
From: vito.muggeo at unipa.it (Vito M. R. Muggeo)
Date: Tue, 30 Jan 2018 12:11:56 +0100
Subject: [R] variable names in lm formula ~.
Message-ID: <85753698-435f-a28b-a97b-049e09bb896c@unipa.it>

dear all,
Is the following intentional? Am I missing anything in documentation?

d<-data.frame(y=rnorm(10,5,.5),exp=rnorm(10), age=rnorm(10))
formula(lm(exp(y)~exp+age, data=d))
#--> exp(y) ~ exp + age

formula(lm(exp(y)~., data=d))
#--> exp(y) ~ age

variable 'exp' (maybe indicating "experience") is not included in the 
model. The same happens with 'log' (and other function names, I suppose..)

best,
vito


-- 
==============================================
Vito M.R. Muggeo
Dip.to Sc Econom, Az e Statistiche
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 23895240
fax: 091 485726
http://dssm.unipa.it/vmuggeo
Associate Editor, Statistical Modelling
Chair, Statistical Modelling Society


From ruipbarradas at sapo.pt  Tue Jan 30 12:17:11 2018
From: ruipbarradas at sapo.pt (ruipbarradas)
Date: Tue, 30 Jan 2018 11:17:11 +0000
Subject: [R] Simulation based on runif to get mean
Message-ID: <fx95vw3lld5wbc0uo5hftl7g.1517311031112@email.android.com>

Hello,
Right. Missed that one.
Rui Barradas


Enviado a partir do meu smartphone Samsung Galaxy.-------- Mensagem original --------De: Eric Berger <ericjberger at gmail.com> Data: 30/01/2018  10:12  (GMT+00:00) Para: Rui Barradas <ruipbarradas at sapo.pt> Cc: Daniel Nordlund <djnordlund at gmail.com>, smart hendsome <putra_autumn86 at yahoo.com>, r-help at r-project.org Assunto: Re: [R] Simulation based on runif to get mean 
Or a shorter version of Rui's approach:
set.seed(2511)? ? # Make the results reproduciblefun <- function(n){? f <- function(){? ? c(mean(runif(5,1,10)),mean(runif(5,10,20)))? }? replicate(n, f())}fun(10)
On Tue, Jan 30, 2018 at 12:03 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
Hello,



Another way would be to use ?replicate and ?colMeans.





set.seed(2511)? ? # Make the results reproducible



fun <- function(n){

? ? f <- function(){

? ? ? ? a <- runif(5, 1, 10)

? ? ? ? b <- runif(5, 10, 20)

? ? ? ? colMeans(cbind(a, b))

? ? }

? ? replicate(n, f())

}



fun(10)



Hope this helps,



Rui Barradas



On 1/30/2018 8:58 AM, Daniel Nordlund wrote:


On 1/29/2018 9:03 PM, smart hendsome via R-help wrote:


Hello everyone,

I have a question regarding simulating based on runif.? Let say I have generated matrix A and B based on runif. Then I find mean for each matrix A and matrix B.? I want this process to be done let say 10 times. Anyone can help me.? Actually I want make the function that I can play around with the number of simulation process that I want. Thanks.

Eg:

a <- matrix(runif(5,1, 10))



b <- matrix(runif(5,10, 20))



c <- cbind(a,b); c



mn <- apply(c,2,mean); mn



Regards,

Zuhri



????[[alternative HTML version deleted]]



______________________________________________

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.






Here is a straight forward implementation of your code in a function with a parameter for the number simulations you want to run.



sim <- function(n){

?? mn <- matrix(0,n, 2)

?? for(i in 1:n) {

???? a <- runif(5,1, 10)

???? b <- runif(5,10, 20)

???? c <- cbind(a,b)

???? mn[i,] <- apply(c, 2, mean)

???? }

?? return(mn)

?? }

# run 10 iterations

sim(10)



In your case, there doesn't seem to be a need to create a and b as matrices; vectors work just as well.? Also, several of the statements could be combined into one.? Whether this meets your needs depends on what your real world task actually is.





Hope this is helpful,



Dan






______________________________________________

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From retour.client.contact at gmail.com  Tue Jan 30 11:14:49 2018
From: retour.client.contact at gmail.com (contact retour-client)
Date: Tue, 30 Jan 2018 11:14:49 +0100
Subject: [R] Could the Odds represent weight in Generalized Linear Model?
Message-ID: <CAFJ7Sp8uySc-tHsA3B0yPvQV_RT97zNipbcW7pYSXDtev7L+aQ@mail.gmail.com>

Hello all,


I'm sorry if my question seems basic.

Im studying a responses (Yes,No) in a survey and, thanks to GLM I obtain
the following relation with my variables : (Yes,No)~ ?0 + Age We note this
this certain type of (Yes,No) response is linked to age (p<0.05 in glm) .

After that we calculated :

model1=glm(cbind(Yes,No) ~ Age + Times + Type, family=binomial)
summary(model1)
exp(model1$coefficients)

exp(model1$coefficients)(Intercept)         Age       Times TypeRegular
 0.01659381  1.02546748  1.01544154  1.70056425

The odds of answering 'Yes' is multiplied with 1.02 for each additional
year of age.

My questions is :

(1) it is possible to add to my model, (Yes,No)~ ?0 + Age, the weight of
the variable Age. Is it in fact the odd value ? Here is an example : is it
ok to formulate my model as that (Yes,No)~ ?0 + 1.02* Age: here 1.02 is
what I call weight of age, in other words, I want to quantify its impact in
the model.

(2)suppose I want to model (Yes,No)~ ?0 + Type with type a categorical
data. odd value of TypeRegular is 1.70056425. But in my model it is simply
Type that include Regular and Irregular. How to adapt this value to Type ?

My data

res=structure(list(Age = c(10, 14, 14, 15, 16, 16, 16, 17, 17, 17, 17,
18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 20,
20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 22, 22,
22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23,
23, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26,
26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27,
27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29,
29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31,
31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33,
33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35,
35, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37,
37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38,
38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40,
40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42,
42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,
43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45,
45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47,
47, 47, 47, 48, 48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 50,
50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,
51, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 52,
52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,
53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55,
55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,
57, 57, 57, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 59,
59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 60, 60, 61, 62, 62, 62, 62,
63, 64, 64, 65, 65, 67, 74), Times = c(6L, 6L, 16L, 6L, 9L, 23L, 33L,
6L, 14L, 17L, 36L, 4L, 9L, 15L, 20L, 26L, 28L, 30L, 33L, 6L, 11L, 14L,
20L, 26L, 28L, 30L, 32L, 4L, 4L, 6L, 9L, 17L, 26L, 28L, 30L, 33L, 44L,
47L, 4L, 6L, 23L, 26L, 32L, 4L, 9L, 11L, 11L, 14L, 14L, 15L, 17L, 18L,
20L, 23L, 26L, 36L, 44L, 50L, 4L, 9L, 28L, 30L, 32L, 4L, 17L, 23L, 4L,
6L, 9L, 9L, 11L, 14L, 25L, 33L, 33L, 51L, 4L, 6L, 14L, 17L, 18L, 26L,
28L, 30L, 32L, 33L, 44L, 50L, 6L, 9L, 9L, 11L, 14L, 17L, 22L, 23L,
30L, 4L, 9L, 11L, 14L, 15L, 20L, 23L, 28L, 29L, 36L, 39L, 43L, 51L,
58L, 14L, 20L, 23L, 26L, 28L, 36L, 51L, 4L, 6L, 9L, 16L, 17L, 18L,
23L, 33L, 37L, 51L, 9L, 11L, 14L, 18L, 23L, 26L, 28L, 58L, 9L, 17L,
33L, 36L, 37L, 58L, 4L, 6L, 9L, 9L, 11L, 17L, 20L, 26L, 28L, 32L, 33L,
47L, 4L, 6L, 9L, 15L, 23L, 28L, 4L, 9L, 9L, 15L, 17L, 18L, 20L, 23L,
28L, 30L, 30L, 4L, 6L, 6L, 9L, 17L, 18L, 33L, 36L, 4L, 6L, 11L, 14L,
15L, 17L, 23L, 26L, 28L, 36L, 4L, 6L, 9L, 11L, 17L, 18L, 23L, 25L,
28L, 30L, 6L, 9L, 11L, 14L, 14L, 17L, 20L, 23L, 28L, 35L, 44L, 4L, 6L,
9L, 14L, 17L, 44L, 6L, 9L, 14L, 17L, 22L, 26L, 28L, 29L, 33L, 36L,
50L, 4L, 6L, 6L, 17L, 20L, 23L, 28L, 30L, 36L, 51L, 58L, 4L, 9L, 9L,
14L, 15L, 17L, 23L, 26L, 28L, 30L, 36L, 38L, 6L, 6L, 9L, 17L, 23L,
26L, 28L, 43L, 44L, 4L, 15L, 17L, 17L, 25L, 26L, 28L, 36L, 44L, 51L,
58L, 6L, 9L, 16L, 25L, 28L, 32L, 44L, 58L, 4L, 9L, 17L, 28L, 30L, 36L,
43L, 44L, 6L, 11L, 14L, 16L, 26L, 30L, 44L, 15L, 20L, 23L, 26L, 28L,
52L, 4L, 6L, 9L, 9L, 11L, 14L, 16L, 17L, 20L, 23L, 26L, 28L, 30L, 33L,
35L, 37L, 50L, 51L, 6L, 9L, 14L, 17L, 18L, 18L, 26L, 44L, 50L, 9L,
14L, 14L, 15L, 18L, 20L, 23L, 28L, 33L, 36L, 43L, 44L, 50L, 4L, 9L,
11L, 14L, 18L, 26L, 28L, 29L, 30L, 32L, 43L, 44L, 52L, 6L, 9L, 20L,
23L, 28L, 30L, 33L, 36L, 43L, 4L, 9L, 11L, 14L, 16L, 20L, 23L, 26L,
28L, 36L, 50L, 51L, 4L, 6L, 9L, 14L, 18L, 23L, 26L, 30L, 36L, 43L,
44L, 52L, 6L, 9L, 17L, 18L, 23L, 26L, 28L, 30L, 35L, 9L, 14L, 20L,
32L, 33L, 36L, 44L, 6L, 9L, 23L, 25L, 36L, 51L, 9L, 17L, 17L, 18L,
20L, 33L, 58L, 9L, 23L, 26L, 28L, 36L, 6L, 20L, 28L, 20L, 23L, 4L,
15L), Type = c("Regular", "Regular", "Irregular", "Regular",
"Regular", "Irregular", "Regular", "Irregular", "Irregular",
"Irregular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Irregular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Irregular", "Regular", "Regular",
"Irregular", "Regular", "Irregular", "Regular", "Regular", "Regular",
"Irregular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Irregular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Irregular",
"Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Irregular", "Regular", "Irregular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
"Regular", "Irregular", "Regular", "Regular", "Regular", "Irregular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Irregular", "Regular", "Irregular",
"Regular", "Regular", "Irregular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Irregular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
"Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Irregular", "Irregular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Irregular", "Regular", "Regular",
"Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Irregular", "Irregular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Irregular", "Regular", "Irregular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Irregular", "Irregular", "Irregular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
"Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Irregular", "Regular", "Regular", "Regular", "Irregular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Irregular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
"Irregular", "Regular", "Regular", "Regular", "Irregular", "Regular",
"Regular", "Regular", "Regular", "Irregular", "Regular", "Regular",
"Regular", "Regular", "Regular", "Irregular", "Regular", "Regular",
"Regular", "Irregular", "Regular", "Regular"), Yes = c(0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L,
0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L,
1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 2L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L,
1L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 2L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L,
0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), No = c(1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 0L, 1L, 1L, 1L, 1L,
2L, 1L, 1L, 1L, 1L, 1L, 3L, 0L, 1L, 1L, 1L, 1L, 1L, 5L, 1L, 1L, 1L,
1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 3L, 1L, 2L, 1L, 1L,
1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 2L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L,
3L, 1L, 2L, 2L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 0L, 1L, 1L, 1L, 2L,
1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 1L, 3L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 2L, 1L, 1L, 1L, 1L, 0L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 5L, 1L, 1L, 0L, 3L,
1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 3L, 2L, 1L, 2L, 0L, 1L, 1L, 1L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 3L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
0L, 1L, 1L, 1L, 0L, 1L, 2L, 1L, 1L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 0L, 1L, 1L, 1L, 2L, 1L, 1L, 0L, 1L, 2L, 1L, 2L, 1L, 1L,
1L, 2L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 3L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 0L, 3L, 1L, 1L, 1L, 1L, 1L, 2L, 0L, 2L, 4L, 1L, 3L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
2L, 2L, 2L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L)),
.Names = c("Age", "Times", "Type", "Yes", "No"), row.names = c(NA,
-426L), class = "data.frame")

Thansk a lot for your help.


Lenny

<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Garanti
sans virus. www.avg.com
<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From j.bayat194 at gmail.com  Tue Jan 30 08:10:02 2018
From: j.bayat194 at gmail.com (javad bayat)
Date: Tue, 30 Jan 2018 10:40:02 +0330
Subject: [R] Calculating angle of a polyline
Message-ID: <CANTxAmL_EqL-n1cFANob_4227C+aDHtKrgnS=6u1SZW6vTmB7Q@mail.gmail.com>

Dear R users
I am trying to find a formula to calculate the angle of a polyline. Is
there a way to do this?
Many thanks.

-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Jan 30 15:23:31 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 30 Jan 2018 06:23:31 -0800
Subject: [R] variable names in lm formula ~.
In-Reply-To: <85753698-435f-a28b-a97b-049e09bb896c@unipa.it>
References: <85753698-435f-a28b-a97b-049e09bb896c@unipa.it>
Message-ID: <80E78752-2349-4BD2-BA7D-85DB731E10B2@dcn.davis.ca.us>

Functions are first class objects, so some kind of collision is bound to happen if you do this... so don't. 
-- 
Sent from my phone. Please excuse my brevity.

On January 30, 2018 3:11:56 AM PST, "Vito M. R. Muggeo" <vito.muggeo at unipa.it> wrote:
>dear all,
>Is the following intentional? Am I missing anything in documentation?
>
>d<-data.frame(y=rnorm(10,5,.5),exp=rnorm(10), age=rnorm(10))
>formula(lm(exp(y)~exp+age, data=d))
>#--> exp(y) ~ exp + age
>
>formula(lm(exp(y)~., data=d))
>#--> exp(y) ~ age
>
>variable 'exp' (maybe indicating "experience") is not included in the 
>model. The same happens with 'log' (and other function names, I
>suppose..)
>
>best,
>vito


From jdnewmil at dcn.davis.ca.us  Tue Jan 30 15:34:04 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 30 Jan 2018 06:34:04 -0800
Subject: [R] Calculating angle of a polyline
In-Reply-To: <CANTxAmL_EqL-n1cFANob_4227C+aDHtKrgnS=6u1SZW6vTmB7Q@mail.gmail.com>
References: <CANTxAmL_EqL-n1cFANob_4227C+aDHtKrgnS=6u1SZW6vTmB7Q@mail.gmail.com>
Message-ID: <0AB8EE08-1441-4171-B85F-B74427AE9E1A@dcn.davis.ca.us>

A polyline by definition has many angles, so your question is ill-formed. And this is a question about math, not R, so is off topic here. I suggest reading Wikipedia.
-- 
Sent from my phone. Please excuse my brevity.

On January 29, 2018 11:10:02 PM PST, javad bayat <j.bayat194 at gmail.com> wrote:
>Dear R users
>I am trying to find a formula to calculate the angle of a polyline. Is
>there a way to do this?
>Many thanks.


From retour.client.contact at gmail.com  Tue Jan 30 15:46:32 2018
From: retour.client.contact at gmail.com (contact retour-client)
Date: Tue, 30 Jan 2018 15:46:32 +0100
Subject: [R] Could the Odds represent weight in Generalized Linear Model?
In-Reply-To: <CAJuCY5yzc6ciu-wyRf_UYui0bvPxv+TuTpBzA0Snrsnar1kK9A@mail.gmail.com>
References: <CAFJ7Sp8uySc-tHsA3B0yPvQV_RT97zNipbcW7pYSXDtev7L+aQ@mail.gmail.com>
 <CAJuCY5yzc6ciu-wyRf_UYui0bvPxv+TuTpBzA0Snrsnar1kK9A@mail.gmail.com>
Message-ID: <CAFJ7Sp_TV7UkUnkiYumr=b8FZm0-=pS1H3p_Mv3fnAv2BevZSw@mail.gmail.com>

Dear Thierry,

Thanks a lot for this answer,

I mean i want to obtain such model *Behavior1 = ?0+?1*Age* , the purpose is
to obtain  *?1*. I want to be sure that the odds value could be the  ?1. Or
how to calculate it ?

Thanks again for your precious help.

Lenny

<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Garanti
sans virus. www.avg.com
<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

2018-01-30 15:37 GMT+01:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear Lenny,
>
> You can do this by using Age as an offset factor.
>
> dataset$wAge <- dataset$Age * 1.02
> glm(cbind(Yes,No) ~ offset(wAge) + Times + Type, family=binomial, data =
> dataset)
>
> Best regards,
>
>
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88
> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
> 1000 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
> <https://www.inbo.be>
>
> 2018-01-30 11:14 GMT+01:00 contact retour-client <
> retour.client.contact at gmail.com>:
>
>> Hello all,
>>
>>
>> I'm sorry if my question seems basic.
>>
>> Im studying a responses (Yes,No) in a survey and, thanks to GLM I obtain
>> the following relation with my variables : (Yes,No)~ ?0 + Age We note this
>> this certain type of (Yes,No) response is linked to age (p<0.05 in glm) .
>>
>> After that we calculated :
>>
>> model1=glm(cbind(Yes,No) ~ Age + Times + Type, family=binomial)
>> summary(model1)
>> exp(model1$coefficients)
>>
>> exp(model1$coefficients)(Intercept)         Age       Times TypeRegular
>>  0.01659381  1.02546748  1.01544154  1.70056425
>>
>> The odds of answering 'Yes' is multiplied with 1.02 for each additional
>> year of age.
>>
>> My questions is :
>>
>> (1) it is possible to add to my model, (Yes,No)~ ?0 + Age, the weight of
>> the variable Age. Is it in fact the odd value ? Here is an example : is it
>> ok to formulate my model as that (Yes,No)~ ?0 + 1.02* Age: here 1.02 is
>> what I call weight of age, in other words, I want to quantify its impact
>> in
>> the model.
>>
>> (2)suppose I want to model (Yes,No)~ ?0 + Type with type a categorical
>> data. odd value of TypeRegular is 1.70056425. But in my model it is simply
>> Type that include Regular and Irregular. How to adapt this value to Type ?
>>
>> My data
>>
>> res=structure(list(Age = c(10, 14, 14, 15, 16, 16, 16, 17, 17, 17, 17,
>> 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 20,
>> 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 22, 22,
>> 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23,
>> 23, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26,
>> 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27,
>> 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29,
>> 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31,
>> 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33,
>> 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35,
>> 35, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37,
>> 37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38,
>> 38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40,
>> 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42,
>> 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,
>> 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45,
>> 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47,
>> 47, 47, 47, 48, 48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 50,
>> 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,
>> 51, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 52,
>> 52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,
>> 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55,
>> 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,
>> 57, 57, 57, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 59,
>> 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 60, 60, 61, 62, 62, 62, 62,
>> 63, 64, 64, 65, 65, 67, 74), Times = c(6L, 6L, 16L, 6L, 9L, 23L, 33L,
>> 6L, 14L, 17L, 36L, 4L, 9L, 15L, 20L, 26L, 28L, 30L, 33L, 6L, 11L, 14L,
>> 20L, 26L, 28L, 30L, 32L, 4L, 4L, 6L, 9L, 17L, 26L, 28L, 30L, 33L, 44L,
>> 47L, 4L, 6L, 23L, 26L, 32L, 4L, 9L, 11L, 11L, 14L, 14L, 15L, 17L, 18L,
>> 20L, 23L, 26L, 36L, 44L, 50L, 4L, 9L, 28L, 30L, 32L, 4L, 17L, 23L, 4L,
>> 6L, 9L, 9L, 11L, 14L, 25L, 33L, 33L, 51L, 4L, 6L, 14L, 17L, 18L, 26L,
>> 28L, 30L, 32L, 33L, 44L, 50L, 6L, 9L, 9L, 11L, 14L, 17L, 22L, 23L,
>> 30L, 4L, 9L, 11L, 14L, 15L, 20L, 23L, 28L, 29L, 36L, 39L, 43L, 51L,
>> 58L, 14L, 20L, 23L, 26L, 28L, 36L, 51L, 4L, 6L, 9L, 16L, 17L, 18L,
>> 23L, 33L, 37L, 51L, 9L, 11L, 14L, 18L, 23L, 26L, 28L, 58L, 9L, 17L,
>> 33L, 36L, 37L, 58L, 4L, 6L, 9L, 9L, 11L, 17L, 20L, 26L, 28L, 32L, 33L,
>> 47L, 4L, 6L, 9L, 15L, 23L, 28L, 4L, 9L, 9L, 15L, 17L, 18L, 20L, 23L,
>> 28L, 30L, 30L, 4L, 6L, 6L, 9L, 17L, 18L, 33L, 36L, 4L, 6L, 11L, 14L,
>> 15L, 17L, 23L, 26L, 28L, 36L, 4L, 6L, 9L, 11L, 17L, 18L, 23L, 25L,
>> 28L, 30L, 6L, 9L, 11L, 14L, 14L, 17L, 20L, 23L, 28L, 35L, 44L, 4L, 6L,
>> 9L, 14L, 17L, 44L, 6L, 9L, 14L, 17L, 22L, 26L, 28L, 29L, 33L, 36L,
>> 50L, 4L, 6L, 6L, 17L, 20L, 23L, 28L, 30L, 36L, 51L, 58L, 4L, 9L, 9L,
>> 14L, 15L, 17L, 23L, 26L, 28L, 30L, 36L, 38L, 6L, 6L, 9L, 17L, 23L,
>> 26L, 28L, 43L, 44L, 4L, 15L, 17L, 17L, 25L, 26L, 28L, 36L, 44L, 51L,
>> 58L, 6L, 9L, 16L, 25L, 28L, 32L, 44L, 58L, 4L, 9L, 17L, 28L, 30L, 36L,
>> 43L, 44L, 6L, 11L, 14L, 16L, 26L, 30L, 44L, 15L, 20L, 23L, 26L, 28L,
>> 52L, 4L, 6L, 9L, 9L, 11L, 14L, 16L, 17L, 20L, 23L, 26L, 28L, 30L, 33L,
>> 35L, 37L, 50L, 51L, 6L, 9L, 14L, 17L, 18L, 18L, 26L, 44L, 50L, 9L,
>> 14L, 14L, 15L, 18L, 20L, 23L, 28L, 33L, 36L, 43L, 44L, 50L, 4L, 9L,
>> 11L, 14L, 18L, 26L, 28L, 29L, 30L, 32L, 43L, 44L, 52L, 6L, 9L, 20L,
>> 23L, 28L, 30L, 33L, 36L, 43L, 4L, 9L, 11L, 14L, 16L, 20L, 23L, 26L,
>> 28L, 36L, 50L, 51L, 4L, 6L, 9L, 14L, 18L, 23L, 26L, 30L, 36L, 43L,
>> 44L, 52L, 6L, 9L, 17L, 18L, 23L, 26L, 28L, 30L, 35L, 9L, 14L, 20L,
>> 32L, 33L, 36L, 44L, 6L, 9L, 23L, 25L, 36L, 51L, 9L, 17L, 17L, 18L,
>> 20L, 33L, 58L, 9L, 23L, 26L, 28L, 36L, 6L, 20L, 28L, 20L, 23L, 4L,
>> 15L), Type = c("Regular", "Regular", "Irregular", "Regular",
>> "Regular", "Irregular", "Regular", "Irregular", "Irregular",
>> "Irregular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Irregular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Irregular", "Regular", "Regular",
>> "Irregular", "Regular", "Irregular", "Regular", "Regular", "Regular",
>> "Irregular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Irregular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Irregular",
>> "Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Irregular", "Regular", "Irregular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Irregular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Irregular", "Regular", "Irregular",
>> "Regular", "Regular", "Irregular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Irregular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Irregular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Irregular", "Regular", "Regular",
>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Irregular", "Irregular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Irregular", "Regular", "Irregular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Irregular", "Irregular", "Irregular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Irregular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Irregular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>> "Irregular", "Regular", "Regular", "Regular", "Irregular", "Regular",
>> "Regular", "Regular", "Regular", "Irregular", "Regular", "Regular",
>> "Regular", "Regular", "Regular", "Irregular", "Regular", "Regular",
>> "Regular", "Irregular", "Regular", "Regular"), Yes = c(0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L,
>> 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L,
>> 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 2L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L,
>> 1L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 2L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L,
>> 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), No = c(1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>> 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 0L, 1L, 1L, 1L, 1L,
>> 2L, 1L, 1L, 1L, 1L, 1L, 3L, 0L, 1L, 1L, 1L, 1L, 1L, 5L, 1L, 1L, 1L,
>> 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 3L, 1L, 2L, 1L, 1L,
>> 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 2L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L,
>> 3L, 1L, 2L, 2L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 0L, 1L, 1L, 1L, 2L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
>> 1L, 1L, 3L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 2L, 1L, 1L, 1L, 1L, 0L, 0L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 5L, 1L, 1L, 0L, 3L,
>> 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 3L, 2L, 1L, 2L, 0L, 1L, 1L, 1L, 0L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 3L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 0L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
>> 0L, 1L, 1L, 1L, 0L, 1L, 2L, 1L, 1L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 0L, 0L, 1L, 1L, 1L, 2L, 1L, 1L, 0L, 1L, 2L, 1L, 2L, 1L, 1L,
>> 1L, 2L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L,
>> 1L, 1L, 1L, 1L, 3L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
>> 1L, 1L, 0L, 3L, 1L, 1L, 1L, 1L, 1L, 2L, 0L, 2L, 4L, 1L, 3L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 2L, 2L, 2L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L)),
>> .Names = c("Age", "Times", "Type", "Yes", "No"), row.names = c(NA,
>> -426L), class = "data.frame")
>>
>> Thansk a lot for your help.
>>
>>
>> Lenny
>>
>> <http://www.avg.com/email-signature?utm_medium=email&utm_
>> source=link&utm_campaign=sig-email&utm_content=webmail>
>> Garanti
>> sans virus. www.avg.com
>> <http://www.avg.com/email-signature?utm_medium=email&utm_
>> source=link&utm_campaign=sig-email&utm_content=webmail>
>> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Tue Jan 30 16:09:31 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Tue, 30 Jan 2018 17:09:31 +0200
Subject: [R] Calculating angle of a polyline
In-Reply-To: <0AB8EE08-1441-4171-B85F-B74427AE9E1A@dcn.davis.ca.us>
References: <CANTxAmL_EqL-n1cFANob_4227C+aDHtKrgnS=6u1SZW6vTmB7Q@mail.gmail.com>
 <0AB8EE08-1441-4171-B85F-B74427AE9E1A@dcn.davis.ca.us>
Message-ID: <CAGgJW77QKGQQthuH_m74ThNxeP1oquUbsxqdKf6fcBCeAAnY0Q@mail.gmail.com>

Assuming your polyline is defined by two vectors, one for the x
coordinates, one for the y coordinates, you can try the following

library(NISTunits)
polyangles <- function(xV,yV) {
  stopifnot( (length(xV)==length(yV)) && (length(xV) >= 3))
  v <- function(i) { c( xV[i]-xV[i-1], yV[i]-yV[i-1])}
  vlen <- function(v) { sqrt(sum(v*v)) }

  lV <- rep(NA_real_,length(xV))
  for ( i in 2:(length(xV)-1) )
    lV[i] <- acos( sum(v(i)*v(i+1))/(vlen(v(i))*vlen(v(i+1))) )
  angleV <- NISTunits::NISTradianTOdeg(lV)
  angleV
}

# example
x <- c(0:3)
y <- c(0,0,1,1)
polyangles( x, y )

# NA 45.0 45.0 NA

Note, I have included the NA's at the beginning and end of the polyline as
a reminder that there is no angle defined there.

HTH,
Eric


On Tue, Jan 30, 2018 at 4:34 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> A polyline by definition has many angles, so your question is ill-formed.
> And this is a question about math, not R, so is off topic here. I suggest
> reading Wikipedia.
> --
> Sent from my phone. Please excuse my brevity.
>
> On January 29, 2018 11:10:02 PM PST, javad bayat <j.bayat194 at gmail.com>
> wrote:
> >Dear R users
> >I am trying to find a formula to calculate the angle of a polyline. Is
> >there a way to do this?
> >Many thanks.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jan 30 17:12:09 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 30 Jan 2018 08:12:09 -0800
Subject: [R] variable names in lm formula ~.
In-Reply-To: <80E78752-2349-4BD2-BA7D-85DB731E10B2@dcn.davis.ca.us>
References: <85753698-435f-a28b-a97b-049e09bb896c@unipa.it>
 <80E78752-2349-4BD2-BA7D-85DB731E10B2@dcn.davis.ca.us>
Message-ID: <CAGxFJbSxcPyvDyMbrA7ofoponbjYS7Xzvm3VnzQktmAtZox_fw@mail.gmail.com>

Well...

?terms.formula says:

"data: a data frame from which the meaning of the special symbol . can
be inferred. It is unused if there is no . in the formula."

So this seems to me to be an obscure bug, as I have found no warning
against this admittedly confusing but still, I think, legal syntax.
Note:

> d <- data.frame(log = runif(10), x = 1:10)
> y <- rnorm(10,5)

> m1 <- lm(y ~ ., data = d)
> formula(m1)
y ~ log + x

> m2 <- update(m1, formula =log(y) ~.)
> formula(m2)
log(y) ~ log + x

> m3 = lm(log(y) ~., data =d)
> formula(m3)
log(y) ~ x

As always, correction appreciated if I'm wrong.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Jan 30, 2018 at 6:23 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
>
> Functions are first class objects, so some kind of collision is bound to happen if you do this... so don't.
> --
> Sent from my phone. Please excuse my brevity.
>
> On January 30, 2018 3:11:56 AM PST, "Vito M. R. Muggeo" <vito.muggeo at unipa.it> wrote:
> >dear all,
> >Is the following intentional? Am I missing anything in documentation?
> >
> >d<-data.frame(y=rnorm(10,5,.5),exp=rnorm(10), age=rnorm(10))
> >formula(lm(exp(y)~exp+age, data=d))
> >#--> exp(y) ~ exp + age
> >
> >formula(lm(exp(y)~., data=d))
> >#--> exp(y) ~ age
> >
> >variable 'exp' (maybe indicating "experience") is not included in the
> >model. The same happens with 'log' (and other function names, I
> >suppose..)
> >
> >best,
> >vito
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Tue Jan 30 15:37:07 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 30 Jan 2018 15:37:07 +0100
Subject: [R] Could the Odds represent weight in Generalized Linear Model?
In-Reply-To: <CAFJ7Sp8uySc-tHsA3B0yPvQV_RT97zNipbcW7pYSXDtev7L+aQ@mail.gmail.com>
References: <CAFJ7Sp8uySc-tHsA3B0yPvQV_RT97zNipbcW7pYSXDtev7L+aQ@mail.gmail.com>
Message-ID: <CAJuCY5yzc6ciu-wyRf_UYui0bvPxv+TuTpBzA0Snrsnar1kK9A@mail.gmail.com>

Dear Lenny,

You can do this by using Age as an offset factor.

dataset$wAge <- dataset$Age * 1.02
glm(cbind(Yes,No) ~ offset(wAge) + Times + Type, family=binomial, data =
dataset)

Best regards,




ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-01-30 11:14 GMT+01:00 contact retour-client <
retour.client.contact at gmail.com>:

> Hello all,
>
>
> I'm sorry if my question seems basic.
>
> Im studying a responses (Yes,No) in a survey and, thanks to GLM I obtain
> the following relation with my variables : (Yes,No)~ ?0 + Age We note this
> this certain type of (Yes,No) response is linked to age (p<0.05 in glm) .
>
> After that we calculated :
>
> model1=glm(cbind(Yes,No) ~ Age + Times + Type, family=binomial)
> summary(model1)
> exp(model1$coefficients)
>
> exp(model1$coefficients)(Intercept)         Age       Times TypeRegular
>  0.01659381  1.02546748  1.01544154  1.70056425
>
> The odds of answering 'Yes' is multiplied with 1.02 for each additional
> year of age.
>
> My questions is :
>
> (1) it is possible to add to my model, (Yes,No)~ ?0 + Age, the weight of
> the variable Age. Is it in fact the odd value ? Here is an example : is it
> ok to formulate my model as that (Yes,No)~ ?0 + 1.02* Age: here 1.02 is
> what I call weight of age, in other words, I want to quantify its impact in
> the model.
>
> (2)suppose I want to model (Yes,No)~ ?0 + Type with type a categorical
> data. odd value of TypeRegular is 1.70056425. But in my model it is simply
> Type that include Regular and Irregular. How to adapt this value to Type ?
>
> My data
>
> res=structure(list(Age = c(10, 14, 14, 15, 16, 16, 16, 17, 17, 17, 17,
> 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 20,
> 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 22, 22,
> 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23,
> 23, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26,
> 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27,
> 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29,
> 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31,
> 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33,
> 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35,
> 35, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37,
> 37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38,
> 38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40,
> 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42,
> 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,
> 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45,
> 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47,
> 47, 47, 47, 48, 48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 50,
> 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,
> 51, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 52,
> 52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,
> 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55,
> 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,
> 57, 57, 57, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 59,
> 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 60, 60, 61, 62, 62, 62, 62,
> 63, 64, 64, 65, 65, 67, 74), Times = c(6L, 6L, 16L, 6L, 9L, 23L, 33L,
> 6L, 14L, 17L, 36L, 4L, 9L, 15L, 20L, 26L, 28L, 30L, 33L, 6L, 11L, 14L,
> 20L, 26L, 28L, 30L, 32L, 4L, 4L, 6L, 9L, 17L, 26L, 28L, 30L, 33L, 44L,
> 47L, 4L, 6L, 23L, 26L, 32L, 4L, 9L, 11L, 11L, 14L, 14L, 15L, 17L, 18L,
> 20L, 23L, 26L, 36L, 44L, 50L, 4L, 9L, 28L, 30L, 32L, 4L, 17L, 23L, 4L,
> 6L, 9L, 9L, 11L, 14L, 25L, 33L, 33L, 51L, 4L, 6L, 14L, 17L, 18L, 26L,
> 28L, 30L, 32L, 33L, 44L, 50L, 6L, 9L, 9L, 11L, 14L, 17L, 22L, 23L,
> 30L, 4L, 9L, 11L, 14L, 15L, 20L, 23L, 28L, 29L, 36L, 39L, 43L, 51L,
> 58L, 14L, 20L, 23L, 26L, 28L, 36L, 51L, 4L, 6L, 9L, 16L, 17L, 18L,
> 23L, 33L, 37L, 51L, 9L, 11L, 14L, 18L, 23L, 26L, 28L, 58L, 9L, 17L,
> 33L, 36L, 37L, 58L, 4L, 6L, 9L, 9L, 11L, 17L, 20L, 26L, 28L, 32L, 33L,
> 47L, 4L, 6L, 9L, 15L, 23L, 28L, 4L, 9L, 9L, 15L, 17L, 18L, 20L, 23L,
> 28L, 30L, 30L, 4L, 6L, 6L, 9L, 17L, 18L, 33L, 36L, 4L, 6L, 11L, 14L,
> 15L, 17L, 23L, 26L, 28L, 36L, 4L, 6L, 9L, 11L, 17L, 18L, 23L, 25L,
> 28L, 30L, 6L, 9L, 11L, 14L, 14L, 17L, 20L, 23L, 28L, 35L, 44L, 4L, 6L,
> 9L, 14L, 17L, 44L, 6L, 9L, 14L, 17L, 22L, 26L, 28L, 29L, 33L, 36L,
> 50L, 4L, 6L, 6L, 17L, 20L, 23L, 28L, 30L, 36L, 51L, 58L, 4L, 9L, 9L,
> 14L, 15L, 17L, 23L, 26L, 28L, 30L, 36L, 38L, 6L, 6L, 9L, 17L, 23L,
> 26L, 28L, 43L, 44L, 4L, 15L, 17L, 17L, 25L, 26L, 28L, 36L, 44L, 51L,
> 58L, 6L, 9L, 16L, 25L, 28L, 32L, 44L, 58L, 4L, 9L, 17L, 28L, 30L, 36L,
> 43L, 44L, 6L, 11L, 14L, 16L, 26L, 30L, 44L, 15L, 20L, 23L, 26L, 28L,
> 52L, 4L, 6L, 9L, 9L, 11L, 14L, 16L, 17L, 20L, 23L, 26L, 28L, 30L, 33L,
> 35L, 37L, 50L, 51L, 6L, 9L, 14L, 17L, 18L, 18L, 26L, 44L, 50L, 9L,
> 14L, 14L, 15L, 18L, 20L, 23L, 28L, 33L, 36L, 43L, 44L, 50L, 4L, 9L,
> 11L, 14L, 18L, 26L, 28L, 29L, 30L, 32L, 43L, 44L, 52L, 6L, 9L, 20L,
> 23L, 28L, 30L, 33L, 36L, 43L, 4L, 9L, 11L, 14L, 16L, 20L, 23L, 26L,
> 28L, 36L, 50L, 51L, 4L, 6L, 9L, 14L, 18L, 23L, 26L, 30L, 36L, 43L,
> 44L, 52L, 6L, 9L, 17L, 18L, 23L, 26L, 28L, 30L, 35L, 9L, 14L, 20L,
> 32L, 33L, 36L, 44L, 6L, 9L, 23L, 25L, 36L, 51L, 9L, 17L, 17L, 18L,
> 20L, 33L, 58L, 9L, 23L, 26L, 28L, 36L, 6L, 20L, 28L, 20L, 23L, 4L,
> 15L), Type = c("Regular", "Regular", "Irregular", "Regular",
> "Regular", "Irregular", "Regular", "Irregular", "Irregular",
> "Irregular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Irregular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Irregular", "Regular", "Regular",
> "Irregular", "Regular", "Irregular", "Regular", "Regular", "Regular",
> "Irregular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Irregular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Irregular",
> "Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Irregular", "Regular", "Irregular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
> "Regular", "Irregular", "Regular", "Regular", "Regular", "Irregular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Irregular", "Regular", "Irregular",
> "Regular", "Regular", "Irregular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Irregular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Irregular", "Irregular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Irregular", "Regular", "Regular",
> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Irregular", "Irregular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Irregular", "Regular", "Irregular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Irregular", "Irregular", "Irregular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Irregular", "Regular", "Regular", "Regular", "Irregular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Irregular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
> "Irregular", "Regular", "Regular", "Regular", "Irregular", "Regular",
> "Regular", "Regular", "Regular", "Irregular", "Regular", "Regular",
> "Regular", "Regular", "Regular", "Irregular", "Regular", "Regular",
> "Regular", "Irregular", "Regular", "Regular"), Yes = c(0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L,
> 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L,
> 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 2L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L,
> 1L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 2L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L,
> 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), No = c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
> 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 0L, 1L, 1L, 1L, 1L,
> 2L, 1L, 1L, 1L, 1L, 1L, 3L, 0L, 1L, 1L, 1L, 1L, 1L, 5L, 1L, 1L, 1L,
> 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 3L, 1L, 2L, 1L, 1L,
> 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 2L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L,
> 3L, 1L, 2L, 2L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 0L, 1L, 1L, 1L, 2L,
> 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
> 1L, 1L, 3L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 2L, 1L, 1L, 1L, 1L, 0L, 0L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 5L, 1L, 1L, 0L, 3L,
> 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 3L, 2L, 1L, 2L, 0L, 1L, 1L, 1L, 0L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 3L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 0L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
> 0L, 1L, 1L, 1L, 0L, 1L, 2L, 1L, 1L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 0L, 0L, 1L, 1L, 1L, 2L, 1L, 1L, 0L, 1L, 2L, 1L, 2L, 1L, 1L,
> 1L, 2L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L,
> 1L, 1L, 1L, 1L, 3L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
> 1L, 1L, 0L, 3L, 1L, 1L, 1L, 1L, 1L, 2L, 0L, 2L, 4L, 1L, 3L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 2L, 2L, 2L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L)),
> .Names = c("Age", "Times", "Type", "Yes", "No"), row.names = c(NA,
> -426L), class = "data.frame")
>
> Thansk a lot for your help.
>
>
> Lenny
>
> <http://www.avg.com/email-signature?utm_medium=email&
> utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> Garanti
> sans virus. www.avg.com
> <http://www.avg.com/email-signature?utm_medium=email&
> utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Jan 30 18:05:37 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 30 Jan 2018 09:05:37 -0800
Subject: [R] Calculating angle of a polyline
In-Reply-To: <CAGgJW77QKGQQthuH_m74ThNxeP1oquUbsxqdKf6fcBCeAAnY0Q@mail.gmail.com>
References: <CANTxAmL_EqL-n1cFANob_4227C+aDHtKrgnS=6u1SZW6vTmB7Q@mail.gmail.com>
 <0AB8EE08-1441-4171-B85F-B74427AE9E1A@dcn.davis.ca.us>
 <CAGgJW77QKGQQthuH_m74ThNxeP1oquUbsxqdKf6fcBCeAAnY0Q@mail.gmail.com>
Message-ID: <CAF8bMcbkNroov_GGvdrPewDyDT_bPa8nZkGS5-uQhz=rd43rTQ@mail.gmail.com>

I like to use complex numbers for 2-dimensional geometry.  E.g.,

> polyAngles2
function (xV, yV)
{
    stopifnot((length(xV) == length(yV)) && (length(xV) >= 3))
    z <- complex(re = xV, im = yV)
    c(NA, diff(Arg(diff(z))), NA) # radians, positive is counter-clockwise
}
> x <- c(0:3)
> y <- c(0,0,1,1)
> polyAngles2(x,y) / pi * 180
[1]  NA  45 -45  NA



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Jan 30, 2018 at 7:09 AM, Eric Berger <ericjberger at gmail.com> wrote:

> Assuming your polyline is defined by two vectors, one for the x
> coordinates, one for the y coordinates, you can try the following
>
> library(NISTunits)
> polyangles <- function(xV,yV) {
>   stopifnot( (length(xV)==length(yV)) && (length(xV) >= 3))
>   v <- function(i) { c( xV[i]-xV[i-1], yV[i]-yV[i-1])}
>   vlen <- function(v) { sqrt(sum(v*v)) }
>
>   lV <- rep(NA_real_,length(xV))
>   for ( i in 2:(length(xV)-1) )
>     lV[i] <- acos( sum(v(i)*v(i+1))/(vlen(v(i))*vlen(v(i+1))) )
>   angleV <- NISTunits::NISTradianTOdeg(lV)
>   angleV
> }
>
> # example
> x <- c(0:3)
> y <- c(0,0,1,1)
> polyangles( x, y )
>
> # NA 45.0 45.0 NA
>
> Note, I have included the NA's at the beginning and end of the polyline as
> a reminder that there is no angle defined there.
>
> HTH,
> Eric
>
>
> On Tue, Jan 30, 2018 at 4:34 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
> > A polyline by definition has many angles, so your question is ill-formed.
> > And this is a question about math, not R, so is off topic here. I suggest
> > reading Wikipedia.
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > On January 29, 2018 11:10:02 PM PST, javad bayat <j.bayat194 at gmail.com>
> > wrote:
> > >Dear R users
> > >I am trying to find a formula to calculate the angle of a polyline. Is
> > >there a way to do this?
> > >Many thanks.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Tue Jan 30 18:15:39 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Tue, 30 Jan 2018 19:15:39 +0200
Subject: [R] Calculating angle of a polyline
In-Reply-To: <CAF8bMcbkNroov_GGvdrPewDyDT_bPa8nZkGS5-uQhz=rd43rTQ@mail.gmail.com>
References: <CANTxAmL_EqL-n1cFANob_4227C+aDHtKrgnS=6u1SZW6vTmB7Q@mail.gmail.com>
 <0AB8EE08-1441-4171-B85F-B74427AE9E1A@dcn.davis.ca.us>
 <CAGgJW77QKGQQthuH_m74ThNxeP1oquUbsxqdKf6fcBCeAAnY0Q@mail.gmail.com>
 <CAF8bMcbkNroov_GGvdrPewDyDT_bPa8nZkGS5-uQhz=rd43rTQ@mail.gmail.com>
Message-ID: <CAGgJW770r0Sh64CdQbxjFqS6eLaVADEi9x_a+ndaydkstiQLPg@mail.gmail.com>

nice

On Tue, Jan 30, 2018 at 7:05 PM, William Dunlap <wdunlap at tibco.com> wrote:

> I like to use complex numbers for 2-dimensional geometry.  E.g.,
>
> > polyAngles2
> function (xV, yV)
> {
>     stopifnot((length(xV) == length(yV)) && (length(xV) >= 3))
>     z <- complex(re = xV, im = yV)
>     c(NA, diff(Arg(diff(z))), NA) # radians, positive is counter-clockwise
> }
> > x <- c(0:3)
> > y <- c(0,0,1,1)
> > polyAngles2(x,y) / pi * 180
> [1]  NA  45 -45  NA
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Jan 30, 2018 at 7:09 AM, Eric Berger <ericjberger at gmail.com>
> wrote:
>
>> Assuming your polyline is defined by two vectors, one for the x
>> coordinates, one for the y coordinates, you can try the following
>>
>> library(NISTunits)
>> polyangles <- function(xV,yV) {
>>   stopifnot( (length(xV)==length(yV)) && (length(xV) >= 3))
>>   v <- function(i) { c( xV[i]-xV[i-1], yV[i]-yV[i-1])}
>>   vlen <- function(v) { sqrt(sum(v*v)) }
>>
>>   lV <- rep(NA_real_,length(xV))
>>   for ( i in 2:(length(xV)-1) )
>>     lV[i] <- acos( sum(v(i)*v(i+1))/(vlen(v(i))*vlen(v(i+1))) )
>>   angleV <- NISTunits::NISTradianTOdeg(lV)
>>   angleV
>> }
>>
>> # example
>> x <- c(0:3)
>> y <- c(0,0,1,1)
>> polyangles( x, y )
>>
>> # NA 45.0 45.0 NA
>>
>> Note, I have included the NA's at the beginning and end of the polyline as
>> a reminder that there is no angle defined there.
>>
>> HTH,
>> Eric
>>
>>
>> On Tue, Jan 30, 2018 at 4:34 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us
>> >
>> wrote:
>>
>> > A polyline by definition has many angles, so your question is
>> ill-formed.
>> > And this is a question about math, not R, so is off topic here. I
>> suggest
>> > reading Wikipedia.
>> > --
>> > Sent from my phone. Please excuse my brevity.
>> >
>> > On January 29, 2018 11:10:02 PM PST, javad bayat <j.bayat194 at gmail.com>
>> > wrote:
>> > >Dear R users
>> > >I am trying to find a formula to calculate the angle of a polyline. Is
>> > >there a way to do this?
>> > >Many thanks.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> > posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From motyocska at yahoo.com  Wed Jan 31 01:19:39 2018
From: motyocska at yahoo.com (Andras Farkas)
Date: Wed, 31 Jan 2018 00:19:39 +0000 (UTC)
Subject: [R] MICE data analysis with glmulti
References: <1269985436.15366.1517357979818.ref@mail.yahoo.com>
Message-ID: <1269985436.15366.1517357979818@mail.yahoo.com>

Dear All,

wonder if you have some thoughts on running the with() function (and perhaps including the pool() function to get the results?) in glmulti? In other words, how to run glmulti with a data set that is produced by mice()?

publicly available code:

data <- airquality
data[4:10,3] <- rep(NA,7)
data[1:5,4] <- NA
data <- data[-c(5,6)]
library(mice)
library(glmulti)

the following line will compute the missing data:
tempData <- mice(data,m=5,maxit=50,meth='pmm',seed=500)

and the following 2 lines will run the regression on the mice output and pool the results to establish the final result of interest for the model specified...
modelFit1 <- with(tempData,glm(Temp~ Ozone+Solar.R+Wind))
summary(pool(modelFit1))


with glmulti I am trying to establish the "best" model by evaluating combinations of all predictors and interactions in different models and would like to force the variable "Ozone" into all models with the following code:

glm.redefined = function(formula, data, always="", ...)?
{glm(as.formula(paste(deparse(formula), always)), data=data, ...)}

then run glmulti:


output<-glmulti(with(tempData,Temp~Solar.R+Wind),?
? ? ? ? ? ? ? ? fitfunc=glm.redefined,?
? ? ? ? ? ? ? ? level=1,?
? ? ? ? ? ? ? ? crit=aic,?
? ? ? ? ? ? ? ? method="h",?
? ? ? ? ? ? ? ? always= "+Ozone")


which will obviously fail once you give it a try... any thoughts on how to identify the best model using glmulti in this fashion? that would fit the different combination of predictors with interactions on the mice() output of tempData?

much appreciate the help...

Andras?


From thierry.onkelinx at inbo.be  Wed Jan 31 10:20:05 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 31 Jan 2018 10:20:05 +0100
Subject: [R] Could the Odds represent weight in Generalized Linear Model?
In-Reply-To: <CAFJ7Sp_TV7UkUnkiYumr=b8FZm0-=pS1H3p_Mv3fnAv2BevZSw@mail.gmail.com>
References: <CAFJ7Sp8uySc-tHsA3B0yPvQV_RT97zNipbcW7pYSXDtev7L+aQ@mail.gmail.com>
 <CAJuCY5yzc6ciu-wyRf_UYui0bvPxv+TuTpBzA0Snrsnar1kK9A@mail.gmail.com>
 <CAFJ7Sp_TV7UkUnkiYumr=b8FZm0-=pS1H3p_Mv3fnAv2BevZSw@mail.gmail.com>
Message-ID: <CAJuCY5wVqJmJmJxU8N5vEo+QDWOrHoXowvFLLTFA_0Kwp_GyAA@mail.gmail.com>

Dear Lenny,

\beta_1 is the log odds ratio for age. If you want the odds ratio,
then you need to calculate it.

It looks like some reading up on glm won't harm you.

Best regards,



ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-01-30 15:46 GMT+01:00 contact retour-client
<retour.client.contact at gmail.com>:
> Dear Thierry,
>
> Thanks a lot for this answer,
>
> I mean i want to obtain such model Behavior1 = ?0+?1*Age , the purpose is to
> obtain  ?1. I want to be sure that the odds value could be the  ?1. Or how
> to calculate it ?
>
> Thanks again for your precious help.
>
> Lenny
>
> Garanti sans virus. www.avg.com
>
> 2018-01-30 15:37 GMT+01:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>>
>> Dear Lenny,
>>
>> You can do this by using Age as an offset factor.
>>
>> dataset$wAge <- dataset$Age * 1.02
>> glm(cbind(Yes,No) ~ offset(wAge) + Times + Type, family=binomial, data =
>> dataset)
>>
>> Best regards,
>>
>>
>>
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
>> FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>>
>>
>> 2018-01-30 11:14 GMT+01:00 contact retour-client
>> <retour.client.contact at gmail.com>:
>>>
>>> Hello all,
>>>
>>>
>>> I'm sorry if my question seems basic.
>>>
>>> Im studying a responses (Yes,No) in a survey and, thanks to GLM I obtain
>>> the following relation with my variables : (Yes,No)~ ?0 + Age We note
>>> this
>>> this certain type of (Yes,No) response is linked to age (p<0.05 in glm) .
>>>
>>> After that we calculated :
>>>
>>> model1=glm(cbind(Yes,No) ~ Age + Times + Type, family=binomial)
>>> summary(model1)
>>> exp(model1$coefficients)
>>>
>>> exp(model1$coefficients)(Intercept)         Age       Times TypeRegular
>>>  0.01659381  1.02546748  1.01544154  1.70056425
>>>
>>> The odds of answering 'Yes' is multiplied with 1.02 for each additional
>>> year of age.
>>>
>>> My questions is :
>>>
>>> (1) it is possible to add to my model, (Yes,No)~ ?0 + Age, the weight of
>>> the variable Age. Is it in fact the odd value ? Here is an example : is
>>> it
>>> ok to formulate my model as that (Yes,No)~ ?0 + 1.02* Age: here 1.02 is
>>> what I call weight of age, in other words, I want to quantify its impact
>>> in
>>> the model.
>>>
>>> (2)suppose I want to model (Yes,No)~ ?0 + Type with type a categorical
>>> data. odd value of TypeRegular is 1.70056425. But in my model it is
>>> simply
>>> Type that include Regular and Irregular. How to adapt this value to Type
>>> ?
>>>
>>> My data
>>>
>>> res=structure(list(Age = c(10, 14, 14, 15, 16, 16, 16, 17, 17, 17, 17,
>>> 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 20,
>>> 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 22, 22,
>>> 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23,
>>> 23, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26,
>>> 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27,
>>> 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29,
>>> 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31,
>>> 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33,
>>> 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35,
>>> 35, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37,
>>> 37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38,
>>> 38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40,
>>> 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42,
>>> 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,
>>> 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45,
>>> 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47,
>>> 47, 47, 47, 48, 48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 50,
>>> 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,
>>> 51, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 52,
>>> 52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,
>>> 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55,
>>> 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,
>>> 57, 57, 57, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 59,
>>> 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 60, 60, 61, 62, 62, 62, 62,
>>> 63, 64, 64, 65, 65, 67, 74), Times = c(6L, 6L, 16L, 6L, 9L, 23L, 33L,
>>> 6L, 14L, 17L, 36L, 4L, 9L, 15L, 20L, 26L, 28L, 30L, 33L, 6L, 11L, 14L,
>>> 20L, 26L, 28L, 30L, 32L, 4L, 4L, 6L, 9L, 17L, 26L, 28L, 30L, 33L, 44L,
>>> 47L, 4L, 6L, 23L, 26L, 32L, 4L, 9L, 11L, 11L, 14L, 14L, 15L, 17L, 18L,
>>> 20L, 23L, 26L, 36L, 44L, 50L, 4L, 9L, 28L, 30L, 32L, 4L, 17L, 23L, 4L,
>>> 6L, 9L, 9L, 11L, 14L, 25L, 33L, 33L, 51L, 4L, 6L, 14L, 17L, 18L, 26L,
>>> 28L, 30L, 32L, 33L, 44L, 50L, 6L, 9L, 9L, 11L, 14L, 17L, 22L, 23L,
>>> 30L, 4L, 9L, 11L, 14L, 15L, 20L, 23L, 28L, 29L, 36L, 39L, 43L, 51L,
>>> 58L, 14L, 20L, 23L, 26L, 28L, 36L, 51L, 4L, 6L, 9L, 16L, 17L, 18L,
>>> 23L, 33L, 37L, 51L, 9L, 11L, 14L, 18L, 23L, 26L, 28L, 58L, 9L, 17L,
>>> 33L, 36L, 37L, 58L, 4L, 6L, 9L, 9L, 11L, 17L, 20L, 26L, 28L, 32L, 33L,
>>> 47L, 4L, 6L, 9L, 15L, 23L, 28L, 4L, 9L, 9L, 15L, 17L, 18L, 20L, 23L,
>>> 28L, 30L, 30L, 4L, 6L, 6L, 9L, 17L, 18L, 33L, 36L, 4L, 6L, 11L, 14L,
>>> 15L, 17L, 23L, 26L, 28L, 36L, 4L, 6L, 9L, 11L, 17L, 18L, 23L, 25L,
>>> 28L, 30L, 6L, 9L, 11L, 14L, 14L, 17L, 20L, 23L, 28L, 35L, 44L, 4L, 6L,
>>> 9L, 14L, 17L, 44L, 6L, 9L, 14L, 17L, 22L, 26L, 28L, 29L, 33L, 36L,
>>> 50L, 4L, 6L, 6L, 17L, 20L, 23L, 28L, 30L, 36L, 51L, 58L, 4L, 9L, 9L,
>>> 14L, 15L, 17L, 23L, 26L, 28L, 30L, 36L, 38L, 6L, 6L, 9L, 17L, 23L,
>>> 26L, 28L, 43L, 44L, 4L, 15L, 17L, 17L, 25L, 26L, 28L, 36L, 44L, 51L,
>>> 58L, 6L, 9L, 16L, 25L, 28L, 32L, 44L, 58L, 4L, 9L, 17L, 28L, 30L, 36L,
>>> 43L, 44L, 6L, 11L, 14L, 16L, 26L, 30L, 44L, 15L, 20L, 23L, 26L, 28L,
>>> 52L, 4L, 6L, 9L, 9L, 11L, 14L, 16L, 17L, 20L, 23L, 26L, 28L, 30L, 33L,
>>> 35L, 37L, 50L, 51L, 6L, 9L, 14L, 17L, 18L, 18L, 26L, 44L, 50L, 9L,
>>> 14L, 14L, 15L, 18L, 20L, 23L, 28L, 33L, 36L, 43L, 44L, 50L, 4L, 9L,
>>> 11L, 14L, 18L, 26L, 28L, 29L, 30L, 32L, 43L, 44L, 52L, 6L, 9L, 20L,
>>> 23L, 28L, 30L, 33L, 36L, 43L, 4L, 9L, 11L, 14L, 16L, 20L, 23L, 26L,
>>> 28L, 36L, 50L, 51L, 4L, 6L, 9L, 14L, 18L, 23L, 26L, 30L, 36L, 43L,
>>> 44L, 52L, 6L, 9L, 17L, 18L, 23L, 26L, 28L, 30L, 35L, 9L, 14L, 20L,
>>> 32L, 33L, 36L, 44L, 6L, 9L, 23L, 25L, 36L, 51L, 9L, 17L, 17L, 18L,
>>> 20L, 33L, 58L, 9L, 23L, 26L, 28L, 36L, 6L, 20L, 28L, 20L, 23L, 4L,
>>> 15L), Type = c("Regular", "Regular", "Irregular", "Regular",
>>> "Regular", "Irregular", "Regular", "Irregular", "Irregular",
>>> "Irregular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Irregular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Irregular", "Regular", "Regular",
>>> "Irregular", "Regular", "Irregular", "Regular", "Regular", "Regular",
>>> "Irregular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Irregular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Irregular",
>>> "Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Irregular", "Regular", "Irregular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
>>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Irregular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Irregular", "Regular", "Irregular",
>>> "Regular", "Regular", "Irregular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Irregular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
>>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Irregular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Irregular", "Regular", "Regular",
>>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Irregular", "Irregular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Irregular", "Regular", "Irregular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Irregular", "Irregular", "Irregular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
>>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Irregular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Irregular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Irregular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Irregular", "Regular", "Regular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Regular", "Regular", "Regular",
>>> "Irregular", "Regular", "Regular", "Regular", "Irregular", "Regular",
>>> "Regular", "Regular", "Regular", "Irregular", "Regular", "Regular",
>>> "Regular", "Regular", "Regular", "Irregular", "Regular", "Regular",
>>> "Regular", "Irregular", "Regular", "Regular"), Yes = c(0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L,
>>> 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L,
>>> 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 2L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L,
>>> 1L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 2L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L,
>>> 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>>> 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), No = c(1L,
>>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>>> 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 0L, 1L, 1L, 1L, 1L,
>>> 2L, 1L, 1L, 1L, 1L, 1L, 3L, 0L, 1L, 1L, 1L, 1L, 1L, 5L, 1L, 1L, 1L,
>>> 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 3L, 1L, 2L, 1L, 1L,
>>> 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L,
>>> 1L, 1L, 1L, 1L, 2L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L,
>>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L,
>>> 3L, 1L, 2L, 2L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 0L, 1L, 1L, 1L, 2L,
>>> 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
>>> 1L, 1L, 3L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L,
>>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 2L, 1L, 1L, 1L, 1L, 0L, 0L,
>>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 5L, 1L, 1L, 0L, 3L,
>>> 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 3L, 2L, 1L, 2L, 0L, 1L, 1L, 1L, 0L,
>>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 3L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
>>> 1L, 1L, 1L, 1L, 1L, 0L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
>>> 0L, 1L, 1L, 1L, 0L, 1L, 2L, 1L, 1L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>> 1L, 1L, 0L, 0L, 1L, 1L, 1L, 2L, 1L, 1L, 0L, 1L, 2L, 1L, 2L, 1L, 1L,
>>> 1L, 2L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L,
>>> 1L, 1L, 1L, 1L, 3L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L,
>>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
>>> 1L, 1L, 0L, 3L, 1L, 1L, 1L, 1L, 1L, 2L, 0L, 2L, 4L, 1L, 3L, 1L, 1L,
>>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>> 2L, 2L, 2L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>> 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L,
>>> 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L)),
>>> .Names = c("Age", "Times", "Type", "Yes", "No"), row.names = c(NA,
>>> -426L), class = "data.frame")
>>>
>>> Thansk a lot for your help.
>>>
>>>
>>> Lenny
>>>
>>>
>>> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>>> Garanti
>>> sans virus. www.avg.com
>>>
>>> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>>> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


From gerdaboerner at gmx.de  Wed Jan 31 10:35:32 2018
From: gerdaboerner at gmx.de (=?UTF-8?Q?Gerda_B=c3=b6rner?=)
Date: Wed, 31 Jan 2018 10:35:32 +0100
Subject: [R] What is the default covariance structure in the glmmPQL
 function (MASS package)?
Message-ID: <e7b27240-4b0d-a9fd-9780-88ad8a724eb9@gmx.de>

Hello,

currently I am trying to fit a generalized linear mixed model using the 
glmmPQL function in the MASS package. I am working with the data 
provided by the book from Heck, Thomas and Tabata (2012) - 
https://www.routledge.com/Multilevel-Modeling-of-Categorical-Outcomes-Using-IBM-SPSS/Heck-Thomas-Tabata/p/book/9781848729568

I was wondering, which variance-covariance structure the glmmPQL 
function is using by default and if it is possible to vary the 
variance-covariance structure with the glmmPQL function. Unfortunately I 
couldn't manage to find out myself.
If it is possible to change it, could someone tell me how to do so? I am 
especially interested in a diagonal structure versus an unstructured 
variance-covariance structure.

Thanks a lot in advance.

Gerda


From spencer.graves at effectivedefense.org  Wed Jan 31 11:36:04 2018
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Wed, 31 Jan 2018 04:36:04 -0600
Subject: [R] Scraping info from a web site?
Message-ID: <824e6fac-8642-9604-7585-189d63986692@effectivedefense.org>

Hi, All:


 ????? What would you suggest one use to read the data on members of the 
US Congress and their positions on net neutrality from 
"https://www.battleforthenet.com/scoreboard" into R?


 ????? I found recommendations for the "rvest" package to "Easily 
Harvest (Scrape) Web Pages".? I tried the following:


URL <- 'https://www.battleforthenet.com/scoreboard/'
library(rvest)
Bftn <- read_html(URL)
str(Bftn)


List of 2
 ?$ node:<externalptr>
 ?$ doc :<externalptr>
 ?- attr(*, "class")= chr [1:2] "xml_document" "xml_node"


 ?????? However, I don't know what to do with <externalptr>.


 ????? The "Selectorgadget" vignette with rvest suggested selecting what 
I wanted on the web page and pasting that as an argument into 
"html_node".? This led me to try the following:


Bftn_nodes <- html_nodes(Bftn,
 ??? '.psb-unknown , #house, #senate, #senate p')


str(Bftn_nodes)
List of 4
 ?$ :List of 2
 ? ..$ node:<externalptr>
 ? ..$ doc :<externalptr>
 ? ..- attr(*, "class")= chr "xml_node"
 ?$ :List of 2
 ? ..$ node:<externalptr>
 ? ..$ doc :<externalptr>
 ? ..- attr(*, "class")= chr "xml_node"
 ?$ :List of 2
 ? ..$ node:<externalptr>
 ? ..$ doc :<externalptr>
 ? ..- attr(*, "class")= chr "xml_node"
 ?$ :List of 2
 ? ..$ node:<externalptr>
 ? ..$ doc :<externalptr>
 ? ..- attr(*, "class")= chr "xml_node"
 ?- attr(*, "class")= chr "xml_nodeset"


 ????? This seems like it may be progress, but I'm still confused on 
what to do next.? Or maybe I should be using a different package? Or 
posting this question to someplace else like StackOverflow.com?


 ????? Thanks,
 ????? Spencer Graves


From bgunter.4567 at gmail.com  Wed Jan 31 17:23:25 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 31 Jan 2018 08:23:25 -0800
Subject: [R] What is the default covariance structure in the glmmPQL
 function (MASS package)?
In-Reply-To: <e7b27240-4b0d-a9fd-9780-88ad8a724eb9@gmx.de>
References: <e7b27240-4b0d-a9fd-9780-88ad8a724eb9@gmx.de>
Message-ID: <CAGxFJbScU_849s7NHVFtQ118iE94zXQFt6JrEtq=7A2bKvxqAQ@mail.gmail.com>

Suggestion:

Post your query on the r-sig-mixed-models list, which is (obviously)
focused on mixed models issues, and where you are likely to find both
greater interest and expertise on such matters.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jan 31, 2018 at 1:35 AM, Gerda B?rner <gerdaboerner at gmx.de> wrote:
> Hello,
>
> currently I am trying to fit a generalized linear mixed model using the
> glmmPQL function in the MASS package. I am working with the data provided by
> the book from Heck, Thomas and Tabata (2012) -
> https://www.routledge.com/Multilevel-Modeling-of-Categorical-Outcomes-Using-IBM-SPSS/Heck-Thomas-Tabata/p/book/9781848729568
>
> I was wondering, which variance-covariance structure the glmmPQL function is
> using by default and if it is possible to vary the variance-covariance
> structure with the glmmPQL function. Unfortunately I couldn't manage to find
> out myself.
> If it is possible to change it, could someone tell me how to do so? I am
> especially interested in a diagonal structure versus an unstructured
> variance-covariance structure.
>
> Thanks a lot in advance.
>
> Gerda
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From elvenpath666 at gmail.com  Wed Jan 31 16:56:45 2018
From: elvenpath666 at gmail.com (Nick Fikas)
Date: Wed, 31 Jan 2018 17:56:45 +0200
Subject: [R] using randomForest() with matrix() as input results to an
 Error: protect(): protection stack overflow
Message-ID: <CA+Vt=QwigKHQ6crksf4_saDATxveNJr=6JaTO0rwV=_Asv7MPA@mail.gmail.com>

Hello,

I'm trying to figure out a solution online but couldn't so far. I realized
that others dealt with such an error but their suggestions didn't work for
me.

So, I'm trying to run the randomForest() using this command:

rf = randomForest(classes~., data=as.matrix(train), mtry=5, ntree=2000,
importance=TRUE)

and it always results in *Error: protect(): protection stack overflow.*

As you can see, I have already turned the training dataset into a matrix
but this didn't fix anything.

> Cstack_info()

      size    current  direction eval_depth
   7969177      13104          1          2

I also tried the options(expressions = 12e4) but nothing really changed.

The PC I'm running this on has 12 GB RAM and runs on Linux.

The dim(train) returns: 50 20040.

Is there something else to try, or I should run it on a different PC?

Thanks.

	[[alternative HTML version deleted]]


From boneill at epixanalytics.com  Tue Jan 30 18:47:55 2018
From: boneill at epixanalytics.com (Barbara O'Neill)
Date: Tue, 30 Jan 2018 17:47:55 +0000
Subject: [R] Quantitative Risk Analysis with R Course 5/1/18 to 5/4/18
Message-ID: <CY4PR20MB1399358B31EA90B78DE0F2F9A8E40@CY4PR20MB1399.namprd20.prod.outlook.com>

Quantitative Risk Analysis with R
May 1-4, 2018
Fort Collins, Colorado, USA

Join us this spring for our QRA with R training. Our class will focus on applied risk modeling methods using the R statistical language and will cover the core principles of QRA and Monte Carlo simulation modeling. Both Bayesian and frequentist methods will be discussed.

This class is very popular with a variety of participants, including those without prior risk analysis experience; current R users who would like to build risk analysis and/or simulation models without using commercial tools; risk analysts who would like to migrate spreadsheet models to the R platform; and even seasoned risk analysts who would like to learn new skills.  However, prior experience using R or other simulation tools is not required.

For additional information and to register please visit:
http://www.epixanalytics.com/quantitative-risk-analysis-with-r-4-days.html.

To register by phone or for any questions please contact:
Barbara O'Neill, boneill at epixanalytics.com<mailto:boneill at epixanalytics.com>
Ph: +1 303 440 8524
EpiX Analytics www.epixanalytics.com<http://www.epixanalytics.com>



	[[alternative HTML version deleted]]


From nicholas.wray at ntlworld.com  Wed Jan 31 18:08:51 2018
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Wed, 31 Jan 2018 17:08:51 +0000 (GMT)
Subject: [R] Problems with "predict" function
Message-ID: <136359071.2814924.1517418531073.JavaMail.open-xchange@oxbe4.tb.ukmail.iss.as9143.net>

Hello,

I am synthesising some sales data over a twelve month period, and then trying to
use the "predict" function, firstly to generate a thirteenth month forecast with
upper and lower 95% confidence limits.  So far so good

But what I then want to do is add the upper sales value at the 95th confidence
limit to the vector of thirteen months and their respective sales to create a
fourteenth month with a predicted sale and the 95% upper confidence limit for
this, and so on  The idea being to create a "trumpet" of extreme posistions

But I keep getting instead of one line of predictions for the fourteenth month,
a whole set.  What I don't understand is why it works OK with my original
synthetic set of twelve months, but doesn't like the set of thirteen sales data
points, even though as far as I can see I'm just repeating the process, albeit
with a different label  I have tried to use different column labels in case that
was the problem but it doesn't seem to make any difference

I am also getting these weird warning messages telling me that things are being
"masked":

The following object is masked _by_ .GlobalEnv:

sales

The following object is masked from highdf (pos = 4):

sales
Etc

Is it something to do with attaching the various data frames?  I am a bit at sea
on this and would be thankful for any pointers

Nick

My code:


m<-runif(1,0,1)
m
mres<-m*(seq(1,12))
mres
ssd<-rexp(1,1)
ssd
devs<-rep(0,length(mres))
for(i in 1:length(mres)){devs[i]<-rnorm(1,0,ssd)}
devs
plot(-10,-10,xlim=c(1,24),ylim=c(0,20000))
sales<-round((mres+devs)*1000)

points(sales,pch=19)

ptr<-cbind(1:length(sales),sales,sales,sales)

ptr
sdf<-data.frame(cbind(1:nrow(ptr),sales))
sdf

colnames(sdf)<-c(?monat?,?mitte?)
sdf
attach(sdf)
s.lm<-lm(mitte~monat)

s.lm
abline(s.lm,lty=2)
news<-data.frame(monat=nrow(sdf)+1)
news
fcs<-predict(s.lm,news,interval="predict")
fcs

points(1+nrow(ptr),fcs[,1],col="grey",pch=19)
points(1+nrow(ptr),fcs[,2])
points(1+nrow(ptr),fcs[,3])
ptr<-rbind(ptr,c(1+nrow(ptr),fcs[2],fcs[1],fcs[3]))
ptr

highdf<-data.frame(ptr[,c(1,4)])
highdf
colnames(highdf)<-c(?month?,?sales?)
highdf

attach(highdf)
h.lm<-lm(highdf[,2]~highdf[,1])
h.lm
abline(h.lm,col="gray",lty=2)
news<-data.frame(month=nrow(ptr)+1)
news
hcs<-predict(h.lm,news,interval="predict")
hcs
	[[alternative HTML version deleted]]


From nicholas.wray at ntlworld.com  Wed Jan 31 18:20:10 2018
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Wed, 31 Jan 2018 17:20:10 +0000 (GMT)
Subject: [R] Problems with "predict" function ii
Message-ID: <1195865783.2815400.1517419210201.JavaMail.open-xchange@oxbe4.tb.ukmail.iss.as9143.net>

I  have realised that I should have used "detach" before attaching another
dataframe, but even when I do this it's still giving me lots of lines, rather
than just one:

My code:


m<-runif(1,0,1)
m
mres<-m*(seq(1,12))
mres
ssd<-rexp(1,1)
ssd
devs<-rep(0,length(mres))
for(i in 1:length(mres)){devs[i]<-rnorm(1,0,ssd)}
devs
plot(-10,-10,xlim=c(1,24),ylim=c(0,20000))
sales<-round((mres+devs)*1000)

points(sales,pch=19)

ptr<-cbind(1:length(sales),sales,sales,sales)

ptr
sdf<-data.frame(cbind(1:nrow(ptr),sales))
sdf

colnames(sdf)<-c(?monat?,?mitte?)
sdf
attach(sdf)
s.lm<-lm(mitte~monat)

s.lm
abline(s.lm,lty=2)
news<-data.frame(monat=nrow(sdf)+1)
news
fcs<-predict(s.lm,news,interval=?predict?)
fcs

points(1+nrow(ptr),fcs[,1],col=?grey?,pch=19)
points(1+nrow(ptr),fcs[,2])
points(1+nrow(ptr),fcs[,3])
ptr<-rbind(ptr,c(1+nrow(ptr),fcs[2],fcs[1],fcs[3]))
ptr

highdf<-data.frame(ptr[,c(1,4)])
highdf
colnames(highdf)<-c(?month?,?sales?)
highdf
detach(sdf)
attach(highdf)
h.lm<-lm(highdf[,2]~highdf[,1])
h.lm
abline(h.lm,col="gray",lty=2)
news<-data.frame(month=nrow(ptr)+1)
news
hcs<-predict(h.lm,news,interval=?predict?)
hcs
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Jan 31 18:28:47 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 31 Jan 2018 09:28:47 -0800
Subject: [R] Problems with "predict" function ii
In-Reply-To: <1195865783.2815400.1517419210201.JavaMail.open-xchange@oxbe4.tb.ukmail.iss.as9143.net>
References: <1195865783.2815400.1517419210201.JavaMail.open-xchange@oxbe4.tb.ukmail.iss.as9143.net>
Message-ID: <3FB6C557-DEB0-43F4-AE73-79B6D0CE4F13@dcn.davis.ca.us>

This is the kind of thing that leads experienced R users to avoid attach for data analysis. Read "The R Inferno".

Use the "data" argument to lm, and the "newdata" argument to predict.lm.
-- 
Sent from my phone. Please excuse my brevity.

On January 31, 2018 9:20:10 AM PST, WRAY NICHOLAS via R-help <r-help at r-project.org> wrote:
>I  have realised that I should have used "detach" before attaching
>another
>dataframe, but even when I do this it's still giving me lots of lines,
>rather
>than just one:
>
>My code:
>
>
>m<-runif(1,0,1)
>m
>mres<-m*(seq(1,12))
>mres
>ssd<-rexp(1,1)
>ssd
>devs<-rep(0,length(mres))
>for(i in 1:length(mres)){devs[i]<-rnorm(1,0,ssd)}
>devs
>plot(-10,-10,xlim=c(1,24),ylim=c(0,20000))
>sales<-round((mres+devs)*1000)
>
>points(sales,pch=19)
>
>ptr<-cbind(1:length(sales),sales,sales,sales)
>
>ptr
>sdf<-data.frame(cbind(1:nrow(ptr),sales))
>sdf
>
>colnames(sdf)<-c(?monat?,?mitte?)
>sdf
>attach(sdf)
>s.lm<-lm(mitte~monat)
>
>s.lm
>abline(s.lm,lty=2)
>news<-data.frame(monat=nrow(sdf)+1)
>news
>fcs<-predict(s.lm,news,interval=?predict?)
>fcs
>
>points(1+nrow(ptr),fcs[,1],col=?grey?,pch=19)
>points(1+nrow(ptr),fcs[,2])
>points(1+nrow(ptr),fcs[,3])
>ptr<-rbind(ptr,c(1+nrow(ptr),fcs[2],fcs[1],fcs[3]))
>ptr
>
>highdf<-data.frame(ptr[,c(1,4)])
>highdf
>colnames(highdf)<-c(?month?,?sales?)
>highdf
>detach(sdf)
>attach(highdf)
>h.lm<-lm(highdf[,2]~highdf[,1])
>h.lm
>abline(h.lm,col="gray",lty=2)
>news<-data.frame(month=nrow(ptr)+1)
>news
>hcs<-predict(h.lm,news,interval=?predict?)
>hcs
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jacob-simmering at uiowa.edu  Wed Jan 31 18:29:35 2018
From: jacob-simmering at uiowa.edu (Simmering, Jacob E)
Date: Wed, 31 Jan 2018 17:29:35 +0000
Subject: [R] Problems with "predict" function
In-Reply-To: <136359071.2814924.1517418531073.JavaMail.open-xchange@oxbe4.tb.ukmail.iss.as9143.net>
References: <136359071.2814924.1517418531073.JavaMail.open-xchange@oxbe4.tb.ukmail.iss.as9143.net>
Message-ID: <59B9CCAF-9E25-45F5-BCF3-E2A9207FFDD1@uiowa.edu>

Your messages about masking come from attaching your data set to the R session. In general, that is bad practice as it leads to confusing code. It is typically better to use the ?data? argument in things like lm() to accomplish this task. 

As near as I can tell, your second set of predictions is not working because your call to lm() directly references vectors from the highdf data frame. If you do this:

h.lm <- lm(sales ~ month, data = highdf)
news <- data.frame(month = nrow(ptr) + 1)
hcs <- predict(h.lm, news, interval = "predict")

You should see the expected results. Note that here I?m directly referring to the variables ?sales? and ?month? and not using the bracket notation. 

> On Jan 31, 2018, at 11:08 AM, WRAY NICHOLAS via R-help <r-help at r-project.org> wrote:
> 
> Hello,
> 
> I am synthesising some sales data over a twelve month period, and then trying to
> use the "predict" function, firstly to generate a thirteenth month forecast with
> upper and lower 95% confidence limits.  So far so good
> 
> But what I then want to do is add the upper sales value at the 95th confidence
> limit to the vector of thirteen months and their respective sales to create a
> fourteenth month with a predicted sale and the 95% upper confidence limit for
> this, and so on  The idea being to create a "trumpet" of extreme posistions
> 
> But I keep getting instead of one line of predictions for the fourteenth month,
> a whole set.  What I don't understand is why it works OK with my original
> synthetic set of twelve months, but doesn't like the set of thirteen sales data
> points, even though as far as I can see I'm just repeating the process, albeit
> with a different label  I have tried to use different column labels in case that
> was the problem but it doesn't seem to make any difference
> 
> I am also getting these weird warning messages telling me that things are being
> "masked":
> 
> The following object is masked _by_ .GlobalEnv:
> 
> sales
> 
> The following object is masked from highdf (pos = 4):
> 
> sales
> Etc
> 
> Is it something to do with attaching the various data frames?  I am a bit at sea
> on this and would be thankful for any pointers
> 
> Nick
> 
> My code:
> 
> 
> m<-runif(1,0,1)
> m
> mres<-m*(seq(1,12))
> mres
> ssd<-rexp(1,1)
> ssd
> devs<-rep(0,length(mres))
> for(i in 1:length(mres)){devs[i]<-rnorm(1,0,ssd)}
> devs
> plot(-10,-10,xlim=c(1,24),ylim=c(0,20000))
> sales<-round((mres+devs)*1000)
> 
> points(sales,pch=19)
> 
> ptr<-cbind(1:length(sales),sales,sales,sales)
> 
> ptr
> sdf<-data.frame(cbind(1:nrow(ptr),sales))
> sdf
> 
> colnames(sdf)<-c(?monat?,?mitte?)
> sdf
> attach(sdf)
> s.lm<-lm(mitte~monat)
> 
> s.lm
> abline(s.lm,lty=2)
> news<-data.frame(monat=nrow(sdf)+1)
> news
> fcs<-predict(s.lm,news,interval="predict")
> fcs
> 
> points(1+nrow(ptr),fcs[,1],col="grey",pch=19)
> points(1+nrow(ptr),fcs[,2])
> points(1+nrow(ptr),fcs[,3])
> ptr<-rbind(ptr,c(1+nrow(ptr),fcs[2],fcs[1],fcs[3]))
> ptr
> 
> highdf<-data.frame(ptr[,c(1,4)])
> highdf
> colnames(highdf)<-c(?month?,?sales?)
> highdf
> 
> attach(highdf)
> h.lm<-lm(highdf[,2]~highdf[,1])
> h.lm
> abline(h.lm,col="gray",lty=2)
> news<-data.frame(month=nrow(ptr)+1)
> news
> hcs<-predict(h.lm,news,interval="predict")
> hcs
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Wed Jan 31 18:47:00 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 31 Jan 2018 17:47:00 +0000
Subject: [R] Problems with "predict" function ii
In-Reply-To: <1195865783.2815400.1517419210201.JavaMail.open-xchange@oxbe4.tb.ukmail.iss.as9143.net>
References: <1195865783.2815400.1517419210201.JavaMail.open-xchange@oxbe4.tb.ukmail.iss.as9143.net>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF880155FD5CF4@SRVEXCHCM301.precheza.cz>

Hi

First of all you should not post in HTML.

Thank you for posting the code, however I do not understand wht exactly do you mean by that you get many lines. I get only one with your code.

Other answers see in line

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of WRAY NICHOLAS via R-help
Sent: Wednesday, January 31, 2018 6:20 PM
To: r-help <r-help at r-project.org>
Subject: [R] Problems with "predict" function ii

I  have realised that I should have used "detach" before attaching another dataframe, but even when I do this it's still giving me lots of lines, rather than just one:



And you should not use attach, it is hardly ever necessary.

My code:


m<-runif(1,0,1)
m
mres<-m*(seq(1,12))
mres
ssd<-rexp(1,1)
ssd
devs<-rep(0,length(mres))
for(i in 1:length(mres)){devs[i]<-rnorm(1,0,ssd)}
devs
plot(-10,-10,xlim=c(1,24),ylim=c(0,20000))
sales<-round((mres+devs)*1000)

points(sales,pch=19)

ptr<-cbind(1:length(sales),sales,sales,sales)

ptr
sdf<-data.frame(cbind(1:nrow(ptr),sales))
sdf

colnames(sdf)<-c(?monat?,?mitte?)
sdf




attach(sdf)
s.lm<-lm(mitte~monat)


instead of attach use
s.lm<-lm(mitte~monat, data=sdf)


s.lm
abline(s.lm,lty=2)
news<-data.frame(monat=nrow(sdf)+1)
news
fcs<-predict(s.lm,news,interval=?predict?)
fcs

points(1+nrow(ptr),fcs[,1],col=?grey?,pch=19)
points(1+nrow(ptr),fcs[,2])
points(1+nrow(ptr),fcs[,3])
ptr<-rbind(ptr,c(1+nrow(ptr),fcs[2],fcs[1],fcs[3]))
ptr

highdf<-data.frame(ptr[,c(1,4)])
highdf
colnames(highdf)<-c(?month?,?sales?)
highdf
##detach(sdf)
##attach(highdf)
##h.lm<-lm(highdf[,2]~highdf[,1])
h.lm<-lm(sales~month, highdf)


h.lm
abline(h.lm,col="gray",lty=2)
news<-data.frame(month=nrow(ptr)+1)
news
hcs<-predict(h.lm,news,interval=?predict?)
hcs

I get a picture with two lines, black from you first call to the abline, second from your second call. What you want to achieve?

Cheers
Petr



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From istazahn at gmail.com  Wed Jan 31 18:47:30 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 31 Jan 2018 12:47:30 -0500
Subject: [R] variable names in lm formula ~.
In-Reply-To: <CAGxFJbSxcPyvDyMbrA7ofoponbjYS7Xzvm3VnzQktmAtZox_fw@mail.gmail.com>
References: <85753698-435f-a28b-a97b-049e09bb896c@unipa.it>
 <80E78752-2349-4BD2-BA7D-85DB731E10B2@dcn.davis.ca.us>
 <CAGxFJbSxcPyvDyMbrA7ofoponbjYS7Xzvm3VnzQktmAtZox_fw@mail.gmail.com>
Message-ID: <CA+vqiLHcaRXFXTK8w7=9v64sffNwk9gEpvc8yLZRdJpkJO6kdA@mail.gmail.com>

I poked at this a little bit and found that the issue exists in
stats:::C_termsform (which is called by terms.formula).

Here is a variation on the demonstrations provided by Vito and Bert earlier:

d<-data.frame(y=rnorm(10,5,.5),
              age=rnorm(10),
              exp=rnorm(10),
              log = runif(10))

fs <- list(y ~ .,
           exp(y) ~ .,
           log(y) ~ .)

lapply(fs, function(x) terms(x, data = d)[[3]])
## [[1]]
## age + exp + log

## [[2]]
## age + log

## [[3]]
## age + exp

lapply(fs,
       function(x)
           .External(stats:::C_termsform,
                     x,
                     NULL,
                     d,
                     FALSE,
                     FALSE)[[3]])
## [[1]]
## age + exp + log

## [[2]]
## age + log

## [[3]]
## age + exp

I don't speak C so I stopped there.

Best,
Ista

On Tue, Jan 30, 2018 at 11:12 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Well...
>
> ?terms.formula says:
>
> "data: a data frame from which the meaning of the special symbol . can
> be inferred. It is unused if there is no . in the formula."
>
> So this seems to me to be an obscure bug, as I have found no warning
> against this admittedly confusing but still, I think, legal syntax.
> Note:
>
>> d <- data.frame(log = runif(10), x = 1:10)
>> y <- rnorm(10,5)
>
>> m1 <- lm(y ~ ., data = d)
>> formula(m1)
> y ~ log + x
>
>> m2 <- update(m1, formula =log(y) ~.)
>> formula(m2)
> log(y) ~ log + x
>
>> m3 = lm(log(y) ~., data =d)
>> formula(m3)
> log(y) ~ x
>
> As always, correction appreciated if I'm wrong.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Tue, Jan 30, 2018 at 6:23 AM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> Functions are first class objects, so some kind of collision is bound to happen if you do this... so don't.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On January 30, 2018 3:11:56 AM PST, "Vito M. R. Muggeo" <vito.muggeo at unipa.it> wrote:
>> >dear all,
>> >Is the following intentional? Am I missing anything in documentation?
>> >
>> >d<-data.frame(y=rnorm(10,5,.5),exp=rnorm(10), age=rnorm(10))
>> >formula(lm(exp(y)~exp+age, data=d))
>> >#--> exp(y) ~ exp + age
>> >
>> >formula(lm(exp(y)~., data=d))
>> >#--> exp(y) ~ age
>> >
>> >variable 'exp' (maybe indicating "experience") is not included in the
>> >model. The same happens with 'log' (and other function names, I
>> >suppose..)
>> >
>> >best,
>> >vito
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Wed Jan 31 19:30:00 2018
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 31 Jan 2018 18:30:00 +0000
Subject: [R] Problems with "predict" function ii
In-Reply-To: <1195865783.2815400.1517419210201.JavaMail.open-xchange@oxbe4.tb.ukmail.iss.as9143.net>
References: <1195865783.2815400.1517419210201.JavaMail.open-xchange@oxbe4.tb.ukmail.iss.as9143.net>
Message-ID: <6cee7a8d-1807-df34-5659-86c9ba1bb44f@sapo.pt>

Hello,

First of all, your question is about 'predict' but you include graphic 
instructions that have nothing to do with it. They do not hurt, but the 
reproducible example should also be minimal.

Second, whenever you use RNG's, you should start it with set.seed().

Now, I have edited your code and it all works. No errors.
I got it rid of attach/detach and of the graphics.
And added spaces around some bits, such as <-, =, etc.


set.seed(187)    # Make the results reproducible

m <- runif(1,0,1)
m
mres <- m*(seq(1, 12))
mres
ssd <- rexp(1, 1)
ssd
devs <- rep(0, length(mres))
for(i in 1:length(mres)){
     devs[i] <- rnorm(1, 0, ssd)
}
devs
sales <- round((mres+devs)*1000)

ptr <- cbind(1:length(sales), sales, sales, sales)
ptr

sdf <- data.frame(1:nrow(ptr), sales)
colnames(sdf)<-c("monat", "mitte")
sdf

#attach(sdf)
s.lm <- lm(mitte ~ monat, sdf)
s.lm

news <- data.frame(monat = nrow(sdf) + 1)
news

fcs <- predict(s.lm, newdata = news, interval = "predict")
fcs

ptr <- rbind(ptr, c(1 + nrow(ptr), fcs[2], fcs[1], fcs[3]))
ptr

highdf <- data.frame(ptr[, c(1, 4)])
colnames(highdf) <- c("month","sales")
highdf

#detach(sdf)
#attach(highdf)
h.lm <- lm(sales ~ month, highdf)
h.lm
news <- data.frame(month = nrow(ptr) + 1)
news
hcs <- predict(h.lm, newdata = news, interval = "predict")
hcs



On 1/31/2018 5:20 PM, WRAY NICHOLAS via R-help wrote:
> I  have realised that I should have used "detach" before attaching another
> dataframe, but even when I do this it's still giving me lots of lines, rather
> than just one:
> 
> My code:
> 
> 
> m<-runif(1,0,1)
> m
> mres<-m*(seq(1,12))
> mres
> ssd<-rexp(1,1)
> ssd
> devs<-rep(0,length(mres))
> for(i in 1:length(mres)){devs[i]<-rnorm(1,0,ssd)}
> devs
> plot(-10,-10,xlim=c(1,24),ylim=c(0,20000))
> sales<-round((mres+devs)*1000)
> 
> points(sales,pch=19)
> 
> ptr<-cbind(1:length(sales),sales,sales,sales)
> 
> ptr
> sdf<-data.frame(cbind(1:nrow(ptr),sales))
> sdf
> 
> colnames(sdf)<-c(?monat?,?mitte?)
> sdf
> attach(sdf)
> s.lm<-lm(mitte~monat)
> 
> s.lm
> abline(s.lm,lty=2)
> news<-data.frame(monat=nrow(sdf)+1)
> news
> fcs<-predict(s.lm,news,interval=?predict?)
> fcs
> 
> points(1+nrow(ptr),fcs[,1],col=?grey?,pch=19)
> points(1+nrow(ptr),fcs[,2])
> points(1+nrow(ptr),fcs[,3])
> ptr<-rbind(ptr,c(1+nrow(ptr),fcs[2],fcs[1],fcs[3]))
> ptr
> 
> highdf<-data.frame(ptr[,c(1,4)])
> highdf
> colnames(highdf)<-c(?month?,?sales?)
> highdf
> detach(sdf)
> attach(highdf)
> h.lm<-lm(highdf[,2]~highdf[,1])
> h.lm
> abline(h.lm,col="gray",lty=2)
> news<-data.frame(month=nrow(ptr)+1)
> news
> hcs<-predict(h.lm,news,interval=?predict?)
> hcs
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


